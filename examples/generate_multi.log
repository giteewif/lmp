here pin
INFO 01-05 12:51:11.410262.410262 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-05 12:51:12.247288.247288 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-05 12:51:12.694147.694147 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-05 12:51:12.694847.694847 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.284s
DEBUG 01-05 12:51:12.849334.849334 cuda_memory_view.py:260] 
DEBUG 01-05 12:51:12.849334.849334 cuda_memory_view.py:260] restore_tensors_from_shared_memory_names time: 0.017360448837280273
DEBUG 01-05 12:51:13.871169.871169 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.12103128433227539 s
DEBUG 01-05 12:51:14.390704.390704 cuda_h.py:19] end generate_input_ids cost 0.5180904865264893 seconds
DEBUG 01-05 12:51:14.390120.390120 cuda_h.py:10] start init_cache
DEBUG 01-05 12:51:14.390609.390609 cuda_h.py:19] end init_cache cost 0.00011324882507324219 seconds
DEBUG 01-05 12:51:17.001960.001960 cuda_h.py:10] start init_weights
DEBUG 01-05 12:51:17.002236.002236 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:17.002350.002350 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:17.002280.002280 cuda_h.py:19] end allocate_cuda_memory cost 0.00042891502380371094 seconds
DEBUG 01-05 12:51:17.002170.002170 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:17.002278.002278 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:17.002551.002551 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:17.002830.002830 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d8d1f75-31c8-480c-a119-37c35f7d8ce3
DEBUG 01-05 12:51:17.002297.002297 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:17.004524.004524 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d8d1f75-31c8-480c-a119-37c35f7d8ce3
DEBUG 01-05 12:51:17.004801.004801 cuda_h.py:19] end load_into_gpu_async cost 0.002163410186767578 seconds
DEBUG 01-05 12:51:17.005770.005770 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:17.005094.005094 cuda_h.py:19] end restore_tensors2 cost 9.512901306152344e-05 seconds
DEBUG 01-05 12:51:17.005757.005757 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030922889709472656 seconds
INFO 01-05 12:51:17.005413.005413 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d8d1f75-31c8-480c-a119-37c35f7d8ce3
INFO 01-05 12:51:17.091299.091299 client.py:127] Model loaded
DEBUG 01-05 12:51:17.091100.091100 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 12:51:17.091264.091264 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:17.091639.091639 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:17.092530.092530 cuda_h.py:19] end allocate_cuda_memory cost 0.0003781318664550781 seconds
DEBUG 01-05 12:51:17.092025.092025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:17.092275.092275 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:17.092855.092855 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:17.092818.092818 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6538be6a-95a3-4f37-9f8a-5e1225bdcf62
DEBUG 01-05 12:51:17.092168.092168 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:17.094891.094891 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6538be6a-95a3-4f37-9f8a-5e1225bdcf62
DEBUG 01-05 12:51:17.094884.094884 cuda_h.py:19] end load_into_gpu_async cost 0.0021615028381347656 seconds
DEBUG 01-05 12:51:17.094629.094629 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:17.094922.094922 cuda_h.py:19] end restore_tensors2 cost 0.00015926361083984375 seconds
DEBUG 01-05 12:51:17.095727.095727 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034427642822265625 seconds
INFO 01-05 12:51:17.095643.095643 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6538be6a-95a3-4f37-9f8a-5e1225bdcf62
INFO 01-05 12:51:17.111957.111957 client.py:127] Model loaded
DEBUG 01-05 12:51:17.112481.112481 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02135777473449707 seconds
DEBUG 01-05 12:51:17.113903.113903 cuda_h.py:19] end init_weights cost 0.11091876029968262 seconds
DEBUG 01-05 12:51:17.113303.113303 cuda_h.py:10] start copy_emodel
DEBUG 01-05 12:51:17.999988.999988 cuda_h.py:19] end copy_emodel cost 0.8862483501434326 seconds
DEBUG 01-05 12:51:18.000618.000618 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 12:51:18.077700.077700 cuda_h.py:19] end init_inputs_tokens cost 0.07734036445617676 seconds
DEBUG 01-05 12:51:18.077320.077320 cuda_h.py:10] start multi_layer
DEBUG 01-05 12:51:18.077725.077725 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 12:51:18.077521.077521 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:18.077654.077654 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:18.077432.077432 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.790855407714844e-05 seconds
DEBUG 01-05 12:51:18.078950.078950 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.271766662597656e-05 seconds
DEBUG 01-05 12:51:18.078122.078122 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:18.078690.078690 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.078589.078589 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.078989.078989 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.078636.078636 cuda_h.py:19] end allocate_cuda_memory cost 0.0002789497375488281 seconds
DEBUG 01-05 12:51:18.078202.078202 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.078800.078800 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.078411.078411 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.078280.078280 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 98682562-e79d-44cd-9b3b-a33247fc28ea
DEBUG 01-05 12:51:18.079318.079318 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.081845.081845 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 98682562-e79d-44cd-9b3b-a33247fc28ea
DEBUG 01-05 12:51:18.081955.081955 cuda_h.py:19] end load_into_gpu_async cost 0.002248525619506836 seconds
DEBUG 01-05 12:51:18.081275.081275 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.081433.081433 cuda_h.py:19] end restore_tensors2 cost 0.00012636184692382812 seconds
DEBUG 01-05 12:51:18.081959.081959 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003092527389526367 seconds
INFO 01-05 12:51:18.082413.082413 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 98682562-e79d-44cd-9b3b-a33247fc28ea
INFO 01-05 12:51:18.089822.089822 client.py:127] Model loaded
DEBUG 01-05 12:51:18.089814.089814 cuda_h.py:19] end sllm_worker_task cost 0.011077880859375 seconds
DEBUG 01-05 12:51:18.169347.169347 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:18.418386.418386 cuda_h.py:19] end self_attn cost 0.24805378913879395 seconds
DEBUG 01-05 12:51:18.418794.418794 cuda_h.py:19] end iln_self_attn_paln cost 0.340618371963501 seconds
DEBUG 01-05 12:51:18.418995.418995 cuda_h.py:10] start dense_mlp
DEBUG 01-05 12:51:18.418725.418725 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:18.418575.418575 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.337860107421875e-05 seconds
DEBUG 01-05 12:51:18.419170.419170 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.419613.419613 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.419971.419971 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.419290.419290 cuda_h.py:19] end allocate_cuda_memory cost 0.0003409385681152344 seconds
DEBUG 01-05 12:51:18.420017.420017 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.420424.420424 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.420659.420659 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.420092.420092 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e0ef516-e7b3-4b81-8209-83a3e7c9bb7c
DEBUG 01-05 12:51:18.420590.420590 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.422662.422662 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e0ef516-e7b3-4b81-8209-83a3e7c9bb7c
DEBUG 01-05 12:51:18.422806.422806 cuda_h.py:19] end load_into_gpu_async cost 0.00247955322265625 seconds
DEBUG 01-05 12:51:18.422722.422722 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.422253.422253 cuda_h.py:19] end restore_tensors2 cost 0.00013899803161621094 seconds
DEBUG 01-05 12:51:18.422944.422944 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003606081008911133 seconds
INFO 01-05 12:51:18.423182.423182 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e0ef516-e7b3-4b81-8209-83a3e7c9bb7c
DEBUG 01-05 12:51:18.425096.425096 cuda_h.py:19] end dense_mlp cost 0.006913423538208008 seconds
DEBUG 01-05 12:51:18.425430.425430 lmp.py:217] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 12:51:18.425478.425478 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 12:51:18.425863.425863 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 12:51:18.425911.425911 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 12:51:18.426264.426264 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.9550323486328125e-05 seconds
DEBUG 01-05 12:51:18.426112.426112 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.173683166503906e-05 seconds
DEBUG 01-05 12:51:18.426285.426285 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:18.426156.426156 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:18.430662.430662 cuda_h.py:19] end self_attn cost 0.0037851333618164062 seconds
DEBUG 01-05 12:51:18.430296.430296 cuda_h.py:19] end iln_self_attn_paln cost 0.004435062408447266 seconds
DEBUG 01-05 12:51:18.430530.430530 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 12:51:18.430207.430207 cuda_h.py:10] start gate
INFO 01-05 12:51:18.430888.430888 client.py:127] Model loaded
DEBUG 01-05 12:51:18.431451.431451 cuda_h.py:19] end sllm_worker_task cost 0.011949300765991211 seconds
DEBUG 01-05 12:51:18.431945.431945 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.431537.431537 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.431508.431508 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.431464.431464 cuda_h.py:19] end allocate_cuda_memory cost 0.0003600120544433594 seconds
DEBUG 01-05 12:51:18.432283.432283 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.432167.432167 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.432495.432495 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.432459.432459 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5cc48b3e-1adc-4ebc-b784-030d51d3e055
DEBUG 01-05 12:51:18.432247.432247 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.434453.434453 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5cc48b3e-1adc-4ebc-b784-030d51d3e055
DEBUG 01-05 12:51:18.434957.434957 cuda_h.py:19] end load_into_gpu_async cost 0.002411365509033203 seconds
DEBUG 01-05 12:51:18.434863.434863 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.435263.435263 cuda_h.py:19] end restore_tensors2 cost 0.0002865791320800781 seconds
DEBUG 01-05 12:51:18.435089.435089 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003937482833862305 seconds
INFO 01-05 12:51:18.436430.436430 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5cc48b3e-1adc-4ebc-b784-030d51d3e055
INFO 01-05 12:51:18.442371.442371 client.py:127] Model loaded
DEBUG 01-05 12:51:18.442806.442806 cuda_h.py:19] end sllm_worker_task cost 0.011005640029907227 seconds
DEBUG 01-05 12:51:18.527018.527018 cuda_h.py:19] end gate cost 0.09693241119384766 seconds
DEBUG 01-05 12:51:18.527114.527114 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:18.528483.528483 lmp.py:365] 
DEBUG 01-05 12:51:18.528483.528483 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:18.528914.528914 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:18.528948.528948 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:18.528883.528883 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:18.528718.528718 lmp.py:369] 
DEBUG 01-05 12:51:18.528718.528718 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:18.528374.528374 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:18.528600.528600 lmp.py:376]   Expert 22 |     35 | CPU
DEBUG 01-05 12:51:18.528389.528389 lmp.py:376]   Expert 62 |     44 | CPU
DEBUG 01-05 12:51:18.528463.528463 lmp.py:376]   Expert  3 |     53 | CPU
DEBUG 01-05 12:51:18.528589.528589 lmp.py:376]   Expert 48 |     56 | CPU
DEBUG 01-05 12:51:18.528855.528855 lmp.py:376]   Expert 18 |     62 | CPU
DEBUG 01-05 12:51:18.528120.528120 lmp.py:376]   Expert 39 |     78 | CPU
DEBUG 01-05 12:51:18.528194.528194 lmp.py:376]   Expert 13 |     82 | CPU
DEBUG 01-05 12:51:18.528267.528267 lmp.py:376]   Expert 47 |     83 | CPU
DEBUG 01-05 12:51:18.528864.528864 lmp.py:376]   Expert 53 |     88 | CPU
DEBUG 01-05 12:51:18.528461.528461 lmp.py:376]   Expert 51 |     91 | CPU
DEBUG 01-05 12:51:18.528057.528057 lmp.py:376]   Expert 32 |     93 | CPU
DEBUG 01-05 12:51:18.528369.528369 lmp.py:376]   Expert 54 |     94 | CPU
DEBUG 01-05 12:51:18.528966.528966 lmp.py:376]   Expert 36 |    101 | CPU
DEBUG 01-05 12:51:18.528801.528801 lmp.py:376]   Expert 58 |    101 | CPU
DEBUG 01-05 12:51:18.528159.528159 lmp.py:376]   Expert 38 |    105 | CPU
DEBUG 01-05 12:51:18.528233.528233 lmp.py:376]   Expert 37 |    114 | CPU
DEBUG 01-05 12:51:18.528829.528829 lmp.py:376]   Expert 25 |    115 | CPU
DEBUG 01-05 12:51:18.528618.528618 lmp.py:376]   Expert 27 |    118 | CPU
DEBUG 01-05 12:51:18.528645.528645 lmp.py:376]   Expert 21 |    121 | CPU
DEBUG 01-05 12:51:18.528434.528434 lmp.py:376]   Expert 31 |    121 | CPU
DEBUG 01-05 12:51:18.528031.528031 lmp.py:376]   Expert 41 |    121 | CPU
DEBUG 01-05 12:51:18.528866.528866 lmp.py:376]   Expert 30 |    124 | CPU
DEBUG 01-05 12:51:18.528462.528462 lmp.py:376]   Expert 55 |    126 | CPU
DEBUG 01-05 12:51:18.528820.528820 lmp.py:376]   Expert 59 |    127 | CPU
DEBUG 01-05 12:51:18.528417.528417 lmp.py:376]   Expert 28 |    132 | CPU
DEBUG 01-05 12:51:18.528537.528537 lmp.py:376]   Expert 49 |    142 | CPU
DEBUG 01-05 12:51:18.528418.528418 lmp.py:376]   Expert 29 |    154 | CPU
DEBUG 01-05 12:51:18.528777.528777 lmp.py:376]   Expert 12 |    156 | CPU
DEBUG 01-05 12:51:18.528135.528135 lmp.py:376]   Expert 50 |    169 | CPU
DEBUG 01-05 12:51:18.528685.528685 lmp.py:376]   Expert 11 |    173 | CPU
DEBUG 01-05 12:51:18.529520.529520 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 12:51:18.529832.529832 lmp.py:376]   Expert 24 |    176 | CPU
DEBUG 01-05 12:51:18.529667.529667 lmp.py:376]   Expert 35 |    179 | GPU
DEBUG 01-05 12:51:18.529549.529549 lmp.py:376]   Expert 60 |    179 | GPU
DEBUG 01-05 12:51:18.529668.529668 lmp.py:376]   Expert 63 |    182 | GPU
DEBUG 01-05 12:51:18.529027.529027 lmp.py:376]   Expert 15 |    189 | GPU
DEBUG 01-05 12:51:18.529862.529862 lmp.py:376]   Expert 61 |    191 | GPU
DEBUG 01-05 12:51:18.529981.529981 lmp.py:376]   Expert 19 |    192 | GPU
DEBUG 01-05 12:51:18.529340.529340 lmp.py:376]   Expert 33 |    194 | GPU
DEBUG 01-05 12:51:18.529698.529698 lmp.py:376]   Expert 23 |    212 | GPU
DEBUG 01-05 12:51:18.529056.529056 lmp.py:376]   Expert 17 |    214 | GPU
DEBUG 01-05 12:51:18.529176.529176 lmp.py:376]   Expert  2 |    222 | GPU
DEBUG 01-05 12:51:18.529773.529773 lmp.py:376]   Expert 52 |    222 | GPU
DEBUG 01-05 12:51:18.529800.529800 lmp.py:376]   Expert  0 |    231 | GPU
DEBUG 01-05 12:51:18.529396.529396 lmp.py:376]   Expert 43 |    231 | GPU
DEBUG 01-05 12:51:18.529516.529516 lmp.py:376]   Expert  1 |    237 | GPU
DEBUG 01-05 12:51:18.529636.529636 lmp.py:376]   Expert 40 |    237 | GPU
DEBUG 01-05 12:51:18.529756.529756 lmp.py:376]   Expert  9 |    250 | GPU
DEBUG 01-05 12:51:18.529637.529637 lmp.py:376]   Expert 44 |    254 | GPU
DEBUG 01-05 12:51:18.529757.529757 lmp.py:376]   Expert 45 |    278 | GPU
DEBUG 01-05 12:51:18.529877.529877 lmp.py:376]   Expert  6 |    287 | GPU
DEBUG 01-05 12:51:18.529235.529235 lmp.py:376]   Expert 14 |    303 | GPU
DEBUG 01-05 12:51:18.529355.529355 lmp.py:376]   Expert  4 |    314 | GPU
DEBUG 01-05 12:51:18.529713.529713 lmp.py:376]   Expert 16 |    314 | GPU
DEBUG 01-05 12:51:18.529833.529833 lmp.py:376]   Expert 26 |    316 | GPU
DEBUG 01-05 12:51:18.529622.529622 lmp.py:376]   Expert  8 |    317 | GPU
DEBUG 01-05 12:51:18.529841.529841 lmp.py:376]   Expert 34 |    327 | GPU
DEBUG 01-05 12:51:18.529630.529630 lmp.py:376]   Expert  7 |    340 | GPU
DEBUG 01-05 12:51:18.529465.529465 lmp.py:376]   Expert  5 |    347 | GPU
DEBUG 01-05 12:51:18.529585.529585 lmp.py:376]   Expert 10 |    357 | GPU
DEBUG 01-05 12:51:18.529704.529704 lmp.py:376]   Expert 46 |    389 | GPU
DEBUG 01-05 12:51:18.529301.529301 lmp.py:376]   Expert 42 |    410 | GPU
DEBUG 01-05 12:51:18.529182.529182 lmp.py:376]   Expert 20 |    422 | GPU
DEBUG 01-05 12:51:18.529302.529302 lmp.py:376]   Expert 57 |    423 | GPU
DEBUG 01-05 12:51:18.529376.529376 lmp.py:377] 
DEBUG 01-05 12:51:18.529376.529376 lmp.py:377]   CPU total tokens: 3528 (28.7%)
DEBUG 01-05 12:51:18.529688.529688 lmp.py:378]   GPU total tokens: 8760 (71.3%)
DEBUG 01-05 12:51:18.529960.529960 cuda_h.py:19] end experts_map_get cost 0.0018911361694335938 seconds
DEBUG 01-05 12:51:18.529179.529179 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:18.529347.529347 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.530422.530422 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.530236.530236 cuda_h.py:19] end allocate_cuda_memory cost 0.0003345012664794922 seconds
DEBUG 01-05 12:51:18.530259.530259 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.530260.530260 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.530275.530275 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.530455.530455 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b19bb705-d8d1-48a5-b183-97c2f43776e4
DEBUG 01-05 12:51:18.530263.530263 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.532975.532975 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b19bb705-d8d1-48a5-b183-97c2f43776e4
DEBUG 01-05 12:51:18.532831.532831 cuda_h.py:19] end load_into_gpu_async cost 0.002421140670776367 seconds
DEBUG 01-05 12:51:18.532057.532057 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.533428.533428 cuda_h.py:19] end restore_tensors2 cost 0.0003504753112792969 seconds
DEBUG 01-05 12:51:18.533912.533912 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036199092864990234 seconds
DEBUG 01-05 12:51:18.536525.536525 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006928205490112305 seconds
DEBUG 01-05 12:51:18.536229.536229 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:18.536036.536036 lmp.py:423] 
DEBUG 01-05 12:51:18.536036.536036 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:18.536105.536105 cuda_h.py:19] end cpu_experts_submit cost 0.0002224445343017578 seconds
DEBUG 01-05 12:51:18.537954.537954 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:18.552681.552681 mlpmodule.py:704] group tensors cost 0.015583038330078125 s
DEBUG 01-05 12:51:18.555883.555883 mlpmodule.py:742] pad cost 0.0023756027221679688 s
DEBUG 01-05 12:51:18.555503.555503 mlpmodule.py:748] create cpu tensor cost 6.985664367675781e-05 s
DEBUG 01-05 12:51:18.556288.556288 mlpmodule.py:753] move to cpu cost 3.981590270996094e-05 s
DEBUG 01-05 12:51:18.595849.595849 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:18.596835.596835 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:18.603435.603435 mlpmodule.py:773] group_w3 first element: 0.01348876953125
WARNING 01-05 12:51:18.603666.603666 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:18.626165.626165 mlpmodule.py:793] group einsum cost 0.06998801231384277 s
DEBUG 01-05 12:51:18.627132.627132 mlpmodule.py:801] cpy2cputensor cost 0.0006830692291259766 s
DEBUG 01-05 12:51:18.641648.641648 cuda_h.py:19] end wait_cetm_experts cost 0.10468745231628418 seconds
DEBUG 01-05 12:51:18.642247.642247 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:18.643514.643514 cuda_h.py:19] end gpu_sexperts cost 0.0011284351348876953 seconds
DEBUG 01-05 12:51:18.643796.643796 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:18.643909.643909 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.059906005859375e-05 seconds
DEBUG 01-05 12:51:18.644848.644848 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:18.644347.644347 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b19bb705-d8d1-48a5-b183-97c2f43776e4
INFO 01-05 12:51:18.645056.645056 client.py:127] Model loaded
DEBUG 01-05 12:51:18.645476.645476 cuda_h.py:19] end wait_experts cost 0.0010824203491210938 seconds
DEBUG 01-05 12:51:18.645324.645324 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:18.645127.645127 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:18.658218.658218 mlpmodule.py:662]  experts func einsum cost 0.12108874320983887 s
DEBUG 01-05 12:51:18.658640.658640 mlpmodule.py:531] gpu group tensors cost 0.013630151748657227 s
DEBUG 01-05 12:51:18.665395.665395 mlpmodule.py:564] gpu pad cost 0.005929708480834961 s
DEBUG 01-05 12:51:18.666268.666268 mlpmodule.py:582] gpu group einsum cost 0.0015821456909179688 s
DEBUG 01-05 12:51:18.673781.673781 mlpmodule.py:611] gpu experts func einsum cost 0.028156280517578125 s
DEBUG 01-05 12:51:18.673416.673416 cuda_h.py:19] end gpu_experts cost 0.028401851654052734 seconds
DEBUG 01-05 12:51:18.673818.673818 cuda_h.py:19] end layer_moe_generate_1 cost 0.24314641952514648 seconds
DEBUG 01-05 12:51:18.674972.674972 lmp.py:217] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 12:51:18.674968.674968 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 12:51:18.674360.674360 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 12:51:18.674733.674733 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 12:51:18.674300.674300 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.673004150390625e-05 seconds
DEBUG 01-05 12:51:18.674321.674321 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 0.00010418891906738281 seconds
DEBUG 01-05 12:51:18.674568.674568 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:18.674393.674393 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.674513.674513 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.674437.674437 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.675987.675987 cuda_h.py:19] end allocate_cuda_memory cost 0.00032138824462890625 seconds
DEBUG 01-05 12:51:18.675668.675668 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.675585.675585 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.675184.675184 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.675934.675934 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 33f47d8a-4623-47c9-899a-a98c18fbbf3d
DEBUG 01-05 12:51:18.675251.675251 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:18.676278.676278 cuda_h.py:10] start self_attn
INFO 01-05 12:51:18.677458.677458 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 33f47d8a-4623-47c9-899a-a98c18fbbf3d
DEBUG 01-05 12:51:18.677291.677291 cuda_h.py:19] end load_into_gpu_async cost 0.0020914077758789062 seconds
DEBUG 01-05 12:51:18.677466.677466 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.677660.677660 cuda_h.py:19] end restore_tensors2 cost 0.00014781951904296875 seconds
DEBUG 01-05 12:51:18.678617.678617 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032172203063964844 seconds
INFO 01-05 12:51:18.679439.679439 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 33f47d8a-4623-47c9-899a-a98c18fbbf3d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:18.681564.681564 cuda_h.py:19] end self_attn cost 0.005512714385986328 seconds
DEBUG 01-05 12:51:18.682019.682019 cuda_h.py:19] end iln_self_attn_paln cost 0.007693052291870117 seconds
DEBUG 01-05 12:51:18.682008.682008 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 12:51:18.682347.682347 cuda_h.py:10] start gate
DEBUG 01-05 12:51:18.683379.683379 cuda_h.py:19] end gate cost 0.0007188320159912109 seconds
DEBUG 01-05 12:51:18.683400.683400 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:18.683727.683727 lmp.py:365] 
DEBUG 01-05 12:51:18.683727.683727 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:18.683628.683628 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:18.683616.683616 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:18.683551.683551 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:18.683578.683578 lmp.py:369] 
DEBUG 01-05 12:51:18.683578.683578 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:18.683843.683843 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:18.683116.683116 lmp.py:376]   Expert  0 |     19 | CPU
DEBUG 01-05 12:51:18.683381.683381 lmp.py:376]   Expert 36 |     23 | CPU
DEBUG 01-05 12:51:18.683693.683693 lmp.py:376]   Expert 10 |     24 | CPU
DEBUG 01-05 12:51:18.683528.683528 lmp.py:376]   Expert 58 |     27 | CPU
DEBUG 01-05 12:51:18.683887.683887 lmp.py:376]   Expert 26 |     33 | CPU
DEBUG 01-05 12:51:18.683245.683245 lmp.py:376]   Expert 34 |     34 | CPU
DEBUG 01-05 12:51:18.683841.683841 lmp.py:376]   Expert 29 |     44 | CPU
DEBUG 01-05 12:51:18.683961.683961 lmp.py:376]   Expert  3 |     52 | CPU
DEBUG 01-05 12:51:18.683750.683750 lmp.py:376]   Expert  6 |     52 | CPU
DEBUG 01-05 12:51:18.683062.683062 lmp.py:376]   Expert  8 |     52 | CPU
DEBUG 01-05 12:51:18.683089.683089 lmp.py:376]   Expert  9 |     52 | CPU
DEBUG 01-05 12:51:18.683639.683639 lmp.py:376]   Expert 27 |     53 | CPU
DEBUG 01-05 12:51:18.683998.683998 lmp.py:376]   Expert 24 |     56 | CPU
DEBUG 01-05 12:51:18.683502.683502 lmp.py:376]   Expert 25 |     66 | CPU
DEBUG 01-05 12:51:18.683151.683151 lmp.py:376]   Expert 21 |     71 | CPU
DEBUG 01-05 12:51:18.683940.683940 lmp.py:376]   Expert  7 |     77 | CPU
DEBUG 01-05 12:51:18.683729.683729 lmp.py:376]   Expert 13 |     90 | CPU
DEBUG 01-05 12:51:18.683279.683279 lmp.py:376]   Expert 28 |     92 | CPU
DEBUG 01-05 12:51:18.684306.684306 lmp.py:376]   Expert 17 |     95 | CPU
DEBUG 01-05 12:51:18.684333.684333 lmp.py:376]   Expert 30 |     99 | CPU
DEBUG 01-05 12:51:18.684361.684361 lmp.py:376]   Expert 60 |    107 | CPU
DEBUG 01-05 12:51:18.684341.684341 lmp.py:376]   Expert 44 |    111 | CPU
DEBUG 01-05 12:51:18.684084.684084 lmp.py:376]   Expert 59 |    112 | CPU
DEBUG 01-05 12:51:18.684634.684634 lmp.py:376]   Expert  1 |    115 | CPU
DEBUG 01-05 12:51:18.684185.684185 lmp.py:376]   Expert 19 |    116 | CPU
DEBUG 01-05 12:51:18.684450.684450 lmp.py:376]   Expert 52 |    118 | CPU
DEBUG 01-05 12:51:18.684762.684762 lmp.py:376]   Expert 40 |    123 | CPU
DEBUG 01-05 12:51:18.684789.684789 lmp.py:376]   Expert 62 |    123 | CPU
DEBUG 01-05 12:51:18.684578.684578 lmp.py:376]   Expert 33 |    125 | CPU
DEBUG 01-05 12:51:18.684367.684367 lmp.py:376]   Expert 35 |    127 | CPU
DEBUG 01-05 12:51:18.684586.684586 lmp.py:376]   Expert 54 |    127 | CPU
DEBUG 01-05 12:51:18.684375.684375 lmp.py:376]   Expert  4 |    146 | CPU
DEBUG 01-05 12:51:18.684640.684640 lmp.py:376]   Expert 63 |    151 | GPU
DEBUG 01-05 12:51:18.684621.684621 lmp.py:376]   Expert 49 |    152 | GPU
DEBUG 01-05 12:51:18.684079.684079 lmp.py:376]   Expert  5 |    155 | GPU
DEBUG 01-05 12:51:18.684536.684536 lmp.py:376]   Expert 38 |    161 | GPU
DEBUG 01-05 12:51:18.684564.684564 lmp.py:376]   Expert 37 |    170 | GPU
DEBUG 01-05 12:51:18.684757.684757 lmp.py:376]   Expert 57 |    176 | GPU
DEBUG 01-05 12:51:18.684261.684261 lmp.py:376]   Expert 16 |    182 | GPU
DEBUG 01-05 12:51:18.684526.684526 lmp.py:376]   Expert 50 |    191 | GPU
DEBUG 01-05 12:51:18.684554.684554 lmp.py:376]   Expert 45 |    198 | GPU
DEBUG 01-05 12:51:18.684104.684104 lmp.py:376]   Expert 56 |    209 | GPU
DEBUG 01-05 12:51:18.684846.684846 lmp.py:376]   Expert 47 |    216 | GPU
DEBUG 01-05 12:51:18.684589.684589 lmp.py:376]   Expert  2 |    227 | GPU
DEBUG 01-05 12:51:18.684762.684762 lmp.py:376]   Expert 31 |    227 | GPU
DEBUG 01-05 12:51:18.684743.684743 lmp.py:376]   Expert 22 |    251 | GPU
DEBUG 01-05 12:51:18.684770.684770 lmp.py:376]   Expert 51 |    251 | GPU
DEBUG 01-05 12:51:18.684320.684320 lmp.py:376]   Expert 23 |    252 | GPU
DEBUG 01-05 12:51:18.684109.684109 lmp.py:376]   Expert 55 |    252 | GPU
DEBUG 01-05 12:51:18.684897.684897 lmp.py:376]   Expert 32 |    256 | GPU
DEBUG 01-05 12:51:18.684686.684686 lmp.py:376]   Expert 46 |    259 | GPU
DEBUG 01-05 12:51:18.684475.684475 lmp.py:376]   Expert 39 |    272 | GPU
DEBUG 01-05 12:51:18.684502.684502 lmp.py:376]   Expert 14 |    278 | GPU
DEBUG 01-05 12:51:18.684814.684814 lmp.py:376]   Expert 12 |    289 | GPU
DEBUG 01-05 12:51:18.684795.684795 lmp.py:376]   Expert 43 |    302 | GPU
DEBUG 01-05 12:51:18.684299.684299 lmp.py:376]   Expert 53 |    313 | GPU
DEBUG 01-05 12:51:18.684233.684233 lmp.py:376]   Expert 20 |    315 | GPU
DEBUG 01-05 12:51:18.684261.684261 lmp.py:376]   Expert 42 |    343 | GPU
DEBUG 01-05 12:51:18.684288.684288 lmp.py:376]   Expert 15 |    389 | GPU
DEBUG 01-05 12:51:18.684076.684076 lmp.py:376]   Expert 41 |    391 | GPU
DEBUG 01-05 12:51:18.684865.684865 lmp.py:376]   Expert 18 |    429 | GPU
DEBUG 01-05 12:51:18.684654.684654 lmp.py:376]   Expert 48 |    488 | GPU
DEBUG 01-05 12:51:18.684443.684443 lmp.py:376]   Expert 11 |    526 | GPU
DEBUG 01-05 12:51:18.684993.684993 lmp.py:376]   Expert 61 |   1456 | GPU
DEBUG 01-05 12:51:18.684451.684451 lmp.py:377] 
DEBUG 01-05 12:51:18.684451.684451 lmp.py:377]   CPU total tokens: 2561 (20.8%)
DEBUG 01-05 12:51:18.684908.684908 lmp.py:378]   GPU total tokens: 9727 (79.2%)
DEBUG 01-05 12:51:18.685611.685611 cuda_h.py:19] end experts_map_get cost 0.0019152164459228516 seconds
DEBUG 01-05 12:51:18.685261.685261 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:18.685090.685090 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.685452.685452 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.685860.685860 cuda_h.py:19] end allocate_cuda_memory cost 0.0002636909484863281 seconds
DEBUG 01-05 12:51:18.685061.685061 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.685870.685870 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.685017.685017 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.685097.685097 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 055af805-9e86-4882-ba41-9c504adec873
DEBUG 01-05 12:51:18.685275.685275 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.686421.686421 client.py:127] Model loaded
DEBUG 01-05 12:51:18.686333.686333 cuda_h.py:19] end sllm_worker_task cost 0.01146078109741211 seconds
INFO 01-05 12:51:18.687159.687159 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 055af805-9e86-4882-ba41-9c504adec873
DEBUG 01-05 12:51:18.687347.687347 cuda_h.py:19] end load_into_gpu_async cost 0.001963376998901367 seconds
DEBUG 01-05 12:51:18.687003.687003 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.687564.687564 cuda_h.py:19] end restore_tensors2 cost 0.0003161430358886719 seconds
DEBUG 01-05 12:51:18.687572.687572 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028917789459228516 seconds
DEBUG 01-05 12:51:18.691387.691387 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00610041618347168 seconds
DEBUG 01-05 12:51:18.691746.691746 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:18.691458.691458 lmp.py:423] 
DEBUG 01-05 12:51:18.691458.691458 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:18.691116.691116 cuda_h.py:19] end cpu_experts_submit cost 0.00012135505676269531 seconds
DEBUG 01-05 12:51:18.691865.691865 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:18.705937.705937 mlpmodule.py:704] group tensors cost 0.013925313949584961 s
DEBUG 01-05 12:51:18.707642.707642 mlpmodule.py:742] pad cost 0.0015587806701660156 s
DEBUG 01-05 12:51:18.707600.707600 mlpmodule.py:748] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-05 12:51:18.708310.708310 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 12:51:18.724072.724072 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:18.725318.725318 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:18.725565.725565 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 12:51:18.725987.725987 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:18.742234.742234 mlpmodule.py:793] group einsum cost 0.03462839126586914 s
DEBUG 01-05 12:51:18.743011.743011 mlpmodule.py:801] cpy2cputensor cost 0.0006279945373535156 s
DEBUG 01-05 12:51:18.750740.750740 cuda_h.py:19] end wait_cetm_experts cost 0.058921098709106445 seconds
DEBUG 01-05 12:51:18.750969.750969 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:18.751440.751440 cuda_h.py:19] end gpu_sexperts cost 0.0005862712860107422 seconds
DEBUG 01-05 12:51:18.751661.751661 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:18.751485.751485 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.100799560546875e-05 seconds
DEBUG 01-05 12:51:18.751856.751856 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:18.751758.751758 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 055af805-9e86-4882-ba41-9c504adec873
INFO 01-05 12:51:18.752191.752191 client.py:127] Model loaded
DEBUG 01-05 12:51:18.752545.752545 cuda_h.py:19] end wait_experts cost 0.0011432170867919922 seconds
DEBUG 01-05 12:51:18.752632.752632 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:18.752295.752295 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:18.753184.753184 mlpmodule.py:531] gpu group tensors cost 0.0007352828979492188 s
DEBUG 01-05 12:51:18.763734.763734 mlpmodule.py:564] gpu pad cost 0.010409116744995117 s
DEBUG 01-05 12:51:18.768049.768049 mlpmodule.py:662]  experts func einsum cost 0.07645845413208008 s
DEBUG 01-05 12:51:18.769063.769063 mlpmodule.py:582] gpu group einsum cost 0.005226612091064453 s
DEBUG 01-05 12:51:18.772266.772266 mlpmodule.py:611] gpu experts func einsum cost 0.019999980926513672 s
DEBUG 01-05 12:51:18.772223.772223 cuda_h.py:19] end gpu_experts cost 0.02020883560180664 seconds
DEBUG 01-05 12:51:18.772493.772493 cuda_h.py:19] end layer_moe_generate_2 cost 0.09059500694274902 seconds
DEBUG 01-05 12:51:18.773778.773778 lmp.py:217] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 12:51:18.773839.773839 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 12:51:18.773734.773734 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 12:51:18.773404.773404 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 12:51:18.773592.773592 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.337860107421875e-05 seconds
DEBUG 01-05 12:51:18.773447.773447 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.319450378417969e-05 seconds
DEBUG 01-05 12:51:18.773243.773243 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:18.773293.773293 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.773223.773223 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.773801.773801 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.773405.773405 cuda_h.py:19] end allocate_cuda_memory cost 0.0001888275146484375 seconds
DEBUG 01-05 12:51:18.773025.773025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.773563.773563 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.774313.774313 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.774745.774745 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 775a8601-4027-4bf2-b697-0942877170c4
DEBUG 01-05 12:51:18.774616.774616 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:18.774332.774332 cuda_h.py:10] start self_attn
INFO 01-05 12:51:18.775362.775362 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 775a8601-4027-4bf2-b697-0942877170c4
DEBUG 01-05 12:51:18.775822.775822 cuda_h.py:19] end load_into_gpu_async cost 0.001804351806640625 seconds
DEBUG 01-05 12:51:18.775346.775346 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.775602.775602 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-05 12:51:18.775133.775133 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002419710159301758 seconds
INFO 01-05 12:51:18.776044.776044 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 775a8601-4027-4bf2-b697-0942877170c4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:18.778105.778105 cuda_h.py:19] end self_attn cost 0.0040073394775390625 seconds
DEBUG 01-05 12:51:18.778346.778346 cuda_h.py:19] end iln_self_attn_paln cost 0.005622148513793945 seconds
DEBUG 01-05 12:51:18.779719.779719 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 12:51:18.779866.779866 cuda_h.py:10] start gate
DEBUG 01-05 12:51:18.779003.779003 cuda_h.py:19] end gate cost 0.0006992816925048828 seconds
DEBUG 01-05 12:51:18.779164.779164 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:18.780365.780365 lmp.py:365] 
DEBUG 01-05 12:51:18.780365.780365 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:18.780711.780711 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:18.780030.780030 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:18.780296.780296 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:18.780700.780700 lmp.py:369] 
DEBUG 01-05 12:51:18.780700.780700 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:18.780535.780535 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:18.780900.780900 lmp.py:376]   Expert 37 |     22 | CPU
DEBUG 01-05 12:51:18.780451.780451 lmp.py:376]   Expert 44 |     22 | CPU
DEBUG 01-05 12:51:18.780094.780094 lmp.py:376]   Expert 15 |     32 | CPU
DEBUG 01-05 12:51:18.780021.780021 lmp.py:376]   Expert 59 |     33 | CPU
DEBUG 01-05 12:51:18.780187.780187 lmp.py:376]   Expert  5 |     34 | CPU
DEBUG 01-05 12:51:18.780115.780115 lmp.py:376]   Expert 16 |     47 | CPU
DEBUG 01-05 12:51:18.780328.780328 lmp.py:376]   Expert 18 |     48 | CPU
DEBUG 01-05 12:51:18.780984.780984 lmp.py:376]   Expert  4 |     62 | CPU
DEBUG 01-05 12:51:18.780150.780150 lmp.py:376]   Expert 32 |     66 | CPU
DEBUG 01-05 12:51:18.780078.780078 lmp.py:376]   Expert  7 |     73 | CPU
DEBUG 01-05 12:51:18.780767.780767 lmp.py:376]   Expert  1 |     78 | CPU
DEBUG 01-05 12:51:18.780695.780695 lmp.py:376]   Expert 61 |     81 | CPU
DEBUG 01-05 12:51:18.780338.780338 lmp.py:376]   Expert 35 |     86 | CPU
DEBUG 01-05 12:51:18.780981.780981 lmp.py:376]   Expert 48 |     89 | CPU
DEBUG 01-05 12:51:18.780862.780862 lmp.py:376]   Expert 24 |     92 | CPU
DEBUG 01-05 12:51:18.780505.780505 lmp.py:376]   Expert 40 |    100 | CPU
DEBUG 01-05 12:51:18.780433.780433 lmp.py:376]   Expert 49 |    109 | CPU
DEBUG 01-05 12:51:18.780122.780122 lmp.py:376]   Expert 63 |    112 | CPU
DEBUG 01-05 12:51:18.780812.780812 lmp.py:376]   Expert 57 |    113 | CPU
DEBUG 01-05 12:51:18.780501.780501 lmp.py:376]   Expert 29 |    116 | CPU
DEBUG 01-05 12:51:18.780429.780429 lmp.py:376]   Expert 28 |    130 | CPU
DEBUG 01-05 12:51:18.780880.780880 lmp.py:376]   Expert 30 |    130 | CPU
DEBUG 01-05 12:51:18.780569.780569 lmp.py:376]   Expert 42 |    132 | CPU
DEBUG 01-05 12:51:18.780258.780258 lmp.py:376]   Expert 58 |    132 | CPU
DEBUG 01-05 12:51:18.780007.780007 lmp.py:376]   Expert 55 |    134 | CPU
DEBUG 01-05 12:51:18.780889.780889 lmp.py:376]   Expert 12 |    137 | CPU
DEBUG 01-05 12:51:18.780770.780770 lmp.py:376]   Expert  6 |    139 | CPU
DEBUG 01-05 12:51:18.780459.780459 lmp.py:376]   Expert 10 |    139 | CPU
DEBUG 01-05 12:51:18.780910.780910 lmp.py:376]   Expert 26 |    140 | CPU
DEBUG 01-05 12:51:18.780600.780600 lmp.py:376]   Expert 47 |    142 | CPU
DEBUG 01-05 12:51:18.780812.780812 lmp.py:376]   Expert 38 |    145 | CPU
DEBUG 01-05 12:51:18.780501.780501 lmp.py:376]   Expert 52 |    145 | CPU
DEBUG 01-05 12:51:18.780714.780714 lmp.py:376]   Expert 11 |    147 | GPU
DEBUG 01-05 12:51:18.780403.780403 lmp.py:376]   Expert 23 |    153 | GPU
DEBUG 01-05 12:51:18.780616.780616 lmp.py:376]   Expert 53 |    154 | GPU
DEBUG 01-05 12:51:18.780067.780067 lmp.py:376]   Expert  2 |    162 | GPU
DEBUG 01-05 12:51:18.780709.780709 lmp.py:376]   Expert 34 |    163 | GPU
DEBUG 01-05 12:51:18.780352.780352 lmp.py:376]   Expert 51 |    178 | GPU
DEBUG 01-05 12:51:18.780757.780757 lmp.py:376]   Expert  3 |    187 | GPU
DEBUG 01-05 12:51:18.780638.780638 lmp.py:376]   Expert  8 |    192 | GPU
DEBUG 01-05 12:51:18.780328.780328 lmp.py:376]   Expert 36 |    192 | GPU
DEBUG 01-05 12:51:18.780779.780779 lmp.py:376]   Expert 22 |    196 | GPU
DEBUG 01-05 12:51:18.780229.780229 lmp.py:376]   Expert 31 |    207 | GPU
DEBUG 01-05 12:51:18.781442.781442 lmp.py:376]   Expert 62 |    215 | GPU
DEBUG 01-05 12:51:18.781131.781131 lmp.py:376]   Expert 39 |    218 | GPU
DEBUG 01-05 12:51:18.781582.781582 lmp.py:376]   Expert 45 |    224 | GPU
DEBUG 01-05 12:51:18.781271.781271 lmp.py:376]   Expert 14 |    248 | GPU
DEBUG 01-05 12:51:18.781484.781484 lmp.py:376]   Expert 27 |    248 | GPU
DEBUG 01-05 12:51:18.781935.781935 lmp.py:376]   Expert 50 |    249 | GPU
DEBUG 01-05 12:51:18.781386.781386 lmp.py:376]   Expert 17 |    256 | GPU
DEBUG 01-05 12:51:18.781552.781552 lmp.py:376]   Expert 13 |    259 | GPU
DEBUG 01-05 12:51:18.781195.781195 lmp.py:376]   Expert 21 |    284 | GPU
DEBUG 01-05 12:51:18.781076.781076 lmp.py:376]   Expert  0 |    291 | GPU
DEBUG 01-05 12:51:18.781481.781481 lmp.py:376]   Expert 56 |    319 | GPU
DEBUG 01-05 12:51:18.781408.781408 lmp.py:376]   Expert 46 |    339 | GPU
DEBUG 01-05 12:51:18.781098.781098 lmp.py:376]   Expert 60 |    349 | GPU
DEBUG 01-05 12:51:18.781171.781171 lmp.py:376]   Expert 20 |    350 | GPU
DEBUG 01-05 12:51:18.781053.781053 lmp.py:376]   Expert 33 |    357 | GPU
DEBUG 01-05 12:51:18.781696.781696 lmp.py:376]   Expert  9 |    375 | GPU
DEBUG 01-05 12:51:18.781577.781577 lmp.py:376]   Expert 25 |    460 | GPU
DEBUG 01-05 12:51:18.781982.781982 lmp.py:376]   Expert 19 |    463 | GPU
DEBUG 01-05 12:51:18.781386.781386 lmp.py:376]   Expert 43 |    496 | GPU
DEBUG 01-05 12:51:18.781791.781791 lmp.py:376]   Expert 54 |    584 | GPU
DEBUG 01-05 12:51:18.781434.781434 lmp.py:376]   Expert 41 |    713 | GPU
DEBUG 01-05 12:51:18.781746.781746 lmp.py:377] 
DEBUG 01-05 12:51:18.781746.781746 lmp.py:377]   CPU total tokens: 3060 (24.9%)
DEBUG 01-05 12:51:18.781296.781296 lmp.py:378]   GPU total tokens: 9228 (75.1%)
DEBUG 01-05 12:51:18.781376.781376 cuda_h.py:19] end experts_map_get cost 0.0015668869018554688 seconds
DEBUG 01-05 12:51:18.781211.781211 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:18.781656.781656 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.781025.781025 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.783018.783018 cuda_h.py:19] end allocate_cuda_memory cost 0.0015401840209960938 seconds
DEBUG 01-05 12:51:18.783100.783100 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.783094.783094 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.783910.783910 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.783706.783706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2fb545db-8e18-4adb-9b4e-017520cb2095
DEBUG 01-05 12:51:18.783665.783665 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.784927.784927 client.py:127] Model loaded
DEBUG 01-05 12:51:18.784811.784811 cuda_h.py:19] end sllm_worker_task cost 0.010654926300048828 seconds
INFO 01-05 12:51:18.785193.785193 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2fb545db-8e18-4adb-9b4e-017520cb2095
DEBUG 01-05 12:51:18.785612.785612 cuda_h.py:19] end load_into_gpu_async cost 0.0024156570434570312 seconds
DEBUG 01-05 12:51:18.785051.785051 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.786412.786412 cuda_h.py:19] end restore_tensors2 cost 0.0002765655517578125 seconds
DEBUG 01-05 12:51:18.786420.786420 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004578113555908203 seconds
DEBUG 01-05 12:51:18.788837.788837 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007382392883300781 seconds
DEBUG 01-05 12:51:18.788534.788534 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:18.789101.789101 lmp.py:423] 
DEBUG 01-05 12:51:18.789101.789101 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:18.789851.789851 cuda_h.py:19] end cpu_experts_submit cost 0.00011706352233886719 seconds
DEBUG 01-05 12:51:18.789315.789315 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:18.796906.796906 mlpmodule.py:704] group tensors cost 0.006797313690185547 s
DEBUG 01-05 12:51:18.799713.799713 mlpmodule.py:742] pad cost 0.002343416213989258 s
DEBUG 01-05 12:51:18.799385.799385 mlpmodule.py:748] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-05 12:51:18.799911.799911 mlpmodule.py:753] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-05 12:51:18.809766.809766 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:18.809566.809566 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:18.809683.809683 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 12:51:18.809938.809938 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:18.826599.826599 mlpmodule.py:793] group einsum cost 0.027184724807739258 s
DEBUG 01-05 12:51:18.827857.827857 mlpmodule.py:801] cpy2cputensor cost 0.0005908012390136719 s
DEBUG 01-05 12:51:18.833377.833377 cuda_h.py:19] end wait_cetm_experts cost 0.04452085494995117 seconds
DEBUG 01-05 12:51:18.833751.833751 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:18.834516.834516 cuda_h.py:19] end gpu_sexperts cost 0.0004520416259765625 seconds
DEBUG 01-05 12:51:18.834068.834068 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:18.834494.834494 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-05 12:51:18.834866.834866 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:18.834575.834575 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2fb545db-8e18-4adb-9b4e-017520cb2095
INFO 01-05 12:51:18.837060.837060 client.py:127] Model loaded
DEBUG 01-05 12:51:18.837718.837718 cuda_h.py:19] end wait_experts cost 0.003265380859375 seconds
DEBUG 01-05 12:51:18.837428.837428 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:18.837899.837899 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:18.838366.838366 mlpmodule.py:531] gpu group tensors cost 0.0006182193756103516 s
DEBUG 01-05 12:51:18.840595.840595 mlpmodule.py:564] gpu pad cost 0.0016584396362304688 s
DEBUG 01-05 12:51:18.840549.840549 mlpmodule.py:582] gpu group einsum cost 0.0005276203155517578 s
DEBUG 01-05 12:51:18.843623.843623 mlpmodule.py:611] gpu experts func einsum cost 0.006108760833740234 s
DEBUG 01-05 12:51:18.844036.844036 cuda_h.py:19] end gpu_experts cost 0.006283283233642578 seconds
DEBUG 01-05 12:51:18.844483.844483 cuda_h.py:19] end layer_moe_generate_3 cost 0.06510162353515625 seconds
DEBUG 01-05 12:51:18.844011.844011 lmp.py:217] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 12:51:18.844058.844058 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 12:51:18.844278.844278 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 12:51:18.844557.844557 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 12:51:18.844281.844281 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 4.220008850097656e-05 seconds
DEBUG 01-05 12:51:18.844984.844984 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.390975952148438e-05 seconds
DEBUG 01-05 12:51:18.844581.844581 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:18.844219.844219 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.844513.844513 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.844409.844409 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.845665.845665 cuda_h.py:19] end allocate_cuda_memory cost 0.0010578632354736328 seconds
DEBUG 01-05 12:51:18.845250.845250 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.845027.845027 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.846578.846578 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.846996.846996 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eed0f975-f1f5-4c12-95d8-4c10137c81b6
DEBUG 01-05 12:51:18.846873.846873 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:18.846561.846561 cuda_h.py:10] start self_attn
INFO 01-05 12:51:18.847035.847035 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eed0f975-f1f5-4c12-95d8-4c10137c81b6
DEBUG 01-05 12:51:18.847793.847793 cuda_h.py:19] end load_into_gpu_async cost 0.0015125274658203125 seconds
DEBUG 01-05 12:51:18.847463.847463 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.847374.847374 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-05 12:51:18.847282.847282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029497146606445312 seconds
INFO 01-05 12:51:18.848600.848600 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eed0f975-f1f5-4c12-95d8-4c10137c81b6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:18.850809.850809 cuda_h.py:19] end self_attn cost 0.003981828689575195 seconds
DEBUG 01-05 12:51:18.850402.850402 cuda_h.py:19] end iln_self_attn_paln cost 0.006299495697021484 seconds
DEBUG 01-05 12:51:18.850338.850338 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 12:51:18.850816.850816 cuda_h.py:10] start gate
DEBUG 01-05 12:51:18.851800.851800 mlpmodule.py:662]  experts func einsum cost 0.062189340591430664 s
DEBUG 01-05 12:51:18.851694.851694 cuda_h.py:19] end gate cost 0.00067901611328125 seconds
DEBUG 01-05 12:51:18.851259.851259 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:18.851891.851891 lmp.py:365] 
DEBUG 01-05 12:51:18.851891.851891 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:18.852363.852363 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:18.852489.852489 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:18.852993.852993 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:18.852828.852828 lmp.py:369] 
DEBUG 01-05 12:51:18.852828.852828 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:18.852902.852902 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:18.852505.852505 lmp.py:376]   Expert 45 |      3 | CPU
DEBUG 01-05 12:51:18.852102.852102 lmp.py:376]   Expert  9 |     22 | CPU
DEBUG 01-05 12:51:18.852745.852745 lmp.py:376]   Expert  3 |     27 | CPU
DEBUG 01-05 12:51:18.852626.852626 lmp.py:376]   Expert 11 |     28 | CPU
DEBUG 01-05 12:51:18.852031.852031 lmp.py:376]   Expert 41 |     46 | CPU
DEBUG 01-05 12:51:18.852674.852674 lmp.py:376]   Expert 60 |     46 | CPU
DEBUG 01-05 12:51:18.852840.852840 lmp.py:376]   Expert 25 |     57 | CPU
DEBUG 01-05 12:51:18.852006.852006 lmp.py:376]   Expert 48 |     57 | CPU
DEBUG 01-05 12:51:18.852126.852126 lmp.py:376]   Expert 51 |     57 | CPU
DEBUG 01-05 12:51:18.852769.852769 lmp.py:376]   Expert 34 |     60 | CPU
DEBUG 01-05 12:51:18.852173.852173 lmp.py:376]   Expert 36 |     60 | CPU
DEBUG 01-05 12:51:18.852578.852578 lmp.py:376]   Expert 53 |     66 | CPU
DEBUG 01-05 12:51:18.852744.852744 lmp.py:376]   Expert 14 |     72 | CPU
DEBUG 01-05 12:51:18.852433.852433 lmp.py:376]   Expert 24 |     72 | CPU
DEBUG 01-05 12:51:18.852361.852361 lmp.py:376]   Expert 58 |     72 | CPU
DEBUG 01-05 12:51:18.852448.852448 lmp.py:376]   Expert  7 |     77 | CPU
DEBUG 01-05 12:51:18.852376.852376 lmp.py:376]   Expert  6 |     81 | CPU
DEBUG 01-05 12:51:18.852065.852065 lmp.py:376]   Expert 31 |     97 | CPU
DEBUG 01-05 12:51:18.852754.852754 lmp.py:376]   Expert 13 |    102 | CPU
DEBUG 01-05 12:51:18.852682.852682 lmp.py:376]   Expert 55 |    103 | CPU
DEBUG 01-05 12:51:18.852610.852610 lmp.py:376]   Expert 47 |    109 | CPU
DEBUG 01-05 12:51:18.852253.852253 lmp.py:376]   Expert  2 |    115 | CPU
DEBUG 01-05 12:51:18.852896.852896 lmp.py:376]   Expert  4 |    115 | CPU
DEBUG 01-05 12:51:18.852539.852539 lmp.py:376]   Expert 40 |    116 | CPU
DEBUG 01-05 12:51:18.852943.852943 lmp.py:376]   Expert 23 |    118 | CPU
DEBUG 01-05 12:51:18.852825.852825 lmp.py:376]   Expert 56 |    120 | CPU
DEBUG 01-05 12:51:18.852514.852514 lmp.py:376]   Expert 28 |    121 | CPU
DEBUG 01-05 12:51:18.852442.852442 lmp.py:376]   Expert 50 |    121 | CPU
DEBUG 01-05 12:51:18.852370.852370 lmp.py:376]   Expert 33 |    123 | CPU
DEBUG 01-05 12:51:18.852297.852297 lmp.py:376]   Expert 16 |    133 | CPU
DEBUG 01-05 12:51:18.852987.852987 lmp.py:376]   Expert 44 |    142 | CPU
DEBUG 01-05 12:51:18.852676.852676 lmp.py:376]   Expert  8 |    146 | CPU
DEBUG 01-05 12:51:18.852365.852365 lmp.py:376]   Expert 10 |    146 | GPU
DEBUG 01-05 12:51:18.852293.852293 lmp.py:376]   Expert 21 |    147 | GPU
DEBUG 01-05 12:51:18.852459.852459 lmp.py:376]   Expert 54 |    149 | GPU
DEBUG 01-05 12:51:18.852340.852340 lmp.py:376]   Expert 37 |    154 | GPU
DEBUG 01-05 12:51:18.852414.852414 lmp.py:376]   Expert 26 |    161 | GPU
DEBUG 01-05 12:51:18.852011.852011 lmp.py:376]   Expert 22 |    163 | GPU
DEBUG 01-05 12:51:18.852607.852607 lmp.py:376]   Expert 57 |    163 | GPU
DEBUG 01-05 12:51:18.852965.852965 lmp.py:376]   Expert 18 |    165 | GPU
DEBUG 01-05 12:51:18.852608.852608 lmp.py:376]   Expert 15 |    178 | GPU
DEBUG 01-05 12:51:18.852490.852490 lmp.py:376]   Expert 27 |    205 | GPU
DEBUG 01-05 12:51:18.852371.852371 lmp.py:376]   Expert 20 |    210 | GPU
DEBUG 01-05 12:51:18.852253.852253 lmp.py:376]   Expert 61 |    210 | GPU
DEBUG 01-05 12:51:18.852134.852134 lmp.py:376]   Expert 46 |    224 | GPU
DEBUG 01-05 12:51:18.852015.852015 lmp.py:376]   Expert 17 |    252 | GPU
DEBUG 01-05 12:51:18.852135.852135 lmp.py:376]   Expert  1 |    255 | GPU
DEBUG 01-05 12:51:18.852732.852732 lmp.py:376]   Expert 63 |    255 | GPU
DEBUG 01-05 12:51:18.852567.852567 lmp.py:376]   Expert 29 |    282 | GPU
DEBUG 01-05 12:51:18.853164.853164 lmp.py:376]   Expert 42 |    282 | GPU
DEBUG 01-05 12:51:18.853999.853999 lmp.py:376]   Expert  0 |    313 | GPU
DEBUG 01-05 12:51:18.853880.853880 lmp.py:376]   Expert 62 |    325 | GPU
DEBUG 01-05 12:51:18.853285.853285 lmp.py:376]   Expert 52 |    327 | GPU
DEBUG 01-05 12:51:18.853404.853404 lmp.py:376]   Expert 32 |    332 | GPU
DEBUG 01-05 12:51:18.853286.853286 lmp.py:376]   Expert 19 |    361 | GPU
DEBUG 01-05 12:51:18.853167.853167 lmp.py:376]   Expert 38 |    366 | GPU
DEBUG 01-05 12:51:18.853049.853049 lmp.py:376]   Expert 35 |    384 | GPU
DEBUG 01-05 12:51:18.853122.853122 lmp.py:376]   Expert 30 |    439 | GPU
DEBUG 01-05 12:51:18.853242.853242 lmp.py:376]   Expert 39 |    439 | GPU
DEBUG 01-05 12:51:18.853838.853838 lmp.py:376]   Expert 49 |    460 | GPU
DEBUG 01-05 12:51:18.853197.853197 lmp.py:376]   Expert 12 |    480 | GPU
DEBUG 01-05 12:51:18.853317.853317 lmp.py:376]   Expert  5 |    490 | GPU
DEBUG 01-05 12:51:18.853960.853960 lmp.py:376]   Expert 43 |    632 | GPU
DEBUG 01-05 12:51:18.853364.853364 lmp.py:376]   Expert 59 |    655 | GPU
DEBUG 01-05 12:51:18.853676.853676 lmp.py:377] 
DEBUG 01-05 12:51:18.853676.853676 lmp.py:377]   CPU total tokens: 2684 (21.8%)
DEBUG 01-05 12:51:18.853511.853511 lmp.py:378]   GPU total tokens: 9604 (78.2%)
DEBUG 01-05 12:51:18.853783.853783 cuda_h.py:19] end experts_map_get cost 0.0015816688537597656 seconds
DEBUG 01-05 12:51:18.853095.853095 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:18.853064.853064 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.853678.853678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.853116.853116 cuda_h.py:19] end allocate_cuda_memory cost 0.00039386749267578125 seconds
DEBUG 01-05 12:51:18.854727.854727 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.854152.854152 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.854253.854253 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.854572.854572 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cec5326e-d872-44fe-a419-00b4470eadc9
DEBUG 01-05 12:51:18.854862.854862 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:18.854546.854546 client.py:127] Model loaded
DEBUG 01-05 12:51:18.854343.854343 cuda_h.py:19] end sllm_worker_task cost 0.010343074798583984 seconds
INFO 01-05 12:51:18.856591.856591 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cec5326e-d872-44fe-a419-00b4470eadc9
DEBUG 01-05 12:51:18.856487.856487 cuda_h.py:19] end load_into_gpu_async cost 0.002877950668334961 seconds
DEBUG 01-05 12:51:18.856144.856144 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.857783.857783 cuda_h.py:19] end restore_tensors2 cost 0.00026702880859375 seconds
DEBUG 01-05 12:51:18.857698.857698 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038836002349853516 seconds
DEBUG 01-05 12:51:18.859892.859892 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006563901901245117 seconds
DEBUG 01-05 12:51:18.859867.859867 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:18.860738.860738 lmp.py:423] 
DEBUG 01-05 12:51:18.860738.860738 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:18.860958.860958 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-05 12:51:18.860774.860774 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:18.864202.864202 mlpmodule.py:704] group tensors cost 0.0039463043212890625 s
DEBUG 01-05 12:51:18.866581.866581 mlpmodule.py:742] pad cost 0.0018739700317382812 s
DEBUG 01-05 12:51:18.866717.866717 mlpmodule.py:748] create cpu tensor cost 4.3392181396484375e-05 s
DEBUG 01-05 12:51:18.866381.866381 mlpmodule.py:753] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-05 12:51:18.875101.875101 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:18.875709.875709 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:18.875143.875143 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 12:51:18.875280.875280 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:18.892436.892436 mlpmodule.py:793] group einsum cost 0.02510857582092285 s
DEBUG 01-05 12:51:18.892979.892979 mlpmodule.py:801] cpy2cputensor cost 0.0005946159362792969 s
DEBUG 01-05 12:51:18.899359.899359 cuda_h.py:19] end wait_cetm_experts cost 0.03879189491271973 seconds
DEBUG 01-05 12:51:18.899521.899521 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:18.899432.899432 cuda_h.py:19] end gpu_sexperts cost 0.0004525184631347656 seconds
DEBUG 01-05 12:51:18.899030.899030 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:18.899933.899933 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:18.899020.899020 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:18.899968.899968 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cec5326e-d872-44fe-a419-00b4470eadc9
INFO 01-05 12:51:18.909059.909059 client.py:127] Model loaded
DEBUG 01-05 12:51:18.909810.909810 cuda_h.py:19] end wait_experts cost 0.00971364974975586 seconds
DEBUG 01-05 12:51:18.909579.909579 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:18.909521.909521 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:18.910308.910308 mlpmodule.py:531] gpu group tensors cost 0.0005106925964355469 s
DEBUG 01-05 12:51:18.911829.911829 mlpmodule.py:564] gpu pad cost 0.0014562606811523438 s
DEBUG 01-05 12:51:18.912940.912940 mlpmodule.py:582] gpu group einsum cost 0.00046443939208984375 s
DEBUG 01-05 12:51:18.914802.914802 mlpmodule.py:611] gpu experts func einsum cost 0.005368709564208984 s
DEBUG 01-05 12:51:18.915633.915633 cuda_h.py:19] end gpu_experts cost 0.005526542663574219 seconds
DEBUG 01-05 12:51:18.915834.915834 cuda_h.py:19] end layer_moe_generate_4 cost 0.0642392635345459 seconds
DEBUG 01-05 12:51:18.915985.915985 lmp.py:217] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 12:51:18.915648.915648 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 12:51:18.915106.915106 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 12:51:18.915961.915961 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 12:51:18.915897.915897 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.9325485229492188e-05 seconds
DEBUG 01-05 12:51:18.915838.915838 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.246566772460938e-05 seconds
DEBUG 01-05 12:51:18.915388.915388 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:18.915735.915735 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:18.915830.915830 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.915422.915422 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.945442.945442 cuda_h.py:19] end allocate_cuda_memory cost 0.03024005889892578 seconds
DEBUG 01-05 12:51:18.946348.946348 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.946846.946846 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.946590.946590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.946544.946544 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ebf11a7e-985c-4fb1-9a52-87d0dc7f6f5b
DEBUG 01-05 12:51:18.946449.946449 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:18.946120.946120 cuda_h.py:10] start self_attn
INFO 01-05 12:51:18.947383.947383 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ebf11a7e-985c-4fb1-9a52-87d0dc7f6f5b
DEBUG 01-05 12:51:18.947193.947193 cuda_h.py:19] end load_into_gpu_async cost 0.0016601085662841797 seconds
DEBUG 01-05 12:51:18.947572.947572 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.947198.947198 cuda_h.py:19] end restore_tensors2 cost 7.486343383789062e-05 seconds
DEBUG 01-05 12:51:18.948020.948020 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.03233599662780762 seconds
INFO 01-05 12:51:18.948566.948566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ebf11a7e-985c-4fb1-9a52-87d0dc7f6f5b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:18.951929.951929 cuda_h.py:19] end self_attn cost 0.004475116729736328 seconds
DEBUG 01-05 12:51:18.951646.951646 cuda_h.py:19] end iln_self_attn_paln cost 0.03614330291748047 seconds
DEBUG 01-05 12:51:18.951676.951676 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 12:51:18.951294.951294 cuda_h.py:10] start gate
DEBUG 01-05 12:51:18.952188.952188 cuda_h.py:19] end gate cost 0.0009129047393798828 seconds
DEBUG 01-05 12:51:18.952958.952958 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:18.953121.953121 lmp.py:365] 
DEBUG 01-05 12:51:18.953121.953121 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:18.953434.953434 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:18.953065.953065 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:18.953212.953212 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:18.953305.953305 lmp.py:369] 
DEBUG 01-05 12:51:18.953305.953305 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:18.953161.953161 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:18.953222.953222 lmp.py:376]   Expert 14 |     19 | CPU
DEBUG 01-05 12:51:18.953031.953031 lmp.py:376]   Expert 18 |     30 | CPU
DEBUG 01-05 12:51:18.953840.953840 lmp.py:376]   Expert 15 |     36 | CPU
DEBUG 01-05 12:51:18.953457.953457 lmp.py:376]   Expert  2 |     45 | CPU
DEBUG 01-05 12:51:18.953551.953551 lmp.py:376]   Expert 23 |     46 | CPU
DEBUG 01-05 12:51:18.953214.953214 lmp.py:376]   Expert 60 |     47 | CPU
DEBUG 01-05 12:51:18.953600.953600 lmp.py:376]   Expert 39 |     49 | CPU
DEBUG 01-05 12:51:18.953740.953740 lmp.py:376]   Expert 17 |     50 | CPU
DEBUG 01-05 12:51:18.953119.953119 lmp.py:376]   Expert 30 |     50 | CPU
DEBUG 01-05 12:51:18.953305.953305 lmp.py:376]   Expert 34 |     54 | CPU
DEBUG 01-05 12:51:18.953445.953445 lmp.py:376]   Expert 45 |     57 | CPU
DEBUG 01-05 12:51:18.954347.954347 lmp.py:376]   Expert 52 |     79 | CPU
DEBUG 01-05 12:51:18.954487.954487 lmp.py:376]   Expert 27 |     83 | CPU
DEBUG 01-05 12:51:18.954389.954389 lmp.py:376]   Expert  9 |     85 | CPU
DEBUG 01-05 12:51:18.954291.954291 lmp.py:376]   Expert 28 |     92 | CPU
DEBUG 01-05 12:51:18.954477.954477 lmp.py:376]   Expert 47 |     93 | CPU
DEBUG 01-05 12:51:18.954379.954379 lmp.py:376]   Expert 55 |     94 | CPU
DEBUG 01-05 12:51:18.954804.954804 lmp.py:376]   Expert 22 |     99 | CPU
DEBUG 01-05 12:51:18.954706.954706 lmp.py:376]   Expert  3 |    103 | CPU
DEBUG 01-05 12:51:18.954131.954131 lmp.py:376]   Expert 62 |    109 | CPU
DEBUG 01-05 12:51:18.954794.954794 lmp.py:376]   Expert  8 |    116 | CPU
DEBUG 01-05 12:51:18.954981.954981 lmp.py:376]   Expert  1 |    117 | CPU
DEBUG 01-05 12:51:18.954882.954882 lmp.py:376]   Expert 40 |    117 | CPU
DEBUG 01-05 12:51:18.954307.954307 lmp.py:376]   Expert  4 |    120 | CPU
DEBUG 01-05 12:51:18.954732.954732 lmp.py:376]   Expert 63 |    122 | CPU
DEBUG 01-05 12:51:18.954919.954919 lmp.py:376]   Expert 19 |    128 | CPU
DEBUG 01-05 12:51:18.954344.954344 lmp.py:376]   Expert 26 |    129 | CPU
DEBUG 01-05 12:51:18.954465.954465 lmp.py:376]   Expert 43 |    129 | CPU
DEBUG 01-05 12:51:18.954751.954751 lmp.py:376]   Expert 48 |    134 | CPU
DEBUG 01-05 12:51:18.954798.954798 lmp.py:376]   Expert 41 |    140 | CPU
DEBUG 01-05 12:51:18.954938.954938 lmp.py:376]   Expert 24 |    143 | CPU
DEBUG 01-05 12:51:18.954363.954363 lmp.py:376]   Expert 51 |    143 | CPU
DEBUG 01-05 12:51:18.954788.954788 lmp.py:376]   Expert 58 |    146 | GPU
DEBUG 01-05 12:51:18.954690.954690 lmp.py:376]   Expert 54 |    150 | GPU
DEBUG 01-05 12:51:18.954115.954115 lmp.py:376]   Expert 25 |    156 | GPU
DEBUG 01-05 12:51:18.954540.954540 lmp.py:376]   Expert 10 |    157 | GPU
DEBUG 01-05 12:51:18.954680.954680 lmp.py:376]   Expert 11 |    157 | GPU
DEBUG 01-05 12:51:18.954866.954866 lmp.py:376]   Expert 38 |    157 | GPU
DEBUG 01-05 12:51:18.954530.954530 lmp.py:376]   Expert 61 |    160 | GPU
DEBUG 01-05 12:51:18.954193.954193 lmp.py:376]   Expert 44 |    162 | GPU
DEBUG 01-05 12:51:18.954095.954095 lmp.py:376]   Expert 29 |    163 | GPU
DEBUG 01-05 12:51:18.955758.955758 lmp.py:376]   Expert 56 |    165 | GPU
DEBUG 01-05 12:51:18.955660.955660 lmp.py:376]   Expert  0 |    176 | GPU
DEBUG 01-05 12:51:18.955323.955323 lmp.py:376]   Expert 46 |    189 | GPU
DEBUG 01-05 12:51:18.955225.955225 lmp.py:376]   Expert 50 |    197 | GPU
DEBUG 01-05 12:51:18.955796.955796 lmp.py:376]   Expert  5 |    201 | GPU
DEBUG 01-05 12:51:18.955698.955698 lmp.py:376]   Expert 36 |    222 | GPU
DEBUG 01-05 12:51:18.955361.955361 lmp.py:376]   Expert 16 |    228 | GPU
DEBUG 01-05 12:51:18.955024.955024 lmp.py:376]   Expert 32 |    231 | GPU
DEBUG 01-05 12:51:18.955449.955449 lmp.py:376]   Expert 12 |    234 | GPU
DEBUG 01-05 12:51:18.955874.955874 lmp.py:376]   Expert  7 |    247 | GPU
DEBUG 01-05 12:51:18.955776.955776 lmp.py:376]   Expert 35 |    251 | GPU
DEBUG 01-05 12:51:18.955678.955678 lmp.py:376]   Expert 57 |    252 | GPU
DEBUG 01-05 12:51:18.955341.955341 lmp.py:376]   Expert 42 |    279 | GPU
DEBUG 01-05 12:51:18.955004.955004 lmp.py:376]   Expert 21 |    290 | GPU
DEBUG 01-05 12:51:18.955145.955145 lmp.py:376]   Expert 59 |    342 | GPU
DEBUG 01-05 12:51:18.955808.955808 lmp.py:376]   Expert 20 |    381 | GPU
DEBUG 01-05 12:51:18.955233.955233 lmp.py:376]   Expert 13 |    394 | GPU
DEBUG 01-05 12:51:18.955896.955896 lmp.py:376]   Expert 33 |    451 | GPU
DEBUG 01-05 12:51:18.955321.955321 lmp.py:376]   Expert  6 |    453 | GPU
DEBUG 01-05 12:51:18.955845.955845 lmp.py:376]   Expert 31 |    456 | GPU
DEBUG 01-05 12:51:18.955986.955986 lmp.py:376]   Expert 49 |    518 | GPU
DEBUG 01-05 12:51:18.955934.955934 lmp.py:376]   Expert 37 |    616 | GPU
DEBUG 01-05 12:51:18.955120.955120 lmp.py:376]   Expert 53 |   1249 | GPU
DEBUG 01-05 12:51:18.955691.955691 lmp.py:377] 
DEBUG 01-05 12:51:18.955691.955691 lmp.py:377]   CPU total tokens: 2858 (23.3%)
DEBUG 01-05 12:51:18.955023.955023 lmp.py:378]   GPU total tokens: 9430 (76.7%)
DEBUG 01-05 12:51:18.955316.955316 cuda_h.py:19] end experts_map_get cost 0.0029172897338867188 seconds
DEBUG 01-05 12:51:18.955410.955410 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:18.955757.955757 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:18.956883.956883 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:18.956298.956298 cuda_h.py:19] end allocate_cuda_memory cost 0.00028514862060546875 seconds
DEBUG 01-05 12:51:18.956997.956997 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:18.956018.956018 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:18.956551.956551 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:18.956943.956943 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 50eafceb-340a-4c82-a397-dcb9e988f30d
DEBUG 01-05 12:51:18.957589.957589 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:18.957052.957052 mlpmodule.py:662]  experts func einsum cost 0.0969858169555664 s
INFO 01-05 12:51:18.957365.957365 client.py:127] Model loaded
DEBUG 01-05 12:51:18.957311.957311 cuda_h.py:19] end sllm_worker_task cost 0.042028188705444336 seconds
INFO 01-05 12:51:18.958259.958259 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 50eafceb-340a-4c82-a397-dcb9e988f30d
DEBUG 01-05 12:51:18.959079.959079 cuda_h.py:19] end load_into_gpu_async cost 0.002382993698120117 seconds
DEBUG 01-05 12:51:18.959902.959902 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:18.959730.959730 cuda_h.py:19] end restore_tensors2 cost 0.0005040168762207031 seconds
DEBUG 01-05 12:51:18.959017.959017 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003764629364013672 seconds
DEBUG 01-05 12:51:18.962713.962713 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006643533706665039 seconds
DEBUG 01-05 12:51:18.962543.962543 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:18.962121.962121 lmp.py:423] 
DEBUG 01-05 12:51:18.962121.962121 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:18.962958.962958 cuda_h.py:19] end cpu_experts_submit cost 0.000102996826171875 seconds
DEBUG 01-05 12:51:18.962130.962130 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:18.970869.970869 mlpmodule.py:704] group tensors cost 0.008024215698242188 s
DEBUG 01-05 12:51:18.973211.973211 mlpmodule.py:742] pad cost 0.002116680145263672 s
DEBUG 01-05 12:51:18.973050.973050 mlpmodule.py:748] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-05 12:51:18.973503.973503 mlpmodule.py:753] move to cpu cost 3.695487976074219e-05 s
DEBUG 01-05 12:51:18.983863.983863 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:18.983325.983325 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:18.983984.983984 mlpmodule.py:773] group_w3 first element: -0.0277099609375
WARNING 01-05 12:51:18.983624.983624 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.002708.002708 mlpmodule.py:793] group einsum cost 0.02819204330444336 s
DEBUG 01-05 12:51:19.002951.002951 mlpmodule.py:801] cpy2cputensor cost 0.0005495548248291016 s
DEBUG 01-05 12:51:19.007733.007733 cuda_h.py:19] end wait_cetm_experts cost 0.04485344886779785 seconds
DEBUG 01-05 12:51:19.007948.007948 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.008137.008137 cuda_h.py:19] end gpu_sexperts cost 0.00044608116149902344 seconds
DEBUG 01-05 12:51:19.008165.008165 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.008884.008884 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.220008850097656e-05 seconds
DEBUG 01-05 12:51:19.008593.008593 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.008303.008303 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 50eafceb-340a-4c82-a397-dcb9e988f30d
INFO 01-05 12:51:19.011832.011832 client.py:127] Model loaded
DEBUG 01-05 12:51:19.011020.011020 cuda_h.py:19] end wait_experts cost 0.002810239791870117 seconds
DEBUG 01-05 12:51:19.011491.011491 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.011678.011678 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.012628.012628 mlpmodule.py:531] gpu group tensors cost 0.0006227493286132812 s
DEBUG 01-05 12:51:19.013535.013535 mlpmodule.py:564] gpu pad cost 0.0017027854919433594 s
DEBUG 01-05 12:51:19.014302.014302 mlpmodule.py:582] gpu group einsum cost 0.0004930496215820312 s
DEBUG 01-05 12:51:19.017960.017960 mlpmodule.py:611] gpu experts func einsum cost 0.006379604339599609 s
DEBUG 01-05 12:51:19.017135.017135 cuda_h.py:19] end gpu_experts cost 0.00655364990234375 seconds
DEBUG 01-05 12:51:19.017820.017820 cuda_h.py:19] end layer_moe_generate_5 cost 0.06617093086242676 seconds
DEBUG 01-05 12:51:19.018401.018401 lmp.py:217] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 12:51:19.018356.018356 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 12:51:19.018006.018006 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 12:51:19.018431.018431 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 12:51:19.018512.018512 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:19.018944.018944 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.651878356933594e-05 seconds
DEBUG 01-05 12:51:19.018687.018687 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.018895.018895 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.018228.018228 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.018581.018581 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.020588.020588 cuda_h.py:19] end allocate_cuda_memory cost 0.0021414756774902344 seconds
DEBUG 01-05 12:51:19.020604.020604 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.020704.020704 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.020812.020812 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.020276.020276 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8921787c-95d4-47c0-a610-33d90724ace4
DEBUG 01-05 12:51:19.021815.021815 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.021291.021291 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.022093.022093 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8921787c-95d4-47c0-a610-33d90724ace4
DEBUG 01-05 12:51:19.022221.022221 cuda_h.py:19] end load_into_gpu_async cost 0.0015745162963867188 seconds
DEBUG 01-05 12:51:19.022208.022208 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.022993.022993 cuda_h.py:19] end restore_tensors2 cost 6.031990051269531e-05 seconds
DEBUG 01-05 12:51:19.022556.022556 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0040395259857177734 seconds
INFO 01-05 12:51:19.023269.023269 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8921787c-95d4-47c0-a610-33d90724ace4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.025744.025744 cuda_h.py:19] end self_attn cost 0.003777027130126953 seconds
DEBUG 01-05 12:51:19.025654.025654 cuda_h.py:19] end iln_self_attn_paln cost 0.007108926773071289 seconds
DEBUG 01-05 12:51:19.025067.025067 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 12:51:19.025551.025551 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.026650.026650 cuda_h.py:19] end gate cost 0.0007281303405761719 seconds
DEBUG 01-05 12:51:19.026572.026572 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.026297.026297 lmp.py:365] 
DEBUG 01-05 12:51:19.026297.026297 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.026484.026484 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.026610.026610 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.026114.026114 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.026996.026996 lmp.py:369] 
DEBUG 01-05 12:51:19.026996.026996 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.026592.026592 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.026911.026911 lmp.py:376]   Expert  1 |     11 | CPU
DEBUG 01-05 12:51:19.026269.026269 lmp.py:376]   Expert  3 |     13 | CPU
DEBUG 01-05 12:51:19.026674.026674 lmp.py:376]   Expert 15 |     26 | CPU
DEBUG 01-05 12:51:19.026840.026840 lmp.py:376]   Expert 14 |     28 | CPU
DEBUG 01-05 12:51:19.026245.026245 lmp.py:376]   Expert 53 |     32 | CPU
DEBUG 01-05 12:51:19.026411.026411 lmp.py:376]   Expert 47 |     38 | CPU
DEBUG 01-05 12:51:19.026338.026338 lmp.py:376]   Expert 52 |     45 | CPU
DEBUG 01-05 12:51:19.026505.026505 lmp.py:376]   Expert 16 |     60 | CPU
DEBUG 01-05 12:51:19.026624.026624 lmp.py:376]   Expert 26 |     65 | CPU
DEBUG 01-05 12:51:19.026029.026029 lmp.py:376]   Expert 40 |     67 | CPU
DEBUG 01-05 12:51:19.027672.027672 lmp.py:376]   Expert 44 |     68 | CPU
DEBUG 01-05 12:51:19.027077.027077 lmp.py:376]   Expert 11 |     71 | CPU
DEBUG 01-05 12:51:19.027243.027243 lmp.py:376]   Expert 10 |     74 | CPU
DEBUG 01-05 12:51:19.027409.027409 lmp.py:376]   Expert 50 |     75 | CPU
DEBUG 01-05 12:51:19.027337.027337 lmp.py:376]   Expert 49 |     85 | CPU
DEBUG 01-05 12:51:19.027503.027503 lmp.py:376]   Expert 41 |     99 | CPU
DEBUG 01-05 12:51:19.027430.027430 lmp.py:376]   Expert  7 |    102 | CPU
DEBUG 01-05 12:51:19.027358.027358 lmp.py:376]   Expert 59 |    102 | CPU
DEBUG 01-05 12:51:19.027047.027047 lmp.py:376]   Expert 37 |    103 | CPU
DEBUG 01-05 12:51:19.027214.027214 lmp.py:376]   Expert 25 |    109 | CPU
DEBUG 01-05 12:51:19.027141.027141 lmp.py:376]   Expert 30 |    109 | CPU
DEBUG 01-05 12:51:19.027831.027831 lmp.py:376]   Expert 35 |    109 | CPU
DEBUG 01-05 12:51:19.027474.027474 lmp.py:376]   Expert  5 |    116 | CPU
DEBUG 01-05 12:51:19.027878.027878 lmp.py:376]   Expert 31 |    119 | CPU
DEBUG 01-05 12:51:19.027521.027521 lmp.py:376]   Expert 32 |    120 | CPU
DEBUG 01-05 12:51:19.027164.027164 lmp.py:376]   Expert 42 |    120 | CPU
DEBUG 01-05 12:51:19.027092.027092 lmp.py:376]   Expert 22 |    122 | CPU
DEBUG 01-05 12:51:19.027258.027258 lmp.py:376]   Expert 63 |    130 | CPU
DEBUG 01-05 12:51:19.027186.027186 lmp.py:376]   Expert 34 |    132 | CPU
DEBUG 01-05 12:51:19.027352.027352 lmp.py:376]   Expert 21 |    133 | CPU
DEBUG 01-05 12:51:19.027279.027279 lmp.py:376]   Expert 62 |    135 | CPU
DEBUG 01-05 12:51:19.027446.027446 lmp.py:376]   Expert 13 |    136 | CPU
DEBUG 01-05 12:51:19.027612.027612 lmp.py:376]   Expert 58 |    139 | GPU
DEBUG 01-05 12:51:19.027539.027539 lmp.py:376]   Expert 51 |    140 | GPU
DEBUG 01-05 12:51:19.027944.027944 lmp.py:376]   Expert 54 |    141 | GPU
DEBUG 01-05 12:51:19.027587.027587 lmp.py:376]   Expert 61 |    143 | GPU
DEBUG 01-05 12:51:19.027992.027992 lmp.py:376]   Expert  4 |    150 | GPU
DEBUG 01-05 12:51:19.027158.027158 lmp.py:376]   Expert  8 |    158 | GPU
DEBUG 01-05 12:51:19.027562.027562 lmp.py:376]   Expert 28 |    166 | GPU
DEBUG 01-05 12:51:19.027728.027728 lmp.py:376]   Expert 38 |    166 | GPU
DEBUG 01-05 12:51:19.027418.027418 lmp.py:376]   Expert  6 |    167 | GPU
DEBUG 01-05 12:51:19.027345.027345 lmp.py:376]   Expert  9 |    179 | GPU
DEBUG 01-05 12:51:19.027035.027035 lmp.py:376]   Expert 12 |    184 | GPU
DEBUG 01-05 12:51:19.027439.027439 lmp.py:376]   Expert  0 |    187 | GPU
DEBUG 01-05 12:51:19.027129.027129 lmp.py:376]   Expert 57 |    193 | GPU
DEBUG 01-05 12:51:19.027818.027818 lmp.py:376]   Expert 29 |    202 | GPU
DEBUG 01-05 12:51:19.027461.027461 lmp.py:376]   Expert 46 |    216 | GPU
DEBUG 01-05 12:51:19.027865.027865 lmp.py:376]   Expert  2 |    236 | GPU
DEBUG 01-05 12:51:19.027032.027032 lmp.py:376]   Expert 17 |    250 | GPU
DEBUG 01-05 12:51:19.027913.027913 lmp.py:376]   Expert 24 |    263 | GPU
DEBUG 01-05 12:51:19.027079.027079 lmp.py:376]   Expert 45 |    265 | GPU
DEBUG 01-05 12:51:19.027007.027007 lmp.py:376]   Expert 19 |    270 | GPU
DEBUG 01-05 12:51:19.027458.027458 lmp.py:376]   Expert 23 |    277 | GPU
DEBUG 01-05 12:51:19.027385.027385 lmp.py:376]   Expert 43 |    288 | GPU
DEBUG 01-05 12:51:19.027075.027075 lmp.py:376]   Expert 33 |    293 | GPU
DEBUG 01-05 12:51:19.027241.027241 lmp.py:376]   Expert 20 |    306 | GPU
DEBUG 01-05 12:51:19.027692.027692 lmp.py:376]   Expert 55 |    342 | GPU
DEBUG 01-05 12:51:19.027619.027619 lmp.py:376]   Expert 48 |    350 | GPU
DEBUG 01-05 12:51:19.027070.027070 lmp.py:376]   Expert 18 |    432 | GPU
DEBUG 01-05 12:51:19.027952.027952 lmp.py:376]   Expert 27 |    466 | GPU
DEBUG 01-05 12:51:19.027356.027356 lmp.py:376]   Expert 39 |    501 | GPU
DEBUG 01-05 12:51:19.027761.027761 lmp.py:376]   Expert 60 |    741 | GPU
DEBUG 01-05 12:51:19.027165.027165 lmp.py:376]   Expert 56 |    858 | GPU
DEBUG 01-05 12:51:19.027331.027331 lmp.py:376]   Expert 36 |    865 | GPU
DEBUG 01-05 12:51:19.027974.027974 lmp.py:377] 
DEBUG 01-05 12:51:19.027974.027974 lmp.py:377]   CPU total tokens: 2754 (22.4%)
DEBUG 01-05 12:51:19.027856.027856 lmp.py:378]   GPU total tokens: 9534 (77.6%)
DEBUG 01-05 12:51:19.027790.027790 cuda_h.py:19] end experts_map_get cost 0.0015368461608886719 seconds
DEBUG 01-05 12:51:19.027910.027910 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.028594.028594 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.028439.028439 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.029200.029200 cuda_h.py:19] end allocate_cuda_memory cost 0.00090789794921875 seconds
DEBUG 01-05 12:51:19.029427.029427 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.029805.029805 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.029383.029383 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.029178.029178 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, afd73ef2-37bd-4182-a914-510cdeafbcb9
DEBUG 01-05 12:51:19.029608.029608 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.029672.029672 mlpmodule.py:662]  experts func einsum cost 0.0666506290435791 s
INFO 01-05 12:51:19.029385.029385 client.py:127] Model loaded
DEBUG 01-05 12:51:19.029182.029182 cuda_h.py:19] end sllm_worker_task cost 0.01127481460571289 seconds
INFO 01-05 12:51:19.031148.031148 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, afd73ef2-37bd-4182-a914-510cdeafbcb9
DEBUG 01-05 12:51:19.031422.031422 cuda_h.py:19] end load_into_gpu_async cost 0.001999378204345703 seconds
DEBUG 01-05 12:51:19.031317.031317 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.031340.031340 cuda_h.py:19] end restore_tensors2 cost 0.0002720355987548828 seconds
DEBUG 01-05 12:51:19.031448.031448 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035202503204345703 seconds
DEBUG 01-05 12:51:19.034080.034080 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062410831451416016 seconds
DEBUG 01-05 12:51:19.034148.034148 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.034178.034178 lmp.py:423] 
DEBUG 01-05 12:51:19.034178.034178 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.034590.034590 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 12:51:19.034909.034909 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.042949.042949 mlpmodule.py:704] group tensors cost 0.008186817169189453 s
DEBUG 01-05 12:51:19.044599.044599 mlpmodule.py:742] pad cost 0.0014128684997558594 s
DEBUG 01-05 12:51:19.044251.044251 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-05 12:51:19.044908.044908 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-05 12:51:19.053187.053187 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.053074.053074 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.053587.053587 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 12:51:19.053564.053564 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.070760.070760 mlpmodule.py:793] group einsum cost 0.02555561065673828 s
DEBUG 01-05 12:51:19.071497.071497 mlpmodule.py:801] cpy2cputensor cost 0.0005686283111572266 s
DEBUG 01-05 12:51:19.076916.076916 cuda_h.py:19] end wait_cetm_experts cost 0.041707754135131836 seconds
DEBUG 01-05 12:51:19.076992.076992 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.076208.076208 cuda_h.py:19] end gpu_sexperts cost 0.0004668235778808594 seconds
DEBUG 01-05 12:51:19.076734.076734 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.076597.076597 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4809112548828125e-05 seconds
DEBUG 01-05 12:51:19.077651.077651 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.077123.077123 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, afd73ef2-37bd-4182-a914-510cdeafbcb9
INFO 01-05 12:51:19.083998.083998 client.py:127] Model loaded
DEBUG 01-05 12:51:19.084442.084442 cuda_h.py:19] end wait_experts cost 0.006946086883544922 seconds
DEBUG 01-05 12:51:19.084710.084710 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.084899.084899 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.086020.086020 mlpmodule.py:531] gpu group tensors cost 0.0015988349914550781 s
DEBUG 01-05 12:51:19.090539.090539 mlpmodule.py:564] gpu pad cost 0.004406452178955078 s
DEBUG 01-05 12:51:19.092663.092663 mlpmodule.py:582] gpu group einsum cost 0.001140594482421875 s
DEBUG 01-05 12:51:19.094291.094291 mlpmodule.py:662]  experts func einsum cost 0.06012916564941406 s
DEBUG 01-05 12:51:19.098339.098339 mlpmodule.py:611] gpu experts func einsum cost 0.014122247695922852 s
DEBUG 01-05 12:51:19.099695.099695 cuda_h.py:19] end gpu_experts cost 0.014858007431030273 seconds
DEBUG 01-05 12:51:19.099271.099271 cuda_h.py:19] end layer_moe_generate_6 cost 0.0738983154296875 seconds
DEBUG 01-05 12:51:19.099777.099777 lmp.py:217] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 12:51:19.099024.099024 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 12:51:19.099819.099819 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 12:51:19.099258.099258 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 12:51:19.099962.099962 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.123283386230469e-05 seconds
DEBUG 01-05 12:51:19.099287.099287 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.580352783203125e-05 seconds
DEBUG 01-05 12:51:19.099030.099030 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.100550.100550 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.100241.100241 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.100554.100554 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.100587.100587 cuda_h.py:19] end allocate_cuda_memory cost 0.0003390312194824219 seconds
DEBUG 01-05 12:51:19.100013.100013 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.100273.100273 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.100957.100957 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.100567.100567 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 561e7cf8-50d3-4960-b7a8-7b2e9e49766d
DEBUG 01-05 12:51:19.100881.100881 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.101090.101090 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.102721.102721 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 561e7cf8-50d3-4960-b7a8-7b2e9e49766d
DEBUG 01-05 12:51:19.102147.102147 cuda_h.py:19] end load_into_gpu_async cost 0.0017652511596679688 seconds
DEBUG 01-05 12:51:19.102525.102525 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.102841.102841 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-05 12:51:19.102856.102856 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024843215942382812 seconds
INFO 01-05 12:51:19.103601.103601 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 561e7cf8-50d3-4960-b7a8-7b2e9e49766d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.106185.106185 cuda_h.py:19] end self_attn cost 0.005162477493286133 seconds
DEBUG 01-05 12:51:19.106054.106054 cuda_h.py:19] end iln_self_attn_paln cost 0.006829500198364258 seconds
DEBUG 01-05 12:51:19.106964.106964 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 12:51:19.106985.106985 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.107930.107930 cuda_h.py:19] end gate cost 0.0008592605590820312 seconds
DEBUG 01-05 12:51:19.107157.107157 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.108529.108529 lmp.py:365] 
DEBUG 01-05 12:51:19.108529.108529 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.108021.108021 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.108638.108638 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.108486.108486 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.108235.108235 lmp.py:369] 
DEBUG 01-05 12:51:19.108235.108235 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.108508.108508 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.108217.108217 lmp.py:376]   Expert  1 |     21 | CPU
DEBUG 01-05 12:51:19.108967.108967 lmp.py:376]   Expert  3 |     26 | CPU
DEBUG 01-05 12:51:19.108762.108762 lmp.py:376]   Expert 15 |     39 | CPU
DEBUG 01-05 12:51:19.108319.108319 lmp.py:376]   Expert 20 |     40 | CPU
DEBUG 01-05 12:51:19.108115.108115 lmp.py:376]   Expert 25 |     43 | CPU
DEBUG 01-05 12:51:19.108864.108864 lmp.py:376]   Expert 31 |     43 | CPU
DEBUG 01-05 12:51:19.108521.108521 lmp.py:376]   Expert 48 |     44 | CPU
DEBUG 01-05 12:51:19.108747.108747 lmp.py:376]   Expert 49 |     49 | CPU
DEBUG 01-05 12:51:19.108734.108734 lmp.py:376]   Expert  6 |     55 | CPU
DEBUG 01-05 12:51:19.108007.108007 lmp.py:376]   Expert 33 |     55 | CPU
DEBUG 01-05 12:51:19.109994.109994 lmp.py:376]   Expert 32 |     57 | CPU
DEBUG 01-05 12:51:19.109267.109267 lmp.py:376]   Expert 41 |     58 | CPU
DEBUG 01-05 12:51:19.109301.109301 lmp.py:376]   Expert  8 |     59 | CPU
DEBUG 01-05 12:51:19.109003.109003 lmp.py:376]   Expert 40 |     62 | CPU
DEBUG 01-05 12:51:19.109468.109468 lmp.py:376]   Expert 16 |     67 | CPU
DEBUG 01-05 12:51:19.109171.109171 lmp.py:376]   Expert 29 |     68 | CPU
DEBUG 01-05 12:51:19.109827.109827 lmp.py:376]   Expert  0 |     69 | CPU
DEBUG 01-05 12:51:19.109861.109861 lmp.py:376]   Expert 59 |     73 | CPU
DEBUG 01-05 12:51:19.109134.109134 lmp.py:376]   Expert 34 |     82 | CPU
DEBUG 01-05 12:51:19.109644.109644 lmp.py:376]   Expert  5 |     84 | CPU
DEBUG 01-05 12:51:19.109917.109917 lmp.py:376]   Expert  7 |     85 | CPU
DEBUG 01-05 12:51:19.109951.109951 lmp.py:376]   Expert 39 |     95 | CPU
DEBUG 01-05 12:51:19.109985.109985 lmp.py:376]   Expert 57 |     97 | CPU
DEBUG 01-05 12:51:19.109972.109972 lmp.py:376]   Expert 18 |    100 | CPU
DEBUG 01-05 12:51:19.109437.109437 lmp.py:376]   Expert 63 |    105 | CPU
DEBUG 01-05 12:51:19.109570.109570 lmp.py:376]   Expert 35 |    106 | CPU
DEBUG 01-05 12:51:19.109127.109127 lmp.py:376]   Expert 58 |    106 | CPU
DEBUG 01-05 12:51:19.109400.109400 lmp.py:376]   Expert 60 |    108 | CPU
DEBUG 01-05 12:51:19.109149.109149 lmp.py:376]   Expert 30 |    111 | CPU
DEBUG 01-05 12:51:19.109944.109944 lmp.py:376]   Expert 50 |    113 | CPU
DEBUG 01-05 12:51:19.109978.109978 lmp.py:376]   Expert 42 |    125 | CPU
DEBUG 01-05 12:51:19.109204.109204 lmp.py:376]   Expert 45 |    131 | CPU
INFO 01-05 12:51:19.109776.109776 client.py:127] Model loaded
DEBUG 01-05 12:51:19.109732.109732 lmp.py:376]   Expert 55 |    133 | GPU
DEBUG 01-05 12:51:19.109105.109105 cuda_h.py:19] end sllm_worker_task cost 0.009590387344360352 seconds
DEBUG 01-05 12:51:19.109583.109583 lmp.py:376]   Expert  4 |    147 | GPU
DEBUG 01-05 12:51:19.109375.109375 lmp.py:376]   Expert 37 |    155 | GPU
DEBUG 01-05 12:51:19.109793.109793 lmp.py:376]   Expert 52 |    162 | GPU
DEBUG 01-05 12:51:19.109588.109588 lmp.py:376]   Expert 19 |    171 | GPU
DEBUG 01-05 12:51:19.109669.109669 lmp.py:376]   Expert 53 |    171 | GPU
DEBUG 01-05 12:51:19.109895.109895 lmp.py:376]   Expert 51 |    179 | GPU
DEBUG 01-05 12:51:19.110405.110405 lmp.py:376]   Expert 13 |    183 | GPU
DEBUG 01-05 12:51:19.110678.110678 lmp.py:376]   Expert 54 |    185 | GPU
DEBUG 01-05 12:51:19.110996.110996 lmp.py:376]   Expert 22 |    202 | GPU
DEBUG 01-05 12:51:19.110600.110600 lmp.py:376]   Expert 36 |    211 | GPU
DEBUG 01-05 12:51:19.110442.110442 lmp.py:376]   Expert 17 |    212 | GPU
DEBUG 01-05 12:51:19.110522.110522 lmp.py:376]   Expert 24 |    212 | GPU
DEBUG 01-05 12:51:19.110125.110125 lmp.py:376]   Expert 26 |    214 | GPU
DEBUG 01-05 12:51:19.110921.110921 lmp.py:376]   Expert 10 |    219 | GPU
DEBUG 01-05 12:51:19.110385.110385 lmp.py:376]   Expert 56 |    235 | GPU
DEBUG 01-05 12:51:19.110896.110896 lmp.py:376]   Expert 43 |    251 | GPU
DEBUG 01-05 12:51:19.110977.110977 lmp.py:376]   Expert 62 |    260 | GPU
DEBUG 01-05 12:51:19.110580.110580 lmp.py:376]   Expert  2 |    262 | GPU
DEBUG 01-05 12:51:19.110183.110183 lmp.py:376]   Expert 27 |    272 | GPU
DEBUG 01-05 12:51:19.110787.110787 lmp.py:376]   Expert 21 |    285 | GPU
DEBUG 01-05 12:51:19.110390.110390 lmp.py:376]   Expert 47 |    291 | GPU
DEBUG 01-05 12:51:19.110424.110424 lmp.py:376]   Expert 61 |    305 | GPU
DEBUG 01-05 12:51:19.110366.110366 lmp.py:376]   Expert 11 |    321 | GPU
DEBUG 01-05 12:51:19.110399.110399 lmp.py:376]   Expert 28 |    322 | GPU
DEBUG 01-05 12:51:19.110480.110480 lmp.py:376]   Expert 14 |    323 | GPU
DEBUG 01-05 12:51:19.110606.110606 lmp.py:376]   Expert 38 |    379 | GPU
DEBUG 01-05 12:51:19.110210.110210 lmp.py:376]   Expert 46 |    415 | GPU
DEBUG 01-05 12:51:19.110813.110813 lmp.py:376]   Expert 44 |    416 | GPU
DEBUG 01-05 12:51:19.110940.110940 lmp.py:376]   Expert 12 |    577 | GPU
DEBUG 01-05 12:51:19.110305.110305 lmp.py:376]   Expert  9 |   1000 | GPU
DEBUG 01-05 12:51:19.110385.110385 lmp.py:376]   Expert 23 |   1242 | GPU
DEBUG 01-05 12:51:19.110658.110658 lmp.py:377] 
DEBUG 01-05 12:51:19.110658.110658 lmp.py:377]   CPU total tokens: 2376 (19.3%)
DEBUG 01-05 12:51:19.110645.110645 lmp.py:378]   GPU total tokens: 9912 (80.7%)
DEBUG 01-05 12:51:19.110070.110070 cuda_h.py:19] end experts_map_get cost 0.002703428268432617 seconds
DEBUG 01-05 12:51:19.110727.110727 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.110146.110146 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.110602.110602 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.111194.111194 cuda_h.py:19] end allocate_cuda_memory cost 0.0002510547637939453 seconds
DEBUG 01-05 12:51:19.111488.111488 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.111688.111688 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.111849.111849 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.111320.111320 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed773bab-d169-4424-ba28-acf7b6264771
DEBUG 01-05 12:51:19.111533.111533 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.113256.113256 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed773bab-d169-4424-ba28-acf7b6264771
DEBUG 01-05 12:51:19.113662.113662 cuda_h.py:19] end load_into_gpu_async cost 0.002368927001953125 seconds
DEBUG 01-05 12:51:19.113385.113385 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.114702.114702 cuda_h.py:19] end restore_tensors2 cost 0.0003459453582763672 seconds
DEBUG 01-05 12:51:19.114571.114571 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033719539642333984 seconds
DEBUG 01-05 12:51:19.117964.117964 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006668806076049805 seconds
DEBUG 01-05 12:51:19.117516.117516 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.117777.117777 lmp.py:423] 
DEBUG 01-05 12:51:19.117777.117777 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.117349.117349 cuda_h.py:19] end cpu_experts_submit cost 0.0001266002655029297 seconds
DEBUG 01-05 12:51:19.117668.117668 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.122517.122517 mlpmodule.py:704] group tensors cost 0.005049705505371094 s
DEBUG 01-05 12:51:19.125633.125633 mlpmodule.py:742] pad cost 0.0020296573638916016 s
DEBUG 01-05 12:51:19.125604.125604 mlpmodule.py:748] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-05 12:51:19.125673.125673 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 12:51:19.134976.134976 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.134385.134385 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.135945.135945 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 12:51:19.135300.135300 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.151362.151362 mlpmodule.py:793] group einsum cost 0.025814056396484375 s
DEBUG 01-05 12:51:19.152677.152677 mlpmodule.py:801] cpy2cputensor cost 0.0005421638488769531 s
DEBUG 01-05 12:51:19.157949.157949 cuda_h.py:19] end wait_cetm_experts cost 0.03941702842712402 seconds
DEBUG 01-05 12:51:19.157886.157886 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.157088.157088 cuda_h.py:19] end gpu_sexperts cost 0.0004525184631347656 seconds
DEBUG 01-05 12:51:19.157163.157163 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.157205.157205 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-05 12:51:19.157862.157862 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.157618.157618 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed773bab-d169-4424-ba28-acf7b6264771
INFO 01-05 12:51:19.166068.166068 client.py:127] Model loaded
DEBUG 01-05 12:51:19.166938.166938 cuda_h.py:19] end wait_experts cost 0.008766412734985352 seconds
DEBUG 01-05 12:51:19.166939.166939 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.166901.166901 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.167709.167709 mlpmodule.py:531] gpu group tensors cost 0.00051116943359375 s
DEBUG 01-05 12:51:19.168687.168687 mlpmodule.py:564] gpu pad cost 0.001474142074584961 s
DEBUG 01-05 12:51:19.169076.169076 mlpmodule.py:582] gpu group einsum cost 0.00046443939208984375 s
DEBUG 01-05 12:51:19.172526.172526 mlpmodule.py:611] gpu experts func einsum cost 0.005326271057128906 s
DEBUG 01-05 12:51:19.172184.172184 cuda_h.py:19] end gpu_experts cost 0.0055103302001953125 seconds
DEBUG 01-05 12:51:19.172313.172313 cuda_h.py:19] end layer_moe_generate_7 cost 0.0653834342956543 seconds
DEBUG 01-05 12:51:19.172690.172690 lmp.py:217] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 12:51:19.172466.172466 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 12:51:19.172931.172931 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 12:51:19.172038.172038 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 12:51:19.172604.172604 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 12:51:19.172671.172671 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 8.678436279296875e-05 seconds
DEBUG 01-05 12:51:19.172705.172705 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.172065.172065 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.172790.172790 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.173448.173448 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.176536.176536 cuda_h.py:19] end allocate_cuda_memory cost 0.0031855106353759766 seconds
DEBUG 01-05 12:51:19.176487.176487 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.176680.176680 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.176132.176132 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.176643.176643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4d1316b-b92a-4fa0-a3ca-9cdfa80bc67c
DEBUG 01-05 12:51:19.176328.176328 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.176267.176267 mlpmodule.py:662]  experts func einsum cost 0.05892205238342285 s
DEBUG 01-05 12:51:19.176539.176539 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.177062.177062 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4d1316b-b92a-4fa0-a3ca-9cdfa80bc67c
DEBUG 01-05 12:51:19.177104.177104 cuda_h.py:19] end load_into_gpu_async cost 0.0015764236450195312 seconds
DEBUG 01-05 12:51:19.177469.177469 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.178061.178061 cuda_h.py:19] end restore_tensors2 cost 6.103515625e-05 seconds
DEBUG 01-05 12:51:19.178393.178393 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0050983428955078125 seconds
INFO 01-05 12:51:19.178760.178760 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4d1316b-b92a-4fa0-a3ca-9cdfa80bc67c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.180329.180329 cuda_h.py:19] end self_attn cost 0.003148317337036133 seconds
DEBUG 01-05 12:51:19.180194.180194 cuda_h.py:19] end iln_self_attn_paln cost 0.0076296329498291016 seconds
DEBUG 01-05 12:51:19.180289.180289 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 12:51:19.180582.180582 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.181836.181836 cuda_h.py:19] end gate cost 0.0006389617919921875 seconds
DEBUG 01-05 12:51:19.181666.181666 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.181133.181133 lmp.py:365] 
DEBUG 01-05 12:51:19.181133.181133 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.181704.181704 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.181175.181175 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.181494.181494 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.181190.181190 lmp.py:369] 
DEBUG 01-05 12:51:19.181190.181190 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.181601.181601 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.181635.181635 lmp.py:376]   Expert 26 |     12 | CPU
DEBUG 01-05 12:51:19.181324.181324 lmp.py:376]   Expert 27 |     21 | CPU
DEBUG 01-05 12:51:19.181821.181821 lmp.py:376]   Expert 30 |     22 | CPU
DEBUG 01-05 12:51:19.181557.181557 lmp.py:376]   Expert  7 |     26 | CPU
DEBUG 01-05 12:51:19.181577.181577 lmp.py:376]   Expert 14 |     28 | CPU
DEBUG 01-05 12:51:19.181836.181836 lmp.py:376]   Expert 38 |     28 | CPU
DEBUG 01-05 12:51:19.181857.181857 lmp.py:376]   Expert 12 |     36 | CPU
DEBUG 01-05 12:51:19.181639.181639 lmp.py:376]   Expert  8 |     37 | CPU
DEBUG 01-05 12:51:19.181659.181659 lmp.py:376]   Expert 53 |     46 | CPU
DEBUG 01-05 12:51:19.181785.181785 lmp.py:376]   Expert 34 |     47 | CPU
DEBUG 01-05 12:51:19.181866.181866 lmp.py:376]   Expert 36 |     51 | CPU
DEBUG 01-05 12:51:19.181800.181800 lmp.py:376]   Expert 33 |     54 | CPU
DEBUG 01-05 12:51:19.181020.181020 lmp.py:376]   Expert 22 |     55 | CPU
DEBUG 01-05 12:51:19.181716.181716 lmp.py:376]   Expert 50 |     69 | CPU
DEBUG 01-05 12:51:19.182266.182266 lmp.py:376]   Expert 13 |     71 | CPU
DEBUG 01-05 12:51:19.182485.182485 lmp.py:376]   Expert 57 |     74 | CPU
DEBUG 01-05 12:51:19.182042.182042 lmp.py:376]   Expert 54 |     76 | CPU
DEBUG 01-05 12:51:19.182255.182255 lmp.py:376]   Expert  2 |     81 | CPU
DEBUG 01-05 12:51:19.182706.182706 lmp.py:376]   Expert 15 |     83 | CPU
DEBUG 01-05 12:51:19.182071.182071 lmp.py:376]   Expert 32 |     91 | CPU
DEBUG 01-05 12:51:19.182535.182535 lmp.py:376]   Expert 18 |     95 | CPU
DEBUG 01-05 12:51:19.182231.182231 lmp.py:376]   Expert 29 |     99 | CPU
DEBUG 01-05 12:51:19.182166.182166 lmp.py:376]   Expert  1 |    102 | CPU
DEBUG 01-05 12:51:19.182385.182385 lmp.py:376]   Expert  9 |    102 | CPU
DEBUG 01-05 12:51:19.182697.182697 lmp.py:376]   Expert 37 |    105 | CPU
DEBUG 01-05 12:51:19.182671.182671 lmp.py:376]   Expert 56 |    116 | CPU
DEBUG 01-05 12:51:19.182645.182645 lmp.py:376]   Expert 58 |    123 | CPU
DEBUG 01-05 12:51:19.182142.182142 lmp.py:376]   Expert 24 |    125 | CPU
DEBUG 01-05 12:51:19.182878.182878 lmp.py:376]   Expert 19 |    126 | CPU
DEBUG 01-05 12:51:19.182613.182613 lmp.py:376]   Expert 16 |    128 | CPU
DEBUG 01-05 12:51:19.182349.182349 lmp.py:376]   Expert 51 |    141 | CPU
DEBUG 01-05 12:51:19.182846.182846 lmp.py:376]   Expert 39 |    142 | CPU
DEBUG 01-05 12:51:19.182450.182450 lmp.py:376]   Expert 60 |    148 | GPU
DEBUG 01-05 12:51:19.182907.182907 lmp.py:376]   Expert 42 |    149 | GPU
DEBUG 01-05 12:51:19.182842.182842 lmp.py:376]   Expert 59 |    153 | GPU
DEBUG 01-05 12:51:19.182538.182538 lmp.py:376]   Expert 44 |    162 | GPU
DEBUG 01-05 12:51:19.182996.182996 lmp.py:376]   Expert 31 |    164 | GPU
DEBUG 01-05 12:51:19.182023.182023 lmp.py:376]   Expert 10 |    166 | GPU
DEBUG 01-05 12:51:19.182765.182765 lmp.py:376]   Expert 40 |    167 | GPU
DEBUG 01-05 12:51:19.182978.182978 lmp.py:376]   Expert 17 |    187 | GPU
DEBUG 01-05 12:51:19.182429.182429 lmp.py:376]   Expert 23 |    194 | GPU
DEBUG 01-05 12:51:19.182562.182562 lmp.py:376]   Expert 46 |    216 | GPU
DEBUG 01-05 12:51:19.182351.182351 lmp.py:376]   Expert 20 |    219 | GPU
DEBUG 01-05 12:51:19.182570.182570 lmp.py:376]   Expert 55 |    223 | GPU
DEBUG 01-05 12:51:19.182551.182551 lmp.py:376]   Expert 49 |    230 | GPU
DEBUG 01-05 12:51:19.182816.182816 lmp.py:376]   Expert  3 |    238 | GPU
DEBUG 01-05 12:51:19.182651.182651 lmp.py:376]   Expert  0 |    245 | GPU
DEBUG 01-05 12:51:19.182910.182910 lmp.py:376]   Expert 41 |    259 | GPU
DEBUG 01-05 12:51:19.182931.182931 lmp.py:376]   Expert 25 |    264 | GPU
DEBUG 01-05 12:51:19.182951.182951 lmp.py:376]   Expert 48 |    266 | GPU
DEBUG 01-05 12:51:19.182971.182971 lmp.py:376]   Expert 43 |    304 | GPU
DEBUG 01-05 12:51:19.182515.182515 lmp.py:376]   Expert 45 |    304 | GPU
DEBUG 01-05 12:51:19.182535.182535 lmp.py:376]   Expert 28 |    322 | GPU
DEBUG 01-05 12:51:19.182377.182377 lmp.py:376]   Expert  6 |    340 | GPU
DEBUG 01-05 12:51:19.182927.182927 lmp.py:376]   Expert 52 |    340 | GPU
DEBUG 01-05 12:51:19.182147.182147 lmp.py:376]   Expert 61 |    348 | GPU
DEBUG 01-05 12:51:19.182128.182128 lmp.py:376]   Expert  4 |    381 | GPU
DEBUG 01-05 12:51:19.182393.182393 lmp.py:376]   Expert 62 |    382 | GPU
DEBUG 01-05 12:51:19.182228.182228 lmp.py:376]   Expert 35 |    430 | GPU
DEBUG 01-05 12:51:19.182302.182302 lmp.py:376]   Expert 47 |    460 | GPU
DEBUG 01-05 12:51:19.182898.182898 lmp.py:376]   Expert 11 |    544 | GPU
DEBUG 01-05 12:51:19.182257.182257 lmp.py:376]   Expert  5 |    621 | GPU
DEBUG 01-05 12:51:19.182092.182092 lmp.py:376]   Expert 63 |    636 | GPU
DEBUG 01-05 12:51:19.182880.182880 lmp.py:376]   Expert 21 |    814 | GPU
DEBUG 01-05 12:51:19.182676.182676 lmp.py:377] 
DEBUG 01-05 12:51:19.182676.182676 lmp.py:377]   CPU total tokens: 2412 (19.6%)
DEBUG 01-05 12:51:19.182372.182372 lmp.py:378]   GPU total tokens: 9876 (80.4%)
DEBUG 01-05 12:51:19.183505.183505 cuda_h.py:19] end experts_map_get cost 0.001703500747680664 seconds
DEBUG 01-05 12:51:19.183056.183056 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.183746.183746 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.183360.183360 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.185517.185517 cuda_h.py:19] end allocate_cuda_memory cost 0.0018677711486816406 seconds
DEBUG 01-05 12:51:19.185519.185519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.185103.185103 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.185449.185449 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.185821.185821 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c6c8561e-937b-4d35-b305-b6c8c426a623
DEBUG 01-05 12:51:19.185371.185371 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.185232.185232 client.py:127] Model loaded
DEBUG 01-05 12:51:19.186798.186798 cuda_h.py:19] end sllm_worker_task cost 0.013069391250610352 seconds
INFO 01-05 12:51:19.187328.187328 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c6c8561e-937b-4d35-b305-b6c8c426a623
DEBUG 01-05 12:51:19.187075.187075 cuda_h.py:19] end load_into_gpu_async cost 0.002308368682861328 seconds
DEBUG 01-05 12:51:19.187304.187304 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.188475.188475 cuda_h.py:19] end restore_tensors2 cost 0.0002892017364501953 seconds
DEBUG 01-05 12:51:19.188066.188066 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004988193511962891 seconds
DEBUG 01-05 12:51:19.190116.190116 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007696866989135742 seconds
DEBUG 01-05 12:51:19.190429.190429 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.190790.190790 lmp.py:423] 
DEBUG 01-05 12:51:19.190790.190790 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.190355.190355 cuda_h.py:19] end cpu_experts_submit cost 0.00011682510375976562 seconds
DEBUG 01-05 12:51:19.191627.191627 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.200122.200122 mlpmodule.py:704] group tensors cost 0.009285926818847656 s
DEBUG 01-05 12:51:19.202799.202799 mlpmodule.py:742] pad cost 0.0018417835235595703 s
DEBUG 01-05 12:51:19.202094.202094 mlpmodule.py:748] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-05 12:51:19.203772.203772 mlpmodule.py:753] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-05 12:51:19.211524.211524 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.211963.211963 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.212563.212563 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 12:51:19.212408.212408 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.230931.230931 mlpmodule.py:793] group einsum cost 0.027219057083129883 s
DEBUG 01-05 12:51:19.231310.231310 mlpmodule.py:801] cpy2cputensor cost 0.0005497932434082031 s
DEBUG 01-05 12:51:19.236208.236208 cuda_h.py:19] end wait_cetm_experts cost 0.04497170448303223 seconds
DEBUG 01-05 12:51:19.236416.236416 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.236353.236353 cuda_h.py:19] end gpu_sexperts cost 0.00047516822814941406 seconds
DEBUG 01-05 12:51:19.236303.236303 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.236298.236298 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:19.236670.236670 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.236426.236426 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c6c8561e-937b-4d35-b305-b6c8c426a623
INFO 01-05 12:51:19.238763.238763 client.py:127] Model loaded
DEBUG 01-05 12:51:19.238898.238898 cuda_h.py:19] end wait_experts cost 0.001821756362915039 seconds
DEBUG 01-05 12:51:19.238270.238270 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.238026.238026 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.239937.239937 mlpmodule.py:531] gpu group tensors cost 0.0006265640258789062 s
DEBUG 01-05 12:51:19.241598.241598 mlpmodule.py:564] gpu pad cost 0.0016868114471435547 s
DEBUG 01-05 12:51:19.241665.241665 mlpmodule.py:582] gpu group einsum cost 0.0005199909210205078 s
DEBUG 01-05 12:51:19.245205.245205 mlpmodule.py:611] gpu experts func einsum cost 0.0064754486083984375 s
DEBUG 01-05 12:51:19.245210.245210 cuda_h.py:19] end gpu_experts cost 0.0067021846771240234 seconds
DEBUG 01-05 12:51:19.245778.245778 cuda_h.py:19] end layer_moe_generate_8 cost 0.0650014877319336 seconds
DEBUG 01-05 12:51:19.245725.245725 lmp.py:217] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 12:51:19.245217.245217 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 12:51:19.245966.245966 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 12:51:19.245252.245252 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 12:51:19.245956.245956 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.24249267578125e-05 seconds
DEBUG 01-05 12:51:19.245666.245666 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.747245788574219e-05 seconds
DEBUG 01-05 12:51:19.245984.245984 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.246596.246596 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.246315.246315 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.246158.246158 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.249659.249659 cuda_h.py:19] end allocate_cuda_memory cost 0.0030698776245117188 seconds
DEBUG 01-05 12:51:19.249662.249662 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.249086.249086 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.249094.249094 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.249413.249413 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc133c31-8f09-4a3c-b340-472c984a3812
DEBUG 01-05 12:51:19.249144.249144 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.249553.249553 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.250298.250298 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc133c31-8f09-4a3c-b340-472c984a3812
DEBUG 01-05 12:51:19.251088.251088 cuda_h.py:19] end load_into_gpu_async cost 0.001615762710571289 seconds
DEBUG 01-05 12:51:19.251883.251883 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.251621.251621 cuda_h.py:19] end restore_tensors2 cost 6.270408630371094e-05 seconds
DEBUG 01-05 12:51:19.251039.251039 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004989147186279297 seconds
INFO 01-05 12:51:19.251394.251394 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc133c31-8f09-4a3c-b340-472c984a3812
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.253226.253226 cuda_h.py:19] end self_attn cost 0.0037965774536132812 seconds
DEBUG 01-05 12:51:19.254235.254235 cuda_h.py:19] end iln_self_attn_paln cost 0.008051156997680664 seconds
DEBUG 01-05 12:51:19.254171.254171 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 12:51:19.254364.254364 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.254497.254497 cuda_h.py:19] end gate cost 0.0007660388946533203 seconds
DEBUG 01-05 12:51:19.255896.255896 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.255104.255104 lmp.py:365] 
DEBUG 01-05 12:51:19.255104.255104 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.255576.255576 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.255702.255702 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.255491.255491 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.255657.255657 lmp.py:369] 
DEBUG 01-05 12:51:19.255657.255657 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.255823.255823 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.255473.255473 lmp.py:376]   Expert 38 |     23 | CPU
DEBUG 01-05 12:51:19.255878.255878 lmp.py:376]   Expert 35 |     24 | CPU
DEBUG 01-05 12:51:19.255328.255328 lmp.py:376]   Expert  7 |     27 | CPU
DEBUG 01-05 12:51:19.255779.255779 lmp.py:376]   Expert  5 |     29 | CPU
DEBUG 01-05 12:51:19.255230.255230 lmp.py:376]   Expert  6 |     31 | CPU
DEBUG 01-05 12:51:19.255158.255158 lmp.py:376]   Expert 13 |     35 | CPU
DEBUG 01-05 12:51:19.255847.255847 lmp.py:376]   Expert 19 |     39 | CPU
DEBUG 01-05 12:51:19.255060.255060 lmp.py:376]   Expert 17 |     42 | CPU
DEBUG 01-05 12:51:19.255987.255987 lmp.py:376]   Expert 60 |     55 | CPU
DEBUG 01-05 12:51:19.255200.255200 lmp.py:376]   Expert 52 |     66 | CPU
DEBUG 01-05 12:51:19.255412.255412 lmp.py:376]   Expert  2 |     67 | CPU
DEBUG 01-05 12:51:19.255863.255863 lmp.py:376]   Expert 27 |     70 | CPU
DEBUG 01-05 12:51:19.255076.255076 lmp.py:376]   Expert 39 |     70 | CPU
DEBUG 01-05 12:51:19.255765.255765 lmp.py:376]   Expert 48 |     70 | CPU
DEBUG 01-05 12:51:19.255501.255501 lmp.py:376]   Expert 45 |     74 | CPU
DEBUG 01-05 12:51:19.255952.255952 lmp.py:376]   Expert 42 |     81 | CPU
DEBUG 01-05 12:51:19.255164.255164 lmp.py:376]   Expert 25 |     82 | CPU
DEBUG 01-05 12:51:19.255376.255376 lmp.py:376]   Expert 54 |     82 | CPU
DEBUG 01-05 12:51:19.255589.255589 lmp.py:376]   Expert 16 |     83 | CPU
DEBUG 01-05 12:51:19.255801.255801 lmp.py:376]   Expert 26 |     86 | CPU
DEBUG 01-05 12:51:19.255537.255537 lmp.py:376]   Expert 29 |     86 | CPU
DEBUG 01-05 12:51:19.255988.255988 lmp.py:376]   Expert 59 |     86 | CPU
DEBUG 01-05 12:51:19.255724.255724 lmp.py:376]   Expert 32 |     88 | CPU
DEBUG 01-05 12:51:19.255936.255936 lmp.py:376]   Expert 20 |     89 | CPU
DEBUG 01-05 12:51:19.255148.255148 lmp.py:376]   Expert 62 |     93 | CPU
DEBUG 01-05 12:51:19.255361.255361 lmp.py:376]   Expert 40 |    107 | CPU
DEBUG 01-05 12:51:19.255527.255527 lmp.py:376]   Expert 12 |    109 | CPU
DEBUG 01-05 12:51:19.255216.255216 lmp.py:376]   Expert 23 |    112 | CPU
DEBUG 01-05 12:51:19.255429.255429 lmp.py:376]   Expert 24 |    125 | CPU
DEBUG 01-05 12:51:19.255118.255118 lmp.py:376]   Expert 57 |    125 | CPU
DEBUG 01-05 12:51:19.255331.255331 lmp.py:376]   Expert 31 |    132 | CPU
DEBUG 01-05 12:51:19.255020.255020 lmp.py:376]   Expert 18 |    149 | CPU
DEBUG 01-05 12:51:19.255709.255709 lmp.py:376]   Expert 41 |    150 | GPU
DEBUG 01-05 12:51:19.255398.255398 lmp.py:376]   Expert 47 |    154 | GPU
DEBUG 01-05 12:51:19.255611.255611 lmp.py:376]   Expert 22 |    156 | GPU
DEBUG 01-05 12:51:19.256539.256539 lmp.py:376]   Expert 14 |    162 | GPU
DEBUG 01-05 12:51:19.256466.256466 lmp.py:376]   Expert 50 |    164 | GPU
DEBUG 01-05 12:51:19.256156.256156 lmp.py:376]   Expert 30 |    165 | GPU
DEBUG 01-05 12:51:19.256607.256607 lmp.py:376]   Expert  1 |    168 | GPU
DEBUG 01-05 12:51:19.256057.256057 lmp.py:376]   Expert 51 |    174 | GPU
DEBUG 01-05 12:51:19.256508.256508 lmp.py:376]   Expert 28 |    177 | GPU
DEBUG 01-05 12:51:19.256959.256959 lmp.py:376]   Expert 34 |    193 | GPU
DEBUG 01-05 12:51:19.256172.256172 lmp.py:376]   Expert 49 |    198 | GPU
DEBUG 01-05 12:51:19.256384.256384 lmp.py:376]   Expert 58 |    208 | GPU
DEBUG 01-05 12:51:19.256597.256597 lmp.py:376]   Expert 33 |    218 | GPU
DEBUG 01-05 12:51:19.256047.256047 lmp.py:376]   Expert 53 |    222 | GPU
DEBUG 01-05 12:51:19.256975.256975 lmp.py:376]   Expert 44 |    229 | GPU
DEBUG 01-05 12:51:19.256426.256426 lmp.py:376]   Expert  0 |    248 | GPU
DEBUG 01-05 12:51:19.256877.256877 lmp.py:376]   Expert 36 |    252 | GPU
DEBUG 01-05 12:51:19.256328.256328 lmp.py:376]   Expert  3 |    255 | GPU
DEBUG 01-05 12:51:19.256302.256302 lmp.py:376]   Expert  8 |    256 | GPU
DEBUG 01-05 12:51:19.256753.256753 lmp.py:376]   Expert  4 |    271 | GPU
DEBUG 01-05 12:51:19.256965.256965 lmp.py:376]   Expert 55 |    304 | GPU
DEBUG 01-05 12:51:19.256178.256178 lmp.py:376]   Expert 37 |    334 | GPU
DEBUG 01-05 12:51:19.256390.256390 lmp.py:376]   Expert 11 |    346 | GPU
DEBUG 01-05 12:51:19.256079.256079 lmp.py:376]   Expert 43 |    352 | GPU
DEBUG 01-05 12:51:19.256246.256246 lmp.py:376]   Expert 10 |    353 | GPU
DEBUG 01-05 12:51:19.256696.256696 lmp.py:376]   Expert 15 |    383 | GPU
DEBUG 01-05 12:51:19.256042.256042 lmp.py:376]   Expert 61 |    400 | GPU
DEBUG 01-05 12:51:19.256129.256129 lmp.py:376]   Expert  9 |    426 | GPU
DEBUG 01-05 12:51:19.256772.256772 lmp.py:376]   Expert 46 |    448 | GPU
DEBUG 01-05 12:51:19.256700.256700 lmp.py:376]   Expert 63 |    528 | GPU
DEBUG 01-05 12:51:19.256389.256389 lmp.py:376]   Expert 21 |    618 | GPU
DEBUG 01-05 12:51:19.256840.256840 lmp.py:376]   Expert 56 |   1339 | GPU
DEBUG 01-05 12:51:19.256675.256675 lmp.py:377] 
DEBUG 01-05 12:51:19.256675.256675 lmp.py:377]   CPU total tokens: 2437 (19.8%)
DEBUG 01-05 12:51:19.256080.256080 lmp.py:378]   GPU total tokens: 9851 (80.2%)
DEBUG 01-05 12:51:19.256207.256207 cuda_h.py:19] end experts_map_get cost 0.0015332698822021484 seconds
DEBUG 01-05 12:51:19.256849.256849 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.256533.256533 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.256147.256147 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.257694.257694 cuda_h.py:19] end allocate_cuda_memory cost 0.0008530616760253906 seconds
DEBUG 01-05 12:51:19.257874.257874 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.257797.257797 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.257944.257944 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.257593.257593 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb7ed616-1904-4b06-b7ef-6b090c5cf375
DEBUG 01-05 12:51:19.258076.258076 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.258948.258948 mlpmodule.py:662]  experts func einsum cost 0.06700944900512695 s
INFO 01-05 12:51:19.258184.258184 client.py:127] Model loaded
DEBUG 01-05 12:51:19.258597.258597 cuda_h.py:19] end sllm_worker_task cost 0.012184381484985352 seconds
INFO 01-05 12:51:19.259643.259643 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb7ed616-1904-4b06-b7ef-6b090c5cf375
DEBUG 01-05 12:51:19.259916.259916 cuda_h.py:19] end load_into_gpu_async cost 0.0021927356719970703 seconds
DEBUG 01-05 12:51:19.260427.260427 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.260126.260126 cuda_h.py:19] end restore_tensors2 cost 0.0002799034118652344 seconds
DEBUG 01-05 12:51:19.260419.260419 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003685474395751953 seconds
DEBUG 01-05 12:51:19.262044.262044 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006365537643432617 seconds
DEBUG 01-05 12:51:19.263681.263681 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.263711.263711 lmp.py:423] 
DEBUG 01-05 12:51:19.263711.263711 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.263170.263170 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 12:51:19.263773.263773 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.267445.267445 mlpmodule.py:704] group tensors cost 0.004540205001831055 s
DEBUG 01-05 12:51:19.270442.270442 mlpmodule.py:742] pad cost 0.001695871353149414 s
DEBUG 01-05 12:51:19.270723.270723 mlpmodule.py:748] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-05 12:51:19.270249.270249 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 12:51:19.279446.279446 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.279240.279240 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.279614.279614 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 12:51:19.279492.279492 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.298973.298973 mlpmodule.py:793] group einsum cost 0.028479576110839844 s
DEBUG 01-05 12:51:19.299330.299330 mlpmodule.py:801] cpy2cputensor cost 0.0005719661712646484 s
DEBUG 01-05 12:51:19.304835.304835 cuda_h.py:19] end wait_cetm_experts cost 0.0411229133605957 seconds
DEBUG 01-05 12:51:19.304296.304296 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.305690.305690 cuda_h.py:19] end gpu_sexperts cost 0.000446319580078125 seconds
DEBUG 01-05 12:51:19.305548.305548 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.305657.305657 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-05 12:51:19.305267.305267 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.305261.305261 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb7ed616-1904-4b06-b7ef-6b090c5cf375
INFO 01-05 12:51:19.312686.312686 client.py:127] Model loaded
DEBUG 01-05 12:51:19.312167.312167 cuda_h.py:19] end wait_experts cost 0.0076525211334228516 seconds
DEBUG 01-05 12:51:19.312890.312890 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.313076.313076 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.313866.313866 mlpmodule.py:531] gpu group tensors cost 0.0007486343383789062 s
DEBUG 01-05 12:51:19.315203.315203 mlpmodule.py:564] gpu pad cost 0.0014882087707519531 s
DEBUG 01-05 12:51:19.315321.315321 mlpmodule.py:582] gpu group einsum cost 0.0004603862762451172 s
DEBUG 01-05 12:51:19.318411.318411 mlpmodule.py:611] gpu experts func einsum cost 0.005749702453613281 s
DEBUG 01-05 12:51:19.318732.318732 cuda_h.py:19] end gpu_experts cost 0.005925893783569336 seconds
DEBUG 01-05 12:51:19.319576.319576 cuda_h.py:19] end layer_moe_generate_9 cost 0.06487202644348145 seconds
DEBUG 01-05 12:51:19.319992.319992 lmp.py:217] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 12:51:19.319238.319238 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 12:51:19.319219.319219 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 12:51:19.319022.319022 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 12:51:19.319395.319395 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.504753112792969e-05 seconds
DEBUG 01-05 12:51:19.319270.319270 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 8.96453857421875e-05 seconds
DEBUG 01-05 12:51:19.319828.319828 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.319055.319055 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.319781.319781 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.319431.319431 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.323820.323820 cuda_h.py:19] end allocate_cuda_memory cost 0.003444194793701172 seconds
DEBUG 01-05 12:51:19.323326.323326 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.323135.323135 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.323004.323004 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.323753.323753 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f376e992-30b9-491e-a2f9-b4c2284f7d76
DEBUG 01-05 12:51:19.323723.323723 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.323549.323549 mlpmodule.py:662]  experts func einsum cost 0.060282230377197266 s
DEBUG 01-05 12:51:19.323009.323009 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.324096.324096 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f376e992-30b9-491e-a2f9-b4c2284f7d76
DEBUG 01-05 12:51:19.324437.324437 cuda_h.py:19] end load_into_gpu_async cost 0.0014851093292236328 seconds
DEBUG 01-05 12:51:19.324901.324901 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.324016.324016 cuda_h.py:19] end restore_tensors2 cost 5.936622619628906e-05 seconds
DEBUG 01-05 12:51:19.324388.324388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005255937576293945 seconds
INFO 01-05 12:51:19.325173.325173 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f376e992-30b9-491e-a2f9-b4c2284f7d76
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.327949.327949 cuda_h.py:19] end self_attn cost 0.0038874149322509766 seconds
DEBUG 01-05 12:51:19.328741.328741 cuda_h.py:19] end iln_self_attn_paln cost 0.008639097213745117 seconds
DEBUG 01-05 12:51:19.328160.328160 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 12:51:19.328930.328930 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.328019.328019 cuda_h.py:19] end gate cost 0.0006546974182128906 seconds
DEBUG 01-05 12:51:19.328041.328041 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.329356.329356 lmp.py:365] 
DEBUG 01-05 12:51:19.329356.329356 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.329834.329834 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.329020.329020 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.329292.329292 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.329128.329128 lmp.py:369] 
DEBUG 01-05 12:51:19.329128.329128 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.329578.329578 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.329705.329705 lmp.py:376]   Expert 34 |      2 | CPU
DEBUG 01-05 12:51:19.329871.329871 lmp.py:376]   Expert 27 |      8 | CPU
DEBUG 01-05 12:51:19.329322.329322 lmp.py:376]   Expert  3 |     12 | CPU
DEBUG 01-05 12:51:19.329296.329296 lmp.py:376]   Expert 14 |     20 | CPU
DEBUG 01-05 12:51:19.329376.329376 lmp.py:376]   Expert 55 |     21 | CPU
DEBUG 01-05 12:51:19.329072.329072 lmp.py:376]   Expert 61 |     21 | CPU
DEBUG 01-05 12:51:19.329160.329160 lmp.py:376]   Expert 47 |     23 | CPU
DEBUG 01-05 12:51:19.329418.329418 lmp.py:376]   Expert 32 |     26 | CPU
DEBUG 01-05 12:51:19.329677.329677 lmp.py:376]   Expert  6 |     27 | CPU
DEBUG 01-05 12:51:19.329459.329459 lmp.py:376]   Expert 13 |     37 | CPU
DEBUG 01-05 12:51:19.329241.329241 lmp.py:376]   Expert 46 |     37 | CPU
DEBUG 01-05 12:51:19.329261.329261 lmp.py:376]   Expert 37 |     40 | CPU
DEBUG 01-05 12:51:19.329242.329242 lmp.py:376]   Expert 44 |     44 | CPU
DEBUG 01-05 12:51:19.329223.329223 lmp.py:376]   Expert 50 |     47 | CPU
DEBUG 01-05 12:51:19.329389.329389 lmp.py:376]   Expert 15 |     51 | CPU
DEBUG 01-05 12:51:19.329171.329171 lmp.py:376]   Expert 48 |     51 | CPU
DEBUG 01-05 12:51:19.329953.329953 lmp.py:376]   Expert 19 |     52 | CPU
DEBUG 01-05 12:51:19.329973.329973 lmp.py:376]   Expert  7 |     58 | CPU
DEBUG 01-05 12:51:19.329994.329994 lmp.py:376]   Expert 17 |     61 | CPU
DEBUG 01-05 12:51:19.329537.329537 lmp.py:376]   Expert 38 |     62 | CPU
DEBUG 01-05 12:51:19.329081.329081 lmp.py:376]   Expert 12 |     76 | CPU
DEBUG 01-05 12:51:19.329624.329624 lmp.py:376]   Expert 54 |     84 | CPU
DEBUG 01-05 12:51:19.329559.329559 lmp.py:376]   Expert 35 |     85 | CPU
DEBUG 01-05 12:51:19.329109.329109 lmp.py:376]   Expert 60 |     87 | CPU
DEBUG 01-05 12:51:19.329521.329521 lmp.py:376]   Expert 26 |     91 | CPU
DEBUG 01-05 12:51:19.329071.329071 lmp.py:376]   Expert 56 |     96 | CPU
DEBUG 01-05 12:51:19.329045.329045 lmp.py:376]   Expert 62 |     99 | CPU
DEBUG 01-05 12:51:19.329257.329257 lmp.py:376]   Expert 43 |    103 | CPU
DEBUG 01-05 12:51:19.329755.329755 lmp.py:376]   Expert 28 |    108 | CPU
DEBUG 01-05 12:51:19.329729.329729 lmp.py:376]   Expert 20 |    111 | CPU
DEBUG 01-05 12:51:19.329133.329133 lmp.py:376]   Expert 29 |    111 | CPU
DEBUG 01-05 12:51:19.329690.329690 lmp.py:376]   Expert 36 |    133 | CPU
DEBUG 01-05 12:51:19.329102.329102 lmp.py:376]   Expert 22 |    142 | GPU
DEBUG 01-05 12:51:19.330844.330844 lmp.py:376]   Expert 25 |    142 | GPU
DEBUG 01-05 12:51:19.330156.330156 lmp.py:376]   Expert 41 |    142 | GPU
DEBUG 01-05 12:51:19.330653.330653 lmp.py:376]   Expert 52 |    147 | GPU
DEBUG 01-05 12:51:19.330627.330627 lmp.py:376]   Expert  5 |    157 | GPU
DEBUG 01-05 12:51:19.330886.330886 lmp.py:376]   Expert 51 |    176 | GPU
DEBUG 01-05 12:51:19.330052.330052 lmp.py:376]   Expert 24 |    181 | GPU
DEBUG 01-05 12:51:19.330086.330086 lmp.py:376]   Expert 59 |    183 | GPU
DEBUG 01-05 12:51:19.330690.330690 lmp.py:376]   Expert 53 |    184 | GPU
DEBUG 01-05 12:51:19.330140.330140 lmp.py:376]   Expert  9 |    203 | GPU
DEBUG 01-05 12:51:19.330638.330638 lmp.py:376]   Expert 45 |    205 | GPU
DEBUG 01-05 12:51:19.330373.330373 lmp.py:376]   Expert 57 |    214 | GPU
DEBUG 01-05 12:51:19.330347.330347 lmp.py:376]   Expert 30 |    221 | GPU
DEBUG 01-05 12:51:19.330606.330606 lmp.py:376]   Expert 21 |    228 | GPU
DEBUG 01-05 12:51:19.330103.330103 lmp.py:376]   Expert 31 |    246 | GPU
DEBUG 01-05 12:51:19.330270.330270 lmp.py:376]   Expert 49 |    257 | GPU
DEBUG 01-05 12:51:19.330019.330019 lmp.py:376]   Expert 63 |    258 | GPU
DEBUG 01-05 12:51:19.330953.330953 lmp.py:376]   Expert  2 |    264 | GPU
DEBUG 01-05 12:51:19.330934.330934 lmp.py:376]   Expert  8 |    274 | GPU
DEBUG 01-05 12:51:19.330246.330246 lmp.py:376]   Expert 16 |    280 | GPU
DEBUG 01-05 12:51:19.330982.330982 lmp.py:376]   Expert 18 |    284 | GPU
DEBUG 01-05 12:51:19.330101.330101 lmp.py:376]   Expert 39 |    294 | GPU
DEBUG 01-05 12:51:19.330705.330705 lmp.py:376]   Expert 42 |    351 | GPU
DEBUG 01-05 12:51:19.330116.330116 lmp.py:376]   Expert 10 |    353 | GPU
DEBUG 01-05 12:51:19.330859.330859 lmp.py:376]   Expert 23 |    360 | GPU
DEBUG 01-05 12:51:19.330409.330409 lmp.py:376]   Expert 40 |    393 | GPU
DEBUG 01-05 12:51:19.330959.330959 lmp.py:376]   Expert  4 |    488 | GPU
DEBUG 01-05 12:51:19.330748.330748 lmp.py:376]   Expert  0 |    532 | GPU
DEBUG 01-05 12:51:19.330060.330060 lmp.py:376]   Expert 33 |    543 | GPU
DEBUG 01-05 12:51:19.330286.330286 lmp.py:376]   Expert 58 |    574 | GPU
DEBUG 01-05 12:51:19.330552.330552 lmp.py:376]   Expert  1 |    934 | GPU
DEBUG 01-05 12:51:19.330771.330771 lmp.py:376]   Expert 11 |   1194 | GPU
DEBUG 01-05 12:51:19.330036.330036 lmp.py:377] 
DEBUG 01-05 12:51:19.330036.330036 lmp.py:377]   CPU total tokens: 1884 (15.3%)
DEBUG 01-05 12:51:19.330964.330964 lmp.py:378]   GPU total tokens: 10404 (84.7%)
DEBUG 01-05 12:51:19.330852.330852 cuda_h.py:19] end experts_map_get cost 0.0016484260559082031 seconds
DEBUG 01-05 12:51:19.330018.330018 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.330378.330378 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.330383.330383 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.331862.331862 cuda_h.py:19] end allocate_cuda_memory cost 0.0002446174621582031 seconds
DEBUG 01-05 12:51:19.331712.331712 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.331164.331164 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.331888.331888 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.331259.331259 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1076e7ab-7e9b-4c3c-a34c-d113a59976e1
DEBUG 01-05 12:51:19.331239.331239 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.331909.331909 client.py:127] Model loaded
DEBUG 01-05 12:51:19.331189.331189 cuda_h.py:19] end sllm_worker_task cost 0.012207746505737305 seconds
INFO 01-05 12:51:19.333970.333970 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1076e7ab-7e9b-4c3c-a34c-d113a59976e1
DEBUG 01-05 12:51:19.333158.333158 cuda_h.py:19] end load_into_gpu_async cost 0.0021686553955078125 seconds
DEBUG 01-05 12:51:19.333418.333418 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.333137.333137 cuda_h.py:19] end restore_tensors2 cost 0.000286102294921875 seconds
DEBUG 01-05 12:51:19.333258.333258 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031137466430664062 seconds
DEBUG 01-05 12:51:19.336421.336421 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005851268768310547 seconds
DEBUG 01-05 12:51:19.336065.336065 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.336790.336790 lmp.py:423] 
DEBUG 01-05 12:51:19.336790.336790 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.336409.336409 cuda_h.py:19] end cpu_experts_submit cost 0.00012564659118652344 seconds
DEBUG 01-05 12:51:19.336456.336456 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.346109.346109 mlpmodule.py:704] group tensors cost 0.009461164474487305 s
DEBUG 01-05 12:51:19.348685.348685 mlpmodule.py:742] pad cost 0.001440286636352539 s
DEBUG 01-05 12:51:19.348476.348476 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-05 12:51:19.348657.348657 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-05 12:51:19.357928.357928 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.357251.357251 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.357288.357288 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 12:51:19.357194.357194 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.374443.374443 mlpmodule.py:793] group einsum cost 0.025579214096069336 s
DEBUG 01-05 12:51:19.375636.375636 mlpmodule.py:801] cpy2cputensor cost 0.0005977153778076172 s
DEBUG 01-05 12:51:19.379550.379550 cuda_h.py:19] end wait_cetm_experts cost 0.04288792610168457 seconds
DEBUG 01-05 12:51:19.379831.379831 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.380894.380894 cuda_h.py:19] end gpu_sexperts cost 0.0004591941833496094 seconds
DEBUG 01-05 12:51:19.380070.380070 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.380688.380688 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-05 12:51:19.380775.380775 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.380008.380008 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1076e7ab-7e9b-4c3c-a34c-d113a59976e1
INFO 01-05 12:51:19.385088.385088 client.py:127] Model loaded
DEBUG 01-05 12:51:19.385567.385567 cuda_h.py:19] end wait_experts cost 0.005221128463745117 seconds
DEBUG 01-05 12:51:19.385369.385369 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.385887.385887 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.386539.386539 mlpmodule.py:531] gpu group tensors cost 0.0006160736083984375 s
DEBUG 01-05 12:51:19.388664.388664 mlpmodule.py:564] gpu pad cost 0.001672983169555664 s
DEBUG 01-05 12:51:19.388737.388737 mlpmodule.py:582] gpu group einsum cost 0.0005297660827636719 s
DEBUG 01-05 12:51:19.391376.391376 mlpmodule.py:611] gpu experts func einsum cost 0.00604248046875 s
DEBUG 01-05 12:51:19.392929.392929 cuda_h.py:19] end gpu_experts cost 0.00621342658996582 seconds
DEBUG 01-05 12:51:19.392607.392607 cuda_h.py:19] end layer_moe_generate_10 cost 0.06395554542541504 seconds
DEBUG 01-05 12:51:19.392235.392235 lmp.py:217] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 12:51:19.392997.392997 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 12:51:19.392501.392501 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 12:51:19.392974.392974 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 12:51:19.392393.392393 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.24249267578125e-05 seconds
DEBUG 01-05 12:51:19.392547.392547 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 8.225440979003906e-05 seconds
DEBUG 01-05 12:51:19.392905.392905 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.392398.392398 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.392116.392116 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.392329.392329 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.393579.393579 cuda_h.py:19] end allocate_cuda_memory cost 0.00028967857360839844 seconds
DEBUG 01-05 12:51:19.393190.393190 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.393853.393853 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.393007.393007 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.393803.393803 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0cc02578-bb27-4413-a2b9-119d62b46662
DEBUG 01-05 12:51:19.393580.393580 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.393214.393214 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.394847.394847 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0cc02578-bb27-4413-a2b9-119d62b46662
DEBUG 01-05 12:51:19.394398.394398 cuda_h.py:19] end load_into_gpu_async cost 0.001628875732421875 seconds
DEBUG 01-05 12:51:19.394194.394194 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.394885.394885 cuda_h.py:19] end restore_tensors2 cost 6.29425048828125e-05 seconds
DEBUG 01-05 12:51:19.394734.394734 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002214670181274414 seconds
INFO 01-05 12:51:19.395327.395327 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0cc02578-bb27-4413-a2b9-119d62b46662
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.397809.397809 cuda_h.py:19] end self_attn cost 0.0034646987915039062 seconds
DEBUG 01-05 12:51:19.397825.397825 cuda_h.py:19] end iln_self_attn_paln cost 0.004897356033325195 seconds
DEBUG 01-05 12:51:19.397046.397046 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 12:51:19.397332.397332 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.398182.398182 cuda_h.py:19] end gate cost 0.0006277561187744141 seconds
DEBUG 01-05 12:51:19.398627.398627 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.398875.398875 lmp.py:365] 
DEBUG 01-05 12:51:19.398875.398875 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.398200.398200 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.398135.398135 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.398208.398208 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.398136.398136 lmp.py:369] 
DEBUG 01-05 12:51:19.398136.398136 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.398064.398064 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.398237.398237 lmp.py:376]   Expert 35 |      6 | CPU
DEBUG 01-05 12:51:19.398164.398164 lmp.py:376]   Expert 39 |     12 | CPU
DEBUG 01-05 12:51:19.398615.398615 lmp.py:376]   Expert 59 |     12 | CPU
DEBUG 01-05 12:51:19.398066.398066 lmp.py:376]   Expert 16 |     19 | CPU
DEBUG 01-05 12:51:19.398802.398802 lmp.py:376]   Expert 19 |     21 | CPU
DEBUG 01-05 12:51:19.398014.398014 lmp.py:376]   Expert  5 |     27 | CPU
DEBUG 01-05 12:51:19.398750.398750 lmp.py:376]   Expert 41 |     36 | CPU
DEBUG 01-05 12:51:19.398724.398724 lmp.py:376]   Expert 38 |     38 | CPU
DEBUG 01-05 12:51:19.398652.398652 lmp.py:376]   Expert  6 |     39 | CPU
DEBUG 01-05 12:51:19.398864.398864 lmp.py:376]   Expert 49 |     42 | CPU
DEBUG 01-05 12:51:19.398554.398554 lmp.py:376]   Expert 23 |     43 | CPU
DEBUG 01-05 12:51:19.398766.398766 lmp.py:376]   Expert 17 |     51 | CPU
DEBUG 01-05 12:51:19.398217.398217 lmp.py:376]   Expert  3 |     52 | CPU
DEBUG 01-05 12:51:19.398191.398191 lmp.py:376]   Expert 46 |     54 | CPU
DEBUG 01-05 12:51:19.398927.398927 lmp.py:376]   Expert  8 |     55 | CPU
DEBUG 01-05 12:51:19.398424.398424 lmp.py:376]   Expert 27 |     55 | CPU
DEBUG 01-05 12:51:19.398782.398782 lmp.py:376]   Expert 15 |     56 | CPU
DEBUG 01-05 12:51:19.398140.398140 lmp.py:376]   Expert  7 |     57 | CPU
DEBUG 01-05 12:51:19.398637.398637 lmp.py:376]   Expert  0 |     66 | CPU
DEBUG 01-05 12:51:19.399611.399611 lmp.py:376]   Expert 48 |     67 | CPU
DEBUG 01-05 12:51:19.399870.399870 lmp.py:376]   Expert 63 |     68 | CPU
DEBUG 01-05 12:51:19.399606.399606 lmp.py:376]   Expert 32 |     71 | CPU
DEBUG 01-05 12:51:19.399341.399341 lmp.py:376]   Expert 20 |     73 | CPU
DEBUG 01-05 12:51:19.399461.399461 lmp.py:376]   Expert 60 |     77 | CPU
DEBUG 01-05 12:51:19.399866.399866 lmp.py:376]   Expert 57 |     80 | CPU
DEBUG 01-05 12:51:19.399317.399317 lmp.py:376]   Expert 25 |     88 | CPU
DEBUG 01-05 12:51:19.399768.399768 lmp.py:376]   Expert 36 |     88 | CPU
DEBUG 01-05 12:51:19.399218.399218 lmp.py:376]   Expert 10 |     89 | CPU
DEBUG 01-05 12:51:19.399669.399669 lmp.py:376]   Expert  4 |     95 | CPU
DEBUG 01-05 12:51:19.399643.399643 lmp.py:376]   Expert 52 |    110 | CPU
DEBUG 01-05 12:51:19.399617.399617 lmp.py:376]   Expert 40 |    111 | CPU
DEBUG 01-05 12:51:19.399592.399592 lmp.py:376]   Expert 62 |    111 | CPU
DEBUG 01-05 12:51:19.399804.399804 lmp.py:376]   Expert 43 |    137 | GPU
DEBUG 01-05 12:51:19.399016.399016 lmp.py:376]   Expert 50 |    138 | GPU
DEBUG 01-05 12:51:19.399229.399229 lmp.py:376]   Expert 61 |    138 | GPU
DEBUG 01-05 12:51:19.399918.399918 lmp.py:376]   Expert 51 |    145 | GPU
DEBUG 01-05 12:51:19.399892.399892 lmp.py:376]   Expert 13 |    152 | GPU
DEBUG 01-05 12:51:19.399297.399297 lmp.py:376]   Expert 12 |    164 | GPU
DEBUG 01-05 12:51:19.399225.399225 lmp.py:376]   Expert  1 |    169 | GPU
DEBUG 01-05 12:51:19.399914.399914 lmp.py:376]   Expert 42 |    174 | GPU
DEBUG 01-05 12:51:19.399842.399842 lmp.py:376]   Expert 47 |    184 | GPU
DEBUG 01-05 12:51:19.399531.399531 lmp.py:376]   Expert 18 |    194 | GPU
DEBUG 01-05 12:51:19.399982.399982 lmp.py:376]   Expert 26 |    207 | GPU
DEBUG 01-05 12:51:19.399433.399433 lmp.py:376]   Expert 34 |    241 | GPU
DEBUG 01-05 12:51:19.399407.399407 lmp.py:376]   Expert 29 |    243 | GPU
DEBUG 01-05 12:51:19.399096.399096 lmp.py:376]   Expert 31 |    247 | GPU
DEBUG 01-05 12:51:19.399308.399308 lmp.py:376]   Expert 55 |    252 | GPU
DEBUG 01-05 12:51:19.399282.399282 lmp.py:376]   Expert 56 |    253 | GPU
DEBUG 01-05 12:51:19.399495.399495 lmp.py:376]   Expert 33 |    286 | GPU
DEBUG 01-05 12:51:19.399707.399707 lmp.py:376]   Expert 44 |    291 | GPU
DEBUG 01-05 12:51:19.399874.399874 lmp.py:376]   Expert 45 |    292 | GPU
DEBUG 01-05 12:51:19.399563.399563 lmp.py:376]   Expert  2 |    294 | GPU
DEBUG 01-05 12:51:19.399252.399252 lmp.py:376]   Expert 14 |    304 | GPU
DEBUG 01-05 12:51:19.399418.399418 lmp.py:376]   Expert 28 |    319 | GPU
DEBUG 01-05 12:51:19.399108.399108 lmp.py:376]   Expert 53 |    333 | GPU
DEBUG 01-05 12:51:19.399558.399558 lmp.py:376]   Expert 24 |    377 | GPU
DEBUG 01-05 12:51:19.399294.399294 lmp.py:376]   Expert 54 |    396 | GPU
DEBUG 01-05 12:51:19.399745.399745 lmp.py:376]   Expert  9 |    403 | GPU
DEBUG 01-05 12:51:19.399957.399957 lmp.py:376]   Expert 21 |    420 | GPU
DEBUG 01-05 12:51:19.399170.399170 lmp.py:376]   Expert 37 |    447 | GPU
DEBUG 01-05 12:51:19.399382.399382 lmp.py:376]   Expert 22 |    474 | GPU
DEBUG 01-05 12:51:19.399833.399833 lmp.py:376]   Expert 58 |    543 | GPU
DEBUG 01-05 12:51:19.399807.399807 lmp.py:376]   Expert 11 |    651 | GPU
DEBUG 01-05 12:51:19.399735.399735 lmp.py:376]   Expert 30 |   1551 | GPU
DEBUG 01-05 12:51:19.399378.399378 lmp.py:377] 
DEBUG 01-05 12:51:19.399378.399378 lmp.py:377]   CPU total tokens: 1869 (15.2%)
DEBUG 01-05 12:51:19.399736.399736 lmp.py:378]   GPU total tokens: 10419 (84.8%)
DEBUG 01-05 12:51:19.399909.399909 cuda_h.py:19] end experts_map_get cost 0.0014793872833251953 seconds
DEBUG 01-05 12:51:19.399267.399267 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.399521.399521 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.399512.399512 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.401631.401631 cuda_h.py:19] end allocate_cuda_memory cost 0.001949310302734375 seconds
DEBUG 01-05 12:51:19.402508.402508 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.402648.402648 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.402650.402650 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.402491.402491 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f026bd92-ab3d-442f-a623-f3cdbfd1f448
DEBUG 01-05 12:51:19.402213.402213 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.402309.402309 mlpmodule.py:662]  experts func einsum cost 0.06548738479614258 s
INFO 01-05 12:51:19.402282.402282 client.py:127] Model loaded
DEBUG 01-05 12:51:19.402649.402649 cuda_h.py:19] end sllm_worker_task cost 0.009981870651245117 seconds
INFO 01-05 12:51:19.403274.403274 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f026bd92-ab3d-442f-a623-f3cdbfd1f448
DEBUG 01-05 12:51:19.403547.403547 cuda_h.py:19] end load_into_gpu_async cost 0.0013277530670166016 seconds
DEBUG 01-05 12:51:19.403773.403773 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.403181.403181 cuda_h.py:19] end restore_tensors2 cost 0.0002751350402832031 seconds
DEBUG 01-05 12:51:19.403573.403573 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039141178131103516 seconds
DEBUG 01-05 12:51:19.406529.406529 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006590843200683594 seconds
DEBUG 01-05 12:51:19.406266.406266 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.406249.406249 lmp.py:423] 
DEBUG 01-05 12:51:19.406249.406249 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.406946.406946 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-05 12:51:19.406503.406503 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.415303.415303 mlpmodule.py:704] group tensors cost 0.008569002151489258 s
DEBUG 01-05 12:51:19.417470.417470 mlpmodule.py:742] pad cost 0.0014653205871582031 s
DEBUG 01-05 12:51:19.417712.417712 mlpmodule.py:748] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-05 12:51:19.417178.417178 mlpmodule.py:753] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-05 12:51:19.426450.426450 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.426482.426482 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.426426.426426 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 12:51:19.426503.426503 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.442304.442304 mlpmodule.py:793] group einsum cost 0.02467203140258789 s
DEBUG 01-05 12:51:19.442578.442578 mlpmodule.py:801] cpy2cputensor cost 0.0004794597625732422 s
DEBUG 01-05 12:51:19.447992.447992 cuda_h.py:19] end wait_cetm_experts cost 0.0410456657409668 seconds
DEBUG 01-05 12:51:19.447393.447393 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.448212.448212 cuda_h.py:19] end gpu_sexperts cost 0.0004570484161376953 seconds
DEBUG 01-05 12:51:19.448725.448725 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.448225.448225 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 12:51:19.448134.448134 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.448512.448512 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f026bd92-ab3d-442f-a623-f3cdbfd1f448
INFO 01-05 12:51:19.455806.455806 client.py:127] Model loaded
DEBUG 01-05 12:51:19.455373.455373 cuda_h.py:19] end wait_experts cost 0.007305622100830078 seconds
DEBUG 01-05 12:51:19.456202.456202 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.456786.456786 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.456433.456433 mlpmodule.py:531] gpu group tensors cost 0.0006322860717773438 s
DEBUG 01-05 12:51:19.463831.463831 mlpmodule.py:564] gpu pad cost 0.007039546966552734 s
DEBUG 01-05 12:51:19.469770.469770 mlpmodule.py:662]  experts func einsum cost 0.062470436096191406 s
DEBUG 01-05 12:51:19.469358.469358 mlpmodule.py:582] gpu group einsum cost 0.00557708740234375 s
DEBUG 01-05 12:51:19.472709.472709 mlpmodule.py:611] gpu experts func einsum cost 0.016179323196411133 s
DEBUG 01-05 12:51:19.472898.472898 cuda_h.py:19] end gpu_experts cost 0.016376733779907227 seconds
DEBUG 01-05 12:51:19.472344.472344 cuda_h.py:19] end layer_moe_generate_11 cost 0.07494354248046875 seconds
DEBUG 01-05 12:51:19.472640.472640 lmp.py:217] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 12:51:19.472688.472688 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 12:51:19.472954.472954 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 12:51:19.472041.472041 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 12:51:19.472592.472592 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.7894973754882812e-05 seconds
DEBUG 01-05 12:51:19.472911.472911 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.817413330078125e-05 seconds
DEBUG 01-05 12:51:19.472554.472554 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.472668.472668 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.473599.473599 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.473502.473502 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.473358.473358 cuda_h.py:19] end allocate_cuda_memory cost 0.00020051002502441406 seconds
DEBUG 01-05 12:51:19.473606.473606 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.473502.473502 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.473530.473530 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.473671.473671 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2870d1d6-6778-4b63-8ca7-f880dd71d99a
DEBUG 01-05 12:51:19.473906.473906 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.473854.473854 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.475748.475748 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2870d1d6-6778-4b63-8ca7-f880dd71d99a
DEBUG 01-05 12:51:19.475367.475367 cuda_h.py:19] end load_into_gpu_async cost 0.001699209213256836 seconds
DEBUG 01-05 12:51:19.475792.475792 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.475193.475193 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-05 12:51:19.475108.475108 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002295970916748047 seconds
INFO 01-05 12:51:19.475220.475220 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2870d1d6-6778-4b63-8ca7-f880dd71d99a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.477858.477858 cuda_h.py:19] end self_attn cost 0.0034165382385253906 seconds
DEBUG 01-05 12:51:19.477868.477868 cuda_h.py:19] end iln_self_attn_paln cost 0.004801273345947266 seconds
DEBUG 01-05 12:51:19.477373.477373 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 12:51:19.477898.477898 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.478833.478833 cuda_h.py:19] end gate cost 0.0006208419799804688 seconds
DEBUG 01-05 12:51:19.478517.478517 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.478474.478474 lmp.py:365] 
DEBUG 01-05 12:51:19.478474.478474 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.478991.478991 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.478403.478403 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.478999.478999 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.478450.478450 lmp.py:369] 
DEBUG 01-05 12:51:19.478450.478450 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.478139.478139 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.478312.478312 lmp.py:376]   Expert 22 |      3 | CPU
DEBUG 01-05 12:51:19.478240.478240 lmp.py:376]   Expert 51 |      4 | CPU
DEBUG 01-05 12:51:19.478929.478929 lmp.py:376]   Expert  4 |     15 | CPU
DEBUG 01-05 12:51:19.478903.478903 lmp.py:376]   Expert 44 |     15 | CPU
DEBUG 01-05 12:51:19.478116.478116 lmp.py:376]   Expert 34 |     17 | CPU
DEBUG 01-05 12:51:19.478851.478851 lmp.py:376]   Expert  0 |     20 | CPU
DEBUG 01-05 12:51:19.478302.478302 lmp.py:376]   Expert 12 |     20 | CPU
DEBUG 01-05 12:51:19.478515.478515 lmp.py:376]   Expert 11 |     23 | CPU
DEBUG 01-05 12:51:19.479204.479204 lmp.py:376]   Expert 13 |     27 | CPU
DEBUG 01-05 12:51:19.479940.479940 lmp.py:376]   Expert 16 |     27 | CPU
DEBUG 01-05 12:51:19.479437.479437 lmp.py:376]   Expert 29 |     27 | CPU
DEBUG 01-05 12:51:19.479173.479173 lmp.py:376]   Expert 27 |     36 | CPU
DEBUG 01-05 12:51:19.479908.479908 lmp.py:376]   Expert 45 |     39 | CPU
DEBUG 01-05 12:51:19.479167.479167 lmp.py:376]   Expert  8 |     42 | CPU
DEBUG 01-05 12:51:19.479903.479903 lmp.py:376]   Expert 32 |     46 | CPU
DEBUG 01-05 12:51:19.479161.479161 lmp.py:376]   Expert 63 |     56 | CPU
DEBUG 01-05 12:51:19.479420.479420 lmp.py:376]   Expert 37 |     58 | CPU
DEBUG 01-05 12:51:19.479156.479156 lmp.py:376]   Expert 23 |     61 | CPU
DEBUG 01-05 12:51:19.479415.479415 lmp.py:376]   Expert  2 |     64 | CPU
DEBUG 01-05 12:51:19.479912.479912 lmp.py:376]   Expert 41 |     66 | CPU
DEBUG 01-05 12:51:19.479171.479171 lmp.py:376]   Expert 47 |     73 | CPU
DEBUG 01-05 12:51:19.479621.479621 lmp.py:376]   Expert 49 |     75 | CPU
DEBUG 01-05 12:51:19.479834.479834 lmp.py:376]   Expert 38 |     88 | CPU
DEBUG 01-05 12:51:19.479046.479046 lmp.py:376]   Expert 55 |     90 | CPU
DEBUG 01-05 12:51:19.479974.479974 lmp.py:376]   Expert  3 |     92 | CPU
DEBUG 01-05 12:51:19.479471.479471 lmp.py:376]   Expert 30 |     93 | CPU
DEBUG 01-05 12:51:19.479730.479730 lmp.py:376]   Expert 62 |     95 | CPU
DEBUG 01-05 12:51:19.479989.479989 lmp.py:376]   Expert 31 |    111 | CPU
DEBUG 01-05 12:51:19.479393.479393 lmp.py:376]   Expert  7 |    116 | CPU
DEBUG 01-05 12:51:19.479083.479083 lmp.py:376]   Expert 35 |    125 | CPU
DEBUG 01-05 12:51:19.479772.479772 lmp.py:376]   Expert 46 |    135 | CPU
DEBUG 01-05 12:51:19.479223.479223 lmp.py:376]   Expert 61 |    138 | CPU
DEBUG 01-05 12:51:19.479912.479912 lmp.py:376]   Expert 14 |    143 | GPU
DEBUG 01-05 12:51:19.479555.479555 lmp.py:376]   Expert 42 |    144 | GPU
DEBUG 01-05 12:51:19.479198.479198 lmp.py:376]   Expert 53 |    147 | GPU
DEBUG 01-05 12:51:19.479318.479318 lmp.py:376]   Expert  5 |    153 | GPU
DEBUG 01-05 12:51:19.479723.479723 lmp.py:376]   Expert 58 |    153 | GPU
DEBUG 01-05 12:51:19.479127.479127 lmp.py:376]   Expert 26 |    156 | GPU
DEBUG 01-05 12:51:19.479055.479055 lmp.py:376]   Expert 57 |    166 | GPU
DEBUG 01-05 12:51:19.479506.479506 lmp.py:376]   Expert 39 |    177 | GPU
DEBUG 01-05 12:51:19.479718.479718 lmp.py:376]   Expert 21 |    180 | GPU
DEBUG 01-05 12:51:19.479407.479407 lmp.py:376]   Expert 60 |    181 | GPU
DEBUG 01-05 12:51:19.479097.479097 lmp.py:376]   Expert 59 |    192 | GPU
DEBUG 01-05 12:51:19.479786.479786 lmp.py:376]   Expert 24 |    193 | GPU
DEBUG 01-05 12:51:19.479999.479999 lmp.py:376]   Expert 18 |    206 | GPU
DEBUG 01-05 12:51:19.479449.479449 lmp.py:376]   Expert 28 |    219 | GPU
DEBUG 01-05 12:51:19.479139.479139 lmp.py:376]   Expert  6 |    222 | GPU
DEBUG 01-05 12:51:19.479543.479543 lmp.py:376]   Expert 19 |    237 | GPU
DEBUG 01-05 12:51:19.479948.479948 lmp.py:376]   Expert 17 |    244 | GPU
DEBUG 01-05 12:51:19.479352.479352 lmp.py:376]   Expert 43 |    260 | GPU
DEBUG 01-05 12:51:19.479909.479909 lmp.py:376]   Expert 54 |    261 | GPU
DEBUG 01-05 12:51:19.479122.479122 lmp.py:376]   Expert 20 |    272 | GPU
DEBUG 01-05 12:51:19.479619.479619 lmp.py:376]   Expert 52 |    280 | GPU
DEBUG 01-05 12:51:19.479116.479116 lmp.py:376]   Expert 50 |    298 | GPU
DEBUG 01-05 12:51:19.479375.479375 lmp.py:376]   Expert 25 |    307 | GPU
DEBUG 01-05 12:51:19.479396.479396 lmp.py:376]   Expert 48 |    312 | GPU
DEBUG 01-05 12:51:19.479131.479131 lmp.py:376]   Expert 40 |    337 | GPU
DEBUG 01-05 12:51:19.479390.479390 lmp.py:376]   Expert  1 |    381 | GPU
DEBUG 01-05 12:51:19.479887.479887 lmp.py:376]   Expert 36 |    393 | GPU
DEBUG 01-05 12:51:19.479384.479384 lmp.py:376]   Expert  9 |    477 | GPU
DEBUG 01-05 12:51:19.479027.479027 lmp.py:376]   Expert 15 |    660 | GPU
DEBUG 01-05 12:51:19.479717.479717 lmp.py:376]   Expert 56 |    729 | GPU
DEBUG 01-05 12:51:19.479168.479168 lmp.py:376]   Expert 33 |    781 | GPU
DEBUG 01-05 12:51:19.479095.479095 lmp.py:376]   Expert 10 |   1530 | GPU
DEBUG 01-05 12:51:19.479023.479023 lmp.py:377] 
DEBUG 01-05 12:51:19.479023.479023 lmp.py:377]   CPU total tokens: 1897 (15.4%)
DEBUG 01-05 12:51:19.479235.479235 lmp.py:378]   GPU total tokens: 10391 (84.6%)
DEBUG 01-05 12:51:19.479978.479978 cuda_h.py:19] end experts_map_get cost 0.0014722347259521484 seconds
DEBUG 01-05 12:51:19.479906.479906 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.480251.480251 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.480335.480335 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.480391.480391 cuda_h.py:19] end allocate_cuda_memory cost 0.0002548694610595703 seconds
DEBUG 01-05 12:51:19.480519.480519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.480606.480606 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.480607.480607 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.480211.480211 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ef68db45-94e2-4d5b-a493-0c4185339194
DEBUG 01-05 12:51:19.480256.480256 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.483238.483238 client.py:127] Model loaded
DEBUG 01-05 12:51:19.483929.483929 cuda_h.py:19] end sllm_worker_task cost 0.010251760482788086 seconds
INFO 01-05 12:51:19.484312.484312 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ef68db45-94e2-4d5b-a493-0c4185339194
DEBUG 01-05 12:51:19.484754.484754 cuda_h.py:19] end load_into_gpu_async cost 0.004408121109008789 seconds
DEBUG 01-05 12:51:19.485909.485909 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.485860.485860 cuda_h.py:19] end restore_tensors2 cost 0.0004265308380126953 seconds
DEBUG 01-05 12:51:19.485775.485775 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005525350570678711 seconds
DEBUG 01-05 12:51:19.488178.488178 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008110523223876953 seconds
DEBUG 01-05 12:51:19.488007.488007 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.488871.488871 lmp.py:423] 
DEBUG 01-05 12:51:19.488871.488871 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.488422.488422 cuda_h.py:19] end cpu_experts_submit cost 0.000102996826171875 seconds
DEBUG 01-05 12:51:19.488046.488046 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.498335.498335 mlpmodule.py:704] group tensors cost 0.010451793670654297 s
DEBUG 01-05 12:51:19.500879.500879 mlpmodule.py:742] pad cost 0.0014166831970214844 s
DEBUG 01-05 12:51:19.501909.501909 mlpmodule.py:748] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-05 12:51:19.501944.501944 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-05 12:51:19.509107.509107 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.510139.510139 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.510467.510467 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 12:51:19.510491.510491 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.526851.526851 mlpmodule.py:793] group einsum cost 0.025420188903808594 s
DEBUG 01-05 12:51:19.527751.527751 mlpmodule.py:801] cpy2cputensor cost 0.0005717277526855469 s
DEBUG 01-05 12:51:19.532254.532254 cuda_h.py:19] end wait_cetm_experts cost 0.04373931884765625 seconds
DEBUG 01-05 12:51:19.532968.532968 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.532410.532410 cuda_h.py:19] end gpu_sexperts cost 0.00047278404235839844 seconds
DEBUG 01-05 12:51:19.532353.532353 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.532992.532992 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:19.533523.533523 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.533186.533186 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ef68db45-94e2-4d5b-a493-0c4185339194
INFO 01-05 12:51:19.537694.537694 client.py:127] Model loaded
DEBUG 01-05 12:51:19.537658.537658 cuda_h.py:19] end wait_experts cost 0.0043833255767822266 seconds
DEBUG 01-05 12:51:19.537534.537534 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.537542.537542 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.538909.538909 mlpmodule.py:531] gpu group tensors cost 0.0006108283996582031 s
DEBUG 01-05 12:51:19.540273.540273 mlpmodule.py:564] gpu pad cost 0.0016808509826660156 s
DEBUG 01-05 12:51:19.540599.540599 mlpmodule.py:582] gpu group einsum cost 0.0005214214324951172 s
DEBUG 01-05 12:51:19.543270.543270 mlpmodule.py:611] gpu experts func einsum cost 0.006247997283935547 s
DEBUG 01-05 12:51:19.543591.543591 cuda_h.py:19] end gpu_experts cost 0.0064296722412109375 seconds
DEBUG 01-05 12:51:19.544084.544084 cuda_h.py:19] end layer_moe_generate_12 cost 0.06629395484924316 seconds
DEBUG 01-05 12:51:19.544904.544904 lmp.py:217] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 12:51:19.544905.544905 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 12:51:19.544124.544124 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 12:51:19.544642.544642 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 12:51:19.544955.544955 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.8848648071289062e-05 seconds
DEBUG 01-05 12:51:19.544989.544989 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.8650970458984375e-05 seconds
DEBUG 01-05 12:51:19.544599.544599 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.544376.544376 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.544962.544962 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.544460.544460 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.551244.551244 cuda_h.py:19] end allocate_cuda_memory cost 0.006369352340698242 seconds
DEBUG 01-05 12:51:19.551235.551235 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.551667.551667 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.551105.551105 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.551331.551331 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 60bf34bb-5cd6-4a6e-af3a-7c4892175bbb
DEBUG 01-05 12:51:19.551778.551778 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.551377.551377 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.552271.552271 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 60bf34bb-5cd6-4a6e-af3a-7c4892175bbb
DEBUG 01-05 12:51:19.552206.552206 cuda_h.py:19] end load_into_gpu_async cost 0.0014863014221191406 seconds
DEBUG 01-05 12:51:19.552909.552909 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.552369.552369 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-05 12:51:19.553410.553410 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008409500122070312 seconds
INFO 01-05 12:51:19.553037.553037 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 60bf34bb-5cd6-4a6e-af3a-7c4892175bbb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.555774.555774 cuda_h.py:19] end self_attn cost 0.0032804012298583984 seconds
DEBUG 01-05 12:51:19.555188.555188 cuda_h.py:19] end iln_self_attn_paln cost 0.011044025421142578 seconds
DEBUG 01-05 12:51:19.555078.555078 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 12:51:19.555032.555032 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.556850.556850 cuda_h.py:19] end gate cost 0.000637054443359375 seconds
DEBUG 01-05 12:51:19.556487.556487 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.556040.556040 lmp.py:365] 
DEBUG 01-05 12:51:19.556040.556040 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.556988.556988 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.556353.556353 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.556665.556665 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.556831.556831 lmp.py:369] 
DEBUG 01-05 12:51:19.556831.556831 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.556998.556998 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.556839.556839 lmp.py:376]   Expert  6 |      1 | CPU
DEBUG 01-05 12:51:19.556482.556482 lmp.py:376]   Expert 53 |      1 | CPU
DEBUG 01-05 12:51:19.556648.556648 lmp.py:376]   Expert 50 |     14 | CPU
DEBUG 01-05 12:51:19.556861.556861 lmp.py:376]   Expert  0 |     29 | CPU
DEBUG 01-05 12:51:19.556073.556073 lmp.py:376]   Expert  2 |     31 | CPU
DEBUG 01-05 12:51:19.556524.556524 lmp.py:376]   Expert 12 |     31 | CPU
DEBUG 01-05 12:51:19.556975.556975 lmp.py:376]   Expert 26 |     32 | CPU
DEBUG 01-05 12:51:19.556949.556949 lmp.py:376]   Expert 31 |     33 | CPU
DEBUG 01-05 12:51:19.556400.556400 lmp.py:376]   Expert 40 |     45 | CPU
DEBUG 01-05 12:51:19.556520.556520 lmp.py:376]   Expert 32 |     48 | CPU
DEBUG 01-05 12:51:19.556209.556209 lmp.py:376]   Expert 34 |     48 | CPU
DEBUG 01-05 12:51:19.556137.556137 lmp.py:376]   Expert 16 |     49 | CPU
DEBUG 01-05 12:51:19.556065.556065 lmp.py:376]   Expert  8 |     50 | CPU
DEBUG 01-05 12:51:19.556754.556754 lmp.py:376]   Expert 19 |     52 | CPU
DEBUG 01-05 12:51:19.556966.556966 lmp.py:376]   Expert 20 |     63 | CPU
DEBUG 01-05 12:51:19.556179.556179 lmp.py:376]   Expert  9 |     68 | CPU
DEBUG 01-05 12:51:19.556630.556630 lmp.py:376]   Expert 13 |     68 | CPU
DEBUG 01-05 12:51:19.557365.557365 lmp.py:376]   Expert 28 |     68 | CPU
DEBUG 01-05 12:51:19.557339.557339 lmp.py:376]   Expert 30 |     76 | CPU
DEBUG 01-05 12:51:19.557313.557313 lmp.py:376]   Expert 61 |     76 | CPU
DEBUG 01-05 12:51:19.557817.557817 lmp.py:376]   Expert 45 |     77 | CPU
DEBUG 01-05 12:51:19.557268.557268 lmp.py:376]   Expert 57 |     82 | CPU
DEBUG 01-05 12:51:19.557719.557719 lmp.py:376]   Expert 25 |     85 | CPU
DEBUG 01-05 12:51:19.557170.557170 lmp.py:376]   Expert 63 |     85 | CPU
DEBUG 01-05 12:51:19.557098.557098 lmp.py:376]   Expert  5 |     90 | CPU
DEBUG 01-05 12:51:19.557787.557787 lmp.py:376]   Expert 11 |     91 | CPU
DEBUG 01-05 12:51:19.557953.557953 lmp.py:376]   Expert 24 |     91 | CPU
DEBUG 01-05 12:51:19.557166.557166 lmp.py:376]   Expert 35 |     91 | CPU
DEBUG 01-05 12:51:19.557378.557378 lmp.py:376]   Expert 58 |    110 | CPU
DEBUG 01-05 12:51:19.557114.557114 lmp.py:376]   Expert 48 |    111 | CPU
DEBUG 01-05 12:51:19.557088.557088 lmp.py:376]   Expert 60 |    116 | CPU
DEBUG 01-05 12:51:19.557824.557824 lmp.py:376]   Expert 52 |    136 | CPU
DEBUG 01-05 12:51:19.557036.557036 lmp.py:376]   Expert 49 |    145 | GPU
DEBUG 01-05 12:51:19.557248.557248 lmp.py:376]   Expert  3 |    153 | GPU
DEBUG 01-05 12:51:19.557222.557222 lmp.py:376]   Expert 62 |    156 | GPU
DEBUG 01-05 12:51:19.557197.557197 lmp.py:376]   Expert 42 |    162 | GPU
DEBUG 01-05 12:51:19.557171.557171 lmp.py:376]   Expert 36 |    178 | GPU
DEBUG 01-05 12:51:19.557621.557621 lmp.py:376]   Expert 37 |    183 | GPU
DEBUG 01-05 12:51:19.557311.557311 lmp.py:376]   Expert 54 |    188 | GPU
DEBUG 01-05 12:51:19.557000.557000 lmp.py:376]   Expert  4 |    189 | GPU
DEBUG 01-05 12:51:19.557689.557689 lmp.py:376]   Expert 46 |    196 | GPU
DEBUG 01-05 12:51:19.557855.557855 lmp.py:376]   Expert 44 |    197 | GPU
DEBUG 01-05 12:51:19.557591.557591 lmp.py:376]   Expert 27 |    204 | GPU
DEBUG 01-05 12:51:19.557804.557804 lmp.py:376]   Expert  1 |    214 | GPU
DEBUG 01-05 12:51:19.557539.557539 lmp.py:376]   Expert 51 |    221 | GPU
DEBUG 01-05 12:51:19.557752.557752 lmp.py:376]   Expert 43 |    223 | GPU
DEBUG 01-05 12:51:19.557249.557249 lmp.py:376]   Expert 33 |    240 | GPU
DEBUG 01-05 12:51:19.557461.557461 lmp.py:376]   Expert 15 |    242 | GPU
DEBUG 01-05 12:51:19.557435.557435 lmp.py:376]   Expert 59 |    244 | GPU
DEBUG 01-05 12:51:19.557933.557933 lmp.py:376]   Expert 17 |    299 | GPU
DEBUG 01-05 12:51:19.557907.557907 lmp.py:376]   Expert 39 |    329 | GPU
DEBUG 01-05 12:51:19.557371.557371 lmp.py:376]   Expert 22 |    342 | GPU
DEBUG 01-05 12:51:19.557345.557345 lmp.py:376]   Expert 29 |    351 | GPU
DEBUG 01-05 12:51:19.557558.557558 lmp.py:376]   Expert 47 |    359 | GPU
DEBUG 01-05 12:51:19.557532.557532 lmp.py:376]   Expert  7 |    374 | GPU
DEBUG 01-05 12:51:19.557506.557506 lmp.py:376]   Expert 14 |    412 | GPU
DEBUG 01-05 12:51:19.557102.557102 lmp.py:376]   Expert 10 |    424 | GPU
DEBUG 01-05 12:51:19.557838.557838 lmp.py:376]   Expert 55 |    440 | GPU
DEBUG 01-05 12:51:19.557858.557858 lmp.py:376]   Expert 38 |    446 | GPU
DEBUG 01-05 12:51:19.557356.557356 lmp.py:376]   Expert 21 |    474 | GPU
DEBUG 01-05 12:51:19.557376.557376 lmp.py:376]   Expert 56 |    534 | GPU
DEBUG 01-05 12:51:19.557396.557396 lmp.py:376]   Expert 41 |    598 | GPU
DEBUG 01-05 12:51:19.557893.557893 lmp.py:376]   Expert 18 |    731 | GPU
DEBUG 01-05 12:51:19.557868.557868 lmp.py:376]   Expert 23 |    792 | GPU
DEBUG 01-05 12:51:19.557795.557795 lmp.py:377] 
DEBUG 01-05 12:51:19.557795.557795 lmp.py:377]   CPU total tokens: 2048 (16.7%)
DEBUG 01-05 12:51:19.557961.557961 lmp.py:378]   GPU total tokens: 10240 (83.3%)
DEBUG 01-05 12:51:19.557373.557373 cuda_h.py:19] end experts_map_get cost 0.0015027523040771484 seconds
DEBUG 01-05 12:51:19.557300.557300 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.557408.557408 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.558306.558306 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.560816.560816 cuda_h.py:19] end allocate_cuda_memory cost 0.002730131149291992 seconds
DEBUG 01-05 12:51:19.560474.560474 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.560468.560468 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.560946.560946 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.560788.560788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b711347-26df-4190-a672-e5e2a24c7011
DEBUG 01-05 12:51:19.561748.561748 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.561231.561231 client.py:127] Model loaded
DEBUG 01-05 12:51:19.561499.561499 cuda_h.py:19] end sllm_worker_task cost 0.016829490661621094 seconds
DEBUG 01-05 12:51:19.561131.561131 mlpmodule.py:662]  experts func einsum cost 0.07299184799194336 s
INFO 01-05 12:51:19.562922.562922 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b711347-26df-4190-a672-e5e2a24c7011
DEBUG 01-05 12:51:19.562050.562050 cuda_h.py:19] end load_into_gpu_async cost 0.001936197280883789 seconds
DEBUG 01-05 12:51:19.562296.562296 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.563988.563988 cuda_h.py:19] end restore_tensors2 cost 0.000274658203125 seconds
DEBUG 01-05 12:51:19.563043.563043 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00529170036315918 seconds
DEBUG 01-05 12:51:19.565564.565564 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008028030395507812 seconds
DEBUG 01-05 12:51:19.565969.565969 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.566668.566668 lmp.py:423] 
DEBUG 01-05 12:51:19.566668.566668 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.566034.566034 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-05 12:51:19.566830.566830 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.570396.570396 mlpmodule.py:704] group tensors cost 0.004145622253417969 s
DEBUG 01-05 12:51:19.572503.572503 mlpmodule.py:742] pad cost 0.001360177993774414 s
DEBUG 01-05 12:51:19.572480.572480 mlpmodule.py:748] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-05 12:51:19.572131.572131 mlpmodule.py:753] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-05 12:51:19.580365.580365 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.580576.580576 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.580135.580135 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 12:51:19.581444.581444 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.596820.596820 mlpmodule.py:793] group einsum cost 0.023642301559448242 s
DEBUG 01-05 12:51:19.596939.596939 mlpmodule.py:801] cpy2cputensor cost 0.0005946159362792969 s
DEBUG 01-05 12:51:19.601205.601205 cuda_h.py:19] end wait_cetm_experts cost 0.03548479080200195 seconds
DEBUG 01-05 12:51:19.601162.601162 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.602530.602530 cuda_h.py:19] end gpu_sexperts cost 0.00045990943908691406 seconds
DEBUG 01-05 12:51:19.602375.602375 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.602060.602060 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-05 12:51:19.602922.602922 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.602347.602347 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b711347-26df-4190-a672-e5e2a24c7011
INFO 01-05 12:51:19.615006.615006 client.py:127] Model loaded
DEBUG 01-05 12:51:19.615524.615524 cuda_h.py:19] end wait_experts cost 0.0130157470703125 seconds
DEBUG 01-05 12:51:19.615294.615294 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.615328.615328 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.616699.616699 mlpmodule.py:531] gpu group tensors cost 0.0005168914794921875 s
DEBUG 01-05 12:51:19.617681.617681 mlpmodule.py:564] gpu pad cost 0.0014107227325439453 s
DEBUG 01-05 12:51:19.618720.618720 mlpmodule.py:582] gpu group einsum cost 0.0004899501800537109 s
DEBUG 01-05 12:51:19.621581.621581 mlpmodule.py:611] gpu experts func einsum cost 0.005693912506103516 s
DEBUG 01-05 12:51:19.621041.621041 cuda_h.py:19] end gpu_experts cost 0.005862712860107422 seconds
DEBUG 01-05 12:51:19.621971.621971 cuda_h.py:19] end layer_moe_generate_13 cost 0.06600475311279297 seconds
DEBUG 01-05 12:51:19.621427.621427 lmp.py:217] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 12:51:19.621766.621766 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 12:51:19.621846.621846 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 12:51:19.621178.621178 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 12:51:19.621836.621836 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 12:51:19.621400.621400 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.818771362304688e-05 seconds
DEBUG 01-05 12:51:19.621619.621619 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.622834.622834 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.622174.622174 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.622865.622865 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.628750.628750 cuda_h.py:19] end allocate_cuda_memory cost 0.006021261215209961 seconds
DEBUG 01-05 12:51:19.628104.628104 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.628251.628251 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.628948.628948 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.628558.628558 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9387c47b-be1a-4a28-8326-5ae0fcce66f1
DEBUG 01-05 12:51:19.628481.628481 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.628936.628936 mlpmodule.py:662]  experts func einsum cost 0.06241798400878906 s
DEBUG 01-05 12:51:19.628011.628011 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.629481.629481 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9387c47b-be1a-4a28-8326-5ae0fcce66f1
DEBUG 01-05 12:51:19.629291.629291 cuda_h.py:19] end load_into_gpu_async cost 0.0016067028045654297 seconds
DEBUG 01-05 12:51:19.629100.629100 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.630449.630449 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-05 12:51:19.630676.630676 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008023262023925781 seconds
INFO 01-05 12:51:19.630625.630625 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9387c47b-be1a-4a28-8326-5ae0fcce66f1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.633038.633038 cuda_h.py:19] end self_attn cost 0.004083871841430664 seconds
DEBUG 01-05 12:51:19.633148.633148 cuda_h.py:19] end iln_self_attn_paln cost 0.01141667366027832 seconds
DEBUG 01-05 12:51:19.633097.633097 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 12:51:19.633013.633013 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.634831.634831 cuda_h.py:19] end gate cost 0.0006678104400634766 seconds
DEBUG 01-05 12:51:19.634529.634529 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.634282.634282 lmp.py:365] 
DEBUG 01-05 12:51:19.634282.634282 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.634329.634329 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.634032.634032 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.634066.634066 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.634762.634762 lmp.py:369] 
DEBUG 01-05 12:51:19.634762.634762 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.634935.634935 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.634115.634115 lmp.py:376]   Expert 61 |      3 | CPU
DEBUG 01-05 12:51:19.634573.634573 lmp.py:376]   Expert  7 |      4 | CPU
DEBUG 01-05 12:51:19.634315.634315 lmp.py:376]   Expert 49 |     25 | CPU
DEBUG 01-05 12:51:19.634581.634581 lmp.py:376]   Expert 48 |     28 | CPU
DEBUG 01-05 12:51:19.634131.634131 lmp.py:376]   Expert 59 |     37 | CPU
DEBUG 01-05 12:51:19.634158.634158 lmp.py:376]   Expert 38 |     40 | CPU
DEBUG 01-05 12:51:19.634947.634947 lmp.py:376]   Expert 40 |     40 | CPU
DEBUG 01-05 12:51:19.634736.634736 lmp.py:376]   Expert 50 |     41 | CPU
DEBUG 01-05 12:51:19.634955.634955 lmp.py:376]   Expert 55 |     42 | CPU
DEBUG 01-05 12:51:19.634697.634697 lmp.py:376]   Expert 32 |     45 | CPU
DEBUG 01-05 12:51:19.634440.634440 lmp.py:376]   Expert 17 |     53 | CPU
DEBUG 01-05 12:51:19.635420.635420 lmp.py:376]   Expert 18 |     57 | CPU
DEBUG 01-05 12:51:19.635209.635209 lmp.py:376]   Expert 43 |     62 | CPU
DEBUG 01-05 12:51:19.635236.635236 lmp.py:376]   Expert 20 |     75 | CPU
DEBUG 01-05 12:51:19.635025.635025 lmp.py:376]   Expert 29 |     83 | CPU
DEBUG 01-05 12:51:19.635814.635814 lmp.py:376]   Expert 35 |     83 | CPU
DEBUG 01-05 12:51:19.635126.635126 lmp.py:376]   Expert 23 |     89 | CPU
DEBUG 01-05 12:51:19.635915.635915 lmp.py:376]   Expert 34 |     90 | CPU
DEBUG 01-05 12:51:19.635465.635465 lmp.py:376]   Expert 54 |     90 | CPU
DEBUG 01-05 12:51:19.635777.635777 lmp.py:376]   Expert 28 |     91 | CPU
DEBUG 01-05 12:51:19.635089.635089 lmp.py:376]   Expert 42 |     94 | CPU
DEBUG 01-05 12:51:19.635116.635116 lmp.py:376]   Expert  0 |    106 | CPU
DEBUG 01-05 12:51:19.635150.635150 lmp.py:376]   Expert 60 |    106 | CPU
DEBUG 01-05 12:51:19.635892.635892 lmp.py:376]   Expert 12 |    109 | CPU
DEBUG 01-05 12:51:19.635111.635111 lmp.py:376]   Expert 51 |    111 | CPU
DEBUG 01-05 12:51:19.635331.635331 lmp.py:376]   Expert 52 |    111 | CPU
DEBUG 01-05 12:51:19.635358.635358 lmp.py:376]   Expert  8 |    116 | CPU
DEBUG 01-05 12:51:19.635670.635670 lmp.py:376]   Expert 21 |    134 | CPU
DEBUG 01-05 12:51:19.635174.635174 lmp.py:376]   Expert 41 |    141 | CPU
DEBUG 01-05 12:51:19.635916.635916 lmp.py:376]   Expert 62 |    147 | CPU
DEBUG 01-05 12:51:19.635182.635182 lmp.py:376]   Expert 30 |    163 | CPU
DEBUG 01-05 12:51:19.635924.635924 lmp.py:376]   Expert 57 |    170 | CPU
DEBUG 01-05 12:51:19.635428.635428 lmp.py:376]   Expert 39 |    182 | GPU
DEBUG 01-05 12:51:19.635409.635409 lmp.py:376]   Expert  6 |    188 | GPU
DEBUG 01-05 12:51:19.635913.635913 lmp.py:376]   Expert 16 |    197 | GPU
DEBUG 01-05 12:51:19.635086.635086 lmp.py:376]   Expert 46 |    205 | GPU
DEBUG 01-05 12:51:19.635020.635020 lmp.py:376]   Expert 53 |    206 | GPU
DEBUG 01-05 12:51:19.635955.635955 lmp.py:376]   Expert 27 |    211 | GPU
DEBUG 01-05 12:51:19.635936.635936 lmp.py:376]   Expert 19 |    216 | GPU
DEBUG 01-05 12:51:19.635678.635678 lmp.py:376]   Expert 58 |    219 | GPU
DEBUG 01-05 12:51:19.635182.635182 lmp.py:376]   Expert 11 |    222 | GPU
DEBUG 01-05 12:51:19.635448.635448 lmp.py:376]   Expert 33 |    224 | GPU
DEBUG 01-05 12:51:19.635713.635713 lmp.py:376]   Expert 45 |    243 | GPU
DEBUG 01-05 12:51:19.635979.635979 lmp.py:376]   Expert 14 |    253 | GPU
DEBUG 01-05 12:51:19.635244.635244 lmp.py:376]   Expert  1 |    254 | GPU
DEBUG 01-05 12:51:19.635417.635417 lmp.py:376]   Expert  3 |    254 | GPU
DEBUG 01-05 12:51:19.635590.635590 lmp.py:376]   Expert 47 |    265 | GPU
DEBUG 01-05 12:51:19.635048.635048 lmp.py:376]   Expert 13 |    267 | GPU
DEBUG 01-05 12:51:19.635744.635744 lmp.py:376]   Expert 37 |    268 | GPU
DEBUG 01-05 12:51:19.635487.635487 lmp.py:376]   Expert 31 |    280 | GPU
DEBUG 01-05 12:51:19.635752.635752 lmp.py:376]   Expert 44 |    294 | GPU
DEBUG 01-05 12:51:19.635779.635779 lmp.py:376]   Expert 56 |    309 | GPU
DEBUG 01-05 12:51:19.635045.635045 lmp.py:376]   Expert 63 |    310 | GPU
DEBUG 01-05 12:51:19.635834.635834 lmp.py:376]   Expert 22 |    316 | GPU
DEBUG 01-05 12:51:19.635099.635099 lmp.py:376]   Expert 26 |    349 | GPU
DEBUG 01-05 12:51:19.635080.635080 lmp.py:376]   Expert 15 |    354 | GPU
DEBUG 01-05 12:51:19.635538.635538 lmp.py:376]   Expert  4 |    369 | GPU
DEBUG 01-05 12:51:19.635949.635949 lmp.py:376]   Expert 36 |    373 | GPU
DEBUG 01-05 12:51:19.635645.635645 lmp.py:376]   Expert  2 |    383 | GPU
DEBUG 01-05 12:51:19.635864.635864 lmp.py:376]   Expert  5 |    387 | GPU
DEBUG 01-05 12:51:19.636607.636607 lmp.py:376]   Expert 25 |    431 | GPU
DEBUG 01-05 12:51:19.636872.636872 lmp.py:376]   Expert  9 |    483 | GPU
DEBUG 01-05 12:51:19.636138.636138 lmp.py:376]   Expert 10 |    584 | GPU
DEBUG 01-05 12:51:19.636642.636642 lmp.py:376]   Expert 24 |    606 | GPU
DEBUG 01-05 12:51:19.636623.636623 lmp.py:377] 
DEBUG 01-05 12:51:19.636623.636623 lmp.py:377]   CPU total tokens: 2586 (21.0%)
DEBUG 01-05 12:51:19.636080.636080 lmp.py:378]   GPU total tokens: 9702 (79.0%)
DEBUG 01-05 12:51:19.636022.636022 cuda_h.py:19] end experts_map_get cost 0.0018393993377685547 seconds
DEBUG 01-05 12:51:19.636718.636718 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.636554.636554 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.636612.636612 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.637558.637558 cuda_h.py:19] end allocate_cuda_memory cost 0.0007112026214599609 seconds
DEBUG 01-05 12:51:19.637223.637223 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.637701.637701 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.637424.637424 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.637081.637081 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de6a0040-6fdf-4262-8858-6dad2f7cce71
DEBUG 01-05 12:51:19.637366.637366 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.637135.637135 client.py:127] Model loaded
DEBUG 01-05 12:51:19.638853.638853 cuda_h.py:19] end sllm_worker_task cost 0.0159149169921875 seconds
INFO 01-05 12:51:19.639040.639040 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de6a0040-6fdf-4262-8858-6dad2f7cce71
DEBUG 01-05 12:51:19.639506.639506 cuda_h.py:19] end load_into_gpu_async cost 0.0022771358489990234 seconds
DEBUG 01-05 12:51:19.639500.639500 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.639689.639689 cuda_h.py:19] end restore_tensors2 cost 0.0002810955047607422 seconds
DEBUG 01-05 12:51:19.639366.639366 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003662586212158203 seconds
DEBUG 01-05 12:51:19.642978.642978 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006340980529785156 seconds
DEBUG 01-05 12:51:19.642761.642761 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.642386.642386 lmp.py:423] 
DEBUG 01-05 12:51:19.642386.642386 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.642460.642460 cuda_h.py:19] end cpu_experts_submit cost 0.00010275840759277344 seconds
DEBUG 01-05 12:51:19.642084.642084 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.648717.648717 mlpmodule.py:704] group tensors cost 0.0053157806396484375 s
DEBUG 01-05 12:51:19.650097.650097 mlpmodule.py:742] pad cost 0.0016598701477050781 s
DEBUG 01-05 12:51:19.650763.650763 mlpmodule.py:748] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-05 12:51:19.650036.650036 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-05 12:51:19.659204.659204 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.659852.659852 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.659041.659041 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 12:51:19.659018.659018 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.677607.677607 mlpmodule.py:793] group einsum cost 0.026860475540161133 s
DEBUG 01-05 12:51:19.678602.678602 mlpmodule.py:801] cpy2cputensor cost 0.0006411075592041016 s
DEBUG 01-05 12:51:19.683727.683727 cuda_h.py:19] end wait_cetm_experts cost 0.040311574935913086 seconds
DEBUG 01-05 12:51:19.683631.683631 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.683092.683092 cuda_h.py:19] end gpu_sexperts cost 0.0004572868347167969 seconds
DEBUG 01-05 12:51:19.683274.683274 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.683959.683959 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-05 12:51:19.683331.683331 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.683325.683325 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de6a0040-6fdf-4262-8858-6dad2f7cce71
INFO 01-05 12:51:19.691812.691812 client.py:127] Model loaded
DEBUG 01-05 12:51:19.691438.691438 cuda_h.py:19] end wait_experts cost 0.00791025161743164 seconds
DEBUG 01-05 12:51:19.691221.691221 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.691713.691713 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.692274.692274 mlpmodule.py:531] gpu group tensors cost 0.0006413459777832031 s
DEBUG 01-05 12:51:19.694981.694981 mlpmodule.py:564] gpu pad cost 0.0014772415161132812 s
DEBUG 01-05 12:51:19.694112.694112 mlpmodule.py:582] gpu group einsum cost 0.0004820823669433594 s
DEBUG 01-05 12:51:19.697465.697465 mlpmodule.py:611] gpu experts func einsum cost 0.005556583404541016 s
DEBUG 01-05 12:51:19.697177.697177 cuda_h.py:19] end gpu_experts cost 0.005750417709350586 seconds
DEBUG 01-05 12:51:19.697213.697213 cuda_h.py:19] end layer_moe_generate_14 cost 0.06433773040771484 seconds
DEBUG 01-05 12:51:19.698689.698689 lmp.py:217] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 12:51:19.698459.698459 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 12:51:19.698930.698930 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 12:51:19.698448.698448 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 12:51:19.698668.698668 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:19.698199.698199 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.677078247070312e-05 seconds
DEBUG 01-05 12:51:19.698094.698094 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.698958.698958 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.698538.698538 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.698573.698573 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.700367.700367 cuda_h.py:19] end allocate_cuda_memory cost 0.001529693603515625 seconds
DEBUG 01-05 12:51:19.700297.700297 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.700775.700775 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.700227.700227 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.700930.700930 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 511e9103-754d-43f9-858d-fd254ed3252d
DEBUG 01-05 12:51:19.700761.700761 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.700932.700932 mlpmodule.py:662]  experts func einsum cost 0.05763411521911621 s
DEBUG 01-05 12:51:19.700728.700728 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.701005.701005 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 511e9103-754d-43f9-858d-fd254ed3252d
DEBUG 01-05 12:51:19.701603.701603 cuda_h.py:19] end load_into_gpu_async cost 0.0011708736419677734 seconds
DEBUG 01-05 12:51:19.701637.701637 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.701613.701613 cuda_h.py:19] end restore_tensors2 cost 6.318092346191406e-05 seconds
DEBUG 01-05 12:51:19.701938.701938 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00302886962890625 seconds
INFO 01-05 12:51:19.702975.702975 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 511e9103-754d-43f9-858d-fd254ed3252d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.704314.704314 cuda_h.py:19] end self_attn cost 0.0033807754516601562 seconds
DEBUG 01-05 12:51:19.704378.704378 cuda_h.py:19] end iln_self_attn_paln cost 0.0062410831451416016 seconds
DEBUG 01-05 12:51:19.704989.704989 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 12:51:19.704328.704328 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.705370.705370 cuda_h.py:19] end gate cost 0.0006284713745117188 seconds
DEBUG 01-05 12:51:19.705392.705392 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.705044.705044 lmp.py:365] 
DEBUG 01-05 12:51:19.705044.705044 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.705714.705714 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.705848.705848 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.705398.705398 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.705803.705803 lmp.py:369] 
DEBUG 01-05 12:51:19.705803.705803 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.705207.705207 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.705963.705963 lmp.py:376]   Expert 63 |      3 | CPU
DEBUG 01-05 12:51:19.705242.705242 lmp.py:376]   Expert 37 |     21 | CPU
DEBUG 01-05 12:51:19.705038.705038 lmp.py:376]   Expert  4 |     27 | CPU
DEBUG 01-05 12:51:19.705357.705357 lmp.py:376]   Expert  5 |     34 | CPU
DEBUG 01-05 12:51:19.705622.705622 lmp.py:376]   Expert 42 |     36 | CPU
DEBUG 01-05 12:51:19.705788.705788 lmp.py:376]   Expert 34 |     37 | CPU
DEBUG 01-05 12:51:19.705716.705716 lmp.py:376]   Expert 53 |     40 | CPU
DEBUG 01-05 12:51:19.705121.705121 lmp.py:376]   Expert 57 |     40 | CPU
DEBUG 01-05 12:51:19.705810.705810 lmp.py:376]   Expert 22 |     47 | CPU
DEBUG 01-05 12:51:19.705499.705499 lmp.py:376]   Expert 41 |     50 | CPU
DEBUG 01-05 12:51:19.706189.706189 lmp.py:376]   Expert 52 |     53 | CPU
DEBUG 01-05 12:51:19.706832.706832 lmp.py:376]   Expert 15 |     54 | CPU
DEBUG 01-05 12:51:19.706011.706011 lmp.py:376]   Expert 48 |     55 | CPU
DEBUG 01-05 12:51:19.706376.706376 lmp.py:376]   Expert 28 |     56 | CPU
DEBUG 01-05 12:51:19.706026.706026 lmp.py:376]   Expert 51 |     61 | CPU
DEBUG 01-05 12:51:19.706630.706630 lmp.py:376]   Expert 32 |     68 | CPU
DEBUG 01-05 12:51:19.706041.706041 lmp.py:376]   Expert  7 |     69 | CPU
DEBUG 01-05 12:51:19.706260.706260 lmp.py:376]   Expert 43 |     75 | CPU
DEBUG 01-05 12:51:19.706718.706718 lmp.py:376]   Expert 40 |     80 | CPU
DEBUG 01-05 12:51:19.706599.706599 lmp.py:376]   Expert 25 |     92 | CPU
DEBUG 01-05 12:51:19.706779.706779 lmp.py:376]   Expert 55 |     93 | CPU
DEBUG 01-05 12:51:19.706429.706429 lmp.py:376]   Expert 29 |    100 | CPU
DEBUG 01-05 12:51:19.706078.706078 lmp.py:376]   Expert 56 |    114 | CPU
DEBUG 01-05 12:51:19.706967.706967 lmp.py:376]   Expert  6 |    116 | CPU
DEBUG 01-05 12:51:19.706616.706616 lmp.py:376]   Expert 14 |    116 | CPU
DEBUG 01-05 12:51:19.706882.706882 lmp.py:376]   Expert 58 |    126 | CPU
DEBUG 01-05 12:51:19.706571.706571 lmp.py:376]   Expert 39 |    127 | CPU
DEBUG 01-05 12:51:19.706022.706022 lmp.py:376]   Expert 23 |    134 | CPU
DEBUG 01-05 12:51:19.706711.706711 lmp.py:376]   Expert 61 |    134 | CPU
DEBUG 01-05 12:51:19.706162.706162 lmp.py:376]   Expert 13 |    145 | CPU
DEBUG 01-05 12:51:19.706282.706282 lmp.py:376]   Expert 33 |    148 | CPU
DEBUG 01-05 12:51:19.706793.706793 lmp.py:376]   Expert 38 |    166 | CPU
DEBUG 01-05 12:51:19.706158.706158 lmp.py:376]   Expert 54 |    168 | GPU
DEBUG 01-05 12:51:19.706569.706569 lmp.py:376]   Expert 50 |    170 | GPU
DEBUG 01-05 12:51:19.706457.706457 lmp.py:376]   Expert 31 |    171 | GPU
DEBUG 01-05 12:51:19.706869.706869 lmp.py:376]   Expert  0 |    182 | GPU
DEBUG 01-05 12:51:19.706373.706373 lmp.py:376]   Expert 12 |    182 | GPU
DEBUG 01-05 12:51:19.706354.706354 lmp.py:376]   Expert  1 |    190 | GPU
DEBUG 01-05 12:51:19.706096.706096 lmp.py:376]   Expert 20 |    201 | GPU
DEBUG 01-05 12:51:19.706838.706838 lmp.py:376]   Expert 35 |    204 | GPU
DEBUG 01-05 12:51:19.706203.706203 lmp.py:376]   Expert 36 |    204 | GPU
DEBUG 01-05 12:51:19.706045.706045 lmp.py:376]   Expert 62 |    205 | GPU
DEBUG 01-05 12:51:19.706172.706172 lmp.py:376]   Expert 49 |    216 | GPU
DEBUG 01-05 12:51:19.706822.706822 lmp.py:376]   Expert 18 |    224 | GPU
DEBUG 01-05 12:51:19.706233.706233 lmp.py:376]   Expert 10 |    227 | GPU
DEBUG 01-05 12:51:19.706499.706499 lmp.py:376]   Expert 16 |    227 | GPU
DEBUG 01-05 12:51:19.706665.706665 lmp.py:376]   Expert 59 |    230 | GPU
DEBUG 01-05 12:51:19.706116.706116 lmp.py:376]   Expert 44 |    277 | GPU
DEBUG 01-05 12:51:19.706567.706567 lmp.py:376]   Expert 26 |    278 | GPU
DEBUG 01-05 12:51:19.706256.706256 lmp.py:376]   Expert  9 |    279 | GPU
DEBUG 01-05 12:51:19.706707.706707 lmp.py:376]   Expert 11 |    282 | GPU
DEBUG 01-05 12:51:19.706310.706310 lmp.py:376]   Expert 19 |    297 | GPU
DEBUG 01-05 12:51:19.706675.706675 lmp.py:376]   Expert 60 |    300 | GPU
DEBUG 01-05 12:51:19.706563.706563 lmp.py:376]   Expert 45 |    302 | GPU
DEBUG 01-05 12:51:19.706975.706975 lmp.py:376]   Expert 17 |    311 | GPU
DEBUG 01-05 12:51:19.706432.706432 lmp.py:376]   Expert 46 |    316 | GPU
DEBUG 01-05 12:51:19.706175.706175 lmp.py:376]   Expert  3 |    330 | GPU
DEBUG 01-05 12:51:19.706917.706917 lmp.py:376]   Expert 47 |    336 | GPU
DEBUG 01-05 12:51:19.707421.707421 lmp.py:376]   Expert 24 |    350 | GPU
DEBUG 01-05 12:51:19.707925.707925 lmp.py:376]   Expert 21 |    362 | GPU
DEBUG 01-05 12:51:19.707429.707429 lmp.py:376]   Expert  2 |    374 | GPU
DEBUG 01-05 12:51:19.707648.707648 lmp.py:376]   Expert 30 |    458 | GPU
DEBUG 01-05 12:51:19.707828.707828 lmp.py:376]   Expert 27 |    597 | GPU
DEBUG 01-05 12:51:19.707286.707286 lmp.py:376]   Expert  8 |   1321 | GPU
DEBUG 01-05 12:51:19.707128.707128 lmp.py:377] 
DEBUG 01-05 12:51:19.707128.707128 lmp.py:377]   CPU total tokens: 2517 (20.5%)
DEBUG 01-05 12:51:19.707446.707446 lmp.py:378]   GPU total tokens: 9771 (79.5%)
DEBUG 01-05 12:51:19.707772.707772 cuda_h.py:19] end experts_map_get cost 0.0018219947814941406 seconds
DEBUG 01-05 12:51:19.707514.707514 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.707152.707152 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.707964.707964 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.708643.708643 cuda_h.py:19] end allocate_cuda_memory cost 0.0012311935424804688 seconds
DEBUG 01-05 12:51:19.708407.708407 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.708507.708507 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.708184.708184 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.708556.708556 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5e4d578-065a-4328-b7fc-33b633c5f205
DEBUG 01-05 12:51:19.709622.709622 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.709669.709669 client.py:127] Model loaded
DEBUG 01-05 12:51:19.709551.709551 cuda_h.py:19] end sllm_worker_task cost 0.010900259017944336 seconds
INFO 01-05 12:51:19.710250.710250 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5e4d578-065a-4328-b7fc-33b633c5f205
DEBUG 01-05 12:51:19.710484.710484 cuda_h.py:19] end load_into_gpu_async cost 0.0012803077697753906 seconds
DEBUG 01-05 12:51:19.710386.710386 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.710237.710237 cuda_h.py:19] end restore_tensors2 cost 0.00028014183044433594 seconds
DEBUG 01-05 12:51:19.710451.710451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031800270080566406 seconds
DEBUG 01-05 12:51:19.713900.713900 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0059413909912109375 seconds
DEBUG 01-05 12:51:19.713405.713405 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.713958.713958 lmp.py:423] 
DEBUG 01-05 12:51:19.713958.713958 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.713245.713245 cuda_h.py:19] end cpu_experts_submit cost 0.00012373924255371094 seconds
DEBUG 01-05 12:51:19.713855.713855 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.723018.723018 mlpmodule.py:704] group tensors cost 0.009692907333374023 s
DEBUG 01-05 12:51:19.725362.725362 mlpmodule.py:742] pad cost 0.0014650821685791016 s
DEBUG 01-05 12:51:19.725630.725630 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-05 12:51:19.725665.725665 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-05 12:51:19.734165.734165 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.734012.734012 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.734094.734094 mlpmodule.py:773] group_w3 first element: -0.0186767578125
WARNING 01-05 12:51:19.734257.734257 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.751579.751579 mlpmodule.py:793] group einsum cost 0.026408910751342773 s
DEBUG 01-05 12:51:19.752304.752304 mlpmodule.py:801] cpy2cputensor cost 0.0006878376007080078 s
DEBUG 01-05 12:51:19.757144.757144 cuda_h.py:19] end wait_cetm_experts cost 0.04398393630981445 seconds
DEBUG 01-05 12:51:19.757962.757962 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.758562.758562 cuda_h.py:19] end gpu_sexperts cost 0.0004546642303466797 seconds
DEBUG 01-05 12:51:19.758645.758645 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.758522.758522 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-05 12:51:19.758669.758669 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.758855.758855 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5e4d578-065a-4328-b7fc-33b633c5f205
INFO 01-05 12:51:19.761472.761472 client.py:127] Model loaded
DEBUG 01-05 12:51:19.761992.761992 cuda_h.py:19] end wait_experts cost 0.003295421600341797 seconds
DEBUG 01-05 12:51:19.761053.761053 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.761492.761492 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.762926.762926 mlpmodule.py:531] gpu group tensors cost 0.0006158351898193359 s
DEBUG 01-05 12:51:19.764906.764906 mlpmodule.py:564] gpu pad cost 0.0016858577728271484 s
DEBUG 01-05 12:51:19.764311.764311 mlpmodule.py:582] gpu group einsum cost 0.0005104541778564453 s
DEBUG 01-05 12:51:19.768960.768960 mlpmodule.py:611] gpu experts func einsum cost 0.006363391876220703 s
DEBUG 01-05 12:51:19.768605.768605 cuda_h.py:19] end gpu_experts cost 0.0065462589263916016 seconds
DEBUG 01-05 12:51:19.768528.768528 cuda_h.py:19] end layer_moe_generate_15 cost 0.06374216079711914 seconds
DEBUG 01-05 12:51:19.768510.768510 lmp.py:217] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 12:51:19.768995.768995 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 12:51:19.768691.768691 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 12:51:19.768923.768923 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 12:51:19.768382.768382 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:19.768324.768324 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.222724914550781e-05 seconds
DEBUG 01-05 12:51:19.768397.768397 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.768571.768571 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.768004.768004 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.768125.768125 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.769471.769471 cuda_h.py:19] end allocate_cuda_memory cost 0.0005664825439453125 seconds
DEBUG 01-05 12:51:19.769957.769957 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.769428.769428 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.769721.769721 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.769470.769470 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16979c99-3d51-4e31-806a-9d60f91dfacb
DEBUG 01-05 12:51:19.769533.769533 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.770072.770072 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.770193.770193 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16979c99-3d51-4e31-806a-9d60f91dfacb
DEBUG 01-05 12:51:19.770599.770599 cuda_h.py:19] end load_into_gpu_async cost 0.0011432170867919922 seconds
DEBUG 01-05 12:51:19.770633.770633 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.770378.770378 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-05 12:51:19.771419.771419 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020639896392822266 seconds
INFO 01-05 12:51:19.771256.771256 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16979c99-3d51-4e31-806a-9d60f91dfacb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.774653.774653 cuda_h.py:19] end self_attn cost 0.004017353057861328 seconds
DEBUG 01-05 12:51:19.774093.774093 cuda_h.py:19] end iln_self_attn_paln cost 0.005715131759643555 seconds
DEBUG 01-05 12:51:19.774982.774982 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 12:51:19.774507.774507 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.775478.775478 mlpmodule.py:662]  experts func einsum cost 0.06162667274475098 s
DEBUG 01-05 12:51:19.775724.775724 cuda_h.py:19] end gate cost 0.0007207393646240234 seconds
DEBUG 01-05 12:51:19.775037.775037 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.775954.775954 lmp.py:365] 
DEBUG 01-05 12:51:19.775954.775954 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.775041.775041 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.775929.775929 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.775764.775764 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.775692.775692 lmp.py:369] 
DEBUG 01-05 12:51:19.775692.775692 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.775335.775335 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.775223.775223 lmp.py:376]   Expert 58 |     17 | CPU
DEBUG 01-05 12:51:19.775389.775389 lmp.py:376]   Expert 49 |     39 | CPU
DEBUG 01-05 12:51:19.775602.775602 lmp.py:376]   Expert 54 |     48 | CPU
DEBUG 01-05 12:51:19.775576.775576 lmp.py:376]   Expert 14 |     52 | CPU
DEBUG 01-05 12:51:19.775312.775312 lmp.py:376]   Expert 13 |     64 | CPU
DEBUG 01-05 12:51:19.775047.775047 lmp.py:376]   Expert 18 |     64 | CPU
DEBUG 01-05 12:51:19.775544.775544 lmp.py:376]   Expert 60 |     64 | CPU
DEBUG 01-05 12:51:19.775280.775280 lmp.py:376]   Expert 39 |     65 | CPU
DEBUG 01-05 12:51:19.775777.775777 lmp.py:376]   Expert 62 |     68 | CPU
DEBUG 01-05 12:51:19.776228.776228 lmp.py:376]   Expert 59 |     72 | CPU
DEBUG 01-05 12:51:19.776679.776679 lmp.py:376]   Expert  6 |     74 | CPU
DEBUG 01-05 12:51:19.776130.776130 lmp.py:376]   Expert 41 |     75 | CPU
DEBUG 01-05 12:51:19.776104.776104 lmp.py:376]   Expert 11 |     78 | CPU
DEBUG 01-05 12:51:19.776316.776316 lmp.py:376]   Expert 32 |     79 | CPU
DEBUG 01-05 12:51:19.776814.776814 lmp.py:376]   Expert 34 |     85 | CPU
DEBUG 01-05 12:51:19.776549.776549 lmp.py:376]   Expert 31 |     87 | CPU
DEBUG 01-05 12:51:19.776477.776477 lmp.py:376]   Expert 44 |     94 | CPU
DEBUG 01-05 12:51:19.776451.776451 lmp.py:376]   Expert 61 |     96 | CPU
DEBUG 01-05 12:51:19.776425.776425 lmp.py:376]   Expert 45 |     97 | CPU
DEBUG 01-05 12:51:19.776114.776114 lmp.py:376]   Expert  0 |    105 | CPU
DEBUG 01-05 12:51:19.776327.776327 lmp.py:376]   Expert 25 |    114 | CPU
DEBUG 01-05 12:51:19.776778.776778 lmp.py:376]   Expert 15 |    116 | CPU
DEBUG 01-05 12:51:19.776467.776467 lmp.py:376]   Expert 30 |    118 | CPU
DEBUG 01-05 12:51:19.776395.776395 lmp.py:376]   Expert 35 |    119 | CPU
DEBUG 01-05 12:51:19.776322.776322 lmp.py:376]   Expert 12 |    129 | CPU
DEBUG 01-05 12:51:19.776488.776488 lmp.py:376]   Expert 42 |    129 | CPU
DEBUG 01-05 12:51:19.776416.776416 lmp.py:376]   Expert 26 |    131 | CPU
DEBUG 01-05 12:51:19.776629.776629 lmp.py:376]   Expert 57 |    131 | CPU
DEBUG 01-05 12:51:19.776841.776841 lmp.py:376]   Expert 63 |    140 | CPU
DEBUG 01-05 12:51:19.776054.776054 lmp.py:376]   Expert 28 |    144 | CPU
DEBUG 01-05 12:51:19.776028.776028 lmp.py:376]   Expert 21 |    146 | CPU
DEBUG 01-05 12:51:19.776479.776479 lmp.py:376]   Expert 56 |    148 | CPU
DEBUG 01-05 12:51:19.776658.776658 lmp.py:376]   Expert 47 |    154 | GPU
DEBUG 01-05 12:51:19.776586.776586 lmp.py:376]   Expert 48 |    161 | GPU
DEBUG 01-05 12:51:19.776798.776798 lmp.py:376]   Expert 38 |    169 | GPU
DEBUG 01-05 12:51:19.776965.776965 lmp.py:376]   Expert 55 |    185 | GPU
DEBUG 01-05 12:51:19.776892.776892 lmp.py:376]   Expert 50 |    192 | GPU
DEBUG 01-05 12:51:19.776820.776820 lmp.py:376]   Expert 43 |    205 | GPU
DEBUG 01-05 12:51:19.776509.776509 lmp.py:376]   Expert 51 |    206 | GPU
DEBUG 01-05 12:51:19.776437.776437 lmp.py:376]   Expert 24 |    212 | GPU
DEBUG 01-05 12:51:19.776411.776411 lmp.py:376]   Expert 36 |    215 | GPU
DEBUG 01-05 12:51:19.776624.776624 lmp.py:376]   Expert 20 |    220 | GPU
DEBUG 01-05 12:51:19.776836.776836 lmp.py:376]   Expert 17 |    224 | GPU
DEBUG 01-05 12:51:19.776048.776048 lmp.py:376]   Expert  2 |    233 | GPU
DEBUG 01-05 12:51:19.776499.776499 lmp.py:376]   Expert  3 |    238 | GPU
DEBUG 01-05 12:51:19.776950.776950 lmp.py:376]   Expert 40 |    248 | GPU
DEBUG 01-05 12:51:19.776163.776163 lmp.py:376]   Expert  7 |    258 | GPU
DEBUG 01-05 12:51:19.776614.776614 lmp.py:376]   Expert  9 |    272 | GPU
DEBUG 01-05 12:51:19.776064.776064 lmp.py:376]   Expert 37 |    275 | GPU
DEBUG 01-05 12:51:19.776515.776515 lmp.py:376]   Expert 53 |    299 | GPU
DEBUG 01-05 12:51:19.776728.776728 lmp.py:376]   Expert 46 |    301 | GPU
DEBUG 01-05 12:51:19.776894.776894 lmp.py:376]   Expert  4 |    307 | GPU
DEBUG 01-05 12:51:19.776822.776822 lmp.py:376]   Expert  1 |    308 | GPU
DEBUG 01-05 12:51:19.776749.776749 lmp.py:376]   Expert 19 |    328 | GPU
DEBUG 01-05 12:51:19.776677.776677 lmp.py:376]   Expert  8 |    333 | GPU
DEBUG 01-05 12:51:19.776128.776128 lmp.py:376]   Expert 33 |    336 | GPU
DEBUG 01-05 12:51:19.776340.776340 lmp.py:376]   Expert 16 |    359 | GPU
DEBUG 01-05 12:51:19.776791.776791 lmp.py:376]   Expert 29 |    369 | GPU
DEBUG 01-05 12:51:19.776004.776004 lmp.py:376]   Expert 10 |    370 | GPU
DEBUG 01-05 12:51:19.776455.776455 lmp.py:376]   Expert 27 |    384 | GPU
DEBUG 01-05 12:51:19.776667.776667 lmp.py:376]   Expert 22 |    419 | GPU
DEBUG 01-05 12:51:19.776118.776118 lmp.py:376]   Expert 52 |    457 | GPU
DEBUG 01-05 12:51:19.776569.776569 lmp.py:376]   Expert  5 |    494 | GPU
DEBUG 01-05 12:51:19.776543.776543 lmp.py:376]   Expert 23 |    569 | GPU
DEBUG 01-05 12:51:19.776424.776424 lmp.py:377] 
DEBUG 01-05 12:51:19.776424.776424 lmp.py:377]   CPU total tokens: 2988 (24.3%)
DEBUG 01-05 12:51:19.776021.776021 lmp.py:378]   GPU total tokens: 9300 (75.7%)
DEBUG 01-05 12:51:19.776671.776671 cuda_h.py:19] end experts_map_get cost 0.0014925003051757812 seconds
DEBUG 01-05 12:51:19.776267.776267 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.777474.777474 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.777227.777227 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.777393.777393 cuda_h.py:19] end allocate_cuda_memory cost 0.0003685951232910156 seconds
DEBUG 01-05 12:51:19.777335.777335 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.777091.777091 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.777238.777238 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.777557.777557 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1dd27d22-0897-4c89-8f6e-32173a767193
DEBUG 01-05 12:51:19.777702.777702 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.778874.778874 client.py:127] Model loaded
DEBUG 01-05 12:51:19.778664.778664 cuda_h.py:19] end sllm_worker_task cost 0.009233713150024414 seconds
INFO 01-05 12:51:19.778283.778283 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1dd27d22-0897-4c89-8f6e-32173a767193
DEBUG 01-05 12:51:19.778841.778841 cuda_h.py:19] end load_into_gpu_async cost 0.0012171268463134766 seconds
DEBUG 01-05 12:51:19.778828.778828 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.779468.779468 cuda_h.py:19] end restore_tensors2 cost 0.0002701282501220703 seconds
DEBUG 01-05 12:51:19.779476.779476 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021905899047851562 seconds
DEBUG 01-05 12:51:19.781896.781896 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004895448684692383 seconds
DEBUG 01-05 12:51:19.781964.781964 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.782709.782709 lmp.py:423] 
DEBUG 01-05 12:51:19.782709.782709 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.782028.782028 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-05 12:51:19.782632.782632 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.790271.790271 mlpmodule.py:704] group tensors cost 0.008667945861816406 s
DEBUG 01-05 12:51:19.793368.793368 mlpmodule.py:742] pad cost 0.0014934539794921875 s
DEBUG 01-05 12:51:19.793444.793444 mlpmodule.py:748] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-05 12:51:19.793479.793479 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-05 12:51:19.802525.802525 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.802596.802596 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.802963.802963 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 12:51:19.802034.802034 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.819417.819417 mlpmodule.py:793] group einsum cost 0.02576160430908203 s
DEBUG 01-05 12:51:19.819350.819350 mlpmodule.py:801] cpy2cputensor cost 0.0006153583526611328 s
DEBUG 01-05 12:51:19.824046.824046 cuda_h.py:19] end wait_cetm_experts cost 0.04239630699157715 seconds
DEBUG 01-05 12:51:19.824196.824196 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.825332.825332 cuda_h.py:19] end gpu_sexperts cost 0.0004639625549316406 seconds
DEBUG 01-05 12:51:19.825978.825978 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.825186.825186 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 12:51:19.825286.825286 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.825950.825950 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1dd27d22-0897-4c89-8f6e-32173a767193
INFO 01-05 12:51:19.831488.831488 client.py:127] Model loaded
DEBUG 01-05 12:51:19.831353.831353 cuda_h.py:19] end wait_experts cost 0.0057032108306884766 seconds
DEBUG 01-05 12:51:19.831891.831891 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.831998.831998 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.831479.831479 mlpmodule.py:531] gpu group tensors cost 0.000606536865234375 s
DEBUG 01-05 12:51:19.833843.833843 mlpmodule.py:564] gpu pad cost 0.001689910888671875 s
DEBUG 01-05 12:51:19.834983.834983 mlpmodule.py:582] gpu group einsum cost 0.0005202293395996094 s
DEBUG 01-05 12:51:19.837540.837540 mlpmodule.py:611] gpu experts func einsum cost 0.005987882614135742 s
DEBUG 01-05 12:51:19.837067.837067 cuda_h.py:19] end gpu_experts cost 0.006197929382324219 seconds
DEBUG 01-05 12:51:19.837890.837890 cuda_h.py:19] end layer_moe_generate_16 cost 0.06289362907409668 seconds
DEBUG 01-05 12:51:19.837333.837333 lmp.py:217] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 12:51:19.837095.837095 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 12:51:19.837315.837315 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 12:51:19.837594.837594 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 12:51:19.837430.837430 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.7894973754882812e-05 seconds
DEBUG 01-05 12:51:19.837226.837226 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.817413330078125e-05 seconds
DEBUG 01-05 12:51:19.837822.837822 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.837752.837752 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.838391.838391 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.838605.838605 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.841481.841481 cuda_h.py:19] end allocate_cuda_memory cost 0.0035941600799560547 seconds
DEBUG 01-05 12:51:19.841603.841603 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.841472.841472 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.841388.841388 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.841422.841422 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 425ea811-251a-4da3-9216-d949748ea306
DEBUG 01-05 12:51:19.842961.842961 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.842218.842218 mlpmodule.py:662]  experts func einsum cost 0.0599057674407959 s
DEBUG 01-05 12:51:19.842504.842504 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.842528.842528 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 425ea811-251a-4da3-9216-d949748ea306
DEBUG 01-05 12:51:19.842887.842887 cuda_h.py:19] end load_into_gpu_async cost 0.0011126995086669922 seconds
DEBUG 01-05 12:51:19.842921.842921 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.843421.843421 cuda_h.py:19] end restore_tensors2 cost 6.151199340820312e-05 seconds
DEBUG 01-05 12:51:19.843508.843508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005039215087890625 seconds
INFO 01-05 12:51:19.843737.843737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 425ea811-251a-4da3-9216-d949748ea306
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.845147.845147 cuda_h.py:19] end self_attn cost 0.0034933090209960938 seconds
DEBUG 01-05 12:51:19.846957.846957 cuda_h.py:19] end iln_self_attn_paln cost 0.00835871696472168 seconds
DEBUG 01-05 12:51:19.846416.846416 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 12:51:19.846179.846179 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.847367.847367 cuda_h.py:19] end gate cost 0.0006315708160400391 seconds
DEBUG 01-05 12:51:19.847050.847050 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.847160.847160 lmp.py:365] 
DEBUG 01-05 12:51:19.847160.847160 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.847121.847121 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.847725.847725 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.847037.847037 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.847441.847441 lmp.py:369] 
DEBUG 01-05 12:51:19.847441.847441 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.847607.847607 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.847019.847019 lmp.py:376]   Expert 28 |     36 | CPU
DEBUG 01-05 12:51:19.847946.847946 lmp.py:376]   Expert 14 |     40 | CPU
DEBUG 01-05 12:51:19.847682.847682 lmp.py:376]   Expert 46 |     43 | CPU
DEBUG 01-05 12:51:19.847418.847418 lmp.py:376]   Expert  1 |     48 | CPU
DEBUG 01-05 12:51:19.847153.847153 lmp.py:376]   Expert 40 |     51 | CPU
DEBUG 01-05 12:51:19.847889.847889 lmp.py:376]   Expert 47 |     51 | CPU
DEBUG 01-05 12:51:19.847148.847148 lmp.py:376]   Expert 36 |     55 | CPU
DEBUG 01-05 12:51:19.847883.847883 lmp.py:376]   Expert 39 |     57 | CPU
DEBUG 01-05 12:51:19.847380.847380 lmp.py:376]   Expert 54 |     67 | CPU
DEBUG 01-05 12:51:19.847308.847308 lmp.py:376]   Expert 25 |     69 | CPU
DEBUG 01-05 12:51:19.847521.847521 lmp.py:376]   Expert 27 |     75 | CPU
DEBUG 01-05 12:51:19.847733.847733 lmp.py:376]   Expert 30 |     75 | CPU
DEBUG 01-05 12:51:19.847946.847946 lmp.py:376]   Expert 31 |     94 | CPU
DEBUG 01-05 12:51:19.847158.847158 lmp.py:376]   Expert 59 |     98 | CPU
DEBUG 01-05 12:51:19.847655.847655 lmp.py:376]   Expert  7 |    100 | CPU
DEBUG 01-05 12:51:19.847391.847391 lmp.py:376]   Expert 16 |    107 | CPU
DEBUG 01-05 12:51:19.847888.847888 lmp.py:376]   Expert 61 |    108 | CPU
DEBUG 01-05 12:51:19.847385.847385 lmp.py:376]   Expert  8 |    109 | CPU
DEBUG 01-05 12:51:19.847883.847883 lmp.py:376]   Expert 60 |    109 | CPU
DEBUG 01-05 12:51:19.847903.847903 lmp.py:376]   Expert 21 |    113 | CPU
DEBUG 01-05 12:51:19.847400.847400 lmp.py:376]   Expert 52 |    117 | CPU
DEBUG 01-05 12:51:19.847659.847659 lmp.py:376]   Expert 50 |    122 | CPU
DEBUG 01-05 12:51:19.847156.847156 lmp.py:376]   Expert 34 |    124 | CPU
DEBUG 01-05 12:51:19.847892.847892 lmp.py:376]   Expert 29 |    131 | CPU
DEBUG 01-05 12:51:19.847104.847104 lmp.py:376]   Expert 24 |    136 | CPU
DEBUG 01-05 12:51:19.847555.847555 lmp.py:376]   Expert  2 |    138 | CPU
DEBUG 01-05 12:51:19.847529.847529 lmp.py:376]   Expert  3 |    140 | CPU
DEBUG 01-05 12:51:19.847742.847742 lmp.py:376]   Expert  9 |    144 | CPU
DEBUG 01-05 12:51:19.847239.847239 lmp.py:376]   Expert 63 |    147 | CPU
DEBUG 01-05 12:51:19.847974.847974 lmp.py:376]   Expert 33 |    149 | CPU
DEBUG 01-05 12:51:19.847233.847233 lmp.py:376]   Expert 56 |    149 | CPU
DEBUG 01-05 12:51:19.847969.847969 lmp.py:376]   Expert 51 |    152 | CPU
DEBUG 01-05 12:51:19.847228.847228 lmp.py:376]   Expert 58 |    154 | GPU
DEBUG 01-05 12:51:19.848725.848725 lmp.py:376]   Expert  6 |    160 | GPU
DEBUG 01-05 12:51:19.848984.848984 lmp.py:376]   Expert 15 |    165 | GPU
DEBUG 01-05 12:51:19.848004.848004 lmp.py:376]   Expert 18 |    175 | GPU
DEBUG 01-05 12:51:19.848740.848740 lmp.py:376]   Expert 10 |    177 | GPU
DEBUG 01-05 12:51:19.848998.848998 lmp.py:376]   Expert  0 |    181 | GPU
DEBUG 01-05 12:51:19.848496.848496 lmp.py:376]   Expert 53 |    189 | GPU
DEBUG 01-05 12:51:19.848231.848231 lmp.py:376]   Expert  4 |    198 | GPU
DEBUG 01-05 12:51:19.848205.848205 lmp.py:376]   Expert 42 |    208 | GPU
DEBUG 01-05 12:51:19.848656.848656 lmp.py:376]   Expert 32 |    214 | GPU
DEBUG 01-05 12:51:19.848392.848392 lmp.py:376]   Expert 35 |    217 | GPU
DEBUG 01-05 12:51:19.848366.848366 lmp.py:376]   Expert  5 |    245 | GPU
DEBUG 01-05 12:51:19.848625.848625 lmp.py:376]   Expert 62 |    252 | GPU
DEBUG 01-05 12:51:19.848883.848883 lmp.py:376]   Expert 11 |    253 | GPU
DEBUG 01-05 12:51:19.848904.848904 lmp.py:376]   Expert 23 |    254 | GPU
DEBUG 01-05 12:51:19.848924.848924 lmp.py:376]   Expert 37 |    255 | GPU
DEBUG 01-05 12:51:19.848183.848183 lmp.py:376]   Expert 45 |    282 | GPU
DEBUG 01-05 12:51:19.848203.848203 lmp.py:376]   Expert 13 |    283 | GPU
DEBUG 01-05 12:51:19.848462.848462 lmp.py:376]   Expert 43 |    292 | GPU
DEBUG 01-05 12:51:19.848721.848721 lmp.py:376]   Expert 48 |    293 | GPU
DEBUG 01-05 12:51:19.848980.848980 lmp.py:376]   Expert 49 |    307 | GPU
DEBUG 01-05 12:51:19.848477.848477 lmp.py:376]   Expert 12 |    314 | GPU
DEBUG 01-05 12:51:19.848928.848928 lmp.py:376]   Expert 44 |    323 | GPU
DEBUG 01-05 12:51:19.848902.848902 lmp.py:376]   Expert 22 |    324 | GPU
DEBUG 01-05 12:51:19.848876.848876 lmp.py:376]   Expert 38 |    326 | GPU
DEBUG 01-05 12:51:19.848526.848526 lmp.py:376]   Expert 20 |    328 | GPU
DEBUG 01-05 12:51:19.848381.848381 lmp.py:376]   Expert 19 |    361 | GPU
DEBUG 01-05 12:51:19.848547.848547 lmp.py:376]   Expert 41 |    379 | GPU
DEBUG 01-05 12:51:19.848713.848713 lmp.py:376]   Expert 57 |    385 | GPU
DEBUG 01-05 12:51:19.848641.848641 lmp.py:376]   Expert 26 |    482 | GPU
DEBUG 01-05 12:51:19.848092.848092 lmp.py:376]   Expert 17 |    562 | GPU
DEBUG 01-05 12:51:19.848781.848781 lmp.py:376]   Expert 55 |    596 | GPU
DEBUG 01-05 12:51:19.848663.848663 lmp.py:377] 
DEBUG 01-05 12:51:19.848663.848663 lmp.py:377]   CPU total tokens: 3154 (25.7%)
DEBUG 01-05 12:51:19.848782.848782 lmp.py:378]   GPU total tokens: 9134 (74.3%)
DEBUG 01-05 12:51:19.848432.848432 cuda_h.py:19] end experts_map_get cost 0.0014810562133789062 seconds
DEBUG 01-05 12:51:19.848314.848314 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.848997.848997 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.848942.848942 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.850184.850184 cuda_h.py:19] end allocate_cuda_memory cost 0.001443624496459961 seconds
DEBUG 01-05 12:51:19.850438.850438 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.850148.850148 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.850195.850195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.850560.850560 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1aa23ac-fd0f-4d39-8531-32e6318be5f7
DEBUG 01-05 12:51:19.850520.850520 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.850225.850225 client.py:127] Model loaded
DEBUG 01-05 12:51:19.850491.850491 cuda_h.py:19] end sllm_worker_task cost 0.012895345687866211 seconds
INFO 01-05 12:51:19.851798.851798 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1aa23ac-fd0f-4d39-8531-32e6318be5f7
DEBUG 01-05 12:51:19.851025.851025 cuda_h.py:19] end load_into_gpu_async cost 0.0012760162353515625 seconds
DEBUG 01-05 12:51:19.851682.851682 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.851327.851327 cuda_h.py:19] end restore_tensors2 cost 0.0002751350402832031 seconds
DEBUG 01-05 12:51:19.852488.852488 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003351926803588867 seconds
DEBUG 01-05 12:51:19.854603.854603 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00605010986328125 seconds
DEBUG 01-05 12:51:19.854194.854194 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.854819.854819 lmp.py:423] 
DEBUG 01-05 12:51:19.854819.854819 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.854702.854702 cuda_h.py:19] end cpu_experts_submit cost 0.0001010894775390625 seconds
DEBUG 01-05 12:51:19.854087.854087 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.864866.864866 mlpmodule.py:704] group tensors cost 0.0098876953125 s
DEBUG 01-05 12:51:19.866723.866723 mlpmodule.py:742] pad cost 0.001378774642944336 s
DEBUG 01-05 12:51:19.867891.867891 mlpmodule.py:748] create cpu tensor cost 3.647804260253906e-05 s
DEBUG 01-05 12:51:19.867496.867496 mlpmodule.py:753] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-05 12:51:19.875869.875869 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.876739.876739 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.876769.876769 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 12:51:19.876105.876105 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.893744.893744 mlpmodule.py:793] group einsum cost 0.026519298553466797 s
DEBUG 01-05 12:51:19.894238.894238 mlpmodule.py:801] cpy2cputensor cost 0.0006256103515625 s
DEBUG 01-05 12:51:19.899333.899333 cuda_h.py:19] end wait_cetm_experts cost 0.044480085372924805 seconds
DEBUG 01-05 12:51:19.899541.899541 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.899836.899836 cuda_h.py:19] end gpu_sexperts cost 0.0004558563232421875 seconds
DEBUG 01-05 12:51:19.900580.900580 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.900906.900906 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:19.900848.900848 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.900127.900127 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1aa23ac-fd0f-4d39-8531-32e6318be5f7
INFO 01-05 12:51:19.903917.903917 client.py:127] Model loaded
DEBUG 01-05 12:51:19.904204.904204 cuda_h.py:19] end wait_experts cost 0.0038814544677734375 seconds
DEBUG 01-05 12:51:19.904768.904768 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.904047.904047 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.904680.904680 mlpmodule.py:531] gpu group tensors cost 0.0006339550018310547 s
DEBUG 01-05 12:51:19.906784.906784 mlpmodule.py:564] gpu pad cost 0.0016562938690185547 s
DEBUG 01-05 12:51:19.907122.907122 mlpmodule.py:582] gpu group einsum cost 0.0005156993865966797 s
DEBUG 01-05 12:51:19.910932.910932 mlpmodule.py:611] gpu experts func einsum cost 0.006366729736328125 s
DEBUG 01-05 12:51:19.910935.910935 cuda_h.py:19] end gpu_experts cost 0.0065555572509765625 seconds
DEBUG 01-05 12:51:19.910044.910044 cuda_h.py:19] end layer_moe_generate_17 cost 0.0644063949584961 seconds
DEBUG 01-05 12:51:19.910771.910771 lmp.py:217] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 12:51:19.910388.910388 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 12:51:19.910892.910892 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 12:51:19.910217.910217 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 12:51:19.911292.911292 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:19.911372.911372 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.745887756347656e-05 seconds
DEBUG 01-05 12:51:19.911777.911777 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.911409.911409 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.911292.911292 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.911367.911367 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.911703.911703 cuda_h.py:19] end allocate_cuda_memory cost 0.00031828880310058594 seconds
DEBUG 01-05 12:51:19.911733.911733 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.911827.911827 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.911789.911789 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.911630.911630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1962a2a-c776-40ee-9fe0-e84acc417d87
DEBUG 01-05 12:51:19.911077.911077 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.912423.912423 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.912166.912166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1962a2a-c776-40ee-9fe0-e84acc417d87
DEBUG 01-05 12:51:19.912240.912240 cuda_h.py:19] end load_into_gpu_async cost 0.0010769367218017578 seconds
DEBUG 01-05 12:51:19.912513.912513 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.912681.912681 cuda_h.py:19] end restore_tensors2 cost 6.341934204101562e-05 seconds
DEBUG 01-05 12:51:19.913471.913471 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017426013946533203 seconds
INFO 01-05 12:51:19.913342.913342 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1962a2a-c776-40ee-9fe0-e84acc417d87
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.916801.916801 cuda_h.py:19] end self_attn cost 0.0039038658142089844 seconds
DEBUG 01-05 12:51:19.916394.916394 cuda_h.py:19] end iln_self_attn_paln cost 0.0053424835205078125 seconds
DEBUG 01-05 12:51:19.916568.916568 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 12:51:19.916854.916854 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.917896.917896 cuda_h.py:19] end gate cost 0.0006289482116699219 seconds
DEBUG 01-05 12:51:19.917024.917024 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.917563.917563 lmp.py:365] 
DEBUG 01-05 12:51:19.917563.917563 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.917796.917796 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.917446.917446 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.917519.917519 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.917686.917686 lmp.py:369] 
DEBUG 01-05 12:51:19.917686.917686 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.917613.917613 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.917501.917501 lmp.py:376]   Expert 54 |     18 | CPU
DEBUG 01-05 12:51:19.917098.917098 lmp.py:376]   Expert 35 |     29 | CPU
DEBUG 01-05 12:51:19.917218.917218 lmp.py:376]   Expert  0 |     31 | CPU
DEBUG 01-05 12:51:19.917622.917622 lmp.py:376]   Expert 19 |     33 | CPU
DEBUG 01-05 12:51:19.917789.917789 lmp.py:376]   Expert 40 |     34 | CPU
DEBUG 01-05 12:51:19.917478.917478 lmp.py:376]   Expert 12 |     42 | CPU
DEBUG 01-05 12:51:19.917929.917929 lmp.py:376]   Expert 34 |     54 | CPU
DEBUG 01-05 12:51:19.917380.917380 lmp.py:376]   Expert 53 |     54 | CPU
DEBUG 01-05 12:51:19.917592.917592 lmp.py:376]   Expert 20 |     55 | CPU
DEBUG 01-05 12:51:19.917043.917043 lmp.py:376]   Expert 58 |     56 | CPU
DEBUG 01-05 12:51:19.917732.917732 lmp.py:376]   Expert  3 |     57 | CPU
DEBUG 01-05 12:51:19.917945.917945 lmp.py:376]   Expert 32 |     58 | CPU
DEBUG 01-05 12:51:19.917919.917919 lmp.py:376]   Expert 41 |     59 | CPU
DEBUG 01-05 12:51:19.917893.917893 lmp.py:376]   Expert 33 |     64 | CPU
DEBUG 01-05 12:51:19.917105.917105 lmp.py:376]   Expert 60 |     64 | CPU
DEBUG 01-05 12:51:19.917318.917318 lmp.py:376]   Expert  6 |     67 | CPU
DEBUG 01-05 12:51:19.917292.917292 lmp.py:376]   Expert  8 |     69 | CPU
DEBUG 01-05 12:51:19.917981.917981 lmp.py:376]   Expert 37 |     73 | CPU
DEBUG 01-05 12:51:19.917670.917670 lmp.py:376]   Expert 25 |     76 | CPU
DEBUG 01-05 12:51:19.917598.917598 lmp.py:376]   Expert 63 |     76 | CPU
DEBUG 01-05 12:51:19.918287.918287 lmp.py:376]   Expert 48 |     81 | CPU
DEBUG 01-05 12:51:19.918738.918738 lmp.py:376]   Expert 13 |     85 | CPU
DEBUG 01-05 12:51:19.918951.918951 lmp.py:376]   Expert 30 |     87 | CPU
DEBUG 01-05 12:51:19.918925.918925 lmp.py:376]   Expert 27 |     89 | CPU
DEBUG 01-05 12:51:19.918899.918899 lmp.py:376]   Expert 24 |     94 | CPU
DEBUG 01-05 12:51:19.918873.918873 lmp.py:376]   Expert 46 |     99 | CPU
DEBUG 01-05 12:51:19.918324.918324 lmp.py:376]   Expert 45 |    109 | CPU
DEBUG 01-05 12:51:19.918059.918059 lmp.py:376]   Expert  5 |    112 | CPU
DEBUG 01-05 12:51:19.918272.918272 lmp.py:376]   Expert 29 |    119 | CPU
DEBUG 01-05 12:51:19.918246.918246 lmp.py:376]   Expert 11 |    121 | CPU
DEBUG 01-05 12:51:19.918458.918458 lmp.py:376]   Expert 22 |    135 | CPU
DEBUG 01-05 12:51:19.918671.918671 lmp.py:376]   Expert 44 |    137 | CPU
DEBUG 01-05 12:51:19.918645.918645 lmp.py:376]   Expert 43 |    139 | GPU
DEBUG 01-05 12:51:19.918334.918334 lmp.py:376]   Expert 56 |    143 | GPU
DEBUG 01-05 12:51:19.918262.918262 lmp.py:376]   Expert 55 |    145 | GPU
DEBUG 01-05 12:51:19.918190.918190 lmp.py:376]   Expert 16 |    149 | GPU
DEBUG 01-05 12:51:19.918879.918879 lmp.py:376]   Expert 21 |    158 | GPU
DEBUG 01-05 12:51:19.918045.918045 lmp.py:376]   Expert 42 |    161 | GPU
DEBUG 01-05 12:51:19.918496.918496 lmp.py:376]   Expert  4 |    165 | GPU
DEBUG 01-05 12:51:19.918470.918470 lmp.py:376]   Expert  9 |    167 | GPU
DEBUG 01-05 12:51:19.918682.918682 lmp.py:376]   Expert 18 |    197 | GPU
DEBUG 01-05 12:51:19.918657.918657 lmp.py:376]   Expert 51 |    203 | GPU
DEBUG 01-05 12:51:19.918631.918631 lmp.py:376]   Expert 59 |    208 | GPU
DEBUG 01-05 12:51:19.918843.918843 lmp.py:376]   Expert 39 |    216 | GPU
DEBUG 01-05 12:51:19.918817.918817 lmp.py:376]   Expert 52 |    222 | GPU
DEBUG 01-05 12:51:19.918030.918030 lmp.py:376]   Expert 31 |    234 | GPU
DEBUG 01-05 12:51:19.918004.918004 lmp.py:376]   Expert 38 |    248 | GPU
DEBUG 01-05 12:51:19.918454.918454 lmp.py:376]   Expert 28 |    251 | GPU
DEBUG 01-05 12:51:19.918667.918667 lmp.py:376]   Expert 10 |    252 | GPU
DEBUG 01-05 12:51:19.918356.918356 lmp.py:376]   Expert  1 |    253 | GPU
DEBUG 01-05 12:51:19.918807.918807 lmp.py:376]   Expert  7 |    283 | GPU
DEBUG 01-05 12:51:19.918735.918735 lmp.py:376]   Expert 50 |    284 | GPU
DEBUG 01-05 12:51:19.918424.918424 lmp.py:376]   Expert 14 |    288 | GPU
DEBUG 01-05 12:51:19.918590.918590 lmp.py:376]   Expert 57 |    300 | GPU
DEBUG 01-05 12:51:19.918041.918041 lmp.py:376]   Expert 36 |    302 | GPU
DEBUG 01-05 12:51:19.918015.918015 lmp.py:376]   Expert 61 |    338 | GPU
DEBUG 01-05 12:51:19.918466.918466 lmp.py:376]   Expert 47 |    374 | GPU
DEBUG 01-05 12:51:19.918679.918679 lmp.py:376]   Expert 26 |    379 | GPU
DEBUG 01-05 12:51:19.918368.918368 lmp.py:376]   Expert 15 |    394 | GPU
DEBUG 01-05 12:51:19.918342.918342 lmp.py:376]   Expert 49 |    414 | GPU
DEBUG 01-05 12:51:19.918554.918554 lmp.py:376]   Expert 17 |    467 | GPU
DEBUG 01-05 12:51:19.918528.918528 lmp.py:376]   Expert  2 |    479 | GPU
DEBUG 01-05 12:51:19.918979.918979 lmp.py:376]   Expert 23 |    739 | GPU
DEBUG 01-05 12:51:19.918921.918921 lmp.py:376]   Expert 62 |   1399 | GPU
DEBUG 01-05 12:51:19.918756.918756 lmp.py:377] 
DEBUG 01-05 12:51:19.918756.918756 lmp.py:377]   CPU total tokens: 2337 (19.0%)
DEBUG 01-05 12:51:19.918875.918875 lmp.py:378]   GPU total tokens: 9951 (81.0%)
DEBUG 01-05 12:51:19.918048.918048 cuda_h.py:19] end experts_map_get cost 0.001497507095336914 seconds
DEBUG 01-05 12:51:19.918168.918168 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.918945.918945 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.918221.918221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.919356.919356 cuda_h.py:19] end allocate_cuda_memory cost 0.0004520416259765625 seconds
DEBUG 01-05 12:51:19.919842.919842 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.919459.919459 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.919937.919937 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.919064.919064 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e7cfeaa3-edc4-49ec-b459-9697ccd08ad2
DEBUG 01-05 12:51:19.919156.919156 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.919252.919252 mlpmodule.py:662]  experts func einsum cost 0.0649271011352539 s
INFO 01-05 12:51:19.920152.920152 client.py:127] Model loaded
DEBUG 01-05 12:51:19.920472.920472 cuda_h.py:19] end sllm_worker_task cost 0.00891423225402832 seconds
INFO 01-05 12:51:19.920399.920399 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e7cfeaa3-edc4-49ec-b459-9697ccd08ad2
DEBUG 01-05 12:51:19.920627.920627 cuda_h.py:19] end load_into_gpu_async cost 0.0012445449829101562 seconds
DEBUG 01-05 12:51:19.920568.920568 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.921121.921121 cuda_h.py:19] end restore_tensors2 cost 0.00027680397033691406 seconds
DEBUG 01-05 12:51:19.921096.921096 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023374557495117188 seconds
DEBUG 01-05 12:51:19.923826.923826 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004987478256225586 seconds
DEBUG 01-05 12:51:19.923987.923987 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.923016.923016 lmp.py:423] 
DEBUG 01-05 12:51:19.923016.923016 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.924475.924475 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 12:51:19.924450.924450 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.928783.928783 mlpmodule.py:704] group tensors cost 0.004297733306884766 s
DEBUG 01-05 12:51:19.930737.930737 mlpmodule.py:742] pad cost 0.0014710426330566406 s
DEBUG 01-05 12:51:19.930880.930880 mlpmodule.py:748] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-05 12:51:19.930392.930392 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-05 12:51:19.939000.939000 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:19.939032.939032 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:19.939214.939214 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 12:51:19.939808.939808 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:19.956769.956769 mlpmodule.py:793] group einsum cost 0.026015281677246094 s
DEBUG 01-05 12:51:19.957914.957914 mlpmodule.py:801] cpy2cputensor cost 0.000583648681640625 s
DEBUG 01-05 12:51:19.962608.962608 cuda_h.py:19] end wait_cetm_experts cost 0.03809356689453125 seconds
DEBUG 01-05 12:51:19.962619.962619 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:19.962550.962550 cuda_h.py:19] end gpu_sexperts cost 0.0004544258117675781 seconds
DEBUG 01-05 12:51:19.962149.962149 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:19.963787.963787 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 12:51:19.963127.963127 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:19.963790.963790 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e7cfeaa3-edc4-49ec-b459-9697ccd08ad2
INFO 01-05 12:51:19.974390.974390 client.py:127] Model loaded
DEBUG 01-05 12:51:19.974432.974432 cuda_h.py:19] end wait_experts cost 0.011252403259277344 seconds
DEBUG 01-05 12:51:19.974678.974678 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:19.974666.974666 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:19.974824.974824 mlpmodule.py:531] gpu group tensors cost 0.0005044937133789062 s
DEBUG 01-05 12:51:19.976422.976422 mlpmodule.py:564] gpu pad cost 0.0014042854309082031 s
DEBUG 01-05 12:51:19.976334.976334 mlpmodule.py:582] gpu group einsum cost 0.000461578369140625 s
DEBUG 01-05 12:51:19.979625.979625 mlpmodule.py:662]  experts func einsum cost 0.05496788024902344 s
DEBUG 01-05 12:51:19.979797.979797 mlpmodule.py:611] gpu experts func einsum cost 0.0054323673248291016 s
DEBUG 01-05 12:51:19.980495.980495 cuda_h.py:19] end gpu_experts cost 0.005599021911621094 seconds
DEBUG 01-05 12:51:19.980842.980842 cuda_h.py:19] end layer_moe_generate_18 cost 0.06354975700378418 seconds
DEBUG 01-05 12:51:19.980742.980742 lmp.py:217] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 12:51:19.980220.980220 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 12:51:19.980963.980963 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 12:51:19.980242.980242 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 12:51:19.980522.980522 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.8623809814453125e-05 seconds
DEBUG 01-05 12:51:19.980987.980987 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.05718994140625e-05 seconds
DEBUG 01-05 12:51:19.980107.980107 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:19.980116.980116 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:19.980019.980019 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.980087.980087 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.980442.980442 cuda_h.py:19] end allocate_cuda_memory cost 0.0002987384796142578 seconds
DEBUG 01-05 12:51:19.981173.981173 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.981506.981506 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.981514.981514 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.981879.981879 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 73ff3134-eda7-4b85-a3c5-98c4fed1e36c
DEBUG 01-05 12:51:19.981895.981895 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:19.981909.981909 cuda_h.py:10] start self_attn
INFO 01-05 12:51:19.982452.982452 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 73ff3134-eda7-4b85-a3c5-98c4fed1e36c
DEBUG 01-05 12:51:19.982858.982858 cuda_h.py:19] end load_into_gpu_async cost 0.0014176368713378906 seconds
DEBUG 01-05 12:51:19.982984.982984 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.982868.982868 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-05 12:51:19.982763.982763 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002028226852416992 seconds
INFO 01-05 12:51:19.983692.983692 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 73ff3134-eda7-4b85-a3c5-98c4fed1e36c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:19.985005.985005 cuda_h.py:19] end self_attn cost 0.003802776336669922 seconds
DEBUG 01-05 12:51:19.985021.985021 cuda_h.py:19] end iln_self_attn_paln cost 0.005140542984008789 seconds
DEBUG 01-05 12:51:19.985480.985480 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 12:51:19.985481.985481 cuda_h.py:10] start gate
DEBUG 01-05 12:51:19.986954.986954 cuda_h.py:19] end gate cost 0.0006289482116699219 seconds
DEBUG 01-05 12:51:19.986307.986307 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:19.986939.986939 lmp.py:365] 
DEBUG 01-05 12:51:19.986939.986939 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:19.986086.986086 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:19.986689.986689 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:19.986478.986478 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:19.986406.986406 lmp.py:369] 
DEBUG 01-05 12:51:19.986406.986406 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:19.986810.986810 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:19.986698.986698 lmp.py:376]   Expert 48 |     28 | CPU
DEBUG 01-05 12:51:19.986341.986341 lmp.py:376]   Expert 52 |     39 | CPU
DEBUG 01-05 12:51:19.986269.986269 lmp.py:376]   Expert 55 |     39 | CPU
DEBUG 01-05 12:51:19.986627.986627 lmp.py:376]   Expert 56 |     44 | CPU
DEBUG 01-05 12:51:19.986270.986270 lmp.py:376]   Expert 44 |     50 | CPU
DEBUG 01-05 12:51:19.986437.986437 lmp.py:376]   Expert  6 |     55 | CPU
DEBUG 01-05 12:51:19.986080.986080 lmp.py:376]   Expert  5 |     63 | CPU
DEBUG 01-05 12:51:19.986722.986722 lmp.py:376]   Expert 23 |     66 | CPU
DEBUG 01-05 12:51:19.986412.986412 lmp.py:376]   Expert 27 |     66 | CPU
DEBUG 01-05 12:51:19.987339.987339 lmp.py:376]   Expert 59 |     69 | CPU
DEBUG 01-05 12:51:19.987029.987029 lmp.py:376]   Expert 57 |     78 | CPU
DEBUG 01-05 12:51:19.987718.987718 lmp.py:376]   Expert 30 |     79 | CPU
DEBUG 01-05 12:51:19.987407.987407 lmp.py:376]   Expert 40 |     84 | CPU
DEBUG 01-05 12:51:19.987620.987620 lmp.py:376]   Expert 18 |     93 | CPU
DEBUG 01-05 12:51:19.987071.987071 lmp.py:376]   Expert 12 |     94 | CPU
DEBUG 01-05 12:51:19.987760.987760 lmp.py:376]   Expert 34 |     96 | CPU
DEBUG 01-05 12:51:19.987741.987741 lmp.py:376]   Expert 33 |     98 | CPU
DEBUG 01-05 12:51:19.987430.987430 lmp.py:376]   Expert 16 |    104 | CPU
DEBUG 01-05 12:51:19.987643.987643 lmp.py:376]   Expert 42 |    111 | CPU
DEBUG 01-05 12:51:19.987094.987094 lmp.py:376]   Expert 26 |    117 | CPU
DEBUG 01-05 12:51:19.987498.987498 lmp.py:376]   Expert  0 |    120 | CPU
DEBUG 01-05 12:51:19.987234.987234 lmp.py:376]   Expert 46 |    122 | CPU
DEBUG 01-05 12:51:19.987731.987731 lmp.py:376]   Expert  8 |    126 | CPU
DEBUG 01-05 12:51:19.987990.987990 lmp.py:376]   Expert 60 |    128 | CPU
DEBUG 01-05 12:51:19.987725.987725 lmp.py:376]   Expert 63 |    129 | CPU
DEBUG 01-05 12:51:19.987223.987223 lmp.py:376]   Expert 54 |    134 | CPU
DEBUG 01-05 12:51:19.987958.987958 lmp.py:376]   Expert 15 |    136 | CPU
DEBUG 01-05 12:51:19.987217.987217 lmp.py:376]   Expert 37 |    140 | CPU
DEBUG 01-05 12:51:19.987191.987191 lmp.py:376]   Expert 62 |    141 | CPU
DEBUG 01-05 12:51:19.987450.987450 lmp.py:376]   Expert 53 |    143 | CPU
DEBUG 01-05 12:51:19.987139.987139 lmp.py:376]   Expert 39 |    147 | CPU
DEBUG 01-05 12:51:19.987067.987067 lmp.py:376]   Expert 32 |    150 | CPU
DEBUG 01-05 12:51:19.987756.987756 lmp.py:376]   Expert 24 |    151 | GPU
DEBUG 01-05 12:51:19.987922.987922 lmp.py:376]   Expert 58 |    154 | GPU
DEBUG 01-05 12:51:19.987373.987373 lmp.py:376]   Expert 14 |    155 | GPU
DEBUG 01-05 12:51:19.987109.987109 lmp.py:376]   Expert  4 |    157 | GPU
DEBUG 01-05 12:51:19.987083.987083 lmp.py:376]   Expert 13 |    158 | GPU
DEBUG 01-05 12:51:19.987580.987580 lmp.py:376]   Expert  1 |    161 | GPU
DEBUG 01-05 12:51:19.987316.987316 lmp.py:376]   Expert 43 |    171 | GPU
DEBUG 01-05 12:51:19.987574.987574 lmp.py:376]   Expert 50 |    177 | GPU
DEBUG 01-05 12:51:19.987548.987548 lmp.py:376]   Expert 61 |    178 | GPU
DEBUG 01-05 12:51:19.987046.987046 lmp.py:376]   Expert 47 |    179 | GPU
DEBUG 01-05 12:51:19.987020.987020 lmp.py:376]   Expert 28 |    208 | GPU
DEBUG 01-05 12:51:19.987755.987755 lmp.py:376]   Expert 49 |    219 | GPU
DEBUG 01-05 12:51:19.987683.987683 lmp.py:376]   Expert 20 |    222 | GPU
DEBUG 01-05 12:51:19.987134.987134 lmp.py:376]   Expert 41 |    235 | GPU
DEBUG 01-05 12:51:19.987062.987062 lmp.py:376]   Expert 17 |    239 | GPU
DEBUG 01-05 12:51:19.987751.987751 lmp.py:376]   Expert 22 |    252 | GPU
DEBUG 01-05 12:51:19.987487.987487 lmp.py:376]   Expert 21 |    262 | GPU
DEBUG 01-05 12:51:19.987222.987222 lmp.py:376]   Expert 25 |    263 | GPU
DEBUG 01-05 12:51:19.987481.987481 lmp.py:376]   Expert 35 |    263 | GPU
DEBUG 01-05 12:51:19.987217.987217 lmp.py:376]   Expert 51 |    273 | GPU
DEBUG 01-05 12:51:19.987475.987475 lmp.py:376]   Expert 38 |    286 | GPU
DEBUG 01-05 12:51:19.987734.987734 lmp.py:376]   Expert 11 |    291 | GPU
DEBUG 01-05 12:51:19.987470.987470 lmp.py:376]   Expert  2 |    323 | GPU
DEBUG 01-05 12:51:19.987967.987967 lmp.py:376]   Expert 31 |    330 | GPU
DEBUG 01-05 12:51:19.987941.987941 lmp.py:376]   Expert 36 |    344 | GPU
DEBUG 01-05 12:51:19.987438.987438 lmp.py:376]   Expert 29 |    387 | GPU
DEBUG 01-05 12:51:19.987936.987936 lmp.py:376]   Expert 10 |    401 | GPU
DEBUG 01-05 12:51:19.987671.987671 lmp.py:376]   Expert 45 |    416 | GPU
DEBUG 01-05 12:51:19.987122.987122 lmp.py:376]   Expert  3 |    433 | GPU
DEBUG 01-05 12:51:19.987811.987811 lmp.py:376]   Expert  9 |    576 | GPU
DEBUG 01-05 12:51:19.987262.987262 lmp.py:376]   Expert 19 |    665 | GPU
DEBUG 01-05 12:51:19.987236.987236 lmp.py:376]   Expert  7 |    670 | GPU
DEBUG 01-05 12:51:19.987164.987164 lmp.py:377] 
DEBUG 01-05 12:51:19.987164.987164 lmp.py:377]   CPU total tokens: 3089 (25.1%)
DEBUG 01-05 12:51:19.987092.987092 lmp.py:378]   GPU total tokens: 9199 (74.9%)
DEBUG 01-05 12:51:19.987073.987073 cuda_h.py:19] end experts_map_get cost 0.0014827251434326172 seconds
DEBUG 01-05 12:51:19.987762.987762 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:19.987916.987916 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:19.988529.988529 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:19.989613.989613 cuda_h.py:19] end allocate_cuda_memory cost 0.0016791820526123047 seconds
DEBUG 01-05 12:51:19.989907.989907 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:19.989710.989710 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:19.989426.989426 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:19.990268.990268 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c25ba82-d849-4f8a-8348-75a67ef198a7
DEBUG 01-05 12:51:19.990281.990281 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:19.990836.990836 client.py:127] Model loaded
DEBUG 01-05 12:51:19.990024.990024 cuda_h.py:19] end sllm_worker_task cost 0.010046958923339844 seconds
INFO 01-05 12:51:19.991598.991598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c25ba82-d849-4f8a-8348-75a67ef198a7
DEBUG 01-05 12:51:19.991872.991872 cuda_h.py:19] end load_into_gpu_async cost 0.0012753009796142578 seconds
DEBUG 01-05 12:51:19.991859.991859 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:19.991717.991717 cuda_h.py:19] end restore_tensors2 cost 0.00029158592224121094 seconds
DEBUG 01-05 12:51:19.991586.991586 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035982131958007812 seconds
DEBUG 01-05 12:51:19.994219.994219 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006314754486083984 seconds
DEBUG 01-05 12:51:19.994241.994241 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:19.994819.994819 lmp.py:423] 
DEBUG 01-05 12:51:19.994819.994819 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:19.994417.994417 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-05 12:51:19.994041.994041 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:19.999253.999253 mlpmodule.py:704] group tensors cost 0.005206108093261719 s
DEBUG 01-05 12:51:20.002660.002660 mlpmodule.py:742] pad cost 0.001791238784790039 s
DEBUG 01-05 12:51:20.002855.002855 mlpmodule.py:748] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-05 12:51:20.002957.002957 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 12:51:20.012488.012488 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.012626.012626 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.012047.012047 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-05 12:51:20.012689.012689 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.028455.028455 mlpmodule.py:793] group einsum cost 0.026062965393066406 s
DEBUG 01-05 12:51:20.029495.029495 mlpmodule.py:801] cpy2cputensor cost 0.000614166259765625 s
DEBUG 01-05 12:51:20.034642.034642 cuda_h.py:19] end wait_cetm_experts cost 0.03964519500732422 seconds
DEBUG 01-05 12:51:20.034599.034599 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.034312.034312 cuda_h.py:19] end gpu_sexperts cost 0.0004696846008300781 seconds
DEBUG 01-05 12:51:20.034918.034918 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.035557.035557 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-05 12:51:20.035227.035227 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.035367.035367 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c25ba82-d849-4f8a-8348-75a67ef198a7
INFO 01-05 12:51:20.044397.044397 client.py:127] Model loaded
DEBUG 01-05 12:51:20.044055.044055 cuda_h.py:19] end wait_experts cost 0.009460926055908203 seconds
DEBUG 01-05 12:51:20.044996.044996 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.044699.044699 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.045188.045188 mlpmodule.py:531] gpu group tensors cost 0.0005023479461669922 s
DEBUG 01-05 12:51:20.046093.046093 mlpmodule.py:564] gpu pad cost 0.0014181137084960938 s
DEBUG 01-05 12:51:20.047377.047377 mlpmodule.py:582] gpu group einsum cost 0.0004901885986328125 s
DEBUG 01-05 12:51:20.050842.050842 mlpmodule.py:611] gpu experts func einsum cost 0.005409717559814453 s
DEBUG 01-05 12:51:20.050323.050323 cuda_h.py:19] end gpu_experts cost 0.005587339401245117 seconds
DEBUG 01-05 12:51:20.050915.050915 cuda_h.py:19] end layer_moe_generate_19 cost 0.06458044052124023 seconds
DEBUG 01-05 12:51:20.050688.050688 lmp.py:217] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 12:51:20.050690.050690 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 12:51:20.050670.050670 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 12:51:20.050711.050711 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 12:51:20.050786.050786 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.8133392333984375e-05 seconds
DEBUG 01-05 12:51:20.050343.050343 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.8650970458984375e-05 seconds
DEBUG 01-05 12:51:20.050986.050986 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.050954.050954 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.050103.050103 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.050839.050839 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.051937.051937 cuda_h.py:19] end allocate_cuda_memory cost 0.0004925727844238281 seconds
DEBUG 01-05 12:51:20.051570.051570 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.051425.051425 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.051195.051195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.051036.051036 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 199b05f5-41ea-41f6-8547-f05a1cd7d94c
DEBUG 01-05 12:51:20.051768.051768 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.051798.051798 mlpmodule.py:662]  experts func einsum cost 0.05709981918334961 s
DEBUG 01-05 12:51:20.051886.051886 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.052634.052634 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 199b05f5-41ea-41f6-8547-f05a1cd7d94c
DEBUG 01-05 12:51:20.052517.052517 cuda_h.py:19] end load_into_gpu_async cost 0.0011556148529052734 seconds
DEBUG 01-05 12:51:20.052405.052405 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.052289.052289 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-05 12:51:20.052422.052422 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019953250885009766 seconds
INFO 01-05 12:51:20.053862.053862 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 199b05f5-41ea-41f6-8547-f05a1cd7d94c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.055455.055455 cuda_h.py:19] end self_attn cost 0.0030951499938964844 seconds
DEBUG 01-05 12:51:20.055120.055120 cuda_h.py:19] end iln_self_attn_paln cost 0.0047762393951416016 seconds
DEBUG 01-05 12:51:20.055288.055288 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 12:51:20.055143.055143 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.056030.056030 cuda_h.py:19] end gate cost 0.0005512237548828125 seconds
DEBUG 01-05 12:51:20.056091.056091 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.056274.056274 lmp.py:365] 
DEBUG 01-05 12:51:20.056274.056274 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.056699.056699 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.056633.056633 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.056707.056707 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.056396.056396 lmp.py:369] 
DEBUG 01-05 12:51:20.056396.056396 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.056562.056562 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.056735.056735 lmp.py:376]   Expert  8 |     17 | CPU
DEBUG 01-05 12:51:20.056901.056901 lmp.py:376]   Expert 13 |     33 | CPU
DEBUG 01-05 12:51:20.056352.056352 lmp.py:376]   Expert 54 |     35 | CPU
DEBUG 01-05 12:51:20.056565.056565 lmp.py:376]   Expert 28 |     62 | CPU
DEBUG 01-05 12:51:20.056777.056777 lmp.py:376]   Expert 36 |     64 | CPU
DEBUG 01-05 12:51:20.056751.056751 lmp.py:376]   Expert  1 |     65 | CPU
DEBUG 01-05 12:51:20.056202.056202 lmp.py:376]   Expert 33 |     69 | CPU
DEBUG 01-05 12:51:20.056891.056891 lmp.py:376]   Expert 11 |     73 | CPU
DEBUG 01-05 12:51:20.056865.056865 lmp.py:376]   Expert 43 |     75 | CPU
DEBUG 01-05 12:51:20.056078.056078 lmp.py:376]   Expert 12 |     78 | CPU
DEBUG 01-05 12:51:20.056529.056529 lmp.py:376]   Expert 14 |     78 | CPU
DEBUG 01-05 12:51:20.056264.056264 lmp.py:376]   Expert 42 |     81 | CPU
DEBUG 01-05 12:51:20.056623.056623 lmp.py:376]   Expert 51 |     84 | CPU
DEBUG 01-05 12:51:20.056789.056789 lmp.py:376]   Expert  6 |     89 | CPU
DEBUG 01-05 12:51:20.056478.056478 lmp.py:376]   Expert 10 |     92 | CPU
DEBUG 01-05 12:51:20.056167.056167 lmp.py:376]   Expert  3 |     93 | CPU
DEBUG 01-05 12:51:20.056095.056095 lmp.py:376]   Expert 19 |     95 | CPU
DEBUG 01-05 12:51:20.056791.056791 lmp.py:376]   Expert  9 |     98 | CPU
DEBUG 01-05 12:51:20.056242.056242 lmp.py:376]   Expert 29 |     98 | CPU
DEBUG 01-05 12:51:20.056216.056216 lmp.py:376]   Expert 38 |    104 | CPU
DEBUG 01-05 12:51:20.056952.056952 lmp.py:376]   Expert 46 |    109 | CPU
DEBUG 01-05 12:51:20.056926.056926 lmp.py:376]   Expert 20 |    117 | CPU
DEBUG 01-05 12:51:20.056661.056661 lmp.py:376]   Expert 61 |    125 | CPU
DEBUG 01-05 12:51:20.056159.056159 lmp.py:376]   Expert 17 |    138 | CPU
DEBUG 01-05 12:51:20.056894.056894 lmp.py:376]   Expert 44 |    138 | CPU
DEBUG 01-05 12:51:20.056868.056868 lmp.py:376]   Expert  0 |    141 | CPU
DEBUG 01-05 12:51:20.057365.057365 lmp.py:376]   Expert 18 |    141 | CPU
DEBUG 01-05 12:51:20.057339.057339 lmp.py:376]   Expert 57 |    144 | CPU
DEBUG 01-05 12:51:20.057313.057313 lmp.py:376]   Expert 63 |    145 | CPU
DEBUG 01-05 12:51:20.057811.057811 lmp.py:376]   Expert 49 |    147 | CPU
DEBUG 01-05 12:51:20.057023.057023 lmp.py:376]   Expert 21 |    154 | CPU
DEBUG 01-05 12:51:20.057759.057759 lmp.py:376]   Expert  5 |    157 | CPU
DEBUG 01-05 12:51:20.057733.057733 lmp.py:376]   Expert 62 |    159 | GPU
DEBUG 01-05 12:51:20.057230.057230 lmp.py:376]   Expert 26 |    160 | GPU
DEBUG 01-05 12:51:20.057442.057442 lmp.py:376]   Expert 52 |    161 | GPU
DEBUG 01-05 12:51:20.057655.057655 lmp.py:376]   Expert 50 |    163 | GPU
DEBUG 01-05 12:51:20.057391.057391 lmp.py:376]   Expert 39 |    165 | GPU
DEBUG 01-05 12:51:20.057365.057365 lmp.py:376]   Expert 55 |    174 | GPU
DEBUG 01-05 12:51:20.057100.057100 lmp.py:376]   Expert 23 |    211 | GPU
DEBUG 01-05 12:51:20.057074.057074 lmp.py:376]   Expert 30 |    213 | GPU
DEBUG 01-05 12:51:20.057287.057287 lmp.py:376]   Expert  7 |    214 | GPU
DEBUG 01-05 12:51:20.057022.057022 lmp.py:376]   Expert 47 |    219 | GPU
DEBUG 01-05 12:51:20.057758.057758 lmp.py:376]   Expert 37 |    224 | GPU
DEBUG 01-05 12:51:20.057255.057255 lmp.py:376]   Expert 16 |    243 | GPU
DEBUG 01-05 12:51:20.057991.057991 lmp.py:376]   Expert 58 |    246 | GPU
DEBUG 01-05 12:51:20.057726.057726 lmp.py:376]   Expert 27 |    248 | GPU
DEBUG 01-05 12:51:20.057939.057939 lmp.py:376]   Expert 53 |    248 | GPU
DEBUG 01-05 12:51:20.057436.057436 lmp.py:376]   Expert 22 |    250 | GPU
DEBUG 01-05 12:51:20.057410.057410 lmp.py:376]   Expert 32 |    251 | GPU
DEBUG 01-05 12:51:20.057907.057907 lmp.py:376]   Expert 24 |    255 | GPU
DEBUG 01-05 12:51:20.057881.057881 lmp.py:376]   Expert 60 |    265 | GPU
DEBUG 01-05 12:51:20.057379.057379 lmp.py:376]   Expert 45 |    266 | GPU
DEBUG 01-05 12:51:20.057353.057353 lmp.py:376]   Expert 41 |    268 | GPU
DEBUG 01-05 12:51:20.057327.057327 lmp.py:376]   Expert 48 |    282 | GPU
DEBUG 01-05 12:51:20.057062.057062 lmp.py:376]   Expert 56 |    282 | GPU
DEBUG 01-05 12:51:20.057036.057036 lmp.py:376]   Expert  2 |    295 | GPU
DEBUG 01-05 12:51:20.057772.057772 lmp.py:376]   Expert  4 |    301 | GPU
DEBUG 01-05 12:51:20.057746.057746 lmp.py:376]   Expert 34 |    320 | GPU
DEBUG 01-05 12:51:20.057243.057243 lmp.py:376]   Expert 15 |    323 | GPU
DEBUG 01-05 12:51:20.057217.057217 lmp.py:376]   Expert 40 |    327 | GPU
DEBUG 01-05 12:51:20.057191.057191 lmp.py:376]   Expert 59 |    357 | GPU
DEBUG 01-05 12:51:20.057927.057927 lmp.py:376]   Expert 31 |    391 | GPU
DEBUG 01-05 12:51:20.057663.057663 lmp.py:376]   Expert 25 |    812 | GPU
DEBUG 01-05 12:51:20.057160.057160 lmp.py:376]   Expert 35 |    856 | GPU
DEBUG 01-05 12:51:20.057849.057849 lmp.py:377] 
DEBUG 01-05 12:51:20.057849.057849 lmp.py:377]   CPU total tokens: 3139 (25.5%)
DEBUG 01-05 12:51:20.057777.057777 lmp.py:378]   GPU total tokens: 9149 (74.5%)
DEBUG 01-05 12:51:20.057473.057473 cuda_h.py:19] end experts_map_get cost 0.0014846324920654297 seconds
DEBUG 01-05 12:51:20.057401.057401 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.057892.057892 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.057010.057010 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.058826.058826 cuda_h.py:19] end allocate_cuda_memory cost 0.0002181529998779297 seconds
DEBUG 01-05 12:51:20.058001.058001 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.058942.058942 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.058274.058274 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.058970.058970 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a08aec3-2532-400a-bd93-656696122769
DEBUG 01-05 12:51:20.058254.058254 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:20.071217.071217 client.py:127] Model loaded
DEBUG 01-05 12:51:20.071520.071520 cuda_h.py:19] end sllm_worker_task cost 0.02115011215209961 seconds
INFO 01-05 12:51:20.072266.072266 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a08aec3-2532-400a-bd93-656696122769
DEBUG 01-05 12:51:20.072622.072622 cuda_h.py:19] end load_into_gpu_async cost 0.014560699462890625 seconds
DEBUG 01-05 12:51:20.072400.072400 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.073459.073459 cuda_h.py:19] end restore_tensors2 cost 0.0007030963897705078 seconds
DEBUG 01-05 12:51:20.073106.073106 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01602959632873535 seconds
DEBUG 01-05 12:51:20.081623.081623 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.024204730987548828 seconds
DEBUG 01-05 12:51:20.082615.082615 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.082562.082562 lmp.py:423] 
DEBUG 01-05 12:51:20.082562.082562 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.082726.082726 cuda_h.py:19] end cpu_experts_submit cost 0.0002739429473876953 seconds
DEBUG 01-05 12:51:20.082265.082265 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.099733.099733 mlpmodule.py:704] group tensors cost 0.0168609619140625 s
DEBUG 01-05 12:51:20.102267.102267 mlpmodule.py:742] pad cost 0.001984119415283203 s
DEBUG 01-05 12:51:20.102715.102715 mlpmodule.py:748] create cpu tensor cost 4.982948303222656e-05 s
DEBUG 01-05 12:51:20.102254.102254 mlpmodule.py:753] move to cpu cost 3.695487976074219e-05 s
DEBUG 01-05 12:51:20.112812.112812 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.112628.112628 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.112379.112379 mlpmodule.py:773] group_w3 first element: -0.046630859375
WARNING 01-05 12:51:20.112695.112695 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.130326.130326 mlpmodule.py:793] group einsum cost 0.02837991714477539 s
DEBUG 01-05 12:51:20.131591.131591 mlpmodule.py:801] cpy2cputensor cost 0.0006034374237060547 s
DEBUG 01-05 12:51:20.136590.136590 cuda_h.py:19] end wait_cetm_experts cost 0.05412459373474121 seconds
DEBUG 01-05 12:51:20.136599.136599 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.137093.137093 cuda_h.py:19] end gpu_sexperts cost 0.0004642009735107422 seconds
DEBUG 01-05 12:51:20.137883.137883 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.137309.137309 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:20.137204.137204 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.137914.137914 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a08aec3-2532-400a-bd93-656696122769
INFO 01-05 12:51:20.138855.138855 client.py:127] Model loaded
DEBUG 01-05 12:51:20.138406.138406 cuda_h.py:19] end wait_experts cost 0.0010671615600585938 seconds
DEBUG 01-05 12:51:20.138825.138825 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.138256.138256 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.139703.139703 mlpmodule.py:531] gpu group tensors cost 0.0006017684936523438 s
DEBUG 01-05 12:51:20.141477.141477 mlpmodule.py:564] gpu pad cost 0.001710653305053711 s
DEBUG 01-05 12:51:20.141576.141576 mlpmodule.py:582] gpu group einsum cost 0.0004911422729492188 s
DEBUG 01-05 12:51:20.145326.145326 mlpmodule.py:611] gpu experts func einsum cost 0.006362199783325195 s
DEBUG 01-05 12:51:20.145455.145455 cuda_h.py:19] end gpu_experts cost 0.006545543670654297 seconds
DEBUG 01-05 12:51:20.145915.145915 cuda_h.py:19] end layer_moe_generate_20 cost 0.08972334861755371 seconds
DEBUG 01-05 12:51:20.145345.145345 lmp.py:217] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 12:51:20.145300.145300 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 12:51:20.145857.145857 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 12:51:20.145713.145713 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 12:51:20.145324.145324 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.3855438232421875e-05 seconds
DEBUG 01-05 12:51:20.145737.145737 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.145202.145202 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 0.0001537799835205078 seconds
DEBUG 01-05 12:51:20.145225.145225 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.145253.145253 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.145290.145290 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.148638.148638 cuda_h.py:19] end allocate_cuda_memory cost 0.0027527809143066406 seconds
DEBUG 01-05 12:51:20.148264.148264 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.148888.148888 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.149824.149824 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.149957.149957 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1c33fc54-ece2-4d7f-8123-1b46ff4bc058
DEBUG 01-05 12:51:20.149311.149311 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.149954.149954 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.150254.150254 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1c33fc54-ece2-4d7f-8123-1b46ff4bc058
DEBUG 01-05 12:51:20.150475.150475 cuda_h.py:19] end load_into_gpu_async cost 0.0010995864868164062 seconds
DEBUG 01-05 12:51:20.150032.150032 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.150253.150253 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-05 12:51:20.150056.150056 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004317522048950195 seconds
INFO 01-05 12:51:20.150299.150299 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1c33fc54-ece2-4d7f-8123-1b46ff4bc058
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.153395.153395 cuda_h.py:19] end self_attn cost 0.0034062862396240234 seconds
DEBUG 01-05 12:51:20.153696.153696 cuda_h.py:19] end iln_self_attn_paln cost 0.007295131683349609 seconds
DEBUG 01-05 12:51:20.153062.153062 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 12:51:20.153401.153401 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.154265.154265 cuda_h.py:19] end gate cost 0.0006387233734130859 seconds
DEBUG 01-05 12:51:20.154095.154095 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.154541.154541 lmp.py:365] 
DEBUG 01-05 12:51:20.154541.154541 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.154582.154582 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.154947.154947 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.154259.154259 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.154664.154664 lmp.py:369] 
DEBUG 01-05 12:51:20.154664.154664 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.154022.154022 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.154910.154910 lmp.py:376]   Expert 44 |     18 | CPU
DEBUG 01-05 12:51:20.154791.154791 lmp.py:376]   Expert 56 |     29 | CPU
DEBUG 01-05 12:51:20.154196.154196 lmp.py:376]   Expert  9 |     35 | CPU
DEBUG 01-05 12:51:20.154839.154839 lmp.py:376]   Expert 26 |     46 | CPU
DEBUG 01-05 12:51:20.154005.154005 lmp.py:376]   Expert  1 |     52 | CPU
DEBUG 01-05 12:51:20.154887.154887 lmp.py:376]   Expert 60 |     52 | CPU
DEBUG 01-05 12:51:20.154814.154814 lmp.py:376]   Expert 35 |     61 | CPU
DEBUG 01-05 12:51:20.154742.154742 lmp.py:376]   Expert 32 |     62 | CPU
DEBUG 01-05 12:51:20.154431.154431 lmp.py:376]   Expert 19 |     66 | CPU
DEBUG 01-05 12:51:20.154074.154074 lmp.py:376]   Expert  6 |     73 | CPU
DEBUG 01-05 12:51:20.154240.154240 lmp.py:376]   Expert 53 |     73 | CPU
DEBUG 01-05 12:51:20.154407.154407 lmp.py:376]   Expert 57 |     74 | CPU
DEBUG 01-05 12:51:20.154096.154096 lmp.py:376]   Expert 49 |     75 | CPU
DEBUG 01-05 12:51:20.154024.154024 lmp.py:376]   Expert 23 |     82 | CPU
DEBUG 01-05 12:51:20.154951.154951 lmp.py:376]   Expert  8 |     83 | CPU
DEBUG 01-05 12:51:20.154402.154402 lmp.py:376]   Expert  3 |     86 | CPU
DEBUG 01-05 12:51:20.154853.154853 lmp.py:376]   Expert 15 |     86 | CPU
DEBUG 01-05 12:51:20.154304.154304 lmp.py:376]   Expert 51 |     87 | CPU
DEBUG 01-05 12:51:20.154278.154278 lmp.py:376]   Expert 52 |     91 | CPU
DEBUG 01-05 12:51:20.154490.154490 lmp.py:376]   Expert 20 |     93 | CPU
DEBUG 01-05 12:51:20.154703.154703 lmp.py:376]   Expert 12 |     98 | CPU
DEBUG 01-05 12:51:20.154631.154631 lmp.py:376]   Expert 41 |     98 | CPU
DEBUG 01-05 12:51:20.154558.154558 lmp.py:376]   Expert 33 |    102 | CPU
DEBUG 01-05 12:51:20.154248.154248 lmp.py:376]   Expert 40 |    106 | CPU
DEBUG 01-05 12:51:20.154414.154414 lmp.py:376]   Expert 25 |    107 | CPU
DEBUG 01-05 12:51:20.154818.154818 lmp.py:376]   Expert 11 |    111 | CPU
DEBUG 01-05 12:51:20.155508.155508 lmp.py:376]   Expert 28 |    112 | CPU
DEBUG 01-05 12:51:20.155720.155720 lmp.py:376]   Expert 24 |    115 | CPU
DEBUG 01-05 12:51:20.155694.155694 lmp.py:376]   Expert 13 |    118 | CPU
DEBUG 01-05 12:51:20.155145.155145 lmp.py:376]   Expert 48 |    122 | CPU
DEBUG 01-05 12:51:20.155357.155357 lmp.py:376]   Expert 14 |    123 | CPU
DEBUG 01-05 12:51:20.155570.155570 lmp.py:376]   Expert 54 |    123 | CPU
DEBUG 01-05 12:51:20.155544.155544 lmp.py:376]   Expert 39 |    132 | GPU
DEBUG 01-05 12:51:20.155995.155995 lmp.py:376]   Expert 59 |    133 | GPU
DEBUG 01-05 12:51:20.155731.155731 lmp.py:376]   Expert  7 |    151 | GPU
DEBUG 01-05 12:51:20.155943.155943 lmp.py:376]   Expert 58 |    152 | GPU
DEBUG 01-05 12:51:20.155632.155632 lmp.py:376]   Expert 10 |    167 | GPU
DEBUG 01-05 12:51:20.155322.155322 lmp.py:376]   Expert 18 |    169 | GPU
DEBUG 01-05 12:51:20.155772.155772 lmp.py:376]   Expert 34 |    176 | GPU
DEBUG 01-05 12:51:20.155462.155462 lmp.py:376]   Expert 63 |    180 | GPU
DEBUG 01-05 12:51:20.155151.155151 lmp.py:376]   Expert 47 |    208 | GPU
DEBUG 01-05 12:51:20.155602.155602 lmp.py:376]   Expert  2 |    214 | GPU
DEBUG 01-05 12:51:20.155576.155576 lmp.py:376]   Expert 38 |    222 | GPU
DEBUG 01-05 12:51:20.155788.155788 lmp.py:376]   Expert 43 |    226 | GPU
DEBUG 01-05 12:51:20.155762.155762 lmp.py:376]   Expert  5 |    233 | GPU
DEBUG 01-05 12:51:20.155737.155737 lmp.py:376]   Expert 21 |    234 | GPU
DEBUG 01-05 12:51:20.155949.155949 lmp.py:376]   Expert 22 |    250 | GPU
DEBUG 01-05 12:51:20.155923.155923 lmp.py:376]   Expert 61 |    259 | GPU
DEBUG 01-05 12:51:20.155897.155897 lmp.py:376]   Expert 55 |    268 | GPU
DEBUG 01-05 12:51:20.155110.155110 lmp.py:376]   Expert 46 |    276 | GPU
DEBUG 01-05 12:51:20.155084.155084 lmp.py:376]   Expert  4 |    297 | GPU
DEBUG 01-05 12:51:20.155296.155296 lmp.py:376]   Expert 62 |    298 | GPU
DEBUG 01-05 12:51:20.155985.155985 lmp.py:376]   Expert 27 |    301 | GPU
DEBUG 01-05 12:51:20.155913.155913 lmp.py:376]   Expert  0 |    318 | GPU
DEBUG 01-05 12:51:20.155126.155126 lmp.py:376]   Expert 29 |    324 | GPU
DEBUG 01-05 12:51:20.155815.155815 lmp.py:376]   Expert 31 |    327 | GPU
DEBUG 01-05 12:51:20.155504.155504 lmp.py:376]   Expert 17 |    347 | GPU
DEBUG 01-05 12:51:20.155955.155955 lmp.py:376]   Expert 16 |    371 | GPU
DEBUG 01-05 12:51:20.155929.155929 lmp.py:376]   Expert 45 |    395 | GPU
DEBUG 01-05 12:51:20.155142.155142 lmp.py:376]   Expert 50 |    398 | GPU
DEBUG 01-05 12:51:20.155354.155354 lmp.py:376]   Expert 36 |    445 | GPU
DEBUG 01-05 12:51:20.155328.155328 lmp.py:376]   Expert 37 |    599 | GPU
DEBUG 01-05 12:51:20.155302.155302 lmp.py:376]   Expert 30 |    717 | GPU
DEBUG 01-05 12:51:20.155276.155276 lmp.py:376]   Expert 42 |    842 | GPU
DEBUG 01-05 12:51:20.155204.155204 lmp.py:377] 
DEBUG 01-05 12:51:20.155204.155204 lmp.py:377]   CPU total tokens: 2659 (21.6%)
DEBUG 01-05 12:51:20.155370.155370 lmp.py:378]   GPU total tokens: 9629 (78.4%)
DEBUG 01-05 12:51:20.155351.155351 cuda_h.py:19] end experts_map_get cost 0.0014951229095458984 seconds
DEBUG 01-05 12:51:20.155755.155755 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.155293.155293 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.155384.155384 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.157092.157092 cuda_h.py:19] end allocate_cuda_memory cost 0.0015420913696289062 seconds
DEBUG 01-05 12:51:20.157889.157889 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.157645.157645 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.157646.157646 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.157250.157250 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 27852590-a61f-409e-90ef-d7903dc71527
DEBUG 01-05 12:51:20.157686.157686 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.157618.157618 mlpmodule.py:662]  experts func einsum cost 0.07516813278198242 s
INFO 01-05 12:51:20.158199.158199 client.py:127] Model loaded
DEBUG 01-05 12:51:20.158440.158440 cuda_h.py:19] end sllm_worker_task cost 0.01234889030456543 seconds
INFO 01-05 12:51:20.158091.158091 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 27852590-a61f-409e-90ef-d7903dc71527
DEBUG 01-05 12:51:20.158364.158364 cuda_h.py:19] end load_into_gpu_async cost 0.0012998580932617188 seconds
DEBUG 01-05 12:51:20.158789.158789 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.159647.159647 cuda_h.py:19] end restore_tensors2 cost 0.00029158592224121094 seconds
DEBUG 01-05 12:51:20.159417.159417 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034749507904052734 seconds
DEBUG 01-05 12:51:20.161724.161724 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0061643123626708984 seconds
DEBUG 01-05 12:51:20.161077.161077 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.162107.162107 lmp.py:423] 
DEBUG 01-05 12:51:20.162107.162107 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.162804.162804 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-05 12:51:20.162930.162930 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.170159.170159 mlpmodule.py:704] group tensors cost 0.008465051651000977 s
DEBUG 01-05 12:51:20.172639.172639 mlpmodule.py:742] pad cost 0.0014367103576660156 s
DEBUG 01-05 12:51:20.172099.172099 mlpmodule.py:748] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-05 12:51:20.172564.172564 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-05 12:51:20.181837.181837 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.181670.181670 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.181944.181944 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 12:51:20.181260.181260 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.197136.197136 mlpmodule.py:793] group einsum cost 0.024719953536987305 s
DEBUG 01-05 12:51:20.198763.198763 mlpmodule.py:801] cpy2cputensor cost 0.0005211830139160156 s
DEBUG 01-05 12:51:20.203081.203081 cuda_h.py:19] end wait_cetm_experts cost 0.04104185104370117 seconds
DEBUG 01-05 12:51:20.203143.203143 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.203769.203769 cuda_h.py:19] end gpu_sexperts cost 0.0004546642303466797 seconds
DEBUG 01-05 12:51:20.203639.203639 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.203635.203635 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 12:51:20.203961.203961 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.203717.203717 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 27852590-a61f-409e-90ef-d7903dc71527
INFO 01-05 12:51:20.212195.212195 client.py:127] Model loaded
DEBUG 01-05 12:51:20.212184.212184 cuda_h.py:19] end wait_experts cost 0.008805990219116211 seconds
DEBUG 01-05 12:51:20.212840.212840 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.212543.212543 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.213072.213072 mlpmodule.py:531] gpu group tensors cost 0.0004961490631103516 s
DEBUG 01-05 12:51:20.214678.214678 mlpmodule.py:564] gpu pad cost 0.0014476776123046875 s
DEBUG 01-05 12:51:20.215306.215306 mlpmodule.py:582] gpu group einsum cost 0.0004608631134033203 s
DEBUG 01-05 12:51:20.218184.218184 mlpmodule.py:611] gpu experts func einsum cost 0.005422830581665039 s
DEBUG 01-05 12:51:20.218505.218505 cuda_h.py:19] end gpu_experts cost 0.005590200424194336 seconds
DEBUG 01-05 12:51:20.218567.218567 cuda_h.py:19] end layer_moe_generate_21 cost 0.06508588790893555 seconds
DEBUG 01-05 12:51:20.218063.218063 lmp.py:217] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 12:51:20.218779.218779 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 12:51:20.218760.218760 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 12:51:20.218562.218562 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 12:51:20.218498.218498 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.075599670410156e-05 seconds
DEBUG 01-05 12:51:20.218293.218293 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.103515625e-05 seconds
DEBUG 01-05 12:51:20.218413.218413 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.218999.218999 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.218240.218240 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.219307.219307 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.220010.220010 cuda_h.py:19] end allocate_cuda_memory cost 0.0015513896942138672 seconds
DEBUG 01-05 12:51:20.220153.220153 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.220300.220300 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.220646.220646 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.220918.220918 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc0e7e93-4a3d-4730-8446-f54fe508c18b
DEBUG 01-05 12:51:20.220080.220080 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.221601.221601 mlpmodule.py:662]  experts func einsum cost 0.05887460708618164 s
DEBUG 01-05 12:51:20.221845.221845 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.222601.222601 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc0e7e93-4a3d-4730-8446-f54fe508c18b
DEBUG 01-05 12:51:20.222152.222152 cuda_h.py:19] end load_into_gpu_async cost 0.0013306140899658203 seconds
DEBUG 01-05 12:51:20.222186.222186 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.222547.222547 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-05 12:51:20.222396.222396 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003244638442993164 seconds
INFO 01-05 12:51:20.222287.222287 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc0e7e93-4a3d-4730-8446-f54fe508c18b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.224462.224462 cuda_h.py:19] end self_attn cost 0.003126859664916992 seconds
DEBUG 01-05 12:51:20.224512.224512 cuda_h.py:19] end iln_self_attn_paln cost 0.0058727264404296875 seconds
DEBUG 01-05 12:51:20.224686.224686 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 12:51:20.224601.224601 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.225411.225411 cuda_h.py:19] end gate cost 0.0006337165832519531 seconds
DEBUG 01-05 12:51:20.225287.225287 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.225966.225966 lmp.py:365] 
DEBUG 01-05 12:51:20.225966.225966 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.225338.225338 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.225034.225034 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.225630.225630 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.225796.225796 lmp.py:369] 
DEBUG 01-05 12:51:20.225796.225796 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.225724.225724 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.225374.225374 lmp.py:376]   Expert 15 |     33 | CPU
DEBUG 01-05 12:51:20.225494.225494 lmp.py:376]   Expert 32 |     48 | CPU
DEBUG 01-05 12:51:20.226183.226183 lmp.py:376]   Expert 49 |     52 | CPU
DEBUG 01-05 12:51:20.226634.226634 lmp.py:376]   Expert 45 |     54 | CPU
DEBUG 01-05 12:51:20.226370.226370 lmp.py:376]   Expert 22 |     58 | CPU
DEBUG 01-05 12:51:20.226105.226105 lmp.py:376]   Expert  6 |     59 | CPU
DEBUG 01-05 12:51:20.226602.226602 lmp.py:376]   Expert 44 |     59 | CPU
DEBUG 01-05 12:51:20.226338.226338 lmp.py:376]   Expert 42 |     62 | CPU
DEBUG 01-05 12:51:20.226597.226597 lmp.py:376]   Expert 37 |     64 | CPU
DEBUG 01-05 12:51:20.226240.226240 lmp.py:376]   Expert 46 |     66 | CPU
DEBUG 01-05 12:51:20.226168.226168 lmp.py:376]   Expert 54 |     66 | CPU
DEBUG 01-05 12:51:20.226857.226857 lmp.py:376]   Expert 52 |     68 | CPU
DEBUG 01-05 12:51:20.226546.226546 lmp.py:376]   Expert 12 |     69 | CPU
DEBUG 01-05 12:51:20.226712.226712 lmp.py:376]   Expert 11 |     72 | CPU
DEBUG 01-05 12:51:20.226117.226117 lmp.py:376]   Expert 48 |     75 | CPU
DEBUG 01-05 12:51:20.226283.226283 lmp.py:376]   Expert 24 |     77 | CPU
DEBUG 01-05 12:51:20.226211.226211 lmp.py:376]   Expert 60 |     81 | CPU
DEBUG 01-05 12:51:20.226662.226662 lmp.py:376]   Expert 30 |     83 | CPU
DEBUG 01-05 12:51:20.226112.226112 lmp.py:376]   Expert 61 |     83 | CPU
DEBUG 01-05 12:51:20.226325.226325 lmp.py:376]   Expert 41 |     86 | CPU
DEBUG 01-05 12:51:20.226537.226537 lmp.py:376]   Expert 47 |     89 | CPU
DEBUG 01-05 12:51:20.226750.226750 lmp.py:376]   Expert  7 |     96 | CPU
DEBUG 01-05 12:51:20.226962.226962 lmp.py:376]   Expert 63 |     97 | CPU
DEBUG 01-05 12:51:20.226175.226175 lmp.py:376]   Expert 13 |    103 | CPU
DEBUG 01-05 12:51:20.226626.226626 lmp.py:376]   Expert 58 |    107 | CPU
DEBUG 01-05 12:51:20.226553.226553 lmp.py:376]   Expert 57 |    108 | CPU
DEBUG 01-05 12:51:20.226958.226958 lmp.py:376]   Expert  0 |    111 | CPU
DEBUG 01-05 12:51:20.226886.226886 lmp.py:376]   Expert 10 |    117 | CPU
DEBUG 01-05 12:51:20.226052.226052 lmp.py:376]   Expert  3 |    121 | CPU
DEBUG 01-05 12:51:20.226218.226218 lmp.py:376]   Expert 39 |    122 | CPU
DEBUG 01-05 12:51:20.226384.226384 lmp.py:376]   Expert 27 |    123 | CPU
DEBUG 01-05 12:51:20.226835.226835 lmp.py:376]   Expert  9 |    130 | CPU
DEBUG 01-05 12:51:20.226047.226047 lmp.py:376]   Expert 38 |    137 | GPU
DEBUG 01-05 12:51:20.226737.226737 lmp.py:376]   Expert 51 |    138 | GPU
DEBUG 01-05 12:51:20.226188.226188 lmp.py:376]   Expert 62 |    141 | GPU
DEBUG 01-05 12:51:20.226162.226162 lmp.py:376]   Expert 26 |    143 | GPU
DEBUG 01-05 12:51:20.226613.226613 lmp.py:376]   Expert 28 |    146 | GPU
DEBUG 01-05 12:51:20.226825.226825 lmp.py:376]   Expert 21 |    150 | GPU
DEBUG 01-05 12:51:20.226037.226037 lmp.py:376]   Expert  2 |    154 | GPU
DEBUG 01-05 12:51:20.226965.226965 lmp.py:376]   Expert 31 |    156 | GPU
DEBUG 01-05 12:51:20.226654.226654 lmp.py:376]   Expert 16 |    177 | GPU
DEBUG 01-05 12:51:20.226582.226582 lmp.py:376]   Expert 25 |    209 | GPU
DEBUG 01-05 12:51:20.226510.226510 lmp.py:376]   Expert  1 |    211 | GPU
DEBUG 01-05 12:51:20.226438.226438 lmp.py:376]   Expert 56 |    218 | GPU
DEBUG 01-05 12:51:20.226412.226412 lmp.py:376]   Expert 17 |    232 | GPU
DEBUG 01-05 12:51:20.226624.226624 lmp.py:376]   Expert 35 |    245 | GPU
DEBUG 01-05 12:51:20.226837.226837 lmp.py:376]   Expert 50 |    247 | GPU
DEBUG 01-05 12:51:20.226811.226811 lmp.py:376]   Expert 40 |    254 | GPU
DEBUG 01-05 12:51:20.226023.226023 lmp.py:376]   Expert 19 |    259 | GPU
DEBUG 01-05 12:51:20.226474.226474 lmp.py:376]   Expert 43 |    266 | GPU
DEBUG 01-05 12:51:20.226448.226448 lmp.py:376]   Expert 14 |    299 | GPU
DEBUG 01-05 12:51:20.226660.226660 lmp.py:376]   Expert 20 |    302 | GPU
DEBUG 01-05 12:51:20.226111.226111 lmp.py:376]   Expert  8 |    328 | GPU
DEBUG 01-05 12:51:20.226085.226085 lmp.py:376]   Expert 23 |    336 | GPU
DEBUG 01-05 12:51:20.226536.226536 lmp.py:376]   Expert 29 |    343 | GPU
DEBUG 01-05 12:51:20.226987.226987 lmp.py:376]   Expert  4 |    356 | GPU
DEBUG 01-05 12:51:20.226961.226961 lmp.py:376]   Expert 18 |    373 | GPU
DEBUG 01-05 12:51:20.226604.226604 lmp.py:376]   Expert 34 |    392 | GPU
DEBUG 01-05 12:51:20.226294.226294 lmp.py:376]   Expert 53 |    392 | GPU
DEBUG 01-05 12:51:20.226221.226221 lmp.py:376]   Expert 55 |    462 | GPU
DEBUG 01-05 12:51:20.226149.226149 lmp.py:376]   Expert 59 |    484 | GPU
DEBUG 01-05 12:51:20.226838.226838 lmp.py:376]   Expert 33 |    620 | GPU
DEBUG 01-05 12:51:20.227051.227051 lmp.py:376]   Expert 36 |    631 | GPU
DEBUG 01-05 12:51:20.227502.227502 lmp.py:376]   Expert  5 |    848 | GPU
DEBUG 01-05 12:51:20.227668.227668 lmp.py:377] 
DEBUG 01-05 12:51:20.227668.227668 lmp.py:377]   CPU total tokens: 2639 (21.5%)
DEBUG 01-05 12:51:20.227311.227311 lmp.py:378]   GPU total tokens: 9649 (78.5%)
DEBUG 01-05 12:51:20.227007.227007 cuda_h.py:19] end experts_map_get cost 0.0014865398406982422 seconds
DEBUG 01-05 12:51:20.227888.227888 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.227095.227095 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.227994.227994 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.228128.228128 cuda_h.py:19] end allocate_cuda_memory cost 0.0012233257293701172 seconds
DEBUG 01-05 12:51:20.228071.228071 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.228781.228781 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.228212.228212 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.228054.228054 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b939eba-f214-4a67-a3d2-77b57ca95196
DEBUG 01-05 12:51:20.228431.228431 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:20.230366.230366 client.py:127] Model loaded
DEBUG 01-05 12:51:20.230123.230123 cuda_h.py:19] end sllm_worker_task cost 0.011151552200317383 seconds
INFO 01-05 12:51:20.230138.230138 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b939eba-f214-4a67-a3d2-77b57ca95196
DEBUG 01-05 12:51:20.230888.230888 cuda_h.py:19] end load_into_gpu_async cost 0.002218961715698242 seconds
DEBUG 01-05 12:51:20.230068.230068 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.231443.231443 cuda_h.py:19] end restore_tensors2 cost 0.0002856254577636719 seconds
DEBUG 01-05 12:51:20.231689.231689 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00406646728515625 seconds
DEBUG 01-05 12:51:20.233844.233844 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0067517757415771484 seconds
DEBUG 01-05 12:51:20.233435.233435 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.233106.233106 lmp.py:423] 
DEBUG 01-05 12:51:20.233106.233106 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.234465.234465 cuda_h.py:19] end cpu_experts_submit cost 0.00010132789611816406 seconds
DEBUG 01-05 12:51:20.234805.234805 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.243711.243711 mlpmodule.py:704] group tensors cost 0.00934910774230957 s
DEBUG 01-05 12:51:20.246716.246716 mlpmodule.py:742] pad cost 0.0017981529235839844 s
DEBUG 01-05 12:51:20.246627.246627 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-05 12:51:20.246490.246490 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-05 12:51:20.254733.254733 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.255520.255520 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.255602.255602 mlpmodule.py:773] group_w3 first element: -0.018798828125
WARNING 01-05 12:51:20.255673.255673 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.271531.271531 mlpmodule.py:793] group einsum cost 0.025269746780395508 s
DEBUG 01-05 12:51:20.272311.272311 mlpmodule.py:801] cpy2cputensor cost 0.0005562305450439453 s
DEBUG 01-05 12:51:20.277641.277641 cuda_h.py:19] end wait_cetm_experts cost 0.043117523193359375 seconds
DEBUG 01-05 12:51:20.277458.277458 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.277475.277475 cuda_h.py:19] end gpu_sexperts cost 0.00046324729919433594 seconds
DEBUG 01-05 12:51:20.277311.277311 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.277784.277784 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:20.277679.277679 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.278435.278435 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b939eba-f214-4a67-a3d2-77b57ca95196
INFO 01-05 12:51:20.284824.284824 client.py:127] Model loaded
DEBUG 01-05 12:51:20.284005.284005 cuda_h.py:19] end wait_experts cost 0.0065631866455078125 seconds
DEBUG 01-05 12:51:20.284238.284238 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.284994.284994 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.285501.285501 mlpmodule.py:531] gpu group tensors cost 0.0006105899810791016 s
DEBUG 01-05 12:51:20.287676.287676 mlpmodule.py:564] gpu pad cost 0.0016205310821533203 s
DEBUG 01-05 12:51:20.287303.287303 mlpmodule.py:582] gpu group einsum cost 0.000453948974609375 s
DEBUG 01-05 12:51:20.290693.290693 mlpmodule.py:611] gpu experts func einsum cost 0.005771636962890625 s
DEBUG 01-05 12:51:20.290412.290412 cuda_h.py:19] end gpu_experts cost 0.005963802337646484 seconds
DEBUG 01-05 12:51:20.290998.290998 cuda_h.py:19] end layer_moe_generate_22 cost 0.06585931777954102 seconds
DEBUG 01-05 12:51:20.290567.290567 lmp.py:217] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 12:51:20.290707.290707 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 12:51:20.290926.290926 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 12:51:20.290205.290205 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 12:51:20.291757.291757 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.86102294921875e-05 seconds
DEBUG 01-05 12:51:20.291552.291552 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.793571472167969e-05 seconds
DEBUG 01-05 12:51:20.291195.291195 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.291594.291594 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.291704.291704 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.291732.291732 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.294330.294330 cuda_h.py:19] end allocate_cuda_memory cost 0.0031769275665283203 seconds
DEBUG 01-05 12:51:20.294168.294168 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.294798.294798 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.294058.294058 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.294523.294523 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 23db14a6-3d79-42ed-af5c-a5eb8b1e6567
DEBUG 01-05 12:51:20.294539.294539 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.294696.294696 mlpmodule.py:662]  experts func einsum cost 0.060721397399902344 s
DEBUG 01-05 12:51:20.295162.295162 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.296074.296074 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 23db14a6-3d79-42ed-af5c-a5eb8b1e6567
DEBUG 01-05 12:51:20.296162.296162 cuda_h.py:19] end load_into_gpu_async cost 0.0017693042755126953 seconds
DEBUG 01-05 12:51:20.296388.296388 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.296511.296511 cuda_h.py:19] end restore_tensors2 cost 6.365776062011719e-05 seconds
DEBUG 01-05 12:51:20.296836.296836 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005292177200317383 seconds
INFO 01-05 12:51:20.297290.297290 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 23db14a6-3d79-42ed-af5c-a5eb8b1e6567
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.298280.298280 cuda_h.py:19] end self_attn cost 0.003246307373046875 seconds
DEBUG 01-05 12:51:20.298150.298150 cuda_h.py:19] end iln_self_attn_paln cost 0.007733345031738281 seconds
DEBUG 01-05 12:51:20.298609.298609 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 12:51:20.298372.298372 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.299798.299798 cuda_h.py:19] end gate cost 0.0006318092346191406 seconds
DEBUG 01-05 12:51:20.299674.299674 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.299651.299651 lmp.py:365] 
DEBUG 01-05 12:51:20.299651.299651 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.299738.299738 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.299149.299149 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.299700.299700 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.300104.300104 lmp.py:369] 
DEBUG 01-05 12:51:20.300104.300104 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.300747.300747 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.300874.300874 lmp.py:376]   Expert 49 |     26 | CPU
DEBUG 01-05 12:51:20.300755.300755 lmp.py:376]   Expert  5 |     30 | CPU
DEBUG 01-05 12:51:20.300445.300445 lmp.py:376]   Expert 44 |     37 | CPU
DEBUG 01-05 12:51:20.300134.300134 lmp.py:376]   Expert 16 |     44 | CPU
DEBUG 01-05 12:51:20.300823.300823 lmp.py:376]   Expert  6 |     45 | CPU
DEBUG 01-05 12:51:20.300513.300513 lmp.py:376]   Expert 17 |     63 | CPU
DEBUG 01-05 12:51:20.300202.300202 lmp.py:376]   Expert 27 |     63 | CPU
DEBUG 01-05 12:51:20.300653.300653 lmp.py:376]   Expert 25 |     75 | CPU
DEBUG 01-05 12:51:20.300104.300104 lmp.py:376]   Expert 63 |     82 | CPU
DEBUG 01-05 12:51:20.300316.300316 lmp.py:376]   Expert  1 |     83 | CPU
DEBUG 01-05 12:51:20.300767.300767 lmp.py:376]   Expert 19 |     87 | CPU
DEBUG 01-05 12:51:20.300456.300456 lmp.py:376]   Expert  7 |     88 | CPU
DEBUG 01-05 12:51:20.300622.300622 lmp.py:376]   Expert 53 |     89 | CPU
DEBUG 01-05 12:51:20.300027.300027 lmp.py:376]   Expert 40 |     91 | CPU
DEBUG 01-05 12:51:20.300670.300670 lmp.py:376]   Expert 38 |     94 | CPU
DEBUG 01-05 12:51:20.300836.300836 lmp.py:376]   Expert 51 |     96 | CPU
DEBUG 01-05 12:51:20.300287.300287 lmp.py:376]   Expert 28 |    107 | CPU
DEBUG 01-05 12:51:20.300499.300499 lmp.py:376]   Expert 45 |    109 | CPU
DEBUG 01-05 12:51:20.300950.300950 lmp.py:376]   Expert 35 |    110 | CPU
DEBUG 01-05 12:51:20.300401.300401 lmp.py:376]   Expert  4 |    112 | CPU
DEBUG 01-05 12:51:20.300389.300389 lmp.py:376]   Expert 52 |    117 | CPU
DEBUG 01-05 12:51:20.300939.300939 lmp.py:376]   Expert 34 |    119 | CPU
DEBUG 01-05 12:51:20.300582.300582 lmp.py:376]   Expert 61 |    124 | CPU
DEBUG 01-05 12:51:20.300510.300510 lmp.py:376]   Expert 30 |    127 | CPU
DEBUG 01-05 12:51:20.300914.300914 lmp.py:376]   Expert 43 |    129 | CPU
DEBUG 01-05 12:51:20.300796.300796 lmp.py:376]   Expert 55 |    130 | CPU
DEBUG 01-05 12:51:20.300439.300439 lmp.py:376]   Expert 24 |    133 | CPU
DEBUG 01-05 12:51:20.300320.300320 lmp.py:376]   Expert 15 |    139 | CPU
DEBUG 01-05 12:51:20.300963.300963 lmp.py:376]   Expert 22 |    143 | CPU
DEBUG 01-05 12:51:20.300129.300129 lmp.py:376]   Expert 58 |    151 | CPU
DEBUG 01-05 12:51:20.300295.300295 lmp.py:376]   Expert 36 |    157 | CPU
DEBUG 01-05 12:51:20.300462.300462 lmp.py:376]   Expert 42 |    157 | CPU
DEBUG 01-05 12:51:20.300866.300866 lmp.py:376]   Expert 47 |    158 | GPU
DEBUG 01-05 12:51:20.300032.300032 lmp.py:376]   Expert  3 |    160 | GPU
DEBUG 01-05 12:51:20.300198.300198 lmp.py:376]   Expert 14 |    161 | GPU
DEBUG 01-05 12:51:20.300603.300603 lmp.py:376]   Expert 39 |    173 | GPU
DEBUG 01-05 12:51:20.300769.300769 lmp.py:376]   Expert 13 |    175 | GPU
DEBUG 01-05 12:51:20.300174.300174 lmp.py:376]   Expert  9 |    178 | GPU
DEBUG 01-05 12:51:20.300340.300340 lmp.py:376]   Expert 60 |    182 | GPU
DEBUG 01-05 12:51:20.300506.300506 lmp.py:376]   Expert 41 |    187 | GPU
DEBUG 01-05 12:51:20.300910.300910 lmp.py:376]   Expert  0 |    188 | GPU
DEBUG 01-05 12:51:20.300792.300792 lmp.py:376]   Expert 26 |    196 | GPU
DEBUG 01-05 12:51:20.300196.300196 lmp.py:376]   Expert 11 |    213 | GPU
DEBUG 01-05 12:51:20.300316.300316 lmp.py:376]   Expert 37 |    214 | GPU
DEBUG 01-05 12:51:20.300482.300482 lmp.py:376]   Expert  8 |    221 | GPU
DEBUG 01-05 12:51:20.300648.300648 lmp.py:376]   Expert 23 |    223 | GPU
DEBUG 01-05 12:51:20.300053.300053 lmp.py:376]   Expert 46 |    237 | GPU
DEBUG 01-05 12:51:20.300458.300458 lmp.py:376]   Expert 33 |    244 | GPU
DEBUG 01-05 12:51:20.300624.300624 lmp.py:376]   Expert 29 |    260 | GPU
DEBUG 01-05 12:51:20.300790.300790 lmp.py:376]   Expert 20 |    273 | GPU
DEBUG 01-05 12:51:20.300956.300956 lmp.py:376]   Expert 56 |    289 | GPU
DEBUG 01-05 12:51:20.300122.300122 lmp.py:376]   Expert 62 |    295 | GPU
DEBUG 01-05 12:51:20.300765.300765 lmp.py:376]   Expert 59 |    299 | GPU
DEBUG 01-05 12:51:20.300647.300647 lmp.py:376]   Expert 57 |    304 | GPU
DEBUG 01-05 12:51:20.300289.300289 lmp.py:376]   Expert 54 |    344 | GPU
DEBUG 01-05 12:51:20.301694.301694 lmp.py:376]   Expert 18 |    363 | GPU
DEBUG 01-05 12:51:20.301337.301337 lmp.py:376]   Expert 21 |    371 | GPU
DEBUG 01-05 12:51:20.301755.301755 lmp.py:376]   Expert  2 |    374 | GPU
DEBUG 01-05 12:51:20.301444.301444 lmp.py:376]   Expert 50 |    388 | GPU
DEBUG 01-05 12:51:20.301134.301134 lmp.py:376]   Expert 32 |    395 | GPU
DEBUG 01-05 12:51:20.301061.301061 lmp.py:376]   Expert 48 |    410 | GPU
DEBUG 01-05 12:51:20.301989.301989 lmp.py:376]   Expert 10 |    453 | GPU
DEBUG 01-05 12:51:20.301440.301440 lmp.py:376]   Expert 31 |    525 | GPU
DEBUG 01-05 12:51:20.301129.301129 lmp.py:376]   Expert 12 |    678 | GPU
DEBUG 01-05 12:51:20.301772.301772 lmp.py:377] 
DEBUG 01-05 12:51:20.301772.301772 lmp.py:377]   CPU total tokens: 3157 (25.7%)
DEBUG 01-05 12:51:20.301369.301369 lmp.py:378]   GPU total tokens: 9131 (74.3%)
DEBUG 01-05 12:51:20.301257.301257 cuda_h.py:19] end experts_map_get cost 0.0015606880187988281 seconds
DEBUG 01-05 12:51:20.301092.301092 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.301061.301061 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.301536.301536 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.302944.302944 cuda_h.py:19] end allocate_cuda_memory cost 0.0012850761413574219 seconds
DEBUG 01-05 12:51:20.302979.302979 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.302258.302258 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.302975.302975 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.302293.302293 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7e2c748-f9c0-41c2-9de4-2063359ec1f7
DEBUG 01-05 12:51:20.303339.303339 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:20.304440.304440 client.py:127] Model loaded
DEBUG 01-05 12:51:20.304197.304197 cuda_h.py:19] end sllm_worker_task cost 0.013147115707397461 seconds
INFO 01-05 12:51:20.304252.304252 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7e2c748-f9c0-41c2-9de4-2063359ec1f7
DEBUG 01-05 12:51:20.305148.305148 cuda_h.py:19] end load_into_gpu_async cost 0.0022323131561279297 seconds
DEBUG 01-05 12:51:20.305327.305327 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.305709.305709 cuda_h.py:19] end restore_tensors2 cost 0.0002903938293457031 seconds
DEBUG 01-05 12:51:20.305293.305293 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004151105880737305 seconds
DEBUG 01-05 12:51:20.308723.308723 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006757974624633789 seconds
DEBUG 01-05 12:51:20.308791.308791 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.308821.308821 lmp.py:423] 
DEBUG 01-05 12:51:20.308821.308821 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.308233.308233 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-05 12:51:20.308360.308360 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.318144.318144 mlpmodule.py:704] group tensors cost 0.010034799575805664 s
DEBUG 01-05 12:51:20.320424.320424 mlpmodule.py:742] pad cost 0.0013930797576904297 s
DEBUG 01-05 12:51:20.320474.320474 mlpmodule.py:748] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-05 12:51:20.320701.320701 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-05 12:51:20.329685.329685 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.330226.330226 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.330494.330494 mlpmodule.py:773] group_w3 first element: 0.08447265625
WARNING 01-05 12:51:20.330988.330988 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.345335.345335 mlpmodule.py:793] group einsum cost 0.024976253509521484 s
DEBUG 01-05 12:51:20.346407.346407 mlpmodule.py:801] cpy2cputensor cost 0.0005867481231689453 s
DEBUG 01-05 12:51:20.351707.351707 cuda_h.py:19] end wait_cetm_experts cost 0.04294300079345703 seconds
DEBUG 01-05 12:51:20.351339.351339 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.351733.351733 cuda_h.py:19] end gpu_sexperts cost 0.0004603862762451172 seconds
DEBUG 01-05 12:51:20.351139.351139 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.351849.351849 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-05 12:51:20.351983.351983 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.351692.351692 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7e2c748-f9c0-41c2-9de4-2063359ec1f7
INFO 01-05 12:51:20.358885.358885 client.py:127] Model loaded
DEBUG 01-05 12:51:20.358497.358497 cuda_h.py:19] end wait_experts cost 0.006422281265258789 seconds
DEBUG 01-05 12:51:20.358399.358399 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.358632.358632 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.359939.359939 mlpmodule.py:531] gpu group tensors cost 0.0006055831909179688 s
DEBUG 01-05 12:51:20.360660.360660 mlpmodule.py:564] gpu pad cost 0.0017066001892089844 s
DEBUG 01-05 12:51:20.361692.361692 mlpmodule.py:582] gpu group einsum cost 0.0004761219024658203 s
DEBUG 01-05 12:51:20.364706.364706 mlpmodule.py:611] gpu experts func einsum cost 0.005910158157348633 s
DEBUG 01-05 12:51:20.364140.364140 cuda_h.py:19] end gpu_experts cost 0.006101131439208984 seconds
DEBUG 01-05 12:51:20.364057.364057 cuda_h.py:19] end layer_moe_generate_23 cost 0.0657491683959961 seconds
DEBUG 01-05 12:51:20.364327.364327 lmp.py:217] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 12:51:20.364852.364852 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 12:51:20.364886.364886 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 12:51:20.364450.364450 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 12:51:20.364955.364955 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:20.364035.364035 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.9604644775390625e-05 seconds
DEBUG 01-05 12:51:20.365155.365155 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.365310.365310 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.365856.365856 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.365282.365282 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.367398.367398 cuda_h.py:19] end allocate_cuda_memory cost 0.002643585205078125 seconds
DEBUG 01-05 12:51:20.368713.368713 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.368535.368535 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.368689.368689 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.368485.368485 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7f7acf0b-0838-4d2a-966e-f9ab0e21b309
DEBUG 01-05 12:51:20.368646.368646 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.368539.368539 mlpmodule.py:662]  experts func einsum cost 0.06002545356750488 s
DEBUG 01-05 12:51:20.368130.368130 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.369151.369151 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7f7acf0b-0838-4d2a-966e-f9ab0e21b309
DEBUG 01-05 12:51:20.369894.369894 cuda_h.py:19] end load_into_gpu_async cost 0.0014226436614990234 seconds
DEBUG 01-05 12:51:20.369928.369928 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.369004.369004 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-05 12:51:20.369091.369091 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004410743713378906 seconds
INFO 01-05 12:51:20.370592.370592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7f7acf0b-0838-4d2a-966e-f9ab0e21b309
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.371360.371360 cuda_h.py:19] end self_attn cost 0.0032596588134765625 seconds
DEBUG 01-05 12:51:20.372880.372880 cuda_h.py:19] end iln_self_attn_paln cost 0.007177829742431641 seconds
DEBUG 01-05 12:51:20.372146.372146 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 12:51:20.372671.372671 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.372740.372740 cuda_h.py:19] end gate cost 0.0006492137908935547 seconds
DEBUG 01-05 12:51:20.373377.373377 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.373347.373347 lmp.py:365] 
DEBUG 01-05 12:51:20.373347.373347 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.373911.373911 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.373846.373846 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.373442.373442 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.373132.373132 lmp.py:369] 
DEBUG 01-05 12:51:20.373132.373132 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.373298.373298 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.373425.373425 lmp.py:376]   Expert 47 |     32 | CPU
DEBUG 01-05 12:51:20.373213.373213 lmp.py:376]   Expert 56 |     33 | CPU
DEBUG 01-05 12:51:20.373333.373333 lmp.py:376]   Expert 44 |     34 | CPU
DEBUG 01-05 12:51:20.373738.373738 lmp.py:376]   Expert 43 |     39 | CPU
DEBUG 01-05 12:51:20.373665.373665 lmp.py:376]   Expert 42 |     40 | CPU
DEBUG 01-05 12:51:20.373593.373593 lmp.py:376]   Expert 16 |     48 | CPU
DEBUG 01-05 12:51:20.373521.373521 lmp.py:376]   Expert 48 |     51 | CPU
DEBUG 01-05 12:51:20.373448.373448 lmp.py:376]   Expert 30 |     59 | CPU
DEBUG 01-05 12:51:20.373138.373138 lmp.py:376]   Expert 22 |     70 | CPU
DEBUG 01-05 12:51:20.373066.373066 lmp.py:376]   Expert  5 |     79 | CPU
DEBUG 01-05 12:51:20.373993.373993 lmp.py:376]   Expert 25 |     80 | CPU
DEBUG 01-05 12:51:20.373683.373683 lmp.py:376]   Expert 54 |     80 | CPU
DEBUG 01-05 12:51:20.373133.373133 lmp.py:376]   Expert 55 |     80 | CPU
DEBUG 01-05 12:51:20.373584.373584 lmp.py:376]   Expert  6 |     91 | CPU
DEBUG 01-05 12:51:20.373227.373227 lmp.py:376]   Expert  2 |     92 | CPU
DEBUG 01-05 12:51:20.373632.373632 lmp.py:376]   Expert 62 |     95 | CPU
DEBUG 01-05 12:51:20.373036.373036 lmp.py:376]   Expert 21 |    106 | CPU
DEBUG 01-05 12:51:20.373441.373441 lmp.py:376]   Expert 51 |    112 | CPU
DEBUG 01-05 12:51:20.373130.373130 lmp.py:376]   Expert  0 |    113 | CPU
DEBUG 01-05 12:51:20.373058.373058 lmp.py:376]   Expert 61 |    119 | CPU
DEBUG 01-05 12:51:20.373509.373509 lmp.py:376]   Expert 41 |    120 | CPU
DEBUG 01-05 12:51:20.373198.373198 lmp.py:376]   Expert 15 |    121 | CPU
DEBUG 01-05 12:51:20.373887.373887 lmp.py:376]   Expert 28 |    130 | CPU
DEBUG 01-05 12:51:20.373577.373577 lmp.py:376]   Expert 63 |    130 | CPU
DEBUG 01-05 12:51:20.373028.373028 lmp.py:376]   Expert  1 |    140 | CPU
DEBUG 01-05 12:51:20.373955.373955 lmp.py:376]   Expert 35 |    140 | CPU
DEBUG 01-05 12:51:20.373883.373883 lmp.py:376]   Expert 60 |    140 | CPU
DEBUG 01-05 12:51:20.373288.373288 lmp.py:376]   Expert 20 |    143 | CPU
DEBUG 01-05 12:51:20.373692.373692 lmp.py:376]   Expert  3 |    147 | CPU
DEBUG 01-05 12:51:20.373097.373097 lmp.py:376]   Expert 29 |    147 | CPU
DEBUG 01-05 12:51:20.373263.373263 lmp.py:376]   Expert 57 |    147 | CPU
DEBUG 01-05 12:51:20.373906.373906 lmp.py:376]   Expert 59 |    147 | CPU
DEBUG 01-05 12:51:20.373834.373834 lmp.py:376]   Expert 36 |    149 | GPU
DEBUG 01-05 12:51:20.374284.374284 lmp.py:376]   Expert 24 |    169 | GPU
DEBUG 01-05 12:51:20.374974.374974 lmp.py:376]   Expert  7 |    172 | GPU
DEBUG 01-05 12:51:20.374186.374186 lmp.py:376]   Expert 19 |    175 | GPU
DEBUG 01-05 12:51:20.374876.374876 lmp.py:376]   Expert 40 |    179 | GPU
DEBUG 01-05 12:51:20.374565.374565 lmp.py:376]   Expert 46 |    182 | GPU
DEBUG 01-05 12:51:20.374016.374016 lmp.py:376]   Expert  4 |    183 | GPU
DEBUG 01-05 12:51:20.374943.374943 lmp.py:376]   Expert 38 |    184 | GPU
DEBUG 01-05 12:51:20.374394.374394 lmp.py:376]   Expert 50 |    185 | GPU
DEBUG 01-05 12:51:20.374560.374560 lmp.py:376]   Expert 53 |    186 | GPU
DEBUG 01-05 12:51:20.374727.374727 lmp.py:376]   Expert 33 |    195 | GPU
DEBUG 01-05 12:51:20.374370.374370 lmp.py:376]   Expert 39 |    195 | GPU
DEBUG 01-05 12:51:20.374774.374774 lmp.py:376]   Expert 34 |    197 | GPU
DEBUG 01-05 12:51:20.374463.374463 lmp.py:376]   Expert 17 |    202 | GPU
DEBUG 01-05 12:51:20.374914.374914 lmp.py:376]   Expert 26 |    207 | GPU
DEBUG 01-05 12:51:20.374888.374888 lmp.py:376]   Expert 49 |    215 | GPU
DEBUG 01-05 12:51:20.374339.374339 lmp.py:376]   Expert 12 |    233 | GPU
DEBUG 01-05 12:51:20.374790.374790 lmp.py:376]   Expert 10 |    235 | GPU
DEBUG 01-05 12:51:20.374241.374241 lmp.py:376]   Expert  9 |    249 | GPU
DEBUG 01-05 12:51:20.374453.374453 lmp.py:376]   Expert 45 |    265 | GPU
DEBUG 01-05 12:51:20.374904.374904 lmp.py:376]   Expert 18 |    288 | GPU
DEBUG 01-05 12:51:20.374355.374355 lmp.py:376]   Expert 14 |    295 | GPU
DEBUG 01-05 12:51:20.374429.374429 lmp.py:376]   Expert 37 |    298 | GPU
DEBUG 01-05 12:51:20.374595.374595 lmp.py:376]   Expert 58 |    298 | GPU
DEBUG 01-05 12:51:20.374999.374999 lmp.py:376]   Expert 31 |    300 | GPU
DEBUG 01-05 12:51:20.374166.374166 lmp.py:376]   Expert 23 |    307 | GPU
DEBUG 01-05 12:51:20.374855.374855 lmp.py:376]   Expert 52 |    312 | GPU
DEBUG 01-05 12:51:20.374544.374544 lmp.py:376]   Expert  8 |    485 | GPU
DEBUG 01-05 12:51:20.374233.374233 lmp.py:376]   Expert 11 |    524 | GPU
DEBUG 01-05 12:51:20.374684.374684 lmp.py:376]   Expert 13 |    593 | GPU
DEBUG 01-05 12:51:20.374374.374374 lmp.py:376]   Expert 32 |    740 | GPU
DEBUG 01-05 12:51:20.374063.374063 lmp.py:376]   Expert 27 |    786 | GPU
DEBUG 01-05 12:51:20.374467.374467 lmp.py:377] 
DEBUG 01-05 12:51:20.374467.374467 lmp.py:377]   CPU total tokens: 3105 (25.3%)
DEBUG 01-05 12:51:20.374349.374349 lmp.py:378]   GPU total tokens: 9183 (74.7%)
DEBUG 01-05 12:51:20.374760.374760 cuda_h.py:19] end experts_map_get cost 0.0015180110931396484 seconds
DEBUG 01-05 12:51:20.374403.374403 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.374133.374133 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.374270.374270 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.376371.376371 cuda_h.py:19] end allocate_cuda_memory cost 0.0017955303192138672 seconds
DEBUG 01-05 12:51:20.376566.376566 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.376752.376752 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.376661.376661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.376549.376549 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 82b3d01c-b724-49c5-b5a7-3aaa65804763
DEBUG 01-05 12:51:20.376032.376032 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:20.377381.377381 client.py:127] Model loaded
DEBUG 01-05 12:51:20.377985.377985 cuda_h.py:19] end sllm_worker_task cost 0.01217794418334961 seconds
INFO 01-05 12:51:20.377248.377248 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 82b3d01c-b724-49c5-b5a7-3aaa65804763
DEBUG 01-05 12:51:20.377760.377760 cuda_h.py:19] end load_into_gpu_async cost 0.0012319087982177734 seconds
DEBUG 01-05 12:51:20.377271.377271 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.378215.378215 cuda_h.py:19] end restore_tensors2 cost 0.0002853870391845703 seconds
DEBUG 01-05 12:51:20.378747.378747 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003660440444946289 seconds
DEBUG 01-05 12:51:20.380979.380979 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006294965744018555 seconds
DEBUG 01-05 12:51:20.380478.380478 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.381447.381447 lmp.py:423] 
DEBUG 01-05 12:51:20.381447.381447 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.381052.381052 cuda_h.py:19] end cpu_experts_submit cost 0.00011444091796875 seconds
DEBUG 01-05 12:51:20.381132.381132 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.386396.386396 mlpmodule.py:704] group tensors cost 0.005361080169677734 s
DEBUG 01-05 12:51:20.389604.389604 mlpmodule.py:742] pad cost 0.001857757568359375 s
DEBUG 01-05 12:51:20.389661.389661 mlpmodule.py:748] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-05 12:51:20.389147.389147 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-05 12:51:20.397164.397164 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.397090.397090 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.397650.397650 mlpmodule.py:773] group_w3 first element: 0.00653076171875
WARNING 01-05 12:51:20.397197.397197 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.413678.413678 mlpmodule.py:793] group einsum cost 0.02429795265197754 s
DEBUG 01-05 12:51:20.414950.414950 mlpmodule.py:801] cpy2cputensor cost 0.0006053447723388672 s
DEBUG 01-05 12:51:20.419845.419845 cuda_h.py:19] end wait_cetm_experts cost 0.03804898262023926 seconds
DEBUG 01-05 12:51:20.419854.419854 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.419480.419480 cuda_h.py:19] end gpu_sexperts cost 0.0004553794860839844 seconds
DEBUG 01-05 12:51:20.419555.419555 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.419312.419312 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:20.419207.419207 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.419201.419201 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 82b3d01c-b724-49c5-b5a7-3aaa65804763
INFO 01-05 12:51:20.431852.431852 client.py:127] Model loaded
DEBUG 01-05 12:51:20.431510.431510 cuda_h.py:19] end wait_experts cost 0.011776924133300781 seconds
DEBUG 01-05 12:51:20.431279.431279 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.431313.431313 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.432015.432015 mlpmodule.py:531] gpu group tensors cost 0.0005183219909667969 s
DEBUG 01-05 12:51:20.433886.433886 mlpmodule.py:564] gpu pad cost 0.001428842544555664 s
DEBUG 01-05 12:51:20.434051.434051 mlpmodule.py:582] gpu group einsum cost 0.0005059242248535156 s
DEBUG 01-05 12:51:20.435487.435487 mlpmodule.py:662]  experts func einsum cost 0.054007530212402344 s
DEBUG 01-05 12:51:20.437084.437084 mlpmodule.py:611] gpu experts func einsum cost 0.005552768707275391 s
DEBUG 01-05 12:51:20.437817.437817 cuda_h.py:19] end gpu_experts cost 0.0057446956634521484 seconds
DEBUG 01-05 12:51:20.437256.437256 cuda_h.py:19] end layer_moe_generate_24 cost 0.06535983085632324 seconds
DEBUG 01-05 12:51:20.437129.437129 lmp.py:217] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 12:51:20.437892.437892 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 12:51:20.437680.437680 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 12:51:20.437575.437575 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 12:51:20.437412.437412 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.9087066650390625e-05 seconds
DEBUG 01-05 12:51:20.437228.437228 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.43865966796875e-05 seconds
DEBUG 01-05 12:51:20.438347.438347 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.438211.438211 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.438796.438796 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.438487.438487 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.438034.438034 cuda_h.py:19] end allocate_cuda_memory cost 0.0002994537353515625 seconds
DEBUG 01-05 12:51:20.438050.438050 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.438906.438906 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.438152.438152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.438471.438471 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c18ed0e-ea4b-4002-94b0-5ca992de3d56
DEBUG 01-05 12:51:20.438964.438964 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.439515.439515 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.440070.440070 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c18ed0e-ea4b-4002-94b0-5ca992de3d56
DEBUG 01-05 12:51:20.440430.440430 cuda_h.py:19] end load_into_gpu_async cost 0.0014035701751708984 seconds
DEBUG 01-05 12:51:20.440987.440987 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.440301.440301 cuda_h.py:19] end restore_tensors2 cost 6.508827209472656e-05 seconds
DEBUG 01-05 12:51:20.440150.440150 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002018451690673828 seconds
INFO 01-05 12:51:20.440958.440958 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c18ed0e-ea4b-4002-94b0-5ca992de3d56
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.443429.443429 cuda_h.py:19] end self_attn cost 0.003914356231689453 seconds
DEBUG 01-05 12:51:20.443996.443996 cuda_h.py:19] end iln_self_attn_paln cost 0.005286693572998047 seconds
DEBUG 01-05 12:51:20.443693.443693 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 12:51:20.443218.443218 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.444581.444581 cuda_h.py:19] end gate cost 0.0007255077362060547 seconds
DEBUG 01-05 12:51:20.444125.444125 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.444433.444433 lmp.py:365] 
DEBUG 01-05 12:51:20.444433.444433 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.444428.444428 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.444601.444601 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.444197.444197 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.444125.444125 lmp.py:369] 
DEBUG 01-05 12:51:20.444125.444125 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.444530.444530 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.444179.444179 lmp.py:376]   Expert 42 |     13 | CPU
DEBUG 01-05 12:51:20.444107.444107 lmp.py:376]   Expert 55 |     17 | CPU
DEBUG 01-05 12:51:20.444320.444320 lmp.py:376]   Expert 33 |     19 | CPU
DEBUG 01-05 12:51:20.444771.444771 lmp.py:376]   Expert  0 |     31 | CPU
DEBUG 01-05 12:51:20.444268.444268 lmp.py:376]   Expert 16 |     39 | CPU
DEBUG 01-05 12:51:20.444242.444242 lmp.py:376]   Expert 24 |     41 | CPU
DEBUG 01-05 12:51:20.444216.444216 lmp.py:376]   Expert 22 |     42 | CPU
DEBUG 01-05 12:51:20.444713.444713 lmp.py:376]   Expert 36 |     42 | CPU
DEBUG 01-05 12:51:20.444449.444449 lmp.py:376]   Expert 32 |     43 | CPU
DEBUG 01-05 12:51:20.444423.444423 lmp.py:376]   Expert  2 |     49 | CPU
DEBUG 01-05 12:51:20.444397.444397 lmp.py:376]   Expert 34 |     58 | CPU
DEBUG 01-05 12:51:20.444894.444894 lmp.py:376]   Expert 23 |     61 | CPU
DEBUG 01-05 12:51:20.444345.444345 lmp.py:376]   Expert 59 |     63 | CPU
DEBUG 01-05 12:51:20.444796.444796 lmp.py:376]   Expert 10 |     68 | CPU
DEBUG 01-05 12:51:20.444770.444770 lmp.py:376]   Expert 18 |     73 | CPU
DEBUG 01-05 12:51:20.444221.444221 lmp.py:376]   Expert 20 |     81 | CPU
DEBUG 01-05 12:51:20.444195.444195 lmp.py:376]   Expert 13 |     84 | CPU
DEBUG 01-05 12:51:20.444453.444453 lmp.py:376]   Expert 21 |     84 | CPU
DEBUG 01-05 12:51:20.444189.444189 lmp.py:376]   Expert 38 |     84 | CPU
DEBUG 01-05 12:51:20.444686.444686 lmp.py:376]   Expert 53 |     86 | CPU
DEBUG 01-05 12:51:20.444422.444422 lmp.py:376]   Expert 47 |     96 | CPU
DEBUG 01-05 12:51:20.444681.444681 lmp.py:376]   Expert 50 |    100 | CPU
DEBUG 01-05 12:51:20.445416.445416 lmp.py:376]   Expert 62 |    100 | CPU
DEBUG 01-05 12:51:20.445914.445914 lmp.py:376]   Expert 27 |    103 | CPU
DEBUG 01-05 12:51:20.445172.445172 lmp.py:376]   Expert 44 |    106 | CPU
DEBUG 01-05 12:51:20.445670.445670 lmp.py:376]   Expert 46 |    106 | CPU
DEBUG 01-05 12:51:20.445928.445928 lmp.py:376]   Expert 14 |    111 | CPU
DEBUG 01-05 12:51:20.445902.445902 lmp.py:376]   Expert 31 |    132 | CPU
DEBUG 01-05 12:51:20.445115.445115 lmp.py:376]   Expert 35 |    137 | CPU
DEBUG 01-05 12:51:20.445089.445089 lmp.py:376]   Expert 43 |    146 | CPU
DEBUG 01-05 12:51:20.445778.445778 lmp.py:376]   Expert 51 |    148 | CPU
DEBUG 01-05 12:51:20.445468.445468 lmp.py:376]   Expert 52 |    149 | CPU
DEBUG 01-05 12:51:20.445965.445965 lmp.py:376]   Expert  4 |    154 | GPU
DEBUG 01-05 12:51:20.445700.445700 lmp.py:376]   Expert 45 |    163 | GPU
DEBUG 01-05 12:51:20.445436.445436 lmp.py:376]   Expert  8 |    164 | GPU
DEBUG 01-05 12:51:20.445933.445933 lmp.py:376]   Expert 56 |    165 | GPU
DEBUG 01-05 12:51:20.445192.445192 lmp.py:376]   Expert 11 |    168 | GPU
DEBUG 01-05 12:51:20.445689.445689 lmp.py:376]   Expert 48 |    175 | GPU
DEBUG 01-05 12:51:20.445948.445948 lmp.py:376]   Expert 12 |    183 | GPU
DEBUG 01-05 12:51:20.445684.445684 lmp.py:376]   Expert  5 |    194 | GPU
DEBUG 01-05 12:51:20.445519.445519 lmp.py:376]   Expert 39 |    206 | GPU
DEBUG 01-05 12:51:20.445731.445731 lmp.py:376]   Expert 15 |    236 | GPU
DEBUG 01-05 12:51:20.445182.445182 lmp.py:376]   Expert  6 |    243 | GPU
DEBUG 01-05 12:51:20.445633.445633 lmp.py:376]   Expert 57 |    248 | GPU
DEBUG 01-05 12:51:20.445322.445322 lmp.py:376]   Expert  3 |    250 | GPU
DEBUG 01-05 12:51:20.445011.445011 lmp.py:376]   Expert 41 |    256 | GPU
DEBUG 01-05 12:51:20.445178.445178 lmp.py:376]   Expert 37 |    261 | GPU
DEBUG 01-05 12:51:20.445390.445390 lmp.py:376]   Expert 25 |    282 | GPU
DEBUG 01-05 12:51:20.445841.445841 lmp.py:376]   Expert 61 |    284 | GPU
DEBUG 01-05 12:51:20.445053.445053 lmp.py:376]   Expert 63 |    285 | GPU
DEBUG 01-05 12:51:20.445266.445266 lmp.py:376]   Expert 26 |    290 | GPU
DEBUG 01-05 12:51:20.445478.445478 lmp.py:376]   Expert 28 |    338 | GPU
DEBUG 01-05 12:51:20.445452.445452 lmp.py:376]   Expert 49 |    371 | GPU
DEBUG 01-05 12:51:20.445426.445426 lmp.py:376]   Expert 30 |    372 | GPU
DEBUG 01-05 12:51:20.445877.445877 lmp.py:376]   Expert 58 |    376 | GPU
DEBUG 01-05 12:51:20.445090.445090 lmp.py:376]   Expert 40 |    377 | GPU
DEBUG 01-05 12:51:20.445064.445064 lmp.py:376]   Expert  7 |    382 | GPU
DEBUG 01-05 12:51:20.445515.445515 lmp.py:376]   Expert 29 |    394 | GPU
DEBUG 01-05 12:51:20.445204.445204 lmp.py:376]   Expert  9 |    410 | GPU
DEBUG 01-05 12:51:20.445893.445893 lmp.py:376]   Expert 54 |    412 | GPU
DEBUG 01-05 12:51:20.445821.445821 lmp.py:376]   Expert  1 |    438 | GPU
DEBUG 01-05 12:51:20.445510.445510 lmp.py:376]   Expert 17 |    463 | GPU
DEBUG 01-05 12:51:20.445676.445676 lmp.py:376]   Expert 60 |    559 | GPU
DEBUG 01-05 12:51:20.445127.445127 lmp.py:376]   Expert 19 |    677 | GPU
DEBUG 01-05 12:51:20.445294.445294 lmp.py:377] 
DEBUG 01-05 12:51:20.445294.445294 lmp.py:377]   CPU total tokens: 2512 (20.4%)
DEBUG 01-05 12:51:20.445698.445698 lmp.py:378]   GPU total tokens: 9776 (79.6%)
DEBUG 01-05 12:51:20.445633.445633 cuda_h.py:19] end experts_map_get cost 0.0014693737030029297 seconds
DEBUG 01-05 12:51:20.445037.445037 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.445098.445098 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.445619.445619 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.446247.446247 cuda_h.py:19] end allocate_cuda_memory cost 0.0009207725524902344 seconds
DEBUG 01-05 12:51:20.446713.446713 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.446469.446469 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.447901.447901 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.447981.447981 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, afcae2c5-15d7-41da-b40a-2d03218954e9
DEBUG 01-05 12:51:20.447365.447365 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:20.447472.447472 client.py:127] Model loaded
DEBUG 01-05 12:51:20.447706.447706 cuda_h.py:19] end sllm_worker_task cost 0.009555816650390625 seconds
INFO 01-05 12:51:20.449722.449722 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, afcae2c5-15d7-41da-b40a-2d03218954e9
DEBUG 01-05 12:51:20.449248.449248 cuda_h.py:19] end load_into_gpu_async cost 0.0026781558990478516 seconds
DEBUG 01-05 12:51:20.449494.449494 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.450193.450193 cuda_h.py:19] end restore_tensors2 cost 0.0002796649932861328 seconds
DEBUG 01-05 12:51:20.450393.450393 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004232883453369141 seconds
DEBUG 01-05 12:51:20.452076.452076 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006877899169921875 seconds
DEBUG 01-05 12:51:20.452105.452105 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.452876.452876 lmp.py:423] 
DEBUG 01-05 12:51:20.452876.452876 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.452050.452050 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 12:51:20.452368.452368 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.463676.463676 mlpmodule.py:704] group tensors cost 0.010026693344116211 s
DEBUG 01-05 12:51:20.465455.465455 mlpmodule.py:742] pad cost 0.0014674663543701172 s
DEBUG 01-05 12:51:20.465962.465962 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-05 12:51:20.465520.465520 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-05 12:51:20.473044.473044 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.473777.473777 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.473237.473237 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 12:51:20.474407.474407 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.488906.488906 mlpmodule.py:793] group einsum cost 0.023528099060058594 s
DEBUG 01-05 12:51:20.489253.489253 mlpmodule.py:801] cpy2cputensor cost 0.0006551742553710938 s
DEBUG 01-05 12:51:20.494239.494239 cuda_h.py:19] end wait_cetm_experts cost 0.04157066345214844 seconds
DEBUG 01-05 12:51:20.494010.494010 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.495344.495344 cuda_h.py:19] end gpu_sexperts cost 0.0004508495330810547 seconds
DEBUG 01-05 12:51:20.495227.495227 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.495414.495414 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:20.495786.495786 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.495304.495304 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, afcae2c5-15d7-41da-b40a-2d03218954e9
INFO 01-05 12:51:20.502846.502846 client.py:127] Model loaded
DEBUG 01-05 12:51:20.503789.503789 cuda_h.py:19] end wait_experts cost 0.007765531539916992 seconds
DEBUG 01-05 12:51:20.503876.503876 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.503393.503393 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.503708.503708 mlpmodule.py:531] gpu group tensors cost 0.0006105899810791016 s
DEBUG 01-05 12:51:20.505581.505581 mlpmodule.py:564] gpu pad cost 0.0015039443969726562 s
DEBUG 01-05 12:51:20.505005.505005 mlpmodule.py:582] gpu group einsum cost 0.0005223751068115234 s
DEBUG 01-05 12:51:20.508716.508716 mlpmodule.py:611] gpu experts func einsum cost 0.005601644515991211 s
DEBUG 01-05 12:51:20.508197.508197 cuda_h.py:19] end gpu_experts cost 0.00579071044921875 seconds
DEBUG 01-05 12:51:20.508312.508312 cuda_h.py:19] end layer_moe_generate_25 cost 0.06552314758300781 seconds
DEBUG 01-05 12:51:20.509807.509807 lmp.py:217] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 12:51:20.509093.509093 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 12:51:20.509074.509074 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 12:51:20.509161.509161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 12:51:20.509620.509620 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.075599670410156e-05 seconds
DEBUG 01-05 12:51:20.509177.509177 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.103515625e-05 seconds
DEBUG 01-05 12:51:20.509297.509297 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.509644.509644 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:20.509905.509905 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.509119.509119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.511303.511303 cuda_h.py:19] end allocate_cuda_memory cost 0.0015058517456054688 seconds
DEBUG 01-05 12:51:20.511080.511080 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.511234.511234 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.511991.511991 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.511171.511171 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 951ce435-2f92-4d3d-b559-c85a4d4fa61a
DEBUG 01-05 12:51:20.511141.511141 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.511458.511458 mlpmodule.py:662]  experts func einsum cost 0.05851149559020996 s
DEBUG 01-05 12:51:20.511225.511225 cuda_h.py:10] start self_attn
INFO 01-05 12:51:20.512860.512860 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 951ce435-2f92-4d3d-b559-c85a4d4fa61a
DEBUG 01-05 12:51:20.512889.512889 cuda_h.py:19] end load_into_gpu_async cost 0.0011487007141113281 seconds
DEBUG 01-05 12:51:20.512923.512923 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.512250.512250 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-05 12:51:20.512768.512768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00299072265625 seconds
INFO 01-05 12:51:20.512759.512759 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 951ce435-2f92-4d3d-b559-c85a4d4fa61a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.515809.515809 cuda_h.py:19] end self_attn cost 0.0035181045532226562 seconds
DEBUG 01-05 12:51:20.515196.515196 cuda_h.py:19] end iln_self_attn_paln cost 0.00625300407409668 seconds
DEBUG 01-05 12:51:20.515847.515847 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 12:51:20.515279.515279 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.516619.516619 cuda_h.py:19] end gate cost 0.0006377696990966797 seconds
DEBUG 01-05 12:51:20.516972.516972 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.516870.516870 lmp.py:365] 
DEBUG 01-05 12:51:20.516870.516870 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.516070.516070 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.516104.516104 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.516892.516892 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.516297.516297 lmp.py:369] 
DEBUG 01-05 12:51:20.516297.516297 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.516178.516178 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.516828.516828 lmp.py:376]   Expert 62 |      5 | CPU
DEBUG 01-05 12:51:20.516471.516471 lmp.py:376]   Expert 30 |     22 | CPU
DEBUG 01-05 12:51:20.516160.516160 lmp.py:376]   Expert  7 |     28 | CPU
DEBUG 01-05 12:51:20.516611.516611 lmp.py:376]   Expert  3 |     29 | CPU
DEBUG 01-05 12:51:20.516062.516062 lmp.py:376]   Expert 22 |     29 | CPU
DEBUG 01-05 12:51:20.516751.516751 lmp.py:376]   Expert 17 |     38 | CPU
DEBUG 01-05 12:51:20.516202.516202 lmp.py:376]   Expert 15 |     44 | CPU
DEBUG 01-05 12:51:20.516415.516415 lmp.py:376]   Expert 49 |     45 | CPU
DEBUG 01-05 12:51:20.516819.516819 lmp.py:376]   Expert 58 |     55 | CPU
DEBUG 01-05 12:51:20.516224.516224 lmp.py:376]   Expert 12 |     68 | CPU
DEBUG 01-05 12:51:20.517152.517152 lmp.py:376]   Expert 27 |     72 | CPU
DEBUG 01-05 12:51:20.517318.517318 lmp.py:376]   Expert 53 |     76 | CPU
DEBUG 01-05 12:51:20.517245.517245 lmp.py:376]   Expert 24 |     83 | CPU
DEBUG 01-05 12:51:20.517696.517696 lmp.py:376]   Expert  6 |     86 | CPU
DEBUG 01-05 12:51:20.517670.517670 lmp.py:376]   Expert 34 |     86 | CPU
DEBUG 01-05 12:51:20.517883.517883 lmp.py:376]   Expert 59 |     89 | CPU
DEBUG 01-05 12:51:20.517095.517095 lmp.py:376]   Expert 61 |     89 | CPU
DEBUG 01-05 12:51:20.517308.517308 lmp.py:376]   Expert 29 |     90 | CPU
DEBUG 01-05 12:51:20.517520.517520 lmp.py:376]   Expert 51 |     90 | CPU
DEBUG 01-05 12:51:20.517971.517971 lmp.py:376]   Expert 21 |     94 | CPU
DEBUG 01-05 12:51:20.517945.517945 lmp.py:376]   Expert 43 |     95 | CPU
DEBUG 01-05 12:51:20.517396.517396 lmp.py:376]   Expert 56 |    100 | CPU
DEBUG 01-05 12:51:20.517847.517847 lmp.py:376]   Expert  8 |    103 | CPU
DEBUG 01-05 12:51:20.517536.517536 lmp.py:376]   Expert 11 |    103 | CPU
DEBUG 01-05 12:51:20.517464.517464 lmp.py:376]   Expert 38 |    105 | CPU
DEBUG 01-05 12:51:20.517153.517153 lmp.py:376]   Expert 13 |    107 | CPU
DEBUG 01-05 12:51:20.517842.517842 lmp.py:376]   Expert 28 |    123 | CPU
DEBUG 01-05 12:51:20.517293.517293 lmp.py:376]   Expert 57 |    123 | CPU
DEBUG 01-05 12:51:20.517281.517281 lmp.py:376]   Expert 26 |    128 | CPU
DEBUG 01-05 12:51:20.517255.517255 lmp.py:376]   Expert 41 |    128 | CPU
DEBUG 01-05 12:51:20.517229.517229 lmp.py:376]   Expert  0 |    130 | CPU
DEBUG 01-05 12:51:20.517965.517965 lmp.py:376]   Expert 36 |    131 | CPU
DEBUG 01-05 12:51:20.517700.517700 lmp.py:376]   Expert 54 |    134 | GPU
DEBUG 01-05 12:51:20.517198.517198 lmp.py:376]   Expert 20 |    139 | GPU
DEBUG 01-05 12:51:20.517933.517933 lmp.py:376]   Expert  9 |    140 | GPU
DEBUG 01-05 12:51:20.517430.517430 lmp.py:376]   Expert 60 |    148 | GPU
DEBUG 01-05 12:51:20.517404.517404 lmp.py:376]   Expert 32 |    150 | GPU
DEBUG 01-05 12:51:20.517617.517617 lmp.py:376]   Expert 47 |    157 | GPU
DEBUG 01-05 12:51:20.517829.517829 lmp.py:376]   Expert 45 |    159 | GPU
DEBUG 01-05 12:51:20.517280.517280 lmp.py:376]   Expert  1 |    163 | GPU
DEBUG 01-05 12:51:20.517446.517446 lmp.py:376]   Expert 42 |    167 | GPU
DEBUG 01-05 12:51:20.517944.517944 lmp.py:376]   Expert 23 |    172 | GPU
DEBUG 01-05 12:51:20.517441.517441 lmp.py:376]   Expert 19 |    181 | GPU
DEBUG 01-05 12:51:20.517700.517700 lmp.py:376]   Expert 55 |    199 | GPU
DEBUG 01-05 12:51:20.517435.517435 lmp.py:376]   Expert 44 |    205 | GPU
DEBUG 01-05 12:51:20.517694.517694 lmp.py:376]   Expert 37 |    239 | GPU
DEBUG 01-05 12:51:20.517953.517953 lmp.py:376]   Expert 48 |    241 | GPU
DEBUG 01-05 12:51:20.517688.517688 lmp.py:376]   Expert  5 |    247 | GPU
DEBUG 01-05 12:51:20.517186.517186 lmp.py:376]   Expert 39 |    247 | GPU
DEBUG 01-05 12:51:20.517921.517921 lmp.py:376]   Expert 10 |    258 | GPU
DEBUG 01-05 12:51:20.517372.517372 lmp.py:376]   Expert  2 |    268 | GPU
DEBUG 01-05 12:51:20.517300.517300 lmp.py:376]   Expert  4 |    272 | GPU
DEBUG 01-05 12:51:20.517274.517274 lmp.py:376]   Expert 16 |    274 | GPU
DEBUG 01-05 12:51:20.517202.517202 lmp.py:376]   Expert 50 |    281 | GPU
DEBUG 01-05 12:51:20.517176.517176 lmp.py:376]   Expert 33 |    284 | GPU
DEBUG 01-05 12:51:20.517673.517673 lmp.py:376]   Expert 31 |    286 | GPU
DEBUG 01-05 12:51:20.517170.517170 lmp.py:376]   Expert 25 |    290 | GPU
DEBUG 01-05 12:51:20.517667.517667 lmp.py:376]   Expert 18 |    296 | GPU
DEBUG 01-05 12:51:20.517403.517403 lmp.py:376]   Expert 63 |    325 | GPU
DEBUG 01-05 12:51:20.517377.517377 lmp.py:376]   Expert 35 |    459 | GPU
DEBUG 01-05 12:51:20.517828.517828 lmp.py:376]   Expert 40 |    560 | GPU
DEBUG 01-05 12:51:20.517040.517040 lmp.py:376]   Expert 46 |    649 | GPU
DEBUG 01-05 12:51:20.517014.517014 lmp.py:376]   Expert 52 |    851 | GPU
DEBUG 01-05 12:51:20.517419.517419 lmp.py:376]   Expert 14 |   1253 | GPU
DEBUG 01-05 12:51:20.517300.517300 lmp.py:377] 
DEBUG 01-05 12:51:20.517300.517300 lmp.py:377]   CPU total tokens: 2594 (21.1%)
DEBUG 01-05 12:51:20.517420.517420 lmp.py:378]   GPU total tokens: 9694 (78.9%)
DEBUG 01-05 12:51:20.517070.517070 cuda_h.py:19] end experts_map_get cost 0.0015077590942382812 seconds
DEBUG 01-05 12:51:20.517143.517143 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.517443.517443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.518580.518580 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.519810.519810 cuda_h.py:19] end allocate_cuda_memory cost 0.0015048980712890625 seconds
DEBUG 01-05 12:51:20.519289.519289 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.519999.519999 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.519239.519239 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.519889.519889 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d036b3d-1abe-4eed-8d91-9a620be8bf12
DEBUG 01-05 12:51:20.520464.520464 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:20.520447.520447 client.py:127] Model loaded
DEBUG 01-05 12:51:20.520475.520475 cuda_h.py:19] end sllm_worker_task cost 0.010887622833251953 seconds
INFO 01-05 12:51:20.521548.521548 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d036b3d-1abe-4eed-8d91-9a620be8bf12
DEBUG 01-05 12:51:20.521222.521222 cuda_h.py:19] end load_into_gpu_async cost 0.0014791488647460938 seconds
DEBUG 01-05 12:51:20.521138.521138 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.521067.521067 cuda_h.py:19] end restore_tensors2 cost 0.0003769397735595703 seconds
DEBUG 01-05 12:51:20.521167.521167 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003813505172729492 seconds
DEBUG 01-05 12:51:20.525307.525307 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007812738418579102 seconds
DEBUG 01-05 12:51:20.525163.525163 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.525591.525591 lmp.py:423] 
DEBUG 01-05 12:51:20.525591.525591 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.526699.526699 cuda_h.py:19] end cpu_experts_submit cost 0.0001418590545654297 seconds
DEBUG 01-05 12:51:20.526270.526270 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.543128.543128 mlpmodule.py:704] group tensors cost 0.017080307006835938 s
DEBUG 01-05 12:51:20.545536.545536 mlpmodule.py:742] pad cost 0.0015921592712402344 s
DEBUG 01-05 12:51:20.545957.545957 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-05 12:51:20.545906.545906 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-05 12:51:20.554350.554350 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.554561.554561 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.554928.554928 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 12:51:20.554998.554998 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.569187.569187 mlpmodule.py:793] group einsum cost 0.023739337921142578 s
DEBUG 01-05 12:51:20.570662.570662 mlpmodule.py:801] cpy2cputensor cost 0.0005846023559570312 s
DEBUG 01-05 12:51:20.578014.578014 cuda_h.py:19] end wait_cetm_experts cost 0.05260324478149414 seconds
DEBUG 01-05 12:51:20.578861.578861 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.579789.579789 cuda_h.py:19] end gpu_sexperts cost 0.0005702972412109375 seconds
DEBUG 01-05 12:51:20.579592.579592 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.579025.579025 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.3855438232421875e-05 seconds
DEBUG 01-05 12:51:20.579636.579636 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.579676.579676 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d036b3d-1abe-4eed-8d91-9a620be8bf12
INFO 01-05 12:51:20.580995.580995 client.py:127] Model loaded
DEBUG 01-05 12:51:20.580514.580514 cuda_h.py:19] end wait_experts cost 0.0010714530944824219 seconds
DEBUG 01-05 12:51:20.580554.580554 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.580834.580834 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.581717.581717 mlpmodule.py:531] gpu group tensors cost 0.0006043910980224609 s
DEBUG 01-05 12:51:20.583738.583738 mlpmodule.py:564] gpu pad cost 0.0017507076263427734 s
DEBUG 01-05 12:51:20.583327.583327 mlpmodule.py:582] gpu group einsum cost 0.0004973411560058594 s
DEBUG 01-05 12:51:20.587336.587336 mlpmodule.py:611] gpu experts func einsum cost 0.006220579147338867 s
DEBUG 01-05 12:51:20.587532.587532 cuda_h.py:19] end gpu_experts cost 0.006415128707885742 seconds
DEBUG 01-05 12:51:20.587832.587832 cuda_h.py:19] end layer_moe_generate_26 cost 0.07172703742980957 seconds
DEBUG 01-05 12:51:20.587997.587997 lmp.py:217] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 12:51:20.587229.587229 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 12:51:20.587733.587733 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 12:51:20.587496.587496 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.0967254638671875e-05 seconds
DEBUG 01-05 12:51:20.587093.587093 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:20.587658.587658 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:20.591867.591867 cuda_h.py:19] end self_attn cost 0.003400087356567383 seconds
DEBUG 01-05 12:51:20.591810.591810 cuda_h.py:19] end iln_self_attn_paln cost 0.003976583480834961 seconds
DEBUG 01-05 12:51:20.591030.591030 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 12:51:20.591839.591839 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.592416.592416 cuda_h.py:19] end gate cost 0.0005676746368408203 seconds
DEBUG 01-05 12:51:20.592519.592519 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:20.592973.592973 lmp.py:365] 
DEBUG 01-05 12:51:20.592973.592973 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:20.592212.592212 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:20.592723.592723 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:20.592942.592942 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:20.592208.592208 lmp.py:369] 
DEBUG 01-05 12:51:20.592208.592208 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:20.592997.592997 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:20.592507.592507 lmp.py:376]   Expert 47 |     14 | CPU
DEBUG 01-05 12:51:20.592058.592058 lmp.py:376]   Expert 18 |     19 | CPU
DEBUG 01-05 12:51:20.592131.592131 lmp.py:376]   Expert 58 |     45 | CPU
DEBUG 01-05 12:51:20.592205.592205 lmp.py:376]   Expert 24 |     46 | CPU
DEBUG 01-05 12:51:20.592801.592801 lmp.py:376]   Expert 50 |     64 | CPU
DEBUG 01-05 12:51:20.592683.592683 lmp.py:376]   Expert 59 |     64 | CPU
DEBUG 01-05 12:51:20.593802.593802 lmp.py:376]   Expert 51 |     70 | CPU
DEBUG 01-05 12:51:20.593876.593876 lmp.py:376]   Expert 19 |     71 | CPU
DEBUG 01-05 12:51:20.593711.593711 lmp.py:376]   Expert 32 |     73 | CPU
DEBUG 01-05 12:51:20.593546.593546 lmp.py:376]   Expert 15 |     74 | CPU
DEBUG 01-05 12:51:20.593666.593666 lmp.py:376]   Expert 40 |     77 | CPU
DEBUG 01-05 12:51:20.593309.593309 lmp.py:376]   Expert 11 |     78 | CPU
DEBUG 01-05 12:51:20.593952.593952 lmp.py:376]   Expert 38 |     84 | CPU
DEBUG 01-05 12:51:20.593595.593595 lmp.py:376]   Expert 52 |     86 | CPU
DEBUG 01-05 12:51:20.593238.593238 lmp.py:376]   Expert 48 |     95 | CPU
DEBUG 01-05 12:51:20.593596.593596 lmp.py:376]   Expert  7 |    100 | CPU
DEBUG 01-05 12:51:20.593954.593954 lmp.py:376]   Expert 39 |    100 | CPU
DEBUG 01-05 12:51:20.593597.593597 lmp.py:376]   Expert 42 |    103 | CPU
DEBUG 01-05 12:51:20.593194.593194 lmp.py:376]   Expert 34 |    104 | CPU
DEBUG 01-05 12:51:20.593267.593267 lmp.py:376]   Expert 44 |    107 | CPU
DEBUG 01-05 12:51:20.593149.593149 lmp.py:376]   Expert 29 |    112 | CPU
DEBUG 01-05 12:51:20.593030.593030 lmp.py:376]   Expert 31 |    116 | CPU
DEBUG 01-05 12:51:20.593627.593627 lmp.py:376]   Expert 12 |    118 | CPU
DEBUG 01-05 12:51:20.593223.593223 lmp.py:376]   Expert 54 |    119 | CPU
DEBUG 01-05 12:51:20.593582.593582 lmp.py:376]   Expert 46 |    124 | CPU
DEBUG 01-05 12:51:20.593463.593463 lmp.py:376]   Expert  8 |    125 | CPU
DEBUG 01-05 12:51:20.593344.593344 lmp.py:376]   Expert  6 |    126 | CPU
DEBUG 01-05 12:51:20.593941.593941 lmp.py:376]   Expert 61 |    131 | CPU
DEBUG 01-05 12:51:20.593253.593253 lmp.py:376]   Expert 25 |    138 | CPU
DEBUG 01-05 12:51:20.593042.593042 lmp.py:376]   Expert 23 |    148 | CPU
DEBUG 01-05 12:51:20.593400.593400 lmp.py:376]   Expert 53 |    148 | CPU
DEBUG 01-05 12:51:20.593997.593997 lmp.py:376]   Expert 22 |    150 | CPU
DEBUG 01-05 12:51:20.593116.593116 lmp.py:376]   Expert 45 |    169 | GPU
DEBUG 01-05 12:51:20.593475.593475 lmp.py:376]   Expert  4 |    172 | GPU
DEBUG 01-05 12:51:20.593595.593595 lmp.py:376]   Expert 49 |    175 | GPU
DEBUG 01-05 12:51:20.593191.593191 lmp.py:376]   Expert 13 |    179 | GPU
DEBUG 01-05 12:51:20.593549.593549 lmp.py:376]   Expert 16 |    179 | GPU
DEBUG 01-05 12:51:20.593908.593908 lmp.py:376]   Expert  1 |    182 | GPU
DEBUG 01-05 12:51:20.593789.593789 lmp.py:376]   Expert 10 |    182 | GPU
DEBUG 01-05 12:51:20.593737.593737 lmp.py:376]   Expert 36 |    182 | GPU
DEBUG 01-05 12:51:20.593618.593618 lmp.py:376]   Expert 56 |    185 | GPU
DEBUG 01-05 12:51:20.593785.593785 lmp.py:376]   Expert 17 |    209 | GPU
DEBUG 01-05 12:51:20.593951.593951 lmp.py:376]   Expert 33 |    215 | GPU
DEBUG 01-05 12:51:20.593117.593117 lmp.py:376]   Expert 26 |    216 | GPU
DEBUG 01-05 12:51:20.593045.593045 lmp.py:376]   Expert 41 |    222 | GPU
DEBUG 01-05 12:51:20.593164.593164 lmp.py:376]   Expert  3 |    225 | GPU
DEBUG 01-05 12:51:20.593569.593569 lmp.py:376]   Expert 57 |    227 | GPU
DEBUG 01-05 12:51:20.593735.593735 lmp.py:376]   Expert 62 |    234 | GPU
DEBUG 01-05 12:51:20.593339.593339 lmp.py:376]   Expert 30 |    238 | GPU
DEBUG 01-05 12:51:20.593697.593697 lmp.py:376]   Expert 55 |    243 | GPU
DEBUG 01-05 12:51:20.593817.593817 lmp.py:376]   Expert  5 |    259 | GPU
DEBUG 01-05 12:51:20.593175.593175 lmp.py:376]   Expert 37 |    271 | GPU
DEBUG 01-05 12:51:20.593341.593341 lmp.py:376]   Expert 35 |    277 | GPU
DEBUG 01-05 12:51:20.593507.593507 lmp.py:376]   Expert  0 |    316 | GPU
DEBUG 01-05 12:51:20.593673.593673 lmp.py:376]   Expert 21 |    333 | GPU
DEBUG 01-05 12:51:20.593839.593839 lmp.py:376]   Expert  2 |    360 | GPU
DEBUG 01-05 12:51:20.593767.593767 lmp.py:376]   Expert 43 |    362 | GPU
DEBUG 01-05 12:51:20.593410.593410 lmp.py:376]   Expert 60 |    374 | GPU
DEBUG 01-05 12:51:20.593576.593576 lmp.py:376]   Expert 28 |    392 | GPU
DEBUG 01-05 12:51:20.593981.593981 lmp.py:376]   Expert 63 |    429 | GPU
DEBUG 01-05 12:51:20.593624.593624 lmp.py:376]   Expert 14 |    499 | GPU
DEBUG 01-05 12:51:20.594505.594505 lmp.py:376]   Expert 27 |    501 | GPU
DEBUG 01-05 12:51:20.594625.594625 lmp.py:376]   Expert 20 |    567 | GPU
DEBUG 01-05 12:51:20.594030.594030 lmp.py:376]   Expert  9 |    685 | GPU
DEBUG 01-05 12:51:20.594865.594865 lmp.py:377] 
DEBUG 01-05 12:51:20.594865.594865 lmp.py:377]   CPU total tokens: 3029 (24.7%)
DEBUG 01-05 12:51:20.594984.594984 lmp.py:378]   GPU total tokens: 9259 (75.3%)
DEBUG 01-05 12:51:20.594873.594873 cuda_h.py:19] end experts_map_get cost 0.0016353130340576172 seconds
DEBUG 01-05 12:51:20.594708.594708 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:20.594107.594107 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:20.594250.594250 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:20.594024.594024 cuda_h.py:19] end allocate_cuda_memory cost 0.0003256797790527344 seconds
DEBUG 01-05 12:51:20.594351.594351 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:20.594537.594537 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:20.594929.594929 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:20.594202.594202 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0c04562a-d803-4c65-8464-d4231a1bc4ca
DEBUG 01-05 12:51:20.595275.595275 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:20.595982.595982 mlpmodule.py:662]  experts func einsum cost 0.06892657279968262 s
INFO 01-05 12:51:20.596406.596406 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0c04562a-d803-4c65-8464-d4231a1bc4ca
DEBUG 01-05 12:51:20.596458.596458 cuda_h.py:19] end load_into_gpu_async cost 0.0015702247619628906 seconds
DEBUG 01-05 12:51:20.596369.596369 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:20.596953.596953 cuda_h.py:19] end restore_tensors2 cost 0.00036525726318359375 seconds
DEBUG 01-05 12:51:20.596822.596822 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027506351470947266 seconds
DEBUG 01-05 12:51:20.599073.599073 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053310394287109375 seconds
DEBUG 01-05 12:51:20.599617.599617 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.599626.599626 lmp.py:423] 
DEBUG 01-05 12:51:20.599626.599626 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:20.599583.599583 cuda_h.py:19] end cpu_experts_submit cost 0.00012159347534179688 seconds
DEBUG 01-05 12:51:20.599663.599663 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.608517.608517 mlpmodule.py:704] group tensors cost 0.008704423904418945 s
DEBUG 01-05 12:51:20.610604.610604 mlpmodule.py:742] pad cost 0.0015611648559570312 s
DEBUG 01-05 12:51:20.610482.610482 mlpmodule.py:748] create cpu tensor cost 6.079673767089844e-05 s
DEBUG 01-05 12:51:20.611611.611611 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 12:51:20.619765.619765 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:20.619492.619492 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.620912.620912 mlpmodule.py:773] group_w3 first element: -0.000606536865234375
WARNING 01-05 12:51:20.620598.620598 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.634312.634312 mlpmodule.py:793] group einsum cost 0.02382206916809082 s
DEBUG 01-05 12:51:20.635836.635836 mlpmodule.py:801] cpy2cputensor cost 0.0006053447723388672 s
DEBUG 01-05 12:51:20.647396.647396 cuda_h.py:19] end wait_cetm_experts cost 0.04810380935668945 seconds
DEBUG 01-05 12:51:20.648321.648321 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.648707.648707 cuda_h.py:19] end gpu_sexperts cost 0.0005917549133300781 seconds
DEBUG 01-05 12:51:20.648080.648080 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:20.648817.648817 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1205673217773438e-05 seconds
DEBUG 01-05 12:51:20.648758.648758 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:20.648852.648852 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0c04562a-d803-4c65-8464-d4231a1bc4ca
INFO 01-05 12:51:20.650341.650341 client.py:127] Model loaded
DEBUG 01-05 12:51:20.650760.650760 cuda_h.py:19] end wait_experts cost 0.0016200542449951172 seconds
DEBUG 01-05 12:51:20.650225.650225 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.650451.650451 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:20.651338.651338 mlpmodule.py:531] gpu group tensors cost 0.0005087852478027344 s
DEBUG 01-05 12:51:20.652045.652045 mlpmodule.py:564] gpu pad cost 0.0014836788177490234 s
DEBUG 01-05 12:51:20.653818.653818 mlpmodule.py:582] gpu group einsum cost 0.0004608631134033203 s
DEBUG 01-05 12:51:20.655234.655234 mlpmodule.py:611] gpu experts func einsum cost 0.00531315803527832 s
DEBUG 01-05 12:51:20.656157.656157 cuda_h.py:19] end gpu_experts cost 0.005473136901855469 seconds
DEBUG 01-05 12:51:20.656597.656597 cuda_h.py:19] end layer_moe_generate_27 cost 0.06436300277709961 seconds
DEBUG 01-05 12:51:20.656476.656476 lmp.py:217] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 12:51:20.656577.656577 cuda_h.py:19] end multi_layer cost 2.578460931777954 seconds
DEBUG 01-05 12:51:20.656035.656035 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 12:51:20.661671.661671 mlpmodule.py:662]  experts func einsum cost 0.06199026107788086 s
DEBUG 01-05 12:51:20.717164.717164 cuda_h.py:19] end init_inputs_tokens cost 0.06155514717102051 seconds
DEBUG 01-05 12:51:20.718135.718135 lmp.py:286] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 12:51:20.718268.718268 cuda_h.py:10] start dense_mlp
DEBUG 01-05 12:51:20.720106.720106 lmp.py:289] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 12:51:20.720976.720976 cuda_h.py:19] end dense_mlp cost 0.002318143844604492 seconds
DEBUG 01-05 12:51:20.720946.720946 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 12:51:20.720086.720086 cuda_h.py:10] start gate
DEBUG 01-05 12:51:20.747491.747491 cuda_h.py:19] end gate cost 0.026910781860351562 seconds
DEBUG 01-05 12:51:20.747626.747626 cuda_h.py:10] start experts_map_get
INFO 01-05 12:51:20.748126.748126 lmp.py:578] 
INFO 01-05 12:51:20.748126.748126 lmp.py:578] Layer 1 Expert Device Distribution:
INFO 01-05 12:51:20.748041.748041 lmp.py:579]   Active experts: 48 (out of 64 total)
INFO 01-05 12:51:20.748783.748783 lmp.py:580] 
INFO 01-05 12:51:20.748783.748783 lmp.py:580]   Detailed Expert Distribution:
INFO 01-05 12:51:20.748579.748579 lmp.py:581]   Expert ID  | Tokens     | Actual Device  
INFO 01-05 12:51:20.748222.748222 lmp.py:582]   ----------------------------------------------------------------------
INFO 01-05 12:51:20.748865.748865 lmp.py:585]   12         | 1          |  meta           
INFO 01-05 12:51:20.748508.748508 lmp.py:585]   17         | 1          |  cuda:1         
INFO 01-05 12:51:20.748635.748635 lmp.py:585]   19         | 1          |  cuda:1         
INFO 01-05 12:51:20.748132.748132 lmp.py:585]   21         | 1          |  meta           
INFO 01-05 12:51:20.748629.748629 lmp.py:585]   32         | 1          |  meta           
INFO 01-05 12:51:20.748649.748649 lmp.py:585]   38         | 1          |  meta           
INFO 01-05 12:51:20.748193.748193 lmp.py:585]   39         | 1          |  meta           
INFO 01-05 12:51:20.748975.748975 lmp.py:585]   41         | 1          |  meta           
INFO 01-05 12:51:20.748995.748995 lmp.py:585]   52         | 1          |  cuda:1         
INFO 01-05 12:51:20.748777.748777 lmp.py:585]   56         | 1          |  meta           
INFO 01-05 12:51:20.748559.748559 lmp.py:585]   0          | 2          |  cuda:1         
INFO 01-05 12:51:20.748818.748818 lmp.py:585]   8          | 2          |  cuda:1         
INFO 01-05 12:51:20.748361.748361 lmp.py:585]   26         | 2          |  cuda:1         
INFO 01-05 12:51:20.748905.748905 lmp.py:585]   33         | 2          |  cuda:1         
INFO 01-05 12:51:20.748925.748925 lmp.py:585]   51         | 2          |  meta           
INFO 01-05 12:51:20.748707.748707 lmp.py:585]   11         | 3          |  meta           
INFO 01-05 12:51:20.748251.748251 lmp.py:585]   22         | 3          |  meta           
INFO 01-05 12:51:20.748271.748271 lmp.py:585]   23         | 3          |  cuda:1         
INFO 01-05 12:51:20.748292.748292 lmp.py:585]   40         | 3          |  cuda:1         
INFO 01-05 12:51:20.748074.748074 lmp.py:585]   43         | 3          |  cuda:1         
INFO 01-05 12:51:20.748855.748855 lmp.py:585]   53         | 3          |  meta           
INFO 01-05 12:51:20.748637.748637 lmp.py:585]   60         | 3          |  cuda:1         
INFO 01-05 12:51:20.748896.748896 lmp.py:585]   61         | 3          |  cuda:1         
INFO 01-05 12:51:20.748632.748632 lmp.py:585]   1          | 4          |  cuda:1         
INFO 01-05 12:51:20.748414.748414 lmp.py:585]   9          | 4          |  cuda:1         
INFO 01-05 12:51:20.748626.748626 lmp.py:585]   10         | 4          |  cuda:1         
INFO 01-05 12:51:20.748408.748408 lmp.py:585]   30         | 4          |  meta           
INFO 01-05 12:51:20.748667.748667 lmp.py:585]   42         | 4          |  cuda:1         
INFO 01-05 12:51:20.748972.748972 lmp.py:585]   45         | 4          |  cuda:1         
INFO 01-05 12:51:20.748754.748754 lmp.py:585]   47         | 4          |  meta           
INFO 01-05 12:51:20.748298.748298 lmp.py:585]   63         | 4          |  cuda:1         
INFO 01-05 12:51:20.748841.748841 lmp.py:585]   5          | 5          |  cuda:1         
INFO 01-05 12:51:20.748861.748861 lmp.py:585]   28         | 5          |  meta           
INFO 01-05 12:51:20.748643.748643 lmp.py:585]   44         | 5          |  cuda:1         
INFO 01-05 12:51:20.748425.748425 lmp.py:585]   59         | 5          |  meta           
INFO 01-05 12:51:20.748446.748446 lmp.py:585]   2          | 6          |  cuda:1         
INFO 01-05 12:51:20.748228.748228 lmp.py:585]   4          | 6          |  cuda:1         
INFO 01-05 12:51:20.748486.748486 lmp.py:585]   15         | 6          |  cuda:1         
INFO 01-05 12:51:20.748030.748030 lmp.py:585]   16         | 6          |  cuda:1         
INFO 01-05 12:51:20.748527.748527 lmp.py:585]   31         | 6          |  meta           
INFO 01-05 12:51:20.748601.748601 lmp.py:585]   46         | 6          |  cuda:1         
INFO 01-05 12:51:20.748860.748860 lmp.py:585]   7          | 7          |  cuda:1         
INFO 01-05 12:51:20.748880.748880 lmp.py:585]   6          | 8          |  cuda:1         
INFO 01-05 12:51:20.749662.749662 lmp.py:585]   14         | 8          |  cuda:1         
INFO 01-05 12:51:20.749682.749682 lmp.py:585]   20         | 8          |  cuda:1         
INFO 01-05 12:51:20.749464.749464 lmp.py:585]   57         | 8          |  cuda:1         
INFO 01-05 12:51:20.749485.749485 lmp.py:585]   34         | 10         |  cuda:1         
INFO 01-05 12:51:20.749505.749505 lmp.py:585]   24         | 11         |  meta           
INFO 01-05 12:51:20.749048.749048 lmp.py:586] ============================================================
INFO 01-05 12:51:20.749048.749048 lmp.py:586] 
INFO 01-05 12:51:20.749268.749268 lmp.py:588] experts_gpu_list: [17, 19, 52, 0, 8, 26, 33, 23, 40, 43, 60, 61, 1, 9, 10, 42, 45, 63, 5, 44, 2, 4, 15, 16, 46, 7, 6, 14, 20, 57, 34]
INFO 01-05 12:51:20.749195.749195 lmp.py:589] experts_cpu_list: [12, 21, 32, 38, 39, 41, 56, 51, 11, 22, 53, 30, 47, 28, 59, 31, 24]
INFO 01-05 12:51:20.749567.749567 lmp.py:590] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-05 12:51:20.749555.749555 cuda_h.py:19] end experts_map_get cost 0.0016024112701416016 seconds
DEBUG 01-05 12:51:20.749319.749319 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:20.749400.749400 lmp.py:600] 
DEBUG 01-05 12:51:20.749400.749400 lmp.py:600]   Computing 17 experts on CPU...
DEBUG 01-05 12:51:20.749197.749197 cuda_h.py:19] end cpu_experts_submit cost 8.916854858398438e-05 seconds
DEBUG 01-05 12:51:20.749701.749701 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:20.765240.765240 mlpmodule.py:704] group tensors cost 0.015334606170654297 s
DEBUG 01-05 12:51:20.767275.767275 mlpmodule.py:742] pad cost 0.0014340877532958984 s
DEBUG 01-05 12:51:20.767472.767472 mlpmodule.py:748] create cpu tensor cost 6.580352783203125e-05 s
DEBUG 01-05 12:51:20.767793.767793 mlpmodule.py:753] move to cpu cost 4.482269287109375e-05 s
DEBUG 01-05 12:51:20.770722.770722 mlpmodule.py:767] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-05 12:51:20.770949.770949 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:20.770362.770362 mlpmodule.py:773] group_w3 first element: 0.01202392578125
WARNING 01-05 12:51:20.771683.771683 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:20.776765.776765 mlpmodule.py:793] group einsum cost 0.00859832763671875 s
DEBUG 01-05 12:51:20.776334.776334 mlpmodule.py:801] cpy2cputensor cost 0.00010156631469726562 s
DEBUG 01-05 12:51:20.778675.778675 cuda_h.py:19] end wait_cetm_experts cost 0.029398202896118164 seconds
DEBUG 01-05 12:51:20.779727.779727 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:20.779845.779845 cuda_h.py:19] end gpu_sexperts cost 0.0007061958312988281 seconds
DEBUG 01-05 12:51:20.779516.779516 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:20.780038.780038 mlpmodule.py:531] gpu group tensors cost 0.0008378028869628906 s
DEBUG 01-05 12:51:20.782307.782307 mlpmodule.py:564] gpu pad cost 0.0016508102416992188 s
DEBUG 01-05 12:51:20.783039.783039 mlpmodule.py:582] gpu group einsum cost 0.0006105899810791016 s
DEBUG 01-05 12:51:20.786576.786576 mlpmodule.py:611] gpu experts func einsum cost 0.00660252571105957 s
DEBUG 01-05 12:51:20.786732.786732 cuda_h.py:19] end gpu_experts cost 0.00678706169128418 seconds
DEBUG 01-05 12:51:20.786861.786861 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.06627082824707031 seconds
DEBUG 01-05 12:51:20.808764.808764 mlpmodule.py:662]  experts func einsum cost 0.05912208557128906 s
DEBUG 01-05 12:51:21.962356.962356 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09347963333129883 s
DEBUG 01-05 12:51:22.315614.315614 cuda_h.py:19] end generate_input_ids cost 0.35153865814208984 seconds
DEBUG 01-05 12:51:22.315288.315288 cuda_h.py:10] start init_cache
DEBUG 01-05 12:51:22.315172.315172 cuda_h.py:19] end init_cache cost 5.316734313964844e-05 seconds
DEBUG 01-05 12:51:24.763277.763277 cuda_h.py:10] start init_weights
DEBUG 01-05 12:51:24.764906.764906 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:24.764108.764108 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:24.765810.765810 cuda_h.py:19] end allocate_cuda_memory cost 0.0003757476806640625 seconds
DEBUG 01-05 12:51:24.765044.765044 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:24.765708.765708 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:24.765266.765266 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:24.765777.765777 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aacc8564-808b-4f06-b73e-69ed0610b437
DEBUG 01-05 12:51:24.765091.765091 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:24.767888.767888 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aacc8564-808b-4f06-b73e-69ed0610b437
DEBUG 01-05 12:51:24.767138.767138 cuda_h.py:19] end load_into_gpu_async cost 0.0021538734436035156 seconds
DEBUG 01-05 12:51:24.767286.767286 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:24.767483.767483 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-05 12:51:24.767424.767424 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002948760986328125 seconds
INFO 01-05 12:51:24.768490.768490 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aacc8564-808b-4f06-b73e-69ed0610b437
INFO 01-05 12:51:24.846760.846760 client.py:127] Model loaded
DEBUG 01-05 12:51:24.846157.846157 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 12:51:24.846049.846049 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:24.846941.846941 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:24.847361.847361 cuda_h.py:19] end allocate_cuda_memory cost 0.00039076805114746094 seconds
DEBUG 01-05 12:51:24.847180.847180 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:24.847342.847342 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:24.847902.847902 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:24.847089.847089 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 211b36ae-717f-449d-aba4-de3f63b3b690
DEBUG 01-05 12:51:24.848672.848672 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:24.849148.849148 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 211b36ae-717f-449d-aba4-de3f63b3b690
DEBUG 01-05 12:51:24.849127.849127 cuda_h.py:19] end load_into_gpu_async cost 0.002079010009765625 seconds
DEBUG 01-05 12:51:24.849958.849958 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:24.850588.850588 cuda_h.py:19] end restore_tensors2 cost 0.00013113021850585938 seconds
DEBUG 01-05 12:51:24.850425.850425 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003251314163208008 seconds
INFO 01-05 12:51:24.850719.850719 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 211b36ae-717f-449d-aba4-de3f63b3b690
INFO 01-05 12:51:24.866749.866749 client.py:127] Model loaded
DEBUG 01-05 12:51:24.867731.867731 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020993709564208984 seconds
DEBUG 01-05 12:51:24.867424.867424 cuda_h.py:19] end init_weights cost 0.10309267044067383 seconds
DEBUG 01-05 12:51:24.867957.867957 cuda_h.py:10] start copy_emodel
DEBUG 01-05 12:51:25.621199.621199 cuda_h.py:19] end copy_emodel cost 0.7529888153076172 seconds
DEBUG 01-05 12:51:25.621140.621140 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 12:51:25.622874.622874 cuda_h.py:19] end init_inputs_tokens cost 0.0002944469451904297 seconds
DEBUG 01-05 12:51:25.622650.622650 cuda_h.py:10] start multi_layer
DEBUG 01-05 12:51:25.622267.622267 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 12:51:25.622056.622056 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:25.622660.622660 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:25.622165.622165 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.123283386230469e-05 seconds
DEBUG 01-05 12:51:25.622265.622265 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.62939453125e-05 seconds
DEBUG 01-05 12:51:25.622155.622155 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.622845.622845 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:25.622698.622698 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.622364.622364 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.623835.623835 cuda_h.py:19] end allocate_cuda_memory cost 0.0003714561462402344 seconds
DEBUG 01-05 12:51:25.623819.623819 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.623734.623734 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.623040.623040 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.623704.623704 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 415204a1-794a-4a39-a6bd-3b2b7aa9ad7f
DEBUG 01-05 12:51:25.623277.623277 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:25.623784.623784 cuda_h.py:10] start self_attn
INFO 01-05 12:51:25.625420.625420 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 415204a1-794a-4a39-a6bd-3b2b7aa9ad7f
DEBUG 01-05 12:51:25.625020.625020 cuda_h.py:19] end load_into_gpu_async cost 0.001987934112548828 seconds
DEBUG 01-05 12:51:25.625875.625875 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.625501.625501 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-05 12:51:25.625840.625840 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027608871459960938 seconds
INFO 01-05 12:51:25.626997.626997 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 415204a1-794a-4a39-a6bd-3b2b7aa9ad7f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:25.628322.628322 cuda_h.py:19] end self_attn cost 0.004930973052978516 seconds
DEBUG 01-05 12:51:25.629491.629491 cuda_h.py:19] end iln_self_attn_paln cost 0.00642848014831543 seconds
DEBUG 01-05 12:51:25.629459.629459 cuda_h.py:10] start dense_mlp
DEBUG 01-05 12:51:25.629838.629838 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:25.629899.629899 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 1.9311904907226562e-05 seconds
DEBUG 01-05 12:51:25.630846.630846 cuda_h.py:19] end dense_mlp cost 0.0010209083557128906 seconds
DEBUG 01-05 12:51:25.630146.630146 lmp.py:217] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 12:51:25.630094.630094 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 12:51:25.630791.630791 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 12:51:25.630686.630686 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 12:51:25.630078.630078 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.5735626220703125e-05 seconds
DEBUG 01-05 12:51:25.630112.630112 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.363059997558594e-05 seconds
DEBUG 01-05 12:51:25.630470.630470 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:25.630630.630630 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
INFO 01-05 12:51:25.634157.634157 client.py:127] Model loaded
DEBUG 01-05 12:51:25.634100.634100 cuda_h.py:19] end sllm_worker_task cost 0.011644601821899414 seconds
DEBUG 01-05 12:51:25.634281.634281 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.634402.634402 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.634252.634252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.634262.634262 cuda_h.py:19] end allocate_cuda_memory cost 0.0002357959747314453 seconds
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:25.634934.634934 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.634009.634009 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.635806.635806 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.635901.635901 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, afff9b90-7e85-4c64-a7d2-fc94de1d3068
DEBUG 01-05 12:51:25.635541.635541 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:25.635295.635295 cuda_h.py:19] end self_attn cost 0.004786252975463867 seconds
DEBUG 01-05 12:51:25.635298.635298 cuda_h.py:19] end iln_self_attn_paln cost 0.005321025848388672 seconds
DEBUG 01-05 12:51:25.635856.635856 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 12:51:25.635765.635765 cuda_h.py:10] start gate
INFO 01-05 12:51:25.636388.636388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, afff9b90-7e85-4c64-a7d2-fc94de1d3068
DEBUG 01-05 12:51:25.636795.636795 cuda_h.py:19] end load_into_gpu_async cost 0.0016984939575195312 seconds
DEBUG 01-05 12:51:25.636664.636664 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.636449.636449 cuda_h.py:19] end restore_tensors2 cost 7.82012939453125e-05 seconds
DEBUG 01-05 12:51:25.636769.636769 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00240325927734375 seconds
INFO 01-05 12:51:25.637977.637977 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, afff9b90-7e85-4c64-a7d2-fc94de1d3068
DEBUG 01-05 12:51:25.637232.637232 cuda_h.py:19] end gate cost 0.0016407966613769531 seconds
DEBUG 01-05 12:51:25.637461.637461 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:25.638955.638955 lmp.py:365] 
DEBUG 01-05 12:51:25.638955.638955 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:25.638572.638572 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:25.638983.638983 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:25.638341.638341 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:25.638269.638269 lmp.py:369] 
DEBUG 01-05 12:51:25.638269.638269 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:25.638866.638866 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:25.638184.638184 lmp.py:376]   Expert 62 |     66 | CPU
DEBUG 01-05 12:51:25.638781.638781 lmp.py:376]   Expert 18 |     68 | CPU
DEBUG 01-05 12:51:25.638947.638947 lmp.py:376]   Expert 22 |     73 | CPU
DEBUG 01-05 12:51:25.638636.638636 lmp.py:376]   Expert 32 |     83 | CPU
DEBUG 01-05 12:51:25.638564.638564 lmp.py:376]   Expert 52 |     94 | CPU
DEBUG 01-05 12:51:25.638253.638253 lmp.py:376]   Expert  3 |    104 | CPU
DEBUG 01-05 12:51:25.638704.638704 lmp.py:376]   Expert 27 |    114 | CPU
DEBUG 01-05 12:51:25.638917.638917 lmp.py:376]   Expert 38 |    114 | CPU
DEBUG 01-05 12:51:25.638368.638368 lmp.py:376]   Expert 13 |    118 | CPU
DEBUG 01-05 12:51:25.638249.638249 lmp.py:376]   Expert 54 |    118 | CPU
DEBUG 01-05 12:51:25.638654.638654 lmp.py:376]   Expert 17 |    121 | CPU
DEBUG 01-05 12:51:25.638820.638820 lmp.py:376]   Expert 11 |    124 | CPU
DEBUG 01-05 12:51:25.638224.638224 lmp.py:376]   Expert 28 |    124 | CPU
DEBUG 01-05 12:51:25.638675.638675 lmp.py:376]   Expert 37 |    125 | CPU
DEBUG 01-05 12:51:25.638888.638888 lmp.py:376]   Expert 58 |    129 | CPU
DEBUG 01-05 12:51:25.638339.638339 lmp.py:376]   Expert 39 |    131 | CPU
DEBUG 01-05 12:51:25.638789.638789 lmp.py:376]   Expert 25 |    135 | CPU
DEBUG 01-05 12:51:25.638002.638002 lmp.py:376]   Expert 41 |    136 | CPU
DEBUG 01-05 12:51:25.638691.638691 lmp.py:376]   Expert 21 |    150 | CPU
DEBUG 01-05 12:51:25.638380.638380 lmp.py:376]   Expert  4 |    151 | CPU
DEBUG 01-05 12:51:25.638831.638831 lmp.py:376]   Expert 30 |    152 | CPU
DEBUG 01-05 12:51:25.638044.638044 lmp.py:376]   Expert 29 |    155 | CPU
DEBUG 01-05 12:51:25.638687.638687 lmp.py:376]   Expert 53 |    155 | CPU
DEBUG 01-05 12:51:25.638091.638091 lmp.py:376]   Expert 49 |    156 | CPU
DEBUG 01-05 12:51:25.638734.638734 lmp.py:376]   Expert 47 |    157 | CPU
DEBUG 01-05 12:51:25.638139.638139 lmp.py:376]   Expert 31 |    168 | CPU
DEBUG 01-05 12:51:25.638828.638828 lmp.py:376]   Expert 33 |    168 | CPU
DEBUG 01-05 12:51:25.638041.638041 lmp.py:376]   Expert 55 |    173 | CPU
DEBUG 01-05 12:51:25.638492.638492 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 12:51:25.638704.638704 lmp.py:376]   Expert 15 |    177 | CPU
DEBUG 01-05 12:51:25.638393.638393 lmp.py:376]   Expert  0 |    178 | CPU
DEBUG 01-05 12:51:25.638844.638844 lmp.py:376]   Expert  1 |    178 | CPU
DEBUG 01-05 12:51:25.638295.638295 lmp.py:376]   Expert 24 |    180 | GPU
DEBUG 01-05 12:51:25.638508.638508 lmp.py:376]   Expert 50 |    182 | GPU
DEBUG 01-05 12:51:25.638958.638958 lmp.py:376]   Expert 51 |    184 | GPU
DEBUG 01-05 12:51:25.638409.638409 lmp.py:376]   Expert 19 |    185 | GPU
DEBUG 01-05 12:51:25.638575.638575 lmp.py:376]   Expert  6 |    186 | GPU
DEBUG 01-05 12:51:25.638742.638742 lmp.py:376]   Expert 10 |    189 | GPU
DEBUG 01-05 12:51:25.638908.638908 lmp.py:376]   Expert 34 |    191 | GPU
DEBUG 01-05 12:51:25.638074.638074 lmp.py:376]   Expert  2 |    195 | GPU
DEBUG 01-05 12:51:25.638286.638286 lmp.py:376]   Expert 45 |    195 | GPU
DEBUG 01-05 12:51:25.638499.638499 lmp.py:376]   Expert 35 |    197 | GPU
DEBUG 01-05 12:51:25.638234.638234 lmp.py:376]   Expert 36 |    198 | GPU
DEBUG 01-05 12:51:25.638447.638447 lmp.py:376]   Expert 61 |    209 | GPU
DEBUG 01-05 12:51:25.638421.638421 lmp.py:376]   Expert 44 |    214 | GPU
DEBUG 01-05 12:51:25.638395.638395 lmp.py:376]   Expert 12 |    223 | GPU
DEBUG 01-05 12:51:25.639607.639607 lmp.py:376]   Expert  5 |    227 | GPU
DEBUG 01-05 12:51:25.639058.639058 lmp.py:376]   Expert 23 |    235 | GPU
DEBUG 01-05 12:51:25.639032.639032 lmp.py:376]   Expert 60 |    235 | GPU
DEBUG 01-05 12:51:25.639675.639675 lmp.py:376]   Expert 43 |    239 | GPU
DEBUG 01-05 12:51:25.639080.639080 lmp.py:376]   Expert  9 |    246 | GPU
DEBUG 01-05 12:51:25.639484.639484 lmp.py:376]   Expert 48 |    252 | GPU
DEBUG 01-05 12:51:25.639817.639817 lmp.py:376]   Expert  8 |    262 | GPU
DEBUG 01-05 12:51:25.639460.639460 lmp.py:376]   Expert 20 |    273 | GPU
DEBUG 01-05 12:51:25.639718.639718 lmp.py:376]   Expert 26 |    285 | GPU
DEBUG 01-05 12:51:25.639977.639977 lmp.py:376]   Expert 57 |    292 | GPU
DEBUG 01-05 12:51:25.639474.639474 lmp.py:376]   Expert  7 |    308 | GPU
DEBUG 01-05 12:51:25.639256.639256 lmp.py:376]   Expert 59 |    308 | GPU
DEBUG 01-05 12:51:25.639038.639038 lmp.py:376]   Expert 16 |    310 | GPU
DEBUG 01-05 12:51:25.639536.639536 lmp.py:376]   Expert 63 |    313 | GPU
DEBUG 01-05 12:51:25.639556.639556 lmp.py:376]   Expert 40 |    320 | GPU
DEBUG 01-05 12:51:25.639576.639576 lmp.py:376]   Expert 46 |    320 | GPU
DEBUG 01-05 12:51:25.639597.639597 lmp.py:376]   Expert 42 |    342 | GPU
DEBUG 01-05 12:51:25.639379.639379 lmp.py:376]   Expert 14 |    525 | GPU
DEBUG 01-05 12:51:25.639830.639830 lmp.py:377] 
DEBUG 01-05 12:51:25.639830.639830 lmp.py:377]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 12:51:25.639996.639996 lmp.py:378]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 12:51:25.639930.639930 cuda_h.py:19] end experts_map_get cost 0.0015087127685546875 seconds
DEBUG 01-05 12:51:25.639335.639335 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:25.639727.639727 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.639228.639228 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.640906.640906 cuda_h.py:19] end allocate_cuda_memory cost 0.0012400150299072266 seconds
DEBUG 01-05 12:51:25.640703.640703 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.640982.640982 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.640897.640897 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.640024.640024 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9349e312-2574-4abd-85f3-c93b659f1a06
DEBUG 01-05 12:51:25.641516.641516 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:25.644490.644490 client.py:127] Model loaded
DEBUG 01-05 12:51:25.644924.644924 cuda_h.py:19] end sllm_worker_task cost 0.010243654251098633 seconds
DEBUG 01-05 12:51:25.644980.644980 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.644446.644446 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.644031.644031 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.645797.645797 cuda_h.py:19] end allocate_cuda_memory cost 0.00025343894958496094 seconds
DEBUG 01-05 12:51:25.645555.645555 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.645637.645637 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.645301.645301 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.645084.645084 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8ab03bfc-ddc0-42eb-9e3a-cf0d69452eec
DEBUG 01-05 12:51:25.645069.645069 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:25.646333.646333 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9349e312-2574-4abd-85f3-c93b659f1a06
DEBUG 01-05 12:51:25.646891.646891 cuda_h.py:19] end load_into_gpu_async cost 0.000682830810546875 seconds
DEBUG 01-05 12:51:25.646640.646640 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.646812.646812 cuda_h.py:19] end restore_tensors2 cost 0.00034546852111816406 seconds
DEBUG 01-05 12:51:25.646456.646456 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016446113586425781 seconds
INFO 01-05 12:51:25.647873.647873 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8ab03bfc-ddc0-42eb-9e3a-cf0d69452eec
DEBUG 01-05 12:51:25.647229.647229 cuda_h.py:19] end load_into_gpu_async cost 0.0018701553344726562 seconds
DEBUG 01-05 12:51:25.647838.647838 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.647122.647122 cuda_h.py:19] end restore_tensors2 cost 9.822845458984375e-05 seconds
DEBUG 01-05 12:51:25.647987.647987 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028717517852783203 seconds
INFO 01-05 12:51:25.649510.649510 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8ab03bfc-ddc0-42eb-9e3a-cf0d69452eec
DEBUG 01-05 12:51:25.651529.651529 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011700630187988281 seconds
DEBUG 01-05 12:51:25.651823.651823 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:25.651151.651151 lmp.py:423] 
DEBUG 01-05 12:51:25.651151.651151 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:25.651954.651954 cuda_h.py:19] end cpu_experts_submit cost 0.00012254714965820312 seconds
DEBUG 01-05 12:51:25.651511.651511 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:25.667357.667357 mlpmodule.py:704] group tensors cost 0.015931367874145508 s
DEBUG 01-05 12:51:25.670590.670590 mlpmodule.py:742] pad cost 0.002257823944091797 s
DEBUG 01-05 12:51:25.671806.671806 mlpmodule.py:748] create cpu tensor cost 6.628036499023438e-05 s
DEBUG 01-05 12:51:25.671298.671298 mlpmodule.py:753] move to cpu cost 4.315376281738281e-05 s
DEBUG 01-05 12:51:25.684015.684015 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:25.684193.684193 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:25.684305.684305 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 12:51:25.684126.684126 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:25.704109.704109 mlpmodule.py:793] group einsum cost 0.03303790092468262 s
INFO 01-05 12:51:25.705876.705876 client.py:127] Model loaded
DEBUG 01-05 12:51:25.705686.705686 mlpmodule.py:801] cpy2cputensor cost 0.0007987022399902344 s
DEBUG 01-05 12:51:25.705791.705791 cuda_h.py:19] end sllm_worker_task cost 0.06072878837585449 seconds
DEBUG 01-05 12:51:25.710703.710703 cuda_h.py:19] end wait_cetm_experts cost 0.05948019027709961 seconds
DEBUG 01-05 12:51:25.710645.710645 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:25.711095.711095 cuda_h.py:19] end gpu_sexperts cost 0.0005321502685546875 seconds
DEBUG 01-05 12:51:25.711667.711667 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:25.711146.711146 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7418136596679688e-05 seconds
DEBUG 01-05 12:51:25.711949.711949 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:25.711089.711089 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9349e312-2574-4abd-85f3-c93b659f1a06
INFO 01-05 12:51:25.712312.712312 client.py:127] Model loaded
DEBUG 01-05 12:51:25.712301.712301 cuda_h.py:19] end wait_experts cost 0.0007879734039306641 seconds
DEBUG 01-05 12:51:25.712057.712057 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:25.712435.712435 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:25.731374.731374 mlpmodule.py:662]  experts func einsum cost 0.08016800880432129 s
DEBUG 01-05 12:51:25.732552.732552 mlpmodule.py:531] gpu group tensors cost 0.01961994171142578 s
DEBUG 01-05 12:51:25.735639.735639 mlpmodule.py:564] gpu pad cost 0.0027120113372802734 s
DEBUG 01-05 12:51:25.736591.736591 mlpmodule.py:582] gpu group einsum cost 0.0014290809631347656 s
DEBUG 01-05 12:51:25.741339.741339 mlpmodule.py:611] gpu experts func einsum cost 0.028496980667114258 s
DEBUG 01-05 12:51:25.741713.741713 cuda_h.py:19] end gpu_experts cost 0.028682947158813477 seconds
DEBUG 01-05 12:51:25.741412.741412 cuda_h.py:19] end layer_moe_generate_1 cost 0.1053621768951416 seconds
DEBUG 01-05 12:51:25.741643.741643 lmp.py:217] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 12:51:25.741810.741810 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 12:51:25.741189.741189 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 12:51:25.741375.741375 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 12:51:25.741463.741463 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.504753112792969e-05 seconds
DEBUG 01-05 12:51:25.741074.741074 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.033348083496094e-05 seconds
DEBUG 01-05 12:51:25.741055.741055 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:25.741821.741821 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.741387.741387 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.742568.742568 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.742218.742218 cuda_h.py:19] end allocate_cuda_memory cost 0.00019240379333496094 seconds
DEBUG 01-05 12:51:25.742102.742102 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.742779.742779 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.742192.742192 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.742617.742617 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4d1e1c1-25b5-4951-9a81-a4ece217af7a
DEBUG 01-05 12:51:25.742356.742356 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:25.742536.742536 cuda_h.py:10] start self_attn
INFO 01-05 12:51:25.744184.744184 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4d1e1c1-25b5-4951-9a81-a4ece217af7a
DEBUG 01-05 12:51:25.744809.744809 cuda_h.py:19] end load_into_gpu_async cost 0.0016624927520751953 seconds
DEBUG 01-05 12:51:25.744710.744710 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.744476.744476 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-05 12:51:25.744715.744715 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002237558364868164 seconds
INFO 01-05 12:51:25.744781.744781 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4d1e1c1-25b5-4951-9a81-a4ece217af7a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:25.747285.747285 cuda_h.py:19] end self_attn cost 0.004103183746337891 seconds
DEBUG 01-05 12:51:25.747449.747449 cuda_h.py:19] end iln_self_attn_paln cost 0.005632162094116211 seconds
DEBUG 01-05 12:51:25.747862.747862 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 12:51:25.747771.747771 cuda_h.py:10] start gate
DEBUG 01-05 12:51:25.748319.748319 cuda_h.py:19] end gate cost 0.0007185935974121094 seconds
DEBUG 01-05 12:51:25.748294.748294 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:25.748642.748642 lmp.py:365] 
DEBUG 01-05 12:51:25.748642.748642 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:25.748021.748021 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:25.748293.748293 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:25.748797.748797 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:25.748155.748155 lmp.py:369] 
DEBUG 01-05 12:51:25.748155.748155 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:25.748990.748990 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:25.748309.748309 lmp.py:376]   Expert 34 |     42 | CPU
DEBUG 01-05 12:51:25.748667.748667 lmp.py:376]   Expert 36 |     50 | CPU
DEBUG 01-05 12:51:25.749310.749310 lmp.py:376]   Expert 58 |     65 | CPU
DEBUG 01-05 12:51:25.749715.749715 lmp.py:376]   Expert  3 |     66 | CPU
DEBUG 01-05 12:51:25.749120.749120 lmp.py:376]   Expert 26 |     70 | CPU
DEBUG 01-05 12:51:25.749524.749524 lmp.py:376]   Expert  8 |     78 | CPU
DEBUG 01-05 12:51:25.749452.749452 lmp.py:376]   Expert 27 |     78 | CPU
DEBUG 01-05 12:51:25.749618.749618 lmp.py:376]   Expert 29 |     80 | CPU
DEBUG 01-05 12:51:25.749546.749546 lmp.py:376]   Expert  7 |     94 | CPU
DEBUG 01-05 12:51:25.749712.749712 lmp.py:376]   Expert 10 |     97 | CPU
DEBUG 01-05 12:51:25.749116.749116 lmp.py:376]   Expert 28 |    106 | CPU
DEBUG 01-05 12:51:25.749998.749998 lmp.py:376]   Expert 13 |    108 | CPU
DEBUG 01-05 12:51:25.749594.749594 lmp.py:376]   Expert 21 |    108 | CPU
DEBUG 01-05 12:51:25.749714.749714 lmp.py:376]   Expert 19 |    114 | CPU
DEBUG 01-05 12:51:25.749880.749880 lmp.py:376]   Expert 62 |    126 | CPU
DEBUG 01-05 12:51:25.749808.749808 lmp.py:376]   Expert 40 |    133 | CPU
DEBUG 01-05 12:51:25.749974.749974 lmp.py:376]   Expert  5 |    140 | CPU
DEBUG 01-05 12:51:25.749140.749140 lmp.py:376]   Expert 52 |    141 | CPU
DEBUG 01-05 12:51:25.749068.749068 lmp.py:376]   Expert 63 |    142 | CPU
DEBUG 01-05 12:51:25.749618.749618 lmp.py:376]   Expert  9 |    148 | CPU
DEBUG 01-05 12:51:25.749738.749738 lmp.py:376]   Expert 25 |    150 | CPU
DEBUG 01-05 12:51:25.749858.749858 lmp.py:376]   Expert 50 |    152 | CPU
DEBUG 01-05 12:51:25.749739.749739 lmp.py:376]   Expert 59 |    152 | CPU
DEBUG 01-05 12:51:25.749621.749621 lmp.py:376]   Expert 33 |    154 | CPU
DEBUG 01-05 12:51:25.749502.749502 lmp.py:376]   Expert 17 |    156 | CPU
DEBUG 01-05 12:51:25.749814.749814 lmp.py:376]   Expert 49 |    156 | CPU
DEBUG 01-05 12:51:25.749649.749649 lmp.py:376]   Expert 16 |    160 | CPU
DEBUG 01-05 12:51:25.749961.749961 lmp.py:376]   Expert 60 |    164 | CPU
DEBUG 01-05 12:51:25.749035.749035 lmp.py:376]   Expert  0 |    167 | CPU
DEBUG 01-05 12:51:25.749154.749154 lmp.py:376]   Expert 24 |    167 | CPU
DEBUG 01-05 12:51:25.749274.749274 lmp.py:376]   Expert 30 |    170 | CPU
DEBUG 01-05 12:51:25.749156.749156 lmp.py:376]   Expert 35 |    170 | CPU
DEBUG 01-05 12:51:25.749799.749799 lmp.py:376]   Expert  1 |    174 | GPU
DEBUG 01-05 12:51:25.749680.749680 lmp.py:376]   Expert 38 |    179 | GPU
DEBUG 01-05 12:51:25.749084.749084 lmp.py:376]   Expert 45 |    180 | GPU
DEBUG 01-05 12:51:25.749966.749966 lmp.py:376]   Expert  6 |    181 | GPU
DEBUG 01-05 12:51:25.749086.749086 lmp.py:376]   Expert 44 |    184 | GPU
DEBUG 01-05 12:51:25.749398.749398 lmp.py:376]   Expert 31 |    199 | GPU
DEBUG 01-05 12:51:25.749332.749332 lmp.py:376]   Expert 48 |    206 | GPU
DEBUG 01-05 12:51:25.749167.749167 lmp.py:376]   Expert 39 |    229 | GPU
DEBUG 01-05 12:51:25.749287.749287 lmp.py:376]   Expert 37 |    237 | GPU
DEBUG 01-05 12:51:25.749215.749215 lmp.py:376]   Expert 55 |    238 | GPU
DEBUG 01-05 12:51:25.749619.749619 lmp.py:376]   Expert  4 |    239 | GPU
DEBUG 01-05 12:51:25.749785.749785 lmp.py:376]   Expert 14 |    242 | GPU
DEBUG 01-05 12:51:25.749713.749713 lmp.py:376]   Expert 22 |    242 | GPU
DEBUG 01-05 12:51:25.749402.749402 lmp.py:376]   Expert 51 |    248 | GPU
DEBUG 01-05 12:51:25.749569.749569 lmp.py:376]   Expert 41 |    255 | GPU
DEBUG 01-05 12:51:25.749496.749496 lmp.py:376]   Expert 57 |    255 | GPU
DEBUG 01-05 12:51:25.749424.749424 lmp.py:376]   Expert  2 |    256 | GPU
DEBUG 01-05 12:51:25.749305.749305 lmp.py:376]   Expert 12 |    262 | GPU
DEBUG 01-05 12:51:25.749187.749187 lmp.py:376]   Expert 47 |    269 | GPU
DEBUG 01-05 12:51:25.749307.749307 lmp.py:376]   Expert 20 |    271 | GPU
DEBUG 01-05 12:51:25.749188.749188 lmp.py:376]   Expert 15 |    275 | GPU
DEBUG 01-05 12:51:25.749069.749069 lmp.py:376]   Expert 42 |    281 | GPU
DEBUG 01-05 12:51:25.749474.749474 lmp.py:376]   Expert 23 |    286 | GPU
DEBUG 01-05 12:51:25.749163.749163 lmp.py:376]   Expert 53 |    304 | GPU
DEBUG 01-05 12:51:25.749329.749329 lmp.py:376]   Expert 61 |    306 | GPU
DEBUG 01-05 12:51:25.749019.749019 lmp.py:376]   Expert 56 |    312 | GPU
DEBUG 01-05 12:51:25.749708.749708 lmp.py:376]   Expert 18 |    314 | GPU
DEBUG 01-05 12:51:25.750397.750397 lmp.py:376]   Expert 54 |    315 | GPU
DEBUG 01-05 12:51:25.750325.750325 lmp.py:376]   Expert 46 |    330 | GPU
DEBUG 01-05 12:51:25.750014.750014 lmp.py:376]   Expert 32 |    338 | GPU
DEBUG 01-05 12:51:25.750180.750180 lmp.py:376]   Expert 43 |    364 | GPU
DEBUG 01-05 12:51:25.750062.750062 lmp.py:376]   Expert 11 |    413 | GPU
DEBUG 01-05 12:51:25.750658.750658 lmp.py:377] 
DEBUG 01-05 12:51:25.750658.750658 lmp.py:377]   CPU total tokens: 3904 (31.8%)
DEBUG 01-05 12:51:25.750970.750970 lmp.py:378]   GPU total tokens: 8384 (68.2%)
DEBUG 01-05 12:51:25.750051.750051 cuda_h.py:19] end experts_map_get cost 0.0017886161804199219 seconds
DEBUG 01-05 12:51:25.750409.750409 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:25.750185.750185 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.750931.750931 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.751494.751494 cuda_h.py:19] end allocate_cuda_memory cost 0.0009407997131347656 seconds
DEBUG 01-05 12:51:25.751913.751913 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.751338.751338 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.751439.751439 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.751718.751718 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 73efd9d9-5fe7-4d74-9a9e-ef7c1290708c
DEBUG 01-05 12:51:25.751605.751605 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:25.752573.752573 client.py:127] Model loaded
DEBUG 01-05 12:51:25.752212.752212 cuda_h.py:19] end sllm_worker_task cost 0.01019597053527832 seconds
INFO 01-05 12:51:25.753757.753757 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 73efd9d9-5fe7-4d74-9a9e-ef7c1290708c
DEBUG 01-05 12:51:25.753878.753878 cuda_h.py:19] end load_into_gpu_async cost 0.0022928714752197266 seconds
DEBUG 01-05 12:51:25.753482.753482 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.754921.754921 cuda_h.py:19] end restore_tensors2 cost 0.00043773651123046875 seconds
DEBUG 01-05 12:51:25.754327.754327 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004013776779174805 seconds
DEBUG 01-05 12:51:25.757993.757993 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007143497467041016 seconds
DEBUG 01-05 12:51:25.757075.757075 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:25.757979.757979 lmp.py:423] 
DEBUG 01-05 12:51:25.757979.757979 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:25.757822.757822 cuda_h.py:19] end cpu_experts_submit cost 0.00011849403381347656 seconds
DEBUG 01-05 12:51:25.757916.757916 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:25.772053.772053 mlpmodule.py:704] group tensors cost 0.014396429061889648 s
DEBUG 01-05 12:51:25.774044.774044 mlpmodule.py:742] pad cost 0.00148773193359375 s
DEBUG 01-05 12:51:25.774318.774318 mlpmodule.py:748] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-05 12:51:25.774215.774215 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-05 12:51:25.785921.785921 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:25.785377.785377 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:25.785115.785115 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 12:51:25.785854.785854 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:25.803318.803318 mlpmodule.py:793] group einsum cost 0.02893662452697754 s
DEBUG 01-05 12:51:25.804181.804181 mlpmodule.py:801] cpy2cputensor cost 0.0006470680236816406 s
DEBUG 01-05 12:51:25.809442.809442 cuda_h.py:19] end wait_cetm_experts cost 0.05144953727722168 seconds
DEBUG 01-05 12:51:25.809597.809597 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:25.809881.809881 cuda_h.py:19] end gpu_sexperts cost 0.0005152225494384766 seconds
DEBUG 01-05 12:51:25.809863.809863 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:25.809687.809687 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.886222839355469e-05 seconds
DEBUG 01-05 12:51:25.809681.809681 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:25.809404.809404 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 73efd9d9-5fe7-4d74-9a9e-ef7c1290708c
INFO 01-05 12:51:25.810264.810264 client.py:127] Model loaded
DEBUG 01-05 12:51:25.810723.810723 cuda_h.py:19] end wait_experts cost 0.0010156631469726562 seconds
DEBUG 01-05 12:51:25.810333.810333 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:25.811950.811950 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:25.811757.811757 mlpmodule.py:531] gpu group tensors cost 0.0006823539733886719 s
DEBUG 01-05 12:51:25.814132.814132 mlpmodule.py:564] gpu pad cost 0.00222015380859375 s
DEBUG 01-05 12:51:25.814725.814725 mlpmodule.py:582] gpu group einsum cost 0.0006396770477294922 s
DEBUG 01-05 12:51:25.819763.819763 mlpmodule.py:611] gpu experts func einsum cost 0.008375167846679688 s
DEBUG 01-05 12:51:25.819042.819042 cuda_h.py:19] end gpu_experts cost 0.008671283721923828 seconds
DEBUG 01-05 12:51:25.819370.819370 cuda_h.py:19] end layer_moe_generate_2 cost 0.07228636741638184 seconds
DEBUG 01-05 12:51:25.819217.819217 lmp.py:217] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 12:51:25.820565.820565 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 12:51:25.820214.820214 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 12:51:25.820799.820799 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 12:51:25.820595.820595 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.123283386230469e-05 seconds
DEBUG 01-05 12:51:25.820682.820682 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.651878356933594e-05 seconds
DEBUG 01-05 12:51:25.820021.820021 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:25.820621.820621 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.820630.820630 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.820982.820982 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.821816.821816 cuda_h.py:19] end allocate_cuda_memory cost 0.0005447864532470703 seconds
DEBUG 01-05 12:51:25.821806.821806 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.821569.821569 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.821723.821723 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.821234.821234 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8922d05a-fc87-40cb-ad8e-6c69f9ecd82c
DEBUG 01-05 12:51:25.821687.821687 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:25.821340.821340 cuda_h.py:10] start self_attn
INFO 01-05 12:51:25.822980.822980 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8922d05a-fc87-40cb-ad8e-6c69f9ecd82c
DEBUG 01-05 12:51:25.822247.822247 cuda_h.py:19] end load_into_gpu_async cost 0.0010614395141601562 seconds
DEBUG 01-05 12:51:25.822519.822519 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.822086.822086 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-05 12:51:25.822180.822180 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019555091857910156 seconds
INFO 01-05 12:51:25.822621.822621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8922d05a-fc87-40cb-ad8e-6c69f9ecd82c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:25.825941.825941 cuda_h.py:19] end self_attn cost 0.004239082336425781 seconds
DEBUG 01-05 12:51:25.826913.826913 cuda_h.py:19] end iln_self_attn_paln cost 0.006032228469848633 seconds
DEBUG 01-05 12:51:25.826756.826756 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 12:51:25.826619.826619 cuda_h.py:10] start gate
INFO 01-05 12:51:25.830352.830352 client.py:127] Model loaded
DEBUG 01-05 12:51:25.830380.830380 cuda_h.py:19] end sllm_worker_task cost 0.009756803512573242 seconds
DEBUG 01-05 12:51:25.830234.830234 mlpmodule.py:662]  experts func einsum cost 0.07283616065979004 s
DEBUG 01-05 12:51:25.831620.831620 cuda_h.py:19] end gate cost 0.004729509353637695 seconds
DEBUG 01-05 12:51:25.831224.831224 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:25.831140.831140 lmp.py:365] 
DEBUG 01-05 12:51:25.831140.831140 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:25.831135.831135 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:25.831215.831215 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:25.831481.831481 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:25.831077.831077 lmp.py:369] 
DEBUG 01-05 12:51:25.831077.831077 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:25.831389.831389 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:25.831231.831231 lmp.py:376]   Expert 61 |     54 | CPU
DEBUG 01-05 12:51:25.831351.831351 lmp.py:376]   Expert 15 |     71 | CPU
DEBUG 01-05 12:51:25.831471.831471 lmp.py:376]   Expert 32 |     72 | CPU
DEBUG 01-05 12:51:25.831114.831114 lmp.py:376]   Expert  4 |     83 | CPU
DEBUG 01-05 12:51:25.831757.831757 lmp.py:376]   Expert 59 |     87 | CPU
DEBUG 01-05 12:51:25.831161.831161 lmp.py:376]   Expert 37 |     89 | CPU
DEBUG 01-05 12:51:25.831996.831996 lmp.py:376]   Expert 16 |     92 | CPU
DEBUG 01-05 12:51:25.832116.832116 lmp.py:376]   Expert  1 |     95 | CPU
DEBUG 01-05 12:51:25.832236.832236 lmp.py:376]   Expert  5 |    101 | CPU
DEBUG 01-05 12:51:25.832879.832879 lmp.py:376]   Expert  6 |    105 | CPU
DEBUG 01-05 12:51:25.832999.832999 lmp.py:376]   Expert 28 |    113 | CPU
DEBUG 01-05 12:51:25.832403.832403 lmp.py:376]   Expert  7 |    117 | CPU
DEBUG 01-05 12:51:25.832808.832808 lmp.py:376]   Expert  8 |    126 | CPU
DEBUG 01-05 12:51:25.832974.832974 lmp.py:376]   Expert 36 |    130 | CPU
DEBUG 01-05 12:51:25.832140.832140 lmp.py:376]   Expert 44 |    131 | CPU
DEBUG 01-05 12:51:25.832306.832306 lmp.py:376]   Expert 42 |    135 | CPU
DEBUG 01-05 12:51:25.832234.832234 lmp.py:376]   Expert 63 |    138 | CPU
DEBUG 01-05 12:51:25.832162.832162 lmp.py:376]   Expert 24 |    139 | CPU
DEBUG 01-05 12:51:25.832520.832520 lmp.py:376]   Expert 10 |    140 | CPU
DEBUG 01-05 12:51:25.832163.832163 lmp.py:376]   Expert 52 |    141 | CPU
DEBUG 01-05 12:51:25.832283.832283 lmp.py:376]   Expert 38 |    142 | CPU
DEBUG 01-05 12:51:25.832641.832641 lmp.py:376]   Expert 29 |    145 | CPU
DEBUG 01-05 12:51:25.832807.832807 lmp.py:376]   Expert 55 |    146 | CPU
DEBUG 01-05 12:51:25.832973.832973 lmp.py:376]   Expert 12 |    149 | CPU
DEBUG 01-05 12:51:25.832901.832901 lmp.py:376]   Expert 49 |    151 | CPU
DEBUG 01-05 12:51:25.832590.832590 lmp.py:376]   Expert 30 |    154 | CPU
DEBUG 01-05 12:51:25.832756.832756 lmp.py:376]   Expert 23 |    159 | CPU
DEBUG 01-05 12:51:25.832922.832922 lmp.py:376]   Expert 26 |    166 | CPU
DEBUG 01-05 12:51:25.832850.832850 lmp.py:376]   Expert 56 |    171 | CPU
DEBUG 01-05 12:51:25.832838.832838 lmp.py:376]   Expert 57 |    172 | CPU
DEBUG 01-05 12:51:25.832170.832170 lmp.py:376]   Expert 58 |    175 | CPU
DEBUG 01-05 12:51:25.832151.832151 lmp.py:376]   Expert 18 |    176 | CPU
DEBUG 01-05 12:51:25.832271.832271 lmp.py:376]   Expert 11 |    177 | GPU
DEBUG 01-05 12:51:25.832914.832914 lmp.py:376]   Expert 62 |    181 | GPU
DEBUG 01-05 12:51:25.832080.832080 lmp.py:376]   Expert 35 |    190 | GPU
DEBUG 01-05 12:51:25.832484.832484 lmp.py:376]   Expert 40 |    190 | GPU
DEBUG 01-05 12:51:25.832651.832651 lmp.py:376]   Expert  2 |    192 | GPU
DEBUG 01-05 12:51:25.832055.832055 lmp.py:376]   Expert 48 |    193 | GPU
DEBUG 01-05 12:51:25.832460.832460 lmp.py:376]   Expert 31 |    195 | GPU
DEBUG 01-05 12:51:25.832626.832626 lmp.py:376]   Expert 13 |    196 | GPU
DEBUG 01-05 12:51:25.832269.832269 lmp.py:376]   Expert 47 |    199 | GPU
DEBUG 01-05 12:51:25.832865.832865 lmp.py:376]   Expert 20 |    209 | GPU
DEBUG 01-05 12:51:25.832747.832747 lmp.py:376]   Expert 45 |    215 | GPU
DEBUG 01-05 12:51:25.832867.832867 lmp.py:376]   Expert  0 |    221 | GPU
DEBUG 01-05 12:51:25.832510.832510 lmp.py:376]   Expert 17 |    223 | GPU
DEBUG 01-05 12:51:25.832153.832153 lmp.py:376]   Expert 33 |    224 | GPU
DEBUG 01-05 12:51:25.832319.832319 lmp.py:376]   Expert 46 |    225 | GPU
DEBUG 01-05 12:51:25.832485.832485 lmp.py:376]   Expert 39 |    230 | GPU
DEBUG 01-05 12:51:25.832889.832889 lmp.py:376]   Expert 22 |    232 | GPU
DEBUG 01-05 12:51:25.832294.832294 lmp.py:376]   Expert 19 |    240 | GPU
DEBUG 01-05 12:51:25.832699.832699 lmp.py:376]   Expert 51 |    243 | GPU
DEBUG 01-05 12:51:25.832865.832865 lmp.py:376]   Expert 53 |    247 | GPU
DEBUG 01-05 12:51:25.832269.832269 lmp.py:376]   Expert 34 |    248 | GPU
DEBUG 01-05 12:51:25.832435.832435 lmp.py:376]   Expert 27 |    268 | GPU
DEBUG 01-05 12:51:25.832078.832078 lmp.py:376]   Expert  3 |    276 | GPU
DEBUG 01-05 12:51:25.832198.832198 lmp.py:376]   Expert 54 |    282 | GPU
DEBUG 01-05 12:51:25.832841.832841 lmp.py:376]   Expert 50 |    303 | GPU
DEBUG 01-05 12:51:25.832961.832961 lmp.py:376]   Expert 60 |    311 | GPU
DEBUG 01-05 12:51:25.832365.832365 lmp.py:376]   Expert 21 |    327 | GPU
DEBUG 01-05 12:51:25.832770.832770 lmp.py:376]   Expert 14 |    344 | GPU
DEBUG 01-05 12:51:25.832936.832936 lmp.py:376]   Expert 43 |    381 | GPU
DEBUG 01-05 12:51:25.832102.832102 lmp.py:376]   Expert  9 |    396 | GPU
DEBUG 01-05 12:51:25.832268.832268 lmp.py:376]   Expert 41 |    399 | GPU
DEBUG 01-05 12:51:25.833435.833435 lmp.py:376]   Expert 25 |    466 | GPU
DEBUG 01-05 12:51:25.833554.833554 lmp.py:377] 
DEBUG 01-05 12:51:25.833554.833554 lmp.py:377]   CPU total tokens: 4065 (33.1%)
DEBUG 01-05 12:51:25.833674.833674 lmp.py:378]   GPU total tokens: 8223 (66.9%)
DEBUG 01-05 12:51:25.833755.833755 cuda_h.py:19] end experts_map_get cost 0.0017628669738769531 seconds
DEBUG 01-05 12:51:25.833066.833066 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:25.833181.833181 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.833463.833463 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.833148.833148 cuda_h.py:19] end allocate_cuda_memory cost 0.00022125244140625 seconds
DEBUG 01-05 12:51:25.833958.833958 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.833760.833760 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.833238.833238 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.833080.833080 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1e7d93cf-6f00-4e32-9892-d59ccf0ead1f
DEBUG 01-05 12:51:25.833961.833961 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:25.835965.835965 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1e7d93cf-6f00-4e32-9892-d59ccf0ead1f
DEBUG 01-05 12:51:25.835669.835669 cuda_h.py:19] end load_into_gpu_async cost 0.0014407634735107422 seconds
DEBUG 01-05 12:51:25.835180.835180 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.835269.835269 cuda_h.py:19] end restore_tensors2 cost 0.0004591941833496094 seconds
DEBUG 01-05 12:51:25.835583.835583 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002483367919921875 seconds
DEBUG 01-05 12:51:25.838213.838213 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005730152130126953 seconds
DEBUG 01-05 12:51:25.838579.838579 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:25.838264.838264 lmp.py:423] 
DEBUG 01-05 12:51:25.838264.838264 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:25.839346.839346 cuda_h.py:19] end cpu_experts_submit cost 0.00011491775512695312 seconds
DEBUG 01-05 12:51:25.839472.839472 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:25.844042.844042 mlpmodule.py:704] group tensors cost 0.0047931671142578125 s
DEBUG 01-05 12:51:25.846331.846331 mlpmodule.py:742] pad cost 0.0018360614776611328 s
DEBUG 01-05 12:51:25.846056.846056 mlpmodule.py:748] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-05 12:51:25.846542.846542 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 12:51:25.856253.856253 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:25.857410.857410 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:25.857817.857817 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 12:51:25.857450.857450 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:25.875004.875004 mlpmodule.py:793] group einsum cost 0.028353452682495117 s
DEBUG 01-05 12:51:25.876637.876637 mlpmodule.py:801] cpy2cputensor cost 0.0006728172302246094 s
DEBUG 01-05 12:51:25.880253.880253 cuda_h.py:19] end wait_cetm_experts cost 0.0418398380279541 seconds
DEBUG 01-05 12:51:25.881169.881169 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:25.881837.881837 cuda_h.py:19] end gpu_sexperts cost 0.000518798828125 seconds
DEBUG 01-05 12:51:25.881342.881342 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:25.881259.881259 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-05 12:51:25.881538.881538 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:25.881824.881824 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1e7d93cf-6f00-4e32-9892-d59ccf0ead1f
INFO 01-05 12:51:25.889975.889975 client.py:127] Model loaded
DEBUG 01-05 12:51:25.889209.889209 cuda_h.py:19] end wait_experts cost 0.0075533390045166016 seconds
DEBUG 01-05 12:51:25.889157.889157 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:25.889967.889967 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:25.890635.890635 mlpmodule.py:531] gpu group tensors cost 0.0006885528564453125 s
DEBUG 01-05 12:51:25.892502.892502 mlpmodule.py:564] gpu pad cost 0.001916646957397461 s
DEBUG 01-05 12:51:25.892982.892982 mlpmodule.py:582] gpu group einsum cost 0.0006017684936523438 s
DEBUG 01-05 12:51:25.896895.896895 mlpmodule.py:611] gpu experts func einsum cost 0.007269859313964844 s
DEBUG 01-05 12:51:25.897558.897558 cuda_h.py:19] end gpu_experts cost 0.007564067840576172 seconds
DEBUG 01-05 12:51:25.897216.897216 cuda_h.py:19] end layer_moe_generate_3 cost 0.07067108154296875 seconds
DEBUG 01-05 12:51:25.897077.897077 lmp.py:217] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 12:51:25.897177.897177 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 12:51:25.897112.897112 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 12:51:25.897822.897822 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 12:51:25.897519.897519 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.9087066650390625e-05 seconds
DEBUG 01-05 12:51:25.897414.897414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.270408630371094e-05 seconds
DEBUG 01-05 12:51:25.897156.897156 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:25.897901.897901 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.897632.897632 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.897283.897283 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.899697.899697 cuda_h.py:19] end allocate_cuda_memory cost 0.0012469291687011719 seconds
DEBUG 01-05 12:51:25.899230.899230 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.899152.899152 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.899115.899115 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.899493.899493 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ad0efa6d-7fc0-4648-8bcd-48a9f4a24a91
DEBUG 01-05 12:51:25.899199.899199 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:25.903208.903208 mlpmodule.py:662]  experts func einsum cost 0.06455230712890625 s
INFO 01-05 12:51:25.903545.903545 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ad0efa6d-7fc0-4648-8bcd-48a9f4a24a91
DEBUG 01-05 12:51:25.904583.904583 cuda_h.py:19] end load_into_gpu_async cost 0.004946231842041016 seconds
DEBUG 01-05 12:51:25.904664.904664 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.904093.904093 cuda_h.py:19] end restore_tensors2 cost 9.179115295410156e-05 seconds
DEBUG 01-05 12:51:25.904797.904797 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0066471099853515625 seconds
DEBUG 01-05 12:51:25.904017.904017 cuda_h.py:10] start self_attn
INFO 01-05 12:51:25.905646.905646 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ad0efa6d-7fc0-4648-8bcd-48a9f4a24a91
INFO 01-05 12:51:25.907943.907943 client.py:127] Model loaded
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-05 12:51:25.907227.907227 cuda_h.py:19] end sllm_worker_task cost 0.010057926177978516 seconds
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:25.908796.908796 cuda_h.py:19] end self_attn cost 0.0041463375091552734 seconds
DEBUG 01-05 12:51:25.909609.909609 cuda_h.py:19] end iln_self_attn_paln cost 0.01150369644165039 seconds
DEBUG 01-05 12:51:25.909975.909975 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 12:51:25.909407.909407 cuda_h.py:10] start gate
DEBUG 01-05 12:51:25.909252.909252 cuda_h.py:19] end gate cost 0.0006875991821289062 seconds
DEBUG 01-05 12:51:25.909605.909605 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:25.910242.910242 lmp.py:365] 
DEBUG 01-05 12:51:25.910242.910242 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:25.910567.910567 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:25.910932.910932 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:25.910483.910483 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:25.910126.910126 lmp.py:369] 
DEBUG 01-05 12:51:25.910126.910126 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:25.910769.910769 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:25.910134.910134 lmp.py:376]   Expert 13 |     41 | CPU
DEBUG 01-05 12:51:25.910015.910015 lmp.py:376]   Expert 60 |     50 | CPU
DEBUG 01-05 12:51:25.910181.910181 lmp.py:376]   Expert 11 |     60 | CPU
DEBUG 01-05 12:51:25.910871.910871 lmp.py:376]   Expert 26 |     74 | CPU
DEBUG 01-05 12:51:25.910321.910321 lmp.py:376]   Expert 56 |     75 | CPU
DEBUG 01-05 12:51:25.910011.910011 lmp.py:376]   Expert  3 |     81 | CPU
DEBUG 01-05 12:51:25.910700.910700 lmp.py:376]   Expert 58 |     88 | CPU
DEBUG 01-05 12:51:25.910628.910628 lmp.py:376]   Expert 25 |     89 | CPU
DEBUG 01-05 12:51:25.910555.910555 lmp.py:376]   Expert 36 |     89 | CPU
DEBUG 01-05 12:51:25.910437.910437 lmp.py:376]   Expert  7 |     91 | CPU
DEBUG 01-05 12:51:25.910603.910603 lmp.py:376]   Expert 34 |     93 | CPU
DEBUG 01-05 12:51:25.910531.910531 lmp.py:376]   Expert 51 |     93 | CPU
DEBUG 01-05 12:51:25.910174.910174 lmp.py:376]   Expert 41 |     99 | CPU
DEBUG 01-05 12:51:25.910863.910863 lmp.py:376]   Expert 28 |    100 | CPU
DEBUG 01-05 12:51:25.910075.910075 lmp.py:376]   Expert 45 |    100 | CPU
DEBUG 01-05 12:51:25.910765.910765 lmp.py:376]   Expert 48 |    101 | CPU
DEBUG 01-05 12:51:25.910977.910977 lmp.py:376]   Expert  6 |    102 | CPU
DEBUG 01-05 12:51:25.910428.910428 lmp.py:376]   Expert 33 |    111 | CPU
DEBUG 01-05 12:51:25.910402.910402 lmp.py:376]   Expert 16 |    112 | CPU
DEBUG 01-05 12:51:25.910615.910615 lmp.py:376]   Expert  9 |    126 | CPU
DEBUG 01-05 12:51:25.910066.910066 lmp.py:376]   Expert 24 |    127 | CPU
DEBUG 01-05 12:51:25.910040.910040 lmp.py:376]   Expert 55 |    128 | CPU
DEBUG 01-05 12:51:25.910444.910444 lmp.py:376]   Expert 18 |    130 | CPU
DEBUG 01-05 12:51:25.910849.910849 lmp.py:376]   Expert 14 |    134 | CPU
DEBUG 01-05 12:51:25.910015.910015 lmp.py:376]   Expert 17 |    136 | CPU
DEBUG 01-05 12:51:25.910181.910181 lmp.py:376]   Expert  4 |    141 | CPU
DEBUG 01-05 12:51:25.910109.910109 lmp.py:376]   Expert 47 |    146 | CPU
DEBUG 01-05 12:51:25.910560.910560 lmp.py:376]   Expert 50 |    146 | CPU
DEBUG 01-05 12:51:25.910772.910772 lmp.py:376]   Expert  2 |    150 | CPU
DEBUG 01-05 12:51:25.910746.910746 lmp.py:376]   Expert 44 |    153 | CPU
DEBUG 01-05 12:51:25.910197.910197 lmp.py:376]   Expert 22 |    167 | CPU
DEBUG 01-05 12:51:25.910171.910171 lmp.py:376]   Expert 54 |    176 | CPU
DEBUG 01-05 12:51:25.910622.910622 lmp.py:376]   Expert 31 |    178 | GPU
DEBUG 01-05 12:51:25.911073.911073 lmp.py:376]   Expert 10 |    179 | GPU
DEBUG 01-05 12:51:25.911047.911047 lmp.py:376]   Expert 40 |    188 | GPU
DEBUG 01-05 12:51:25.911259.911259 lmp.py:376]   Expert 37 |    190 | GPU
DEBUG 01-05 12:51:25.911472.911472 lmp.py:376]   Expert 21 |    198 | GPU
DEBUG 01-05 12:51:25.911115.911115 lmp.py:376]   Expert 46 |    200 | GPU
DEBUG 01-05 12:51:25.911042.911042 lmp.py:376]   Expert 61 |    202 | GPU
DEBUG 01-05 12:51:25.911493.911493 lmp.py:376]   Expert 15 |    208 | GPU
DEBUG 01-05 12:51:25.911421.911421 lmp.py:376]   Expert  8 |    209 | GPU
DEBUG 01-05 12:51:25.911349.911349 lmp.py:376]   Expert 42 |    211 | GPU
DEBUG 01-05 12:51:25.911800.911800 lmp.py:376]   Expert 53 |    211 | GPU
DEBUG 01-05 12:51:25.911012.911012 lmp.py:376]   Expert 63 |    219 | GPU
DEBUG 01-05 12:51:25.911986.911986 lmp.py:376]   Expert 27 |    220 | GPU
DEBUG 01-05 12:51:25.911437.911437 lmp.py:376]   Expert 20 |    225 | GPU
DEBUG 01-05 12:51:25.911649.911649 lmp.py:376]   Expert 29 |    225 | GPU
DEBUG 01-05 12:51:25.911624.911624 lmp.py:376]   Expert 32 |    233 | GPU
DEBUG 01-05 12:51:25.911836.911836 lmp.py:376]   Expert 57 |    240 | GPU
DEBUG 01-05 12:51:25.911572.911572 lmp.py:376]   Expert 19 |    264 | GPU
DEBUG 01-05 12:51:25.911261.911261 lmp.py:376]   Expert 23 |    265 | GPU
DEBUG 01-05 12:51:25.911950.911950 lmp.py:376]   Expert 38 |    266 | GPU
DEBUG 01-05 12:51:25.911878.911878 lmp.py:376]   Expert  0 |    267 | GPU
DEBUG 01-05 12:51:25.911806.911806 lmp.py:376]   Expert  1 |    278 | GPU
DEBUG 01-05 12:51:25.911733.911733 lmp.py:376]   Expert 12 |    284 | GPU
DEBUG 01-05 12:51:25.911469.911469 lmp.py:376]   Expert 62 |    299 | GPU
DEBUG 01-05 12:51:25.911443.911443 lmp.py:376]   Expert 30 |    314 | GPU
DEBUG 01-05 12:51:25.911417.911417 lmp.py:376]   Expert 49 |    325 | GPU
DEBUG 01-05 12:51:25.911391.911391 lmp.py:376]   Expert 35 |    331 | GPU
DEBUG 01-05 12:51:25.911604.911604 lmp.py:376]   Expert 52 |    400 | GPU
DEBUG 01-05 12:51:25.911339.911339 lmp.py:376]   Expert 39 |    420 | GPU
DEBUG 01-05 12:51:25.911313.911313 lmp.py:376]   Expert  5 |    421 | GPU
DEBUG 01-05 12:51:25.911287.911287 lmp.py:376]   Expert 43 |    474 | GPU
DEBUG 01-05 12:51:25.911738.911738 lmp.py:376]   Expert 59 |    635 | GPU
DEBUG 01-05 12:51:25.911381.911381 lmp.py:377] 
DEBUG 01-05 12:51:25.911381.911381 lmp.py:377]   CPU total tokens: 3509 (28.6%)
DEBUG 01-05 12:51:25.911263.911263 lmp.py:378]   GPU total tokens: 8779 (71.4%)
DEBUG 01-05 12:51:25.911197.911197 cuda_h.py:19] end experts_map_get cost 0.0016379356384277344 seconds
DEBUG 01-05 12:51:25.911840.911840 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:25.911424.911424 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.911469.911469 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.912523.912523 cuda_h.py:19] end allocate_cuda_memory cost 0.00021767616271972656 seconds
DEBUG 01-05 12:51:25.912651.912651 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.912977.912977 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.912793.912793 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.912442.912442 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 551e16b7-c23d-4b52-97a3-bf715f83e33e
DEBUG 01-05 12:51:25.912793.912793 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:25.914989.914989 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 551e16b7-c23d-4b52-97a3-bf715f83e33e
DEBUG 01-05 12:51:25.914210.914210 cuda_h.py:19] end load_into_gpu_async cost 0.0022058486938476562 seconds
DEBUG 01-05 12:51:25.914489.914489 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.914962.914962 cuda_h.py:19] end restore_tensors2 cost 0.00045990943908691406 seconds
DEBUG 01-05 12:51:25.914044.914044 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032422542572021484 seconds
DEBUG 01-05 12:51:25.918581.918581 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00648808479309082 seconds
DEBUG 01-05 12:51:25.918471.918471 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:25.918725.918725 lmp.py:423] 
DEBUG 01-05 12:51:25.918725.918725 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:25.918661.918661 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-05 12:51:25.918715.918715 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:25.924423.924423 mlpmodule.py:704] group tensors cost 0.005754232406616211 s
DEBUG 01-05 12:51:25.926372.926372 mlpmodule.py:742] pad cost 0.0018546581268310547 s
DEBUG 01-05 12:51:25.926383.926383 mlpmodule.py:748] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-05 12:51:25.926107.926107 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-05 12:51:25.938106.938106 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:25.938363.938363 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:25.938399.938399 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 12:51:25.939330.939330 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:25.957876.957876 mlpmodule.py:793] group einsum cost 0.03019428253173828 s
DEBUG 01-05 12:51:25.958024.958024 mlpmodule.py:801] cpy2cputensor cost 0.0006687641143798828 s
DEBUG 01-05 12:51:25.962087.962087 cuda_h.py:19] end wait_cetm_experts cost 0.04446721076965332 seconds
DEBUG 01-05 12:51:25.962149.962149 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:25.963678.963678 cuda_h.py:19] end gpu_sexperts cost 0.0005199909210205078 seconds
DEBUG 01-05 12:51:25.963090.963090 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:25.963345.963345 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.981590270996094e-05 seconds
DEBUG 01-05 12:51:25.963101.963101 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:25.963148.963148 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 551e16b7-c23d-4b52-97a3-bf715f83e33e
INFO 01-05 12:51:25.967044.967044 client.py:127] Model loaded
DEBUG 01-05 12:51:25.967993.967993 cuda_h.py:19] end wait_experts cost 0.004063606262207031 seconds
DEBUG 01-05 12:51:25.967034.967034 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:25.967889.967889 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:25.968770.968770 mlpmodule.py:531] gpu group tensors cost 0.0006990432739257812 s
DEBUG 01-05 12:51:25.977861.977861 mlpmodule.py:564] gpu pad cost 0.008991718292236328 s
DEBUG 01-05 12:51:25.985242.985242 mlpmodule.py:662]  experts func einsum cost 0.06722688674926758 s
DEBUG 01-05 12:51:25.986530.986530 mlpmodule.py:582] gpu group einsum cost 0.008416891098022461 s
DEBUG 01-05 12:51:25.990433.990433 mlpmodule.py:611] gpu experts func einsum cost 0.022886037826538086 s
DEBUG 01-05 12:51:25.990682.990682 cuda_h.py:19] end gpu_experts cost 0.02308511734008789 seconds
DEBUG 01-05 12:51:25.991454.991454 cuda_h.py:19] end layer_moe_generate_4 cost 0.08191967010498047 seconds
DEBUG 01-05 12:51:25.991746.991746 lmp.py:217] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 12:51:25.991615.991615 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 12:51:25.991749.991749 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 12:51:25.991233.991233 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 12:51:25.991852.991852 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.314018249511719e-05 seconds
DEBUG 01-05 12:51:25.991568.991568 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.557868957519531e-05 seconds
DEBUG 01-05 12:51:25.991655.991655 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:25.991864.991864 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:25.991245.991245 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:25.991479.991479 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:25.992275.992275 cuda_h.py:19] end allocate_cuda_memory cost 0.00019168853759765625 seconds
DEBUG 01-05 12:51:25.992643.992643 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:25.992750.992750 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:25.992825.992825 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:25.992826.992826 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 75f3ab62-3abc-41be-93a8-aacc2e5899da
DEBUG 01-05 12:51:25.992684.992684 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:25.992153.992153 cuda_h.py:10] start self_attn
INFO 01-05 12:51:25.993070.993070 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 75f3ab62-3abc-41be-93a8-aacc2e5899da
DEBUG 01-05 12:51:25.993165.993165 cuda_h.py:19] end load_into_gpu_async cost 0.0017085075378417969 seconds
DEBUG 01-05 12:51:25.993021.993021 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:25.994554.994554 cuda_h.py:19] end restore_tensors2 cost 7.581710815429688e-05 seconds
DEBUG 01-05 12:51:25.994609.994609 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022945404052734375 seconds
INFO 01-05 12:51:25.994201.994201 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 75f3ab62-3abc-41be-93a8-aacc2e5899da
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:25.997762.997762 cuda_h.py:19] end self_attn cost 0.0044765472412109375 seconds
DEBUG 01-05 12:51:25.997906.997906 cuda_h.py:19] end iln_self_attn_paln cost 0.006078958511352539 seconds
DEBUG 01-05 12:51:25.997511.997511 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 12:51:25.997658.997658 cuda_h.py:10] start gate
DEBUG 01-05 12:51:25.998933.998933 cuda_h.py:19] end gate cost 0.0008683204650878906 seconds
DEBUG 01-05 12:51:25.998955.998955 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:25.999348.999348 lmp.py:365] 
DEBUG 01-05 12:51:25.999348.999348 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:25.999866.999866 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:25.999946.999946 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:25.999403.999403 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:25.999822.999822 lmp.py:369] 
DEBUG 01-05 12:51:25.999822.999822 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:25.999849.999849 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:25.999406.999406 lmp.py:376]   Expert 34 |     23 | CPU
DEBUG 01-05 12:51:25.999003.999003 lmp.py:376]   Expert 47 |     45 | CPU
DEBUG 01-05 12:51:25.999838.999838 lmp.py:376]   Expert 15 |     48 | CPU
DEBUG 01-05 12:51:25.999481.999481 lmp.py:376]   Expert 39 |     49 | CPU
DEBUG 01-05 12:51:25.999124.999124 lmp.py:376]   Expert  2 |     55 | CPU
DEBUG 01-05 12:51:25.999528.999528 lmp.py:376]   Expert 18 |     72 | CPU
DEBUG 01-05 12:51:25.999933.999933 lmp.py:376]   Expert  3 |     87 | CPU
DEBUG 01-05 12:51:25.999337.999337 lmp.py:376]   Expert 23 |     92 | CPU
DEBUG 01-05 12:51:25.999742.999742 lmp.py:376]   Expert 27 |     94 | CPU
DEBUG 01-05 12:51:25.999385.999385 lmp.py:376]   Expert 30 |    101 | CPU
DEBUG 01-05 12:51:25.999981.999981 lmp.py:376]   Expert 45 |    103 | CPU
DEBUG 01-05 12:51:25.999816.999816 lmp.py:376]   Expert 28 |    108 | CPU
DEBUG 01-05 12:51:25.999936.999936 lmp.py:376]   Expert 17 |    109 | CPU
DEBUG 01-05 12:51:25.999295.999295 lmp.py:376]   Expert  4 |    111 | CPU
DEBUG 01-05 12:51:25.999938.999938 lmp.py:376]   Expert  0 |    118 | CPU
DEBUG 01-05 12:51:25.999104.999104 lmp.py:376]   Expert 52 |    118 | CPU
DEBUG 01-05 12:51:25.999508.999508 lmp.py:376]   Expert 22 |    120 | CPU
DEBUG 01-05 12:51:25.999674.999674 lmp.py:376]   Expert 62 |    122 | CPU
DEBUG 01-05 12:51:25.999079.999079 lmp.py:376]   Expert  8 |    123 | CPU
DEBUG 01-05 12:51:25.999483.999483 lmp.py:376]   Expert 60 |    125 | CPU
DEBUG 01-05 12:51:25.999888.999888 lmp.py:376]   Expert 63 |    126 | CPU
DEBUG 01-05 12:51:25.999054.999054 lmp.py:376]   Expert  9 |    131 | CPU
DEBUG 01-05 12:51:25.999459.999459 lmp.py:376]   Expert 48 |    137 | CPU
DEBUG 01-05 12:51:25.999625.999625 lmp.py:376]   Expert 14 |    141 | CPU
DEBUG 01-05 12:51:25.999791.999791 lmp.py:376]   Expert 51 |    141 | CPU
DEBUG 01-05 12:51:25.999672.999672 lmp.py:376]   Expert 54 |    144 | CPU
DEBUG 01-05 12:51:25.999031.999031 lmp.py:376]   Expert 41 |    150 | CPU
DEBUG 01-05 12:51:25.999389.999389 lmp.py:376]   Expert 46 |    152 | CPU
DEBUG 01-05 12:51:25.999509.999509 lmp.py:376]   Expert 10 |    157 | CPU
DEBUG 01-05 12:51:25.999913.999913 lmp.py:376]   Expert 57 |    161 | CPU
DEBUG 01-05 12:51:25.999841.999841 lmp.py:376]   Expert 25 |    164 | CPU
DEBUG 01-05 12:51:25.999007.999007 lmp.py:376]   Expert  1 |    166 | CPU
DEBUG 01-05 12:51:25.999412.999412 lmp.py:376]   Expert 38 |    168 | GPU
DEBUG 01-05 12:51:25.999339.999339 lmp.py:376]   Expert 43 |    169 | GPU
DEBUG 01-05 12:51:25.999505.999505 lmp.py:376]   Expert 36 |    170 | GPU
DEBUG 01-05 12:51:25.999672.999672 lmp.py:376]   Expert 24 |    174 | GPU
DEBUG 01-05 12:51:25.999599.999599 lmp.py:376]   Expert 26 |    179 | GPU
DEBUG 01-05 12:51:25.999765.999765 lmp.py:376]   Expert 11 |    189 | GPU
DEBUG 01-05 12:51:25.999170.999170 lmp.py:376]   Expert 32 |    193 | GPU
DEBUG 01-05 12:51:25.999005.999005 lmp.py:376]   Expert 56 |    195 | GPU
DEBUG 01-05 12:51:25.999125.999125 lmp.py:376]   Expert 16 |    201 | GPU
DEBUG 01-05 12:51:26.000722.000722 lmp.py:376]   Expert 29 |    207 | GPU
DEBUG 01-05 12:51:26.000557.000557 lmp.py:376]   Expert 58 |    208 | GPU
DEBUG 01-05 12:51:26.000200.000200 lmp.py:376]   Expert 12 |    217 | GPU
DEBUG 01-05 12:51:26.000604.000604 lmp.py:376]   Expert 55 |    223 | GPU
DEBUG 01-05 12:51:26.000770.000770 lmp.py:376]   Expert 50 |    225 | GPU
DEBUG 01-05 12:51:26.000936.000936 lmp.py:376]   Expert 19 |    228 | GPU
DEBUG 01-05 12:51:26.000103.000103 lmp.py:376]   Expert 44 |    229 | GPU
DEBUG 01-05 12:51:26.000507.000507 lmp.py:376]   Expert 61 |    230 | GPU
DEBUG 01-05 12:51:26.000435.000435 lmp.py:376]   Expert 42 |    235 | GPU
DEBUG 01-05 12:51:26.000363.000363 lmp.py:376]   Expert  7 |    238 | GPU
DEBUG 01-05 12:51:26.000529.000529 lmp.py:376]   Expert 35 |    241 | GPU
DEBUG 01-05 12:51:26.000456.000456 lmp.py:376]   Expert 59 |    259 | GPU
DEBUG 01-05 12:51:26.000676.000676 lmp.py:376]   Expert 21 |    271 | GPU
DEBUG 01-05 12:51:26.000795.000795 lmp.py:376]   Expert  5 |    283 | GPU
DEBUG 01-05 12:51:26.000915.000915 lmp.py:376]   Expert 20 |    297 | GPU
DEBUG 01-05 12:51:26.000035.000035 lmp.py:376]   Expert 40 |    298 | GPU
DEBUG 01-05 12:51:26.000440.000440 lmp.py:376]   Expert 31 |    319 | GPU
DEBUG 01-05 12:51:26.000559.000559 lmp.py:376]   Expert 13 |    352 | GPU
DEBUG 01-05 12:51:26.000679.000679 lmp.py:376]   Expert 33 |    352 | GPU
DEBUG 01-05 12:51:26.000561.000561 lmp.py:376]   Expert  6 |    381 | GPU
DEBUG 01-05 12:51:26.000680.000680 lmp.py:376]   Expert 49 |    391 | GPU
DEBUG 01-05 12:51:26.000562.000562 lmp.py:376]   Expert 37 |    487 | GPU
DEBUG 01-05 12:51:26.000364.000364 lmp.py:376]   Expert 53 |    886 | GPU
DEBUG 01-05 12:51:26.000438.000438 lmp.py:377] 
DEBUG 01-05 12:51:26.000438.000438 lmp.py:377]   CPU total tokens: 3593 (29.2%)
DEBUG 01-05 12:51:26.000226.000226 lmp.py:378]   GPU total tokens: 8695 (70.8%)
DEBUG 01-05 12:51:26.000307.000307 cuda_h.py:19] end experts_map_get cost 0.0017743110656738281 seconds
DEBUG 01-05 12:51:26.000049.000049 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.000071.000071 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.000685.000685 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.001632.001632 cuda_h.py:19] end allocate_cuda_memory cost 0.0005583763122558594 seconds
DEBUG 01-05 12:51:26.001574.001574 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.001999.001999 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.001292.001292 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.001326.001326 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4db4fbbb-53d3-42b7-b6d3-c3fec9a12242
DEBUG 01-05 12:51:26.001736.001736 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.002725.002725 client.py:127] Model loaded
DEBUG 01-05 12:51:26.002079.002079 cuda_h.py:19] end sllm_worker_task cost 0.010447025299072266 seconds
INFO 01-05 12:51:26.003991.003991 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4db4fbbb-53d3-42b7-b6d3-c3fec9a12242
DEBUG 01-05 12:51:26.003255.003255 cuda_h.py:19] end load_into_gpu_async cost 0.002484560012817383 seconds
DEBUG 01-05 12:51:26.003563.003563 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.004257.004257 cuda_h.py:19] end restore_tensors2 cost 0.0006728172302246094 seconds
DEBUG 01-05 12:51:26.004002.004002 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0042383670806884766 seconds
DEBUG 01-05 12:51:26.010522.010522 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00954580307006836 seconds
DEBUG 01-05 12:51:26.010293.010293 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.010609.010609 lmp.py:423] 
DEBUG 01-05 12:51:26.010609.010609 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.010161.010161 cuda_h.py:19] end cpu_experts_submit cost 0.00016880035400390625 seconds
DEBUG 01-05 12:51:26.010600.010600 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.022673.022673 mlpmodule.py:704] group tensors cost 0.011626482009887695 s
DEBUG 01-05 12:51:26.025635.025635 mlpmodule.py:742] pad cost 0.0025098323822021484 s
DEBUG 01-05 12:51:26.026990.026990 mlpmodule.py:748] create cpu tensor cost 4.9591064453125e-05 s
DEBUG 01-05 12:51:26.026721.026721 mlpmodule.py:753] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-05 12:51:26.035117.035117 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.035726.035726 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.036762.036762 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 12:51:26.036978.036978 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.054525.054525 mlpmodule.py:793] group einsum cost 0.028074979782104492 s
DEBUG 01-05 12:51:26.055799.055799 mlpmodule.py:801] cpy2cputensor cost 0.0006515979766845703 s
DEBUG 01-05 12:51:26.059933.059933 cuda_h.py:19] end wait_cetm_experts cost 0.04945063591003418 seconds
DEBUG 01-05 12:51:26.059465.059465 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.060741.060741 cuda_h.py:19] end gpu_sexperts cost 0.00047779083251953125 seconds
DEBUG 01-05 12:51:26.060962.060962 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.060216.060216 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 12:51:26.060826.060826 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.060536.060536 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4db4fbbb-53d3-42b7-b6d3-c3fec9a12242
INFO 01-05 12:51:26.061471.061471 client.py:127] Model loaded
DEBUG 01-05 12:51:26.061805.061805 cuda_h.py:19] end wait_experts cost 0.0011115074157714844 seconds
DEBUG 01-05 12:51:26.061700.061700 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.061979.061979 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.062149.062149 mlpmodule.py:531] gpu group tensors cost 0.0006434917449951172 s
DEBUG 01-05 12:51:26.074381.074381 mlpmodule.py:564] gpu pad cost 0.011621475219726562 s
DEBUG 01-05 12:51:26.078876.078876 mlpmodule.py:662]  experts func einsum cost 0.06797218322753906 s
DEBUG 01-05 12:51:26.079923.079923 mlpmodule.py:582] gpu group einsum cost 0.004610776901245117 s
DEBUG 01-05 12:51:26.082377.082377 mlpmodule.py:611] gpu experts func einsum cost 0.020507097244262695 s
DEBUG 01-05 12:51:26.082950.082950 cuda_h.py:19] end gpu_experts cost 0.020695209503173828 seconds
DEBUG 01-05 12:51:26.082602.082602 cuda_h.py:19] end layer_moe_generate_5 cost 0.08497047424316406 seconds
DEBUG 01-05 12:51:26.082298.082298 lmp.py:217] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 12:51:26.082829.082829 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 12:51:26.082340.082340 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 12:51:26.082632.082632 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 12:51:26.083389.083389 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.24249267578125e-05 seconds
DEBUG 01-05 12:51:26.083861.083861 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.009506225585938e-05 seconds
DEBUG 01-05 12:51:26.083226.083226 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.083108.083108 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.083887.083887 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.083783.083783 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.083394.083394 cuda_h.py:19] end allocate_cuda_memory cost 0.0002040863037109375 seconds
DEBUG 01-05 12:51:26.083860.083860 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.083331.083331 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.083769.083769 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.083042.083042 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b85b4c0-ea7c-411f-b735-e9251724bd26
DEBUG 01-05 12:51:26.083157.083157 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.084054.084054 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.084354.084354 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b85b4c0-ea7c-411f-b735-e9251724bd26
DEBUG 01-05 12:51:26.085667.085667 cuda_h.py:19] end load_into_gpu_async cost 0.0013349056243896484 seconds
DEBUG 01-05 12:51:26.085701.085701 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.085062.085062 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-05 12:51:26.085626.085626 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018346309661865234 seconds
INFO 01-05 12:51:26.085973.085973 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b85b4c0-ea7c-411f-b735-e9251724bd26
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.087735.087735 cuda_h.py:19] end self_attn cost 0.003277301788330078 seconds
DEBUG 01-05 12:51:26.087043.087043 cuda_h.py:19] end iln_self_attn_paln cost 0.0046079158782958984 seconds
DEBUG 01-05 12:51:26.087403.087403 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 12:51:26.087265.087265 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.088770.088770 cuda_h.py:19] end gate cost 0.0006206035614013672 seconds
DEBUG 01-05 12:51:26.088169.088169 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.088364.088364 lmp.py:365] 
DEBUG 01-05 12:51:26.088364.088364 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.088213.088213 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.088624.088624 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.088698.088698 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.088626.088626 lmp.py:369] 
DEBUG 01-05 12:51:26.088626.088626 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.088030.088030 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.088918.088918 lmp.py:376]   Expert  1 |      6 | CPU
DEBUG 01-05 12:51:26.088323.088323 lmp.py:376]   Expert  3 |     31 | CPU
DEBUG 01-05 12:51:26.088012.088012 lmp.py:376]   Expert 14 |     47 | CPU
DEBUG 01-05 12:51:26.089225.089225 lmp.py:376]   Expert 53 |     52 | CPU
DEBUG 01-05 12:51:26.089868.089868 lmp.py:376]   Expert 52 |     59 | CPU
DEBUG 01-05 12:51:26.089557.089557 lmp.py:376]   Expert 35 |     67 | CPU
DEBUG 01-05 12:51:26.089246.089246 lmp.py:376]   Expert 15 |     71 | CPU
DEBUG 01-05 12:51:26.089935.089935 lmp.py:376]   Expert 10 |     78 | CPU
DEBUG 01-05 12:51:26.089625.089625 lmp.py:376]   Expert 44 |     79 | CPU
DEBUG 01-05 12:51:26.089268.089268 lmp.py:376]   Expert 11 |     85 | CPU
DEBUG 01-05 12:51:26.089911.089911 lmp.py:376]   Expert 63 |     90 | CPU
DEBUG 01-05 12:51:26.089077.089077 lmp.py:376]   Expert 49 |    101 | CPU
DEBUG 01-05 12:51:26.089720.089720 lmp.py:376]   Expert 26 |    105 | CPU
DEBUG 01-05 12:51:26.089648.089648 lmp.py:376]   Expert 50 |    105 | CPU
DEBUG 01-05 12:51:26.089337.089337 lmp.py:376]   Expert  7 |    108 | CPU
DEBUG 01-05 12:51:26.089788.089788 lmp.py:376]   Expert 37 |    114 | CPU
DEBUG 01-05 12:51:26.089762.089762 lmp.py:376]   Expert 34 |    115 | CPU
DEBUG 01-05 12:51:26.089213.089213 lmp.py:376]   Expert 40 |    116 | CPU
DEBUG 01-05 12:51:26.089664.089664 lmp.py:376]   Expert 47 |    117 | CPU
DEBUG 01-05 12:51:26.089876.089876 lmp.py:376]   Expert 22 |    119 | CPU
DEBUG 01-05 12:51:26.089327.089327 lmp.py:376]   Expert 16 |    120 | CPU
DEBUG 01-05 12:51:26.089778.089778 lmp.py:376]   Expert 32 |    131 | CPU
DEBUG 01-05 12:51:26.089944.089944 lmp.py:376]   Expert 62 |    133 | CPU
DEBUG 01-05 12:51:26.089110.089110 lmp.py:376]   Expert 28 |    136 | CPU
DEBUG 01-05 12:51:26.089276.089276 lmp.py:376]   Expert 30 |    146 | CPU
DEBUG 01-05 12:51:26.089442.089442 lmp.py:376]   Expert  4 |    147 | CPU
DEBUG 01-05 12:51:26.089608.089608 lmp.py:376]   Expert 31 |    150 | CPU
DEBUG 01-05 12:51:26.089298.089298 lmp.py:376]   Expert 41 |    152 | CPU
DEBUG 01-05 12:51:26.089510.089510 lmp.py:376]   Expert 58 |    155 | CPU
DEBUG 01-05 12:51:26.089961.089961 lmp.py:376]   Expert 57 |    159 | CPU
DEBUG 01-05 12:51:26.089174.089174 lmp.py:376]   Expert 51 |    161 | CPU
DEBUG 01-05 12:51:26.089386.089386 lmp.py:376]   Expert 25 |    168 | CPU
DEBUG 01-05 12:51:26.089837.089837 lmp.py:376]   Expert 54 |    174 | GPU
DEBUG 01-05 12:51:26.089288.089288 lmp.py:376]   Expert 59 |    178 | GPU
DEBUG 01-05 12:51:26.089500.089500 lmp.py:376]   Expert 45 |    179 | GPU
DEBUG 01-05 12:51:26.089719.089719 lmp.py:376]   Expert  9 |    190 | GPU
DEBUG 01-05 12:51:26.089170.089170 lmp.py:376]   Expert 21 |    191 | GPU
DEBUG 01-05 12:51:26.089621.089621 lmp.py:376]   Expert 55 |    194 | GPU
DEBUG 01-05 12:51:26.089834.089834 lmp.py:376]   Expert 38 |    196 | GPU
DEBUG 01-05 12:51:26.089000.089000 lmp.py:376]   Expert  0 |    199 | GPU
DEBUG 01-05 12:51:26.089735.089735 lmp.py:376]   Expert 12 |    208 | GPU
DEBUG 01-05 12:51:26.089710.089710 lmp.py:376]   Expert 33 |    208 | GPU
DEBUG 01-05 12:51:26.089207.089207 lmp.py:376]   Expert 29 |    211 | GPU
DEBUG 01-05 12:51:26.089942.089942 lmp.py:376]   Expert  8 |    215 | GPU
DEBUG 01-05 12:51:26.089963.089963 lmp.py:376]   Expert  6 |    216 | GPU
DEBUG 01-05 12:51:26.089698.089698 lmp.py:376]   Expert 13 |    218 | GPU
DEBUG 01-05 12:51:26.089196.089196 lmp.py:376]   Expert  5 |    219 | GPU
DEBUG 01-05 12:51:26.089931.089931 lmp.py:376]   Expert 46 |    225 | GPU
DEBUG 01-05 12:51:26.089428.089428 lmp.py:376]   Expert 19 |    226 | GPU
DEBUG 01-05 12:51:26.089164.089164 lmp.py:376]   Expert 43 |    226 | GPU
DEBUG 01-05 12:51:26.089615.089615 lmp.py:376]   Expert  2 |    233 | GPU
DEBUG 01-05 12:51:26.089066.089066 lmp.py:376]   Expert 42 |    240 | GPU
DEBUG 01-05 12:51:26.089517.089517 lmp.py:376]   Expert 24 |    250 | GPU
DEBUG 01-05 12:51:26.089968.089968 lmp.py:376]   Expert 17 |    257 | GPU
DEBUG 01-05 12:51:26.089703.089703 lmp.py:376]   Expert 23 |    263 | GPU
DEBUG 01-05 12:51:26.089439.089439 lmp.py:376]   Expert 61 |    281 | GPU
DEBUG 01-05 12:51:26.089936.089936 lmp.py:376]   Expert 20 |    349 | GPU
DEBUG 01-05 12:51:26.089672.089672 lmp.py:376]   Expert 27 |    351 | GPU
DEBUG 01-05 12:51:26.089169.089169 lmp.py:376]   Expert 18 |    375 | GPU
DEBUG 01-05 12:51:26.089904.089904 lmp.py:376]   Expert 48 |    391 | GPU
DEBUG 01-05 12:51:26.089163.089163 lmp.py:376]   Expert 39 |    419 | GPU
DEBUG 01-05 12:51:26.089137.089137 lmp.py:376]   Expert 60 |    473 | GPU
DEBUG 01-05 12:51:26.089396.089396 lmp.py:376]   Expert 56 |    610 | GPU
DEBUG 01-05 12:51:26.089370.089370 lmp.py:376]   Expert 36 |    700 | GPU
DEBUG 01-05 12:51:26.090821.090821 lmp.py:377] 
DEBUG 01-05 12:51:26.090821.090821 lmp.py:377]   CPU total tokens: 3423 (27.9%)
DEBUG 01-05 12:51:26.090510.090510 lmp.py:378]   GPU total tokens: 8865 (72.1%)
DEBUG 01-05 12:51:26.090968.090968 cuda_h.py:19] end experts_map_get cost 0.001474618911743164 seconds
DEBUG 01-05 12:51:26.090373.090373 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.090195.090195 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.090279.090279 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.092577.092577 cuda_h.py:19] end allocate_cuda_memory cost 0.0019450187683105469 seconds
DEBUG 01-05 12:51:26.092996.092996 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.092276.092276 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.092085.092085 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.092450.092450 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b9c486fb-cd7b-4078-9431-bfe786181af9
DEBUG 01-05 12:51:26.092529.092529 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.092574.092574 client.py:127] Model loaded
DEBUG 01-05 12:51:26.092477.092477 cuda_h.py:19] end sllm_worker_task cost 0.00970602035522461 seconds
INFO 01-05 12:51:26.093202.093202 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b9c486fb-cd7b-4078-9431-bfe786181af9
DEBUG 01-05 12:51:26.093237.093237 cuda_h.py:19] end load_into_gpu_async cost 0.0016188621520996094 seconds
DEBUG 01-05 12:51:26.093940.093940 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.094132.094132 cuda_h.py:19] end restore_tensors2 cost 0.00036025047302246094 seconds
DEBUG 01-05 12:51:26.094445.094445 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004268646240234375 seconds
DEBUG 01-05 12:51:26.097562.097562 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007027626037597656 seconds
DEBUG 01-05 12:51:26.097035.097035 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.097144.097144 lmp.py:423] 
DEBUG 01-05 12:51:26.097144.097144 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.097225.097225 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-05 12:51:26.097259.097259 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.107184.107184 mlpmodule.py:704] group tensors cost 0.01009821891784668 s
DEBUG 01-05 12:51:26.109343.109343 mlpmodule.py:742] pad cost 0.0014834403991699219 s
DEBUG 01-05 12:51:26.109942.109942 mlpmodule.py:748] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-05 12:51:26.109593.109593 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-05 12:51:26.119256.119256 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.119619.119619 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.119085.119085 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 12:51:26.119567.119567 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.137973.137973 mlpmodule.py:793] group einsum cost 0.027702808380126953 s
DEBUG 01-05 12:51:26.138683.138683 mlpmodule.py:801] cpy2cputensor cost 0.0006363391876220703 s
DEBUG 01-05 12:51:26.143851.143851 cuda_h.py:19] end wait_cetm_experts cost 0.04593348503112793 seconds
DEBUG 01-05 12:51:26.143617.143617 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.143124.143124 cuda_h.py:19] end gpu_sexperts cost 0.0004496574401855469 seconds
DEBUG 01-05 12:51:26.144061.144061 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.144984.144984 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-05 12:51:26.144608.144608 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.144841.144841 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b9c486fb-cd7b-4078-9431-bfe786181af9
INFO 01-05 12:51:26.146815.146815 client.py:127] Model loaded
DEBUG 01-05 12:51:26.147772.147772 cuda_h.py:19] end wait_experts cost 0.0028939247131347656 seconds
DEBUG 01-05 12:51:26.147887.147887 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.147564.147564 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.147701.147701 mlpmodule.py:531] gpu group tensors cost 0.000640869140625 s
DEBUG 01-05 12:51:26.149246.149246 mlpmodule.py:564] gpu pad cost 0.0017576217651367188 s
DEBUG 01-05 12:51:26.150037.150037 mlpmodule.py:582] gpu group einsum cost 0.0005574226379394531 s
DEBUG 01-05 12:51:26.153232.153232 mlpmodule.py:611] gpu experts func einsum cost 0.0066149234771728516 s
DEBUG 01-05 12:51:26.154938.154938 cuda_h.py:19] end gpu_experts cost 0.006845712661743164 seconds
DEBUG 01-05 12:51:26.154061.154061 cuda_h.py:19] end layer_moe_generate_6 cost 0.06628870964050293 seconds
DEBUG 01-05 12:51:26.154584.154584 lmp.py:217] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 12:51:26.154407.154407 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 12:51:26.154434.154434 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 12:51:26.154462.154462 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 12:51:26.154782.154782 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.0517578125e-05 seconds
DEBUG 01-05 12:51:26.154770.154770 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.222724914550781e-05 seconds
DEBUG 01-05 12:51:26.154367.154367 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.154157.154157 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.154167.154167 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.154434.154434 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.156536.156536 cuda_h.py:19] end allocate_cuda_memory cost 0.0018277168273925781 seconds
DEBUG 01-05 12:51:26.156976.156976 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.156785.156785 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.156892.156892 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.156165.156165 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, daeb4f30-c9df-4c7f-bc01-98a924da42b1
DEBUG 01-05 12:51:26.156088.156088 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.157258.157258 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.158238.158238 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, daeb4f30-c9df-4c7f-bc01-98a924da42b1
DEBUG 01-05 12:51:26.158366.158366 cuda_h.py:19] end load_into_gpu_async cost 0.001340627670288086 seconds
DEBUG 01-05 12:51:26.158831.158831 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.158953.158953 cuda_h.py:19] end restore_tensors2 cost 6.365776062011719e-05 seconds
DEBUG 01-05 12:51:26.158325.158325 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003487110137939453 seconds
INFO 01-05 12:51:26.158136.158136 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, daeb4f30-c9df-4c7f-bc01-98a924da42b1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.160351.160351 cuda_h.py:19] end self_attn cost 0.0030927658081054688 seconds
DEBUG 01-05 12:51:26.160599.160599 cuda_h.py:19] end iln_self_attn_paln cost 0.006109476089477539 seconds
DEBUG 01-05 12:51:26.160912.160912 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 12:51:26.160198.160198 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.161921.161921 cuda_h.py:19] end gate cost 0.0006060600280761719 seconds
DEBUG 01-05 12:51:26.161174.161174 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.161767.161767 lmp.py:365] 
DEBUG 01-05 12:51:26.161767.161767 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.161285.161285 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.161265.161265 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.161624.161624 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.161598.161598 lmp.py:369] 
DEBUG 01-05 12:51:26.161598.161598 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.161810.161810 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.161937.161937 lmp.py:376]   Expert  1 |     21 | CPU
DEBUG 01-05 12:51:26.161341.161341 lmp.py:376]   Expert  3 |     27 | CPU
DEBUG 01-05 12:51:26.161031.161031 lmp.py:376]   Expert 25 |     45 | CPU
DEBUG 01-05 12:51:26.161197.161197 lmp.py:376]   Expert 40 |     54 | CPU
DEBUG 01-05 12:51:26.161409.161409 lmp.py:376]   Expert 41 |     57 | CPU
DEBUG 01-05 12:51:26.161622.161622 lmp.py:376]   Expert 49 |     57 | CPU
DEBUG 01-05 12:51:26.161119.161119 lmp.py:376]   Expert 15 |     64 | CPU
DEBUG 01-05 12:51:26.162093.162093 lmp.py:376]   Expert  8 |     65 | CPU
DEBUG 01-05 12:51:26.162829.162829 lmp.py:376]   Expert 20 |     66 | CPU
DEBUG 01-05 12:51:26.162326.162326 lmp.py:376]   Expert 31 |     75 | CPU
DEBUG 01-05 12:51:26.162823.162823 lmp.py:376]   Expert 39 |     80 | CPU
DEBUG 01-05 12:51:26.162989.162989 lmp.py:376]   Expert 29 |     82 | CPU
DEBUG 01-05 12:51:26.162440.162440 lmp.py:376]   Expert 48 |     82 | CPU
DEBUG 01-05 12:51:26.162652.162652 lmp.py:376]   Expert  5 |     83 | CPU
DEBUG 01-05 12:51:26.162865.162865 lmp.py:376]   Expert 16 |     83 | CPU
DEBUG 01-05 12:51:26.162269.162269 lmp.py:376]   Expert 63 |     92 | CPU
DEBUG 01-05 12:51:26.162959.162959 lmp.py:376]   Expert  6 |     97 | CPU
DEBUG 01-05 12:51:26.162886.162886 lmp.py:376]   Expert 32 |     97 | CPU
DEBUG 01-05 12:51:26.162814.162814 lmp.py:376]   Expert 57 |    103 | CPU
DEBUG 01-05 12:51:26.162219.162219 lmp.py:376]   Expert 18 |    104 | CPU
DEBUG 01-05 12:51:26.162670.162670 lmp.py:376]   Expert 58 |    114 | CPU
DEBUG 01-05 12:51:26.162405.162405 lmp.py:376]   Expert 59 |    126 | CPU
DEBUG 01-05 12:51:26.162618.162618 lmp.py:376]   Expert 30 |    141 | CPU
DEBUG 01-05 12:51:26.162069.162069 lmp.py:376]   Expert 53 |    148 | CPU
DEBUG 01-05 12:51:26.162281.162281 lmp.py:376]   Expert 35 |    151 | CPU
DEBUG 01-05 12:51:26.162732.162732 lmp.py:376]   Expert 55 |    155 | CPU
DEBUG 01-05 12:51:26.162183.162183 lmp.py:376]   Expert  4 |    156 | CPU
DEBUG 01-05 12:51:26.162395.162395 lmp.py:376]   Expert 34 |    156 | CPU
DEBUG 01-05 12:51:26.162085.162085 lmp.py:376]   Expert 26 |    160 | CPU
DEBUG 01-05 12:51:26.162774.162774 lmp.py:376]   Expert 45 |    162 | CPU
DEBUG 01-05 12:51:26.162702.162702 lmp.py:376]   Expert 52 |    174 | CPU
DEBUG 01-05 12:51:26.162868.162868 lmp.py:376]   Expert  0 |    175 | CPU
DEBUG 01-05 12:51:26.162795.162795 lmp.py:376]   Expert 33 |    175 | GPU
DEBUG 01-05 12:51:26.162723.162723 lmp.py:376]   Expert 50 |    183 | GPU
DEBUG 01-05 12:51:26.162697.162697 lmp.py:376]   Expert  7 |    187 | GPU
DEBUG 01-05 12:51:26.162009.162009 lmp.py:376]   Expert 54 |    191 | GPU
DEBUG 01-05 12:51:26.162891.162891 lmp.py:376]   Expert 19 |    198 | GPU
DEBUG 01-05 12:51:26.162341.162341 lmp.py:376]   Expert 28 |    198 | GPU
DEBUG 01-05 12:51:26.162315.162315 lmp.py:376]   Expert 42 |    203 | GPU
DEBUG 01-05 12:51:26.162766.162766 lmp.py:376]   Expert 24 |    205 | GPU
DEBUG 01-05 12:51:26.162979.162979 lmp.py:376]   Expert 21 |    206 | GPU
DEBUG 01-05 12:51:26.162191.162191 lmp.py:376]   Expert 51 |    210 | GPU
DEBUG 01-05 12:51:26.162642.162642 lmp.py:376]   Expert 60 |    210 | GPU
DEBUG 01-05 12:51:26.162855.162855 lmp.py:376]   Expert 43 |    213 | GPU
DEBUG 01-05 12:51:26.162021.162021 lmp.py:376]   Expert 17 |    219 | GPU
DEBUG 01-05 12:51:26.162710.162710 lmp.py:376]   Expert 36 |    220 | GPU
DEBUG 01-05 12:51:26.162876.162876 lmp.py:376]   Expert 13 |    223 | GPU
DEBUG 01-05 12:51:26.162804.162804 lmp.py:376]   Expert 27 |    227 | GPU
DEBUG 01-05 12:51:26.162070.162070 lmp.py:376]   Expert 10 |    247 | GPU
DEBUG 01-05 12:51:26.162997.162997 lmp.py:376]   Expert 37 |    252 | GPU
DEBUG 01-05 12:51:26.162687.162687 lmp.py:376]   Expert 62 |    262 | GPU
DEBUG 01-05 12:51:26.162899.162899 lmp.py:376]   Expert 47 |    263 | GPU
DEBUG 01-05 12:51:26.162350.162350 lmp.py:376]   Expert 11 |    267 | GPU
DEBUG 01-05 12:51:26.162039.162039 lmp.py:376]   Expert 22 |    276 | GPU
DEBUG 01-05 12:51:26.162728.162728 lmp.py:376]   Expert  2 |    307 | GPU
DEBUG 01-05 12:51:26.162179.162179 lmp.py:376]   Expert 56 |    312 | GPU
DEBUG 01-05 12:51:26.162630.162630 lmp.py:376]   Expert 61 |    319 | GPU
DEBUG 01-05 12:51:26.162035.162035 lmp.py:376]   Expert 14 |    355 | GPU
DEBUG 01-05 12:51:26.162439.162439 lmp.py:376]   Expert 38 |    356 | GPU
DEBUG 01-05 12:51:26.162129.162129 lmp.py:376]   Expert 44 |    357 | GPU
DEBUG 01-05 12:51:26.162056.162056 lmp.py:376]   Expert 46 |    368 | GPU
DEBUG 01-05 12:51:26.162746.162746 lmp.py:376]   Expert 12 |    573 | GPU
DEBUG 01-05 12:51:26.162720.162720 lmp.py:376]   Expert  9 |    605 | GPU
DEBUG 01-05 12:51:26.162932.162932 lmp.py:376]   Expert 23 |    649 | GPU
DEBUG 01-05 12:51:26.162860.162860 lmp.py:377] 
DEBUG 01-05 12:51:26.162860.162860 lmp.py:377]   CPU total tokens: 3252 (26.5%)
DEBUG 01-05 12:51:26.162026.162026 lmp.py:378]   GPU total tokens: 9036 (73.5%)
DEBUG 01-05 12:51:26.162722.162722 cuda_h.py:19] end experts_map_get cost 0.0015001296997070312 seconds
DEBUG 01-05 12:51:26.163127.163127 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.163334.163334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.163610.163610 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.164495.164495 cuda_h.py:19] end allocate_cuda_memory cost 0.00128173828125 seconds
DEBUG 01-05 12:51:26.164590.164590 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.164492.164492 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.164639.164639 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.164719.164719 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0f40ff74-df68-4e39-827b-1e4d1a85a71f
DEBUG 01-05 12:51:26.164037.164037 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.165822.165822 mlpmodule.py:662]  experts func einsum cost 0.0675358772277832 s
INFO 01-05 12:51:26.166454.166454 client.py:127] Model loaded
DEBUG 01-05 12:51:26.166582.166582 cuda_h.py:19] end sllm_worker_task cost 0.011407136917114258 seconds
INFO 01-05 12:51:26.166106.166106 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0f40ff74-df68-4e39-827b-1e4d1a85a71f
DEBUG 01-05 12:51:26.166572.166572 cuda_h.py:19] end load_into_gpu_async cost 0.002198934555053711 seconds
DEBUG 01-05 12:51:26.166752.166752 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.167236.167236 cuda_h.py:19] end restore_tensors2 cost 0.0004010200500488281 seconds
DEBUG 01-05 12:51:26.167688.167688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004240512847900391 seconds
DEBUG 01-05 12:51:26.170878.170878 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006987810134887695 seconds
DEBUG 01-05 12:51:26.170999.170999 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.170909.170909 lmp.py:423] 
DEBUG 01-05 12:51:26.170909.170909 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.170606.170606 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-05 12:51:26.170184.170184 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.174542.174542 mlpmodule.py:704] group tensors cost 0.004450559616088867 s
DEBUG 01-05 12:51:26.176824.176824 mlpmodule.py:742] pad cost 0.0013985633850097656 s
DEBUG 01-05 12:51:26.176808.176808 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-05 12:51:26.176081.176081 mlpmodule.py:753] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-05 12:51:26.186165.186165 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.186475.186475 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.186651.186651 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 12:51:26.186582.186582 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.205242.205242 mlpmodule.py:793] group einsum cost 0.028067588806152344 s
DEBUG 01-05 12:51:26.205363.205363 mlpmodule.py:801] cpy2cputensor cost 0.0006692409515380859 s
DEBUG 01-05 12:51:26.210159.210159 cuda_h.py:19] end wait_cetm_experts cost 0.040343523025512695 seconds
DEBUG 01-05 12:51:26.210725.210725 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.211471.211471 cuda_h.py:19] end gpu_sexperts cost 0.00045680999755859375 seconds
DEBUG 01-05 12:51:26.211077.211077 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.211391.211391 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-05 12:51:26.211445.211445 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.211347.211347 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0f40ff74-df68-4e39-827b-1e4d1a85a71f
INFO 01-05 12:51:26.221678.221678 client.py:127] Model loaded
DEBUG 01-05 12:51:26.221667.221667 cuda_h.py:19] end wait_experts cost 0.00954127311706543 seconds
DEBUG 01-05 12:51:26.221085.221085 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.221264.221264 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.221830.221830 mlpmodule.py:531] gpu group tensors cost 0.0005896091461181641 s
DEBUG 01-05 12:51:26.223774.223774 mlpmodule.py:564] gpu pad cost 0.0014491081237792969 s
DEBUG 01-05 12:51:26.223702.223702 mlpmodule.py:582] gpu group einsum cost 0.0005238056182861328 s
DEBUG 01-05 12:51:26.226708.226708 mlpmodule.py:611] gpu experts func einsum cost 0.005661487579345703 s
DEBUG 01-05 12:51:26.227807.227807 cuda_h.py:19] end gpu_experts cost 0.005913257598876953 seconds
DEBUG 01-05 12:51:26.227737.227737 cuda_h.py:19] end layer_moe_generate_7 cost 0.06634283065795898 seconds
DEBUG 01-05 12:51:26.227266.227266 lmp.py:217] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 12:51:26.227929.227929 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 12:51:26.227195.227195 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 12:51:26.227282.227282 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 12:51:26.227357.227357 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:26.227126.227126 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.462501525878906e-05 seconds
DEBUG 01-05 12:51:26.227485.227485 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.227122.227122 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.227100.227100 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.227320.227320 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.230142.230142 cuda_h.py:19] end allocate_cuda_memory cost 0.0023577213287353516 seconds
DEBUG 01-05 12:51:26.230496.230496 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.230749.230749 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.230188.230188 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.230937.230937 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 999b2269-8f41-42c4-8896-a144685cd183
DEBUG 01-05 12:51:26.230191.230191 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.230613.230613 mlpmodule.py:662]  experts func einsum cost 0.060167789459228516 s
DEBUG 01-05 12:51:26.230748.230748 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.231346.231346 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 999b2269-8f41-42c4-8896-a144685cd183
DEBUG 01-05 12:51:26.231804.231804 cuda_h.py:19] end load_into_gpu_async cost 0.001058340072631836 seconds
DEBUG 01-05 12:51:26.231600.231600 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.231722.231722 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-05 12:51:26.231571.231571 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037522315979003906 seconds
INFO 01-05 12:51:26.231860.231860 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 999b2269-8f41-42c4-8896-a144685cd183
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.234308.234308 cuda_h.py:19] end self_attn cost 0.0034003257751464844 seconds
DEBUG 01-05 12:51:26.234516.234516 cuda_h.py:19] end iln_self_attn_paln cost 0.007052183151245117 seconds
DEBUG 01-05 12:51:26.234353.234353 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 12:51:26.234115.234115 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.235077.235077 cuda_h.py:19] end gate cost 0.0006029605865478516 seconds
DEBUG 01-05 12:51:26.235761.235761 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.235585.235585 lmp.py:365] 
DEBUG 01-05 12:51:26.235585.235585 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.235056.235056 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.235421.235421 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.235210.235210 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.235853.235853 lmp.py:369] 
DEBUG 01-05 12:51:26.235853.235853 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.235973.235973 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.235384.235384 lmp.py:376]   Expert  7 |     22 | CPU
DEBUG 01-05 12:51:26.235266.235266 lmp.py:376]   Expert 27 |     24 | CPU
DEBUG 01-05 12:51:26.235193.235193 lmp.py:376]   Expert 14 |     27 | CPU
DEBUG 01-05 12:51:26.235121.235121 lmp.py:376]   Expert 30 |     34 | CPU
DEBUG 01-05 12:51:26.235572.235572 lmp.py:376]   Expert 38 |     43 | CPU
DEBUG 01-05 12:51:26.235023.235023 lmp.py:376]   Expert 12 |     53 | CPU
DEBUG 01-05 12:51:26.235189.235189 lmp.py:376]   Expert 34 |     61 | CPU
DEBUG 01-05 12:51:26.235640.235640 lmp.py:376]   Expert 36 |     62 | CPU
DEBUG 01-05 12:51:26.235568.235568 lmp.py:376]   Expert 22 |     66 | CPU
DEBUG 01-05 12:51:26.235019.235019 lmp.py:376]   Expert  8 |     68 | CPU
DEBUG 01-05 12:51:26.235946.235946 lmp.py:376]   Expert 53 |     69 | CPU
DEBUG 01-05 12:51:26.235636.235636 lmp.py:376]   Expert 26 |     79 | CPU
DEBUG 01-05 12:51:26.235802.235802 lmp.py:376]   Expert 54 |     81 | CPU
DEBUG 01-05 12:51:26.236206.236206 lmp.py:376]   Expert 33 |     93 | CPU
DEBUG 01-05 12:51:26.236372.236372 lmp.py:376]   Expert 40 |     93 | CPU
DEBUG 01-05 12:51:26.236062.236062 lmp.py:376]   Expert  1 |     94 | CPU
DEBUG 01-05 12:51:26.236751.236751 lmp.py:376]   Expert 57 |    101 | CPU
DEBUG 01-05 12:51:26.236202.236202 lmp.py:376]   Expert  9 |    105 | CPU
DEBUG 01-05 12:51:26.236653.236653 lmp.py:376]   Expert 13 |    111 | CPU
DEBUG 01-05 12:51:26.236104.236104 lmp.py:376]   Expert 50 |    113 | CPU
DEBUG 01-05 12:51:26.236793.236793 lmp.py:376]   Expert 32 |    118 | CPU
DEBUG 01-05 12:51:26.236482.236482 lmp.py:376]   Expert 29 |    120 | CPU
DEBUG 01-05 12:51:26.236172.236172 lmp.py:376]   Expert 17 |    121 | CPU
DEBUG 01-05 12:51:26.236861.236861 lmp.py:376]   Expert 59 |    131 | CPU
DEBUG 01-05 12:51:26.236312.236312 lmp.py:376]   Expert 44 |    139 | CPU
DEBUG 01-05 12:51:26.236763.236763 lmp.py:376]   Expert 24 |    142 | CPU
DEBUG 01-05 12:51:26.236690.236690 lmp.py:376]   Expert 60 |    143 | CPU
DEBUG 01-05 12:51:26.236572.236572 lmp.py:376]   Expert 15 |    161 | CPU
DEBUG 01-05 12:51:26.236738.236738 lmp.py:376]   Expert 10 |    162 | CPU
DEBUG 01-05 12:51:26.236904.236904 lmp.py:376]   Expert 51 |    165 | CPU
DEBUG 01-05 12:51:26.236309.236309 lmp.py:376]   Expert  2 |    166 | CPU
DEBUG 01-05 12:51:26.236475.236475 lmp.py:376]   Expert 16 |    166 | CPU
DEBUG 01-05 12:51:26.236164.236164 lmp.py:376]   Expert 56 |    170 | GPU
DEBUG 01-05 12:51:26.236615.236615 lmp.py:376]   Expert 37 |    172 | GPU
DEBUG 01-05 12:51:26.236304.236304 lmp.py:376]   Expert 18 |    188 | GPU
DEBUG 01-05 12:51:26.236994.236994 lmp.py:376]   Expert 31 |    188 | GPU
DEBUG 01-05 12:51:26.236266.236266 lmp.py:376]   Expert 39 |    190 | GPU
DEBUG 01-05 12:51:26.236194.236194 lmp.py:376]   Expert 19 |    199 | GPU
DEBUG 01-05 12:51:26.236644.236644 lmp.py:376]   Expert 58 |    214 | GPU
DEBUG 01-05 12:51:26.236287.236287 lmp.py:376]   Expert 61 |    224 | GPU
DEBUG 01-05 12:51:26.236454.236454 lmp.py:376]   Expert 49 |    239 | GPU
DEBUG 01-05 12:51:26.236620.236620 lmp.py:376]   Expert 41 |    243 | GPU
DEBUG 01-05 12:51:26.236786.236786 lmp.py:376]   Expert 46 |    244 | GPU
DEBUG 01-05 12:51:26.236714.236714 lmp.py:376]   Expert 35 |    249 | GPU
DEBUG 01-05 12:51:26.236403.236403 lmp.py:376]   Expert  0 |    254 | GPU
DEBUG 01-05 12:51:26.236092.236092 lmp.py:376]   Expert 23 |    255 | GPU
DEBUG 01-05 12:51:26.236781.236781 lmp.py:376]   Expert 42 |    255 | GPU
DEBUG 01-05 12:51:26.236232.236232 lmp.py:376]   Expert  3 |    266 | GPU
DEBUG 01-05 12:51:26.236922.236922 lmp.py:376]   Expert  6 |    268 | GPU
DEBUG 01-05 12:51:26.236134.236134 lmp.py:376]   Expert  4 |    279 | GPU
DEBUG 01-05 12:51:26.236062.236062 lmp.py:376]   Expert 28 |    288 | GPU
DEBUG 01-05 12:51:26.236513.236513 lmp.py:376]   Expert 55 |    296 | GPU
DEBUG 01-05 12:51:26.236156.236156 lmp.py:376]   Expert 43 |    305 | GPU
DEBUG 01-05 12:51:26.236322.236322 lmp.py:376]   Expert 45 |    321 | GPU
DEBUG 01-05 12:51:26.236488.236488 lmp.py:376]   Expert 20 |    324 | GPU
DEBUG 01-05 12:51:26.236416.236416 lmp.py:376]   Expert 52 |    326 | GPU
DEBUG 01-05 12:51:26.236582.236582 lmp.py:376]   Expert 48 |    341 | GPU
DEBUG 01-05 12:51:26.236033.236033 lmp.py:376]   Expert 25 |    344 | GPU
DEBUG 01-05 12:51:26.236722.236722 lmp.py:376]   Expert 47 |    344 | GPU
DEBUG 01-05 12:51:26.236173.236173 lmp.py:376]   Expert 11 |    393 | GPU
DEBUG 01-05 12:51:26.236862.236862 lmp.py:376]   Expert 62 |    403 | GPU
DEBUG 01-05 12:51:26.236313.236313 lmp.py:376]   Expert 63 |    405 | GPU
DEBUG 01-05 12:51:26.236764.236764 lmp.py:376]   Expert 21 |    427 | GPU
DEBUG 01-05 12:51:26.236215.236215 lmp.py:376]   Expert  5 |    541 | GPU
DEBUG 01-05 12:51:26.236619.236619 lmp.py:377] 
DEBUG 01-05 12:51:26.236619.236619 lmp.py:377]   CPU total tokens: 3133 (25.5%)
DEBUG 01-05 12:51:26.236316.236316 lmp.py:378]   GPU total tokens: 9155 (74.5%)
DEBUG 01-05 12:51:26.236965.236965 cuda_h.py:19] end experts_map_get cost 0.0015282630920410156 seconds
DEBUG 01-05 12:51:26.236370.236370 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.236769.236769 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.237191.237191 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.238222.238222 cuda_h.py:19] end allocate_cuda_memory cost 0.0015027523040771484 seconds
DEBUG 01-05 12:51:26.238463.238463 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.238133.238133 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.238611.238611 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.238976.238976 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c0417d10-de22-4127-a782-c8c1118b4ad6
DEBUG 01-05 12:51:26.239280.239280 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.239528.239528 client.py:127] Model loaded
DEBUG 01-05 12:51:26.239001.239001 cuda_h.py:19] end sllm_worker_task cost 0.011693716049194336 seconds
INFO 01-05 12:51:26.240189.240189 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c0417d10-de22-4127-a782-c8c1118b4ad6
DEBUG 01-05 12:51:26.240270.240270 cuda_h.py:19] end load_into_gpu_async cost 0.0013358592987060547 seconds
DEBUG 01-05 12:51:26.240735.240735 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.240319.240319 cuda_h.py:19] end restore_tensors2 cost 0.00040268898010253906 seconds
DEBUG 01-05 12:51:26.240963.240963 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003596067428588867 seconds
DEBUG 01-05 12:51:26.243863.243863 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006201744079589844 seconds
DEBUG 01-05 12:51:26.243030.243030 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.243630.243630 lmp.py:423] 
DEBUG 01-05 12:51:26.243630.243630 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.243327.243327 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-05 12:51:26.243453.243453 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.252841.252841 mlpmodule.py:704] group tensors cost 0.009455680847167969 s
DEBUG 01-05 12:51:26.255354.255354 mlpmodule.py:742] pad cost 0.0016121864318847656 s
DEBUG 01-05 12:51:26.255490.255490 mlpmodule.py:748] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-05 12:51:26.255439.255439 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-05 12:51:26.264807.264807 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.264720.264720 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.264472.264472 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 12:51:26.264396.264396 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.280113.280113 mlpmodule.py:793] group einsum cost 0.025000810623168945 s
DEBUG 01-05 12:51:26.281692.281692 mlpmodule.py:801] cpy2cputensor cost 0.0006873607635498047 s
DEBUG 01-05 12:51:26.286091.286091 cuda_h.py:19] end wait_cetm_experts cost 0.042736053466796875 seconds
DEBUG 01-05 12:51:26.286287.286287 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.286417.286417 cuda_h.py:19] end gpu_sexperts cost 0.0004551410675048828 seconds
DEBUG 01-05 12:51:26.286983.286983 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.286079.286079 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:26.287326.287326 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.287274.287274 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c0417d10-de22-4127-a782-c8c1118b4ad6
INFO 01-05 12:51:26.293880.293880 client.py:127] Model loaded
DEBUG 01-05 12:51:26.294069.294069 cuda_h.py:19] end wait_experts cost 0.006940603256225586 seconds
DEBUG 01-05 12:51:26.294799.294799 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.294430.294430 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.294503.294503 mlpmodule.py:531] gpu group tensors cost 0.0006892681121826172 s
DEBUG 01-05 12:51:26.296565.296565 mlpmodule.py:564] gpu pad cost 0.0015742778778076172 s
DEBUG 01-05 12:51:26.297968.297968 mlpmodule.py:582] gpu group einsum cost 0.0004961490631103516 s
DEBUG 01-05 12:51:26.300997.300997 mlpmodule.py:611] gpu experts func einsum cost 0.005970478057861328 s
DEBUG 01-05 12:51:26.300107.300107 cuda_h.py:19] end gpu_experts cost 0.006189107894897461 seconds
DEBUG 01-05 12:51:26.300077.300077 cuda_h.py:19] end layer_moe_generate_8 cost 0.06570696830749512 seconds
DEBUG 01-05 12:51:26.300295.300295 lmp.py:217] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 12:51:26.300343.300343 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 12:51:26.300085.300085 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 12:51:26.300080.300080 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 12:51:26.300492.300492 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.8133392333984375e-05 seconds
DEBUG 01-05 12:51:26.300977.300977 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.843971252441406e-05 seconds
DEBUG 01-05 12:51:26.300097.300097 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.300404.300404 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.300566.300566 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.300926.300926 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.305693.305693 cuda_h.py:19] end allocate_cuda_memory cost 0.004495143890380859 seconds
DEBUG 01-05 12:51:26.305656.305656 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.305234.305234 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.305864.305864 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.305614.305614 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7f12632a-7d00-4dcf-aece-3f5b25cc18c4
DEBUG 01-05 12:51:26.305683.305683 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.305449.305449 mlpmodule.py:662]  experts func einsum cost 0.06244659423828125 s
DEBUG 01-05 12:51:26.306497.306497 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.307697.307697 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7f12632a-7d00-4dcf-aece-3f5b25cc18c4
DEBUG 01-05 12:51:26.307487.307487 cuda_h.py:19] end load_into_gpu_async cost 0.00162506103515625 seconds
DEBUG 01-05 12:51:26.307282.307282 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.307305.307305 cuda_h.py:19] end restore_tensors2 cost 6.151199340820312e-05 seconds
DEBUG 01-05 12:51:26.307631.307631 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0064394474029541016 seconds
INFO 01-05 12:51:26.307203.307203 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7f12632a-7d00-4dcf-aece-3f5b25cc18c4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.309314.309314 cuda_h.py:19] end self_attn cost 0.0031681060791015625 seconds
DEBUG 01-05 12:51:26.309370.309370 cuda_h.py:19] end iln_self_attn_paln cost 0.008913993835449219 seconds
DEBUG 01-05 12:51:26.309921.309921 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 12:51:26.309684.309684 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.310315.310315 cuda_h.py:19] end gate cost 0.0006077289581298828 seconds
DEBUG 01-05 12:51:26.310522.310522 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.310525.310525 lmp.py:365] 
DEBUG 01-05 12:51:26.310525.310525 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.310135.310135 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.310308.310308 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.310143.310143 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.310832.310832 lmp.py:369] 
DEBUG 01-05 12:51:26.310832.310832 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.310760.310760 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.310410.310410 lmp.py:376]   Expert 35 |     34 | CPU
DEBUG 01-05 12:51:26.310576.310576 lmp.py:376]   Expert  7 |     38 | CPU
DEBUG 01-05 12:51:26.310311.310311 lmp.py:376]   Expert  2 |     47 | CPU
DEBUG 01-05 12:51:26.310286.310286 lmp.py:376]   Expert  6 |     49 | CPU
DEBUG 01-05 12:51:26.310021.310021 lmp.py:376]   Expert 26 |     49 | CPU
DEBUG 01-05 12:51:26.310234.310234 lmp.py:376]   Expert  5 |     53 | CPU
DEBUG 01-05 12:51:26.311208.311208 lmp.py:376]   Expert 60 |     58 | CPU
DEBUG 01-05 12:51:26.311705.311705 lmp.py:376]   Expert 13 |     60 | CPU
DEBUG 01-05 12:51:26.311202.311202 lmp.py:376]   Expert 38 |     62 | CPU
DEBUG 01-05 12:51:26.311653.311653 lmp.py:376]   Expert 19 |     63 | CPU
DEBUG 01-05 12:51:26.311104.311104 lmp.py:376]   Expert 48 |     70 | CPU
DEBUG 01-05 12:51:26.311316.311316 lmp.py:376]   Expert 25 |     74 | CPU
DEBUG 01-05 12:51:26.311290.311290 lmp.py:376]   Expert 17 |     75 | CPU
DEBUG 01-05 12:51:26.311503.311503 lmp.py:376]   Expert 39 |     78 | CPU
DEBUG 01-05 12:51:26.311238.311238 lmp.py:376]   Expert 45 |     92 | CPU
DEBUG 01-05 12:51:26.311736.311736 lmp.py:376]   Expert 52 |     92 | CPU
DEBUG 01-05 12:51:26.311994.311994 lmp.py:376]   Expert 54 |     95 | CPU
DEBUG 01-05 12:51:26.311492.311492 lmp.py:376]   Expert 27 |    104 | CPU
DEBUG 01-05 12:51:26.311512.311512 lmp.py:376]   Expert 59 |    128 | CPU
DEBUG 01-05 12:51:26.311248.311248 lmp.py:376]   Expert 29 |    136 | CPU
DEBUG 01-05 12:51:26.311506.311506 lmp.py:376]   Expert 16 |    142 | CPU
DEBUG 01-05 12:51:26.311004.311004 lmp.py:376]   Expert 24 |    146 | CPU
DEBUG 01-05 12:51:26.311647.311647 lmp.py:376]   Expert 57 |    150 | CPU
DEBUG 01-05 12:51:26.311528.311528 lmp.py:376]   Expert 40 |    154 | CPU
DEBUG 01-05 12:51:26.311694.311694 lmp.py:376]   Expert 49 |    154 | CPU
DEBUG 01-05 12:51:26.311860.311860 lmp.py:376]   Expert 14 |    158 | CPU
DEBUG 01-05 12:51:26.311788.311788 lmp.py:376]   Expert 20 |    161 | CPU
DEBUG 01-05 12:51:26.311239.311239 lmp.py:376]   Expert 32 |    164 | CPU
DEBUG 01-05 12:51:26.311928.311928 lmp.py:376]   Expert 42 |    164 | CPU
DEBUG 01-05 12:51:26.311141.311141 lmp.py:376]   Expert 62 |    165 | CPU
DEBUG 01-05 12:51:26.311592.311592 lmp.py:376]   Expert 30 |    166 | CPU
DEBUG 01-05 12:51:26.311804.311804 lmp.py:376]   Expert 12 |    168 | CPU
DEBUG 01-05 12:51:26.311255.311255 lmp.py:376]   Expert 22 |    171 | GPU
DEBUG 01-05 12:51:26.311706.311706 lmp.py:376]   Expert 31 |    171 | GPU
DEBUG 01-05 12:51:26.311918.311918 lmp.py:376]   Expert 28 |    177 | GPU
DEBUG 01-05 12:51:26.311369.311369 lmp.py:376]   Expert 58 |    180 | GPU
DEBUG 01-05 12:51:26.311820.311820 lmp.py:376]   Expert 11 |    185 | GPU
DEBUG 01-05 12:51:26.311271.311271 lmp.py:376]   Expert  1 |    186 | GPU
DEBUG 01-05 12:51:26.311722.311722 lmp.py:376]   Expert 18 |    188 | GPU
DEBUG 01-05 12:51:26.311649.311649 lmp.py:376]   Expert 33 |    189 | GPU
DEBUG 01-05 12:51:26.311816.311816 lmp.py:376]   Expert 23 |    191 | GPU
DEBUG 01-05 12:51:26.311743.311743 lmp.py:376]   Expert 41 |    194 | GPU
DEBUG 01-05 12:51:26.311486.311486 lmp.py:376]   Expert 43 |    194 | GPU
DEBUG 01-05 12:51:26.311698.311698 lmp.py:376]   Expert 10 |    204 | GPU
DEBUG 01-05 12:51:26.311195.311195 lmp.py:376]   Expert 34 |    206 | GPU
DEBUG 01-05 12:51:26.311408.311408 lmp.py:376]   Expert  3 |    210 | GPU
DEBUG 01-05 12:51:26.311667.311667 lmp.py:376]   Expert 50 |    217 | GPU
DEBUG 01-05 12:51:26.311402.311402 lmp.py:376]   Expert 51 |    224 | GPU
DEBUG 01-05 12:51:26.311899.311899 lmp.py:376]   Expert  4 |    229 | GPU
DEBUG 01-05 12:51:26.311397.311397 lmp.py:376]   Expert 47 |    229 | GPU
DEBUG 01-05 12:51:26.311894.311894 lmp.py:376]   Expert 53 |    236 | GPU
DEBUG 01-05 12:51:26.311630.311630 lmp.py:376]   Expert 36 |    254 | GPU
DEBUG 01-05 12:51:26.311127.311127 lmp.py:376]   Expert  0 |    290 | GPU
DEBUG 01-05 12:51:26.311101.311101 lmp.py:376]   Expert 44 |    296 | GPU
DEBUG 01-05 12:51:26.311360.311360 lmp.py:376]   Expert 61 |    317 | GPU
DEBUG 01-05 12:51:26.311095.311095 lmp.py:376]   Expert 37 |    339 | GPU
DEBUG 01-05 12:51:26.311308.311308 lmp.py:376]   Expert 55 |    368 | GPU
DEBUG 01-05 12:51:26.311759.311759 lmp.py:376]   Expert  8 |    370 | GPU
DEBUG 01-05 12:51:26.311971.311971 lmp.py:376]   Expert  9 |    371 | GPU
DEBUG 01-05 12:51:26.311660.311660 lmp.py:376]   Expert 63 |    461 | GPU
DEBUG 01-05 12:51:26.311158.311158 lmp.py:376]   Expert 15 |    480 | GPU
DEBUG 01-05 12:51:26.311893.311893 lmp.py:376]   Expert 46 |    486 | GPU
DEBUG 01-05 12:51:26.311914.311914 lmp.py:376]   Expert 56 |    559 | GPU
DEBUG 01-05 12:51:26.311172.311172 lmp.py:376]   Expert 21 |    567 | GPU
DEBUG 01-05 12:51:26.311623.311623 lmp.py:377] 
DEBUG 01-05 12:51:26.311623.311623 lmp.py:377]   CPU total tokens: 3349 (27.3%)
DEBUG 01-05 12:51:26.311312.311312 lmp.py:378]   GPU total tokens: 8939 (72.7%)
DEBUG 01-05 12:51:26.311055.311055 cuda_h.py:19] end experts_map_get cost 0.0014545917510986328 seconds
DEBUG 01-05 12:51:26.311983.311983 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.312805.312805 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.312273.312273 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.313485.313485 cuda_h.py:19] end allocate_cuda_memory cost 0.0013513565063476562 seconds
DEBUG 01-05 12:51:26.313839.313839 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.313118.313118 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.313596.313596 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.313200.313200 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0a16985d-d0c3-4b62-9e5d-f3899567904c
DEBUG 01-05 12:51:26.313657.313657 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.315464.315464 client.py:127] Model loaded
DEBUG 01-05 12:51:26.315314.315314 cuda_h.py:19] end sllm_worker_task cost 0.014423131942749023 seconds
INFO 01-05 12:51:26.316034.316034 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0a16985d-d0c3-4b62-9e5d-f3899567904c
DEBUG 01-05 12:51:26.316453.316453 cuda_h.py:19] end load_into_gpu_async cost 0.0032639503479003906 seconds
DEBUG 01-05 12:51:26.316633.316633 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.317422.317422 cuda_h.py:19] end restore_tensors2 cost 0.00041103363037109375 seconds
DEBUG 01-05 12:51:26.317305.317305 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005400896072387695 seconds
DEBUG 01-05 12:51:26.320046.320046 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007985115051269531 seconds
DEBUG 01-05 12:51:26.320167.320167 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.320123.320123 lmp.py:423] 
DEBUG 01-05 12:51:26.320123.320123 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.320721.320721 cuda_h.py:19] end cpu_experts_submit cost 0.00010132789611816406 seconds
DEBUG 01-05 12:51:26.320106.320106 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.326426.326426 mlpmodule.py:704] group tensors cost 0.005645275115966797 s
DEBUG 01-05 12:51:26.328891.328891 mlpmodule.py:742] pad cost 0.0018470287322998047 s
DEBUG 01-05 12:51:26.328470.328470 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-05 12:51:26.328764.328764 mlpmodule.py:753] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-05 12:51:26.337265.337265 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.337906.337906 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.337896.337896 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 12:51:26.338728.338728 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.353162.353162 mlpmodule.py:793] group einsum cost 0.025041818618774414 s
DEBUG 01-05 12:51:26.354099.354099 mlpmodule.py:801] cpy2cputensor cost 0.0006964206695556641 s
DEBUG 01-05 12:51:26.359259.359259 cuda_h.py:19] end wait_cetm_experts cost 0.03914809226989746 seconds
DEBUG 01-05 12:51:26.359846.359846 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.360738.360738 cuda_h.py:19] end gpu_sexperts cost 0.0004565715789794922 seconds
DEBUG 01-05 12:51:26.360728.360728 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.360936.360936 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 12:51:26.360752.360752 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.360938.360938 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0a16985d-d0c3-4b62-9e5d-f3899567904c
INFO 01-05 12:51:26.370620.370620 client.py:127] Model loaded
DEBUG 01-05 12:51:26.370804.370804 cuda_h.py:19] end wait_experts cost 0.010218620300292969 seconds
DEBUG 01-05 12:51:26.370076.370076 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.370017.370017 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.371693.371693 mlpmodule.py:531] gpu group tensors cost 0.0005333423614501953 s
DEBUG 01-05 12:51:26.372729.372729 mlpmodule.py:564] gpu pad cost 0.0014162063598632812 s
DEBUG 01-05 12:51:26.373397.373397 mlpmodule.py:582] gpu group einsum cost 0.0005075931549072266 s
DEBUG 01-05 12:51:26.375171.375171 mlpmodule.py:611] gpu experts func einsum cost 0.005308866500854492 s
DEBUG 01-05 12:51:26.376207.376207 cuda_h.py:19] end gpu_experts cost 0.005479335784912109 seconds
DEBUG 01-05 12:51:26.376170.376170 cuda_h.py:19] end layer_moe_generate_9 cost 0.06634044647216797 seconds
DEBUG 01-05 12:51:26.376739.376739 lmp.py:217] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 12:51:26.376402.376402 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 12:51:26.376668.376668 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 12:51:26.376106.376106 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 12:51:26.376665.376665 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:26.376129.376129 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.532669067382812e-05 seconds
DEBUG 01-05 12:51:26.376726.376726 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.376649.376649 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.376149.376149 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.376270.376270 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.378345.378345 cuda_h.py:19] end allocate_cuda_memory cost 0.0014240741729736328 seconds
DEBUG 01-05 12:51:26.378864.378864 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.378601.378601 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.378516.378516 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.378550.378550 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b5e9041-d3ac-4e2c-a818-179748537338
DEBUG 01-05 12:51:26.378897.378897 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.378478.378478 mlpmodule.py:662]  experts func einsum cost 0.058264732360839844 s
DEBUG 01-05 12:51:26.378096.378096 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.379215.379215 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b5e9041-d3ac-4e2c-a818-179748537338
DEBUG 01-05 12:51:26.379574.379574 cuda_h.py:19] end load_into_gpu_async cost 0.0013837814331054688 seconds
DEBUG 01-05 12:51:26.379893.379893 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.379096.379096 cuda_h.py:19] end restore_tensors2 cost 8.535385131835938e-05 seconds
DEBUG 01-05 12:51:26.379747.379747 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031774044036865234 seconds
INFO 01-05 12:51:26.380698.380698 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b5e9041-d3ac-4e2c-a818-179748537338
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.382822.382822 cuda_h.py:19] end self_attn cost 0.003416776657104492 seconds
DEBUG 01-05 12:51:26.382354.382354 cuda_h.py:19] end iln_self_attn_paln cost 0.0060884952545166016 seconds
DEBUG 01-05 12:51:26.382290.382290 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 12:51:26.382291.382291 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.383512.383512 cuda_h.py:19] end gate cost 0.0006215572357177734 seconds
DEBUG 01-05 12:51:26.383242.383242 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.383576.383576 lmp.py:365] 
DEBUG 01-05 12:51:26.383576.383576 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.383855.383855 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.383551.383551 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.383386.383386 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.383552.383552 lmp.py:369] 
DEBUG 01-05 12:51:26.383552.383552 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.383719.383719 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.383229.383229 lmp.py:376]   Expert 34 |      6 | CPU
DEBUG 01-05 12:51:26.383018.383018 lmp.py:376]   Expert  3 |     22 | CPU
DEBUG 01-05 12:51:26.383423.383423 lmp.py:376]   Expert 61 |     23 | CPU
DEBUG 01-05 12:51:26.383350.383350 lmp.py:376]   Expert 14 |     25 | CPU
DEBUG 01-05 12:51:26.383801.383801 lmp.py:376]   Expert 48 |     39 | CPU
DEBUG 01-05 12:51:26.383014.383014 lmp.py:376]   Expert 47 |     44 | CPU
DEBUG 01-05 12:51:26.383465.383465 lmp.py:376]   Expert 32 |     47 | CPU
DEBUG 01-05 12:51:26.383915.383915 lmp.py:376]   Expert 55 |     50 | CPU
DEBUG 01-05 12:51:26.383128.383128 lmp.py:376]   Expert 15 |     70 | CPU
DEBUG 01-05 12:51:26.383532.383532 lmp.py:376]   Expert 13 |     72 | CPU
DEBUG 01-05 12:51:26.384699.384699 lmp.py:376]   Expert 44 |     76 | CPU
DEBUG 01-05 12:51:26.384626.384626 lmp.py:376]   Expert 27 |     77 | CPU
DEBUG 01-05 12:51:26.384792.384792 lmp.py:376]   Expert 19 |     78 | CPU
DEBUG 01-05 12:51:26.384482.384482 lmp.py:376]   Expert 12 |     80 | CPU
DEBUG 01-05 12:51:26.384171.384171 lmp.py:376]   Expert  7 |     82 | CPU
DEBUG 01-05 12:51:26.384145.384145 lmp.py:376]   Expert  6 |     87 | CPU
DEBUG 01-05 12:51:26.384834.384834 lmp.py:376]   Expert 54 |    101 | CPU
DEBUG 01-05 12:51:26.384047.384047 lmp.py:376]   Expert 56 |    103 | CPU
DEBUG 01-05 12:51:26.384498.384498 lmp.py:376]   Expert 50 |    104 | CPU
DEBUG 01-05 12:51:26.384710.384710 lmp.py:376]   Expert 26 |    110 | CPU
DEBUG 01-05 12:51:26.384161.384161 lmp.py:376]   Expert 38 |    112 | CPU
DEBUG 01-05 12:51:26.384612.384612 lmp.py:376]   Expert 28 |    113 | CPU
DEBUG 01-05 12:51:26.384586.384586 lmp.py:376]   Expert 20 |    119 | CPU
DEBUG 01-05 12:51:26.384799.384799 lmp.py:376]   Expert 46 |    119 | CPU
DEBUG 01-05 12:51:26.384726.384726 lmp.py:376]   Expert 62 |    121 | CPU
DEBUG 01-05 12:51:26.384892.384892 lmp.py:376]   Expert 37 |    131 | CPU
DEBUG 01-05 12:51:26.384297.384297 lmp.py:376]   Expert 35 |    143 | CPU
DEBUG 01-05 12:51:26.384986.384986 lmp.py:376]   Expert 43 |    144 | CPU
DEBUG 01-05 12:51:26.384199.384199 lmp.py:376]   Expert 36 |    152 | CPU
DEBUG 01-05 12:51:26.384650.384650 lmp.py:376]   Expert 52 |    157 | CPU
DEBUG 01-05 12:51:26.384862.384862 lmp.py:376]   Expert 45 |    158 | CPU
DEBUG 01-05 12:51:26.384551.384551 lmp.py:376]   Expert 60 |    159 | CPU
DEBUG 01-05 12:51:26.384764.384764 lmp.py:376]   Expert 17 |    169 | GPU
DEBUG 01-05 12:51:26.384944.384944 lmp.py:376]   Expert 29 |    169 | GPU
DEBUG 01-05 12:51:26.384156.384156 lmp.py:376]   Expert 41 |    170 | GPU
DEBUG 01-05 12:51:26.384368.384368 lmp.py:376]   Expert 25 |    171 | GPU
DEBUG 01-05 12:51:26.384581.384581 lmp.py:376]   Expert 22 |    178 | GPU
DEBUG 01-05 12:51:26.384793.384793 lmp.py:376]   Expert 51 |    184 | GPU
DEBUG 01-05 12:51:26.384483.384483 lmp.py:376]   Expert 24 |    189 | GPU
DEBUG 01-05 12:51:26.384887.384887 lmp.py:376]   Expert 63 |    190 | GPU
DEBUG 01-05 12:51:26.384053.384053 lmp.py:376]   Expert  2 |    198 | GPU
DEBUG 01-05 12:51:26.384981.384981 lmp.py:376]   Expert 42 |    206 | GPU
DEBUG 01-05 12:51:26.384432.384432 lmp.py:376]   Expert 57 |    214 | GPU
DEBUG 01-05 12:51:26.384121.384121 lmp.py:376]   Expert  5 |    225 | GPU
DEBUG 01-05 12:51:26.384811.384811 lmp.py:376]   Expert 21 |    237 | GPU
DEBUG 01-05 12:51:26.384023.384023 lmp.py:376]   Expert 18 |    241 | GPU
DEBUG 01-05 12:51:26.384712.384712 lmp.py:376]   Expert 31 |    241 | GPU
DEBUG 01-05 12:51:26.384163.384163 lmp.py:376]   Expert 59 |    245 | GPU
DEBUG 01-05 12:51:26.384376.384376 lmp.py:376]   Expert 53 |    253 | GPU
DEBUG 01-05 12:51:26.384350.384350 lmp.py:376]   Expert 30 |    262 | GPU
DEBUG 01-05 12:51:26.384562.384562 lmp.py:376]   Expert 39 |    269 | GPU
DEBUG 01-05 12:51:26.384967.384967 lmp.py:376]   Expert 16 |    276 | GPU
DEBUG 01-05 12:51:26.384133.384133 lmp.py:376]   Expert  8 |    291 | GPU
DEBUG 01-05 12:51:26.384537.384537 lmp.py:376]   Expert  9 |    303 | GPU
DEBUG 01-05 12:51:26.384465.384465 lmp.py:376]   Expert 10 |    313 | GPU
DEBUG 01-05 12:51:26.384393.384393 lmp.py:376]   Expert 49 |    347 | GPU
DEBUG 01-05 12:51:26.384367.384367 lmp.py:376]   Expert 33 |    355 | GPU
DEBUG 01-05 12:51:26.384818.384818 lmp.py:376]   Expert 23 |    370 | GPU
DEBUG 01-05 12:51:26.384269.384269 lmp.py:376]   Expert 40 |    419 | GPU
DEBUG 01-05 12:51:26.384481.384481 lmp.py:376]   Expert  0 |    439 | GPU
DEBUG 01-05 12:51:26.384932.384932 lmp.py:376]   Expert 11 |    506 | GPU
DEBUG 01-05 12:51:26.384383.384383 lmp.py:376]   Expert 58 |    523 | GPU
DEBUG 01-05 12:51:26.384834.384834 lmp.py:376]   Expert  1 |    599 | GPU
DEBUG 01-05 12:51:26.384046.384046 lmp.py:376]   Expert  4 |    612 | GPU
DEBUG 01-05 12:51:26.384212.384212 lmp.py:377] 
DEBUG 01-05 12:51:26.384212.384212 lmp.py:377]   CPU total tokens: 2924 (23.8%)
DEBUG 01-05 12:51:26.384855.384855 lmp.py:378]   GPU total tokens: 9364 (76.2%)
DEBUG 01-05 12:51:26.384267.384267 cuda_h.py:19] end experts_map_get cost 0.001501321792602539 seconds
DEBUG 01-05 12:51:26.384387.384387 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.385117.385117 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.385108.385108 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.386452.386452 cuda_h.py:19] end allocate_cuda_memory cost 0.0017304420471191406 seconds
DEBUG 01-05 12:51:26.386202.386202 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.387488.387488 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.387734.387734 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.387384.387384 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9808aaa6-7750-4d25-98f4-8df7af72b565
DEBUG 01-05 12:51:26.387642.387642 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.387533.387533 client.py:127] Model loaded
DEBUG 01-05 12:51:26.387006.387006 cuda_h.py:19] end sllm_worker_task cost 0.010957002639770508 seconds
INFO 01-05 12:51:26.388943.388943 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9808aaa6-7750-4d25-98f4-8df7af72b565
DEBUG 01-05 12:51:26.388151.388151 cuda_h.py:19] end load_into_gpu_async cost 0.0013837814331054688 seconds
DEBUG 01-05 12:51:26.388284.388284 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.388696.388696 cuda_h.py:19] end restore_tensors2 cost 0.0004169940948486328 seconds
DEBUG 01-05 12:51:26.388010.388010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003897428512573242 seconds
DEBUG 01-05 12:51:26.391534.391534 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0065419673919677734 seconds
DEBUG 01-05 12:51:26.391655.391655 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.391300.391300 lmp.py:423] 
DEBUG 01-05 12:51:26.391300.391300 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.391613.391613 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-05 12:51:26.391501.391501 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.402755.402755 mlpmodule.py:704] group tensors cost 0.01020359992980957 s
DEBUG 01-05 12:51:26.404055.404055 mlpmodule.py:742] pad cost 0.0014362335205078125 s
DEBUG 01-05 12:51:26.404151.404151 mlpmodule.py:748] create cpu tensor cost 5.2928924560546875e-05 s
DEBUG 01-05 12:51:26.404948.404948 mlpmodule.py:753] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-05 12:51:26.413795.413795 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.413780.413780 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.413148.413148 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 12:51:26.413456.413456 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.430643.430643 mlpmodule.py:793] group einsum cost 0.026417255401611328 s
DEBUG 01-05 12:51:26.431267.431267 mlpmodule.py:801] cpy2cputensor cost 0.0006601810455322266 s
DEBUG 01-05 12:51:26.436701.436701 cuda_h.py:19] end wait_cetm_experts cost 0.044695377349853516 seconds
DEBUG 01-05 12:51:26.436221.436221 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.437205.437205 cuda_h.py:19] end gpu_sexperts cost 0.0004489421844482422 seconds
DEBUG 01-05 12:51:26.437573.437573 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.437496.437496 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:26.437120.437120 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.437353.437353 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9808aaa6-7750-4d25-98f4-8df7af72b565
INFO 01-05 12:51:26.442449.442449 client.py:127] Model loaded
DEBUG 01-05 12:51:26.442922.442922 cuda_h.py:19] end wait_experts cost 0.005334138870239258 seconds
DEBUG 01-05 12:51:26.442268.442268 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.442806.442806 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.443552.443552 mlpmodule.py:531] gpu group tensors cost 0.0006339550018310547 s
DEBUG 01-05 12:51:26.445248.445248 mlpmodule.py:564] gpu pad cost 0.0016880035400390625 s
DEBUG 01-05 12:51:26.445580.445580 mlpmodule.py:582] gpu group einsum cost 0.0005331039428710938 s
DEBUG 01-05 12:51:26.448059.448059 mlpmodule.py:611] gpu experts func einsum cost 0.006062507629394531 s
DEBUG 01-05 12:51:26.449095.449095 cuda_h.py:19] end gpu_experts cost 0.006257772445678711 seconds
DEBUG 01-05 12:51:26.449111.449111 cuda_h.py:19] end layer_moe_generate_10 cost 0.06640934944152832 seconds
DEBUG 01-05 12:51:26.449547.449547 lmp.py:217] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 12:51:26.449641.449641 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 12:51:26.449145.449145 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 12:51:26.449047.449047 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 12:51:26.449791.449791 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:26.449301.449301 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.8650970458984375e-05 seconds
DEBUG 01-05 12:51:26.449898.449898 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.449153.449153 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.449288.449288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.449886.449886 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.450389.450389 cuda_h.py:19] end allocate_cuda_memory cost 0.000335693359375 seconds
DEBUG 01-05 12:51:26.450431.450431 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.450617.450617 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.450056.450056 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.450090.450090 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 07734aca-b96b-475b-a51e-b91aaa6dddaa
DEBUG 01-05 12:51:26.450013.450013 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.450459.450459 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.451194.451194 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 07734aca-b96b-475b-a51e-b91aaa6dddaa
DEBUG 01-05 12:51:26.451984.451984 cuda_h.py:19] end load_into_gpu_async cost 0.0012526512145996094 seconds
DEBUG 01-05 12:51:26.451541.451541 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.451531.451531 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 12:51:26.451810.451810 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001895904541015625 seconds
INFO 01-05 12:51:26.452045.452045 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 07734aca-b96b-475b-a51e-b91aaa6dddaa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.454754.454754 cuda_h.py:19] end self_attn cost 0.0038101673126220703 seconds
DEBUG 01-05 12:51:26.454657.454657 cuda_h.py:19] end iln_self_attn_paln cost 0.00523686408996582 seconds
DEBUG 01-05 12:51:26.454209.454209 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 12:51:26.454256.454256 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.455345.455345 cuda_h.py:19] end gate cost 0.000629425048828125 seconds
DEBUG 01-05 12:51:26.455359.455359 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.455508.455508 lmp.py:365] 
DEBUG 01-05 12:51:26.455508.455508 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.455118.455118 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.455099.455099 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.455649.455649 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.455816.455816 lmp.py:369] 
DEBUG 01-05 12:51:26.455816.455816 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.455982.455982 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.455393.455393 lmp.py:376]   Expert 19 |     16 | CPU
DEBUG 01-05 12:51:26.455943.455943 lmp.py:376]   Expert 35 |     16 | CPU
DEBUG 01-05 12:51:26.456732.456732 lmp.py:376]   Expert 39 |     25 | CPU
DEBUG 01-05 12:51:26.456468.456468 lmp.py:376]   Expert 16 |     31 | CPU
DEBUG 01-05 12:51:26.456203.456203 lmp.py:376]   Expert 59 |     38 | CPU
DEBUG 01-05 12:51:26.456939.456939 lmp.py:376]   Expert 49 |     49 | CPU
DEBUG 01-05 12:51:26.456913.456913 lmp.py:376]   Expert 41 |     53 | CPU
DEBUG 01-05 12:51:26.456410.456410 lmp.py:376]   Expert 17 |     59 | CPU
DEBUG 01-05 12:51:26.456384.456384 lmp.py:376]   Expert  5 |     74 | CPU
DEBUG 01-05 12:51:26.456882.456882 lmp.py:376]   Expert  7 |     77 | CPU
DEBUG 01-05 12:51:26.456856.456856 lmp.py:376]   Expert  3 |     78 | CPU
DEBUG 01-05 12:51:26.456830.456830 lmp.py:376]   Expert 15 |     78 | CPU
DEBUG 01-05 12:51:26.456757.456757 lmp.py:376]   Expert 23 |     80 | CPU
DEBUG 01-05 12:51:26.456493.456493 lmp.py:376]   Expert  8 |     82 | CPU
DEBUG 01-05 12:51:26.456944.456944 lmp.py:376]   Expert  0 |     83 | CPU
DEBUG 01-05 12:51:26.456918.456918 lmp.py:376]   Expert  6 |     87 | CPU
DEBUG 01-05 12:51:26.456322.456322 lmp.py:376]   Expert 44 |    100 | CPU
DEBUG 01-05 12:51:26.456012.456012 lmp.py:376]   Expert 38 |    101 | CPU
DEBUG 01-05 12:51:26.456701.456701 lmp.py:376]   Expert  4 |    102 | CPU
DEBUG 01-05 12:51:26.456152.456152 lmp.py:376]   Expert 62 |    105 | CPU
DEBUG 01-05 12:51:26.456841.456841 lmp.py:376]   Expert 40 |    106 | CPU
DEBUG 01-05 12:51:26.456054.456054 lmp.py:376]   Expert 46 |    108 | CPU
DEBUG 01-05 12:51:26.456743.456743 lmp.py:376]   Expert 63 |    108 | CPU
DEBUG 01-05 12:51:26.456194.456194 lmp.py:376]   Expert 10 |    109 | CPU
DEBUG 01-05 12:51:26.456645.456645 lmp.py:376]   Expert 52 |    112 | CPU
DEBUG 01-05 12:51:26.456963.456963 lmp.py:376]   Expert 32 |    121 | CPU
DEBUG 01-05 12:51:26.456461.456461 lmp.py:376]   Expert 27 |    122 | CPU
DEBUG 01-05 12:51:26.456912.456912 lmp.py:376]   Expert  1 |    134 | CPU
DEBUG 01-05 12:51:26.456124.456124 lmp.py:376]   Expert 50 |    135 | CPU
DEBUG 01-05 12:51:26.456005.456005 lmp.py:376]   Expert 48 |    137 | CPU
DEBUG 01-05 12:51:26.456648.456648 lmp.py:376]   Expert 60 |    140 | CPU
DEBUG 01-05 12:51:26.456338.456338 lmp.py:376]   Expert 25 |    141 | CPU
DEBUG 01-05 12:51:26.456504.456504 lmp.py:376]   Expert 31 |    144 | GPU
DEBUG 01-05 12:51:26.456432.456432 lmp.py:376]   Expert 20 |    155 | GPU
DEBUG 01-05 12:51:26.456121.456121 lmp.py:376]   Expert 36 |    158 | GPU
DEBUG 01-05 12:51:26.456572.456572 lmp.py:376]   Expert 51 |    171 | GPU
DEBUG 01-05 12:51:26.456023.456023 lmp.py:376]   Expert 13 |    176 | GPU
DEBUG 01-05 12:51:26.456235.456235 lmp.py:376]   Expert 57 |    178 | GPU
DEBUG 01-05 12:51:26.456686.456686 lmp.py:376]   Expert 61 |    178 | GPU
DEBUG 01-05 12:51:26.456137.456137 lmp.py:376]   Expert 18 |    184 | GPU
DEBUG 01-05 12:51:26.456588.456588 lmp.py:376]   Expert 56 |    192 | GPU
DEBUG 01-05 12:51:26.456039.456039 lmp.py:376]   Expert 42 |    193 | GPU
DEBUG 01-05 12:51:26.456682.456682 lmp.py:376]   Expert 26 |    211 | GPU
DEBUG 01-05 12:51:26.456848.456848 lmp.py:376]   Expert  2 |    218 | GPU
DEBUG 01-05 12:51:26.456775.456775 lmp.py:376]   Expert 43 |    236 | GPU
DEBUG 01-05 12:51:26.456942.456942 lmp.py:376]   Expert 47 |    256 | GPU
DEBUG 01-05 12:51:26.456392.456392 lmp.py:376]   Expert 33 |    258 | GPU
DEBUG 01-05 12:51:26.456605.456605 lmp.py:376]   Expert 53 |    276 | GPU
DEBUG 01-05 12:51:26.456056.456056 lmp.py:376]   Expert 12 |    284 | GPU
DEBUG 01-05 12:51:26.456268.456268 lmp.py:376]   Expert 55 |    297 | GPU
DEBUG 01-05 12:51:26.456242.456242 lmp.py:376]   Expert 45 |    311 | GPU
DEBUG 01-05 12:51:26.456455.456455 lmp.py:376]   Expert 58 |    312 | GPU
DEBUG 01-05 12:51:26.456667.456667 lmp.py:376]   Expert 14 |    324 | GPU
DEBUG 01-05 12:51:26.456641.456641 lmp.py:376]   Expert 29 |    324 | GPU
DEBUG 01-05 12:51:26.456046.456046 lmp.py:376]   Expert 24 |    335 | GPU
DEBUG 01-05 12:51:26.456974.456974 lmp.py:376]   Expert 37 |    341 | GPU
DEBUG 01-05 12:51:26.456901.456901 lmp.py:376]   Expert 34 |    364 | GPU
DEBUG 01-05 12:51:26.456829.456829 lmp.py:376]   Expert 54 |    369 | GPU
DEBUG 01-05 12:51:26.456234.456234 lmp.py:376]   Expert 21 |    379 | GPU
DEBUG 01-05 12:51:26.456446.456446 lmp.py:376]   Expert 28 |    401 | GPU
DEBUG 01-05 12:51:26.456658.456658 lmp.py:376]   Expert  9 |    405 | GPU
DEBUG 01-05 12:51:26.456109.456109 lmp.py:376]   Expert 11 |    417 | GPU
DEBUG 01-05 12:51:26.457560.457560 lmp.py:376]   Expert 22 |    451 | GPU
DEBUG 01-05 12:51:26.457773.457773 lmp.py:376]   Expert 30 |    983 | GPU
DEBUG 01-05 12:51:26.457177.457177 lmp.py:377] 
DEBUG 01-05 12:51:26.457177.457177 lmp.py:377]   CPU total tokens: 2807 (22.8%)
DEBUG 01-05 12:51:26.457582.457582 lmp.py:378]   GPU total tokens: 9481 (77.2%)
DEBUG 01-05 12:51:26.457755.457755 cuda_h.py:19] end experts_map_get cost 0.0014927387237548828 seconds
DEBUG 01-05 12:51:26.457398.457398 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.457273.457273 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.457934.457934 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.457178.457178 cuda_h.py:19] end allocate_cuda_memory cost 0.0005340576171875 seconds
DEBUG 01-05 12:51:26.457796.457796 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.457221.457221 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.457606.457606 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.458018.458018 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42d5e86c-2960-4178-a2d1-a8284b9916f0
DEBUG 01-05 12:51:26.458991.458991 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.458313.458313 mlpmodule.py:662]  experts func einsum cost 0.06645894050598145 s
INFO 01-05 12:51:26.458025.458025 client.py:127] Model loaded
DEBUG 01-05 12:51:26.458532.458532 cuda_h.py:19] end sllm_worker_task cost 0.008855342864990234 seconds
INFO 01-05 12:51:26.459438.459438 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42d5e86c-2960-4178-a2d1-a8284b9916f0
DEBUG 01-05 12:51:26.459282.459282 cuda_h.py:19] end load_into_gpu_async cost 0.0014123916625976562 seconds
DEBUG 01-05 12:51:26.459031.459031 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.459006.459006 cuda_h.py:19] end restore_tensors2 cost 0.0004119873046875 seconds
DEBUG 01-05 12:51:26.459180.459180 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027163028717041016 seconds
DEBUG 01-05 12:51:26.462427.462427 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0054013729095458984 seconds
DEBUG 01-05 12:51:26.462310.462310 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.462816.462816 lmp.py:423] 
DEBUG 01-05 12:51:26.462816.462816 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.462129.462129 cuda_h.py:19] end cpu_experts_submit cost 0.00010514259338378906 seconds
DEBUG 01-05 12:51:26.462733.462733 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.475955.475955 mlpmodule.py:704] group tensors cost 0.012663602828979492 s
DEBUG 01-05 12:51:26.477785.477785 mlpmodule.py:742] pad cost 0.0014450550079345703 s
DEBUG 01-05 12:51:26.477669.477669 mlpmodule.py:748] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-05 12:51:26.477082.477082 mlpmodule.py:753] move to cpu cost 2.7179718017578125e-05 s
DEBUG 01-05 12:51:26.487037.487037 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.487397.487397 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.487235.487235 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 12:51:26.487539.487539 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.504117.504117 mlpmodule.py:793] group einsum cost 0.02688765525817871 s
DEBUG 01-05 12:51:26.505622.505622 mlpmodule.py:801] cpy2cputensor cost 0.0005824565887451172 s
DEBUG 01-05 12:51:26.510728.510728 cuda_h.py:19] end wait_cetm_experts cost 0.047493696212768555 seconds
DEBUG 01-05 12:51:26.510115.510115 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.510211.510211 cuda_h.py:19] end gpu_sexperts cost 0.0004515647888183594 seconds
DEBUG 01-05 12:51:26.510445.510445 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.510441.510441 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-05 12:51:26.511289.511289 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.511284.511284 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42d5e86c-2960-4178-a2d1-a8284b9916f0
INFO 01-05 12:51:26.512760.512760 client.py:127] Model loaded
DEBUG 01-05 12:51:26.512894.512894 cuda_h.py:19] end wait_experts cost 0.0012230873107910156 seconds
DEBUG 01-05 12:51:26.512551.512551 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.512115.512115 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.513192.513192 mlpmodule.py:531] gpu group tensors cost 0.0006318092346191406 s
DEBUG 01-05 12:51:26.526703.526703 mlpmodule.py:564] gpu pad cost 0.013418912887573242 s
DEBUG 01-05 12:51:26.531750.531750 mlpmodule.py:662]  experts func einsum cost 0.06905555725097656 s
DEBUG 01-05 12:51:26.532957.532957 mlpmodule.py:582] gpu group einsum cost 0.0057370662689208984 s
DEBUG 01-05 12:51:26.535724.535724 mlpmodule.py:611] gpu experts func einsum cost 0.023458480834960938 s
DEBUG 01-05 12:51:26.536212.536212 cuda_h.py:19] end gpu_experts cost 0.023666858673095703 seconds
DEBUG 01-05 12:51:26.536394.536394 cuda_h.py:19] end layer_moe_generate_11 cost 0.08124852180480957 seconds
DEBUG 01-05 12:51:26.536149.536149 lmp.py:217] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 12:51:26.536349.536349 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 12:51:26.536112.536112 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 12:51:26.536974.536974 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 12:51:26.536016.536016 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.170967102050781e-05 seconds
DEBUG 01-05 12:51:26.536110.536110 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.224082946777344e-05 seconds
DEBUG 01-05 12:51:26.536377.536377 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.536531.536531 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.536408.536408 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.536095.536095 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.537580.537580 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
DEBUG 01-05 12:51:26.537424.537424 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.537009.537009 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.537607.537607 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.537700.537700 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3b6d3ce0-3223-4198-901b-aa23cbff9d32
DEBUG 01-05 12:51:26.537797.537797 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.537647.537647 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.538292.538292 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3b6d3ce0-3223-4198-901b-aa23cbff9d32
DEBUG 01-05 12:51:26.538195.538195 cuda_h.py:19] end load_into_gpu_async cost 0.0013992786407470703 seconds
DEBUG 01-05 12:51:26.538573.538573 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.538683.538683 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-05 12:51:26.538545.538545 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020084381103515625 seconds
INFO 01-05 12:51:26.539270.539270 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3b6d3ce0-3223-4198-901b-aa23cbff9d32
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.541326.541326 cuda_h.py:19] end self_attn cost 0.0039806365966796875 seconds
DEBUG 01-05 12:51:26.542388.542388 cuda_h.py:19] end iln_self_attn_paln cost 0.005300998687744141 seconds
DEBUG 01-05 12:51:26.542417.542417 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 12:51:26.542703.542703 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.542155.542155 cuda_h.py:19] end gate cost 0.0006170272827148438 seconds
DEBUG 01-05 12:51:26.542123.542123 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.543663.543663 lmp.py:365] 
DEBUG 01-05 12:51:26.543663.543663 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.543657.543657 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.543545.543545 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.543049.543049 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.543169.543169 lmp.py:369] 
DEBUG 01-05 12:51:26.543169.543169 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.543289.543289 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.543654.543654 lmp.py:376]   Expert 63 |     12 | CPU
DEBUG 01-05 12:51:26.543774.543774 lmp.py:376]   Expert 51 |     16 | CPU
DEBUG 01-05 12:51:26.543178.543178 lmp.py:376]   Expert 34 |     17 | CPU
DEBUG 01-05 12:51:26.543868.543868 lmp.py:376]   Expert 11 |     28 | CPU
DEBUG 01-05 12:51:26.543319.543319 lmp.py:376]   Expert 12 |     28 | CPU
DEBUG 01-05 12:51:26.543246.543246 lmp.py:376]   Expert 16 |     28 | CPU
DEBUG 01-05 12:51:26.543936.543936 lmp.py:376]   Expert 22 |     32 | CPU
DEBUG 01-05 12:51:26.543625.543625 lmp.py:376]   Expert 47 |     38 | CPU
DEBUG 01-05 12:51:26.543076.543076 lmp.py:376]   Expert  4 |     46 | CPU
DEBUG 01-05 12:51:26.543719.543719 lmp.py:376]   Expert 44 |     48 | CPU
DEBUG 01-05 12:51:26.543600.543600 lmp.py:376]   Expert  0 |     52 | CPU
DEBUG 01-05 12:51:26.543243.543243 lmp.py:376]   Expert 29 |     61 | CPU
DEBUG 01-05 12:51:26.543694.543694 lmp.py:376]   Expert 32 |     71 | CPU
DEBUG 01-05 12:51:26.543383.543383 lmp.py:376]   Expert 27 |     75 | CPU
DEBUG 01-05 12:51:26.543073.543073 lmp.py:376]   Expert 41 |     79 | CPU
DEBUG 01-05 12:51:26.543524.543524 lmp.py:376]   Expert  8 |     80 | CPU
DEBUG 01-05 12:51:26.543213.543213 lmp.py:376]   Expert 13 |     80 | CPU
DEBUG 01-05 12:51:26.543187.543187 lmp.py:376]   Expert 37 |     87 | CPU
DEBUG 01-05 12:51:26.543876.543876 lmp.py:376]   Expert 23 |     94 | CPU
DEBUG 01-05 12:51:26.543327.543327 lmp.py:376]   Expert 49 |    102 | CPU
DEBUG 01-05 12:51:26.543540.543540 lmp.py:376]   Expert 43 |    103 | CPU
DEBUG 01-05 12:51:26.543229.543229 lmp.py:376]   Expert  2 |    110 | CPU
DEBUG 01-05 12:51:26.543263.543263 lmp.py:376]   Expert 21 |    114 | CPU
DEBUG 01-05 12:51:26.543191.543191 lmp.py:376]   Expert  3 |    130 | CPU
DEBUG 01-05 12:51:26.543165.543165 lmp.py:376]   Expert 39 |    131 | CPU
DEBUG 01-05 12:51:26.543900.543900 lmp.py:376]   Expert 62 |    136 | CPU
DEBUG 01-05 12:51:26.543397.543397 lmp.py:376]   Expert 14 |    137 | CPU
DEBUG 01-05 12:51:26.543133.543133 lmp.py:376]   Expert 30 |    145 | CPU
DEBUG 01-05 12:51:26.543630.543630 lmp.py:376]   Expert 55 |    145 | CPU
DEBUG 01-05 12:51:26.543127.543127 lmp.py:376]   Expert 42 |    156 | CPU
DEBUG 01-05 12:51:26.543625.543625 lmp.py:376]   Expert 61 |    156 | CPU
DEBUG 01-05 12:51:26.543122.543122 lmp.py:376]   Expert  7 |    157 | CPU
DEBUG 01-05 12:51:26.543619.543619 lmp.py:376]   Expert 58 |    170 | GPU
DEBUG 01-05 12:51:26.543116.543116 lmp.py:376]   Expert 45 |    177 | GPU
DEBUG 01-05 12:51:26.543044.543044 lmp.py:376]   Expert 18 |    188 | GPU
DEBUG 01-05 12:51:26.543687.543687 lmp.py:376]   Expert 53 |    190 | GPU
DEBUG 01-05 12:51:26.543661.543661 lmp.py:376]   Expert  5 |    193 | GPU
DEBUG 01-05 12:51:26.543920.543920 lmp.py:376]   Expert 38 |    196 | GPU
DEBUG 01-05 12:51:26.543417.543417 lmp.py:376]   Expert 31 |    205 | GPU
DEBUG 01-05 12:51:26.543676.543676 lmp.py:376]   Expert 35 |    211 | GPU
DEBUG 01-05 12:51:26.543173.543173 lmp.py:376]   Expert 17 |    214 | GPU
DEBUG 01-05 12:51:26.543670.543670 lmp.py:376]   Expert  6 |    220 | GPU
DEBUG 01-05 12:51:26.543691.543691 lmp.py:376]   Expert 19 |    233 | GPU
DEBUG 01-05 12:51:26.543188.543188 lmp.py:376]   Expert  1 |    236 | GPU
DEBUG 01-05 12:51:26.544447.544447 lmp.py:376]   Expert 50 |    238 | GPU
DEBUG 01-05 12:51:26.544182.544182 lmp.py:376]   Expert 20 |    240 | GPU
DEBUG 01-05 12:51:26.544633.544633 lmp.py:376]   Expert 46 |    247 | GPU
DEBUG 01-05 12:51:26.544799.544799 lmp.py:376]   Expert 57 |    260 | GPU
DEBUG 01-05 12:51:26.544535.544535 lmp.py:376]   Expert 59 |    284 | GPU
DEBUG 01-05 12:51:26.544794.544794 lmp.py:376]   Expert 52 |    289 | GPU
DEBUG 01-05 12:51:26.544052.544052 lmp.py:376]   Expert 26 |    290 | GPU
DEBUG 01-05 12:51:26.544550.544550 lmp.py:376]   Expert 25 |    307 | GPU
DEBUG 01-05 12:51:26.544047.544047 lmp.py:376]   Expert 60 |    313 | GPU
DEBUG 01-05 12:51:26.544306.544306 lmp.py:376]   Expert 48 |    315 | GPU
DEBUG 01-05 12:51:26.544564.544564 lmp.py:376]   Expert 28 |    318 | GPU
DEBUG 01-05 12:51:26.544062.544062 lmp.py:376]   Expert 54 |    325 | GPU
DEBUG 01-05 12:51:26.544320.544320 lmp.py:376]   Expert 24 |    343 | GPU
DEBUG 01-05 12:51:26.544818.544818 lmp.py:376]   Expert 36 |    343 | GPU
DEBUG 01-05 12:51:26.544076.544076 lmp.py:376]   Expert 40 |    380 | GPU
DEBUG 01-05 12:51:26.544004.544004 lmp.py:376]   Expert 33 |    425 | GPU
DEBUG 01-05 12:51:26.544693.544693 lmp.py:376]   Expert  9 |    444 | GPU
DEBUG 01-05 12:51:26.544191.544191 lmp.py:376]   Expert 15 |    523 | GPU
DEBUG 01-05 12:51:26.544688.544688 lmp.py:376]   Expert 56 |    561 | GPU
DEBUG 01-05 12:51:26.544947.544947 lmp.py:376]   Expert 10 |    716 | GPU
DEBUG 01-05 12:51:26.544636.544636 lmp.py:377] 
DEBUG 01-05 12:51:26.544636.544636 lmp.py:377]   CPU total tokens: 2694 (21.9%)
DEBUG 01-05 12:51:26.544087.544087 lmp.py:378]   GPU total tokens: 9594 (78.1%)
DEBUG 01-05 12:51:26.544068.544068 cuda_h.py:19] end experts_map_get cost 0.0014770030975341797 seconds
DEBUG 01-05 12:51:26.544519.544519 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.544024.544024 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.544538.544538 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.545016.545016 cuda_h.py:19] end allocate_cuda_memory cost 0.0011990070343017578 seconds
DEBUG 01-05 12:51:26.545237.545237 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.545278.545278 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.545233.545233 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.545598.545598 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e710c2c0-80b0-46c8-af8f-1bfe16e9ddaf
DEBUG 01-05 12:51:26.546279.546279 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.546722.546722 client.py:127] Model loaded
DEBUG 01-05 12:51:26.546460.546460 cuda_h.py:19] end sllm_worker_task cost 0.009873390197753906 seconds
INFO 01-05 12:51:26.547937.547937 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e710c2c0-80b0-46c8-af8f-1bfe16e9ddaf
DEBUG 01-05 12:51:26.547972.547972 cuda_h.py:19] end load_into_gpu_async cost 0.00156402587890625 seconds
DEBUG 01-05 12:51:26.547483.547483 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.547404.547404 cuda_h.py:19] end restore_tensors2 cost 0.0003719329833984375 seconds
DEBUG 01-05 12:51:26.547995.547995 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003467082977294922 seconds
DEBUG 01-05 12:51:26.550365.550365 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0060672760009765625 seconds
DEBUG 01-05 12:51:26.550579.550579 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.550058.550058 lmp.py:423] 
DEBUG 01-05 12:51:26.550058.550058 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.550894.550894 cuda_h.py:19] end cpu_experts_submit cost 0.00010037422180175781 seconds
DEBUG 01-05 12:51:26.550518.550518 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.562049.562049 mlpmodule.py:704] group tensors cost 0.012125968933105469 s
DEBUG 01-05 12:51:26.565569.565569 mlpmodule.py:742] pad cost 0.0014295578002929688 s
DEBUG 01-05 12:51:26.565075.565075 mlpmodule.py:748] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-05 12:51:26.565587.565587 mlpmodule.py:753] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-05 12:51:26.574208.574208 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.574796.574796 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.574117.574117 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 12:51:26.575280.575280 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.590659.590659 mlpmodule.py:793] group einsum cost 0.025603532791137695 s
DEBUG 01-05 12:51:26.591453.591453 mlpmodule.py:801] cpy2cputensor cost 0.0006852149963378906 s
DEBUG 01-05 12:51:26.596626.596626 cuda_h.py:19] end wait_cetm_experts cost 0.04608035087585449 seconds
DEBUG 01-05 12:51:26.596107.596107 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.597143.597143 cuda_h.py:19] end gpu_sexperts cost 0.00042510032653808594 seconds
DEBUG 01-05 12:51:26.597888.597888 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.597957.597957 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:26.597250.597250 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.597436.597436 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e710c2c0-80b0-46c8-af8f-1bfe16e9ddaf
INFO 01-05 12:51:26.600632.600632 client.py:127] Model loaded
DEBUG 01-05 12:51:26.600106.600106 cuda_h.py:19] end wait_experts cost 0.0031957626342773438 seconds
DEBUG 01-05 12:51:26.600452.600452 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.600460.600460 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.601769.601769 mlpmodule.py:531] gpu group tensors cost 0.0006380081176757812 s
DEBUG 01-05 12:51:26.603291.603291 mlpmodule.py:564] gpu pad cost 0.0016512870788574219 s
DEBUG 01-05 12:51:26.604617.604617 mlpmodule.py:582] gpu group einsum cost 0.0005266666412353516 s
DEBUG 01-05 12:51:26.607942.607942 mlpmodule.py:611] gpu experts func einsum cost 0.0064182281494140625 s
DEBUG 01-05 12:51:26.607303.607303 cuda_h.py:19] end gpu_experts cost 0.0065937042236328125 seconds
DEBUG 01-05 12:51:26.607936.607936 cuda_h.py:19] end layer_moe_generate_12 cost 0.0655202865600586 seconds
DEBUG 01-05 12:51:26.607903.607903 lmp.py:217] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 12:51:26.607566.607566 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 12:51:26.607831.607831 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 12:51:26.607157.607157 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 12:51:26.608040.608040 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.7418136596679688e-05 seconds
DEBUG 01-05 12:51:26.608789.608789 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.817413330078125e-05 seconds
DEBUG 01-05 12:51:26.608385.608385 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.608937.608937 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.608359.608359 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.608917.608917 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.616002.616002 cuda_h.py:19] end allocate_cuda_memory cost 0.008214473724365234 seconds
DEBUG 01-05 12:51:26.616966.616966 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.616444.616444 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.616890.616890 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.616592.616592 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ca1cedd3-8016-4704-9b02-bbbdeea9623a
DEBUG 01-05 12:51:26.616960.616960 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.617241.617241 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.618330.618330 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ca1cedd3-8016-4704-9b02-bbbdeea9623a
DEBUG 01-05 12:51:26.618927.618927 cuda_h.py:19] end load_into_gpu_async cost 0.0013747215270996094 seconds
DEBUG 01-05 12:51:26.618246.618246 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.618468.618468 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-05 12:51:26.618793.618793 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009972810745239258 seconds
INFO 01-05 12:51:26.618949.618949 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ca1cedd3-8016-4704-9b02-bbbdeea9623a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.620815.620815 cuda_h.py:19] end self_attn cost 0.0032346248626708984 seconds
DEBUG 01-05 12:51:26.620202.620202 cuda_h.py:19] end iln_self_attn_paln cost 0.012688398361206055 seconds
DEBUG 01-05 12:51:26.620469.620469 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 12:51:26.620708.620708 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.621744.621744 cuda_h.py:19] end gate cost 0.0006234645843505859 seconds
DEBUG 01-05 12:51:26.621950.621950 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.621622.621622 lmp.py:365] 
DEBUG 01-05 12:51:26.621622.621622 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.621948.621948 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.621882.621882 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.621717.621717 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.621883.621883 lmp.py:369] 
DEBUG 01-05 12:51:26.621883.621883 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.621811.621811 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.621223.621223 lmp.py:376]   Expert  6 |     13 | CPU
DEBUG 01-05 12:51:26.621389.621389 lmp.py:376]   Expert 53 |     13 | CPU
DEBUG 01-05 12:51:26.622840.622840 lmp.py:376]   Expert 19 |     17 | CPU
DEBUG 01-05 12:51:26.622052.622052 lmp.py:376]   Expert 50 |     26 | CPU
DEBUG 01-05 12:51:26.622741.622741 lmp.py:376]   Expert  2 |     45 | CPU
DEBUG 01-05 12:51:26.622954.622954 lmp.py:376]   Expert 26 |     46 | CPU
DEBUG 01-05 12:51:26.622689.622689 lmp.py:376]   Expert  0 |     57 | CPU
DEBUG 01-05 12:51:26.622571.622571 lmp.py:376]   Expert  8 |     60 | CPU
DEBUG 01-05 12:51:26.622975.622975 lmp.py:376]   Expert 12 |     62 | CPU
DEBUG 01-05 12:51:26.622141.622141 lmp.py:376]   Expert 31 |     79 | CPU
DEBUG 01-05 12:51:26.622261.622261 lmp.py:376]   Expert 16 |     88 | CPU
DEBUG 01-05 12:51:26.622712.622712 lmp.py:376]   Expert 20 |     91 | CPU
DEBUG 01-05 12:51:26.622163.622163 lmp.py:376]   Expert 30 |     99 | CPU
DEBUG 01-05 12:51:26.622852.622852 lmp.py:376]   Expert 40 |     99 | CPU
DEBUG 01-05 12:51:26.622065.622065 lmp.py:376]   Expert 32 |    103 | CPU
DEBUG 01-05 12:51:26.622516.622516 lmp.py:376]   Expert 28 |    111 | CPU
DEBUG 01-05 12:51:26.622967.622967 lmp.py:376]   Expert 57 |    119 | CPU
DEBUG 01-05 12:51:26.622417.622417 lmp.py:376]   Expert 61 |    120 | CPU
DEBUG 01-05 12:51:26.622630.622630 lmp.py:376]   Expert 35 |    122 | CPU
DEBUG 01-05 12:51:26.622034.622034 lmp.py:376]   Expert 63 |    123 | CPU
DEBUG 01-05 12:51:26.622201.622201 lmp.py:376]   Expert 48 |    126 | CPU
DEBUG 01-05 12:51:26.622605.622605 lmp.py:376]   Expert 18 |    127 | CPU
DEBUG 01-05 12:51:26.622056.622056 lmp.py:376]   Expert 13 |    129 | CPU
DEBUG 01-05 12:51:26.622229.622229 lmp.py:376]   Expert 60 |    130 | CPU
DEBUG 01-05 12:51:26.622157.622157 lmp.py:376]   Expert  5 |    132 | CPU
DEBUG 01-05 12:51:26.622608.622608 lmp.py:376]   Expert 11 |    133 | CPU
DEBUG 01-05 12:51:26.622297.622297 lmp.py:376]   Expert 34 |    137 | CPU
DEBUG 01-05 12:51:26.622986.622986 lmp.py:376]   Expert 24 |    145 | CPU
DEBUG 01-05 12:51:26.622199.622199 lmp.py:376]   Expert 52 |    153 | CPU
DEBUG 01-05 12:51:26.622126.622126 lmp.py:376]   Expert  9 |    154 | CPU
DEBUG 01-05 12:51:26.622531.622531 lmp.py:376]   Expert 45 |    161 | CPU
DEBUG 01-05 12:51:26.622459.622459 lmp.py:376]   Expert 58 |    164 | CPU
DEBUG 01-05 12:51:26.622863.622863 lmp.py:376]   Expert 37 |    175 | GPU
DEBUG 01-05 12:51:26.622314.622314 lmp.py:376]   Expert 42 |    175 | GPU
DEBUG 01-05 12:51:26.622527.622527 lmp.py:376]   Expert  3 |    180 | GPU
DEBUG 01-05 12:51:26.622216.622216 lmp.py:376]   Expert 25 |    181 | GPU
DEBUG 01-05 12:51:26.622667.622667 lmp.py:376]   Expert  4 |    203 | GPU
DEBUG 01-05 12:51:26.622118.622118 lmp.py:376]   Expert 46 |    209 | GPU
DEBUG 01-05 12:51:26.622569.622569 lmp.py:376]   Expert 17 |    211 | GPU
DEBUG 01-05 12:51:26.622457.622457 lmp.py:376]   Expert  7 |    214 | GPU
DEBUG 01-05 12:51:26.622908.622908 lmp.py:376]   Expert 27 |    217 | GPU
DEBUG 01-05 12:51:26.622597.622597 lmp.py:376]   Expert 39 |    224 | GPU
DEBUG 01-05 12:51:26.622048.622048 lmp.py:376]   Expert 22 |    226 | GPU
DEBUG 01-05 12:51:26.622452.622452 lmp.py:376]   Expert 33 |    229 | GPU
DEBUG 01-05 12:51:26.622618.622618 lmp.py:376]   Expert 51 |    232 | GPU
DEBUG 01-05 12:51:26.622546.622546 lmp.py:376]   Expert 62 |    234 | GPU
DEBUG 01-05 12:51:26.622235.622235 lmp.py:376]   Expert 43 |    235 | GPU
DEBUG 01-05 12:51:26.622925.622925 lmp.py:376]   Expert 54 |    246 | GPU
DEBUG 01-05 12:51:26.622137.622137 lmp.py:376]   Expert 49 |    252 | GPU
DEBUG 01-05 12:51:26.622827.622827 lmp.py:376]   Expert  1 |    261 | GPU
DEBUG 01-05 12:51:26.622516.622516 lmp.py:376]   Expert 36 |    278 | GPU
DEBUG 01-05 12:51:26.622967.622967 lmp.py:376]   Expert 29 |    282 | GPU
DEBUG 01-05 12:51:26.622418.622418 lmp.py:376]   Expert 44 |    282 | GPU
DEBUG 01-05 12:51:26.622107.622107 lmp.py:376]   Expert 59 |    315 | GPU
DEBUG 01-05 12:51:26.622035.622035 lmp.py:376]   Expert 15 |    319 | GPU
DEBUG 01-05 12:51:26.622201.622201 lmp.py:376]   Expert 47 |    321 | GPU
DEBUG 01-05 12:51:26.622890.622890 lmp.py:376]   Expert 38 |    342 | GPU
DEBUG 01-05 12:51:26.622579.622579 lmp.py:376]   Expert 14 |    396 | GPU
DEBUG 01-05 12:51:26.622030.622030 lmp.py:376]   Expert 23 |    397 | GPU
DEBUG 01-05 12:51:26.622243.622243 lmp.py:376]   Expert 41 |    404 | GPU
DEBUG 01-05 12:51:26.622694.622694 lmp.py:376]   Expert 55 |    404 | GPU
DEBUG 01-05 12:51:26.623383.623383 lmp.py:376]   Expert 21 |    406 | GPU
DEBUG 01-05 12:51:26.623595.623595 lmp.py:376]   Expert 10 |    469 | GPU
DEBUG 01-05 12:51:26.623046.623046 lmp.py:376]   Expert 56 |    585 | GPU
DEBUG 01-05 12:51:26.623689.623689 lmp.py:377] 
DEBUG 01-05 12:51:26.623689.623689 lmp.py:377]   CPU total tokens: 3184 (25.9%)
DEBUG 01-05 12:51:26.623809.623809 lmp.py:378]   GPU total tokens: 9104 (74.1%)
DEBUG 01-05 12:51:26.623936.623936 cuda_h.py:19] end experts_map_get cost 0.0015065670013427734 seconds
DEBUG 01-05 12:51:26.623340.623340 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.623978.623978 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.623922.623922 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.625390.625390 cuda_h.py:19] end allocate_cuda_memory cost 0.0024530887603759766 seconds
DEBUG 01-05 12:51:26.625049.625049 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.625758.625758 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.625382.625382 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.625701.625701 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 00b68e23-516d-41f9-aec4-5bf85a354553
DEBUG 01-05 12:51:26.626350.626350 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.626594.626594 mlpmodule.py:662]  experts func einsum cost 0.07548213005065918 s
INFO 01-05 12:51:26.626688.626688 client.py:127] Model loaded
DEBUG 01-05 12:51:26.626011.626011 cuda_h.py:19] end sllm_worker_task cost 0.01849532127380371 seconds
INFO 01-05 12:51:26.627161.627161 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 00b68e23-516d-41f9-aec4-5bf85a354553
DEBUG 01-05 12:51:26.627964.627964 cuda_h.py:19] end load_into_gpu_async cost 0.0012018680572509766 seconds
DEBUG 01-05 12:51:26.627144.627144 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.627893.627893 cuda_h.py:19] end restore_tensors2 cost 0.0003857612609863281 seconds
DEBUG 01-05 12:51:26.627206.627206 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0044286251068115234 seconds
DEBUG 01-05 12:51:26.630466.630466 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007079124450683594 seconds
DEBUG 01-05 12:51:26.630726.630726 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.630020.630020 lmp.py:423] 
DEBUG 01-05 12:51:26.630020.630020 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.630101.630101 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-05 12:51:26.630036.630036 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.635637.635637 mlpmodule.py:704] group tensors cost 0.004912853240966797 s
DEBUG 01-05 12:51:26.637894.637894 mlpmodule.py:742] pad cost 0.001676797866821289 s
DEBUG 01-05 12:51:26.637196.637196 mlpmodule.py:748] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-05 12:51:26.638789.638789 mlpmodule.py:753] move to cpu cost 5.14984130859375e-05 s
DEBUG 01-05 12:51:26.648207.648207 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.648618.648618 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.648045.648045 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 12:51:26.648727.648727 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.670072.670072 mlpmodule.py:793] group einsum cost 0.032451629638671875 s
DEBUG 01-05 12:51:26.672158.672158 mlpmodule.py:801] cpy2cputensor cost 0.0007884502410888672 s
DEBUG 01-05 12:51:26.684379.684379 cuda_h.py:19] end wait_cetm_experts cost 0.05428361892700195 seconds
DEBUG 01-05 12:51:26.685619.685619 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.685974.685974 cuda_h.py:19] end gpu_sexperts cost 0.0008187294006347656 seconds
DEBUG 01-05 12:51:26.686965.686965 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.686637.686637 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.125999450683594e-05 seconds
DEBUG 01-05 12:51:26.686076.686076 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.686077.686077 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 00b68e23-516d-41f9-aec4-5bf85a354553
INFO 01-05 12:51:26.687335.687335 client.py:127] Model loaded
DEBUG 01-05 12:51:26.687284.687284 cuda_h.py:19] end wait_experts cost 0.0010318756103515625 seconds
DEBUG 01-05 12:51:26.687225.687225 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.687166.687166 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.688130.688130 mlpmodule.py:531] gpu group tensors cost 0.0007774829864501953 s
DEBUG 01-05 12:51:26.689764.689764 mlpmodule.py:564] gpu pad cost 0.0016603469848632812 s
DEBUG 01-05 12:51:26.690477.690477 mlpmodule.py:582] gpu group einsum cost 0.0006659030914306641 s
DEBUG 01-05 12:51:26.693194.693194 mlpmodule.py:611] gpu experts func einsum cost 0.006444454193115234 s
DEBUG 01-05 12:51:26.694748.694748 cuda_h.py:19] end gpu_experts cost 0.0066792964935302734 seconds
DEBUG 01-05 12:51:26.694161.694161 cuda_h.py:19] end layer_moe_generate_13 cost 0.07326745986938477 seconds
DEBUG 01-05 12:51:26.694018.694018 lmp.py:217] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 12:51:26.694258.694258 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 12:51:26.694524.694524 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 12:51:26.694088.694088 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 12:51:26.694838.694838 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.600120544433594e-05 seconds
DEBUG 01-05 12:51:26.694608.694608 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 8.20159912109375e-05 seconds
DEBUG 01-05 12:51:26.694727.694727 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.694471.694471 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.694642.694642 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.694121.694121 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.702995.702995 cuda_h.py:19] end allocate_cuda_memory cost 0.007275581359863281 seconds
DEBUG 01-05 12:51:26.702237.702237 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.702623.702623 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.702744.702744 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.702500.702500 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5ea27096-2787-4673-b105-0a964981b297
DEBUG 01-05 12:51:26.702198.702198 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.702698.702698 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.703746.703746 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5ea27096-2787-4673-b105-0a964981b297
DEBUG 01-05 12:51:26.703834.703834 cuda_h.py:19] end load_into_gpu_async cost 0.0011715888977050781 seconds
DEBUG 01-05 12:51:26.703021.703021 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.703661.703661 cuda_h.py:19] end restore_tensors2 cost 8.559226989746094e-05 seconds
DEBUG 01-05 12:51:26.703000.703000 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008857250213623047 seconds
INFO 01-05 12:51:26.704870.704870 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5ea27096-2787-4673-b105-0a964981b297
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.707503.707503 cuda_h.py:19] end self_attn cost 0.004983186721801758 seconds
DEBUG 01-05 12:51:26.708502.708502 cuda_h.py:19] end iln_self_attn_paln cost 0.013517618179321289 seconds
DEBUG 01-05 12:51:26.708451.708451 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 12:51:26.708605.708605 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.709309.709309 cuda_h.py:19] end gate cost 0.0008311271667480469 seconds
DEBUG 01-05 12:51:26.709676.709676 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.709151.709151 lmp.py:365] 
DEBUG 01-05 12:51:26.709151.709151 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.709629.709629 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.709332.709332 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.709266.709266 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.709009.709009 lmp.py:369] 
DEBUG 01-05 12:51:26.709009.709009 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.709182.709182 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.709315.709315 lmp.py:376]   Expert 61 |     10 | CPU
DEBUG 01-05 12:51:26.709488.709488 lmp.py:376]   Expert  7 |     15 | CPU
DEBUG 01-05 12:51:26.709231.709231 lmp.py:376]   Expert 59 |     38 | CPU
DEBUG 01-05 12:51:26.709735.709735 lmp.py:376]   Expert 34 |     50 | CPU
DEBUG 01-05 12:51:26.709053.709053 lmp.py:376]   Expert 50 |     55 | CPU
DEBUG 01-05 12:51:26.709749.709749 lmp.py:376]   Expert 38 |     57 | CPU
DEBUG 01-05 12:51:26.709061.709061 lmp.py:376]   Expert 48 |     59 | CPU
DEBUG 01-05 12:51:26.709373.709373 lmp.py:376]   Expert 49 |     62 | CPU
DEBUG 01-05 12:51:26.709447.709447 lmp.py:376]   Expert 40 |     66 | CPU
DEBUG 01-05 12:51:26.709758.709758 lmp.py:376]   Expert 55 |     72 | CPU
DEBUG 01-05 12:51:26.709693.709693 lmp.py:376]   Expert 32 |     74 | CPU
DEBUG 01-05 12:51:26.710959.710959 lmp.py:376]   Expert 43 |     95 | CPU
DEBUG 01-05 12:51:26.710463.710463 lmp.py:376]   Expert  0 |    105 | CPU
DEBUG 01-05 12:51:26.710490.710490 lmp.py:376]   Expert 18 |    105 | CPU
DEBUG 01-05 12:51:26.710278.710278 lmp.py:376]   Expert 44 |    105 | CPU
DEBUG 01-05 12:51:26.710829.710829 lmp.py:376]   Expert 23 |    109 | CPU
DEBUG 01-05 12:51:26.710902.710902 lmp.py:376]   Expert 35 |    110 | CPU
DEBUG 01-05 12:51:26.710214.710214 lmp.py:376]   Expert 60 |    110 | CPU
DEBUG 01-05 12:51:26.710003.710003 lmp.py:376]   Expert  8 |    115 | CPU
DEBUG 01-05 12:51:26.710076.710076 lmp.py:376]   Expert 28 |    115 | CPU
DEBUG 01-05 12:51:26.710388.710388 lmp.py:376]   Expert 39 |    116 | CPU
DEBUG 01-05 12:51:26.710939.710939 lmp.py:376]   Expert 29 |    118 | CPU
DEBUG 01-05 12:51:26.710158.710158 lmp.py:376]   Expert 20 |    121 | CPU
DEBUG 01-05 12:51:26.710377.710377 lmp.py:376]   Expert 51 |    123 | CPU
DEBUG 01-05 12:51:26.710835.710835 lmp.py:376]   Expert 17 |    131 | CPU
DEBUG 01-05 12:51:26.710054.710054 lmp.py:376]   Expert 41 |    133 | CPU
DEBUG 01-05 12:51:26.710273.710273 lmp.py:376]   Expert 54 |    139 | CPU
DEBUG 01-05 12:51:26.710777.710777 lmp.py:376]   Expert 21 |    146 | CPU
DEBUG 01-05 12:51:26.710281.710281 lmp.py:376]   Expert 12 |    151 | CPU
DEBUG 01-05 12:51:26.710785.710785 lmp.py:376]   Expert 57 |    174 | CPU
DEBUG 01-05 12:51:26.710812.710812 lmp.py:376]   Expert 45 |    178 | CPU
DEBUG 01-05 12:51:26.710078.710078 lmp.py:376]   Expert 42 |    181 | CPU
DEBUG 01-05 12:51:26.710820.710820 lmp.py:376]   Expert 52 |    182 | GPU
DEBUG 01-05 12:51:26.710040.710040 lmp.py:376]   Expert 62 |    190 | GPU
DEBUG 01-05 12:51:26.710497.710497 lmp.py:376]   Expert  6 |    194 | GPU
DEBUG 01-05 12:51:26.710955.710955 lmp.py:376]   Expert 31 |    197 | GPU
DEBUG 01-05 12:51:26.710174.710174 lmp.py:376]   Expert  3 |    215 | GPU
DEBUG 01-05 12:51:26.710917.710917 lmp.py:376]   Expert 13 |    215 | GPU
DEBUG 01-05 12:51:26.710182.710182 lmp.py:376]   Expert 26 |    221 | GPU
DEBUG 01-05 12:51:26.710448.710448 lmp.py:376]   Expert 30 |    221 | GPU
DEBUG 01-05 12:51:26.710713.710713 lmp.py:376]   Expert 11 |    225 | GPU
DEBUG 01-05 12:51:26.710217.710217 lmp.py:376]   Expert 14 |    228 | GPU
DEBUG 01-05 12:51:26.710721.710721 lmp.py:376]   Expert 46 |    229 | GPU
DEBUG 01-05 12:51:26.710225.710225 lmp.py:376]   Expert 19 |    234 | GPU
DEBUG 01-05 12:51:26.710206.710206 lmp.py:376]   Expert 36 |    234 | GPU
DEBUG 01-05 12:51:26.710664.710664 lmp.py:376]   Expert 27 |    252 | GPU
DEBUG 01-05 12:51:26.710883.710883 lmp.py:376]   Expert  2 |    265 | GPU
DEBUG 01-05 12:51:26.710493.710493 lmp.py:376]   Expert 22 |    270 | GPU
DEBUG 01-05 12:51:26.710759.710759 lmp.py:376]   Expert  4 |    277 | GPU
DEBUG 01-05 12:51:26.710839.710839 lmp.py:376]   Expert  5 |    286 | GPU
DEBUG 01-05 12:51:26.710390.710390 lmp.py:376]   Expert 37 |    290 | GPU
DEBUG 01-05 12:51:26.710225.710225 lmp.py:376]   Expert 33 |    293 | GPU
DEBUG 01-05 12:51:26.710775.710775 lmp.py:376]   Expert 56 |    302 | GPU
DEBUG 01-05 12:51:26.710087.710087 lmp.py:376]   Expert  1 |    303 | GPU
DEBUG 01-05 12:51:26.710975.710975 lmp.py:376]   Expert 53 |    308 | GPU
DEBUG 01-05 12:51:26.710671.710671 lmp.py:376]   Expert 16 |    314 | GPU
DEBUG 01-05 12:51:26.710321.710321 lmp.py:376]   Expert 58 |    317 | GPU
DEBUG 01-05 12:51:26.710448.710448 lmp.py:376]   Expert 10 |    339 | GPU
DEBUG 01-05 12:51:26.710336.710336 lmp.py:376]   Expert 63 |    355 | GPU
DEBUG 01-05 12:51:26.711509.711509 lmp.py:376]   Expert 47 |    376 | GPU
DEBUG 01-05 12:51:26.711682.711682 lmp.py:376]   Expert 24 |    378 | GPU
DEBUG 01-05 12:51:26.711855.711855 lmp.py:376]   Expert 15 |    382 | GPU
DEBUG 01-05 12:51:26.711266.711266 lmp.py:376]   Expert 25 |    469 | GPU
DEBUG 01-05 12:51:26.711724.711724 lmp.py:376]   Expert  9 |    489 | GPU
DEBUG 01-05 12:51:26.711612.711612 lmp.py:377] 
DEBUG 01-05 12:51:26.711612.711612 lmp.py:377]   CPU total tokens: 3238 (26.4%)
DEBUG 01-05 12:51:26.711262.711262 lmp.py:378]   GPU total tokens: 9050 (73.6%)
DEBUG 01-05 12:51:26.711872.711872 cuda_h.py:19] end experts_map_get cost 0.0018661022186279297 seconds
DEBUG 01-05 12:51:26.711952.711952 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.711087.711087 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.711530.711530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.711064.711064 cuda_h.py:19] end allocate_cuda_memory cost 0.0002665519714355469 seconds
DEBUG 01-05 12:51:26.711212.711212 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.711213.711213 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.711626.711626 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.711667.711667 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 078d029b-5eb1-4a79-98fa-ae630fb22a8b
DEBUG 01-05 12:51:26.712711.712711 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.712911.712911 client.py:127] Model loaded
DEBUG 01-05 12:51:26.712721.712721 cuda_h.py:19] end sllm_worker_task cost 0.017799854278564453 seconds
DEBUG 01-05 12:51:26.712673.712673 mlpmodule.py:662]  experts func einsum cost 0.0821230411529541 s
INFO 01-05 12:51:26.713951.713951 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 078d029b-5eb1-4a79-98fa-ae630fb22a8b
DEBUG 01-05 12:51:26.713656.713656 cuda_h.py:19] end load_into_gpu_async cost 0.0019347667694091797 seconds
DEBUG 01-05 12:51:26.713127.713127 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.714994.714994 cuda_h.py:19] end restore_tensors2 cost 0.0007519721984863281 seconds
DEBUG 01-05 12:51:26.714367.714367 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033991336822509766 seconds
DEBUG 01-05 12:51:26.717615.717615 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006308794021606445 seconds
DEBUG 01-05 12:51:26.717551.717551 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.717090.717090 lmp.py:423] 
DEBUG 01-05 12:51:26.717090.717090 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.717324.717324 cuda_h.py:19] end cpu_experts_submit cost 0.00011992454528808594 seconds
DEBUG 01-05 12:51:26.717451.717451 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.723804.723804 mlpmodule.py:704] group tensors cost 0.0052661895751953125 s
DEBUG 01-05 12:51:26.725277.725277 mlpmodule.py:742] pad cost 0.0016078948974609375 s
DEBUG 01-05 12:51:26.725805.725805 mlpmodule.py:748] create cpu tensor cost 7.271766662597656e-05 s
DEBUG 01-05 12:51:26.725907.725907 mlpmodule.py:753] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-05 12:51:26.735329.735329 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.735240.735240 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.735050.735050 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 12:51:26.736010.736010 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.753629.753629 mlpmodule.py:793] group einsum cost 0.02781963348388672 s
DEBUG 01-05 12:51:26.754450.754450 mlpmodule.py:801] cpy2cputensor cost 0.0006296634674072266 s
DEBUG 01-05 12:51:26.758034.758034 cuda_h.py:19] end wait_cetm_experts cost 0.041085243225097656 seconds
DEBUG 01-05 12:51:26.759413.759413 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.759124.759124 cuda_h.py:19] end gpu_sexperts cost 0.0005950927734375 seconds
DEBUG 01-05 12:51:26.759055.759055 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.760370.760370 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-05 12:51:26.760901.760901 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.760518.760518 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 078d029b-5eb1-4a79-98fa-ae630fb22a8b
INFO 01-05 12:51:26.767376.767376 client.py:127] Model loaded
DEBUG 01-05 12:51:26.767241.767241 cuda_h.py:19] end wait_experts cost 0.007344722747802734 seconds
DEBUG 01-05 12:51:26.767209.767209 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.767078.767078 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.768805.768805 mlpmodule.py:531] gpu group tensors cost 0.0006458759307861328 s
DEBUG 01-05 12:51:26.770192.770192 mlpmodule.py:564] gpu pad cost 0.0017588138580322266 s
DEBUG 01-05 12:51:26.770143.770143 mlpmodule.py:582] gpu group einsum cost 0.0006158351898193359 s
DEBUG 01-05 12:51:26.773005.773005 mlpmodule.py:611] gpu experts func einsum cost 0.0060253143310546875 s
DEBUG 01-05 12:51:26.773228.773228 cuda_h.py:19] end gpu_experts cost 0.00625920295715332 seconds
DEBUG 01-05 12:51:26.773244.773244 cuda_h.py:19] end layer_moe_generate_14 cost 0.06557679176330566 seconds
DEBUG 01-05 12:51:26.774204.774204 lmp.py:217] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 12:51:26.774867.774867 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 12:51:26.774894.774894 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 12:51:26.774796.774796 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 12:51:26.774209.774209 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 12:51:26.774124.774124 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.748603820800781e-05 seconds
DEBUG 01-05 12:51:26.774058.774058 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.774724.774724 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.774444.774444 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.774426.774426 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.774577.774577 cuda_h.py:19] end allocate_cuda_memory cost 0.0003204345703125 seconds
DEBUG 01-05 12:51:26.775521.775521 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.775999.775999 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.775914.775914 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.775664.775664 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e635e07a-090b-4c45-a663-28b0819cb2bb
DEBUG 01-05 12:51:26.775017.775017 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.775717.775717 mlpmodule.py:662]  experts func einsum cost 0.05731368064880371 s
DEBUG 01-05 12:51:26.775720.775720 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.776544.776544 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e635e07a-090b-4c45-a663-28b0819cb2bb
DEBUG 01-05 12:51:26.776287.776287 cuda_h.py:19] end load_into_gpu_async cost 0.0010890960693359375 seconds
DEBUG 01-05 12:51:26.776275.776275 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.776828.776828 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-05 12:51:26.776153.776153 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001750946044921875 seconds
INFO 01-05 12:51:26.776497.776497 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e635e07a-090b-4c45-a663-28b0819cb2bb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.779405.779405 cuda_h.py:19] end self_attn cost 0.0039577484130859375 seconds
DEBUG 01-05 12:51:26.780290.780290 cuda_h.py:19] end iln_self_attn_paln cost 0.0056879520416259766 seconds
DEBUG 01-05 12:51:26.780510.780510 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 12:51:26.780034.780034 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.780435.780435 cuda_h.py:19] end gate cost 0.0006482601165771484 seconds
DEBUG 01-05 12:51:26.780357.780357 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.781287.781287 lmp.py:365] 
DEBUG 01-05 12:51:26.781287.781287 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.781090.781090 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.781455.781455 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.781528.781528 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.781694.781694 lmp.py:369] 
DEBUG 01-05 12:51:26.781694.781694 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.781099.781099 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.781987.781987 lmp.py:376]   Expert 63 |     12 | CPU
DEBUG 01-05 12:51:26.781153.781153 lmp.py:376]   Expert 34 |     56 | CPU
DEBUG 01-05 12:51:26.781366.781366 lmp.py:376]   Expert 37 |     56 | CPU
DEBUG 01-05 12:51:26.781340.781340 lmp.py:376]   Expert 42 |     60 | CPU
DEBUG 01-05 12:51:26.781837.781837 lmp.py:376]   Expert  4 |     61 | CPU
DEBUG 01-05 12:51:26.781573.781573 lmp.py:376]   Expert 48 |     69 | CPU
DEBUG 01-05 12:51:26.781070.781070 lmp.py:376]   Expert 22 |     78 | CPU
DEBUG 01-05 12:51:26.781474.781474 lmp.py:376]   Expert 28 |     79 | CPU
DEBUG 01-05 12:51:26.781164.781164 lmp.py:376]   Expert 57 |     81 | CPU
DEBUG 01-05 12:51:26.781615.781615 lmp.py:376]   Expert 51 |     83 | CPU
DEBUG 01-05 12:51:26.781734.781734 lmp.py:376]   Expert 53 |     84 | CPU
DEBUG 01-05 12:51:26.781139.781139 lmp.py:376]   Expert 15 |     87 | CPU
DEBUG 01-05 12:51:26.781828.781828 lmp.py:376]   Expert  5 |     90 | CPU
DEBUG 01-05 12:51:26.781279.781279 lmp.py:376]   Expert 40 |     93 | CPU
DEBUG 01-05 12:51:26.781492.781492 lmp.py:376]   Expert 43 |     98 | CPU
DEBUG 01-05 12:51:26.781181.781181 lmp.py:376]   Expert 41 |     99 | CPU
DEBUG 01-05 12:51:26.781632.781632 lmp.py:376]   Expert  6 |    117 | CPU
DEBUG 01-05 12:51:26.781083.781083 lmp.py:376]   Expert  7 |    122 | CPU
DEBUG 01-05 12:51:26.781295.781295 lmp.py:376]   Expert 32 |    127 | CPU
DEBUG 01-05 12:51:26.781508.781508 lmp.py:376]   Expert 55 |    129 | CPU
DEBUG 01-05 12:51:26.781912.781912 lmp.py:376]   Expert 29 |    130 | CPU
DEBUG 01-05 12:51:26.781840.781840 lmp.py:376]   Expert 56 |    140 | CPU
DEBUG 01-05 12:51:26.781768.781768 lmp.py:376]   Expert 44 |    150 | CPU
DEBUG 01-05 12:51:26.781457.781457 lmp.py:376]   Expert 52 |    150 | CPU
DEBUG 01-05 12:51:26.781146.781146 lmp.py:376]   Expert 14 |    156 | CPU
DEBUG 01-05 12:51:26.781597.781597 lmp.py:376]   Expert 61 |    156 | CPU
DEBUG 01-05 12:51:26.781048.781048 lmp.py:376]   Expert  2 |    157 | CPU
DEBUG 01-05 12:51:26.781022.781022 lmp.py:376]   Expert 25 |    158 | CPU
DEBUG 01-05 12:51:26.781711.781711 lmp.py:376]   Expert 12 |    174 | CPU
DEBUG 01-05 12:51:26.781162.781162 lmp.py:376]   Expert 33 |    175 | CPU
DEBUG 01-05 12:51:26.781613.781613 lmp.py:376]   Expert 54 |    181 | CPU
DEBUG 01-05 12:51:26.781587.781587 lmp.py:376]   Expert 50 |    192 | CPU
DEBUG 01-05 12:51:26.781038.781038 lmp.py:376]   Expert 35 |    193 | GPU
DEBUG 01-05 12:51:26.781443.781443 lmp.py:376]   Expert 39 |    198 | GPU
DEBUG 01-05 12:51:26.781370.781370 lmp.py:376]   Expert 62 |    198 | GPU
DEBUG 01-05 12:51:26.781298.781298 lmp.py:376]   Expert 11 |    211 | GPU
DEBUG 01-05 12:51:26.781226.781226 lmp.py:376]   Expert 31 |    213 | GPU
DEBUG 01-05 12:51:26.781630.781630 lmp.py:376]   Expert 20 |    219 | GPU
DEBUG 01-05 12:51:26.781081.781081 lmp.py:376]   Expert 58 |    222 | GPU
DEBUG 01-05 12:51:26.781532.781532 lmp.py:376]   Expert 45 |    225 | GPU
DEBUG 01-05 12:51:26.781983.781983 lmp.py:376]   Expert 47 |    225 | GPU
DEBUG 01-05 12:51:26.781672.781672 lmp.py:376]   Expert 23 |    230 | GPU
DEBUG 01-05 12:51:26.781885.781885 lmp.py:376]   Expert 10 |    233 | GPU
DEBUG 01-05 12:51:26.781097.781097 lmp.py:376]   Expert 59 |    238 | GPU
DEBUG 01-05 12:51:26.782025.782025 lmp.py:376]   Expert  1 |    239 | GPU
DEBUG 01-05 12:51:26.782476.782476 lmp.py:376]   Expert 13 |    240 | GPU
DEBUG 01-05 12:51:26.782688.782688 lmp.py:376]   Expert 24 |    246 | GPU
DEBUG 01-05 12:51:26.782377.782377 lmp.py:376]   Expert  9 |    248 | GPU
DEBUG 01-05 12:51:26.782305.782305 lmp.py:376]   Expert  0 |    253 | GPU
DEBUG 01-05 12:51:26.782471.782471 lmp.py:376]   Expert 36 |    255 | GPU
DEBUG 01-05 12:51:26.782399.782399 lmp.py:376]   Expert 38 |    260 | GPU
DEBUG 01-05 12:51:26.782565.782565 lmp.py:376]   Expert 16 |    266 | GPU
DEBUG 01-05 12:51:26.782254.782254 lmp.py:376]   Expert 18 |    267 | GPU
DEBUG 01-05 12:51:26.782467.782467 lmp.py:376]   Expert 46 |    294 | GPU
DEBUG 01-05 12:51:26.782918.782918 lmp.py:376]   Expert 60 |    302 | GPU
DEBUG 01-05 12:51:26.782130.782130 lmp.py:376]   Expert 49 |    312 | GPU
DEBUG 01-05 12:51:26.782343.782343 lmp.py:376]   Expert  3 |    314 | GPU
DEBUG 01-05 12:51:26.782555.782555 lmp.py:376]   Expert 19 |    315 | GPU
DEBUG 01-05 12:51:26.782768.782768 lmp.py:376]   Expert 30 |    316 | GPU
DEBUG 01-05 12:51:26.782742.782742 lmp.py:376]   Expert 26 |    335 | GPU
DEBUG 01-05 12:51:26.782954.782954 lmp.py:376]   Expert 21 |    340 | GPU
DEBUG 01-05 12:51:26.782643.782643 lmp.py:376]   Expert 27 |    348 | GPU
DEBUG 01-05 12:51:26.782618.782618 lmp.py:376]   Expert 17 |    377 | GPU
DEBUG 01-05 12:51:26.782545.782545 lmp.py:376]   Expert  8 |    556 | GPU
DEBUG 01-05 12:51:26.782188.782188 lmp.py:377] 
DEBUG 01-05 12:51:26.782188.782188 lmp.py:377]   CPU total tokens: 3600 (29.3%)
DEBUG 01-05 12:51:26.782308.782308 lmp.py:378]   GPU total tokens: 8688 (70.7%)
DEBUG 01-05 12:51:26.782243.782243 cuda_h.py:19] end experts_map_get cost 0.00150299072265625 seconds
DEBUG 01-05 12:51:26.782124.782124 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.782861.782861 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.782243.782243 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.783429.783429 cuda_h.py:19] end allocate_cuda_memory cost 0.0003840923309326172 seconds
DEBUG 01-05 12:51:26.783385.783385 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.783049.783049 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.783003.783003 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.783369.783369 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01e90e4f-7571-41b5-a9b9-7ae44f49099f
DEBUG 01-05 12:51:26.783159.783159 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.783675.783675 client.py:127] Model loaded
DEBUG 01-05 12:51:26.783418.783418 cuda_h.py:19] end sllm_worker_task cost 0.009118080139160156 seconds
INFO 01-05 12:51:26.784884.784884 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01e90e4f-7571-41b5-a9b9-7ae44f49099f
DEBUG 01-05 12:51:26.784787.784787 cuda_h.py:19] end load_into_gpu_async cost 0.0012722015380859375 seconds
DEBUG 01-05 12:51:26.784159.784159 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.784835.784835 cuda_h.py:19] end restore_tensors2 cost 0.00040149688720703125 seconds
DEBUG 01-05 12:51:26.784003.784003 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002434253692626953 seconds
DEBUG 01-05 12:51:26.787092.787092 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00514531135559082 seconds
DEBUG 01-05 12:51:26.787882.787882 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.787388.787388 lmp.py:423] 
DEBUG 01-05 12:51:26.787388.787388 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.787476.787476 cuda_h.py:19] end cpu_experts_submit cost 0.00011348724365234375 seconds
DEBUG 01-05 12:51:26.787841.787841 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.803971.803971 mlpmodule.py:704] group tensors cost 0.015651464462280273 s
DEBUG 01-05 12:51:26.806069.806069 mlpmodule.py:742] pad cost 0.0018155574798583984 s
DEBUG 01-05 12:51:26.806093.806093 mlpmodule.py:748] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-05 12:51:26.806626.806626 mlpmodule.py:753] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-05 12:51:26.816466.816466 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.816853.816853 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.816557.816557 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 12:51:26.816547.816547 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.834989.834989 mlpmodule.py:793] group einsum cost 0.0275876522064209 s
DEBUG 01-05 12:51:26.835593.835593 mlpmodule.py:801] cpy2cputensor cost 0.0006806850433349609 s
DEBUG 01-05 12:51:26.839474.839474 cuda_h.py:19] end wait_cetm_experts cost 0.05165696144104004 seconds
DEBUG 01-05 12:51:26.839275.839275 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.840468.840468 cuda_h.py:19] end gpu_sexperts cost 0.0005888938903808594 seconds
DEBUG 01-05 12:51:26.840067.840067 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.840361.840361 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.457069396972656e-05 seconds
DEBUG 01-05 12:51:26.840117.840117 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.840780.840780 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01e90e4f-7571-41b5-a9b9-7ae44f49099f
INFO 01-05 12:51:26.841476.841476 client.py:127] Model loaded
DEBUG 01-05 12:51:26.841578.841578 cuda_h.py:19] end wait_experts cost 0.0010712146759033203 seconds
DEBUG 01-05 12:51:26.841811.841811 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.841852.841852 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.842936.842936 mlpmodule.py:531] gpu group tensors cost 0.0006401538848876953 s
DEBUG 01-05 12:51:26.844050.844050 mlpmodule.py:564] gpu pad cost 0.0017838478088378906 s
DEBUG 01-05 12:51:26.845731.845731 mlpmodule.py:582] gpu group einsum cost 0.0006515979766845703 s
DEBUG 01-05 12:51:26.848857.848857 mlpmodule.py:611] gpu experts func einsum cost 0.006795644760131836 s
DEBUG 01-05 12:51:26.848716.848716 cuda_h.py:19] end gpu_experts cost 0.007028818130493164 seconds
DEBUG 01-05 12:51:26.848507.848507 cuda_h.py:19] end layer_moe_generate_15 cost 0.06871628761291504 seconds
DEBUG 01-05 12:51:26.849111.849111 lmp.py:217] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 12:51:26.849258.849258 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 12:51:26.849484.849484 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 12:51:26.849770.849770 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 12:51:26.849143.849143 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.504753112792969e-05 seconds
DEBUG 01-05 12:51:26.849614.849614 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.937980651855469e-05 seconds
DEBUG 01-05 12:51:26.849610.849610 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.849110.849110 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.849007.849007 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.849740.849740 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.850612.850612 cuda_h.py:19] end allocate_cuda_memory cost 0.0004963874816894531 seconds
DEBUG 01-05 12:51:26.850383.850383 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.850053.850053 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.850074.850074 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.850069.850069 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de974416-b273-44d4-805c-f109faca5831
DEBUG 01-05 12:51:26.850807.850807 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.850761.850761 cuda_h.py:10] start self_attn
INFO 01-05 12:51:26.851247.851247 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de974416-b273-44d4-805c-f109faca5831
DEBUG 01-05 12:51:26.851958.851958 cuda_h.py:19] end load_into_gpu_async cost 0.0011212825775146484 seconds
DEBUG 01-05 12:51:26.851668.851668 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.851989.851989 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-05 12:51:26.851751.851751 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019626617431640625 seconds
INFO 01-05 12:51:26.852960.852960 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de974416-b273-44d4-805c-f109faca5831
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.855960.855960 cuda_h.py:19] end self_attn cost 0.004288911819458008 seconds
DEBUG 01-05 12:51:26.855375.855375 cuda_h.py:19] end iln_self_attn_paln cost 0.0059626102447509766 seconds
DEBUG 01-05 12:51:26.855688.855688 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 12:51:26.855689.855689 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.856110.856110 mlpmodule.py:662]  experts func einsum cost 0.06828904151916504 s
DEBUG 01-05 12:51:26.856718.856718 cuda_h.py:19] end gate cost 0.0008084774017333984 seconds
DEBUG 01-05 12:51:26.856642.856642 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.856600.856600 lmp.py:365] 
DEBUG 01-05 12:51:26.856600.856600 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.856462.856462 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.857450.857450 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.857292.857292 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.857034.857034 lmp.py:369] 
DEBUG 01-05 12:51:26.857034.857034 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.857969.857969 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.857148.857148 lmp.py:376]   Expert 58 |     19 | CPU
DEBUG 01-05 12:51:26.857368.857368 lmp.py:376]   Expert 43 |     63 | CPU
DEBUG 01-05 12:51:26.857872.857872 lmp.py:376]   Expert 14 |     64 | CPU
DEBUG 01-05 12:51:26.857137.857137 lmp.py:376]   Expert 13 |     77 | CPU
DEBUG 01-05 12:51:26.857164.857164 lmp.py:376]   Expert 54 |     80 | CPU
DEBUG 01-05 12:51:26.857476.857476 lmp.py:376]   Expert 45 |     85 | CPU
DEBUG 01-05 12:51:26.857841.857841 lmp.py:376]   Expert 11 |     93 | CPU
DEBUG 01-05 12:51:26.857822.857822 lmp.py:376]   Expert 39 |     97 | CPU
DEBUG 01-05 12:51:26.857088.857088 lmp.py:376]   Expert 59 |    102 | CPU
DEBUG 01-05 12:51:26.857592.857592 lmp.py:376]   Expert 60 |    103 | CPU
DEBUG 01-05 12:51:26.857096.857096 lmp.py:376]   Expert 18 |    113 | CPU
DEBUG 01-05 12:51:26.857123.857123 lmp.py:376]   Expert 28 |    115 | CPU
DEBUG 01-05 12:51:26.857912.857912 lmp.py:376]   Expert  6 |    116 | CPU
DEBUG 01-05 12:51:26.857462.857462 lmp.py:376]   Expert 34 |    116 | CPU
DEBUG 01-05 12:51:26.857489.857489 lmp.py:376]   Expert 61 |    119 | CPU
DEBUG 01-05 12:51:26.857801.857801 lmp.py:376]   Expert 57 |    122 | CPU
DEBUG 01-05 12:51:26.857590.857590 lmp.py:376]   Expert 25 |    127 | CPU
DEBUG 01-05 12:51:26.857094.857094 lmp.py:376]   Expert 49 |    128 | CPU
DEBUG 01-05 12:51:26.857598.857598 lmp.py:376]   Expert  0 |    129 | CPU
DEBUG 01-05 12:51:26.857102.857102 lmp.py:376]   Expert 51 |    133 | CPU
DEBUG 01-05 12:51:26.857367.857367 lmp.py:376]   Expert 62 |    135 | CPU
DEBUG 01-05 12:51:26.857394.857394 lmp.py:376]   Expert 41 |    140 | CPU
DEBUG 01-05 12:51:26.857905.857905 lmp.py:376]   Expert 32 |    143 | CPU
DEBUG 01-05 12:51:26.857502.857502 lmp.py:376]   Expert 50 |    143 | CPU
DEBUG 01-05 12:51:26.857205.857205 lmp.py:376]   Expert 30 |    148 | CPU
DEBUG 01-05 12:51:26.857940.857940 lmp.py:376]   Expert 38 |    149 | CPU
DEBUG 01-05 12:51:26.857676.857676 lmp.py:376]   Expert 35 |    150 | CPU
DEBUG 01-05 12:51:26.857935.857935 lmp.py:376]   Expert 12 |    151 | CPU
DEBUG 01-05 12:51:26.857147.857147 lmp.py:376]   Expert 15 |    160 | CPU
DEBUG 01-05 12:51:26.857645.857645 lmp.py:376]   Expert 37 |    167 | CPU
DEBUG 01-05 12:51:26.857380.857380 lmp.py:376]   Expert 31 |    172 | CPU
DEBUG 01-05 12:51:26.857639.857639 lmp.py:376]   Expert 63 |    180 | CPU
DEBUG 01-05 12:51:26.857136.857136 lmp.py:376]   Expert 48 |    185 | GPU
DEBUG 01-05 12:51:26.857633.857633 lmp.py:376]   Expert 56 |    185 | GPU
DEBUG 01-05 12:51:26.857892.857892 lmp.py:376]   Expert 26 |    186 | GPU
DEBUG 01-05 12:51:26.857436.857436 lmp.py:376]   Expert 42 |    186 | GPU
DEBUG 01-05 12:51:26.857218.857218 lmp.py:376]   Expert 10 |    198 | GPU
DEBUG 01-05 12:51:26.857000.857000 lmp.py:376]   Expert 44 |    202 | GPU
DEBUG 01-05 12:51:26.857258.857258 lmp.py:376]   Expert 55 |    207 | GPU
DEBUG 01-05 12:51:26.857802.857802 lmp.py:376]   Expert 40 |    209 | GPU
DEBUG 01-05 12:51:26.857822.857822 lmp.py:376]   Expert  3 |    211 | GPU
DEBUG 01-05 12:51:26.857319.857319 lmp.py:376]   Expert 21 |    212 | GPU
DEBUG 01-05 12:51:26.857817.857817 lmp.py:376]   Expert 33 |    220 | GPU
DEBUG 01-05 12:51:26.857314.857314 lmp.py:376]   Expert 16 |    225 | GPU
DEBUG 01-05 12:51:26.857573.857573 lmp.py:376]   Expert  1 |    231 | GPU
DEBUG 01-05 12:51:26.857547.857547 lmp.py:376]   Expert  9 |    233 | GPU
DEBUG 01-05 12:51:26.857329.857329 lmp.py:376]   Expert 47 |    234 | GPU
DEBUG 01-05 12:51:26.857111.857111 lmp.py:376]   Expert 19 |    249 | GPU
DEBUG 01-05 12:51:26.857893.857893 lmp.py:376]   Expert 36 |    249 | GPU
DEBUG 01-05 12:51:26.857913.857913 lmp.py:376]   Expert 46 |    249 | GPU
DEBUG 01-05 12:51:26.857695.857695 lmp.py:376]   Expert  2 |    256 | GPU
DEBUG 01-05 12:51:26.858238.858238 lmp.py:376]   Expert 24 |    261 | GPU
DEBUG 01-05 12:51:26.858782.858782 lmp.py:376]   Expert 22 |    263 | GPU
DEBUG 01-05 12:51:26.858564.858564 lmp.py:376]   Expert 20 |    272 | GPU
DEBUG 01-05 12:51:26.858107.858107 lmp.py:376]   Expert  8 |    276 | GPU
DEBUG 01-05 12:51:26.858128.858128 lmp.py:376]   Expert 53 |    278 | GPU
DEBUG 01-05 12:51:26.858102.858102 lmp.py:376]   Expert  7 |    285 | GPU
DEBUG 01-05 12:51:26.858122.858122 lmp.py:376]   Expert 29 |    303 | GPU
DEBUG 01-05 12:51:26.858143.858143 lmp.py:376]   Expert 23 |    353 | GPU
DEBUG 01-05 12:51:26.858878.858878 lmp.py:376]   Expert  4 |    354 | GPU
DEBUG 01-05 12:51:26.858660.858660 lmp.py:376]   Expert 17 |    375 | GPU
DEBUG 01-05 12:51:26.858442.858442 lmp.py:376]   Expert 27 |    428 | GPU
DEBUG 01-05 12:51:26.858224.858224 lmp.py:376]   Expert 52 |    435 | GPU
DEBUG 01-05 12:51:26.858006.858006 lmp.py:376]   Expert  5 |    439 | GPU
DEBUG 01-05 12:51:26.858742.858742 lmp.py:377] 
DEBUG 01-05 12:51:26.858742.858742 lmp.py:377]   CPU total tokens: 3839 (31.2%)
DEBUG 01-05 12:51:26.858477.858477 lmp.py:378]   GPU total tokens: 8449 (68.8%)
DEBUG 01-05 12:51:26.858458.858458 cuda_h.py:19] end experts_map_get cost 0.0015878677368164062 seconds
DEBUG 01-05 12:51:26.858671.858671 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.858162.858162 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.858472.858472 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.858999.858999 cuda_h.py:19] end allocate_cuda_memory cost 0.00027370452880859375 seconds
INFO 01-05 12:51:26.858606.858606 client.py:127] Model loaded
DEBUG 01-05 12:51:26.858291.858291 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.859942.859942 cuda_h.py:19] end sllm_worker_task cost 0.00954747200012207 seconds
DEBUG 01-05 12:51:26.859182.859182 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.859940.859940 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.859213.859213 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95329937-c830-41c8-a7c2-32468f1a26b8
DEBUG 01-05 12:51:26.859878.859878 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.860775.860775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95329937-c830-41c8-a7c2-32468f1a26b8
DEBUG 01-05 12:51:26.860803.860803 cuda_h.py:19] end load_into_gpu_async cost 0.0015490055084228516 seconds
DEBUG 01-05 12:51:26.860791.860791 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.861660.861660 cuda_h.py:19] end restore_tensors2 cost 0.0004038810729980469 seconds
DEBUG 01-05 12:51:26.861019.861019 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028204917907714844 seconds
DEBUG 01-05 12:51:26.863750.863750 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0055103302001953125 seconds
DEBUG 01-05 12:51:26.863487.863487 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.863542.863542 lmp.py:423] 
DEBUG 01-05 12:51:26.863542.863542 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.863008.863008 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-05 12:51:26.864181.864181 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.873406.873406 mlpmodule.py:704] group tensors cost 0.0093994140625 s
DEBUG 01-05 12:51:26.875166.875166 mlpmodule.py:742] pad cost 0.001468658447265625 s
DEBUG 01-05 12:51:26.875971.875971 mlpmodule.py:748] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-05 12:51:26.875629.875629 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-05 12:51:26.885410.885410 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.885141.885141 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.886475.886475 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 12:51:26.886140.886140 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.902043.902043 mlpmodule.py:793] group einsum cost 0.02615833282470703 s
DEBUG 01-05 12:51:26.903072.903072 mlpmodule.py:801] cpy2cputensor cost 0.0007038116455078125 s
DEBUG 01-05 12:51:26.907915.907915 cuda_h.py:19] end wait_cetm_experts cost 0.0434112548828125 seconds
DEBUG 01-05 12:51:26.907477.907477 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.908717.908717 cuda_h.py:19] end gpu_sexperts cost 0.0005888938903808594 seconds
DEBUG 01-05 12:51:26.908659.908659 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.908258.908258 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.316734313964844e-05 seconds
DEBUG 01-05 12:51:26.908875.908875 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.908446.908446 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95329937-c830-41c8-a7c2-32468f1a26b8
INFO 01-05 12:51:26.914655.914655 client.py:127] Model loaded
DEBUG 01-05 12:51:26.915850.915850 cuda_h.py:19] end wait_experts cost 0.006514072418212891 seconds
DEBUG 01-05 12:51:26.915937.915937 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.915169.915169 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.915830.915830 mlpmodule.py:531] gpu group tensors cost 0.0006461143493652344 s
DEBUG 01-05 12:51:26.917679.917679 mlpmodule.py:564] gpu pad cost 0.001744985580444336 s
DEBUG 01-05 12:51:26.918473.918473 mlpmodule.py:582] gpu group einsum cost 0.0005135536193847656 s
DEBUG 01-05 12:51:26.921854.921854 mlpmodule.py:611] gpu experts func einsum cost 0.005930900573730469 s
DEBUG 01-05 12:51:26.921546.921546 cuda_h.py:19] end gpu_experts cost 0.006109952926635742 seconds
DEBUG 01-05 12:51:26.921747.921747 cuda_h.py:19] end layer_moe_generate_16 cost 0.06563997268676758 seconds
DEBUG 01-05 12:51:26.921138.921138 lmp.py:217] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 12:51:26.921086.921086 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 12:51:26.921113.921113 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 12:51:26.921438.921438 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 12:51:26.921275.921275 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.9325485229492188e-05 seconds
DEBUG 01-05 12:51:26.921329.921329 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.462501525878906e-05 seconds
DEBUG 01-05 12:51:26.921972.921972 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:26.921398.921398 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:26.921343.921343 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.921762.921762 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.923190.923190 cuda_h.py:19] end allocate_cuda_memory cost 0.001451730728149414 seconds
DEBUG 01-05 12:51:26.923692.923692 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.923252.923252 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.923062.923062 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.923527.923527 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc31c8a9-2708-4ab8-985d-0c43af49897e
DEBUG 01-05 12:51:26.923450.923450 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:26.924392.924392 mlpmodule.py:662]  experts func einsum cost 0.05983591079711914 s
DEBUG 01-05 12:51:26.924530.924530 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:26.927198.927198 cuda_h.py:19] end self_attn cost 0.0024292469024658203 seconds
DEBUG 01-05 12:51:26.927870.927870 cuda_h.py:19] end iln_self_attn_paln cost 0.005616426467895508 seconds
DEBUG 01-05 12:51:26.927567.927567 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 12:51:26.927568.927568 cuda_h.py:10] start gate
DEBUG 01-05 12:51:26.927781.927781 cuda_h.py:19] end gate cost 0.000579833984375 seconds
DEBUG 01-05 12:51:26.928941.928941 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:26.928256.928256 lmp.py:365] 
DEBUG 01-05 12:51:26.928256.928256 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:26.928085.928085 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:26.928504.928504 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:26.928584.928584 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:26.928512.928512 lmp.py:369] 
DEBUG 01-05 12:51:26.928512.928512 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:26.928453.928453 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:26.928295.928295 lmp.py:376]   Expert 39 |     42 | CPU
DEBUG 01-05 12:51:26.928415.928415 lmp.py:376]   Expert 28 |     53 | CPU
DEBUG 01-05 12:51:26.928104.928104 lmp.py:376]   Expert 14 |     62 | CPU
DEBUG 01-05 12:51:26.928555.928555 lmp.py:376]   Expert 47 |     63 | CPU
DEBUG 01-05 12:51:26.928767.928767 lmp.py:376]   Expert 36 |     66 | CPU
DEBUG 01-05 12:51:26.928741.928741 lmp.py:376]   Expert  1 |     74 | CPU
DEBUG 01-05 12:51:26.928954.928954 lmp.py:376]   Expert  8 |     84 | CPU
DEBUG 01-05 12:51:26.928928.928928 lmp.py:376]   Expert 27 |     87 | CPU
DEBUG 01-05 12:51:26.928663.928663 lmp.py:376]   Expert  7 |     88 | CPU
DEBUG 01-05 12:51:26.928637.928637 lmp.py:376]   Expert 40 |     91 | CPU
DEBUG 01-05 12:51:26.928373.928373 lmp.py:376]   Expert 52 |     94 | CPU
DEBUG 01-05 12:51:26.928109.928109 lmp.py:376]   Expert 25 |    100 | CPU
DEBUG 01-05 12:51:26.928560.928560 lmp.py:376]   Expert  3 |    113 | CPU
DEBUG 01-05 12:51:26.928772.928772 lmp.py:376]   Expert 54 |    116 | CPU
DEBUG 01-05 12:51:26.928985.928985 lmp.py:376]   Expert 31 |    123 | CPU
DEBUG 01-05 12:51:26.928959.928959 lmp.py:376]   Expert 60 |    127 | CPU
DEBUG 01-05 12:51:26.928933.928933 lmp.py:376]   Expert 30 |    130 | CPU
DEBUG 01-05 12:51:26.928907.928907 lmp.py:376]   Expert 46 |    137 | CPU
DEBUG 01-05 12:51:26.928404.928404 lmp.py:376]   Expert 50 |    140 | CPU
DEBUG 01-05 12:51:26.928901.928901 lmp.py:376]   Expert 63 |    143 | CPU
DEBUG 01-05 12:51:26.928637.928637 lmp.py:376]   Expert 24 |    144 | CPU
DEBUG 01-05 12:51:26.928134.928134 lmp.py:376]   Expert 59 |    145 | CPU
DEBUG 01-05 12:51:26.928870.928870 lmp.py:376]   Expert  6 |    150 | CPU
DEBUG 01-05 12:51:26.928605.928605 lmp.py:376]   Expert 56 |    151 | CPU
DEBUG 01-05 12:51:26.928102.928102 lmp.py:376]   Expert 58 |    152 | CPU
DEBUG 01-05 12:51:26.928076.928076 lmp.py:376]   Expert 61 |    154 | CPU
DEBUG 01-05 12:51:26.928050.928050 lmp.py:376]   Expert  2 |    159 | CPU
DEBUG 01-05 12:51:26.928786.928786 lmp.py:376]   Expert 16 |    167 | CPU
DEBUG 01-05 12:51:26.928283.928283 lmp.py:376]   Expert 53 |    167 | CPU
DEBUG 01-05 12:51:26.928019.928019 lmp.py:376]   Expert 49 |    170 | CPU
DEBUG 01-05 12:51:26.928231.928231 lmp.py:376]   Expert 11 |    180 | CPU
DEBUG 01-05 12:51:26.929729.929729 lmp.py:376]   Expert 34 |    183 | CPU
DEBUG 01-05 12:51:26.929464.929464 lmp.py:376]   Expert 43 |    187 | GPU
DEBUG 01-05 12:51:26.929200.929200 lmp.py:376]   Expert 18 |    189 | GPU
DEBUG 01-05 12:51:26.929366.929366 lmp.py:376]   Expert 10 |    192 | GPU
DEBUG 01-05 12:51:26.929055.929055 lmp.py:376]   Expert 21 |    192 | GPU
DEBUG 01-05 12:51:26.929268.929268 lmp.py:376]   Expert 15 |    193 | GPU
DEBUG 01-05 12:51:26.929719.929719 lmp.py:376]   Expert 29 |    195 | GPU
DEBUG 01-05 12:51:26.929693.929693 lmp.py:376]   Expert 33 |    195 | GPU
DEBUG 01-05 12:51:26.929951.929951 lmp.py:376]   Expert 37 |    196 | GPU
DEBUG 01-05 12:51:26.929449.929449 lmp.py:376]   Expert 32 |    224 | GPU
DEBUG 01-05 12:51:26.929184.929184 lmp.py:376]   Expert 20 |    227 | GPU
DEBUG 01-05 12:51:26.929920.929920 lmp.py:376]   Expert 13 |    228 | GPU
DEBUG 01-05 12:51:26.929417.929417 lmp.py:376]   Expert 44 |    229 | GPU
DEBUG 01-05 12:51:26.929153.929153 lmp.py:376]   Expert 57 |    238 | GPU
DEBUG 01-05 12:51:26.929888.929888 lmp.py:376]   Expert 35 |    239 | GPU
DEBUG 01-05 12:51:26.929862.929862 lmp.py:376]   Expert  0 |    241 | GPU
DEBUG 01-05 12:51:26.929121.929121 lmp.py:376]   Expert 42 |    245 | GPU
DEBUG 01-05 12:51:26.929095.929095 lmp.py:376]   Expert  9 |    250 | GPU
DEBUG 01-05 12:51:26.929785.929785 lmp.py:376]   Expert 51 |    256 | GPU
DEBUG 01-05 12:51:26.929474.929474 lmp.py:376]   Expert 22 |    269 | GPU
DEBUG 01-05 12:51:26.929163.929163 lmp.py:376]   Expert  5 |    273 | GPU
DEBUG 01-05 12:51:26.929376.929376 lmp.py:376]   Expert 38 |    276 | GPU
DEBUG 01-05 12:51:26.929350.929350 lmp.py:376]   Expert 19 |    279 | GPU
DEBUG 01-05 12:51:26.929847.929847 lmp.py:376]   Expert 23 |    286 | GPU
DEBUG 01-05 12:51:26.929583.929583 lmp.py:376]   Expert 62 |    296 | GPU
DEBUG 01-05 12:51:26.929841.929841 lmp.py:376]   Expert 48 |    305 | GPU
DEBUG 01-05 12:51:26.929339.929339 lmp.py:376]   Expert  4 |    314 | GPU
DEBUG 01-05 12:51:26.929836.929836 lmp.py:376]   Expert 12 |    322 | GPU
DEBUG 01-05 12:51:26.929571.929571 lmp.py:376]   Expert 45 |    339 | GPU
DEBUG 01-05 12:51:26.929022.929022 lmp.py:376]   Expert 26 |    347 | GPU
DEBUG 01-05 12:51:26.929473.929473 lmp.py:376]   Expert 41 |    356 | GPU
DEBUG 01-05 12:51:26.929162.929162 lmp.py:376]   Expert 55 |    382 | GPU
DEBUG 01-05 12:51:26.929329.929329 lmp.py:376]   Expert 17 |    473 | GPU
DEBUG 01-05 12:51:26.929210.929210 lmp.py:377] 
DEBUG 01-05 12:51:26.929210.929210 lmp.py:377]   CPU total tokens: 3855 (31.4%)
DEBUG 01-05 12:51:26.929330.929330 lmp.py:378]   GPU total tokens: 8433 (68.6%)
DEBUG 01-05 12:51:26.929695.929695 cuda_h.py:19] end experts_map_get cost 0.0015108585357666016 seconds
DEBUG 01-05 12:51:26.929815.929815 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:26.929975.929975 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:26.929364.929364 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:26.930942.930942 cuda_h.py:19] end allocate_cuda_memory cost 0.0002167224884033203 seconds
DEBUG 01-05 12:51:26.930514.930514 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:26.930747.930747 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:26.930033.930033 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:26.930683.930683 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 31116aa8-fb39-4b48-af54-ebc6361d09a3
DEBUG 01-05 12:51:26.930903.930903 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:26.930316.930316 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc31c8a9-2708-4ab8-985d-0c43af49897e
DEBUG 01-05 12:51:26.930066.930066 cuda_h.py:19] end load_into_gpu_async cost 0.0008304119110107422 seconds
DEBUG 01-05 12:51:26.931723.931723 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.931130.931130 cuda_h.py:19] end restore_tensors2 cost 6.246566772460938e-05 seconds
DEBUG 01-05 12:51:26.931693.931693 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014557838439941406 seconds
INFO 01-05 12:51:26.931534.931534 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc31c8a9-2708-4ab8-985d-0c43af49897e
INFO 01-05 12:51:26.932153.932153 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 31116aa8-fb39-4b48-af54-ebc6361d09a3
DEBUG 01-05 12:51:26.932403.932403 cuda_h.py:19] end load_into_gpu_async cost 0.002572774887084961 seconds
DEBUG 01-05 12:51:26.932128.932128 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:26.933786.933786 cuda_h.py:19] end restore_tensors2 cost 0.0008089542388916016 seconds
DEBUG 01-05 12:51:26.933543.933543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004082441329956055 seconds
DEBUG 01-05 12:51:26.936058.936058 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006858110427856445 seconds
DEBUG 01-05 12:51:26.936862.936862 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:26.936778.936778 lmp.py:423] 
DEBUG 01-05 12:51:26.936778.936778 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:26.936681.936681 cuda_h.py:19] end cpu_experts_submit cost 0.00011873245239257812 seconds
DEBUG 01-05 12:51:26.936239.936239 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:26.955499.955499 mlpmodule.py:704] group tensors cost 0.0181732177734375 s
DEBUG 01-05 12:51:26.958536.958536 mlpmodule.py:742] pad cost 0.0019519329071044922 s
DEBUG 01-05 12:51:26.958753.958753 mlpmodule.py:748] create cpu tensor cost 5.125999450683594e-05 s
DEBUG 01-05 12:51:26.958544.958544 mlpmodule.py:753] move to cpu cost 4.696846008300781e-05 s
DEBUG 01-05 12:51:26.968483.968483 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:26.968029.968029 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:26.968257.968257 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 12:51:26.968624.968624 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:26.986337.986337 mlpmodule.py:793] group einsum cost 0.02775740623474121 s
DEBUG 01-05 12:51:26.986145.986145 mlpmodule.py:801] cpy2cputensor cost 0.0006496906280517578 s
DEBUG 01-05 12:51:26.991726.991726 cuda_h.py:19] end wait_cetm_experts cost 0.05463552474975586 seconds
DEBUG 01-05 12:51:26.991170.991170 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:26.992152.992152 cuda_h.py:19] end gpu_sexperts cost 0.0006077289581298828 seconds
DEBUG 01-05 12:51:26.992531.992531 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:26.992635.992635 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 6.723403930664062e-05 seconds
DEBUG 01-05 12:51:26.992682.992682 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:26.992299.992299 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 31116aa8-fb39-4b48-af54-ebc6361d09a3
INFO 01-05 12:51:26.992713.992713 client.py:127] Model loaded
DEBUG 01-05 12:51:26.992611.992611 cuda_h.py:19] end sllm_worker_task cost 0.07109332084655762 seconds
INFO 01-05 12:51:26.993274.993274 client.py:127] Model loaded
DEBUG 01-05 12:51:26.993316.993316 cuda_h.py:19] end wait_experts cost 0.0007162094116210938 seconds
DEBUG 01-05 12:51:26.993165.993165 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:26.993921.993921 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:26.994536.994536 mlpmodule.py:531] gpu group tensors cost 0.0006833076477050781 s
DEBUG 01-05 12:51:26.995976.995976 mlpmodule.py:564] gpu pad cost 0.0018143653869628906 s
DEBUG 01-05 12:51:26.996734.996734 mlpmodule.py:582] gpu group einsum cost 0.0005717277526855469 s
DEBUG 01-05 12:51:27.000442.000442 mlpmodule.py:611] gpu experts func einsum cost 0.006757259368896484 s
DEBUG 01-05 12:51:27.000956.000956 cuda_h.py:19] end gpu_experts cost 0.0069789886474609375 seconds
DEBUG 01-05 12:51:27.000370.000370 cuda_h.py:19] end layer_moe_generate_17 cost 0.0729973316192627 seconds
DEBUG 01-05 12:51:27.000901.000901 lmp.py:217] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 12:51:27.000379.000379 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 12:51:27.000652.000652 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 12:51:27.000984.000984 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 12:51:27.000211.000211 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.24249267578125e-05 seconds
DEBUG 01-05 12:51:27.000067.000067 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.914138793945312e-05 seconds
DEBUG 01-05 12:51:27.000862.000862 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.000885.000885 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.000059.000059 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.001180.001180 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.002102.002102 cuda_h.py:19] end allocate_cuda_memory cost 0.000993490219116211 seconds
DEBUG 01-05 12:51:27.002912.002912 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.002291.002291 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.002306.002306 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.002293.002293 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6eab6491-6ab6-4c11-8439-08c91a172df3
DEBUG 01-05 12:51:27.002548.002548 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.002506.002506 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.003160.003160 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6eab6491-6ab6-4c11-8439-08c91a172df3
DEBUG 01-05 12:51:27.003665.003665 cuda_h.py:19] end load_into_gpu_async cost 0.001468658447265625 seconds
DEBUG 01-05 12:51:27.003222.003222 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.003020.003020 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 12:51:27.003345.003345 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002779722213745117 seconds
INFO 01-05 12:51:27.004715.004715 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6eab6491-6ab6-4c11-8439-08c91a172df3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.006768.006768 cuda_h.py:19] end self_attn cost 0.0034177303314208984 seconds
DEBUG 01-05 12:51:27.006766.006766 cuda_h.py:19] end iln_self_attn_paln cost 0.005583524703979492 seconds
DEBUG 01-05 12:51:27.006748.006748 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 12:51:27.006510.006510 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.007957.007957 cuda_h.py:19] end gate cost 0.0006468296051025391 seconds
DEBUG 01-05 12:51:27.007833.007833 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.007055.007055 lmp.py:365] 
DEBUG 01-05 12:51:27.007055.007055 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.007049.007049 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.007938.007938 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.007726.007726 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.007992.007992 lmp.py:369] 
DEBUG 01-05 12:51:27.007992.007992 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.007257.007257 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.007576.007576 lmp.py:376]   Expert 35 |     49 | CPU
DEBUG 01-05 12:51:27.007934.007934 lmp.py:376]   Expert  0 |     54 | CPU
DEBUG 01-05 12:51:27.007293.007293 lmp.py:376]   Expert 53 |     65 | CPU
DEBUG 01-05 12:51:27.007459.007459 lmp.py:376]   Expert 58 |     65 | CPU
DEBUG 01-05 12:51:27.007340.007340 lmp.py:376]   Expert  3 |     70 | CPU
DEBUG 01-05 12:51:27.007745.007745 lmp.py:376]   Expert 54 |     70 | CPU
DEBUG 01-05 12:51:27.007865.007865 lmp.py:376]   Expert 19 |     73 | CPU
DEBUG 01-05 12:51:27.007031.007031 lmp.py:376]   Expert  6 |     79 | CPU
DEBUG 01-05 12:51:27.007581.007581 lmp.py:376]   Expert 34 |     87 | CPU
DEBUG 01-05 12:51:27.007462.007462 lmp.py:376]   Expert 12 |     88 | CPU
DEBUG 01-05 12:51:27.007821.007821 lmp.py:376]   Expert 41 |     88 | CPU
DEBUG 01-05 12:51:27.007225.007225 lmp.py:376]   Expert 20 |     90 | CPU
DEBUG 01-05 12:51:27.007345.007345 lmp.py:376]   Expert 37 |     91 | CPU
DEBUG 01-05 12:51:27.007034.007034 lmp.py:376]   Expert 40 |     97 | CPU
DEBUG 01-05 12:51:27.007916.007916 lmp.py:376]   Expert 60 |    102 | CPU
DEBUG 01-05 12:51:27.007605.007605 lmp.py:376]   Expert 43 |    107 | CPU
DEBUG 01-05 12:51:27.008248.008248 lmp.py:376]   Expert 63 |    107 | CPU
DEBUG 01-05 12:51:27.008176.008176 lmp.py:376]   Expert 48 |    109 | CPU
DEBUG 01-05 12:51:27.008819.008819 lmp.py:376]   Expert  8 |    113 | CPU
DEBUG 01-05 12:51:27.008508.008508 lmp.py:376]   Expert 30 |    116 | CPU
DEBUG 01-05 12:51:27.008105.008105 lmp.py:376]   Expert 46 |    118 | CPU
DEBUG 01-05 12:51:27.008509.008509 lmp.py:376]   Expert 44 |    122 | CPU
DEBUG 01-05 12:51:27.008106.008106 lmp.py:376]   Expert 32 |    123 | CPU
DEBUG 01-05 12:51:27.008749.008749 lmp.py:376]   Expert 13 |    132 | CPU
DEBUG 01-05 12:51:27.008153.008153 lmp.py:376]   Expert 45 |    132 | CPU
DEBUG 01-05 12:51:27.008081.008081 lmp.py:376]   Expert 17 |    137 | CPU
DEBUG 01-05 12:51:27.008486.008486 lmp.py:376]   Expert 29 |    140 | CPU
DEBUG 01-05 12:51:27.008413.008413 lmp.py:376]   Expert 33 |    141 | CPU
DEBUG 01-05 12:51:27.008579.008579 lmp.py:376]   Expert  5 |    143 | CPU
DEBUG 01-05 12:51:27.008507.008507 lmp.py:376]   Expert 55 |    144 | CPU
DEBUG 01-05 12:51:27.008912.008912 lmp.py:376]   Expert  4 |    149 | CPU
DEBUG 01-05 12:51:27.008601.008601 lmp.py:376]   Expert 25 |    163 | CPU
DEBUG 01-05 12:51:27.008244.008244 lmp.py:376]   Expert 27 |    172 | GPU
DEBUG 01-05 12:51:27.008649.008649 lmp.py:376]   Expert 11 |    173 | GPU
DEBUG 01-05 12:51:27.008768.008768 lmp.py:376]   Expert 18 |    174 | GPU
DEBUG 01-05 12:51:27.008696.008696 lmp.py:376]   Expert 39 |    175 | GPU
DEBUG 01-05 12:51:27.008293.008293 lmp.py:376]   Expert 42 |    190 | GPU
DEBUG 01-05 12:51:27.008459.008459 lmp.py:376]   Expert 56 |    192 | GPU
DEBUG 01-05 12:51:27.008308.008308 lmp.py:376]   Expert 52 |    198 | GPU
DEBUG 01-05 12:51:27.008997.008997 lmp.py:376]   Expert 22 |    204 | GPU
DEBUG 01-05 12:51:27.008468.008468 lmp.py:376]   Expert 24 |    204 | GPU
DEBUG 01-05 12:51:27.008979.008979 lmp.py:376]   Expert 51 |    208 | GPU
DEBUG 01-05 12:51:27.008814.008814 lmp.py:376]   Expert  1 |    213 | GPU
DEBUG 01-05 12:51:27.008649.008649 lmp.py:376]   Expert  7 |    214 | GPU
DEBUG 01-05 12:51:27.008007.008007 lmp.py:376]   Expert  9 |    214 | GPU
DEBUG 01-05 12:51:27.008319.008319 lmp.py:376]   Expert 50 |    221 | GPU
DEBUG 01-05 12:51:27.008677.008677 lmp.py:376]   Expert 59 |    228 | GPU
DEBUG 01-05 12:51:27.008036.008036 lmp.py:376]   Expert 61 |    242 | GPU
DEBUG 01-05 12:51:27.008394.008394 lmp.py:376]   Expert 16 |    263 | GPU
DEBUG 01-05 12:51:27.008514.008514 lmp.py:376]   Expert 31 |    267 | GPU
DEBUG 01-05 12:51:27.008872.008872 lmp.py:376]   Expert 47 |    272 | GPU
DEBUG 01-05 12:51:27.008469.008469 lmp.py:376]   Expert 28 |    276 | GPU
DEBUG 01-05 12:51:27.008827.008827 lmp.py:376]   Expert 57 |    281 | GPU
DEBUG 01-05 12:51:27.008423.008423 lmp.py:376]   Expert 21 |    286 | GPU
DEBUG 01-05 12:51:27.008020.008020 lmp.py:376]   Expert 14 |    312 | GPU
DEBUG 01-05 12:51:27.008378.008378 lmp.py:376]   Expert 38 |    312 | GPU
DEBUG 01-05 12:51:27.008690.008690 lmp.py:376]   Expert  2 |    345 | GPU
DEBUG 01-05 12:51:27.008764.008764 lmp.py:376]   Expert 10 |    346 | GPU
DEBUG 01-05 12:51:27.008076.008076 lmp.py:376]   Expert 15 |    357 | GPU
DEBUG 01-05 12:51:27.008149.008149 lmp.py:376]   Expert 49 |    361 | GPU
DEBUG 01-05 12:51:27.008507.008507 lmp.py:376]   Expert 36 |    399 | GPU
DEBUG 01-05 12:51:27.008342.008342 lmp.py:376]   Expert 23 |    446 | GPU
DEBUG 01-05 12:51:27.008462.008462 lmp.py:376]   Expert 26 |    453 | GPU
DEBUG 01-05 12:51:27.008820.008820 lmp.py:376]   Expert 62 |    726 | GPU
DEBUG 01-05 12:51:27.008371.008371 lmp.py:377] 
DEBUG 01-05 12:51:27.008371.008371 lmp.py:377]   CPU total tokens: 3364 (27.4%)
DEBUG 01-05 12:51:27.008444.008444 lmp.py:378]   GPU total tokens: 8924 (72.6%)
DEBUG 01-05 12:51:27.008763.008763 cuda_h.py:19] end experts_map_get cost 0.0016407966613769531 seconds
DEBUG 01-05 12:51:27.008790.008790 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.009812.009812 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.009770.009770 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.010622.010622 cuda_h.py:19] end allocate_cuda_memory cost 0.001682281494140625 seconds
DEBUG 01-05 12:51:27.010565.010565 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.010566.010566 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.011620.011620 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.011370.011370 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 06647dc4-5439-4d5d-b86a-6a5b2ded0ff6
DEBUG 01-05 12:51:27.011107.011107 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.011716.011716 mlpmodule.py:662]  experts func einsum cost 0.07454061508178711 s
INFO 01-05 12:51:27.011300.011300 client.py:127] Model loaded
DEBUG 01-05 12:51:27.011557.011557 cuda_h.py:19] end sllm_worker_task cost 0.010897636413574219 seconds
INFO 01-05 12:51:27.012887.012887 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 06647dc4-5439-4d5d-b86a-6a5b2ded0ff6
DEBUG 01-05 12:51:27.012691.012691 cuda_h.py:19] end load_into_gpu_async cost 0.0013592243194580078 seconds
DEBUG 01-05 12:51:27.012109.012109 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.012931.012931 cuda_h.py:19] end restore_tensors2 cost 0.0003933906555175781 seconds
DEBUG 01-05 12:51:27.012291.012291 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003804445266723633 seconds
DEBUG 01-05 12:51:27.015169.015169 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006535530090332031 seconds
DEBUG 01-05 12:51:27.015634.015634 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.015074.015074 lmp.py:423] 
DEBUG 01-05 12:51:27.015074.015074 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.015778.015778 cuda_h.py:19] end cpu_experts_submit cost 0.00011301040649414062 seconds
DEBUG 01-05 12:51:27.015051.015051 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.021784.021784 mlpmodule.py:704] group tensors cost 0.005050182342529297 s
DEBUG 01-05 12:51:27.023378.023378 mlpmodule.py:742] pad cost 0.0015163421630859375 s
DEBUG 01-05 12:51:27.023527.023527 mlpmodule.py:748] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-05 12:51:27.023185.023185 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-05 12:51:27.032760.032760 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.032551.032551 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.032130.032130 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 12:51:27.033656.033656 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.049528.049528 mlpmodule.py:793] group einsum cost 0.026381731033325195 s
DEBUG 01-05 12:51:27.050382.050382 mlpmodule.py:801] cpy2cputensor cost 0.0006473064422607422 s
DEBUG 01-05 12:51:27.055883.055883 cuda_h.py:19] end wait_cetm_experts cost 0.039238691329956055 seconds
DEBUG 01-05 12:51:27.055001.055001 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.055187.055187 cuda_h.py:19] end gpu_sexperts cost 0.0005414485931396484 seconds
DEBUG 01-05 12:51:27.055261.055261 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.055350.055350 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 12:51:27.055622.055622 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.055755.055755 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 06647dc4-5439-4d5d-b86a-6a5b2ded0ff6
INFO 01-05 12:51:27.066193.066193 client.py:127] Model loaded
DEBUG 01-05 12:51:27.066871.066871 cuda_h.py:19] end wait_experts cost 0.010967493057250977 seconds
DEBUG 01-05 12:51:27.067819.067819 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.067198.067198 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.067289.067289 mlpmodule.py:531] gpu group tensors cost 0.0008492469787597656 s
DEBUG 01-05 12:51:27.070780.070780 mlpmodule.py:662]  experts func einsum cost 0.054802894592285156 s
DEBUG 01-05 12:51:27.070964.070964 mlpmodule.py:564] gpu pad cost 0.0028641223907470703 s
DEBUG 01-05 12:51:27.071324.071324 mlpmodule.py:582] gpu group einsum cost 0.0007266998291015625 s
DEBUG 01-05 12:51:27.076245.076245 mlpmodule.py:611] gpu experts func einsum cost 0.009628772735595703 s
DEBUG 01-05 12:51:27.076236.076236 cuda_h.py:19] end gpu_experts cost 0.009858846664428711 seconds
DEBUG 01-05 12:51:27.077235.077235 cuda_h.py:19] end layer_moe_generate_18 cost 0.07047653198242188 seconds
DEBUG 01-05 12:51:27.077407.077407 lmp.py:217] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 12:51:27.077878.077878 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 12:51:27.077336.077336 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 12:51:27.077138.077138 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 12:51:27.077405.077405 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:27.077108.077108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.175041198730469e-05 seconds
DEBUG 01-05 12:51:27.077201.077201 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.077773.077773 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.077872.077872 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.077286.077286 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.078150.078150 cuda_h.py:19] end allocate_cuda_memory cost 0.00041294097900390625 seconds
DEBUG 01-05 12:51:27.078340.078340 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.078655.078655 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.078115.078115 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.078249.078249 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f5ce287f-2e22-4ef6-aece-c2bbfcbfe135
DEBUG 01-05 12:51:27.078089.078089 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.078200.078200 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.079367.079367 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f5ce287f-2e22-4ef6-aece-c2bbfcbfe135
DEBUG 01-05 12:51:27.079470.079470 cuda_h.py:19] end load_into_gpu_async cost 0.0014066696166992188 seconds
DEBUG 01-05 12:51:27.079684.079684 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.080722.080722 cuda_h.py:19] end restore_tensors2 cost 0.00011873245239257812 seconds
DEBUG 01-05 12:51:27.080984.080984 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024743080139160156 seconds
INFO 01-05 12:51:27.081612.081612 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f5ce287f-2e22-4ef6-aece-c2bbfcbfe135
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.083379.083379 cuda_h.py:19] end self_attn cost 0.004492044448852539 seconds
DEBUG 01-05 12:51:27.083257.083257 cuda_h.py:19] end iln_self_attn_paln cost 0.0063669681549072266 seconds
DEBUG 01-05 12:51:27.083285.083285 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 12:51:27.083571.083571 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.084971.084971 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-05 12:51:27.084370.084370 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.084062.084062 lmp.py:365] 
DEBUG 01-05 12:51:27.084062.084062 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.084149.084149 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.084846.084846 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.085442.085442 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.085655.085655 lmp.py:369] 
DEBUG 01-05 12:51:27.085655.085655 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.085106.085106 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.085802.085802 lmp.py:376]   Expert 60 |     49 | CPU
DEBUG 01-05 12:51:27.085729.085729 lmp.py:376]   Expert 56 |     55 | CPU
DEBUG 01-05 12:51:27.085703.085703 lmp.py:376]   Expert 12 |     65 | CPU
DEBUG 01-05 12:51:27.085677.085677 lmp.py:376]   Expert  5 |     78 | CPU
DEBUG 01-05 12:51:27.085651.085651 lmp.py:376]   Expert 55 |     78 | CPU
DEBUG 01-05 12:51:27.085579.085579 lmp.py:376]   Expert  6 |     83 | CPU
DEBUG 01-05 12:51:27.085507.085507 lmp.py:376]   Expert 18 |     85 | CPU
DEBUG 01-05 12:51:27.085719.085719 lmp.py:376]   Expert 48 |     89 | CPU
DEBUG 01-05 12:51:27.085647.085647 lmp.py:376]   Expert 59 |     89 | CPU
DEBUG 01-05 12:51:27.085860.085860 lmp.py:376]   Expert 30 |     94 | CPU
DEBUG 01-05 12:51:27.085595.085595 lmp.py:376]   Expert 44 |     94 | CPU
DEBUG 01-05 12:51:27.085808.085808 lmp.py:376]   Expert 52 |     98 | CPU
DEBUG 01-05 12:51:27.085543.085543 lmp.py:376]   Expert 42 |    103 | CPU
DEBUG 01-05 12:51:27.085279.085279 lmp.py:376]   Expert 23 |    105 | CPU
DEBUG 01-05 12:51:27.085253.085253 lmp.py:376]   Expert 33 |    109 | CPU
DEBUG 01-05 12:51:27.085227.085227 lmp.py:376]   Expert 27 |    119 | CPU
DEBUG 01-05 12:51:27.085201.085201 lmp.py:376]   Expert 34 |    119 | CPU
DEBUG 01-05 12:51:27.085414.085414 lmp.py:376]   Expert 24 |    127 | CPU
DEBUG 01-05 12:51:27.085341.085341 lmp.py:376]   Expert 57 |    132 | CPU
DEBUG 01-05 12:51:27.085792.085792 lmp.py:376]   Expert 32 |    133 | CPU
DEBUG 01-05 12:51:27.085005.085005 lmp.py:376]   Expert 54 |    140 | CPU
DEBUG 01-05 12:51:27.085217.085217 lmp.py:376]   Expert  8 |    150 | CPU
DEBUG 01-05 12:51:27.085668.085668 lmp.py:376]   Expert 63 |    150 | CPU
DEBUG 01-05 12:51:27.085880.085880 lmp.py:376]   Expert 15 |    152 | CPU
DEBUG 01-05 12:51:27.085616.085616 lmp.py:376]   Expert 17 |    153 | CPU
DEBUG 01-05 12:51:27.085590.085590 lmp.py:376]   Expert 58 |    156 | CPU
DEBUG 01-05 12:51:27.085803.085803 lmp.py:376]   Expert  1 |    157 | CPU
DEBUG 01-05 12:51:27.085538.085538 lmp.py:376]   Expert  0 |    158 | CPU
DEBUG 01-05 12:51:27.085274.085274 lmp.py:376]   Expert 13 |    159 | CPU
DEBUG 01-05 12:51:27.085009.085009 lmp.py:376]   Expert 62 |    159 | CPU
DEBUG 01-05 12:51:27.085983.085983 lmp.py:376]   Expert 16 |    160 | CPU
DEBUG 01-05 12:51:27.085719.085719 lmp.py:376]   Expert 26 |    160 | CPU
DEBUG 01-05 12:51:27.085077.085077 lmp.py:376]   Expert 46 |    163 | GPU
DEBUG 01-05 12:51:27.085005.085005 lmp.py:376]   Expert 19 |    168 | GPU
DEBUG 01-05 12:51:27.085217.085217 lmp.py:376]   Expert 43 |    169 | GPU
DEBUG 01-05 12:51:27.085907.085907 lmp.py:376]   Expert 39 |    175 | GPU
DEBUG 01-05 12:51:27.085119.085119 lmp.py:376]   Expert 49 |    180 | GPU
DEBUG 01-05 12:51:27.085332.085332 lmp.py:376]   Expert 47 |    188 | GPU
DEBUG 01-05 12:51:27.085067.085067 lmp.py:376]   Expert  4 |    194 | GPU
DEBUG 01-05 12:51:27.085041.085041 lmp.py:376]   Expert 40 |    194 | GPU
DEBUG 01-05 12:51:27.085777.085777 lmp.py:376]   Expert 25 |    196 | GPU
DEBUG 01-05 12:51:27.085751.085751 lmp.py:376]   Expert 50 |    205 | GPU
DEBUG 01-05 12:51:27.085632.085632 lmp.py:376]   Expert 53 |    205 | GPU
DEBUG 01-05 12:51:27.085799.085799 lmp.py:376]   Expert 35 |    219 | GPU
DEBUG 01-05 12:51:27.085442.085442 lmp.py:376]   Expert 37 |    222 | GPU
DEBUG 01-05 12:51:27.085846.085846 lmp.py:376]   Expert 22 |    228 | GPU
DEBUG 01-05 12:51:27.085489.085489 lmp.py:376]   Expert 20 |    230 | GPU
DEBUG 01-05 12:51:27.085894.085894 lmp.py:376]   Expert 14 |    231 | GPU
DEBUG 01-05 12:51:27.085821.085821 lmp.py:376]   Expert 11 |    237 | GPU
DEBUG 01-05 12:51:27.085749.085749 lmp.py:376]   Expert 41 |    259 | GPU
DEBUG 01-05 12:51:27.085200.085200 lmp.py:376]   Expert 51 |    259 | GPU
DEBUG 01-05 12:51:27.085889.085889 lmp.py:376]   Expert 38 |    279 | GPU
DEBUG 01-05 12:51:27.085340.085340 lmp.py:376]   Expert 36 |    280 | GPU
DEBUG 01-05 12:51:27.085029.085029 lmp.py:376]   Expert 21 |    293 | GPU
DEBUG 01-05 12:51:27.085957.085957 lmp.py:376]   Expert 28 |    302 | GPU
DEBUG 01-05 12:51:27.085885.085885 lmp.py:376]   Expert 10 |    326 | GPU
DEBUG 01-05 12:51:27.085336.085336 lmp.py:376]   Expert 45 |    335 | GPU
DEBUG 01-05 12:51:27.086502.086502 lmp.py:376]   Expert  2 |    357 | GPU
DEBUG 01-05 12:51:27.086668.086668 lmp.py:376]   Expert  9 |    362 | GPU
DEBUG 01-05 12:51:27.086073.086073 lmp.py:376]   Expert 61 |    365 | GPU
DEBUG 01-05 12:51:27.086477.086477 lmp.py:376]   Expert  3 |    372 | GPU
DEBUG 01-05 12:51:27.086166.086166 lmp.py:376]   Expert 29 |    400 | GPU
DEBUG 01-05 12:51:27.086094.086094 lmp.py:376]   Expert 31 |    410 | GPU
DEBUG 01-05 12:51:27.086260.086260 lmp.py:376]   Expert  7 |    527 | GPU
DEBUG 01-05 12:51:27.086903.086903 lmp.py:377] 
DEBUG 01-05 12:51:27.086903.086903 lmp.py:377]   CPU total tokens: 3758 (30.6%)
DEBUG 01-05 12:51:27.086546.086546 lmp.py:378]   GPU total tokens: 8530 (69.4%)
DEBUG 01-05 12:51:27.086481.086481 cuda_h.py:19] end experts_map_get cost 0.0014920234680175781 seconds
DEBUG 01-05 12:51:27.086601.086601 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.086807.086807 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.086190.086190 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.086443.086443 cuda_h.py:19] end allocate_cuda_memory cost 0.00022363662719726562 seconds
DEBUG 01-05 12:51:27.086048.086048 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.086566.086566 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.086520.086520 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.086885.086885 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aa68b1f3-8a41-48c9-a5d2-27ade0a2cd70
DEBUG 01-05 12:51:27.087702.087702 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.087894.087894 client.py:127] Model loaded
DEBUG 01-05 12:51:27.087792.087792 cuda_h.py:19] end sllm_worker_task cost 0.009674787521362305 seconds
INFO 01-05 12:51:27.088966.088966 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aa68b1f3-8a41-48c9-a5d2-27ade0a2cd70
DEBUG 01-05 12:51:27.088386.088386 cuda_h.py:19] end load_into_gpu_async cost 0.0015497207641601562 seconds
DEBUG 01-05 12:51:27.088089.088089 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.088798.088798 cuda_h.py:19] end restore_tensors2 cost 0.00038695335388183594 seconds
DEBUG 01-05 12:51:27.088535.088535 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025148391723632812 seconds
DEBUG 01-05 12:51:27.091533.091533 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00525975227355957 seconds
DEBUG 01-05 12:51:27.091216.091216 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.091723.091723 lmp.py:423] 
DEBUG 01-05 12:51:27.091723.091723 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.091188.091188 cuda_h.py:19] end cpu_experts_submit cost 0.00011205673217773438 seconds
DEBUG 01-05 12:51:27.091553.091553 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.102298.102298 mlpmodule.py:704] group tensors cost 0.010255098342895508 s
DEBUG 01-05 12:51:27.105401.105401 mlpmodule.py:742] pad cost 0.0018303394317626953 s
DEBUG 01-05 12:51:27.105663.105663 mlpmodule.py:748] create cpu tensor cost 4.887580871582031e-05 s
DEBUG 01-05 12:51:27.105183.105183 mlpmodule.py:753] move to cpu cost 6.0558319091796875e-05 s
DEBUG 01-05 12:51:27.114640.114640 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.114570.114570 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.114241.114241 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-05 12:51:27.114199.114199 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.131601.131601 mlpmodule.py:793] group einsum cost 0.02625131607055664 s
DEBUG 01-05 12:51:27.132828.132828 mlpmodule.py:801] cpy2cputensor cost 0.0006723403930664062 s
DEBUG 01-05 12:51:27.136869.136869 cuda_h.py:19] end wait_cetm_experts cost 0.04513144493103027 seconds
DEBUG 01-05 12:51:27.137094.137094 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.138621.138621 cuda_h.py:19] end gpu_sexperts cost 0.0008208751678466797 seconds
DEBUG 01-05 12:51:27.138995.138995 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.138616.138616 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.221366882324219e-05 seconds
DEBUG 01-05 12:51:27.138479.138479 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.138773.138773 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aa68b1f3-8a41-48c9-a5d2-27ade0a2cd70
INFO 01-05 12:51:27.142770.142770 client.py:127] Model loaded
DEBUG 01-05 12:51:27.142483.142483 cuda_h.py:19] end wait_experts cost 0.004380702972412109 seconds
DEBUG 01-05 12:51:27.142962.142962 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.142064.142064 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.144078.144078 mlpmodule.py:531] gpu group tensors cost 0.0014271736145019531 s
DEBUG 01-05 12:51:27.148639.148639 mlpmodule.py:564] gpu pad cost 0.004184722900390625 s
DEBUG 01-05 12:51:27.149796.149796 mlpmodule.py:582] gpu group einsum cost 0.0007975101470947266 s
DEBUG 01-05 12:51:27.152693.152693 mlpmodule.py:662]  experts func einsum cost 0.060497283935546875 s
DEBUG 01-05 12:51:27.155354.155354 mlpmodule.py:611] gpu experts func einsum cost 0.012653589248657227 s
DEBUG 01-05 12:51:27.155367.155367 cuda_h.py:19] end gpu_experts cost 0.013010025024414062 seconds
DEBUG 01-05 12:51:27.156140.156140 cuda_h.py:19] end layer_moe_generate_19 cost 0.07218694686889648 seconds
DEBUG 01-05 12:51:27.156800.156800 lmp.py:217] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 12:51:27.156557.156557 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 12:51:27.156572.156572 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 12:51:27.156197.156197 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 12:51:27.156055.156055 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.030632019042969e-05 seconds
DEBUG 01-05 12:51:27.156939.156939 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.156212.156212 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00020551681518554688 seconds
DEBUG 01-05 12:51:27.156580.156580 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.157760.157760 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.157161.157161 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.157969.157969 cuda_h.py:19] end allocate_cuda_memory cost 0.00033211708068847656 seconds
DEBUG 01-05 12:51:27.157064.157064 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.157066.157066 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.157142.157142 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.157103.157103 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b8adc66-1d1d-42cc-9607-c5e15b6c4199
DEBUG 01-05 12:51:27.157888.157888 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.158137.158137 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.158588.158588 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b8adc66-1d1d-42cc-9607-c5e15b6c4199
DEBUG 01-05 12:51:27.158359.158359 cuda_h.py:19] end load_into_gpu_async cost 0.0012311935424804688 seconds
DEBUG 01-05 12:51:27.158459.158459 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.159993.159993 cuda_h.py:19] end restore_tensors2 cost 7.510185241699219e-05 seconds
DEBUG 01-05 12:51:27.159623.159623 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019817352294921875 seconds
INFO 01-05 12:51:27.159074.159074 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b8adc66-1d1d-42cc-9607-c5e15b6c4199
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.163083.163083 cuda_h.py:19] end self_attn cost 0.0048525333404541016 seconds
DEBUG 01-05 12:51:27.163068.163068 cuda_h.py:19] end iln_self_attn_paln cost 0.006261110305786133 seconds
DEBUG 01-05 12:51:27.163998.163998 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 12:51:27.163205.163205 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.164786.164786 cuda_h.py:19] end gate cost 0.0007040500640869141 seconds
DEBUG 01-05 12:51:27.164483.164483 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.164431.164431 lmp.py:365] 
DEBUG 01-05 12:51:27.164431.164431 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.164307.164307 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.164593.164593 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.164157.164157 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.164860.164860 lmp.py:369] 
DEBUG 01-05 12:51:27.164860.164860 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.164562.164562 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.164371.164371 lmp.py:376]   Expert 54 |     53 | CPU
DEBUG 01-05 12:51:27.165121.165121 lmp.py:376]   Expert 28 |     57 | CPU
DEBUG 01-05 12:51:27.165400.165400 lmp.py:376]   Expert  8 |     60 | CPU
DEBUG 01-05 12:51:27.165387.165387 lmp.py:376]   Expert 13 |     70 | CPU
DEBUG 01-05 12:51:27.165898.165898 lmp.py:376]   Expert  6 |     76 | CPU
DEBUG 01-05 12:51:27.165409.165409 lmp.py:376]   Expert  1 |     78 | CPU
DEBUG 01-05 12:51:27.165350.165350 lmp.py:376]   Expert 43 |     84 | CPU
DEBUG 01-05 12:51:27.165576.165576 lmp.py:376]   Expert 42 |     92 | CPU
DEBUG 01-05 12:51:27.165087.165087 lmp.py:376]   Expert 33 |     98 | CPU
DEBUG 01-05 12:51:27.165836.165836 lmp.py:376]   Expert 36 |     98 | CPU
DEBUG 01-05 12:51:27.165824.165824 lmp.py:376]   Expert 12 |    101 | CPU
DEBUG 01-05 12:51:27.165858.165858 lmp.py:376]   Expert 19 |    105 | CPU
DEBUG 01-05 12:51:27.165369.165369 lmp.py:376]   Expert 10 |    107 | CPU
DEBUG 01-05 12:51:27.165403.165403 lmp.py:376]   Expert 51 |    111 | CPU
DEBUG 01-05 12:51:27.165390.165390 lmp.py:376]   Expert 30 |    116 | CPU
DEBUG 01-05 12:51:27.165093.165093 lmp.py:376]   Expert 38 |    122 | CPU
DEBUG 01-05 12:51:27.165081.165081 lmp.py:376]   Expert 14 |    125 | CPU
DEBUG 01-05 12:51:27.165307.165307 lmp.py:376]   Expert 57 |    125 | CPU
DEBUG 01-05 12:51:27.165579.165579 lmp.py:376]   Expert  9 |    129 | CPU
DEBUG 01-05 12:51:27.165852.165852 lmp.py:376]   Expert 39 |    129 | CPU
DEBUG 01-05 12:51:27.165124.165124 lmp.py:376]   Expert 11 |    135 | CPU
DEBUG 01-05 12:51:27.165920.165920 lmp.py:376]   Expert 50 |    137 | CPU
DEBUG 01-05 12:51:27.165669.165669 lmp.py:376]   Expert 46 |    139 | CPU
DEBUG 01-05 12:51:27.165418.165418 lmp.py:376]   Expert  7 |    146 | CPU
DEBUG 01-05 12:51:27.165167.165167 lmp.py:376]   Expert 52 |    153 | CPU
DEBUG 01-05 12:51:27.165155.165155 lmp.py:376]   Expert 29 |    155 | CPU
DEBUG 01-05 12:51:27.165427.165427 lmp.py:376]   Expert 63 |    156 | CPU
DEBUG 01-05 12:51:27.165700.165700 lmp.py:376]   Expert 49 |    158 | CPU
DEBUG 01-05 12:51:27.165733.165733 lmp.py:376]   Expert  5 |    162 | CPU
DEBUG 01-05 12:51:27.165006.165006 lmp.py:376]   Expert 61 |    167 | CPU
DEBUG 01-05 12:51:27.165278.165278 lmp.py:376]   Expert 20 |    169 | CPU
DEBUG 01-05 12:51:27.165266.165266 lmp.py:376]   Expert  3 |    170 | CPU
DEBUG 01-05 12:51:27.165492.165492 lmp.py:376]   Expert 53 |    171 | GPU
DEBUG 01-05 12:51:27.165241.165241 lmp.py:376]   Expert 44 |    176 | GPU
DEBUG 01-05 12:51:27.165752.165752 lmp.py:376]   Expert 22 |    178 | GPU
DEBUG 01-05 12:51:27.165547.165547 lmp.py:376]   Expert 62 |    188 | GPU
DEBUG 01-05 12:51:27.165581.165581 lmp.py:376]   Expert 18 |    193 | GPU
DEBUG 01-05 12:51:27.165854.165854 lmp.py:376]   Expert  0 |    200 | GPU
DEBUG 01-05 12:51:27.165126.165126 lmp.py:376]   Expert 17 |    201 | GPU
DEBUG 01-05 12:51:27.165160.165160 lmp.py:376]   Expert 37 |    210 | GPU
DEBUG 01-05 12:51:27.166194.166194 lmp.py:376]   Expert 47 |    212 | GPU
DEBUG 01-05 12:51:27.166182.166182 lmp.py:376]   Expert  2 |    213 | GPU
DEBUG 01-05 12:51:27.166931.166931 lmp.py:376]   Expert 23 |    231 | GPU
DEBUG 01-05 12:51:27.166442.166442 lmp.py:376]   Expert 55 |    232 | GPU
DEBUG 01-05 12:51:27.166906.166906 lmp.py:376]   Expert 26 |    234 | GPU
DEBUG 01-05 12:51:27.166702.166702 lmp.py:376]   Expert 32 |    236 | GPU
DEBUG 01-05 12:51:27.166497.166497 lmp.py:376]   Expert 45 |    236 | GPU
DEBUG 01-05 12:51:27.166008.166008 lmp.py:376]   Expert 60 |    239 | GPU
DEBUG 01-05 12:51:27.166519.166519 lmp.py:376]   Expert 16 |    248 | GPU
DEBUG 01-05 12:51:27.166314.166314 lmp.py:376]   Expert 15 |    268 | GPU
DEBUG 01-05 12:51:27.166825.166825 lmp.py:376]   Expert 21 |    272 | GPU
DEBUG 01-05 12:51:27.166574.166574 lmp.py:376]   Expert 34 |    274 | GPU
DEBUG 01-05 12:51:27.166323.166323 lmp.py:376]   Expert 58 |    284 | GPU
DEBUG 01-05 12:51:27.166357.166357 lmp.py:376]   Expert  4 |    296 | GPU
DEBUG 01-05 12:51:27.166868.166868 lmp.py:376]   Expert 24 |    298 | GPU
DEBUG 01-05 12:51:27.166386.166386 lmp.py:376]   Expert 27 |    302 | GPU
DEBUG 01-05 12:51:27.166612.166612 lmp.py:376]   Expert 31 |    303 | GPU
DEBUG 01-05 12:51:27.166407.166407 lmp.py:376]   Expert 59 |    305 | GPU
DEBUG 01-05 12:51:27.166918.166918 lmp.py:376]   Expert 56 |    315 | GPU
DEBUG 01-05 12:51:27.166667.166667 lmp.py:376]   Expert 40 |    322 | GPU
DEBUG 01-05 12:51:27.166940.166940 lmp.py:376]   Expert 41 |    323 | GPU
DEBUG 01-05 12:51:27.166927.166927 lmp.py:376]   Expert 48 |    334 | GPU
DEBUG 01-05 12:51:27.166961.166961 lmp.py:376]   Expert 25 |    477 | GPU
DEBUG 01-05 12:51:27.166757.166757 lmp.py:376]   Expert 35 |    534 | GPU
DEBUG 01-05 12:51:27.166983.166983 lmp.py:377] 
DEBUG 01-05 12:51:27.166983.166983 lmp.py:377]   CPU total tokens: 3783 (30.8%)
DEBUG 01-05 12:51:27.166970.166970 lmp.py:378]   GPU total tokens: 8505 (69.2%)
DEBUG 01-05 12:51:27.166680.166680 cuda_h.py:19] end experts_map_get cost 0.0022711753845214844 seconds
DEBUG 01-05 12:51:27.166098.166098 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.166756.166756 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.166364.166364 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.167348.167348 cuda_h.py:19] end allocate_cuda_memory cost 0.00024127960205078125 seconds
DEBUG 01-05 12:51:27.167026.167026 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.167703.167703 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.167294.167294 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.167242.167242 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 68b41d7c-7446-4643-8519-6fc427653430
DEBUG 01-05 12:51:27.167643.167643 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.167318.167318 client.py:127] Model loaded
DEBUG 01-05 12:51:27.167446.167446 cuda_h.py:19] end sllm_worker_task cost 0.01104283332824707 seconds
INFO 01-05 12:51:27.168756.168756 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 68b41d7c-7446-4643-8519-6fc427653430
DEBUG 01-05 12:51:27.169387.169387 cuda_h.py:19] end load_into_gpu_async cost 0.0016307830810546875 seconds
DEBUG 01-05 12:51:27.169560.169560 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.169017.169017 cuda_h.py:19] end restore_tensors2 cost 0.00038313865661621094 seconds
DEBUG 01-05 12:51:27.169840.169840 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026650428771972656 seconds
DEBUG 01-05 12:51:27.172464.172464 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005357265472412109 seconds
DEBUG 01-05 12:51:27.172817.172817 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.172442.172442 lmp.py:423] 
DEBUG 01-05 12:51:27.172442.172442 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.172762.172762 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-05 12:51:27.172173.172173 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.187169.187169 mlpmodule.py:704] group tensors cost 0.015012979507446289 s
DEBUG 01-05 12:51:27.190461.190461 mlpmodule.py:742] pad cost 0.0018239021301269531 s
DEBUG 01-05 12:51:27.190843.190843 mlpmodule.py:748] create cpu tensor cost 7.295608520507812e-05 s
DEBUG 01-05 12:51:27.190329.190329 mlpmodule.py:753] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-05 12:51:27.198253.198253 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.198355.198355 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.198973.198973 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 12:51:27.198924.198924 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.214382.214382 mlpmodule.py:793] group einsum cost 0.02367258071899414 s
DEBUG 01-05 12:51:27.214238.214238 mlpmodule.py:801] cpy2cputensor cost 0.0006837844848632812 s
DEBUG 01-05 12:51:27.219058.219058 cuda_h.py:19] end wait_cetm_experts cost 0.04708695411682129 seconds
DEBUG 01-05 12:51:27.219039.219039 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.220993.220993 cuda_h.py:19] end gpu_sexperts cost 0.0010745525360107422 seconds
DEBUG 01-05 12:51:27.221739.221739 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.221459.221459 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.14984130859375e-05 seconds
DEBUG 01-05 12:51:27.221038.221038 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.221477.221477 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 68b41d7c-7446-4643-8519-6fc427653430
INFO 01-05 12:51:27.222896.222896 client.py:127] Model loaded
DEBUG 01-05 12:51:27.222795.222795 cuda_h.py:19] end wait_experts cost 0.0015652179718017578 seconds
DEBUG 01-05 12:51:27.222605.222605 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.223800.223800 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.224562.224562 mlpmodule.py:531] gpu group tensors cost 0.0014545917510986328 s
DEBUG 01-05 12:51:27.229578.229578 mlpmodule.py:564] gpu pad cost 0.0043032169342041016 s
DEBUG 01-05 12:51:27.230893.230893 mlpmodule.py:582] gpu group einsum cost 0.0007240772247314453 s
DEBUG 01-05 12:51:27.234990.234990 mlpmodule.py:611] gpu experts func einsum cost 0.011258840560913086 s
DEBUG 01-05 12:51:27.234590.234590 cuda_h.py:19] end gpu_experts cost 0.011547088623046875 seconds
DEBUG 01-05 12:51:27.234091.234091 cuda_h.py:19] end layer_moe_generate_20 cost 0.07116293907165527 seconds
DEBUG 01-05 12:51:27.235008.235008 mlpmodule.py:662]  experts func einsum cost 0.06244349479675293 s
DEBUG 01-05 12:51:27.235860.235860 lmp.py:217] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 12:51:27.235765.235765 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 12:51:27.235058.235058 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 12:51:27.235887.235887 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 12:51:27.235096.235096 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 4.029273986816406e-05 seconds
DEBUG 01-05 12:51:27.235549.235549 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.235915.235915 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 0.0001933574676513672 seconds
DEBUG 01-05 12:51:27.235276.235276 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.235205.235205 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.235253.235253 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.236499.236499 cuda_h.py:19] end allocate_cuda_memory cost 0.0003349781036376953 seconds
DEBUG 01-05 12:51:27.236879.236879 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.236827.236827 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.236995.236995 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.236698.236698 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54c544be-443a-4b68-bfce-80a3d3b2b3fa
DEBUG 01-05 12:51:27.236383.236383 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.236206.236206 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.237997.237997 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54c544be-443a-4b68-bfce-80a3d3b2b3fa
DEBUG 01-05 12:51:27.237356.237356 cuda_h.py:19] end load_into_gpu_async cost 0.0011615753173828125 seconds
DEBUG 01-05 12:51:27.237675.237675 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.237042.237042 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 12:51:27.237368.237368 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018651485443115234 seconds
INFO 01-05 12:51:27.238280.238280 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54c544be-443a-4b68-bfce-80a3d3b2b3fa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.241875.241875 cuda_h.py:19] end self_attn cost 0.004067659378051758 seconds
DEBUG 01-05 12:51:27.241209.241209 cuda_h.py:19] end iln_self_attn_paln cost 0.005529165267944336 seconds
DEBUG 01-05 12:51:27.241429.241429 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 12:51:27.241953.241953 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.242166.242166 cuda_h.py:19] end gate cost 0.0007913112640380859 seconds
DEBUG 01-05 12:51:27.242089.242089 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.242582.242582 lmp.py:365] 
DEBUG 01-05 12:51:27.242582.242582 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.242338.242338 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.242226.242226 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.242492.242492 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.242135.242135 lmp.py:369] 
DEBUG 01-05 12:51:27.242135.242135 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.242493.242493 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.242858.242858 lmp.py:376]   Expert  9 |     29 | CPU
DEBUG 01-05 12:51:27.242978.242978 lmp.py:376]   Expert 44 |     52 | CPU
DEBUG 01-05 12:51:27.242667.242667 lmp.py:376]   Expert 60 |     52 | CPU
DEBUG 01-05 12:51:27.242595.242595 lmp.py:376]   Expert 20 |     65 | CPU
DEBUG 01-05 12:51:27.242284.242284 lmp.py:376]   Expert 26 |     66 | CPU
DEBUG 01-05 12:51:27.242973.242973 lmp.py:376]   Expert 56 |     72 | CPU
DEBUG 01-05 12:51:27.242901.242901 lmp.py:376]   Expert  1 |     74 | CPU
DEBUG 01-05 12:51:27.242590.242590 lmp.py:376]   Expert 19 |     75 | CPU
DEBUG 01-05 12:51:27.242233.242233 lmp.py:376]   Expert 32 |     76 | CPU
DEBUG 01-05 12:51:27.242399.242399 lmp.py:376]   Expert 54 |     91 | CPU
DEBUG 01-05 12:51:27.242327.242327 lmp.py:376]   Expert 51 |     93 | CPU
DEBUG 01-05 12:51:27.242732.242732 lmp.py:376]   Expert 57 |    103 | CPU
DEBUG 01-05 12:51:27.243659.243659 lmp.py:376]   Expert  8 |    113 | CPU
DEBUG 01-05 12:51:27.243349.243349 lmp.py:376]   Expert  3 |    117 | CPU
DEBUG 01-05 12:51:27.243800.243800 lmp.py:376]   Expert 12 |    121 | CPU
DEBUG 01-05 12:51:27.243250.243250 lmp.py:376]   Expert 48 |    121 | CPU
DEBUG 01-05 12:51:27.243940.243940 lmp.py:376]   Expert 14 |    122 | CPU
DEBUG 01-05 12:51:27.243629.243629 lmp.py:376]   Expert 25 |    122 | CPU
DEBUG 01-05 12:51:27.243080.243080 lmp.py:376]   Expert  6 |    127 | CPU
DEBUG 01-05 12:51:27.243008.243008 lmp.py:376]   Expert 33 |    132 | CPU
DEBUG 01-05 12:51:27.243174.243174 lmp.py:376]   Expert 23 |    134 | CPU
DEBUG 01-05 12:51:27.243102.243102 lmp.py:376]   Expert 52 |    134 | CPU
DEBUG 01-05 12:51:27.243268.243268 lmp.py:376]   Expert  7 |    140 | CPU
DEBUG 01-05 12:51:27.243434.243434 lmp.py:376]   Expert 15 |    140 | CPU
DEBUG 01-05 12:51:27.243362.243362 lmp.py:376]   Expert 13 |    141 | CPU
DEBUG 01-05 12:51:27.243051.243051 lmp.py:376]   Expert 49 |    142 | CPU
DEBUG 01-05 12:51:27.243502.243502 lmp.py:376]   Expert 34 |    146 | CPU
DEBUG 01-05 12:51:27.243953.243953 lmp.py:376]   Expert 53 |    149 | CPU
DEBUG 01-05 12:51:27.243165.243165 lmp.py:376]   Expert 40 |    154 | CPU
DEBUG 01-05 12:51:27.243616.243616 lmp.py:376]   Expert 35 |    163 | CPU
DEBUG 01-05 12:51:27.243828.243828 lmp.py:376]   Expert 59 |    167 | CPU
DEBUG 01-05 12:51:27.243802.243802 lmp.py:376]   Expert 61 |    168 | CPU
DEBUG 01-05 12:51:27.243253.243253 lmp.py:376]   Expert 50 |    175 | GPU
DEBUG 01-05 12:51:27.243704.243704 lmp.py:376]   Expert 28 |    180 | GPU
DEBUG 01-05 12:51:27.243870.243870 lmp.py:376]   Expert 58 |    181 | GPU
DEBUG 01-05 12:51:27.243036.243036 lmp.py:376]   Expert 24 |    185 | GPU
DEBUG 01-05 12:51:27.243203.243203 lmp.py:376]   Expert 39 |    185 | GPU
DEBUG 01-05 12:51:27.243369.243369 lmp.py:376]   Expert 41 |    202 | GPU
DEBUG 01-05 12:51:27.243820.243820 lmp.py:376]   Expert  2 |    203 | GPU
DEBUG 01-05 12:51:27.243271.243271 lmp.py:376]   Expert 27 |    206 | GPU
DEBUG 01-05 12:51:27.243721.243721 lmp.py:376]   Expert 38 |    212 | GPU
DEBUG 01-05 12:51:27.243934.243934 lmp.py:376]   Expert 18 |    225 | GPU
DEBUG 01-05 12:51:27.243385.243385 lmp.py:376]   Expert 43 |    226 | GPU
DEBUG 01-05 12:51:27.243836.243836 lmp.py:376]   Expert 11 |    233 | GPU
DEBUG 01-05 12:51:27.243048.243048 lmp.py:376]   Expert 37 |    240 | GPU
DEBUG 01-05 12:51:27.243261.243261 lmp.py:376]   Expert 62 |    245 | GPU
DEBUG 01-05 12:51:27.243950.243950 lmp.py:376]   Expert  4 |    253 | GPU
DEBUG 01-05 12:51:27.243878.243878 lmp.py:376]   Expert 17 |    257 | GPU
DEBUG 01-05 12:51:27.243805.243805 lmp.py:376]   Expert 29 |    261 | GPU
DEBUG 01-05 12:51:27.243733.243733 lmp.py:376]   Expert 10 |    263 | GPU
DEBUG 01-05 12:51:27.243661.243661 lmp.py:376]   Expert 47 |    267 | GPU
DEBUG 01-05 12:51:27.243112.243112 lmp.py:376]   Expert 22 |    270 | GPU
DEBUG 01-05 12:51:27.243563.243563 lmp.py:376]   Expert 30 |    279 | GPU
DEBUG 01-05 12:51:27.243013.243013 lmp.py:376]   Expert 63 |    280 | GPU
DEBUG 01-05 12:51:27.243703.243703 lmp.py:376]   Expert  5 |    286 | GPU
DEBUG 01-05 12:51:27.243915.243915 lmp.py:376]   Expert 31 |    290 | GPU
DEBUG 01-05 12:51:27.243366.243366 lmp.py:376]   Expert 55 |    294 | GPU
DEBUG 01-05 12:51:27.243578.243578 lmp.py:376]   Expert 21 |    298 | GPU
DEBUG 01-05 12:51:27.243791.243791 lmp.py:376]   Expert 16 |    345 | GPU
DEBUG 01-05 12:51:27.243242.243242 lmp.py:376]   Expert 46 |    358 | GPU
DEBUG 01-05 12:51:27.243693.243693 lmp.py:376]   Expert 36 |    387 | GPU
DEBUG 01-05 12:51:27.243144.243144 lmp.py:376]   Expert  0 |    427 | GPU
DEBUG 01-05 12:51:27.243740.243740 lmp.py:376]   Expert 45 |    427 | GPU
DEBUG 01-05 12:51:27.243668.243668 lmp.py:376]   Expert 42 |    547 | GPU
DEBUG 01-05 12:51:27.243788.243788 lmp.py:377] 
DEBUG 01-05 12:51:27.243788.243788 lmp.py:377]   CPU total tokens: 3601 (29.3%)
DEBUG 01-05 12:51:27.243908.243908 lmp.py:378]   GPU total tokens: 8687 (70.7%)
DEBUG 01-05 12:51:27.243842.243842 cuda_h.py:19] end experts_map_get cost 0.0015120506286621094 seconds
DEBUG 01-05 12:51:27.243485.243485 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.243977.243977 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.244882.244882 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.245322.245322 cuda_h.py:19] end allocate_cuda_memory cost 0.0008530616760253906 seconds
DEBUG 01-05 12:51:27.245278.245278 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.245703.245703 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.245989.245989 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.245401.245401 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8874e1ce-b485-4c05-93cc-01043f43a973
DEBUG 01-05 12:51:27.245800.245800 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.245803.245803 client.py:127] Model loaded
DEBUG 01-05 12:51:27.245991.245991 cuda_h.py:19] end sllm_worker_task cost 0.010086297988891602 seconds
INFO 01-05 12:51:27.246758.246758 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8874e1ce-b485-4c05-93cc-01043f43a973
DEBUG 01-05 12:51:27.246555.246555 cuda_h.py:19] end load_into_gpu_async cost 0.0012927055358886719 seconds
DEBUG 01-05 12:51:27.246019.246019 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.246615.246615 cuda_h.py:19] end restore_tensors2 cost 0.0003783702850341797 seconds
DEBUG 01-05 12:51:27.246346.246346 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028824806213378906 seconds
DEBUG 01-05 12:51:27.249790.249790 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005711078643798828 seconds
DEBUG 01-05 12:51:27.249997.249997 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.249860.249860 lmp.py:423] 
DEBUG 01-05 12:51:27.249860.249860 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.249034.249034 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-05 12:51:27.249446.249446 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.267559.267559 mlpmodule.py:704] group tensors cost 0.017748594284057617 s
DEBUG 01-05 12:51:27.270511.270511 mlpmodule.py:742] pad cost 0.0017533302307128906 s
DEBUG 01-05 12:51:27.270436.270436 mlpmodule.py:748] create cpu tensor cost 4.935264587402344e-05 s
DEBUG 01-05 12:51:27.270915.270915 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 12:51:27.278372.278372 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.279057.279057 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.279390.279390 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 12:51:27.279626.279626 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.294443.294443 mlpmodule.py:793] group einsum cost 0.02359604835510254 s
DEBUG 01-05 12:51:27.295232.295232 mlpmodule.py:801] cpy2cputensor cost 0.0006556510925292969 s
DEBUG 01-05 12:51:27.299473.299473 cuda_h.py:19] end wait_cetm_experts cost 0.049581289291381836 seconds
DEBUG 01-05 12:51:27.299838.299838 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.300433.300433 cuda_h.py:19] end gpu_sexperts cost 0.0010194778442382812 seconds
DEBUG 01-05 12:51:27.301417.301417 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.301568.301568 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.14984130859375e-05 seconds
DEBUG 01-05 12:51:27.301908.301908 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.301871.301871 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8874e1ce-b485-4c05-93cc-01043f43a973
INFO 01-05 12:51:27.302078.302078 client.py:127] Model loaded
DEBUG 01-05 12:51:27.302652.302652 cuda_h.py:19] end wait_experts cost 0.00138092041015625 seconds
DEBUG 01-05 12:51:27.302324.302324 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.302280.302280 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.304630.304630 mlpmodule.py:531] gpu group tensors cost 0.0013554096221923828 s
DEBUG 01-05 12:51:27.308818.308818 mlpmodule.py:564] gpu pad cost 0.0042934417724609375 s
DEBUG 01-05 12:51:27.310394.310394 mlpmodule.py:582] gpu group einsum cost 0.0010285377502441406 s
DEBUG 01-05 12:51:27.314498.314498 mlpmodule.py:611] gpu experts func einsum cost 0.01149129867553711 s
DEBUG 01-05 12:51:27.314343.314343 cuda_h.py:19] end gpu_experts cost 0.011784553527832031 seconds
DEBUG 01-05 12:51:27.314161.314161 cuda_h.py:19] end layer_moe_generate_21 cost 0.07325911521911621 seconds
DEBUG 01-05 12:51:27.314434.314434 lmp.py:217] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 12:51:27.315555.315555 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 12:51:27.315748.315748 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 12:51:27.315810.315810 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 12:51:27.315673.315673 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.719329833984375e-05 seconds
DEBUG 01-05 12:51:27.315966.315966 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 8.296966552734375e-05 seconds
DEBUG 01-05 12:51:27.315861.315861 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.315115.315115 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.315424.315424 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.315022.315022 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.315506.315506 cuda_h.py:19] end allocate_cuda_memory cost 0.0003895759582519531 seconds
DEBUG 01-05 12:51:27.316153.316153 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.316161.316161 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.316083.316083 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.316978.316978 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a94ffd2-d6e7-48af-925d-0d253be68040
DEBUG 01-05 12:51:27.316616.316616 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.316952.316952 mlpmodule.py:662]  experts func einsum cost 0.06632566452026367 s
DEBUG 01-05 12:51:27.316768.316768 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.317441.317441 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a94ffd2-d6e7-48af-925d-0d253be68040
DEBUG 01-05 12:51:27.317105.317105 cuda_h.py:19] end load_into_gpu_async cost 0.0015037059783935547 seconds
DEBUG 01-05 12:51:27.317623.317623 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.317129.317129 cuda_h.py:19] end restore_tensors2 cost 6.318092346191406e-05 seconds
DEBUG 01-05 12:51:27.317793.317793 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022716522216796875 seconds
INFO 01-05 12:51:27.318665.318665 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a94ffd2-d6e7-48af-925d-0d253be68040
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.320103.320103 cuda_h.py:19] end self_attn cost 0.0037674903869628906 seconds
DEBUG 01-05 12:51:27.321484.321484 cuda_h.py:19] end iln_self_attn_paln cost 0.005722999572753906 seconds
DEBUG 01-05 12:51:27.321373.321373 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 12:51:27.321136.321136 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.321986.321986 cuda_h.py:19] end gate cost 0.0006279945373535156 seconds
DEBUG 01-05 12:51:27.321193.321193 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.322647.322647 lmp.py:365] 
DEBUG 01-05 12:51:27.322647.322647 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.322840.322840 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.322974.322974 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.322385.322385 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.322174.322174 lmp.py:369] 
DEBUG 01-05 12:51:27.322174.322174 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.322201.322201 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.322904.322904 lmp.py:376]   Expert 11 |     56 | CPU
DEBUG 01-05 12:51:27.322931.322931 lmp.py:376]   Expert 49 |     64 | CPU
DEBUG 01-05 12:51:27.322958.322958 lmp.py:376]   Expert 32 |     66 | CPU
DEBUG 01-05 12:51:27.322508.322508 lmp.py:376]   Expert  1 |     67 | CPU
DEBUG 01-05 12:51:27.322774.322774 lmp.py:376]   Expert 54 |     80 | CPU
DEBUG 01-05 12:51:27.322324.322324 lmp.py:376]   Expert  6 |     83 | CPU
DEBUG 01-05 12:51:27.322113.322113 lmp.py:376]   Expert 12 |     85 | CPU
DEBUG 01-05 12:51:27.322140.322140 lmp.py:376]   Expert  7 |     88 | CPU
DEBUG 01-05 12:51:27.322690.322690 lmp.py:376]   Expert 22 |     89 | CPU
DEBUG 01-05 12:51:27.322764.322764 lmp.py:376]   Expert 45 |     90 | CPU
DEBUG 01-05 12:51:27.322076.322076 lmp.py:376]   Expert 46 |     91 | CPU
DEBUG 01-05 12:51:27.322388.322388 lmp.py:376]   Expert 41 |     92 | CPU
DEBUG 01-05 12:51:27.322700.322700 lmp.py:376]   Expert 42 |     93 | CPU
DEBUG 01-05 12:51:27.322296.322296 lmp.py:376]   Expert 44 |     93 | CPU
DEBUG 01-05 12:51:27.322131.322131 lmp.py:376]   Expert 63 |     98 | CPU
DEBUG 01-05 12:51:27.322159.322159 lmp.py:376]   Expert 52 |    103 | CPU
DEBUG 01-05 12:51:27.322709.322709 lmp.py:376]   Expert 60 |    106 | CPU
DEBUG 01-05 12:51:27.322259.322259 lmp.py:376]   Expert 15 |    109 | CPU
DEBUG 01-05 12:51:27.322048.322048 lmp.py:376]   Expert 24 |    110 | CPU
DEBUG 01-05 12:51:27.322360.322360 lmp.py:376]   Expert 61 |    117 | CPU
DEBUG 01-05 12:51:27.322433.322433 lmp.py:376]   Expert 10 |    118 | CPU
DEBUG 01-05 12:51:27.322507.322507 lmp.py:376]   Expert 37 |    118 | CPU
DEBUG 01-05 12:51:27.322580.322580 lmp.py:376]   Expert 48 |    126 | CPU
DEBUG 01-05 12:51:27.322654.322654 lmp.py:376]   Expert 13 |    128 | CPU
DEBUG 01-05 12:51:27.322250.322250 lmp.py:376]   Expert 62 |    128 | CPU
DEBUG 01-05 12:51:27.322801.322801 lmp.py:376]   Expert 28 |    129 | CPU
DEBUG 01-05 12:51:27.322636.322636 lmp.py:376]   Expert  9 |    130 | CPU
DEBUG 01-05 12:51:27.322948.322948 lmp.py:376]   Expert  3 |    132 | CPU
DEBUG 01-05 12:51:27.322260.322260 lmp.py:376]   Expert 21 |    132 | CPU
DEBUG 01-05 12:51:27.322810.322810 lmp.py:376]   Expert 57 |    133 | CPU
DEBUG 01-05 12:51:27.322360.322360 lmp.py:376]   Expert 31 |    138 | CPU
DEBUG 01-05 12:51:27.322434.322434 lmp.py:376]   Expert 30 |    140 | CPU
DEBUG 01-05 12:51:27.322507.322507 lmp.py:376]   Expert  0 |    150 | GPU
DEBUG 01-05 12:51:27.322581.322581 lmp.py:376]   Expert 27 |    156 | GPU
DEBUG 01-05 12:51:27.322416.322416 lmp.py:376]   Expert 47 |    158 | GPU
DEBUG 01-05 12:51:27.322489.322489 lmp.py:376]   Expert 26 |    161 | GPU
DEBUG 01-05 12:51:27.322801.322801 lmp.py:376]   Expert 43 |    173 | GPU
DEBUG 01-05 12:51:27.323875.323875 lmp.py:376]   Expert 51 |    192 | GPU
DEBUG 01-05 12:51:27.323710.323710 lmp.py:376]   Expert 50 |    194 | GPU
DEBUG 01-05 12:51:27.323783.323783 lmp.py:376]   Expert 58 |    201 | GPU
DEBUG 01-05 12:51:27.323334.323334 lmp.py:376]   Expert 38 |    213 | GPU
DEBUG 01-05 12:51:27.323645.323645 lmp.py:376]   Expert 39 |    213 | GPU
DEBUG 01-05 12:51:27.323196.323196 lmp.py:376]   Expert  8 |    216 | GPU
DEBUG 01-05 12:51:27.323746.323746 lmp.py:376]   Expert 16 |    221 | GPU
DEBUG 01-05 12:51:27.323820.323820 lmp.py:376]   Expert  2 |    226 | GPU
DEBUG 01-05 12:51:27.323178.323178 lmp.py:376]   Expert 19 |    227 | GPU
DEBUG 01-05 12:51:27.323013.323013 lmp.py:376]   Expert 33 |    246 | GPU
DEBUG 01-05 12:51:27.323086.323086 lmp.py:376]   Expert  4 |    260 | GPU
DEBUG 01-05 12:51:27.323683.323683 lmp.py:376]   Expert 56 |    261 | GPU
DEBUG 01-05 12:51:27.323518.323518 lmp.py:376]   Expert 34 |    272 | GPU
DEBUG 01-05 12:51:27.323353.323353 lmp.py:376]   Expert 35 |    277 | GPU
DEBUG 01-05 12:51:27.323142.323142 lmp.py:376]   Expert 17 |    278 | GPU
DEBUG 01-05 12:51:27.323215.323215 lmp.py:376]   Expert 23 |    287 | GPU
DEBUG 01-05 12:51:27.323243.323243 lmp.py:376]   Expert 20 |    304 | GPU
DEBUG 01-05 12:51:27.323554.323554 lmp.py:376]   Expert 53 |    314 | GPU
DEBUG 01-05 12:51:27.323389.323389 lmp.py:376]   Expert 29 |    336 | GPU
DEBUG 01-05 12:51:27.323986.323986 lmp.py:376]   Expert 59 |    341 | GPU
DEBUG 01-05 12:51:27.323583.323583 lmp.py:376]   Expert 18 |    350 | GPU
DEBUG 01-05 12:51:27.323941.323941 lmp.py:376]   Expert 25 |    358 | GPU
DEBUG 01-05 12:51:27.323015.323015 lmp.py:376]   Expert 55 |    361 | GPU
DEBUG 01-05 12:51:27.323373.323373 lmp.py:376]   Expert 40 |    370 | GPU
DEBUG 01-05 12:51:27.323969.323969 lmp.py:376]   Expert 14 |    463 | GPU
DEBUG 01-05 12:51:27.323520.323520 lmp.py:376]   Expert 36 |    565 | GPU
DEBUG 01-05 12:51:27.323593.323593 lmp.py:376]   Expert  5 |    612 | GPU
DEBUG 01-05 12:51:27.323859.323859 lmp.py:377] 
DEBUG 01-05 12:51:27.323859.323859 lmp.py:377]   CPU total tokens: 3332 (27.1%)
DEBUG 01-05 12:51:27.323363.323363 lmp.py:378]   GPU total tokens: 8956 (72.9%)
DEBUG 01-05 12:51:27.323681.323681 cuda_h.py:19] end experts_map_get cost 0.0017011165618896484 seconds
DEBUG 01-05 12:51:27.323470.323470 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.323300.323300 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.323159.323159 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.324890.324890 cuda_h.py:19] end allocate_cuda_memory cost 0.0010297298431396484 seconds
DEBUG 01-05 12:51:27.324170.324170 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.324933.324933 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.324418.324418 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.325121.325121 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 198e473c-854a-4cfa-a799-a0a95e79c210
DEBUG 01-05 12:51:27.325692.325692 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.325446.325446 client.py:127] Model loaded
DEBUG 01-05 12:51:27.325991.325991 cuda_h.py:19] end sllm_worker_task cost 0.010015487670898438 seconds
INFO 01-05 12:51:27.326617.326617 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 198e473c-854a-4cfa-a799-a0a95e79c210
DEBUG 01-05 12:51:27.326963.326963 cuda_h.py:19] end load_into_gpu_async cost 0.0012874603271484375 seconds
DEBUG 01-05 12:51:27.326851.326851 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.326520.326520 cuda_h.py:19] end restore_tensors2 cost 0.00036263465881347656 seconds
DEBUG 01-05 12:51:27.326726.326726 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030298233032226562 seconds
DEBUG 01-05 12:51:27.329394.329394 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0058133602142333984 seconds
DEBUG 01-05 12:51:27.329443.329443 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.329168.329168 lmp.py:423] 
DEBUG 01-05 12:51:27.329168.329168 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.329348.329348 cuda_h.py:19] end cpu_experts_submit cost 0.00011277198791503906 seconds
DEBUG 01-05 12:51:27.329283.329283 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.346955.346955 mlpmodule.py:704] group tensors cost 0.016996383666992188 s
DEBUG 01-05 12:51:27.349574.349574 mlpmodule.py:742] pad cost 0.0015761852264404297 s
DEBUG 01-05 12:51:27.349452.349452 mlpmodule.py:748] create cpu tensor cost 5.984306335449219e-05 s
DEBUG 01-05 12:51:27.349448.349448 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-05 12:51:27.358773.358773 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.358081.358081 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.358706.358706 mlpmodule.py:773] group_w3 first element: 0.025390625
WARNING 01-05 12:51:27.358425.358425 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.374011.374011 mlpmodule.py:793] group einsum cost 0.02506542205810547 s
DEBUG 01-05 12:51:27.375380.375380 mlpmodule.py:801] cpy2cputensor cost 0.0005629062652587891 s
DEBUG 01-05 12:51:27.379759.379759 cuda_h.py:19] end wait_cetm_experts cost 0.05013442039489746 seconds
DEBUG 01-05 12:51:27.380480.380480 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.380791.380791 cuda_h.py:19] end gpu_sexperts cost 0.0007157325744628906 seconds
DEBUG 01-05 12:51:27.380523.380523 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.381983.381983 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.6716461181640625e-05 seconds
DEBUG 01-05 12:51:27.381918.381918 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.381933.381933 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 198e473c-854a-4cfa-a799-a0a95e79c210
INFO 01-05 12:51:27.382494.382494 client.py:127] Model loaded
DEBUG 01-05 12:51:27.382358.382358 cuda_h.py:19] end wait_experts cost 0.001219034194946289 seconds
DEBUG 01-05 12:51:27.382579.382579 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.382468.382468 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.383159.383159 mlpmodule.py:531] gpu group tensors cost 0.0011126995086669922 s
DEBUG 01-05 12:51:27.387923.387923 mlpmodule.py:564] gpu pad cost 0.0035126209259033203 s
DEBUG 01-05 12:51:27.388601.388601 mlpmodule.py:582] gpu group einsum cost 0.0007562637329101562 s
DEBUG 01-05 12:51:27.393776.393776 mlpmodule.py:611] gpu experts func einsum cost 0.010458707809448242 s
DEBUG 01-05 12:51:27.393164.393164 cuda_h.py:19] end gpu_experts cost 0.010704278945922852 seconds
DEBUG 01-05 12:51:27.393955.393955 cuda_h.py:19] end layer_moe_generate_22 cost 0.07213139533996582 seconds
DEBUG 01-05 12:51:27.393942.393942 lmp.py:217] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 12:51:27.393434.393434 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 12:51:27.393229.393229 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 12:51:27.393231.393231 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 12:51:27.393411.393411 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 12:51:27.393406.393406 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.818771362304688e-05 seconds
DEBUG 01-05 12:51:27.393817.393817 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.393044.393044 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.393558.393558 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.393056.393056 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.395207.395207 cuda_h.py:19] end allocate_cuda_memory cost 0.0016896724700927734 seconds
DEBUG 01-05 12:51:27.395169.395169 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.395913.395913 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.395213.395213 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.395916.395916 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a95e8bd8-7eec-4fe7-8375-c61833811ac8
DEBUG 01-05 12:51:27.395554.395554 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.396422.396422 mlpmodule.py:662]  experts func einsum cost 0.06618785858154297 s
DEBUG 01-05 12:51:27.396845.396845 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.396445.396445 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a95e8bd8-7eec-4fe7-8375-c61833811ac8
DEBUG 01-05 12:51:27.396904.396904 cuda_h.py:19] end load_into_gpu_async cost 0.0011162757873535156 seconds
DEBUG 01-05 12:51:27.396892.396892 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.396206.396206 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-05 12:51:27.397293.397293 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003145456314086914 seconds
INFO 01-05 12:51:27.397981.397981 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a95e8bd8-7eec-4fe7-8375-c61833811ac8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.400762.400762 cuda_h.py:19] end self_attn cost 0.003926515579223633 seconds
DEBUG 01-05 12:51:27.400911.400911 cuda_h.py:19] end iln_self_attn_paln cost 0.0071294307708740234 seconds
DEBUG 01-05 12:51:27.400523.400523 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 12:51:27.400392.400392 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.401109.401109 cuda_h.py:19] end gate cost 0.000804901123046875 seconds
DEBUG 01-05 12:51:27.401184.401184 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.402599.402599 lmp.py:365] 
DEBUG 01-05 12:51:27.402599.402599 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.402031.402031 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.402356.402356 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.402436.402436 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.402371.402371 lmp.py:369] 
DEBUG 01-05 12:51:27.402371.402371 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.402067.402067 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.402022.402022 lmp.py:376]   Expert  5 |     55 | CPU
DEBUG 01-05 12:51:27.402142.402142 lmp.py:376]   Expert 27 |     64 | CPU
DEBUG 01-05 12:51:27.402546.402546 lmp.py:376]   Expert 49 |     68 | CPU
DEBUG 01-05 12:51:27.402712.402712 lmp.py:376]   Expert 44 |     80 | CPU
DEBUG 01-05 12:51:27.402640.402640 lmp.py:376]   Expert 19 |     82 | CPU
DEBUG 01-05 12:51:27.402568.402568 lmp.py:376]   Expert 17 |     93 | CPU
DEBUG 01-05 12:51:27.402496.402496 lmp.py:376]   Expert 55 |     95 | CPU
DEBUG 01-05 12:51:27.402423.402423 lmp.py:376]   Expert  7 |     98 | CPU
DEBUG 01-05 12:51:27.402351.402351 lmp.py:376]   Expert 53 |    110 | CPU
DEBUG 01-05 12:51:27.402802.402802 lmp.py:376]   Expert 25 |    115 | CPU
DEBUG 01-05 12:51:27.402253.402253 lmp.py:376]   Expert 22 |    119 | CPU
DEBUG 01-05 12:51:27.402180.402180 lmp.py:376]   Expert 40 |    119 | CPU
DEBUG 01-05 12:51:27.402062.402062 lmp.py:376]   Expert 58 |    121 | CPU
DEBUG 01-05 12:51:27.402228.402228 lmp.py:376]   Expert 52 |    122 | CPU
DEBUG 01-05 12:51:27.402633.402633 lmp.py:376]   Expert 34 |    124 | CPU
DEBUG 01-05 12:51:27.402799.402799 lmp.py:376]   Expert 43 |    124 | CPU
DEBUG 01-05 12:51:27.402726.402726 lmp.py:376]   Expert  4 |    126 | CPU
DEBUG 01-05 12:51:27.402654.402654 lmp.py:376]   Expert 35 |    126 | CPU
DEBUG 01-05 12:51:27.402105.402105 lmp.py:376]   Expert 38 |    133 | CPU
DEBUG 01-05 12:51:27.402794.402794 lmp.py:376]   Expert 16 |    135 | CPU
DEBUG 01-05 12:51:27.402484.402484 lmp.py:376]   Expert  6 |    139 | CPU
DEBUG 01-05 12:51:27.402934.402934 lmp.py:376]   Expert  1 |    141 | CPU
DEBUG 01-05 12:51:27.402624.402624 lmp.py:376]   Expert 63 |    141 | CPU
DEBUG 01-05 12:51:27.402075.402075 lmp.py:376]   Expert 42 |    144 | CPU
DEBUG 01-05 12:51:27.402526.402526 lmp.py:376]   Expert 51 |    149 | CPU
DEBUG 01-05 12:51:27.402215.402215 lmp.py:376]   Expert 47 |    155 | CPU
DEBUG 01-05 12:51:27.402904.402904 lmp.py:376]   Expert  9 |    163 | CPU
DEBUG 01-05 12:51:27.402355.402355 lmp.py:376]   Expert 13 |    174 | CPU
DEBUG 01-05 12:51:27.402806.402806 lmp.py:376]   Expert 36 |    180 | CPU
DEBUG 01-05 12:51:27.402495.402495 lmp.py:376]   Expert 45 |    180 | CPU
DEBUG 01-05 12:51:27.402423.402423 lmp.py:376]   Expert  0 |    181 | CPU
DEBUG 01-05 12:51:27.402874.402874 lmp.py:376]   Expert 46 |    183 | CPU
DEBUG 01-05 12:51:27.402325.402325 lmp.py:376]   Expert 30 |    189 | GPU
DEBUG 01-05 12:51:27.402776.402776 lmp.py:376]   Expert 26 |    190 | GPU
DEBUG 01-05 12:51:27.402226.402226 lmp.py:376]   Expert 23 |    196 | GPU
DEBUG 01-05 12:51:27.402916.402916 lmp.py:376]   Expert 11 |    198 | GPU
DEBUG 01-05 12:51:27.402559.402559 lmp.py:376]   Expert  2 |    202 | GPU
DEBUG 01-05 12:51:27.402725.402725 lmp.py:376]   Expert 39 |    203 | GPU
DEBUG 01-05 12:51:27.403129.403129 lmp.py:376]   Expert 28 |    204 | GPU
DEBUG 01-05 12:51:27.403296.403296 lmp.py:376]   Expert 60 |    206 | GPU
DEBUG 01-05 12:51:27.403985.403985 lmp.py:376]   Expert 62 |    207 | GPU
DEBUG 01-05 12:51:27.403913.403913 lmp.py:376]   Expert  3 |    219 | GPU
DEBUG 01-05 12:51:27.403125.403125 lmp.py:376]   Expert 15 |    220 | GPU
DEBUG 01-05 12:51:27.403576.403576 lmp.py:376]   Expert 41 |    221 | GPU
DEBUG 01-05 12:51:27.403788.403788 lmp.py:376]   Expert 12 |    224 | GPU
DEBUG 01-05 12:51:27.403239.403239 lmp.py:376]   Expert 61 |    224 | GPU
DEBUG 01-05 12:51:27.403929.403929 lmp.py:376]   Expert 24 |    227 | GPU
DEBUG 01-05 12:51:27.403379.403379 lmp.py:376]   Expert 29 |    248 | GPU
DEBUG 01-05 12:51:27.403592.403592 lmp.py:376]   Expert 10 |    261 | GPU
DEBUG 01-05 12:51:27.403758.403758 lmp.py:376]   Expert 14 |    261 | GPU
DEBUG 01-05 12:51:27.403686.403686 lmp.py:376]   Expert 21 |    270 | GPU
DEBUG 01-05 12:51:27.403852.403852 lmp.py:376]   Expert 20 |    275 | GPU
DEBUG 01-05 12:51:27.403256.403256 lmp.py:376]   Expert 33 |    278 | GPU
DEBUG 01-05 12:51:27.403946.403946 lmp.py:376]   Expert 32 |    283 | GPU
DEBUG 01-05 12:51:27.403158.403158 lmp.py:376]   Expert  8 |    285 | GPU
DEBUG 01-05 12:51:27.403371.403371 lmp.py:376]   Expert 31 |    287 | GPU
DEBUG 01-05 12:51:27.403060.403060 lmp.py:376]   Expert 57 |    288 | GPU
DEBUG 01-05 12:51:27.403749.403749 lmp.py:376]   Expert 59 |    295 | GPU
DEBUG 01-05 12:51:27.403962.403962 lmp.py:376]   Expert 37 |    298 | GPU
DEBUG 01-05 12:51:27.403174.403174 lmp.py:376]   Expert 18 |    307 | GPU
DEBUG 01-05 12:51:27.403625.403625 lmp.py:376]   Expert 50 |    309 | GPU
DEBUG 01-05 12:51:27.403076.403076 lmp.py:376]   Expert 56 |    363 | GPU
DEBUG 01-05 12:51:27.403481.403481 lmp.py:376]   Expert 48 |    389 | GPU
DEBUG 01-05 12:51:27.403931.403931 lmp.py:376]   Expert 54 |    422 | GPU
DEBUG 01-05 12:51:27.403290.403290 lmp.py:377] 
DEBUG 01-05 12:51:27.403290.403290 lmp.py:377]   CPU total tokens: 4039 (32.9%)
DEBUG 01-05 12:51:27.403933.403933 lmp.py:378]   GPU total tokens: 8249 (67.1%)
DEBUG 01-05 12:51:27.403629.403629 cuda_h.py:19] end experts_map_get cost 0.001596212387084961 seconds
DEBUG 01-05 12:51:27.403033.403033 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.403240.403240 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.403099.403099 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.404887.404887 cuda_h.py:19] end allocate_cuda_memory cost 0.0005471706390380859 seconds
DEBUG 01-05 12:51:27.404889.404889 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.404553.404553 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.404422.404422 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.404071.404071 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f960e924-1550-4afe-a38b-5f5b0be71d6e
DEBUG 01-05 12:51:27.404987.404987 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.404907.404907 client.py:127] Model loaded
DEBUG 01-05 12:51:27.404195.404195 cuda_h.py:19] end sllm_worker_task cost 0.011113405227661133 seconds
INFO 01-05 12:51:27.405715.405715 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f960e924-1550-4afe-a38b-5f5b0be71d6e
DEBUG 01-05 12:51:27.405703.405703 cuda_h.py:19] end load_into_gpu_async cost 0.0013380050659179688 seconds
DEBUG 01-05 12:51:27.405930.405930 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.406962.406962 cuda_h.py:19] end restore_tensors2 cost 0.00034928321838378906 seconds
DEBUG 01-05 12:51:27.406930.406930 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002594470977783203 seconds
DEBUG 01-05 12:51:27.408591.408591 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005369663238525391 seconds
DEBUG 01-05 12:51:27.408918.408918 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.409451.409451 lmp.py:423] 
DEBUG 01-05 12:51:27.409451.409451 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.409347.409347 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-05 12:51:27.409473.409473 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.426717.426717 mlpmodule.py:704] group tensors cost 0.01667308807373047 s
DEBUG 01-05 12:51:27.428210.428210 mlpmodule.py:742] pad cost 0.0016086101531982422 s
DEBUG 01-05 12:51:27.428068.428068 mlpmodule.py:748] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-05 12:51:27.428633.428633 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-05 12:51:27.438584.438584 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.438037.438037 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.438324.438324 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-05 12:51:27.438897.438897 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.455950.455950 mlpmodule.py:793] group einsum cost 0.026215076446533203 s
DEBUG 01-05 12:51:27.455496.455496 mlpmodule.py:801] cpy2cputensor cost 0.0006754398345947266 s
DEBUG 01-05 12:51:27.460793.460793 cuda_h.py:19] end wait_cetm_experts cost 0.051186323165893555 seconds
DEBUG 01-05 12:51:27.460648.460648 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.461346.461346 cuda_h.py:19] end gpu_sexperts cost 0.0007882118225097656 seconds
DEBUG 01-05 12:51:27.461667.461667 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.461439.461439 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.3392181396484375e-05 seconds
DEBUG 01-05 12:51:27.461990.461990 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.461449.461449 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f960e924-1550-4afe-a38b-5f5b0be71d6e
INFO 01-05 12:51:27.462108.462108 client.py:127] Model loaded
DEBUG 01-05 12:51:27.462905.462905 cuda_h.py:19] end wait_experts cost 0.0011501312255859375 seconds
DEBUG 01-05 12:51:27.462277.462277 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.463841.463841 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.463568.463568 mlpmodule.py:531] gpu group tensors cost 0.0006608963012695312 s
DEBUG 01-05 12:51:27.465544.465544 mlpmodule.py:564] gpu pad cost 0.001821756362915039 s
DEBUG 01-05 12:51:27.466374.466374 mlpmodule.py:582] gpu group einsum cost 0.0005574226379394531 s
DEBUG 01-05 12:51:27.469902.469902 mlpmodule.py:611] gpu experts func einsum cost 0.006701231002807617 s
DEBUG 01-05 12:51:27.469522.469522 cuda_h.py:19] end gpu_experts cost 0.006892681121826172 seconds
DEBUG 01-05 12:51:27.469644.469644 cuda_h.py:19] end layer_moe_generate_23 cost 0.06904721260070801 seconds
DEBUG 01-05 12:51:27.470883.470883 lmp.py:217] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 12:51:27.470606.470606 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 12:51:27.470216.470216 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 12:51:27.470602.470602 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 12:51:27.470259.470259 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.3855438232421875e-05 seconds
DEBUG 01-05 12:51:27.470876.470876 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.985664367675781e-05 seconds
DEBUG 01-05 12:51:27.470626.470626 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.470193.470193 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.470475.470475 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.470311.470311 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.471330.471330 cuda_h.py:19] end allocate_cuda_memory cost 0.0003287792205810547 seconds
DEBUG 01-05 12:51:27.471279.471279 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.471181.471181 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.471196.471196 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.471137.471137 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bdbbf1fc-2b8e-4281-a964-0f2a8a77ee86
DEBUG 01-05 12:51:27.471630.471630 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.471191.471191 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.472473.472473 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bdbbf1fc-2b8e-4281-a964-0f2a8a77ee86
DEBUG 01-05 12:51:27.472840.472840 cuda_h.py:19] end load_into_gpu_async cost 0.0010797977447509766 seconds
DEBUG 01-05 12:51:27.472827.472827 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.472838.472838 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-05 12:51:27.472693.472693 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017426013946533203 seconds
INFO 01-05 12:51:27.472313.472313 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bdbbf1fc-2b8e-4281-a964-0f2a8a77ee86
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.475211.475211 cuda_h.py:19] end self_attn cost 0.004061460494995117 seconds
DEBUG 01-05 12:51:27.476579.476579 cuda_h.py:19] end iln_self_attn_paln cost 0.0056874752044677734 seconds
DEBUG 01-05 12:51:27.476660.476660 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 12:51:27.476423.476423 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.476720.476720 mlpmodule.py:662]  experts func einsum cost 0.06702709197998047 s
DEBUG 01-05 12:51:27.477187.477187 cuda_h.py:19] end gate cost 0.0008001327514648438 seconds
DEBUG 01-05 12:51:27.477256.477256 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.477716.477716 lmp.py:365] 
DEBUG 01-05 12:51:27.477716.477716 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.477995.477995 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.477407.477407 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.477480.477480 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.477554.477554 lmp.py:369] 
DEBUG 01-05 12:51:27.477554.477554 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.477342.477342 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.477469.477469 lmp.py:376]   Expert 43 |     65 | CPU
DEBUG 01-05 12:51:27.477066.477066 lmp.py:376]   Expert 47 |     67 | CPU
DEBUG 01-05 12:51:27.477709.477709 lmp.py:376]   Expert 42 |     70 | CPU
DEBUG 01-05 12:51:27.477875.477875 lmp.py:376]   Expert 44 |     76 | CPU
DEBUG 01-05 12:51:27.477279.477279 lmp.py:376]   Expert  6 |     79 | CPU
DEBUG 01-05 12:51:27.477969.477969 lmp.py:376]   Expert 25 |     81 | CPU
DEBUG 01-05 12:51:27.477658.477658 lmp.py:376]   Expert 62 |     88 | CPU
DEBUG 01-05 12:51:27.477016.477016 lmp.py:376]   Expert 35 |     94 | CPU
DEBUG 01-05 12:51:27.477659.477659 lmp.py:376]   Expert 60 |     98 | CPU
DEBUG 01-05 12:51:27.477064.477064 lmp.py:376]   Expert 54 |    100 | CPU
DEBUG 01-05 12:51:27.477707.477707 lmp.py:376]   Expert 48 |    101 | CPU
DEBUG 01-05 12:51:27.477350.477350 lmp.py:376]   Expert  5 |    102 | CPU
DEBUG 01-05 12:51:27.477039.477039 lmp.py:376]   Expert 16 |    105 | CPU
DEBUG 01-05 12:51:27.477443.477443 lmp.py:376]   Expert 29 |    105 | CPU
DEBUG 01-05 12:51:27.477610.477610 lmp.py:376]   Expert 55 |    107 | CPU
DEBUG 01-05 12:51:27.477299.477299 lmp.py:376]   Expert 22 |    125 | CPU
DEBUG 01-05 12:51:27.477227.477227 lmp.py:376]   Expert 56 |    132 | CPU
DEBUG 01-05 12:51:27.477154.477154 lmp.py:376]   Expert 30 |    135 | CPU
DEBUG 01-05 12:51:27.477797.477797 lmp.py:376]   Expert 51 |    143 | CPU
DEBUG 01-05 12:51:27.477202.477202 lmp.py:376]   Expert  4 |    151 | CPU
DEBUG 01-05 12:51:27.477606.477606 lmp.py:376]   Expert 36 |    153 | CPU
DEBUG 01-05 12:51:27.477011.477011 lmp.py:376]   Expert 28 |    159 | CPU
DEBUG 01-05 12:51:27.478700.478700 lmp.py:376]   Expert 61 |    159 | CPU
DEBUG 01-05 12:51:27.478151.478151 lmp.py:376]   Expert  7 |    160 | CPU
DEBUG 01-05 12:51:27.478079.478079 lmp.py:376]   Expert 49 |    160 | CPU
DEBUG 01-05 12:51:27.478007.478007 lmp.py:376]   Expert  1 |    164 | CPU
DEBUG 01-05 12:51:27.478696.478696 lmp.py:376]   Expert 31 |    167 | CPU
DEBUG 01-05 12:51:27.478624.478624 lmp.py:376]   Expert 38 |    168 | CPU
DEBUG 01-05 12:51:27.478313.478313 lmp.py:376]   Expert 17 |    169 | CPU
DEBUG 01-05 12:51:27.478002.478002 lmp.py:376]   Expert 20 |    171 | CPU
DEBUG 01-05 12:51:27.478122.478122 lmp.py:376]   Expert 59 |    174 | CPU
DEBUG 01-05 12:51:27.478003.478003 lmp.py:376]   Expert 21 |    179 | CPU
DEBUG 01-05 12:51:27.478170.478170 lmp.py:376]   Expert 46 |    183 | GPU
DEBUG 01-05 12:51:27.478336.478336 lmp.py:376]   Expert 14 |    184 | GPU
DEBUG 01-05 12:51:27.478025.478025 lmp.py:376]   Expert 34 |    189 | GPU
DEBUG 01-05 12:51:27.478953.478953 lmp.py:376]   Expert  0 |    190 | GPU
DEBUG 01-05 12:51:27.478880.478880 lmp.py:376]   Expert 15 |    195 | GPU
DEBUG 01-05 12:51:27.478570.478570 lmp.py:376]   Expert  3 |    202 | GPU
DEBUG 01-05 12:51:27.478497.478497 lmp.py:376]   Expert 40 |    204 | GPU
DEBUG 01-05 12:51:27.478187.478187 lmp.py:376]   Expert 53 |    204 | GPU
DEBUG 01-05 12:51:27.478638.478638 lmp.py:376]   Expert 41 |    208 | GPU
DEBUG 01-05 12:51:27.478089.478089 lmp.py:376]   Expert 63 |    210 | GPU
DEBUG 01-05 12:51:27.478778.478778 lmp.py:376]   Expert 19 |    214 | GPU
DEBUG 01-05 12:51:27.478467.478467 lmp.py:376]   Expert 24 |    218 | GPU
DEBUG 01-05 12:51:27.478872.478872 lmp.py:376]   Expert 37 |    220 | GPU
DEBUG 01-05 12:51:27.478515.478515 lmp.py:376]   Expert  2 |    224 | GPU
DEBUG 01-05 12:51:27.478681.478681 lmp.py:376]   Expert 57 |    224 | GPU
DEBUG 01-05 12:51:27.478370.478370 lmp.py:376]   Expert 10 |    238 | GPU
DEBUG 01-05 12:51:27.478583.478583 lmp.py:376]   Expert 26 |    243 | GPU
DEBUG 01-05 12:51:27.478033.478033 lmp.py:376]   Expert 23 |    244 | GPU
DEBUG 01-05 12:51:27.478484.478484 lmp.py:376]   Expert 50 |    244 | GPU
DEBUG 01-05 12:51:27.478174.478174 lmp.py:376]   Expert 45 |    250 | GPU
DEBUG 01-05 12:51:27.478386.478386 lmp.py:376]   Expert 58 |    252 | GPU
DEBUG 01-05 12:51:27.478075.478075 lmp.py:376]   Expert 32 |    254 | GPU
DEBUG 01-05 12:51:27.478003.478003 lmp.py:376]   Expert 52 |    260 | GPU
DEBUG 01-05 12:51:27.478692.478692 lmp.py:376]   Expert  9 |    271 | GPU
DEBUG 01-05 12:51:27.478905.478905 lmp.py:376]   Expert 12 |    288 | GPU
DEBUG 01-05 12:51:27.478594.478594 lmp.py:376]   Expert 18 |    290 | GPU
DEBUG 01-05 12:51:27.478045.478045 lmp.py:376]   Expert 13 |    309 | GPU
DEBUG 01-05 12:51:27.478688.478688 lmp.py:376]   Expert 33 |    334 | GPU
DEBUG 01-05 12:51:27.478616.478616 lmp.py:376]   Expert 39 |    339 | GPU
DEBUG 01-05 12:51:27.478543.478543 lmp.py:376]   Expert  8 |    357 | GPU
DEBUG 01-05 12:51:27.478948.478948 lmp.py:376]   Expert 11 |    374 | GPU
DEBUG 01-05 12:51:27.478876.478876 lmp.py:376]   Expert 27 |    665 | GPU
DEBUG 01-05 12:51:27.478757.478757 lmp.py:377] 
DEBUG 01-05 12:51:27.478757.478757 lmp.py:377]   CPU total tokens: 4007 (32.6%)
DEBUG 01-05 12:51:27.478162.478162 lmp.py:378]   GPU total tokens: 8281 (67.4%)
DEBUG 01-05 12:51:27.478858.478858 cuda_h.py:19] end experts_map_get cost 0.0015397071838378906 seconds
DEBUG 01-05 12:51:27.478501.478501 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.478661.478661 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.478143.478143 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.479637.479637 cuda_h.py:19] end allocate_cuda_memory cost 0.000293731689453125 seconds
DEBUG 01-05 12:51:27.479156.479156 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.479912.479912 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.479251.479251 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.479616.479616 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d68213b-6135-4012-926e-ee6f05e9bf38
DEBUG 01-05 12:51:27.479550.479550 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.479397.479397 client.py:127] Model loaded
DEBUG 01-05 12:51:27.479286.479286 cuda_h.py:19] end sllm_worker_task cost 0.009207010269165039 seconds
INFO 01-05 12:51:27.480242.480242 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d68213b-6135-4012-926e-ee6f05e9bf38
DEBUG 01-05 12:51:27.480231.480231 cuda_h.py:19] end load_into_gpu_async cost 0.0012159347534179688 seconds
DEBUG 01-05 12:51:27.480934.480934 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.481483.481483 cuda_h.py:19] end restore_tensors2 cost 0.00034356117248535156 seconds
DEBUG 01-05 12:51:27.481021.481021 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022084712982177734 seconds
DEBUG 01-05 12:51:27.483373.483373 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004865407943725586 seconds
DEBUG 01-05 12:51:27.483455.483455 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.483199.483199 lmp.py:423] 
DEBUG 01-05 12:51:27.483199.483199 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.483811.483811 cuda_h.py:19] end cpu_experts_submit cost 0.00011372566223144531 seconds
DEBUG 01-05 12:51:27.483560.483560 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.493362.493362 mlpmodule.py:704] group tensors cost 0.009334325790405273 s
DEBUG 01-05 12:51:27.495387.495387 mlpmodule.py:742] pad cost 0.001605987548828125 s
DEBUG 01-05 12:51:27.495206.495206 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-05 12:51:27.495440.495440 mlpmodule.py:753] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-05 12:51:27.504202.504202 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.504490.504490 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.504367.504367 mlpmodule.py:773] group_w3 first element: -0.019287109375
WARNING 01-05 12:51:27.504755.504755 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.521483.521483 mlpmodule.py:793] group einsum cost 0.02555561065673828 s
DEBUG 01-05 12:51:27.522812.522812 mlpmodule.py:801] cpy2cputensor cost 0.0007338523864746094 s
DEBUG 01-05 12:51:27.526693.526693 cuda_h.py:19] end wait_cetm_experts cost 0.04285788536071777 seconds
DEBUG 01-05 12:51:27.527924.527924 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.527090.527090 cuda_h.py:19] end gpu_sexperts cost 0.0005702972412109375 seconds
DEBUG 01-05 12:51:27.527933.527933 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.527558.527558 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.337860107421875e-05 seconds
DEBUG 01-05 12:51:27.527122.527122 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.527832.527832 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d68213b-6135-4012-926e-ee6f05e9bf38
INFO 01-05 12:51:27.535464.535464 client.py:127] Model loaded
DEBUG 01-05 12:51:27.535274.535274 cuda_h.py:19] end wait_experts cost 0.0076634883880615234 seconds
DEBUG 01-05 12:51:27.535030.535030 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.535455.535455 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.536824.536824 mlpmodule.py:531] gpu group tensors cost 0.0006401538848876953 s
DEBUG 01-05 12:51:27.537052.537052 mlpmodule.py:564] gpu pad cost 0.0016226768493652344 s
DEBUG 01-05 12:51:27.538166.538166 mlpmodule.py:582] gpu group einsum cost 0.0005695819854736328 s
DEBUG 01-05 12:51:27.541868.541868 mlpmodule.py:611] gpu experts func einsum cost 0.0057299137115478516 s
DEBUG 01-05 12:51:27.541071.541071 cuda_h.py:19] end gpu_experts cost 0.005934715270996094 seconds
DEBUG 01-05 12:51:27.541407.541407 mlpmodule.py:662]  experts func einsum cost 0.057559967041015625 s
DEBUG 01-05 12:51:27.541835.541835 cuda_h.py:19] end layer_moe_generate_24 cost 0.06548571586608887 seconds
DEBUG 01-05 12:51:27.542865.542865 lmp.py:217] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 12:51:27.542887.542887 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 12:51:27.542629.542629 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 12:51:27.542054.542054 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 12:51:27.542182.542182 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.24249267578125e-05 seconds
DEBUG 01-05 12:51:27.542236.542236 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.843971252441406e-05 seconds
DEBUG 01-05 12:51:27.542833.542833 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.542292.542292 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.542078.542078 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.542014.542014 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.542966.542966 cuda_h.py:19] end allocate_cuda_memory cost 0.00031447410583496094 seconds
DEBUG 01-05 12:51:27.543843.543843 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.543652.543652 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.543521.543521 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.543317.543317 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4dd2566b-4963-41e6-969f-b5634b0969ce
DEBUG 01-05 12:51:27.543360.543360 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.543322.543322 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.544312.544312 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4dd2566b-4963-41e6-969f-b5634b0969ce
DEBUG 01-05 12:51:27.544354.544354 cuda_h.py:19] end load_into_gpu_async cost 0.001567840576171875 seconds
DEBUG 01-05 12:51:27.544541.544541 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.544220.544220 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-05 12:51:27.544142.544142 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022547245025634766 seconds
INFO 01-05 12:51:27.545559.545559 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4dd2566b-4963-41e6-969f-b5634b0969ce
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.546558.546558 cuda_h.py:19] end self_attn cost 0.0034143924713134766 seconds
DEBUG 01-05 12:51:27.547581.547581 cuda_h.py:19] end iln_self_attn_paln cost 0.004822731018066406 seconds
DEBUG 01-05 12:51:27.547086.547086 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 12:51:27.547372.547372 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.547076.547076 cuda_h.py:19] end gate cost 0.0006260871887207031 seconds
DEBUG 01-05 12:51:27.548999.548999 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.548161.548161 lmp.py:365] 
DEBUG 01-05 12:51:27.548161.548161 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.548725.548725 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.548911.548911 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.548415.548415 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.548104.548104 lmp.py:369] 
DEBUG 01-05 12:51:27.548104.548104 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.548701.548701 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.548066.548066 lmp.py:376]   Expert 36 |     46 | CPU
DEBUG 01-05 12:51:27.548948.548948 lmp.py:376]   Expert 18 |     55 | CPU
DEBUG 01-05 12:51:27.548398.548398 lmp.py:376]   Expert 33 |     58 | CPU
DEBUG 01-05 12:51:27.548611.548611 lmp.py:376]   Expert 42 |     58 | CPU
DEBUG 01-05 12:51:27.548823.548823 lmp.py:376]   Expert 13 |     60 | CPU
DEBUG 01-05 12:51:27.548274.548274 lmp.py:376]   Expert  0 |     70 | CPU
DEBUG 01-05 12:51:27.548248.548248 lmp.py:376]   Expert 16 |     83 | CPU
DEBUG 01-05 12:51:27.548461.548461 lmp.py:376]   Expert 47 |     84 | CPU
DEBUG 01-05 12:51:27.548673.548673 lmp.py:376]   Expert 62 |     87 | CPU
DEBUG 01-05 12:51:27.548409.548409 lmp.py:376]   Expert 10 |     94 | CPU
DEBUG 01-05 12:51:27.548860.548860 lmp.py:376]   Expert 21 |     94 | CPU
DEBUG 01-05 12:51:27.548072.548072 lmp.py:376]   Expert 22 |     94 | CPU
DEBUG 01-05 12:51:27.548477.548477 lmp.py:376]   Expert 38 |    100 | CPU
DEBUG 01-05 12:51:27.548928.548928 lmp.py:376]   Expert 27 |    114 | CPU
DEBUG 01-05 12:51:27.548617.548617 lmp.py:376]   Expert 34 |    114 | CPU
DEBUG 01-05 12:51:27.548545.548545 lmp.py:376]   Expert 50 |    114 | CPU
DEBUG 01-05 12:51:27.548995.548995 lmp.py:376]   Expert  5 |    115 | CPU
DEBUG 01-05 12:51:27.548877.548877 lmp.py:376]   Expert 53 |    115 | CPU
DEBUG 01-05 12:51:27.548043.548043 lmp.py:376]   Expert 59 |    118 | CPU
DEBUG 01-05 12:51:27.548209.548209 lmp.py:376]   Expert 43 |    125 | CPU
DEBUG 01-05 12:51:27.548898.548898 lmp.py:376]   Expert 48 |    125 | CPU
DEBUG 01-05 12:51:27.548826.548826 lmp.py:376]   Expert 20 |    127 | CPU
DEBUG 01-05 12:51:27.548277.548277 lmp.py:376]   Expert 56 |    129 | CPU
DEBUG 01-05 12:51:27.548966.548966 lmp.py:376]   Expert  2 |    131 | CPU
DEBUG 01-05 12:51:27.548894.548894 lmp.py:376]   Expert 44 |    133 | CPU
DEBUG 01-05 12:51:27.548537.548537 lmp.py:376]   Expert 41 |    134 | CPU
DEBUG 01-05 12:51:27.548942.548942 lmp.py:376]   Expert 14 |    135 | CPU
DEBUG 01-05 12:51:27.548346.548346 lmp.py:376]   Expert 32 |    139 | CPU
DEBUG 01-05 12:51:27.548751.548751 lmp.py:376]   Expert  3 |    141 | CPU
DEBUG 01-05 12:51:27.548678.548678 lmp.py:376]   Expert 24 |    143 | CPU
DEBUG 01-05 12:51:27.548368.548368 lmp.py:376]   Expert 31 |    145 | CPU
DEBUG 01-05 12:51:27.548580.548580 lmp.py:376]   Expert  4 |    148 | CPU
DEBUG 01-05 12:51:27.549508.549508 lmp.py:376]   Expert 23 |    156 | GPU
DEBUG 01-05 12:51:27.549197.549197 lmp.py:376]   Expert 55 |    163 | GPU
DEBUG 01-05 12:51:27.549648.549648 lmp.py:376]   Expert 45 |    165 | GPU
DEBUG 01-05 12:51:27.549861.549861 lmp.py:376]   Expert 46 |    169 | GPU
DEBUG 01-05 12:51:27.549311.549311 lmp.py:376]   Expert 39 |    179 | GPU
DEBUG 01-05 12:51:27.549001.549001 lmp.py:376]   Expert  6 |    182 | GPU
DEBUG 01-05 12:51:27.549452.549452 lmp.py:376]   Expert 61 |    196 | GPU
DEBUG 01-05 12:51:27.549141.549141 lmp.py:376]   Expert 51 |    197 | GPU
DEBUG 01-05 12:51:27.549115.549115 lmp.py:376]   Expert 52 |    197 | GPU
DEBUG 01-05 12:51:27.549804.549804 lmp.py:376]   Expert  1 |    203 | GPU
DEBUG 01-05 12:51:27.549732.549732 lmp.py:376]   Expert  8 |    213 | GPU
DEBUG 01-05 12:51:27.549660.549660 lmp.py:376]   Expert 12 |    216 | GPU
DEBUG 01-05 12:51:27.549587.549587 lmp.py:376]   Expert 11 |    222 | GPU
DEBUG 01-05 12:51:27.549992.549992 lmp.py:376]   Expert 40 |    227 | GPU
DEBUG 01-05 12:51:27.549443.549443 lmp.py:376]   Expert 35 |    231 | GPU
DEBUG 01-05 12:51:27.549894.549894 lmp.py:376]   Expert  7 |    234 | GPU
DEBUG 01-05 12:51:27.549345.549345 lmp.py:376]   Expert 37 |    253 | GPU
DEBUG 01-05 12:51:27.549796.549796 lmp.py:376]   Expert 15 |    257 | GPU
DEBUG 01-05 12:51:27.549008.549008 lmp.py:376]   Expert 49 |    258 | GPU
DEBUG 01-05 12:51:27.549459.549459 lmp.py:376]   Expert 57 |    289 | GPU
DEBUG 01-05 12:51:27.549910.549910 lmp.py:376]   Expert 26 |    290 | GPU
DEBUG 01-05 12:51:27.549361.549361 lmp.py:376]   Expert 28 |    299 | GPU
DEBUG 01-05 12:51:27.549050.549050 lmp.py:376]   Expert 30 |    305 | GPU
DEBUG 01-05 12:51:27.549216.549216 lmp.py:376]   Expert 63 |    322 | GPU
DEBUG 01-05 12:51:27.549382.549382 lmp.py:376]   Expert 58 |    328 | GPU
DEBUG 01-05 12:51:27.549310.549310 lmp.py:376]   Expert 54 |    369 | GPU
DEBUG 01-05 12:51:27.549761.549761 lmp.py:376]   Expert 25 |    373 | GPU
DEBUG 01-05 12:51:27.549735.549735 lmp.py:376]   Expert  9 |    403 | GPU
DEBUG 01-05 12:51:27.549186.549186 lmp.py:376]   Expert 17 |    426 | GPU
DEBUG 01-05 12:51:27.549637.549637 lmp.py:376]   Expert 60 |    461 | GPU
DEBUG 01-05 12:51:27.549611.549611 lmp.py:376]   Expert 29 |    505 | GPU
DEBUG 01-05 12:51:27.549062.549062 lmp.py:376]   Expert 19 |    572 | GPU
DEBUG 01-05 12:51:27.549705.549705 lmp.py:377] 
DEBUG 01-05 12:51:27.549705.549705 lmp.py:377]   CPU total tokens: 3428 (27.9%)
DEBUG 01-05 12:51:27.549301.549301 lmp.py:378]   GPU total tokens: 8860 (72.1%)
DEBUG 01-05 12:51:27.549236.549236 cuda_h.py:19] end experts_map_get cost 0.001516580581665039 seconds
DEBUG 01-05 12:51:27.549594.549594 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.549086.549086 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.549898.549898 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.551630.551630 cuda_h.py:19] end allocate_cuda_memory cost 0.002050161361694336 seconds
DEBUG 01-05 12:51:27.551315.551315 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.551979.551979 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.552218.552218 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.552106.552106 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1dee18f4-1e47-49af-be35-2aa9c1f2964d
DEBUG 01-05 12:51:27.552795.552795 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.552656.552656 client.py:127] Model loaded
DEBUG 01-05 12:51:27.552082.552082 cuda_h.py:19] end sllm_worker_task cost 0.010191917419433594 seconds
INFO 01-05 12:51:27.554644.554644 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1dee18f4-1e47-49af-be35-2aa9c1f2964d
DEBUG 01-05 12:51:27.554494.554494 cuda_h.py:19] end load_into_gpu_async cost 0.0021333694458007812 seconds
DEBUG 01-05 12:51:27.554217.554217 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.554308.554308 cuda_h.py:19] end restore_tensors2 cost 0.0003230571746826172 seconds
DEBUG 01-05 12:51:27.554085.554085 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004893779754638672 seconds
DEBUG 01-05 12:51:27.557116.557116 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007659912109375 seconds
DEBUG 01-05 12:51:27.557913.557913 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.557161.557161 lmp.py:423] 
DEBUG 01-05 12:51:27.557161.557161 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.557434.557434 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 12:51:27.557183.557183 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.568572.568572 mlpmodule.py:704] group tensors cost 0.010385751724243164 s
DEBUG 01-05 12:51:27.570825.570825 mlpmodule.py:742] pad cost 0.001680135726928711 s
DEBUG 01-05 12:51:27.570829.570829 mlpmodule.py:748] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-05 12:51:27.570964.570964 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-05 12:51:27.579448.579448 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.579729.579729 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.579785.579785 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 12:51:27.579888.579888 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.594805.594805 mlpmodule.py:793] group einsum cost 0.023476600646972656 s
DEBUG 01-05 12:51:27.595156.595156 mlpmodule.py:801] cpy2cputensor cost 0.0006117820739746094 s
DEBUG 01-05 12:51:27.599856.599856 cuda_h.py:19] end wait_cetm_experts cost 0.041957855224609375 seconds
DEBUG 01-05 12:51:27.599027.599027 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.600392.600392 cuda_h.py:19] end gpu_sexperts cost 0.0005757808685302734 seconds
DEBUG 01-05 12:51:27.600216.600216 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.600609.600609 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.2901763916015625e-05 seconds
DEBUG 01-05 12:51:27.600888.600888 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.600075.600075 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1dee18f4-1e47-49af-be35-2aa9c1f2964d
INFO 01-05 12:51:27.608618.608618 client.py:127] Model loaded
DEBUG 01-05 12:51:27.608567.608567 cuda_h.py:19] end wait_experts cost 0.007983207702636719 seconds
DEBUG 01-05 12:51:27.608131.608131 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.608841.608841 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.609799.609799 mlpmodule.py:531] gpu group tensors cost 0.0006501674652099609 s
DEBUG 01-05 12:51:27.610702.610702 mlpmodule.py:564] gpu pad cost 0.001589059829711914 s
DEBUG 01-05 12:51:27.611271.611271 mlpmodule.py:582] gpu group einsum cost 0.00047850608825683594 s
DEBUG 01-05 12:51:27.614709.614709 mlpmodule.py:662]  experts func einsum cost 0.056441545486450195 s
DEBUG 01-05 12:51:27.614591.614591 mlpmodule.py:611] gpu experts func einsum cost 0.005896091461181641 s
DEBUG 01-05 12:51:27.614576.614576 cuda_h.py:19] end gpu_experts cost 0.006127595901489258 seconds
DEBUG 01-05 12:51:27.614492.614492 cuda_h.py:19] end layer_moe_generate_25 cost 0.0674738883972168 seconds
DEBUG 01-05 12:51:27.614922.614922 lmp.py:217] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 12:51:27.615546.615546 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 12:51:27.615573.615573 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 12:51:27.615660.615660 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 12:51:27.615496.615496 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.0994415283203125e-05 seconds
DEBUG 01-05 12:51:27.615027.615027 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.534027099609375e-05 seconds
DEBUG 01-05 12:51:27.615101.615101 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.615375.615375 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:27.615856.615856 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.615157.615157 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.615052.615052 cuda_h.py:19] end allocate_cuda_memory cost 0.00036907196044921875 seconds
DEBUG 01-05 12:51:27.615412.615412 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.616851.616851 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.616568.616568 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.616662.616662 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d68a3e87-9b11-4939-8b3d-ddabc67b56f3
DEBUG 01-05 12:51:27.616129.616129 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:27.616302.616302 cuda_h.py:10] start self_attn
INFO 01-05 12:51:27.617602.617602 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d68a3e87-9b11-4939-8b3d-ddabc67b56f3
DEBUG 01-05 12:51:27.617359.617359 cuda_h.py:19] end load_into_gpu_async cost 0.0015316009521484375 seconds
DEBUG 01-05 12:51:27.617307.617307 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.617887.617887 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-05 12:51:27.617557.617557 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022847652435302734 seconds
INFO 01-05 12:51:27.618854.618854 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d68a3e87-9b11-4939-8b3d-ddabc67b56f3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.619663.619663 cuda_h.py:19] end self_attn cost 0.003400087356567383 seconds
DEBUG 01-05 12:51:27.620832.620832 cuda_h.py:19] end iln_self_attn_paln cost 0.005004405975341797 seconds
DEBUG 01-05 12:51:27.620338.620338 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 12:51:27.620100.620100 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.620341.620341 cuda_h.py:19] end gate cost 0.0006358623504638672 seconds
DEBUG 01-05 12:51:27.621025.621025 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.621479.621479 lmp.py:365] 
DEBUG 01-05 12:51:27.621479.621479 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.621804.621804 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.621216.621216 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.621289.621289 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.621694.621694 lmp.py:369] 
DEBUG 01-05 12:51:27.621694.621694 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.621337.621337 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.621940.621940 lmp.py:376]   Expert 17 |     54 | CPU
DEBUG 01-05 12:51:27.621868.621868 lmp.py:376]   Expert  3 |     59 | CPU
DEBUG 01-05 12:51:27.621080.621080 lmp.py:376]   Expert 19 |     61 | CPU
DEBUG 01-05 12:51:27.621293.621293 lmp.py:376]   Expert 62 |     64 | CPU
DEBUG 01-05 12:51:27.621028.621028 lmp.py:376]   Expert 30 |     70 | CPU
DEBUG 01-05 12:51:27.621479.621479 lmp.py:376]   Expert 49 |     70 | CPU
DEBUG 01-05 12:51:27.621215.621215 lmp.py:376]   Expert 58 |     71 | CPU
DEBUG 01-05 12:51:27.621189.621189 lmp.py:376]   Expert 59 |     76 | CPU
DEBUG 01-05 12:51:27.621401.621401 lmp.py:376]   Expert 55 |     82 | CPU
DEBUG 01-05 12:51:27.621375.621375 lmp.py:376]   Expert 24 |     86 | CPU
DEBUG 01-05 12:51:27.621349.621349 lmp.py:376]   Expert  9 |     88 | CPU
DEBUG 01-05 12:51:27.621800.621800 lmp.py:376]   Expert 51 |     88 | CPU
DEBUG 01-05 12:51:27.621251.621251 lmp.py:376]   Expert  8 |     89 | CPU
DEBUG 01-05 12:51:27.621609.621609 lmp.py:376]   Expert 61 |     91 | CPU
DEBUG 01-05 12:51:27.621014.621014 lmp.py:376]   Expert  7 |     93 | CPU
DEBUG 01-05 12:51:27.621180.621180 lmp.py:376]   Expert 15 |     93 | CPU
DEBUG 01-05 12:51:27.621108.621108 lmp.py:376]   Expert 60 |     98 | CPU
DEBUG 01-05 12:51:27.621036.621036 lmp.py:376]   Expert  6 |    101 | CPU
DEBUG 01-05 12:51:27.621486.621486 lmp.py:376]   Expert 56 |    101 | CPU
DEBUG 01-05 12:51:27.621176.621176 lmp.py:376]   Expert 21 |    105 | CPU
DEBUG 01-05 12:51:27.621103.621103 lmp.py:376]   Expert 43 |    114 | CPU
DEBUG 01-05 12:51:27.621793.621793 lmp.py:376]   Expert 12 |    115 | CPU
DEBUG 01-05 12:51:27.621482.621482 lmp.py:376]   Expert 11 |    118 | CPU
DEBUG 01-05 12:51:27.621695.621695 lmp.py:376]   Expert 13 |    120 | CPU
DEBUG 01-05 12:51:27.621384.621384 lmp.py:376]   Expert 26 |    137 | CPU
DEBUG 01-05 12:51:27.621073.621073 lmp.py:376]   Expert  0 |    140 | CPU
DEBUG 01-05 12:51:27.621001.621001 lmp.py:376]   Expert 27 |    141 | CPU
DEBUG 01-05 12:51:27.621452.621452 lmp.py:376]   Expert 47 |    141 | CPU
DEBUG 01-05 12:51:27.621141.621141 lmp.py:376]   Expert 22 |    143 | CPU
DEBUG 01-05 12:51:27.621546.621546 lmp.py:376]   Expert 38 |    143 | CPU
DEBUG 01-05 12:51:27.621473.621473 lmp.py:376]   Expert 28 |    145 | CPU
DEBUG 01-05 12:51:27.621639.621639 lmp.py:376]   Expert 41 |    146 | CPU
DEBUG 01-05 12:51:27.621282.621282 lmp.py:376]   Expert 53 |    146 | GPU
DEBUG 01-05 12:51:27.621210.621210 lmp.py:376]   Expert 29 |    148 | GPU
DEBUG 01-05 12:51:27.622138.622138 lmp.py:376]   Expert 34 |    152 | GPU
DEBUG 01-05 12:51:27.622827.622827 lmp.py:376]   Expert 45 |    155 | GPU
DEBUG 01-05 12:51:27.622516.622516 lmp.py:376]   Expert 48 |    175 | GPU
DEBUG 01-05 12:51:27.622683.622683 lmp.py:376]   Expert 37 |    179 | GPU
DEBUG 01-05 12:51:27.622133.622133 lmp.py:376]   Expert 57 |    181 | GPU
DEBUG 01-05 12:51:27.622061.622061 lmp.py:376]   Expert 32 |    187 | GPU
DEBUG 01-05 12:51:27.622227.622227 lmp.py:376]   Expert 23 |    194 | GPU
DEBUG 01-05 12:51:27.622155.622155 lmp.py:376]   Expert  1 |    199 | GPU
DEBUG 01-05 12:51:27.622321.622321 lmp.py:376]   Expert 42 |    203 | GPU
DEBUG 01-05 12:51:27.622203.622203 lmp.py:376]   Expert 36 |    209 | GPU
DEBUG 01-05 12:51:27.622846.622846 lmp.py:376]   Expert 54 |    219 | GPU
DEBUG 01-05 12:51:27.622489.622489 lmp.py:376]   Expert  4 |    225 | GPU
DEBUG 01-05 12:51:27.622847.622847 lmp.py:376]   Expert 39 |    226 | GPU
DEBUG 01-05 12:51:27.622536.622536 lmp.py:376]   Expert 31 |    247 | GPU
DEBUG 01-05 12:51:27.622464.622464 lmp.py:376]   Expert 16 |    253 | GPU
DEBUG 01-05 12:51:27.622915.622915 lmp.py:376]   Expert 33 |    264 | GPU
DEBUG 01-05 12:51:27.622842.622842 lmp.py:376]   Expert 20 |    266 | GPU
DEBUG 01-05 12:51:27.622009.622009 lmp.py:376]   Expert  2 |    280 | GPU
DEBUG 01-05 12:51:27.622175.622175 lmp.py:376]   Expert 44 |    305 | GPU
DEBUG 01-05 12:51:27.622102.622102 lmp.py:376]   Expert 18 |    314 | GPU
DEBUG 01-05 12:51:27.622553.622553 lmp.py:376]   Expert 50 |    325 | GPU
DEBUG 01-05 12:51:27.622719.622719 lmp.py:376]   Expert 25 |    326 | GPU
DEBUG 01-05 12:51:27.622124.622124 lmp.py:376]   Expert  5 |    333 | GPU
DEBUG 01-05 12:51:27.622529.622529 lmp.py:376]   Expert 35 |    362 | GPU
DEBUG 01-05 12:51:27.622410.622410 lmp.py:376]   Expert 10 |    364 | GPU
DEBUG 01-05 12:51:27.622338.622338 lmp.py:376]   Expert 63 |    400 | GPU
DEBUG 01-05 12:51:27.622789.622789 lmp.py:376]   Expert 40 |    461 | GPU
DEBUG 01-05 12:51:27.622478.622478 lmp.py:376]   Expert 46 |    462 | GPU
DEBUG 01-05 12:51:27.622929.622929 lmp.py:376]   Expert 52 |    510 | GPU
DEBUG 01-05 12:51:27.622141.622141 lmp.py:376]   Expert 14 |    775 | GPU
DEBUG 01-05 12:51:27.622023.622023 lmp.py:377] 
DEBUG 01-05 12:51:27.622023.622023 lmp.py:377]   CPU total tokens: 3243 (26.4%)
DEBUG 01-05 12:51:27.622666.622666 lmp.py:378]   GPU total tokens: 9045 (73.6%)
DEBUG 01-05 12:51:27.622123.622123 cuda_h.py:19] end experts_map_get cost 0.001519918441772461 seconds
DEBUG 01-05 12:51:27.622766.622766 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.622304.622304 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.622494.622494 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.624206.624206 cuda_h.py:19] end allocate_cuda_memory cost 0.002035856246948242 seconds
DEBUG 01-05 12:51:27.624718.624718 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.624951.624951 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.624098.624098 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.624178.624178 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2c538cc7-bef1-402e-8506-c408c748b671
DEBUG 01-05 12:51:27.625728.625728 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.625312.625312 client.py:127] Model loaded
DEBUG 01-05 12:51:27.625189.625189 cuda_h.py:19] end sllm_worker_task cost 0.010152101516723633 seconds
INFO 01-05 12:51:27.626034.626034 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2c538cc7-bef1-402e-8506-c408c748b671
DEBUG 01-05 12:51:27.626307.626307 cuda_h.py:19] end load_into_gpu_async cost 0.0013484954833984375 seconds
DEBUG 01-05 12:51:27.626533.626533 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.626638.626638 cuda_h.py:19] end restore_tensors2 cost 0.00033354759216308594 seconds
DEBUG 01-05 12:51:27.626745.626745 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004060506820678711 seconds
DEBUG 01-05 12:51:27.629525.629525 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006817817687988281 seconds
DEBUG 01-05 12:51:27.629785.629785 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.629510.629510 lmp.py:423] 
DEBUG 01-05 12:51:27.629510.629510 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.629452.629452 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-05 12:51:27.629056.629056 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.635260.635260 mlpmodule.py:704] group tensors cost 0.0059010982513427734 s
DEBUG 01-05 12:51:27.638077.638077 mlpmodule.py:742] pad cost 0.002022266387939453 s
DEBUG 01-05 12:51:27.638823.638823 mlpmodule.py:748] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-05 12:51:27.638885.638885 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 12:51:27.647970.647970 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.647258.647258 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.647314.647314 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 12:51:27.647132.647132 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.662304.662304 mlpmodule.py:793] group einsum cost 0.023503541946411133 s
DEBUG 01-05 12:51:27.663687.663687 mlpmodule.py:801] cpy2cputensor cost 0.0005934238433837891 s
DEBUG 01-05 12:51:27.667529.667529 cuda_h.py:19] end wait_cetm_experts cost 0.03781294822692871 seconds
DEBUG 01-05 12:51:27.667839.667839 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.668422.668422 cuda_h.py:19] end gpu_sexperts cost 0.0005619525909423828 seconds
DEBUG 01-05 12:51:27.668464.668464 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.668918.668918 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-05 12:51:27.668528.668528 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.668714.668714 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2c538cc7-bef1-402e-8506-c408c748b671
DEBUG 01-05 12:51:27.681963.681963 mlpmodule.py:662]  experts func einsum cost 0.05124855041503906 s
INFO 01-05 12:51:27.681264.681264 client.py:127] Model loaded
DEBUG 01-05 12:51:27.681754.681754 cuda_h.py:19] end wait_experts cost 0.013211250305175781 seconds
DEBUG 01-05 12:51:27.681438.681438 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.681309.681309 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.682199.682199 mlpmodule.py:531] gpu group tensors cost 0.0005297660827636719 s
DEBUG 01-05 12:51:27.684084.684084 mlpmodule.py:564] gpu pad cost 0.0014352798461914062 s
DEBUG 01-05 12:51:27.684720.684720 mlpmodule.py:582] gpu group einsum cost 0.0005390644073486328 s
DEBUG 01-05 12:51:27.687611.687611 mlpmodule.py:611] gpu experts func einsum cost 0.005504608154296875 s
DEBUG 01-05 12:51:27.687250.687250 cuda_h.py:19] end gpu_experts cost 0.005765199661254883 seconds
DEBUG 01-05 12:51:27.687742.687742 cuda_h.py:19] end layer_moe_generate_26 cost 0.06743717193603516 seconds
DEBUG 01-05 12:51:27.687325.687325 lmp.py:217] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 12:51:27.687472.687472 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 12:51:27.687691.687691 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 12:51:27.688361.688361 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.239776611328125e-05 seconds
DEBUG 01-05 12:51:27.688673.688673 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:27.688206.688206 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:27.690800.690800 cuda_h.py:19] end self_attn cost 0.002454042434692383 seconds
DEBUG 01-05 12:51:27.691571.691571 cuda_h.py:19] end iln_self_attn_paln cost 0.003056049346923828 seconds
DEBUG 01-05 12:51:27.691838.691838 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 12:51:27.691316.691316 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.691297.691297 cuda_h.py:19] end gate cost 0.000583648681640625 seconds
DEBUG 01-05 12:51:27.691888.691888 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:27.692302.692302 lmp.py:365] 
DEBUG 01-05 12:51:27.692302.692302 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:27.692296.692296 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:27.692661.692661 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:27.692212.692212 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:27.692332.692332 lmp.py:369] 
DEBUG 01-05 12:51:27.692332.692332 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:27.692451.692451 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:27.692578.692578 lmp.py:376]   Expert 47 |     37 | CPU
DEBUG 01-05 12:51:27.692221.692221 lmp.py:376]   Expert 18 |     38 | CPU
DEBUG 01-05 12:51:27.692149.692149 lmp.py:376]   Expert 54 |     61 | CPU
DEBUG 01-05 12:51:27.692600.692600 lmp.py:376]   Expert 15 |     69 | CPU
DEBUG 01-05 12:51:27.692064.692064 lmp.py:376]   Expert 58 |     70 | CPU
DEBUG 01-05 12:51:27.692469.692469 lmp.py:376]   Expert 24 |     76 | CPU
DEBUG 01-05 12:51:27.692257.692257 lmp.py:376]   Expert 32 |     76 | CPU
DEBUG 01-05 12:51:27.692470.692470 lmp.py:376]   Expert  7 |     78 | CPU
DEBUG 01-05 12:51:27.692921.692921 lmp.py:376]   Expert 59 |     78 | CPU
DEBUG 01-05 12:51:27.692895.692895 lmp.py:376]   Expert 38 |     87 | CPU
DEBUG 01-05 12:51:27.692299.692299 lmp.py:376]   Expert 12 |     91 | CPU
DEBUG 01-05 12:51:27.692465.692465 lmp.py:376]   Expert 11 |     94 | CPU
DEBUG 01-05 12:51:27.692393.692393 lmp.py:376]   Expert 61 |     96 | CPU
DEBUG 01-05 12:51:27.692321.692321 lmp.py:376]   Expert 42 |    105 | CPU
DEBUG 01-05 12:51:27.692772.692772 lmp.py:376]   Expert 40 |    116 | CPU
DEBUG 01-05 12:51:27.692746.692746 lmp.py:376]   Expert  6 |    122 | CPU
DEBUG 01-05 12:51:27.692958.692958 lmp.py:376]   Expert 45 |    122 | CPU
DEBUG 01-05 12:51:27.692932.692932 lmp.py:376]   Expert 46 |    125 | CPU
DEBUG 01-05 12:51:27.692906.692906 lmp.py:376]   Expert 23 |    127 | CPU
DEBUG 01-05 12:51:27.692119.692119 lmp.py:376]   Expert 39 |    127 | CPU
DEBUG 01-05 12:51:27.692570.692570 lmp.py:376]   Expert 52 |    129 | CPU
DEBUG 01-05 12:51:27.692544.692544 lmp.py:376]   Expert 34 |    141 | CPU
DEBUG 01-05 12:51:27.692756.692756 lmp.py:376]   Expert 44 |    143 | CPU
DEBUG 01-05 12:51:27.692969.692969 lmp.py:376]   Expert 48 |    144 | CPU
DEBUG 01-05 12:51:27.692181.692181 lmp.py:376]   Expert  3 |    148 | CPU
DEBUG 01-05 12:51:27.692884.692884 lmp.py:376]   Expert 51 |    152 | CPU
DEBUG 01-05 12:51:27.692289.692289 lmp.py:376]   Expert 30 |    155 | CPU
DEBUG 01-05 12:51:27.692693.692693 lmp.py:376]   Expert 10 |    166 | CPU
DEBUG 01-05 12:51:27.692621.692621 lmp.py:376]   Expert 16 |    172 | CPU
DEBUG 01-05 12:51:27.692310.692310 lmp.py:376]   Expert 56 |    174 | CPU
DEBUG 01-05 12:51:27.692284.692284 lmp.py:376]   Expert 31 |    175 | CPU
DEBUG 01-05 12:51:27.692497.692497 lmp.py:376]   Expert 19 |    185 | CPU
DEBUG 01-05 12:51:27.692186.692186 lmp.py:376]   Expert 22 |    185 | GPU
DEBUG 01-05 12:51:27.692398.692398 lmp.py:376]   Expert  4 |    186 | GPU
DEBUG 01-05 12:51:27.692849.692849 lmp.py:376]   Expert 25 |    187 | GPU
DEBUG 01-05 12:51:27.692062.692062 lmp.py:376]   Expert 29 |    188 | GPU
DEBUG 01-05 12:51:27.692513.692513 lmp.py:376]   Expert 50 |    189 | GPU
DEBUG 01-05 12:51:27.692202.692202 lmp.py:376]   Expert  1 |    192 | GPU
DEBUG 01-05 12:51:27.692130.692130 lmp.py:376]   Expert 13 |    196 | GPU
DEBUG 01-05 12:51:27.692819.692819 lmp.py:376]   Expert 57 |    207 | GPU
DEBUG 01-05 12:51:27.693939.693939 lmp.py:376]   Expert 33 |    209 | GPU
DEBUG 01-05 12:51:27.693866.693866 lmp.py:376]   Expert 36 |    209 | GPU
DEBUG 01-05 12:51:27.693079.693079 lmp.py:376]   Expert 17 |    213 | GPU
DEBUG 01-05 12:51:27.693053.693053 lmp.py:376]   Expert 62 |    216 | GPU
DEBUG 01-05 12:51:27.693265.693265 lmp.py:376]   Expert 55 |    230 | GPU
DEBUG 01-05 12:51:27.693001.693001 lmp.py:376]   Expert  5 |    232 | GPU
DEBUG 01-05 12:51:27.693214.693214 lmp.py:376]   Expert  8 |    239 | GPU
DEBUG 01-05 12:51:27.693664.693664 lmp.py:376]   Expert 26 |    241 | GPU
DEBUG 01-05 12:51:27.693638.693638 lmp.py:376]   Expert 53 |    242 | GPU
DEBUG 01-05 12:51:27.693612.693612 lmp.py:376]   Expert  0 |    243 | GPU
DEBUG 01-05 12:51:27.693779.693779 lmp.py:376]   Expert 49 |    247 | GPU
DEBUG 01-05 12:51:27.693706.693706 lmp.py:376]   Expert 41 |    256 | GPU
DEBUG 01-05 12:51:27.693396.693396 lmp.py:376]   Expert 35 |    268 | GPU
DEBUG 01-05 12:51:27.693323.693323 lmp.py:376]   Expert 28 |    272 | GPU
DEBUG 01-05 12:51:27.693536.693536 lmp.py:376]   Expert 37 |    286 | GPU
DEBUG 01-05 12:51:27.693510.693510 lmp.py:376]   Expert 14 |    309 | GPU
DEBUG 01-05 12:51:27.693722.693722 lmp.py:376]   Expert 27 |    337 | GPU
DEBUG 01-05 12:51:27.693458.693458 lmp.py:376]   Expert  2 |    358 | GPU
DEBUG 01-05 12:51:27.693432.693432 lmp.py:376]   Expert 21 |    360 | GPU
DEBUG 01-05 12:51:27.693406.693406 lmp.py:376]   Expert  9 |    376 | GPU
DEBUG 01-05 12:51:27.693142.693142 lmp.py:376]   Expert 60 |    387 | GPU
DEBUG 01-05 12:51:27.693354.693354 lmp.py:376]   Expert 43 |    391 | GPU
DEBUG 01-05 12:51:27.693090.693090 lmp.py:376]   Expert 63 |    449 | GPU
DEBUG 01-05 12:51:27.693541.693541 lmp.py:376]   Expert 20 |    509 | GPU
DEBUG 01-05 12:51:27.693945.693945 lmp.py:377] 
DEBUG 01-05 12:51:27.693945.693945 lmp.py:377]   CPU total tokens: 3679 (29.9%)
DEBUG 01-05 12:51:27.693827.693827 lmp.py:378]   GPU total tokens: 8609 (70.1%)
DEBUG 01-05 12:51:27.693715.693715 cuda_h.py:19] end experts_map_get cost 0.0015294551849365234 seconds
DEBUG 01-05 12:51:27.693835.693835 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:27.693234.693234 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:27.693484.693484 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:27.694873.694873 cuda_h.py:19] end allocate_cuda_memory cost 0.0003235340118408203 seconds
DEBUG 01-05 12:51:27.694008.694008 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:27.694764.694764 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:27.694580.694580 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:27.694706.694706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f3f5d31-53f1-4ac4-9968-f2d4d4d49d51
DEBUG 01-05 12:51:27.694508.694508 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:27.695583.695583 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f3f5d31-53f1-4ac4-9968-f2d4d4d49d51
DEBUG 01-05 12:51:27.695751.695751 cuda_h.py:19] end load_into_gpu_async cost 0.0013930797576904297 seconds
DEBUG 01-05 12:51:27.695308.695308 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:27.695426.695426 cuda_h.py:19] end restore_tensors2 cost 0.0003428459167480469 seconds
DEBUG 01-05 12:51:27.695726.695726 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024127960205078125 seconds
DEBUG 01-05 12:51:27.698180.698180 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005143642425537109 seconds
DEBUG 01-05 12:51:27.698824.698824 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.698734.698734 lmp.py:423] 
DEBUG 01-05 12:51:27.698734.698734 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:27.698868.698868 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-05 12:51:27.698041.698041 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.711724.711724 mlpmodule.py:704] group tensors cost 0.012216806411743164 s
DEBUG 01-05 12:51:27.713972.713972 mlpmodule.py:742] pad cost 0.0016932487487792969 s
DEBUG 01-05 12:51:27.713705.713705 mlpmodule.py:748] create cpu tensor cost 4.8160552978515625e-05 s
DEBUG 01-05 12:51:27.713270.713270 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 12:51:27.724801.724801 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:27.724513.724513 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.724807.724807 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 12:51:27.724810.724810 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.740843.740843 mlpmodule.py:793] group einsum cost 0.026758432388305664 s
DEBUG 01-05 12:51:27.741044.741044 mlpmodule.py:801] cpy2cputensor cost 0.0006945133209228516 s
DEBUG 01-05 12:51:27.746616.746616 cuda_h.py:19] end wait_cetm_experts cost 0.047156333923339844 seconds
DEBUG 01-05 12:51:27.746986.746986 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.746351.746351 cuda_h.py:19] end gpu_sexperts cost 0.00057220458984375 seconds
DEBUG 01-05 12:51:27.746108.746108 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:27.746991.746991 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3589859008789062e-05 seconds
DEBUG 01-05 12:51:27.747694.747694 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:27.747403.747403 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f3f5d31-53f1-4ac4-9968-f2d4d4d49d51
INFO 01-05 12:51:27.749770.749770 client.py:127] Model loaded
DEBUG 01-05 12:51:27.749249.749249 cuda_h.py:19] end wait_experts cost 0.0023088455200195312 seconds
DEBUG 01-05 12:51:27.749336.749336 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.749807.749807 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:27.750203.750203 mlpmodule.py:531] gpu group tensors cost 0.0006575584411621094 s
DEBUG 01-05 12:51:27.751244.751244 mlpmodule.py:564] gpu pad cost 0.0017635822296142578 s
DEBUG 01-05 12:51:27.752690.752690 mlpmodule.py:582] gpu group einsum cost 0.0005638599395751953 s
DEBUG 01-05 12:51:27.756331.756331 mlpmodule.py:611] gpu experts func einsum cost 0.006648540496826172 s
DEBUG 01-05 12:51:27.756043.756043 cuda_h.py:19] end gpu_experts cost 0.006846904754638672 seconds
DEBUG 01-05 12:51:27.756212.756212 cuda_h.py:19] end layer_moe_generate_27 cost 0.06513190269470215 seconds
DEBUG 01-05 12:51:27.756073.756073 lmp.py:217] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 12:51:27.756572.756572 cuda_h.py:19] end multi_layer cost 2.134291410446167 seconds
DEBUG 01-05 12:51:27.756129.756129 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 12:51:27.759070.759070 mlpmodule.py:662]  experts func einsum cost 0.060367584228515625 s
DEBUG 01-05 12:51:27.759688.759688 cuda_h.py:19] end init_inputs_tokens cost 0.0032148361206054688 seconds
DEBUG 01-05 12:51:27.759916.759916 lmp.py:286] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 12:51:27.760427.760427 cuda_h.py:10] start dense_mlp
DEBUG 01-05 12:51:27.760362.760362 lmp.py:289] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 12:51:27.760490.760490 cuda_h.py:19] end dense_mlp cost 0.0006492137908935547 seconds
DEBUG 01-05 12:51:27.760484.760484 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 12:51:27.760048.760048 cuda_h.py:10] start gate
DEBUG 01-05 12:51:27.761728.761728 cuda_h.py:19] end gate cost 0.0005047321319580078 seconds
DEBUG 01-05 12:51:27.761505.761505 cuda_h.py:10] start experts_map_get
INFO 01-05 12:51:27.762037.762037 lmp.py:578] 
INFO 01-05 12:51:27.762037.762037 lmp.py:578] Layer 1 Expert Device Distribution:
INFO 01-05 12:51:27.762946.762946 lmp.py:579]   Active experts: 47 (out of 64 total)
INFO 01-05 12:51:27.762926.762926 lmp.py:580] 
INFO 01-05 12:51:27.762926.762926 lmp.py:580]   Detailed Expert Distribution:
INFO 01-05 12:51:27.762430.762430 lmp.py:581]   Expert ID  | Tokens     | Actual Device  
INFO 01-05 12:51:27.762881.762881 lmp.py:582]   ----------------------------------------------------------------------
INFO 01-05 12:51:27.762286.762286 lmp.py:585]   9          | 1          |  cuda:1         
INFO 01-05 12:51:27.762214.762214 lmp.py:585]   12         | 1          |  cuda:1         
INFO 01-05 12:51:27.762188.762188 lmp.py:585]   17         | 1          |  meta           
INFO 01-05 12:51:27.762923.762923 lmp.py:585]   19         | 1          |  cuda:1         
INFO 01-05 12:51:27.762421.762421 lmp.py:585]   22         | 1          |  meta           
INFO 01-05 12:51:27.762679.762679 lmp.py:585]   28         | 1          |  meta           
INFO 01-05 12:51:27.762938.762938 lmp.py:585]   30         | 1          |  meta           
INFO 01-05 12:51:27.762435.762435 lmp.py:585]   36         | 1          |  cuda:1         
INFO 01-05 12:51:27.762456.762456 lmp.py:585]   40         | 1          |  cuda:1         
INFO 01-05 12:51:27.762476.762476 lmp.py:585]   44         | 1          |  cuda:1         
INFO 01-05 12:51:27.762735.762735 lmp.py:585]   48         | 1          |  cuda:1         
INFO 01-05 12:51:27.762755.762755 lmp.py:585]   49         | 1          |  meta           
INFO 01-05 12:51:27.762537.762537 lmp.py:585]   52         | 1          |  meta           
INFO 01-05 12:51:27.762988.762988 lmp.py:585]   55         | 1          |  meta           
INFO 01-05 12:51:27.762962.762962 lmp.py:585]   1          | 2          |  meta           
INFO 01-05 12:51:27.762221.762221 lmp.py:585]   16         | 2          |  cuda:1         
INFO 01-05 12:51:27.762672.762672 lmp.py:585]   35         | 2          |  cuda:1         
INFO 01-05 12:51:27.762931.762931 lmp.py:585]   43         | 2          |  cuda:1         
INFO 01-05 12:51:27.762189.762189 lmp.py:585]   47         | 2          |  meta           
INFO 01-05 12:51:27.762971.762971 lmp.py:585]   53         | 2          |  meta           
INFO 01-05 12:51:27.762992.762992 lmp.py:585]   8          | 3          |  cuda:1         
INFO 01-05 12:51:27.762012.762012 lmp.py:585]   41         | 3          |  meta           
INFO 01-05 12:51:27.762032.762032 lmp.py:585]   45         | 3          |  cuda:1         
INFO 01-05 12:51:27.762814.762814 lmp.py:585]   60         | 3          |  cuda:1         
INFO 01-05 12:51:27.762073.762073 lmp.py:585]   0          | 4          |  meta           
INFO 01-05 12:51:27.762855.762855 lmp.py:585]   2          | 4          |  cuda:1         
INFO 01-05 12:51:27.762637.762637 lmp.py:585]   10         | 4          |  cuda:1         
INFO 01-05 12:51:27.762134.762134 lmp.py:585]   11         | 4          |  meta           
INFO 01-05 12:51:27.762870.762870 lmp.py:585]   26         | 4          |  cuda:1         
INFO 01-05 12:51:27.762367.762367 lmp.py:585]   4          | 5          |  meta           
INFO 01-05 12:51:27.762626.762626 lmp.py:585]   5          | 5          |  cuda:1         
INFO 01-05 12:51:27.762123.762123 lmp.py:585]   33         | 5          |  meta           
INFO 01-05 12:51:27.762143.762143 lmp.py:585]   6          | 6          |  cuda:1         
INFO 01-05 12:51:27.762925.762925 lmp.py:585]   7          | 6          |  cuda:1         
INFO 01-05 12:51:27.762946.762946 lmp.py:585]   59         | 6          |  cuda:1         
INFO 01-05 12:51:27.762728.762728 lmp.py:585]   14         | 7          |  cuda:1         
INFO 01-05 12:51:27.762510.762510 lmp.py:585]   15         | 7          |  meta           
INFO 01-05 12:51:27.762530.762530 lmp.py:585]   20         | 7          |  cuda:1         
INFO 01-05 12:51:27.762312.762312 lmp.py:585]   23         | 7          |  cuda:1         
INFO 01-05 12:51:27.762332.762332 lmp.py:585]   42         | 7          |  cuda:1         
INFO 01-05 12:51:27.762353.762353 lmp.py:585]   46         | 7          |  cuda:1         
INFO 01-05 12:51:27.762088.762088 lmp.py:585]   61         | 7          |  cuda:1         
INFO 01-05 12:51:27.762586.762586 lmp.py:585]   57         | 8          |  cuda:1         
INFO 01-05 12:51:27.762321.762321 lmp.py:585]   63         | 10         |  cuda:1         
INFO 01-05 12:51:27.762818.762818 lmp.py:585]   31         | 11         |  meta           
INFO 01-05 12:51:27.762554.762554 lmp.py:585]   34         | 11         |  cuda:1         
INFO 01-05 12:51:27.762098.762098 lmp.py:585]   24         | 12         |  cuda:1         
INFO 01-05 12:51:27.762641.762641 lmp.py:586] ============================================================
INFO 01-05 12:51:27.762641.762641 lmp.py:586] 
INFO 01-05 12:51:27.762622.762622 lmp.py:588] experts_gpu_list: [9, 12, 19, 36, 40, 44, 48, 16, 35, 43, 8, 45, 60, 2, 10, 26, 5, 6, 7, 59, 14, 20, 23, 42, 46, 61, 57, 63, 34, 24]
INFO 01-05 12:51:27.762073.762073 lmp.py:589] experts_cpu_list: [17, 22, 28, 30, 49, 52, 55, 1, 47, 53, 41, 0, 11, 4, 33, 15, 31]
INFO 01-05 12:51:27.762299.762299 lmp.py:590] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-05 12:51:27.762240.762240 cuda_h.py:19] end experts_map_get cost 0.0015687942504882812 seconds
DEBUG 01-05 12:51:27.762044.762044 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:27.763503.763503 lmp.py:600] 
DEBUG 01-05 12:51:27.763503.763503 lmp.py:600]   Computing 17 experts on CPU...
DEBUG 01-05 12:51:27.763207.763207 cuda_h.py:19] end cpu_experts_submit cost 8.96453857421875e-05 seconds
DEBUG 01-05 12:51:27.763757.763757 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:27.768133.768133 mlpmodule.py:704] group tensors cost 0.004698991775512695 s
DEBUG 01-05 12:51:27.769194.769194 mlpmodule.py:742] pad cost 0.0009386539459228516 s
DEBUG 01-05 12:51:27.769490.769490 mlpmodule.py:748] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-05 12:51:27.769770.769770 mlpmodule.py:753] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-05 12:51:27.772582.772582 mlpmodule.py:767] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-05 12:51:27.772962.772962 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:27.772905.772905 mlpmodule.py:773] group_w3 first element: 0.016845703125
WARNING 01-05 12:51:27.772179.772179 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:27.776438.776438 mlpmodule.py:793] group einsum cost 0.007052898406982422 s
DEBUG 01-05 12:51:27.777834.777834 mlpmodule.py:801] cpy2cputensor cost 8.678436279296875e-05 s
DEBUG 01-05 12:51:27.779661.779661 cuda_h.py:19] end wait_cetm_experts cost 0.016244173049926758 seconds
DEBUG 01-05 12:51:27.779880.779880 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:27.780837.780837 cuda_h.py:19] end gpu_sexperts cost 0.0006558895111083984 seconds
DEBUG 01-05 12:51:27.780398.780398 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:27.781105.781105 mlpmodule.py:531] gpu group tensors cost 0.0008330345153808594 s
DEBUG 01-05 12:51:27.783605.783605 mlpmodule.py:564] gpu pad cost 0.0020265579223632812 s
DEBUG 01-05 12:51:27.784469.784469 mlpmodule.py:582] gpu group einsum cost 0.0005800724029541016 s
DEBUG 01-05 12:51:27.787879.787879 mlpmodule.py:662]  experts func einsum cost 0.02440953254699707 s
DEBUG 01-05 12:51:27.788701.788701 mlpmodule.py:611] gpu experts func einsum cost 0.007544040679931641 s
DEBUG 01-05 12:51:27.788826.788826 cuda_h.py:19] end gpu_experts cost 0.007786750793457031 seconds
DEBUG 01-05 12:51:27.788167.788167 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.02768874168395996 seconds
DEBUG 01-05 12:51:28.968049.968049 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09206342697143555 s
DEBUG 01-05 12:51:29.315824.315824 cuda_h.py:19] end generate_input_ids cost 0.3460655212402344 seconds
DEBUG 01-05 12:51:29.315061.315061 cuda_h.py:10] start init_cache
DEBUG 01-05 12:51:29.315661.315661 cuda_h.py:19] end init_cache cost 6.67572021484375e-05 seconds
DEBUG 01-05 12:51:31.734410.734410 cuda_h.py:10] start init_weights
DEBUG 01-05 12:51:31.734700.734700 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:31.735733.735733 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:31.735027.735027 cuda_h.py:19] end allocate_cuda_memory cost 0.0004222393035888672 seconds
DEBUG 01-05 12:51:31.735499.735499 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:31.735017.735017 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:31.735694.735694 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:31.735774.735774 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a70d6fbc-8d48-465b-ae98-dab078b62347
DEBUG 01-05 12:51:31.735181.735181 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:31.737720.737720 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a70d6fbc-8d48-465b-ae98-dab078b62347
DEBUG 01-05 12:51:31.737325.737325 cuda_h.py:19] end load_into_gpu_async cost 0.0022614002227783203 seconds
DEBUG 01-05 12:51:31.737643.737643 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:31.738798.738798 cuda_h.py:19] end restore_tensors2 cost 5.1975250244140625e-05 seconds
DEBUG 01-05 12:51:31.738978.738978 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029709339141845703 seconds
INFO 01-05 12:51:31.738852.738852 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a70d6fbc-8d48-465b-ae98-dab078b62347
INFO 01-05 12:51:31.817957.817957 client.py:127] Model loaded
DEBUG 01-05 12:51:31.817744.817744 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 12:51:31.817013.817013 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:31.817567.817567 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:31.818028.818028 cuda_h.py:19] end allocate_cuda_memory cost 0.0004200935363769531 seconds
DEBUG 01-05 12:51:31.818947.818947 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:31.818685.818685 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:31.818721.818721 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:31.818624.818624 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 82642296-1cb7-462f-9622-589816331d0d
DEBUG 01-05 12:51:31.819392.819392 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:31.820670.820670 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 82642296-1cb7-462f-9622-589816331d0d
DEBUG 01-05 12:51:31.820887.820887 cuda_h.py:19] end load_into_gpu_async cost 0.0020723342895507812 seconds
DEBUG 01-05 12:51:31.820287.820287 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:31.821049.821049 cuda_h.py:19] end restore_tensors2 cost 0.00013136863708496094 seconds
DEBUG 01-05 12:51:31.821933.821933 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032629966735839844 seconds
INFO 01-05 12:51:31.821512.821512 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 82642296-1cb7-462f-9622-589816331d0d
INFO 01-05 12:51:31.837804.837804 client.py:127] Model loaded
DEBUG 01-05 12:51:31.838679.838679 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020913124084472656 seconds
DEBUG 01-05 12:51:31.838518.838518 cuda_h.py:19] end init_weights cost 0.1039431095123291 seconds
DEBUG 01-05 12:51:31.838289.838289 cuda_h.py:10] start copy_emodel
DEBUG 01-05 12:51:32.601878.601878 cuda_h.py:19] end copy_emodel cost 0.7629373073577881 seconds
DEBUG 01-05 12:51:32.602456.602456 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 12:51:32.603249.603249 cuda_h.py:19] end init_inputs_tokens cost 0.0002799034118652344 seconds
DEBUG 01-05 12:51:32.603701.603701 cuda_h.py:10] start multi_layer
DEBUG 01-05 12:51:32.603271.603271 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 12:51:32.603537.603537 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:32.603856.603856 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:32.603666.603666 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 4.553794860839844e-05 seconds
DEBUG 01-05 12:51:32.603343.603343 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 9.369850158691406e-05 seconds
DEBUG 01-05 12:51:32.603940.603940 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:32.603453.603453 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.603550.603550 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.603731.603731 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.604290.604290 cuda_h.py:19] end allocate_cuda_memory cost 0.00022840499877929688 seconds
DEBUG 01-05 12:51:32.604345.604345 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.604566.604566 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.604541.604541 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.604205.604205 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 390e1dd8-87c9-46c5-abba-fd78689e7332
DEBUG 01-05 12:51:32.604115.604115 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.604513.604513 cuda_h.py:10] start self_attn
INFO 01-05 12:51:32.606307.606307 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 390e1dd8-87c9-46c5-abba-fd78689e7332
DEBUG 01-05 12:51:32.606494.606494 cuda_h.py:19] end load_into_gpu_async cost 0.0020186901092529297 seconds
DEBUG 01-05 12:51:32.606158.606158 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.606930.606930 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-05 12:51:32.606713.606713 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002640247344970703 seconds
INFO 01-05 12:51:32.606850.606850 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 390e1dd8-87c9-46c5-abba-fd78689e7332
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:32.609762.609762 cuda_h.py:19] end self_attn cost 0.004777193069458008 seconds
DEBUG 01-05 12:51:32.609421.609421 cuda_h.py:19] end iln_self_attn_paln cost 0.006435394287109375 seconds
DEBUG 01-05 12:51:32.609720.609720 cuda_h.py:10] start dense_mlp
DEBUG 01-05 12:51:32.609622.609622 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 12:51:32.610160.610160 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 1.9550323486328125e-05 seconds
DEBUG 01-05 12:51:32.610153.610153 cuda_h.py:19] end dense_mlp cost 0.0010221004486083984 seconds
DEBUG 01-05 12:51:32.611262.611262 lmp.py:217] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 12:51:32.611210.611210 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 12:51:32.611191.611191 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 12:51:32.611086.611086 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 12:51:32.611001.611001 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.9073486328125e-05 seconds
DEBUG 01-05 12:51:32.611605.611605 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.506111145019531e-05 seconds
DEBUG 01-05 12:51:32.611486.611486 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:32.611732.611732 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
INFO 01-05 12:51:32.614419.614419 client.py:127] Model loaded
DEBUG 01-05 12:51:32.615985.615985 cuda_h.py:19] end sllm_worker_task cost 0.011419057846069336 seconds
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:32.615916.615916 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.615428.615428 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.615066.615066 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.615373.615373 cuda_h.py:19] end allocate_cuda_memory cost 0.00020575523376464844 seconds
DEBUG 01-05 12:51:32.615363.615363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.615954.615954 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.615367.615367 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.615375.615375 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aac57b96-d42d-4060-aa1d-f5ab3c1973e2
DEBUG 01-05 12:51:32.615802.615802 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.616695.616695 cuda_h.py:19] end self_attn cost 0.004800558090209961 seconds
DEBUG 01-05 12:51:32.616170.616170 cuda_h.py:19] end iln_self_attn_paln cost 0.005357265472412109 seconds
DEBUG 01-05 12:51:32.616397.616397 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 12:51:32.616782.616782 cuda_h.py:10] start gate
INFO 01-05 12:51:32.617692.617692 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aac57b96-d42d-4060-aa1d-f5ab3c1973e2
DEBUG 01-05 12:51:32.617085.617085 cuda_h.py:19] end load_into_gpu_async cost 0.0017440319061279297 seconds
DEBUG 01-05 12:51:32.617566.617566 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.617405.617405 cuda_h.py:19] end restore_tensors2 cost 7.915496826171875e-05 seconds
DEBUG 01-05 12:51:32.617453.617453 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024836063385009766 seconds
DEBUG 01-05 12:51:32.617065.617065 cuda_h.py:19] end gate cost 0.0010821819305419922 seconds
DEBUG 01-05 12:51:32.617431.617431 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:32.618216.618216 lmp.py:365] 
DEBUG 01-05 12:51:32.618216.618216 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:32.618925.618925 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:32.618006.618006 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:32.618510.618510 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:32.618106.618106 lmp.py:369] 
DEBUG 01-05 12:51:32.618106.618106 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:32.618941.618941 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:32.618975.618975 lmp.py:376]   Expert 62 |     66 | CPU
DEBUG 01-05 12:51:32.618334.618334 lmp.py:376]   Expert 18 |     68 | CPU
DEBUG 01-05 12:51:32.618738.618738 lmp.py:376]   Expert 22 |     73 | CPU
DEBUG 01-05 12:51:32.618666.618666 lmp.py:376]   Expert 32 |     83 | CPU
DEBUG 01-05 12:51:32.618832.618832 lmp.py:376]   Expert 52 |     94 | CPU
DEBUG 01-05 12:51:32.618521.618521 lmp.py:376]   Expert  3 |    104 | CPU
DEBUG 01-05 12:51:32.618449.618449 lmp.py:376]   Expert 27 |    114 | CPU
DEBUG 01-05 12:51:32.618377.618377 lmp.py:376]   Expert 38 |    114 | CPU
DEBUG 01-05 12:51:32.618828.618828 lmp.py:376]   Expert 13 |    118 | CPU
DEBUG 01-05 12:51:32.618279.618279 lmp.py:376]   Expert 54 |    118 | CPU
DEBUG 01-05 12:51:32.618921.618921 lmp.py:376]   Expert 17 |    121 | CPU
DEBUG 01-05 12:51:32.618803.618803 lmp.py:376]   Expert 11 |    124 | CPU
DEBUG 01-05 12:51:32.618969.618969 lmp.py:376]   Expert 28 |    124 | CPU
DEBUG 01-05 12:51:32.618612.618612 lmp.py:376]   Expert 37 |    125 | CPU
DEBUG 01-05 12:51:32.618301.618301 lmp.py:376]   Expert 58 |    129 | CPU
DEBUG 01-05 12:51:32.618752.618752 lmp.py:376]   Expert 39 |    131 | CPU
DEBUG 01-05 12:51:32.618203.618203 lmp.py:376]   Expert 25 |    135 | CPU
DEBUG 01-05 12:51:32.618892.618892 lmp.py:376]   Expert 41 |    136 | CPU
DEBUG 01-05 12:51:32.618820.618820 lmp.py:376]   Expert 21 |    150 | CPU
DEBUG 01-05 12:51:32.618509.618509 lmp.py:376]   Expert  4 |    151 | CPU
DEBUG 01-05 12:51:32.618199.618199 lmp.py:376]   Expert 30 |    152 | CPU
DEBUG 01-05 12:51:32.618126.618126 lmp.py:376]   Expert 29 |    155 | CPU
DEBUG 01-05 12:51:32.618054.618054 lmp.py:376]   Expert 53 |    155 | CPU
DEBUG 01-05 12:51:32.618743.618743 lmp.py:376]   Expert 49 |    156 | CPU
DEBUG 01-05 12:51:32.618386.618386 lmp.py:376]   Expert 47 |    157 | CPU
DEBUG 01-05 12:51:32.618791.618791 lmp.py:376]   Expert 31 |    168 | CPU
DEBUG 01-05 12:51:32.618911.618911 lmp.py:376]   Expert 33 |    168 | CPU
DEBUG 01-05 12:51:32.618315.618315 lmp.py:376]   Expert 55 |    173 | CPU
DEBUG 01-05 12:51:32.618005.618005 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 12:51:32.618217.618217 lmp.py:376]   Expert 15 |    177 | CPU
DEBUG 01-05 12:51:32.618145.618145 lmp.py:376]   Expert  0 |    178 | CPU
DEBUG 01-05 12:51:32.618357.618357 lmp.py:376]   Expert  1 |    178 | CPU
DEBUG 01-05 12:51:32.618808.618808 lmp.py:376]   Expert 24 |    180 | GPU
DEBUG 01-05 12:51:32.618021.618021 lmp.py:376]   Expert 50 |    182 | GPU
DEBUG 01-05 12:51:32.618472.618472 lmp.py:376]   Expert 51 |    184 | GPU
DEBUG 01-05 12:51:32.618922.618922 lmp.py:376]   Expert 19 |    185 | GPU
DEBUG 01-05 12:51:32.618612.618612 lmp.py:376]   Expert  6 |    186 | GPU
DEBUG 01-05 12:51:32.618824.618824 lmp.py:376]   Expert 10 |    189 | GPU
DEBUG 01-05 12:51:32.618513.618513 lmp.py:376]   Expert 34 |    191 | GPU
DEBUG 01-05 12:51:32.619918.619918 lmp.py:376]   Expert  2 |    195 | GPU
DEBUG 01-05 12:51:32.619846.619846 lmp.py:376]   Expert 45 |    195 | GPU
DEBUG 01-05 12:51:32.619012.619012 lmp.py:376]   Expert 35 |    197 | GPU
DEBUG 01-05 12:51:32.619701.619701 lmp.py:376]   Expert 36 |    198 | GPU
DEBUG 01-05 12:51:32.619914.619914 lmp.py:376]   Expert 61 |    209 | GPU
DEBUG 01-05 12:51:32.619365.619365 lmp.py:376]   Expert 44 |    214 | GPU
DEBUG 01-05 12:51:32.619815.619815 lmp.py:376]   Expert 12 |    223 | GPU
DEBUG 01-05 12:51:32.619266.619266 lmp.py:376]   Expert  5 |    227 | GPU
DEBUG 01-05 12:51:32.619479.619479 lmp.py:376]   Expert 23 |    235 | GPU
DEBUG 01-05 12:51:32.619930.619930 lmp.py:376]   Expert 60 |    235 | GPU
DEBUG 01-05 12:51:32.619380.619380 lmp.py:376]   Expert 43 |    239 | GPU
DEBUG 01-05 12:51:32.619593.619593 lmp.py:376]   Expert  9 |    246 | GPU
DEBUG 01-05 12:51:32.619044.619044 lmp.py:376]   Expert 48 |    252 | GPU
DEBUG 01-05 12:51:32.619495.619495 lmp.py:376]   Expert  8 |    262 | GPU
DEBUG 01-05 12:51:32.619946.619946 lmp.py:376]   Expert 20 |    273 | GPU
DEBUG 01-05 12:51:32.619396.619396 lmp.py:376]   Expert 26 |    285 | GPU
DEBUG 01-05 12:51:32.619563.619563 lmp.py:376]   Expert 57 |    292 | GPU
DEBUG 01-05 12:51:32.619729.619729 lmp.py:376]   Expert  7 |    308 | GPU
DEBUG 01-05 12:51:32.619372.619372 lmp.py:376]   Expert 59 |    308 | GPU
DEBUG 01-05 12:51:32.619538.619538 lmp.py:376]   Expert 16 |    310 | GPU
DEBUG 01-05 12:51:32.619227.619227 lmp.py:376]   Expert 63 |    313 | GPU
DEBUG 01-05 12:51:32.619678.619678 lmp.py:376]   Expert 40 |    320 | GPU
DEBUG 01-05 12:51:32.619891.619891 lmp.py:376]   Expert 46 |    320 | GPU
DEBUG 01-05 12:51:32.619865.619865 lmp.py:376]   Expert 42 |    342 | GPU
DEBUG 01-05 12:51:32.619077.619077 lmp.py:376]   Expert 14 |    525 | GPU
DEBUG 01-05 12:51:32.619243.619243 lmp.py:377] 
DEBUG 01-05 12:51:32.619243.619243 lmp.py:377]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 12:51:32.619648.619648 lmp.py:378]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 12:51:32.619105.619105 cuda_h.py:19] end experts_map_get cost 0.0015227794647216797 seconds
DEBUG 01-05 12:51:32.619987.619987 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:32.619863.619863 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.619278.619278 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.620771.620771 cuda_h.py:19] end allocate_cuda_memory cost 0.00124359130859375 seconds
DEBUG 01-05 12:51:32.620329.620329 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.621608.621608 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.621464.621464 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.621113.621113 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1c843d0-23c9-4f9a-ba30-e9287e97ff76
DEBUG 01-05 12:51:32.621764.621764 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:32.621712.621712 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aac57b96-d42d-4060-aa1d-f5ab3c1973e2
INFO 01-05 12:51:32.623133.623133 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1c843d0-23c9-4f9a-ba30-e9287e97ff76
DEBUG 01-05 12:51:32.623969.623969 cuda_h.py:19] end load_into_gpu_async cost 0.0022649765014648438 seconds
DEBUG 01-05 12:51:32.623003.623003 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.623558.623558 cuda_h.py:19] end restore_tensors2 cost 0.0003485679626464844 seconds
DEBUG 01-05 12:51:32.623679.623679 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004195451736450195 seconds
DEBUG 01-05 12:51:32.626100.626100 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0069026947021484375 seconds
DEBUG 01-05 12:51:32.626943.626943 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:32.626747.626747 lmp.py:423] 
DEBUG 01-05 12:51:32.626747.626747 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:32.626498.626498 cuda_h.py:19] end cpu_experts_submit cost 0.00011944770812988281 seconds
DEBUG 01-05 12:51:32.626055.626055 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:32.643688.643688 mlpmodule.py:704] group tensors cost 0.016974925994873047 s
INFO 01-05 12:51:32.645651.645651 client.py:127] Model loaded
DEBUG 01-05 12:51:32.645295.645295 cuda_h.py:19] end sllm_worker_task cost 0.030043601989746094 seconds
DEBUG 01-05 12:51:32.645558.645558 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.645918.645918 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.645266.645266 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.646921.646921 cuda_h.py:19] end allocate_cuda_memory cost 0.0004596710205078125 seconds
DEBUG 01-05 12:51:32.646205.646205 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.646089.646089 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.646238.646238 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.646240.646240 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9df06c45-e401-4916-b15e-58323962eaf5
DEBUG 01-05 12:51:32.646058.646058 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:32.648318.648318 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9df06c45-e401-4916-b15e-58323962eaf5
DEBUG 01-05 12:51:32.648051.648051 cuda_h.py:19] end load_into_gpu_async cost 0.0022478103637695312 seconds
DEBUG 01-05 12:51:32.648922.648922 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.648207.648207 cuda_h.py:19] end restore_tensors2 cost 0.0001327991485595703 seconds
DEBUG 01-05 12:51:32.649430.649430 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035266876220703125 seconds
INFO 01-05 12:51:32.650359.650359 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9df06c45-e401-4916-b15e-58323962eaf5
DEBUG 01-05 12:51:32.650294.650294 mlpmodule.py:742] pad cost 0.005968332290649414 s
DEBUG 01-05 12:51:32.650736.650736 mlpmodule.py:748] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-05 12:51:32.651528.651528 mlpmodule.py:753] move to cpu cost 5.173683166503906e-05 s
DEBUG 01-05 12:51:32.663909.663909 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:32.663271.663271 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:32.664803.664803 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 12:51:32.664934.664934 mlpmodule.py:783] start einsum2
INFO 01-05 12:51:32.682290.682290 client.py:127] Model loaded
DEBUG 01-05 12:51:32.682276.682276 cuda_h.py:19] end sllm_worker_task cost 0.036989450454711914 seconds
DEBUG 01-05 12:51:32.691861.691861 mlpmodule.py:793] group einsum cost 0.03995537757873535 s
DEBUG 01-05 12:51:32.719422.719422 mlpmodule.py:801] cpy2cputensor cost 0.02803778648376465 s
DEBUG 01-05 12:51:32.723355.723355 cuda_h.py:19] end wait_cetm_experts cost 0.09709978103637695 seconds
DEBUG 01-05 12:51:32.723313.723313 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:32.724355.724355 cuda_h.py:19] end gpu_sexperts cost 0.0006158351898193359 seconds
DEBUG 01-05 12:51:32.724821.724821 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:32.724962.724962 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 12:51:32.724573.724573 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:32.724567.724567 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1c843d0-23c9-4f9a-ba30-e9287e97ff76
INFO 01-05 12:51:32.725023.725023 client.py:127] Model loaded
DEBUG 01-05 12:51:32.726481.726481 cuda_h.py:19] end wait_experts cost 0.0012011528015136719 seconds
DEBUG 01-05 12:51:32.726900.726900 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:32.726463.726463 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:32.739284.739284 mlpmodule.py:662]  experts func einsum cost 0.11239409446716309 s
DEBUG 01-05 12:51:32.739568.739568 mlpmodule.py:531] gpu group tensors cost 0.013494014739990234 s
DEBUG 01-05 12:51:32.741852.741852 mlpmodule.py:564] gpu pad cost 0.0020575523376464844 s
DEBUG 01-05 12:51:32.743027.743027 mlpmodule.py:582] gpu group einsum cost 0.0011737346649169922 s
DEBUG 01-05 12:51:32.746425.746425 mlpmodule.py:611] gpu experts func einsum cost 0.020322084426879883 s
DEBUG 01-05 12:51:32.746457.746457 cuda_h.py:19] end gpu_experts cost 0.020572185516357422 seconds
DEBUG 01-05 12:51:32.746387.746387 cuda_h.py:19] end layer_moe_generate_1 cost 0.13001561164855957 seconds
DEBUG 01-05 12:51:32.746426.746426 lmp.py:217] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 12:51:32.746765.746765 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 12:51:32.746269.746269 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 12:51:32.746594.746594 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 12:51:32.747861.747861 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:32.747372.747372 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.079673767089844e-05 seconds
DEBUG 01-05 12:51:32.747969.747969 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:32.747620.747620 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.747731.747731 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.747448.747448 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.747291.747291 cuda_h.py:19] end allocate_cuda_memory cost 0.00019025802612304688 seconds
DEBUG 01-05 12:51:32.747274.747274 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.747256.747256 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.747569.747569 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.747755.747755 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bbc8a0f3-790c-48ee-af16-6dd4a34922cb
DEBUG 01-05 12:51:32.747495.747495 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.748097.748097 cuda_h.py:10] start self_attn
INFO 01-05 12:51:32.749847.749847 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bbc8a0f3-790c-48ee-af16-6dd4a34922cb
DEBUG 01-05 12:51:32.749465.749465 cuda_h.py:19] end load_into_gpu_async cost 0.0019092559814453125 seconds
DEBUG 01-05 12:51:32.749527.749527 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.749160.749160 cuda_h.py:19] end restore_tensors2 cost 8.082389831542969e-05 seconds
DEBUG 01-05 12:51:32.749691.749691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025217533111572266 seconds
INFO 01-05 12:51:32.750246.750246 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bbc8a0f3-790c-48ee-af16-6dd4a34922cb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:32.751826.751826 cuda_h.py:19] end self_attn cost 0.0034945011138916016 seconds
DEBUG 01-05 12:51:32.752055.752055 cuda_h.py:19] end iln_self_attn_paln cost 0.004832744598388672 seconds
DEBUG 01-05 12:51:32.752990.752990 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 12:51:32.752468.752468 cuda_h.py:10] start gate
DEBUG 01-05 12:51:32.752730.752730 cuda_h.py:19] end gate cost 0.0006518363952636719 seconds
DEBUG 01-05 12:51:32.752274.752274 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:32.753337.753337 lmp.py:365] 
DEBUG 01-05 12:51:32.753337.753337 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:32.753140.753140 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:32.753505.753505 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:32.753293.753293 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:32.753459.753459 lmp.py:369] 
DEBUG 01-05 12:51:32.753459.753459 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:32.753910.753910 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:32.753798.753798 lmp.py:376]   Expert 34 |     42 | CPU
DEBUG 01-05 12:51:32.753965.753965 lmp.py:376]   Expert 36 |     49 | CPU
DEBUG 01-05 12:51:32.753416.753416 lmp.py:376]   Expert 58 |     62 | CPU
DEBUG 01-05 12:51:32.753390.753390 lmp.py:376]   Expert 26 |     65 | CPU
DEBUG 01-05 12:51:32.753602.753602 lmp.py:376]   Expert  3 |     68 | CPU
DEBUG 01-05 12:51:32.753099.753099 lmp.py:376]   Expert 27 |     74 | CPU
DEBUG 01-05 12:51:32.753789.753789 lmp.py:376]   Expert  8 |     78 | CPU
DEBUG 01-05 12:51:32.753955.753955 lmp.py:376]   Expert 29 |     79 | CPU
DEBUG 01-05 12:51:32.753882.753882 lmp.py:376]   Expert  7 |     92 | CPU
DEBUG 01-05 12:51:32.753095.753095 lmp.py:376]   Expert 10 |     97 | CPU
DEBUG 01-05 12:51:32.753830.753830 lmp.py:376]   Expert 21 |    107 | CPU
DEBUG 01-05 12:51:32.753805.753805 lmp.py:376]   Expert 28 |    107 | CPU
DEBUG 01-05 12:51:32.753540.753540 lmp.py:376]   Expert 13 |    108 | CPU
DEBUG 01-05 12:51:32.753276.753276 lmp.py:376]   Expert 19 |    113 | CPU
DEBUG 01-05 12:51:32.753011.753011 lmp.py:376]   Expert 62 |    122 | CPU
DEBUG 01-05 12:51:32.753747.753747 lmp.py:376]   Expert 40 |    134 | CPU
DEBUG 01-05 12:51:32.753244.753244 lmp.py:376]   Expert  5 |    140 | CPU
DEBUG 01-05 12:51:32.753318.753318 lmp.py:376]   Expert 52 |    141 | CPU
DEBUG 01-05 12:51:32.753245.753245 lmp.py:376]   Expert 63 |    143 | CPU
DEBUG 01-05 12:51:32.753219.753219 lmp.py:376]   Expert  9 |    150 | CPU
DEBUG 01-05 12:51:32.753955.753955 lmp.py:376]   Expert 59 |    150 | CPU
DEBUG 01-05 12:51:32.753929.753929 lmp.py:376]   Expert 25 |    153 | CPU
DEBUG 01-05 12:51:32.753426.753426 lmp.py:376]   Expert 33 |    153 | CPU
DEBUG 01-05 12:51:32.753162.753162 lmp.py:376]   Expert 17 |    156 | CPU
DEBUG 01-05 12:51:32.753898.753898 lmp.py:376]   Expert 50 |    156 | CPU
DEBUG 01-05 12:51:32.753633.753633 lmp.py:376]   Expert 49 |    158 | CPU
DEBUG 01-05 12:51:32.753369.753369 lmp.py:376]   Expert 16 |    161 | CPU
DEBUG 01-05 12:51:32.753343.753343 lmp.py:376]   Expert 60 |    164 | CPU
DEBUG 01-05 12:51:32.753509.753509 lmp.py:376]   Expert  0 |    165 | CPU
DEBUG 01-05 12:51:32.753245.753245 lmp.py:376]   Expert 30 |    168 | CPU
DEBUG 01-05 12:51:32.753219.753219 lmp.py:376]   Expert 35 |    169 | CPU
DEBUG 01-05 12:51:32.753716.753716 lmp.py:376]   Expert  1 |    170 | CPU
DEBUG 01-05 12:51:32.753359.753359 lmp.py:376]   Expert 24 |    174 | GPU
DEBUG 01-05 12:51:32.753287.753287 lmp.py:376]   Expert 45 |    178 | GPU
DEBUG 01-05 12:51:32.753214.753214 lmp.py:376]   Expert 38 |    180 | GPU
DEBUG 01-05 12:51:32.753904.753904 lmp.py:376]   Expert 44 |    183 | GPU
DEBUG 01-05 12:51:32.753593.753593 lmp.py:376]   Expert  6 |    191 | GPU
DEBUG 01-05 12:51:32.753521.753521 lmp.py:376]   Expert 31 |    197 | GPU
DEBUG 01-05 12:51:32.753164.753164 lmp.py:376]   Expert 48 |    208 | GPU
DEBUG 01-05 12:51:32.753807.753807 lmp.py:376]   Expert 39 |    223 | GPU
DEBUG 01-05 12:51:32.753496.753496 lmp.py:376]   Expert  4 |    233 | GPU
DEBUG 01-05 12:51:32.753185.753185 lmp.py:376]   Expert 55 |    234 | GPU
DEBUG 01-05 12:51:32.753875.753875 lmp.py:376]   Expert 22 |    240 | GPU
DEBUG 01-05 12:51:32.753802.753802 lmp.py:376]   Expert 37 |    241 | GPU
DEBUG 01-05 12:51:32.754730.754730 lmp.py:376]   Expert 14 |    242 | GPU
DEBUG 01-05 12:51:32.754181.754181 lmp.py:376]   Expert 51 |    248 | GPU
DEBUG 01-05 12:51:32.754632.754632 lmp.py:376]   Expert 57 |    249 | GPU
DEBUG 01-05 12:51:32.754559.754559 lmp.py:376]   Expert  2 |    255 | GPU
DEBUG 01-05 12:51:32.754487.754487 lmp.py:376]   Expert 41 |    256 | GPU
DEBUG 01-05 12:51:32.754892.754892 lmp.py:376]   Expert 12 |    259 | GPU
DEBUG 01-05 12:51:32.754819.754819 lmp.py:376]   Expert 15 |    271 | GPU
DEBUG 01-05 12:51:32.754509.754509 lmp.py:376]   Expert 47 |    272 | GPU
DEBUG 01-05 12:51:32.754436.754436 lmp.py:376]   Expert 20 |    278 | GPU
DEBUG 01-05 12:51:32.754126.754126 lmp.py:376]   Expert 42 |    282 | GPU
DEBUG 01-05 12:51:32.754815.754815 lmp.py:376]   Expert 23 |    289 | GPU
DEBUG 01-05 12:51:32.754504.754504 lmp.py:376]   Expert 53 |    298 | GPU
DEBUG 01-05 12:51:32.754194.754194 lmp.py:376]   Expert 54 |    314 | GPU
DEBUG 01-05 12:51:32.754883.754883 lmp.py:376]   Expert 56 |    315 | GPU
DEBUG 01-05 12:51:32.754572.754572 lmp.py:376]   Expert 18 |    317 | GPU
DEBUG 01-05 12:51:32.754454.754454 lmp.py:376]   Expert 46 |    326 | GPU
DEBUG 01-05 12:51:32.754381.754381 lmp.py:376]   Expert 61 |    326 | GPU
DEBUG 01-05 12:51:32.754832.754832 lmp.py:376]   Expert 32 |    333 | GPU
DEBUG 01-05 12:51:32.754760.754760 lmp.py:376]   Expert 43 |    370 | GPU
DEBUG 01-05 12:51:32.754449.754449 lmp.py:376]   Expert 11 |    412 | GPU
DEBUG 01-05 12:51:32.754854.754854 lmp.py:377] 
DEBUG 01-05 12:51:32.754854.754854 lmp.py:377]   CPU total tokens: 3894 (31.7%)
DEBUG 01-05 12:51:32.754974.754974 lmp.py:378]   GPU total tokens: 8394 (68.3%)
DEBUG 01-05 12:51:32.754339.754339 cuda_h.py:19] end experts_map_get cost 0.0014934539794921875 seconds
DEBUG 01-05 12:51:32.754458.754458 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:32.754904.754904 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.754935.754935 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.755776.755776 cuda_h.py:19] end allocate_cuda_memory cost 0.0013592243194580078 seconds
DEBUG 01-05 12:51:32.756473.756473 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.756514.756514 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.756515.756515 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.756834.756834 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2663a477-355b-4856-9a0e-8c733b06a15a
DEBUG 01-05 12:51:32.756131.756131 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:32.757898.757898 client.py:127] Model loaded
DEBUG 01-05 12:51:32.758268.758268 cuda_h.py:19] end sllm_worker_task cost 0.010702371597290039 seconds
INFO 01-05 12:51:32.759187.759187 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2663a477-355b-4856-9a0e-8c733b06a15a
DEBUG 01-05 12:51:32.759761.759761 cuda_h.py:19] end load_into_gpu_async cost 0.0032196044921875 seconds
DEBUG 01-05 12:51:32.759625.759625 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.759895.759895 cuda_h.py:19] end restore_tensors2 cost 0.0004875659942626953 seconds
DEBUG 01-05 12:51:32.759208.759208 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0055043697357177734 seconds
DEBUG 01-05 12:51:32.762451.762451 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008254289627075195 seconds
DEBUG 01-05 12:51:32.762579.762579 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:32.762965.762965 lmp.py:423] 
DEBUG 01-05 12:51:32.762965.762965 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:32.762762.762762 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-05 12:51:32.762657.762657 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:32.780630.780630 mlpmodule.py:704] group tensors cost 0.017091751098632812 s
DEBUG 01-05 12:51:32.782421.782421 mlpmodule.py:742] pad cost 0.0016331672668457031 s
DEBUG 01-05 12:51:32.782955.782955 mlpmodule.py:748] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-05 12:51:32.782282.782282 mlpmodule.py:753] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-05 12:51:32.792269.792269 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:32.792474.792474 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:32.792994.792994 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 12:51:32.792912.792912 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:32.807695.807695 mlpmodule.py:793] group einsum cost 0.024735689163208008 s
DEBUG 01-05 12:51:32.808727.808727 mlpmodule.py:801] cpy2cputensor cost 0.0007274150848388672 s
DEBUG 01-05 12:51:32.813990.813990 cuda_h.py:19] end wait_cetm_experts cost 0.05041646957397461 seconds
DEBUG 01-05 12:51:32.813883.813883 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:32.814493.814493 cuda_h.py:19] end gpu_sexperts cost 0.0005834102630615234 seconds
DEBUG 01-05 12:51:32.814674.814674 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:32.814438.814438 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.337860107421875e-05 seconds
DEBUG 01-05 12:51:32.814380.814380 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:32.814089.814089 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2663a477-355b-4856-9a0e-8c733b06a15a
INFO 01-05 12:51:32.815126.815126 client.py:127] Model loaded
DEBUG 01-05 12:51:32.815346.815346 cuda_h.py:19] end wait_experts cost 0.00135040283203125 seconds
DEBUG 01-05 12:51:32.815526.815526 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:32.815421.815421 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:32.816467.816467 mlpmodule.py:531] gpu group tensors cost 0.0006852149963378906 s
DEBUG 01-05 12:51:32.818375.818375 mlpmodule.py:564] gpu pad cost 0.0017330646514892578 s
DEBUG 01-05 12:51:32.819350.819350 mlpmodule.py:582] gpu group einsum cost 0.0005741119384765625 s
DEBUG 01-05 12:51:32.822457.822457 mlpmodule.py:611] gpu experts func einsum cost 0.006717681884765625 s
DEBUG 01-05 12:51:32.822508.822508 cuda_h.py:19] end gpu_experts cost 0.00694584846496582 seconds
DEBUG 01-05 12:51:32.822008.822008 cuda_h.py:19] end layer_moe_generate_2 cost 0.07069778442382812 seconds
DEBUG 01-05 12:51:32.823737.823737 lmp.py:217] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 12:51:32.823506.823506 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 12:51:32.823302.823302 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 12:51:32.823396.823396 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 12:51:32.823100.823100 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.337860107421875e-05 seconds
DEBUG 01-05 12:51:32.823048.823048 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.818771362304688e-05 seconds
DEBUG 01-05 12:51:32.823890.823890 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:32.823832.823832 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.823663.823663 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.823777.823777 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.832276.832276 cuda_h.py:19] end allocate_cuda_memory cost 0.008717060089111328 seconds
DEBUG 01-05 12:51:32.832977.832977 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.832700.832700 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.832192.832192 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.832895.832895 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94823871-219c-41bc-ae7d-c1cebbde41c5
DEBUG 01-05 12:51:32.832864.832864 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.832475.832475 cuda_h.py:10] start self_attn
INFO 01-05 12:51:32.834316.834316 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94823871-219c-41bc-ae7d-c1cebbde41c5
DEBUG 01-05 12:51:32.834344.834344 cuda_h.py:19] end load_into_gpu_async cost 0.0016353130340576172 seconds
DEBUG 01-05 12:51:32.834186.834186 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.834229.834229 cuda_h.py:19] end restore_tensors2 cost 6.508827209472656e-05 seconds
DEBUG 01-05 12:51:32.834508.834508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010777473449707031 seconds
INFO 01-05 12:51:32.834604.834604 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94823871-219c-41bc-ae7d-c1cebbde41c5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:32.836889.836889 cuda_h.py:19] end self_attn cost 0.003388643264770508 seconds
DEBUG 01-05 12:51:32.836545.836545 cuda_h.py:19] end iln_self_attn_paln cost 0.013403654098510742 seconds
DEBUG 01-05 12:51:32.836832.836832 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 12:51:32.836847.836847 cuda_h.py:10] start gate
DEBUG 01-05 12:51:32.837078.837078 cuda_h.py:19] end gate cost 0.0007238388061523438 seconds
DEBUG 01-05 12:51:32.837206.837206 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:32.838729.838729 lmp.py:365] 
DEBUG 01-05 12:51:32.838729.838729 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:32.838883.838883 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:32.838354.838354 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:32.838533.838533 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:32.838137.838137 lmp.py:369] 
DEBUG 01-05 12:51:32.838137.838137 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:32.838694.838694 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:32.838212.838212 lmp.py:376]   Expert 61 |     53 | CPU
DEBUG 01-05 12:51:32.838007.838007 lmp.py:376]   Expert 15 |     66 | CPU
DEBUG 01-05 12:51:32.838372.838372 lmp.py:376]   Expert 32 |     69 | CPU
DEBUG 01-05 12:51:32.838214.838214 lmp.py:376]   Expert  4 |     82 | CPU
DEBUG 01-05 12:51:32.838149.838149 lmp.py:376]   Expert 59 |     88 | CPU
DEBUG 01-05 12:51:32.838242.838242 lmp.py:376]   Expert 37 |     90 | CPU
DEBUG 01-05 12:51:32.838468.838468 lmp.py:376]   Expert 16 |     91 | CPU
DEBUG 01-05 12:51:32.838310.838310 lmp.py:376]   Expert  1 |     92 | CPU
DEBUG 01-05 12:51:32.838152.838152 lmp.py:376]   Expert  6 |    105 | CPU
DEBUG 01-05 12:51:32.838325.838325 lmp.py:376]   Expert 28 |    114 | CPU
DEBUG 01-05 12:51:32.838213.838213 lmp.py:376]   Expert  5 |    115 | CPU
DEBUG 01-05 12:51:32.838386.838386 lmp.py:376]   Expert  7 |    120 | CPU
DEBUG 01-05 12:51:32.838513.838513 lmp.py:376]   Expert 36 |    128 | CPU
DEBUG 01-05 12:51:32.838447.838447 lmp.py:376]   Expert 44 |    128 | CPU
DEBUG 01-05 12:51:32.838051.838051 lmp.py:376]   Expert  8 |    130 | CPU
DEBUG 01-05 12:51:32.838654.838654 lmp.py:376]   Expert 42 |    133 | CPU
DEBUG 01-05 12:51:32.838496.838496 lmp.py:376]   Expert 24 |    137 | CPU
DEBUG 01-05 12:51:32.838192.838192 lmp.py:376]   Expert 63 |    138 | CPU
DEBUG 01-05 12:51:32.838557.838557 lmp.py:376]   Expert 10 |    139 | CPU
DEBUG 01-05 12:51:32.838253.838253 lmp.py:376]   Expert 29 |    142 | CPU
DEBUG 01-05 12:51:32.838618.838618 lmp.py:376]   Expert 38 |    143 | CPU
DEBUG 01-05 12:51:32.838314.838314 lmp.py:376]   Expert 52 |    143 | CPU
DEBUG 01-05 12:51:32.838203.838203 lmp.py:376]   Expert 49 |    150 | CPU
DEBUG 01-05 12:51:32.838137.838137 lmp.py:376]   Expert 12 |    151 | CPU
DEBUG 01-05 12:51:32.838217.838217 lmp.py:376]   Expert 55 |    151 | CPU
DEBUG 01-05 12:51:32.838344.838344 lmp.py:376]   Expert 26 |    155 | CPU
DEBUG 01-05 12:51:32.838901.838901 lmp.py:376]   Expert 30 |    156 | CPU
DEBUG 01-05 12:51:32.838836.838836 lmp.py:376]   Expert 23 |    161 | CPU
DEBUG 01-05 12:51:32.838962.838962 lmp.py:376]   Expert 57 |    170 | CPU
DEBUG 01-05 12:51:32.838897.838897 lmp.py:376]   Expert 56 |    174 | CPU
DEBUG 01-05 12:51:32.838785.838785 lmp.py:376]   Expert 58 |    175 | CPU
DEBUG 01-05 12:51:32.838719.838719 lmp.py:376]   Expert 11 |    177 | CPU
DEBUG 01-05 12:51:32.838614.838614 lmp.py:376]   Expert 62 |    180 | GPU
DEBUG 01-05 12:51:32.838310.838310 lmp.py:376]   Expert 18 |    181 | GPU
DEBUG 01-05 12:51:32.839152.839152 lmp.py:376]   Expert 48 |    191 | GPU
DEBUG 01-05 12:51:32.839040.839040 lmp.py:376]   Expert  2 |    193 | GPU
DEBUG 01-05 12:51:32.839882.839882 lmp.py:376]   Expert 40 |    193 | GPU
DEBUG 01-05 12:51:32.839532.839532 lmp.py:376]   Expert 47 |    193 | GPU
DEBUG 01-05 12:51:32.839182.839182 lmp.py:376]   Expert 31 |    195 | GPU
DEBUG 01-05 12:51:32.839878.839878 lmp.py:376]   Expert 35 |    195 | GPU
DEBUG 01-05 12:51:32.839051.839051 lmp.py:376]   Expert 13 |    196 | GPU
DEBUG 01-05 12:51:32.839985.839985 lmp.py:376]   Expert 20 |    206 | GPU
DEBUG 01-05 12:51:32.839397.839397 lmp.py:376]   Expert 45 |    211 | GPU
DEBUG 01-05 12:51:32.839570.839570 lmp.py:376]   Expert  0 |    222 | GPU
DEBUG 01-05 12:51:32.839981.839981 lmp.py:376]   Expert 46 |    225 | GPU
DEBUG 01-05 12:51:32.839392.839392 lmp.py:376]   Expert 17 |    227 | GPU
DEBUG 01-05 12:51:32.839757.839757 lmp.py:376]   Expert 39 |    229 | GPU
DEBUG 01-05 12:51:32.839407.839407 lmp.py:376]   Expert 22 |    233 | GPU
DEBUG 01-05 12:51:32.839534.839534 lmp.py:376]   Expert 33 |    235 | GPU
DEBUG 01-05 12:51:32.839230.839230 lmp.py:376]   Expert 19 |    240 | GPU
DEBUG 01-05 12:51:32.839880.839880 lmp.py:376]   Expert 51 |    240 | GPU
DEBUG 01-05 12:51:32.839099.839099 lmp.py:376]   Expert 34 |    243 | GPU
DEBUG 01-05 12:51:32.839225.839225 lmp.py:376]   Expert 53 |    254 | GPU
DEBUG 01-05 12:51:32.839683.839683 lmp.py:376]   Expert 27 |    269 | GPU
DEBUG 01-05 12:51:32.839094.839094 lmp.py:376]   Expert  3 |    272 | GPU
DEBUG 01-05 12:51:32.839983.839983 lmp.py:376]   Expert 54 |    291 | GPU
DEBUG 01-05 12:51:32.839586.839586 lmp.py:376]   Expert 50 |    299 | GPU
DEBUG 01-05 12:51:32.839713.839713 lmp.py:376]   Expert 60 |    311 | GPU
DEBUG 01-05 12:51:32.839362.839362 lmp.py:376]   Expert 21 |    326 | GPU
DEBUG 01-05 12:51:32.839297.839297 lmp.py:376]   Expert 14 |    334 | GPU
DEBUG 01-05 12:51:32.839424.839424 lmp.py:376]   Expert 43 |    382 | GPU
DEBUG 01-05 12:51:32.839120.839120 lmp.py:376]   Expert  9 |    391 | GPU
DEBUG 01-05 12:51:32.839769.839769 lmp.py:376]   Expert 41 |    398 | GPU
DEBUG 01-05 12:51:32.839711.839711 lmp.py:376]   Expert 25 |    467 | GPU
DEBUG 01-05 12:51:32.839798.839798 lmp.py:377] 
DEBUG 01-05 12:51:32.839798.839798 lmp.py:377]   CPU total tokens: 4066 (33.1%)
DEBUG 01-05 12:51:32.839070.839070 lmp.py:378]   GPU total tokens: 8222 (66.9%)
DEBUG 01-05 12:51:32.839780.839780 cuda_h.py:19] end experts_map_get cost 0.0020723342895507812 seconds
DEBUG 01-05 12:51:32.839814.839814 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:32.839087.839087 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.840490.840490 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.841391.841391 cuda_h.py:19] end allocate_cuda_memory cost 0.0011484622955322266 seconds
DEBUG 01-05 12:51:32.841493.841493 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.841024.841024 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.841661.841661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.841417.841417 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8250b53f-865a-4edb-be73-8ef3f9f18082
DEBUG 01-05 12:51:32.841114.841114 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.841791.841791 mlpmodule.py:662]  experts func einsum cost 0.07868123054504395 s
INFO 01-05 12:51:32.842997.842997 client.py:127] Model loaded
DEBUG 01-05 12:51:32.842930.842930 cuda_h.py:19] end sllm_worker_task cost 0.018840312957763672 seconds
INFO 01-05 12:51:32.843746.843746 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8250b53f-865a-4edb-be73-8ef3f9f18082
DEBUG 01-05 12:51:32.844419.844419 cuda_h.py:19] end load_into_gpu_async cost 0.0026962757110595703 seconds
DEBUG 01-05 12:51:32.844104.844104 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.844429.844429 cuda_h.py:19] end restore_tensors2 cost 0.0005228519439697266 seconds
DEBUG 01-05 12:51:32.844477.844477 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00489354133605957 seconds
DEBUG 01-05 12:51:32.847781.847781 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076999664306640625 seconds
DEBUG 01-05 12:51:32.847618.847618 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:32.847601.847601 lmp.py:423] 
DEBUG 01-05 12:51:32.847601.847601 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:32.847020.847020 cuda_h.py:19] end cpu_experts_submit cost 0.00011324882507324219 seconds
DEBUG 01-05 12:51:32.847624.847624 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:32.856398.856398 mlpmodule.py:704] group tensors cost 0.008780479431152344 s
DEBUG 01-05 12:51:32.861552.861552 mlpmodule.py:742] pad cost 0.0032651424407958984 s
DEBUG 01-05 12:51:32.861324.861324 mlpmodule.py:748] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-05 12:51:32.861459.861459 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-05 12:51:32.871988.871988 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:32.871571.871571 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:32.871508.871508 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 12:51:32.871492.871492 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:32.888490.888490 mlpmodule.py:793] group einsum cost 0.027154922485351562 s
DEBUG 01-05 12:51:32.889077.889077 mlpmodule.py:801] cpy2cputensor cost 0.0007305145263671875 s
DEBUG 01-05 12:51:32.894298.894298 cuda_h.py:19] end wait_cetm_experts cost 0.046172380447387695 seconds
DEBUG 01-05 12:51:32.894330.894330 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:32.894239.894239 cuda_h.py:19] end gpu_sexperts cost 0.0005896091461181641 seconds
DEBUG 01-05 12:51:32.894519.894519 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:32.894045.894045 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.266334533691406e-05 seconds
DEBUG 01-05 12:51:32.894655.894655 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:32.895365.895365 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8250b53f-865a-4edb-be73-8ef3f9f18082
INFO 01-05 12:51:32.896287.896287 client.py:127] Model loaded
DEBUG 01-05 12:51:32.896084.896084 cuda_h.py:19] end wait_experts cost 0.0013034343719482422 seconds
DEBUG 01-05 12:51:32.896648.896648 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:32.896404.896404 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:32.897913.897913 mlpmodule.py:531] gpu group tensors cost 0.0006558895111083984 s
DEBUG 01-05 12:51:32.898675.898675 mlpmodule.py:564] gpu pad cost 0.0017313957214355469 s
DEBUG 01-05 12:51:32.899854.899854 mlpmodule.py:582] gpu group einsum cost 0.0005445480346679688 s
DEBUG 01-05 12:51:32.903157.903157 mlpmodule.py:611] gpu experts func einsum cost 0.00677037239074707 s
DEBUG 01-05 12:51:32.903899.903899 cuda_h.py:19] end gpu_experts cost 0.007071733474731445 seconds
DEBUG 01-05 12:51:32.903650.903650 cuda_h.py:19] end layer_moe_generate_3 cost 0.06671547889709473 seconds
DEBUG 01-05 12:51:32.903148.903148 lmp.py:217] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 12:51:32.903825.903825 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 12:51:32.903336.903336 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 12:51:32.903622.903622 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 12:51:32.903518.903518 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.4809112548828125e-05 seconds
DEBUG 01-05 12:51:32.903512.903512 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.890296936035156e-05 seconds
DEBUG 01-05 12:51:32.903354.903354 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:32.904104.904104 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.904465.904465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.904818.904818 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.904081.904081 cuda_h.py:19] end allocate_cuda_memory cost 0.0002970695495605469 seconds
DEBUG 01-05 12:51:32.904123.904123 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.904263.904263 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.904754.904754 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.904934.904934 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff3c0baf-6e2e-44db-b121-6c83200431bb
DEBUG 01-05 12:51:32.904957.904957 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.905175.905175 cuda_h.py:10] start self_attn
INFO 01-05 12:51:32.906042.906042 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff3c0baf-6e2e-44db-b121-6c83200431bb
DEBUG 01-05 12:51:32.906408.906408 cuda_h.py:19] end load_into_gpu_async cost 0.0015783309936523438 seconds
DEBUG 01-05 12:51:32.906204.906204 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.906426.906426 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-05 12:51:32.906036.906036 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021822452545166016 seconds
INFO 01-05 12:51:32.906595.906595 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff3c0baf-6e2e-44db-b121-6c83200431bb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:32.908859.908859 cuda_h.py:19] end self_attn cost 0.003300905227661133 seconds
DEBUG 01-05 12:51:32.908624.908624 cuda_h.py:19] end iln_self_attn_paln cost 0.0048711299896240234 seconds
DEBUG 01-05 12:51:32.908845.908845 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 12:51:32.908892.908892 cuda_h.py:10] start gate
DEBUG 01-05 12:51:32.909596.909596 cuda_h.py:19] end gate cost 0.0006268024444580078 seconds
DEBUG 01-05 12:51:32.909426.909426 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:32.909588.909588 lmp.py:365] 
DEBUG 01-05 12:51:32.909588.909588 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:32.910205.910205 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:32.910809.910809 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:32.910882.910882 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:32.910810.910810 lmp.py:369] 
DEBUG 01-05 12:51:32.910810.910810 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:32.910738.910738 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:32.910626.910626 lmp.py:376]   Expert 13 |     36 | CPU
DEBUG 01-05 12:51:32.910653.910653 lmp.py:376]   Expert 60 |     54 | CPU
DEBUG 01-05 12:51:32.910965.910965 lmp.py:376]   Expert 11 |     63 | CPU
DEBUG 01-05 12:51:32.910654.910654 lmp.py:376]   Expert 56 |     78 | CPU
DEBUG 01-05 12:51:32.910059.910059 lmp.py:376]   Expert  3 |     79 | CPU
DEBUG 01-05 12:51:32.910463.910463 lmp.py:376]   Expert 26 |     79 | CPU
DEBUG 01-05 12:51:32.910583.910583 lmp.py:376]   Expert 58 |     82 | CPU
DEBUG 01-05 12:51:32.910511.910511 lmp.py:376]   Expert  7 |     86 | CPU
DEBUG 01-05 12:51:32.910392.910392 lmp.py:376]   Expert 25 |     87 | CPU
DEBUG 01-05 12:51:32.910797.910797 lmp.py:376]   Expert 36 |     90 | CPU
DEBUG 01-05 12:51:32.910916.910916 lmp.py:376]   Expert 51 |     92 | CPU
DEBUG 01-05 12:51:32.910844.910844 lmp.py:376]   Expert 28 |     94 | CPU
DEBUG 01-05 12:51:32.910202.910202 lmp.py:376]   Expert 45 |     94 | CPU
DEBUG 01-05 12:51:32.910130.910130 lmp.py:376]   Expert 34 |     96 | CPU
DEBUG 01-05 12:51:32.910012.910012 lmp.py:376]   Expert 48 |     98 | CPU
DEBUG 01-05 12:51:32.910701.910701 lmp.py:376]   Expert  6 |    100 | CPU
DEBUG 01-05 12:51:32.910105.910105 lmp.py:376]   Expert 41 |    103 | CPU
DEBUG 01-05 12:51:32.910556.910556 lmp.py:376]   Expert 16 |    104 | CPU
DEBUG 01-05 12:51:32.910914.910914 lmp.py:376]   Expert 33 |    109 | CPU
DEBUG 01-05 12:51:32.910365.910365 lmp.py:376]   Expert 55 |    125 | CPU
DEBUG 01-05 12:51:32.910532.910532 lmp.py:376]   Expert  9 |    127 | CPU
DEBUG 01-05 12:51:32.910698.910698 lmp.py:376]   Expert 24 |    127 | CPU
DEBUG 01-05 12:51:32.910056.910056 lmp.py:376]   Expert 18 |    128 | CPU
DEBUG 01-05 12:51:32.910222.910222 lmp.py:376]   Expert 14 |    132 | CPU
DEBUG 01-05 12:51:32.910819.910819 lmp.py:376]   Expert 17 |    133 | CPU
DEBUG 01-05 12:51:32.910223.910223 lmp.py:376]   Expert  4 |    141 | CPU
DEBUG 01-05 12:51:32.910343.910343 lmp.py:376]   Expert 50 |    144 | CPU
DEBUG 01-05 12:51:32.910032.910032 lmp.py:376]   Expert  2 |    147 | CPU
DEBUG 01-05 12:51:32.910437.910437 lmp.py:376]   Expert 47 |    150 | CPU
DEBUG 01-05 12:51:32.910365.910365 lmp.py:376]   Expert 44 |    156 | CPU
DEBUG 01-05 12:51:32.910008.910008 lmp.py:376]   Expert 22 |    167 | CPU
DEBUG 01-05 12:51:32.910174.910174 lmp.py:376]   Expert 10 |    175 | CPU
DEBUG 01-05 12:51:32.910294.910294 lmp.py:376]   Expert 31 |    183 | GPU
DEBUG 01-05 12:51:32.910221.910221 lmp.py:376]   Expert 54 |    186 | GPU
DEBUG 01-05 12:51:32.910579.910579 lmp.py:376]   Expert 37 |    188 | GPU
DEBUG 01-05 12:51:32.910984.910984 lmp.py:376]   Expert 40 |    194 | GPU
DEBUG 01-05 12:51:32.910865.910865 lmp.py:376]   Expert 21 |    198 | GPU
DEBUG 01-05 12:51:32.910555.910555 lmp.py:376]   Expert 61 |    198 | GPU
DEBUG 01-05 12:51:32.910959.910959 lmp.py:376]   Expert 15 |    202 | GPU
DEBUG 01-05 12:51:32.910887.910887 lmp.py:376]   Expert 46 |    202 | GPU
DEBUG 01-05 12:51:32.910530.910530 lmp.py:376]   Expert 53 |    206 | GPU
DEBUG 01-05 12:51:32.910219.910219 lmp.py:376]   Expert  8 |    209 | GPU
DEBUG 01-05 12:51:32.910862.910862 lmp.py:376]   Expert 42 |    213 | GPU
DEBUG 01-05 12:51:32.910313.910313 lmp.py:376]   Expert 63 |    219 | GPU
DEBUG 01-05 12:51:32.910671.910671 lmp.py:376]   Expert 27 |    230 | GPU
DEBUG 01-05 12:51:32.910314.910314 lmp.py:376]   Expert 29 |    231 | GPU
DEBUG 01-05 12:51:32.910196.910196 lmp.py:376]   Expert 20 |    232 | GPU
DEBUG 01-05 12:51:32.910362.910362 lmp.py:376]   Expert 32 |    233 | GPU
DEBUG 01-05 12:51:32.910197.910197 lmp.py:376]   Expert 57 |    236 | GPU
DEBUG 01-05 12:51:32.910125.910125 lmp.py:376]   Expert 19 |    262 | GPU
DEBUG 01-05 12:51:32.910768.910768 lmp.py:376]   Expert 38 |    263 | GPU
DEBUG 01-05 12:51:32.911980.911980 lmp.py:376]   Expert 23 |    269 | GPU
DEBUG 01-05 12:51:32.911100.911100 lmp.py:376]   Expert  0 |    275 | GPU
DEBUG 01-05 12:51:32.911789.911789 lmp.py:376]   Expert  1 |    283 | GPU
DEBUG 01-05 12:51:32.911955.911955 lmp.py:376]   Expert 62 |    292 | GPU
DEBUG 01-05 12:51:32.911883.911883 lmp.py:376]   Expert 12 |    295 | GPU
DEBUG 01-05 12:51:32.911526.911526 lmp.py:376]   Expert 30 |    307 | GPU
DEBUG 01-05 12:51:32.911169.911169 lmp.py:376]   Expert 49 |    318 | GPU
DEBUG 01-05 12:51:32.911766.911766 lmp.py:376]   Expert 35 |    331 | GPU
DEBUG 01-05 12:51:32.911932.911932 lmp.py:376]   Expert 52 |    397 | GPU
DEBUG 01-05 12:51:32.911575.911575 lmp.py:376]   Expert  5 |    424 | GPU
DEBUG 01-05 12:51:32.911264.911264 lmp.py:376]   Expert 39 |    424 | GPU
DEBUG 01-05 12:51:32.911145.911145 lmp.py:376]   Expert 43 |    486 | GPU
DEBUG 01-05 12:51:32.911596.911596 lmp.py:376]   Expert 59 |    626 | GPU
DEBUG 01-05 12:51:32.911431.911431 lmp.py:377] 
DEBUG 01-05 12:51:32.911431.911431 lmp.py:377]   CPU total tokens: 3476 (28.3%)
DEBUG 01-05 12:51:32.911074.911074 lmp.py:378]   GPU total tokens: 8812 (71.7%)
DEBUG 01-05 12:51:32.911439.911439 cuda_h.py:19] end experts_map_get cost 0.0015621185302734375 seconds
DEBUG 01-05 12:51:32.911082.911082 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:32.911342.911342 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.911579.911579 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.913501.913501 cuda_h.py:19] end allocate_cuda_memory cost 0.001804351806640625 seconds
DEBUG 01-05 12:51:32.913650.913650 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.913982.913982 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.913110.913110 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.913243.913243 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6bffc49d-7ffc-4bf6-9493-22e962e2ea0c
DEBUG 01-05 12:51:32.913852.913852 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.913997.913997 mlpmodule.py:662]  experts func einsum cost 0.06589174270629883 s
INFO 01-05 12:51:32.914119.914119 client.py:127] Model loaded
DEBUG 01-05 12:51:32.914824.914824 cuda_h.py:19] end sllm_worker_task cost 0.010133981704711914 seconds
INFO 01-05 12:51:32.915305.915305 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6bffc49d-7ffc-4bf6-9493-22e962e2ea0c
DEBUG 01-05 12:51:32.915632.915632 cuda_h.py:19] end load_into_gpu_async cost 0.002408742904663086 seconds
DEBUG 01-05 12:51:32.915309.915309 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.916859.916859 cuda_h.py:19] end restore_tensors2 cost 0.0003790855407714844 seconds
DEBUG 01-05 12:51:32.916364.916364 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004978179931640625 seconds
DEBUG 01-05 12:51:32.918749.918749 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00762629508972168 seconds
DEBUG 01-05 12:51:32.919347.919347 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:32.919641.919641 lmp.py:423] 
DEBUG 01-05 12:51:32.919641.919641 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:32.919537.919537 cuda_h.py:19] end cpu_experts_submit cost 0.00011301040649414062 seconds
DEBUG 01-05 12:51:32.919710.919710 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:32.924584.924584 mlpmodule.py:704] group tensors cost 0.005239009857177734 s
DEBUG 01-05 12:51:32.927655.927655 mlpmodule.py:742] pad cost 0.0018506050109863281 s
DEBUG 01-05 12:51:32.927209.927209 mlpmodule.py:748] create cpu tensor cost 5.030632019042969e-05 s
DEBUG 01-05 12:51:32.927595.927595 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-05 12:51:32.936108.936108 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:32.936445.936445 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:32.937349.937349 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 12:51:32.937121.937121 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:32.952767.952767 mlpmodule.py:793] group einsum cost 0.024619579315185547 s
DEBUG 01-05 12:51:32.953494.953494 mlpmodule.py:801] cpy2cputensor cost 0.0007486343383789062 s
DEBUG 01-05 12:51:32.957322.957322 cuda_h.py:19] end wait_cetm_experts cost 0.03836846351623535 seconds
DEBUG 01-05 12:51:32.957354.957354 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:32.958997.958997 cuda_h.py:19] end gpu_sexperts cost 0.0005729198455810547 seconds
DEBUG 01-05 12:51:32.958729.958729 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:32.958553.958553 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.361701965332031e-05 seconds
DEBUG 01-05 12:51:32.958402.958402 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:32.958019.958019 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6bffc49d-7ffc-4bf6-9493-22e962e2ea0c
INFO 01-05 12:51:32.966622.966622 client.py:127] Model loaded
DEBUG 01-05 12:51:32.966095.966095 cuda_h.py:19] end wait_experts cost 0.007992982864379883 seconds
DEBUG 01-05 12:51:32.966374.966374 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:32.966083.966083 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:32.967512.967512 mlpmodule.py:531] gpu group tensors cost 0.0006508827209472656 s
DEBUG 01-05 12:51:32.970442.970442 mlpmodule.py:564] gpu pad cost 0.0034019947052001953 s
DEBUG 01-05 12:51:32.975495.975495 mlpmodule.py:662]  experts func einsum cost 0.055635690689086914 s
DEBUG 01-05 12:51:32.975914.975914 mlpmodule.py:582] gpu group einsum cost 0.0044934749603271484 s
DEBUG 01-05 12:51:32.978282.978282 mlpmodule.py:611] gpu experts func einsum cost 0.011576175689697266 s
DEBUG 01-05 12:51:32.978744.978744 cuda_h.py:19] end gpu_experts cost 0.011830806732177734 seconds
DEBUG 01-05 12:51:32.978668.978668 cuda_h.py:19] end layer_moe_generate_4 cost 0.06964302062988281 seconds
DEBUG 01-05 12:51:32.978595.978595 lmp.py:217] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 12:51:32.978265.978265 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 12:51:32.978053.978053 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 12:51:32.978902.978902 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 12:51:32.978884.978884 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.170967102050781e-05 seconds
DEBUG 01-05 12:51:32.978700.978700 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.62939453125e-05 seconds
DEBUG 01-05 12:51:32.979581.979581 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:32.979591.979591 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:32.979560.979560 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.979247.979247 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.979303.979303 cuda_h.py:19] end allocate_cuda_memory cost 0.00036144256591796875 seconds
DEBUG 01-05 12:51:32.980719.980719 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.980339.980339 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.980543.980543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.980586.980586 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a4056a5-adb6-4c9b-8770-85dd9bf7df17
DEBUG 01-05 12:51:32.980077.980077 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:32.980305.980305 cuda_h.py:10] start self_attn
INFO 01-05 12:51:32.982572.982572 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a4056a5-adb6-4c9b-8770-85dd9bf7df17
DEBUG 01-05 12:51:32.982233.982233 cuda_h.py:19] end load_into_gpu_async cost 0.0023763179779052734 seconds
DEBUG 01-05 12:51:32.982985.982985 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.982172.982172 cuda_h.py:19] end restore_tensors2 cost 0.00014781951904296875 seconds
DEBUG 01-05 12:51:32.983652.983652 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036382675170898438 seconds
INFO 01-05 12:51:32.984587.984587 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a4056a5-adb6-4c9b-8770-85dd9bf7df17
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:32.985773.985773 cuda_h.py:19] end self_attn cost 0.004685640335083008 seconds
DEBUG 01-05 12:51:32.986552.986552 cuda_h.py:19] end iln_self_attn_paln cost 0.00687718391418457 seconds
DEBUG 01-05 12:51:32.986534.986534 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 12:51:32.986297.986297 cuda_h.py:10] start gate
DEBUG 01-05 12:51:32.986164.986164 cuda_h.py:19] end gate cost 0.0007464885711669922 seconds
DEBUG 01-05 12:51:32.986802.986802 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:32.987394.987394 lmp.py:365] 
DEBUG 01-05 12:51:32.987394.987394 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:32.987720.987720 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:32.987131.987131 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:32.987681.987681 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:32.987563.987563 lmp.py:369] 
DEBUG 01-05 12:51:32.987563.987563 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:32.987729.987729 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:32.987094.987094 lmp.py:376]   Expert 34 |     27 | CPU
DEBUG 01-05 12:51:32.987499.987499 lmp.py:376]   Expert 15 |     47 | CPU
DEBUG 01-05 12:51:32.987473.987473 lmp.py:376]   Expert 47 |     47 | CPU
DEBUG 01-05 12:51:32.987447.987447 lmp.py:376]   Expert 39 |     48 | CPU
DEBUG 01-05 12:51:32.987659.987659 lmp.py:376]   Expert  2 |     55 | CPU
DEBUG 01-05 12:51:32.987156.987156 lmp.py:376]   Expert 18 |     71 | CPU
DEBUG 01-05 12:51:32.987892.987892 lmp.py:376]   Expert  3 |     88 | CPU
DEBUG 01-05 12:51:32.987151.987151 lmp.py:376]   Expert 23 |     90 | CPU
DEBUG 01-05 12:51:32.987509.987509 lmp.py:376]   Expert 27 |     90 | CPU
DEBUG 01-05 12:51:32.987437.987437 lmp.py:376]   Expert 30 |     99 | CPU
DEBUG 01-05 12:51:32.987126.987126 lmp.py:376]   Expert 17 |    110 | CPU
DEBUG 01-05 12:51:32.987292.987292 lmp.py:376]   Expert 45 |    110 | CPU
DEBUG 01-05 12:51:32.987981.987981 lmp.py:376]   Expert 52 |    110 | CPU
DEBUG 01-05 12:51:32.987955.987955 lmp.py:376]   Expert  4 |    113 | CPU
DEBUG 01-05 12:51:32.987691.987691 lmp.py:376]   Expert 28 |    113 | CPU
DEBUG 01-05 12:51:32.987188.987188 lmp.py:376]   Expert  0 |    116 | CPU
DEBUG 01-05 12:51:32.987162.987162 lmp.py:376]   Expert 63 |    120 | CPU
DEBUG 01-05 12:51:32.987136.987136 lmp.py:376]   Expert 22 |    121 | CPU
DEBUG 01-05 12:51:32.987395.987395 lmp.py:376]   Expert 62 |    121 | CPU
DEBUG 01-05 12:51:32.987131.987131 lmp.py:376]   Expert  8 |    122 | CPU
DEBUG 01-05 12:51:32.987628.987628 lmp.py:376]   Expert 60 |    123 | CPU
DEBUG 01-05 12:51:32.987364.987364 lmp.py:376]   Expert  9 |    129 | CPU
DEBUG 01-05 12:51:32.987099.987099 lmp.py:376]   Expert 48 |    136 | CPU
DEBUG 01-05 12:51:32.987550.987550 lmp.py:376]   Expert 14 |    140 | CPU
DEBUG 01-05 12:51:32.987001.987001 lmp.py:376]   Expert 51 |    142 | CPU
DEBUG 01-05 12:51:32.987452.987452 lmp.py:376]   Expert 54 |    147 | CPU
DEBUG 01-05 12:51:32.987188.987188 lmp.py:376]   Expert 41 |    148 | CPU
DEBUG 01-05 12:51:32.987685.987685 lmp.py:376]   Expert 10 |    151 | CPU
DEBUG 01-05 12:51:32.987182.987182 lmp.py:376]   Expert 46 |    154 | CPU
DEBUG 01-05 12:51:32.987441.987441 lmp.py:376]   Expert 36 |    160 | CPU
DEBUG 01-05 12:51:32.987938.987938 lmp.py:376]   Expert  1 |    166 | CPU
DEBUG 01-05 12:51:32.987197.987197 lmp.py:376]   Expert 25 |    170 | CPU
DEBUG 01-05 12:51:32.987455.987455 lmp.py:376]   Expert 43 |    171 | GPU
DEBUG 01-05 12:51:32.987953.987953 lmp.py:376]   Expert 57 |    171 | GPU
DEBUG 01-05 12:51:32.987450.987450 lmp.py:376]   Expert 38 |    174 | GPU
DEBUG 01-05 12:51:32.987186.987186 lmp.py:376]   Expert 26 |    178 | GPU
DEBUG 01-05 12:51:32.987544.987544 lmp.py:376]   Expert 24 |    179 | GPU
DEBUG 01-05 12:51:32.987425.987425 lmp.py:376]   Expert 11 |    188 | GPU
DEBUG 01-05 12:51:32.988307.988307 lmp.py:376]   Expert 32 |    194 | GPU
DEBUG 01-05 12:51:32.988188.988188 lmp.py:376]   Expert 56 |    197 | GPU
DEBUG 01-05 12:51:32.988354.988354 lmp.py:376]   Expert 16 |    200 | GPU
DEBUG 01-05 12:51:32.988282.988282 lmp.py:376]   Expert 58 |    203 | GPU
DEBUG 01-05 12:51:32.988210.988210 lmp.py:376]   Expert 29 |    207 | GPU
DEBUG 01-05 12:51:32.988899.988899 lmp.py:376]   Expert 12 |    213 | GPU
DEBUG 01-05 12:51:32.988303.988303 lmp.py:376]   Expert 55 |    224 | GPU
DEBUG 01-05 12:51:32.988231.988231 lmp.py:376]   Expert 50 |    228 | GPU
DEBUG 01-05 12:51:32.988159.988159 lmp.py:376]   Expert 42 |    231 | GPU
DEBUG 01-05 12:51:32.988325.988325 lmp.py:376]   Expert 44 |    231 | GPU
DEBUG 01-05 12:51:32.988253.988253 lmp.py:376]   Expert 61 |    231 | GPU
DEBUG 01-05 12:51:32.988896.988896 lmp.py:376]   Expert 19 |    232 | GPU
DEBUG 01-05 12:51:32.988539.988539 lmp.py:376]   Expert  7 |    236 | GPU
DEBUG 01-05 12:51:32.988943.988943 lmp.py:376]   Expert 35 |    240 | GPU
DEBUG 01-05 12:51:32.988063.988063 lmp.py:376]   Expert 59 |    259 | GPU
DEBUG 01-05 12:51:32.988229.988229 lmp.py:376]   Expert 21 |    284 | GPU
DEBUG 01-05 12:51:32.988395.988395 lmp.py:376]   Expert  5 |    289 | GPU
DEBUG 01-05 12:51:32.988323.988323 lmp.py:376]   Expert 20 |    297 | GPU
DEBUG 01-05 12:51:32.988251.988251 lmp.py:376]   Expert 40 |    300 | GPU
DEBUG 01-05 12:51:32.988417.988417 lmp.py:376]   Expert 31 |    324 | GPU
DEBUG 01-05 12:51:32.988583.988583 lmp.py:376]   Expert 13 |    349 | GPU
DEBUG 01-05 12:51:32.988749.988749 lmp.py:376]   Expert 33 |    357 | GPU
DEBUG 01-05 12:51:32.988975.988975 lmp.py:376]   Expert  6 |    369 | GPU
DEBUG 01-05 12:51:32.988426.988426 lmp.py:376]   Expert 49 |    392 | GPU
DEBUG 01-05 12:51:32.988592.988592 lmp.py:376]   Expert 37 |    481 | GPU
DEBUG 01-05 12:51:32.988712.988712 lmp.py:376]   Expert 53 |    875 | GPU
DEBUG 01-05 12:51:32.988832.988832 lmp.py:377] 
DEBUG 01-05 12:51:32.988832.988832 lmp.py:377]   CPU total tokens: 3584 (29.2%)
DEBUG 01-05 12:51:32.988667.988667 lmp.py:378]   GPU total tokens: 8704 (70.8%)
DEBUG 01-05 12:51:32.988317.988317 cuda_h.py:19] end experts_map_get cost 0.0015113353729248047 seconds
DEBUG 01-05 12:51:32.988913.988913 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:32.988074.988074 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:32.988588.988588 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:32.989389.989389 cuda_h.py:19] end allocate_cuda_memory cost 0.0009438991546630859 seconds
DEBUG 01-05 12:51:32.989086.989086 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:32.989366.989366 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:32.989473.989473 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:32.989030.989030 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7438112-6a3f-4424-984c-0ee1b224189a
DEBUG 01-05 12:51:32.990712.990712 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:32.990286.990286 client.py:127] Model loaded
DEBUG 01-05 12:51:32.990847.990847 cuda_h.py:19] end sllm_worker_task cost 0.011352777481079102 seconds
INFO 01-05 12:51:32.992163.992163 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7438112-6a3f-4424-984c-0ee1b224189a
DEBUG 01-05 12:51:32.992966.992966 cuda_h.py:19] end load_into_gpu_async cost 0.0025110244750976562 seconds
DEBUG 01-05 12:51:32.992954.992954 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:32.992432.992432 cuda_h.py:19] end restore_tensors2 cost 0.0003960132598876953 seconds
DEBUG 01-05 12:51:32.992367.992367 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004195690155029297 seconds
DEBUG 01-05 12:51:32.995771.995771 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006785154342651367 seconds
DEBUG 01-05 12:51:32.995753.995753 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:32.995616.995616 lmp.py:423] 
DEBUG 01-05 12:51:32.995616.995616 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:32.995029.995029 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-05 12:51:32.995917.995917 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.001749.001749 mlpmodule.py:704] group tensors cost 0.006018877029418945 s
DEBUG 01-05 12:51:33.004729.004729 mlpmodule.py:742] pad cost 0.001627206802368164 s
DEBUG 01-05 12:51:33.004594.004594 mlpmodule.py:748] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-05 12:51:33.004821.004821 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-05 12:51:33.015935.015935 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.015312.015312 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.015057.015057 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 12:51:33.015564.015564 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.030554.030554 mlpmodule.py:793] group einsum cost 0.02572321891784668 s
DEBUG 01-05 12:51:33.031128.031128 mlpmodule.py:801] cpy2cputensor cost 0.0007035732269287109 s
DEBUG 01-05 12:51:33.035675.035675 cuda_h.py:19] end wait_cetm_experts cost 0.03999066352844238 seconds
DEBUG 01-05 12:51:33.035416.035416 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.036556.036556 cuda_h.py:19] end gpu_sexperts cost 0.00057220458984375 seconds
DEBUG 01-05 12:51:33.036545.036545 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.036878.036878 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.123283386230469e-05 seconds
DEBUG 01-05 12:51:33.036727.036727 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.036914.036914 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7438112-6a3f-4424-984c-0ee1b224189a
INFO 01-05 12:51:33.042296.042296 client.py:127] Model loaded
DEBUG 01-05 12:51:33.042868.042868 cuda_h.py:19] end wait_experts cost 0.006357669830322266 seconds
DEBUG 01-05 12:51:33.042386.042386 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.043095.043095 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.043980.043980 mlpmodule.py:531] gpu group tensors cost 0.0006396770477294922 s
DEBUG 01-05 12:51:33.051994.051994 mlpmodule.py:564] gpu pad cost 0.007235288619995117 s
DEBUG 01-05 12:51:33.053911.053911 mlpmodule.py:662]  experts func einsum cost 0.057955265045166016 s
DEBUG 01-05 12:51:33.054894.054894 mlpmodule.py:582] gpu group einsum cost 0.0033445358276367188 s
DEBUG 01-05 12:51:33.060091.060091 mlpmodule.py:611] gpu experts func einsum cost 0.017395734786987305 s
DEBUG 01-05 12:51:33.060164.060164 cuda_h.py:19] end gpu_experts cost 0.017676353454589844 seconds
DEBUG 01-05 12:51:33.060976.060976 cuda_h.py:19] end layer_moe_generate_5 cost 0.0746605396270752 seconds
DEBUG 01-05 12:51:33.061175.061175 lmp.py:217] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 12:51:33.061051.061051 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 12:51:33.061707.061707 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 12:51:33.061377.061377 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 12:51:33.061519.061519 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.600120544433594e-05 seconds
DEBUG 01-05 12:51:33.061851.061851 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.486343383789062e-05 seconds
DEBUG 01-05 12:51:33.061408.061408 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.061371.061371 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.061131.061131 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.061665.061665 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.061723.061723 cuda_h.py:19] end allocate_cuda_memory cost 0.00025200843811035156 seconds
DEBUG 01-05 12:51:33.062475.062475 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.062968.062968 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.062706.062706 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.062635.062635 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d9c05b7-8137-47e6-b5ab-df1ce6757a9c
DEBUG 01-05 12:51:33.062906.062906 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.062941.062941 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.064070.064070 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d9c05b7-8137-47e6-b5ab-df1ce6757a9c
DEBUG 01-05 12:51:33.064676.064676 cuda_h.py:19] end load_into_gpu_async cost 0.0019598007202148438 seconds
DEBUG 01-05 12:51:33.064175.064175 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.064134.064134 cuda_h.py:19] end restore_tensors2 cost 0.00011014938354492188 seconds
DEBUG 01-05 12:51:33.064893.064893 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00286865234375 seconds
INFO 01-05 12:51:33.065622.065622 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d9c05b7-8137-47e6-b5ab-df1ce6757a9c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.067055.067055 cuda_h.py:19] end self_attn cost 0.004718303680419922 seconds
DEBUG 01-05 12:51:33.067776.067776 cuda_h.py:19] end iln_self_attn_paln cost 0.0065898895263671875 seconds
DEBUG 01-05 12:51:33.067202.067202 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 12:51:33.067455.067455 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.068582.068582 cuda_h.py:19] end gate cost 0.0007905960083007812 seconds
DEBUG 01-05 12:51:33.068173.068173 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.069528.069528 lmp.py:365] 
DEBUG 01-05 12:51:33.069528.069528 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.069284.069284 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.069218.069218 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.069053.069053 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.069742.069742 lmp.py:369] 
DEBUG 01-05 12:51:33.069742.069742 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.069432.069432 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.069843.069843 lmp.py:376]   Expert  1 |      6 | CPU
DEBUG 01-05 12:51:33.069201.069201 lmp.py:376]   Expert  3 |     27 | CPU
DEBUG 01-05 12:51:33.069891.069891 lmp.py:376]   Expert 14 |     52 | CPU
DEBUG 01-05 12:51:33.069057.069057 lmp.py:376]   Expert 53 |     53 | CPU
DEBUG 01-05 12:51:33.069130.069130 lmp.py:376]   Expert 52 |     59 | CPU
DEBUG 01-05 12:51:33.069343.069343 lmp.py:376]   Expert 35 |     70 | CPU
DEBUG 01-05 12:51:33.069078.069078 lmp.py:376]   Expert 44 |     78 | CPU
DEBUG 01-05 12:51:33.069814.069814 lmp.py:376]   Expert 15 |     79 | CPU
DEBUG 01-05 12:51:33.069311.069311 lmp.py:376]   Expert 10 |     80 | CPU
DEBUG 01-05 12:51:33.069047.069047 lmp.py:376]   Expert 11 |     81 | CPU
DEBUG 01-05 12:51:33.069544.069544 lmp.py:376]   Expert 63 |     89 | CPU
DEBUG 01-05 12:51:33.069041.069041 lmp.py:376]   Expert 49 |     99 | CPU
DEBUG 01-05 12:51:33.069538.069538 lmp.py:376]   Expert 26 |    100 | CPU
DEBUG 01-05 12:51:33.069274.069274 lmp.py:376]   Expert 50 |    103 | CPU
DEBUG 01-05 12:51:33.069771.069771 lmp.py:376]   Expert 37 |    108 | CPU
DEBUG 01-05 12:51:33.069269.069269 lmp.py:376]   Expert 34 |    113 | CPU
DEBUG 01-05 12:51:33.069527.069527 lmp.py:376]   Expert 47 |    114 | CPU
DEBUG 01-05 12:51:33.069501.069501 lmp.py:376]   Expert  7 |    118 | CPU
DEBUG 01-05 12:51:33.069667.069667 lmp.py:376]   Expert 22 |    118 | CPU
DEBUG 01-05 12:51:33.069165.069165 lmp.py:376]   Expert 16 |    120 | CPU
DEBUG 01-05 12:51:33.069092.069092 lmp.py:376]   Expert 40 |    120 | CPU
DEBUG 01-05 12:51:33.069066.069066 lmp.py:376]   Expert 28 |    128 | CPU
DEBUG 01-05 12:51:33.069325.069325 lmp.py:376]   Expert 32 |    130 | CPU
DEBUG 01-05 12:51:33.069061.069061 lmp.py:376]   Expert 62 |    135 | CPU
DEBUG 01-05 12:51:33.069558.069558 lmp.py:376]   Expert  4 |    148 | CPU
DEBUG 01-05 12:51:33.069817.069817 lmp.py:376]   Expert 30 |    151 | CPU
DEBUG 01-05 12:51:33.069791.069791 lmp.py:376]   Expert 31 |    154 | CPU
DEBUG 01-05 12:51:33.069527.069527 lmp.py:376]   Expert 41 |    154 | CPU
DEBUG 01-05 12:51:33.069024.069024 lmp.py:376]   Expert 58 |    155 | CPU
DEBUG 01-05 12:51:33.069759.069759 lmp.py:376]   Expert 51 |    159 | CPU
DEBUG 01-05 12:51:33.069257.069257 lmp.py:376]   Expert 57 |    164 | CPU
DEBUG 01-05 12:51:33.069515.069515 lmp.py:376]   Expert 25 |    170 | CPU
DEBUG 01-05 12:51:33.069489.069489 lmp.py:376]   Expert 54 |    173 | GPU
DEBUG 01-05 12:51:33.069225.069225 lmp.py:376]   Expert  9 |    182 | GPU
DEBUG 01-05 12:51:33.069676.069676 lmp.py:376]   Expert 59 |    184 | GPU
DEBUG 01-05 12:51:33.069604.069604 lmp.py:376]   Expert 45 |    185 | GPU
DEBUG 01-05 12:51:33.069339.069339 lmp.py:376]   Expert 21 |    190 | GPU
DEBUG 01-05 12:51:33.069505.069505 lmp.py:376]   Expert 55 |    192 | GPU
DEBUG 01-05 12:51:33.069910.069910 lmp.py:376]   Expert 38 |    197 | GPU
DEBUG 01-05 12:51:33.069361.069361 lmp.py:376]   Expert  0 |    204 | GPU
DEBUG 01-05 12:51:33.069050.069050 lmp.py:376]   Expert 29 |    207 | GPU
DEBUG 01-05 12:51:33.069978.069978 lmp.py:376]   Expert 33 |    207 | GPU
DEBUG 01-05 12:51:33.069667.069667 lmp.py:376]   Expert 12 |    212 | GPU
DEBUG 01-05 12:51:33.069595.069595 lmp.py:376]   Expert  8 |    214 | GPU
DEBUG 01-05 12:51:33.070523.070523 lmp.py:376]   Expert 13 |    215 | GPU
DEBUG 01-05 12:51:33.070973.070973 lmp.py:376]   Expert  6 |    216 | GPU
DEBUG 01-05 12:51:33.070901.070901 lmp.py:376]   Expert  5 |    218 | GPU
DEBUG 01-05 12:51:33.070829.070829 lmp.py:376]   Expert 19 |    218 | GPU
DEBUG 01-05 12:51:33.070949.070949 lmp.py:376]   Expert 46 |    218 | GPU
DEBUG 01-05 12:51:33.070214.070214 lmp.py:376]   Expert 43 |    222 | GPU
DEBUG 01-05 12:51:33.070241.070241 lmp.py:376]   Expert  2 |    231 | GPU
DEBUG 01-05 12:51:33.070169.070169 lmp.py:376]   Expert 42 |    238 | GPU
DEBUG 01-05 12:51:33.070858.070858 lmp.py:376]   Expert 24 |    249 | GPU
DEBUG 01-05 12:51:33.070309.070309 lmp.py:376]   Expert 17 |    256 | GPU
DEBUG 01-05 12:51:33.070999.070999 lmp.py:376]   Expert 23 |    264 | GPU
DEBUG 01-05 12:51:33.070688.070688 lmp.py:376]   Expert 61 |    285 | GPU
DEBUG 01-05 12:51:33.070616.070616 lmp.py:376]   Expert 20 |    350 | GPU
DEBUG 01-05 12:51:33.070543.070543 lmp.py:376]   Expert 27 |    350 | GPU
DEBUG 01-05 12:51:33.070233.070233 lmp.py:376]   Expert 18 |    376 | GPU
DEBUG 01-05 12:51:33.070922.070922 lmp.py:376]   Expert 48 |    395 | GPU
DEBUG 01-05 12:51:33.070803.070803 lmp.py:376]   Expert 39 |    419 | GPU
DEBUG 01-05 12:51:33.070685.070685 lmp.py:376]   Expert 60 |    467 | GPU
DEBUG 01-05 12:51:33.070043.070043 lmp.py:376]   Expert 56 |    608 | GPU
DEBUG 01-05 12:51:33.070209.070209 lmp.py:376]   Expert 36 |    711 | GPU
DEBUG 01-05 12:51:33.070091.070091 lmp.py:377] 
DEBUG 01-05 12:51:33.070091.070091 lmp.py:377]   CPU total tokens: 3435 (28.0%)
DEBUG 01-05 12:51:33.070449.070449 lmp.py:378]   GPU total tokens: 8853 (72.0%)
DEBUG 01-05 12:51:33.070860.070860 cuda_h.py:19] end experts_map_get cost 0.0014982223510742188 seconds
DEBUG 01-05 12:51:33.070503.070503 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.070379.070379 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.070324.070324 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.071300.071300 cuda_h.py:19] end allocate_cuda_memory cost 0.0008273124694824219 seconds
DEBUG 01-05 12:51:33.071805.071805 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.071084.071084 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.071437.071437 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.071186.071186 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 48f0993f-5efd-47d2-b047-974b93eeca87
DEBUG 01-05 12:51:33.071974.071974 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.072109.072109 client.py:127] Model loaded
DEBUG 01-05 12:51:33.072531.072531 cuda_h.py:19] end sllm_worker_task cost 0.010973215103149414 seconds
INFO 01-05 12:51:33.073879.073879 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 48f0993f-5efd-47d2-b047-974b93eeca87
DEBUG 01-05 12:51:33.073106.073106 cuda_h.py:19] end load_into_gpu_async cost 0.0024361610412597656 seconds
DEBUG 01-05 12:51:33.074783.074783 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.074208.074208 cuda_h.py:19] end restore_tensors2 cost 0.0003917217254638672 seconds
DEBUG 01-05 12:51:33.074190.074190 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004015684127807617 seconds
DEBUG 01-05 12:51:33.077376.077376 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006655693054199219 seconds
DEBUG 01-05 12:51:33.077451.077451 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.077003.077003 lmp.py:423] 
DEBUG 01-05 12:51:33.077003.077003 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.077469.077469 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 12:51:33.077072.077072 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.089105.089105 mlpmodule.py:704] group tensors cost 0.012021303176879883 s
DEBUG 01-05 12:51:33.092554.092554 mlpmodule.py:742] pad cost 0.0018727779388427734 s
DEBUG 01-05 12:51:33.092592.092592 mlpmodule.py:748] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-05 12:51:33.092124.092124 mlpmodule.py:753] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-05 12:51:33.102974.102974 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.102503.102503 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.102593.102593 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 12:51:33.102610.102610 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.117714.117714 mlpmodule.py:793] group einsum cost 0.024856090545654297 s
DEBUG 01-05 12:51:33.118659.118659 mlpmodule.py:801] cpy2cputensor cost 0.0006999969482421875 s
DEBUG 01-05 12:51:33.122504.122504 cuda_h.py:19] end wait_cetm_experts cost 0.045257568359375 seconds
DEBUG 01-05 12:51:33.122337.122337 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.123318.123318 cuda_h.py:19] end gpu_sexperts cost 0.0005753040313720703 seconds
DEBUG 01-05 12:51:33.123115.123115 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.123879.123879 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.266334533691406e-05 seconds
DEBUG 01-05 12:51:33.123297.123297 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.123960.123960 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 48f0993f-5efd-47d2-b047-974b93eeca87
INFO 01-05 12:51:33.124297.124297 client.py:127] Model loaded
DEBUG 01-05 12:51:33.124478.124478 cuda_h.py:19] end wait_experts cost 0.0012257099151611328 seconds
DEBUG 01-05 12:51:33.124135.124135 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.124414.124414 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.125035.125035 mlpmodule.py:531] gpu group tensors cost 0.0006515979766845703 s
DEBUG 01-05 12:51:33.127148.127148 mlpmodule.py:564] gpu pad cost 0.0017461776733398438 s
DEBUG 01-05 12:51:33.128512.128512 mlpmodule.py:582] gpu group einsum cost 0.0005104541778564453 s
DEBUG 01-05 12:51:33.131205.131205 mlpmodule.py:611] gpu experts func einsum cost 0.006709575653076172 s
DEBUG 01-05 12:51:33.131986.131986 cuda_h.py:19] end gpu_experts cost 0.006988525390625 seconds
DEBUG 01-05 12:51:33.132029.132029 cuda_h.py:19] end layer_moe_generate_6 cost 0.06401610374450684 seconds
DEBUG 01-05 12:51:33.132202.132202 lmp.py:217] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 12:51:33.132972.132972 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 12:51:33.132052.132052 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 12:51:33.132384.132384 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 12:51:33.132586.132586 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 4.792213439941406e-05 seconds
DEBUG 01-05 12:51:33.132489.132489 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.132378.132378 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.00017452239990234375 seconds
DEBUG 01-05 12:51:33.132970.132970 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.132841.132841 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.132419.132419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.134858.134858 cuda_h.py:19] end allocate_cuda_memory cost 0.0015311241149902344 seconds
DEBUG 01-05 12:51:33.134906.134906 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.134770.134770 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.134023.134023 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.134487.134487 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e98cbc10-5149-48df-89db-6e1f9e234626
DEBUG 01-05 12:51:33.134172.134172 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.135273.135273 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.136756.136756 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e98cbc10-5149-48df-89db-6e1f9e234626
DEBUG 01-05 12:51:33.136977.136977 cuda_h.py:19] end load_into_gpu_async cost 0.0016262531280517578 seconds
DEBUG 01-05 12:51:33.136295.136295 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.136702.136702 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-05 12:51:33.136313.136313 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035622119903564453 seconds
INFO 01-05 12:51:33.136204.136204 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e98cbc10-5149-48df-89db-6e1f9e234626
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.139135.139135 cuda_h.py:19] end self_attn cost 0.003937482833862305 seconds
DEBUG 01-05 12:51:33.139609.139609 cuda_h.py:19] end iln_self_attn_paln cost 0.006617307662963867 seconds
DEBUG 01-05 12:51:33.139638.139638 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 12:51:33.139685.139685 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.140716.140716 cuda_h.py:19] end gate cost 0.0006914138793945312 seconds
DEBUG 01-05 12:51:33.140546.140546 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.140152.140152 lmp.py:365] 
DEBUG 01-05 12:51:33.140152.140152 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.140961.140961 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.140234.140234 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.140691.140691 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.140765.140765 lmp.py:369] 
DEBUG 01-05 12:51:33.140765.140765 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.140077.140077 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.140587.140587 lmp.py:376]   Expert  1 |     20 | CPU
DEBUG 01-05 12:51:33.140138.140138 lmp.py:376]   Expert  3 |     25 | CPU
DEBUG 01-05 12:51:33.140973.140973 lmp.py:376]   Expert 25 |     45 | CPU
DEBUG 01-05 12:51:33.140331.140331 lmp.py:376]   Expert 40 |     56 | CPU
DEBUG 01-05 12:51:33.140120.140120 lmp.py:376]   Expert 41 |     56 | CPU
DEBUG 01-05 12:51:33.140955.140955 lmp.py:376]   Expert 49 |     60 | CPU
DEBUG 01-05 12:51:33.140790.140790 lmp.py:376]   Expert 15 |     66 | CPU
DEBUG 01-05 12:51:33.140102.140102 lmp.py:376]   Expert  8 |     67 | CPU
DEBUG 01-05 12:51:33.140460.140460 lmp.py:376]   Expert 20 |     67 | CPU
DEBUG 01-05 12:51:33.140057.140057 lmp.py:376]   Expert 31 |     74 | CPU
DEBUG 01-05 12:51:33.140653.140653 lmp.py:376]   Expert 48 |     80 | CPU
DEBUG 01-05 12:51:33.140250.140250 lmp.py:376]   Expert 29 |     83 | CPU
DEBUG 01-05 12:51:33.141608.141608 lmp.py:376]   Expert 39 |     83 | CPU
DEBUG 01-05 12:51:33.141728.141728 lmp.py:376]   Expert 16 |     86 | CPU
DEBUG 01-05 12:51:33.141086.141086 lmp.py:376]   Expert  5 |     89 | CPU
DEBUG 01-05 12:51:33.141206.141206 lmp.py:376]   Expert  6 |     94 | CPU
DEBUG 01-05 12:51:33.141280.141280 lmp.py:376]   Expert 63 |     95 | CPU
DEBUG 01-05 12:51:33.141876.141876 lmp.py:376]   Expert 32 |     98 | CPU
DEBUG 01-05 12:51:33.141950.141950 lmp.py:376]   Expert 57 |    100 | CPU
DEBUG 01-05 12:51:33.141500.141500 lmp.py:376]   Expert 18 |    101 | CPU
DEBUG 01-05 12:51:33.141097.141097 lmp.py:376]   Expert 58 |    115 | CPU
DEBUG 01-05 12:51:33.141216.141216 lmp.py:376]   Expert 59 |    127 | CPU
DEBUG 01-05 12:51:33.141575.141575 lmp.py:376]   Expert 30 |    141 | CPU
DEBUG 01-05 12:51:33.141695.141695 lmp.py:376]   Expert 55 |    147 | CPU
DEBUG 01-05 12:51:33.141291.141291 lmp.py:376]   Expert 53 |    156 | CPU
DEBUG 01-05 12:51:33.141649.141649 lmp.py:376]   Expert  4 |    158 | CPU
DEBUG 01-05 12:51:33.141339.141339 lmp.py:376]   Expert 35 |    158 | CPU
DEBUG 01-05 12:51:33.141982.141982 lmp.py:376]   Expert 34 |    162 | CPU
DEBUG 01-05 12:51:33.141671.141671 lmp.py:376]   Expert 26 |    164 | CPU
DEBUG 01-05 12:51:33.141851.141851 lmp.py:376]   Expert 45 |    164 | CPU
DEBUG 01-05 12:51:33.141401.141401 lmp.py:376]   Expert 52 |    166 | CPU
DEBUG 01-05 12:51:33.141998.141998 lmp.py:376]   Expert  0 |    174 | CPU
DEBUG 01-05 12:51:33.141594.141594 lmp.py:376]   Expert 33 |    178 | GPU
DEBUG 01-05 12:51:33.141999.141999 lmp.py:376]   Expert 50 |    183 | GPU
DEBUG 01-05 12:51:33.141165.141165 lmp.py:376]   Expert  7 |    186 | GPU
DEBUG 01-05 12:51:33.141570.141570 lmp.py:376]   Expert 54 |    193 | GPU
DEBUG 01-05 12:51:33.141213.141213 lmp.py:376]   Expert 28 |    194 | GPU
DEBUG 01-05 12:51:33.141856.141856 lmp.py:376]   Expert 19 |    199 | GPU
DEBUG 01-05 12:51:33.141783.141783 lmp.py:376]   Expert 21 |    201 | GPU
DEBUG 01-05 12:51:33.141188.141188 lmp.py:376]   Expert 42 |    206 | GPU
DEBUG 01-05 12:51:33.141831.141831 lmp.py:376]   Expert 24 |    209 | GPU
DEBUG 01-05 12:51:33.141189.141189 lmp.py:376]   Expert 43 |    211 | GPU
DEBUG 01-05 12:51:33.141547.141547 lmp.py:376]   Expert 60 |    211 | GPU
DEBUG 01-05 12:51:33.141429.141429 lmp.py:376]   Expert 51 |    213 | GPU
DEBUG 01-05 12:51:33.141072.141072 lmp.py:376]   Expert 36 |    215 | GPU
DEBUG 01-05 12:51:33.141953.141953 lmp.py:376]   Expert 13 |    221 | GPU
DEBUG 01-05 12:51:33.141358.141358 lmp.py:376]   Expert 27 |    226 | GPU
DEBUG 01-05 12:51:33.141001.141001 lmp.py:376]   Expert 17 |    228 | GPU
DEBUG 01-05 12:51:33.141882.141882 lmp.py:376]   Expert 10 |    243 | GPU
DEBUG 01-05 12:51:33.141048.141048 lmp.py:376]   Expert 37 |    250 | GPU
DEBUG 01-05 12:51:33.141691.141691 lmp.py:376]   Expert 47 |    252 | GPU
DEBUG 01-05 12:51:33.141857.141857 lmp.py:376]   Expert 62 |    262 | GPU
DEBUG 01-05 12:51:33.141262.141262 lmp.py:376]   Expert 11 |    271 | GPU
DEBUG 01-05 12:51:33.141620.141620 lmp.py:376]   Expert 22 |    283 | GPU
DEBUG 01-05 12:51:33.141740.141740 lmp.py:376]   Expert  2 |    305 | GPU
DEBUG 01-05 12:51:33.141860.141860 lmp.py:376]   Expert 56 |    311 | GPU
DEBUG 01-05 12:51:33.141456.141456 lmp.py:376]   Expert 61 |    311 | GPU
DEBUG 01-05 12:51:33.141099.141099 lmp.py:376]   Expert 44 |    350 | GPU
DEBUG 01-05 12:51:33.141981.141981 lmp.py:376]   Expert 14 |    353 | GPU
DEBUG 01-05 12:51:33.141385.141385 lmp.py:376]   Expert 38 |    353 | GPU
DEBUG 01-05 12:51:33.141505.141505 lmp.py:376]   Expert 46 |    382 | GPU
DEBUG 01-05 12:51:33.141386.141386 lmp.py:376]   Expert 12 |    570 | GPU
DEBUG 01-05 12:51:33.141268.141268 lmp.py:376]   Expert  9 |    592 | GPU
DEBUG 01-05 12:51:33.141434.141434 lmp.py:376]   Expert 23 |    649 | GPU
DEBUG 01-05 12:51:33.141746.141746 lmp.py:377] 
DEBUG 01-05 12:51:33.141746.141746 lmp.py:377]   CPU total tokens: 3277 (26.7%)
DEBUG 01-05 12:51:33.141342.141342 lmp.py:378]   GPU total tokens: 9011 (73.3%)
DEBUG 01-05 12:51:33.141707.141707 cuda_h.py:19] end experts_map_get cost 0.001636505126953125 seconds
DEBUG 01-05 12:51:33.142019.142019 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.142803.142803 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.142423.142423 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.142076.142076 cuda_h.py:19] end allocate_cuda_memory cost 0.0002732276916503906 seconds
DEBUG 01-05 12:51:33.142157.142157 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.142390.142390 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.142935.142935 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.142922.142922 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 791bd81c-db7d-48f1-b743-c7f3b1b0d37e
DEBUG 01-05 12:51:33.142518.142518 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.143510.143510 mlpmodule.py:662]  experts func einsum cost 0.0654749870300293 s
INFO 01-05 12:51:33.143092.143092 client.py:127] Model loaded
DEBUG 01-05 12:51:33.143778.143778 cuda_h.py:19] end sllm_worker_task cost 0.010677814483642578 seconds
INFO 01-05 12:51:33.145379.145379 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 791bd81c-db7d-48f1-b743-c7f3b1b0d37e
DEBUG 01-05 12:51:33.145815.145815 cuda_h.py:19] end load_into_gpu_async cost 0.002577543258666992 seconds
DEBUG 01-05 12:51:33.145062.145062 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.145868.145868 cuda_h.py:19] end restore_tensors2 cost 0.00046062469482421875 seconds
DEBUG 01-05 12:51:33.145473.145473 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037708282470703125 seconds
DEBUG 01-05 12:51:33.148742.148742 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006334066390991211 seconds
DEBUG 01-05 12:51:33.148434.148434 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.148158.148158 lmp.py:423] 
DEBUG 01-05 12:51:33.148158.148158 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.148485.148485 cuda_h.py:19] end cpu_experts_submit cost 0.00011444091796875 seconds
DEBUG 01-05 12:51:33.148473.148473 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.153404.153404 mlpmodule.py:704] group tensors cost 0.004683256149291992 s
DEBUG 01-05 12:51:33.155785.155785 mlpmodule.py:742] pad cost 0.0014691352844238281 s
DEBUG 01-05 12:51:33.155649.155649 mlpmodule.py:748] create cpu tensor cost 4.291534423828125e-05 s
DEBUG 01-05 12:51:33.155261.155261 mlpmodule.py:753] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-05 12:51:33.165437.165437 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.166741.166741 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.166639.166639 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 12:51:33.166729.166729 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.182585.182585 mlpmodule.py:793] group einsum cost 0.02642536163330078 s
DEBUG 01-05 12:51:33.183152.183152 mlpmodule.py:801] cpy2cputensor cost 0.0007030963897705078 s
DEBUG 01-05 12:51:33.187173.187173 cuda_h.py:19] end wait_cetm_experts cost 0.039029836654663086 seconds
DEBUG 01-05 12:51:33.187443.187443 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.188312.188312 cuda_h.py:19] end gpu_sexperts cost 0.000598907470703125 seconds
DEBUG 01-05 12:51:33.188109.188109 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.188204.188204 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 12:51:33.188576.188576 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.188716.188716 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 791bd81c-db7d-48f1-b743-c7f3b1b0d37e
INFO 01-05 12:51:33.195079.195079 client.py:127] Model loaded
DEBUG 01-05 12:51:33.195359.195359 cuda_h.py:19] end wait_experts cost 0.006550312042236328 seconds
DEBUG 01-05 12:51:33.195354.195354 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.195587.195587 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.196432.196432 mlpmodule.py:531] gpu group tensors cost 0.0006430149078369141 s
DEBUG 01-05 12:51:33.197725.197725 mlpmodule.py:564] gpu pad cost 0.0017764568328857422 s
DEBUG 01-05 12:51:33.198444.198444 mlpmodule.py:582] gpu group einsum cost 0.0004050731658935547 s
DEBUG 01-05 12:51:33.201656.201656 mlpmodule.py:611] gpu experts func einsum cost 0.006144523620605469 s
DEBUG 01-05 12:51:33.201980.201980 cuda_h.py:19] end gpu_experts cost 0.006401538848876953 seconds
DEBUG 01-05 12:51:33.201956.201956 cuda_h.py:19] end layer_moe_generate_7 cost 0.06228232383728027 seconds
DEBUG 01-05 12:51:33.202254.202254 lmp.py:217] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 12:51:33.202401.202401 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 12:51:33.202905.202905 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 12:51:33.202992.202992 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 12:51:33.202444.202444 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.7418136596679688e-05 seconds
DEBUG 01-05 12:51:33.202213.202213 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.2479248046875e-05 seconds
DEBUG 01-05 12:51:33.202572.202572 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.202316.202316 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.202862.202862 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.202268.202268 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.205006.205006 cuda_h.py:19] end allocate_cuda_memory cost 0.002974271774291992 seconds
DEBUG 01-05 12:51:33.205984.205984 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.205390.205390 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.205451.205451 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.205631.205631 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d31eb26-d829-4a80-91f4-eec477033b17
DEBUG 01-05 12:51:33.205647.205647 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.206653.206653 mlpmodule.py:662]  experts func einsum cost 0.05723714828491211 s
DEBUG 01-05 12:51:33.206472.206472 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.207510.207510 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d31eb26-d829-4a80-91f4-eec477033b17
DEBUG 01-05 12:51:33.207207.207207 cuda_h.py:19] end load_into_gpu_async cost 0.0016551017761230469 seconds
DEBUG 01-05 12:51:33.207956.207956 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.207986.207986 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-05 12:51:33.207550.207550 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005073070526123047 seconds
INFO 01-05 12:51:33.208356.208356 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d31eb26-d829-4a80-91f4-eec477033b17
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.210393.210393 cuda_h.py:19] end self_attn cost 0.003883838653564453 seconds
DEBUG 01-05 12:51:33.210490.210490 cuda_h.py:19] end iln_self_attn_paln cost 0.00840616226196289 seconds
DEBUG 01-05 12:51:33.210472.210472 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 12:51:33.210758.210758 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.211886.211886 cuda_h.py:19] end gate cost 0.0006234645843505859 seconds
DEBUG 01-05 12:51:33.211000.211000 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.211785.211785 lmp.py:365] 
DEBUG 01-05 12:51:33.211785.211785 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.211826.211826 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.211237.211237 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.211787.211787 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.211238.211238 lmp.py:369] 
DEBUG 01-05 12:51:33.211238.211238 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.211927.211927 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.211577.211577 lmp.py:376]   Expert  7 |     21 | CPU
DEBUG 01-05 12:51:33.211505.211505 lmp.py:376]   Expert 27 |     25 | CPU
DEBUG 01-05 12:51:33.211717.211717 lmp.py:376]   Expert 14 |     28 | CPU
DEBUG 01-05 12:51:33.211168.211168 lmp.py:376]   Expert 30 |     32 | CPU
DEBUG 01-05 12:51:33.211050.211050 lmp.py:376]   Expert 38 |     48 | CPU
DEBUG 01-05 12:51:33.211501.211501 lmp.py:376]   Expert 12 |     54 | CPU
DEBUG 01-05 12:51:33.211713.211713 lmp.py:376]   Expert 36 |     60 | CPU
DEBUG 01-05 12:51:33.211449.211449 lmp.py:376]   Expert 53 |     64 | CPU
DEBUG 01-05 12:51:33.212423.212423 lmp.py:376]   Expert 22 |     65 | CPU
DEBUG 01-05 12:51:33.212397.212397 lmp.py:376]   Expert 34 |     69 | CPU
DEBUG 01-05 12:51:33.212609.212609 lmp.py:376]   Expert  8 |     73 | CPU
DEBUG 01-05 12:51:33.212822.212822 lmp.py:376]   Expert 26 |     78 | CPU
DEBUG 01-05 12:51:33.212749.212749 lmp.py:376]   Expert 54 |     81 | CPU
DEBUG 01-05 12:51:33.212200.212200 lmp.py:376]   Expert  1 |     92 | CPU
DEBUG 01-05 12:51:33.212413.212413 lmp.py:376]   Expert 33 |     96 | CPU
DEBUG 01-05 12:51:33.212910.212910 lmp.py:376]   Expert 57 |    100 | CPU
DEBUG 01-05 12:51:33.212646.212646 lmp.py:376]   Expert 40 |    101 | CPU
DEBUG 01-05 12:51:33.212143.212143 lmp.py:376]   Expert  9 |    111 | CPU
DEBUG 01-05 12:51:33.212878.212878 lmp.py:376]   Expert 13 |    113 | CPU
DEBUG 01-05 12:51:33.212376.212376 lmp.py:376]   Expert 32 |    115 | CPU
DEBUG 01-05 12:51:33.212111.212111 lmp.py:376]   Expert 50 |    115 | CPU
DEBUG 01-05 12:51:33.212085.212085 lmp.py:376]   Expert 29 |    119 | CPU
DEBUG 01-05 12:51:33.212775.212775 lmp.py:376]   Expert 17 |    129 | CPU
DEBUG 01-05 12:51:33.212464.212464 lmp.py:376]   Expert 59 |    134 | CPU
DEBUG 01-05 12:51:33.212438.212438 lmp.py:376]   Expert 44 |    139 | CPU
DEBUG 01-05 12:51:33.212935.212935 lmp.py:376]   Expert 60 |    148 | CPU
DEBUG 01-05 12:51:33.212909.212909 lmp.py:376]   Expert 24 |    150 | CPU
DEBUG 01-05 12:51:33.212168.212168 lmp.py:376]   Expert 10 |    154 | CPU
DEBUG 01-05 12:51:33.212904.212904 lmp.py:376]   Expert 16 |    165 | CPU
DEBUG 01-05 12:51:33.212401.212401 lmp.py:376]   Expert 56 |    165 | CPU
DEBUG 01-05 12:51:33.212136.212136 lmp.py:376]   Expert 15 |    166 | CPU
DEBUG 01-05 12:51:33.212634.212634 lmp.py:376]   Expert 51 |    171 | CPU
DEBUG 01-05 12:51:33.212952.212952 lmp.py:376]   Expert  2 |    174 | GPU
DEBUG 01-05 12:51:33.212357.212357 lmp.py:376]   Expert 37 |    177 | GPU
DEBUG 01-05 12:51:33.212046.212046 lmp.py:376]   Expert 18 |    191 | GPU
DEBUG 01-05 12:51:33.212974.212974 lmp.py:376]   Expert 31 |    191 | GPU
DEBUG 01-05 12:51:33.212425.212425 lmp.py:376]   Expert 19 |    196 | GPU
DEBUG 01-05 12:51:33.212637.212637 lmp.py:376]   Expert 39 |    197 | GPU
DEBUG 01-05 12:51:33.212088.212088 lmp.py:376]   Expert 58 |    218 | GPU
DEBUG 01-05 12:51:33.212777.212777 lmp.py:376]   Expert 61 |    222 | GPU
DEBUG 01-05 12:51:33.212467.212467 lmp.py:376]   Expert 46 |    238 | GPU
DEBUG 01-05 12:51:33.212441.212441 lmp.py:376]   Expert 41 |    239 | GPU
DEBUG 01-05 12:51:33.212130.212130 lmp.py:376]   Expert 49 |    239 | GPU
DEBUG 01-05 12:51:33.212535.212535 lmp.py:376]   Expert 35 |    246 | GPU
DEBUG 01-05 12:51:33.212701.212701 lmp.py:376]   Expert  0 |    254 | GPU
DEBUG 01-05 12:51:33.212628.212628 lmp.py:376]   Expert 42 |    255 | GPU
DEBUG 01-05 12:51:33.212841.212841 lmp.py:376]   Expert 23 |    259 | GPU
DEBUG 01-05 12:51:33.212292.212292 lmp.py:376]   Expert  6 |    266 | GPU
DEBUG 01-05 12:51:33.212981.212981 lmp.py:376]   Expert  3 |    268 | GPU
DEBUG 01-05 12:51:33.212432.212432 lmp.py:376]   Expert  4 |    274 | GPU
DEBUG 01-05 12:51:33.212121.212121 lmp.py:376]   Expert 28 |    280 | GPU
DEBUG 01-05 12:51:33.212334.212334 lmp.py:376]   Expert 55 |    283 | GPU
DEBUG 01-05 12:51:33.212785.212785 lmp.py:376]   Expert 43 |    305 | GPU
DEBUG 01-05 12:51:33.212235.212235 lmp.py:376]   Expert 45 |    316 | GPU
DEBUG 01-05 12:51:33.212117.212117 lmp.py:376]   Expert 20 |    322 | GPU
DEBUG 01-05 12:51:33.212283.212283 lmp.py:376]   Expert 52 |    332 | GPU
DEBUG 01-05 12:51:33.212449.212449 lmp.py:376]   Expert 25 |    342 | GPU
DEBUG 01-05 12:51:33.212138.212138 lmp.py:376]   Expert 48 |    342 | GPU
DEBUG 01-05 12:51:33.212351.212351 lmp.py:376]   Expert 47 |    345 | GPU
DEBUG 01-05 12:51:33.212563.212563 lmp.py:376]   Expert 11 |    372 | GPU
DEBUG 01-05 12:51:33.212776.212776 lmp.py:376]   Expert 62 |    403 | GPU
DEBUG 01-05 12:51:33.212988.212988 lmp.py:376]   Expert 63 |    407 | GPU
DEBUG 01-05 12:51:33.212439.212439 lmp.py:376]   Expert 21 |    419 | GPU
DEBUG 01-05 12:51:33.212128.212128 lmp.py:376]   Expert  5 |    535 | GPU
DEBUG 01-05 12:51:33.212295.212295 lmp.py:377] 
DEBUG 01-05 12:51:33.212295.212295 lmp.py:377]   CPU total tokens: 3181 (25.9%)
DEBUG 01-05 12:51:33.212699.212699 lmp.py:378]   GPU total tokens: 9107 (74.1%)
DEBUG 01-05 12:51:33.212157.212157 cuda_h.py:19] end experts_map_get cost 0.0014922618865966797 seconds
DEBUG 01-05 12:51:33.212800.212800 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.213530.213530 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.213521.213521 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.213180.213180 cuda_h.py:19] end allocate_cuda_memory cost 0.0004525184631347656 seconds
DEBUG 01-05 12:51:33.213705.213705 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.213938.213938 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.213317.213317 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.213443.213443 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f486f8a-76bf-4d3f-9444-2bd8fdd22829
DEBUG 01-05 12:51:33.214370.214370 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.214930.214930 client.py:127] Model loaded
DEBUG 01-05 12:51:33.214164.214164 cuda_h.py:19] end sllm_worker_task cost 0.011990785598754883 seconds
INFO 01-05 12:51:33.216910.216910 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f486f8a-76bf-4d3f-9444-2bd8fdd22829
DEBUG 01-05 12:51:33.216876.216876 cuda_h.py:19] end load_into_gpu_async cost 0.0024619102478027344 seconds
DEBUG 01-05 12:51:33.216746.216746 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.217555.217555 cuda_h.py:19] end restore_tensors2 cost 0.0007779598236083984 seconds
DEBUG 01-05 12:51:33.217445.217445 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004163026809692383 seconds
DEBUG 01-05 12:51:33.219175.219175 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006815671920776367 seconds
DEBUG 01-05 12:51:33.219673.219673 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.219967.219967 lmp.py:423] 
DEBUG 01-05 12:51:33.219967.219967 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.220525.220525 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-05 12:51:33.220698.220698 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.238460.238460 mlpmodule.py:704] group tensors cost 0.01772761344909668 s
DEBUG 01-05 12:51:33.240411.240411 mlpmodule.py:742] pad cost 0.001794576644897461 s
DEBUG 01-05 12:51:33.240912.240912 mlpmodule.py:748] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-05 12:51:33.240776.240776 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-05 12:51:33.250314.250314 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.250730.250730 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.250899.250899 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 12:51:33.251453.251453 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.266854.266854 mlpmodule.py:793] group einsum cost 0.025784969329833984 s
DEBUG 01-05 12:51:33.267388.267388 mlpmodule.py:801] cpy2cputensor cost 0.0007097721099853516 s
DEBUG 01-05 12:51:33.272458.272458 cuda_h.py:19] end wait_cetm_experts cost 0.051892757415771484 seconds
DEBUG 01-05 12:51:33.272391.272391 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.272869.272869 cuda_h.py:19] end gpu_sexperts cost 0.000591278076171875 seconds
DEBUG 01-05 12:51:33.272142.272142 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.272145.272145 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.24249267578125e-05 seconds
DEBUG 01-05 12:51:33.272470.272470 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.272703.272703 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f486f8a-76bf-4d3f-9444-2bd8fdd22829
INFO 01-05 12:51:33.274921.274921 client.py:127] Model loaded
DEBUG 01-05 12:51:33.274957.274957 cuda_h.py:19] end wait_experts cost 0.0012395381927490234 seconds
DEBUG 01-05 12:51:33.274613.274613 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.274654.274654 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.275877.275877 mlpmodule.py:531] gpu group tensors cost 0.0006394386291503906 s
DEBUG 01-05 12:51:33.276476.276476 mlpmodule.py:564] gpu pad cost 0.001825571060180664 s
DEBUG 01-05 12:51:33.277902.277902 mlpmodule.py:582] gpu group einsum cost 0.0005590915679931641 s
DEBUG 01-05 12:51:33.281814.281814 mlpmodule.py:611] gpu experts func einsum cost 0.006876230239868164 s
DEBUG 01-05 12:51:33.281093.281093 cuda_h.py:19] end gpu_experts cost 0.007171154022216797 seconds
DEBUG 01-05 12:51:33.281937.281937 cuda_h.py:19] end layer_moe_generate_8 cost 0.0708167552947998 seconds
DEBUG 01-05 12:51:33.281541.281541 lmp.py:217] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 12:51:33.281542.281542 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 12:51:33.281861.281861 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 12:51:33.281431.281431 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 12:51:33.281235.281235 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.504753112792969e-05 seconds
DEBUG 01-05 12:51:33.282131.282131 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.282583.282583 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.00015044212341308594 seconds
DEBUG 01-05 12:51:33.282791.282791 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.282813.282813 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.282954.282954 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.284544.284544 cuda_h.py:19] end allocate_cuda_memory cost 0.0017082691192626953 seconds
DEBUG 01-05 12:51:33.284594.284594 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.284165.284165 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.284802.284802 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.284790.284790 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0659e63f-1fde-4628-9efd-737105121131
DEBUG 01-05 12:51:33.284621.284621 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.284668.284668 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.285674.285674 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0659e63f-1fde-4628-9efd-737105121131
DEBUG 01-05 12:51:33.286431.286431 cuda_h.py:19] end load_into_gpu_async cost 0.0018122196197509766 seconds
DEBUG 01-05 12:51:33.286008.286008 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.286422.286422 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-05 12:51:33.286271.286271 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003943204879760742 seconds
INFO 01-05 12:51:33.286182.286182 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0659e63f-1fde-4628-9efd-737105121131
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.288356.288356 cuda_h.py:19] end self_attn cost 0.0032854080200195312 seconds
DEBUG 01-05 12:51:33.288420.288420 cuda_h.py:19] end iln_self_attn_paln cost 0.0061533451080322266 seconds
DEBUG 01-05 12:51:33.288164.288164 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 12:51:33.288165.288165 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.289948.289948 cuda_h.py:19] end gate cost 0.0006148815155029297 seconds
DEBUG 01-05 12:51:33.289877.289877 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.289993.289993 lmp.py:365] 
DEBUG 01-05 12:51:33.289993.289993 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.289080.289080 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.289968.289968 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.289565.289565 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.289493.289493 lmp.py:369] 
DEBUG 01-05 12:51:33.289493.289493 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.289944.289944 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.289640.289640 lmp.py:376]   Expert 35 |     34 | CPU
DEBUG 01-05 12:51:33.289329.289329 lmp.py:376]   Expert  7 |     39 | CPU
DEBUG 01-05 12:51:33.289065.289065 lmp.py:376]   Expert 26 |     43 | CPU
DEBUG 01-05 12:51:33.289516.289516 lmp.py:376]   Expert  2 |     45 | CPU
DEBUG 01-05 12:51:33.289251.289251 lmp.py:376]   Expert  6 |     46 | CPU
DEBUG 01-05 12:51:33.289987.289987 lmp.py:376]   Expert  5 |     51 | CPU
DEBUG 01-05 12:51:33.289961.289961 lmp.py:376]   Expert 60 |     58 | CPU
DEBUG 01-05 12:51:33.289412.289412 lmp.py:376]   Expert 13 |     60 | CPU
DEBUG 01-05 12:51:33.289386.289386 lmp.py:376]   Expert 38 |     62 | CPU
DEBUG 01-05 12:51:33.289837.289837 lmp.py:376]   Expert 19 |     67 | CPU
DEBUG 01-05 12:51:33.289288.289288 lmp.py:376]   Expert 48 |     71 | CPU
DEBUG 01-05 12:51:33.289785.289785 lmp.py:376]   Expert 25 |     78 | CPU
DEBUG 01-05 12:51:33.289282.289282 lmp.py:376]   Expert 39 |     78 | CPU
DEBUG 01-05 12:51:33.289779.289779 lmp.py:376]   Expert 17 |     79 | CPU
DEBUG 01-05 12:51:33.289515.289515 lmp.py:376]   Expert 52 |     93 | CPU
DEBUG 01-05 12:51:33.289774.289774 lmp.py:376]   Expert 54 |     95 | CPU
DEBUG 01-05 12:51:33.289509.289509 lmp.py:376]   Expert 27 |     96 | CPU
DEBUG 01-05 12:51:33.289768.289768 lmp.py:376]   Expert 45 |    100 | CPU
DEBUG 01-05 12:51:33.289027.289027 lmp.py:376]   Expert 29 |    131 | CPU
DEBUG 01-05 12:51:33.289524.289524 lmp.py:376]   Expert 59 |    132 | CPU
DEBUG 01-05 12:51:33.290021.290021 lmp.py:376]   Expert 24 |    141 | CPU
DEBUG 01-05 12:51:33.290949.290949 lmp.py:376]   Expert 16 |    144 | CPU
DEBUG 01-05 12:51:33.290400.290400 lmp.py:376]   Expert 57 |    149 | CPU
DEBUG 01-05 12:51:33.290612.290612 lmp.py:376]   Expert 40 |    156 | CPU
DEBUG 01-05 12:51:33.290593.290593 lmp.py:376]   Expert 49 |    156 | CPU
DEBUG 01-05 12:51:33.290998.290998 lmp.py:376]   Expert 14 |    157 | CPU
DEBUG 01-05 12:51:33.290257.290257 lmp.py:376]   Expert 20 |    157 | CPU
DEBUG 01-05 12:51:33.290515.290515 lmp.py:376]   Expert 62 |    161 | CPU
DEBUG 01-05 12:51:33.290774.290774 lmp.py:376]   Expert 12 |    162 | CPU
DEBUG 01-05 12:51:33.290033.290033 lmp.py:376]   Expert 32 |    162 | CPU
DEBUG 01-05 12:51:33.290530.290530 lmp.py:376]   Expert 42 |    165 | CPU
DEBUG 01-05 12:51:33.290888.290888 lmp.py:376]   Expert 30 |    171 | CPU
DEBUG 01-05 12:51:33.290531.290531 lmp.py:376]   Expert 31 |    175 | GPU
DEBUG 01-05 12:51:33.290174.290174 lmp.py:376]   Expert 22 |    176 | GPU
DEBUG 01-05 12:51:33.290532.290532 lmp.py:376]   Expert 28 |    178 | GPU
DEBUG 01-05 12:51:33.290891.290891 lmp.py:376]   Expert 11 |    181 | GPU
DEBUG 01-05 12:51:33.290117.290117 lmp.py:376]   Expert 58 |    182 | GPU
DEBUG 01-05 12:51:33.290190.290190 lmp.py:376]   Expert 18 |    187 | GPU
DEBUG 01-05 12:51:33.290072.290072 lmp.py:376]   Expert  1 |    188 | GPU
DEBUG 01-05 12:51:33.290191.290191 lmp.py:376]   Expert 33 |    191 | GPU
DEBUG 01-05 12:51:33.290834.290834 lmp.py:376]   Expert 41 |    191 | GPU
DEBUG 01-05 12:51:33.290239.290239 lmp.py:376]   Expert 23 |    192 | GPU
DEBUG 01-05 12:51:33.290882.290882 lmp.py:376]   Expert 43 |    194 | GPU
DEBUG 01-05 12:51:33.290287.290287 lmp.py:376]   Expert  3 |    206 | GPU
DEBUG 01-05 12:51:33.290929.290929 lmp.py:376]   Expert 10 |    206 | GPU
DEBUG 01-05 12:51:33.290572.290572 lmp.py:376]   Expert 34 |    209 | GPU
DEBUG 01-05 12:51:33.290739.290739 lmp.py:376]   Expert 50 |    213 | GPU
DEBUG 01-05 12:51:33.290858.290858 lmp.py:376]   Expert 51 |    227 | GPU
DEBUG 01-05 12:51:33.290501.290501 lmp.py:376]   Expert 47 |    230 | GPU
DEBUG 01-05 12:51:33.290621.290621 lmp.py:376]   Expert  4 |    234 | GPU
DEBUG 01-05 12:51:33.290264.290264 lmp.py:376]   Expert 53 |    242 | GPU
DEBUG 01-05 12:51:33.290146.290146 lmp.py:376]   Expert 36 |    251 | GPU
DEBUG 01-05 12:51:33.290550.290550 lmp.py:376]   Expert 44 |    282 | GPU
DEBUG 01-05 12:51:33.290432.290432 lmp.py:376]   Expert  0 |    294 | GPU
DEBUG 01-05 12:51:33.290598.290598 lmp.py:376]   Expert 61 |    315 | GPU
DEBUG 01-05 12:51:33.290002.290002 lmp.py:376]   Expert 37 |    341 | GPU
DEBUG 01-05 12:51:33.290645.290645 lmp.py:376]   Expert 55 |    360 | GPU
DEBUG 01-05 12:51:33.290003.290003 lmp.py:376]   Expert  9 |    367 | GPU
DEBUG 01-05 12:51:33.290170.290170 lmp.py:376]   Expert  8 |    373 | GPU
DEBUG 01-05 12:51:33.290574.290574 lmp.py:376]   Expert 63 |    465 | GPU
DEBUG 01-05 12:51:33.290456.290456 lmp.py:376]   Expert 15 |    480 | GPU
DEBUG 01-05 12:51:33.290575.290575 lmp.py:376]   Expert 46 |    491 | GPU
DEBUG 01-05 12:51:33.290695.290695 lmp.py:376]   Expert 21 |    563 | GPU
DEBUG 01-05 12:51:33.290815.290815 lmp.py:376]   Expert 56 |    565 | GPU
DEBUG 01-05 12:51:33.290888.290888 lmp.py:377] 
DEBUG 01-05 12:51:33.290888.290888 lmp.py:377]   CPU total tokens: 3339 (27.2%)
DEBUG 01-05 12:51:33.290247.290247 lmp.py:378]   GPU total tokens: 8949 (72.8%)
DEBUG 01-05 12:51:33.290135.290135 cuda_h.py:19] end experts_map_get cost 0.0015311241149902344 seconds
DEBUG 01-05 12:51:33.290731.290731 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.290991.290991 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.291652.291652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.292217.292217 cuda_h.py:19] end allocate_cuda_memory cost 0.0012264251708984375 seconds
DEBUG 01-05 12:51:33.292822.292822 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.292154.292154 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.292301.292301 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.292812.292812 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 436aff9c-5905-4fb2-9f3c-b83abf67fcad
DEBUG 01-05 12:51:33.292070.292070 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.292309.292309 mlpmodule.py:662]  experts func einsum cost 0.0725562572479248 s
INFO 01-05 12:51:33.294486.294486 client.py:127] Model loaded
DEBUG 01-05 12:51:33.294205.294205 cuda_h.py:19] end sllm_worker_task cost 0.011964559555053711 seconds
INFO 01-05 12:51:33.295826.295826 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 436aff9c-5905-4fb2-9f3c-b83abf67fcad
DEBUG 01-05 12:51:33.295993.295993 cuda_h.py:19] end load_into_gpu_async cost 0.0031163692474365234 seconds
DEBUG 01-05 12:51:33.295550.295550 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.295212.295212 cuda_h.py:19] end restore_tensors2 cost 0.0003573894500732422 seconds
DEBUG 01-05 12:51:33.295380.295380 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0050373077392578125 seconds
DEBUG 01-05 12:51:33.298022.298022 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076656341552734375 seconds
DEBUG 01-05 12:51:33.298905.298905 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.298768.298768 lmp.py:423] 
DEBUG 01-05 12:51:33.298768.298768 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.298181.298181 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-05 12:51:33.298043.298043 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.307401.307401 mlpmodule.py:704] group tensors cost 0.008840322494506836 s
DEBUG 01-05 12:51:33.310621.310621 mlpmodule.py:742] pad cost 0.00189971923828125 s
DEBUG 01-05 12:51:33.310698.310698 mlpmodule.py:748] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-05 12:51:33.310900.310900 mlpmodule.py:753] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-05 12:51:33.320870.320870 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.320744.320744 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.320502.320502 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 12:51:33.321996.321996 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.336181.336181 mlpmodule.py:793] group einsum cost 0.02533435821533203 s
DEBUG 01-05 12:51:33.336739.336739 mlpmodule.py:801] cpy2cputensor cost 0.0006301403045654297 s
DEBUG 01-05 12:51:33.341785.341785 cuda_h.py:19] end wait_cetm_experts cost 0.042644500732421875 seconds
DEBUG 01-05 12:51:33.341340.341340 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.342784.342784 cuda_h.py:19] end gpu_sexperts cost 0.0005681514739990234 seconds
DEBUG 01-05 12:51:33.342958.342958 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.342623.342623 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 12:51:33.342518.342518 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.342989.342989 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 436aff9c-5905-4fb2-9f3c-b83abf67fcad
INFO 01-05 12:51:33.345055.345055 client.py:127] Model loaded
DEBUG 01-05 12:51:33.345574.345574 cuda_h.py:19] end wait_experts cost 0.003030538558959961 seconds
DEBUG 01-05 12:51:33.345661.345661 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.345894.345894 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.346839.346839 mlpmodule.py:531] gpu group tensors cost 0.0006453990936279297 s
DEBUG 01-05 12:51:33.348829.348829 mlpmodule.py:564] gpu pad cost 0.001833200454711914 s
DEBUG 01-05 12:51:33.348475.348475 mlpmodule.py:582] gpu group einsum cost 0.0005860328674316406 s
DEBUG 01-05 12:51:33.352064.352064 mlpmodule.py:611] gpu experts func einsum cost 0.006779670715332031 s
DEBUG 01-05 12:51:33.352025.352025 cuda_h.py:19] end gpu_experts cost 0.007085561752319336 seconds
DEBUG 01-05 12:51:33.352075.352075 cuda_h.py:19] end layer_moe_generate_9 cost 0.06415319442749023 seconds
DEBUG 01-05 12:51:33.352473.352473 lmp.py:217] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 12:51:33.352328.352328 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 12:51:33.353555.353555 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 12:51:33.353470.353470 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 12:51:33.353213.353213 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.8371810913085938e-05 seconds
DEBUG 01-05 12:51:33.353108.353108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.103515625e-05 seconds
DEBUG 01-05 12:51:33.353348.353348 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.353683.353683 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.353129.353129 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.353720.353720 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.353553.353553 cuda_h.py:19] end allocate_cuda_memory cost 0.00029587745666503906 seconds
DEBUG 01-05 12:51:33.353164.353164 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.353020.353020 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.353412.353412 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.353399.353399 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16f9ddd7-76fe-442e-81e1-f0b7b9b0d139
DEBUG 01-05 12:51:33.353992.353992 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.354366.354366 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.355288.355288 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16f9ddd7-76fe-442e-81e1-f0b7b9b0d139
DEBUG 01-05 12:51:33.355363.355363 cuda_h.py:19] end load_into_gpu_async cost 0.0015516281127929688 seconds
DEBUG 01-05 12:51:33.355682.355682 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.355049.355049 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-05 12:51:33.355282.355282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021555423736572266 seconds
INFO 01-05 12:51:33.356656.356656 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16f9ddd7-76fe-442e-81e1-f0b7b9b0d139
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.357105.357105 cuda_h.py:19] end self_attn cost 0.0032143592834472656 seconds
DEBUG 01-05 12:51:33.357440.357440 cuda_h.py:19] end iln_self_attn_paln cost 0.004708528518676758 seconds
DEBUG 01-05 12:51:33.357330.357330 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 12:51:33.358570.358570 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.358373.358373 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-05 12:51:33.358295.358295 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.359934.359934 lmp.py:365] 
DEBUG 01-05 12:51:33.359934.359934 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.359783.359783 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.359002.359002 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.359553.359553 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.359765.359765 lmp.py:369] 
DEBUG 01-05 12:51:33.359765.359765 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.359931.359931 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.359349.359349 lmp.py:376]   Expert 34 |      6 | CPU
DEBUG 01-05 12:51:33.359754.359754 lmp.py:376]   Expert  3 |     23 | CPU
DEBUG 01-05 12:51:33.359966.359966 lmp.py:376]   Expert 61 |     27 | CPU
DEBUG 01-05 12:51:33.359702.359702 lmp.py:376]   Expert 14 |     30 | CPU
DEBUG 01-05 12:51:33.359676.359676 lmp.py:376]   Expert 48 |     39 | CPU
DEBUG 01-05 12:51:33.359412.359412 lmp.py:376]   Expert 47 |     46 | CPU
DEBUG 01-05 12:51:33.359147.359147 lmp.py:376]   Expert 32 |     47 | CPU
DEBUG 01-05 12:51:33.359598.359598 lmp.py:376]   Expert 55 |     51 | CPU
DEBUG 01-05 12:51:33.359572.359572 lmp.py:376]   Expert 27 |     64 | CPU
DEBUG 01-05 12:51:33.359785.359785 lmp.py:376]   Expert 15 |     70 | CPU
DEBUG 01-05 12:51:33.359236.359236 lmp.py:376]   Expert 12 |     78 | CPU
DEBUG 01-05 12:51:33.359448.359448 lmp.py:376]   Expert 13 |     78 | CPU
DEBUG 01-05 12:51:33.359422.359422 lmp.py:376]   Expert  7 |     84 | CPU
DEBUG 01-05 12:51:33.359158.359158 lmp.py:376]   Expert 19 |     87 | CPU
DEBUG 01-05 12:51:33.359801.359801 lmp.py:376]   Expert 44 |     89 | CPU
DEBUG 01-05 12:51:33.359490.359490 lmp.py:376]   Expert  6 |     92 | CPU
DEBUG 01-05 12:51:33.359941.359941 lmp.py:376]   Expert 54 |     99 | CPU
DEBUG 01-05 12:51:33.359630.359630 lmp.py:376]   Expert 50 |    100 | CPU
DEBUG 01-05 12:51:33.359081.359081 lmp.py:376]   Expert 26 |    103 | CPU
DEBUG 01-05 12:51:33.359532.359532 lmp.py:376]   Expert 56 |    105 | CPU
DEBUG 01-05 12:51:33.359221.359221 lmp.py:376]   Expert 38 |    109 | CPU
DEBUG 01-05 12:51:33.359864.359864 lmp.py:376]   Expert 28 |    111 | CPU
DEBUG 01-05 12:51:33.359030.359030 lmp.py:376]   Expert 46 |    115 | CPU
DEBUG 01-05 12:51:33.359196.359196 lmp.py:376]   Expert 37 |    127 | CPU
DEBUG 01-05 12:51:33.359124.359124 lmp.py:376]   Expert 20 |    129 | CPU
DEBUG 01-05 12:51:33.359052.359052 lmp.py:376]   Expert 62 |    135 | CPU
DEBUG 01-05 12:51:33.359741.359741 lmp.py:376]   Expert 43 |    143 | CPU
DEBUG 01-05 12:51:33.359954.359954 lmp.py:376]   Expert 35 |    146 | CPU
DEBUG 01-05 12:51:33.359404.359404 lmp.py:376]   Expert 36 |    154 | CPU
DEBUG 01-05 12:51:33.359855.359855 lmp.py:376]   Expert 60 |    156 | CPU
DEBUG 01-05 12:51:33.359306.359306 lmp.py:376]   Expert 45 |    161 | CPU
DEBUG 01-05 12:51:33.359519.359519 lmp.py:376]   Expert 52 |    164 | CPU
DEBUG 01-05 12:51:33.359685.359685 lmp.py:376]   Expert 29 |    167 | GPU
DEBUG 01-05 12:51:33.359851.359851 lmp.py:376]   Expert 24 |    169 | GPU
DEBUG 01-05 12:51:33.359540.359540 lmp.py:376]   Expert 25 |    170 | GPU
DEBUG 01-05 12:51:33.359468.359468 lmp.py:376]   Expert 17 |    175 | GPU
DEBUG 01-05 12:51:33.359873.359873 lmp.py:376]   Expert 41 |    177 | GPU
DEBUG 01-05 12:51:33.359323.359323 lmp.py:376]   Expert 51 |    183 | GPU
DEBUG 01-05 12:51:33.359774.359774 lmp.py:376]   Expert 22 |    185 | GPU
DEBUG 01-05 12:51:33.359464.359464 lmp.py:376]   Expert  2 |    186 | GPU
DEBUG 01-05 12:51:33.359915.359915 lmp.py:376]   Expert 63 |    194 | GPU
DEBUG 01-05 12:51:33.359604.359604 lmp.py:376]   Expert 42 |    207 | GPU
DEBUG 01-05 12:51:33.359578.359578 lmp.py:376]   Expert 57 |    215 | GPU
DEBUG 01-05 12:51:33.359790.359790 lmp.py:376]   Expert  5 |    227 | GPU
DEBUG 01-05 12:51:33.359241.359241 lmp.py:376]   Expert 21 |    233 | GPU
DEBUG 01-05 12:51:33.359646.359646 lmp.py:376]   Expert 31 |    235 | GPU
DEBUG 01-05 12:51:33.359050.359050 lmp.py:376]   Expert 59 |    237 | GPU
DEBUG 01-05 12:51:33.359216.359216 lmp.py:376]   Expert 18 |    244 | GPU
DEBUG 01-05 12:51:33.359144.359144 lmp.py:376]   Expert 53 |    256 | GPU
DEBUG 01-05 12:51:33.359502.359502 lmp.py:376]   Expert 39 |    259 | GPU
DEBUG 01-05 12:51:33.359861.359861 lmp.py:376]   Expert 30 |    264 | GPU
DEBUG 01-05 12:51:33.359788.359788 lmp.py:376]   Expert 16 |    280 | GPU
DEBUG 01-05 12:51:33.360239.360239 lmp.py:376]   Expert  8 |    293 | GPU
DEBUG 01-05 12:51:33.360167.360167 lmp.py:376]   Expert  9 |    305 | GPU
DEBUG 01-05 12:51:33.360379.360379 lmp.py:376]   Expert 10 |    306 | GPU
DEBUG 01-05 12:51:33.360830.360830 lmp.py:376]   Expert 49 |    345 | GPU
DEBUG 01-05 12:51:33.360586.360586 lmp.py:376]   Expert 33 |    356 | GPU
DEBUG 01-05 12:51:33.360613.360613 lmp.py:376]   Expert 23 |    380 | GPU
DEBUG 01-05 12:51:33.360780.360780 lmp.py:376]   Expert 40 |    412 | GPU
DEBUG 01-05 12:51:33.360899.360899 lmp.py:376]   Expert  0 |    441 | GPU
DEBUG 01-05 12:51:33.360827.360827 lmp.py:376]   Expert 11 |    515 | GPU
DEBUG 01-05 12:51:33.360470.360470 lmp.py:376]   Expert 58 |    520 | GPU
DEBUG 01-05 12:51:33.360921.360921 lmp.py:376]   Expert  1 |    583 | GPU
DEBUG 01-05 12:51:33.360326.360326 lmp.py:376]   Expert  4 |    601 | GPU
DEBUG 01-05 12:51:33.360492.360492 lmp.py:377] 
DEBUG 01-05 12:51:33.360492.360492 lmp.py:377]   CPU total tokens: 2968 (24.2%)
DEBUG 01-05 12:51:33.360850.360850 lmp.py:378]   GPU total tokens: 9320 (75.8%)
DEBUG 01-05 12:51:33.360023.360023 cuda_h.py:19] end experts_map_get cost 0.0015263557434082031 seconds
DEBUG 01-05 12:51:33.360335.360335 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.360641.360641 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.360361.360361 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.361773.361773 cuda_h.py:19] end allocate_cuda_memory cost 0.0011832714080810547 seconds
DEBUG 01-05 12:51:33.361080.361080 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.361883.361883 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.361096.361096 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.361322.361322 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb115746-1718-4f14-bcab-02b611aa0096
DEBUG 01-05 12:51:33.362965.362965 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.362778.362778 mlpmodule.py:662]  experts func einsum cost 0.06325078010559082 s
INFO 01-05 12:51:33.363580.363580 client.py:127] Model loaded
DEBUG 01-05 12:51:33.363968.363968 cuda_h.py:19] end sllm_worker_task cost 0.010202884674072266 seconds
INFO 01-05 12:51:33.364359.364359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb115746-1718-4f14-bcab-02b611aa0096
DEBUG 01-05 12:51:33.365971.365971 cuda_h.py:19] end load_into_gpu_async cost 0.0032224655151367188 seconds
DEBUG 01-05 12:51:33.365389.365389 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.365462.365462 cuda_h.py:19] end restore_tensors2 cost 0.00037217140197753906 seconds
DEBUG 01-05 12:51:33.365921.365921 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005168437957763672 seconds
DEBUG 01-05 12:51:33.368249.368249 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0077054500579833984 seconds
DEBUG 01-05 12:51:33.368363.368363 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.368227.368227 lmp.py:423] 
DEBUG 01-05 12:51:33.368227.368227 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.368401.368401 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-05 12:51:33.368574.368574 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.377555.377555 mlpmodule.py:704] group tensors cost 0.00910639762878418 s
DEBUG 01-05 12:51:33.379747.379747 mlpmodule.py:742] pad cost 0.0015709400177001953 s
DEBUG 01-05 12:51:33.379818.379818 mlpmodule.py:748] create cpu tensor cost 6.031990051269531e-05 s
DEBUG 01-05 12:51:33.379860.379860 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-05 12:51:33.388496.388496 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.388821.388821 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.388374.388374 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 12:51:33.388775.388775 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.402168.402168 mlpmodule.py:793] group einsum cost 0.02296900749206543 s
DEBUG 01-05 12:51:33.403999.403999 mlpmodule.py:801] cpy2cputensor cost 0.0006995201110839844 s
DEBUG 01-05 12:51:33.408236.408236 cuda_h.py:19] end wait_cetm_experts cost 0.04006004333496094 seconds
DEBUG 01-05 12:51:33.408659.408659 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.409725.409725 cuda_h.py:19] end gpu_sexperts cost 0.0005686283111572266 seconds
DEBUG 01-05 12:51:33.409953.409953 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.409617.409617 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 12:51:33.409466.409466 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.409414.409414 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb115746-1718-4f14-bcab-02b611aa0096
INFO 01-05 12:51:33.415649.415649 client.py:127] Model loaded
DEBUG 01-05 12:51:33.415837.415837 cuda_h.py:19] end wait_experts cost 0.0061032772064208984 seconds
DEBUG 01-05 12:51:33.415070.415070 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.415779.415779 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.416241.416241 mlpmodule.py:531] gpu group tensors cost 0.0006403923034667969 s
DEBUG 01-05 12:51:33.418164.418164 mlpmodule.py:564] gpu pad cost 0.0018198490142822266 s
DEBUG 01-05 12:51:33.418238.418238 mlpmodule.py:582] gpu group einsum cost 0.0005352497100830078 s
DEBUG 01-05 12:51:33.422132.422132 mlpmodule.py:611] gpu experts func einsum cost 0.0064928531646728516 s
DEBUG 01-05 12:51:33.422291.422291 cuda_h.py:19] end gpu_experts cost 0.006769895553588867 seconds
DEBUG 01-05 12:51:33.422313.422313 cuda_h.py:19] end layer_moe_generate_10 cost 0.06435394287109375 seconds
DEBUG 01-05 12:51:33.422333.422333 lmp.py:217] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 12:51:33.422950.422950 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 12:51:33.422977.422977 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 12:51:33.422780.422780 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 12:51:33.422616.422616 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.86102294921875e-05 seconds
DEBUG 01-05 12:51:33.422173.422173 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.793571472167969e-05 seconds
DEBUG 01-05 12:51:33.422054.422054 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.422560.422560 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.422803.422803 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.422215.422215 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.426420.426420 cuda_h.py:19] end allocate_cuda_memory cost 0.003283977508544922 seconds
DEBUG 01-05 12:51:33.426970.426970 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.426708.426708 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.426590.426590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.426446.426446 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 999fa399-cddb-46a5-ac24-954619022db3
DEBUG 01-05 12:51:33.426482.426482 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.426932.426932 mlpmodule.py:662]  experts func einsum cost 0.058587074279785156 s
DEBUG 01-05 12:51:33.427387.427387 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.428734.428734 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 999fa399-cddb-46a5-ac24-954619022db3
DEBUG 01-05 12:51:33.428067.428067 cuda_h.py:19] end load_into_gpu_async cost 0.0016322135925292969 seconds
DEBUG 01-05 12:51:33.428207.428207 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.428324.428324 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-05 12:51:33.428140.428140 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005476236343383789 seconds
INFO 01-05 12:51:33.429046.429046 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 999fa399-cddb-46a5-ac24-954619022db3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.430073.430073 cuda_h.py:19] end self_attn cost 0.0035636425018310547 seconds
DEBUG 01-05 12:51:33.431878.431878 cuda_h.py:19] end iln_self_attn_paln cost 0.008549690246582031 seconds
DEBUG 01-05 12:51:33.431543.431543 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 12:51:33.431736.431736 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.432599.432599 cuda_h.py:19] end gate cost 0.0006389617919921875 seconds
DEBUG 01-05 12:51:33.432283.432283 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.432836.432836 lmp.py:365] 
DEBUG 01-05 12:51:33.432836.432836 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.432500.432500 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.432103.432103 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.432130.432130 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.432012.432012 lmp.py:369] 
DEBUG 01-05 12:51:33.432012.432012 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.432608.432608 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.432973.432973 lmp.py:376]   Expert 35 |     15 | CPU
DEBUG 01-05 12:51:33.432093.432093 lmp.py:376]   Expert 19 |     22 | CPU
DEBUG 01-05 12:51:33.432736.432736 lmp.py:376]   Expert 39 |     28 | CPU
DEBUG 01-05 12:51:33.432902.432902 lmp.py:376]   Expert 16 |     36 | CPU
DEBUG 01-05 12:51:33.432307.432307 lmp.py:376]   Expert 59 |     38 | CPU
DEBUG 01-05 12:51:33.432473.432473 lmp.py:376]   Expert 41 |     50 | CPU
DEBUG 01-05 12:51:33.432401.432401 lmp.py:376]   Expert 49 |     51 | CPU
DEBUG 01-05 12:51:33.432090.432090 lmp.py:376]   Expert 17 |     58 | CPU
DEBUG 01-05 12:51:33.432018.432018 lmp.py:376]   Expert  3 |     72 | CPU
DEBUG 01-05 12:51:33.432661.432661 lmp.py:376]   Expert  7 |     73 | CPU
DEBUG 01-05 12:51:33.432065.432065 lmp.py:376]   Expert  5 |     74 | CPU
DEBUG 01-05 12:51:33.432708.432708 lmp.py:376]   Expert  8 |     76 | CPU
DEBUG 01-05 12:51:33.432351.432351 lmp.py:376]   Expert 15 |     81 | CPU
DEBUG 01-05 12:51:33.432040.432040 lmp.py:376]   Expert 23 |     82 | CPU
DEBUG 01-05 12:51:33.432968.432968 lmp.py:376]   Expert  6 |     87 | CPU
DEBUG 01-05 12:51:33.432657.432657 lmp.py:376]   Expert 44 |     87 | CPU
DEBUG 01-05 12:51:33.432347.432347 lmp.py:376]   Expert  0 |     88 | CPU
DEBUG 01-05 12:51:33.432275.432275 lmp.py:376]   Expert 38 |     97 | CPU
DEBUG 01-05 12:51:33.432725.432725 lmp.py:376]   Expert  4 |    102 | CPU
DEBUG 01-05 12:51:33.432415.432415 lmp.py:376]   Expert 10 |    104 | CPU
DEBUG 01-05 12:51:33.432104.432104 lmp.py:376]   Expert 40 |    109 | CPU
DEBUG 01-05 12:51:33.432747.432747 lmp.py:376]   Expert 63 |    109 | CPU
DEBUG 01-05 12:51:33.432390.432390 lmp.py:376]   Expert 62 |    111 | CPU
DEBUG 01-05 12:51:33.432556.432556 lmp.py:376]   Expert 46 |    113 | CPU
DEBUG 01-05 12:51:33.432961.432961 lmp.py:376]   Expert 52 |    113 | CPU
DEBUG 01-05 12:51:33.432604.432604 lmp.py:376]   Expert 32 |    120 | CPU
DEBUG 01-05 12:51:33.433293.433293 lmp.py:376]   Expert 27 |    131 | CPU
DEBUG 01-05 12:51:33.433744.433744 lmp.py:376]   Expert 25 |    132 | CPU
DEBUG 01-05 12:51:33.433195.433195 lmp.py:376]   Expert 50 |    132 | CPU
DEBUG 01-05 12:51:33.433884.433884 lmp.py:376]   Expert  1 |    134 | CPU
DEBUG 01-05 12:51:33.433335.433335 lmp.py:376]   Expert 60 |    138 | CPU
DEBUG 01-05 12:51:33.433786.433786 lmp.py:376]   Expert 31 |    142 | CPU
DEBUG 01-05 12:51:33.433475.433475 lmp.py:376]   Expert 48 |    145 | GPU
DEBUG 01-05 12:51:33.433164.433164 lmp.py:376]   Expert 20 |    149 | GPU
DEBUG 01-05 12:51:33.433569.433569 lmp.py:376]   Expert 36 |    160 | GPU
DEBUG 01-05 12:51:33.433973.433973 lmp.py:376]   Expert 51 |    173 | GPU
DEBUG 01-05 12:51:33.433378.433378 lmp.py:376]   Expert 61 |    178 | GPU
DEBUG 01-05 12:51:33.433306.433306 lmp.py:376]   Expert 57 |    181 | GPU
DEBUG 01-05 12:51:33.433949.433949 lmp.py:376]   Expert 13 |    184 | GPU
DEBUG 01-05 12:51:33.433400.433400 lmp.py:376]   Expert 18 |    194 | GPU
DEBUG 01-05 12:51:33.433327.433327 lmp.py:376]   Expert 42 |    194 | GPU
DEBUG 01-05 12:51:33.433778.433778 lmp.py:376]   Expert 56 |    195 | GPU
DEBUG 01-05 12:51:33.433467.433467 lmp.py:376]   Expert 26 |    212 | GPU
DEBUG 01-05 12:51:33.433680.433680 lmp.py:376]   Expert  2 |    223 | GPU
DEBUG 01-05 12:51:33.433131.433131 lmp.py:376]   Expert 43 |    238 | GPU
DEBUG 01-05 12:51:33.433343.433343 lmp.py:376]   Expert 47 |    259 | GPU
DEBUG 01-05 12:51:33.433033.433033 lmp.py:376]   Expert 33 |    264 | GPU
DEBUG 01-05 12:51:33.433483.433483 lmp.py:376]   Expert 53 |    271 | GPU
DEBUG 01-05 12:51:33.433650.433650 lmp.py:376]   Expert 12 |    284 | GPU
DEBUG 01-05 12:51:33.433293.433293 lmp.py:376]   Expert 55 |    293 | GPU
DEBUG 01-05 12:51:33.433220.433220 lmp.py:376]   Expert 58 |    301 | GPU
DEBUG 01-05 12:51:33.433386.433386 lmp.py:376]   Expert 45 |    304 | GPU
DEBUG 01-05 12:51:33.433076.433076 lmp.py:376]   Expert 14 |    316 | GPU
DEBUG 01-05 12:51:33.433765.433765 lmp.py:376]   Expert 29 |    325 | GPU
DEBUG 01-05 12:51:33.433454.433454 lmp.py:376]   Expert 24 |    332 | GPU
DEBUG 01-05 12:51:33.433905.433905 lmp.py:376]   Expert 37 |    345 | GPU
DEBUG 01-05 12:51:33.433595.433595 lmp.py:376]   Expert 34 |    363 | GPU
DEBUG 01-05 12:51:33.433807.433807 lmp.py:376]   Expert 21 |    373 | GPU
DEBUG 01-05 12:51:33.433258.433258 lmp.py:376]   Expert 54 |    373 | GPU
DEBUG 01-05 12:51:33.433709.433709 lmp.py:376]   Expert 28 |    405 | GPU
DEBUG 01-05 12:51:33.433683.433683 lmp.py:376]   Expert  9 |    406 | GPU
DEBUG 01-05 12:51:33.433611.433611 lmp.py:376]   Expert 11 |    428 | GPU
DEBUG 01-05 12:51:33.433538.433538 lmp.py:376]   Expert 22 |    447 | GPU
DEBUG 01-05 12:51:33.433228.433228 lmp.py:376]   Expert 30 |    968 | GPU
DEBUG 01-05 12:51:33.433347.433347 lmp.py:377] 
DEBUG 01-05 12:51:33.433347.433347 lmp.py:377]   CPU total tokens: 2805 (22.8%)
DEBUG 01-05 12:51:33.433229.433229 lmp.py:378]   GPU total tokens: 9483 (77.2%)
DEBUG 01-05 12:51:33.433163.433163 cuda_h.py:19] end experts_map_get cost 0.0015354156494140625 seconds
DEBUG 01-05 12:51:33.433806.433806 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.433205.433205 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.433057.433057 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.435995.435995 cuda_h.py:19] end allocate_cuda_memory cost 0.001466989517211914 seconds
DEBUG 01-05 12:51:33.435315.435315 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.435833.435833 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.435026.435026 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.435298.435298 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f69db737-54e1-4462-8cde-85a0605092a4
DEBUG 01-05 12:51:33.435510.435510 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.436519.436519 client.py:127] Model loaded
DEBUG 01-05 12:51:33.436873.436873 cuda_h.py:19] end sllm_worker_task cost 0.01336216926574707 seconds
INFO 01-05 12:51:33.437339.437339 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f69db737-54e1-4462-8cde-85a0605092a4
DEBUG 01-05 12:51:33.437242.437242 cuda_h.py:19] end load_into_gpu_async cost 0.002334117889404297 seconds
DEBUG 01-05 12:51:33.437137.437137 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.438303.438303 cuda_h.py:19] end restore_tensors2 cost 0.000377655029296875 seconds
DEBUG 01-05 12:51:33.438139.438139 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045282840728759766 seconds
DEBUG 01-05 12:51:33.441699.441699 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0072672367095947266 seconds
DEBUG 01-05 12:51:33.441682.441682 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.441452.441452 lmp.py:423] 
DEBUG 01-05 12:51:33.441452.441452 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.441918.441918 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-05 12:51:33.441906.441906 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.456351.456351 mlpmodule.py:704] group tensors cost 0.014863729476928711 s
DEBUG 01-05 12:51:33.458305.458305 mlpmodule.py:742] pad cost 0.0016016960144042969 s
DEBUG 01-05 12:51:33.458137.458137 mlpmodule.py:748] create cpu tensor cost 6.508827209472656e-05 s
DEBUG 01-05 12:51:33.458517.458517 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-05 12:51:33.468327.468327 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.468134.468134 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.468826.468826 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 12:51:33.468355.468355 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.482991.482991 mlpmodule.py:793] group einsum cost 0.023584842681884766 s
DEBUG 01-05 12:51:33.483701.483701 mlpmodule.py:801] cpy2cputensor cost 0.0006439685821533203 s
DEBUG 01-05 12:51:33.487940.487940 cuda_h.py:19] end wait_cetm_experts cost 0.04664802551269531 seconds
DEBUG 01-05 12:51:33.488741.488741 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.488656.488656 cuda_h.py:19] end gpu_sexperts cost 0.0005970001220703125 seconds
DEBUG 01-05 12:51:33.488645.488645 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.488978.488978 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 12:51:33.488350.488350 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.488775.488775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f69db737-54e1-4462-8cde-85a0605092a4
INFO 01-05 12:51:33.490648.490648 client.py:127] Model loaded
DEBUG 01-05 12:51:33.490636.490636 cuda_h.py:19] end wait_experts cost 0.0011970996856689453 seconds
DEBUG 01-05 12:51:33.490485.490485 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.490480.490480 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.490365.490365 mlpmodule.py:531] gpu group tensors cost 0.0006358623504638672 s
DEBUG 01-05 12:51:33.503671.503671 mlpmodule.py:564] gpu pad cost 0.01206827163696289 s
DEBUG 01-05 12:51:33.512253.512253 mlpmodule.py:662]  experts func einsum cost 0.07071614265441895 s
DEBUG 01-05 12:51:33.513076.513076 mlpmodule.py:582] gpu group einsum cost 0.010181903839111328 s
DEBUG 01-05 12:51:33.519745.519745 mlpmodule.py:611] gpu experts func einsum cost 0.02938389778137207 s
DEBUG 01-05 12:51:33.519806.519806 cuda_h.py:19] end gpu_experts cost 0.029730796813964844 seconds
DEBUG 01-05 12:51:33.520010.520010 cuda_h.py:19] end layer_moe_generate_11 cost 0.08868288993835449 seconds
DEBUG 01-05 12:51:33.520802.520802 lmp.py:217] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 12:51:33.520890.520890 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 12:51:33.520520.520520 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 12:51:33.520947.520947 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 12:51:33.520844.520844 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 4.6253204345703125e-05 seconds
DEBUG 01-05 12:51:33.520104.520104 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00010609626770019531 seconds
DEBUG 01-05 12:51:33.520920.520920 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.520327.520327 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.520006.520006 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.521671.521671 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.521905.521905 cuda_h.py:19] end allocate_cuda_memory cost 0.00022840499877929688 seconds
DEBUG 01-05 12:51:33.521484.521484 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.521446.521446 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.521951.521951 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.521283.521283 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9aeb115-1e7a-43e9-a43c-b9b034ed66f6
DEBUG 01-05 12:51:33.521565.521565 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.522629.522629 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.523691.523691 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9aeb115-1e7a-43e9-a43c-b9b034ed66f6
DEBUG 01-05 12:51:33.523925.523925 cuda_h.py:19] end load_into_gpu_async cost 0.0016505718231201172 seconds
DEBUG 01-05 12:51:33.523542.523542 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.523797.523797 cuda_h.py:19] end restore_tensors2 cost 8.249282836914062e-05 seconds
DEBUG 01-05 12:51:33.523567.523567 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022656917572021484 seconds
INFO 01-05 12:51:33.524608.524608 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9aeb115-1e7a-43e9-a43c-b9b034ed66f6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.526695.526695 cuda_h.py:19] end self_attn cost 0.004667997360229492 seconds
DEBUG 01-05 12:51:33.527142.527142 cuda_h.py:19] end iln_self_attn_paln cost 0.006403446197509766 seconds
DEBUG 01-05 12:51:33.527409.527409 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 12:51:33.527934.527934 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.527869.527869 cuda_h.py:19] end gate cost 0.000621795654296875 seconds
DEBUG 01-05 12:51:33.528507.528507 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.528146.528146 lmp.py:365] 
DEBUG 01-05 12:51:33.528146.528146 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.528471.528471 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.528883.528883 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.528718.528718 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.528328.528328 lmp.py:369] 
DEBUG 01-05 12:51:33.528328.528328 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.528209.528209 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.528051.528051 lmp.py:376]   Expert 51 |     13 | CPU
DEBUG 01-05 12:51:33.528456.528456 lmp.py:376]   Expert 63 |     17 | CPU
DEBUG 01-05 12:51:33.528907.528907 lmp.py:376]   Expert 34 |     24 | CPU
DEBUG 01-05 12:51:33.528881.528881 lmp.py:376]   Expert 22 |     29 | CPU
DEBUG 01-05 12:51:33.528855.528855 lmp.py:376]   Expert 47 |     29 | CPU
DEBUG 01-05 12:51:33.528829.528829 lmp.py:376]   Expert 12 |     30 | CPU
DEBUG 01-05 12:51:33.528803.528803 lmp.py:376]   Expert 11 |     31 | CPU
DEBUG 01-05 12:51:33.528300.528300 lmp.py:376]   Expert 16 |     35 | CPU
DEBUG 01-05 12:51:33.528036.528036 lmp.py:376]   Expert  4 |     42 | CPU
DEBUG 01-05 12:51:33.528440.528440 lmp.py:376]   Expert 44 |     51 | CPU
DEBUG 01-05 12:51:33.528130.528130 lmp.py:376]   Expert  0 |     57 | CPU
DEBUG 01-05 12:51:33.528918.528918 lmp.py:376]   Expert 29 |     62 | CPU
DEBUG 01-05 12:51:33.528369.528369 lmp.py:376]   Expert 32 |     68 | CPU
DEBUG 01-05 12:51:33.528105.528105 lmp.py:376]   Expert 27 |     73 | CPU
DEBUG 01-05 12:51:33.528840.528840 lmp.py:376]   Expert 13 |     76 | CPU
DEBUG 01-05 12:51:33.528099.528099 lmp.py:376]   Expert 37 |     88 | CPU
DEBUG 01-05 12:51:33.528835.528835 lmp.py:376]   Expert 41 |     93 | CPU
DEBUG 01-05 12:51:33.528094.528094 lmp.py:376]   Expert  8 |     94 | CPU
DEBUG 01-05 12:51:33.528591.528591 lmp.py:376]   Expert 23 |     94 | CPU
DEBUG 01-05 12:51:33.528850.528850 lmp.py:376]   Expert 49 |     99 | CPU
DEBUG 01-05 12:51:33.528585.528585 lmp.py:376]   Expert 21 |    100 | CPU
DEBUG 01-05 12:51:33.528844.528844 lmp.py:376]   Expert  2 |    105 | CPU
DEBUG 01-05 12:51:33.528103.528103 lmp.py:376]   Expert 43 |    107 | CPU
DEBUG 01-05 12:51:33.528600.528600 lmp.py:376]   Expert 62 |    133 | CPU
DEBUG 01-05 12:51:33.528051.528051 lmp.py:376]   Expert  3 |    134 | CPU
DEBUG 01-05 12:51:33.528263.528263 lmp.py:376]   Expert 39 |    138 | CPU
DEBUG 01-05 12:51:33.528476.528476 lmp.py:376]   Expert 14 |    139 | CPU
DEBUG 01-05 12:51:33.528973.528973 lmp.py:376]   Expert 30 |    143 | CPU
DEBUG 01-05 12:51:33.528470.528470 lmp.py:376]   Expert 55 |    148 | CPU
DEBUG 01-05 12:51:33.528729.528729 lmp.py:376]   Expert  7 |    152 | CPU
DEBUG 01-05 12:51:33.528226.528226 lmp.py:376]   Expert 61 |    155 | CPU
DEBUG 01-05 12:51:33.528485.528485 lmp.py:376]   Expert 42 |    157 | CPU
DEBUG 01-05 12:51:33.528982.528982 lmp.py:376]   Expert 58 |    166 | GPU
DEBUG 01-05 12:51:33.528003.528003 lmp.py:376]   Expert 45 |    178 | GPU
DEBUG 01-05 12:51:33.528500.528500 lmp.py:376]   Expert 53 |    188 | GPU
DEBUG 01-05 12:51:33.529997.529997 lmp.py:376]   Expert  5 |    190 | GPU
DEBUG 01-05 12:51:33.529256.529256 lmp.py:376]   Expert 18 |    194 | GPU
DEBUG 01-05 12:51:33.529991.529991 lmp.py:376]   Expert 31 |    196 | GPU
DEBUG 01-05 12:51:33.529250.529250 lmp.py:376]   Expert 38 |    196 | GPU
DEBUG 01-05 12:51:33.529701.529701 lmp.py:376]   Expert 35 |    210 | GPU
DEBUG 01-05 12:51:33.529152.529152 lmp.py:376]   Expert  6 |    216 | GPU
DEBUG 01-05 12:51:33.529126.529126 lmp.py:376]   Expert 17 |    218 | GPU
DEBUG 01-05 12:51:33.529577.529577 lmp.py:376]   Expert  1 |    229 | GPU
DEBUG 01-05 12:51:33.529551.529551 lmp.py:376]   Expert 19 |    234 | GPU
DEBUG 01-05 12:51:33.529810.529810 lmp.py:376]   Expert 20 |    242 | GPU
DEBUG 01-05 12:51:33.529830.529830 lmp.py:376]   Expert 50 |    242 | GPU
DEBUG 01-05 12:51:33.529327.529327 lmp.py:376]   Expert 46 |    250 | GPU
DEBUG 01-05 12:51:33.529586.529586 lmp.py:376]   Expert 57 |    252 | GPU
DEBUG 01-05 12:51:33.529083.529083 lmp.py:376]   Expert 59 |    280 | GPU
DEBUG 01-05 12:51:33.529581.529581 lmp.py:376]   Expert 52 |    284 | GPU
DEBUG 01-05 12:51:33.529601.529601 lmp.py:376]   Expert 26 |    286 | GPU
DEBUG 01-05 12:51:33.529052.529052 lmp.py:376]   Expert 60 |    307 | GPU
DEBUG 01-05 12:51:33.529741.529741 lmp.py:376]   Expert 48 |    308 | GPU
DEBUG 01-05 12:51:33.529430.529430 lmp.py:376]   Expert 25 |    311 | GPU
DEBUG 01-05 12:51:33.529643.529643 lmp.py:376]   Expert 54 |    314 | GPU
DEBUG 01-05 12:51:33.529378.529378 lmp.py:376]   Expert 28 |    320 | GPU
DEBUG 01-05 12:51:33.529876.529876 lmp.py:376]   Expert 24 |    349 | GPU
DEBUG 01-05 12:51:33.529611.529611 lmp.py:376]   Expert 36 |    349 | GPU
DEBUG 01-05 12:51:33.529109.529109 lmp.py:376]   Expert 40 |    391 | GPU
DEBUG 01-05 12:51:33.529844.529844 lmp.py:376]   Expert 33 |    416 | GPU
DEBUG 01-05 12:51:33.529103.529103 lmp.py:376]   Expert  9 |    452 | GPU
DEBUG 01-05 12:51:33.529839.529839 lmp.py:376]   Expert 15 |    523 | GPU
DEBUG 01-05 12:51:33.529097.529097 lmp.py:376]   Expert 56 |    548 | GPU
DEBUG 01-05 12:51:33.529595.529595 lmp.py:376]   Expert 10 |    733 | GPU
DEBUG 01-05 12:51:33.529999.529999 lmp.py:377] 
DEBUG 01-05 12:51:33.529999.529999 lmp.py:377]   CPU total tokens: 2716 (22.1%)
DEBUG 01-05 12:51:33.529404.529404 lmp.py:378]   GPU total tokens: 9572 (77.9%)
DEBUG 01-05 12:51:33.529338.529338 cuda_h.py:19] end experts_map_get cost 0.001462697982788086 seconds
DEBUG 01-05 12:51:33.529981.529981 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.529287.529287 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.529617.529617 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.530060.530060 cuda_h.py:19] end allocate_cuda_memory cost 0.0005402565002441406 seconds
DEBUG 01-05 12:51:33.530757.530757 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.530559.530559 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.530514.530514 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.530833.530833 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9c0229b8-ba08-40f0-b489-d4da95800a27
DEBUG 01-05 12:51:33.530515.530515 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.531476.531476 client.py:127] Model loaded
DEBUG 01-05 12:51:33.531883.531883 cuda_h.py:19] end sllm_worker_task cost 0.010167598724365234 seconds
INFO 01-05 12:51:33.532108.532108 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9c0229b8-ba08-40f0-b489-d4da95800a27
DEBUG 01-05 12:51:33.532119.532119 cuda_h.py:19] end load_into_gpu_async cost 0.0024650096893310547 seconds
DEBUG 01-05 12:51:33.532751.532751 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.533242.533242 cuda_h.py:19] end restore_tensors2 cost 0.0005426406860351562 seconds
DEBUG 01-05 12:51:33.533992.533992 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004002809524536133 seconds
DEBUG 01-05 12:51:33.536973.536973 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0066394805908203125 seconds
DEBUG 01-05 12:51:33.536179.536179 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.536540.536540 lmp.py:423] 
DEBUG 01-05 12:51:33.536540.536540 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.536668.536668 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-05 12:51:33.536657.536657 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.554774.554774 mlpmodule.py:704] group tensors cost 0.017436981201171875 s
DEBUG 01-05 12:51:33.557399.557399 mlpmodule.py:742] pad cost 0.0020935535430908203 s
DEBUG 01-05 12:51:33.557391.557391 mlpmodule.py:748] create cpu tensor cost 5.7220458984375e-05 s
DEBUG 01-05 12:51:33.557744.557744 mlpmodule.py:753] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-05 12:51:33.566372.566372 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.566411.566411 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.566825.566825 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 12:51:33.566730.566730 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.580946.580946 mlpmodule.py:793] group einsum cost 0.023332595825195312 s
DEBUG 01-05 12:51:33.581182.581182 mlpmodule.py:801] cpy2cputensor cost 0.0006883144378662109 s
DEBUG 01-05 12:51:33.586393.586393 cuda_h.py:19] end wait_cetm_experts cost 0.04959225654602051 seconds
DEBUG 01-05 12:51:33.586696.586696 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.586193.586193 cuda_h.py:19] end gpu_sexperts cost 0.0005710124969482422 seconds
DEBUG 01-05 12:51:33.586129.586129 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.586462.586462 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-05 12:51:33.587311.587311 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.587544.587544 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9c0229b8-ba08-40f0-b489-d4da95800a27
INFO 01-05 12:51:33.588994.588994 client.py:127] Model loaded
DEBUG 01-05 12:51:33.588121.588121 cuda_h.py:19] end wait_experts cost 0.0012333393096923828 seconds
DEBUG 01-05 12:51:33.588255.588255 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.588342.588342 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.589810.589810 mlpmodule.py:531] gpu group tensors cost 0.0006320476531982422 s
DEBUG 01-05 12:51:33.590666.590666 mlpmodule.py:564] gpu pad cost 0.0017671585083007812 s
DEBUG 01-05 12:51:33.591117.591117 mlpmodule.py:582] gpu group einsum cost 0.0005311965942382812 s
DEBUG 01-05 12:51:33.595904.595904 mlpmodule.py:611] gpu experts func einsum cost 0.0065996646881103516 s
DEBUG 01-05 12:51:33.595954.595954 cuda_h.py:19] end gpu_experts cost 0.006806850433349609 seconds
DEBUG 01-05 12:51:33.595884.595884 cuda_h.py:19] end layer_moe_generate_12 cost 0.06794548034667969 seconds
DEBUG 01-05 12:51:33.595997.595997 lmp.py:217] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 12:51:33.595198.595198 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 12:51:33.595470.595470 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 12:51:33.595517.595517 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 12:51:33.595222.595222 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.337860107421875e-05 seconds
DEBUG 01-05 12:51:33.595931.595931 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.794929504394531e-05 seconds
DEBUG 01-05 12:51:33.595535.595535 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.595101.595101 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.595283.595283 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.595735.595735 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.603314.603314 cuda_h.py:19] end allocate_cuda_memory cost 0.00754094123840332 seconds
DEBUG 01-05 12:51:33.603642.603642 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.603703.603703 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.603115.603115 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.603395.603395 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb85daca-ce1c-40b8-8314-80be22a8d95e
DEBUG 01-05 12:51:33.603079.603079 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.604520.604520 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.605794.605794 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb85daca-ce1c-40b8-8314-80be22a8d95e
DEBUG 01-05 12:51:33.605207.605207 cuda_h.py:19] end load_into_gpu_async cost 0.0016021728515625 seconds
DEBUG 01-05 12:51:33.605479.605479 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.605800.605800 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-05 12:51:33.605410.605410 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009508609771728516 seconds
INFO 01-05 12:51:33.605950.605950 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb85daca-ce1c-40b8-8314-80be22a8d95e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.607931.607931 cuda_h.py:19] end self_attn cost 0.003320932388305664 seconds
DEBUG 01-05 12:51:33.607638.607638 cuda_h.py:19] end iln_self_attn_paln cost 0.012155532836914062 seconds
DEBUG 01-05 12:51:33.607303.607303 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 12:51:33.607602.607602 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.608747.608747 cuda_h.py:19] end gate cost 0.0007326602935791016 seconds
DEBUG 01-05 12:51:33.608266.608266 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.609537.609537 lmp.py:365] 
DEBUG 01-05 12:51:33.609537.609537 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.609161.609161 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.609486.609486 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.609428.609428 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.609031.609031 lmp.py:369] 
DEBUG 01-05 12:51:33.609031.609031 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.609588.609588 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.609344.609344 lmp.py:376]   Expert 53 |     10 | CPU
DEBUG 01-05 12:51:33.609186.609186 lmp.py:376]   Expert  6 |     13 | CPU
DEBUG 01-05 12:51:33.609796.609796 lmp.py:376]   Expert 19 |     21 | CPU
DEBUG 01-05 12:51:33.609400.609400 lmp.py:376]   Expert 50 |     24 | CPU
DEBUG 01-05 12:51:33.609811.609811 lmp.py:376]   Expert 26 |     40 | CPU
DEBUG 01-05 12:51:33.609461.609461 lmp.py:376]   Expert  2 |     48 | CPU
DEBUG 01-05 12:51:33.609111.609111 lmp.py:376]   Expert  0 |     50 | CPU
DEBUG 01-05 12:51:33.609045.609045 lmp.py:376]   Expert 12 |     63 | CPU
DEBUG 01-05 12:51:33.609649.609649 lmp.py:376]   Expert  8 |     64 | CPU
DEBUG 01-05 12:51:33.609537.609537 lmp.py:376]   Expert 31 |     78 | CPU
DEBUG 01-05 12:51:33.609663.609663 lmp.py:376]   Expert 20 |     93 | CPU
DEBUG 01-05 12:51:33.609551.609551 lmp.py:376]   Expert 16 |     94 | CPU
DEBUG 01-05 12:51:33.609486.609486 lmp.py:376]   Expert 32 |     97 | CPU
DEBUG 01-05 12:51:33.609420.609420 lmp.py:376]   Expert 40 |     97 | CPU
DEBUG 01-05 12:51:33.609593.609593 lmp.py:376]   Expert 30 |    108 | CPU
DEBUG 01-05 12:51:33.609528.609528 lmp.py:376]   Expert 28 |    111 | CPU
DEBUG 01-05 12:51:33.609462.609462 lmp.py:376]   Expert 35 |    115 | CPU
DEBUG 01-05 12:51:33.609635.609635 lmp.py:376]   Expert 63 |    117 | CPU
DEBUG 01-05 12:51:33.609808.609808 lmp.py:376]   Expert 61 |    121 | CPU
DEBUG 01-05 12:51:33.609696.609696 lmp.py:376]   Expert 48 |    123 | CPU
DEBUG 01-05 12:51:33.609585.609585 lmp.py:376]   Expert 57 |    125 | CPU
DEBUG 01-05 12:51:33.609711.609711 lmp.py:376]   Expert 13 |    126 | CPU
DEBUG 01-05 12:51:33.609884.609884 lmp.py:376]   Expert 18 |    126 | CPU
DEBUG 01-05 12:51:33.609819.609819 lmp.py:376]   Expert  5 |    129 | CPU
DEBUG 01-05 12:51:33.609992.609992 lmp.py:376]   Expert 60 |    137 | CPU
DEBUG 01-05 12:51:33.609926.609926 lmp.py:376]   Expert 11 |    138 | CPU
DEBUG 01-05 12:51:33.609576.609576 lmp.py:376]   Expert 34 |    138 | CPU
DEBUG 01-05 12:51:33.609987.609987 lmp.py:376]   Expert 24 |    151 | CPU
DEBUG 01-05 12:51:33.610114.610114 lmp.py:376]   Expert 58 |    151 | CPU
DEBUG 01-05 12:51:33.610002.610002 lmp.py:376]   Expert 52 |    154 | CPU
DEBUG 01-05 12:51:33.610652.610652 lmp.py:376]   Expert  9 |    163 | CPU
DEBUG 01-05 12:51:33.610586.610586 lmp.py:376]   Expert  3 |    169 | CPU
DEBUG 01-05 12:51:33.610759.610759 lmp.py:376]   Expert 37 |    177 | GPU
DEBUG 01-05 12:51:33.610694.610694 lmp.py:376]   Expert 42 |    178 | GPU
DEBUG 01-05 12:51:33.610867.610867 lmp.py:376]   Expert 25 |    179 | GPU
DEBUG 01-05 12:51:33.610801.610801 lmp.py:376]   Expert 45 |    182 | GPU
DEBUG 01-05 12:51:33.610451.610451 lmp.py:376]   Expert  4 |    204 | GPU
DEBUG 01-05 12:51:33.610339.610339 lmp.py:376]   Expert 46 |    205 | GPU
DEBUG 01-05 12:51:33.610227.610227 lmp.py:376]   Expert 17 |    212 | GPU
DEBUG 01-05 12:51:33.610115.610115 lmp.py:376]   Expert 27 |    217 | GPU
DEBUG 01-05 12:51:33.610527.610527 lmp.py:376]   Expert 33 |    222 | GPU
DEBUG 01-05 12:51:33.610700.610700 lmp.py:376]   Expert  7 |    224 | GPU
DEBUG 01-05 12:51:33.610396.610396 lmp.py:376]   Expert 43 |    226 | GPU
DEBUG 01-05 12:51:33.610330.610330 lmp.py:376]   Expert 39 |    229 | GPU
DEBUG 01-05 12:51:33.610026.610026 lmp.py:376]   Expert 22 |    232 | GPU
DEBUG 01-05 12:51:33.610961.610961 lmp.py:376]   Expert 51 |    232 | GPU
DEBUG 01-05 12:51:33.610088.610088 lmp.py:376]   Expert 62 |    237 | GPU
DEBUG 01-05 12:51:33.610453.610453 lmp.py:376]   Expert 54 |    251 | GPU
DEBUG 01-05 12:51:33.610341.610341 lmp.py:376]   Expert 49 |    252 | GPU
DEBUG 01-05 12:51:33.610229.610229 lmp.py:376]   Expert  1 |    261 | GPU
DEBUG 01-05 12:51:33.610163.610163 lmp.py:376]   Expert 29 |    268 | GPU
DEBUG 01-05 12:51:33.610621.610621 lmp.py:376]   Expert 36 |    269 | GPU
DEBUG 01-05 12:51:33.610556.610556 lmp.py:376]   Expert 44 |    280 | GPU
DEBUG 01-05 12:51:33.610252.610252 lmp.py:376]   Expert 59 |    315 | GPU
DEBUG 01-05 12:51:33.610948.610948 lmp.py:376]   Expert 15 |    317 | GPU
DEBUG 01-05 12:51:33.610882.610882 lmp.py:376]   Expert 47 |    318 | GPU
DEBUG 01-05 12:51:33.610532.610532 lmp.py:376]   Expert 38 |    336 | GPU
DEBUG 01-05 12:51:33.610182.610182 lmp.py:376]   Expert 14 |    393 | GPU
DEBUG 01-05 12:51:33.610308.610308 lmp.py:376]   Expert 23 |    393 | GPU
DEBUG 01-05 12:51:33.610243.610243 lmp.py:376]   Expert 55 |    403 | GPU
DEBUG 01-05 12:51:33.610177.610177 lmp.py:376]   Expert 21 |    410 | GPU
DEBUG 01-05 12:51:33.610874.610874 lmp.py:376]   Expert 41 |    413 | GPU
DEBUG 01-05 12:51:33.610331.610331 lmp.py:376]   Expert 10 |    469 | GPU
DEBUG 01-05 12:51:33.610027.610027 lmp.py:376]   Expert 56 |    590 | GPU
DEBUG 01-05 12:51:33.610392.610392 lmp.py:377] 
DEBUG 01-05 12:51:33.610392.610392 lmp.py:377]   CPU total tokens: 3194 (26.0%)
DEBUG 01-05 12:51:33.610996.610996 lmp.py:378]   GPU total tokens: 9094 (74.0%)
DEBUG 01-05 12:51:33.610560.610560 cuda_h.py:19] end experts_map_get cost 0.0020051002502441406 seconds
DEBUG 01-05 12:51:33.610355.610355 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.610013.610013 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.611561.611561 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.613993.613993 cuda_h.py:19] end allocate_cuda_memory cost 0.0019447803497314453 seconds
DEBUG 01-05 12:51:33.613918.613918 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.613941.613941 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.613461.613461 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.613311.613311 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8cfffd0c-6196-4c5c-b56e-4823516b276c
DEBUG 01-05 12:51:33.613869.613869 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.613485.613485 client.py:127] Model loaded
DEBUG 01-05 12:51:33.614913.614913 mlpmodule.py:662]  experts func einsum cost 0.07740163803100586 s
DEBUG 01-05 12:51:33.614464.614464 cuda_h.py:19] end sllm_worker_task cost 0.018440961837768555 seconds
INFO 01-05 12:51:33.615431.615431 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8cfffd0c-6196-4c5c-b56e-4823516b276c
DEBUG 01-05 12:51:33.615827.615827 cuda_h.py:19] end load_into_gpu_async cost 0.0025038719177246094 seconds
DEBUG 01-05 12:51:33.615836.615836 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.616416.616416 cuda_h.py:19] end restore_tensors2 cost 0.0008523464202880859 seconds
DEBUG 01-05 12:51:33.616936.616936 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005984783172607422 seconds
DEBUG 01-05 12:51:33.621004.621004 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011037826538085938 seconds
DEBUG 01-05 12:51:33.622689.622689 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.622720.622720 lmp.py:423] 
DEBUG 01-05 12:51:33.622720.622720 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.622624.622624 cuda_h.py:19] end cpu_experts_submit cost 0.0001800060272216797 seconds
DEBUG 01-05 12:51:33.622209.622209 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.628005.628005 mlpmodule.py:704] group tensors cost 0.005845069885253906 s
DEBUG 01-05 12:51:33.631097.631097 mlpmodule.py:742] pad cost 0.0019235610961914062 s
DEBUG 01-05 12:51:33.631584.631584 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-05 12:51:33.631527.631527 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-05 12:51:33.641737.641737 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.641458.641458 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.641217.641217 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 12:51:33.641903.641903 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.658768.658768 mlpmodule.py:793] group einsum cost 0.026712656021118164 s
DEBUG 01-05 12:51:33.658766.658766 mlpmodule.py:801] cpy2cputensor cost 0.000713348388671875 s
DEBUG 01-05 12:51:33.663433.663433 cuda_h.py:19] end wait_cetm_experts cost 0.041013240814208984 seconds
DEBUG 01-05 12:51:33.663803.663803 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.664499.664499 cuda_h.py:19] end gpu_sexperts cost 0.0005784034729003906 seconds
DEBUG 01-05 12:51:33.664196.664196 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.664006.664006 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 12:51:33.664180.664180 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.664367.664367 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8cfffd0c-6196-4c5c-b56e-4823516b276c
INFO 01-05 12:51:33.666303.666303 client.py:127] Model loaded
DEBUG 01-05 12:51:33.666007.666007 cuda_h.py:19] end wait_experts cost 0.0017011165618896484 seconds
DEBUG 01-05 12:51:33.666379.666379 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.666135.666135 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.666159.666159 mlpmodule.py:531] gpu group tensors cost 0.0006325244903564453 s
DEBUG 01-05 12:51:33.668087.668087 mlpmodule.py:564] gpu pad cost 0.0017490386962890625 s
DEBUG 01-05 12:51:33.669260.669260 mlpmodule.py:582] gpu group einsum cost 0.0005521774291992188 s
DEBUG 01-05 12:51:33.672729.672729 mlpmodule.py:611] gpu experts func einsum cost 0.006600379943847656 s
DEBUG 01-05 12:51:33.673693.673693 cuda_h.py:19] end gpu_experts cost 0.0068035125732421875 seconds
DEBUG 01-05 12:51:33.673431.673431 cuda_h.py:19] end layer_moe_generate_13 cost 0.06512022018432617 seconds
DEBUG 01-05 12:51:33.673366.673366 lmp.py:217] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 12:51:33.673275.673275 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 12:51:33.673547.673547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 12:51:33.673310.673310 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 12:51:33.673081.673081 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.62396240234375e-05 seconds
DEBUG 01-05 12:51:33.673023.673023 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.673760.673760 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.0001609325408935547 seconds
DEBUG 01-05 12:51:33.673637.673637 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.673990.673990 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.673323.673323 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.680180.680180 cuda_h.py:19] end allocate_cuda_memory cost 0.00612330436706543 seconds
DEBUG 01-05 12:51:33.680555.680555 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.680033.680033 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.680001.680001 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.680227.680227 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ac157c68-c1fa-481f-ae5e-57213543fc8a
DEBUG 01-05 12:51:33.680581.680581 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.680168.680168 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.681751.681751 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ac157c68-c1fa-481f-ae5e-57213543fc8a
DEBUG 01-05 12:51:33.681164.681164 cuda_h.py:19] end load_into_gpu_async cost 0.0015363693237304688 seconds
DEBUG 01-05 12:51:33.681767.681767 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.681419.681419 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-05 12:51:33.681268.681268 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008059978485107422 seconds
INFO 01-05 12:51:33.682966.682966 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ac157c68-c1fa-481f-ae5e-57213543fc8a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.684833.684833 cuda_h.py:19] end self_attn cost 0.0033731460571289062 seconds
DEBUG 01-05 12:51:33.684585.684585 cuda_h.py:19] end iln_self_attn_paln cost 0.010536432266235352 seconds
DEBUG 01-05 12:51:33.684329.684329 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 12:51:33.684615.684615 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.685358.685358 cuda_h.py:19] end gate cost 0.0006210803985595703 seconds
DEBUG 01-05 12:51:33.685042.685042 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.685343.685343 lmp.py:365] 
DEBUG 01-05 12:51:33.685343.685343 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.685192.685192 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.685842.685842 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.685677.685677 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.685366.685366 lmp.py:369] 
DEBUG 01-05 12:51:33.685366.685366 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.685294.685294 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.685228.685228 lmp.py:376]   Expert 61 |     10 | CPU
DEBUG 01-05 12:51:33.685394.685394 lmp.py:376]   Expert  7 |     17 | CPU
DEBUG 01-05 12:51:33.685084.685084 lmp.py:376]   Expert 59 |     36 | CPU
DEBUG 01-05 12:51:33.685727.685727 lmp.py:376]   Expert 48 |     59 | CPU
DEBUG 01-05 12:51:33.685416.685416 lmp.py:376]   Expert 34 |     60 | CPU
DEBUG 01-05 12:51:33.685105.685105 lmp.py:376]   Expert 50 |     61 | CPU
DEBUG 01-05 12:51:33.685318.685318 lmp.py:376]   Expert 38 |     67 | CPU
DEBUG 01-05 12:51:33.685769.685769 lmp.py:376]   Expert 49 |     67 | CPU
DEBUG 01-05 12:51:33.685220.685220 lmp.py:376]   Expert 40 |     70 | CPU
DEBUG 01-05 12:51:33.685863.685863 lmp.py:376]   Expert 55 |     71 | CPU
DEBUG 01-05 12:51:33.685320.685320 lmp.py:376]   Expert 32 |     72 | CPU
DEBUG 01-05 12:51:33.685202.685202 lmp.py:376]   Expert  0 |     97 | CPU
DEBUG 01-05 12:51:33.685129.685129 lmp.py:376]   Expert 43 |     97 | CPU
DEBUG 01-05 12:51:33.685819.685819 lmp.py:376]   Expert 44 |    100 | CPU
DEBUG 01-05 12:51:33.685508.685508 lmp.py:376]   Expert 35 |    102 | CPU
DEBUG 01-05 12:51:33.685482.685482 lmp.py:376]   Expert 18 |    105 | CPU
DEBUG 01-05 12:51:33.685694.685694 lmp.py:376]   Expert 60 |    109 | CPU
DEBUG 01-05 12:51:33.685907.685907 lmp.py:376]   Expert 23 |    112 | CPU
DEBUG 01-05 12:51:33.685881.685881 lmp.py:376]   Expert 29 |    112 | CPU
DEBUG 01-05 12:51:33.685332.685332 lmp.py:376]   Expert  8 |    113 | CPU
DEBUG 01-05 12:51:33.685783.685783 lmp.py:376]   Expert 20 |    117 | CPU
DEBUG 01-05 12:51:33.685995.685995 lmp.py:376]   Expert 39 |    117 | CPU
DEBUG 01-05 12:51:33.686684.686684 lmp.py:376]   Expert 51 |    119 | CPU
DEBUG 01-05 12:51:33.686612.686612 lmp.py:376]   Expert 28 |    122 | CPU
DEBUG 01-05 12:51:33.686302.686302 lmp.py:376]   Expert 41 |    129 | CPU
DEBUG 01-05 12:51:33.686514.686514 lmp.py:376]   Expert 17 |    130 | CPU
DEBUG 01-05 12:51:33.686203.686203 lmp.py:376]   Expert 21 |    141 | CPU
DEBUG 01-05 12:51:33.686131.686131 lmp.py:376]   Expert 54 |    142 | CPU
DEBUG 01-05 12:51:33.686343.686343 lmp.py:376]   Expert 12 |    150 | CPU
DEBUG 01-05 12:51:33.686318.686318 lmp.py:376]   Expert 45 |    170 | CPU
DEBUG 01-05 12:51:33.686530.686530 lmp.py:376]   Expert 42 |    176 | CPU
DEBUG 01-05 12:51:33.686742.686742 lmp.py:376]   Expert 57 |    178 | CPU
DEBUG 01-05 12:51:33.686955.686955 lmp.py:376]   Expert 52 |    179 | GPU
DEBUG 01-05 12:51:33.686406.686406 lmp.py:376]   Expert  6 |    199 | GPU
DEBUG 01-05 12:51:33.686618.686618 lmp.py:376]   Expert 62 |    200 | GPU
DEBUG 01-05 12:51:33.686308.686308 lmp.py:376]   Expert 31 |    201 | GPU
DEBUG 01-05 12:51:33.686997.686997 lmp.py:376]   Expert 13 |    209 | GPU
DEBUG 01-05 12:51:33.686686.686686 lmp.py:376]   Expert  3 |    215 | GPU
DEBUG 01-05 12:51:33.686852.686852 lmp.py:376]   Expert 11 |    222 | GPU
DEBUG 01-05 12:51:33.686780.686780 lmp.py:376]   Expert 30 |    222 | GPU
DEBUG 01-05 12:51:33.686231.686231 lmp.py:376]   Expert 14 |    228 | GPU
DEBUG 01-05 12:51:33.686205.686205 lmp.py:376]   Expert 26 |    228 | GPU
DEBUG 01-05 12:51:33.686656.686656 lmp.py:376]   Expert 46 |    230 | GPU
DEBUG 01-05 12:51:33.686107.686107 lmp.py:376]   Expert 36 |    232 | GPU
DEBUG 01-05 12:51:33.686558.686558 lmp.py:376]   Expert 19 |    234 | GPU
DEBUG 01-05 12:51:33.686770.686770 lmp.py:376]   Expert 27 |    246 | GPU
DEBUG 01-05 12:51:33.686744.686744 lmp.py:376]   Expert 22 |    266 | GPU
DEBUG 01-05 12:51:33.686957.686957 lmp.py:376]   Expert  2 |    273 | GPU
DEBUG 01-05 12:51:33.686407.686407 lmp.py:376]   Expert  4 |    275 | GPU
DEBUG 01-05 12:51:33.686620.686620 lmp.py:376]   Expert  5 |    289 | GPU
DEBUG 01-05 12:51:33.686548.686548 lmp.py:376]   Expert 37 |    294 | GPU
DEBUG 01-05 12:51:33.686237.686237 lmp.py:376]   Expert 33 |    298 | GPU
DEBUG 01-05 12:51:33.686688.686688 lmp.py:376]   Expert  1 |    301 | GPU
DEBUG 01-05 12:51:33.686616.686616 lmp.py:376]   Expert 58 |    303 | GPU
DEBUG 01-05 12:51:33.686305.686305 lmp.py:376]   Expert 56 |    304 | GPU
DEBUG 01-05 12:51:33.686994.686994 lmp.py:376]   Expert 53 |    308 | GPU
DEBUG 01-05 12:51:33.686683.686683 lmp.py:376]   Expert 16 |    317 | GPU
DEBUG 01-05 12:51:33.686657.686657 lmp.py:376]   Expert 10 |    328 | GPU
DEBUG 01-05 12:51:33.686870.686870 lmp.py:376]   Expert 63 |    357 | GPU
DEBUG 01-05 12:51:33.686559.686559 lmp.py:376]   Expert 47 |    370 | GPU
DEBUG 01-05 12:51:33.686295.686295 lmp.py:376]   Expert 24 |    382 | GPU
DEBUG 01-05 12:51:33.686507.686507 lmp.py:376]   Expert 15 |    386 | GPU
DEBUG 01-05 12:51:33.686720.686720 lmp.py:376]   Expert 25 |    473 | GPU
DEBUG 01-05 12:51:33.686694.686694 lmp.py:376]   Expert  9 |    491 | GPU
DEBUG 01-05 12:51:33.686098.686098 lmp.py:377] 
DEBUG 01-05 12:51:33.686098.686098 lmp.py:377]   CPU total tokens: 3228 (26.3%)
DEBUG 01-05 12:51:33.686741.686741 lmp.py:378]   GPU total tokens: 9060 (73.7%)
DEBUG 01-05 12:51:33.686676.686676 cuda_h.py:19] end experts_map_get cost 0.0014929771423339844 seconds
DEBUG 01-05 12:51:33.686319.686319 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.686433.686433 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.686438.686438 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.688774.688774 cuda_h.py:19] end allocate_cuda_memory cost 0.0018999576568603516 seconds
DEBUG 01-05 12:51:33.688240.688240 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.688426.688426 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.689957.689957 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.689535.689535 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54d2053b-43bd-49e9-881e-bdcf6f95547a
DEBUG 01-05 12:51:33.689475.689475 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.689626.689626 mlpmodule.py:662]  experts func einsum cost 0.06677103042602539 s
INFO 01-05 12:51:33.689885.689885 client.py:127] Model loaded
DEBUG 01-05 12:51:33.689453.689453 cuda_h.py:19] end sllm_worker_task cost 0.016052961349487305 seconds
INFO 01-05 12:51:33.691643.691643 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54d2053b-43bd-49e9-881e-bdcf6f95547a
DEBUG 01-05 12:51:33.691109.691109 cuda_h.py:19] end load_into_gpu_async cost 0.002187013626098633 seconds
DEBUG 01-05 12:51:33.691858.691858 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.691230.691230 cuda_h.py:19] end restore_tensors2 cost 0.00038933753967285156 seconds
DEBUG 01-05 12:51:33.691589.691589 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004832029342651367 seconds
DEBUG 01-05 12:51:33.694610.694610 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007490873336791992 seconds
DEBUG 01-05 12:51:33.694632.694632 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.694807.694807 lmp.py:423] 
DEBUG 01-05 12:51:33.694807.694807 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.694511.694511 cuda_h.py:19] end cpu_experts_submit cost 0.00011372566223144531 seconds
DEBUG 01-05 12:51:33.694161.694161 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.701131.701131 mlpmodule.py:704] group tensors cost 0.0065174102783203125 s
DEBUG 01-05 12:51:33.703283.703283 mlpmodule.py:742] pad cost 0.0014941692352294922 s
DEBUG 01-05 12:51:33.703909.703909 mlpmodule.py:748] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-05 12:51:33.703851.703851 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-05 12:51:33.713361.713361 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.713705.713705 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.713827.713827 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 12:51:33.713865.713865 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.728573.728573 mlpmodule.py:793] group einsum cost 0.0252382755279541 s
DEBUG 01-05 12:51:33.729398.729398 mlpmodule.py:801] cpy2cputensor cost 0.0006787776947021484 s
DEBUG 01-05 12:51:33.734648.734648 cuda_h.py:19] end wait_cetm_experts cost 0.03979015350341797 seconds
DEBUG 01-05 12:51:33.734442.734442 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.735416.735416 cuda_h.py:19] end gpu_sexperts cost 0.0005707740783691406 seconds
DEBUG 01-05 12:51:33.735405.735405 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.735215.735215 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-05 12:51:33.735355.735355 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.735972.735972 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54d2053b-43bd-49e9-881e-bdcf6f95547a
INFO 01-05 12:51:33.741526.741526 client.py:127] Model loaded
DEBUG 01-05 12:51:33.741191.741191 cuda_h.py:19] end wait_experts cost 0.0061299800872802734 seconds
DEBUG 01-05 12:51:33.741947.741947 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.741226.741226 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.742071.742071 mlpmodule.py:531] gpu group tensors cost 0.0006430149078369141 s
DEBUG 01-05 12:51:33.744232.744232 mlpmodule.py:564] gpu pad cost 0.0017817020416259766 s
DEBUG 01-05 12:51:33.744538.744538 mlpmodule.py:582] gpu group einsum cost 0.0005252361297607422 s
DEBUG 01-05 12:51:33.747279.747279 mlpmodule.py:611] gpu experts func einsum cost 0.00606226921081543 s
DEBUG 01-05 12:51:33.747462.747462 cuda_h.py:19] end gpu_experts cost 0.006249427795410156 seconds
DEBUG 01-05 12:51:33.747908.747908 cuda_h.py:19] end layer_moe_generate_14 cost 0.06335258483886719 seconds
DEBUG 01-05 12:51:33.748206.748206 lmp.py:217] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 12:51:33.748346.748346 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 12:51:33.748134.748134 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 12:51:33.748414.748414 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 12:51:33.748819.748819 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.8848648071289062e-05 seconds
DEBUG 01-05 12:51:33.748635.748635 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.319450378417969e-05 seconds
DEBUG 01-05 12:51:33.748278.748278 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.748737.748737 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.748848.748848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.748592.748592 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.750718.750718 cuda_h.py:19] end allocate_cuda_memory cost 0.0015463829040527344 seconds
DEBUG 01-05 12:51:33.750829.750829 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.750208.750208 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.750276.750276 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.750740.750740 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43b67d9d-e367-4fd2-a70d-b100be9442e6
DEBUG 01-05 12:51:33.750141.750141 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.750239.750239 mlpmodule.py:662]  experts func einsum cost 0.05586743354797363 s
DEBUG 01-05 12:51:33.750025.750025 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.751126.751126 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43b67d9d-e367-4fd2-a70d-b100be9442e6
DEBUG 01-05 12:51:33.751254.751254 cuda_h.py:19] end load_into_gpu_async cost 0.0015769004821777344 seconds
DEBUG 01-05 12:51:33.751242.751242 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.751225.751225 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-05 12:51:33.752551.752551 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003536224365234375 seconds
INFO 01-05 12:51:33.752588.752588 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43b67d9d-e367-4fd2-a70d-b100be9442e6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.754231.754231 cuda_h.py:19] end self_attn cost 0.003284931182861328 seconds
DEBUG 01-05 12:51:33.754301.754301 cuda_h.py:19] end iln_self_attn_paln cost 0.006299018859863281 seconds
DEBUG 01-05 12:51:33.754329.754329 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 12:51:33.754377.754377 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.755882.755882 cuda_h.py:19] end gate cost 0.0006210803985595703 seconds
DEBUG 01-05 12:51:33.755327.755327 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.755960.755960 lmp.py:365] 
DEBUG 01-05 12:51:33.755960.755960 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.755000.755000 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.755604.755604 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.755916.755916 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.755082.755082 lmp.py:369] 
DEBUG 01-05 12:51:33.755082.755082 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.755963.755963 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.755328.755328 lmp.py:376]   Expert 63 |     15 | CPU
DEBUG 01-05 12:51:33.755971.755971 lmp.py:376]   Expert 34 |     49 | CPU
DEBUG 01-05 12:51:33.755422.755422 lmp.py:376]   Expert 37 |     58 | CPU
DEBUG 01-05 12:51:33.755019.755019 lmp.py:376]   Expert 42 |     61 | CPU
DEBUG 01-05 12:51:33.755662.755662 lmp.py:376]   Expert  4 |     62 | CPU
DEBUG 01-05 12:51:33.755828.755828 lmp.py:376]   Expert 48 |     67 | CPU
DEBUG 01-05 12:51:33.755232.755232 lmp.py:376]   Expert 28 |     74 | CPU
DEBUG 01-05 12:51:33.755398.755398 lmp.py:376]   Expert 22 |     78 | CPU
DEBUG 01-05 12:51:33.755803.755803 lmp.py:376]   Expert 51 |     80 | CPU
DEBUG 01-05 12:51:33.756446.756446 lmp.py:376]   Expert 57 |     80 | CPU
DEBUG 01-05 12:51:33.756089.756089 lmp.py:376]   Expert 15 |     81 | CPU
DEBUG 01-05 12:51:33.756732.756732 lmp.py:376]   Expert 53 |     82 | CPU
DEBUG 01-05 12:51:33.756660.756660 lmp.py:376]   Expert 40 |     86 | CPU
DEBUG 01-05 12:51:33.756349.756349 lmp.py:376]   Expert  5 |     95 | CPU
DEBUG 01-05 12:51:33.756800.756800 lmp.py:376]   Expert 41 |     98 | CPU
DEBUG 01-05 12:51:33.756489.756489 lmp.py:376]   Expert 43 |    101 | CPU
DEBUG 01-05 12:51:33.756178.756178 lmp.py:376]   Expert  6 |    113 | CPU
DEBUG 01-05 12:51:33.756629.756629 lmp.py:376]   Expert  7 |    122 | CPU
DEBUG 01-05 12:51:33.756842.756842 lmp.py:376]   Expert 55 |    126 | CPU
DEBUG 01-05 12:51:33.756293.756293 lmp.py:376]   Expert 29 |    136 | CPU
DEBUG 01-05 12:51:33.756982.756982 lmp.py:376]   Expert 32 |    136 | CPU
DEBUG 01-05 12:51:33.756148.756148 lmp.py:376]   Expert 56 |    138 | CPU
DEBUG 01-05 12:51:33.756314.756314 lmp.py:376]   Expert 52 |    145 | CPU
DEBUG 01-05 12:51:33.756242.756242 lmp.py:376]   Expert  2 |    149 | CPU
DEBUG 01-05 12:51:33.756408.756408 lmp.py:376]   Expert 44 |    150 | CPU
DEBUG 01-05 12:51:33.756859.756859 lmp.py:376]   Expert 14 |    155 | CPU
DEBUG 01-05 12:51:33.756071.756071 lmp.py:376]   Expert 25 |    156 | CPU
DEBUG 01-05 12:51:33.756761.756761 lmp.py:376]   Expert 61 |    164 | CPU
DEBUG 01-05 12:51:33.756212.756212 lmp.py:376]   Expert 12 |    177 | CPU
DEBUG 01-05 12:51:33.756424.756424 lmp.py:376]   Expert 54 |    181 | CPU
DEBUG 01-05 12:51:33.756875.756875 lmp.py:376]   Expert 33 |    182 | CPU
DEBUG 01-05 12:51:33.756161.756161 lmp.py:376]   Expert 50 |    186 | CPU
DEBUG 01-05 12:51:33.756089.756089 lmp.py:376]   Expert 35 |    195 | GPU
DEBUG 01-05 12:51:33.756255.756255 lmp.py:376]   Expert 62 |    197 | GPU
DEBUG 01-05 12:51:33.756335.756335 lmp.py:376]   Expert 39 |    202 | GPU
DEBUG 01-05 12:51:33.756740.756740 lmp.py:376]   Expert 11 |    213 | GPU
DEBUG 01-05 12:51:33.756906.756906 lmp.py:376]   Expert 31 |    214 | GPU
DEBUG 01-05 12:51:33.756833.756833 lmp.py:376]   Expert 58 |    215 | GPU
DEBUG 01-05 12:51:33.756523.756523 lmp.py:376]   Expert 45 |    220 | GPU
DEBUG 01-05 12:51:33.756735.756735 lmp.py:376]   Expert 20 |    221 | GPU
DEBUG 01-05 12:51:33.756186.756186 lmp.py:376]   Expert 59 |    224 | GPU
DEBUG 01-05 12:51:33.756637.756637 lmp.py:376]   Expert 47 |    226 | GPU
DEBUG 01-05 12:51:33.756326.756326 lmp.py:376]   Expert 10 |    227 | GPU
DEBUG 01-05 12:51:33.756539.756539 lmp.py:376]   Expert 23 |    231 | GPU
DEBUG 01-05 12:51:33.756990.756990 lmp.py:376]   Expert  1 |    239 | GPU
DEBUG 01-05 12:51:33.756441.756441 lmp.py:376]   Expert 13 |    239 | GPU
DEBUG 01-05 12:51:33.756653.756653 lmp.py:376]   Expert 24 |    250 | GPU
DEBUG 01-05 12:51:33.756342.756342 lmp.py:376]   Expert  0 |    251 | GPU
DEBUG 01-05 12:51:33.756270.756270 lmp.py:376]   Expert  9 |    253 | GPU
DEBUG 01-05 12:51:33.756721.756721 lmp.py:376]   Expert 36 |    257 | GPU
DEBUG 01-05 12:51:33.756649.756649 lmp.py:376]   Expert 38 |    262 | GPU
DEBUG 01-05 12:51:33.756292.756292 lmp.py:376]   Expert 18 |    265 | GPU
DEBUG 01-05 12:51:33.756219.756219 lmp.py:376]   Expert 16 |    270 | GPU
DEBUG 01-05 12:51:33.756624.756624 lmp.py:376]   Expert 46 |    286 | GPU
DEBUG 01-05 12:51:33.756790.756790 lmp.py:376]   Expert 60 |    297 | GPU
DEBUG 01-05 12:51:33.756956.756956 lmp.py:376]   Expert 49 |    310 | GPU
DEBUG 01-05 12:51:33.756169.756169 lmp.py:376]   Expert  3 |    313 | GPU
DEBUG 01-05 12:51:33.756620.756620 lmp.py:376]   Expert 19 |    316 | GPU
DEBUG 01-05 12:51:33.756070.756070 lmp.py:376]   Expert 30 |    318 | GPU
DEBUG 01-05 12:51:33.756283.756283 lmp.py:376]   Expert 26 |    344 | GPU
DEBUG 01-05 12:51:33.756972.756972 lmp.py:376]   Expert 21 |    347 | GPU
DEBUG 01-05 12:51:33.756661.756661 lmp.py:376]   Expert 27 |    350 | GPU
DEBUG 01-05 12:51:33.756874.756874 lmp.py:376]   Expert 17 |    380 | GPU
DEBUG 01-05 12:51:33.756086.756086 lmp.py:376]   Expert  8 |    573 | GPU
DEBUG 01-05 12:51:33.756491.756491 lmp.py:377] 
DEBUG 01-05 12:51:33.756491.756491 lmp.py:377]   CPU total tokens: 3583 (29.2%)
DEBUG 01-05 12:51:33.756895.756895 lmp.py:378]   GPU total tokens: 8705 (70.8%)
DEBUG 01-05 12:51:33.757499.757499 cuda_h.py:19] end experts_map_get cost 0.0015382766723632812 seconds
DEBUG 01-05 12:51:33.757334.757334 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.757210.757210 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.757254.757254 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.758378.758378 cuda_h.py:19] end allocate_cuda_memory cost 0.0016734600067138672 seconds
DEBUG 01-05 12:51:33.758982.758982 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.759546.759546 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.759832.759832 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.759628.759628 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5137c5e1-925e-4d45-be83-53d7932dba1c
DEBUG 01-05 12:51:33.759939.759939 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.759714.759714 client.py:127] Model loaded
DEBUG 01-05 12:51:33.759385.759385 cuda_h.py:19] end sllm_worker_task cost 0.011287450790405273 seconds
INFO 01-05 12:51:33.761547.761547 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5137c5e1-925e-4d45-be83-53d7932dba1c
DEBUG 01-05 12:51:33.761490.761490 cuda_h.py:19] end load_into_gpu_async cost 0.0022728443145751953 seconds
DEBUG 01-05 12:51:33.761670.761670 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.761259.761259 cuda_h.py:19] end restore_tensors2 cost 0.00037360191345214844 seconds
DEBUG 01-05 12:51:33.761996.761996 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00466465950012207 seconds
DEBUG 01-05 12:51:33.764293.764293 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007246255874633789 seconds
DEBUG 01-05 12:51:33.764884.764884 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.764589.764589 lmp.py:423] 
DEBUG 01-05 12:51:33.764589.764589 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.764578.764578 cuda_h.py:19] end cpu_experts_submit cost 0.00013399124145507812 seconds
DEBUG 01-05 12:51:33.764420.764420 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.781503.781503 mlpmodule.py:704] group tensors cost 0.016463279724121094 s
DEBUG 01-05 12:51:33.783932.783932 mlpmodule.py:742] pad cost 0.0018312931060791016 s
DEBUG 01-05 12:51:33.784604.784604 mlpmodule.py:748] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-05 12:51:33.784693.784693 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-05 12:51:33.794881.794881 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.794410.794410 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.794625.794625 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 12:51:33.794894.794894 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.810151.810151 mlpmodule.py:793] group einsum cost 0.026662588119506836 s
DEBUG 01-05 12:51:33.811440.811440 mlpmodule.py:801] cpy2cputensor cost 0.00070953369140625 s
DEBUG 01-05 12:51:33.816709.816709 cuda_h.py:19] end wait_cetm_experts cost 0.05168342590332031 seconds
DEBUG 01-05 12:51:33.816947.816947 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.817484.817484 cuda_h.py:19] end gpu_sexperts cost 0.0005638599395751953 seconds
DEBUG 01-05 12:51:33.817949.817949 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.817329.817329 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 12:51:33.817655.817655 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.817278.817278 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5137c5e1-925e-4d45-be83-53d7932dba1c
INFO 01-05 12:51:33.818216.818216 client.py:127] Model loaded
DEBUG 01-05 12:51:33.818158.818158 cuda_h.py:19] end wait_experts cost 0.0013532638549804688 seconds
DEBUG 01-05 12:51:33.818960.818960 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.818001.818001 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.819761.819761 mlpmodule.py:531] gpu group tensors cost 0.0006506443023681641 s
DEBUG 01-05 12:51:33.821784.821784 mlpmodule.py:564] gpu pad cost 0.001821279525756836 s
DEBUG 01-05 12:51:33.821197.821197 mlpmodule.py:582] gpu group einsum cost 0.0005626678466796875 s
DEBUG 01-05 12:51:33.825406.825406 mlpmodule.py:611] gpu experts func einsum cost 0.006673336029052734 s
DEBUG 01-05 12:51:33.825933.825933 cuda_h.py:19] end gpu_experts cost 0.006866931915283203 seconds
DEBUG 01-05 12:51:33.825956.825956 cuda_h.py:19] end layer_moe_generate_15 cost 0.07090210914611816 seconds
DEBUG 01-05 12:51:33.825500.825500 lmp.py:217] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 12:51:33.825223.825223 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 12:51:33.825734.825734 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 12:51:33.825258.825258 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 12:51:33.826870.826870 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.409385681152344e-05 seconds
DEBUG 01-05 12:51:33.826143.826143 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.826357.826357 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00014734268188476562 seconds
DEBUG 01-05 12:51:33.826565.826565 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.826348.826348 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.826397.826397 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.826272.826272 cuda_h.py:19] end allocate_cuda_memory cost 0.0005204677581787109 seconds
DEBUG 01-05 12:51:33.827512.827512 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.827752.827752 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.827721.827721 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.827662.827662 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be8e6d15-cd5b-4317-a0ff-88819f3ee1e9
DEBUG 01-05 12:51:33.827824.827824 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.827248.827248 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.828504.828504 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be8e6d15-cd5b-4317-a0ff-88819f3ee1e9
DEBUG 01-05 12:51:33.828924.828924 cuda_h.py:19] end load_into_gpu_async cost 0.0015628337860107422 seconds
DEBUG 01-05 12:51:33.828435.828435 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.828610.828610 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-05 12:51:33.828697.828697 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024569034576416016 seconds
INFO 01-05 12:51:33.829636.829636 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be8e6d15-cd5b-4317-a0ff-88819f3ee1e9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.831609.831609 cuda_h.py:19] end self_attn cost 0.0033864974975585938 seconds
DEBUG 01-05 12:51:33.831984.831984 cuda_h.py:19] end iln_self_attn_paln cost 0.005012035369873047 seconds
DEBUG 01-05 12:51:33.831588.831588 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 12:51:33.831020.831020 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.832877.832877 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-05 12:51:33.832845.832845 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.832551.832551 lmp.py:365] 
DEBUG 01-05 12:51:33.832551.832551 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.832453.832453 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.832149.832149 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.832461.832461 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.832872.832872 lmp.py:369] 
DEBUG 01-05 12:51:33.832872.832872 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.832376.832376 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.832410.832410 lmp.py:376]   Expert 58 |     19 | CPU
DEBUG 01-05 12:51:33.832530.832530 lmp.py:376]   Expert 43 |     64 | CPU
DEBUG 01-05 12:51:33.832650.832650 lmp.py:376]   Expert 14 |     66 | CPU
DEBUG 01-05 12:51:33.832578.832578 lmp.py:376]   Expert 13 |     80 | CPU
DEBUG 01-05 12:51:33.832459.832459 lmp.py:376]   Expert 54 |     87 | CPU
DEBUG 01-05 12:51:33.832387.832387 lmp.py:376]   Expert 11 |     89 | CPU
DEBUG 01-05 12:51:33.832791.832791 lmp.py:376]   Expert 45 |     91 | CPU
DEBUG 01-05 12:51:33.832719.832719 lmp.py:376]   Expert 59 |     98 | CPU
DEBUG 01-05 12:51:33.832123.832123 lmp.py:376]   Expert 39 |    101 | CPU
DEBUG 01-05 12:51:33.832574.832574 lmp.py:376]   Expert 60 |    104 | CPU
DEBUG 01-05 12:51:33.832217.832217 lmp.py:376]   Expert 18 |    115 | CPU
DEBUG 01-05 12:51:33.832145.832145 lmp.py:376]   Expert 57 |    115 | CPU
DEBUG 01-05 12:51:33.832265.832265 lmp.py:376]   Expert  6 |    116 | CPU
DEBUG 01-05 12:51:33.832431.832431 lmp.py:376]   Expert 28 |    119 | CPU
DEBUG 01-05 12:51:33.832789.832789 lmp.py:376]   Expert 61 |    120 | CPU
DEBUG 01-05 12:51:33.832479.832479 lmp.py:376]   Expert 34 |    121 | CPU
DEBUG 01-05 12:51:33.832645.832645 lmp.py:376]   Expert 25 |    129 | CPU
DEBUG 01-05 12:51:33.832096.832096 lmp.py:376]   Expert 49 |    132 | CPU
DEBUG 01-05 12:51:33.832454.832454 lmp.py:376]   Expert  0 |    136 | CPU
DEBUG 01-05 12:51:33.833143.833143 lmp.py:376]   Expert 50 |    137 | CPU
DEBUG 01-05 12:51:33.833548.833548 lmp.py:376]   Expert 62 |    138 | CPU
DEBUG 01-05 12:51:33.833760.833760 lmp.py:376]   Expert 51 |    139 | CPU
DEBUG 01-05 12:51:33.833688.833688 lmp.py:376]   Expert 32 |    140 | CPU
DEBUG 01-05 12:51:33.833139.833139 lmp.py:376]   Expert 41 |    142 | CPU
DEBUG 01-05 12:51:33.833543.833543 lmp.py:376]   Expert 35 |    143 | CPU
DEBUG 01-05 12:51:33.833233.833233 lmp.py:376]   Expert 30 |    146 | CPU
DEBUG 01-05 12:51:33.833352.833352 lmp.py:376]   Expert 38 |    154 | CPU
DEBUG 01-05 12:51:33.833280.833280 lmp.py:376]   Expert 15 |    159 | CPU
DEBUG 01-05 12:51:33.833161.833161 lmp.py:376]   Expert 12 |    160 | CPU
DEBUG 01-05 12:51:33.833566.833566 lmp.py:376]   Expert 37 |    168 | CPU
DEBUG 01-05 12:51:33.833209.833209 lmp.py:376]   Expert 31 |    170 | CPU
DEBUG 01-05 12:51:33.833660.833660 lmp.py:376]   Expert 26 |    176 | CPU
DEBUG 01-05 12:51:33.833303.833303 lmp.py:376]   Expert 48 |    184 | GPU
DEBUG 01-05 12:51:33.833231.833231 lmp.py:376]   Expert 42 |    185 | GPU
DEBUG 01-05 12:51:33.833112.833112 lmp.py:376]   Expert 63 |    189 | GPU
DEBUG 01-05 12:51:33.833040.833040 lmp.py:376]   Expert 56 |    192 | GPU
DEBUG 01-05 12:51:33.833683.833683 lmp.py:376]   Expert 10 |    196 | GPU
DEBUG 01-05 12:51:33.833372.833372 lmp.py:376]   Expert 44 |    197 | GPU
DEBUG 01-05 12:51:33.833492.833492 lmp.py:376]   Expert  3 |    201 | GPU
DEBUG 01-05 12:51:33.833658.833658 lmp.py:376]   Expert 40 |    205 | GPU
DEBUG 01-05 12:51:33.833778.833778 lmp.py:376]   Expert 55 |    209 | GPU
DEBUG 01-05 12:51:33.833705.833705 lmp.py:376]   Expert 21 |    213 | GPU
DEBUG 01-05 12:51:33.833348.833348 lmp.py:376]   Expert 33 |    225 | GPU
DEBUG 01-05 12:51:33.833799.833799 lmp.py:376]   Expert 16 |    227 | GPU
DEBUG 01-05 12:51:33.833204.833204 lmp.py:376]   Expert  1 |    228 | GPU
DEBUG 01-05 12:51:33.833416.833416 lmp.py:376]   Expert 47 |    232 | GPU
DEBUG 01-05 12:51:33.833059.833059 lmp.py:376]   Expert  9 |    235 | GPU
DEBUG 01-05 12:51:33.833510.833510 lmp.py:376]   Expert 19 |    244 | GPU
DEBUG 01-05 12:51:33.833392.833392 lmp.py:376]   Expert 36 |    247 | GPU
DEBUG 01-05 12:51:33.833604.833604 lmp.py:376]   Expert 46 |    252 | GPU
DEBUG 01-05 12:51:33.833009.833009 lmp.py:376]   Expert 24 |    256 | GPU
DEBUG 01-05 12:51:33.833413.833413 lmp.py:376]   Expert  2 |    257 | GPU
DEBUG 01-05 12:51:33.833010.833010 lmp.py:376]   Expert 20 |    263 | GPU
DEBUG 01-05 12:51:33.833414.833414 lmp.py:376]   Expert 22 |    273 | GPU
DEBUG 01-05 12:51:33.833296.833296 lmp.py:376]   Expert  8 |    279 | GPU
DEBUG 01-05 12:51:33.833985.833985 lmp.py:376]   Expert 53 |    279 | GPU
DEBUG 01-05 12:51:33.833628.833628 lmp.py:376]   Expert  7 |    285 | GPU
DEBUG 01-05 12:51:33.833079.833079 lmp.py:376]   Expert 29 |    302 | GPU
DEBUG 01-05 12:51:33.833483.833483 lmp.py:376]   Expert 23 |    343 | GPU
DEBUG 01-05 12:51:33.833934.833934 lmp.py:376]   Expert  4 |    347 | GPU
DEBUG 01-05 12:51:33.833577.833577 lmp.py:376]   Expert 17 |    370 | GPU
DEBUG 01-05 12:51:33.833267.833267 lmp.py:376]   Expert 27 |    423 | GPU
DEBUG 01-05 12:51:33.833671.833671 lmp.py:376]   Expert 52 |    435 | GPU
DEBUG 01-05 12:51:33.833884.833884 lmp.py:376]   Expert  5 |    441 | GPU
DEBUG 01-05 12:51:33.833957.833957 lmp.py:377] 
DEBUG 01-05 12:51:33.833957.833957 lmp.py:377]   CPU total tokens: 3874 (31.5%)
DEBUG 01-05 12:51:33.833077.833077 lmp.py:378]   GPU total tokens: 8414 (68.5%)
DEBUG 01-05 12:51:33.833157.833157 cuda_h.py:19] end experts_map_get cost 0.0015709400177001953 seconds
DEBUG 01-05 12:51:33.833754.833754 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.833775.833775 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.834634.834634 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.835535.835535 cuda_h.py:19] end allocate_cuda_memory cost 0.0017549991607666016 seconds
DEBUG 01-05 12:51:33.835737.835737 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.835361.835361 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.835653.835653 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.836018.836018 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 55867b72-71df-4d90-9891-097abe22927b
DEBUG 01-05 12:51:33.836051.836051 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.836118.836118 client.py:127] Model loaded
DEBUG 01-05 12:51:33.836577.836577 cuda_h.py:19] end sllm_worker_task cost 0.010445833206176758 seconds
DEBUG 01-05 12:51:33.840974.840974 mlpmodule.py:662]  experts func einsum cost 0.07584190368652344 s
INFO 01-05 12:51:33.840233.840233 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 55867b72-71df-4d90-9891-097abe22927b
DEBUG 01-05 12:51:33.841096.841096 cuda_h.py:19] end load_into_gpu_async cost 0.0051174163818359375 seconds
DEBUG 01-05 12:51:33.841794.841794 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.841279.841279 cuda_h.py:19] end restore_tensors2 cost 0.0005671977996826172 seconds
DEBUG 01-05 12:51:33.841010.841010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007976293563842773 seconds
DEBUG 01-05 12:51:33.846429.846429 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012401580810546875 seconds
DEBUG 01-05 12:51:33.846199.846199 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.846879.846879 lmp.py:423] 
DEBUG 01-05 12:51:33.846879.846879 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.846829.846829 cuda_h.py:19] end cpu_experts_submit cost 0.00016450881958007812 seconds
DEBUG 01-05 12:51:33.846038.846038 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.860589.860589 mlpmodule.py:704] group tensors cost 0.013824462890625 s
DEBUG 01-05 12:51:33.863153.863153 mlpmodule.py:742] pad cost 0.002245187759399414 s
DEBUG 01-05 12:51:33.863589.863589 mlpmodule.py:748] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-05 12:51:33.864996.864996 mlpmodule.py:753] move to cpu cost 3.933906555175781e-05 s
DEBUG 01-05 12:51:33.871612.871612 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.872227.872227 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.872489.872489 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 12:51:33.872598.872598 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.887889.887889 mlpmodule.py:793] group einsum cost 0.023634672164916992 s
DEBUG 01-05 12:51:33.888892.888892 mlpmodule.py:801] cpy2cputensor cost 0.0006732940673828125 s
DEBUG 01-05 12:51:33.893897.893897 cuda_h.py:19] end wait_cetm_experts cost 0.046323537826538086 seconds
DEBUG 01-05 12:51:33.893360.893360 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.893049.893049 cuda_h.py:19] end gpu_sexperts cost 0.0005700588226318359 seconds
DEBUG 01-05 12:51:33.893038.893038 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.894133.894133 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 12:51:33.894227.894227 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.894652.894652 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 55867b72-71df-4d90-9891-097abe22927b
INFO 01-05 12:51:33.895216.895216 client.py:127] Model loaded
DEBUG 01-05 12:51:33.895013.895013 cuda_h.py:19] end wait_experts cost 0.0012857913970947266 seconds
DEBUG 01-05 12:51:33.895623.895623 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.895664.895664 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.896350.896350 mlpmodule.py:531] gpu group tensors cost 0.0006310939788818359 s
DEBUG 01-05 12:51:33.898632.898632 mlpmodule.py:564] gpu pad cost 0.0018296241760253906 s
DEBUG 01-05 12:51:33.898971.898971 mlpmodule.py:582] gpu group einsum cost 0.0005440711975097656 s
DEBUG 01-05 12:51:33.902013.902013 mlpmodule.py:611] gpu experts func einsum cost 0.006772279739379883 s
DEBUG 01-05 12:51:33.902250.902250 cuda_h.py:19] end gpu_experts cost 0.0070323944091796875 seconds
DEBUG 01-05 12:51:33.902141.902141 cuda_h.py:19] end layer_moe_generate_16 cost 0.07105588912963867 seconds
DEBUG 01-05 12:51:33.902863.902863 lmp.py:217] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 12:51:33.902626.902626 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 12:51:33.902137.902137 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 12:51:33.902138.902138 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 12:51:33.902988.902988 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.457069396972656e-05 seconds
DEBUG 01-05 12:51:33.903653.903653 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.903357.903357 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.00016260147094726562 seconds
DEBUG 01-05 12:51:33.903062.903062 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.903124.903124 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.903922.903922 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.909338.909338 cuda_h.py:19] end allocate_cuda_memory cost 0.005551338195800781 seconds
DEBUG 01-05 12:51:33.909870.909870 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.909533.909533 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.909628.909628 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.909782.909782 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e586dda-0bda-4252-8768-493a0eeb0a23
DEBUG 01-05 12:51:33.909666.909666 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.909853.909853 mlpmodule.py:662]  experts func einsum cost 0.06268525123596191 s
DEBUG 01-05 12:51:33.909352.909352 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.910755.910755 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e586dda-0bda-4252-8768-493a0eeb0a23
DEBUG 01-05 12:51:33.910505.910505 cuda_h.py:19] end load_into_gpu_async cost 0.0017323493957519531 seconds
DEBUG 01-05 12:51:33.910062.910062 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.910807.910807 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-05 12:51:33.911133.911133 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007693767547607422 seconds
INFO 01-05 12:51:33.911309.911309 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e586dda-0bda-4252-8768-493a0eeb0a23
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.913229.913229 cuda_h.py:19] end self_attn cost 0.003946781158447266 seconds
DEBUG 01-05 12:51:33.914539.914539 cuda_h.py:19] end iln_self_attn_paln cost 0.010833978652954102 seconds
DEBUG 01-05 12:51:33.914190.914190 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 12:51:33.914337.914337 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.915365.915365 cuda_h.py:19] end gate cost 0.0007917881011962891 seconds
DEBUG 01-05 12:51:33.915195.915195 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.915157.915157 lmp.py:365] 
DEBUG 01-05 12:51:33.915157.915157 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.915675.915675 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.915993.915993 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.915974.915974 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.915094.915094 lmp.py:369] 
DEBUG 01-05 12:51:33.915094.915094 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.915929.915929 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.915009.915009 lmp.py:376]   Expert 39 |     45 | CPU
DEBUG 01-05 12:51:33.915845.915845 lmp.py:376]   Expert 28 |     58 | CPU
DEBUG 01-05 12:51:33.915964.915964 lmp.py:376]   Expert 14 |     64 | CPU
DEBUG 01-05 12:51:33.915607.915607 lmp.py:376]   Expert 36 |     69 | CPU
DEBUG 01-05 12:51:33.915250.915250 lmp.py:376]   Expert 47 |     70 | CPU
DEBUG 01-05 12:51:33.915277.915277 lmp.py:376]   Expert  1 |     80 | CPU
DEBUG 01-05 12:51:33.915305.915305 lmp.py:376]   Expert  7 |     87 | CPU
DEBUG 01-05 12:51:33.915378.915378 lmp.py:376]   Expert  8 |     88 | CPU
DEBUG 01-05 12:51:33.915452.915452 lmp.py:376]   Expert 40 |     89 | CPU
DEBUG 01-05 12:51:33.916287.916287 lmp.py:376]   Expert 52 |     92 | CPU
DEBUG 01-05 12:51:33.916645.916645 lmp.py:376]   Expert 27 |     93 | CPU
DEBUG 01-05 12:51:33.916242.916242 lmp.py:376]   Expert 25 |     96 | CPU
DEBUG 01-05 12:51:33.916600.916600 lmp.py:376]   Expert  3 |    109 | CPU
DEBUG 01-05 12:51:33.916720.916720 lmp.py:376]   Expert 54 |    112 | CPU
DEBUG 01-05 12:51:33.916601.916601 lmp.py:376]   Expert 31 |    118 | CPU
DEBUG 01-05 12:51:33.916959.916959 lmp.py:376]   Expert 60 |    130 | CPU
DEBUG 01-05 12:51:33.916079.916079 lmp.py:376]   Expert 30 |    131 | CPU
DEBUG 01-05 12:51:33.916199.916199 lmp.py:376]   Expert 24 |    137 | CPU
DEBUG 01-05 12:51:33.916795.916795 lmp.py:376]   Expert 46 |    137 | CPU
DEBUG 01-05 12:51:33.916869.916869 lmp.py:376]   Expert 63 |    143 | CPU
DEBUG 01-05 12:51:33.916466.916466 lmp.py:376]   Expert 50 |    144 | CPU
DEBUG 01-05 12:51:33.916301.916301 lmp.py:376]   Expert  6 |    146 | CPU
DEBUG 01-05 12:51:33.916420.916420 lmp.py:376]   Expert 61 |    146 | CPU
DEBUG 01-05 12:51:33.916302.916302 lmp.py:376]   Expert 59 |    149 | CPU
DEBUG 01-05 12:51:33.916183.916183 lmp.py:376]   Expert 56 |    154 | CPU
DEBUG 01-05 12:51:33.916303.916303 lmp.py:376]   Expert 58 |    155 | CPU
DEBUG 01-05 12:51:33.916423.916423 lmp.py:376]   Expert  2 |    156 | CPU
DEBUG 01-05 12:51:33.916066.916066 lmp.py:376]   Expert 16 |    160 | CPU
DEBUG 01-05 12:51:33.916186.916186 lmp.py:376]   Expert 49 |    165 | CPU
DEBUG 01-05 12:51:33.916305.916305 lmp.py:376]   Expert 53 |    167 | CPU
DEBUG 01-05 12:51:33.916962.916962 lmp.py:376]   Expert 34 |    175 | CPU
DEBUG 01-05 12:51:33.916843.916843 lmp.py:376]   Expert 11 |    182 | CPU
DEBUG 01-05 12:51:33.916679.916679 lmp.py:376]   Expert 15 |    184 | GPU
DEBUG 01-05 12:51:33.916275.916275 lmp.py:376]   Expert 18 |    186 | GPU
DEBUG 01-05 12:51:33.916633.916633 lmp.py:376]   Expert 43 |    189 | GPU
DEBUG 01-05 12:51:33.916230.916230 lmp.py:376]   Expert 10 |    190 | GPU
DEBUG 01-05 12:51:33.916350.916350 lmp.py:376]   Expert 37 |    193 | GPU
DEBUG 01-05 12:51:33.916470.916470 lmp.py:376]   Expert 33 |    199 | GPU
DEBUG 01-05 12:51:33.916589.916589 lmp.py:376]   Expert 29 |    202 | GPU
DEBUG 01-05 12:51:33.916232.916232 lmp.py:376]   Expert 21 |    205 | GPU
DEBUG 01-05 12:51:33.916829.916829 lmp.py:376]   Expert 32 |    219 | GPU
DEBUG 01-05 12:51:33.916710.916710 lmp.py:376]   Expert 20 |    223 | GPU
DEBUG 01-05 12:51:33.916069.916069 lmp.py:376]   Expert 13 |    232 | GPU
DEBUG 01-05 12:51:33.916857.916857 lmp.py:376]   Expert 44 |    233 | GPU
DEBUG 01-05 12:51:33.916454.916454 lmp.py:376]   Expert 57 |    233 | GPU
DEBUG 01-05 12:51:33.916766.916766 lmp.py:376]   Expert 42 |    240 | GPU
DEBUG 01-05 12:51:33.916601.916601 lmp.py:376]   Expert  0 |    241 | GPU
DEBUG 01-05 12:51:33.916482.916482 lmp.py:376]   Expert 35 |    243 | GPU
DEBUG 01-05 12:51:33.916318.916318 lmp.py:376]   Expert  9 |    252 | GPU
DEBUG 01-05 12:51:33.916437.916437 lmp.py:376]   Expert 51 |    258 | GPU
DEBUG 01-05 12:51:33.916319.916319 lmp.py:376]   Expert  5 |    266 | GPU
DEBUG 01-05 12:51:33.916200.916200 lmp.py:376]   Expert 22 |    273 | GPU
DEBUG 01-05 12:51:33.916558.916558 lmp.py:376]   Expert 19 |    278 | GPU
DEBUG 01-05 12:51:33.916440.916440 lmp.py:376]   Expert 38 |    284 | GPU
DEBUG 01-05 12:51:33.916560.916560 lmp.py:376]   Expert 23 |    285 | GPU
DEBUG 01-05 12:51:33.916441.916441 lmp.py:376]   Expert 62 |    304 | GPU
DEBUG 01-05 12:51:33.916561.916561 lmp.py:376]   Expert 48 |    307 | GPU
DEBUG 01-05 12:51:33.916111.916111 lmp.py:376]   Expert 12 |    308 | GPU
DEBUG 01-05 12:51:33.916708.916708 lmp.py:376]   Expert  4 |    316 | GPU
DEBUG 01-05 12:51:33.916543.916543 lmp.py:376]   Expert 45 |    337 | GPU
DEBUG 01-05 12:51:33.916477.916477 lmp.py:376]   Expert 26 |    348 | GPU
DEBUG 01-05 12:51:33.916227.916227 lmp.py:376]   Expert 41 |    364 | GPU
DEBUG 01-05 12:51:33.917168.917168 lmp.py:376]   Expert 55 |    381 | GPU
DEBUG 01-05 12:51:33.917322.917322 lmp.py:376]   Expert 17 |    468 | GPU
DEBUG 01-05 12:51:33.917700.917700 lmp.py:377] 
DEBUG 01-05 12:51:33.917700.917700 lmp.py:377]   CPU total tokens: 3847 (31.3%)
DEBUG 01-05 12:51:33.917648.917648 lmp.py:378]   GPU total tokens: 8441 (68.7%)
DEBUG 01-05 12:51:33.917034.917034 cuda_h.py:19] end experts_map_get cost 0.0018842220306396484 seconds
DEBUG 01-05 12:51:33.917743.917743 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.917051.917051 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.917933.917933 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.918091.918091 cuda_h.py:19] end allocate_cuda_memory cost 0.0004978179931640625 seconds
DEBUG 01-05 12:51:33.918617.918617 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.918710.918710 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.918096.918096 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.918845.918845 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8efc9722-74df-4b36-9a6f-5854f9b1e280
DEBUG 01-05 12:51:33.918779.918779 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:33.918725.918725 client.py:127] Model loaded
DEBUG 01-05 12:51:33.918999.918999 cuda_h.py:19] end sllm_worker_task cost 0.01572895050048828 seconds
INFO 01-05 12:51:33.920916.920916 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8efc9722-74df-4b36-9a6f-5854f9b1e280
DEBUG 01-05 12:51:33.920058.920058 cuda_h.py:19] end load_into_gpu_async cost 0.002256155014038086 seconds
DEBUG 01-05 12:51:33.920668.920668 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.920179.920179 cuda_h.py:19] end restore_tensors2 cost 0.00041794776916503906 seconds
DEBUG 01-05 12:51:33.920016.920016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036504268646240234 seconds
DEBUG 01-05 12:51:33.924960.924960 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006826639175415039 seconds
DEBUG 01-05 12:51:33.924127.924127 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:33.924217.924217 lmp.py:423] 
DEBUG 01-05 12:51:33.924217.924217 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:33.924398.924398 cuda_h.py:19] end cpu_experts_submit cost 0.00011849403381347656 seconds
DEBUG 01-05 12:51:33.924193.924193 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:33.940092.940092 mlpmodule.py:704] group tensors cost 0.01625537872314453 s
DEBUG 01-05 12:51:33.943601.943601 mlpmodule.py:742] pad cost 0.0020241737365722656 s
DEBUG 01-05 12:51:33.943791.943791 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 12:51:33.943522.943522 mlpmodule.py:753] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-05 12:51:33.954354.954354 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:33.954705.954705 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:33.954297.954297 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 12:51:33.954652.954652 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:33.970036.970036 mlpmodule.py:793] group einsum cost 0.02672863006591797 s
DEBUG 01-05 12:51:33.971298.971298 mlpmodule.py:801] cpy2cputensor cost 0.0006873607635498047 s
DEBUG 01-05 12:51:33.976757.976757 cuda_h.py:19] end wait_cetm_experts cost 0.05177950859069824 seconds
DEBUG 01-05 12:51:33.976127.976127 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:33.976096.976096 cuda_h.py:19] end gpu_sexperts cost 0.0006020069122314453 seconds
DEBUG 01-05 12:51:33.977561.977561 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:33.977994.977994 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.314018249511719e-05 seconds
DEBUG 01-05 12:51:33.977035.977035 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:33.977745.977745 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8efc9722-74df-4b36-9a6f-5854f9b1e280
INFO 01-05 12:51:33.978091.978091 client.py:127] Model loaded
DEBUG 01-05 12:51:33.978080.978080 cuda_h.py:19] end wait_experts cost 0.0013012886047363281 seconds
DEBUG 01-05 12:51:33.978544.978544 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:33.978393.978393 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:33.979669.979669 mlpmodule.py:531] gpu group tensors cost 0.0006468296051025391 s
DEBUG 01-05 12:51:33.981167.981167 mlpmodule.py:564] gpu pad cost 0.0017478466033935547 s
DEBUG 01-05 12:51:33.981669.981669 mlpmodule.py:582] gpu group einsum cost 0.0005095005035400391 s
DEBUG 01-05 12:51:33.985150.985150 mlpmodule.py:611] gpu experts func einsum cost 0.006513833999633789 s
DEBUG 01-05 12:51:33.985571.985571 cuda_h.py:19] end gpu_experts cost 0.006697177886962891 seconds
DEBUG 01-05 12:51:33.985878.985878 cuda_h.py:19] end layer_moe_generate_17 cost 0.07094478607177734 seconds
DEBUG 01-05 12:51:33.985084.985084 lmp.py:217] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 12:51:33.985755.985755 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 12:51:33.985027.985027 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 12:51:33.985836.985836 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 12:51:33.985163.985163 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.647804260253906e-05 seconds
DEBUG 01-05 12:51:33.985111.985111 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.104873657226562e-05 seconds
DEBUG 01-05 12:51:33.985714.985714 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:33.985512.985512 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:33.985442.985442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.985557.985557 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.986057.986057 cuda_h.py:19] end allocate_cuda_memory cost 0.0004730224609375 seconds
DEBUG 01-05 12:51:33.986675.986675 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.986292.986292 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.986638.986638 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.986818.986818 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2fff5697-4f59-4a5f-bca2-9178e9026397
DEBUG 01-05 12:51:33.986741.986741 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:33.987500.987500 cuda_h.py:10] start self_attn
INFO 01-05 12:51:33.988283.988283 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2fff5697-4f59-4a5f-bca2-9178e9026397
DEBUG 01-05 12:51:33.988888.988888 cuda_h.py:19] end load_into_gpu_async cost 0.0015592575073242188 seconds
DEBUG 01-05 12:51:33.988299.988299 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:33.988713.988713 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 12:51:33.988939.988939 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002339601516723633 seconds
INFO 01-05 12:51:33.988836.988836 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2fff5697-4f59-4a5f-bca2-9178e9026397
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:33.990464.990464 cuda_h.py:19] end self_attn cost 0.0032112598419189453 seconds
DEBUG 01-05 12:51:33.990004.990004 cuda_h.py:19] end iln_self_attn_paln cost 0.004851818084716797 seconds
DEBUG 01-05 12:51:33.990886.990886 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 12:51:33.990742.990742 cuda_h.py:10] start gate
DEBUG 01-05 12:51:33.991386.991386 cuda_h.py:19] end gate cost 0.0006194114685058594 seconds
DEBUG 01-05 12:51:33.991593.991593 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:33.991357.991357 lmp.py:365] 
DEBUG 01-05 12:51:33.991357.991357 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:33.991299.991299 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:33.991564.991564 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:33.991207.991207 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:33.991943.991943 lmp.py:369] 
DEBUG 01-05 12:51:33.991943.991943 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:33.991678.991678 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:33.991421.991421 lmp.py:376]   Expert 35 |     52 | CPU
DEBUG 01-05 12:51:33.991918.991918 lmp.py:376]   Expert  0 |     58 | CPU
DEBUG 01-05 12:51:33.991276.991276 lmp.py:376]   Expert  3 |     63 | CPU
DEBUG 01-05 12:51:33.991681.991681 lmp.py:376]   Expert 53 |     66 | CPU
DEBUG 01-05 12:51:33.991463.991463 lmp.py:376]   Expert 19 |     68 | CPU
DEBUG 01-05 12:51:33.991245.991245 lmp.py:376]   Expert 58 |     69 | CPU
DEBUG 01-05 12:51:33.991027.991027 lmp.py:376]   Expert 54 |     71 | CPU
DEBUG 01-05 12:51:33.991285.991285 lmp.py:376]   Expert 12 |     79 | CPU
DEBUG 01-05 12:51:33.991067.991067 lmp.py:376]   Expert  6 |     80 | CPU
DEBUG 01-05 12:51:33.991902.991902 lmp.py:376]   Expert 41 |     89 | CPU
DEBUG 01-05 12:51:33.991022.991022 lmp.py:376]   Expert 20 |     90 | CPU
DEBUG 01-05 12:51:33.991188.991188 lmp.py:376]   Expert 34 |     90 | CPU
DEBUG 01-05 12:51:33.992354.992354 lmp.py:376]   Expert 37 |     94 | CPU
DEBUG 01-05 12:51:33.992044.992044 lmp.py:376]   Expert 60 |     97 | CPU
DEBUG 01-05 12:51:33.992687.992687 lmp.py:376]   Expert 40 |     99 | CPU
DEBUG 01-05 12:51:33.992614.992614 lmp.py:376]   Expert 63 |    104 | CPU
DEBUG 01-05 12:51:33.992781.992781 lmp.py:376]   Expert  8 |    115 | CPU
DEBUG 01-05 12:51:33.992185.992185 lmp.py:376]   Expert 43 |    116 | CPU
DEBUG 01-05 12:51:33.992351.992351 lmp.py:376]   Expert 48 |    119 | CPU
DEBUG 01-05 12:51:33.992564.992564 lmp.py:376]   Expert 30 |    121 | CPU
DEBUG 01-05 12:51:33.992253.992253 lmp.py:376]   Expert 46 |    124 | CPU
DEBUG 01-05 12:51:33.992989.992989 lmp.py:376]   Expert 13 |    125 | CPU
DEBUG 01-05 12:51:33.992678.992678 lmp.py:376]   Expert 32 |    126 | CPU
DEBUG 01-05 12:51:33.992414.992414 lmp.py:376]   Expert 45 |    128 | CPU
DEBUG 01-05 12:51:33.992341.992341 lmp.py:376]   Expert 44 |    130 | CPU
DEBUG 01-05 12:51:33.992554.992554 lmp.py:376]   Expert 33 |    134 | CPU
DEBUG 01-05 12:51:33.992482.992482 lmp.py:376]   Expert 17 |    137 | CPU
DEBUG 01-05 12:51:33.992979.992979 lmp.py:376]   Expert 29 |    142 | CPU
DEBUG 01-05 12:51:33.992145.992145 lmp.py:376]   Expert 55 |    142 | CPU
DEBUG 01-05 12:51:33.992357.992357 lmp.py:376]   Expert  4 |    147 | CPU
DEBUG 01-05 12:51:33.992285.992285 lmp.py:376]   Expert  5 |    149 | CPU
DEBUG 01-05 12:51:33.992259.992259 lmp.py:376]   Expert 25 |    163 | CPU
DEBUG 01-05 12:51:33.992187.992187 lmp.py:376]   Expert 11 |    172 | GPU
DEBUG 01-05 12:51:33.992161.992161 lmp.py:376]   Expert 27 |    173 | GPU
DEBUG 01-05 12:51:33.992089.992089 lmp.py:376]   Expert 39 |    174 | GPU
DEBUG 01-05 12:51:33.992884.992884 lmp.py:376]   Expert 18 |    176 | GPU
DEBUG 01-05 12:51:33.992050.992050 lmp.py:376]   Expert 56 |    185 | GPU
DEBUG 01-05 12:51:33.992263.992263 lmp.py:376]   Expert 42 |    195 | GPU
DEBUG 01-05 12:51:33.992190.992190 lmp.py:376]   Expert 52 |    202 | GPU
DEBUG 01-05 12:51:33.992926.992926 lmp.py:376]   Expert 22 |    207 | GPU
DEBUG 01-05 12:51:33.992615.992615 lmp.py:376]   Expert  7 |    208 | GPU
DEBUG 01-05 12:51:33.992351.992351 lmp.py:376]   Expert 24 |    208 | GPU
DEBUG 01-05 12:51:33.992517.992517 lmp.py:376]   Expert  1 |    211 | GPU
DEBUG 01-05 12:51:33.992730.992730 lmp.py:376]   Expert 50 |    212 | GPU
DEBUG 01-05 12:51:33.992657.992657 lmp.py:376]   Expert  9 |    213 | GPU
DEBUG 01-05 12:51:33.992393.992393 lmp.py:376]   Expert 51 |    215 | GPU
DEBUG 01-05 12:51:33.992466.992466 lmp.py:376]   Expert 59 |    225 | GPU
DEBUG 01-05 12:51:33.992679.992679 lmp.py:376]   Expert 61 |    241 | GPU
DEBUG 01-05 12:51:33.992845.992845 lmp.py:376]   Expert 16 |    261 | GPU
DEBUG 01-05 12:51:33.992819.992819 lmp.py:376]   Expert 31 |    266 | GPU
DEBUG 01-05 12:51:33.992747.992747 lmp.py:376]   Expert 28 |    270 | GPU
DEBUG 01-05 12:51:33.992482.992482 lmp.py:376]   Expert 47 |    277 | GPU
DEBUG 01-05 12:51:33.992172.992172 lmp.py:376]   Expert 57 |    278 | GPU
DEBUG 01-05 12:51:33.992623.992623 lmp.py:376]   Expert 21 |    292 | GPU
DEBUG 01-05 12:51:33.992789.992789 lmp.py:376]   Expert 14 |    307 | GPU
DEBUG 01-05 12:51:33.992001.992001 lmp.py:376]   Expert 38 |    310 | GPU
DEBUG 01-05 12:51:33.992406.992406 lmp.py:376]   Expert 10 |    336 | GPU
DEBUG 01-05 12:51:33.992380.992380 lmp.py:376]   Expert  2 |    340 | GPU
DEBUG 01-05 12:51:33.992308.992308 lmp.py:376]   Expert 15 |    354 | GPU
DEBUG 01-05 12:51:33.992520.992520 lmp.py:376]   Expert 49 |    373 | GPU
DEBUG 01-05 12:51:33.992448.992448 lmp.py:376]   Expert 36 |    400 | GPU
DEBUG 01-05 12:51:33.992660.992660 lmp.py:376]   Expert 23 |    447 | GPU
DEBUG 01-05 12:51:33.992588.992588 lmp.py:376]   Expert 26 |    459 | GPU
DEBUG 01-05 12:51:33.992324.992324 lmp.py:376]   Expert 62 |    714 | GPU
DEBUG 01-05 12:51:33.992966.992966 lmp.py:377] 
DEBUG 01-05 12:51:33.992966.992966 lmp.py:377]   CPU total tokens: 3387 (27.6%)
DEBUG 01-05 12:51:33.992894.992894 lmp.py:378]   GPU total tokens: 8901 (72.4%)
DEBUG 01-05 12:51:33.992829.992829 cuda_h.py:19] end experts_map_get cost 0.0014827251434326172 seconds
DEBUG 01-05 12:51:33.992756.992756 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:33.992824.992824 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:33.993623.993623 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:33.994168.994168 cuda_h.py:19] end allocate_cuda_memory cost 0.0012133121490478516 seconds
DEBUG 01-05 12:51:33.994296.994296 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:33.994814.994814 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:33.994961.994961 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:33.994372.994372 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f3cbd127-ce89-43b0-8bff-52c2c7df2fc6
DEBUG 01-05 12:51:33.994491.994491 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.000623.000623 mlpmodule.py:662]  experts func einsum cost 0.07546210289001465 s
INFO 01-05 12:51:34.000141.000141 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f3cbd127-ce89-43b0-8bff-52c2c7df2fc6
DEBUG 01-05 12:51:34.000746.000746 cuda_h.py:19] end load_into_gpu_async cost 0.006235599517822266 seconds
DEBUG 01-05 12:51:34.000568.000568 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.001125.001125 cuda_h.py:19] end restore_tensors2 cost 0.0003833770751953125 seconds
DEBUG 01-05 12:51:34.001246.001246 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008224964141845703 seconds
INFO 01-05 12:51:34.000534.000534 client.py:127] Model loaded
DEBUG 01-05 12:51:34.001811.001811 cuda_h.py:19] end sllm_worker_task cost 0.015549659729003906 seconds
DEBUG 01-05 12:51:34.003740.003740 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010948657989501953 seconds
DEBUG 01-05 12:51:34.003484.003484 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.004109.004109 lmp.py:423] 
DEBUG 01-05 12:51:34.004109.004109 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.004574.004574 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-05 12:51:34.004654.004654 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.012417.012417 mlpmodule.py:704] group tensors cost 0.007888317108154297 s
DEBUG 01-05 12:51:34.015288.015288 mlpmodule.py:742] pad cost 0.0026192665100097656 s
DEBUG 01-05 12:51:34.015576.015576 mlpmodule.py:748] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-05 12:51:34.015711.015711 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-05 12:51:34.023372.023372 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.024357.024357 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.024003.024003 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 12:51:34.024543.024543 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.039182.039182 mlpmodule.py:793] group einsum cost 0.023304462432861328 s
DEBUG 01-05 12:51:34.040203.040203 mlpmodule.py:801] cpy2cputensor cost 0.0006158351898193359 s
DEBUG 01-05 12:51:34.044128.044128 cuda_h.py:19] end wait_cetm_experts cost 0.0403752326965332 seconds
DEBUG 01-05 12:51:34.044670.044670 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.045491.045491 cuda_h.py:19] end gpu_sexperts cost 0.0005633831024169922 seconds
DEBUG 01-05 12:51:34.045904.045904 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.045615.045615 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:34.045271.045271 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.045034.045034 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f3cbd127-ce89-43b0-8bff-52c2c7df2fc6
INFO 01-05 12:51:34.047552.047552 client.py:127] Model loaded
DEBUG 01-05 12:51:34.048640.048640 cuda_h.py:19] end wait_experts cost 0.002484560012817383 seconds
DEBUG 01-05 12:51:34.048820.048820 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.048146.048146 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.048456.048456 mlpmodule.py:531] gpu group tensors cost 0.0006687641143798828 s
DEBUG 01-05 12:51:34.050158.050158 mlpmodule.py:564] gpu pad cost 0.0017228126525878906 s
DEBUG 01-05 12:51:34.051753.051753 mlpmodule.py:582] gpu group einsum cost 0.0005116462707519531 s
DEBUG 01-05 12:51:34.054018.054018 mlpmodule.py:611] gpu experts func einsum cost 0.006596803665161133 s
DEBUG 01-05 12:51:34.054207.054207 cuda_h.py:19] end gpu_experts cost 0.006788492202758789 seconds
DEBUG 01-05 12:51:34.054992.054992 cuda_h.py:19] end layer_moe_generate_18 cost 0.06423282623291016 seconds
DEBUG 01-05 12:51:34.055958.055958 lmp.py:217] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 12:51:34.055575.055575 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 12:51:34.055556.055556 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 12:51:34.055550.055550 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 12:51:34.055863.055863 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:34.055043.055043 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.008148193359375e-05 seconds
DEBUG 01-05 12:51:34.055593.055593 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.055716.055716 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.055931.055931 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.055475.055475 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.059416.059416 cuda_h.py:19] end allocate_cuda_memory cost 0.00429844856262207 seconds
DEBUG 01-05 12:51:34.059505.059505 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.060082.060082 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.060667.060667 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.060654.060654 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 033bce6f-3804-4fb9-8c94-190382df1cba
DEBUG 01-05 12:51:34.060194.060194 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.060577.060577 mlpmodule.py:662]  experts func einsum cost 0.05600881576538086 s
DEBUG 01-05 12:51:34.060627.060627 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.061667.061667 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 033bce6f-3804-4fb9-8c94-190382df1cba
DEBUG 01-05 12:51:34.061338.061338 cuda_h.py:19] end load_into_gpu_async cost 0.0016989707946777344 seconds
DEBUG 01-05 12:51:34.061849.061849 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.061130.061130 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-05 12:51:34.061847.061847 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006368160247802734 seconds
INFO 01-05 12:51:34.062719.062719 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 033bce6f-3804-4fb9-8c94-190382df1cba
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.064434.064434 cuda_h.py:19] end self_attn cost 0.003997802734375 seconds
DEBUG 01-05 12:51:34.065178.065178 cuda_h.py:19] end iln_self_attn_paln cost 0.009707450866699219 seconds
DEBUG 01-05 12:51:34.065107.065107 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 12:51:34.065485.065485 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.065436.065436 cuda_h.py:19] end gate cost 0.0006690025329589844 seconds
DEBUG 01-05 12:51:34.065543.065543 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.066063.066063 lmp.py:365] 
DEBUG 01-05 12:51:34.066063.066063 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.066527.066527 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.066269.066269 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.066151.066151 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.066886.066886 lmp.py:369] 
DEBUG 01-05 12:51:34.066886.066886 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.066384.066384 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.066126.066126 lmp.py:376]   Expert 56 |     54 | CPU
DEBUG 01-05 12:51:34.066100.066100 lmp.py:376]   Expert 60 |     56 | CPU
DEBUG 01-05 12:51:34.066359.066359 lmp.py:376]   Expert 12 |     62 | CPU
DEBUG 01-05 12:51:34.066856.066856 lmp.py:376]   Expert  5 |     76 | CPU
DEBUG 01-05 12:51:34.066876.066876 lmp.py:376]   Expert 55 |     79 | CPU
DEBUG 01-05 12:51:34.066897.066897 lmp.py:376]   Expert  6 |     84 | CPU
DEBUG 01-05 12:51:34.066917.066917 lmp.py:376]   Expert 18 |     86 | CPU
DEBUG 01-05 12:51:34.066699.066699 lmp.py:376]   Expert 44 |     86 | CPU
DEBUG 01-05 12:51:34.066481.066481 lmp.py:376]   Expert 48 |     86 | CPU
DEBUG 01-05 12:51:34.066740.066740 lmp.py:376]   Expert 59 |     88 | CPU
DEBUG 01-05 12:51:34.066522.066522 lmp.py:376]   Expert 30 |     97 | CPU
DEBUG 01-05 12:51:34.066065.066065 lmp.py:376]   Expert 23 |    103 | CPU
DEBUG 01-05 12:51:34.066847.066847 lmp.py:376]   Expert 52 |    107 | CPU
DEBUG 01-05 12:51:34.066868.066868 lmp.py:376]   Expert 33 |    108 | CPU
DEBUG 01-05 12:51:34.066650.066650 lmp.py:376]   Expert 42 |    108 | CPU
DEBUG 01-05 12:51:34.066432.066432 lmp.py:376]   Expert 27 |    119 | CPU
DEBUG 01-05 12:51:34.066975.066975 lmp.py:376]   Expert 57 |    122 | CPU
DEBUG 01-05 12:51:34.066996.066996 lmp.py:376]   Expert 34 |    125 | CPU
DEBUG 01-05 12:51:34.066539.066539 lmp.py:376]   Expert 24 |    130 | CPU
DEBUG 01-05 12:51:34.066083.066083 lmp.py:376]   Expert 32 |    136 | CPU
DEBUG 01-05 12:51:34.066865.066865 lmp.py:376]   Expert 54 |    144 | CPU
DEBUG 01-05 12:51:34.066647.066647 lmp.py:376]   Expert 15 |    149 | CPU
DEBUG 01-05 12:51:34.066190.066190 lmp.py:376]   Expert 62 |    149 | CPU
DEBUG 01-05 12:51:34.066972.066972 lmp.py:376]   Expert 16 |    152 | CPU
DEBUG 01-05 12:51:34.066754.066754 lmp.py:376]   Expert 63 |    156 | CPU
DEBUG 01-05 12:51:34.066112.066112 lmp.py:376]   Expert  1 |    158 | CPU
DEBUG 01-05 12:51:34.066133.066133 lmp.py:376]   Expert 13 |    159 | CPU
DEBUG 01-05 12:51:34.066676.066676 lmp.py:376]   Expert 46 |    159 | CPU
DEBUG 01-05 12:51:34.066458.066458 lmp.py:376]   Expert  0 |    160 | CPU
DEBUG 01-05 12:51:34.066240.066240 lmp.py:376]   Expert  8 |    162 | CPU
DEBUG 01-05 12:51:34.066784.066784 lmp.py:376]   Expert 26 |    162 | CPU
DEBUG 01-05 12:51:34.066327.066327 lmp.py:376]   Expert 58 |    162 | CPU
DEBUG 01-05 12:51:34.066109.066109 lmp.py:376]   Expert 17 |    163 | GPU
DEBUG 01-05 12:51:34.066653.066653 lmp.py:376]   Expert 43 |    169 | GPU
DEBUG 01-05 12:51:34.066434.066434 lmp.py:376]   Expert 49 |    177 | GPU
DEBUG 01-05 12:51:34.066978.066978 lmp.py:376]   Expert 19 |    179 | GPU
DEBUG 01-05 12:51:34.066522.066522 lmp.py:376]   Expert 39 |    179 | GPU
DEBUG 01-05 12:51:34.066304.066304 lmp.py:376]   Expert 47 |    188 | GPU
DEBUG 01-05 12:51:34.066324.066324 lmp.py:376]   Expert  4 |    195 | GPU
DEBUG 01-05 12:51:34.066867.066867 lmp.py:376]   Expert 25 |    197 | GPU
DEBUG 01-05 12:51:34.066034.066034 lmp.py:376]   Expert 40 |    198 | GPU
DEBUG 01-05 12:51:34.066292.066292 lmp.py:376]   Expert 53 |    204 | GPU
DEBUG 01-05 12:51:34.066028.066028 lmp.py:376]   Expert 50 |    207 | GPU
DEBUG 01-05 12:51:34.066525.066525 lmp.py:376]   Expert 22 |    218 | GPU
DEBUG 01-05 12:51:34.066261.066261 lmp.py:376]   Expert 37 |    218 | GPU
DEBUG 01-05 12:51:34.066996.066996 lmp.py:376]   Expert 35 |    219 | GPU
DEBUG 01-05 12:51:34.066970.066970 lmp.py:376]   Expert 14 |    228 | GPU
DEBUG 01-05 12:51:34.066229.066229 lmp.py:376]   Expert 20 |    228 | GPU
DEBUG 01-05 12:51:34.067203.067203 lmp.py:376]   Expert 11 |    236 | GPU
DEBUG 01-05 12:51:34.067701.067701 lmp.py:376]   Expert 41 |    255 | GPU
DEBUG 01-05 12:51:34.067675.067675 lmp.py:376]   Expert 51 |    262 | GPU
DEBUG 01-05 12:51:34.067410.067410 lmp.py:376]   Expert 36 |    277 | GPU
DEBUG 01-05 12:51:34.067146.067146 lmp.py:376]   Expert 38 |    279 | GPU
DEBUG 01-05 12:51:34.067643.067643 lmp.py:376]   Expert 21 |    294 | GPU
DEBUG 01-05 12:51:34.067617.067617 lmp.py:376]   Expert 28 |    297 | GPU
DEBUG 01-05 12:51:34.067876.067876 lmp.py:376]   Expert 10 |    321 | GPU
DEBUG 01-05 12:51:34.067850.067850 lmp.py:376]   Expert 45 |    330 | GPU
DEBUG 01-05 12:51:34.067586.067586 lmp.py:376]   Expert  2 |    355 | GPU
DEBUG 01-05 12:51:34.067083.067083 lmp.py:376]   Expert 61 |    355 | GPU
DEBUG 01-05 12:51:34.067818.067818 lmp.py:376]   Expert  3 |    365 | GPU
DEBUG 01-05 12:51:34.067077.067077 lmp.py:376]   Expert  9 |    370 | GPU
DEBUG 01-05 12:51:34.067574.067574 lmp.py:376]   Expert 29 |    399 | GPU
DEBUG 01-05 12:51:34.067072.067072 lmp.py:376]   Expert 31 |    407 | GPU
DEBUG 01-05 12:51:34.067569.067569 lmp.py:376]   Expert  7 |    535 | GPU
DEBUG 01-05 12:51:34.067020.067020 lmp.py:377] 
DEBUG 01-05 12:51:34.067020.067020 lmp.py:377]   CPU total tokens: 3784 (30.8%)
DEBUG 01-05 12:51:34.067709.067709 lmp.py:378]   GPU total tokens: 8504 (69.2%)
DEBUG 01-05 12:51:34.067451.067451 cuda_h.py:19] end experts_map_get cost 0.0013816356658935547 seconds
DEBUG 01-05 12:51:34.067617.067617 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.067540.067540 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.067869.067869 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.068890.068890 cuda_h.py:19] end allocate_cuda_memory cost 0.0007922649383544922 seconds
DEBUG 01-05 12:51:34.068110.068110 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.068111.068111 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.068159.068159 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.068855.068855 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3f7bf524-d355-4062-82ea-5b33ec59362a
DEBUG 01-05 12:51:34.068537.068537 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.068932.068932 client.py:127] Model loaded
DEBUG 01-05 12:51:34.069119.069119 cuda_h.py:19] end sllm_worker_task cost 0.013557672500610352 seconds
INFO 01-05 12:51:34.070706.070706 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3f7bf524-d355-4062-82ea-5b33ec59362a
DEBUG 01-05 12:51:34.070310.070310 cuda_h.py:19] end load_into_gpu_async cost 0.0021805763244628906 seconds
DEBUG 01-05 12:51:34.070867.070867 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.070661.070661 cuda_h.py:19] end restore_tensors2 cost 0.0003514289855957031 seconds
DEBUG 01-05 12:51:34.071822.071822 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003663301467895508 seconds
DEBUG 01-05 12:51:34.073166.073166 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062770843505859375 seconds
DEBUG 01-05 12:51:34.073672.073672 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.073880.073880 lmp.py:423] 
DEBUG 01-05 12:51:34.073880.073880 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.073531.073531 cuda_h.py:19] end cpu_experts_submit cost 0.00010418891906738281 seconds
DEBUG 01-05 12:51:34.073750.073750 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.078093.078093 mlpmodule.py:704] group tensors cost 0.004879474639892578 s
DEBUG 01-05 12:51:34.081370.081370 mlpmodule.py:742] pad cost 0.0019180774688720703 s
DEBUG 01-05 12:51:34.081070.081070 mlpmodule.py:748] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-05 12:51:34.081795.081795 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 12:51:34.091032.091032 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.091918.091918 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.091180.091180 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-05 12:51:34.091012.091012 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.107927.107927 mlpmodule.py:793] group einsum cost 0.026195526123046875 s
DEBUG 01-05 12:51:34.108338.108338 mlpmodule.py:801] cpy2cputensor cost 0.0007281303405761719 s
DEBUG 01-05 12:51:34.115052.115052 cuda_h.py:19] end wait_cetm_experts cost 0.041794538497924805 seconds
DEBUG 01-05 12:51:34.115024.115024 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.116894.116894 cuda_h.py:19] end gpu_sexperts cost 0.0005979537963867188 seconds
DEBUG 01-05 12:51:34.116975.116975 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.116163.116163 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 12:51:34.116058.116058 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.116767.116767 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3f7bf524-d355-4062-82ea-5b33ec59362a
INFO 01-05 12:51:34.121928.121928 client.py:127] Model loaded
DEBUG 01-05 12:51:34.121633.121633 cuda_h.py:19] end wait_experts cost 0.004675865173339844 seconds
DEBUG 01-05 12:51:34.121289.121289 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.121899.121899 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.122030.122030 mlpmodule.py:531] gpu group tensors cost 0.0006439685821533203 s
DEBUG 01-05 12:51:34.123312.123312 mlpmodule.py:564] gpu pad cost 0.0016624927520751953 s
DEBUG 01-05 12:51:34.124810.124810 mlpmodule.py:582] gpu group einsum cost 0.0003762245178222656 s
DEBUG 01-05 12:51:34.127726.127726 mlpmodule.py:611] gpu experts func einsum cost 0.005616664886474609 s
DEBUG 01-05 12:51:34.127987.127987 cuda_h.py:19] end gpu_experts cost 0.0057909488677978516 seconds
DEBUG 01-05 12:51:34.127665.127665 cuda_h.py:19] end layer_moe_generate_19 cost 0.06214570999145508 seconds
DEBUG 01-05 12:51:34.127333.127333 lmp.py:217] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 12:51:34.127851.127851 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 12:51:34.127925.127925 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 12:51:34.127634.127634 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 12:51:34.127232.127232 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 12:51:34.127597.127597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.817413330078125e-05 seconds
DEBUG 01-05 12:51:34.127525.127525 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.127389.127389 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.127505.127505 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.127387.127387 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.131874.131874 cuda_h.py:19] end allocate_cuda_memory cost 0.003384828567504883 seconds
DEBUG 01-05 12:51:34.131470.131470 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.131228.131228 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.131100.131100 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.131632.131632 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 28d396da-f1a2-4e44-add5-6b5d6f70991f
DEBUG 01-05 12:51:34.132374.132374 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.132190.132190 mlpmodule.py:662]  experts func einsum cost 0.058237552642822266 s
DEBUG 01-05 12:51:34.132770.132770 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.133706.133706 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 28d396da-f1a2-4e44-add5-6b5d6f70991f
DEBUG 01-05 12:51:34.133940.133940 cuda_h.py:19] end load_into_gpu_async cost 0.0016937255859375 seconds
DEBUG 01-05 12:51:34.133981.133981 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.133322.133322 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-05 12:51:34.133324.133324 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0056264400482177734 seconds
INFO 01-05 12:51:34.134487.134487 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 28d396da-f1a2-4e44-add5-6b5d6f70991f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.136734.136734 cuda_h.py:19] end self_attn cost 0.003777027130126953 seconds
DEBUG 01-05 12:51:34.136525.136525 cuda_h.py:19] end iln_self_attn_paln cost 0.009067773818969727 seconds
DEBUG 01-05 12:51:34.136930.136930 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 12:51:34.136071.136071 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.137708.137708 cuda_h.py:19] end gate cost 0.0006139278411865234 seconds
DEBUG 01-05 12:51:34.137816.137816 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.137620.137620 lmp.py:365] 
DEBUG 01-05 12:51:34.137620.137620 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.137707.137707 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.137449.137449 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.137569.137569 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.137781.137781 lmp.py:369] 
DEBUG 01-05 12:51:34.137781.137781 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.137994.137994 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.137405.137405 lmp.py:376]   Expert 54 |     54 | CPU
DEBUG 01-05 12:51:34.137333.137333 lmp.py:376]   Expert 28 |     57 | CPU
DEBUG 01-05 12:51:34.137545.137545 lmp.py:376]   Expert  8 |     61 | CPU
DEBUG 01-05 12:51:34.137758.137758 lmp.py:376]   Expert 13 |     68 | CPU
DEBUG 01-05 12:51:34.137732.137732 lmp.py:376]   Expert  1 |     78 | CPU
DEBUG 01-05 12:51:34.137713.137713 lmp.py:376]   Expert  6 |     78 | CPU
DEBUG 01-05 12:51:34.138210.138210 lmp.py:376]   Expert 43 |     78 | CPU
DEBUG 01-05 12:51:34.138707.138707 lmp.py:376]   Expert 42 |     92 | CPU
DEBUG 01-05 12:51:34.138727.138727 lmp.py:376]   Expert 36 |     94 | CPU
DEBUG 01-05 12:51:34.138509.138509 lmp.py:376]   Expert 12 |     96 | CPU
DEBUG 01-05 12:51:34.138530.138530 lmp.py:376]   Expert 33 |    101 | CPU
DEBUG 01-05 12:51:34.138312.138312 lmp.py:376]   Expert 10 |    107 | CPU
DEBUG 01-05 12:51:34.138855.138855 lmp.py:376]   Expert 19 |    111 | CPU
DEBUG 01-05 12:51:34.138637.138637 lmp.py:376]   Expert 51 |    116 | CPU
DEBUG 01-05 12:51:34.138419.138419 lmp.py:376]   Expert 30 |    119 | CPU
DEBUG 01-05 12:51:34.138201.138201 lmp.py:376]   Expert 38 |    120 | CPU
DEBUG 01-05 12:51:34.138983.138983 lmp.py:376]   Expert 57 |    120 | CPU
DEBUG 01-05 12:51:34.138527.138527 lmp.py:376]   Expert 14 |    121 | CPU
DEBUG 01-05 12:51:34.138547.138547 lmp.py:376]   Expert 50 |    129 | CPU
DEBUG 01-05 12:51:34.138090.138090 lmp.py:376]   Expert  9 |    130 | CPU
DEBUG 01-05 12:51:34.138872.138872 lmp.py:376]   Expert 46 |    130 | CPU
DEBUG 01-05 12:51:34.138178.138178 lmp.py:376]   Expert 39 |    133 | CPU
DEBUG 01-05 12:51:34.138959.138959 lmp.py:376]   Expert 11 |    136 | CPU
DEBUG 01-05 12:51:34.138741.138741 lmp.py:376]   Expert  7 |    149 | CPU
DEBUG 01-05 12:51:34.138523.138523 lmp.py:376]   Expert 52 |    150 | CPU
DEBUG 01-05 12:51:34.138067.138067 lmp.py:376]   Expert 63 |    152 | CPU
DEBUG 01-05 12:51:34.138326.138326 lmp.py:376]   Expert 29 |    156 | CPU
DEBUG 01-05 12:51:34.138869.138869 lmp.py:376]   Expert 49 |    159 | CPU
DEBUG 01-05 12:51:34.138651.138651 lmp.py:376]   Expert 61 |    159 | CPU
DEBUG 01-05 12:51:34.138956.138956 lmp.py:376]   Expert  5 |    165 | CPU
DEBUG 01-05 12:51:34.138500.138500 lmp.py:376]   Expert 22 |    165 | CPU
DEBUG 01-05 12:51:34.138282.138282 lmp.py:376]   Expert  3 |    167 | CPU
DEBUG 01-05 12:51:34.138064.138064 lmp.py:376]   Expert 20 |    170 | GPU
DEBUG 01-05 12:51:34.138846.138846 lmp.py:376]   Expert 53 |    175 | GPU
DEBUG 01-05 12:51:34.138389.138389 lmp.py:376]   Expert 44 |    178 | GPU
DEBUG 01-05 12:51:34.138933.138933 lmp.py:376]   Expert 62 |    182 | GPU
DEBUG 01-05 12:51:34.138953.138953 lmp.py:376]   Expert 18 |    198 | GPU
DEBUG 01-05 12:51:34.138973.138973 lmp.py:376]   Expert  0 |    200 | GPU
DEBUG 01-05 12:51:34.138755.138755 lmp.py:376]   Expert 17 |    202 | GPU
DEBUG 01-05 12:51:34.138537.138537 lmp.py:376]   Expert 47 |    210 | GPU
DEBUG 01-05 12:51:34.138319.138319 lmp.py:376]   Expert 37 |    211 | GPU
DEBUG 01-05 12:51:34.138863.138863 lmp.py:376]   Expert  2 |    224 | GPU
DEBUG 01-05 12:51:34.138883.138883 lmp.py:376]   Expert 55 |    225 | GPU
DEBUG 01-05 12:51:34.138904.138904 lmp.py:376]   Expert 23 |    231 | GPU
DEBUG 01-05 12:51:34.138447.138447 lmp.py:376]   Expert 26 |    233 | GPU
DEBUG 01-05 12:51:34.138991.138991 lmp.py:376]   Expert 45 |    235 | GPU
DEBUG 01-05 12:51:34.138534.138534 lmp.py:376]   Expert 32 |    237 | GPU
DEBUG 01-05 12:51:34.138316.138316 lmp.py:376]   Expert 60 |    239 | GPU
DEBUG 01-05 12:51:34.138621.138621 lmp.py:376]   Expert 16 |    252 | GPU
DEBUG 01-05 12:51:34.138403.138403 lmp.py:376]   Expert 15 |    270 | GPU
DEBUG 01-05 12:51:34.138947.138947 lmp.py:376]   Expert 34 |    273 | GPU
DEBUG 01-05 12:51:34.138490.138490 lmp.py:376]   Expert 21 |    283 | GPU
DEBUG 01-05 12:51:34.138272.138272 lmp.py:376]   Expert 24 |    285 | GPU
DEBUG 01-05 12:51:34.138816.138816 lmp.py:376]   Expert 58 |    290 | GPU
DEBUG 01-05 12:51:34.138598.138598 lmp.py:376]   Expert  4 |    293 | GPU
DEBUG 01-05 12:51:34.138141.138141 lmp.py:376]   Expert 31 |    302 | GPU
DEBUG 01-05 12:51:34.138685.138685 lmp.py:376]   Expert 27 |    306 | GPU
DEBUG 01-05 12:51:34.138705.138705 lmp.py:376]   Expert 59 |    308 | GPU
DEBUG 01-05 12:51:34.138249.138249 lmp.py:376]   Expert 56 |    317 | GPU
DEBUG 01-05 12:51:34.138792.138792 lmp.py:376]   Expert 40 |    323 | GPU
DEBUG 01-05 12:51:34.138243.138243 lmp.py:376]   Expert 41 |    332 | GPU
DEBUG 01-05 12:51:34.138787.138787 lmp.py:376]   Expert 48 |    337 | GPU
DEBUG 01-05 12:51:34.138330.138330 lmp.py:376]   Expert 25 |    481 | GPU
DEBUG 01-05 12:51:34.138874.138874 lmp.py:376]   Expert 35 |    535 | GPU
DEBUG 01-05 12:51:34.138371.138371 lmp.py:377] 
DEBUG 01-05 12:51:34.138371.138371 lmp.py:377]   CPU total tokens: 3751 (30.5%)
DEBUG 01-05 12:51:34.138868.138868 lmp.py:378]   GPU total tokens: 8537 (69.5%)
DEBUG 01-05 12:51:34.138418.138418 cuda_h.py:19] end experts_map_get cost 0.0013680458068847656 seconds
DEBUG 01-05 12:51:34.138393.138393 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.138646.138646 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.139491.139491 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.140944.140944 cuda_h.py:19] end allocate_cuda_memory cost 0.0014262199401855469 seconds
DEBUG 01-05 12:51:34.140595.140595 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.140444.140444 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.140445.140445 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.140095.140095 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fd84c51f-68f8-45a5-bf1a-ac3b51b9480f
DEBUG 01-05 12:51:34.140584.140584 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.141538.141538 client.py:127] Model loaded
DEBUG 01-05 12:51:34.141109.141109 cuda_h.py:19] end sllm_worker_task cost 0.013511896133422852 seconds
INFO 01-05 12:51:34.142016.142016 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fd84c51f-68f8-45a5-bf1a-ac3b51b9480f
DEBUG 01-05 12:51:34.142197.142197 cuda_h.py:19] end load_into_gpu_async cost 0.0021326541900634766 seconds
DEBUG 01-05 12:51:34.142423.142423 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.143456.143456 cuda_h.py:19] end restore_tensors2 cost 0.0003497600555419922 seconds
DEBUG 01-05 12:51:34.143808.143808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004243373870849609 seconds
DEBUG 01-05 12:51:34.145546.145546 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006935596466064453 seconds
DEBUG 01-05 12:51:34.145376.145376 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.145332.145332 lmp.py:423] 
DEBUG 01-05 12:51:34.145332.145332 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.146360.146360 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-05 12:51:34.146341.146341 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.162735.162735 mlpmodule.py:704] group tensors cost 0.016597986221313477 s
DEBUG 01-05 12:51:34.165241.165241 mlpmodule.py:742] pad cost 0.0020737648010253906 s
DEBUG 01-05 12:51:34.165325.165325 mlpmodule.py:748] create cpu tensor cost 5.4836273193359375e-05 s
DEBUG 01-05 12:51:34.166387.166387 mlpmodule.py:753] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-05 12:51:34.175594.175594 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.175633.175633 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.176417.176417 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 12:51:34.176779.176779 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.191262.191262 mlpmodule.py:793] group einsum cost 0.02584099769592285 s
DEBUG 01-05 12:51:34.192073.192073 mlpmodule.py:801] cpy2cputensor cost 0.0006804466247558594 s
DEBUG 01-05 12:51:34.197812.197812 cuda_h.py:19] end wait_cetm_experts cost 0.05118846893310547 seconds
DEBUG 01-05 12:51:34.197731.197731 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.198798.198798 cuda_h.py:19] end gpu_sexperts cost 0.0005691051483154297 seconds
DEBUG 01-05 12:51:34.198449.198449 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.198213.198213 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-05 12:51:34.198499.198499 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.198255.198255 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fd84c51f-68f8-45a5-bf1a-ac3b51b9480f
INFO 01-05 12:51:34.199855.199855 client.py:127] Model loaded
DEBUG 01-05 12:51:34.199129.199129 cuda_h.py:19] end wait_experts cost 0.001382589340209961 seconds
DEBUG 01-05 12:51:34.199786.199786 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.199873.199873 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.200553.200553 mlpmodule.py:531] gpu group tensors cost 0.0006632804870605469 s
DEBUG 01-05 12:51:34.202064.202064 mlpmodule.py:564] gpu pad cost 0.001756906509399414 s
DEBUG 01-05 12:51:34.202459.202459 mlpmodule.py:582] gpu group einsum cost 0.00042748451232910156 s
DEBUG 01-05 12:51:34.206686.206686 mlpmodule.py:611] gpu experts func einsum cost 0.006415128707885742 s
DEBUG 01-05 12:51:34.206955.206955 cuda_h.py:19] end gpu_experts cost 0.0066280364990234375 seconds
DEBUG 01-05 12:51:34.206170.206170 cuda_h.py:19] end layer_moe_generate_20 cost 0.06963467597961426 seconds
DEBUG 01-05 12:51:34.206363.206363 lmp.py:217] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 12:51:34.206371.206371 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 12:51:34.206358.206358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 12:51:34.206452.206452 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 12:51:34.206302.206302 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.5762786865234375e-05 seconds
DEBUG 01-05 12:51:34.206820.206820 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.937980651855469e-05 seconds
DEBUG 01-05 12:51:34.206470.206470 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.206274.206274 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.207317.207317 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.207008.207008 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.208310.208310 cuda_h.py:19] end allocate_cuda_memory cost 0.0008881092071533203 seconds
DEBUG 01-05 12:51:34.208737.208737 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.208877.208877 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.208892.208892 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.208955.208955 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5526d217-71c1-4e96-9650-37a1941fe620
DEBUG 01-05 12:51:34.208607.208607 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.208381.208381 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.209925.209925 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5526d217-71c1-4e96-9650-37a1941fe620
DEBUG 01-05 12:51:34.209530.209530 cuda_h.py:19] end load_into_gpu_async cost 0.0017077922821044922 seconds
DEBUG 01-05 12:51:34.209895.209895 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.209163.209163 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-05 12:51:34.210104.210104 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002901315689086914 seconds
INFO 01-05 12:51:34.210339.210339 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5526d217-71c1-4e96-9650-37a1941fe620
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.212582.212582 cuda_h.py:19] end self_attn cost 0.003171682357788086 seconds
DEBUG 01-05 12:51:34.212161.212161 cuda_h.py:19] end iln_self_attn_paln cost 0.0053942203521728516 seconds
DEBUG 01-05 12:51:34.212044.212044 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 12:51:34.212059.212059 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.213087.213087 cuda_h.py:19] end gate cost 0.0006201267242431641 seconds
DEBUG 01-05 12:51:34.213433.213433 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.213734.213734 lmp.py:365] 
DEBUG 01-05 12:51:34.213734.213734 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.213921.213921 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.213332.213332 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.213597.213597 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.213717.213717 lmp.py:369] 
DEBUG 01-05 12:51:34.213717.213717 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.213076.213076 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.213441.213441 lmp.py:376]   Expert  9 |     25 | CPU
DEBUG 01-05 12:51:34.213752.213752 lmp.py:376]   Expert 44 |     55 | CPU
DEBUG 01-05 12:51:34.213872.213872 lmp.py:376]   Expert 60 |     56 | CPU
DEBUG 01-05 12:51:34.213277.213277 lmp.py:376]   Expert 20 |     60 | CPU
DEBUG 01-05 12:51:34.213158.213158 lmp.py:376]   Expert 26 |     69 | CPU
DEBUG 01-05 12:51:34.213278.213278 lmp.py:376]   Expert 56 |     69 | CPU
DEBUG 01-05 12:51:34.213636.213636 lmp.py:376]   Expert  1 |     71 | CPU
DEBUG 01-05 12:51:34.213279.213279 lmp.py:376]   Expert 19 |     74 | CPU
DEBUG 01-05 12:51:34.213684.213684 lmp.py:376]   Expert 32 |     78 | CPU
DEBUG 01-05 12:51:34.213327.213327 lmp.py:376]   Expert 54 |     91 | CPU
DEBUG 01-05 12:51:34.213731.213731 lmp.py:376]   Expert 51 |    100 | CPU
DEBUG 01-05 12:51:34.213136.213136 lmp.py:376]   Expert 57 |    104 | CPU
DEBUG 01-05 12:51:34.213779.213779 lmp.py:376]   Expert  8 |    112 | CPU
DEBUG 01-05 12:51:34.213183.213183 lmp.py:376]   Expert 12 |    116 | CPU
DEBUG 01-05 12:51:34.213065.213065 lmp.py:376]   Expert  3 |    121 | CPU
DEBUG 01-05 12:51:34.213469.213469 lmp.py:376]   Expert 14 |    122 | CPU
DEBUG 01-05 12:51:34.213635.213635 lmp.py:376]   Expert 48 |    122 | CPU
DEBUG 01-05 12:51:34.213563.213563 lmp.py:376]   Expert  6 |    124 | CPU
DEBUG 01-05 12:51:34.213776.213776 lmp.py:376]   Expert 52 |    125 | CPU
DEBUG 01-05 12:51:34.213465.213465 lmp.py:376]   Expert 25 |    126 | CPU
DEBUG 01-05 12:51:34.213439.213439 lmp.py:376]   Expert  7 |    131 | CPU
DEBUG 01-05 12:51:34.213128.213128 lmp.py:376]   Expert 33 |    133 | CPU
DEBUG 01-05 12:51:34.213102.213102 lmp.py:376]   Expert 23 |    139 | CPU
DEBUG 01-05 12:51:34.213553.213553 lmp.py:376]   Expert 13 |    141 | CPU
DEBUG 01-05 12:51:34.213289.213289 lmp.py:376]   Expert 15 |    146 | CPU
DEBUG 01-05 12:51:34.213217.213217 lmp.py:376]   Expert 40 |    147 | CPU
DEBUG 01-05 12:51:34.213714.213714 lmp.py:376]   Expert 49 |    150 | CPU
DEBUG 01-05 12:51:34.213641.213641 lmp.py:376]   Expert 34 |    151 | CPU
DEBUG 01-05 12:51:34.214616.214616 lmp.py:376]   Expert 53 |    152 | CPU
DEBUG 01-05 12:51:34.214305.214305 lmp.py:376]   Expert 35 |    153 | CPU
DEBUG 01-05 12:51:34.214040.214040 lmp.py:376]   Expert 50 |    161 | CPU
DEBUG 01-05 12:51:34.214968.214968 lmp.py:376]   Expert 59 |    168 | CPU
DEBUG 01-05 12:51:34.214181.214181 lmp.py:376]   Expert 61 |    173 | GPU
DEBUG 01-05 12:51:34.214870.214870 lmp.py:376]   Expert 28 |    177 | GPU
DEBUG 01-05 12:51:34.214818.214818 lmp.py:376]   Expert 24 |    183 | GPU
DEBUG 01-05 12:51:34.214938.214938 lmp.py:376]   Expert 58 |    187 | GPU
DEBUG 01-05 12:51:34.214342.214342 lmp.py:376]   Expert 39 |    189 | GPU
DEBUG 01-05 12:51:34.214747.214747 lmp.py:376]   Expert  2 |    200 | GPU
DEBUG 01-05 12:51:34.214152.214152 lmp.py:376]   Expert 41 |    200 | GPU
DEBUG 01-05 12:51:34.214794.214794 lmp.py:376]   Expert 27 |    203 | GPU
DEBUG 01-05 12:51:34.214199.214199 lmp.py:376]   Expert 38 |    218 | GPU
DEBUG 01-05 12:51:34.214365.214365 lmp.py:376]   Expert 18 |    222 | GPU
DEBUG 01-05 12:51:34.214770.214770 lmp.py:376]   Expert 43 |    227 | GPU
DEBUG 01-05 12:51:34.214174.214174 lmp.py:376]   Expert 11 |    234 | GPU
DEBUG 01-05 12:51:34.214340.214340 lmp.py:376]   Expert 37 |    238 | GPU
DEBUG 01-05 12:51:34.214507.214507 lmp.py:376]   Expert  4 |    253 | GPU
DEBUG 01-05 12:51:34.214673.214673 lmp.py:376]   Expert 62 |    256 | GPU
DEBUG 01-05 12:51:34.214316.214316 lmp.py:376]   Expert 17 |    260 | GPU
DEBUG 01-05 12:51:34.214720.214720 lmp.py:376]   Expert 10 |    261 | GPU
DEBUG 01-05 12:51:34.214886.214886 lmp.py:376]   Expert 22 |    270 | GPU
DEBUG 01-05 12:51:34.214814.214814 lmp.py:376]   Expert 29 |    270 | GPU
DEBUG 01-05 12:51:34.214980.214980 lmp.py:376]   Expert 47 |    271 | GPU
DEBUG 01-05 12:51:34.214623.214623 lmp.py:376]   Expert  5 |    275 | GPU
DEBUG 01-05 12:51:34.214028.214028 lmp.py:376]   Expert 30 |    275 | GPU
DEBUG 01-05 12:51:34.214432.214432 lmp.py:376]   Expert 31 |    284 | GPU
DEBUG 01-05 12:51:34.214837.214837 lmp.py:376]   Expert 55 |    285 | GPU
DEBUG 01-05 12:51:34.214003.214003 lmp.py:376]   Expert 63 |    289 | GPU
DEBUG 01-05 12:51:34.214169.214169 lmp.py:376]   Expert 21 |    299 | GPU
DEBUG 01-05 12:51:34.214097.214097 lmp.py:376]   Expert 16 |    338 | GPU
DEBUG 01-05 12:51:34.214740.214740 lmp.py:376]   Expert 46 |    370 | GPU
DEBUG 01-05 12:51:34.214429.214429 lmp.py:376]   Expert 36 |    389 | GPU
DEBUG 01-05 12:51:34.214595.214595 lmp.py:376]   Expert 45 |    410 | GPU
DEBUG 01-05 12:51:34.214523.214523 lmp.py:376]   Expert  0 |    434 | GPU
DEBUG 01-05 12:51:34.214928.214928 lmp.py:376]   Expert 42 |    556 | GPU
DEBUG 01-05 12:51:34.214571.214571 lmp.py:377] 
DEBUG 01-05 12:51:34.214571.214571 lmp.py:377]   CPU total tokens: 3592 (29.2%)
DEBUG 01-05 12:51:34.214214.214214 lmp.py:378]   GPU total tokens: 8696 (70.8%)
DEBUG 01-05 12:51:34.214340.214340 cuda_h.py:19] end experts_map_get cost 0.0015556812286376953 seconds
DEBUG 01-05 12:51:34.214698.214698 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.214005.214005 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.214142.214142 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.217842.217842 cuda_h.py:19] end allocate_cuda_memory cost 0.0020995140075683594 seconds
DEBUG 01-05 12:51:34.217262.217262 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.217302.217302 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.217926.217926 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.217006.217006 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 781aa58a-a808-419d-adde-019e8d0aaba6
DEBUG 01-05 12:51:34.217887.217887 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.217006.217006 mlpmodule.py:662]  experts func einsum cost 0.07122015953063965 s
INFO 01-05 12:51:34.217729.217729 client.py:127] Model loaded
DEBUG 01-05 12:51:34.217880.217880 cuda_h.py:19] end sllm_worker_task cost 0.01088094711303711 seconds
INFO 01-05 12:51:34.219388.219388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 781aa58a-a808-419d-adde-019e8d0aaba6
DEBUG 01-05 12:51:34.219933.219933 cuda_h.py:19] end load_into_gpu_async cost 0.0022194385528564453 seconds
DEBUG 01-05 12:51:34.219344.219344 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.219965.219965 cuda_h.py:19] end restore_tensors2 cost 0.0003228187561035156 seconds
DEBUG 01-05 12:51:34.219080.219080 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004982948303222656 seconds
DEBUG 01-05 12:51:34.222530.222530 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007608175277709961 seconds
DEBUG 01-05 12:51:34.222022.222022 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.222408.222408 lmp.py:423] 
DEBUG 01-05 12:51:34.222408.222408 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.222867.222867 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-05 12:51:34.222610.222610 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.236167.236167 mlpmodule.py:704] group tensors cost 0.0131683349609375 s
DEBUG 01-05 12:51:34.238707.238707 mlpmodule.py:742] pad cost 0.0021431446075439453 s
DEBUG 01-05 12:51:34.239182.239182 mlpmodule.py:748] create cpu tensor cost 5.91278076171875e-05 s
DEBUG 01-05 12:51:34.239059.239059 mlpmodule.py:753] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-05 12:51:34.248494.248494 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.249547.249547 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.249484.249484 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 12:51:34.249852.249852 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.264699.264699 mlpmodule.py:793] group einsum cost 0.025359153747558594 s
DEBUG 01-05 12:51:34.265574.265574 mlpmodule.py:801] cpy2cputensor cost 0.0006151199340820312 s
DEBUG 01-05 12:51:34.269964.269964 cuda_h.py:19] end wait_cetm_experts cost 0.04731154441833496 seconds
DEBUG 01-05 12:51:34.270506.270506 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.270182.270182 cuda_h.py:19] end gpu_sexperts cost 0.0005614757537841797 seconds
DEBUG 01-05 12:51:34.270548.270548 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.305072.305072 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.03516697883605957 seconds
DEBUG 01-05 12:51:34.306743.306743 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.306552.306552 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 781aa58a-a808-419d-adde-019e8d0aaba6
INFO 01-05 12:51:34.307987.307987 client.py:127] Model loaded
DEBUG 01-05 12:51:34.307793.307793 cuda_h.py:19] end wait_experts cost 0.0016407966613769531 seconds
DEBUG 01-05 12:51:34.307511.307511 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.307943.307943 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.308001.308001 mlpmodule.py:531] gpu group tensors cost 0.0005984306335449219 s
DEBUG 01-05 12:51:34.310559.310559 mlpmodule.py:564] gpu pad cost 0.0013763904571533203 s
DEBUG 01-05 12:51:34.310561.310561 mlpmodule.py:582] gpu group einsum cost 0.00039958953857421875 s
DEBUG 01-05 12:51:34.313161.313161 mlpmodule.py:611] gpu experts func einsum cost 0.005175113677978516 s
DEBUG 01-05 12:51:34.313277.313277 cuda_h.py:19] end gpu_experts cost 0.0054209232330322266 seconds
DEBUG 01-05 12:51:34.313763.313763 cuda_h.py:19] end layer_moe_generate_21 cost 0.10095834732055664 seconds
DEBUG 01-05 12:51:34.313484.313484 lmp.py:217] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 12:51:34.313916.313916 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 12:51:34.313705.313705 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 12:51:34.313553.313553 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 12:51:34.313343.313343 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.8848648071289062e-05 seconds
DEBUG 01-05 12:51:34.313185.313185 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.936622619628906e-05 seconds
DEBUG 01-05 12:51:34.313113.313113 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.313308.313308 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.313121.313121 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.314515.314515 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.314032.314032 cuda_h.py:19] end allocate_cuda_memory cost 0.0003619194030761719 seconds
DEBUG 01-05 12:51:34.314969.314969 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.314514.314514 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.314125.314125 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.314895.314895 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32f2adba-7ade-4346-bcdb-3030b8468248
DEBUG 01-05 12:51:34.314097.314097 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.315109.315109 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.316949.316949 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32f2adba-7ade-4346-bcdb-3030b8468248
DEBUG 01-05 12:51:34.316940.316940 cuda_h.py:19] end load_into_gpu_async cost 0.001851797103881836 seconds
DEBUG 01-05 12:51:34.316412.316412 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.316120.316120 cuda_h.py:19] end restore_tensors2 cost 0.00011682510375976562 seconds
DEBUG 01-05 12:51:34.316016.316016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027456283569335938 seconds
INFO 01-05 12:51:34.317933.317933 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32f2adba-7ade-4346-bcdb-3030b8468248
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.319328.319328 cuda_h.py:19] end self_attn cost 0.004487276077270508 seconds
DEBUG 01-05 12:51:34.320668.320668 cuda_h.py:19] end iln_self_attn_paln cost 0.006281137466430664 seconds
DEBUG 01-05 12:51:34.320074.320074 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 12:51:34.320883.320883 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.320661.320661 cuda_h.py:19] end gate cost 0.0006432533264160156 seconds
DEBUG 01-05 12:51:34.320914.320914 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.321407.321407 lmp.py:365] 
DEBUG 01-05 12:51:34.321407.321407 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.321302.321302 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.321383.321383 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.321602.321602 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.321814.321814 lmp.py:369] 
DEBUG 01-05 12:51:34.321814.321814 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.321504.321504 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.321538.321538 lmp.py:376]   Expert 11 |     56 | CPU
DEBUG 01-05 12:51:34.321657.321657 lmp.py:376]   Expert  1 |     62 | CPU
DEBUG 01-05 12:51:34.321062.321062 lmp.py:376]   Expert 49 |     62 | CPU
DEBUG 01-05 12:51:34.321467.321467 lmp.py:376]   Expert 32 |     66 | CPU
DEBUG 01-05 12:51:34.321156.321156 lmp.py:376]   Expert 12 |     85 | CPU
DEBUG 01-05 12:51:34.321322.321322 lmp.py:376]   Expert 22 |     87 | CPU
DEBUG 01-05 12:51:34.321250.321250 lmp.py:376]   Expert 45 |     87 | CPU
DEBUG 01-05 12:51:34.321177.321177 lmp.py:376]   Expert  7 |     88 | CPU
DEBUG 01-05 12:51:34.321867.321867 lmp.py:376]   Expert 54 |     88 | CPU
DEBUG 01-05 12:51:34.321556.321556 lmp.py:376]   Expert 41 |     90 | CPU
DEBUG 01-05 12:51:34.321484.321484 lmp.py:376]   Expert  6 |     91 | CPU
DEBUG 01-05 12:51:34.321173.321173 lmp.py:376]   Expert 46 |     91 | CPU
DEBUG 01-05 12:51:34.321862.321862 lmp.py:376]   Expert 42 |     92 | CPU
DEBUG 01-05 12:51:34.321936.321936 lmp.py:376]   Expert 63 |     92 | CPU
DEBUG 01-05 12:51:34.321864.321864 lmp.py:376]   Expert 44 |     95 | CPU
DEBUG 01-05 12:51:34.321314.321314 lmp.py:376]   Expert 60 |    103 | CPU
DEBUG 01-05 12:51:34.321765.321765 lmp.py:376]   Expert 52 |    110 | CPU
DEBUG 01-05 12:51:34.321455.321455 lmp.py:376]   Expert 15 |    113 | CPU
DEBUG 01-05 12:51:34.321144.321144 lmp.py:376]   Expert 37 |    115 | CPU
DEBUG 01-05 12:51:34.321595.321595 lmp.py:376]   Expert 24 |    116 | CPU
DEBUG 01-05 12:51:34.321761.321761 lmp.py:376]   Expert 61 |    119 | CPU
DEBUG 01-05 12:51:34.321450.321450 lmp.py:376]   Expert 10 |    123 | CPU
DEBUG 01-05 12:51:34.321140.321140 lmp.py:376]   Expert 13 |    123 | CPU
DEBUG 01-05 12:51:34.321829.321829 lmp.py:376]   Expert 62 |    124 | CPU
DEBUG 01-05 12:51:34.321041.321041 lmp.py:376]   Expert  9 |    126 | CPU
DEBUG 01-05 12:51:34.321731.321731 lmp.py:376]   Expert 28 |    130 | CPU
DEBUG 01-05 12:51:34.321420.321420 lmp.py:376]   Expert 48 |    131 | CPU
DEBUG 01-05 12:51:34.321871.321871 lmp.py:376]   Expert 57 |    133 | CPU
DEBUG 01-05 12:51:34.321560.321560 lmp.py:376]   Expert  3 |    134 | CPU
DEBUG 01-05 12:51:34.321773.321773 lmp.py:376]   Expert 21 |    135 | CPU
DEBUG 01-05 12:51:34.321223.321223 lmp.py:376]   Expert 31 |    138 | CPU
DEBUG 01-05 12:51:34.321913.321913 lmp.py:376]   Expert  0 |    147 | CPU
DEBUG 01-05 12:51:34.321602.321602 lmp.py:376]   Expert 30 |    147 | GPU
DEBUG 01-05 12:51:34.321815.321815 lmp.py:376]   Expert 47 |    156 | GPU
DEBUG 01-05 12:51:34.321265.321265 lmp.py:376]   Expert 27 |    157 | GPU
DEBUG 01-05 12:51:34.321716.321716 lmp.py:376]   Expert 26 |    166 | GPU
DEBUG 01-05 12:51:34.321690.321690 lmp.py:376]   Expert 43 |    175 | GPU
DEBUG 01-05 12:51:34.321903.321903 lmp.py:376]   Expert 50 |    193 | GPU
DEBUG 01-05 12:51:34.321354.321354 lmp.py:376]   Expert 51 |    200 | GPU
DEBUG 01-05 12:51:34.321328.321328 lmp.py:376]   Expert 58 |    203 | GPU
DEBUG 01-05 12:51:34.321540.321540 lmp.py:376]   Expert 38 |    210 | GPU
DEBUG 01-05 12:51:34.321753.321753 lmp.py:376]   Expert 16 |    212 | GPU
DEBUG 01-05 12:51:34.321727.321727 lmp.py:376]   Expert  8 |    213 | GPU
DEBUG 01-05 12:51:34.321178.321178 lmp.py:376]   Expert 39 |    216 | GPU
DEBUG 01-05 12:51:34.321628.321628 lmp.py:376]   Expert  2 |    226 | GPU
DEBUG 01-05 12:51:34.322079.322079 lmp.py:376]   Expert 19 |    228 | GPU
DEBUG 01-05 12:51:34.322530.322530 lmp.py:376]   Expert 33 |    252 | GPU
DEBUG 01-05 12:51:34.322319.322319 lmp.py:376]   Expert 34 |    257 | GPU
DEBUG 01-05 12:51:34.322485.322485 lmp.py:376]   Expert 56 |    261 | GPU
DEBUG 01-05 12:51:34.322174.322174 lmp.py:376]   Expert  4 |    264 | GPU
DEBUG 01-05 12:51:34.322387.322387 lmp.py:376]   Expert 17 |    271 | GPU
DEBUG 01-05 12:51:34.322599.322599 lmp.py:376]   Expert 35 |    280 | GPU
DEBUG 01-05 12:51:34.322050.322050 lmp.py:376]   Expert 23 |    292 | GPU
DEBUG 01-05 12:51:34.322024.322024 lmp.py:376]   Expert 20 |    299 | GPU
DEBUG 01-05 12:51:34.322714.322714 lmp.py:376]   Expert 53 |    323 | GPU
DEBUG 01-05 12:51:34.322787.322787 lmp.py:376]   Expert 59 |    330 | GPU
DEBUG 01-05 12:51:34.322430.322430 lmp.py:376]   Expert 29 |    334 | GPU
DEBUG 01-05 12:51:34.322596.322596 lmp.py:376]   Expert 18 |    342 | GPU
DEBUG 01-05 12:51:34.322001.322001 lmp.py:376]   Expert 25 |    364 | GPU
DEBUG 01-05 12:51:34.322644.322644 lmp.py:376]   Expert 40 |    372 | GPU
DEBUG 01-05 12:51:34.322287.322287 lmp.py:376]   Expert 55 |    372 | GPU
DEBUG 01-05 12:51:34.322691.322691 lmp.py:376]   Expert 14 |    457 | GPU
DEBUG 01-05 12:51:34.322857.322857 lmp.py:376]   Expert 36 |    560 | GPU
DEBUG 01-05 12:51:34.322023.322023 lmp.py:376]   Expert  5 |    604 | GPU
DEBUG 01-05 12:51:34.322620.322620 lmp.py:377] 
DEBUG 01-05 12:51:34.322620.322620 lmp.py:377]   CPU total tokens: 3352 (27.3%)
DEBUG 01-05 12:51:34.322740.322740 lmp.py:378]   GPU total tokens: 8936 (72.7%)
DEBUG 01-05 12:51:34.322628.322628 cuda_h.py:19] end experts_map_get cost 0.0015189647674560547 seconds
INFO 01-05 12:51:34.324141.324141 client.py:127] Model loaded
DEBUG 01-05 12:51:34.322055.322055 mlpmodule.py:662]  experts func einsum cost 0.09967613220214844 s
DEBUG 01-05 12:51:34.592633.592633 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.593501.593501 cuda_h.py:19] end sllm_worker_task cost 0.27930140495300293 seconds
DEBUG 01-05 12:51:34.593115.593115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.594547.594547 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.595252.595252 cuda_h.py:19] end allocate_cuda_memory cost 0.0005676746368408203 seconds
DEBUG 01-05 12:51:34.595550.595550 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.595301.595301 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.595319.595319 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.595189.595189 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 91c880c3-6c1a-4d91-8c06-b4e8f3796bf7
DEBUG 01-05 12:51:34.596719.596719 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.598531.598531 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 91c880c3-6c1a-4d91-8c06-b4e8f3796bf7
DEBUG 01-05 12:51:34.598550.598550 cuda_h.py:19] end load_into_gpu_async cost 0.0028820037841796875 seconds
DEBUG 01-05 12:51:34.598580.598580 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.599646.599646 cuda_h.py:19] end restore_tensors2 cost 0.0010864734649658203 seconds
DEBUG 01-05 12:51:34.599803.599803 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0055921077728271484 seconds
DEBUG 01-05 12:51:34.606072.606072 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.013087749481201172 seconds
DEBUG 01-05 12:51:34.606638.606638 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.607069.607069 lmp.py:423] 
DEBUG 01-05 12:51:34.607069.607069 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.607922.607922 cuda_h.py:19] end cpu_experts_submit cost 0.0002932548522949219 seconds
DEBUG 01-05 12:51:34.607506.607506 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.624817.624817 mlpmodule.py:704] group tensors cost 0.017021656036376953 s
DEBUG 01-05 12:51:34.626244.626244 mlpmodule.py:742] pad cost 0.0017008781433105469 s
DEBUG 01-05 12:51:34.627924.627924 mlpmodule.py:748] create cpu tensor cost 5.626678466796875e-05 s
DEBUG 01-05 12:51:34.627211.627211 mlpmodule.py:753] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-05 12:51:34.637590.637590 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.637264.637264 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.637407.637407 mlpmodule.py:773] group_w3 first element: -0.018798828125
WARNING 01-05 12:51:34.637808.637808 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.652851.652851 mlpmodule.py:793] group einsum cost 0.02515864372253418 s
DEBUG 01-05 12:51:34.653143.653143 mlpmodule.py:801] cpy2cputensor cost 0.0006170272827148438 s
DEBUG 01-05 12:51:34.657324.657324 cuda_h.py:19] end wait_cetm_experts cost 0.050429582595825195 seconds
DEBUG 01-05 12:51:34.658172.658172 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.659680.659680 cuda_h.py:19] end gpu_sexperts cost 0.0010378360748291016 seconds
DEBUG 01-05 12:51:34.659340.659340 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.659491.659491 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.4836273193359375e-05 seconds
DEBUG 01-05 12:51:34.659639.659639 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.659364.659364 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 91c880c3-6c1a-4d91-8c06-b4e8f3796bf7
INFO 01-05 12:51:34.660707.660707 client.py:127] Model loaded
DEBUG 01-05 12:51:34.661075.661075 cuda_h.py:19] end wait_experts cost 0.0014729499816894531 seconds
DEBUG 01-05 12:51:34.661031.661031 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.661133.661133 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.662194.662194 mlpmodule.py:531] gpu group tensors cost 0.0014481544494628906 s
DEBUG 01-05 12:51:34.666598.666598 mlpmodule.py:564] gpu pad cost 0.0037908554077148438 s
DEBUG 01-05 12:51:34.667863.667863 mlpmodule.py:582] gpu group einsum cost 0.0010573863983154297 s
DEBUG 01-05 12:51:34.671180.671180 mlpmodule.py:611] gpu experts func einsum cost 0.00972890853881836 s
DEBUG 01-05 12:51:34.671735.671735 cuda_h.py:19] end gpu_experts cost 0.010077238082885742 seconds
DEBUG 01-05 12:51:34.671380.671380 cuda_h.py:19] end layer_moe_generate_22 cost 0.35128355026245117 seconds
DEBUG 01-05 12:51:34.671634.671634 lmp.py:217] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 12:51:34.671357.671357 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 12:51:34.671053.671053 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 12:51:34.671101.671101 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 12:51:34.671236.671236 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.647804260253906e-05 seconds
DEBUG 01-05 12:51:34.671674.671674 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 8.559226989746094e-05 seconds
DEBUG 01-05 12:51:34.671032.671032 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.671544.671544 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.672720.672720 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.672684.672684 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.675932.675932 cuda_h.py:19] end allocate_cuda_memory cost 0.0030210018157958984 seconds
DEBUG 01-05 12:51:34.675406.675406 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.675089.675089 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.675588.675588 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.675628.675628 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 406bdf20-29c6-4436-8880-004b5501e946
DEBUG 01-05 12:51:34.675526.675526 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.675972.675972 mlpmodule.py:662]  experts func einsum cost 0.06818532943725586 s
DEBUG 01-05 12:51:34.676790.676790 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.677120.677120 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 406bdf20-29c6-4436-8880-004b5501e946
DEBUG 01-05 12:51:34.677155.677155 cuda_h.py:19] end load_into_gpu_async cost 0.0017702579498291016 seconds
DEBUG 01-05 12:51:34.677427.677427 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.677769.677769 cuda_h.py:19] end restore_tensors2 cost 8.463859558105469e-05 seconds
DEBUG 01-05 12:51:34.677955.677955 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005177974700927734 seconds
INFO 01-05 12:51:34.677873.677873 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 406bdf20-29c6-4436-8880-004b5501e946
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.679762.679762 cuda_h.py:19] end self_attn cost 0.0035996437072753906 seconds
DEBUG 01-05 12:51:34.680070.680070 cuda_h.py:19] end iln_self_attn_paln cost 0.008214712142944336 seconds
DEBUG 01-05 12:51:34.680006.680006 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 12:51:34.680245.680245 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.680116.680116 cuda_h.py:19] end gate cost 0.0006442070007324219 seconds
DEBUG 01-05 12:51:34.680753.680753 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.681452.681452 lmp.py:365] 
DEBUG 01-05 12:51:34.681452.681452 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.681638.681638 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.681242.681242 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.681746.681746 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.681627.681627 lmp.py:369] 
DEBUG 01-05 12:51:34.681627.681627 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.681509.681509 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.681589.681589 lmp.py:376]   Expert  5 |     53 | CPU
DEBUG 01-05 12:51:34.681709.681709 lmp.py:376]   Expert 49 |     66 | CPU
DEBUG 01-05 12:51:34.681113.681113 lmp.py:376]   Expert 27 |     68 | CPU
DEBUG 01-05 12:51:34.681279.681279 lmp.py:376]   Expert 19 |     81 | CPU
DEBUG 01-05 12:51:34.681207.681207 lmp.py:376]   Expert 44 |     81 | CPU
DEBUG 01-05 12:51:34.681373.681373 lmp.py:376]   Expert 17 |     96 | CPU
DEBUG 01-05 12:51:34.681824.681824 lmp.py:376]   Expert 55 |     96 | CPU
DEBUG 01-05 12:51:34.681752.681752 lmp.py:376]   Expert  7 |     97 | CPU
DEBUG 01-05 12:51:34.681441.681441 lmp.py:376]   Expert 53 |    109 | CPU
DEBUG 01-05 12:51:34.681991.681991 lmp.py:376]   Expert 52 |    110 | CPU
DEBUG 01-05 12:51:34.681158.681158 lmp.py:376]   Expert 40 |    116 | CPU
DEBUG 01-05 12:51:34.681562.681562 lmp.py:376]   Expert 43 |    117 | CPU
DEBUG 01-05 12:51:34.681728.681728 lmp.py:376]   Expert 22 |    119 | CPU
DEBUG 01-05 12:51:34.681894.681894 lmp.py:376]   Expert 34 |    120 | CPU
DEBUG 01-05 12:51:34.681584.681584 lmp.py:376]   Expert 25 |    121 | CPU
DEBUG 01-05 12:51:34.681796.681796 lmp.py:376]   Expert 58 |    123 | CPU
DEBUG 01-05 12:51:34.681247.681247 lmp.py:376]   Expert 35 |    127 | CPU
DEBUG 01-05 12:51:34.681698.681698 lmp.py:376]   Expert 38 |    129 | CPU
DEBUG 01-05 12:51:34.681672.681672 lmp.py:376]   Expert  4 |    132 | CPU
DEBUG 01-05 12:51:34.681123.681123 lmp.py:376]   Expert  6 |    136 | CPU
DEBUG 01-05 12:51:34.681574.681574 lmp.py:376]   Expert  1 |    143 | CPU
DEBUG 01-05 12:51:34.681025.681025 lmp.py:376]   Expert 16 |    144 | CPU
DEBUG 01-05 12:51:34.681237.681237 lmp.py:376]   Expert 51 |    146 | CPU
DEBUG 01-05 12:51:34.681403.681403 lmp.py:376]   Expert 42 |    147 | CPU
DEBUG 01-05 12:51:34.681331.681331 lmp.py:376]   Expert 47 |    148 | CPU
DEBUG 01-05 12:51:34.681259.681259 lmp.py:376]   Expert 63 |    154 | CPU
DEBUG 01-05 12:51:34.681425.681425 lmp.py:376]   Expert  9 |    164 | CPU
DEBUG 01-05 12:51:34.681114.681114 lmp.py:376]   Expert 13 |    175 | CPU
DEBUG 01-05 12:51:34.681327.681327 lmp.py:376]   Expert  0 |    178 | CPU
DEBUG 01-05 12:51:34.681777.681777 lmp.py:376]   Expert 30 |    180 | CPU
DEBUG 01-05 12:51:34.681990.681990 lmp.py:376]   Expert 26 |    182 | CPU
DEBUG 01-05 12:51:34.681726.681726 lmp.py:376]   Expert 36 |    187 | CPU
DEBUG 01-05 12:51:34.681176.681176 lmp.py:376]   Expert 46 |    188 | GPU
DEBUG 01-05 12:51:34.681104.681104 lmp.py:376]   Expert 45 |    189 | GPU
DEBUG 01-05 12:51:34.681317.681317 lmp.py:376]   Expert 23 |    194 | GPU
DEBUG 01-05 12:51:34.681529.681529 lmp.py:376]   Expert 28 |    195 | GPU
DEBUG 01-05 12:51:34.681457.681457 lmp.py:376]   Expert 11 |    200 | GPU
DEBUG 01-05 12:51:34.681385.681385 lmp.py:376]   Expert  2 |    202 | GPU
DEBUG 01-05 12:51:34.682312.682312 lmp.py:376]   Expert 39 |    204 | GPU
DEBUG 01-05 12:51:34.682240.682240 lmp.py:376]   Expert 62 |    208 | GPU
DEBUG 01-05 12:51:34.682168.682168 lmp.py:376]   Expert 60 |    212 | GPU
DEBUG 01-05 12:51:34.682380.682380 lmp.py:376]   Expert 41 |    213 | GPU
DEBUG 01-05 12:51:34.682831.682831 lmp.py:376]   Expert  3 |    217 | GPU
DEBUG 01-05 12:51:34.682282.682282 lmp.py:376]   Expert 12 |    219 | GPU
DEBUG 01-05 12:51:34.682018.682018 lmp.py:376]   Expert 15 |    219 | GPU
DEBUG 01-05 12:51:34.682707.682707 lmp.py:376]   Expert 61 |    226 | GPU
DEBUG 01-05 12:51:34.682158.682158 lmp.py:376]   Expert 24 |    233 | GPU
DEBUG 01-05 12:51:34.682370.682370 lmp.py:376]   Expert 10 |    252 | GPU
DEBUG 01-05 12:51:34.682583.682583 lmp.py:376]   Expert 29 |    254 | GPU
DEBUG 01-05 12:51:34.682034.682034 lmp.py:376]   Expert 21 |    259 | GPU
DEBUG 01-05 12:51:34.682438.682438 lmp.py:376]   Expert 14 |    261 | GPU
DEBUG 01-05 12:51:34.682843.682843 lmp.py:376]   Expert 20 |    273 | GPU
DEBUG 01-05 12:51:34.682532.682532 lmp.py:376]   Expert 33 |    280 | GPU
DEBUG 01-05 12:51:34.682698.682698 lmp.py:376]   Expert 32 |    286 | GPU
DEBUG 01-05 12:51:34.682626.682626 lmp.py:376]   Expert 57 |    286 | GPU
DEBUG 01-05 12:51:34.682600.682600 lmp.py:376]   Expert  8 |    289 | GPU
DEBUG 01-05 12:51:34.682051.682051 lmp.py:376]   Expert 31 |    292 | GPU
DEBUG 01-05 12:51:34.682502.682502 lmp.py:376]   Expert 59 |    298 | GPU
DEBUG 01-05 12:51:34.682714.682714 lmp.py:376]   Expert 37 |    300 | GPU
DEBUG 01-05 12:51:34.682403.682403 lmp.py:376]   Expert 50 |    301 | GPU
DEBUG 01-05 12:51:34.682854.682854 lmp.py:376]   Expert 18 |    315 | GPU
DEBUG 01-05 12:51:34.682067.682067 lmp.py:376]   Expert 56 |    375 | GPU
DEBUG 01-05 12:51:34.682279.682279 lmp.py:376]   Expert 48 |    400 | GPU
DEBUG 01-05 12:51:34.682730.682730 lmp.py:376]   Expert 54 |    403 | GPU
DEBUG 01-05 12:51:34.682135.682135 lmp.py:377] 
DEBUG 01-05 12:51:34.682135.682135 lmp.py:377]   CPU total tokens: 4045 (32.9%)
DEBUG 01-05 12:51:34.682301.682301 lmp.py:378]   GPU total tokens: 8243 (67.1%)
DEBUG 01-05 12:51:34.682474.682474 cuda_h.py:19] end experts_map_get cost 0.0015218257904052734 seconds
DEBUG 01-05 12:51:34.682309.682309 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.682615.682615 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.682673.682673 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.683531.683531 cuda_h.py:19] end allocate_cuda_memory cost 0.0012667179107666016 seconds
DEBUG 01-05 12:51:34.684149.684149 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.684813.684813 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.684476.684476 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.684272.684272 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 320eecb6-f2ab-4fae-b84a-ed404efd004b
DEBUG 01-05 12:51:34.684570.684570 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.684477.684477 client.py:127] Model loaded
DEBUG 01-05 12:51:34.684188.684188 cuda_h.py:19] end sllm_worker_task cost 0.012816190719604492 seconds
INFO 01-05 12:51:34.686516.686516 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 320eecb6-f2ab-4fae-b84a-ed404efd004b
DEBUG 01-05 12:51:34.686266.686266 cuda_h.py:19] end load_into_gpu_async cost 0.0022630691528320312 seconds
DEBUG 01-05 12:51:34.686161.686161 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.686320.686320 cuda_h.py:19] end restore_tensors2 cost 0.000370025634765625 seconds
DEBUG 01-05 12:51:34.686110.686110 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004275083541870117 seconds
DEBUG 01-05 12:51:34.689013.689013 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006951332092285156 seconds
DEBUG 01-05 12:51:34.689895.689895 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.689534.689534 lmp.py:423] 
DEBUG 01-05 12:51:34.689534.689534 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.689761.689761 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-05 12:51:34.689411.689411 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.699544.699544 mlpmodule.py:704] group tensors cost 0.009646415710449219 s
DEBUG 01-05 12:51:34.702776.702776 mlpmodule.py:742] pad cost 0.0019404888153076172 s
DEBUG 01-05 12:51:34.702429.702429 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-05 12:51:34.702015.702015 mlpmodule.py:753] move to cpu cost 3.814697265625e-05 s
DEBUG 01-05 12:51:34.716459.716459 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.717921.717921 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.717467.717467 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-05 12:51:34.717001.717001 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.736924.736924 mlpmodule.py:793] group einsum cost 0.03380250930786133 s
DEBUG 01-05 12:51:34.737479.737479 mlpmodule.py:801] cpy2cputensor cost 0.0007035732269287109 s
DEBUG 01-05 12:51:34.741530.741530 cuda_h.py:19] end wait_cetm_experts cost 0.051947593688964844 seconds
DEBUG 01-05 12:51:34.741490.741490 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.742100.742100 cuda_h.py:19] end gpu_sexperts cost 0.0005819797515869141 seconds
DEBUG 01-05 12:51:34.742374.742374 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.742482.742482 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.62396240234375e-05 seconds
DEBUG 01-05 12:51:34.742523.742523 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.742994.742994 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 320eecb6-f2ab-4fae-b84a-ed404efd004b
INFO 01-05 12:51:34.744224.744224 client.py:127] Model loaded
DEBUG 01-05 12:51:34.744498.744498 cuda_h.py:19] end wait_experts cost 0.001390695571899414 seconds
DEBUG 01-05 12:51:34.744870.744870 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.744149.744149 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.744294.744294 mlpmodule.py:531] gpu group tensors cost 0.0006883144378662109 s
DEBUG 01-05 12:51:34.746401.746401 mlpmodule.py:564] gpu pad cost 0.0017364025115966797 s
DEBUG 01-05 12:51:34.747832.747832 mlpmodule.py:582] gpu group einsum cost 0.0005645751953125 s
DEBUG 01-05 12:51:34.750772.750772 mlpmodule.py:611] gpu experts func einsum cost 0.006659746170043945 s
DEBUG 01-05 12:51:34.751577.751577 cuda_h.py:19] end gpu_experts cost 0.006847381591796875 seconds
DEBUG 01-05 12:51:34.751030.751030 cuda_h.py:19] end layer_moe_generate_23 cost 0.07091355323791504 seconds
DEBUG 01-05 12:51:34.751945.751945 lmp.py:217] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 12:51:34.751661.751661 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 12:51:34.751457.751457 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 12:51:34.751981.751981 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 12:51:34.751447.751447 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 12:51:34.751110.751110 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.818771362304688e-05 seconds
DEBUG 01-05 12:51:34.751284.751284 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.751590.751590 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.751527.751527 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.751915.751915 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.752464.752464 cuda_h.py:19] end allocate_cuda_memory cost 0.00032830238342285156 seconds
DEBUG 01-05 12:51:34.752367.752367 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.752461.752461 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.752091.752091 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.752033.752033 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4179e84a-44c2-49b3-a7d9-a0d6e51b509a
DEBUG 01-05 12:51:34.752546.752546 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.752492.752492 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.753219.753219 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4179e84a-44c2-49b3-a7d9-a0d6e51b509a
DEBUG 01-05 12:51:34.753969.753969 cuda_h.py:19] end load_into_gpu_async cost 0.0015304088592529297 seconds
DEBUG 01-05 12:51:34.753003.753003 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.753986.753986 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-05 12:51:34.753597.753597 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002176046371459961 seconds
INFO 01-05 12:51:34.754514.754514 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4179e84a-44c2-49b3-a7d9-a0d6e51b509a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.756857.756857 cuda_h.py:19] end self_attn cost 0.003892183303833008 seconds
DEBUG 01-05 12:51:34.757516.757516 cuda_h.py:19] end iln_self_attn_paln cost 0.0053408145904541016 seconds
DEBUG 01-05 12:51:34.757737.757737 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 12:51:34.757738.757738 cuda_h.py:10] start gate
INFO 01-05 12:51:34.761727.761727 client.py:127] Model loaded
DEBUG 01-05 12:51:34.761894.761894 cuda_h.py:19] end sllm_worker_task cost 0.009374380111694336 seconds
DEBUG 01-05 12:51:34.761109.761109 mlpmodule.py:662]  experts func einsum cost 0.07185721397399902 s
DEBUG 01-05 12:51:34.762888.762888 cuda_h.py:19] end gate cost 0.005227088928222656 seconds
DEBUG 01-05 12:51:34.762103.762103 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.762649.762649 lmp.py:365] 
DEBUG 01-05 12:51:34.762649.762649 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.762213.762213 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.762432.762432 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.762029.762029 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.762718.762718 lmp.py:369] 
DEBUG 01-05 12:51:34.762718.762718 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.762123.762123 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.762534.762534 lmp.py:376]   Expert 47 |     60 | CPU
DEBUG 01-05 12:51:34.763985.763985 lmp.py:376]   Expert 42 |     66 | CPU
DEBUG 01-05 12:51:34.763244.763244 lmp.py:376]   Expert 25 |     70 | CPU
DEBUG 01-05 12:51:34.763503.763503 lmp.py:376]   Expert 43 |     70 | CPU
DEBUG 01-05 12:51:34.763285.763285 lmp.py:376]   Expert  6 |     78 | CPU
DEBUG 01-05 12:51:34.763305.763305 lmp.py:376]   Expert 44 |     81 | CPU
DEBUG 01-05 12:51:34.763848.763848 lmp.py:376]   Expert 62 |     85 | CPU
DEBUG 01-05 12:51:34.763869.763869 lmp.py:376]   Expert 35 |     88 | CPU
DEBUG 01-05 12:51:34.763889.763889 lmp.py:376]   Expert 60 |     97 | CPU
DEBUG 01-05 12:51:34.763433.763433 lmp.py:376]   Expert 48 |    100 | CPU
DEBUG 01-05 12:51:34.763691.763691 lmp.py:376]   Expert  5 |    103 | CPU
DEBUG 01-05 12:51:34.763427.763427 lmp.py:376]   Expert 29 |    103 | CPU
DEBUG 01-05 12:51:34.763163.763163 lmp.py:376]   Expert 54 |    107 | CPU
DEBUG 01-05 12:51:34.763660.763660 lmp.py:376]   Expert 55 |    107 | CPU
DEBUG 01-05 12:51:34.763680.763680 lmp.py:376]   Expert 16 |    119 | CPU
DEBUG 01-05 12:51:34.763416.763416 lmp.py:376]   Expert 22 |    125 | CPU
DEBUG 01-05 12:51:34.763198.763198 lmp.py:376]   Expert 30 |    129 | CPU
DEBUG 01-05 12:51:34.763457.763457 lmp.py:376]   Expert 56 |    133 | CPU
DEBUG 01-05 12:51:34.763000.763000 lmp.py:376]   Expert 51 |    141 | CPU
DEBUG 01-05 12:51:34.763259.763259 lmp.py:376]   Expert  7 |    153 | CPU
DEBUG 01-05 12:51:34.763279.763279 lmp.py:376]   Expert 36 |    153 | CPU
DEBUG 01-05 12:51:34.763061.763061 lmp.py:376]   Expert  4 |    155 | CPU
DEBUG 01-05 12:51:34.763082.763082 lmp.py:376]   Expert 61 |    159 | CPU
DEBUG 01-05 12:51:34.763864.763864 lmp.py:376]   Expert 28 |    160 | CPU
DEBUG 01-05 12:51:34.763122.763122 lmp.py:376]   Expert 49 |    162 | CPU
DEBUG 01-05 12:51:34.763143.763143 lmp.py:376]   Expert  1 |    165 | CPU
DEBUG 01-05 12:51:34.763925.763925 lmp.py:376]   Expert 20 |    168 | CPU
DEBUG 01-05 12:51:34.763660.763660 lmp.py:376]   Expert 59 |    170 | CPU
DEBUG 01-05 12:51:34.763396.763396 lmp.py:376]   Expert 17 |    173 | CPU
DEBUG 01-05 12:51:34.763416.763416 lmp.py:376]   Expert 31 |    173 | CPU
DEBUG 01-05 12:51:34.763198.763198 lmp.py:376]   Expert 38 |    173 | CPU
DEBUG 01-05 12:51:34.763980.763980 lmp.py:376]   Expert 21 |    176 | CPU
DEBUG 01-05 12:51:34.763762.763762 lmp.py:376]   Expert 46 |    181 | GPU
DEBUG 01-05 12:51:34.763544.763544 lmp.py:376]   Expert 34 |    188 | GPU
DEBUG 01-05 12:51:34.763088.763088 lmp.py:376]   Expert 15 |    190 | GPU
DEBUG 01-05 12:51:34.763870.763870 lmp.py:376]   Expert 14 |    193 | GPU
DEBUG 01-05 12:51:34.763890.763890 lmp.py:376]   Expert  3 |    195 | GPU
DEBUG 01-05 12:51:34.763434.763434 lmp.py:376]   Expert  0 |    196 | GPU
DEBUG 01-05 12:51:34.763977.763977 lmp.py:376]   Expert 19 |    203 | GPU
DEBUG 01-05 12:51:34.763521.763521 lmp.py:376]   Expert 41 |    206 | GPU
DEBUG 01-05 12:51:34.763303.763303 lmp.py:376]   Expert 63 |    207 | GPU
DEBUG 01-05 12:51:34.763277.763277 lmp.py:376]   Expert 40 |    208 | GPU
DEBUG 01-05 12:51:34.763059.763059 lmp.py:376]   Expert 53 |    211 | GPU
DEBUG 01-05 12:51:34.763317.763317 lmp.py:376]   Expert  2 |    212 | GPU
DEBUG 01-05 12:51:34.763099.763099 lmp.py:376]   Expert 24 |    213 | GPU
DEBUG 01-05 12:51:34.763643.763643 lmp.py:376]   Expert 57 |    221 | GPU
DEBUG 01-05 12:51:34.763186.763186 lmp.py:376]   Expert 37 |    227 | GPU
DEBUG 01-05 12:51:34.763207.763207 lmp.py:376]   Expert 10 |    234 | GPU
DEBUG 01-05 12:51:34.763989.763989 lmp.py:376]   Expert 50 |    236 | GPU
DEBUG 01-05 12:51:34.763532.763532 lmp.py:376]   Expert 23 |    239 | GPU
DEBUG 01-05 12:51:34.763314.763314 lmp.py:376]   Expert 26 |    240 | GPU
DEBUG 01-05 12:51:34.763004.763004 lmp.py:376]   Expert 45 |    249 | GPU
DEBUG 01-05 12:51:34.763216.763216 lmp.py:376]   Expert 58 |    253 | GPU
DEBUG 01-05 12:51:34.763998.763998 lmp.py:376]   Expert 32 |    259 | GPU
DEBUG 01-05 12:51:34.763780.763780 lmp.py:376]   Expert 52 |    262 | GPU
DEBUG 01-05 12:51:34.763562.763562 lmp.py:376]   Expert  9 |    273 | GPU
DEBUG 01-05 12:51:34.763105.763105 lmp.py:376]   Expert 18 |    288 | GPU
DEBUG 01-05 12:51:34.763887.763887 lmp.py:376]   Expert 12 |    291 | GPU
DEBUG 01-05 12:51:34.763431.763431 lmp.py:376]   Expert 13 |    325 | GPU
DEBUG 01-05 12:51:34.763451.763451 lmp.py:376]   Expert 33 |    332 | GPU
DEBUG 01-05 12:51:34.763233.763233 lmp.py:376]   Expert 39 |    341 | GPU
DEBUG 01-05 12:51:34.763015.763015 lmp.py:376]   Expert  8 |    363 | GPU
DEBUG 01-05 12:51:34.763559.763559 lmp.py:376]   Expert 11 |    377 | GPU
DEBUG 01-05 12:51:34.763102.763102 lmp.py:376]   Expert 27 |    673 | GPU
DEBUG 01-05 12:51:34.763838.763838 lmp.py:377] 
DEBUG 01-05 12:51:34.763838.763838 lmp.py:377]   CPU total tokens: 4002 (32.6%)
DEBUG 01-05 12:51:34.763335.763335 lmp.py:378]   GPU total tokens: 8286 (67.4%)
DEBUG 01-05 12:51:34.763362.763362 cuda_h.py:19] end experts_map_get cost 0.0013937950134277344 seconds
DEBUG 01-05 12:51:34.764813.764813 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.764212.764212 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.764402.764402 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.764235.764235 cuda_h.py:19] end allocate_cuda_memory cost 0.0002994537353515625 seconds
DEBUG 01-05 12:51:34.764515.764515 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.764271.764271 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.764987.764987 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.764399.764399 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb996dc8-98be-459a-ae68-071ea7a5254f
DEBUG 01-05 12:51:34.764996.764996 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.766089.766089 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb996dc8-98be-459a-ae68-071ea7a5254f
DEBUG 01-05 12:51:34.767041.767041 cuda_h.py:19] end load_into_gpu_async cost 0.002411365509033203 seconds
DEBUG 01-05 12:51:34.767481.767481 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.767934.767934 cuda_h.py:19] end restore_tensors2 cost 0.0004088878631591797 seconds
DEBUG 01-05 12:51:34.767094.767094 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035774707794189453 seconds
DEBUG 01-05 12:51:34.770478.770478 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006188154220581055 seconds
DEBUG 01-05 12:51:34.770447.770447 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.770356.770356 lmp.py:423] 
DEBUG 01-05 12:51:34.770356.770356 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.770107.770107 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-05 12:51:34.770995.770995 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.778142.778142 mlpmodule.py:704] group tensors cost 0.008112192153930664 s
DEBUG 01-05 12:51:34.780249.780249 mlpmodule.py:742] pad cost 0.0016279220581054688 s
DEBUG 01-05 12:51:34.781438.781438 mlpmodule.py:748] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-05 12:51:34.781625.781625 mlpmodule.py:753] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-05 12:51:34.789266.789266 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.789073.789073 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.789440.789440 mlpmodule.py:773] group_w3 first element: -0.019287109375
WARNING 01-05 12:51:34.789001.789001 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.804541.804541 mlpmodule.py:793] group einsum cost 0.02331256866455078 s
DEBUG 01-05 12:51:34.805391.805391 mlpmodule.py:801] cpy2cputensor cost 0.0006654262542724609 s
DEBUG 01-05 12:51:34.809147.809147 cuda_h.py:19] end wait_cetm_experts cost 0.03946995735168457 seconds
DEBUG 01-05 12:51:34.810218.810218 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.810100.810100 cuda_h.py:19] end gpu_sexperts cost 0.0005724430084228516 seconds
DEBUG 01-05 12:51:34.810950.810950 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.810720.810720 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-05 12:51:34.810615.810615 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.810563.810563 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb996dc8-98be-459a-ae68-071ea7a5254f
INFO 01-05 12:51:34.817202.817202 client.py:127] Model loaded
DEBUG 01-05 12:51:34.817105.817105 cuda_h.py:19] end wait_experts cost 0.006684541702270508 seconds
DEBUG 01-05 12:51:34.817146.817146 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.817856.817856 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.818231.818231 mlpmodule.py:531] gpu group tensors cost 0.0006463527679443359 s
DEBUG 01-05 12:51:34.820714.820714 mlpmodule.py:564] gpu pad cost 0.0017039775848388672 s
DEBUG 01-05 12:51:34.820210.820210 mlpmodule.py:582] gpu group einsum cost 0.0005090236663818359 s
DEBUG 01-05 12:51:34.823756.823756 mlpmodule.py:611] gpu experts func einsum cost 0.005843400955200195 s
DEBUG 01-05 12:51:34.823925.823925 cuda_h.py:19] end gpu_experts cost 0.006022930145263672 seconds
DEBUG 01-05 12:51:34.823225.823225 cuda_h.py:19] end layer_moe_generate_24 cost 0.06658744812011719 seconds
DEBUG 01-05 12:51:34.823708.823708 lmp.py:217] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 12:51:34.824087.824087 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 12:51:34.824591.824591 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 12:51:34.824440.824440 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 12:51:34.824322.824322 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 12:51:34.824330.824330 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.486343383789062e-05 seconds
DEBUG 01-05 12:51:34.824450.824450 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.824619.824619 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.824092.824092 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.824180.824180 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.824352.824352 cuda_h.py:19] end allocate_cuda_memory cost 0.00033020973205566406 seconds
DEBUG 01-05 12:51:34.824824.824824 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.824203.824203 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.824072.824072 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.824821.824821 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 417468ae-3559-4977-a76e-9e6a05900f59
DEBUG 01-05 12:51:34.825314.825314 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.825823.825823 mlpmodule.py:662]  experts func einsum cost 0.05455923080444336 s
DEBUG 01-05 12:51:34.825270.825270 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.826030.826030 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 417468ae-3559-4977-a76e-9e6a05900f59
DEBUG 01-05 12:51:34.826873.826873 cuda_h.py:19] end load_into_gpu_async cost 0.0016162395477294922 seconds
DEBUG 01-05 12:51:34.826907.826907 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.826506.826506 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-05 12:51:34.826070.826070 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022573471069335938 seconds
INFO 01-05 12:51:34.827981.827981 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 417468ae-3559-4977-a76e-9e6a05900f59
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.828812.828812 cuda_h.py:19] end self_attn cost 0.0032529830932617188 seconds
DEBUG 01-05 12:51:34.829299.829299 cuda_h.py:19] end iln_self_attn_paln cost 0.004950284957885742 seconds
DEBUG 01-05 12:51:34.829804.829804 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 12:51:34.829328.829328 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.829483.829483 cuda_h.py:19] end gate cost 0.0006420612335205078 seconds
DEBUG 01-05 12:51:34.829406.829406 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.830422.830422 lmp.py:365] 
DEBUG 01-05 12:51:34.830422.830422 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.830986.830986 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.830920.830920 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.830756.830756 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.830968.830968 lmp.py:369] 
DEBUG 01-05 12:51:34.830968.830968 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.830180.830180 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.830830.830830 lmp.py:376]   Expert 36 |     44 | CPU
DEBUG 01-05 12:51:34.830520.830520 lmp.py:376]   Expert 33 |     49 | CPU
DEBUG 01-05 12:51:34.830970.830970 lmp.py:376]   Expert 13 |     55 | CPU
DEBUG 01-05 12:51:34.830944.830944 lmp.py:376]   Expert 18 |     57 | CPU
DEBUG 01-05 12:51:34.830680.830680 lmp.py:376]   Expert 42 |     60 | CPU
DEBUG 01-05 12:51:34.830654.830654 lmp.py:376]   Expert  0 |     69 | CPU
DEBUG 01-05 12:51:34.830390.830390 lmp.py:376]   Expert 16 |     78 | CPU
DEBUG 01-05 12:51:34.830364.830364 lmp.py:376]   Expert 22 |     82 | CPU
DEBUG 01-05 12:51:34.830960.830960 lmp.py:376]   Expert 10 |     83 | CPU
DEBUG 01-05 12:51:34.830888.830888 lmp.py:376]   Expert 62 |     86 | CPU
DEBUG 01-05 12:51:34.830339.830339 lmp.py:376]   Expert 47 |     87 | CPU
DEBUG 01-05 12:51:34.830552.830552 lmp.py:376]   Expert 21 |     97 | CPU
DEBUG 01-05 12:51:34.830002.830002 lmp.py:376]   Expert 38 |    105 | CPU
DEBUG 01-05 12:51:34.830692.830692 lmp.py:376]   Expert  5 |    111 | CPU
DEBUG 01-05 12:51:34.830904.830904 lmp.py:376]   Expert 27 |    112 | CPU
DEBUG 01-05 12:51:34.830593.830593 lmp.py:376]   Expert 50 |    112 | CPU
DEBUG 01-05 12:51:34.830568.830568 lmp.py:376]   Expert 59 |    115 | CPU
DEBUG 01-05 12:51:34.830257.830257 lmp.py:376]   Expert 34 |    116 | CPU
DEBUG 01-05 12:51:34.830423.830423 lmp.py:376]   Expert 53 |    120 | CPU
DEBUG 01-05 12:51:34.830351.830351 lmp.py:376]   Expert 43 |    122 | CPU
DEBUG 01-05 12:51:34.830802.830802 lmp.py:376]   Expert  2 |    124 | CPU
DEBUG 01-05 12:51:34.830776.830776 lmp.py:376]   Expert 44 |    125 | CPU
DEBUG 01-05 12:51:34.830226.830226 lmp.py:376]   Expert 48 |    130 | CPU
DEBUG 01-05 12:51:34.830677.830677 lmp.py:376]   Expert 14 |    131 | CPU
DEBUG 01-05 12:51:34.830651.830651 lmp.py:376]   Expert 24 |    136 | CPU
DEBUG 01-05 12:51:34.830102.830102 lmp.py:376]   Expert 56 |    136 | CPU
DEBUG 01-05 12:51:34.830507.830507 lmp.py:376]   Expert 41 |    138 | CPU
DEBUG 01-05 12:51:34.830435.830435 lmp.py:376]   Expert 32 |    139 | CPU
DEBUG 01-05 12:51:34.830885.830885 lmp.py:376]   Expert 31 |    144 | CPU
DEBUG 01-05 12:51:34.830621.830621 lmp.py:376]   Expert 20 |    147 | CPU
DEBUG 01-05 12:51:34.830834.830834 lmp.py:376]   Expert 23 |    148 | CPU
DEBUG 01-05 12:51:34.830284.830284 lmp.py:376]   Expert  4 |    151 | CPU
DEBUG 01-05 12:51:34.830258.830258 lmp.py:376]   Expert 45 |    157 | GPU
DEBUG 01-05 12:51:34.830471.830471 lmp.py:376]   Expert  3 |    158 | GPU
DEBUG 01-05 12:51:34.830445.830445 lmp.py:376]   Expert 55 |    165 | GPU
DEBUG 01-05 12:51:34.830657.830657 lmp.py:376]   Expert 46 |    175 | GPU
DEBUG 01-05 12:51:34.830062.830062 lmp.py:376]   Expert 39 |    178 | GPU
DEBUG 01-05 12:51:34.830228.830228 lmp.py:376]   Expert 61 |    179 | GPU
DEBUG 01-05 12:51:34.831156.831156 lmp.py:376]   Expert  6 |    186 | GPU
DEBUG 01-05 12:51:34.831368.831368 lmp.py:376]   Expert 51 |    201 | GPU
DEBUG 01-05 12:51:34.831104.831104 lmp.py:376]   Expert 52 |    204 | GPU
DEBUG 01-05 12:51:34.831316.831316 lmp.py:376]   Expert  1 |    211 | GPU
DEBUG 01-05 12:51:34.831290.831290 lmp.py:376]   Expert 12 |    213 | GPU
DEBUG 01-05 12:51:34.831503.831503 lmp.py:376]   Expert  8 |    222 | GPU
DEBUG 01-05 12:51:34.831477.831477 lmp.py:376]   Expert 40 |    225 | GPU
DEBUG 01-05 12:51:34.831213.831213 lmp.py:376]   Expert 11 |    231 | GPU
DEBUG 01-05 12:51:34.831425.831425 lmp.py:376]   Expert 35 |    232 | GPU
DEBUG 01-05 12:51:34.831876.831876 lmp.py:376]   Expert  7 |    235 | GPU
DEBUG 01-05 12:51:34.831565.831565 lmp.py:376]   Expert 37 |    252 | GPU
DEBUG 01-05 12:51:34.831778.831778 lmp.py:376]   Expert 15 |    257 | GPU
DEBUG 01-05 12:51:34.831990.831990 lmp.py:376]   Expert 49 |    260 | GPU
DEBUG 01-05 12:51:34.831726.831726 lmp.py:376]   Expert 57 |    290 | GPU
DEBUG 01-05 12:51:34.831938.831938 lmp.py:376]   Expert 26 |    291 | GPU
DEBUG 01-05 12:51:34.831912.831912 lmp.py:376]   Expert 28 |    296 | GPU
DEBUG 01-05 12:51:34.831886.831886 lmp.py:376]   Expert 30 |    305 | GPU
DEBUG 01-05 12:51:34.831860.831860 lmp.py:376]   Expert 58 |    325 | GPU
DEBUG 01-05 12:51:34.831596.831596 lmp.py:376]   Expert 63 |    329 | GPU
DEBUG 01-05 12:51:34.831285.831285 lmp.py:376]   Expert 25 |    368 | GPU
DEBUG 01-05 12:51:34.831690.831690 lmp.py:376]   Expert 54 |    372 | GPU
DEBUG 01-05 12:51:34.831902.831902 lmp.py:376]   Expert  9 |    399 | GPU
DEBUG 01-05 12:51:34.831876.831876 lmp.py:376]   Expert 17 |    440 | GPU
DEBUG 01-05 12:51:34.831850.831850 lmp.py:376]   Expert 60 |    463 | GPU
DEBUG 01-05 12:51:34.831063.831063 lmp.py:376]   Expert 29 |    500 | GPU
DEBUG 01-05 12:51:34.831514.831514 lmp.py:376]   Expert 19 |    560 | GPU
DEBUG 01-05 12:51:34.831680.831680 lmp.py:377] 
DEBUG 01-05 12:51:34.831680.831680 lmp.py:377]   CPU total tokens: 3409 (27.7%)
DEBUG 01-05 12:51:34.831846.831846 lmp.py:378]   GPU total tokens: 8879 (72.3%)
DEBUG 01-05 12:51:34.831542.831542 cuda_h.py:19] end experts_map_get cost 0.0014770030975341797 seconds
DEBUG 01-05 12:51:34.831185.831185 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.831299.831299 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.831443.831443 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.833047.833047 cuda_h.py:19] end allocate_cuda_memory cost 0.001992464065551758 seconds
DEBUG 01-05 12:51:34.833818.833818 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.833620.833620 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.833430.833430 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.833795.833795 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5ab8ba04-9385-4690-8bc5-c77982ceebdb
DEBUG 01-05 12:51:34.834948.834948 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.834796.834796 client.py:127] Model loaded
DEBUG 01-05 12:51:34.834268.834268 cuda_h.py:19] end sllm_worker_task cost 0.010212898254394531 seconds
INFO 01-05 12:51:34.836951.836951 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5ab8ba04-9385-4690-8bc5-c77982ceebdb
DEBUG 01-05 12:51:34.836532.836532 cuda_h.py:19] end load_into_gpu_async cost 0.002479076385498047 seconds
DEBUG 01-05 12:51:34.836522.836522 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.836729.836729 cuda_h.py:19] end restore_tensors2 cost 0.0003643035888671875 seconds
DEBUG 01-05 12:51:34.836843.836843 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005330085754394531 seconds
DEBUG 01-05 12:51:34.839086.839086 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00790548324584961 seconds
DEBUG 01-05 12:51:34.839293.839293 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.839680.839680 lmp.py:423] 
DEBUG 01-05 12:51:34.839680.839680 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.839808.839808 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-05 12:51:34.839504.839504 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.849069.849069 mlpmodule.py:704] group tensors cost 0.01003408432006836 s
DEBUG 01-05 12:51:34.852797.852797 mlpmodule.py:742] pad cost 0.0015864372253417969 s
DEBUG 01-05 12:51:34.852802.852802 mlpmodule.py:748] create cpu tensor cost 6.151199340820312e-05 s
DEBUG 01-05 12:51:34.852056.852056 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 12:51:34.863677.863677 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.864961.864961 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.864461.864461 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 12:51:34.864737.864737 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.879485.879485 mlpmodule.py:793] group einsum cost 0.02736973762512207 s
DEBUG 01-05 12:51:34.880758.880758 mlpmodule.py:801] cpy2cputensor cost 0.0006308555603027344 s
DEBUG 01-05 12:51:34.885128.885128 cuda_h.py:19] end wait_cetm_experts cost 0.045472145080566406 seconds
DEBUG 01-05 12:51:34.885507.885507 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.886006.886006 cuda_h.py:19] end gpu_sexperts cost 0.0005879402160644531 seconds
DEBUG 01-05 12:51:34.886155.886155 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.886363.886363 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 12:51:34.886735.886735 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.886398.886398 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5ab8ba04-9385-4690-8bc5-c77982ceebdb
INFO 01-05 12:51:34.887899.887899 client.py:127] Model loaded
DEBUG 01-05 12:51:34.887505.887505 cuda_h.py:19] end wait_experts cost 0.001413583755493164 seconds
DEBUG 01-05 12:51:34.887182.887182 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.887415.887415 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.888387.888387 mlpmodule.py:531] gpu group tensors cost 0.0006661415100097656 s
DEBUG 01-05 12:51:34.890702.890702 mlpmodule.py:564] gpu pad cost 0.0017807483673095703 s
DEBUG 01-05 12:51:34.891181.891181 mlpmodule.py:582] gpu group einsum cost 0.000553131103515625 s
DEBUG 01-05 12:51:34.894267.894267 mlpmodule.py:611] gpu experts func einsum cost 0.006757259368896484 s
DEBUG 01-05 12:51:34.894026.894026 cuda_h.py:19] end gpu_experts cost 0.006981372833251953 seconds
DEBUG 01-05 12:51:34.894342.894342 cuda_h.py:19] end layer_moe_generate_25 cost 0.06567049026489258 seconds
DEBUG 01-05 12:51:34.895827.895827 lmp.py:217] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 12:51:34.895027.895027 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 12:51:34.895061.895061 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 12:51:34.895586.895586 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 12:51:34.895720.895720 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.457069396972656e-05 seconds
DEBUG 01-05 12:51:34.895715.895715 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.890296936035156e-05 seconds
DEBUG 01-05 12:51:34.895603.895603 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.895307.895307 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 12:51:34.895999.895999 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.895020.895020 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.900335.900335 cuda_h.py:19] end allocate_cuda_memory cost 0.004582405090332031 seconds
DEBUG 01-05 12:51:34.900708.900708 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.900705.900705 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.900958.900958 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.900900.900900 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7f604136-c825-4f36-88fd-dc845308808b
DEBUG 01-05 12:51:34.900585.900585 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 12:51:34.901811.901811 mlpmodule.py:662]  experts func einsum cost 0.0611112117767334 s
DEBUG 01-05 12:51:34.901822.901822 cuda_h.py:10] start self_attn
INFO 01-05 12:51:34.902593.902593 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7f604136-c825-4f36-88fd-dc845308808b
DEBUG 01-05 12:51:34.902913.902913 cuda_h.py:19] end load_into_gpu_async cost 0.0016632080078125 seconds
DEBUG 01-05 12:51:34.902901.902901 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.902222.902222 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-05 12:51:34.902309.902309 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006870746612548828 seconds
INFO 01-05 12:51:34.902524.902524 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7f604136-c825-4f36-88fd-dc845308808b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.904626.904626 cuda_h.py:19] end self_attn cost 0.003331899642944336 seconds
DEBUG 01-05 12:51:34.905999.905999 cuda_h.py:19] end iln_self_attn_paln cost 0.00963449478149414 seconds
DEBUG 01-05 12:51:34.905028.905028 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 12:51:34.905267.905267 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.905779.905779 cuda_h.py:19] end gate cost 0.0006256103515625 seconds
DEBUG 01-05 12:51:34.905463.905463 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.906864.906864 lmp.py:365] 
DEBUG 01-05 12:51:34.906864.906864 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.906428.906428 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.906885.906885 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.906197.906197 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.906602.906602 lmp.py:369] 
DEBUG 01-05 12:51:34.906602.906602 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.906291.906291 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.906371.906371 lmp.py:376]   Expert  3 |     59 | CPU
DEBUG 01-05 12:51:34.906253.906253 lmp.py:376]   Expert 17 |     62 | CPU
DEBUG 01-05 12:51:34.906657.906657 lmp.py:376]   Expert 62 |     64 | CPU
DEBUG 01-05 12:51:34.906585.906585 lmp.py:376]   Expert 49 |     66 | CPU
DEBUG 01-05 12:51:34.906513.906513 lmp.py:376]   Expert 30 |     67 | CPU
DEBUG 01-05 12:51:34.906440.906440 lmp.py:376]   Expert 59 |     71 | CPU
DEBUG 01-05 12:51:34.906368.906368 lmp.py:376]   Expert 58 |     74 | CPU
DEBUG 01-05 12:51:34.906057.906057 lmp.py:376]   Expert 19 |     77 | CPU
DEBUG 01-05 12:51:34.906177.906177 lmp.py:376]   Expert 24 |     79 | CPU
DEBUG 01-05 12:51:34.906820.906820 lmp.py:376]   Expert 61 |     79 | CPU
DEBUG 01-05 12:51:34.906225.906225 lmp.py:376]   Expert 51 |     81 | CPU
DEBUG 01-05 12:51:34.906629.906629 lmp.py:376]   Expert 55 |     81 | CPU
DEBUG 01-05 12:51:34.906795.906795 lmp.py:376]   Expert  9 |     85 | CPU
DEBUG 01-05 12:51:34.906485.906485 lmp.py:376]   Expert  7 |     91 | CPU
DEBUG 01-05 12:51:34.906412.906412 lmp.py:376]   Expert  8 |     93 | CPU
DEBUG 01-05 12:51:34.906863.906863 lmp.py:376]   Expert  6 |     96 | CPU
DEBUG 01-05 12:51:34.906314.906314 lmp.py:376]   Expert 56 |     97 | CPU
DEBUG 01-05 12:51:34.906004.906004 lmp.py:376]   Expert 60 |     97 | CPU
DEBUG 01-05 12:51:34.906693.906693 lmp.py:376]   Expert 15 |    100 | CPU
DEBUG 01-05 12:51:34.906144.906144 lmp.py:376]   Expert 21 |    102 | CPU
DEBUG 01-05 12:51:34.906595.906595 lmp.py:376]   Expert 12 |    112 | CPU
DEBUG 01-05 12:51:34.906284.906284 lmp.py:376]   Expert 11 |    114 | CPU
DEBUG 01-05 12:51:34.906688.906688 lmp.py:376]   Expert 43 |    117 | CPU
DEBUG 01-05 12:51:34.906855.906855 lmp.py:376]   Expert 13 |    120 | CPU
DEBUG 01-05 12:51:34.906259.906259 lmp.py:376]   Expert 27 |    139 | CPU
DEBUG 01-05 12:51:34.906187.906187 lmp.py:376]   Expert 47 |    139 | CPU
DEBUG 01-05 12:51:34.906591.906591 lmp.py:376]   Expert  0 |    140 | CPU
DEBUG 01-05 12:51:34.906281.906281 lmp.py:376]   Expert 29 |    140 | CPU
DEBUG 01-05 12:51:34.906732.906732 lmp.py:376]   Expert 38 |    140 | CPU
DEBUG 01-05 12:51:34.906183.906183 lmp.py:376]   Expert 26 |    142 | CPU
DEBUG 01-05 12:51:34.906633.906633 lmp.py:376]   Expert 28 |    144 | CPU
DEBUG 01-05 12:51:34.906084.906084 lmp.py:376]   Expert 41 |    144 | CPU
DEBUG 01-05 12:51:34.906535.906535 lmp.py:376]   Expert 53 |    145 | GPU
DEBUG 01-05 12:51:34.906986.906986 lmp.py:376]   Expert 22 |    147 | GPU
DEBUG 01-05 12:51:34.906675.906675 lmp.py:376]   Expert 45 |    150 | GPU
DEBUG 01-05 12:51:34.906649.906649 lmp.py:376]   Expert 34 |    165 | GPU
DEBUG 01-05 12:51:34.906100.906100 lmp.py:376]   Expert 48 |    168 | GPU
DEBUG 01-05 12:51:34.906266.906266 lmp.py:376]   Expert 57 |    176 | GPU
DEBUG 01-05 12:51:34.906194.906194 lmp.py:376]   Expert 37 |    180 | GPU
DEBUG 01-05 12:51:34.906883.906883 lmp.py:376]   Expert 32 |    188 | GPU
DEBUG 01-05 12:51:34.906050.906050 lmp.py:376]   Expert  1 |    189 | GPU
DEBUG 01-05 12:51:34.906739.906739 lmp.py:376]   Expert 23 |    198 | GPU
DEBUG 01-05 12:51:34.906951.906951 lmp.py:376]   Expert 42 |    203 | GPU
DEBUG 01-05 12:51:34.907641.907641 lmp.py:376]   Expert 36 |    211 | GPU
DEBUG 01-05 12:51:34.907330.907330 lmp.py:376]   Expert 54 |    222 | GPU
DEBUG 01-05 12:51:34.907781.907781 lmp.py:376]   Expert 39 |    228 | GPU
DEBUG 01-05 12:51:34.907993.907993 lmp.py:376]   Expert  4 |    229 | GPU
DEBUG 01-05 12:51:34.907444.907444 lmp.py:376]   Expert 31 |    247 | GPU
DEBUG 01-05 12:51:34.907372.907372 lmp.py:376]   Expert 16 |    251 | GPU
DEBUG 01-05 12:51:34.907776.907776 lmp.py:376]   Expert 20 |    269 | GPU
DEBUG 01-05 12:51:34.907466.907466 lmp.py:376]   Expert 33 |    271 | GPU
DEBUG 01-05 12:51:34.907678.907678 lmp.py:376]   Expert  2 |    287 | GPU
DEBUG 01-05 12:51:34.907129.907129 lmp.py:376]   Expert 44 |    307 | GPU
DEBUG 01-05 12:51:34.907580.907580 lmp.py:376]   Expert 18 |    314 | GPU
DEBUG 01-05 12:51:34.907031.907031 lmp.py:376]   Expert 25 |    321 | GPU
DEBUG 01-05 12:51:34.907243.907243 lmp.py:376]   Expert  5 |    328 | GPU
DEBUG 01-05 12:51:34.907694.907694 lmp.py:376]   Expert 50 |    328 | GPU
DEBUG 01-05 12:51:34.907383.907383 lmp.py:376]   Expert 10 |    359 | GPU
DEBUG 01-05 12:51:34.907073.907073 lmp.py:376]   Expert 35 |    367 | GPU
DEBUG 01-05 12:51:34.907524.907524 lmp.py:376]   Expert 63 |    398 | GPU
DEBUG 01-05 12:51:34.907928.907928 lmp.py:376]   Expert 40 |    453 | GPU
DEBUG 01-05 12:51:34.907571.907571 lmp.py:376]   Expert 46 |    460 | GPU
DEBUG 01-05 12:51:34.907261.907261 lmp.py:376]   Expert 52 |    511 | GPU
DEBUG 01-05 12:51:34.907711.907711 lmp.py:376]   Expert 14 |    806 | GPU
DEBUG 01-05 12:51:34.907116.907116 lmp.py:377] 
DEBUG 01-05 12:51:34.907116.907116 lmp.py:377]   CPU total tokens: 3212 (26.1%)
DEBUG 01-05 12:51:34.907282.907282 lmp.py:378]   GPU total tokens: 9076 (73.9%)
DEBUG 01-05 12:51:34.907740.907740 cuda_h.py:19] end experts_map_get cost 0.0015113353729248047 seconds
DEBUG 01-05 12:51:34.907621.907621 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.907451.907451 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.907733.907733 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.909795.909795 cuda_h.py:19] end allocate_cuda_memory cost 0.0018024444580078125 seconds
DEBUG 01-05 12:51:34.909830.909830 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.909394.909394 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.909534.909534 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.909614.909614 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c24b0196-a903-41b8-80e8-4cf2e134461c
DEBUG 01-05 12:51:34.909720.909720 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.910648.910648 client.py:127] Model loaded
DEBUG 01-05 12:51:34.910167.910167 cuda_h.py:19] end sllm_worker_task cost 0.01473689079284668 seconds
INFO 01-05 12:51:34.911011.911011 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c24b0196-a903-41b8-80e8-4cf2e134461c
DEBUG 01-05 12:51:34.911616.911616 cuda_h.py:19] end load_into_gpu_async cost 0.002267122268676758 seconds
DEBUG 01-05 12:51:34.911100.911100 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.912920.912920 cuda_h.py:19] end restore_tensors2 cost 0.00033354759216308594 seconds
DEBUG 01-05 12:51:34.912081.912081 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004761457443237305 seconds
DEBUG 01-05 12:51:34.914743.914743 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007366657257080078 seconds
DEBUG 01-05 12:51:34.914811.914811 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.914264.914264 lmp.py:423] 
DEBUG 01-05 12:51:34.914264.914264 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.915107.915107 cuda_h.py:19] end cpu_experts_submit cost 0.00012183189392089844 seconds
DEBUG 01-05 12:51:34.915234.915234 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.926594.926594 mlpmodule.py:704] group tensors cost 0.011037111282348633 s
DEBUG 01-05 12:51:34.930120.930120 mlpmodule.py:742] pad cost 0.002935647964477539 s
DEBUG 01-05 12:51:34.930158.930158 mlpmodule.py:748] create cpu tensor cost 5.3882598876953125e-05 s
DEBUG 01-05 12:51:34.930266.930266 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 12:51:34.939225.939225 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:34.939661.939661 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:34.939459.939459 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 12:51:34.939166.939166 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:34.954663.954663 mlpmodule.py:793] group einsum cost 0.02341461181640625 s
DEBUG 01-05 12:51:34.954061.954061 mlpmodule.py:801] cpy2cputensor cost 0.000606536865234375 s
DEBUG 01-05 12:51:34.959542.959542 cuda_h.py:19] end wait_cetm_experts cost 0.0443272590637207 seconds
DEBUG 01-05 12:51:34.959249.959249 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:34.960415.960415 cuda_h.py:19] end gpu_sexperts cost 0.0005712509155273438 seconds
DEBUG 01-05 12:51:34.960927.960927 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:34.960023.960023 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 12:51:34.960110.960110 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:34.960702.960702 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c24b0196-a903-41b8-80e8-4cf2e134461c
INFO 01-05 12:51:34.962602.962602 client.py:127] Model loaded
DEBUG 01-05 12:51:34.962591.962591 cuda_h.py:19] end wait_experts cost 0.0016379356384277344 seconds
DEBUG 01-05 12:51:34.962539.962539 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:34.962772.962772 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:34.962671.962671 mlpmodule.py:531] gpu group tensors cost 0.0006461143493652344 s
DEBUG 01-05 12:51:34.964057.964057 mlpmodule.py:564] gpu pad cost 0.001773834228515625 s
DEBUG 01-05 12:51:34.965957.965957 mlpmodule.py:582] gpu group einsum cost 0.0005249977111816406 s
DEBUG 01-05 12:51:34.968613.968613 mlpmodule.py:611] gpu experts func einsum cost 0.00664067268371582 s
DEBUG 01-05 12:51:34.968703.968703 cuda_h.py:19] end gpu_experts cost 0.006832599639892578 seconds
DEBUG 01-05 12:51:34.969395.969395 cuda_h.py:19] end layer_moe_generate_26 cost 0.06393265724182129 seconds
DEBUG 01-05 12:51:34.969462.969462 lmp.py:217] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 12:51:34.969085.969085 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 12:51:34.969358.969358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 12:51:34.969651.969651 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.2159347534179688e-05 seconds
DEBUG 01-05 12:51:34.969969.969969 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 12:51:34.969258.969258 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 12:51:34.972126.972126 cuda_h.py:19] end self_attn cost 0.002516508102416992 seconds
DEBUG 01-05 12:51:34.972507.972507 cuda_h.py:19] end iln_self_attn_paln cost 0.0031638145446777344 seconds
DEBUG 01-05 12:51:34.972827.972827 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 12:51:34.972928.972928 cuda_h.py:10] start gate
DEBUG 01-05 12:51:34.972020.972020 mlpmodule.py:662]  experts func einsum cost 0.057595014572143555 s
DEBUG 01-05 12:51:34.974957.974957 cuda_h.py:19] end gate cost 0.0012378692626953125 seconds
DEBUG 01-05 12:51:34.974225.974225 cuda_h.py:10] start experts_map_get
DEBUG 01-05 12:51:34.974964.974964 lmp.py:365] 
DEBUG 01-05 12:51:34.974964.974964 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 12:51:34.974766.974766 lmp.py:366]   Total experts: 64
DEBUG 01-05 12:51:34.974224.974224 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 12:51:34.974344.974344 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 12:51:34.974318.974318 lmp.py:369] 
DEBUG 01-05 12:51:34.974318.974318 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 12:51:34.974245.974245 lmp.py:370]   -----------------------------------
DEBUG 01-05 12:51:34.974465.974465 lmp.py:376]   Expert 18 |     38 | CPU
DEBUG 01-05 12:51:34.974916.974916 lmp.py:376]   Expert 47 |     45 | CPU
DEBUG 01-05 12:51:34.974413.974413 lmp.py:376]   Expert 54 |     58 | CPU
DEBUG 01-05 12:51:34.974387.974387 lmp.py:376]   Expert 58 |     68 | CPU
DEBUG 01-05 12:51:34.974361.974361 lmp.py:376]   Expert 15 |     69 | CPU
DEBUG 01-05 12:51:34.974620.974620 lmp.py:376]   Expert 24 |     75 | CPU
DEBUG 01-05 12:51:34.974640.974640 lmp.py:376]   Expert 32 |     80 | CPU
DEBUG 01-05 12:51:34.974422.974422 lmp.py:376]   Expert 59 |     80 | CPU
DEBUG 01-05 12:51:34.974681.974681 lmp.py:376]   Expert  7 |     81 | CPU
DEBUG 01-05 12:51:34.974701.974701 lmp.py:376]   Expert 38 |     86 | CPU
DEBUG 01-05 12:51:34.974722.974722 lmp.py:376]   Expert 12 |     90 | CPU
DEBUG 01-05 12:51:34.974980.974980 lmp.py:376]   Expert 11 |     92 | CPU
DEBUG 01-05 12:51:34.974001.974001 lmp.py:376]   Expert 61 |     95 | CPU
DEBUG 01-05 12:51:34.974452.974452 lmp.py:376]   Expert 42 |    110 | CPU
DEBUG 01-05 12:51:34.974949.974949 lmp.py:376]   Expert  6 |    117 | CPU
DEBUG 01-05 12:51:34.974446.974446 lmp.py:376]   Expert 23 |    118 | CPU
DEBUG 01-05 12:51:34.974228.974228 lmp.py:376]   Expert 40 |    118 | CPU
DEBUG 01-05 12:51:34.974248.974248 lmp.py:376]   Expert 46 |    119 | CPU
DEBUG 01-05 12:51:34.974792.974792 lmp.py:376]   Expert 52 |    124 | CPU
DEBUG 01-05 12:51:34.974812.974812 lmp.py:376]   Expert 45 |    125 | CPU
DEBUG 01-05 12:51:34.974594.974594 lmp.py:376]   Expert 39 |    133 | CPU
DEBUG 01-05 12:51:34.974138.974138 lmp.py:376]   Expert 34 |    136 | CPU
DEBUG 01-05 12:51:34.974158.974158 lmp.py:376]   Expert 44 |    139 | CPU
DEBUG 01-05 12:51:34.974940.974940 lmp.py:376]   Expert 51 |    146 | CPU
DEBUG 01-05 12:51:34.974437.974437 lmp.py:376]   Expert 48 |    148 | CPU
DEBUG 01-05 12:51:34.974696.974696 lmp.py:376]   Expert  3 |    153 | CPU
DEBUG 01-05 12:51:34.974240.974240 lmp.py:376]   Expert 30 |    156 | CPU
DEBUG 01-05 12:51:34.974022.974022 lmp.py:376]   Expert 10 |    158 | CPU
DEBUG 01-05 12:51:34.974042.974042 lmp.py:376]   Expert 16 |    166 | CPU
DEBUG 01-05 12:51:34.974824.974824 lmp.py:376]   Expert 56 |    178 | CPU
DEBUG 01-05 12:51:34.974367.974367 lmp.py:376]   Expert 31 |    181 | CPU
DEBUG 01-05 12:51:34.975911.975911 lmp.py:376]   Expert 29 |    185 | CPU
DEBUG 01-05 12:51:34.975454.975454 lmp.py:376]   Expert 25 |    188 | GPU
DEBUG 01-05 12:51:34.975475.975475 lmp.py:376]   Expert 22 |    189 | GPU
DEBUG 01-05 12:51:34.975734.975734 lmp.py:376]   Expert  1 |    192 | GPU
DEBUG 01-05 12:51:34.975992.975992 lmp.py:376]   Expert 19 |    192 | GPU
DEBUG 01-05 12:51:34.975774.975774 lmp.py:376]   Expert  4 |    193 | GPU
DEBUG 01-05 12:51:34.975318.975318 lmp.py:376]   Expert 13 |    195 | GPU
DEBUG 01-05 12:51:34.975861.975861 lmp.py:376]   Expert 17 |    198 | GPU
DEBUG 01-05 12:51:34.975643.975643 lmp.py:376]   Expert 50 |    198 | GPU
DEBUG 01-05 12:51:34.975948.975948 lmp.py:376]   Expert 62 |    204 | GPU
DEBUG 01-05 12:51:34.975730.975730 lmp.py:376]   Expert 33 |    207 | GPU
DEBUG 01-05 12:51:34.975274.975274 lmp.py:376]   Expert 36 |    208 | GPU
DEBUG 01-05 12:51:34.975818.975818 lmp.py:376]   Expert 57 |    213 | GPU
DEBUG 01-05 12:51:34.975361.975361 lmp.py:376]   Expert  5 |    221 | GPU
DEBUG 01-05 12:51:34.975620.975620 lmp.py:376]   Expert  8 |    228 | GPU
DEBUG 01-05 12:51:34.975640.975640 lmp.py:376]   Expert 55 |    228 | GPU
DEBUG 01-05 12:51:34.975422.975422 lmp.py:376]   Expert 53 |    242 | GPU
DEBUG 01-05 12:51:34.975727.975727 lmp.py:376]   Expert 26 |    244 | GPU
DEBUG 01-05 12:51:34.975509.975509 lmp.py:376]   Expert  0 |    249 | GPU
DEBUG 01-05 12:51:34.975053.975053 lmp.py:376]   Expert 41 |    249 | GPU
DEBUG 01-05 12:51:34.975596.975596 lmp.py:376]   Expert 49 |    250 | GPU
DEBUG 01-05 12:51:34.975901.975901 lmp.py:376]   Expert 35 |    268 | GPU
DEBUG 01-05 12:51:34.975445.975445 lmp.py:376]   Expert 28 |    277 | GPU
DEBUG 01-05 12:51:34.975988.975988 lmp.py:376]   Expert 37 |    289 | GPU
DEBUG 01-05 12:51:34.975009.975009 lmp.py:376]   Expert 14 |    313 | GPU
DEBUG 01-05 12:51:34.975791.975791 lmp.py:376]   Expert 27 |    343 | GPU
DEBUG 01-05 12:51:34.975050.975050 lmp.py:376]   Expert 21 |    357 | GPU
DEBUG 01-05 12:51:34.975070.975070 lmp.py:376]   Expert  2 |    359 | GPU
DEBUG 01-05 12:51:34.975852.975852 lmp.py:376]   Expert 60 |    388 | GPU
DEBUG 01-05 12:51:34.975395.975395 lmp.py:376]   Expert  9 |    390 | GPU
DEBUG 01-05 12:51:34.975177.975177 lmp.py:376]   Expert 43 |    399 | GPU
DEBUG 01-05 12:51:34.975198.975198 lmp.py:376]   Expert 63 |    449 | GPU
DEBUG 01-05 12:51:34.975741.975741 lmp.py:376]   Expert 20 |    501 | GPU
DEBUG 01-05 12:51:34.975715.975715 lmp.py:377] 
DEBUG 01-05 12:51:34.975715.975715 lmp.py:377]   CPU total tokens: 3667 (29.8%)
DEBUG 01-05 12:51:34.975451.975451 lmp.py:378]   GPU total tokens: 8621 (70.2%)
DEBUG 01-05 12:51:34.975240.975240 cuda_h.py:19] end experts_map_get cost 0.0013885498046875 seconds
DEBUG 01-05 12:51:34.975691.975691 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 12:51:34.975613.975613 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 12:51:34.975518.975518 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 12:51:34.976312.976312 cuda_h.py:19] end allocate_cuda_memory cost 0.0003421306610107422 seconds
DEBUG 01-05 12:51:34.976354.976354 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 12:51:34.976441.976441 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 12:51:34.976350.976350 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 12:51:34.976999.976999 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 34bbf365-853c-4b47-aa04-78c3932b8bbe
DEBUG 01-05 12:51:34.976370.976370 client.py:106] call stub.LoadModelAsync
INFO 01-05 12:51:34.978881.978881 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 34bbf365-853c-4b47-aa04-78c3932b8bbe
DEBUG 01-05 12:51:34.978479.978479 cuda_h.py:19] end load_into_gpu_async cost 0.002309560775756836 seconds
DEBUG 01-05 12:51:34.978321.978321 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 12:51:34.978730.978730 cuda_h.py:19] end restore_tensors2 cost 0.0003483295440673828 seconds
DEBUG 01-05 12:51:34.978222.978222 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033426284790039062 seconds
DEBUG 01-05 12:51:34.981222.981222 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005948781967163086 seconds
DEBUG 01-05 12:51:34.981435.981435 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:34.981180.981180 lmp.py:423] 
DEBUG 01-05 12:51:34.981180.981180 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 12:51:34.981745.981745 cuda_h.py:19] end cpu_experts_submit cost 0.00011444091796875 seconds
DEBUG 01-05 12:51:34.981349.981349 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:34.995895.995895 mlpmodule.py:704] group tensors cost 0.01345515251159668 s
DEBUG 01-05 12:51:34.998963.998963 mlpmodule.py:742] pad cost 0.00215911865234375 s
DEBUG 01-05 12:51:34.998246.998246 mlpmodule.py:748] create cpu tensor cost 5.650520324707031e-05 s
DEBUG 01-05 12:51:34.998838.998838 mlpmodule.py:753] move to cpu cost 3.814697265625e-05 s
DEBUG 01-05 12:51:35.008286.008286 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 12:51:35.008569.008569 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:35.008157.008157 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 12:51:35.008903.008903 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:35.023668.023668 mlpmodule.py:793] group einsum cost 0.025101661682128906 s
DEBUG 01-05 12:51:35.024957.024957 mlpmodule.py:801] cpy2cputensor cost 0.0007042884826660156 s
DEBUG 01-05 12:51:35.029744.029744 cuda_h.py:19] end wait_cetm_experts cost 0.04734015464782715 seconds
DEBUG 01-05 12:51:35.029723.029723 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:35.029082.029082 cuda_h.py:19] end gpu_sexperts cost 0.0005724430084228516 seconds
DEBUG 01-05 12:51:35.030832.030832 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 12:51:35.030807.030807 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1682510375976562e-05 seconds
DEBUG 01-05 12:51:35.030987.030987 cuda_h.py:10] start wait_experts
INFO 01-05 12:51:35.030458.030458 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 34bbf365-853c-4b47-aa04-78c3932b8bbe
INFO 01-05 12:51:35.031188.031188 client.py:127] Model loaded
DEBUG 01-05 12:51:35.031416.031416 cuda_h.py:19] end wait_experts cost 0.001302957534790039 seconds
DEBUG 01-05 12:51:35.031649.031649 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:35.031073.031073 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 12:51:35.032555.032555 mlpmodule.py:531] gpu group tensors cost 0.0006554126739501953 s
DEBUG 01-05 12:51:35.034788.034788 mlpmodule.py:564] gpu pad cost 0.0017666816711425781 s
DEBUG 01-05 12:51:35.034960.034960 mlpmodule.py:582] gpu group einsum cost 0.0005128383636474609 s
DEBUG 01-05 12:51:35.038952.038952 mlpmodule.py:611] gpu experts func einsum cost 0.006563663482666016 s
DEBUG 01-05 12:51:35.038910.038910 cuda_h.py:19] end gpu_experts cost 0.006794929504394531 seconds
DEBUG 01-05 12:51:35.038298.038298 cuda_h.py:19] end layer_moe_generate_27 cost 0.0656578540802002 seconds
DEBUG 01-05 12:51:35.038412.038412 lmp.py:217] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 12:51:35.038850.038850 cuda_h.py:19] end multi_layer cost 2.4354071617126465 seconds
DEBUG 01-05 12:51:35.038838.038838 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 12:51:35.041788.041788 cuda_h.py:19] end init_inputs_tokens cost 0.0030198097229003906 seconds
DEBUG 01-05 12:51:35.041830.041830 lmp.py:286] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 12:51:35.041056.041056 cuda_h.py:10] start dense_mlp
DEBUG 01-05 12:51:35.042573.042573 lmp.py:289] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 12:51:35.042410.042410 cuda_h.py:19] end dense_mlp cost 0.0006530284881591797 seconds
DEBUG 01-05 12:51:35.042589.042589 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 12:51:35.042915.042915 cuda_h.py:10] start gate
DEBUG 01-05 12:51:35.042710.042710 mlpmodule.py:662]  experts func einsum cost 0.06075906753540039 s
DEBUG 01-05 12:51:35.043880.043880 cuda_h.py:19] end gate cost 0.0007007122039794922 seconds
DEBUG 01-05 12:51:35.043426.043426 cuda_h.py:10] start experts_map_get
INFO 01-05 12:51:35.044634.044634 lmp.py:578] 
INFO 01-05 12:51:35.044634.044634 lmp.py:578] Layer 1 Expert Device Distribution:
INFO 01-05 12:51:35.044258.044258 lmp.py:579]   Active experts: 50 (out of 64 total)
INFO 01-05 12:51:35.044477.044477 lmp.py:580] 
INFO 01-05 12:51:35.044477.044477 lmp.py:580]   Detailed Expert Distribution:
INFO 01-05 12:51:35.044034.044034 lmp.py:581]   Expert ID  | Tokens     | Actual Device  
INFO 01-05 12:51:35.044154.044154 lmp.py:582]   ----------------------------------------------------------------------
INFO 01-05 12:51:35.044513.044513 lmp.py:585]   8          | 1          |  cuda:1         
INFO 01-05 12:51:35.044440.044440 lmp.py:585]   12         | 1          |  cuda:1         
INFO 01-05 12:51:35.044130.044130 lmp.py:585]   17         | 1          |  meta           
INFO 01-05 12:51:35.044342.044342 lmp.py:585]   19         | 1          |  cuda:1         
INFO 01-05 12:51:35.044554.044554 lmp.py:585]   22         | 1          |  meta           
INFO 01-05 12:51:35.044529.044529 lmp.py:585]   28         | 1          |  meta           
INFO 01-05 12:51:35.044503.044503 lmp.py:585]   29         | 1          |  meta           
INFO 01-05 12:51:35.044238.044238 lmp.py:585]   30         | 1          |  meta           
INFO 01-05 12:51:35.044451.044451 lmp.py:585]   48         | 1          |  cuda:1         
INFO 01-05 12:51:35.044425.044425 lmp.py:585]   49         | 1          |  meta           
INFO 01-05 12:51:35.044922.044922 lmp.py:585]   50         | 1          |  cuda:1         
INFO 01-05 12:51:35.044896.044896 lmp.py:585]   52         | 1          |  meta           
INFO 01-05 12:51:35.044837.044837 lmp.py:585]   53         | 1          |  meta           
INFO 01-05 12:51:35.044811.044811 lmp.py:585]   54         | 1          |  meta           
INFO 01-05 12:51:35.044024.044024 lmp.py:585]   55         | 1          |  meta           
INFO 01-05 12:51:35.044759.044759 lmp.py:585]   1          | 2          |  meta           
INFO 01-05 12:51:35.044495.044495 lmp.py:585]   9          | 2          |  cuda:1         
INFO 01-05 12:51:35.044231.044231 lmp.py:585]   35         | 2          |  cuda:1         
INFO 01-05 12:51:35.044443.044443 lmp.py:585]   38         | 2          |  meta           
INFO 01-05 12:51:35.044702.044702 lmp.py:585]   40         | 2          |  cuda:1         
INFO 01-05 12:51:35.044438.044438 lmp.py:585]   41         | 2          |  meta           
INFO 01-05 12:51:35.044935.044935 lmp.py:585]   43         | 2          |  cuda:1         
INFO 01-05 12:51:35.044909.044909 lmp.py:585]   45         | 2          |  cuda:1         
INFO 01-05 12:51:35.044168.044168 lmp.py:585]   16         | 3          |  cuda:1         
INFO 01-05 12:51:35.044618.044618 lmp.py:585]   33         | 3          |  meta           
INFO 01-05 12:51:35.044308.044308 lmp.py:585]   47         | 3          |  meta           
INFO 01-05 12:51:35.044043.044043 lmp.py:585]   0          | 4          |  meta           
INFO 01-05 12:51:35.044017.044017 lmp.py:585]   4          | 4          |  meta           
INFO 01-05 12:51:35.044753.044753 lmp.py:585]   59         | 4          |  cuda:1         
INFO 01-05 12:51:35.044012.044012 lmp.py:585]   60         | 4          |  cuda:1         
INFO 01-05 12:51:35.044986.044986 lmp.py:585]   2          | 5          |  cuda:1         
INFO 01-05 12:51:35.044483.044483 lmp.py:585]   5          | 5          |  cuda:1         
INFO 01-05 12:51:35.044219.044219 lmp.py:585]   7          | 5          |  cuda:1         
INFO 01-05 12:51:35.044716.044716 lmp.py:585]   10         | 5          |  cuda:1         
INFO 01-05 12:51:35.044928.044928 lmp.py:585]   11         | 5          |  meta           
INFO 01-05 12:51:35.044902.044902 lmp.py:585]   15         | 5          |  meta           
INFO 01-05 12:51:35.044638.044638 lmp.py:585]   23         | 5          |  cuda:1         
INFO 01-05 12:51:35.044135.044135 lmp.py:585]   26         | 5          |  cuda:1         
INFO 01-05 12:51:35.044109.044109 lmp.py:585]   44         | 5          |  cuda:1         
INFO 01-05 12:51:35.044607.044607 lmp.py:585]   46         | 5          |  cuda:1         
INFO 01-05 12:51:35.044342.044342 lmp.py:585]   42         | 6          |  cuda:1         
INFO 01-05 12:51:35.044839.044839 lmp.py:585]   61         | 6          |  cuda:1         
INFO 01-05 12:51:35.044337.044337 lmp.py:585]   6          | 7          |  cuda:1         
INFO 01-05 12:51:35.044357.044357 lmp.py:585]   14         | 8          |  cuda:1         
INFO 01-05 12:51:35.044761.044761 lmp.py:585]   20         | 8          |  cuda:1         
INFO 01-05 12:51:35.044212.044212 lmp.py:585]   24         | 8          |  cuda:1         
INFO 01-05 12:51:35.044710.044710 lmp.py:585]   63         | 8          |  cuda:1         
INFO 01-05 12:51:35.044445.044445 lmp.py:585]   34         | 10         |  cuda:1         
INFO 01-05 12:51:35.044942.044942 lmp.py:585]   31         | 12         |  meta           
INFO 01-05 12:51:35.044440.044440 lmp.py:585]   57         | 13         |  cuda:1         
INFO 01-05 12:51:35.045222.045222 lmp.py:586] ============================================================
INFO 01-05 12:51:35.045222.045222 lmp.py:586] 
INFO 01-05 12:51:35.045772.045772 lmp.py:588] experts_gpu_list: [8, 12, 19, 48, 50, 9, 35, 40, 43, 45, 16, 59, 60, 2, 5, 7, 10, 23, 26, 44, 46, 42, 61, 6, 14, 20, 24, 63, 34, 57]
INFO 01-05 12:51:35.045176.045176 lmp.py:589] experts_cpu_list: [17, 22, 28, 29, 30, 49, 52, 53, 54, 55, 1, 38, 41, 33, 47, 0, 4, 11, 15, 31]
INFO 01-05 12:51:35.045370.045370 lmp.py:590] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-05 12:51:35.045457.045457 cuda_h.py:19] end experts_map_get cost 0.0016791820526123047 seconds
DEBUG 01-05 12:51:35.045598.045598 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 12:51:35.045580.045580 lmp.py:600] 
DEBUG 01-05 12:51:35.045580.045580 lmp.py:600]   Computing 20 experts on CPU...
DEBUG 01-05 12:51:35.045569.045569 cuda_h.py:19] end cpu_experts_submit cost 8.869171142578125e-05 seconds
DEBUG 01-05 12:51:35.045841.045841 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 12:51:35.049153.049153 mlpmodule.py:704] group tensors cost 0.0037620067596435547 s
DEBUG 01-05 12:51:35.050324.050324 mlpmodule.py:742] pad cost 0.0010590553283691406 s
DEBUG 01-05 12:51:35.050043.050043 mlpmodule.py:748] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-05 12:51:35.051131.051131 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-05 12:51:35.054578.054578 mlpmodule.py:767] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-05 12:51:35.054726.054726 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 12:51:35.054576.054576 mlpmodule.py:773] group_w3 first element: 0.016845703125
WARNING 01-05 12:51:35.054658.054658 mlpmodule.py:783] start einsum2
DEBUG 01-05 12:51:35.060237.060237 mlpmodule.py:793] group einsum cost 0.009224653244018555 s
DEBUG 01-05 12:51:35.060813.060813 mlpmodule.py:801] cpy2cputensor cost 7.62939453125e-05 s
DEBUG 01-05 12:51:35.063099.063099 cuda_h.py:19] end wait_cetm_experts cost 0.018086910247802734 seconds
DEBUG 01-05 12:51:35.063338.063338 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 12:51:35.064426.064426 cuda_h.py:19] end gpu_sexperts cost 0.0007870197296142578 seconds
DEBUG 01-05 12:51:35.064197.064197 cuda_h.py:10] start gpu_experts
DEBUG 01-05 12:51:35.065791.065791 mlpmodule.py:531] gpu group tensors cost 0.000980377197265625 s
DEBUG 01-05 12:51:35.067498.067498 mlpmodule.py:564] gpu pad cost 0.001667022705078125 s
DEBUG 01-05 12:51:35.068585.068585 mlpmodule.py:582] gpu group einsum cost 0.0005393028259277344 s
DEBUG 01-05 12:51:35.071723.071723 mlpmodule.py:611] gpu experts func einsum cost 0.006692647933959961 s
DEBUG 01-05 12:51:35.071389.071389 cuda_h.py:19] end gpu_experts cost 0.006869077682495117 seconds
DEBUG 01-05 12:51:35.071842.071842 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.02909374237060547 seconds
DEBUG 01-05 12:51:35.099444.099444 mlpmodule.py:662]  experts func einsum cost 0.0540158748626709 s
Collecting data...
Generating '/tmp/nsys-report-f445.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [11%                         ] report1.nsys-rep[1/1] [=15%                        ] report1.nsys-rep[1/1] [==19%                       ] report1.nsys-rep[1/1] [===24%                      ] report1.nsys-rep[1/1] [=====29%                    ] report1.nsys-rep[1/1] [======34%                   ] report1.nsys-rep[1/1] [=======39%                  ] report1.nsys-rep[1/1] [=========44%                ] report1.nsys-rep[1/1] [==========49%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
