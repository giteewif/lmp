here pin
INFO 01-15 10:09:00.989692.989692 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-15 10:09:01.817152.817152 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-15 10:09:02.257832.257832 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-15 10:09:02.257229.257229 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.268s
DEBUG 01-15 10:09:04.607713.607713 cuda_memory_view.py:613] 
DEBUG 01-15 10:09:04.607713.607713 cuda_memory_view.py:613] restore_tensors_from_shared_memory_names time: 0.012871980667114258
DEBUG 01-15 10:09:04.624663.624663 cuda_h.py:10] start init_mp_process
DEBUG 01-15 10:09:04.659316.659316 cuda_h.py:19] end init_mp_process cost 0.03578472137451172 seconds
here pin
INFO 01-15 10:09:06.306823.306823 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-15 10:09:06.662384.662384 cuda_h.py:10] start generate_input_ids
DEBUG 01-15 10:09:07.132751.132751 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
generate input ids cost 0.11962890625 s
DEBUG 01-15 10:09:07.195499.195499 cuda_h.py:19] end generate_input_ids cost 0.5330700874328613 seconds
DEBUG 01-15 10:09:07.195385.195385 cuda_h.py:10] start init_cache
DEBUG 01-15 10:09:07.195667.195667 cuda_h.py:19] end init_cache cost 6.103515625e-05 seconds
DEBUG 01-15 10:09:07.595258.595258 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-15 10:09:07.595603.595603 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.289s
DEBUG 01-15 10:09:09.814049.814049 cpu_thread_manager_mp.py:78] 初始化
DEBUG 01-15 10:09:09.918969.918969 cuda_memory_view.py:613] 
DEBUG 01-15 10:09:09.918969.918969 cuda_memory_view.py:613] restore_tensors_from_shared_memory_names time: 0.015019655227661133
DEBUG 01-15 10:09:10.033617.033617 cuda_h.py:10] start init_meta_layer
DEBUG 01-15 10:09:10.034732.034732 cuda_h.py:19] end init_meta_layer cost 1.2874603271484375e-05 seconds
DEBUG 01-15 10:09:10.034534.034534 cuda_h.py:10] start init_weights
DEBUG 01-15 10:09:10.034536.034536 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:10.034067.034067 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:10.034695.034695 cuda_h.py:19] end allocate_cuda_memory cost 0.0005273818969726562 seconds
DEBUG 01-15 10:09:10.034924.034924 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:10.034952.034952 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:10.035299.035299 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:10.035532.035532 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e57484fb-ff1e-4ce1-bbe7-4e67ab81571c
DEBUG 01-15 10:09:10.035119.035119 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:10.037910.037910 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e57484fb-ff1e-4ce1-bbe7-4e67ab81571c
DEBUG 01-15 10:09:10.037603.037603 cuda_h.py:19] end load_into_gpu_async cost 0.00225067138671875 seconds
DEBUG 01-15 10:09:10.037856.037856 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:10.037986.037986 cuda_h.py:19] end restore_tensors2 cost 9.441375732421875e-05 seconds
DEBUG 01-15 10:09:10.037511.037511 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003187894821166992 seconds
DEBUG 01-15 10:09:10.037313.037313 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:10.037730.037730 cuda_h.py:19] end restore2model cost 0.00017714500427246094 seconds
INFO 01-15 10:09:10.037732.037732 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e57484fb-ff1e-4ce1-bbe7-4e67ab81571c
INFO 01-15 10:09:10.114099.114099 client.py:127] Model loaded
DEBUG 01-15 10:09:10.114310.114310 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-15 10:09:10.114864.114864 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:10.114557.114557 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:10.115287.115287 cuda_h.py:19] end allocate_cuda_memory cost 0.0003714561462402344 seconds
DEBUG 01-15 10:09:10.115107.115107 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:10.115130.115130 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:10.115027.115027 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:10.115937.115937 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3272df45-f2a7-4a6e-bd37-356647a96f76
DEBUG 01-15 10:09:10.115281.115281 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:10.116562.116562 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3272df45-f2a7-4a6e-bd37-356647a96f76
DEBUG 01-15 10:09:10.116162.116162 cuda_h.py:19] end load_into_gpu_async cost 0.0013530254364013672 seconds
DEBUG 01-15 10:09:10.116688.116688 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:10.117993.117993 cuda_h.py:19] end restore_tensors2 cost 0.00014448165893554688 seconds
DEBUG 01-15 10:09:10.117115.117115 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024900436401367188 seconds
INFO 01-15 10:09:10.117118.117118 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3272df45-f2a7-4a6e-bd37-356647a96f76
INFO 01-15 10:09:10.133134.133134 client.py:127] Model loaded
DEBUG 01-15 10:09:10.133702.133702 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:10.134522.134522 cuda_h.py:19] end restore2model cost 0.0008566379547119141 seconds
DEBUG 01-15 10:09:10.135235.135235 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020420551300048828 seconds
DEBUG 01-15 10:09:10.135265.135265 cuda_h.py:19] end init_weights cost 0.10088896751403809 seconds
DEBUG 01-15 10:09:10.135267.135267 cuda_h.py:10] start copy_emodel
DEBUG 01-15 10:09:10.907751.907751 cuda_h.py:19] end copy_emodel cost 0.772453784942627 seconds
DEBUG 01-15 10:09:10.908828.908828 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-15 10:09:10.981315.981315 cuda_h.py:19] end init_inputs_tokens cost 0.0734260082244873 seconds
DEBUG 01-15 10:09:10.982226.982226 cuda_h.py:10] start prefill
DEBUG 01-15 10:09:10.982473.982473 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:10.982203.982203 lmp.py:1495] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-15 10:09:10.982190.982190 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:10.982608.982608 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:10.982750.982750 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 4.076957702636719e-05 seconds
DEBUG 01-15 10:09:10.982267.982267 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.367134094238281e-05 seconds
DEBUG 01-15 10:09:10.982315.982315 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:10.982139.982139 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:10.982745.982745 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:10.982590.982590 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:10.982103.982103 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:10.983598.983598 cuda_h.py:19] end allocate_cuda_memory cost 0.0002701282501220703 seconds
DEBUG 01-15 10:09:10.983595.983595 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:10.983285.983285 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:10.983612.983612 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:10.983242.983242 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f8989930-030e-4a9f-8c1c-c3beafec8ac7
DEBUG 01-15 10:09:10.983989.983989 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:10.985675.985675 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f8989930-030e-4a9f-8c1c-c3beafec8ac7
DEBUG 01-15 10:09:10.985691.985691 cuda_h.py:19] end load_into_gpu_async cost 0.002438068389892578 seconds
DEBUG 01-15 10:09:10.985607.985607 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:10.985248.985248 cuda_h.py:19] end restore_tensors2 cost 0.00011324882507324219 seconds
DEBUG 01-15 10:09:10.985700.985700 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032165050506591797 seconds
INFO 01-15 10:09:10.985390.985390 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f8989930-030e-4a9f-8c1c-c3beafec8ac7
INFO 01-15 10:09:10.993320.993320 client.py:127] Model loaded
DEBUG 01-15 10:09:10.993210.993210 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:10.994253.994253 cuda_h.py:19] end restore2model cost 0.0008022785186767578 seconds
DEBUG 01-15 10:09:10.994481.994481 cuda_h.py:19] end sllm_worker_task cost 0.012185335159301758 seconds
DEBUG 01-15 10:09:11.072909.072909 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.320861.320861 cuda_h.py:19] end self_attn cost 0.24801301956176758 seconds
DEBUG 01-15 10:09:11.321228.321228 cuda_h.py:19] end iln_self_attn_paln cost 0.3389465808868408 seconds
DEBUG 01-15 10:09:11.321085.321085 cuda_h.py:10] start dense_mlp
DEBUG 01-15 10:09:11.328310.328310 cuda_h.py:19] end dense_mlp cost 0.006690263748168945 seconds
DEBUG 01-15 10:09:11.328645.328645 cuda_h.py:19] end prefill_layer cost 0.34609508514404297 seconds
DEBUG 01-15 10:09:11.328507.328507 lmp.py:1552] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-15 10:09:11.328303.328303 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:11.328575.328575 lmp.py:1495] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-15 10:09:11.328940.328940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:11.328736.328736 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:11.328175.328175 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.361701965332031e-05 seconds
DEBUG 01-15 10:09:11.328600.328600 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 8.225440979003906e-05 seconds
DEBUG 01-15 10:09:11.328151.328151 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:11.328312.328312 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:11.328227.328227 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:11.328514.328514 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.329389.329389 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.329211.329211 cuda_h.py:19] end allocate_cuda_memory cost 0.0003001689910888672 seconds
DEBUG 01-15 10:09:11.329899.329899 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.329585.329585 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.329338.329338 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.330659.330659 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ffbc406a-279b-46dd-85c3-2af0c5a19e0f
DEBUG 01-15 10:09:11.330229.330229 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.330218.330218 cuda_h.py:10] start self_attn
INFO 01-15 10:09:11.332831.332831 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ffbc406a-279b-46dd-85c3-2af0c5a19e0f
DEBUG 01-15 10:09:11.332857.332857 cuda_h.py:19] end load_into_gpu_async cost 0.002375364303588867 seconds
DEBUG 01-15 10:09:11.332601.332601 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.332709.332709 cuda_h.py:19] end restore_tensors2 cost 0.00015997886657714844 seconds
DEBUG 01-15 10:09:11.332528.332528 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035881996154785156 seconds
INFO 01-15 10:09:11.332791.332791 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ffbc406a-279b-46dd-85c3-2af0c5a19e0f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.334714.334714 cuda_h.py:19] end self_attn cost 0.0034499168395996094 seconds
DEBUG 01-15 10:09:11.334518.334518 cuda_h.py:19] end iln_self_attn_paln cost 0.005643129348754883 seconds
DEBUG 01-15 10:09:11.334606.334606 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-15 10:09:11.334369.334369 cuda_h.py:10] start gate
INFO 01-15 10:09:11.340818.340818 client.py:127] Model loaded
DEBUG 01-15 10:09:11.340401.340401 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.341415.341415 cuda_h.py:19] end restore2model cost 0.0009312629699707031 seconds
DEBUG 01-15 10:09:11.341717.341717 cuda_h.py:19] end sllm_worker_task cost 0.012808799743652344 seconds
DEBUG 01-15 10:09:11.432176.432176 cuda_h.py:19] end gate cost 0.09759354591369629 seconds
DEBUG 01-15 10:09:11.432147.432147 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:11.432112.432112 lmp.py:1616] 
DEBUG 01-15 10:09:11.432112.432112 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:11.432021.432021 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:11.432624.432624 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:11.432651.432651 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:11.432294.432294 lmp.py:1620] 
DEBUG 01-15 10:09:11.432294.432294 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:11.432176.432176 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:11.432203.432203 lmp.py:1626]   Expert 25 |     64 | CPU
DEBUG 01-15 10:09:11.432084.432084 lmp.py:1626]   Expert 54 |     67 | CPU
DEBUG 01-15 10:09:11.432727.432727 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:11.432893.432893 lmp.py:1626]   Expert 31 |     72 | CPU
DEBUG 01-15 10:09:11.432821.432821 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:11.432987.432987 lmp.py:1626]   Expert 62 |     87 | CPU
DEBUG 01-15 10:09:11.432153.432153 lmp.py:1626]   Expert 18 |     88 | CPU
DEBUG 01-15 10:09:11.432081.432081 lmp.py:1626]   Expert 52 |     98 | CPU
DEBUG 01-15 10:09:11.432486.432486 lmp.py:1626]   Expert 22 |    100 | CPU
DEBUG 01-15 10:09:11.432413.432413 lmp.py:1626]   Expert 47 |    104 | CPU
DEBUG 01-15 10:09:11.432341.432341 lmp.py:1626]   Expert  0 |    113 | CPU
DEBUG 01-15 10:09:11.432269.432269 lmp.py:1626]   Expert 37 |    117 | CPU
DEBUG 01-15 10:09:11.432435.432435 lmp.py:1626]   Expert 27 |    121 | CPU
DEBUG 01-15 10:09:11.432370.432370 lmp.py:1626]   Expert 32 |    123 | CPU
DEBUG 01-15 10:09:11.432589.432589 lmp.py:1626]   Expert 41 |    130 | CPU
DEBUG 01-15 10:09:11.432947.432947 lmp.py:1626]   Expert 44 |    131 | CPU
DEBUG 01-15 10:09:11.432352.432352 lmp.py:1626]   Expert 28 |    136 | CPU
DEBUG 01-15 10:09:11.433279.433279 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:11.433969.433969 lmp.py:1626]   Expert 58 |    140 | CPU
DEBUG 01-15 10:09:11.433658.433658 lmp.py:1626]   Expert 60 |    144 | CPU
DEBUG 01-15 10:09:11.433347.433347 lmp.py:1626]   Expert 43 |    147 | CPU
DEBUG 01-15 10:09:11.433037.433037 lmp.py:1626]   Expert  1 |    150 | CPU
DEBUG 01-15 10:09:11.433203.433203 lmp.py:1626]   Expert 38 |    153 | CPU
DEBUG 01-15 10:09:11.433130.433130 lmp.py:1626]   Expert 49 |    154 | CPU
DEBUG 01-15 10:09:11.433058.433058 lmp.py:1626]   Expert 51 |    155 | CPU
DEBUG 01-15 10:09:11.433509.433509 lmp.py:1626]   Expert 34 |    161 | CPU
DEBUG 01-15 10:09:11.433914.433914 lmp.py:1626]   Expert 35 |    164 | CPU
DEBUG 01-15 10:09:11.433080.433080 lmp.py:1626]   Expert 36 |    168 | CPU
DEBUG 01-15 10:09:11.433246.433246 lmp.py:1626]   Expert 11 |    170 | CPU
DEBUG 01-15 10:09:11.433604.433604 lmp.py:1626]   Expert 17 |    170 | CPU
DEBUG 01-15 10:09:11.433962.433962 lmp.py:1626]   Expert 59 |    174 | CPU
DEBUG 01-15 10:09:11.433367.433367 lmp.py:1626]   Expert 10 |    180 | CPU
DEBUG 01-15 10:09:11.433533.433533 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:11.433699.433699 lmp.py:1626]   Expert  2 |    186 | GPU
DEBUG 01-15 10:09:11.433388.433388 lmp.py:1626]   Expert 39 |    189 | GPU
DEBUG 01-15 10:09:11.433078.433078 lmp.py:1626]   Expert 33 |    197 | GPU
DEBUG 01-15 10:09:11.433005.433005 lmp.py:1626]   Expert 12 |    198 | GPU
DEBUG 01-15 10:09:11.433172.433172 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:11.433861.433861 lmp.py:1626]   Expert 48 |    198 | GPU
DEBUG 01-15 10:09:11.433027.433027 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:11.433955.433955 lmp.py:1626]   Expert 53 |    204 | GPU
DEBUG 01-15 10:09:11.433882.433882 lmp.py:1626]   Expert 19 |    220 | GPU
DEBUG 01-15 10:09:11.433572.433572 lmp.py:1626]   Expert 26 |    221 | GPU
DEBUG 01-15 10:09:11.433261.433261 lmp.py:1626]   Expert 30 |    221 | GPU
DEBUG 01-15 10:09:11.433950.433950 lmp.py:1626]   Expert 45 |    221 | GPU
DEBUG 01-15 10:09:11.433070.433070 lmp.py:1626]   Expert  5 |    227 | GPU
DEBUG 01-15 10:09:11.433667.433667 lmp.py:1626]   Expert  4 |    229 | GPU
DEBUG 01-15 10:09:11.433025.433025 lmp.py:1626]   Expert 24 |    229 | GPU
DEBUG 01-15 10:09:11.433191.433191 lmp.py:1626]   Expert 42 |    242 | GPU
DEBUG 01-15 10:09:11.433119.433119 lmp.py:1626]   Expert 50 |    245 | GPU
DEBUG 01-15 10:09:11.433808.433808 lmp.py:1626]   Expert 29 |    254 | GPU
DEBUG 01-15 10:09:11.433498.433498 lmp.py:1626]   Expert 56 |    262 | GPU
DEBUG 01-15 10:09:11.433187.433187 lmp.py:1626]   Expert 61 |    270 | GPU
DEBUG 01-15 10:09:11.433115.433115 lmp.py:1626]   Expert  8 |    283 | GPU
DEBUG 01-15 10:09:11.433565.433565 lmp.py:1626]   Expert 63 |    285 | GPU
DEBUG 01-15 10:09:11.433255.433255 lmp.py:1626]   Expert 46 |    294 | GPU
DEBUG 01-15 10:09:11.433182.433182 lmp.py:1626]   Expert  9 |    300 | GPU
DEBUG 01-15 10:09:11.433633.433633 lmp.py:1626]   Expert  6 |    316 | GPU
DEBUG 01-15 10:09:11.433561.433561 lmp.py:1626]   Expert 16 |    316 | GPU
DEBUG 01-15 10:09:11.433489.433489 lmp.py:1626]   Expert 40 |    319 | GPU
DEBUG 01-15 10:09:11.433609.433609 lmp.py:1626]   Expert  7 |    322 | GPU
DEBUG 01-15 10:09:11.433967.433967 lmp.py:1626]   Expert 23 |    325 | GPU
DEBUG 01-15 10:09:11.433325.433325 lmp.py:1626]   Expert 14 |    413 | GPU
DEBUG 01-15 10:09:11.433253.433253 lmp.py:1626]   Expert 57 |    464 | GPU
DEBUG 01-15 10:09:11.433657.433657 lmp.py:1627] 
DEBUG 01-15 10:09:11.433657.433657 lmp.py:1627]   CPU total tokens: 4059 (33.0%)
DEBUG 01-15 10:09:11.433777.433777 lmp.py:1628]   GPU total tokens: 8229 (67.0%)
DEBUG 01-15 10:09:11.433857.433857 cuda_h.py:19] end experts_map_get cost 0.0016164779663085938 seconds
DEBUG 01-15 10:09:11.433385.433385 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:11.434877.434877 lmp.py:1636] 
DEBUG 01-15 10:09:11.434877.434877 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:11.435576.435576 cuda_h.py:19] end cpu_experts_submit cost 0.0011081695556640625 seconds
DEBUG 01-15 10:09:11.435730.435730 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:11.435289.435289 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.435119.435119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.435091.435091 cuda_h.py:19] end allocate_cuda_memory cost 0.00031876564025878906 seconds
DEBUG 01-15 10:09:11.435623.435623 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.435479.435479 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.436778.436778 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.436196.436196 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aef5c7ef-e8fc-4293-b806-ba48d5a1f7ff
DEBUG 01-15 10:09:11.436667.436667 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:11.438024.438024 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aef5c7ef-e8fc-4293-b806-ba48d5a1f7ff
DEBUG 01-15 10:09:11.438358.438358 cuda_h.py:19] end load_into_gpu_async cost 0.0025072097778320312 seconds
DEBUG 01-15 10:09:11.438445.438445 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.438329.438329 cuda_h.py:19] end restore_tensors2 cost 0.0002739429473876953 seconds
DEBUG 01-15 10:09:11.438575.438575 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035905838012695312 seconds
DEBUG 01-15 10:09:11.438100.438100 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.441213.441213 cuda_h.py:19] end restore2model cost 0.002755880355834961 seconds
DEBUG 01-15 10:09:11.441831.441831 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006541252136230469 seconds
DEBUG 01-15 10:09:11.441157.441157 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:11.442816.442816 cuda_h.py:19] end gpu_sexperts cost 0.00048470497131347656 seconds
DEBUG 01-15 10:09:11.442183.442183 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:11.465597.465597 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.023004531860351562 seconds
DEBUG 01-15 10:09:11.466418.466418 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:11.466206.466206 cuda_h.py:19] end gpu_group_list cost 0.00035572052001953125 seconds
DEBUG 01-15 10:09:11.466147.466147 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:11.467080.467080 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007092952728271484 seconds
DEBUG 01-15 10:09:11.467816.467816 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:11.467759.467759 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-15 10:09:11.467124.467124 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:11.566179.566179 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:11.566605.566605 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:11.586950.586950 cuda_h.py:19] end move_flatidxs cost 0.019903898239135742 seconds
DEBUG 01-15 10:09:11.587628.587628 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:11.591343.591343 cuda_h.py:19] end group_tensors cost 0.004485607147216797 seconds
DEBUG 01-15 10:09:11.592787.592787 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:11.610135.610135 cuda_h.py:19] end group pad cost 0.017813444137573242 seconds
DEBUG 01-15 10:09:11.610427.610427 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:11.640743.640743 cuda_h.py:19] end group_einsum cost 0.029895305633544922 seconds
DEBUG 01-15 10:09:11.640091.640091 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:11.646224.646224 cuda_h.py:19] end get_outputs_cpu1 cost 0.005436420440673828 seconds
DEBUG 01-15 10:09:11.650975.650975 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.18259644508361816 seconds
DEBUG 01-15 10:09:11.650177.650177 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:11.650326.650326 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.653996.653996 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0865631103515625 seconds
DEBUG 01-15 10:09:11.657856.657856 cuda_h.py:19] end index_scatter cost 0.006250143051147461 seconds
DEBUG 01-15 10:09:11.657143.657143 cuda_h.py:19] end cpuoutputsdeal cost 0.0068511962890625 seconds
DEBUG 01-15 10:09:11.657549.657549 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:11.657650.657650 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aef5c7ef-e8fc-4293-b806-ba48d5a1f7ff
INFO 01-15 10:09:11.658075.658075 client.py:127] Model loaded
DEBUG 01-15 10:09:11.658885.658885 cuda_h.py:19] end wait_experts cost 0.0015137195587158203 seconds
DEBUG 01-15 10:09:11.659973.659973 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:11.659431.659431 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:11.659134.659134 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:11.659732.659732 cuda_h.py:19] end gpu_group_tensor cost 0.0006172657012939453 seconds
DEBUG 01-15 10:09:11.659564.659564 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:11.661905.661905 cuda_h.py:19] end gpu_group_einsum cost 0.0018169879913330078 seconds
DEBUG 01-15 10:09:11.661426.661426 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:11.661309.661309 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:11.662489.662489 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020313262939453125 seconds
DEBUG 01-15 10:09:11.662867.662867 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:11.662103.662103 cuda_h.py:19] end concat_expert_out cost 7.200241088867188e-05 seconds
DEBUG 01-15 10:09:11.662489.662489 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.662181.662181 cuda_h.py:19] end index_scatter cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:11.662421.662421 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005855560302734375 seconds
DEBUG 01-15 10:09:11.662264.662264 cuda_h.py:19] end gpu_experts cost 0.0035245418548583984 seconds
DEBUG 01-15 10:09:11.662696.662696 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.3282301425933838 seconds
DEBUG 01-15 10:09:11.662413.662413 cuda_h.py:19] end prefill_layer cost 0.33456873893737793 seconds
DEBUG 01-15 10:09:11.662004.662004 lmp.py:1552] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-15 10:09:11.662846.662846 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:11.662688.662688 lmp.py:1495] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-15 10:09:11.662245.662245 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:11.663187.663187 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:11.663169.663169 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 2.9802322387695312e-05 seconds
DEBUG 01-15 10:09:11.663792.663792 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.104873657226562e-05 seconds
DEBUG 01-15 10:09:11.663919.663919 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:11.663656.663656 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:11.663626.663626 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:11.663713.663713 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.663677.663677 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.663578.663578 cuda_h.py:19] end allocate_cuda_memory cost 0.0001628398895263672 seconds
DEBUG 01-15 10:09:11.663812.663812 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.663144.663144 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.663728.663728 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.663100.663100 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 891a8469-981a-4f99-ab59-9a132669c103
DEBUG 01-15 10:09:11.663686.663686 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.664551.664551 cuda_h.py:10] start self_attn
INFO 01-15 10:09:11.664502.664502 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 891a8469-981a-4f99-ab59-9a132669c103
DEBUG 01-15 10:09:11.664445.664445 cuda_h.py:19] end load_into_gpu_async cost 0.0010635852813720703 seconds
DEBUG 01-15 10:09:11.664916.664916 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.664515.664515 cuda_h.py:19] end restore_tensors2 cost 6.079673767089844e-05 seconds
DEBUG 01-15 10:09:11.664516.664516 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015583038330078125 seconds
INFO 01-15 10:09:11.665737.665737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 891a8469-981a-4f99-ab59-9a132669c103
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.667040.667040 cuda_h.py:19] end self_attn cost 0.003672361373901367 seconds
DEBUG 01-15 10:09:11.668142.668142 cuda_h.py:19] end iln_self_attn_paln cost 0.0050470829010009766 seconds
DEBUG 01-15 10:09:11.668793.668793 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-15 10:09:11.668887.668887 cuda_h.py:10] start gate
DEBUG 01-15 10:09:11.669062.669062 cuda_h.py:19] end gate cost 0.0006570816040039062 seconds
DEBUG 01-15 10:09:11.669753.669753 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:11.669941.669941 lmp.py:1616] 
DEBUG 01-15 10:09:11.669941.669941 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:11.669697.669697 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:11.669062.669062 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:11.669566.669566 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:11.669070.669070 lmp.py:1620] 
DEBUG 01-15 10:09:11.669070.669070 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:11.669588.669588 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:11.669145.669145 lmp.py:1626]   Expert 58 |     51 | CPU
DEBUG 01-15 10:09:11.669795.669795 lmp.py:1626]   Expert 27 |     56 | CPU
DEBUG 01-15 10:09:11.669491.669491 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:11.669710.669710 lmp.py:1626]   Expert 17 |     84 | CPU
DEBUG 01-15 10:09:11.669168.669168 lmp.py:1626]   Expert  0 |     88 | CPU
DEBUG 01-15 10:09:11.669864.669864 lmp.py:1626]   Expert 24 |     88 | CPU
DEBUG 01-15 10:09:11.669606.669606 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:11.669825.669825 lmp.py:1626]   Expert 34 |    114 | CPU
DEBUG 01-15 10:09:11.669998.669998 lmp.py:1626]   Expert 51 |    118 | CPU
DEBUG 01-15 10:09:11.669694.669694 lmp.py:1626]   Expert 32 |    120 | CPU
DEBUG 01-15 10:09:11.669629.669629 lmp.py:1626]   Expert  9 |    128 | CPU
DEBUG 01-15 10:09:11.669563.669563 lmp.py:1626]   Expert 23 |    135 | CPU
DEBUG 01-15 10:09:11.669544.669544 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:11.669525.669525 lmp.py:1626]   Expert 15 |    136 | CPU
DEBUG 01-15 10:09:11.669029.669029 lmp.py:1626]   Expert 26 |    138 | CPU
DEBUG 01-15 10:09:11.669010.669010 lmp.py:1626]   Expert 30 |    144 | CPU
DEBUG 01-15 10:09:11.669229.669229 lmp.py:1626]   Expert 45 |    146 | CPU
DEBUG 01-15 10:09:11.669448.669448 lmp.py:1626]   Expert 62 |    147 | CPU
DEBUG 01-15 10:09:11.669144.669144 lmp.py:1626]   Expert 57 |    150 | CPU
DEBUG 01-15 10:09:11.669841.669841 lmp.py:1626]   Expert  1 |    152 | CPU
DEBUG 01-15 10:09:11.669775.669775 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:11.669571.669571 lmp.py:1626]   Expert  8 |    159 | CPU
DEBUG 01-15 10:09:11.669167.669167 lmp.py:1626]   Expert 29 |    160 | CPU
DEBUG 01-15 10:09:11.669333.669333 lmp.py:1626]   Expert 25 |    165 | CPU
DEBUG 01-15 10:09:11.669500.669500 lmp.py:1626]   Expert 54 |    167 | CPU
DEBUG 01-15 10:09:11.670666.670666 lmp.py:1626]   Expert  6 |    170 | CPU
DEBUG 01-15 10:09:11.670832.670832 lmp.py:1626]   Expert 49 |    171 | CPU
DEBUG 01-15 10:09:11.670521.670521 lmp.py:1626]   Expert 48 |    173 | CPU
DEBUG 01-15 10:09:11.670687.670687 lmp.py:1626]   Expert 12 |    176 | CPU
DEBUG 01-15 10:09:11.670092.670092 lmp.py:1626]   Expert 35 |    176 | CPU
DEBUG 01-15 10:09:11.670735.670735 lmp.py:1626]   Expert 37 |    178 | CPU
DEBUG 01-15 10:09:11.670139.670139 lmp.py:1626]   Expert 60 |    187 | CPU
DEBUG 01-15 10:09:11.670782.670782 lmp.py:1626]   Expert 13 |    188 | GPU
DEBUG 01-15 10:09:11.670425.670425 lmp.py:1626]   Expert 33 |    189 | GPU
DEBUG 01-15 10:09:11.670830.670830 lmp.py:1626]   Expert 53 |    189 | GPU
DEBUG 01-15 10:09:11.670758.670758 lmp.py:1626]   Expert 10 |    194 | GPU
DEBUG 01-15 10:09:11.670685.670685 lmp.py:1626]   Expert 16 |    195 | GPU
DEBUG 01-15 10:09:11.670613.670613 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:11.670541.670541 lmp.py:1626]   Expert 40 |    200 | GPU
DEBUG 01-15 10:09:11.670230.670230 lmp.py:1626]   Expert 43 |    202 | GPU
DEBUG 01-15 10:09:11.670396.670396 lmp.py:1626]   Expert 38 |    204 | GPU
DEBUG 01-15 10:09:11.670562.670562 lmp.py:1626]   Expert  5 |    208 | GPU
DEBUG 01-15 10:09:11.670967.670967 lmp.py:1626]   Expert 44 |    216 | GPU
DEBUG 01-15 10:09:11.670371.670371 lmp.py:1626]   Expert 19 |    217 | GPU
DEBUG 01-15 10:09:11.670014.670014 lmp.py:1626]   Expert 50 |    217 | GPU
DEBUG 01-15 10:09:11.670896.670896 lmp.py:1626]   Expert 52 |    217 | GPU
DEBUG 01-15 10:09:11.670823.670823 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:11.670751.670751 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:11.670679.670679 lmp.py:1626]   Expert 59 |    223 | GPU
DEBUG 01-15 10:09:11.670607.670607 lmp.py:1626]   Expert 55 |    233 | GPU
DEBUG 01-15 10:09:11.670296.670296 lmp.py:1626]   Expert 31 |    241 | GPU
DEBUG 01-15 10:09:11.670224.670224 lmp.py:1626]   Expert 56 |    241 | GPU
DEBUG 01-15 10:09:11.670151.670151 lmp.py:1626]   Expert 20 |    251 | GPU
DEBUG 01-15 10:09:11.670602.670602 lmp.py:1626]   Expert 39 |    252 | GPU
DEBUG 01-15 10:09:11.670292.670292 lmp.py:1626]   Expert 22 |    265 | GPU
DEBUG 01-15 10:09:11.670981.670981 lmp.py:1626]   Expert  2 |    267 | GPU
DEBUG 01-15 10:09:11.670909.670909 lmp.py:1626]   Expert 47 |    276 | GPU
DEBUG 01-15 10:09:11.670552.670552 lmp.py:1626]   Expert 63 |    276 | GPU
DEBUG 01-15 10:09:11.670195.670195 lmp.py:1626]   Expert 42 |    303 | GPU
DEBUG 01-15 10:09:11.670599.670599 lmp.py:1626]   Expert 18 |    314 | GPU
DEBUG 01-15 10:09:11.670004.670004 lmp.py:1626]   Expert 14 |    317 | GPU
DEBUG 01-15 10:09:11.670647.670647 lmp.py:1626]   Expert 46 |    367 | GPU
DEBUG 01-15 10:09:11.670574.670574 lmp.py:1626]   Expert 11 |    387 | GPU
DEBUG 01-15 10:09:11.670264.670264 lmp.py:1626]   Expert 61 |    460 | GPU
DEBUG 01-15 10:09:11.670145.670145 lmp.py:1627] 
DEBUG 01-15 10:09:11.670145.670145 lmp.py:1627]   CPU total tokens: 4341 (35.3%)
DEBUG 01-15 10:09:11.670265.670265 lmp.py:1628]   GPU total tokens: 7947 (64.7%)
DEBUG 01-15 10:09:11.670915.670915 cuda_h.py:19] end experts_map_get cost 0.0016334056854248047 seconds
DEBUG 01-15 10:09:11.670718.670718 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:11.670520.670520 lmp.py:1636] 
DEBUG 01-15 10:09:11.670520.670520 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:11.670973.670973 cuda_h.py:19] end cpu_experts_submit cost 5.125999450683594e-05 seconds
DEBUG 01-15 10:09:11.670205.670205 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:11.670035.670035 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.671662.671662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.671148.671148 cuda_h.py:19] end allocate_cuda_memory cost 0.00021505355834960938 seconds
DEBUG 01-15 10:09:11.671044.671044 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.671992.671992 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.671139.671139 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.671319.671319 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 297cce1d-2634-4839-b312-9ab39de1b2f7
DEBUG 01-15 10:09:11.671503.671503 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:11.672397.672397 client.py:127] Model loaded
DEBUG 01-15 10:09:11.672770.672770 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.672362.672362 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:11.672155.672155 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 297cce1d-2634-4839-b312-9ab39de1b2f7
DEBUG 01-15 10:09:11.672521.672521 cuda_h.py:19] end load_into_gpu_async cost 0.0011601448059082031 seconds
DEBUG 01-15 10:09:11.672277.672277 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.672843.672843 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:11.672671.672671 cuda_h.py:19] end restore_tensors2 cost 0.0002586841583251953 seconds
DEBUG 01-15 10:09:11.672692.672692 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020029544830322266 seconds
DEBUG 01-15 10:09:11.673839.673839 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.673917.673917 cuda_h.py:19] end restore2model cost 0.00030612945556640625 seconds
DEBUG 01-15 10:09:11.673221.673221 cuda_h.py:19] end sllm_worker_task cost 0.010241985321044922 seconds
DEBUG 01-15 10:09:11.673931.673931 cuda_h.py:19] end move_flatidxs cost 0.0009810924530029297 seconds
DEBUG 01-15 10:09:11.673145.673145 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:11.675994.675994 cuda_h.py:19] end restore2model cost 0.002820253372192383 seconds
DEBUG 01-15 10:09:11.675891.675891 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005010366439819336 seconds
DEBUG 01-15 10:09:11.675401.675401 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:11.676279.676279 cuda_h.py:19] end gpu_sexperts cost 0.00026416778564453125 seconds
DEBUG 01-15 10:09:11.676108.676108 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:11.677583.677583 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00147247314453125 seconds
DEBUG 01-15 10:09:11.677325.677325 cuda_h.py:19] end group_tensors cost 0.003953456878662109 seconds
DEBUG 01-15 10:09:11.678768.678768 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:11.678198.678198 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:11.679294.679294 cuda_h.py:19] end gpu_group_list cost 0.0005784034729003906 seconds
DEBUG 01-15 10:09:11.679699.679699 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:11.680599.680599 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010654926300048828 seconds
DEBUG 01-15 10:09:11.680086.680086 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:11.680354.680354 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-15 10:09:11.680508.680508 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:11.682429.682429 cuda_h.py:19] end group pad cost 0.0036628246307373047 seconds
DEBUG 01-15 10:09:11.682603.682603 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:11.708212.708212 cuda_h.py:19] end group_einsum cost 0.02581930160522461 seconds
DEBUG 01-15 10:09:11.708019.708019 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:11.715468.715468 cuda_h.py:19] end get_outputs_cpu1 cost 0.007196187973022461 seconds
DEBUG 01-15 10:09:11.717264.717264 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03673076629638672 seconds
DEBUG 01-15 10:09:11.717318.717318 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:11.718645.718645 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.045720577239990234 seconds
DEBUG 01-15 10:09:11.718076.718076 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.718059.718059 cuda_h.py:19] end index_scatter cost 0.00016689300537109375 seconds
DEBUG 01-15 10:09:11.719413.719413 cuda_h.py:19] end cpuoutputsdeal cost 0.0017232894897460938 seconds
DEBUG 01-15 10:09:11.719313.719313 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:11.720858.720858 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 297cce1d-2634-4839-b312-9ab39de1b2f7
INFO 01-15 10:09:11.722202.722202 client.py:127] Model loaded
DEBUG 01-15 10:09:11.722450.722450 cuda_h.py:19] end wait_experts cost 0.002658843994140625 seconds
DEBUG 01-15 10:09:11.722067.722067 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:11.722115.722115 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:11.722355.722355 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:11.723498.723498 cuda_h.py:19] end gpu_group_tensor cost 0.0002837181091308594 seconds
DEBUG 01-15 10:09:11.723529.723529 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:11.723809.723809 cuda_h.py:19] end gpu_group_einsum cost 0.0006093978881835938 seconds
DEBUG 01-15 10:09:11.724483.724483 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:11.724194.724194 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:11.724869.724869 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003478527069091797 seconds
DEBUG 01-15 10:09:11.724268.724268 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:11.724407.724407 cuda_h.py:19] end concat_expert_out cost 0.0003437995910644531 seconds
DEBUG 01-15 10:09:11.725212.725212 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.725905.725905 cuda_h.py:19] end index_scatter cost 8.106231689453125e-05 seconds
DEBUG 01-15 10:09:11.725695.725695 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011053085327148438 seconds
DEBUG 01-15 10:09:11.725412.725412 cuda_h.py:19] end gpu_experts cost 0.0025787353515625 seconds
DEBUG 01-15 10:09:11.725051.725051 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.05711030960083008 seconds
DEBUG 01-15 10:09:11.725871.725871 cuda_h.py:19] end prefill_layer cost 0.06280636787414551 seconds
DEBUG 01-15 10:09:11.725806.725806 lmp.py:1552] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-15 10:09:11.725701.725701 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:11.725312.725312 lmp.py:1495] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-15 10:09:11.725114.725114 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:11.725632.725632 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:11.726502.726502 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.0067901611328125e-05 seconds
DEBUG 01-15 10:09:11.726450.726450 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 8.487701416015625e-05 seconds
DEBUG 01-15 10:09:11.726530.726530 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:11.726579.726579 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:11.726986.726986 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.726968.726968 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.727748.727748 cuda_h.py:19] end allocate_cuda_memory cost 0.0006499290466308594 seconds
DEBUG 01-15 10:09:11.727055.727055 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:11.727536.727536 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.727936.727936 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.727385.727385 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.728117.728117 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2c05e533-6ecf-47da-bb8c-85141bcaa027
DEBUG 01-15 10:09:11.728556.728556 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.728071.728071 cuda_h.py:10] start self_attn
INFO 01-15 10:09:11.729045.729045 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2c05e533-6ecf-47da-bb8c-85141bcaa027
DEBUG 01-15 10:09:11.729303.729303 cuda_h.py:19] end load_into_gpu_async cost 0.0020666122436523438 seconds
DEBUG 01-15 10:09:11.729631.729631 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.730891.730891 cuda_h.py:19] end restore_tensors2 cost 0.00017452239990234375 seconds
DEBUG 01-15 10:09:11.730590.730590 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039479732513427734 seconds
INFO 01-15 10:09:11.730747.730747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2c05e533-6ecf-47da-bb8c-85141bcaa027
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.734079.734079 cuda_h.py:19] end self_attn cost 0.005474090576171875 seconds
DEBUG 01-15 10:09:11.734587.734587 cuda_h.py:19] end iln_self_attn_paln cost 0.008399248123168945 seconds
DEBUG 01-15 10:09:11.734868.734868 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-15 10:09:11.734346.734346 cuda_h.py:10] start gate
DEBUG 01-15 10:09:11.735739.735739 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-15 10:09:11.735999.735999 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:11.735877.735877 lmp.py:1616] 
DEBUG 01-15 10:09:11.735877.735877 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:11.735063.735063 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:11.735667.735667 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:11.735601.735601 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:11.735198.735198 lmp.py:1620] 
DEBUG 01-15 10:09:11.735198.735198 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:11.735556.735556 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:11.735868.735868 lmp.py:1626]   Expert  1 |     50 | CPU
DEBUG 01-15 10:09:11.735988.735988 lmp.py:1626]   Expert 27 |     62 | CPU
DEBUG 01-15 10:09:11.735823.735823 lmp.py:1626]   Expert  7 |     76 | CPU
DEBUG 01-15 10:09:11.735420.735420 lmp.py:1626]   Expert 48 |     81 | CPU
DEBUG 01-15 10:09:11.735447.735447 lmp.py:1626]   Expert 15 |     98 | CPU
DEBUG 01-15 10:09:11.735567.735567 lmp.py:1626]   Expert 30 |    108 | CPU
DEBUG 01-15 10:09:11.735686.735686 lmp.py:1626]   Expert 61 |    116 | CPU
DEBUG 01-15 10:09:11.735045.735045 lmp.py:1626]   Expert 32 |    118 | CPU
DEBUG 01-15 10:09:11.735880.735880 lmp.py:1626]   Expert 45 |    118 | CPU
DEBUG 01-15 10:09:11.735284.735284 lmp.py:1626]   Expert 18 |    119 | CPU
DEBUG 01-15 10:09:11.735973.735973 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:11.735378.735378 lmp.py:1626]   Expert 36 |    138 | CPU
DEBUG 01-15 10:09:11.736975.736975 lmp.py:1626]   Expert 39 |    138 | CPU
DEBUG 01-15 10:09:11.736956.736956 lmp.py:1626]   Expert  5 |    139 | CPU
DEBUG 01-15 10:09:11.736837.736837 lmp.py:1626]   Expert 11 |    139 | CPU
DEBUG 01-15 10:09:11.736579.736579 lmp.py:1626]   Expert 26 |    139 | CPU
DEBUG 01-15 10:09:11.736222.736222 lmp.py:1626]   Expert  6 |    143 | CPU
DEBUG 01-15 10:09:11.736965.736965 lmp.py:1626]   Expert 59 |    144 | CPU
DEBUG 01-15 10:09:11.736091.736091 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:11.736118.736118 lmp.py:1626]   Expert 49 |    155 | CPU
DEBUG 01-15 10:09:11.736669.736669 lmp.py:1626]   Expert 23 |    156 | CPU
DEBUG 01-15 10:09:11.736696.736696 lmp.py:1626]   Expert  2 |    158 | CPU
DEBUG 01-15 10:09:11.736200.736200 lmp.py:1626]   Expert  9 |    158 | CPU
DEBUG 01-15 10:09:11.736466.736466 lmp.py:1626]   Expert 50 |    165 | CPU
DEBUG 01-15 10:09:11.736970.736970 lmp.py:1626]   Expert 56 |    167 | CPU
DEBUG 01-15 10:09:11.736474.736474 lmp.py:1626]   Expert 40 |    168 | CPU
DEBUG 01-15 10:09:11.736739.736739 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:11.736150.736150 lmp.py:1626]   Expert 16 |    171 | CPU
DEBUG 01-15 10:09:11.736701.736701 lmp.py:1626]   Expert 35 |    174 | CPU
DEBUG 01-15 10:09:11.736490.736490 lmp.py:1626]   Expert  4 |    185 | CPU
DEBUG 01-15 10:09:11.736100.736100 lmp.py:1626]   Expert 37 |    189 | CPU
DEBUG 01-15 10:09:11.736816.736816 lmp.py:1626]   Expert 13 |    191 | CPU
DEBUG 01-15 10:09:11.736797.736797 lmp.py:1626]   Expert 42 |    191 | GPU
DEBUG 01-15 10:09:11.736301.736301 lmp.py:1626]   Expert 17 |    197 | GPU
DEBUG 01-15 10:09:11.736090.736090 lmp.py:1626]   Expert 38 |    197 | GPU
DEBUG 01-15 10:09:11.736309.736309 lmp.py:1626]   Expert 62 |    197 | GPU
DEBUG 01-15 10:09:11.736336.736336 lmp.py:1626]   Expert 21 |    202 | GPU
DEBUG 01-15 10:09:11.736840.736840 lmp.py:1626]   Expert  3 |    208 | GPU
DEBUG 01-15 10:09:11.736490.736490 lmp.py:1626]   Expert 44 |    209 | GPU
DEBUG 01-15 10:09:11.736040.736040 lmp.py:1626]   Expert 58 |    211 | GPU
DEBUG 01-15 10:09:11.736306.736306 lmp.py:1626]   Expert 60 |    211 | GPU
DEBUG 01-15 10:09:11.736446.736446 lmp.py:1626]   Expert 28 |    212 | GPU
DEBUG 01-15 10:09:11.736473.736473 lmp.py:1626]   Expert 47 |    214 | GPU
DEBUG 01-15 10:09:11.736878.736878 lmp.py:1626]   Expert 10 |    215 | GPU
INFO 01-15 10:09:11.736855.736855 client.py:127] Model loaded
DEBUG 01-15 10:09:11.736046.736046 lmp.py:1626]   Expert 53 |    218 | GPU
DEBUG 01-15 10:09:11.737241.737241 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.737952.737952 lmp.py:1626]   Expert 55 |    220 | GPU
DEBUG 01-15 10:09:11.737221.737221 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:11.737685.737685 lmp.py:1626]   Expert 33 |    227 | GPU
DEBUG 01-15 10:09:11.737951.737951 lmp.py:1626]   Expert 57 |    227 | GPU
DEBUG 01-15 10:09:11.737978.737978 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:11.737959.737959 lmp.py:1626]   Expert 46 |    237 | GPU
DEBUG 01-15 10:09:11.737178.737178 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:11.737682.737682 lmp.py:1626]   Expert 19 |    243 | GPU
DEBUG 01-15 10:09:11.737901.737901 lmp.py:1626]   Expert 24 |    247 | GPU
DEBUG 01-15 10:09:11.737359.737359 lmp.py:1626]   Expert 14 |    262 | GPU
DEBUG 01-15 10:09:11.737055.737055 lmp.py:1626]   Expert 63 |    267 | GPU
DEBUG 01-15 10:09:11.737513.737513 lmp.py:1626]   Expert 12 |    275 | GPU
DEBUG 01-15 10:09:11.737017.737017 lmp.py:1626]   Expert 29 |    275 | GPU
DEBUG 01-15 10:09:11.737474.737474 lmp.py:1626]   Expert 22 |    278 | GPU
DEBUG 01-15 10:09:11.737455.737455 lmp.py:1626]   Expert  0 |    295 | GPU
DEBUG 01-15 10:09:11.737197.737197 lmp.py:1626]   Expert 43 |    311 | GPU
DEBUG 01-15 10:09:11.737701.737701 lmp.py:1626]   Expert 54 |    339 | GPU
DEBUG 01-15 10:09:11.737921.737921 lmp.py:1626]   Expert 41 |    383 | GPU
DEBUG 01-15 10:09:11.737186.737186 lmp.py:1626]   Expert 25 |    410 | GPU
DEBUG 01-15 10:09:11.737644.737644 lmp.py:1627] 
DEBUG 01-15 10:09:11.737644.737644 lmp.py:1627]   CPU total tokens: 4409 (35.9%)
DEBUG 01-15 10:09:11.737532.737532 lmp.py:1628]   GPU total tokens: 7879 (64.1%)
DEBUG 01-15 10:09:11.737527.737527 cuda_h.py:19] end experts_map_get cost 0.0024619102478027344 seconds
DEBUG 01-15 10:09:11.738811.738811 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:11.738494.738494 lmp.py:1636] 
DEBUG 01-15 10:09:11.738494.738494 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:11.738245.738245 cuda_h.py:19] end cpu_experts_submit cost 6.318092346191406e-05 seconds
DEBUG 01-15 10:09:11.738424.738424 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:11.738837.738837 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.738319.738319 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.738718.738718 cuda_h.py:19] end allocate_cuda_memory cost 0.0002193450927734375 seconds
DEBUG 01-15 10:09:11.738005.738005 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.738576.738576 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.738021.738021 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.738685.738685 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 422a8263-7ed6-4536-9bb4-5fc873e13465
DEBUG 01-15 10:09:11.739831.739831 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.739695.739695 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:11.740144.740144 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:11.740688.740688 cuda_h.py:19] end restore2model cost 0.0030443668365478516 seconds
DEBUG 01-15 10:09:11.740250.740250 cuda_h.py:19] end sllm_worker_task cost 0.014198541641235352 seconds
INFO 01-15 10:09:11.740458.740458 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 422a8263-7ed6-4536-9bb4-5fc873e13465
DEBUG 01-15 10:09:11.740597.740597 cuda_h.py:19] end load_into_gpu_async cost 0.002203226089477539 seconds
DEBUG 01-15 10:09:11.741058.741058 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.741401.741401 cuda_h.py:19] end move_flatidxs cost 0.0010523796081542969 seconds
DEBUG 01-15 10:09:11.741065.741065 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:11.741672.741672 cuda_h.py:19] end restore_tensors2 cost 0.0008573532104492188 seconds
DEBUG 01-15 10:09:11.742485.742485 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003880739212036133 seconds
DEBUG 01-15 10:09:11.742826.742826 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.745059.745059 cuda_h.py:19] end restore2model cost 0.002633333206176758 seconds
DEBUG 01-15 10:09:11.745533.745533 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0069696903228759766 seconds
DEBUG 01-15 10:09:11.745376.745376 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:11.745201.745201 cuda_h.py:19] end gpu_sexperts cost 0.0002923011779785156 seconds
DEBUG 01-15 10:09:11.745852.745852 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:11.746697.746697 cuda_h.py:19] end group_tensors cost 0.004973888397216797 seconds
DEBUG 01-15 10:09:11.747554.747554 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015277862548828125 seconds
DEBUG 01-15 10:09:11.747277.747277 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:11.748726.748726 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:11.748766.748766 cuda_h.py:19] end gpu_group_list cost 0.0004832744598388672 seconds
DEBUG 01-15 10:09:11.749507.749507 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:11.750587.750587 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011029243469238281 seconds
DEBUG 01-15 10:09:11.750443.750443 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:11.750545.750545 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.790855407714844e-05 seconds
DEBUG 01-15 10:09:11.750023.750023 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:11.751693.751693 cuda_h.py:19] end group pad cost 0.0038602352142333984 seconds
DEBUG 01-15 10:09:11.751629.751629 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:11.775137.775137 cuda_h.py:19] end group_einsum cost 0.024372339248657227 seconds
DEBUG 01-15 10:09:11.775858.775858 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:11.782832.782832 cuda_h.py:19] end get_outputs_cpu1 cost 0.006849527359008789 seconds
DEBUG 01-15 10:09:11.785311.785311 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03442668914794922 seconds
DEBUG 01-15 10:09:11.785610.785610 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:11.785998.785998 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.786167.786167 cuda_h.py:19] end index_scatter cost 0.00017213821411132812 seconds
DEBUG 01-15 10:09:11.786630.786630 cuda_h.py:19] end cpuoutputsdeal cost 0.0014677047729492188 seconds
DEBUG 01-15 10:09:11.786589.786589 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:11.787895.787895 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 422a8263-7ed6-4536-9bb4-5fc873e13465
DEBUG 01-15 10:09:11.787963.787963 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04742741584777832 seconds
INFO 01-15 10:09:11.790724.790724 client.py:127] Model loaded
DEBUG 01-15 10:09:11.790428.790428 cuda_h.py:19] end wait_experts cost 0.0030753612518310547 seconds
DEBUG 01-15 10:09:11.790707.790707 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:11.790995.790995 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:11.790035.790035 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:11.790839.790839 cuda_h.py:19] end gpu_group_tensor cost 0.0002453327178955078 seconds
DEBUG 01-15 10:09:11.790095.790095 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:11.791329.791329 cuda_h.py:19] end gpu_group_einsum cost 0.0006158351898193359 seconds
DEBUG 01-15 10:09:11.791797.791797 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:11.791362.791362 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:11.791606.791606 cuda_h.py:19] end all_expert_outputs_slices cost 0.00031447410583496094 seconds
DEBUG 01-15 10:09:11.791660.791660 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:11.792121.792121 cuda_h.py:19] end concat_expert_out cost 0.0002613067626953125 seconds
DEBUG 01-15 10:09:11.792051.792051 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.792049.792049 cuda_h.py:19] end index_scatter cost 0.00010180473327636719 seconds
DEBUG 01-15 10:09:11.792196.792196 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009813308715820312 seconds
DEBUG 01-15 10:09:11.792576.792576 cuda_h.py:19] end gpu_experts cost 0.0023682117462158203 seconds
DEBUG 01-15 10:09:11.792161.792161 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.05797910690307617 seconds
DEBUG 01-15 10:09:11.793035.793035 cuda_h.py:19] end prefill_layer cost 0.06710290908813477 seconds
DEBUG 01-15 10:09:11.793680.793680 lmp.py:1552] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-15 10:09:11.793859.793859 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:11.793708.793708 lmp.py:1495] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-15 10:09:11.793603.793603 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:11.793928.793928 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:11.793600.793600 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 4.267692565917969e-05 seconds
DEBUG 01-15 10:09:11.793356.793356 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.772445678710938e-05 seconds
DEBUG 01-15 10:09:11.793482.793482 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:11.793929.793929 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:11.793992.793992 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:11.793986.793986 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.793951.793951 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.794822.794822 cuda_h.py:19] end allocate_cuda_memory cost 0.00039839744567871094 seconds
DEBUG 01-15 10:09:11.794875.794875 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.794429.794429 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.794062.794062 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.794813.794813 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3edd4c2b-c082-4ce6-b1f8-5fabd446c0a2
DEBUG 01-15 10:09:11.795701.795701 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.795484.795484 cuda_h.py:10] start self_attn
INFO 01-15 10:09:11.795459.795459 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3edd4c2b-c082-4ce6-b1f8-5fabd446c0a2
DEBUG 01-15 10:09:11.796544.796544 cuda_h.py:19] end load_into_gpu_async cost 0.0014488697052001953 seconds
DEBUG 01-15 10:09:11.796362.796362 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.796245.796245 cuda_h.py:19] end restore_tensors2 cost 0.00015974044799804688 seconds
DEBUG 01-15 10:09:11.796289.796289 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028214454650878906 seconds
INFO 01-15 10:09:11.796466.796466 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3edd4c2b-c082-4ce6-b1f8-5fabd446c0a2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.799736.799736 cuda_h.py:19] end self_attn cost 0.004253864288330078 seconds
DEBUG 01-15 10:09:11.800893.800893 cuda_h.py:19] end iln_self_attn_paln cost 0.006692409515380859 seconds
DEBUG 01-15 10:09:11.800359.800359 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-15 10:09:11.800883.800883 cuda_h.py:10] start gate
DEBUG 01-15 10:09:11.800495.800495 cuda_h.py:19] end gate cost 0.0006275177001953125 seconds
DEBUG 01-15 10:09:11.800563.800563 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:11.801593.801593 lmp.py:1616] 
DEBUG 01-15 10:09:11.801593.801593 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:11.801163.801163 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:11.801197.801197 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:11.801701.801701 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:11.801583.801583 lmp.py:1620] 
DEBUG 01-15 10:09:11.801583.801583 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:11.801941.801941 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:11.801491.801491 lmp.py:1626]   Expert 14 |     66 | CPU
DEBUG 01-15 10:09:11.801373.801373 lmp.py:1626]   Expert 57 |     71 | CPU
DEBUG 01-15 10:09:11.801016.801016 lmp.py:1626]   Expert 13 |     74 | CPU
DEBUG 01-15 10:09:11.801659.801659 lmp.py:1626]   Expert 26 |     81 | CPU
DEBUG 01-15 10:09:11.801063.801063 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:11.801229.801229 lmp.py:1626]   Expert 54 |     91 | CPU
DEBUG 01-15 10:09:11.801872.801872 lmp.py:1626]   Expert 11 |     93 | CPU
DEBUG 01-15 10:09:11.801038.801038 lmp.py:1626]   Expert 45 |     93 | CPU
DEBUG 01-15 10:09:11.801205.801205 lmp.py:1626]   Expert 58 |    101 | CPU
DEBUG 01-15 10:09:11.801132.801132 lmp.py:1626]   Expert 30 |    109 | CPU
DEBUG 01-15 10:09:11.801822.801822 lmp.py:1626]   Expert 51 |    109 | CPU
DEBUG 01-15 10:09:11.801511.801511 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:11.801200.801200 lmp.py:1626]   Expert 10 |    114 | CPU
DEBUG 01-15 10:09:11.801366.801366 lmp.py:1626]   Expert 32 |    115 | CPU
DEBUG 01-15 10:09:11.801532.801532 lmp.py:1626]   Expert 20 |    124 | CPU
DEBUG 01-15 10:09:11.801460.801460 lmp.py:1626]   Expert  8 |    134 | CPU
DEBUG 01-15 10:09:11.801865.801865 lmp.py:1626]   Expert  4 |    136 | CPU
DEBUG 01-15 10:09:11.801508.801508 lmp.py:1626]   Expert 63 |    137 | CPU
DEBUG 01-15 10:09:11.801435.801435 lmp.py:1626]   Expert 53 |    140 | CPU
DEBUG 01-15 10:09:11.801363.801363 lmp.py:1626]   Expert 34 |    144 | CPU
DEBUG 01-15 10:09:11.801052.801052 lmp.py:1626]   Expert 61 |    144 | CPU
DEBUG 01-15 10:09:11.801742.801742 lmp.py:1626]   Expert 16 |    147 | CPU
DEBUG 01-15 10:09:11.801431.801431 lmp.py:1626]   Expert 47 |    147 | CPU
DEBUG 01-15 10:09:11.801359.801359 lmp.py:1626]   Expert 60 |    159 | CPU
DEBUG 01-15 10:09:11.801286.801286 lmp.py:1626]   Expert 28 |    160 | CPU
DEBUG 01-15 10:09:11.801214.801214 lmp.py:1626]   Expert 17 |    162 | CPU
DEBUG 01-15 10:09:11.801619.801619 lmp.py:1626]   Expert 42 |    162 | CPU
DEBUG 01-15 10:09:11.801546.801546 lmp.py:1626]   Expert 29 |    170 | CPU
DEBUG 01-15 10:09:11.801050.801050 lmp.py:1626]   Expert 44 |    171 | CPU
DEBUG 01-15 10:09:11.801078.801078 lmp.py:1626]   Expert  7 |    176 | CPU
DEBUG 01-15 10:09:11.801105.801105 lmp.py:1626]   Expert 27 |    176 | CPU
DEBUG 01-15 10:09:11.801893.801893 lmp.py:1626]   Expert 41 |    180 | CPU
DEBUG 01-15 10:09:11.801205.801205 lmp.py:1626]   Expert 48 |    182 | GPU
DEBUG 01-15 10:09:11.801709.801709 lmp.py:1626]   Expert  9 |    184 | GPU
DEBUG 01-15 10:09:11.801975.801975 lmp.py:1626]   Expert 56 |    186 | GPU
DEBUG 01-15 10:09:11.801525.801525 lmp.py:1626]   Expert  2 |    188 | GPU
DEBUG 01-15 10:09:11.801837.801837 lmp.py:1626]   Expert  3 |    188 | GPU
DEBUG 01-15 10:09:11.801626.801626 lmp.py:1626]   Expert 15 |    190 | GPU
DEBUG 01-15 10:09:11.801938.801938 lmp.py:1626]   Expert 24 |    193 | GPU
DEBUG 01-15 10:09:11.801011.801011 lmp.py:1626]   Expert  0 |    195 | GPU
DEBUG 01-15 10:09:11.801562.801562 lmp.py:1626]   Expert 18 |    200 | GPU
DEBUG 01-15 10:09:11.802304.802304 lmp.py:1626]   Expert 55 |    208 | GPU
DEBUG 01-15 10:09:11.802854.802854 lmp.py:1626]   Expert 40 |    212 | GPU
DEBUG 01-15 10:09:11.802882.802882 lmp.py:1626]   Expert 23 |    216 | GPU
DEBUG 01-15 10:09:11.802909.802909 lmp.py:1626]   Expert 38 |    216 | GPU
DEBUG 01-15 10:09:11.802697.802697 lmp.py:1626]   Expert 22 |    217 | GPU
DEBUG 01-15 10:09:11.802009.802009 lmp.py:1626]   Expert 37 |    223 | GPU
DEBUG 01-15 10:09:11.802037.802037 lmp.py:1626]   Expert  6 |    225 | GPU
DEBUG 01-15 10:09:11.802825.802825 lmp.py:1626]   Expert 46 |    232 | GPU
DEBUG 01-15 10:09:11.802376.802376 lmp.py:1626]   Expert 19 |    243 | GPU
DEBUG 01-15 10:09:11.802687.802687 lmp.py:1626]   Expert 39 |    249 | GPU
DEBUG 01-15 10:09:11.802191.802191 lmp.py:1626]   Expert 25 |    251 | GPU
DEBUG 01-15 10:09:11.802457.802457 lmp.py:1626]   Expert 50 |    259 | GPU
DEBUG 01-15 10:09:11.802007.802007 lmp.py:1626]   Expert 12 |    260 | GPU
DEBUG 01-15 10:09:11.802796.802796 lmp.py:1626]   Expert 62 |    270 | GPU
DEBUG 01-15 10:09:11.802823.802823 lmp.py:1626]   Expert 21 |    279 | GPU
DEBUG 01-15 10:09:11.802374.802374 lmp.py:1626]   Expert 35 |    288 | GPU
DEBUG 01-15 10:09:11.802354.802354 lmp.py:1626]   Expert 49 |    291 | GPU
DEBUG 01-15 10:09:11.802143.802143 lmp.py:1626]   Expert 33 |    300 | GPU
DEBUG 01-15 10:09:11.802409.802409 lmp.py:1626]   Expert 52 |    301 | GPU
DEBUG 01-15 10:09:11.802436.802436 lmp.py:1626]   Expert  1 |    347 | GPU
DEBUG 01-15 10:09:11.802986.802986 lmp.py:1626]   Expert  5 |    382 | GPU
DEBUG 01-15 10:09:11.802537.802537 lmp.py:1626]   Expert 43 |    437 | GPU
DEBUG 01-15 10:09:11.802610.802610 lmp.py:1626]   Expert 59 |    586 | GPU
DEBUG 01-15 10:09:11.802352.802352 lmp.py:1627] 
DEBUG 01-15 10:09:11.802352.802352 lmp.py:1627]   CPU total tokens: 4090 (33.3%)
DEBUG 01-15 10:09:11.802095.802095 lmp.py:1628]   GPU total tokens: 8198 (66.7%)
DEBUG 01-15 10:09:11.802606.802606 cuda_h.py:19] end experts_map_get cost 0.0016524791717529297 seconds
DEBUG 01-15 10:09:11.802648.802648 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:11.802119.802119 lmp.py:1636] 
DEBUG 01-15 10:09:11.802119.802119 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:11.802863.802863 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-15 10:09:11.802559.802559 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:11.802633.802633 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.803588.803588 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.803874.803874 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-15 10:09:11.803439.803439 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.803295.803295 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.803687.803687 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.803344.803344 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8c60a4a4-296d-40e6-9d25-d92f74739aaa
DEBUG 01-15 10:09:11.803415.803415 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:11.803562.803562 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.803472.803472 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:11.804709.804709 client.py:127] Model loaded
DEBUG 01-15 10:09:11.804654.804654 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.804092.804092 cuda_h.py:19] end move_flatidxs cost 0.0008463859558105469 seconds
DEBUG 01-15 10:09:11.804928.804928 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:11.805893.805893 cuda_h.py:19] end restore2model cost 0.0011012554168701172 seconds
INFO 01-15 10:09:11.805693.805693 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8c60a4a4-296d-40e6-9d25-d92f74739aaa
DEBUG 01-15 10:09:11.805532.805532 cuda_h.py:19] end sllm_worker_task cost 0.011962652206420898 seconds
DEBUG 01-15 10:09:11.805285.805285 cuda_h.py:19] end load_into_gpu_async cost 0.002259969711303711 seconds
DEBUG 01-15 10:09:11.805290.805290 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.806837.806837 cuda_h.py:19] end restore_tensors2 cost 0.0003039836883544922 seconds
DEBUG 01-15 10:09:11.806144.806144 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032804012298583984 seconds
DEBUG 01-15 10:09:11.806006.806006 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.808759.808759 cuda_h.py:19] end restore2model cost 0.0024843215942382812 seconds
DEBUG 01-15 10:09:11.808033.808033 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062253475189208984 seconds
DEBUG 01-15 10:09:11.808212.808212 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:11.809872.809872 cuda_h.py:19] end gpu_sexperts cost 0.0002770423889160156 seconds
DEBUG 01-15 10:09:11.809562.809562 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:11.809813.809813 cuda_h.py:19] end group_tensors cost 0.004229068756103516 seconds
DEBUG 01-15 10:09:11.809363.809363 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:11.811108.811108 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0020110607147216797 seconds
DEBUG 01-15 10:09:11.812339.812339 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:11.813449.813449 cuda_h.py:19] end gpu_group_list cost 0.00046563148498535156 seconds
DEBUG 01-15 10:09:11.813111.813111 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:11.813758.813758 cuda_h.py:19] end group pad cost 0.0036444664001464844 seconds
DEBUG 01-15 10:09:11.813310.813310 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:11.815436.815436 cuda_h.py:19] end acpu_expert_weight_slices cost 0.002081632614135742 seconds
DEBUG 01-15 10:09:11.815679.815679 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:11.816322.816322 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00012636184692382812 seconds
DEBUG 01-15 10:09:11.816988.816988 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:11.833364.833364 cuda_h.py:19] end group_einsum cost 0.0195004940032959 seconds
DEBUG 01-15 10:09:11.833826.833826 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:11.837771.837771 cuda_h.py:19] end get_outputs_cpu1 cost 0.004621744155883789 seconds
DEBUG 01-15 10:09:11.839540.839540 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03548789024353027 seconds
DEBUG 01-15 10:09:11.840368.840368 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0238649845123291 seconds
DEBUG 01-15 10:09:11.840799.840799 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:11.840757.840757 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.841390.841390 cuda_h.py:19] end index_scatter cost 0.0001678466796875 seconds
DEBUG 01-15 10:09:11.842850.842850 cuda_h.py:19] end cpuoutputsdeal cost 0.0015685558319091797 seconds
DEBUG 01-15 10:09:11.842960.842960 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:11.842466.842466 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8c60a4a4-296d-40e6-9d25-d92f74739aaa
INFO 01-15 10:09:11.855801.855801 client.py:127] Model loaded
DEBUG 01-15 10:09:11.855832.855832 cuda_h.py:19] end wait_experts cost 0.013303756713867188 seconds
DEBUG 01-15 10:09:11.855072.855072 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:11.855796.855796 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:11.855214.855214 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:11.856544.856544 cuda_h.py:19] end gpu_group_tensor cost 0.0005233287811279297 seconds
DEBUG 01-15 10:09:11.856086.856086 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:11.857622.857622 cuda_h.py:19] end gpu_group_einsum cost 0.0007262229919433594 seconds
DEBUG 01-15 10:09:11.857699.857699 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:11.857966.857966 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:11.857438.857438 cuda_h.py:19] end all_expert_outputs_slices cost 0.000209808349609375 seconds
DEBUG 01-15 10:09:11.857717.857717 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:11.857124.857124 cuda_h.py:19] end concat_expert_out cost 5.602836608886719e-05 seconds
DEBUG 01-15 10:09:11.857941.857941 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.857547.857547 cuda_h.py:19] end index_scatter cost 6.389617919921875e-05 seconds
DEBUG 01-15 10:09:11.857972.857972 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000579833984375 seconds
DEBUG 01-15 10:09:11.858099.858099 cuda_h.py:19] end gpu_experts cost 0.0023751258850097656 seconds
DEBUG 01-15 10:09:11.858817.858817 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.057961225509643555 seconds
DEBUG 01-15 10:09:11.858073.858073 cuda_h.py:19] end prefill_layer cost 0.06529474258422852 seconds
DEBUG 01-15 10:09:11.858949.858949 lmp.py:1552] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-15 10:09:11.858837.858837 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:11.858441.858441 lmp.py:1495] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-15 10:09:11.858567.858567 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:11.858316.858316 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:11.858014.858014 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.266334533691406e-05 seconds
DEBUG 01-15 10:09:11.858048.858048 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.079673767089844e-05 seconds
DEBUG 01-15 10:09:11.858360.858360 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:11.858931.858931 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:11.858657.858657 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:11.859234.859234 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.859630.859630 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.859243.859243 cuda_h.py:19] end allocate_cuda_memory cost 0.00041747093200683594 seconds
DEBUG 01-15 10:09:11.859653.859653 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.859828.859828 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.860699.860699 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.860988.860988 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7598749-5e1f-433d-887b-d66632c58b17
DEBUG 01-15 10:09:11.860837.860837 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.860066.860066 cuda_h.py:10] start self_attn
INFO 01-15 10:09:11.861944.861944 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7598749-5e1f-433d-887b-d66632c58b17
DEBUG 01-15 10:09:11.861744.861744 cuda_h.py:19] end load_into_gpu_async cost 0.0016524791717529297 seconds
DEBUG 01-15 10:09:11.861192.861192 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.862690.862690 cuda_h.py:19] end restore_tensors2 cost 0.00014138221740722656 seconds
DEBUG 01-15 10:09:11.862687.862687 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003144979476928711 seconds
INFO 01-15 10:09:11.862539.862539 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7598749-5e1f-433d-887b-d66632c58b17
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.865867.865867 cuda_h.py:19] end self_attn cost 0.004199028015136719 seconds
DEBUG 01-15 10:09:11.865772.865772 cuda_h.py:19] end iln_self_attn_paln cost 0.006734132766723633 seconds
DEBUG 01-15 10:09:11.865383.865383 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-15 10:09:11.865530.865530 cuda_h.py:10] start gate
DEBUG 01-15 10:09:11.866287.866287 cuda_h.py:19] end gate cost 0.0006268024444580078 seconds
DEBUG 01-15 10:09:11.866647.866647 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:11.866948.866948 lmp.py:1616] 
DEBUG 01-15 10:09:11.866948.866948 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:11.866419.866419 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:11.866784.866784 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:11.866573.866573 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:11.866216.866216 lmp.py:1620] 
DEBUG 01-15 10:09:11.866216.866216 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:11.866336.866336 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:11.866409.866409 lmp.py:1626]   Expert 34 |     24 | CPU
DEBUG 01-15 10:09:11.866814.866814 lmp.py:1626]   Expert 45 |     67 | CPU
DEBUG 01-15 10:09:11.866218.866218 lmp.py:1626]   Expert 22 |     73 | CPU
DEBUG 01-15 10:09:11.866623.866623 lmp.py:1626]   Expert 57 |     77 | CPU
DEBUG 01-15 10:09:11.866789.866789 lmp.py:1626]   Expert 17 |     96 | CPU
DEBUG 01-15 10:09:11.866194.866194 lmp.py:1626]   Expert 15 |     99 | CPU
DEBUG 01-15 10:09:11.866360.866360 lmp.py:1626]   Expert  4 |    100 | CPU
DEBUG 01-15 10:09:11.866003.866003 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:11.866646.866646 lmp.py:1626]   Expert 60 |    112 | CPU
DEBUG 01-15 10:09:11.866573.866573 lmp.py:1626]   Expert 32 |    113 | CPU
DEBUG 01-15 10:09:11.866501.866501 lmp.py:1626]   Expert 36 |    124 | CPU
DEBUG 01-15 10:09:11.866429.866429 lmp.py:1626]   Expert 14 |    126 | CPU
DEBUG 01-15 10:09:11.866118.866118 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:11.866046.866046 lmp.py:1626]   Expert 12 |    128 | CPU
DEBUG 01-15 10:09:11.866735.866735 lmp.py:1626]   Expert 52 |    130 | CPU
DEBUG 01-15 10:09:11.866901.866901 lmp.py:1626]   Expert 25 |    132 | CPU
DEBUG 01-15 10:09:11.866829.866829 lmp.py:1626]   Expert  8 |    134 | CPU
DEBUG 01-15 10:09:11.866233.866233 lmp.py:1626]   Expert  2 |    139 | CPU
DEBUG 01-15 10:09:11.866307.866307 lmp.py:1626]   Expert 35 |    142 | CPU
DEBUG 01-15 10:09:11.866380.866380 lmp.py:1626]   Expert  5 |    147 | CPU
DEBUG 01-15 10:09:11.867023.867023 lmp.py:1626]   Expert 23 |    153 | CPU
DEBUG 01-15 10:09:11.867004.867004 lmp.py:1626]   Expert 30 |    153 | CPU
DEBUG 01-15 10:09:11.867270.867270 lmp.py:1626]   Expert  0 |    157 | CPU
DEBUG 01-15 10:09:11.867297.867297 lmp.py:1626]   Expert 39 |    157 | CPU
DEBUG 01-15 10:09:11.867086.867086 lmp.py:1626]   Expert 61 |    157 | CPU
DEBUG 01-15 10:09:11.867874.867874 lmp.py:1626]   Expert  3 |    167 | CPU
DEBUG 01-15 10:09:11.867617.867617 lmp.py:1626]   Expert 13 |    171 | CPU
DEBUG 01-15 10:09:11.867882.867882 lmp.py:1626]   Expert 42 |    172 | CPU
DEBUG 01-15 10:09:11.867148.867148 lmp.py:1626]   Expert 31 |    174 | CPU
DEBUG 01-15 10:09:11.867937.867937 lmp.py:1626]   Expert 44 |    174 | CPU
DEBUG 01-15 10:09:11.867726.867726 lmp.py:1626]   Expert  9 |    179 | CPU
DEBUG 01-15 10:09:11.867276.867276 lmp.py:1626]   Expert 41 |    179 | CPU
DEBUG 01-15 10:09:11.867303.867303 lmp.py:1626]   Expert 46 |    179 | GPU
DEBUG 01-15 10:09:11.867853.867853 lmp.py:1626]   Expert 43 |    180 | GPU
DEBUG 01-15 10:09:11.867404.867404 lmp.py:1626]   Expert 62 |    190 | GPU
DEBUG 01-15 10:09:11.867861.867861 lmp.py:1626]   Expert 26 |    191 | GPU
DEBUG 01-15 10:09:11.867604.867604 lmp.py:1626]   Expert 18 |    192 | GPU
DEBUG 01-15 10:09:11.867346.867346 lmp.py:1626]   Expert 50 |    192 | GPU
DEBUG 01-15 10:09:11.867373.867373 lmp.py:1626]   Expert 27 |    193 | GPU
DEBUG 01-15 10:09:11.867162.867162 lmp.py:1626]   Expert 51 |    195 | GPU
DEBUG 01-15 10:09:11.867712.867712 lmp.py:1626]   Expert 49 |    197 | GPU
DEBUG 01-15 10:09:11.867263.867263 lmp.py:1626]   Expert 11 |    200 | GPU
DEBUG 01-15 10:09:11.867051.867051 lmp.py:1626]   Expert 47 |    203 | GPU
DEBUG 01-15 10:09:11.867840.867840 lmp.py:1626]   Expert 19 |    204 | GPU
DEBUG 01-15 10:09:11.867106.867106 lmp.py:1626]   Expert 20 |    204 | GPU
DEBUG 01-15 10:09:11.867848.867848 lmp.py:1626]   Expert 63 |    205 | GPU
DEBUG 01-15 10:09:11.867352.867352 lmp.py:1626]   Expert 55 |    211 | GPU
DEBUG 01-15 10:09:11.867618.867618 lmp.py:1626]   Expert 56 |    211 | GPU
DEBUG 01-15 10:09:11.867930.867930 lmp.py:1626]   Expert 38 |    217 | GPU
DEBUG 01-15 10:09:11.867718.867718 lmp.py:1626]   Expert 48 |    228 | GPU
DEBUG 01-15 10:09:11.867507.867507 lmp.py:1626]   Expert  1 |    237 | GPU
DEBUG 01-15 10:09:11.867057.867057 lmp.py:1626]   Expert 10 |    242 | GPU
DEBUG 01-15 10:09:11.867846.867846 lmp.py:1626]   Expert 21 |    246 | GPU
DEBUG 01-15 10:09:11.867350.867350 lmp.py:1626]   Expert 54 |    248 | GPU
DEBUG 01-15 10:09:11.867331.867331 lmp.py:1626]   Expert  7 |    249 | GPU
DEBUG 01-15 10:09:11.867120.867120 lmp.py:1626]   Expert 33 |    256 | GPU
DEBUG 01-15 10:09:11.867670.867670 lmp.py:1626]   Expert 29 |    259 | GPU
DEBUG 01-15 10:09:11.867697.867697 lmp.py:1626]   Expert 40 |    266 | GPU
DEBUG 01-15 10:09:11.867248.867248 lmp.py:1626]   Expert 24 |    269 | GPU
DEBUG 01-15 10:09:11.867275.867275 lmp.py:1626]   Expert 59 |    301 | GPU
DEBUG 01-15 10:09:11.867587.867587 lmp.py:1626]   Expert 37 |    332 | GPU
DEBUG 01-15 10:09:11.867375.867375 lmp.py:1626]   Expert 58 |    365 | GPU
DEBUG 01-15 10:09:11.867403.867403 lmp.py:1626]   Expert  6 |    388 | GPU
DEBUG 01-15 10:09:11.867907.867907 lmp.py:1626]   Expert 53 |    851 | GPU
DEBUG 01-15 10:09:11.867364.867364 lmp.py:1627] 
DEBUG 01-15 10:09:11.867364.867364 lmp.py:1627]   CPU total tokens: 4187 (34.1%)
DEBUG 01-15 10:09:11.867345.867345 lmp.py:1628]   GPU total tokens: 8101 (65.9%)
DEBUG 01-15 10:09:11.867902.867902 cuda_h.py:19] end experts_map_get cost 0.001668691635131836 seconds
DEBUG 01-15 10:09:11.868328.868328 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:11.868177.868177 lmp.py:1636] 
DEBUG 01-15 10:09:11.868177.868177 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:11.868775.868775 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-15 10:09:11.868663.868663 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:11.868022.868022 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.868583.868583 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.868916.868916 cuda_h.py:19] end allocate_cuda_memory cost 0.00021004676818847656 seconds
DEBUG 01-15 10:09:11.868812.868812 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.868197.868197 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.868543.868543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.868630.868630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4ef24fd6-cc4f-43d0-bb2a-0bd85b664387
DEBUG 01-15 10:09:11.868352.868352 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:11.869347.869347 client.py:127] Model loaded
DEBUG 01-15 10:09:11.869766.869766 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.870370.870370 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:11.870398.870398 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:11.870977.870977 cuda_h.py:19] end restore2model cost 0.001065969467163086 seconds
DEBUG 01-15 10:09:11.870670.870670 cuda_h.py:19] end sllm_worker_task cost 0.011851072311401367 seconds
INFO 01-15 10:09:11.871961.871961 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4ef24fd6-cc4f-43d0-bb2a-0bd85b664387
DEBUG 01-15 10:09:11.871772.871772 cuda_h.py:19] end load_into_gpu_async cost 0.002525806427001953 seconds
DEBUG 01-15 10:09:11.871005.871005 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.871778.871778 cuda_h.py:19] end restore_tensors2 cost 0.0002982616424560547 seconds
DEBUG 01-15 10:09:11.871123.871123 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033860206604003906 seconds
DEBUG 01-15 10:09:11.871794.871794 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.871547.871547 cuda_h.py:19] end move_flatidxs cost 0.0009968280792236328 seconds
DEBUG 01-15 10:09:11.871934.871934 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:11.874562.874562 cuda_h.py:19] end restore2model cost 0.0025298595428466797 seconds
DEBUG 01-15 10:09:11.874743.874743 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006108999252319336 seconds
DEBUG 01-15 10:09:11.874538.874538 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:11.874383.874383 cuda_h.py:19] end gpu_sexperts cost 0.0002722740173339844 seconds
DEBUG 01-15 10:09:11.874934.874934 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:11.876441.876441 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014605522155761719 seconds
DEBUG 01-15 10:09:11.876367.876367 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:11.877877.877877 cuda_h.py:19] end gpu_group_list cost 0.00032138824462890625 seconds
DEBUG 01-15 10:09:11.877079.877079 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:11.878633.878633 cuda_h.py:19] end acpu_expert_weight_slices cost 0.000682830810546875 seconds
DEBUG 01-15 10:09:11.878741.878741 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:11.878855.878855 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-15 10:09:11.878458.878458 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:11.883216.883216 cuda_h.py:19] end group_tensors cost 0.011354684829711914 seconds
DEBUG 01-15 10:09:11.883009.883009 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:11.887856.887856 cuda_h.py:19] end group pad cost 0.004083395004272461 seconds
DEBUG 01-15 10:09:11.887838.887838 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:11.911804.911804 cuda_h.py:19] end group_einsum cost 0.023411989212036133 seconds
DEBUG 01-15 10:09:11.911273.911273 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:11.916492.916492 cuda_h.py:19] end get_outputs_cpu1 cost 0.004677534103393555 seconds
DEBUG 01-15 10:09:11.917509.917509 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.047139644622802734 seconds
DEBUG 01-15 10:09:11.918266.918266 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04027605056762695 seconds
DEBUG 01-15 10:09:11.918418.918418 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:11.919976.919976 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.919310.919310 cuda_h.py:19] end index_scatter cost 0.00015735626220703125 seconds
DEBUG 01-15 10:09:11.920051.920051 cuda_h.py:19] end cpuoutputsdeal cost 0.001203298568725586 seconds
DEBUG 01-15 10:09:11.920022.920022 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:11.920621.920621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4ef24fd6-cc4f-43d0-bb2a-0bd85b664387
INFO 01-15 10:09:11.921851.921851 client.py:127] Model loaded
DEBUG 01-15 10:09:11.921273.921273 cuda_h.py:19] end wait_experts cost 0.0014691352844238281 seconds
DEBUG 01-15 10:09:11.921229.921229 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:11.921644.921644 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:11.922845.922845 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:11.922602.922602 cuda_h.py:19] end gpu_group_tensor cost 0.0003745555877685547 seconds
DEBUG 01-15 10:09:11.922768.922768 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:11.925742.925742 cuda_h.py:19] end gpu_group_einsum cost 0.002250194549560547 seconds
DEBUG 01-15 10:09:11.925930.925930 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:11.925729.925729 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:11.926367.926367 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005571842193603516 seconds
DEBUG 01-15 10:09:11.926859.926859 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:11.926429.926429 cuda_h.py:19] end concat_expert_out cost 0.00013017654418945312 seconds
DEBUG 01-15 10:09:11.926964.926964 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.926580.926580 cuda_h.py:19] end index_scatter cost 0.00011897087097167969 seconds
DEBUG 01-15 10:09:11.926325.926325 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014119148254394531 seconds
DEBUG 01-15 10:09:11.927410.927410 cuda_h.py:19] end gpu_experts cost 0.005155324935913086 seconds
DEBUG 01-15 10:09:11.927503.927503 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.061698198318481445 seconds
DEBUG 01-15 10:09:11.927481.927481 cuda_h.py:19] end prefill_layer cost 0.0694277286529541 seconds
DEBUG 01-15 10:09:11.928618.928618 lmp.py:1552] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-15 10:09:11.928429.928429 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:11.928762.928762 lmp.py:1495] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-15 10:09:11.928526.928526 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:11.928297.928297 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:11.928143.928143 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:11.928490.928490 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 0.00016045570373535156 seconds
DEBUG 01-15 10:09:11.928340.928340 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:11.928194.928194 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:11.929618.929618 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:11.929681.929681 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.929421.929421 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.930176.930176 cuda_h.py:19] end allocate_cuda_memory cost 0.00048351287841796875 seconds
DEBUG 01-15 10:09:11.930685.930685 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.930337.930337 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.930070.930070 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.930562.930562 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb605cc8-d5f6-4f6b-b83a-f7a5c75b25b3
DEBUG 01-15 10:09:11.930331.930331 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.931141.931141 cuda_h.py:10] start self_attn
INFO 01-15 10:09:11.932720.932720 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb605cc8-d5f6-4f6b-b83a-f7a5c75b25b3
DEBUG 01-15 10:09:11.932350.932350 cuda_h.py:19] end load_into_gpu_async cost 0.0023534297943115234 seconds
DEBUG 01-15 10:09:11.932750.932750 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.933785.933785 cuda_h.py:19] end restore_tensors2 cost 0.00015854835510253906 seconds
DEBUG 01-15 10:09:11.933206.933206 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037207603454589844 seconds
INFO 01-15 10:09:11.933787.933787 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb605cc8-d5f6-4f6b-b83a-f7a5c75b25b3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:11.936920.936920 cuda_h.py:19] end self_attn cost 0.00493621826171875 seconds
DEBUG 01-15 10:09:11.936723.936723 cuda_h.py:19] end iln_self_attn_paln cost 0.008005619049072266 seconds
DEBUG 01-15 10:09:11.936487.936487 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-15 10:09:11.936826.936826 cuda_h.py:10] start gate
DEBUG 01-15 10:09:11.937406.937406 cuda_h.py:19] end gate cost 0.0006709098815917969 seconds
DEBUG 01-15 10:09:11.937620.937620 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:11.937300.937300 lmp.py:1616] 
DEBUG 01-15 10:09:11.937300.937300 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:11.937771.937771 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:11.938851.938851 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:11.938693.938693 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:11.938151.938151 lmp.py:1620] 
DEBUG 01-15 10:09:11.938151.938151 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:11.938370.938370 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:11.938020.938020 lmp.py:1626]   Expert  1 |     45 | CPU
DEBUG 01-15 10:09:11.938239.938239 lmp.py:1626]   Expert  7 |     59 | CPU
DEBUG 01-15 10:09:11.938743.938743 lmp.py:1626]   Expert 37 |     70 | CPU
DEBUG 01-15 10:09:11.938770.938770 lmp.py:1626]   Expert 54 |     76 | CPU
DEBUG 01-15 10:09:11.938513.938513 lmp.py:1626]   Expert 17 |     77 | CPU
DEBUG 01-15 10:09:11.938970.938970 lmp.py:1626]   Expert 18 |     84 | CPU
DEBUG 01-15 10:09:11.938759.938759 lmp.py:1626]   Expert  9 |     91 | CPU
DEBUG 01-15 10:09:11.938548.938548 lmp.py:1626]   Expert 13 |     92 | CPU
DEBUG 01-15 10:09:11.938052.938052 lmp.py:1626]   Expert 58 |    100 | CPU
DEBUG 01-15 10:09:11.938079.938079 lmp.py:1626]   Expert 22 |    103 | CPU
DEBUG 01-15 10:09:11.938583.938583 lmp.py:1626]   Expert  0 |    105 | CPU
DEBUG 01-15 10:09:11.938849.938849 lmp.py:1626]   Expert 16 |    117 | CPU
DEBUG 01-15 10:09:11.938876.938876 lmp.py:1626]   Expert 26 |    117 | CPU
DEBUG 01-15 10:09:11.938903.938903 lmp.py:1626]   Expert 10 |    121 | CPU
DEBUG 01-15 10:09:11.938645.938645 lmp.py:1626]   Expert 63 |    129 | CPU
DEBUG 01-15 10:09:11.938911.938911 lmp.py:1626]   Expert 59 |    131 | CPU
DEBUG 01-15 10:09:11.938700.938700 lmp.py:1626]   Expert 43 |    141 | CPU
DEBUG 01-15 10:09:11.938250.938250 lmp.py:1626]   Expert 62 |    142 | CPU
DEBUG 01-15 10:09:11.938800.938800 lmp.py:1626]   Expert 28 |    147 | CPU
DEBUG 01-15 10:09:11.938351.938351 lmp.py:1626]   Expert 29 |    149 | CPU
DEBUG 01-15 10:09:11.938139.938139 lmp.py:1626]   Expert 33 |    149 | CPU
DEBUG 01-15 10:09:11.938928.938928 lmp.py:1626]   Expert  2 |    157 | CPU
DEBUG 01-15 10:09:11.938479.938479 lmp.py:1626]   Expert 51 |    161 | CPU
DEBUG 01-15 10:09:11.938267.938267 lmp.py:1626]   Expert 55 |    164 | CPU
DEBUG 01-15 10:09:11.938818.938818 lmp.py:1626]   Expert 11 |    166 | CPU
DEBUG 01-15 10:09:11.938560.938560 lmp.py:1626]   Expert  3 |    167 | CPU
DEBUG 01-15 10:09:11.938064.938064 lmp.py:1626]   Expert 32 |    168 | CPU
DEBUG 01-15 10:09:11.938853.938853 lmp.py:1626]   Expert 53 |    168 | CPU
DEBUG 01-15 10:09:11.938403.938403 lmp.py:1626]   Expert 23 |    170 | CPU
DEBUG 01-15 10:09:11.938953.938953 lmp.py:1626]   Expert 45 |    170 | CPU
DEBUG 01-15 10:09:11.938265.938265 lmp.py:1626]   Expert 40 |    171 | CPU
DEBUG 01-15 10:09:11.938531.938531 lmp.py:1626]   Expert 34 |    174 | CPU
DEBUG 01-15 10:09:11.938273.938273 lmp.py:1626]   Expert 14 |    177 | GPU
DEBUG 01-15 10:09:11.938062.938062 lmp.py:1626]   Expert 52 |    182 | GPU
DEBUG 01-15 10:09:11.938851.938851 lmp.py:1626]   Expert 41 |    183 | GPU
DEBUG 01-15 10:09:11.938401.938401 lmp.py:1626]   Expert 42 |    184 | GPU
DEBUG 01-15 10:09:11.938667.938667 lmp.py:1626]   Expert 21 |    185 | GPU
DEBUG 01-15 10:09:11.938217.938217 lmp.py:1626]   Expert 57 |    196 | GPU
DEBUG 01-15 10:09:11.938529.938529 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:11.938556.938556 lmp.py:1626]   Expert 30 |    199 | GPU
DEBUG 01-15 10:09:11.938060.938060 lmp.py:1626]   Expert 35 |    208 | GPU
DEBUG 01-15 10:09:11.938610.938610 lmp.py:1626]   Expert  4 |    217 | GPU
DEBUG 01-15 10:09:11.938922.938922 lmp.py:1626]   Expert 12 |    219 | GPU
DEBUG 01-15 10:09:11.938473.938473 lmp.py:1626]   Expert 46 |    229 | GPU
DEBUG 01-15 10:09:11.938785.938785 lmp.py:1626]   Expert 19 |    230 | GPU
DEBUG 01-15 10:09:11.939096.939096 lmp.py:1626]   Expert 50 |    230 | GPU
DEBUG 01-15 10:09:11.939362.939362 lmp.py:1626]   Expert 24 |    231 | GPU
DEBUG 01-15 10:09:11.939436.939436 lmp.py:1626]   Expert 44 |    234 | GPU
DEBUG 01-15 10:09:11.939701.939701 lmp.py:1626]   Expert 49 |    234 | GPU
DEBUG 01-15 10:09:11.939967.939967 lmp.py:1626]   Expert  8 |    237 | GPU
DEBUG 01-15 10:09:11.939994.939994 lmp.py:1626]   Expert 38 |    238 | GPU
DEBUG 01-15 10:09:11.939783.939783 lmp.py:1626]   Expert  6 |    246 | GPU
DEBUG 01-15 10:09:11.939029.939029 lmp.py:1626]   Expert 47 |    248 | GPU
DEBUG 01-15 10:09:11.939626.939626 lmp.py:1626]   Expert 31 |    255 | GPU
DEBUG 01-15 10:09:11.939792.939792 lmp.py:1626]   Expert 61 |    259 | GPU
DEBUG 01-15 10:09:11.939581.939581 lmp.py:1626]   Expert 39 |    276 | GPU
DEBUG 01-15 10:09:11.939846.939846 lmp.py:1626]   Expert  5 |    303 | GPU
DEBUG 01-15 10:09:11.939112.939112 lmp.py:1626]   Expert 36 |    305 | GPU
DEBUG 01-15 10:09:11.939377.939377 lmp.py:1626]   Expert 27 |    307 | GPU
DEBUG 01-15 10:09:11.939404.939404 lmp.py:1626]   Expert 60 |    334 | GPU
DEBUG 01-15 10:09:11.939955.939955 lmp.py:1626]   Expert 20 |    338 | GPU
DEBUG 01-15 10:09:11.939743.939743 lmp.py:1626]   Expert 48 |    371 | GPU
DEBUG 01-15 10:09:11.939771.939771 lmp.py:1626]   Expert 25 |    395 | GPU
DEBUG 01-15 10:09:11.939083.939083 lmp.py:1626]   Expert 56 |    558 | GPU
DEBUG 01-15 10:09:11.939302.939302 lmp.py:1627] 
DEBUG 01-15 10:09:11.939302.939302 lmp.py:1627]   CPU total tokens: 4081 (33.2%)
DEBUG 01-15 10:09:11.939236.939236 lmp.py:1628]   GPU total tokens: 8207 (66.8%)
DEBUG 01-15 10:09:11.939986.939986 cuda_h.py:19] end experts_map_get cost 0.0017840862274169922 seconds
INFO 01-15 10:09:11.939858.939858 client.py:127] Model loaded
DEBUG 01-15 10:09:11.939261.939261 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:11.939749.939749 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.940792.940792 lmp.py:1636] 
DEBUG 01-15 10:09:11.940792.940792 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:11.940487.940487 cuda_h.py:19] end cpu_experts_submit cost 0.0003781318664550781 seconds
DEBUG 01-15 10:09:11.940979.940979 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:11.940974.940974 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:11.940416.940416 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:11.940181.940181 cuda_h.py:19] end allocate_cuda_memory cost 0.00024509429931640625 seconds
DEBUG 01-15 10:09:11.941461.941461 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:11.941078.941078 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:11.941186.941186 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:11.941127.941127 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b28eae53-81c7-4896-be07-1ddd676f6b55
DEBUG 01-15 10:09:11.941505.941505 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:11.942661.942661 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:11.942705.942705 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:11.942866.942866 cuda_h.py:19] end restore2model cost 0.0026400089263916016 seconds
INFO 01-15 10:09:11.943084.943084 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b28eae53-81c7-4896-be07-1ddd676f6b55
DEBUG 01-15 10:09:11.943520.943520 cuda_h.py:19] end sllm_worker_task cost 0.013801097869873047 seconds
DEBUG 01-15 10:09:11.943518.943518 cuda_h.py:19] end load_into_gpu_async cost 0.002239227294921875 seconds
DEBUG 01-15 10:09:11.943198.943198 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:11.943543.943543 cuda_h.py:19] end move_flatidxs cost 0.0009975433349609375 seconds
DEBUG 01-15 10:09:11.943609.943609 cuda_h.py:19] end restore_tensors2 cost 0.00037670135498046875 seconds
DEBUG 01-15 10:09:11.943770.943770 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033686161041259766 seconds
DEBUG 01-15 10:09:11.943194.943194 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:11.943440.943440 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:11.946190.946190 cuda_h.py:19] end restore2model cost 0.002592802047729492 seconds
DEBUG 01-15 10:09:11.946080.946080 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0061566829681396484 seconds
DEBUG 01-15 10:09:11.946829.946829 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:11.946270.946270 cuda_h.py:19] end gpu_sexperts cost 0.0002923011779785156 seconds
DEBUG 01-15 10:09:11.947060.947060 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:11.948402.948402 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014786720275878906 seconds
DEBUG 01-15 10:09:11.949328.949328 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:11.949307.949307 cuda_h.py:19] end gpu_group_list cost 0.0003216266632080078 seconds
DEBUG 01-15 10:09:11.949709.949709 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:11.950839.950839 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006883144378662109 seconds
DEBUG 01-15 10:09:11.950470.950470 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:11.950207.950207 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-15 10:09:11.950333.950333 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:11.953482.953482 cuda_h.py:19] end group_tensors cost 0.009753704071044922 seconds
DEBUG 01-15 10:09:11.954339.954339 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:11.958975.958975 cuda_h.py:19] end group pad cost 0.0037169456481933594 seconds
DEBUG 01-15 10:09:11.958394.958394 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:11.980901.980901 cuda_h.py:19] end group_einsum cost 0.022363901138305664 seconds
DEBUG 01-15 10:09:11.980741.980741 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:11.985842.985842 cuda_h.py:19] end get_outputs_cpu1 cost 0.004907369613647461 seconds
DEBUG 01-15 10:09:11.986083.986083 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.044304609298706055 seconds
DEBUG 01-15 10:09:11.987143.987143 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03676795959472656 seconds
DEBUG 01-15 10:09:11.987751.987751 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:11.988090.988090 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.988151.988151 cuda_h.py:19] end index_scatter cost 0.00013589859008789062 seconds
DEBUG 01-15 10:09:11.988478.988478 cuda_h.py:19] end cpuoutputsdeal cost 0.0012400150299072266 seconds
DEBUG 01-15 10:09:11.989773.989773 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:11.989412.989412 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b28eae53-81c7-4896-be07-1ddd676f6b55
INFO 01-15 10:09:11.995583.995583 client.py:127] Model loaded
DEBUG 01-15 10:09:11.996581.996581 cuda_h.py:19] end wait_experts cost 0.00683283805847168 seconds
DEBUG 01-15 10:09:11.996491.996491 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:11.996667.996667 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:11.996922.996922 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:11.996136.996136 cuda_h.py:19] end gpu_group_tensor cost 0.000392913818359375 seconds
DEBUG 01-15 10:09:11.996143.996143 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:11.998204.998204 cuda_h.py:19] end gpu_group_einsum cost 0.0010900497436523438 seconds
DEBUG 01-15 10:09:11.998013.998013 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:11.998183.998183 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:11.999483.999483 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005598068237304688 seconds
DEBUG 01-15 10:09:11.999399.999399 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:11.999916.999916 cuda_h.py:19] end concat_expert_out cost 0.00012922286987304688 seconds
DEBUG 01-15 10:09:11.999821.999821 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:11.999338.999338 cuda_h.py:19] end index_scatter cost 0.00011849403381347656 seconds
DEBUG 01-15 10:09:11.999984.999984 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001386880874633789 seconds
DEBUG 01-15 10:09:12.000208.000208 cuda_h.py:19] end gpu_experts cost 0.003931522369384766 seconds
DEBUG 01-15 10:09:12.000744.000744 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.06338000297546387 seconds
DEBUG 01-15 10:09:12.001378.001378 cuda_h.py:19] end prefill_layer cost 0.07277607917785645 seconds
DEBUG 01-15 10:09:12.001316.001316 lmp.py:1552] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-15 10:09:12.001504.001504 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.001791.001791 lmp.py:1495] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-15 10:09:12.001555.001555 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:12.001796.001796 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:12.001767.001767 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.031990051269531e-05 seconds
DEBUG 01-15 10:09:12.001033.001033 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.0001246929168701172 seconds
DEBUG 01-15 10:09:12.001386.001386 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.001377.001377 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.001953.001953 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.002941.002941 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.002258.002258 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.002925.002925 cuda_h.py:19] end allocate_cuda_memory cost 0.0004584789276123047 seconds
DEBUG 01-15 10:09:12.003090.003090 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.003457.003457 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.003474.003474 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.003344.003344 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9fd85640-d0a0-49c9-825c-07436cfeebed
DEBUG 01-15 10:09:12.003590.003590 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.004952.004952 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.005939.005939 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9fd85640-d0a0-49c9-825c-07436cfeebed
DEBUG 01-15 10:09:12.005640.005640 cuda_h.py:19] end load_into_gpu_async cost 0.002096414566040039 seconds
DEBUG 01-15 10:09:12.005611.005611 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.005222.005222 cuda_h.py:19] end restore_tensors2 cost 0.00015735626220703125 seconds
DEBUG 01-15 10:09:12.005404.005404 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003435850143432617 seconds
INFO 01-15 10:09:12.005468.005468 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9fd85640-d0a0-49c9-825c-07436cfeebed
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.010472.010472 cuda_h.py:19] end self_attn cost 0.006234645843505859 seconds
DEBUG 01-15 10:09:12.011803.011803 cuda_h.py:19] end iln_self_attn_paln cost 0.009615659713745117 seconds
DEBUG 01-15 10:09:12.011727.011727 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-15 10:09:12.011260.011260 cuda_h.py:10] start gate
INFO 01-15 10:09:12.012592.012592 client.py:127] Model loaded
DEBUG 01-15 10:09:12.012585.012585 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.013113.013113 cuda_h.py:19] end restore2model cost 0.0012216567993164062 seconds
DEBUG 01-15 10:09:12.013266.013266 cuda_h.py:19] end sllm_worker_task cost 0.011704206466674805 seconds
DEBUG 01-15 10:09:12.014490.014490 cuda_h.py:19] end gate cost 0.0024399757385253906 seconds
DEBUG 01-15 10:09:12.014487.014487 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.014632.014632 lmp.py:1616] 
DEBUG 01-15 10:09:12.014632.014632 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.014071.014071 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.014919.014919 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.014715.014715 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.014649.014649 lmp.py:1620] 
DEBUG 01-15 10:09:12.014649.014649 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.014538.014538 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.014294.014294 lmp.py:1626]   Expert 50 |     45 | CPU
DEBUG 01-15 10:09:12.014420.014420 lmp.py:1626]   Expert  3 |     54 | CPU
DEBUG 01-15 10:09:12.014593.014593 lmp.py:1626]   Expert 46 |     56 | CPU
DEBUG 01-15 10:09:12.014528.014528 lmp.py:1626]   Expert  1 |     77 | CPU
DEBUG 01-15 10:09:12.014747.014747 lmp.py:1626]   Expert 29 |     86 | CPU
DEBUG 01-15 10:09:12.014205.014205 lmp.py:1626]   Expert  4 |     87 | CPU
DEBUG 01-15 10:09:12.014424.014424 lmp.py:1626]   Expert 40 |     94 | CPU
DEBUG 01-15 10:09:12.014120.014120 lmp.py:1626]   Expert 15 |     97 | CPU
DEBUG 01-15 10:09:12.014578.014578 lmp.py:1626]   Expert  8 |    110 | CPU
DEBUG 01-15 10:09:12.014804.014804 lmp.py:1626]   Expert 28 |    113 | CPU
DEBUG 01-15 10:09:12.014500.014500 lmp.py:1626]   Expert 41 |    113 | CPU
DEBUG 01-15 10:09:12.014481.014481 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:12.014461.014461 lmp.py:1626]   Expert 48 |    127 | CPU
DEBUG 01-15 10:09:12.015442.015442 lmp.py:1626]   Expert 27 |    128 | CPU
DEBUG 01-15 10:09:12.015900.015900 lmp.py:1626]   Expert  6 |    129 | CPU
DEBUG 01-15 10:09:12.015358.015358 lmp.py:1626]   Expert 13 |    132 | CPU
DEBUG 01-15 10:09:12.015815.015815 lmp.py:1626]   Expert 54 |    134 | CPU
DEBUG 01-15 10:09:12.015035.015035 lmp.py:1626]   Expert  7 |    135 | CPU
DEBUG 01-15 10:09:12.015207.015207 lmp.py:1626]   Expert 51 |    137 | CPU
DEBUG 01-15 10:09:12.015427.015427 lmp.py:1626]   Expert 39 |    138 | CPU
DEBUG 01-15 10:09:12.015884.015884 lmp.py:1626]   Expert 60 |    140 | CPU
DEBUG 01-15 10:09:12.015104.015104 lmp.py:1626]   Expert 18 |    141 | CPU
DEBUG 01-15 10:09:12.015561.015561 lmp.py:1626]   Expert 14 |    146 | CPU
DEBUG 01-15 10:09:12.015019.015019 lmp.py:1626]   Expert 43 |    147 | CPU
DEBUG 01-15 10:09:12.015238.015238 lmp.py:1626]   Expert 52 |    147 | CPU
DEBUG 01-15 10:09:12.015219.015219 lmp.py:1626]   Expert 56 |    148 | CPU
DEBUG 01-15 10:09:12.015961.015961 lmp.py:1626]   Expert 20 |    150 | CPU
DEBUG 01-15 10:09:12.015850.015850 lmp.py:1626]   Expert 36 |    151 | CPU
DEBUG 01-15 10:09:12.015831.015831 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:12.015811.015811 lmp.py:1626]   Expert 45 |    156 | CPU
DEBUG 01-15 10:09:12.015554.015554 lmp.py:1626]   Expert 10 |    157 | CPU
DEBUG 01-15 10:09:12.015535.015535 lmp.py:1626]   Expert 11 |    157 | CPU
DEBUG 01-15 10:09:12.015277.015277 lmp.py:1626]   Expert  5 |    161 | GPU
DEBUG 01-15 10:09:12.015258.015258 lmp.py:1626]   Expert 62 |    168 | GPU
DEBUG 01-15 10:09:12.015669.015669 lmp.py:1626]   Expert 57 |    173 | GPU
DEBUG 01-15 10:09:12.015888.015888 lmp.py:1626]   Expert 44 |    178 | GPU
DEBUG 01-15 10:09:12.015869.015869 lmp.py:1626]   Expert 58 |    179 | GPU
DEBUG 01-15 10:09:12.015612.015612 lmp.py:1626]   Expert 25 |    181 | GPU
DEBUG 01-15 10:09:12.015354.015354 lmp.py:1626]   Expert 33 |    183 | GPU
DEBUG 01-15 10:09:12.015097.015097 lmp.py:1626]   Expert 53 |    183 | GPU
DEBUG 01-15 10:09:12.015077.015077 lmp.py:1626]   Expert 32 |    189 | GPU
DEBUG 01-15 10:09:12.015535.015535 lmp.py:1626]   Expert  2 |    190 | GPU
DEBUG 01-15 10:09:12.015185.015185 lmp.py:1626]   Expert 35 |    197 | GPU
DEBUG 01-15 10:09:12.015166.015166 lmp.py:1626]   Expert 21 |    201 | GPU
DEBUG 01-15 10:09:12.015146.015146 lmp.py:1626]   Expert 31 |    201 | GPU
DEBUG 01-15 10:09:12.015127.015127 lmp.py:1626]   Expert 63 |    202 | GPU
DEBUG 01-15 10:09:12.015870.015870 lmp.py:1626]   Expert 49 |    206 | GPU
DEBUG 01-15 10:09:12.015612.015612 lmp.py:1626]   Expert 17 |    208 | GPU
DEBUG 01-15 10:09:12.015593.015593 lmp.py:1626]   Expert 42 |    217 | GPU
DEBUG 01-15 10:09:12.015335.015335 lmp.py:1626]   Expert 34 |    222 | GPU
DEBUG 01-15 10:09:12.015270.015270 lmp.py:1626]   Expert 37 |    229 | GPU
DEBUG 01-15 10:09:12.015489.015489 lmp.py:1626]   Expert 59 |    230 | GPU
DEBUG 01-15 10:09:12.015232.015232 lmp.py:1626]   Expert 22 |    239 | GPU
DEBUG 01-15 10:09:12.015212.015212 lmp.py:1626]   Expert  0 |    241 | GPU
DEBUG 01-15 10:09:12.015193.015193 lmp.py:1626]   Expert 19 |    259 | GPU
DEBUG 01-15 10:09:12.015174.015174 lmp.py:1626]   Expert 24 |    286 | GPU
DEBUG 01-15 10:09:12.015155.015155 lmp.py:1626]   Expert 61 |    290 | GPU
DEBUG 01-15 10:09:12.015189.015189 lmp.py:1626]   Expert 30 |    301 | GPU
DEBUG 01-15 10:09:12.015408.015408 lmp.py:1626]   Expert 47 |    317 | GPU
DEBUG 01-15 10:09:12.015389.015389 lmp.py:1626]   Expert 38 |    365 | GPU
DEBUG 01-15 10:09:12.016131.016131 lmp.py:1626]   Expert 26 |    376 | GPU
DEBUG 01-15 10:09:12.016874.016874 lmp.py:1626]   Expert 12 |    425 | GPU
DEBUG 01-15 10:09:12.016616.016616 lmp.py:1626]   Expert  9 |    681 | GPU
DEBUG 01-15 10:09:12.016359.016359 lmp.py:1626]   Expert 23 |    701 | GPU
DEBUG 01-15 10:09:12.016293.016293 lmp.py:1627] 
DEBUG 01-15 10:09:12.016293.016293 lmp.py:1627]   CPU total tokens: 3909 (31.8%)
DEBUG 01-15 10:09:12.016373.016373 lmp.py:1628]   GPU total tokens: 8379 (68.2%)
DEBUG 01-15 10:09:12.016745.016745 cuda_h.py:19] end experts_map_get cost 0.0019452571868896484 seconds
DEBUG 01-15 10:09:12.016715.016715 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.016001.016001 lmp.py:1636] 
DEBUG 01-15 10:09:12.016001.016001 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.016050.016050 cuda_h.py:19] end cpu_experts_submit cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:12.016799.016799 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.016199.016199 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.016199.016199 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.016945.016945 cuda_h.py:19] end allocate_cuda_memory cost 0.00025773048400878906 seconds
DEBUG 01-15 10:09:12.017199.017199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.017114.017114 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.017719.017719 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.017912.017912 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0104884e-3af4-4cdf-b7a6-4c14cfbbda52
DEBUG 01-15 10:09:12.017272.017272 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.018081.018081 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:12.018249.018249 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0104884e-3af4-4cdf-b7a6-4c14cfbbda52
DEBUG 01-15 10:09:12.018624.018624 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.018791.018791 cuda_h.py:19] end load_into_gpu_async cost 0.0017826557159423828 seconds
DEBUG 01-15 10:09:12.018522.018522 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.019548.019548 cuda_h.py:19] end restore_tensors2 cost 0.0005109310150146484 seconds
DEBUG 01-15 10:09:12.019252.019252 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031287670135498047 seconds
DEBUG 01-15 10:09:12.019651.019651 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.019609.019609 cuda_h.py:19] end move_flatidxs cost 0.0010290145874023438 seconds
DEBUG 01-15 10:09:12.020651.020651 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.022687.022687 cuda_h.py:19] end restore2model cost 0.0032172203063964844 seconds
DEBUG 01-15 10:09:12.022537.022537 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006592512130737305 seconds
DEBUG 01-15 10:09:12.022948.022948 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.023740.023740 cuda_h.py:19] end gpu_sexperts cost 0.0002727508544921875 seconds
DEBUG 01-15 10:09:12.023954.023954 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.024031.024031 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001497507095336914 seconds
DEBUG 01-15 10:09:12.025653.025653 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.026248.026248 cuda_h.py:19] end gpu_group_list cost 0.0003223419189453125 seconds
DEBUG 01-15 10:09:12.026490.026490 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.025690.025690 cuda_h.py:19] end group_tensors cost 0.005493879318237305 seconds
DEBUG 01-15 10:09:12.026907.026907 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.026834.026834 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007421970367431641 seconds
DEBUG 01-15 10:09:12.026511.026511 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.027202.027202 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-15 10:09:12.027329.027329 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.030662.030662 cuda_h.py:19] end group pad cost 0.0039026737213134766 seconds
DEBUG 01-15 10:09:12.030896.030896 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.051655.051655 cuda_h.py:19] end group_einsum cost 0.021375179290771484 seconds
DEBUG 01-15 10:09:12.051759.051759 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.056869.056869 cuda_h.py:19] end get_outputs_cpu1 cost 0.0043849945068359375 seconds
DEBUG 01-15 10:09:12.057482.057482 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03876495361328125 seconds
DEBUG 01-15 10:09:12.058109.058109 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03095555305480957 seconds
DEBUG 01-15 10:09:12.058829.058829 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.058144.058144 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.058918.058918 cuda_h.py:19] end index_scatter cost 0.000102996826171875 seconds
DEBUG 01-15 10:09:12.059349.059349 cuda_h.py:19] end cpuoutputsdeal cost 0.0012345314025878906 seconds
DEBUG 01-15 10:09:12.059451.059451 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.059778.059778 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0104884e-3af4-4cdf-b7a6-4c14cfbbda52
INFO 01-15 10:09:12.069946.069946 client.py:127] Model loaded
DEBUG 01-15 10:09:12.069340.069340 cuda_h.py:19] end wait_experts cost 0.009694099426269531 seconds
DEBUG 01-15 10:09:12.069329.069329 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.069286.069286 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.069991.069991 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.069838.069838 cuda_h.py:19] end gpu_group_tensor cost 0.0003151893615722656 seconds
DEBUG 01-15 10:09:12.070566.070566 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.071044.071044 cuda_h.py:19] end gpu_group_einsum cost 0.0009260177612304688 seconds
DEBUG 01-15 10:09:12.071945.071945 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.071465.071465 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.071886.071886 cuda_h.py:19] end all_expert_outputs_slices cost 0.0004525184631347656 seconds
DEBUG 01-15 10:09:12.072305.072305 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.072529.072529 cuda_h.py:19] end concat_expert_out cost 0.00010323524475097656 seconds
DEBUG 01-15 10:09:12.072209.072209 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.072990.072990 cuda_h.py:19] end index_scatter cost 0.00012063980102539062 seconds
DEBUG 01-15 10:09:12.072284.072284 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011506080627441406 seconds
DEBUG 01-15 10:09:12.072958.072958 cuda_h.py:19] end gpu_experts cost 0.003271341323852539 seconds
DEBUG 01-15 10:09:12.072811.072811 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06136512756347656 seconds
DEBUG 01-15 10:09:12.073006.073006 cuda_h.py:19] end prefill_layer cost 0.07227349281311035 seconds
DEBUG 01-15 10:09:12.073182.073182 lmp.py:1552] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-15 10:09:12.073078.073078 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.073451.073451 lmp.py:1495] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-15 10:09:12.073778.073778 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:12.073589.073589 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:12.074017.074017 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:12.074066.074066 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 0.000148773193359375 seconds
DEBUG 01-15 10:09:12.074286.074286 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.074358.074358 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.074331.074331 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.074537.074537 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.074794.074794 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.075169.075169 cuda_h.py:19] end allocate_cuda_memory cost 0.0004184246063232422 seconds
DEBUG 01-15 10:09:12.075625.075625 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.075939.075939 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.075042.075042 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.075290.075290 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41feecb3-6afb-4f2c-a28c-5a82941482fb
DEBUG 01-15 10:09:12.076529.076529 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.076899.076899 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.077296.077296 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41feecb3-6afb-4f2c-a28c-5a82941482fb
DEBUG 01-15 10:09:12.077951.077951 cuda_h.py:19] end load_into_gpu_async cost 0.0017206668853759766 seconds
DEBUG 01-15 10:09:12.077013.077013 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.077226.077226 cuda_h.py:19] end restore_tensors2 cost 0.00015115737915039062 seconds
DEBUG 01-15 10:09:12.077693.077693 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029654502868652344 seconds
INFO 01-15 10:09:12.077392.077392 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41feecb3-6afb-4f2c-a28c-5a82941482fb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.082930.082930 cuda_h.py:19] end self_attn cost 0.005693197250366211 seconds
DEBUG 01-15 10:09:12.083886.083886 cuda_h.py:19] end iln_self_attn_paln cost 0.008939743041992188 seconds
DEBUG 01-15 10:09:12.083955.083955 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-15 10:09:12.083785.083785 cuda_h.py:10] start gate
INFO 01-15 10:09:12.084251.084251 client.py:127] Model loaded
DEBUG 01-15 10:09:12.084210.084210 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.084691.084691 cuda_h.py:19] end gate cost 0.0011031627655029297 seconds
DEBUG 01-15 10:09:12.084548.084548 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.085005.085005 lmp.py:1616] 
DEBUG 01-15 10:09:12.085005.085005 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.085682.085682 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.085346.085346 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.085241.085241 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.085559.085559 lmp.py:1620] 
DEBUG 01-15 10:09:12.085559.085559 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.085547.085547 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.085535.085535 lmp.py:1626]   Expert 38 |     13 | CPU
DEBUG 01-15 10:09:12.085568.085568 lmp.py:1626]   Expert 39 |     60 | CPU
DEBUG 01-15 10:09:12.085117.085117 lmp.py:1626]   Expert  7 |     70 | CPU
DEBUG 01-15 10:09:12.085211.085211 lmp.py:1626]   Expert 30 |     74 | CPU
DEBUG 01-15 10:09:12.085006.085006 lmp.py:1626]   Expert 14 |     93 | CPU
DEBUG 01-15 10:09:12.085848.085848 lmp.py:1626]   Expert 24 |     94 | CPU
DEBUG 01-15 10:09:12.085452.085452 lmp.py:1626]   Expert 27 |     94 | CPU
DEBUG 01-15 10:09:12.085340.085340 lmp.py:1626]   Expert 36 |     96 | CPU
DEBUG 01-15 10:09:12.085705.085705 lmp.py:1626]   Expert 40 |     96 | CPU
DEBUG 01-15 10:09:12.085547.085547 lmp.py:1626]   Expert 17 |     98 | CPU
DEBUG 01-15 10:09:12.085912.085912 lmp.py:1626]   Expert 16 |    104 | CPU
DEBUG 01-15 10:09:12.085230.085230 lmp.py:1626]   Expert 32 |    106 | CPU
DEBUG 01-15 10:09:12.085357.085357 lmp.py:1626]   Expert 18 |    109 | CPU
DEBUG 01-15 10:09:12.085245.085245 lmp.py:1626]   Expert 48 |    109 | CPU
DEBUG 01-15 10:09:12.085849.085849 lmp.py:1626]   Expert  1 |    112 | CPU
DEBUG 01-15 10:09:12.085498.085498 lmp.py:1626]   Expert 12 |    117 | CPU
DEBUG 01-15 10:09:12.085863.085863 lmp.py:1626]   Expert  6 |    124 | CPU
DEBUG 01-15 10:09:12.085275.085275 lmp.py:1626]   Expert 59 |    130 | CPU
DEBUG 01-15 10:09:12.085309.085309 lmp.py:1626]   Expert 42 |    136 | CPU
DEBUG 01-15 10:09:12.085674.085674 lmp.py:1626]   Expert  0 |    142 | CPU
DEBUG 01-15 10:09:12.086800.086800 lmp.py:1626]   Expert 22 |    145 | CPU
DEBUG 01-15 10:09:12.086688.086688 lmp.py:1626]   Expert 51 |    147 | CPU
DEBUG 01-15 10:09:12.086338.086338 lmp.py:1626]   Expert 53 |    148 | CPU
DEBUG 01-15 10:09:12.086703.086703 lmp.py:1626]   Expert  8 |    160 | CPU
DEBUG 01-15 10:09:12.086068.086068 lmp.py:1626]   Expert 44 |    168 | CPU
DEBUG 01-15 10:09:12.086956.086956 lmp.py:1626]   Expert 60 |    169 | CPU
DEBUG 01-15 10:09:12.086798.086798 lmp.py:1626]   Expert 15 |    170 | CPU
DEBUG 01-15 10:09:12.086879.086879 lmp.py:1626]   Expert 29 |    170 | CPU
DEBUG 01-15 10:09:12.086959.086959 lmp.py:1626]   Expert 54 |    173 | CPU
DEBUG 01-15 10:09:12.086324.086324 lmp.py:1626]   Expert 35 |    180 | CPU
DEBUG 01-15 10:09:12.086450.086450 lmp.py:1626]   Expert 34 |    182 | CPU
DEBUG 01-15 10:09:12.086008.086008 lmp.py:1626]   Expert 33 |    183 | CPU
DEBUG 01-15 10:09:12.086088.086088 lmp.py:1626]   Expert 47 |    188 | GPU
DEBUG 01-15 10:09:12.086453.086453 lmp.py:1626]   Expert 19 |    191 | GPU
DEBUG 01-15 10:09:12.086818.086818 lmp.py:1626]   Expert  9 |    193 | GPU
DEBUG 01-15 10:09:12.086183.086183 lmp.py:1626]   Expert 46 |    198 | GPU
DEBUG 01-15 10:09:12.086309.086309 lmp.py:1626]   Expert 21 |    199 | GPU
DEBUG 01-15 10:09:12.086628.086628 lmp.py:1626]   Expert 56 |    199 | GPU
DEBUG 01-15 10:09:12.086232.086232 lmp.py:1626]   Expert  3 |    200 | GPU
DEBUG 01-15 10:09:12.086358.086358 lmp.py:1626]   Expert 45 |    200 | GPU
DEBUG 01-15 10:09:12.086246.086246 lmp.py:1626]   Expert 20 |    202 | GPU
DEBUG 01-15 10:09:12.086611.086611 lmp.py:1626]   Expert 49 |    204 | GPU
DEBUG 01-15 10:09:12.086453.086453 lmp.py:1626]   Expert 28 |    208 | GPU
DEBUG 01-15 10:09:12.086580.086580 lmp.py:1626]   Expert 57 |    221 | GPU
DEBUG 01-15 10:09:12.086422.086422 lmp.py:1626]   Expert  2 |    223 | GPU
DEBUG 01-15 10:09:12.086502.086502 lmp.py:1626]   Expert 13 |    224 | GPU
DEBUG 01-15 10:09:12.086390.086390 lmp.py:1626]   Expert 43 |    226 | GPU
DEBUG 01-15 10:09:12.086517.086517 lmp.py:1626]   Expert  4 |    227 | GPU
DEBUG 01-15 10:09:12.086597.086597 lmp.py:1626]   Expert 10 |    240 | GPU
DEBUG 01-15 10:09:12.086485.086485 lmp.py:1626]   Expert 50 |    243 | GPU
DEBUG 01-15 10:09:12.086850.086850 lmp.py:1626]   Expert 41 |    248 | GPU
DEBUG 01-15 10:09:12.086738.086738 lmp.py:1626]   Expert 26 |    249 | GPU
DEBUG 01-15 10:09:12.086580.086580 lmp.py:1626]   Expert 63 |    255 | GPU
DEBUG 01-15 10:09:12.086661.086661 lmp.py:1626]   Expert 37 |    259 | GPU
DEBUG 01-15 10:09:12.086787.086787 lmp.py:1626]   Expert 31 |    270 | GPU
DEBUG 01-15 10:09:12.086914.086914 lmp.py:1626]   Expert 61 |    274 | GPU
DEBUG 01-15 10:09:12.086040.086040 lmp.py:1626]   Expert 52 |    305 | GPU
DEBUG 01-15 10:09:12.086405.086405 lmp.py:1626]   Expert 58 |    319 | GPU
DEBUG 01-15 10:09:12.086770.086770 lmp.py:1626]   Expert 62 |    323 | GPU
DEBUG 01-15 10:09:12.086851.086851 lmp.py:1626]   Expert 55 |    342 | GPU
DEBUG 01-15 10:09:12.086931.086931 lmp.py:1626]   Expert 11 |    380 | GPU
DEBUG 01-15 10:09:12.086819.086819 lmp.py:1626]   Expert 23 |    384 | GPU
DEBUG 01-15 10:09:12.087946.087946 lmp.py:1626]   Expert 25 |    405 | GPU
DEBUG 01-15 10:09:12.087311.087311 lmp.py:1626]   Expert  5 |    517 | GPU
DEBUG 01-15 10:09:12.087106.087106 lmp.py:1627] 
DEBUG 01-15 10:09:12.087106.087106 lmp.py:1627]   CPU total tokens: 3972 (32.3%)
DEBUG 01-15 10:09:12.087617.087617 lmp.py:1628]   GPU total tokens: 8316 (67.7%)
DEBUG 01-15 10:09:12.087088.087088 cuda_h.py:19] end experts_map_get cost 0.002251863479614258 seconds
DEBUG 01-15 10:09:12.088140.088140 cuda_h.py:19] end restore2model cost 0.0034275054931640625 seconds
DEBUG 01-15 10:09:12.088131.088131 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.088492.088492 cuda_h.py:19] end sllm_worker_task cost 0.01349639892578125 seconds
DEBUG 01-15 10:09:12.088291.088291 lmp.py:1636] 
DEBUG 01-15 10:09:12.088291.088291 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.088293.088293 cuda_h.py:19] end cpu_experts_submit cost 0.00025391578674316406 seconds
DEBUG 01-15 10:09:12.088764.088764 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.088780.088780 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.088024.088024 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.089764.089764 cuda_h.py:19] end allocate_cuda_memory cost 0.00029087066650390625 seconds
DEBUG 01-15 10:09:12.089088.089088 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.089918.089918 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.089939.089939 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.089318.089318 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 743ebbd3-4b12-44ec-bf87-62c70c727bfd
DEBUG 01-15 10:09:12.090081.090081 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.090380.090380 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.090626.090626 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:12.091350.091350 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 743ebbd3-4b12-44ec-bf87-62c70c727bfd
DEBUG 01-15 10:09:12.091154.091154 cuda_h.py:19] end load_into_gpu_async cost 0.001508951187133789 seconds
DEBUG 01-15 10:09:12.091532.091532 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.091296.091296 cuda_h.py:19] end restore_tensors2 cost 0.0004246234893798828 seconds
DEBUG 01-15 10:09:12.091808.091808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029735565185546875 seconds
DEBUG 01-15 10:09:12.091582.091582 cuda_h.py:19] end move_flatidxs cost 0.0009579658508300781 seconds
DEBUG 01-15 10:09:12.091485.091485 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.091160.091160 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.094792.094792 cuda_h.py:19] end restore2model cost 0.003000974655151367 seconds
DEBUG 01-15 10:09:12.094582.094582 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0061855316162109375 seconds
DEBUG 01-15 10:09:12.094377.094377 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.095249.095249 cuda_h.py:19] end gpu_sexperts cost 0.0002942085266113281 seconds
DEBUG 01-15 10:09:12.095940.095940 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.097345.097345 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001981496810913086 seconds
DEBUG 01-15 10:09:12.098555.098555 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.098025.098025 cuda_h.py:19] end gpu_group_list cost 0.00032830238342285156 seconds
DEBUG 01-15 10:09:12.098718.098718 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.099716.099716 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006940364837646484 seconds
DEBUG 01-15 10:09:12.099539.099539 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.099561.099561 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1696090698242188e-05 seconds
DEBUG 01-15 10:09:12.099687.099687 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.105874.105874 cuda_h.py:19] end group_tensors cost 0.013355731964111328 seconds
DEBUG 01-15 10:09:12.106298.106298 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.109328.109328 cuda_h.py:19] end group pad cost 0.003833770751953125 seconds
DEBUG 01-15 10:09:12.109833.109833 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.133693.133693 cuda_h.py:19] end group_einsum cost 0.023615598678588867 seconds
DEBUG 01-15 10:09:12.133778.133778 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.139859.139859 cuda_h.py:19] end get_outputs_cpu1 cost 0.005882978439331055 seconds
DEBUG 01-15 10:09:12.140800.140800 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05040597915649414 seconds
DEBUG 01-15 10:09:12.141587.141587 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04201984405517578 seconds
DEBUG 01-15 10:09:12.141653.141653 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.142826.142826 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.142763.142763 cuda_h.py:19] end index_scatter cost 0.00014638900756835938 seconds
DEBUG 01-15 10:09:12.142932.142932 cuda_h.py:19] end cpuoutputsdeal cost 0.0011224746704101562 seconds
DEBUG 01-15 10:09:12.143843.143843 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.143343.143343 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 743ebbd3-4b12-44ec-bf87-62c70c727bfd
INFO 01-15 10:09:12.144865.144865 client.py:127] Model loaded
DEBUG 01-15 10:09:12.144169.144169 cuda_h.py:19] end wait_experts cost 0.0013513565063476562 seconds
DEBUG 01-15 10:09:12.144364.144364 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.144871.144871 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.144450.144450 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.145955.145955 cuda_h.py:19] end gpu_group_tensor cost 0.0003654956817626953 seconds
DEBUG 01-15 10:09:12.145770.145770 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.146770.146770 cuda_h.py:19] end gpu_group_einsum cost 0.0010845661163330078 seconds
DEBUG 01-15 10:09:12.146341.146341 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.147558.147558 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.147598.147598 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005481243133544922 seconds
DEBUG 01-15 10:09:12.147323.147323 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.147356.147356 cuda_h.py:19] end concat_expert_out cost 0.00012636184692382812 seconds
DEBUG 01-15 10:09:12.148169.148169 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.148891.148891 cuda_h.py:19] end index_scatter cost 0.00011610984802246094 seconds
DEBUG 01-15 10:09:12.148067.148067 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013828277587890625 seconds
DEBUG 01-15 10:09:12.148424.148424 cuda_h.py:19] end gpu_experts cost 0.003906965255737305 seconds
DEBUG 01-15 10:09:12.148867.148867 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.06536602973937988 seconds
DEBUG 01-15 10:09:12.149938.149938 cuda_h.py:19] end prefill_layer cost 0.07563018798828125 seconds
DEBUG 01-15 10:09:12.149233.149233 lmp.py:1552] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-15 10:09:12.149467.149467 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.149608.149608 lmp.py:1495] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-15 10:09:12.149703.149703 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:12.149852.149852 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:12.150717.150717 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.890296936035156e-05 seconds
DEBUG 01-15 10:09:12.150104.150104 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.0001533031463623047 seconds
DEBUG 01-15 10:09:12.150570.150570 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.150562.150562 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.150151.150151 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.150960.150960 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.150494.150494 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.151398.151398 cuda_h.py:19] end allocate_cuda_memory cost 0.0003876686096191406 seconds
DEBUG 01-15 10:09:12.151940.151940 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.151824.151824 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.151417.151417 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.151334.151334 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16db6a4a-4162-44fc-92a5-32d8c63b5595
DEBUG 01-15 10:09:12.151321.151321 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.152723.152723 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.152877.152877 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16db6a4a-4162-44fc-92a5-32d8c63b5595
DEBUG 01-15 10:09:12.153869.153869 cuda_h.py:19] end load_into_gpu_async cost 0.001743316650390625 seconds
DEBUG 01-15 10:09:12.153508.153508 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.153707.153707 cuda_h.py:19] end restore_tensors2 cost 0.00014019012451171875 seconds
DEBUG 01-15 10:09:12.153399.153399 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002930164337158203 seconds
INFO 01-15 10:09:12.153451.153451 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16db6a4a-4162-44fc-92a5-32d8c63b5595
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.157544.157544 cuda_h.py:19] end self_attn cost 0.004702568054199219 seconds
DEBUG 01-15 10:09:12.158571.158571 cuda_h.py:19] end iln_self_attn_paln cost 0.00807809829711914 seconds
DEBUG 01-15 10:09:12.158812.158812 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-15 10:09:12.158005.158005 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.159618.159618 cuda_h.py:19] end gate cost 0.0006608963012695312 seconds
DEBUG 01-15 10:09:12.159838.159838 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.159009.159009 lmp.py:1616] 
DEBUG 01-15 10:09:12.159009.159009 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.159003.159003 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.159176.159176 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.159441.159441 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.159846.159846 lmp.py:1620] 
DEBUG 01-15 10:09:12.159846.159846 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.159827.159827 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.159238.159238 lmp.py:1626]   Expert 24 |     39 | CPU
DEBUG 01-15 10:09:12.159504.159504 lmp.py:1626]   Expert  2 |     45 | CPU
DEBUG 01-15 10:09:12.159054.159054 lmp.py:1626]   Expert 26 |     65 | CPU
DEBUG 01-15 10:09:12.159896.159896 lmp.py:1626]   Expert 32 |     65 | CPU
DEBUG 01-15 10:09:12.159969.159969 lmp.py:1626]   Expert 19 |     69 | CPU
DEBUG 01-15 10:09:12.159043.159043 lmp.py:1626]   Expert 50 |     70 | CPU
DEBUG 01-15 10:09:12.159878.159878 lmp.py:1626]   Expert 15 |     80 | CPU
DEBUG 01-15 10:09:12.159951.159951 lmp.py:1626]   Expert  7 |     82 | CPU
DEBUG 01-15 10:09:12.159548.159548 lmp.py:1626]   Expert 28 |     82 | CPU
DEBUG 01-15 10:09:12.159337.159337 lmp.py:1626]   Expert 60 |     82 | CPU
DEBUG 01-15 10:09:12.159410.159410 lmp.py:1626]   Expert  4 |     83 | CPU
DEBUG 01-15 10:09:12.159245.159245 lmp.py:1626]   Expert 59 |     89 | CPU
DEBUG 01-15 10:09:12.159081.159081 lmp.py:1626]   Expert 23 |     98 | CPU
DEBUG 01-15 10:09:12.159154.159154 lmp.py:1626]   Expert 49 |    100 | CPU
DEBUG 01-15 10:09:12.159704.159704 lmp.py:1626]   Expert  5 |    102 | CPU
DEBUG 01-15 10:09:12.159016.159016 lmp.py:1626]   Expert 12 |    105 | CPU
DEBUG 01-15 10:09:12.159090.159090 lmp.py:1626]   Expert 10 |    112 | CPU
DEBUG 01-15 10:09:12.159786.159786 lmp.py:1626]   Expert 27 |    113 | CPU
DEBUG 01-15 10:09:12.159098.159098 lmp.py:1626]   Expert  3 |    124 | CPU
DEBUG 01-15 10:09:12.159171.159171 lmp.py:1626]   Expert 25 |    125 | CPU
DEBUG 01-15 10:09:12.160006.160006 lmp.py:1626]   Expert 41 |    125 | CPU
DEBUG 01-15 10:09:12.160080.160080 lmp.py:1626]   Expert 20 |    130 | CPU
DEBUG 01-15 10:09:12.160153.160153 lmp.py:1626]   Expert 40 |    130 | CPU
DEBUG 01-15 10:09:12.160227.160227 lmp.py:1626]   Expert 13 |    133 | CPU
DEBUG 01-15 10:09:12.160062.160062 lmp.py:1626]   Expert 16 |    134 | CPU
DEBUG 01-15 10:09:12.160897.160897 lmp.py:1626]   Expert 35 |    146 | CPU
DEBUG 01-15 10:09:12.160924.160924 lmp.py:1626]   Expert 37 |    146 | CPU
DEBUG 01-15 10:09:12.160998.160998 lmp.py:1626]   Expert 17 |    147 | CPU
DEBUG 01-15 10:09:12.160071.160071 lmp.py:1626]   Expert 47 |    148 | CPU
DEBUG 01-15 10:09:12.160906.160906 lmp.py:1626]   Expert 22 |    160 | CPU
DEBUG 01-15 10:09:12.160741.160741 lmp.py:1626]   Expert 53 |    166 | CPU
DEBUG 01-15 10:09:12.160291.160291 lmp.py:1626]   Expert 39 |    170 | CPU
DEBUG 01-15 10:09:12.160080.160080 lmp.py:1626]   Expert 36 |    179 | GPU
DEBUG 01-15 10:09:12.160869.160869 lmp.py:1626]   Expert 38 |    179 | GPU
DEBUG 01-15 10:09:12.160181.160181 lmp.py:1626]   Expert 52 |    182 | GPU
DEBUG 01-15 10:09:12.160254.160254 lmp.py:1626]   Expert 44 |    183 | GPU
DEBUG 01-15 10:09:12.160328.160328 lmp.py:1626]   Expert 58 |    183 | GPU
DEBUG 01-15 10:09:12.160686.160686 lmp.py:1626]   Expert 18 |    187 | GPU
DEBUG 01-15 10:09:12.160283.160283 lmp.py:1626]   Expert 62 |    198 | GPU
DEBUG 01-15 10:09:12.160879.160879 lmp.py:1626]   Expert 48 |    208 | GPU
DEBUG 01-15 10:09:12.160251.160251 lmp.py:1626]   Expert 11 |    210 | GPU
DEBUG 01-15 10:09:12.160278.160278 lmp.py:1626]   Expert 14 |    217 | GPU
DEBUG 01-15 10:09:12.160113.160113 lmp.py:1626]   Expert 30 |    219 | GPU
DEBUG 01-15 10:09:12.160472.160472 lmp.py:1626]   Expert  1 |    230 | GPU
DEBUG 01-15 10:09:12.160545.160545 lmp.py:1626]   Expert 45 |    234 | GPU
DEBUG 01-15 10:09:12.160142.160142 lmp.py:1626]   Expert 42 |    235 | GPU
DEBUG 01-15 10:09:12.160599.160599 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:12.160865.160865 lmp.py:1626]   Expert 51 |    241 | GPU
DEBUG 01-15 10:09:12.160177.160177 lmp.py:1626]   Expert  6 |    242 | GPU
DEBUG 01-15 10:09:12.160774.160774 lmp.py:1626]   Expert 29 |    259 | GPU
DEBUG 01-15 10:09:12.160324.160324 lmp.py:1626]   Expert 34 |    265 | GPU
DEBUG 01-15 10:09:12.160159.160159 lmp.py:1626]   Expert 33 |    275 | GPU
DEBUG 01-15 10:09:12.160994.160994 lmp.py:1626]   Expert 57 |    297 | GPU
DEBUG 01-15 10:09:12.160956.160956 lmp.py:1626]   Expert 61 |    302 | GPU
DEBUG 01-15 10:09:12.160552.160552 lmp.py:1626]   Expert 43 |    308 | GPU
DEBUG 01-15 10:09:12.160718.160718 lmp.py:1626]   Expert  0 |    323 | GPU
DEBUG 01-15 10:09:12.160792.160792 lmp.py:1626]   Expert 46 |    351 | GPU
DEBUG 01-15 10:09:12.160581.160581 lmp.py:1626]   Expert  8 |    378 | GPU
DEBUG 01-15 10:09:12.160654.160654 lmp.py:1626]   Expert  9 |    392 | GPU
DEBUG 01-15 10:09:12.160966.160966 lmp.py:1626]   Expert 56 |    393 | GPU
DEBUG 01-15 10:09:12.160516.160516 lmp.py:1626]   Expert 54 |    395 | GPU
DEBUG 01-15 10:09:12.160544.160544 lmp.py:1626]   Expert 63 |    404 | GPU
DEBUG 01-15 10:09:12.160140.160140 lmp.py:1626]   Expert 55 |    426 | GPU
DEBUG 01-15 10:09:12.160737.160737 lmp.py:1626]   Expert 21 |    491 | GPU
DEBUG 01-15 10:09:12.160526.160526 lmp.py:1627] 
DEBUG 01-15 10:09:12.160526.160526 lmp.py:1627]   CPU total tokens: 3465 (28.2%)
DEBUG 01-15 10:09:12.160030.160030 lmp.py:1628]   GPU total tokens: 8823 (71.8%)
DEBUG 01-15 10:09:12.160540.160540 cuda_h.py:19] end experts_map_get cost 0.001752614974975586 seconds
INFO 01-15 10:09:12.161856.161856 client.py:127] Model loaded
DEBUG 01-15 10:09:12.161662.161662 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.161189.161189 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.161436.161436 lmp.py:1636] 
DEBUG 01-15 10:09:12.161436.161436 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.162333.162333 cuda_h.py:19] end restore2model cost 0.0011277198791503906 seconds
DEBUG 01-15 10:09:12.162159.162159 cuda_h.py:19] end cpu_experts_submit cost 0.0014078617095947266 seconds
DEBUG 01-15 10:09:12.163870.163870 cuda_h.py:19] end sllm_worker_task cost 0.012544631958007812 seconds
DEBUG 01-15 10:09:12.163674.163674 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.163047.163047 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.163080.163080 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.163694.163694 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.163051.163051 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.164109.164109 cuda_h.py:19] end allocate_cuda_memory cost 0.0002658367156982422 seconds
DEBUG 01-15 10:09:12.164442.164442 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.164629.164629 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.164498.164498 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.164154.164154 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ccc84930-b846-4b74-a709-933ab76a7725
DEBUG 01-15 10:09:12.164142.164142 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.164088.164088 cuda_h.py:19] end move_flatidxs cost 0.0008418560028076172 seconds
DEBUG 01-15 10:09:12.164818.164818 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:12.165973.165973 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ccc84930-b846-4b74-a709-933ab76a7725
DEBUG 01-15 10:09:12.165047.165047 cuda_h.py:19] end load_into_gpu_async cost 0.0014324188232421875 seconds
DEBUG 01-15 10:09:12.165320.165320 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.166101.166101 cuda_h.py:19] end restore_tensors2 cost 0.00037598609924316406 seconds
DEBUG 01-15 10:09:12.166739.166739 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002443075180053711 seconds
DEBUG 01-15 10:09:12.166316.166316 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.168895.168895 cuda_h.py:19] end restore2model cost 0.0026085376739501953 seconds
DEBUG 01-15 10:09:12.168400.168400 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005257368087768555 seconds
DEBUG 01-15 10:09:12.168434.168434 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.169530.169530 cuda_h.py:19] end gpu_sexperts cost 0.0002853870391845703 seconds
DEBUG 01-15 10:09:12.169790.169790 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.170040.170040 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014789104461669922 seconds
DEBUG 01-15 10:09:12.170946.170946 cuda_h.py:19] end group_tensors cost 0.005567073822021484 seconds
DEBUG 01-15 10:09:12.171322.171322 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.171964.171964 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.172482.172482 cuda_h.py:19] end gpu_group_list cost 0.0005047321319580078 seconds
DEBUG 01-15 10:09:12.172429.172429 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.173127.173127 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010144710540771484 seconds
DEBUG 01-15 10:09:12.173871.173871 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.173926.173926 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-15 10:09:12.173543.173543 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.174539.174539 cuda_h.py:19] end group pad cost 0.0036444664001464844 seconds
DEBUG 01-15 10:09:12.175343.175343 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.195866.195866 cuda_h.py:19] end group_einsum cost 0.020097732543945312 seconds
DEBUG 01-15 10:09:12.195461.195461 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.199142.199142 cuda_h.py:19] end get_outputs_cpu1 cost 0.004047393798828125 seconds
DEBUG 01-15 10:09:12.200085.200085 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03666114807128906 seconds
DEBUG 01-15 10:09:12.201758.201758 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.027889490127563477 seconds
DEBUG 01-15 10:09:12.201718.201718 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.202825.202825 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.202576.202576 cuda_h.py:19] end index_scatter cost 0.00014734268188476562 seconds
DEBUG 01-15 10:09:12.203733.203733 cuda_h.py:19] end cpuoutputsdeal cost 0.0013234615325927734 seconds
DEBUG 01-15 10:09:12.203705.203705 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.203912.203912 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ccc84930-b846-4b74-a709-933ab76a7725
INFO 01-15 10:09:12.214414.214414 client.py:127] Model loaded
DEBUG 01-15 10:09:12.214463.214463 cuda_h.py:19] end wait_experts cost 0.011124849319458008 seconds
DEBUG 01-15 10:09:12.214358.214358 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.214877.214877 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.214057.214057 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.214496.214496 cuda_h.py:19] end gpu_group_tensor cost 0.00022459030151367188 seconds
DEBUG 01-15 10:09:12.215506.215506 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.215988.215988 cuda_h.py:19] end gpu_group_einsum cost 0.0005199909210205078 seconds
DEBUG 01-15 10:09:12.215191.215191 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.215358.215358 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.216459.216459 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002162456512451172 seconds
DEBUG 01-15 10:09:12.216262.216262 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.216861.216861 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-15 10:09:12.216141.216141 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.216237.216237 cuda_h.py:19] end index_scatter cost 6.341934204101562e-05 seconds
DEBUG 01-15 10:09:12.216530.216530 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005958080291748047 seconds
DEBUG 01-15 10:09:12.216850.216850 cuda_h.py:19] end gpu_experts cost 0.0018124580383300781 seconds
DEBUG 01-15 10:09:12.216667.216667 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.05814862251281738 seconds
DEBUG 01-15 10:09:12.216453.216453 cuda_h.py:19] end prefill_layer cost 0.0671682357788086 seconds
DEBUG 01-15 10:09:12.216991.216991 lmp.py:1552] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-15 10:09:12.216402.216402 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.216052.216052 lmp.py:1495] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-15 10:09:12.216179.216179 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:12.217451.217451 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:12.217003.217003 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.218650817871094e-05 seconds
DEBUG 01-15 10:09:12.217845.217845 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.817413330078125e-05 seconds
DEBUG 01-15 10:09:12.217441.217441 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.217974.217974 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.217977.217977 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.217302.217302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.217453.217453 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.218934.218934 cuda_h.py:19] end allocate_cuda_memory cost 0.0004096031188964844 seconds
DEBUG 01-15 10:09:12.218336.218336 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.218936.218936 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.218701.218701 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.218803.218803 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a991e8a4-6203-48c0-91cb-abd61128dccf
DEBUG 01-15 10:09:12.218345.218345 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.219040.219040 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.219188.219188 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a991e8a4-6203-48c0-91cb-abd61128dccf
DEBUG 01-15 10:09:12.220525.220525 cuda_h.py:19] end load_into_gpu_async cost 0.0015861988067626953 seconds
DEBUG 01-15 10:09:12.220854.220854 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.220868.220868 cuda_h.py:19] end restore_tensors2 cost 0.00013828277587890625 seconds
DEBUG 01-15 10:09:12.220343.220343 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029137134552001953 seconds
INFO 01-15 10:09:12.220612.220612 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a991e8a4-6203-48c0-91cb-abd61128dccf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.223981.223981 cuda_h.py:19] end self_attn cost 0.004274606704711914 seconds
DEBUG 01-15 10:09:12.223548.223548 cuda_h.py:19] end iln_self_attn_paln cost 0.006718635559082031 seconds
DEBUG 01-15 10:09:12.223875.223875 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-15 10:09:12.223452.223452 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.224462.224462 cuda_h.py:19] end gate cost 0.0006387233734130859 seconds
DEBUG 01-15 10:09:12.224198.224198 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.224877.224877 lmp.py:1616] 
DEBUG 01-15 10:09:12.224877.224877 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.225964.225964 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.225614.225614 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.225403.225403 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.225569.225569 lmp.py:1620] 
DEBUG 01-15 10:09:12.225569.225569 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.225973.225973 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.225570.225570 lmp.py:1626]   Expert 43 |     16 | CPU
DEBUG 01-15 10:09:12.225451.225451 lmp.py:1626]   Expert 27 |     31 | CPU
DEBUG 01-15 10:09:12.225617.225617 lmp.py:1626]   Expert 26 |     53 | CPU
DEBUG 01-15 10:09:12.225068.225068 lmp.py:1626]   Expert 34 |     53 | CPU
DEBUG 01-15 10:09:12.225234.225234 lmp.py:1626]   Expert 56 |     53 | CPU
DEBUG 01-15 10:09:12.225924.225924 lmp.py:1626]   Expert  3 |     58 | CPU
DEBUG 01-15 10:09:12.225613.225613 lmp.py:1626]   Expert  4 |     68 | CPU
DEBUG 01-15 10:09:12.225826.225826 lmp.py:1626]   Expert 61 |     80 | CPU
DEBUG 01-15 10:09:12.225276.225276 lmp.py:1626]   Expert 14 |     95 | CPU
DEBUG 01-15 10:09:12.225250.225250 lmp.py:1626]   Expert 38 |     98 | CPU
DEBUG 01-15 10:09:12.225655.225655 lmp.py:1626]   Expert  2 |    113 | CPU
DEBUG 01-15 10:09:12.225583.225583 lmp.py:1626]   Expert 17 |    120 | CPU
DEBUG 01-15 10:09:12.225318.225318 lmp.py:1626]   Expert 22 |    124 | CPU
DEBUG 01-15 10:09:12.225769.225769 lmp.py:1626]   Expert 37 |    129 | CPU
DEBUG 01-15 10:09:12.225743.225743 lmp.py:1626]   Expert 47 |    129 | CPU
DEBUG 01-15 10:09:12.225194.225194 lmp.py:1626]   Expert 55 |    130 | CPU
DEBUG 01-15 10:09:12.225407.225407 lmp.py:1626]   Expert 54 |    133 | CPU
DEBUG 01-15 10:09:12.225381.225381 lmp.py:1626]   Expert 28 |    135 | CPU
DEBUG 01-15 10:09:12.225593.225593 lmp.py:1626]   Expert  7 |    144 | CPU
DEBUG 01-15 10:09:12.225759.225759 lmp.py:1626]   Expert 48 |    144 | CPU
DEBUG 01-15 10:09:12.225740.225740 lmp.py:1626]   Expert  5 |    145 | CPU
DEBUG 01-15 10:09:12.225337.225337 lmp.py:1626]   Expert 15 |    145 | CPU
DEBUG 01-15 10:09:12.225887.225887 lmp.py:1626]   Expert 51 |    148 | CPU
DEBUG 01-15 10:09:12.225437.225437 lmp.py:1626]   Expert 60 |    149 | CPU
DEBUG 01-15 10:09:12.225240.225240 lmp.py:1626]   Expert 45 |    152 | CPU
DEBUG 01-15 10:09:12.225028.225028 lmp.py:1626]   Expert 63 |    153 | CPU
DEBUG 01-15 10:09:12.225579.225579 lmp.py:1626]   Expert 12 |    154 | CPU
DEBUG 01-15 10:09:12.225891.225891 lmp.py:1626]   Expert 19 |    157 | CPU
DEBUG 01-15 10:09:12.225441.225441 lmp.py:1626]   Expert  6 |    166 | CPU
DEBUG 01-15 10:09:12.225230.225230 lmp.py:1626]   Expert 57 |    166 | CPU
DEBUG 01-15 10:09:12.225065.225065 lmp.py:1626]   Expert 52 |    176 | CPU
DEBUG 01-15 10:09:12.225900.225900 lmp.py:1626]   Expert 50 |    179 | CPU
DEBUG 01-15 10:09:12.225450.225450 lmp.py:1626]   Expert 18 |    182 | GPU
DEBUG 01-15 10:09:12.225285.225285 lmp.py:1626]   Expert 44 |    182 | GPU
DEBUG 01-15 10:09:12.225597.225597 lmp.py:1626]   Expert 31 |    186 | GPU
DEBUG 01-15 10:09:12.225147.225147 lmp.py:1626]   Expert 13 |    190 | GPU
DEBUG 01-15 10:09:12.225221.225221 lmp.py:1626]   Expert 30 |    191 | GPU
DEBUG 01-15 10:09:12.225725.225725 lmp.py:1626]   Expert 23 |    193 | GPU
DEBUG 01-15 10:09:12.225037.225037 lmp.py:1626]   Expert 53 |    196 | GPU
DEBUG 01-15 10:09:12.225587.225587 lmp.py:1626]   Expert 59 |    196 | GPU
DEBUG 01-15 10:09:12.225045.225045 lmp.py:1626]   Expert 39 |    197 | GPU
DEBUG 01-15 10:09:12.225834.225834 lmp.py:1626]   Expert 20 |    201 | GPU
DEBUG 01-15 10:09:12.225907.225907 lmp.py:1626]   Expert 29 |    202 | GPU
DEBUG 01-15 10:09:12.225742.225742 lmp.py:1626]   Expert 21 |    204 | GPU
DEBUG 01-15 10:09:12.225339.225339 lmp.py:1626]   Expert 16 |    208 | GPU
DEBUG 01-15 10:09:12.225366.225366 lmp.py:1626]   Expert 36 |    213 | GPU
DEBUG 01-15 10:09:12.225155.225155 lmp.py:1626]   Expert 41 |    217 | GPU
DEBUG 01-15 10:09:12.225751.225751 lmp.py:1626]   Expert 25 |    219 | GPU
DEBUG 01-15 10:09:12.225063.225063 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:12.226375.226375 lmp.py:1626]   Expert 49 |    229 | GPU
DEBUG 01-15 10:09:12.226687.226687 lmp.py:1626]   Expert 46 |    234 | GPU
DEBUG 01-15 10:09:12.226191.226191 lmp.py:1626]   Expert 10 |    248 | GPU
DEBUG 01-15 10:09:12.226457.226457 lmp.py:1626]   Expert  8 |    249 | GPU
DEBUG 01-15 10:09:12.226530.226530 lmp.py:1626]   Expert 42 |    251 | GPU
DEBUG 01-15 10:09:12.226604.226604 lmp.py:1626]   Expert 62 |    266 | GPU
DEBUG 01-15 10:09:12.226108.226108 lmp.py:1626]   Expert 35 |    278 | GPU
DEBUG 01-15 10:09:12.226420.226420 lmp.py:1626]   Expert 33 |    292 | GPU
DEBUG 01-15 10:09:12.226970.226970 lmp.py:1626]   Expert  9 |    294 | GPU
DEBUG 01-15 10:09:12.226520.226520 lmp.py:1626]   Expert 58 |    296 | GPU
DEBUG 01-15 10:09:12.226071.226071 lmp.py:1626]   Expert 40 |    389 | GPU
DEBUG 01-15 10:09:12.226621.226621 lmp.py:1626]   Expert 11 |    423 | GPU
DEBUG 01-15 10:09:12.226694.226694 lmp.py:1626]   Expert  0 |    429 | GPU
DEBUG 01-15 10:09:12.226768.226768 lmp.py:1626]   Expert 24 |    564 | GPU
DEBUG 01-15 10:09:12.226364.226364 lmp.py:1626]   Expert  1 |    648 | GPU
DEBUG 01-15 10:09:12.226630.226630 lmp.py:1627] 
DEBUG 01-15 10:09:12.226630.226630 lmp.py:1627]   CPU total tokens: 3796 (30.9%)
DEBUG 01-15 10:09:12.226134.226134 lmp.py:1628]   GPU total tokens: 8492 (69.1%)
DEBUG 01-15 10:09:12.226168.226168 cuda_h.py:19] end experts_map_get cost 0.001634359359741211 seconds
DEBUG 01-15 10:09:12.226786.226786 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.226827.226827 lmp.py:1636] 
DEBUG 01-15 10:09:12.226827.226827 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.226524.226524 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:12.226697.226697 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.226103.226103 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.226492.226492 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.227667.227667 cuda_h.py:19] end allocate_cuda_memory cost 0.00023174285888671875 seconds
DEBUG 01-15 10:09:12.227801.227801 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.227464.227464 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.227095.227095 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.227990.227990 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5dd69a20-923c-494b-95c2-98f70592d14e
DEBUG 01-15 10:09:12.227625.227625 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:12.227259.227259 client.py:127] Model loaded
DEBUG 01-15 10:09:12.228642.228642 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.228074.228074 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.228895.228895 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.229661.229661 cuda_h.py:19] end restore2model cost 0.001077890396118164 seconds
INFO 01-15 10:09:12.229647.229647 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5dd69a20-923c-494b-95c2-98f70592d14e
DEBUG 01-15 10:09:12.229068.229068 cuda_h.py:19] end sllm_worker_task cost 0.012017488479614258 seconds
DEBUG 01-15 10:09:12.229682.229682 cuda_h.py:19] end load_into_gpu_async cost 0.0025331974029541016 seconds
DEBUG 01-15 10:09:12.229242.229242 cuda_h.py:19] end move_flatidxs cost 0.0009872913360595703 seconds
DEBUG 01-15 10:09:12.229886.229886 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.229939.229939 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.230706.230706 cuda_h.py:19] end restore_tensors2 cost 0.00032830238342285156 seconds
DEBUG 01-15 10:09:12.230204.230204 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003597736358642578 seconds
DEBUG 01-15 10:09:12.230067.230067 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.232817.232817 cuda_h.py:19] end restore2model cost 0.0025911331176757812 seconds
DEBUG 01-15 10:09:12.232474.232474 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006373882293701172 seconds
DEBUG 01-15 10:09:12.232462.232462 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.233830.233830 cuda_h.py:19] end gpu_sexperts cost 0.00027370452880859375 seconds
DEBUG 01-15 10:09:12.233759.233759 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.234869.234869 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014801025390625 seconds
DEBUG 01-15 10:09:12.235974.235974 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.235629.235629 cuda_h.py:19] end gpu_group_list cost 0.00032973289489746094 seconds
DEBUG 01-15 10:09:12.236162.236162 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.236346.236346 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006914138793945312 seconds
DEBUG 01-15 10:09:12.236692.236692 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.236329.236329 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-15 10:09:12.236555.236555 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.239291.239291 cuda_h.py:19] end group_tensors cost 0.010081291198730469 seconds
DEBUG 01-15 10:09:12.240867.240867 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.244126.244126 cuda_h.py:19] end group pad cost 0.003930091857910156 seconds
DEBUG 01-15 10:09:12.244201.244201 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.265866.265866 cuda_h.py:19] end group_einsum cost 0.020386219024658203 seconds
DEBUG 01-15 10:09:12.265468.265468 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.269693.269693 cuda_h.py:19] end get_outputs_cpu1 cost 0.004271268844604492 seconds
DEBUG 01-15 10:09:12.270425.270425 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.042235612869262695 seconds
DEBUG 01-15 10:09:12.271984.271984 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.034893035888671875 seconds
DEBUG 01-15 10:09:12.272494.272494 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.272691.272691 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.272469.272469 cuda_h.py:19] end index_scatter cost 0.00015997886657714844 seconds
DEBUG 01-15 10:09:12.273922.273922 cuda_h.py:19] end cpuoutputsdeal cost 0.00177001953125 seconds
DEBUG 01-15 10:09:12.274357.274357 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.274280.274280 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5dd69a20-923c-494b-95c2-98f70592d14e
INFO 01-15 10:09:12.278228.278228 client.py:127] Model loaded
DEBUG 01-15 10:09:12.278932.278932 cuda_h.py:19] end wait_experts cost 0.0040738582611083984 seconds
DEBUG 01-15 10:09:12.278496.278496 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.278306.278306 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.278586.278586 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.278125.278125 cuda_h.py:19] end gpu_group_tensor cost 0.0002613067626953125 seconds
DEBUG 01-15 10:09:12.278957.278957 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.279297.279297 cuda_h.py:19] end gpu_group_einsum cost 0.0006208419799804688 seconds
DEBUG 01-15 10:09:12.279534.279534 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.279861.279861 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.280627.280627 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003108978271484375 seconds
DEBUG 01-15 10:09:12.280815.280815 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.280176.280176 cuda_h.py:19] end concat_expert_out cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:12.280072.280072 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.280923.280923 cuda_h.py:19] end index_scatter cost 6.771087646484375e-05 seconds
DEBUG 01-15 10:09:12.280607.280607 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000728607177734375 seconds
DEBUG 01-15 10:09:12.280417.280417 cuda_h.py:19] end gpu_experts cost 0.0021622180938720703 seconds
DEBUG 01-15 10:09:12.280718.280718 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.05659127235412598 seconds
DEBUG 01-15 10:09:12.280599.280599 cuda_h.py:19] end prefill_layer cost 0.06398749351501465 seconds
DEBUG 01-15 10:09:12.281965.281965 lmp.py:1552] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-15 10:09:12.281953.281953 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.281894.281894 lmp.py:1495] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-15 10:09:12.281358.281358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:12.281446.281446 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:12.281680.281680 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.910064697265625e-05 seconds
DEBUG 01-15 10:09:12.281767.281767 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.081031799316406e-05 seconds
DEBUG 01-15 10:09:12.281224.281224 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.281293.281293 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.281880.281880 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.281635.281635 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.281170.281170 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.282314.282314 cuda_h.py:19] end allocate_cuda_memory cost 0.0003859996795654297 seconds
DEBUG 01-15 10:09:12.282419.282419 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.282740.282740 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.282625.282625 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.282046.282046 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a8ca62e-afce-469d-ba13-9e43cc45b7fb
DEBUG 01-15 10:09:12.283185.283185 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.283644.283644 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.284079.284079 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a8ca62e-afce-469d-ba13-9e43cc45b7fb
DEBUG 01-15 10:09:12.284316.284316 cuda_h.py:19] end load_into_gpu_async cost 0.001577615737915039 seconds
DEBUG 01-15 10:09:12.284524.284524 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.284698.284698 cuda_h.py:19] end restore_tensors2 cost 0.00015497207641601562 seconds
DEBUG 01-15 10:09:12.284497.284497 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002884387969970703 seconds
INFO 01-15 10:09:12.284310.284310 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a8ca62e-afce-469d-ba13-9e43cc45b7fb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.287607.287607 cuda_h.py:19] end self_attn cost 0.004312753677368164 seconds
DEBUG 01-15 10:09:12.288440.288440 cuda_h.py:19] end iln_self_attn_paln cost 0.006793022155761719 seconds
DEBUG 01-15 10:09:12.288151.288151 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-15 10:09:12.288198.288198 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.288075.288075 cuda_h.py:19] end gate cost 0.0006451606750488281 seconds
DEBUG 01-15 10:09:12.288819.288819 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.289942.289942 lmp.py:1616] 
DEBUG 01-15 10:09:12.289942.289942 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.289174.289174 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.289109.289109 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.289136.289136 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.289825.289825 lmp.py:1620] 
DEBUG 01-15 10:09:12.289825.289825 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.289992.289992 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.289350.289350 lmp.py:1626]   Expert 13 |     17 | CPU
DEBUG 01-15 10:09:12.289278.289278 lmp.py:1626]   Expert 39 |     18 | CPU
DEBUG 01-15 10:09:12.289967.289967 lmp.py:1626]   Expert 49 |     38 | CPU
DEBUG 01-15 10:09:12.289941.289941 lmp.py:1626]   Expert 35 |     55 | CPU
DEBUG 01-15 10:09:12.289869.289869 lmp.py:1626]   Expert 19 |     64 | CPU
DEBUG 01-15 10:09:12.289319.289319 lmp.py:1626]   Expert  9 |     71 | CPU
DEBUG 01-15 10:09:12.289532.289532 lmp.py:1626]   Expert 26 |     74 | CPU
DEBUG 01-15 10:09:12.289506.289506 lmp.py:1626]   Expert 32 |     75 | CPU
DEBUG 01-15 10:09:12.289480.289480 lmp.py:1626]   Expert 41 |     78 | CPU
DEBUG 01-15 10:09:12.289931.289931 lmp.py:1626]   Expert 33 |     84 | CPU
DEBUG 01-15 10:09:12.289667.289667 lmp.py:1626]   Expert 23 |     86 | CPU
DEBUG 01-15 10:09:12.289879.289879 lmp.py:1626]   Expert 46 |     88 | CPU
DEBUG 01-15 10:09:12.289091.289091 lmp.py:1626]   Expert 18 |     91 | CPU
DEBUG 01-15 10:09:12.289734.289734 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:12.289424.289424 lmp.py:1626]   Expert 38 |     97 | CPU
DEBUG 01-15 10:09:12.289875.289875 lmp.py:1626]   Expert  3 |    102 | CPU
DEBUG 01-15 10:09:12.289087.289087 lmp.py:1626]   Expert 17 |    105 | CPU
DEBUG 01-15 10:09:12.289300.289300 lmp.py:1626]   Expert  6 |    106 | CPU
DEBUG 01-15 10:09:12.289327.289327 lmp.py:1626]   Expert 20 |    118 | CPU
DEBUG 01-15 10:09:12.289400.289400 lmp.py:1626]   Expert 40 |    129 | CPU
DEBUG 01-15 10:09:12.289235.289235 lmp.py:1626]   Expert 61 |    131 | CPU
DEBUG 01-15 10:09:12.289170.289170 lmp.py:1626]   Expert 62 |    133 | CPU
DEBUG 01-15 10:09:12.289482.289482 lmp.py:1626]   Expert 43 |    134 | CPU
DEBUG 01-15 10:09:12.289078.289078 lmp.py:1626]   Expert 44 |    134 | CPU
DEBUG 01-15 10:09:12.289152.289152 lmp.py:1626]   Expert 50 |    136 | CPU
DEBUG 01-15 10:09:12.289179.289179 lmp.py:1626]   Expert 15 |    137 | CPU
DEBUG 01-15 10:09:12.289776.289776 lmp.py:1626]   Expert 59 |    137 | CPU
DEBUG 01-15 10:09:12.289849.289849 lmp.py:1626]   Expert 16 |    140 | CPU
DEBUG 01-15 10:09:12.289399.289399 lmp.py:1626]   Expert 63 |    140 | CPU
DEBUG 01-15 10:09:12.289996.289996 lmp.py:1626]   Expert 42 |    141 | CPU
DEBUG 01-15 10:09:12.289070.289070 lmp.py:1626]   Expert  2 |    146 | CPU
DEBUG 01-15 10:09:12.289335.289335 lmp.py:1626]   Expert 36 |    150 | CPU
DEBUG 01-15 10:09:12.289409.289409 lmp.py:1626]   Expert 10 |    159 | GPU
DEBUG 01-15 10:09:12.289721.289721 lmp.py:1626]   Expert  5 |    182 | GPU
DEBUG 01-15 10:09:12.289317.289317 lmp.py:1626]   Expert 34 |    186 | GPU
DEBUG 01-15 10:09:12.289629.289629 lmp.py:1626]   Expert 27 |    190 | GPU
DEBUG 01-15 10:09:12.289941.289941 lmp.py:1626]   Expert 52 |    190 | GPU
DEBUG 01-15 10:09:12.290445.290445 lmp.py:1626]   Expert 45 |    192 | GPU
DEBUG 01-15 10:09:12.290757.290757 lmp.py:1626]   Expert 60 |    203 | GPU
DEBUG 01-15 10:09:12.290354.290354 lmp.py:1626]   Expert 48 |    207 | GPU
DEBUG 01-15 10:09:12.290189.290189 lmp.py:1626]   Expert 51 |    210 | GPU
DEBUG 01-15 10:09:12.290785.290785 lmp.py:1626]   Expert 56 |    213 | GPU
DEBUG 01-15 10:09:12.290336.290336 lmp.py:1626]   Expert 53 |    230 | GPU
DEBUG 01-15 10:09:12.290171.290171 lmp.py:1626]   Expert 24 |    231 | GPU
DEBUG 01-15 10:09:12.290006.290006 lmp.py:1626]   Expert  7 |    232 | GPU
DEBUG 01-15 10:09:12.290794.290794 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:12.290630.290630 lmp.py:1626]   Expert 57 |    250 | GPU
DEBUG 01-15 10:09:12.290465.290465 lmp.py:1626]   Expert 47 |    255 | GPU
DEBUG 01-15 10:09:12.290300.290300 lmp.py:1626]   Expert 29 |    260 | GPU
DEBUG 01-15 10:09:12.290850.290850 lmp.py:1626]   Expert 21 |    264 | GPU
DEBUG 01-15 10:09:12.290685.290685 lmp.py:1626]   Expert  0 |    286 | GPU
DEBUG 01-15 10:09:12.290759.290759 lmp.py:1626]   Expert  4 |    289 | GPU
DEBUG 01-15 10:09:12.290024.290024 lmp.py:1626]   Expert 14 |    290 | GPU
DEBUG 01-15 10:09:12.290574.290574 lmp.py:1626]   Expert 22 |    313 | GPU
DEBUG 01-15 10:09:12.290886.290886 lmp.py:1626]   Expert 58 |    315 | GPU
DEBUG 01-15 10:09:12.290721.290721 lmp.py:1626]   Expert  1 |    317 | GPU
DEBUG 01-15 10:09:12.290318.290318 lmp.py:1626]   Expert 55 |    317 | GPU
DEBUG 01-15 10:09:12.290153.290153 lmp.py:1626]   Expert 37 |    318 | GPU
DEBUG 01-15 10:09:12.290988.290988 lmp.py:1626]   Expert 54 |    333 | GPU
DEBUG 01-15 10:09:12.290300.290300 lmp.py:1626]   Expert 28 |    361 | GPU
DEBUG 01-15 10:09:12.290850.290850 lmp.py:1626]   Expert 12 |    381 | GPU
DEBUG 01-15 10:09:12.290685.290685 lmp.py:1626]   Expert 11 |    396 | GPU
DEBUG 01-15 10:09:12.290474.290474 lmp.py:1626]   Expert 25 |    396 | GPU
DEBUG 01-15 10:09:12.290309.290309 lmp.py:1626]   Expert 30 |    835 | GPU
DEBUG 01-15 10:09:12.290860.290860 lmp.py:1627] 
DEBUG 01-15 10:09:12.290860.290860 lmp.py:1627]   CPU total tokens: 3246 (26.4%)
DEBUG 01-15 10:09:12.290364.290364 lmp.py:1628]   GPU total tokens: 9042 (73.6%)
DEBUG 01-15 10:09:12.290398.290398 cuda_h.py:19] end experts_map_get cost 0.0016260147094726562 seconds
DEBUG 01-15 10:09:12.290844.290844 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.290792.290792 lmp.py:1636] 
DEBUG 01-15 10:09:12.290792.290792 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.290344.290344 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-15 10:09:12.290325.290325 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.290638.290638 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.290835.290835 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.291460.291460 cuda_h.py:19] end allocate_cuda_memory cost 0.0002503395080566406 seconds
INFO 01-15 10:09:12.291447.291447 client.py:127] Model loaded
DEBUG 01-15 10:09:12.291257.291257 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.291148.291148 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.292356.292356 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.291908.291908 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.292487.292487 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.292477.292477 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.292902.292902 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d5eba2e-63cb-48ea-b908-1e0b9810c0ad
DEBUG 01-15 10:09:12.292247.292247 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.292432.292432 cuda_h.py:19] end move_flatidxs cost 0.0008447170257568359 seconds
DEBUG 01-15 10:09:12.293831.293831 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:12.293063.293063 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d5eba2e-63cb-48ea-b908-1e0b9810c0ad
DEBUG 01-15 10:09:12.293920.293920 cuda_h.py:19] end load_into_gpu_async cost 0.0014848709106445312 seconds
DEBUG 01-15 10:09:12.293107.293107 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.293947.293947 cuda_h.py:19] end restore_tensors2 cost 0.0003459453582763672 seconds
DEBUG 01-15 10:09:12.294755.294755 cuda_h.py:19] end restore2model cost 0.002135038375854492 seconds
DEBUG 01-15 10:09:12.294155.294155 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035352706909179688 seconds
DEBUG 01-15 10:09:12.294312.294312 cuda_h.py:19] end sllm_worker_task cost 0.012899637222290039 seconds
DEBUG 01-15 10:09:12.294813.294813 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.297596.297596 cuda_h.py:19] end restore2model cost 0.002634286880493164 seconds
DEBUG 01-15 10:09:12.297923.297923 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006773710250854492 seconds
DEBUG 01-15 10:09:12.297957.297957 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.297955.297955 cuda_h.py:19] end gpu_sexperts cost 0.0002999305725097656 seconds
DEBUG 01-15 10:09:12.297176.297176 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.299710.299710 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014789104461669922 seconds
DEBUG 01-15 10:09:12.300967.300967 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.300106.300106 cuda_h.py:19] end gpu_group_list cost 0.0003337860107421875 seconds
DEBUG 01-15 10:09:12.300123.300123 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.301114.301114 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006899833679199219 seconds
DEBUG 01-15 10:09:12.301268.301268 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.301098.301098 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.09808349609375e-05 seconds
DEBUG 01-15 10:09:12.301224.301224 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.302763.302763 cuda_h.py:19] end group_tensors cost 0.009004354476928711 seconds
DEBUG 01-15 10:09:12.302714.302714 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.306472.306472 cuda_h.py:19] end group pad cost 0.0037946701049804688 seconds
DEBUG 01-15 10:09:12.306560.306560 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.328363.328363 cuda_h.py:19] end group_einsum cost 0.02192544937133789 seconds
DEBUG 01-15 10:09:12.328488.328488 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.333998.333998 cuda_h.py:19] end get_outputs_cpu1 cost 0.004278421401977539 seconds
DEBUG 01-15 10:09:12.334849.334849 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04214215278625488 seconds
DEBUG 01-15 10:09:12.335423.335423 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03373908996582031 seconds
DEBUG 01-15 10:09:12.335555.335555 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.336955.336955 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.336812.336812 cuda_h.py:19] end index_scatter cost 0.00016188621520996094 seconds
DEBUG 01-15 10:09:12.337303.337303 cuda_h.py:19] end cpuoutputsdeal cost 0.001642465591430664 seconds
DEBUG 01-15 10:09:12.337412.337412 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.337680.337680 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d5eba2e-63cb-48ea-b908-1e0b9810c0ad
INFO 01-15 10:09:12.344454.344454 client.py:127] Model loaded
DEBUG 01-15 10:09:12.344691.344691 cuda_h.py:19] end wait_experts cost 0.006650686264038086 seconds
DEBUG 01-15 10:09:12.344839.344839 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.344659.344659 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.344628.344628 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.344670.344670 cuda_h.py:19] end gpu_group_tensor cost 0.00037097930908203125 seconds
DEBUG 01-15 10:09:12.345221.345221 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.346632.346632 cuda_h.py:19] end gpu_group_einsum cost 0.0011005401611328125 seconds
DEBUG 01-15 10:09:12.346872.346872 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.346340.346340 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.347850.347850 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005116462707519531 seconds
DEBUG 01-15 10:09:12.347852.347852 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.347442.347442 cuda_h.py:19] end concat_expert_out cost 0.00011849403381347656 seconds
DEBUG 01-15 10:09:12.347956.347956 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.347929.347929 cuda_h.py:19] end index_scatter cost 0.00011110305786132812 seconds
DEBUG 01-15 10:09:12.348376.348376 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0012805461883544922 seconds
DEBUG 01-15 10:09:12.348441.348441 cuda_h.py:19] end gpu_experts cost 0.003850698471069336 seconds
DEBUG 01-15 10:09:12.348705.348705 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.060213327407836914 seconds
DEBUG 01-15 10:09:12.349306.349306 cuda_h.py:19] end prefill_layer cost 0.0680532455444336 seconds
DEBUG 01-15 10:09:12.349316.349316 lmp.py:1552] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-15 10:09:12.349259.349259 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.349870.349870 lmp.py:1495] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-15 10:09:12.349674.349674 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:12.349722.349722 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:12.349151.349151 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.723403930664062e-05 seconds
DEBUG 01-15 10:09:12.349723.349723 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.000148773193359375 seconds
DEBUG 01-15 10:09:12.349515.349515 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.349115.349115 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.350208.350208 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.350992.350992 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.350522.350522 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.351168.351168 cuda_h.py:19] end allocate_cuda_memory cost 0.0003943443298339844 seconds
DEBUG 01-15 10:09:12.351677.351677 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.351037.351037 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.351379.351379 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.351388.351388 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 540017c1-5926-4299-af3c-11d152d578b4
DEBUG 01-15 10:09:12.351898.351898 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.352134.352134 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.353920.353920 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 540017c1-5926-4299-af3c-11d152d578b4
DEBUG 01-15 10:09:12.353098.353098 cuda_h.py:19] end load_into_gpu_async cost 0.0017919540405273438 seconds
DEBUG 01-15 10:09:12.353096.353096 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.353986.353986 cuda_h.py:19] end restore_tensors2 cost 0.00014400482177734375 seconds
DEBUG 01-15 10:09:12.353307.353307 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033102035522460938 seconds
INFO 01-15 10:09:12.354132.354132 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 540017c1-5926-4299-af3c-11d152d578b4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.358161.358161 cuda_h.py:19] end self_attn cost 0.005404233932495117 seconds
DEBUG 01-15 10:09:12.358447.358447 cuda_h.py:19] end iln_self_attn_paln cost 0.008352518081665039 seconds
DEBUG 01-15 10:09:12.358708.358708 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-15 10:09:12.358153.358153 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.359226.359226 cuda_h.py:19] end gate cost 0.0007441043853759766 seconds
DEBUG 01-15 10:09:12.359645.359645 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.360996.360996 lmp.py:1616] 
DEBUG 01-15 10:09:12.360996.360996 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.360912.360912 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.360337.360337 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.360709.360709 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.360981.360981 lmp.py:1620] 
DEBUG 01-15 10:09:12.360981.360981 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.360538.360538 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.360526.360526 lmp.py:1626]   Expert 12 |     20 | CPU
DEBUG 01-15 10:09:12.360083.360083 lmp.py:1626]   Expert 47 |     24 | CPU
DEBUG 01-15 10:09:12.360117.360117 lmp.py:1626]   Expert 38 |     31 | CPU
DEBUG 01-15 10:09:12.360959.360959 lmp.py:1626]   Expert 27 |     35 | CPU
DEBUG 01-15 10:09:12.360800.360800 lmp.py:1626]   Expert 16 |     36 | CPU
DEBUG 01-15 10:09:12.360927.360927 lmp.py:1626]   Expert 52 |     39 | CPU
DEBUG 01-15 10:09:12.360829.360829 lmp.py:1626]   Expert 63 |     48 | CPU
DEBUG 01-15 10:09:12.360432.360432 lmp.py:1626]   Expert  4 |     59 | CPU
DEBUG 01-15 10:09:12.360989.360989 lmp.py:1626]   Expert 43 |     61 | CPU
DEBUG 01-15 10:09:12.360308.360308 lmp.py:1626]   Expert 44 |     62 | CPU
DEBUG 01-15 10:09:12.360627.360627 lmp.py:1626]   Expert 61 |     64 | CPU
DEBUG 01-15 10:09:12.360230.360230 lmp.py:1626]   Expert 34 |     76 | CPU
DEBUG 01-15 10:09:12.360595.360595 lmp.py:1626]   Expert 53 |     83 | CPU
DEBUG 01-15 10:09:12.360675.360675 lmp.py:1626]   Expert  0 |     86 | CPU
DEBUG 01-15 10:09:12.360040.360040 lmp.py:1626]   Expert 32 |     89 | CPU
DEBUG 01-15 10:09:12.360644.360644 lmp.py:1626]   Expert 37 |     90 | CPU
DEBUG 01-15 10:09:12.360771.360771 lmp.py:1626]   Expert 13 |    102 | CPU
DEBUG 01-15 10:09:12.360136.360136 lmp.py:1626]   Expert 39 |    115 | CPU
DEBUG 01-15 10:09:12.360216.360216 lmp.py:1626]   Expert 21 |    118 | CPU
DEBUG 01-15 10:09:12.360011.360011 lmp.py:1626]   Expert 11 |    120 | CPU
DEBUG 01-15 10:09:12.360568.360568 lmp.py:1626]   Expert 20 |    127 | CPU
DEBUG 01-15 10:09:12.360172.360172 lmp.py:1626]   Expert  8 |    130 | CPU
DEBUG 01-15 10:09:12.360775.360775 lmp.py:1626]   Expert 60 |    133 | CPU
DEBUG 01-15 10:09:12.360140.360140 lmp.py:1626]   Expert 14 |    134 | CPU
DEBUG 01-15 10:09:12.360029.360029 lmp.py:1626]   Expert 57 |    139 | CPU
DEBUG 01-15 10:09:12.360155.360155 lmp.py:1626]   Expert 22 |    141 | CPU
DEBUG 01-15 10:09:12.360997.360997 lmp.py:1626]   Expert 45 |    154 | CPU
DEBUG 01-15 10:09:12.360885.360885 lmp.py:1626]   Expert 17 |    157 | CPU
DEBUG 01-15 10:09:12.360012.360012 lmp.py:1626]   Expert 18 |    157 | CPU
DEBUG 01-15 10:09:12.360807.360807 lmp.py:1626]   Expert 23 |    157 | CPU
DEBUG 01-15 10:09:12.360364.360364 lmp.py:1626]   Expert  2 |    160 | CPU
DEBUG 01-15 10:09:12.361683.361683 lmp.py:1626]   Expert 58 |    161 | CPU
DEBUG 01-15 10:09:12.361479.361479 lmp.py:1626]   Expert  7 |    164 | GPU
DEBUG 01-15 10:09:12.361844.361844 lmp.py:1626]   Expert 30 |    167 | GPU
DEBUG 01-15 10:09:12.361209.361209 lmp.py:1626]   Expert 42 |    169 | GPU
DEBUG 01-15 10:09:12.361574.361574 lmp.py:1626]   Expert 48 |    179 | GPU
DEBUG 01-15 10:09:12.361700.361700 lmp.py:1626]   Expert 49 |    179 | GPU
DEBUG 01-15 10:09:12.361065.361065 lmp.py:1626]   Expert 55 |    180 | GPU
DEBUG 01-15 10:09:12.361192.361192 lmp.py:1626]   Expert 62 |    180 | GPU
DEBUG 01-15 10:09:12.361842.361842 lmp.py:1626]   Expert 35 |    183 | GPU
DEBUG 01-15 10:09:12.361445.361445 lmp.py:1626]   Expert 51 |    187 | GPU
DEBUG 01-15 10:09:12.361525.361525 lmp.py:1626]   Expert 29 |    188 | GPU
DEBUG 01-15 10:09:12.361083.361083 lmp.py:1626]   Expert 25 |    193 | GPU
DEBUG 01-15 10:09:12.361686.361686 lmp.py:1626]   Expert 36 |    193 | GPU
DEBUG 01-15 10:09:12.361574.361574 lmp.py:1626]   Expert  6 |    195 | GPU
DEBUG 01-15 10:09:12.361939.361939 lmp.py:1626]   Expert  1 |    200 | GPU
DEBUG 01-15 10:09:12.361543.361543 lmp.py:1626]   Expert 31 |    207 | GPU
DEBUG 01-15 10:09:12.361146.361146 lmp.py:1626]   Expert 28 |    221 | GPU
DEBUG 01-15 10:09:12.361511.361511 lmp.py:1626]   Expert  5 |    229 | GPU
DEBUG 01-15 10:09:12.361638.361638 lmp.py:1626]   Expert 54 |    230 | GPU
DEBUG 01-15 10:09:12.361764.361764 lmp.py:1626]   Expert 41 |    232 | GPU
DEBUG 01-15 10:09:12.361904.361904 lmp.py:1626]   Expert 19 |    237 | GPU
DEBUG 01-15 10:09:12.361601.361601 lmp.py:1626]   Expert  9 |    239 | GPU
DEBUG 01-15 10:09:12.361628.361628 lmp.py:1626]   Expert 24 |    253 | GPU
DEBUG 01-15 10:09:12.361516.361516 lmp.py:1626]   Expert 50 |    287 | GPU
DEBUG 01-15 10:09:12.361927.361927 lmp.py:1626]   Expert 46 |    302 | GPU
DEBUG 01-15 10:09:12.361815.361815 lmp.py:1626]   Expert 59 |    311 | GPU
DEBUG 01-15 10:09:12.361419.361419 lmp.py:1626]   Expert 56 |    375 | GPU
DEBUG 01-15 10:09:12.361307.361307 lmp.py:1626]   Expert 26 |    405 | GPU
DEBUG 01-15 10:09:12.361911.361911 lmp.py:1626]   Expert 33 |    421 | GPU
DEBUG 01-15 10:09:12.361468.361468 lmp.py:1626]   Expert  3 |    590 | GPU
DEBUG 01-15 10:09:12.361786.361786 lmp.py:1626]   Expert 10 |    643 | GPU
DEBUG 01-15 10:09:12.361628.361628 lmp.py:1626]   Expert 15 |    648 | GPU
DEBUG 01-15 10:09:12.361755.361755 lmp.py:1626]   Expert 40 |    793 | GPU
DEBUG 01-15 10:09:12.361073.361073 lmp.py:1627] 
DEBUG 01-15 10:09:12.361073.361073 lmp.py:1627]   CPU total tokens: 3108 (25.3%)
DEBUG 01-15 10:09:12.361107.361107 lmp.py:1628]   GPU total tokens: 9180 (74.7%)
DEBUG 01-15 10:09:12.361148.361148 cuda_h.py:19] end experts_map_get cost 0.002125978469848633 seconds
INFO 01-15 10:09:12.361663.361663 client.py:127] Model loaded
DEBUG 01-15 10:09:12.362998.362998 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.362585.362585 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.362270.362270 lmp.py:1636] 
DEBUG 01-15 10:09:12.362270.362270 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.363635.363635 cuda_h.py:19] end restore2model cost 0.001081705093383789 seconds
DEBUG 01-15 10:09:12.363230.363230 cuda_h.py:19] end cpu_experts_submit cost 0.0013735294342041016 seconds
DEBUG 01-15 10:09:12.364431.364431 cuda_h.py:19] end sllm_worker_task cost 0.013977527618408203 seconds
DEBUG 01-15 10:09:12.364601.364601 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.364177.364177 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.364861.364861 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.364668.364668 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.364032.364032 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.365091.365091 cuda_h.py:19] end allocate_cuda_memory cost 0.00030231475830078125 seconds
DEBUG 01-15 10:09:12.365199.365199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.365346.365346 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.365268.365268 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.365216.365216 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e52b4bcf-ac80-4cb5-b1e1-d869762e8046
DEBUG 01-15 10:09:12.365755.365755 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.365587.365587 cuda_h.py:19] end move_flatidxs cost 0.0008702278137207031 seconds
DEBUG 01-15 10:09:12.365714.365714 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:12.366059.366059 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e52b4bcf-ac80-4cb5-b1e1-d869762e8046
DEBUG 01-15 10:09:12.366293.366293 cuda_h.py:19] end load_into_gpu_async cost 0.0017857551574707031 seconds
DEBUG 01-15 10:09:12.366765.366765 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.367376.367376 cuda_h.py:19] end restore_tensors2 cost 0.0004189014434814453 seconds
DEBUG 01-15 10:09:12.367358.367358 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029306411743164062 seconds
DEBUG 01-15 10:09:12.367604.367604 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.370527.370527 cuda_h.py:19] end restore2model cost 0.002782583236694336 seconds
DEBUG 01-15 10:09:12.370608.370608 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005942583084106445 seconds
DEBUG 01-15 10:09:12.370927.370927 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.370507.370507 cuda_h.py:19] end gpu_sexperts cost 0.00029087066650390625 seconds
DEBUG 01-15 10:09:12.370628.370628 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.372481.372481 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015039443969726562 seconds
DEBUG 01-15 10:09:12.373613.373613 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.373029.373029 cuda_h.py:19] end gpu_group_list cost 0.0003287792205810547 seconds
DEBUG 01-15 10:09:12.373384.373384 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.374376.374376 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006911754608154297 seconds
DEBUG 01-15 10:09:12.374337.374337 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.374644.374644 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0742416381835938e-05 seconds
DEBUG 01-15 10:09:12.374532.374532 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.376854.376854 cuda_h.py:19] end group_tensors cost 0.010831832885742188 seconds
DEBUG 01-15 10:09:12.377651.377651 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.381305.381305 cuda_h.py:19] end group pad cost 0.004034757614135742 seconds
DEBUG 01-15 10:09:12.381287.381287 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.402585.402585 cuda_h.py:19] end group_einsum cost 0.021094560623168945 seconds
DEBUG 01-15 10:09:12.402312.402312 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.406171.406171 cuda_h.py:19] end get_outputs_cpu1 cost 0.0036242008209228516 seconds
DEBUG 01-15 10:09:12.407818.407818 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04297208786010742 seconds
DEBUG 01-15 10:09:12.408908.408908 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03429460525512695 seconds
DEBUG 01-15 10:09:12.409126.409126 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.409744.409744 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.409694.409694 cuda_h.py:19] end index_scatter cost 0.0001537799835205078 seconds
DEBUG 01-15 10:09:12.410685.410685 cuda_h.py:19] end cpuoutputsdeal cost 0.0011489391326904297 seconds
DEBUG 01-15 10:09:12.410887.410887 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.410625.410625 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e52b4bcf-ac80-4cb5-b1e1-d869762e8046
INFO 01-15 10:09:12.417004.417004 client.py:127] Model loaded
DEBUG 01-15 10:09:12.417757.417757 cuda_h.py:19] end wait_experts cost 0.007091045379638672 seconds
DEBUG 01-15 10:09:12.417905.417905 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.417797.417797 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.417190.417190 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.418424.418424 cuda_h.py:19] end gpu_group_tensor cost 0.00037360191345214844 seconds
DEBUG 01-15 10:09:12.418537.418537 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.419101.419101 cuda_h.py:19] end gpu_group_einsum cost 0.001111745834350586 seconds
DEBUG 01-15 10:09:12.420202.420202 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.420279.420279 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.420507.420507 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005767345428466797 seconds
DEBUG 01-15 10:09:12.420092.420092 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.421179.421179 cuda_h.py:19] end concat_expert_out cost 0.0001270771026611328 seconds
DEBUG 01-15 10:09:12.421991.421991 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.421270.421270 cuda_h.py:19] end index_scatter cost 0.00011944770812988281 seconds
DEBUG 01-15 10:09:12.421200.421200 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001405954360961914 seconds
DEBUG 01-15 10:09:12.421417.421417 cuda_h.py:19] end gpu_experts cost 0.00395965576171875 seconds
DEBUG 01-15 10:09:12.421523.421523 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06304788589477539 seconds
DEBUG 01-15 10:09:12.422667.422667 cuda_h.py:19] end prefill_layer cost 0.0732259750366211 seconds
DEBUG 01-15 10:09:12.422108.422108 lmp.py:1552] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-15 10:09:12.422818.422818 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.422152.422152 lmp.py:1495] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-15 10:09:12.422916.422916 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:12.423971.423971 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:12.423606.423606 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.295608520507812e-05 seconds
DEBUG 01-15 10:09:12.423198.423198 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.0001697540283203125 seconds
DEBUG 01-15 10:09:12.423571.423571 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.423180.423180 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.423776.423776 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.423035.423035 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.424478.424478 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.424018.424018 cuda_h.py:19] end allocate_cuda_memory cost 0.0004012584686279297 seconds
DEBUG 01-15 10:09:12.424135.424135 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.424973.424973 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.424726.424726 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.425358.425358 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aa176a07-b343-45eb-80cc-63b9af871021
DEBUG 01-15 10:09:12.425676.425676 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.425333.425333 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.426909.426909 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aa176a07-b343-45eb-80cc-63b9af871021
DEBUG 01-15 10:09:12.426326.426326 cuda_h.py:19] end load_into_gpu_async cost 0.0016222000122070312 seconds
DEBUG 01-15 10:09:12.426284.426284 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.426007.426007 cuda_h.py:19] end restore_tensors2 cost 0.00013780593872070312 seconds
DEBUG 01-15 10:09:12.426798.426798 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028858184814453125 seconds
INFO 01-15 10:09:12.427910.427910 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aa176a07-b343-45eb-80cc-63b9af871021
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.431076.431076 cuda_h.py:19] end self_attn cost 0.005181074142456055 seconds
DEBUG 01-15 10:09:12.431978.431978 cuda_h.py:19] end iln_self_attn_paln cost 0.008336305618286133 seconds
DEBUG 01-15 10:09:12.431432.431432 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-15 10:09:12.431036.431036 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.432845.432845 cuda_h.py:19] end gate cost 0.0007572174072265625 seconds
DEBUG 01-15 10:09:12.432840.432840 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.433444.433444 lmp.py:1616] 
DEBUG 01-15 10:09:12.433444.433444 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.433313.433313 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.433453.433453 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.433301.433301 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.433766.433766 lmp.py:1620] 
DEBUG 01-15 10:09:12.433766.433766 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.433515.433515 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.433172.433172 lmp.py:1626]   Expert 42 |     21 | CPU
DEBUG 01-15 10:09:12.433590.433590 lmp.py:1626]   Expert 19 |     24 | CPU
DEBUG 01-15 10:09:12.433862.433862 lmp.py:1626]   Expert 30 |     27 | CPU
DEBUG 01-15 10:09:12.433611.433611 lmp.py:1626]   Expert 32 |     47 | CPU
DEBUG 01-15 10:09:12.433884.433884 lmp.py:1626]   Expert  6 |     57 | CPU
DEBUG 01-15 10:09:12.433871.433871 lmp.py:1626]   Expert  5 |     73 | CPU
DEBUG 01-15 10:09:12.433144.433144 lmp.py:1626]   Expert 53 |     74 | CPU
DEBUG 01-15 10:09:12.433370.433370 lmp.py:1626]   Expert  1 |     79 | CPU
DEBUG 01-15 10:09:12.433880.433880 lmp.py:1626]   Expert  9 |    120 | CPU
DEBUG 01-15 10:09:12.433630.433630 lmp.py:1626]   Expert 13 |    121 | CPU
DEBUG 01-15 10:09:12.433333.433333 lmp.py:1626]   Expert 63 |    128 | CPU
DEBUG 01-15 10:09:12.433320.433320 lmp.py:1626]   Expert 50 |    130 | CPU
DEBUG 01-15 10:09:12.433593.433593 lmp.py:1626]   Expert 58 |    130 | CPU
DEBUG 01-15 10:09:12.433627.433627 lmp.py:1626]   Expert 34 |    131 | CPU
DEBUG 01-15 10:09:12.433660.433660 lmp.py:1626]   Expert 26 |    136 | CPU
DEBUG 01-15 10:09:12.433218.433218 lmp.py:1626]   Expert 11 |    137 | CPU
DEBUG 01-15 10:09:12.433205.433205 lmp.py:1626]   Expert 31 |    137 | CPU
DEBUG 01-15 10:09:12.433954.433954 lmp.py:1626]   Expert 18 |    138 | CPU
DEBUG 01-15 10:09:12.433227.433227 lmp.py:1626]   Expert 59 |    140 | CPU
DEBUG 01-15 10:09:12.433784.433784 lmp.py:1626]   Expert 40 |    145 | CPU
DEBUG 01-15 10:09:12.433056.433056 lmp.py:1626]   Expert 12 |    149 | CPU
DEBUG 01-15 10:09:12.433329.433329 lmp.py:1626]   Expert 46 |    149 | CPU
DEBUG 01-15 10:09:12.433124.433124 lmp.py:1626]   Expert  4 |    151 | CPU
DEBUG 01-15 10:09:12.433827.433827 lmp.py:1626]   Expert 48 |    152 | CPU
DEBUG 01-15 10:09:12.433623.433623 lmp.py:1626]   Expert 56 |    152 | CPU
DEBUG 01-15 10:09:12.433657.433657 lmp.py:1626]   Expert  2 |    153 | CPU
DEBUG 01-15 10:09:12.434690.434690 lmp.py:1626]   Expert 20 |    155 | CPU
DEBUG 01-15 10:09:12.434963.434963 lmp.py:1626]   Expert 61 |    155 | CPU
DEBUG 01-15 10:09:12.434235.434235 lmp.py:1626]   Expert 33 |    156 | CPU
DEBUG 01-15 10:09:12.434984.434984 lmp.py:1626]   Expert 35 |    164 | CPU
DEBUG 01-15 10:09:12.434018.434018 lmp.py:1626]   Expert 10 |    167 | CPU
DEBUG 01-15 10:09:12.434575.434575 lmp.py:1626]   Expert 55 |    169 | CPU
DEBUG 01-15 10:09:12.434609.434609 lmp.py:1626]   Expert 51 |    174 | GPU
DEBUG 01-15 10:09:12.434882.434882 lmp.py:1626]   Expert 36 |    180 | GPU
DEBUG 01-15 10:09:12.434869.434869 lmp.py:1626]   Expert  8 |    182 | GPU
DEBUG 01-15 10:09:12.434095.434095 lmp.py:1626]   Expert 52 |    184 | GPU
DEBUG 01-15 10:09:12.434129.434129 lmp.py:1626]   Expert 37 |    187 | GPU
DEBUG 01-15 10:09:12.434163.434163 lmp.py:1626]   Expert 57 |    204 | GPU
DEBUG 01-15 10:09:12.434436.434436 lmp.py:1626]   Expert  0 |    205 | GPU
DEBUG 01-15 10:09:12.434708.434708 lmp.py:1626]   Expert 39 |    221 | GPU
DEBUG 01-15 10:09:12.434742.434742 lmp.py:1626]   Expert 25 |    224 | GPU
DEBUG 01-15 10:09:12.434253.434253 lmp.py:1626]   Expert 62 |    236 | GPU
DEBUG 01-15 10:09:12.434048.434048 lmp.py:1626]   Expert 38 |    242 | GPU
DEBUG 01-15 10:09:12.434321.434321 lmp.py:1626]   Expert  3 |    245 | GPU
DEBUG 01-15 10:09:12.434878.434878 lmp.py:1626]   Expert  7 |    245 | GPU
DEBUG 01-15 10:09:12.434912.434912 lmp.py:1626]   Expert 24 |    251 | GPU
DEBUG 01-15 10:09:12.434946.434946 lmp.py:1626]   Expert 27 |    254 | GPU
DEBUG 01-15 10:09:12.434695.434695 lmp.py:1626]   Expert 28 |    256 | GPU
DEBUG 01-15 10:09:12.434729.434729 lmp.py:1626]   Expert 49 |    258 | GPU
DEBUG 01-15 10:09:12.434240.434240 lmp.py:1626]   Expert 60 |    258 | GPU
INFO 01-15 10:09:12.434456.434456 client.py:127] Model loaded
DEBUG 01-15 10:09:12.434553.434553 lmp.py:1626]   Expert 21 |    262 | GPU
DEBUG 01-15 10:09:12.434855.434855 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.435758.435758 lmp.py:1626]   Expert 16 |    268 | GPU
DEBUG 01-15 10:09:12.436535.436535 cuda_h.py:19] end restore2model cost 0.0011112689971923828 seconds
DEBUG 01-15 10:09:12.436612.436612 lmp.py:1626]   Expert 43 |    270 | GPU
DEBUG 01-15 10:09:12.436855.436855 cuda_h.py:19] end sllm_worker_task cost 0.012625455856323242 seconds
DEBUG 01-15 10:09:12.436660.436660 lmp.py:1626]   Expert 23 |    273 | GPU
DEBUG 01-15 10:09:12.436626.436626 lmp.py:1626]   Expert 29 |    278 | GPU
DEBUG 01-15 10:09:12.436806.436806 lmp.py:1626]   Expert 15 |    291 | GPU
DEBUG 01-15 10:09:12.436410.436410 lmp.py:1626]   Expert 47 |    293 | GPU
DEBUG 01-15 10:09:12.436490.436490 lmp.py:1626]   Expert 22 |    294 | GPU
DEBUG 01-15 10:09:12.436570.436570 lmp.py:1626]   Expert 41 |    298 | GPU
DEBUG 01-15 10:09:12.436935.436935 lmp.py:1626]   Expert 44 |    306 | GPU
DEBUG 01-15 10:09:12.436062.436062 lmp.py:1626]   Expert 54 |    351 | GPU
DEBUG 01-15 10:09:12.437188.437188 lmp.py:1626]   Expert 14 |    375 | GPU
DEBUG 01-15 10:09:12.437315.437315 lmp.py:1626]   Expert 17 |    405 | GPU
DEBUG 01-15 10:09:12.437157.437157 lmp.py:1626]   Expert 45 |    451 | GPU
DEBUG 01-15 10:09:12.437668.437668 lmp.py:1627] 
DEBUG 01-15 10:09:12.437668.437668 lmp.py:1627]   CPU total tokens: 3867 (31.5%)
DEBUG 01-15 10:09:12.437655.437655 lmp.py:1628]   GPU total tokens: 8421 (68.5%)
DEBUG 01-15 10:09:12.437656.437656 cuda_h.py:19] end experts_map_get cost 0.0043485164642333984 seconds
DEBUG 01-15 10:09:12.437487.437487 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.437210.437210 lmp.py:1636] 
DEBUG 01-15 10:09:12.437210.437210 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.437266.437266 cuda_h.py:19] end cpu_experts_submit cost 7.653236389160156e-05 seconds
DEBUG 01-15 10:09:12.437876.437876 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.437269.437269 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.437653.437653 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.438542.438542 cuda_h.py:19] end allocate_cuda_memory cost 0.0003070831298828125 seconds
DEBUG 01-15 10:09:12.438159.438159 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.438181.438181 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.438904.438904 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.438926.438926 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.438735.438735 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 268615f4-7a2b-4662-ba5d-c61296064a78
DEBUG 01-15 10:09:12.438054.438054 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.438247.438247 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.439939.439939 cuda_h.py:19] end move_flatidxs cost 0.0008687973022460938 seconds
DEBUG 01-15 10:09:12.439590.439590 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:12.439849.439849 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 268615f4-7a2b-4662-ba5d-c61296064a78
DEBUG 01-15 10:09:12.439169.439169 cuda_h.py:19] end load_into_gpu_async cost 0.001565694808959961 seconds
DEBUG 01-15 10:09:12.440348.440348 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.440084.440084 cuda_h.py:19] end restore_tensors2 cost 0.0003745555877685547 seconds
DEBUG 01-15 10:09:12.440390.440390 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002971172332763672 seconds
DEBUG 01-15 10:09:12.440775.440775 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.443386.443386 cuda_h.py:19] end restore2model cost 0.002593994140625 seconds
DEBUG 01-15 10:09:12.443845.443845 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005778789520263672 seconds
DEBUG 01-15 10:09:12.443071.443071 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.443871.443871 cuda_h.py:19] end gpu_sexperts cost 0.0003070831298828125 seconds
DEBUG 01-15 10:09:12.443853.443853 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.445110.445110 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015218257904052734 seconds
DEBUG 01-15 10:09:12.445851.445851 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.446798.446798 cuda_h.py:19] end gpu_group_list cost 0.0003333091735839844 seconds
DEBUG 01-15 10:09:12.446676.446676 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.447489.447489 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006995201110839844 seconds
DEBUG 01-15 10:09:12.447166.447166 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.447280.447280 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-15 10:09:12.447453.447453 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.451077.451077 cuda_h.py:19] end group_tensors cost 0.01210331916809082 seconds
DEBUG 01-15 10:09:12.452738.452738 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.456106.456106 cuda_h.py:19] end group pad cost 0.004220485687255859 seconds
DEBUG 01-15 10:09:12.456612.456612 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.480406.480406 cuda_h.py:19] end group_einsum cost 0.02325606346130371 seconds
DEBUG 01-15 10:09:12.480471.480471 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.484722.484722 cuda_h.py:19] end get_outputs_cpu1 cost 0.004652500152587891 seconds
DEBUG 01-15 10:09:12.485069.485069 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.047464609146118164 seconds
DEBUG 01-15 10:09:12.487564.487564 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03982114791870117 seconds
DEBUG 01-15 10:09:12.487027.487027 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.487745.487745 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.488880.488880 cuda_h.py:19] end index_scatter cost 0.0001571178436279297 seconds
DEBUG 01-15 10:09:12.488825.488825 cuda_h.py:19] end cpuoutputsdeal cost 0.001186370849609375 seconds
DEBUG 01-15 10:09:12.488266.488266 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.488912.488912 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 268615f4-7a2b-4662-ba5d-c61296064a78
INFO 01-15 10:09:12.490160.490160 client.py:127] Model loaded
DEBUG 01-15 10:09:12.491476.491476 cuda_h.py:19] end wait_experts cost 0.0022149085998535156 seconds
DEBUG 01-15 10:09:12.491286.491286 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.491886.491886 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.491750.491750 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.491069.491069 cuda_h.py:19] end gpu_group_tensor cost 0.0003685951232910156 seconds
DEBUG 01-15 10:09:12.492944.492944 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.493874.493874 cuda_h.py:19] end gpu_group_einsum cost 0.0011196136474609375 seconds
DEBUG 01-15 10:09:12.493299.493299 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.493131.493131 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.494146.494146 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005643367767333984 seconds
DEBUG 01-15 10:09:12.494824.494824 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.494764.494764 cuda_h.py:19] end concat_expert_out cost 0.0001266002655029297 seconds
DEBUG 01-15 10:09:12.494054.494054 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.494425.494425 cuda_h.py:19] end index_scatter cost 0.00011682510375976562 seconds
DEBUG 01-15 10:09:12.494547.494547 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013854503631591797 seconds
DEBUG 01-15 10:09:12.495487.495487 cuda_h.py:19] end gpu_experts cost 0.003942251205444336 seconds
DEBUG 01-15 10:09:12.495023.495023 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.0634772777557373 seconds
DEBUG 01-15 10:09:12.496551.496551 cuda_h.py:19] end prefill_layer cost 0.07321453094482422 seconds
DEBUG 01-15 10:09:12.496515.496515 lmp.py:1552] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-15 10:09:12.496272.496272 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.496844.496844 lmp.py:1495] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-15 10:09:12.496820.496820 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:12.496545.496545 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:12.496656.496656 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.343292236328125e-05 seconds
DEBUG 01-15 10:09:12.496879.496879 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.496691.496691 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.0003447532653808594 seconds
DEBUG 01-15 10:09:12.497175.497175 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.497326.497326 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.497604.497604 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.498965.498965 cuda_h.py:19] end allocate_cuda_memory cost 0.0004203319549560547 seconds
DEBUG 01-15 10:09:12.498666.498666 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.498219.498219 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.498130.498130 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.498808.498808 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6c445b01-b789-4cd5-88af-63bd09b7f938
DEBUG 01-15 10:09:12.498225.498225 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.499161.499161 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.499913.499913 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.499572.499572 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6c445b01-b789-4cd5-88af-63bd09b7f938
DEBUG 01-15 10:09:12.500301.500301 cuda_h.py:19] end load_into_gpu_async cost 0.0016660690307617188 seconds
DEBUG 01-15 10:09:12.500702.500702 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.500551.500551 cuda_h.py:19] end restore_tensors2 cost 0.00016260147094726562 seconds
DEBUG 01-15 10:09:12.500964.500964 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031020641326904297 seconds
INFO 01-15 10:09:12.500228.500228 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6c445b01-b789-4cd5-88af-63bd09b7f938
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.504828.504828 cuda_h.py:19] end self_attn cost 0.005278587341308594 seconds
DEBUG 01-15 10:09:12.505638.505638 cuda_h.py:19] end iln_self_attn_paln cost 0.007779836654663086 seconds
DEBUG 01-15 10:09:12.505628.505628 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-15 10:09:12.505710.505710 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.506794.506794 cuda_h.py:19] end gate cost 0.0008842945098876953 seconds
DEBUG 01-15 10:09:12.506227.506227 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.507078.507078 lmp.py:1616] 
DEBUG 01-15 10:09:12.507078.507078 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.507053.507053 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.507107.507107 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.507870.507870 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.507533.507533 lmp.py:1620] 
DEBUG 01-15 10:09:12.507533.507533 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.507958.507958 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.507529.507529 lmp.py:1626]   Expert 34 |     28 | CPU
DEBUG 01-15 10:09:12.507192.507192 lmp.py:1626]   Expert  7 |     31 | CPU
DEBUG 01-15 10:09:12.507809.507809 lmp.py:1626]   Expert 13 |     42 | CPU
DEBUG 01-15 10:09:12.507473.507473 lmp.py:1626]   Expert 54 |     76 | CPU
DEBUG 01-15 10:09:12.507898.507898 lmp.py:1626]   Expert 18 |     85 | CPU
DEBUG 01-15 10:09:12.507084.507084 lmp.py:1626]   Expert 49 |     88 | CPU
DEBUG 01-15 10:09:12.507463.507463 lmp.py:1626]   Expert 39 |     89 | CPU
DEBUG 01-15 10:09:12.507411.507411 lmp.py:1626]   Expert 59 |    102 | CPU
DEBUG 01-15 10:09:12.507882.507882 lmp.py:1626]   Expert 21 |    107 | CPU
DEBUG 01-15 10:09:12.507592.507592 lmp.py:1626]   Expert  0 |    108 | CPU
DEBUG 01-15 10:09:12.507825.507825 lmp.py:1626]   Expert 16 |    108 | CPU
DEBUG 01-15 10:09:12.507249.507249 lmp.py:1626]   Expert 41 |    117 | CPU
DEBUG 01-15 10:09:12.507198.507198 lmp.py:1626]   Expert 15 |    121 | CPU
DEBUG 01-15 10:09:12.507430.507430 lmp.py:1626]   Expert 22 |    121 | CPU
DEBUG 01-15 10:09:12.507617.507617 lmp.py:1626]   Expert 45 |    122 | CPU
DEBUG 01-15 10:09:12.507565.507565 lmp.py:1626]   Expert 17 |    125 | CPU
DEBUG 01-15 10:09:12.507559.507559 lmp.py:1626]   Expert  8 |    136 | CPU
DEBUG 01-15 10:09:12.507792.507792 lmp.py:1626]   Expert 52 |    136 | CPU
DEBUG 01-15 10:09:12.507740.507740 lmp.py:1626]   Expert 61 |    137 | CPU
DEBUG 01-15 10:09:12.507496.507496 lmp.py:1626]   Expert 35 |    138 | CPU
DEBUG 01-15 10:09:12.507775.507775 lmp.py:1626]   Expert 38 |    141 | CPU
DEBUG 01-15 10:09:12.507168.507168 lmp.py:1626]   Expert 12 |    144 | CPU
DEBUG 01-15 10:09:12.508262.508262 lmp.py:1626]   Expert 48 |    147 | CPU
DEBUG 01-15 10:09:12.508448.508448 lmp.py:1626]   Expert 31 |    148 | CPU
DEBUG 01-15 10:09:12.508873.508873 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:12.508821.508821 lmp.py:1626]   Expert 53 |    156 | CPU
DEBUG 01-15 10:09:12.508723.508723 lmp.py:1626]   Expert 50 |    159 | CPU
DEBUG 01-15 10:09:12.508909.508909 lmp.py:1626]   Expert 40 |    160 | CPU
DEBUG 01-15 10:09:12.508619.508619 lmp.py:1626]   Expert 60 |    160 | CPU
DEBUG 01-15 10:09:12.508090.508090 lmp.py:1626]   Expert 27 |    174 | CPU
DEBUG 01-15 10:09:12.508800.508800 lmp.py:1626]   Expert 19 |    194 | CPU
DEBUG 01-15 10:09:12.508563.508563 lmp.py:1626]   Expert 29 |    200 | CPU
DEBUG 01-15 10:09:12.508988.508988 lmp.py:1626]   Expert  4 |    201 | GPU
DEBUG 01-15 10:09:12.508459.508459 lmp.py:1626]   Expert 30 |    204 | GPU
DEBUG 01-15 10:09:12.508521.508521 lmp.py:1626]   Expert 11 |    216 | GPU
DEBUG 01-15 10:09:12.508072.508072 lmp.py:1626]   Expert 20 |    217 | GPU
DEBUG 01-15 10:09:12.508145.508145 lmp.py:1626]   Expert 26 |    220 | GPU
DEBUG 01-15 10:09:12.508457.508457 lmp.py:1626]   Expert 57 |    223 | GPU
DEBUG 01-15 10:09:12.508292.508292 lmp.py:1626]   Expert  6 |    226 | GPU
DEBUG 01-15 10:09:12.508365.508365 lmp.py:1626]   Expert 46 |    226 | GPU
DEBUG 01-15 10:09:12.508962.508962 lmp.py:1626]   Expert 43 |    231 | GPU
DEBUG 01-15 10:09:12.508512.508512 lmp.py:1626]   Expert  2 |    240 | GPU
DEBUG 01-15 10:09:12.508586.508586 lmp.py:1626]   Expert 23 |    240 | GPU
DEBUG 01-15 10:09:12.508852.508852 lmp.py:1626]   Expert 33 |    242 | GPU
DEBUG 01-15 10:09:12.508163.508163 lmp.py:1626]   Expert 42 |    247 | GPU
DEBUG 01-15 10:09:12.508237.508237 lmp.py:1626]   Expert 55 |    253 | GPU
DEBUG 01-15 10:09:12.508787.508787 lmp.py:1626]   Expert 56 |    253 | GPU
DEBUG 01-15 10:09:12.508384.508384 lmp.py:1626]   Expert 32 |    257 | GPU
DEBUG 01-15 10:09:12.508934.508934 lmp.py:1626]   Expert  9 |    261 | GPU
DEBUG 01-15 10:09:12.508769.508769 lmp.py:1626]   Expert  3 |    262 | GPU
DEBUG 01-15 10:09:12.508604.508604 lmp.py:1626]   Expert 14 |    265 | GPU
DEBUG 01-15 10:09:12.508393.508393 lmp.py:1626]   Expert 28 |    267 | GPU
DEBUG 01-15 10:09:12.508705.508705 lmp.py:1626]   Expert 44 |    275 | GPU
DEBUG 01-15 10:09:12.508540.508540 lmp.py:1626]   Expert  1 |    278 | GPU
DEBUG 01-15 10:09:12.508375.508375 lmp.py:1626]   Expert 51 |    278 | GPU
DEBUG 01-15 10:09:12.508972.508972 lmp.py:1626]   Expert 58 |    279 | GPU
DEBUG 01-15 10:09:12.508568.508568 lmp.py:1626]   Expert 37 |    288 | GPU
DEBUG 01-15 10:09:12.508403.508403 lmp.py:1626]   Expert 63 |    288 | GPU
DEBUG 01-15 10:09:12.508000.508000 lmp.py:1626]   Expert 47 |    289 | GPU
DEBUG 01-15 10:09:12.508312.508312 lmp.py:1626]   Expert 24 |    303 | GPU
DEBUG 01-15 10:09:12.508147.508147 lmp.py:1626]   Expert 62 |    309 | GPU
DEBUG 01-15 10:09:12.508936.508936 lmp.py:1626]   Expert 10 |    311 | GPU
DEBUG 01-15 10:09:12.508201.508201 lmp.py:1626]   Expert 25 |    319 | GPU
DEBUG 01-15 10:09:12.509798.509798 lmp.py:1626]   Expert  5 |    365 | GPU
DEBUG 01-15 10:09:12.509256.509256 lmp.py:1627] 
DEBUG 01-15 10:09:12.509256.509256 lmp.py:1627]   CPU total tokens: 3955 (32.2%)
DEBUG 01-15 10:09:12.509998.509998 lmp.py:1628]   GPU total tokens: 8333 (67.8%)
DEBUG 01-15 10:09:12.509463.509463 cuda_h.py:19] end experts_map_get cost 0.0024492740631103516 seconds
INFO 01-15 10:09:12.509792.509792 client.py:127] Model loaded
DEBUG 01-15 10:09:12.509373.509373 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.509675.509675 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.509168.509168 lmp.py:1636] 
DEBUG 01-15 10:09:12.509168.509168 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.510362.510362 cuda_h.py:19] end cpu_experts_submit cost 0.0004658699035644531 seconds
DEBUG 01-15 10:09:12.510449.510449 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.510643.510643 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.510816.510816 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.510772.510772 cuda_h.py:19] end allocate_cuda_memory cost 0.0002484321594238281 seconds
DEBUG 01-15 10:09:12.510099.510099 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.510239.510239 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.510592.510592 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.510155.510155 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 73340440-a94b-42a3-86c6-9a68f80b81f0
DEBUG 01-15 10:09:12.511494.511494 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.511979.511979 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.512119.512119 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.512685.512685 cuda_h.py:19] end restore2model cost 0.002647876739501953 seconds
INFO 01-15 10:09:12.512913.512913 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 73340440-a94b-42a3-86c6-9a68f80b81f0
DEBUG 01-15 10:09:12.512535.512535 cuda_h.py:19] end sllm_worker_task cost 0.015694379806518555 seconds
DEBUG 01-15 10:09:12.513159.513159 cuda_h.py:19] end move_flatidxs cost 0.000946044921875 seconds
DEBUG 01-15 10:09:12.513287.513287 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.513071.513071 cuda_h.py:19] end load_into_gpu_async cost 0.0022706985473632812 seconds
DEBUG 01-15 10:09:12.513037.513037 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.513169.513169 cuda_h.py:19] end restore_tensors2 cost 0.00034999847412109375 seconds
DEBUG 01-15 10:09:12.513131.513131 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003458261489868164 seconds
DEBUG 01-15 10:09:12.513715.513715 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.516415.516415 cuda_h.py:19] end restore2model cost 0.0026628971099853516 seconds
DEBUG 01-15 10:09:12.516947.516947 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0063402652740478516 seconds
DEBUG 01-15 10:09:12.516696.516696 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.516045.516045 cuda_h.py:19] end gpu_sexperts cost 0.00029540061950683594 seconds
DEBUG 01-15 10:09:12.516020.516020 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.518407.518407 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014431476593017578 seconds
DEBUG 01-15 10:09:12.519763.519763 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.519708.519708 cuda_h.py:19] end gpu_group_list cost 0.00029850006103515625 seconds
DEBUG 01-15 10:09:12.518479.518479 cuda_h.py:19] end group_tensors cost 0.005677223205566406 seconds
DEBUG 01-15 10:09:12.519096.519096 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.519753.519753 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.520013.520013 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008471012115478516 seconds
DEBUG 01-15 10:09:12.520617.520617 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.520739.520739 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-15 10:09:12.520911.520911 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.523542.523542 cuda_h.py:19] end group pad cost 0.004101991653442383 seconds
DEBUG 01-15 10:09:12.523431.523431 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.547375.547375 cuda_h.py:19] end group_einsum cost 0.024122953414916992 seconds
DEBUG 01-15 10:09:12.548407.548407 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.552125.552125 cuda_h.py:19] end get_outputs_cpu1 cost 0.004561185836791992 seconds
DEBUG 01-15 10:09:12.554714.554714 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03436398506164551 seconds
DEBUG 01-15 10:09:12.555680.555680 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.555469.555469 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.555311.555311 cuda_h.py:19] end index_scatter cost 0.00014138221740722656 seconds
DEBUG 01-15 10:09:12.555450.555450 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0438230037689209 seconds
DEBUG 01-15 10:09:12.556777.556777 cuda_h.py:19] end cpuoutputsdeal cost 0.0012140274047851562 seconds
DEBUG 01-15 10:09:12.556575.556575 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.556537.556537 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 73340440-a94b-42a3-86c6-9a68f80b81f0
INFO 01-15 10:09:12.563380.563380 client.py:127] Model loaded
DEBUG 01-15 10:09:12.563179.563179 cuda_h.py:19] end wait_experts cost 0.00711369514465332 seconds
DEBUG 01-15 10:09:12.563612.563612 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.563458.563458 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.564567.564567 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.564047.564047 cuda_h.py:19] end gpu_group_tensor cost 0.0004150867462158203 seconds
DEBUG 01-15 10:09:12.564366.564366 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.565453.565453 cuda_h.py:19] end gpu_group_einsum cost 0.0011112689971923828 seconds
DEBUG 01-15 10:09:12.566885.566885 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.566009.566009 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.566176.566176 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005667209625244141 seconds
DEBUG 01-15 10:09:12.567331.567331 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.567179.567179 cuda_h.py:19] end concat_expert_out cost 0.00012683868408203125 seconds
DEBUG 01-15 10:09:12.567753.567753 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.567608.567608 cuda_h.py:19] end index_scatter cost 0.00012183189392089844 seconds
DEBUG 01-15 10:09:12.567730.567730 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001399993896484375 seconds
DEBUG 01-15 10:09:12.567862.567862 cuda_h.py:19] end gpu_experts cost 0.004010438919067383 seconds
DEBUG 01-15 10:09:12.568590.568590 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.062478065490722656 seconds
DEBUG 01-15 10:09:12.568232.568232 cuda_h.py:19] end prefill_layer cost 0.07250237464904785 seconds
DEBUG 01-15 10:09:12.568733.568733 lmp.py:1552] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-15 10:09:12.569159.569159 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.569969.569969 lmp.py:1495] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-15 10:09:12.569018.569018 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:12.569696.569696 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:12.569423.569423 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:12.569593.569593 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.569399.569399 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.0003380775451660156 seconds
DEBUG 01-15 10:09:12.569644.569644 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.570411.570411 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.570265.570265 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.570432.570432 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.571332.571332 cuda_h.py:19] end allocate_cuda_memory cost 0.000400543212890625 seconds
DEBUG 01-15 10:09:12.571217.571217 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.571684.571684 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.571833.571833 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.571134.571134 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bfdd263-5484-4638-8fe3-37a3608fd785
DEBUG 01-15 10:09:12.571352.571352 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.572546.572546 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
INFO 01-15 10:09:12.575018.575018 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bfdd263-5484-4638-8fe3-37a3608fd785
DEBUG 01-15 10:09:12.575985.575985 cuda_h.py:19] end load_into_gpu_async cost 0.004042625427246094 seconds
DEBUG 01-15 10:09:12.575524.575524 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.575744.575744 cuda_h.py:19] end restore_tensors2 cost 0.0001399517059326172 seconds
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
DEBUG 01-15 10:09:12.575418.575418 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005792856216430664 seconds
INFO 01-15 10:09:12.576033.576033 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bfdd263-5484-4638-8fe3-37a3608fd785
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.577834.577834 cuda_h.py:19] end self_attn cost 0.0044934749603271484 seconds
DEBUG 01-15 10:09:12.577833.577833 cuda_h.py:19] end iln_self_attn_paln cost 0.007142305374145508 seconds
DEBUG 01-15 10:09:12.577167.577167 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-15 10:09:12.577128.577128 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.578907.578907 cuda_h.py:19] end gate cost 0.0006756782531738281 seconds
DEBUG 01-15 10:09:12.578267.578267 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.578583.578583 lmp.py:1616] 
DEBUG 01-15 10:09:12.578583.578583 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.578816.578816 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.578565.578565 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.578930.578930 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.578434.578434 lmp.py:1620] 
DEBUG 01-15 10:09:12.578434.578434 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.578176.578176 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.578111.578111 lmp.py:1626]   Expert 15 |     64 | CPU
DEBUG 01-15 10:09:12.578615.578615 lmp.py:1626]   Expert 41 |     70 | CPU
DEBUG 01-15 10:09:12.578403.578403 lmp.py:1626]   Expert  0 |     76 | CPU
DEBUG 01-15 10:09:12.578431.578431 lmp.py:1626]   Expert 63 |     77 | CPU
DEBUG 01-15 10:09:12.578935.578935 lmp.py:1626]   Expert 20 |     82 | CPU
DEBUG 01-15 10:09:12.578723.578723 lmp.py:1626]   Expert 45 |     88 | CPU
DEBUG 01-15 10:09:12.578512.578512 lmp.py:1626]   Expert  7 |     89 | CPU
DEBUG 01-15 10:09:12.579301.579301 lmp.py:1626]   Expert 28 |     96 | CPU
DEBUG 01-15 10:09:12.579090.579090 lmp.py:1626]   Expert 54 |    105 | CPU
DEBUG 01-15 10:09:12.579355.579355 lmp.py:1626]   Expert 12 |    109 | CPU
DEBUG 01-15 10:09:12.579905.579905 lmp.py:1626]   Expert 52 |    117 | CPU
DEBUG 01-15 10:09:12.579694.579694 lmp.py:1626]   Expert 40 |    120 | CPU
DEBUG 01-15 10:09:12.579006.579006 lmp.py:1626]   Expert  5 |    123 | CPU
DEBUG 01-15 10:09:12.579556.579556 lmp.py:1626]   Expert 59 |    124 | CPU
DEBUG 01-15 10:09:12.579822.579822 lmp.py:1626]   Expert  4 |    132 | CPU
DEBUG 01-15 10:09:12.579611.579611 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:12.579923.579923 lmp.py:1626]   Expert 61 |    133 | CPU
DEBUG 01-15 10:09:12.579473.579473 lmp.py:1626]   Expert 62 |    136 | CPU
DEBUG 01-15 10:09:12.579023.579023 lmp.py:1626]   Expert 55 |    138 | CPU
DEBUG 01-15 10:09:12.579050.579050 lmp.py:1626]   Expert 13 |    139 | CPU
DEBUG 01-15 10:09:12.579316.579316 lmp.py:1626]   Expert 21 |    140 | CPU
DEBUG 01-15 10:09:12.579628.579628 lmp.py:1626]   Expert 42 |    141 | CPU
DEBUG 01-15 10:09:12.579225.579225 lmp.py:1626]   Expert 14 |    144 | CPU
DEBUG 01-15 10:09:12.579252.579252 lmp.py:1626]   Expert 22 |    148 | CPU
DEBUG 01-15 10:09:12.579564.579564 lmp.py:1626]   Expert 10 |    150 | CPU
DEBUG 01-15 10:09:12.579591.579591 lmp.py:1626]   Expert 51 |    154 | CPU
DEBUG 01-15 10:09:12.579380.579380 lmp.py:1626]   Expert 32 |    157 | CPU
DEBUG 01-15 10:09:12.579691.579691 lmp.py:1626]   Expert 25 |    168 | CPU
DEBUG 01-15 10:09:12.579527.579527 lmp.py:1626]   Expert  1 |    174 | CPU
DEBUG 01-15 10:09:12.579600.579600 lmp.py:1626]   Expert 47 |    176 | CPU
DEBUG 01-15 10:09:12.579673.579673 lmp.py:1626]   Expert 26 |    177 | CPU
DEBUG 01-15 10:09:12.579985.579985 lmp.py:1626]   Expert 53 |    177 | CPU
DEBUG 01-15 10:09:12.579536.579536 lmp.py:1626]   Expert 19 |    178 | GPU
DEBUG 01-15 10:09:12.579324.579324 lmp.py:1626]   Expert 50 |    178 | GPU
DEBUG 01-15 10:09:12.579160.579160 lmp.py:1626]   Expert  6 |    182 | GPU
DEBUG 01-15 10:09:12.579538.579538 lmp.py:1626]   Expert 11 |    182 | GPU
DEBUG 01-15 10:09:12.579704.579704 lmp.py:1626]   Expert  2 |    183 | GPU
DEBUG 01-15 10:09:12.579201.579201 lmp.py:1626]   Expert 35 |    185 | GPU
DEBUG 01-15 10:09:12.579368.579368 lmp.py:1626]   Expert 30 |    186 | GPU
DEBUG 01-15 10:09:12.579057.579057 lmp.py:1626]   Expert 57 |    191 | GPU
DEBUG 01-15 10:09:12.579508.579508 lmp.py:1626]   Expert 56 |    192 | GPU
DEBUG 01-15 10:09:12.579482.579482 lmp.py:1626]   Expert 48 |    207 | GPU
DEBUG 01-15 10:09:12.579217.579217 lmp.py:1626]   Expert 24 |    209 | GPU
DEBUG 01-15 10:09:12.579430.579430 lmp.py:1626]   Expert 16 |    210 | GPU
DEBUG 01-15 10:09:12.579404.579404 lmp.py:1626]   Expert 44 |    210 | GPU
DEBUG 01-15 10:09:12.579140.579140 lmp.py:1626]   Expert 46 |    219 | GPU
DEBUG 01-15 10:09:12.579875.579875 lmp.py:1626]   Expert 39 |    223 | GPU
DEBUG 01-15 10:09:12.579326.579326 lmp.py:1626]   Expert 18 |    229 | GPU
DEBUG 01-15 10:09:12.579777.579777 lmp.py:1626]   Expert 29 |    232 | GPU
DEBUG 01-15 10:09:12.579989.579989 lmp.py:1626]   Expert 37 |    240 | GPU
DEBUG 01-15 10:09:12.579487.579487 lmp.py:1626]   Expert 31 |    251 | GPU
DEBUG 01-15 10:09:12.579222.579222 lmp.py:1626]   Expert 36 |    256 | GPU
DEBUG 01-15 10:09:12.579720.579720 lmp.py:1626]   Expert 60 |    258 | GPU
DEBUG 01-15 10:09:12.579694.579694 lmp.py:1626]   Expert  3 |    261 | GPU
DEBUG 01-15 10:09:12.579429.579429 lmp.py:1626]   Expert 38 |    262 | GPU
DEBUG 01-15 10:09:12.579403.579403 lmp.py:1626]   Expert  9 |    266 | GPU
DEBUG 01-15 10:09:12.579093.579093 lmp.py:1626]   Expert 17 |    267 | GPU
DEBUG 01-15 10:09:12.579020.579020 lmp.py:1626]   Expert 23 |    274 | GPU
DEBUG 01-15 10:09:12.579233.579233 lmp.py:1626]   Expert 27 |    348 | GPU
DEBUG 01-15 10:09:12.579445.579445 lmp.py:1626]   Expert 43 |    362 | GPU
DEBUG 01-15 10:09:12.579419.579419 lmp.py:1626]   Expert  8 |    399 | GPU
DEBUG 01-15 10:09:12.579632.579632 lmp.py:1626]   Expert 33 |    399 | GPU
DEBUG 01-15 10:09:12.580606.580606 lmp.py:1626]   Expert 58 |    443 | GPU
DEBUG 01-15 10:09:12.580341.580341 lmp.py:1626]   Expert 49 |    549 | GPU
DEBUG 01-15 10:09:12.580031.580031 lmp.py:1627] 
DEBUG 01-15 10:09:12.580031.580031 lmp.py:1627]   CPU total tokens: 4057 (33.0%)
DEBUG 01-15 10:09:12.580912.580912 lmp.py:1628]   GPU total tokens: 8231 (67.0%)
DEBUG 01-15 10:09:12.580800.580800 cuda_h.py:19] end experts_map_get cost 0.0016632080078125 seconds
DEBUG 01-15 10:09:12.580220.580220 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.580307.580307 lmp.py:1636] 
DEBUG 01-15 10:09:12.580307.580307 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.580150.580150 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-15 10:09:12.580846.580846 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.580265.580265 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.580966.580966 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.581325.581325 cuda_h.py:19] end allocate_cuda_memory cost 0.0013871192932128906 seconds
DEBUG 01-15 10:09:12.581440.581440 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.582773.582773 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.582708.582708 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.582034.582034 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 04d4ca5c-33d1-48f3-a40d-166c9a712868
DEBUG 01-15 10:09:12.582538.582538 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:12.582438.582438 client.py:127] Model loaded
DEBUG 01-15 10:09:12.583940.583940 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.583590.583590 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.583834.583834 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:12.584860.584860 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 04d4ca5c-33d1-48f3-a40d-166c9a712868
DEBUG 01-15 10:09:12.584615.584615 cuda_h.py:19] end load_into_gpu_async cost 0.0023910999298095703 seconds
DEBUG 01-15 10:09:12.584711.584711 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.584667.584667 cuda_h.py:19] end move_flatidxs cost 0.0008900165557861328 seconds
DEBUG 01-15 10:09:12.584703.584703 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.585129.585129 cuda_h.py:19] end restore_tensors2 cost 0.0009214878082275391 seconds
DEBUG 01-15 10:09:12.585794.585794 cuda_h.py:19] end restore2model cost 0.002668142318725586 seconds
DEBUG 01-15 10:09:12.585824.585824 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005565166473388672 seconds
DEBUG 01-15 10:09:12.586107.586107 cuda_h.py:19] end sllm_worker_task cost 0.01619696617126465 seconds
DEBUG 01-15 10:09:12.586363.586363 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.590463.590463 cuda_h.py:19] end group_tensors cost 0.005463838577270508 seconds
DEBUG 01-15 10:09:12.590553.590553 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.593426.593426 cuda_h.py:19] end restore2model cost 0.0069959163665771484 seconds
DEBUG 01-15 10:09:12.593887.593887 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.01327061653137207 seconds
DEBUG 01-15 10:09:12.593313.593313 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.594792.594792 cuda_h.py:19] end gpu_sexperts cost 0.0007643699645996094 seconds
DEBUG 01-15 10:09:12.594564.594564 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.594701.594701 cuda_h.py:19] end group pad cost 0.003981113433837891 seconds
DEBUG 01-15 10:09:12.594829.594829 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.598395.598395 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.003964900970458984 seconds
DEBUG 01-15 10:09:12.599053.599053 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.600748.600748 cuda_h.py:19] end gpu_group_list cost 0.00035119056701660156 seconds
DEBUG 01-15 10:09:12.600688.600688 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.601929.601929 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008337497711181641 seconds
DEBUG 01-15 10:09:12.601759.601759 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.601164.601164 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-15 10:09:12.601344.601344 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.616486.616486 cuda_h.py:19] end group_einsum cost 0.02170085906982422 seconds
DEBUG 01-15 10:09:12.616405.616405 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.622705.622705 cuda_h.py:19] end get_outputs_cpu1 cost 0.005311727523803711 seconds
DEBUG 01-15 10:09:12.623961.623961 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03985714912414551 seconds
DEBUG 01-15 10:09:12.624755.624755 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.023246049880981445 seconds
DEBUG 01-15 10:09:12.624047.624047 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.625824.625824 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.625496.625496 cuda_h.py:19] end index_scatter cost 0.00015926361083984375 seconds
DEBUG 01-15 10:09:12.626890.626890 cuda_h.py:19] end cpuoutputsdeal cost 0.0015330314636230469 seconds
DEBUG 01-15 10:09:12.626192.626192 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.626128.626128 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 04d4ca5c-33d1-48f3-a40d-166c9a712868
INFO 01-15 10:09:12.635789.635789 client.py:127] Model loaded
DEBUG 01-15 10:09:12.635262.635262 cuda_h.py:19] end wait_experts cost 0.009102821350097656 seconds
DEBUG 01-15 10:09:12.635682.635682 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.636966.636966 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.636042.636042 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.636107.636107 cuda_h.py:19] end gpu_group_tensor cost 0.00045609474182128906 seconds
DEBUG 01-15 10:09:12.636529.636529 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.637244.637244 cuda_h.py:19] end gpu_group_einsum cost 0.0007147789001464844 seconds
DEBUG 01-15 10:09:12.637587.637587 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.637550.637550 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.638477.638477 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003714561462402344 seconds
DEBUG 01-15 10:09:12.638326.638326 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.638501.638501 cuda_h.py:19] end concat_expert_out cost 6.008148193359375e-05 seconds
DEBUG 01-15 10:09:12.638457.638457 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.638236.638236 cuda_h.py:19] end index_scatter cost 8.606910705566406e-05 seconds
DEBUG 01-15 10:09:12.638999.638999 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007734298706054688 seconds
DEBUG 01-15 10:09:12.638432.638432 cuda_h.py:19] end gpu_experts cost 0.002729654312133789 seconds
DEBUG 01-15 10:09:12.638170.638170 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06116604804992676 seconds
DEBUG 01-15 10:09:12.639147.639147 cuda_h.py:19] end prefill_layer cost 0.07018470764160156 seconds
DEBUG 01-15 10:09:12.639467.639467 lmp.py:1552] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-15 10:09:12.639786.639786 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.639820.639820 lmp.py:1495] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-15 10:09:12.639138.639138 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:12.639464.639464 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:12.639466.639466 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 4.5299530029296875e-05 seconds
DEBUG 01-15 10:09:12.639931.639931 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.43865966796875e-05 seconds
DEBUG 01-15 10:09:12.639004.639004 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.639034.639034 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.639694.639694 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.640821.640821 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.640575.640575 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.640414.640414 cuda_h.py:19] end allocate_cuda_memory cost 0.0004088878631591797 seconds
DEBUG 01-15 10:09:12.640301.640301 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.641311.641311 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.641951.641951 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.641769.641769 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a6ed8f1a-3b5b-4c49-9c56-17eb7529d577
DEBUG 01-15 10:09:12.641969.641969 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.641018.641018 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.642405.642405 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a6ed8f1a-3b5b-4c49-9c56-17eb7529d577
DEBUG 01-15 10:09:12.643425.643425 cuda_h.py:19] end load_into_gpu_async cost 0.0020089149475097656 seconds
DEBUG 01-15 10:09:12.643747.643747 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.643185.643185 cuda_h.py:19] end restore_tensors2 cost 0.0001373291015625 seconds
DEBUG 01-15 10:09:12.643334.643334 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003348112106323242 seconds
INFO 01-15 10:09:12.643135.643135 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a6ed8f1a-3b5b-4c49-9c56-17eb7529d577
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.646219.646219 cuda_h.py:19] end self_attn cost 0.004912853240966797 seconds
DEBUG 01-15 10:09:12.647630.647630 cuda_h.py:19] end iln_self_attn_paln cost 0.0075914859771728516 seconds
DEBUG 01-15 10:09:12.647924.647924 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-15 10:09:12.647840.647840 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.648788.648788 cuda_h.py:19] end gate cost 0.0007982254028320312 seconds
DEBUG 01-15 10:09:12.648678.648678 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.648854.648854 lmp.py:1616] 
DEBUG 01-15 10:09:12.648854.648854 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.648047.648047 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.648042.648042 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.648599.648599 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.648295.648295 lmp.py:1620] 
DEBUG 01-15 10:09:12.648295.648295 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.648898.648898 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.648455.648455 lmp.py:1626]   Expert 58 |     35 | CPU
DEBUG 01-15 10:09:12.648390.648390 lmp.py:1626]   Expert 31 |     60 | CPU
DEBUG 01-15 10:09:12.648086.648086 lmp.py:1626]   Expert 49 |     60 | CPU
DEBUG 01-15 10:09:12.648782.648782 lmp.py:1626]   Expert 47 |     62 | CPU
DEBUG 01-15 10:09:12.648909.648909 lmp.py:1626]   Expert  4 |     66 | CPU
DEBUG 01-15 10:09:12.649889.649889 lmp.py:1626]   Expert 38 |     69 | CPU
DEBUG 01-15 10:09:12.649109.649109 lmp.py:1626]   Expert 45 |     71 | CPU
DEBUG 01-15 10:09:12.649566.649566 lmp.py:1626]   Expert 41 |     83 | CPU
DEBUG 01-15 10:09:12.649786.649786 lmp.py:1626]   Expert 43 |     83 | CPU
DEBUG 01-15 10:09:12.649243.649243 lmp.py:1626]   Expert 33 |     95 | CPU
DEBUG 01-15 10:09:12.649939.649939 lmp.py:1626]   Expert 57 |    101 | CPU
DEBUG 01-15 10:09:12.649112.649112 lmp.py:1626]   Expert 11 |    105 | CPU
DEBUG 01-15 10:09:12.649855.649855 lmp.py:1626]   Expert 50 |    107 | CPU
DEBUG 01-15 10:09:12.649074.649074 lmp.py:1626]   Expert  2 |    112 | CPU
DEBUG 01-15 10:09:12.649055.649055 lmp.py:1626]   Expert 51 |    115 | CPU
DEBUG 01-15 10:09:12.649559.649559 lmp.py:1626]   Expert 14 |    122 | CPU
DEBUG 01-15 10:09:12.649540.649540 lmp.py:1626]   Expert  0 |    123 | CPU
DEBUG 01-15 10:09:12.649759.649759 lmp.py:1626]   Expert 54 |    125 | CPU
DEBUG 01-15 10:09:12.649978.649978 lmp.py:1626]   Expert 56 |    139 | CPU
DEBUG 01-15 10:09:12.649959.649959 lmp.py:1626]   Expert 34 |    142 | CPU
DEBUG 01-15 10:09:12.649225.649225 lmp.py:1626]   Expert 26 |    144 | CPU
DEBUG 01-15 10:09:12.649490.649490 lmp.py:1626]   Expert 27 |    154 | CPU
DEBUG 01-15 10:09:12.649233.649233 lmp.py:1626]   Expert 28 |    157 | CPU
DEBUG 01-15 10:09:12.649213.649213 lmp.py:1626]   Expert 55 |    159 | CPU
DEBUG 01-15 10:09:12.649956.649956 lmp.py:1626]   Expert 10 |    163 | CPU
DEBUG 01-15 10:09:12.649175.649175 lmp.py:1626]   Expert 25 |    163 | CPU
DEBUG 01-15 10:09:12.649586.649586 lmp.py:1626]   Expert  9 |    176 | CPU
DEBUG 01-15 10:09:12.649090.649090 lmp.py:1626]   Expert 13 |    179 | CPU
DEBUG 01-15 10:09:12.649786.649786 lmp.py:1626]   Expert 61 |    189 | CPU
DEBUG 01-15 10:09:12.649052.649052 lmp.py:1626]   Expert  6 |    192 | CPU
DEBUG 01-15 10:09:12.649033.649033 lmp.py:1626]   Expert  7 |    193 | CPU
DEBUG 01-15 10:09:12.649444.649444 lmp.py:1626]   Expert 48 |    193 | CPU
DEBUG 01-15 10:09:12.649425.649425 lmp.py:1626]   Expert 46 |    196 | GPU
DEBUG 01-15 10:09:12.649221.649221 lmp.py:1626]   Expert 24 |    201 | GPU
DEBUG 01-15 10:09:12.649930.649930 lmp.py:1626]   Expert 18 |    204 | GPU
DEBUG 01-15 10:09:12.649196.649196 lmp.py:1626]   Expert 42 |    204 | GPU
DEBUG 01-15 10:09:12.649461.649461 lmp.py:1626]   Expert 40 |    209 | GPU
DEBUG 01-15 10:09:12.649250.649250 lmp.py:1626]   Expert 63 |    214 | GPU
DEBUG 01-15 10:09:12.649800.649800 lmp.py:1626]   Expert 12 |    215 | GPU
DEBUG 01-15 10:09:12.649351.649351 lmp.py:1626]   Expert 29 |    216 | GPU
DEBUG 01-15 10:09:12.649140.649140 lmp.py:1626]   Expert 21 |    218 | GPU
DEBUG 01-15 10:09:12.649405.649405 lmp.py:1626]   Expert 59 |    219 | GPU
DEBUG 01-15 10:09:12.649955.649955 lmp.py:1626]   Expert 22 |    220 | GPU
DEBUG 01-15 10:09:12.649983.649983 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:12.649202.649202 lmp.py:1626]   Expert 19 |    229 | GPU
DEBUG 01-15 10:09:12.649467.649467 lmp.py:1626]   Expert 36 |    237 | GPU
DEBUG 01-15 10:09:12.649733.649733 lmp.py:1626]   Expert  3 |    239 | GPU
DEBUG 01-15 10:09:12.649999.649999 lmp.py:1626]   Expert  1 |    246 | GPU
DEBUG 01-15 10:09:12.649549.649549 lmp.py:1626]   Expert 37 |    246 | GPU
DEBUG 01-15 10:09:12.649576.649576 lmp.py:1626]   Expert 16 |    248 | GPU
DEBUG 01-15 10:09:12.649365.649365 lmp.py:1626]   Expert 20 |    258 | GPU
DEBUG 01-15 10:09:12.649869.649869 lmp.py:1626]   Expert  5 |    265 | GPU
DEBUG 01-15 10:09:12.649088.649088 lmp.py:1626]   Expert  8 |    268 | GPU
DEBUG 01-15 10:09:12.650115.650115 lmp.py:1626]   Expert 30 |    270 | GPU
DEBUG 01-15 10:09:12.650381.650381 lmp.py:1626]   Expert 15 |    275 | GPU
DEBUG 01-15 10:09:12.650170.650170 lmp.py:1626]   Expert 62 |    275 | GPU
DEBUG 01-15 10:09:12.650720.650720 lmp.py:1626]   Expert 39 |    298 | GPU
DEBUG 01-15 10:09:12.650270.650270 lmp.py:1626]   Expert 35 |    299 | GPU
DEBUG 01-15 10:09:12.650297.650297 lmp.py:1626]   Expert 17 |    308 | GPU
DEBUG 01-15 10:09:12.650563.650563 lmp.py:1626]   Expert 60 |    315 | GPU
DEBUG 01-15 10:09:12.650305.650305 lmp.py:1626]   Expert 52 |    351 | GPU
DEBUG 01-15 10:09:12.650598.650598 lmp.py:1626]   Expert 23 |    368 | GPU
DEBUG 01-15 10:09:12.650718.650718 lmp.py:1626]   Expert 44 |    379 | GPU
DEBUG 01-15 10:09:12.650930.650930 lmp.py:1626]   Expert 53 |    436 | GPU
DEBUG 01-15 10:09:12.650150.650150 lmp.py:1627] 
DEBUG 01-15 10:09:12.650150.650150 lmp.py:1627]   CPU total tokens: 3937 (32.0%)
DEBUG 01-15 10:09:12.650846.650846 lmp.py:1628]   GPU total tokens: 8351 (68.0%)
DEBUG 01-15 10:09:12.650549.650549 cuda_h.py:19] end experts_map_get cost 0.002050638198852539 seconds
INFO 01-15 10:09:12.650878.650878 client.py:127] Model loaded
DEBUG 01-15 10:09:12.650803.650803 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.650549.650549 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.650095.650095 lmp.py:1636] 
DEBUG 01-15 10:09:12.650095.650095 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.651952.651952 cuda_h.py:19] end cpu_experts_submit cost 0.0004627704620361328 seconds
DEBUG 01-15 10:09:12.651469.651469 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.651909.651909 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.651002.651002 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.651684.651684 cuda_h.py:19] end allocate_cuda_memory cost 0.00035500526428222656 seconds
DEBUG 01-15 10:09:12.652932.652932 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.652079.652079 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.652630.652630 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.652340.652340 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e35ba550-7747-43ba-aa88-de63286fda1b
DEBUG 01-15 10:09:12.652481.652481 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.653293.653293 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.654339.654339 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.654259.654259 cuda_h.py:19] end restore2model cost 0.003167390823364258 seconds
DEBUG 01-15 10:09:12.654855.654855 cuda_h.py:19] end sllm_worker_task cost 0.014287710189819336 seconds
INFO 01-15 10:09:12.654034.654034 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e35ba550-7747-43ba-aa88-de63286fda1b
DEBUG 01-15 10:09:12.654799.654799 cuda_h.py:19] end load_into_gpu_async cost 0.0025284290313720703 seconds
DEBUG 01-15 10:09:12.654893.654893 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.655984.655984 cuda_h.py:19] end restore_tensors2 cost 0.0004932880401611328 seconds
DEBUG 01-15 10:09:12.655389.655389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003836393356323242 seconds
DEBUG 01-15 10:09:12.655557.655557 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.655969.655969 cuda_h.py:19] end move_flatidxs cost 0.0011017322540283203 seconds
DEBUG 01-15 10:09:12.655139.655139 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.658161.658161 cuda_h.py:19] end restore2model cost 0.0033538341522216797 seconds
DEBUG 01-15 10:09:12.658123.658123 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007441520690917969 seconds
DEBUG 01-15 10:09:12.658873.658873 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.659056.659056 cuda_h.py:19] end gpu_sexperts cost 0.0003142356872558594 seconds
DEBUG 01-15 10:09:12.659985.659985 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.661193.661193 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002005338668823242 seconds
DEBUG 01-15 10:09:12.662870.662870 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.662558.662558 cuda_h.py:19] end gpu_group_list cost 0.0003161430358886719 seconds
DEBUG 01-15 10:09:12.662741.662741 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.663583.663583 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009615421295166016 seconds
DEBUG 01-15 10:09:12.663981.663981 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.663632.663632 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-15 10:09:12.663997.663997 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.670022.670022 cuda_h.py:19] end group_tensors cost 0.014607429504394531 seconds
DEBUG 01-15 10:09:12.671912.671912 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.675410.675410 cuda_h.py:19] end group pad cost 0.004340648651123047 seconds
DEBUG 01-15 10:09:12.675823.675823 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.699683.699683 cuda_h.py:19] end group_einsum cost 0.023614168167114258 seconds
DEBUG 01-15 10:09:12.699238.699238 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.709449.709449 cuda_h.py:19] end get_outputs_cpu1 cost 0.010156869888305664 seconds
DEBUG 01-15 10:09:12.711857.711857 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05762815475463867 seconds
DEBUG 01-15 10:09:12.712912.712912 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04837846755981445 seconds
DEBUG 01-15 10:09:12.712668.712668 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.713022.713022 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.713197.713197 cuda_h.py:19] end index_scatter cost 0.00016498565673828125 seconds
DEBUG 01-15 10:09:12.713267.713267 cuda_h.py:19] end cpuoutputsdeal cost 0.0011813640594482422 seconds
DEBUG 01-15 10:09:12.714178.714178 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.714254.714254 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e35ba550-7747-43ba-aa88-de63286fda1b
INFO 01-15 10:09:12.715374.715374 client.py:127] Model loaded
DEBUG 01-15 10:09:12.715842.715842 cuda_h.py:19] end wait_experts cost 0.0013532638549804688 seconds
DEBUG 01-15 10:09:12.715937.715937 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.715544.715544 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.715077.715077 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.716642.716642 cuda_h.py:19] end gpu_group_tensor cost 0.0003714561462402344 seconds
DEBUG 01-15 10:09:12.716008.716008 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.717203.717203 cuda_h.py:19] end gpu_group_einsum cost 0.0011487007141113281 seconds
DEBUG 01-15 10:09:12.717774.717774 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.718990.718990 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.718190.718190 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005586147308349609 seconds
DEBUG 01-15 10:09:12.718438.718438 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.718809.718809 cuda_h.py:19] end concat_expert_out cost 0.00013446807861328125 seconds
DEBUG 01-15 10:09:12.719799.719799 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.719572.719572 cuda_h.py:19] end index_scatter cost 8.368492126464844e-05 seconds
DEBUG 01-15 10:09:12.719084.719084 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0012574195861816406 seconds
DEBUG 01-15 10:09:12.719671.719671 cuda_h.py:19] end gpu_experts cost 0.0038471221923828125 seconds
DEBUG 01-15 10:09:12.719947.719947 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.0722358226776123 seconds
DEBUG 01-15 10:09:12.720484.720484 cuda_h.py:19] end prefill_layer cost 0.08074593544006348 seconds
DEBUG 01-15 10:09:12.720573.720573 lmp.py:1552] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-15 10:09:12.720065.720065 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.720795.720795 lmp.py:1495] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-15 10:09:12.720262.720262 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:12.720005.720005 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:12.720632.720632 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.7697296142578125e-05 seconds
DEBUG 01-15 10:09:12.720753.720753 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.00011777877807617188 seconds
DEBUG 01-15 10:09:12.720238.720238 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.720691.720691 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.720609.720609 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.720234.720234 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.721919.721919 cuda_h.py:19] end allocate_cuda_memory cost 0.00024819374084472656 seconds
DEBUG 01-15 10:09:12.721213.721213 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.721698.721698 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.721733.721733 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.721065.721065 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1708741e-40f3-4359-8a03-e3709fe288e3
DEBUG 01-15 10:09:12.721354.721354 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.721969.721969 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:12.722819.722819 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1708741e-40f3-4359-8a03-e3709fe288e3
DEBUG 01-15 10:09:12.722769.722769 cuda_h.py:19] end load_into_gpu_async cost 0.0009298324584960938 seconds
DEBUG 01-15 10:09:12.722147.722147 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.722410.722410 cuda_h.py:19] end restore_tensors2 cost 8.916854858398438e-05 seconds
DEBUG 01-15 10:09:12.722272.722272 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015709400177001953 seconds
INFO 01-15 10:09:12.722075.722075 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1708741e-40f3-4359-8a03-e3709fe288e3
DEBUG 01-15 10:09:12.722178.722178 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.728254.728254 cuda_h.py:19] end self_attn cost 0.005320072174072266 seconds
DEBUG 01-15 10:09:12.728390.728390 cuda_h.py:19] end iln_self_attn_paln cost 0.008065938949584961 seconds
DEBUG 01-15 10:09:12.728307.728307 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-15 10:09:12.728990.728990 cuda_h.py:10] start gate
INFO 01-15 10:09:12.729072.729072 client.py:127] Model loaded
DEBUG 01-15 10:09:12.729313.729313 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.730993.730993 cuda_h.py:19] end restore2model cost 0.0006473064422607422 seconds
DEBUG 01-15 10:09:12.730340.730340 cuda_h.py:19] end sllm_worker_task cost 0.009190559387207031 seconds
DEBUG 01-15 10:09:12.730732.730732 cuda_h.py:19] end gate cost 0.0013496875762939453 seconds
DEBUG 01-15 10:09:12.730814.730814 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.730520.730520 lmp.py:1616] 
DEBUG 01-15 10:09:12.730520.730520 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.730752.730752 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.730117.730117 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.730860.730860 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.730264.730264 lmp.py:1620] 
DEBUG 01-15 10:09:12.730264.730264 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.730146.730146 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.730703.730703 lmp.py:1626]   Expert  4 |     10 | CPU
DEBUG 01-15 10:09:12.730492.730492 lmp.py:1626]   Expert 28 |     28 | CPU
DEBUG 01-15 10:09:12.730942.730942 lmp.py:1626]   Expert  7 |     45 | CPU
DEBUG 01-15 10:09:12.730870.730870 lmp.py:1626]   Expert 53 |     56 | CPU
DEBUG 01-15 10:09:12.730275.730275 lmp.py:1626]   Expert 52 |     68 | CPU
DEBUG 01-15 10:09:12.730964.730964 lmp.py:1626]   Expert 43 |     71 | CPU
DEBUG 01-15 10:09:12.730415.730415 lmp.py:1626]   Expert 49 |     83 | CPU
DEBUG 01-15 10:09:12.730627.730627 lmp.py:1626]   Expert 12 |     89 | CPU
DEBUG 01-15 10:09:12.730840.730840 lmp.py:1626]   Expert 47 |    100 | CPU
DEBUG 01-15 10:09:12.731291.731291 lmp.py:1626]   Expert 33 |    105 | CPU
DEBUG 01-15 10:09:12.731265.731265 lmp.py:1626]   Expert 24 |    106 | CPU
DEBUG 01-15 10:09:12.731716.731716 lmp.py:1626]   Expert  2 |    113 | CPU
DEBUG 01-15 10:09:12.731167.731167 lmp.py:1626]   Expert 15 |    113 | CPU
DEBUG 01-15 10:09:12.731617.731617 lmp.py:1626]   Expert 50 |    113 | CPU
DEBUG 01-15 10:09:12.731830.731830 lmp.py:1626]   Expert 39 |    114 | CPU
DEBUG 01-15 10:09:12.731042.731042 lmp.py:1626]   Expert 60 |    114 | CPU
DEBUG 01-15 10:09:12.731732.731732 lmp.py:1626]   Expert 36 |    119 | CPU
DEBUG 01-15 10:09:12.731706.731706 lmp.py:1626]   Expert 25 |    122 | CPU
DEBUG 01-15 10:09:12.731157.731157 lmp.py:1626]   Expert  6 |    126 | CPU
DEBUG 01-15 10:09:12.731369.731369 lmp.py:1626]   Expert 61 |    134 | CPU
DEBUG 01-15 10:09:12.731343.731343 lmp.py:1626]   Expert 59 |    137 | CPU
DEBUG 01-15 10:09:12.731556.731556 lmp.py:1626]   Expert  3 |    142 | CPU
DEBUG 01-15 10:09:12.731722.731722 lmp.py:1626]   Expert 27 |    143 | CPU
DEBUG 01-15 10:09:12.731173.731173 lmp.py:1626]   Expert 58 |    147 | CPU
DEBUG 01-15 10:09:12.731385.731385 lmp.py:1626]   Expert  8 |    150 | CPU
DEBUG 01-15 10:09:12.731359.731359 lmp.py:1626]   Expert 30 |    150 | CPU
DEBUG 01-15 10:09:12.731572.731572 lmp.py:1626]   Expert 31 |    152 | CPU
DEBUG 01-15 10:09:12.731307.731307 lmp.py:1626]   Expert 10 |    157 | CPU
DEBUG 01-15 10:09:12.731281.731281 lmp.py:1626]   Expert 38 |    159 | CPU
DEBUG 01-15 10:09:12.731686.731686 lmp.py:1626]   Expert 40 |    159 | CPU
DEBUG 01-15 10:09:12.731898.731898 lmp.py:1626]   Expert 57 |    159 | CPU
DEBUG 01-15 10:09:12.731634.731634 lmp.py:1626]   Expert 41 |    162 | CPU
DEBUG 01-15 10:09:12.731608.731608 lmp.py:1626]   Expert 14 |    163 | GPU
DEBUG 01-15 10:09:12.731582.731582 lmp.py:1626]   Expert 37 |    163 | GPU
DEBUG 01-15 10:09:12.731318.731318 lmp.py:1626]   Expert 54 |    163 | GPU
DEBUG 01-15 10:09:12.731292.731292 lmp.py:1626]   Expert 32 |    165 | GPU
DEBUG 01-15 10:09:12.731743.731743 lmp.py:1626]   Expert 46 |    168 | GPU
DEBUG 01-15 10:09:12.731955.731955 lmp.py:1626]   Expert 42 |    173 | GPU
DEBUG 01-15 10:09:12.731452.731452 lmp.py:1626]   Expert 19 |    174 | GPU
DEBUG 01-15 10:09:12.731188.731188 lmp.py:1626]   Expert 11 |    178 | GPU
DEBUG 01-15 10:09:12.731923.731923 lmp.py:1626]   Expert 34 |    192 | GPU
DEBUG 01-15 10:09:12.731659.731659 lmp.py:1626]   Expert 18 |    193 | GPU
DEBUG 01-15 10:09:12.731395.731395 lmp.py:1626]   Expert 22 |    193 | GPU
DEBUG 01-15 10:09:12.731607.731607 lmp.py:1626]   Expert  0 |    195 | GPU
DEBUG 01-15 10:09:12.731343.731343 lmp.py:1626]   Expert 26 |    197 | GPU
DEBUG 01-15 10:09:12.731078.731078 lmp.py:1626]   Expert 56 |    198 | GPU
DEBUG 01-15 10:09:12.731291.731291 lmp.py:1626]   Expert 44 |    203 | GPU
DEBUG 01-15 10:09:12.731742.731742 lmp.py:1626]   Expert  1 |    205 | GPU
DEBUG 01-15 10:09:12.731954.731954 lmp.py:1626]   Expert 51 |    211 | GPU
DEBUG 01-15 10:09:12.731928.731928 lmp.py:1626]   Expert 20 |    226 | GPU
DEBUG 01-15 10:09:12.731664.731664 lmp.py:1626]   Expert 29 |    229 | GPU
DEBUG 01-15 10:09:12.731638.731638 lmp.py:1626]   Expert 48 |    236 | GPU
DEBUG 01-15 10:09:12.731612.731612 lmp.py:1626]   Expert 21 |    239 | GPU
DEBUG 01-15 10:09:12.731348.731348 lmp.py:1626]   Expert 45 |    240 | GPU
DEBUG 01-15 10:09:12.731083.731083 lmp.py:1626]   Expert 35 |    253 | GPU
DEBUG 01-15 10:09:12.731057.731057 lmp.py:1626]   Expert 55 |    253 | GPU
DEBUG 01-15 10:09:12.731270.731270 lmp.py:1626]   Expert 16 |    254 | GPU
DEBUG 01-15 10:09:12.731005.731005 lmp.py:1626]   Expert  5 |    295 | GPU
DEBUG 01-15 10:09:12.731887.731887 lmp.py:1626]   Expert 23 |    372 | GPU
DEBUG 01-15 10:09:12.731099.731099 lmp.py:1626]   Expert 13 |    383 | GPU
DEBUG 01-15 10:09:12.731550.731550 lmp.py:1626]   Expert 17 |    437 | GPU
DEBUG 01-15 10:09:12.731524.731524 lmp.py:1626]   Expert  9 |    457 | GPU
DEBUG 01-15 10:09:12.731975.731975 lmp.py:1626]   Expert 63 |    459 | GPU
DEBUG 01-15 10:09:12.731187.731187 lmp.py:1626]   Expert 62 |   1175 | GPU
DEBUG 01-15 10:09:12.731354.731354 lmp.py:1627] 
DEBUG 01-15 10:09:12.731354.731354 lmp.py:1627]   CPU total tokens: 3646 (29.7%)
DEBUG 01-15 10:09:12.731527.731527 lmp.py:1628]   GPU total tokens: 8642 (70.3%)
DEBUG 01-15 10:09:12.731329.731329 cuda_h.py:19] end experts_map_get cost 0.0015103816986083984 seconds
DEBUG 01-15 10:09:12.732371.732371 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.732696.732696 lmp.py:1636] 
DEBUG 01-15 10:09:12.732696.732696 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.732440.732440 cuda_h.py:19] end cpu_experts_submit cost 5.555152893066406e-05 seconds
DEBUG 01-15 10:09:12.732182.732182 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.732449.732449 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.732793.732793 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.732596.732596 cuda_h.py:19] end allocate_cuda_memory cost 0.00019168853759765625 seconds
DEBUG 01-15 10:09:12.732962.732962 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.732433.732433 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.732534.732534 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.732568.732568 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01fe4ed9-b4d7-4223-8633-ba57c7ac54ef
DEBUG 01-15 10:09:12.732356.732356 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:12.733074.733074 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01fe4ed9-b4d7-4223-8633-ba57c7ac54ef
DEBUG 01-15 10:09:12.733586.733586 cuda_h.py:19] end load_into_gpu_async cost 0.0011980533599853516 seconds
DEBUG 01-15 10:09:12.733435.733435 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.734021.734021 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.734701.734701 cuda_h.py:19] end restore_tensors2 cost 0.00041413307189941406 seconds
DEBUG 01-15 10:09:12.734683.734683 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002218008041381836 seconds
DEBUG 01-15 10:09:12.734566.734566 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.734579.734579 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.736221.736221 cuda_h.py:19] end move_flatidxs cost 0.0010890960693359375 seconds
DEBUG 01-15 10:09:12.736064.736064 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.737809.737809 cuda_h.py:19] end restore2model cost 0.002675771713256836 seconds
DEBUG 01-15 10:09:12.737189.737189 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00510859489440918 seconds
DEBUG 01-15 10:09:12.737223.737223 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.737995.737995 cuda_h.py:19] end gpu_sexperts cost 0.0002918243408203125 seconds
DEBUG 01-15 10:09:12.737209.737209 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.739923.739923 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015075206756591797 seconds
DEBUG 01-15 10:09:12.739644.739644 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.740153.740153 cuda_h.py:19] end gpu_group_list cost 0.00032520294189453125 seconds
DEBUG 01-15 10:09:12.740038.740038 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.741818.741818 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007069110870361328 seconds
DEBUG 01-15 10:09:12.741356.741356 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.741848.741848 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-15 10:09:12.741259.741259 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.746232.746232 cuda_h.py:19] end group_tensors cost 0.010715961456298828 seconds
DEBUG 01-15 10:09:12.747912.747912 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.755319.755319 cuda_h.py:19] end group pad cost 0.007707357406616211 seconds
DEBUG 01-15 10:09:12.755638.755638 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.777926.777926 cuda_h.py:19] end group_einsum cost 0.02213740348815918 seconds
DEBUG 01-15 10:09:12.778865.778865 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.782227.782227 cuda_h.py:19] end get_outputs_cpu1 cost 0.004617214202880859 seconds
DEBUG 01-15 10:09:12.783534.783534 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.049460649490356445 seconds
DEBUG 01-15 10:09:12.784098.784098 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04316401481628418 seconds
DEBUG 01-15 10:09:12.784092.784092 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.785531.785531 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.785580.785580 cuda_h.py:19] end index_scatter cost 0.0001609325408935547 seconds
DEBUG 01-15 10:09:12.786657.786657 cuda_h.py:19] end cpuoutputsdeal cost 0.0011546611785888672 seconds
DEBUG 01-15 10:09:12.786568.786568 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.786876.786876 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01fe4ed9-b4d7-4223-8633-ba57c7ac54ef
INFO 01-15 10:09:12.787484.787484 client.py:127] Model loaded
DEBUG 01-15 10:09:12.787760.787760 cuda_h.py:19] end wait_experts cost 0.0012898445129394531 seconds
DEBUG 01-15 10:09:12.787331.787331 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.787866.787866 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.787929.787929 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.788162.788162 cuda_h.py:19] end gpu_group_tensor cost 0.0003745555877685547 seconds
DEBUG 01-15 10:09:12.788476.788476 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.790820.790820 cuda_h.py:19] end gpu_group_einsum cost 0.002246856689453125 seconds
DEBUG 01-15 10:09:12.791569.791569 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.791302.791302 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.791076.791076 cuda_h.py:19] end all_expert_outputs_slices cost 0.0004949569702148438 seconds
DEBUG 01-15 10:09:12.791125.791125 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.792608.792608 cuda_h.py:19] end concat_expert_out cost 0.00011229515075683594 seconds
DEBUG 01-15 10:09:12.792923.792923 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.792757.792757 cuda_h.py:19] end index_scatter cost 0.000102996826171875 seconds
DEBUG 01-15 10:09:12.792058.792058 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0012493133544921875 seconds
DEBUG 01-15 10:09:12.792255.792255 cuda_h.py:19] end gpu_experts cost 0.0049512386322021484 seconds
DEBUG 01-15 10:09:12.792241.792241 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.06383991241455078 seconds
DEBUG 01-15 10:09:12.793077.793077 cuda_h.py:19] end prefill_layer cost 0.07309174537658691 seconds
DEBUG 01-15 10:09:12.793763.793763 lmp.py:1552] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-15 10:09:12.793129.793129 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.793211.793211 lmp.py:1495] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-15 10:09:12.793246.793246 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:12.793480.793480 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:12.793756.793756 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.389617919921875e-05 seconds
DEBUG 01-15 10:09:12.794182.794182 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.0001430511474609375 seconds
DEBUG 01-15 10:09:12.794780.794780 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.794461.794461 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.794532.794532 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.794916.794916 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.794390.794390 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.795426.795426 cuda_h.py:19] end allocate_cuda_memory cost 0.0003848075866699219 seconds
DEBUG 01-15 10:09:12.795114.795114 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.795474.795474 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.795253.795253 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.795070.795070 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3121acf9-a295-4d88-8bad-e428526c650a
DEBUG 01-15 10:09:12.795249.795249 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.796071.796071 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.796886.796886 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3121acf9-a295-4d88-8bad-e428526c650a
DEBUG 01-15 10:09:12.796216.796216 cuda_h.py:19] end load_into_gpu_async cost 0.0015597343444824219 seconds
DEBUG 01-15 10:09:12.797125.797125 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.797915.797915 cuda_h.py:19] end restore_tensors2 cost 0.00015544891357421875 seconds
DEBUG 01-15 10:09:12.797514.797514 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027370452880859375 seconds
INFO 01-15 10:09:12.797883.797883 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3121acf9-a295-4d88-8bad-e428526c650a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.802985.802985 cuda_h.py:19] end self_attn cost 0.005609989166259766 seconds
DEBUG 01-15 10:09:12.802693.802693 cuda_h.py:19] end iln_self_attn_paln cost 0.00840616226196289 seconds
DEBUG 01-15 10:09:12.802225.802225 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-15 10:09:12.802339.802339 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.803273.803273 cuda_h.py:19] end gate cost 0.0007474422454833984 seconds
DEBUG 01-15 10:09:12.803931.803931 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.803018.803018 lmp.py:1616] 
DEBUG 01-15 10:09:12.803018.803018 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.803317.803317 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.804126.804126 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.804690.804690 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.804393.804393 lmp.py:1620] 
DEBUG 01-15 10:09:12.804393.804393 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.804334.804334 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.804468.804468 lmp.py:1626]   Expert 32 |     34 | CPU
DEBUG 01-15 10:09:12.804409.804409 lmp.py:1626]   Expert  5 |     50 | CPU
DEBUG 01-15 10:09:12.804589.804589 lmp.py:1626]   Expert 30 |     51 | CPU
DEBUG 01-15 10:09:12.804815.804815 lmp.py:1626]   Expert 46 |     74 | CPU
DEBUG 01-15 10:09:12.804803.804803 lmp.py:1626]   Expert  8 |     89 | CPU
DEBUG 01-15 10:09:12.804075.804075 lmp.py:1626]   Expert 40 |     91 | CPU
DEBUG 01-15 10:09:12.804063.804063 lmp.py:1626]   Expert 12 |    100 | CPU
DEBUG 01-15 10:09:12.804765.804765 lmp.py:1626]   Expert 17 |    106 | CPU
DEBUG 01-15 10:09:12.804753.804753 lmp.py:1626]   Expert 27 |    108 | CPU
DEBUG 01-15 10:09:12.804025.804025 lmp.py:1626]   Expert 60 |    113 | CPU
DEBUG 01-15 10:09:12.804742.804742 lmp.py:1626]   Expert  3 |    115 | CPU
DEBUG 01-15 10:09:12.804491.804491 lmp.py:1626]   Expert 58 |    116 | CPU
DEBUG 01-15 10:09:12.804585.804585 lmp.py:1626]   Expert 21 |    120 | CPU
DEBUG 01-15 10:09:12.804049.804049 lmp.py:1626]   Expert 28 |    120 | CPU
DEBUG 01-15 10:09:12.804560.804560 lmp.py:1626]   Expert 29 |    121 | CPU
DEBUG 01-15 10:09:12.804594.804594 lmp.py:1626]   Expert 25 |    126 | CPU
DEBUG 01-15 10:09:12.804628.804628 lmp.py:1626]   Expert 41 |    130 | CPU
DEBUG 01-15 10:09:12.804900.804900 lmp.py:1626]   Expert 35 |    133 | CPU
DEBUG 01-15 10:09:12.804703.804703 lmp.py:1626]   Expert 19 |    135 | CPU
DEBUG 01-15 10:09:12.804214.804214 lmp.py:1626]   Expert  0 |    145 | CPU
DEBUG 01-15 10:09:12.804201.804201 lmp.py:1626]   Expert  6 |    145 | CPU
DEBUG 01-15 10:09:12.804235.804235 lmp.py:1626]   Expert 52 |    148 | CPU
DEBUG 01-15 10:09:12.804031.804031 lmp.py:1626]   Expert 56 |    149 | CPU
DEBUG 01-15 10:09:12.804780.804780 lmp.py:1626]   Expert 54 |    150 | CPU
DEBUG 01-15 10:09:12.804052.804052 lmp.py:1626]   Expert 37 |    154 | CPU
DEBUG 01-15 10:09:12.804325.804325 lmp.py:1626]   Expert 63 |    155 | CPU
DEBUG 01-15 10:09:12.804359.804359 lmp.py:1626]   Expert 53 |    157 | CPU
DEBUG 01-15 10:09:12.804869.804869 lmp.py:1626]   Expert 48 |    158 | CPU
DEBUG 01-15 10:09:12.804142.804142 lmp.py:1626]   Expert 36 |    163 | CPU
DEBUG 01-15 10:09:12.804891.804891 lmp.py:1626]   Expert 59 |    168 | CPU
DEBUG 01-15 10:09:12.804402.804402 lmp.py:1626]   Expert  9 |    181 | CPU
DEBUG 01-15 10:09:12.804436.804436 lmp.py:1626]   Expert  1 |    188 | CPU
DEBUG 01-15 10:09:12.804231.804231 lmp.py:1626]   Expert 39 |    190 | GPU
DEBUG 01-15 10:09:12.805027.805027 lmp.py:1626]   Expert 20 |    200 | GPU
DEBUG 01-15 10:09:12.805538.805538 lmp.py:1626]   Expert 61 |    202 | GPU
DEBUG 01-15 10:09:12.805810.805810 lmp.py:1626]   Expert 43 |    203 | GPU
DEBUG 01-15 10:09:12.805559.805559 lmp.py:1626]   Expert 42 |    204 | GPU
DEBUG 01-15 10:09:12.805070.805070 lmp.py:1626]   Expert  7 |    207 | GPU
DEBUG 01-15 10:09:12.805104.805104 lmp.py:1626]   Expert 47 |    207 | GPU
DEBUG 01-15 10:09:12.805091.805091 lmp.py:1626]   Expert 11 |    208 | GPU
DEBUG 01-15 10:09:12.805887.805887 lmp.py:1626]   Expert 34 |    209 | GPU
DEBUG 01-15 10:09:12.805921.805921 lmp.py:1626]   Expert 55 |    210 | GPU
DEBUG 01-15 10:09:12.805955.805955 lmp.py:1626]   Expert 16 |    219 | GPU
DEBUG 01-15 10:09:12.805750.805750 lmp.py:1626]   Expert 13 |    223 | GPU
DEBUG 01-15 10:09:12.805976.805976 lmp.py:1626]   Expert 57 |    224 | GPU
DEBUG 01-15 10:09:12.805772.805772 lmp.py:1626]   Expert 18 |    225 | GPU
DEBUG 01-15 10:09:12.805806.805806 lmp.py:1626]   Expert 15 |    232 | GPU
DEBUG 01-15 10:09:12.805601.805601 lmp.py:1626]   Expert  4 |    241 | GPU
DEBUG 01-15 10:09:12.805397.805397 lmp.py:1626]   Expert 50 |    243 | GPU
DEBUG 01-15 10:09:12.805908.805908 lmp.py:1626]   Expert 33 |    246 | GPU
DEBUG 01-15 10:09:12.805180.805180 lmp.py:1626]   Expert 22 |    248 | GPU
DEBUG 01-15 10:09:12.805976.805976 lmp.py:1626]   Expert 45 |    248 | GPU
DEBUG 01-15 10:09:12.805771.805771 lmp.py:1626]   Expert 31 |    250 | GPU
DEBUG 01-15 10:09:12.805567.805567 lmp.py:1626]   Expert 51 |    254 | GPU
DEBUG 01-15 10:09:12.805362.805362 lmp.py:1626]   Expert 49 |    271 | GPU
DEBUG 01-15 10:09:12.805396.805396 lmp.py:1626]   Expert 38 |    276 | GPU
DEBUG 01-15 10:09:12.805430.805430 lmp.py:1626]   Expert 26 |    277 | GPU
DEBUG 01-15 10:09:12.805179.805179 lmp.py:1626]   Expert 10 |    285 | GPU
DEBUG 01-15 10:09:12.805167.805167 lmp.py:1626]   Expert 44 |    296 | GPU
DEBUG 01-15 10:09:12.805201.805201 lmp.py:1626]   Expert  2 |    301 | GPU
DEBUG 01-15 10:09:12.805235.805235 lmp.py:1626]   Expert 24 |    306 | GPU
DEBUG 01-15 10:09:12.805269.805269 lmp.py:1626]   Expert 14 |    310 | GPU
DEBUG 01-15 10:09:12.805541.805541 lmp.py:1626]   Expert 23 |    408 | GPU
DEBUG 01-15 10:09:12.805814.805814 lmp.py:1626]   Expert 62 |    672 | GPU
DEBUG 01-15 10:09:12.805278.805278 lmp.py:1627] 
DEBUG 01-15 10:09:12.805278.805278 lmp.py:1627]   CPU total tokens: 3993 (32.5%)
DEBUG 01-15 10:09:12.805219.805219 lmp.py:1628]   GPU total tokens: 8295 (67.5%)
DEBUG 01-15 10:09:12.805075.805075 cuda_h.py:19] end experts_map_get cost 0.002277851104736328 seconds
INFO 01-15 10:09:12.805497.805497 client.py:127] Model loaded
DEBUG 01-15 10:09:12.806799.806799 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.806669.806669 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.806604.806604 lmp.py:1636] 
DEBUG 01-15 10:09:12.806604.806604 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.806475.806475 cuda_h.py:19] end cpu_experts_submit cost 0.0002949237823486328 seconds
DEBUG 01-15 10:09:12.806046.806046 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.806638.806638 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.806182.806182 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.807192.807192 cuda_h.py:19] end allocate_cuda_memory cost 0.00023984909057617188 seconds
DEBUG 01-15 10:09:12.807486.807486 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.807209.807209 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.807615.807615 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.807709.807709 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e298f1e-59f7-46a3-a15f-b7b94cc53892
DEBUG 01-15 10:09:12.807916.807916 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.808484.808484 cuda_h.py:19] end restore2model cost 0.0024302005767822266 seconds
INFO 01-15 10:09:12.809400.809400 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e298f1e-59f7-46a3-a15f-b7b94cc53892
DEBUG 01-15 10:09:12.809364.809364 cuda_h.py:19] end sllm_worker_task cost 0.014977693557739258 seconds
DEBUG 01-15 10:09:12.809103.809103 cuda_h.py:19] end load_into_gpu_async cost 0.0023717880249023438 seconds
DEBUG 01-15 10:09:12.809875.809875 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.810150.810150 cuda_h.py:19] end restore_tensors2 cost 0.000446319580078125 seconds
DEBUG 01-15 10:09:12.810606.810606 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.810648.810648 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003624439239501953 seconds
DEBUG 01-15 10:09:12.810186.810186 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.810144.810144 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.811962.811962 cuda_h.py:19] end move_flatidxs cost 0.0010175704956054688 seconds
DEBUG 01-15 10:09:12.811136.811136 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.812771.812771 cuda_h.py:19] end restore2model cost 0.0026123523712158203 seconds
DEBUG 01-15 10:09:12.813144.813144 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006461620330810547 seconds
DEBUG 01-15 10:09:12.813178.813178 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.813076.813076 cuda_h.py:19] end gpu_sexperts cost 0.00028014183044433594 seconds
DEBUG 01-15 10:09:12.813528.813528 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.814752.814752 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014982223510742188 seconds
DEBUG 01-15 10:09:12.815737.815737 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.816425.816425 cuda_h.py:19] end gpu_group_list cost 0.0003190040588378906 seconds
DEBUG 01-15 10:09:12.816058.816058 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.816454.816454 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007042884826660156 seconds
DEBUG 01-15 10:09:12.817038.817038 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.817861.817861 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-15 10:09:12.817557.817557 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.817960.817960 cuda_h.py:19] end group_tensors cost 0.005372047424316406 seconds
DEBUG 01-15 10:09:12.817619.817619 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.822789.822789 cuda_h.py:19] end group pad cost 0.004039764404296875 seconds
DEBUG 01-15 10:09:12.822586.822586 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.844461.844461 cuda_h.py:19] end group_einsum cost 0.02267169952392578 seconds
DEBUG 01-15 10:09:12.845824.845824 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.849172.849172 cuda_h.py:19] end get_outputs_cpu1 cost 0.004784345626831055 seconds
DEBUG 01-15 10:09:12.850739.850739 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.040462493896484375 seconds
DEBUG 01-15 10:09:12.851870.851870 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03477978706359863 seconds
DEBUG 01-15 10:09:12.852041.852041 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.852855.852855 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.852763.852763 cuda_h.py:19] end index_scatter cost 0.00012230873107910156 seconds
DEBUG 01-15 10:09:12.853755.853755 cuda_h.py:19] end cpuoutputsdeal cost 0.0013065338134765625 seconds
DEBUG 01-15 10:09:12.853626.853626 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.853992.853992 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e298f1e-59f7-46a3-a15f-b7b94cc53892
INFO 01-15 10:09:12.859938.859938 client.py:127] Model loaded
DEBUG 01-15 10:09:12.859206.859206 cuda_h.py:19] end wait_experts cost 0.006206989288330078 seconds
DEBUG 01-15 10:09:12.859267.859267 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.859105.859105 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.859788.859788 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.860189.860189 cuda_h.py:19] end gpu_group_tensor cost 0.0002484321594238281 seconds
DEBUG 01-15 10:09:12.860605.860605 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.861376.861376 cuda_h.py:19] end gpu_group_einsum cost 0.0008118152618408203 seconds
DEBUG 01-15 10:09:12.861607.861607 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.861200.861200 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.862254.862254 cuda_h.py:19] end all_expert_outputs_slices cost 0.00037407875061035156 seconds
DEBUG 01-15 10:09:12.862037.862037 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.862850.862850 cuda_h.py:19] end concat_expert_out cost 8.606910705566406e-05 seconds
DEBUG 01-15 10:09:12.862694.862694 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.862261.862261 cuda_h.py:19] end index_scatter cost 7.915496826171875e-05 seconds
DEBUG 01-15 10:09:12.862389.862389 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009312629699707031 seconds
DEBUG 01-15 10:09:12.862346.862346 cuda_h.py:19] end gpu_experts cost 0.0027196407318115234 seconds
DEBUG 01-15 10:09:12.862477.862477 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.0600733757019043 seconds
DEBUG 01-15 10:09:12.863403.863403 cuda_h.py:19] end prefill_layer cost 0.0696265697479248 seconds
DEBUG 01-15 10:09:12.863035.863035 lmp.py:1552] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-15 10:09:12.863335.863335 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.863873.863873 lmp.py:1495] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-15 10:09:12.863457.863457 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:12.863856.863856 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:12.863515.863515 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.221366882324219e-05 seconds
DEBUG 01-15 10:09:12.863106.863106 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 0.00010728836059570312 seconds
DEBUG 01-15 10:09:12.863213.863213 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.863707.863707 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.864851.864851 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.864653.864653 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.864009.864009 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.864272.864272 cuda_h.py:19] end allocate_cuda_memory cost 0.0004401206970214844 seconds
DEBUG 01-15 10:09:12.865378.865378 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.865938.865938 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.865625.865625 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.865296.865296 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 77eacd1c-0367-4b7f-b02b-f7d48efdf86b
DEBUG 01-15 10:09:12.865495.865495 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.865558.865558 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.866026.866026 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 77eacd1c-0367-4b7f-b02b-f7d48efdf86b
DEBUG 01-15 10:09:12.866017.866017 cuda_h.py:19] end load_into_gpu_async cost 0.001566171646118164 seconds
DEBUG 01-15 10:09:12.866450.866450 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.867922.867922 cuda_h.py:19] end restore_tensors2 cost 0.00015616416931152344 seconds
DEBUG 01-15 10:09:12.867806.867806 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002897500991821289 seconds
INFO 01-15 10:09:12.867480.867480 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 77eacd1c-0367-4b7f-b02b-f7d48efdf86b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.871846.871846 cuda_h.py:19] end self_attn cost 0.005348682403564453 seconds
DEBUG 01-15 10:09:12.871221.871221 cuda_h.py:19] end iln_self_attn_paln cost 0.007894754409790039 seconds
DEBUG 01-15 10:09:12.871448.871448 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-15 10:09:12.871165.871165 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.872362.872362 cuda_h.py:19] end gate cost 0.0007050037384033203 seconds
DEBUG 01-15 10:09:12.872006.872006 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.872799.872799 lmp.py:1616] 
DEBUG 01-15 10:09:12.872799.872799 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:12.872416.872416 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.873688.873688 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.873384.873384 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.873080.873080 lmp.py:1620] 
DEBUG 01-15 10:09:12.873080.873080 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.873492.873492 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.873903.873903 lmp.py:1626]   Expert 44 |     40 | CPU
DEBUG 01-15 10:09:12.873407.873407 lmp.py:1626]   Expert  1 |     47 | CPU
DEBUG 01-15 10:09:12.873719.873719 lmp.py:1626]   Expert 60 |     59 | CPU
DEBUG 01-15 10:09:12.873508.873508 lmp.py:1626]   Expert 28 |     69 | CPU
DEBUG 01-15 10:09:12.873058.873058 lmp.py:1626]   Expert 48 |     80 | CPU
DEBUG 01-15 10:09:12.873847.873847 lmp.py:1626]   Expert 27 |     89 | CPU
DEBUG 01-15 10:09:12.873397.873397 lmp.py:1626]   Expert  0 |     97 | CPU
DEBUG 01-15 10:09:12.873186.873186 lmp.py:1626]   Expert 62 |    105 | CPU
DEBUG 01-15 10:09:12.873974.873974 lmp.py:1626]   Expert 42 |    112 | CPU
DEBUG 01-15 10:09:12.873286.873286 lmp.py:1626]   Expert 22 |    114 | CPU
DEBUG 01-15 10:09:12.873075.873075 lmp.py:1626]   Expert 30 |    115 | CPU
DEBUG 01-15 10:09:12.873625.873625 lmp.py:1626]   Expert 59 |    119 | CPU
DEBUG 01-15 10:09:12.873937.873937 lmp.py:1626]   Expert 58 |    122 | CPU
DEBUG 01-15 10:09:12.873964.873964 lmp.py:1626]   Expert 16 |    124 | CPU
DEBUG 01-15 10:09:12.873945.873945 lmp.py:1626]   Expert  8 |    127 | CPU
DEBUG 01-15 10:09:12.873211.873211 lmp.py:1626]   Expert 12 |    128 | CPU
DEBUG 01-15 10:09:12.873000.873000 lmp.py:1626]   Expert 50 |    135 | CPU
DEBUG 01-15 10:09:12.873788.873788 lmp.py:1626]   Expert 56 |    142 | CPU
DEBUG 01-15 10:09:12.873054.873054 lmp.py:1626]   Expert  5 |    144 | CPU
DEBUG 01-15 10:09:12.873081.873081 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:12.873155.873155 lmp.py:1626]   Expert 15 |    154 | CPU
DEBUG 01-15 10:09:12.873990.873990 lmp.py:1626]   Expert 26 |    154 | CPU
DEBUG 01-15 10:09:12.873825.873825 lmp.py:1626]   Expert 57 |    156 | CPU
DEBUG 01-15 10:09:12.873660.873660 lmp.py:1626]   Expert 32 |    158 | CPU
DEBUG 01-15 10:09:12.873210.873210 lmp.py:1626]   Expert 47 |    158 | CPU
DEBUG 01-15 10:09:12.873522.873522 lmp.py:1626]   Expert 34 |    160 | CPU
DEBUG 01-15 10:09:12.873788.873788 lmp.py:1626]   Expert 24 |    163 | CPU
DEBUG 01-15 10:09:12.873153.873153 lmp.py:1626]   Expert 52 |    166 | CPU
DEBUG 01-15 10:09:12.873895.873895 lmp.py:1626]   Expert  2 |    167 | CPU
DEBUG 01-15 10:09:12.873968.873968 lmp.py:1626]   Expert  6 |    170 | CPU
DEBUG 01-15 10:09:12.873042.873042 lmp.py:1626]   Expert 18 |    172 | CPU
DEBUG 01-15 10:09:12.873115.873115 lmp.py:1626]   Expert 40 |    172 | CPU
DEBUG 01-15 10:09:12.873189.873189 lmp.py:1626]   Expert 54 |    172 | GPU
DEBUG 01-15 10:09:12.873739.873739 lmp.py:1626]   Expert 13 |    173 | GPU
DEBUG 01-15 10:09:12.873574.873574 lmp.py:1626]   Expert  3 |    174 | GPU
DEBUG 01-15 10:09:12.873886.873886 lmp.py:1626]   Expert 41 |    174 | GPU
DEBUG 01-15 10:09:12.873960.873960 lmp.py:1626]   Expert 19 |    182 | GPU
DEBUG 01-15 10:09:12.873510.873510 lmp.py:1626]   Expert 20 |    186 | GPU
DEBUG 01-15 10:09:12.873299.873299 lmp.py:1626]   Expert 46 |    186 | GPU
DEBUG 01-15 10:09:12.873088.873088 lmp.py:1626]   Expert 37 |    187 | GPU
DEBUG 01-15 10:09:12.873876.873876 lmp.py:1626]   Expert 25 |    190 | GPU
DEBUG 01-15 10:09:12.873711.873711 lmp.py:1626]   Expert 17 |    194 | GPU
DEBUG 01-15 10:09:12.873785.873785 lmp.py:1626]   Expert 51 |    195 | GPU
DEBUG 01-15 10:09:12.873143.873143 lmp.py:1626]   Expert 43 |    198 | GPU
DEBUG 01-15 10:09:12.873217.873217 lmp.py:1626]   Expert 35 |    203 | GPU
DEBUG 01-15 10:09:12.873813.873813 lmp.py:1626]   Expert 11 |    204 | GPU
DEBUG 01-15 10:09:12.874648.874648 lmp.py:1626]   Expert 31 |    205 | GPU
DEBUG 01-15 10:09:12.874483.874483 lmp.py:1626]   Expert 23 |    212 | GPU
DEBUG 01-15 10:09:12.874842.874842 lmp.py:1626]   Expert 39 |    220 | GPU
DEBUG 01-15 10:09:12.874915.874915 lmp.py:1626]   Expert 49 |    221 | GPU
DEBUG 01-15 10:09:12.874419.874419 lmp.py:1626]   Expert 53 |    229 | GPU
DEBUG 01-15 10:09:12.874731.874731 lmp.py:1626]   Expert 10 |    233 | GPU
DEBUG 01-15 10:09:12.874997.874997 lmp.py:1626]   Expert 33 |    249 | GPU
DEBUG 01-15 10:09:12.874070.874070 lmp.py:1626]   Expert 36 |    260 | GPU
DEBUG 01-15 10:09:12.874667.874667 lmp.py:1626]   Expert 38 |    267 | GPU
DEBUG 01-15 10:09:12.874502.874502 lmp.py:1626]   Expert  4 |    305 | GPU
DEBUG 01-15 10:09:12.874814.874814 lmp.py:1626]   Expert 21 |    335 | GPU
DEBUG 01-15 10:09:12.874887.874887 lmp.py:1626]   Expert 14 |    346 | GPU
DEBUG 01-15 10:09:12.874245.874245 lmp.py:1626]   Expert 63 |    370 | GPU
DEBUG 01-15 10:09:12.874796.874796 lmp.py:1626]   Expert 45 |    373 | GPU
DEBUG 01-15 10:09:12.874631.874631 lmp.py:1626]   Expert  9 |    385 | GPU
DEBUG 01-15 10:09:12.874704.874704 lmp.py:1626]   Expert 61 |    388 | GPU
DEBUG 01-15 10:09:12.874731.874731 lmp.py:1626]   Expert 29 |    489 | GPU
DEBUG 01-15 10:09:12.874997.874997 lmp.py:1626]   Expert  7 |    514 | GPU
DEBUG 01-15 10:09:12.874978.874978 lmp.py:1627] 
DEBUG 01-15 10:09:12.874978.874978 lmp.py:1627]   CPU total tokens: 4069 (33.1%)
DEBUG 01-15 10:09:12.874005.874005 lmp.py:1628]   GPU total tokens: 8219 (66.9%)
DEBUG 01-15 10:09:12.874039.874039 cuda_h.py:19] end experts_map_get cost 0.0017483234405517578 seconds
DEBUG 01-15 10:09:12.874611.874611 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.874320.874320 lmp.py:1636] 
DEBUG 01-15 10:09:12.874320.874320 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.874548.874548 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-15 10:09:12.874390.874390 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.874617.874617 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.874358.874358 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.875731.875731 cuda_h.py:19] end allocate_cuda_memory cost 0.0002033710479736328 seconds
DEBUG 01-15 10:09:12.875111.875111 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.875251.875251 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.875212.875212 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.875107.875107 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 688a8e88-bc0d-4bff-b101-3a1a75be57cc
DEBUG 01-15 10:09:12.875830.875830 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:12.876353.876353 client.py:127] Model loaded
DEBUG 01-15 10:09:12.876854.876854 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.876956.876956 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:12.876350.876350 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 688a8e88-bc0d-4bff-b101-3a1a75be57cc
DEBUG 01-15 10:09:12.876498.876498 cuda_h.py:19] end load_into_gpu_async cost 0.00144195556640625 seconds
DEBUG 01-15 10:09:12.876830.876830 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.876629.876629 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.877733.877733 cuda_h.py:19] end restore_tensors2 cost 0.00042510032653808594 seconds
DEBUG 01-15 10:09:12.877000.877000 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00250244140625 seconds
DEBUG 01-15 10:09:12.877789.877789 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.877063.877063 cuda_h.py:19] end move_flatidxs cost 0.0010182857513427734 seconds
DEBUG 01-15 10:09:12.877052.877052 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.878927.878927 cuda_h.py:19] end restore2model cost 0.0014905929565429688 seconds
DEBUG 01-15 10:09:12.878947.878947 cuda_h.py:19] end sllm_worker_task cost 0.014729976654052734 seconds
DEBUG 01-15 10:09:12.881438.881438 cuda_h.py:19] end restore2model cost 0.00409245491027832 seconds
DEBUG 01-15 10:09:12.881924.881924 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0068302154541015625 seconds
DEBUG 01-15 10:09:12.881196.881196 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.881161.881161 cuda_h.py:19] end gpu_sexperts cost 0.000293731689453125 seconds
DEBUG 01-15 10:09:12.881613.881613 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.883452.883452 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014958381652832031 seconds
DEBUG 01-15 10:09:12.884517.884517 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.883270.883270 cuda_h.py:19] end group_tensors cost 0.005658864974975586 seconds
DEBUG 01-15 10:09:12.884618.884618 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.884908.884908 cuda_h.py:19] end gpu_group_list cost 0.0003426074981689453 seconds
DEBUG 01-15 10:09:12.884077.884077 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.885580.885580 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007147789001464844 seconds
DEBUG 01-15 10:09:12.885833.885833 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.885947.885947 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-15 10:09:12.885597.885597 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.891131.891131 cuda_h.py:19] end group pad cost 0.0065534114837646484 seconds
DEBUG 01-15 10:09:12.891405.891405 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.915815.915815 cuda_h.py:19] end group_einsum cost 0.024003982543945312 seconds
DEBUG 01-15 10:09:12.915118.915118 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.924255.924255 cuda_h.py:19] end get_outputs_cpu1 cost 0.008774280548095703 seconds
DEBUG 01-15 10:09:12.925419.925419 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04854130744934082 seconds
DEBUG 01-15 10:09:12.926799.926799 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04076695442199707 seconds
DEBUG 01-15 10:09:12.926719.926719 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.926713.926713 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.927523.927523 cuda_h.py:19] end index_scatter cost 0.00014543533325195312 seconds
DEBUG 01-15 10:09:12.927981.927981 cuda_h.py:19] end cpuoutputsdeal cost 0.0010199546813964844 seconds
DEBUG 01-15 10:09:12.927395.927395 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.927020.927020 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 688a8e88-bc0d-4bff-b101-3a1a75be57cc
INFO 01-15 10:09:12.928993.928993 client.py:127] Model loaded
DEBUG 01-15 10:09:12.929480.929480 cuda_h.py:19] end wait_experts cost 0.0012943744659423828 seconds
DEBUG 01-15 10:09:12.929178.929178 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.929665.929665 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.929991.929991 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.929931.929931 cuda_h.py:19] end gpu_group_tensor cost 0.0003132820129394531 seconds
DEBUG 01-15 10:09:12.929481.929481 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.930358.930358 cuda_h.py:19] end gpu_group_einsum cost 0.0009732246398925781 seconds
DEBUG 01-15 10:09:12.931027.931027 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:12.931554.931554 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:12.931598.931598 cuda_h.py:19] end all_expert_outputs_slices cost 0.00045752525329589844 seconds
DEBUG 01-15 10:09:12.931779.931779 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:12.932711.932711 cuda_h.py:19] end concat_expert_out cost 0.00010371208190917969 seconds
DEBUG 01-15 10:09:12.932410.932410 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.932461.932461 cuda_h.py:19] end index_scatter cost 7.987022399902344e-05 seconds
DEBUG 01-15 10:09:12.932589.932589 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001069784164428711 seconds
DEBUG 01-15 10:09:12.932911.932911 cuda_h.py:19] end gpu_experts cost 0.0032608509063720703 seconds
DEBUG 01-15 10:09:12.932472.932472 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.060793161392211914 seconds
DEBUG 01-15 10:09:12.933882.933882 cuda_h.py:19] end prefill_layer cost 0.06969952583312988 seconds
DEBUG 01-15 10:09:12.933421.933421 lmp.py:1552] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-15 10:09:12.933290.933290 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:12.933590.933590 lmp.py:1495] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-15 10:09:12.933366.933366 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:12.933957.933957 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:12.933855.933855 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.316734313964844e-05 seconds
DEBUG 01-15 10:09:12.933353.933353 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00010943412780761719 seconds
DEBUG 01-15 10:09:12.933692.933692 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:12.933670.933670 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:12.933899.933899 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:12.934825.934825 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.934988.934988 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.934208.934208 cuda_h.py:19] end allocate_cuda_memory cost 0.0003638267517089844 seconds
DEBUG 01-15 10:09:12.934842.934842 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.934229.934229 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.934981.934981 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.935388.935388 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b3e6dd0-a6ce-404c-b758-dfd85cee4842
DEBUG 01-15 10:09:12.935155.935155 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:12.935705.935705 cuda_h.py:10] start self_attn
INFO 01-15 10:09:12.936522.936522 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b3e6dd0-a6ce-404c-b758-dfd85cee4842
DEBUG 01-15 10:09:12.936532.936532 cuda_h.py:19] end load_into_gpu_async cost 0.001344442367553711 seconds
DEBUG 01-15 10:09:12.936760.936760 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.936012.936012 cuda_h.py:19] end restore_tensors2 cost 0.00015854835510253906 seconds
DEBUG 01-15 10:09:12.936021.936021 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024251937866210938 seconds
INFO 01-15 10:09:12.936026.936026 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b3e6dd0-a6ce-404c-b758-dfd85cee4842
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:12.941430.941430 cuda_h.py:19] end self_attn cost 0.00552058219909668 seconds
DEBUG 01-15 10:09:12.941680.941680 cuda_h.py:19] end iln_self_attn_paln cost 0.008082389831542969 seconds
DEBUG 01-15 10:09:12.941438.941438 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-15 10:09:12.941765.941765 cuda_h.py:10] start gate
DEBUG 01-15 10:09:12.942308.942308 cuda_h.py:19] end gate cost 0.000732421875 seconds
DEBUG 01-15 10:09:12.942091.942091 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:12.943685.943685 lmp.py:1616] 
DEBUG 01-15 10:09:12.943685.943685 lmp.py:1616] Expert Token Distribution & Device Allocation:
INFO 01-15 10:09:12.943648.943648 client.py:127] Model loaded
DEBUG 01-15 10:09:12.943636.943636 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:12.943896.943896 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.943275.943275 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:12.943511.943511 cuda_h.py:19] end restore2model cost 0.00047087669372558594 seconds
DEBUG 01-15 10:09:12.943818.943818 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:12.943992.943992 cuda_h.py:19] end sllm_worker_task cost 0.009935855865478516 seconds
DEBUG 01-15 10:09:12.944337.944337 lmp.py:1620] 
DEBUG 01-15 10:09:12.944337.944337 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:12.944499.944499 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:12.944957.944957 lmp.py:1626]   Expert 54 |     21 | CPU
DEBUG 01-15 10:09:12.944554.944554 lmp.py:1626]   Expert  3 |     32 | CPU
DEBUG 01-15 10:09:12.944435.944435 lmp.py:1626]   Expert  8 |     41 | CPU
DEBUG 01-15 10:09:12.944032.944032 lmp.py:1626]   Expert 28 |     43 | CPU
DEBUG 01-15 10:09:12.944582.944582 lmp.py:1626]   Expert 43 |     53 | CPU
DEBUG 01-15 10:09:12.944940.944940 lmp.py:1626]   Expert 63 |     54 | CPU
DEBUG 01-15 10:09:12.944345.944345 lmp.py:1626]   Expert 38 |     72 | CPU
DEBUG 01-15 10:09:12.944511.944511 lmp.py:1626]   Expert 36 |     76 | CPU
DEBUG 01-15 10:09:12.944439.944439 lmp.py:1626]   Expert  6 |     79 | CPU
DEBUG 01-15 10:09:12.944366.944366 lmp.py:1626]   Expert 39 |     96 | CPU
DEBUG 01-15 10:09:12.944532.944532 lmp.py:1626]   Expert 57 |     97 | CPU
DEBUG 01-15 10:09:12.944937.944937 lmp.py:1626]   Expert 41 |    105 | CPU
DEBUG 01-15 10:09:12.944865.944865 lmp.py:1626]   Expert 12 |    109 | CPU
DEBUG 01-15 10:09:12.944316.944316 lmp.py:1626]   Expert 52 |    114 | CPU
DEBUG 01-15 10:09:12.944542.944542 lmp.py:1626]   Expert 19 |    120 | CPU
DEBUG 01-15 10:09:12.944999.944999 lmp.py:1626]   Expert 47 |    126 | CPU
DEBUG 01-15 10:09:12.944596.944596 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:12.944716.944716 lmp.py:1626]   Expert 22 |    140 | CPU
DEBUG 01-15 10:09:12.944120.944120 lmp.py:1626]   Expert 46 |    144 | CPU
DEBUG 01-15 10:09:12.944286.944286 lmp.py:1626]   Expert 50 |    149 | CPU
DEBUG 01-15 10:09:12.944976.944976 lmp.py:1626]   Expert 24 |    162 | CPU
DEBUG 01-15 10:09:12.944903.944903 lmp.py:1626]   Expert 40 |    162 | CPU
DEBUG 01-15 10:09:12.944831.944831 lmp.py:1626]   Expert 20 |    164 | CPU
DEBUG 01-15 10:09:12.944521.944521 lmp.py:1626]   Expert 55 |    168 | CPU
DEBUG 01-15 10:09:12.944448.944448 lmp.py:1626]   Expert 37 |    169 | CPU
DEBUG 01-15 10:09:12.944138.944138 lmp.py:1626]   Expert 23 |    170 | CPU
DEBUG 01-15 10:09:12.944065.944065 lmp.py:1626]   Expert  2 |    175 | CPU
DEBUG 01-15 10:09:12.944993.944993 lmp.py:1626]   Expert 53 |    175 | CPU
DEBUG 01-15 10:09:12.944590.944590 lmp.py:1626]   Expert 61 |    177 | CPU
DEBUG 01-15 10:09:12.944279.944279 lmp.py:1626]   Expert 21 |    178 | CPU
DEBUG 01-15 10:09:12.944399.944399 lmp.py:1626]   Expert 42 |    179 | CPU
DEBUG 01-15 10:09:12.944326.944326 lmp.py:1626]   Expert 49 |    181 | CPU
DEBUG 01-15 10:09:12.944254.944254 lmp.py:1626]   Expert 33 |    191 | GPU
DEBUG 01-15 10:09:12.944182.944182 lmp.py:1626]   Expert 18 |    192 | GPU
DEBUG 01-15 10:09:12.944871.944871 lmp.py:1626]   Expert 32 |    194 | GPU
DEBUG 01-15 10:09:12.944037.944037 lmp.py:1626]   Expert 16 |    200 | GPU
DEBUG 01-15 10:09:12.944965.944965 lmp.py:1626]   Expert  5 |    201 | GPU
DEBUG 01-15 10:09:12.944893.944893 lmp.py:1626]   Expert 30 |    201 | GPU
DEBUG 01-15 10:09:12.944820.944820 lmp.py:1626]   Expert  0 |    203 | GPU
DEBUG 01-15 10:09:12.944510.944510 lmp.py:1626]   Expert 14 |    204 | GPU
DEBUG 01-15 10:09:12.944199.944199 lmp.py:1626]   Expert  7 |    207 | GPU
DEBUG 01-15 10:09:12.944319.944319 lmp.py:1626]   Expert 34 |    209 | GPU
DEBUG 01-15 10:09:12.944723.944723 lmp.py:1626]   Expert 31 |    215 | GPU
DEBUG 01-15 10:09:12.944082.944082 lmp.py:1626]   Expert 60 |    217 | GPU
DEBUG 01-15 10:09:12.944248.944248 lmp.py:1626]   Expert 62 |    220 | GPU
DEBUG 01-15 10:09:12.944937.944937 lmp.py:1626]   Expert 59 |    221 | GPU
DEBUG 01-15 10:09:12.944388.944388 lmp.py:1626]   Expert  9 |    223 | GPU
DEBUG 01-15 10:09:12.944839.944839 lmp.py:1626]   Expert 10 |    226 | GPU
DEBUG 01-15 10:09:12.944528.944528 lmp.py:1626]   Expert 17 |    226 | GPU
DEBUG 01-15 10:09:12.944979.944979 lmp.py:1626]   Expert 29 |    231 | GPU
DEBUG 01-15 10:09:12.945668.945668 lmp.py:1626]   Expert 58 |    232 | GPU
DEBUG 01-15 10:09:12.945881.945881 lmp.py:1626]   Expert 15 |    236 | GPU
DEBUG 01-15 10:09:12.945570.945570 lmp.py:1626]   Expert  4 |    238 | GPU
DEBUG 01-15 10:09:12.945021.945021 lmp.py:1626]   Expert 26 |    242 | GPU
DEBUG 01-15 10:09:12.945141.945141 lmp.py:1626]   Expert 51 |    257 | GPU
DEBUG 01-15 10:09:12.945261.945261 lmp.py:1626]   Expert 11 |    265 | GPU
DEBUG 01-15 10:09:12.945380.945380 lmp.py:1626]   Expert 44 |    270 | GPU
DEBUG 01-15 10:09:12.945547.945547 lmp.py:1626]   Expert 56 |    289 | GPU
DEBUG 01-15 10:09:12.945236.945236 lmp.py:1626]   Expert 27 |    290 | GPU
DEBUG 01-15 10:09:12.945925.945925 lmp.py:1626]   Expert  1 |    334 | GPU
DEBUG 01-15 10:09:12.945376.945376 lmp.py:1626]   Expert 45 |    367 | GPU
DEBUG 01-15 10:09:12.945827.945827 lmp.py:1626]   Expert 25 |    460 | GPU
DEBUG 01-15 10:09:12.945278.945278 lmp.py:1626]   Expert 35 |    508 | GPU
DEBUG 01-15 10:09:12.945967.945967 lmp.py:1626]   Expert 48 |    650 | GPU
DEBUG 01-15 10:09:12.945849.945849 lmp.py:1627] 
DEBUG 01-15 10:09:12.945849.945849 lmp.py:1627]   CPU total tokens: 3869 (31.5%)
DEBUG 01-15 10:09:12.945968.945968 lmp.py:1628]   GPU total tokens: 8419 (68.5%)
DEBUG 01-15 10:09:12.945194.945194 cuda_h.py:19] end experts_map_get cost 0.002466917037963867 seconds
DEBUG 01-15 10:09:12.945005.945005 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:12.945714.945714 lmp.py:1636] 
DEBUG 01-15 10:09:12.945714.945714 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:12.945604.945604 cuda_h.py:19] end cpu_experts_submit cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:12.945207.945207 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:12.945726.945726 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:12.945375.945375 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:12.945641.945641 cuda_h.py:19] end allocate_cuda_memory cost 0.0001957416534423828 seconds
DEBUG 01-15 10:09:12.946107.946107 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:12.946101.946101 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:12.946963.946963 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:12.946620.946620 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e222029-6020-4f78-a341-6749c497dddb
DEBUG 01-15 10:09:12.946269.946269 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:12.947298.947298 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e222029-6020-4f78-a341-6749c497dddb
DEBUG 01-15 10:09:12.947291.947291 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:12.947340.947340 cuda_h.py:19] end load_into_gpu_async cost 0.0011906623840332031 seconds
DEBUG 01-15 10:09:12.947665.947665 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:12.947884.947884 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:12.947865.947865 cuda_h.py:19] end restore_tensors2 cost 0.0003998279571533203 seconds
DEBUG 01-15 10:09:12.947840.947840 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002199411392211914 seconds
DEBUG 01-15 10:09:12.947716.947716 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:12.948503.948503 cuda_h.py:19] end move_flatidxs cost 0.0010182857513427734 seconds
DEBUG 01-15 10:09:12.948240.948240 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:12.950614.950614 cuda_h.py:19] end restore2model cost 0.0026590824127197266 seconds
DEBUG 01-15 10:09:12.950941.950941 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005078554153442383 seconds
DEBUG 01-15 10:09:12.950452.950452 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:12.950602.950602 cuda_h.py:19] end gpu_sexperts cost 0.00028967857360839844 seconds
DEBUG 01-15 10:09:12.950484.950484 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:12.952424.952424 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015270709991455078 seconds
DEBUG 01-15 10:09:12.953258.953258 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:12.953667.953667 cuda_h.py:19] end gpu_group_list cost 0.000324249267578125 seconds
DEBUG 01-15 10:09:12.953824.953824 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:12.954160.954160 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006990432739257812 seconds
DEBUG 01-15 10:09:12.954075.954075 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:12.954851.954851 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-15 10:09:12.954739.954739 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:12.958304.958304 cuda_h.py:19] end group_tensors cost 0.009977579116821289 seconds
DEBUG 01-15 10:09:12.959088.959088 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:12.963891.963891 cuda_h.py:19] end group pad cost 0.004541873931884766 seconds
DEBUG 01-15 10:09:12.963933.963933 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:12.984643.984643 cuda_h.py:19] end group_einsum cost 0.020514726638793945 seconds
DEBUG 01-15 10:09:12.984768.984768 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:12.989419.989419 cuda_h.py:19] end get_outputs_cpu1 cost 0.004935503005981445 seconds
DEBUG 01-15 10:09:12.990034.990034 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.043488264083862305 seconds
DEBUG 01-15 10:09:12.991788.991788 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03718447685241699 seconds
DEBUG 01-15 10:09:12.992251.992251 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:12.992449.992449 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:12.992007.992007 cuda_h.py:19] end index_scatter cost 0.00014352798461914062 seconds
DEBUG 01-15 10:09:12.993911.993911 cuda_h.py:19] end cpuoutputsdeal cost 0.0012595653533935547 seconds
DEBUG 01-15 10:09:12.993894.993894 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:12.993043.993043 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e222029-6020-4f78-a341-6749c497dddb
INFO 01-15 10:09:12.997063.997063 client.py:127] Model loaded
DEBUG 01-15 10:09:12.997980.997980 cuda_h.py:19] end wait_experts cost 0.0042798519134521484 seconds
DEBUG 01-15 10:09:12.997870.997870 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:12.998450.998450 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:12.998730.998730 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:12.998623.998623 cuda_h.py:19] end gpu_group_tensor cost 0.0003142356872558594 seconds
DEBUG 01-15 10:09:12.998742.998742 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:12.999513.999513 cuda_h.py:19] end gpu_group_einsum cost 0.0009682178497314453 seconds
DEBUG 01-15 10:09:12.999785.999785 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.000589.000589 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.000137.000137 cuda_h.py:19] end all_expert_outputs_slices cost 0.0004773139953613281 seconds
DEBUG 01-15 10:09:13.000610.000610 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.000556.000556 cuda_h.py:19] end concat_expert_out cost 0.00010967254638671875 seconds
DEBUG 01-15 10:09:13.000951.000951 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.001089.001089 cuda_h.py:19] end index_scatter cost 9.560585021972656e-05 seconds
DEBUG 01-15 10:09:13.001429.001429 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011665821075439453 seconds
DEBUG 01-15 10:09:13.001328.001328 cuda_h.py:19] end gpu_experts cost 0.003335714340209961 seconds
DEBUG 01-15 10:09:13.001207.001207 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.05949234962463379 seconds
DEBUG 01-15 10:09:13.002567.002567 cuda_h.py:19] end prefill_layer cost 0.06872272491455078 seconds
DEBUG 01-15 10:09:13.002126.002126 lmp.py:1552] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-15 10:09:13.002155.002155 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.002375.002375 lmp.py:1495] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-15 10:09:13.002119.002119 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:13.002300.002300 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:13.002171.002171 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.127357482910156e-05 seconds
DEBUG 01-15 10:09:13.002417.002417 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 0.00010704994201660156 seconds
DEBUG 01-15 10:09:13.002372.002372 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.002607.002607 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:13.002757.002757 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:13.002589.002589 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.003287.003287 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.003723.003723 cuda_h.py:19] end allocate_cuda_memory cost 0.00029730796813964844 seconds
DEBUG 01-15 10:09:13.003402.003402 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.003100.003100 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.003387.003387 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.003594.003594 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2cf2ed6e-a9f6-423b-abfe-f0d4c3afa6f5
DEBUG 01-15 10:09:13.003009.003009 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.004206.004206 cuda_h.py:10] start self_attn
INFO 01-15 10:09:13.004608.004608 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2cf2ed6e-a9f6-423b-abfe-f0d4c3afa6f5
DEBUG 01-15 10:09:13.004485.004485 cuda_h.py:19] end load_into_gpu_async cost 0.0012326240539550781 seconds
DEBUG 01-15 10:09:13.004354.004354 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.005419.005419 cuda_h.py:19] end restore_tensors2 cost 0.00010895729064941406 seconds
DEBUG 01-15 10:09:13.005633.005633 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002046823501586914 seconds
INFO 01-15 10:09:13.005146.005146 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2cf2ed6e-a9f6-423b-abfe-f0d4c3afa6f5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.009384.009384 cuda_h.py:19] end self_attn cost 0.004817485809326172 seconds
DEBUG 01-15 10:09:13.009630.009630 cuda_h.py:19] end iln_self_attn_paln cost 0.006849527359008789 seconds
DEBUG 01-15 10:09:13.009176.009176 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-15 10:09:13.009476.009476 cuda_h.py:10] start gate
DEBUG 01-15 10:09:13.010031.010031 cuda_h.py:19] end gate cost 0.0008771419525146484 seconds
DEBUG 01-15 10:09:13.010987.010987 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.011400.011400 lmp.py:1616] 
DEBUG 01-15 10:09:13.011400.011400 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.011158.011158 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.011450.011450 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.011306.011306 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.011062.011062 lmp.py:1620] 
DEBUG 01-15 10:09:13.011062.011062 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.011579.011579 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.011335.011335 lmp.py:1626]   Expert 44 |     28 | CPU
DEBUG 01-15 10:09:13.011184.011184 lmp.py:1626]   Expert  9 |     35 | CPU
DEBUG 01-15 10:09:13.011033.011033 lmp.py:1626]   Expert 11 |     35 | CPU
DEBUG 01-15 10:09:13.011835.011835 lmp.py:1626]   Expert 56 |     59 | CPU
DEBUG 01-15 10:09:13.011637.011637 lmp.py:1626]   Expert 54 |     82 | CPU
DEBUG 01-15 10:09:13.011009.011009 lmp.py:1626]   Expert 62 |     92 | CPU
DEBUG 01-15 10:09:13.011904.011904 lmp.py:1626]   Expert  7 |     93 | CPU
DEBUG 01-15 10:09:13.011322.011322 lmp.py:1626]   Expert 47 |     97 | CPU
DEBUG 01-15 10:09:13.011502.011502 lmp.py:1626]   Expert 51 |     97 | CPU
DEBUG 01-15 10:09:13.011397.011397 lmp.py:1626]   Expert 60 |    106 | CPU
DEBUG 01-15 10:09:13.011053.011053 lmp.py:1626]   Expert 22 |    108 | CPU
DEBUG 01-15 10:09:13.011617.011617 lmp.py:1626]   Expert 52 |    108 | CPU
DEBUG 01-15 10:09:13.011181.011181 lmp.py:1626]   Expert 53 |    109 | CPU
DEBUG 01-15 10:09:13.011791.011791 lmp.py:1626]   Expert 41 |    110 | CPU
DEBUG 01-15 10:09:13.011733.011733 lmp.py:1626]   Expert  8 |    126 | CPU
DEBUG 01-15 10:09:13.011674.011674 lmp.py:1626]   Expert  6 |    127 | CPU
DEBUG 01-15 10:09:13.011569.011569 lmp.py:1626]   Expert  1 |    128 | CPU
DEBUG 01-15 10:09:13.011987.011987 lmp.py:1626]   Expert  2 |    130 | CPU
DEBUG 01-15 10:09:13.011313.011313 lmp.py:1626]   Expert 32 |    130 | CPU
DEBUG 01-15 10:09:13.011877.011877 lmp.py:1626]   Expert 48 |    130 | CPU
DEBUG 01-15 10:09:13.011679.011679 lmp.py:1626]   Expert 23 |    140 | CPU
DEBUG 01-15 10:09:13.012574.012574 lmp.py:1626]   Expert 27 |    141 | CPU
DEBUG 01-15 10:09:13.012992.012992 lmp.py:1626]   Expert 59 |    141 | CPU
DEBUG 01-15 10:09:13.012556.012556 lmp.py:1626]   Expert 35 |    142 | CPU
DEBUG 01-15 10:09:13.012166.012166 lmp.py:1626]   Expert 26 |    146 | CPU
DEBUG 01-15 10:09:13.012730.012730 lmp.py:1626]   Expert 39 |    146 | CPU
DEBUG 01-15 10:09:13.012486.012486 lmp.py:1626]   Expert 50 |    152 | CPU
DEBUG 01-15 10:09:13.012242.012242 lmp.py:1626]   Expert 14 |    159 | CPU
DEBUG 01-15 10:09:13.012806.012806 lmp.py:1626]   Expert 46 |    164 | CPU
DEBUG 01-15 10:09:13.012370.012370 lmp.py:1626]   Expert 24 |    168 | CPU
DEBUG 01-15 10:09:13.012695.012695 lmp.py:1626]   Expert 34 |    170 | CPU
DEBUG 01-15 10:09:13.012259.012259 lmp.py:1626]   Expert 38 |    170 | CPU
DEBUG 01-15 10:09:13.012346.012346 lmp.py:1626]   Expert  0 |    171 | GPU
DEBUG 01-15 10:09:13.012864.012864 lmp.py:1626]   Expert 49 |    175 | GPU
DEBUG 01-15 10:09:13.012157.012157 lmp.py:1626]   Expert  4 |    176 | GPU
DEBUG 01-15 10:09:13.012151.012151 lmp.py:1626]   Expert 40 |    183 | GPU
DEBUG 01-15 10:09:13.012192.012192 lmp.py:1626]   Expert 63 |    186 | GPU
DEBUG 01-15 10:09:13.012709.012709 lmp.py:1626]   Expert  5 |    187 | GPU
DEBUG 01-15 10:09:13.012035.012035 lmp.py:1626]   Expert 19 |    190 | GPU
DEBUG 01-15 10:09:13.012599.012599 lmp.py:1626]   Expert 13 |    196 | GPU
DEBUG 01-15 10:09:13.012971.012971 lmp.py:1626]   Expert 43 |    204 | GPU
DEBUG 01-15 10:09:13.012819.012819 lmp.py:1626]   Expert 29 |    206 | GPU
DEBUG 01-15 10:09:13.012429.012429 lmp.py:1626]   Expert 57 |    209 | GPU
DEBUG 01-15 10:09:13.012947.012947 lmp.py:1626]   Expert 61 |    210 | GPU
DEBUG 01-15 10:09:13.012465.012465 lmp.py:1626]   Expert 31 |    224 | GPU
DEBUG 01-15 10:09:13.012505.012505 lmp.py:1626]   Expert 33 |    225 | GPU
DEBUG 01-15 10:09:13.012592.012592 lmp.py:1626]   Expert 16 |    248 | GPU
DEBUG 01-15 10:09:13.012679.012679 lmp.py:1626]   Expert 37 |    249 | GPU
DEBUG 01-15 10:09:13.012528.012528 lmp.py:1626]   Expert 20 |    255 | GPU
DEBUG 01-15 10:09:13.012138.012138 lmp.py:1626]   Expert  3 |    256 | GPU
DEBUG 01-15 10:09:13.012225.012225 lmp.py:1626]   Expert 15 |    259 | GPU
DEBUG 01-15 10:09:13.012505.012505 lmp.py:1626]   Expert 36 |    273 | GPU
DEBUG 01-15 10:09:13.012989.012989 lmp.py:1626]   Expert 18 |    278 | GPU
DEBUG 01-15 10:09:13.012632.012632 lmp.py:1626]   Expert 12 |    282 | GPU
DEBUG 01-15 10:09:13.012798.012798 lmp.py:1626]   Expert 28 |    303 | GPU
DEBUG 01-15 10:09:13.013965.013965 lmp.py:1626]   Expert 17 |    306 | GPU
DEBUG 01-15 10:09:13.013131.013131 lmp.py:1626]   Expert 55 |    310 | GPU
DEBUG 01-15 10:09:13.013297.013297 lmp.py:1626]   Expert 30 |    314 | GPU
DEBUG 01-15 10:09:13.013463.013463 lmp.py:1626]   Expert 25 |    323 | GPU
DEBUG 01-15 10:09:13.013391.013391 lmp.py:1626]   Expert 58 |    336 | GPU
DEBUG 01-15 10:09:13.013557.013557 lmp.py:1626]   Expert 10 |    362 | GPU
DEBUG 01-15 10:09:13.013915.013915 lmp.py:1626]   Expert 45 |    387 | GPU
DEBUG 01-15 10:09:13.013750.013750 lmp.py:1626]   Expert 21 |    392 | GPU
DEBUG 01-15 10:09:13.013585.013585 lmp.py:1626]   Expert 42 |    644 | GPU
DEBUG 01-15 10:09:13.013943.013943 lmp.py:1627] 
DEBUG 01-15 10:09:13.013943.013943 lmp.py:1627]   CPU total tokens: 3769 (30.7%)
DEBUG 01-15 10:09:13.013540.013540 lmp.py:1628]   GPU total tokens: 8519 (69.3%)
DEBUG 01-15 10:09:13.013667.013667 cuda_h.py:19] end experts_map_get cost 0.002461671829223633 seconds
INFO 01-15 10:09:13.013955.013955 client.py:127] Model loaded
DEBUG 01-15 10:09:13.013137.013137 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.013510.013510 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.013956.013956 lmp.py:1636] 
DEBUG 01-15 10:09:13.013956.013956 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.013182.013182 cuda_h.py:19] end cpu_experts_submit cost 0.00024056434631347656 seconds
DEBUG 01-15 10:09:13.013501.013501 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.013543.013543 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.014423.014423 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.014902.014902 cuda_h.py:19] end allocate_cuda_memory cost 0.00021147727966308594 seconds
DEBUG 01-15 10:09:13.014745.014745 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.014501.014501 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.014317.014317 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.014020.014020 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a698e2cc-7717-4a2a-a842-ccf4d1f97c89
DEBUG 01-15 10:09:13.014152.014152 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.015398.015398 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.015076.015076 cuda_h.py:19] end restore2model cost 0.0023193359375 seconds
DEBUG 01-15 10:09:13.016980.016980 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.016875.016875 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a698e2cc-7717-4a2a-a842-ccf4d1f97c89
DEBUG 01-15 10:09:13.016567.016567 cuda_h.py:19] end sllm_worker_task cost 0.013189315795898438 seconds
DEBUG 01-15 10:09:13.016543.016543 cuda_h.py:19] end load_into_gpu_async cost 0.0018496513366699219 seconds
DEBUG 01-15 10:09:13.016526.016526 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.016170.016170 cuda_h.py:19] end restore_tensors2 cost 0.00041103363037109375 seconds
DEBUG 01-15 10:09:13.016675.016675 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029518604278564453 seconds
DEBUG 01-15 10:09:13.016306.016306 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.017348.017348 cuda_h.py:19] end move_flatidxs cost 0.0010373592376708984 seconds
DEBUG 01-15 10:09:13.017576.017576 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.019586.019586 cuda_h.py:19] end restore2model cost 0.002598285675048828 seconds
DEBUG 01-15 10:09:13.019383.019383 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0057523250579833984 seconds
DEBUG 01-15 10:09:13.019178.019178 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.019514.019514 cuda_h.py:19] end gpu_sexperts cost 0.00028586387634277344 seconds
DEBUG 01-15 10:09:13.019489.019489 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.021335.021335 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001495361328125 seconds
DEBUG 01-15 10:09:13.022400.022400 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.022386.022386 cuda_h.py:19] end gpu_group_list cost 0.0003266334533691406 seconds
DEBUG 01-15 10:09:13.022595.022595 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.023878.023878 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006933212280273438 seconds
DEBUG 01-15 10:09:13.023032.023032 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:13.023285.023285 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.621246337890625e-05 seconds
DEBUG 01-15 10:09:13.023935.023935 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.027138.027138 cuda_h.py:19] end group_tensors cost 0.010407686233520508 seconds
DEBUG 01-15 10:09:13.028616.028616 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.032347.032347 cuda_h.py:19] end group pad cost 0.004162788391113281 seconds
DEBUG 01-15 10:09:13.032283.032283 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.051962.051962 cuda_h.py:19] end group_einsum cost 0.0188138484954834 seconds
DEBUG 01-15 10:09:13.051040.051040 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.056999.056999 cuda_h.py:19] end get_outputs_cpu1 cost 0.004630088806152344 seconds
DEBUG 01-15 10:09:13.057136.057136 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.041707515716552734 seconds
DEBUG 01-15 10:09:13.058997.058997 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.034623146057128906 seconds
DEBUG 01-15 10:09:13.058686.058686 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.058481.058481 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.059721.059721 cuda_h.py:19] end index_scatter cost 0.0001442432403564453 seconds
DEBUG 01-15 10:09:13.059350.059350 cuda_h.py:19] end cpuoutputsdeal cost 0.0011420249938964844 seconds
DEBUG 01-15 10:09:13.059856.059856 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.059719.059719 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a698e2cc-7717-4a2a-a842-ccf4d1f97c89
INFO 01-15 10:09:13.066924.066924 client.py:127] Model loaded
DEBUG 01-15 10:09:13.066922.066922 cuda_h.py:19] end wait_experts cost 0.00643610954284668 seconds
DEBUG 01-15 10:09:13.066593.066593 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.066107.066107 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.066024.066024 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.067410.067410 cuda_h.py:19] end gpu_group_tensor cost 0.0003809928894042969 seconds
DEBUG 01-15 10:09:13.067054.067054 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.068248.068248 cuda_h.py:19] end gpu_group_einsum cost 0.001154184341430664 seconds
DEBUG 01-15 10:09:13.068296.068296 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.068943.068943 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.069666.069666 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005564689636230469 seconds
DEBUG 01-15 10:09:13.069537.069537 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.069053.069053 cuda_h.py:19] end concat_expert_out cost 0.00012731552124023438 seconds
DEBUG 01-15 10:09:13.069158.069158 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.070880.070880 cuda_h.py:19] end index_scatter cost 0.0001289844512939453 seconds
DEBUG 01-15 10:09:13.070148.070148 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014064311981201172 seconds
DEBUG 01-15 10:09:13.070849.070849 cuda_h.py:19] end gpu_experts cost 0.004015922546386719 seconds
DEBUG 01-15 10:09:13.070776.070776 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06096148490905762 seconds
DEBUG 01-15 10:09:13.071756.071756 cuda_h.py:19] end prefill_layer cost 0.06912493705749512 seconds
DEBUG 01-15 10:09:13.071581.071581 lmp.py:1552] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-15 10:09:13.071007.071007 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.071818.071818 lmp.py:1495] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-15 10:09:13.071151.071151 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:13.071114.071114 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:13.072702.072702 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.319450378417969e-05 seconds
DEBUG 01-15 10:09:13.072996.072996 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.00016164779663085938 seconds
DEBUG 01-15 10:09:13.072223.072223 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.072845.072845 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:13.072340.072340 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:13.072966.072966 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.072878.072878 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.073208.073208 cuda_h.py:19] end allocate_cuda_memory cost 0.0004584789276123047 seconds
DEBUG 01-15 10:09:13.073519.073519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.073053.073053 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.073408.073408 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.074272.074272 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b2faea0-b6b5-490d-a5b7-20e828eed208
DEBUG 01-15 10:09:13.074935.074935 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.074907.074907 cuda_h.py:10] start self_attn
INFO 01-15 10:09:13.075525.075525 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b2faea0-b6b5-490d-a5b7-20e828eed208
DEBUG 01-15 10:09:13.075039.075039 cuda_h.py:19] end load_into_gpu_async cost 0.0017790794372558594 seconds
DEBUG 01-15 10:09:13.075141.075141 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.075215.075215 cuda_h.py:19] end restore_tensors2 cost 0.0001571178436279297 seconds
DEBUG 01-15 10:09:13.076273.076273 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031490325927734375 seconds
INFO 01-15 10:09:13.076775.076775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b2faea0-b6b5-490d-a5b7-20e828eed208
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.080522.080522 cuda_h.py:19] end self_attn cost 0.005584239959716797 seconds
DEBUG 01-15 10:09:13.080062.080062 cuda_h.py:19] end iln_self_attn_paln cost 0.008549213409423828 seconds
DEBUG 01-15 10:09:13.080813.080813 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-15 10:09:13.080756.080756 cuda_h.py:10] start gate
DEBUG 01-15 10:09:13.081803.081803 cuda_h.py:19] end gate cost 0.0009570121765136719 seconds
DEBUG 01-15 10:09:13.082388.082388 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.082691.082691 lmp.py:1616] 
DEBUG 01-15 10:09:13.082691.082691 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.082865.082865 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.082927.082927 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.082458.082458 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.082936.082936 lmp.py:1620] 
DEBUG 01-15 10:09:13.082936.082936 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.082460.082460 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.082846.082846 lmp.py:1626]   Expert 25 |     13 | CPU
DEBUG 01-15 10:09:13.082131.082131 lmp.py:1626]   Expert 48 |     32 | CPU
DEBUG 01-15 10:09:13.082086.082086 lmp.py:1626]   Expert 45 |     36 | CPU
DEBUG 01-15 10:09:13.082803.082803 lmp.py:1626]   Expert  9 |     62 | CPU
DEBUG 01-15 10:09:13.082897.082897 lmp.py:1626]   Expert 43 |     82 | CPU
DEBUG 01-15 10:09:13.082467.082467 lmp.py:1626]   Expert  0 |     85 | CPU
DEBUG 01-15 10:09:13.083800.083800 lmp.py:1626]   Expert 54 |     87 | CPU
DEBUG 01-15 10:09:13.083655.083655 lmp.py:1626]   Expert 47 |     88 | CPU
DEBUG 01-15 10:09:13.083703.083703 lmp.py:1626]   Expert 20 |     89 | CPU
DEBUG 01-15 10:09:13.083989.083989 lmp.py:1626]   Expert 36 |     93 | CPU
DEBUG 01-15 10:09:13.083082.083082 lmp.py:1626]   Expert 57 |     93 | CPU
DEBUG 01-15 10:09:13.083415.083415 lmp.py:1626]   Expert  6 |     94 | CPU
DEBUG 01-15 10:09:13.083032.083032 lmp.py:1626]   Expert 62 |    101 | CPU
DEBUG 01-15 10:09:13.083602.083602 lmp.py:1626]   Expert 15 |    103 | CPU
DEBUG 01-15 10:09:13.083412.083412 lmp.py:1626]   Expert 13 |    105 | CPU
DEBUG 01-15 10:09:13.083221.083221 lmp.py:1626]   Expert 61 |    105 | CPU
DEBUG 01-15 10:09:13.083791.083791 lmp.py:1626]   Expert 50 |    106 | CPU
DEBUG 01-15 10:09:13.083170.083170 lmp.py:1626]   Expert  1 |    109 | CPU
DEBUG 01-15 10:09:13.083264.083264 lmp.py:1626]   Expert 38 |    110 | CPU
DEBUG 01-15 10:09:13.083119.083119 lmp.py:1626]   Expert 37 |    115 | CPU
DEBUG 01-15 10:09:13.083213.083213 lmp.py:1626]   Expert 46 |    117 | CPU
DEBUG 01-15 10:09:13.083307.083307 lmp.py:1626]   Expert 14 |    122 | CPU
DEBUG 01-15 10:09:13.083162.083162 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:13.083495.083495 lmp.py:1626]   Expert 52 |    137 | CPU
DEBUG 01-15 10:09:13.083350.083350 lmp.py:1626]   Expert 28 |    138 | CPU
DEBUG 01-15 10:09:13.083729.083729 lmp.py:1626]   Expert 21 |    140 | CPU
DEBUG 01-15 10:09:13.083823.083823 lmp.py:1626]   Expert 44 |    144 | CPU
DEBUG 01-15 10:09:13.083155.083155 lmp.py:1626]   Expert 24 |    152 | CPU
DEBUG 01-15 10:09:13.083732.083732 lmp.py:1626]   Expert 10 |    153 | CPU
DEBUG 01-15 10:09:13.083375.083375 lmp.py:1626]   Expert 42 |    156 | CPU
DEBUG 01-15 10:09:13.083257.083257 lmp.py:1626]   Expert 11 |    160 | CPU
DEBUG 01-15 10:09:13.083423.083423 lmp.py:1626]   Expert  2 |    163 | CPU
DEBUG 01-15 10:09:13.083304.083304 lmp.py:1626]   Expert 35 |    171 | GPU
DEBUG 01-15 10:09:13.083709.083709 lmp.py:1626]   Expert 26 |    175 | GPU
DEBUG 01-15 10:09:13.083875.083875 lmp.py:1626]   Expert 31 |    176 | GPU
DEBUG 01-15 10:09:13.083518.083518 lmp.py:1626]   Expert 19 |    185 | GPU
DEBUG 01-15 10:09:13.083684.083684 lmp.py:1626]   Expert  3 |    187 | GPU
DEBUG 01-15 10:09:13.083089.083089 lmp.py:1626]   Expert 32 |    188 | GPU
DEBUG 01-15 10:09:13.083447.083447 lmp.py:1626]   Expert 12 |    195 | GPU
DEBUG 01-15 10:09:13.083282.083282 lmp.py:1626]   Expert 60 |    206 | GPU
DEBUG 01-15 10:09:13.084402.084402 lmp.py:1626]   Expert 56 |    210 | GPU
DEBUG 01-15 10:09:13.084045.084045 lmp.py:1626]   Expert 40 |    211 | GPU
DEBUG 01-15 10:09:13.084449.084449 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:13.084377.084377 lmp.py:1626]   Expert 53 |    228 | GPU
DEBUG 01-15 10:09:13.084020.084020 lmp.py:1626]   Expert 23 |    233 | GPU
DEBUG 01-15 10:09:13.084424.084424 lmp.py:1626]   Expert 16 |    234 | GPU
DEBUG 01-15 10:09:13.084352.084352 lmp.py:1626]   Expert  8 |    235 | GPU
DEBUG 01-15 10:09:13.084757.084757 lmp.py:1626]   Expert 58 |    235 | GPU
DEBUG 01-15 10:09:13.084923.084923 lmp.py:1626]   Expert 51 |    236 | GPU
DEBUG 01-15 10:09:13.084327.084327 lmp.py:1626]   Expert 59 |    239 | GPU
DEBUG 01-15 10:09:13.084732.084732 lmp.py:1626]   Expert  4 |    250 | GPU
DEBUG 01-15 10:09:13.084137.084137 lmp.py:1626]   Expert 49 |    268 | GPU
DEBUG 01-15 10:09:13.084495.084495 lmp.py:1626]   Expert 55 |    269 | GPU
DEBUG 01-15 10:09:13.084376.084376 lmp.py:1626]   Expert 29 |    277 | GPU
DEBUG 01-15 10:09:13.084642.084642 lmp.py:1626]   Expert 34 |    280 | GPU
DEBUG 01-15 10:09:13.084093.084093 lmp.py:1626]   Expert 18 |    285 | GPU
DEBUG 01-15 10:09:13.084067.084067 lmp.py:1626]   Expert 63 |    294 | GPU
DEBUG 01-15 10:09:13.084518.084518 lmp.py:1626]   Expert 27 |    355 | GPU
DEBUG 01-15 10:09:13.084922.084922 lmp.py:1626]   Expert 39 |    375 | GPU
DEBUG 01-15 10:09:13.084327.084327 lmp.py:1626]   Expert 17 |    395 | GPU
DEBUG 01-15 10:09:13.084731.084731 lmp.py:1626]   Expert 22 |    434 | GPU
DEBUG 01-15 10:09:13.084136.084136 lmp.py:1626]   Expert 33 |    454 | GPU
DEBUG 01-15 10:09:13.084408.084408 lmp.py:1626]   Expert 30 |    456 | GPU
DEBUG 01-15 10:09:13.084290.084290 lmp.py:1626]   Expert  5 |    707 | GPU
DEBUG 01-15 10:09:13.084886.084886 lmp.py:1627] 
DEBUG 01-15 10:09:13.084886.084886 lmp.py:1627]   CPU total tokens: 3426 (27.9%)
DEBUG 01-15 10:09:13.084483.084483 lmp.py:1628]   GPU total tokens: 8862 (72.1%)
DEBUG 01-15 10:09:13.084133.084133 cuda_h.py:19] end experts_map_get cost 0.002398252487182617 seconds
INFO 01-15 10:09:13.084342.084342 client.py:127] Model loaded
DEBUG 01-15 10:09:13.084074.084074 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.084600.084600 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.084575.084575 lmp.py:1636] 
DEBUG 01-15 10:09:13.084575.084575 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.085763.085763 cuda_h.py:19] end cpu_experts_submit cost 0.0002830028533935547 seconds
DEBUG 01-15 10:09:13.085797.085797 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.085548.085548 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.085044.085044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.085062.085062 cuda_h.py:19] end allocate_cuda_memory cost 0.0002913475036621094 seconds
DEBUG 01-15 10:09:13.085627.085627 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.085144.085144 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.085629.085629 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.085902.085902 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36c047a6-224c-4850-8389-437e2f55e82d
DEBUG 01-15 10:09:13.086835.086835 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.087482.087482 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.087435.087435 cuda_h.py:19] end restore2model cost 0.0026352405548095703 seconds
DEBUG 01-15 10:09:13.087833.087833 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.087798.087798 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36c047a6-224c-4850-8389-437e2f55e82d
DEBUG 01-15 10:09:13.087126.087126 cuda_h.py:19] end sllm_worker_task cost 0.01508641242980957 seconds
DEBUG 01-15 10:09:13.087269.087269 cuda_h.py:19] end load_into_gpu_async cost 0.0021207332611083984 seconds
DEBUG 01-15 10:09:13.088259.088259 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.088883.088883 cuda_h.py:19] end restore_tensors2 cost 0.0004303455352783203 seconds
DEBUG 01-15 10:09:13.088912.088912 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033326148986816406 seconds
DEBUG 01-15 10:09:13.088496.088496 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.088784.088784 cuda_h.py:19] end move_flatidxs cost 0.0011594295501708984 seconds
DEBUG 01-15 10:09:13.089715.089715 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.091782.091782 cuda_h.py:19] end restore2model cost 0.0025620460510253906 seconds
DEBUG 01-15 10:09:13.091532.091532 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006101846694946289 seconds
DEBUG 01-15 10:09:13.091612.091612 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.091498.091498 cuda_h.py:19] end gpu_sexperts cost 0.00030612945556640625 seconds
DEBUG 01-15 10:09:13.091712.091712 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.093757.093757 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015072822570800781 seconds
DEBUG 01-15 10:09:13.093358.093358 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.094351.094351 cuda_h.py:19] end gpu_group_list cost 0.0003333091735839844 seconds
DEBUG 01-15 10:09:13.094084.094084 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.095281.095281 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007011890411376953 seconds
DEBUG 01-15 10:09:13.095196.095196 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:13.095449.095449 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-15 10:09:13.095145.095145 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.105818.105818 cuda_h.py:19] end group_tensors cost 0.01624274253845215 seconds
DEBUG 01-15 10:09:13.106050.106050 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.110388.110388 cuda_h.py:19] end group pad cost 0.004081249237060547 seconds
DEBUG 01-15 10:09:13.110913.110913 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.132363.132363 cuda_h.py:19] end group_einsum cost 0.021821975708007812 seconds
DEBUG 01-15 10:09:13.132553.132553 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.137417.137417 cuda_h.py:19] end get_outputs_cpu1 cost 0.004353046417236328 seconds
DEBUG 01-15 10:09:13.137030.137030 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.050629615783691406 seconds
DEBUG 01-15 10:09:13.138018.138018 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04339742660522461 seconds
DEBUG 01-15 10:09:13.139065.139065 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.139187.139187 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.139250.139250 cuda_h.py:19] end index_scatter cost 0.0001685619354248047 seconds
DEBUG 01-15 10:09:13.140114.140114 cuda_h.py:19] end cpuoutputsdeal cost 0.0011606216430664062 seconds
DEBUG 01-15 10:09:13.140651.140651 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.140734.140734 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36c047a6-224c-4850-8389-437e2f55e82d
INFO 01-15 10:09:13.141126.141126 client.py:127] Model loaded
DEBUG 01-15 10:09:13.141018.141018 cuda_h.py:19] end wait_experts cost 0.0013763904571533203 seconds
DEBUG 01-15 10:09:13.142352.142352 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.142482.142482 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.142776.142776 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.142619.142619 cuda_h.py:19] end gpu_group_tensor cost 0.0003693103790283203 seconds
DEBUG 01-15 10:09:13.142692.142692 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.144111.144111 cuda_h.py:19] end gpu_group_einsum cost 0.0011096000671386719 seconds
DEBUG 01-15 10:09:13.144253.144253 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.144409.144409 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.145281.145281 cuda_h.py:19] end all_expert_outputs_slices cost 0.00047087669372558594 seconds
DEBUG 01-15 10:09:13.145939.145939 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.145262.145262 cuda_h.py:19] end concat_expert_out cost 0.00010633468627929688 seconds
DEBUG 01-15 10:09:13.145134.145134 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.145809.145809 cuda_h.py:19] end index_scatter cost 0.00011205673217773438 seconds
DEBUG 01-15 10:09:13.145388.145388 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011653900146484375 seconds
DEBUG 01-15 10:09:13.145193.145193 cuda_h.py:19] end gpu_experts cost 0.0037147998809814453 seconds
DEBUG 01-15 10:09:13.145557.145557 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06505799293518066 seconds
DEBUG 01-15 10:09:13.146069.146069 cuda_h.py:19] end prefill_layer cost 0.0749368667602539 seconds
DEBUG 01-15 10:09:13.146198.146198 lmp.py:1552] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-15 10:09:13.146557.146557 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.146016.146016 lmp.py:1495] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-15 10:09:13.146713.146713 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:13.146609.146609 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:13.147733.147733 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.9604644775390625e-05 seconds
DEBUG 01-15 10:09:13.147518.147518 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:13.147369.147369 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00028967857360839844 seconds
DEBUG 01-15 10:09:13.147163.147163 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.147001.147001 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.147350.147350 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.147555.147555 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:13.148488.148488 cuda_h.py:19] end allocate_cuda_memory cost 0.000461578369140625 seconds
DEBUG 01-15 10:09:13.148809.148809 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.148368.148368 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.148432.148432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.149633.149633 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94e13235-b09e-4049-a12f-4c505b2e983f
DEBUG 01-15 10:09:13.149759.149759 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.149064.149064 cuda_h.py:10] start self_attn
INFO 01-15 10:09:13.150914.150914 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94e13235-b09e-4049-a12f-4c505b2e983f
DEBUG 01-15 10:09:13.150905.150905 cuda_h.py:19] end load_into_gpu_async cost 0.0015869140625 seconds
DEBUG 01-15 10:09:13.150099.150099 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.150465.150465 cuda_h.py:19] end restore_tensors2 cost 0.0001590251922607422 seconds
DEBUG 01-15 10:09:13.150825.150825 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003175020217895508 seconds
INFO 01-15 10:09:13.151653.151653 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94e13235-b09e-4049-a12f-4c505b2e983f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.155322.155322 cuda_h.py:19] end self_attn cost 0.005631446838378906 seconds
DEBUG 01-15 10:09:13.155420.155420 cuda_h.py:19] end iln_self_attn_paln cost 0.008137226104736328 seconds
DEBUG 01-15 10:09:13.156515.156515 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-15 10:09:13.156053.156053 cuda_h.py:10] start gate
DEBUG 01-15 10:09:13.156365.156365 cuda_h.py:19] end gate cost 0.0007486343383789062 seconds
DEBUG 01-15 10:09:13.156492.156492 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.157592.157592 lmp.py:1616] 
DEBUG 01-15 10:09:13.157592.157592 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.157553.157553 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.157740.157740 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.157635.157635 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.157669.157669 lmp.py:1620] 
DEBUG 01-15 10:09:13.157669.157669 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.157941.157941 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.157167.157167 lmp.py:1626]   Expert  5 |     14 | CPU
DEBUG 01-15 10:09:13.157963.157963 lmp.py:1626]   Expert 56 |     30 | CPU
DEBUG 01-15 10:09:13.157043.157043 lmp.py:1626]   Expert 27 |     84 | CPU
DEBUG 01-15 10:09:13.157123.157123 lmp.py:1626]   Expert 16 |     86 | CPU
DEBUG 01-15 10:09:13.157488.157488 lmp.py:1626]   Expert 17 |     87 | CPU
DEBUG 01-15 10:09:13.157853.157853 lmp.py:1626]   Expert 40 |     97 | CPU
DEBUG 01-15 10:09:13.157457.157457 lmp.py:1626]   Expert 49 |    104 | CPU
DEBUG 01-15 10:09:13.157060.157060 lmp.py:1626]   Expert 51 |    104 | CPU
DEBUG 01-15 10:09:13.157617.157617 lmp.py:1626]   Expert 63 |    104 | CPU
DEBUG 01-15 10:09:13.157174.157174 lmp.py:1626]   Expert 53 |    106 | CPU
DEBUG 01-15 10:09:13.157778.157778 lmp.py:1626]   Expert 28 |    110 | CPU
DEBUG 01-15 10:09:13.157904.157904 lmp.py:1626]   Expert  7 |    112 | CPU
DEBUG 01-15 10:09:13.157269.157269 lmp.py:1626]   Expert 47 |    120 | CPU
DEBUG 01-15 10:09:13.157396.157396 lmp.py:1626]   Expert 37 |    123 | CPU
DEBUG 01-15 10:09:13.157523.157523 lmp.py:1626]   Expert 38 |    124 | CPU
DEBUG 01-15 10:09:13.157649.157649 lmp.py:1626]   Expert 62 |    125 | CPU
DEBUG 01-15 10:09:13.157776.157776 lmp.py:1626]   Expert 11 |    127 | CPU
DEBUG 01-15 10:09:13.157902.157902 lmp.py:1626]   Expert 58 |    129 | CPU
DEBUG 01-15 10:09:13.157698.157698 lmp.py:1626]   Expert 57 |    135 | CPU
DEBUG 01-15 10:09:13.157255.157255 lmp.py:1626]   Expert 39 |    142 | CPU
DEBUG 01-15 10:09:13.157858.157858 lmp.py:1626]   Expert  1 |    145 | CPU
DEBUG 01-15 10:09:13.157985.157985 lmp.py:1626]   Expert 14 |    150 | CPU
DEBUG 01-15 10:09:13.158112.158112 lmp.py:1626]   Expert 25 |    155 | CPU
DEBUG 01-15 10:09:13.158238.158238 lmp.py:1626]   Expert 52 |    156 | CPU
DEBUG 01-15 10:09:13.158365.158365 lmp.py:1626]   Expert 23 |    158 | CPU
DEBUG 01-15 10:09:13.158491.158491 lmp.py:1626]   Expert 33 |    159 | CPU
DEBUG 01-15 10:09:13.158572.158572 lmp.py:1626]   Expert 21 |    165 | CPU
DEBUG 01-15 10:09:13.158652.158652 lmp.py:1626]   Expert 60 |    170 | CPU
DEBUG 01-15 10:09:13.158448.158448 lmp.py:1626]   Expert  6 |    172 | CPU
DEBUG 01-15 10:09:13.158528.158528 lmp.py:1626]   Expert 45 |    173 | CPU
DEBUG 01-15 10:09:13.158654.158654 lmp.py:1626]   Expert 19 |    181 | CPU
DEBUG 01-15 10:09:13.158781.158781 lmp.py:1626]   Expert 44 |    183 | CPU
DEBUG 01-15 10:09:13.158146.158146 lmp.py:1626]   Expert  4 |    184 | GPU
DEBUG 01-15 10:09:13.158034.158034 lmp.py:1626]   Expert 12 |    184 | GPU
DEBUG 01-15 10:09:13.158638.158638 lmp.py:1626]   Expert 31 |    196 | GPU
DEBUG 01-15 10:09:13.158526.158526 lmp.py:1626]   Expert  3 |    198 | GPU
DEBUG 01-15 10:09:13.158414.158414 lmp.py:1626]   Expert 30 |    199 | GPU
DEBUG 01-15 10:09:13.158793.158793 lmp.py:1626]   Expert 55 |    199 | GPU
DEBUG 01-15 10:09:13.158827.158827 lmp.py:1626]   Expert 36 |    203 | GPU
DEBUG 01-15 10:09:13.158192.158192 lmp.py:1626]   Expert  9 |    212 | GPU
DEBUG 01-15 10:09:13.158795.158795 lmp.py:1626]   Expert  0 |    221 | GPU
DEBUG 01-15 10:09:13.158922.158922 lmp.py:1626]   Expert 34 |    224 | GPU
DEBUG 01-15 10:09:13.158048.158048 lmp.py:1626]   Expert 22 |    227 | GPU
DEBUG 01-15 10:09:13.158413.158413 lmp.py:1626]   Expert 41 |    230 | GPU
DEBUG 01-15 10:09:13.158540.158540 lmp.py:1626]   Expert 54 |    230 | GPU
DEBUG 01-15 10:09:13.158382.158382 lmp.py:1626]   Expert 26 |    235 | GPU
DEBUG 01-15 10:09:13.158700.158700 lmp.py:1626]   Expert 43 |    239 | GPU
DEBUG 01-15 10:09:13.158019.158019 lmp.py:1626]   Expert 59 |    251 | GPU
DEBUG 01-15 10:09:13.158861.158861 lmp.py:1626]   Expert 13 |    254 | GPU
DEBUG 01-15 10:09:13.158988.158988 lmp.py:1626]   Expert 18 |    255 | GPU
DEBUG 01-15 10:09:13.158876.158876 lmp.py:1626]   Expert 50 |    255 | GPU
DEBUG 01-15 10:09:13.158002.158002 lmp.py:1626]   Expert 20 |    257 | GPU
DEBUG 01-15 10:09:13.158129.158129 lmp.py:1626]   Expert 15 |    260 | GPU
DEBUG 01-15 10:09:13.158017.158017 lmp.py:1626]   Expert 42 |    261 | GPU
DEBUG 01-15 10:09:13.158144.158144 lmp.py:1626]   Expert 24 |    264 | GPU
DEBUG 01-15 10:09:13.158032.158032 lmp.py:1626]   Expert 29 |    267 | GPU
DEBUG 01-15 10:09:13.158874.158874 lmp.py:1626]   Expert 61 |    271 | GPU
DEBUG 01-15 10:09:13.158716.158716 lmp.py:1626]   Expert 35 |    282 | GPU
DEBUG 01-15 10:09:13.158319.158319 lmp.py:1626]   Expert 32 |    307 | GPU
DEBUG 01-15 10:09:13.158446.158446 lmp.py:1626]   Expert 10 |    336 | GPU
DEBUG 01-15 10:09:13.158334.158334 lmp.py:1626]   Expert  8 |    339 | GPU
DEBUG 01-15 10:09:13.158461.158461 lmp.py:1626]   Expert  2 |    342 | GPU
DEBUG 01-15 10:09:13.158587.158587 lmp.py:1626]   Expert 46 |    426 | GPU
DEBUG 01-15 10:09:13.158475.158475 lmp.py:1626]   Expert 48 |    450 | GPU
DEBUG 01-15 10:09:13.159463.159463 lmp.py:1627] 
DEBUG 01-15 10:09:13.159463.159463 lmp.py:1627]   CPU total tokens: 4030 (32.8%)
DEBUG 01-15 10:09:13.159974.159974 lmp.py:1628]   GPU total tokens: 8258 (67.2%)
DEBUG 01-15 10:09:13.159968.159968 cuda_h.py:19] end experts_map_get cost 0.0021042823791503906 seconds
INFO 01-15 10:09:13.159714.159714 client.py:127] Model loaded
DEBUG 01-15 10:09:13.159109.159109 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.159403.159403 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.159716.159716 lmp.py:1636] 
DEBUG 01-15 10:09:13.159716.159716 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.159235.159235 cuda_h.py:19] end cpu_experts_submit cost 0.00028061866760253906 seconds
DEBUG 01-15 10:09:13.159706.159706 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.159192.159192 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.160537.160537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.160805.160805 cuda_h.py:19] end allocate_cuda_memory cost 0.00022339820861816406 seconds
DEBUG 01-15 10:09:13.160304.160304 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.160319.160319 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.161625.161625 cuda_h.py:19] end restore2model cost 0.001934051513671875 seconds
DEBUG 01-15 10:09:13.161880.161880 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.162618.162618 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 395ff81d-a0be-4279-8b17-f6fe7f5de9fa
DEBUG 01-15 10:09:13.162161.162161 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.162739.162739 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.162595.162595 cuda_h.py:19] end sllm_worker_task cost 0.014689922332763672 seconds
DEBUG 01-15 10:09:13.162094.162094 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.163479.163479 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 395ff81d-a0be-4279-8b17-f6fe7f5de9fa
DEBUG 01-15 10:09:13.163336.163336 cuda_h.py:19] end load_into_gpu_async cost 0.0030639171600341797 seconds
DEBUG 01-15 10:09:13.163860.163860 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.163352.163352 cuda_h.py:19] end move_flatidxs cost 0.0008993148803710938 seconds
DEBUG 01-15 10:09:13.163910.163910 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.164963.164963 cuda_h.py:19] end restore_tensors2 cost 0.0004627704620361328 seconds
DEBUG 01-15 10:09:13.164435.164435 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004255771636962891 seconds
DEBUG 01-15 10:09:13.164019.164019 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.166326.166326 cuda_h.py:19] end restore2model cost 0.0025827884674072266 seconds
DEBUG 01-15 10:09:13.166592.166592 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007050037384033203 seconds
DEBUG 01-15 10:09:13.166149.166149 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.167603.167603 cuda_h.py:19] end gpu_sexperts cost 0.00026917457580566406 seconds
DEBUG 01-15 10:09:13.167241.167241 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.168480.168480 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015802383422851562 seconds
DEBUG 01-15 10:09:13.169638.169638 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.169293.169293 cuda_h.py:19] end gpu_group_list cost 0.0003216266632080078 seconds
DEBUG 01-15 10:09:13.170819.170819 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.170737.170737 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006737709045410156 seconds
DEBUG 01-15 10:09:13.170076.170076 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:13.170230.170230 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-15 10:09:13.170880.170880 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.173312.173312 cuda_h.py:19] end group_tensors cost 0.009978294372558594 seconds
DEBUG 01-15 10:09:13.174905.174905 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.178637.178637 cuda_h.py:19] end group pad cost 0.004383563995361328 seconds
DEBUG 01-15 10:09:13.178294.178294 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.198839.198839 cuda_h.py:19] end group_einsum cost 0.019132614135742188 seconds
DEBUG 01-15 10:09:13.198606.198606 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.203936.203936 cuda_h.py:19] end get_outputs_cpu1 cost 0.004831790924072266 seconds
DEBUG 01-15 10:09:13.204882.204882 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.041635990142822266 seconds
DEBUG 01-15 10:09:13.205613.205613 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.034476518630981445 seconds
DEBUG 01-15 10:09:13.205468.205468 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.206590.206590 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.206301.206301 cuda_h.py:19] end index_scatter cost 0.0001647472381591797 seconds
DEBUG 01-15 10:09:13.207869.207869 cuda_h.py:19] end cpuoutputsdeal cost 0.0015976428985595703 seconds
DEBUG 01-15 10:09:13.207887.207887 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.207962.207962 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 395ff81d-a0be-4279-8b17-f6fe7f5de9fa
INFO 01-15 10:09:13.213348.213348 client.py:127] Model loaded
DEBUG 01-15 10:09:13.213300.213300 cuda_h.py:19] end wait_experts cost 0.0061187744140625 seconds
DEBUG 01-15 10:09:13.213017.213017 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.213439.213439 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.213356.213356 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.214874.214874 cuda_h.py:19] end gpu_group_tensor cost 0.0003731250762939453 seconds
DEBUG 01-15 10:09:13.214656.214656 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.215865.215865 cuda_h.py:19] end gpu_group_einsum cost 0.0009944438934326172 seconds
DEBUG 01-15 10:09:13.215250.215250 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.216161.216161 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.216082.216082 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005328655242919922 seconds
DEBUG 01-15 10:09:13.216999.216999 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.216488.216488 cuda_h.py:19] end concat_expert_out cost 0.0001163482666015625 seconds
DEBUG 01-15 10:09:13.217420.217420 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.217896.217896 cuda_h.py:19] end index_scatter cost 0.00010132789611816406 seconds
DEBUG 01-15 10:09:13.217335.217335 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001275777816772461 seconds
DEBUG 01-15 10:09:13.217340.217340 cuda_h.py:19] end gpu_experts cost 0.0036444664001464844 seconds
DEBUG 01-15 10:09:13.217372.217372 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06153988838195801 seconds
DEBUG 01-15 10:09:13.218838.218838 cuda_h.py:19] end prefill_layer cost 0.07142043113708496 seconds
DEBUG 01-15 10:09:13.218186.218186 lmp.py:1552] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-15 10:09:13.218698.218698 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.218449.218449 lmp.py:1495] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-15 10:09:13.218914.218914 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:13.218387.218387 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:13.218755.218755 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.0558319091796875e-05 seconds
DEBUG 01-15 10:09:13.218641.218641 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:13.219750.219750 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00030732154846191406 seconds
DEBUG 01-15 10:09:13.219696.219696 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.219066.219066 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.219165.219165 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.220080.220080 cuda_h.py:19] end allocate_cuda_memory cost 0.0004162788391113281 seconds
DEBUG 01-15 10:09:13.220867.220867 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.220116.220116 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.220464.220464 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.220712.220712 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f02ed93-a3f4-47b0-8f89-cb79d5b3dcfe
DEBUG 01-15 10:09:13.220176.220176 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.221464.221464 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:13.221703.221703 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f02ed93-a3f4-47b0-8f89-cb79d5b3dcfe
DEBUG 01-15 10:09:13.222549.222549 cuda_h.py:19] end load_into_gpu_async cost 0.001651763916015625 seconds
DEBUG 01-15 10:09:13.222651.222651 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.222195.222195 cuda_h.py:19] end restore_tensors2 cost 0.00015020370483398438 seconds
DEBUG 01-15 10:09:13.222363.222363 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003006458282470703 seconds
DEBUG 01-15 10:09:13.222620.222620 cuda_h.py:10] start self_attn
INFO 01-15 10:09:13.222777.222777 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f02ed93-a3f4-47b0-8f89-cb79d5b3dcfe
INFO 01-15 10:09:13.228081.228081 client.py:127] Model loaded
DEBUG 01-15 10:09:13.229190.229190 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.230796.230796 cuda_h.py:19] end restore2model cost 0.0009887218475341797 seconds
DEBUG 01-15 10:09:13.230475.230475 cuda_h.py:19] end sllm_worker_task cost 0.011022329330444336 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.234644.234644 cuda_h.py:19] end self_attn cost 0.011711597442626953 seconds
DEBUG 01-15 10:09:13.235965.235965 cuda_h.py:19] end iln_self_attn_paln cost 0.01582789421081543 seconds
DEBUG 01-15 10:09:13.235493.235493 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-15 10:09:13.235892.235892 cuda_h.py:10] start gate
DEBUG 01-15 10:09:13.236369.236369 cuda_h.py:19] end gate cost 0.0007605552673339844 seconds
DEBUG 01-15 10:09:13.236835.236835 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.236637.236637 lmp.py:1616] 
DEBUG 01-15 10:09:13.236637.236637 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.237929.237929 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.237639.237639 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.237296.237296 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.237330.237330 lmp.py:1620] 
DEBUG 01-15 10:09:13.237330.237330 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.237648.237648 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.237921.237921 lmp.py:1626]   Expert 36 |     20 | CPU
DEBUG 01-15 10:09:13.237762.237762 lmp.py:1626]   Expert 35 |     31 | CPU
DEBUG 01-15 10:09:13.237889.237889 lmp.py:1626]   Expert 25 |     45 | CPU
DEBUG 01-15 10:09:13.237300.237300 lmp.py:1626]   Expert 46 |     46 | CPU
DEBUG 01-15 10:09:13.237189.237189 lmp.py:1626]   Expert 51 |     52 | CPU
DEBUG 01-15 10:09:13.237838.237838 lmp.py:1626]   Expert 16 |     61 | CPU
DEBUG 01-15 10:09:13.237488.237488 lmp.py:1626]   Expert 30 |     63 | CPU
DEBUG 01-15 10:09:13.237138.237138 lmp.py:1626]   Expert  0 |     64 | CPU
DEBUG 01-15 10:09:13.237695.237695 lmp.py:1626]   Expert 47 |     68 | CPU
DEBUG 01-15 10:09:13.237014.237014 lmp.py:1626]   Expert 43 |     70 | CPU
DEBUG 01-15 10:09:13.237140.237140 lmp.py:1626]   Expert 55 |     71 | CPU
DEBUG 01-15 10:09:13.237790.237790 lmp.py:1626]   Expert 42 |     73 | CPU
DEBUG 01-15 10:09:13.237963.237963 lmp.py:1626]   Expert 44 |     74 | CPU
DEBUG 01-15 10:09:13.237136.237136 lmp.py:1626]   Expert 39 |     75 | CPU
DEBUG 01-15 10:09:13.237547.237547 lmp.py:1626]   Expert  2 |     83 | CPU
DEBUG 01-15 10:09:13.237959.237959 lmp.py:1626]   Expert  4 |    104 | CPU
DEBUG 01-15 10:09:13.237370.237370 lmp.py:1626]   Expert 48 |    118 | CPU
DEBUG 01-15 10:09:13.237543.237543 lmp.py:1626]   Expert 33 |    119 | CPU
DEBUG 01-15 10:09:13.237438.237438 lmp.py:1626]   Expert  6 |    124 | CPU
DEBUG 01-15 10:09:13.237280.237280 lmp.py:1626]   Expert 13 |    125 | CPU
DEBUG 01-15 10:09:13.237360.237360 lmp.py:1626]   Expert 24 |    125 | CPU
DEBUG 01-15 10:09:13.237010.237010 lmp.py:1626]   Expert 61 |    126 | CPU
DEBUG 01-15 10:09:13.237421.237421 lmp.py:1626]   Expert 56 |    129 | CPU
DEBUG 01-15 10:09:13.237594.237594 lmp.py:1626]   Expert 29 |    131 | CPU
DEBUG 01-15 10:09:13.237005.237005 lmp.py:1626]   Expert 15 |    135 | CPU
DEBUG 01-15 10:09:13.237655.237655 lmp.py:1626]   Expert 54 |    142 | CPU
DEBUG 01-15 10:09:13.237066.237066 lmp.py:1626]   Expert  9 |    143 | CPU
DEBUG 01-15 10:09:13.237478.237478 lmp.py:1626]   Expert 38 |    145 | CPU
DEBUG 01-15 10:09:13.237273.237273 lmp.py:1626]   Expert  7 |    147 | CPU
DEBUG 01-15 10:09:13.237830.237830 lmp.py:1626]   Expert 20 |    147 | CPU
DEBUG 01-15 10:09:13.237911.237911 lmp.py:1626]   Expert 59 |    150 | CPU
DEBUG 01-15 10:09:13.237084.237084 lmp.py:1626]   Expert 62 |    156 | CPU
DEBUG 01-15 10:09:13.237495.237495 lmp.py:1626]   Expert 19 |    158 | GPU
DEBUG 01-15 10:09:13.237668.237668 lmp.py:1626]   Expert 45 |    160 | GPU
DEBUG 01-15 10:09:13.237841.237841 lmp.py:1626]   Expert 34 |    188 | GPU
DEBUG 01-15 10:09:13.237014.237014 lmp.py:1626]   Expert 57 |    192 | GPU
DEBUG 01-15 10:09:13.237664.237664 lmp.py:1626]   Expert 50 |    194 | GPU
DEBUG 01-15 10:09:13.238075.238075 lmp.py:1626]   Expert 31 |    199 | GPU
DEBUG 01-15 10:09:13.238155.238155 lmp.py:1626]   Expert 10 |    202 | GPU
DEBUG 01-15 10:09:13.238997.238997 lmp.py:1626]   Expert 23 |    208 | GPU
DEBUG 01-15 10:09:13.238647.238647 lmp.py:1626]   Expert  8 |    210 | GPU
DEBUG 01-15 10:09:13.238058.238058 lmp.py:1626]   Expert 60 |    218 | GPU
DEBUG 01-15 10:09:13.238470.238470 lmp.py:1626]   Expert 18 |    219 | GPU
DEBUG 01-15 10:09:13.238404.238404 lmp.py:1626]   Expert 53 |    219 | GPU
DEBUG 01-15 10:09:13.238339.238339 lmp.py:1626]   Expert 22 |    221 | GPU
DEBUG 01-15 10:09:13.238035.238035 lmp.py:1626]   Expert 52 |    225 | GPU
DEBUG 01-15 10:09:13.238446.238446 lmp.py:1626]   Expert 37 |    233 | GPU
DEBUG 01-15 10:09:13.238049.238049 lmp.py:1626]   Expert  5 |    240 | GPU
DEBUG 01-15 10:09:13.238891.238891 lmp.py:1626]   Expert 17 |    242 | GPU
DEBUG 01-15 10:09:13.238256.238256 lmp.py:1626]   Expert 11 |    251 | GPU
DEBUG 01-15 10:09:13.238383.238383 lmp.py:1626]   Expert  1 |    270 | GPU
DEBUG 01-15 10:09:13.238841.238841 lmp.py:1626]   Expert 49 |    276 | GPU
DEBUG 01-15 10:09:13.238252.238252 lmp.py:1626]   Expert 41 |    282 | GPU
DEBUG 01-15 10:09:13.238186.238186 lmp.py:1626]   Expert 26 |    287 | GPU
DEBUG 01-15 10:09:13.238121.238121 lmp.py:1626]   Expert 28 |    289 | GPU
DEBUG 01-15 10:09:13.238055.238055 lmp.py:1626]   Expert 32 |    292 | GPU
DEBUG 01-15 10:09:13.238990.238990 lmp.py:1626]   Expert 58 |    297 | GPU
DEBUG 01-15 10:09:13.238924.238924 lmp.py:1626]   Expert 40 |    304 | GPU
DEBUG 01-15 10:09:13.238289.238289 lmp.py:1626]   Expert 14 |    308 | GPU
DEBUG 01-15 10:09:13.238416.238416 lmp.py:1626]   Expert 12 |    334 | GPU
DEBUG 01-15 10:09:13.238827.238827 lmp.py:1626]   Expert 63 |    337 | GPU
DEBUG 01-15 10:09:13.238762.238762 lmp.py:1626]   Expert 21 |    390 | GPU
DEBUG 01-15 10:09:13.238696.238696 lmp.py:1626]   Expert 27 |    663 | GPU
DEBUG 01-15 10:09:13.238869.238869 lmp.py:1626]   Expert  3 |   1018 | GPU
DEBUG 01-15 10:09:13.238234.238234 lmp.py:1627] 
DEBUG 01-15 10:09:13.238234.238234 lmp.py:1627]   CPU total tokens: 3162 (25.7%)
DEBUG 01-15 10:09:13.238076.238076 lmp.py:1628]   GPU total tokens: 9126 (74.3%)
DEBUG 01-15 10:09:13.238163.238163 cuda_h.py:19] end experts_map_get cost 0.0020644664764404297 seconds
DEBUG 01-15 10:09:13.238795.238795 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.238803.238803 lmp.py:1636] 
DEBUG 01-15 10:09:13.238803.238803 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.238435.238435 cuda_h.py:19] end cpu_experts_submit cost 7.867813110351562e-05 seconds
DEBUG 01-15 10:09:13.238807.238807 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.238293.238293 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.239427.239427 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.239205.239205 cuda_h.py:19] end allocate_cuda_memory cost 0.0002467632293701172 seconds
DEBUG 01-15 10:09:13.239929.239929 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.239414.239414 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.240014.240014 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.240103.240103 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 751ba2d4-fe07-4668-851a-16dea0873079
DEBUG 01-15 10:09:13.240874.240874 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.241502.241502 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.241968.241968 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.242270.242270 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 751ba2d4-fe07-4668-851a-16dea0873079
DEBUG 01-15 10:09:13.243845.243845 cuda_h.py:19] end load_into_gpu_async cost 0.0033545494079589844 seconds
DEBUG 01-15 10:09:13.243821.243821 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.243274.243274 cuda_h.py:19] end move_flatidxs cost 0.0010876655578613281 seconds
DEBUG 01-15 10:09:13.243113.243113 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.244462.244462 cuda_h.py:19] end restore_tensors2 cost 0.0008466243743896484 seconds
DEBUG 01-15 10:09:13.244426.244426 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005117893218994141 seconds
DEBUG 01-15 10:09:13.244222.244222 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.247986.247986 cuda_h.py:19] end restore2model cost 0.0029859542846679688 seconds
DEBUG 01-15 10:09:13.247498.247498 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008345365524291992 seconds
DEBUG 01-15 10:09:13.247055.247055 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.247132.247132 cuda_h.py:19] end gpu_sexperts cost 0.0003058910369873047 seconds
DEBUG 01-15 10:09:13.247015.247015 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.249669.249669 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014994144439697266 seconds
DEBUG 01-15 10:09:13.249833.249833 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.250422.250422 cuda_h.py:19] end gpu_group_list cost 0.0003173351287841797 seconds
DEBUG 01-15 10:09:13.250869.250869 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.251617.251617 cuda_h.py:19] end acpu_expert_weight_slices cost 0.000720977783203125 seconds
DEBUG 01-15 10:09:13.251439.251439 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:13.251931.251931 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.71661376953125e-05 seconds
DEBUG 01-15 10:09:13.251819.251819 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.259868.259868 cuda_h.py:19] end group_tensors cost 0.015743732452392578 seconds
DEBUG 01-15 10:09:13.259314.259314 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.264527.264527 cuda_h.py:19] end group pad cost 0.004307270050048828 seconds
DEBUG 01-15 10:09:13.264550.264550 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.286730.286730 cuda_h.py:19] end group_einsum cost 0.021922826766967773 seconds
DEBUG 01-15 10:09:13.286332.286332 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.291942.291942 cuda_h.py:19] end get_outputs_cpu1 cost 0.004908561706542969 seconds
DEBUG 01-15 10:09:13.292689.292689 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05109691619873047 seconds
DEBUG 01-15 10:09:13.293645.293645 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04199504852294922 seconds
DEBUG 01-15 10:09:13.293877.293877 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.294901.294901 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.294779.294779 cuda_h.py:19] end index_scatter cost 0.0001666545867919922 seconds
DEBUG 01-15 10:09:13.294557.294557 cuda_h.py:19] end cpuoutputsdeal cost 0.0012054443359375 seconds
DEBUG 01-15 10:09:13.295806.295806 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.295736.295736 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 751ba2d4-fe07-4668-851a-16dea0873079
INFO 01-15 10:09:13.296199.296199 client.py:127] Model loaded
DEBUG 01-15 10:09:13.296336.296336 cuda_h.py:19] end wait_experts cost 0.0014998912811279297 seconds
DEBUG 01-15 10:09:13.296053.296053 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.296045.296045 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.296630.296630 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.297380.297380 cuda_h.py:19] end gpu_group_tensor cost 0.0003705024719238281 seconds
DEBUG 01-15 10:09:13.297547.297547 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.298283.298283 cuda_h.py:19] end gpu_group_einsum cost 0.0010976791381835938 seconds
DEBUG 01-15 10:09:13.299708.299708 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.299063.299063 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.299893.299893 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005664825439453125 seconds
DEBUG 01-15 10:09:13.299286.299286 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.300366.300366 cuda_h.py:19] end concat_expert_out cost 0.0001246929168701172 seconds
DEBUG 01-15 10:09:13.300794.300794 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.300782.300782 cuda_h.py:19] end index_scatter cost 0.00014829635620117188 seconds
DEBUG 01-15 10:09:13.300395.300395 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014262199401855469 seconds
DEBUG 01-15 10:09:13.300281.300281 cuda_h.py:19] end gpu_experts cost 0.0039594173431396484 seconds
DEBUG 01-15 10:09:13.300916.300916 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.0652155876159668 seconds
DEBUG 01-15 10:09:13.301538.301538 cuda_h.py:19] end prefill_layer cost 0.08316564559936523 seconds
DEBUG 01-15 10:09:13.301893.301893 lmp.py:1552] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-15 10:09:13.301843.301843 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.301792.301792 lmp.py:1495] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-15 10:09:13.302364.302364 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:13.302565.302565 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:13.302054.302054 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:13.302621.302621 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:13.302386.302386 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.00032067298889160156 seconds
DEBUG 01-15 10:09:13.302969.302969 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.302058.302058 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.302322.302322 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.303157.303157 cuda_h.py:19] end allocate_cuda_memory cost 0.0004165172576904297 seconds
DEBUG 01-15 10:09:13.303628.303628 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:13.303115.303115 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.304189.304189 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.304875.304875 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.304315.304315 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fa5ae1d6-a308-42ac-b703-5eb243088508
DEBUG 01-15 10:09:13.304329.304329 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.305624.305624 cuda_h.py:10] start self_attn
INFO 01-15 10:09:13.305648.305648 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fa5ae1d6-a308-42ac-b703-5eb243088508
DEBUG 01-15 10:09:13.305838.305838 cuda_h.py:19] end load_into_gpu_async cost 0.0015993118286132812 seconds
DEBUG 01-15 10:09:13.305848.305848 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.306637.306637 cuda_h.py:19] end restore_tensors2 cost 0.0001544952392578125 seconds
DEBUG 01-15 10:09:13.306282.306282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003215789794921875 seconds
INFO 01-15 10:09:13.306215.306215 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fa5ae1d6-a308-42ac-b703-5eb243088508
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.310110.310110 cuda_h.py:19] end self_attn cost 0.005283355712890625 seconds
DEBUG 01-15 10:09:13.311045.311045 cuda_h.py:19] end iln_self_attn_paln cost 0.008044719696044922 seconds
DEBUG 01-15 10:09:13.311022.311022 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-15 10:09:13.311480.311480 cuda_h.py:10] start gate
DEBUG 01-15 10:09:13.312915.312915 cuda_h.py:19] end gate cost 0.0008618831634521484 seconds
DEBUG 01-15 10:09:13.312348.312348 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.312372.312372 lmp.py:1616] 
DEBUG 01-15 10:09:13.312372.312372 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.312162.312162 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.312362.312362 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.312648.312648 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.312119.312119 lmp.py:1620] 
DEBUG 01-15 10:09:13.312119.312119 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.312305.312305 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.312923.312923 lmp.py:1626]   Expert 13 |     28 | CPU
DEBUG 01-15 10:09:13.313063.313063 lmp.py:1626]   Expert  9 |     40 | CPU
DEBUG 01-15 10:09:13.313488.313488 lmp.py:1626]   Expert 25 |     40 | CPU
DEBUG 01-15 10:09:13.313197.313197 lmp.py:1626]   Expert 44 |     41 | CPU
DEBUG 01-15 10:09:13.313337.313337 lmp.py:1626]   Expert 16 |     46 | CPU
DEBUG 01-15 10:09:13.313332.313332 lmp.py:1626]   Expert 38 |     47 | CPU
DEBUG 01-15 10:09:13.313565.313565 lmp.py:1626]   Expert 22 |     54 | CPU
DEBUG 01-15 10:09:13.313321.313321 lmp.py:1626]   Expert  2 |     55 | CPU
DEBUG 01-15 10:09:13.313077.313077 lmp.py:1626]   Expert 33 |     57 | CPU
INFO 01-15 10:09:13.313399.313399 client.py:127] Model loaded
DEBUG 01-15 10:09:13.313516.313516 lmp.py:1626]   Expert 42 |     62 | CPU
DEBUG 01-15 10:09:13.313009.313009 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.313792.313792 lmp.py:1626]   Expert  5 |     66 | CPU
DEBUG 01-15 10:09:13.313499.313499 lmp.py:1626]   Expert 23 |     79 | CPU
DEBUG 01-15 10:09:13.313023.313023 lmp.py:1626]   Expert 24 |     81 | CPU
DEBUG 01-15 10:09:13.314971.314971 lmp.py:1626]   Expert 10 |     85 | CPU
DEBUG 01-15 10:09:13.314204.314204 lmp.py:1626]   Expert 59 |    100 | CPU
DEBUG 01-15 10:09:13.314914.314914 lmp.py:1626]   Expert 21 |    107 | CPU
DEBUG 01-15 10:09:13.314862.314862 lmp.py:1626]   Expert 45 |    116 | CPU
DEBUG 01-15 10:09:13.314856.314856 lmp.py:1626]   Expert 46 |    116 | CPU
DEBUG 01-15 10:09:13.314850.314850 lmp.py:1626]   Expert 55 |    116 | CPU
DEBUG 01-15 10:09:13.314083.314083 lmp.py:1626]   Expert 61 |    122 | CPU
DEBUG 01-15 10:09:13.314508.314508 lmp.py:1626]   Expert 31 |    127 | CPU
DEBUG 01-15 10:09:13.314503.314503 lmp.py:1626]   Expert 51 |    138 | CPU
DEBUG 01-15 10:09:13.314497.314497 lmp.py:1626]   Expert  6 |    141 | CPU
DEBUG 01-15 10:09:13.314922.314922 lmp.py:1626]   Expert 36 |    141 | CPU
DEBUG 01-15 10:09:13.314678.314678 lmp.py:1626]   Expert  8 |    143 | CPU
DEBUG 01-15 10:09:13.314434.314434 lmp.py:1626]   Expert 43 |    146 | CPU
DEBUG 01-15 10:09:13.314859.314859 lmp.py:1626]   Expert  3 |    149 | CPU
DEBUG 01-15 10:09:13.314092.314092 lmp.py:1626]   Expert  0 |    152 | CPU
DEBUG 01-15 10:09:13.314086.314086 lmp.py:1626]   Expert 18 |    156 | CPU
DEBUG 01-15 10:09:13.314604.314604 lmp.py:1626]   Expert 48 |    159 | CPU
DEBUG 01-15 10:09:13.314121.314121 lmp.py:1626]   Expert 26 |    160 | CPU
DEBUG 01-15 10:09:13.314639.314639 lmp.py:1626]   Expert 41 |    167 | CPU
DEBUG 01-15 10:09:13.314918.314918 lmp.py:1626]   Expert 12 |    176 | GPU
DEBUG 01-15 10:09:13.314959.314959 lmp.py:1626]   Expert  7 |    177 | GPU
DEBUG 01-15 10:09:13.314000.314000 lmp.py:1626]   Expert 20 |    185 | GPU
DEBUG 01-15 10:09:13.314517.314517 lmp.py:1626]   Expert 28 |    187 | GPU
DEBUG 01-15 10:09:13.314035.314035 lmp.py:1626]   Expert 56 |    189 | GPU
DEBUG 01-15 10:09:13.314791.314791 lmp.py:1626]   Expert  1 |    191 | GPU
DEBUG 01-15 10:09:13.314308.314308 lmp.py:1626]   Expert 27 |    192 | GPU
DEBUG 01-15 10:09:13.314826.314826 lmp.py:1626]   Expert 34 |    194 | GPU
DEBUG 01-15 10:09:13.314820.314820 lmp.py:1626]   Expert 47 |    202 | GPU
DEBUG 01-15 10:09:13.314530.314530 lmp.py:1626]   Expert 32 |    213 | GPU
DEBUG 01-15 10:09:13.314048.314048 lmp.py:1626]   Expert 11 |    218 | GPU
DEBUG 01-15 10:09:13.314565.314565 lmp.py:1626]   Expert 40 |    227 | GPU
DEBUG 01-15 10:09:13.314083.314083 lmp.py:1626]   Expert 53 |    233 | GPU
DEBUG 01-15 10:09:13.315077.315077 lmp.py:1626]   Expert 49 |    234 | GPU
DEBUG 01-15 10:09:13.315264.315264 lmp.py:1626]   Expert 63 |    240 | GPU
DEBUG 01-15 10:09:13.315781.315781 lmp.py:1626]   Expert 50 |    244 | GPU
DEBUG 01-15 10:09:13.315060.315060 lmp.py:1626]   Expert 29 |    245 | GPU
DEBUG 01-15 10:09:13.315578.315578 lmp.py:1626]   Expert  4 |    246 | GPU
DEBUG 01-15 10:09:13.315334.315334 lmp.py:1626]   Expert 15 |    246 | GPU
DEBUG 01-15 10:09:13.315090.315090 lmp.py:1626]   Expert 30 |    249 | GPU
DEBUG 01-15 10:09:13.315276.315276 lmp.py:1626]   Expert 35 |    273 | GPU
DEBUG 01-15 10:09:13.315032.315032 lmp.py:1626]   Expert 14 |    275 | GPU
DEBUG 01-15 10:09:13.315027.315027 lmp.py:1626]   Expert 37 |    303 | GPU
DEBUG 01-15 10:09:13.315306.315306 lmp.py:1626]   Expert 52 |    338 | GPU
DEBUG 01-15 10:09:13.315400.315400 lmp.py:1626]   Expert 17 |    360 | GPU
DEBUG 01-15 10:09:13.315156.315156 lmp.py:1626]   Expert 54 |    380 | GPU
DEBUG 01-15 10:09:13.315912.315912 lmp.py:1626]   Expert 39 |    387 | GPU
DEBUG 01-15 10:09:13.315191.315191 lmp.py:1626]   Expert 57 |    412 | GPU
DEBUG 01-15 10:09:13.315470.315470 lmp.py:1626]   Expert 60 |    457 | GPU
DEBUG 01-15 10:09:13.315988.315988 lmp.py:1626]   Expert 62 |    461 | GPU
DEBUG 01-15 10:09:13.315413.315413 lmp.py:1626]   Expert 19 |    543 | GPU
DEBUG 01-15 10:09:13.315122.315122 lmp.py:1626]   Expert 58 |    574 | GPU
DEBUG 01-15 10:09:13.315978.315978 lmp.py:1627] 
DEBUG 01-15 10:09:13.315978.315978 lmp.py:1627]   CPU total tokens: 3237 (26.3%)
DEBUG 01-15 10:09:13.315787.315787 lmp.py:1628]   GPU total tokens: 9051 (73.7%)
DEBUG 01-15 10:09:13.315987.315987 cuda_h.py:19] end experts_map_get cost 0.0034050941467285156 seconds
DEBUG 01-15 10:09:13.316318.316318 cuda_h.py:19] end restore2model cost 0.0029458999633789062 seconds
DEBUG 01-15 10:09:13.316706.316706 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.316271.316271 cuda_h.py:19] end sllm_worker_task cost 0.014177560806274414 seconds
DEBUG 01-15 10:09:13.316141.316141 lmp.py:1636] 
DEBUG 01-15 10:09:13.316141.316141 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.317948.317948 cuda_h.py:19] end cpu_experts_submit cost 0.0001780986785888672 seconds
DEBUG 01-15 10:09:13.317267.317267 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.317302.317302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.317898.317898 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.317840.317840 cuda_h.py:19] end allocate_cuda_memory cost 0.0002014636993408203 seconds
DEBUG 01-15 10:09:13.318724.318724 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.318216.318216 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.318178.318178 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.318549.318549 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5e3802b0-8151-4b74-830d-5357b1fdd646
DEBUG 01-15 10:09:13.318005.318005 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.318967.318967 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.318839.318839 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.319624.319624 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5e3802b0-8151-4b74-830d-5357b1fdd646
DEBUG 01-15 10:09:13.319745.319745 cuda_h.py:19] end load_into_gpu_async cost 0.0013725757598876953 seconds
DEBUG 01-15 10:09:13.319018.319018 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.319362.319362 cuda_h.py:19] end move_flatidxs cost 0.0009150505065917969 seconds
DEBUG 01-15 10:09:13.319298.319298 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.319117.319117 cuda_h.py:19] end restore_tensors2 cost 0.0003631114959716797 seconds
DEBUG 01-15 10:09:13.320893.320893 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002797842025756836 seconds
DEBUG 01-15 10:09:13.320616.320616 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.322024.322024 cuda_h.py:19] end restore2model cost 0.0026574134826660156 seconds
DEBUG 01-15 10:09:13.322490.322490 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005654335021972656 seconds
DEBUG 01-15 10:09:13.322875.322875 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.323799.323799 cuda_h.py:19] end gpu_sexperts cost 0.00026535987854003906 seconds
DEBUG 01-15 10:09:13.323152.323152 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.324645.324645 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014510154724121094 seconds
DEBUG 01-15 10:09:13.325055.325055 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.325988.325988 cuda_h.py:19] end gpu_group_list cost 0.0003228187561035156 seconds
DEBUG 01-15 10:09:13.325475.325475 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.326851.326851 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006892681121826172 seconds
DEBUG 01-15 10:09:13.326812.326812 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:13.326019.326019 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-15 10:09:13.326384.326384 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.329181.329181 cuda_h.py:19] end group_tensors cost 0.009525537490844727 seconds
DEBUG 01-15 10:09:13.329503.329503 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.333312.333312 cuda_h.py:19] end group pad cost 0.003723621368408203 seconds
DEBUG 01-15 10:09:13.333970.333970 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.353010.353010 cuda_h.py:19] end group_einsum cost 0.02008962631225586 seconds
DEBUG 01-15 10:09:13.354585.354585 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.358130.358130 cuda_h.py:19] end get_outputs_cpu1 cost 0.004319429397583008 seconds
DEBUG 01-15 10:09:13.359499.359499 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04098248481750488 seconds
DEBUG 01-15 10:09:13.360145.360145 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03390979766845703 seconds
DEBUG 01-15 10:09:13.360542.360542 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.361721.361721 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.361339.361339 cuda_h.py:19] end index_scatter cost 0.00014209747314453125 seconds
DEBUG 01-15 10:09:13.362926.362926 cuda_h.py:19] end cpuoutputsdeal cost 0.0011126995086669922 seconds
DEBUG 01-15 10:09:13.362525.362525 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.362581.362581 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5e3802b0-8151-4b74-830d-5357b1fdd646
INFO 01-15 10:09:13.369365.369365 client.py:127] Model loaded
DEBUG 01-15 10:09:13.369595.369595 cuda_h.py:19] end wait_experts cost 0.007142543792724609 seconds
DEBUG 01-15 10:09:13.369120.369120 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.369489.369489 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.369736.369736 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.370341.370341 cuda_h.py:19] end gpu_group_tensor cost 0.00036907196044921875 seconds
DEBUG 01-15 10:09:13.370514.370514 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.371530.371530 cuda_h.py:19] end gpu_group_einsum cost 0.0011627674102783203 seconds
DEBUG 01-15 10:09:13.371909.371909 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.372125.372125 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.372135.372135 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005903244018554688 seconds
DEBUG 01-15 10:09:13.372912.372912 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.372191.372191 cuda_h.py:19] end concat_expert_out cost 0.00012803077697753906 seconds
DEBUG 01-15 10:09:13.373527.373527 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.373402.373402 cuda_h.py:19] end index_scatter cost 0.00012111663818359375 seconds
DEBUG 01-15 10:09:13.373623.373623 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014450550079345703 seconds
DEBUG 01-15 10:09:13.373318.373318 cuda_h.py:19] end gpu_experts cost 0.0040416717529296875 seconds
DEBUG 01-15 10:09:13.373569.373569 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.0625605583190918 seconds
DEBUG 01-15 10:09:13.374442.374442 cuda_h.py:19] end prefill_layer cost 0.07259202003479004 seconds
DEBUG 01-15 10:09:13.374498.374498 lmp.py:1552] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-15 10:09:13.374302.374302 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.374728.374728 lmp.py:1495] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-15 10:09:13.374061.374061 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:13.374978.374978 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:13.375943.375943 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:13.375383.375383 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.00015997886657714844 seconds
DEBUG 01-15 10:09:13.375446.375446 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:13.375397.375397 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.375913.375913 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.375662.375662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.376150.376150 cuda_h.py:19] end allocate_cuda_memory cost 0.00043082237243652344 seconds
DEBUG 01-15 10:09:13.376057.376057 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.376001.376001 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.376608.376608 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.376809.376809 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 701031c3-ca39-4d5e-8054-af3d451b98cc
DEBUG 01-15 10:09:13.377034.377034 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.377885.377885 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:13.377472.377472 cuda_h.py:10] start self_attn
INFO 01-15 10:09:13.378388.378388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 701031c3-ca39-4d5e-8054-af3d451b98cc
DEBUG 01-15 10:09:13.378949.378949 cuda_h.py:19] end load_into_gpu_async cost 0.001615762710571289 seconds
DEBUG 01-15 10:09:13.378105.378105 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.378715.378715 cuda_h.py:19] end restore_tensors2 cost 0.0001556873321533203 seconds
DEBUG 01-15 10:09:13.378030.378030 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029189586639404297 seconds
INFO 01-15 10:09:13.378372.378372 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 701031c3-ca39-4d5e-8054-af3d451b98cc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.383792.383792 cuda_h.py:19] end self_attn cost 0.005516529083251953 seconds
DEBUG 01-15 10:09:13.383279.383279 cuda_h.py:19] end iln_self_attn_paln cost 0.008269786834716797 seconds
DEBUG 01-15 10:09:13.384269.384269 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-15 10:09:13.384166.384166 cuda_h.py:10] start gate
INFO 01-15 10:09:13.384629.384629 client.py:127] Model loaded
DEBUG 01-15 10:09:13.385640.385640 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.386095.386095 cuda_h.py:19] end restore2model cost 0.0010576248168945312 seconds
DEBUG 01-15 10:09:13.386848.386848 cuda_h.py:19] end sllm_worker_task cost 0.010750770568847656 seconds
DEBUG 01-15 10:09:13.386426.386426 cuda_h.py:19] end gate cost 0.00238037109375 seconds
DEBUG 01-15 10:09:13.386276.386276 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.386108.386108 lmp.py:1616] 
DEBUG 01-15 10:09:13.386108.386108 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.386772.386772 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.387090.387090 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.387786.387786 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.387383.387383 lmp.py:1620] 
DEBUG 01-15 10:09:13.387383.387383 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.387980.387980 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.387768.387768 lmp.py:1626]   Expert 20 |     11 | CPU
DEBUG 01-15 10:09:13.387080.387080 lmp.py:1626]   Expert 61 |     11 | CPU
DEBUG 01-15 10:09:13.387438.387438 lmp.py:1626]   Expert 11 |     29 | CPU
DEBUG 01-15 10:09:13.387797.387797 lmp.py:1626]   Expert  7 |     36 | CPU
DEBUG 01-15 10:09:13.387678.387678 lmp.py:1626]   Expert 51 |     44 | CPU
DEBUG 01-15 10:09:13.387228.387228 lmp.py:1626]   Expert 62 |     44 | CPU
DEBUG 01-15 10:09:13.387017.387017 lmp.py:1626]   Expert  3 |     45 | CPU
DEBUG 01-15 10:09:13.387806.387806 lmp.py:1626]   Expert 30 |     50 | CPU
DEBUG 01-15 10:09:13.387164.387164 lmp.py:1626]   Expert 17 |     53 | CPU
DEBUG 01-15 10:09:13.387284.387284 lmp.py:1626]   Expert 29 |     54 | CPU
DEBUG 01-15 10:09:13.387927.387927 lmp.py:1626]   Expert  6 |     60 | CPU
DEBUG 01-15 10:09:13.387808.387808 lmp.py:1626]   Expert  9 |     67 | CPU
DEBUG 01-15 10:09:13.387451.387451 lmp.py:1626]   Expert 38 |     77 | CPU
DEBUG 01-15 10:09:13.387094.387094 lmp.py:1626]   Expert 63 |     77 | CPU
DEBUG 01-15 10:09:13.387976.387976 lmp.py:1626]   Expert 55 |     84 | CPU
DEBUG 01-15 10:09:13.387857.387857 lmp.py:1626]   Expert 59 |     88 | CPU
DEBUG 01-15 10:09:13.387262.387262 lmp.py:1626]   Expert  8 |     93 | CPU
DEBUG 01-15 10:09:13.387905.387905 lmp.py:1626]   Expert 48 |     93 | CPU
DEBUG 01-15 10:09:13.387786.387786 lmp.py:1626]   Expert 19 |     97 | CPU
DEBUG 01-15 10:09:13.387667.387667 lmp.py:1626]   Expert 49 |    102 | CPU
DEBUG 01-15 10:09:13.387218.387218 lmp.py:1626]   Expert 22 |    103 | CPU
DEBUG 01-15 10:09:13.387291.387291 lmp.py:1626]   Expert 24 |    111 | CPU
DEBUG 01-15 10:09:13.387934.387934 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:13.387577.387577 lmp.py:1626]   Expert 34 |    116 | CPU
DEBUG 01-15 10:09:13.387220.387220 lmp.py:1626]   Expert 42 |    117 | CPU
DEBUG 01-15 10:09:13.387340.387340 lmp.py:1626]   Expert 50 |    120 | CPU
DEBUG 01-15 10:09:13.387983.387983 lmp.py:1626]   Expert 39 |    125 | CPU
DEBUG 01-15 10:09:13.387387.387387 lmp.py:1626]   Expert  4 |    130 | CPU
DEBUG 01-15 10:09:13.387030.387030 lmp.py:1626]   Expert 37 |    142 | CPU
DEBUG 01-15 10:09:13.387912.387912 lmp.py:1626]   Expert 15 |    148 | CPU
DEBUG 01-15 10:09:13.387555.387555 lmp.py:1626]   Expert 41 |    150 | CPU
DEBUG 01-15 10:09:13.387198.387198 lmp.py:1626]   Expert 23 |    158 | CPU
DEBUG 01-15 10:09:13.387417.387417 lmp.py:1626]   Expert 56 |    161 | GPU
DEBUG 01-15 10:09:13.387967.387967 lmp.py:1626]   Expert 16 |    163 | GPU
DEBUG 01-15 10:09:13.387524.387524 lmp.py:1626]   Expert 60 |    164 | GPU
DEBUG 01-15 10:09:13.387644.387644 lmp.py:1626]   Expert 44 |    168 | GPU
DEBUG 01-15 10:09:13.387287.387287 lmp.py:1626]   Expert  1 |    178 | GPU
DEBUG 01-15 10:09:13.387169.387169 lmp.py:1626]   Expert 21 |    181 | GPU
DEBUG 01-15 10:09:13.387812.387812 lmp.py:1626]   Expert 43 |    184 | GPU
DEBUG 01-15 10:09:13.387693.387693 lmp.py:1626]   Expert 47 |    191 | GPU
DEBUG 01-15 10:09:13.387098.387098 lmp.py:1626]   Expert 53 |    191 | GPU
DEBUG 01-15 10:09:13.387979.387979 lmp.py:1626]   Expert 33 |    198 | GPU
DEBUG 01-15 10:09:13.387622.387622 lmp.py:1626]   Expert 12 |    202 | GPU
DEBUG 01-15 10:09:13.387026.387026 lmp.py:1626]   Expert 13 |    208 | GPU
DEBUG 01-15 10:09:13.387623.387623 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:13.387173.387173 lmp.py:1626]   Expert 28 |    232 | GPU
DEBUG 01-15 10:09:13.387485.387485 lmp.py:1626]   Expert  0 |    253 | GPU
DEBUG 01-15 10:09:13.387797.387797 lmp.py:1626]   Expert 54 |    255 | GPU
DEBUG 01-15 10:09:13.387440.387440 lmp.py:1626]   Expert 31 |    257 | GPU
DEBUG 01-15 10:09:13.387560.387560 lmp.py:1626]   Expert 26 |    259 | GPU
DEBUG 01-15 10:09:13.388726.388726 lmp.py:1626]   Expert 10 |    265 | GPU
DEBUG 01-15 10:09:13.388131.388131 lmp.py:1626]   Expert 18 |    268 | GPU
DEBUG 01-15 10:09:13.388535.388535 lmp.py:1626]   Expert 57 |    272 | GPU
DEBUG 01-15 10:09:13.388178.388178 lmp.py:1626]   Expert  2 |    280 | GPU
DEBUG 01-15 10:09:13.388583.388583 lmp.py:1626]   Expert 58 |    299 | GPU
DEBUG 01-15 10:09:13.388987.388987 lmp.py:1626]   Expert 40 |    338 | GPU
DEBUG 01-15 10:09:13.388630.388630 lmp.py:1626]   Expert 25 |    361 | GPU
DEBUG 01-15 10:09:13.388465.388465 lmp.py:1626]   Expert 45 |    363 | GPU
DEBUG 01-15 10:09:13.388539.388539 lmp.py:1626]   Expert  5 |    442 | GPU
DEBUG 01-15 10:09:13.388851.388851 lmp.py:1626]   Expert 35 |    459 | GPU
DEBUG 01-15 10:09:13.388732.388732 lmp.py:1626]   Expert 27 |    483 | GPU
DEBUG 01-15 10:09:13.388137.388137 lmp.py:1626]   Expert 46 |    550 | GPU
DEBUG 01-15 10:09:13.388780.388780 lmp.py:1626]   Expert 52 |    600 | GPU
DEBUG 01-15 10:09:13.388184.388184 lmp.py:1626]   Expert 14 |    890 | GPU
DEBUG 01-15 10:09:13.388543.388543 lmp.py:1627] 
DEBUG 01-15 10:09:13.388543.388543 lmp.py:1627]   CPU total tokens: 2748 (22.4%)
DEBUG 01-15 10:09:13.388854.388854 lmp.py:1628]   GPU total tokens: 9540 (77.6%)
DEBUG 01-15 10:09:13.388219.388219 cuda_h.py:19] end experts_map_get cost 0.0016481876373291016 seconds
DEBUG 01-15 10:09:13.388407.388407 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.388177.388177 lmp.py:1636] 
DEBUG 01-15 10:09:13.388177.388177 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.388119.388119 cuda_h.py:19] end cpu_experts_submit cost 6.222724914550781e-05 seconds
DEBUG 01-15 10:09:13.388292.388292 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.388235.388235 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.388990.388990 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.389561.389561 cuda_h.py:19] end allocate_cuda_memory cost 0.00020766258239746094 seconds
DEBUG 01-15 10:09:13.389550.389550 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.389167.389167 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.389082.389082 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.389408.389408 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7067d115-f2dc-46c6-bb1e-c935e970764a
DEBUG 01-15 10:09:13.389156.389156 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.390372.390372 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.390047.390047 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.391240.391240 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7067d115-f2dc-46c6-bb1e-c935e970764a
DEBUG 01-15 10:09:13.391044.391044 cuda_h.py:19] end load_into_gpu_async cost 0.0022597312927246094 seconds
DEBUG 01-15 10:09:13.391608.391608 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.391265.391265 cuda_h.py:19] end restore_tensors2 cost 0.0004208087921142578 seconds
DEBUG 01-15 10:09:13.391671.391671 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003314495086669922 seconds
DEBUG 01-15 10:09:13.391501.391501 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.392148.392148 cuda_h.py:19] end move_flatidxs cost 0.0010941028594970703 seconds
DEBUG 01-15 10:09:13.392557.392557 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.394977.394977 cuda_h.py:19] end restore2model cost 0.0029115676879882812 seconds
DEBUG 01-15 10:09:13.394158.394158 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006443500518798828 seconds
DEBUG 01-15 10:09:13.394145.394145 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.395249.395249 cuda_h.py:19] end gpu_sexperts cost 0.00028896331787109375 seconds
DEBUG 01-15 10:09:13.395178.395178 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.397895.397895 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016150474548339844 seconds
DEBUG 01-15 10:09:13.397677.397677 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.398027.398027 cuda_h.py:19] end gpu_group_list cost 0.0003180503845214844 seconds
DEBUG 01-15 10:09:13.398613.398613 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.399075.399075 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006873607635498047 seconds
DEBUG 01-15 10:09:13.399321.399321 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:13.399144.399144 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-15 10:09:13.399078.399078 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.407539.407539 cuda_h.py:19] end group_tensors cost 0.01559591293334961 seconds
DEBUG 01-15 10:09:13.408643.408643 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.412679.412679 cuda_h.py:19] end group pad cost 0.003590106964111328 seconds
DEBUG 01-15 10:09:13.412992.412992 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.433242.433242 cuda_h.py:19] end group_einsum cost 0.021235227584838867 seconds
DEBUG 01-15 10:09:13.433367.433367 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.437274.437274 cuda_h.py:19] end get_outputs_cpu1 cost 0.0034770965576171875 seconds
DEBUG 01-15 10:09:13.438338.438338 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04767251014709473 seconds
DEBUG 01-15 10:09:13.439447.439447 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04039144515991211 seconds
DEBUG 01-15 10:09:13.439063.439063 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.440808.440808 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.440011.440011 cuda_h.py:19] end index_scatter cost 0.00020551681518554688 seconds
DEBUG 01-15 10:09:13.441703.441703 cuda_h.py:19] end cpuoutputsdeal cost 0.0012106895446777344 seconds
DEBUG 01-15 10:09:13.441276.441276 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.441206.441206 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7067d115-f2dc-46c6-bb1e-c935e970764a
INFO 01-15 10:09:13.442635.442635 client.py:127] Model loaded
DEBUG 01-15 10:09:13.442719.442719 cuda_h.py:19] end wait_experts cost 0.0014722347259521484 seconds
DEBUG 01-15 10:09:13.442291.442291 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.442706.442706 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.443861.443861 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.443319.443319 cuda_h.py:19] end gpu_group_tensor cost 0.0003669261932373047 seconds
DEBUG 01-15 10:09:13.443724.443724 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.444873.444873 cuda_h.py:19] end gpu_group_einsum cost 0.0011565685272216797 seconds
DEBUG 01-15 10:09:13.445914.445914 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.445507.445507 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.446774.446774 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005562305450439453 seconds
DEBUG 01-15 10:09:13.446883.446883 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.446877.446877 cuda_h.py:19] end concat_expert_out cost 0.00012993812561035156 seconds
DEBUG 01-15 10:09:13.446259.446259 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.446153.446153 cuda_h.py:19] end index_scatter cost 0.0001163482666015625 seconds
DEBUG 01-15 10:09:13.446706.446706 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013988018035888672 seconds
DEBUG 01-15 10:09:13.446499.446499 cuda_h.py:19] end gpu_experts cost 0.0039806365966796875 seconds
DEBUG 01-15 10:09:13.447234.447234 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.06297016143798828 seconds
DEBUG 01-15 10:09:13.447284.447284 cuda_h.py:19] end prefill_layer cost 0.07298994064331055 seconds
DEBUG 01-15 10:09:13.447685.447685 lmp.py:1552] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-15 10:09:13.447163.447163 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:13.447071.447071 lmp.py:1495] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-15 10:09:13.447503.447503 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:13.448500.448500 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:13.448322.448322 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:13.452334.452334 cuda_h.py:19] end self_attn cost 0.003439188003540039 seconds
DEBUG 01-15 10:09:13.452017.452017 cuda_h.py:19] end iln_self_attn_paln cost 0.004442691802978516 seconds
DEBUG 01-15 10:09:13.452610.452610 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-15 10:09:13.452492.452492 cuda_h.py:10] start gate
DEBUG 01-15 10:09:13.453442.453442 cuda_h.py:19] end gate cost 0.0008237361907958984 seconds
DEBUG 01-15 10:09:13.453014.453014 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:13.454805.454805 lmp.py:1616] 
DEBUG 01-15 10:09:13.454805.454805 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:13.454489.454489 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:13.454635.454635 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:13.454014.454014 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:13.454770.454770 lmp.py:1620] 
DEBUG 01-15 10:09:13.454770.454770 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:13.454096.454096 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:13.454328.454328 lmp.py:1626]   Expert 18 |     66 | CPU
DEBUG 01-15 10:09:13.454892.454892 lmp.py:1626]   Expert 47 |     68 | CPU
DEBUG 01-15 10:09:13.454695.454695 lmp.py:1626]   Expert 54 |     71 | CPU
DEBUG 01-15 10:09:13.454735.454735 lmp.py:1626]   Expert 23 |     77 | CPU
DEBUG 01-15 10:09:13.454776.454776 lmp.py:1626]   Expert 48 |     79 | CPU
DEBUG 01-15 10:09:13.454148.454148 lmp.py:1626]   Expert 44 |     85 | CPU
DEBUG 01-15 10:09:13.454281.454281 lmp.py:1626]   Expert 45 |     86 | CPU
DEBUG 01-15 10:09:13.454415.454415 lmp.py:1626]   Expert 20 |     91 | CPU
DEBUG 01-15 10:09:13.454071.454071 lmp.py:1626]   Expert 31 |     98 | CPU
DEBUG 01-15 10:09:13.454635.454635 lmp.py:1626]   Expert 36 |    107 | CPU
DEBUG 01-15 10:09:13.454199.454199 lmp.py:1626]   Expert 61 |    108 | CPU
DEBUG 01-15 10:09:13.454332.454332 lmp.py:1626]   Expert 33 |    120 | CPU
DEBUG 01-15 10:09:13.454989.454989 lmp.py:1626]   Expert 42 |    120 | CPU
DEBUG 01-15 10:09:13.454169.454169 lmp.py:1626]   Expert 43 |    121 | CPU
DEBUG 01-15 10:09:13.454825.454825 lmp.py:1626]   Expert 10 |    123 | CPU
DEBUG 01-15 10:09:13.454243.454243 lmp.py:1626]   Expert 24 |    124 | CPU
DEBUG 01-15 10:09:13.454423.454423 lmp.py:1626]   Expert 49 |    125 | CPU
DEBUG 01-15 10:09:13.454841.454841 lmp.py:1626]   Expert 11 |    127 | CPU
DEBUG 01-15 10:09:13.454259.454259 lmp.py:1626]   Expert 56 |    132 | CPU
DEBUG 01-15 10:09:13.454346.454346 lmp.py:1626]   Expert  6 |    135 | CPU
DEBUG 01-15 10:09:13.454434.454434 lmp.py:1626]   Expert 51 |    146 | CPU
DEBUG 01-15 10:09:13.454567.454567 lmp.py:1626]   Expert  0 |    149 | CPU
DEBUG 01-15 10:09:13.454223.454223 lmp.py:1626]   Expert  5 |    150 | CPU
DEBUG 01-15 10:09:13.454118.454118 lmp.py:1626]   Expert 17 |    151 | CPU
DEBUG 01-15 10:09:13.454775.454775 lmp.py:1626]   Expert 12 |    155 | CPU
DEBUG 01-15 10:09:13.454432.454432 lmp.py:1626]   Expert 40 |    158 | CPU
DEBUG 01-15 10:09:13.454995.454995 lmp.py:1626]   Expert 55 |    160 | CPU
DEBUG 01-15 10:09:13.455083.455083 lmp.py:1626]   Expert 57 |    161 | CPU
DEBUG 01-15 10:09:13.455646.455646 lmp.py:1626]   Expert 59 |    162 | CPU
DEBUG 01-15 10:09:13.455541.455541 lmp.py:1626]   Expert 26 |    163 | CPU
DEBUG 01-15 10:09:13.455198.455198 lmp.py:1626]   Expert 46 |    165 | CPU
DEBUG 01-15 10:09:13.455855.455855 lmp.py:1626]   Expert 13 |    167 | CPU
DEBUG 01-15 10:09:13.455273.455273 lmp.py:1626]   Expert 38 |    167 | GPU
DEBUG 01-15 10:09:13.455929.455929 lmp.py:1626]   Expert 58 |    172 | GPU
DEBUG 01-15 10:09:13.455493.455493 lmp.py:1626]   Expert 30 |    174 | GPU
DEBUG 01-15 10:09:13.455819.455819 lmp.py:1626]   Expert 35 |    175 | GPU
DEBUG 01-15 10:09:13.455714.455714 lmp.py:1626]   Expert 50 |    175 | GPU
DEBUG 01-15 10:09:13.455609.455609 lmp.py:1626]   Expert  7 |    181 | GPU
DEBUG 01-15 10:09:13.455027.455027 lmp.py:1626]   Expert 16 |    184 | GPU
DEBUG 01-15 10:09:13.455445.455445 lmp.py:1626]   Expert 15 |    201 | GPU
DEBUG 01-15 10:09:13.455101.455101 lmp.py:1626]   Expert 32 |    201 | GPU
DEBUG 01-15 10:09:13.455712.455712 lmp.py:1626]   Expert 14 |    206 | GPU
DEBUG 01-15 10:09:13.455276.455276 lmp.py:1626]   Expert  1 |    216 | GPU
DEBUG 01-15 10:09:13.455647.455647 lmp.py:1626]   Expert  4 |    222 | GPU
DEBUG 01-15 10:09:13.455542.455542 lmp.py:1626]   Expert  3 |    224 | GPU
DEBUG 01-15 10:09:13.455199.455199 lmp.py:1626]   Expert 39 |    236 | GPU
DEBUG 01-15 10:09:13.455617.455617 lmp.py:1626]   Expert 34 |    238 | GPU
DEBUG 01-15 10:09:13.455797.455797 lmp.py:1626]   Expert 28 |    246 | GPU
DEBUG 01-15 10:09:13.455215.455215 lmp.py:1626]   Expert 52 |    246 | GPU
DEBUG 01-15 10:09:13.455825.455825 lmp.py:1626]   Expert 25 |    256 | GPU
DEBUG 01-15 10:09:13.455151.455151 lmp.py:1626]   Expert 22 |    258 | GPU
DEBUG 01-15 10:09:13.455807.455807 lmp.py:1626]   Expert  2 |    271 | GPU
DEBUG 01-15 10:09:13.455464.455464 lmp.py:1626]   Expert 41 |    280 | GPU
DEBUG 01-15 10:09:13.455882.455882 lmp.py:1626]   Expert 21 |    281 | GPU
DEBUG 01-15 10:09:13.455062.455062 lmp.py:1626]   Expert 60 |    284 | GPU
DEBUG 01-15 10:09:13.455241.455241 lmp.py:1626]   Expert 63 |    287 | GPU
DEBUG 01-15 10:09:13.455136.455136 lmp.py:1626]   Expert 29 |    296 | GPU
DEBUG 01-15 10:09:13.455223.455223 lmp.py:1626]   Expert 62 |    296 | GPU
DEBUG 01-15 10:09:13.455310.455310 lmp.py:1626]   Expert 27 |    302 | GPU
DEBUG 01-15 10:09:13.455967.455967 lmp.py:1626]   Expert  8 |    334 | GPU
DEBUG 01-15 10:09:13.455623.455623 lmp.py:1626]   Expert 37 |    334 | GPU
DEBUG 01-15 10:09:13.455326.455326 lmp.py:1626]   Expert 53 |    335 | GPU
DEBUG 01-15 10:09:13.455983.455983 lmp.py:1626]   Expert 19 |    444 | GPU
DEBUG 01-15 10:09:13.456832.456832 lmp.py:1626]   Expert  9 |    616 | GPU
DEBUG 01-15 10:09:13.456634.456634 lmp.py:1627] 
DEBUG 01-15 10:09:13.456634.456634 lmp.py:1627]   CPU total tokens: 3950 (32.1%)
DEBUG 01-15 10:09:13.456198.456198 lmp.py:1628]   GPU total tokens: 8338 (67.9%)
DEBUG 01-15 10:09:13.456245.456245 cuda_h.py:19] end experts_map_get cost 0.002513408660888672 seconds
DEBUG 01-15 10:09:13.456321.456321 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:13.456528.456528 lmp.py:1636] 
DEBUG 01-15 10:09:13.456528.456528 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:13.456028.456028 cuda_h.py:19] end cpu_experts_submit cost 8.559226989746094e-05 seconds
DEBUG 01-15 10:09:13.456791.456791 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:13.456298.456298 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:13.456962.456962 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:13.457611.457611 cuda_h.py:19] end allocate_cuda_memory cost 0.0003540515899658203 seconds
DEBUG 01-15 10:09:13.457978.457978 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:13.457470.457470 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:13.457114.457114 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:13.457917.457917 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01dddb52-41dc-4316-bd8c-391d9e64d990
DEBUG 01-15 10:09:13.457931.457931 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:13.458396.458396 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:13.458842.458842 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:13.459043.459043 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01dddb52-41dc-4316-bd8c-391d9e64d990
DEBUG 01-15 10:09:13.459610.459610 cuda_h.py:19] end load_into_gpu_async cost 0.0015976428985595703 seconds
DEBUG 01-15 10:09:13.459280.459280 cuda_h.py:19] end move_flatidxs cost 0.0009436607360839844 seconds
DEBUG 01-15 10:09:13.459143.459143 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:13.459091.459091 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:13.460907.460907 cuda_h.py:19] end restore_tensors2 cost 0.0008168220520019531 seconds
DEBUG 01-15 10:09:13.460121.460121 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003760814666748047 seconds
DEBUG 01-15 10:09:13.460705.460705 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:13.462327.462327 cuda_h.py:19] end restore2model cost 0.0025360584259033203 seconds
DEBUG 01-15 10:09:13.462256.462256 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006527423858642578 seconds
DEBUG 01-15 10:09:13.462098.462098 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:13.463003.463003 cuda_h.py:19] end gpu_sexperts cost 0.00026917457580566406 seconds
DEBUG 01-15 10:09:13.463594.463594 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:13.464539.464539 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001505136489868164 seconds
DEBUG 01-15 10:09:13.465830.465830 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:13.466743.466743 cuda_h.py:19] end gpu_group_list cost 0.0003113746643066406 seconds
DEBUG 01-15 10:09:13.466892.466892 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:13.466633.466633 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007176399230957031 seconds
DEBUG 01-15 10:09:13.466833.466833 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:13.466535.466535 cuda_h.py:19] end group_tensors cost 0.007287740707397461 seconds
DEBUG 01-15 10:09:13.467690.467690 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:13.471262.471262 cuda_h.py:19] end group pad cost 0.003984689712524414 seconds
DEBUG 01-15 10:09:13.471290.471290 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:13.492069.492069 cuda_h.py:19] end group_einsum cost 0.020395994186401367 seconds
DEBUG 01-15 10:09:13.492955.492955 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:13.497315.497315 cuda_h.py:19] end get_outputs_cpu1 cost 0.005518674850463867 seconds
DEBUG 01-15 10:09:13.498830.498830 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.040726423263549805 seconds
DEBUG 01-15 10:09:13.500461.500461 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03310537338256836 seconds
DEBUG 01-15 10:09:13.500427.500427 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:13.500350.500350 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.501359.501359 cuda_h.py:19] end index_scatter cost 0.00014400482177734375 seconds
DEBUG 01-15 10:09:13.501125.501125 cuda_h.py:19] end cpuoutputsdeal cost 0.0011699199676513672 seconds
DEBUG 01-15 10:09:13.501870.501870 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:13.501925.501925 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01dddb52-41dc-4316-bd8c-391d9e64d990
INFO 01-15 10:09:13.509093.509093 client.py:127] Model loaded
DEBUG 01-15 10:09:13.509330.509330 cuda_h.py:19] end wait_experts cost 0.008132457733154297 seconds
DEBUG 01-15 10:09:13.509716.509716 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:13.510277.510277 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:13.510955.510955 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:13.510036.510036 cuda_h.py:19] end gpu_group_tensor cost 0.0003669261932373047 seconds
DEBUG 01-15 10:09:13.510157.510157 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:13.512264.512264 cuda_h.py:19] end gpu_group_einsum cost 0.001123666763305664 seconds
DEBUG 01-15 10:09:13.512266.512266 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:13.512662.512662 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:13.513253.513253 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005605220794677734 seconds
DEBUG 01-15 10:09:13.513885.513885 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:13.513686.513686 cuda_h.py:19] end concat_expert_out cost 0.0001285076141357422 seconds
DEBUG 01-15 10:09:13.513545.513545 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:13.513916.513916 cuda_h.py:19] end index_scatter cost 0.00011849403381347656 seconds
DEBUG 01-15 10:09:13.513469.513469 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013928413391113281 seconds
DEBUG 01-15 10:09:13.513885.513885 cuda_h.py:19] end gpu_experts cost 0.003986835479736328 seconds
DEBUG 01-15 10:09:13.514183.514183 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06156635284423828 seconds
DEBUG 01-15 10:09:13.514797.514797 cuda_h.py:19] end prefill_layer cost 0.06695199012756348 seconds
DEBUG 01-15 10:09:13.515073.515073 lmp.py:1552] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-15 10:09:13.515751.515751 cuda_h.py:19] end prefill cost 2.5330381393432617 seconds
DEBUG 01-15 10:09:15.712040.712040 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11281347274780273 s
DEBUG 01-15 10:09:16.151441.151441 cuda_h.py:19] end generate_input_ids cost 0.43824291229248047 seconds
DEBUG 01-15 10:09:16.151168.151168 cuda_h.py:10] start init_cache
DEBUG 01-15 10:09:16.152233.152233 cuda_h.py:19] end init_cache cost 9.1552734375e-05 seconds
DEBUG 01-15 10:09:18.536054.536054 cuda_h.py:10] start init_meta_layer
DEBUG 01-15 10:09:18.538822.538822 cuda_h.py:19] end init_meta_layer cost 1.0967254638671875e-05 seconds
DEBUG 01-15 10:09:18.538915.538915 cuda_h.py:10] start init_weights
DEBUG 01-15 10:09:18.538910.538910 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:18.538620.538620 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:18.540842.540842 cuda_h.py:19] end allocate_cuda_memory cost 0.0020666122436523438 seconds
DEBUG 01-15 10:09:18.540500.540500 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:18.540256.540256 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:18.540595.540595 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:18.540152.540152 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a23e58ab-bd50-448c-a313-36a140b3ccc4
DEBUG 01-15 10:09:18.540215.540215 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:18.541298.541298 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a23e58ab-bd50-448c-a313-36a140b3ccc4
DEBUG 01-15 10:09:18.541035.541035 cuda_h.py:19] end load_into_gpu_async cost 0.0013127326965332031 seconds
DEBUG 01-15 10:09:18.541353.541353 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:18.541416.541416 cuda_h.py:19] end restore_tensors2 cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:18.541357.541357 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003644227981567383 seconds
DEBUG 01-15 10:09:18.541530.541530 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:18.541867.541867 cuda_h.py:19] end restore2model cost 0.00015544891357421875 seconds
INFO 01-15 10:09:18.541146.541146 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a23e58ab-bd50-448c-a313-36a140b3ccc4
INFO 01-15 10:09:18.619541.619541 client.py:127] Model loaded
DEBUG 01-15 10:09:18.619638.619638 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-15 10:09:18.619901.619901 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:18.619904.619904 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:18.620239.620239 cuda_h.py:19] end allocate_cuda_memory cost 0.0004038810729980469 seconds
DEBUG 01-15 10:09:18.620959.620959 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:18.620935.620935 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:18.620064.620064 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:18.620775.620775 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d26dd046-7200-421a-ac91-2ee6b08d2fe4
DEBUG 01-15 10:09:18.621383.621383 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:18.622624.622624 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d26dd046-7200-421a-ac91-2ee6b08d2fe4
DEBUG 01-15 10:09:18.622078.622078 cuda_h.py:19] end load_into_gpu_async cost 0.0018918514251708984 seconds
DEBUG 01-15 10:09:18.622835.622835 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:18.622021.622021 cuda_h.py:19] end restore_tensors2 cost 0.00013017654418945312 seconds
DEBUG 01-15 10:09:18.622183.622183 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030107498168945312 seconds
INFO 01-15 10:09:18.623755.623755 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d26dd046-7200-421a-ac91-2ee6b08d2fe4
INFO 01-15 10:09:18.639873.639873 client.py:127] Model loaded
DEBUG 01-15 10:09:18.639056.639056 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:18.640174.640174 cuda_h.py:19] end restore2model cost 0.0008330345153808594 seconds
DEBUG 01-15 10:09:18.640304.640304 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02097344398498535 seconds
DEBUG 01-15 10:09:18.640181.640181 cuda_h.py:19] end init_weights cost 0.10283184051513672 seconds
DEBUG 01-15 10:09:18.640753.640753 cuda_h.py:10] start copy_emodel
DEBUG 01-15 10:09:19.419914.419914 cuda_h.py:19] end copy_emodel cost 0.7786397933959961 seconds
DEBUG 01-15 10:09:19.420631.420631 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-15 10:09:19.420199.420199 cuda_h.py:19] end init_inputs_tokens cost 0.0003056526184082031 seconds
DEBUG 01-15 10:09:19.420518.420518 cuda_h.py:10] start prefill
DEBUG 01-15 10:09:19.420374.420374 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.421315.421315 lmp.py:1495] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-15 10:09:19.421011.421011 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:19.421807.421807 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:19.421041.421041 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.719329833984375e-05 seconds
DEBUG 01-15 10:09:19.421505.421505 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.224082946777344e-05 seconds
DEBUG 01-15 10:09:19.421864.421864 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.421283.421283 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.421737.421737 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.421005.421005 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.421117.421117 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.422748.422748 cuda_h.py:19] end allocate_cuda_memory cost 0.0003066062927246094 seconds
DEBUG 01-15 10:09:19.422839.422839 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.422080.422080 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.422135.422135 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.422826.422826 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c2777ff9-86ce-4437-a00e-2c67200096c5
DEBUG 01-15 10:09:19.422447.422447 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.422626.422626 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.424742.424742 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c2777ff9-86ce-4437-a00e-2c67200096c5
DEBUG 01-15 10:09:19.424633.424633 cuda_h.py:19] end load_into_gpu_async cost 0.0016717910766601562 seconds
DEBUG 01-15 10:09:19.424117.424117 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.424685.424685 cuda_h.py:19] end restore_tensors2 cost 9.703636169433594e-05 seconds
DEBUG 01-15 10:09:19.424986.424986 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027341842651367188 seconds
INFO 01-15 10:09:19.424591.424591 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c2777ff9-86ce-4437-a00e-2c67200096c5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.427160.427160 cuda_h.py:19] end self_attn cost 0.004608869552612305 seconds
DEBUG 01-15 10:09:19.427912.427912 cuda_h.py:19] end iln_self_attn_paln cost 0.006749629974365234 seconds
DEBUG 01-15 10:09:19.428926.428926 cuda_h.py:10] start dense_mlp
INFO 01-15 10:09:19.431702.431702 client.py:127] Model loaded
DEBUG 01-15 10:09:19.431195.431195 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.432234.432234 cuda_h.py:19] end restore2model cost 0.0007030963897705078 seconds
DEBUG 01-15 10:09:19.432535.432535 cuda_h.py:19] end sllm_worker_task cost 0.010913372039794922 seconds
DEBUG 01-15 10:09:19.432432.432432 cuda_h.py:19] end dense_mlp cost 0.004584312438964844 seconds
DEBUG 01-15 10:09:19.432999.432999 cuda_h.py:19] end prefill_layer cost 0.011704683303833008 seconds
DEBUG 01-15 10:09:19.432423.432423 lmp.py:1552] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-15 10:09:19.432643.432643 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.432961.432961 lmp.py:1495] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-15 10:09:19.432896.432896 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:19.432023.432023 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:19.432229.432229 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.1696090698242188e-05 seconds
DEBUG 01-15 10:09:19.432694.432694 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.054473876953125e-05 seconds
DEBUG 01-15 10:09:19.432767.432767 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.432134.432134 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.433785.433785 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.433787.433787 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.433426.433426 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.433893.433893 cuda_h.py:19] end allocate_cuda_memory cost 0.0002472400665283203 seconds
DEBUG 01-15 10:09:19.433447.433447 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.433403.433403 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.433479.433479 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.433898.433898 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e958a5e4-e96f-4d6e-a51f-cee7ea9a4110
DEBUG 01-15 10:09:19.434234.434234 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.434789.434789 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.435796.435796 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e958a5e4-e96f-4d6e-a51f-cee7ea9a4110
DEBUG 01-15 10:09:19.435032.435032 cuda_h.py:19] end load_into_gpu_async cost 0.0015819072723388672 seconds
DEBUG 01-15 10:09:19.435537.435537 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.435172.435172 cuda_h.py:19] end restore_tensors2 cost 9.72747802734375e-05 seconds
DEBUG 01-15 10:09:19.435684.435684 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002400636672973633 seconds
INFO 01-15 10:09:19.435667.435667 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e958a5e4-e96f-4d6e-a51f-cee7ea9a4110
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.437989.437989 cuda_h.py:19] end self_attn cost 0.003139972686767578 seconds
DEBUG 01-15 10:09:19.437170.437170 cuda_h.py:19] end iln_self_attn_paln cost 0.0046939849853515625 seconds
DEBUG 01-15 10:09:19.437742.437742 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-15 10:09:19.437220.437220 cuda_h.py:10] start gate
DEBUG 01-15 10:09:19.438770.438770 cuda_h.py:19] end gate cost 0.0007584095001220703 seconds
DEBUG 01-15 10:09:19.438454.438454 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.438179.438179 lmp.py:1616] 
DEBUG 01-15 10:09:19.438179.438179 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.438173.438173 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.438584.438584 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.438135.438135 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.438301.438301 lmp.py:1620] 
DEBUG 01-15 10:09:19.438301.438301 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.439659.439659 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.439216.439216 lmp.py:1626]   Expert 25 |     64 | CPU
DEBUG 01-15 10:09:19.439144.439144 lmp.py:1626]   Expert 54 |     67 | CPU
DEBUG 01-15 10:09:19.439833.439833 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:19.439523.439523 lmp.py:1626]   Expert 31 |     72 | CPU
DEBUG 01-15 10:09:19.439735.439735 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:19.439093.439093 lmp.py:1626]   Expert 62 |     87 | CPU
DEBUG 01-15 10:09:19.439213.439213 lmp.py:1626]   Expert 18 |     88 | CPU
DEBUG 01-15 10:09:19.439094.439094 lmp.py:1626]   Expert 52 |     98 | CPU
DEBUG 01-15 10:09:19.439261.439261 lmp.py:1626]   Expert 22 |    100 | CPU
DEBUG 01-15 10:09:19.439904.439904 lmp.py:1626]   Expert 47 |    104 | CPU
DEBUG 01-15 10:09:19.439023.439023 lmp.py:1626]   Expert  0 |    113 | CPU
DEBUG 01-15 10:09:19.439858.439858 lmp.py:1626]   Expert 37 |    117 | CPU
DEBUG 01-15 10:09:19.439694.439694 lmp.py:1626]   Expert 27 |    121 | CPU
DEBUG 01-15 10:09:19.439575.439575 lmp.py:1626]   Expert 32 |    123 | CPU
DEBUG 01-15 10:09:19.439218.439218 lmp.py:1626]   Expert 41 |    130 | CPU
DEBUG 01-15 10:09:19.439861.439861 lmp.py:1626]   Expert 44 |    131 | CPU
DEBUG 01-15 10:09:19.439027.439027 lmp.py:1626]   Expert 28 |    136 | CPU
DEBUG 01-15 10:09:19.439670.439670 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:19.439075.439075 lmp.py:1626]   Expert 58 |    140 | CPU
DEBUG 01-15 10:09:19.439956.439956 lmp.py:1626]   Expert 60 |    144 | CPU
DEBUG 01-15 10:09:19.439599.439599 lmp.py:1626]   Expert 43 |    147 | CPU
DEBUG 01-15 10:09:19.439388.439388 lmp.py:1626]   Expert  1 |    150 | CPU
DEBUG 01-15 10:09:19.439792.439792 lmp.py:1626]   Expert 38 |    153 | CPU
DEBUG 01-15 10:09:19.439197.439197 lmp.py:1626]   Expert 49 |    154 | CPU
DEBUG 01-15 10:09:19.439601.439601 lmp.py:1626]   Expert 51 |    155 | CPU
DEBUG 01-15 10:09:19.439436.439436 lmp.py:1626]   Expert 34 |    161 | CPU
DEBUG 01-15 10:09:19.439033.439033 lmp.py:1626]   Expert 35 |    164 | CPU
DEBUG 01-15 10:09:19.439391.439391 lmp.py:1626]   Expert 36 |    168 | CPU
DEBUG 01-15 10:09:19.439273.439273 lmp.py:1626]   Expert 11 |    170 | CPU
DEBUG 01-15 10:09:19.439677.439677 lmp.py:1626]   Expert 17 |    170 | CPU
DEBUG 01-15 10:09:19.439082.439082 lmp.py:1626]   Expert 59 |    174 | CPU
DEBUG 01-15 10:09:19.439725.439725 lmp.py:1626]   Expert 10 |    180 | CPU
DEBUG 01-15 10:09:19.439129.439129 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:19.439295.439295 lmp.py:1626]   Expert  2 |    186 | GPU
DEBUG 01-15 10:09:19.439938.439938 lmp.py:1626]   Expert 39 |    189 | GPU
DEBUG 01-15 10:09:19.439105.439105 lmp.py:1626]   Expert 33 |    197 | GPU
DEBUG 01-15 10:09:19.439509.439509 lmp.py:1626]   Expert 12 |    198 | GPU
DEBUG 01-15 10:09:19.439675.439675 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:19.439365.439365 lmp.py:1626]   Expert 48 |    198 | GPU
DEBUG 01-15 10:09:19.439769.439769 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:19.439127.439127 lmp.py:1626]   Expert 53 |    204 | GPU
DEBUG 01-15 10:09:19.439486.439486 lmp.py:1626]   Expert 19 |    220 | GPU
DEBUG 01-15 10:09:19.439129.439129 lmp.py:1626]   Expert 26 |    221 | GPU
DEBUG 01-15 10:09:19.439056.439056 lmp.py:1626]   Expert 30 |    221 | GPU
DEBUG 01-15 10:09:19.439222.439222 lmp.py:1626]   Expert 45 |    221 | GPU
DEBUG 01-15 10:09:19.439150.439150 lmp.py:1626]   Expert  5 |    227 | GPU
DEBUG 01-15 10:09:19.439316.439316 lmp.py:1626]   Expert  4 |    229 | GPU
DEBUG 01-15 10:09:19.439482.439482 lmp.py:1626]   Expert 24 |    229 | GPU
DEBUG 01-15 10:09:19.439649.439649 lmp.py:1626]   Expert 42 |    242 | GPU
DEBUG 01-15 10:09:19.439815.439815 lmp.py:1626]   Expert 50 |    245 | GPU
DEBUG 01-15 10:09:19.439981.439981 lmp.py:1626]   Expert 29 |    254 | GPU
DEBUG 01-15 10:09:19.439909.439909 lmp.py:1626]   Expert 56 |    262 | GPU
DEBUG 01-15 10:09:19.439267.439267 lmp.py:1626]   Expert 61 |    270 | GPU
DEBUG 01-15 10:09:19.439863.439863 lmp.py:1626]   Expert  8 |    283 | GPU
DEBUG 01-15 10:09:19.439506.439506 lmp.py:1626]   Expert 63 |    285 | GPU
DEBUG 01-15 10:09:19.439673.439673 lmp.py:1626]   Expert 46 |    294 | GPU
DEBUG 01-15 10:09:19.440839.440839 lmp.py:1626]   Expert  9 |    300 | GPU
DEBUG 01-15 10:09:19.440674.440674 lmp.py:1626]   Expert  6 |    316 | GPU
DEBUG 01-15 10:09:19.440840.440840 lmp.py:1626]   Expert 16 |    316 | GPU
DEBUG 01-15 10:09:19.440774.440774 lmp.py:1626]   Expert 40 |    319 | GPU
DEBUG 01-15 10:09:19.440941.440941 lmp.py:1626]   Expert  7 |    322 | GPU
DEBUG 01-15 10:09:19.440107.440107 lmp.py:1626]   Expert 23 |    325 | GPU
DEBUG 01-15 10:09:19.440273.440273 lmp.py:1626]   Expert 14 |    413 | GPU
DEBUG 01-15 10:09:19.440154.440154 lmp.py:1626]   Expert 57 |    464 | GPU
DEBUG 01-15 10:09:19.440705.440705 lmp.py:1627] 
DEBUG 01-15 10:09:19.440705.440705 lmp.py:1627]   CPU total tokens: 4059 (33.0%)
DEBUG 01-15 10:09:19.440255.440255 lmp.py:1628]   GPU total tokens: 8229 (67.0%)
DEBUG 01-15 10:09:19.440143.440143 cuda_h.py:19] end experts_map_get cost 0.0015687942504882812 seconds
DEBUG 01-15 10:09:19.440099.440099 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.440471.440471 lmp.py:1636] 
DEBUG 01-15 10:09:19.440471.440471 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.440161.440161 cuda_h.py:19] end cpu_experts_submit cost 5.125999450683594e-05 seconds
DEBUG 01-15 10:09:19.440142.440142 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.440840.440840 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.440453.440453 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.442496.442496 cuda_h.py:19] end allocate_cuda_memory cost 0.0014345645904541016 seconds
DEBUG 01-15 10:09:19.442670.442670 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.442996.442996 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.442249.442249 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.442998.442998 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8e364f75-374b-491d-aff3-8223a4e5976f
DEBUG 01-15 10:09:19.442179.442179 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:19.443721.443721 client.py:127] Model loaded
DEBUG 01-15 10:09:19.443771.443771 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.443006.443006 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:19.443529.443529 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.444350.444350 cuda_h.py:19] end restore2model cost 0.0008039474487304688 seconds
INFO 01-15 10:09:19.444513.444513 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8e364f75-374b-491d-aff3-8223a4e5976f
DEBUG 01-15 10:09:19.444681.444681 cuda_h.py:19] end sllm_worker_task cost 0.011083602905273438 seconds
DEBUG 01-15 10:09:19.444042.444042 cuda_h.py:19] end load_into_gpu_async cost 0.0021677017211914062 seconds
DEBUG 01-15 10:09:19.444641.444641 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.444575.444575 cuda_h.py:19] end move_flatidxs cost 0.0009016990661621094 seconds
DEBUG 01-15 10:09:19.444827.444827 cuda_h.py:19] end restore_tensors2 cost 0.00038695335388183594 seconds
DEBUG 01-15 10:09:19.444942.444942 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:19.444816.444816 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004418611526489258 seconds
DEBUG 01-15 10:09:19.444486.444486 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.447170.447170 cuda_h.py:19] end restore2model cost 0.0025806427001953125 seconds
DEBUG 01-15 10:09:19.447503.447503 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0071871280670166016 seconds
DEBUG 01-15 10:09:19.447491.447491 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.447408.447408 cuda_h.py:19] end gpu_sexperts cost 0.0002593994140625 seconds
DEBUG 01-15 10:09:19.447760.447760 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.449071.449071 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0019137859344482422 seconds
DEBUG 01-15 10:09:19.450243.450243 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.451243.451243 cuda_h.py:19] end gpu_group_list cost 0.00032973289489746094 seconds
DEBUG 01-15 10:09:19.450759.450759 cuda_h.py:19] end group_tensors cost 0.00557708740234375 seconds
DEBUG 01-15 10:09:19.451121.451121 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.451671.451671 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.452972.452972 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0012485980987548828 seconds
DEBUG 01-15 10:09:19.452405.452405 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.452091.452091 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-15 10:09:19.452986.452986 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.455655.455655 cuda_h.py:19] end group pad cost 0.004393577575683594 seconds
DEBUG 01-15 10:09:19.455306.455306 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.478180.478180 cuda_h.py:19] end group_einsum cost 0.02281641960144043 seconds
DEBUG 01-15 10:09:19.478120.478120 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.485740.485740 cuda_h.py:19] end get_outputs_cpu1 cost 0.006168842315673828 seconds
DEBUG 01-15 10:09:19.487037.487037 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.034880876541137695 seconds
DEBUG 01-15 10:09:19.487087.487087 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.488718.488718 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.488458.488458 cuda_h.py:19] end index_scatter cost 9.655952453613281e-05 seconds
DEBUG 01-15 10:09:19.488422.488422 cuda_h.py:19] end cpuoutputsdeal cost 0.0008730888366699219 seconds
DEBUG 01-15 10:09:19.488728.488728 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.488591.488591 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8e364f75-374b-491d-aff3-8223a4e5976f
DEBUG 01-15 10:09:19.489428.489428 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04629254341125488 seconds
INFO 01-15 10:09:19.494988.494988 client.py:127] Model loaded
DEBUG 01-15 10:09:19.494374.494374 cuda_h.py:19] end wait_experts cost 0.006200551986694336 seconds
DEBUG 01-15 10:09:19.495892.495892 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.495503.495503 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.495213.495213 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.495291.495291 cuda_h.py:19] end gpu_group_tensor cost 0.0007212162017822266 seconds
DEBUG 01-15 10:09:19.495952.495952 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.496373.496373 cuda_h.py:19] end gpu_group_einsum cost 0.0008537769317626953 seconds
DEBUG 01-15 10:09:19.497728.497728 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.497041.497041 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.497912.497912 cuda_h.py:19] end all_expert_outputs_slices cost 0.00025653839111328125 seconds
DEBUG 01-15 10:09:19.497290.497290 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.497498.497498 cuda_h.py:19] end concat_expert_out cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:19.497858.497858 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.497543.497543 cuda_h.py:19] end index_scatter cost 5.412101745605469e-05 seconds
DEBUG 01-15 10:09:19.497206.497206 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005934238433837891 seconds
DEBUG 01-15 10:09:19.497248.497248 cuda_h.py:19] end gpu_experts cost 0.002691030502319336 seconds
DEBUG 01-15 10:09:19.497972.497972 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.06003832817077637 seconds
DEBUG 01-15 10:09:19.498201.498201 cuda_h.py:19] end prefill_layer cost 0.06530904769897461 seconds
DEBUG 01-15 10:09:19.498627.498627 lmp.py:1552] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-15 10:09:19.498754.498754 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.498881.498881 lmp.py:1495] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-15 10:09:19.498722.498722 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:19.498233.498233 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:19.498308.498308 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.0279159545898438e-05 seconds
DEBUG 01-15 10:09:19.498819.498819 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 5.817413330078125e-05 seconds
DEBUG 01-15 10:09:19.498654.498654 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.498941.498941 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.498725.498725 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.498980.498980 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.498763.498763 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.498341.498341 cuda_h.py:19] end allocate_cuda_memory cost 0.0002167224884033203 seconds
DEBUG 01-15 10:09:19.498621.498621 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.499092.499092 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.499253.499253 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.499241.499241 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4bb066f9-dbdb-4471-89f8-315407237bc3
DEBUG 01-15 10:09:19.499018.499018 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.499657.499657 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.499729.499729 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4bb066f9-dbdb-4471-89f8-315407237bc3
DEBUG 01-15 10:09:19.499658.499658 cuda_h.py:19] end load_into_gpu_async cost 0.0008726119995117188 seconds
DEBUG 01-15 10:09:19.499738.499738 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.500251.500251 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-15 10:09:19.500007.500007 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00139617919921875 seconds
INFO 01-15 10:09:19.500705.500705 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4bb066f9-dbdb-4471-89f8-315407237bc3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.503851.503851 cuda_h.py:19] end self_attn cost 0.0035545825958251953 seconds
DEBUG 01-15 10:09:19.503212.503212 cuda_h.py:19] end iln_self_attn_paln cost 0.004982948303222656 seconds
DEBUG 01-15 10:09:19.503108.503108 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-15 10:09:19.503202.503202 cuda_h.py:10] start gate
DEBUG 01-15 10:09:19.504947.504947 cuda_h.py:19] end gate cost 0.0006561279296875 seconds
DEBUG 01-15 10:09:19.504922.504922 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.504006.504006 lmp.py:1616] 
DEBUG 01-15 10:09:19.504006.504006 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.504669.504669 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.504511.504511 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.504538.504538 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.504419.504419 lmp.py:1620] 
DEBUG 01-15 10:09:19.504419.504419 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.504493.504493 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.504282.504282 lmp.py:1626]   Expert 58 |     51 | CPU
DEBUG 01-15 10:09:19.504640.504640 lmp.py:1626]   Expert 27 |     56 | CPU
DEBUG 01-15 10:09:19.504283.504283 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:19.504926.504926 lmp.py:1626]   Expert 17 |     84 | CPU
DEBUG 01-15 10:09:19.504330.504330 lmp.py:1626]   Expert  0 |     88 | CPU
DEBUG 01-15 10:09:19.504735.504735 lmp.py:1626]   Expert 24 |     88 | CPU
DEBUG 01-15 10:09:19.504139.504139 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:19.504306.504306 lmp.py:1626]   Expert 34 |    114 | CPU
DEBUG 01-15 10:09:19.504425.504425 lmp.py:1626]   Expert 51 |    118 | CPU
DEBUG 01-15 10:09:19.504307.504307 lmp.py:1626]   Expert 32 |    120 | CPU
DEBUG 01-15 10:09:19.504950.504950 lmp.py:1626]   Expert  9 |    129 | CPU
DEBUG 01-15 10:09:19.504354.504354 lmp.py:1626]   Expert 23 |    135 | CPU
DEBUG 01-15 10:09:19.504474.504474 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:19.504402.504402 lmp.py:1626]   Expert 15 |    136 | CPU
DEBUG 01-15 10:09:19.504568.504568 lmp.py:1626]   Expert 26 |    138 | CPU
DEBUG 01-15 10:09:19.504257.504257 lmp.py:1626]   Expert 30 |    144 | CPU
DEBUG 01-15 10:09:19.504185.504185 lmp.py:1626]   Expert 45 |    146 | CPU
DEBUG 01-15 10:09:19.504113.504113 lmp.py:1626]   Expert 62 |    147 | CPU
DEBUG 01-15 10:09:19.504279.504279 lmp.py:1626]   Expert 57 |    150 | CPU
DEBUG 01-15 10:09:19.504445.504445 lmp.py:1626]   Expert  1 |    152 | CPU
DEBUG 01-15 10:09:19.505373.505373 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:19.505300.505300 lmp.py:1626]   Expert  8 |    159 | CPU
DEBUG 01-15 10:09:19.505182.505182 lmp.py:1626]   Expert 29 |    160 | CPU
DEBUG 01-15 10:09:19.505586.505586 lmp.py:1626]   Expert 25 |    164 | CPU
DEBUG 01-15 10:09:19.505991.505991 lmp.py:1626]   Expert 54 |    167 | CPU
DEBUG 01-15 10:09:19.505396.505396 lmp.py:1626]   Expert  6 |    170 | CPU
DEBUG 01-15 10:09:19.505277.505277 lmp.py:1626]   Expert 49 |    171 | CPU
DEBUG 01-15 10:09:19.505443.505443 lmp.py:1626]   Expert 48 |    174 | CPU
DEBUG 01-15 10:09:19.505371.505371 lmp.py:1626]   Expert 12 |    176 | CPU
DEBUG 01-15 10:09:19.505298.505298 lmp.py:1626]   Expert 35 |    176 | CPU
DEBUG 01-15 10:09:19.505749.505749 lmp.py:1626]   Expert 37 |    178 | CPU
DEBUG 01-15 10:09:19.505439.505439 lmp.py:1626]   Expert 60 |    186 | CPU
DEBUG 01-15 10:09:19.505128.505128 lmp.py:1626]   Expert 13 |    188 | GPU
DEBUG 01-15 10:09:19.505678.505678 lmp.py:1626]   Expert 33 |    189 | GPU
DEBUG 01-15 10:09:19.505083.505083 lmp.py:1626]   Expert 53 |    189 | GPU
DEBUG 01-15 10:09:19.505249.505249 lmp.py:1626]   Expert 10 |    194 | GPU
DEBUG 01-15 10:09:19.505926.505926 lmp.py:1626]   Expert 16 |    195 | GPU
DEBUG 01-15 10:09:19.505046.505046 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:19.505973.505973 lmp.py:1626]   Expert 40 |    200 | GPU
DEBUG 01-15 10:09:19.505186.505186 lmp.py:1626]   Expert 43 |    203 | GPU
DEBUG 01-15 10:09:19.505160.505160 lmp.py:1626]   Expert 38 |    204 | GPU
DEBUG 01-15 10:09:19.505372.505372 lmp.py:1626]   Expert  5 |    208 | GPU
DEBUG 01-15 10:09:19.505108.505108 lmp.py:1626]   Expert 44 |    216 | GPU
DEBUG 01-15 10:09:19.505844.505844 lmp.py:1626]   Expert 19 |    217 | GPU
DEBUG 01-15 10:09:19.505818.505818 lmp.py:1626]   Expert 50 |    217 | GPU
DEBUG 01-15 10:09:19.505507.505507 lmp.py:1626]   Expert 52 |    217 | GPU
DEBUG 01-15 10:09:19.505196.505196 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:19.505647.505647 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:19.505098.505098 lmp.py:1626]   Expert 59 |    223 | GPU
DEBUG 01-15 10:09:19.505549.505549 lmp.py:1626]   Expert 55 |    233 | GPU
DEBUG 01-15 10:09:19.505761.505761 lmp.py:1626]   Expert 56 |    240 | GPU
DEBUG 01-15 10:09:19.505974.505974 lmp.py:1626]   Expert 31 |    241 | GPU
DEBUG 01-15 10:09:19.505471.505471 lmp.py:1626]   Expert 20 |    251 | GPU
DEBUG 01-15 10:09:19.505684.505684 lmp.py:1626]   Expert 39 |    252 | GPU
DEBUG 01-15 10:09:19.505419.505419 lmp.py:1626]   Expert 22 |    264 | GPU
DEBUG 01-15 10:09:19.505393.505393 lmp.py:1626]   Expert  2 |    267 | GPU
DEBUG 01-15 10:09:19.505367.505367 lmp.py:1626]   Expert 47 |    276 | GPU
DEBUG 01-15 10:09:19.505341.505341 lmp.py:1626]   Expert 63 |    276 | GPU
DEBUG 01-15 10:09:19.505554.505554 lmp.py:1626]   Expert 42 |    303 | GPU
DEBUG 01-15 10:09:19.505005.505005 lmp.py:1626]   Expert 18 |    314 | GPU
DEBUG 01-15 10:09:19.505694.505694 lmp.py:1626]   Expert 14 |    317 | GPU
DEBUG 01-15 10:09:19.505860.505860 lmp.py:1626]   Expert 46 |    367 | GPU
DEBUG 01-15 10:09:19.505549.505549 lmp.py:1626]   Expert 11 |    388 | GPU
DEBUG 01-15 10:09:19.505239.505239 lmp.py:1626]   Expert 61 |    460 | GPU
DEBUG 01-15 10:09:19.505405.505405 lmp.py:1627] 
DEBUG 01-15 10:09:19.505405.505405 lmp.py:1627]   CPU total tokens: 4341 (35.3%)
DEBUG 01-15 10:09:19.505571.505571 lmp.py:1628]   GPU total tokens: 7947 (64.7%)
DEBUG 01-15 10:09:19.505267.505267 cuda_h.py:19] end experts_map_get cost 0.0015599727630615234 seconds
DEBUG 01-15 10:09:19.505640.505640 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.505012.505012 lmp.py:1636] 
DEBUG 01-15 10:09:19.505012.505012 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.505894.505894 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-15 10:09:19.505160.505160 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.506321.506321 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.506054.506054 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.506018.506018 cuda_h.py:19] end allocate_cuda_memory cost 0.00021505355834960938 seconds
DEBUG 01-15 10:09:19.506253.506253 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.506632.506632 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.506872.506872 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.506998.506998 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0650a3c9-2fa8-469f-abf6-f957b7c6ec09
DEBUG 01-15 10:09:19.507435.507435 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.507064.507064 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:19.507142.507142 client.py:127] Model loaded
DEBUG 01-15 10:09:19.507840.507840 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.507043.507043 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.507620.507620 cuda_h.py:19] end restore2model cost 0.0003314018249511719 seconds
DEBUG 01-15 10:09:19.507151.507151 cuda_h.py:19] end sllm_worker_task cost 0.009087800979614258 seconds
INFO 01-15 10:09:19.507254.507254 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0650a3c9-2fa8-469f-abf6-f957b7c6ec09
DEBUG 01-15 10:09:19.507005.507005 cuda_h.py:19] end load_into_gpu_async cost 0.001047372817993164 seconds
DEBUG 01-15 10:09:19.507423.507423 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.508028.508028 cuda_h.py:19] end restore_tensors2 cost 0.00045299530029296875 seconds
DEBUG 01-15 10:09:19.508336.508336 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024068355560302734 seconds
DEBUG 01-15 10:09:19.508137.508137 cuda_h.py:19] end move_flatidxs cost 0.0009527206420898438 seconds
DEBUG 01-15 10:09:19.508251.508251 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.508496.508496 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:19.511762.511762 cuda_h.py:19] end restore2model cost 0.0025556087493896484 seconds
DEBUG 01-15 10:09:19.511294.511294 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005167722702026367 seconds
DEBUG 01-15 10:09:19.511805.511805 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.511233.511233 cuda_h.py:19] end gpu_sexperts cost 0.00028395652770996094 seconds
DEBUG 01-15 10:09:19.511777.511777 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.513798.513798 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015578269958496094 seconds
DEBUG 01-15 10:09:19.513567.513567 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.514971.514971 cuda_h.py:19] end gpu_group_list cost 0.000335693359375 seconds
DEBUG 01-15 10:09:19.514703.514703 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.515107.515107 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007467269897460938 seconds
DEBUG 01-15 10:09:19.515381.515381 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.514561.514561 cuda_h.py:19] end group_tensors cost 0.0060465335845947266 seconds
DEBUG 01-15 10:09:19.515965.515965 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-15 10:09:19.515900.515900 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.515293.515293 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.520926.520926 cuda_h.py:19] end group pad cost 0.004793882369995117 seconds
DEBUG 01-15 10:09:19.520127.520127 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.542673.542673 cuda_h.py:19] end group_einsum cost 0.022146224975585938 seconds
DEBUG 01-15 10:09:19.542077.542077 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.549497.549497 cuda_h.py:19] end get_outputs_cpu1 cost 0.006711006164550781 seconds
DEBUG 01-15 10:09:19.550528.550528 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04345393180847168 seconds
DEBUG 01-15 10:09:19.551087.551087 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03638792037963867 seconds
DEBUG 01-15 10:09:19.551627.551627 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.552107.552107 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.552340.552340 cuda_h.py:19] end index_scatter cost 0.00018334388732910156 seconds
DEBUG 01-15 10:09:19.553665.553665 cuda_h.py:19] end cpuoutputsdeal cost 0.0012819766998291016 seconds
DEBUG 01-15 10:09:19.553263.553263 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.553079.553079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0650a3c9-2fa8-469f-abf6-f957b7c6ec09
INFO 01-15 10:09:19.558684.558684 client.py:127] Model loaded
DEBUG 01-15 10:09:19.558931.558931 cuda_h.py:19] end wait_experts cost 0.005092620849609375 seconds
DEBUG 01-15 10:09:19.558687.558687 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.558252.558252 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.558015.558015 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.558228.558228 cuda_h.py:19] end gpu_group_tensor cost 0.00019502639770507812 seconds
DEBUG 01-15 10:09:19.558563.558563 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.559461.559461 cuda_h.py:19] end gpu_group_einsum cost 0.0004763603210449219 seconds
DEBUG 01-15 10:09:19.559133.559133 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.559347.559347 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.559291.559291 cuda_h.py:19] end all_expert_outputs_slices cost 0.00027942657470703125 seconds
DEBUG 01-15 10:09:19.559047.559047 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.560787.560787 cuda_h.py:19] end concat_expert_out cost 0.00029730796813964844 seconds
DEBUG 01-15 10:09:19.560043.560043 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.560132.560132 cuda_h.py:19] end index_scatter cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:19.560471.560471 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000946044921875 seconds
DEBUG 01-15 10:09:19.560209.560209 cuda_h.py:19] end gpu_experts cost 0.0021131038665771484 seconds
DEBUG 01-15 10:09:19.560033.560033 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.05725216865539551 seconds
DEBUG 01-15 10:09:19.561662.561662 cuda_h.py:19] end prefill_layer cost 0.0628972053527832 seconds
DEBUG 01-15 10:09:19.561466.561466 lmp.py:1552] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-15 10:09:19.561169.561169 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.561348.561348 lmp.py:1495] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-15 10:09:19.561959.561959 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:19.561052.561052 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:19.561717.561717 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.981590270996094e-05 seconds
DEBUG 01-15 10:09:19.561235.561235 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.271766662597656e-05 seconds
DEBUG 01-15 10:09:19.561553.561553 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.561284.561284 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.561009.561009 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.561972.561972 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.561146.561146 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.561836.561836 cuda_h.py:19] end allocate_cuda_memory cost 0.00019073486328125 seconds
DEBUG 01-15 10:09:19.562104.562104 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.562251.562251 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.562080.562080 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.562121.562121 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8cf249c7-84dd-44ea-90c8-d11f48c7048d
DEBUG 01-15 10:09:19.562541.562541 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.562325.562325 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.562848.562848 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8cf249c7-84dd-44ea-90c8-d11f48c7048d
DEBUG 01-15 10:09:19.562552.562552 cuda_h.py:19] end load_into_gpu_async cost 0.0008893013000488281 seconds
DEBUG 01-15 10:09:19.563116.563116 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.563583.563583 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-15 10:09:19.563531.563531 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001434326171875 seconds
INFO 01-15 10:09:19.563466.563466 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8cf249c7-84dd-44ea-90c8-d11f48c7048d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.566309.566309 cuda_h.py:19] end self_attn cost 0.003611326217651367 seconds
DEBUG 01-15 10:09:19.566750.566750 cuda_h.py:19] end iln_self_attn_paln cost 0.0050623416900634766 seconds
DEBUG 01-15 10:09:19.566593.566593 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-15 10:09:19.566449.566449 cuda_h.py:10] start gate
DEBUG 01-15 10:09:19.567882.567882 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-15 10:09:19.567619.567619 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.567589.567589 lmp.py:1616] 
DEBUG 01-15 10:09:19.567589.567589 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.567583.567583 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.567995.567995 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.567783.567783 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.567665.567665 lmp.py:1620] 
DEBUG 01-15 10:09:19.567665.567665 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.567023.567023 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.567050.567050 lmp.py:1626]   Expert  1 |     50 | CPU
DEBUG 01-15 10:09:19.567408.567408 lmp.py:1626]   Expert 27 |     62 | CPU
DEBUG 01-15 10:09:19.567528.567528 lmp.py:1626]   Expert  7 |     76 | CPU
DEBUG 01-15 10:09:19.567933.567933 lmp.py:1626]   Expert 48 |     81 | CPU
DEBUG 01-15 10:09:19.567337.567337 lmp.py:1626]   Expert 15 |     98 | CPU
DEBUG 01-15 10:09:19.567742.567742 lmp.py:1626]   Expert 30 |    108 | CPU
DEBUG 01-15 10:09:19.567908.567908 lmp.py:1626]   Expert 61 |    115 | CPU
DEBUG 01-15 10:09:19.567074.567074 lmp.py:1626]   Expert 32 |    118 | CPU
DEBUG 01-15 10:09:19.567432.567432 lmp.py:1626]   Expert 45 |    118 | CPU
DEBUG 01-15 10:09:19.567314.567314 lmp.py:1626]   Expert 18 |    119 | CPU
DEBUG 01-15 10:09:19.567195.567195 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:19.567838.567838 lmp.py:1626]   Expert 39 |    135 | CPU
DEBUG 01-15 10:09:19.567719.567719 lmp.py:1626]   Expert 36 |    139 | CPU
DEBUG 01-15 10:09:19.568177.568177 lmp.py:1626]   Expert 11 |    140 | CPU
DEBUG 01-15 10:09:19.568582.568582 lmp.py:1626]   Expert 26 |    140 | CPU
DEBUG 01-15 10:09:19.568271.568271 lmp.py:1626]   Expert  5 |    141 | CPU
DEBUG 01-15 10:09:19.568437.568437 lmp.py:1626]   Expert  6 |    142 | CPU
DEBUG 01-15 10:09:19.568365.568365 lmp.py:1626]   Expert 59 |    144 | CPU
DEBUG 01-15 10:09:19.568293.568293 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:19.568220.568220 lmp.py:1626]   Expert 23 |    155 | CPU
DEBUG 01-15 10:09:19.568625.568625 lmp.py:1626]   Expert 49 |    155 | CPU
DEBUG 01-15 10:09:19.568791.568791 lmp.py:1626]   Expert  2 |    157 | CPU
DEBUG 01-15 10:09:19.568719.568719 lmp.py:1626]   Expert  9 |    159 | CPU
DEBUG 01-15 10:09:19.568646.568646 lmp.py:1626]   Expert 50 |    165 | CPU
DEBUG 01-15 10:09:19.568574.568574 lmp.py:1626]   Expert 40 |    168 | CPU
DEBUG 01-15 10:09:19.568787.568787 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:19.568237.568237 lmp.py:1626]   Expert 56 |    168 | CPU
DEBUG 01-15 10:09:19.568450.568450 lmp.py:1626]   Expert 16 |    171 | CPU
DEBUG 01-15 10:09:19.568424.568424 lmp.py:1626]   Expert 35 |    173 | CPU
DEBUG 01-15 10:09:19.568398.568398 lmp.py:1626]   Expert  4 |    185 | CPU
DEBUG 01-15 10:09:19.568564.568564 lmp.py:1626]   Expert 37 |    189 | CPU
DEBUG 01-15 10:09:19.568492.568492 lmp.py:1626]   Expert 13 |    191 | CPU
DEBUG 01-15 10:09:19.568420.568420 lmp.py:1626]   Expert 42 |    191 | GPU
DEBUG 01-15 10:09:19.568109.568109 lmp.py:1626]   Expert 17 |    197 | GPU
DEBUG 01-15 10:09:19.568037.568037 lmp.py:1626]   Expert 38 |    197 | GPU
DEBUG 01-15 10:09:19.568488.568488 lmp.py:1626]   Expert 62 |    200 | GPU
DEBUG 01-15 10:09:19.568952.568952 lmp.py:1626]   Expert 21 |    202 | GPU
DEBUG 01-15 10:09:19.568403.568403 lmp.py:1626]   Expert 44 |    207 | GPU
DEBUG 01-15 10:09:19.568615.568615 lmp.py:1626]   Expert  3 |    208 | GPU
DEBUG 01-15 10:09:19.568828.568828 lmp.py:1626]   Expert 28 |    212 | GPU
DEBUG 01-15 10:09:19.568040.568040 lmp.py:1626]   Expert 58 |    212 | GPU
DEBUG 01-15 10:09:19.568491.568491 lmp.py:1626]   Expert 60 |    212 | GPU
DEBUG 01-15 10:09:19.568657.568657 lmp.py:1626]   Expert 10 |    214 | GPU
DEBUG 01-15 10:09:19.568062.568062 lmp.py:1626]   Expert 47 |    214 | GPU
DEBUG 01-15 10:09:19.568228.568228 lmp.py:1626]   Expert 53 |    218 | GPU
DEBUG 01-15 10:09:19.568156.568156 lmp.py:1626]   Expert 55 |    220 | GPU
DEBUG 01-15 10:09:19.568083.568083 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:19.568773.568773 lmp.py:1626]   Expert 57 |    226 | GPU
DEBUG 01-15 10:09:19.568985.568985 lmp.py:1626]   Expert 33 |    228 | GPU
DEBUG 01-15 10:09:19.568436.568436 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:19.568649.568649 lmp.py:1626]   Expert 46 |    237 | GPU
DEBUG 01-15 10:09:19.568384.568384 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:19.568835.568835 lmp.py:1626]   Expert 19 |    244 | GPU
DEBUG 01-15 10:09:19.568047.568047 lmp.py:1626]   Expert 24 |    245 | GPU
DEBUG 01-15 10:09:19.568260.568260 lmp.py:1626]   Expert 14 |    261 | GPU
DEBUG 01-15 10:09:19.568234.568234 lmp.py:1626]   Expert 63 |    267 | GPU
DEBUG 01-15 10:09:19.568400.568400 lmp.py:1626]   Expert 12 |    275 | GPU
DEBUG 01-15 10:09:19.568328.568328 lmp.py:1626]   Expert 29 |    275 | GPU
DEBUG 01-15 10:09:19.568779.568779 lmp.py:1626]   Expert 22 |    278 | GPU
DEBUG 01-15 10:09:19.568706.568706 lmp.py:1626]   Expert  0 |    295 | GPU
DEBUG 01-15 10:09:19.568111.568111 lmp.py:1626]   Expert 43 |    310 | GPU
DEBUG 01-15 10:09:19.568562.568562 lmp.py:1626]   Expert 54 |    339 | GPU
DEBUG 01-15 10:09:19.568013.568013 lmp.py:1626]   Expert 41 |    385 | GPU
DEBUG 01-15 10:09:19.568987.568987 lmp.py:1626]   Expert 25 |    410 | GPU
DEBUG 01-15 10:09:19.568915.568915 lmp.py:1627] 
DEBUG 01-15 10:09:19.568915.568915 lmp.py:1627]   CPU total tokens: 4408 (35.9%)
DEBUG 01-15 10:09:19.568319.568319 lmp.py:1628]   GPU total tokens: 7880 (64.1%)
DEBUG 01-15 10:09:19.568777.568777 cuda_h.py:19] end experts_map_get cost 0.0015268325805664062 seconds
DEBUG 01-15 10:09:19.568911.568911 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.568283.568283 lmp.py:1636] 
DEBUG 01-15 10:09:19.568283.568283 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.569689.569689 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-15 10:09:19.569908.569908 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.569738.569738 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.569358.569358 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.569669.569669 cuda_h.py:19] end allocate_cuda_memory cost 0.0002512931823730469 seconds
DEBUG 01-15 10:09:19.569906.569906 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:19.569208.569208 client.py:127] Model loaded
DEBUG 01-15 10:09:19.569549.569549 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.570577.570577 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.570532.570532 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.570525.570525 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.570598.570598 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.570136.570136 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 46a0abfd-a5c6-4515-89a6-480998f44005
DEBUG 01-15 10:09:19.570063.570063 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.570101.570101 cuda_h.py:19] end restore2model cost 0.0007183551788330078 seconds
DEBUG 01-15 10:09:19.570831.570831 cuda_h.py:19] end sllm_worker_task cost 0.009242534637451172 seconds
DEBUG 01-15 10:09:19.571370.571370 cuda_h.py:19] end move_flatidxs cost 0.0008563995361328125 seconds
DEBUG 01-15 10:09:19.571068.571068 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:19.571463.571463 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 46a0abfd-a5c6-4515-89a6-480998f44005
DEBUG 01-15 10:09:19.571598.571598 cuda_h.py:19] end load_into_gpu_async cost 0.001386404037475586 seconds
DEBUG 01-15 10:09:19.571731.571731 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.571317.571317 cuda_h.py:19] end restore_tensors2 cost 0.0004360675811767578 seconds
DEBUG 01-15 10:09:19.572736.572736 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028886795043945312 seconds
DEBUG 01-15 10:09:19.572837.572837 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.574306.574306 cuda_h.py:19] end restore2model cost 0.0025289058685302734 seconds
DEBUG 01-15 10:09:19.574355.574355 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005608797073364258 seconds
DEBUG 01-15 10:09:19.574912.574912 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.575611.575611 cuda_h.py:19] end gpu_sexperts cost 0.0002741813659667969 seconds
DEBUG 01-15 10:09:19.575156.575156 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.576975.576975 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014789104461669922 seconds
DEBUG 01-15 10:09:19.577451.577451 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.576212.576212 cuda_h.py:19] end group_tensors cost 0.0056400299072265625 seconds
DEBUG 01-15 10:09:19.577881.577881 cuda_h.py:19] end gpu_group_list cost 0.0003314018249511719 seconds
DEBUG 01-15 10:09:19.577617.577617 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.577945.577945 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.579171.579171 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011687278747558594 seconds
DEBUG 01-15 10:09:19.579161.579161 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.579428.579428 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-15 10:09:19.579522.579522 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.581569.581569 cuda_h.py:19] end group pad cost 0.004048585891723633 seconds
DEBUG 01-15 10:09:19.581551.581551 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.603733.603733 cuda_h.py:19] end group_einsum cost 0.021350860595703125 seconds
DEBUG 01-15 10:09:19.603003.603003 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.608247.608247 cuda_h.py:19] end get_outputs_cpu1 cost 0.004851579666137695 seconds
DEBUG 01-15 10:09:19.609962.609962 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0393986701965332 seconds
DEBUG 01-15 10:09:19.610269.610269 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031330108642578125 seconds
DEBUG 01-15 10:09:19.610985.610985 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.611981.611981 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.611958.611958 cuda_h.py:19] end index_scatter cost 0.00016999244689941406 seconds
DEBUG 01-15 10:09:19.612997.612997 cuda_h.py:19] end cpuoutputsdeal cost 0.0016601085662841797 seconds
DEBUG 01-15 10:09:19.612074.612074 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.612701.612701 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 46a0abfd-a5c6-4515-89a6-480998f44005
INFO 01-15 10:09:19.622493.622493 client.py:127] Model loaded
DEBUG 01-15 10:09:19.622545.622545 cuda_h.py:19] end wait_experts cost 0.009599924087524414 seconds
DEBUG 01-15 10:09:19.622408.622408 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.622811.622811 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.622257.622257 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.623531.623531 cuda_h.py:19] end gpu_group_tensor cost 0.00040268898010253906 seconds
DEBUG 01-15 10:09:19.623765.623765 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.624983.624983 cuda_h.py:19] end gpu_group_einsum cost 0.0010645389556884766 seconds
DEBUG 01-15 10:09:19.624607.624607 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.625777.625777 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.625673.625673 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005788803100585938 seconds
DEBUG 01-15 10:09:19.625352.625352 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.626299.626299 cuda_h.py:19] end concat_expert_out cost 0.0001304149627685547 seconds
DEBUG 01-15 10:09:19.626165.626165 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.626206.626206 cuda_h.py:19] end index_scatter cost 0.0001513957977294922 seconds
DEBUG 01-15 10:09:19.626573.626573 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014524459838867188 seconds
DEBUG 01-15 10:09:19.626017.626017 cuda_h.py:19] end gpu_experts cost 0.004063606262207031 seconds
DEBUG 01-15 10:09:19.626798.626798 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.06025505065917969 seconds
DEBUG 01-15 10:09:19.627433.627433 cuda_h.py:19] end prefill_layer cost 0.0664067268371582 seconds
DEBUG 01-15 10:09:19.627313.627313 lmp.py:1552] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-15 10:09:19.627547.627547 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.627119.627119 lmp.py:1495] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-15 10:09:19.628167.628167 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:19.628700.628700 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:19.628361.628361 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 9.179115295410156e-05 seconds
DEBUG 01-15 10:09:19.628207.628207 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.628608.628608 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 0.00034618377685546875 seconds
DEBUG 01-15 10:09:19.628203.628203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.628213.628213 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.628297.628297 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.629405.629405 cuda_h.py:19] end allocate_cuda_memory cost 0.0002906322479248047 seconds
DEBUG 01-15 10:09:19.629037.629037 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.629992.629992 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.629298.629298 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.629054.629054 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5e9a8b65-9e8a-497d-bbfa-c7ba4267dede
DEBUG 01-15 10:09:19.629998.629998 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.629542.629542 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:19.630989.630989 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5e9a8b65-9e8a-497d-bbfa-c7ba4267dede
DEBUG 01-15 10:09:19.630496.630496 cuda_h.py:19] end load_into_gpu_async cost 0.001003265380859375 seconds
DEBUG 01-15 10:09:19.630729.630729 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.630600.630600 cuda_h.py:19] end restore_tensors2 cost 8.606910705566406e-05 seconds
DEBUG 01-15 10:09:19.630071.630071 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00180816650390625 seconds
INFO 01-15 10:09:19.630676.630676 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5e9a8b65-9e8a-497d-bbfa-c7ba4267dede
DEBUG 01-15 10:09:19.631368.631368 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.636113.636113 cuda_h.py:19] end self_attn cost 0.005313396453857422 seconds
DEBUG 01-15 10:09:19.637080.637080 cuda_h.py:19] end iln_self_attn_paln cost 0.008051156997680664 seconds
DEBUG 01-15 10:09:19.637647.637647 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-15 10:09:19.637735.637735 cuda_h.py:10] start gate
INFO 01-15 10:09:19.637489.637489 client.py:127] Model loaded
DEBUG 01-15 10:09:19.637419.637419 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.638713.638713 cuda_h.py:19] end restore2model cost 0.0006248950958251953 seconds
DEBUG 01-15 10:09:19.638352.638352 cuda_h.py:19] end sllm_worker_task cost 0.009615659713745117 seconds
DEBUG 01-15 10:09:19.639478.639478 cuda_h.py:19] end gate cost 0.0017392635345458984 seconds
DEBUG 01-15 10:09:19.639905.639905 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.639844.639844 lmp.py:1616] 
DEBUG 01-15 10:09:19.639844.639844 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.639541.639541 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.639410.639410 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.639796.639796 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.639605.639605 lmp.py:1620] 
DEBUG 01-15 10:09:19.639605.639605 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.639414.639414 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.639177.639177 lmp.py:1626]   Expert 14 |     67 | CPU
DEBUG 01-15 10:09:19.640555.640555 lmp.py:1626]   Expert 57 |     72 | CPU
DEBUG 01-15 10:09:19.640219.640219 lmp.py:1626]   Expert 13 |     75 | CPU
DEBUG 01-15 10:09:19.640789.640789 lmp.py:1626]   Expert 26 |     80 | CPU
DEBUG 01-15 10:09:19.640168.640168 lmp.py:1626]   Expert 31 |     90 | CPU
DEBUG 01-15 10:09:19.640354.640354 lmp.py:1626]   Expert 11 |     93 | CPU
DEBUG 01-15 10:09:19.640680.640680 lmp.py:1626]   Expert 54 |     93 | CPU
DEBUG 01-15 10:09:19.640892.640892 lmp.py:1626]   Expert 45 |     95 | CPU
DEBUG 01-15 10:09:19.640866.640866 lmp.py:1626]   Expert 58 |    100 | CPU
DEBUG 01-15 10:09:19.640079.640079 lmp.py:1626]   Expert 30 |    108 | CPU
DEBUG 01-15 10:09:19.640245.640245 lmp.py:1626]   Expert 51 |    109 | CPU
DEBUG 01-15 10:09:19.640696.640696 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:19.640670.640670 lmp.py:1626]   Expert 10 |    114 | CPU
DEBUG 01-15 10:09:19.640121.640121 lmp.py:1626]   Expert 32 |    115 | CPU
DEBUG 01-15 10:09:19.640333.640333 lmp.py:1626]   Expert 20 |    127 | CPU
DEBUG 01-15 10:09:19.640884.640884 lmp.py:1626]   Expert  8 |    133 | CPU
DEBUG 01-15 10:09:19.640480.640480 lmp.py:1626]   Expert  4 |    136 | CPU
DEBUG 01-15 10:09:19.640693.640693 lmp.py:1626]   Expert 63 |    136 | CPU
DEBUG 01-15 10:09:19.640667.640667 lmp.py:1626]   Expert 53 |    141 | CPU
DEBUG 01-15 10:09:19.640682.640682 lmp.py:1626]   Expert 34 |    144 | CPU
DEBUG 01-15 10:09:19.640894.640894 lmp.py:1626]   Expert 61 |    144 | CPU
DEBUG 01-15 10:09:19.640868.640868 lmp.py:1626]   Expert 47 |    146 | CPU
DEBUG 01-15 10:09:19.640842.640842 lmp.py:1626]   Expert 16 |    147 | CPU
DEBUG 01-15 10:09:19.640816.640816 lmp.py:1626]   Expert 28 |    159 | CPU
DEBUG 01-15 10:09:19.640552.640552 lmp.py:1626]   Expert 60 |    159 | CPU
DEBUG 01-15 10:09:19.640764.640764 lmp.py:1626]   Expert 42 |    161 | CPU
DEBUG 01-15 10:09:19.640738.640738 lmp.py:1626]   Expert 17 |    162 | CPU
DEBUG 01-15 10:09:19.640381.640381 lmp.py:1626]   Expert 29 |    170 | CPU
DEBUG 01-15 10:09:19.640408.640408 lmp.py:1626]   Expert 44 |    171 | CPU
DEBUG 01-15 10:09:19.640621.640621 lmp.py:1626]   Expert 27 |    175 | CPU
DEBUG 01-15 10:09:19.640833.640833 lmp.py:1626]   Expert  7 |    176 | CPU
DEBUG 01-15 10:09:19.640569.640569 lmp.py:1626]   Expert 41 |    179 | CPU
DEBUG 01-15 10:09:19.640543.640543 lmp.py:1626]   Expert 48 |    183 | GPU
DEBUG 01-15 10:09:19.640279.640279 lmp.py:1626]   Expert  9 |    184 | GPU
DEBUG 01-15 10:09:19.640014.640014 lmp.py:1626]   Expert 56 |    185 | GPU
DEBUG 01-15 10:09:19.640988.640988 lmp.py:1626]   Expert  3 |    188 | GPU
DEBUG 01-15 10:09:19.640962.640962 lmp.py:1626]   Expert  2 |    190 | GPU
DEBUG 01-15 10:09:19.640605.640605 lmp.py:1626]   Expert 15 |    191 | GPU
DEBUG 01-15 10:09:19.640056.640056 lmp.py:1626]   Expert 24 |    193 | GPU
DEBUG 01-15 10:09:19.640699.640699 lmp.py:1626]   Expert  0 |    195 | GPU
DEBUG 01-15 10:09:19.640912.640912 lmp.py:1626]   Expert 18 |    199 | GPU
DEBUG 01-15 10:09:19.640124.640124 lmp.py:1626]   Expert 55 |    206 | GPU
DEBUG 01-15 10:09:19.640337.640337 lmp.py:1626]   Expert 38 |    214 | GPU
DEBUG 01-15 10:09:19.640311.640311 lmp.py:1626]   Expert 40 |    215 | GPU
DEBUG 01-15 10:09:19.640808.640808 lmp.py:1626]   Expert 22 |    217 | GPU
DEBUG 01-15 10:09:19.640782.640782 lmp.py:1626]   Expert 23 |    218 | GPU
DEBUG 01-15 10:09:19.640518.640518 lmp.py:1626]   Expert  6 |    222 | GPU
DEBUG 01-15 10:09:19.640492.640492 lmp.py:1626]   Expert 37 |    223 | GPU
DEBUG 01-15 10:09:19.640466.640466 lmp.py:1626]   Expert 46 |    233 | GPU
DEBUG 01-15 10:09:19.640678.640678 lmp.py:1626]   Expert 19 |    242 | GPU
DEBUG 01-15 10:09:19.640844.640844 lmp.py:1626]   Expert 39 |    248 | GPU
DEBUG 01-15 10:09:19.640871.640871 lmp.py:1626]   Expert 25 |    251 | GPU
DEBUG 01-15 10:09:19.640276.640276 lmp.py:1626]   Expert 50 |    259 | GPU
DEBUG 01-15 10:09:19.640488.640488 lmp.py:1626]   Expert 12 |    260 | GPU
DEBUG 01-15 10:09:19.641224.641224 lmp.py:1626]   Expert 62 |    270 | GPU
DEBUG 01-15 10:09:19.641436.641436 lmp.py:1626]   Expert 21 |    280 | GPU
DEBUG 01-15 10:09:19.641172.641172 lmp.py:1626]   Expert 35 |    284 | GPU
DEBUG 01-15 10:09:19.641385.641385 lmp.py:1626]   Expert 49 |    292 | GPU
DEBUG 01-15 10:09:19.641120.641120 lmp.py:1626]   Expert 52 |    299 | GPU
DEBUG 01-15 10:09:19.641094.641094 lmp.py:1626]   Expert 33 |    301 | GPU
DEBUG 01-15 10:09:19.641068.641068 lmp.py:1626]   Expert  1 |    348 | GPU
DEBUG 01-15 10:09:19.641281.641281 lmp.py:1626]   Expert  5 |    383 | GPU
DEBUG 01-15 10:09:19.641831.641831 lmp.py:1626]   Expert 43 |    439 | GPU
DEBUG 01-15 10:09:19.641474.641474 lmp.py:1626]   Expert 59 |    586 | GPU
DEBUG 01-15 10:09:19.641071.641071 lmp.py:1627] 
DEBUG 01-15 10:09:19.641071.641071 lmp.py:1627]   CPU total tokens: 4090 (33.3%)
DEBUG 01-15 10:09:19.641859.641859 lmp.py:1628]   GPU total tokens: 8198 (66.7%)
DEBUG 01-15 10:09:19.641986.641986 cuda_h.py:19] end experts_map_get cost 0.001977205276489258 seconds
DEBUG 01-15 10:09:19.641743.641743 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.641353.641353 lmp.py:1636] 
DEBUG 01-15 10:09:19.641353.641353 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.641627.641627 cuda_h.py:19] end cpu_experts_submit cost 6.0558319091796875e-05 seconds
DEBUG 01-15 10:09:19.641846.641846 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.641027.641027 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.641723.641723 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.642898.642898 cuda_h.py:19] end allocate_cuda_memory cost 0.0002677440643310547 seconds
DEBUG 01-15 10:09:19.642735.642735 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.642306.642306 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.642990.642990 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.642646.642646 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3e3e759-4e45-48e2-9c26-285c13cede24
DEBUG 01-15 10:09:19.642662.642662 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:19.642218.642218 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.642649.642649 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.643424.643424 cuda_h.py:19] end move_flatidxs cost 0.0009136199951171875 seconds
DEBUG 01-15 10:09:19.644790.644790 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:19.649839.649839 cuda_h.py:19] end group_tensors cost 0.005781412124633789 seconds
DEBUG 01-15 10:09:19.650032.650032 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.654315.654315 cuda_h.py:19] end group pad cost 0.0038330554962158203 seconds
DEBUG 01-15 10:09:19.654058.654058 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.675136.675136 cuda_h.py:19] end group_einsum cost 0.021026611328125 seconds
DEBUG 01-15 10:09:19.675784.675784 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.680379.680379 cuda_h.py:19] end get_outputs_cpu1 cost 0.004045963287353516 seconds
DEBUG 01-15 10:09:19.681983.681983 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03833723068237305 seconds
INFO 01-15 10:09:19.717369.717369 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3e3e759-4e45-48e2-9c26-285c13cede24
DEBUG 01-15 10:09:19.717848.717848 cuda_h.py:19] end load_into_gpu_async cost 0.07508134841918945 seconds
DEBUG 01-15 10:09:19.717368.717368 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.719573.719573 cuda_h.py:19] end restore_tensors2 cost 0.0012853145599365234 seconds
DEBUG 01-15 10:09:19.719619.719619 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.07774734497070312 seconds
DEBUG 01-15 10:09:19.719318.719318 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.727663.727663 cuda_h.py:19] end restore2model cost 0.00802755355834961 seconds
DEBUG 01-15 10:09:19.727576.727576 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0862431526184082 seconds
DEBUG 01-15 10:09:19.727539.727539 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.728580.728580 cuda_h.py:19] end gpu_sexperts cost 0.001127481460571289 seconds
DEBUG 01-15 10:09:19.729340.729340 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.732723.732723 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0028662681579589844 seconds
DEBUG 01-15 10:09:19.733302.733302 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.733300.733300 cuda_h.py:19] end gpu_group_list cost 0.00045108795166015625 seconds
DEBUG 01-15 10:09:19.733491.733491 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.734725.734725 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009975433349609375 seconds
DEBUG 01-15 10:09:19.734966.734966 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.735677.735677 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-15 10:09:19.735194.735194 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.735213.735213 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0005376338958740234 seconds
DEBUG 01-15 10:09:19.735858.735858 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.735440.735440 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.735716.735716 cuda_h.py:19] end index_scatter cost 8.034706115722656e-05 seconds
DEBUG 01-15 10:09:19.736327.736327 cuda_h.py:19] end cpuoutputsdeal cost 0.0009372234344482422 seconds
DEBUG 01-15 10:09:19.736018.736018 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.736072.736072 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3e3e759-4e45-48e2-9c26-285c13cede24
INFO 01-15 10:09:19.764247.764247 client.py:127] Model loaded
DEBUG 01-15 10:09:19.764411.764411 cuda_h.py:19] end wait_experts cost 0.02811574935913086 seconds
DEBUG 01-15 10:09:19.764335.764335 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.765120.765120 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.765183.765183 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.766630.766630 cuda_h.py:19] end gpu_group_tensor cost 0.0008018016815185547 seconds
DEBUG 01-15 10:09:19.766903.766903 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.767109.767109 cuda_h.py:19] end gpu_group_einsum cost 0.0012962818145751953 seconds
DEBUG 01-15 10:09:19.767217.767217 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.768671.768671 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.768219.768219 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006222724914550781 seconds
DEBUG 01-15 10:09:19.768102.768102 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.769202.769202 cuda_h.py:19] end concat_expert_out cost 0.0001361370086669922 seconds
DEBUG 01-15 10:09:19.769161.769161 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.769015.769015 cuda_h.py:19] end index_scatter cost 0.0001227855682373047 seconds
DEBUG 01-15 10:09:19.769853.769853 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014886856079101562 seconds
DEBUG 01-15 10:09:19.769978.769978 cuda_h.py:19] end gpu_experts cost 0.004683732986450195 seconds
DEBUG 01-15 10:09:19.769997.769997 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.13263630867004395 seconds
DEBUG 01-15 10:09:19.770835.770835 cuda_h.py:19] end prefill_layer cost 0.14261817932128906 seconds
DEBUG 01-15 10:09:19.770555.770555 lmp.py:1552] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-15 10:09:19.770458.770458 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.770745.770745 lmp.py:1495] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-15 10:09:19.770463.770463 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:19.771565.771565 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:19.771132.771132 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.389617919921875e-05 seconds
DEBUG 01-15 10:09:19.771892.771892 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.771174.771174 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 0.0003402233123779297 seconds
DEBUG 01-15 10:09:19.771400.771400 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.771178.771178 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.771018.771018 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.772455.772455 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.772566.772566 cuda_h.py:19] end allocate_cuda_memory cost 0.0004057884216308594 seconds
DEBUG 01-15 10:09:19.772296.772296 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.772444.772444 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.773275.773275 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.773688.773688 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6be1e4f7-dfb1-42f5-8270-e0ee820e74d3
DEBUG 01-15 10:09:19.773958.773958 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.773743.773743 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.775574.775574 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6be1e4f7-dfb1-42f5-8270-e0ee820e74d3
DEBUG 01-15 10:09:19.775805.775805 cuda_h.py:19] end load_into_gpu_async cost 0.002256155014038086 seconds
DEBUG 01-15 10:09:19.775245.775245 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.775392.775392 cuda_h.py:19] end restore_tensors2 cost 0.00017213821411132812 seconds
DEBUG 01-15 10:09:19.775322.775322 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003783702850341797 seconds
INFO 01-15 10:09:19.775924.775924 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6be1e4f7-dfb1-42f5-8270-e0ee820e74d3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.779829.779829 cuda_h.py:19] end self_attn cost 0.005802154541015625 seconds
DEBUG 01-15 10:09:19.780549.780549 cuda_h.py:19] end iln_self_attn_paln cost 0.008210420608520508 seconds
DEBUG 01-15 10:09:19.780691.780691 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-15 10:09:19.780846.780846 cuda_h.py:10] start gate
DEBUG 01-15 10:09:19.781241.781241 cuda_h.py:19] end gate cost 0.00102996826171875 seconds
DEBUG 01-15 10:09:19.781555.781555 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.782304.782304 lmp.py:1616] 
DEBUG 01-15 10:09:19.782304.782304 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.782590.782590 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.782578.782578 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.782227.782227 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.782208.782208 lmp.py:1620] 
DEBUG 01-15 10:09:19.782208.782208 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.782904.782904 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.782031.782031 lmp.py:1626]   Expert 34 |     25 | CPU
DEBUG 01-15 10:09:19.782012.782012 lmp.py:1626]   Expert 45 |     65 | CPU
DEBUG 01-15 10:09:19.782277.782277 lmp.py:1626]   Expert 22 |     73 | CPU
DEBUG 01-15 10:09:19.782304.782304 lmp.py:1626]   Expert 57 |     76 | CPU
DEBUG 01-15 10:09:19.782570.782570 lmp.py:1626]   Expert 17 |     96 | CPU
DEBUG 01-15 10:09:19.782127.782127 lmp.py:1626]   Expert  4 |    100 | CPU
DEBUG 01-15 10:09:19.782585.782585 lmp.py:1626]   Expert 15 |    100 | CPU
DEBUG 01-15 10:09:19.782427.782427 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:19.782454.782454 lmp.py:1626]   Expert 32 |    112 | CPU
DEBUG 01-15 10:09:19.782481.782481 lmp.py:1626]   Expert 60 |    114 | CPU
DEBUG 01-15 10:09:19.782508.782508 lmp.py:1626]   Expert 36 |    124 | CPU
DEBUG 01-15 10:09:19.782058.782058 lmp.py:1626]   Expert 14 |    125 | CPU
DEBUG 01-15 10:09:19.782562.782562 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:19.782590.782590 lmp.py:1626]   Expert 12 |    128 | CPU
DEBUG 01-15 10:09:19.782378.782378 lmp.py:1626]   Expert 25 |    130 | CPU
DEBUG 01-15 10:09:19.782929.782929 lmp.py:1626]   Expert 52 |    130 | CPU
DEBUG 01-15 10:09:19.782717.782717 lmp.py:1626]   Expert  8 |    135 | CPU
DEBUG 01-15 10:09:19.782460.782460 lmp.py:1626]   Expert  2 |    139 | CPU
DEBUG 01-15 10:09:19.782202.782202 lmp.py:1626]   Expert 35 |    142 | CPU
DEBUG 01-15 10:09:19.782421.782421 lmp.py:1626]   Expert  5 |    147 | CPU
DEBUG 01-15 10:09:19.782972.782972 lmp.py:1626]   Expert 23 |    155 | CPU
DEBUG 01-15 10:09:19.782522.782522 lmp.py:1626]   Expert 30 |    155 | CPU
DEBUG 01-15 10:09:19.782072.782072 lmp.py:1626]   Expert 39 |    156 | CPU
DEBUG 01-15 10:09:19.782576.782576 lmp.py:1626]   Expert  0 |    157 | CPU
DEBUG 01-15 10:09:19.782604.782604 lmp.py:1626]   Expert 61 |    157 | CPU
DEBUG 01-15 10:09:19.782869.782869 lmp.py:1626]   Expert  3 |    169 | CPU
DEBUG 01-15 10:09:19.782181.782181 lmp.py:1626]   Expert 13 |    170 | CPU
DEBUG 01-15 10:09:19.782208.782208 lmp.py:1626]   Expert 42 |    171 | CPU
DEBUG 01-15 10:09:19.782520.782520 lmp.py:1626]   Expert 31 |    172 | CPU
DEBUG 01-15 10:09:19.782051.782051 lmp.py:1626]   Expert 44 |    174 | CPU
DEBUG 01-15 10:09:19.782363.782363 lmp.py:1626]   Expert 41 |    176 | CPU
DEBUG 01-15 10:09:19.782768.782768 lmp.py:1626]   Expert 46 |    178 | CPU
DEBUG 01-15 10:09:19.782126.782126 lmp.py:1626]   Expert  9 |    179 | GPU
DEBUG 01-15 10:09:19.782676.782676 lmp.py:1626]   Expert 43 |    182 | GPU
DEBUG 01-15 10:09:19.782558.782558 lmp.py:1626]   Expert 26 |    192 | GPU
DEBUG 01-15 10:09:19.782724.782724 lmp.py:1626]   Expert 27 |    192 | GPU
DEBUG 01-15 10:09:19.782367.782367 lmp.py:1626]   Expert 50 |    192 | GPU
DEBUG 01-15 10:09:19.782533.782533 lmp.py:1626]   Expert 18 |    193 | GPU
DEBUG 01-15 10:09:19.782938.782938 lmp.py:1626]   Expert 62 |    193 | GPU
DEBUG 01-15 10:09:19.782104.782104 lmp.py:1626]   Expert 51 |    195 | GPU
DEBUG 01-15 10:09:19.782508.782508 lmp.py:1626]   Expert 49 |    196 | GPU
DEBUG 01-15 10:09:19.783674.783674 lmp.py:1626]   Expert 11 |    199 | GPU
DEBUG 01-15 10:09:19.783841.783841 lmp.py:1626]   Expert 19 |    202 | GPU
DEBUG 01-15 10:09:19.783530.783530 lmp.py:1626]   Expert 47 |    202 | GPU
DEBUG 01-15 10:09:19.783458.783458 lmp.py:1626]   Expert 20 |    206 | GPU
DEBUG 01-15 10:09:19.783438.783438 lmp.py:1626]   Expert 63 |    208 | GPU
DEBUG 01-15 10:09:19.783273.783273 lmp.py:1626]   Expert 55 |    209 | GPU
DEBUG 01-15 10:09:19.783632.783632 lmp.py:1626]   Expert 56 |    211 | GPU
DEBUG 01-15 10:09:19.783036.783036 lmp.py:1626]   Expert 38 |    218 | GPU
DEBUG 01-15 10:09:19.783202.783202 lmp.py:1626]   Expert 48 |    229 | GPU
DEBUG 01-15 10:09:19.783369.783369 lmp.py:1626]   Expert  1 |    236 | GPU
DEBUG 01-15 10:09:19.783535.783535 lmp.py:1626]   Expert 10 |    239 | GPU
DEBUG 01-15 10:09:19.783701.783701 lmp.py:1626]   Expert 21 |    246 | GPU
DEBUG 01-15 10:09:19.783867.783867 lmp.py:1626]   Expert 54 |    247 | GPU
DEBUG 01-15 10:09:19.783795.783795 lmp.py:1626]   Expert  7 |    248 | GPU
DEBUG 01-15 10:09:19.783961.783961 lmp.py:1626]   Expert 33 |    256 | GPU
DEBUG 01-15 10:09:19.783650.783650 lmp.py:1626]   Expert 29 |    259 | GPU
DEBUG 01-15 10:09:19.783816.783816 lmp.py:1626]   Expert 40 |    264 | GPU
DEBUG 01-15 10:09:19.783559.783559 lmp.py:1626]   Expert 24 |    270 | GPU
DEBUG 01-15 10:09:19.783255.783255 lmp.py:1626]   Expert 59 |    301 | GPU
DEBUG 01-15 10:09:19.783189.783189 lmp.py:1626]   Expert 37 |    333 | GPU
DEBUG 01-15 10:09:19.783216.783216 lmp.py:1626]   Expert 58 |    366 | GPU
DEBUG 01-15 10:09:19.783005.783005 lmp.py:1626]   Expert  6 |    388 | GPU
DEBUG 01-15 10:09:19.783032.783032 lmp.py:1626]   Expert 53 |    855 | GPU
DEBUG 01-15 10:09:19.783252.783252 lmp.py:1627] 
DEBUG 01-15 10:09:19.783252.783252 lmp.py:1627]   CPU total tokens: 4182 (34.0%)
DEBUG 01-15 10:09:19.783232.783232 lmp.py:1628]   GPU total tokens: 8106 (66.0%)
DEBUG 01-15 10:09:19.783220.783220 cuda_h.py:19] end experts_map_get cost 0.0018057823181152344 seconds
INFO 01-15 10:09:19.783443.783443 client.py:127] Model loaded
DEBUG 01-15 10:09:19.783070.783070 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.783113.783113 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.783884.783884 lmp.py:1636] 
DEBUG 01-15 10:09:19.783884.783884 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.784889.784889 cuda_h.py:19] end cpu_experts_submit cost 0.0003573894500732422 seconds
DEBUG 01-15 10:09:19.784645.784645 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.784886.784886 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.784052.784052 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.784723.784723 cuda_h.py:19] end allocate_cuda_memory cost 0.00024175643920898438 seconds
DEBUG 01-15 10:09:19.784534.784534 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.784820.784820 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.785934.785934 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.785498.785498 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b745a64-5b44-4be4-83d4-ea49d56114b3
DEBUG 01-15 10:09:19.785267.785267 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.786911.786911 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:19.786341.786341 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.786131.786131 cuda_h.py:19] end restore2model cost 0.002672910690307617 seconds
DEBUG 01-15 10:09:19.786666.786666 cuda_h.py:19] end sllm_worker_task cost 0.015288352966308594 seconds
DEBUG 01-15 10:09:19.787958.787958 cuda_h.py:19] end move_flatidxs cost 0.0009341239929199219 seconds
INFO 01-15 10:09:19.787004.787004 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b745a64-5b44-4be4-83d4-ea49d56114b3
DEBUG 01-15 10:09:19.787708.787708 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:19.787312.787312 cuda_h.py:19] end load_into_gpu_async cost 0.0028171539306640625 seconds
DEBUG 01-15 10:09:19.787121.787121 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.788734.788734 cuda_h.py:19] end restore_tensors2 cost 0.0004932880401611328 seconds
DEBUG 01-15 10:09:19.788174.788174 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004010915756225586 seconds
DEBUG 01-15 10:09:19.788441.788441 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.791920.791920 cuda_h.py:19] end restore2model cost 0.0028123855590820312 seconds
DEBUG 01-15 10:09:19.791876.791876 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00706171989440918 seconds
DEBUG 01-15 10:09:19.791625.791625 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.791391.791391 cuda_h.py:19] end gpu_sexperts cost 0.00028634071350097656 seconds
DEBUG 01-15 10:09:19.791797.791797 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.793626.793626 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015938282012939453 seconds
DEBUG 01-15 10:09:19.794237.794237 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.794867.794867 cuda_h.py:19] end gpu_group_list cost 0.00036716461181640625 seconds
DEBUG 01-15 10:09:19.794493.794493 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.795340.795340 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007238388061523438 seconds
DEBUG 01-15 10:09:19.795223.795223 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.795999.795999 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.71661376953125e-05 seconds
DEBUG 01-15 10:09:19.795695.795695 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.797689.797689 cuda_h.py:19] end group_tensors cost 0.009871959686279297 seconds
DEBUG 01-15 10:09:19.798576.798576 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.802164.802164 cuda_h.py:19] end group pad cost 0.004067182540893555 seconds
DEBUG 01-15 10:09:19.802577.802577 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.825152.825152 cuda_h.py:19] end group_einsum cost 0.023228168487548828 seconds
DEBUG 01-15 10:09:19.826038.826038 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.831344.831344 cuda_h.py:19] end get_outputs_cpu1 cost 0.004887819290161133 seconds
DEBUG 01-15 10:09:19.832196.832196 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04559755325317383 seconds
DEBUG 01-15 10:09:19.833086.833086 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03749966621398926 seconds
DEBUG 01-15 10:09:19.833914.833914 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.833477.833477 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.834817.834817 cuda_h.py:19] end index_scatter cost 0.00014710426330566406 seconds
DEBUG 01-15 10:09:19.834572.834572 cuda_h.py:19] end cpuoutputsdeal cost 0.0011725425720214844 seconds
DEBUG 01-15 10:09:19.834131.834131 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.834140.834140 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b745a64-5b44-4be4-83d4-ea49d56114b3
INFO 01-15 10:09:19.838486.838486 client.py:127] Model loaded
DEBUG 01-15 10:09:19.838272.838272 cuda_h.py:19] end wait_experts cost 0.003932952880859375 seconds
DEBUG 01-15 10:09:19.838929.838929 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.839755.839755 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.839942.839942 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.839664.839664 cuda_h.py:19] end gpu_group_tensor cost 0.0003275871276855469 seconds
DEBUG 01-15 10:09:19.839021.839021 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.842796.842796 cuda_h.py:19] end gpu_group_einsum cost 0.0022666454315185547 seconds
DEBUG 01-15 10:09:19.842240.842240 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.842959.842959 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.842418.842418 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003788471221923828 seconds
DEBUG 01-15 10:09:19.842578.842578 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.842324.842324 cuda_h.py:19] end concat_expert_out cost 7.939338684082031e-05 seconds
DEBUG 01-15 10:09:19.843248.843248 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.843776.843776 cuda_h.py:19] end index_scatter cost 9.202957153320312e-05 seconds
DEBUG 01-15 10:09:19.843658.843658 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009274482727050781 seconds
DEBUG 01-15 10:09:19.843430.843430 cuda_h.py:19] end gpu_experts cost 0.004423379898071289 seconds
DEBUG 01-15 10:09:19.843057.843057 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06304931640625 seconds
DEBUG 01-15 10:09:19.844373.844373 cuda_h.py:19] end prefill_layer cost 0.07314872741699219 seconds
DEBUG 01-15 10:09:19.844701.844701 lmp.py:1552] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-15 10:09:19.844656.844656 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.844564.844564 lmp.py:1495] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-15 10:09:19.844711.844711 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:19.844527.844527 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:19.844312.844312 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 4.8160552978515625e-05 seconds
DEBUG 01-15 10:09:19.844641.844641 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.844949.844949 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 0.00030303001403808594 seconds
DEBUG 01-15 10:09:19.844566.844566 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.844212.844212 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.845329.845329 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.845711.845711 cuda_h.py:19] end allocate_cuda_memory cost 0.00037026405334472656 seconds
DEBUG 01-15 10:09:19.845608.845608 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.845908.845908 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.845704.845704 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.845328.845328 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1f8b6ff0-2b80-4714-8a88-b9adc33d3805
DEBUG 01-15 10:09:19.845114.845114 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.846883.846883 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.846713.846713 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.846093.846093 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1f8b6ff0-2b80-4714-8a88-b9adc33d3805
DEBUG 01-15 10:09:19.847275.847275 cuda_h.py:19] end load_into_gpu_async cost 0.0012850761413574219 seconds
DEBUG 01-15 10:09:19.847806.847806 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.847944.847944 cuda_h.py:19] end restore_tensors2 cost 0.0001010894775390625 seconds
DEBUG 01-15 10:09:19.847951.847951 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002218484878540039 seconds
INFO 01-15 10:09:19.847571.847571 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1f8b6ff0-2b80-4714-8a88-b9adc33d3805
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.851800.851800 cuda_h.py:19] end self_attn cost 0.004880666732788086 seconds
DEBUG 01-15 10:09:19.852439.852439 cuda_h.py:19] end iln_self_attn_paln cost 0.006939411163330078 seconds
DEBUG 01-15 10:09:19.852329.852329 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-15 10:09:19.852795.852795 cuda_h.py:10] start gate
DEBUG 01-15 10:09:19.853283.853283 cuda_h.py:19] end gate cost 0.0007109642028808594 seconds
DEBUG 01-15 10:09:19.853457.853457 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.853051.853051 lmp.py:1616] 
DEBUG 01-15 10:09:19.853051.853051 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.853523.853523 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.853603.853603 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.853107.853107 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.853227.853227 lmp.py:1620] 
DEBUG 01-15 10:09:19.853227.853227 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.853062.853062 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.853049.853049 lmp.py:1626]   Expert  1 |     45 | CPU
DEBUG 01-15 10:09:19.853692.853692 lmp.py:1626]   Expert  7 |     61 | CPU
DEBUG 01-15 10:09:19.853859.853859 lmp.py:1626]   Expert 37 |     70 | CPU
DEBUG 01-15 10:09:19.853548.853548 lmp.py:1626]   Expert 17 |     76 | CPU
DEBUG 01-15 10:09:19.853522.853522 lmp.py:1626]   Expert 54 |     76 | CPU
DEBUG 01-15 10:09:19.853211.853211 lmp.py:1626]   Expert 18 |     85 | CPU
DEBUG 01-15 10:09:19.853424.853424 lmp.py:1626]   Expert  9 |     93 | CPU
DEBUG 01-15 10:09:19.853398.853398 lmp.py:1626]   Expert 13 |     94 | CPU
DEBUG 01-15 10:09:19.853610.853610 lmp.py:1626]   Expert 58 |    100 | CPU
DEBUG 01-15 10:09:19.853637.853637 lmp.py:1626]   Expert 22 |    104 | CPU
DEBUG 01-15 10:09:19.853996.853996 lmp.py:1626]   Expert  0 |    107 | CPU
DEBUG 01-15 10:09:19.853400.853400 lmp.py:1626]   Expert 26 |    115 | CPU
DEBUG 01-15 10:09:19.853805.853805 lmp.py:1626]   Expert 16 |    117 | CPU
DEBUG 01-15 10:09:19.853494.853494 lmp.py:1626]   Expert 10 |    122 | CPU
DEBUG 01-15 10:09:19.853706.853706 lmp.py:1626]   Expert 63 |    130 | CPU
DEBUG 01-15 10:09:19.853919.853919 lmp.py:1626]   Expert 59 |    131 | CPU
DEBUG 01-15 10:09:19.853370.853370 lmp.py:1626]   Expert 62 |    138 | CPU
DEBUG 01-15 10:09:19.853582.853582 lmp.py:1626]   Expert 43 |    143 | CPU
DEBUG 01-15 10:09:19.853272.853272 lmp.py:1626]   Expert 28 |    146 | CPU
DEBUG 01-15 10:09:19.853722.853722 lmp.py:1626]   Expert 29 |    147 | CPU
DEBUG 01-15 10:09:19.853935.853935 lmp.py:1626]   Expert 33 |    149 | CPU
DEBUG 01-15 10:09:19.853624.853624 lmp.py:1626]   Expert  2 |    159 | CPU
DEBUG 01-15 10:09:19.853175.853175 lmp.py:1626]   Expert 51 |    162 | CPU
DEBUG 01-15 10:09:19.853010.853010 lmp.py:1626]   Expert 11 |    165 | CPU
DEBUG 01-15 10:09:19.853798.853798 lmp.py:1626]   Expert 45 |    165 | CPU
DEBUG 01-15 10:09:19.853607.853607 lmp.py:1626]   Expert 55 |    165 | CPU
DEBUG 01-15 10:09:19.854204.854204 lmp.py:1626]   Expert  3 |    167 | CPU
DEBUG 01-15 10:09:19.854231.854231 lmp.py:1626]   Expert 32 |    167 | CPU
DEBUG 01-15 10:09:19.854828.854828 lmp.py:1626]   Expert 23 |    169 | CPU
DEBUG 01-15 10:09:19.854186.854186 lmp.py:1626]   Expert 53 |    169 | CPU
DEBUG 01-15 10:09:19.854021.854021 lmp.py:1626]   Expert 40 |    170 | CPU
DEBUG 01-15 10:09:19.854141.854141 lmp.py:1626]   Expert 34 |    173 | CPU
DEBUG 01-15 10:09:19.854738.854738 lmp.py:1626]   Expert 14 |    177 | GPU
DEBUG 01-15 10:09:19.854811.854811 lmp.py:1626]   Expert 41 |    181 | GPU
DEBUG 01-15 10:09:19.854646.854646 lmp.py:1626]   Expert 52 |    181 | GPU
DEBUG 01-15 10:09:19.854481.854481 lmp.py:1626]   Expert 42 |    185 | GPU
DEBUG 01-15 10:09:19.854555.854555 lmp.py:1626]   Expert 21 |    186 | GPU
DEBUG 01-15 10:09:19.854357.854357 lmp.py:1626]   Expert 57 |    195 | GPU
DEBUG 01-15 10:09:19.854431.854431 lmp.py:1626]   Expert 30 |    198 | GPU
DEBUG 01-15 10:09:19.854312.854312 lmp.py:1626]   Expert 15 |    200 | GPU
DEBUG 01-15 10:09:19.854670.854670 lmp.py:1626]   Expert 35 |    209 | GPU
DEBUG 01-15 10:09:19.854267.854267 lmp.py:1626]   Expert  4 |    217 | GPU
DEBUG 01-15 10:09:19.854148.854148 lmp.py:1626]   Expert 12 |    218 | GPU
DEBUG 01-15 10:09:19.854745.854745 lmp.py:1626]   Expert 46 |    227 | GPU
DEBUG 01-15 10:09:19.854103.854103 lmp.py:1626]   Expert 19 |    230 | GPU
DEBUG 01-15 10:09:19.854985.854985 lmp.py:1626]   Expert 50 |    230 | GPU
DEBUG 01-15 10:09:19.854581.854581 lmp.py:1626]   Expert 24 |    231 | GPU
DEBUG 01-15 10:09:19.854893.854893 lmp.py:1626]   Expert 44 |    234 | GPU
DEBUG 01-15 10:09:19.854967.854967 lmp.py:1626]   Expert  8 |    235 | GPU
DEBUG 01-15 10:09:19.854278.854278 lmp.py:1626]   Expert 49 |    237 | GPU
DEBUG 01-15 10:09:19.854398.854398 lmp.py:1626]   Expert 38 |    238 | GPU
DEBUG 01-15 10:09:19.854280.854280 lmp.py:1626]   Expert 47 |    247 | GPU
DEBUG 01-15 10:09:19.854876.854876 lmp.py:1626]   Expert  6 |    248 | GPU
DEBUG 01-15 10:09:19.854758.854758 lmp.py:1626]   Expert 31 |    254 | GPU
DEBUG 01-15 10:09:19.854116.854116 lmp.py:1626]   Expert 61 |    263 | GPU
DEBUG 01-15 10:09:19.854236.854236 lmp.py:1626]   Expert 39 |    274 | GPU
DEBUG 01-15 10:09:19.854594.854594 lmp.py:1626]   Expert  5 |    302 | GPU
DEBUG 01-15 10:09:19.854714.854714 lmp.py:1626]   Expert 36 |    306 | GPU
DEBUG 01-15 10:09:19.854503.854503 lmp.py:1626]   Expert 27 |    308 | GPU
DEBUG 01-15 10:09:19.854814.854814 lmp.py:1626]   Expert 60 |    333 | GPU
DEBUG 01-15 10:09:19.854934.854934 lmp.py:1626]   Expert 20 |    340 | GPU
DEBUG 01-15 10:09:19.854292.854292 lmp.py:1626]   Expert 48 |    369 | GPU
DEBUG 01-15 10:09:19.854651.854651 lmp.py:1626]   Expert 25 |    398 | GPU
DEBUG 01-15 10:09:19.854009.854009 lmp.py:1626]   Expert 56 |    557 | GPU
DEBUG 01-15 10:09:19.854559.854559 lmp.py:1627] 
DEBUG 01-15 10:09:19.854559.854559 lmp.py:1627]   CPU total tokens: 4080 (33.2%)
DEBUG 01-15 10:09:19.854871.854871 lmp.py:1628]   GPU total tokens: 8208 (66.8%)
DEBUG 01-15 10:09:19.854951.854951 cuda_h.py:19] end experts_map_get cost 0.0016696453094482422 seconds
INFO 01-15 10:09:19.854266.854266 client.py:127] Model loaded
DEBUG 01-15 10:09:19.854024.854024 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.855987.855987 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.855406.855406 lmp.py:1636] 
DEBUG 01-15 10:09:19.855406.855406 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.855343.855343 cuda_h.py:19] end cpu_experts_submit cost 0.0002727508544921875 seconds
DEBUG 01-15 10:09:19.855807.855807 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.855511.855511 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.855683.855683 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.855036.855036 cuda_h.py:19] end allocate_cuda_memory cost 0.00022101402282714844 seconds
DEBUG 01-15 10:09:19.855893.855893 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.856318.856318 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.856048.856048 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.856612.856612 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e6408ee9-d7e4-424b-a50f-86649f732048
DEBUG 01-15 10:09:19.856408.856408 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.857259.857259 cuda_h.py:19] end restore2model cost 0.002426624298095703 seconds
DEBUG 01-15 10:09:19.857002.857002 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:19.857211.857211 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e6408ee9-d7e4-424b-a50f-86649f732048
DEBUG 01-15 10:09:19.857578.857578 cuda_h.py:19] end sllm_worker_task cost 0.013067007064819336 seconds
DEBUG 01-15 10:09:19.857920.857920 cuda_h.py:19] end load_into_gpu_async cost 0.0019462108612060547 seconds
DEBUG 01-15 10:09:19.858784.858784 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.858208.858208 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.858173.858173 cuda_h.py:19] end restore_tensors2 cost 0.0005023479461669922 seconds
DEBUG 01-15 10:09:19.858606.858606 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032014846801757812 seconds
DEBUG 01-15 10:09:19.858051.858051 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.859009.859009 cuda_h.py:19] end move_flatidxs cost 0.0010848045349121094 seconds
DEBUG 01-15 10:09:19.859456.859456 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:19.861389.861389 cuda_h.py:19] end restore2model cost 0.002919435501098633 seconds
DEBUG 01-15 10:09:19.861101.861101 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006371259689331055 seconds
DEBUG 01-15 10:09:19.861539.861539 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.862054.862054 cuda_h.py:19] end gpu_sexperts cost 0.0003132820129394531 seconds
DEBUG 01-15 10:09:19.862413.862413 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.863428.863428 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015900135040283203 seconds
DEBUG 01-15 10:09:19.864697.864697 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.865260.865260 cuda_h.py:19] end gpu_group_list cost 0.0003483295440673828 seconds
DEBUG 01-15 10:09:19.865185.865185 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.866537.866537 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007750988006591797 seconds
DEBUG 01-15 10:09:19.866778.866778 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.866276.866276 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0742416381835938e-05 seconds
DEBUG 01-15 10:09:19.866641.866641 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.871591.871591 cuda_h.py:19] end group_tensors cost 0.011695623397827148 seconds
DEBUG 01-15 10:09:19.871035.871035 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.876638.876638 cuda_h.py:19] end group pad cost 0.0041103363037109375 seconds
DEBUG 01-15 10:09:19.876382.876382 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.899732.899732 cuda_h.py:19] end group_einsum cost 0.023241519927978516 seconds
DEBUG 01-15 10:09:19.899195.899195 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.904761.904761 cuda_h.py:19] end get_outputs_cpu1 cost 0.004589080810546875 seconds
DEBUG 01-15 10:09:19.905522.905522 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04747319221496582 seconds
DEBUG 01-15 10:09:19.906033.906033 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04009819030761719 seconds
DEBUG 01-15 10:09:19.906145.906145 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.907477.907477 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.907094.907094 cuda_h.py:19] end index_scatter cost 0.00014495849609375 seconds
DEBUG 01-15 10:09:19.907671.907671 cuda_h.py:19] end cpuoutputsdeal cost 0.001180887222290039 seconds
DEBUG 01-15 10:09:19.907323.907323 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.908902.908902 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e6408ee9-d7e4-424b-a50f-86649f732048
INFO 01-15 10:09:19.909755.909755 client.py:127] Model loaded
DEBUG 01-15 10:09:19.909911.909911 cuda_h.py:19] end wait_experts cost 0.0012803077697753906 seconds
DEBUG 01-15 10:09:19.909324.909324 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.909811.909811 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.909515.909515 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.909077.909077 cuda_h.py:19] end gpu_group_tensor cost 0.00031685829162597656 seconds
DEBUG 01-15 10:09:19.910912.910912 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.911436.911436 cuda_h.py:19] end gpu_group_einsum cost 0.0011372566223144531 seconds
DEBUG 01-15 10:09:19.911013.911013 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.911109.911109 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.912599.912599 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005049705505371094 seconds
DEBUG 01-15 10:09:19.912025.912025 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.912859.912859 cuda_h.py:19] end concat_expert_out cost 0.0001125335693359375 seconds
DEBUG 01-15 10:09:19.912591.912591 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.912618.912618 cuda_h.py:19] end index_scatter cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:19.912581.912581 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0012481212615966797 seconds
DEBUG 01-15 10:09:19.913169.913169 cuda_h.py:19] end gpu_experts cost 0.0036203861236572266 seconds
DEBUG 01-15 10:09:19.913014.913014 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.06095385551452637 seconds
DEBUG 01-15 10:09:19.913332.913332 cuda_h.py:19] end prefill_layer cost 0.06959152221679688 seconds
DEBUG 01-15 10:09:19.913202.913202 lmp.py:1552] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-15 10:09:19.913826.913826 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.913257.913257 lmp.py:1495] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-15 10:09:19.913358.913358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:19.914558.914558 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:19.914495.914495 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 5.1021575927734375e-05 seconds
DEBUG 01-15 10:09:19.914695.914695 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.00010156631469726562 seconds
DEBUG 01-15 10:09:19.914120.914120 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.914124.914124 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.914393.914393 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.914102.914102 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.914697.914697 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.915807.915807 cuda_h.py:19] end allocate_cuda_memory cost 0.0004055500030517578 seconds
DEBUG 01-15 10:09:19.915860.915860 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.915578.915578 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.915848.915848 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.915374.915374 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b5f9f3dd-c503-42fe-a227-4354e92857ee
DEBUG 01-15 10:09:19.916130.916130 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.916494.916494 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.917823.917823 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b5f9f3dd-c503-42fe-a227-4354e92857ee
DEBUG 01-15 10:09:19.917888.917888 cuda_h.py:19] end load_into_gpu_async cost 0.0015254020690917969 seconds
DEBUG 01-15 10:09:19.917990.917990 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.917964.917964 cuda_h.py:19] end restore_tensors2 cost 0.000152587890625 seconds
DEBUG 01-15 10:09:19.917894.917894 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027921199798583984 seconds
INFO 01-15 10:09:19.917403.917403 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b5f9f3dd-c503-42fe-a227-4354e92857ee
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.921162.921162 cuda_h.py:19] end self_attn cost 0.00521087646484375 seconds
DEBUG 01-15 10:09:19.922779.922779 cuda_h.py:19] end iln_self_attn_paln cost 0.007779359817504883 seconds
DEBUG 01-15 10:09:19.922849.922849 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-15 10:09:19.922539.922539 cuda_h.py:10] start gate
DEBUG 01-15 10:09:19.923610.923610 cuda_h.py:19] end gate cost 0.0008749961853027344 seconds
DEBUG 01-15 10:09:19.923997.923997 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.923184.923184 lmp.py:1616] 
DEBUG 01-15 10:09:19.923184.923184 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.923178.923178 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.923113.923113 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.923425.923425 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.923068.923068 lmp.py:1620] 
DEBUG 01-15 10:09:19.923068.923068 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.923572.923572 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.923553.923553 lmp.py:1626]   Expert 50 |     43 | CPU
DEBUG 01-15 10:09:19.923103.923103 lmp.py:1626]   Expert  3 |     52 | CPU
DEBUG 01-15 10:09:19.923269.923269 lmp.py:1626]   Expert 46 |     55 | CPU
DEBUG 01-15 10:09:19.923958.923958 lmp.py:1626]   Expert  1 |     78 | CPU
DEBUG 01-15 10:09:19.923648.923648 lmp.py:1626]   Expert  4 |     86 | CPU
DEBUG 01-15 10:09:19.923536.923536 lmp.py:1626]   Expert 29 |     87 | CPU
DEBUG 01-15 10:09:19.923656.923656 lmp.py:1626]   Expert 15 |     96 | CPU
DEBUG 01-15 10:09:19.923537.923537 lmp.py:1626]   Expert 40 |     98 | CPU
DEBUG 01-15 10:09:19.923657.923657 lmp.py:1626]   Expert  8 |    110 | CPU
DEBUG 01-15 10:09:19.923061.923061 lmp.py:1626]   Expert 41 |    112 | CPU
DEBUG 01-15 10:09:19.923658.923658 lmp.py:1626]   Expert 28 |    114 | CPU
DEBUG 01-15 10:09:19.923493.923493 lmp.py:1626]   Expert 16 |    124 | CPU
DEBUG 01-15 10:09:19.923090.923090 lmp.py:1626]   Expert 27 |    128 | CPU
DEBUG 01-15 10:09:19.923402.923402 lmp.py:1626]   Expert 48 |    129 | CPU
DEBUG 01-15 10:09:19.924045.924045 lmp.py:1626]   Expert  6 |    131 | CPU
DEBUG 01-15 10:09:19.924926.924926 lmp.py:1626]   Expert 13 |    131 | CPU
DEBUG 01-15 10:09:19.924046.924046 lmp.py:1626]   Expert 54 |    134 | CPU
DEBUG 01-15 10:09:19.924689.924689 lmp.py:1626]   Expert 39 |    136 | CPU
DEBUG 01-15 10:09:19.924809.924809 lmp.py:1626]   Expert 51 |    136 | CPU
DEBUG 01-15 10:09:19.924690.924690 lmp.py:1626]   Expert  7 |    137 | CPU
DEBUG 01-15 10:09:19.924856.924856 lmp.py:1626]   Expert 60 |    140 | CPU
DEBUG 01-15 10:09:19.924738.924738 lmp.py:1626]   Expert 18 |    141 | CPU
DEBUG 01-15 10:09:19.924381.924381 lmp.py:1626]   Expert 14 |    145 | CPU
DEBUG 01-15 10:09:19.924785.924785 lmp.py:1626]   Expert 43 |    145 | CPU
DEBUG 01-15 10:09:19.924190.924190 lmp.py:1626]   Expert 52 |    146 | CPU
DEBUG 01-15 10:09:19.924356.924356 lmp.py:1626]   Expert 56 |    146 | CPU
DEBUG 01-15 10:09:19.924237.924237 lmp.py:1626]   Expert 20 |    148 | CPU
DEBUG 01-15 10:09:19.924834.924834 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:19.924192.924192 lmp.py:1626]   Expert 36 |    154 | CPU
DEBUG 01-15 10:09:19.924789.924789 lmp.py:1626]   Expert 10 |    157 | CPU
DEBUG 01-15 10:09:19.924955.924955 lmp.py:1626]   Expert 11 |    157 | CPU
DEBUG 01-15 10:09:19.924121.924121 lmp.py:1626]   Expert 45 |    159 | CPU
DEBUG 01-15 10:09:19.924526.924526 lmp.py:1626]   Expert  5 |    161 | GPU
DEBUG 01-15 10:09:19.924453.924453 lmp.py:1626]   Expert 62 |    167 | GPU
DEBUG 01-15 10:09:19.924858.924858 lmp.py:1626]   Expert 57 |    173 | GPU
DEBUG 01-15 10:09:19.924415.924415 lmp.py:1626]   Expert 44 |    176 | GPU
DEBUG 01-15 10:09:19.924820.924820 lmp.py:1626]   Expert 33 |    179 | GPU
DEBUG 01-15 10:09:19.924768.924768 lmp.py:1626]   Expert 25 |    181 | GPU
DEBUG 01-15 10:09:19.924364.924364 lmp.py:1626]   Expert 58 |    182 | GPU
DEBUG 01-15 10:09:19.924961.924961 lmp.py:1626]   Expert 53 |    184 | GPU
DEBUG 01-15 10:09:19.924319.924319 lmp.py:1626]   Expert  2 |    190 | GPU
DEBUG 01-15 10:09:19.924724.924724 lmp.py:1626]   Expert 32 |    190 | GPU
DEBUG 01-15 10:09:19.924367.924367 lmp.py:1626]   Expert 21 |    201 | GPU
DEBUG 01-15 10:09:19.924294.924294 lmp.py:1626]   Expert 35 |    201 | GPU
DEBUG 01-15 10:09:19.924461.924461 lmp.py:1626]   Expert 31 |    202 | GPU
DEBUG 01-15 10:09:19.924388.924388 lmp.py:1626]   Expert 49 |    204 | GPU
DEBUG 01-15 10:09:19.924031.924031 lmp.py:1626]   Expert 63 |    204 | GPU
DEBUG 01-15 10:09:19.924674.924674 lmp.py:1626]   Expert 17 |    206 | GPU
DEBUG 01-15 10:09:19.924079.924079 lmp.py:1626]   Expert 42 |    218 | GPU
DEBUG 01-15 10:09:19.924199.924199 lmp.py:1626]   Expert 34 |    223 | GPU
DEBUG 01-15 10:09:19.924842.924842 lmp.py:1626]   Expert 37 |    229 | GPU
DEBUG 01-15 10:09:19.924200.924200 lmp.py:1626]   Expert 59 |    230 | GPU
DEBUG 01-15 10:09:19.924796.924796 lmp.py:1626]   Expert 22 |    239 | GPU
DEBUG 01-15 10:09:19.924691.924691 lmp.py:1626]   Expert  0 |    240 | GPU
DEBUG 01-15 10:09:19.924050.924050 lmp.py:1626]   Expert 19 |    257 | GPU
DEBUG 01-15 10:09:19.924454.924454 lmp.py:1626]   Expert 24 |    286 | GPU
DEBUG 01-15 10:09:19.924097.924097 lmp.py:1626]   Expert 61 |    288 | GPU
DEBUG 01-15 10:09:19.924740.924740 lmp.py:1626]   Expert 30 |    300 | GPU
DEBUG 01-15 10:09:19.924145.924145 lmp.py:1626]   Expert 47 |    320 | GPU
DEBUG 01-15 10:09:19.924549.924549 lmp.py:1626]   Expert 38 |    367 | GPU
DEBUG 01-15 10:09:19.924192.924192 lmp.py:1626]   Expert 26 |    376 | GPU
DEBUG 01-15 10:09:19.924074.924074 lmp.py:1626]   Expert 12 |    424 | GPU
DEBUG 01-15 10:09:19.924386.924386 lmp.py:1626]   Expert  9 |    683 | GPU
DEBUG 01-15 10:09:19.924459.924459 lmp.py:1626]   Expert 23 |    701 | GPU
DEBUG 01-15 10:09:19.924725.924725 lmp.py:1627] 
DEBUG 01-15 10:09:19.924725.924725 lmp.py:1627]   CPU total tokens: 3906 (31.8%)
DEBUG 01-15 10:09:19.924560.924560 lmp.py:1628]   GPU total tokens: 8382 (68.2%)
DEBUG 01-15 10:09:19.924686.924686 cuda_h.py:19] end experts_map_get cost 0.0017671585083007812 seconds
INFO 01-15 10:09:19.925439.925439 client.py:127] Model loaded
DEBUG 01-15 10:09:19.925350.925350 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.925260.925260 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.925725.925725 lmp.py:1636] 
DEBUG 01-15 10:09:19.925725.925725 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.925662.925662 cuda_h.py:19] end cpu_experts_submit cost 0.0002722740173339844 seconds
DEBUG 01-15 10:09:19.925027.925027 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.925293.925293 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.925843.925843 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.926315.926315 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-15 10:09:19.926257.926257 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.926252.926252 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.926352.926352 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.926214.926214 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2e2a532-13e5-4c55-b6b6-6e26c53dbe6c
DEBUG 01-15 10:09:19.926196.926196 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:19.927973.927973 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2e2a532-13e5-4c55-b6b6-6e26c53dbe6c
DEBUG 01-15 10:09:19.927431.927431 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:19.927468.927468 cuda_h.py:19] end load_into_gpu_async cost 0.0016999244689941406 seconds
DEBUG 01-15 10:09:19.927283.927283 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.928958.928958 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.928878.928878 cuda_h.py:19] end restore_tensors2 cost 0.00051116943359375 seconds
DEBUG 01-15 10:09:19.928364.928364 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002869129180908203 seconds
DEBUG 01-15 10:09:19.928485.928485 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.928256.928256 cuda_h.py:19] end restore2model cost 0.0032601356506347656 seconds
DEBUG 01-15 10:09:19.929480.929480 cuda_h.py:19] end sllm_worker_task cost 0.014480829238891602 seconds
DEBUG 01-15 10:09:19.929713.929713 cuda_h.py:19] end move_flatidxs cost 0.00110626220703125 seconds
DEBUG 01-15 10:09:19.929742.929742 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:19.931541.931541 cuda_h.py:19] end restore2model cost 0.0028901100158691406 seconds
DEBUG 01-15 10:09:19.931697.931697 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006157636642456055 seconds
DEBUG 01-15 10:09:19.931923.931923 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:19.932762.932762 cuda_h.py:19] end gpu_sexperts cost 0.0003044605255126953 seconds
DEBUG 01-15 10:09:19.932122.932122 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:19.934266.934266 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0018963813781738281 seconds
DEBUG 01-15 10:09:19.935674.935674 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:19.935708.935708 cuda_h.py:19] end gpu_group_list cost 0.0003781318664550781 seconds
DEBUG 01-15 10:09:19.935635.935635 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:19.936260.936260 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008008480072021484 seconds
DEBUG 01-15 10:09:19.936454.936454 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:19.936999.936999 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1219253540039062e-05 seconds
DEBUG 01-15 10:09:19.936695.936695 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:19.936308.936308 cuda_h.py:19] end group_tensors cost 0.006583452224731445 seconds
DEBUG 01-15 10:09:19.936796.936796 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:19.940624.940624 cuda_h.py:19] end group pad cost 0.0038781166076660156 seconds
DEBUG 01-15 10:09:19.940029.940029 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:19.961942.961942 cuda_h.py:19] end group_einsum cost 0.02001476287841797 seconds
DEBUG 01-15 10:09:19.961311.961311 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:19.965677.965677 cuda_h.py:19] end get_outputs_cpu1 cost 0.004538059234619141 seconds
DEBUG 01-15 10:09:19.966496.966496 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03876900672912598 seconds
DEBUG 01-15 10:09:19.967036.967036 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03085470199584961 seconds
DEBUG 01-15 10:09:19.967591.967591 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:19.968245.968245 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.968285.968285 cuda_h.py:19] end index_scatter cost 0.00012612342834472656 seconds
DEBUG 01-15 10:09:19.968039.968039 cuda_h.py:19] end cpuoutputsdeal cost 0.0010743141174316406 seconds
DEBUG 01-15 10:09:19.969970.969970 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:19.969581.969581 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2e2a532-13e5-4c55-b6b6-6e26c53dbe6c
INFO 01-15 10:09:19.978752.978752 client.py:127] Model loaded
DEBUG 01-15 10:09:19.978339.978339 cuda_h.py:19] end wait_experts cost 0.009589195251464844 seconds
DEBUG 01-15 10:09:19.978705.978705 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:19.978007.978007 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:19.978572.978572 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:19.979030.979030 cuda_h.py:19] end gpu_group_tensor cost 0.00032138824462890625 seconds
DEBUG 01-15 10:09:19.979546.979546 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:19.980890.980890 cuda_h.py:19] end gpu_group_einsum cost 0.0010700225830078125 seconds
DEBUG 01-15 10:09:19.980513.980513 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:19.981133.981133 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:19.981171.981171 cuda_h.py:19] end all_expert_outputs_slices cost 0.00048828125 seconds
DEBUG 01-15 10:09:19.981120.981120 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:19.981848.981848 cuda_h.py:19] end concat_expert_out cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:19.981773.981773 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:19.982289.982289 cuda_h.py:19] end index_scatter cost 0.00010013580322265625 seconds
DEBUG 01-15 10:09:19.982245.982245 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011932849884033203 seconds
DEBUG 01-15 10:09:19.982807.982807 cuda_h.py:19] end gpu_experts cost 0.003543376922607422 seconds
DEBUG 01-15 10:09:19.982482.982482 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06038403511047363 seconds
DEBUG 01-15 10:09:19.983871.983871 cuda_h.py:19] end prefill_layer cost 0.06932950019836426 seconds
DEBUG 01-15 10:09:19.983020.983020 lmp.py:1552] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-15 10:09:19.983095.983095 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:19.983554.983554 lmp.py:1495] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-15 10:09:19.983059.983059 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:19.983571.983571 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:19.983198.983198 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 8.058547973632812e-05 seconds
DEBUG 01-15 10:09:19.983479.983479 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 0.0001583099365234375 seconds
DEBUG 01-15 10:09:19.983262.983262 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:19.984491.984491 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:19.984894.984894 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.984996.984996 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.984948.984948 cuda_h.py:19] end allocate_cuda_memory cost 0.00030231475830078125 seconds
DEBUG 01-15 10:09:19.984474.984474 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.984713.984713 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.984589.984589 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.984915.984915 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a28be3f4-4bca-4eb3-8baf-0bccab00efc9
DEBUG 01-15 10:09:19.984242.984242 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.985382.985382 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:19.985593.985593 cuda_h.py:10] start self_attn
INFO 01-15 10:09:19.985598.985598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a28be3f4-4bca-4eb3-8baf-0bccab00efc9
DEBUG 01-15 10:09:19.986996.986996 cuda_h.py:19] end load_into_gpu_async cost 0.0013282299041748047 seconds
DEBUG 01-15 10:09:19.986759.986759 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.986306.986306 cuda_h.py:19] end restore_tensors2 cost 9.608268737792969e-05 seconds
DEBUG 01-15 10:09:19.986493.986493 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020155906677246094 seconds
INFO 01-15 10:09:19.986495.986495 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a28be3f4-4bca-4eb3-8baf-0bccab00efc9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:19.991307.991307 cuda_h.py:19] end self_attn cost 0.005629539489746094 seconds
DEBUG 01-15 10:09:19.992684.992684 cuda_h.py:19] end iln_self_attn_paln cost 0.008179187774658203 seconds
DEBUG 01-15 10:09:19.992363.992363 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-15 10:09:19.992743.992743 cuda_h.py:10] start gate
INFO 01-15 10:09:19.992290.992290 client.py:127] Model loaded
DEBUG 01-15 10:09:19.992413.992413 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:19.993761.993761 cuda_h.py:19] end restore2model cost 0.0006635189056396484 seconds
DEBUG 01-15 10:09:19.993273.993273 cuda_h.py:19] end sllm_worker_task cost 0.009359359741210938 seconds
DEBUG 01-15 10:09:19.994168.994168 cuda_h.py:19] end gate cost 0.001756906509399414 seconds
DEBUG 01-15 10:09:19.994992.994992 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:19.994262.994262 lmp.py:1616] 
DEBUG 01-15 10:09:19.994262.994262 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:19.994084.994084 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:19.994072.994072 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:19.994053.994053 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:19.994126.994126 lmp.py:1620] 
DEBUG 01-15 10:09:19.994126.994126 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:19.994392.994392 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:19.994419.994419 lmp.py:1626]   Expert 38 |     13 | CPU
DEBUG 01-15 10:09:19.994539.994539 lmp.py:1626]   Expert 39 |     61 | CPU
DEBUG 01-15 10:09:19.994943.994943 lmp.py:1626]   Expert  7 |     72 | CPU
DEBUG 01-15 10:09:19.994109.994109 lmp.py:1626]   Expert 30 |     73 | CPU
DEBUG 01-15 10:09:19.994037.994037 lmp.py:1626]   Expert 24 |     92 | CPU
DEBUG 01-15 10:09:19.994442.994442 lmp.py:1626]   Expert 14 |     93 | CPU
DEBUG 01-15 10:09:19.994846.994846 lmp.py:1626]   Expert 27 |     95 | CPU
DEBUG 01-15 10:09:19.994774.994774 lmp.py:1626]   Expert 36 |     97 | CPU
DEBUG 01-15 10:09:19.994940.994940 lmp.py:1626]   Expert 17 |     99 | CPU
DEBUG 01-15 10:09:19.994106.994106 lmp.py:1626]   Expert 40 |    100 | CPU
DEBUG 01-15 10:09:19.994465.994465 lmp.py:1626]   Expert 16 |    104 | CPU
DEBUG 01-15 10:09:19.994823.994823 lmp.py:1626]   Expert 32 |    105 | CPU
DEBUG 01-15 10:09:19.994519.994519 lmp.py:1626]   Expert 48 |    109 | CPU
DEBUG 01-15 10:09:19.994923.994923 lmp.py:1626]   Expert 18 |    110 | CPU
DEBUG 01-15 10:09:19.994566.994566 lmp.py:1626]   Expert  1 |    114 | CPU
DEBUG 01-15 10:09:19.994494.994494 lmp.py:1626]   Expert 12 |    116 | CPU
DEBUG 01-15 10:09:19.995422.995422 lmp.py:1626]   Expert  6 |    127 | CPU
DEBUG 01-15 10:09:19.995350.995350 lmp.py:1626]   Expert 59 |    130 | CPU
DEBUG 01-15 10:09:19.995277.995277 lmp.py:1626]   Expert 42 |    136 | CPU
DEBUG 01-15 10:09:19.995443.995443 lmp.py:1626]   Expert  0 |    140 | CPU
DEBUG 01-15 10:09:19.995371.995371 lmp.py:1626]   Expert 22 |    145 | CPU
DEBUG 01-15 10:09:19.995537.995537 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:19.995657.995657 lmp.py:1626]   Expert 53 |    149 | CPU
DEBUG 01-15 10:09:19.995446.995446 lmp.py:1626]   Expert  8 |    160 | CPU
DEBUG 01-15 10:09:19.995612.995612 lmp.py:1626]   Expert 60 |    167 | CPU
DEBUG 01-15 10:09:19.995778.995778 lmp.py:1626]   Expert 15 |    168 | CPU
DEBUG 01-15 10:09:19.995944.995944 lmp.py:1626]   Expert 44 |    169 | CPU
DEBUG 01-15 10:09:19.995872.995872 lmp.py:1626]   Expert 29 |    171 | CPU
DEBUG 01-15 10:09:19.995561.995561 lmp.py:1626]   Expert 54 |    173 | CPU
DEBUG 01-15 10:09:19.995966.995966 lmp.py:1626]   Expert 34 |    182 | CPU
DEBUG 01-15 10:09:19.995132.995132 lmp.py:1626]   Expert 35 |    182 | CPU
DEBUG 01-15 10:09:19.995298.995298 lmp.py:1626]   Expert 33 |    183 | CPU
DEBUG 01-15 10:09:19.995226.995226 lmp.py:1626]   Expert 47 |    189 | GPU
DEBUG 01-15 10:09:19.995630.995630 lmp.py:1626]   Expert 19 |    190 | GPU
DEBUG 01-15 10:09:19.995558.995558 lmp.py:1626]   Expert  9 |    191 | GPU
DEBUG 01-15 10:09:19.995486.995486 lmp.py:1626]   Expert 46 |    198 | GPU
DEBUG 01-15 10:09:19.995652.995652 lmp.py:1626]   Expert 56 |    198 | GPU
DEBUG 01-15 10:09:19.995341.995341 lmp.py:1626]   Expert  3 |    199 | GPU
DEBUG 01-15 10:09:19.995507.995507 lmp.py:1626]   Expert 45 |    199 | GPU
DEBUG 01-15 10:09:19.995197.995197 lmp.py:1626]   Expert 21 |    200 | GPU
DEBUG 01-15 10:09:19.995701.995701 lmp.py:1626]   Expert 20 |    201 | GPU
DEBUG 01-15 10:09:19.995297.995297 lmp.py:1626]   Expert 49 |    203 | GPU
DEBUG 01-15 10:09:19.995463.995463 lmp.py:1626]   Expert 28 |    207 | GPU
DEBUG 01-15 10:09:19.995630.995630 lmp.py:1626]   Expert  2 |    222 | GPU
DEBUG 01-15 10:09:19.995319.995319 lmp.py:1626]   Expert 57 |    223 | GPU
DEBUG 01-15 10:09:19.995485.995485 lmp.py:1626]   Expert  4 |    226 | GPU
DEBUG 01-15 10:09:19.995174.995174 lmp.py:1626]   Expert 13 |    226 | GPU
DEBUG 01-15 10:09:19.995340.995340 lmp.py:1626]   Expert 43 |    228 | GPU
DEBUG 01-15 10:09:19.995030.995030 lmp.py:1626]   Expert 10 |    240 | GPU
DEBUG 01-15 10:09:19.995434.995434 lmp.py:1626]   Expert 50 |    244 | GPU
DEBUG 01-15 10:09:19.995362.995362 lmp.py:1626]   Expert 41 |    246 | GPU
DEBUG 01-15 10:09:19.995482.995482 lmp.py:1626]   Expert 26 |    250 | GPU
DEBUG 01-15 10:09:19.995602.995602 lmp.py:1626]   Expert 63 |    252 | GPU
DEBUG 01-15 10:09:19.995721.995721 lmp.py:1626]   Expert 37 |    258 | GPU
DEBUG 01-15 10:09:19.995318.995318 lmp.py:1626]   Expert 61 |    272 | GPU
DEBUG 01-15 10:09:19.995484.995484 lmp.py:1626]   Expert 31 |    273 | GPU
DEBUG 01-15 10:09:19.995412.995412 lmp.py:1626]   Expert 52 |    305 | GPU
DEBUG 01-15 10:09:19.995863.995863 lmp.py:1626]   Expert 58 |    317 | GPU
DEBUG 01-15 10:09:19.995791.995791 lmp.py:1626]   Expert 62 |    326 | GPU
DEBUG 01-15 10:09:19.995718.995718 lmp.py:1626]   Expert 55 |    339 | GPU
DEBUG 01-15 10:09:19.995646.995646 lmp.py:1626]   Expert 11 |    378 | GPU
DEBUG 01-15 10:09:19.995574.995574 lmp.py:1626]   Expert 23 |    384 | GPU
DEBUG 01-15 10:09:19.995740.995740 lmp.py:1626]   Expert 25 |    407 | GPU
DEBUG 01-15 10:09:19.995906.995906 lmp.py:1626]   Expert  5 |    517 | GPU
DEBUG 01-15 10:09:19.995086.995086 lmp.py:1627] 
DEBUG 01-15 10:09:19.995086.995086 lmp.py:1627]   CPU total tokens: 3980 (32.4%)
DEBUG 01-15 10:09:19.995351.995351 lmp.py:1628]   GPU total tokens: 8308 (67.6%)
DEBUG 01-15 10:09:19.995862.995862 cuda_h.py:19] end experts_map_get cost 0.0016283988952636719 seconds
DEBUG 01-15 10:09:19.995003.995003 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:19.995713.995713 lmp.py:1636] 
DEBUG 01-15 10:09:19.995713.995713 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:19.996609.996609 cuda_h.py:19] end cpu_experts_submit cost 6.461143493652344e-05 seconds
DEBUG 01-15 10:09:19.996259.996259 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:19.996486.996486 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:19.996473.996473 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:19.996819.996819 cuda_h.py:19] end allocate_cuda_memory cost 0.0002446174621582031 seconds
DEBUG 01-15 10:09:19.997074.997074 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:19.997028.997028 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:19.997713.997713 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:19.997419.997419 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:19.997754.997754 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bfbd9b26-9f2e-4bed-97dd-20ed46c19ae3
DEBUG 01-15 10:09:19.997463.997463 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:19.997709.997709 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:19.998830.998830 cuda_h.py:19] end move_flatidxs cost 0.0009894371032714844 seconds
DEBUG 01-15 10:09:19.998932.998932 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:19.998476.998476 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bfbd9b26-9f2e-4bed-97dd-20ed46c19ae3
DEBUG 01-15 10:09:19.998180.998180 cuda_h.py:19] end load_into_gpu_async cost 0.0017626285552978516 seconds
DEBUG 01-15 10:09:19.998168.998168 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:19.999822.999822 cuda_h.py:19] end restore_tensors2 cost 0.0005254745483398438 seconds
DEBUG 01-15 10:09:19.999102.999102 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033426284790039062 seconds
DEBUG 01-15 10:09:19.999309.999309 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.002633.002633 cuda_h.py:19] end restore2model cost 0.0028939247131347656 seconds
DEBUG 01-15 10:09:20.002252.002252 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006501197814941406 seconds
DEBUG 01-15 10:09:20.002955.002955 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.002331.002331 cuda_h.py:19] end gpu_sexperts cost 0.00031447410583496094 seconds
DEBUG 01-15 10:09:20.003167.003167 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.005829.005829 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0023124217987060547 seconds
DEBUG 01-15 10:09:20.006965.006965 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.006232.006232 cuda_h.py:19] end gpu_group_list cost 0.0003609657287597656 seconds
DEBUG 01-15 10:09:20.006309.006309 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.007190.007190 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007476806640625 seconds
DEBUG 01-15 10:09:20.007642.007642 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.007994.007994 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-15 10:09:20.007644.007644 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.012847.012847 cuda_h.py:19] end group_tensors cost 0.014189481735229492 seconds
DEBUG 01-15 10:09:20.014573.014573 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.018735.018735 cuda_h.py:19] end group pad cost 0.003988742828369141 seconds
DEBUG 01-15 10:09:20.018677.018677 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.041268.041268 cuda_h.py:19] end group_einsum cost 0.022868633270263672 seconds
DEBUG 01-15 10:09:20.041585.041585 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.046191.046191 cuda_h.py:19] end get_outputs_cpu1 cost 0.004610776901245117 seconds
DEBUG 01-15 10:09:20.047130.047130 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.049750566482543945 seconds
DEBUG 01-15 10:09:20.048796.048796 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.040430307388305664 seconds
DEBUG 01-15 10:09:20.048123.048123 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.049073.049073 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.049705.049705 cuda_h.py:19] end index_scatter cost 0.00016927719116210938 seconds
DEBUG 01-15 10:09:20.049214.049214 cuda_h.py:19] end cpuoutputsdeal cost 0.0012271404266357422 seconds
DEBUG 01-15 10:09:20.050893.050893 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.050777.050777 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bfbd9b26-9f2e-4bed-97dd-20ed46c19ae3
INFO 01-15 10:09:20.051864.051864 client.py:127] Model loaded
DEBUG 01-15 10:09:20.051802.051802 cuda_h.py:19] end wait_experts cost 0.0013613700866699219 seconds
DEBUG 01-15 10:09:20.051421.051421 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.051823.051823 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.051978.051978 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.052557.052557 cuda_h.py:19] end gpu_group_tensor cost 0.0003814697265625 seconds
DEBUG 01-15 10:09:20.052803.052803 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.053943.053943 cuda_h.py:19] end gpu_group_einsum cost 0.0010752677917480469 seconds
DEBUG 01-15 10:09:20.053911.053911 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.054069.054069 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.054488.054488 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005745887756347656 seconds
DEBUG 01-15 10:09:20.054359.054359 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.055313.055313 cuda_h.py:19] end concat_expert_out cost 0.0001354217529296875 seconds
DEBUG 01-15 10:09:20.055271.055271 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.055119.055119 cuda_h.py:19] end index_scatter cost 0.00010919570922851562 seconds
DEBUG 01-15 10:09:20.055393.055393 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013952255249023438 seconds
DEBUG 01-15 10:09:20.055701.055701 cuda_h.py:19] end gpu_experts cost 0.003949403762817383 seconds
DEBUG 01-15 10:09:20.055693.055693 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.06338310241699219 seconds
DEBUG 01-15 10:09:20.056840.056840 cuda_h.py:19] end prefill_layer cost 0.07281970977783203 seconds
DEBUG 01-15 10:09:20.056896.056896 lmp.py:1552] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-15 10:09:20.056673.056673 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.056495.056495 lmp.py:1495] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-15 10:09:20.056603.056603 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:20.056797.056797 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:20.056900.056900 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:20.056876.056876 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.00011754035949707031 seconds
DEBUG 01-15 10:09:20.056645.056645 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.057273.057273 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.057966.057966 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.057849.057849 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.057196.057196 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.057076.057076 cuda_h.py:19] end allocate_cuda_memory cost 0.0003192424774169922 seconds
DEBUG 01-15 10:09:20.057654.057654 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.057755.057755 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.058783.058783 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.058592.058592 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e746fae3-d5ce-4001-bdf3-ba787fa2de71
DEBUG 01-15 10:09:20.058040.058040 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.058974.058974 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.058765.058765 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e746fae3-d5ce-4001-bdf3-ba787fa2de71
DEBUG 01-15 10:09:20.058649.058649 cuda_h.py:19] end load_into_gpu_async cost 0.0009713172912597656 seconds
DEBUG 01-15 10:09:20.058073.058073 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.059574.059574 cuda_h.py:19] end restore_tensors2 cost 9.465217590332031e-05 seconds
DEBUG 01-15 10:09:20.059999.059999 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016829967498779297 seconds
INFO 01-15 10:09:20.059743.059743 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e746fae3-d5ce-4001-bdf3-ba787fa2de71
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.063988.063988 cuda_h.py:19] end self_attn cost 0.005203962326049805 seconds
DEBUG 01-15 10:09:20.064841.064841 cuda_h.py:19] end iln_self_attn_paln cost 0.00756525993347168 seconds
DEBUG 01-15 10:09:20.064805.064805 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-15 10:09:20.064768.064768 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.065667.065667 cuda_h.py:19] end gate cost 0.0006773471832275391 seconds
DEBUG 01-15 10:09:20.065887.065887 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.065905.065905 lmp.py:1616] 
DEBUG 01-15 10:09:20.065905.065905 lmp.py:1616] Expert Token Distribution & Device Allocation:
INFO 01-15 10:09:20.065703.065703 client.py:127] Model loaded
DEBUG 01-15 10:09:20.065494.065494 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.066172.066172 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.066055.066055 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.066817.066817 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.066420.066420 lmp.py:1620] 
DEBUG 01-15 10:09:20.066420.066420 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.066355.066355 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.066051.066051 lmp.py:1626]   Expert 24 |     38 | CPU
DEBUG 01-15 10:09:20.066601.066601 lmp.py:1626]   Expert  2 |     47 | CPU
DEBUG 01-15 10:09:20.066805.066805 lmp.py:1626]   Expert 32 |     64 | CPU
DEBUG 01-15 10:09:20.066653.066653 lmp.py:1626]   Expert 26 |     65 | CPU
DEBUG 01-15 10:09:20.066919.066919 lmp.py:1626]   Expert 19 |     68 | CPU
DEBUG 01-15 10:09:20.066708.066708 lmp.py:1626]   Expert 50 |     70 | CPU
DEBUG 01-15 10:09:20.066020.066020 lmp.py:1626]   Expert 15 |     80 | CPU
DEBUG 01-15 10:09:20.066331.066331 lmp.py:1626]   Expert  4 |     82 | CPU
DEBUG 01-15 10:09:20.066166.066166 lmp.py:1626]   Expert  7 |     82 | CPU
DEBUG 01-15 10:09:20.066108.066108 lmp.py:1626]   Expert 28 |     82 | CPU
DEBUG 01-15 10:09:20.066181.066181 lmp.py:1626]   Expert 60 |     85 | CPU
DEBUG 01-15 10:09:20.066778.066778 lmp.py:1626]   Expert 59 |     89 | CPU
DEBUG 01-15 10:09:20.066136.066136 lmp.py:1626]   Expert 23 |     97 | CPU
DEBUG 01-15 10:09:20.066256.066256 lmp.py:1626]   Expert 49 |     98 | CPU
DEBUG 01-15 10:09:20.066119.066119 lmp.py:1626]   Expert  5 |    105 | CPU
DEBUG 01-15 10:09:20.066345.066345 lmp.py:1626]   Expert 12 |    107 | CPU
DEBUG 01-15 10:09:20.066419.066419 lmp.py:1626]   Expert 10 |    112 | CPU
DEBUG 01-15 10:09:20.066254.066254 lmp.py:1626]   Expert 27 |    114 | CPU
DEBUG 01-15 10:09:20.066851.066851 lmp.py:1626]   Expert 41 |    124 | CPU
DEBUG 01-15 10:09:20.066030.066030 lmp.py:1626]   Expert  3 |    125 | CPU
DEBUG 01-15 10:09:20.067342.067342 lmp.py:1626]   Expert 25 |    125 | CPU
DEBUG 01-15 10:09:20.067939.067939 lmp.py:1626]   Expert 20 |    129 | CPU
DEBUG 01-15 10:09:20.067012.067012 lmp.py:1626]   Expert 16 |    130 | CPU
DEBUG 01-15 10:09:20.067086.067086 lmp.py:1626]   Expert 40 |    130 | CPU
DEBUG 01-15 10:09:20.067636.067636 lmp.py:1626]   Expert 13 |    131 | CPU
DEBUG 01-15 10:09:20.067948.067948 lmp.py:1626]   Expert 17 |    144 | CPU
DEBUG 01-15 10:09:20.067830.067830 lmp.py:1626]   Expert 37 |    145 | CPU
DEBUG 01-15 10:09:20.067949.067949 lmp.py:1626]   Expert 35 |    149 | CPU
DEBUG 01-15 10:09:20.067592.067592 lmp.py:1626]   Expert 47 |    150 | CPU
DEBUG 01-15 10:09:20.067474.067474 lmp.py:1626]   Expert 22 |    159 | CPU
DEBUG 01-15 10:09:20.067594.067594 lmp.py:1626]   Expert 53 |    166 | CPU
DEBUG 01-15 10:09:20.067713.067713 lmp.py:1626]   Expert 39 |    170 | CPU
DEBUG 01-15 10:09:20.067224.067224 lmp.py:1626]   Expert 38 |    178 | GPU
DEBUG 01-15 10:09:20.067728.067728 lmp.py:1626]   Expert 36 |    180 | GPU
DEBUG 01-15 10:09:20.067108.067108 lmp.py:1626]   Expert 44 |    180 | GPU
DEBUG 01-15 10:09:20.067096.067096 lmp.py:1626]   Expert 52 |    182 | GPU
DEBUG 01-15 10:09:20.067407.067407 lmp.py:1626]   Expert 58 |    185 | GPU
DEBUG 01-15 10:09:20.067527.067527 lmp.py:1626]   Expert 18 |    187 | GPU
DEBUG 01-15 10:09:20.067647.067647 lmp.py:1626]   Expert 62 |    199 | GPU
DEBUG 01-15 10:09:20.067005.067005 lmp.py:1626]   Expert 11 |    209 | GPU
DEBUG 01-15 10:09:20.067840.067840 lmp.py:1626]   Expert 48 |    210 | GPU
DEBUG 01-15 10:09:20.067459.067459 lmp.py:1626]   Expert 14 |    217 | GPU
DEBUG 01-15 10:09:20.067969.067969 lmp.py:1626]   Expert 30 |    217 | GPU
DEBUG 01-15 10:09:20.067804.067804 lmp.py:1626]   Expert  1 |    229 | GPU
DEBUG 01-15 10:09:20.067163.067163 lmp.py:1626]   Expert 42 |    235 | GPU
DEBUG 01-15 10:09:20.067521.067521 lmp.py:1626]   Expert 45 |    236 | GPU
DEBUG 01-15 10:09:20.067641.067641 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:20.067522.067522 lmp.py:1626]   Expert 51 |    240 | GPU
DEBUG 01-15 10:09:20.067642.067642 lmp.py:1626]   Expert  6 |    241 | GPU
DEBUG 01-15 10:09:20.067000.067000 lmp.py:1626]   Expert 29 |    262 | GPU
DEBUG 01-15 10:09:20.067426.067426 lmp.py:1626]   Expert 34 |    264 | GPU
DEBUG 01-15 10:09:20.067368.067368 lmp.py:1626]   Expert 33 |    276 | GPU
DEBUG 01-15 10:09:20.067726.067726 lmp.py:1626]   Expert 57 |    297 | GPU
DEBUG 01-15 10:09:20.067846.067846 lmp.py:1626]   Expert 61 |    304 | GPU
DEBUG 01-15 10:09:20.067727.067727 lmp.py:1626]   Expert 43 |    307 | GPU
DEBUG 01-15 10:09:20.067324.067324 lmp.py:1626]   Expert  0 |    322 | GPU
DEBUG 01-15 10:09:20.067934.067934 lmp.py:1626]   Expert 46 |    350 | GPU
DEBUG 01-15 10:09:20.067484.067484 lmp.py:1626]   Expert  8 |    382 | GPU
DEBUG 01-15 10:09:20.067229.067229 lmp.py:1626]   Expert  9 |    393 | GPU
DEBUG 01-15 10:09:20.067978.067978 lmp.py:1626]   Expert 56 |    393 | GPU
DEBUG 01-15 10:09:20.068336.068336 lmp.py:1626]   Expert 54 |    395 | GPU
DEBUG 01-15 10:09:20.068218.068218 lmp.py:1626]   Expert 63 |    407 | GPU
DEBUG 01-15 10:09:20.068099.068099 lmp.py:1626]   Expert 55 |    424 | GPU
DEBUG 01-15 10:09:20.068173.068173 lmp.py:1626]   Expert 21 |    488 | GPU
DEBUG 01-15 10:09:20.068154.068154 lmp.py:1627] 
DEBUG 01-15 10:09:20.068154.068154 lmp.py:1627]   CPU total tokens: 3462 (28.2%)
DEBUG 01-15 10:09:20.068896.068896 lmp.py:1628]   GPU total tokens: 8826 (71.8%)
DEBUG 01-15 10:09:20.068314.068314 cuda_h.py:19] end experts_map_get cost 0.002635478973388672 seconds
DEBUG 01-15 10:09:20.068391.068391 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.068168.068168 lmp.py:1636] 
DEBUG 01-15 10:09:20.068168.068168 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.068971.068971 cuda_h.py:19] end cpu_experts_submit cost 6.580352783203125e-05 seconds
DEBUG 01-15 10:09:20.068211.068211 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.068657.068657 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.068598.068598 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.068422.068422 cuda_h.py:19] end allocate_cuda_memory cost 0.0002465248107910156 seconds
DEBUG 01-15 10:09:20.069392.069392 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.069108.069108 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.069507.069507 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.069641.069641 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d547e04-4892-48f7-a598-5c5fffda926e
DEBUG 01-15 10:09:20.069913.069913 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.069642.069642 cuda_h.py:19] end restore2model cost 0.0033948421478271484 seconds
DEBUG 01-15 10:09:20.070236.070236 cuda_h.py:19] end sllm_worker_task cost 0.012756109237670898 seconds
DEBUG 01-15 10:09:20.070548.070548 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:20.070619.070619 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d547e04-4892-48f7-a598-5c5fffda926e
DEBUG 01-15 10:09:20.070442.070442 cuda_h.py:19] end load_into_gpu_async cost 0.0014736652374267578 seconds
DEBUG 01-15 10:09:20.070722.070722 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.070035.070035 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.071767.071767 cuda_h.py:19] end restore_tensors2 cost 0.0005314350128173828 seconds
DEBUG 01-15 10:09:20.071001.071001 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002719402313232422 seconds
DEBUG 01-15 10:09:20.071129.071129 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.071019.071019 cuda_h.py:19] end move_flatidxs cost 0.0010442733764648438 seconds
DEBUG 01-15 10:09:20.071100.071100 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.074711.074711 cuda_h.py:19] end restore2model cost 0.002713918685913086 seconds
DEBUG 01-15 10:09:20.074541.074541 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00568699836730957 seconds
DEBUG 01-15 10:09:20.074575.074575 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.074394.074394 cuda_h.py:19] end gpu_sexperts cost 0.00029277801513671875 seconds
DEBUG 01-15 10:09:20.074800.074800 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.076940.076940 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015790462493896484 seconds
DEBUG 01-15 10:09:20.076113.076113 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.077988.077988 cuda_h.py:19] end gpu_group_list cost 0.00033664703369140625 seconds
DEBUG 01-15 10:09:20.077574.077574 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.078615.078615 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007543563842773438 seconds
DEBUG 01-15 10:09:20.078398.078398 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.078274.078274 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-15 10:09:20.078493.078493 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.080978.080978 cuda_h.py:19] end group_tensors cost 0.008336067199707031 seconds
DEBUG 01-15 10:09:20.081526.081526 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.085106.085106 cuda_h.py:19] end group pad cost 0.0035703182220458984 seconds
DEBUG 01-15 10:09:20.085094.085094 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.102984.102984 cuda_h.py:19] end group_einsum cost 0.017765045166015625 seconds
DEBUG 01-15 10:09:20.103923.103923 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.108647.108647 cuda_h.py:19] end get_outputs_cpu1 cost 0.005366802215576172 seconds
DEBUG 01-15 10:09:20.109063.109063 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03899264335632324 seconds
DEBUG 01-15 10:09:20.110782.110782 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03229165077209473 seconds
DEBUG 01-15 10:09:20.111590.111590 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.111753.111753 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.111041.111041 cuda_h.py:19] end index_scatter cost 0.00016188621520996094 seconds
DEBUG 01-15 10:09:20.112118.112118 cuda_h.py:19] end cpuoutputsdeal cost 0.0015883445739746094 seconds
DEBUG 01-15 10:09:20.112751.112751 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.112523.112523 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d547e04-4892-48f7-a598-5c5fffda926e
INFO 01-15 10:09:20.119190.119190 client.py:127] Model loaded
DEBUG 01-15 10:09:20.119704.119704 cuda_h.py:19] end wait_experts cost 0.006623506546020508 seconds
DEBUG 01-15 10:09:20.119945.119945 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.119837.119837 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.119131.119131 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.120730.120730 cuda_h.py:19] end gpu_group_tensor cost 0.0003979206085205078 seconds
DEBUG 01-15 10:09:20.120500.120500 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.121803.121803 cuda_h.py:19] end gpu_group_einsum cost 0.001232147216796875 seconds
DEBUG 01-15 10:09:20.122719.122719 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.122458.122458 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.122991.122991 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005948543548583984 seconds
DEBUG 01-15 10:09:20.123795.123795 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.123750.123750 cuda_h.py:19] end concat_expert_out cost 0.00013375282287597656 seconds
DEBUG 01-15 10:09:20.123278.123278 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.123318.123318 cuda_h.py:19] end index_scatter cost 0.0001201629638671875 seconds
DEBUG 01-15 10:09:20.123440.123440 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001451730728149414 seconds
DEBUG 01-15 10:09:20.123816.123816 cuda_h.py:19] end gpu_experts cost 0.0041887760162353516 seconds
DEBUG 01-15 10:09:20.124532.124532 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.05938863754272461 seconds
DEBUG 01-15 10:09:20.124342.124342 cuda_h.py:19] end prefill_layer cost 0.0683753490447998 seconds
DEBUG 01-15 10:09:20.125618.125618 lmp.py:1552] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-15 10:09:20.125613.125613 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.125185.125185 lmp.py:1495] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-15 10:09:20.125188.125188 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:20.125958.125958 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:20.125778.125778 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.794929504394531e-05 seconds
DEBUG 01-15 10:09:20.125828.125828 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 0.0001857280731201172 seconds
DEBUG 01-15 10:09:20.125678.125678 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.125969.125969 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.125020.125020 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.126378.126378 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.126096.126096 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.126962.126962 cuda_h.py:19] end allocate_cuda_memory cost 0.00030493736267089844 seconds
DEBUG 01-15 10:09:20.126879.126879 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.126165.126165 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.126041.126041 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.126843.126843 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19603ce4-4ce4-48f3-b02d-a62cb9cbaaf3
DEBUG 01-15 10:09:20.126217.126217 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.127114.127114 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.127845.127845 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19603ce4-4ce4-48f3-b02d-a62cb9cbaaf3
DEBUG 01-15 10:09:20.127914.127914 cuda_h.py:19] end load_into_gpu_async cost 0.0012166500091552734 seconds
DEBUG 01-15 10:09:20.128386.128386 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.128032.128032 cuda_h.py:19] end restore_tensors2 cost 9.751319885253906e-05 seconds
DEBUG 01-15 10:09:20.128219.128219 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00191497802734375 seconds
INFO 01-15 10:09:20.128937.128937 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19603ce4-4ce4-48f3-b02d-a62cb9cbaaf3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.133018.133018 cuda_h.py:19] end self_attn cost 0.005489349365234375 seconds
DEBUG 01-15 10:09:20.133202.133202 cuda_h.py:19] end iln_self_attn_paln cost 0.00785970687866211 seconds
DEBUG 01-15 10:09:20.133735.133735 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-15 10:09:20.133189.133189 cuda_h.py:10] start gate
INFO 01-15 10:09:20.134443.134443 client.py:127] Model loaded
DEBUG 01-15 10:09:20.134545.134545 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.135073.135073 cuda_h.py:19] end gate cost 0.0014109611511230469 seconds
DEBUG 01-15 10:09:20.135452.135452 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.136052.136052 lmp.py:1616] 
DEBUG 01-15 10:09:20.136052.136052 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.136482.136482 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.136106.136106 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.136755.136755 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.136021.136021 lmp.py:1620] 
DEBUG 01-15 10:09:20.136021.136021 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.136539.136539 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.136711.136711 lmp.py:1626]   Expert 43 |     16 | CPU
DEBUG 01-15 10:09:20.136845.136845 lmp.py:1626]   Expert 27 |     31 | CPU
DEBUG 01-15 10:09:20.136634.136634 lmp.py:1626]   Expert 26 |     50 | CPU
DEBUG 01-15 10:09:20.136707.136707 lmp.py:1626]   Expert 56 |     53 | CPU
DEBUG 01-15 10:09:20.136019.136019 lmp.py:1626]   Expert 34 |     54 | CPU
DEBUG 01-15 10:09:20.136523.136523 lmp.py:1626]   Expert  3 |     57 | CPU
DEBUG 01-15 10:09:20.136789.136789 lmp.py:1626]   Expert  4 |     66 | CPU
DEBUG 01-15 10:09:20.136054.136054 lmp.py:1626]   Expert 61 |     81 | CPU
DEBUG 01-15 10:09:20.136604.136604 lmp.py:1626]   Expert 14 |     93 | CPU
DEBUG 01-15 10:09:20.136678.136678 lmp.py:1626]   Expert 38 |     99 | CPU
DEBUG 01-15 10:09:20.136467.136467 lmp.py:1626]   Expert  2 |    112 | CPU
DEBUG 01-15 10:09:20.136885.136885 lmp.py:1626]   Expert 17 |    120 | CPU
DEBUG 01-15 10:09:20.136912.136912 lmp.py:1626]   Expert 22 |    124 | CPU
DEBUG 01-15 10:09:20.136986.136986 lmp.py:1626]   Expert 47 |    128 | CPU
DEBUG 01-15 10:09:20.136582.136582 lmp.py:1626]   Expert 37 |    131 | CPU
DEBUG 01-15 10:09:20.136656.136656 lmp.py:1626]   Expert 55 |    132 | CPU
DEBUG 01-15 10:09:20.136491.136491 lmp.py:1626]   Expert 28 |    135 | CPU
DEBUG 01-15 10:09:20.136087.136087 lmp.py:1626]   Expert 54 |    135 | CPU
DEBUG 01-15 10:09:20.136399.136399 lmp.py:1626]   Expert 48 |    145 | CPU
DEBUG 01-15 10:09:20.136188.136188 lmp.py:1626]   Expert  7 |    146 | CPU
DEBUG 01-15 10:09:20.136977.136977 lmp.py:1626]   Expert 15 |    146 | CPU
DEBUG 01-15 10:09:20.136242.136242 lmp.py:1626]   Expert  5 |    147 | CPU
DEBUG 01-15 10:09:20.136985.136985 lmp.py:1626]   Expert 45 |    147 | CPU
DEBUG 01-15 10:09:20.136058.136058 lmp.py:1626]   Expert 51 |    147 | CPU
DEBUG 01-15 10:09:20.136715.136715 lmp.py:1626]   Expert 60 |    148 | CPU
DEBUG 01-15 10:09:20.136742.136742 lmp.py:1626]   Expert 63 |    153 | CPU
DEBUG 01-15 10:09:20.136577.136577 lmp.py:1626]   Expert 12 |    156 | CPU
DEBUG 01-15 10:09:20.136412.136412 lmp.py:1626]   Expert 19 |    161 | CPU
DEBUG 01-15 10:09:20.136486.136486 lmp.py:1626]   Expert  6 |    166 | CPU
DEBUG 01-15 10:09:20.136082.136082 lmp.py:1626]   Expert 57 |    166 | CPU
DEBUG 01-15 10:09:20.136109.136109 lmp.py:1626]   Expert 52 |    177 | CPU
DEBUG 01-15 10:09:20.137421.137421 lmp.py:1626]   Expert 18 |    179 | CPU
DEBUG 01-15 10:09:20.137687.137687 lmp.py:1626]   Expert 50 |    180 | GPU
DEBUG 01-15 10:09:20.137237.137237 lmp.py:1626]   Expert 44 |    185 | GPU
DEBUG 01-15 10:09:20.137072.137072 lmp.py:1626]   Expert 31 |    186 | GPU
DEBUG 01-15 10:09:20.137384.137384 lmp.py:1626]   Expert 13 |    189 | GPU
DEBUG 01-15 10:09:20.137219.137219 lmp.py:1626]   Expert 30 |    189 | GPU
DEBUG 01-15 10:09:20.137876.137876 lmp.py:1626]   Expert 23 |    192 | GPU
DEBUG 01-15 10:09:20.137426.137426 lmp.py:1626]   Expert 39 |    197 | GPU
DEBUG 01-15 10:09:20.137738.137738 lmp.py:1626]   Expert 53 |    197 | GPU
DEBUG 01-15 10:09:20.137573.137573 lmp.py:1626]   Expert 59 |    198 | GPU
DEBUG 01-15 10:09:20.137600.137600 lmp.py:1626]   Expert 21 |    200 | GPU
DEBUG 01-15 10:09:20.137912.137912 lmp.py:1626]   Expert 20 |    201 | GPU
DEBUG 01-15 10:09:20.137939.137939 lmp.py:1626]   Expert 29 |    202 | GPU
DEBUG 01-15 10:09:20.137774.137774 lmp.py:1626]   Expert 36 |    211 | GPU
DEBUG 01-15 10:09:20.137848.137848 lmp.py:1626]   Expert 16 |    213 | GPU
DEBUG 01-15 10:09:20.137445.137445 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:20.137280.137280 lmp.py:1626]   Expert 25 |    220 | GPU
DEBUG 01-15 10:09:20.137353.137353 lmp.py:1626]   Expert 32 |    222 | GPU
DEBUG 01-15 10:09:20.137427.137427 lmp.py:1626]   Expert 49 |    225 | GPU
DEBUG 01-15 10:09:20.137262.137262 lmp.py:1626]   Expert 46 |    237 | GPU
DEBUG 01-15 10:09:20.137680.137680 lmp.py:1626]   Expert  8 |    247 | GPU
DEBUG 01-15 10:09:20.137468.137468 lmp.py:1626]   Expert 42 |    248 | GPU
DEBUG 01-15 10:09:20.137496.137496 lmp.py:1626]   Expert 10 |    250 | GPU
DEBUG 01-15 10:09:20.137331.137331 lmp.py:1626]   Expert 62 |    265 | GPU
DEBUG 01-15 10:09:20.137166.137166 lmp.py:1626]   Expert 35 |    278 | GPU
DEBUG 01-15 10:09:20.137762.137762 lmp.py:1626]   Expert 33 |    289 | GPU
DEBUG 01-15 10:09:20.137359.137359 lmp.py:1626]   Expert  9 |    292 | GPU
DEBUG 01-15 10:09:20.137678.137678 lmp.py:1626]   Expert 58 |    298 | GPU
DEBUG 01-15 10:09:20.137228.137228 lmp.py:1626]   Expert 40 |    387 | GPU
DEBUG 01-15 10:09:20.137825.137825 lmp.py:1626]   Expert 11 |    425 | GPU
DEBUG 01-15 10:09:20.137660.137660 lmp.py:1626]   Expert  0 |    431 | GPU
DEBUG 01-15 10:09:20.137733.137733 lmp.py:1626]   Expert 24 |    566 | GPU
DEBUG 01-15 10:09:20.137330.137330 lmp.py:1626]   Expert  1 |    648 | GPU
DEBUG 01-15 10:09:20.137119.137119 lmp.py:1627] 
DEBUG 01-15 10:09:20.137119.137119 lmp.py:1627]   CPU total tokens: 3801 (30.9%)
DEBUG 01-15 10:09:20.137398.137398 lmp.py:1628]   GPU total tokens: 8487 (69.1%)
DEBUG 01-15 10:09:20.137293.137293 cuda_h.py:19] end experts_map_get cost 0.002098560333251953 seconds
DEBUG 01-15 10:09:20.137211.137211 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.137510.137510 lmp.py:1636] 
DEBUG 01-15 10:09:20.137510.137510 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.137758.137758 cuda_h.py:19] end cpu_experts_submit cost 6.794929504394531e-05 seconds
DEBUG 01-15 10:09:20.137507.137507 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.138926.138926 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.138807.138807 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.138592.138592 cuda_h.py:19] end allocate_cuda_memory cost 0.00025725364685058594 seconds
DEBUG 01-15 10:09:20.138839.138839 cuda_h.py:19] end restore2model cost 0.003607034683227539 seconds
DEBUG 01-15 10:09:20.139768.139768 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.139151.139151 cuda_h.py:19] end sllm_worker_task cost 0.01318812370300293 seconds
DEBUG 01-15 10:09:20.139703.139703 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.139384.139384 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.139948.139948 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 250c6d6e-e790-4a42-9d98-ab1894193d58
DEBUG 01-15 10:09:20.139502.139502 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.139583.139583 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.139896.139896 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.140033.140033 cuda_h.py:19] end move_flatidxs cost 0.0009038448333740234 seconds
DEBUG 01-15 10:09:20.140631.140631 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:20.141643.141643 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 250c6d6e-e790-4a42-9d98-ab1894193d58
DEBUG 01-15 10:09:20.141208.141208 cuda_h.py:19] end load_into_gpu_async cost 0.0016427040100097656 seconds
DEBUG 01-15 10:09:20.141103.141103 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.141803.141803 cuda_h.py:19] end restore_tensors2 cost 0.0004863739013671875 seconds
DEBUG 01-15 10:09:20.141507.141507 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003667593002319336 seconds
DEBUG 01-15 10:09:20.141283.141283 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.144146.144146 cuda_h.py:19] end restore2model cost 0.0027778148651123047 seconds
DEBUG 01-15 10:09:20.144858.144858 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006693363189697266 seconds
DEBUG 01-15 10:09:20.144753.144753 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.145446.145446 cuda_h.py:19] end gpu_sexperts cost 0.0003027915954589844 seconds
DEBUG 01-15 10:09:20.145282.145282 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.146080.146080 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016393661499023438 seconds
DEBUG 01-15 10:09:20.147988.147988 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.148360.148360 cuda_h.py:19] end gpu_group_list cost 0.0003571510314941406 seconds
DEBUG 01-15 10:09:20.148483.148483 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.148828.148828 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007753372192382812 seconds
DEBUG 01-15 10:09:20.149280.149280 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.149540.149540 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-15 10:09:20.149952.149952 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.150700.150700 cuda_h.py:19] end group_tensors cost 0.009137630462646484 seconds
DEBUG 01-15 10:09:20.150211.150211 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.155224.155224 cuda_h.py:19] end group pad cost 0.004097700119018555 seconds
DEBUG 01-15 10:09:20.155736.155736 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.175739.175739 cuda_h.py:19] end group_einsum cost 0.020762920379638672 seconds
DEBUG 01-15 10:09:20.176334.176334 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.182927.182927 cuda_h.py:19] end get_outputs_cpu1 cost 0.0067098140716552734 seconds
DEBUG 01-15 10:09:20.184925.184925 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04453301429748535 seconds
DEBUG 01-15 10:09:20.185115.185115 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03586268424987793 seconds
DEBUG 01-15 10:09:20.185948.185948 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.185357.185357 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.185191.185191 cuda_h.py:19] end index_scatter cost 0.0001163482666015625 seconds
DEBUG 01-15 10:09:20.186377.186377 cuda_h.py:19] end cpuoutputsdeal cost 0.0012664794921875 seconds
DEBUG 01-15 10:09:20.186082.186082 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.186615.186615 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 250c6d6e-e790-4a42-9d98-ab1894193d58
INFO 01-15 10:09:20.190678.190678 client.py:127] Model loaded
DEBUG 01-15 10:09:20.190457.190457 cuda_h.py:19] end wait_experts cost 0.0037870407104492188 seconds
DEBUG 01-15 10:09:20.190823.190823 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.190880.190880 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.190060.190060 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.191497.191497 cuda_h.py:19] end gpu_group_tensor cost 0.00032782554626464844 seconds
DEBUG 01-15 10:09:20.191001.191001 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.192908.192908 cuda_h.py:19] end gpu_group_einsum cost 0.0008904933929443359 seconds
DEBUG 01-15 10:09:20.192016.192016 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.192542.192542 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.193792.193792 cuda_h.py:19] end all_expert_outputs_slices cost 0.000469207763671875 seconds
DEBUG 01-15 10:09:20.193781.193781 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.193244.193244 cuda_h.py:19] end concat_expert_out cost 0.00010609626770019531 seconds
DEBUG 01-15 10:09:20.193877.193877 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.193161.193161 cuda_h.py:19] end index_scatter cost 9.703636169433594e-05 seconds
DEBUG 01-15 10:09:20.193786.193786 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011494159698486328 seconds
DEBUG 01-15 10:09:20.193029.193029 cuda_h.py:19] end gpu_experts cost 0.003324747085571289 seconds
DEBUG 01-15 10:09:20.194716.194716 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.060277700424194336 seconds
DEBUG 01-15 10:09:20.194178.194178 cuda_h.py:19] end prefill_layer cost 0.06958222389221191 seconds
DEBUG 01-15 10:09:20.194135.194135 lmp.py:1552] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-15 10:09:20.194686.194686 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.195907.195907 lmp.py:1495] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-15 10:09:20.195412.195412 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:20.195162.195162 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:20.195716.195716 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:20.195706.195706 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.195748.195748 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 0.0002334117889404297 seconds
DEBUG 01-15 10:09:20.195454.195454 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.195310.195310 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.195187.195187 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.196073.196073 cuda_h.py:19] end allocate_cuda_memory cost 0.00022673606872558594 seconds
DEBUG 01-15 10:09:20.196453.196453 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.196738.196738 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.196522.196522 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.196748.196748 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cbff99bd-1b55-4f73-aae5-73cc01eebdb7
DEBUG 01-15 10:09:20.196916.196916 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.196458.196458 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.196347.196347 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.197823.197823 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cbff99bd-1b55-4f73-aae5-73cc01eebdb7
DEBUG 01-15 10:09:20.197805.197805 cuda_h.py:19] end load_into_gpu_async cost 0.000997781753540039 seconds
DEBUG 01-15 10:09:20.197554.197554 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.197121.197121 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-15 10:09:20.197784.197784 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016286373138427734 seconds
INFO 01-15 10:09:20.197316.197316 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cbff99bd-1b55-4f73-aae5-73cc01eebdb7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.201186.201186 cuda_h.py:19] end self_attn cost 0.004400014877319336 seconds
DEBUG 01-15 10:09:20.201862.201862 cuda_h.py:19] end iln_self_attn_paln cost 0.006040096282958984 seconds
DEBUG 01-15 10:09:20.201070.201070 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-15 10:09:20.201569.201569 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.202976.202976 cuda_h.py:19] end gate cost 0.0008454322814941406 seconds
DEBUG 01-15 10:09:20.202879.202879 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.203041.203041 lmp.py:1616] 
DEBUG 01-15 10:09:20.203041.203041 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.203248.203248 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.203534.203534 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.203005.203005 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.203092.203092 lmp.py:1620] 
DEBUG 01-15 10:09:20.203092.203092 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.203464.203464 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.203551.203551 lmp.py:1626]   Expert 39 |     15 | CPU
DEBUG 01-15 10:09:20.203492.203492 lmp.py:1626]   Expert 13 |     16 | CPU
DEBUG 01-15 10:09:20.203433.203433 lmp.py:1626]   Expert 49 |     38 | CPU
DEBUG 01-15 10:09:20.203659.203659 lmp.py:1626]   Expert 35 |     54 | CPU
DEBUG 01-15 10:09:20.203362.203362 lmp.py:1626]   Expert 19 |     64 | CPU
DEBUG 01-15 10:09:20.203257.203257 lmp.py:1626]   Expert  9 |     72 | CPU
DEBUG 01-15 10:09:20.203391.203391 lmp.py:1626]   Expert 26 |     74 | CPU
DEBUG 01-15 10:09:20.203332.203332 lmp.py:1626]   Expert 32 |     75 | CPU
DEBUG 01-15 10:09:20.203273.203273 lmp.py:1626]   Expert 41 |     78 | CPU
DEBUG 01-15 10:09:20.203499.203499 lmp.py:1626]   Expert 33 |     80 | CPU
DEBUG 01-15 10:09:20.203202.203202 lmp.py:1626]   Expert 23 |     88 | CPU
DEBUG 01-15 10:09:20.203051.203051 lmp.py:1626]   Expert 46 |     88 | CPU
DEBUG 01-15 10:09:20.203376.203376 lmp.py:1626]   Expert 18 |     90 | CPU
DEBUG 01-15 10:09:20.203463.203463 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:20.203358.203358 lmp.py:1626]   Expert 38 |     99 | CPU
DEBUG 01-15 10:09:20.203253.203253 lmp.py:1626]   Expert  3 |    104 | CPU
DEBUG 01-15 10:09:20.204910.204910 lmp.py:1626]   Expert 17 |    104 | CPU
DEBUG 01-15 10:09:20.204043.204043 lmp.py:1626]   Expert  6 |    107 | CPU
DEBUG 01-15 10:09:20.204846.204846 lmp.py:1626]   Expert 20 |    117 | CPU
DEBUG 01-15 10:09:20.204409.204409 lmp.py:1626]   Expert 40 |    128 | CPU
DEBUG 01-15 10:09:20.204550.204550 lmp.py:1626]   Expert 61 |    131 | CPU
DEBUG 01-15 10:09:20.204445.204445 lmp.py:1626]   Expert 62 |    133 | CPU
DEBUG 01-15 10:09:20.204624.204624 lmp.py:1626]   Expert 15 |    134 | CPU
DEBUG 01-15 10:09:20.204281.204281 lmp.py:1626]   Expert 44 |    134 | CPU
DEBUG 01-15 10:09:20.204222.204222 lmp.py:1626]   Expert 50 |    135 | CPU
DEBUG 01-15 10:09:20.204402.204402 lmp.py:1626]   Expert 43 |    136 | CPU
DEBUG 01-15 10:09:20.204343.204343 lmp.py:1626]   Expert 59 |    137 | CPU
DEBUG 01-15 10:09:20.204761.204761 lmp.py:1626]   Expert 16 |    138 | CPU
INFO 01-15 10:09:20.204294.204294 client.py:127] Model loaded
DEBUG 01-15 10:09:20.204521.204521 lmp.py:1626]   Expert 63 |    139 | CPU
DEBUG 01-15 10:09:20.204973.204973 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.204967.204967 lmp.py:1626]   Expert 42 |    143 | CPU
DEBUG 01-15 10:09:20.204313.204313 lmp.py:1626]   Expert  2 |    147 | CPU
DEBUG 01-15 10:09:20.204592.204592 lmp.py:1626]   Expert 36 |    151 | CPU
DEBUG 01-15 10:09:20.204821.204821 lmp.py:1626]   Expert 10 |    159 | GPU
DEBUG 01-15 10:09:20.204346.204346 lmp.py:1626]   Expert  5 |    183 | GPU
DEBUG 01-15 10:09:20.204479.204479 lmp.py:1626]   Expert 34 |    187 | GPU
DEBUG 01-15 10:09:20.205136.205136 lmp.py:1626]   Expert 27 |    189 | GPU
DEBUG 01-15 10:09:20.205330.205330 lmp.py:1626]   Expert 52 |    190 | GPU
DEBUG 01-15 10:09:20.205379.205379 lmp.py:1626]   Expert 45 |    192 | GPU
DEBUG 01-15 10:09:20.205565.205565 lmp.py:1626]   Expert 60 |    198 | GPU
DEBUG 01-15 10:09:20.205507.205507 lmp.py:1626]   Expert 48 |    207 | GPU
DEBUG 01-15 10:09:20.205787.205787 lmp.py:1626]   Expert 51 |    211 | GPU
DEBUG 01-15 10:09:20.205359.205359 lmp.py:1626]   Expert 56 |    214 | GPU
DEBUG 01-15 10:09:20.205307.205307 lmp.py:1626]   Expert 24 |    229 | GPU
DEBUG 01-15 10:09:20.205202.205202 lmp.py:1626]   Expert  7 |    233 | GPU
DEBUG 01-15 10:09:20.205382.205382 lmp.py:1626]   Expert 53 |    233 | GPU
DEBUG 01-15 10:09:20.205800.205800 lmp.py:1626]   Expert  8 |    243 | GPU
DEBUG 01-15 10:09:20.205233.205233 cuda_h.py:19] end restore2model cost 0.0009503364562988281 seconds
DEBUG 01-15 10:09:20.205419.205419 lmp.py:1626]   Expert 57 |    252 | GPU
DEBUG 01-15 10:09:20.205448.205448 cuda_h.py:19] end sllm_worker_task cost 0.01012110710144043 seconds
DEBUG 01-15 10:09:20.205324.205324 lmp.py:1626]   Expert 47 |    253 | GPU
DEBUG 01-15 10:09:20.205631.205631 lmp.py:1626]   Expert 29 |    261 | GPU
DEBUG 01-15 10:09:20.205003.205003 lmp.py:1626]   Expert 21 |    263 | GPU
DEBUG 01-15 10:09:20.205944.205944 lmp.py:1626]   Expert  0 |    287 | GPU
DEBUG 01-15 10:09:20.205647.205647 lmp.py:1626]   Expert  4 |    287 | GPU
DEBUG 01-15 10:09:20.205635.205635 lmp.py:1626]   Expert 14 |    291 | GPU
DEBUG 01-15 10:09:20.205338.205338 lmp.py:1626]   Expert 22 |    314 | GPU
DEBUG 01-15 10:09:20.205378.205378 lmp.py:1626]   Expert  1 |    317 | GPU
DEBUG 01-15 10:09:20.205035.205035 lmp.py:1626]   Expert 55 |    317 | GPU
DEBUG 01-15 10:09:20.205499.205499 lmp.py:1626]   Expert 37 |    318 | GPU
DEBUG 01-15 10:09:20.206964.206964 lmp.py:1626]   Expert 58 |    318 | GPU
DEBUG 01-15 10:09:20.206713.206713 lmp.py:1626]   Expert 54 |    331 | GPU
DEBUG 01-15 10:09:20.206462.206462 lmp.py:1626]   Expert 28 |    360 | GPU
DEBUG 01-15 10:09:20.206211.206211 lmp.py:1626]   Expert 12 |    378 | GPU
DEBUG 01-15 10:09:20.206437.206437 lmp.py:1626]   Expert 25 |    398 | GPU
DEBUG 01-15 10:09:20.206948.206948 lmp.py:1626]   Expert 11 |    400 | GPU
DEBUG 01-15 10:09:20.206128.206128 lmp.py:1626]   Expert 30 |    835 | GPU
DEBUG 01-15 10:09:20.206606.206606 lmp.py:1627] 
DEBUG 01-15 10:09:20.206606.206606 lmp.py:1627]   CPU total tokens: 3240 (26.4%)
DEBUG 01-15 10:09:20.206249.206249 lmp.py:1628]   GPU total tokens: 9048 (73.6%)
DEBUG 01-15 10:09:20.206614.206614 cuda_h.py:19] end experts_map_get cost 0.0033097267150878906 seconds
DEBUG 01-15 10:09:20.206325.206325 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.206935.206935 lmp.py:1636] 
DEBUG 01-15 10:09:20.206935.206935 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.206348.206348 cuda_h.py:19] end cpu_experts_submit cost 5.793571472167969e-05 seconds
DEBUG 01-15 10:09:20.206296.206296 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.206132.206132 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.206821.206821 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.206948.206948 cuda_h.py:19] end allocate_cuda_memory cost 0.00019741058349609375 seconds
DEBUG 01-15 10:09:20.207082.207082 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.207573.207573 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.207058.207058 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.207761.207761 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 77d4d6f0-fcbe-4b43-87b4-a68997cc595f
DEBUG 01-15 10:09:20.207742.207742 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.207022.207022 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.207718.207718 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:20.208511.208511 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 77d4d6f0-fcbe-4b43-87b4-a68997cc595f
DEBUG 01-15 10:09:20.208592.208592 cuda_h.py:19] end load_into_gpu_async cost 0.0013463497161865234 seconds
DEBUG 01-15 10:09:20.208057.208057 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.208651.208651 cuda_h.py:19] end move_flatidxs cost 0.0009055137634277344 seconds
DEBUG 01-15 10:09:20.208964.208964 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.209543.209543 cuda_h.py:19] end restore_tensors2 cost 0.0004699230194091797 seconds
DEBUG 01-15 10:09:20.209248.209248 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028345584869384766 seconds
DEBUG 01-15 10:09:20.209348.209348 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.211401.211401 cuda_h.py:19] end restore2model cost 0.002538442611694336 seconds
DEBUG 01-15 10:09:20.212688.212688 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005570411682128906 seconds
DEBUG 01-15 10:09:20.212358.212358 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.215783.215783 cuda_h.py:19] end gpu_sexperts cost 0.00029158592224121094 seconds
DEBUG 01-15 10:09:20.215137.215137 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.217460.217460 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016973018646240234 seconds
DEBUG 01-15 10:09:20.217468.217468 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.218820.218820 cuda_h.py:19] end gpu_group_list cost 0.00036716461181640625 seconds
DEBUG 01-15 10:09:20.218036.218036 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.219168.219168 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007219314575195312 seconds
DEBUG 01-15 10:09:20.219229.219229 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.219005.219005 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-15 10:09:20.219178.219178 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.219825.219825 cuda_h.py:19] end group_tensors cost 0.010246992111206055 seconds
DEBUG 01-15 10:09:20.220484.220484 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.224875.224875 cuda_h.py:19] end group pad cost 0.004685878753662109 seconds
DEBUG 01-15 10:09:20.224718.224718 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.244490.244490 cuda_h.py:19] end group_einsum cost 0.019020795822143555 seconds
DEBUG 01-15 10:09:20.244999.244999 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.248653.248653 cuda_h.py:19] end get_outputs_cpu1 cost 0.004233121871948242 seconds
DEBUG 01-15 10:09:20.249594.249594 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04150223731994629 seconds
DEBUG 01-15 10:09:20.250690.250690 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03085494041442871 seconds
DEBUG 01-15 10:09:20.250915.250915 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.250867.250867 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.251167.251167 cuda_h.py:19] end index_scatter cost 0.00017595291137695312 seconds
DEBUG 01-15 10:09:20.251062.251062 cuda_h.py:19] end cpuoutputsdeal cost 0.0011708736419677734 seconds
DEBUG 01-15 10:09:20.251833.251833 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.251291.251291 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 77d4d6f0-fcbe-4b43-87b4-a68997cc595f
INFO 01-15 10:09:20.258673.258673 client.py:127] Model loaded
DEBUG 01-15 10:09:20.258783.258783 cuda_h.py:19] end wait_experts cost 0.007176637649536133 seconds
DEBUG 01-15 10:09:20.259481.259481 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.259829.259829 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.259202.259202 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.259725.259725 cuda_h.py:19] end gpu_group_tensor cost 0.00032210350036621094 seconds
DEBUG 01-15 10:09:20.259036.259036 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.260850.260850 cuda_h.py:19] end gpu_group_einsum cost 0.0008955001831054688 seconds
DEBUG 01-15 10:09:20.260930.260930 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.261827.261827 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.261461.261461 cuda_h.py:19] end all_expert_outputs_slices cost 0.00047326087951660156 seconds
DEBUG 01-15 10:09:20.261165.261165 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.261681.261681 cuda_h.py:19] end concat_expert_out cost 0.00010776519775390625 seconds
DEBUG 01-15 10:09:20.261029.261029 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.262267.262267 cuda_h.py:19] end index_scatter cost 9.870529174804688e-05 seconds
DEBUG 01-15 10:09:20.262938.262938 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011563301086425781 seconds
DEBUG 01-15 10:09:20.262758.262758 cuda_h.py:19] end gpu_experts cost 0.00327301025390625 seconds
DEBUG 01-15 10:09:20.262875.262875 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.060582876205444336 seconds
DEBUG 01-15 10:09:20.263574.263574 cuda_h.py:19] end prefill_layer cost 0.06818151473999023 seconds
DEBUG 01-15 10:09:20.263684.263684 lmp.py:1552] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-15 10:09:20.263567.263567 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.263641.263641 lmp.py:1495] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-15 10:09:20.263431.263431 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:20.263466.263466 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:20.263676.263676 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.91278076171875e-05 seconds
DEBUG 01-15 10:09:20.263764.263764 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00013065338134765625 seconds
DEBUG 01-15 10:09:20.263878.263878 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.263890.263890 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.264292.264292 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.264722.264722 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.264833.264833 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.264069.264069 cuda_h.py:19] end allocate_cuda_memory cost 0.0004031658172607422 seconds
DEBUG 01-15 10:09:20.265207.265207 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.265368.265368 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.265105.265105 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.265530.265530 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7d13b1e-4c73-4b3b-abee-3d7d798d065c
DEBUG 01-15 10:09:20.265063.265063 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.265202.265202 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.266093.266093 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7d13b1e-4c73-4b3b-abee-3d7d798d065c
DEBUG 01-15 10:09:20.266361.266361 cuda_h.py:19] end load_into_gpu_async cost 0.0011875629425048828 seconds
DEBUG 01-15 10:09:20.266263.266263 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.266956.266956 cuda_h.py:19] end restore_tensors2 cost 9.703636169433594e-05 seconds
DEBUG 01-15 10:09:20.266096.266096 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002198934555053711 seconds
INFO 01-15 10:09:20.266431.266431 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7d13b1e-4c73-4b3b-abee-3d7d798d065c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.270709.270709 cuda_h.py:19] end self_attn cost 0.004893302917480469 seconds
DEBUG 01-15 10:09:20.271830.271830 cuda_h.py:19] end iln_self_attn_paln cost 0.007592916488647461 seconds
DEBUG 01-15 10:09:20.271535.271535 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-15 10:09:20.271510.271510 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.272280.272280 cuda_h.py:19] end gate cost 0.0011854171752929688 seconds
DEBUG 01-15 10:09:20.272283.272283 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.273324.273324 lmp.py:1616] 
DEBUG 01-15 10:09:20.273324.273324 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.273677.273677 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.273678.273678 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.273626.273626 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.273667.273667 lmp.py:1620] 
DEBUG 01-15 10:09:20.273667.273667 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.273946.273946 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.273179.273179 lmp.py:1626]   Expert 12 |     18 | CPU
DEBUG 01-15 10:09:20.273220.273220 lmp.py:1626]   Expert 47 |     23 | CPU
DEBUG 01-15 10:09:20.273545.273545 lmp.py:1626]   Expert 38 |     32 | CPU
DEBUG 01-15 10:09:20.273917.273917 lmp.py:1626]   Expert 27 |     33 | CPU
DEBUG 01-15 10:09:20.273573.273573 lmp.py:1626]   Expert 16 |     36 | CPU
DEBUG 01-15 10:09:20.273707.273707 lmp.py:1626]   Expert 52 |     40 | CPU
DEBUG 01-15 10:09:20.273363.273363 lmp.py:1626]   Expert 63 |     49 | CPU
DEBUG 01-15 10:09:20.273927.273927 lmp.py:1626]   Expert  4 |     58 | CPU
DEBUG 01-15 10:09:20.273399.273399 lmp.py:1626]   Expert 44 |     60 | CPU
DEBUG 01-15 10:09:20.273532.273532 lmp.py:1626]   Expert 43 |     62 | CPU
DEBUG 01-15 10:09:20.273619.273619 lmp.py:1626]   Expert 61 |     64 | CPU
DEBUG 01-15 10:09:20.273706.273706 lmp.py:1626]   Expert 34 |     77 | CPU
INFO 01-15 10:09:20.273490.273490 client.py:127] Model loaded
DEBUG 01-15 10:09:20.274388.274388 lmp.py:1626]   Expert 53 |     83 | CPU
DEBUG 01-15 10:09:20.274503.274503 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.274214.274214 lmp.py:1626]   Expert  0 |     87 | CPU
DEBUG 01-15 10:09:20.274928.274928 lmp.py:1626]   Expert 32 |     90 | CPU
DEBUG 01-15 10:09:20.274499.274499 lmp.py:1626]   Expert 37 |     90 | CPU
DEBUG 01-15 10:09:20.274539.274539 lmp.py:1626]   Expert 13 |    103 | CPU
DEBUG 01-15 10:09:20.274865.274865 lmp.py:1626]   Expert 21 |    116 | CPU
DEBUG 01-15 10:09:20.274475.274475 lmp.py:1626]   Expert 39 |    116 | CPU
DEBUG 01-15 10:09:20.274370.274370 lmp.py:1626]   Expert 11 |    120 | CPU
DEBUG 01-15 10:09:20.274503.274503 lmp.py:1626]   Expert 20 |    126 | CPU
DEBUG 01-15 10:09:20.274637.274637 lmp.py:1626]   Expert  8 |    131 | CPU
DEBUG 01-15 10:09:20.274055.274055 lmp.py:1626]   Expert 60 |    131 | CPU
DEBUG 01-15 10:09:20.274904.274904 lmp.py:1626]   Expert 14 |    137 | CPU
DEBUG 01-15 10:09:20.274560.274560 lmp.py:1626]   Expert 57 |    139 | CPU
DEBUG 01-15 10:09:20.274693.274693 lmp.py:1626]   Expert 22 |    140 | CPU
DEBUG 01-15 10:09:20.274781.274781 lmp.py:1626]   Expert  2 |    156 | CPU
DEBUG 01-15 10:09:20.274676.274676 lmp.py:1626]   Expert 45 |    156 | CPU
DEBUG 01-15 10:09:20.274809.274809 lmp.py:1626]   Expert 17 |    157 | CPU
DEBUG 01-15 10:09:20.274989.274989 lmp.py:1626]   Expert 18 |    157 | CPU
DEBUG 01-15 10:09:20.275407.275407 lmp.py:1626]   Expert 23 |    158 | CPU
DEBUG 01-15 10:09:20.275825.275825 lmp.py:1626]   Expert  7 |    162 | CPU
DEBUG 01-15 10:09:20.275912.275912 lmp.py:1626]   Expert 58 |    163 | GPU
DEBUG 01-15 10:09:20.275237.275237 lmp.py:1626]   Expert 30 |    165 | GPU
DEBUG 01-15 10:09:20.275040.275040 lmp.py:1626]   Expert 42 |    171 | GPU
DEBUG 01-15 10:09:20.275412.275412 lmp.py:1626]   Expert 49 |    178 | GPU
DEBUG 01-15 10:09:20.275307.275307 lmp.py:1626]   Expert 48 |    179 | GPU
DEBUG 01-15 10:09:20.275963.275963 lmp.py:1626]   Expert 62 |    180 | GPU
DEBUG 01-15 10:09:20.275620.275620 lmp.py:1626]   Expert 55 |    181 | GPU
DEBUG 01-15 10:09:20.275230.275230 lmp.py:1626]   Expert 51 |    184 | GPU
DEBUG 01-15 10:09:20.275079.275079 lmp.py:1626]   Expert 29 |    188 | GPU
DEBUG 01-15 10:09:20.275642.275642 lmp.py:1626]   Expert 35 |    188 | GPU
DEBUG 01-15 10:09:20.275776.275776 lmp.py:1626]   Expert 25 |    193 | GPU
DEBUG 01-15 10:09:20.275432.275432 lmp.py:1626]   Expert  6 |    194 | GPU
DEBUG 01-15 10:09:20.275327.275327 lmp.py:1626]   Expert 36 |    194 | GPU
DEBUG 01-15 10:09:20.275984.275984 lmp.py:1626]   Expert  1 |    200 | GPU
DEBUG 01-15 10:09:20.275879.275879 lmp.py:1626]   Expert 31 |    207 | GPU
DEBUG 01-15 10:09:20.275489.275489 lmp.py:1626]   Expert 28 |    222 | GPU
DEBUG 01-15 10:09:20.275576.275576 lmp.py:1626]   Expert 54 |    228 | GPU
DEBUG 01-15 10:09:20.275471.275471 lmp.py:1626]   Expert  5 |    231 | GPU
DEBUG 01-15 10:09:20.275128.275128 lmp.py:1626]   Expert 41 |    232 | GPU
DEBUG 01-15 10:09:20.275023.275023 lmp.py:1626]   Expert  9 |    237 | GPU
DEBUG 01-15 10:09:20.275918.275918 lmp.py:1626]   Expert 19 |    238 | GPU
DEBUG 01-15 10:09:20.275289.275289 lmp.py:1626]   Expert 24 |    252 | GPU
DEBUG 01-15 10:09:20.275900.275900 lmp.py:1626]   Expert 50 |    289 | GPU
DEBUG 01-15 10:09:20.275225.275225 lmp.py:1626]   Expert 46 |    306 | GPU
DEBUG 01-15 10:09:20.275835.275835 lmp.py:1626]   Expert 59 |    311 | GPU
DEBUG 01-15 10:09:20.275492.275492 lmp.py:1626]   Expert 56 |    376 | GPU
DEBUG 01-15 10:09:20.275387.275387 lmp.py:1626]   Expert 26 |    406 | GPU
DEBUG 01-15 10:09:20.275520.275520 lmp.py:1626]   Expert 33 |    422 | GPU
DEBUG 01-15 10:09:20.275415.275415 lmp.py:1626]   Expert  3 |    586 | GPU
DEBUG 01-15 10:09:20.275502.275502 lmp.py:1626]   Expert 10 |    641 | GPU
DEBUG 01-15 10:09:20.276225.276225 lmp.py:1626]   Expert 15 |    648 | GPU
DEBUG 01-15 10:09:20.276564.276564 lmp.py:1626]   Expert 40 |    791 | GPU
DEBUG 01-15 10:09:20.276274.276274 lmp.py:1627] 
DEBUG 01-15 10:09:20.276274.276274 lmp.py:1627]   CPU total tokens: 3107 (25.3%)
DEBUG 01-15 10:09:20.276460.276460 lmp.py:1628]   GPU total tokens: 9181 (74.7%)
DEBUG 01-15 10:09:20.276084.276084 cuda_h.py:19] end experts_map_get cost 0.0033197402954101562 seconds
DEBUG 01-15 10:09:20.276050.276050 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.276278.276278 lmp.py:1636] 
DEBUG 01-15 10:09:20.276278.276278 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.276963.276963 cuda_h.py:19] end cpu_experts_submit cost 8.416175842285156e-05 seconds
DEBUG 01-15 10:09:20.276964.276964 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.276669.276669 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.276804.276804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.277856.277856 cuda_h.py:19] end allocate_cuda_memory cost 0.00029778480529785156 seconds
DEBUG 01-15 10:09:20.277547.277547 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.277801.277801 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.277385.277385 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.277326.277326 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 570fa03f-50f8-47d9-be82-244eddc90368
DEBUG 01-15 10:09:20.277254.277254 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.277625.277625 cuda_h.py:19] end restore2model cost 0.0036776065826416016 seconds
DEBUG 01-15 10:09:20.278336.278336 cuda_h.py:19] end sllm_worker_task cost 0.014202356338500977 seconds
INFO 01-15 10:09:20.278239.278239 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 570fa03f-50f8-47d9-be82-244eddc90368
DEBUG 01-15 10:09:20.278302.278302 cuda_h.py:19] end load_into_gpu_async cost 0.0013151168823242188 seconds
DEBUG 01-15 10:09:20.278011.278011 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.278367.278367 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.279997.279997 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.279235.279235 cuda_h.py:19] end restore_tensors2 cost 0.0005214214324951172 seconds
DEBUG 01-15 10:09:20.279496.279496 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027136802673339844 seconds
DEBUG 01-15 10:09:20.279048.279048 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.280537.280537 cuda_h.py:19] end move_flatidxs cost 0.0010294914245605469 seconds
DEBUG 01-15 10:09:20.280672.280672 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.282352.282352 cuda_h.py:19] end restore2model cost 0.002719879150390625 seconds
DEBUG 01-15 10:09:20.282183.282183 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0057103633880615234 seconds
DEBUG 01-15 10:09:20.282191.282191 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.282116.282116 cuda_h.py:19] end gpu_sexperts cost 0.0003001689910888672 seconds
DEBUG 01-15 10:09:20.282283.282283 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.284149.284149 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015180110931396484 seconds
DEBUG 01-15 10:09:20.285017.285017 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.285740.285740 cuda_h.py:19] end gpu_group_list cost 0.0003533363342285156 seconds
DEBUG 01-15 10:09:20.285472.285472 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.286710.286710 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007312297821044922 seconds
DEBUG 01-15 10:09:20.286340.286340 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.286739.286739 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-15 10:09:20.286151.286151 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.292468.292468 cuda_h.py:19] end group_tensors cost 0.01265096664428711 seconds
DEBUG 01-15 10:09:20.293620.293620 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.297813.297813 cuda_h.py:19] end group pad cost 0.003529787063598633 seconds
DEBUG 01-15 10:09:20.297616.297616 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.315186.315186 cuda_h.py:19] end group_einsum cost 0.018520116806030273 seconds
DEBUG 01-15 10:09:20.316503.316503 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.319517.319517 cuda_h.py:19] end get_outputs_cpu1 cost 0.0035130977630615234 seconds
DEBUG 01-15 10:09:20.320696.320696 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.041579246520996094 seconds
DEBUG 01-15 10:09:20.321985.321985 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03473210334777832 seconds
DEBUG 01-15 10:09:20.321595.321595 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.322684.322684 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.322508.322508 cuda_h.py:19] end index_scatter cost 0.00016546249389648438 seconds
DEBUG 01-15 10:09:20.323693.323693 cuda_h.py:19] end cpuoutputsdeal cost 0.0016491413116455078 seconds
DEBUG 01-15 10:09:20.323426.323426 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.323740.323740 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 570fa03f-50f8-47d9-be82-244eddc90368
INFO 01-15 10:09:20.329605.329605 client.py:127] Model loaded
DEBUG 01-15 10:09:20.329564.329564 cuda_h.py:19] end wait_experts cost 0.005809783935546875 seconds
DEBUG 01-15 10:09:20.329473.329473 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.329749.329749 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.329282.329282 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.330423.330423 cuda_h.py:19] end gpu_group_tensor cost 0.0003783702850341797 seconds
DEBUG 01-15 10:09:20.330543.330543 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.331094.331094 cuda_h.py:19] end gpu_group_einsum cost 0.0013115406036376953 seconds
DEBUG 01-15 10:09:20.331103.331103 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.332226.332226 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.332137.332137 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006232261657714844 seconds
DEBUG 01-15 10:09:20.332345.332345 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.333584.333584 cuda_h.py:19] end concat_expert_out cost 0.00013399124145507812 seconds
DEBUG 01-15 10:09:20.333397.333397 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.333059.333059 cuda_h.py:19] end index_scatter cost 0.00012230873107910156 seconds
DEBUG 01-15 10:09:20.333658.333658 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014679431915283203 seconds
DEBUG 01-15 10:09:20.333718.333718 cuda_h.py:19] end gpu_experts cost 0.00425267219543457 seconds
DEBUG 01-15 10:09:20.333591.333591 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06234478950500488 seconds
DEBUG 01-15 10:09:20.334599.334599 cuda_h.py:19] end prefill_layer cost 0.0713045597076416 seconds
DEBUG 01-15 10:09:20.334484.334484 lmp.py:1552] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-15 10:09:20.334241.334241 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.335972.335972 lmp.py:1495] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-15 10:09:20.335829.335829 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:20.335692.335692 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:20.335465.335465 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:20.335469.335469 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.0001888275146484375 seconds
DEBUG 01-15 10:09:20.335127.335127 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.335641.335641 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.335805.335805 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.335815.335815 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.336515.336515 cuda_h.py:19] end allocate_cuda_memory cost 0.00029659271240234375 seconds
DEBUG 01-15 10:09:20.336292.336292 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.336486.336486 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.336792.336792 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.336893.336893 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6baddd57-ebb5-40d2-9c34-3dd61628e84e
DEBUG 01-15 10:09:20.336552.336552 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.336546.336546 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:20.337235.337235 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6baddd57-ebb5-40d2-9c34-3dd61628e84e
DEBUG 01-15 10:09:20.337158.337158 cuda_h.py:19] end load_into_gpu_async cost 0.0010912418365478516 seconds
DEBUG 01-15 10:09:20.337106.337106 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.337077.337077 cuda_h.py:19] end restore_tensors2 cost 8.893013000488281e-05 seconds
DEBUG 01-15 10:09:20.337217.337217 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017704963684082031 seconds
INFO 01-15 10:09:20.337743.337743 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6baddd57-ebb5-40d2-9c34-3dd61628e84e
DEBUG 01-15 10:09:20.337435.337435 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.342826.342826 cuda_h.py:19] end self_attn cost 0.0046045780181884766 seconds
DEBUG 01-15 10:09:20.343298.343298 cuda_h.py:19] end iln_self_attn_paln cost 0.007604360580444336 seconds
DEBUG 01-15 10:09:20.343705.343705 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-15 10:09:20.343448.343448 cuda_h.py:10] start gate
INFO 01-15 10:09:20.344427.344427 client.py:127] Model loaded
DEBUG 01-15 10:09:20.344197.344197 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.344358.344358 cuda_h.py:19] end gate cost 0.0012047290802001953 seconds
DEBUG 01-15 10:09:20.344653.344653 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.345174.345174 lmp.py:1616] 
DEBUG 01-15 10:09:20.345174.345174 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.345918.345918 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.345787.345787 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.345411.345411 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.345266.345266 lmp.py:1620] 
DEBUG 01-15 10:09:20.345266.345266 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.345122.345122 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.345646.345646 lmp.py:1626]   Expert 19 |     23 | CPU
DEBUG 01-15 10:09:20.345263.345263 lmp.py:1626]   Expert 42 |     23 | CPU
DEBUG 01-15 10:09:20.345450.345450 lmp.py:1626]   Expert 30 |     26 | CPU
DEBUG 01-15 10:09:20.345590.345590 lmp.py:1626]   Expert 32 |     47 | CPU
DEBUG 01-15 10:09:20.345445.345445 lmp.py:1626]   Expert  6 |     57 | CPU
DEBUG 01-15 10:09:20.345632.345632 lmp.py:1626]   Expert  5 |     72 | CPU
DEBUG 01-15 10:09:20.345580.345580 lmp.py:1626]   Expert 53 |     75 | CPU
DEBUG 01-15 10:09:20.345051.345051 lmp.py:1626]   Expert  1 |     80 | CPU
DEBUG 01-15 10:09:20.345476.345476 lmp.py:1626]   Expert 63 |    123 | CPU
DEBUG 01-15 10:09:20.345901.345901 lmp.py:1626]   Expert 13 |    124 | CPU
DEBUG 01-15 10:09:20.345518.345518 lmp.py:1626]   Expert  9 |    125 | CPU
DEBUG 01-15 10:09:20.345373.345373 lmp.py:1626]   Expert 34 |    128 | CPU
DEBUG 01-15 10:09:20.345752.345752 lmp.py:1626]   Expert 50 |    130 | CPU
DEBUG 01-15 10:09:20.345938.345938 lmp.py:1626]   Expert 58 |    130 | CPU
DEBUG 01-15 10:09:20.345887.345887 lmp.py:1626]   Expert 11 |    135 | CPU
DEBUG 01-15 10:09:20.345358.345358 lmp.py:1626]   Expert 26 |    136 | CPU
DEBUG 01-15 10:09:20.345306.345306 lmp.py:1626]   Expert 59 |    137 | CPU
DEBUG 01-15 10:09:20.346777.346777 lmp.py:1626]   Expert 18 |    140 | CPU
DEBUG 01-15 10:09:20.346871.346871 lmp.py:1626]   Expert 31 |    140 | CPU
DEBUG 01-15 10:09:20.346011.346011 lmp.py:1626]   Expert 40 |    145 | CPU
DEBUG 01-15 10:09:20.346198.346198 lmp.py:1626]   Expert 12 |    148 | CPU
DEBUG 01-15 10:09:20.346384.346384 lmp.py:1626]   Expert  2 |    152 | CPU
DEBUG 01-15 10:09:20.346332.346332 lmp.py:1626]   Expert  4 |    152 | CPU
DEBUG 01-15 10:09:20.346565.346565 lmp.py:1626]   Expert 46 |    152 | CPU
DEBUG 01-15 10:09:20.346275.346275 lmp.py:1626]   Expert 20 |    153 | CPU
DEBUG 01-15 10:09:20.346984.346984 lmp.py:1626]   Expert 48 |    153 | CPU
DEBUG 01-15 10:09:20.346085.346085 lmp.py:1626]   Expert 56 |    154 | CPU
DEBUG 01-15 10:09:20.346987.346987 lmp.py:1626]   Expert 33 |    155 | CPU
DEBUG 01-15 10:09:20.346458.346458 lmp.py:1626]   Expert 61 |    157 | CPU
DEBUG 01-15 10:09:20.346691.346691 lmp.py:1626]   Expert 35 |    162 | CPU
DEBUG 01-15 10:09:20.346507.346507 lmp.py:1626]   Expert 10 |    167 | CPU
DEBUG 01-15 10:09:20.346084.346084 lmp.py:1626]   Expert 55 |    171 | CPU
DEBUG 01-15 10:09:20.346701.346701 lmp.py:1626]   Expert 51 |    174 | GPU
DEBUG 01-15 10:09:20.346948.346948 lmp.py:1626]   Expert 36 |    180 | GPU
DEBUG 01-15 10:09:20.346896.346896 lmp.py:1626]   Expert  8 |    185 | GPU
DEBUG 01-15 10:09:20.346996.346996 lmp.py:1626]   Expert 52 |    185 | GPU
DEBUG 01-15 10:09:20.346375.346375 lmp.py:1626]   Expert 37 |    187 | GPU
DEBUG 01-15 10:09:20.346205.346205 lmp.py:1626]   Expert  0 |    203 | GPU
DEBUG 01-15 10:09:20.346298.346298 lmp.py:1626]   Expert 57 |    205 | GPU
DEBUG 01-15 10:09:20.346770.346770 lmp.py:1626]   Expert 39 |    219 | GPU
DEBUG 01-15 10:09:20.346526.346526 lmp.py:1626]   Expert 25 |    225 | GPU
DEBUG 01-15 10:09:20.346282.346282 lmp.py:1626]   Expert 62 |    233 | GPU
DEBUG 01-15 10:09:20.346276.346276 lmp.py:1626]   Expert 38 |    241 | GPU
DEBUG 01-15 10:09:20.346701.346701 lmp.py:1626]   Expert  7 |    244 | GPU
DEBUG 01-15 10:09:20.346411.346411 lmp.py:1626]   Expert 24 |    248 | GPU
DEBUG 01-15 10:09:20.346405.346405 lmp.py:1626]   Expert  3 |    249 | GPU
DEBUG 01-15 10:09:20.346161.346161 lmp.py:1626]   Expert 27 |    253 | GPU
DEBUG 01-15 10:09:20.347394.347394 lmp.py:1626]   Expert 28 |    253 | GPU
DEBUG 01-15 10:09:20.347627.347627 lmp.py:1626]   Expert 49 |    256 | GPU
DEBUG 01-15 10:09:20.347336.347336 lmp.py:1626]   Expert 60 |    256 | GPU
DEBUG 01-15 10:09:20.347523.347523 lmp.py:1626]   Expert 21 |    261 | GPU
DEBUG 01-15 10:09:20.347425.347425 lmp.py:1626]   Expert 16 |    268 | GPU
DEBUG 01-15 10:09:20.347896.347896 lmp.py:1626]   Expert 43 |    270 | GPU
DEBUG 01-15 10:09:20.347129.347129 lmp.py:1626]   Expert 23 |    275 | GPU
DEBUG 01-15 10:09:20.347123.347123 lmp.py:1626]   Expert 29 |    278 | GPU
DEBUG 01-15 10:09:20.347356.347356 lmp.py:1626]   Expert 15 |    294 | GPU
DEBUG 01-15 10:09:20.347589.347589 lmp.py:1626]   Expert 22 |    295 | GPU
DEBUG 01-15 10:09:20.347775.347775 lmp.py:1626]   Expert 47 |    295 | GPU
DEBUG 01-15 10:09:20.347962.347962 lmp.py:1626]   Expert 41 |    298 | GPU
DEBUG 01-15 10:09:20.347195.347195 lmp.py:1626]   Expert 44 |    305 | GPU
DEBUG 01-15 10:09:20.347428.347428 lmp.py:1626]   Expert 54 |    353 | GPU
DEBUG 01-15 10:09:20.347660.347660 lmp.py:1626]   Expert 14 |    375 | GPU
DEBUG 01-15 10:09:20.347893.347893 lmp.py:1626]   Expert 17 |    404 | GPU
DEBUG 01-15 10:09:20.347888.347888 lmp.py:1626]   Expert 45 |    449 | GPU
DEBUG 01-15 10:09:20.347028.347028 lmp.py:1627] 
DEBUG 01-15 10:09:20.347028.347028 lmp.py:1627]   CPU total tokens: 3872 (31.5%)
DEBUG 01-15 10:09:20.347837.347837 lmp.py:1628]   GPU total tokens: 8416 (68.5%)
DEBUG 01-15 10:09:20.347083.347083 cuda_h.py:19] end experts_map_get cost 0.002893209457397461 seconds
DEBUG 01-15 10:09:20.347513.347513 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.347217.347217 lmp.py:1636] 
DEBUG 01-15 10:09:20.347217.347217 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.347293.347293 cuda_h.py:19] end cpu_experts_submit cost 8.916854858398438e-05 seconds
DEBUG 01-15 10:09:20.348155.348155 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.348238.348238 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.348193.348193 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.348299.348299 cuda_h.py:19] end allocate_cuda_memory cost 0.00030541419982910156 seconds
DEBUG 01-15 10:09:20.348144.348144 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.348357.348357 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.348068.348068 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.349175.349175 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 424a4ef2-1877-4b64-b88e-a66e9642e9ad
DEBUG 01-15 10:09:20.349866.349866 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.349035.349035 cuda_h.py:19] end restore2model cost 0.0055882930755615234 seconds
DEBUG 01-15 10:09:20.350039.350039 cuda_h.py:19] end sllm_worker_task cost 0.014306306838989258 seconds
DEBUG 01-15 10:09:20.350548.350548 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:20.350682.350682 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 424a4ef2-1877-4b64-b88e-a66e9642e9ad
DEBUG 01-15 10:09:20.350453.350453 cuda_h.py:19] end load_into_gpu_async cost 0.0014758110046386719 seconds
DEBUG 01-15 10:09:20.350586.350586 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.350066.350066 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.350835.350835 cuda_h.py:19] end restore_tensors2 cost 0.00047278404235839844 seconds
DEBUG 01-15 10:09:20.350347.350347 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002814769744873047 seconds
DEBUG 01-15 10:09:20.351409.351409 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.351335.351335 cuda_h.py:19] end move_flatidxs cost 0.0010411739349365234 seconds
DEBUG 01-15 10:09:20.351231.351231 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.353341.353341 cuda_h.py:19] end restore2model cost 0.0026891231536865234 seconds
DEBUG 01-15 10:09:20.353198.353198 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005786895751953125 seconds
DEBUG 01-15 10:09:20.353537.353537 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.354965.354965 cuda_h.py:19] end gpu_sexperts cost 0.00028443336486816406 seconds
DEBUG 01-15 10:09:20.354847.354847 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.355898.355898 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001478433609008789 seconds
DEBUG 01-15 10:09:20.356151.356151 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.356224.356224 cuda_h.py:19] end gpu_group_list cost 0.0003428459167480469 seconds
DEBUG 01-15 10:09:20.357678.357678 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.357088.357088 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007169246673583984 seconds
DEBUG 01-15 10:09:20.357765.357765 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.357448.357448 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-15 10:09:20.357383.357383 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.364599.364599 cuda_h.py:19] end group_tensors cost 0.012722492218017578 seconds
DEBUG 01-15 10:09:20.365269.365269 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.371356.371356 cuda_h.py:19] end group pad cost 0.005698442459106445 seconds
DEBUG 01-15 10:09:20.371769.371769 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.396359.396359 cuda_h.py:19] end group_einsum cost 0.02544689178466797 seconds
DEBUG 01-15 10:09:20.396715.396715 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.402047.402047 cuda_h.py:19] end get_outputs_cpu1 cost 0.005296468734741211 seconds
DEBUG 01-15 10:09:20.402631.402631 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.052637577056884766 seconds
DEBUG 01-15 10:09:20.403090.403090 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04576992988586426 seconds
DEBUG 01-15 10:09:20.404303.404303 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.404124.404124 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.404240.404240 cuda_h.py:19] end index_scatter cost 0.00016999244689941406 seconds
DEBUG 01-15 10:09:20.405694.405694 cuda_h.py:19] end cpuoutputsdeal cost 0.001272439956665039 seconds
DEBUG 01-15 10:09:20.405366.405366 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.405104.405104 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 424a4ef2-1877-4b64-b88e-a66e9642e9ad
INFO 01-15 10:09:20.406272.406272 client.py:127] Model loaded
DEBUG 01-15 10:09:20.407555.407555 cuda_h.py:19] end wait_experts cost 0.001392364501953125 seconds
DEBUG 01-15 10:09:20.407557.407557 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.407449.407449 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.407650.407650 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.407884.407884 cuda_h.py:19] end gpu_group_tensor cost 0.0003757476806640625 seconds
DEBUG 01-15 10:09:20.407574.407574 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.409028.409028 cuda_h.py:19] end gpu_group_einsum cost 0.0012135505676269531 seconds
DEBUG 01-15 10:09:20.409207.409207 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.409211.409211 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.410812.410812 cuda_h.py:19] end all_expert_outputs_slices cost 0.0004754066467285156 seconds
DEBUG 01-15 10:09:20.410616.410616 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.410747.410747 cuda_h.py:19] end concat_expert_out cost 0.00010848045349121094 seconds
DEBUG 01-15 10:09:20.410850.410850 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.410505.410505 cuda_h.py:19] end index_scatter cost 9.369850158691406e-05 seconds
DEBUG 01-15 10:09:20.410600.410600 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011601448059082031 seconds
DEBUG 01-15 10:09:20.410797.410797 cuda_h.py:19] end gpu_experts cost 0.0037298202514648438 seconds
DEBUG 01-15 10:09:20.411278.411278 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06771373748779297 seconds
DEBUG 01-15 10:09:20.411958.411958 cuda_h.py:19] end prefill_layer cost 0.0767066478729248 seconds
DEBUG 01-15 10:09:20.411339.411339 lmp.py:1552] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-15 10:09:20.411360.411360 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.411574.411574 lmp.py:1495] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-15 10:09:20.411026.411026 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:20.412631.412631 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:20.412509.412509 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.389617919921875e-05 seconds
DEBUG 01-15 10:09:20.412736.412736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.00013136863708496094 seconds
DEBUG 01-15 10:09:20.412466.412466 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.412279.412279 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.412320.412320 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.412767.412767 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.412530.412530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.413064.413064 cuda_h.py:19] end allocate_cuda_memory cost 0.00043201446533203125 seconds
DEBUG 01-15 10:09:20.413408.413408 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.413014.413014 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.413170.413170 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.414418.414418 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29ac2960-8b6e-4bf4-8f1f-bfc660d5bdfe
DEBUG 01-15 10:09:20.414266.414266 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.414705.414705 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.415111.415111 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29ac2960-8b6e-4bf4-8f1f-bfc660d5bdfe
DEBUG 01-15 10:09:20.415049.415049 cuda_h.py:19] end load_into_gpu_async cost 0.0014274120330810547 seconds
DEBUG 01-15 10:09:20.415243.415243 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.415172.415172 cuda_h.py:19] end restore_tensors2 cost 0.00015473365783691406 seconds
DEBUG 01-15 10:09:20.415294.415294 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026810169219970703 seconds
INFO 01-15 10:09:20.415657.415657 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29ac2960-8b6e-4bf4-8f1f-bfc660d5bdfe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.420405.420405 cuda_h.py:19] end self_attn cost 0.00557255744934082 seconds
DEBUG 01-15 10:09:20.420875.420875 cuda_h.py:19] end iln_self_attn_paln cost 0.008393287658691406 seconds
DEBUG 01-15 10:09:20.420493.420493 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-15 10:09:20.420978.420978 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.421646.421646 cuda_h.py:19] end gate cost 0.0007331371307373047 seconds
DEBUG 01-15 10:09:20.421251.421251 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.422899.422899 lmp.py:1616] 
DEBUG 01-15 10:09:20.422899.422899 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.422523.422523 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.422325.422325 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.422028.422028 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.422347.422347 lmp.py:1620] 
DEBUG 01-15 10:09:20.422347.422347 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.422427.422427 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.422223.422223 lmp.py:1626]   Expert 34 |     28 | CPU
DEBUG 01-15 10:09:20.422826.422826 lmp.py:1626]   Expert  7 |     33 | CPU
DEBUG 01-15 10:09:20.422774.422774 lmp.py:1626]   Expert 13 |     40 | CPU
DEBUG 01-15 10:09:20.422424.422424 lmp.py:1626]   Expert 54 |     76 | CPU
DEBUG 01-15 10:09:20.422074.422074 lmp.py:1626]   Expert 18 |     83 | CPU
DEBUG 01-15 10:09:20.422008.422008 lmp.py:1626]   Expert 39 |     88 | CPU
DEBUG 01-15 10:09:20.422897.422897 lmp.py:1626]   Expert 49 |     88 | CPU
DEBUG 01-15 10:09:20.422738.422738 lmp.py:1626]   Expert 59 |    104 | CPU
DEBUG 01-15 10:09:20.422103.422103 lmp.py:1626]   Expert 21 |    106 | CPU
DEBUG 01-15 10:09:20.422992.422992 lmp.py:1626]   Expert  0 |    109 | CPU
DEBUG 01-15 10:09:20.422926.422926 lmp.py:1626]   Expert 16 |    113 | CPU
DEBUG 01-15 10:09:20.422861.422861 lmp.py:1626]   Expert 15 |    117 | CPU
DEBUG 01-15 10:09:20.422795.422795 lmp.py:1626]   Expert 41 |    117 | CPU
DEBUG 01-15 10:09:20.422968.422968 lmp.py:1626]   Expert 22 |    122 | CPU
DEBUG 01-15 10:09:20.422903.422903 lmp.py:1626]   Expert 45 |    122 | CPU
DEBUG 01-15 10:09:20.422837.422837 lmp.py:1626]   Expert 17 |    124 | CPU
DEBUG 01-15 10:09:20.422964.422964 lmp.py:1626]   Expert 61 |    133 | CPU
DEBUG 01-15 10:09:20.422090.422090 lmp.py:1626]   Expert  8 |    136 | CPU
DEBUG 01-15 10:09:20.422932.422932 lmp.py:1626]   Expert 35 |    136 | CPU
DEBUG 01-15 10:09:20.422344.422344 lmp.py:1626]   Expert 52 |    136 | CPU
DEBUG 01-15 10:09:20.422278.422278 lmp.py:1626]   Expert 38 |    140 | CPU
DEBUG 01-15 10:09:20.422974.422974 lmp.py:1626]   Expert 12 |    142 | CPU
DEBUG 01-15 10:09:20.422670.422670 lmp.py:1626]   Expert 31 |    148 | CPU
DEBUG 01-15 10:09:20.422605.422605 lmp.py:1626]   Expert 48 |    148 | CPU
DEBUG 01-15 10:09:20.422301.422301 lmp.py:1626]   Expert 53 |    153 | CPU
DEBUG 01-15 10:09:20.422474.422474 lmp.py:1626]   Expert 36 |    154 | CPU
DEBUG 01-15 10:09:20.422885.422885 lmp.py:1626]   Expert 60 |    157 | CPU
DEBUG 01-15 10:09:20.422773.422773 lmp.py:1626]   Expert 50 |    161 | CPU
DEBUG 01-15 10:09:20.422185.422185 lmp.py:1626]   Expert 40 |    163 | CPU
DEBUG 01-15 10:09:20.422596.422596 lmp.py:1626]   Expert 27 |    175 | CPU
DEBUG 01-15 10:09:20.422530.422530 lmp.py:1626]   Expert 19 |    195 | CPU
DEBUG 01-15 10:09:20.422465.422465 lmp.py:1626]   Expert  4 |    198 | CPU
DEBUG 01-15 10:09:20.422399.422399 lmp.py:1626]   Expert 29 |    202 | GPU
DEBUG 01-15 10:09:20.422619.422619 lmp.py:1626]   Expert 30 |    204 | GPU
DEBUG 01-15 10:09:20.422553.422553 lmp.py:1626]   Expert 20 |    219 | GPU
DEBUG 01-15 10:09:20.423772.423772 lmp.py:1626]   Expert 26 |    219 | GPU
DEBUG 01-15 10:09:20.423230.423230 lmp.py:1626]   Expert 11 |    220 | GPU
DEBUG 01-15 10:09:20.423926.423926 lmp.py:1626]   Expert 57 |    223 | GPU
DEBUG 01-15 10:09:20.423384.423384 lmp.py:1626]   Expert  6 |    226 | GPU
DEBUG 01-15 10:09:20.423511.423511 lmp.py:1626]   Expert 46 |    226 | GPU
DEBUG 01-15 10:09:20.423399.423399 lmp.py:1626]   Expert 43 |    233 | GPU
DEBUG 01-15 10:09:20.423048.423048 lmp.py:1626]   Expert 33 |    240 | GPU
DEBUG 01-15 10:09:20.423460.423460 lmp.py:1626]   Expert  2 |    243 | GPU
DEBUG 01-15 10:09:20.423156.423156 lmp.py:1626]   Expert 23 |    243 | GPU
DEBUG 01-15 10:09:20.423375.423375 lmp.py:1626]   Expert 42 |    246 | GPU
DEBUG 01-15 10:09:20.423071.423071 lmp.py:1626]   Expert 55 |    252 | GPU
DEBUG 01-15 10:09:20.423006.423006 lmp.py:1626]   Expert 56 |    254 | GPU
DEBUG 01-15 10:09:20.423702.423702 lmp.py:1626]   Expert 32 |    258 | GPU
DEBUG 01-15 10:09:20.423067.423067 lmp.py:1626]   Expert  9 |    259 | GPU
DEBUG 01-15 10:09:20.423955.423955 lmp.py:1626]   Expert  3 |    262 | GPU
DEBUG 01-15 10:09:20.423320.423320 lmp.py:1626]   Expert 14 |    263 | GPU
DEBUG 01-15 10:09:20.423255.423255 lmp.py:1626]   Expert 28 |    266 | GPU
DEBUG 01-15 10:09:20.423666.423666 lmp.py:1626]   Expert  1 |    276 | GPU
DEBUG 01-15 10:09:20.423600.423600 lmp.py:1626]   Expert 44 |    278 | GPU
DEBUG 01-15 10:09:20.423058.423058 lmp.py:1626]   Expert 51 |    278 | GPU
DEBUG 01-15 10:09:20.423754.423754 lmp.py:1626]   Expert 58 |    279 | GPU
DEBUG 01-15 10:09:20.423450.423450 lmp.py:1626]   Expert 63 |    287 | GPU
DEBUG 01-15 10:09:20.423146.423146 lmp.py:1626]   Expert 37 |    288 | GPU
DEBUG 01-15 10:09:20.423273.423273 lmp.py:1626]   Expert 47 |    293 | GPU
DEBUG 01-15 10:09:20.423684.423684 lmp.py:1626]   Expert 24 |    301 | GPU
DEBUG 01-15 10:09:20.423380.423380 lmp.py:1626]   Expert 10 |    310 | GPU
DEBUG 01-15 10:09:20.423315.423315 lmp.py:1626]   Expert 62 |    312 | GPU
DEBUG 01-15 10:09:20.423011.423011 lmp.py:1626]   Expert 25 |    320 | GPU
DEBUG 01-15 10:09:20.423469.423469 lmp.py:1626]   Expert  5 |    363 | GPU
DEBUG 01-15 10:09:20.423357.423357 lmp.py:1627] 
DEBUG 01-15 10:09:20.423357.423357 lmp.py:1627]   CPU total tokens: 3945 (32.1%)
DEBUG 01-15 10:09:20.423483.423483 lmp.py:1628]   GPU total tokens: 8343 (67.9%)
DEBUG 01-15 10:09:20.423902.423902 cuda_h.py:19] end experts_map_get cost 0.001989126205444336 seconds
DEBUG 01-15 10:09:20.423441.423441 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.423396.423396 lmp.py:1636] 
DEBUG 01-15 10:09:20.423396.423396 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.423868.423868 cuda_h.py:19] end cpu_experts_submit cost 6.604194641113281e-05 seconds
DEBUG 01-15 10:09:20.423094.423094 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.423805.423805 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.424812.424812 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.424332.424332 cuda_h.py:19] end allocate_cuda_memory cost 0.000232696533203125 seconds
DEBUG 01-15 10:09:20.424950.424950 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.424713.424713 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.424032.424032 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.424411.424411 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1becb3d-3050-4ba8-89ab-14644af31521
DEBUG 01-15 10:09:20.424294.424294 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:20.425918.425918 client.py:127] Model loaded
DEBUG 01-15 10:09:20.425280.425280 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.425878.425878 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:20.426503.426503 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1becb3d-3050-4ba8-89ab-14644af31521
DEBUG 01-15 10:09:20.426797.426797 cuda_h.py:19] end load_into_gpu_async cost 0.00153350830078125 seconds
DEBUG 01-15 10:09:20.426321.426321 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.426592.426592 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.426008.426008 cuda_h.py:19] end restore_tensors2 cost 0.0005061626434326172 seconds
DEBUG 01-15 10:09:20.427642.427642 cuda_h.py:19] end move_flatidxs cost 0.0010135173797607422 seconds
DEBUG 01-15 10:09:20.427531.427531 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.427815.427815 cuda_h.py:19] end restore2model cost 0.0018422603607177734 seconds
DEBUG 01-15 10:09:20.427281.427281 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003682851791381836 seconds
DEBUG 01-15 10:09:20.427080.427080 cuda_h.py:19] end sllm_worker_task cost 0.015085458755493164 seconds
DEBUG 01-15 10:09:20.427977.427977 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.431936.431936 cuda_h.py:19] end restore2model cost 0.002980470657348633 seconds
DEBUG 01-15 10:09:20.431031.431031 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0071947574615478516 seconds
DEBUG 01-15 10:09:20.431588.431588 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.431877.431877 cuda_h.py:19] end gpu_sexperts cost 0.00028824806213378906 seconds
DEBUG 01-15 10:09:20.431184.431184 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.433122.433122 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001499176025390625 seconds
DEBUG 01-15 10:09:20.433287.433287 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.433960.433960 cuda_h.py:19] end group_tensors cost 0.006029367446899414 seconds
DEBUG 01-15 10:09:20.434645.434645 cuda_h.py:19] end gpu_group_list cost 0.00035858154296875 seconds
DEBUG 01-15 10:09:20.434281.434281 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.434231.434231 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.435307.435307 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008225440979003906 seconds
DEBUG 01-15 10:09:20.435706.435706 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.435151.435151 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.71661376953125e-05 seconds
DEBUG 01-15 10:09:20.435562.435562 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.438042.438042 cuda_h.py:19] end group pad cost 0.00468754768371582 seconds
DEBUG 01-15 10:09:20.439276.439276 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.461665.461665 cuda_h.py:19] end group_einsum cost 0.022600650787353516 seconds
DEBUG 01-15 10:09:20.461584.461584 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.466742.466742 cuda_h.py:19] end get_outputs_cpu1 cost 0.0046350955963134766 seconds
DEBUG 01-15 10:09:20.467876.467876 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04138803482055664 seconds
DEBUG 01-15 10:09:20.468797.468797 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03286147117614746 seconds
DEBUG 01-15 10:09:20.468307.468307 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.468452.468452 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.469962.469962 cuda_h.py:19] end index_scatter cost 0.00012373924255371094 seconds
DEBUG 01-15 10:09:20.469117.469117 cuda_h.py:19] end cpuoutputsdeal cost 0.001165151596069336 seconds
DEBUG 01-15 10:09:20.469649.469649 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.469823.469823 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1becb3d-3050-4ba8-89ab-14644af31521
INFO 01-15 10:09:20.475870.475870 client.py:127] Model loaded
DEBUG 01-15 10:09:20.476510.476510 cuda_h.py:19] end wait_experts cost 0.0062673091888427734 seconds
DEBUG 01-15 10:09:20.476591.476591 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.476509.476509 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.476213.476213 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.476560.476560 cuda_h.py:19] end gpu_group_tensor cost 0.00039696693420410156 seconds
DEBUG 01-15 10:09:20.476329.476329 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.478431.478431 cuda_h.py:19] end gpu_group_einsum cost 0.0011746883392333984 seconds
DEBUG 01-15 10:09:20.478186.478186 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.478805.478805 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.479923.479923 cuda_h.py:19] end all_expert_outputs_slices cost 0.0004775524139404297 seconds
DEBUG 01-15 10:09:20.479250.479250 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.479096.479096 cuda_h.py:19] end concat_expert_out cost 0.00010752677917480469 seconds
DEBUG 01-15 10:09:20.479637.479637 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.479835.479835 cuda_h.py:19] end index_scatter cost 0.00010037422180175781 seconds
DEBUG 01-15 10:09:20.479175.479175 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011718273162841797 seconds
DEBUG 01-15 10:09:20.479763.479763 cuda_h.py:19] end gpu_experts cost 0.003686666488647461 seconds
DEBUG 01-15 10:09:20.480404.480404 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.059194087982177734 seconds
DEBUG 01-15 10:09:20.485396.485396 cuda_h.py:19] end prefill_layer cost 0.07349252700805664 seconds
DEBUG 01-15 10:09:20.486866.486866 lmp.py:1552] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-15 10:09:20.486245.486245 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.486054.486054 lmp.py:1495] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-15 10:09:20.486625.486625 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:20.486573.486573 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:20.486119.486119 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.745887756347656e-05 seconds
DEBUG 01-15 10:09:20.486868.486868 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 9.012222290039062e-05 seconds
DEBUG 01-15 10:09:20.486796.486796 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.486032.486032 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.486051.486051 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.486117.486117 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.487465.487465 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.487866.487866 cuda_h.py:19] end allocate_cuda_memory cost 0.000408172607421875 seconds
DEBUG 01-15 10:09:20.487070.487070 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.487331.487331 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.487581.487581 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.487266.487266 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d84133b8-d62e-4263-b1e3-9d2a7775e0af
DEBUG 01-15 10:09:20.488457.488457 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.488029.488029 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.489290.489290 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d84133b8-d62e-4263-b1e3-9d2a7775e0af
DEBUG 01-15 10:09:20.489943.489943 cuda_h.py:19] end load_into_gpu_async cost 0.002069711685180664 seconds
DEBUG 01-15 10:09:20.489733.489733 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.490156.490156 cuda_h.py:19] end restore_tensors2 cost 0.00011968612670898438 seconds
DEBUG 01-15 10:09:20.490523.490523 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003179311752319336 seconds
INFO 01-15 10:09:20.490951.490951 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d84133b8-d62e-4263-b1e3-9d2a7775e0af
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.492386.492386 cuda_h.py:19] end self_attn cost 0.0044596195220947266 seconds
DEBUG 01-15 10:09:20.493263.493263 cuda_h.py:19] end iln_self_attn_paln cost 0.006813526153564453 seconds
DEBUG 01-15 10:09:20.493113.493113 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-15 10:09:20.493684.493684 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.494670.494670 cuda_h.py:19] end gate cost 0.0007269382476806641 seconds
DEBUG 01-15 10:09:20.494168.494168 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.494278.494278 lmp.py:1616] 
DEBUG 01-15 10:09:20.494278.494278 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.494703.494703 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.494360.494360 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.494956.494956 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.494123.494123 lmp.py:1620] 
DEBUG 01-15 10:09:20.494123.494123 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.494719.494719 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.494177.494177 lmp.py:1626]   Expert 15 |     61 | CPU
DEBUG 01-15 10:09:20.494581.494581 lmp.py:1626]   Expert 41 |     72 | CPU
DEBUG 01-15 10:09:20.494794.494794 lmp.py:1626]   Expert  0 |     74 | CPU
DEBUG 01-15 10:09:20.494483.494483 lmp.py:1626]   Expert 63 |     76 | CPU
DEBUG 01-15 10:09:20.494696.494696 lmp.py:1626]   Expert 20 |     83 | CPU
DEBUG 01-15 10:09:20.494908.494908 lmp.py:1626]   Expert 45 |     88 | CPU
DEBUG 01-15 10:09:20.494121.494121 lmp.py:1626]   Expert  7 |     91 | CPU
DEBUG 01-15 10:09:20.494048.494048 lmp.py:1626]   Expert 28 |     97 | CPU
DEBUG 01-15 10:09:20.494407.494407 lmp.py:1626]   Expert 54 |    106 | CPU
DEBUG 01-15 10:09:20.494526.494526 lmp.py:1626]   Expert 12 |    110 | CPU
DEBUG 01-15 10:09:20.494931.494931 lmp.py:1626]   Expert 40 |    121 | CPU
DEBUG 01-15 10:09:20.494335.494335 lmp.py:1626]   Expert 52 |    121 | CPU
DEBUG 01-15 10:09:20.494740.494740 lmp.py:1626]   Expert 59 |    122 | CPU
DEBUG 01-15 10:09:20.494145.494145 lmp.py:1626]   Expert  5 |    124 | CPU
DEBUG 01-15 10:09:20.494980.494980 lmp.py:1626]   Expert  4 |    131 | CPU
DEBUG 01-15 10:09:20.494338.494338 lmp.py:1626]   Expert 34 |    134 | CPU
DEBUG 01-15 10:09:20.494935.494935 lmp.py:1626]   Expert 61 |    134 | CPU
DEBUG 01-15 10:09:20.494054.494054 lmp.py:1626]   Expert 13 |    135 | CPU
DEBUG 01-15 10:09:20.494697.494697 lmp.py:1626]   Expert 62 |    135 | CPU
DEBUG 01-15 10:09:20.494102.494102 lmp.py:1626]   Expert 55 |    138 | CPU
DEBUG 01-15 10:09:20.494506.494506 lmp.py:1626]   Expert 21 |    143 | CPU
DEBUG 01-15 10:09:20.494673.494673 lmp.py:1626]   Expert 42 |    143 | CPU
DEBUG 01-15 10:09:20.495077.495077 lmp.py:1626]   Expert 14 |    146 | CPU
DEBUG 01-15 10:09:20.495243.495243 lmp.py:1626]   Expert 10 |    148 | CPU
DEBUG 01-15 10:09:20.495409.495409 lmp.py:1626]   Expert 22 |    148 | CPU
DEBUG 01-15 10:09:20.495814.495814 lmp.py:1626]   Expert 32 |    156 | CPU
DEBUG 01-15 10:09:20.495219.495219 lmp.py:1626]   Expert 51 |    157 | CPU
DEBUG 01-15 10:09:20.495623.495623 lmp.py:1626]   Expert 25 |    166 | CPU
DEBUG 01-15 10:09:20.495504.495504 lmp.py:1626]   Expert  1 |    172 | CPU
DEBUG 01-15 10:09:20.495386.495386 lmp.py:1626]   Expert 53 |    174 | CPU
DEBUG 01-15 10:09:20.495744.495744 lmp.py:1626]   Expert 47 |    178 | CPU
DEBUG 01-15 10:09:20.495771.495771 lmp.py:1626]   Expert 50 |    178 | CPU
DEBUG 01-15 10:09:20.495891.495891 lmp.py:1626]   Expert 26 |    179 | GPU
DEBUG 01-15 10:09:20.495534.495534 lmp.py:1626]   Expert  6 |    180 | GPU
DEBUG 01-15 10:09:20.495939.495939 lmp.py:1626]   Expert 19 |    180 | GPU
DEBUG 01-15 10:09:20.495343.495343 lmp.py:1626]   Expert  2 |    184 | GPU
DEBUG 01-15 10:09:20.495748.495748 lmp.py:1626]   Expert 30 |    185 | GPU
DEBUG 01-15 10:09:20.495914.495914 lmp.py:1626]   Expert 11 |    186 | GPU
DEBUG 01-15 10:09:20.495080.495080 lmp.py:1626]   Expert 35 |    187 | GPU
DEBUG 01-15 10:09:20.495485.495485 lmp.py:1626]   Expert 57 |    188 | GPU
DEBUG 01-15 10:09:20.495604.495604 lmp.py:1626]   Expert 56 |    190 | GPU
DEBUG 01-15 10:09:20.495724.495724 lmp.py:1626]   Expert 48 |    203 | GPU
DEBUG 01-15 10:09:20.495844.495844 lmp.py:1626]   Expert 16 |    210 | GPU
DEBUG 01-15 10:09:20.495487.495487 lmp.py:1626]   Expert 44 |    211 | GPU
DEBUG 01-15 10:09:20.495368.495368 lmp.py:1626]   Expert 24 |    212 | GPU
DEBUG 01-15 10:09:20.495488.495488 lmp.py:1626]   Expert 46 |    217 | GPU
DEBUG 01-15 10:09:20.495654.495654 lmp.py:1626]   Expert 18 |    224 | GPU
DEBUG 01-15 10:09:20.495059.495059 lmp.py:1626]   Expert 39 |    225 | GPU
DEBUG 01-15 10:09:20.495225.495225 lmp.py:1626]   Expert 29 |    234 | GPU
DEBUG 01-15 10:09:20.495630.495630 lmp.py:1626]   Expert 37 |    243 | GPU
DEBUG 01-15 10:09:20.495319.495319 lmp.py:1626]   Expert 31 |    254 | GPU
DEBUG 01-15 10:09:20.495439.495439 lmp.py:1626]   Expert 60 |    255 | GPU
DEBUG 01-15 10:09:20.495082.495082 lmp.py:1626]   Expert  3 |    256 | GPU
DEBUG 01-15 10:09:20.495678.495678 lmp.py:1626]   Expert 36 |    257 | GPU
DEBUG 01-15 10:09:20.495798.495798 lmp.py:1626]   Expert 38 |    261 | GPU
DEBUG 01-15 10:09:20.495633.495633 lmp.py:1626]   Expert  9 |    264 | GPU
DEBUG 01-15 10:09:20.495991.495991 lmp.py:1626]   Expert 17 |    268 | GPU
DEBUG 01-15 10:09:20.495396.495396 lmp.py:1626]   Expert 23 |    278 | GPU
DEBUG 01-15 10:09:20.495039.495039 lmp.py:1626]   Expert 27 |    350 | GPU
DEBUG 01-15 10:09:20.495444.495444 lmp.py:1626]   Expert 43 |    365 | GPU
DEBUG 01-15 10:09:20.495610.495610 lmp.py:1626]   Expert  8 |    396 | GPU
DEBUG 01-15 10:09:20.495776.495776 lmp.py:1626]   Expert 33 |    398 | GPU
DEBUG 01-15 10:09:20.495180.495180 lmp.py:1626]   Expert 58 |    443 | GPU
DEBUG 01-15 10:09:20.495346.495346 lmp.py:1626]   Expert 49 |    543 | GPU
DEBUG 01-15 10:09:20.495466.495466 lmp.py:1627] 
DEBUG 01-15 10:09:20.495466.495466 lmp.py:1627]   CPU total tokens: 4062 (33.1%)
DEBUG 01-15 10:09:20.495586.495586 lmp.py:1628]   GPU total tokens: 8226 (66.9%)
DEBUG 01-15 10:09:20.495713.495713 cuda_h.py:19] end experts_map_get cost 0.0016009807586669922 seconds
DEBUG 01-15 10:09:20.495192.495192 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.495571.495571 lmp.py:1636] 
DEBUG 01-15 10:09:20.495571.495571 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.495083.495083 cuda_h.py:19] end cpu_experts_submit cost 6.29425048828125e-05 seconds
DEBUG 01-15 10:09:20.495063.495063 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.496807.496807 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.496779.496779 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.496040.496040 cuda_h.py:19] end allocate_cuda_memory cost 0.0002262592315673828 seconds
INFO 01-15 10:09:20.497601.497601 client.py:127] Model loaded
DEBUG 01-15 10:09:20.497903.497903 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.497900.497900 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.497836.497836 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.497345.497345 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.497373.497373 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.497618.497618 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.497314.497314 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 72ad430c-07a2-48ba-a60c-7e5d62fc536f
DEBUG 01-15 10:09:20.497083.497083 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.498510.498510 cuda_h.py:19] end move_flatidxs cost 0.0008728504180908203 seconds
DEBUG 01-15 10:09:20.498877.498877 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.498011.498011 cuda_h.py:19] end restore2model cost 0.0012056827545166016 seconds
DEBUG 01-15 10:09:20.498154.498154 cuda_h.py:19] end sllm_worker_task cost 0.011801481246948242 seconds
INFO 01-15 10:09:20.498464.498464 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 72ad430c-07a2-48ba-a60c-7e5d62fc536f
DEBUG 01-15 10:09:20.498883.498883 cuda_h.py:19] end load_into_gpu_async cost 0.0016264915466308594 seconds
DEBUG 01-15 10:09:20.498262.498262 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.499838.499838 cuda_h.py:19] end restore_tensors2 cost 0.0003638267517089844 seconds
DEBUG 01-15 10:09:20.499482.499482 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033173561096191406 seconds
DEBUG 01-15 10:09:20.499437.499437 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.501474.501474 cuda_h.py:19] end restore2model cost 0.0024471282958984375 seconds
DEBUG 01-15 10:09:20.501555.501555 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005958080291748047 seconds
DEBUG 01-15 10:09:20.501417.501417 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.502780.502780 cuda_h.py:19] end gpu_sexperts cost 0.0003063678741455078 seconds
DEBUG 01-15 10:09:20.502139.502139 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.503899.503899 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015075206756591797 seconds
DEBUG 01-15 10:09:20.504303.504303 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.505945.505945 cuda_h.py:19] end gpu_group_list cost 0.0003180503845214844 seconds
DEBUG 01-15 10:09:20.505161.505161 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.504727.504727 cuda_h.py:19] end group_tensors cost 0.006159543991088867 seconds
DEBUG 01-15 10:09:20.505142.505142 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.506069.506069 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009758472442626953 seconds
DEBUG 01-15 10:09:20.506065.506065 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.506081.506081 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-15 10:09:20.506307.506307 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.509417.509417 cuda_h.py:19] end group pad cost 0.003801107406616211 seconds
DEBUG 01-15 10:09:20.509207.509207 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.529006.529006 cuda_h.py:19] end group_einsum cost 0.02002573013305664 seconds
DEBUG 01-15 10:09:20.529468.529468 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.534848.534848 cuda_h.py:19] end get_outputs_cpu1 cost 0.004733085632324219 seconds
DEBUG 01-15 10:09:20.535677.535677 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.037885427474975586 seconds
DEBUG 01-15 10:09:20.536187.536187 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.029587984085083008 seconds
DEBUG 01-15 10:09:20.536436.536436 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.536193.536193 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.536464.536464 cuda_h.py:19] end index_scatter cost 9.894371032714844e-05 seconds
DEBUG 01-15 10:09:20.537662.537662 cuda_h.py:19] end cpuoutputsdeal cost 0.0007910728454589844 seconds
DEBUG 01-15 10:09:20.537353.537353 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.537599.537599 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 72ad430c-07a2-48ba-a60c-7e5d62fc536f
INFO 01-15 10:09:20.549463.549463 client.py:127] Model loaded
DEBUG 01-15 10:09:20.549359.549359 cuda_h.py:19] end wait_experts cost 0.012226343154907227 seconds
DEBUG 01-15 10:09:20.549393.549393 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.549482.549482 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.549900.549900 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.549470.549470 cuda_h.py:19] end gpu_group_tensor cost 0.00018262863159179688 seconds
DEBUG 01-15 10:09:20.549281.549281 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.550854.550854 cuda_h.py:19] end gpu_group_einsum cost 0.0006580352783203125 seconds
DEBUG 01-15 10:09:20.550295.550295 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.550416.550416 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.550140.550140 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002231597900390625 seconds
DEBUG 01-15 10:09:20.550942.550942 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.550449.550449 cuda_h.py:19] end concat_expert_out cost 6.127357482910156e-05 seconds
DEBUG 01-15 10:09:20.551438.551438 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.551712.551712 cuda_h.py:19] end index_scatter cost 5.7220458984375e-05 seconds
DEBUG 01-15 10:09:20.551945.551945 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005793571472167969 seconds
DEBUG 01-15 10:09:20.551895.551895 cuda_h.py:19] end gpu_experts cost 0.00189208984375 seconds
DEBUG 01-15 10:09:20.551089.551089 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.05799269676208496 seconds
DEBUG 01-15 10:09:20.551240.551240 cuda_h.py:19] end prefill_layer cost 0.06548738479614258 seconds
DEBUG 01-15 10:09:20.551931.551931 lmp.py:1552] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-15 10:09:20.551104.551104 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.551376.551376 lmp.py:1495] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-15 10:09:20.551741.551741 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:20.551013.551013 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:20.551565.551565 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.123283386230469e-05 seconds
DEBUG 01-15 10:09:20.551917.551917 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.551840.551840 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00012826919555664062 seconds
DEBUG 01-15 10:09:20.552226.552226 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.552665.552665 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.552376.552376 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.552181.552181 cuda_h.py:19] end allocate_cuda_memory cost 0.00022983551025390625 seconds
DEBUG 01-15 10:09:20.552363.552363 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.552384.552384 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.552321.552321 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.552197.552197 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.552138.552138 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61cdb292-a58a-4942-91c2-4a6c4b832d33
DEBUG 01-15 10:09:20.552870.552870 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.553991.553991 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.553980.553980 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61cdb292-a58a-4942-91c2-4a6c4b832d33
DEBUG 01-15 10:09:20.553413.553413 cuda_h.py:19] end load_into_gpu_async cost 0.0009446144104003906 seconds
DEBUG 01-15 10:09:20.553453.553453 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.553828.553828 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-15 10:09:20.553537.553537 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001689910888671875 seconds
INFO 01-15 10:09:20.553493.553493 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61cdb292-a58a-4942-91c2-4a6c4b832d33
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.556642.556642 cuda_h.py:19] end self_attn cost 0.0035445690155029297 seconds
DEBUG 01-15 10:09:20.557684.557684 cuda_h.py:19] end iln_self_attn_paln cost 0.004813432693481445 seconds
DEBUG 01-15 10:09:20.557474.557474 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-15 10:09:20.557376.557376 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.557385.557385 cuda_h.py:19] end gate cost 0.0006420612335205078 seconds
DEBUG 01-15 10:09:20.557877.557877 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.558132.558132 lmp.py:1616] 
DEBUG 01-15 10:09:20.558132.558132 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.558411.558411 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.558299.558299 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.558849.558849 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.558731.558731 lmp.py:1620] 
DEBUG 01-15 10:09:20.558731.558731 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.558327.558327 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.558878.558878 lmp.py:1626]   Expert 58 |     35 | CPU
DEBUG 01-15 10:09:20.558282.558282 lmp.py:1626]   Expert 31 |     59 | CPU
DEBUG 01-15 10:09:20.558879.558879 lmp.py:1626]   Expert 47 |     62 | CPU
DEBUG 01-15 10:09:20.558999.558999 lmp.py:1626]   Expert 49 |     62 | CPU
DEBUG 01-15 10:09:20.558403.558403 lmp.py:1626]   Expert  4 |     66 | CPU
DEBUG 01-15 10:09:20.558808.558808 lmp.py:1626]   Expert 38 |     70 | CPU
DEBUG 01-15 10:09:20.558974.558974 lmp.py:1626]   Expert 45 |     72 | CPU
DEBUG 01-15 10:09:20.558902.558902 lmp.py:1626]   Expert 43 |     83 | CPU
DEBUG 01-15 10:09:20.558260.558260 lmp.py:1626]   Expert 41 |     84 | CPU
DEBUG 01-15 10:09:20.558380.558380 lmp.py:1626]   Expert 33 |     97 | CPU
DEBUG 01-15 10:09:20.558738.558738 lmp.py:1626]   Expert 50 |    103 | CPU
DEBUG 01-15 10:09:20.558858.558858 lmp.py:1626]   Expert 57 |    103 | CPU
DEBUG 01-15 10:09:20.558216.558216 lmp.py:1626]   Expert 11 |    108 | CPU
DEBUG 01-15 10:09:20.558382.558382 lmp.py:1626]   Expert  2 |    114 | CPU
DEBUG 01-15 10:09:20.558548.558548 lmp.py:1626]   Expert 51 |    116 | CPU
DEBUG 01-15 10:09:20.558714.558714 lmp.py:1626]   Expert 14 |    121 | CPU
DEBUG 01-15 10:09:20.558642.558642 lmp.py:1626]   Expert  0 |    122 | CPU
DEBUG 01-15 10:09:20.558570.558570 lmp.py:1626]   Expert 54 |    128 | CPU
DEBUG 01-15 10:09:20.558736.558736 lmp.py:1626]   Expert 26 |    142 | CPU
DEBUG 01-15 10:09:20.558664.558664 lmp.py:1626]   Expert 34 |    142 | CPU
DEBUG 01-15 10:09:20.558068.558068 lmp.py:1626]   Expert 56 |    143 | CPU
DEBUG 01-15 10:09:20.558426.558426 lmp.py:1626]   Expert 27 |    153 | CPU
DEBUG 01-15 10:09:20.558785.558785 lmp.py:1626]   Expert 55 |    157 | CPU
DEBUG 01-15 10:09:20.558666.558666 lmp.py:1626]   Expert 28 |    159 | CPU
DEBUG 01-15 10:09:20.558647.558647 lmp.py:1626]   Expert 10 |    161 | CPU
DEBUG 01-15 10:09:20.558575.558575 lmp.py:1626]   Expert 25 |    163 | CPU
DEBUG 01-15 10:09:20.558549.558549 lmp.py:1626]   Expert  9 |    174 | CPU
DEBUG 01-15 10:09:20.558000.558000 lmp.py:1626]   Expert 13 |    176 | CPU
DEBUG 01-15 10:09:20.558450.558450 lmp.py:1626]   Expert 61 |    185 | CPU
DEBUG 01-15 10:09:20.558901.558901 lmp.py:1626]   Expert  7 |    192 | CPU
DEBUG 01-15 10:09:20.558875.558875 lmp.py:1626]   Expert  6 |    194 | CPU
DEBUG 01-15 10:09:20.558326.558326 lmp.py:1626]   Expert 48 |    196 | CPU
DEBUG 01-15 10:09:20.558539.558539 lmp.py:1626]   Expert 46 |    197 | GPU
DEBUG 01-15 10:09:20.558513.558513 lmp.py:1626]   Expert 24 |    198 | GPU
DEBUG 01-15 10:09:20.558202.558202 lmp.py:1626]   Expert 42 |    200 | GPU
DEBUG 01-15 10:09:20.558368.558368 lmp.py:1626]   Expert 18 |    203 | GPU
DEBUG 01-15 10:09:20.558534.558534 lmp.py:1626]   Expert 40 |    209 | GPU
DEBUG 01-15 10:09:20.558224.558224 lmp.py:1626]   Expert 12 |    213 | GPU
DEBUG 01-15 10:09:20.558151.558151 lmp.py:1626]   Expert 22 |    216 | GPU
DEBUG 01-15 10:09:20.558364.558364 lmp.py:1626]   Expert 63 |    216 | GPU
DEBUG 01-15 10:09:20.558338.558338 lmp.py:1626]   Expert 21 |    218 | GPU
DEBUG 01-15 10:09:20.558073.558073 lmp.py:1626]   Expert 29 |    218 | GPU
DEBUG 01-15 10:09:20.558524.558524 lmp.py:1626]   Expert 59 |    218 | GPU
DEBUG 01-15 10:09:20.559737.559737 lmp.py:1626]   Expert 32 |    227 | GPU
DEBUG 01-15 10:09:20.559472.559472 lmp.py:1626]   Expert 19 |    229 | GPU
DEBUG 01-15 10:09:20.559208.559208 lmp.py:1626]   Expert 36 |    236 | GPU
DEBUG 01-15 10:09:20.559421.559421 lmp.py:1626]   Expert  3 |    242 | GPU
DEBUG 01-15 10:09:20.559156.559156 lmp.py:1626]   Expert 16 |    246 | GPU
DEBUG 01-15 10:09:20.559369.559369 lmp.py:1626]   Expert  1 |    248 | GPU
DEBUG 01-15 10:09:20.559296.559296 lmp.py:1626]   Expert 37 |    248 | GPU
DEBUG 01-15 10:09:20.559986.559986 lmp.py:1626]   Expert 20 |    260 | GPU
DEBUG 01-15 10:09:20.559675.559675 lmp.py:1626]   Expert  5 |    265 | GPU
DEBUG 01-15 10:09:20.559841.559841 lmp.py:1626]   Expert  8 |    265 | GPU
DEBUG 01-15 10:09:20.559007.559007 lmp.py:1626]   Expert 30 |    269 | GPU
DEBUG 01-15 10:09:20.559697.559697 lmp.py:1626]   Expert 62 |    272 | GPU
DEBUG 01-15 10:09:20.559671.559671 lmp.py:1626]   Expert 15 |    274 | GPU
DEBUG 01-15 10:09:20.559406.559406 lmp.py:1626]   Expert 39 |    298 | GPU
DEBUG 01-15 10:09:20.559619.559619 lmp.py:1626]   Expert 35 |    300 | GPU
DEBUG 01-15 10:09:20.559593.559593 lmp.py:1626]   Expert 17 |    309 | GPU
DEBUG 01-15 10:09:20.559567.559567 lmp.py:1626]   Expert 60 |    316 | GPU
DEBUG 01-15 10:09:20.559541.559541 lmp.py:1626]   Expert 52 |    355 | GPU
DEBUG 01-15 10:09:20.559276.559276 lmp.py:1626]   Expert 23 |    366 | GPU
DEBUG 01-15 10:09:20.559250.559250 lmp.py:1626]   Expert 44 |    378 | GPU
DEBUG 01-15 10:09:20.559987.559987 lmp.py:1626]   Expert 53 |    437 | GPU
DEBUG 01-15 10:09:20.559412.559412 lmp.py:1627] 
DEBUG 01-15 10:09:20.559412.559412 lmp.py:1627]   CPU total tokens: 3942 (32.1%)
DEBUG 01-15 10:09:20.559247.559247 lmp.py:1628]   GPU total tokens: 8346 (67.9%)
DEBUG 01-15 10:09:20.559374.559374 cuda_h.py:19] end experts_map_get cost 0.0015647411346435547 seconds
DEBUG 01-15 10:09:20.559939.559939 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.559026.559026 lmp.py:1636] 
DEBUG 01-15 10:09:20.559026.559026 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.559286.559286 cuda_h.py:19] end cpu_experts_submit cost 5.1021575927734375e-05 seconds
DEBUG 01-15 10:09:20.559651.559651 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.559203.559203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.559790.559790 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.560769.560769 cuda_h.py:19] end allocate_cuda_memory cost 0.00030112266540527344 seconds
DEBUG 01-15 10:09:20.560500.560500 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.560355.560355 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.560211.560211 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.560337.560337 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff62c9eb-fb4c-44b7-83b1-873fbf0cfdcd
DEBUG 01-15 10:09:20.560669.560669 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:20.560113.560113 client.py:127] Model loaded
DEBUG 01-15 10:09:20.561274.561274 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.561401.561401 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.561031.561031 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:20.561722.561722 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff62c9eb-fb4c-44b7-83b1-873fbf0cfdcd
DEBUG 01-15 10:09:20.561803.561803 cuda_h.py:19] end load_into_gpu_async cost 0.0013108253479003906 seconds
DEBUG 01-15 10:09:20.561221.561221 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.561247.561247 cuda_h.py:19] end restore_tensors2 cost 0.0003399848937988281 seconds
DEBUG 01-15 10:09:20.562157.562157 cuda_h.py:19] end restore2model cost 0.0009891986846923828 seconds
DEBUG 01-15 10:09:20.562808.562808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024182796478271484 seconds
DEBUG 01-15 10:09:20.562327.562327 cuda_h.py:19] end sllm_worker_task cost 0.010123491287231445 seconds
DEBUG 01-15 10:09:20.562223.562223 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.562781.562781 cuda_h.py:19] end move_flatidxs cost 0.0009772777557373047 seconds
DEBUG 01-15 10:09:20.562956.562956 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.564574.564574 cuda_h.py:19] end restore2model cost 0.0024847984313964844 seconds
DEBUG 01-15 10:09:20.564702.564702 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005244255065917969 seconds
DEBUG 01-15 10:09:20.564736.564736 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.565567.565567 cuda_h.py:19] end gpu_sexperts cost 0.00026702880859375 seconds
DEBUG 01-15 10:09:20.565250.565250 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.566336.566336 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015385150909423828 seconds
DEBUG 01-15 10:09:20.567282.567282 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.567758.567758 cuda_h.py:19] end gpu_group_list cost 0.00030303001403808594 seconds
DEBUG 01-15 10:09:20.568245.568245 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.568476.568476 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007274150848388672 seconds
DEBUG 01-15 10:09:20.568537.568537 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.568360.568360 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-15 10:09:20.568341.568341 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.573523.573523 cuda_h.py:19] end group_tensors cost 0.011357545852661133 seconds
DEBUG 01-15 10:09:20.574601.574601 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.578229.578229 cuda_h.py:19] end group pad cost 0.0038678646087646484 seconds
DEBUG 01-15 10:09:20.578788.578788 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.601988.601988 cuda_h.py:19] end group_einsum cost 0.022109031677246094 seconds
DEBUG 01-15 10:09:20.601450.601450 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.605063.605063 cuda_h.py:19] end get_outputs_cpu1 cost 0.004589080810546875 seconds
DEBUG 01-15 10:09:20.606157.606157 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04540514945983887 seconds
DEBUG 01-15 10:09:20.607935.607935 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03863382339477539 seconds
DEBUG 01-15 10:09:20.607498.607498 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.608674.608674 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.608878.608878 cuda_h.py:19] end index_scatter cost 0.00010848045349121094 seconds
DEBUG 01-15 10:09:20.609655.609655 cuda_h.py:19] end cpuoutputsdeal cost 0.0016536712646484375 seconds
DEBUG 01-15 10:09:20.609022.609022 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.609837.609837 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff62c9eb-fb4c-44b7-83b1-873fbf0cfdcd
INFO 01-15 10:09:20.611302.611302 client.py:127] Model loaded
DEBUG 01-15 10:09:20.611576.611576 cuda_h.py:19] end wait_experts cost 0.0022699832916259766 seconds
DEBUG 01-15 10:09:20.611186.611186 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.612135.612135 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.612129.612129 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.612912.612912 cuda_h.py:19] end gpu_group_tensor cost 0.00018930435180664062 seconds
DEBUG 01-15 10:09:20.612671.612671 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.613470.613470 cuda_h.py:19] end gpu_group_einsum cost 0.0006403923034667969 seconds
DEBUG 01-15 10:09:20.613852.613852 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.613417.613417 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.613906.613906 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003211498260498047 seconds
DEBUG 01-15 10:09:20.613159.613159 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.613712.613712 cuda_h.py:19] end concat_expert_out cost 5.7697296142578125e-05 seconds
DEBUG 01-15 10:09:20.613886.613886 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.613578.613578 cuda_h.py:19] end index_scatter cost 5.1975250244140625e-05 seconds
DEBUG 01-15 10:09:20.614340.614340 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006968975067138672 seconds
DEBUG 01-15 10:09:20.614403.614403 cuda_h.py:19] end gpu_experts cost 0.0020987987518310547 seconds
DEBUG 01-15 10:09:20.614604.614604 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.0570528507232666 seconds
DEBUG 01-15 10:09:20.614704.614704 cuda_h.py:19] end prefill_layer cost 0.06280994415283203 seconds
DEBUG 01-15 10:09:20.614156.614156 lmp.py:1552] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-15 10:09:20.614098.614098 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.614807.614807 lmp.py:1495] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-15 10:09:20.614941.614941 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:20.614220.614220 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:20.614785.614785 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.6716461181640625e-05 seconds
DEBUG 01-15 10:09:20.614064.614064 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:20.614336.614336 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.614737.614737 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.615283.615283 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.615312.615312 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.615202.615202 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.615636.615636 cuda_h.py:19] end allocate_cuda_memory cost 0.0002818107604980469 seconds
DEBUG 01-15 10:09:20.615089.615089 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.615475.615475 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.615589.615589 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.615630.615630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a7de5ff5-dd4e-4564-a6a7-0cadbc72764f
DEBUG 01-15 10:09:20.615428.615428 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.616093.616093 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.616478.616478 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a7de5ff5-dd4e-4564-a6a7-0cadbc72764f
DEBUG 01-15 10:09:20.616328.616328 cuda_h.py:19] end load_into_gpu_async cost 0.0009441375732421875 seconds
DEBUG 01-15 10:09:20.616368.616368 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.616869.616869 cuda_h.py:19] end restore_tensors2 cost 9.226799011230469e-05 seconds
DEBUG 01-15 10:09:20.616870.616870 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016064643859863281 seconds
INFO 01-15 10:09:20.616111.616111 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a7de5ff5-dd4e-4564-a6a7-0cadbc72764f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.620985.620985 cuda_h.py:19] end self_attn cost 0.003815174102783203 seconds
DEBUG 01-15 10:09:20.620730.620730 cuda_h.py:19] end iln_self_attn_paln cost 0.005383014678955078 seconds
DEBUG 01-15 10:09:20.620619.620619 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-15 10:09:20.620680.620680 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.621796.621796 cuda_h.py:19] end gate cost 0.0006480216979980469 seconds
DEBUG 01-15 10:09:20.621963.621963 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.621125.621125 lmp.py:1616] 
DEBUG 01-15 10:09:20.621125.621125 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.621266.621266 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.621584.621584 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.621850.621850 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.621493.621493 lmp.py:1620] 
DEBUG 01-15 10:09:20.621493.621493 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.621851.621851 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.621163.621163 lmp.py:1626]   Expert  4 |      9 | CPU
DEBUG 01-15 10:09:20.621044.621044 lmp.py:1626]   Expert 28 |     27 | CPU
DEBUG 01-15 10:09:20.621687.621687 lmp.py:1626]   Expert  7 |     47 | CPU
DEBUG 01-15 10:09:20.621046.621046 lmp.py:1626]   Expert 53 |     58 | CPU
DEBUG 01-15 10:09:20.621404.621404 lmp.py:1626]   Expert 43 |     69 | CPU
DEBUG 01-15 10:09:20.621047.621047 lmp.py:1626]   Expert 52 |     69 | CPU
DEBUG 01-15 10:09:20.621167.621167 lmp.py:1626]   Expert 49 |     81 | CPU
DEBUG 01-15 10:09:20.621571.621571 lmp.py:1626]   Expert 12 |     89 | CPU
DEBUG 01-15 10:09:20.621737.621737 lmp.py:1626]   Expert 47 |    101 | CPU
DEBUG 01-15 10:09:20.621903.621903 lmp.py:1626]   Expert 24 |    104 | CPU
DEBUG 01-15 10:09:20.621831.621831 lmp.py:1626]   Expert 33 |    108 | CPU
DEBUG 01-15 10:09:20.621997.621997 lmp.py:1626]   Expert  2 |    110 | CPU
DEBUG 01-15 10:09:20.621163.621163 lmp.py:1626]   Expert 50 |    110 | CPU
DEBUG 01-15 10:09:20.621330.621330 lmp.py:1626]   Expert 15 |    112 | CPU
DEBUG 01-15 10:09:20.621019.621019 lmp.py:1626]   Expert 39 |    113 | CPU
DEBUG 01-15 10:09:20.621662.621662 lmp.py:1626]   Expert 60 |    113 | CPU
DEBUG 01-15 10:09:20.621066.621066 lmp.py:1626]   Expert 36 |    120 | CPU
DEBUG 01-15 10:09:20.621948.621948 lmp.py:1626]   Expert 25 |    124 | CPU
DEBUG 01-15 10:09:20.621591.621591 lmp.py:1626]   Expert  6 |    126 | CPU
DEBUG 01-15 10:09:20.621711.621711 lmp.py:1626]   Expert 61 |    132 | CPU
DEBUG 01-15 10:09:20.621354.621354 lmp.py:1626]   Expert 59 |    135 | CPU
DEBUG 01-15 10:09:20.621520.621520 lmp.py:1626]   Expert  3 |    141 | CPU
DEBUG 01-15 10:09:20.621447.621447 lmp.py:1626]   Expert 58 |    143 | CPU
DEBUG 01-15 10:09:20.621613.621613 lmp.py:1626]   Expert 27 |    144 | CPU
DEBUG 01-15 10:09:20.621541.621541 lmp.py:1626]   Expert  8 |    150 | CPU
DEBUG 01-15 10:09:20.622707.622707 lmp.py:1626]   Expert 30 |    150 | CPU
DEBUG 01-15 10:09:20.622635.622635 lmp.py:1626]   Expert 31 |    150 | CPU
DEBUG 01-15 10:09:20.622278.622278 lmp.py:1626]   Expert 10 |    156 | CPU
DEBUG 01-15 10:09:20.622398.622398 lmp.py:1626]   Expert 38 |    158 | CPU
DEBUG 01-15 10:09:20.622802.622802 lmp.py:1626]   Expert 40 |    158 | CPU
DEBUG 01-15 10:09:20.622684.622684 lmp.py:1626]   Expert 41 |    159 | CPU
DEBUG 01-15 10:09:20.622327.622327 lmp.py:1626]   Expert 57 |    161 | CPU
DEBUG 01-15 10:09:20.622016.622016 lmp.py:1626]   Expert 14 |    162 | GPU
DEBUG 01-15 10:09:20.622944.622944 lmp.py:1626]   Expert 37 |    162 | GPU
DEBUG 01-15 10:09:20.622872.622872 lmp.py:1626]   Expert 54 |    165 | GPU
DEBUG 01-15 10:09:20.622322.622322 lmp.py:1626]   Expert 32 |    166 | GPU
DEBUG 01-15 10:09:20.622012.622012 lmp.py:1626]   Expert 46 |    168 | GPU
DEBUG 01-15 10:09:20.622939.622939 lmp.py:1626]   Expert 42 |    173 | GPU
DEBUG 01-15 10:09:20.622629.622629 lmp.py:1626]   Expert 19 |    176 | GPU
DEBUG 01-15 10:09:20.622556.622556 lmp.py:1626]   Expert 11 |    181 | GPU
DEBUG 01-15 10:09:20.622961.622961 lmp.py:1626]   Expert 18 |    192 | GPU
DEBUG 01-15 10:09:20.622366.622366 lmp.py:1626]   Expert 34 |    193 | GPU
DEBUG 01-15 10:09:20.622770.622770 lmp.py:1626]   Expert 22 |    194 | GPU
DEBUG 01-15 10:09:20.622936.622936 lmp.py:1626]   Expert 26 |    194 | GPU
DEBUG 01-15 10:09:20.622626.622626 lmp.py:1626]   Expert 56 |    198 | GPU
DEBUG 01-15 10:09:20.622315.622315 lmp.py:1626]   Expert  0 |    200 | GPU
DEBUG 01-15 10:09:20.622004.622004 lmp.py:1626]   Expert  1 |    203 | GPU
DEBUG 01-15 10:09:20.622170.622170 lmp.py:1626]   Expert 44 |    204 | GPU
DEBUG 01-15 10:09:20.622098.622098 lmp.py:1626]   Expert 51 |    213 | GPU
DEBUG 01-15 10:09:20.622026.622026 lmp.py:1626]   Expert 20 |    225 | GPU
DEBUG 01-15 10:09:20.622953.622953 lmp.py:1626]   Expert 29 |    231 | GPU
DEBUG 01-15 10:09:20.622881.622881 lmp.py:1626]   Expert 48 |    235 | GPU
DEBUG 01-15 10:09:20.622286.622286 lmp.py:1626]   Expert 21 |    243 | GPU
DEBUG 01-15 10:09:20.622737.622737 lmp.py:1626]   Expert 45 |    243 | GPU
DEBUG 01-15 10:09:20.622664.622664 lmp.py:1626]   Expert 35 |    251 | GPU
DEBUG 01-15 10:09:20.622354.622354 lmp.py:1626]   Expert 55 |    252 | GPU
DEBUG 01-15 10:09:20.622281.622281 lmp.py:1626]   Expert 16 |    253 | GPU
DEBUG 01-15 10:09:20.622447.622447 lmp.py:1626]   Expert  5 |    294 | GPU
DEBUG 01-15 10:09:20.622852.622852 lmp.py:1626]   Expert 23 |    375 | GPU
DEBUG 01-15 10:09:20.622257.622257 lmp.py:1626]   Expert 13 |    384 | GPU
DEBUG 01-15 10:09:20.622900.622900 lmp.py:1626]   Expert 17 |    433 | GPU
DEBUG 01-15 10:09:20.622827.622827 lmp.py:1626]   Expert  9 |    457 | GPU
DEBUG 01-15 10:09:20.622517.622517 lmp.py:1626]   Expert 63 |    464 | GPU
DEBUG 01-15 10:09:20.622967.622967 lmp.py:1626]   Expert 62 |   1177 | GPU
DEBUG 01-15 10:09:20.622372.622372 lmp.py:1627] 
DEBUG 01-15 10:09:20.622372.622372 lmp.py:1627]   CPU total tokens: 3627 (29.5%)
DEBUG 01-15 10:09:20.622253.622253 lmp.py:1628]   GPU total tokens: 8661 (70.5%)
DEBUG 01-15 10:09:20.622950.622950 cuda_h.py:19] end experts_map_get cost 0.0015416145324707031 seconds
DEBUG 01-15 10:09:20.622369.622369 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.622694.622694 lmp.py:1636] 
DEBUG 01-15 10:09:20.622694.622694 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.622723.622723 cuda_h.py:19] end cpu_experts_submit cost 5.507469177246094e-05 seconds
DEBUG 01-15 10:09:20.622273.622273 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.622202.622202 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.623174.623174 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.623520.623520 cuda_h.py:19] end allocate_cuda_memory cost 0.00022101402282714844 seconds
DEBUG 01-15 10:09:20.623684.623684 cuda_h.py:10] start load_into_gpu_async
INFO 01-15 10:09:20.623250.623250 client.py:127] Model loaded
DEBUG 01-15 10:09:20.623915.623915 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.623598.623598 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.623267.623267 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.624167.624167 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.623567.623567 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.624842.624842 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 75db2b6b-f147-474d-92a3-cd431883675a
DEBUG 01-15 10:09:20.624233.624233 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.624003.624003 cuda_h.py:19] end restore2model cost 0.0007259845733642578 seconds
DEBUG 01-15 10:09:20.624071.624071 cuda_h.py:19] end sllm_worker_task cost 0.009627103805541992 seconds
DEBUG 01-15 10:09:20.624866.624866 cuda_h.py:19] end move_flatidxs cost 0.0008461475372314453 seconds
DEBUG 01-15 10:09:20.625411.625411 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:20.625623.625623 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 75db2b6b-f147-474d-92a3-cd431883675a
DEBUG 01-15 10:09:20.625936.625936 cuda_h.py:19] end load_into_gpu_async cost 0.0014226436614990234 seconds
DEBUG 01-15 10:09:20.625937.625937 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.625002.625002 cuda_h.py:19] end restore_tensors2 cost 0.0003371238708496094 seconds
DEBUG 01-15 10:09:20.625785.625785 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027589797973632812 seconds
DEBUG 01-15 10:09:20.625555.625555 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.628009.628009 cuda_h.py:19] end restore2model cost 0.0024480819702148438 seconds
DEBUG 01-15 10:09:20.628991.628991 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005387783050537109 seconds
DEBUG 01-15 10:09:20.628548.628548 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.628929.628929 cuda_h.py:19] end gpu_sexperts cost 0.00028514862060546875 seconds
DEBUG 01-15 10:09:20.628712.628712 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.630989.630989 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015017986297607422 seconds
DEBUG 01-15 10:09:20.630565.630565 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.631312.631312 cuda_h.py:19] end gpu_group_list cost 0.0003261566162109375 seconds
DEBUG 01-15 10:09:20.631376.631376 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.632394.632394 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007116794586181641 seconds
DEBUG 01-15 10:09:20.632502.632502 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.632086.632086 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-15 10:09:20.632021.632021 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.634284.634284 cuda_h.py:19] end group_tensors cost 0.009021520614624023 seconds
DEBUG 01-15 10:09:20.634549.634549 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.638490.638490 cuda_h.py:19] end group pad cost 0.0037317276000976562 seconds
DEBUG 01-15 10:09:20.638426.638426 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.657243.657243 cuda_h.py:19] end group_einsum cost 0.018558979034423828 seconds
DEBUG 01-15 10:09:20.657758.657758 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.661469.661469 cuda_h.py:19] end get_outputs_cpu1 cost 0.004347324371337891 seconds
DEBUG 01-15 10:09:20.662828.662828 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03882431983947754 seconds
DEBUG 01-15 10:09:20.663688.663688 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031158924102783203 seconds
DEBUG 01-15 10:09:20.663348.663348 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.663655.663655 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.664097.664097 cuda_h.py:19] end index_scatter cost 8.630752563476562e-05 seconds
DEBUG 01-15 10:09:20.664383.664383 cuda_h.py:19] end cpuoutputsdeal cost 0.0007901191711425781 seconds
DEBUG 01-15 10:09:20.664789.664789 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.664797.664797 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 75db2b6b-f147-474d-92a3-cd431883675a
INFO 01-15 10:09:20.674705.674705 client.py:127] Model loaded
DEBUG 01-15 10:09:20.675641.675641 cuda_h.py:19] end wait_experts cost 0.010391950607299805 seconds
DEBUG 01-15 10:09:20.675867.675867 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.675326.675326 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.675506.675506 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.675757.675757 cuda_h.py:19] end gpu_group_tensor cost 0.0001583099365234375 seconds
DEBUG 01-15 10:09:20.675092.675092 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.676113.676113 cuda_h.py:19] end gpu_group_einsum cost 0.0011916160583496094 seconds
DEBUG 01-15 10:09:20.676170.676170 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.676523.676523 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.677610.677610 cuda_h.py:19] end all_expert_outputs_slices cost 0.00021123886108398438 seconds
DEBUG 01-15 10:09:20.677320.677320 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.677343.677343 cuda_h.py:19] end concat_expert_out cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:20.677855.677855 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.677183.677183 cuda_h.py:19] end index_scatter cost 6.723403930664062e-05 seconds
DEBUG 01-15 10:09:20.677277.677277 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005664825439453125 seconds
DEBUG 01-15 10:09:20.677517.677517 cuda_h.py:19] end gpu_experts cost 0.002386808395385742 seconds
DEBUG 01-15 10:09:20.677858.677858 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.05712294578552246 seconds
DEBUG 01-15 10:09:20.677472.677472 cuda_h.py:19] end prefill_layer cost 0.06316494941711426 seconds
DEBUG 01-15 10:09:20.677209.677209 lmp.py:1552] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-15 10:09:20.677382.677382 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.677031.677031 lmp.py:1495] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-15 10:09:20.677112.677112 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:20.678338.678338 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:20.678982.678982 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.9325485229492188e-05 seconds
DEBUG 01-15 10:09:20.678778.678778 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.6743621826171875e-05 seconds
DEBUG 01-15 10:09:20.678520.678520 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.678390.678390 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.678564.678564 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.678429.678429 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.678119.678119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.678161.678161 cuda_h.py:19] end allocate_cuda_memory cost 0.0002071857452392578 seconds
DEBUG 01-15 10:09:20.678964.678964 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.678959.678959 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.678682.678682 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.678882.678882 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb143c3d-1462-4ebd-ab0d-9e7d600c4e00
DEBUG 01-15 10:09:20.678852.678852 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.679244.679244 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.679720.679720 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb143c3d-1462-4ebd-ab0d-9e7d600c4e00
DEBUG 01-15 10:09:20.679265.679265 cuda_h.py:19] end load_into_gpu_async cost 0.001032114028930664 seconds
DEBUG 01-15 10:09:20.679868.679868 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.679004.679004 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-15 10:09:20.679045.679045 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001547098159790039 seconds
INFO 01-15 10:09:20.679576.679576 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb143c3d-1462-4ebd-ab0d-9e7d600c4e00
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.684434.684434 cuda_h.py:19] end self_attn cost 0.005194664001464844 seconds
DEBUG 01-15 10:09:20.684675.684675 cuda_h.py:19] end iln_self_attn_paln cost 0.006577491760253906 seconds
DEBUG 01-15 10:09:20.684703.684703 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-15 10:09:20.684320.684320 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.685105.685105 cuda_h.py:19] end gate cost 0.0006511211395263672 seconds
DEBUG 01-15 10:09:20.685981.685981 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.685627.685627 lmp.py:1616] 
DEBUG 01-15 10:09:20.685627.685627 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.685482.685482 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.685085.685085 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.685874.685874 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.685756.685756 lmp.py:1620] 
DEBUG 01-15 10:09:20.685756.685756 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.685352.685352 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.685426.685426 lmp.py:1626]   Expert 32 |     33 | CPU
DEBUG 01-15 10:09:20.686830.686830 lmp.py:1626]   Expert 30 |     51 | CPU
DEBUG 01-15 10:09:20.686043.686043 lmp.py:1626]   Expert  5 |     54 | CPU
DEBUG 01-15 10:09:20.686970.686970 lmp.py:1626]   Expert 46 |     74 | CPU
DEBUG 01-15 10:09:20.686382.686382 lmp.py:1626]   Expert  8 |     88 | CPU
DEBUG 01-15 10:09:20.686786.686786 lmp.py:1626]   Expert 40 |     89 | CPU
DEBUG 01-15 10:09:20.686906.686906 lmp.py:1626]   Expert 12 |    101 | CPU
DEBUG 01-15 10:09:20.686072.686072 lmp.py:1626]   Expert 17 |    104 | CPU
DEBUG 01-15 10:09:20.686477.686477 lmp.py:1626]   Expert 27 |    112 | CPU
DEBUG 01-15 10:09:20.686405.686405 lmp.py:1626]   Expert  3 |    114 | CPU
DEBUG 01-15 10:09:20.686617.686617 lmp.py:1626]   Expert 60 |    115 | CPU
DEBUG 01-15 10:09:20.686830.686830 lmp.py:1626]   Expert 58 |    116 | CPU
DEBUG 01-15 10:09:20.686280.686280 lmp.py:1626]   Expert 21 |    118 | CPU
DEBUG 01-15 10:09:20.686016.686016 lmp.py:1626]   Expert 29 |    120 | CPU
DEBUG 01-15 10:09:20.686228.686228 lmp.py:1626]   Expert 28 |    121 | CPU
DEBUG 01-15 10:09:20.686203.686203 lmp.py:1626]   Expert 25 |    123 | CPU
DEBUG 01-15 10:09:20.686660.686660 lmp.py:1626]   Expert 41 |    127 | CPU
DEBUG 01-15 10:09:20.686972.686972 lmp.py:1626]   Expert 35 |    133 | CPU
DEBUG 01-15 10:09:20.686377.686377 lmp.py:1626]   Expert 19 |    134 | CPU
DEBUG 01-15 10:09:20.686781.686781 lmp.py:1626]   Expert  0 |    146 | CPU
DEBUG 01-15 10:09:20.686709.686709 lmp.py:1626]   Expert  6 |    146 | CPU
DEBUG 01-15 10:09:20.686398.686398 lmp.py:1626]   Expert 52 |    146 | CPU
DEBUG 01-15 10:09:20.686088.686088 lmp.py:1626]   Expert 54 |    149 | CPU
DEBUG 01-15 10:09:20.686015.686015 lmp.py:1626]   Expert 56 |    150 | CPU
DEBUG 01-15 10:09:20.686466.686466 lmp.py:1626]   Expert 37 |    153 | CPU
DEBUG 01-15 10:09:20.686440.686440 lmp.py:1626]   Expert 48 |    155 | CPU
DEBUG 01-15 10:09:20.686653.686653 lmp.py:1626]   Expert 63 |    156 | CPU
DEBUG 01-15 10:09:20.686388.686388 lmp.py:1626]   Expert 53 |    158 | CPU
DEBUG 01-15 10:09:20.686700.686700 lmp.py:1626]   Expert 36 |    162 | CPU
DEBUG 01-15 10:09:20.686204.686204 lmp.py:1626]   Expert 59 |    169 | CPU
DEBUG 01-15 10:09:20.686278.686278 lmp.py:1626]   Expert  9 |    180 | CPU
DEBUG 01-15 10:09:20.686874.686874 lmp.py:1626]   Expert  1 |    186 | CPU
DEBUG 01-15 10:09:20.686233.686233 lmp.py:1626]   Expert 39 |    195 | GPU
DEBUG 01-15 10:09:20.686114.686114 lmp.py:1626]   Expert 20 |    197 | GPU
DEBUG 01-15 10:09:20.686757.686757 lmp.py:1626]   Expert 61 |    202 | GPU
DEBUG 01-15 10:09:20.686161.686161 lmp.py:1626]   Expert 42 |    204 | GPU
DEBUG 01-15 10:09:20.686328.686328 lmp.py:1626]   Expert 43 |    204 | GPU
DEBUG 01-15 10:09:20.686255.686255 lmp.py:1626]   Expert  7 |    205 | GPU
DEBUG 01-15 10:09:20.686660.686660 lmp.py:1626]   Expert 11 |    206 | GPU
DEBUG 01-15 10:09:20.686826.686826 lmp.py:1626]   Expert 34 |    207 | GPU
DEBUG 01-15 10:09:20.686515.686515 lmp.py:1626]   Expert 47 |    207 | GPU
DEBUG 01-15 10:09:20.686920.686920 lmp.py:1626]   Expert 55 |    214 | GPU
DEBUG 01-15 10:09:20.686848.686848 lmp.py:1626]   Expert 57 |    222 | GPU
DEBUG 01-15 10:09:20.686775.686775 lmp.py:1626]   Expert 13 |    223 | GPU
DEBUG 01-15 10:09:20.686233.686233 lmp.py:1626]   Expert 16 |    225 | GPU
DEBUG 01-15 10:09:20.686975.686975 lmp.py:1626]   Expert 18 |    230 | GPU
DEBUG 01-15 10:09:20.686857.686857 lmp.py:1626]   Expert 15 |    235 | GPU
DEBUG 01-15 10:09:20.686314.686314 lmp.py:1626]   Expert  4 |    238 | GPU
DEBUG 01-15 10:09:20.686004.686004 lmp.py:1626]   Expert 22 |    246 | GPU
DEBUG 01-15 10:09:20.686647.686647 lmp.py:1626]   Expert 33 |    247 | GPU
DEBUG 01-15 10:09:20.686813.686813 lmp.py:1626]   Expert 45 |    248 | GPU
DEBUG 01-15 10:09:20.686741.686741 lmp.py:1626]   Expert 50 |    248 | GPU
DEBUG 01-15 10:09:20.686907.686907 lmp.py:1626]   Expert 31 |    252 | GPU
DEBUG 01-15 10:09:20.686834.686834 lmp.py:1626]   Expert 51 |    254 | GPU
DEBUG 01-15 10:09:20.686285.686285 lmp.py:1626]   Expert 49 |    268 | GPU
DEBUG 01-15 10:09:20.686975.686975 lmp.py:1626]   Expert 38 |    275 | GPU
DEBUG 01-15 10:09:20.686194.686194 lmp.py:1626]   Expert 26 |    279 | GPU
DEBUG 01-15 10:09:20.686075.686075 lmp.py:1626]   Expert 10 |    285 | GPU
DEBUG 01-15 10:09:20.687765.687765 lmp.py:1626]   Expert 44 |    295 | GPU
DEBUG 01-15 10:09:20.687938.687938 lmp.py:1626]   Expert  2 |    300 | GPU
DEBUG 01-15 10:09:20.687865.687865 lmp.py:1626]   Expert 24 |    306 | GPU
DEBUG 01-15 10:09:20.687568.687568 lmp.py:1626]   Expert 14 |    313 | GPU
DEBUG 01-15 10:09:20.687211.687211 lmp.py:1626]   Expert 23 |    403 | GPU
DEBUG 01-15 10:09:20.687092.687092 lmp.py:1626]   Expert 62 |    672 | GPU
DEBUG 01-15 10:09:20.687166.687166 lmp.py:1627] 
DEBUG 01-15 10:09:20.687166.687166 lmp.py:1627]   CPU total tokens: 3983 (32.4%)
DEBUG 01-15 10:09:20.687809.687809 lmp.py:1628]   GPU total tokens: 8305 (67.6%)
DEBUG 01-15 10:09:20.687982.687982 cuda_h.py:19] end experts_map_get cost 0.0015876293182373047 seconds
INFO 01-15 10:09:20.687461.687461 client.py:127] Model loaded
DEBUG 01-15 10:09:20.687212.687212 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.687235.687235 cuda_h.py:19] end restore2model cost 0.0004673004150390625 seconds
DEBUG 01-15 10:09:20.687588.687588 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.687212.687212 cuda_h.py:19] end sllm_worker_task cost 0.009534835815429688 seconds
DEBUG 01-15 10:09:20.687532.687532 lmp.py:1636] 
DEBUG 01-15 10:09:20.687532.687532 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.688979.688979 cuda_h.py:19] end cpu_experts_submit cost 0.0001232624053955078 seconds
DEBUG 01-15 10:09:20.688013.688013 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.688942.688942 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.688259.688259 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.688009.688009 cuda_h.py:19] end allocate_cuda_memory cost 0.0001995563507080078 seconds
DEBUG 01-15 10:09:20.688613.688613 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.688177.688177 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.688684.688684 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.689567.689567 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81d34548-6d60-4975-8edf-9b35772f21b4
DEBUG 01-15 10:09:20.689461.689461 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.689157.689157 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.689236.689236 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:20.690206.690206 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81d34548-6d60-4975-8edf-9b35772f21b4
DEBUG 01-15 10:09:20.690897.690897 cuda_h.py:19] end load_into_gpu_async cost 0.0015115737915039062 seconds
DEBUG 01-15 10:09:20.690123.690123 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.690221.690221 cuda_h.py:19] end move_flatidxs cost 0.0008685588836669922 seconds
DEBUG 01-15 10:09:20.690634.690634 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.690334.690334 cuda_h.py:19] end restore_tensors2 cost 0.0003387928009033203 seconds
DEBUG 01-15 10:09:20.690362.690362 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024254322052001953 seconds
DEBUG 01-15 10:09:20.690178.690178 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.693115.693115 cuda_h.py:19] end restore2model cost 0.0024521350860595703 seconds
DEBUG 01-15 10:09:20.693382.693382 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005059003829956055 seconds
DEBUG 01-15 10:09:20.693224.693224 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.693902.693902 cuda_h.py:19] end gpu_sexperts cost 0.0002601146697998047 seconds
DEBUG 01-15 10:09:20.693348.693348 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.695770.695770 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015041828155517578 seconds
DEBUG 01-15 10:09:20.695478.695478 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.696901.696901 cuda_h.py:19] end gpu_group_list cost 0.00032591819763183594 seconds
DEBUG 01-15 10:09:20.696303.696303 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.696146.696146 cuda_h.py:19] end group_tensors cost 0.005942821502685547 seconds
DEBUG 01-15 10:09:20.697501.697501 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007252693176269531 seconds
DEBUG 01-15 10:09:20.697137.697137 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.697277.697277 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.697716.697716 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-15 10:09:20.697220.697220 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.700565.700565 cuda_h.py:19] end group pad cost 0.003633737564086914 seconds
DEBUG 01-15 10:09:20.700547.700547 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.720577.720577 cuda_h.py:19] end group_einsum cost 0.01959848403930664 seconds
DEBUG 01-15 10:09:20.720755.720755 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.725130.725130 cuda_h.py:19] end get_outputs_cpu1 cost 0.004800558090209961 seconds
DEBUG 01-15 10:09:20.726601.726601 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03711652755737305 seconds
DEBUG 01-15 10:09:20.727698.727698 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03001117706298828 seconds
DEBUG 01-15 10:09:20.727698.727698 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.728781.728781 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.728022.728022 cuda_h.py:19] end index_scatter cost 0.0001659393310546875 seconds
DEBUG 01-15 10:09:20.729337.729337 cuda_h.py:19] end cpuoutputsdeal cost 0.0017499923706054688 seconds
DEBUG 01-15 10:09:20.729382.729382 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.729065.729065 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81d34548-6d60-4975-8edf-9b35772f21b4
INFO 01-15 10:09:20.740635.740635 client.py:127] Model loaded
DEBUG 01-15 10:09:20.740897.740897 cuda_h.py:19] end wait_experts cost 0.011187076568603516 seconds
DEBUG 01-15 10:09:20.740798.740798 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.740940.740940 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.740411.740411 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.741930.741930 cuda_h.py:19] end gpu_group_tensor cost 0.00024366378784179688 seconds
DEBUG 01-15 10:09:20.741060.741060 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.741529.741529 cuda_h.py:19] end gpu_group_einsum cost 0.0005054473876953125 seconds
DEBUG 01-15 10:09:20.742354.742354 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.742191.742191 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.742796.742796 cuda_h.py:19] end all_expert_outputs_slices cost 0.00023889541625976562 seconds
DEBUG 01-15 10:09:20.742982.742982 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.742919.742919 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-15 10:09:20.742538.742538 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.742395.742395 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:20.742681.742681 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006196498870849609 seconds
DEBUG 01-15 10:09:20.742598.742598 cuda_h.py:19] end gpu_experts cost 0.0018966197967529297 seconds
DEBUG 01-15 10:09:20.742806.742806 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.058014631271362305 seconds
DEBUG 01-15 10:09:20.743740.743740 cuda_h.py:19] end prefill_layer cost 0.06526446342468262 seconds
DEBUG 01-15 10:09:20.743245.743245 lmp.py:1552] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-15 10:09:20.743663.743663 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.743128.743128 lmp.py:1495] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-15 10:09:20.743023.743023 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:20.743587.743587 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:20.743576.743576 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.337860107421875e-05 seconds
DEBUG 01-15 10:09:20.743093.743093 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:20.743697.743697 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.743454.743454 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.743061.743061 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.743261.743261 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.743391.743391 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.744687.744687 cuda_h.py:19] end allocate_cuda_memory cost 0.000286102294921875 seconds
DEBUG 01-15 10:09:20.744775.744775 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.744677.744677 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.744162.744162 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.744561.744561 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a100e7f5-8408-4de7-961e-c188357e4a8f
DEBUG 01-15 10:09:20.744861.744861 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.744652.744652 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.745071.745071 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a100e7f5-8408-4de7-961e-c188357e4a8f
DEBUG 01-15 10:09:20.745377.745377 cuda_h.py:19] end load_into_gpu_async cost 0.0009377002716064453 seconds
DEBUG 01-15 10:09:20.745981.745981 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.745554.745554 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-15 10:09:20.745833.745833 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015418529510498047 seconds
INFO 01-15 10:09:20.745172.745172 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a100e7f5-8408-4de7-961e-c188357e4a8f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.748756.748756 cuda_h.py:19] end self_attn cost 0.003838062286376953 seconds
DEBUG 01-15 10:09:20.748898.748898 cuda_h.py:19] end iln_self_attn_paln cost 0.0053822994232177734 seconds
DEBUG 01-15 10:09:20.748165.748165 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-15 10:09:20.749020.749020 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.749400.749400 cuda_h.py:19] end gate cost 0.0006334781646728516 seconds
DEBUG 01-15 10:09:20.749084.749084 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.750352.750352 lmp.py:1616] 
DEBUG 01-15 10:09:20.750352.750352 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.750062.750062 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.750904.750904 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.750408.750408 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.750527.750527 lmp.py:1620] 
DEBUG 01-15 10:09:20.750527.750527 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.750601.750601 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.750151.750151 lmp.py:1626]   Expert 44 |     41 | CPU
DEBUG 01-15 10:09:20.750033.750033 lmp.py:1626]   Expert  1 |     48 | CPU
DEBUG 01-15 10:09:20.750437.750437 lmp.py:1626]   Expert 60 |     58 | CPU
DEBUG 01-15 10:09:20.750842.750842 lmp.py:1626]   Expert 28 |     70 | CPU
DEBUG 01-15 10:09:20.750008.750008 lmp.py:1626]   Expert 48 |     77 | CPU
DEBUG 01-15 10:09:20.750412.750412 lmp.py:1626]   Expert 27 |     84 | CPU
DEBUG 01-15 10:09:20.750579.750579 lmp.py:1626]   Expert  0 |     98 | CPU
DEBUG 01-15 10:09:20.750983.750983 lmp.py:1626]   Expert 62 |    108 | CPU
DEBUG 01-15 10:09:20.750149.750149 lmp.py:1626]   Expert 30 |    113 | CPU
DEBUG 01-15 10:09:20.750508.750508 lmp.py:1626]   Expert 42 |    113 | CPU
DEBUG 01-15 10:09:20.750389.750389 lmp.py:1626]   Expert 22 |    114 | CPU
DEBUG 01-15 10:09:20.750509.750509 lmp.py:1626]   Expert 59 |    115 | CPU
DEBUG 01-15 10:09:20.750390.750390 lmp.py:1626]   Expert 58 |    121 | CPU
DEBUG 01-15 10:09:20.750510.750510 lmp.py:1626]   Expert 16 |    124 | CPU
DEBUG 01-15 10:09:20.750676.750676 lmp.py:1626]   Expert 12 |    126 | CPU
DEBUG 01-15 10:09:20.750842.750842 lmp.py:1626]   Expert  8 |    129 | CPU
DEBUG 01-15 10:09:20.750008.750008 lmp.py:1626]   Expert 50 |    134 | CPU
DEBUG 01-15 10:09:20.750413.750413 lmp.py:1626]   Expert  5 |    141 | CPU
DEBUG 01-15 10:09:20.750102.750102 lmp.py:1626]   Expert 56 |    143 | CPU
DEBUG 01-15 10:09:20.750268.750268 lmp.py:1626]   Expert 15 |    151 | CPU
DEBUG 01-15 10:09:20.750719.750719 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:20.750031.750031 lmp.py:1626]   Expert 26 |    154 | CPU
DEBUG 01-15 10:09:20.750389.750389 lmp.py:1626]   Expert 57 |    155 | CPU
DEBUG 01-15 10:09:20.750271.750271 lmp.py:1626]   Expert 32 |    156 | CPU
DEBUG 01-15 10:09:20.750629.750629 lmp.py:1626]   Expert 34 |    159 | CPU
DEBUG 01-15 10:09:20.750510.750510 lmp.py:1626]   Expert 47 |    160 | CPU
DEBUG 01-15 10:09:20.750677.750677 lmp.py:1626]   Expert 24 |    161 | CPU
DEBUG 01-15 10:09:20.750843.750843 lmp.py:1626]   Expert  2 |    165 | CPU
DEBUG 01-15 10:09:20.750009.750009 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:20.750175.750175 lmp.py:1626]   Expert 40 |    170 | CPU
DEBUG 01-15 10:09:20.750341.750341 lmp.py:1626]   Expert  6 |    171 | CPU
DEBUG 01-15 10:09:20.750030.750030 lmp.py:1626]   Expert 18 |    172 | CPU
DEBUG 01-15 10:09:20.750197.750197 lmp.py:1626]   Expert 13 |    174 | GPU
DEBUG 01-15 10:09:20.750124.750124 lmp.py:1626]   Expert 41 |    174 | GPU
DEBUG 01-15 10:09:20.750052.750052 lmp.py:1626]   Expert 19 |    176 | GPU
DEBUG 01-15 10:09:20.750410.750410 lmp.py:1626]   Expert 54 |    176 | GPU
DEBUG 01-15 10:09:20.750768.750768 lmp.py:1626]   Expert  3 |    177 | GPU
DEBUG 01-15 10:09:20.750888.750888 lmp.py:1626]   Expert 20 |    183 | GPU
DEBUG 01-15 10:09:20.750008.750008 lmp.py:1626]   Expert 46 |    184 | GPU
DEBUG 01-15 10:09:20.750128.750128 lmp.py:1626]   Expert 37 |    185 | GPU
DEBUG 01-15 10:09:20.750771.750771 lmp.py:1626]   Expert 25 |    191 | GPU
DEBUG 01-15 10:09:20.750175.750175 lmp.py:1626]   Expert 51 |    195 | GPU
DEBUG 01-15 10:09:20.750342.750342 lmp.py:1626]   Expert 43 |    199 | GPU
DEBUG 01-15 10:09:20.750746.750746 lmp.py:1626]   Expert 17 |    202 | GPU
DEBUG 01-15 10:09:20.750674.750674 lmp.py:1626]   Expert 31 |    203 | GPU
DEBUG 01-15 10:09:20.750840.750840 lmp.py:1626]   Expert 11 |    204 | GPU
DEBUG 01-15 10:09:20.750006.750006 lmp.py:1626]   Expert 35 |    207 | GPU
DEBUG 01-15 10:09:20.751887.751887 lmp.py:1626]   Expert 23 |    211 | GPU
DEBUG 01-15 10:09:20.751246.751246 lmp.py:1626]   Expert 49 |    220 | GPU
DEBUG 01-15 10:09:20.751366.751366 lmp.py:1626]   Expert 39 |    221 | GPU
DEBUG 01-15 10:09:20.751009.751009 lmp.py:1626]   Expert 53 |    231 | GPU
DEBUG 01-15 10:09:20.751890.751890 lmp.py:1626]   Expert 10 |    232 | GPU
DEBUG 01-15 10:09:20.751056.751056 lmp.py:1626]   Expert 33 |    247 | GPU
DEBUG 01-15 10:09:20.751461.751461 lmp.py:1626]   Expert 36 |    265 | GPU
DEBUG 01-15 10:09:20.751627.751627 lmp.py:1626]   Expert 38 |    268 | GPU
DEBUG 01-15 10:09:20.751554.751554 lmp.py:1626]   Expert  4 |    305 | GPU
DEBUG 01-15 10:09:20.751482.751482 lmp.py:1626]   Expert 21 |    336 | GPU
DEBUG 01-15 10:09:20.751171.751171 lmp.py:1626]   Expert 14 |    347 | GPU
DEBUG 01-15 10:09:20.751338.751338 lmp.py:1626]   Expert 63 |    370 | GPU
DEBUG 01-15 10:09:20.751457.751457 lmp.py:1626]   Expert 45 |    373 | GPU
DEBUG 01-15 10:09:20.751862.751862 lmp.py:1626]   Expert  9 |    390 | GPU
DEBUG 01-15 10:09:20.751267.751267 lmp.py:1626]   Expert 61 |    390 | GPU
DEBUG 01-15 10:09:20.751671.751671 lmp.py:1626]   Expert 29 |    488 | GPU
DEBUG 01-15 10:09:20.751552.751552 lmp.py:1626]   Expert  7 |    514 | GPU
DEBUG 01-15 10:09:20.751672.751672 lmp.py:1627] 
DEBUG 01-15 10:09:20.751672.751672 lmp.py:1627]   CPU total tokens: 4050 (33.0%)
DEBUG 01-15 10:09:20.751554.751554 lmp.py:1628]   GPU total tokens: 8238 (67.0%)
DEBUG 01-15 10:09:20.751727.751727 cuda_h.py:19] end experts_map_get cost 0.0015692710876464844 seconds
DEBUG 01-15 10:09:20.751477.751477 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.751326.751326 lmp.py:1636] 
DEBUG 01-15 10:09:20.751326.751326 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.751208.751208 cuda_h.py:19] end cpu_experts_submit cost 5.2928924560546875e-05 seconds
DEBUG 01-15 10:09:20.751997.751997 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.751542.751542 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.751805.751805 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.751409.751409 cuda_h.py:19] end allocate_cuda_memory cost 0.00020074844360351562 seconds
DEBUG 01-15 10:09:20.752008.752008 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.752287.752287 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.752167.752167 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.752399.752399 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45b80391-72da-4e7e-b49e-c17107ddcddd
DEBUG 01-15 10:09:20.752956.752956 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:20.753041.753041 client.py:127] Model loaded
DEBUG 01-15 10:09:20.753937.753937 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.753338.753338 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.753702.753702 cuda_h.py:19] end restore2model cost 0.00045013427734375 seconds
DEBUG 01-15 10:09:20.753585.753585 cuda_h.py:19] end sllm_worker_task cost 0.009868860244750977 seconds
DEBUG 01-15 10:09:20.753662.753662 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:20.753768.753768 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45b80391-72da-4e7e-b49e-c17107ddcddd
DEBUG 01-15 10:09:20.753460.753460 cuda_h.py:19] end load_into_gpu_async cost 0.0017702579498291016 seconds
DEBUG 01-15 10:09:20.753752.753752 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.754145.754145 cuda_h.py:19] end restore_tensors2 cost 0.0004279613494873047 seconds
DEBUG 01-15 10:09:20.754571.754571 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002840757369995117 seconds
DEBUG 01-15 10:09:20.754639.754639 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.754056.754056 cuda_h.py:19] end move_flatidxs cost 0.001138448715209961 seconds
DEBUG 01-15 10:09:20.754126.754126 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.757273.757273 cuda_h.py:19] end restore2model cost 0.003272533416748047 seconds
DEBUG 01-15 10:09:20.757369.757369 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00632476806640625 seconds
DEBUG 01-15 10:09:20.757032.757032 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.758627.758627 cuda_h.py:19] end gpu_sexperts cost 0.00032973289489746094 seconds
DEBUG 01-15 10:09:20.758921.758921 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.760580.760580 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0018451213836669922 seconds
DEBUG 01-15 10:09:20.763191.763191 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.763785.763785 cuda_h.py:19] end gpu_group_list cost 0.00042176246643066406 seconds
DEBUG 01-15 10:09:20.763840.763840 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.764817.764817 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010492801666259766 seconds
DEBUG 01-15 10:09:20.764521.764521 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.765656.765656 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-15 10:09:20.765074.765074 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.766956.766956 cuda_h.py:19] end group_tensors cost 0.01104593276977539 seconds
DEBUG 01-15 10:09:20.767575.767575 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.771912.771912 cuda_h.py:19] end group pad cost 0.004221677780151367 seconds
DEBUG 01-15 10:09:20.771993.771993 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.792968.792968 cuda_h.py:19] end group_einsum cost 0.02031707763671875 seconds
DEBUG 01-15 10:09:20.792523.792523 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.797621.797621 cuda_h.py:19] end get_outputs_cpu1 cost 0.004629611968994141 seconds
DEBUG 01-15 10:09:20.797582.797582 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0445094108581543 seconds
DEBUG 01-15 10:09:20.798125.798125 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03368520736694336 seconds
DEBUG 01-15 10:09:20.798658.798658 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.799172.799172 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.799713.799713 cuda_h.py:19] end index_scatter cost 9.608268737792969e-05 seconds
DEBUG 01-15 10:09:20.800083.800083 cuda_h.py:19] end cpuoutputsdeal cost 0.0011873245239257812 seconds
DEBUG 01-15 10:09:20.800535.800535 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.800212.800212 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45b80391-72da-4e7e-b49e-c17107ddcddd
INFO 01-15 10:09:20.804720.804720 client.py:127] Model loaded
DEBUG 01-15 10:09:20.804854.804854 cuda_h.py:19] end wait_experts cost 0.003958940505981445 seconds
DEBUG 01-15 10:09:20.804418.804418 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.804858.804858 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.804329.804329 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.804222.804222 cuda_h.py:19] end gpu_group_tensor cost 0.000308990478515625 seconds
DEBUG 01-15 10:09:20.804299.804299 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.805982.805982 cuda_h.py:19] end gpu_group_einsum cost 0.0005981922149658203 seconds
DEBUG 01-15 10:09:20.805331.805331 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.805213.805213 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.805939.805939 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002923011779785156 seconds
DEBUG 01-15 10:09:20.805126.805126 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.806295.806295 cuda_h.py:19] end concat_expert_out cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:20.806138.806138 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.806545.806545 cuda_h.py:19] end index_scatter cost 5.555152893066406e-05 seconds
DEBUG 01-15 10:09:20.806592.806592 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006442070007324219 seconds
DEBUG 01-15 10:09:20.806323.806323 cuda_h.py:19] end gpu_experts cost 0.002080202102661133 seconds
DEBUG 01-15 10:09:20.806737.806737 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.057413578033447266 seconds
DEBUG 01-15 10:09:20.806581.806581 cuda_h.py:19] end prefill_layer cost 0.06356573104858398 seconds
DEBUG 01-15 10:09:20.806947.806947 lmp.py:1552] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-15 10:09:20.807365.807365 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.807022.807022 lmp.py:1495] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-15 10:09:20.807871.807871 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:20.807388.807388 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:20.807953.807953 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.6716461181640625e-05 seconds
DEBUG 01-15 10:09:20.807517.807517 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.961822509765625e-05 seconds
DEBUG 01-15 10:09:20.807405.807405 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.807878.807878 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.807883.807883 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.807235.807235 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.807770.807770 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.808783.808783 cuda_h.py:19] end allocate_cuda_memory cost 0.0003533363342285156 seconds
DEBUG 01-15 10:09:20.808767.808767 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.808298.808298 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.808849.808849 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.808128.808128 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24ff97e5-dcef-4989-8159-0978d9249e4f
DEBUG 01-15 10:09:20.808125.808125 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.808090.808090 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.809509.809509 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24ff97e5-dcef-4989-8159-0978d9249e4f
DEBUG 01-15 10:09:20.809962.809962 cuda_h.py:19] end load_into_gpu_async cost 0.0010499954223632812 seconds
DEBUG 01-15 10:09:20.809341.809341 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.809583.809583 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-15 10:09:20.809008.809008 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017902851104736328 seconds
INFO 01-15 10:09:20.809374.809374 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24ff97e5-dcef-4989-8159-0978d9249e4f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.812963.812963 cuda_h.py:19] end self_attn cost 0.0032744407653808594 seconds
DEBUG 01-15 10:09:20.812378.812378 cuda_h.py:19] end iln_self_attn_paln cost 0.005072593688964844 seconds
DEBUG 01-15 10:09:20.812142.812142 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-15 10:09:20.812719.812719 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.813254.813254 cuda_h.py:19] end gate cost 0.0007123947143554688 seconds
DEBUG 01-15 10:09:20.813176.813176 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.813637.813637 lmp.py:1616] 
DEBUG 01-15 10:09:20.813637.813637 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.813585.813585 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.813519.813519 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.813593.813593 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.813905.813905 lmp.py:1620] 
DEBUG 01-15 10:09:20.813905.813905 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.813786.813786 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.813621.813621 lmp.py:1626]   Expert 54 |     21 | CPU
DEBUG 01-15 10:09:20.813264.813264 lmp.py:1626]   Expert  3 |     33 | CPU
DEBUG 01-15 10:09:20.813622.813622 lmp.py:1626]   Expert  8 |     43 | CPU
DEBUG 01-15 10:09:20.813027.813027 lmp.py:1626]   Expert 28 |     43 | CPU
DEBUG 01-15 10:09:20.813908.813908 lmp.py:1626]   Expert 43 |     54 | CPU
DEBUG 01-15 10:09:20.813313.813313 lmp.py:1626]   Expert 63 |     55 | CPU
DEBUG 01-15 10:09:20.813479.813479 lmp.py:1626]   Expert 36 |     75 | CPU
DEBUG 01-15 10:09:20.813930.813930 lmp.py:1626]   Expert 38 |     80 | CPU
DEBUG 01-15 10:09:20.813672.813672 lmp.py:1626]   Expert  6 |     83 | CPU
DEBUG 01-15 10:09:20.813792.813792 lmp.py:1626]   Expert 39 |     97 | CPU
DEBUG 01-15 10:09:20.813958.813958 lmp.py:1626]   Expert 57 |    100 | CPU
DEBUG 01-15 10:09:20.813363.813363 lmp.py:1626]   Expert 12 |    106 | CPU
DEBUG 01-15 10:09:20.813291.813291 lmp.py:1626]   Expert 41 |    106 | CPU
DEBUG 01-15 10:09:20.813887.813887 lmp.py:1626]   Expert 52 |    111 | CPU
DEBUG 01-15 10:09:20.813769.813769 lmp.py:1626]   Expert 19 |    121 | CPU
DEBUG 01-15 10:09:20.813696.813696 lmp.py:1626]   Expert 47 |    127 | CPU
DEBUG 01-15 10:09:20.813816.813816 lmp.py:1626]   Expert 13 |    132 | CPU
DEBUG 01-15 10:09:20.813697.813697 lmp.py:1626]   Expert 22 |    138 | CPU
DEBUG 01-15 10:09:20.813340.813340 lmp.py:1626]   Expert 46 |    143 | CPU
DEBUG 01-15 10:09:20.813222.813222 lmp.py:1626]   Expert 50 |    153 | CPU
DEBUG 01-15 10:09:20.814580.814580 lmp.py:1626]   Expert 40 |    162 | CPU
DEBUG 01-15 10:09:20.814938.814938 lmp.py:1626]   Expert 20 |    163 | CPU
DEBUG 01-15 10:09:20.814773.814773 lmp.py:1626]   Expert 24 |    163 | CPU
DEBUG 01-15 10:09:20.814940.814940 lmp.py:1626]   Expert 55 |    167 | CPU
DEBUG 01-15 10:09:20.814106.814106 lmp.py:1626]   Expert 37 |    168 | CPU
DEBUG 01-15 10:09:20.814272.814272 lmp.py:1626]   Expert 23 |    170 | CPU
DEBUG 01-15 10:09:20.814438.814438 lmp.py:1626]   Expert 53 |    173 | CPU
DEBUG 01-15 10:09:20.814988.814988 lmp.py:1626]   Expert  2 |    175 | CPU
DEBUG 01-15 10:09:20.814108.814108 lmp.py:1626]   Expert 21 |    177 | CPU
DEBUG 01-15 10:09:20.814989.814989 lmp.py:1626]   Expert 42 |    177 | CPU
DEBUG 01-15 10:09:20.814871.814871 lmp.py:1626]   Expert 49 |    177 | CPU
DEBUG 01-15 10:09:20.814514.814514 lmp.py:1626]   Expert 61 |    177 | CPU
DEBUG 01-15 10:09:20.814395.814395 lmp.py:1626]   Expert 18 |    190 | GPU
DEBUG 01-15 10:09:20.814992.814992 lmp.py:1626]   Expert 33 |    193 | GPU
DEBUG 01-15 10:09:20.814396.814396 lmp.py:1626]   Expert 32 |    197 | GPU
DEBUG 01-15 10:09:20.814563.814563 lmp.py:1626]   Expert  0 |    200 | GPU
DEBUG 01-15 10:09:20.814729.814729 lmp.py:1626]   Expert 16 |    202 | GPU
DEBUG 01-15 10:09:20.814895.814895 lmp.py:1626]   Expert 30 |    202 | GPU
DEBUG 01-15 10:09:20.814061.814061 lmp.py:1626]   Expert  5 |    203 | GPU
DEBUG 01-15 10:09:20.814373.814373 lmp.py:1626]   Expert 14 |    204 | GPU
DEBUG 01-15 10:09:20.814731.814731 lmp.py:1626]   Expert  7 |    209 | GPU
DEBUG 01-15 10:09:20.814136.814136 lmp.py:1626]   Expert 31 |    209 | GPU
DEBUG 01-15 10:09:20.814017.814017 lmp.py:1626]   Expert 34 |    210 | GPU
DEBUG 01-15 10:09:20.814898.814898 lmp.py:1626]   Expert 62 |    217 | GPU
DEBUG 01-15 10:09:20.814303.814303 lmp.py:1626]   Expert 59 |    220 | GPU
DEBUG 01-15 10:09:20.814138.814138 lmp.py:1626]   Expert 60 |    220 | GPU
DEBUG 01-15 10:09:20.814304.814304 lmp.py:1626]   Expert  9 |    222 | GPU
DEBUG 01-15 10:09:20.814232.814232 lmp.py:1626]   Expert 17 |    224 | GPU
DEBUG 01-15 10:09:20.814160.814160 lmp.py:1626]   Expert 10 |    228 | GPU
DEBUG 01-15 10:09:20.814087.814087 lmp.py:1626]   Expert 29 |    230 | GPU
DEBUG 01-15 10:09:20.814015.814015 lmp.py:1626]   Expert 58 |    235 | GPU
DEBUG 01-15 10:09:20.814850.814850 lmp.py:1626]   Expert  4 |    236 | GPU
DEBUG 01-15 10:09:20.814255.814255 lmp.py:1626]   Expert 15 |    240 | GPU
DEBUG 01-15 10:09:20.814659.814659 lmp.py:1626]   Expert 26 |    244 | GPU
DEBUG 01-15 10:09:20.814064.814064 lmp.py:1626]   Expert 51 |    257 | GPU
DEBUG 01-15 10:09:20.814468.814468 lmp.py:1626]   Expert 11 |    261 | GPU
DEBUG 01-15 10:09:20.814271.814271 lmp.py:1626]   Expert 44 |    272 | GPU
DEBUG 01-15 10:09:20.814914.814914 lmp.py:1626]   Expert 56 |    290 | GPU
DEBUG 01-15 10:09:20.814510.814510 lmp.py:1626]   Expert 27 |    292 | GPU
DEBUG 01-15 10:09:20.814961.814961 lmp.py:1626]   Expert  1 |    331 | GPU
DEBUG 01-15 10:09:20.814174.814174 lmp.py:1626]   Expert 45 |    365 | GPU
DEBUG 01-15 10:09:20.814148.814148 lmp.py:1626]   Expert 25 |    459 | GPU
DEBUG 01-15 10:09:20.814599.814599 lmp.py:1626]   Expert 35 |    518 | GPU
DEBUG 01-15 10:09:20.814811.814811 lmp.py:1626]   Expert 48 |    638 | GPU
DEBUG 01-15 10:09:20.814885.814885 lmp.py:1627] 
DEBUG 01-15 10:09:20.814885.814885 lmp.py:1627]   CPU total tokens: 3870 (31.5%)
DEBUG 01-15 10:09:20.814289.814289 lmp.py:1628]   GPU total tokens: 8418 (68.5%)
DEBUG 01-15 10:09:20.814416.814416 cuda_h.py:19] end experts_map_get cost 0.0015871524810791016 seconds
DEBUG 01-15 10:09:20.814895.814895 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.814764.814764 lmp.py:1636] 
DEBUG 01-15 10:09:20.814764.814764 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.815177.815177 cuda_h.py:19] end cpu_experts_submit cost 6.866455078125e-05 seconds
DEBUG 01-15 10:09:20.815634.815634 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.815947.815947 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.815252.815252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.816916.816916 cuda_h.py:19] end allocate_cuda_memory cost 0.0010149478912353516 seconds
DEBUG 01-15 10:09:20.816442.816442 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.816251.816251 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.816543.816543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.816385.816385 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f5ed5240-d55d-4f65-966c-4526996a912b
DEBUG 01-15 10:09:20.816786.816786 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:20.817754.817754 client.py:127] Model loaded
DEBUG 01-15 10:09:20.817326.817326 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.817769.817769 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.817437.817437 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:20.817775.817775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f5ed5240-d55d-4f65-966c-4526996a912b
DEBUG 01-15 10:09:20.817956.817956 cuda_h.py:19] end load_into_gpu_async cost 0.001291036605834961 seconds
DEBUG 01-15 10:09:20.817090.817090 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.818021.818021 cuda_h.py:19] end restore_tensors2 cost 0.0004811286926269531 seconds
DEBUG 01-15 10:09:20.818912.818912 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032820701599121094 seconds
DEBUG 01-15 10:09:20.818742.818742 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.818839.818839 cuda_h.py:19] end move_flatidxs cost 0.00087738037109375 seconds
DEBUG 01-15 10:09:20.818616.818616 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.818880.818880 cuda_h.py:19] end restore2model cost 0.0001385211944580078 seconds
DEBUG 01-15 10:09:20.818832.818832 cuda_h.py:19] end sllm_worker_task cost 0.011302471160888672 seconds
DEBUG 01-15 10:09:20.821657.821657 cuda_h.py:19] end restore2model cost 0.002780914306640625 seconds
DEBUG 01-15 10:09:20.821183.821183 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006281137466430664 seconds
DEBUG 01-15 10:09:20.821171.821171 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.821075.821075 cuda_h.py:19] end gpu_sexperts cost 0.0002853870391845703 seconds
DEBUG 01-15 10:09:20.821289.821289 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.823282.823282 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015408992767333984 seconds
DEBUG 01-15 10:09:20.824255.824255 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.824692.824692 cuda_h.py:19] end gpu_group_list cost 0.00033974647521972656 seconds
DEBUG 01-15 10:09:20.824909.824909 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.825511.825511 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007538795471191406 seconds
DEBUG 01-15 10:09:20.825811.825811 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.825634.825634 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-15 10:09:20.825330.825330 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.829378.829378 cuda_h.py:19] end group_tensors cost 0.010667800903320312 seconds
DEBUG 01-15 10:09:20.830045.830045 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.834544.834544 cuda_h.py:19] end group pad cost 0.0037920475006103516 seconds
DEBUG 01-15 10:09:20.834573.834573 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.852513.852513 cuda_h.py:19] end group_einsum cost 0.018686294555664062 seconds
DEBUG 01-15 10:09:20.853498.853498 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.857152.857152 cuda_h.py:19] end get_outputs_cpu1 cost 0.004622459411621094 seconds
DEBUG 01-15 10:09:20.858928.858928 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0410614013671875 seconds
DEBUG 01-15 10:09:20.859730.859730 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03384733200073242 seconds
DEBUG 01-15 10:09:20.859951.859951 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.859595.859595 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.859792.859792 cuda_h.py:19] end index_scatter cost 8.392333984375e-05 seconds
DEBUG 01-15 10:09:20.860101.860101 cuda_h.py:19] end cpuoutputsdeal cost 0.0008413791656494141 seconds
DEBUG 01-15 10:09:20.860262.860262 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.860309.860309 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f5ed5240-d55d-4f65-966c-4526996a912b
INFO 01-15 10:09:20.868866.868866 client.py:127] Model loaded
DEBUG 01-15 10:09:20.868655.868655 cuda_h.py:19] end wait_experts cost 0.00777435302734375 seconds
DEBUG 01-15 10:09:20.868643.868643 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.868195.868195 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.868481.868481 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.868632.868632 cuda_h.py:19] end gpu_group_tensor cost 0.0001552104949951172 seconds
DEBUG 01-15 10:09:20.868252.868252 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.869107.869107 cuda_h.py:19] end gpu_group_einsum cost 0.0005834102630615234 seconds
DEBUG 01-15 10:09:20.869184.869184 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.869882.869882 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.869356.869356 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002799034118652344 seconds
DEBUG 01-15 10:09:20.869165.869165 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.869016.869016 cuda_h.py:19] end concat_expert_out cost 6.818771362304688e-05 seconds
DEBUG 01-15 10:09:20.870568.870568 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.870014.870014 cuda_h.py:19] end index_scatter cost 5.14984130859375e-05 seconds
DEBUG 01-15 10:09:20.870346.870346 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006368160247802734 seconds
DEBUG 01-15 10:09:20.870541.870541 cuda_h.py:19] end gpu_experts cost 0.0018689632415771484 seconds
DEBUG 01-15 10:09:20.870596.870596 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.057848453521728516 seconds
DEBUG 01-15 10:09:20.870186.870186 cuda_h.py:19] end prefill_layer cost 0.06363224983215332 seconds
DEBUG 01-15 10:09:20.870844.870844 lmp.py:1552] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-15 10:09:20.870792.870792 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.870455.870455 lmp.py:1495] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-15 10:09:20.870311.870311 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:20.870120.870120 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:20.870599.870599 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.7670135498046875e-05 seconds
DEBUG 01-15 10:09:20.870077.870077 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.772445678710938e-05 seconds
DEBUG 01-15 10:09:20.871641.871641 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.871398.871398 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.871765.871765 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.871833.871833 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.871114.871114 cuda_h.py:19] end allocate_cuda_memory cost 0.0002415180206298828 seconds
DEBUG 01-15 10:09:20.871732.871732 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.871204.871204 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.871457.871457 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.871968.871968 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 57c01ff9-9b19-4a29-b33a-ae903f992a42
DEBUG 01-15 10:09:20.871076.871076 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.871167.871167 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.872829.872829 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.872622.872622 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 57c01ff9-9b19-4a29-b33a-ae903f992a42
DEBUG 01-15 10:09:20.872551.872551 cuda_h.py:19] end load_into_gpu_async cost 0.0010619163513183594 seconds
DEBUG 01-15 10:09:20.872869.872869 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.872336.872336 cuda_h.py:19] end restore_tensors2 cost 7.319450378417969e-05 seconds
DEBUG 01-15 10:09:20.872900.872900 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016160011291503906 seconds
INFO 01-15 10:09:20.872002.872002 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 57c01ff9-9b19-4a29-b33a-ae903f992a42
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.876654.876654 cuda_h.py:19] end self_attn cost 0.003801584243774414 seconds
DEBUG 01-15 10:09:20.876515.876515 cuda_h.py:19] end iln_self_attn_paln cost 0.0054836273193359375 seconds
DEBUG 01-15 10:09:20.876809.876809 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-15 10:09:20.876015.876015 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.877054.877054 cuda_h.py:19] end gate cost 0.0008931159973144531 seconds
DEBUG 01-15 10:09:20.877334.877334 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.878229.878229 lmp.py:1616] 
DEBUG 01-15 10:09:20.878229.878229 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.878005.878005 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.878384.878384 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.878186.878186 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.878650.878650 lmp.py:1620] 
DEBUG 01-15 10:09:20.878650.878650 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.878115.878115 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.878294.878294 lmp.py:1626]   Expert 44 |     29 | CPU
DEBUG 01-15 10:09:20.878044.878044 lmp.py:1626]   Expert  9 |     35 | CPU
DEBUG 01-15 10:09:20.878554.878554 lmp.py:1626]   Expert 11 |     36 | CPU
DEBUG 01-15 10:09:20.878588.878588 lmp.py:1626]   Expert 56 |     58 | CPU
DEBUG 01-15 10:09:20.878814.878814 lmp.py:1626]   Expert 54 |     77 | CPU
DEBUG 01-15 10:09:20.878279.878279 lmp.py:1626]   Expert 62 |     89 | CPU
DEBUG 01-15 10:09:20.878790.878790 lmp.py:1626]   Expert  7 |     92 | CPU
DEBUG 01-15 10:09:20.878062.878062 lmp.py:1626]   Expert 47 |     96 | CPU
DEBUG 01-15 10:09:20.878858.878858 lmp.py:1626]   Expert 51 |    100 | CPU
DEBUG 01-15 10:09:20.878653.878653 lmp.py:1626]   Expert 60 |    106 | CPU
DEBUG 01-15 10:09:20.878972.878972 lmp.py:1626]   Expert 22 |    108 | CPU
DEBUG 01-15 10:09:20.878529.878529 lmp.py:1626]   Expert 52 |    108 | CPU
DEBUG 01-15 10:09:20.878848.878848 lmp.py:1626]   Expert 41 |    111 | CPU
DEBUG 01-15 10:09:20.878405.878405 lmp.py:1626]   Expert 53 |    112 | CPU
DEBUG 01-15 10:09:20.878916.878916 lmp.py:1626]   Expert  1 |    125 | CPU
DEBUG 01-15 10:09:20.878188.878188 lmp.py:1626]   Expert  8 |    127 | CPU
DEBUG 01-15 10:09:20.878699.878699 lmp.py:1626]   Expert 48 |    128 | CPU
DEBUG 01-15 10:09:20.878733.878733 lmp.py:1626]   Expert  6 |    130 | CPU
DEBUG 01-15 10:09:20.878813.878813 lmp.py:1626]   Expert 32 |    130 | CPU
DEBUG 01-15 10:09:20.878893.878893 lmp.py:1626]   Expert  2 |    131 | CPU
DEBUG 01-15 10:09:20.878974.878974 lmp.py:1626]   Expert 27 |    139 | CPU
DEBUG 01-15 10:09:20.878531.878531 lmp.py:1626]   Expert 23 |    140 | CPU
DEBUG 01-15 10:09:20.878803.878803 lmp.py:1626]   Expert 35 |    140 | CPU
DEBUG 01-15 10:09:20.878075.878075 lmp.py:1626]   Expert 59 |    141 | CPU
DEBUG 01-15 10:09:20.878825.878825 lmp.py:1626]   Expert 39 |    146 | CPU
DEBUG 01-15 10:09:20.878143.878143 lmp.py:1626]   Expert 26 |    148 | CPU
DEBUG 01-15 10:09:20.878224.878224 lmp.py:1626]   Expert 50 |    148 | CPU
DEBUG 01-15 10:09:20.878304.878304 lmp.py:1626]   Expert 14 |    159 | CPU
DEBUG 01-15 10:09:20.878384.878384 lmp.py:1626]   Expert 24 |    168 | CPU
DEBUG 01-15 10:09:20.878464.878464 lmp.py:1626]   Expert 46 |    168 | CPU
DEBUG 01-15 10:09:20.879498.879498 lmp.py:1626]   Expert 38 |    169 | CPU
DEBUG 01-15 10:09:20.879771.879771 lmp.py:1626]   Expert  0 |    170 | CPU
DEBUG 01-15 10:09:20.879189.879189 lmp.py:1626]   Expert  4 |    172 | GPU
DEBUG 01-15 10:09:20.879176.879176 lmp.py:1626]   Expert 34 |    172 | GPU
DEBUG 01-15 10:09:20.879257.879257 lmp.py:1626]   Expert 49 |    177 | GPU
DEBUG 01-15 10:09:20.879337.879337 lmp.py:1626]   Expert 40 |    179 | GPU
DEBUG 01-15 10:09:20.879417.879417 lmp.py:1626]   Expert  5 |    184 | GPU
DEBUG 01-15 10:09:20.879259.879259 lmp.py:1626]   Expert 63 |    187 | GPU
DEBUG 01-15 10:09:20.879101.879101 lmp.py:1626]   Expert 19 |    191 | GPU
DEBUG 01-15 10:09:20.879897.879897 lmp.py:1626]   Expert 13 |    195 | GPU
DEBUG 01-15 10:09:20.879169.879169 lmp.py:1626]   Expert 29 |    204 | GPU
DEBUG 01-15 10:09:20.879964.879964 lmp.py:1626]   Expert 43 |    204 | GPU
DEBUG 01-15 10:09:20.879283.879283 lmp.py:1626]   Expert 57 |    209 | GPU
DEBUG 01-15 10:09:20.879363.879363 lmp.py:1626]   Expert 61 |    212 | GPU
DEBUG 01-15 10:09:20.879205.879205 lmp.py:1626]   Expert 33 |    223 | GPU
DEBUG 01-15 10:09:20.879524.879524 lmp.py:1626]   Expert 31 |    224 | GPU
DEBUG 01-15 10:09:20.879604.879604 lmp.py:1626]   Expert 20 |    252 | GPU
DEBUG 01-15 10:09:20.879307.879307 lmp.py:1626]   Expert 16 |    253 | GPU
DEBUG 01-15 10:09:20.879533.879533 lmp.py:1626]   Expert 37 |    254 | GPU
DEBUG 01-15 10:09:20.879759.879759 lmp.py:1626]   Expert  3 |    256 | GPU
DEBUG 01-15 10:09:20.879270.879270 lmp.py:1626]   Expert 15 |    257 | GPU
DEBUG 01-15 10:09:20.879304.879304 lmp.py:1626]   Expert 36 |    273 | GPU
DEBUG 01-15 10:09:20.879338.879338 lmp.py:1626]   Expert 18 |    277 | GPU
DEBUG 01-15 10:09:20.879610.879610 lmp.py:1626]   Expert 12 |    292 | GPU
DEBUG 01-15 10:09:20.879644.879644 lmp.py:1626]   Expert 17 |    304 | GPU
DEBUG 01-15 10:09:20.879393.879393 lmp.py:1626]   Expert 28 |    305 | GPU
DEBUG 01-15 10:09:20.879619.879619 lmp.py:1626]   Expert 55 |    308 | GPU
DEBUG 01-15 10:09:20.879130.879130 lmp.py:1626]   Expert 30 |    320 | GPU
DEBUG 01-15 10:09:20.879879.879879 lmp.py:1626]   Expert 25 |    323 | GPU
DEBUG 01-15 10:09:20.879629.879629 lmp.py:1626]   Expert 58 |    334 | GPU
DEBUG 01-15 10:09:20.879663.879663 lmp.py:1626]   Expert 10 |    362 | GPU
DEBUG 01-15 10:09:20.879697.879697 lmp.py:1626]   Expert 45 |    385 | GPU
DEBUG 01-15 10:09:20.879492.879492 lmp.py:1626]   Expert 21 |    394 | GPU
DEBUG 01-15 10:09:20.879241.879241 lmp.py:1626]   Expert 42 |    642 | GPU
DEBUG 01-15 10:09:20.879183.879183 lmp.py:1627] 
DEBUG 01-15 10:09:20.879183.879183 lmp.py:1627]   CPU total tokens: 3764 (30.6%)
DEBUG 01-15 10:09:20.879554.879554 lmp.py:1628]   GPU total tokens: 8524 (69.4%)
DEBUG 01-15 10:09:20.879125.879125 cuda_h.py:19] end experts_map_get cost 0.0022280216217041016 seconds
DEBUG 01-15 10:09:20.880380.880380 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.880672.880672 lmp.py:1636] 
DEBUG 01-15 10:09:20.880672.880672 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.880290.880290 cuda_h.py:19] end cpu_experts_submit cost 6.771087646484375e-05 seconds
DEBUG 01-15 10:09:20.880570.880570 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.880049.880049 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.880188.880188 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.880987.880987 cuda_h.py:19] end allocate_cuda_memory cost 0.00025963783264160156 seconds
INFO 01-15 10:09:20.881350.881350 client.py:127] Model loaded
DEBUG 01-15 10:09:20.881035.881035 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.881753.881753 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.881516.881516 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.881502.881502 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.881013.881013 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e2f4d60-c911-460a-8ab2-51fbdf5d5343
DEBUG 01-15 10:09:20.881340.881340 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.881757.881757 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.881299.881299 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.882356.882356 cuda_h.py:19] end restore2model cost 0.0009131431579589844 seconds
DEBUG 01-15 10:09:20.882245.882245 cuda_h.py:19] end sllm_worker_task cost 0.011175394058227539 seconds
INFO 01-15 10:09:20.882700.882700 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e2f4d60-c911-460a-8ab2-51fbdf5d5343
DEBUG 01-15 10:09:20.882767.882767 cuda_h.py:19] end move_flatidxs cost 0.0008680820465087891 seconds
DEBUG 01-15 10:09:20.882477.882477 cuda_h.py:19] end load_into_gpu_async cost 0.0016183853149414062 seconds
DEBUG 01-15 10:09:20.882942.882942 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.882670.882670 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.883177.883177 cuda_h.py:19] end restore_tensors2 cost 0.00044226646423339844 seconds
DEBUG 01-15 10:09:20.883841.883841 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032541751861572266 seconds
DEBUG 01-15 10:09:20.883717.883717 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.886671.886671 cuda_h.py:19] end restore2model cost 0.0033338069915771484 seconds
DEBUG 01-15 10:09:20.887680.887680 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006826877593994141 seconds
DEBUG 01-15 10:09:20.887820.887820 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.887628.887628 cuda_h.py:19] end gpu_sexperts cost 0.00034427642822265625 seconds
DEBUG 01-15 10:09:20.887756.887756 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.889228.889228 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001986265182495117 seconds
DEBUG 01-15 10:09:20.890335.890335 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.891225.891225 cuda_h.py:19] end gpu_group_list cost 0.0004189014434814453 seconds
DEBUG 01-15 10:09:20.891329.891329 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.892828.892828 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008008480072021484 seconds
DEBUG 01-15 10:09:20.892174.892174 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.892951.892951 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.621246337890625e-05 seconds
DEBUG 01-15 10:09:20.892124.892124 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.893892.893892 cuda_h.py:19] end group_tensors cost 0.010346412658691406 seconds
DEBUG 01-15 10:09:20.894250.894250 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.898983.898983 cuda_h.py:19] end group pad cost 0.0038590431213378906 seconds
DEBUG 01-15 10:09:20.898773.898773 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.916183.916183 cuda_h.py:19] end group_einsum cost 0.017868518829345703 seconds
DEBUG 01-15 10:09:20.916328.916328 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.920811.920811 cuda_h.py:19] end get_outputs_cpu1 cost 0.004670381546020508 seconds
DEBUG 01-15 10:09:20.921798.921798 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0400998592376709 seconds
DEBUG 01-15 10:09:20.922912.922912 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.030411481857299805 seconds
DEBUG 01-15 10:09:20.922286.922286 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.922944.922944 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.923513.923513 cuda_h.py:19] end index_scatter cost 9.679794311523438e-05 seconds
DEBUG 01-15 10:09:20.923501.923501 cuda_h.py:19] end cpuoutputsdeal cost 0.0008518695831298828 seconds
DEBUG 01-15 10:09:20.923808.923808 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.923968.923968 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e2f4d60-c911-460a-8ab2-51fbdf5d5343
INFO 01-15 10:09:20.932178.932178 client.py:127] Model loaded
DEBUG 01-15 10:09:20.932121.932121 cuda_h.py:19] end wait_experts cost 0.009107112884521484 seconds
DEBUG 01-15 10:09:20.932552.932552 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.932429.932429 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.932576.932576 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.933664.933664 cuda_h.py:19] end gpu_group_tensor cost 0.00020194053649902344 seconds
DEBUG 01-15 10:09:20.933688.933688 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.934122.934122 cuda_h.py:19] end gpu_group_einsum cost 0.0006535053253173828 seconds
DEBUG 01-15 10:09:20.934683.934683 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.934222.934222 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:20.934057.934057 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003502368927001953 seconds
DEBUG 01-15 10:09:20.934025.934025 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:20.934102.934102 cuda_h.py:19] end concat_expert_out cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:20.934410.934410 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.935367.935367 cuda_h.py:19] end index_scatter cost 6.747245788574219e-05 seconds
DEBUG 01-15 10:09:20.935376.935376 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000865936279296875 seconds
DEBUG 01-15 10:09:20.935982.935982 cuda_h.py:19] end gpu_experts cost 0.0023202896118164062 seconds
DEBUG 01-15 10:09:20.935722.935722 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.05866837501525879 seconds
DEBUG 01-15 10:09:20.935980.935980 cuda_h.py:19] end prefill_layer cost 0.06491875648498535 seconds
DEBUG 01-15 10:09:20.935677.935677 lmp.py:1552] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-15 10:09:20.935486.935486 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:20.935865.935865 lmp.py:1495] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-15 10:09:20.935952.935952 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:20.935807.935807 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:20.936214.936214 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.24249267578125e-05 seconds
DEBUG 01-15 10:09:20.936653.936653 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.00010418891906738281 seconds
DEBUG 01-15 10:09:20.936647.936647 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:20.936881.936881 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:20.936072.936072 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:20.936556.936556 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.936522.936522 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.936935.936935 cuda_h.py:19] end allocate_cuda_memory cost 0.00023293495178222656 seconds
DEBUG 01-15 10:09:20.936116.936116 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.936872.936872 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.936224.936224 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.936212.936212 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 38378822-6e50-4150-925e-50f1d37e9703
DEBUG 01-15 10:09:20.936367.936367 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:20.937762.937762 cuda_h.py:10] start self_attn
INFO 01-15 10:09:20.937026.937026 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 38378822-6e50-4150-925e-50f1d37e9703
DEBUG 01-15 10:09:20.937432.937432 cuda_h.py:19] end load_into_gpu_async cost 0.0009036064147949219 seconds
DEBUG 01-15 10:09:20.937942.937942 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.937403.937403 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:20.937443.937443 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014424324035644531 seconds
INFO 01-15 10:09:20.937002.937002 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 38378822-6e50-4150-925e-50f1d37e9703
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:20.940005.940005 cuda_h.py:19] end self_attn cost 0.003209829330444336 seconds
DEBUG 01-15 10:09:20.940287.940287 cuda_h.py:19] end iln_self_attn_paln cost 0.004819393157958984 seconds
DEBUG 01-15 10:09:20.941044.941044 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-15 10:09:20.941357.941357 cuda_h.py:10] start gate
DEBUG 01-15 10:09:20.941859.941859 cuda_h.py:19] end gate cost 0.0007188320159912109 seconds
DEBUG 01-15 10:09:20.941689.941689 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:20.942899.942899 lmp.py:1616] 
DEBUG 01-15 10:09:20.942899.942899 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:20.942191.942191 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:20.942808.942808 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:20.942842.942842 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:20.942207.942207 lmp.py:1620] 
DEBUG 01-15 10:09:20.942207.942207 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:20.942764.942764 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:20.942560.942560 lmp.py:1626]   Expert 25 |     13 | CPU
DEBUG 01-15 10:09:20.942395.942395 lmp.py:1626]   Expert 48 |     32 | CPU
DEBUG 01-15 10:09:20.942276.942276 lmp.py:1626]   Expert 45 |     36 | CPU
DEBUG 01-15 10:09:20.942919.942919 lmp.py:1626]   Expert  9 |     62 | CPU
DEBUG 01-15 10:09:20.942324.942324 lmp.py:1626]   Expert 43 |     83 | CPU
DEBUG 01-15 10:09:20.942490.942490 lmp.py:1626]   Expert 54 |     83 | CPU
DEBUG 01-15 10:09:20.942445.942445 lmp.py:1626]   Expert  0 |     86 | CPU
DEBUG 01-15 10:09:20.942333.942333 lmp.py:1626]   Expert 20 |     88 | CPU
DEBUG 01-15 10:09:20.942082.942082 lmp.py:1626]   Expert 47 |     89 | CPU
DEBUG 01-15 10:09:20.942878.942878 lmp.py:1626]   Expert 57 |     90 | CPU
DEBUG 01-15 10:09:20.942243.942243 lmp.py:1626]   Expert  6 |     92 | CPU
DEBUG 01-15 10:09:20.942608.942608 lmp.py:1626]   Expert 36 |     97 | CPU
DEBUG 01-15 10:09:20.942066.942066 lmp.py:1626]   Expert 15 |    104 | CPU
DEBUG 01-15 10:09:20.942477.942477 lmp.py:1626]   Expert 61 |    104 | CPU
DEBUG 01-15 10:09:20.942120.942120 lmp.py:1626]   Expert 62 |    104 | CPU
DEBUG 01-15 10:09:20.942286.942286 lmp.py:1626]   Expert 13 |    107 | CPU
DEBUG 01-15 10:09:20.942452.942452 lmp.py:1626]   Expert  1 |    110 | CPU
DEBUG 01-15 10:09:20.942394.942394 lmp.py:1626]   Expert 38 |    110 | CPU
DEBUG 01-15 10:09:20.942143.942143 lmp.py:1626]   Expert 50 |    110 | CPU
DEBUG 01-15 10:09:20.942031.942031 lmp.py:1626]   Expert 37 |    114 | CPU
DEBUG 01-15 10:09:20.942833.942833 lmp.py:1626]   Expert 14 |    117 | CPU
DEBUG 01-15 10:09:20.942152.942152 lmp.py:1626]   Expert 46 |    119 | CPU
DEBUG 01-15 10:09:20.942517.942517 lmp.py:1626]   Expert 28 |    134 | CPU
DEBUG 01-15 10:09:20.942167.942167 lmp.py:1626]   Expert  7 |    138 | CPU
DEBUG 01-15 10:09:20.942148.942148 lmp.py:1626]   Expert 21 |    138 | CPU
DEBUG 01-15 10:09:20.942314.942314 lmp.py:1626]   Expert 44 |    142 | CPU
DEBUG 01-15 10:09:20.942480.942480 lmp.py:1626]   Expert 52 |    142 | CPU
DEBUG 01-15 10:09:20.942408.942408 lmp.py:1626]   Expert 10 |    152 | CPU
DEBUG 01-15 10:09:20.942256.942256 lmp.py:1626]   Expert 24 |    153 | CPU
DEBUG 01-15 10:09:20.943529.943529 lmp.py:1626]   Expert 42 |    153 | CPU
DEBUG 01-15 10:09:20.943344.943344 lmp.py:1626]   Expert 11 |    159 | CPU
DEBUG 01-15 10:09:20.943140.943140 lmp.py:1626]   Expert  2 |    165 | CPU
DEBUG 01-15 10:09:20.943505.943505 lmp.py:1626]   Expert 35 |    170 | GPU
DEBUG 01-15 10:09:20.943393.943393 lmp.py:1626]   Expert 26 |    174 | GPU
DEBUG 01-15 10:09:20.943612.943612 lmp.py:1626]   Expert 31 |    176 | GPU
DEBUG 01-15 10:09:20.943309.943309 lmp.py:1626]   Expert  3 |    184 | GPU
DEBUG 01-15 10:09:20.943190.943190 lmp.py:1626]   Expert 19 |    187 | GPU
DEBUG 01-15 10:09:20.943118.943118 lmp.py:1626]   Expert 32 |    187 | GPU
DEBUG 01-15 10:09:20.943045.943045 lmp.py:1626]   Expert 12 |    194 | GPU
DEBUG 01-15 10:09:20.943940.943940 lmp.py:1626]   Expert 56 |    210 | GPU
DEBUG 01-15 10:09:20.943451.943451 lmp.py:1626]   Expert 60 |    212 | GPU
DEBUG 01-15 10:09:20.943439.943439 lmp.py:1626]   Expert 40 |    215 | GPU
DEBUG 01-15 10:09:20.943850.943850 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:20.943215.943215 lmp.py:1626]   Expert  8 |    232 | GPU
DEBUG 01-15 10:09:20.943342.943342 lmp.py:1626]   Expert 23 |    232 | GPU
DEBUG 01-15 10:09:20.943230.943230 lmp.py:1626]   Expert 53 |    233 | GPU
DEBUG 01-15 10:09:20.943972.943972 lmp.py:1626]   Expert 16 |    234 | GPU
DEBUG 01-15 10:09:20.943138.943138 lmp.py:1626]   Expert 51 |    234 | GPU
DEBUG 01-15 10:09:20.943305.943305 lmp.py:1626]   Expert 58 |    237 | GPU
DEBUG 01-15 10:09:20.943292.943292 lmp.py:1626]   Expert 59 |    240 | GPU
DEBUG 01-15 10:09:20.943134.943134 lmp.py:1626]   Expert  4 |    251 | GPU
DEBUG 01-15 10:09:20.943168.943168 lmp.py:1626]   Expert 55 |    265 | GPU
DEBUG 01-15 10:09:20.943295.943295 lmp.py:1626]   Expert 49 |    268 | GPU
DEBUG 01-15 10:09:20.943898.943898 lmp.py:1626]   Expert 29 |    278 | GPU
DEBUG 01-15 10:09:20.943786.943786 lmp.py:1626]   Expert 34 |    281 | GPU
DEBUG 01-15 10:09:20.943436.943436 lmp.py:1626]   Expert 18 |    282 | GPU
DEBUG 01-15 10:09:20.943655.943655 lmp.py:1626]   Expert 63 |    295 | GPU
DEBUG 01-15 10:09:20.943398.943398 lmp.py:1626]   Expert 27 |    356 | GPU
DEBUG 01-15 10:09:20.943902.943902 lmp.py:1626]   Expert 39 |    381 | GPU
DEBUG 01-15 10:09:20.943644.943644 lmp.py:1626]   Expert 17 |    390 | GPU
DEBUG 01-15 10:09:20.943162.943162 lmp.py:1626]   Expert 22 |    427 | GPU
DEBUG 01-15 10:09:20.943619.943619 lmp.py:1626]   Expert 33 |    452 | GPU
DEBUG 01-15 10:09:20.943362.943362 lmp.py:1626]   Expert 30 |    456 | GPU
DEBUG 01-15 10:09:20.943926.943926 lmp.py:1626]   Expert  5 |    710 | GPU
DEBUG 01-15 10:09:20.943582.943582 lmp.py:1627] 
DEBUG 01-15 10:09:20.943582.943582 lmp.py:1627]   CPU total tokens: 3426 (27.9%)
DEBUG 01-15 10:09:20.943901.943901 lmp.py:1628]   GPU total tokens: 8862 (72.1%)
DEBUG 01-15 10:09:20.943472.943472 cuda_h.py:19] end experts_map_get cost 0.001975536346435547 seconds
DEBUG 01-15 10:09:20.943143.943143 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:20.944840.944840 lmp.py:1636] 
DEBUG 01-15 10:09:20.944840.944840 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:20.944167.944167 cuda_h.py:19] end cpu_experts_submit cost 6.628036499023438e-05 seconds
DEBUG 01-15 10:09:20.944486.944486 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:20.944025.944025 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:20.944746.944746 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:20.945119.945119 cuda_h.py:19] end allocate_cuda_memory cost 0.00034880638122558594 seconds
DEBUG 01-15 10:09:20.945510.945510 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:20.945976.945976 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:20.945799.945799 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:20.945807.945807 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:20.945940.945940 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42a3b195-0b70-48a8-b856-caf088b666c0
DEBUG 01-15 10:09:20.945511.945511 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:20.945579.945579 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:20.945712.945712 client.py:127] Model loaded
DEBUG 01-15 10:09:20.945694.945694 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.946774.946774 cuda_h.py:19] end move_flatidxs cost 0.0008690357208251953 seconds
DEBUG 01-15 10:09:20.946517.946517 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:20.946651.946651 cuda_h.py:19] end restore2model cost 0.00045371055603027344 seconds
DEBUG 01-15 10:09:20.946387.946387 cuda_h.py:19] end sllm_worker_task cost 0.009995698928833008 seconds
INFO 01-15 10:09:20.946723.946723 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42a3b195-0b70-48a8-b856-caf088b666c0
DEBUG 01-15 10:09:20.946017.946017 cuda_h.py:19] end load_into_gpu_async cost 0.0013883113861083984 seconds
DEBUG 01-15 10:09:20.946158.946158 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:20.947662.947662 cuda_h.py:19] end restore_tensors2 cost 0.0004062652587890625 seconds
DEBUG 01-15 10:09:20.947605.947605 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028514862060546875 seconds
DEBUG 01-15 10:09:20.947964.947964 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:20.949325.949325 cuda_h.py:19] end restore2model cost 0.002620220184326172 seconds
DEBUG 01-15 10:09:20.949354.949354 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005735874176025391 seconds
DEBUG 01-15 10:09:20.949832.949832 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:20.950207.950207 cuda_h.py:19] end gpu_sexperts cost 0.00027441978454589844 seconds
DEBUG 01-15 10:09:20.950124.950124 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:20.951581.951581 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015597343444824219 seconds
DEBUG 01-15 10:09:20.952861.952861 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:20.953663.953663 cuda_h.py:19] end gpu_group_list cost 0.00035643577575683594 seconds
DEBUG 01-15 10:09:20.953105.953105 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:20.954643.954643 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008029937744140625 seconds
DEBUG 01-15 10:09:20.954142.954142 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:20.954362.954362 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.811981201171875e-05 seconds
DEBUG 01-15 10:09:20.954827.954827 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:20.956258.956258 cuda_h.py:19] end group_tensors cost 0.009804964065551758 seconds
DEBUG 01-15 10:09:20.956489.956489 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:20.960618.960618 cuda_h.py:19] end group pad cost 0.0036246776580810547 seconds
DEBUG 01-15 10:09:20.960647.960647 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:20.979622.979622 cuda_h.py:19] end group_einsum cost 0.019134521484375 seconds
DEBUG 01-15 10:09:20.979892.979892 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:20.984208.984208 cuda_h.py:19] end get_outputs_cpu1 cost 0.004222869873046875 seconds
DEBUG 01-15 10:09:20.985052.985052 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04001641273498535 seconds
DEBUG 01-15 10:09:20.985031.985031 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031553030014038086 seconds
DEBUG 01-15 10:09:20.986876.986876 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:20.986375.986375 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:20.986910.986910 cuda_h.py:19] end index_scatter cost 8.749961853027344e-05 seconds
DEBUG 01-15 10:09:20.986031.986031 cuda_h.py:19] end cpuoutputsdeal cost 0.0008101463317871094 seconds
DEBUG 01-15 10:09:20.986383.986383 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:20.986643.986643 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42a3b195-0b70-48a8-b856-caf088b666c0
INFO 01-15 10:09:20.997004.997004 client.py:127] Model loaded
DEBUG 01-15 10:09:20.997909.997909 cuda_h.py:19] end wait_experts cost 0.010296344757080078 seconds
DEBUG 01-15 10:09:20.997554.997554 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:20.997016.997016 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:20.997548.997548 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:20.998884.998884 cuda_h.py:19] end gpu_group_tensor cost 0.0004012584686279297 seconds
DEBUG 01-15 10:09:20.998865.998865 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:20.999513.999513 cuda_h.py:19] end gpu_group_einsum cost 0.001012563705444336 seconds
DEBUG 01-15 10:09:20.999765.999765 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:20.999042.999042 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:21.000704.000704 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006558895111083984 seconds
DEBUG 01-15 10:09:21.000117.000117 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:21.001623.001623 cuda_h.py:19] end concat_expert_out cost 0.0001761913299560547 seconds
DEBUG 01-15 10:09:21.001026.001026 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.001108.001108 cuda_h.py:19] end index_scatter cost 0.00018405914306640625 seconds
DEBUG 01-15 10:09:21.001377.001377 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016789436340332031 seconds
DEBUG 01-15 10:09:21.001475.001475 cuda_h.py:19] end gpu_experts cost 0.0042877197265625 seconds
DEBUG 01-15 10:09:21.001994.001994 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.060919761657714844 seconds
DEBUG 01-15 10:09:21.002249.002249 cuda_h.py:19] end prefill_layer cost 0.06683969497680664 seconds
DEBUG 01-15 10:09:21.002306.002306 lmp.py:1552] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-15 10:09:21.002282.002282 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:21.002278.002278 lmp.py:1495] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-15 10:09:21.003069.003069 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:21.003754.003754 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:21.003078.003078 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:21.003061.003061 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:21.003427.003427 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00025963783264160156 seconds
DEBUG 01-15 10:09:21.003105.003105 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.003804.003804 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:21.003912.003912 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.004510.004510 cuda_h.py:19] end allocate_cuda_memory cost 0.00027251243591308594 seconds
DEBUG 01-15 10:09:21.004121.004121 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.004069.004069 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.004760.004760 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.004463.004463 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d85de392-de72-4064-9455-2030c85ea1f6
DEBUG 01-15 10:09:21.004916.004916 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.004618.004618 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:21.005167.005167 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d85de392-de72-4064-9455-2030c85ea1f6
DEBUG 01-15 10:09:21.005951.005951 cuda_h.py:19] end load_into_gpu_async cost 0.0010008811950683594 seconds
DEBUG 01-15 10:09:21.005269.005269 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.005180.005180 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-15 10:09:21.005698.005698 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017271041870117188 seconds
INFO 01-15 10:09:21.005230.005230 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d85de392-de72-4064-9455-2030c85ea1f6
DEBUG 01-15 10:09:21.005081.005081 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:21.010646.010646 cuda_h.py:19] end self_attn cost 0.00503849983215332 seconds
DEBUG 01-15 10:09:21.011085.011085 cuda_h.py:19] end iln_self_attn_paln cost 0.007592916488647461 seconds
DEBUG 01-15 10:09:21.011916.011916 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-15 10:09:21.011569.011569 cuda_h.py:10] start gate
DEBUG 01-15 10:09:21.012838.012838 cuda_h.py:19] end gate cost 0.0010437965393066406 seconds
DEBUG 01-15 10:09:21.012144.012144 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:21.013525.013525 lmp.py:1616] 
DEBUG 01-15 10:09:21.013525.013525 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:21.013149.013149 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:21.013567.013567 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:21.013594.013594 lmp.py:1619]   GPU experts: 32 (50%)
INFO 01-15 10:09:21.013418.013418 client.py:127] Model loaded
DEBUG 01-15 10:09:21.013685.013685 lmp.py:1620] 
DEBUG 01-15 10:09:21.013685.013685 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:21.013276.013276 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.013456.013456 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:21.013513.013513 lmp.py:1626]   Expert  5 |     14 | CPU
DEBUG 01-15 10:09:21.013852.013852 lmp.py:1626]   Expert 56 |     32 | CPU
DEBUG 01-15 10:09:21.013747.013747 lmp.py:1626]   Expert 27 |     84 | CPU
DEBUG 01-15 10:09:21.013496.013496 lmp.py:1626]   Expert 16 |     88 | CPU
DEBUG 01-15 10:09:21.013292.013292 lmp.py:1626]   Expert 17 |     90 | CPU
DEBUG 01-15 10:09:21.013796.013796 lmp.py:1626]   Expert 40 |     92 | CPU
DEBUG 01-15 10:09:21.013916.013916 lmp.py:1626]   Expert 63 |     98 | CPU
DEBUG 01-15 10:09:21.013797.013797 lmp.py:1626]   Expert 51 |    106 | CPU
DEBUG 01-15 10:09:21.013440.013440 lmp.py:1626]   Expert 49 |    107 | CPU
DEBUG 01-15 10:09:21.013441.013441 lmp.py:1626]   Expert 53 |    107 | CPU
DEBUG 01-15 10:09:21.014568.014568 lmp.py:1626]   Expert 28 |    108 | CPU
DEBUG 01-15 10:09:21.014555.014555 lmp.py:1626]   Expert  7 |    112 | CPU
DEBUG 01-15 10:09:21.014589.014589 lmp.py:1626]   Expert 38 |    122 | CPU
DEBUG 01-15 10:09:21.014193.014193 lmp.py:1626]   Expert 47 |    122 | CPU
DEBUG 01-15 10:09:21.014273.014273 lmp.py:1626]   Expert 37 |    123 | CPU
DEBUG 01-15 10:09:21.014923.014923 lmp.py:1626]   Expert 62 |    126 | CPU
DEBUG 01-15 10:09:21.014520.014520 lmp.py:1626]   Expert 11 |    127 | CPU
DEBUG 01-15 10:09:21.014507.014507 lmp.py:1626]   Expert 58 |    127 | CPU
DEBUG 01-15 10:09:21.014342.014342 lmp.py:1626]   Expert 57 |    136 | CPU
DEBUG 01-15 10:09:21.014423.014423 lmp.py:1626]   Expert 39 |    146 | CPU
DEBUG 01-15 10:09:21.014887.014887 lmp.py:1626]   Expert  1 |    147 | CPU
DEBUG 01-15 10:09:21.014497.014497 lmp.py:1626]   Expert 14 |    149 | CPU
DEBUG 01-15 10:09:21.014339.014339 lmp.py:1626]   Expert 52 |    152 | CPU
DEBUG 01-15 10:09:21.014419.014419 lmp.py:1626]   Expert 23 |    157 | CPU
DEBUG 01-15 10:09:21.014023.014023 lmp.py:1626]   Expert 25 |    157 | CPU
DEBUG 01-15 10:09:21.014335.014335 lmp.py:1626]   Expert 33 |    160 | CPU
DEBUG 01-15 10:09:21.014739.014739 lmp.py:1626]   Expert 60 |    167 | CPU
DEBUG 01-15 10:09:21.014144.014144 lmp.py:1626]   Expert 21 |    169 | CPU
DEBUG 01-15 10:09:21.014085.014085 lmp.py:1626]   Expert  6 |    171 | CPU
DEBUG 01-15 10:09:21.014357.014357 lmp.py:1626]   Expert 45 |    176 | CPU
DEBUG 01-15 10:09:21.014769.014769 lmp.py:1626]   Expert 12 |    181 | CPU
DEBUG 01-15 10:09:21.014756.014756 lmp.py:1626]   Expert 19 |    181 | CPU
DEBUG 01-15 10:09:21.014314.014314 lmp.py:1626]   Expert  4 |    184 | GPU
DEBUG 01-15 10:09:21.014155.014155 lmp.py:1626]   Expert 44 |    185 | GPU
DEBUG 01-15 10:09:21.014997.014997 lmp.py:1626]   Expert 31 |    195 | GPU
DEBUG 01-15 10:09:21.014693.014693 lmp.py:1626]   Expert 30 |    196 | GPU
DEBUG 01-15 10:09:21.014389.014389 lmp.py:1626]   Expert  3 |    197 | GPU
DEBUG 01-15 10:09:21.014477.014477 lmp.py:1626]   Expert 55 |    197 | GPU
DEBUG 01-15 10:09:21.014510.014510 lmp.py:1626]   Expert 36 |    205 | GPU
DEBUG 01-15 10:09:21.014452.014452 lmp.py:1626]   Expert  9 |    210 | GPU
DEBUG 01-15 10:09:21.014102.014102 lmp.py:1626]   Expert  0 |    220 | GPU
DEBUG 01-15 10:09:21.014182.014182 lmp.py:1626]   Expert 34 |    223 | GPU
DEBUG 01-15 10:09:21.014024.014024 lmp.py:1626]   Expert 22 |    226 | GPU
DEBUG 01-15 10:09:21.014389.014389 lmp.py:1626]   Expert 41 |    230 | GPU
DEBUG 01-15 10:09:21.014701.014701 lmp.py:1626]   Expert 26 |    236 | GPU
DEBUG 01-15 10:09:21.014582.014582 lmp.py:1626]   Expert 54 |    236 | GPU
DEBUG 01-15 10:09:21.014093.014093 lmp.py:1626]   Expert 43 |    237 | GPU
DEBUG 01-15 10:09:21.014928.014928 lmp.py:1626]   Expert 13 |    254 | GPU
DEBUG 01-15 10:09:21.014439.014439 lmp.py:1626]   Expert 18 |    254 | GPU
DEBUG 01-15 10:09:21.014049.014049 lmp.py:1626]   Expert 20 |    254 | GPU
DEBUG 01-15 10:09:21.014368.014368 lmp.py:1626]   Expert 59 |    254 | GPU
DEBUG 01-15 10:09:21.014971.014971 lmp.py:1626]   Expert 15 |    259 | GPU
DEBUG 01-15 10:09:21.014528.014528 lmp.py:1626]   Expert 42 |    259 | GPU
DEBUG 01-15 10:09:21.015893.015893 lmp.py:1626]   Expert 50 |    259 | GPU
DEBUG 01-15 10:09:21.015351.015351 lmp.py:1626]   Expert 24 |    263 | GPU
DEBUG 01-15 10:09:21.015047.015047 lmp.py:1626]   Expert 29 |    271 | GPU
DEBUG 01-15 10:09:21.015757.015757 lmp.py:1626]   Expert 61 |    271 | GPU
DEBUG 01-15 10:09:21.015453.015453 lmp.py:1626]   Expert 35 |    281 | GPU
DEBUG 01-15 10:09:21.015626.015626 lmp.py:1626]   Expert 32 |    304 | GPU
DEBUG 01-15 10:09:21.015666.015666 lmp.py:1626]   Expert  8 |    339 | GPU
DEBUG 01-15 10:09:21.015323.015323 lmp.py:1626]   Expert 10 |    341 | GPU
DEBUG 01-15 10:09:21.015642.015642 lmp.py:1626]   Expert  2 |    344 | GPU
DEBUG 01-15 10:09:21.015245.015245 lmp.py:1626]   Expert 46 |    424 | GPU
DEBUG 01-15 10:09:21.015279.015279 lmp.py:1626]   Expert 48 |    446 | GPU
DEBUG 01-15 10:09:21.015551.015551 lmp.py:1627] 
DEBUG 01-15 10:09:21.015551.015551 lmp.py:1627]   CPU total tokens: 4034 (32.8%)
DEBUG 01-15 10:09:21.015579.015579 lmp.py:1628]   GPU total tokens: 8254 (67.2%)
DEBUG 01-15 10:09:21.015851.015851 cuda_h.py:19] end experts_map_get cost 0.0024826526641845703 seconds
DEBUG 01-15 10:09:21.015307.015307 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:21.015840.015840 lmp.py:1636] 
DEBUG 01-15 10:09:21.015840.015840 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:21.015041.015041 cuda_h.py:19] end cpu_experts_submit cost 8.082389831542969e-05 seconds
DEBUG 01-15 10:09:21.015460.015460 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:21.015442.015442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.015130.015130 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.016351.016351 cuda_h.py:19] end allocate_cuda_memory cost 0.000213623046875 seconds
DEBUG 01-15 10:09:21.016817.016817 cuda_h.py:19] end restore2model cost 0.002812623977661133 seconds
DEBUG 01-15 10:09:21.016219.016219 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.016626.016626 cuda_h.py:19] end sllm_worker_task cost 0.013170957565307617 seconds
DEBUG 01-15 10:09:21.016422.016422 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.016068.016068 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.016578.016578 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1699267d-7f88-4983-a881-22930006e0b2
DEBUG 01-15 10:09:21.016958.016958 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:21.017164.017164 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:21.017476.017476 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.018871.018871 cuda_h.py:19] end move_flatidxs cost 0.0008707046508789062 seconds
DEBUG 01-15 10:09:21.018383.018383 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:21.018816.018816 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1699267d-7f88-4983-a881-22930006e0b2
DEBUG 01-15 10:09:21.018798.018798 cuda_h.py:19] end load_into_gpu_async cost 0.0015439987182617188 seconds
DEBUG 01-15 10:09:21.018078.018078 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.018986.018986 cuda_h.py:19] end restore_tensors2 cost 0.0003757476806640625 seconds
DEBUG 01-15 10:09:21.018340.018340 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030565261840820312 seconds
DEBUG 01-15 10:09:21.018845.018845 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.021385.021385 cuda_h.py:19] end restore2model cost 0.002645730972290039 seconds
DEBUG 01-15 10:09:21.021751.021751 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005909442901611328 seconds
DEBUG 01-15 10:09:21.021229.021229 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:21.022756.022756 cuda_h.py:19] end gpu_sexperts cost 0.00028014183044433594 seconds
DEBUG 01-15 10:09:21.022659.022659 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:21.023072.023072 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015735626220703125 seconds
DEBUG 01-15 10:09:21.024425.024425 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:21.024220.024220 cuda_h.py:19] end gpu_group_list cost 0.0003535747528076172 seconds
DEBUG 01-15 10:09:21.025364.025364 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:21.025108.025108 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008144378662109375 seconds
DEBUG 01-15 10:09:21.026845.026845 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:21.026748.026748 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-15 10:09:21.026835.026835 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:21.028738.028738 cuda_h.py:19] end group_tensors cost 0.009939193725585938 seconds
DEBUG 01-15 10:09:21.028612.028612 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:21.032214.032214 cuda_h.py:19] end group pad cost 0.0038955211639404297 seconds
DEBUG 01-15 10:09:21.032150.032150 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:21.054815.054815 cuda_h.py:19] end group_einsum cost 0.021518468856811523 seconds
DEBUG 01-15 10:09:21.054847.054847 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:21.059979.059979 cuda_h.py:19] end get_outputs_cpu1 cost 0.00448155403137207 seconds
DEBUG 01-15 10:09:21.060682.060682 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.043062448501586914 seconds
DEBUG 01-15 10:09:21.060836.060836 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03477168083190918 seconds
DEBUG 01-15 10:09:21.061124.061124 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:21.061616.061616 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.061535.061535 cuda_h.py:19] end index_scatter cost 0.00010156631469726562 seconds
DEBUG 01-15 10:09:21.061239.061239 cuda_h.py:19] end cpuoutputsdeal cost 0.0008177757263183594 seconds
DEBUG 01-15 10:09:21.061731.061731 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:21.062401.062401 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1699267d-7f88-4983-a881-22930006e0b2
INFO 01-15 10:09:21.069616.069616 client.py:127] Model loaded
DEBUG 01-15 10:09:21.069261.069261 cuda_h.py:19] end wait_experts cost 0.0073091983795166016 seconds
DEBUG 01-15 10:09:21.069925.069925 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:21.069582.069582 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:21.069054.069054 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:21.069942.069942 cuda_h.py:19] end gpu_group_tensor cost 0.00020265579223632812 seconds
DEBUG 01-15 10:09:21.069277.069277 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:21.070837.070837 cuda_h.py:19] end gpu_group_einsum cost 0.0006444454193115234 seconds
DEBUG 01-15 10:09:21.070550.070550 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:21.070353.070353 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:21.071446.071446 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003440380096435547 seconds
DEBUG 01-15 10:09:21.071692.071692 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:21.071284.071284 cuda_h.py:19] end concat_expert_out cost 5.269050598144531e-05 seconds
DEBUG 01-15 10:09:21.071127.071127 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.071356.071356 cuda_h.py:19] end index_scatter cost 6.461143493652344e-05 seconds
DEBUG 01-15 10:09:21.071834.071834 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007221698760986328 seconds
DEBUG 01-15 10:09:21.071227.071227 cuda_h.py:19] end gpu_experts cost 0.002092123031616211 seconds
DEBUG 01-15 10:09:21.071720.071720 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.05992841720581055 seconds
DEBUG 01-15 10:09:21.071946.071946 cuda_h.py:19] end prefill_layer cost 0.06900262832641602 seconds
DEBUG 01-15 10:09:21.072352.072352 lmp.py:1552] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-15 10:09:21.072624.072624 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:21.072227.072227 lmp.py:1495] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-15 10:09:21.072798.072798 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:21.072978.072978 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:21.072814.072814 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.075599670410156e-05 seconds
DEBUG 01-15 10:09:21.072087.072087 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:21.072875.072875 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:21.072149.072149 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:21.072802.072802 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:21.072479.072479 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.072450.072450 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.072122.072122 cuda_h.py:19] end allocate_cuda_memory cost 0.0002472400665283203 seconds
DEBUG 01-15 10:09:21.072337.072337 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.073099.073099 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.073783.073783 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.073155.073155 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4b28fdd4-5248-4b92-a071-b300e9b22afc
DEBUG 01-15 10:09:21.073874.073874 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.073265.073265 cuda_h.py:10] start self_attn
INFO 01-15 10:09:21.074599.074599 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4b28fdd4-5248-4b92-a071-b300e9b22afc
DEBUG 01-15 10:09:21.074018.074018 cuda_h.py:19] end load_into_gpu_async cost 0.0015196800231933594 seconds
DEBUG 01-15 10:09:21.074628.074628 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.074354.074354 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-15 10:09:21.074845.074845 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021398067474365234 seconds
INFO 01-15 10:09:21.074781.074781 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4b28fdd4-5248-4b92-a071-b300e9b22afc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:21.076769.076769 cuda_h.py:19] end self_attn cost 0.003504514694213867 seconds
DEBUG 01-15 10:09:21.077971.077971 cuda_h.py:19] end iln_self_attn_paln cost 0.00499272346496582 seconds
DEBUG 01-15 10:09:21.077622.077622 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-15 10:09:21.077000.077000 cuda_h.py:10] start gate
DEBUG 01-15 10:09:21.078621.078621 cuda_h.py:19] end gate cost 0.000705718994140625 seconds
DEBUG 01-15 10:09:21.078212.078212 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:21.078275.078275 lmp.py:1616] 
DEBUG 01-15 10:09:21.078275.078275 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:21.078283.078283 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:21.078363.078363 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:21.078960.078960 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:21.078126.078126 lmp.py:1620] 
DEBUG 01-15 10:09:21.078126.078126 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:21.078246.078246 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:21.078081.078081 lmp.py:1626]   Expert 36 |     21 | CPU
DEBUG 01-15 10:09:21.078724.078724 lmp.py:1626]   Expert 35 |     30 | CPU
DEBUG 01-15 10:09:21.078651.078651 lmp.py:1626]   Expert 25 |     47 | CPU
DEBUG 01-15 10:09:21.078102.078102 lmp.py:1626]   Expert 46 |     49 | CPU
DEBUG 01-15 10:09:21.078553.078553 lmp.py:1626]   Expert 51 |     51 | CPU
DEBUG 01-15 10:09:21.078242.078242 lmp.py:1626]   Expert 16 |     58 | CPU
DEBUG 01-15 10:09:21.078932.078932 lmp.py:1626]   Expert 30 |     61 | CPU
DEBUG 01-15 10:09:21.078859.078859 lmp.py:1626]   Expert  0 |     64 | CPU
DEBUG 01-15 10:09:21.078840.078840 lmp.py:1626]   Expert 43 |     68 | CPU
DEBUG 01-15 10:09:21.078768.078768 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:21.078980.078980 lmp.py:1626]   Expert 44 |     73 | CPU
DEBUG 01-15 10:09:21.078193.078193 lmp.py:1626]   Expert 47 |     73 | CPU
DEBUG 01-15 10:09:21.078882.078882 lmp.py:1626]   Expert 39 |     75 | CPU
DEBUG 01-15 10:09:21.078095.078095 lmp.py:1626]   Expert 42 |     76 | CPU
DEBUG 01-15 10:09:21.078784.078784 lmp.py:1626]   Expert  2 |     82 | CPU
DEBUG 01-15 10:09:21.078235.078235 lmp.py:1626]   Expert  4 |    110 | CPU
DEBUG 01-15 10:09:21.078686.078686 lmp.py:1626]   Expert 48 |    116 | CPU
DEBUG 01-15 10:09:21.078898.078898 lmp.py:1626]   Expert 33 |    119 | CPU
DEBUG 01-15 10:09:21.078111.078111 lmp.py:1626]   Expert  6 |    121 | CPU
DEBUG 01-15 10:09:21.078800.078800 lmp.py:1626]   Expert 61 |    123 | CPU
DEBUG 01-15 10:09:21.078781.078781 lmp.py:1626]   Expert 13 |    126 | CPU
DEBUG 01-15 10:09:21.078470.078470 lmp.py:1626]   Expert 24 |    128 | CPU
DEBUG 01-15 10:09:21.078405.078405 lmp.py:1626]   Expert 56 |    130 | CPU
DEBUG 01-15 10:09:21.078094.078094 lmp.py:1626]   Expert 15 |    134 | CPU
DEBUG 01-15 10:09:21.078306.078306 lmp.py:1626]   Expert 29 |    137 | CPU
DEBUG 01-15 10:09:21.078757.078757 lmp.py:1626]   Expert 54 |    139 | CPU
DEBUG 01-15 10:09:21.079970.079970 lmp.py:1626]   Expert  9 |    143 | CPU
DEBUG 01-15 10:09:21.079182.079182 lmp.py:1626]   Expert 38 |    143 | CPU
DEBUG 01-15 10:09:21.079395.079395 lmp.py:1626]   Expert 20 |    144 | CPU
DEBUG 01-15 10:09:21.079846.079846 lmp.py:1626]   Expert  7 |    146 | CPU
DEBUG 01-15 10:09:21.079058.079058 lmp.py:1626]   Expert 59 |    151 | CPU
DEBUG 01-15 10:09:21.079270.079270 lmp.py:1626]   Expert 62 |    155 | CPU
DEBUG 01-15 10:09:21.079721.079721 lmp.py:1626]   Expert 45 |    160 | GPU
DEBUG 01-15 10:09:21.079934.079934 lmp.py:1626]   Expert 19 |    161 | GPU
DEBUG 01-15 10:09:21.079908.079908 lmp.py:1626]   Expert 34 |    187 | GPU
DEBUG 01-15 10:09:21.079359.079359 lmp.py:1626]   Expert 57 |    189 | GPU
DEBUG 01-15 10:09:21.079810.079810 lmp.py:1626]   Expert 50 |    192 | GPU
DEBUG 01-15 10:09:21.079784.079784 lmp.py:1626]   Expert 10 |    202 | GPU
DEBUG 01-15 10:09:21.079903.079903 lmp.py:1626]   Expert 31 |    202 | GPU
DEBUG 01-15 10:09:21.079308.079308 lmp.py:1626]   Expert 23 |    208 | GPU
DEBUG 01-15 10:09:21.079997.079997 lmp.py:1626]   Expert  8 |    214 | GPU
DEBUG 01-15 10:09:21.079925.079925 lmp.py:1626]   Expert 60 |    216 | GPU
DEBUG 01-15 10:09:21.079091.079091 lmp.py:1626]   Expert 18 |    218 | GPU
DEBUG 01-15 10:09:21.079734.079734 lmp.py:1626]   Expert 22 |    222 | GPU
DEBUG 01-15 10:09:21.079662.079662 lmp.py:1626]   Expert 53 |    225 | GPU
DEBUG 01-15 10:09:21.079590.079590 lmp.py:1626]   Expert 52 |    227 | GPU
DEBUG 01-15 10:09:21.079756.079756 lmp.py:1626]   Expert 37 |    231 | GPU
DEBUG 01-15 10:09:21.079399.079399 lmp.py:1626]   Expert  5 |    237 | GPU
DEBUG 01-15 10:09:21.079757.079757 lmp.py:1626]   Expert 17 |    245 | GPU
DEBUG 01-15 10:09:21.079685.079685 lmp.py:1626]   Expert 11 |    257 | GPU
DEBUG 01-15 10:09:21.079089.079089 lmp.py:1626]   Expert  1 |    270 | GPU
DEBUG 01-15 10:09:21.079494.079494 lmp.py:1626]   Expert 49 |    276 | GPU
DEBUG 01-15 10:09:21.079660.079660 lmp.py:1626]   Expert 41 |    279 | GPU
DEBUG 01-15 10:09:21.079826.079826 lmp.py:1626]   Expert 28 |    287 | GPU
DEBUG 01-15 10:09:21.079992.079992 lmp.py:1626]   Expert 26 |    291 | GPU
DEBUG 01-15 10:09:21.079158.079158 lmp.py:1626]   Expert 32 |    291 | GPU
DEBUG 01-15 10:09:21.079324.079324 lmp.py:1626]   Expert 58 |    297 | GPU
DEBUG 01-15 10:09:21.079491.079491 lmp.py:1626]   Expert 40 |    303 | GPU
DEBUG 01-15 10:09:21.079895.079895 lmp.py:1626]   Expert 14 |    308 | GPU
DEBUG 01-15 10:09:21.079300.079300 lmp.py:1626]   Expert 12 |    329 | GPU
DEBUG 01-15 10:09:21.079227.079227 lmp.py:1626]   Expert 63 |    335 | GPU
DEBUG 01-15 10:09:21.079586.079586 lmp.py:1626]   Expert 21 |    388 | GPU
DEBUG 01-15 10:09:21.079990.079990 lmp.py:1626]   Expert 27 |    664 | GPU
DEBUG 01-15 10:09:21.079395.079395 lmp.py:1626]   Expert  3 |   1012 | GPU
DEBUG 01-15 10:09:21.079038.079038 lmp.py:1627] 
DEBUG 01-15 10:09:21.079038.079038 lmp.py:1627]   CPU total tokens: 3165 (25.8%)
DEBUG 01-15 10:09:21.079396.079396 lmp.py:1628]   GPU total tokens: 9123 (74.2%)
DEBUG 01-15 10:09:21.079569.079569 cuda_h.py:19] end experts_map_get cost 0.001535177230834961 seconds
DEBUG 01-15 10:09:21.079148.079148 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:21.079950.079950 lmp.py:1636] 
DEBUG 01-15 10:09:21.079950.079950 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:21.079164.079164 cuda_h.py:19] end cpu_experts_submit cost 5.173683166503906e-05 seconds
DEBUG 01-15 10:09:21.079098.079098 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:21.079643.079643 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.080153.080153 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.080048.080048 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:21.080252.080252 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:21.081741.081741 cuda_h.py:19] end allocate_cuda_memory cost 0.0007078647613525391 seconds
DEBUG 01-15 10:09:21.081109.081109 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.081423.081423 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.081246.081246 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.081326.081326 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7032ef7a-6520-4507-b778-ecdaa9194975
DEBUG 01-15 10:09:21.081926.081926 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.081263.081263 cuda_h.py:19] end move_flatidxs cost 0.0008654594421386719 seconds
DEBUG 01-15 10:09:21.081947.081947 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:21.081425.081425 client.py:127] Model loaded
DEBUG 01-15 10:09:21.081257.081257 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.082747.082747 cuda_h.py:19] end restore2model cost 0.00035858154296875 seconds
DEBUG 01-15 10:09:21.082954.082954 cuda_h.py:19] end sllm_worker_task cost 0.009841203689575195 seconds
INFO 01-15 10:09:21.082550.082550 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7032ef7a-6520-4507-b778-ecdaa9194975
DEBUG 01-15 10:09:21.082486.082486 cuda_h.py:19] end load_into_gpu_async cost 0.0012755393981933594 seconds
DEBUG 01-15 10:09:21.082189.082189 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.082068.082068 cuda_h.py:19] end restore_tensors2 cost 0.0003409385681152344 seconds
DEBUG 01-15 10:09:21.083805.083805 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028040409088134766 seconds
DEBUG 01-15 10:09:21.083575.083575 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.085594.085594 cuda_h.py:19] end restore2model cost 0.002512693405151367 seconds
DEBUG 01-15 10:09:21.085100.085100 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005773067474365234 seconds
DEBUG 01-15 10:09:21.085088.085088 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:21.086986.086986 cuda_h.py:19] end gpu_sexperts cost 0.00027561187744140625 seconds
DEBUG 01-15 10:09:21.086305.086305 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:21.087615.087615 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014913082122802734 seconds
DEBUG 01-15 10:09:21.088455.088455 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:21.088746.088746 cuda_h.py:19] end gpu_group_list cost 0.00032329559326171875 seconds
DEBUG 01-15 10:09:21.088333.088333 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:21.089199.089199 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007045269012451172 seconds
DEBUG 01-15 10:09:21.089399.089399 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:21.089281.089281 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-15 10:09:21.089646.089646 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:21.091308.091308 cuda_h.py:19] end group_tensors cost 0.00995016098022461 seconds
DEBUG 01-15 10:09:21.092975.092975 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:21.096899.096899 cuda_h.py:19] end group pad cost 0.0036041736602783203 seconds
DEBUG 01-15 10:09:21.096735.096735 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:21.115050.115050 cuda_h.py:19] end group_einsum cost 0.01882338523864746 seconds
DEBUG 01-15 10:09:21.115082.115082 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:21.119473.119473 cuda_h.py:19] end get_outputs_cpu1 cost 0.004462480545043945 seconds
DEBUG 01-15 10:09:21.120202.120202 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.040131568908691406 seconds
DEBUG 01-15 10:09:21.121640.121640 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031792640686035156 seconds
DEBUG 01-15 10:09:21.121160.121160 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:21.121712.121712 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.122241.122241 cuda_h.py:19] end index_scatter cost 9.250640869140625e-05 seconds
DEBUG 01-15 10:09:21.122924.122924 cuda_h.py:19] end cpuoutputsdeal cost 0.0008358955383300781 seconds
DEBUG 01-15 10:09:21.122323.122323 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:21.122199.122199 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7032ef7a-6520-4507-b778-ecdaa9194975
INFO 01-15 10:09:21.132855.132855 client.py:127] Model loaded
DEBUG 01-15 10:09:21.132890.132890 cuda_h.py:19] end wait_experts cost 0.010173559188842773 seconds
DEBUG 01-15 10:09:21.132892.132892 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:21.132331.132331 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:21.132379.132379 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:21.133074.133074 cuda_h.py:19] end gpu_group_tensor cost 0.0001633167266845703 seconds
DEBUG 01-15 10:09:21.133311.133311 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:21.133306.133306 cuda_h.py:19] end gpu_group_einsum cost 0.0006031990051269531 seconds
DEBUG 01-15 10:09:21.134907.134907 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:21.134386.134386 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:21.134846.134846 cuda_h.py:19] end all_expert_outputs_slices cost 0.00026679039001464844 seconds
DEBUG 01-15 10:09:21.134352.134352 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:21.134746.134746 cuda_h.py:19] end concat_expert_out cost 7.390975952148438e-05 seconds
DEBUG 01-15 10:09:21.134285.134285 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.134773.134773 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-15 10:09:21.134556.134556 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007364749908447266 seconds
DEBUG 01-15 10:09:21.134930.134930 cuda_h.py:19] end gpu_experts cost 0.002102375030517578 seconds
DEBUG 01-15 10:09:21.135105.135105 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.05773353576660156 seconds
DEBUG 01-15 10:09:21.135869.135869 cuda_h.py:19] end prefill_layer cost 0.06345582008361816 seconds
DEBUG 01-15 10:09:21.135580.135580 lmp.py:1552] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-15 10:09:21.135588.135588 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:21.135165.135165 lmp.py:1495] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-15 10:09:21.135690.135690 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:21.135784.135784 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:21.135257.135257 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.337860107421875e-05 seconds
DEBUG 01-15 10:09:21.135325.135325 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:21.135268.135268 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:21.136468.136468 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:21.136947.136947 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.136388.136388 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.136460.136460 cuda_h.py:19] end allocate_cuda_memory cost 0.00033211708068847656 seconds
DEBUG 01-15 10:09:21.136562.136562 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.136086.136086 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.136670.136670 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.136089.136089 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ad89e843-1f41-41b1-8401-3db72bfa4885
DEBUG 01-15 10:09:21.136628.136628 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.136825.136825 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:21.137819.137819 cuda_h.py:10] start self_attn
INFO 01-15 10:09:21.137409.137409 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ad89e843-1f41-41b1-8401-3db72bfa4885
DEBUG 01-15 10:09:21.137292.137292 cuda_h.py:19] end load_into_gpu_async cost 0.0009942054748535156 seconds
DEBUG 01-15 10:09:21.137233.137233 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.137607.137607 cuda_h.py:19] end restore_tensors2 cost 7.486343383789062e-05 seconds
DEBUG 01-15 10:09:21.137363.137363 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00165557861328125 seconds
INFO 01-15 10:09:21.137710.137710 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ad89e843-1f41-41b1-8401-3db72bfa4885
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:21.141125.141125 cuda_h.py:19] end self_attn cost 0.0043354034423828125 seconds
DEBUG 01-15 10:09:21.142216.142216 cuda_h.py:19] end iln_self_attn_paln cost 0.005997419357299805 seconds
DEBUG 01-15 10:09:21.142841.142841 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-15 10:09:21.142235.142235 cuda_h.py:10] start gate
DEBUG 01-15 10:09:21.143017.143017 cuda_h.py:19] end gate cost 0.0007786750793457031 seconds
DEBUG 01-15 10:09:21.143052.143052 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:21.143132.143132 lmp.py:1616] 
DEBUG 01-15 10:09:21.143132.143132 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:21.143313.143313 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:21.143798.143798 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:21.143653.143653 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:21.143933.143933 lmp.py:1620] 
DEBUG 01-15 10:09:21.143933.143933 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:21.143351.143351 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:21.143908.143908 lmp.py:1626]   Expert 13 |     28 | CPU
DEBUG 01-15 10:09:21.143969.143969 lmp.py:1626]   Expert 44 |     39 | CPU
DEBUG 01-15 10:09:21.143301.143301 lmp.py:1626]   Expert 25 |     40 | CPU
DEBUG 01-15 10:09:21.143865.143865 lmp.py:1626]   Expert  9 |     44 | CPU
DEBUG 01-15 10:09:21.143906.143906 lmp.py:1626]   Expert 38 |     44 | CPU
DEBUG 01-15 10:09:21.143755.143755 lmp.py:1626]   Expert 16 |     48 | CPU
DEBUG 01-15 10:09:21.144173.144173 lmp.py:1626]   Expert  2 |     52 | CPU
DEBUG 01-15 10:09:21.144320.144320 lmp.py:1626]   Expert 22 |     56 | CPU
DEBUG 01-15 10:09:21.144990.144990 lmp.py:1626]   Expert 33 |     56 | CPU
DEBUG 01-15 10:09:21.144368.144368 lmp.py:1626]   Expert 42 |     60 | CPU
DEBUG 01-15 10:09:21.144886.144886 lmp.py:1626]   Expert  5 |     67 | CPU
DEBUG 01-15 10:09:21.144993.144993 lmp.py:1626]   Expert 23 |     77 | CPU
DEBUG 01-15 10:09:21.144604.144604 lmp.py:1626]   Expert 24 |     79 | CPU
DEBUG 01-15 10:09:21.144777.144777 lmp.py:1626]   Expert 10 |     84 | CPU
DEBUG 01-15 10:09:21.144917.144917 lmp.py:1626]   Expert 59 |    102 | CPU
DEBUG 01-15 10:09:21.144103.144103 lmp.py:1626]   Expert 21 |    106 | CPU
DEBUG 01-15 10:09:21.144104.144104 lmp.py:1626]   Expert 55 |    113 | CPU
DEBUG 01-15 10:09:21.144490.144490 lmp.py:1626]   Expert 46 |    114 | CPU
DEBUG 01-15 10:09:21.144723.144723 lmp.py:1626]   Expert 45 |    116 | CPU
DEBUG 01-15 10:09:21.144810.144810 lmp.py:1626]   Expert 61 |    123 | CPU
DEBUG 01-15 10:09:21.144274.144274 lmp.py:1626]   Expert 31 |    130 | CPU
DEBUG 01-15 10:09:21.144454.144454 lmp.py:1626]   Expert  8 |    141 | CPU
DEBUG 01-15 10:09:21.144045.144045 lmp.py:1626]   Expert 51 |    141 | CPU
DEBUG 01-15 10:09:21.144139.144139 lmp.py:1626]   Expert 36 |    142 | CPU
DEBUG 01-15 10:09:21.144226.144226 lmp.py:1626]   Expert  6 |    144 | CPU
DEBUG 01-15 10:09:21.144028.144028 lmp.py:1626]   Expert 43 |    151 | CPU
DEBUG 01-15 10:09:21.144877.144877 lmp.py:1626]   Expert  3 |    152 | CPU
DEBUG 01-15 10:09:21.144719.144719 lmp.py:1626]   Expert  0 |    155 | CPU
DEBUG 01-15 10:09:21.144845.144845 lmp.py:1626]   Expert 18 |    158 | CPU
DEBUG 01-15 10:09:21.144986.144986 lmp.py:1626]   Expert 26 |    159 | CPU
DEBUG 01-15 10:09:21.144980.144980 lmp.py:1626]   Expert 48 |    159 | CPU
DEBUG 01-15 10:09:21.144551.144551 lmp.py:1626]   Expert 41 |    166 | CPU
DEBUG 01-15 10:09:21.144075.144075 lmp.py:1626]   Expert 12 |    175 | GPU
DEBUG 01-15 10:09:21.144831.144831 lmp.py:1626]   Expert  7 |    178 | GPU
DEBUG 01-15 10:09:21.144349.144349 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:21.144482.144482 lmp.py:1626]   Expert 56 |    186 | GPU
DEBUG 01-15 10:09:21.144344.144344 lmp.py:1626]   Expert 27 |    188 | GPU
DEBUG 01-15 10:09:21.145901.145901 lmp.py:1626]   Expert 28 |    189 | GPU
DEBUG 01-15 10:09:21.145903.145903 lmp.py:1626]   Expert 34 |    194 | GPU
DEBUG 01-15 10:09:21.145566.145566 lmp.py:1626]   Expert  1 |    196 | GPU
DEBUG 01-15 10:09:21.145322.145322 lmp.py:1626]   Expert 47 |    202 | GPU
DEBUG 01-15 10:09:21.145078.145078 lmp.py:1626]   Expert 11 |    213 | GPU
DEBUG 01-15 10:09:21.145119.145119 lmp.py:1626]   Expert 32 |    216 | GPU
DEBUG 01-15 10:09:21.145960.145960 lmp.py:1626]   Expert 40 |    226 | GPU
DEBUG 01-15 10:09:21.145895.145895 lmp.py:1626]   Expert 49 |    232 | GPU
DEBUG 01-15 10:09:21.145095.145095 lmp.py:1626]   Expert 53 |    236 | GPU
DEBUG 01-15 10:09:21.145566.145566 lmp.py:1626]   Expert 63 |    237 | GPU
DEBUG 01-15 10:09:21.145084.145084 lmp.py:1626]   Expert 15 |    245 | GPU
DEBUG 01-15 10:09:21.145648.145648 lmp.py:1626]   Expert  4 |    246 | GPU
DEBUG 01-15 10:09:21.145543.145543 lmp.py:1626]   Expert 29 |    247 | GPU
DEBUG 01-15 10:09:21.145928.145928 lmp.py:1626]   Expert 30 |    248 | GPU
DEBUG 01-15 10:09:21.145188.145188 lmp.py:1626]   Expert 50 |    249 | GPU
DEBUG 01-15 10:09:21.145891.145891 lmp.py:1626]   Expert 35 |    271 | GPU
DEBUG 01-15 10:09:21.145733.145733 lmp.py:1626]   Expert 14 |    274 | GPU
DEBUG 01-15 10:09:21.145621.145621 lmp.py:1626]   Expert 37 |    302 | GPU
DEBUG 01-15 10:09:21.145271.145271 lmp.py:1626]   Expert 52 |    338 | GPU
DEBUG 01-15 10:09:21.145775.145775 lmp.py:1626]   Expert 17 |    361 | GPU
DEBUG 01-15 10:09:21.145703.145703 lmp.py:1626]   Expert 54 |    380 | GPU
DEBUG 01-15 10:09:21.145869.145869 lmp.py:1626]   Expert 39 |    391 | GPU
DEBUG 01-15 10:09:21.145095.145095 lmp.py:1626]   Expert 57 |    412 | GPU
DEBUG 01-15 10:09:21.145367.145367 lmp.py:1626]   Expert 60 |    458 | GPU
DEBUG 01-15 10:09:21.145070.145070 lmp.py:1626]   Expert 62 |    458 | GPU
DEBUG 01-15 10:09:21.145243.145243 lmp.py:1626]   Expert 19 |    543 | GPU
DEBUG 01-15 10:09:21.145846.145846 lmp.py:1626]   Expert 58 |    569 | GPU
DEBUG 01-15 10:09:21.145119.145119 lmp.py:1627] 
DEBUG 01-15 10:09:21.145119.145119 lmp.py:1627]   CPU total tokens: 3246 (26.4%)
DEBUG 01-15 10:09:21.145199.145199 lmp.py:1628]   GPU total tokens: 9042 (73.6%)
DEBUG 01-15 10:09:21.145809.145809 cuda_h.py:19] end experts_map_get cost 0.0025796890258789062 seconds
INFO 01-15 10:09:21.145873.145873 client.py:127] Model loaded
DEBUG 01-15 10:09:21.146868.146868 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:21.146036.146036 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.146004.146004 lmp.py:1636] 
DEBUG 01-15 10:09:21.146004.146004 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:21.146099.146099 cuda_h.py:19] end cpu_experts_submit cost 0.0002503395080566406 seconds
DEBUG 01-15 10:09:21.146139.146139 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:21.146793.146793 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.146014.146014 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.147320.147320 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:21.147135.147135 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:21.147288.147288 cuda_h.py:19] end allocate_cuda_memory cost 0.0002243518829345703 seconds
DEBUG 01-15 10:09:21.147783.147783 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.147368.147368 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.147846.147846 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.147211.147211 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 10a19849-337b-4a4a-b777-86a5084744b7
DEBUG 01-15 10:09:21.147391.147391 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.148788.148788 cuda_h.py:19] end restore2model cost 0.0019893646240234375 seconds
DEBUG 01-15 10:09:21.148259.148259 cuda_h.py:19] end move_flatidxs cost 0.0008692741394042969 seconds
DEBUG 01-15 10:09:21.148916.148916 cuda_h.py:19] end sllm_worker_task cost 0.012134790420532227 seconds
DEBUG 01-15 10:09:21.148579.148579 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:21.148209.148209 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 10a19849-337b-4a4a-b777-86a5084744b7
DEBUG 01-15 10:09:21.148012.148012 cuda_h.py:19] end load_into_gpu_async cost 0.0014557838439941406 seconds
DEBUG 01-15 10:09:21.148060.148060 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.149066.149066 cuda_h.py:19] end restore_tensors2 cost 0.0003566741943359375 seconds
DEBUG 01-15 10:09:21.149909.149909 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025763511657714844 seconds
DEBUG 01-15 10:09:21.149315.149315 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.152164.152164 cuda_h.py:19] end restore2model cost 0.0025577545166015625 seconds
DEBUG 01-15 10:09:21.152735.152735 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005433559417724609 seconds
DEBUG 01-15 10:09:21.152545.152545 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:21.152311.152311 cuda_h.py:19] end gpu_sexperts cost 0.00031828880310058594 seconds
DEBUG 01-15 10:09:21.152638.152638 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:21.154180.154180 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015082359313964844 seconds
DEBUG 01-15 10:09:21.154558.154558 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:21.155268.155268 cuda_h.py:19] end gpu_group_list cost 0.00035381317138671875 seconds
DEBUG 01-15 10:09:21.155358.155358 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:21.156757.156757 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007717609405517578 seconds
DEBUG 01-15 10:09:21.156282.156282 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:21.156933.156933 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-15 10:09:21.156636.156636 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:21.158074.158074 cuda_h.py:19] end group_tensors cost 0.010184526443481445 seconds
DEBUG 01-15 10:09:21.159563.159563 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:21.163346.163346 cuda_h.py:19] end group pad cost 0.003965854644775391 seconds
DEBUG 01-15 10:09:21.163044.163044 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:21.182235.182235 cuda_h.py:19] end group_einsum cost 0.019247770309448242 seconds
DEBUG 01-15 10:09:21.182167.182167 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:21.187191.187191 cuda_h.py:19] end get_outputs_cpu1 cost 0.0044057369232177734 seconds
DEBUG 01-15 10:09:21.188463.188463 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0409543514251709 seconds
DEBUG 01-15 10:09:21.188319.188319 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03240251541137695 seconds
DEBUG 01-15 10:09:21.189786.189786 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:21.189866.189866 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.189461.189461 cuda_h.py:19] end index_scatter cost 0.0001049041748046875 seconds
DEBUG 01-15 10:09:21.189270.189270 cuda_h.py:19] end cpuoutputsdeal cost 0.0007750988006591797 seconds
DEBUG 01-15 10:09:21.189192.189192 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:21.189286.189286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 10a19849-337b-4a4a-b777-86a5084744b7
INFO 01-15 10:09:21.199414.199414 client.py:127] Model loaded
DEBUG 01-15 10:09:21.199781.199781 cuda_h.py:19] end wait_experts cost 0.009638309478759766 seconds
DEBUG 01-15 10:09:21.199576.199576 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:21.199936.199936 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:21.199115.199115 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:21.199897.199897 cuda_h.py:19] end gpu_group_tensor cost 0.00016236305236816406 seconds
DEBUG 01-15 10:09:21.199516.199516 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:21.200100.200100 cuda_h.py:19] end gpu_group_einsum cost 0.0005977153778076172 seconds
DEBUG 01-15 10:09:21.200383.200383 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:21.200233.200233 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:21.201522.201522 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002663135528564453 seconds
DEBUG 01-15 10:09:21.201185.201185 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:21.201937.201937 cuda_h.py:19] end concat_expert_out cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:21.201349.201349 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.201180.201180 cuda_h.py:19] end index_scatter cost 5.650520324707031e-05 seconds
DEBUG 01-15 10:09:21.201221.201221 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006403923034667969 seconds
DEBUG 01-15 10:09:21.201667.201667 cuda_h.py:19] end gpu_experts cost 0.0018951892852783203 seconds
DEBUG 01-15 10:09:21.201392.201392 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.059287309646606445 seconds
DEBUG 01-15 10:09:21.201198.201198 cuda_h.py:19] end prefill_layer cost 0.06624674797058105 seconds
DEBUG 01-15 10:09:21.201365.201365 lmp.py:1552] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-15 10:09:21.202983.202983 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:21.202202.202202 lmp.py:1495] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-15 10:09:21.202852.202852 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:21.202601.202601 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:21.202629.202629 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.170967102050781e-05 seconds
DEBUG 01-15 10:09:21.202160.202160 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.414817810058594e-05 seconds
DEBUG 01-15 10:09:21.202042.202042 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:21.202382.202382 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:21.202406.202406 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:21.202652.202652 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.202908.202908 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.202315.202315 cuda_h.py:19] end allocate_cuda_memory cost 0.000263214111328125 seconds
DEBUG 01-15 10:09:21.202053.202053 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.203168.203168 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.203944.203944 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.203885.203885 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0855191f-26af-4c0c-9057-39c3c398ec32
DEBUG 01-15 10:09:21.203994.203994 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.203214.203214 cuda_h.py:10] start self_attn
INFO 01-15 10:09:21.204795.204795 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0855191f-26af-4c0c-9057-39c3c398ec32
DEBUG 01-15 10:09:21.204658.204658 cuda_h.py:19] end load_into_gpu_async cost 0.0015900135040283203 seconds
DEBUG 01-15 10:09:21.204129.204129 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.204649.204649 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-15 10:09:21.204359.204359 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022144317626953125 seconds
INFO 01-15 10:09:21.204049.204049 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0855191f-26af-4c0c-9057-39c3c398ec32
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:21.206909.206909 cuda_h.py:19] end self_attn cost 0.003276348114013672 seconds
DEBUG 01-15 10:09:21.207859.207859 cuda_h.py:19] end iln_self_attn_paln cost 0.004773378372192383 seconds
DEBUG 01-15 10:09:21.207020.207020 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-15 10:09:21.207551.207551 cuda_h.py:10] start gate
DEBUG 01-15 10:09:21.207230.207230 cuda_h.py:19] end gate cost 0.0006411075592041016 seconds
DEBUG 01-15 10:09:21.207106.207106 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:21.208268.208268 lmp.py:1616] 
DEBUG 01-15 10:09:21.208268.208268 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:21.208077.208077 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:21.208634.208634 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:21.208853.208853 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:21.208927.208927 lmp.py:1620] 
DEBUG 01-15 10:09:21.208927.208927 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:21.208285.208285 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:21.208358.208358 lmp.py:1626]   Expert 20 |     11 | CPU
DEBUG 01-15 10:09:21.208240.208240 lmp.py:1626]   Expert 61 |     12 | CPU
DEBUG 01-15 10:09:21.208883.208883 lmp.py:1626]   Expert 11 |     28 | CPU
DEBUG 01-15 10:09:21.208910.208910 lmp.py:1626]   Expert  7 |     39 | CPU
DEBUG 01-15 10:09:21.208030.208030 lmp.py:1626]   Expert 62 |     43 | CPU
DEBUG 01-15 10:09:21.208276.208276 lmp.py:1626]   Expert 51 |     45 | CPU
DEBUG 01-15 10:09:21.208204.208204 lmp.py:1626]   Expert  3 |     46 | CPU
DEBUG 01-15 10:09:21.208569.208569 lmp.py:1626]   Expert 30 |     51 | CPU
DEBUG 01-15 10:09:21.208258.208258 lmp.py:1626]   Expert 17 |     55 | CPU
DEBUG 01-15 10:09:21.208093.208093 lmp.py:1626]   Expert 29 |     59 | CPU
DEBUG 01-15 10:09:21.208975.208975 lmp.py:1626]   Expert  6 |     60 | CPU
DEBUG 01-15 10:09:21.208664.208664 lmp.py:1626]   Expert  9 |     66 | CPU
DEBUG 01-15 10:09:21.208592.208592 lmp.py:1626]   Expert 38 |     77 | CPU
DEBUG 01-15 10:09:21.208281.208281 lmp.py:1626]   Expert 63 |     77 | CPU
DEBUG 01-15 10:09:21.208970.208970 lmp.py:1626]   Expert 55 |     81 | CPU
DEBUG 01-15 10:09:21.208044.208044 lmp.py:1626]   Expert 59 |     90 | CPU
DEBUG 01-15 10:09:21.208971.208971 lmp.py:1626]   Expert  8 |     93 | CPU
DEBUG 01-15 10:09:21.208899.208899 lmp.py:1626]   Expert 48 |     93 | CPU
DEBUG 01-15 10:09:21.208165.208165 lmp.py:1626]   Expert 19 |     95 | CPU
DEBUG 01-15 10:09:21.208490.208490 lmp.py:1626]   Expert 22 |    100 | CPU
DEBUG 01-15 10:09:21.208848.208848 lmp.py:1626]   Expert 49 |    104 | CPU
DEBUG 01-15 10:09:21.208253.208253 lmp.py:1626]   Expert 24 |    109 | CPU
DEBUG 01-15 10:09:21.208942.208942 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:21.208916.208916 lmp.py:1626]   Expert 34 |    116 | CPU
DEBUG 01-15 10:09:21.208513.208513 lmp.py:1626]   Expert 42 |    117 | CPU
DEBUG 01-15 10:09:21.208487.208487 lmp.py:1626]   Expert 50 |    120 | CPU
DEBUG 01-15 10:09:21.208223.208223 lmp.py:1626]   Expert 39 |    127 | CPU
DEBUG 01-15 10:09:21.208197.208197 lmp.py:1626]   Expert  4 |    132 | CPU
DEBUG 01-15 10:09:21.208409.208409 lmp.py:1626]   Expert 37 |    144 | CPU
DEBUG 01-15 10:09:21.208145.208145 lmp.py:1626]   Expert 41 |    144 | CPU
DEBUG 01-15 10:09:21.208364.208364 lmp.py:1626]   Expert 15 |    149 | CPU
DEBUG 01-15 10:09:21.208530.208530 lmp.py:1626]   Expert 23 |    155 | CPU
DEBUG 01-15 10:09:21.208935.208935 lmp.py:1626]   Expert 56 |    161 | GPU
DEBUG 01-15 10:09:21.208339.208339 lmp.py:1626]   Expert 60 |    164 | GPU
DEBUG 01-15 10:09:21.208552.208552 lmp.py:1626]   Expert 16 |    166 | GPU
DEBUG 01-15 10:09:21.208287.208287 lmp.py:1626]   Expert 44 |    169 | GPU
DEBUG 01-15 10:09:21.208500.208500 lmp.py:1626]   Expert  1 |    178 | GPU
DEBUG 01-15 10:09:21.208620.208620 lmp.py:1626]   Expert 21 |    182 | GPU
DEBUG 01-15 10:09:21.209832.209832 lmp.py:1626]   Expert 43 |    182 | GPU
DEBUG 01-15 10:09:21.209806.209806 lmp.py:1626]   Expert 53 |    192 | GPU
DEBUG 01-15 10:09:21.209303.209303 lmp.py:1626]   Expert 47 |    193 | GPU
DEBUG 01-15 10:09:21.209277.209277 lmp.py:1626]   Expert 12 |    198 | GPU
DEBUG 01-15 10:09:21.209252.209252 lmp.py:1626]   Expert 33 |    199 | GPU
DEBUG 01-15 10:09:21.209279.209279 lmp.py:1626]   Expert 13 |    208 | GPU
DEBUG 01-15 10:09:21.209445.209445 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:21.209518.209518 lmp.py:1626]   Expert 28 |    231 | GPU
DEBUG 01-15 10:09:21.209208.209208 lmp.py:1626]   Expert  0 |    254 | GPU
DEBUG 01-15 10:09:21.209612.209612 lmp.py:1626]   Expert 31 |    258 | GPU
DEBUG 01-15 10:09:21.209825.209825 lmp.py:1626]   Expert 54 |    258 | GPU
DEBUG 01-15 10:09:21.209037.209037 lmp.py:1626]   Expert 26 |    259 | GPU
DEBUG 01-15 10:09:21.209157.209157 lmp.py:1626]   Expert 10 |    264 | GPU
DEBUG 01-15 10:09:21.209893.209893 lmp.py:1626]   Expert 18 |    267 | GPU
DEBUG 01-15 10:09:21.209867.209867 lmp.py:1626]   Expert 57 |    268 | GPU
DEBUG 01-15 10:09:21.209364.209364 lmp.py:1626]   Expert  2 |    281 | GPU
DEBUG 01-15 10:09:21.209153.209153 lmp.py:1626]   Expert 58 |    298 | GPU
DEBUG 01-15 10:09:21.209365.209365 lmp.py:1626]   Expert 40 |    340 | GPU
DEBUG 01-15 10:09:21.209531.209531 lmp.py:1626]   Expert 25 |    360 | GPU
DEBUG 01-15 10:09:21.209697.209697 lmp.py:1626]   Expert 45 |    363 | GPU
DEBUG 01-15 10:09:21.209102.209102 lmp.py:1626]   Expert  5 |    436 | GPU
DEBUG 01-15 10:09:21.209314.209314 lmp.py:1626]   Expert 35 |    462 | GPU
DEBUG 01-15 10:09:21.209719.209719 lmp.py:1626]   Expert 27 |    485 | GPU
DEBUG 01-15 10:09:21.209170.209170 lmp.py:1626]   Expert 46 |    555 | GPU
DEBUG 01-15 10:09:21.209144.209144 lmp.py:1626]   Expert 52 |    597 | GPU
DEBUG 01-15 10:09:21.209641.209641 lmp.py:1626]   Expert 14 |    884 | GPU
DEBUG 01-15 10:09:21.209807.209807 lmp.py:1627] 
DEBUG 01-15 10:09:21.209807.209807 lmp.py:1627]   CPU total tokens: 2751 (22.4%)
DEBUG 01-15 10:09:21.209973.209973 lmp.py:1628]   GPU total tokens: 9537 (77.6%)
DEBUG 01-15 10:09:21.209007.209007 cuda_h.py:19] end experts_map_get cost 0.0015833377838134766 seconds
DEBUG 01-15 10:09:21.209718.209718 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:21.209474.209474 lmp.py:1636] 
DEBUG 01-15 10:09:21.209474.209474 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:21.209264.209264 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:21.209053.209053 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:21.209141.209141 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.209981.209981 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.210503.210503 cuda_h.py:19] end allocate_cuda_memory cost 0.0009095668792724609 seconds
DEBUG 01-15 10:09:21.210968.210968 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.211527.211527 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.211416.211416 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.211404.211404 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9b1bd3b-d2c1-4969-898f-cd34984f6ad4
DEBUG 01-15 10:09:21.211537.211537 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.211332.211332 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:21.211601.211601 client.py:127] Model loaded
DEBUG 01-15 10:09:21.211563.211563 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:21.211160.211160 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.212997.212997 cuda_h.py:19] end restore2model cost 0.0004374980926513672 seconds
DEBUG 01-15 10:09:21.212873.212873 cuda_h.py:19] end sllm_worker_task cost 0.009758472442626953 seconds
DEBUG 01-15 10:09:21.212626.212626 cuda_h.py:19] end move_flatidxs cost 0.0008394718170166016 seconds
DEBUG 01-15 10:09:21.212787.212787 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:21.213906.213906 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9b1bd3b-d2c1-4969-898f-cd34984f6ad4
DEBUG 01-15 10:09:21.213226.213226 cuda_h.py:19] end load_into_gpu_async cost 0.002270221710205078 seconds
DEBUG 01-15 10:09:21.213929.213929 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.213709.213709 cuda_h.py:19] end restore_tensors2 cost 0.00033736228942871094 seconds
DEBUG 01-15 10:09:21.213399.213399 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004131317138671875 seconds
DEBUG 01-15 10:09:21.213030.213030 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.216287.216287 cuda_h.py:19] end restore2model cost 0.0025107860565185547 seconds
DEBUG 01-15 10:09:21.216031.216031 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006844043731689453 seconds
DEBUG 01-15 10:09:21.216688.216688 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:21.216268.216268 cuda_h.py:19] end gpu_sexperts cost 0.0002791881561279297 seconds
DEBUG 01-15 10:09:21.216905.216905 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:21.218367.218367 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015001296997070312 seconds
DEBUG 01-15 10:09:21.219181.219181 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:21.219075.219075 cuda_h.py:19] end gpu_group_list cost 0.0003299713134765625 seconds
DEBUG 01-15 10:09:21.219516.219516 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:21.220779.220779 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007147789001464844 seconds
DEBUG 01-15 10:09:21.220556.220556 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:21.220663.220663 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-15 10:09:21.220075.220075 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:21.221600.221600 cuda_h.py:19] end group_tensors cost 0.009024620056152344 seconds
DEBUG 01-15 10:09:21.222003.222003 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:21.225156.225156 cuda_h.py:19] end group pad cost 0.0035364627838134766 seconds
DEBUG 01-15 10:09:21.226376.226376 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:21.243974.243974 cuda_h.py:19] end group_einsum cost 0.017171621322631836 seconds
DEBUG 01-15 10:09:21.243238.243238 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:21.247560.247560 cuda_h.py:19] end get_outputs_cpu1 cost 0.003607034683227539 seconds
DEBUG 01-15 10:09:21.247501.247501 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03643321990966797 seconds
DEBUG 01-15 10:09:21.249038.249038 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.028681278228759766 seconds
DEBUG 01-15 10:09:21.249800.249800 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:21.250167.250167 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.250389.250389 cuda_h.py:19] end index_scatter cost 0.0001709461212158203 seconds
DEBUG 01-15 10:09:21.251338.251338 cuda_h.py:19] end cpuoutputsdeal cost 0.0017321109771728516 seconds
DEBUG 01-15 10:09:21.251932.251932 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:21.251961.251961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9b1bd3b-d2c1-4969-898f-cd34984f6ad4
INFO 01-15 10:09:21.263672.263672 client.py:127] Model loaded
DEBUG 01-15 10:09:21.263922.263922 cuda_h.py:19] end wait_experts cost 0.012302398681640625 seconds
DEBUG 01-15 10:09:21.263885.263885 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:21.264453.264453 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:21.264515.264515 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:21.264942.264942 cuda_h.py:19] end gpu_group_tensor cost 0.0004112720489501953 seconds
DEBUG 01-15 10:09:21.264162.264162 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:21.266116.266116 cuda_h.py:19] end gpu_group_einsum cost 0.0010731220245361328 seconds
DEBUG 01-15 10:09:21.266792.266792 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:21.266549.266549 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:21.266564.266564 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022864341735839844 seconds
DEBUG 01-15 10:09:21.266221.266221 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:21.266245.266245 cuda_h.py:19] end concat_expert_out cost 7.581710815429688e-05 seconds
DEBUG 01-15 10:09:21.266141.266141 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.266231.266231 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-15 10:09:21.267894.267894 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006241798400878906 seconds
DEBUG 01-15 10:09:21.267857.267857 cuda_h.py:19] end gpu_experts cost 0.0030422210693359375 seconds
DEBUG 01-15 10:09:21.267482.267482 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.060030460357666016 seconds
DEBUG 01-15 10:09:21.267503.267503 cuda_h.py:19] end prefill_layer cost 0.06555771827697754 seconds
DEBUG 01-15 10:09:21.267300.267300 lmp.py:1552] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-15 10:09:21.267334.267334 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:21.267798.267798 lmp.py:1495] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-15 10:09:21.267978.267978 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:21.267040.267040 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:21.268369.268369 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:21.271002.271002 cuda_h.py:19] end self_attn cost 0.003631114959716797 seconds
DEBUG 01-15 10:09:21.272053.272053 cuda_h.py:19] end iln_self_attn_paln cost 0.00437474250793457 seconds
DEBUG 01-15 10:09:21.272433.272433 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-15 10:09:21.272487.272487 cuda_h.py:10] start gate
DEBUG 01-15 10:09:21.272100.272100 cuda_h.py:19] end gate cost 0.0006577968597412109 seconds
DEBUG 01-15 10:09:21.273559.273559 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:21.273874.273874 lmp.py:1616] 
DEBUG 01-15 10:09:21.273874.273874 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:21.273160.273160 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:21.273102.273102 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:21.273705.273705 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:21.273971.273971 lmp.py:1620] 
DEBUG 01-15 10:09:21.273971.273971 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:21.273905.273905 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:21.273363.273363 lmp.py:1626]   Expert 47 |     64 | CPU
DEBUG 01-15 10:09:21.273390.273390 lmp.py:1626]   Expert 18 |     65 | CPU
DEBUG 01-15 10:09:21.273702.273702 lmp.py:1626]   Expert 54 |     71 | CPU
DEBUG 01-15 10:09:21.273775.273775 lmp.py:1626]   Expert 23 |     78 | CPU
DEBUG 01-15 10:09:21.273087.273087 lmp.py:1626]   Expert 48 |     81 | CPU
DEBUG 01-15 10:09:21.273638.273638 lmp.py:1626]   Expert 44 |     84 | CPU
DEBUG 01-15 10:09:21.273711.273711 lmp.py:1626]   Expert 45 |     84 | CPU
DEBUG 01-15 10:09:21.273215.273215 lmp.py:1626]   Expert 20 |     92 | CPU
DEBUG 01-15 10:09:21.273481.273481 lmp.py:1626]   Expert 31 |     97 | CPU
DEBUG 01-15 10:09:21.273223.273223 lmp.py:1626]   Expert 36 |    107 | CPU
DEBUG 01-15 10:09:21.273489.273489 lmp.py:1626]   Expert 61 |    109 | CPU
DEBUG 01-15 10:09:21.273516.273516 lmp.py:1626]   Expert 33 |    119 | CPU
DEBUG 01-15 10:09:21.273589.273589 lmp.py:1626]   Expert 42 |    119 | CPU
DEBUG 01-15 10:09:21.273424.273424 lmp.py:1626]   Expert 10 |    123 | CPU
DEBUG 01-15 10:09:21.273498.273498 lmp.py:1626]   Expert 24 |    123 | CPU
DEBUG 01-15 10:09:21.273095.273095 lmp.py:1626]   Expert 43 |    123 | CPU
DEBUG 01-15 10:09:21.273930.273930 lmp.py:1626]   Expert 11 |    125 | CPU
DEBUG 01-15 10:09:21.273003.273003 lmp.py:1626]   Expert 49 |    127 | CPU
DEBUG 01-15 10:09:21.273315.273315 lmp.py:1626]   Expert 56 |    129 | CPU
DEBUG 01-15 10:09:21.273627.273627 lmp.py:1626]   Expert  6 |    136 | CPU
DEBUG 01-15 10:09:21.273939.273939 lmp.py:1626]   Expert 51 |    143 | CPU
DEBUG 01-15 10:09:21.273774.273774 lmp.py:1626]   Expert  5 |    149 | CPU
DEBUG 01-15 10:09:21.273801.273801 lmp.py:1626]   Expert 17 |    149 | CPU
DEBUG 01-15 10:09:21.273590.273590 lmp.py:1626]   Expert  0 |    150 | CPU
DEBUG 01-15 10:09:21.273140.273140 lmp.py:1626]   Expert 40 |    158 | CPU
DEBUG 01-15 10:09:21.274167.274167 lmp.py:1626]   Expert 12 |    161 | CPU
DEBUG 01-15 10:09:21.274002.274002 lmp.py:1626]   Expert 55 |    161 | CPU
DEBUG 01-15 10:09:21.274837.274837 lmp.py:1626]   Expert 57 |    162 | CPU
DEBUG 01-15 10:09:21.274673.274673 lmp.py:1626]   Expert 26 |    163 | CPU
DEBUG 01-15 10:09:21.274508.274508 lmp.py:1626]   Expert 59 |    163 | CPU
DEBUG 01-15 10:09:21.274866.274866 lmp.py:1626]   Expert 38 |    167 | CPU
DEBUG 01-15 10:09:21.274131.274131 lmp.py:1626]   Expert 46 |    168 | CPU
DEBUG 01-15 10:09:21.274205.274205 lmp.py:1626]   Expert 50 |    172 | GPU
DEBUG 01-15 10:09:21.274755.274755 lmp.py:1626]   Expert 13 |    173 | GPU
DEBUG 01-15 10:09:21.274067.274067 lmp.py:1626]   Expert 30 |    174 | GPU
DEBUG 01-15 10:09:21.274141.274141 lmp.py:1626]   Expert 58 |    174 | GPU
DEBUG 01-15 10:09:21.274499.274499 lmp.py:1626]   Expert 35 |    175 | GPU
DEBUG 01-15 10:09:21.274572.274572 lmp.py:1626]   Expert  7 |    182 | GPU
DEBUG 01-15 10:09:21.274931.274931 lmp.py:1626]   Expert 16 |    182 | GPU
DEBUG 01-15 10:09:21.274289.274289 lmp.py:1626]   Expert 15 |    202 | GPU
DEBUG 01-15 10:09:21.274885.274885 lmp.py:1626]   Expert 32 |    205 | GPU
DEBUG 01-15 10:09:21.274482.274482 lmp.py:1626]   Expert 14 |    206 | GPU
DEBUG 01-15 10:09:21.274032.274032 lmp.py:1626]   Expert  1 |    214 | GPU
DEBUG 01-15 10:09:21.274106.274106 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:21.274895.274895 lmp.py:1626]   Expert  3 |    224 | GPU
DEBUG 01-15 10:09:21.274445.274445 lmp.py:1626]   Expert 34 |    238 | GPU
DEBUG 01-15 10:09:21.274234.274234 lmp.py:1626]   Expert 39 |    239 | GPU
DEBUG 01-15 10:09:21.274307.274307 lmp.py:1626]   Expert 28 |    245 | GPU
DEBUG 01-15 10:09:21.274904.274904 lmp.py:1626]   Expert 52 |    247 | GPU
DEBUG 01-15 10:09:21.274501.274501 lmp.py:1626]   Expert 25 |    253 | GPU
DEBUG 01-15 10:09:21.274336.274336 lmp.py:1626]   Expert 22 |    259 | GPU
DEBUG 01-15 10:09:21.274932.274932 lmp.py:1626]   Expert  2 |    274 | GPU
DEBUG 01-15 10:09:21.274006.274006 lmp.py:1626]   Expert 21 |    280 | GPU
DEBUG 01-15 10:09:21.274602.274602 lmp.py:1626]   Expert 41 |    282 | GPU
DEBUG 01-15 10:09:21.274437.274437 lmp.py:1626]   Expert 60 |    283 | GPU
DEBUG 01-15 10:09:21.274988.274988 lmp.py:1626]   Expert 63 |    288 | GPU
DEBUG 01-15 10:09:21.274300.274300 lmp.py:1626]   Expert 29 |    293 | GPU
DEBUG 01-15 10:09:21.274612.274612 lmp.py:1626]   Expert 62 |    297 | GPU
DEBUG 01-15 10:09:21.274400.274400 lmp.py:1626]   Expert 27 |    303 | GPU
DEBUG 01-15 10:09:21.274235.274235 lmp.py:1626]   Expert 37 |    328 | GPU
DEBUG 01-15 10:09:21.274070.274070 lmp.py:1626]   Expert 53 |    335 | GPU
DEBUG 01-15 10:09:21.274667.274667 lmp.py:1626]   Expert  8 |    337 | GPU
DEBUG 01-15 10:09:21.274025.274025 lmp.py:1626]   Expert 19 |    441 | GPU
DEBUG 01-15 10:09:21.274860.274860 lmp.py:1626]   Expert  9 |    612 | GPU
DEBUG 01-15 10:09:21.274411.274411 lmp.py:1627] 
DEBUG 01-15 10:09:21.274411.274411 lmp.py:1627]   CPU total tokens: 3950 (32.1%)
DEBUG 01-15 10:09:21.274438.274438 lmp.py:1628]   GPU total tokens: 8338 (67.9%)
DEBUG 01-15 10:09:21.274233.274233 cuda_h.py:19] end experts_map_get cost 0.0017294883728027344 seconds
DEBUG 01-15 10:09:21.274044.274044 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:21.274422.274422 lmp.py:1636] 
DEBUG 01-15 10:09:21.274422.274422 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:21.274126.274126 cuda_h.py:19] end cpu_experts_submit cost 6.127357482910156e-05 seconds
DEBUG 01-15 10:09:21.274015.274015 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:21.275334.275334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:21.275241.275241 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:21.275121.275121 cuda_h.py:19] end allocate_cuda_memory cost 0.00032591819763183594 seconds
DEBUG 01-15 10:09:21.275600.275600 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:21.275648.275648 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:21.275331.275331 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:21.275087.275087 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a3b59dcb-6ae6-4d52-8a11-52d02981bcb3
DEBUG 01-15 10:09:21.276175.276175 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:21.276299.276299 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:21.277444.277444 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:21.277920.277920 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a3b59dcb-6ae6-4d52-8a11-52d02981bcb3
DEBUG 01-15 10:09:21.277394.277394 cuda_h.py:19] end load_into_gpu_async cost 0.0019123554229736328 seconds
DEBUG 01-15 10:09:21.277939.277939 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:21.278939.278939 cuda_h.py:19] end move_flatidxs cost 0.0008702278137207031 seconds
DEBUG 01-15 10:09:21.278258.278258 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:21.278455.278455 cuda_h.py:19] end restore_tensors2 cost 0.0005414485931396484 seconds
DEBUG 01-15 10:09:21.278663.278663 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032646656036376953 seconds
DEBUG 01-15 10:09:21.278275.278275 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:21.282521.282521 cuda_h.py:19] end restore2model cost 0.0045125484466552734 seconds
DEBUG 01-15 10:09:21.283073.283073 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00805354118347168 seconds
DEBUG 01-15 10:09:21.283942.283942 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:21.283594.283594 cuda_h.py:19] end gpu_sexperts cost 0.00042557716369628906 seconds
DEBUG 01-15 10:09:21.283849.283849 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:21.284130.284130 cuda_h.py:19] end group_tensors cost 0.006387233734130859 seconds
DEBUG 01-15 10:09:21.285740.285740 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:21.286974.286974 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0026950836181640625 seconds
DEBUG 01-15 10:09:21.287184.287184 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:21.288052.288052 cuda_h.py:19] end gpu_group_list cost 0.0003592967987060547 seconds
DEBUG 01-15 10:09:21.288733.288733 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:21.289814.289814 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007848739624023438 seconds
DEBUG 01-15 10:09:21.289504.289504 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:21.289818.289818 cuda_h.py:19] end group pad cost 0.004243373870849609 seconds
DEBUG 01-15 10:09:21.289708.289708 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:21.311915.311915 cuda_h.py:19] end group_einsum cost 0.021509647369384766 seconds
DEBUG 01-15 10:09:21.311808.311808 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:21.316583.316583 cuda_h.py:19] end get_outputs_cpu1 cost 0.0046710968017578125 seconds
DEBUG 01-15 10:09:21.317637.317637 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0400996208190918 seconds
DEBUG 01-15 10:09:21.318091.318091 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.028713226318359375 seconds
DEBUG 01-15 10:09:21.318383.318383 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:21.318996.318996 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.318422.318422 cuda_h.py:19] end index_scatter cost 0.000164031982421875 seconds
DEBUG 01-15 10:09:21.319838.319838 cuda_h.py:19] end cpuoutputsdeal cost 0.0015997886657714844 seconds
DEBUG 01-15 10:09:21.320517.320517 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:21.320262.320262 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a3b59dcb-6ae6-4d52-8a11-52d02981bcb3
INFO 01-15 10:09:21.328103.328103 client.py:127] Model loaded
DEBUG 01-15 10:09:21.328862.328862 cuda_h.py:19] end wait_experts cost 0.008843660354614258 seconds
DEBUG 01-15 10:09:21.329295.329295 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:21.329717.329717 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:21.329726.329726 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:21.329006.329006 cuda_h.py:19] end gpu_group_tensor cost 0.0003757476806640625 seconds
DEBUG 01-15 10:09:21.329411.329411 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:21.331896.331896 cuda_h.py:19] end gpu_group_einsum cost 0.0011227130889892578 seconds
DEBUG 01-15 10:09:21.331375.331375 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:21.331160.331160 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:21.332420.332420 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005700588226318359 seconds
DEBUG 01-15 10:09:21.332953.332953 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:21.332643.332643 cuda_h.py:19] end concat_expert_out cost 0.00015163421630859375 seconds
DEBUG 01-15 10:09:21.332793.332793 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:21.332933.332933 cuda_h.py:19] end index_scatter cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:21.332532.332532 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014221668243408203 seconds
DEBUG 01-15 10:09:21.333339.333339 cuda_h.py:19] end gpu_experts cost 0.003999948501586914 seconds
DEBUG 01-15 10:09:21.333828.333828 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06102323532104492 seconds
DEBUG 01-15 10:09:21.334272.334272 cuda_h.py:19] end prefill_layer cost 0.06633973121643066 seconds
DEBUG 01-15 10:09:21.334349.334349 lmp.py:1552] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-15 10:09:21.334689.334689 cuda_h.py:19] end prefill cost 1.913292646408081 seconds
DEBUG 01-15 10:09:23.523271.523271 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09038686752319336 s
DEBUG 01-15 10:09:23.905194.905194 cuda_h.py:19] end generate_input_ids cost 0.3803737163543701 seconds
DEBUG 01-15 10:09:23.906936.906936 cuda_h.py:10] start init_cache
DEBUG 01-15 10:09:23.906152.906152 cuda_h.py:19] end init_cache cost 8.273124694824219e-05 seconds
DEBUG 01-15 10:09:26.372723.372723 cuda_h.py:10] start init_meta_layer
DEBUG 01-15 10:09:26.374259.374259 cuda_h.py:19] end init_meta_layer cost 1.3589859008789062e-05 seconds
DEBUG 01-15 10:09:26.374197.374197 cuda_h.py:10] start init_weights
DEBUG 01-15 10:09:26.374490.374490 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:26.374683.374683 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:26.376733.376733 cuda_h.py:19] end allocate_cuda_memory cost 0.0022537708282470703 seconds
DEBUG 01-15 10:09:26.376928.376928 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:26.376313.376313 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:26.376031.376031 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:26.376687.376687 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e63b95c-c551-4558-beb6-a0f577ee2a23
DEBUG 01-15 10:09:26.377406.377406 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:26.378794.378794 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e63b95c-c551-4558-beb6-a0f577ee2a23
DEBUG 01-15 10:09:26.378061.378061 cuda_h.py:19] end load_into_gpu_async cost 0.001575469970703125 seconds
DEBUG 01-15 10:09:26.378380.378380 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:26.378694.378694 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-15 10:09:26.378397.378397 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00412297248840332 seconds
DEBUG 01-15 10:09:26.378570.378570 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:26.378073.378073 cuda_h.py:19] end restore2model cost 0.00017261505126953125 seconds
INFO 01-15 10:09:26.378690.378690 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e63b95c-c551-4558-beb6-a0f577ee2a23
INFO 01-15 10:09:26.455750.455750 client.py:127] Model loaded
DEBUG 01-15 10:09:26.456285.456285 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-15 10:09:26.456401.456401 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:26.456465.456465 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:26.456066.456066 cuda_h.py:19] end allocate_cuda_memory cost 0.000392913818359375 seconds
DEBUG 01-15 10:09:26.457309.457309 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:26.457908.457908 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:26.457991.457991 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:26.457702.457702 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2f375eb1-aa47-49e3-8c0f-7ba8211bd4ca
DEBUG 01-15 10:09:26.457787.457787 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:26.459508.459508 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2f375eb1-aa47-49e3-8c0f-7ba8211bd4ca
DEBUG 01-15 10:09:26.459049.459049 cuda_h.py:19] end load_into_gpu_async cost 0.0020360946655273438 seconds
DEBUG 01-15 10:09:26.459258.459258 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:26.459940.459940 cuda_h.py:19] end restore_tensors2 cost 0.00013780593872070312 seconds
DEBUG 01-15 10:09:26.459155.459155 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032536983489990234 seconds
INFO 01-15 10:09:26.459111.459111 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2f375eb1-aa47-49e3-8c0f-7ba8211bd4ca
INFO 01-15 10:09:26.476512.476512 client.py:127] Model loaded
DEBUG 01-15 10:09:26.476557.476557 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:26.477198.477198 cuda_h.py:19] end restore2model cost 0.0008656978607177734 seconds
DEBUG 01-15 10:09:26.477428.477428 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02118849754333496 seconds
DEBUG 01-15 10:09:26.477404.477404 cuda_h.py:19] end init_weights cost 0.10306406021118164 seconds
DEBUG 01-15 10:09:26.477254.477254 cuda_h.py:10] start copy_emodel
DEBUG 01-15 10:09:27.193091.193091 cuda_h.py:19] end copy_emodel cost 0.7161474227905273 seconds
DEBUG 01-15 10:09:27.194971.194971 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-15 10:09:27.194797.194797 cuda_h.py:19] end init_inputs_tokens cost 0.00028443336486816406 seconds
DEBUG 01-15 10:09:27.194620.194620 cuda_h.py:10] start prefill
DEBUG 01-15 10:09:27.194091.194091 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.195715.195715 lmp.py:1495] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-15 10:09:27.195457.195457 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:27.195061.195061 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:27.195049.195049 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.24249267578125e-05 seconds
DEBUG 01-15 10:09:27.195627.195627 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 8.106231689453125e-05 seconds
DEBUG 01-15 10:09:27.195469.195469 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.195689.195689 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.195194.195194 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.195579.195579 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.195787.195787 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.195288.195288 cuda_h.py:19] end allocate_cuda_memory cost 0.0002903938293457031 seconds
DEBUG 01-15 10:09:27.196318.196318 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.196187.196187 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.196812.196812 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.196907.196907 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de29d2c7-e09b-4ead-8fae-0854a760e4d7
DEBUG 01-15 10:09:27.196375.196375 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.196669.196669 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.197216.197216 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de29d2c7-e09b-4ead-8fae-0854a760e4d7
DEBUG 01-15 10:09:27.197445.197445 cuda_h.py:19] end load_into_gpu_async cost 0.0017654895782470703 seconds
DEBUG 01-15 10:09:27.197552.197552 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.198319.198319 cuda_h.py:19] end restore_tensors2 cost 0.00010085105895996094 seconds
DEBUG 01-15 10:09:27.198294.198294 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002518892288208008 seconds
INFO 01-15 10:09:27.198463.198463 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de29d2c7-e09b-4ead-8fae-0854a760e4d7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.202512.202512 cuda_h.py:19] end self_attn cost 0.0053293704986572266 seconds
DEBUG 01-15 10:09:27.202258.202258 cuda_h.py:19] end iln_self_attn_paln cost 0.0071184635162353516 seconds
DEBUG 01-15 10:09:27.202796.202796 cuda_h.py:10] start dense_mlp
INFO 01-15 10:09:27.205362.205362 client.py:127] Model loaded
DEBUG 01-15 10:09:27.205457.205457 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.205656.205656 cuda_h.py:19] end restore2model cost 0.0005536079406738281 seconds
DEBUG 01-15 10:09:27.205121.205121 cuda_h.py:19] end sllm_worker_task cost 0.010274171829223633 seconds
DEBUG 01-15 10:09:27.205575.205575 cuda_h.py:19] end dense_mlp cost 0.003451824188232422 seconds
DEBUG 01-15 10:09:27.205294.205294 cuda_h.py:19] end prefill_layer cost 0.010972976684570312 seconds
DEBUG 01-15 10:09:27.206434.206434 lmp.py:1552] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-15 10:09:27.206368.206368 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.206018.206018 lmp.py:1495] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-15 10:09:27.206429.206429 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:27.206033.206033 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:27.206809.206809 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.0503997802734375e-05 seconds
DEBUG 01-15 10:09:27.206419.206419 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.982948303222656e-05 seconds
DEBUG 01-15 10:09:27.206447.206447 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.206885.206885 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.206802.206802 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.206626.206626 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.206058.206058 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.206132.206132 cuda_h.py:19] end allocate_cuda_memory cost 0.000263214111328125 seconds
DEBUG 01-15 10:09:27.207408.207408 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.207794.207794 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.207208.207208 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.207449.207449 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f2a11ec5-daf7-4808-b133-ab2b737d4fc0
DEBUG 01-15 10:09:27.207560.207560 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.207156.207156 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.208451.208451 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f2a11ec5-daf7-4808-b133-ab2b737d4fc0
DEBUG 01-15 10:09:27.208514.208514 cuda_h.py:19] end load_into_gpu_async cost 0.0017201900482177734 seconds
DEBUG 01-15 10:09:27.208563.208563 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.209794.209794 cuda_h.py:19] end restore_tensors2 cost 0.0001087188720703125 seconds
DEBUG 01-15 10:09:27.209148.209148 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026955604553222656 seconds
INFO 01-15 10:09:27.209940.209940 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f2a11ec5-daf7-4808-b133-ab2b737d4fc0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.211977.211977 cuda_h.py:19] end self_attn cost 0.0034830570220947266 seconds
DEBUG 01-15 10:09:27.211741.211741 cuda_h.py:19] end iln_self_attn_paln cost 0.005209445953369141 seconds
DEBUG 01-15 10:09:27.211114.211114 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-15 10:09:27.211731.211731 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.212856.212856 cuda_h.py:19] end gate cost 0.0009365081787109375 seconds
DEBUG 01-15 10:09:27.212640.212640 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.212901.212901 lmp.py:1616] 
DEBUG 01-15 10:09:27.212901.212901 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.212565.212565 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.212645.212645 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.212672.212672 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.212315.212315 lmp.py:1620] 
DEBUG 01-15 10:09:27.212315.212315 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.212673.212673 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.212747.212747 lmp.py:1626]   Expert 25 |     64 | CPU
DEBUG 01-15 10:09:27.212867.212867 lmp.py:1626]   Expert 54 |     67 | CPU
DEBUG 01-15 10:09:27.213510.213510 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:27.213391.213391 lmp.py:1626]   Expert 31 |     72 | CPU
DEBUG 01-15 10:09:27.213795.213795 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:27.213915.213915 lmp.py:1626]   Expert 62 |     87 | CPU
DEBUG 01-15 10:09:27.213797.213797 lmp.py:1626]   Expert 18 |     88 | CPU
DEBUG 01-15 10:09:27.213678.213678 lmp.py:1626]   Expert 52 |     98 | CPU
DEBUG 01-15 10:09:27.213321.213321 lmp.py:1626]   Expert 22 |    100 | CPU
DEBUG 01-15 10:09:27.213487.213487 lmp.py:1626]   Expert 47 |    104 | CPU
DEBUG 01-15 10:09:27.213892.213892 lmp.py:1626]   Expert  0 |    113 | CPU
DEBUG 01-15 10:09:27.213058.213058 lmp.py:1626]   Expert 37 |    117 | CPU
DEBUG 01-15 10:09:27.213462.213462 lmp.py:1626]   Expert 27 |    121 | CPU
DEBUG 01-15 10:09:27.213251.213251 lmp.py:1626]   Expert 32 |    123 | CPU
DEBUG 01-15 10:09:27.213894.213894 lmp.py:1626]   Expert 41 |    130 | CPU
DEBUG 01-15 10:09:27.213537.213537 lmp.py:1626]   Expert 44 |    131 | CPU
DEBUG 01-15 10:09:27.213180.213180 lmp.py:1626]   Expert 28 |    136 | CPU
DEBUG 01-15 10:09:27.213538.213538 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:27.213704.213704 lmp.py:1626]   Expert 58 |    140 | CPU
DEBUG 01-15 10:09:27.213871.213871 lmp.py:1626]   Expert 60 |    144 | CPU
DEBUG 01-15 10:09:27.213037.213037 lmp.py:1626]   Expert 43 |    147 | CPU
DEBUG 01-15 10:09:27.213203.213203 lmp.py:1626]   Expert  1 |    150 | CPU
DEBUG 01-15 10:09:27.213607.213607 lmp.py:1626]   Expert 38 |    153 | CPU
DEBUG 01-15 10:09:27.213535.213535 lmp.py:1626]   Expert 49 |    154 | CPU
DEBUG 01-15 10:09:27.213940.213940 lmp.py:1626]   Expert 51 |    155 | CPU
DEBUG 01-15 10:09:27.213106.213106 lmp.py:1626]   Expert 34 |    161 | CPU
DEBUG 01-15 10:09:27.213226.213226 lmp.py:1626]   Expert 35 |    164 | CPU
DEBUG 01-15 10:09:27.213869.213869 lmp.py:1626]   Expert 36 |    168 | CPU
DEBUG 01-15 10:09:27.213035.213035 lmp.py:1626]   Expert 11 |    170 | CPU
DEBUG 01-15 10:09:27.213201.213201 lmp.py:1626]   Expert 17 |    170 | CPU
DEBUG 01-15 10:09:27.213605.213605 lmp.py:1626]   Expert 59 |    174 | CPU
DEBUG 01-15 10:09:27.213533.213533 lmp.py:1626]   Expert 10 |    180 | CPU
DEBUG 01-15 10:09:27.213699.213699 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:27.213865.213865 lmp.py:1626]   Expert  2 |    186 | GPU
DEBUG 01-15 10:09:27.213032.213032 lmp.py:1626]   Expert 39 |    189 | GPU
DEBUG 01-15 10:09:27.213198.213198 lmp.py:1626]   Expert 33 |    197 | GPU
DEBUG 01-15 10:09:27.213602.213602 lmp.py:1626]   Expert 12 |    198 | GPU
DEBUG 01-15 10:09:27.213007.213007 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:27.213173.213173 lmp.py:1626]   Expert 48 |    198 | GPU
DEBUG 01-15 10:09:27.213578.213578 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:27.213413.213413 lmp.py:1626]   Expert 53 |    204 | GPU
DEBUG 01-15 10:09:27.213532.213532 lmp.py:1626]   Expert 19 |    220 | GPU
DEBUG 01-15 10:09:27.213891.213891 lmp.py:1626]   Expert 26 |    221 | GPU
DEBUG 01-15 10:09:27.213772.213772 lmp.py:1626]   Expert 30 |    221 | GPU
DEBUG 01-15 10:09:27.213700.213700 lmp.py:1626]   Expert 45 |    221 | GPU
DEBUG 01-15 10:09:27.213866.213866 lmp.py:1626]   Expert  5 |    227 | GPU
DEBUG 01-15 10:09:27.213555.213555 lmp.py:1626]   Expert  4 |    229 | GPU
DEBUG 01-15 10:09:27.213244.213244 lmp.py:1626]   Expert 24 |    229 | GPU
DEBUG 01-15 10:09:27.213172.213172 lmp.py:1626]   Expert 42 |    242 | GPU
DEBUG 01-15 10:09:27.213338.213338 lmp.py:1626]   Expert 50 |    245 | GPU
DEBUG 01-15 10:09:27.213266.213266 lmp.py:1626]   Expert 29 |    254 | GPU
DEBUG 01-15 10:09:27.213717.213717 lmp.py:1626]   Expert 56 |    262 | GPU
DEBUG 01-15 10:09:27.213168.213168 lmp.py:1626]   Expert 61 |    270 | GPU
DEBUG 01-15 10:09:27.213572.213572 lmp.py:1626]   Expert  8 |    283 | GPU
DEBUG 01-15 10:09:27.213739.213739 lmp.py:1626]   Expert 63 |    285 | GPU
DEBUG 01-15 10:09:27.213620.213620 lmp.py:1626]   Expert 46 |    294 | GPU
DEBUG 01-15 10:09:27.213024.213024 lmp.py:1626]   Expert  9 |    300 | GPU
DEBUG 01-15 10:09:27.213952.213952 lmp.py:1626]   Expert  6 |    316 | GPU
DEBUG 01-15 10:09:27.213641.213641 lmp.py:1626]   Expert 16 |    316 | GPU
DEBUG 01-15 10:09:27.214092.214092 lmp.py:1626]   Expert 40 |    319 | GPU
DEBUG 01-15 10:09:27.214782.214782 lmp.py:1626]   Expert  7 |    322 | GPU
DEBUG 01-15 10:09:27.214948.214948 lmp.py:1626]   Expert 23 |    325 | GPU
DEBUG 01-15 10:09:27.214399.214399 lmp.py:1626]   Expert 14 |    413 | GPU
DEBUG 01-15 10:09:27.214088.214088 lmp.py:1626]   Expert 57 |    464 | GPU
DEBUG 01-15 10:09:27.214731.214731 lmp.py:1627] 
DEBUG 01-15 10:09:27.214731.214731 lmp.py:1627]   CPU total tokens: 4059 (33.0%)
DEBUG 01-15 10:09:27.214089.214089 lmp.py:1628]   GPU total tokens: 8229 (67.0%)
DEBUG 01-15 10:09:27.214977.214977 cuda_h.py:19] end experts_map_get cost 0.0015549659729003906 seconds
DEBUG 01-15 10:09:27.214424.214424 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.214995.214995 lmp.py:1636] 
DEBUG 01-15 10:09:27.214995.214995 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.214116.214116 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:27.214335.214335 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.214164.214164 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.214222.214222 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.215389.215389 cuda_h.py:19] end allocate_cuda_memory cost 0.0007891654968261719 seconds
DEBUG 01-15 10:09:27.215570.215570 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.215326.215326 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.215850.215850 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.215931.215931 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2329c686-7cfc-49f9-86c3-e4de9740edfc
DEBUG 01-15 10:09:27.215251.215251 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:27.216130.216130 client.py:127] Model loaded
DEBUG 01-15 10:09:27.216996.216996 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.217826.217826 cuda_h.py:19] end restore2model cost 0.0007765293121337891 seconds
DEBUG 01-15 10:09:27.217377.217377 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:27.217380.217380 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2329c686-7cfc-49f9-86c3-e4de9740edfc
DEBUG 01-15 10:09:27.217363.217363 cuda_h.py:19] end sllm_worker_task cost 0.01122593879699707 seconds
DEBUG 01-15 10:09:27.217399.217399 cuda_h.py:19] end load_into_gpu_async cost 0.0021889209747314453 seconds
DEBUG 01-15 10:09:27.217045.217045 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.217342.217342 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:27.218276.218276 cuda_h.py:19] end restore_tensors2 cost 0.00035262107849121094 seconds
DEBUG 01-15 10:09:27.218973.218973 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037679672241210938 seconds
DEBUG 01-15 10:09:27.218259.218259 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.219530.219530 cuda_h.py:19] end move_flatidxs cost 0.0011587142944335938 seconds
DEBUG 01-15 10:09:27.219950.219950 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.220534.220534 cuda_h.py:19] end restore2model cost 0.0026302337646484375 seconds
DEBUG 01-15 10:09:27.220113.220113 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0065898895263671875 seconds
DEBUG 01-15 10:09:27.220577.220577 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.221495.221495 cuda_h.py:19] end gpu_sexperts cost 0.0002925395965576172 seconds
DEBUG 01-15 10:09:27.221563.221563 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.223808.223808 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0019352436065673828 seconds
DEBUG 01-15 10:09:27.224555.224555 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.224244.224244 cuda_h.py:19] end gpu_group_list cost 0.0003533363342285156 seconds
DEBUG 01-15 10:09:27.224772.224772 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.225381.225381 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007181167602539062 seconds
DEBUG 01-15 10:09:27.225826.225826 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.225125.225125 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-15 10:09:27.225014.225014 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.233236.233236 cuda_h.py:19] end group_tensors cost 0.013752460479736328 seconds
DEBUG 01-15 10:09:27.234112.234112 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.242795.242795 cuda_h.py:19] end group pad cost 0.007891416549682617 seconds
DEBUG 01-15 10:09:27.242354.242354 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.268681.268681 cuda_h.py:19] end group_einsum cost 0.026676416397094727 seconds
DEBUG 01-15 10:09:27.269951.269951 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.274408.274408 cuda_h.py:19] end get_outputs_cpu1 cost 0.0054590702056884766 seconds
DEBUG 01-15 10:09:27.276812.276812 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.058710575103759766 seconds
DEBUG 01-15 10:09:27.277986.277986 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0515141487121582 seconds
DEBUG 01-15 10:09:27.277258.277258 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.277750.277750 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.278125.278125 cuda_h.py:19] end index_scatter cost 0.0001544952392578125 seconds
DEBUG 01-15 10:09:27.278868.278868 cuda_h.py:19] end cpuoutputsdeal cost 0.0013165473937988281 seconds
DEBUG 01-15 10:09:27.278134.278134 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.278858.278858 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2329c686-7cfc-49f9-86c3-e4de9740edfc
INFO 01-15 10:09:27.279756.279756 client.py:127] Model loaded
DEBUG 01-15 10:09:27.279314.279314 cuda_h.py:19] end wait_experts cost 0.0009741783142089844 seconds
DEBUG 01-15 10:09:27.279209.279209 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.279012.279012 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.279106.279106 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.280830.280830 cuda_h.py:19] end gpu_group_tensor cost 0.0008082389831542969 seconds
DEBUG 01-15 10:09:27.280464.280464 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.281349.281349 cuda_h.py:19] end gpu_group_einsum cost 0.0008459091186523438 seconds
DEBUG 01-15 10:09:27.281889.281889 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.281580.281580 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.282205.282205 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002541542053222656 seconds
DEBUG 01-15 10:09:27.282530.282530 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.282461.282461 cuda_h.py:19] end concat_expert_out cost 5.698204040527344e-05 seconds
DEBUG 01-15 10:09:27.282635.282635 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.282989.282989 cuda_h.py:19] end index_scatter cost 5.221366882324219e-05 seconds
DEBUG 01-15 10:09:27.282321.282321 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005946159362792969 seconds
DEBUG 01-15 10:09:27.282237.282237 cuda_h.py:19] end gpu_experts cost 0.002802133560180664 seconds
DEBUG 01-15 10:09:27.282061.282061 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.07117319107055664 seconds
DEBUG 01-15 10:09:27.283539.283539 cuda_h.py:19] end prefill_layer cost 0.07706499099731445 seconds
DEBUG 01-15 10:09:27.283528.283528 lmp.py:1552] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-15 10:09:27.283754.283754 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.283934.283934 lmp.py:1495] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-15 10:09:27.283451.283451 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:27.283969.283969 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:27.283388.283388 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.528594970703125e-05 seconds
DEBUG 01-15 10:09:27.283906.283906 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:27.283271.283271 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.283194.283194 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.283667.283667 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.283220.283220 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.283494.283494 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.283959.283959 cuda_h.py:19] end allocate_cuda_memory cost 0.0002002716064453125 seconds
DEBUG 01-15 10:09:27.284021.284021 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.284453.284453 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.284137.284137 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.284416.284416 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9841378c-8399-4962-87a4-cda5c3dd5ca5
DEBUG 01-15 10:09:27.284068.284068 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.284275.284275 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.284130.284130 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9841378c-8399-4962-87a4-cda5c3dd5ca5
DEBUG 01-15 10:09:27.285073.285073 cuda_h.py:19] end load_into_gpu_async cost 0.0009126663208007812 seconds
DEBUG 01-15 10:09:27.285114.285114 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.285886.285886 cuda_h.py:19] end restore_tensors2 cost 8.296966552734375e-05 seconds
DEBUG 01-15 10:09:27.285695.285695 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014734268188476562 seconds
INFO 01-15 10:09:27.285353.285353 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9841378c-8399-4962-87a4-cda5c3dd5ca5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.287002.287002 cuda_h.py:19] end self_attn cost 0.0032367706298828125 seconds
DEBUG 01-15 10:09:27.288231.288231 cuda_h.py:19] end iln_self_attn_paln cost 0.004714250564575195 seconds
DEBUG 01-15 10:09:27.288120.288120 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-15 10:09:27.288214.288214 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.288031.288031 cuda_h.py:19] end gate cost 0.0006387233734130859 seconds
DEBUG 01-15 10:09:27.288053.288053 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.289534.289534 lmp.py:1616] 
DEBUG 01-15 10:09:27.289534.289534 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.289575.289575 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.289701.289701 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.289775.289775 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.289179.289179 lmp.py:1620] 
DEBUG 01-15 10:09:27.289179.289179 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.289061.289061 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.289896.289896 lmp.py:1626]   Expert 58 |     51 | CPU
DEBUG 01-15 10:09:27.289062.289062 lmp.py:1626]   Expert 27 |     56 | CPU
DEBUG 01-15 10:09:27.289990.289990 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:27.289440.289440 lmp.py:1626]   Expert 17 |     84 | CPU
DEBUG 01-15 10:09:27.289653.289653 lmp.py:1626]   Expert  0 |     88 | CPU
DEBUG 01-15 10:09:27.289865.289865 lmp.py:1626]   Expert 24 |     88 | CPU
DEBUG 01-15 10:09:27.289316.289316 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:27.289290.289290 lmp.py:1626]   Expert 34 |    114 | CPU
DEBUG 01-15 10:09:27.289741.289741 lmp.py:1626]   Expert 51 |    118 | CPU
DEBUG 01-15 10:09:27.289384.289384 lmp.py:1626]   Expert 32 |    120 | CPU
DEBUG 01-15 10:09:27.289312.289312 lmp.py:1626]   Expert  9 |    129 | CPU
DEBUG 01-15 10:09:27.289240.289240 lmp.py:1626]   Expert 23 |    135 | CPU
DEBUG 01-15 10:09:27.289406.289406 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:27.289532.289532 lmp.py:1626]   Expert 15 |    136 | CPU
DEBUG 01-15 10:09:27.289414.289414 lmp.py:1626]   Expert 26 |    138 | CPU
DEBUG 01-15 10:09:27.289341.289341 lmp.py:1626]   Expert 30 |    144 | CPU
DEBUG 01-15 10:09:27.289269.289269 lmp.py:1626]   Expert 45 |    146 | CPU
DEBUG 01-15 10:09:27.289197.289197 lmp.py:1626]   Expert 62 |    147 | CPU
DEBUG 01-15 10:09:27.289125.289125 lmp.py:1626]   Expert 57 |    150 | CPU
DEBUG 01-15 10:09:27.289052.289052 lmp.py:1626]   Expert  1 |    152 | CPU
DEBUG 01-15 10:09:27.289218.289218 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:27.289338.289338 lmp.py:1626]   Expert  8 |    159 | CPU
DEBUG 01-15 10:09:27.289981.289981 lmp.py:1626]   Expert 29 |    160 | CPU
DEBUG 01-15 10:09:27.289624.289624 lmp.py:1626]   Expert 25 |    165 | CPU
DEBUG 01-15 10:09:27.289029.289029 lmp.py:1626]   Expert 54 |    167 | CPU
DEBUG 01-15 10:09:27.289910.289910 lmp.py:1626]   Expert  6 |    170 | CPU
DEBUG 01-15 10:09:27.289792.289792 lmp.py:1626]   Expert 49 |    171 | CPU
DEBUG 01-15 10:09:27.289673.289673 lmp.py:1626]   Expert 48 |    173 | CPU
DEBUG 01-15 10:09:27.289078.289078 lmp.py:1626]   Expert 12 |    176 | CPU
DEBUG 01-15 10:09:27.289959.289959 lmp.py:1626]   Expert 35 |    176 | CPU
DEBUG 01-15 10:09:27.289363.289363 lmp.py:1626]   Expert 37 |    178 | CPU
DEBUG 01-15 10:09:27.289006.289006 lmp.py:1626]   Expert 60 |    186 | CPU
DEBUG 01-15 10:09:27.289888.289888 lmp.py:1626]   Expert 13 |    188 | GPU
DEBUG 01-15 10:09:27.289769.289769 lmp.py:1626]   Expert 33 |    189 | GPU
DEBUG 01-15 10:09:27.290174.290174 lmp.py:1626]   Expert 53 |    189 | GPU
DEBUG 01-15 10:09:27.290817.290817 lmp.py:1626]   Expert 10 |    194 | GPU
DEBUG 01-15 10:09:27.290221.290221 lmp.py:1626]   Expert 16 |    195 | GPU
DEBUG 01-15 10:09:27.290341.290341 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:27.290746.290746 lmp.py:1626]   Expert 40 |    200 | GPU
DEBUG 01-15 10:09:27.290435.290435 lmp.py:1626]   Expert 43 |    202 | GPU
DEBUG 01-15 10:09:27.290363.290363 lmp.py:1626]   Expert 38 |    204 | GPU
DEBUG 01-15 10:09:27.290529.290529 lmp.py:1626]   Expert  5 |    208 | GPU
DEBUG 01-15 10:09:27.290695.290695 lmp.py:1626]   Expert 44 |    216 | GPU
DEBUG 01-15 10:09:27.290861.290861 lmp.py:1626]   Expert 19 |    217 | GPU
DEBUG 01-15 10:09:27.290504.290504 lmp.py:1626]   Expert 50 |    217 | GPU
DEBUG 01-15 10:09:27.290386.290386 lmp.py:1626]   Expert 52 |    217 | GPU
DEBUG 01-15 10:09:27.290267.290267 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:27.290625.290625 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:27.290268.290268 lmp.py:1626]   Expert 59 |    223 | GPU
DEBUG 01-15 10:09:27.290434.290434 lmp.py:1626]   Expert 55 |    233 | GPU
DEBUG 01-15 10:09:27.290362.290362 lmp.py:1626]   Expert 31 |    241 | GPU
DEBUG 01-15 10:09:27.290290.290290 lmp.py:1626]   Expert 56 |    241 | GPU
DEBUG 01-15 10:09:27.290456.290456 lmp.py:1626]   Expert 20 |    251 | GPU
DEBUG 01-15 10:09:27.290145.290145 lmp.py:1626]   Expert 39 |    252 | GPU
DEBUG 01-15 10:09:27.290311.290311 lmp.py:1626]   Expert 22 |    265 | GPU
DEBUG 01-15 10:09:27.290239.290239 lmp.py:1626]   Expert  2 |    267 | GPU
DEBUG 01-15 10:09:27.290359.290359 lmp.py:1626]   Expert 47 |    276 | GPU
DEBUG 01-15 10:09:27.290763.290763 lmp.py:1626]   Expert 63 |    276 | GPU
DEBUG 01-15 10:09:27.290929.290929 lmp.py:1626]   Expert 42 |    303 | GPU
DEBUG 01-15 10:09:27.290572.290572 lmp.py:1626]   Expert 18 |    314 | GPU
DEBUG 01-15 10:09:27.290977.290977 lmp.py:1626]   Expert 14 |    317 | GPU
DEBUG 01-15 10:09:27.290620.290620 lmp.py:1626]   Expert 46 |    367 | GPU
DEBUG 01-15 10:09:27.290309.290309 lmp.py:1626]   Expert 11 |    387 | GPU
DEBUG 01-15 10:09:27.290237.290237 lmp.py:1626]   Expert 61 |    460 | GPU
DEBUG 01-15 10:09:27.290357.290357 lmp.py:1627] 
DEBUG 01-15 10:09:27.290357.290357 lmp.py:1627]   CPU total tokens: 4341 (35.3%)
DEBUG 01-15 10:09:27.290715.290715 lmp.py:1628]   GPU total tokens: 7947 (64.7%)
DEBUG 01-15 10:09:27.290888.290888 cuda_h.py:19] end experts_map_get cost 0.001569986343383789 seconds
DEBUG 01-15 10:09:27.290215.290215 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.290255.290255 lmp.py:1636] 
DEBUG 01-15 10:09:27.290255.290255 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.290423.290423 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-15 10:09:27.290880.290880 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.290140.290140 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.290159.290159 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.292874.292874 cuda_h.py:19] end allocate_cuda_memory cost 0.001337289810180664 seconds
DEBUG 01-15 10:09:27.292883.292883 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.292116.292116 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.292640.292640 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.292243.292243 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80fc42b0-f783-493b-9c77-d5c18f99d38e
DEBUG 01-15 10:09:27.292117.292117 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:27.293992.293992 client.py:127] Model loaded
DEBUG 01-15 10:09:27.293152.293152 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.293208.293208 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.293323.293323 cuda_h.py:19] end restore2model cost 0.0003407001495361328 seconds
DEBUG 01-15 10:09:27.293994.293994 cuda_h.py:19] end sllm_worker_task cost 0.00984954833984375 seconds
INFO 01-15 10:09:27.293575.293575 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80fc42b0-f783-493b-9c77-d5c18f99d38e
DEBUG 01-15 10:09:27.293133.293133 cuda_h.py:19] end load_into_gpu_async cost 0.0013089179992675781 seconds
DEBUG 01-15 10:09:27.293790.293790 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.293325.293325 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:27.294664.294664 cuda_h.py:19] end restore_tensors2 cost 0.0003724098205566406 seconds
DEBUG 01-15 10:09:27.294739.294739 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003401041030883789 seconds
DEBUG 01-15 10:09:27.294700.294700 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.294608.294608 cuda_h.py:19] end move_flatidxs cost 0.0008823871612548828 seconds
DEBUG 01-15 10:09:27.294200.294200 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.296518.296518 cuda_h.py:19] end restore2model cost 0.0026445388793945312 seconds
DEBUG 01-15 10:09:27.297083.297083 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006236553192138672 seconds
DEBUG 01-15 10:09:27.297356.297356 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.297393.297393 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-15 10:09:27.297030.297030 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.298770.298770 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014929771423339844 seconds
DEBUG 01-15 10:09:27.299842.299842 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.300417.300417 cuda_h.py:19] end gpu_group_list cost 0.00034332275390625 seconds
DEBUG 01-15 10:09:27.300481.300481 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.299072.299072 cuda_h.py:19] end group_tensors cost 0.004853010177612305 seconds
DEBUG 01-15 10:09:27.300512.300512 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.301570.301570 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010249614715576172 seconds
DEBUG 01-15 10:09:27.301579.301579 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.301582.301582 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-15 10:09:27.301192.301192 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.304805.304805 cuda_h.py:19] end group pad cost 0.00394749641418457 seconds
DEBUG 01-15 10:09:27.304217.304217 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.323254.323254 cuda_h.py:19] end group_einsum cost 0.019359111785888672 seconds
DEBUG 01-15 10:09:27.324610.324610 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.328627.328627 cuda_h.py:19] end get_outputs_cpu1 cost 0.0047876834869384766 seconds
DEBUG 01-15 10:09:27.329568.329568 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.036185503005981445 seconds
DEBUG 01-15 10:09:27.330316.330316 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.028965473175048828 seconds
DEBUG 01-15 10:09:27.330234.330234 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.330772.330772 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.330863.330863 cuda_h.py:19] end index_scatter cost 8.0108642578125e-05 seconds
DEBUG 01-15 10:09:27.331474.331474 cuda_h.py:19] end cpuoutputsdeal cost 0.0008039474487304688 seconds
DEBUG 01-15 10:09:27.331019.331019 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.331358.331358 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80fc42b0-f783-493b-9c77-d5c18f99d38e
INFO 01-15 10:09:27.344906.344906 client.py:127] Model loaded
DEBUG 01-15 10:09:27.344034.344034 cuda_h.py:19] end wait_experts cost 0.0128631591796875 seconds
DEBUG 01-15 10:09:27.344611.344611 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.344454.344454 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.344032.344032 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.344728.344728 cuda_h.py:19] end gpu_group_tensor cost 0.00019407272338867188 seconds
DEBUG 01-15 10:09:27.344097.344097 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.345086.345086 cuda_h.py:19] end gpu_group_einsum cost 0.0004367828369140625 seconds
DEBUG 01-15 10:09:27.345315.345315 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.345952.345952 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.345927.345927 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020074844360351562 seconds
DEBUG 01-15 10:09:27.345199.345199 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.346415.346415 cuda_h.py:19] end concat_expert_out cost 0.00026798248291015625 seconds
DEBUG 01-15 10:09:27.346609.346609 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.346692.346692 cuda_h.py:19] end index_scatter cost 6.198883056640625e-05 seconds
DEBUG 01-15 10:09:27.346163.346163 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007660388946533203 seconds
DEBUG 01-15 10:09:27.346728.346728 cuda_h.py:19] end gpu_experts cost 0.0018877983093261719 seconds
DEBUG 01-15 10:09:27.346320.346320 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.05814170837402344 seconds
DEBUG 01-15 10:09:27.346185.346185 cuda_h.py:19] end prefill_layer cost 0.06349039077758789 seconds
DEBUG 01-15 10:09:27.346419.346419 lmp.py:1552] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-15 10:09:27.346116.346116 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.346050.346050 lmp.py:1495] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-15 10:09:27.346130.346130 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:27.346926.346926 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:27.346246.346246 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.0994415283203125e-05 seconds
DEBUG 01-15 10:09:27.346280.346280 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:27.346400.346400 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.347256.347256 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.347974.347974 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.347334.347334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.347025.347025 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.347662.347662 cuda_h.py:19] end allocate_cuda_memory cost 0.0001900196075439453 seconds
DEBUG 01-15 10:09:27.347220.347220 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.347645.347645 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.347414.347414 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.347925.347925 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c342a48d-ec75-4e87-b086-c4597a37008b
DEBUG 01-15 10:09:27.347603.347603 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.347274.347274 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.348504.348504 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c342a48d-ec75-4e87-b086-c4597a37008b
DEBUG 01-15 10:09:27.349460.349460 cuda_h.py:19] end load_into_gpu_async cost 0.0014061927795410156 seconds
DEBUG 01-15 10:09:27.349455.349455 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.349419.349419 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-15 10:09:27.349519.349519 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019276142120361328 seconds
INFO 01-15 10:09:27.349939.349939 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c342a48d-ec75-4e87-b086-c4597a37008b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.351394.351394 cuda_h.py:19] end self_attn cost 0.003538370132446289 seconds
DEBUG 01-15 10:09:27.351497.351497 cuda_h.py:19] end iln_self_attn_paln cost 0.004854917526245117 seconds
DEBUG 01-15 10:09:27.351764.351764 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-15 10:09:27.351904.351904 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.352838.352838 cuda_h.py:19] end gate cost 0.0007612705230712891 seconds
DEBUG 01-15 10:09:27.352952.352952 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.353723.353723 lmp.py:1616] 
DEBUG 01-15 10:09:27.353723.353723 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.353002.353002 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.353890.353890 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.353964.353964 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.353653.353653 lmp.py:1620] 
DEBUG 01-15 10:09:27.353653.353653 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.353581.353581 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.353178.353178 lmp.py:1626]   Expert  1 |     50 | CPU
DEBUG 01-15 10:09:27.353059.353059 lmp.py:1626]   Expert 27 |     62 | CPU
DEBUG 01-15 10:09:27.353987.353987 lmp.py:1626]   Expert  7 |     74 | CPU
DEBUG 01-15 10:09:27.353676.353676 lmp.py:1626]   Expert 48 |     81 | CPU
DEBUG 01-15 10:09:27.353319.353319 lmp.py:1626]   Expert 15 |     97 | CPU
DEBUG 01-15 10:09:27.353247.353247 lmp.py:1626]   Expert 30 |    109 | CPU
DEBUG 01-15 10:09:27.353936.353936 lmp.py:1626]   Expert 61 |    115 | CPU
DEBUG 01-15 10:09:27.353625.353625 lmp.py:1626]   Expert 32 |    117 | CPU
DEBUG 01-15 10:09:27.353553.353553 lmp.py:1626]   Expert 18 |    119 | CPU
DEBUG 01-15 10:09:27.353004.353004 lmp.py:1626]   Expert 45 |    119 | CPU
DEBUG 01-15 10:09:27.353693.353693 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:27.353906.353906 lmp.py:1626]   Expert 39 |    136 | CPU
DEBUG 01-15 10:09:27.353118.353118 lmp.py:1626]   Expert 26 |    139 | CPU
DEBUG 01-15 10:09:27.353569.353569 lmp.py:1626]   Expert 36 |    139 | CPU
DEBUG 01-15 10:09:27.353543.353543 lmp.py:1626]   Expert 11 |    140 | CPU
DEBUG 01-15 10:09:27.353994.353994 lmp.py:1626]   Expert  5 |    141 | CPU
DEBUG 01-15 10:09:27.353206.353206 lmp.py:1626]   Expert 59 |    142 | CPU
DEBUG 01-15 10:09:27.353180.353180 lmp.py:1626]   Expert  6 |    145 | CPU
DEBUG 01-15 10:09:27.353108.353108 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:27.353559.353559 lmp.py:1626]   Expert 23 |    155 | CPU
DEBUG 01-15 10:09:27.353586.353586 lmp.py:1626]   Expert 49 |    155 | CPU
DEBUG 01-15 10:09:27.353991.353991 lmp.py:1626]   Expert  2 |    158 | CPU
DEBUG 01-15 10:09:27.353442.353442 lmp.py:1626]   Expert  9 |    159 | CPU
DEBUG 01-15 10:09:27.353131.353131 lmp.py:1626]   Expert 50 |    165 | CPU
DEBUG 01-15 10:09:27.353343.353343 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:27.353794.353794 lmp.py:1626]   Expert 56 |    168 | CPU
DEBUG 01-15 10:09:27.353768.353768 lmp.py:1626]   Expert 40 |    169 | CPU
DEBUG 01-15 10:09:27.353650.353650 lmp.py:1626]   Expert 16 |    170 | CPU
DEBUG 01-15 10:09:27.353577.353577 lmp.py:1626]   Expert 35 |    175 | CPU
DEBUG 01-15 10:09:27.353744.353744 lmp.py:1626]   Expert  4 |    184 | CPU
DEBUG 01-15 10:09:27.353910.353910 lmp.py:1626]   Expert 37 |    189 | CPU
DEBUG 01-15 10:09:27.353837.353837 lmp.py:1626]   Expert 13 |    191 | CPU
DEBUG 01-15 10:09:27.353765.353765 lmp.py:1626]   Expert 42 |    191 | GPU
DEBUG 01-15 10:09:27.353693.353693 lmp.py:1626]   Expert 17 |    197 | GPU
DEBUG 01-15 10:09:27.353859.353859 lmp.py:1626]   Expert 38 |    197 | GPU
DEBUG 01-15 10:09:27.353502.353502 lmp.py:1626]   Expert 62 |    199 | GPU
DEBUG 01-15 10:09:27.353907.353907 lmp.py:1626]   Expert 21 |    202 | GPU
DEBUG 01-15 10:09:27.353549.353549 lmp.py:1626]   Expert  3 |    208 | GPU
DEBUG 01-15 10:09:27.353954.353954 lmp.py:1626]   Expert 44 |    209 | GPU
DEBUG 01-15 10:09:27.353882.353882 lmp.py:1626]   Expert 60 |    211 | GPU
DEBUG 01-15 10:09:27.353048.353048 lmp.py:1626]   Expert 28 |    212 | GPU
DEBUG 01-15 10:09:27.353214.353214 lmp.py:1626]   Expert 58 |    213 | GPU
DEBUG 01-15 10:09:27.353619.353619 lmp.py:1626]   Expert 47 |    214 | GPU
DEBUG 01-15 10:09:27.353546.353546 lmp.py:1626]   Expert 10 |    215 | GPU
DEBUG 01-15 10:09:27.353236.353236 lmp.py:1626]   Expert 53 |    218 | GPU
DEBUG 01-15 10:09:27.353925.353925 lmp.py:1626]   Expert 55 |    220 | GPU
DEBUG 01-15 10:09:27.354091.354091 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:27.354019.354019 lmp.py:1626]   Expert 57 |    225 | GPU
DEBUG 01-15 10:09:27.354946.354946 lmp.py:1626]   Expert 33 |    227 | GPU
DEBUG 01-15 10:09:27.354066.354066 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:27.354471.354471 lmp.py:1626]   Expert 46 |    237 | GPU
DEBUG 01-15 10:09:27.354114.354114 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:27.354518.354518 lmp.py:1626]   Expert 19 |    242 | GPU
DEBUG 01-15 10:09:27.354923.354923 lmp.py:1626]   Expert 24 |    247 | GPU
DEBUG 01-15 10:09:27.354851.354851 lmp.py:1626]   Expert 14 |    261 | GPU
DEBUG 01-15 10:09:27.354778.354778 lmp.py:1626]   Expert 63 |    267 | GPU
DEBUG 01-15 10:09:27.354706.354706 lmp.py:1626]   Expert 29 |    275 | GPU
DEBUG 01-15 10:09:27.354634.354634 lmp.py:1626]   Expert 12 |    276 | GPU
DEBUG 01-15 10:09:27.354323.354323 lmp.py:1626]   Expert 22 |    278 | GPU
DEBUG 01-15 10:09:27.354251.354251 lmp.py:1626]   Expert  0 |    295 | GPU
DEBUG 01-15 10:09:27.354417.354417 lmp.py:1626]   Expert 43 |    310 | GPU
DEBUG 01-15 10:09:27.354345.354345 lmp.py:1626]   Expert 54 |    339 | GPU
DEBUG 01-15 10:09:27.354272.354272 lmp.py:1626]   Expert 41 |    383 | GPU
DEBUG 01-15 10:09:27.354439.354439 lmp.py:1626]   Expert 25 |    410 | GPU
DEBUG 01-15 10:09:27.354558.354558 lmp.py:1627] 
DEBUG 01-15 10:09:27.354558.354558 lmp.py:1627]   CPU total tokens: 4409 (35.9%)
DEBUG 01-15 10:09:27.354632.354632 lmp.py:1628]   GPU total tokens: 7879 (64.1%)
DEBUG 01-15 10:09:27.354805.354805 cuda_h.py:19] end experts_map_get cost 0.0015146732330322266 seconds
DEBUG 01-15 10:09:27.354701.354701 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.354834.354834 lmp.py:1636] 
DEBUG 01-15 10:09:27.354834.354834 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.354094.354094 cuda_h.py:19] end cpu_experts_submit cost 5.030632019042969e-05 seconds
DEBUG 01-15 10:09:27.354314.354314 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.354620.354620 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.354347.354347 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.355206.355206 cuda_h.py:19] end allocate_cuda_memory cost 0.0007050037384033203 seconds
DEBUG 01-15 10:09:27.355950.355950 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.355845.355845 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.355177.355177 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.355542.355542 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4bf11aeb-2538-45ea-beaf-5c67d8ccac8d
DEBUG 01-15 10:09:27.355601.355601 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:27.356342.356342 client.py:127] Model loaded
DEBUG 01-15 10:09:27.356775.356775 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.356047.356047 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.356089.356089 cuda_h.py:19] end restore2model cost 0.0004343986511230469 seconds
DEBUG 01-15 10:09:27.356872.356872 cuda_h.py:19] end sllm_worker_task cost 0.009532451629638672 seconds
DEBUG 01-15 10:09:27.356919.356919 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:27.357388.357388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4bf11aeb-2538-45ea-beaf-5c67d8ccac8d
DEBUG 01-15 10:09:27.357238.357238 cuda_h.py:19] end load_into_gpu_async cost 0.002252817153930664 seconds
DEBUG 01-15 10:09:27.357047.357047 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.357182.357182 cuda_h.py:19] end move_flatidxs cost 0.0008625984191894531 seconds
DEBUG 01-15 10:09:27.357157.357157 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.358348.358348 cuda_h.py:19] end restore_tensors2 cost 0.00043511390686035156 seconds
DEBUG 01-15 10:09:27.358774.358774 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037751197814941406 seconds
DEBUG 01-15 10:09:27.358312.358312 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.361070.361070 cuda_h.py:19] end restore2model cost 0.002635955810546875 seconds
DEBUG 01-15 10:09:27.361343.361343 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006600379943847656 seconds
DEBUG 01-15 10:09:27.361331.361331 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.361685.361685 cuda_h.py:19] end gpu_sexperts cost 0.0002617835998535156 seconds
DEBUG 01-15 10:09:27.361369.361369 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.363029.363029 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014674663543701172 seconds
DEBUG 01-15 10:09:27.363749.363749 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.364332.364332 cuda_h.py:19] end gpu_group_list cost 0.00034809112548828125 seconds
DEBUG 01-15 10:09:27.364527.364527 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.363341.363341 cuda_h.py:19] end group_tensors cost 0.005849599838256836 seconds
DEBUG 01-15 10:09:27.364222.364222 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.365770.365770 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0008652210235595703 seconds
DEBUG 01-15 10:09:27.365229.365229 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.365701.365701 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-15 10:09:27.365272.365272 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.368336.368336 cuda_h.py:19] end group pad cost 0.004126071929931641 seconds
DEBUG 01-15 10:09:27.368047.368047 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.388172.388172 cuda_h.py:19] end group_einsum cost 0.01987147331237793 seconds
DEBUG 01-15 10:09:27.389449.389449 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.393251.393251 cuda_h.py:19] end get_outputs_cpu1 cost 0.004863739013671875 seconds
DEBUG 01-15 10:09:27.394675.394675 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0380556583404541 seconds
DEBUG 01-15 10:09:27.395898.395898 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.030290842056274414 seconds
DEBUG 01-15 10:09:27.395237.395237 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.396334.396334 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.397916.397916 cuda_h.py:19] end index_scatter cost 0.000171661376953125 seconds
DEBUG 01-15 10:09:27.397967.397967 cuda_h.py:19] end cpuoutputsdeal cost 0.0015375614166259766 seconds
DEBUG 01-15 10:09:27.397326.397326 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.397526.397526 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4bf11aeb-2538-45ea-beaf-5c67d8ccac8d
INFO 01-15 10:09:27.407571.407571 client.py:127] Model loaded
DEBUG 01-15 10:09:27.407759.407759 cuda_h.py:19] end wait_experts cost 0.010111808776855469 seconds
DEBUG 01-15 10:09:27.407985.407985 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.407775.407775 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.407908.407908 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.408611.408611 cuda_h.py:19] end gpu_group_tensor cost 0.0002071857452392578 seconds
DEBUG 01-15 10:09:27.408397.408397 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.408938.408938 cuda_h.py:19] end gpu_group_einsum cost 0.0004961490631103516 seconds
DEBUG 01-15 10:09:27.408842.408842 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.408533.408533 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.409137.409137 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002040863037109375 seconds
DEBUG 01-15 10:09:27.409508.409508 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.409571.409571 cuda_h.py:19] end concat_expert_out cost 5.1975250244140625e-05 seconds
DEBUG 01-15 10:09:27.409891.409891 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.409298.409298 cuda_h.py:19] end index_scatter cost 5.8650970458984375e-05 seconds
DEBUG 01-15 10:09:27.409868.409868 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005381107330322266 seconds
DEBUG 01-15 10:09:27.409010.409010 cuda_h.py:19] end gpu_experts cost 0.0017163753509521484 seconds
DEBUG 01-15 10:09:27.409688.409688 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.05763888359069824 seconds
DEBUG 01-15 10:09:27.409688.409688 cuda_h.py:19] end prefill_layer cost 0.0631411075592041 seconds
DEBUG 01-15 10:09:27.410213.410213 lmp.py:1552] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-15 10:09:27.410055.410055 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.410182.410182 lmp.py:1495] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-15 10:09:27.410308.410308 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:27.410819.410819 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:27.410900.410900 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.9802322387695312e-05 seconds
DEBUG 01-15 10:09:27.410173.410173 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.079673767089844e-05 seconds
DEBUG 01-15 10:09:27.410769.410769 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.410971.410971 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.410172.410172 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.410845.410845 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.410953.410953 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.410389.410389 cuda_h.py:19] end allocate_cuda_memory cost 0.0003097057342529297 seconds
DEBUG 01-15 10:09:27.411194.411194 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.411063.411063 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.411753.411753 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.411417.411417 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22b42c83-f089-43b5-aa6d-7f9fdafb6087
DEBUG 01-15 10:09:27.411506.411506 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.411234.411234 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.412781.412781 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22b42c83-f089-43b5-aa6d-7f9fdafb6087
DEBUG 01-15 10:09:27.412154.412154 cuda_h.py:19] end load_into_gpu_async cost 0.0015423297882080078 seconds
DEBUG 01-15 10:09:27.412056.412056 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.412027.412027 cuda_h.py:19] end restore_tensors2 cost 8.535385131835938e-05 seconds
DEBUG 01-15 10:09:27.412127.412127 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022592544555664062 seconds
INFO 01-15 10:09:27.412964.412964 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22b42c83-f089-43b5-aa6d-7f9fdafb6087
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.414556.414556 cuda_h.py:19] end self_attn cost 0.0034046173095703125 seconds
DEBUG 01-15 10:09:27.415056.415056 cuda_h.py:19] end iln_self_attn_paln cost 0.004956245422363281 seconds
DEBUG 01-15 10:09:27.415515.415515 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-15 10:09:27.415370.415370 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.416426.416426 cuda_h.py:19] end gate cost 0.0006399154663085938 seconds
DEBUG 01-15 10:09:27.416447.416447 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.416424.416424 lmp.py:1616] 
DEBUG 01-15 10:09:27.416424.416424 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.416194.416194 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.416228.416228 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.416493.416493 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.416613.416613 lmp.py:1620] 
DEBUG 01-15 10:09:27.416613.416613 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.416733.416733 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.416283.416283 lmp.py:1626]   Expert 14 |     66 | CPU
DEBUG 01-15 10:09:27.416165.416165 lmp.py:1626]   Expert 57 |     72 | CPU
DEBUG 01-15 10:09:27.416907.416907 lmp.py:1626]   Expert 13 |     75 | CPU
DEBUG 01-15 10:09:27.416312.416312 lmp.py:1626]   Expert 26 |     80 | CPU
DEBUG 01-15 10:09:27.416478.416478 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:27.416405.416405 lmp.py:1626]   Expert 11 |     93 | CPU
DEBUG 01-15 10:09:27.416095.416095 lmp.py:1626]   Expert 54 |     93 | CPU
DEBUG 01-15 10:09:27.416645.416645 lmp.py:1626]   Expert 45 |     95 | CPU
DEBUG 01-15 10:09:27.416050.416050 lmp.py:1626]   Expert 58 |    101 | CPU
DEBUG 01-15 10:09:27.416408.416408 lmp.py:1626]   Expert 30 |    107 | CPU
DEBUG 01-15 10:09:27.416289.416289 lmp.py:1626]   Expert 51 |    109 | CPU
DEBUG 01-15 10:09:27.416932.416932 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:27.416337.416337 lmp.py:1626]   Expert 10 |    114 | CPU
DEBUG 01-15 10:09:27.416218.416218 lmp.py:1626]   Expert 32 |    115 | CPU
DEBUG 01-15 10:09:27.416245.416245 lmp.py:1626]   Expert 20 |    126 | CPU
DEBUG 01-15 10:09:27.416888.416888 lmp.py:1626]   Expert  8 |    133 | CPU
DEBUG 01-15 10:09:27.416054.416054 lmp.py:1626]   Expert 63 |    137 | CPU
DEBUG 01-15 10:09:27.416459.416459 lmp.py:1626]   Expert  4 |    138 | CPU
DEBUG 01-15 10:09:27.416625.416625 lmp.py:1626]   Expert 53 |    141 | CPU
DEBUG 01-15 10:09:27.416553.416553 lmp.py:1626]   Expert 34 |    143 | CPU
DEBUG 01-15 10:09:27.416626.416626 lmp.py:1626]   Expert 61 |    144 | CPU
DEBUG 01-15 10:09:27.416792.416792 lmp.py:1626]   Expert 47 |    147 | CPU
DEBUG 01-15 10:09:27.416488.416488 lmp.py:1626]   Expert 16 |    148 | CPU
DEBUG 01-15 10:09:27.416655.416655 lmp.py:1626]   Expert 28 |    159 | CPU
DEBUG 01-15 10:09:27.416582.416582 lmp.py:1626]   Expert 60 |    159 | CPU
DEBUG 01-15 10:09:27.416510.416510 lmp.py:1626]   Expert 17 |    163 | CPU
DEBUG 01-15 10:09:27.416676.416676 lmp.py:1626]   Expert 42 |    165 | CPU
DEBUG 01-15 10:09:27.416796.416796 lmp.py:1626]   Expert 29 |    170 | CPU
DEBUG 01-15 10:09:27.417247.417247 lmp.py:1626]   Expert 44 |    170 | CPU
DEBUG 01-15 10:09:27.417459.417459 lmp.py:1626]   Expert 27 |    174 | CPU
DEBUG 01-15 10:09:27.417195.417195 lmp.py:1626]   Expert  7 |    176 | CPU
DEBUG 01-15 10:09:27.417407.417407 lmp.py:1626]   Expert 41 |    179 | CPU
DEBUG 01-15 10:09:27.417382.417382 lmp.py:1626]   Expert 48 |    183 | GPU
DEBUG 01-15 10:09:27.417786.417786 lmp.py:1626]   Expert  9 |    184 | GPU
DEBUG 01-15 10:09:27.417475.417475 lmp.py:1626]   Expert 56 |    184 | GPU
DEBUG 01-15 10:09:27.417641.417641 lmp.py:1626]   Expert  2 |    187 | GPU
DEBUG 01-15 10:09:27.417569.417569 lmp.py:1626]   Expert  3 |    188 | GPU
DEBUG 01-15 10:09:27.417497.417497 lmp.py:1626]   Expert 15 |    190 | GPU
DEBUG 01-15 10:09:27.417186.417186 lmp.py:1626]   Expert  0 |    194 | GPU
DEBUG 01-15 10:09:27.417637.417637 lmp.py:1626]   Expert 24 |    194 | GPU
DEBUG 01-15 10:09:27.417850.417850 lmp.py:1626]   Expert 18 |    200 | GPU
DEBUG 01-15 10:09:27.417208.417208 lmp.py:1626]   Expert 55 |    206 | GPU
DEBUG 01-15 10:09:27.417659.417659 lmp.py:1626]   Expert 40 |    213 | GPU
DEBUG 01-15 10:09:27.417633.417633 lmp.py:1626]   Expert 23 |    215 | GPU
DEBUG 01-15 10:09:27.417368.417368 lmp.py:1626]   Expert 38 |    216 | GPU
DEBUG 01-15 10:09:27.417342.417342 lmp.py:1626]   Expert 22 |    217 | GPU
DEBUG 01-15 10:09:27.417316.417316 lmp.py:1626]   Expert 37 |    222 | GPU
DEBUG 01-15 10:09:27.417198.417198 lmp.py:1626]   Expert  6 |    223 | GPU
DEBUG 01-15 10:09:27.417410.417410 lmp.py:1626]   Expert 46 |    231 | GPU
DEBUG 01-15 10:09:27.417623.417623 lmp.py:1626]   Expert 19 |    245 | GPU
DEBUG 01-15 10:09:27.417835.417835 lmp.py:1626]   Expert 39 |    249 | GPU
DEBUG 01-15 10:09:27.417571.417571 lmp.py:1626]   Expert 25 |    251 | GPU
DEBUG 01-15 10:09:27.417022.417022 lmp.py:1626]   Expert 50 |    257 | GPU
DEBUG 01-15 10:09:27.417949.417949 lmp.py:1626]   Expert 12 |    258 | GPU
DEBUG 01-15 10:09:27.417877.417877 lmp.py:1626]   Expert 62 |    270 | GPU
DEBUG 01-15 10:09:27.417566.417566 lmp.py:1626]   Expert 21 |    280 | GPU
DEBUG 01-15 10:09:27.417494.417494 lmp.py:1626]   Expert 35 |    286 | GPU
DEBUG 01-15 10:09:27.417945.417945 lmp.py:1626]   Expert 49 |    291 | GPU
DEBUG 01-15 10:09:27.417303.417303 lmp.py:1626]   Expert 52 |    300 | GPU
DEBUG 01-15 10:09:27.417754.417754 lmp.py:1626]   Expert 33 |    302 | GPU
DEBUG 01-15 10:09:27.417967.417967 lmp.py:1626]   Expert  1 |    348 | GPU
DEBUG 01-15 10:09:27.417941.417941 lmp.py:1626]   Expert  5 |    384 | GPU
DEBUG 01-15 10:09:27.417915.417915 lmp.py:1626]   Expert 43 |    438 | GPU
DEBUG 01-15 10:09:27.417889.417889 lmp.py:1626]   Expert 59 |    586 | GPU
DEBUG 01-15 10:09:27.417485.417485 lmp.py:1627] 
DEBUG 01-15 10:09:27.417485.417485 lmp.py:1627]   CPU total tokens: 4096 (33.3%)
DEBUG 01-15 10:09:27.417367.417367 lmp.py:1628]   GPU total tokens: 8192 (66.7%)
DEBUG 01-15 10:09:27.417255.417255 cuda_h.py:19] end experts_map_get cost 0.0015499591827392578 seconds
DEBUG 01-15 10:09:27.417820.417820 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.417960.417960 lmp.py:1636] 
DEBUG 01-15 10:09:27.417960.417960 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.417128.417128 cuda_h.py:19] end cpu_experts_submit cost 5.245208740234375e-05 seconds
DEBUG 01-15 10:09:27.417016.417016 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.417230.417230 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.418493.418493 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.418067.418067 cuda_h.py:19] end allocate_cuda_memory cost 0.0006082057952880859 seconds
DEBUG 01-15 10:09:27.419056.419056 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.419381.419381 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.419237.419237 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.419602.419602 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 63a3adb6-c48a-4091-811f-355bd39f79ac
DEBUG 01-15 10:09:27.419687.419687 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.419105.419105 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.419640.419640 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:27.419774.419774 client.py:127] Model loaded
DEBUG 01-15 10:09:27.419425.419425 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.420524.420524 cuda_h.py:19] end restore2model cost 0.0005228519439697266 seconds
DEBUG 01-15 10:09:27.420373.420373 cuda_h.py:19] end sllm_worker_task cost 0.009665727615356445 seconds
DEBUG 01-15 10:09:27.420972.420972 cuda_h.py:19] end move_flatidxs cost 0.0009331703186035156 seconds
DEBUG 01-15 10:09:27.420650.420650 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:27.421862.421862 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 63a3adb6-c48a-4091-811f-355bd39f79ac
DEBUG 01-15 10:09:27.421580.421580 cuda_h.py:19] end load_into_gpu_async cost 0.002179861068725586 seconds
DEBUG 01-15 10:09:27.421952.421952 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.421093.421093 cuda_h.py:19] end restore_tensors2 cost 0.00042366981506347656 seconds
DEBUG 01-15 10:09:27.421658.421658 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003871440887451172 seconds
DEBUG 01-15 10:09:27.421812.421812 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.424566.424566 cuda_h.py:19] end restore2model cost 0.0025284290313720703 seconds
DEBUG 01-15 10:09:27.424774.424774 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006597995758056641 seconds
DEBUG 01-15 10:09:27.424908.424908 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.424667.424667 cuda_h.py:19] end gpu_sexperts cost 0.00028014183044433594 seconds
DEBUG 01-15 10:09:27.424542.424542 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.426416.426416 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001522064208984375 seconds
DEBUG 01-15 10:09:27.427641.427641 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.427165.427165 cuda_h.py:19] end gpu_group_list cost 0.00036072731018066406 seconds
DEBUG 01-15 10:09:27.427282.427282 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.428123.428123 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007386207580566406 seconds
DEBUG 01-15 10:09:27.428045.428045 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.428629.428629 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-15 10:09:27.428087.428087 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.428881.428881 cuda_h.py:19] end group_tensors cost 0.007438182830810547 seconds
DEBUG 01-15 10:09:27.428429.428429 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.433656.433656 cuda_h.py:19] end group pad cost 0.004130125045776367 seconds
DEBUG 01-15 10:09:27.433977.433977 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.453267.453267 cuda_h.py:19] end group_einsum cost 0.01962900161743164 seconds
DEBUG 01-15 10:09:27.453805.453805 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.458439.458439 cuda_h.py:19] end get_outputs_cpu1 cost 0.004786014556884766 seconds
DEBUG 01-15 10:09:27.458534.458534 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03982210159301758 seconds
DEBUG 01-15 10:09:27.460235.460235 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031626224517822266 seconds
DEBUG 01-15 10:09:27.460985.460985 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.461672.461672 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.461833.461833 cuda_h.py:19] end index_scatter cost 9.036064147949219e-05 seconds
DEBUG 01-15 10:09:27.462880.462880 cuda_h.py:19] end cpuoutputsdeal cost 0.0013737678527832031 seconds
DEBUG 01-15 10:09:27.462570.462570 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.462485.462485 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 63a3adb6-c48a-4091-811f-355bd39f79ac
INFO 01-15 10:09:27.471242.471242 client.py:127] Model loaded
DEBUG 01-15 10:09:27.471701.471701 cuda_h.py:19] end wait_experts cost 0.009228944778442383 seconds
DEBUG 01-15 10:09:27.471451.471451 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.471287.471287 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.471182.471182 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.472403.472403 cuda_h.py:19] end gpu_group_tensor cost 0.0004372596740722656 seconds
DEBUG 01-15 10:09:27.472858.472858 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.472901.472901 cuda_h.py:19] end gpu_group_einsum cost 0.0006546974182128906 seconds
DEBUG 01-15 10:09:27.473990.473990 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.473297.473297 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.473086.473086 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020313262939453125 seconds
DEBUG 01-15 10:09:27.473550.473550 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.473513.473513 cuda_h.py:19] end concat_expert_out cost 5.030632019042969e-05 seconds
DEBUG 01-15 10:09:27.473303.473303 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.473988.473988 cuda_h.py:19] end index_scatter cost 5.435943603515625e-05 seconds
DEBUG 01-15 10:09:27.473267.473267 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005183219909667969 seconds
DEBUG 01-15 10:09:27.473647.473647 cuda_h.py:19] end gpu_experts cost 0.002086162567138672 seconds
DEBUG 01-15 10:09:27.473504.473504 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.05838942527770996 seconds
DEBUG 01-15 10:09:27.474839.474839 cuda_h.py:19] end prefill_layer cost 0.06392931938171387 seconds
DEBUG 01-15 10:09:27.474166.474166 lmp.py:1552] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-15 10:09:27.474338.474338 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.474227.474227 lmp.py:1495] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-15 10:09:27.474592.474592 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:27.474864.474864 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:27.474747.474747 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.0517578125e-05 seconds
DEBUG 01-15 10:09:27.474112.474112 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.602836608886719e-05 seconds
DEBUG 01-15 10:09:27.474993.474993 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.474810.474810 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.474150.474150 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.474465.474465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.474155.474155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.474097.474097 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-15 10:09:27.474682.474682 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.474492.474492 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.474930.474930 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.475487.475487 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 28a02f67-b06a-4fe1-8d0f-873231ef78dc
DEBUG 01-15 10:09:27.475258.475258 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.475768.475768 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.475619.475619 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 28a02f67-b06a-4fe1-8d0f-873231ef78dc
DEBUG 01-15 10:09:27.475163.475163 cuda_h.py:19] end load_into_gpu_async cost 0.0008816719055175781 seconds
DEBUG 01-15 10:09:27.475005.475005 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.475519.475519 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-15 10:09:27.475321.475321 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014064311981201172 seconds
INFO 01-15 10:09:27.476773.476773 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 28a02f67-b06a-4fe1-8d0f-873231ef78dc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.478499.478499 cuda_h.py:19] end self_attn cost 0.0035698413848876953 seconds
DEBUG 01-15 10:09:27.479939.479939 cuda_h.py:19] end iln_self_attn_paln cost 0.004884004592895508 seconds
DEBUG 01-15 10:09:27.479775.479775 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-15 10:09:27.479200.479200 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.479004.479004 cuda_h.py:19] end gate cost 0.0006306171417236328 seconds
DEBUG 01-15 10:09:27.480356.480356 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.480697.480697 lmp.py:1616] 
DEBUG 01-15 10:09:27.480697.480697 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.480499.480499 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.480196.480196 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.480507.480507 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.480435.480435 lmp.py:1620] 
DEBUG 01-15 10:09:27.480435.480435 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.480184.480184 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.480212.480212 lmp.py:1626]   Expert 34 |     23 | CPU
DEBUG 01-15 10:09:27.480285.480285 lmp.py:1626]   Expert 45 |     66 | CPU
DEBUG 01-15 10:09:27.480882.480882 lmp.py:1626]   Expert 22 |     73 | CPU
DEBUG 01-15 10:09:27.480763.480763 lmp.py:1626]   Expert 57 |     77 | CPU
DEBUG 01-15 10:09:27.480644.480644 lmp.py:1626]   Expert 17 |     96 | CPU
DEBUG 01-15 10:09:27.480764.480764 lmp.py:1626]   Expert  4 |     99 | CPU
DEBUG 01-15 10:09:27.480507.480507 lmp.py:1626]   Expert 15 |    100 | CPU
DEBUG 01-15 10:09:27.480673.480673 lmp.py:1626]   Expert 28 |    107 | CPU
DEBUG 01-15 10:09:27.480839.480839 lmp.py:1626]   Expert 60 |    111 | CPU
DEBUG 01-15 10:09:27.480005.480005 lmp.py:1626]   Expert 32 |    113 | CPU
DEBUG 01-15 10:09:27.480171.480171 lmp.py:1626]   Expert 36 |    123 | CPU
DEBUG 01-15 10:09:27.480576.480576 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:27.480742.480742 lmp.py:1626]   Expert 14 |    128 | CPU
DEBUG 01-15 10:09:27.480908.480908 lmp.py:1626]   Expert 12 |    129 | CPU
DEBUG 01-15 10:09:27.480789.480789 lmp.py:1626]   Expert 25 |    130 | CPU
DEBUG 01-15 10:09:27.480909.480909 lmp.py:1626]   Expert 52 |    130 | CPU
DEBUG 01-15 10:09:27.480029.480029 lmp.py:1626]   Expert  8 |    134 | CPU
DEBUG 01-15 10:09:27.480864.480864 lmp.py:1626]   Expert  2 |    139 | CPU
DEBUG 01-15 10:09:27.480507.480507 lmp.py:1626]   Expert 35 |    142 | CPU
DEBUG 01-15 10:09:27.480673.480673 lmp.py:1626]   Expert  5 |    147 | CPU
DEBUG 01-15 10:09:27.480601.480601 lmp.py:1626]   Expert 23 |    153 | CPU
DEBUG 01-15 10:09:27.480006.480006 lmp.py:1626]   Expert 30 |    153 | CPU
DEBUG 01-15 10:09:27.480172.480172 lmp.py:1626]   Expert 39 |    157 | CPU
DEBUG 01-15 10:09:27.480338.480338 lmp.py:1626]   Expert 61 |    157 | CPU
DEBUG 01-15 10:09:27.480742.480742 lmp.py:1626]   Expert  0 |    158 | CPU
DEBUG 01-15 10:09:27.480909.480909 lmp.py:1626]   Expert  3 |    168 | CPU
DEBUG 01-15 10:09:27.480790.480790 lmp.py:1626]   Expert 13 |    170 | CPU
DEBUG 01-15 10:09:27.480433.480433 lmp.py:1626]   Expert 42 |    172 | CPU
DEBUG 01-15 10:09:27.480553.480553 lmp.py:1626]   Expert 44 |    174 | CPU
DEBUG 01-15 10:09:27.480673.480673 lmp.py:1626]   Expert 41 |    176 | CPU
DEBUG 01-15 10:09:27.480315.480315 lmp.py:1626]   Expert  9 |    177 | CPU
DEBUG 01-15 10:09:27.480243.480243 lmp.py:1626]   Expert 31 |    177 | CPU
DEBUG 01-15 10:09:27.480409.480409 lmp.py:1626]   Expert 46 |    178 | GPU
DEBUG 01-15 10:09:27.481099.481099 lmp.py:1626]   Expert 43 |    182 | GPU
DEBUG 01-15 10:09:27.481265.481265 lmp.py:1626]   Expert 26 |    191 | GPU
DEBUG 01-15 10:09:27.481193.481193 lmp.py:1626]   Expert 62 |    191 | GPU
DEBUG 01-15 10:09:27.481359.481359 lmp.py:1626]   Expert 50 |    193 | GPU
DEBUG 01-15 10:09:27.481286.481286 lmp.py:1626]   Expert 18 |    194 | GPU
DEBUG 01-15 10:09:27.481691.481691 lmp.py:1626]   Expert 27 |    194 | GPU
DEBUG 01-15 10:09:27.481572.481572 lmp.py:1626]   Expert 49 |    195 | GPU
DEBUG 01-15 10:09:27.481215.481215 lmp.py:1626]   Expert 51 |    195 | GPU
DEBUG 01-15 10:09:27.481574.481574 lmp.py:1626]   Expert 11 |    199 | GPU
DEBUG 01-15 10:09:27.481693.481693 lmp.py:1626]   Expert 47 |    202 | GPU
DEBUG 01-15 10:09:27.481859.481859 lmp.py:1626]   Expert 19 |    203 | GPU
DEBUG 01-15 10:09:27.481264.481264 lmp.py:1626]   Expert 63 |    205 | GPU
DEBUG 01-15 10:09:27.481430.481430 lmp.py:1626]   Expert 20 |    206 | GPU
DEBUG 01-15 10:09:27.481596.481596 lmp.py:1626]   Expert 55 |    210 | GPU
DEBUG 01-15 10:09:27.481001.481001 lmp.py:1626]   Expert 56 |    211 | GPU
DEBUG 01-15 10:09:27.481167.481167 lmp.py:1626]   Expert 38 |    217 | GPU
DEBUG 01-15 10:09:27.481095.481095 lmp.py:1626]   Expert 48 |    228 | GPU
DEBUG 01-15 10:09:27.481738.481738 lmp.py:1626]   Expert  1 |    236 | GPU
DEBUG 01-15 10:09:27.481619.481619 lmp.py:1626]   Expert 10 |    240 | GPU
DEBUG 01-15 10:09:27.481739.481739 lmp.py:1626]   Expert 21 |    247 | GPU
DEBUG 01-15 10:09:27.481620.481620 lmp.py:1626]   Expert  7 |    249 | GPU
DEBUG 01-15 10:09:27.481502.481502 lmp.py:1626]   Expert 54 |    249 | GPU
DEBUG 01-15 10:09:27.481668.481668 lmp.py:1626]   Expert 33 |    254 | GPU
DEBUG 01-15 10:09:27.481596.481596 lmp.py:1626]   Expert 29 |    260 | GPU
DEBUG 01-15 10:09:27.481762.481762 lmp.py:1626]   Expert 40 |    265 | GPU
DEBUG 01-15 10:09:27.481213.481213 lmp.py:1626]   Expert 24 |    270 | GPU
DEBUG 01-15 10:09:27.481379.481379 lmp.py:1626]   Expert 59 |    299 | GPU
DEBUG 01-15 10:09:27.481306.481306 lmp.py:1626]   Expert 37 |    332 | GPU
DEBUG 01-15 10:09:27.481473.481473 lmp.py:1626]   Expert 58 |    364 | GPU
DEBUG 01-15 10:09:27.481639.481639 lmp.py:1626]   Expert  6 |    389 | GPU
DEBUG 01-15 10:09:27.481805.481805 lmp.py:1626]   Expert 53 |    855 | GPU
DEBUG 01-15 10:09:27.481163.481163 lmp.py:1627] 
DEBUG 01-15 10:09:27.481163.481163 lmp.py:1627]   CPU total tokens: 4185 (34.1%)
DEBUG 01-15 10:09:27.481574.481574 lmp.py:1628]   GPU total tokens: 8103 (65.9%)
DEBUG 01-15 10:09:27.481986.481986 cuda_h.py:19] end experts_map_get cost 0.0015597343444824219 seconds
DEBUG 01-15 10:09:27.481498.481498 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.481916.481916 lmp.py:1636] 
DEBUG 01-15 10:09:27.481916.481916 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.481414.481414 cuda_h.py:19] end cpu_experts_submit cost 5.030632019042969e-05 seconds
DEBUG 01-15 10:09:27.481203.481203 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.481509.481509 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.481488.481488 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.482706.482706 cuda_h.py:19] end allocate_cuda_memory cost 0.00033783912658691406 seconds
DEBUG 01-15 10:09:27.482549.482549 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.482113.482113 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.482399.482399 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.482479.482479 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 875dbaee-e629-4f24-9b70-82a7069cdf04
DEBUG 01-15 10:09:27.482061.482061 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:27.483035.483035 client.py:127] Model loaded
DEBUG 01-15 10:09:27.483713.483713 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.483136.483136 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:27.483966.483966 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 875dbaee-e629-4f24-9b70-82a7069cdf04
DEBUG 01-15 10:09:27.483140.483140 cuda_h.py:19] end load_into_gpu_async cost 0.0012116432189941406 seconds
DEBUG 01-15 10:09:27.483843.483843 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.483326.483326 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:27.484757.484757 cuda_h.py:19] end restore_tensors2 cost 0.0003666877746582031 seconds
DEBUG 01-15 10:09:27.484408.484408 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002288818359375 seconds
DEBUG 01-15 10:09:27.484800.484800 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.484153.484153 cuda_h.py:19] end restore2model cost 0.00022840499877929688 seconds
DEBUG 01-15 10:09:27.484316.484316 cuda_h.py:19] end sllm_worker_task cost 0.01000833511352539 seconds
DEBUG 01-15 10:09:27.484554.484554 cuda_h.py:19] end move_flatidxs cost 0.0010063648223876953 seconds
DEBUG 01-15 10:09:27.484205.484205 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.487785.487785 cuda_h.py:19] end restore2model cost 0.002871274948120117 seconds
DEBUG 01-15 10:09:27.487496.487496 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005354404449462891 seconds
DEBUG 01-15 10:09:27.487576.487576 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.487639.487639 cuda_h.py:19] end gpu_sexperts cost 0.0002613067626953125 seconds
DEBUG 01-15 10:09:27.487422.487422 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.489765.489765 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015177726745605469 seconds
DEBUG 01-15 10:09:27.489521.489521 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.490985.490985 cuda_h.py:19] end gpu_group_list cost 0.0003540515899658203 seconds
DEBUG 01-15 10:09:27.490757.490757 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.491768.491768 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007073879241943359 seconds
DEBUG 01-15 10:09:27.491214.491214 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.491659.491659 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-15 10:09:27.491024.491024 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.494671.494671 cuda_h.py:19] end group_tensors cost 0.009917020797729492 seconds
DEBUG 01-15 10:09:27.495776.495776 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.499100.499100 cuda_h.py:19] end group pad cost 0.003908634185791016 seconds
DEBUG 01-15 10:09:27.499890.499890 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.519564.519564 cuda_h.py:19] end group_einsum cost 0.019216537475585938 seconds
DEBUG 01-15 10:09:27.519457.519457 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.524519.524519 cuda_h.py:19] end get_outputs_cpu1 cost 0.004956960678100586 seconds
DEBUG 01-15 10:09:27.525620.525620 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0414888858795166 seconds
DEBUG 01-15 10:09:27.526263.526263 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.035135507583618164 seconds
DEBUG 01-15 10:09:27.526740.526740 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.527393.527393 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.527176.527176 cuda_h.py:19] end index_scatter cost 0.00017309188842773438 seconds
DEBUG 01-15 10:09:27.528718.528718 cuda_h.py:19] end cpuoutputsdeal cost 0.0016105175018310547 seconds
DEBUG 01-15 10:09:27.528191.528191 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.528961.528961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 875dbaee-e629-4f24-9b70-82a7069cdf04
INFO 01-15 10:09:27.534197.534197 client.py:127] Model loaded
DEBUG 01-15 10:09:27.534451.534451 cuda_h.py:19] end wait_experts cost 0.005735158920288086 seconds
DEBUG 01-15 10:09:27.534638.534638 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.534971.534971 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.534681.534681 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.534531.534531 cuda_h.py:19] end gpu_group_tensor cost 0.00024580955505371094 seconds
DEBUG 01-15 10:09:27.534840.534840 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.535633.535633 cuda_h.py:19] end gpu_group_einsum cost 0.0010998249053955078 seconds
DEBUG 01-15 10:09:27.536094.536094 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.536454.536454 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.536284.536284 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022935867309570312 seconds
DEBUG 01-15 10:09:27.536908.536908 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.536785.536785 cuda_h.py:19] end concat_expert_out cost 5.555152893066406e-05 seconds
DEBUG 01-15 10:09:27.536535.536535 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.536810.536810 cuda_h.py:19] end index_scatter cost 6.794929504394531e-05 seconds
DEBUG 01-15 10:09:27.536096.536096 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005884170532226562 seconds
DEBUG 01-15 10:09:27.536522.536522 cuda_h.py:19] end gpu_experts cost 0.0024514198303222656 seconds
DEBUG 01-15 10:09:27.536239.536239 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.057546377182006836 seconds
DEBUG 01-15 10:09:27.537656.537656 cuda_h.py:19] end prefill_layer cost 0.06305789947509766 seconds
DEBUG 01-15 10:09:27.537420.537420 lmp.py:1552] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-15 10:09:27.537070.537070 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.537673.537673 lmp.py:1495] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-15 10:09:27.537277.537277 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:27.537834.537834 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:27.537001.537001 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.956390380859375e-05 seconds
DEBUG 01-15 10:09:27.537750.537750 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.745887756347656e-05 seconds
DEBUG 01-15 10:09:27.537778.537778 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.537833.537833 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.537419.537419 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.537838.537838 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.537045.537045 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.538173.538173 cuda_h.py:19] end allocate_cuda_memory cost 0.00023674964904785156 seconds
DEBUG 01-15 10:09:27.538069.538069 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.538779.538779 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.538548.538548 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.538582.538582 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 440d5c62-9f98-455a-9d35-f07612e9f118
DEBUG 01-15 10:09:27.538307.538307 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.538296.538296 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.539341.539341 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 440d5c62-9f98-455a-9d35-f07612e9f118
DEBUG 01-15 10:09:27.539078.539078 cuda_h.py:19] end load_into_gpu_async cost 0.0010280609130859375 seconds
DEBUG 01-15 10:09:27.539397.539397 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.539910.539910 cuda_h.py:19] end restore_tensors2 cost 7.319450378417969e-05 seconds
DEBUG 01-15 10:09:27.539328.539328 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00156402587890625 seconds
INFO 01-15 10:09:27.539998.539998 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 440d5c62-9f98-455a-9d35-f07612e9f118
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.543655.543655 cuda_h.py:19] end self_attn cost 0.004422903060913086 seconds
DEBUG 01-15 10:09:27.543590.543590 cuda_h.py:19] end iln_self_attn_paln cost 0.006045341491699219 seconds
DEBUG 01-15 10:09:27.543255.543255 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-15 10:09:27.543733.543733 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.544626.544626 cuda_h.py:19] end gate cost 0.000728607177734375 seconds
DEBUG 01-15 10:09:27.544124.544124 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.544480.544480 lmp.py:1616] 
DEBUG 01-15 10:09:27.544480.544480 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.544527.544527 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.544416.544416 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.544728.544728 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.544894.544894 lmp.py:1620] 
DEBUG 01-15 10:09:27.544894.544894 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.544060.544060 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.544895.544895 lmp.py:1626]   Expert  1 |     45 | CPU
DEBUG 01-15 10:09:27.544538.544538 lmp.py:1626]   Expert  7 |     60 | CPU
DEBUG 01-15 10:09:27.544989.544989 lmp.py:1626]   Expert 37 |     71 | CPU
DEBUG 01-15 10:09:27.544201.544201 lmp.py:1626]   Expert 17 |     76 | CPU
DEBUG 01-15 10:09:27.545367.545367 lmp.py:1626]   Expert 54 |     76 | CPU
DEBUG 01-15 10:09:27.545818.545818 lmp.py:1626]   Expert 18 |     85 | CPU
DEBUG 01-15 10:09:27.545508.545508 lmp.py:1626]   Expert  9 |     91 | CPU
DEBUG 01-15 10:09:27.545482.545482 lmp.py:1626]   Expert 13 |     92 | CPU
DEBUG 01-15 10:09:27.545456.545456 lmp.py:1626]   Expert 58 |     99 | CPU
DEBUG 01-15 10:09:27.545668.545668 lmp.py:1626]   Expert 22 |    101 | CPU
DEBUG 01-15 10:09:27.545357.545357 lmp.py:1626]   Expert  0 |    109 | CPU
DEBUG 01-15 10:09:27.545808.545808 lmp.py:1626]   Expert 26 |    116 | CPU
DEBUG 01-15 10:09:27.545782.545782 lmp.py:1626]   Expert 16 |    119 | CPU
DEBUG 01-15 10:09:27.545995.545995 lmp.py:1626]   Expert 10 |    122 | CPU
DEBUG 01-15 10:09:27.545207.545207 lmp.py:1626]   Expert 63 |    129 | CPU
DEBUG 01-15 10:09:27.545181.545181 lmp.py:1626]   Expert 59 |    131 | CPU
DEBUG 01-15 10:09:27.545109.545109 lmp.py:1626]   Expert 62 |    139 | CPU
DEBUG 01-15 10:09:27.545037.545037 lmp.py:1626]   Expert 43 |    143 | CPU
DEBUG 01-15 10:09:27.545488.545488 lmp.py:1626]   Expert 28 |    146 | CPU
DEBUG 01-15 10:09:27.545462.545462 lmp.py:1626]   Expert 33 |    147 | CPU
DEBUG 01-15 10:09:27.545674.545674 lmp.py:1626]   Expert 29 |    149 | CPU
DEBUG 01-15 10:09:27.545887.545887 lmp.py:1626]   Expert  2 |    157 | CPU
DEBUG 01-15 10:09:27.545861.545861 lmp.py:1626]   Expert 51 |    162 | CPU
DEBUG 01-15 10:09:27.545835.545835 lmp.py:1626]   Expert 55 |    166 | CPU
DEBUG 01-15 10:09:27.545570.545570 lmp.py:1626]   Expert 11 |    167 | CPU
DEBUG 01-15 10:09:27.545021.545021 lmp.py:1626]   Expert 23 |    167 | CPU
DEBUG 01-15 10:09:27.545234.545234 lmp.py:1626]   Expert 32 |    167 | CPU
DEBUG 01-15 10:09:27.545969.545969 lmp.py:1626]   Expert  3 |    168 | CPU
DEBUG 01-15 10:09:27.545182.545182 lmp.py:1626]   Expert 40 |    168 | CPU
DEBUG 01-15 10:09:27.545156.545156 lmp.py:1626]   Expert 53 |    168 | CPU
DEBUG 01-15 10:09:27.545891.545891 lmp.py:1626]   Expert 45 |    169 | CPU
DEBUG 01-15 10:09:27.545865.545865 lmp.py:1626]   Expert 34 |    174 | CPU
DEBUG 01-15 10:09:27.545601.545601 lmp.py:1626]   Expert 14 |    176 | GPU
DEBUG 01-15 10:09:27.545814.545814 lmp.py:1626]   Expert 41 |    182 | GPU
DEBUG 01-15 10:09:27.545264.545264 lmp.py:1626]   Expert 52 |    182 | GPU
DEBUG 01-15 10:09:27.545477.545477 lmp.py:1626]   Expert 42 |    183 | GPU
DEBUG 01-15 10:09:27.545212.545212 lmp.py:1626]   Expert 21 |    187 | GPU
DEBUG 01-15 10:09:27.545948.545948 lmp.py:1626]   Expert 57 |    196 | GPU
DEBUG 01-15 10:09:27.545922.545922 lmp.py:1626]   Expert 15 |    198 | GPU
DEBUG 01-15 10:09:27.545896.545896 lmp.py:1626]   Expert 30 |    199 | GPU
DEBUG 01-15 10:09:27.545870.545870 lmp.py:1626]   Expert 35 |    208 | GPU
DEBUG 01-15 10:09:27.545752.545752 lmp.py:1626]   Expert  4 |    216 | GPU
DEBUG 01-15 10:09:27.545679.545679 lmp.py:1626]   Expert 12 |    217 | GPU
DEBUG 01-15 10:09:27.545892.545892 lmp.py:1626]   Expert 46 |    228 | GPU
DEBUG 01-15 10:09:27.545627.545627 lmp.py:1626]   Expert 24 |    230 | GPU
DEBUG 01-15 10:09:27.545601.545601 lmp.py:1626]   Expert 19 |    231 | GPU
DEBUG 01-15 10:09:27.545337.545337 lmp.py:1626]   Expert 50 |    231 | GPU
DEBUG 01-15 10:09:27.545311.545311 lmp.py:1626]   Expert 44 |    233 | GPU
DEBUG 01-15 10:09:27.545524.545524 lmp.py:1626]   Expert  8 |    234 | GPU
DEBUG 01-15 10:09:27.545259.545259 lmp.py:1626]   Expert 49 |    236 | GPU
DEBUG 01-15 10:09:27.545233.545233 lmp.py:1626]   Expert 38 |    238 | GPU
DEBUG 01-15 10:09:27.545446.545446 lmp.py:1626]   Expert  6 |    246 | GPU
DEBUG 01-15 10:09:27.545420.545420 lmp.py:1626]   Expert 47 |    248 | GPU
DEBUG 01-15 10:09:27.545632.545632 lmp.py:1626]   Expert 31 |    255 | GPU
DEBUG 01-15 10:09:27.545368.545368 lmp.py:1626]   Expert 61 |    263 | GPU
DEBUG 01-15 10:09:27.545342.545342 lmp.py:1626]   Expert 39 |    277 | GPU
DEBUG 01-15 10:09:27.545554.545554 lmp.py:1626]   Expert  5 |    305 | GPU
DEBUG 01-15 10:09:27.545528.545528 lmp.py:1626]   Expert 36 |    306 | GPU
DEBUG 01-15 10:09:27.545502.545502 lmp.py:1626]   Expert 27 |    307 | GPU
DEBUG 01-15 10:09:27.545238.545238 lmp.py:1626]   Expert 60 |    332 | GPU
DEBUG 01-15 10:09:27.545166.545166 lmp.py:1626]   Expert 20 |    341 | GPU
DEBUG 01-15 10:09:27.545094.545094 lmp.py:1626]   Expert 48 |    370 | GPU
DEBUG 01-15 10:09:27.545783.545783 lmp.py:1626]   Expert 25 |    398 | GPU
DEBUG 01-15 10:09:27.545426.545426 lmp.py:1626]   Expert 56 |    556 | GPU
DEBUG 01-15 10:09:27.545307.545307 lmp.py:1627] 
DEBUG 01-15 10:09:27.545307.545307 lmp.py:1627]   CPU total tokens: 4079 (33.2%)
DEBUG 01-15 10:09:27.545189.545189 lmp.py:1628]   GPU total tokens: 8209 (66.8%)
DEBUG 01-15 10:09:27.546362.546362 cuda_h.py:19] end experts_map_get cost 0.0015156269073486328 seconds
INFO 01-15 10:09:27.546762.546762 client.py:127] Model loaded
DEBUG 01-15 10:09:27.546591.546591 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.546246.546246 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.546214.546214 lmp.py:1636] 
DEBUG 01-15 10:09:27.546214.546214 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.546773.546773 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-15 10:09:27.546707.546707 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.546682.546682 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.546224.546224 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.546291.546291 cuda_h.py:19] end allocate_cuda_memory cost 0.00019049644470214844 seconds
DEBUG 01-15 10:09:27.547038.547038 cuda_h.py:19] end restore2model cost 0.001024484634399414 seconds
DEBUG 01-15 10:09:27.547591.547591 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.547686.547686 cuda_h.py:19] end sllm_worker_task cost 0.00989675521850586 seconds
DEBUG 01-15 10:09:27.547522.547522 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.547306.547306 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.547102.547102 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6621b2d5-0181-4237-ba97-440a146ba367
DEBUG 01-15 10:09:27.547459.547459 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.548443.548443 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.548554.548554 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:27.548955.548955 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6621b2d5-0181-4237-ba97-440a146ba367
DEBUG 01-15 10:09:27.548599.548599 cuda_h.py:19] end load_into_gpu_async cost 0.0013217926025390625 seconds
DEBUG 01-15 10:09:27.548686.548686 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.549647.549647 cuda_h.py:19] end move_flatidxs cost 0.0008962154388427734 seconds
DEBUG 01-15 10:09:27.549728.549728 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.549668.549668 cuda_h.py:19] end restore_tensors2 cost 0.00041604042053222656 seconds
DEBUG 01-15 10:09:27.549458.549458 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029709339141845703 seconds
DEBUG 01-15 10:09:27.549705.549705 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.552918.552918 cuda_h.py:19] end restore2model cost 0.002585887908935547 seconds
DEBUG 01-15 10:09:27.552053.552053 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005744457244873047 seconds
DEBUG 01-15 10:09:27.552802.552802 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.552780.552780 cuda_h.py:19] end gpu_sexperts cost 0.00030303001403808594 seconds
DEBUG 01-15 10:09:27.552801.552801 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.554729.554729 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001562356948852539 seconds
DEBUG 01-15 10:09:27.555657.555657 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.555068.555068 cuda_h.py:19] end gpu_group_list cost 0.0003483295440673828 seconds
DEBUG 01-15 10:09:27.555423.555423 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.556284.556284 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007340908050537109 seconds
DEBUG 01-15 10:09:27.556511.556511 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.556056.556056 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.09808349609375e-05 seconds
DEBUG 01-15 10:09:27.556944.556944 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.560542.560542 cuda_h.py:19] end group_tensors cost 0.01101374626159668 seconds
DEBUG 01-15 10:09:27.561962.561962 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.565141.565141 cuda_h.py:19] end group pad cost 0.004106044769287109 seconds
DEBUG 01-15 10:09:27.565931.565931 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.584055.584055 cuda_h.py:19] end group_einsum cost 0.019034624099731445 seconds
DEBUG 01-15 10:09:27.584133.584133 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.590830.590830 cuda_h.py:19] end get_outputs_cpu1 cost 0.005102634429931641 seconds
DEBUG 01-15 10:09:27.590618.590618 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.042734622955322266 seconds
DEBUG 01-15 10:09:27.591921.591921 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.035223960876464844 seconds
DEBUG 01-15 10:09:27.592637.592637 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.592091.592091 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.592297.592297 cuda_h.py:19] end index_scatter cost 0.0001704692840576172 seconds
DEBUG 01-15 10:09:27.593699.593699 cuda_h.py:19] end cpuoutputsdeal cost 0.0015664100646972656 seconds
DEBUG 01-15 10:09:27.593933.593933 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.593517.593517 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6621b2d5-0181-4237-ba97-440a146ba367
INFO 01-15 10:09:27.599574.599574 client.py:127] Model loaded
DEBUG 01-15 10:09:27.599716.599716 cuda_h.py:19] end wait_experts cost 0.005738258361816406 seconds
DEBUG 01-15 10:09:27.599279.599279 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.599090.599090 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.599369.599369 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.599948.599948 cuda_h.py:19] end gpu_group_tensor cost 0.000255584716796875 seconds
DEBUG 01-15 10:09:27.600873.600873 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.600035.600035 cuda_h.py:19] end gpu_group_einsum cost 0.0008409023284912109 seconds
DEBUG 01-15 10:09:27.601278.601278 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.601797.601797 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.601915.601915 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003287792205810547 seconds
DEBUG 01-15 10:09:27.601354.601354 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.601906.601906 cuda_h.py:19] end concat_expert_out cost 5.6743621826171875e-05 seconds
DEBUG 01-15 10:09:27.601233.601233 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.601283.601283 cuda_h.py:19] end index_scatter cost 7.343292236328125e-05 seconds
DEBUG 01-15 10:09:27.601569.601569 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007264614105224609 seconds
DEBUG 01-15 10:09:27.601432.601432 cuda_h.py:19] end gpu_experts cost 0.0023686885833740234 seconds
DEBUG 01-15 10:09:27.602349.602349 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.05835843086242676 seconds
DEBUG 01-15 10:09:27.602233.602233 cuda_h.py:19] end prefill_layer cost 0.06515383720397949 seconds
DEBUG 01-15 10:09:27.602719.602719 lmp.py:1552] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-15 10:09:27.602799.602799 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.602687.602687 lmp.py:1495] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-15 10:09:27.602290.602290 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:27.602947.602947 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:27.602313.602313 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.123283386230469e-05 seconds
DEBUG 01-15 10:09:27.602208.602208 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.4849853515625e-05 seconds
DEBUG 01-15 10:09:27.602997.602997 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.602907.602907 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.602578.602578 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.602872.602872 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.603509.603509 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.603075.603075 cuda_h.py:19] end allocate_cuda_memory cost 0.00024199485778808594 seconds
DEBUG 01-15 10:09:27.603402.603402 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.603111.603111 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.603126.603126 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.603875.603875 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2092648f-9c0a-4fc5-890c-68f801215c71
DEBUG 01-15 10:09:27.603222.603222 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.603093.603093 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.604072.604072 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2092648f-9c0a-4fc5-890c-68f801215c71
DEBUG 01-15 10:09:27.604100.604100 cuda_h.py:19] end load_into_gpu_async cost 0.0010447502136230469 seconds
DEBUG 01-15 10:09:27.604134.604134 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.604409.604409 cuda_h.py:19] end restore_tensors2 cost 7.224082946777344e-05 seconds
DEBUG 01-15 10:09:27.604688.604688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015912055969238281 seconds
INFO 01-15 10:09:27.604193.604193 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2092648f-9c0a-4fc5-890c-68f801215c71
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.606821.606821 cuda_h.py:19] end self_attn cost 0.0028967857360839844 seconds
DEBUG 01-15 10:09:27.607289.607289 cuda_h.py:19] end iln_self_attn_paln cost 0.0043261051177978516 seconds
DEBUG 01-15 10:09:27.607986.607986 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-15 10:09:27.607603.607603 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.607520.607520 cuda_h.py:19] end gate cost 0.0006425380706787109 seconds
DEBUG 01-15 10:09:27.607018.607018 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.608671.608671 lmp.py:1616] 
DEBUG 01-15 10:09:27.608671.608671 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.608857.608857 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.608461.608461 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.608965.608965 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.608608.608608 lmp.py:1620] 
DEBUG 01-15 10:09:27.608608.608608 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.608489.608489 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.608722.608722 lmp.py:1626]   Expert 50 |     43 | CPU
DEBUG 01-15 10:09:27.608272.608272 lmp.py:1626]   Expert  3 |     53 | CPU
DEBUG 01-15 10:09:27.608153.608153 lmp.py:1626]   Expert 46 |     56 | CPU
DEBUG 01-15 10:09:27.608465.608465 lmp.py:1626]   Expert  1 |     77 | CPU
DEBUG 01-15 10:09:27.608108.608108 lmp.py:1626]   Expert  4 |     87 | CPU
DEBUG 01-15 10:09:27.608751.608751 lmp.py:1626]   Expert 29 |     88 | CPU
DEBUG 01-15 10:09:27.608394.608394 lmp.py:1626]   Expert 15 |     96 | CPU
DEBUG 01-15 10:09:27.608799.608799 lmp.py:1626]   Expert 40 |     97 | CPU
DEBUG 01-15 10:09:27.608965.608965 lmp.py:1626]   Expert  8 |    110 | CPU
DEBUG 01-15 10:09:27.608131.608131 lmp.py:1626]   Expert 28 |    111 | CPU
DEBUG 01-15 10:09:27.608536.608536 lmp.py:1626]   Expert 41 |    112 | CPU
DEBUG 01-15 10:09:27.608702.608702 lmp.py:1626]   Expert 16 |    124 | CPU
DEBUG 01-15 10:09:27.608021.608021 lmp.py:1626]   Expert 27 |    128 | CPU
DEBUG 01-15 10:09:27.608902.608902 lmp.py:1626]   Expert 48 |    128 | CPU
DEBUG 01-15 10:09:27.608353.608353 lmp.py:1626]   Expert  6 |    130 | CPU
DEBUG 01-15 10:09:27.608565.608565 lmp.py:1626]   Expert 13 |    131 | CPU
DEBUG 01-15 10:09:27.608016.608016 lmp.py:1626]   Expert 54 |    133 | CPU
DEBUG 01-15 10:09:27.608851.608851 lmp.py:1626]   Expert  7 |    135 | CPU
DEBUG 01-15 10:09:27.608779.608779 lmp.py:1626]   Expert 51 |    136 | CPU
DEBUG 01-15 10:09:27.608230.608230 lmp.py:1626]   Expert 18 |    140 | CPU
DEBUG 01-15 10:09:27.608919.608919 lmp.py:1626]   Expert 39 |    140 | CPU
DEBUG 01-15 10:09:27.608608.608608 lmp.py:1626]   Expert 60 |    142 | CPU
DEBUG 01-15 10:09:27.608582.608582 lmp.py:1626]   Expert 14 |    146 | CPU
DEBUG 01-15 10:09:27.608272.608272 lmp.py:1626]   Expert 56 |    146 | CPU
DEBUG 01-15 10:09:27.608723.608723 lmp.py:1626]   Expert 43 |    148 | CPU
DEBUG 01-15 10:09:27.608127.608127 lmp.py:1626]   Expert 52 |    148 | CPU
DEBUG 01-15 10:09:27.608532.608532 lmp.py:1626]   Expert 20 |    150 | CPU
DEBUG 01-15 10:09:27.608221.608221 lmp.py:1626]   Expert 36 |    151 | CPU
DEBUG 01-15 10:09:27.608434.608434 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:27.608646.608646 lmp.py:1626]   Expert 10 |    157 | CPU
DEBUG 01-15 10:09:27.608858.608858 lmp.py:1626]   Expert 11 |    158 | CPU
DEBUG 01-15 10:09:27.608309.608309 lmp.py:1626]   Expert 45 |    159 | CPU
DEBUG 01-15 10:09:27.608283.608283 lmp.py:1626]   Expert  5 |    160 | GPU
DEBUG 01-15 10:09:27.608449.608449 lmp.py:1626]   Expert 62 |    167 | GPU
DEBUG 01-15 10:09:27.608377.608377 lmp.py:1626]   Expert 57 |    172 | GPU
DEBUG 01-15 10:09:27.609828.609828 lmp.py:1626]   Expert 44 |    178 | GPU
DEBUG 01-15 10:09:27.609802.609802 lmp.py:1626]   Expert 33 |    180 | GPU
DEBUG 01-15 10:09:27.609253.609253 lmp.py:1626]   Expert 25 |    181 | GPU
DEBUG 01-15 10:09:27.609704.609704 lmp.py:1626]   Expert 58 |    182 | GPU
DEBUG 01-15 10:09:27.609678.609678 lmp.py:1626]   Expert 53 |    184 | GPU
DEBUG 01-15 10:09:27.609890.609890 lmp.py:1626]   Expert  2 |    189 | GPU
DEBUG 01-15 10:09:27.609864.609864 lmp.py:1626]   Expert 32 |    189 | GPU
DEBUG 01-15 10:09:27.609600.609600 lmp.py:1626]   Expert 35 |    199 | GPU
DEBUG 01-15 10:09:27.609574.609574 lmp.py:1626]   Expert 31 |    200 | GPU
DEBUG 01-15 10:09:27.609310.609310 lmp.py:1626]   Expert 21 |    201 | GPU
DEBUG 01-15 10:09:27.609761.609761 lmp.py:1626]   Expert 63 |    204 | GPU
DEBUG 01-15 10:09:27.609212.609212 lmp.py:1626]   Expert 49 |    206 | GPU
DEBUG 01-15 10:09:27.609662.609662 lmp.py:1626]   Expert 17 |    209 | GPU
DEBUG 01-15 10:09:27.609636.609636 lmp.py:1626]   Expert 42 |    219 | GPU
DEBUG 01-15 10:09:27.609610.609610 lmp.py:1626]   Expert 34 |    222 | GPU
DEBUG 01-15 10:09:27.609346.609346 lmp.py:1626]   Expert 37 |    228 | GPU
DEBUG 01-15 10:09:27.609559.609559 lmp.py:1626]   Expert 59 |    228 | GPU
DEBUG 01-15 10:09:27.609533.609533 lmp.py:1626]   Expert 22 |    240 | GPU
DEBUG 01-15 10:09:27.609507.609507 lmp.py:1626]   Expert  0 |    241 | GPU
DEBUG 01-15 10:09:27.609342.609342 lmp.py:1626]   Expert 19 |    258 | GPU
DEBUG 01-15 10:09:27.609793.609793 lmp.py:1626]   Expert 24 |    286 | GPU
DEBUG 01-15 10:09:27.609767.609767 lmp.py:1626]   Expert 61 |    288 | GPU
DEBUG 01-15 10:09:27.609502.609502 lmp.py:1626]   Expert 30 |    301 | GPU
DEBUG 01-15 10:09:27.609476.609476 lmp.py:1626]   Expert 47 |    317 | GPU
DEBUG 01-15 10:09:27.609450.609450 lmp.py:1626]   Expert 38 |    365 | GPU
DEBUG 01-15 10:09:27.609186.609186 lmp.py:1626]   Expert 26 |    375 | GPU
DEBUG 01-15 10:09:27.609398.609398 lmp.py:1626]   Expert 12 |    427 | GPU
DEBUG 01-15 10:09:27.609088.609088 lmp.py:1626]   Expert  9 |    680 | GPU
DEBUG 01-15 10:09:27.609777.609777 lmp.py:1626]   Expert 23 |    701 | GPU
DEBUG 01-15 10:09:27.609705.609705 lmp.py:1627] 
DEBUG 01-15 10:09:27.609705.609705 lmp.py:1627]   CPU total tokens: 3911 (31.8%)
DEBUG 01-15 10:09:27.609109.609109 lmp.py:1628]   GPU total tokens: 8377 (68.2%)
DEBUG 01-15 10:09:27.609329.609329 cuda_h.py:19] end experts_map_get cost 0.0015327930450439453 seconds
DEBUG 01-15 10:09:27.609609.609609 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.609411.609411 lmp.py:1636] 
DEBUG 01-15 10:09:27.609411.609411 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.609532.609532 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-15 10:09:27.609467.609467 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.609773.609773 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.609884.609884 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.611768.611768 cuda_h.py:19] end allocate_cuda_memory cost 0.0018465518951416016 seconds
DEBUG 01-15 10:09:27.612734.612734 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.612643.612643 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.612359.612359 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.612963.612963 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7b2a1a57-411f-4729-acc1-040ffdfb167e
DEBUG 01-15 10:09:27.612675.612675 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.612864.612864 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.612648.612648 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:27.612637.612637 client.py:127] Model loaded
DEBUG 01-15 10:09:27.612705.612705 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.613353.613353 cuda_h.py:19] end restore2model cost 0.0003426074981689453 seconds
DEBUG 01-15 10:09:27.613546.613546 cuda_h.py:19] end sllm_worker_task cost 0.010054588317871094 seconds
DEBUG 01-15 10:09:27.613573.613573 cuda_h.py:19] end move_flatidxs cost 0.0008623600006103516 seconds
DEBUG 01-15 10:09:27.613986.613986 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:27.614506.614506 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7b2a1a57-411f-4729-acc1-040ffdfb167e
DEBUG 01-15 10:09:27.614309.614309 cuda_h.py:19] end load_into_gpu_async cost 0.002103567123413086 seconds
DEBUG 01-15 10:09:27.614489.614489 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.614894.614894 cuda_h.py:19] end restore_tensors2 cost 0.00041031837463378906 seconds
DEBUG 01-15 10:09:27.614022.614022 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005041360855102539 seconds
DEBUG 01-15 10:09:27.614653.614653 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.617227.617227 cuda_h.py:19] end restore2model cost 0.0026760101318359375 seconds
DEBUG 01-15 10:09:27.617116.617116 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007899999618530273 seconds
DEBUG 01-15 10:09:27.617958.617958 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.617147.617147 cuda_h.py:19] end gpu_sexperts cost 0.0002841949462890625 seconds
DEBUG 01-15 10:09:27.617454.617454 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.620428.620428 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002153635025024414 seconds
DEBUG 01-15 10:09:27.620097.620097 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.621071.621071 cuda_h.py:19] end gpu_group_list cost 0.0003399848937988281 seconds
DEBUG 01-15 10:09:27.621042.621042 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.622524.622524 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006995201110839844 seconds
DEBUG 01-15 10:09:27.622916.622916 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.622593.622593 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-15 10:09:27.622766.622766 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.626793.626793 cuda_h.py:19] end group_tensors cost 0.012551546096801758 seconds
DEBUG 01-15 10:09:27.627857.627857 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.632386.632386 cuda_h.py:19] end group pad cost 0.005035877227783203 seconds
DEBUG 01-15 10:09:27.632343.632343 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.652502.652502 cuda_h.py:19] end group_einsum cost 0.019479751586914062 seconds
DEBUG 01-15 10:09:27.652779.652779 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.657981.657981 cuda_h.py:19] end get_outputs_cpu1 cost 0.00478363037109375 seconds
DEBUG 01-15 10:09:27.658616.658616 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04577279090881348 seconds
DEBUG 01-15 10:09:27.658558.658558 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.036451101303100586 seconds
DEBUG 01-15 10:09:27.658561.658561 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.659702.659702 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.659362.659362 cuda_h.py:19] end index_scatter cost 7.867813110351562e-05 seconds
DEBUG 01-15 10:09:27.659007.659007 cuda_h.py:19] end cpuoutputsdeal cost 0.0008153915405273438 seconds
DEBUG 01-15 10:09:27.659267.659267 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.659606.659606 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7b2a1a57-411f-4729-acc1-040ffdfb167e
INFO 01-15 10:09:27.664684.664684 client.py:127] Model loaded
DEBUG 01-15 10:09:27.664726.664726 cuda_h.py:19] end wait_experts cost 0.004377841949462891 seconds
DEBUG 01-15 10:09:27.664528.664528 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.664089.664089 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.664944.664944 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.664766.664766 cuda_h.py:19] end gpu_group_tensor cost 0.00018906593322753906 seconds
DEBUG 01-15 10:09:27.664816.664816 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.665199.665199 cuda_h.py:19] end gpu_group_einsum cost 0.0005176067352294922 seconds
DEBUG 01-15 10:09:27.665541.665541 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.665231.665231 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.665241.665241 cuda_h.py:19] end all_expert_outputs_slices cost 0.00025725364685058594 seconds
DEBUG 01-15 10:09:27.665567.665567 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.665205.665205 cuda_h.py:19] end concat_expert_out cost 5.340576171875e-05 seconds
DEBUG 01-15 10:09:27.666949.666949 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.666872.666872 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-15 10:09:27.666681.666681 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005893707275390625 seconds
DEBUG 01-15 10:09:27.666690.666690 cuda_h.py:19] end gpu_experts cost 0.001847982406616211 seconds
DEBUG 01-15 10:09:27.666799.666799 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.059066057205200195 seconds
DEBUG 01-15 10:09:27.666752.666752 cuda_h.py:19] end prefill_layer cost 0.06405353546142578 seconds
DEBUG 01-15 10:09:27.666655.666655 lmp.py:1552] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-15 10:09:27.666358.666358 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.666061.666061 lmp.py:1495] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-15 10:09:27.666433.666433 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:27.666235.666235 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:27.666085.666085 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.6716461181640625e-05 seconds
DEBUG 01-15 10:09:27.666126.666126 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.937980651855469e-05 seconds
DEBUG 01-15 10:09:27.666206.666206 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.667109.667109 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.667054.667054 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.667738.667738 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.667868.667868 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.667672.667672 cuda_h.py:19] end allocate_cuda_memory cost 0.0002377033233642578 seconds
DEBUG 01-15 10:09:27.667410.667410 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.667319.667319 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.667241.667241 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.667851.667851 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b3452a6c-a23f-4110-b81a-f76e693ae4e3
DEBUG 01-15 10:09:27.667073.667073 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.668309.668309 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.668953.668953 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b3452a6c-a23f-4110-b81a-f76e693ae4e3
DEBUG 01-15 10:09:27.668419.668419 cuda_h.py:19] end load_into_gpu_async cost 0.0010221004486083984 seconds
DEBUG 01-15 10:09:27.668268.668268 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.668146.668146 cuda_h.py:19] end restore_tensors2 cost 8.988380432128906e-05 seconds
DEBUG 01-15 10:09:27.668955.668955 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016345977783203125 seconds
INFO 01-15 10:09:27.669203.669203 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b3452a6c-a23f-4110-b81a-f76e693ae4e3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.671540.671540 cuda_h.py:19] end self_attn cost 0.0030364990234375 seconds
DEBUG 01-15 10:09:27.671292.671292 cuda_h.py:19] end iln_self_attn_paln cost 0.004700422286987305 seconds
DEBUG 01-15 10:09:27.671135.671135 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-15 10:09:27.671898.671898 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.672980.672980 cuda_h.py:19] end gate cost 0.0006587505340576172 seconds
DEBUG 01-15 10:09:27.672956.672956 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.672072.672072 lmp.py:1616] 
DEBUG 01-15 10:09:27.672072.672072 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.672589.672589 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.672431.672431 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.672326.672326 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.672731.672731 lmp.py:1620] 
DEBUG 01-15 10:09:27.672731.672731 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.672374.672374 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.672685.672685 lmp.py:1626]   Expert 38 |     12 | CPU
DEBUG 01-15 10:09:27.672852.672852 lmp.py:1626]   Expert 39 |     61 | CPU
DEBUG 01-15 10:09:27.673541.673541 lmp.py:1626]   Expert  7 |     71 | CPU
DEBUG 01-15 10:09:27.673469.673469 lmp.py:1626]   Expert 30 |     74 | CPU
DEBUG 01-15 10:09:27.673919.673919 lmp.py:1626]   Expert 14 |     94 | CPU
DEBUG 01-15 10:09:27.673370.673370 lmp.py:1626]   Expert 24 |     94 | CPU
DEBUG 01-15 10:09:27.673060.673060 lmp.py:1626]   Expert 27 |     95 | CPU
DEBUG 01-15 10:09:27.673226.673226 lmp.py:1626]   Expert 36 |     97 | CPU
DEBUG 01-15 10:09:27.673438.673438 lmp.py:1626]   Expert 40 |     97 | CPU
DEBUG 01-15 10:09:27.673088.673088 lmp.py:1626]   Expert 17 |     99 | CPU
DEBUG 01-15 10:09:27.673969.673969 lmp.py:1626]   Expert 16 |    104 | CPU
DEBUG 01-15 10:09:27.673612.673612 lmp.py:1626]   Expert 32 |    106 | CPU
DEBUG 01-15 10:09:27.673255.673255 lmp.py:1626]   Expert 18 |    108 | CPU
DEBUG 01-15 10:09:27.673898.673898 lmp.py:1626]   Expert 48 |    109 | CPU
DEBUG 01-15 10:09:27.673541.673541 lmp.py:1626]   Expert  1 |    113 | CPU
DEBUG 01-15 10:09:27.673707.673707 lmp.py:1626]   Expert 12 |    113 | CPU
DEBUG 01-15 10:09:27.673397.673397 lmp.py:1626]   Expert  6 |    125 | CPU
DEBUG 01-15 10:09:27.673609.673609 lmp.py:1626]   Expert 59 |    132 | CPU
DEBUG 01-15 10:09:27.673822.673822 lmp.py:1626]   Expert 42 |    136 | CPU
DEBUG 01-15 10:09:27.673796.673796 lmp.py:1626]   Expert  0 |    140 | CPU
DEBUG 01-15 10:09:27.673008.673008 lmp.py:1626]   Expert 22 |    145 | CPU
DEBUG 01-15 10:09:27.673459.673459 lmp.py:1626]   Expert 53 |    148 | CPU
DEBUG 01-15 10:09:27.673433.673433 lmp.py:1626]   Expert 51 |    150 | CPU
DEBUG 01-15 10:09:27.673407.673407 lmp.py:1626]   Expert  8 |    159 | CPU
DEBUG 01-15 10:09:27.673381.673381 lmp.py:1626]   Expert 44 |    167 | CPU
DEBUG 01-15 10:09:27.673355.673355 lmp.py:1626]   Expert 60 |    168 | CPU
DEBUG 01-15 10:09:27.673237.673237 lmp.py:1626]   Expert 15 |    169 | CPU
DEBUG 01-15 10:09:27.673641.673641 lmp.py:1626]   Expert 29 |    171 | CPU
DEBUG 01-15 10:09:27.673330.673330 lmp.py:1626]   Expert 54 |    173 | CPU
DEBUG 01-15 10:09:27.673020.673020 lmp.py:1626]   Expert 34 |    179 | CPU
DEBUG 01-15 10:09:27.673186.673186 lmp.py:1626]   Expert 35 |    180 | CPU
DEBUG 01-15 10:09:27.673114.673114 lmp.py:1626]   Expert 33 |    181 | CPU
DEBUG 01-15 10:09:27.673565.673565 lmp.py:1626]   Expert 47 |    188 | GPU
DEBUG 01-15 10:09:27.673492.673492 lmp.py:1626]   Expert 19 |    190 | GPU
DEBUG 01-15 10:09:27.673658.673658 lmp.py:1626]   Expert  9 |    193 | GPU
DEBUG 01-15 10:09:27.673825.673825 lmp.py:1626]   Expert  3 |    197 | GPU
DEBUG 01-15 10:09:27.673991.673991 lmp.py:1626]   Expert 46 |    198 | GPU
DEBUG 01-15 10:09:27.673918.673918 lmp.py:1626]   Expert 56 |    198 | GPU
DEBUG 01-15 10:09:27.673846.673846 lmp.py:1626]   Expert 20 |    201 | GPU
DEBUG 01-15 10:09:27.673251.673251 lmp.py:1626]   Expert 21 |    201 | GPU
DEBUG 01-15 10:09:27.673178.673178 lmp.py:1626]   Expert 45 |    201 | GPU
DEBUG 01-15 10:09:27.673868.673868 lmp.py:1626]   Expert 49 |    203 | GPU
DEBUG 01-15 10:09:27.673795.673795 lmp.py:1626]   Expert 28 |    208 | GPU
DEBUG 01-15 10:09:27.673723.673723 lmp.py:1626]   Expert 57 |    223 | GPU
DEBUG 01-15 10:09:27.673889.673889 lmp.py:1626]   Expert  2 |    224 | GPU
DEBUG 01-15 10:09:27.673817.673817 lmp.py:1626]   Expert 43 |    225 | GPU
DEBUG 01-15 10:09:27.673745.673745 lmp.py:1626]   Expert 13 |    226 | GPU
DEBUG 01-15 10:09:27.673434.673434 lmp.py:1626]   Expert  4 |    229 | GPU
DEBUG 01-15 10:09:27.673885.673885 lmp.py:1626]   Expert 10 |    240 | GPU
DEBUG 01-15 10:09:27.673813.673813 lmp.py:1626]   Expert 50 |    243 | GPU
DEBUG 01-15 10:09:27.673740.673740 lmp.py:1626]   Expert 41 |    245 | GPU
DEBUG 01-15 10:09:27.673668.673668 lmp.py:1626]   Expert 26 |    251 | GPU
DEBUG 01-15 10:09:27.673357.673357 lmp.py:1626]   Expert 63 |    256 | GPU
DEBUG 01-15 10:09:27.673100.673100 lmp.py:1626]   Expert 37 |    262 | GPU
DEBUG 01-15 10:09:27.673789.673789 lmp.py:1626]   Expert 31 |    270 | GPU
DEBUG 01-15 10:09:27.673763.673763 lmp.py:1626]   Expert 61 |    272 | GPU
DEBUG 01-15 10:09:27.673737.673737 lmp.py:1626]   Expert 52 |    305 | GPU
DEBUG 01-15 10:09:27.673473.673473 lmp.py:1626]   Expert 58 |    319 | GPU
DEBUG 01-15 10:09:27.673924.673924 lmp.py:1626]   Expert 62 |    323 | GPU
DEBUG 01-15 10:09:27.673136.673136 lmp.py:1626]   Expert 55 |    336 | GPU
DEBUG 01-15 10:09:27.673110.673110 lmp.py:1626]   Expert 11 |    381 | GPU
DEBUG 01-15 10:09:27.674323.674323 lmp.py:1626]   Expert 23 |    383 | GPU
DEBUG 01-15 10:09:27.674774.674774 lmp.py:1626]   Expert 25 |    410 | GPU
DEBUG 01-15 10:09:27.674224.674224 lmp.py:1626]   Expert  5 |    517 | GPU
DEBUG 01-15 10:09:27.674914.674914 lmp.py:1627] 
DEBUG 01-15 10:09:27.674914.674914 lmp.py:1627]   CPU total tokens: 3970 (32.3%)
DEBUG 01-15 10:09:27.674318.674318 lmp.py:1628]   GPU total tokens: 8318 (67.7%)
DEBUG 01-15 10:09:27.674014.674014 cuda_h.py:19] end experts_map_get cost 0.0015244483947753906 seconds
DEBUG 01-15 10:09:27.674149.674149 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.674759.674759 lmp.py:1636] 
DEBUG 01-15 10:09:27.674759.674759 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.674880.674880 cuda_h.py:19] end cpu_experts_submit cost 5.316734313964844e-05 seconds
DEBUG 01-15 10:09:27.674815.674815 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.674836.674836 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.674577.674577 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.676133.676133 cuda_h.py:19] end allocate_cuda_memory cost 0.0015342235565185547 seconds
DEBUG 01-15 10:09:27.676616.676616 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.676147.676147 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.676340.676340 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.676659.676659 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1e8d64dd-1930-40e6-9d97-bb133570bcd0
DEBUG 01-15 10:09:27.676244.676244 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.676016.676016 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.676444.676444 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:27.676604.676604 client.py:127] Model loaded
DEBUG 01-15 10:09:27.676725.676725 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.677222.677222 cuda_h.py:19] end restore2model cost 0.0003676414489746094 seconds
DEBUG 01-15 10:09:27.677383.677383 cuda_h.py:19] end sllm_worker_task cost 0.010179519653320312 seconds
INFO 01-15 10:09:27.677287.677287 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1e8d64dd-1930-40e6-9d97-bb133570bcd0
DEBUG 01-15 10:09:27.677892.677892 cuda_h.py:19] end load_into_gpu_async cost 0.0010738372802734375 seconds
DEBUG 01-15 10:09:27.677118.677118 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.677534.677534 cuda_h.py:19] end move_flatidxs cost 0.0008473396301269531 seconds
DEBUG 01-15 10:09:27.677456.677456 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.677258.677258 cuda_h.py:19] end restore_tensors2 cost 0.00039315223693847656 seconds
DEBUG 01-15 10:09:27.678763.678763 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003714323043823242 seconds
DEBUG 01-15 10:09:27.678307.678307 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.680721.680721 cuda_h.py:19] end restore2model cost 0.002628326416015625 seconds
DEBUG 01-15 10:09:27.680233.680233 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006535768508911133 seconds
DEBUG 01-15 10:09:27.680505.680505 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.681595.681595 cuda_h.py:19] end gpu_sexperts cost 0.00028061866760253906 seconds
DEBUG 01-15 10:09:27.681902.681902 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.682669.682669 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015130043029785156 seconds
DEBUG 01-15 10:09:27.683318.683318 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.683159.683159 cuda_h.py:19] end gpu_group_list cost 0.00034999847412109375 seconds
DEBUG 01-15 10:09:27.684892.684892 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.684672.684672 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007092952728271484 seconds
DEBUG 01-15 10:09:27.684495.684495 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.684271.684271 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-15 10:09:27.684967.684967 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.687898.687898 cuda_h.py:19] end group_tensors cost 0.009205341339111328 seconds
DEBUG 01-15 10:09:27.687532.687532 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.691030.691030 cuda_h.py:19] end group pad cost 0.003920793533325195 seconds
DEBUG 01-15 10:09:27.691250.691250 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.710763.710763 cuda_h.py:19] end group_einsum cost 0.018585205078125 seconds
DEBUG 01-15 10:09:27.710040.710040 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.715697.715697 cuda_h.py:19] end get_outputs_cpu1 cost 0.0043179988861083984 seconds
DEBUG 01-15 10:09:27.715597.715597 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03910374641418457 seconds
DEBUG 01-15 10:09:27.716616.716616 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0317540168762207 seconds
DEBUG 01-15 10:09:27.716477.716477 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.717388.717388 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.717543.717543 cuda_h.py:19] end index_scatter cost 0.0001678466796875 seconds
DEBUG 01-15 10:09:27.718780.718780 cuda_h.py:19] end cpuoutputsdeal cost 0.0016224384307861328 seconds
DEBUG 01-15 10:09:27.718182.718182 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.718258.718258 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1e8d64dd-1930-40e6-9d97-bb133570bcd0
INFO 01-15 10:09:27.728741.728741 client.py:127] Model loaded
DEBUG 01-15 10:09:27.728878.728878 cuda_h.py:19] end wait_experts cost 0.009629249572753906 seconds
DEBUG 01-15 10:09:27.728833.728833 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.728881.728881 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.728061.728061 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.728515.728515 cuda_h.py:19] end gpu_group_tensor cost 0.0002675056457519531 seconds
DEBUG 01-15 10:09:27.729161.729161 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.729332.729332 cuda_h.py:19] end gpu_group_einsum cost 0.0004973411560058594 seconds
DEBUG 01-15 10:09:27.729720.729720 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.729549.729549 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.730769.730769 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020599365234375 seconds
DEBUG 01-15 10:09:27.730518.730518 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.730819.730819 cuda_h.py:19] end concat_expert_out cost 5.316734313964844e-05 seconds
DEBUG 01-15 10:09:27.730808.730808 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.730666.730666 cuda_h.py:19] end index_scatter cost 6.723403930664062e-05 seconds
DEBUG 01-15 10:09:27.730091.730091 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005507469177246094 seconds
DEBUG 01-15 10:09:27.730331.730331 cuda_h.py:19] end gpu_experts cost 0.0018181800842285156 seconds
DEBUG 01-15 10:09:27.730195.730195 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.05872011184692383 seconds
DEBUG 01-15 10:09:27.730692.730692 cuda_h.py:19] end prefill_layer cost 0.0641183853149414 seconds
DEBUG 01-15 10:09:27.730310.730310 lmp.py:1552] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-15 10:09:27.731960.731960 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.731848.731848 lmp.py:1495] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-15 10:09:27.731974.731974 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:27.731247.731247 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:27.731037.731037 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.218650817871094e-05 seconds
DEBUG 01-15 10:09:27.731873.731873 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.731126.731126 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.00013327598571777344 seconds
DEBUG 01-15 10:09:27.731274.731274 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.731859.731859 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.731431.731431 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.731858.731858 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.731519.731519 cuda_h.py:19] end allocate_cuda_memory cost 0.00028967857360839844 seconds
DEBUG 01-15 10:09:27.732649.732649 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.732365.732365 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.732327.732327 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.732599.732599 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df96f870-4604-416c-a504-bbf71ad4b74e
DEBUG 01-15 10:09:27.732198.732198 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.732777.732777 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.733249.733249 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df96f870-4604-416c-a504-bbf71ad4b74e
DEBUG 01-15 10:09:27.733324.733324 cuda_h.py:19] end load_into_gpu_async cost 0.0011279582977294922 seconds
DEBUG 01-15 10:09:27.733596.733596 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.733209.733209 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-15 10:09:27.733488.733488 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001928567886352539 seconds
INFO 01-15 10:09:27.733105.733105 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df96f870-4604-416c-a504-bbf71ad4b74e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.735542.735542 cuda_h.py:19] end self_attn cost 0.0027861595153808594 seconds
DEBUG 01-15 10:09:27.735326.735326 cuda_h.py:19] end iln_self_attn_paln cost 0.004153013229370117 seconds
DEBUG 01-15 10:09:27.735739.735739 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-15 10:09:27.735833.735833 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.736604.736604 cuda_h.py:19] end gate cost 0.0006320476531982422 seconds
DEBUG 01-15 10:09:27.736387.736387 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.736165.736165 lmp.py:1616] 
DEBUG 01-15 10:09:27.736165.736165 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.736206.736206 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.736617.736617 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.736644.736644 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.736049.736049 lmp.py:1620] 
DEBUG 01-15 10:09:27.736049.736049 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.736930.736930 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.736765.736765 lmp.py:1626]   Expert 24 |     40 | CPU
DEBUG 01-15 10:09:27.736077.736077 lmp.py:1626]   Expert  2 |     46 | CPU
DEBUG 01-15 10:09:27.736197.736197 lmp.py:1626]   Expert 26 |     64 | CPU
DEBUG 01-15 10:09:27.736601.736601 lmp.py:1626]   Expert 32 |     67 | CPU
DEBUG 01-15 10:09:27.736244.736244 lmp.py:1626]   Expert 19 |     70 | CPU
DEBUG 01-15 10:09:27.736126.736126 lmp.py:1626]   Expert 50 |     70 | CPU
DEBUG 01-15 10:09:27.736769.736769 lmp.py:1626]   Expert 15 |     80 | CPU
DEBUG 01-15 10:09:27.736173.736173 lmp.py:1626]   Expert  4 |     82 | CPU
DEBUG 01-15 10:09:27.737339.737339 lmp.py:1626]   Expert 28 |     82 | CPU
DEBUG 01-15 10:09:27.737506.737506 lmp.py:1626]   Expert  7 |     84 | CPU
DEBUG 01-15 10:09:27.737433.737433 lmp.py:1626]   Expert 60 |     84 | CPU
DEBUG 01-15 10:09:27.737599.737599 lmp.py:1626]   Expert 59 |     90 | CPU
DEBUG 01-15 10:09:27.737004.737004 lmp.py:1626]   Expert 23 |     96 | CPU
DEBUG 01-15 10:09:27.737885.737885 lmp.py:1626]   Expert 49 |     99 | CPU
DEBUG 01-15 10:09:27.737767.737767 lmp.py:1626]   Expert  5 |    103 | CPU
DEBUG 01-15 10:09:27.737171.737171 lmp.py:1626]   Expert 12 |    105 | CPU
DEBUG 01-15 10:09:27.737576.737576 lmp.py:1626]   Expert 10 |    112 | CPU
DEBUG 01-15 10:09:27.737981.737981 lmp.py:1626]   Expert 27 |    112 | CPU
DEBUG 01-15 10:09:27.737147.737147 lmp.py:1626]   Expert 41 |    123 | CPU
DEBUG 01-15 10:09:27.737790.737790 lmp.py:1626]   Expert  3 |    125 | CPU
DEBUG 01-15 10:09:27.737194.737194 lmp.py:1626]   Expert 25 |    126 | CPU
DEBUG 01-15 10:09:27.737599.737599 lmp.py:1626]   Expert 40 |    129 | CPU
DEBUG 01-15 10:09:27.737003.737003 lmp.py:1626]   Expert 20 |    131 | CPU
DEBUG 01-15 10:09:27.737885.737885 lmp.py:1626]   Expert 13 |    132 | CPU
DEBUG 01-15 10:09:27.737289.737289 lmp.py:1626]   Expert 16 |    135 | CPU
DEBUG 01-15 10:09:27.737217.737217 lmp.py:1626]   Expert 37 |    145 | CPU
DEBUG 01-15 10:09:27.737383.737383 lmp.py:1626]   Expert 35 |    146 | CPU
DEBUG 01-15 10:09:27.737788.737788 lmp.py:1626]   Expert 17 |    147 | CPU
DEBUG 01-15 10:09:27.737954.737954 lmp.py:1626]   Expert 47 |    151 | CPU
DEBUG 01-15 10:09:27.737597.737597 lmp.py:1626]   Expert 22 |    158 | CPU
DEBUG 01-15 10:09:27.737478.737478 lmp.py:1626]   Expert 53 |    165 | CPU
DEBUG 01-15 10:09:27.737644.737644 lmp.py:1626]   Expert 39 |    171 | CPU
DEBUG 01-15 10:09:27.737049.737049 lmp.py:1626]   Expert 38 |    176 | GPU
DEBUG 01-15 10:09:27.737453.737453 lmp.py:1626]   Expert 44 |    179 | GPU
DEBUG 01-15 10:09:27.737620.737620 lmp.py:1626]   Expert 36 |    182 | GPU
DEBUG 01-15 10:09:27.737786.737786 lmp.py:1626]   Expert 58 |    183 | GPU
DEBUG 01-15 10:09:27.737713.737713 lmp.py:1626]   Expert 52 |    184 | GPU
DEBUG 01-15 10:09:27.737356.737356 lmp.py:1626]   Expert 18 |    187 | GPU
DEBUG 01-15 10:09:27.737761.737761 lmp.py:1626]   Expert 62 |    198 | GPU
DEBUG 01-15 10:09:27.737689.737689 lmp.py:1626]   Expert 11 |    211 | GPU
DEBUG 01-15 10:09:27.737855.737855 lmp.py:1626]   Expert 48 |    211 | GPU
DEBUG 01-15 10:09:27.737783.737783 lmp.py:1626]   Expert 14 |    218 | GPU
DEBUG 01-15 10:09:27.737472.737472 lmp.py:1626]   Expert 30 |    219 | GPU
DEBUG 01-15 10:09:27.737400.737400 lmp.py:1626]   Expert  1 |    229 | GPU
DEBUG 01-15 10:09:27.737327.737327 lmp.py:1626]   Expert 45 |    232 | GPU
DEBUG 01-15 10:09:27.737732.737732 lmp.py:1626]   Expert 42 |    233 | GPU
DEBUG 01-15 10:09:27.737898.737898 lmp.py:1626]   Expert 31 |    236 | GPU
DEBUG 01-15 10:09:27.737826.737826 lmp.py:1626]   Expert  6 |    242 | GPU
DEBUG 01-15 10:09:27.737753.737753 lmp.py:1626]   Expert 51 |    242 | GPU
DEBUG 01-15 10:09:27.737681.737681 lmp.py:1626]   Expert 29 |    262 | GPU
DEBUG 01-15 10:09:27.737847.737847 lmp.py:1626]   Expert 34 |    263 | GPU
DEBUG 01-15 10:09:27.737537.737537 lmp.py:1626]   Expert 33 |    275 | GPU
DEBUG 01-15 10:09:27.737464.737464 lmp.py:1626]   Expert 57 |    296 | GPU
DEBUG 01-15 10:09:27.737392.737392 lmp.py:1626]   Expert 61 |    306 | GPU
DEBUG 01-15 10:09:27.737035.737035 lmp.py:1626]   Expert 43 |    308 | GPU
DEBUG 01-15 10:09:27.737440.737440 lmp.py:1626]   Expert  0 |    319 | GPU
DEBUG 01-15 10:09:27.737367.737367 lmp.py:1626]   Expert 46 |    352 | GPU
DEBUG 01-15 10:09:27.737772.737772 lmp.py:1626]   Expert  8 |    377 | GPU
DEBUG 01-15 10:09:27.737461.737461 lmp.py:1626]   Expert 56 |    387 | GPU
DEBUG 01-15 10:09:27.737627.737627 lmp.py:1626]   Expert  9 |    392 | GPU
DEBUG 01-15 10:09:27.737555.737555 lmp.py:1626]   Expert 54 |    396 | GPU
DEBUG 01-15 10:09:27.737721.737721 lmp.py:1626]   Expert 63 |    409 | GPU
DEBUG 01-15 10:09:27.737126.737126 lmp.py:1626]   Expert 55 |    426 | GPU
DEBUG 01-15 10:09:27.737292.737292 lmp.py:1626]   Expert 21 |    488 | GPU
DEBUG 01-15 10:09:27.737173.737173 lmp.py:1627] 
DEBUG 01-15 10:09:27.737173.737173 lmp.py:1627]   CPU total tokens: 3470 (28.2%)
DEBUG 01-15 10:09:27.737293.737293 lmp.py:1628]   GPU total tokens: 8818 (71.8%)
DEBUG 01-15 10:09:27.738989.738989 cuda_h.py:19] end experts_map_get cost 0.001539468765258789 seconds
DEBUG 01-15 10:09:27.738839.738839 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.738926.738926 lmp.py:1636] 
DEBUG 01-15 10:09:27.738926.738926 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.738948.738948 cuda_h.py:19] end cpu_experts_submit cost 5.0067901611328125e-05 seconds
DEBUG 01-15 10:09:27.738736.738736 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.738182.738182 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.738068.738068 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.740955.740955 cuda_h.py:19] end allocate_cuda_memory cost 0.0025136470794677734 seconds
DEBUG 01-15 10:09:27.741429.741429 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.741576.741576 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.741292.741292 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.741372.741372 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3117b4b8-e025-4804-8f6e-39e6c010c118
DEBUG 01-15 10:09:27.741531.741531 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.741318.741318 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:27.741772.741772 client.py:127] Model loaded
DEBUG 01-15 10:09:27.741544.741544 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.741988.741988 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:27.742663.742663 cuda_h.py:19] end restore2model cost 0.0003693103790283203 seconds
DEBUG 01-15 10:09:27.742910.742910 cuda_h.py:19] end sllm_worker_task cost 0.010873794555664062 seconds
INFO 01-15 10:09:27.742299.742299 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3117b4b8-e025-4804-8f6e-39e6c010c118
DEBUG 01-15 10:09:27.742334.742334 cuda_h.py:19] end load_into_gpu_async cost 0.0012936592102050781 seconds
DEBUG 01-15 10:09:27.742037.742037 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.742410.742410 cuda_h.py:19] end move_flatidxs cost 0.0008761882781982422 seconds
DEBUG 01-15 10:09:27.742161.742161 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.743501.743501 cuda_h.py:19] end restore_tensors2 cost 0.0003857612609863281 seconds
DEBUG 01-15 10:09:27.743960.743960 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0048334598541259766 seconds
DEBUG 01-15 10:09:27.743114.743114 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.745680.745680 cuda_h.py:19] end restore2model cost 0.0026340484619140625 seconds
DEBUG 01-15 10:09:27.745000.745000 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007651567459106445 seconds
DEBUG 01-15 10:09:27.745034.745034 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.746494.746494 cuda_h.py:19] end gpu_sexperts cost 0.0002734661102294922 seconds
DEBUG 01-15 10:09:27.746277.746277 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.747620.747620 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001482248306274414 seconds
DEBUG 01-15 10:09:27.748573.748573 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.748255.748255 cuda_h.py:19] end gpu_group_list cost 0.0003428459167480469 seconds
DEBUG 01-15 10:09:27.749649.749649 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.748701.748701 cuda_h.py:19] end group_tensors cost 0.006001949310302734 seconds
DEBUG 01-15 10:09:27.749508.749508 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.749948.749948 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007638931274414062 seconds
DEBUG 01-15 10:09:27.749727.749727 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.750160.750160 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.24249267578125e-05 seconds
DEBUG 01-15 10:09:27.750101.750101 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.753374.753374 cuda_h.py:19] end group pad cost 0.003839254379272461 seconds
DEBUG 01-15 10:09:27.753231.753231 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.770215.770215 cuda_h.py:19] end group_einsum cost 0.01723623275756836 seconds
DEBUG 01-15 10:09:27.771287.771287 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.776875.776875 cuda_h.py:19] end get_outputs_cpu1 cost 0.005034685134887695 seconds
DEBUG 01-15 10:09:27.776092.776092 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03527665138244629 seconds
DEBUG 01-15 10:09:27.777052.777052 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.02772378921508789 seconds
DEBUG 01-15 10:09:27.778814.778814 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.778519.778519 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.778476.778476 cuda_h.py:19] end index_scatter cost 0.00016427040100097656 seconds
DEBUG 01-15 10:09:27.779627.779627 cuda_h.py:19] end cpuoutputsdeal cost 0.0016150474548339844 seconds
DEBUG 01-15 10:09:27.779498.779498 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.780528.780528 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3117b4b8-e025-4804-8f6e-39e6c010c118
INFO 01-15 10:09:27.792764.792764 client.py:127] Model loaded
DEBUG 01-15 10:09:27.792609.792609 cuda_h.py:19] end wait_experts cost 0.012323617935180664 seconds
DEBUG 01-15 10:09:27.792902.792902 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.792621.792621 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.792754.792754 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.792982.792982 cuda_h.py:19] end gpu_group_tensor cost 0.000244140625 seconds
DEBUG 01-15 10:09:27.792860.792860 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.793407.793407 cuda_h.py:19] end gpu_group_einsum cost 0.00046324729919433594 seconds
DEBUG 01-15 10:09:27.793689.793689 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.793803.793803 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.793877.793877 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020360946655273438 seconds
DEBUG 01-15 10:09:27.793626.793626 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.793496.793496 cuda_h.py:19] end concat_expert_out cost 5.1021575927734375e-05 seconds
DEBUG 01-15 10:09:27.793816.793816 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.794514.794514 cuda_h.py:19] end index_scatter cost 6.461143493652344e-05 seconds
DEBUG 01-15 10:09:27.794509.794509 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005326271057128906 seconds
DEBUG 01-15 10:09:27.794412.794412 cuda_h.py:19] end gpu_experts cost 0.0017216205596923828 seconds
DEBUG 01-15 10:09:27.794798.794798 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.05851101875305176 seconds
DEBUG 01-15 10:09:27.794361.794361 cuda_h.py:19] end prefill_layer cost 0.06357693672180176 seconds
DEBUG 01-15 10:09:27.794549.794549 lmp.py:1552] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-15 10:09:27.794960.794960 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.794133.794133 lmp.py:1495] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-15 10:09:27.794259.794259 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:27.794724.794724 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:27.794322.794322 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.0994415283203125e-05 seconds
DEBUG 01-15 10:09:27.794879.794879 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.817413330078125e-05 seconds
DEBUG 01-15 10:09:27.794999.794999 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.794617.794617 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.795865.795865 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.795371.795371 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.795161.795161 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.795873.795873 cuda_h.py:19] end allocate_cuda_memory cost 0.00028061866760253906 seconds
DEBUG 01-15 10:09:27.795962.795962 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.795387.795387 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.795110.795110 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.795144.795144 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c45439af-a8ad-48a5-9007-b64a8c70bf8a
DEBUG 01-15 10:09:27.795398.795398 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.795493.795493 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.796121.796121 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c45439af-a8ad-48a5-9007-b64a8c70bf8a
DEBUG 01-15 10:09:27.796719.796719 cuda_h.py:19] end load_into_gpu_async cost 0.0010166168212890625 seconds
DEBUG 01-15 10:09:27.796799.796799 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.796266.796266 cuda_h.py:19] end restore_tensors2 cost 7.343292236328125e-05 seconds
DEBUG 01-15 10:09:27.796830.796830 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016040802001953125 seconds
INFO 01-15 10:09:27.796342.796342 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c45439af-a8ad-48a5-9007-b64a8c70bf8a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.798948.798948 cuda_h.py:19] end self_attn cost 0.00286865234375 seconds
DEBUG 01-15 10:09:27.799833.799833 cuda_h.py:19] end iln_self_attn_paln cost 0.0043087005615234375 seconds
DEBUG 01-15 10:09:27.799199.799199 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-15 10:09:27.799770.799770 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.799931.799931 cuda_h.py:19] end gate cost 0.0006470680236816406 seconds
DEBUG 01-15 10:09:27.800999.800999 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.800698.800698 lmp.py:1616] 
DEBUG 01-15 10:09:27.800698.800698 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.800077.800077 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.800886.800886 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.800105.800105 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.800901.800901 lmp.py:1620] 
DEBUG 01-15 10:09:27.800901.800901 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.800451.800451 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.800478.800478 lmp.py:1626]   Expert 43 |     16 | CPU
DEBUG 01-15 10:09:27.800313.800313 lmp.py:1626]   Expert 27 |     32 | CPU
DEBUG 01-15 10:09:27.800910.800910 lmp.py:1626]   Expert 26 |     52 | CPU
DEBUG 01-15 10:09:27.800268.800268 lmp.py:1626]   Expert 34 |     53 | CPU
DEBUG 01-15 10:09:27.800865.800865 lmp.py:1626]   Expert 56 |     54 | CPU
DEBUG 01-15 10:09:27.800223.800223 lmp.py:1626]   Expert  3 |     58 | CPU
DEBUG 01-15 10:09:27.800297.800297 lmp.py:1626]   Expert  4 |     68 | CPU
DEBUG 01-15 10:09:27.800132.800132 lmp.py:1626]   Expert 61 |     80 | CPU
DEBUG 01-15 10:09:27.800490.800490 lmp.py:1626]   Expert 14 |     95 | CPU
DEBUG 01-15 10:09:27.800848.800848 lmp.py:1626]   Expert 38 |    101 | CPU
DEBUG 01-15 10:09:27.800206.800206 lmp.py:1626]   Expert  2 |    111 | CPU
DEBUG 01-15 10:09:27.800088.800088 lmp.py:1626]   Expert 17 |    122 | CPU
DEBUG 01-15 10:09:27.800446.800446 lmp.py:1626]   Expert 22 |    122 | CPU
DEBUG 01-15 10:09:27.800804.800804 lmp.py:1626]   Expert 47 |    128 | CPU
DEBUG 01-15 10:09:27.800686.800686 lmp.py:1626]   Expert 37 |    131 | CPU
DEBUG 01-15 10:09:27.800805.800805 lmp.py:1626]   Expert 55 |    132 | CPU
DEBUG 01-15 10:09:27.800925.800925 lmp.py:1626]   Expert 28 |    136 | CPU
DEBUG 01-15 10:09:27.800807.800807 lmp.py:1626]   Expert 54 |    136 | CPU
DEBUG 01-15 10:09:27.800165.800165 lmp.py:1626]   Expert  7 |    144 | CPU
DEBUG 01-15 10:09:27.800046.800046 lmp.py:1626]   Expert 48 |    144 | CPU
DEBUG 01-15 10:09:27.800928.800928 lmp.py:1626]   Expert 15 |    145 | CPU
DEBUG 01-15 10:09:27.800809.800809 lmp.py:1626]   Expert  5 |    148 | CPU
DEBUG 01-15 10:09:27.800452.800452 lmp.py:1626]   Expert 60 |    148 | CPU
DEBUG 01-15 10:09:27.800095.800095 lmp.py:1626]   Expert 51 |    150 | CPU
DEBUG 01-15 10:09:27.800976.800976 lmp.py:1626]   Expert 45 |    151 | CPU
DEBUG 01-15 10:09:27.800096.800096 lmp.py:1626]   Expert 63 |    154 | CPU
DEBUG 01-15 10:09:27.800693.800693 lmp.py:1626]   Expert 12 |    155 | CPU
DEBUG 01-15 10:09:27.800336.800336 lmp.py:1626]   Expert 19 |    158 | CPU
DEBUG 01-15 10:09:27.801979.801979 lmp.py:1626]   Expert  6 |    166 | CPU
DEBUG 01-15 10:09:27.801860.801860 lmp.py:1626]   Expert 57 |    169 | CPU
DEBUG 01-15 10:09:27.801503.801503 lmp.py:1626]   Expert 52 |    177 | CPU
DEBUG 01-15 10:09:27.801908.801908 lmp.py:1626]   Expert 50 |    179 | CPU
DEBUG 01-15 10:09:27.801028.801028 lmp.py:1626]   Expert 18 |    182 | GPU
DEBUG 01-15 10:09:27.801909.801909 lmp.py:1626]   Expert 44 |    184 | GPU
DEBUG 01-15 10:09:27.801790.801790 lmp.py:1626]   Expert 31 |    185 | GPU
DEBUG 01-15 10:09:27.801149.801149 lmp.py:1626]   Expert 13 |    190 | GPU
DEBUG 01-15 10:09:27.801984.801984 lmp.py:1626]   Expert 30 |    190 | GPU
DEBUG 01-15 10:09:27.801103.801103 lmp.py:1626]   Expert 23 |    192 | GPU
DEBUG 01-15 10:09:27.801985.801985 lmp.py:1626]   Expert 39 |    196 | GPU
DEBUG 01-15 10:09:27.801866.801866 lmp.py:1626]   Expert 53 |    196 | GPU
DEBUG 01-15 10:09:27.801748.801748 lmp.py:1626]   Expert 59 |    198 | GPU
DEBUG 01-15 10:09:27.801391.801391 lmp.py:1626]   Expert 20 |    200 | GPU
DEBUG 01-15 10:09:27.801034.801034 lmp.py:1626]   Expert 21 |    203 | GPU
DEBUG 01-15 10:09:27.801392.801392 lmp.py:1626]   Expert 29 |    203 | GPU
DEBUG 01-15 10:09:27.801273.801273 lmp.py:1626]   Expert 16 |    209 | GPU
DEBUG 01-15 10:09:27.801393.801393 lmp.py:1626]   Expert 36 |    212 | GPU
DEBUG 01-15 10:09:27.801990.801990 lmp.py:1626]   Expert 41 |    218 | GPU
DEBUG 01-15 10:09:27.801109.801109 lmp.py:1626]   Expert 25 |    219 | GPU
DEBUG 01-15 10:09:27.801991.801991 lmp.py:1626]   Expert 49 |    223 | GPU
DEBUG 01-15 10:09:27.801872.801872 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:27.801515.801515 lmp.py:1626]   Expert 46 |    235 | GPU
DEBUG 01-15 10:09:27.801158.801158 lmp.py:1626]   Expert  8 |    245 | GPU
DEBUG 01-15 10:09:27.801801.801801 lmp.py:1626]   Expert 10 |    249 | GPU
DEBUG 01-15 10:09:27.801444.801444 lmp.py:1626]   Expert 42 |    250 | GPU
DEBUG 01-15 10:09:27.801802.801802 lmp.py:1626]   Expert 62 |    264 | GPU
DEBUG 01-15 10:09:27.801399.801399 lmp.py:1626]   Expert 35 |    276 | GPU
DEBUG 01-15 10:09:27.801280.801280 lmp.py:1626]   Expert 33 |    291 | GPU
DEBUG 01-15 10:09:27.801923.801923 lmp.py:1626]   Expert  9 |    292 | GPU
DEBUG 01-15 10:09:27.801566.801566 lmp.py:1626]   Expert 58 |    299 | GPU
DEBUG 01-15 10:09:27.801209.801209 lmp.py:1626]   Expert 40 |    386 | GPU
DEBUG 01-15 10:09:27.801852.801852 lmp.py:1626]   Expert 11 |    421 | GPU
DEBUG 01-15 10:09:27.801257.801257 lmp.py:1626]   Expert  0 |    426 | GPU
DEBUG 01-15 10:09:27.801138.801138 lmp.py:1626]   Expert 24 |    565 | GPU
DEBUG 01-15 10:09:27.801258.801258 lmp.py:1626]   Expert  1 |    649 | GPU
DEBUG 01-15 10:09:27.801616.801616 lmp.py:1627] 
DEBUG 01-15 10:09:27.801616.801616 lmp.py:1627]   CPU total tokens: 3815 (31.0%)
DEBUG 01-15 10:09:27.801690.801690 lmp.py:1628]   GPU total tokens: 8473 (69.0%)
DEBUG 01-15 10:09:27.801578.801578 cuda_h.py:19] end experts_map_get cost 0.0016262531280517578 seconds
DEBUG 01-15 10:09:27.801143.801143 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.801753.801753 lmp.py:1636] 
DEBUG 01-15 10:09:27.801753.801753 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.801159.801159 cuda_h.py:19] end cpu_experts_submit cost 5.245208740234375e-05 seconds
DEBUG 01-15 10:09:27.801855.801855 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.801546.801546 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.802710.802710 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.803261.803261 cuda_h.py:19] end allocate_cuda_memory cost 0.0017750263214111328 seconds
DEBUG 01-15 10:09:27.803819.803819 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.803575.803575 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.804268.804268 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.804355.804355 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f59e29e6-99f5-4a6c-93bf-8b8487778ddd
DEBUG 01-15 10:09:27.804541.804541 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.804637.804637 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:27.804606.804606 client.py:127] Model loaded
DEBUG 01-15 10:09:27.804787.804787 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.804134.804134 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:27.805941.805941 cuda_h.py:19] end restore2model cost 0.0004258155822753906 seconds
DEBUG 01-15 10:09:27.805817.805817 cuda_h.py:19] end sllm_worker_task cost 0.010167121887207031 seconds
INFO 01-15 10:09:27.805952.805952 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f59e29e6-99f5-4a6c-93bf-8b8487778ddd
DEBUG 01-15 10:09:27.805656.805656 cuda_h.py:19] end load_into_gpu_async cost 0.0016367435455322266 seconds
DEBUG 01-15 10:09:27.805174.805174 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.805793.805793 cuda_h.py:19] end move_flatidxs cost 0.0008502006530761719 seconds
DEBUG 01-15 10:09:27.805153.805153 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.806958.806958 cuda_h.py:19] end restore_tensors2 cost 0.0004363059997558594 seconds
DEBUG 01-15 10:09:27.806344.806344 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004251003265380859 seconds
DEBUG 01-15 10:09:27.806644.806644 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.808060.808060 cuda_h.py:19] end restore2model cost 0.0026907920837402344 seconds
DEBUG 01-15 10:09:27.809426.809426 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007140398025512695 seconds
DEBUG 01-15 10:09:27.809460.809460 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.809510.809510 cuda_h.py:19] end gpu_sexperts cost 0.0002865791320800781 seconds
DEBUG 01-15 10:09:27.809625.809625 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.810385.810385 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015077590942382812 seconds
DEBUG 01-15 10:09:27.811624.811624 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.812023.812023 cuda_h.py:19] end gpu_group_list cost 0.00036406517028808594 seconds
DEBUG 01-15 10:09:27.812782.812782 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.813572.813572 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007789134979248047 seconds
DEBUG 01-15 10:09:27.813891.813891 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.813191.813191 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4543533325195312e-05 seconds
DEBUG 01-15 10:09:27.813139.813139 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.817602.817602 cuda_h.py:19] end group_tensors cost 0.01120901107788086 seconds
DEBUG 01-15 10:09:27.817013.817013 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.821031.821031 cuda_h.py:19] end group pad cost 0.003847837448120117 seconds
DEBUG 01-15 10:09:27.821451.821451 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.839054.839054 cuda_h.py:19] end group_einsum cost 0.01774144172668457 seconds
DEBUG 01-15 10:09:27.839841.839841 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.844289.844289 cuda_h.py:19] end get_outputs_cpu1 cost 0.004605531692504883 seconds
DEBUG 01-15 10:09:27.845560.845560 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04051923751831055 seconds
DEBUG 01-15 10:09:27.846081.846081 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03280973434448242 seconds
DEBUG 01-15 10:09:27.846029.846029 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.846694.846694 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.847181.847181 cuda_h.py:19] end index_scatter cost 0.0001659393310546875 seconds
DEBUG 01-15 10:09:27.848040.848040 cuda_h.py:19] end cpuoutputsdeal cost 0.0016224384307861328 seconds
DEBUG 01-15 10:09:27.848011.848011 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.848372.848372 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f59e29e6-99f5-4a6c-93bf-8b8487778ddd
INFO 01-15 10:09:27.855405.855405 client.py:127] Model loaded
DEBUG 01-15 10:09:27.855773.855773 cuda_h.py:19] end wait_experts cost 0.0072553157806396484 seconds
DEBUG 01-15 10:09:27.855491.855491 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.855429.855429 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.855531.855531 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.856520.856520 cuda_h.py:19] end gpu_group_tensor cost 0.0003719329833984375 seconds
DEBUG 01-15 10:09:27.856429.856429 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.857536.857536 cuda_h.py:19] end gpu_group_einsum cost 0.0011115074157714844 seconds
DEBUG 01-15 10:09:27.858088.858088 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.858097.858097 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.858637.858637 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002536773681640625 seconds
DEBUG 01-15 10:09:27.858055.858055 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.858999.858999 cuda_h.py:19] end concat_expert_out cost 6.628036499023438e-05 seconds
DEBUG 01-15 10:09:27.858756.858756 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.858839.858839 cuda_h.py:19] end index_scatter cost 6.628036499023438e-05 seconds
DEBUG 01-15 10:09:27.858979.858979 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006449222564697266 seconds
DEBUG 01-15 10:09:27.858757.858757 cuda_h.py:19] end gpu_experts cost 0.0031228065490722656 seconds
DEBUG 01-15 10:09:27.858243.858243 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.059621572494506836 seconds
DEBUG 01-15 10:09:27.859237.859237 cuda_h.py:19] end prefill_layer cost 0.06460762023925781 seconds
DEBUG 01-15 10:09:27.859119.859119 lmp.py:1552] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-15 10:09:27.859531.859531 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.859180.859180 lmp.py:1495] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-15 10:09:27.859261.859261 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:27.859771.859771 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:27.859230.859230 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.3855438232421875e-05 seconds
DEBUG 01-15 10:09:27.859264.859264 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.151199340820312e-05 seconds
DEBUG 01-15 10:09:27.859152.859152 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.859990.859990 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.859421.859421 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.859437.859437 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.860419.860419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.860038.860038 cuda_h.py:19] end allocate_cuda_memory cost 0.0005118846893310547 seconds
DEBUG 01-15 10:09:27.861390.861390 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.861149.861149 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.861168.861168 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.861198.861198 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ab4aa262-a2e3-4853-bc7c-42e453021fdf
DEBUG 01-15 10:09:27.861658.861658 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.861714.861714 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.863515.863515 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ab4aa262-a2e3-4853-bc7c-42e453021fdf
DEBUG 01-15 10:09:27.863411.863411 cuda_h.py:19] end load_into_gpu_async cost 0.002706289291381836 seconds
DEBUG 01-15 10:09:27.863975.863975 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.864018.864018 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-15 10:09:27.864013.864013 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003936767578125 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
INFO 01-15 10:09:27.864236.864236 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ab4aa262-a2e3-4853-bc7c-42e453021fdf
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.865547.865547 cuda_h.py:19] end self_attn cost 0.0028705596923828125 seconds
DEBUG 01-15 10:09:27.865438.865438 cuda_h.py:19] end iln_self_attn_paln cost 0.005728483200073242 seconds
DEBUG 01-15 10:09:27.865427.865427 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-15 10:09:27.865382.865382 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.866020.866020 cuda_h.py:19] end gate cost 0.0006456375122070312 seconds
DEBUG 01-15 10:09:27.866949.866949 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.866681.866681 lmp.py:1616] 
DEBUG 01-15 10:09:27.866681.866681 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.866960.866960 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.866133.866133 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.866207.866207 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.866042.866042 lmp.py:1620] 
DEBUG 01-15 10:09:27.866042.866042 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.866877.866877 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.866427.866427 lmp.py:1626]   Expert 13 |     15 | CPU
DEBUG 01-15 10:09:27.866308.866308 lmp.py:1626]   Expert 39 |     16 | CPU
DEBUG 01-15 10:09:27.866951.866951 lmp.py:1626]   Expert 49 |     38 | CPU
DEBUG 01-15 10:09:27.866594.866594 lmp.py:1626]   Expert 35 |     54 | CPU
DEBUG 01-15 10:09:27.866714.866714 lmp.py:1626]   Expert 19 |     62 | CPU
DEBUG 01-15 10:09:27.866072.866072 lmp.py:1626]   Expert  9 |     71 | CPU
DEBUG 01-15 10:09:27.866000.866000 lmp.py:1626]   Expert 26 |     75 | CPU
DEBUG 01-15 10:09:27.866405.866405 lmp.py:1626]   Expert 32 |     75 | CPU
DEBUG 01-15 10:09:27.866571.866571 lmp.py:1626]   Expert 41 |     76 | CPU
DEBUG 01-15 10:09:27.866975.866975 lmp.py:1626]   Expert 33 |     83 | CPU
DEBUG 01-15 10:09:27.866142.866142 lmp.py:1626]   Expert 23 |     86 | CPU
DEBUG 01-15 10:09:27.866546.866546 lmp.py:1626]   Expert 46 |     88 | CPU
DEBUG 01-15 10:09:27.866712.866712 lmp.py:1626]   Expert 18 |     89 | CPU
DEBUG 01-15 10:09:27.866355.866355 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:27.866237.866237 lmp.py:1626]   Expert 38 |     99 | CPU
DEBUG 01-15 10:09:27.866641.866641 lmp.py:1626]   Expert  3 |    103 | CPU
DEBUG 01-15 10:09:27.866331.866331 lmp.py:1626]   Expert 17 |    104 | CPU
DEBUG 01-15 10:09:27.866497.866497 lmp.py:1626]   Expert  6 |    107 | CPU
DEBUG 01-15 10:09:27.866424.866424 lmp.py:1626]   Expert 20 |    117 | CPU
DEBUG 01-15 10:09:27.866591.866591 lmp.py:1626]   Expert 40 |    128 | CPU
DEBUG 01-15 10:09:27.866518.866518 lmp.py:1626]   Expert 61 |    131 | CPU
DEBUG 01-15 10:09:27.866684.866684 lmp.py:1626]   Expert 43 |    134 | CPU
DEBUG 01-15 10:09:27.866327.866327 lmp.py:1626]   Expert 15 |    135 | CPU
DEBUG 01-15 10:09:27.867493.867493 lmp.py:1626]   Expert 62 |    135 | CPU
DEBUG 01-15 10:09:27.867375.867375 lmp.py:1626]   Expert 44 |    136 | CPU
DEBUG 01-15 10:09:27.867256.867256 lmp.py:1626]   Expert 50 |    136 | CPU
DEBUG 01-15 10:09:27.867138.867138 lmp.py:1626]   Expert 59 |    137 | CPU
DEBUG 01-15 10:09:27.867496.867496 lmp.py:1626]   Expert 16 |    138 | CPU
DEBUG 01-15 10:09:27.867139.867139 lmp.py:1626]   Expert 63 |    139 | CPU
DEBUG 01-15 10:09:27.867020.867020 lmp.py:1626]   Expert 42 |    140 | CPU
DEBUG 01-15 10:09:27.867140.867140 lmp.py:1626]   Expert  2 |    146 | CPU
DEBUG 01-15 10:09:27.867783.867783 lmp.py:1626]   Expert 36 |    152 | CPU
DEBUG 01-15 10:09:27.867949.867949 lmp.py:1626]   Expert 10 |    160 | GPU
DEBUG 01-15 10:09:27.867115.867115 lmp.py:1626]   Expert  5 |    183 | GPU
DEBUG 01-15 10:09:27.867043.867043 lmp.py:1626]   Expert 34 |    186 | GPU
DEBUG 01-15 10:09:27.867209.867209 lmp.py:1626]   Expert 52 |    189 | GPU
DEBUG 01-15 10:09:27.867137.867137 lmp.py:1626]   Expert 27 |    190 | GPU
DEBUG 01-15 10:09:27.867780.867780 lmp.py:1626]   Expert 45 |    191 | GPU
DEBUG 01-15 10:09:27.867184.867184 lmp.py:1626]   Expert 60 |    200 | GPU
DEBUG 01-15 10:09:27.867351.867351 lmp.py:1626]   Expert 48 |    207 | GPU
DEBUG 01-15 10:09:27.867278.867278 lmp.py:1626]   Expert 51 |    212 | GPU
DEBUG 01-15 10:09:27.867444.867444 lmp.py:1626]   Expert 56 |    214 | GPU
DEBUG 01-15 10:09:27.867372.867372 lmp.py:1626]   Expert  7 |    233 | GPU
DEBUG 01-15 10:09:27.867300.867300 lmp.py:1626]   Expert 24 |    233 | GPU
DEBUG 01-15 10:09:27.867466.867466 lmp.py:1626]   Expert 53 |    234 | GPU
DEBUG 01-15 10:09:27.867394.867394 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:27.867037.867037 lmp.py:1626]   Expert 57 |    251 | GPU
DEBUG 01-15 10:09:27.867680.867680 lmp.py:1626]   Expert 47 |    254 | GPU
DEBUG 01-15 10:09:27.867846.867846 lmp.py:1626]   Expert 29 |    261 | GPU
DEBUG 01-15 10:09:27.867774.867774 lmp.py:1626]   Expert 21 |    264 | GPU
DEBUG 01-15 10:09:27.867701.867701 lmp.py:1626]   Expert  0 |    286 | GPU
DEBUG 01-15 10:09:27.867867.867867 lmp.py:1626]   Expert 14 |    288 | GPU
DEBUG 01-15 10:09:27.867034.867034 lmp.py:1626]   Expert  4 |    291 | GPU
DEBUG 01-15 10:09:27.867961.867961 lmp.py:1626]   Expert 22 |    313 | GPU
DEBUG 01-15 10:09:27.867889.867889 lmp.py:1626]   Expert 58 |    315 | GPU
DEBUG 01-15 10:09:27.867055.867055 lmp.py:1626]   Expert  1 |    318 | GPU
DEBUG 01-15 10:09:27.867367.867367 lmp.py:1626]   Expert 37 |    318 | GPU
DEBUG 01-15 10:09:27.867725.867725 lmp.py:1626]   Expert 55 |    318 | GPU
DEBUG 01-15 10:09:27.867653.867653 lmp.py:1626]   Expert 54 |    331 | GPU
DEBUG 01-15 10:09:27.867819.867819 lmp.py:1626]   Expert 28 |    357 | GPU
DEBUG 01-15 10:09:27.867747.867747 lmp.py:1626]   Expert 12 |    380 | GPU
DEBUG 01-15 10:09:27.867675.867675 lmp.py:1626]   Expert 25 |    397 | GPU
DEBUG 01-15 10:09:27.867602.867602 lmp.py:1626]   Expert 11 |    400 | GPU
DEBUG 01-15 10:09:27.867292.867292 lmp.py:1626]   Expert 30 |    837 | GPU
DEBUG 01-15 10:09:27.867173.867173 lmp.py:1627] 
DEBUG 01-15 10:09:27.867173.867173 lmp.py:1627]   CPU total tokens: 3236 (26.3%)
DEBUG 01-15 10:09:27.867293.867293 lmp.py:1628]   GPU total tokens: 9052 (73.7%)
DEBUG 01-15 10:09:27.867466.867466 cuda_h.py:19] end experts_map_get cost 0.0015463829040527344 seconds
DEBUG 01-15 10:09:27.867123.867123 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.867403.867403 lmp.py:1636] 
DEBUG 01-15 10:09:27.867403.867403 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.867093.867093 cuda_h.py:19] end cpu_experts_submit cost 5.1975250244140625e-05 seconds
DEBUG 01-15 10:09:27.867836.867836 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.867142.867142 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.868352.868352 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.870412.870412 cuda_h.py:19] end allocate_cuda_memory cost 0.0019397735595703125 seconds
DEBUG 01-15 10:09:27.870070.870070 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.870349.870349 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.870396.870396 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.870523.870523 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a53773f7-f30d-4799-98d7-82224d307666
DEBUG 01-15 10:09:27.870218.870218 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.871050.871050 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.871349.871349 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:27.871178.871178 client.py:127] Model loaded
DEBUG 01-15 10:09:27.871451.871451 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.872229.872229 cuda_h.py:19] end restore2model cost 0.00042700767517089844 seconds
DEBUG 01-15 10:09:27.872151.872151 cuda_h.py:19] end sllm_worker_task cost 0.012255191802978516 seconds
DEBUG 01-15 10:09:27.872440.872440 cuda_h.py:19] end move_flatidxs cost 0.0008771419525146484 seconds
DEBUG 01-15 10:09:27.872919.872919 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:27.872530.872530 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a53773f7-f30d-4799-98d7-82224d307666
DEBUG 01-15 10:09:27.872280.872280 cuda_h.py:19] end load_into_gpu_async cost 0.0022988319396972656 seconds
DEBUG 01-15 10:09:27.872983.872983 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.872898.872898 cuda_h.py:19] end restore_tensors2 cost 0.00040340423583984375 seconds
DEBUG 01-15 10:09:27.873311.873311 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0050160884857177734 seconds
DEBUG 01-15 10:09:27.873080.873080 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.875663.875663 cuda_h.py:19] end restore2model cost 0.002543210983276367 seconds
DEBUG 01-15 10:09:27.875830.875830 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007734060287475586 seconds
DEBUG 01-15 10:09:27.875672.875672 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.876901.876901 cuda_h.py:19] end gpu_sexperts cost 0.00027942657470703125 seconds
DEBUG 01-15 10:09:27.876254.876254 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.877703.877703 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015249252319335938 seconds
DEBUG 01-15 10:09:27.878134.878134 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.878075.878075 cuda_h.py:19] end gpu_group_list cost 0.0003464221954345703 seconds
DEBUG 01-15 10:09:27.878046.878046 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.879270.879270 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007207393646240234 seconds
DEBUG 01-15 10:09:27.879292.879292 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.879161.879161 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-15 10:09:27.879857.879857 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.882518.882518 cuda_h.py:19] end group_tensors cost 0.009909868240356445 seconds
DEBUG 01-15 10:09:27.883272.883272 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.887451.887451 cuda_h.py:19] end group pad cost 0.004503488540649414 seconds
DEBUG 01-15 10:09:27.887102.887102 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.907056.907056 cuda_h.py:19] end group_einsum cost 0.019294261932373047 seconds
DEBUG 01-15 10:09:27.907041.907041 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.911019.911019 cuda_h.py:19] end get_outputs_cpu1 cost 0.004618167877197266 seconds
DEBUG 01-15 10:09:27.912502.912502 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04148983955383301 seconds
DEBUG 01-15 10:09:27.913965.913965 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.033811092376708984 seconds
DEBUG 01-15 10:09:27.913350.913350 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.914916.914916 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.914356.914356 cuda_h.py:19] end index_scatter cost 0.00016760826110839844 seconds
DEBUG 01-15 10:09:27.915434.915434 cuda_h.py:19] end cpuoutputsdeal cost 0.0016071796417236328 seconds
DEBUG 01-15 10:09:27.915352.915352 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.915858.915858 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a53773f7-f30d-4799-98d7-82224d307666
INFO 01-15 10:09:27.922119.922119 client.py:127] Model loaded
DEBUG 01-15 10:09:27.923832.923832 cuda_h.py:19] end wait_experts cost 0.0071523189544677734 seconds
DEBUG 01-15 10:09:27.923696.923696 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.923872.923872 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.923219.923219 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.923361.923361 cuda_h.py:19] end gpu_group_tensor cost 0.0003745555877685547 seconds
DEBUG 01-15 10:09:27.923481.923481 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.925798.925798 cuda_h.py:19] end gpu_group_einsum cost 0.001245737075805664 seconds
DEBUG 01-15 10:09:27.925966.925966 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.925096.925096 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.926019.926019 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005960464477539062 seconds
DEBUG 01-15 10:09:27.926843.926843 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.926406.926406 cuda_h.py:19] end concat_expert_out cost 0.0001285076141357422 seconds
DEBUG 01-15 10:09:27.926173.926173 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.927550.927550 cuda_h.py:19] end index_scatter cost 0.00012159347534179688 seconds
DEBUG 01-15 10:09:27.927865.927865 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014369487762451172 seconds
DEBUG 01-15 10:09:27.927579.927579 cuda_h.py:19] end gpu_experts cost 0.004164934158325195 seconds
DEBUG 01-15 10:09:27.927553.927553 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06205415725708008 seconds
DEBUG 01-15 10:09:27.928183.928183 cuda_h.py:19] end prefill_layer cost 0.06887125968933105 seconds
DEBUG 01-15 10:09:27.928492.928492 lmp.py:1552] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-15 10:09:27.928541.928541 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:27.928352.928352 lmp.py:1495] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-15 10:09:27.928923.928923 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:27.928264.928264 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:27.928944.928944 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.961822509765625e-05 seconds
DEBUG 01-15 10:09:27.929532.929532 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:27.929736.929736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00037598609924316406 seconds
DEBUG 01-15 10:09:27.929126.929126 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.929037.929037 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:27.929551.929551 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.930574.930574 cuda_h.py:19] end allocate_cuda_memory cost 0.00029969215393066406 seconds
DEBUG 01-15 10:09:27.930629.930629 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.930631.930631 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.930699.930699 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.930309.930309 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99641c82-024b-45db-8641-942601ce7602
DEBUG 01-15 10:09:27.930352.930352 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:27.930134.930134 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:27.931782.931782 cuda_h.py:10] start self_attn
INFO 01-15 10:09:27.931216.931216 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99641c82-024b-45db-8641-942601ce7602
DEBUG 01-15 10:09:27.931861.931861 cuda_h.py:19] end load_into_gpu_async cost 0.0015361309051513672 seconds
DEBUG 01-15 10:09:27.931332.931332 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.931541.931541 cuda_h.py:19] end restore_tensors2 cost 9.131431579589844e-05 seconds
DEBUG 01-15 10:09:27.931728.931728 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002348661422729492 seconds
INFO 01-15 10:09:27.932889.932889 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99641c82-024b-45db-8641-942601ce7602
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:27.936381.936381 cuda_h.py:19] end self_attn cost 0.005090236663818359 seconds
DEBUG 01-15 10:09:27.937654.937654 cuda_h.py:19] end iln_self_attn_paln cost 0.00730586051940918 seconds
DEBUG 01-15 10:09:27.937346.937346 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-15 10:09:27.937228.937228 cuda_h.py:10] start gate
DEBUG 01-15 10:09:27.938252.938252 cuda_h.py:19] end gate cost 0.0008409023284912109 seconds
DEBUG 01-15 10:09:27.938877.938877 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:27.938290.938290 lmp.py:1616] 
DEBUG 01-15 10:09:27.938290.938290 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:27.938596.938596 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:27.938697.938697 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:27.938552.938552 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:27.938593.938593 lmp.py:1620] 
DEBUG 01-15 10:09:27.938593.938593 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:27.938634.938634 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:27.938582.938582 lmp.py:1626]   Expert 12 |     18 | CPU
DEBUG 01-15 10:09:27.938146.938146 lmp.py:1626]   Expert 47 |     23 | CPU
DEBUG 01-15 10:09:27.938140.938140 lmp.py:1626]   Expert 38 |     33 | CPU
DEBUG 01-15 10:09:27.938420.938420 lmp.py:1626]   Expert 16 |     36 | CPU
DEBUG 01-15 10:09:27.938268.938268 lmp.py:1626]   Expert 27 |     37 | CPU
DEBUG 01-15 10:09:27.939402.939402 lmp.py:1626]   Expert 52 |     40 | CPU
DEBUG 01-15 10:09:27.939535.939535 lmp.py:1626]   Expert 63 |     42 | CPU
DEBUG 01-15 10:09:27.939145.939145 lmp.py:1626]   Expert  4 |     58 | CPU
DEBUG 01-15 10:09:27.939709.939709 lmp.py:1626]   Expert 44 |     61 | CPU
DEBUG 01-15 10:09:27.939571.939571 lmp.py:1626]   Expert 43 |     62 | CPU
DEBUG 01-15 10:09:27.939658.939658 lmp.py:1626]   Expert 61 |     66 | CPU
DEBUG 01-15 10:09:27.939030.939030 lmp.py:1626]   Expert 34 |     76 | CPU
DEBUG 01-15 10:09:27.939356.939356 lmp.py:1626]   Expert 53 |     82 | CPU
DEBUG 01-15 10:09:27.939158.939158 lmp.py:1626]   Expert  0 |     86 | CPU
DEBUG 01-15 10:09:27.939722.939722 lmp.py:1626]   Expert 32 |     88 | CPU
DEBUG 01-15 10:09:27.939047.939047 lmp.py:1626]   Expert 37 |     90 | CPU
DEBUG 01-15 10:09:27.939896.939896 lmp.py:1626]   Expert 13 |    103 | CPU
DEBUG 01-15 10:09:27.939414.939414 lmp.py:1626]   Expert 39 |    115 | CPU
DEBUG 01-15 10:09:27.939785.939785 lmp.py:1626]   Expert 21 |    118 | CPU
DEBUG 01-15 10:09:27.939157.939157 lmp.py:1626]   Expert 11 |    120 | CPU
DEBUG 01-15 10:09:27.939291.939291 lmp.py:1626]   Expert 20 |    127 | CPU
DEBUG 01-15 10:09:27.939662.939662 lmp.py:1626]   Expert  8 |    129 | CPU
DEBUG 01-15 10:09:27.939703.939703 lmp.py:1626]   Expert 60 |    133 | CPU
DEBUG 01-15 10:09:27.939790.939790 lmp.py:1626]   Expert 57 |    139 | CPU
DEBUG 01-15 10:09:27.939639.939639 lmp.py:1626]   Expert 14 |    140 | CPU
DEBUG 01-15 10:09:27.939011.939011 lmp.py:1626]   Expert 22 |    141 | CPU
DEBUG 01-15 10:09:27.939859.939859 lmp.py:1626]   Expert 45 |    151 | CPU
DEBUG 01-15 10:09:27.939231.939231 lmp.py:1626]   Expert  2 |    155 | CPU
DEBUG 01-15 10:09:27.939080.939080 lmp.py:1626]   Expert 18 |    157 | CPU
DEBUG 01-15 10:09:27.939458.939458 lmp.py:1626]   Expert 23 |    158 | CPU
DEBUG 01-15 10:09:27.939545.939545 lmp.py:1626]   Expert 17 |    159 | CPU
DEBUG 01-15 10:09:27.939156.939156 lmp.py:1626]   Expert  7 |    163 | CPU
DEBUG 01-15 10:09:27.939528.939528 lmp.py:1626]   Expert 58 |    163 | GPU
DEBUG 01-15 10:09:27.939423.939423 lmp.py:1626]   Expert 30 |    165 | GPU
DEBUG 01-15 10:09:27.939079.939079 lmp.py:1626]   Expert 42 |    171 | GPU
DEBUG 01-15 10:09:27.939974.939974 lmp.py:1626]   Expert 48 |    179 | GPU
DEBUG 01-15 10:09:27.939823.939823 lmp.py:1626]   Expert 49 |    179 | GPU
DEBUG 01-15 10:09:27.939148.939148 lmp.py:1626]   Expert 55 |    180 | GPU
DEBUG 01-15 10:09:27.939758.939758 lmp.py:1626]   Expert 62 |    180 | GPU
DEBUG 01-15 10:09:27.940607.940607 lmp.py:1626]   Expert 35 |    185 | GPU
DEBUG 01-15 10:09:27.940979.940979 lmp.py:1626]   Expert 51 |    185 | GPU
DEBUG 01-15 10:09:27.940874.940874 lmp.py:1626]   Expert 29 |    189 | GPU
DEBUG 01-15 10:09:27.940484.940484 lmp.py:1626]   Expert  6 |    192 | GPU
DEBUG 01-15 10:09:27.940333.940333 lmp.py:1626]   Expert 25 |    193 | GPU
DEBUG 01-15 10:09:27.940658.940658 lmp.py:1626]   Expert 36 |    194 | GPU
DEBUG 01-15 10:09:27.940792.940792 lmp.py:1626]   Expert  1 |    198 | GPU
DEBUG 01-15 10:09:27.940402.940402 lmp.py:1626]   Expert 31 |    208 | GPU
DEBUG 01-15 10:09:27.940774.940774 lmp.py:1626]   Expert 28 |    223 | GPU
DEBUG 01-15 10:09:27.940576.940576 lmp.py:1626]   Expert  5 |    229 | GPU
DEBUG 01-15 10:09:27.940425.940425 lmp.py:1626]   Expert 54 |    229 | GPU
DEBUG 01-15 10:09:27.940273.940273 lmp.py:1626]   Expert 41 |    232 | GPU
DEBUG 01-15 10:09:27.940407.940407 lmp.py:1626]   Expert 19 |    239 | GPU
DEBUG 01-15 10:09:27.940653.940653 lmp.py:1626]   Expert  9 |    240 | GPU
DEBUG 01-15 10:09:27.940740.940740 lmp.py:1626]   Expert 24 |    255 | GPU
DEBUG 01-15 10:09:27.940112.940112 lmp.py:1626]   Expert 50 |    285 | GPU
DEBUG 01-15 10:09:27.940961.940961 lmp.py:1626]   Expert 46 |    306 | GPU
DEBUG 01-15 10:09:27.940524.940524 lmp.py:1626]   Expert 59 |    311 | GPU
DEBUG 01-15 10:09:27.940896.940896 lmp.py:1626]   Expert 56 |    375 | GPU
DEBUG 01-15 10:09:27.940507.940507 lmp.py:1626]   Expert 26 |    406 | GPU
DEBUG 01-15 10:09:27.940640.940640 lmp.py:1626]   Expert 33 |    424 | GPU
DEBUG 01-15 10:09:27.940773.940773 lmp.py:1626]   Expert  3 |    587 | GPU
DEBUG 01-15 10:09:27.940384.940384 lmp.py:1626]   Expert 10 |    644 | GPU
DEBUG 01-15 10:09:27.940968.940968 lmp.py:1626]   Expert 15 |    645 | GPU
DEBUG 01-15 10:09:27.940658.940658 lmp.py:1626]   Expert 40 |    791 | GPU
DEBUG 01-15 10:09:27.940779.940779 lmp.py:1627] 
DEBUG 01-15 10:09:27.940779.940779 lmp.py:1627]   CPU total tokens: 3106 (25.3%)
DEBUG 01-15 10:09:27.940662.940662 lmp.py:1628]   GPU total tokens: 9182 (74.7%)
DEBUG 01-15 10:09:27.940201.940201 cuda_h.py:19] end experts_map_get cost 0.002718687057495117 seconds
INFO 01-15 10:09:27.941801.941801 client.py:127] Model loaded
DEBUG 01-15 10:09:27.941831.941831 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.941205.941205 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:27.941317.941317 lmp.py:1636] 
DEBUG 01-15 10:09:27.941317.941317 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:27.941878.941878 cuda_h.py:19] end cpu_experts_submit cost 0.00013637542724609375 seconds
DEBUG 01-15 10:09:27.942475.942475 cuda_h.py:19] end restore2model cost 0.0009765625 seconds
DEBUG 01-15 10:09:27.942716.942716 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:27.942400.942400 cuda_h.py:19] end sllm_worker_task cost 0.013353586196899414 seconds
DEBUG 01-15 10:09:27.943033.943033 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:27.942606.942606 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:27.943271.943271 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:27.943220.943220 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:27.943526.943526 cuda_h.py:19] end allocate_cuda_memory cost 0.0003485679626464844 seconds
DEBUG 01-15 10:09:27.944893.944893 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:27.944961.944961 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:27.944043.944043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:27.944143.944143 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9424d893-d535-4e5a-b8c5-7bb3378785dc
DEBUG 01-15 10:09:27.944649.944649 cuda_h.py:19] end move_flatidxs cost 0.0009093284606933594 seconds
DEBUG 01-15 10:09:27.944108.944108 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:27.944474.944474 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:27.945623.945623 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9424d893-d535-4e5a-b8c5-7bb3378785dc
DEBUG 01-15 10:09:27.945506.945506 cuda_h.py:19] end load_into_gpu_async cost 0.0016350746154785156 seconds
DEBUG 01-15 10:09:27.945778.945778 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:27.946544.946544 cuda_h.py:19] end restore_tensors2 cost 0.0004985332489013672 seconds
DEBUG 01-15 10:09:27.946063.946063 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003175973892211914 seconds
DEBUG 01-15 10:09:27.946601.946601 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:27.949273.949273 cuda_h.py:19] end restore2model cost 0.0026416778564453125 seconds
DEBUG 01-15 10:09:27.949924.949924 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006246328353881836 seconds
DEBUG 01-15 10:09:27.949051.949051 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:27.949412.949412 cuda_h.py:19] end gpu_sexperts cost 0.00026917457580566406 seconds
DEBUG 01-15 10:09:27.949579.949579 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:27.951035.951035 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014955997467041016 seconds
DEBUG 01-15 10:09:27.951187.951187 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:27.952471.952471 cuda_h.py:19] end gpu_group_list cost 0.0003261566162109375 seconds
DEBUG 01-15 10:09:27.952528.952528 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:27.953142.953142 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006952285766601562 seconds
DEBUG 01-15 10:09:27.953580.953580 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:27.953595.953595 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-15 10:09:27.953099.953099 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:27.954262.954262 cuda_h.py:19] end group_tensors cost 0.009898900985717773 seconds
DEBUG 01-15 10:09:27.954915.954915 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:27.958822.958822 cuda_h.py:19] end group pad cost 0.0038797855377197266 seconds
DEBUG 01-15 10:09:27.958950.958950 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:27.978773.978773 cuda_h.py:19] end group_einsum cost 0.019377708435058594 seconds
DEBUG 01-15 10:09:27.978329.978329 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:27.982371.982371 cuda_h.py:19] end get_outputs_cpu1 cost 0.003960132598876953 seconds
DEBUG 01-15 10:09:27.983866.983866 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0402369499206543 seconds
DEBUG 01-15 10:09:27.984241.984241 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031074047088623047 seconds
DEBUG 01-15 10:09:27.984201.984201 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:27.984444.984444 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:27.985048.985048 cuda_h.py:19] end index_scatter cost 0.00015616416931152344 seconds
DEBUG 01-15 10:09:27.985887.985887 cuda_h.py:19] end cpuoutputsdeal cost 0.0012416839599609375 seconds
DEBUG 01-15 10:09:27.985208.985208 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:27.985787.985787 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9424d893-d535-4e5a-b8c5-7bb3378785dc
INFO 01-15 10:09:27.996140.996140 client.py:127] Model loaded
DEBUG 01-15 10:09:27.996450.996450 cuda_h.py:19] end wait_experts cost 0.01049661636352539 seconds
DEBUG 01-15 10:09:27.996651.996651 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:27.996165.996165 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:27.996758.996758 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:27.997667.997667 cuda_h.py:19] end gpu_group_tensor cost 0.0003802776336669922 seconds
DEBUG 01-15 10:09:27.997171.997171 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:27.998818.998818 cuda_h.py:19] end gpu_group_einsum cost 0.0009963512420654297 seconds
DEBUG 01-15 10:09:27.998681.998681 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:27.998850.998850 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:27.999892.999892 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005817413330078125 seconds
DEBUG 01-15 10:09:27.999047.999047 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:27.999849.999849 cuda_h.py:19] end concat_expert_out cost 0.00012755393981933594 seconds
DEBUG 01-15 10:09:27.999708.999708 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.000305.000305 cuda_h.py:19] end index_scatter cost 0.00012493133544921875 seconds
DEBUG 01-15 10:09:28.000480.000480 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001435995101928711 seconds
DEBUG 01-15 10:09:28.000189.000189 cuda_h.py:19] end gpu_experts cost 0.003941774368286133 seconds
DEBUG 01-15 10:09:28.000547.000547 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06350421905517578 seconds
DEBUG 01-15 10:09:28.001495.001495 cuda_h.py:19] end prefill_layer cost 0.07291960716247559 seconds
DEBUG 01-15 10:09:28.001434.001434 lmp.py:1552] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-15 10:09:28.001383.001383 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.001809.001809 lmp.py:1495] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-15 10:09:28.001427.001427 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:28.001675.001675 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:28.002204.002204 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 8.368492126464844e-05 seconds
DEBUG 01-15 10:09:28.002081.002081 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00018072128295898438 seconds
DEBUG 01-15 10:09:28.002838.002838 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.002617.002617 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.002810.002810 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.002488.002488 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.003618.003618 cuda_h.py:19] end allocate_cuda_memory cost 0.00029659271240234375 seconds
DEBUG 01-15 10:09:28.003767.003767 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.003052.003052 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.003949.003949 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.003181.003181 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 06085520-c5bc-485b-9b84-af4dd79ca6aa
DEBUG 01-15 10:09:28.003463.003463 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.003459.003459 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:28.004966.004966 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 06085520-c5bc-485b-9b84-af4dd79ca6aa
DEBUG 01-15 10:09:28.004565.004565 cuda_h.py:19] end load_into_gpu_async cost 0.0012543201446533203 seconds
DEBUG 01-15 10:09:28.004466.004466 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.004338.004338 cuda_h.py:19] end restore_tensors2 cost 8.96453857421875e-05 seconds
DEBUG 01-15 10:09:28.004048.004048 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001920461654663086 seconds
INFO 01-15 10:09:28.004474.004474 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 06085520-c5bc-485b-9b84-af4dd79ca6aa
DEBUG 01-15 10:09:28.004586.004586 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.009937.009937 cuda_h.py:19] end self_attn cost 0.004633426666259766 seconds
DEBUG 01-15 10:09:28.010100.010100 cuda_h.py:19] end iln_self_attn_paln cost 0.007587909698486328 seconds
DEBUG 01-15 10:09:28.010759.010759 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-15 10:09:28.010278.010278 cuda_h.py:10] start gate
INFO 01-15 10:09:28.011668.011668 client.py:127] Model loaded
DEBUG 01-15 10:09:28.011930.011930 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.011352.011352 cuda_h.py:19] end gate cost 0.0015664100646972656 seconds
DEBUG 01-15 10:09:28.012711.012711 cuda_h.py:19] end restore2model cost 0.0009260177612304688 seconds
DEBUG 01-15 10:09:28.012324.012324 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.012303.012303 cuda_h.py:19] end sllm_worker_task cost 0.009988069534301758 seconds
DEBUG 01-15 10:09:28.013774.013774 lmp.py:1616] 
DEBUG 01-15 10:09:28.013774.013774 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.013144.013144 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.013636.013636 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.013829.013829 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.013446.013446 lmp.py:1620] 
DEBUG 01-15 10:09:28.013446.013446 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.013825.013825 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.013018.013018 lmp.py:1626]   Expert 42 |     23 | CPU
DEBUG 01-15 10:09:28.013304.013304 lmp.py:1626]   Expert 19 |     25 | CPU
DEBUG 01-15 10:09:28.013444.013444 lmp.py:1626]   Expert 30 |     27 | CPU
DEBUG 01-15 10:09:28.013392.013392 lmp.py:1626]   Expert 32 |     45 | CPU
DEBUG 01-15 10:09:28.013102.013102 lmp.py:1626]   Expert  6 |     58 | CPU
DEBUG 01-15 10:09:28.013288.013288 lmp.py:1626]   Expert 53 |     73 | CPU
DEBUG 01-15 10:09:28.013998.013998 lmp.py:1626]   Expert  5 |     77 | CPU
DEBUG 01-15 10:09:28.013708.013708 lmp.py:1626]   Expert  1 |     81 | CPU
DEBUG 01-15 10:09:28.013431.013431 lmp.py:1626]   Expert 13 |    120 | CPU
DEBUG 01-15 10:09:28.013094.013094 lmp.py:1626]   Expert  9 |    123 | CPU
DEBUG 01-15 10:09:28.013565.013565 lmp.py:1626]   Expert 63 |    125 | CPU
DEBUG 01-15 10:09:28.013275.013275 lmp.py:1626]   Expert 34 |    126 | CPU
DEBUG 01-15 10:09:28.013746.013746 lmp.py:1626]   Expert 58 |    130 | CPU
DEBUG 01-15 10:09:28.014648.014648 lmp.py:1626]   Expert 50 |    131 | CPU
DEBUG 01-15 10:09:28.014265.014265 lmp.py:1626]   Expert 11 |    135 | CPU
DEBUG 01-15 10:09:28.014975.014975 lmp.py:1626]   Expert 26 |    135 | CPU
DEBUG 01-15 10:09:28.014208.014208 lmp.py:1626]   Expert 31 |    139 | CPU
DEBUG 01-15 10:09:28.014679.014679 lmp.py:1626]   Expert 59 |    140 | CPU
DEBUG 01-15 10:09:28.014819.014819 lmp.py:1626]   Expert 18 |    142 | CPU
DEBUG 01-15 10:09:28.014198.014198 lmp.py:1626]   Expert 40 |    145 | CPU
DEBUG 01-15 10:09:28.014907.014907 lmp.py:1626]   Expert 12 |    149 | CPU
DEBUG 01-15 10:09:28.014379.014379 lmp.py:1626]   Expert 46 |    150 | CPU
DEBUG 01-15 10:09:28.014373.014373 lmp.py:1626]   Expert 20 |    152 | CPU
DEBUG 01-15 10:09:28.014367.014367 lmp.py:1626]   Expert 48 |    152 | CPU
DEBUG 01-15 10:09:28.014984.014984 lmp.py:1626]   Expert 56 |    152 | CPU
DEBUG 01-15 10:09:28.014125.014125 lmp.py:1626]   Expert  4 |    153 | CPU
DEBUG 01-15 10:09:28.014596.014596 lmp.py:1626]   Expert  2 |    154 | CPU
DEBUG 01-15 10:09:28.014829.014829 lmp.py:1626]   Expert 61 |    154 | CPU
DEBUG 01-15 10:09:28.014823.014823 lmp.py:1626]   Expert 33 |    155 | CPU
DEBUG 01-15 10:09:28.014294.014294 lmp.py:1626]   Expert 35 |    162 | CPU
DEBUG 01-15 10:09:28.014766.014766 lmp.py:1626]   Expert 10 |    166 | CPU
DEBUG 01-15 10:09:28.014760.014760 lmp.py:1626]   Expert 55 |    169 | CPU
DEBUG 01-15 10:09:28.014993.014993 lmp.py:1626]   Expert 51 |    175 | GPU
DEBUG 01-15 10:09:28.014226.014226 lmp.py:1626]   Expert 36 |    178 | GPU
DEBUG 01-15 10:09:28.014459.014459 lmp.py:1626]   Expert  8 |    183 | GPU
DEBUG 01-15 10:09:28.014691.014691 lmp.py:1626]   Expert 52 |    183 | GPU
DEBUG 01-15 10:09:28.014686.014686 lmp.py:1626]   Expert 37 |    187 | GPU
DEBUG 01-15 10:09:28.014919.014919 lmp.py:1626]   Expert 57 |    206 | GPU
DEBUG 01-15 10:09:28.014536.014536 lmp.py:1626]   Expert  0 |    207 | GPU
DEBUG 01-15 10:09:28.014007.014007 lmp.py:1626]   Expert 39 |    220 | GPU
DEBUG 01-15 10:09:28.014684.014684 lmp.py:1626]   Expert 25 |    225 | GPU
DEBUG 01-15 10:09:28.014181.014181 lmp.py:1626]   Expert 62 |    235 | GPU
DEBUG 01-15 10:09:28.014155.014155 lmp.py:1626]   Expert 38 |    238 | GPU
DEBUG 01-15 10:09:28.014652.014652 lmp.py:1626]   Expert  7 |    244 | GPU
DEBUG 01-15 10:09:28.014434.014434 lmp.py:1626]   Expert  3 |    246 | GPU
DEBUG 01-15 10:09:28.014455.014455 lmp.py:1626]   Expert 24 |    249 | GPU
DEBUG 01-15 10:09:28.014237.014237 lmp.py:1626]   Expert 28 |    253 | GPU
DEBUG 01-15 10:09:28.015019.015019 lmp.py:1626]   Expert 27 |    256 | GPU
DEBUG 01-15 10:09:28.015800.015800 lmp.py:1626]   Expert 60 |    258 | GPU
DEBUG 01-15 10:09:28.015106.015106 lmp.py:1626]   Expert 49 |    260 | GPU
DEBUG 01-15 10:09:28.015649.015649 lmp.py:1626]   Expert 21 |    262 | GPU
DEBUG 01-15 10:09:28.015908.015908 lmp.py:1626]   Expert 16 |    268 | GPU
DEBUG 01-15 10:09:28.015451.015451 lmp.py:1626]   Expert 43 |    270 | GPU
DEBUG 01-15 10:09:28.015472.015472 lmp.py:1626]   Expert 23 |    276 | GPU
DEBUG 01-15 10:09:28.015068.015068 lmp.py:1626]   Expert 29 |    276 | GPU
DEBUG 01-15 10:09:28.015089.015089 lmp.py:1626]   Expert 22 |    292 | GPU
DEBUG 01-15 10:09:28.015632.015632 lmp.py:1626]   Expert 47 |    292 | GPU
DEBUG 01-15 10:09:28.015414.015414 lmp.py:1626]   Expert 15 |    293 | GPU
DEBUG 01-15 10:09:28.015196.015196 lmp.py:1626]   Expert 41 |    296 | GPU
DEBUG 01-15 10:09:28.015455.015455 lmp.py:1626]   Expert 44 |    305 | GPU
DEBUG 01-15 10:09:28.015999.015999 lmp.py:1626]   Expert 54 |    351 | GPU
DEBUG 01-15 10:09:28.015781.015781 lmp.py:1626]   Expert 14 |    376 | GPU
DEBUG 01-15 10:09:28.015324.015324 lmp.py:1626]   Expert 17 |    405 | GPU
DEBUG 01-15 10:09:28.015344.015344 lmp.py:1626]   Expert 45 |    455 | GPU
DEBUG 01-15 10:09:28.015511.015511 lmp.py:1627] 
DEBUG 01-15 10:09:28.015511.015511 lmp.py:1627]   CPU total tokens: 3868 (31.5%)
DEBUG 01-15 10:09:28.015915.015915 lmp.py:1628]   GPU total tokens: 8420 (68.5%)
DEBUG 01-15 10:09:28.015088.015088 cuda_h.py:19] end experts_map_get cost 0.0025746822357177734 seconds
DEBUG 01-15 10:09:28.015461.015461 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.015118.015118 lmp.py:1636] 
DEBUG 01-15 10:09:28.015118.015118 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.015053.015053 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-15 10:09:28.015319.015319 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.015215.015215 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.015612.015612 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.016277.016277 cuda_h.py:19] end allocate_cuda_memory cost 0.00024318695068359375 seconds
DEBUG 01-15 10:09:28.016346.016346 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.016917.016917 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.016263.016263 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.016681.016681 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d14dc762-0525-49a6-9a34-53fc8cae1dfd
DEBUG 01-15 10:09:28.016775.016775 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.017246.017246 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.017372.017372 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:28.017246.017246 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d14dc762-0525-49a6-9a34-53fc8cae1dfd
DEBUG 01-15 10:09:28.017019.017019 cuda_h.py:19] end load_into_gpu_async cost 0.001638650894165039 seconds
DEBUG 01-15 10:09:28.017651.017651 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.018937.018937 cuda_h.py:19] end move_flatidxs cost 0.0009813308715820312 seconds
DEBUG 01-15 10:09:28.018256.018256 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.018012.018012 cuda_h.py:19] end restore_tensors2 cost 0.0006556510925292969 seconds
DEBUG 01-15 10:09:28.018459.018459 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00310516357421875 seconds
DEBUG 01-15 10:09:28.018288.018288 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.021067.021067 cuda_h.py:19] end restore2model cost 0.0026514530181884766 seconds
DEBUG 01-15 10:09:28.021738.021738 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005975484848022461 seconds
DEBUG 01-15 10:09:28.021249.021249 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.021658.021658 cuda_h.py:19] end gpu_sexperts cost 0.00030517578125 seconds
DEBUG 01-15 10:09:28.021640.021640 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.023826.023826 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015766620635986328 seconds
DEBUG 01-15 10:09:28.024328.024328 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.024291.024291 cuda_h.py:19] end gpu_group_list cost 0.0004100799560546875 seconds
DEBUG 01-15 10:09:28.024461.024461 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.025122.025122 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007278919219970703 seconds
DEBUG 01-15 10:09:28.025065.025065 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.025272.025272 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9788742065429688e-05 seconds
DEBUG 01-15 10:09:28.025491.025491 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.031662.031662 cuda_h.py:19] end group_tensors cost 0.012647151947021484 seconds
DEBUG 01-15 10:09:28.032714.032714 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.036495.036495 cuda_h.py:19] end group pad cost 0.004065752029418945 seconds
DEBUG 01-15 10:09:28.036000.036000 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.054633.054633 cuda_h.py:19] end group_einsum cost 0.018628835678100586 seconds
DEBUG 01-15 10:09:28.055135.055135 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.059570.059570 cuda_h.py:19] end get_outputs_cpu1 cost 0.0046024322509765625 seconds
DEBUG 01-15 10:09:28.060159.060159 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04321789741516113 seconds
DEBUG 01-15 10:09:28.061237.061237 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.035657405853271484 seconds
DEBUG 01-15 10:09:28.061257.061257 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.062926.062926 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.062690.062690 cuda_h.py:19] end index_scatter cost 0.000148773193359375 seconds
DEBUG 01-15 10:09:28.062040.062040 cuda_h.py:19] end cpuoutputsdeal cost 0.00115966796875 seconds
DEBUG 01-15 10:09:28.063599.063599 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.063701.063701 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d14dc762-0525-49a6-9a34-53fc8cae1dfd
INFO 01-15 10:09:28.067425.067425 client.py:127] Model loaded
DEBUG 01-15 10:09:28.067555.067555 cuda_h.py:19] end wait_experts cost 0.004741668701171875 seconds
DEBUG 01-15 10:09:28.067650.067650 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.068973.068973 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.068227.068227 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.068647.068647 cuda_h.py:19] end gpu_group_tensor cost 0.00040340423583984375 seconds
DEBUG 01-15 10:09:28.068013.068013 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.070161.070161 cuda_h.py:19] end gpu_group_einsum cost 0.0011551380157470703 seconds
DEBUG 01-15 10:09:28.070633.070633 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.070849.070849 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.071606.071606 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005803108215332031 seconds
DEBUG 01-15 10:09:28.071782.071782 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.071736.071736 cuda_h.py:19] end concat_expert_out cost 0.0001366138458251953 seconds
DEBUG 01-15 10:09:28.071310.071310 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.071396.071396 cuda_h.py:19] end index_scatter cost 0.00011897087097167969 seconds
DEBUG 01-15 10:09:28.071757.071757 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014314651489257812 seconds
DEBUG 01-15 10:09:28.072048.072048 cuda_h.py:19] end gpu_experts cost 0.0040853023529052734 seconds
DEBUG 01-15 10:09:28.072637.072637 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.061955928802490234 seconds
DEBUG 01-15 10:09:28.073733.073733 cuda_h.py:19] end prefill_layer cost 0.07128024101257324 seconds
DEBUG 01-15 10:09:28.073870.073870 lmp.py:1552] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-15 10:09:28.073104.073104 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.073914.073914 lmp.py:1495] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-15 10:09:28.073486.073486 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:28.073018.073018 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:28.073030.073030 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:28.073140.073140 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.073164.073164 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.0003108978271484375 seconds
DEBUG 01-15 10:09:28.074235.074235 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.074484.074484 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.074422.074422 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.074688.074688 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.075683.075683 cuda_h.py:19] end allocate_cuda_memory cost 0.0003247261047363281 seconds
DEBUG 01-15 10:09:28.075692.075692 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.075727.075727 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.075457.075457 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.075690.075690 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3a6a26a7-a9de-441d-b6ac-dd3c8bd6d46f
DEBUG 01-15 10:09:28.075302.075302 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.076962.076962 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.076537.076537 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3a6a26a7-a9de-441d-b6ac-dd3c8bd6d46f
DEBUG 01-15 10:09:28.076805.076805 cuda_h.py:19] end load_into_gpu_async cost 0.0011439323425292969 seconds
DEBUG 01-15 10:09:28.076945.076945 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.076585.076585 cuda_h.py:19] end restore_tensors2 cost 9.274482727050781e-05 seconds
DEBUG 01-15 10:09:28.076487.076487 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023717880249023438 seconds
INFO 01-15 10:09:28.076654.076654 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3a6a26a7-a9de-441d-b6ac-dd3c8bd6d46f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.081907.081907 cuda_h.py:19] end self_attn cost 0.0051233768463134766 seconds
DEBUG 01-15 10:09:28.081414.081414 cuda_h.py:19] end iln_self_attn_paln cost 0.0073511600494384766 seconds
DEBUG 01-15 10:09:28.081503.081503 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-15 10:09:28.081684.081684 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.082181.082181 cuda_h.py:19] end gate cost 0.0009388923645019531 seconds
DEBUG 01-15 10:09:28.083058.083058 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.083845.083845 lmp.py:1616] 
DEBUG 01-15 10:09:28.083845.083845 lmp.py:1616] Expert Token Distribution & Device Allocation:
INFO 01-15 10:09:28.083802.083802 client.py:127] Model loaded
DEBUG 01-15 10:09:28.083746.083746 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.083299.083299 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.083387.083387 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.084149.084149 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.084747.084747 lmp.py:1620] 
DEBUG 01-15 10:09:28.084747.084747 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.084848.084848 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.084710.084710 lmp.py:1626]   Expert 34 |     29 | CPU
DEBUG 01-15 10:09:28.084427.084427 lmp.py:1626]   Expert  7 |     30 | CPU
DEBUG 01-15 10:09:28.084712.084712 lmp.py:1626]   Expert 13 |     42 | CPU
DEBUG 01-15 10:09:28.084760.084760 lmp.py:1626]   Expert 54 |     78 | CPU
DEBUG 01-15 10:09:28.084715.084715 lmp.py:1626]   Expert 18 |     83 | CPU
DEBUG 01-15 10:09:28.084239.084239 lmp.py:1626]   Expert 39 |     86 | CPU
DEBUG 01-15 10:09:28.084048.084048 lmp.py:1626]   Expert 49 |     91 | CPU
DEBUG 01-15 10:09:28.084857.084857 lmp.py:1626]   Expert 16 |    105 | CPU
DEBUG 01-15 10:09:28.084905.084905 lmp.py:1626]   Expert  0 |    106 | CPU
DEBUG 01-15 10:09:28.084668.084668 lmp.py:1626]   Expert 59 |    106 | CPU
DEBUG 01-15 10:09:28.084000.084000 lmp.py:1626]   Expert 21 |    107 | CPU
DEBUG 01-15 10:09:28.084571.084571 lmp.py:1626]   Expert 41 |    116 | CPU
DEBUG 01-15 10:09:28.084903.084903 lmp.py:1626]   Expert 15 |    119 | CPU
DEBUG 01-15 10:09:28.084474.084474 lmp.py:1626]   Expert 22 |    120 | CPU
DEBUG 01-15 10:09:28.085237.085237 lmp.py:1626]   Expert 45 |    122 | CPU
DEBUG 01-15 10:09:28.085807.085807 lmp.py:1626]   Expert 17 |    126 | CPU
DEBUG 01-15 10:09:28.085901.085901 lmp.py:1626]   Expert 52 |    134 | CPU
DEBUG 01-15 10:09:28.085233.085233 lmp.py:1626]   Expert  8 |    135 | CPU
DEBUG 01-15 10:09:28.085042.085042 lmp.py:1626]   Expert 35 |    137 | CPU
DEBUG 01-15 10:09:28.085819.085819 lmp.py:1626]   Expert 61 |    138 | CPU
DEBUG 01-15 10:09:28.085297.085297 lmp.py:1626]   Expert 38 |    140 | CPU
DEBUG 01-15 10:09:28.085060.085060 lmp.py:1626]   Expert 12 |    145 | CPU
DEBUG 01-15 10:09:28.085584.085584 lmp.py:1626]   Expert 48 |    148 | CPU
DEBUG 01-15 10:09:28.085347.085347 lmp.py:1626]   Expert 31 |    153 | CPU
DEBUG 01-15 10:09:28.085348.085348 lmp.py:1626]   Expert 36 |    154 | CPU
DEBUG 01-15 10:09:28.085634.085634 lmp.py:1626]   Expert 53 |    157 | CPU
DEBUG 01-15 10:09:28.085920.085920 lmp.py:1626]   Expert 50 |    159 | CPU
DEBUG 01-15 10:09:28.085729.085729 lmp.py:1626]   Expert 60 |    159 | CPU
DEBUG 01-15 10:09:28.085777.085777 lmp.py:1626]   Expert 40 |    161 | CPU
DEBUG 01-15 10:09:28.085539.085539 lmp.py:1626]   Expert 27 |    175 | CPU
DEBUG 01-15 10:09:28.085587.085587 lmp.py:1626]   Expert 19 |    195 | CPU
DEBUG 01-15 10:09:28.085634.085634 lmp.py:1626]   Expert  4 |    196 | CPU
DEBUG 01-15 10:09:28.085682.085682 lmp.py:1626]   Expert 29 |    201 | GPU
DEBUG 01-15 10:09:28.085206.085206 lmp.py:1626]   Expert 30 |    204 | GPU
DEBUG 01-15 10:09:28.085492.085492 lmp.py:1626]   Expert 26 |    217 | GPU
DEBUG 01-15 10:09:28.085825.085825 lmp.py:1626]   Expert 11 |    219 | GPU
DEBUG 01-15 10:09:28.085157.085157 lmp.py:1626]   Expert 20 |    220 | GPU
DEBUG 01-15 10:09:28.085681.085681 lmp.py:1626]   Expert 57 |    224 | GPU
DEBUG 01-15 10:09:28.085775.085775 lmp.py:1626]   Expert  6 |    227 | GPU
DEBUG 01-15 10:09:28.085107.085107 lmp.py:1626]   Expert 46 |    228 | GPU
DEBUG 01-15 10:09:28.085678.085678 lmp.py:1626]   Expert 43 |    229 | GPU
DEBUG 01-15 10:09:28.085249.085249 lmp.py:1626]   Expert 33 |    239 | GPU
DEBUG 01-15 10:09:28.085819.085819 lmp.py:1626]   Expert 23 |    242 | GPU
DEBUG 01-15 10:09:28.086675.086675 lmp.py:1626]   Expert  2 |    243 | GPU
DEBUG 01-15 10:09:28.086007.086007 lmp.py:1626]   Expert 42 |    247 | GPU
DEBUG 01-15 10:09:28.086538.086538 lmp.py:1626]   Expert 55 |    252 | GPU
DEBUG 01-15 10:09:28.086109.086109 lmp.py:1626]   Expert 32 |    254 | GPU
DEBUG 01-15 10:09:28.086944.086944 lmp.py:1626]   Expert 56 |    256 | GPU
DEBUG 01-15 10:09:28.086302.086302 lmp.py:1626]   Expert  3 |    261 | GPU
DEBUG 01-15 10:09:28.086137.086137 lmp.py:1626]   Expert  9 |    262 | GPU
DEBUG 01-15 10:09:28.086496.086496 lmp.py:1626]   Expert 28 |    264 | GPU
DEBUG 01-15 10:09:28.086377.086377 lmp.py:1626]   Expert 14 |    265 | GPU
DEBUG 01-15 10:09:28.086258.086258 lmp.py:1626]   Expert 51 |    275 | GPU
DEBUG 01-15 10:09:28.086378.086378 lmp.py:1626]   Expert 44 |    277 | GPU
DEBUG 01-15 10:09:28.086498.086498 lmp.py:1626]   Expert  1 |    278 | GPU
DEBUG 01-15 10:09:28.086856.086856 lmp.py:1626]   Expert 58 |    279 | GPU
DEBUG 01-15 10:09:28.086691.086691 lmp.py:1626]   Expert 63 |    286 | GPU
DEBUG 01-15 10:09:28.086811.086811 lmp.py:1626]   Expert 37 |    287 | GPU
DEBUG 01-15 10:09:28.086692.086692 lmp.py:1626]   Expert 47 |    295 | GPU
DEBUG 01-15 10:09:28.086335.086335 lmp.py:1626]   Expert 24 |    302 | GPU
DEBUG 01-15 10:09:28.086171.086171 lmp.py:1626]   Expert 10 |    310 | GPU
DEBUG 01-15 10:09:28.086290.086290 lmp.py:1626]   Expert 62 |    311 | GPU
DEBUG 01-15 10:09:28.086933.086933 lmp.py:1626]   Expert 25 |    317 | GPU
DEBUG 01-15 10:09:28.086576.086576 lmp.py:1626]   Expert  5 |    365 | GPU
DEBUG 01-15 10:09:28.086365.086365 lmp.py:1627] 
DEBUG 01-15 10:09:28.086365.086365 lmp.py:1627]   CPU total tokens: 3952 (32.2%)
DEBUG 01-15 10:09:28.086915.086915 lmp.py:1628]   GPU total tokens: 8336 (67.8%)
DEBUG 01-15 10:09:28.086426.086426 cuda_h.py:19] end experts_map_get cost 0.0034172534942626953 seconds
DEBUG 01-15 10:09:28.086409.086409 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.086033.086033 lmp.py:1636] 
DEBUG 01-15 10:09:28.086033.086033 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.086304.086304 cuda_h.py:19] end cpu_experts_submit cost 0.0001647472381591797 seconds
DEBUG 01-15 10:09:28.086344.086344 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.086386.086386 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.087280.087280 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.087899.087899 cuda_h.py:19] end allocate_cuda_memory cost 0.0002422332763671875 seconds
DEBUG 01-15 10:09:28.087941.087941 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.087575.087575 cuda_h.py:19] end restore2model cost 0.00394129753112793 seconds
DEBUG 01-15 10:09:28.088518.088518 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.088912.088912 cuda_h.py:19] end sllm_worker_task cost 0.014106988906860352 seconds
DEBUG 01-15 10:09:28.088016.088016 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.088397.088397 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 51a40b57-07b1-4bf6-8b21-c602c6c9ba2c
DEBUG 01-15 10:09:28.088598.088598 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.088595.088595 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.089755.089755 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:28.089392.089392 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 51a40b57-07b1-4bf6-8b21-c602c6c9ba2c
DEBUG 01-15 10:09:28.090874.090874 cuda_h.py:19] end load_into_gpu_async cost 0.001940011978149414 seconds
DEBUG 01-15 10:09:28.090122.090122 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.090110.090110 cuda_h.py:19] end move_flatidxs cost 0.0011234283447265625 seconds
DEBUG 01-15 10:09:28.090948.090948 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.090873.090873 cuda_h.py:19] end restore_tensors2 cost 0.0007989406585693359 seconds
DEBUG 01-15 10:09:28.091054.091054 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004082441329956055 seconds
DEBUG 01-15 10:09:28.091545.091545 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.094658.094658 cuda_h.py:19] end restore2model cost 0.002928495407104492 seconds
DEBUG 01-15 10:09:28.094892.094892 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007225990295410156 seconds
DEBUG 01-15 10:09:28.094018.094018 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.094214.094214 cuda_h.py:19] end gpu_sexperts cost 0.00028896331787109375 seconds
DEBUG 01-15 10:09:28.094236.094236 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.096460.096460 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014867782592773438 seconds
DEBUG 01-15 10:09:28.096798.096798 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.097632.097632 cuda_h.py:19] end gpu_group_list cost 0.0003218650817871094 seconds
DEBUG 01-15 10:09:28.097927.097927 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.098470.098470 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007448196411132812 seconds
DEBUG 01-15 10:09:28.098484.098484 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.098744.098744 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-15 10:09:28.098109.098109 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.102753.102753 cuda_h.py:19] end group_tensors cost 0.011669397354125977 seconds
DEBUG 01-15 10:09:28.103663.103663 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.107463.107463 cuda_h.py:19] end group pad cost 0.004248619079589844 seconds
DEBUG 01-15 10:09:28.107743.107743 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.128354.128354 cuda_h.py:19] end group_einsum cost 0.02028942108154297 seconds
DEBUG 01-15 10:09:28.128877.128877 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.133463.133463 cuda_h.py:19] end get_outputs_cpu1 cost 0.0045702457427978516 seconds
DEBUG 01-15 10:09:28.133695.133695 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04496622085571289 seconds
DEBUG 01-15 10:09:28.134347.134347 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03648066520690918 seconds
DEBUG 01-15 10:09:28.134008.134008 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.135001.135001 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.135962.135962 cuda_h.py:19] end index_scatter cost 0.00013327598571777344 seconds
DEBUG 01-15 10:09:28.136476.136476 cuda_h.py:19] end cpuoutputsdeal cost 0.001255035400390625 seconds
DEBUG 01-15 10:09:28.136207.136207 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.136230.136230 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 51a40b57-07b1-4bf6-8b21-c602c6c9ba2c
INFO 01-15 10:09:28.140107.140107 client.py:127] Model loaded
DEBUG 01-15 10:09:28.140707.140707 cuda_h.py:19] end wait_experts cost 0.003757476806640625 seconds
DEBUG 01-15 10:09:28.140226.140226 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.140601.140601 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.140372.140372 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.140181.140181 cuda_h.py:19] end gpu_group_tensor cost 0.00034809112548828125 seconds
DEBUG 01-15 10:09:28.141950.141950 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.142263.142263 cuda_h.py:19] end gpu_group_einsum cost 0.000926971435546875 seconds
DEBUG 01-15 10:09:28.142330.142330 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.142155.142155 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.143705.143705 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005400180816650391 seconds
DEBUG 01-15 10:09:28.143661.143661 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.143111.143111 cuda_h.py:19] end concat_expert_out cost 0.00011968612670898438 seconds
DEBUG 01-15 10:09:28.143387.143387 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.143752.143752 cuda_h.py:19] end index_scatter cost 0.00011181831359863281 seconds
DEBUG 01-15 10:09:28.143582.143582 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013210773468017578 seconds
DEBUG 01-15 10:09:28.143058.143058 cuda_h.py:19] end gpu_experts cost 0.0036399364471435547 seconds
DEBUG 01-15 10:09:28.144588.144588 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.062181711196899414 seconds
DEBUG 01-15 10:09:28.144113.144113 cuda_h.py:19] end prefill_layer cost 0.07159137725830078 seconds
DEBUG 01-15 10:09:28.145435.145435 lmp.py:1552] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-15 10:09:28.145093.145093 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.145327.145327 lmp.py:1495] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-15 10:09:28.145852.145852 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:28.145332.145332 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:28.145237.145237 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.556510925292969e-05 seconds
DEBUG 01-15 10:09:28.145413.145413 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.145563.145563 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.0003101825714111328 seconds
DEBUG 01-15 10:09:28.145204.145204 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.146923.146923 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.146808.146808 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.146645.146645 cuda_h.py:19] end allocate_cuda_memory cost 0.0003027915954589844 seconds
DEBUG 01-15 10:09:28.146237.146237 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.146815.146815 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.146174.146174 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.146453.146453 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6447f25f-b304-4f22-913f-7eae5700fb61
DEBUG 01-15 10:09:28.146543.146543 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.147993.147993 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:28.147692.147692 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6447f25f-b304-4f22-913f-7eae5700fb61
DEBUG 01-15 10:09:28.147046.147046 cuda_h.py:19] end load_into_gpu_async cost 0.0009799003601074219 seconds
DEBUG 01-15 10:09:28.147279.147279 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.147701.147701 cuda_h.py:19] end restore_tensors2 cost 9.012222290039062e-05 seconds
DEBUG 01-15 10:09:28.147126.147126 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018191337585449219 seconds
INFO 01-15 10:09:28.148717.148717 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6447f25f-b304-4f22-913f-7eae5700fb61
DEBUG 01-15 10:09:28.148378.148378 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.152119.152119 cuda_h.py:19] end self_attn cost 0.004583120346069336 seconds
DEBUG 01-15 10:09:28.153744.153744 cuda_h.py:19] end iln_self_attn_paln cost 0.007081747055053711 seconds
DEBUG 01-15 10:09:28.153211.153211 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-15 10:09:28.153060.153060 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.154675.154675 cuda_h.py:19] end gate cost 0.0008859634399414062 seconds
DEBUG 01-15 10:09:28.154830.154830 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.155066.155066 lmp.py:1616] 
DEBUG 01-15 10:09:28.155066.155066 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.155810.155810 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.155632.155632 lmp.py:1618]   CPU experts: 32 (50%)
INFO 01-15 10:09:28.155178.155178 client.py:127] Model loaded
DEBUG 01-15 10:09:28.155122.155122 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.155145.155145 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.155511.155511 lmp.py:1620] 
DEBUG 01-15 10:09:28.155511.155511 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.155506.155506 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.156852.156852 lmp.py:1626]   Expert 15 |     60 | CPU
DEBUG 01-15 10:09:28.156999.156999 lmp.py:1626]   Expert 41 |     70 | CPU
DEBUG 01-15 10:09:28.156000.156000 lmp.py:1626]   Expert  0 |     74 | CPU
DEBUG 01-15 10:09:28.156478.156478 lmp.py:1626]   Expert 63 |     75 | CPU
DEBUG 01-15 10:09:28.156334.156334 lmp.py:1626]   Expert 20 |     83 | CPU
DEBUG 01-15 10:09:28.156388.156388 lmp.py:1626]   Expert  7 |     91 | CPU
DEBUG 01-15 10:09:28.156204.156204 lmp.py:1626]   Expert 45 |     93 | CPU
DEBUG 01-15 10:09:28.156470.156470 lmp.py:1626]   Expert 28 |    101 | CPU
DEBUG 01-15 10:09:28.156735.156735 lmp.py:1626]   Expert 54 |    107 | CPU
DEBUG 01-15 10:09:28.156524.156524 lmp.py:1626]   Expert 12 |    108 | CPU
DEBUG 01-15 10:09:28.156836.156836 lmp.py:1626]   Expert 52 |    119 | CPU
DEBUG 01-15 10:09:28.156148.156148 lmp.py:1626]   Expert 59 |    123 | CPU
DEBUG 01-15 10:09:28.156983.156983 lmp.py:1626]   Expert  5 |    124 | CPU
DEBUG 01-15 10:09:28.156818.156818 lmp.py:1626]   Expert 40 |    124 | CPU
DEBUG 01-15 10:09:28.156414.156414 lmp.py:1626]   Expert  4 |    130 | CPU
DEBUG 01-15 10:09:28.156641.156641 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:28.156237.156237 lmp.py:1626]   Expert 62 |    134 | CPU
DEBUG 01-15 10:09:28.156264.156264 lmp.py:1626]   Expert 61 |    138 | CPU
DEBUG 01-15 10:09:28.156338.156338 lmp.py:1626]   Expert 13 |    139 | CPU
DEBUG 01-15 10:09:28.156603.156603 lmp.py:1626]   Expert 55 |    139 | CPU
DEBUG 01-15 10:09:28.156869.156869 lmp.py:1626]   Expert 42 |    140 | CPU
DEBUG 01-15 10:09:28.156373.156373 lmp.py:1626]   Expert 21 |    142 | CPU
DEBUG 01-15 10:09:28.156446.156446 lmp.py:1626]   Expert 10 |    146 | CPU
DEBUG 01-15 10:09:28.156282.156282 lmp.py:1626]   Expert 14 |    146 | CPU
DEBUG 01-15 10:09:28.156640.156640 lmp.py:1626]   Expert 22 |    149 | CPU
DEBUG 01-15 10:09:28.156998.156998 lmp.py:1626]   Expert 51 |    156 | CPU
DEBUG 01-15 10:09:28.156833.156833 lmp.py:1626]   Expert 32 |    157 | CPU
DEBUG 01-15 10:09:28.156191.156191 lmp.py:1626]   Expert 25 |    168 | CPU
DEBUG 01-15 10:09:28.156026.156026 lmp.py:1626]   Expert  1 |    173 | CPU
DEBUG 01-15 10:09:28.156100.156100 lmp.py:1626]   Expert 19 |    175 | CPU
DEBUG 01-15 10:09:28.156365.156365 lmp.py:1626]   Expert 53 |    175 | CPU
DEBUG 01-15 10:09:28.156631.156631 lmp.py:1626]   Expert 47 |    176 | CPU
DEBUG 01-15 10:09:28.156368.156368 cuda_h.py:19] end restore2model cost 0.0013811588287353516 seconds
DEBUG 01-15 10:09:28.157344.157344 lmp.py:1626]   Expert 50 |    177 | GPU
DEBUG 01-15 10:09:28.157512.157512 cuda_h.py:19] end sllm_worker_task cost 0.011202812194824219 seconds
DEBUG 01-15 10:09:28.157276.157276 lmp.py:1626]   Expert 26 |    179 | GPU
DEBUG 01-15 10:09:28.157770.157770 lmp.py:1626]   Expert  6 |    181 | GPU
DEBUG 01-15 10:09:28.157559.157559 lmp.py:1626]   Expert  2 |    182 | GPU
DEBUG 01-15 10:09:28.157725.157725 lmp.py:1626]   Expert 30 |    183 | GPU
DEBUG 01-15 10:09:28.157653.157653 lmp.py:1626]   Expert 11 |    186 | GPU
DEBUG 01-15 10:09:28.157779.157779 lmp.py:1626]   Expert 35 |    187 | GPU
DEBUG 01-15 10:09:28.157661.157661 lmp.py:1626]   Expert 57 |    190 | GPU
DEBUG 01-15 10:09:28.157780.157780 lmp.py:1626]   Expert 56 |    192 | GPU
DEBUG 01-15 10:09:28.157947.157947 lmp.py:1626]   Expert 48 |    202 | GPU
DEBUG 01-15 10:09:28.157874.157874 lmp.py:1626]   Expert 24 |    206 | GPU
DEBUG 01-15 10:09:28.157087.157087 lmp.py:1626]   Expert 44 |    209 | GPU
DEBUG 01-15 10:09:28.157015.157015 lmp.py:1626]   Expert 16 |    212 | GPU
DEBUG 01-15 10:09:28.157465.157465 lmp.py:1626]   Expert 46 |    215 | GPU
DEBUG 01-15 10:09:28.157916.157916 lmp.py:1626]   Expert 39 |    222 | GPU
DEBUG 01-15 10:09:28.157367.157367 lmp.py:1626]   Expert 18 |    227 | GPU
DEBUG 01-15 10:09:28.157341.157341 lmp.py:1626]   Expert 29 |    233 | GPU
DEBUG 01-15 10:09:28.157554.157554 lmp.py:1626]   Expert 37 |    244 | GPU
DEBUG 01-15 10:09:28.157005.157005 lmp.py:1626]   Expert 31 |    253 | GPU
DEBUG 01-15 10:09:28.157124.157124 lmp.py:1626]   Expert 36 |    257 | GPU
DEBUG 01-15 10:09:28.157814.157814 lmp.py:1626]   Expert 60 |    257 | GPU
DEBUG 01-15 10:09:28.157695.157695 lmp.py:1626]   Expert  3 |    259 | GPU
DEBUG 01-15 10:09:28.157146.157146 lmp.py:1626]   Expert 38 |    262 | GPU
DEBUG 01-15 10:09:28.157120.157120 lmp.py:1626]   Expert 17 |    264 | GPU
DEBUG 01-15 10:09:28.157332.157332 lmp.py:1626]   Expert  9 |    268 | GPU
DEBUG 01-15 10:09:28.157307.157307 lmp.py:1626]   Expert 23 |    277 | GPU
DEBUG 01-15 10:09:28.157281.157281 lmp.py:1626]   Expert 27 |    346 | GPU
DEBUG 01-15 10:09:28.157255.157255 lmp.py:1626]   Expert 43 |    364 | GPU
DEBUG 01-15 10:09:28.157229.157229 lmp.py:1626]   Expert 33 |    397 | GPU
DEBUG 01-15 10:09:28.157441.157441 lmp.py:1626]   Expert  8 |    401 | GPU
DEBUG 01-15 10:09:28.157415.157415 lmp.py:1626]   Expert 58 |    446 | GPU
DEBUG 01-15 10:09:28.157389.157389 lmp.py:1626]   Expert 49 |    542 | GPU
DEBUG 01-15 10:09:28.157509.157509 lmp.py:1627] 
DEBUG 01-15 10:09:28.157509.157509 lmp.py:1627]   CPU total tokens: 4068 (33.1%)
DEBUG 01-15 10:09:28.157582.157582 lmp.py:1628]   GPU total tokens: 8220 (66.9%)
DEBUG 01-15 10:09:28.157332.157332 cuda_h.py:19] end experts_map_get cost 0.0032727718353271484 seconds
DEBUG 01-15 10:09:28.157619.157619 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.157898.157898 lmp.py:1636] 
DEBUG 01-15 10:09:28.157898.157898 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.158079.158079 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-15 10:09:28.158921.158921 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.158201.158201 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.158758.158758 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.158343.158343 cuda_h.py:19] end allocate_cuda_memory cost 0.0002529621124267578 seconds
DEBUG 01-15 10:09:28.158101.158101 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.158526.158526 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.158064.158064 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.158958.158958 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42df85bc-117a-4e6c-8bab-a8d02076f8d9
DEBUG 01-15 10:09:28.159808.159808 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.159502.159502 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:28.159404.159404 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42df85bc-117a-4e6c-8bab-a8d02076f8d9
DEBUG 01-15 10:09:28.159869.159869 cuda_h.py:19] end load_into_gpu_async cost 0.0011658668518066406 seconds
DEBUG 01-15 10:09:28.159910.159910 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.159190.159190 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.160698.160698 cuda_h.py:19] end restore_tensors2 cost 0.0005536079406738281 seconds
DEBUG 01-15 10:09:28.160024.160024 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024051666259765625 seconds
DEBUG 01-15 10:09:28.160053.160053 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.161973.161973 cuda_h.py:19] end move_flatidxs cost 0.0009770393371582031 seconds
DEBUG 01-15 10:09:28.161233.161233 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.163075.163075 cuda_h.py:19] end restore2model cost 0.0026192665100097656 seconds
DEBUG 01-15 10:09:28.163587.163587 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00524449348449707 seconds
DEBUG 01-15 10:09:28.163283.163283 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.163519.163519 cuda_h.py:19] end gpu_sexperts cost 0.00028443336486816406 seconds
DEBUG 01-15 10:09:28.163302.163302 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.165328.165328 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015201568603515625 seconds
DEBUG 01-15 10:09:28.166632.166632 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.166010.166010 cuda_h.py:19] end gpu_group_list cost 0.0003376007080078125 seconds
DEBUG 01-15 10:09:28.166497.166497 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.167688.167688 cuda_h.py:19] end acpu_expert_weight_slices cost 0.000728607177734375 seconds
DEBUG 01-15 10:09:28.167127.167127 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.167718.167718 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0503997802734375e-05 seconds
DEBUG 01-15 10:09:28.167129.167129 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.166536.166536 cuda_h.py:19] end group_tensors cost 0.0058345794677734375 seconds
DEBUG 01-15 10:09:28.167357.167357 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.171422.171422 cuda_h.py:19] end group pad cost 0.004053831100463867 seconds
DEBUG 01-15 10:09:28.171802.171802 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.191075.191075 cuda_h.py:19] end group_einsum cost 0.0199434757232666 seconds
DEBUG 01-15 10:09:28.192107.192107 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.198611.198611 cuda_h.py:19] end get_outputs_cpu1 cost 0.006249904632568359 seconds
DEBUG 01-15 10:09:28.199598.199598 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03938412666320801 seconds
DEBUG 01-15 10:09:28.200105.200105 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03262758255004883 seconds
DEBUG 01-15 10:09:28.200409.200409 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.200173.200173 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.201864.201864 cuda_h.py:19] end index_scatter cost 0.00015211105346679688 seconds
DEBUG 01-15 10:09:28.201951.201951 cuda_h.py:19] end cpuoutputsdeal cost 0.0012366771697998047 seconds
DEBUG 01-15 10:09:28.201127.201127 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.201228.201228 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42df85bc-117a-4e6c-8bab-a8d02076f8d9
INFO 01-15 10:09:28.210208.210208 client.py:127] Model loaded
DEBUG 01-15 10:09:28.210159.210159 cuda_h.py:19] end wait_experts cost 0.009011268615722656 seconds
DEBUG 01-15 10:09:28.210592.210592 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.211491.211491 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.211454.211454 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.211879.211879 cuda_h.py:19] end gpu_group_tensor cost 0.0003783702850341797 seconds
DEBUG 01-15 10:09:28.211437.211437 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.213164.213164 cuda_h.py:19] end gpu_group_einsum cost 0.00122833251953125 seconds
DEBUG 01-15 10:09:28.213941.213941 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.213203.213203 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.214624.214624 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006048679351806641 seconds
DEBUG 01-15 10:09:28.214448.214448 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.214249.214249 cuda_h.py:19] end concat_expert_out cost 0.00012922286987304688 seconds
DEBUG 01-15 10:09:28.214493.214493 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.214063.214063 cuda_h.py:19] end index_scatter cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:28.214231.214231 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014514923095703125 seconds
DEBUG 01-15 10:09:28.215893.215893 cuda_h.py:19] end gpu_experts cost 0.0041544437408447266 seconds
DEBUG 01-15 10:09:28.215958.215958 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06182527542114258 seconds
DEBUG 01-15 10:09:28.216179.216179 cuda_h.py:19] end prefill_layer cost 0.07094764709472656 seconds
DEBUG 01-15 10:09:28.216833.216833 lmp.py:1552] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-15 10:09:28.216664.216664 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.216997.216997 lmp.py:1495] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-15 10:09:28.216854.216854 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:28.216432.216432 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:28.216060.216060 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.818771362304688e-05 seconds
DEBUG 01-15 10:09:28.216923.216923 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00015592575073242188 seconds
DEBUG 01-15 10:09:28.216197.216197 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.217632.217632 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.217969.217969 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.217959.217959 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.217722.217722 cuda_h.py:19] end allocate_cuda_memory cost 0.0003609657287597656 seconds
DEBUG 01-15 10:09:28.217281.217281 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.217872.217872 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.217437.217437 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.218638.218638 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2d13f387-87c7-4133-9ee9-3bd9b9a3a9eb
DEBUG 01-15 10:09:28.218953.218953 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.218643.218643 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.218688.218688 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.219829.219829 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2d13f387-87c7-4133-9ee9-3bd9b9a3a9eb
DEBUG 01-15 10:09:28.219309.219309 cuda_h.py:19] end load_into_gpu_async cost 0.0013706684112548828 seconds
DEBUG 01-15 10:09:28.219893.219893 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.219859.219859 cuda_h.py:19] end restore_tensors2 cost 0.00011014938354492188 seconds
DEBUG 01-15 10:09:28.219589.219589 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022292137145996094 seconds
INFO 01-15 10:09:28.219030.219030 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2d13f387-87c7-4133-9ee9-3bd9b9a3a9eb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.224252.224252 cuda_h.py:19] end self_attn cost 0.005263805389404297 seconds
DEBUG 01-15 10:09:28.224826.224826 cuda_h.py:19] end iln_self_attn_paln cost 0.007831096649169922 seconds
DEBUG 01-15 10:09:28.224591.224591 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-15 10:09:28.225202.225202 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.226423.226423 cuda_h.py:19] end gate cost 0.0009779930114746094 seconds
DEBUG 01-15 10:09:28.226015.226015 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.226882.226882 lmp.py:1616] 
DEBUG 01-15 10:09:28.226882.226882 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.226301.226301 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.226077.226077 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.226609.226609 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.226994.226994 lmp.py:1620] 
DEBUG 01-15 10:09:28.226994.226994 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.226525.226525 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.226295.226295 lmp.py:1626]   Expert 58 |     34 | CPU
DEBUG 01-15 10:09:28.227965.227965 lmp.py:1626]   Expert 31 |     60 | CPU
DEBUG 01-15 10:09:28.227681.227681 lmp.py:1626]   Expert 47 |     60 | CPU
DEBUG 01-15 10:09:28.227113.227113 lmp.py:1626]   Expert 49 |     62 | CPU
DEBUG 01-15 10:09:28.227783.227783 lmp.py:1626]   Expert  4 |     66 | CPU
DEBUG 01-15 10:09:28.227215.227215 lmp.py:1626]   Expert 38 |     69 | CPU
DEBUG 01-15 10:09:28.227647.227647 lmp.py:1626]   Expert 45 |     74 | CPU
DEBUG 01-15 10:09:28.227078.227078 lmp.py:1626]   Expert 41 |     82 | CPU
DEBUG 01-15 10:09:28.227272.227272 lmp.py:1626]   Expert 43 |     82 | CPU
DEBUG 01-15 10:09:28.227226.227226 lmp.py:1626]   Expert 33 |     94 | CPU
DEBUG 01-15 10:09:28.227850.227850 lmp.py:1626]   Expert 57 |    102 | CPU
DEBUG 01-15 10:09:28.227520.227520 lmp.py:1626]   Expert 50 |    105 | CPU
DEBUG 01-15 10:09:28.227475.227475 lmp.py:1626]   Expert 11 |    109 | CPU
DEBUG 01-15 10:09:28.227715.227715 lmp.py:1626]   Expert  2 |    111 | CPU
DEBUG 01-15 10:09:28.227054.227054 lmp.py:1626]   Expert 51 |    116 | CPU
DEBUG 01-15 10:09:28.227201.227201 lmp.py:1626]   Expert  0 |    124 | CPU
DEBUG 01-15 10:09:28.227441.227441 lmp.py:1626]   Expert 14 |    125 | CPU
DEBUG 01-15 10:09:28.227157.227157 lmp.py:1626]   Expert 54 |    125 | CPU
DEBUG 01-15 10:09:28.227397.227397 lmp.py:1626]   Expert 56 |    141 | CPU
DEBUG 01-15 10:09:28.227113.227113 lmp.py:1626]   Expert 26 |    142 | CPU
DEBUG 01-15 10:09:28.227783.227783 lmp.py:1626]   Expert 34 |    142 | CPU
DEBUG 01-15 10:09:28.227977.227977 lmp.py:1626]   Expert 27 |    152 | CPU
DEBUG 01-15 10:09:28.227978.227978 lmp.py:1626]   Expert 55 |    158 | CPU
DEBUG 01-15 10:09:28.227502.227502 lmp.py:1626]   Expert 25 |    161 | CPU
DEBUG 01-15 10:09:28.227265.227265 lmp.py:1626]   Expert 28 |    161 | CPU
DEBUG 01-15 10:09:28.227359.227359 lmp.py:1626]   Expert 10 |    163 | CPU
DEBUG 01-15 10:09:28.227479.227479 lmp.py:1626]   Expert  9 |    176 | CPU
DEBUG 01-15 10:09:28.227314.227314 lmp.py:1626]   Expert 13 |    179 | CPU
DEBUG 01-15 10:09:28.227447.227447 lmp.py:1626]   Expert 48 |    189 | CPU
DEBUG 01-15 10:09:28.227521.227521 lmp.py:1626]   Expert 61 |    189 | CPU
DEBUG 01-15 10:09:28.228879.228879 lmp.py:1626]   Expert  6 |    191 | CPU
DEBUG 01-15 10:09:28.228999.228999 lmp.py:1626]   Expert  7 |    194 | CPU
DEBUG 01-15 10:09:28.228118.228118 lmp.py:1626]   Expert 46 |    195 | GPU
DEBUG 01-15 10:09:28.228000.228000 lmp.py:1626]   Expert 24 |    201 | GPU
DEBUG 01-15 10:09:28.228358.228358 lmp.py:1626]   Expert 42 |    202 | GPU
DEBUG 01-15 10:09:28.228955.228955 lmp.py:1626]   Expert 18 |    203 | GPU
DEBUG 01-15 10:09:28.228598.228598 lmp.py:1626]   Expert 40 |    208 | GPU
DEBUG 01-15 10:09:28.228717.228717 lmp.py:1626]   Expert 12 |    213 | GPU
DEBUG 01-15 10:09:28.228599.228599 lmp.py:1626]   Expert 63 |    215 | GPU
DEBUG 01-15 10:09:28.228434.228434 lmp.py:1626]   Expert 29 |    217 | GPU
DEBUG 01-15 10:09:28.228507.228507 lmp.py:1626]   Expert 59 |    218 | GPU
DEBUG 01-15 10:09:28.228819.228819 lmp.py:1626]   Expert 22 |    219 | GPU
DEBUG 01-15 10:09:28.228701.228701 lmp.py:1626]   Expert 21 |    220 | GPU
DEBUG 01-15 10:09:28.228344.228344 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:28.228987.228987 lmp.py:1626]   Expert 19 |    229 | GPU
DEBUG 01-15 10:09:28.228106.228106 lmp.py:1626]   Expert 36 |    234 | GPU
DEBUG 01-15 10:09:28.228465.228465 lmp.py:1626]   Expert  3 |    239 | GPU
DEBUG 01-15 10:09:28.228869.228869 lmp.py:1626]   Expert 37 |    243 | GPU
DEBUG 01-15 10:09:28.228512.228512 lmp.py:1626]   Expert  1 |    246 | GPU
DEBUG 01-15 10:09:28.228632.228632 lmp.py:1626]   Expert 16 |    250 | GPU
DEBUG 01-15 10:09:28.228275.228275 lmp.py:1626]   Expert 20 |    260 | GPU
DEBUG 01-15 10:09:28.228216.228216 lmp.py:1626]   Expert  8 |    264 | GPU
DEBUG 01-15 10:09:28.228218.228218 lmp.py:1626]   Expert  5 |    266 | GPU
DEBUG 01-15 10:09:28.228291.228291 lmp.py:1626]   Expert 30 |    272 | GPU
DEBUG 01-15 10:09:28.228557.228557 lmp.py:1626]   Expert 15 |    274 | GPU
DEBUG 01-15 10:09:28.228392.228392 lmp.py:1626]   Expert 62 |    276 | GPU
DEBUG 01-15 10:09:28.228988.228988 lmp.py:1626]   Expert 35 |    299 | GPU
DEBUG 01-15 10:09:28.228062.228062 lmp.py:1626]   Expert 39 |    299 | GPU
DEBUG 01-15 10:09:28.228897.228897 lmp.py:1626]   Expert 17 |    306 | GPU
DEBUG 01-15 10:09:28.228209.228209 lmp.py:1626]   Expert 60 |    318 | GPU
DEBUG 01-15 10:09:28.228805.228805 lmp.py:1626]   Expert 52 |    355 | GPU
DEBUG 01-15 10:09:28.228640.228640 lmp.py:1626]   Expert 23 |    366 | GPU
DEBUG 01-15 10:09:28.228714.228714 lmp.py:1626]   Expert 44 |    380 | GPU
DEBUG 01-15 10:09:28.228311.228311 lmp.py:1626]   Expert 53 |    438 | GPU
DEBUG 01-15 10:09:28.228576.228576 lmp.py:1627] 
DEBUG 01-15 10:09:28.228576.228576 lmp.py:1627]   CPU total tokens: 3938 (32.0%)
DEBUG 01-15 10:09:28.228272.228272 lmp.py:1628]   GPU total tokens: 8350 (68.0%)
DEBUG 01-15 10:09:28.228260.228260 cuda_h.py:19] end experts_map_get cost 0.002518892288208008 seconds
DEBUG 01-15 10:09:28.228262.228262 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.228164.228164 lmp.py:1636] 
DEBUG 01-15 10:09:28.228164.228164 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.228583.228583 cuda_h.py:19] end cpu_experts_submit cost 6.270408630371094e-05 seconds
DEBUG 01-15 10:09:28.228425.228425 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.228944.228944 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.229017.229017 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.229682.229682 cuda_h.py:19] end allocate_cuda_memory cost 0.0002434253692626953 seconds
DEBUG 01-15 10:09:28.229194.229194 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.229142.229142 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.229203.229203 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.229429.229429 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ffc4c0d5-cf32-475f-bdda-6da5c201524a
DEBUG 01-15 10:09:28.229410.229410 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:28.230000.230000 client.py:127] Model loaded
DEBUG 01-15 10:09:28.230899.230899 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.231102.231102 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.231884.231884 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.231915.231915 cuda_h.py:19] end restore2model cost 0.0007781982421875 seconds
DEBUG 01-15 10:09:28.231169.231169 cuda_h.py:19] end sllm_worker_task cost 0.01449275016784668 seconds
INFO 01-15 10:09:28.231129.231129 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ffc4c0d5-cf32-475f-bdda-6da5c201524a
DEBUG 01-15 10:09:28.231953.231953 cuda_h.py:19] end load_into_gpu_async cost 0.0024559497833251953 seconds
DEBUG 01-15 10:09:28.232755.232755 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.232157.232157 cuda_h.py:19] end restore_tensors2 cost 0.0005142688751220703 seconds
DEBUG 01-15 10:09:28.232053.232053 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003636598587036133 seconds
DEBUG 01-15 10:09:28.232691.232691 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.232393.232393 cuda_h.py:19] end move_flatidxs cost 0.0012106895446777344 seconds
DEBUG 01-15 10:09:28.233232.233232 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.235821.235821 cuda_h.py:19] end restore2model cost 0.0026595592498779297 seconds
DEBUG 01-15 10:09:28.235810.235810 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0065038204193115234 seconds
DEBUG 01-15 10:09:28.235128.235128 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.235728.235728 cuda_h.py:19] end gpu_sexperts cost 0.0002713203430175781 seconds
DEBUG 01-15 10:09:28.235749.235749 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.237318.237318 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001508474349975586 seconds
DEBUG 01-15 10:09:28.238576.238576 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.238052.238052 cuda_h.py:19] end gpu_group_list cost 0.00033545494079589844 seconds
DEBUG 01-15 10:09:28.238401.238401 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.239380.239380 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007181167602539062 seconds
DEBUG 01-15 10:09:28.239341.239341 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.239502.239502 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-15 10:09:28.239198.239198 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.249962.249962 cuda_h.py:19] end group_tensors cost 0.016181468963623047 seconds
DEBUG 01-15 10:09:28.250361.250361 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.254856.254856 cuda_h.py:19] end group pad cost 0.004621267318725586 seconds
DEBUG 01-15 10:09:28.254315.254315 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.279306.279306 cuda_h.py:19] end group_einsum cost 0.024380207061767578 seconds
DEBUG 01-15 10:09:28.279305.279305 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.283875.283875 cuda_h.py:19] end get_outputs_cpu1 cost 0.0040667057037353516 seconds
DEBUG 01-15 10:09:28.284829.284829 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05318927764892578 seconds
DEBUG 01-15 10:09:28.285936.285936 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.045685768127441406 seconds
DEBUG 01-15 10:09:28.285744.285744 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.285681.285681 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.286352.286352 cuda_h.py:19] end index_scatter cost 0.00016808509826660156 seconds
DEBUG 01-15 10:09:28.286025.286025 cuda_h.py:19] end cpuoutputsdeal cost 0.0011584758758544922 seconds
DEBUG 01-15 10:09:28.286551.286551 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.286435.286435 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ffc4c0d5-cf32-475f-bdda-6da5c201524a
INFO 01-15 10:09:28.288694.288694 client.py:127] Model loaded
DEBUG 01-15 10:09:28.288685.288685 cuda_h.py:19] end wait_experts cost 0.001352071762084961 seconds
DEBUG 01-15 10:09:28.288973.288973 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.288646.288646 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.288656.288656 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.289412.289412 cuda_h.py:19] end gpu_group_tensor cost 0.0003750324249267578 seconds
DEBUG 01-15 10:09:28.289155.289155 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.290730.290730 cuda_h.py:19] end gpu_group_einsum cost 0.001224517822265625 seconds
DEBUG 01-15 10:09:28.290261.290261 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.290908.290908 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.291109.291109 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005958080291748047 seconds
DEBUG 01-15 10:09:28.291218.291218 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.291781.291781 cuda_h.py:19] end concat_expert_out cost 0.00012874603271484375 seconds
DEBUG 01-15 10:09:28.292117.292117 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.292157.292157 cuda_h.py:19] end index_scatter cost 0.00011968612670898438 seconds
DEBUG 01-15 10:09:28.292756.292756 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014231204986572266 seconds
DEBUG 01-15 10:09:28.292247.292247 cuda_h.py:19] end gpu_experts cost 0.0041544437408447266 seconds
DEBUG 01-15 10:09:28.292790.292790 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.06777787208557129 seconds
DEBUG 01-15 10:09:28.293076.293076 cuda_h.py:19] end prefill_layer cost 0.07712006568908691 seconds
DEBUG 01-15 10:09:28.293736.293736 lmp.py:1552] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-15 10:09:28.293355.293355 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.293880.293880 lmp.py:1495] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-15 10:09:28.293691.293691 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:28.294415.294415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:28.294533.294533 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.653236389160156e-05 seconds
DEBUG 01-15 10:09:28.294862.294862 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.294011.294011 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.00033092498779296875 seconds
DEBUG 01-15 10:09:28.294772.294772 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.294577.294577 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.294125.294125 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.295099.295099 cuda_h.py:19] end allocate_cuda_memory cost 0.0004127025604248047 seconds
DEBUG 01-15 10:09:28.295100.295100 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.295872.295872 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.296985.296985 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.296241.296241 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.296939.296939 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb83ccef-8168-4307-b31d-791438d5cdb6
DEBUG 01-15 10:09:28.296007.296007 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.297719.297719 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.297580.297580 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb83ccef-8168-4307-b31d-791438d5cdb6
DEBUG 01-15 10:09:28.297518.297518 cuda_h.py:19] end load_into_gpu_async cost 0.0016524791717529297 seconds
DEBUG 01-15 10:09:28.297865.297865 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.298084.298084 cuda_h.py:19] end restore_tensors2 cost 0.00015687942504882812 seconds
DEBUG 01-15 10:09:28.298021.298021 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003274679183959961 seconds
INFO 01-15 10:09:28.298815.298815 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb83ccef-8168-4307-b31d-791438d5cdb6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.302314.302314 cuda_h.py:19] end self_attn cost 0.004745960235595703 seconds
DEBUG 01-15 10:09:28.302176.302176 cuda_h.py:19] end iln_self_attn_paln cost 0.007725238800048828 seconds
DEBUG 01-15 10:09:28.302907.302907 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-15 10:09:28.302121.302121 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.303965.303965 cuda_h.py:19] end gate cost 0.0008535385131835938 seconds
DEBUG 01-15 10:09:28.303630.303630 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.304699.304699 lmp.py:1616] 
DEBUG 01-15 10:09:28.304699.304699 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.304528.304528 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.304642.304642 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.304452.304452 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.304684.304684 lmp.py:1620] 
DEBUG 01-15 10:09:28.304684.304684 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.304917.304917 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.304865.304865 lmp.py:1626]   Expert  4 |      9 | CPU
DEBUG 01-15 10:09:28.304860.304860 lmp.py:1626]   Expert 28 |     26 | CPU
DEBUG 01-15 10:09:28.304662.304662 lmp.py:1626]   Expert  7 |     46 | CPU
DEBUG 01-15 10:09:28.304464.304464 lmp.py:1626]   Expert 53 |     57 | CPU
DEBUG 01-15 10:09:28.304551.304551 lmp.py:1626]   Expert 52 |     69 | CPU
DEBUG 01-15 10:09:28.304354.304354 lmp.py:1626]   Expert 43 |     74 | CPU
DEBUG 01-15 10:09:28.304110.304110 lmp.py:1626]   Expert 49 |     81 | CPU
DEBUG 01-15 10:09:28.304343.304343 lmp.py:1626]   Expert 12 |     88 | CPU
DEBUG 01-15 10:09:28.304668.304668 lmp.py:1626]   Expert 47 |    100 | CPU
DEBUG 01-15 10:09:28.304994.304994 lmp.py:1626]   Expert 33 |    107 | CPU
DEBUG 01-15 10:09:28.304081.304081 lmp.py:1626]   Expert  2 |    109 | CPU
DEBUG 01-15 10:09:28.304883.304883 lmp.py:1626]   Expert 24 |    109 | CPU
DEBUG 01-15 10:09:28.304970.304970 lmp.py:1626]   Expert 15 |    113 | CPU
DEBUG 01-15 10:09:28.304819.304819 lmp.py:1626]   Expert 50 |    113 | CPU
DEBUG 01-15 10:09:28.304667.304667 lmp.py:1626]   Expert 39 |    114 | CPU
DEBUG 01-15 10:09:28.304516.304516 lmp.py:1626]   Expert 60 |    115 | CPU
DEBUG 01-15 10:09:28.305795.305795 lmp.py:1626]   Expert 36 |    118 | CPU
DEBUG 01-15 10:09:28.305597.305597 lmp.py:1626]   Expert 25 |    122 | CPU
DEBUG 01-15 10:09:28.305923.305923 lmp.py:1626]   Expert  6 |    127 | CPU
DEBUG 01-15 10:09:28.305533.305533 lmp.py:1626]   Expert 59 |    133 | CPU
DEBUG 01-15 10:09:28.305382.305382 lmp.py:1626]   Expert 61 |    133 | CPU
DEBUG 01-15 10:09:28.305992.305992 lmp.py:1626]   Expert  3 |    141 | CPU
DEBUG 01-15 10:09:28.305317.305317 lmp.py:1626]   Expert 58 |    144 | CPU
DEBUG 01-15 10:09:28.305120.305120 lmp.py:1626]   Expert 27 |    145 | CPU
DEBUG 01-15 10:09:28.305637.305637 lmp.py:1626]   Expert  8 |    148 | CPU
DEBUG 01-15 10:09:28.305486.305486 lmp.py:1626]   Expert 30 |    150 | CPU
DEBUG 01-15 10:09:28.305858.305858 lmp.py:1626]   Expert 31 |    152 | CPU
DEBUG 01-15 10:09:28.305230.305230 lmp.py:1626]   Expert 10 |    156 | CPU
DEBUG 01-15 10:09:28.305317.305317 lmp.py:1626]   Expert 38 |    157 | CPU
DEBUG 01-15 10:09:28.305165.305165 lmp.py:1626]   Expert 40 |    158 | CPU
DEBUG 01-15 10:09:28.305206.305206 lmp.py:1626]   Expert 57 |    158 | CPU
DEBUG 01-15 10:09:28.305247.305247 lmp.py:1626]   Expert 14 |    161 | CPU
DEBUG 01-15 10:09:28.305334.305334 lmp.py:1626]   Expert 41 |    162 | GPU
DEBUG 01-15 10:09:28.305421.305421 lmp.py:1626]   Expert 37 |    163 | GPU
DEBUG 01-15 10:09:28.305270.305270 lmp.py:1626]   Expert 46 |    165 | GPU
DEBUG 01-15 10:09:28.305880.305880 lmp.py:1626]   Expert 32 |    166 | GPU
DEBUG 01-15 10:09:28.305490.305490 lmp.py:1626]   Expert 54 |    167 | GPU
DEBUG 01-15 10:09:28.305531.305531 lmp.py:1626]   Expert 19 |    175 | GPU
DEBUG 01-15 10:09:28.305095.305095 lmp.py:1626]   Expert 42 |    175 | GPU
DEBUG 01-15 10:09:28.305182.305182 lmp.py:1626]   Expert 11 |    178 | GPU
DEBUG 01-15 10:09:28.305792.305792 lmp.py:1626]   Expert 34 |    189 | GPU
DEBUG 01-15 10:09:28.305925.305925 lmp.py:1626]   Expert 22 |    190 | GPU
DEBUG 01-15 10:09:28.305820.305820 lmp.py:1626]   Expert 18 |    191 | GPU
DEBUG 01-15 10:09:28.305954.305954 lmp.py:1626]   Expert 26 |    198 | GPU
DEBUG 01-15 10:09:28.305279.305279 lmp.py:1626]   Expert  0 |    200 | GPU
DEBUG 01-15 10:09:28.305843.305843 lmp.py:1626]   Expert 56 |    202 | GPU
DEBUG 01-15 10:09:28.305215.305215 lmp.py:1626]   Expert 44 |    203 | GPU
DEBUG 01-15 10:09:28.305825.305825 lmp.py:1626]   Expert  1 |    206 | GPU
DEBUG 01-15 10:09:28.305959.305959 lmp.py:1626]   Expert 51 |    212 | GPU
DEBUG 01-15 10:09:28.305569.305569 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:28.305702.305702 lmp.py:1626]   Expert 29 |    231 | GPU
DEBUG 01-15 10:09:28.306505.306505 lmp.py:1626]   Expert 48 |    235 | GPU
DEBUG 01-15 10:09:28.306307.306307 lmp.py:1626]   Expert 45 |    240 | GPU
DEBUG 01-15 10:09:28.306348.306348 lmp.py:1626]   Expert 21 |    242 | GPU
DEBUG 01-15 10:09:28.306481.306481 lmp.py:1626]   Expert 35 |    252 | GPU
DEBUG 01-15 10:09:28.306614.306614 lmp.py:1626]   Expert 55 |    253 | GPU
DEBUG 01-15 10:09:28.306225.306225 lmp.py:1626]   Expert 16 |    254 | GPU
DEBUG 01-15 10:09:28.306835.306835 lmp.py:1626]   Expert  5 |    294 | GPU
DEBUG 01-15 10:09:28.306207.306207 lmp.py:1626]   Expert 23 |    374 | GPU
DEBUG 01-15 10:09:28.306578.306578 lmp.py:1626]   Expert 13 |    382 | GPU
DEBUG 01-15 10:09:28.306619.306619 lmp.py:1626]   Expert 17 |    434 | GPU
DEBUG 01-15 10:09:28.306945.306945 lmp.py:1626]   Expert  9 |    457 | GPU
DEBUG 01-15 10:09:28.306793.306793 lmp.py:1626]   Expert 63 |    459 | GPU
DEBUG 01-15 10:09:28.306642.306642 lmp.py:1626]   Expert 62 |   1183 | GPU
DEBUG 01-15 10:09:28.306206.306206 lmp.py:1627] 
DEBUG 01-15 10:09:28.306206.306206 lmp.py:1627]   CPU total tokens: 3633 (29.6%)
DEBUG 01-15 10:09:28.306962.306962 lmp.py:1628]   GPU total tokens: 8655 (70.4%)
DEBUG 01-15 10:09:28.306963.306963 cuda_h.py:19] end experts_map_get cost 0.0025894641876220703 seconds
DEBUG 01-15 10:09:28.306138.306138 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.306915.306915 lmp.py:1636] 
DEBUG 01-15 10:09:28.306915.306915 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.306169.306169 cuda_h.py:19] end cpu_experts_submit cost 8.0108642578125e-05 seconds
DEBUG 01-15 10:09:28.306515.306515 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.306896.306896 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.307884.307884 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.307305.307305 cuda_h.py:19] end allocate_cuda_memory cost 0.0002598762512207031 seconds
DEBUG 01-15 10:09:28.307321.307321 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.307621.307621 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.307887.307887 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.307842.307842 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 600ee13a-cf5c-4ea0-9233-3b9654beea18
DEBUG 01-15 10:09:28.307793.307793 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:28.308360.308360 client.py:127] Model loaded
DEBUG 01-15 10:09:28.308205.308205 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.308969.308969 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.309361.309361 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:28.308301.308301 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 600ee13a-cf5c-4ea0-9233-3b9654beea18
DEBUG 01-15 10:09:28.310155.310155 cuda_h.py:19] end restore2model cost 0.0010597705841064453 seconds
DEBUG 01-15 10:09:28.310331.310331 cuda_h.py:19] end move_flatidxs cost 0.0010352134704589844 seconds
DEBUG 01-15 10:09:28.310221.310221 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.310186.310186 cuda_h.py:19] end load_into_gpu_async cost 0.0026175975799560547 seconds
DEBUG 01-15 10:09:28.310440.310440 cuda_h.py:19] end sllm_worker_task cost 0.015606164932250977 seconds
DEBUG 01-15 10:09:28.310708.310708 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.311683.311683 cuda_h.py:19] end restore_tensors2 cost 0.0006608963012695312 seconds
DEBUG 01-15 10:09:28.311573.311573 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004355669021606445 seconds
DEBUG 01-15 10:09:28.311589.311589 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.315069.315069 cuda_h.py:19] end restore2model cost 0.004594326019287109 seconds
DEBUG 01-15 10:09:28.316979.316979 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009245872497558594 seconds
DEBUG 01-15 10:09:28.316251.316251 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.316255.316255 cuda_h.py:19] end gpu_sexperts cost 0.0002872943878173828 seconds
DEBUG 01-15 10:09:28.316668.316668 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.318767.318767 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015442371368408203 seconds
DEBUG 01-15 10:09:28.318383.318383 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.319754.319754 cuda_h.py:19] end gpu_group_list cost 0.00032711029052734375 seconds
DEBUG 01-15 10:09:28.319102.319102 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.320021.320021 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007090568542480469 seconds
DEBUG 01-15 10:09:28.320267.320267 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.320044.320044 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-15 10:09:28.320694.320694 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.320585.320585 cuda_h.py:19] end group_tensors cost 0.010050296783447266 seconds
DEBUG 01-15 10:09:28.321646.321646 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.324858.324858 cuda_h.py:19] end group pad cost 0.0037195682525634766 seconds
DEBUG 01-15 10:09:28.324079.324079 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.344337.344337 cuda_h.py:19] end group_einsum cost 0.019087553024291992 seconds
DEBUG 01-15 10:09:28.344031.344031 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.348703.348703 cuda_h.py:19] end get_outputs_cpu1 cost 0.004355907440185547 seconds
DEBUG 01-15 10:09:28.349406.349406 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04064512252807617 seconds
DEBUG 01-15 10:09:28.350654.350654 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03019404411315918 seconds
DEBUG 01-15 10:09:28.350482.350482 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.351741.351741 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.351935.351935 cuda_h.py:19] end index_scatter cost 0.00014591217041015625 seconds
DEBUG 01-15 10:09:28.351306.351306 cuda_h.py:19] end cpuoutputsdeal cost 0.0011887550354003906 seconds
DEBUG 01-15 10:09:28.352203.352203 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.352782.352782 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 600ee13a-cf5c-4ea0-9233-3b9654beea18
INFO 01-15 10:09:28.359008.359008 client.py:127] Model loaded
DEBUG 01-15 10:09:28.359396.359396 cuda_h.py:19] end wait_experts cost 0.00706171989440918 seconds
DEBUG 01-15 10:09:28.359047.359047 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.359395.359395 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.359835.359835 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.359823.359823 cuda_h.py:19] end gpu_group_tensor cost 0.0003712177276611328 seconds
DEBUG 01-15 10:09:28.360705.360705 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.362419.362419 cuda_h.py:19] end gpu_group_einsum cost 0.0024144649505615234 seconds
DEBUG 01-15 10:09:28.362878.362878 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.362578.362578 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.363885.363885 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005974769592285156 seconds
DEBUG 01-15 10:09:28.363663.363663 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.363802.363802 cuda_h.py:19] end concat_expert_out cost 0.0001308917999267578 seconds
DEBUG 01-15 10:09:28.364807.364807 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.364377.364377 cuda_h.py:19] end index_scatter cost 0.0001220703125 seconds
DEBUG 01-15 10:09:28.364619.364619 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014581680297851562 seconds
DEBUG 01-15 10:09:28.364287.364287 cuda_h.py:19] end gpu_experts cost 0.005347490310668945 seconds
DEBUG 01-15 10:09:28.364400.364400 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.061928749084472656 seconds
DEBUG 01-15 10:09:28.365539.365539 cuda_h.py:19] end prefill_layer cost 0.07168459892272949 seconds
DEBUG 01-15 10:09:28.365570.365570 lmp.py:1552] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-15 10:09:28.365327.365327 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.365992.365992 lmp.py:1495] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-15 10:09:28.365371.365371 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:28.366857.366857 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:28.366631.366631 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:28.366448.366448 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.00015783309936523438 seconds
DEBUG 01-15 10:09:28.366768.366768 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.366064.366064 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.366523.366523 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.366176.366176 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.367947.367947 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.367976.367976 cuda_h.py:19] end allocate_cuda_memory cost 0.00037598609924316406 seconds
DEBUG 01-15 10:09:28.367564.367564 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.367540.367540 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.367697.367697 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.368275.368275 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e09f6921-88fd-4717-a263-67f8fe1a0ecd
DEBUG 01-15 10:09:28.368077.368077 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.368888.368888 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.369185.369185 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e09f6921-88fd-4717-a263-67f8fe1a0ecd
DEBUG 01-15 10:09:28.369415.369415 cuda_h.py:19] end load_into_gpu_async cost 0.0015888214111328125 seconds
DEBUG 01-15 10:09:28.369179.369179 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.369922.369922 cuda_h.py:19] end restore_tensors2 cost 0.00015592575073242188 seconds
DEBUG 01-15 10:09:28.369090.369090 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002753734588623047 seconds
INFO 01-15 10:09:28.369479.369479 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e09f6921-88fd-4717-a263-67f8fe1a0ecd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.374722.374722 cuda_h.py:19] end self_attn cost 0.004981279373168945 seconds
DEBUG 01-15 10:09:28.374590.374590 cuda_h.py:19] end iln_self_attn_paln cost 0.008087158203125 seconds
DEBUG 01-15 10:09:28.374891.374891 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-15 10:09:28.374734.374734 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.375612.375612 cuda_h.py:19] end gate cost 0.0008399486541748047 seconds
DEBUG 01-15 10:09:28.375276.375276 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.376093.376093 lmp.py:1616] 
DEBUG 01-15 10:09:28.376093.376093 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.376876.376876 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.376308.376308 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.376925.376925 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.376919.376919 lmp.py:1620] 
DEBUG 01-15 10:09:28.376919.376919 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.376914.376914 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.376100.376100 lmp.py:1626]   Expert 32 |     35 | CPU
DEBUG 01-15 10:09:28.376141.376141 lmp.py:1626]   Expert  5 |     52 | CPU
DEBUG 01-15 10:09:28.376467.376467 lmp.py:1626]   Expert 30 |     54 | CPU
DEBUG 01-15 10:09:28.376554.376554 lmp.py:1626]   Expert 46 |     73 | CPU
DEBUG 01-15 10:09:28.376402.376402 lmp.py:1626]   Expert 40 |     88 | CPU
DEBUG 01-15 10:09:28.376251.376251 lmp.py:1626]   Expert  8 |     90 | CPU
DEBUG 01-15 10:09:28.376875.376875 lmp.py:1626]   Expert 12 |    101 | CPU
DEBUG 01-15 10:09:28.376962.376962 lmp.py:1626]   Expert 17 |    107 | CPU
DEBUG 01-15 10:09:28.376811.376811 lmp.py:1626]   Expert 27 |    112 | CPU
DEBUG 01-15 10:09:28.376851.376851 lmp.py:1626]   Expert 60 |    112 | CPU
DEBUG 01-15 10:09:28.376130.376130 lmp.py:1626]   Expert  3 |    113 | CPU
DEBUG 01-15 10:09:28.376655.376655 lmp.py:1626]   Expert 58 |    116 | CPU
DEBUG 01-15 10:09:28.376696.376696 lmp.py:1626]   Expert 21 |    119 | CPU
DEBUG 01-15 10:09:28.376259.376259 lmp.py:1626]   Expert 28 |    120 | CPU
DEBUG 01-15 10:09:28.376062.376062 lmp.py:1626]   Expert 29 |    120 | CPU
DEBUG 01-15 10:09:28.376626.376626 lmp.py:1626]   Expert 25 |    126 | CPU
DEBUG 01-15 10:09:28.376713.376713 lmp.py:1626]   Expert 41 |    128 | CPU
DEBUG 01-15 10:09:28.376323.376323 lmp.py:1626]   Expert 35 |    133 | CPU
DEBUG 01-15 10:09:28.376456.376456 lmp.py:1626]   Expert 19 |    136 | CPU
DEBUG 01-15 10:09:28.376571.376571 lmp.py:1626]   Expert 52 |    143 | CPU
DEBUG 01-15 10:09:28.376088.376088 lmp.py:1626]   Expert  0 |    145 | CPU
DEBUG 01-15 10:09:28.376506.376506 lmp.py:1626]   Expert  6 |    145 | CPU
DEBUG 01-15 10:09:28.376878.376878 lmp.py:1626]   Expert 54 |    149 | CPU
DEBUG 01-15 10:09:28.376011.376011 lmp.py:1626]   Expert 56 |    150 | CPU
DEBUG 01-15 10:09:28.376906.376906 lmp.py:1626]   Expert 37 |    153 | CPU
DEBUG 01-15 10:09:28.376040.376040 lmp.py:1626]   Expert 48 |    153 | CPU
DEBUG 01-15 10:09:28.377412.377412 lmp.py:1626]   Expert 63 |    154 | CPU
DEBUG 01-15 10:09:28.377214.377214 lmp.py:1626]   Expert 53 |    157 | CPU
DEBUG 01-15 10:09:28.377301.377301 lmp.py:1626]   Expert 36 |    161 | CPU
DEBUG 01-15 10:09:28.377196.377196 lmp.py:1626]   Expert 59 |    170 | CPU
DEBUG 01-15 10:09:28.377091.377091 lmp.py:1626]   Expert  9 |    180 | CPU
DEBUG 01-15 10:09:28.377701.377701 lmp.py:1626]   Expert  1 |    186 | CPU
DEBUG 01-15 10:09:28.377643.377643 lmp.py:1626]   Expert 39 |    191 | GPU
DEBUG 01-15 10:09:28.377061.377061 lmp.py:1626]   Expert 20 |    200 | GPU
DEBUG 01-15 10:09:28.377671.377671 lmp.py:1626]   Expert 61 |    202 | GPU
DEBUG 01-15 10:09:28.377996.377996 lmp.py:1626]   Expert 42 |    205 | GPU
DEBUG 01-15 10:09:28.377799.377799 lmp.py:1626]   Expert  7 |    206 | GPU
DEBUG 01-15 10:09:28.377601.377601 lmp.py:1626]   Expert 11 |    207 | GPU
DEBUG 01-15 10:09:28.377496.377496 lmp.py:1626]   Expert 43 |    207 | GPU
DEBUG 01-15 10:09:28.377153.377153 lmp.py:1626]   Expert 34 |    208 | GPU
DEBUG 01-15 10:09:28.377022.377022 lmp.py:1626]   Expert 47 |    208 | GPU
DEBUG 01-15 10:09:28.377393.377393 lmp.py:1626]   Expert 55 |    215 | GPU
DEBUG 01-15 10:09:28.377480.377480 lmp.py:1626]   Expert 13 |    221 | GPU
DEBUG 01-15 10:09:28.377568.377568 lmp.py:1626]   Expert 16 |    221 | GPU
DEBUG 01-15 10:09:28.377939.377939 lmp.py:1626]   Expert 57 |    225 | GPU
DEBUG 01-15 10:09:28.377834.377834 lmp.py:1626]   Expert 18 |    229 | GPU
DEBUG 01-15 10:09:28.377968.377968 lmp.py:1626]   Expert 15 |    234 | GPU
DEBUG 01-15 10:09:28.377624.377624 lmp.py:1626]   Expert  4 |    241 | GPU
DEBUG 01-15 10:09:28.377281.377281 lmp.py:1626]   Expert 50 |    244 | GPU
DEBUG 01-15 10:09:28.377699.377699 lmp.py:1626]   Expert 33 |    247 | GPU
DEBUG 01-15 10:09:28.377024.377024 lmp.py:1626]   Expert 45 |    247 | GPU
DEBUG 01-15 10:09:28.377350.377350 lmp.py:1626]   Expert 22 |    248 | GPU
DEBUG 01-15 10:09:28.377199.377199 lmp.py:1626]   Expert 31 |    249 | GPU
DEBUG 01-15 10:09:28.377094.377094 lmp.py:1626]   Expert 51 |    255 | GPU
DEBUG 01-15 10:09:28.377227.377227 lmp.py:1626]   Expert 49 |    262 | GPU
DEBUG 01-15 10:09:28.377122.377122 lmp.py:1626]   Expert 38 |    277 | GPU
DEBUG 01-15 10:09:28.377778.377778 lmp.py:1626]   Expert 26 |    281 | GPU
DEBUG 01-15 10:09:28.377866.377866 lmp.py:1626]   Expert 10 |    289 | GPU
DEBUG 01-15 10:09:28.377953.377953 lmp.py:1626]   Expert 44 |    293 | GPU
DEBUG 01-15 10:09:28.377278.377278 lmp.py:1626]   Expert  2 |    299 | GPU
DEBUG 01-15 10:09:28.378650.378650 lmp.py:1626]   Expert 24 |    307 | GPU
DEBUG 01-15 10:09:28.378022.378022 lmp.py:1626]   Expert 14 |    312 | GPU
DEBUG 01-15 10:09:28.378917.378917 lmp.py:1626]   Expert 23 |    404 | GPU
DEBUG 01-15 10:09:28.378573.378573 lmp.py:1626]   Expert 62 |    673 | GPU
DEBUG 01-15 10:09:28.378899.378899 lmp.py:1627] 
DEBUG 01-15 10:09:28.378899.378899 lmp.py:1627]   CPU total tokens: 3981 (32.4%)
DEBUG 01-15 10:09:28.378939.378939 lmp.py:1628]   GPU total tokens: 8307 (67.6%)
DEBUG 01-15 10:09:28.378133.378133 cuda_h.py:19] end experts_map_get cost 0.002590656280517578 seconds
INFO 01-15 10:09:28.378707.378707 client.py:127] Model loaded
DEBUG 01-15 10:09:28.378254.378254 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.378363.378363 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.378683.378683 lmp.py:1636] 
DEBUG 01-15 10:09:28.378683.378683 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.379537.379537 cuda_h.py:19] end restore2model cost 0.0010824203491210938 seconds
DEBUG 01-15 10:09:28.379362.379362 cuda_h.py:19] end cpu_experts_submit cost 0.0013120174407958984 seconds
DEBUG 01-15 10:09:28.380048.380048 cuda_h.py:19] end sllm_worker_task cost 0.013230085372924805 seconds
DEBUG 01-15 10:09:28.380567.380567 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.380310.380310 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.380250.380250 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.381909.381909 cuda_h.py:19] end allocate_cuda_memory cost 0.00023674964904785156 seconds
DEBUG 01-15 10:09:28.381421.381421 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.381177.381177 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.381754.381754 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.381030.381030 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.381218.381218 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ae75ba29-740b-40f2-84a9-85b9664c4185
DEBUG 01-15 10:09:28.381630.381630 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.381307.381307 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.382566.382566 cuda_h.py:19] end move_flatidxs cost 0.0010709762573242188 seconds
DEBUG 01-15 10:09:28.382643.382643 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:28.383141.383141 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ae75ba29-740b-40f2-84a9-85b9664c4185
DEBUG 01-15 10:09:28.383792.383792 cuda_h.py:19] end load_into_gpu_async cost 0.0021715164184570312 seconds
DEBUG 01-15 10:09:28.383926.383926 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.383880.383880 cuda_h.py:19] end restore_tensors2 cost 0.0003952980041503906 seconds
DEBUG 01-15 10:09:28.383001.383001 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003217458724975586 seconds
DEBUG 01-15 10:09:28.384255.384255 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.386241.386241 cuda_h.py:19] end restore2model cost 0.0027306079864501953 seconds
DEBUG 01-15 10:09:28.386992.386992 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006165742874145508 seconds
DEBUG 01-15 10:09:28.386833.386833 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.387347.387347 cuda_h.py:19] end gpu_sexperts cost 0.0002770423889160156 seconds
DEBUG 01-15 10:09:28.387607.387607 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.388758.388758 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015170574188232422 seconds
DEBUG 01-15 10:09:28.389731.389731 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.389286.389286 cuda_h.py:19] end gpu_group_list cost 0.0003299713134765625 seconds
DEBUG 01-15 10:09:28.390204.390204 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.390488.390488 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007314682006835938 seconds
DEBUG 01-15 10:09:28.390357.390357 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.390988.390988 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-15 10:09:28.390922.390922 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.394063.394063 cuda_h.py:19] end group_tensors cost 0.011059999465942383 seconds
DEBUG 01-15 10:09:28.395351.395351 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.399314.399314 cuda_h.py:19] end group pad cost 0.004330635070800781 seconds
DEBUG 01-15 10:09:28.399303.399303 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.420316.420316 cuda_h.py:19] end group_einsum cost 0.02047586441040039 seconds
DEBUG 01-15 10:09:28.420156.420156 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.425697.425697 cuda_h.py:19] end get_outputs_cpu1 cost 0.004609346389770508 seconds
DEBUG 01-15 10:09:28.426367.426367 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.044727325439453125 seconds
DEBUG 01-15 10:09:28.427511.427511 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03610730171203613 seconds
DEBUG 01-15 10:09:28.427404.427404 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.427879.427879 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.427290.427290 cuda_h.py:19] end index_scatter cost 0.00012421607971191406 seconds
DEBUG 01-15 10:09:28.428990.428990 cuda_h.py:19] end cpuoutputsdeal cost 0.0012097358703613281 seconds
DEBUG 01-15 10:09:28.428205.428205 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.428809.428809 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ae75ba29-740b-40f2-84a9-85b9664c4185
INFO 01-15 10:09:28.433939.433939 client.py:127] Model loaded
DEBUG 01-15 10:09:28.434042.434042 cuda_h.py:19] end wait_experts cost 0.00537109375 seconds
DEBUG 01-15 10:09:28.434408.434408 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.434895.434895 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.434699.434699 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.434500.434500 cuda_h.py:19] end gpu_group_tensor cost 0.00031685829162597656 seconds
DEBUG 01-15 10:09:28.434334.434334 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.435822.435822 cuda_h.py:19] end gpu_group_einsum cost 0.0010411739349365234 seconds
DEBUG 01-15 10:09:28.436915.436915 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.436959.436959 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.436183.436183 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005228519439697266 seconds
DEBUG 01-15 10:09:28.436133.436133 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.437741.437741 cuda_h.py:19] end concat_expert_out cost 0.00010538101196289062 seconds
DEBUG 01-15 10:09:28.437136.437136 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.437896.437896 cuda_h.py:19] end index_scatter cost 9.775161743164062e-05 seconds
DEBUG 01-15 10:09:28.437899.437899 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0012061595916748047 seconds
DEBUG 01-15 10:09:28.437374.437374 cuda_h.py:19] end gpu_experts cost 0.0034639835357666016 seconds
DEBUG 01-15 10:09:28.437823.437823 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.06316924095153809 seconds
DEBUG 01-15 10:09:28.438171.438171 cuda_h.py:19] end prefill_layer cost 0.07259893417358398 seconds
DEBUG 01-15 10:09:28.438838.438838 lmp.py:1552] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-15 10:09:28.438866.438866 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.438133.438133 lmp.py:1495] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-15 10:09:28.438969.438969 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:28.438243.438243 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:28.438313.438313 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.151199340820312e-05 seconds
DEBUG 01-15 10:09:28.439640.439640 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 0.00013303756713867188 seconds
DEBUG 01-15 10:09:28.439337.439337 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.439322.439322 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.439754.439754 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.439108.439108 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.439308.439308 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.440738.440738 cuda_h.py:19] end allocate_cuda_memory cost 0.0004611015319824219 seconds
DEBUG 01-15 10:09:28.440215.440215 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.440193.440193 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.440727.440727 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.440671.440671 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 078fc679-d887-4afe-8f38-b58d08e1a111
DEBUG 01-15 10:09:28.441426.441426 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.441980.441980 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.442074.442074 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 078fc679-d887-4afe-8f38-b58d08e1a111
DEBUG 01-15 10:09:28.442947.442947 cuda_h.py:19] end load_into_gpu_async cost 0.0017485618591308594 seconds
DEBUG 01-15 10:09:28.442717.442717 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.442791.442791 cuda_h.py:19] end restore_tensors2 cost 0.00015687942504882812 seconds
DEBUG 01-15 10:09:28.442762.442762 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031211376190185547 seconds
INFO 01-15 10:09:28.443992.443992 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 078fc679-d887-4afe-8f38-b58d08e1a111
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.446156.446156 cuda_h.py:19] end self_attn cost 0.00537562370300293 seconds
DEBUG 01-15 10:09:28.447595.447595 cuda_h.py:19] end iln_self_attn_paln cost 0.00824117660522461 seconds
DEBUG 01-15 10:09:28.447671.447671 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-15 10:09:28.447084.447084 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.448706.448706 cuda_h.py:19] end gate cost 0.0009260177612304688 seconds
DEBUG 01-15 10:09:28.448378.448378 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.449097.449097 lmp.py:1616] 
DEBUG 01-15 10:09:28.449097.449097 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.449887.449887 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.449803.449803 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.449426.449426 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.449282.449282 lmp.py:1620] 
DEBUG 01-15 10:09:28.449282.449282 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.449137.449137 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.449900.449900 lmp.py:1626]   Expert 44 |     40 | CPU
DEBUG 01-15 10:09:28.449279.449279 lmp.py:1626]   Expert  1 |     47 | CPU
DEBUG 01-15 10:09:28.449432.449432 lmp.py:1626]   Expert 60 |     64 | CPU
DEBUG 01-15 10:09:28.449288.449288 lmp.py:1626]   Expert 28 |     69 | CPU
DEBUG 01-15 10:09:28.449428.449428 lmp.py:1626]   Expert 48 |     77 | CPU
DEBUG 01-15 10:09:28.449999.449999 lmp.py:1626]   Expert 27 |     87 | CPU
DEBUG 01-15 10:09:28.449377.449377 lmp.py:1626]   Expert  0 |     99 | CPU
DEBUG 01-15 10:09:28.449233.449233 lmp.py:1626]   Expert 62 |    107 | CPU
DEBUG 01-15 10:09:28.449611.449611 lmp.py:1626]   Expert 22 |    111 | CPU
DEBUG 01-15 10:09:28.449275.449275 lmp.py:1626]   Expert 42 |    112 | CPU
DEBUG 01-15 10:09:28.449938.449938 lmp.py:1626]   Expert 30 |    115 | CPU
DEBUG 01-15 10:09:28.449078.449078 lmp.py:1626]   Expert 59 |    117 | CPU
DEBUG 01-15 10:09:28.449742.449742 lmp.py:1626]   Expert 58 |    119 | CPU
DEBUG 01-15 10:09:28.449312.449312 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:28.449168.449168 lmp.py:1626]   Expert  8 |    130 | CPU
DEBUG 01-15 10:09:28.449738.449738 lmp.py:1626]   Expert 12 |    130 | CPU
DEBUG 01-15 10:09:28.449640.449640 lmp.py:1626]   Expert 50 |    133 | CPU
DEBUG 01-15 10:09:28.449542.449542 lmp.py:1626]   Expert  5 |    141 | CPU
DEBUG 01-15 10:09:28.449728.449728 lmp.py:1626]   Expert 56 |    143 | CPU
DEBUG 01-15 10:09:28.450153.450153 lmp.py:1626]   Expert 55 |    150 | CPU
DEBUG 01-15 10:09:28.450055.450055 lmp.py:1626]   Expert 15 |    152 | CPU
DEBUG 01-15 10:09:28.450434.450434 lmp.py:1626]   Expert 26 |    155 | CPU
DEBUG 01-15 10:09:28.450812.450812 lmp.py:1626]   Expert 57 |    156 | CPU
DEBUG 01-15 10:09:28.450714.450714 lmp.py:1626]   Expert 32 |    157 | CPU
DEBUG 01-15 10:09:28.450377.450377 lmp.py:1626]   Expert 34 |    159 | CPU
DEBUG 01-15 10:09:28.450233.450233 lmp.py:1626]   Expert 47 |    159 | CPU
DEBUG 01-15 10:09:28.450565.450565 lmp.py:1626]   Expert 24 |    163 | CPU
DEBUG 01-15 10:09:28.450421.450421 lmp.py:1626]   Expert  2 |    166 | CPU
DEBUG 01-15 10:09:28.450084.450084 lmp.py:1626]   Expert 52 |    167 | CPU
DEBUG 01-15 10:09:28.450747.450747 lmp.py:1626]   Expert 40 |    170 | CPU
DEBUG 01-15 10:09:28.450888.450888 lmp.py:1626]   Expert 13 |    171 | CPU
DEBUG 01-15 10:09:28.450505.450505 lmp.py:1626]   Expert 18 |    172 | CPU
DEBUG 01-15 10:09:28.450360.450360 lmp.py:1626]   Expert 41 |    172 | GPU
DEBUG 01-15 10:09:28.450262.450262 lmp.py:1626]   Expert 54 |    173 | GPU
DEBUG 01-15 10:09:28.450448.450448 lmp.py:1626]   Expert  6 |    174 | GPU
DEBUG 01-15 10:09:28.450112.450112 lmp.py:1626]   Expert  3 |    177 | GPU
DEBUG 01-15 10:09:28.450775.450775 lmp.py:1626]   Expert 19 |    177 | GPU
DEBUG 01-15 10:09:28.450869.450869 lmp.py:1626]   Expert 37 |    181 | GPU
DEBUG 01-15 10:09:28.450724.450724 lmp.py:1626]   Expert 20 |    183 | GPU
DEBUG 01-15 10:09:28.450626.450626 lmp.py:1626]   Expert 25 |    186 | GPU
DEBUG 01-15 10:09:28.450051.450051 lmp.py:1626]   Expert 46 |    186 | GPU
DEBUG 01-15 10:09:28.450138.450138 lmp.py:1626]   Expert 51 |    196 | GPU
DEBUG 01-15 10:09:28.450258.450258 lmp.py:1626]   Expert 17 |    197 | GPU
DEBUG 01-15 10:09:28.450662.450662 lmp.py:1626]   Expert 43 |    200 | GPU
DEBUG 01-15 10:09:28.450067.450067 lmp.py:1626]   Expert 31 |    201 | GPU
DEBUG 01-15 10:09:28.450425.450425 lmp.py:1626]   Expert 11 |    202 | GPU
DEBUG 01-15 10:09:28.450307.450307 lmp.py:1626]   Expert 35 |    204 | GPU
DEBUG 01-15 10:09:28.450665.450665 lmp.py:1626]   Expert 23 |    211 | GPU
DEBUG 01-15 10:09:28.450023.450023 lmp.py:1626]   Expert 39 |    220 | GPU
DEBUG 01-15 10:09:28.450620.450620 lmp.py:1626]   Expert 49 |    220 | GPU
DEBUG 01-15 10:09:28.450739.450739 lmp.py:1626]   Expert 53 |    230 | GPU
DEBUG 01-15 10:09:28.450621.450621 lmp.py:1626]   Expert 10 |    234 | GPU
DEBUG 01-15 10:09:28.450502.450502 lmp.py:1626]   Expert 33 |    247 | GPU
DEBUG 01-15 10:09:28.450145.450145 lmp.py:1626]   Expert 36 |    265 | GPU
DEBUG 01-15 10:09:28.450027.450027 lmp.py:1626]   Expert 38 |    269 | GPU
DEBUG 01-15 10:09:28.450908.450908 lmp.py:1626]   Expert  4 |    305 | GPU
DEBUG 01-15 10:09:28.451551.451551 lmp.py:1626]   Expert 21 |    335 | GPU
DEBUG 01-15 10:09:28.451671.451671 lmp.py:1626]   Expert 14 |    349 | GPU
DEBUG 01-15 10:09:28.451267.451267 lmp.py:1626]   Expert 63 |    370 | GPU
DEBUG 01-15 10:09:28.451864.451864 lmp.py:1626]   Expert 45 |    373 | GPU
DEBUG 01-15 10:09:28.451699.451699 lmp.py:1626]   Expert  9 |    387 | GPU
DEBUG 01-15 10:09:28.451534.451534 lmp.py:1626]   Expert 61 |    394 | GPU
DEBUG 01-15 10:09:28.451177.451177 lmp.py:1626]   Expert 29 |    492 | GPU
DEBUG 01-15 10:09:28.451820.451820 lmp.py:1626]   Expert  7 |    514 | GPU
DEBUG 01-15 10:09:28.451417.451417 lmp.py:1627] 
DEBUG 01-15 10:09:28.451417.451417 lmp.py:1627]   CPU total tokens: 4064 (33.1%)
DEBUG 01-15 10:09:28.451013.451013 lmp.py:1628]   GPU total tokens: 8224 (66.9%)
DEBUG 01-15 10:09:28.451617.451617 cuda_h.py:19] end experts_map_get cost 0.0025551319122314453 seconds
DEBUG 01-15 10:09:28.451189.451189 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.451852.451852 lmp.py:1636] 
DEBUG 01-15 10:09:28.451852.451852 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.451457.451457 cuda_h.py:19] end cpu_experts_submit cost 5.91278076171875e-05 seconds
DEBUG 01-15 10:09:28.451676.451676 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.451241.451241 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.451400.451400 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.451719.451719 cuda_h.py:19] end allocate_cuda_memory cost 0.00020170211791992188 seconds
DEBUG 01-15 10:09:28.451655.451655 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.451980.451980 sllm_store_c.py:27] get device uuid map
INFO 01-15 10:09:28.452397.452397 client.py:127] Model loaded
DEBUG 01-15 10:09:28.452243.452243 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.452208.452208 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5512f52a-d35a-4ac7-b307-b72a01d764b1
DEBUG 01-15 10:09:28.452254.452254 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.453414.453414 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.453985.453985 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.452663.452663 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.454321.454321 cuda_h.py:19] end move_flatidxs cost 0.0009090900421142578 seconds
DEBUG 01-15 10:09:28.454548.454548 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.454354.454354 cuda_h.py:19] end restore2model cost 0.0009751319885253906 seconds
INFO 01-15 10:09:28.454630.454630 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5512f52a-d35a-4ac7-b307-b72a01d764b1
DEBUG 01-15 10:09:28.454567.454567 cuda_h.py:19] end sllm_worker_task cost 0.01492619514465332 seconds
DEBUG 01-15 10:09:28.454941.454941 cuda_h.py:19] end load_into_gpu_async cost 0.002598285675048828 seconds
DEBUG 01-15 10:09:28.454786.454786 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.455244.455244 cuda_h.py:19] end restore_tensors2 cost 0.000415802001953125 seconds
DEBUG 01-15 10:09:28.455650.455650 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036821365356445312 seconds
DEBUG 01-15 10:09:28.455188.455188 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.458666.458666 cuda_h.py:19] end restore2model cost 0.002782106399536133 seconds
DEBUG 01-15 10:09:28.458125.458125 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0066640377044677734 seconds
DEBUG 01-15 10:09:28.458967.458967 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.458587.458587 cuda_h.py:19] end gpu_sexperts cost 0.00028705596923828125 seconds
DEBUG 01-15 10:09:28.458463.458463 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.460621.460621 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015168190002441406 seconds
DEBUG 01-15 10:09:28.460177.460177 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.460503.460503 cuda_h.py:19] end group_tensors cost 0.006095409393310547 seconds
DEBUG 01-15 10:09:28.461803.461803 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.461158.461158 cuda_h.py:19] end gpu_group_list cost 0.0003578662872314453 seconds
DEBUG 01-15 10:09:28.461480.461480 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.462760.462760 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007970333099365234 seconds
DEBUG 01-15 10:09:28.462721.462721 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.462405.462405 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-15 10:09:28.462055.462055 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.465652.465652 cuda_h.py:19] end group pad cost 0.0041468143463134766 seconds
DEBUG 01-15 10:09:28.465416.465416 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.486117.486117 cuda_h.py:19] end group_einsum cost 0.020824909210205078 seconds
DEBUG 01-15 10:09:28.486287.486287 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.491663.491663 cuda_h.py:19] end get_outputs_cpu1 cost 0.004796504974365234 seconds
DEBUG 01-15 10:09:28.492324.492324 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.039180755615234375 seconds
DEBUG 01-15 10:09:28.493992.493992 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03066730499267578 seconds
DEBUG 01-15 10:09:28.493058.493058 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.493251.493251 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.493166.493166 cuda_h.py:19] end index_scatter cost 0.00014734268188476562 seconds
DEBUG 01-15 10:09:28.494649.494649 cuda_h.py:19] end cpuoutputsdeal cost 0.0011589527130126953 seconds
DEBUG 01-15 10:09:28.494540.494540 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.494264.494264 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5512f52a-d35a-4ac7-b307-b72a01d764b1
INFO 01-15 10:09:28.505174.505174 client.py:127] Model loaded
DEBUG 01-15 10:09:28.505503.505503 cuda_h.py:19] end wait_experts cost 0.010715723037719727 seconds
DEBUG 01-15 10:09:28.505267.505267 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.505351.505351 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.505599.505599 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.506409.506409 cuda_h.py:19] end gpu_group_tensor cost 0.00037980079650878906 seconds
DEBUG 01-15 10:09:28.506059.506059 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.507474.507474 cuda_h.py:19] end gpu_group_einsum cost 0.0010018348693847656 seconds
DEBUG 01-15 10:09:28.507899.507899 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.507923.507923 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.508383.508383 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006072521209716797 seconds
DEBUG 01-15 10:09:28.508399.508399 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.508923.508923 cuda_h.py:19] end concat_expert_out cost 0.00013327598571777344 seconds
DEBUG 01-15 10:09:28.508835.508835 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.509405.509405 cuda_h.py:19] end index_scatter cost 0.0001220703125 seconds
DEBUG 01-15 10:09:28.509435.509435 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014548301696777344 seconds
DEBUG 01-15 10:09:28.509765.509765 cuda_h.py:19] end gpu_experts cost 0.0039141178131103516 seconds
DEBUG 01-15 10:09:28.509407.509407 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.062067270278930664 seconds
DEBUG 01-15 10:09:28.510255.510255 cuda_h.py:19] end prefill_layer cost 0.0716714859008789 seconds
DEBUG 01-15 10:09:28.510286.510286 lmp.py:1552] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-15 10:09:28.510520.510520 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.510661.510661 lmp.py:1495] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-15 10:09:28.510756.510756 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:28.510050.510050 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:28.510632.510632 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.771087646484375e-05 seconds
DEBUG 01-15 10:09:28.511594.511594 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00015735626220703125 seconds
DEBUG 01-15 10:09:28.511533.511533 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.511893.511893 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.511779.511779 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.511329.511329 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.511447.511447 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.512436.512436 cuda_h.py:19] end allocate_cuda_memory cost 0.0004487037658691406 seconds
DEBUG 01-15 10:09:28.512256.512256 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.512578.512578 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.512542.512542 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.512312.512312 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a81a4238-1fde-46b8-91bd-b81e2c24e118
DEBUG 01-15 10:09:28.513942.513942 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.513807.513807 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.514157.514157 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a81a4238-1fde-46b8-91bd-b81e2c24e118
DEBUG 01-15 10:09:28.514526.514526 cuda_h.py:19] end load_into_gpu_async cost 0.0016090869903564453 seconds
DEBUG 01-15 10:09:28.514482.514482 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.514748.514748 cuda_h.py:19] end restore_tensors2 cost 0.0001575946807861328 seconds
DEBUG 01-15 10:09:28.514328.514328 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003019571304321289 seconds
INFO 01-15 10:09:28.514015.514015 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a81a4238-1fde-46b8-91bd-b81e2c24e118
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.519947.519947 cuda_h.py:19] end self_attn cost 0.0060689449310302734 seconds
DEBUG 01-15 10:09:28.520018.520018 cuda_h.py:19] end iln_self_attn_paln cost 0.008819103240966797 seconds
DEBUG 01-15 10:09:28.520758.520758 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-15 10:09:28.520952.520952 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.521783.521783 cuda_h.py:19] end gate cost 0.0010056495666503906 seconds
DEBUG 01-15 10:09:28.521334.521334 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.522585.522585 lmp.py:1616] 
DEBUG 01-15 10:09:28.522585.522585 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.522970.522970 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.522057.522057 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.522568.522568 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.522741.522741 lmp.py:1620] 
DEBUG 01-15 10:09:28.522741.522741 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.522914.522914 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.522709.522709 lmp.py:1626]   Expert 54 |     21 | CPU
DEBUG 01-15 10:09:28.522597.522597 lmp.py:1626]   Expert  3 |     33 | CPU
DEBUG 01-15 10:09:28.522294.522294 lmp.py:1626]   Expert  8 |     39 | CPU
DEBUG 01-15 10:09:28.522943.522943 lmp.py:1626]   Expert 28 |     44 | CPU
DEBUG 01-15 10:09:28.522593.522593 lmp.py:1626]   Expert 43 |     54 | CPU
DEBUG 01-15 10:09:28.522481.522481 lmp.py:1626]   Expert 63 |     56 | CPU
DEBUG 01-15 10:09:28.522893.522893 lmp.py:1626]   Expert 38 |     74 | CPU
DEBUG 01-15 10:09:28.522350.522350 lmp.py:1626]   Expert 36 |     76 | CPU
DEBUG 01-15 10:09:28.522046.522046 lmp.py:1626]   Expert  6 |     82 | CPU
DEBUG 01-15 10:09:28.522742.522742 lmp.py:1626]   Expert 39 |     99 | CPU
DEBUG 01-15 10:09:28.522962.522962 lmp.py:1626]   Expert 57 |     99 | CPU
DEBUG 01-15 10:09:28.522419.522419 lmp.py:1626]   Expert 41 |    103 | CPU
DEBUG 01-15 10:09:28.522877.522877 lmp.py:1626]   Expert 12 |    106 | CPU
DEBUG 01-15 10:09:28.522096.522096 lmp.py:1626]   Expert 52 |    110 | CPU
DEBUG 01-15 10:09:28.522223.522223 lmp.py:1626]   Expert 19 |    120 | CPU
DEBUG 01-15 10:09:28.522111.522111 lmp.py:1626]   Expert 47 |    127 | CPU
DEBUG 01-15 10:09:28.522999.522999 lmp.py:1626]   Expert 13 |    134 | CPU
DEBUG 01-15 10:09:28.522934.522934 lmp.py:1626]   Expert 22 |    137 | CPU
DEBUG 01-15 10:09:28.522868.522868 lmp.py:1626]   Expert 46 |    147 | CPU
DEBUG 01-15 10:09:28.522564.522564 lmp.py:1626]   Expert 50 |    150 | CPU
DEBUG 01-15 10:09:28.522784.522784 lmp.py:1626]   Expert 40 |    162 | CPU
DEBUG 01-15 10:09:28.522480.522480 lmp.py:1626]   Expert 20 |    165 | CPU
DEBUG 01-15 10:09:28.522176.522176 lmp.py:1626]   Expert 24 |    166 | CPU
DEBUG 01-15 10:09:28.522634.522634 lmp.py:1626]   Expert 55 |    167 | CPU
DEBUG 01-15 10:09:28.522330.522330 lmp.py:1626]   Expert  2 |    173 | CPU
DEBUG 01-15 10:09:28.522979.522979 lmp.py:1626]   Expert 21 |    173 | CPU
DEBUG 01-15 10:09:28.522914.522914 lmp.py:1626]   Expert 37 |    173 | CPU
DEBUG 01-15 10:09:28.522325.522325 lmp.py:1626]   Expert 23 |    174 | CPU
DEBUG 01-15 10:09:28.522783.522783 lmp.py:1626]   Expert 61 |    176 | CPU
DEBUG 01-15 10:09:28.522764.522764 lmp.py:1626]   Expert 42 |    178 | CPU
DEBUG 01-15 10:09:28.522983.522983 lmp.py:1626]   Expert 53 |    178 | CPU
DEBUG 01-15 10:09:28.522964.522964 lmp.py:1626]   Expert 49 |    180 | CPU
DEBUG 01-15 10:09:28.522183.522183 lmp.py:1626]   Expert 33 |    190 | GPU
DEBUG 01-15 10:09:28.522164.522164 lmp.py:1626]   Expert 18 |    191 | GPU
DEBUG 01-15 10:09:28.522383.522383 lmp.py:1626]   Expert 32 |    196 | GPU
DEBUG 01-15 10:09:28.522602.522602 lmp.py:1626]   Expert  0 |    200 | GPU
DEBUG 01-15 10:09:28.522822.522822 lmp.py:1626]   Expert 30 |    202 | GPU
DEBUG 01-15 10:09:28.522803.522803 lmp.py:1626]   Expert  5 |    203 | GPU
DEBUG 01-15 10:09:28.523022.523022 lmp.py:1626]   Expert 16 |    203 | GPU
DEBUG 01-15 10:09:28.523479.523479 lmp.py:1626]   Expert 14 |    208 | GPU
DEBUG 01-15 10:09:28.523460.523460 lmp.py:1626]   Expert 34 |    209 | GPU
DEBUG 01-15 10:09:28.523633.523633 lmp.py:1626]   Expert 31 |    210 | GPU
DEBUG 01-15 10:09:28.523521.523521 lmp.py:1626]   Expert  7 |    217 | GPU
DEBUG 01-15 10:09:28.523933.523933 lmp.py:1626]   Expert 59 |    220 | GPU
DEBUG 01-15 10:09:28.523106.523106 lmp.py:1626]   Expert 60 |    220 | GPU
DEBUG 01-15 10:09:28.523802.523802 lmp.py:1626]   Expert  9 |    221 | GPU
DEBUG 01-15 10:09:28.523021.523021 lmp.py:1626]   Expert 62 |    221 | GPU
DEBUG 01-15 10:09:28.523240.523240 lmp.py:1626]   Expert 17 |    223 | GPU
DEBUG 01-15 10:09:28.523221.523221 lmp.py:1626]   Expert 10 |    225 | GPU
DEBUG 01-15 10:09:28.523679.523679 lmp.py:1626]   Expert 29 |    227 | GPU
DEBUG 01-15 10:09:28.523183.523183 lmp.py:1626]   Expert 58 |    233 | GPU
DEBUG 01-15 10:09:28.523356.523356 lmp.py:1626]   Expert 15 |    235 | GPU
DEBUG 01-15 10:09:28.523529.523529 lmp.py:1626]   Expert  4 |    236 | GPU
DEBUG 01-15 10:09:28.523417.523417 lmp.py:1626]   Expert 26 |    241 | GPU
DEBUG 01-15 10:09:28.523305.523305 lmp.py:1626]   Expert 51 |    254 | GPU
DEBUG 01-15 10:09:28.523001.523001 lmp.py:1626]   Expert 11 |    262 | GPU
DEBUG 01-15 10:09:28.523936.523936 lmp.py:1626]   Expert 44 |    266 | GPU
DEBUG 01-15 10:09:28.523393.523393 lmp.py:1626]   Expert 56 |    289 | GPU
DEBUG 01-15 10:09:28.523374.523374 lmp.py:1626]   Expert 27 |    290 | GPU
DEBUG 01-15 10:09:28.523832.523832 lmp.py:1626]   Expert  1 |    330 | GPU
DEBUG 01-15 10:09:28.523813.523813 lmp.py:1626]   Expert 45 |    364 | GPU
DEBUG 01-15 10:09:28.523569.523569 lmp.py:1626]   Expert 25 |    465 | GPU
DEBUG 01-15 10:09:28.523503.523503 lmp.py:1626]   Expert 35 |    517 | GPU
DEBUG 01-15 10:09:28.523391.523391 lmp.py:1626]   Expert 48 |    644 | GPU
DEBUG 01-15 10:09:28.523995.523995 lmp.py:1627] 
DEBUG 01-15 10:09:28.523995.523995 lmp.py:1627]   CPU total tokens: 3876 (31.5%)
DEBUG 01-15 10:09:28.523075.523075 lmp.py:1628]   GPU total tokens: 8412 (68.5%)
DEBUG 01-15 10:09:28.523970.523970 cuda_h.py:19] end experts_map_get cost 0.00194549560546875 seconds
DEBUG 01-15 10:09:28.523787.523787 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.523073.523073 lmp.py:1636] 
DEBUG 01-15 10:09:28.523073.523073 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.523784.523784 cuda_h.py:19] end cpu_experts_submit cost 6.628036499023438e-05 seconds
DEBUG 01-15 10:09:28.523010.523010 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.523628.523628 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.524244.524244 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.524935.524935 cuda_h.py:19] end allocate_cuda_memory cost 0.0002155303955078125 seconds
DEBUG 01-15 10:09:28.524123.524123 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.524455.524455 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.524563.524563 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.524604.524604 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 21d91760-4c9c-471a-9113-408197b97212
DEBUG 01-15 10:09:28.524904.524904 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:28.525164.525164 client.py:127] Model loaded
DEBUG 01-15 10:09:28.525566.525566 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.525874.525874 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.525816.525816 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.526684.526684 cuda_h.py:19] end restore2model cost 0.0010440349578857422 seconds
DEBUG 01-15 10:09:28.526981.526981 cuda_h.py:19] end move_flatidxs cost 0.0009293556213378906 seconds
DEBUG 01-15 10:09:28.527354.527354 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:28.526444.526444 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 21d91760-4c9c-471a-9113-408197b97212
DEBUG 01-15 10:09:28.527202.527202 cuda_h.py:19] end sllm_worker_task cost 0.015601634979248047 seconds
DEBUG 01-15 10:09:28.527821.527821 cuda_h.py:19] end load_into_gpu_async cost 0.0026149749755859375 seconds
DEBUG 01-15 10:09:28.527679.527679 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.527067.527067 cuda_h.py:19] end restore_tensors2 cost 0.00046181678771972656 seconds
DEBUG 01-15 10:09:28.527486.527486 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003833293914794922 seconds
DEBUG 01-15 10:09:28.527322.527322 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.531509.531509 cuda_h.py:19] end restore2model cost 0.0031561851501464844 seconds
DEBUG 01-15 10:09:28.531220.531220 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007220029830932617 seconds
DEBUG 01-15 10:09:28.531545.531545 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.531232.531232 cuda_h.py:19] end gpu_sexperts cost 0.00029587745666503906 seconds
DEBUG 01-15 10:09:28.531346.531346 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.533868.533868 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015072822570800781 seconds
DEBUG 01-15 10:09:28.533138.533138 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.534165.534165 cuda_h.py:19] end gpu_group_list cost 0.00035691261291503906 seconds
DEBUG 01-15 10:09:28.534844.534844 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.535208.535208 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007205009460449219 seconds
DEBUG 01-15 10:09:28.535216.535216 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.535369.535369 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-15 10:09:28.535304.535304 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.539306.539306 cuda_h.py:19] end group_tensors cost 0.012732267379760742 seconds
DEBUG 01-15 10:09:28.540570.540570 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.544592.544592 cuda_h.py:19] end group pad cost 0.00413966178894043 seconds
DEBUG 01-15 10:09:28.544680.544680 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.565296.565296 cuda_h.py:19] end group_einsum cost 0.02086663246154785 seconds
DEBUG 01-15 10:09:28.565467.565467 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.571759.571759 cuda_h.py:19] end get_outputs_cpu1 cost 0.0058994293212890625 seconds
DEBUG 01-15 10:09:28.572945.572945 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04693603515625 seconds
DEBUG 01-15 10:09:28.573729.573729 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.038338422775268555 seconds
DEBUG 01-15 10:09:28.573198.573198 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.574204.574204 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.574369.574369 cuda_h.py:19] end index_scatter cost 0.0001201629638671875 seconds
DEBUG 01-15 10:09:28.575810.575810 cuda_h.py:19] end cpuoutputsdeal cost 0.0011951923370361328 seconds
DEBUG 01-15 10:09:28.575534.575534 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.575331.575331 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 21d91760-4c9c-471a-9113-408197b97212
INFO 01-15 10:09:28.577717.577717 client.py:127] Model loaded
DEBUG 01-15 10:09:28.577455.577455 cuda_h.py:19] end wait_experts cost 0.002313375473022461 seconds
DEBUG 01-15 10:09:28.577655.577655 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.577393.577393 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.577507.577507 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.577854.577854 cuda_h.py:19] end gpu_group_tensor cost 0.0002455711364746094 seconds
DEBUG 01-15 10:09:28.578489.578489 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.578255.578255 cuda_h.py:19] end gpu_group_einsum cost 0.0006728172302246094 seconds
DEBUG 01-15 10:09:28.578042.578042 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.579720.579720 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.579124.579124 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003559589385986328 seconds
DEBUG 01-15 10:09:28.579709.579709 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.579978.579978 cuda_h.py:19] end concat_expert_out cost 7.987022399902344e-05 seconds
DEBUG 01-15 10:09:28.579762.579762 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.579501.579501 cuda_h.py:19] end index_scatter cost 7.319450378417969e-05 seconds
DEBUG 01-15 10:09:28.579715.579715 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008571147918701172 seconds
DEBUG 01-15 10:09:28.580156.580156 cuda_h.py:19] end gpu_experts cost 0.0024716854095458984 seconds
DEBUG 01-15 10:09:28.580504.580504 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.0596158504486084 seconds
DEBUG 01-15 10:09:28.580255.580255 cuda_h.py:19] end prefill_layer cost 0.07013344764709473 seconds
DEBUG 01-15 10:09:28.580516.580516 lmp.py:1552] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-15 10:09:28.580047.580047 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.580770.580770 lmp.py:1495] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-15 10:09:28.581447.581447 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:28.581270.581270 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:28.581300.581300 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 4.982948303222656e-05 seconds
DEBUG 01-15 10:09:28.581076.581076 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 9.942054748535156e-05 seconds
DEBUG 01-15 10:09:28.581892.581892 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.581571.581571 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.581655.581655 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.581502.581502 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.581097.581097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.582155.582155 cuda_h.py:19] end allocate_cuda_memory cost 0.0004382133483886719 seconds
DEBUG 01-15 10:09:28.582182.582182 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.582523.582523 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.582455.582455 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.582630.582630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ecd1de53-b13d-4625-b85f-66a876c18667
DEBUG 01-15 10:09:28.583816.583816 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.583644.583644 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.584710.584710 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ecd1de53-b13d-4625-b85f-66a876c18667
DEBUG 01-15 10:09:28.584676.584676 cuda_h.py:19] end load_into_gpu_async cost 0.0017948150634765625 seconds
DEBUG 01-15 10:09:28.584567.584567 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.584277.584277 cuda_h.py:19] end restore_tensors2 cost 0.0001513957977294922 seconds
DEBUG 01-15 10:09:28.584996.584996 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031690597534179688 seconds
INFO 01-15 10:09:28.585491.585491 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ecd1de53-b13d-4625-b85f-66a876c18667
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.587482.587482 cuda_h.py:19] end self_attn cost 0.003984212875366211 seconds
DEBUG 01-15 10:09:28.587474.587474 cuda_h.py:19] end iln_self_attn_paln cost 0.006459951400756836 seconds
DEBUG 01-15 10:09:28.587370.587370 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-15 10:09:28.587802.587802 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.588909.588909 cuda_h.py:19] end gate cost 0.0007801055908203125 seconds
DEBUG 01-15 10:09:28.588884.588884 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.589352.589352 lmp.py:1616] 
DEBUG 01-15 10:09:28.589352.589352 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.589685.589685 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.589003.589003 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.589223.589223 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.589058.589058 lmp.py:1620] 
DEBUG 01-15 10:09:28.589058.589058 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.589131.589131 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.589635.589635 lmp.py:1626]   Expert 44 |     29 | CPU
DEBUG 01-15 10:09:28.589470.589470 lmp.py:1626]   Expert 11 |     34 | CPU
DEBUG 01-15 10:09:28.589828.589828 lmp.py:1626]   Expert  9 |     35 | CPU
DEBUG 01-15 10:09:28.589187.589187 lmp.py:1626]   Expert 56 |     57 | CPU
DEBUG 01-15 10:09:28.589545.589545 lmp.py:1626]   Expert 54 |     80 | CPU
DEBUG 01-15 10:09:28.589665.589665 lmp.py:1626]   Expert 47 |     92 | CPU
DEBUG 01-15 10:09:28.589261.589261 lmp.py:1626]   Expert 62 |     92 | CPU
DEBUG 01-15 10:09:28.589143.589143 lmp.py:1626]   Expert  7 |     95 | CPU
DEBUG 01-15 10:09:28.589024.589024 lmp.py:1626]   Expert 51 |     99 | CPU
DEBUG 01-15 10:09:28.589382.589382 lmp.py:1626]   Expert 52 |    107 | CPU
DEBUG 01-15 10:09:28.589264.589264 lmp.py:1626]   Expert 60 |    108 | CPU
DEBUG 01-15 10:09:28.589384.589384 lmp.py:1626]   Expert 22 |    109 | CPU
DEBUG 01-15 10:09:28.589027.589027 lmp.py:1626]   Expert 41 |    111 | CPU
DEBUG 01-15 10:09:28.589670.589670 lmp.py:1626]   Expert 53 |    112 | CPU
DEBUG 01-15 10:09:28.589313.589313 lmp.py:1626]   Expert  6 |    127 | CPU
DEBUG 01-15 10:09:28.589955.589955 lmp.py:1626]   Expert  8 |    127 | CPU
DEBUG 01-15 10:09:28.589837.589837 lmp.py:1626]   Expert 32 |    128 | CPU
DEBUG 01-15 10:09:28.589480.589480 lmp.py:1626]   Expert 48 |    128 | CPU
DEBUG 01-15 10:09:28.589123.589123 lmp.py:1626]   Expert  1 |    130 | CPU
DEBUG 01-15 10:09:28.589004.589004 lmp.py:1626]   Expert  2 |    130 | CPU
DEBUG 01-15 10:09:28.589124.589124 lmp.py:1626]   Expert 59 |    139 | CPU
DEBUG 01-15 10:09:28.589005.589005 lmp.py:1626]   Expert 23 |    140 | CPU
DEBUG 01-15 10:09:28.589887.589887 lmp.py:1626]   Expert 35 |    140 | CPU
DEBUG 01-15 10:09:28.589530.589530 lmp.py:1626]   Expert 27 |    142 | CPU
DEBUG 01-15 10:09:28.589173.589173 lmp.py:1626]   Expert 39 |    146 | CPU
DEBUG 01-15 10:09:28.589816.589816 lmp.py:1626]   Expert 26 |    147 | CPU
DEBUG 01-15 10:09:28.589459.589459 lmp.py:1626]   Expert 50 |    152 | CPU
DEBUG 01-15 10:09:28.589102.589102 lmp.py:1626]   Expert 14 |    155 | CPU
DEBUG 01-15 10:09:28.589506.589506 lmp.py:1626]   Expert 46 |    168 | CPU
DEBUG 01-15 10:09:28.589533.589533 lmp.py:1626]   Expert  0 |    171 | CPU
DEBUG 01-15 10:09:28.589322.589322 lmp.py:1626]   Expert 24 |    171 | CPU
DEBUG 01-15 10:09:28.589396.589396 lmp.py:1626]   Expert 34 |    172 | CPU
DEBUG 01-15 10:09:28.589781.589781 lmp.py:1626]   Expert  4 |    173 | GPU
DEBUG 01-15 10:09:28.589808.589808 lmp.py:1626]   Expert 38 |    173 | GPU
DEBUG 01-15 10:09:28.589451.589451 lmp.py:1626]   Expert 40 |    183 | GPU
DEBUG 01-15 10:09:28.589571.589571 lmp.py:1626]   Expert 49 |    183 | GPU
DEBUG 01-15 10:09:28.589691.589691 lmp.py:1626]   Expert  5 |    184 | GPU
DEBUG 01-15 10:09:28.589811.589811 lmp.py:1626]   Expert 63 |    186 | GPU
DEBUG 01-15 10:09:28.589930.589930 lmp.py:1626]   Expert 19 |    192 | GPU
DEBUG 01-15 10:09:28.589812.589812 lmp.py:1626]   Expert 13 |    197 | GPU
DEBUG 01-15 10:09:28.589932.589932 lmp.py:1626]   Expert 43 |    198 | GPU
DEBUG 01-15 10:09:28.589051.589051 lmp.py:1626]   Expert 29 |    202 | GPU
DEBUG 01-15 10:09:28.589933.589933 lmp.py:1626]   Expert 57 |    207 | GPU
DEBUG 01-15 10:09:28.589053.589053 lmp.py:1626]   Expert 61 |    209 | GPU
DEBUG 01-15 10:09:28.590696.590696 lmp.py:1626]   Expert 33 |    224 | GPU
DEBUG 01-15 10:09:28.590577.590577 lmp.py:1626]   Expert 31 |    225 | GPU
DEBUG 01-15 10:09:28.590220.590220 lmp.py:1626]   Expert 16 |    252 | GPU
DEBUG 01-15 10:09:28.590340.590340 lmp.py:1626]   Expert 37 |    252 | GPU
DEBUG 01-15 10:09:28.590221.590221 lmp.py:1626]   Expert  3 |    253 | GPU
DEBUG 01-15 10:09:28.590010.590010 lmp.py:1626]   Expert 20 |    253 | GPU
DEBUG 01-15 10:09:28.590130.590130 lmp.py:1626]   Expert 15 |    264 | GPU
DEBUG 01-15 10:09:28.590011.590011 lmp.py:1626]   Expert 36 |    274 | GPU
DEBUG 01-15 10:09:28.590654.590654 lmp.py:1626]   Expert 18 |    277 | GPU
DEBUG 01-15 10:09:28.590059.590059 lmp.py:1626]   Expert 12 |    284 | GPU
DEBUG 01-15 10:09:28.590702.590702 lmp.py:1626]   Expert 28 |    299 | GPU
DEBUG 01-15 10:09:28.590345.590345 lmp.py:1626]   Expert 17 |    304 | GPU
DEBUG 01-15 10:09:28.590464.590464 lmp.py:1626]   Expert 55 |    309 | GPU
DEBUG 01-15 10:09:28.590869.590869 lmp.py:1626]   Expert 30 |    317 | GPU
DEBUG 01-15 10:09:28.590512.590512 lmp.py:1626]   Expert 25 |    320 | GPU
DEBUG 01-15 10:09:28.590155.590155 lmp.py:1626]   Expert 58 |    336 | GPU
DEBUG 01-15 10:09:28.590036.590036 lmp.py:1626]   Expert 10 |    362 | GPU
DEBUG 01-15 10:09:28.590918.590918 lmp.py:1626]   Expert 45 |    386 | GPU
DEBUG 01-15 10:09:28.590322.590322 lmp.py:1626]   Expert 21 |    395 | GPU
DEBUG 01-15 10:09:28.590965.590965 lmp.py:1626]   Expert 42 |    642 | GPU
DEBUG 01-15 10:09:28.590516.590516 lmp.py:1627] 
DEBUG 01-15 10:09:28.590516.590516 lmp.py:1627]   CPU total tokens: 3773 (30.7%)
DEBUG 01-15 10:09:28.590589.590589 lmp.py:1628]   GPU total tokens: 8515 (69.3%)
DEBUG 01-15 10:09:28.590669.590669 cuda_h.py:19] end experts_map_get cost 0.0016710758209228516 seconds
DEBUG 01-15 10:09:28.590095.590095 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.590328.590328 lmp.py:1636] 
DEBUG 01-15 10:09:28.590328.590328 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.590602.590602 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-15 10:09:28.590821.590821 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.590717.590717 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.590949.590949 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.591171.591171 cuda_h.py:19] end allocate_cuda_memory cost 0.0006537437438964844 seconds
DEBUG 01-15 10:09:28.591783.591783 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.591876.591876 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.591997.591997 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.591131.591131 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb7716a0-5b35-4f1f-8636-fe07b7882a12
DEBUG 01-15 10:09:28.591702.591702 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:28.592763.592763 client.py:127] Model loaded
DEBUG 01-15 10:09:28.592873.592873 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.592928.592928 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:28.593884.593884 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb7716a0-5b35-4f1f-8636-fe07b7882a12
DEBUG 01-15 10:09:28.593403.593403 cuda_h.py:19] end load_into_gpu_async cost 0.0014736652374267578 seconds
DEBUG 01-15 10:09:28.593013.593013 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.593099.593099 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.593955.593955 cuda_h.py:19] end restore_tensors2 cost 0.00042057037353515625 seconds
DEBUG 01-15 10:09:28.593984.593984 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029785633087158203 seconds
DEBUG 01-15 10:09:28.593396.593396 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.594630.594630 cuda_h.py:19] end move_flatidxs cost 0.0009593963623046875 seconds
DEBUG 01-15 10:09:28.594599.594599 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.594893.594893 cuda_h.py:19] end restore2model cost 0.0009505748748779297 seconds
DEBUG 01-15 10:09:28.595108.595108 cuda_h.py:19] end sllm_worker_task cost 0.013376235961914062 seconds
DEBUG 01-15 10:09:28.597030.597030 cuda_h.py:19] end restore2model cost 0.003874063491821289 seconds
DEBUG 01-15 10:09:28.597033.597033 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007085323333740234 seconds
DEBUG 01-15 10:09:28.597590.597590 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.598515.598515 cuda_h.py:19] end gpu_sexperts cost 0.00029921531677246094 seconds
DEBUG 01-15 10:09:28.598821.598821 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.599873.599873 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015149116516113281 seconds
DEBUG 01-15 10:09:28.600582.600582 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.600251.600251 cuda_h.py:19] end gpu_group_list cost 0.0003368854522705078 seconds
DEBUG 01-15 10:09:28.600261.600261 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.601425.601425 cuda_h.py:19] end acpu_expert_weight_slices cost 0.000713348388671875 seconds
DEBUG 01-15 10:09:28.601910.601910 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.601402.601402 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-15 10:09:28.601336.601336 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.603636.603636 cuda_h.py:19] end group_tensors cost 0.009189367294311523 seconds
DEBUG 01-15 10:09:28.604153.604153 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.608786.608786 cuda_h.py:19] end group pad cost 0.0038182735443115234 seconds
DEBUG 01-15 10:09:28.608186.608186 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.626399.626399 cuda_h.py:19] end group_einsum cost 0.018325328826904297 seconds
DEBUG 01-15 10:09:28.627093.627093 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.631401.631401 cuda_h.py:19] end get_outputs_cpu1 cost 0.004580974578857422 seconds
DEBUG 01-15 10:09:28.632136.632136 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0393671989440918 seconds
DEBUG 01-15 10:09:28.633896.633896 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0314793586730957 seconds
DEBUG 01-15 10:09:28.633207.633207 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.634539.634539 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.634223.634223 cuda_h.py:19] end index_scatter cost 0.00014519691467285156 seconds
DEBUG 01-15 10:09:28.634632.634632 cuda_h.py:19] end cpuoutputsdeal cost 0.001142740249633789 seconds
DEBUG 01-15 10:09:28.634662.634662 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.634287.634287 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb7716a0-5b35-4f1f-8636-fe07b7882a12
INFO 01-15 10:09:28.644751.644751 client.py:127] Model loaded
DEBUG 01-15 10:09:28.644604.644604 cuda_h.py:19] end wait_experts cost 0.009261608123779297 seconds
DEBUG 01-15 10:09:28.644845.644845 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.644095.644095 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.644733.644733 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.644358.644358 cuda_h.py:19] end gpu_group_tensor cost 0.0003829002380371094 seconds
DEBUG 01-15 10:09:28.645763.645763 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.646389.646389 cuda_h.py:19] end gpu_group_einsum cost 0.0009822845458984375 seconds
DEBUG 01-15 10:09:28.646337.646337 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.646600.646600 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.647635.647635 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005791187286376953 seconds
DEBUG 01-15 10:09:28.647836.647836 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.647545.647545 cuda_h.py:19] end concat_expert_out cost 0.0001308917999267578 seconds
DEBUG 01-15 10:09:28.647166.647166 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.647206.647206 cuda_h.py:19] end index_scatter cost 0.00011944770812988281 seconds
DEBUG 01-15 10:09:28.648282.648282 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014045238494873047 seconds
DEBUG 01-15 10:09:28.648579.648579 cuda_h.py:19] end gpu_experts cost 0.0038771629333496094 seconds
DEBUG 01-15 10:09:28.648050.648050 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06060147285461426 seconds
DEBUG 01-15 10:09:28.649415.649415 cuda_h.py:19] end prefill_layer cost 0.06829619407653809 seconds
DEBUG 01-15 10:09:28.649261.649261 lmp.py:1552] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-15 10:09:28.649449.649449 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.649736.649736 lmp.py:1495] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-15 10:09:28.649977.649977 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:28.649555.649555 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:28.649375.649375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:28.649465.649465 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.650376.650376 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.0003228187561035156 seconds
DEBUG 01-15 10:09:28.650184.650184 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.650081.650081 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.650537.650537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.651419.651419 cuda_h.py:19] end allocate_cuda_memory cost 0.0004458427429199219 seconds
DEBUG 01-15 10:09:28.651711.651711 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.651338.651338 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.651743.651743 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.651707.651707 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.651762.651762 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9f19b887-9c8a-4d02-ac37-3f499c932454
DEBUG 01-15 10:09:28.652140.652140 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.652494.652494 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.653794.653794 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9f19b887-9c8a-4d02-ac37-3f499c932454
DEBUG 01-15 10:09:28.653926.653926 cuda_h.py:19] end load_into_gpu_async cost 0.0017123222351074219 seconds
DEBUG 01-15 10:09:28.653743.653743 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.653870.653870 cuda_h.py:19] end restore_tensors2 cost 0.00016045570373535156 seconds
DEBUG 01-15 10:09:28.653019.653019 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033922195434570312 seconds
INFO 01-15 10:09:28.654637.654637 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9f19b887-9c8a-4d02-ac37-3f499c932454
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.658395.658395 cuda_h.py:19] end self_attn cost 0.005416393280029297 seconds
DEBUG 01-15 10:09:28.658172.658172 cuda_h.py:19] end iln_self_attn_paln cost 0.008185148239135742 seconds
DEBUG 01-15 10:09:28.658347.658347 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-15 10:09:28.658760.658760 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.659184.659184 cuda_h.py:19] end gate cost 0.0009133815765380859 seconds
DEBUG 01-15 10:09:28.660908.660908 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.660165.660165 lmp.py:1616] 
DEBUG 01-15 10:09:28.660165.660165 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.660954.660954 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.660870.660870 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.660109.660109 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.660488.660488 lmp.py:1620] 
DEBUG 01-15 10:09:28.660488.660488 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.660675.660675 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.660292.660292 lmp.py:1626]   Expert 25 |     13 | CPU
DEBUG 01-15 10:09:28.660478.660478 lmp.py:1626]   Expert 48 |     32 | CPU
DEBUG 01-15 10:09:28.660188.660188 lmp.py:1626]   Expert 45 |     36 | CPU
DEBUG 01-15 10:09:28.660235.660235 lmp.py:1626]   Expert  9 |     65 | CPU
DEBUG 01-15 10:09:28.660568.660568 lmp.py:1626]   Expert  0 |     84 | CPU
DEBUG 01-15 10:09:28.660185.660185 lmp.py:1626]   Expert 20 |     87 | CPU
DEBUG 01-15 10:09:28.661517.661517 lmp.py:1626]   Expert 54 |     87 | CPU
DEBUG 01-15 10:09:28.661419.661419 lmp.py:1626]   Expert 43 |     88 | CPU
DEBUG 01-15 10:09:28.661320.661320 lmp.py:1626]   Expert 57 |     90 | CPU
DEBUG 01-15 10:09:28.661507.661507 lmp.py:1626]   Expert 47 |     92 | CPU
DEBUG 01-15 10:09:28.661170.661170 lmp.py:1626]   Expert 36 |     93 | CPU
DEBUG 01-15 10:09:28.661595.661595 lmp.py:1626]   Expert  6 |     96 | CPU
DEBUG 01-15 10:09:28.661689.661689 lmp.py:1626]   Expert 15 |    102 | CPU
DEBUG 01-15 10:09:28.661068.661068 lmp.py:1626]   Expert 62 |    103 | CPU
DEBUG 01-15 10:09:28.661685.661685 lmp.py:1626]   Expert 50 |    105 | CPU
DEBUG 01-15 10:09:28.661348.661348 lmp.py:1626]   Expert 13 |    106 | CPU
DEBUG 01-15 10:09:28.661534.661534 lmp.py:1626]   Expert  1 |    108 | CPU
DEBUG 01-15 10:09:28.661959.661959 lmp.py:1626]   Expert 61 |    108 | CPU
DEBUG 01-15 10:09:28.661100.661100 lmp.py:1626]   Expert 38 |    110 | CPU
DEBUG 01-15 10:09:28.661240.661240 lmp.py:1626]   Expert 37 |    114 | CPU
DEBUG 01-15 10:09:28.661380.661380 lmp.py:1626]   Expert 14 |    118 | CPU
DEBUG 01-15 10:09:28.661043.661043 lmp.py:1626]   Expert 46 |    122 | CPU
DEBUG 01-15 10:09:28.661468.661468 lmp.py:1626]   Expert  7 |    134 | CPU
DEBUG 01-15 10:09:28.661893.661893 lmp.py:1626]   Expert 21 |    139 | CPU
DEBUG 01-15 10:09:28.661510.661510 lmp.py:1626]   Expert 28 |    140 | CPU
DEBUG 01-15 10:09:28.661366.661366 lmp.py:1626]   Expert 52 |    143 | CPU
DEBUG 01-15 10:09:28.661983.661983 lmp.py:1626]   Expert 44 |    147 | CPU
DEBUG 01-15 10:09:28.661646.661646 lmp.py:1626]   Expert 10 |    152 | CPU
DEBUG 01-15 10:09:28.661309.661309 lmp.py:1626]   Expert 42 |    153 | CPU
DEBUG 01-15 10:09:28.661211.661211 lmp.py:1626]   Expert 24 |    155 | CPU
DEBUG 01-15 10:09:28.661113.661113 lmp.py:1626]   Expert 11 |    159 | CPU
DEBUG 01-15 10:09:28.661730.661730 lmp.py:1626]   Expert  2 |    164 | CPU
DEBUG 01-15 10:09:28.661585.661585 lmp.py:1626]   Expert 26 |    171 | GPU
DEBUG 01-15 10:09:28.661202.661202 lmp.py:1626]   Expert 35 |    171 | GPU
DEBUG 01-15 10:09:28.661581.661581 lmp.py:1626]   Expert 31 |    175 | GPU
DEBUG 01-15 10:09:28.661483.661483 lmp.py:1626]   Expert  3 |    183 | GPU
DEBUG 01-15 10:09:28.662908.662908 lmp.py:1626]   Expert 19 |    183 | GPU
DEBUG 01-15 10:09:28.662763.662763 lmp.py:1626]   Expert 32 |    187 | GPU
DEBUG 01-15 10:09:28.662142.662142 lmp.py:1626]   Expert 12 |    194 | GPU
DEBUG 01-15 10:09:28.662997.662997 lmp.py:1626]   Expert 60 |    207 | GPU
DEBUG 01-15 10:09:28.662137.662137 lmp.py:1626]   Expert 56 |    208 | GPU
DEBUG 01-15 10:09:28.662562.662562 lmp.py:1626]   Expert 40 |    215 | GPU
DEBUG 01-15 10:09:28.662987.662987 lmp.py:1626]   Expert 41 |    217 | GPU
DEBUG 01-15 10:09:28.662650.662650 lmp.py:1626]   Expert  8 |    231 | GPU
DEBUG 01-15 10:09:28.662506.662506 lmp.py:1626]   Expert 23 |    232 | GPU
DEBUG 01-15 10:09:28.662123.662123 lmp.py:1626]   Expert 53 |    232 | GPU
DEBUG 01-15 10:09:28.662740.662740 lmp.py:1626]   Expert 58 |    233 | GPU
DEBUG 01-15 10:09:28.662403.662403 lmp.py:1626]   Expert 16 |    234 | GPU
DEBUG 01-15 10:09:28.662067.662067 lmp.py:1626]   Expert 51 |    237 | GPU
DEBUG 01-15 10:09:28.662445.662445 lmp.py:1626]   Expert 59 |    241 | GPU
DEBUG 01-15 10:09:28.662062.662062 lmp.py:1626]   Expert  4 |    250 | GPU
DEBUG 01-15 10:09:28.662202.662202 lmp.py:1626]   Expert 55 |    262 | GPU
DEBUG 01-15 10:09:28.662343.662343 lmp.py:1626]   Expert 49 |    268 | GPU
DEBUG 01-15 10:09:28.662768.662768 lmp.py:1626]   Expert 29 |    277 | GPU
DEBUG 01-15 10:09:28.662192.662192 lmp.py:1626]   Expert 18 |    282 | GPU
DEBUG 01-15 10:09:28.662048.662048 lmp.py:1626]   Expert 34 |    282 | GPU
DEBUG 01-15 10:09:28.662427.662427 lmp.py:1626]   Expert 63 |    295 | GPU
DEBUG 01-15 10:09:28.662805.662805 lmp.py:1626]   Expert 27 |    357 | GPU
DEBUG 01-15 10:09:28.662230.662230 lmp.py:1626]   Expert 39 |    380 | GPU
DEBUG 01-15 10:09:28.662655.662655 lmp.py:1626]   Expert 17 |    392 | GPU
DEBUG 01-15 10:09:28.662841.662841 lmp.py:1626]   Expert 22 |    430 | GPU
DEBUG 01-15 10:09:28.662505.662505 lmp.py:1626]   Expert 33 |    453 | GPU
DEBUG 01-15 10:09:28.662883.662883 lmp.py:1626]   Expert 30 |    454 | GPU
DEBUG 01-15 10:09:28.662739.662739 lmp.py:1626]   Expert  5 |    710 | GPU
DEBUG 01-15 10:09:28.662548.662548 lmp.py:1627] 
DEBUG 01-15 10:09:28.662548.662548 lmp.py:1627]   CPU total tokens: 3445 (28.0%)
DEBUG 01-15 10:09:28.662357.662357 lmp.py:1628]   GPU total tokens: 8843 (72.0%)
DEBUG 01-15 10:09:28.663888.663888 cuda_h.py:19] end experts_map_get cost 0.0029191970825195312 seconds
DEBUG 01-15 10:09:28.663647.663647 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.663880.663880 lmp.py:1636] 
DEBUG 01-15 10:09:28.663880.663880 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.663007.663007 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-15 10:09:28.663942.663942 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.663600.663600 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.663362.663362 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.663628.663628 cuda_h.py:19] end allocate_cuda_memory cost 0.0001983642578125 seconds
DEBUG 01-15 10:09:28.663279.663279 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.663366.663366 sllm_store_c.py:27] get device uuid map
INFO 01-15 10:09:28.663403.663403 client.py:127] Model loaded
DEBUG 01-15 10:09:28.664171.664171 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.664295.664295 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cfff4975-de51-438c-8e05-6bfe3a0e6b89
DEBUG 01-15 10:09:28.664144.664144 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.665907.665907 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.666823.666823 cuda_h.py:19] end move_flatidxs cost 0.0009434223175048828 seconds
DEBUG 01-15 10:09:28.666686.666686 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.680296.680296 cuda_h.py:19] end group_tensors cost 0.014191627502441406 seconds
DEBUG 01-15 10:09:28.681441.681441 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.685174.685174 cuda_h.py:19] end group pad cost 0.003858804702758789 seconds
DEBUG 01-15 10:09:28.685832.685832 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.664320.664320 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.688005.688005 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.689930.689930 cuda_h.py:19] end restore2model cost 0.0011856555938720703 seconds
DEBUG 01-15 10:09:28.689743.689743 cuda_h.py:19] end sllm_worker_task cost 0.03926348686218262 seconds
INFO 01-15 10:09:28.691111.691111 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cfff4975-de51-438c-8e05-6bfe3a0e6b89
DEBUG 01-15 10:09:28.691385.691385 cuda_h.py:19] end load_into_gpu_async cost 0.027468442916870117 seconds
DEBUG 01-15 10:09:28.691803.691803 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.691135.691135 cuda_h.py:19] end restore_tensors2 cost 0.0006029605865478516 seconds
DEBUG 01-15 10:09:28.692628.692628 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.028716564178466797 seconds
DEBUG 01-15 10:09:28.692855.692855 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.695385.695385 cuda_h.py:19] end restore2model cost 0.0031206607818603516 seconds
DEBUG 01-15 10:09:28.695627.695627 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.032117366790771484 seconds
DEBUG 01-15 10:09:28.695860.695860 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.696209.696209 cuda_h.py:19] end gpu_sexperts cost 0.0006792545318603516 seconds
DEBUG 01-15 10:09:28.696336.696336 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.697714.697714 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0017528533935546875 seconds
DEBUG 01-15 10:09:28.698574.698574 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.699488.699488 cuda_h.py:19] end gpu_group_list cost 0.0003466606140136719 seconds
DEBUG 01-15 10:09:28.699358.699358 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.700084.700084 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010728836059570312 seconds
DEBUG 01-15 10:09:28.700821.700821 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.700447.700447 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 7.510185241699219e-05 seconds
DEBUG 01-15 10:09:28.700481.700481 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.704500.704500 cuda_h.py:19] end group_einsum cost 0.01947188377380371 seconds
DEBUG 01-15 10:09:28.704294.704294 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.709401.709401 cuda_h.py:19] end get_outputs_cpu1 cost 0.0043332576751708984 seconds
DEBUG 01-15 10:09:28.710916.710916 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.045087337493896484 seconds
DEBUG 01-15 10:09:28.710712.710712 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.010205507278442383 seconds
DEBUG 01-15 10:09:28.711960.711960 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.711053.711053 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.711421.711421 cuda_h.py:19] end index_scatter cost 8.130073547363281e-05 seconds
DEBUG 01-15 10:09:28.711216.711216 cuda_h.py:19] end cpuoutputsdeal cost 0.0008914470672607422 seconds
DEBUG 01-15 10:09:28.712231.712231 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.712709.712709 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cfff4975-de51-438c-8e05-6bfe3a0e6b89
INFO 01-15 10:09:28.741253.741253 client.py:127] Model loaded
DEBUG 01-15 10:09:28.741370.741370 cuda_h.py:19] end wait_experts cost 0.029443979263305664 seconds
DEBUG 01-15 10:09:28.741625.741625 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.741139.741139 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.741056.741056 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.742449.742449 cuda_h.py:19] end gpu_group_tensor cost 0.0003857612609863281 seconds
DEBUG 01-15 10:09:28.742476.742476 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.743836.743836 cuda_h.py:19] end gpu_group_einsum cost 0.0009279251098632812 seconds
DEBUG 01-15 10:09:28.743731.743731 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.743371.743371 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.744460.744460 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006000995635986328 seconds
DEBUG 01-15 10:09:28.744907.744907 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.744192.744192 cuda_h.py:19] end concat_expert_out cost 0.00013399124145507812 seconds
DEBUG 01-15 10:09:28.745389.745389 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.745098.745098 cuda_h.py:19] end index_scatter cost 0.00012087821960449219 seconds
DEBUG 01-15 10:09:28.745459.745459 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00145721435546875 seconds
DEBUG 01-15 10:09:28.745497.745497 cuda_h.py:19] end gpu_experts cost 0.0038352012634277344 seconds
DEBUG 01-15 10:09:28.745086.745086 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.0866847038269043 seconds
DEBUG 01-15 10:09:28.746372.746372 cuda_h.py:19] end prefill_layer cost 0.09691476821899414 seconds
DEBUG 01-15 10:09:28.746052.746052 lmp.py:1552] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-15 10:09:28.746286.746286 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.746858.746858 lmp.py:1495] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-15 10:09:28.746907.746907 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:28.746678.746678 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:28.747153.747153 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.341934204101562e-05 seconds
DEBUG 01-15 10:09:28.747023.747023 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00015163421630859375 seconds
DEBUG 01-15 10:09:28.747012.747012 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.747871.747871 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.747270.747270 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.747869.747869 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.747342.747342 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.748548.748548 cuda_h.py:19] end allocate_cuda_memory cost 0.0005033016204833984 seconds
DEBUG 01-15 10:09:28.748288.748288 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.748126.748126 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.748944.748944 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.749953.749953 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 237842d6-c76a-4267-895a-13be2f7cf733
DEBUG 01-15 10:09:28.749371.749371 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.749944.749944 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.750901.750901 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 237842d6-c76a-4267-895a-13be2f7cf733
DEBUG 01-15 10:09:28.750462.750462 cuda_h.py:19] end load_into_gpu_async cost 0.0017180442810058594 seconds
DEBUG 01-15 10:09:28.750133.750133 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.750260.750260 cuda_h.py:19] end restore_tensors2 cost 0.0001590251922607422 seconds
DEBUG 01-15 10:09:28.750905.750905 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003030061721801758 seconds
INFO 01-15 10:09:28.751785.751785 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 237842d6-c76a-4267-895a-13be2f7cf733
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.756640.756640 cuda_h.py:19] end self_attn cost 0.00620722770690918 seconds
DEBUG 01-15 10:09:28.756668.756668 cuda_h.py:19] end iln_self_attn_paln cost 0.009436607360839844 seconds
DEBUG 01-15 10:09:28.756737.756737 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-15 10:09:28.756858.756858 cuda_h.py:10] start gate
INFO 01-15 10:09:28.757042.757042 client.py:127] Model loaded
DEBUG 01-15 10:09:28.757292.757292 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.758027.758027 cuda_h.py:19] end restore2model cost 0.0010814666748046875 seconds
DEBUG 01-15 10:09:28.758166.758166 cuda_h.py:19] end sllm_worker_task cost 0.011260271072387695 seconds
DEBUG 01-15 10:09:28.759416.759416 cuda_h.py:19] end gate cost 0.0021791458129882812 seconds
DEBUG 01-15 10:09:28.759909.759909 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.759144.759144 lmp.py:1616] 
DEBUG 01-15 10:09:28.759144.759144 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.759835.759835 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.759697.759697 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.759075.759075 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.759785.759785 lmp.py:1620] 
DEBUG 01-15 10:09:28.759785.759785 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.759587.759587 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.759343.759343 lmp.py:1626]   Expert  5 |     15 | CPU
DEBUG 01-15 10:09:28.759669.759669 lmp.py:1626]   Expert 56 |     31 | CPU
DEBUG 01-15 10:09:28.759518.759518 lmp.py:1626]   Expert 27 |     84 | CPU
DEBUG 01-15 10:09:28.759651.759651 lmp.py:1626]   Expert 16 |     85 | CPU
DEBUG 01-15 10:09:28.759215.759215 lmp.py:1626]   Expert 17 |     90 | CPU
DEBUG 01-15 10:09:28.760732.760732 lmp.py:1626]   Expert 40 |     96 | CPU
DEBUG 01-15 10:09:28.760535.760535 lmp.py:1626]   Expert 63 |    100 | CPU
DEBUG 01-15 10:09:28.760430.760430 lmp.py:1626]   Expert 51 |    105 | CPU
DEBUG 01-15 10:09:28.760086.760086 lmp.py:1626]   Expert 53 |    106 | CPU
DEBUG 01-15 10:09:28.760981.760981 lmp.py:1626]   Expert 49 |    108 | CPU
DEBUG 01-15 10:09:28.760161.760161 lmp.py:1626]   Expert 28 |    110 | CPU
DEBUG 01-15 10:09:28.760579.760579 lmp.py:1626]   Expert  7 |    111 | CPU
DEBUG 01-15 10:09:28.760997.760997 lmp.py:1626]   Expert 47 |    120 | CPU
DEBUG 01-15 10:09:28.760084.760084 lmp.py:1626]   Expert 38 |    123 | CPU
DEBUG 01-15 10:09:28.760648.760648 lmp.py:1626]   Expert 37 |    126 | CPU
DEBUG 01-15 10:09:28.760305.760305 lmp.py:1626]   Expert 62 |    126 | CPU
DEBUG 01-15 10:09:28.760484.760484 lmp.py:1626]   Expert 11 |    128 | CPU
DEBUG 01-15 10:09:28.760426.760426 lmp.py:1626]   Expert 58 |    128 | CPU
DEBUG 01-15 10:09:28.760573.760573 lmp.py:1626]   Expert 57 |    137 | CPU
DEBUG 01-15 10:09:28.760660.760660 lmp.py:1626]   Expert 39 |    146 | CPU
DEBUG 01-15 10:09:28.760078.760078 lmp.py:1626]   Expert  1 |    148 | CPU
DEBUG 01-15 10:09:28.760973.760973 lmp.py:1626]   Expert 14 |    149 | CPU
DEBUG 01-15 10:09:28.760822.760822 lmp.py:1626]   Expert 52 |    153 | CPU
DEBUG 01-15 10:09:28.760147.760147 lmp.py:1626]   Expert 23 |    154 | CPU
DEBUG 01-15 10:09:28.760804.760804 lmp.py:1626]   Expert 25 |    156 | CPU
DEBUG 01-15 10:09:28.760222.760222 lmp.py:1626]   Expert 33 |    160 | CPU
DEBUG 01-15 10:09:28.760925.760925 lmp.py:1626]   Expert 21 |    167 | CPU
DEBUG 01-15 10:09:28.760343.760343 lmp.py:1626]   Expert  6 |    173 | CPU
DEBUG 01-15 10:09:28.760284.760284 lmp.py:1626]   Expert 60 |    173 | CPU
DEBUG 01-15 10:09:28.760941.760941 lmp.py:1626]   Expert 45 |    178 | CPU
DEBUG 01-15 10:09:28.760359.760359 lmp.py:1626]   Expert 19 |    180 | CPU
DEBUG 01-15 10:09:28.760207.760207 lmp.py:1626]   Expert 44 |    182 | CPU
DEBUG 01-15 10:09:28.760818.760818 lmp.py:1626]   Expert  4 |    184 | GPU
DEBUG 01-15 10:09:28.760474.760474 lmp.py:1626]   Expert 12 |    187 | GPU
DEBUG 01-15 10:09:28.760131.760131 lmp.py:1626]   Expert 30 |    191 | GPU
DEBUG 01-15 10:09:28.760549.760549 lmp.py:1626]   Expert 31 |    196 | GPU
DEBUG 01-15 10:09:28.760967.760967 lmp.py:1626]   Expert 55 |    198 | GPU
DEBUG 01-15 10:09:28.760624.760624 lmp.py:1626]   Expert  3 |    200 | GPU
DEBUG 01-15 10:09:28.760042.760042 lmp.py:1626]   Expert 36 |    201 | GPU
DEBUG 01-15 10:09:28.760937.760937 lmp.py:1626]   Expert  9 |    206 | GPU
DEBUG 01-15 10:09:28.761593.761593 lmp.py:1626]   Expert  0 |    219 | GPU
DEBUG 01-15 10:09:28.761680.761680 lmp.py:1626]   Expert 34 |    223 | GPU
DEBUG 01-15 10:09:28.761006.761006 lmp.py:1626]   Expert 22 |    224 | GPU
DEBUG 01-15 10:09:28.761424.761424 lmp.py:1626]   Expert 41 |    229 | GPU
DEBUG 01-15 10:09:28.761127.761127 lmp.py:1626]   Expert 54 |    234 | GPU
DEBUG 01-15 10:09:28.761306.761306 lmp.py:1626]   Expert 26 |    236 | GPU
DEBUG 01-15 10:09:28.761771.761771 lmp.py:1626]   Expert 43 |    240 | GPU
DEBUG 01-15 10:09:28.761143.761143 lmp.py:1626]   Expert 59 |    251 | GPU
DEBUG 01-15 10:09:28.761515.761515 lmp.py:1626]   Expert 18 |    252 | GPU
DEBUG 01-15 10:09:28.761125.761125 lmp.py:1626]   Expert 15 |    254 | GPU
DEBUG 01-15 10:09:28.761305.761305 lmp.py:1626]   Expert 13 |    255 | GPU
DEBUG 01-15 10:09:28.761769.761769 lmp.py:1626]   Expert 20 |    257 | GPU
DEBUG 01-15 10:09:28.761710.761710 lmp.py:1626]   Expert 50 |    258 | GPU
DEBUG 01-15 10:09:28.761413.761413 lmp.py:1626]   Expert 24 |    263 | GPU
DEBUG 01-15 10:09:28.761116.761116 lmp.py:1626]   Expert 29 |    267 | GPU
DEBUG 01-15 10:09:28.761249.761249 lmp.py:1626]   Expert 42 |    267 | GPU
DEBUG 01-15 10:09:28.761575.761575 lmp.py:1626]   Expert 61 |    267 | GPU
DEBUG 01-15 10:09:28.761424.761424 lmp.py:1626]   Expert 35 |    281 | GPU
DEBUG 01-15 10:09:28.761080.761080 lmp.py:1626]   Expert 32 |    309 | GPU
DEBUG 01-15 10:09:28.761021.761021 lmp.py:1626]   Expert 10 |    338 | GPU
DEBUG 01-15 10:09:28.761963.761963 lmp.py:1626]   Expert  2 |    339 | GPU
DEBUG 01-15 10:09:28.761904.761904 lmp.py:1626]   Expert  8 |    340 | GPU
DEBUG 01-15 10:09:28.761368.761368 lmp.py:1626]   Expert 46 |    426 | GPU
DEBUG 01-15 10:09:28.761740.761740 lmp.py:1626]   Expert 48 |    448 | GPU
DEBUG 01-15 10:09:28.761781.761781 lmp.py:1627] 
DEBUG 01-15 10:09:28.761781.761781 lmp.py:1627]   CPU total tokens: 4048 (32.9%)
DEBUG 01-15 10:09:28.761299.761299 lmp.py:1628]   GPU total tokens: 8240 (67.1%)
DEBUG 01-15 10:09:28.761585.761585 cuda_h.py:19] end experts_map_get cost 0.00252532958984375 seconds
DEBUG 01-15 10:09:28.761521.761521 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.761536.761536 lmp.py:1636] 
DEBUG 01-15 10:09:28.761536.761536 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.761791.761791 cuda_h.py:19] end cpu_experts_submit cost 8.106231689453125e-05 seconds
DEBUG 01-15 10:09:28.761600.761600 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.762199.762199 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.762115.762115 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.762470.762470 cuda_h.py:19] end allocate_cuda_memory cost 0.00027823448181152344 seconds
DEBUG 01-15 10:09:28.762109.762109 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.762124.762124 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.762867.762867 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.762445.762445 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 543afc14-c96a-4d02-ab45-4ec9043a785d
DEBUG 01-15 10:09:28.763859.763859 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.764326.764326 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:28.765971.765971 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 543afc14-c96a-4d02-ab45-4ec9043a785d
DEBUG 01-15 10:09:28.765676.765676 cuda_h.py:19] end load_into_gpu_async cost 0.002443552017211914 seconds
DEBUG 01-15 10:09:28.765709.765709 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.765495.765495 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.765367.765367 cuda_h.py:19] end restore_tensors2 cost 0.00042319297790527344 seconds
DEBUG 01-15 10:09:28.765203.765203 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003650188446044922 seconds
DEBUG 01-15 10:09:28.765595.765595 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.766792.766792 cuda_h.py:19] end move_flatidxs cost 0.0011856555938720703 seconds
DEBUG 01-15 10:09:28.766200.766200 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.768738.768738 cuda_h.py:19] end restore2model cost 0.0026400089263916016 seconds
DEBUG 01-15 10:09:28.768588.768588 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0065212249755859375 seconds
DEBUG 01-15 10:09:28.768429.768429 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.768068.768068 cuda_h.py:19] end gpu_sexperts cost 0.00026607513427734375 seconds
DEBUG 01-15 10:09:28.768090.768090 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.770029.770029 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001489877700805664 seconds
DEBUG 01-15 10:09:28.771651.771651 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.771367.771367 cuda_h.py:19] end gpu_group_list cost 0.00037550926208496094 seconds
DEBUG 01-15 10:09:28.771377.771377 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.772416.772416 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007269382476806641 seconds
DEBUG 01-15 10:09:28.772146.772146 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.772969.772969 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-15 10:09:28.772665.772665 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.782008.782008 cuda_h.py:19] end group_tensors cost 0.01575160026550293 seconds
DEBUG 01-15 10:09:28.783359.783359 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.787577.787577 cuda_h.py:19] end group pad cost 0.004075288772583008 seconds
DEBUG 01-15 10:09:28.787797.787797 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.807733.807733 cuda_h.py:19] end group_einsum cost 0.01995229721069336 seconds
DEBUG 01-15 10:09:28.807573.807573 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.812022.812022 cuda_h.py:19] end get_outputs_cpu1 cost 0.0048215389251708984 seconds
DEBUG 01-15 10:09:28.813744.813744 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.048708200454711914 seconds
DEBUG 01-15 10:09:28.814835.814835 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.041787147521972656 seconds
DEBUG 01-15 10:09:28.814836.814836 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.815839.815839 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.815087.815087 cuda_h.py:19] end index_scatter cost 0.0001659393310546875 seconds
DEBUG 01-15 10:09:28.816449.816449 cuda_h.py:19] end cpuoutputsdeal cost 0.0011873245239257812 seconds
DEBUG 01-15 10:09:28.816459.816459 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.816866.816866 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 543afc14-c96a-4d02-ab45-4ec9043a785d
INFO 01-15 10:09:28.817895.817895 client.py:127] Model loaded
DEBUG 01-15 10:09:28.817131.817131 cuda_h.py:19] end wait_experts cost 0.0013968944549560547 seconds
DEBUG 01-15 10:09:28.817087.817087 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.817907.817907 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.817346.817346 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.818918.818918 cuda_h.py:19] end gpu_group_tensor cost 0.00037932395935058594 seconds
DEBUG 01-15 10:09:28.818522.818522 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.819366.819366 cuda_h.py:19] end gpu_group_einsum cost 0.0011756420135498047 seconds
DEBUG 01-15 10:09:28.820183.820183 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.820399.820399 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.820773.820773 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006163120269775391 seconds
DEBUG 01-15 10:09:28.821028.821028 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.821359.821359 cuda_h.py:19] end concat_expert_out cost 0.00013256072998046875 seconds
DEBUG 01-15 10:09:28.821126.821126 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.821927.821927 cuda_h.py:19] end index_scatter cost 0.00011801719665527344 seconds
DEBUG 01-15 10:09:28.821811.821811 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001451253890991211 seconds
DEBUG 01-15 10:09:28.821664.821664 cuda_h.py:19] end gpu_experts cost 0.004111051559448242 seconds
DEBUG 01-15 10:09:28.822777.822777 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06520986557006836 seconds
DEBUG 01-15 10:09:28.822890.822890 cuda_h.py:19] end prefill_layer cost 0.07610368728637695 seconds
DEBUG 01-15 10:09:28.823967.823967 lmp.py:1552] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-15 10:09:28.823201.823201 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.823773.823773 lmp.py:1495] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-15 10:09:28.823676.823676 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:28.823970.823970 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:28.823121.823121 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:28.823792.823792 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00015282630920410156 seconds
DEBUG 01-15 10:09:28.823304.823304 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.823628.823628 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.823918.823918 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.824269.824269 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.824174.824174 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.824623.824623 cuda_h.py:19] end allocate_cuda_memory cost 0.0004439353942871094 seconds
DEBUG 01-15 10:09:28.824741.824741 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.825479.825479 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.825628.825628 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.825684.825684 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81880dc7-9353-458c-b6af-ad80eca8da31
DEBUG 01-15 10:09:28.825055.825055 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.826740.826740 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.826260.826260 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81880dc7-9353-458c-b6af-ad80eca8da31
DEBUG 01-15 10:09:28.826419.826419 cuda_h.py:19] end load_into_gpu_async cost 0.0015587806701660156 seconds
DEBUG 01-15 10:09:28.826959.826959 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.826239.826239 cuda_h.py:19] end restore_tensors2 cost 0.00015926361083984375 seconds
DEBUG 01-15 10:09:28.827501.827501 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002886533737182617 seconds
INFO 01-15 10:09:28.827885.827885 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81880dc7-9353-458c-b6af-ad80eca8da31
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.831495.831495 cuda_h.py:19] end self_attn cost 0.005028724670410156 seconds
DEBUG 01-15 10:09:28.831483.831483 cuda_h.py:19] end iln_self_attn_paln cost 0.00803375244140625 seconds
DEBUG 01-15 10:09:28.831260.831260 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-15 10:09:28.831090.831090 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.832576.832576 cuda_h.py:19] end gate cost 0.0008358955383300781 seconds
DEBUG 01-15 10:09:28.832002.832002 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.833495.833495 lmp.py:1616] 
DEBUG 01-15 10:09:28.833495.833495 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.833278.833278 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.833286.833286 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.833188.833188 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.833182.833182 lmp.py:1620] 
DEBUG 01-15 10:09:28.833182.833182 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.833461.833461 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.833410.833410 lmp.py:1626]   Expert 36 |     21 | CPU
DEBUG 01-15 10:09:28.833973.833973 lmp.py:1626]   Expert 35 |     28 | CPU
DEBUG 01-15 10:09:28.833822.833822 lmp.py:1626]   Expert 25 |     44 | CPU
DEBUG 01-15 10:09:28.833432.833432 lmp.py:1626]   Expert 46 |     49 | CPU
DEBUG 01-15 10:09:28.833804.833804 lmp.py:1626]   Expert 51 |     52 | CPU
DEBUG 01-15 10:09:28.833414.833414 lmp.py:1626]   Expert 30 |     60 | CPU
DEBUG 01-15 10:09:28.833786.833786 lmp.py:1626]   Expert 16 |     63 | CPU
DEBUG 01-15 10:09:28.833396.833396 lmp.py:1626]   Expert  0 |     64 | CPU
DEBUG 01-15 10:09:28.833007.833007 lmp.py:1626]   Expert 43 |     68 | CPU
DEBUG 01-15 10:09:28.833684.833684 lmp.py:1626]   Expert 47 |     72 | CPU
DEBUG 01-15 10:09:28.833247.833247 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:28.833858.833858 lmp.py:1626]   Expert 44 |     73 | CPU
DEBUG 01-15 10:09:28.833468.833468 lmp.py:1626]   Expert 39 |     76 | CPU
DEBUG 01-15 10:09:28.833078.833078 lmp.py:1626]   Expert 42 |     76 | CPU
DEBUG 01-15 10:09:28.833212.833212 lmp.py:1626]   Expert  2 |     85 | CPU
DEBUG 01-15 10:09:28.833822.833822 lmp.py:1626]   Expert  4 |    109 | CPU
DEBUG 01-15 10:09:28.833955.833955 lmp.py:1626]   Expert 33 |    118 | CPU
DEBUG 01-15 10:09:28.833089.833089 lmp.py:1626]   Expert  6 |    122 | CPU
DEBUG 01-15 10:09:28.833520.833520 lmp.py:1626]   Expert 61 |    123 | CPU
DEBUG 01-15 10:09:28.834561.834561 lmp.py:1626]   Expert 48 |    124 | CPU
DEBUG 01-15 10:09:28.834886.834886 lmp.py:1626]   Expert 13 |    125 | CPU
DEBUG 01-15 10:09:28.834020.834020 lmp.py:1626]   Expert 24 |    126 | CPU
DEBUG 01-15 10:09:28.834676.834676 lmp.py:1626]   Expert 56 |    131 | CPU
DEBUG 01-15 10:09:28.834571.834571 lmp.py:1626]   Expert 15 |    132 | CPU
DEBUG 01-15 10:09:28.834466.834466 lmp.py:1626]   Expert 38 |    137 | CPU
DEBUG 01-15 10:09:28.834361.834361 lmp.py:1626]   Expert 29 |    139 | CPU
DEBUG 01-15 10:09:28.834733.834733 lmp.py:1626]   Expert 54 |    140 | CPU
DEBUG 01-15 10:09:28.834343.834343 lmp.py:1626]   Expert  9 |    141 | CPU
DEBUG 01-15 10:09:28.834430.834430 lmp.py:1626]   Expert 20 |    141 | CPU
DEBUG 01-15 10:09:28.834564.834564 lmp.py:1626]   Expert  7 |    144 | CPU
DEBUG 01-15 10:09:28.834459.834459 lmp.py:1626]   Expert 59 |    149 | CPU
DEBUG 01-15 10:09:28.834354.834354 lmp.py:1626]   Expert 62 |    155 | CPU
DEBUG 01-15 10:09:28.834010.834010 lmp.py:1626]   Expert 45 |    157 | GPU
DEBUG 01-15 10:09:28.834905.834905 lmp.py:1626]   Expert 19 |    160 | GPU
DEBUG 01-15 10:09:28.834562.834562 lmp.py:1626]   Expert 34 |    188 | GPU
DEBUG 01-15 10:09:28.834980.834980 lmp.py:1626]   Expert 50 |    189 | GPU
DEBUG 01-15 10:09:28.834306.834306 lmp.py:1626]   Expert 57 |    191 | GPU
DEBUG 01-15 10:09:28.834154.834154 lmp.py:1626]   Expert 10 |    203 | GPU
DEBUG 01-15 10:09:28.834003.834003 lmp.py:1626]   Expert 31 |    203 | GPU
DEBUG 01-15 10:09:28.834136.834136 lmp.py:1626]   Expert 23 |    204 | GPU
DEBUG 01-15 10:09:28.834793.834793 lmp.py:1626]   Expert 60 |    213 | GPU
DEBUG 01-15 10:09:28.834403.834403 lmp.py:1626]   Expert  8 |    214 | GPU
DEBUG 01-15 10:09:28.834298.834298 lmp.py:1626]   Expert 18 |    216 | GPU
DEBUG 01-15 10:09:28.834193.834193 lmp.py:1626]   Expert 22 |    221 | GPU
DEBUG 01-15 10:09:28.834565.834565 lmp.py:1626]   Expert 53 |    223 | GPU
DEBUG 01-15 10:09:28.834175.834175 lmp.py:1626]   Expert 52 |    227 | GPU
DEBUG 01-15 10:09:28.834024.834024 lmp.py:1626]   Expert 37 |    230 | GPU
DEBUG 01-15 10:09:28.834634.834634 lmp.py:1626]   Expert  5 |    241 | GPU
DEBUG 01-15 10:09:28.834290.834290 lmp.py:1626]   Expert 17 |    245 | GPU
DEBUG 01-15 10:09:28.834709.834709 lmp.py:1626]   Expert 11 |    253 | GPU
DEBUG 01-15 10:09:28.834842.834842 lmp.py:1626]   Expert  1 |    270 | GPU
DEBUG 01-15 10:09:28.834737.834737 lmp.py:1626]   Expert 49 |    277 | GPU
DEBUG 01-15 10:09:28.834824.834824 lmp.py:1626]   Expert 41 |    283 | GPU
DEBUG 01-15 10:09:28.834673.834673 lmp.py:1626]   Expert 28 |    288 | GPU
DEBUG 01-15 10:09:28.835760.835760 lmp.py:1626]   Expert 26 |    291 | GPU
DEBUG 01-15 10:09:28.835655.835655 lmp.py:1626]   Expert 32 |    291 | GPU
DEBUG 01-15 10:09:28.835311.835311 lmp.py:1626]   Expert 58 |    299 | GPU
DEBUG 01-15 10:09:28.835968.835968 lmp.py:1626]   Expert 40 |    303 | GPU
DEBUG 01-15 10:09:28.835101.835101 lmp.py:1626]   Expert 14 |    311 | GPU
DEBUG 01-15 10:09:28.835427.835427 lmp.py:1626]   Expert 12 |    330 | GPU
DEBUG 01-15 10:09:28.835514.835514 lmp.py:1626]   Expert 63 |    338 | GPU
DEBUG 01-15 10:09:28.835409.835409 lmp.py:1626]   Expert 21 |    382 | GPU
DEBUG 01-15 10:09:28.835827.835827 lmp.py:1626]   Expert 27 |    670 | GPU
DEBUG 01-15 10:09:28.835722.835722 lmp.py:1626]   Expert  3 |   1018 | GPU
DEBUG 01-15 10:09:28.835809.835809 lmp.py:1627] 
DEBUG 01-15 10:09:28.835809.835809 lmp.py:1627]   CPU total tokens: 3159 (25.7%)
DEBUG 01-15 10:09:28.835850.835850 lmp.py:1628]   GPU total tokens: 9129 (74.3%)
DEBUG 01-15 10:09:28.835089.835089 cuda_h.py:19] end experts_map_get cost 0.0025472640991210938 seconds
DEBUG 01-15 10:09:28.835457.835457 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.835471.835471 lmp.py:1636] 
DEBUG 01-15 10:09:28.835471.835471 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.835388.835388 cuda_h.py:19] end cpu_experts_submit cost 7.82012939453125e-05 seconds
DEBUG 01-15 10:09:28.835197.835197 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.836696.836696 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.836982.836982 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.836427.836427 cuda_h.py:19] end allocate_cuda_memory cost 0.00022125244140625 seconds
DEBUG 01-15 10:09:28.836655.836655 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.836934.836934 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.836548.836548 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.836286.836286 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.836228.836228 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f3a07627-db8a-4f45-92a2-9e04713a358a
DEBUG 01-15 10:09:28.836394.836394 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.836487.836487 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:28.837230.837230 client.py:127] Model loaded
DEBUG 01-15 10:09:28.837353.837353 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.837036.837036 cuda_h.py:19] end move_flatidxs cost 0.0008950233459472656 seconds
DEBUG 01-15 10:09:28.837256.837256 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.838019.838019 cuda_h.py:19] end restore2model cost 0.0009984970092773438 seconds
INFO 01-15 10:09:28.838003.838003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f3a07627-db8a-4f45-92a2-9e04713a358a
DEBUG 01-15 10:09:28.838801.838801 cuda_h.py:19] end sllm_worker_task cost 0.014518022537231445 seconds
DEBUG 01-15 10:09:28.838844.838844 cuda_h.py:19] end load_into_gpu_async cost 0.002069711685180664 seconds
DEBUG 01-15 10:09:28.838596.838596 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.839624.839624 cuda_h.py:19] end restore_tensors2 cost 0.0004150867462158203 seconds
DEBUG 01-15 10:09:28.839222.839222 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031952857971191406 seconds
DEBUG 01-15 10:09:28.839660.839660 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.841575.841575 cuda_h.py:19] end restore2model cost 0.002576589584350586 seconds
DEBUG 01-15 10:09:28.842796.842796 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00598597526550293 seconds
DEBUG 01-15 10:09:28.842638.842638 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.842151.842151 cuda_h.py:19] end gpu_sexperts cost 0.00027823448181152344 seconds
DEBUG 01-15 10:09:28.842266.842266 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.843813.843813 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014939308166503906 seconds
DEBUG 01-15 10:09:28.844429.844429 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.845601.845601 cuda_h.py:19] end gpu_group_list cost 0.0003597736358642578 seconds
DEBUG 01-15 10:09:28.845565.845565 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.845345.845345 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007116794586181641 seconds
DEBUG 01-15 10:09:28.846353.846353 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.846507.846507 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-15 10:09:28.846203.846203 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.847465.847465 cuda_h.py:19] end group_tensors cost 0.009942770004272461 seconds
DEBUG 01-15 10:09:28.848326.848326 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.852134.852134 cuda_h.py:19] end group pad cost 0.0037021636962890625 seconds
DEBUG 01-15 10:09:28.852746.852746 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.871874.871874 cuda_h.py:19] end group_einsum cost 0.018355607986450195 seconds
DEBUG 01-15 10:09:28.871647.871647 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.875565.875565 cuda_h.py:19] end get_outputs_cpu1 cost 0.0046160221099853516 seconds
DEBUG 01-15 10:09:28.876811.876811 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03999829292297363 seconds
DEBUG 01-15 10:09:28.878964.878964 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0319366455078125 seconds
DEBUG 01-15 10:09:28.878495.878495 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.878829.878829 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.879362.879362 cuda_h.py:19] end index_scatter cost 0.0001678466796875 seconds
DEBUG 01-15 10:09:28.880909.880909 cuda_h.py:19] end cpuoutputsdeal cost 0.0016067028045654297 seconds
DEBUG 01-15 10:09:28.880927.880927 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.880671.880671 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f3a07627-db8a-4f45-92a2-9e04713a358a
INFO 01-15 10:09:28.888355.888355 client.py:127] Model loaded
DEBUG 01-15 10:09:28.888545.888545 cuda_h.py:19] end wait_experts cost 0.008692026138305664 seconds
DEBUG 01-15 10:09:28.888031.888031 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.889460.889460 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.889754.889754 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.889399.889399 cuda_h.py:19] end gpu_group_tensor cost 0.0003962516784667969 seconds
DEBUG 01-15 10:09:28.889625.889625 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.891416.891416 cuda_h.py:19] end gpu_group_einsum cost 0.0009636878967285156 seconds
DEBUG 01-15 10:09:28.891987.891987 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.891058.891058 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.892491.892491 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005893707275390625 seconds
DEBUG 01-15 10:09:28.892646.892646 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.892070.892070 cuda_h.py:19] end concat_expert_out cost 0.00013017654418945312 seconds
DEBUG 01-15 10:09:28.892261.892261 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.892275.892275 cuda_h.py:19] end index_scatter cost 0.0001316070556640625 seconds
DEBUG 01-15 10:09:28.892589.892589 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014693737030029297 seconds
DEBUG 01-15 10:09:28.892635.892635 cuda_h.py:19] end gpu_experts cost 0.003916740417480469 seconds
DEBUG 01-15 10:09:28.893701.893701 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.061365365982055664 seconds
DEBUG 01-15 10:09:28.894610.894610 cuda_h.py:19] end prefill_layer cost 0.07086825370788574 seconds
DEBUG 01-15 10:09:28.894442.894442 lmp.py:1552] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-15 10:09:28.894245.894245 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.894672.894672 lmp.py:1495] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-15 10:09:28.894859.894859 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:28.894153.894153 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:28.894211.894211 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.67572021484375e-05 seconds
DEBUG 01-15 10:09:28.894267.894267 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.00015544891357421875 seconds
DEBUG 01-15 10:09:28.894494.894494 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.894559.894559 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.895009.895009 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.895775.895775 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.895404.895404 cuda_h.py:19] end allocate_cuda_memory cost 0.0004696846008300781 seconds
DEBUG 01-15 10:09:28.895614.895614 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.896306.896306 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.896740.896740 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.896319.896319 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5231b94d-1661-47a7-9583-f9bea31b4c79
DEBUG 01-15 10:09:28.896101.896101 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.896138.896138 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.897592.897592 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.898678.898678 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5231b94d-1661-47a7-9583-f9bea31b4c79
DEBUG 01-15 10:09:28.898623.898623 cuda_h.py:19] end load_into_gpu_async cost 0.002161264419555664 seconds
DEBUG 01-15 10:09:28.898533.898533 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.898130.898130 cuda_h.py:19] end restore_tensors2 cost 0.00015401840209960938 seconds
DEBUG 01-15 10:09:28.898856.898856 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034422874450683594 seconds
INFO 01-15 10:09:28.898888.898888 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5231b94d-1661-47a7-9583-f9bea31b4c79
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.902420.902420 cuda_h.py:19] end self_attn cost 0.005645275115966797 seconds
DEBUG 01-15 10:09:28.903768.903768 cuda_h.py:19] end iln_self_attn_paln cost 0.008694648742675781 seconds
DEBUG 01-15 10:09:28.903049.903049 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-15 10:09:28.903667.903667 cuda_h.py:10] start gate
DEBUG 01-15 10:09:28.904311.904311 cuda_h.py:19] end gate cost 0.0009703636169433594 seconds
DEBUG 01-15 10:09:28.904857.904857 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.905486.905486 lmp.py:1616] 
DEBUG 01-15 10:09:28.905486.905486 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.905998.905998 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.905728.905728 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.905451.905451 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.905644.905644 lmp.py:1620] 
DEBUG 01-15 10:09:28.905644.905644 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.905791.905791 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.905322.905322 lmp.py:1626]   Expert 13 |     26 | CPU
DEBUG 01-15 10:09:28.905708.905708 lmp.py:1626]   Expert 44 |     39 | CPU
DEBUG 01-15 10:09:28.905901.905901 lmp.py:1626]   Expert  9 |     42 | CPU
DEBUG 01-15 10:09:28.905379.905379 lmp.py:1626]   Expert 25 |     43 | CPU
DEBUG 01-15 10:09:28.905142.905142 lmp.py:1626]   Expert 16 |     45 | CPU
DEBUG 01-15 10:09:28.905812.905812 lmp.py:1626]   Expert 38 |     46 | CPU
DEBUG 01-15 10:09:28.905005.905005 lmp.py:1626]   Expert  2 |     52 | CPU
DEBUG 01-15 10:09:28.905199.905199 lmp.py:1626]   Expert 22 |     52 | CPU
DEBUG 01-15 10:09:28.905961.905961 lmp.py:1626]   Expert 33 |     56 | CPU
DEBUG 01-15 10:09:28.905393.905393 lmp.py:1626]   Expert 42 |     62 | CPU
DEBUG 01-15 10:09:28.905348.905348 lmp.py:1626]   Expert  5 |     69 | CPU
DEBUG 01-15 10:09:28.906018.906018 lmp.py:1626]   Expert 23 |     76 | CPU
DEBUG 01-15 10:09:28.906688.906688 lmp.py:1626]   Expert 24 |     79 | CPU
DEBUG 01-15 10:09:28.906405.906405 lmp.py:1626]   Expert 10 |     87 | CPU
DEBUG 01-15 10:09:28.906406.906406 lmp.py:1626]   Expert 59 |    101 | CPU
DEBUG 01-15 10:09:28.906599.906599 lmp.py:1626]   Expert 21 |    107 | CPU
DEBUG 01-15 10:09:28.906839.906839 lmp.py:1626]   Expert 46 |    112 | CPU
DEBUG 01-15 10:09:28.906555.906555 lmp.py:1626]   Expert 45 |    116 | CPU
DEBUG 01-15 10:09:28.906080.906080 lmp.py:1626]   Expert 55 |    116 | CPU
DEBUG 01-15 10:09:28.906604.906604 lmp.py:1626]   Expert 61 |    124 | CPU
DEBUG 01-15 10:09:28.906844.906844 lmp.py:1626]   Expert 31 |    128 | CPU
DEBUG 01-15 10:09:28.906322.906322 lmp.py:1626]   Expert  6 |    138 | CPU
DEBUG 01-15 10:09:28.906277.906277 lmp.py:1626]   Expert 51 |    139 | CPU
DEBUG 01-15 10:09:28.906993.906993 lmp.py:1626]   Expert 36 |    143 | CPU
DEBUG 01-15 10:09:28.906425.906425 lmp.py:1626]   Expert  8 |    144 | CPU
DEBUG 01-15 10:09:28.906591.906591 lmp.py:1626]   Expert 43 |    145 | CPU
DEBUG 01-15 10:09:28.906472.906472 lmp.py:1626]   Expert  3 |    149 | CPU
DEBUG 01-15 10:09:28.906877.906877 lmp.py:1626]   Expert  0 |    152 | CPU
DEBUG 01-15 10:09:28.906043.906043 lmp.py:1626]   Expert 26 |    159 | CPU
DEBUG 01-15 10:09:28.906401.906401 lmp.py:1626]   Expert 48 |    160 | CPU
DEBUG 01-15 10:09:28.906998.906998 lmp.py:1626]   Expert 18 |    161 | CPU
DEBUG 01-15 10:09:28.906595.906595 lmp.py:1626]   Expert 41 |    167 | CPU
DEBUG 01-15 10:09:28.906668.906668 lmp.py:1626]   Expert 12 |    177 | GPU
DEBUG 01-15 10:09:28.906265.906265 lmp.py:1626]   Expert  7 |    180 | GPU
DEBUG 01-15 10:09:28.906385.906385 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:28.906028.906028 lmp.py:1626]   Expert 56 |    188 | GPU
DEBUG 01-15 10:09:28.906909.906909 lmp.py:1626]   Expert 28 |    189 | GPU
DEBUG 01-15 10:09:28.906790.906790 lmp.py:1626]   Expert 27 |    192 | GPU
DEBUG 01-15 10:09:28.906877.906877 lmp.py:1626]   Expert 34 |    193 | GPU
DEBUG 01-15 10:09:28.906236.906236 lmp.py:1626]   Expert  1 |    200 | GPU
DEBUG 01-15 10:09:28.906355.906355 lmp.py:1626]   Expert 47 |    202 | GPU
DEBUG 01-15 10:09:28.906475.906475 lmp.py:1626]   Expert 32 |    213 | GPU
DEBUG 01-15 10:09:28.906072.906072 lmp.py:1626]   Expert 11 |    214 | GPU
DEBUG 01-15 10:09:28.906907.906907 lmp.py:1626]   Expert 40 |    228 | GPU
DEBUG 01-15 10:09:28.906788.906788 lmp.py:1626]   Expert 49 |    234 | GPU
DEBUG 01-15 10:09:28.906431.906431 lmp.py:1626]   Expert 53 |    235 | GPU
DEBUG 01-15 10:09:28.906836.906836 lmp.py:1626]   Expert 63 |    241 | GPU
DEBUG 01-15 10:09:28.906479.906479 lmp.py:1626]   Expert 29 |    244 | GPU
DEBUG 01-15 10:09:28.906122.906122 lmp.py:1626]   Expert 15 |    245 | GPU
DEBUG 01-15 10:09:28.906765.906765 lmp.py:1626]   Expert  4 |    247 | GPU
DEBUG 01-15 10:09:28.906408.906408 lmp.py:1626]   Expert 50 |    249 | GPU
DEBUG 01-15 10:09:28.906051.906051 lmp.py:1626]   Expert 30 |    250 | GPU
DEBUG 01-15 10:09:28.907171.907171 lmp.py:1626]   Expert 35 |    272 | GPU
DEBUG 01-15 10:09:28.907767.907767 lmp.py:1626]   Expert 14 |    273 | GPU
INFO 01-15 10:09:28.907745.907745 client.py:127] Model loaded
DEBUG 01-15 10:09:28.907755.907755 lmp.py:1626]   Expert 37 |    301 | GPU
DEBUG 01-15 10:09:28.907903.907903 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.907203.907203 lmp.py:1626]   Expert 52 |    338 | GPU
DEBUG 01-15 10:09:28.907270.907270 lmp.py:1626]   Expert 17 |    361 | GPU
DEBUG 01-15 10:09:28.907059.907059 lmp.py:1626]   Expert 54 |    376 | GPU
DEBUG 01-15 10:09:28.907179.907179 lmp.py:1626]   Expert 39 |    390 | GPU
DEBUG 01-15 10:09:28.907252.907252 lmp.py:1626]   Expert 57 |    410 | GPU
DEBUG 01-15 10:09:28.907610.907610 lmp.py:1626]   Expert 60 |    458 | GPU
DEBUG 01-15 10:09:28.907445.907445 lmp.py:1626]   Expert 62 |    458 | GPU
DEBUG 01-15 10:09:28.907281.907281 lmp.py:1626]   Expert 19 |    543 | GPU
DEBUG 01-15 10:09:28.907400.907400 lmp.py:1626]   Expert 58 |    570 | GPU
DEBUG 01-15 10:09:28.907474.907474 lmp.py:1627] 
DEBUG 01-15 10:09:28.907474.907474 lmp.py:1627]   CPU total tokens: 3235 (26.3%)
DEBUG 01-15 10:09:28.907309.907309 lmp.py:1628]   GPU total tokens: 9053 (73.7%)
DEBUG 01-15 10:09:28.907866.907866 cuda_h.py:19] end experts_map_get cost 0.0029747486114501953 seconds
DEBUG 01-15 10:09:28.907142.907142 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.907335.907335 lmp.py:1636] 
DEBUG 01-15 10:09:28.907335.907335 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.908370.908370 cuda_h.py:19] end cpu_experts_submit cost 6.031990051269531e-05 seconds
DEBUG 01-15 10:09:28.908735.908735 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.908340.908340 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.908691.908691 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.908620.908620 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-15 10:09:28.908516.908516 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.908511.908511 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.908280.908280 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.908030.908030 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7b4a7c1d-a7d6-4bfe-83a3-58a9c6cce256
DEBUG 01-15 10:09:28.908911.908911 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.909218.909218 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:28.910369.910369 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.910785.910785 cuda_h.py:19] end restore2model cost 0.002853870391845703 seconds
DEBUG 01-15 10:09:28.910944.910944 cuda_h.py:19] end sllm_worker_task cost 0.015487194061279297 seconds
INFO 01-15 10:09:28.910665.910665 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7b4a7c1d-a7d6-4bfe-83a3-58a9c6cce256
DEBUG 01-15 10:09:28.910091.910091 cuda_h.py:19] end load_into_gpu_async cost 0.0021097660064697266 seconds
DEBUG 01-15 10:09:28.910940.910940 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.911915.911915 cuda_h.py:19] end restore_tensors2 cost 0.0004127025604248047 seconds
DEBUG 01-15 10:09:28.911606.911606 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031549930572509766 seconds
DEBUG 01-15 10:09:28.911144.911144 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.911548.911548 cuda_h.py:19] end move_flatidxs cost 0.0009343624114990234 seconds
DEBUG 01-15 10:09:28.911583.911583 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.914610.914610 cuda_h.py:19] end restore2model cost 0.0026311874389648438 seconds
DEBUG 01-15 10:09:28.914168.914168 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005984306335449219 seconds
DEBUG 01-15 10:09:28.914461.914461 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.914121.914121 cuda_h.py:19] end gpu_sexperts cost 0.0002796649932861328 seconds
DEBUG 01-15 10:09:28.914188.914188 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.915061.915061 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001486063003540039 seconds
DEBUG 01-15 10:09:28.916961.916961 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.917795.917795 cuda_h.py:19] end gpu_group_list cost 0.00035262107849121094 seconds
DEBUG 01-15 10:09:28.917243.917243 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.918136.918136 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007233619689941406 seconds
DEBUG 01-15 10:09:28.918482.918482 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.918305.918305 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-15 10:09:28.918478.918478 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.922345.922345 cuda_h.py:19] end group_tensors cost 0.010836362838745117 seconds
DEBUG 01-15 10:09:28.923190.923190 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:28.927561.927561 cuda_h.py:19] end group pad cost 0.003894805908203125 seconds
DEBUG 01-15 10:09:28.927973.927973 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:28.947115.947115 cuda_h.py:19] end group_einsum cost 0.020340442657470703 seconds
DEBUG 01-15 10:09:28.947934.947934 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:28.952757.952757 cuda_h.py:19] end get_outputs_cpu1 cost 0.004340410232543945 seconds
DEBUG 01-15 10:09:28.953234.953234 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04294443130493164 seconds
DEBUG 01-15 10:09:28.953768.953768 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03570389747619629 seconds
DEBUG 01-15 10:09:28.954788.954788 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:28.954604.954604 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.954612.954612 cuda_h.py:19] end index_scatter cost 0.000148773193359375 seconds
DEBUG 01-15 10:09:28.955160.955160 cuda_h.py:19] end cpuoutputsdeal cost 0.0011374950408935547 seconds
DEBUG 01-15 10:09:28.955528.955528 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:28.955060.955060 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7b4a7c1d-a7d6-4bfe-83a3-58a9c6cce256
INFO 01-15 10:09:28.961394.961394 client.py:127] Model loaded
DEBUG 01-15 10:09:28.961961.961961 cuda_h.py:19] end wait_experts cost 0.005760669708251953 seconds
DEBUG 01-15 10:09:28.961109.961109 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:28.961339.961339 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:28.961156.961156 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:28.962443.962443 cuda_h.py:19] end gpu_group_tensor cost 0.00037741661071777344 seconds
DEBUG 01-15 10:09:28.962855.962855 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:28.963555.963555 cuda_h.py:19] end gpu_group_einsum cost 0.0012094974517822266 seconds
DEBUG 01-15 10:09:28.963748.963748 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:28.963634.963634 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:28.964572.964572 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006422996520996094 seconds
DEBUG 01-15 10:09:28.964018.964018 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:28.964403.964403 cuda_h.py:19] end concat_expert_out cost 0.00013446807861328125 seconds
DEBUG 01-15 10:09:28.965792.965792 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:28.965693.965693 cuda_h.py:19] end index_scatter cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:28.965338.965338 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014927387237548828 seconds
DEBUG 01-15 10:09:28.965768.965768 cuda_h.py:19] end gpu_experts cost 0.004170656204223633 seconds
DEBUG 01-15 10:09:28.965211.965211 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.062127113342285156 seconds
DEBUG 01-15 10:09:28.966531.966531 cuda_h.py:19] end prefill_layer cost 0.07232284545898438 seconds
DEBUG 01-15 10:09:28.966700.966700 lmp.py:1552] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-15 10:09:28.966888.966888 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:28.966791.966791 lmp.py:1495] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-15 10:09:28.966025.966025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:28.966292.966292 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:28.967441.967441 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.316734313964844e-05 seconds
DEBUG 01-15 10:09:28.967470.967470 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.00011920928955078125 seconds
DEBUG 01-15 10:09:28.967100.967100 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:28.967349.967349 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:28.967077.967077 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.967929.967929 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.968755.968755 cuda_h.py:19] end allocate_cuda_memory cost 0.0004398822784423828 seconds
DEBUG 01-15 10:09:28.968828.968828 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:28.968229.968229 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.968561.968561 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.968022.968022 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.968270.968270 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 23a70a49-6ed6-4a43-bf2a-f041e9beb5c6
DEBUG 01-15 10:09:28.969953.969953 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.969810.969810 cuda_h.py:10] start self_attn
INFO 01-15 10:09:28.970929.970929 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 23a70a49-6ed6-4a43-bf2a-f041e9beb5c6
DEBUG 01-15 10:09:28.970682.970682 cuda_h.py:19] end load_into_gpu_async cost 0.0016324520111083984 seconds
DEBUG 01-15 10:09:28.970161.970161 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.970281.970281 cuda_h.py:19] end restore_tensors2 cost 0.00015282630920410156 seconds
DEBUG 01-15 10:09:28.970258.970258 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003130674362182617 seconds
INFO 01-15 10:09:28.970402.970402 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 23a70a49-6ed6-4a43-bf2a-f041e9beb5c6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:28.975108.975108 cuda_h.py:19] end self_attn cost 0.006006002426147461 seconds
DEBUG 01-15 10:09:28.976477.976477 cuda_h.py:19] end iln_self_attn_paln cost 0.009033203125 seconds
DEBUG 01-15 10:09:28.976309.976309 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-15 10:09:28.976934.976934 cuda_h.py:10] start gate
INFO 01-15 10:09:28.977444.977444 client.py:127] Model loaded
DEBUG 01-15 10:09:28.977653.977653 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.978341.978341 cuda_h.py:19] end restore2model cost 0.0010502338409423828 seconds
DEBUG 01-15 10:09:28.978835.978835 cuda_h.py:19] end sllm_worker_task cost 0.010968208312988281 seconds
DEBUG 01-15 10:09:28.978340.978340 cuda_h.py:19] end gate cost 0.002167224884033203 seconds
DEBUG 01-15 10:09:28.978289.978289 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:28.979494.979494 lmp.py:1616] 
DEBUG 01-15 10:09:28.979494.979494 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:28.979018.979018 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:28.979959.979959 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:28.979040.979040 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:28.979974.979974 lmp.py:1620] 
DEBUG 01-15 10:09:28.979974.979974 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:28.979624.979624 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:28.979750.979750 lmp.py:1626]   Expert 20 |     11 | CPU
DEBUG 01-15 10:09:28.979923.979923 lmp.py:1626]   Expert 61 |     11 | CPU
DEBUG 01-15 10:09:28.979143.979143 lmp.py:1626]   Expert 11 |     28 | CPU
DEBUG 01-15 10:09:28.979316.979316 lmp.py:1626]   Expert  7 |     40 | CPU
DEBUG 01-15 10:09:28.979535.979535 lmp.py:1626]   Expert 62 |     41 | CPU
DEBUG 01-15 10:09:28.979231.979231 lmp.py:1626]   Expert  3 |     45 | CPU
DEBUG 01-15 10:09:28.979020.979020 lmp.py:1626]   Expert 51 |     45 | CPU
DEBUG 01-15 10:09:28.979285.979285 lmp.py:1626]   Expert 30 |     51 | CPU
DEBUG 01-15 10:09:28.979836.979836 lmp.py:1626]   Expert 17 |     54 | CPU
DEBUG 01-15 10:09:28.979386.979386 lmp.py:1626]   Expert 29 |     56 | CPU
DEBUG 01-15 10:09:28.979989.979989 lmp.py:1626]   Expert  6 |     61 | CPU
DEBUG 01-15 10:09:28.979209.979209 lmp.py:1626]   Expert  9 |     65 | CPU
DEBUG 01-15 10:09:28.979428.979428 lmp.py:1626]   Expert 63 |     77 | CPU
DEBUG 01-15 10:09:28.979455.979455 lmp.py:1626]   Expert 38 |     78 | CPU
DEBUG 01-15 10:09:28.979244.979244 lmp.py:1626]   Expert 55 |     82 | CPU
DEBUG 01-15 10:09:28.979032.979032 lmp.py:1626]   Expert 59 |     88 | CPU
DEBUG 01-15 10:09:28.979583.979583 lmp.py:1626]   Expert 48 |     92 | CPU
DEBUG 01-15 10:09:28.979133.979133 lmp.py:1626]   Expert  8 |     94 | CPU
DEBUG 01-15 10:09:28.979445.979445 lmp.py:1626]   Expert 19 |     95 | CPU
DEBUG 01-15 10:09:28.979995.979995 lmp.py:1626]   Expert 49 |     99 | CPU
DEBUG 01-15 10:09:28.979215.979215 lmp.py:1626]   Expert 22 |    103 | CPU
DEBUG 01-15 10:09:28.979195.979195 lmp.py:1626]   Expert 24 |    110 | CPU
DEBUG 01-15 10:09:28.979415.979415 lmp.py:1626]   Expert 36 |    114 | CPU
DEBUG 01-15 10:09:28.979203.979203 lmp.py:1626]   Expert 34 |    115 | CPU
DEBUG 01-15 10:09:28.979754.979754 lmp.py:1626]   Expert 42 |    117 | CPU
DEBUG 01-15 10:09:28.979066.979066 lmp.py:1626]   Expert 50 |    120 | CPU
DEBUG 01-15 10:09:28.979854.979854 lmp.py:1626]   Expert 39 |    123 | CPU
DEBUG 01-15 10:09:28.979643.979643 lmp.py:1626]   Expert  4 |    131 | CPU
DEBUG 01-15 10:09:28.979717.979717 lmp.py:1626]   Expert 37 |    142 | CPU
DEBUG 01-15 10:09:28.979790.979790 lmp.py:1626]   Expert 15 |    146 | CPU
DEBUG 01-15 10:09:28.979771.979771 lmp.py:1626]   Expert 41 |    149 | CPU
DEBUG 01-15 10:09:28.979752.979752 lmp.py:1626]   Expert 23 |    153 | CPU
DEBUG 01-15 10:09:28.979971.979971 lmp.py:1626]   Expert 56 |    162 | GPU
DEBUG 01-15 10:09:28.979521.979521 lmp.py:1626]   Expert 60 |    165 | GPU
DEBUG 01-15 10:09:28.980833.980833 lmp.py:1626]   Expert 16 |    166 | GPU
DEBUG 01-15 10:09:28.980145.980145 lmp.py:1626]   Expert 44 |    167 | GPU
DEBUG 01-15 10:09:28.980695.980695 lmp.py:1626]   Expert  1 |    178 | GPU
DEBUG 01-15 10:09:28.980246.980246 lmp.py:1626]   Expert 21 |    180 | GPU
DEBUG 01-15 10:09:28.980558.980558 lmp.py:1626]   Expert 43 |    182 | GPU
DEBUG 01-15 10:09:28.980108.980108 lmp.py:1626]   Expert 53 |    191 | GPU
DEBUG 01-15 10:09:28.980420.980420 lmp.py:1626]   Expert 47 |    193 | GPU
DEBUG 01-15 10:09:28.980209.980209 lmp.py:1626]   Expert 33 |    201 | GPU
DEBUG 01-15 10:09:28.980951.980951 lmp.py:1626]   Expert 12 |    203 | GPU
DEBUG 01-15 10:09:28.980932.980932 lmp.py:1626]   Expert 13 |    208 | GPU
DEBUG 01-15 10:09:28.980913.980913 lmp.py:1626]   Expert 32 |    224 | GPU
DEBUG 01-15 10:09:28.980702.980702 lmp.py:1626]   Expert 28 |    231 | GPU
DEBUG 01-15 10:09:28.980490.980490 lmp.py:1626]   Expert  0 |    254 | GPU
DEBUG 01-15 10:09:28.980802.980802 lmp.py:1626]   Expert 54 |    258 | GPU
DEBUG 01-15 10:09:28.980352.980352 lmp.py:1626]   Expert 31 |    259 | GPU
DEBUG 01-15 10:09:28.980426.980426 lmp.py:1626]   Expert 26 |    261 | GPU
DEBUG 01-15 10:09:28.980738.980738 lmp.py:1626]   Expert 10 |    262 | GPU
DEBUG 01-15 10:09:28.980288.980288 lmp.py:1626]   Expert 18 |    268 | GPU
DEBUG 01-15 10:09:28.980600.980600 lmp.py:1626]   Expert 57 |    272 | GPU
DEBUG 01-15 10:09:28.980104.980104 lmp.py:1626]   Expert  2 |    281 | GPU
DEBUG 01-15 10:09:28.980383.980383 lmp.py:1626]   Expert 58 |    299 | GPU
DEBUG 01-15 10:09:28.980218.980218 lmp.py:1626]   Expert 40 |    341 | GPU
DEBUG 01-15 10:09:28.980007.980007 lmp.py:1626]   Expert 45 |    362 | GPU
DEBUG 01-15 10:09:28.980557.980557 lmp.py:1626]   Expert 25 |    363 | GPU
DEBUG 01-15 10:09:28.980631.980631 lmp.py:1626]   Expert  5 |    442 | GPU
DEBUG 01-15 10:09:28.980943.980943 lmp.py:1626]   Expert 35 |    464 | GPU
DEBUG 01-15 10:09:28.980255.980255 lmp.py:1626]   Expert 27 |    484 | GPU
DEBUG 01-15 10:09:28.980567.980567 lmp.py:1626]   Expert 46 |    549 | GPU
DEBUG 01-15 10:09:28.980879.980879 lmp.py:1626]   Expert 52 |    596 | GPU
DEBUG 01-15 10:09:28.980621.980621 lmp.py:1626]   Expert 14 |    886 | GPU
DEBUG 01-15 10:09:28.980555.980555 lmp.py:1627] 
DEBUG 01-15 10:09:28.980555.980555 lmp.py:1627]   CPU total tokens: 2736 (22.3%)
DEBUG 01-15 10:09:28.980490.980490 lmp.py:1628]   GPU total tokens: 9552 (77.7%)
DEBUG 01-15 10:09:28.980478.980478 cuda_h.py:19] end experts_map_get cost 0.0018262863159179688 seconds
DEBUG 01-15 10:09:28.980434.980434 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:28.980481.980481 lmp.py:1636] 
DEBUG 01-15 10:09:28.980481.980481 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:28.980139.980139 cuda_h.py:19] end cpu_experts_submit cost 6.365776062011719e-05 seconds
DEBUG 01-15 10:09:28.980981.980981 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:28.980976.980976 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:28.981599.981599 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:28.981814.981814 cuda_h.py:19] end allocate_cuda_memory cost 0.0002219676971435547 seconds
DEBUG 01-15 10:09:28.981955.981955 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:28.981718.981718 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:28.981110.981110 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:28.981959.981959 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 84d2814e-ca7c-42c5-8028-619334439cb8
DEBUG 01-15 10:09:28.981590.981590 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:28.982413.982413 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:28.982341.982341 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 84d2814e-ca7c-42c5-8028-619334439cb8
DEBUG 01-15 10:09:28.982959.982959 cuda_h.py:19] end load_into_gpu_async cost 0.0014736652374267578 seconds
DEBUG 01-15 10:09:28.983815.983815 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:28.983134.983134 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:28.983830.983830 cuda_h.py:19] end restore_tensors2 cost 0.00043892860412597656 seconds
DEBUG 01-15 10:09:28.983150.983150 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002591848373413086 seconds
DEBUG 01-15 10:09:28.983318.983318 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:28.984098.984098 cuda_h.py:19] end move_flatidxs cost 0.0010175704956054688 seconds
DEBUG 01-15 10:09:28.984809.984809 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:28.986717.986717 cuda_h.py:19] end restore2model cost 0.0029952526092529297 seconds
DEBUG 01-15 10:09:28.986898.986898 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005813121795654297 seconds
DEBUG 01-15 10:09:28.986508.986508 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:28.987977.987977 cuda_h.py:19] end gpu_sexperts cost 0.00030994415283203125 seconds
DEBUG 01-15 10:09:28.987482.987482 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:28.988941.988941 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015993118286132812 seconds
DEBUG 01-15 10:09:28.989059.989059 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:28.989542.989542 cuda_h.py:19] end gpu_group_list cost 0.0003426074981689453 seconds
DEBUG 01-15 10:09:28.990837.990837 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:28.990339.990339 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007166862487792969 seconds
DEBUG 01-15 10:09:28.990970.990970 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:28.990746.990746 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-15 10:09:28.990681.990681 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:28.996485.996485 cuda_h.py:19] end group_tensors cost 0.012249469757080078 seconds
DEBUG 01-15 10:09:28.997596.997596 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:29.001280.001280 cuda_h.py:19] end group pad cost 0.0037508010864257812 seconds
DEBUG 01-15 10:09:29.001739.001739 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:29.020356.020356 cuda_h.py:19] end group_einsum cost 0.0195310115814209 seconds
DEBUG 01-15 10:09:29.021507.021507 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:29.024886.024886 cuda_h.py:19] end get_outputs_cpu1 cost 0.003556966781616211 seconds
DEBUG 01-15 10:09:29.025476.025476 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.042517900466918945 seconds
DEBUG 01-15 10:09:29.026254.026254 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.035425424575805664 seconds
DEBUG 01-15 10:09:29.026908.026908 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:29.026543.026543 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:29.027391.027391 cuda_h.py:19] end index_scatter cost 0.00012183189392089844 seconds
DEBUG 01-15 10:09:29.027136.027136 cuda_h.py:19] end cpuoutputsdeal cost 0.0011789798736572266 seconds
DEBUG 01-15 10:09:29.027575.027575 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:29.027180.027180 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 84d2814e-ca7c-42c5-8028-619334439cb8
INFO 01-15 10:09:29.033924.033924 client.py:127] Model loaded
DEBUG 01-15 10:09:29.033087.033087 cuda_h.py:19] end wait_experts cost 0.005341529846191406 seconds
DEBUG 01-15 10:09:29.033646.033646 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:29.033563.033563 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:29.033983.033983 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:29.033936.033936 cuda_h.py:19] end gpu_group_tensor cost 0.0003228187561035156 seconds
DEBUG 01-15 10:09:29.034870.034870 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:29.035270.035270 cuda_h.py:19] end gpu_group_einsum cost 0.0009748935699462891 seconds
DEBUG 01-15 10:09:29.035932.035932 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:29.035168.035168 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:29.036524.036524 cuda_h.py:19] end all_expert_outputs_slices cost 0.00047588348388671875 seconds
DEBUG 01-15 10:09:29.036943.036943 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:29.036313.036313 cuda_h.py:19] end concat_expert_out cost 0.00010657310485839844 seconds
DEBUG 01-15 10:09:29.036330.036330 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:29.036303.036303 cuda_h.py:19] end index_scatter cost 0.00010251998901367188 seconds
DEBUG 01-15 10:09:29.036736.036736 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0011780261993408203 seconds
DEBUG 01-15 10:09:29.036410.036410 cuda_h.py:19] end gpu_experts cost 0.003385305404663086 seconds
DEBUG 01-15 10:09:29.036428.036428 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.060445547103881836 seconds
DEBUG 01-15 10:09:29.037307.037307 cuda_h.py:19] end prefill_layer cost 0.07077550888061523 seconds
DEBUG 01-15 10:09:29.037734.037734 lmp.py:1552] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-15 10:09:29.037332.037332 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:29.037122.037122 lmp.py:1495] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-15 10:09:29.037912.037912 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:29.038440.038440 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:29.038664.038664 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:29.042608.042608 cuda_h.py:19] end self_attn cost 0.00380706787109375 seconds
DEBUG 01-15 10:09:29.042022.042022 cuda_h.py:19] end iln_self_attn_paln cost 0.005005598068237305 seconds
DEBUG 01-15 10:09:29.043297.043297 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-15 10:09:29.043524.043524 cuda_h.py:10] start gate
DEBUG 01-15 10:09:29.044411.044411 cuda_h.py:19] end gate cost 0.0009095668792724609 seconds
DEBUG 01-15 10:09:29.044711.044711 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:29.044942.044942 lmp.py:1616] 
DEBUG 01-15 10:09:29.044942.044942 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:29.044639.044639 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:29.044508.044508 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:29.044655.044655 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:29.044749.044749 lmp.py:1620] 
DEBUG 01-15 10:09:29.044749.044749 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:29.044366.044366 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:29.045606.045606 lmp.py:1626]   Expert 18 |     66 | CPU
DEBUG 01-15 10:09:29.045938.045938 lmp.py:1626]   Expert 54 |     72 | CPU
DEBUG 01-15 10:09:29.045601.045601 lmp.py:1626]   Expert 47 |     73 | CPU
DEBUG 01-15 10:09:29.045265.045265 lmp.py:1626]   Expert 23 |     76 | CPU
DEBUG 01-15 10:09:29.045166.045166 lmp.py:1626]   Expert 48 |     77 | CPU
DEBUG 01-15 10:09:29.045737.045737 lmp.py:1626]   Expert 44 |     84 | CPU
DEBUG 01-15 10:09:29.045069.045069 lmp.py:1626]   Expert 45 |     86 | CPU
DEBUG 01-15 10:09:29.045971.045971 lmp.py:1626]   Expert 20 |     90 | CPU
DEBUG 01-15 10:09:29.045158.045158 lmp.py:1626]   Expert 31 |     98 | CPU
DEBUG 01-15 10:09:29.045106.045106 lmp.py:1626]   Expert 36 |    105 | CPU
DEBUG 01-15 10:09:29.045577.045577 lmp.py:1626]   Expert 61 |    110 | CPU
DEBUG 01-15 10:09:29.045956.045956 lmp.py:1626]   Expert 42 |    118 | CPU
DEBUG 01-15 10:09:29.045811.045811 lmp.py:1626]   Expert 33 |    119 | CPU
DEBUG 01-15 10:09:29.045905.045905 lmp.py:1626]   Expert 43 |    120 | CPU
DEBUG 01-15 10:09:29.045091.045091 lmp.py:1626]   Expert 10 |    122 | CPU
DEBUG 01-15 10:09:29.045993.045993 lmp.py:1626]   Expert 24 |    123 | CPU
DEBUG 01-15 10:09:29.045703.045703 lmp.py:1626]   Expert 11 |    127 | CPU
DEBUG 01-15 10:09:29.045174.045174 lmp.py:1626]   Expert 49 |    127 | CPU
DEBUG 01-15 10:09:29.045791.045791 lmp.py:1626]   Expert 56 |    128 | CPU
DEBUG 01-15 10:09:29.045408.045408 lmp.py:1626]   Expert  6 |    137 | CPU
DEBUG 01-15 10:09:29.045502.045502 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:29.045689.045689 lmp.py:1626]   Expert 17 |    148 | CPU
DEBUG 01-15 10:09:29.045113.045113 lmp.py:1626]   Expert  0 |    149 | CPU
DEBUG 01-15 10:09:29.045300.045300 lmp.py:1626]   Expert  5 |    151 | CPU
DEBUG 01-15 10:09:29.045010.045010 lmp.py:1626]   Expert 12 |    158 | CPU
DEBUG 01-15 10:09:29.045196.045196 lmp.py:1626]   Expert 40 |    160 | CPU
DEBUG 01-15 10:09:29.045575.045575 lmp.py:1626]   Expert 55 |    160 | CPU
DEBUG 01-15 10:09:29.045192.045192 lmp.py:1626]   Expert 59 |    160 | CPU
DEBUG 01-15 10:09:29.045617.045617 lmp.py:1626]   Expert 26 |    163 | CPU
DEBUG 01-15 10:09:29.045326.045326 lmp.py:1626]   Expert 57 |    164 | CPU
DEBUG 01-15 10:09:29.045559.045559 lmp.py:1626]   Expert 46 |    165 | CPU
DEBUG 01-15 10:09:29.046507.046507 lmp.py:1626]   Expert 38 |    168 | CPU
DEBUG 01-15 10:09:29.046747.046747 lmp.py:1626]   Expert 13 |    169 | GPU
DEBUG 01-15 10:09:29.046126.046126 lmp.py:1626]   Expert 58 |    171 | GPU
DEBUG 01-15 10:09:29.046074.046074 lmp.py:1626]   Expert 30 |    172 | GPU
DEBUG 01-15 10:09:29.046022.046022 lmp.py:1626]   Expert 35 |    174 | GPU
DEBUG 01-15 10:09:29.046255.046255 lmp.py:1626]   Expert 50 |    175 | GPU
DEBUG 01-15 10:09:29.046726.046726 lmp.py:1626]   Expert  7 |    180 | GPU
DEBUG 01-15 10:09:29.046628.046628 lmp.py:1626]   Expert 16 |    183 | GPU
DEBUG 01-15 10:09:29.046768.046768 lmp.py:1626]   Expert 32 |    200 | GPU
DEBUG 01-15 10:09:29.046001.046001 lmp.py:1626]   Expert 15 |    201 | GPU
DEBUG 01-15 10:09:29.046472.046472 lmp.py:1626]   Expert 14 |    205 | GPU
DEBUG 01-15 10:09:29.046182.046182 lmp.py:1626]   Expert  1 |    215 | GPU
DEBUG 01-15 10:09:29.046560.046560 lmp.py:1626]   Expert  4 |    224 | GPU
DEBUG 01-15 10:09:29.046462.046462 lmp.py:1626]   Expert  3 |    226 | GPU
DEBUG 01-15 10:09:29.046364.046364 lmp.py:1626]   Expert 39 |    237 | GPU
DEBUG 01-15 10:09:29.046312.046312 lmp.py:1626]   Expert 34 |    239 | GPU
DEBUG 01-15 10:09:29.046021.046021 lmp.py:1626]   Expert 28 |    245 | GPU
DEBUG 01-15 10:09:29.046969.046969 lmp.py:1626]   Expert 52 |    247 | GPU
DEBUG 01-15 10:09:29.046348.046348 lmp.py:1626]   Expert 22 |    257 | GPU
DEBUG 01-15 10:09:29.046250.046250 lmp.py:1626]   Expert 25 |    259 | GPU
DEBUG 01-15 10:09:29.046390.046390 lmp.py:1626]   Expert  2 |    276 | GPU
DEBUG 01-15 10:09:29.046100.046100 lmp.py:1626]   Expert 21 |    279 | GPU
DEBUG 01-15 10:09:29.046333.046333 lmp.py:1626]   Expert 41 |    280 | GPU
DEBUG 01-15 10:09:29.046804.046804 lmp.py:1626]   Expert 60 |    283 | GPU
DEBUG 01-15 10:09:29.046328.046328 lmp.py:1626]   Expert 63 |    290 | GPU
DEBUG 01-15 10:09:29.046468.046468 lmp.py:1626]   Expert 29 |    297 | GPU
DEBUG 01-15 10:09:29.046132.046132 lmp.py:1626]   Expert 62 |    297 | GPU
DEBUG 01-15 10:09:29.046557.046557 lmp.py:1626]   Expert 27 |    300 | GPU
DEBUG 01-15 10:09:29.046028.046028 lmp.py:1626]   Expert 37 |    332 | GPU
DEBUG 01-15 10:09:29.046738.046738 lmp.py:1626]   Expert 53 |    332 | GPU
DEBUG 01-15 10:09:29.046401.046401 lmp.py:1626]   Expert  8 |    337 | GPU
DEBUG 01-15 10:09:29.047541.047541 lmp.py:1626]   Expert 19 |    443 | GPU
DEBUG 01-15 10:09:29.047681.047681 lmp.py:1626]   Expert  9 |    614 | GPU
DEBUG 01-15 10:09:29.047060.047060 lmp.py:1627] 
DEBUG 01-15 10:09:29.047060.047060 lmp.py:1627]   CPU total tokens: 3949 (32.1%)
DEBUG 01-15 10:09:29.047631.047631 lmp.py:1628]   GPU total tokens: 8339 (67.9%)
DEBUG 01-15 10:09:29.047446.047446 cuda_h.py:19] end experts_map_get cost 0.0029137134552001953 seconds
DEBUG 01-15 10:09:29.047020.047020 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:29.047948.047948 lmp.py:1636] 
DEBUG 01-15 10:09:29.047948.047948 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:29.047077.047077 cuda_h.py:19] end cpu_experts_submit cost 9.131431579589844e-05 seconds
DEBUG 01-15 10:09:29.047847.047847 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:29.047328.047328 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:29.047886.047886 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:29.048410.048410 cuda_h.py:19] end allocate_cuda_memory cost 0.00035834312438964844 seconds
DEBUG 01-15 10:09:29.048884.048884 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:29.048072.048072 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:29.048127.048127 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:29.048096.048096 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 56a92daf-c31b-40ba-b2d1-3b210e9306c9
DEBUG 01-15 10:09:29.048367.048367 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:29.050733.050733 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 56a92daf-c31b-40ba-b2d1-3b210e9306c9
DEBUG 01-15 10:09:29.050245.050245 cuda_h.py:19] end load_into_gpu_async cost 0.001817941665649414 seconds
DEBUG 01-15 10:09:29.050663.050663 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:29.050210.050210 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:29.050652.050652 cuda_h.py:19] end restore_tensors2 cost 0.0004210472106933594 seconds
DEBUG 01-15 10:09:29.050488.050488 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003165006637573242 seconds
DEBUG 01-15 10:09:29.050410.050410 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:29.051212.051212 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:29.052311.052311 cuda_h.py:19] end move_flatidxs cost 0.001211404800415039 seconds
DEBUG 01-15 10:09:29.052958.052958 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:29.053203.053203 cuda_h.py:19] end restore2model cost 0.0026946067810058594 seconds
DEBUG 01-15 10:09:29.053384.053384 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006114482879638672 seconds
DEBUG 01-15 10:09:29.053180.053180 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:29.053501.053501 cuda_h.py:19] end gpu_sexperts cost 0.0002758502960205078 seconds
DEBUG 01-15 10:09:29.054238.054238 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:29.055628.055628 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015153884887695312 seconds
DEBUG 01-15 10:09:29.056231.056231 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:29.056218.056218 cuda_h.py:19] end gpu_group_list cost 0.00035643577575683594 seconds
DEBUG 01-15 10:09:29.056381.056381 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:29.057950.057950 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007295608520507812 seconds
DEBUG 01-15 10:09:29.057911.057911 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:29.062240.062240 cuda_h.py:19] end group_tensors cost 0.00969839096069336 seconds
DEBUG 01-15 10:09:29.063612.063612 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:29.068662.068662 cuda_h.py:19] end group pad cost 0.004169940948486328 seconds
DEBUG 01-15 10:09:29.068598.068598 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:29.088598.088598 cuda_h.py:19] end group_einsum cost 0.019893407821655273 seconds
DEBUG 01-15 10:09:29.088530.088530 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:29.093037.093037 cuda_h.py:19] end get_outputs_cpu1 cost 0.0047550201416015625 seconds
DEBUG 01-15 10:09:29.093401.093401 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04331469535827637 seconds
DEBUG 01-15 10:09:29.094942.094942 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0370173454284668 seconds
DEBUG 01-15 10:09:29.094915.094915 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:29.095870.095870 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:29.095779.095779 cuda_h.py:19] end index_scatter cost 0.00014710426330566406 seconds
DEBUG 01-15 10:09:29.096917.096917 cuda_h.py:19] end cpuoutputsdeal cost 0.0011458396911621094 seconds
DEBUG 01-15 10:09:29.096238.096238 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:29.096792.096792 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 56a92daf-c31b-40ba-b2d1-3b210e9306c9
INFO 01-15 10:09:29.101079.101079 client.py:127] Model loaded
DEBUG 01-15 10:09:29.101355.101355 cuda_h.py:19] end wait_experts cost 0.004825592041015625 seconds
DEBUG 01-15 10:09:29.101073.101073 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:29.101872.101872 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:29.101643.101643 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:29.101645.101645 cuda_h.py:19] end gpu_group_tensor cost 0.0003790855407714844 seconds
DEBUG 01-15 10:09:29.102865.102865 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:29.103875.103875 cuda_h.py:19] end gpu_group_einsum cost 0.0011937618255615234 seconds
DEBUG 01-15 10:09:29.103115.103115 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:29.103808.103808 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:29.104620.104620 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006225109100341797 seconds
DEBUG 01-15 10:09:29.104874.104874 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:29.104444.104444 cuda_h.py:19] end concat_expert_out cost 0.0001342296600341797 seconds
DEBUG 01-15 10:09:29.105688.105688 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:29.105304.105304 cuda_h.py:19] end index_scatter cost 0.00012230873107910156 seconds
DEBUG 01-15 10:09:29.105188.105188 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014638900756835938 seconds
DEBUG 01-15 10:09:29.105909.105909 cuda_h.py:19] end gpu_experts cost 0.00412750244140625 seconds
DEBUG 01-15 10:09:29.105544.105544 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06251263618469238 seconds
DEBUG 01-15 10:09:29.106632.106632 cuda_h.py:19] end prefill_layer cost 0.06862020492553711 seconds
DEBUG 01-15 10:09:29.106663.106663 lmp.py:1552] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-15 10:09:29.106864.106864 cuda_h.py:19] end prefill cost 1.9117321968078613 seconds
DEBUG 01-15 10:09:31.301891.301891 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11547732353210449 s
DEBUG 01-15 10:09:31.799579.799579 cuda_h.py:19] end generate_input_ids cost 0.4951307773590088 seconds
DEBUG 01-15 10:09:31.799623.799623 cuda_h.py:10] start init_cache
DEBUG 01-15 10:09:31.799966.799966 cuda_h.py:19] end init_cache cost 0.00011086463928222656 seconds
DEBUG 01-15 10:09:34.341267.341267 cuda_h.py:10] start init_meta_layer
DEBUG 01-15 10:09:34.346625.346625 cuda_h.py:19] end init_meta_layer cost 3.3855438232421875e-05 seconds
DEBUG 01-15 10:09:34.346425.346425 cuda_h.py:10] start init_weights
DEBUG 01-15 10:09:34.346083.346083 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:34.346336.346336 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:34.348529.348529 cuda_h.py:19] end allocate_cuda_memory cost 0.0021791458129882812 seconds
DEBUG 01-15 10:09:34.348168.348168 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:34.348553.348553 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:34.348357.348357 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:34.348543.348543 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61a1a790-5a4e-4c53-868d-783a358e4d80
DEBUG 01-15 10:09:34.348005.348005 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:34.350388.350388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61a1a790-5a4e-4c53-868d-783a358e4d80
DEBUG 01-15 10:09:34.350728.350728 cuda_h.py:19] end load_into_gpu_async cost 0.0016787052154541016 seconds
DEBUG 01-15 10:09:34.350736.350736 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:34.350766.350766 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:34.350568.350568 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004190921783447266 seconds
DEBUG 01-15 10:09:34.350841.350841 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:34.350160.350160 cuda_h.py:19] end restore2model cost 0.0002105236053466797 seconds
INFO 01-15 10:09:34.350737.350737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61a1a790-5a4e-4c53-868d-783a358e4d80
INFO 01-15 10:09:34.428786.428786 client.py:127] Model loaded
DEBUG 01-15 10:09:34.428209.428209 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-15 10:09:34.429683.429683 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:34.429052.429052 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:34.429291.429291 cuda_h.py:19] end allocate_cuda_memory cost 0.0005025863647460938 seconds
DEBUG 01-15 10:09:34.429686.429686 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:34.430040.430040 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:34.430613.430613 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:34.430437.430437 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8c76f1ba-7e0d-4061-b911-0ff237ec2181
DEBUG 01-15 10:09:34.430987.430987 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:34.431424.431424 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8c76f1ba-7e0d-4061-b911-0ff237ec2181
DEBUG 01-15 10:09:34.432542.432542 cuda_h.py:19] end load_into_gpu_async cost 0.002119779586791992 seconds
DEBUG 01-15 10:09:34.432657.432657 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:34.432748.432748 cuda_h.py:19] end restore_tensors2 cost 0.00026917457580566406 seconds
DEBUG 01-15 10:09:34.432500.432500 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003541231155395508 seconds
INFO 01-15 10:09:34.432079.432079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8c76f1ba-7e0d-4061-b911-0ff237ec2181
INFO 01-15 10:09:34.447659.447659 client.py:127] Model loaded
DEBUG 01-15 10:09:34.448041.448041 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:34.449513.449513 cuda_h.py:19] end restore2model cost 0.0009517669677734375 seconds
DEBUG 01-15 10:09:34.449365.449365 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020207881927490234 seconds
DEBUG 01-15 10:09:34.449242.449242 cuda_h.py:19] end init_weights cost 0.10308670997619629 seconds
DEBUG 01-15 10:09:34.449668.449668 cuda_h.py:10] start copy_emodel
DEBUG 01-15 10:09:35.362259.362259 cuda_h.py:19] end copy_emodel cost 0.9128196239471436 seconds
DEBUG 01-15 10:09:35.363127.363127 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-15 10:09:35.364893.364893 cuda_h.py:19] end init_inputs_tokens cost 0.0006847381591796875 seconds
DEBUG 01-15 10:09:35.364630.364630 cuda_h.py:10] start prefill
DEBUG 01-15 10:09:35.364075.364075 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.364023.364023 lmp.py:1495] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-15 10:09:35.364580.364580 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:35.364489.364489 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:35.364501.364501 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 0.00012445449829101562 seconds
DEBUG 01-15 10:09:35.364826.364826 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 0.0001571178436279297 seconds
DEBUG 01-15 10:09:35.364946.364946 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.364903.364903 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.364062.364062 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.365261.365261 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.365049.365049 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.366277.366277 cuda_h.py:19] end allocate_cuda_memory cost 0.0007612705230712891 seconds
DEBUG 01-15 10:09:35.366336.366336 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.366187.366187 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.366113.366113 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.366844.366844 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54ee495b-fd6f-47e1-bff7-68c685cd0c23
DEBUG 01-15 10:09:35.367947.367947 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.368086.368086 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.368488.368488 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54ee495b-fd6f-47e1-bff7-68c685cd0c23
DEBUG 01-15 10:09:35.369972.369972 cuda_h.py:19] end load_into_gpu_async cost 0.002472400665283203 seconds
DEBUG 01-15 10:09:35.369041.369041 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.369256.369256 cuda_h.py:19] end restore_tensors2 cost 0.00018453598022460938 seconds
DEBUG 01-15 10:09:35.369624.369624 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004181623458862305 seconds
INFO 01-15 10:09:35.369278.369278 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54ee495b-fd6f-47e1-bff7-68c685cd0c23
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.375020.375020 cuda_h.py:19] end self_attn cost 0.007814168930053711 seconds
DEBUG 01-15 10:09:35.376370.376370 cuda_h.py:19] end iln_self_attn_paln cost 0.011832952499389648 seconds
DEBUG 01-15 10:09:35.376180.376180 cuda_h.py:10] start dense_mlp
INFO 01-15 10:09:35.377579.377579 client.py:127] Model loaded
DEBUG 01-15 10:09:35.377897.377897 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.378772.378772 cuda_h.py:19] end restore2model cost 0.0013093948364257812 seconds
DEBUG 01-15 10:09:35.378023.378023 cuda_h.py:19] end sllm_worker_task cost 0.013688087463378906 seconds
DEBUG 01-15 10:09:35.379002.379002 cuda_h.py:19] end dense_mlp cost 0.002560853958129883 seconds
DEBUG 01-15 10:09:35.379464.379464 cuda_h.py:19] end prefill_layer cost 0.014932394027709961 seconds
DEBUG 01-15 10:09:35.379657.379657 lmp.py:1552] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-15 10:09:35.379976.379976 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.379056.379056 lmp.py:1495] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-15 10:09:35.379229.379229 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:35.379309.379309 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:35.379192.379192 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.9325485229492188e-05 seconds
DEBUG 01-15 10:09:35.379371.379371 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.9604644775390625e-05 seconds
DEBUG 01-15 10:09:35.379922.379922 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.379672.379672 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.379744.379744 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.379561.379561 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.379338.379338 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.380322.380322 cuda_h.py:19] end allocate_cuda_memory cost 0.00041484832763671875 seconds
DEBUG 01-15 10:09:35.380678.380678 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.380462.380462 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.380042.380042 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.380144.380144 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5000e30b-46fb-41c5-9768-aa19b066aa48
DEBUG 01-15 10:09:35.381263.381263 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.381969.381969 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.382940.382940 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5000e30b-46fb-41c5-9768-aa19b066aa48
DEBUG 01-15 10:09:35.382768.382768 cuda_h.py:19] end load_into_gpu_async cost 0.0017969608306884766 seconds
DEBUG 01-15 10:09:35.382684.382684 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.382228.382228 cuda_h.py:19] end restore_tensors2 cost 0.000152587890625 seconds
DEBUG 01-15 10:09:35.382920.382920 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030107498168945312 seconds
INFO 01-15 10:09:35.383898.383898 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5000e30b-46fb-41c5-9768-aa19b066aa48
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.385231.385231 cuda_h.py:19] end self_attn cost 0.004175662994384766 seconds
DEBUG 01-15 10:09:35.385552.385552 cuda_h.py:19] end iln_self_attn_paln cost 0.006540060043334961 seconds
DEBUG 01-15 10:09:35.386436.386436 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-15 10:09:35.386014.386014 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.387708.387708 cuda_h.py:19] end gate cost 0.0011096000671386719 seconds
DEBUG 01-15 10:09:35.387590.387590 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.387364.387364 lmp.py:1616] 
DEBUG 01-15 10:09:35.387364.387364 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.387319.387319 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.387399.387399 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.387188.387188 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.387546.387546 lmp.py:1620] 
DEBUG 01-15 10:09:35.387546.387546 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.387335.387335 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.387839.387839 lmp.py:1626]   Expert 25 |     64 | CPU
DEBUG 01-15 10:09:35.387959.387959 lmp.py:1626]   Expert 54 |     67 | CPU
DEBUG 01-15 10:09:35.387655.387655 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:35.387728.387728 lmp.py:1626]   Expert 31 |     72 | CPU
DEBUG 01-15 10:09:35.387610.387610 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:35.387683.387683 lmp.py:1626]   Expert 62 |     87 | CPU
DEBUG 01-15 10:09:35.387326.387326 lmp.py:1626]   Expert 18 |     88 | CPU
DEBUG 01-15 10:09:35.387731.387731 lmp.py:1626]   Expert 52 |     98 | CPU
DEBUG 01-15 10:09:35.387897.387897 lmp.py:1626]   Expert 22 |    100 | CPU
DEBUG 01-15 10:09:35.387301.387301 lmp.py:1626]   Expert 47 |    104 | CPU
DEBUG 01-15 10:09:35.387706.387706 lmp.py:1626]   Expert  0 |    113 | CPU
DEBUG 01-15 10:09:35.388110.388110 lmp.py:1626]   Expert 37 |    117 | CPU
DEBUG 01-15 10:09:35.388753.388753 lmp.py:1626]   Expert 27 |    121 | CPU
DEBUG 01-15 10:09:35.388919.388919 lmp.py:1626]   Expert 32 |    123 | CPU
DEBUG 01-15 10:09:35.388324.388324 lmp.py:1626]   Expert 41 |    130 | CPU
DEBUG 01-15 10:09:35.388590.388590 lmp.py:1626]   Expert 44 |    131 | CPU
DEBUG 01-15 10:09:35.388570.388570 lmp.py:1626]   Expert 28 |    136 | CPU
DEBUG 01-15 10:09:35.388737.388737 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:35.388141.388141 lmp.py:1626]   Expert 58 |    140 | CPU
DEBUG 01-15 10:09:35.388784.388784 lmp.py:1626]   Expert 60 |    144 | CPU
DEBUG 01-15 10:09:35.388950.388950 lmp.py:1626]   Expert 43 |    147 | CPU
DEBUG 01-15 10:09:35.388116.388116 lmp.py:1626]   Expert  1 |    150 | CPU
DEBUG 01-15 10:09:35.388521.388521 lmp.py:1626]   Expert 38 |    153 | CPU
DEBUG 01-15 10:09:35.388449.388449 lmp.py:1626]   Expert 49 |    154 | CPU
DEBUG 01-15 10:09:35.388376.388376 lmp.py:1626]   Expert 51 |    155 | CPU
DEBUG 01-15 10:09:35.388543.388543 lmp.py:1626]   Expert 34 |    161 | CPU
DEBUG 01-15 10:09:35.388947.388947 lmp.py:1626]   Expert 35 |    164 | CPU
DEBUG 01-15 10:09:35.388544.388544 lmp.py:1626]   Expert 36 |    168 | CPU
DEBUG 01-15 10:09:35.388571.388571 lmp.py:1626]   Expert 11 |    170 | CPU
DEBUG 01-15 10:09:35.388929.388929 lmp.py:1626]   Expert 17 |    170 | CPU
DEBUG 01-15 10:09:35.388572.388572 lmp.py:1626]   Expert 59 |    174 | CPU
DEBUG 01-15 10:09:35.388738.388738 lmp.py:1626]   Expert 10 |    180 | CPU
DEBUG 01-15 10:09:35.388904.388904 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:35.388058.388058 lmp.py:1626]   Expert  2 |    186 | GPU
DEBUG 01-15 10:09:35.388608.388608 lmp.py:1626]   Expert 39 |    189 | GPU
DEBUG 01-15 10:09:35.388728.388728 lmp.py:1626]   Expert 33 |    197 | GPU
DEBUG 01-15 10:09:35.388087.388087 lmp.py:1626]   Expert 12 |    198 | GPU
DEBUG 01-15 10:09:35.388160.388160 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:35.388757.388757 lmp.py:1626]   Expert 48 |    198 | GPU
DEBUG 01-15 10:09:35.388406.388406 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:35.388526.388526 lmp.py:1626]   Expert 53 |    204 | GPU
DEBUG 01-15 10:09:35.388984.388984 lmp.py:1626]   Expert 19 |    220 | GPU
DEBUG 01-15 10:09:35.388104.388104 lmp.py:1626]   Expert 26 |    221 | GPU
DEBUG 01-15 10:09:35.388747.388747 lmp.py:1626]   Expert 30 |    221 | GPU
DEBUG 01-15 10:09:35.388105.388105 lmp.py:1626]   Expert 45 |    221 | GPU
DEBUG 01-15 10:09:35.388516.388516 lmp.py:1626]   Expert  5 |    227 | GPU
DEBUG 01-15 10:09:35.388636.388636 lmp.py:1626]   Expert  4 |    229 | GPU
DEBUG 01-15 10:09:35.388517.388517 lmp.py:1626]   Expert 24 |    229 | GPU
DEBUG 01-15 10:09:35.388160.388160 lmp.py:1626]   Expert 42 |    242 | GPU
DEBUG 01-15 10:09:35.388280.388280 lmp.py:1626]   Expert 50 |    245 | GPU
DEBUG 01-15 10:09:35.388400.388400 lmp.py:1626]   Expert 29 |    254 | GPU
DEBUG 01-15 10:09:35.388281.388281 lmp.py:1626]   Expert 56 |    262 | GPU
DEBUG 01-15 10:09:35.388163.388163 lmp.py:1626]   Expert 61 |    270 | GPU
DEBUG 01-15 10:09:35.388760.388760 lmp.py:1626]   Expert  8 |    283 | GPU
DEBUG 01-15 10:09:35.388979.388979 lmp.py:1626]   Expert 63 |    285 | GPU
DEBUG 01-15 10:09:35.388483.388483 lmp.py:1626]   Expert 46 |    294 | GPU
DEBUG 01-15 10:09:35.388603.388603 lmp.py:1626]   Expert  9 |    300 | GPU
DEBUG 01-15 10:09:35.388961.388961 lmp.py:1626]   Expert  6 |    316 | GPU
DEBUG 01-15 10:09:35.388604.388604 lmp.py:1626]   Expert 16 |    316 | GPU
DEBUG 01-15 10:09:35.388247.388247 lmp.py:1626]   Expert 40 |    319 | GPU
DEBUG 01-15 10:09:35.388843.388843 lmp.py:1626]   Expert  7 |    322 | GPU
DEBUG 01-15 10:09:35.388725.388725 lmp.py:1626]   Expert 23 |    325 | GPU
DEBUG 01-15 10:09:35.388845.388845 lmp.py:1626]   Expert 14 |    413 | GPU
DEBUG 01-15 10:09:35.388488.388488 lmp.py:1626]   Expert 57 |    464 | GPU
DEBUG 01-15 10:09:35.389561.389561 lmp.py:1627] 
DEBUG 01-15 10:09:35.389561.389561 lmp.py:1627]   CPU total tokens: 4059 (33.0%)
DEBUG 01-15 10:09:35.389396.389396 lmp.py:1628]   GPU total tokens: 8229 (67.0%)
DEBUG 01-15 10:09:35.389430.389430 cuda_h.py:19] end experts_map_get cost 0.0017154216766357422 seconds
DEBUG 01-15 10:09:35.389195.389195 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.389766.389766 lmp.py:1636] 
DEBUG 01-15 10:09:35.389766.389766 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.389385.389385 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-15 10:09:35.389558.389558 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.389653.389653 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.389463.389463 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.389101.389101 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-15 10:09:35.389189.389189 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.389753.389753 sllm_store_c.py:27] get device uuid map
INFO 01-15 10:09:35.390953.390953 client.py:127] Model loaded
DEBUG 01-15 10:09:35.390726.390726 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.390361.390361 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.391294.391294 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1802809-e84c-4c29-ba2a-d65939c1f4d8
DEBUG 01-15 10:09:35.391478.391478 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.391778.391778 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.392553.392553 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.392639.392639 cuda_h.py:19] end restore2model cost 0.0016639232635498047 seconds
DEBUG 01-15 10:09:35.392915.392915 cuda_h.py:19] end sllm_worker_task cost 0.013162374496459961 seconds
DEBUG 01-15 10:09:35.393459.393459 cuda_h.py:19] end move_flatidxs cost 0.0011718273162841797 seconds
DEBUG 01-15 10:09:35.393205.393205 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:35.393058.393058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1802809-e84c-4c29-ba2a-d65939c1f4d8
DEBUG 01-15 10:09:35.393650.393650 cuda_h.py:19] end load_into_gpu_async cost 0.0038521289825439453 seconds
DEBUG 01-15 10:09:35.393737.393737 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.394924.394924 cuda_h.py:19] end restore_tensors2 cost 0.0005960464477539062 seconds
DEBUG 01-15 10:09:35.394119.394119 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005162954330444336 seconds
DEBUG 01-15 10:09:35.394107.394107 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.397185.397185 cuda_h.py:19] end restore2model cost 0.0030748844146728516 seconds
DEBUG 01-15 10:09:35.397685.397685 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008495569229125977 seconds
DEBUG 01-15 10:09:35.397195.397195 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.398426.398426 cuda_h.py:19] end gpu_sexperts cost 0.0003147125244140625 seconds
DEBUG 01-15 10:09:35.398898.398898 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.400683.400683 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0018429756164550781 seconds
DEBUG 01-15 10:09:35.400458.400458 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.401100.401100 cuda_h.py:19] end gpu_group_list cost 0.0003123283386230469 seconds
DEBUG 01-15 10:09:35.401554.401554 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.402732.402732 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007200241088867188 seconds
DEBUG 01-15 10:09:35.402800.402800 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.402789.402789 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7642974853515625e-05 seconds
DEBUG 01-15 10:09:35.402485.402485 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.403437.403437 cuda_h.py:19] end group_tensors cost 0.009802818298339844 seconds
DEBUG 01-15 10:09:35.404475.404475 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.411977.411977 cuda_h.py:19] end group pad cost 0.006745815277099609 seconds
DEBUG 01-15 10:09:35.411867.411867 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.434506.434506 cuda_h.py:19] end group_einsum cost 0.022354602813720703 seconds
DEBUG 01-15 10:09:35.434168.434168 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.439588.439588 cuda_h.py:19] end get_outputs_cpu1 cost 0.004759311676025391 seconds
DEBUG 01-15 10:09:35.440060.440060 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.048462867736816406 seconds
DEBUG 01-15 10:09:35.441638.441638 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.038718223571777344 seconds
DEBUG 01-15 10:09:35.441641.441641 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.441219.441219 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.441357.441357 cuda_h.py:19] end index_scatter cost 0.00012087821960449219 seconds
DEBUG 01-15 10:09:35.442212.442212 cuda_h.py:19] end cpuoutputsdeal cost 0.0008044242858886719 seconds
DEBUG 01-15 10:09:35.442896.442896 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.442659.442659 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1802809-e84c-4c29-ba2a-d65939c1f4d8
INFO 01-15 10:09:35.443561.443561 client.py:127] Model loaded
DEBUG 01-15 10:09:35.443504.443504 cuda_h.py:19] end wait_experts cost 0.0012955665588378906 seconds
DEBUG 01-15 10:09:35.443014.443014 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.443434.443434 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.443044.443044 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.444737.444737 cuda_h.py:19] end gpu_group_tensor cost 0.0006878376007080078 seconds
DEBUG 01-15 10:09:35.444550.444550 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.445839.445839 cuda_h.py:19] end gpu_group_einsum cost 0.0008656978607177734 seconds
DEBUG 01-15 10:09:35.445279.445279 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.445824.445824 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.445356.445356 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022268295288085938 seconds
DEBUG 01-15 10:09:35.445158.445158 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.445797.445797 cuda_h.py:19] end concat_expert_out cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:35.445163.445163 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.446755.446755 cuda_h.py:19] end index_scatter cost 5.2928924560546875e-05 seconds
DEBUG 01-15 10:09:35.446180.446180 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005552768707275391 seconds
DEBUG 01-15 10:09:35.446520.446520 cuda_h.py:19] end gpu_experts cost 0.0026319026947021484 seconds
DEBUG 01-15 10:09:35.446291.446291 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.06011319160461426 seconds
DEBUG 01-15 10:09:35.446133.446133 cuda_h.py:19] end prefill_layer cost 0.06736040115356445 seconds
DEBUG 01-15 10:09:35.446149.446149 lmp.py:1552] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-15 10:09:35.446275.446275 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.446117.446117 lmp.py:1495] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-15 10:09:35.446197.446197 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:35.446377.446377 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:35.446128.446128 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.5762786865234375e-05 seconds
DEBUG 01-15 10:09:35.446592.446592 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.461143493652344e-05 seconds
DEBUG 01-15 10:09:35.446334.446334 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.446297.446297 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.447459.447459 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.447859.447859 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.447087.447087 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.447723.447723 cuda_h.py:19] end allocate_cuda_memory cost 0.0001862049102783203 seconds
DEBUG 01-15 10:09:35.447858.447858 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.447475.447475 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.447543.447543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.447583.447583 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0aa42713-b1f9-40ed-a8cd-86bda0af5a91
DEBUG 01-15 10:09:35.447143.447143 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.448981.448981 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.448241.448241 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0aa42713-b1f9-40ed-a8cd-86bda0af5a91
DEBUG 01-15 10:09:35.448780.448780 cuda_h.py:19] end load_into_gpu_async cost 0.0012068748474121094 seconds
DEBUG 01-15 10:09:35.448112.448112 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.448414.448414 cuda_h.py:19] end restore_tensors2 cost 8.416175842285156e-05 seconds
DEBUG 01-15 10:09:35.448880.448880 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017709732055664062 seconds
INFO 01-15 10:09:35.449359.449359 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0aa42713-b1f9-40ed-a8cd-86bda0af5a91
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.451908.451908 cuda_h.py:19] end self_attn cost 0.0038840770721435547 seconds
DEBUG 01-15 10:09:35.452773.452773 cuda_h.py:19] end iln_self_attn_paln cost 0.005349397659301758 seconds
DEBUG 01-15 10:09:35.452185.452185 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-15 10:09:35.452061.452061 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.453900.453900 cuda_h.py:19] end gate cost 0.0006837844848632812 seconds
DEBUG 01-15 10:09:35.453114.453114 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.453078.453078 lmp.py:1616] 
DEBUG 01-15 10:09:35.453078.453078 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.453311.453311 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.453438.453438 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.453750.453750 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.453108.453108 lmp.py:1620] 
DEBUG 01-15 10:09:35.453108.453108 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.453612.453612 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.453639.453639 lmp.py:1626]   Expert 58 |     51 | CPU
DEBUG 01-15 10:09:35.453236.453236 lmp.py:1626]   Expert 27 |     56 | CPU
DEBUG 01-15 10:09:35.453355.453355 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:35.453998.453998 lmp.py:1626]   Expert 17 |     84 | CPU
DEBUG 01-15 10:09:35.453165.453165 lmp.py:1626]   Expert  0 |     88 | CPU
DEBUG 01-15 10:09:35.453331.453331 lmp.py:1626]   Expert 24 |     88 | CPU
DEBUG 01-15 10:09:35.453497.453497 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:35.453663.453663 lmp.py:1626]   Expert 34 |    114 | CPU
DEBUG 01-15 10:09:35.453306.453306 lmp.py:1626]   Expert 51 |    118 | CPU
DEBUG 01-15 10:09:35.453426.453426 lmp.py:1626]   Expert 32 |    120 | CPU
DEBUG 01-15 10:09:35.453069.453069 lmp.py:1626]   Expert  9 |    129 | CPU
DEBUG 01-15 10:09:35.453189.453189 lmp.py:1626]   Expert 23 |    135 | CPU
DEBUG 01-15 10:09:35.453308.453308 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:35.453951.453951 lmp.py:1626]   Expert 15 |    136 | CPU
DEBUG 01-15 10:09:35.453879.453879 lmp.py:1626]   Expert 26 |    138 | CPU
DEBUG 01-15 10:09:35.453568.453568 lmp.py:1626]   Expert 30 |    144 | CPU
DEBUG 01-15 10:09:35.453734.453734 lmp.py:1626]   Expert 45 |    146 | CPU
DEBUG 01-15 10:09:35.453662.453662 lmp.py:1626]   Expert 62 |    147 | CPU
DEBUG 01-15 10:09:35.453352.453352 lmp.py:1626]   Expert 57 |    149 | CPU
DEBUG 01-15 10:09:35.453279.453279 lmp.py:1626]   Expert  1 |    152 | CPU
DEBUG 01-15 10:09:35.453207.453207 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:35.453565.453565 lmp.py:1626]   Expert  8 |    159 | CPU
DEBUG 01-15 10:09:35.454208.454208 lmp.py:1626]   Expert 29 |    160 | CPU
DEBUG 01-15 10:09:35.454851.454851 lmp.py:1626]   Expert 25 |    165 | CPU
DEBUG 01-15 10:09:35.454256.454256 lmp.py:1626]   Expert 54 |    166 | CPU
DEBUG 01-15 10:09:35.454899.454899 lmp.py:1626]   Expert  6 |    171 | CPU
DEBUG 01-15 10:09:35.454065.454065 lmp.py:1626]   Expert 49 |    171 | CPU
DEBUG 01-15 10:09:35.454469.454469 lmp.py:1626]   Expert 48 |    173 | CPU
DEBUG 01-15 10:09:35.454397.454397 lmp.py:1626]   Expert 12 |    176 | CPU
DEBUG 01-15 10:09:35.454086.454086 lmp.py:1626]   Expert 35 |    176 | CPU
DEBUG 01-15 10:09:35.454014.454014 lmp.py:1626]   Expert 37 |    178 | CPU
DEBUG 01-15 10:09:35.454942.454942 lmp.py:1626]   Expert 60 |    186 | CPU
DEBUG 01-15 10:09:35.454870.454870 lmp.py:1626]   Expert 13 |    188 | GPU
DEBUG 01-15 10:09:35.454320.454320 lmp.py:1626]   Expert 33 |    189 | GPU
DEBUG 01-15 10:09:35.454679.454679 lmp.py:1626]   Expert 53 |    189 | GPU
DEBUG 01-15 10:09:35.454083.454083 lmp.py:1626]   Expert 16 |    194 | GPU
DEBUG 01-15 10:09:35.454488.454488 lmp.py:1626]   Expert 10 |    195 | GPU
DEBUG 01-15 10:09:35.454131.454131 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:35.454774.454774 lmp.py:1626]   Expert 40 |    200 | GPU
DEBUG 01-15 10:09:35.454701.454701 lmp.py:1626]   Expert 43 |    202 | GPU
DEBUG 01-15 10:09:35.454629.454629 lmp.py:1626]   Expert 38 |    204 | GPU
DEBUG 01-15 10:09:35.454080.454080 lmp.py:1626]   Expert  5 |    208 | GPU
DEBUG 01-15 10:09:35.454008.454008 lmp.py:1626]   Expert 44 |    216 | GPU
DEBUG 01-15 10:09:35.454174.454174 lmp.py:1626]   Expert 19 |    217 | GPU
DEBUG 01-15 10:09:35.454102.454102 lmp.py:1626]   Expert 50 |    217 | GPU
DEBUG 01-15 10:09:35.454268.454268 lmp.py:1626]   Expert 41 |    218 | GPU
DEBUG 01-15 10:09:35.454586.454586 lmp.py:1626]   Expert 52 |    218 | GPU
DEBUG 01-15 10:09:35.454991.454991 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:35.454919.454919 lmp.py:1626]   Expert 59 |    223 | GPU
DEBUG 01-15 10:09:35.454846.454846 lmp.py:1626]   Expert 55 |    233 | GPU
DEBUG 01-15 10:09:35.454820.454820 lmp.py:1626]   Expert 31 |    241 | GPU
DEBUG 01-15 10:09:35.454033.454033 lmp.py:1626]   Expert 56 |    241 | GPU
DEBUG 01-15 10:09:35.454245.454245 lmp.py:1626]   Expert 20 |    251 | GPU
DEBUG 01-15 10:09:35.454981.454981 lmp.py:1626]   Expert 39 |    252 | GPU
DEBUG 01-15 10:09:35.454955.454955 lmp.py:1626]   Expert 22 |    265 | GPU
DEBUG 01-15 10:09:35.454929.454929 lmp.py:1626]   Expert  2 |    267 | GPU
DEBUG 01-15 10:09:35.454142.454142 lmp.py:1626]   Expert 47 |    276 | GPU
DEBUG 01-15 10:09:35.454116.454116 lmp.py:1626]   Expert 63 |    276 | GPU
DEBUG 01-15 10:09:35.454851.454851 lmp.py:1626]   Expert 42 |    303 | GPU
DEBUG 01-15 10:09:35.454064.454064 lmp.py:1626]   Expert 18 |    314 | GPU
DEBUG 01-15 10:09:35.454991.454991 lmp.py:1626]   Expert 14 |    317 | GPU
DEBUG 01-15 10:09:35.454204.454204 lmp.py:1626]   Expert 46 |    367 | GPU
DEBUG 01-15 10:09:35.454893.454893 lmp.py:1626]   Expert 11 |    388 | GPU
DEBUG 01-15 10:09:35.454821.454821 lmp.py:1626]   Expert 61 |    460 | GPU
DEBUG 01-15 10:09:35.454987.454987 lmp.py:1627] 
DEBUG 01-15 10:09:35.454987.454987 lmp.py:1627]   CPU total tokens: 4340 (35.3%)
DEBUG 01-15 10:09:35.454153.454153 lmp.py:1628]   GPU total tokens: 7948 (64.7%)
DEBUG 01-15 10:09:35.454611.454611 cuda_h.py:19] end experts_map_get cost 0.0015673637390136719 seconds
DEBUG 01-15 10:09:35.454414.454414 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.454409.454409 lmp.py:1636] 
DEBUG 01-15 10:09:35.454409.454409 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.454298.454298 cuda_h.py:19] end cpu_experts_submit cost 6.127357482910156e-05 seconds
DEBUG 01-15 10:09:35.454041.454041 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.454970.454970 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.455525.455525 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.455367.455367 cuda_h.py:19] end allocate_cuda_memory cost 0.0001995563507080078 seconds
DEBUG 01-15 10:09:35.455131.455131 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.455503.455503 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.455504.455504 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.455061.455061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a19468d4-eac1-4cc6-9df1-c24b5ca2f6a9
DEBUG 01-15 10:09:35.455837.455837 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:35.456523.456523 client.py:127] Model loaded
DEBUG 01-15 10:09:35.456521.456521 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.456205.456205 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.456517.456517 cuda_h.py:19] end restore2model cost 0.00041604042053222656 seconds
DEBUG 01-15 10:09:35.456055.456055 cuda_h.py:19] end sllm_worker_task cost 0.009597301483154297 seconds
INFO 01-15 10:09:35.456797.456797 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a19468d4-eac1-4cc6-9df1-c24b5ca2f6a9
DEBUG 01-15 10:09:35.457786.457786 cuda_h.py:19] end load_into_gpu_async cost 0.0015401840209960938 seconds
DEBUG 01-15 10:09:35.457443.457443 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.457091.457091 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.457542.457542 cuda_h.py:19] end restore_tensors2 cost 0.0005719661712646484 seconds
DEBUG 01-15 10:09:35.457068.457068 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027170181274414062 seconds
DEBUG 01-15 10:09:35.457791.457791 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.458677.458677 cuda_h.py:19] end move_flatidxs cost 0.0010006427764892578 seconds
DEBUG 01-15 10:09:35.458837.458837 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.460812.460812 cuda_h.py:19] end restore2model cost 0.002759695053100586 seconds
DEBUG 01-15 10:09:35.460080.460080 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005694866180419922 seconds
DEBUG 01-15 10:09:35.460736.460736 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.461734.461734 cuda_h.py:19] end gpu_sexperts cost 0.0002834796905517578 seconds
DEBUG 01-15 10:09:35.461371.461371 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.462450.462450 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00153350830078125 seconds
DEBUG 01-15 10:09:35.463956.463956 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.463472.463472 cuda_h.py:19] end gpu_group_list cost 0.00031495094299316406 seconds
DEBUG 01-15 10:09:35.463012.463012 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.464893.464893 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007445812225341797 seconds
DEBUG 01-15 10:09:35.464100.464100 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.464115.464115 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-15 10:09:35.464049.464049 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.464879.464879 cuda_h.py:19] end group_tensors cost 0.006346225738525391 seconds
DEBUG 01-15 10:09:35.465173.465173 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.469125.469125 cuda_h.py:19] end group pad cost 0.0038347244262695312 seconds
DEBUG 01-15 10:09:35.469399.469399 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.488491.488491 cuda_h.py:19] end group_einsum cost 0.019068479537963867 seconds
DEBUG 01-15 10:09:35.488079.488079 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.493229.493229 cuda_h.py:19] end get_outputs_cpu1 cost 0.004815816879272461 seconds
DEBUG 01-15 10:09:35.494362.494362 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.037656545639038086 seconds
DEBUG 01-15 10:09:35.495937.495937 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0303800106048584 seconds
DEBUG 01-15 10:09:35.495902.495902 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.496607.496607 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.496137.496137 cuda_h.py:19] end index_scatter cost 9.703636169433594e-05 seconds
DEBUG 01-15 10:09:35.497570.497570 cuda_h.py:19] end cpuoutputsdeal cost 0.001375436782836914 seconds
DEBUG 01-15 10:09:35.497036.497036 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.497050.497050 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a19468d4-eac1-4cc6-9df1-c24b5ca2f6a9
INFO 01-15 10:09:35.508424.508424 client.py:127] Model loaded
DEBUG 01-15 10:09:35.508343.508343 cuda_h.py:19] end wait_experts cost 0.010918140411376953 seconds
DEBUG 01-15 10:09:35.508068.508068 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.508524.508524 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.508895.508895 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.508202.508202 cuda_h.py:19] end gpu_group_tensor cost 0.0002319812774658203 seconds
DEBUG 01-15 10:09:35.508604.508604 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.509265.509265 cuda_h.py:19] end gpu_group_einsum cost 0.0005102157592773438 seconds
DEBUG 01-15 10:09:35.509930.509930 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.509389.509389 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.509689.509689 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022912025451660156 seconds
DEBUG 01-15 10:09:35.509260.509260 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.510855.510855 cuda_h.py:19] end concat_expert_out cost 0.00032782554626464844 seconds
DEBUG 01-15 10:09:35.510818.510818 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.510146.510146 cuda_h.py:19] end index_scatter cost 6.270408630371094e-05 seconds
DEBUG 01-15 10:09:35.510855.510855 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008826255798339844 seconds
DEBUG 01-15 10:09:35.510561.510561 cuda_h.py:19] end gpu_experts cost 0.002161741256713867 seconds
DEBUG 01-15 10:09:35.510822.510822 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.05833697319030762 seconds
DEBUG 01-15 10:09:35.511137.511137 cuda_h.py:19] end prefill_layer cost 0.06447672843933105 seconds
DEBUG 01-15 10:09:35.511432.511432 lmp.py:1552] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-15 10:09:35.511844.511844 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.511732.511732 lmp.py:1495] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-15 10:09:35.511382.511382 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:35.511608.511608 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:35.511451.511451 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.6716461181640625e-05 seconds
DEBUG 01-15 10:09:35.511267.511267 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.867813110351562e-05 seconds
DEBUG 01-15 10:09:35.511386.511386 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.511753.511753 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.511704.511704 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.511381.511381 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.511783.511783 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.512606.512606 cuda_h.py:19] end allocate_cuda_memory cost 0.00021958351135253906 seconds
DEBUG 01-15 10:09:35.512118.512118 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.512112.512112 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.512412.512412 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.512684.512684 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cdecd047-1a73-4d12-b786-294ecc0dea9a
DEBUG 01-15 10:09:35.512191.512191 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.512731.512731 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.513304.513304 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cdecd047-1a73-4d12-b786-294ecc0dea9a
DEBUG 01-15 10:09:35.513333.513333 cuda_h.py:19] end load_into_gpu_async cost 0.0016357898712158203 seconds
DEBUG 01-15 10:09:35.513797.513797 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.514072.514072 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-15 10:09:35.514782.514782 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021636486053466797 seconds
INFO 01-15 10:09:35.514672.514672 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cdecd047-1a73-4d12-b786-294ecc0dea9a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.517551.517551 cuda_h.py:19] end self_attn cost 0.0050334930419921875 seconds
DEBUG 01-15 10:09:35.518251.518251 cuda_h.py:19] end iln_self_attn_paln cost 0.006531476974487305 seconds
DEBUG 01-15 10:09:35.518863.518863 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-15 10:09:35.518910.518910 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.519015.519015 cuda_h.py:19] end gate cost 0.0007083415985107422 seconds
DEBUG 01-15 10:09:35.519659.519659 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.519040.519040 lmp.py:1616] 
DEBUG 01-15 10:09:35.519040.519040 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.519273.519273 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.519161.519161 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.519712.519712 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.519355.519355 lmp.py:1620] 
DEBUG 01-15 10:09:35.519355.519355 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.519190.519190 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.519694.519694 lmp.py:1626]   Expert  1 |     50 | CPU
DEBUG 01-15 10:09:35.519813.519813 lmp.py:1626]   Expert 27 |     62 | CPU
DEBUG 01-15 10:09:35.519741.519741 lmp.py:1626]   Expert  7 |     74 | CPU
DEBUG 01-15 10:09:35.519430.519430 lmp.py:1626]   Expert 48 |     82 | CPU
DEBUG 01-15 10:09:35.519027.519027 lmp.py:1626]   Expert 15 |     98 | CPU
DEBUG 01-15 10:09:35.519908.519908 lmp.py:1626]   Expert 30 |    109 | CPU
DEBUG 01-15 10:09:35.519313.519313 lmp.py:1626]   Expert 61 |    115 | CPU
DEBUG 01-15 10:09:35.519718.519718 lmp.py:1626]   Expert 32 |    118 | CPU
DEBUG 01-15 10:09:35.519884.519884 lmp.py:1626]   Expert 45 |    118 | CPU
DEBUG 01-15 10:09:35.519004.519004 lmp.py:1626]   Expert 18 |    119 | CPU
DEBUG 01-15 10:09:35.519362.519362 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:35.519766.519766 lmp.py:1626]   Expert 39 |    135 | CPU
DEBUG 01-15 10:09:35.519986.519986 lmp.py:1626]   Expert 26 |    138 | CPU
DEBUG 01-15 10:09:35.519390.519390 lmp.py:1626]   Expert 36 |    138 | CPU
DEBUG 01-15 10:09:35.519841.519841 lmp.py:1626]   Expert  5 |    140 | CPU
DEBUG 01-15 10:09:35.519053.519053 lmp.py:1626]   Expert 11 |    141 | CPU
DEBUG 01-15 10:09:35.519266.519266 lmp.py:1626]   Expert  6 |    143 | CPU
DEBUG 01-15 10:09:35.519478.519478 lmp.py:1626]   Expert 59 |    144 | CPU
DEBUG 01-15 10:09:35.519691.519691 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:35.519426.519426 lmp.py:1626]   Expert 49 |    154 | CPU
DEBUG 01-15 10:09:35.519401.519401 lmp.py:1626]   Expert  2 |    156 | CPU
DEBUG 01-15 10:09:35.519851.519851 lmp.py:1626]   Expert 23 |    157 | CPU
DEBUG 01-15 10:09:35.519302.519302 lmp.py:1626]   Expert  9 |    158 | CPU
DEBUG 01-15 10:09:35.519992.519992 lmp.py:1626]   Expert 50 |    165 | CPU
DEBUG 01-15 10:09:35.519442.519442 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:35.519609.519609 lmp.py:1626]   Expert 56 |    168 | CPU
DEBUG 01-15 10:09:35.519821.519821 lmp.py:1626]   Expert 40 |    169 | CPU
DEBUG 01-15 10:09:35.520318.520318 lmp.py:1626]   Expert 16 |    173 | CPU
DEBUG 01-15 10:09:35.520292.520292 lmp.py:1626]   Expert 35 |    173 | CPU
DEBUG 01-15 10:09:35.520790.520790 lmp.py:1626]   Expert  4 |    185 | CPU
DEBUG 01-15 10:09:35.520764.520764 lmp.py:1626]   Expert 37 |    189 | CPU
DEBUG 01-15 10:09:35.520261.520261 lmp.py:1626]   Expert 13 |    191 | CPU
DEBUG 01-15 10:09:35.520235.520235 lmp.py:1626]   Expert 42 |    191 | GPU
DEBUG 01-15 10:09:35.520970.520970 lmp.py:1626]   Expert 17 |    197 | GPU
DEBUG 01-15 10:09:35.520421.520421 lmp.py:1626]   Expert 38 |    197 | GPU
DEBUG 01-15 10:09:35.520349.520349 lmp.py:1626]   Expert 62 |    199 | GPU
DEBUG 01-15 10:09:35.520038.520038 lmp.py:1626]   Expert 21 |    201 | GPU
DEBUG 01-15 10:09:35.520966.520966 lmp.py:1626]   Expert  3 |    208 | GPU
DEBUG 01-15 10:09:35.520940.520940 lmp.py:1626]   Expert 44 |    208 | GPU
DEBUG 01-15 10:09:35.520914.520914 lmp.py:1626]   Expert 28 |    212 | GPU
DEBUG 01-15 10:09:35.520650.520650 lmp.py:1626]   Expert 60 |    212 | GPU
DEBUG 01-15 10:09:35.520862.520862 lmp.py:1626]   Expert 58 |    213 | GPU
DEBUG 01-15 10:09:35.520598.520598 lmp.py:1626]   Expert 10 |    214 | GPU
DEBUG 01-15 10:09:35.520334.520334 lmp.py:1626]   Expert 47 |    214 | GPU
DEBUG 01-15 10:09:35.520308.520308 lmp.py:1626]   Expert 53 |    218 | GPU
DEBUG 01-15 10:09:35.520043.520043 lmp.py:1626]   Expert 55 |    219 | GPU
DEBUG 01-15 10:09:35.520256.520256 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:35.520707.520707 lmp.py:1626]   Expert 57 |    225 | GPU
DEBUG 01-15 10:09:35.520157.520157 lmp.py:1626]   Expert 33 |    228 | GPU
DEBUG 01-15 10:09:35.520085.520085 lmp.py:1626]   Expert 46 |    237 | GPU
DEBUG 01-15 10:09:35.520013.520013 lmp.py:1626]   Expert 31 |    238 | GPU
DEBUG 01-15 10:09:35.520716.520716 lmp.py:1626]   Expert  8 |    240 | GPU
DEBUG 01-15 10:09:35.520690.520690 lmp.py:1626]   Expert 19 |    243 | GPU
DEBUG 01-15 10:09:35.520664.520664 lmp.py:1626]   Expert 24 |    246 | GPU
DEBUG 01-15 10:09:35.520161.520161 lmp.py:1626]   Expert 14 |    262 | GPU
DEBUG 01-15 10:09:35.520135.520135 lmp.py:1626]   Expert 63 |    267 | GPU
DEBUG 01-15 10:09:35.520871.520871 lmp.py:1626]   Expert 12 |    276 | GPU
DEBUG 01-15 10:09:35.520083.520083 lmp.py:1626]   Expert 29 |    276 | GPU
DEBUG 01-15 10:09:35.520057.520057 lmp.py:1626]   Expert 22 |    278 | GPU
DEBUG 01-15 10:09:35.520508.520508 lmp.py:1626]   Expert  0 |    294 | GPU
DEBUG 01-15 10:09:35.520244.520244 lmp.py:1626]   Expert 43 |    310 | GPU
DEBUG 01-15 10:09:35.520695.520695 lmp.py:1626]   Expert 54 |    340 | GPU
DEBUG 01-15 10:09:35.520384.520384 lmp.py:1626]   Expert 41 |    384 | GPU
DEBUG 01-15 10:09:35.520835.520835 lmp.py:1626]   Expert 25 |    410 | GPU
DEBUG 01-15 10:09:35.520716.520716 lmp.py:1627] 
DEBUG 01-15 10:09:35.520716.520716 lmp.py:1627]   CPU total tokens: 4408 (35.9%)
DEBUG 01-15 10:09:35.520836.520836 lmp.py:1628]   GPU total tokens: 7880 (64.1%)
DEBUG 01-15 10:09:35.520168.520168 cuda_h.py:19] end experts_map_get cost 0.0015401840209960938 seconds
DEBUG 01-15 10:09:35.520925.520925 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.520536.520536 lmp.py:1636] 
DEBUG 01-15 10:09:35.520536.520536 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.520948.520948 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-15 10:09:35.520075.520075 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.520626.520626 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.521221.521221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.521501.521501 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-15 10:09:35.521827.521827 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.521491.521491 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.521446.521446 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.521480.521480 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3362d9d8-35d5-43fb-adf0-50e942e954b3
DEBUG 01-15 10:09:35.521924.521924 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:35.522721.522721 client.py:127] Model loaded
DEBUG 01-15 10:09:35.522518.522518 cuda_h.py:10] start restore2model
INFO 01-15 10:09:35.522031.522031 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3362d9d8-35d5-43fb-adf0-50e942e954b3
DEBUG 01-15 10:09:35.522219.522219 cuda_h.py:19] end load_into_gpu_async cost 0.0013744831085205078 seconds
DEBUG 01-15 10:09:35.522783.522783 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.522532.522532 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.523313.523313 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.523042.523042 cuda_h.py:19] end restore_tensors2 cost 0.0005826950073242188 seconds
DEBUG 01-15 10:09:35.523998.523998 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025663375854492188 seconds
DEBUG 01-15 10:09:35.523436.523436 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.524178.524178 cuda_h.py:19] end restore2model cost 0.0005464553833007812 seconds
DEBUG 01-15 10:09:35.524274.524274 cuda_h.py:19] end sllm_worker_task cost 0.012430429458618164 seconds
DEBUG 01-15 10:09:35.524541.524541 cuda_h.py:19] end move_flatidxs cost 0.0010030269622802734 seconds
DEBUG 01-15 10:09:35.524907.524907 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.526302.526302 cuda_h.py:19] end restore2model cost 0.0032711029052734375 seconds
DEBUG 01-15 10:09:35.526848.526848 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0060579776763916016 seconds
DEBUG 01-15 10:09:35.526836.526836 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.527416.527416 cuda_h.py:19] end gpu_sexperts cost 0.0002903938293457031 seconds
DEBUG 01-15 10:09:35.527252.527252 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.529118.529118 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016851425170898438 seconds
DEBUG 01-15 10:09:35.529387.529387 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.530420.530420 cuda_h.py:19] end gpu_group_list cost 0.0003437995910644531 seconds
DEBUG 01-15 10:09:35.530219.530219 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.531994.531994 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007388591766357422 seconds
DEBUG 01-15 10:09:35.530600.530600 cuda_h.py:19] end group_tensors cost 0.0062236785888671875 seconds
DEBUG 01-15 10:09:35.531347.531347 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.531984.531984 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8835067749023438e-05 seconds
DEBUG 01-15 10:09:35.531395.531395 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.531694.531694 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.535355.535355 cuda_h.py:19] end group pad cost 0.0042591094970703125 seconds
DEBUG 01-15 10:09:35.535959.535959 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.557590.557590 cuda_h.py:19] end group_einsum cost 0.021892786026000977 seconds
DEBUG 01-15 10:09:35.557767.557767 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.562947.562947 cuda_h.py:19] end get_outputs_cpu1 cost 0.004905223846435547 seconds
DEBUG 01-15 10:09:35.563809.563809 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04080009460449219 seconds
DEBUG 01-15 10:09:35.564464.564464 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.033217668533325195 seconds
DEBUG 01-15 10:09:35.565562.565562 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.565339.565339 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.565471.565471 cuda_h.py:19] end index_scatter cost 8.845329284667969e-05 seconds
DEBUG 01-15 10:09:35.566737.566737 cuda_h.py:19] end cpuoutputsdeal cost 0.001295328140258789 seconds
DEBUG 01-15 10:09:35.566427.566427 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.566157.566157 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3362d9d8-35d5-43fb-adf0-50e942e954b3
INFO 01-15 10:09:35.573321.573321 client.py:127] Model loaded
DEBUG 01-15 10:09:35.573363.573363 cuda_h.py:19] end wait_experts cost 0.006554603576660156 seconds
DEBUG 01-15 10:09:35.573165.573165 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.573353.573353 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.573255.573255 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.573879.573879 cuda_h.py:19] end gpu_group_tensor cost 0.00021409988403320312 seconds
DEBUG 01-15 10:09:35.573267.573267 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.574585.574585 cuda_h.py:19] end gpu_group_einsum cost 0.0005402565002441406 seconds
DEBUG 01-15 10:09:35.574403.574403 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.574617.574617 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.574454.574454 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002715587615966797 seconds
DEBUG 01-15 10:09:35.574018.574018 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.574518.574518 cuda_h.py:19] end concat_expert_out cost 5.412101745605469e-05 seconds
DEBUG 01-15 10:09:35.574215.574215 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.574523.574523 cuda_h.py:19] end index_scatter cost 5.1975250244140625e-05 seconds
DEBUG 01-15 10:09:35.574901.574901 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006105899810791016 seconds
DEBUG 01-15 10:09:35.575050.575050 cuda_h.py:19] end gpu_experts cost 0.0018546581268310547 seconds
DEBUG 01-15 10:09:35.575436.575436 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.05685234069824219 seconds
DEBUG 01-15 10:09:35.575915.575915 cuda_h.py:19] end prefill_layer cost 0.06421160697937012 seconds
DEBUG 01-15 10:09:35.575454.575454 lmp.py:1552] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-15 10:09:35.575581.575581 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.575469.575469 lmp.py:1495] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-15 10:09:35.575649.575649 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:35.575497.575497 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:35.575625.575625 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.361701965332031e-05 seconds
DEBUG 01-15 10:09:35.575659.575659 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.103515625e-05 seconds
DEBUG 01-15 10:09:35.575494.575494 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.575503.575503 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.576103.576103 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.576450.576450 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.576545.576545 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.576179.576179 cuda_h.py:19] end allocate_cuda_memory cost 0.0003116130828857422 seconds
DEBUG 01-15 10:09:35.576798.576798 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.576653.576653 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.576721.576721 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.576093.576093 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, da84c105-59c9-4c4c-89ac-018435b69b4c
DEBUG 01-15 10:09:35.576400.576400 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.577600.577600 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.577299.577299 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, da84c105-59c9-4c4c-89ac-018435b69b4c
DEBUG 01-15 10:09:35.577036.577036 cuda_h.py:19] end load_into_gpu_async cost 0.0009496212005615234 seconds
DEBUG 01-15 10:09:35.577070.577070 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.577398.577398 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-15 10:09:35.577677.577677 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001596212387084961 seconds
INFO 01-15 10:09:35.577083.577083 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, da84c105-59c9-4c4c-89ac-018435b69b4c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.580474.580474 cuda_h.py:19] end self_attn cost 0.003705739974975586 seconds
DEBUG 01-15 10:09:35.581604.581604 cuda_h.py:19] end iln_self_attn_paln cost 0.0052149295806884766 seconds
DEBUG 01-15 10:09:35.581970.581970 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-15 10:09:35.581587.581587 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.581332.581332 cuda_h.py:19] end gate cost 0.0006563663482666016 seconds
DEBUG 01-15 10:09:35.581069.581069 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.582304.582304 lmp.py:1616] 
DEBUG 01-15 10:09:35.582304.582304 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.582491.582491 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.582856.582856 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.582360.582360 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.582433.582433 lmp.py:1620] 
DEBUG 01-15 10:09:35.582433.582433 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.582699.582699 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.582726.582726 lmp.py:1626]   Expert 14 |     67 | CPU
DEBUG 01-15 10:09:35.582846.582846 lmp.py:1626]   Expert 57 |     72 | CPU
DEBUG 01-15 10:09:35.582489.582489 lmp.py:1626]   Expert 13 |     74 | CPU
DEBUG 01-15 10:09:35.582132.582132 lmp.py:1626]   Expert 26 |     79 | CPU
DEBUG 01-15 10:09:35.582536.582536 lmp.py:1626]   Expert 31 |     90 | CPU
DEBUG 01-15 10:09:35.582702.582702 lmp.py:1626]   Expert 54 |     91 | CPU
DEBUG 01-15 10:09:35.582107.582107 lmp.py:1626]   Expert 45 |     92 | CPU
DEBUG 01-15 10:09:35.582512.582512 lmp.py:1626]   Expert 11 |     94 | CPU
DEBUG 01-15 10:09:35.582678.582678 lmp.py:1626]   Expert 58 |    100 | CPU
DEBUG 01-15 10:09:35.582082.582082 lmp.py:1626]   Expert 30 |    107 | CPU
DEBUG 01-15 10:09:35.582487.582487 lmp.py:1626]   Expert 51 |    109 | CPU
DEBUG 01-15 10:09:35.582083.582083 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:35.582680.582680 lmp.py:1626]   Expert 10 |    114 | CPU
DEBUG 01-15 10:09:35.582846.582846 lmp.py:1626]   Expert 32 |    115 | CPU
DEBUG 01-15 10:09:35.582012.582012 lmp.py:1626]   Expert 20 |    127 | CPU
DEBUG 01-15 10:09:35.582417.582417 lmp.py:1626]   Expert  8 |    135 | CPU
DEBUG 01-15 10:09:35.582583.582583 lmp.py:1626]   Expert  4 |    137 | CPU
DEBUG 01-15 10:09:35.582272.582272 lmp.py:1626]   Expert 63 |    137 | CPU
DEBUG 01-15 10:09:35.582439.582439 lmp.py:1626]   Expert 53 |    141 | CPU
DEBUG 01-15 10:09:35.582128.582128 lmp.py:1626]   Expert 34 |    144 | CPU
DEBUG 01-15 10:09:35.582056.582056 lmp.py:1626]   Expert 61 |    145 | CPU
DEBUG 01-15 10:09:35.582222.582222 lmp.py:1626]   Expert 16 |    148 | CPU
DEBUG 01-15 10:09:35.582149.582149 lmp.py:1626]   Expert 47 |    148 | CPU
DEBUG 01-15 10:09:35.582316.582316 lmp.py:1626]   Expert 28 |    158 | CPU
DEBUG 01-15 10:09:35.582197.582197 lmp.py:1626]   Expert 60 |    158 | CPU
DEBUG 01-15 10:09:35.582555.582555 lmp.py:1626]   Expert 17 |    162 | CPU
DEBUG 01-15 10:09:35.582390.582390 lmp.py:1626]   Expert 42 |    164 | CPU
DEBUG 01-15 10:09:35.582556.582556 lmp.py:1626]   Expert 44 |    170 | CPU
DEBUG 01-15 10:09:35.582723.582723 lmp.py:1626]   Expert 29 |    171 | CPU
DEBUG 01-15 10:09:35.582173.582173 lmp.py:1626]   Expert 27 |    174 | CPU
DEBUG 01-15 10:09:35.582340.582340 lmp.py:1626]   Expert  7 |    176 | CPU
DEBUG 01-15 10:09:35.582029.582029 lmp.py:1626]   Expert 41 |    179 | CPU
DEBUG 01-15 10:09:35.582957.582957 lmp.py:1626]   Expert  9 |    183 | GPU
DEBUG 01-15 10:09:35.582884.582884 lmp.py:1626]   Expert 48 |    184 | GPU
DEBUG 01-15 10:09:35.583812.583812 lmp.py:1626]   Expert 56 |    184 | GPU
DEBUG 01-15 10:09:35.583078.583078 lmp.py:1626]   Expert  3 |    188 | GPU
DEBUG 01-15 10:09:35.583482.583482 lmp.py:1626]   Expert  2 |    190 | GPU
DEBUG 01-15 10:09:35.583695.583695 lmp.py:1626]   Expert 15 |    191 | GPU
DEBUG 01-15 10:09:35.583007.583007 lmp.py:1626]   Expert  0 |    194 | GPU
DEBUG 01-15 10:09:35.583457.583457 lmp.py:1626]   Expert 24 |    194 | GPU
DEBUG 01-15 10:09:35.583193.583193 lmp.py:1626]   Expert 18 |    200 | GPU
DEBUG 01-15 10:09:35.583167.583167 lmp.py:1626]   Expert 55 |    208 | GPU
DEBUG 01-15 10:09:35.583903.583903 lmp.py:1626]   Expert 40 |    214 | GPU
DEBUG 01-15 10:09:35.583877.583877 lmp.py:1626]   Expert 22 |    216 | GPU
DEBUG 01-15 10:09:35.583612.583612 lmp.py:1626]   Expert 38 |    216 | GPU
DEBUG 01-15 10:09:35.583586.583586 lmp.py:1626]   Expert 23 |    217 | GPU
DEBUG 01-15 10:09:35.583084.583084 lmp.py:1626]   Expert  6 |    223 | GPU
DEBUG 01-15 10:09:35.583296.583296 lmp.py:1626]   Expert 37 |    223 | GPU
DEBUG 01-15 10:09:35.583509.583509 lmp.py:1626]   Expert 46 |    232 | GPU
DEBUG 01-15 10:09:35.583582.583582 lmp.py:1626]   Expert 19 |    243 | GPU
DEBUG 01-15 10:09:35.583225.583225 lmp.py:1626]   Expert 39 |    248 | GPU
DEBUG 01-15 10:09:35.583868.583868 lmp.py:1626]   Expert 25 |    251 | GPU
DEBUG 01-15 10:09:35.583080.583080 lmp.py:1626]   Expert 50 |    257 | GPU
DEBUG 01-15 10:09:35.583293.583293 lmp.py:1626]   Expert 12 |    261 | GPU
DEBUG 01-15 10:09:35.583029.583029 lmp.py:1626]   Expert 62 |    271 | GPU
DEBUG 01-15 10:09:35.583003.583003 lmp.py:1626]   Expert 21 |    279 | GPU
DEBUG 01-15 10:09:35.583215.583215 lmp.py:1626]   Expert 35 |    286 | GPU
DEBUG 01-15 10:09:35.583951.583951 lmp.py:1626]   Expert 49 |    291 | GPU
DEBUG 01-15 10:09:35.583925.583925 lmp.py:1626]   Expert 52 |    298 | GPU
DEBUG 01-15 10:09:35.583660.583660 lmp.py:1626]   Expert 33 |    300 | GPU
DEBUG 01-15 10:09:35.583111.583111 lmp.py:1626]   Expert  1 |    348 | GPU
DEBUG 01-15 10:09:35.583324.583324 lmp.py:1626]   Expert  5 |    385 | GPU
DEBUG 01-15 10:09:35.583298.583298 lmp.py:1626]   Expert 43 |    437 | GPU
DEBUG 01-15 10:09:35.583464.583464 lmp.py:1626]   Expert 59 |    585 | GPU
DEBUG 01-15 10:09:35.583061.583061 lmp.py:1627] 
DEBUG 01-15 10:09:35.583061.583061 lmp.py:1627]   CPU total tokens: 4091 (33.3%)
DEBUG 01-15 10:09:35.583465.583465 lmp.py:1628]   GPU total tokens: 8197 (66.7%)
DEBUG 01-15 10:09:35.583684.583684 cuda_h.py:19] end experts_map_get cost 0.00154876708984375 seconds
DEBUG 01-15 10:09:35.583912.583912 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.583091.583091 lmp.py:1636] 
DEBUG 01-15 10:09:35.583091.583091 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.583835.583835 cuda_h.py:19] end cpu_experts_submit cost 5.602836608886719e-05 seconds
DEBUG 01-15 10:09:35.583054.583054 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.583652.583652 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.583571.583571 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.584988.584988 cuda_h.py:19] end allocate_cuda_memory cost 0.00027060508728027344 seconds
DEBUG 01-15 10:09:35.584375.584375 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.584415.584415 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.584463.584463 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.584358.584358 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cbf67c8a-059f-4d70-9198-e550bc5192f5
DEBUG 01-15 10:09:35.584976.584976 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:35.584645.584645 client.py:127] Model loaded
DEBUG 01-15 10:09:35.585728.585728 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.585682.585682 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.584997.584997 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.585664.585664 cuda_h.py:19] end restore2model cost 0.0005788803100585938 seconds
DEBUG 01-15 10:09:35.585474.585474 cuda_h.py:19] end sllm_worker_task cost 0.009645462036132812 seconds
DEBUG 01-15 10:09:35.585619.585619 cuda_h.py:19] end move_flatidxs cost 0.0008399486541748047 seconds
DEBUG 01-15 10:09:35.586734.586734 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:35.586907.586907 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cbf67c8a-059f-4d70-9198-e550bc5192f5
DEBUG 01-15 10:09:35.586135.586135 cuda_h.py:19] end load_into_gpu_async cost 0.0018963813781738281 seconds
DEBUG 01-15 10:09:35.586268.586268 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.587850.587850 cuda_h.py:19] end restore_tensors2 cost 0.0005421638488769531 seconds
DEBUG 01-15 10:09:35.587945.587945 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033872127532958984 seconds
DEBUG 01-15 10:09:35.587092.587092 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.589423.589423 cuda_h.py:19] end restore2model cost 0.002740144729614258 seconds
DEBUG 01-15 10:09:35.590009.590009 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006331920623779297 seconds
DEBUG 01-15 10:09:35.590566.590566 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.590510.590510 cuda_h.py:19] end gpu_sexperts cost 0.0002808570861816406 seconds
DEBUG 01-15 10:09:35.590909.590909 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.591955.591955 cuda_h.py:19] end group_tensors cost 0.005173921585083008 seconds
DEBUG 01-15 10:09:35.591349.591349 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.592220.592220 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001529693603515625 seconds
DEBUG 01-15 10:09:35.593627.593627 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.593323.593323 cuda_h.py:19] end gpu_group_list cost 0.0005133152008056641 seconds
DEBUG 01-15 10:09:35.594454.594454 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.595594.595594 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011310577392578125 seconds
DEBUG 01-15 10:09:35.595457.595457 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.595346.595346 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0503997802734375e-05 seconds
DEBUG 01-15 10:09:35.595049.595049 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.595012.595012 cuda_h.py:19] end group pad cost 0.0039103031158447266 seconds
DEBUG 01-15 10:09:35.595471.595471 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.614056.614056 cuda_h.py:19] end group_einsum cost 0.01839447021484375 seconds
DEBUG 01-15 10:09:35.614771.614771 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.619064.619064 cuda_h.py:19] end get_outputs_cpu1 cost 0.004893302917480469 seconds
DEBUG 01-15 10:09:35.620349.620349 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.035567522048950195 seconds
DEBUG 01-15 10:09:35.621603.621603 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.02635931968688965 seconds
DEBUG 01-15 10:09:35.621442.621442 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.622553.622553 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.622645.622645 cuda_h.py:19] end index_scatter cost 9.131431579589844e-05 seconds
DEBUG 01-15 10:09:35.623623.623623 cuda_h.py:19] end cpuoutputsdeal cost 0.0012121200561523438 seconds
DEBUG 01-15 10:09:35.623466.623466 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.623474.623474 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cbf67c8a-059f-4d70-9198-e550bc5192f5
INFO 01-15 10:09:35.637511.637511 client.py:127] Model loaded
DEBUG 01-15 10:09:35.637805.637805 cuda_h.py:19] end wait_experts cost 0.014646530151367188 seconds
DEBUG 01-15 10:09:35.638892.638892 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.638312.638312 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.638637.638637 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.638285.638285 cuda_h.py:19] end gpu_group_tensor cost 0.0005071163177490234 seconds
DEBUG 01-15 10:09:35.638892.638892 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.639249.639249 cuda_h.py:19] end gpu_group_einsum cost 0.0009152889251708984 seconds
DEBUG 01-15 10:09:35.639219.639219 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.639155.639155 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.640376.640376 cuda_h.py:19] end all_expert_outputs_slices cost 0.00023627281188964844 seconds
DEBUG 01-15 10:09:35.640417.640417 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.640301.640301 cuda_h.py:19] end concat_expert_out cost 5.8650970458984375e-05 seconds
DEBUG 01-15 10:09:35.640462.640462 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.640684.640684 cuda_h.py:19] end index_scatter cost 6.175041198730469e-05 seconds
DEBUG 01-15 10:09:35.640678.640678 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006127357482910156 seconds
DEBUG 01-15 10:09:35.640449.640449 cuda_h.py:19] end gpu_experts cost 0.0025620460510253906 seconds
DEBUG 01-15 10:09:35.640704.640704 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.0594637393951416 seconds
DEBUG 01-15 10:09:35.641216.641216 cuda_h.py:19] end prefill_layer cost 0.06543421745300293 seconds
DEBUG 01-15 10:09:35.641677.641677 lmp.py:1552] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-15 10:09:35.641088.641088 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.641499.641499 lmp.py:1495] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-15 10:09:35.641103.641103 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:35.641329.641329 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:35.641410.641410 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.62396240234375e-05 seconds
DEBUG 01-15 10:09:35.641305.641305 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.628036499023438e-05 seconds
DEBUG 01-15 10:09:35.641617.641617 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.641639.641639 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.641616.641616 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.641240.641240 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.641973.641973 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.642021.642021 cuda_h.py:19] end allocate_cuda_memory cost 0.00020647048950195312 seconds
DEBUG 01-15 10:09:35.642977.642977 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.642554.642554 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.642344.642344 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.642531.642531 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22c5be6a-4b40-40f3-a54a-03783bf10ed6
DEBUG 01-15 10:09:35.642786.642786 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.642384.642384 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.643690.643690 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22c5be6a-4b40-40f3-a54a-03783bf10ed6
DEBUG 01-15 10:09:35.643296.643296 cuda_h.py:19] end load_into_gpu_async cost 0.001177072525024414 seconds
DEBUG 01-15 10:09:35.643820.643820 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.643122.643122 cuda_h.py:19] end restore_tensors2 cost 8.249282836914062e-05 seconds
DEBUG 01-15 10:09:35.643746.643746 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017497539520263672 seconds
INFO 01-15 10:09:35.643450.643450 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22c5be6a-4b40-40f3-a54a-03783bf10ed6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.645193.645193 cuda_h.py:19] end self_attn cost 0.0033071041107177734 seconds
DEBUG 01-15 10:09:35.646461.646461 cuda_h.py:19] end iln_self_attn_paln cost 0.0048084259033203125 seconds
DEBUG 01-15 10:09:35.646496.646496 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-15 10:09:35.646875.646875 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.647310.647310 cuda_h.py:19] end gate cost 0.0007102489471435547 seconds
DEBUG 01-15 10:09:35.647239.647239 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.647753.647753 lmp.py:1616] 
DEBUG 01-15 10:09:35.647753.647753 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.647032.647032 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.647443.647443 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.647471.647471 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.647114.647114 lmp.py:1620] 
DEBUG 01-15 10:09:35.647114.647114 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.647949.647949 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.647545.647545 lmp.py:1626]   Expert 34 |     24 | CPU
DEBUG 01-15 10:09:35.647711.647711 lmp.py:1626]   Expert 45 |     65 | CPU
DEBUG 01-15 10:09:35.647401.647401 lmp.py:1626]   Expert 22 |     74 | CPU
DEBUG 01-15 10:09:35.647613.647613 lmp.py:1626]   Expert 57 |     75 | CPU
DEBUG 01-15 10:09:35.647302.647302 lmp.py:1626]   Expert 17 |     95 | CPU
DEBUG 01-15 10:09:35.647992.647992 lmp.py:1626]   Expert  4 |     99 | CPU
DEBUG 01-15 10:09:35.647443.647443 lmp.py:1626]   Expert 15 |     99 | CPU
DEBUG 01-15 10:09:35.647655.647655 lmp.py:1626]   Expert 28 |    106 | CPU
DEBUG 01-15 10:09:35.647106.647106 lmp.py:1626]   Expert 60 |    111 | CPU
DEBUG 01-15 10:09:35.647511.647511 lmp.py:1626]   Expert 32 |    112 | CPU
DEBUG 01-15 10:09:35.647723.647723 lmp.py:1626]   Expert 36 |    124 | CPU
DEBUG 01-15 10:09:35.647697.647697 lmp.py:1626]   Expert 14 |    126 | CPU
DEBUG 01-15 10:09:35.647546.647546 lmp.py:1626]   Expert 16 |    127 | CPU
DEBUG 01-15 10:09:35.647666.647666 lmp.py:1626]   Expert 12 |    128 | CPU
DEBUG 01-15 10:09:35.647355.647355 lmp.py:1626]   Expert 52 |    130 | CPU
DEBUG 01-15 10:09:35.647329.647329 lmp.py:1626]   Expert 25 |    131 | CPU
DEBUG 01-15 10:09:35.647541.647541 lmp.py:1626]   Expert  8 |    135 | CPU
DEBUG 01-15 10:09:35.647754.647754 lmp.py:1626]   Expert  2 |    139 | CPU
DEBUG 01-15 10:09:35.647728.647728 lmp.py:1626]   Expert 35 |    143 | CPU
DEBUG 01-15 10:09:35.647179.647179 lmp.py:1626]   Expert  5 |    148 | CPU
DEBUG 01-15 10:09:35.647630.647630 lmp.py:1626]   Expert 23 |    155 | CPU
DEBUG 01-15 10:09:35.647365.647365 lmp.py:1626]   Expert 30 |    155 | CPU
DEBUG 01-15 10:09:35.648578.648578 lmp.py:1626]   Expert 39 |    157 | CPU
DEBUG 01-15 10:09:35.648029.648029 lmp.py:1626]   Expert 61 |    157 | CPU
DEBUG 01-15 10:09:35.648672.648672 lmp.py:1626]   Expert  0 |    159 | CPU
DEBUG 01-15 10:09:35.648983.648983 lmp.py:1626]   Expert  3 |    168 | CPU
DEBUG 01-15 10:09:35.648388.648388 lmp.py:1626]   Expert 13 |    169 | CPU
DEBUG 01-15 10:09:35.648839.648839 lmp.py:1626]   Expert 31 |    172 | CPU
DEBUG 01-15 10:09:35.648813.648813 lmp.py:1626]   Expert 42 |    172 | CPU
DEBUG 01-15 10:09:35.648310.648310 lmp.py:1626]   Expert 41 |    176 | CPU
DEBUG 01-15 10:09:35.648284.648284 lmp.py:1626]   Expert 44 |    176 | CPU
DEBUG 01-15 10:09:35.648020.648020 lmp.py:1626]   Expert 46 |    177 | CPU
DEBUG 01-15 10:09:35.648471.648471 lmp.py:1626]   Expert  9 |    178 | GPU
DEBUG 01-15 10:09:35.648683.648683 lmp.py:1626]   Expert 43 |    181 | GPU
DEBUG 01-15 10:09:35.648419.648419 lmp.py:1626]   Expert 26 |    192 | GPU
DEBUG 01-15 10:09:35.648631.648631 lmp.py:1626]   Expert 50 |    193 | GPU
DEBUG 01-15 10:09:35.648082.648082 lmp.py:1626]   Expert 62 |    193 | GPU
DEBUG 01-15 10:09:35.648725.648725 lmp.py:1626]   Expert 18 |    194 | GPU
DEBUG 01-15 10:09:35.648130.648130 lmp.py:1626]   Expert 49 |    194 | GPU
DEBUG 01-15 10:09:35.648773.648773 lmp.py:1626]   Expert 51 |    195 | GPU
DEBUG 01-15 10:09:35.648224.648224 lmp.py:1626]   Expert 27 |    196 | GPU
DEBUG 01-15 10:09:35.648959.648959 lmp.py:1626]   Expert 11 |    198 | GPU
DEBUG 01-15 10:09:35.648933.648933 lmp.py:1626]   Expert 47 |    203 | GPU
DEBUG 01-15 10:09:35.648669.648669 lmp.py:1626]   Expert 19 |    205 | GPU
DEBUG 01-15 10:09:35.648643.648643 lmp.py:1626]   Expert 63 |    205 | GPU
DEBUG 01-15 10:09:35.648816.648816 lmp.py:1626]   Expert 20 |    208 | GPU
DEBUG 01-15 10:09:35.648267.648267 lmp.py:1626]   Expert 55 |    212 | GPU
DEBUG 01-15 10:09:35.648194.648194 lmp.py:1626]   Expert 56 |    212 | GPU
DEBUG 01-15 10:09:35.648645.648645 lmp.py:1626]   Expert 38 |    217 | GPU
DEBUG 01-15 10:09:35.648619.648619 lmp.py:1626]   Expert 48 |    226 | GPU
DEBUG 01-15 10:09:35.648785.648785 lmp.py:1626]   Expert  1 |    235 | GPU
DEBUG 01-15 10:09:35.648336.648336 lmp.py:1626]   Expert 10 |    240 | GPU
DEBUG 01-15 10:09:35.648886.648886 lmp.py:1626]   Expert 21 |    246 | GPU
DEBUG 01-15 10:09:35.648099.648099 lmp.py:1626]   Expert 54 |    247 | GPU
DEBUG 01-15 10:09:35.648311.648311 lmp.py:1626]   Expert  7 |    250 | GPU
DEBUG 01-15 10:09:35.648047.648047 lmp.py:1626]   Expert 33 |    256 | GPU
DEBUG 01-15 10:09:35.648021.648021 lmp.py:1626]   Expert 29 |    260 | GPU
DEBUG 01-15 10:09:35.648233.648233 lmp.py:1626]   Expert 40 |    264 | GPU
DEBUG 01-15 10:09:35.648207.648207 lmp.py:1626]   Expert 24 |    270 | GPU
DEBUG 01-15 10:09:35.648420.648420 lmp.py:1626]   Expert 59 |    298 | GPU
DEBUG 01-15 10:09:35.648394.648394 lmp.py:1626]   Expert 37 |    331 | GPU
DEBUG 01-15 10:09:35.648083.648083 lmp.py:1626]   Expert 58 |    364 | GPU
DEBUG 01-15 10:09:35.648534.648534 lmp.py:1626]   Expert  6 |    387 | GPU
DEBUG 01-15 10:09:35.648985.648985 lmp.py:1626]   Expert 53 |    854 | GPU
DEBUG 01-15 10:09:35.648105.648105 lmp.py:1627] 
DEBUG 01-15 10:09:35.648105.648105 lmp.py:1627]   CPU total tokens: 4184 (34.0%)
DEBUG 01-15 10:09:35.648224.648224 lmp.py:1628]   GPU total tokens: 8104 (66.0%)
DEBUG 01-15 10:09:35.648920.648920 cuda_h.py:19] end experts_map_get cost 0.0015273094177246094 seconds
DEBUG 01-15 10:09:35.648294.648294 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.648188.648188 lmp.py:1636] 
DEBUG 01-15 10:09:35.648188.648188 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.648217.648217 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:35.648059.648059 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.648557.648557 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.649383.649383 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.650575.650575 cuda_h.py:19] end allocate_cuda_memory cost 0.0013358592987060547 seconds
DEBUG 01-15 10:09:35.650350.650350 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.650589.650589 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.650591.650591 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.650717.650717 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43238f9a-8cf0-4e75-9acf-3b349c08c58e
DEBUG 01-15 10:09:35.651810.651810 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:35.651204.651204 client.py:127] Model loaded
DEBUG 01-15 10:09:35.651359.651359 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.651371.651371 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.652170.652170 cuda_h.py:19] end restore2model cost 0.000446319580078125 seconds
DEBUG 01-15 10:09:35.652622.652622 cuda_h.py:19] end sllm_worker_task cost 0.010436534881591797 seconds
INFO 01-15 10:09:35.652123.652123 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43238f9a-8cf0-4e75-9acf-3b349c08c58e
DEBUG 01-15 10:09:35.652570.652570 cuda_h.py:19] end load_into_gpu_async cost 0.0013837814331054688 seconds
DEBUG 01-15 10:09:35.652432.652432 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.652305.652305 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.653516.653516 cuda_h.py:19] end restore_tensors2 cost 0.0006875991821289062 seconds
DEBUG 01-15 10:09:35.653950.653950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004192352294921875 seconds
DEBUG 01-15 10:09:35.653131.653131 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.653567.653567 cuda_h.py:19] end move_flatidxs cost 0.0011141300201416016 seconds
DEBUG 01-15 10:09:35.653346.653346 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.657944.657944 cuda_h.py:19] end restore2model cost 0.004650592803955078 seconds
DEBUG 01-15 10:09:35.658180.658180 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009119510650634766 seconds
DEBUG 01-15 10:09:35.658525.658525 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.658390.658390 cuda_h.py:19] end gpu_sexperts cost 0.0004425048828125 seconds
DEBUG 01-15 10:09:35.658829.658829 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.661992.661992 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0026242733001708984 seconds
DEBUG 01-15 10:09:35.662355.662355 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.663357.663357 cuda_h.py:19] end gpu_group_list cost 0.000545501708984375 seconds
DEBUG 01-15 10:09:35.663950.663950 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.664149.664149 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007343292236328125 seconds
DEBUG 01-15 10:09:35.664494.664494 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.664748.664748 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-15 10:09:35.664397.664397 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.669704.669704 cuda_h.py:19] end group_tensors cost 0.015946388244628906 seconds
DEBUG 01-15 10:09:35.670747.670747 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.674408.674408 cuda_h.py:19] end group pad cost 0.004254817962646484 seconds
DEBUG 01-15 10:09:35.675198.675198 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.695501.695501 cuda_h.py:19] end group_einsum cost 0.02042531967163086 seconds
DEBUG 01-15 10:09:35.695672.695672 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.700381.700381 cuda_h.py:19] end get_outputs_cpu1 cost 0.004873991012573242 seconds
DEBUG 01-15 10:09:35.701520.701520 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04978585243225098 seconds
DEBUG 01-15 10:09:35.702047.702047 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03850603103637695 seconds
DEBUG 01-15 10:09:35.703024.703024 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.703974.703974 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.703032.703032 cuda_h.py:19] end index_scatter cost 9.012222290039062e-05 seconds
DEBUG 01-15 10:09:35.703129.703129 cuda_h.py:19] end cpuoutputsdeal cost 0.0007004737854003906 seconds
DEBUG 01-15 10:09:35.703018.703018 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.703278.703278 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43238f9a-8cf0-4e75-9acf-3b349c08c58e
INFO 01-15 10:09:35.705154.705154 client.py:127] Model loaded
DEBUG 01-15 10:09:35.705133.705133 cuda_h.py:19] end wait_experts cost 0.0013964176177978516 seconds
DEBUG 01-15 10:09:35.705725.705725 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.705094.705094 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.705726.705726 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.706371.706371 cuda_h.py:19] end gpu_group_tensor cost 0.00038814544677734375 seconds
DEBUG 01-15 10:09:35.706206.706206 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.708904.708904 cuda_h.py:19] end gpu_group_einsum cost 0.002329111099243164 seconds
DEBUG 01-15 10:09:35.709648.709648 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.709355.709355 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.709383.709383 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005674362182617188 seconds
DEBUG 01-15 10:09:35.709922.709922 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.710267.710267 cuda_h.py:19] end concat_expert_out cost 0.000141143798828125 seconds
DEBUG 01-15 10:09:35.710372.710372 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.710465.710465 cuda_h.py:19] end index_scatter cost 0.00012254714965820312 seconds
DEBUG 01-15 10:09:35.710779.710779 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014252662658691406 seconds
DEBUG 01-15 10:09:35.710162.710162 cuda_h.py:19] end gpu_experts cost 0.00526881217956543 seconds
DEBUG 01-15 10:09:35.710414.710414 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06453728675842285 seconds
DEBUG 01-15 10:09:35.711770.711770 cuda_h.py:19] end prefill_layer cost 0.07036900520324707 seconds
DEBUG 01-15 10:09:35.711279.711279 lmp.py:1552] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-15 10:09:35.711897.711897 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.712899.712899 lmp.py:1495] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-15 10:09:35.712710.712710 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:35.712527.712527 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:35.712856.712856 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.031990051269531e-05 seconds
DEBUG 01-15 10:09:35.712892.712892 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.712253.712253 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 0.00024366378784179688 seconds
DEBUG 01-15 10:09:35.712674.712674 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.712273.712273 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.712726.712726 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.713061.713061 cuda_h.py:19] end allocate_cuda_memory cost 0.00019311904907226562 seconds
DEBUG 01-15 10:09:35.713103.713103 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.713528.713528 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.713357.713357 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.713345.713345 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9f2a8d87-200b-40ce-a87c-8bcef61cba32
DEBUG 01-15 10:09:35.713838.713838 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.713738.713738 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.713309.713309 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.714697.714697 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9f2a8d87-200b-40ce-a87c-8bcef61cba32
DEBUG 01-15 10:09:35.714630.714630 cuda_h.py:19] end load_into_gpu_async cost 0.0010554790496826172 seconds
DEBUG 01-15 10:09:35.714955.714955 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.714230.714230 cuda_h.py:19] end restore_tensors2 cost 7.224082946777344e-05 seconds
DEBUG 01-15 10:09:35.714747.714747 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016565322875976562 seconds
INFO 01-15 10:09:35.714081.714081 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9f2a8d87-200b-40ce-a87c-8bcef61cba32
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.718118.718118 cuda_h.py:19] end self_attn cost 0.004375457763671875 seconds
DEBUG 01-15 10:09:35.718233.718233 cuda_h.py:19] end iln_self_attn_paln cost 0.0061495304107666016 seconds
DEBUG 01-15 10:09:35.719401.719401 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-15 10:09:35.719622.719622 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.720766.720766 cuda_h.py:19] end gate cost 0.0008931159973144531 seconds
DEBUG 01-15 10:09:35.720537.720537 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.720892.720892 lmp.py:1616] 
DEBUG 01-15 10:09:35.720892.720892 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.720105.720105 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.720683.720683 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.720015.720015 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.720771.720771 lmp.py:1620] 
DEBUG 01-15 10:09:35.720771.720771 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.720242.720242 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.720144.720144 lmp.py:1626]   Expert  1 |     45 | CPU
DEBUG 01-15 10:09:35.720662.720662 lmp.py:1626]   Expert  7 |     60 | CPU
DEBUG 01-15 10:09:35.720371.720371 lmp.py:1626]   Expert 37 |     71 | CPU
DEBUG 01-15 10:09:35.720187.720187 lmp.py:1626]   Expert 17 |     75 | CPU
DEBUG 01-15 10:09:35.721466.721466 lmp.py:1626]   Expert 54 |     75 | CPU
DEBUG 01-15 10:09:35.721269.721269 lmp.py:1626]   Expert 18 |     84 | CPU
DEBUG 01-15 10:09:35.721356.721356 lmp.py:1626]   Expert 13 |     90 | CPU
DEBUG 01-15 10:09:35.721681.721681 lmp.py:1626]   Expert  9 |     91 | CPU
DEBUG 01-15 10:09:35.721768.721768 lmp.py:1626]   Expert 22 |    101 | CPU
DEBUG 01-15 10:09:35.721855.721855 lmp.py:1626]   Expert 58 |    101 | CPU
DEBUG 01-15 10:09:35.721896.721896 lmp.py:1626]   Expert  0 |    108 | CPU
DEBUG 01-15 10:09:35.721460.721460 lmp.py:1626]   Expert 26 |    116 | CPU
DEBUG 01-15 10:09:35.721786.721786 lmp.py:1626]   Expert 16 |    119 | CPU
DEBUG 01-15 10:09:35.721542.721542 lmp.py:1626]   Expert 10 |    122 | CPU
DEBUG 01-15 10:09:35.721682.721682 lmp.py:1626]   Expert 63 |    129 | CPU
DEBUG 01-15 10:09:35.721961.721961 lmp.py:1626]   Expert 59 |    131 | CPU
DEBUG 01-15 10:09:35.721240.721240 lmp.py:1626]   Expert 62 |    139 | CPU
DEBUG 01-15 10:09:35.721281.721281 lmp.py:1626]   Expert 43 |    143 | CPU
DEBUG 01-15 10:09:35.721944.721944 lmp.py:1626]   Expert 28 |    146 | CPU
DEBUG 01-15 10:09:35.721270.721270 lmp.py:1626]   Expert 33 |    148 | CPU
DEBUG 01-15 10:09:35.721880.721880 lmp.py:1626]   Expert 29 |    149 | CPU
DEBUG 01-15 10:09:35.721013.721013 lmp.py:1626]   Expert  2 |    156 | CPU
DEBUG 01-15 10:09:35.721623.721623 lmp.py:1626]   Expert 51 |    164 | CPU
DEBUG 01-15 10:09:35.721518.721518 lmp.py:1626]   Expert 55 |    165 | CPU
DEBUG 01-15 10:09:35.721413.721413 lmp.py:1626]   Expert  3 |    167 | CPU
DEBUG 01-15 10:09:35.721547.721547 lmp.py:1626]   Expert 11 |    167 | CPU
DEBUG 01-15 10:09:35.721203.721203 lmp.py:1626]   Expert 23 |    167 | CPU
DEBUG 01-15 10:09:35.721575.721575 lmp.py:1626]   Expert 53 |    167 | CPU
DEBUG 01-15 10:09:35.721901.721901 lmp.py:1626]   Expert 32 |    168 | CPU
DEBUG 01-15 10:09:35.721988.721988 lmp.py:1626]   Expert 45 |    169 | CPU
DEBUG 01-15 10:09:35.721790.721790 lmp.py:1626]   Expert 40 |    170 | CPU
DEBUG 01-15 10:09:35.721923.721923 lmp.py:1626]   Expert 14 |    175 | CPU
DEBUG 01-15 10:09:35.721057.721057 lmp.py:1626]   Expert 34 |    175 | GPU
DEBUG 01-15 10:09:35.721429.721429 lmp.py:1626]   Expert 41 |    182 | GPU
DEBUG 01-15 10:09:35.721231.721231 lmp.py:1626]   Expert 52 |    182 | GPU
INFO 01-15 10:09:35.721664.721664 client.py:127] Model loaded
DEBUG 01-15 10:09:35.722123.722123 lmp.py:1626]   Expert 42 |    184 | GPU
DEBUG 01-15 10:09:35.722336.722336 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.722238.722238 lmp.py:1626]   Expert 21 |    186 | GPU
DEBUG 01-15 10:09:35.722530.722530 lmp.py:1626]   Expert 57 |    195 | GPU
DEBUG 01-15 10:09:35.722063.722063 lmp.py:1626]   Expert 30 |    197 | GPU
DEBUG 01-15 10:09:35.722779.722779 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:35.722250.722250 lmp.py:1626]   Expert 35 |    209 | GPU
DEBUG 01-15 10:09:35.722529.722529 lmp.py:1626]   Expert 12 |    218 | GPU
DEBUG 01-15 10:09:35.722809.722809 lmp.py:1626]   Expert  4 |    219 | GPU
DEBUG 01-15 10:09:35.722334.722334 lmp.py:1626]   Expert 46 |    227 | GPU
DEBUG 01-15 10:09:35.722185.722185 lmp.py:1626]   Expert 19 |    231 | GPU
DEBUG 01-15 10:09:35.722233.722233 lmp.py:1626]   Expert 24 |    231 | GPU
DEBUG 01-15 10:09:35.722750.722750 lmp.py:1626]   Expert 50 |    231 | GPU
DEBUG 01-15 10:09:35.722506.722506 lmp.py:1626]   Expert 44 |    232 | GPU
DEBUG 01-15 10:09:35.722501.722501 lmp.py:1626]   Expert  8 |    235 | GPU
DEBUG 01-15 10:09:35.722734.722734 lmp.py:1626]   Expert 49 |    236 | GPU
DEBUG 01-15 10:09:35.722536.722536 lmp.py:1626]   Expert 38 |    237 | GPU
DEBUG 01-15 10:09:35.722338.722338 lmp.py:1626]   Expert  6 |    246 | GPU
DEBUG 01-15 10:09:35.722425.722425 lmp.py:1626]   Expert 47 |    248 | GPU
DEBUG 01-15 10:09:35.722512.722512 lmp.py:1626]   Expert 31 |    256 | GPU
DEBUG 01-15 10:09:35.723792.723792 lmp.py:1626]   Expert 61 |    264 | GPU
DEBUG 01-15 10:09:35.723309.723309 lmp.py:1626]   Expert 39 |    275 | GPU
DEBUG 01-15 10:09:35.723304.723304 lmp.py:1626]   Expert 36 |    304 | GPU
DEBUG 01-15 10:09:35.723867.723867 lmp.py:1626]   Expert  5 |    306 | GPU
DEBUG 01-15 10:09:35.723908.723908 lmp.py:1626]   Expert 27 |    309 | GPU
DEBUG 01-15 10:09:35.723439.723439 lmp.py:1626]   Expert 60 |    335 | GPU
DEBUG 01-15 10:09:35.723605.723605 lmp.py:1626]   Expert 20 |    340 | GPU
DEBUG 01-15 10:09:35.723533.723533 lmp.py:1626]   Expert 48 |    367 | GPU
DEBUG 01-15 10:09:35.723461.723461 lmp.py:1626]   Expert 25 |    397 | GPU
DEBUG 01-15 10:09:35.723389.723389 lmp.py:1626]   Expert 56 |    557 | GPU
DEBUG 01-15 10:09:35.723747.723747 lmp.py:1627] 
DEBUG 01-15 10:09:35.723747.723747 lmp.py:1627]   CPU total tokens: 4078 (33.2%)
DEBUG 01-15 10:09:35.723059.723059 lmp.py:1628]   GPU total tokens: 8210 (66.8%)
DEBUG 01-15 10:09:35.723570.723570 cuda_h.py:19] end experts_map_get cost 0.0031037330627441406 seconds
DEBUG 01-15 10:09:35.723393.723393 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.723825.723825 lmp.py:1636] 
DEBUG 01-15 10:09:35.723825.723825 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.723999.723999 cuda_h.py:19] end cpu_experts_submit cost 5.841255187988281e-05 seconds
DEBUG 01-15 10:09:35.723649.723649 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.723293.723293 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.723305.723305 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.723604.723604 cuda_h.py:19] end allocate_cuda_memory cost 0.00018548965454101562 seconds
DEBUG 01-15 10:09:35.723778.723778 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.724103.724103 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.724297.724297 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.724662.724662 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a21dcf62-23f1-45b1-9322-e39184c156bd
DEBUG 01-15 10:09:35.724132.724132 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.724891.724891 cuda_h.py:19] end restore2model cost 0.0026383399963378906 seconds
DEBUG 01-15 10:09:35.724868.724868 cuda_h.py:19] end sllm_worker_task cost 0.012336969375610352 seconds
DEBUG 01-15 10:09:35.725706.725706 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:35.725457.725457 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a21dcf62-23f1-45b1-9322-e39184c156bd
DEBUG 01-15 10:09:35.725492.725492 cuda_h.py:19] end load_into_gpu_async cost 0.001336812973022461 seconds
DEBUG 01-15 10:09:35.725911.725911 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.725098.725098 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.725404.725404 cuda_h.py:19] end restore_tensors2 cost 0.00047779083251953125 seconds
DEBUG 01-15 10:09:35.725691.725691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023758411407470703 seconds
DEBUG 01-15 10:09:35.726269.726269 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.726212.726212 cuda_h.py:19] end move_flatidxs cost 0.0009577274322509766 seconds
DEBUG 01-15 10:09:35.726670.726670 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.728647.728647 cuda_h.py:19] end restore2model cost 0.0027399063110351562 seconds
DEBUG 01-15 10:09:35.728848.728848 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005320072174072266 seconds
DEBUG 01-15 10:09:35.728074.728074 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.729587.729587 cuda_h.py:19] end gpu_sexperts cost 0.00027632713317871094 seconds
DEBUG 01-15 10:09:35.729609.729609 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.730773.730773 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014891624450683594 seconds
DEBUG 01-15 10:09:35.731350.731350 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.731111.731111 cuda_h.py:19] end gpu_group_list cost 0.0003247261047363281 seconds
DEBUG 01-15 10:09:35.732605.732605 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.732930.732930 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007600784301757812 seconds
DEBUG 01-15 10:09:35.732282.732282 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.732297.732297 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-15 10:09:35.733993.733993 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.737939.737939 cuda_h.py:19] end group_tensors cost 0.010756254196166992 seconds
DEBUG 01-15 10:09:35.738907.738907 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.742368.742368 cuda_h.py:19] end group pad cost 0.004010677337646484 seconds
DEBUG 01-15 10:09:35.742350.742350 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.763862.763862 cuda_h.py:19] end group_einsum cost 0.020763635635375977 seconds
DEBUG 01-15 10:09:35.763219.763219 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.768889.768889 cuda_h.py:19] end get_outputs_cpu1 cost 0.004695892333984375 seconds
DEBUG 01-15 10:09:35.769956.769956 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04378080368041992 seconds
DEBUG 01-15 10:09:35.770869.770869 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03736138343811035 seconds
DEBUG 01-15 10:09:35.770497.770497 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.771328.771328 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.771572.771572 cuda_h.py:19] end index_scatter cost 9.1552734375e-05 seconds
DEBUG 01-15 10:09:35.771891.771891 cuda_h.py:19] end cpuoutputsdeal cost 0.0008902549743652344 seconds
DEBUG 01-15 10:09:35.771197.771197 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.771066.771066 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a21dcf62-23f1-45b1-9322-e39184c156bd
INFO 01-15 10:09:35.776109.776109 client.py:127] Model loaded
DEBUG 01-15 10:09:35.776363.776363 cuda_h.py:19] end wait_experts cost 0.004929780960083008 seconds
DEBUG 01-15 10:09:35.776834.776834 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.776691.776691 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.777792.777792 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.777409.777409 cuda_h.py:19] end gpu_group_tensor cost 0.00021266937255859375 seconds
DEBUG 01-15 10:09:35.777896.777896 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.777341.777341 cuda_h.py:19] end gpu_group_einsum cost 0.0005624294281005859 seconds
DEBUG 01-15 10:09:35.778881.778881 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.778572.778572 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.778317.778317 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002739429473876953 seconds
DEBUG 01-15 10:09:35.778358.778358 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.778758.778758 cuda_h.py:19] end concat_expert_out cost 5.4836273193359375e-05 seconds
DEBUG 01-15 10:09:35.778978.778978 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.778855.778855 cuda_h.py:19] end index_scatter cost 5.1021575927734375e-05 seconds
DEBUG 01-15 10:09:35.778519.778519 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000606536865234375 seconds
DEBUG 01-15 10:09:35.778442.778442 cuda_h.py:19] end gpu_experts cost 0.0018954277038574219 seconds
DEBUG 01-15 10:09:35.778504.778504 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.05978870391845703 seconds
DEBUG 01-15 10:09:35.779337.779337 cuda_h.py:19] end prefill_layer cost 0.06746149063110352 seconds
DEBUG 01-15 10:09:35.779538.779538 lmp.py:1552] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-15 10:09:35.779241.779241 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.779613.779613 lmp.py:1495] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-15 10:09:35.779985.779985 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:35.779026.779026 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:35.779736.779736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.886222839355469e-05 seconds
DEBUG 01-15 10:09:35.779016.779016 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.152557373046875e-05 seconds
DEBUG 01-15 10:09:35.779904.779904 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.779469.779469 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.779865.779865 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.780356.780356 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.780831.780831 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.780538.780538 cuda_h.py:19] end allocate_cuda_memory cost 0.0003044605255126953 seconds
DEBUG 01-15 10:09:35.780534.780534 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.780681.780681 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.780649.780649 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.780637.780637 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0de36956-11b9-46fa-9644-e234ff1bbc78
DEBUG 01-15 10:09:35.780030.780030 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.781709.781709 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.781651.781651 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0de36956-11b9-46fa-9644-e234ff1bbc78
DEBUG 01-15 10:09:35.781554.781554 cuda_h.py:19] end load_into_gpu_async cost 0.0009639263153076172 seconds
DEBUG 01-15 10:09:35.781595.781595 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.781929.781929 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-15 10:09:35.781354.781354 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016088485717773438 seconds
INFO 01-15 10:09:35.781191.781191 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0de36956-11b9-46fa-9644-e234ff1bbc78
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.784266.784266 cuda_h.py:19] end self_attn cost 0.0031218528747558594 seconds
DEBUG 01-15 10:09:35.784787.784787 cuda_h.py:19] end iln_self_attn_paln cost 0.0047969818115234375 seconds
DEBUG 01-15 10:09:35.784107.784107 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-15 10:09:35.784347.784347 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.785893.785893 cuda_h.py:19] end gate cost 0.0006496906280517578 seconds
DEBUG 01-15 10:09:35.785438.785438 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.785627.785627 lmp.py:1616] 
DEBUG 01-15 10:09:35.785627.785627 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.785906.785906 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.785079.785079 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.785914.785914 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.785080.785080 lmp.py:1620] 
DEBUG 01-15 10:09:35.785080.785080 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.785723.785723 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.785082.785082 lmp.py:1626]   Expert 50 |     44 | CPU
DEBUG 01-15 10:09:35.785724.785724 lmp.py:1626]   Expert  3 |     54 | CPU
DEBUG 01-15 10:09:35.785606.785606 lmp.py:1626]   Expert 46 |     56 | CPU
DEBUG 01-15 10:09:35.785010.785010 lmp.py:1626]   Expert  1 |     75 | CPU
DEBUG 01-15 10:09:35.785177.785177 lmp.py:1626]   Expert  4 |     87 | CPU
DEBUG 01-15 10:09:35.785343.785343 lmp.py:1626]   Expert 29 |     88 | CPU
DEBUG 01-15 10:09:35.785509.785509 lmp.py:1626]   Expert 40 |     95 | CPU
DEBUG 01-15 10:09:35.785483.785483 lmp.py:1626]   Expert 15 |     96 | CPU
DEBUG 01-15 10:09:35.786934.786934 lmp.py:1626]   Expert  8 |    111 | CPU
DEBUG 01-15 10:09:35.786146.786146 lmp.py:1626]   Expert 28 |    112 | CPU
DEBUG 01-15 10:09:35.786359.786359 lmp.py:1626]   Expert 41 |    112 | CPU
DEBUG 01-15 10:09:35.786571.786571 lmp.py:1626]   Expert 48 |    126 | CPU
DEBUG 01-15 10:09:35.786784.786784 lmp.py:1626]   Expert 16 |    127 | CPU
DEBUG 01-15 10:09:35.786996.786996 lmp.py:1626]   Expert 27 |    127 | CPU
DEBUG 01-15 10:09:35.786209.786209 lmp.py:1626]   Expert  6 |    129 | CPU
DEBUG 01-15 10:09:35.786898.786898 lmp.py:1626]   Expert 13 |    130 | CPU
DEBUG 01-15 10:09:35.786872.786872 lmp.py:1626]   Expert 54 |    133 | CPU
DEBUG 01-15 10:09:35.786084.786084 lmp.py:1626]   Expert 39 |    137 | CPU
DEBUG 01-15 10:09:35.786204.786204 lmp.py:1626]   Expert  7 |    138 | CPU
DEBUG 01-15 10:09:35.786132.786132 lmp.py:1626]   Expert 51 |    139 | CPU
DEBUG 01-15 10:09:35.786298.786298 lmp.py:1626]   Expert 18 |    142 | CPU
DEBUG 01-15 10:09:35.786226.786226 lmp.py:1626]   Expert 60 |    142 | CPU
DEBUG 01-15 10:09:35.786836.786836 lmp.py:1626]   Expert 14 |    144 | CPU
DEBUG 01-15 10:09:35.786479.786479 lmp.py:1626]   Expert 43 |    146 | CPU
DEBUG 01-15 10:09:35.786168.786168 lmp.py:1626]   Expert 56 |    146 | CPU
DEBUG 01-15 10:09:35.786096.786096 lmp.py:1626]   Expert 52 |    147 | CPU
DEBUG 01-15 10:09:35.786785.786785 lmp.py:1626]   Expert 20 |    149 | CPU
DEBUG 01-15 10:09:35.786759.786759 lmp.py:1626]   Expert 36 |    151 | CPU
DEBUG 01-15 10:09:35.786972.786972 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:35.786423.786423 lmp.py:1626]   Expert 10 |    157 | CPU
DEBUG 01-15 10:09:35.786397.786397 lmp.py:1626]   Expert 11 |    158 | CPU
DEBUG 01-15 10:09:35.786609.786609 lmp.py:1626]   Expert 45 |    159 | CPU
DEBUG 01-15 10:09:35.786822.786822 lmp.py:1626]   Expert  5 |    162 | GPU
DEBUG 01-15 10:09:35.786557.786557 lmp.py:1626]   Expert 62 |    164 | GPU
DEBUG 01-15 10:09:35.786770.786770 lmp.py:1626]   Expert 57 |    172 | GPU
DEBUG 01-15 10:09:35.786982.786982 lmp.py:1626]   Expert 44 |    178 | GPU
DEBUG 01-15 10:09:35.786910.786910 lmp.py:1626]   Expert 33 |    180 | GPU
DEBUG 01-15 10:09:35.786076.786076 lmp.py:1626]   Expert 25 |    182 | GPU
DEBUG 01-15 10:09:35.786242.786242 lmp.py:1626]   Expert 53 |    182 | GPU
DEBUG 01-15 10:09:35.786170.786170 lmp.py:1626]   Expert 58 |    182 | GPU
DEBUG 01-15 10:09:35.786098.786098 lmp.py:1626]   Expert  2 |    189 | GPU
DEBUG 01-15 10:09:35.786549.786549 lmp.py:1626]   Expert 32 |    189 | GPU
DEBUG 01-15 10:09:35.786761.786761 lmp.py:1626]   Expert 21 |    200 | GPU
DEBUG 01-15 10:09:35.786212.786212 lmp.py:1626]   Expert 31 |    200 | GPU
DEBUG 01-15 10:09:35.786424.786424 lmp.py:1626]   Expert 35 |    200 | GPU
DEBUG 01-15 10:09:35.786637.786637 lmp.py:1626]   Expert 63 |    205 | GPU
DEBUG 01-15 10:09:35.786611.786611 lmp.py:1626]   Expert 17 |    206 | GPU
DEBUG 01-15 10:09:35.786062.786062 lmp.py:1626]   Expert 49 |    206 | GPU
DEBUG 01-15 10:09:35.786513.786513 lmp.py:1626]   Expert 42 |    219 | GPU
DEBUG 01-15 10:09:35.786963.786963 lmp.py:1626]   Expert 34 |    221 | GPU
DEBUG 01-15 10:09:35.786130.786130 lmp.py:1626]   Expert 37 |    227 | GPU
DEBUG 01-15 10:09:35.786057.786057 lmp.py:1626]   Expert 59 |    231 | GPU
DEBUG 01-15 10:09:35.786747.786747 lmp.py:1626]   Expert 22 |    240 | GPU
DEBUG 01-15 10:09:35.786390.786390 lmp.py:1626]   Expert  0 |    242 | GPU
DEBUG 01-15 10:09:35.786840.786840 lmp.py:1626]   Expert 19 |    258 | GPU
DEBUG 01-15 10:09:35.786576.786576 lmp.py:1626]   Expert 24 |    286 | GPU
DEBUG 01-15 10:09:35.786789.786789 lmp.py:1626]   Expert 61 |    287 | GPU
DEBUG 01-15 10:09:35.786763.786763 lmp.py:1626]   Expert 30 |    301 | GPU
DEBUG 01-15 10:09:35.786737.786737 lmp.py:1626]   Expert 47 |    322 | GPU
DEBUG 01-15 10:09:35.786711.786711 lmp.py:1626]   Expert 38 |    367 | GPU
DEBUG 01-15 10:09:35.786685.786685 lmp.py:1626]   Expert 26 |    375 | GPU
DEBUG 01-15 10:09:35.786659.786659 lmp.py:1626]   Expert 12 |    428 | GPU
DEBUG 01-15 10:09:35.786063.786063 lmp.py:1626]   Expert  9 |    678 | GPU
DEBUG 01-15 10:09:35.786991.786991 lmp.py:1626]   Expert 23 |    701 | GPU
DEBUG 01-15 10:09:35.786634.786634 lmp.py:1627] 
DEBUG 01-15 10:09:35.786634.786634 lmp.py:1627]   CPU total tokens: 3908 (31.8%)
DEBUG 01-15 10:09:35.786277.786277 lmp.py:1628]   GPU total tokens: 8380 (68.2%)
DEBUG 01-15 10:09:35.786165.786165 cuda_h.py:19] end experts_map_get cost 0.0015268325805664062 seconds
DEBUG 01-15 10:09:35.787108.787108 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.787910.787910 lmp.py:1636] 
DEBUG 01-15 10:09:35.787910.787910 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.787607.787607 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-15 10:09:35.787588.787588 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.787901.787901 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.787443.787443 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.788844.788844 cuda_h.py:19] end allocate_cuda_memory cost 0.0014543533325195312 seconds
DEBUG 01-15 10:09:35.788038.788038 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.789002.789002 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.789639.789639 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.789673.789673 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5449a0f2-64d2-4cab-9840-1cbc85c5f88d
DEBUG 01-15 10:09:35.789355.789355 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.789304.789304 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.789500.789500 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:35.789169.789169 client.py:127] Model loaded
DEBUG 01-15 10:09:35.789225.789225 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.790981.790981 cuda_h.py:19] end restore2model cost 0.0003829002380371094 seconds
DEBUG 01-15 10:09:35.790373.790373 cuda_h.py:19] end sllm_worker_task cost 0.010207176208496094 seconds
INFO 01-15 10:09:35.790601.790601 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5449a0f2-64d2-4cab-9840-1cbc85c5f88d
DEBUG 01-15 10:09:35.790113.790113 cuda_h.py:19] end load_into_gpu_async cost 0.001344919204711914 seconds
DEBUG 01-15 10:09:35.790192.790192 cuda_h.py:19] end move_flatidxs cost 0.0008435249328613281 seconds
DEBUG 01-15 10:09:35.790769.790769 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.790968.790968 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.791623.791623 cuda_h.py:19] end restore_tensors2 cost 0.0005276203155517578 seconds
DEBUG 01-15 10:09:35.791453.791453 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003993988037109375 seconds
DEBUG 01-15 10:09:35.791634.791634 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.794978.794978 cuda_h.py:19] end restore2model cost 0.0027086734771728516 seconds
DEBUG 01-15 10:09:35.794941.794941 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006943941116333008 seconds
DEBUG 01-15 10:09:35.794213.794213 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.794727.794727 cuda_h.py:19] end gpu_sexperts cost 0.0002777576446533203 seconds
DEBUG 01-15 10:09:35.794887.794887 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.796199.796199 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015654563903808594 seconds
DEBUG 01-15 10:09:35.795860.795860 cuda_h.py:19] end group_tensors cost 0.005218982696533203 seconds
DEBUG 01-15 10:09:35.796931.796931 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.797896.797896 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.797167.797167 cuda_h.py:19] end gpu_group_list cost 0.0004696846008300781 seconds
DEBUG 01-15 10:09:35.797630.797630 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.799585.799585 cuda_h.py:19] end acpu_expert_weight_slices cost 0.001163482666015625 seconds
DEBUG 01-15 10:09:35.799462.799462 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.799657.799657 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.765655517578125e-05 seconds
DEBUG 01-15 10:09:35.799313.799313 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.800763.800763 cuda_h.py:19] end group pad cost 0.0038285255432128906 seconds
DEBUG 01-15 10:09:35.800361.800361 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.827869.827869 cuda_h.py:19] end group_einsum cost 0.027136564254760742 seconds
DEBUG 01-15 10:09:35.827497.827497 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.834650.834650 cuda_h.py:19] end get_outputs_cpu1 cost 0.006847381591796875 seconds
DEBUG 01-15 10:09:35.835724.835724 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04616189002990723 seconds
DEBUG 01-15 10:09:35.836113.836113 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0372614860534668 seconds
DEBUG 01-15 10:09:35.837529.837529 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.837722.837722 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.837800.837800 cuda_h.py:19] end index_scatter cost 8.463859558105469e-05 seconds
DEBUG 01-15 10:09:35.838371.838371 cuda_h.py:19] end cpuoutputsdeal cost 0.001271963119506836 seconds
DEBUG 01-15 10:09:35.838870.838870 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.838156.838156 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5449a0f2-64d2-4cab-9840-1cbc85c5f88d
INFO 01-15 10:09:35.841739.841739 client.py:127] Model loaded
DEBUG 01-15 10:09:35.841913.841913 cuda_h.py:19] end wait_experts cost 0.0028460025787353516 seconds
DEBUG 01-15 10:09:35.841186.841186 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.841836.841836 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.841639.841639 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.841540.841540 cuda_h.py:19] end gpu_group_tensor cost 0.00017976760864257812 seconds
DEBUG 01-15 10:09:35.841928.841928 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.842032.842032 cuda_h.py:19] end gpu_group_einsum cost 0.0004897117614746094 seconds
DEBUG 01-15 10:09:35.842651.842651 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.842673.842673 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.842204.842204 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022101402282714844 seconds
DEBUG 01-15 10:09:35.842338.842338 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.842546.842546 cuda_h.py:19] end concat_expert_out cost 5.650520324707031e-05 seconds
DEBUG 01-15 10:09:35.842528.842528 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.842643.842643 cuda_h.py:19] end index_scatter cost 5.2928924560546875e-05 seconds
DEBUG 01-15 10:09:35.843306.843306 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005514621734619141 seconds
DEBUG 01-15 10:09:35.843269.843269 cuda_h.py:19] end gpu_experts cost 0.0016894340515136719 seconds
DEBUG 01-15 10:09:35.843901.843901 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.05848979949951172 seconds
DEBUG 01-15 10:09:35.843599.843599 cuda_h.py:19] end prefill_layer cost 0.06406593322753906 seconds
DEBUG 01-15 10:09:35.843788.843788 lmp.py:1552] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-15 10:09:35.843153.843153 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.843995.843995 lmp.py:1495] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-15 10:09:35.843075.843075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:35.843732.843732 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:35.843721.843721 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.457069396972656e-05 seconds
DEBUG 01-15 10:09:35.843708.843708 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.29425048828125e-05 seconds
DEBUG 01-15 10:09:35.843166.843166 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.844784.844784 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.844451.844451 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.844843.844843 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.844749.844749 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.844727.844727 cuda_h.py:19] end allocate_cuda_memory cost 0.00027871131896972656 seconds
DEBUG 01-15 10:09:35.844419.844419 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.844327.844327 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.844541.844541 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.844628.844628 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16731d93-f353-425d-a42a-68de585433c8
DEBUG 01-15 10:09:35.845803.845803 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.845215.845215 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.845031.845031 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16731d93-f353-425d-a42a-68de585433c8
DEBUG 01-15 10:09:35.845059.845059 cuda_h.py:19] end load_into_gpu_async cost 0.0011010169982910156 seconds
DEBUG 01-15 10:09:35.845716.845716 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.846780.846780 cuda_h.py:19] end restore_tensors2 cost 8.797645568847656e-05 seconds
DEBUG 01-15 10:09:35.846397.846397 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017697811126708984 seconds
INFO 01-15 10:09:35.846684.846684 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16731d93-f353-425d-a42a-68de585433c8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.848475.848475 cuda_h.py:19] end self_attn cost 0.0031435489654541016 seconds
DEBUG 01-15 10:09:35.848460.848460 cuda_h.py:19] end iln_self_attn_paln cost 0.004785776138305664 seconds
DEBUG 01-15 10:09:35.848303.848303 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-15 10:09:35.848205.848205 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.849049.849049 cuda_h.py:19] end gate cost 0.0006585121154785156 seconds
DEBUG 01-15 10:09:35.849117.849117 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.849353.849353 lmp.py:1616] 
DEBUG 01-15 10:09:35.849353.849353 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.849301.849301 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.849950.849950 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.850216.850216 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.850621.850621 lmp.py:1620] 
DEBUG 01-15 10:09:35.850621.850621 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.850025.850025 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.850860.850860 lmp.py:1626]   Expert 38 |     13 | CPU
DEBUG 01-15 10:09:35.850026.850026 lmp.py:1626]   Expert 39 |     60 | CPU
DEBUG 01-15 10:09:35.850954.850954 lmp.py:1626]   Expert  7 |     72 | CPU
DEBUG 01-15 10:09:35.850312.850312 lmp.py:1626]   Expert 30 |     74 | CPU
DEBUG 01-15 10:09:35.850478.850478 lmp.py:1626]   Expert 24 |     93 | CPU
DEBUG 01-15 10:09:35.850360.850360 lmp.py:1626]   Expert 27 |     94 | CPU
DEBUG 01-15 10:09:35.850526.850526 lmp.py:1626]   Expert 14 |     95 | CPU
DEBUG 01-15 10:09:35.850454.850454 lmp.py:1626]   Expert 36 |     97 | CPU
DEBUG 01-15 10:09:35.850858.850858 lmp.py:1626]   Expert 40 |     97 | CPU
DEBUG 01-15 10:09:35.850740.850740 lmp.py:1626]   Expert 17 |     99 | CPU
DEBUG 01-15 10:09:35.850952.850952 lmp.py:1626]   Expert 16 |    104 | CPU
DEBUG 01-15 10:09:35.850688.850688 lmp.py:1626]   Expert 32 |    106 | CPU
DEBUG 01-15 10:09:35.850900.850900 lmp.py:1626]   Expert 48 |    109 | CPU
DEBUG 01-15 10:09:35.850874.850874 lmp.py:1626]   Expert 18 |    110 | CPU
DEBUG 01-15 10:09:35.850279.850279 lmp.py:1626]   Expert  1 |    115 | CPU
DEBUG 01-15 10:09:35.850491.850491 lmp.py:1626]   Expert 12 |    116 | CPU
DEBUG 01-15 10:09:35.850942.850942 lmp.py:1626]   Expert  6 |    128 | CPU
DEBUG 01-15 10:09:35.850347.850347 lmp.py:1626]   Expert 59 |    130 | CPU
DEBUG 01-15 10:09:35.850036.850036 lmp.py:1626]   Expert 42 |    136 | CPU
DEBUG 01-15 10:09:35.850202.850202 lmp.py:1626]   Expert  0 |    140 | CPU
DEBUG 01-15 10:09:35.850130.850130 lmp.py:1626]   Expert 22 |    145 | CPU
DEBUG 01-15 10:09:35.850819.850819 lmp.py:1626]   Expert 53 |    147 | CPU
DEBUG 01-15 10:09:35.850654.850654 lmp.py:1626]   Expert 51 |    149 | CPU
DEBUG 01-15 10:09:35.850628.850628 lmp.py:1626]   Expert  8 |    162 | CPU
DEBUG 01-15 10:09:35.850602.850602 lmp.py:1626]   Expert 60 |    167 | CPU
DEBUG 01-15 10:09:35.850815.850815 lmp.py:1626]   Expert 15 |    169 | CPU
DEBUG 01-15 10:09:35.850789.850789 lmp.py:1626]   Expert 44 |    169 | CPU
DEBUG 01-15 10:09:35.850909.850909 lmp.py:1626]   Expert 29 |    171 | CPU
DEBUG 01-15 10:09:35.850982.850982 lmp.py:1626]   Expert 54 |    174 | CPU
DEBUG 01-15 10:09:35.850148.850148 lmp.py:1626]   Expert 35 |    179 | CPU
DEBUG 01-15 10:09:35.850791.850791 lmp.py:1626]   Expert 34 |    180 | CPU
DEBUG 01-15 10:09:35.850434.850434 lmp.py:1626]   Expert 33 |    183 | CPU
DEBUG 01-15 10:09:35.850554.850554 lmp.py:1626]   Expert 47 |    188 | GPU
DEBUG 01-15 10:09:35.850674.850674 lmp.py:1626]   Expert  9 |    190 | GPU
DEBUG 01-15 10:09:35.850747.850747 lmp.py:1626]   Expert 19 |    195 | GPU
DEBUG 01-15 10:09:35.850913.850913 lmp.py:1626]   Expert 21 |    197 | GPU
DEBUG 01-15 10:09:35.850080.850080 lmp.py:1626]   Expert 46 |    197 | GPU
DEBUG 01-15 10:09:35.850246.850246 lmp.py:1626]   Expert  3 |    198 | GPU
DEBUG 01-15 10:09:35.850412.850412 lmp.py:1626]   Expert 56 |    198 | GPU
DEBUG 01-15 10:09:35.850770.850770 lmp.py:1626]   Expert 45 |    200 | GPU
DEBUG 01-15 10:09:35.850936.850936 lmp.py:1626]   Expert 49 |    201 | GPU
DEBUG 01-15 10:09:35.850626.850626 lmp.py:1626]   Expert 20 |    202 | GPU
DEBUG 01-15 10:09:35.850553.850553 lmp.py:1626]   Expert 28 |    207 | GPU
DEBUG 01-15 10:09:35.850719.850719 lmp.py:1626]   Expert 57 |    222 | GPU
DEBUG 01-15 10:09:35.850124.850124 lmp.py:1626]   Expert  2 |    223 | GPU
DEBUG 01-15 10:09:35.850529.850529 lmp.py:1626]   Expert 43 |    226 | GPU
DEBUG 01-15 10:09:35.850171.850171 lmp.py:1626]   Expert 13 |    227 | GPU
DEBUG 01-15 10:09:35.850814.850814 lmp.py:1626]   Expert  4 |    228 | GPU
DEBUG 01-15 10:09:35.850650.850650 lmp.py:1626]   Expert 10 |    238 | GPU
DEBUG 01-15 10:09:35.850577.850577 lmp.py:1626]   Expert 50 |    243 | GPU
DEBUG 01-15 10:09:35.850505.850505 lmp.py:1626]   Expert 41 |    245 | GPU
DEBUG 01-15 10:09:35.850194.850194 lmp.py:1626]   Expert 26 |    251 | GPU
DEBUG 01-15 10:09:35.850360.850360 lmp.py:1626]   Expert 63 |    254 | GPU
DEBUG 01-15 10:09:35.850288.850288 lmp.py:1626]   Expert 37 |    259 | GPU
DEBUG 01-15 10:09:35.851885.851885 lmp.py:1626]   Expert 61 |    272 | GPU
DEBUG 01-15 10:09:35.851005.851005 lmp.py:1626]   Expert 31 |    273 | GPU
DEBUG 01-15 10:09:35.851648.851648 lmp.py:1626]   Expert 52 |    304 | GPU
DEBUG 01-15 10:09:35.851052.851052 lmp.py:1626]   Expert 58 |    316 | GPU
DEBUG 01-15 10:09:35.851172.851172 lmp.py:1626]   Expert 62 |    324 | GPU
DEBUG 01-15 10:09:35.851053.851053 lmp.py:1626]   Expert 55 |    341 | GPU
DEBUG 01-15 10:09:35.851365.851365 lmp.py:1626]   Expert 11 |    379 | GPU
DEBUG 01-15 10:09:35.851055.851055 lmp.py:1626]   Expert 23 |    385 | GPU
DEBUG 01-15 10:09:35.851744.851744 lmp.py:1626]   Expert 25 |    406 | GPU
DEBUG 01-15 10:09:35.851672.851672 lmp.py:1626]   Expert  5 |    516 | GPU
DEBUG 01-15 10:09:35.851315.851315 lmp.py:1627] 
DEBUG 01-15 10:09:35.851315.851315 lmp.py:1627]   CPU total tokens: 3983 (32.4%)
DEBUG 01-15 10:09:35.851911.851911 lmp.py:1628]   GPU total tokens: 8305 (67.6%)
DEBUG 01-15 10:09:35.851707.851707 cuda_h.py:19] end experts_map_get cost 0.0015645027160644531 seconds
DEBUG 01-15 10:09:35.851272.851272 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.851458.851458 lmp.py:1636] 
DEBUG 01-15 10:09:35.851458.851458 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.851818.851818 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-15 10:09:35.851514.851514 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.851158.851158 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.851514.851514 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.853084.853084 cuda_h.py:19] end allocate_cuda_memory cost 0.001542806625366211 seconds
DEBUG 01-15 10:09:35.853549.853549 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.853113.853113 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.853591.853591 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.853433.853433 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 89ec79ce-b25c-49ce-b91f-4230ef77219e
DEBUG 01-15 10:09:35.853778.853778 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:35.853249.853249 client.py:127] Model loaded
DEBUG 01-15 10:09:35.854125.854125 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.854754.854754 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.854177.854177 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.854873.854873 cuda_h.py:19] end restore2model cost 0.0003447532653808594 seconds
DEBUG 01-15 10:09:35.854496.854496 cuda_h.py:19] end sllm_worker_task cost 0.010219812393188477 seconds
INFO 01-15 10:09:35.854724.854724 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 89ec79ce-b25c-49ce-b91f-4230ef77219e
DEBUG 01-15 10:09:35.854442.854442 cuda_h.py:19] end load_into_gpu_async cost 0.0015015602111816406 seconds
DEBUG 01-15 10:09:35.854529.854529 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.855863.855863 cuda_h.py:19] end move_flatidxs cost 0.0008742809295654297 seconds
DEBUG 01-15 10:09:35.855945.855945 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.855987.855987 cuda_h.py:19] end restore_tensors2 cost 0.0005865097045898438 seconds
DEBUG 01-15 10:09:35.855956.855956 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00403904914855957 seconds
DEBUG 01-15 10:09:35.855872.855872 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.858354.858354 cuda_h.py:19] end restore2model cost 0.0027151107788085938 seconds
DEBUG 01-15 10:09:35.858834.858834 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00695347785949707 seconds
DEBUG 01-15 10:09:35.858152.858152 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.858851.858851 cuda_h.py:19] end gpu_sexperts cost 0.00027561187744140625 seconds
DEBUG 01-15 10:09:35.858489.858489 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.861928.861928 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0022199153900146484 seconds
DEBUG 01-15 10:09:35.861652.861652 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.862295.862295 cuda_h.py:19] end gpu_group_list cost 0.00033855438232421875 seconds
DEBUG 01-15 10:09:35.862650.862650 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.863379.863379 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007767677307128906 seconds
DEBUG 01-15 10:09:35.863275.863275 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.863575.863575 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-15 10:09:35.863748.863748 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.866727.866727 cuda_h.py:19] end group_tensors cost 0.011454582214355469 seconds
DEBUG 01-15 10:09:35.867947.867947 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.873005.873005 cuda_h.py:19] end group pad cost 0.005258321762084961 seconds
DEBUG 01-15 10:09:35.873511.873511 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.894620.894620 cuda_h.py:19] end group_einsum cost 0.02176976203918457 seconds
DEBUG 01-15 10:09:35.895731.895731 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.903258.903258 cuda_h.py:19] end get_outputs_cpu1 cost 0.007967472076416016 seconds
DEBUG 01-15 10:09:35.903120.903120 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04964447021484375 seconds
DEBUG 01-15 10:09:35.907994.907994 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.043869972229003906 seconds
DEBUG 01-15 10:09:35.907740.907740 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.907511.907511 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.907775.907775 cuda_h.py:19] end index_scatter cost 0.00010395050048828125 seconds
DEBUG 01-15 10:09:35.908242.908242 cuda_h.py:19] end cpuoutputsdeal cost 0.0007162094116210938 seconds
DEBUG 01-15 10:09:35.908171.908171 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.908325.908325 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 89ec79ce-b25c-49ce-b91f-4230ef77219e
INFO 01-15 10:09:35.909308.909308 client.py:127] Model loaded
DEBUG 01-15 10:09:35.909032.909032 cuda_h.py:19] end wait_experts cost 0.0011610984802246094 seconds
DEBUG 01-15 10:09:35.909411.909411 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.909135.909135 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.909666.909666 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.909357.909357 cuda_h.py:19] end gpu_group_tensor cost 0.00022983551025390625 seconds
DEBUG 01-15 10:09:35.909004.909004 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.910964.910964 cuda_h.py:19] end gpu_group_einsum cost 0.0007276535034179688 seconds
DEBUG 01-15 10:09:35.910922.910922 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.910295.910295 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.911116.911116 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003466606140136719 seconds
DEBUG 01-15 10:09:35.911919.911919 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.911657.911657 cuda_h.py:19] end concat_expert_out cost 5.459785461425781e-05 seconds
DEBUG 01-15 10:09:35.911400.911400 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.911847.911847 cuda_h.py:19] end index_scatter cost 5.125999450683594e-05 seconds
DEBUG 01-15 10:09:35.911464.911464 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007026195526123047 seconds
DEBUG 01-15 10:09:35.911361.911361 cuda_h.py:19] end gpu_experts cost 0.002251863479614258 seconds
DEBUG 01-15 10:09:35.911708.911708 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.06290960311889648 seconds
DEBUG 01-15 10:09:35.912180.912180 cuda_h.py:19] end prefill_layer cost 0.06859898567199707 seconds
DEBUG 01-15 10:09:35.912276.912276 lmp.py:1552] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-15 10:09:35.912171.912171 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.912543.912543 lmp.py:1495] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-15 10:09:35.912915.912915 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:35.912386.912386 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:35.912388.912388 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 4.315376281738281e-05 seconds
DEBUG 01-15 10:09:35.912760.912760 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.390975952148438e-05 seconds
DEBUG 01-15 10:09:35.912840.912840 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.912711.912711 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.913691.913691 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.913408.913408 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.913847.913847 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.913125.913125 cuda_h.py:19] end allocate_cuda_memory cost 0.0004718303680419922 seconds
DEBUG 01-15 10:09:35.914396.914396 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.914115.914115 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.914331.914331 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.914930.914930 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b3659546-b830-4d56-8fd4-50776a53a755
DEBUG 01-15 10:09:35.914175.914175 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.914109.914109 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.915598.915598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b3659546-b830-4d56-8fd4-50776a53a755
DEBUG 01-15 10:09:35.915246.915246 cuda_h.py:19] end load_into_gpu_async cost 0.0017428398132324219 seconds
DEBUG 01-15 10:09:35.916183.916183 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.916277.916277 cuda_h.py:19] end restore_tensors2 cost 0.00015020370483398438 seconds
DEBUG 01-15 10:09:35.916023.916023 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031256675720214844 seconds
INFO 01-15 10:09:35.916499.916499 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b3659546-b830-4d56-8fd4-50776a53a755
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.918740.918740 cuda_h.py:19] end self_attn cost 0.003937959671020508 seconds
DEBUG 01-15 10:09:35.919122.919122 cuda_h.py:19] end iln_self_attn_paln cost 0.0063898563385009766 seconds
DEBUG 01-15 10:09:35.919819.919819 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-15 10:09:35.919151.919151 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.920600.920600 cuda_h.py:19] end gate cost 0.0007188320159912109 seconds
DEBUG 01-15 10:09:35.920476.920476 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.920579.920579 lmp.py:1616] 
DEBUG 01-15 10:09:35.920579.920579 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.920058.920058 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.920376.920376 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.920119.920119 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.920715.920715 lmp.py:1620] 
DEBUG 01-15 10:09:35.920715.920715 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.920550.920550 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.920101.920101 lmp.py:1626]   Expert 24 |     39 | CPU
DEBUG 01-15 10:09:35.920220.920220 lmp.py:1626]   Expert  2 |     46 | CPU
DEBUG 01-15 10:09:35.920863.920863 lmp.py:1626]   Expert 26 |     62 | CPU
DEBUG 01-15 10:09:35.920268.920268 lmp.py:1626]   Expert 32 |     65 | CPU
DEBUG 01-15 10:09:35.920434.920434 lmp.py:1626]   Expert 19 |     68 | CPU
DEBUG 01-15 10:09:35.920362.920362 lmp.py:1626]   Expert 50 |     69 | CPU
DEBUG 01-15 10:09:35.920290.920290 lmp.py:1626]   Expert 15 |     79 | CPU
DEBUG 01-15 10:09:35.920217.920217 lmp.py:1626]   Expert  4 |     81 | CPU
DEBUG 01-15 10:09:35.920099.920099 lmp.py:1626]   Expert 28 |     82 | CPU
DEBUG 01-15 10:09:35.920980.920980 lmp.py:1626]   Expert  7 |     84 | CPU
DEBUG 01-15 10:09:35.920623.920623 lmp.py:1626]   Expert 60 |     84 | CPU
DEBUG 01-15 10:09:35.920266.920266 lmp.py:1626]   Expert 59 |     90 | CPU
DEBUG 01-15 10:09:35.920909.920909 lmp.py:1626]   Expert 49 |     96 | CPU
DEBUG 01-15 10:09:35.920075.920075 lmp.py:1626]   Expert 23 |    100 | CPU
DEBUG 01-15 10:09:35.920480.920480 lmp.py:1626]   Expert  5 |    102 | CPU
DEBUG 01-15 10:09:35.920407.920407 lmp.py:1626]   Expert 12 |    106 | CPU
DEBUG 01-15 10:09:35.920335.920335 lmp.py:1626]   Expert 10 |    111 | CPU
DEBUG 01-15 10:09:35.920263.920263 lmp.py:1626]   Expert 27 |    112 | CPU
DEBUG 01-15 10:09:35.920714.920714 lmp.py:1626]   Expert 41 |    120 | CPU
DEBUG 01-15 10:09:35.920641.920641 lmp.py:1626]   Expert  3 |    126 | CPU
DEBUG 01-15 10:09:35.920000.920000 lmp.py:1626]   Expert 20 |    128 | CPU
DEBUG 01-15 10:09:35.920643.920643 lmp.py:1626]   Expert 25 |    128 | CPU
DEBUG 01-15 10:09:35.920047.920047 lmp.py:1626]   Expert 40 |    128 | CPU
DEBUG 01-15 10:09:35.920452.920452 lmp.py:1626]   Expert 13 |    133 | CPU
DEBUG 01-15 10:09:35.920856.920856 lmp.py:1626]   Expert 16 |    133 | CPU
DEBUG 01-15 10:09:35.920022.920022 lmp.py:1626]   Expert 17 |    144 | CPU
DEBUG 01-15 10:09:35.920189.920189 lmp.py:1626]   Expert 37 |    146 | CPU
DEBUG 01-15 10:09:35.921878.921878 lmp.py:1626]   Expert 35 |    147 | CPU
DEBUG 01-15 10:09:35.921806.921806 lmp.py:1626]   Expert 47 |    154 | CPU
DEBUG 01-15 10:09:35.921495.921495 lmp.py:1626]   Expert 22 |    160 | CPU
DEBUG 01-15 10:09:35.921184.921184 lmp.py:1626]   Expert 53 |    165 | CPU
DEBUG 01-15 10:09:35.921112.921112 lmp.py:1626]   Expert 39 |    171 | CPU
DEBUG 01-15 10:09:35.921801.921801 lmp.py:1626]   Expert 38 |    177 | GPU
DEBUG 01-15 10:09:35.921491.921491 lmp.py:1626]   Expert 44 |    178 | GPU
DEBUG 01-15 10:09:35.921610.921610 lmp.py:1626]   Expert 36 |    183 | GPU
DEBUG 01-15 10:09:35.921015.921015 lmp.py:1626]   Expert 52 |    183 | GPU
DEBUG 01-15 10:09:35.921658.921658 lmp.py:1626]   Expert 58 |    184 | GPU
DEBUG 01-15 10:09:35.921301.921301 lmp.py:1626]   Expert 18 |    186 | GPU
DEBUG 01-15 10:09:35.921229.921229 lmp.py:1626]   Expert 62 |    197 | GPU
DEBUG 01-15 10:09:35.921156.921156 lmp.py:1626]   Expert 11 |    208 | GPU
DEBUG 01-15 10:09:35.921607.921607 lmp.py:1626]   Expert 48 |    210 | GPU
DEBUG 01-15 10:09:35.921535.921535 lmp.py:1626]   Expert 14 |    217 | GPU
DEBUG 01-15 10:09:35.921224.921224 lmp.py:1626]   Expert 30 |    217 | GPU
DEBUG 01-15 10:09:35.921152.921152 lmp.py:1626]   Expert  1 |    229 | GPU
DEBUG 01-15 10:09:35.921318.921318 lmp.py:1626]   Expert 42 |    235 | GPU
DEBUG 01-15 10:09:35.921007.921007 lmp.py:1626]   Expert 45 |    235 | GPU
DEBUG 01-15 10:09:35.921174.921174 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:35.921101.921101 lmp.py:1626]   Expert 51 |    241 | GPU
DEBUG 01-15 10:09:35.921791.921791 lmp.py:1626]   Expert  6 |    242 | GPU
DEBUG 01-15 10:09:35.921957.921957 lmp.py:1626]   Expert 29 |    264 | GPU
DEBUG 01-15 10:09:35.921361.921361 lmp.py:1626]   Expert 34 |    264 | GPU
DEBUG 01-15 10:09:35.921766.921766 lmp.py:1626]   Expert 33 |    275 | GPU
DEBUG 01-15 10:09:35.921409.921409 lmp.py:1626]   Expert 57 |    297 | GPU
DEBUG 01-15 10:09:35.921575.921575 lmp.py:1626]   Expert 61 |    305 | GPU
DEBUG 01-15 10:09:35.921741.921741 lmp.py:1626]   Expert 43 |    309 | GPU
DEBUG 01-15 10:09:35.921669.921669 lmp.py:1626]   Expert  0 |    322 | GPU
DEBUG 01-15 10:09:35.921120.921120 lmp.py:1626]   Expert 46 |    350 | GPU
DEBUG 01-15 10:09:35.921286.921286 lmp.py:1626]   Expert  8 |    381 | GPU
DEBUG 01-15 10:09:35.921975.921975 lmp.py:1626]   Expert 56 |    392 | GPU
DEBUG 01-15 10:09:35.921426.921426 lmp.py:1626]   Expert  9 |    393 | GPU
DEBUG 01-15 10:09:35.921115.921115 lmp.py:1626]   Expert 54 |    396 | GPU
DEBUG 01-15 10:09:35.921520.921520 lmp.py:1626]   Expert 63 |    411 | GPU
DEBUG 01-15 10:09:35.921924.921924 lmp.py:1626]   Expert 55 |    425 | GPU
DEBUG 01-15 10:09:35.921329.921329 lmp.py:1626]   Expert 21 |    486 | GPU
DEBUG 01-15 10:09:35.921449.921449 lmp.py:1627] 
DEBUG 01-15 10:09:35.921449.921449 lmp.py:1627]   CPU total tokens: 3459 (28.1%)
DEBUG 01-15 10:09:35.921807.921807 lmp.py:1628]   GPU total tokens: 8829 (71.9%)
DEBUG 01-15 10:09:35.921741.921741 cuda_h.py:19] end experts_map_get cost 0.0015723705291748047 seconds
DEBUG 01-15 10:09:35.921598.921598 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.921447.921447 lmp.py:1636] 
DEBUG 01-15 10:09:35.921447.921447 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.921190.921190 cuda_h.py:19] end cpu_experts_submit cost 5.602836608886719e-05 seconds
DEBUG 01-15 10:09:35.921171.921171 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.921385.921385 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.922456.922456 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.923286.923286 cuda_h.py:19] end allocate_cuda_memory cost 0.0009984970092773438 seconds
DEBUG 01-15 10:09:35.923602.923602 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.923033.923033 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.923942.923942 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.923214.923214 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 58b37cba-5783-453f-9fd0-ae1de843f86e
DEBUG 01-15 10:09:35.923147.923147 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:35.923739.923739 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.923192.923192 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:35.923134.923134 client.py:127] Model loaded
DEBUG 01-15 10:09:35.924535.924535 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.924105.924105 cuda_h.py:19] end restore2model cost 0.0003838539123535156 seconds
DEBUG 01-15 10:09:35.924167.924167 cuda_h.py:19] end sllm_worker_task cost 0.0113983154296875 seconds
DEBUG 01-15 10:09:35.924024.924024 cuda_h.py:19] end move_flatidxs cost 0.0008418560028076172 seconds
INFO 01-15 10:09:35.924778.924778 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 58b37cba-5783-453f-9fd0-ae1de843f86e
DEBUG 01-15 10:09:35.924231.924231 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.924887.924887 cuda_h.py:19] end load_into_gpu_async cost 0.0013625621795654297 seconds
DEBUG 01-15 10:09:35.924120.924120 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.925071.925071 cuda_h.py:19] end restore_tensors2 cost 0.0006690025329589844 seconds
DEBUG 01-15 10:09:35.925067.925067 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003740549087524414 seconds
DEBUG 01-15 10:09:35.925248.925248 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.928034.928034 cuda_h.py:19] end restore2model cost 0.0026504993438720703 seconds
DEBUG 01-15 10:09:35.928029.928029 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0066149234771728516 seconds
DEBUG 01-15 10:09:35.928825.928825 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.928623.928623 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-15 10:09:35.928068.928068 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.930797.930797 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015549659729003906 seconds
DEBUG 01-15 10:09:35.931442.931442 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.930254.930254 cuda_h.py:19] end group_tensors cost 0.005805492401123047 seconds
DEBUG 01-15 10:09:35.931747.931747 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:35.931972.931972 cuda_h.py:19] end gpu_group_list cost 0.0003180503845214844 seconds
DEBUG 01-15 10:09:35.931661.931661 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.933367.933367 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011909008026123047 seconds
DEBUG 01-15 10:09:35.933218.933218 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.933982.933982 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-15 10:09:35.933360.933360 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:35.936669.936669 cuda_h.py:19] end group pad cost 0.0048983097076416016 seconds
DEBUG 01-15 10:09:35.936412.936412 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:35.954360.954360 cuda_h.py:19] end group_einsum cost 0.01813673973083496 seconds
DEBUG 01-15 10:09:35.954809.954809 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:35.959010.959010 cuda_h.py:19] end get_outputs_cpu1 cost 0.004148244857788086 seconds
DEBUG 01-15 10:09:35.959836.959836 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03615069389343262 seconds
DEBUG 01-15 10:09:35.960753.960753 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.027295351028442383 seconds
DEBUG 01-15 10:09:35.960658.960658 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:35.961308.961308 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.961544.961544 cuda_h.py:19] end index_scatter cost 8.058547973632812e-05 seconds
DEBUG 01-15 10:09:35.961228.961228 cuda_h.py:19] end cpuoutputsdeal cost 0.0007698535919189453 seconds
DEBUG 01-15 10:09:35.961435.961435 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:35.961721.961721 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 58b37cba-5783-453f-9fd0-ae1de843f86e
INFO 01-15 10:09:35.973070.973070 client.py:127] Model loaded
DEBUG 01-15 10:09:35.973258.973258 cuda_h.py:19] end wait_experts cost 0.012093544006347656 seconds
DEBUG 01-15 10:09:35.973722.973722 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:35.973685.973685 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:35.974931.974931 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:35.974847.974847 cuda_h.py:19] end gpu_group_tensor cost 0.00021505355834960938 seconds
DEBUG 01-15 10:09:35.974487.974487 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:35.975403.975403 cuda_h.py:19] end gpu_group_einsum cost 0.0005953311920166016 seconds
DEBUG 01-15 10:09:35.975758.975758 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:35.975925.975925 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:35.975861.975861 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002396106719970703 seconds
DEBUG 01-15 10:09:35.975471.975471 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:35.975779.975779 cuda_h.py:19] end concat_expert_out cost 5.602836608886719e-05 seconds
DEBUG 01-15 10:09:35.975159.975159 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:35.975612.975612 cuda_h.py:19] end index_scatter cost 5.8650970458984375e-05 seconds
DEBUG 01-15 10:09:35.975130.975130 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005865097045898438 seconds
DEBUG 01-15 10:09:35.975477.975477 cuda_h.py:19] end gpu_experts cost 0.0019311904907226562 seconds
DEBUG 01-15 10:09:35.975910.975910 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.056673526763916016 seconds
DEBUG 01-15 10:09:35.976661.976661 cuda_h.py:19] end prefill_layer cost 0.06384778022766113 seconds
DEBUG 01-15 10:09:35.976042.976042 lmp.py:1552] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-15 10:09:35.976692.976692 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:35.976818.976818 lmp.py:1495] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-15 10:09:35.976422.976422 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:35.976793.976793 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:35.976822.976822 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.24249267578125e-05 seconds
DEBUG 01-15 10:09:35.976187.976187 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.817413330078125e-05 seconds
DEBUG 01-15 10:09:35.976068.976068 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:35.976455.976455 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:35.976332.976332 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:35.976885.976885 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.977482.977482 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.977102.977102 cuda_h.py:19] end allocate_cuda_memory cost 0.0002815723419189453 seconds
DEBUG 01-15 10:09:35.977998.977998 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.977185.977185 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.977915.977915 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.977426.977426 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e68808c2-62cc-4097-8f95-4c5d0861cb1f
DEBUG 01-15 10:09:35.977303.977303 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:35.977663.977663 cuda_h.py:10] start self_attn
INFO 01-15 10:09:35.978380.978380 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e68808c2-62cc-4097-8f95-4c5d0861cb1f
DEBUG 01-15 10:09:35.978071.978071 cuda_h.py:19] end load_into_gpu_async cost 0.0009338855743408203 seconds
DEBUG 01-15 10:09:35.978105.978105 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.978671.978671 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-15 10:09:35.978950.978950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015254020690917969 seconds
INFO 01-15 10:09:35.978640.978640 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e68808c2-62cc-4097-8f95-4c5d0861cb1f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:35.981393.981393 cuda_h.py:19] end self_attn cost 0.0031464099884033203 seconds
DEBUG 01-15 10:09:35.981244.981244 cuda_h.py:19] end iln_self_attn_paln cost 0.004631519317626953 seconds
DEBUG 01-15 10:09:35.981465.981465 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-15 10:09:35.981082.981082 cuda_h.py:10] start gate
DEBUG 01-15 10:09:35.982370.982370 cuda_h.py:19] end gate cost 0.0006709098815917969 seconds
DEBUG 01-15 10:09:35.982107.982107 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:35.982382.982382 lmp.py:1616] 
DEBUG 01-15 10:09:35.982382.982382 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:35.982423.982423 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:35.982073.982073 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:35.982623.982623 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:35.982266.982266 lmp.py:1620] 
DEBUG 01-15 10:09:35.982266.982266 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:35.982624.982624 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:35.982698.982698 lmp.py:1626]   Expert 43 |     16 | CPU
DEBUG 01-15 10:09:35.982341.982341 lmp.py:1626]   Expert 27 |     31 | CPU
DEBUG 01-15 10:09:35.982030.982030 lmp.py:1626]   Expert 26 |     52 | CPU
DEBUG 01-15 10:09:35.982958.982958 lmp.py:1626]   Expert 34 |     53 | CPU
DEBUG 01-15 10:09:35.982409.982409 lmp.py:1626]   Expert 56 |     55 | CPU
DEBUG 01-15 10:09:35.982336.982336 lmp.py:1626]   Expert  3 |     59 | CPU
DEBUG 01-15 10:09:35.982787.982787 lmp.py:1626]   Expert  4 |     65 | CPU
DEBUG 01-15 10:09:35.982476.982476 lmp.py:1626]   Expert 61 |     80 | CPU
DEBUG 01-15 10:09:35.982643.982643 lmp.py:1626]   Expert 14 |     93 | CPU
DEBUG 01-15 10:09:35.982524.982524 lmp.py:1626]   Expert 38 |    100 | CPU
DEBUG 01-15 10:09:35.982929.982929 lmp.py:1626]   Expert  2 |    110 | CPU
DEBUG 01-15 10:09:35.982333.982333 lmp.py:1626]   Expert 17 |    119 | CPU
DEBUG 01-15 10:09:35.982499.982499 lmp.py:1626]   Expert 22 |    122 | CPU
DEBUG 01-15 10:09:35.982427.982427 lmp.py:1626]   Expert 47 |    129 | CPU
DEBUG 01-15 10:09:35.982116.982116 lmp.py:1626]   Expert 37 |    131 | CPU
DEBUG 01-15 10:09:35.982806.982806 lmp.py:1626]   Expert 55 |    132 | CPU
DEBUG 01-15 10:09:35.982256.982256 lmp.py:1626]   Expert 28 |    138 | CPU
DEBUG 01-15 10:09:35.982184.982184 lmp.py:1626]   Expert 54 |    138 | CPU
DEBUG 01-15 10:09:35.982112.982112 lmp.py:1626]   Expert  5 |    143 | CPU
DEBUG 01-15 10:09:35.982563.982563 lmp.py:1626]   Expert  7 |    145 | CPU
DEBUG 01-15 10:09:35.983014.983014 lmp.py:1626]   Expert 15 |    146 | CPU
DEBUG 01-15 10:09:35.983657.983657 lmp.py:1626]   Expert 48 |    146 | CPU
DEBUG 01-15 10:09:35.983823.983823 lmp.py:1626]   Expert 60 |    147 | CPU
DEBUG 01-15 10:09:35.983227.983227 lmp.py:1626]   Expert 45 |    148 | CPU
DEBUG 01-15 10:09:35.983393.983393 lmp.py:1626]   Expert 51 |    149 | CPU
DEBUG 01-15 10:09:35.983844.983844 lmp.py:1626]   Expert 63 |    153 | CPU
DEBUG 01-15 10:09:35.983057.983057 lmp.py:1626]   Expert 12 |    157 | CPU
DEBUG 01-15 10:09:35.983508.983508 lmp.py:1626]   Expert 19 |    157 | CPU
DEBUG 01-15 10:09:35.983959.983959 lmp.py:1626]   Expert 57 |    166 | CPU
DEBUG 01-15 10:09:35.983409.983409 lmp.py:1626]   Expert  6 |    167 | CPU
DEBUG 01-15 10:09:35.983860.983860 lmp.py:1626]   Expert 52 |    172 | CPU
DEBUG 01-15 10:09:35.983073.983073 lmp.py:1626]   Expert 50 |    180 | CPU
DEBUG 01-15 10:09:35.983524.983524 lmp.py:1626]   Expert 18 |    181 | GPU
DEBUG 01-15 10:09:35.983975.983975 lmp.py:1626]   Expert 44 |    182 | GPU
DEBUG 01-15 10:09:35.983664.983664 lmp.py:1626]   Expert 31 |    184 | GPU
DEBUG 01-15 10:09:35.983592.983592 lmp.py:1626]   Expert 30 |    189 | GPU
DEBUG 01-15 10:09:35.983758.983758 lmp.py:1626]   Expert 13 |    191 | GPU
DEBUG 01-15 10:09:35.983924.983924 lmp.py:1626]   Expert 23 |    193 | GPU
DEBUG 01-15 10:09:35.983567.983567 lmp.py:1626]   Expert 39 |    197 | GPU
DEBUG 01-15 10:09:35.983256.983256 lmp.py:1626]   Expert 53 |    197 | GPU
DEBUG 01-15 10:09:35.983230.983230 lmp.py:1626]   Expert 59 |    197 | GPU
DEBUG 01-15 10:09:35.983681.983681 lmp.py:1626]   Expert 20 |    200 | GPU
DEBUG 01-15 10:09:35.983609.983609 lmp.py:1626]   Expert 21 |    202 | GPU
DEBUG 01-15 10:09:35.983060.983060 lmp.py:1626]   Expert 29 |    203 | GPU
DEBUG 01-15 10:09:35.983510.983510 lmp.py:1626]   Expert 16 |    210 | GPU
DEBUG 01-15 10:09:35.983200.983200 lmp.py:1626]   Expert 36 |    212 | GPU
DEBUG 01-15 10:09:35.983651.983651 lmp.py:1626]   Expert 25 |    219 | GPU
DEBUG 01-15 10:09:35.983578.983578 lmp.py:1626]   Expert 41 |    220 | GPU
DEBUG 01-15 10:09:35.983983.983983 lmp.py:1626]   Expert 49 |    223 | GPU
DEBUG 01-15 10:09:35.983149.983149 lmp.py:1626]   Expert 32 |    227 | GPU
DEBUG 01-15 10:09:35.983315.983315 lmp.py:1626]   Expert 46 |    237 | GPU
DEBUG 01-15 10:09:35.983481.983481 lmp.py:1626]   Expert 10 |    249 | GPU
DEBUG 01-15 10:09:35.983171.983171 lmp.py:1626]   Expert  8 |    250 | GPU
DEBUG 01-15 10:09:35.983622.983622 lmp.py:1626]   Expert 42 |    252 | GPU
DEBUG 01-15 10:09:35.983072.983072 lmp.py:1626]   Expert 62 |    266 | GPU
DEBUG 01-15 10:09:35.983523.983523 lmp.py:1626]   Expert 35 |    279 | GPU
DEBUG 01-15 10:09:35.983736.983736 lmp.py:1626]   Expert 33 |    290 | GPU
DEBUG 01-15 10:09:35.983902.983902 lmp.py:1626]   Expert  9 |    293 | GPU
DEBUG 01-15 10:09:35.983545.983545 lmp.py:1626]   Expert 58 |    297 | GPU
DEBUG 01-15 10:09:35.983711.983711 lmp.py:1626]   Expert 40 |    386 | GPU
DEBUG 01-15 10:09:35.983639.983639 lmp.py:1626]   Expert 11 |    421 | GPU
DEBUG 01-15 10:09:35.983043.983043 lmp.py:1626]   Expert  0 |    428 | GPU
DEBUG 01-15 10:09:35.983494.983494 lmp.py:1626]   Expert 24 |    565 | GPU
DEBUG 01-15 10:09:35.983707.983707 lmp.py:1626]   Expert  1 |    649 | GPU
DEBUG 01-15 10:09:35.983634.983634 lmp.py:1627] 
DEBUG 01-15 10:09:35.983634.983634 lmp.py:1627]   CPU total tokens: 3799 (30.9%)
DEBUG 01-15 10:09:35.983800.983800 lmp.py:1628]   GPU total tokens: 8489 (69.1%)
DEBUG 01-15 10:09:35.983543.983543 cuda_h.py:19] end experts_map_get cost 0.0015234947204589844 seconds
DEBUG 01-15 10:09:35.983293.983293 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:35.983904.983904 lmp.py:1636] 
DEBUG 01-15 10:09:35.983904.983904 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:35.983263.983263 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-15 10:09:35.983529.983529 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:35.984265.984265 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:35.984522.984522 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:35.985423.985423 cuda_h.py:19] end allocate_cuda_memory cost 0.001367807388305664 seconds
DEBUG 01-15 10:09:35.985426.985426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:35.985136.985136 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:35.985753.985753 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:35.985925.985925 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b34ac51-e547-4428-80ac-d36e83b961a4
DEBUG 01-15 10:09:35.985442.985442 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:35.986234.986234 client.py:127] Model loaded
DEBUG 01-15 10:09:35.986985.986985 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.986844.986844 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:35.986217.986217 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b34ac51-e547-4428-80ac-d36e83b961a4
DEBUG 01-15 10:09:35.986935.986935 cuda_h.py:19] end load_into_gpu_async cost 0.001325368881225586 seconds
DEBUG 01-15 10:09:35.987830.987830 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:35.987354.987354 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:35.987713.987713 cuda_h.py:19] end restore_tensors2 cost 0.0006182193756103516 seconds
DEBUG 01-15 10:09:35.987982.987982 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037641525268554688 seconds
DEBUG 01-15 10:09:35.987811.987811 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:35.988528.988528 cuda_h.py:19] end restore2model cost 0.0002124309539794922 seconds
DEBUG 01-15 10:09:35.988916.988916 cuda_h.py:19] end sllm_worker_task cost 0.011228322982788086 seconds
DEBUG 01-15 10:09:35.988662.988662 cuda_h.py:19] end move_flatidxs cost 0.0011816024780273438 seconds
DEBUG 01-15 10:09:35.988825.988825 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:35.990421.990421 cuda_h.py:19] end restore2model cost 0.002943277359008789 seconds
DEBUG 01-15 10:09:35.990708.990708 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006923198699951172 seconds
DEBUG 01-15 10:09:35.990504.990504 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:35.991342.991342 cuda_h.py:19] end gpu_sexperts cost 0.00026988983154296875 seconds
DEBUG 01-15 10:09:35.991933.991933 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:35.992939.992939 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001550436019897461 seconds
DEBUG 01-15 10:09:35.993624.993624 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:35.994246.994246 cuda_h.py:19] end gpu_group_list cost 0.000316619873046875 seconds
DEBUG 01-15 10:09:35.994409.994409 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:35.995814.995814 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007853507995605469 seconds
DEBUG 01-15 10:09:35.995995.995995 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:35.995056.995056 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-15 10:09:35.995183.995183 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.004254.004254 cuda_h.py:19] end group_tensors cost 0.015466928482055664 seconds
DEBUG 01-15 10:09:36.005155.005155 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.009626.009626 cuda_h.py:19] end group pad cost 0.00449824333190918 seconds
DEBUG 01-15 10:09:36.009800.009800 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.031691.031691 cuda_h.py:19] end group_einsum cost 0.021175146102905273 seconds
DEBUG 01-15 10:09:36.031855.031855 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.036407.036407 cuda_h.py:19] end get_outputs_cpu1 cost 0.004753589630126953 seconds
DEBUG 01-15 10:09:36.036317.036317 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04994940757751465 seconds
DEBUG 01-15 10:09:36.037133.037133 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.042174577713012695 seconds
DEBUG 01-15 10:09:36.037502.037502 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.037181.037181 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.038636.038636 cuda_h.py:19] end index_scatter cost 0.00010037422180175781 seconds
DEBUG 01-15 10:09:36.038096.038096 cuda_h.py:19] end cpuoutputsdeal cost 0.0006794929504394531 seconds
DEBUG 01-15 10:09:36.038402.038402 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.038125.038125 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b34ac51-e547-4428-80ac-d36e83b961a4
INFO 01-15 10:09:36.039664.039664 client.py:127] Model loaded
DEBUG 01-15 10:09:36.039368.039368 cuda_h.py:19] end wait_experts cost 0.0011360645294189453 seconds
DEBUG 01-15 10:09:36.039402.039402 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.039590.039590 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.039915.039915 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.039631.039631 cuda_h.py:19] end gpu_group_tensor cost 0.0001850128173828125 seconds
DEBUG 01-15 10:09:36.039780.039780 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.040447.040447 cuda_h.py:19] end gpu_group_einsum cost 0.0008287429809570312 seconds
DEBUG 01-15 10:09:36.041065.041065 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.041684.041684 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.041117.041117 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002486705780029297 seconds
DEBUG 01-15 10:09:36.041310.041310 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.041427.041427 cuda_h.py:19] end concat_expert_out cost 8.702278137207031e-05 seconds
DEBUG 01-15 10:09:36.041390.041390 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.041645.041645 cuda_h.py:19] end index_scatter cost 7.796287536621094e-05 seconds
DEBUG 01-15 10:09:36.041931.041931 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006947517395019531 seconds
DEBUG 01-15 10:09:36.041756.041756 cuda_h.py:19] end gpu_experts cost 0.002447843551635742 seconds
DEBUG 01-15 10:09:36.042117.042117 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.06059741973876953 seconds
DEBUG 01-15 10:09:36.042454.042454 cuda_h.py:19] end prefill_layer cost 0.06605076789855957 seconds
DEBUG 01-15 10:09:36.042761.042761 lmp.py:1552] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-15 10:09:36.042034.042034 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.042306.042306 lmp.py:1495] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-15 10:09:36.042247.042247 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:36.042288.042288 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:36.042529.042529 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 4.267692565917969e-05 seconds
DEBUG 01-15 10:09:36.042722.042722 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 8.296966552734375e-05 seconds
DEBUG 01-15 10:09:36.042564.042564 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.043347.043347 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.043892.043892 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.043583.043583 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.043476.043476 cuda_h.py:19] end allocate_cuda_memory cost 0.000335693359375 seconds
DEBUG 01-15 10:09:36.043538.043538 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.043447.043447 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.043091.043091 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.043993.043993 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1bea906b-0533-44b0-a789-cbeb4e26e4e8
DEBUG 01-15 10:09:36.043175.043175 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.044923.044923 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.044506.044506 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.044757.044757 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1bea906b-0533-44b0-a789-cbeb4e26e4e8
DEBUG 01-15 10:09:36.044388.044388 cuda_h.py:19] end load_into_gpu_async cost 0.0012197494506835938 seconds
DEBUG 01-15 10:09:36.044482.044482 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.045275.045275 cuda_h.py:19] end restore_tensors2 cost 9.417533874511719e-05 seconds
DEBUG 01-15 10:09:36.045898.045898 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019414424896240234 seconds
INFO 01-15 10:09:36.045451.045451 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1bea906b-0533-44b0-a789-cbeb4e26e4e8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.048043.048043 cuda_h.py:19] end self_attn cost 0.0040853023529052734 seconds
DEBUG 01-15 10:09:36.048974.048974 cuda_h.py:19] end iln_self_attn_paln cost 0.005887508392333984 seconds
DEBUG 01-15 10:09:36.048010.048010 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-15 10:09:36.048295.048295 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.049922.049922 cuda_h.py:19] end gate cost 0.0006725788116455078 seconds
DEBUG 01-15 10:09:36.049659.049659 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.050239.050239 lmp.py:1616] 
DEBUG 01-15 10:09:36.050239.050239 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.050472.050472 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.050552.050552 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.050818.050818 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.050176.050176 lmp.py:1620] 
DEBUG 01-15 10:09:36.050176.050176 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.050726.050726 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.050515.050515 lmp.py:1626]   Expert 13 |     16 | CPU
DEBUG 01-15 10:09:36.050158.050158 lmp.py:1626]   Expert 39 |     17 | CPU
DEBUG 01-15 10:09:36.050086.050086 lmp.py:1626]   Expert 49 |     38 | CPU
DEBUG 01-15 10:09:36.050013.050013 lmp.py:1626]   Expert 35 |     54 | CPU
DEBUG 01-15 10:09:36.050703.050703 lmp.py:1626]   Expert 19 |     62 | CPU
DEBUG 01-15 10:09:36.050630.050630 lmp.py:1626]   Expert 32 |     73 | CPU
DEBUG 01-15 10:09:36.050320.050320 lmp.py:1626]   Expert  9 |     74 | CPU
DEBUG 01-15 10:09:36.050009.050009 lmp.py:1626]   Expert 26 |     74 | CPU
DEBUG 01-15 10:09:36.050666.050666 lmp.py:1626]   Expert 41 |     77 | CPU
DEBUG 01-15 10:09:36.050640.050640 lmp.py:1626]   Expert 33 |     83 | CPU
DEBUG 01-15 10:09:36.050614.050614 lmp.py:1626]   Expert 23 |     86 | CPU
DEBUG 01-15 10:09:36.050541.050541 lmp.py:1626]   Expert 46 |     89 | CPU
DEBUG 01-15 10:09:36.050231.050231 lmp.py:1626]   Expert 18 |     90 | CPU
DEBUG 01-15 10:09:36.050920.050920 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:36.050609.050609 lmp.py:1626]   Expert 38 |    100 | CPU
DEBUG 01-15 10:09:36.050060.050060 lmp.py:1626]   Expert  3 |    104 | CPU
DEBUG 01-15 10:09:36.050511.050511 lmp.py:1626]   Expert  6 |    104 | CPU
DEBUG 01-15 10:09:36.050247.050247 lmp.py:1626]   Expert 17 |    105 | CPU
DEBUG 01-15 10:09:36.050459.050459 lmp.py:1626]   Expert 20 |    117 | CPU
DEBUG 01-15 10:09:36.050195.050195 lmp.py:1626]   Expert 40 |    128 | CPU
DEBUG 01-15 10:09:36.050407.050407 lmp.py:1626]   Expert 61 |    130 | CPU
DEBUG 01-15 10:09:36.050381.050381 lmp.py:1626]   Expert 62 |    133 | CPU
DEBUG 01-15 10:09:36.050355.050355 lmp.py:1626]   Expert 43 |    134 | CPU
DEBUG 01-15 10:09:36.050045.050045 lmp.py:1626]   Expert 15 |    136 | CPU
DEBUG 01-15 10:09:36.050734.050734 lmp.py:1626]   Expert 44 |    136 | CPU
DEBUG 01-15 10:09:36.050423.050423 lmp.py:1626]   Expert 50 |    136 | CPU
DEBUG 01-15 10:09:36.050636.050636 lmp.py:1626]   Expert 16 |    137 | CPU
DEBUG 01-15 10:09:36.050325.050325 lmp.py:1626]   Expert 63 |    141 | CPU
DEBUG 01-15 10:09:36.050537.050537 lmp.py:1626]   Expert 59 |    142 | CPU
DEBUG 01-15 10:09:36.050273.050273 lmp.py:1626]   Expert 42 |    144 | CPU
DEBUG 01-15 10:09:36.050009.050009 lmp.py:1626]   Expert  2 |    148 | CPU
DEBUG 01-15 10:09:36.050413.050413 lmp.py:1626]   Expert 36 |    149 | CPU
DEBUG 01-15 10:09:36.050341.050341 lmp.py:1626]   Expert 10 |    159 | GPU
DEBUG 01-15 10:09:36.050030.050030 lmp.py:1626]   Expert  5 |    179 | GPU
DEBUG 01-15 10:09:36.050481.050481 lmp.py:1626]   Expert 34 |    185 | GPU
DEBUG 01-15 10:09:36.050170.050170 lmp.py:1626]   Expert 52 |    186 | GPU
DEBUG 01-15 10:09:36.050098.050098 lmp.py:1626]   Expert 27 |    188 | GPU
DEBUG 01-15 10:09:36.050264.050264 lmp.py:1626]   Expert 45 |    191 | GPU
DEBUG 01-15 10:09:36.050192.050192 lmp.py:1626]   Expert 60 |    198 | GPU
DEBUG 01-15 10:09:36.050358.050358 lmp.py:1626]   Expert 48 |    208 | GPU
DEBUG 01-15 10:09:36.050286.050286 lmp.py:1626]   Expert 51 |    211 | GPU
DEBUG 01-15 10:09:36.050929.050929 lmp.py:1626]   Expert 56 |    215 | GPU
DEBUG 01-15 10:09:36.050141.050141 lmp.py:1626]   Expert 53 |    230 | GPU
DEBUG 01-15 10:09:36.050831.050831 lmp.py:1626]   Expert  7 |    232 | GPU
DEBUG 01-15 10:09:36.050281.050281 lmp.py:1626]   Expert 24 |    232 | GPU
DEBUG 01-15 10:09:36.050971.050971 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:36.050660.050660 lmp.py:1626]   Expert 57 |    252 | GPU
DEBUG 01-15 10:09:36.050873.050873 lmp.py:1626]   Expert 47 |    253 | GPU
DEBUG 01-15 10:09:36.051323.051323 lmp.py:1626]   Expert 29 |    261 | GPU
DEBUG 01-15 10:09:36.051728.051728 lmp.py:1626]   Expert 21 |    262 | GPU
DEBUG 01-15 10:09:36.051656.051656 lmp.py:1626]   Expert  4 |    286 | GPU
DEBUG 01-15 10:09:36.051299.051299 lmp.py:1626]   Expert 14 |    288 | GPU
DEBUG 01-15 10:09:36.051465.051465 lmp.py:1626]   Expert  0 |    289 | GPU
DEBUG 01-15 10:09:36.051631.051631 lmp.py:1626]   Expert 22 |    316 | GPU
DEBUG 01-15 10:09:36.051320.051320 lmp.py:1626]   Expert 58 |    316 | GPU
DEBUG 01-15 10:09:36.051248.051248 lmp.py:1626]   Expert  1 |    317 | GPU
DEBUG 01-15 10:09:36.051699.051699 lmp.py:1626]   Expert 37 |    318 | GPU
DEBUG 01-15 10:09:36.051150.051150 lmp.py:1626]   Expert 55 |    318 | GPU
DEBUG 01-15 10:09:36.051601.051601 lmp.py:1626]   Expert 54 |    332 | GPU
DEBUG 01-15 10:09:36.051813.051813 lmp.py:1626]   Expert 28 |    363 | GPU
DEBUG 01-15 10:09:36.051502.051502 lmp.py:1626]   Expert 12 |    382 | GPU
DEBUG 01-15 10:09:36.051953.051953 lmp.py:1626]   Expert 25 |    398 | GPU
DEBUG 01-15 10:09:36.051404.051404 lmp.py:1626]   Expert 11 |    401 | GPU
DEBUG 01-15 10:09:36.051809.051809 lmp.py:1626]   Expert 30 |    833 | GPU
DEBUG 01-15 10:09:36.051167.051167 lmp.py:1627] 
DEBUG 01-15 10:09:36.051167.051167 lmp.py:1627]   CPU total tokens: 3248 (26.4%)
DEBUG 01-15 10:09:36.051002.051002 lmp.py:1628]   GPU total tokens: 9040 (73.6%)
DEBUG 01-15 10:09:36.051129.051129 cuda_h.py:19] end experts_map_get cost 0.0015468597412109375 seconds
DEBUG 01-15 10:09:36.051694.051694 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.051066.051066 lmp.py:1636] 
DEBUG 01-15 10:09:36.051066.051066 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.051392.051392 cuda_h.py:19] end cpu_experts_submit cost 6.175041198730469e-05 seconds
DEBUG 01-15 10:09:36.051479.051479 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.051681.051681 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.051516.051516 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.052256.052256 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:36.052369.052369 client.py:127] Model loaded
DEBUG 01-15 10:09:36.052400.052400 cuda_h.py:19] end allocate_cuda_memory cost 0.0002677440643310547 seconds
DEBUG 01-15 10:09:36.052416.052416 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.052800.052800 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.052444.052444 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.052605.052605 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.052581.052581 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.052045.052045 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 320c52c6-6cc0-48b4-b4e0-74b53607fa00
DEBUG 01-15 10:09:36.053450.053450 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.053731.053731 cuda_h.py:19] end move_flatidxs cost 0.0008449554443359375 seconds
DEBUG 01-15 10:09:36.053653.053653 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.053037.053037 cuda_h.py:19] end restore2model cost 0.0008409023284912109 seconds
DEBUG 01-15 10:09:36.053344.053344 cuda_h.py:19] end sllm_worker_task cost 0.010519027709960938 seconds
INFO 01-15 10:09:36.054910.054910 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 320c52c6-6cc0-48b4-b4e0-74b53607fa00
DEBUG 01-15 10:09:36.054767.054767 cuda_h.py:19] end load_into_gpu_async cost 0.0014529228210449219 seconds
DEBUG 01-15 10:09:36.054092.054092 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.055835.055835 cuda_h.py:19] end restore_tensors2 cost 0.0005841255187988281 seconds
DEBUG 01-15 10:09:36.055619.055619 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034682750701904297 seconds
DEBUG 01-15 10:09:36.055634.055634 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.057509.057509 cuda_h.py:19] end restore2model cost 0.0027573108673095703 seconds
DEBUG 01-15 10:09:36.057127.057127 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006453990936279297 seconds
DEBUG 01-15 10:09:36.058876.058876 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.058451.058451 cuda_h.py:19] end gpu_sexperts cost 0.0003228187561035156 seconds
DEBUG 01-15 10:09:36.058493.058493 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.060259.060259 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0018935203552246094 seconds
DEBUG 01-15 10:09:36.061837.061837 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.061183.061183 cuda_h.py:19] end gpu_group_list cost 0.0003933906555175781 seconds
DEBUG 01-15 10:09:36.062434.062434 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.062605.062605 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009140968322753906 seconds
DEBUG 01-15 10:09:36.063084.063084 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.063305.063305 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2649765014648438e-05 seconds
DEBUG 01-15 10:09:36.063723.063723 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.063810.063810 cuda_h.py:19] end group_tensors cost 0.009589433670043945 seconds
DEBUG 01-15 10:09:36.064028.064028 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.068928.068928 cuda_h.py:19] end group pad cost 0.00429081916809082 seconds
DEBUG 01-15 10:09:36.068149.068149 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.088091.088091 cuda_h.py:19] end group_einsum cost 0.01974773406982422 seconds
DEBUG 01-15 10:09:36.088150.088150 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.093657.093657 cuda_h.py:19] end get_outputs_cpu1 cost 0.004588127136230469 seconds
DEBUG 01-15 10:09:36.093749.093749 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04150652885437012 seconds
DEBUG 01-15 10:09:36.094749.094749 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03174448013305664 seconds
DEBUG 01-15 10:09:36.095180.095180 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.095898.095898 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.095537.095537 cuda_h.py:19] end index_scatter cost 0.00017213821411132812 seconds
DEBUG 01-15 10:09:36.096727.096727 cuda_h.py:19] end cpuoutputsdeal cost 0.001592397689819336 seconds
DEBUG 01-15 10:09:36.097320.097320 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.097019.097019 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 320c52c6-6cc0-48b4-b4e0-74b53607fa00
INFO 01-15 10:09:36.105781.105781 client.py:127] Model loaded
DEBUG 01-15 10:09:36.105455.105455 cuda_h.py:19] end wait_experts cost 0.008685827255249023 seconds
DEBUG 01-15 10:09:36.105411.105411 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.105734.105734 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.106173.106173 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.106897.106897 cuda_h.py:19] end gpu_group_tensor cost 0.00038552284240722656 seconds
DEBUG 01-15 10:09:36.106124.106124 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.108190.108190 cuda_h.py:19] end gpu_group_einsum cost 0.001268625259399414 seconds
DEBUG 01-15 10:09:36.108987.108987 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.108548.108548 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.109386.109386 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006048679351806641 seconds
DEBUG 01-15 10:09:36.109110.109110 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.109342.109342 cuda_h.py:19] end concat_expert_out cost 0.0001316070556640625 seconds
DEBUG 01-15 10:09:36.109923.109923 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.109109.109109 cuda_h.py:19] end index_scatter cost 0.00012159347534179688 seconds
DEBUG 01-15 10:09:36.109801.109801 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014424324035644531 seconds
DEBUG 01-15 10:09:36.110244.110244 cuda_h.py:19] end gpu_experts cost 0.0042302608489990234 seconds
DEBUG 01-15 10:09:36.110979.110979 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06134462356567383 seconds
DEBUG 01-15 10:09:36.111983.111983 cuda_h.py:19] end prefill_layer cost 0.06844067573547363 seconds
DEBUG 01-15 10:09:36.111326.111326 lmp.py:1552] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-15 10:09:36.111083.111083 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.111847.111847 lmp.py:1495] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-15 10:09:36.111227.111227 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:36.111375.111375 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:36.111863.111863 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.985664367675781e-05 seconds
DEBUG 01-15 10:09:36.111734.111734 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00016260147094726562 seconds
DEBUG 01-15 10:09:36.111007.111007 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.112276.112276 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.112215.112215 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.112636.112636 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.112042.112042 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.113870.113870 cuda_h.py:19] end allocate_cuda_memory cost 0.0003399848937988281 seconds
DEBUG 01-15 10:09:36.113323.113323 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.113477.113477 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.113261.113261 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.113931.113931 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 146d231a-9a99-4a79-91d0-136e3a361218
DEBUG 01-15 10:09:36.113856.113856 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.114709.114709 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.114602.114602 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 146d231a-9a99-4a79-91d0-136e3a361218
DEBUG 01-15 10:09:36.114545.114545 cuda_h.py:19] end load_into_gpu_async cost 0.0014531612396240234 seconds
DEBUG 01-15 10:09:36.114454.114454 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.114346.114346 cuda_h.py:19] end restore_tensors2 cost 0.00010180473327636719 seconds
DEBUG 01-15 10:09:36.115486.115486 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002229928970336914 seconds
INFO 01-15 10:09:36.115845.115845 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 146d231a-9a99-4a79-91d0-136e3a361218
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.119332.119332 cuda_h.py:19] end self_attn cost 0.0050089359283447266 seconds
DEBUG 01-15 10:09:36.119633.119633 cuda_h.py:19] end iln_self_attn_paln cost 0.007547855377197266 seconds
DEBUG 01-15 10:09:36.119093.119093 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-15 10:09:36.119883.119883 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.120181.120181 cuda_h.py:19] end gate cost 0.0009365081787109375 seconds
DEBUG 01-15 10:09:36.121528.121528 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.121524.121524 lmp.py:1616] 
DEBUG 01-15 10:09:36.121524.121524 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.121784.121784 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.121123.121123 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.121555.121555 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.121457.121457 lmp.py:1620] 
DEBUG 01-15 10:09:36.121457.121457 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.121120.121120 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.121453.121453 lmp.py:1626]   Expert 12 |     18 | CPU
DEBUG 01-15 10:09:36.121877.121877 lmp.py:1626]   Expert 47 |     23 | CPU
DEBUG 01-15 10:09:36.121633.121633 lmp.py:1626]   Expert 27 |     31 | CPU
DEBUG 01-15 10:09:36.121582.121582 lmp.py:1626]   Expert 38 |     31 | CPU
DEBUG 01-15 10:09:36.121338.121338 lmp.py:1626]   Expert 16 |     35 | CPU
DEBUG 01-15 10:09:36.121094.121094 lmp.py:1626]   Expert 52 |     40 | CPU
DEBUG 01-15 10:09:36.121995.121995 lmp.py:1626]   Expert 63 |     44 | CPU
DEBUG 01-15 10:09:36.121228.121228 lmp.py:1626]   Expert  4 |     59 | CPU
DEBUG 01-15 10:09:36.121891.121891 lmp.py:1626]   Expert 43 |     63 | CPU
DEBUG 01-15 10:09:36.122316.122316 lmp.py:1626]   Expert 44 |     63 | CPU
DEBUG 01-15 10:09:36.122834.122834 lmp.py:1626]   Expert 61 |     64 | CPU
DEBUG 01-15 10:09:36.122113.122113 lmp.py:1626]   Expert 34 |     77 | CPU
DEBUG 01-15 10:09:36.122108.122108 lmp.py:1626]   Expert 53 |     81 | CPU
DEBUG 01-15 10:09:36.122340.122340 lmp.py:1626]   Expert 32 |     87 | CPU
DEBUG 01-15 10:09:36.122858.122858 lmp.py:1626]   Expert  0 |     89 | CPU
DEBUG 01-15 10:09:36.122091.122091 lmp.py:1626]   Expert 37 |     92 | CPU
DEBUG 01-15 10:09:36.122277.122277 lmp.py:1626]   Expert 13 |    103 | CPU
DEBUG 01-15 10:09:36.122795.122795 lmp.py:1626]   Expert 39 |    113 | CPU
DEBUG 01-15 10:09:36.122074.122074 lmp.py:1626]   Expert 11 |    120 | CPU
DEBUG 01-15 10:09:36.122592.122592 lmp.py:1626]   Expert 21 |    120 | CPU
DEBUG 01-15 10:09:36.122632.122632 lmp.py:1626]   Expert 20 |    127 | CPU
DEBUG 01-15 10:09:36.122627.122627 lmp.py:1626]   Expert  8 |    131 | CPU
DEBUG 01-15 10:09:36.122098.122098 lmp.py:1626]   Expert 60 |    132 | CPU
DEBUG 01-15 10:09:36.122569.122569 lmp.py:1626]   Expert 14 |    136 | CPU
DEBUG 01-15 10:09:36.122325.122325 lmp.py:1626]   Expert 57 |    137 | CPU
DEBUG 01-15 10:09:36.122366.122366 lmp.py:1626]   Expert 22 |    142 | CPU
DEBUG 01-15 10:09:36.122645.122645 lmp.py:1626]   Expert 45 |    154 | CPU
DEBUG 01-15 10:09:36.122163.122163 lmp.py:1626]   Expert 18 |    156 | CPU
DEBUG 01-15 10:09:36.122680.122680 lmp.py:1626]   Expert  2 |    158 | CPU
DEBUG 01-15 10:09:36.122152.122152 lmp.py:1626]   Expert 17 |    159 | CPU
DEBUG 01-15 10:09:36.122861.122861 lmp.py:1626]   Expert 23 |    159 | CPU
DEBUG 01-15 10:09:36.122856.122856 lmp.py:1626]   Expert  7 |    162 | CPU
DEBUG 01-15 10:09:36.122373.122373 lmp.py:1626]   Expert 58 |    163 | GPU
DEBUG 01-15 10:09:36.122891.122891 lmp.py:1626]   Expert 30 |    166 | GPU
DEBUG 01-15 10:09:36.122693.122693 lmp.py:1626]   Expert 42 |    168 | GPU
DEBUG 01-15 10:09:36.122972.122972 lmp.py:1626]   Expert 62 |    180 | GPU
DEBUG 01-15 10:09:36.122251.122251 lmp.py:1626]   Expert 49 |    181 | GPU
DEBUG 01-15 10:09:36.122723.122723 lmp.py:1626]   Expert 55 |    181 | GPU
DEBUG 01-15 10:09:36.122432.122432 lmp.py:1626]   Expert 48 |    182 | GPU
DEBUG 01-15 10:09:36.122235.122235 lmp.py:1626]   Expert 35 |    183 | GPU
DEBUG 01-15 10:09:36.122991.122991 lmp.py:1626]   Expert 51 |    188 | GPU
DEBUG 01-15 10:09:36.122508.122508 lmp.py:1626]   Expert 29 |    190 | GPU
DEBUG 01-15 10:09:36.123787.123787 lmp.py:1626]   Expert 25 |    193 | GPU
DEBUG 01-15 10:09:36.123497.123497 lmp.py:1626]   Expert  6 |    194 | GPU
DEBUG 01-15 10:09:36.123492.123492 lmp.py:1626]   Expert 36 |    194 | GPU
DEBUG 01-15 10:09:36.123486.123486 lmp.py:1626]   Expert  1 |    199 | GPU
DEBUG 01-15 10:09:36.123050.123050 lmp.py:1626]   Expert 31 |    206 | GPU
DEBUG 01-15 10:09:36.123806.123806 lmp.py:1626]   Expert 28 |    221 | GPU
DEBUG 01-15 10:09:36.123323.123323 lmp.py:1626]   Expert 54 |    225 | GPU
DEBUG 01-15 10:09:36.123662.123662 lmp.py:1626]   Expert  5 |    230 | GPU
DEBUG 01-15 10:09:36.123657.123657 lmp.py:1626]   Expert 41 |    231 | GPU
INFO 01-15 10:09:36.123455.123455 client.py:127] Model loaded
DEBUG 01-15 10:09:36.123796.123796 lmp.py:1626]   Expert  9 |    239 | GPU
DEBUG 01-15 10:09:36.123826.123826 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.123907.123907 lmp.py:1626]   Expert 19 |    239 | GPU
DEBUG 01-15 10:09:36.124974.124974 lmp.py:1626]   Expert 24 |    255 | GPU
DEBUG 01-15 10:09:36.124081.124081 lmp.py:1626]   Expert 50 |    290 | GPU
DEBUG 01-15 10:09:36.124983.124983 lmp.py:1626]   Expert 46 |    304 | GPU
DEBUG 01-15 10:09:36.124931.124931 lmp.py:1626]   Expert 59 |    310 | GPU
DEBUG 01-15 10:09:36.124402.124402 lmp.py:1626]   Expert 56 |    374 | GPU
DEBUG 01-15 10:09:36.124681.124681 lmp.py:1626]   Expert 26 |    407 | GPU
DEBUG 01-15 10:09:36.124722.124722 lmp.py:1626]   Expert 33 |    421 | GPU
DEBUG 01-15 10:09:36.124001.124001 lmp.py:1626]   Expert  3 |    588 | GPU
DEBUG 01-15 10:09:36.124949.124949 lmp.py:1626]   Expert 10 |    640 | GPU
DEBUG 01-15 10:09:36.124421.124421 lmp.py:1626]   Expert 15 |    647 | GPU
DEBUG 01-15 10:09:36.124700.124700 lmp.py:1626]   Expert 40 |    793 | GPU
DEBUG 01-15 10:09:36.124708.124708 lmp.py:1627] 
DEBUG 01-15 10:09:36.124708.124708 lmp.py:1627]   CPU total tokens: 3106 (25.3%)
DEBUG 01-15 10:09:36.124325.124325 lmp.py:1628]   GPU total tokens: 9182 (74.7%)
DEBUG 01-15 10:09:36.124240.124240 cuda_h.py:19] end experts_map_get cost 0.00342559814453125 seconds
DEBUG 01-15 10:09:36.124948.124948 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.124175.124175 lmp.py:1636] 
DEBUG 01-15 10:09:36.124175.124175 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.124397.124397 cuda_h.py:19] end cpu_experts_submit cost 9.34600830078125e-05 seconds
DEBUG 01-15 10:09:36.124305.124305 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.124488.124488 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.125093.125093 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.125057.125057 cuda_h.py:19] end allocate_cuda_memory cost 0.0002636909484863281 seconds
DEBUG 01-15 10:09:36.125629.125629 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.125200.125200 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.125837.125837 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.125970.125970 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3b34d9c-56e8-4c0c-bd64-706683f19885
DEBUG 01-15 10:09:36.125773.125773 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.126178.126178 cuda_h.py:19] end restore2model cost 0.003045797348022461 seconds
DEBUG 01-15 10:09:36.126923.126923 cuda_h.py:19] end sllm_worker_task cost 0.014358043670654297 seconds
DEBUG 01-15 10:09:36.127559.127559 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:36.127950.127950 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3b34d9c-56e8-4c0c-bd64-706683f19885
DEBUG 01-15 10:09:36.127112.127112 cuda_h.py:19] end load_into_gpu_async cost 0.0017230510711669922 seconds
DEBUG 01-15 10:09:36.127476.127476 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.127060.127060 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.127172.127172 cuda_h.py:19] end restore_tensors2 cost 0.0005457401275634766 seconds
DEBUG 01-15 10:09:36.128691.128691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030612945556640625 seconds
DEBUG 01-15 10:09:36.128149.128149 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.128175.128175 cuda_h.py:19] end move_flatidxs cost 0.0010266304016113281 seconds
DEBUG 01-15 10:09:36.128092.128092 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.130289.130289 cuda_h.py:19] end restore2model cost 0.002737283706665039 seconds
DEBUG 01-15 10:09:36.130788.130788 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006077766418457031 seconds
DEBUG 01-15 10:09:36.130438.130438 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.131065.131065 cuda_h.py:19] end gpu_sexperts cost 0.0002925395965576172 seconds
DEBUG 01-15 10:09:36.131232.131232 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.132929.132929 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016031265258789062 seconds
DEBUG 01-15 10:09:36.133489.133489 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.134370.134370 cuda_h.py:19] end gpu_group_list cost 0.00032973289489746094 seconds
DEBUG 01-15 10:09:36.134772.134772 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.135289.135289 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007617473602294922 seconds
DEBUG 01-15 10:09:36.135032.135032 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.135061.135061 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0503997802734375e-05 seconds
DEBUG 01-15 10:09:36.135664.135664 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.143247.143247 cuda_h.py:19] end group_tensors cost 0.015047311782836914 seconds
DEBUG 01-15 10:09:36.144768.144768 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.148812.148812 cuda_h.py:19] end group pad cost 0.004225015640258789 seconds
DEBUG 01-15 10:09:36.148894.148894 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.169946.169946 cuda_h.py:19] end group_einsum cost 0.02045273780822754 seconds
DEBUG 01-15 10:09:36.169872.169872 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.173896.173896 cuda_h.py:19] end get_outputs_cpu1 cost 0.004017353057861328 seconds
DEBUG 01-15 10:09:36.174936.174936 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04734969139099121 seconds
DEBUG 01-15 10:09:36.175755.175755 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04001188278198242 seconds
DEBUG 01-15 10:09:36.175424.175424 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.176905.176905 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.176201.176201 cuda_h.py:19] end index_scatter cost 0.00023412704467773438 seconds
DEBUG 01-15 10:09:36.177535.177535 cuda_h.py:19] end cpuoutputsdeal cost 0.0016262531280517578 seconds
DEBUG 01-15 10:09:36.177884.177884 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.177536.177536 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3b34d9c-56e8-4c0c-bd64-706683f19885
INFO 01-15 10:09:36.178315.178315 client.py:127] Model loaded
DEBUG 01-15 10:09:36.179313.179313 cuda_h.py:19] end wait_experts cost 0.0014605522155761719 seconds
DEBUG 01-15 10:09:36.179838.179838 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.179161.179161 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.179216.179216 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.179357.179357 cuda_h.py:19] end gpu_group_tensor cost 0.0003788471221923828 seconds
DEBUG 01-15 10:09:36.180617.180617 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.181907.181907 cuda_h.py:19] end gpu_group_einsum cost 0.0010523796081542969 seconds
DEBUG 01-15 10:09:36.181346.181346 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.181423.181423 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.182657.182657 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005843639373779297 seconds
DEBUG 01-15 10:09:36.182428.182428 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.182899.182899 cuda_h.py:19] end concat_expert_out cost 0.00013065338134765625 seconds
DEBUG 01-15 10:09:36.182804.182804 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.182275.182275 cuda_h.py:19] end index_scatter cost 0.00012230873107910156 seconds
DEBUG 01-15 10:09:36.182966.182966 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001409292221069336 seconds
DEBUG 01-15 10:09:36.183436.183436 cuda_h.py:19] end gpu_experts cost 0.0039174556732177734 seconds
DEBUG 01-15 10:09:36.183217.183217 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06337547302246094 seconds
DEBUG 01-15 10:09:36.184995.184995 cuda_h.py:19] end prefill_layer cost 0.07263946533203125 seconds
DEBUG 01-15 10:09:36.184914.184914 lmp.py:1552] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-15 10:09:36.189202.189202 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.189498.189498 lmp.py:1495] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-15 10:09:36.189897.189897 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:36.190820.190820 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:36.190830.190830 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.842613220214844e-05 seconds
DEBUG 01-15 10:09:36.190692.190692 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00011897087097167969 seconds
DEBUG 01-15 10:09:36.190633.190633 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.190281.190281 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.190014.190014 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.190865.190865 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.191749.191749 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.191771.191771 cuda_h.py:19] end allocate_cuda_memory cost 0.00038433074951171875 seconds
DEBUG 01-15 10:09:36.191257.191257 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.191642.191642 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.191362.191362 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.191979.191979 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0a1ad64c-f7f0-4f27-a319-a8376f336ffe
DEBUG 01-15 10:09:36.191480.191480 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.192907.192907 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.192871.192871 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0a1ad64c-f7f0-4f27-a319-a8376f336ffe
DEBUG 01-15 10:09:36.193424.193424 cuda_h.py:19] end load_into_gpu_async cost 0.0013828277587890625 seconds
DEBUG 01-15 10:09:36.193087.193087 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.193449.193449 cuda_h.py:19] end restore_tensors2 cost 0.00010037422180175781 seconds
DEBUG 01-15 10:09:36.193112.193112 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002173185348510742 seconds
INFO 01-15 10:09:36.193665.193665 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0a1ad64c-f7f0-4f27-a319-a8376f336ffe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.197700.197700 cuda_h.py:19] end self_attn cost 0.004971981048583984 seconds
DEBUG 01-15 10:09:36.197672.197672 cuda_h.py:19] end iln_self_attn_paln cost 0.0076389312744140625 seconds
DEBUG 01-15 10:09:36.197457.197457 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-15 10:09:36.198603.198603 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.198418.198418 cuda_h.py:19] end gate cost 0.0007398128509521484 seconds
DEBUG 01-15 10:09:36.198228.198228 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.199518.199518 lmp.py:1616] 
DEBUG 01-15 10:09:36.199518.199518 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.199466.199466 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.199546.199546 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.199812.199812 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.199885.199885 lmp.py:1620] 
DEBUG 01-15 10:09:36.199885.199885 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.199919.199919 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.199331.199331 lmp.py:1626]   Expert 42 |     23 | CPU
DEBUG 01-15 10:09:36.199735.199735 lmp.py:1626]   Expert 19 |     24 | CPU
DEBUG 01-15 10:09:36.199663.199663 lmp.py:1626]   Expert 30 |     27 | CPU
DEBUG 01-15 10:09:36.199352.199352 lmp.py:1626]   Expert 32 |     46 | CPU
DEBUG 01-15 10:09:36.199803.199803 lmp.py:1626]   Expert  6 |     57 | CPU
DEBUG 01-15 10:09:36.199254.199254 lmp.py:1626]   Expert 53 |     72 | CPU
DEBUG 01-15 10:09:36.199420.199420 lmp.py:1626]   Expert  5 |     73 | CPU
DEBUG 01-15 10:09:36.199109.199109 lmp.py:1626]   Expert  1 |     79 | CPU
DEBUG 01-15 10:09:36.199037.199037 lmp.py:1626]   Expert 13 |    120 | CPU
DEBUG 01-15 10:09:36.199203.199203 lmp.py:1626]   Expert  9 |    125 | CPU
DEBUG 01-15 10:09:36.199707.199707 lmp.py:1626]   Expert 34 |    127 | CPU
DEBUG 01-15 10:09:36.199827.199827 lmp.py:1626]   Expert 63 |    127 | CPU
DEBUG 01-15 10:09:36.199755.199755 lmp.py:1626]   Expert 50 |    130 | CPU
DEBUG 01-15 10:09:36.199682.199682 lmp.py:1626]   Expert 58 |    131 | CPU
DEBUG 01-15 10:09:36.199372.199372 lmp.py:1626]   Expert 11 |    135 | CPU
DEBUG 01-15 10:09:36.199584.199584 lmp.py:1626]   Expert 26 |    136 | CPU
DEBUG 01-15 10:09:36.199274.199274 lmp.py:1626]   Expert 31 |    139 | CPU
DEBUG 01-15 10:09:36.199724.199724 lmp.py:1626]   Expert 18 |    140 | CPU
DEBUG 01-15 10:09:36.199414.199414 lmp.py:1626]   Expert 59 |    141 | CPU
DEBUG 01-15 10:09:36.199626.199626 lmp.py:1626]   Expert 40 |    145 | CPU
DEBUG 01-15 10:09:36.199792.199792 lmp.py:1626]   Expert 12 |    150 | CPU
DEBUG 01-15 10:09:36.199243.199243 lmp.py:1626]   Expert 46 |    150 | CPU
DEBUG 01-15 10:09:36.199933.199933 lmp.py:1626]   Expert  4 |    151 | CPU
DEBUG 01-15 10:09:36.199383.199383 lmp.py:1626]   Expert  2 |    153 | CPU
DEBUG 01-15 10:09:36.199026.199026 lmp.py:1626]   Expert 20 |    153 | CPU
DEBUG 01-15 10:09:36.199338.199338 lmp.py:1626]   Expert 48 |    153 | CPU
DEBUG 01-15 10:09:36.199220.199220 lmp.py:1626]   Expert 56 |    153 | CPU
DEBUG 01-15 10:09:36.199147.199147 lmp.py:1626]   Expert 33 |    155 | CPU
DEBUG 01-15 10:09:36.199075.199075 lmp.py:1626]   Expert 61 |    155 | CPU
DEBUG 01-15 10:09:36.199526.199526 lmp.py:1626]   Expert 35 |    165 | CPU
DEBUG 01-15 10:09:36.199215.199215 lmp.py:1626]   Expert 10 |    168 | CPU
DEBUG 01-15 10:09:36.199189.199189 lmp.py:1626]   Expert 55 |    172 | CPU
DEBUG 01-15 10:09:36.199978.199978 lmp.py:1626]   Expert 51 |    173 | GPU
DEBUG 01-15 10:09:36.199528.199528 lmp.py:1626]   Expert 36 |    179 | GPU
DEBUG 01-15 10:09:36.199363.199363 lmp.py:1626]   Expert  8 |    180 | GPU
DEBUG 01-15 10:09:36.199960.199960 lmp.py:1626]   Expert 52 |    182 | GPU
DEBUG 01-15 10:09:36.199272.199272 lmp.py:1626]   Expert 37 |    188 | GPU
DEBUG 01-15 10:09:36.200107.200107 lmp.py:1626]   Expert 57 |    205 | GPU
DEBUG 01-15 10:09:36.200134.200134 lmp.py:1626]   Expert  0 |    208 | GPU
DEBUG 01-15 10:09:36.200923.200923 lmp.py:1626]   Expert 39 |    222 | GPU
DEBUG 01-15 10:09:36.200189.200189 lmp.py:1626]   Expert 25 |    228 | GPU
DEBUG 01-15 10:09:36.200077.200077 lmp.py:1626]   Expert 62 |    234 | GPU
DEBUG 01-15 10:09:36.200912.200912 lmp.py:1626]   Expert 38 |    241 | GPU
DEBUG 01-15 10:09:36.200985.200985 lmp.py:1626]   Expert  7 |    246 | GPU
DEBUG 01-15 10:09:36.200820.200820 lmp.py:1626]   Expert  3 |    249 | GPU
DEBUG 01-15 10:09:36.200179.200179 lmp.py:1626]   Expert 24 |    250 | GPU
DEBUG 01-15 10:09:36.200775.200775 lmp.py:1626]   Expert 27 |    252 | GPU
DEBUG 01-15 10:09:36.200610.200610 lmp.py:1626]   Expert 28 |    255 | GPU
DEBUG 01-15 10:09:36.200969.200969 lmp.py:1626]   Expert 49 |    256 | GPU
DEBUG 01-15 10:09:36.200565.200565 lmp.py:1626]   Expert 60 |    258 | GPU
DEBUG 01-15 10:09:36.200116.200116 lmp.py:1626]   Expert 21 |    261 | GPU
DEBUG 01-15 10:09:36.200904.200904 lmp.py:1626]   Expert 16 |    266 | GPU
DEBUG 01-15 10:09:36.200455.200455 lmp.py:1626]   Expert 43 |    269 | GPU
DEBUG 01-15 10:09:36.200290.200290 lmp.py:1626]   Expert 23 |    273 | GPU
DEBUG 01-15 10:09:36.200409.200409 lmp.py:1626]   Expert 29 |    275 | GPU
DEBUG 01-15 10:09:36.200529.200529 lmp.py:1626]   Expert 15 |    290 | GPU
DEBUG 01-15 10:09:36.200364.200364 lmp.py:1626]   Expert 41 |    295 | GPU
DEBUG 01-15 10:09:36.200167.200167 lmp.py:1626]   Expert 47 |    295 | GPU
DEBUG 01-15 10:09:36.200955.200955 lmp.py:1626]   Expert 22 |    296 | GPU
DEBUG 01-15 10:09:36.200790.200790 lmp.py:1626]   Expert 44 |    305 | GPU
DEBUG 01-15 10:09:36.200341.200341 lmp.py:1626]   Expert 54 |    354 | GPU
DEBUG 01-15 10:09:36.200653.200653 lmp.py:1626]   Expert 14 |    375 | GPU
DEBUG 01-15 10:09:36.200680.200680 lmp.py:1626]   Expert 17 |    403 | GPU
DEBUG 01-15 10:09:36.200707.200707 lmp.py:1626]   Expert 45 |    450 | GPU
DEBUG 01-15 10:09:36.200734.200734 lmp.py:1627] 
DEBUG 01-15 10:09:36.200734.200734 lmp.py:1627]   CPU total tokens: 3875 (31.5%)
DEBUG 01-15 10:09:36.200000.200000 lmp.py:1628]   GPU total tokens: 8413 (68.5%)
DEBUG 01-15 10:09:36.200272.200272 cuda_h.py:19] end experts_map_get cost 0.0016870498657226562 seconds
INFO 01-15 10:09:36.200845.200845 client.py:127] Model loaded
DEBUG 01-15 10:09:36.200610.200610 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.200295.200295 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.200192.200192 lmp.py:1636] 
DEBUG 01-15 10:09:36.200192.200192 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.201971.201971 cuda_h.py:19] end cpu_experts_submit cost 0.00033164024353027344 seconds
DEBUG 01-15 10:09:36.201396.201396 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.201259.201259 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.201844.201844 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.201398.201398 cuda_h.py:19] end allocate_cuda_memory cost 0.0002982616424560547 seconds
DEBUG 01-15 10:09:36.202209.202209 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.202448.202448 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.202754.202754 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.202557.202557 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f2bdb9b7-fcb0-4ba6-9a0f-22f1ff3eb620
DEBUG 01-15 10:09:36.202744.202744 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.203813.203813 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.203355.203355 cuda_h.py:19] end restore2model cost 0.002794027328491211 seconds
DEBUG 01-15 10:09:36.203523.203523 cuda_h.py:19] end sllm_worker_task cost 0.013168573379516602 seconds
DEBUG 01-15 10:09:36.203345.203345 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:36.204561.204561 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f2bdb9b7-fcb0-4ba6-9a0f-22f1ff3eb620
DEBUG 01-15 10:09:36.204432.204432 cuda_h.py:19] end load_into_gpu_async cost 0.002093076705932617 seconds
DEBUG 01-15 10:09:36.204010.204010 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.204858.204858 cuda_h.py:19] end restore_tensors2 cost 0.0005915164947509766 seconds
DEBUG 01-15 10:09:36.204034.204034 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003528118133544922 seconds
DEBUG 01-15 10:09:36.204916.204916 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.205893.205893 cuda_h.py:19] end move_flatidxs cost 0.0010728836059570312 seconds
DEBUG 01-15 10:09:36.205451.205451 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.207845.207845 cuda_h.py:19] end restore2model cost 0.0029633045196533203 seconds
DEBUG 01-15 10:09:36.208391.208391 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0067462921142578125 seconds
DEBUG 01-15 10:09:36.208471.208471 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.208345.208345 cuda_h.py:19] end gpu_sexperts cost 0.0003490447998046875 seconds
DEBUG 01-15 10:09:36.208612.208612 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.210448.210448 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015990734100341797 seconds
DEBUG 01-15 10:09:36.211179.211179 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.211146.211146 cuda_h.py:19] end gpu_group_list cost 0.0003390312194824219 seconds
DEBUG 01-15 10:09:36.211547.211547 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.212567.212567 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007467269897460938 seconds
DEBUG 01-15 10:09:36.212794.212794 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.212054.212054 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-15 10:09:36.212465.212465 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.215711.215711 cuda_h.py:19] end group_tensors cost 0.010467529296875 seconds
DEBUG 01-15 10:09:36.216854.216854 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.221773.221773 cuda_h.py:19] end group pad cost 0.004450798034667969 seconds
DEBUG 01-15 10:09:36.221576.221576 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.241961.241961 cuda_h.py:19] end group_einsum cost 0.020099401473999023 seconds
DEBUG 01-15 10:09:36.241370.241370 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.246573.246573 cuda_h.py:19] end get_outputs_cpu1 cost 0.004782676696777344 seconds
DEBUG 01-15 10:09:36.247434.247434 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04336214065551758 seconds
DEBUG 01-15 10:09:36.248634.248634 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03599715232849121 seconds
DEBUG 01-15 10:09:36.248746.248746 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.249601.249601 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.249047.249047 cuda_h.py:19] end index_scatter cost 0.00015592575073242188 seconds
DEBUG 01-15 10:09:36.250053.250053 cuda_h.py:19] end cpuoutputsdeal cost 0.0011594295501708984 seconds
DEBUG 01-15 10:09:36.250135.250135 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.250429.250429 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f2bdb9b7-fcb0-4ba6-9a0f-22f1ff3eb620
INFO 01-15 10:09:36.254002.254002 client.py:127] Model loaded
DEBUG 01-15 10:09:36.254251.254251 cuda_h.py:19] end wait_experts cost 0.004757404327392578 seconds
DEBUG 01-15 10:09:36.254332.254332 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.255925.255925 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.255822.255822 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.255252.255252 cuda_h.py:19] end gpu_group_tensor cost 0.00032401084899902344 seconds
DEBUG 01-15 10:09:36.255855.255855 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.256014.256014 cuda_h.py:19] end gpu_group_einsum cost 0.0009052753448486328 seconds
DEBUG 01-15 10:09:36.256637.256637 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.257706.257706 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.257827.257827 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003883838653564453 seconds
DEBUG 01-15 10:09:36.257133.257133 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.257899.257899 cuda_h.py:19] end concat_expert_out cost 8.702278137207031e-05 seconds
DEBUG 01-15 10:09:36.257936.257936 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.257218.257218 cuda_h.py:19] end index_scatter cost 8.106231689453125e-05 seconds
DEBUG 01-15 10:09:36.257254.257254 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009500980377197266 seconds
DEBUG 01-15 10:09:36.258708.258708 cuda_h.py:19] end gpu_experts cost 0.003065824508666992 seconds
DEBUG 01-15 10:09:36.258692.258692 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.060212135314941406 seconds
DEBUG 01-15 10:09:36.258801.258801 cuda_h.py:19] end prefill_layer cost 0.0690009593963623 seconds
DEBUG 01-15 10:09:36.259977.259977 lmp.py:1552] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-15 10:09:36.259084.259084 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.259622.259622 lmp.py:1495] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-15 10:09:36.259398.259398 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:36.259751.259751 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:36.259509.259509 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:36.259769.259769 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.00011229515075683594 seconds
DEBUG 01-15 10:09:36.259870.259870 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.259033.259033 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.259833.259833 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.259114.259114 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.260067.260067 cuda_h.py:19] end allocate_cuda_memory cost 0.00033974647521972656 seconds
DEBUG 01-15 10:09:36.260944.260944 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.260614.260614 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.260974.260974 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.260776.260776 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e432ab20-4118-42c8-83ea-2a621b116935
DEBUG 01-15 10:09:36.260078.260078 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.260555.260555 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.261561.261561 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.261722.261722 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e432ab20-4118-42c8-83ea-2a621b116935
DEBUG 01-15 10:09:36.261374.261374 cuda_h.py:19] end load_into_gpu_async cost 0.0013301372528076172 seconds
DEBUG 01-15 10:09:36.261322.261322 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.261161.261161 cuda_h.py:19] end restore_tensors2 cost 9.679794311523438e-05 seconds
DEBUG 01-15 10:09:36.261301.261301 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020668506622314453 seconds
INFO 01-15 10:09:36.261919.261919 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e432ab20-4118-42c8-83ea-2a621b116935
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.266453.266453 cuda_h.py:19] end self_attn cost 0.005357027053833008 seconds
DEBUG 01-15 10:09:36.267441.267441 cuda_h.py:19] end iln_self_attn_paln cost 0.00770878791809082 seconds
DEBUG 01-15 10:09:36.267821.267821 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-15 10:09:36.267822.267822 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.267356.267356 cuda_h.py:19] end gate cost 0.0006723403930664062 seconds
DEBUG 01-15 10:09:36.268821.268821 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.268607.268607 lmp.py:1616] 
DEBUG 01-15 10:09:36.268607.268607 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.268523.268523 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.268888.268888 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.268723.268723 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.268889.268889 lmp.py:1620] 
DEBUG 01-15 10:09:36.268889.268889 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.268009.268009 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.268559.268559 lmp.py:1626]   Expert 34 |     28 | CPU
DEBUG 01-15 10:09:36.268202.268202 lmp.py:1626]   Expert  7 |     31 | CPU
DEBUG 01-15 10:09:36.268891.268891 lmp.py:1626]   Expert 13 |     42 | CPU
DEBUG 01-15 10:09:36.268058.268058 lmp.py:1626]   Expert 54 |     76 | CPU
DEBUG 01-15 10:09:36.268985.268985 lmp.py:1626]   Expert 18 |     84 | CPU
DEBUG 01-15 10:09:36.268436.268436 lmp.py:1626]   Expert 39 |     86 | CPU
DEBUG 01-15 10:09:36.268410.268410 lmp.py:1626]   Expert 49 |     89 | CPU
DEBUG 01-15 10:09:36.268861.268861 lmp.py:1626]   Expert 59 |    104 | CPU
DEBUG 01-15 10:09:36.268550.268550 lmp.py:1626]   Expert  0 |    106 | CPU
DEBUG 01-15 10:09:36.268524.268524 lmp.py:1626]   Expert 21 |    108 | CPU
DEBUG 01-15 10:09:36.268737.268737 lmp.py:1626]   Expert 16 |    110 | CPU
DEBUG 01-15 10:09:36.268949.268949 lmp.py:1626]   Expert 15 |    117 | CPU
DEBUG 01-15 10:09:36.268923.268923 lmp.py:1626]   Expert 41 |    117 | CPU
DEBUG 01-15 10:09:36.268136.268136 lmp.py:1626]   Expert 22 |    121 | CPU
DEBUG 01-15 10:09:36.268825.268825 lmp.py:1626]   Expert 45 |    122 | CPU
DEBUG 01-15 10:09:36.268276.268276 lmp.py:1626]   Expert 17 |    127 | CPU
DEBUG 01-15 10:09:36.268157.268157 lmp.py:1626]   Expert 52 |    134 | CPU
DEBUG 01-15 10:09:36.268370.268370 lmp.py:1626]   Expert  8 |    135 | CPU
DEBUG 01-15 10:09:36.268821.268821 lmp.py:1626]   Expert 61 |    135 | CPU
DEBUG 01-15 10:09:36.268033.268033 lmp.py:1626]   Expert 35 |    137 | CPU
DEBUG 01-15 10:09:36.268007.268007 lmp.py:1626]   Expert 38 |    142 | CPU
DEBUG 01-15 10:09:36.268697.268697 lmp.py:1626]   Expert 12 |    143 | CPU
DEBUG 01-15 10:09:36.268671.268671 lmp.py:1626]   Expert 31 |    148 | CPU
DEBUG 01-15 10:09:36.268406.268406 lmp.py:1626]   Expert 48 |    149 | CPU
DEBUG 01-15 10:09:36.268380.268380 lmp.py:1626]   Expert 53 |    154 | CPU
DEBUG 01-15 10:09:36.268831.268831 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:36.268805.268805 lmp.py:1626]   Expert 60 |    159 | CPU
DEBUG 01-15 10:09:36.268018.268018 lmp.py:1626]   Expert 40 |    160 | CPU
DEBUG 01-15 10:09:36.268469.268469 lmp.py:1626]   Expert 50 |    163 | CPU
DEBUG 01-15 10:09:36.268204.268204 lmp.py:1626]   Expert 27 |    175 | CPU
DEBUG 01-15 10:09:36.268417.268417 lmp.py:1626]   Expert 19 |    195 | CPU
DEBUG 01-15 10:09:36.269629.269629 lmp.py:1626]   Expert  4 |    200 | CPU
DEBUG 01-15 10:09:36.269603.269603 lmp.py:1626]   Expert 29 |    200 | GPU
DEBUG 01-15 10:09:36.269816.269816 lmp.py:1626]   Expert 30 |    203 | GPU
DEBUG 01-15 10:09:36.269267.269267 lmp.py:1626]   Expert 11 |    216 | GPU
DEBUG 01-15 10:09:36.269671.269671 lmp.py:1626]   Expert 20 |    220 | GPU
DEBUG 01-15 10:09:36.269314.269314 lmp.py:1626]   Expert 26 |    220 | GPU
DEBUG 01-15 10:09:36.269719.269719 lmp.py:1626]   Expert 57 |    224 | GPU
DEBUG 01-15 10:09:36.269170.269170 lmp.py:1626]   Expert  6 |    226 | GPU
DEBUG 01-15 10:09:36.269382.269382 lmp.py:1626]   Expert 43 |    226 | GPU
DEBUG 01-15 10:09:36.269356.269356 lmp.py:1626]   Expert 46 |    228 | GPU
DEBUG 01-15 10:09:36.269569.269569 lmp.py:1626]   Expert 23 |    239 | GPU
DEBUG 01-15 10:09:36.269019.269019 lmp.py:1626]   Expert 33 |    240 | GPU
DEBUG 01-15 10:09:36.269470.269470 lmp.py:1626]   Expert 42 |    244 | GPU
DEBUG 01-15 10:09:36.269921.269921 lmp.py:1626]   Expert  2 |    246 | GPU
DEBUG 01-15 10:09:36.269134.269134 lmp.py:1626]   Expert 55 |    251 | GPU
DEBUG 01-15 10:09:36.269585.269585 lmp.py:1626]   Expert 56 |    256 | GPU
DEBUG 01-15 10:09:36.269035.269035 lmp.py:1626]   Expert 32 |    258 | GPU
DEBUG 01-15 10:09:36.269301.269301 lmp.py:1626]   Expert  3 |    260 | GPU
DEBUG 01-15 10:09:36.269090.269090 lmp.py:1626]   Expert  9 |    261 | GPU
DEBUG 01-15 10:09:36.269594.269594 lmp.py:1626]   Expert 28 |    264 | GPU
DEBUG 01-15 10:09:36.269667.269667 lmp.py:1626]   Expert 14 |    267 | GPU
DEBUG 01-15 10:09:36.269787.269787 lmp.py:1626]   Expert  1 |    276 | GPU
DEBUG 01-15 10:09:36.269860.269860 lmp.py:1626]   Expert 44 |    277 | GPU
DEBUG 01-15 10:09:36.269696.269696 lmp.py:1626]   Expert 51 |    277 | GPU
DEBUG 01-15 10:09:36.269054.269054 lmp.py:1626]   Expert 58 |    282 | GPU
DEBUG 01-15 10:09:36.269650.269650 lmp.py:1626]   Expert 37 |    286 | GPU
DEBUG 01-15 10:09:36.269486.269486 lmp.py:1626]   Expert 63 |    288 | GPU
DEBUG 01-15 10:09:36.269844.269844 lmp.py:1626]   Expert 47 |    292 | GPU
DEBUG 01-15 10:09:36.269964.269964 lmp.py:1626]   Expert 24 |    302 | GPU
DEBUG 01-15 10:09:36.269799.269799 lmp.py:1626]   Expert 10 |    313 | GPU
DEBUG 01-15 10:09:36.269349.269349 lmp.py:1626]   Expert 62 |    314 | GPU
DEBUG 01-15 10:09:36.269138.269138 lmp.py:1626]   Expert 25 |    316 | GPU
DEBUG 01-15 10:09:36.269688.269688 lmp.py:1626]   Expert  5 |    364 | GPU
DEBUG 01-15 10:09:36.269000.269000 lmp.py:1627] 
DEBUG 01-15 10:09:36.269000.269000 lmp.py:1627]   CPU total tokens: 3952 (32.2%)
DEBUG 01-15 10:09:36.269789.269789 lmp.py:1628]   GPU total tokens: 8336 (67.8%)
DEBUG 01-15 10:09:36.269631.269631 cuda_h.py:19] end experts_map_get cost 0.001585245132446289 seconds
INFO 01-15 10:09:36.269554.269554 client.py:127] Model loaded
DEBUG 01-15 10:09:36.269477.269477 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.269300.269300 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.270088.270088 lmp.py:1636] 
DEBUG 01-15 10:09:36.270088.270088 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.270773.270773 cuda_h.py:19] end cpu_experts_submit cost 8.654594421386719e-05 seconds
DEBUG 01-15 10:09:36.270807.270807 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.270333.270333 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.270115.270115 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.270085.270085 cuda_h.py:19] end allocate_cuda_memory cost 0.0002560615539550781 seconds
DEBUG 01-15 10:09:36.271757.271757 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.271420.271420 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.271627.271627 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.271668.271668 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b8f69d03-5ea3-45cf-bff2-a2c3e27f19d4
DEBUG 01-15 10:09:36.271947.271947 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.272073.272073 cuda_h.py:19] end restore2model cost 0.0022606849670410156 seconds
DEBUG 01-15 10:09:36.272064.272064 cuda_h.py:19] end sllm_worker_task cost 0.012650728225708008 seconds
DEBUG 01-15 10:09:36.272042.272042 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:36.272537.272537 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b8f69d03-5ea3-45cf-bff2-a2c3e27f19d4
DEBUG 01-15 10:09:36.272981.272981 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.272076.272076 cuda_h.py:19] end load_into_gpu_async cost 0.0017786026000976562 seconds
DEBUG 01-15 10:09:36.272547.272547 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.273558.273558 cuda_h.py:19] end restore_tensors2 cost 0.000507354736328125 seconds
DEBUG 01-15 10:09:36.273700.273700 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030167102813720703 seconds
DEBUG 01-15 10:09:36.273960.273960 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.273743.273743 cuda_h.py:19] end move_flatidxs cost 0.0009436607360839844 seconds
DEBUG 01-15 10:09:36.273394.273394 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.276736.276736 cuda_h.py:19] end restore2model cost 0.0027840137481689453 seconds
DEBUG 01-15 10:09:36.276375.276375 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006045341491699219 seconds
DEBUG 01-15 10:09:36.276601.276601 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.276128.276128 cuda_h.py:19] end gpu_sexperts cost 0.000286102294921875 seconds
DEBUG 01-15 10:09:36.276249.276249 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.278183.278183 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001566171646118164 seconds
DEBUG 01-15 10:09:36.279688.279688 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.279767.279767 cuda_h.py:19] end gpu_group_list cost 0.00031876564025878906 seconds
DEBUG 01-15 10:09:36.279691.279691 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.280196.280196 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007829666137695312 seconds
DEBUG 01-15 10:09:36.280787.280787 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.280901.280901 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-15 10:09:36.280312.280312 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.280268.280268 cuda_h.py:19] end group_tensors cost 0.0062863826751708984 seconds
DEBUG 01-15 10:09:36.280183.280183 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.285131.285131 cuda_h.py:19] end group pad cost 0.0045013427734375 seconds
DEBUG 01-15 10:09:36.285027.285027 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.306025.306025 cuda_h.py:19] end group_einsum cost 0.021226882934570312 seconds
DEBUG 01-15 10:09:36.307335.307335 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.312826.312826 cuda_h.py:19] end get_outputs_cpu1 cost 0.004881620407104492 seconds
DEBUG 01-15 10:09:36.312873.312873 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04035472869873047 seconds
DEBUG 01-15 10:09:36.313451.313451 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03293204307556152 seconds
DEBUG 01-15 10:09:36.313291.313291 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.314382.314382 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.314859.314859 cuda_h.py:19] end index_scatter cost 0.00012564659118652344 seconds
DEBUG 01-15 10:09:36.315869.315869 cuda_h.py:19] end cpuoutputsdeal cost 0.0012063980102539062 seconds
DEBUG 01-15 10:09:36.315117.315117 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.315788.315788 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b8f69d03-5ea3-45cf-bff2-a2c3e27f19d4
INFO 01-15 10:09:36.324476.324476 client.py:127] Model loaded
DEBUG 01-15 10:09:36.324361.324361 cuda_h.py:19] end wait_experts cost 0.00959324836730957 seconds
DEBUG 01-15 10:09:36.324780.324780 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.325798.325798 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.325932.325932 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.325556.325556 cuda_h.py:19] end gpu_group_tensor cost 0.0003554821014404297 seconds
DEBUG 01-15 10:09:36.325510.325510 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.326370.326370 cuda_h.py:19] end gpu_group_einsum cost 0.0010654926300048828 seconds
DEBUG 01-15 10:09:36.327145.327145 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.327003.327003 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.327236.327236 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005567073822021484 seconds
DEBUG 01-15 10:09:36.327160.327160 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.328200.328200 cuda_h.py:19] end concat_expert_out cost 0.00012969970703125 seconds
DEBUG 01-15 10:09:36.328973.328973 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.328901.328901 cuda_h.py:19] end index_scatter cost 0.00014138221740722656 seconds
DEBUG 01-15 10:09:36.328361.328361 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001405954360961914 seconds
DEBUG 01-15 10:09:36.328321.328321 cuda_h.py:19] end gpu_experts cost 0.003812551498413086 seconds
DEBUG 01-15 10:09:36.329340.329340 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.061750173568725586 seconds
DEBUG 01-15 10:09:36.329628.329628 cuda_h.py:19] end prefill_layer cost 0.07077598571777344 seconds
DEBUG 01-15 10:09:36.330719.330719 lmp.py:1552] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-15 10:09:36.330622.330622 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.330286.330286 lmp.py:1495] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-15 10:09:36.330573.330573 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:36.330391.330391 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:36.330925.330925 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.05718994140625e-05 seconds
DEBUG 01-15 10:09:36.330219.330219 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.00015807151794433594 seconds
DEBUG 01-15 10:09:36.330115.330115 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.330378.330378 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.330220.330220 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.331037.331037 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.331017.331017 cuda_h.py:19] end allocate_cuda_memory cost 0.0003261566162109375 seconds
DEBUG 01-15 10:09:36.331926.331926 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.331928.331928 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.331472.331472 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.331513.331513 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41c3ca73-353a-4217-817f-abbdd15d3d4f
DEBUG 01-15 10:09:36.331795.331795 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.331822.331822 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:36.332492.332492 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41c3ca73-353a-4217-817f-abbdd15d3d4f
DEBUG 01-15 10:09:36.332754.332754 cuda_h.py:19] end load_into_gpu_async cost 0.001135110855102539 seconds
DEBUG 01-15 10:09:36.332463.332463 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.332918.332918 cuda_h.py:19] end restore_tensors2 cost 9.560585021972656e-05 seconds
DEBUG 01-15 10:09:36.332581.332581 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018377304077148438 seconds
INFO 01-15 10:09:36.332961.332961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41c3ca73-353a-4217-817f-abbdd15d3d4f
DEBUG 01-15 10:09:36.333084.333084 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.339971.339971 cuda_h.py:19] end self_attn cost 0.005983829498291016 seconds
INFO 01-15 10:09:36.339645.339645 client.py:127] Model loaded
DEBUG 01-15 10:09:36.339900.339900 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.340522.340522 cuda_h.py:19] end iln_self_attn_paln cost 0.009527444839477539 seconds
DEBUG 01-15 10:09:36.340060.340060 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-15 10:09:36.340764.340764 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.340165.340165 cuda_h.py:19] end restore2model cost 0.000949859619140625 seconds
DEBUG 01-15 10:09:36.340659.340659 cuda_h.py:19] end sllm_worker_task cost 0.009967803955078125 seconds
DEBUG 01-15 10:09:36.341930.341930 cuda_h.py:19] end gate cost 0.0009398460388183594 seconds
DEBUG 01-15 10:09:36.341343.341343 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.342359.342359 lmp.py:1616] 
DEBUG 01-15 10:09:36.342359.342359 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.342612.342612 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.342766.342766 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.342522.342522 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.342417.342417 lmp.py:1620] 
DEBUG 01-15 10:09:36.342417.342417 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.342312.342312 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.342399.342399 lmp.py:1626]   Expert 15 |     66 | CPU
DEBUG 01-15 10:09:36.342056.342056 lmp.py:1626]   Expert 41 |     69 | CPU
DEBUG 01-15 10:09:36.342997.342997 lmp.py:1626]   Expert  0 |     76 | CPU
DEBUG 01-15 10:09:36.342223.342223 lmp.py:1626]   Expert 63 |     76 | CPU
DEBUG 01-15 10:09:36.342449.342449 lmp.py:1626]   Expert 20 |     83 | CPU
DEBUG 01-15 10:09:36.342198.342198 lmp.py:1626]   Expert 45 |     87 | CPU
DEBUG 01-15 10:09:36.342186.342186 lmp.py:1626]   Expert  7 |     91 | CPU
DEBUG 01-15 10:09:36.342419.342419 lmp.py:1626]   Expert 28 |    100 | CPU
DEBUG 01-15 10:09:36.342360.342360 lmp.py:1626]   Expert 54 |    105 | CPU
DEBUG 01-15 10:09:36.342586.342586 lmp.py:1626]   Expert 12 |    110 | CPU
DEBUG 01-15 10:09:36.342574.342574 lmp.py:1626]   Expert 52 |    116 | CPU
DEBUG 01-15 10:09:36.342323.342323 lmp.py:1626]   Expert 40 |    118 | CPU
DEBUG 01-15 10:09:36.342834.342834 lmp.py:1626]   Expert 59 |    124 | CPU
DEBUG 01-15 10:09:36.342344.342344 lmp.py:1626]   Expert  5 |    127 | CPU
DEBUG 01-15 10:09:36.342094.342094 lmp.py:1626]   Expert  4 |    130 | CPU
DEBUG 01-15 10:09:36.342320.342320 lmp.py:1626]   Expert 34 |    132 | CPU
DEBUG 01-15 10:09:36.342784.342784 lmp.py:1626]   Expert 13 |    137 | CPU
DEBUG 01-15 10:09:36.342487.342487 lmp.py:1626]   Expert 62 |    137 | CPU
DEBUG 01-15 10:09:36.342475.342475 lmp.py:1626]   Expert 55 |    138 | CPU
DEBUG 01-15 10:09:36.342224.342224 lmp.py:1626]   Expert 61 |    138 | CPU
DEBUG 01-15 10:09:36.342973.342973 lmp.py:1626]   Expert 42 |    141 | CPU
DEBUG 01-15 10:09:36.342199.342199 lmp.py:1626]   Expert 21 |    142 | CPU
DEBUG 01-15 10:09:36.343379.343379 lmp.py:1626]   Expert 14 |    146 | CPU
DEBUG 01-15 10:09:36.343128.343128 lmp.py:1626]   Expert 10 |    148 | CPU
DEBUG 01-15 10:09:36.343639.343639 lmp.py:1626]   Expert 22 |    149 | CPU
DEBUG 01-15 10:09:36.343911.343911 lmp.py:1626]   Expert 51 |    154 | CPU
DEBUG 01-15 10:09:36.343660.343660 lmp.py:1626]   Expert 32 |    158 | CPU
DEBUG 01-15 10:09:36.343410.343410 lmp.py:1626]   Expert 25 |    169 | CPU
DEBUG 01-15 10:09:36.343351.343351 lmp.py:1626]   Expert  1 |    173 | CPU
DEBUG 01-15 10:09:36.343100.343100 lmp.py:1626]   Expert 47 |    176 | CPU
DEBUG 01-15 10:09:36.343372.343372 lmp.py:1626]   Expert 19 |    177 | CPU
DEBUG 01-15 10:09:36.343406.343406 lmp.py:1626]   Expert 50 |    177 | CPU
DEBUG 01-15 10:09:36.343156.343156 lmp.py:1626]   Expert 53 |    177 | GPU
DEBUG 01-15 10:09:36.343666.343666 lmp.py:1626]   Expert 26 |    178 | GPU
DEBUG 01-15 10:09:36.343177.343177 lmp.py:1626]   Expert  2 |    181 | GPU
DEBUG 01-15 10:09:36.343118.343118 lmp.py:1626]   Expert 35 |    183 | GPU
DEBUG 01-15 10:09:36.343868.343868 lmp.py:1626]   Expert  6 |    184 | GPU
DEBUG 01-15 10:09:36.343378.343378 lmp.py:1626]   Expert 11 |    184 | GPU
DEBUG 01-15 10:09:36.343174.343174 lmp.py:1626]   Expert 30 |    184 | GPU
DEBUG 01-15 10:09:36.343208.343208 lmp.py:1626]   Expert 56 |    192 | GPU
DEBUG 01-15 10:09:36.343480.343480 lmp.py:1626]   Expert 57 |    192 | GPU
DEBUG 01-15 10:09:36.343706.343706 lmp.py:1626]   Expert 48 |    204 | GPU
DEBUG 01-15 10:09:36.343740.343740 lmp.py:1626]   Expert 24 |    207 | GPU
DEBUG 01-15 10:09:36.343013.343013 lmp.py:1626]   Expert 16 |    211 | GPU
DEBUG 01-15 10:09:36.343047.343047 lmp.py:1626]   Expert 44 |    213 | GPU
DEBUG 01-15 10:09:36.343319.343319 lmp.py:1626]   Expert 46 |    217 | GPU
DEBUG 01-15 10:09:36.343353.343353 lmp.py:1626]   Expert 18 |    223 | GPU
DEBUG 01-15 10:09:36.343387.343387 lmp.py:1626]   Expert 39 |    229 | GPU
DEBUG 01-15 10:09:36.343951.343951 lmp.py:1626]   Expert 29 |    233 | GPU
DEBUG 01-15 10:09:36.343223.343223 lmp.py:1626]   Expert 37 |    243 | GPU
DEBUG 01-15 10:09:36.343496.343496 lmp.py:1626]   Expert  3 |    254 | GPU
DEBUG 01-15 10:09:36.343291.343291 lmp.py:1626]   Expert 31 |    254 | GPU
DEBUG 01-15 10:09:36.343325.343325 lmp.py:1626]   Expert 36 |    256 | GPU
DEBUG 01-15 10:09:36.343359.343359 lmp.py:1626]   Expert 60 |    258 | GPU
DEBUG 01-15 10:09:36.343393.343393 lmp.py:1626]   Expert 38 |    263 | GPU
DEBUG 01-15 10:09:36.343857.343857 lmp.py:1626]   Expert  9 |    264 | GPU
DEBUG 01-15 10:09:36.343130.343130 lmp.py:1626]   Expert 17 |    265 | GPU
DEBUG 01-15 10:09:36.343641.343641 lmp.py:1626]   Expert 23 |    276 | GPU
DEBUG 01-15 10:09:36.343674.343674 lmp.py:1626]   Expert 27 |    346 | GPU
DEBUG 01-15 10:09:36.343470.343470 lmp.py:1626]   Expert 43 |    365 | GPU
DEBUG 01-15 10:09:36.343742.343742 lmp.py:1626]   Expert  8 |    398 | GPU
DEBUG 01-15 10:09:36.344253.344253 lmp.py:1626]   Expert 33 |    399 | GPU
DEBUG 01-15 10:09:36.344764.344764 lmp.py:1626]   Expert 58 |    446 | GPU
DEBUG 01-15 10:09:36.344275.344275 lmp.py:1626]   Expert 49 |    539 | GPU
DEBUG 01-15 10:09:36.344216.344216 lmp.py:1627] 
DEBUG 01-15 10:09:36.344216.344216 lmp.py:1627]   CPU total tokens: 4070 (33.1%)
DEBUG 01-15 10:09:36.344873.344873 lmp.py:1628]   GPU total tokens: 8218 (66.9%)
DEBUG 01-15 10:09:36.344298.344298 cuda_h.py:19] end experts_map_get cost 0.002347707748413086 seconds
DEBUG 01-15 10:09:36.344512.344512 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.344620.344620 lmp.py:1636] 
DEBUG 01-15 10:09:36.344620.344620 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.344351.344351 cuda_h.py:19] end cpu_experts_submit cost 8.177757263183594e-05 seconds
DEBUG 01-15 10:09:36.344220.344220 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.344203.344203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.344755.344755 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.345106.345106 cuda_h.py:19] end allocate_cuda_memory cost 0.00034546852111816406 seconds
DEBUG 01-15 10:09:36.345527.345527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.345953.345953 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.345326.345326 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.345811.345811 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f683a19a-c0f4-46db-81a0-f8d1bd70250d
DEBUG 01-15 10:09:36.346460.346460 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.346684.346684 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.346931.346931 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.347428.347428 cuda_h.py:19] end move_flatidxs cost 0.0009226799011230469 seconds
DEBUG 01-15 10:09:36.347848.347848 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:36.348100.348100 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f683a19a-c0f4-46db-81a0-f8d1bd70250d
DEBUG 01-15 10:09:36.348785.348785 cuda_h.py:19] end load_into_gpu_async cost 0.0025098323822021484 seconds
DEBUG 01-15 10:09:36.348647.348647 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.348759.348759 cuda_h.py:19] end restore_tensors2 cost 0.0005354881286621094 seconds
DEBUG 01-15 10:09:36.348570.348570 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004378080368041992 seconds
DEBUG 01-15 10:09:36.348783.348783 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.351206.351206 cuda_h.py:19] end restore2model cost 0.0027027130126953125 seconds
DEBUG 01-15 10:09:36.351394.351394 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007327079772949219 seconds
DEBUG 01-15 10:09:36.351043.351043 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.352710.352710 cuda_h.py:19] end gpu_sexperts cost 0.00028514862060546875 seconds
DEBUG 01-15 10:09:36.352400.352400 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.353202.353202 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015747547149658203 seconds
DEBUG 01-15 10:09:36.353227.353227 cuda_h.py:19] end group_tensors cost 0.006343841552734375 seconds
DEBUG 01-15 10:09:36.354459.354459 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.354296.354296 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.355570.355570 cuda_h.py:19] end gpu_group_list cost 0.0004296302795410156 seconds
DEBUG 01-15 10:09:36.355978.355978 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.356337.356337 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007848739624023438 seconds
DEBUG 01-15 10:09:36.356796.356796 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.356341.356341 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0742416381835938e-05 seconds
DEBUG 01-15 10:09:36.356613.356613 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.358388.358388 cuda_h.py:19] end group pad cost 0.00414276123046875 seconds
DEBUG 01-15 10:09:36.358377.358377 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.377575.377575 cuda_h.py:19] end group_einsum cost 0.019093990325927734 seconds
DEBUG 01-15 10:09:36.378839.378839 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.383062.383062 cuda_h.py:19] end get_outputs_cpu1 cost 0.004992008209228516 seconds
DEBUG 01-15 10:09:36.383843.383843 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03785848617553711 seconds
DEBUG 01-15 10:09:36.384278.384278 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.028684616088867188 seconds
DEBUG 01-15 10:09:36.385303.385303 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.385964.385964 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.385374.385374 cuda_h.py:19] end index_scatter cost 0.00012373924255371094 seconds
DEBUG 01-15 10:09:36.386867.386867 cuda_h.py:19] end cpuoutputsdeal cost 0.0011603832244873047 seconds
DEBUG 01-15 10:09:36.386360.386360 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.386773.386773 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f683a19a-c0f4-46db-81a0-f8d1bd70250d
INFO 01-15 10:09:36.400378.400378 client.py:127] Model loaded
DEBUG 01-15 10:09:36.400859.400859 cuda_h.py:19] end wait_experts cost 0.013860940933227539 seconds
DEBUG 01-15 10:09:36.400630.400630 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.400311.400311 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.400989.400989 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.401660.401660 cuda_h.py:19] end gpu_group_tensor cost 0.0003807544708251953 seconds
DEBUG 01-15 10:09:36.401164.401164 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.402873.402873 cuda_h.py:19] end gpu_group_einsum cost 0.0012879371643066406 seconds
DEBUG 01-15 10:09:36.402081.402081 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.403118.403118 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.403021.403021 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005815029144287109 seconds
DEBUG 01-15 10:09:36.403845.403845 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.404508.404508 cuda_h.py:19] end concat_expert_out cost 0.00013184547424316406 seconds
DEBUG 01-15 10:09:36.404274.404274 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.404249.404249 cuda_h.py:19] end index_scatter cost 0.00012373924255371094 seconds
DEBUG 01-15 10:09:36.404285.404285 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014486312866210938 seconds
DEBUG 01-15 10:09:36.404391.404391 cuda_h.py:19] end gpu_experts cost 0.00422978401184082 seconds
DEBUG 01-15 10:09:36.404986.404986 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06420540809631348 seconds
DEBUG 01-15 10:09:36.405525.405525 cuda_h.py:19] end prefill_layer cost 0.07555246353149414 seconds
DEBUG 01-15 10:09:36.405523.405523 lmp.py:1552] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-15 10:09:36.405472.405472 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.406567.406567 lmp.py:1495] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-15 10:09:36.406100.406100 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:36.406712.406712 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:36.406347.406347 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.152557373046875e-05 seconds
DEBUG 01-15 10:09:36.406594.406594 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00015974044799804688 seconds
DEBUG 01-15 10:09:36.406798.406798 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.406173.406173 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.406788.406788 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.407624.407624 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.407047.407047 cuda_h.py:19] end allocate_cuda_memory cost 0.0003211498260498047 seconds
DEBUG 01-15 10:09:36.407262.407262 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.407893.407893 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.407405.407405 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.407790.407790 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a4c5d50-fa5e-4c00-8b5d-a1e7c424a803
DEBUG 01-15 10:09:36.407483.407483 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.408929.408929 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.408394.408394 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.409760.409760 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a4c5d50-fa5e-4c00-8b5d-a1e7c424a803
DEBUG 01-15 10:09:36.409849.409849 cuda_h.py:19] end load_into_gpu_async cost 0.0018603801727294922 seconds
DEBUG 01-15 10:09:36.409096.409096 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.409524.409524 cuda_h.py:19] end restore_tensors2 cost 0.00010728836059570312 seconds
DEBUG 01-15 10:09:36.409578.409578 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026433467864990234 seconds
INFO 01-15 10:09:36.409601.409601 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a4c5d50-fa5e-4c00-8b5d-a1e7c424a803
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.414468.414468 cuda_h.py:19] end self_attn cost 0.0052509307861328125 seconds
DEBUG 01-15 10:09:36.414220.414220 cuda_h.py:19] end iln_self_attn_paln cost 0.007808685302734375 seconds
DEBUG 01-15 10:09:36.414210.414210 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-15 10:09:36.414576.414576 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.415735.415735 cuda_h.py:19] end gate cost 0.0009353160858154297 seconds
DEBUG 01-15 10:09:36.416036.416036 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.416637.416637 lmp.py:1616] 
DEBUG 01-15 10:09:36.416637.416637 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.416533.416533 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.416071.416071 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.416887.416887 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.416173.416173 lmp.py:1620] 
DEBUG 01-15 10:09:36.416173.416173 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.416936.416936 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.416367.416367 lmp.py:1626]   Expert 58 |     35 | CPU
DEBUG 01-15 10:09:36.416369.416369 lmp.py:1626]   Expert 47 |     58 | CPU
DEBUG 01-15 10:09:36.416370.416370 lmp.py:1626]   Expert 31 |     59 | CPU
DEBUG 01-15 10:09:36.416133.416133 lmp.py:1626]   Expert 49 |     60 | CPU
DEBUG 01-15 10:09:36.416942.416942 lmp.py:1626]   Expert  4 |     65 | CPU
DEBUG 01-15 10:09:36.417989.417989 lmp.py:1626]   Expert 38 |     71 | CPU
DEBUG 01-15 10:09:36.417322.417322 lmp.py:1626]   Expert 45 |     72 | CPU
DEBUG 01-15 10:09:36.417654.417654 lmp.py:1626]   Expert 43 |     82 | CPU
DEBUG 01-15 10:09:36.417086.417086 lmp.py:1626]   Expert 41 |     84 | CPU
DEBUG 01-15 10:09:36.417325.417325 lmp.py:1626]   Expert 33 |     96 | CPU
DEBUG 01-15 10:09:36.417657.417657 lmp.py:1626]   Expert 50 |    102 | CPU
DEBUG 01-15 10:09:36.417275.417275 lmp.py:1626]   Expert 57 |    102 | CPU
DEBUG 01-15 10:09:36.417257.417257 lmp.py:1626]   Expert 11 |    108 | CPU
DEBUG 01-15 10:09:36.417496.417496 lmp.py:1626]   Expert  2 |    115 | CPU
DEBUG 01-15 10:09:36.417352.417352 lmp.py:1626]   Expert 51 |    117 | CPU
DEBUG 01-15 10:09:36.417207.417207 lmp.py:1626]   Expert 14 |    123 | CPU
DEBUG 01-15 10:09:36.417493.417493 lmp.py:1626]   Expert  0 |    124 | CPU
DEBUG 01-15 10:09:36.417587.417587 lmp.py:1626]   Expert 54 |    124 | CPU
DEBUG 01-15 10:09:36.417204.417204 lmp.py:1626]   Expert 56 |    139 | CPU
DEBUG 01-15 10:09:36.417059.417059 lmp.py:1626]   Expert 34 |    142 | CPU
DEBUG 01-15 10:09:36.417392.417392 lmp.py:1626]   Expert 26 |    143 | CPU
DEBUG 01-15 10:09:36.417154.417154 lmp.py:1626]   Expert 27 |    151 | CPU
DEBUG 01-15 10:09:36.417248.417248 lmp.py:1626]   Expert 55 |    157 | CPU
DEBUG 01-15 10:09:36.417865.417865 lmp.py:1626]   Expert 28 |    159 | CPU
DEBUG 01-15 10:09:36.417005.417005 lmp.py:1626]   Expert 10 |    164 | CPU
DEBUG 01-15 10:09:36.417099.417099 lmp.py:1626]   Expert 25 |    164 | CPU
DEBUG 01-15 10:09:36.417147.417147 lmp.py:1626]   Expert  9 |    178 | CPU
DEBUG 01-15 10:09:36.417002.417002 lmp.py:1626]   Expert 13 |    178 | CPU
DEBUG 01-15 10:09:36.417858.417858 lmp.py:1626]   Expert 61 |    187 | CPU
DEBUG 01-15 10:09:36.417912.417912 lmp.py:1626]   Expert  6 |    191 | CPU
DEBUG 01-15 10:09:36.417628.417628 lmp.py:1626]   Expert 48 |    193 | CPU
DEBUG 01-15 10:09:36.417199.417199 lmp.py:1626]   Expert  7 |    195 | CPU
DEBUG 01-15 10:09:36.417770.417770 lmp.py:1626]   Expert 24 |    197 | GPU
DEBUG 01-15 10:09:36.418864.418864 lmp.py:1626]   Expert 46 |    197 | GPU
DEBUG 01-15 10:09:36.418150.418150 lmp.py:1626]   Expert 42 |    203 | GPU
DEBUG 01-15 10:09:36.418005.418005 lmp.py:1626]   Expert 18 |    204 | GPU
DEBUG 01-15 10:09:36.418384.418384 lmp.py:1626]   Expert 40 |    208 | GPU
DEBUG 01-15 10:09:36.418716.418716 lmp.py:1626]   Expert 22 |    215 | GPU
DEBUG 01-15 10:09:36.418571.418571 lmp.py:1626]   Expert 29 |    215 | GPU
DEBUG 01-15 10:09:36.418381.418381 lmp.py:1626]   Expert 12 |    217 | GPU
DEBUG 01-15 10:09:36.418474.418474 lmp.py:1626]   Expert 59 |    217 | GPU
DEBUG 01-15 10:09:36.418091.418091 lmp.py:1626]   Expert 63 |    217 | GPU
DEBUG 01-15 10:09:36.418708.418708 lmp.py:1626]   Expert 21 |    219 | GPU
DEBUG 01-15 10:09:36.418087.418087 lmp.py:1626]   Expert 19 |    227 | GPU
DEBUG 01-15 10:09:36.418704.418704 lmp.py:1626]   Expert 32 |    230 | GPU
DEBUG 01-15 10:09:36.418275.418275 lmp.py:1626]   Expert 36 |    234 | GPU
DEBUG 01-15 10:09:36.418653.418653 lmp.py:1626]   Expert 37 |    242 | GPU
DEBUG 01-15 10:09:36.418509.418509 lmp.py:1626]   Expert  3 |    243 | GPU
DEBUG 01-15 10:09:36.418649.418649 lmp.py:1626]   Expert 16 |    247 | GPU
DEBUG 01-15 10:09:36.418743.418743 lmp.py:1626]   Expert  1 |    248 | GPU
DEBUG 01-15 10:09:36.418552.418552 lmp.py:1626]   Expert  5 |    261 | GPU
DEBUG 01-15 10:09:36.418076.418076 lmp.py:1626]   Expert 20 |    261 | GPU
DEBUG 01-15 10:09:36.418932.418932 lmp.py:1626]   Expert  8 |    269 | GPU
DEBUG 01-15 10:09:36.418072.418072 lmp.py:1626]   Expert 30 |    271 | GPU
DEBUG 01-15 10:09:36.418974.418974 lmp.py:1626]   Expert 62 |    273 | GPU
DEBUG 01-15 10:09:36.418875.418875 lmp.py:1626]   Expert 15 |    275 | GPU
DEBUG 01-15 10:09:36.418923.418923 lmp.py:1626]   Expert 35 |    300 | GPU
DEBUG 01-15 10:09:36.418778.418778 lmp.py:1626]   Expert 39 |    300 | GPU
DEBUG 01-15 10:09:36.418999.418999 lmp.py:1626]   Expert 17 |    306 | GPU
DEBUG 01-15 10:09:36.418947.418947 lmp.py:1626]   Expert 60 |    317 | GPU
INFO 01-15 10:09:36.419542.419542 client.py:127] Model loaded
DEBUG 01-15 10:09:36.419627.419627 lmp.py:1626]   Expert 52 |    357 | GPU
DEBUG 01-15 10:09:36.419220.419220 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.419905.419905 lmp.py:1626]   Expert 23 |    364 | GPU
DEBUG 01-15 10:09:36.419460.419460 lmp.py:1626]   Expert 44 |    377 | GPU
DEBUG 01-15 10:09:36.419521.419521 lmp.py:1626]   Expert 53 |    439 | GPU
DEBUG 01-15 10:09:36.419263.419263 lmp.py:1627] 
DEBUG 01-15 10:09:36.419263.419263 lmp.py:1627]   CPU total tokens: 3938 (32.0%)
DEBUG 01-15 10:09:36.419151.419151 lmp.py:1628]   GPU total tokens: 8350 (68.0%)
DEBUG 01-15 10:09:36.419099.419099 cuda_h.py:19] end experts_map_get cost 0.003825664520263672 seconds
DEBUG 01-15 10:09:36.420596.420596 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.420703.420703 lmp.py:1636] 
DEBUG 01-15 10:09:36.420703.420703 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.420606.420606 cuda_h.py:19] end cpu_experts_submit cost 7.05718994140625e-05 seconds
DEBUG 01-15 10:09:36.420733.420733 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.420874.420874 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.420061.420061 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.420549.420549 cuda_h.py:19] end allocate_cuda_memory cost 0.00028514862060546875 seconds
DEBUG 01-15 10:09:36.420167.420167 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.420499.420499 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.421468.421468 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.421124.421124 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d60796c4-ba84-4194-b122-0982b9f0cfca
DEBUG 01-15 10:09:36.421721.421721 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.422611.422611 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.422387.422387 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.422161.422161 cuda_h.py:19] end restore2model cost 0.0031249523162841797 seconds
DEBUG 01-15 10:09:36.422510.422510 cuda_h.py:19] end sllm_worker_task cost 0.016035079956054688 seconds
DEBUG 01-15 10:09:36.423188.423188 cuda_h.py:19] end move_flatidxs cost 0.0009119510650634766 seconds
DEBUG 01-15 10:09:36.423839.423839 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:36.423384.423384 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d60796c4-ba84-4194-b122-0982b9f0cfca
DEBUG 01-15 10:09:36.423884.423884 cuda_h.py:19] end load_into_gpu_async cost 0.002984285354614258 seconds
DEBUG 01-15 10:09:36.423117.423117 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.424936.424936 cuda_h.py:19] end restore_tensors2 cost 0.0005047321319580078 seconds
DEBUG 01-15 10:09:36.424508.424508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004267692565917969 seconds
DEBUG 01-15 10:09:36.424953.424953 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.427485.427485 cuda_h.py:19] end restore2model cost 0.0027806758880615234 seconds
DEBUG 01-15 10:09:36.427024.427024 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007283449172973633 seconds
DEBUG 01-15 10:09:36.427535.427535 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.427492.427492 cuda_h.py:19] end gpu_sexperts cost 0.00028896331787109375 seconds
DEBUG 01-15 10:09:36.427421.427421 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.429089.429089 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015106201171875 seconds
DEBUG 01-15 10:09:36.430260.430260 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.430855.430855 cuda_h.py:19] end gpu_group_list cost 0.0003192424774169922 seconds
DEBUG 01-15 10:09:36.430727.430727 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.431877.431877 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007026195526123047 seconds
DEBUG 01-15 10:09:36.431938.431938 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.431006.431006 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-15 10:09:36.431656.431656 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.436830.436830 cuda_h.py:19] end group_tensors cost 0.012729406356811523 seconds
DEBUG 01-15 10:09:36.437632.437632 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.441423.441423 cuda_h.py:19] end group pad cost 0.004182577133178711 seconds
DEBUG 01-15 10:09:36.441452.441452 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.464519.464519 cuda_h.py:19] end group_einsum cost 0.023281335830688477 seconds
DEBUG 01-15 10:09:36.464921.464921 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.469697.469697 cuda_h.py:19] end get_outputs_cpu1 cost 0.004891633987426758 seconds
DEBUG 01-15 10:09:36.470464.470464 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.048325538635253906 seconds
DEBUG 01-15 10:09:36.471264.471264 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03983426094055176 seconds
DEBUG 01-15 10:09:36.471820.471820 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.472783.472783 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.472197.472197 cuda_h.py:19] end index_scatter cost 0.00019240379333496094 seconds
DEBUG 01-15 10:09:36.472101.472101 cuda_h.py:19] end cpuoutputsdeal cost 0.0011641979217529297 seconds
DEBUG 01-15 10:09:36.473641.473641 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.473095.473095 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d60796c4-ba84-4194-b122-0982b9f0cfca
INFO 01-15 10:09:36.475242.475242 client.py:127] Model loaded
DEBUG 01-15 10:09:36.475272.475272 cuda_h.py:19] end wait_experts cost 0.0023522377014160156 seconds
DEBUG 01-15 10:09:36.475838.475838 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.475862.475862 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.475626.475626 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.476256.476256 cuda_h.py:19] end gpu_group_tensor cost 0.00035691261291503906 seconds
DEBUG 01-15 10:09:36.476482.476482 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.477487.477487 cuda_h.py:19] end gpu_group_einsum cost 0.0012297630310058594 seconds
DEBUG 01-15 10:09:36.478621.478621 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.478969.478969 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.478527.478527 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005481243133544922 seconds
DEBUG 01-15 10:09:36.478198.478198 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.479463.479463 cuda_h.py:19] end concat_expert_out cost 0.00012373924255371094 seconds
DEBUG 01-15 10:09:36.479454.479454 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.479057.479057 cuda_h.py:19] end index_scatter cost 0.00011849403381347656 seconds
DEBUG 01-15 10:09:36.479411.479411 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013325214385986328 seconds
DEBUG 01-15 10:09:36.479595.479595 cuda_h.py:19] end gpu_experts cost 0.003972768783569336 seconds
DEBUG 01-15 10:09:36.479740.479740 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.06483197212219238 seconds
DEBUG 01-15 10:09:36.480072.480072 cuda_h.py:19] end prefill_layer cost 0.07459235191345215 seconds
DEBUG 01-15 10:09:36.480434.480434 lmp.py:1552] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-15 10:09:36.480104.480104 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.480251.480251 lmp.py:1495] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-15 10:09:36.480921.480921 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:36.480644.480644 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:36.480157.480157 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.412101745605469e-05 seconds
DEBUG 01-15 10:09:36.481026.481026 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.00010609626770019531 seconds
DEBUG 01-15 10:09:36.481974.481974 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.481885.481885 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.481208.481208 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.481015.481015 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.481967.481967 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.482700.482700 cuda_h.py:19] end allocate_cuda_memory cost 0.0004241466522216797 seconds
DEBUG 01-15 10:09:36.482468.482468 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.482498.482498 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.482390.482390 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.482440.482440 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ce6f4d0-a790-4f0f-aead-f0f5542f1402
DEBUG 01-15 10:09:36.482302.482302 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.483111.483111 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.483435.483435 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ce6f4d0-a790-4f0f-aead-f0f5542f1402
DEBUG 01-15 10:09:36.484168.484168 cuda_h.py:19] end load_into_gpu_async cost 0.0016155242919921875 seconds
DEBUG 01-15 10:09:36.484325.484325 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.484870.484870 cuda_h.py:19] end restore_tensors2 cost 0.00035858154296875 seconds
DEBUG 01-15 10:09:36.484252.484252 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032415390014648438 seconds
INFO 01-15 10:09:36.485670.485670 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ce6f4d0-a790-4f0f-aead-f0f5542f1402
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.488237.488237 cuda_h.py:19] end self_attn cost 0.005442142486572266 seconds
DEBUG 01-15 10:09:36.489503.489503 cuda_h.py:19] end iln_self_attn_paln cost 0.00803375244140625 seconds
DEBUG 01-15 10:09:36.489241.489241 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-15 10:09:36.489554.489554 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.490102.490102 cuda_h.py:19] end gate cost 0.0008769035339355469 seconds
DEBUG 01-15 10:09:36.490058.490058 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.490687.490687 lmp.py:1616] 
DEBUG 01-15 10:09:36.490687.490687 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.490159.490159 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.490762.490762 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.490835.490835 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.490717.490717 lmp.py:1620] 
DEBUG 01-15 10:09:36.490717.490717 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.490598.490598 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.490910.490910 lmp.py:1626]   Expert  4 |     10 | CPU
DEBUG 01-15 10:09:36.490076.490076 lmp.py:1626]   Expert 28 |     28 | CPU
DEBUG 01-15 10:09:36.490242.490242 lmp.py:1626]   Expert  7 |     48 | CPU
DEBUG 01-15 10:09:36.490932.490932 lmp.py:1626]   Expert 53 |     56 | CPU
DEBUG 01-15 10:09:36.490859.490859 lmp.py:1626]   Expert 52 |     68 | CPU
DEBUG 01-15 10:09:36.490549.490549 lmp.py:1626]   Expert 43 |     72 | CPU
DEBUG 01-15 10:09:36.490476.490476 lmp.py:1626]   Expert 49 |     84 | CPU
DEBUG 01-15 10:09:36.490689.490689 lmp.py:1626]   Expert 12 |     88 | CPU
DEBUG 01-15 10:09:36.490901.490901 lmp.py:1626]   Expert 47 |    103 | CPU
DEBUG 01-15 10:09:36.490114.490114 lmp.py:1626]   Expert 24 |    106 | CPU
DEBUG 01-15 10:09:36.490088.490088 lmp.py:1626]   Expert 33 |    107 | CPU
DEBUG 01-15 10:09:36.490685.490685 lmp.py:1626]   Expert 50 |    109 | CPU
DEBUG 01-15 10:09:36.491566.491566 lmp.py:1626]   Expert 60 |    110 | CPU
DEBUG 01-15 10:09:36.491163.491163 lmp.py:1626]   Expert  2 |    111 | CPU
DEBUG 01-15 10:09:36.491759.491759 lmp.py:1626]   Expert 15 |    113 | CPU
DEBUG 01-15 10:09:36.491594.491594 lmp.py:1626]   Expert 39 |    114 | CPU
DEBUG 01-15 10:09:36.491476.491476 lmp.py:1626]   Expert 36 |    119 | CPU
DEBUG 01-15 10:09:36.491880.491880 lmp.py:1626]   Expert 25 |    122 | CPU
DEBUG 01-15 10:09:36.491523.491523 lmp.py:1626]   Expert  6 |    125 | CPU
DEBUG 01-15 10:09:36.491928.491928 lmp.py:1626]   Expert 61 |    128 | CPU
DEBUG 01-15 10:09:36.491332.491332 lmp.py:1626]   Expert 59 |    138 | CPU
DEBUG 01-15 10:09:36.491260.491260 lmp.py:1626]   Expert  3 |    141 | CPU
DEBUG 01-15 10:09:36.491426.491426 lmp.py:1626]   Expert 27 |    143 | CPU
DEBUG 01-15 10:09:36.491592.491592 lmp.py:1626]   Expert 58 |    143 | CPU
DEBUG 01-15 10:09:36.491235.491235 lmp.py:1626]   Expert 30 |    149 | CPU
DEBUG 01-15 10:09:36.491640.491640 lmp.py:1626]   Expert  8 |    150 | CPU
DEBUG 01-15 10:09:36.491283.491283 lmp.py:1626]   Expert 31 |    153 | CPU
DEBUG 01-15 10:09:36.491449.491449 lmp.py:1626]   Expert 10 |    158 | CPU
DEBUG 01-15 10:09:36.491152.491152 lmp.py:1626]   Expert 40 |    158 | CPU
DEBUG 01-15 10:09:36.491795.491795 lmp.py:1626]   Expert 57 |    159 | CPU
DEBUG 01-15 10:09:36.491438.491438 lmp.py:1626]   Expert 38 |    161 | CPU
DEBUG 01-15 10:09:36.491034.491034 lmp.py:1626]   Expert 41 |    161 | CPU
DEBUG 01-15 10:09:36.491439.491439 lmp.py:1626]   Expert 14 |    162 | GPU
DEBUG 01-15 10:09:36.491844.491844 lmp.py:1626]   Expert 54 |    163 | GPU
DEBUG 01-15 10:09:36.491248.491248 lmp.py:1626]   Expert 37 |    164 | GPU
DEBUG 01-15 10:09:36.491653.491653 lmp.py:1626]   Expert 32 |    165 | GPU
DEBUG 01-15 10:09:36.491819.491819 lmp.py:1626]   Expert 46 |    170 | GPU
DEBUG 01-15 10:09:36.491985.491985 lmp.py:1626]   Expert 19 |    172 | GPU
DEBUG 01-15 10:09:36.491913.491913 lmp.py:1626]   Expert 42 |    173 | GPU
DEBUG 01-15 10:09:36.491079.491079 lmp.py:1626]   Expert 11 |    178 | GPU
DEBUG 01-15 10:09:36.491483.491483 lmp.py:1626]   Expert 18 |    193 | GPU
DEBUG 01-15 10:09:36.491126.491126 lmp.py:1626]   Expert 22 |    194 | GPU
DEBUG 01-15 10:09:36.491769.491769 lmp.py:1626]   Expert 34 |    195 | GPU
DEBUG 01-15 10:09:36.491174.491174 lmp.py:1626]   Expert 26 |    196 | GPU
DEBUG 01-15 10:09:36.491294.491294 lmp.py:1626]   Expert  0 |    199 | GPU
DEBUG 01-15 10:09:36.491890.491890 lmp.py:1626]   Expert 56 |    200 | GPU
DEBUG 01-15 10:09:36.491487.491487 lmp.py:1626]   Expert  1 |    202 | GPU
DEBUG 01-15 10:09:36.491892.491892 lmp.py:1626]   Expert 44 |    202 | GPU
DEBUG 01-15 10:09:36.491727.491727 lmp.py:1626]   Expert 51 |    214 | GPU
DEBUG 01-15 10:09:36.491131.491131 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:36.491536.491536 lmp.py:1626]   Expert 29 |    230 | GPU
DEBUG 01-15 10:09:36.491225.491225 lmp.py:1626]   Expert 48 |    236 | GPU
DEBUG 01-15 10:09:36.491391.491391 lmp.py:1626]   Expert 45 |    239 | GPU
DEBUG 01-15 10:09:36.491557.491557 lmp.py:1626]   Expert 21 |    243 | GPU
DEBUG 01-15 10:09:36.491485.491485 lmp.py:1626]   Expert 35 |    249 | GPU
DEBUG 01-15 10:09:36.491413.491413 lmp.py:1626]   Expert 16 |    252 | GPU
DEBUG 01-15 10:09:36.491579.491579 lmp.py:1626]   Expert 55 |    253 | GPU
DEBUG 01-15 10:09:36.491699.491699 lmp.py:1626]   Expert  5 |    294 | GPU
DEBUG 01-15 10:09:36.491534.491534 lmp.py:1626]   Expert 23 |    373 | GPU
DEBUG 01-15 10:09:36.491892.491892 lmp.py:1626]   Expert 13 |    385 | GPU
DEBUG 01-15 10:09:36.491297.491297 lmp.py:1626]   Expert 17 |    434 | GPU
DEBUG 01-15 10:09:36.491701.491701 lmp.py:1626]   Expert  9 |    457 | GPU
DEBUG 01-15 10:09:36.491106.491106 lmp.py:1626]   Expert 63 |    461 | GPU
DEBUG 01-15 10:09:36.491510.491510 lmp.py:1626]   Expert 62 |   1182 | GPU
DEBUG 01-15 10:09:36.491153.491153 lmp.py:1627] 
DEBUG 01-15 10:09:36.491153.491153 lmp.py:1627]   CPU total tokens: 3635 (29.6%)
DEBUG 01-15 10:09:36.491465.491465 lmp.py:1628]   GPU total tokens: 8653 (70.4%)
DEBUG 01-15 10:09:36.491592.491592 cuda_h.py:19] end experts_map_get cost 0.0016505718231201172 seconds
INFO 01-15 10:09:36.492199.492199 client.py:127] Model loaded
DEBUG 01-15 10:09:36.492123.492123 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.492410.492410 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.492161.492161 lmp.py:1636] 
DEBUG 01-15 10:09:36.492161.492161 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.492583.492583 cuda_h.py:19] end cpu_experts_submit cost 0.0003514289855957031 seconds
DEBUG 01-15 10:09:36.492809.492809 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.492228.492228 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.493174.493174 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.494696.494696 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.494669.494669 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.494912.494912 cuda_h.py:19] end allocate_cuda_memory cost 0.0006947517395019531 seconds
DEBUG 01-15 10:09:36.495642.495642 cuda_h.py:19] end move_flatidxs cost 0.0008997917175292969 seconds
DEBUG 01-15 10:09:36.495108.495108 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.495703.495703 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.496808.496808 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.496628.496628 cuda_h.py:19] end restore2model cost 0.0036840438842773438 seconds
DEBUG 01-15 10:09:36.496153.496153 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.496081.496081 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c03dccb7-7bff-4b60-bcf3-8eac839770eb
DEBUG 01-15 10:09:36.496976.496976 cuda_h.py:19] end sllm_worker_task cost 0.015081644058227539 seconds
DEBUG 01-15 10:09:36.497693.497693 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:36.498984.498984 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c03dccb7-7bff-4b60-bcf3-8eac839770eb
DEBUG 01-15 10:09:36.499048.499048 cuda_h.py:19] end load_into_gpu_async cost 0.003022432327270508 seconds
DEBUG 01-15 10:09:36.499641.499641 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.500950.500950 cuda_h.py:19] end restore_tensors2 cost 0.0012259483337402344 seconds
DEBUG 01-15 10:09:36.500121.500121 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007816076278686523 seconds
DEBUG 01-15 10:09:36.500959.500959 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.506393.506393 cuda_h.py:19] end group_tensors cost 0.01083993911743164 seconds
DEBUG 01-15 10:09:36.507148.507148 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.508334.508334 cuda_h.py:19] end restore2model cost 0.007138252258300781 seconds
DEBUG 01-15 10:09:36.508192.508192 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.015342950820922852 seconds
DEBUG 01-15 10:09:36.508061.508061 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.508796.508796 cuda_h.py:19] end gpu_sexperts cost 0.0007321834564208984 seconds
DEBUG 01-15 10:09:36.509050.509050 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.511577.511577 cuda_h.py:19] end group pad cost 0.004057168960571289 seconds
DEBUG 01-15 10:09:36.511142.511142 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.512929.512929 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0034241676330566406 seconds
DEBUG 01-15 10:09:36.514187.514187 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.514759.514759 cuda_h.py:19] end gpu_group_list cost 0.0005905628204345703 seconds
DEBUG 01-15 10:09:36.515721.515721 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.516999.516999 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011134147644042969 seconds
DEBUG 01-15 10:09:36.516696.516696 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.516023.516023 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-15 10:09:36.516342.516342 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.529324.529324 cuda_h.py:19] end group_einsum cost 0.018195390701293945 seconds
DEBUG 01-15 10:09:36.529826.529826 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.534586.534586 cuda_h.py:19] end get_outputs_cpu1 cost 0.004847049713134766 seconds
DEBUG 01-15 10:09:36.535857.535857 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0411224365234375 seconds
DEBUG 01-15 10:09:36.536947.536947 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.01979851722717285 seconds
DEBUG 01-15 10:09:36.536573.536573 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.536621.536621 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.536228.536228 cuda_h.py:19] end index_scatter cost 7.843971252441406e-05 seconds
DEBUG 01-15 10:09:36.537256.537256 cuda_h.py:19] end cpuoutputsdeal cost 0.0007805824279785156 seconds
DEBUG 01-15 10:09:36.537986.537986 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.537272.537272 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c03dccb7-7bff-4b60-bcf3-8eac839770eb
INFO 01-15 10:09:36.549500.549500 client.py:127] Model loaded
DEBUG 01-15 10:09:36.549741.549741 cuda_h.py:19] end wait_experts cost 0.01242828369140625 seconds
DEBUG 01-15 10:09:36.549590.549590 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.549062.549062 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.549249.549249 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.550390.550390 cuda_h.py:19] end gpu_group_tensor cost 0.0002117156982421875 seconds
DEBUG 01-15 10:09:36.550076.550076 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.551936.551936 cuda_h.py:19] end gpu_group_einsum cost 0.0013196468353271484 seconds
DEBUG 01-15 10:09:36.551596.551596 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.551578.551578 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.552713.552713 cuda_h.py:19] end all_expert_outputs_slices cost 0.00024247169494628906 seconds
DEBUG 01-15 10:09:36.552946.552946 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.552791.552791 cuda_h.py:19] end concat_expert_out cost 6.222724914550781e-05 seconds
DEBUG 01-15 10:09:36.552959.552959 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.552201.552201 cuda_h.py:19] end index_scatter cost 6.723403930664062e-05 seconds
DEBUG 01-15 10:09:36.552202.552202 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006482601165771484 seconds
DEBUG 01-15 10:09:36.552510.552510 cuda_h.py:19] end gpu_experts cost 0.0027244091033935547 seconds
DEBUG 01-15 10:09:36.552910.552910 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.06343746185302734 seconds
DEBUG 01-15 10:09:36.553762.553762 cuda_h.py:19] end prefill_layer cost 0.07242584228515625 seconds
DEBUG 01-15 10:09:36.553322.553322 lmp.py:1552] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-15 10:09:36.553501.553501 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.553966.553966 lmp.py:1495] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-15 10:09:36.553907.553907 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:36.553471.553471 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:36.553844.553844 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.743171691894531e-05 seconds
DEBUG 01-15 10:09:36.553885.553885 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.961822509765625e-05 seconds
DEBUG 01-15 10:09:36.553058.553058 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.553854.553854 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.553493.553493 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.553237.553237 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.554675.554675 cuda_h.py:19] end allocate_cuda_memory cost 0.00021886825561523438 seconds
DEBUG 01-15 10:09:36.554241.554241 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.554473.554473 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.554342.554342 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.554138.554138 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a17098bc-84ce-43e6-bcc2-e10f3e04dd31
DEBUG 01-15 10:09:36.554015.554015 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.554013.554013 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.554986.554986 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.555793.555793 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a17098bc-84ce-43e6-bcc2-e10f3e04dd31
DEBUG 01-15 10:09:36.555835.555835 cuda_h.py:19] end load_into_gpu_async cost 0.0017037391662597656 seconds
DEBUG 01-15 10:09:36.555207.555207 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.555303.555303 cuda_h.py:19] end restore_tensors2 cost 7.915496826171875e-05 seconds
DEBUG 01-15 10:09:36.555775.555775 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022475719451904297 seconds
INFO 01-15 10:09:36.556736.556736 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a17098bc-84ce-43e6-bcc2-e10f3e04dd31
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.559072.559072 cuda_h.py:19] end self_attn cost 0.004705905914306641 seconds
DEBUG 01-15 10:09:36.559910.559910 cuda_h.py:19] end iln_self_attn_paln cost 0.006249904632568359 seconds
DEBUG 01-15 10:09:36.559422.559422 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-15 10:09:36.559562.559562 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.560069.560069 cuda_h.py:19] end gate cost 0.0006558895111083984 seconds
DEBUG 01-15 10:09:36.560945.560945 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.560849.560849 lmp.py:1616] 
DEBUG 01-15 10:09:36.560849.560849 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.561129.561129 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.561540.561540 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.561090.561090 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.561733.561733 lmp.py:1620] 
DEBUG 01-15 10:09:36.561733.561733 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.561330.561330 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.561642.561642 lmp.py:1626]   Expert 32 |     30 | CPU
DEBUG 01-15 10:09:36.561046.561046 lmp.py:1626]   Expert  5 |     52 | CPU
DEBUG 01-15 10:09:36.561212.561212 lmp.py:1626]   Expert 30 |     53 | CPU
DEBUG 01-15 10:09:36.561140.561140 lmp.py:1626]   Expert 46 |     73 | CPU
DEBUG 01-15 10:09:36.561830.561830 lmp.py:1626]   Expert  8 |     87 | CPU
DEBUG 01-15 10:09:36.561996.561996 lmp.py:1626]   Expert 40 |     94 | CPU
DEBUG 01-15 10:09:36.561447.561447 lmp.py:1626]   Expert 12 |    100 | CPU
DEBUG 01-15 10:09:36.561136.561136 lmp.py:1626]   Expert 17 |    104 | CPU
DEBUG 01-15 10:09:36.561064.561064 lmp.py:1626]   Expert 27 |    111 | CPU
DEBUG 01-15 10:09:36.561276.561276 lmp.py:1626]   Expert 60 |    113 | CPU
DEBUG 01-15 10:09:36.561204.561204 lmp.py:1626]   Expert  3 |    114 | CPU
DEBUG 01-15 10:09:36.561370.561370 lmp.py:1626]   Expert 58 |    115 | CPU
DEBUG 01-15 10:09:36.561774.561774 lmp.py:1626]   Expert 21 |    116 | CPU
DEBUG 01-15 10:09:36.561702.561702 lmp.py:1626]   Expert 29 |    120 | CPU
DEBUG 01-15 10:09:36.561107.561107 lmp.py:1626]   Expert 28 |    121 | CPU
DEBUG 01-15 10:09:36.561034.561034 lmp.py:1626]   Expert 41 |    127 | CPU
DEBUG 01-15 10:09:36.561485.561485 lmp.py:1626]   Expert 25 |    128 | CPU
DEBUG 01-15 10:09:36.561175.561175 lmp.py:1626]   Expert 19 |    135 | CPU
DEBUG 01-15 10:09:36.561864.561864 lmp.py:1626]   Expert 35 |    135 | CPU
DEBUG 01-15 10:09:36.561553.561553 lmp.py:1626]   Expert  0 |    145 | CPU
DEBUG 01-15 10:09:36.561766.561766 lmp.py:1626]   Expert  6 |    146 | CPU
DEBUG 01-15 10:09:36.561740.561740 lmp.py:1626]   Expert 54 |    147 | CPU
DEBUG 01-15 10:09:36.561191.561191 lmp.py:1626]   Expert 37 |    150 | CPU
DEBUG 01-15 10:09:36.561787.561787 lmp.py:1626]   Expert 52 |    150 | CPU
DEBUG 01-15 10:09:36.561099.561099 lmp.py:1626]   Expert 56 |    150 | CPU
DEBUG 01-15 10:09:36.561219.561219 lmp.py:1626]   Expert 63 |    156 | CPU
DEBUG 01-15 10:09:36.561577.561577 lmp.py:1626]   Expert 53 |    157 | CPU
DEBUG 01-15 10:09:36.561459.561459 lmp.py:1626]   Expert 48 |    158 | CPU
DEBUG 01-15 10:09:36.561294.561294 lmp.py:1626]   Expert 36 |    162 | CPU
DEBUG 01-15 10:09:36.561367.561367 lmp.py:1626]   Expert 59 |    170 | CPU
DEBUG 01-15 10:09:36.561725.561725 lmp.py:1626]   Expert  9 |    182 | CPU
DEBUG 01-15 10:09:36.561084.561084 lmp.py:1626]   Expert  1 |    188 | CPU
DEBUG 01-15 10:09:36.561157.561157 lmp.py:1626]   Expert 39 |    192 | GPU
DEBUG 01-15 10:09:36.561277.561277 lmp.py:1626]   Expert 20 |    197 | GPU
DEBUG 01-15 10:09:36.561874.561874 lmp.py:1626]   Expert 42 |    201 | GPU
DEBUG 01-15 10:09:36.561470.561470 lmp.py:1626]   Expert 61 |    202 | GPU
DEBUG 01-15 10:09:36.561067.561067 lmp.py:1626]   Expert  7 |    203 | GPU
DEBUG 01-15 10:09:36.561663.561663 lmp.py:1626]   Expert 43 |    205 | GPU
DEBUG 01-15 10:09:36.561260.561260 lmp.py:1626]   Expert 34 |    206 | GPU
DEBUG 01-15 10:09:36.561618.561618 lmp.py:1626]   Expert 11 |    207 | GPU
DEBUG 01-15 10:09:36.561977.561977 lmp.py:1626]   Expert 47 |    209 | GPU
DEBUG 01-15 10:09:36.561381.561381 lmp.py:1626]   Expert 55 |    213 | GPU
DEBUG 01-15 10:09:36.561786.561786 lmp.py:1626]   Expert 13 |    222 | GPU
DEBUG 01-15 10:09:36.561190.561190 lmp.py:1626]   Expert 16 |    223 | GPU
DEBUG 01-15 10:09:36.561356.561356 lmp.py:1626]   Expert 57 |    223 | GPU
DEBUG 01-15 10:09:36.561284.561284 lmp.py:1626]   Expert 18 |    230 | GPU
DEBUG 01-15 10:09:36.561927.561927 lmp.py:1626]   Expert 15 |    233 | GPU
DEBUG 01-15 10:09:36.561570.561570 lmp.py:1626]   Expert  4 |    238 | GPU
DEBUG 01-15 10:09:36.561498.561498 lmp.py:1626]   Expert 50 |    244 | GPU
DEBUG 01-15 10:09:36.561379.561379 lmp.py:1626]   Expert 22 |    246 | GPU
DEBUG 01-15 10:09:36.561737.561737 lmp.py:1626]   Expert 33 |    247 | GPU
DEBUG 01-15 10:09:36.562096.562096 lmp.py:1626]   Expert 45 |    247 | GPU
DEBUG 01-15 10:09:36.562692.562692 lmp.py:1626]   Expert 31 |    249 | GPU
DEBUG 01-15 10:09:36.562812.562812 lmp.py:1626]   Expert 51 |    255 | GPU
DEBUG 01-15 10:09:36.562694.562694 lmp.py:1626]   Expert 49 |    263 | GPU
DEBUG 01-15 10:09:36.562336.562336 lmp.py:1626]   Expert 26 |    276 | GPU
DEBUG 01-15 10:09:36.562741.562741 lmp.py:1626]   Expert 38 |    277 | GPU
DEBUG 01-15 10:09:36.562622.562622 lmp.py:1626]   Expert 10 |    284 | GPU
DEBUG 01-15 10:09:36.562504.562504 lmp.py:1626]   Expert 44 |    297 | GPU
DEBUG 01-15 10:09:36.562908.562908 lmp.py:1626]   Expert  2 |    303 | GPU
DEBUG 01-15 10:09:36.562551.562551 lmp.py:1626]   Expert 24 |    307 | GPU
DEBUG 01-15 10:09:36.562194.562194 lmp.py:1626]   Expert 14 |    313 | GPU
DEBUG 01-15 10:09:36.562076.562076 lmp.py:1626]   Expert 23 |    407 | GPU
DEBUG 01-15 10:09:36.562911.562911 lmp.py:1626]   Expert 62 |    680 | GPU
DEBUG 01-15 10:09:36.562746.562746 lmp.py:1627] 
DEBUG 01-15 10:09:36.562746.562746 lmp.py:1627]   CPU total tokens: 3989 (32.5%)
DEBUG 01-15 10:09:36.562296.562296 lmp.py:1628]   GPU total tokens: 8299 (67.5%)
DEBUG 01-15 10:09:36.562138.562138 cuda_h.py:19] end experts_map_get cost 0.0015892982482910156 seconds
DEBUG 01-15 10:09:36.562319.562319 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.562976.562976 lmp.py:1636] 
DEBUG 01-15 10:09:36.562976.562976 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.562666.562666 cuda_h.py:19] end cpu_experts_submit cost 5.1975250244140625e-05 seconds
DEBUG 01-15 10:09:36.562455.562455 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.562145.562145 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.562740.562740 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.562092.562092 cuda_h.py:19] end allocate_cuda_memory cost 0.00019168853759765625 seconds
DEBUG 01-15 10:09:36.562935.562935 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.562976.562976 sllm_store_c.py:27] get device uuid map
INFO 01-15 10:09:36.563705.563705 client.py:127] Model loaded
DEBUG 01-15 10:09:36.563152.563152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.563840.563840 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81fa8504-6a7a-4726-b9b8-9dad1dc9dcf5
DEBUG 01-15 10:09:36.563946.563946 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.564946.564946 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.564231.564231 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.563725.563725 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.565422.565422 cuda_h.py:19] end move_flatidxs cost 0.0008842945098876953 seconds
DEBUG 01-15 10:09:36.565026.565026 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.565422.565422 cuda_h.py:19] end restore2model cost 0.000978231430053711 seconds
INFO 01-15 10:09:36.565651.565651 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81fa8504-6a7a-4726-b9b8-9dad1dc9dcf5
DEBUG 01-15 10:09:36.565977.565977 cuda_h.py:19] end sllm_worker_task cost 0.012070894241333008 seconds
DEBUG 01-15 10:09:36.565355.565355 cuda_h.py:19] end load_into_gpu_async cost 0.002979755401611328 seconds
DEBUG 01-15 10:09:36.566899.566899 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.567470.567470 cuda_h.py:19] end restore_tensors2 cost 0.001127481460571289 seconds
DEBUG 01-15 10:09:36.567846.567846 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005079030990600586 seconds
DEBUG 01-15 10:09:36.567342.567342 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.572873.572873 cuda_h.py:19] end group_tensors cost 0.007628679275512695 seconds
DEBUG 01-15 10:09:36.573846.573846 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.577907.577907 cuda_h.py:19] end restore2model cost 0.009824037551879883 seconds
DEBUG 01-15 10:09:36.577988.577988 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.015489578247070312 seconds
DEBUG 01-15 10:09:36.578474.578474 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.578702.578702 cuda_h.py:19] end group pad cost 0.00435328483581543 seconds
DEBUG 01-15 10:09:36.578161.578161 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.579671.579671 cuda_h.py:19] end gpu_sexperts cost 0.0010285377502441406 seconds
DEBUG 01-15 10:09:36.579438.579438 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.584324.584324 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.005189180374145508 seconds
DEBUG 01-15 10:09:36.586606.586606 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.587205.587205 cuda_h.py:19] end gpu_group_list cost 0.000423431396484375 seconds
DEBUG 01-15 10:09:36.587296.587296 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.588466.588466 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0012655258178710938 seconds
DEBUG 01-15 10:09:36.588138.588138 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.588943.588943 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 6.103515625e-05 seconds
DEBUG 01-15 10:09:36.588076.588076 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.600997.600997 cuda_h.py:19] end group_einsum cost 0.022679805755615234 seconds
DEBUG 01-15 10:09:36.601545.601545 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.606172.606172 cuda_h.py:19] end get_outputs_cpu1 cost 0.00481414794921875 seconds
DEBUG 01-15 10:09:36.606285.606285 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.042860984802246094 seconds
DEBUG 01-15 10:09:36.607412.607412 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.018838167190551758 seconds
DEBUG 01-15 10:09:36.607385.607385 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.608247.608247 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.608488.608488 cuda_h.py:19] end index_scatter cost 0.00018596649169921875 seconds
DEBUG 01-15 10:09:36.609376.609376 cuda_h.py:19] end cpuoutputsdeal cost 0.001241445541381836 seconds
DEBUG 01-15 10:09:36.609214.609214 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.609077.609077 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81fa8504-6a7a-4726-b9b8-9dad1dc9dcf5
INFO 01-15 10:09:36.616853.616853 client.py:127] Model loaded
DEBUG 01-15 10:09:36.616746.616746 cuda_h.py:19] end wait_experts cost 0.007303476333618164 seconds
DEBUG 01-15 10:09:36.616384.616384 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.616336.616336 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.616067.616067 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.617580.617580 cuda_h.py:19] end gpu_group_tensor cost 0.00040030479431152344 seconds
DEBUG 01-15 10:09:36.617999.617999 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.618771.618771 cuda_h.py:19] end gpu_group_einsum cost 0.0011911392211914062 seconds
DEBUG 01-15 10:09:36.619164.619164 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.619194.619194 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.620236.620236 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005824565887451172 seconds
DEBUG 01-15 10:09:36.620345.620345 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.620346.620346 cuda_h.py:19] end concat_expert_out cost 0.0001342296600341797 seconds
DEBUG 01-15 10:09:36.620808.620808 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.620683.620683 cuda_h.py:19] end index_scatter cost 0.00013375282287597656 seconds
DEBUG 01-15 10:09:36.620997.620997 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014615058898925781 seconds
DEBUG 01-15 10:09:36.620129.620129 cuda_h.py:19] end gpu_experts cost 0.00416111946105957 seconds
DEBUG 01-15 10:09:36.621480.621480 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.061199188232421875 seconds
DEBUG 01-15 10:09:36.622827.622827 cuda_h.py:19] end prefill_layer cost 0.06862807273864746 seconds
DEBUG 01-15 10:09:36.622759.622759 lmp.py:1552] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-15 10:09:36.622469.622469 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.622088.622088 lmp.py:1495] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-15 10:09:36.622805.622805 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:36.622814.622814 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:36.622641.622641 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.748603820800781e-05 seconds
DEBUG 01-15 10:09:36.622576.622576 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 0.00014710426330566406 seconds
DEBUG 01-15 10:09:36.622260.622260 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.622953.622953 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.623820.623820 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.623545.623545 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.623664.623664 cuda_h.py:19] end allocate_cuda_memory cost 0.00035834312438964844 seconds
DEBUG 01-15 10:09:36.623389.623389 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.623151.623151 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.623842.623842 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.623167.623167 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 46f93773-f470-499d-ae67-a7a71f891c5a
DEBUG 01-15 10:09:36.623449.623449 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.624502.624502 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.624610.624610 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.624920.624920 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 46f93773-f470-499d-ae67-a7a71f891c5a
DEBUG 01-15 10:09:36.625232.625232 cuda_h.py:19] end load_into_gpu_async cost 0.0014219284057617188 seconds
DEBUG 01-15 10:09:36.625909.625909 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.625119.625119 cuda_h.py:19] end restore_tensors2 cost 9.250640869140625e-05 seconds
DEBUG 01-15 10:09:36.625497.625497 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002177715301513672 seconds
INFO 01-15 10:09:36.625693.625693 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 46f93773-f470-499d-ae67-a7a71f891c5a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.629617.629617 cuda_h.py:19] end self_attn cost 0.0048978328704833984 seconds
DEBUG 01-15 10:09:36.630639.630639 cuda_h.py:19] end iln_self_attn_paln cost 0.007491111755371094 seconds
DEBUG 01-15 10:09:36.630078.630078 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-15 10:09:36.630378.630378 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.631922.631922 cuda_h.py:19] end gate cost 0.0007791519165039062 seconds
DEBUG 01-15 10:09:36.631004.631004 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.631588.631588 lmp.py:1616] 
DEBUG 01-15 10:09:36.631588.631588 lmp.py:1616] Expert Token Distribution & Device Allocation:
INFO 01-15 10:09:36.631133.631133 client.py:127] Model loaded
DEBUG 01-15 10:09:36.631970.631970 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.631945.631945 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.631847.631847 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.632033.632033 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.632974.632974 lmp.py:1620] 
DEBUG 01-15 10:09:36.632974.632974 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.632723.632723 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.632949.632949 lmp.py:1626]   Expert 44 |     38 | CPU
DEBUG 01-15 10:09:36.632221.632221 lmp.py:1626]   Expert  1 |     47 | CPU
DEBUG 01-15 10:09:36.632779.632779 lmp.py:1626]   Expert 60 |     63 | CPU
DEBUG 01-15 10:09:36.632336.632336 lmp.py:1626]   Expert 28 |     73 | CPU
DEBUG 01-15 10:09:36.632939.632939 lmp.py:1626]   Expert 48 |     78 | CPU
DEBUG 01-15 10:09:36.632543.632543 lmp.py:1626]   Expert 27 |     85 | CPU
DEBUG 01-15 10:09:36.632908.632908 lmp.py:1626]   Expert  0 |     97 | CPU
DEBUG 01-15 10:09:36.632511.632511 lmp.py:1626]   Expert 62 |    108 | CPU
DEBUG 01-15 10:09:36.632744.632744 lmp.py:1626]   Expert 22 |    113 | CPU
DEBUG 01-15 10:09:36.632824.632824 lmp.py:1626]   Expert 42 |    114 | CPU
DEBUG 01-15 10:09:36.632904.632904 lmp.py:1626]   Expert 30 |    115 | CPU
DEBUG 01-15 10:09:36.632746.632746 lmp.py:1626]   Expert 59 |    116 | CPU
DEBUG 01-15 10:09:36.632065.632065 lmp.py:1626]   Expert 58 |    121 | CPU
DEBUG 01-15 10:09:36.632668.632668 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:36.632318.632318 lmp.py:1626]   Expert  8 |    131 | CPU
DEBUG 01-15 10:09:36.632206.632206 lmp.py:1626]   Expert 12 |    133 | CPU
DEBUG 01-15 10:09:36.632095.632095 lmp.py:1626]   Expert 50 |    134 | CPU
DEBUG 01-15 10:09:36.632221.632221 lmp.py:1626]   Expert  5 |    142 | CPU
DEBUG 01-15 10:09:36.632348.632348 lmp.py:1626]   Expert 56 |    144 | CPU
DEBUG 01-15 10:09:36.632428.632428 lmp.py:1626]   Expert 55 |    150 | CPU
DEBUG 01-15 10:09:36.632508.632508 lmp.py:1626]   Expert 57 |    152 | CPU
DEBUG 01-15 10:09:36.632350.632350 lmp.py:1626]   Expert 15 |    153 | CPU
DEBUG 01-15 10:09:36.632669.632669 lmp.py:1626]   Expert 26 |    154 | CPU
DEBUG 01-15 10:09:36.632795.632795 lmp.py:1626]   Expert 32 |    156 | CPU
DEBUG 01-15 10:09:36.632445.632445 lmp.py:1626]   Expert 34 |    156 | CPU
DEBUG 01-15 10:09:36.632095.632095 lmp.py:1626]   Expert 47 |    158 | CPU
DEBUG 01-15 10:09:36.632745.632745 lmp.py:1626]   Expert 24 |    163 | CPU
DEBUG 01-15 10:09:36.632394.632394 lmp.py:1626]   Expert  2 |    165 | CPU
DEBUG 01-15 10:09:36.632283.632283 lmp.py:1626]   Expert 52 |    165 | CPU
DEBUG 01-15 10:09:36.632694.632694 lmp.py:1626]   Expert  6 |    171 | CPU
DEBUG 01-15 10:09:36.632297.632297 lmp.py:1626]   Expert 40 |    171 | CPU
DEBUG 01-15 10:09:36.632378.632378 lmp.py:1626]   Expert 18 |    172 | CPU
DEBUG 01-15 10:09:36.632220.632220 lmp.py:1626]   Expert 13 |    173 | GPU
DEBUG 01-15 10:09:36.632538.632538 lmp.py:1626]   Expert 41 |    174 | GPU
DEBUG 01-15 10:09:36.633426.633426 lmp.py:1626]   Expert 54 |    174 | GPU
DEBUG 01-15 10:09:36.633315.633315 lmp.py:1626]   Expert  3 |    177 | GPU
DEBUG 01-15 10:09:36.633964.633964 lmp.py:1626]   Expert 19 |    178 | GPU
DEBUG 01-15 10:09:36.633614.633614 lmp.py:1626]   Expert 37 |    182 | GPU
DEBUG 01-15 10:09:36.633264.633264 lmp.py:1626]   Expert 20 |    183 | GPU
DEBUG 01-15 10:09:36.633914.633914 lmp.py:1626]   Expert 46 |    185 | GPU
DEBUG 01-15 10:09:36.633563.633563 lmp.py:1626]   Expert 25 |    189 | GPU
DEBUG 01-15 10:09:36.633213.633213 lmp.py:1626]   Expert 51 |    194 | GPU
DEBUG 01-15 10:09:36.633294.633294 lmp.py:1626]   Expert 11 |    198 | GPU
DEBUG 01-15 10:09:36.633135.633135 lmp.py:1626]   Expert 43 |    201 | GPU
DEBUG 01-15 10:09:36.633853.633853 lmp.py:1626]   Expert 17 |    204 | GPU
DEBUG 01-15 10:09:36.633033.633033 lmp.py:1626]   Expert 35 |    205 | GPU
DEBUG 01-15 10:09:36.633159.633159 lmp.py:1626]   Expert 31 |    207 | GPU
DEBUG 01-15 10:09:36.633524.633524 lmp.py:1626]   Expert 23 |    213 | GPU
DEBUG 01-15 10:09:36.633128.633128 lmp.py:1626]   Expert 39 |    221 | GPU
DEBUG 01-15 10:09:36.633685.633685 lmp.py:1626]   Expert 49 |    223 | GPU
DEBUG 01-15 10:09:36.633480.633480 lmp.py:1626]   Expert 53 |    229 | GPU
DEBUG 01-15 10:09:36.633845.633845 lmp.py:1626]   Expert 10 |    232 | GPU
DEBUG 01-15 10:09:36.633495.633495 lmp.py:1626]   Expert 33 |    249 | GPU
DEBUG 01-15 10:09:36.633383.633383 lmp.py:1626]   Expert 36 |    264 | GPU
DEBUG 01-15 10:09:36.633033.633033 lmp.py:1626]   Expert 38 |    267 | GPU
DEBUG 01-15 10:09:36.633683.633683 lmp.py:1626]   Expert  4 |    302 | GPU
DEBUG 01-15 10:09:36.633333.633333 lmp.py:1626]   Expert 21 |    335 | GPU
DEBUG 01-15 10:09:36.633698.633698 lmp.py:1626]   Expert 14 |    346 | GPU
DEBUG 01-15 10:09:36.633063.633063 lmp.py:1626]   Expert 45 |    370 | GPU
DEBUG 01-15 10:09:36.633381.633381 lmp.py:1626]   Expert 63 |    370 | GPU
DEBUG 01-15 10:09:36.633270.633270 lmp.py:1626]   Expert  9 |    388 | GPU
DEBUG 01-15 10:09:36.633681.633681 lmp.py:1626]   Expert 61 |    391 | GPU
DEBUG 01-15 10:09:36.633808.633808 lmp.py:1626]   Expert 29 |    484 | GPU
DEBUG 01-15 10:09:36.633457.633457 lmp.py:1626]   Expert  7 |    516 | GPU
DEBUG 01-15 10:09:36.633776.633776 lmp.py:1627] 
DEBUG 01-15 10:09:36.633776.633776 lmp.py:1627]   CPU total tokens: 4064 (33.1%)
DEBUG 01-15 10:09:36.633333.633333 lmp.py:1628]   GPU total tokens: 8224 (66.9%)
DEBUG 01-15 10:09:36.633089.633089 cuda_h.py:19] end experts_map_get cost 0.0025177001953125 seconds
DEBUG 01-15 10:09:36.633796.633796 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.634580.634580 lmp.py:1636] 
DEBUG 01-15 10:09:36.634580.634580 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.634020.634020 cuda_h.py:19] end cpu_experts_submit cost 7.843971252441406e-05 seconds
DEBUG 01-15 10:09:36.634060.634060 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.634262.634262 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.634473.634473 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.634450.634450 cuda_h.py:19] end allocate_cuda_memory cost 0.00025653839111328125 seconds
DEBUG 01-15 10:09:36.634720.634720 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.634065.634065 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.634948.634948 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.634181.634181 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1355ecf0-ceb5-45df-b100-aea9e9754c56
DEBUG 01-15 10:09:36.635270.635270 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.635919.635919 cuda_h.py:19] end restore2model cost 0.003476381301879883 seconds
DEBUG 01-15 10:09:36.635801.635801 cuda_h.py:19] end sllm_worker_task cost 0.012524843215942383 seconds
INFO 01-15 10:09:36.636378.636378 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1355ecf0-ceb5-45df-b100-aea9e9754c56
DEBUG 01-15 10:09:36.636341.636341 cuda_h.py:19] end load_into_gpu_async cost 0.0017094612121582031 seconds
DEBUG 01-15 10:09:36.636581.636581 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.636233.636233 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.637742.637742 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.637427.637427 cuda_h.py:19] end restore_tensors2 cost 0.0005192756652832031 seconds
DEBUG 01-15 10:09:36.637960.637960 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030095577239990234 seconds
DEBUG 01-15 10:09:36.637074.637074 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.638508.638508 cuda_h.py:19] end move_flatidxs cost 0.0011665821075439453 seconds
DEBUG 01-15 10:09:36.638479.638479 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.640933.640933 cuda_h.py:19] end restore2model cost 0.0026688575744628906 seconds
DEBUG 01-15 10:09:36.640306.640306 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005911350250244141 seconds
DEBUG 01-15 10:09:36.640386.640386 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.640304.640304 cuda_h.py:19] end gpu_sexperts cost 0.00029540061950683594 seconds
DEBUG 01-15 10:09:36.640041.640041 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.642609.642609 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015077590942382812 seconds
DEBUG 01-15 10:09:36.642504.642504 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.643682.643682 cuda_h.py:19] end gpu_group_list cost 0.00032210350036621094 seconds
DEBUG 01-15 10:09:36.643520.643520 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.644209.644209 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007483959197998047 seconds
DEBUG 01-15 10:09:36.644793.644793 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.644331.644331 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-15 10:09:36.644789.644789 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.649322.649322 cuda_h.py:19] end group_tensors cost 0.01064920425415039 seconds
DEBUG 01-15 10:09:36.650418.650418 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.654311.654311 cuda_h.py:19] end group pad cost 0.004631757736206055 seconds
DEBUG 01-15 10:09:36.654797.654797 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.676386.676386 cuda_h.py:19] end group_einsum cost 0.021050453186035156 seconds
DEBUG 01-15 10:09:36.676742.676742 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.681811.681811 cuda_h.py:19] end get_outputs_cpu1 cost 0.004735708236694336 seconds
DEBUG 01-15 10:09:36.681327.681327 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04496884346008301 seconds
DEBUG 01-15 10:09:36.683943.683943 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03894376754760742 seconds
DEBUG 01-15 10:09:36.683889.683889 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.683704.683704 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.684493.684493 cuda_h.py:19] end index_scatter cost 0.0001442432403564453 seconds
DEBUG 01-15 10:09:36.684753.684753 cuda_h.py:19] end cpuoutputsdeal cost 0.0011987686157226562 seconds
DEBUG 01-15 10:09:36.684577.684577 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.684857.684857 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1355ecf0-ceb5-45df-b100-aea9e9754c56
INFO 01-15 10:09:36.687908.687908 client.py:127] Model loaded
DEBUG 01-15 10:09:36.687634.687634 cuda_h.py:19] end wait_experts cost 0.002825021743774414 seconds
DEBUG 01-15 10:09:36.687477.687477 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.687918.687918 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.687913.687913 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.688590.688590 cuda_h.py:19] end gpu_group_tensor cost 0.0003609657287597656 seconds
DEBUG 01-15 10:09:36.688533.688533 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.689256.689256 cuda_h.py:19] end gpu_group_einsum cost 0.0009243488311767578 seconds
DEBUG 01-15 10:09:36.689601.689601 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.689843.689843 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.690462.690462 cuda_h.py:19] end all_expert_outputs_slices cost 0.0008053779602050781 seconds
DEBUG 01-15 10:09:36.690265.690265 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.691901.691901 cuda_h.py:19] end concat_expert_out cost 0.00012087821960449219 seconds
DEBUG 01-15 10:09:36.691554.691554 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.691104.691104 cuda_h.py:19] end index_scatter cost 0.00011944770812988281 seconds
DEBUG 01-15 10:09:36.691020.691020 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015559196472167969 seconds
DEBUG 01-15 10:09:36.691416.691416 cuda_h.py:19] end gpu_experts cost 0.003861665725708008 seconds
DEBUG 01-15 10:09:36.691700.691700 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06143355369567871 seconds
DEBUG 01-15 10:09:36.692200.692200 cuda_h.py:19] end prefill_layer cost 0.07019472122192383 seconds
DEBUG 01-15 10:09:36.692680.692680 lmp.py:1552] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-15 10:09:36.692046.692046 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.692227.692227 lmp.py:1495] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-15 10:09:36.692455.692455 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:36.692689.692689 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:36.692733.692733 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:36.693293.693293 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.693454.693454 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00025391578674316406 seconds
DEBUG 01-15 10:09:36.693789.693789 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.693798.693798 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.693821.693821 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.693435.693435 cuda_h.py:19] end allocate_cuda_memory cost 0.00022721290588378906 seconds
DEBUG 01-15 10:09:36.693100.693100 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.693955.693955 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.693738.693738 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.693587.693587 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df314207-34e0-4c2c-a611-25c5b35e35ce
DEBUG 01-15 10:09:36.694769.694769 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.694484.694484 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:36.694650.694650 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df314207-34e0-4c2c-a611-25c5b35e35ce
DEBUG 01-15 10:09:36.694824.694824 cuda_h.py:19] end load_into_gpu_async cost 0.0010275840759277344 seconds
DEBUG 01-15 10:09:36.694289.694289 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.695007.695007 cuda_h.py:19] end restore_tensors2 cost 8.320808410644531e-05 seconds
DEBUG 01-15 10:09:36.695763.695763 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016758441925048828 seconds
INFO 01-15 10:09:36.695256.695256 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df314207-34e0-4c2c-a611-25c5b35e35ce
DEBUG 01-15 10:09:36.695805.695805 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.702341.702341 cuda_h.py:19] end self_attn cost 0.007144451141357422 seconds
INFO 01-15 10:09:36.703174.703174 client.py:127] Model loaded
DEBUG 01-15 10:09:36.703238.703238 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.704402.704402 cuda_h.py:19] end restore2model cost 0.0008699893951416016 seconds
DEBUG 01-15 10:09:36.704981.704981 cuda_h.py:19] end sllm_worker_task cost 0.011075258255004883 seconds
DEBUG 01-15 10:09:36.704137.704137 cuda_h.py:19] end iln_self_attn_paln cost 0.011126041412353516 seconds
DEBUG 01-15 10:09:36.704108.704108 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-15 10:09:36.704222.704222 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.706366.706366 cuda_h.py:19] end gate cost 0.0012881755828857422 seconds
DEBUG 01-15 10:09:36.706309.706309 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.707256.707256 lmp.py:1616] 
DEBUG 01-15 10:09:36.707256.707256 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.707841.707841 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.707411.707411 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.707783.707783 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.707532.707532 lmp.py:1620] 
DEBUG 01-15 10:09:36.707532.707532 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.707997.707997 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.707461.707461 lmp.py:1626]   Expert 54 |     21 | CPU
DEBUG 01-15 10:09:36.707018.707018 lmp.py:1626]   Expert  3 |     32 | CPU
DEBUG 01-15 10:09:36.707860.707860 lmp.py:1626]   Expert  8 |     38 | CPU
DEBUG 01-15 10:09:36.707464.707464 lmp.py:1626]   Expert 28 |     45 | CPU
DEBUG 01-15 10:09:36.707590.707590 lmp.py:1626]   Expert 43 |     53 | CPU
DEBUG 01-15 10:09:36.707478.707478 lmp.py:1626]   Expert 63 |     54 | CPU
DEBUG 01-15 10:09:36.707605.707605 lmp.py:1626]   Expert 36 |     75 | CPU
DEBUG 01-15 10:09:36.707732.707732 lmp.py:1626]   Expert 38 |     78 | CPU
DEBUG 01-15 10:09:36.707620.707620 lmp.py:1626]   Expert  6 |     81 | CPU
DEBUG 01-15 10:09:36.707746.707746 lmp.py:1626]   Expert 39 |     96 | CPU
DEBUG 01-15 10:09:36.707396.707396 lmp.py:1626]   Expert 57 |     98 | CPU
DEBUG 01-15 10:09:36.707006.707006 lmp.py:1626]   Expert 41 |    104 | CPU
DEBUG 01-15 10:09:36.707272.707272 lmp.py:1626]   Expert 52 |    108 | CPU
DEBUG 01-15 10:09:36.707491.707491 lmp.py:1626]   Expert 12 |    111 | CPU
DEBUG 01-15 10:09:36.707849.707849 lmp.py:1626]   Expert 19 |    120 | CPU
DEBUG 01-15 10:09:36.707539.707539 lmp.py:1626]   Expert 47 |    127 | CPU
DEBUG 01-15 10:09:36.707751.707751 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:36.707441.707441 lmp.py:1626]   Expert 22 |    138 | CPU
DEBUG 01-15 10:09:36.707891.707891 lmp.py:1626]   Expert 46 |    146 | CPU
DEBUG 01-15 10:09:36.707865.707865 lmp.py:1626]   Expert 50 |    153 | CPU
DEBUG 01-15 10:09:36.707555.707555 lmp.py:1626]   Expert 40 |    163 | CPU
DEBUG 01-15 10:09:36.707006.707006 lmp.py:1626]   Expert 20 |    165 | CPU
DEBUG 01-15 10:09:36.707933.707933 lmp.py:1626]   Expert 24 |    165 | CPU
DEBUG 01-15 10:09:36.707384.707384 lmp.py:1626]   Expert 55 |    166 | CPU
DEBUG 01-15 10:09:36.707835.707835 lmp.py:1626]   Expert 37 |    170 | CPU
DEBUG 01-15 10:09:36.707955.707955 lmp.py:1626]   Expert 23 |    171 | CPU
DEBUG 01-15 10:09:36.707075.707075 lmp.py:1626]   Expert 53 |    172 | CPU
DEBUG 01-15 10:09:36.707340.707340 lmp.py:1626]   Expert  2 |    173 | CPU
DEBUG 01-15 10:09:36.707791.707791 lmp.py:1626]   Expert 21 |    173 | CPU
DEBUG 01-15 10:09:36.707242.707242 lmp.py:1626]   Expert 61 |    175 | CPU
DEBUG 01-15 10:09:36.707693.707693 lmp.py:1626]   Expert 49 |    178 | CPU
DEBUG 01-15 10:09:36.707144.707144 lmp.py:1626]   Expert 42 |    179 | CPU
DEBUG 01-15 10:09:36.707118.707118 lmp.py:1626]   Expert 18 |    191 | GPU
DEBUG 01-15 10:09:36.707807.707807 lmp.py:1626]   Expert 33 |    191 | GPU
DEBUG 01-15 10:09:36.707020.707020 lmp.py:1626]   Expert 32 |    199 | GPU
DEBUG 01-15 10:09:36.707232.707232 lmp.py:1626]   Expert 14 |    201 | GPU
DEBUG 01-15 10:09:36.707683.707683 lmp.py:1626]   Expert 30 |    201 | GPU
DEBUG 01-15 10:09:36.707372.707372 lmp.py:1626]   Expert  0 |    202 | GPU
DEBUG 01-15 10:09:36.707823.707823 lmp.py:1626]   Expert  5 |    202 | GPU
DEBUG 01-15 10:09:36.707466.707466 lmp.py:1626]   Expert 16 |    203 | GPU
DEBUG 01-15 10:09:36.707679.707679 lmp.py:1626]   Expert  7 |    208 | GPU
DEBUG 01-15 10:09:36.707129.707129 lmp.py:1626]   Expert 34 |    210 | GPU
DEBUG 01-15 10:09:36.708580.708580 lmp.py:1626]   Expert 31 |    211 | GPU
DEBUG 01-15 10:09:36.708554.708554 lmp.py:1626]   Expert 60 |    218 | GPU
DEBUG 01-15 10:09:36.708767.708767 lmp.py:1626]   Expert 62 |    220 | GPU
DEBUG 01-15 10:09:36.708741.708741 lmp.py:1626]   Expert 59 |    221 | GPU
DEBUG 01-15 10:09:36.708715.708715 lmp.py:1626]   Expert  9 |    222 | GPU
DEBUG 01-15 10:09:36.708689.708689 lmp.py:1626]   Expert 17 |    223 | GPU
DEBUG 01-15 10:09:36.708425.708425 lmp.py:1626]   Expert 10 |    224 | GPU
DEBUG 01-15 10:09:36.708637.708637 lmp.py:1626]   Expert 29 |    231 | GPU
DEBUG 01-15 10:09:36.708088.708088 lmp.py:1626]   Expert  4 |    235 | GPU
DEBUG 01-15 10:09:36.708539.708539 lmp.py:1626]   Expert 15 |    235 | GPU
DEBUG 01-15 10:09:36.708473.708473 lmp.py:1626]   Expert 58 |    238 | GPU
DEBUG 01-15 10:09:36.708355.708355 lmp.py:1626]   Expert 26 |    245 | GPU
DEBUG 01-15 10:09:36.708236.708236 lmp.py:1626]   Expert 51 |    254 | GPU
DEBUG 01-15 10:09:36.708925.708925 lmp.py:1626]   Expert 11 |    264 | GPU
DEBUG 01-15 10:09:36.708900.708900 lmp.py:1626]   Expert 44 |    267 | GPU
DEBUG 01-15 10:09:36.708112.708112 lmp.py:1626]   Expert 56 |    289 | GPU
DEBUG 01-15 10:09:36.708324.708324 lmp.py:1626]   Expert 27 |    291 | GPU
DEBUG 01-15 10:09:36.708537.708537 lmp.py:1626]   Expert  1 |    332 | GPU
DEBUG 01-15 10:09:36.708749.708749 lmp.py:1626]   Expert 45 |    368 | GPU
DEBUG 01-15 10:09:36.708962.708962 lmp.py:1626]   Expert 25 |    461 | GPU
DEBUG 01-15 10:09:36.708174.708174 lmp.py:1626]   Expert 35 |    521 | GPU
DEBUG 01-15 10:09:36.708387.708387 lmp.py:1626]   Expert 48 |    644 | GPU
DEBUG 01-15 10:09:36.708983.708983 lmp.py:1627] 
DEBUG 01-15 10:09:36.708983.708983 lmp.py:1627]   CPU total tokens: 3866 (31.5%)
DEBUG 01-15 10:09:36.708376.708376 lmp.py:1628]   GPU total tokens: 8422 (68.5%)
DEBUG 01-15 10:09:36.708125.708125 cuda_h.py:19] end experts_map_get cost 0.0021800994873046875 seconds
DEBUG 01-15 10:09:36.708532.708532 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.708718.708718 lmp.py:1636] 
DEBUG 01-15 10:09:36.708718.708718 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.708390.708390 cuda_h.py:19] end cpu_experts_submit cost 7.414817810058594e-05 seconds
DEBUG 01-15 10:09:36.708039.708039 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.708611.708611 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.709547.709547 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.709625.709625 cuda_h.py:19] end allocate_cuda_memory cost 0.0005052089691162109 seconds
DEBUG 01-15 10:09:36.709284.709284 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.709431.709431 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.709381.709381 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.709806.709806 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 935e5513-382c-48d6-afd2-021b68aafa40
DEBUG 01-15 10:09:36.710044.710044 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.711748.711748 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:36.711031.711031 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 935e5513-382c-48d6-afd2-021b68aafa40
DEBUG 01-15 10:09:36.711172.711172 cuda_h.py:19] end load_into_gpu_async cost 0.0019490718841552734 seconds
DEBUG 01-15 10:09:36.711875.711875 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.711232.711232 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.712129.712129 cuda_h.py:19] end restore_tensors2 cost 0.0008227825164794922 seconds
DEBUG 01-15 10:09:36.712985.712985 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038280487060546875 seconds
DEBUG 01-15 10:09:36.712206.712206 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.712305.712305 cuda_h.py:19] end move_flatidxs cost 0.0009369850158691406 seconds
DEBUG 01-15 10:09:36.712625.712625 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.715024.715024 cuda_h.py:19] end restore2model cost 0.0032329559326171875 seconds
DEBUG 01-15 10:09:36.716656.716656 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0073108673095703125 seconds
DEBUG 01-15 10:09:36.716644.716644 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.716929.716929 cuda_h.py:19] end gpu_sexperts cost 0.00038695335388183594 seconds
DEBUG 01-15 10:09:36.716050.716050 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.718438.718438 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002039194107055664 seconds
DEBUG 01-15 10:09:36.719391.719391 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.719847.719847 cuda_h.py:19] end gpu_group_list cost 0.0003230571746826172 seconds
DEBUG 01-15 10:09:36.720984.720984 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.721470.721470 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010170936584472656 seconds
DEBUG 01-15 10:09:36.721346.721346 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.721282.721282 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-15 10:09:36.721362.721362 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.723113.723113 cuda_h.py:19] end group_tensors cost 0.010357141494750977 seconds
DEBUG 01-15 10:09:36.723774.723774 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.727352.727352 cuda_h.py:19] end group pad cost 0.003954648971557617 seconds
DEBUG 01-15 10:09:36.727142.727142 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.748990.748990 cuda_h.py:19] end group_einsum cost 0.020895004272460938 seconds
DEBUG 01-15 10:09:36.749824.749824 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.754924.754924 cuda_h.py:19] end get_outputs_cpu1 cost 0.004919290542602539 seconds
DEBUG 01-15 10:09:36.754818.754818 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.043326616287231445 seconds
DEBUG 01-15 10:09:36.755229.755229 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.034361839294433594 seconds
DEBUG 01-15 10:09:36.755094.755094 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.756526.756526 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.756975.756975 cuda_h.py:19] end index_scatter cost 0.00010037422180175781 seconds
DEBUG 01-15 10:09:36.756931.756931 cuda_h.py:19] end cpuoutputsdeal cost 0.0008230209350585938 seconds
DEBUG 01-15 10:09:36.756045.756045 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.756093.756093 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 935e5513-382c-48d6-afd2-021b68aafa40
INFO 01-15 10:09:36.762944.762944 client.py:127] Model loaded
DEBUG 01-15 10:09:36.762018.762018 cuda_h.py:19] end wait_experts cost 0.0060939788818359375 seconds
DEBUG 01-15 10:09:36.762529.762529 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.762902.762902 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.762705.762705 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.763182.763182 cuda_h.py:19] end gpu_group_tensor cost 0.00018334388732910156 seconds
DEBUG 01-15 10:09:36.763517.763517 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.763861.763861 cuda_h.py:19] end gpu_group_einsum cost 0.000553131103515625 seconds
DEBUG 01-15 10:09:36.763302.763302 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.764562.764562 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.764009.764009 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002655982971191406 seconds
DEBUG 01-15 10:09:36.764580.764580 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.764484.764484 cuda_h.py:19] end concat_expert_out cost 6.031990051269531e-05 seconds
DEBUG 01-15 10:09:36.764566.764566 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.764516.764516 cuda_h.py:19] end index_scatter cost 6.270408630371094e-05 seconds
DEBUG 01-15 10:09:36.764610.764610 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006453990936279297 seconds
DEBUG 01-15 10:09:36.764235.764235 cuda_h.py:19] end gpu_experts cost 0.0018663406372070312 seconds
DEBUG 01-15 10:09:36.764496.764496 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06000638008117676 seconds
DEBUG 01-15 10:09:36.765559.765559 cuda_h.py:19] end prefill_layer cost 0.07261490821838379 seconds
DEBUG 01-15 10:09:36.765562.765562 lmp.py:1552] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-15 10:09:36.765927.765927 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.765769.765769 lmp.py:1495] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-15 10:09:36.765087.765087 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:36.765744.765744 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:36.765163.765163 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.814697265625e-05 seconds
DEBUG 01-15 10:09:36.765105.765105 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.866455078125e-05 seconds
DEBUG 01-15 10:09:36.765655.765655 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.765141.765141 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.765018.765018 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.765379.765379 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.765367.765367 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.766103.766103 cuda_h.py:19] end allocate_cuda_memory cost 0.00036334991455078125 seconds
DEBUG 01-15 10:09:36.766244.766244 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.766384.766384 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.766922.766922 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.766625.766625 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a457636c-a667-4612-94e2-7a9c9b43e7bb
DEBUG 01-15 10:09:36.766046.766046 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.766784.766784 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.767527.767527 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a457636c-a667-4612-94e2-7a9c9b43e7bb
DEBUG 01-15 10:09:36.767695.767695 cuda_h.py:19] end load_into_gpu_async cost 0.0009658336639404297 seconds
DEBUG 01-15 10:09:36.767490.767490 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.767978.767978 cuda_h.py:19] end restore_tensors2 cost 8.797645568847656e-05 seconds
DEBUG 01-15 10:09:36.767356.767356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016717910766601562 seconds
INFO 01-15 10:09:36.767398.767398 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a457636c-a667-4612-94e2-7a9c9b43e7bb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.770836.770836 cuda_h.py:19] end self_attn cost 0.003873109817504883 seconds
DEBUG 01-15 10:09:36.771013.771013 cuda_h.py:19] end iln_self_attn_paln cost 0.005537271499633789 seconds
DEBUG 01-15 10:09:36.771426.771426 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-15 10:09:36.771758.771758 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.771199.771199 cuda_h.py:19] end gate cost 0.0006780624389648438 seconds
DEBUG 01-15 10:09:36.772413.772413 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.772477.772477 lmp.py:1616] 
DEBUG 01-15 10:09:36.772477.772477 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.772584.772584 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.772334.772334 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.772122.772122 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.772765.772765 lmp.py:1620] 
DEBUG 01-15 10:09:36.772765.772765 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.772362.772362 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.772435.772435 lmp.py:1626]   Expert 44 |     29 | CPU
DEBUG 01-15 10:09:36.772840.772840 lmp.py:1626]   Expert  9 |     35 | CPU
DEBUG 01-15 10:09:36.772529.772529 lmp.py:1626]   Expert 11 |     36 | CPU
DEBUG 01-15 10:09:36.772219.772219 lmp.py:1626]   Expert 56 |     58 | CPU
DEBUG 01-15 10:09:36.772908.772908 lmp.py:1626]   Expert 54 |     80 | CPU
DEBUG 01-15 10:09:36.772120.772120 lmp.py:1626]   Expert  7 |     91 | CPU
DEBUG 01-15 10:09:36.772863.772863 lmp.py:1626]   Expert 62 |     92 | CPU
DEBUG 01-15 10:09:36.772221.772221 lmp.py:1626]   Expert 47 |     95 | CPU
DEBUG 01-15 10:09:36.772672.772672 lmp.py:1626]   Expert 51 |     99 | CPU
DEBUG 01-15 10:09:36.772838.772838 lmp.py:1626]   Expert 60 |    107 | CPU
DEBUG 01-15 10:09:36.772766.772766 lmp.py:1626]   Expert 22 |    109 | CPU
DEBUG 01-15 10:09:36.772693.772693 lmp.py:1626]   Expert 52 |    109 | CPU
DEBUG 01-15 10:09:36.772144.772144 lmp.py:1626]   Expert 41 |    111 | CPU
DEBUG 01-15 10:09:36.772118.772118 lmp.py:1626]   Expert 53 |    111 | CPU
DEBUG 01-15 10:09:36.772331.772331 lmp.py:1626]   Expert  1 |    127 | CPU
DEBUG 01-15 10:09:36.772543.772543 lmp.py:1626]   Expert 48 |    127 | CPU
DEBUG 01-15 10:09:36.772517.772517 lmp.py:1626]   Expert  6 |    128 | CPU
DEBUG 01-15 10:09:36.772730.772730 lmp.py:1626]   Expert  8 |    129 | CPU
DEBUG 01-15 10:09:36.772942.772942 lmp.py:1626]   Expert 32 |    130 | CPU
DEBUG 01-15 10:09:36.772208.772208 lmp.py:1626]   Expert  2 |    132 | CPU
DEBUG 01-15 10:09:36.772089.772089 lmp.py:1626]   Expert 35 |    134 | CPU
DEBUG 01-15 10:09:36.772255.772255 lmp.py:1626]   Expert 27 |    135 | CPU
DEBUG 01-15 10:09:36.772945.772945 lmp.py:1626]   Expert 59 |    140 | CPU
DEBUG 01-15 10:09:36.772872.772872 lmp.py:1626]   Expert 23 |    141 | CPU
DEBUG 01-15 10:09:36.772039.772039 lmp.py:1626]   Expert 26 |    147 | CPU
DEBUG 01-15 10:09:36.772489.772489 lmp.py:1626]   Expert 39 |    147 | CPU
DEBUG 01-15 10:09:36.772702.772702 lmp.py:1626]   Expert 50 |    150 | CPU
DEBUG 01-15 10:09:36.772676.772676 lmp.py:1626]   Expert 14 |    159 | CPU
DEBUG 01-15 10:09:36.772888.772888 lmp.py:1626]   Expert 46 |    168 | CPU
DEBUG 01-15 10:09:36.773101.773101 lmp.py:1626]   Expert 38 |    169 | CPU
DEBUG 01-15 10:09:36.773075.773075 lmp.py:1626]   Expert  0 |    171 | CPU
DEBUG 01-15 10:09:36.773287.773287 lmp.py:1626]   Expert 24 |    172 | CPU
DEBUG 01-15 10:09:36.773500.773500 lmp.py:1626]   Expert  4 |    173 | GPU
DEBUG 01-15 10:09:36.773050.773050 lmp.py:1626]   Expert 34 |    173 | GPU
DEBUG 01-15 10:09:36.773170.773170 lmp.py:1626]   Expert 49 |    175 | GPU
DEBUG 01-15 10:09:36.773005.773005 lmp.py:1626]   Expert 40 |    182 | GPU
DEBUG 01-15 10:09:36.773363.773363 lmp.py:1626]   Expert  5 |    186 | GPU
DEBUG 01-15 10:09:36.773006.773006 lmp.py:1626]   Expert 63 |    187 | GPU
DEBUG 01-15 10:09:36.773411.773411 lmp.py:1626]   Expert 19 |    193 | GPU
DEBUG 01-15 10:09:36.773577.773577 lmp.py:1626]   Expert 13 |    197 | GPU
DEBUG 01-15 10:09:36.773266.773266 lmp.py:1626]   Expert 43 |    201 | GPU
DEBUG 01-15 10:09:36.773956.773956 lmp.py:1626]   Expert 29 |    205 | GPU
DEBUG 01-15 10:09:36.773883.773883 lmp.py:1626]   Expert 57 |    208 | GPU
DEBUG 01-15 10:09:36.773334.773334 lmp.py:1626]   Expert 61 |    210 | GPU
DEBUG 01-15 10:09:36.773262.773262 lmp.py:1626]   Expert 31 |    223 | GPU
DEBUG 01-15 10:09:36.773097.773097 lmp.py:1626]   Expert 33 |    224 | GPU
DEBUG 01-15 10:09:36.773409.773409 lmp.py:1626]   Expert 16 |    249 | GPU
DEBUG 01-15 10:09:36.773813.773813 lmp.py:1626]   Expert 37 |    255 | GPU
DEBUG 01-15 10:09:36.773980.773980 lmp.py:1626]   Expert  3 |    256 | GPU
DEBUG 01-15 10:09:36.773384.773384 lmp.py:1626]   Expert 20 |    256 | GPU
DEBUG 01-15 10:09:36.773789.773789 lmp.py:1626]   Expert 15 |    257 | GPU
DEBUG 01-15 10:09:36.773478.773478 lmp.py:1626]   Expert 36 |    271 | GPU
DEBUG 01-15 10:09:36.773406.773406 lmp.py:1626]   Expert 18 |    277 | GPU
DEBUG 01-15 10:09:36.773095.773095 lmp.py:1626]   Expert 12 |    285 | GPU
DEBUG 01-15 10:09:36.773023.773023 lmp.py:1626]   Expert 28 |    302 | GPU
DEBUG 01-15 10:09:36.773474.773474 lmp.py:1626]   Expert 17 |    304 | GPU
DEBUG 01-15 10:09:36.773163.773163 lmp.py:1626]   Expert 55 |    307 | GPU
DEBUG 01-15 10:09:36.773091.773091 lmp.py:1626]   Expert 30 |    319 | GPU
DEBUG 01-15 10:09:36.773257.773257 lmp.py:1626]   Expert 25 |    323 | GPU
DEBUG 01-15 10:09:36.773615.773615 lmp.py:1626]   Expert 58 |    335 | GPU
DEBUG 01-15 10:09:36.773165.773165 lmp.py:1626]   Expert 10 |    361 | GPU
DEBUG 01-15 10:09:36.773570.773570 lmp.py:1626]   Expert 45 |    388 | GPU
DEBUG 01-15 10:09:36.773736.773736 lmp.py:1626]   Expert 21 |    393 | GPU
DEBUG 01-15 10:09:36.773141.773141 lmp.py:1626]   Expert 42 |    645 | GPU
DEBUG 01-15 10:09:36.773214.773214 lmp.py:1627] 
DEBUG 01-15 10:09:36.773214.773214 lmp.py:1627]   CPU total tokens: 3768 (30.7%)
DEBUG 01-15 10:09:36.773811.773811 lmp.py:1628]   GPU total tokens: 8520 (69.3%)
DEBUG 01-15 10:09:36.773222.773222 cuda_h.py:19] end experts_map_get cost 0.0015854835510253906 seconds
DEBUG 01-15 10:09:36.773648.773648 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.773927.773927 lmp.py:1636] 
DEBUG 01-15 10:09:36.773927.773927 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.773155.773155 cuda_h.py:19] end cpu_experts_submit cost 6.246566772460938e-05 seconds
DEBUG 01-15 10:09:36.773089.773089 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.773641.773641 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.774461.774461 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.774817.774817 cuda_h.py:19] end allocate_cuda_memory cost 0.00029540061950683594 seconds
DEBUG 01-15 10:09:36.774428.774428 cuda_h.py:10] start load_into_gpu_async
INFO 01-15 10:09:36.774854.774854 client.py:127] Model loaded
DEBUG 01-15 10:09:36.774181.774181 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.774013.774013 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.775870.775870 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.775731.775731 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1bec7391-6e47-4c6d-9432-86f9f2dff963
DEBUG 01-15 10:09:36.775897.775897 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.775925.775925 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.775716.775716 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.775845.775845 cuda_h.py:19] end restore2model cost 0.00077056884765625 seconds
DEBUG 01-15 10:09:36.775820.775820 cuda_h.py:19] end sllm_worker_task cost 0.01002359390258789 seconds
INFO 01-15 10:09:36.776970.776970 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1bec7391-6e47-4c6d-9432-86f9f2dff963
DEBUG 01-15 10:09:36.776926.776926 cuda_h.py:19] end load_into_gpu_async cost 0.0018832683563232422 seconds
DEBUG 01-15 10:09:36.776490.776490 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.776336.776336 cuda_h.py:19] end move_flatidxs cost 0.0008494853973388672 seconds
DEBUG 01-15 10:09:36.776019.776019 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.776889.776889 cuda_h.py:19] end restore_tensors2 cost 0.00040841102600097656 seconds
DEBUG 01-15 10:09:36.777586.777586 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030956268310546875 seconds
DEBUG 01-15 10:09:36.777256.777256 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.779724.779724 cuda_h.py:19] end restore2model cost 0.0028769969940185547 seconds
DEBUG 01-15 10:09:36.780343.780343 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00616765022277832 seconds
DEBUG 01-15 10:09:36.780244.780244 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.780741.780741 cuda_h.py:19] end gpu_sexperts cost 0.0003612041473388672 seconds
DEBUG 01-15 10:09:36.780584.780584 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.782565.782565 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001943349838256836 seconds
DEBUG 01-15 10:09:36.783995.783995 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.783349.783349 cuda_h.py:19] end gpu_group_list cost 0.00041365623474121094 seconds
DEBUG 01-15 10:09:36.784546.784546 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.785274.785274 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009446144104003906 seconds
DEBUG 01-15 10:09:36.785303.785303 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.785331.785331 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8835067749023438e-05 seconds
DEBUG 01-15 10:09:36.785418.785418 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.786078.786078 cuda_h.py:19] end group_tensors cost 0.01022028923034668 seconds
DEBUG 01-15 10:09:36.787776.787776 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.792008.792008 cuda_h.py:19] end group pad cost 0.0041162967681884766 seconds
DEBUG 01-15 10:09:36.792613.792613 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.810410.810410 cuda_h.py:19] end group_einsum cost 0.01876091957092285 seconds
DEBUG 01-15 10:09:36.811150.811150 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.815414.815414 cuda_h.py:19] end get_outputs_cpu1 cost 0.004657268524169922 seconds
DEBUG 01-15 10:09:36.816288.816288 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04108166694641113 seconds
DEBUG 01-15 10:09:36.818364.818364 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.032706499099731445 seconds
DEBUG 01-15 10:09:36.818291.818291 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.818008.818008 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.818666.818666 cuda_h.py:19] end index_scatter cost 0.0001685619354248047 seconds
DEBUG 01-15 10:09:36.819799.819799 cuda_h.py:19] end cpuoutputsdeal cost 0.00164794921875 seconds
DEBUG 01-15 10:09:36.820492.820492 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.820767.820767 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1bec7391-6e47-4c6d-9432-86f9f2dff963
INFO 01-15 10:09:36.827473.827473 client.py:127] Model loaded
DEBUG 01-15 10:09:36.827392.827392 cuda_h.py:19] end wait_experts cost 0.007208108901977539 seconds
DEBUG 01-15 10:09:36.827448.827448 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.827823.827823 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.827270.827270 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.828353.828353 cuda_h.py:19] end gpu_group_tensor cost 0.00043392181396484375 seconds
DEBUG 01-15 10:09:36.828581.828581 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.829790.829790 cuda_h.py:19] end gpu_group_einsum cost 0.0013637542724609375 seconds
DEBUG 01-15 10:09:36.830230.830230 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.830698.830698 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.831440.831440 cuda_h.py:19] end all_expert_outputs_slices cost 0.0010881423950195312 seconds
DEBUG 01-15 10:09:36.831131.831131 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.831411.831411 cuda_h.py:19] end concat_expert_out cost 0.00015687942504882812 seconds
DEBUG 01-15 10:09:36.832873.832873 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.832386.832386 cuda_h.py:19] end index_scatter cost 0.0001780986785888672 seconds
DEBUG 01-15 10:09:36.832310.832310 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0020906925201416016 seconds
DEBUG 01-15 10:09:36.832085.832085 cuda_h.py:19] end gpu_experts cost 0.005098104476928711 seconds
DEBUG 01-15 10:09:36.832999.832999 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06157684326171875 seconds
DEBUG 01-15 10:09:36.833463.833463 cuda_h.py:19] end prefill_layer cost 0.06818532943725586 seconds
DEBUG 01-15 10:09:36.833732.833732 lmp.py:1552] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-15 10:09:36.833735.833735 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.833744.833744 lmp.py:1495] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-15 10:09:36.834992.834992 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:36.834822.834822 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:36.834510.834510 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.818771362304688e-05 seconds
DEBUG 01-15 10:09:36.834998.834998 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.834413.834413 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.0003502368927001953 seconds
DEBUG 01-15 10:09:36.834095.834095 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.834245.834245 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.835350.835350 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.835448.835448 cuda_h.py:19] end allocate_cuda_memory cost 0.0003616809844970703 seconds
DEBUG 01-15 10:09:36.835186.835186 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.835379.835379 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.835988.835988 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.836356.836356 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.836203.836203 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 06a3f475-71d4-475e-a1ad-dc520c705177
DEBUG 01-15 10:09:36.836544.836544 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.837417.837417 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.837282.837282 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 06a3f475-71d4-475e-a1ad-dc520c705177
DEBUG 01-15 10:09:36.837789.837789 cuda_h.py:19] end load_into_gpu_async cost 0.001737833023071289 seconds
DEBUG 01-15 10:09:36.837975.837975 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.837052.837052 cuda_h.py:19] end restore_tensors2 cost 9.894371032714844e-05 seconds
DEBUG 01-15 10:09:36.837239.837239 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002669095993041992 seconds
INFO 01-15 10:09:36.837156.837156 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 06a3f475-71d4-475e-a1ad-dc520c705177
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.843767.843767 cuda_h.py:19] end self_attn cost 0.005930423736572266 seconds
DEBUG 01-15 10:09:36.843247.843247 cuda_h.py:19] end iln_self_attn_paln cost 0.00846719741821289 seconds
DEBUG 01-15 10:09:36.843269.843269 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-15 10:09:36.843198.843198 cuda_h.py:10] start gate
INFO 01-15 10:09:36.844102.844102 client.py:127] Model loaded
DEBUG 01-15 10:09:36.844026.844026 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.845693.845693 cuda_h.py:19] end restore2model cost 0.0006883144378662109 seconds
DEBUG 01-15 10:09:36.845781.845781 cuda_h.py:19] end sllm_worker_task cost 0.010436534881591797 seconds
DEBUG 01-15 10:09:36.845116.845116 cuda_h.py:19] end gate cost 0.0014226436614990234 seconds
DEBUG 01-15 10:09:36.845867.845867 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.846593.846593 lmp.py:1616] 
DEBUG 01-15 10:09:36.846593.846593 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.846038.846038 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.846947.846947 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.846087.846087 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.846413.846413 lmp.py:1620] 
DEBUG 01-15 10:09:36.846413.846413 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.846453.846453 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.846017.846017 lmp.py:1626]   Expert 25 |     14 | CPU
DEBUG 01-15 10:09:36.846866.846866 lmp.py:1626]   Expert 48 |     32 | CPU
DEBUG 01-15 10:09:36.846522.846522 lmp.py:1626]   Expert 45 |     36 | CPU
DEBUG 01-15 10:09:36.846941.846941 lmp.py:1626]   Expert  9 |     65 | CPU
DEBUG 01-15 10:09:36.846643.846643 lmp.py:1626]   Expert 43 |     83 | CPU
DEBUG 01-15 10:09:36.846585.846585 lmp.py:1626]   Expert  0 |     84 | CPU
DEBUG 01-15 10:09:36.846764.846764 lmp.py:1626]   Expert 54 |     84 | CPU
DEBUG 01-15 10:09:36.846944.846944 lmp.py:1626]   Expert 20 |     87 | CPU
DEBUG 01-15 10:09:36.846409.846409 lmp.py:1626]   Expert 47 |     87 | CPU
DEBUG 01-15 10:09:36.846019.846019 lmp.py:1626]   Expert 57 |     89 | CPU
DEBUG 01-15 10:09:36.846391.846391 lmp.py:1626]   Expert  6 |     94 | CPU
DEBUG 01-15 10:09:36.846524.846524 lmp.py:1626]   Expert 36 |     96 | CPU
DEBUG 01-15 10:09:36.846465.846465 lmp.py:1626]   Expert 62 |    102 | CPU
DEBUG 01-15 10:09:36.846930.846930 lmp.py:1626]   Expert 15 |    103 | CPU
DEBUG 01-15 10:09:36.846633.846633 lmp.py:1626]   Expert  1 |    104 | CPU
DEBUG 01-15 10:09:36.846097.846097 lmp.py:1626]   Expert 61 |    106 | CPU
DEBUG 01-15 10:09:36.846562.846562 lmp.py:1626]   Expert 13 |    107 | CPU
DEBUG 01-15 10:09:36.846218.846218 lmp.py:1626]   Expert 50 |    108 | CPU
DEBUG 01-15 10:09:36.846113.846113 lmp.py:1626]   Expert 38 |    113 | CPU
DEBUG 01-15 10:09:36.846008.846008 lmp.py:1626]   Expert 37 |    115 | CPU
DEBUG 01-15 10:09:36.846949.846949 lmp.py:1626]   Expert 46 |    121 | CPU
DEBUG 01-15 10:09:36.846891.846891 lmp.py:1626]   Expert 14 |    122 | CPU
DEBUG 01-15 10:09:36.846355.846355 lmp.py:1626]   Expert 28 |    135 | CPU
DEBUG 01-15 10:09:36.846058.846058 lmp.py:1626]   Expert 21 |    138 | CPU
DEBUG 01-15 10:09:36.846523.846523 lmp.py:1626]   Expert 52 |    139 | CPU
DEBUG 01-15 10:09:36.846894.846894 lmp.py:1626]   Expert  7 |    140 | CPU
DEBUG 01-15 10:09:36.846028.846028 lmp.py:1626]   Expert 44 |    143 | CPU
DEBUG 01-15 10:09:36.846400.846400 lmp.py:1626]   Expert 24 |    151 | CPU
DEBUG 01-15 10:09:36.847102.847102 lmp.py:1626]   Expert 10 |    153 | CPU
DEBUG 01-15 10:09:36.847328.847328 lmp.py:1626]   Expert 42 |    155 | CPU
DEBUG 01-15 10:09:36.847793.847793 lmp.py:1626]   Expert 11 |    158 | CPU
DEBUG 01-15 10:09:36.847257.847257 lmp.py:1626]   Expert  2 |    164 | CPU
DEBUG 01-15 10:09:36.847298.847298 lmp.py:1626]   Expert 35 |    169 | GPU
DEBUG 01-15 10:09:36.847193.847193 lmp.py:1626]   Expert 26 |    176 | GPU
DEBUG 01-15 10:09:36.847803.847803 lmp.py:1626]   Expert 31 |    177 | GPU
DEBUG 01-15 10:09:36.847506.847506 lmp.py:1626]   Expert  3 |    185 | GPU
DEBUG 01-15 10:09:36.847732.847732 lmp.py:1626]   Expert 19 |    186 | GPU
DEBUG 01-15 10:09:36.847674.847674 lmp.py:1626]   Expert 32 |    186 | GPU
DEBUG 01-15 10:09:36.847661.847661 lmp.py:1626]   Expert 12 |    191 | GPU
DEBUG 01-15 10:09:36.847126.847126 lmp.py:1626]   Expert 56 |    209 | GPU
DEBUG 01-15 10:09:36.847259.847259 lmp.py:1626]   Expert 40 |    213 | GPU
DEBUG 01-15 10:09:36.847154.847154 lmp.py:1626]   Expert 60 |    213 | GPU
DEBUG 01-15 10:09:36.847287.847287 lmp.py:1626]   Expert 41 |    217 | GPU
DEBUG 01-15 10:09:36.847182.847182 lmp.py:1626]   Expert  8 |    230 | GPU
DEBUG 01-15 10:09:36.847600.847600 lmp.py:1626]   Expert 53 |    230 | GPU
DEBUG 01-15 10:09:36.847065.847065 lmp.py:1626]   Expert 23 |    231 | GPU
DEBUG 01-15 10:09:36.847006.847006 lmp.py:1626]   Expert 16 |    232 | GPU
DEBUG 01-15 10:09:36.847948.847948 lmp.py:1626]   Expert 51 |    236 | GPU
DEBUG 01-15 10:09:36.847889.847889 lmp.py:1626]   Expert 58 |    237 | GPU
DEBUG 01-15 10:09:36.847545.847545 lmp.py:1626]   Expert 59 |    241 | GPU
DEBUG 01-15 10:09:36.847440.847440 lmp.py:1626]   Expert  4 |    252 | GPU
DEBUG 01-15 10:09:36.847097.847097 lmp.py:1626]   Expert 49 |    268 | GPU
DEBUG 01-15 10:09:36.847561.847561 lmp.py:1626]   Expert 55 |    270 | GPU
DEBUG 01-15 10:09:36.847264.847264 lmp.py:1626]   Expert 29 |    276 | GPU
DEBUG 01-15 10:09:36.847490.847490 lmp.py:1626]   Expert 18 |    282 | GPU
DEBUG 01-15 10:09:36.847716.847716 lmp.py:1626]   Expert 34 |    285 | GPU
DEBUG 01-15 10:09:36.847942.847942 lmp.py:1626]   Expert 63 |    295 | GPU
DEBUG 01-15 10:09:36.847168.847168 lmp.py:1626]   Expert 27 |    357 | GPU
DEBUG 01-15 10:09:36.847633.847633 lmp.py:1626]   Expert 39 |    379 | GPU
DEBUG 01-15 10:09:36.847289.847289 lmp.py:1626]   Expert 17 |    395 | GPU
DEBUG 01-15 10:09:36.847184.847184 lmp.py:1626]   Expert 22 |    427 | GPU
DEBUG 01-15 10:09:36.847556.847556 lmp.py:1626]   Expert 30 |    454 | GPU
DEBUG 01-15 10:09:36.847021.847021 lmp.py:1626]   Expert 33 |    454 | GPU
DEBUG 01-15 10:09:36.847247.847247 lmp.py:1626]   Expert  5 |    707 | GPU
DEBUG 01-15 10:09:36.847142.847142 lmp.py:1627] 
DEBUG 01-15 10:09:36.847142.847142 lmp.py:1627]   CPU total tokens: 3428 (27.9%)
DEBUG 01-15 10:09:36.848990.848990 lmp.py:1628]   GPU total tokens: 8860 (72.1%)
DEBUG 01-15 10:09:36.848515.848515 cuda_h.py:19] end experts_map_get cost 0.002680540084838867 seconds
DEBUG 01-15 10:09:36.848836.848836 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.848659.848659 lmp.py:1636] 
DEBUG 01-15 10:09:36.848659.848659 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.848098.848098 cuda_h.py:19] end cpu_experts_submit cost 7.700920104980469e-05 seconds
DEBUG 01-15 10:09:36.848431.848431 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.848666.848666 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.848609.848609 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.849588.849588 cuda_h.py:19] end allocate_cuda_memory cost 0.0003104209899902344 seconds
DEBUG 01-15 10:09:36.849817.849817 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.849387.849387 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.849687.849687 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.849748.849748 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5e029824-7071-40b5-9c65-3e0a9b2f62bf
DEBUG 01-15 10:09:36.849738.849738 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.850833.850833 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.850622.850622 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.851715.851715 cuda_h.py:19] end move_flatidxs cost 0.0009140968322753906 seconds
DEBUG 01-15 10:09:36.851896.851896 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:36.851646.851646 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5e029824-7071-40b5-9c65-3e0a9b2f62bf
DEBUG 01-15 10:09:36.851688.851688 cuda_h.py:19] end load_into_gpu_async cost 0.002256631851196289 seconds
DEBUG 01-15 10:09:36.851775.851775 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.851956.851956 cuda_h.py:19] end restore_tensors2 cost 0.0004222393035888672 seconds
DEBUG 01-15 10:09:36.851355.851355 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035245418548583984 seconds
DEBUG 01-15 10:09:36.852654.852654 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.855846.855846 cuda_h.py:19] end restore2model cost 0.0031287670135498047 seconds
DEBUG 01-15 10:09:36.855696.855696 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006900787353515625 seconds
DEBUG 01-15 10:09:36.855253.855253 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.855980.855980 cuda_h.py:19] end gpu_sexperts cost 0.0003147125244140625 seconds
DEBUG 01-15 10:09:36.855340.855340 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.857003.857003 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0019617080688476562 seconds
DEBUG 01-15 10:09:36.858347.858347 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.859724.859724 cuda_h.py:19] end gpu_group_list cost 0.00033402442932128906 seconds
DEBUG 01-15 10:09:36.859616.859616 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.860035.860035 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010039806365966797 seconds
DEBUG 01-15 10:09:36.860004.860004 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.860879.860879 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-15 10:09:36.860291.860291 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.862709.862709 cuda_h.py:19] end group_tensors cost 0.010808229446411133 seconds
DEBUG 01-15 10:09:36.862942.862942 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.866194.866194 cuda_h.py:19] end group pad cost 0.00392603874206543 seconds
DEBUG 01-15 10:09:36.867852.867852 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.886678.886678 cuda_h.py:19] end group_einsum cost 0.019052982330322266 seconds
DEBUG 01-15 10:09:36.886472.886472 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.890391.890391 cuda_h.py:19] end get_outputs_cpu1 cost 0.004431486129760742 seconds
DEBUG 01-15 10:09:36.891409.891409 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04144549369812012 seconds
DEBUG 01-15 10:09:36.892321.892321 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03209495544433594 seconds
DEBUG 01-15 10:09:36.892040.892040 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.892479.892479 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.893722.893722 cuda_h.py:19] end index_scatter cost 8.153915405273438e-05 seconds
DEBUG 01-15 10:09:36.893723.893723 cuda_h.py:19] end cpuoutputsdeal cost 0.0007798671722412109 seconds
DEBUG 01-15 10:09:36.893791.893791 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.893223.893223 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5e029824-7071-40b5-9c65-3e0a9b2f62bf
INFO 01-15 10:09:36.902214.902214 client.py:127] Model loaded
DEBUG 01-15 10:09:36.902110.902110 cuda_h.py:19] end wait_experts cost 0.00929713249206543 seconds
DEBUG 01-15 10:09:36.902144.902144 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.902556.902556 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.902451.902451 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.903484.903484 cuda_h.py:19] end gpu_group_tensor cost 0.0001728534698486328 seconds
DEBUG 01-15 10:09:36.903064.903064 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.903519.903519 cuda_h.py:19] end gpu_group_einsum cost 0.00046539306640625 seconds
DEBUG 01-15 10:09:36.903237.903237 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.903782.903782 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.904031.904031 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002944469451904297 seconds
DEBUG 01-15 10:09:36.904940.904940 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.904122.904122 cuda_h.py:19] end concat_expert_out cost 7.152557373046875e-05 seconds
DEBUG 01-15 10:09:36.904860.904860 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.904267.904267 cuda_h.py:19] end index_scatter cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:36.904659.904659 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006947517395019531 seconds
DEBUG 01-15 10:09:36.904629.904629 cuda_h.py:19] end gpu_experts cost 0.001810312271118164 seconds
DEBUG 01-15 10:09:36.904684.904684 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06100821495056152 seconds
DEBUG 01-15 10:09:36.905892.905892 cuda_h.py:19] end prefill_layer cost 0.07129192352294922 seconds
DEBUG 01-15 10:09:36.905344.905344 lmp.py:1552] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-15 10:09:36.905802.905802 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.905975.905975 lmp.py:1495] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-15 10:09:36.905055.905055 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:36.905520.905520 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:36.905647.905647 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.457069396972656e-05 seconds
DEBUG 01-15 10:09:36.905345.905345 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.905221.905221 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.0001404285430908203 seconds
DEBUG 01-15 10:09:36.905991.905991 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.905384.905384 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.905293.905293 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.906472.906472 cuda_h.py:19] end allocate_cuda_memory cost 0.0002932548522949219 seconds
DEBUG 01-15 10:09:36.906382.906382 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.906788.906788 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.906017.906017 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.906085.906085 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.906072.906072 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 867d2633-cfbe-4358-afe9-5f736f50fdfa
DEBUG 01-15 10:09:36.906472.906472 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.906144.906144 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.907080.907080 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 867d2633-cfbe-4358-afe9-5f736f50fdfa
DEBUG 01-15 10:09:36.907724.907724 cuda_h.py:19] end load_into_gpu_async cost 0.0011556148529052734 seconds
DEBUG 01-15 10:09:36.907851.907851 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.907040.907040 cuda_h.py:19] end restore_tensors2 cost 8.034706115722656e-05 seconds
DEBUG 01-15 10:09:36.907273.907273 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001979827880859375 seconds
INFO 01-15 10:09:36.907234.907234 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 867d2633-cfbe-4358-afe9-5f736f50fdfa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.910845.910845 cuda_h.py:19] end self_attn cost 0.0032656192779541016 seconds
DEBUG 01-15 10:09:36.910206.910206 cuda_h.py:19] end iln_self_attn_paln cost 0.0046613216400146484 seconds
DEBUG 01-15 10:09:36.910380.910380 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-15 10:09:36.910951.910951 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.911219.911219 cuda_h.py:19] end gate cost 0.0006566047668457031 seconds
DEBUG 01-15 10:09:36.911287.911287 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.911324.911324 lmp.py:1616] 
DEBUG 01-15 10:09:36.911324.911324 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:36.911603.911603 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.911253.911253 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.911518.911518 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.911684.911684 lmp.py:1620] 
DEBUG 01-15 10:09:36.911684.911684 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.911519.911519 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.911354.911354 lmp.py:1626]   Expert  5 |     13 | CPU
DEBUG 01-15 10:09:36.911521.911521 lmp.py:1626]   Expert 56 |     32 | CPU
DEBUG 01-15 10:09:36.911210.911210 lmp.py:1626]   Expert 16 |     81 | CPU
DEBUG 01-15 10:09:36.911138.911138 lmp.py:1626]   Expert 17 |     87 | CPU
DEBUG 01-15 10:09:36.911588.911588 lmp.py:1626]   Expert 27 |     89 | CPU
DEBUG 01-15 10:09:36.911039.911039 lmp.py:1626]   Expert 40 |     94 | CPU
DEBUG 01-15 10:09:36.911729.911729 lmp.py:1626]   Expert 63 |     99 | CPU
DEBUG 01-15 10:09:36.911418.911418 lmp.py:1626]   Expert 51 |    103 | CPU
DEBUG 01-15 10:09:36.911107.911107 lmp.py:1626]   Expert 49 |    104 | CPU
DEBUG 01-15 10:09:36.911081.911081 lmp.py:1626]   Expert 53 |    108 | CPU
DEBUG 01-15 10:09:36.911532.911532 lmp.py:1626]   Expert 28 |    109 | CPU
DEBUG 01-15 10:09:36.911222.911222 lmp.py:1626]   Expert  7 |    114 | CPU
DEBUG 01-15 10:09:36.911911.911911 lmp.py:1626]   Expert 47 |    123 | CPU
DEBUG 01-15 10:09:36.911123.911123 lmp.py:1626]   Expert 38 |    124 | CPU
DEBUG 01-15 10:09:36.911336.911336 lmp.py:1626]   Expert 62 |    125 | CPU
DEBUG 01-15 10:09:36.911263.911263 lmp.py:1626]   Expert 37 |    126 | CPU
DEBUG 01-15 10:09:36.911953.911953 lmp.py:1626]   Expert 11 |    128 | CPU
DEBUG 01-15 10:09:36.911165.911165 lmp.py:1626]   Expert 58 |    129 | CPU
DEBUG 01-15 10:09:36.912616.912616 lmp.py:1626]   Expert 57 |    137 | CPU
DEBUG 01-15 10:09:36.912067.912067 lmp.py:1626]   Expert  1 |    146 | CPU
DEBUG 01-15 10:09:36.912279.912279 lmp.py:1626]   Expert 14 |    146 | CPU
DEBUG 01-15 10:09:36.912492.912492 lmp.py:1626]   Expert 39 |    147 | CPU
DEBUG 01-15 10:09:36.912704.912704 lmp.py:1626]   Expert 52 |    152 | CPU
DEBUG 01-15 10:09:36.912917.912917 lmp.py:1626]   Expert 23 |    157 | CPU
DEBUG 01-15 10:09:36.912037.912037 lmp.py:1626]   Expert 25 |    158 | CPU
DEBUG 01-15 10:09:36.912872.912872 lmp.py:1626]   Expert 33 |    163 | CPU
DEBUG 01-15 10:09:36.912038.912038 lmp.py:1626]   Expert 21 |    166 | CPU
DEBUG 01-15 10:09:36.912204.912204 lmp.py:1626]   Expert  6 |    172 | CPU
DEBUG 01-15 10:09:36.912609.912609 lmp.py:1626]   Expert 60 |    173 | CPU
DEBUG 01-15 10:09:36.912536.912536 lmp.py:1626]   Expert 45 |    175 | CPU
DEBUG 01-15 10:09:36.912702.912702 lmp.py:1626]   Expert 19 |    180 | CPU
DEBUG 01-15 10:09:36.912630.912630 lmp.py:1626]   Expert 44 |    183 | CPU
DEBUG 01-15 10:09:36.912558.912558 lmp.py:1626]   Expert 12 |    186 | GPU
DEBUG 01-15 10:09:36.912486.912486 lmp.py:1626]   Expert  4 |    187 | GPU
DEBUG 01-15 10:09:36.912413.912413 lmp.py:1626]   Expert 30 |    195 | GPU
DEBUG 01-15 10:09:36.912341.912341 lmp.py:1626]   Expert  3 |    196 | GPU
DEBUG 01-15 10:09:36.912269.912269 lmp.py:1626]   Expert 31 |    196 | GPU
DEBUG 01-15 10:09:36.912435.912435 lmp.py:1626]   Expert 55 |    198 | GPU
DEBUG 01-15 10:09:36.912555.912555 lmp.py:1626]   Expert 36 |    200 | GPU
DEBUG 01-15 10:09:36.912198.912198 lmp.py:1626]   Expert  9 |    207 | GPU
DEBUG 01-15 10:09:36.912993.912993 lmp.py:1626]   Expert  0 |    217 | GPU
DEBUG 01-15 10:09:36.912543.912543 lmp.py:1626]   Expert 22 |    225 | GPU
DEBUG 01-15 10:09:36.912471.912471 lmp.py:1626]   Expert 34 |    225 | GPU
DEBUG 01-15 10:09:36.912637.912637 lmp.py:1626]   Expert 41 |    229 | GPU
DEBUG 01-15 10:09:36.912803.912803 lmp.py:1626]   Expert 54 |    233 | GPU
DEBUG 01-15 10:09:36.912731.912731 lmp.py:1626]   Expert 26 |    234 | GPU
DEBUG 01-15 10:09:36.912659.912659 lmp.py:1626]   Expert 43 |    240 | GPU
DEBUG 01-15 10:09:36.912587.912587 lmp.py:1626]   Expert 59 |    251 | GPU
DEBUG 01-15 10:09:36.912276.912276 lmp.py:1626]   Expert 13 |    254 | GPU
DEBUG 01-15 10:09:36.912442.912442 lmp.py:1626]   Expert 18 |    255 | GPU
DEBUG 01-15 10:09:36.912900.912900 lmp.py:1626]   Expert 20 |    255 | GPU
DEBUG 01-15 10:09:36.912112.912112 lmp.py:1626]   Expert 50 |    259 | GPU
DEBUG 01-15 10:09:36.912616.912616 lmp.py:1626]   Expert 15 |    260 | GPU
DEBUG 01-15 10:09:36.912067.912067 lmp.py:1626]   Expert 42 |    265 | GPU
DEBUG 01-15 10:09:36.912041.912041 lmp.py:1626]   Expert 24 |    266 | GPU
DEBUG 01-15 10:09:36.912254.912254 lmp.py:1626]   Expert 61 |    269 | GPU
DEBUG 01-15 10:09:36.912228.912228 lmp.py:1626]   Expert 29 |    270 | GPU
DEBUG 01-15 10:09:36.912202.912202 lmp.py:1626]   Expert 35 |    278 | GPU
DEBUG 01-15 10:09:36.912414.912414 lmp.py:1626]   Expert 32 |    304 | GPU
DEBUG 01-15 10:09:36.912627.912627 lmp.py:1626]   Expert  2 |    338 | GPU
DEBUG 01-15 10:09:36.912601.912601 lmp.py:1626]   Expert  8 |    340 | GPU
DEBUG 01-15 10:09:36.912052.912052 lmp.py:1626]   Expert 10 |    342 | GPU
DEBUG 01-15 10:09:36.912502.912502 lmp.py:1626]   Expert 46 |    426 | GPU
DEBUG 01-15 10:09:36.912238.912238 lmp.py:1626]   Expert 48 |    445 | GPU
DEBUG 01-15 10:09:36.912643.912643 lmp.py:1627] 
DEBUG 01-15 10:09:36.912643.912643 lmp.py:1627]   CPU total tokens: 4043 (32.9%)
DEBUG 01-15 10:09:36.912246.912246 lmp.py:1628]   GPU total tokens: 8245 (67.1%)
DEBUG 01-15 10:09:36.912942.912942 cuda_h.py:19] end experts_map_get cost 0.0015447139739990234 seconds
DEBUG 01-15 10:09:36.912838.912838 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.912972.912972 lmp.py:1636] 
DEBUG 01-15 10:09:36.912972.912972 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.912146.912146 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-15 10:09:36.913127.913127 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.913771.913771 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.913538.913538 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.913850.913850 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.914049.914049 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:36.914303.914303 cuda_h.py:19] end allocate_cuda_memory cost 0.001188516616821289 seconds
DEBUG 01-15 10:09:36.914199.914199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.914478.914478 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.914480.914480 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.914798.914798 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9190a3c0-1a06-4dbf-a59d-fff6a2efad77
DEBUG 01-15 10:09:36.915241.915241 cuda_h.py:19] end move_flatidxs cost 0.0009312629699707031 seconds
DEBUG 01-15 10:09:36.915971.915971 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.915424.915424 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:36.915390.915390 client.py:127] Model loaded
DEBUG 01-15 10:09:36.915233.915233 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.915570.915570 cuda_h.py:19] end restore2model cost 0.0005242824554443359 seconds
DEBUG 01-15 10:09:36.916168.916168 cuda_h.py:19] end sllm_worker_task cost 0.010428667068481445 seconds
INFO 01-15 10:09:36.916952.916952 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9190a3c0-1a06-4dbf-a59d-fff6a2efad77
DEBUG 01-15 10:09:36.916511.916511 cuda_h.py:19] end load_into_gpu_async cost 0.0013546943664550781 seconds
DEBUG 01-15 10:09:36.916545.916545 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.916302.916302 cuda_h.py:19] end restore_tensors2 cost 0.00042700767517089844 seconds
DEBUG 01-15 10:09:36.916284.916284 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036177635192871094 seconds
DEBUG 01-15 10:09:36.916000.916000 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.919932.919932 cuda_h.py:19] end restore2model cost 0.0026946067810058594 seconds
DEBUG 01-15 10:09:36.919358.919358 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006504535675048828 seconds
DEBUG 01-15 10:09:36.919200.919200 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.919721.919721 cuda_h.py:19] end gpu_sexperts cost 0.0002815723419189453 seconds
DEBUG 01-15 10:09:36.919504.919504 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:36.921902.921902 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001558065414428711 seconds
DEBUG 01-15 10:09:36.922082.922082 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:36.922022.922022 cuda_h.py:19] end gpu_group_list cost 0.0003256797790527344 seconds
DEBUG 01-15 10:09:36.922145.922145 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:36.923815.923815 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007696151733398438 seconds
DEBUG 01-15 10:09:36.923445.923445 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:36.923314.923314 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.621246337890625e-05 seconds
DEBUG 01-15 10:09:36.923772.923772 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:36.924690.924690 cuda_h.py:19] end group_tensors cost 0.009374618530273438 seconds
DEBUG 01-15 10:09:36.925941.925941 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:36.929074.929074 cuda_h.py:19] end group pad cost 0.0039081573486328125 seconds
DEBUG 01-15 10:09:36.929864.929864 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:36.948757.948757 cuda_h.py:19] end group_einsum cost 0.018694639205932617 seconds
DEBUG 01-15 10:09:36.948921.948921 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:36.953550.953550 cuda_h.py:19] end get_outputs_cpu1 cost 0.005061626434326172 seconds
DEBUG 01-15 10:09:36.954563.954563 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04020214080810547 seconds
DEBUG 01-15 10:09:36.955702.955702 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03184771537780762 seconds
DEBUG 01-15 10:09:36.955783.955783 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:36.956666.956666 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.956167.956167 cuda_h.py:19] end index_scatter cost 0.00019812583923339844 seconds
DEBUG 01-15 10:09:36.957021.957021 cuda_h.py:19] end cpuoutputsdeal cost 0.0014595985412597656 seconds
DEBUG 01-15 10:09:36.957886.957886 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:36.957015.957015 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9190a3c0-1a06-4dbf-a59d-fff6a2efad77
INFO 01-15 10:09:36.967438.967438 client.py:127] Model loaded
DEBUG 01-15 10:09:36.968770.968770 cuda_h.py:19] end wait_experts cost 0.010281801223754883 seconds
DEBUG 01-15 10:09:36.968310.968310 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:36.968190.968190 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:36.968008.968008 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:36.969307.969307 cuda_h.py:19] end gpu_group_tensor cost 0.0005164146423339844 seconds
DEBUG 01-15 10:09:36.969121.969121 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:36.971495.971495 cuda_h.py:19] end gpu_group_einsum cost 0.0017197132110595703 seconds
DEBUG 01-15 10:09:36.971499.971499 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:36.971518.971518 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:36.973337.973337 cuda_h.py:19] end all_expert_outputs_slices cost 0.001589059829711914 seconds
DEBUG 01-15 10:09:36.973131.973131 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:36.973533.973533 cuda_h.py:19] end concat_expert_out cost 0.00019502639770507812 seconds
DEBUG 01-15 10:09:36.974322.974322 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:36.974624.974624 cuda_h.py:19] end index_scatter cost 0.0001850128173828125 seconds
DEBUG 01-15 10:09:36.974106.974106 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.002957582473754883 seconds
DEBUG 01-15 10:09:36.974380.974380 cuda_h.py:19] end gpu_experts cost 0.006726741790771484 seconds
DEBUG 01-15 10:09:36.975012.975012 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06470203399658203 seconds
DEBUG 01-15 10:09:36.976921.976921 cuda_h.py:19] end prefill_layer cost 0.07113170623779297 seconds
DEBUG 01-15 10:09:36.976385.976385 lmp.py:1552] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-15 10:09:36.976064.976064 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:36.976505.976505 lmp.py:1495] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-15 10:09:36.977561.977561 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:36.977340.977340 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:36.977771.977771 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 8.893013000488281e-05 seconds
DEBUG 01-15 10:09:36.977889.977889 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:36.977285.977285 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.0003993511199951172 seconds
DEBUG 01-15 10:09:36.977516.977516 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.978879.978879 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:36.978937.978937 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.978016.978016 cuda_h.py:19] end allocate_cuda_memory cost 0.0003581047058105469 seconds
DEBUG 01-15 10:09:36.978562.978562 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.978801.978801 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.979325.979325 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:36.979187.979187 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.979008.979008 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2bfed07e-eada-4611-bcc6-049a611b5025
DEBUG 01-15 10:09:36.979482.979482 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.980680.980680 cuda_h.py:10] start self_attn
INFO 01-15 10:09:36.980376.980376 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2bfed07e-eada-4611-bcc6-049a611b5025
DEBUG 01-15 10:09:36.981512.981512 cuda_h.py:19] end load_into_gpu_async cost 0.002239227294921875 seconds
DEBUG 01-15 10:09:36.981229.981229 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.981366.981366 cuda_h.py:19] end restore_tensors2 cost 0.00011181831359863281 seconds
DEBUG 01-15 10:09:36.981698.981698 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031995773315429688 seconds
INFO 01-15 10:09:36.981510.981510 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2bfed07e-eada-4611-bcc6-049a611b5025
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:36.986153.986153 cuda_h.py:19] end self_attn cost 0.0054552555084228516 seconds
DEBUG 01-15 10:09:36.986666.986666 cuda_h.py:19] end iln_self_attn_paln cost 0.00856328010559082 seconds
DEBUG 01-15 10:09:36.986067.986067 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-15 10:09:36.987533.987533 cuda_h.py:10] start gate
DEBUG 01-15 10:09:36.988952.988952 cuda_h.py:19] end gate cost 0.0009853839874267578 seconds
DEBUG 01-15 10:09:36.988160.988160 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:36.988809.988809 lmp.py:1616] 
DEBUG 01-15 10:09:36.988809.988809 lmp.py:1616] Expert Token Distribution & Device Allocation:
INFO 01-15 10:09:36.988846.988846 client.py:127] Model loaded
DEBUG 01-15 10:09:36.989102.989102 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:36.989728.989728 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.989161.989161 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:36.989881.989881 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:36.989532.989532 lmp.py:1620] 
DEBUG 01-15 10:09:36.989532.989532 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:36.989023.989023 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:36.989779.989779 lmp.py:1626]   Expert 36 |     19 | CPU
DEBUG 01-15 10:09:36.990825.990825 lmp.py:1626]   Expert 35 |     32 | CPU
DEBUG 01-15 10:09:36.990634.990634 lmp.py:1626]   Expert 25 |     45 | CPU
DEBUG 01-15 10:09:36.990191.990191 lmp.py:1626]   Expert 46 |     49 | CPU
DEBUG 01-15 10:09:36.990987.990987 lmp.py:1626]   Expert 51 |     51 | CPU
DEBUG 01-15 10:09:36.990305.990305 lmp.py:1626]   Expert 16 |     61 | CPU
DEBUG 01-15 10:09:36.990386.990386 lmp.py:1626]   Expert  0 |     64 | CPU
DEBUG 01-15 10:09:36.990943.990943 lmp.py:1626]   Expert 30 |     65 | CPU
DEBUG 01-15 10:09:36.990023.990023 lmp.py:1626]   Expert 47 |     68 | CPU
DEBUG 01-15 10:09:36.990103.990103 lmp.py:1626]   Expert 43 |     70 | CPU
DEBUG 01-15 10:09:36.990422.990422 lmp.py:1626]   Expert 44 |     73 | CPU
DEBUG 01-15 10:09:36.990264.990264 lmp.py:1626]   Expert 39 |     75 | CPU
DEBUG 01-15 10:09:36.990583.990583 lmp.py:1626]   Expert 42 |     76 | CPU
DEBUG 01-15 10:09:36.990617.990617 lmp.py:1626]   Expert 55 |     77 | CPU
DEBUG 01-15 10:09:36.990650.990650 lmp.py:1626]   Expert  2 |     82 | CPU
DEBUG 01-15 10:09:36.990684.990684 lmp.py:1626]   Expert  4 |    110 | CPU
DEBUG 01-15 10:09:36.990003.990003 lmp.py:1626]   Expert 48 |    117 | CPU
DEBUG 01-15 10:09:36.990322.990322 lmp.py:1626]   Expert 33 |    120 | CPU
DEBUG 01-15 10:09:36.990164.990164 lmp.py:1626]   Expert  6 |    125 | CPU
DEBUG 01-15 10:09:36.990006.990006 lmp.py:1626]   Expert 13 |    125 | CPU
DEBUG 01-15 10:09:36.990847.990847 lmp.py:1626]   Expert 24 |    126 | CPU
DEBUG 01-15 10:09:36.990451.990451 lmp.py:1626]   Expert 61 |    126 | CPU
DEBUG 01-15 10:09:36.990054.990054 lmp.py:1626]   Expert 29 |    129 | CPU
DEBUG 01-15 10:09:36.990896.990896 lmp.py:1626]   Expert 56 |    131 | CPU
DEBUG 01-15 10:09:36.990692.990692 lmp.py:1626]   Expert 15 |    132 | CPU
DEBUG 01-15 10:09:36.990249.990249 lmp.py:1626]   Expert 54 |    143 | CPU
DEBUG 01-15 10:09:36.990521.990521 lmp.py:1626]   Expert  7 |    144 | CPU
DEBUG 01-15 10:09:36.990363.990363 lmp.py:1626]   Expert  9 |    145 | CPU
DEBUG 01-15 10:09:36.990205.990205 lmp.py:1626]   Expert 38 |    145 | CPU
DEBUG 01-15 10:09:36.990047.990047 lmp.py:1626]   Expert 20 |    146 | CPU
DEBUG 01-15 10:09:36.990796.990796 lmp.py:1626]   Expert 59 |    152 | CPU
DEBUG 01-15 10:09:36.990161.990161 lmp.py:1626]   Expert 62 |    157 | CPU
DEBUG 01-15 10:09:36.990526.990526 lmp.py:1626]   Expert 45 |    160 | GPU
DEBUG 01-15 10:09:36.990129.990129 lmp.py:1626]   Expert 19 |    162 | GPU
DEBUG 01-15 10:09:36.990448.990448 lmp.py:1626]   Expert 34 |    185 | GPU
DEBUG 01-15 10:09:36.990244.990244 lmp.py:1626]   Expert 50 |    193 | GPU
DEBUG 01-15 10:09:36.990085.990085 lmp.py:1626]   Expert 57 |    193 | GPU
DEBUG 01-15 10:09:36.990166.990166 lmp.py:1626]   Expert 10 |    203 | GPU
DEBUG 01-15 10:09:36.990246.990246 lmp.py:1626]   Expert 31 |    204 | GPU
DEBUG 01-15 10:09:36.990326.990326 lmp.py:1626]   Expert  8 |    209 | GPU
DEBUG 01-15 10:09:36.990691.990691 lmp.py:1626]   Expert 23 |    209 | GPU
DEBUG 01-15 10:09:36.991295.991295 lmp.py:1626]   Expert 60 |    213 | GPU
DEBUG 01-15 10:09:36.991137.991137 lmp.py:1626]   Expert 18 |    217 | GPU
DEBUG 01-15 10:09:36.991455.991455 lmp.py:1626]   Expert 53 |    218 | GPU
DEBUG 01-15 10:09:36.991498.991498 lmp.py:1626]   Expert 22 |    222 | GPU
DEBUG 01-15 10:09:36.991009.991009 lmp.py:1626]   Expert 52 |    227 | GPU
DEBUG 01-15 10:09:36.991083.991083 lmp.py:1626]   Expert 37 |    230 | GPU
DEBUG 01-15 10:09:36.991964.991964 lmp.py:1626]   Expert  5 |    239 | GPU
DEBUG 01-15 10:09:36.991846.991846 lmp.py:1626]   Expert 17 |    244 | GPU
DEBUG 01-15 10:09:36.991157.991157 lmp.py:1626]   Expert 11 |    255 | GPU
DEBUG 01-15 10:09:36.991469.991469 lmp.py:1626]   Expert  1 |    269 | GPU
DEBUG 01-15 10:09:36.991020.991020 lmp.py:1626]   Expert 49 |    276 | GPU
DEBUG 01-15 10:09:36.991808.991808 lmp.py:1626]   Expert 41 |    279 | GPU
DEBUG 01-15 10:09:36.991882.991882 lmp.py:1626]   Expert 28 |    284 | GPU
DEBUG 01-15 10:09:36.991240.991240 lmp.py:1626]   Expert 26 |    290 | GPU
DEBUG 01-15 10:09:36.991075.991075 lmp.py:1626]   Expert 32 |    294 | GPU
DEBUG 01-15 10:09:36.991195.991195 lmp.py:1626]   Expert 58 |    298 | GPU
DEBUG 01-15 10:09:36.991315.991315 lmp.py:1626]   Expert 40 |    303 | GPU
DEBUG 01-15 10:09:36.991673.991673 lmp.py:1626]   Expert 14 |    308 | GPU
DEBUG 01-15 10:09:36.991793.991793 lmp.py:1626]   Expert 12 |    327 | GPU
DEBUG 01-15 10:09:36.991913.991913 lmp.py:1626]   Expert 63 |    335 | GPU
DEBUG 01-15 10:09:36.991033.991033 lmp.py:1626]   Expert 21 |    380 | GPU
DEBUG 01-15 10:09:36.991344.991344 lmp.py:1626]   Expert 27 |    667 | GPU
DEBUG 01-15 10:09:36.991418.991418 lmp.py:1626]   Expert  3 |   1015 | GPU
DEBUG 01-15 10:09:36.991922.991922 lmp.py:1627] 
DEBUG 01-15 10:09:36.991922.991922 lmp.py:1627]   CPU total tokens: 3180 (25.9%)
DEBUG 01-15 10:09:36.991187.991187 lmp.py:1628]   GPU total tokens: 9108 (74.1%)
DEBUG 01-15 10:09:36.991082.991082 cuda_h.py:19] end experts_map_get cost 0.0033686161041259766 seconds
DEBUG 01-15 10:09:36.991969.991969 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:36.991990.991990 lmp.py:1636] 
DEBUG 01-15 10:09:36.991990.991990 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:36.991178.991178 cuda_h.py:19] end cpu_experts_submit cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:36.991351.991351 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:36.991201.991201 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:36.992050.992050 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:36.992134.992134 cuda_h.py:19] end allocate_cuda_memory cost 0.0003008842468261719 seconds
DEBUG 01-15 10:09:36.992389.992389 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:36.992436.992436 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:36.992166.992166 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:36.992061.992061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97151988-b67c-48c7-9b16-c4a113aa0ac8
DEBUG 01-15 10:09:36.992931.992931 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:36.993181.993181 cuda_h.py:19] end restore2model cost 0.004426240921020508 seconds
DEBUG 01-15 10:09:36.993953.993953 cuda_h.py:19] end sllm_worker_task cost 0.01603841781616211 seconds
DEBUG 01-15 10:09:36.993850.993850 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:36.994402.994402 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:36.994925.994925 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97151988-b67c-48c7-9b16-c4a113aa0ac8
DEBUG 01-15 10:09:36.995630.995630 cuda_h.py:19] end load_into_gpu_async cost 0.002421140670776367 seconds
DEBUG 01-15 10:09:36.995008.995008 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:36.995338.995338 cuda_h.py:19] end move_flatidxs cost 0.0009565353393554688 seconds
DEBUG 01-15 10:09:36.995777.995777 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:36.995361.995361 cuda_h.py:19] end restore_tensors2 cost 0.0004096031188964844 seconds
DEBUG 01-15 10:09:36.995389.995389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003624439239501953 seconds
DEBUG 01-15 10:09:36.995371.995371 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:36.998169.998169 cuda_h.py:19] end restore2model cost 0.0028383731842041016 seconds
DEBUG 01-15 10:09:36.998477.998477 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00670313835144043 seconds
DEBUG 01-15 10:09:36.998511.998511 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:36.998820.998820 cuda_h.py:19] end gpu_sexperts cost 0.0003008842468261719 seconds
DEBUG 01-15 10:09:36.999656.999656 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:37.000460.000460 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016090869903564453 seconds
DEBUG 01-15 10:09:37.001730.001730 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:37.001922.001922 cuda_h.py:19] end gpu_group_list cost 0.0003361701965332031 seconds
DEBUG 01-15 10:09:37.001370.001370 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:37.002845.002845 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006957054138183594 seconds
DEBUG 01-15 10:09:37.002475.002475 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:37.002682.002682 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-15 10:09:37.002140.002140 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:37.007116.007116 cuda_h.py:19] end group_tensors cost 0.0116424560546875 seconds
DEBUG 01-15 10:09:37.007878.007878 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:37.011300.011300 cuda_h.py:19] end group pad cost 0.003835439682006836 seconds
DEBUG 01-15 10:09:37.011527.011527 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:37.032437.032437 cuda_h.py:19] end group_einsum cost 0.02094411849975586 seconds
DEBUG 01-15 10:09:37.032316.032316 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:37.037778.037778 cuda_h.py:19] end get_outputs_cpu1 cost 0.004416942596435547 seconds
DEBUG 01-15 10:09:37.038312.038312 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04415488243103027 seconds
DEBUG 01-15 10:09:37.039351.039351 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03629493713378906 seconds
DEBUG 01-15 10:09:37.039129.039129 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:37.039071.039071 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.039308.039308 cuda_h.py:19] end index_scatter cost 8.082389831542969e-05 seconds
DEBUG 01-15 10:09:37.040131.040131 cuda_h.py:19] end cpuoutputsdeal cost 0.0008068084716796875 seconds
DEBUG 01-15 10:09:37.040669.040669 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:37.040677.040677 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97151988-b67c-48c7-9b16-c4a113aa0ac8
INFO 01-15 10:09:37.046503.046503 client.py:127] Model loaded
DEBUG 01-15 10:09:37.046247.046247 cuda_h.py:19] end wait_experts cost 0.0059397220611572266 seconds
DEBUG 01-15 10:09:37.046565.046565 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:37.046170.046170 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:37.046780.046780 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:37.046913.046913 cuda_h.py:19] end gpu_group_tensor cost 0.00017452239990234375 seconds
DEBUG 01-15 10:09:37.046386.046386 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:37.047235.047235 cuda_h.py:19] end gpu_group_einsum cost 0.0005807876586914062 seconds
DEBUG 01-15 10:09:37.047498.047498 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:37.047625.047625 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:37.047880.047880 cuda_h.py:19] end all_expert_outputs_slices cost 0.00025916099548339844 seconds
DEBUG 01-15 10:09:37.047213.047213 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:37.047865.047865 cuda_h.py:19] end concat_expert_out cost 6.127357482910156e-05 seconds
DEBUG 01-15 10:09:37.047768.047768 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.047923.047923 cuda_h.py:19] end index_scatter cost 4.8160552978515625e-05 seconds
DEBUG 01-15 10:09:37.047679.047679 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006158351898193359 seconds
DEBUG 01-15 10:09:37.048535.048535 cuda_h.py:19] end gpu_experts cost 0.001851797103881836 seconds
DEBUG 01-15 10:09:37.048544.048544 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06107974052429199 seconds
DEBUG 01-15 10:09:37.048421.048421 cuda_h.py:19] end prefill_layer cost 0.07168698310852051 seconds
DEBUG 01-15 10:09:37.048873.048873 lmp.py:1552] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-15 10:09:37.048099.048099 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:37.048941.048941 lmp.py:1495] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-15 10:09:37.048975.048975 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:37.048916.048916 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:37.048991.048991 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.0994415283203125e-05 seconds
DEBUG 01-15 10:09:37.048740.048740 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:37.048767.048767 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:37.048254.048254 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:37.049867.049867 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:37.049975.049975 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:37.049827.049827 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:37.049699.049699 cuda_h.py:19] end allocate_cuda_memory cost 0.0002849102020263672 seconds
DEBUG 01-15 10:09:37.049245.049245 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:37.049869.049869 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:37.049122.049122 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:37.049110.049110 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d461c2a-a559-4f0c-9ec5-097d762521b0
DEBUG 01-15 10:09:37.049841.049841 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:37.050995.050995 cuda_h.py:10] start self_attn
INFO 01-15 10:09:37.050744.050744 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d461c2a-a559-4f0c-9ec5-097d762521b0
DEBUG 01-15 10:09:37.050958.050958 cuda_h.py:19] end load_into_gpu_async cost 0.0008721351623535156 seconds
DEBUG 01-15 10:09:37.050515.050515 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:37.050942.050942 cuda_h.py:19] end restore_tensors2 cost 7.82012939453125e-05 seconds
DEBUG 01-15 10:09:37.050744.050744 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015125274658203125 seconds
INFO 01-15 10:09:37.050111.050111 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d461c2a-a559-4f0c-9ec5-097d762521b0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:37.054515.054515 cuda_h.py:19] end self_attn cost 0.004781246185302734 seconds
DEBUG 01-15 10:09:37.055923.055923 cuda_h.py:19] end iln_self_attn_paln cost 0.006406307220458984 seconds
DEBUG 01-15 10:09:37.055528.055528 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-15 10:09:37.055622.055622 cuda_h.py:10] start gate
DEBUG 01-15 10:09:37.056096.056096 cuda_h.py:19] end gate cost 0.0006670951843261719 seconds
DEBUG 01-15 10:09:37.056448.056448 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:37.056368.056368 lmp.py:1616] 
DEBUG 01-15 10:09:37.056368.056368 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:37.056607.056607 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:37.056926.056926 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:37.056192.056192 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:37.056550.056550 lmp.py:1620] 
DEBUG 01-15 10:09:37.056550.056550 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:37.056623.056623 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:37.056650.056650 lmp.py:1626]   Expert 13 |     25 | CPU
DEBUG 01-15 10:09:37.056247.056247 lmp.py:1626]   Expert 44 |     40 | CPU
DEBUG 01-15 10:09:37.056082.056082 lmp.py:1626]   Expert 25 |     41 | CPU
DEBUG 01-15 10:09:37.056202.056202 lmp.py:1626]   Expert  9 |     42 | CPU
DEBUG 01-15 10:09:37.056607.056607 lmp.py:1626]   Expert 38 |     46 | CPU
DEBUG 01-15 10:09:37.056250.056250 lmp.py:1626]   Expert 16 |     47 | CPU
DEBUG 01-15 10:09:37.056654.056654 lmp.py:1626]   Expert  2 |     54 | CPU
DEBUG 01-15 10:09:37.056820.056820 lmp.py:1626]   Expert 33 |     55 | CPU
DEBUG 01-15 10:09:37.056986.056986 lmp.py:1626]   Expert 22 |     56 | CPU
DEBUG 01-15 10:09:37.056152.056152 lmp.py:1626]   Expert 42 |     60 | CPU
DEBUG 01-15 10:09:37.056319.056319 lmp.py:1626]   Expert  5 |     66 | CPU
DEBUG 01-15 10:09:37.056723.056723 lmp.py:1626]   Expert 23 |     75 | CPU
DEBUG 01-15 10:09:37.056889.056889 lmp.py:1626]   Expert 10 |     79 | CPU
DEBUG 01-15 10:09:37.056055.056055 lmp.py:1626]   Expert 24 |     79 | CPU
DEBUG 01-15 10:09:37.056983.056983 lmp.py:1626]   Expert 59 |    102 | CPU
DEBUG 01-15 10:09:37.056672.056672 lmp.py:1626]   Expert 21 |    104 | CPU
DEBUG 01-15 10:09:37.056839.056839 lmp.py:1626]   Expert 46 |    112 | CPU
DEBUG 01-15 10:09:37.056766.056766 lmp.py:1626]   Expert 45 |    116 | CPU
DEBUG 01-15 10:09:37.056932.056932 lmp.py:1626]   Expert 55 |    118 | CPU
DEBUG 01-15 10:09:37.056099.056099 lmp.py:1626]   Expert 61 |    121 | CPU
DEBUG 01-15 10:09:37.056742.056742 lmp.py:1626]   Expert 31 |    131 | CPU
DEBUG 01-15 10:09:37.056908.056908 lmp.py:1626]   Expert 51 |    140 | CPU
DEBUG 01-15 10:09:37.057551.057551 lmp.py:1626]   Expert  6 |    141 | CPU
DEBUG 01-15 10:09:37.057717.057717 lmp.py:1626]   Expert 36 |    142 | CPU
DEBUG 01-15 10:09:37.057883.057883 lmp.py:1626]   Expert  8 |    144 | CPU
DEBUG 01-15 10:09:37.057811.057811 lmp.py:1626]   Expert 43 |    149 | CPU
DEBUG 01-15 10:09:37.057738.057738 lmp.py:1626]   Expert  3 |    151 | CPU
DEBUG 01-15 10:09:37.057666.057666 lmp.py:1626]   Expert  0 |    153 | CPU
DEBUG 01-15 10:09:37.057832.057832 lmp.py:1626]   Expert 26 |    158 | CPU
DEBUG 01-15 10:09:37.057760.057760 lmp.py:1626]   Expert 48 |    158 | CPU
DEBUG 01-15 10:09:37.057211.057211 lmp.py:1626]   Expert 18 |    161 | CPU
DEBUG 01-15 10:09:37.057139.057139 lmp.py:1626]   Expert 41 |    165 | CPU
DEBUG 01-15 10:09:37.057735.057735 lmp.py:1626]   Expert 12 |    174 | GPU
DEBUG 01-15 10:09:37.057378.057378 lmp.py:1626]   Expert 20 |    177 | GPU
DEBUG 01-15 10:09:37.057021.057021 lmp.py:1626]   Expert  7 |    181 | GPU
DEBUG 01-15 10:09:37.057426.057426 lmp.py:1626]   Expert 28 |    186 | GPU
DEBUG 01-15 10:09:37.057353.057353 lmp.py:1626]   Expert 56 |    188 | GPU
DEBUG 01-15 10:09:37.057520.057520 lmp.py:1626]   Expert  1 |    192 | GPU
DEBUG 01-15 10:09:37.057209.057209 lmp.py:1626]   Expert 27 |    194 | GPU
DEBUG 01-15 10:09:37.057137.057137 lmp.py:1626]   Expert 34 |    199 | GPU
DEBUG 01-15 10:09:37.057303.057303 lmp.py:1626]   Expert 47 |    204 | GPU
DEBUG 01-15 10:09:37.057992.057992 lmp.py:1626]   Expert 32 |    216 | GPU
DEBUG 01-15 10:09:37.057681.057681 lmp.py:1626]   Expert 11 |    217 | GPU
DEBUG 01-15 10:09:37.057371.057371 lmp.py:1626]   Expert 40 |    226 | GPU
DEBUG 01-15 10:09:37.057014.057014 lmp.py:1626]   Expert 49 |    234 | GPU
DEBUG 01-15 10:09:37.057418.057418 lmp.py:1626]   Expert 53 |    236 | GPU
DEBUG 01-15 10:09:37.057823.057823 lmp.py:1626]   Expert 63 |    240 | GPU
DEBUG 01-15 10:09:37.057466.057466 lmp.py:1626]   Expert 15 |    245 | GPU
DEBUG 01-15 10:09:37.057109.057109 lmp.py:1626]   Expert 29 |    246 | GPU
DEBUG 01-15 10:09:37.057036.057036 lmp.py:1626]   Expert  4 |    247 | GPU
DEBUG 01-15 10:09:37.057726.057726 lmp.py:1626]   Expert 50 |    247 | GPU
DEBUG 01-15 10:09:37.057177.057177 lmp.py:1626]   Expert 30 |    249 | GPU
DEBUG 01-15 10:09:37.057104.057104 lmp.py:1626]   Expert 35 |    269 | GPU
DEBUG 01-15 10:09:37.057794.057794 lmp.py:1626]   Expert 14 |    274 | GPU
DEBUG 01-15 10:09:37.057721.057721 lmp.py:1626]   Expert 37 |    302 | GPU
DEBUG 01-15 10:09:37.057411.057411 lmp.py:1626]   Expert 52 |    338 | GPU
DEBUG 01-15 10:09:37.057338.057338 lmp.py:1626]   Expert 17 |    363 | GPU
DEBUG 01-15 10:09:37.057789.057789 lmp.py:1626]   Expert 54 |    379 | GPU
DEBUG 01-15 10:09:37.057479.057479 lmp.py:1626]   Expert 39 |    389 | GPU
DEBUG 01-15 10:09:37.057406.057406 lmp.py:1626]   Expert 57 |    415 | GPU
DEBUG 01-15 10:09:37.057811.057811 lmp.py:1626]   Expert 62 |    457 | GPU
DEBUG 01-15 10:09:37.057215.057215 lmp.py:1626]   Expert 60 |    458 | GPU
DEBUG 01-15 10:09:37.057620.057620 lmp.py:1626]   Expert 19 |    544 | GPU
DEBUG 01-15 10:09:37.057024.057024 lmp.py:1626]   Expert 58 |    571 | GPU
DEBUG 01-15 10:09:37.057144.057144 lmp.py:1627] 
DEBUG 01-15 10:09:37.057144.057144 lmp.py:1627]   CPU total tokens: 3231 (26.3%)
DEBUG 01-15 10:09:37.057026.057026 lmp.py:1628]   GPU total tokens: 9057 (73.7%)
DEBUG 01-15 10:09:37.057960.057960 cuda_h.py:19] end experts_map_get cost 0.001613616943359375 seconds
DEBUG 01-15 10:09:37.057525.057525 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:37.057851.057851 lmp.py:1636] 
DEBUG 01-15 10:09:37.057851.057851 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:37.057979.057979 cuda_h.py:19] end cpu_experts_submit cost 5.817413330078125e-05 seconds
DEBUG 01-15 10:09:37.057244.057244 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:37.057273.057273 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:37.058133.058133 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:37.058771.058771 cuda_h.py:19] end allocate_cuda_memory cost 0.0002262592315673828 seconds
DEBUG 01-15 10:09:37.058754.058754 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:37.058656.058656 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:37.058902.058902 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:37.058267.058267 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 17cc9f45-5c52-475f-b827-89f26f2a4dc7
DEBUG 01-15 10:09:37.058957.058957 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:37.059808.059808 client.py:127] Model loaded
DEBUG 01-15 10:09:37.059661.059661 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:37.059229.059229 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:37.059103.059103 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:37.059278.059278 cuda_h.py:19] end restore2model cost 0.00040793418884277344 seconds
DEBUG 01-15 10:09:37.059816.059816 cuda_h.py:19] end sllm_worker_task cost 0.010710000991821289 seconds
INFO 01-15 10:09:37.059035.059035 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 17cc9f45-5c52-475f-b827-89f26f2a4dc7
DEBUG 01-15 10:09:37.060686.060686 cuda_h.py:19] end load_into_gpu_async cost 0.0014951229095458984 seconds
DEBUG 01-15 10:09:37.060674.060674 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:37.060410.060410 cuda_h.py:19] end restore_tensors2 cost 0.0004124641418457031 seconds
DEBUG 01-15 10:09:37.060531.060531 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025544166564941406 seconds
DEBUG 01-15 10:09:37.060339.060339 cuda_h.py:19] end move_flatidxs cost 0.0008535385131835938 seconds
DEBUG 01-15 10:09:37.060824.060824 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:37.060738.060738 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:37.063576.063576 cuda_h.py:19] end restore2model cost 0.0026683807373046875 seconds
DEBUG 01-15 10:09:37.063843.063843 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005406856536865234 seconds
DEBUG 01-15 10:09:37.063208.063208 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:37.063868.063868 cuda_h.py:19] end gpu_sexperts cost 0.00028061866760253906 seconds
DEBUG 01-15 10:09:37.063174.063174 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:37.065656.065656 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015141963958740234 seconds
DEBUG 01-15 10:09:37.066762.066762 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:37.066271.066271 cuda_h.py:19] end gpu_group_list cost 0.0003273487091064453 seconds
DEBUG 01-15 10:09:37.066149.066149 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:37.067612.067612 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007221698760986328 seconds
DEBUG 01-15 10:09:37.067050.067050 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:37.067112.067112 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-15 10:09:37.067046.067046 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:37.070782.070782 cuda_h.py:19] end group_tensors cost 0.00978994369506836 seconds
DEBUG 01-15 10:09:37.071069.071069 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:37.075127.075127 cuda_h.py:19] end group pad cost 0.004060506820678711 seconds
DEBUG 01-15 10:09:37.075586.075586 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:37.093923.093923 cuda_h.py:19] end group_einsum cost 0.018280506134033203 seconds
DEBUG 01-15 10:09:37.093610.093610 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:37.098674.098674 cuda_h.py:19] end get_outputs_cpu1 cost 0.004616975784301758 seconds
DEBUG 01-15 10:09:37.099502.099502 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03990364074707031 seconds
DEBUG 01-15 10:09:37.101018.101018 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.033492088317871094 seconds
DEBUG 01-15 10:09:37.101099.101099 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:37.101794.101794 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.102143.102143 cuda_h.py:19] end index_scatter cost 0.00019311904907226562 seconds
DEBUG 01-15 10:09:37.102576.102576 cuda_h.py:19] end cpuoutputsdeal cost 0.0014595985412597656 seconds
DEBUG 01-15 10:09:37.102778.102778 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:37.103576.103576 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 17cc9f45-5c52-475f-b827-89f26f2a4dc7
INFO 01-15 10:09:37.111364.111364 client.py:127] Model loaded
DEBUG 01-15 10:09:37.111660.111660 cuda_h.py:19] end wait_experts cost 0.008248329162597656 seconds
DEBUG 01-15 10:09:37.111623.111623 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:37.111151.111151 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:37.111743.111743 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:37.112635.112635 cuda_h.py:19] end gpu_group_tensor cost 0.000431060791015625 seconds
DEBUG 01-15 10:09:37.112643.112643 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:37.113105.113105 cuda_h.py:19] end gpu_group_einsum cost 0.0013737678527832031 seconds
DEBUG 01-15 10:09:37.114916.114916 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:37.114768.114768 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:37.115301.115301 cuda_h.py:19] end all_expert_outputs_slices cost 0.000989675521850586 seconds
DEBUG 01-15 10:09:37.115986.115986 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:37.115630.115630 cuda_h.py:19] end concat_expert_out cost 0.00014662742614746094 seconds
DEBUG 01-15 10:09:37.115324.115324 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.116888.116888 cuda_h.py:19] end index_scatter cost 0.0001468658447265625 seconds
DEBUG 01-15 10:09:37.116209.116209 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0019321441650390625 seconds
DEBUG 01-15 10:09:37.116911.116911 cuda_h.py:19] end gpu_experts cost 0.004981040954589844 seconds
DEBUG 01-15 10:09:37.116303.116303 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.061269521713256836 seconds
DEBUG 01-15 10:09:37.117309.117309 cuda_h.py:19] end prefill_layer cost 0.06871652603149414 seconds
DEBUG 01-15 10:09:37.117002.117002 lmp.py:1552] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-15 10:09:37.117004.117004 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:37.117775.117775 lmp.py:1495] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-15 10:09:37.117308.117308 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:37.117754.117754 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:37.118203.118203 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:37.118457.118457 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.00016379356384277344 seconds
DEBUG 01-15 10:09:37.118360.118360 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:37.118447.118447 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:37.118328.118328 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:37.118960.118960 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:37.119739.119739 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:37.119723.119723 cuda_h.py:19] end allocate_cuda_memory cost 0.0005834102630615234 seconds
DEBUG 01-15 10:09:37.119954.119954 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:37.119460.119460 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:37.120901.120901 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:37.120387.120387 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a59435f-b420-457b-93d2-cfbc4a295e20
DEBUG 01-15 10:09:37.120626.120626 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:37.121253.121253 cuda_h.py:10] start self_attn
INFO 01-15 10:09:37.121671.121671 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a59435f-b420-457b-93d2-cfbc4a295e20
DEBUG 01-15 10:09:37.121517.121517 cuda_h.py:19] end load_into_gpu_async cost 0.0018963813781738281 seconds
DEBUG 01-15 10:09:37.121050.121050 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:37.122243.122243 cuda_h.py:19] end restore_tensors2 cost 0.00017309188842773438 seconds
DEBUG 01-15 10:09:37.122188.122188 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033655166625976562 seconds
INFO 01-15 10:09:37.122717.122717 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a59435f-b420-457b-93d2-cfbc4a295e20
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:37.127359.127359 cuda_h.py:19] end self_attn cost 0.005963563919067383 seconds
DEBUG 01-15 10:09:37.127589.127589 cuda_h.py:19] end iln_self_attn_paln cost 0.009708642959594727 seconds
DEBUG 01-15 10:09:37.128287.128287 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-15 10:09:37.128223.128223 cuda_h.py:10] start gate
DEBUG 01-15 10:09:37.129391.129391 cuda_h.py:19] end gate cost 0.0010149478912353516 seconds
DEBUG 01-15 10:09:37.129215.129215 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:37.130340.130340 lmp.py:1616] 
DEBUG 01-15 10:09:37.130340.130340 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:37.130984.130984 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:37.130946.130946 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:37.130139.130139 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:37.130756.130756 lmp.py:1620] 
DEBUG 01-15 10:09:37.130756.130756 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:37.130519.130519 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:37.130520.130520 lmp.py:1626]   Expert 20 |     11 | CPU
DEBUG 01-15 10:09:37.130376.130376 lmp.py:1626]   Expert 61 |     11 | CPU
DEBUG 01-15 10:09:37.130277.130277 lmp.py:1626]   Expert 11 |     29 | CPU
DEBUG 01-15 10:09:37.130179.130179 lmp.py:1626]   Expert  7 |     40 | CPU
DEBUG 01-15 10:09:37.130604.130604 lmp.py:1626]   Expert 62 |     42 | CPU
DEBUG 01-15 10:09:37.130029.130029 lmp.py:1626]   Expert  3 |     45 | CPU
DEBUG 01-15 10:09:37.130931.130931 lmp.py:1626]   Expert 51 |     45 | CPU
DEBUG 01-15 10:09:37.130356.130356 lmp.py:1626]   Expert 30 |     51 | CPU
DEBUG 01-15 10:09:37.130781.130781 lmp.py:1626]   Expert 17 |     53 | CPU
DEBUG 01-15 10:09:37.130682.130682 lmp.py:1626]   Expert 29 |     55 | CPU
DEBUG 01-15 10:09:37.130776.130776 lmp.py:1626]   Expert  6 |     61 | CPU
DEBUG 01-15 10:09:37.130393.130393 lmp.py:1626]   Expert  9 |     65 | CPU
DEBUG 01-15 10:09:37.130103.130103 lmp.py:1626]   Expert 63 |     75 | CPU
DEBUG 01-15 10:09:37.130528.130528 lmp.py:1626]   Expert 38 |     76 | CPU
DEBUG 01-15 10:09:37.130999.130999 lmp.py:1626]   Expert 55 |     81 | CPU
DEBUG 01-15 10:09:37.130709.130709 lmp.py:1626]   Expert 59 |     87 | CPU
DEBUG 01-15 10:09:37.130895.130895 lmp.py:1626]   Expert 48 |     91 | CPU
DEBUG 01-15 10:09:37.130605.130605 lmp.py:1626]   Expert 19 |     92 | CPU
DEBUG 01-15 10:09:37.130030.130030 lmp.py:1626]   Expert  8 |     96 | CPU
DEBUG 01-15 10:09:37.130216.130216 lmp.py:1626]   Expert 22 |     99 | CPU
DEBUG 01-15 10:09:37.130164.130164 lmp.py:1626]   Expert 49 |     99 | CPU
DEBUG 01-15 10:09:37.130589.130589 lmp.py:1626]   Expert 24 |    108 | CPU
DEBUG 01-15 10:09:37.130537.130537 lmp.py:1626]   Expert 36 |    113 | CPU
DEBUG 01-15 10:09:37.131486.131486 lmp.py:1626]   Expert 34 |    116 | CPU
DEBUG 01-15 10:09:37.131672.131672 lmp.py:1626]   Expert 42 |    117 | CPU
DEBUG 01-15 10:09:37.131382.131382 lmp.py:1626]   Expert 50 |    120 | CPU
DEBUG 01-15 10:09:37.131853.131853 lmp.py:1626]   Expert 39 |    126 | CPU
DEBUG 01-15 10:09:37.131516.131516 lmp.py:1626]   Expert  4 |    131 | CPU
DEBUG 01-15 10:09:37.131657.131657 lmp.py:1626]   Expert 37 |    144 | CPU
DEBUG 01-15 10:09:37.131320.131320 lmp.py:1626]   Expert 41 |    146 | CPU
DEBUG 01-15 10:09:37.131791.131791 lmp.py:1626]   Expert 15 |    148 | CPU
DEBUG 01-15 10:09:37.131514.131514 lmp.py:1626]   Expert 23 |    155 | CPU
DEBUG 01-15 10:09:37.131939.131939 lmp.py:1626]   Expert 56 |    164 | GPU
DEBUG 01-15 10:09:37.131411.131411 lmp.py:1626]   Expert 16 |    165 | GPU
DEBUG 01-15 10:09:37.131359.131359 lmp.py:1626]   Expert 60 |    165 | GPU
DEBUG 01-15 10:09:37.131830.131830 lmp.py:1626]   Expert 44 |    168 | GPU
DEBUG 01-15 10:09:37.131778.131778 lmp.py:1626]   Expert  1 |    179 | GPU
DEBUG 01-15 10:09:37.131249.131249 lmp.py:1626]   Expert 21 |    181 | GPU
DEBUG 01-15 10:09:37.131959.131959 lmp.py:1626]   Expert 43 |    182 | GPU
DEBUG 01-15 10:09:37.131145.131145 lmp.py:1626]   Expert 47 |    190 | GPU
DEBUG 01-15 10:09:37.131855.131855 lmp.py:1626]   Expert 53 |    193 | GPU
DEBUG 01-15 10:09:37.131042.131042 lmp.py:1626]   Expert 33 |    200 | GPU
DEBUG 01-15 10:09:37.131751.131751 lmp.py:1626]   Expert 12 |    201 | GPU
DEBUG 01-15 10:09:37.131461.131461 lmp.py:1626]   Expert 13 |    208 | GPU
DEBUG 01-15 10:09:37.131694.131694 lmp.py:1626]   Expert 32 |    226 | GPU
DEBUG 01-15 10:09:37.131927.131927 lmp.py:1626]   Expert 28 |    230 | GPU
DEBUG 01-15 10:09:37.131159.131159 lmp.py:1626]   Expert 54 |    254 | GPU
DEBUG 01-15 10:09:37.131584.131584 lmp.py:1626]   Expert  0 |    257 | GPU
DEBUG 01-15 10:09:37.131294.131294 lmp.py:1626]   Expert 31 |    259 | GPU
DEBUG 01-15 10:09:37.131719.131719 lmp.py:1626]   Expert 26 |    261 | GPU
DEBUG 01-15 10:09:37.131190.131190 lmp.py:1626]   Expert 10 |    264 | GPU
DEBUG 01-15 10:09:37.131900.131900 lmp.py:1626]   Expert 18 |    268 | GPU
DEBUG 01-15 10:09:37.131371.131371 lmp.py:1626]   Expert 57 |    274 | GPU
DEBUG 01-15 10:09:37.131842.131842 lmp.py:1626]   Expert  2 |    281 | GPU
DEBUG 01-15 10:09:37.132029.132029 lmp.py:1626]   Expert 58 |    300 | GPU
DEBUG 01-15 10:09:37.132215.132215 lmp.py:1626]   Expert 40 |    343 | GPU
DEBUG 01-15 10:09:37.132925.132925 lmp.py:1626]   Expert 25 |    359 | GPU
DEBUG 01-15 10:09:37.132635.132635 lmp.py:1626]   Expert 45 |    362 | GPU
DEBUG 01-15 10:09:37.132106.132106 lmp.py:1626]   Expert  5 |    440 | GPU
DEBUG 01-15 10:09:37.132054.132054 lmp.py:1626]   Expert 35 |    460 | GPU
DEBUG 01-15 10:09:37.132048.132048 lmp.py:1626]   Expert 27 |    486 | GPU
DEBUG 01-15 10:09:37.132997.132997 lmp.py:1626]   Expert 46 |    552 | GPU
DEBUG 01-15 10:09:37.132422.132422 lmp.py:1626]   Expert 52 |    593 | GPU
DEBUG 01-15 10:09:37.132131.132131 lmp.py:1626]   Expert 14 |    895 | GPU
DEBUG 01-15 10:09:37.132510.132510 lmp.py:1627] 
DEBUG 01-15 10:09:37.132510.132510 lmp.py:1627]   CPU total tokens: 2728 (22.2%)
DEBUG 01-15 10:09:37.132888.132888 lmp.py:1628]   GPU total tokens: 9560 (77.8%)
DEBUG 01-15 10:09:37.132764.132764 cuda_h.py:19] end experts_map_get cost 0.0030968189239501953 seconds
DEBUG 01-15 10:09:37.132973.132973 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:37.132259.132259 lmp.py:1636] 
DEBUG 01-15 10:09:37.132259.132259 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:37.132255.132255 cuda_h.py:19] end cpu_experts_submit cost 6.651878356933594e-05 seconds
DEBUG 01-15 10:09:37.132574.132574 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:37.132146.132146 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:37.132995.132995 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:37.133290.133290 cuda_h.py:19] end allocate_cuda_memory cost 0.000278472900390625 seconds
DEBUG 01-15 10:09:37.133253.133253 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:37.133254.133254 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:37.133674.133674 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:37.133622.133622 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e70ff85d-9e63-4150-81ed-60aee6bfec09
DEBUG 01-15 10:09:37.133371.133371 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:37.134148.134148 client.py:127] Model loaded
DEBUG 01-15 10:09:37.134545.134545 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:37.134460.134460 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:37.134203.134203 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:37.134307.134307 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e70ff85d-9e63-4150-81ed-60aee6bfec09
DEBUG 01-15 10:09:37.135006.135006 cuda_h.py:19] end load_into_gpu_async cost 0.0016734600067138672 seconds
DEBUG 01-15 10:09:37.135716.135716 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:37.135897.135897 cuda_h.py:19] end restore_tensors2 cost 0.0004546642303466797 seconds
DEBUG 01-15 10:09:37.135972.135972 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028982162475585938 seconds
DEBUG 01-15 10:09:37.135000.135000 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:37.135766.135766 cuda_h.py:19] end move_flatidxs cost 0.0009109973907470703 seconds
DEBUG 01-15 10:09:37.135708.135708 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:37.138987.138987 cuda_h.py:19] end restore2model cost 0.002313375473022461 seconds
DEBUG 01-15 10:09:37.138629.138629 cuda_h.py:19] end sllm_worker_task cost 0.019615888595581055 seconds
DEBUG 01-15 10:09:37.141579.141579 cuda_h.py:19] end restore2model cost 0.005364894866943359 seconds
DEBUG 01-15 10:09:37.141689.141689 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008554220199584961 seconds
DEBUG 01-15 10:09:37.141538.141538 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:37.141716.141716 cuda_h.py:19] end gpu_sexperts cost 0.0003407001495361328 seconds
DEBUG 01-15 10:09:37.141705.141705 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:37.143874.143874 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0020537376403808594 seconds
DEBUG 01-15 10:09:37.144785.144785 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:37.145222.145222 cuda_h.py:19] end gpu_group_list cost 0.0003368854522705078 seconds
DEBUG 01-15 10:09:37.145451.145451 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:37.146745.146745 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010166168212890625 seconds
DEBUG 01-15 10:09:37.146045.146045 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:37.146504.146504 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-15 10:09:37.146822.146822 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:37.146364.146364 cuda_h.py:19] end group_tensors cost 0.010831594467163086 seconds
DEBUG 01-15 10:09:37.147285.147285 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:37.151581.151581 cuda_h.py:19] end group pad cost 0.0036406517028808594 seconds
DEBUG 01-15 10:09:37.151086.151086 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:37.170540.170540 cuda_h.py:19] end group_einsum cost 0.019377946853637695 seconds
DEBUG 01-15 10:09:37.170227.170227 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:37.174861.174861 cuda_h.py:19] end get_outputs_cpu1 cost 0.003462553024291992 seconds
DEBUG 01-15 10:09:37.175422.175422 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04050445556640625 seconds
DEBUG 01-15 10:09:37.176480.176480 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0294649600982666 seconds
DEBUG 01-15 10:09:37.176728.176728 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:37.176500.176500 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.176637.176637 cuda_h.py:19] end index_scatter cost 7.843971252441406e-05 seconds
DEBUG 01-15 10:09:37.177049.177049 cuda_h.py:19] end cpuoutputsdeal cost 0.0008296966552734375 seconds
DEBUG 01-15 10:09:37.177925.177925 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:37.177164.177164 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e70ff85d-9e63-4150-81ed-60aee6bfec09
INFO 01-15 10:09:37.185021.185021 client.py:127] Model loaded
DEBUG 01-15 10:09:37.186586.186586 cuda_h.py:19] end wait_experts cost 0.008847713470458984 seconds
DEBUG 01-15 10:09:37.186243.186243 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:37.186662.186662 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:37.186657.186657 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:37.186333.186333 cuda_h.py:19] end gpu_group_tensor cost 0.00018715858459472656 seconds
DEBUG 01-15 10:09:37.186052.186052 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:37.187894.187894 cuda_h.py:19] end gpu_group_einsum cost 0.0005705356597900391 seconds
DEBUG 01-15 10:09:37.187871.187871 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:37.187714.187714 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:37.187195.187195 cuda_h.py:19] end all_expert_outputs_slices cost 0.00028443336486816406 seconds
DEBUG 01-15 10:09:37.187958.187958 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:37.187862.187862 cuda_h.py:19] end concat_expert_out cost 7.2479248046875e-05 seconds
DEBUG 01-15 10:09:37.187944.187944 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.187735.187735 cuda_h.py:19] end index_scatter cost 5.698204040527344e-05 seconds
DEBUG 01-15 10:09:37.187259.187259 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006620883941650391 seconds
DEBUG 01-15 10:09:37.188129.188129 cuda_h.py:19] end gpu_experts cost 0.001926422119140625 seconds
DEBUG 01-15 10:09:37.188483.188483 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.05999898910522461 seconds
DEBUG 01-15 10:09:37.188241.188241 cuda_h.py:19] end prefill_layer cost 0.070892333984375 seconds
DEBUG 01-15 10:09:37.188038.188038 lmp.py:1552] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-15 10:09:37.188787.188787 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:37.188729.188729 lmp.py:1495] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-15 10:09:37.188908.188908 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:37.188832.188832 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:37.189829.189829 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:37.193201.193201 cuda_h.py:19] end self_attn cost 0.004536628723144531 seconds
DEBUG 01-15 10:09:37.194589.194589 cuda_h.py:19] end iln_self_attn_paln cost 0.005278825759887695 seconds
DEBUG 01-15 10:09:37.194916.194916 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-15 10:09:37.194063.194063 cuda_h.py:10] start gate
DEBUG 01-15 10:09:37.194378.194378 cuda_h.py:19] end gate cost 0.0006506443023681641 seconds
DEBUG 01-15 10:09:37.194260.194260 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:37.195298.195298 lmp.py:1616] 
DEBUG 01-15 10:09:37.195298.195298 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:37.195630.195630 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:37.195141.195141 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:37.195553.195553 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:37.195295.195295 lmp.py:1620] 
DEBUG 01-15 10:09:37.195295.195295 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:37.195230.195230 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:37.195641.195641 lmp.py:1626]   Expert 18 |     66 | CPU
DEBUG 01-15 10:09:37.195906.195906 lmp.py:1626]   Expert 47 |     66 | CPU
DEBUG 01-15 10:09:37.195980.195980 lmp.py:1626]   Expert 54 |     71 | CPU
DEBUG 01-15 10:09:37.195577.195577 lmp.py:1626]   Expert 23 |     78 | CPU
DEBUG 01-15 10:09:37.195412.195412 lmp.py:1626]   Expert 48 |     80 | CPU
DEBUG 01-15 10:09:37.195008.195008 lmp.py:1626]   Expert 44 |     84 | CPU
DEBUG 01-15 10:09:37.195082.195082 lmp.py:1626]   Expert 45 |     87 | CPU
DEBUG 01-15 10:09:37.195155.195155 lmp.py:1626]   Expert 20 |     93 | CPU
DEBUG 01-15 10:09:37.195990.195990 lmp.py:1626]   Expert 31 |     94 | CPU
DEBUG 01-15 10:09:37.195302.195302 lmp.py:1626]   Expert 36 |    105 | CPU
DEBUG 01-15 10:09:37.195329.195329 lmp.py:1626]   Expert 61 |    111 | CPU
DEBUG 01-15 10:09:37.195357.195357 lmp.py:1626]   Expert 33 |    120 | CPU
DEBUG 01-15 10:09:37.195861.195861 lmp.py:1626]   Expert 42 |    120 | CPU
DEBUG 01-15 10:09:37.195457.195457 lmp.py:1626]   Expert 10 |    121 | CPU
DEBUG 01-15 10:09:37.195306.195306 lmp.py:1626]   Expert 24 |    121 | CPU
DEBUG 01-15 10:09:37.195518.195518 lmp.py:1626]   Expert 43 |    123 | CPU
DEBUG 01-15 10:09:37.195492.195492 lmp.py:1626]   Expert 11 |    125 | CPU
DEBUG 01-15 10:09:37.195466.195466 lmp.py:1626]   Expert 49 |    126 | CPU
DEBUG 01-15 10:09:37.195202.195202 lmp.py:1626]   Expert 56 |    130 | CPU
DEBUG 01-15 10:09:37.195415.195415 lmp.py:1626]   Expert  6 |    136 | CPU
DEBUG 01-15 10:09:37.195865.195865 lmp.py:1626]   Expert 51 |    142 | CPU
DEBUG 01-15 10:09:37.195893.195893 lmp.py:1626]   Expert 17 |    147 | CPU
DEBUG 01-15 10:09:37.195297.195297 lmp.py:1626]   Expert  0 |    150 | CPU
DEBUG 01-15 10:09:37.195132.195132 lmp.py:1626]   Expert  5 |    154 | CPU
DEBUG 01-15 10:09:37.195921.195921 lmp.py:1626]   Expert 12 |    154 | CPU
DEBUG 01-15 10:09:37.195895.195895 lmp.py:1626]   Expert 40 |    158 | CPU
DEBUG 01-15 10:09:37.195869.195869 lmp.py:1626]   Expert 55 |    160 | CPU
DEBUG 01-15 10:09:37.195843.195843 lmp.py:1626]   Expert 57 |    161 | CPU
DEBUG 01-15 10:09:37.195579.195579 lmp.py:1626]   Expert 59 |    161 | CPU
DEBUG 01-15 10:09:37.195314.195314 lmp.py:1626]   Expert 26 |    164 | CPU
DEBUG 01-15 10:09:37.195050.195050 lmp.py:1626]   Expert 38 |    167 | CPU
DEBUG 01-15 10:09:37.195262.195262 lmp.py:1626]   Expert 13 |    171 | CPU
DEBUG 01-15 10:09:37.195998.195998 lmp.py:1626]   Expert 46 |    171 | GPU
DEBUG 01-15 10:09:37.195210.195210 lmp.py:1626]   Expert 58 |    173 | GPU
DEBUG 01-15 10:09:37.195138.195138 lmp.py:1626]   Expert 30 |    174 | GPU
DEBUG 01-15 10:09:37.196212.196212 lmp.py:1626]   Expert 50 |    174 | GPU
DEBUG 01-15 10:09:37.196616.196616 lmp.py:1626]   Expert 35 |    176 | GPU
DEBUG 01-15 10:09:37.196829.196829 lmp.py:1626]   Expert  7 |    181 | GPU
DEBUG 01-15 10:09:37.196803.196803 lmp.py:1626]   Expert 16 |    181 | GPU
DEBUG 01-15 10:09:37.196538.196538 lmp.py:1626]   Expert 15 |    203 | GPU
DEBUG 01-15 10:09:37.196751.196751 lmp.py:1626]   Expert 32 |    203 | GPU
DEBUG 01-15 10:09:37.196486.196486 lmp.py:1626]   Expert 14 |    205 | GPU
DEBUG 01-15 10:09:37.196461.196461 lmp.py:1626]   Expert  1 |    216 | GPU
DEBUG 01-15 10:09:37.196435.196435 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:37.196170.196170 lmp.py:1626]   Expert  3 |    227 | GPU
DEBUG 01-15 10:09:37.196383.196383 lmp.py:1626]   Expert 39 |    238 | GPU
DEBUG 01-15 10:09:37.196118.196118 lmp.py:1626]   Expert 34 |    239 | GPU
DEBUG 01-15 10:09:37.196284.196284 lmp.py:1626]   Expert 28 |    243 | GPU
DEBUG 01-15 10:09:37.196073.196073 lmp.py:1626]   Expert 52 |    246 | GPU
DEBUG 01-15 10:09:37.196286.196286 lmp.py:1626]   Expert 22 |    260 | GPU
DEBUG 01-15 10:09:37.196260.196260 lmp.py:1626]   Expert 25 |    260 | GPU
DEBUG 01-15 10:09:37.196995.196995 lmp.py:1626]   Expert  2 |    272 | GPU
DEBUG 01-15 10:09:37.196731.196731 lmp.py:1626]   Expert 41 |    280 | GPU
DEBUG 01-15 10:09:37.196705.196705 lmp.py:1626]   Expert 21 |    282 | GPU
DEBUG 01-15 10:09:37.196964.196964 lmp.py:1626]   Expert 60 |    284 | GPU
DEBUG 01-15 10:09:37.196699.196699 lmp.py:1626]   Expert 63 |    289 | GPU
DEBUG 01-15 10:09:37.196197.196197 lmp.py:1626]   Expert 29 |    292 | GPU
DEBUG 01-15 10:09:37.196932.196932 lmp.py:1626]   Expert 62 |    297 | GPU
DEBUG 01-15 10:09:37.196297.196297 lmp.py:1626]   Expert 27 |    301 | GPU
DEBUG 01-15 10:09:37.196510.196510 lmp.py:1626]   Expert 37 |    329 | GPU
DEBUG 01-15 10:09:37.196484.196484 lmp.py:1626]   Expert  8 |    335 | GPU
DEBUG 01-15 10:09:37.196173.196173 lmp.py:1626]   Expert 53 |    335 | GPU
DEBUG 01-15 10:09:37.196147.196147 lmp.py:1626]   Expert 19 |    445 | GPU
DEBUG 01-15 10:09:37.196552.196552 lmp.py:1626]   Expert  9 |    610 | GPU
DEBUG 01-15 10:09:37.196718.196718 lmp.py:1627] 
DEBUG 01-15 10:09:37.196718.196718 lmp.py:1627]   CPU total tokens: 3946 (32.1%)
DEBUG 01-15 10:09:37.196314.196314 lmp.py:1628]   GPU total tokens: 8342 (67.9%)
DEBUG 01-15 10:09:37.196011.196011 cuda_h.py:19] end experts_map_get cost 0.0016102790832519531 seconds
DEBUG 01-15 10:09:37.196668.196668 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:37.196325.196325 lmp.py:1636] 
DEBUG 01-15 10:09:37.196325.196325 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:37.196261.196261 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-15 10:09:37.196718.196718 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:37.196892.196892 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:37.196799.196799 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:37.197995.197995 cuda_h.py:19] end allocate_cuda_memory cost 0.00028395652770996094 seconds
DEBUG 01-15 10:09:37.197882.197882 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:37.197744.197744 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:37.197375.197375 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:37.197362.197362 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 07618f6e-3e95-4d95-9f27-0e8d081ede45
DEBUG 01-15 10:09:37.197608.197608 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:37.198007.198007 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:37.198933.198933 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:37.199971.199971 cuda_h.py:19] end move_flatidxs cost 0.0008778572082519531 seconds
DEBUG 01-15 10:09:37.199145.199145 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:37.199368.199368 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 07618f6e-3e95-4d95-9f27-0e8d081ede45
DEBUG 01-15 10:09:37.199343.199343 cuda_h.py:19] end load_into_gpu_async cost 0.00167083740234375 seconds
DEBUG 01-15 10:09:37.199185.199185 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:37.199954.199954 cuda_h.py:19] end restore_tensors2 cost 0.0004017353057861328 seconds
DEBUG 01-15 10:09:37.199168.199168 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003058195114135742 seconds
DEBUG 01-15 10:09:37.199275.199275 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:37.202426.202426 cuda_h.py:19] end restore2model cost 0.0026786327362060547 seconds
DEBUG 01-15 10:09:37.202567.202567 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005939483642578125 seconds
DEBUG 01-15 10:09:37.202621.202621 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:37.203466.203466 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-15 10:09:37.203534.203534 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:37.204229.204229 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015251636505126953 seconds
DEBUG 01-15 10:09:37.205990.205990 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:37.205015.205015 cuda_h.py:19] end gpu_group_list cost 0.0003204345703125 seconds
DEBUG 01-15 10:09:37.205648.205648 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:37.205553.205553 cuda_h.py:19] end group_tensors cost 0.00621485710144043 seconds
DEBUG 01-15 10:09:37.206791.206791 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:37.206127.206127 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007860660552978516 seconds
DEBUG 01-15 10:09:37.206765.206765 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:37.210391.210391 cuda_h.py:19] end group pad cost 0.004006147384643555 seconds
DEBUG 01-15 10:09:37.210134.210134 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:37.228446.228446 cuda_h.py:19] end group_einsum cost 0.018336772918701172 seconds
DEBUG 01-15 10:09:37.228895.228895 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:37.233536.233536 cuda_h.py:19] end get_outputs_cpu1 cost 0.0046117305755615234 seconds
DEBUG 01-15 10:09:37.234111.234111 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03631114959716797 seconds
DEBUG 01-15 10:09:37.235520.235520 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.028978824615478516 seconds
DEBUG 01-15 10:09:37.236421.236421 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:37.237645.237645 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.237185.237185 cuda_h.py:19] end index_scatter cost 0.00018906593322753906 seconds
DEBUG 01-15 10:09:37.238577.238577 cuda_h.py:19] end cpuoutputsdeal cost 0.0019829273223876953 seconds
DEBUG 01-15 10:09:37.238898.238898 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:37.238676.238676 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 07618f6e-3e95-4d95-9f27-0e8d081ede45
INFO 01-15 10:09:37.250005.250005 client.py:127] Model loaded
DEBUG 01-15 10:09:37.251991.251991 cuda_h.py:19] end wait_experts cost 0.012766838073730469 seconds
DEBUG 01-15 10:09:37.251444.251444 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:37.251641.251641 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:37.251571.251571 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:37.251442.251442 cuda_h.py:19] end gpu_group_tensor cost 0.0004177093505859375 seconds
DEBUG 01-15 10:09:37.252748.252748 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:37.253400.253400 cuda_h.py:19] end gpu_group_einsum cost 0.0013966560363769531 seconds
DEBUG 01-15 10:09:37.253091.253091 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:37.254467.254467 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:37.255502.255502 cuda_h.py:19] end all_expert_outputs_slices cost 0.0011620521545410156 seconds
DEBUG 01-15 10:09:37.255863.255863 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:37.255335.255335 cuda_h.py:19] end concat_expert_out cost 0.0001583099365234375 seconds
DEBUG 01-15 10:09:37.255651.255651 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:37.256322.256322 cuda_h.py:19] end index_scatter cost 0.00015544891357421875 seconds
DEBUG 01-15 10:09:37.256835.256835 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0021219253540039062 seconds
DEBUG 01-15 10:09:37.256742.256742 cuda_h.py:19] end gpu_experts cost 0.005054473876953125 seconds
DEBUG 01-15 10:09:37.256042.256042 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06243634223937988 seconds
DEBUG 01-15 10:09:37.257247.257247 cuda_h.py:19] end prefill_layer cost 0.06865286827087402 seconds
DEBUG 01-15 10:09:37.257840.257840 lmp.py:1552] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-15 10:09:37.257095.257095 cuda_h.py:19] end prefill cost 1.8933875560760498 seconds
DEBUG 01-15 10:09:39.463627.463627 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.10517740249633789 s
DEBUG 01-15 10:09:39.897469.897469 cuda_h.py:19] end generate_input_ids cost 0.430217981338501 seconds
DEBUG 01-15 10:09:39.898217.898217 cuda_h.py:10] start init_cache
DEBUG 01-15 10:09:39.898529.898529 cuda_h.py:19] end init_cache cost 0.00018024444580078125 seconds
DEBUG 01-15 10:09:42.645702.645702 cuda_h.py:10] start init_meta_layer
DEBUG 01-15 10:09:42.645939.645939 cuda_h.py:19] end init_meta_layer cost 1.6450881958007812e-05 seconds
DEBUG 01-15 10:09:42.646319.646319 cuda_h.py:10] start init_weights
DEBUG 01-15 10:09:42.646194.646194 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:42.646871.646871 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:42.648234.648234 cuda_h.py:19] end allocate_cuda_memory cost 0.002096891403198242 seconds
DEBUG 01-15 10:09:42.648641.648641 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:42.648788.648788 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:42.648147.648147 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:42.648950.648950 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 846c6135-0382-42f8-9226-79cc7859894b
DEBUG 01-15 10:09:42.648059.648059 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:42.650294.650294 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 846c6135-0382-42f8-9226-79cc7859894b
DEBUG 01-15 10:09:42.650146.650146 cuda_h.py:19] end load_into_gpu_async cost 0.0017974376678466797 seconds
DEBUG 01-15 10:09:42.650533.650533 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:42.650558.650558 cuda_h.py:19] end restore_tensors2 cost 9.393692016601562e-05 seconds
DEBUG 01-15 10:09:42.650599.650599 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004348039627075195 seconds
DEBUG 01-15 10:09:42.650964.650964 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:42.650467.650467 cuda_h.py:19] end restore2model cost 0.00017261505126953125 seconds
INFO 01-15 10:09:42.650415.650415 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 846c6135-0382-42f8-9226-79cc7859894b
INFO 01-15 10:09:42.729466.729466 client.py:127] Model loaded
DEBUG 01-15 10:09:42.730968.730968 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-15 10:09:42.730734.730734 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:42.730110.730110 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:42.730776.730776 cuda_h.py:19] end allocate_cuda_memory cost 0.00042366981506347656 seconds
DEBUG 01-15 10:09:42.731887.731887 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:42.731771.731771 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:42.731338.731338 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:42.731055.731055 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fdcb8163-4c6a-4f6f-93e2-a786fea5755a
DEBUG 01-15 10:09:42.731154.731154 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:42.733584.733584 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fdcb8163-4c6a-4f6f-93e2-a786fea5755a
DEBUG 01-15 10:09:42.733715.733715 cuda_h.py:19] end load_into_gpu_async cost 0.002060413360595703 seconds
DEBUG 01-15 10:09:42.733671.733671 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:42.733798.733798 cuda_h.py:19] end restore_tensors2 cost 0.00015497207641601562 seconds
DEBUG 01-15 10:09:42.733542.733542 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032846927642822266 seconds
INFO 01-15 10:09:42.733737.733737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fdcb8163-4c6a-4f6f-93e2-a786fea5755a
INFO 01-15 10:09:42.748380.748380 client.py:127] Model loaded
DEBUG 01-15 10:09:42.748808.748808 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:42.749023.749023 cuda_h.py:19] end restore2model cost 0.0009706020355224609 seconds
DEBUG 01-15 10:09:42.750014.750014 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.01987314224243164 seconds
DEBUG 01-15 10:09:42.750805.750805 cuda_h.py:19] end init_weights cost 0.10389828681945801 seconds
DEBUG 01-15 10:09:42.750569.750569 cuda_h.py:10] start copy_emodel
DEBUG 01-15 10:09:43.604471.604471 cuda_h.py:19] end copy_emodel cost 0.854557991027832 seconds
DEBUG 01-15 10:09:43.605804.605804 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-15 10:09:43.606486.606486 cuda_h.py:19] end init_inputs_tokens cost 0.0003521442413330078 seconds
DEBUG 01-15 10:09:43.606740.606740 cuda_h.py:10] start prefill
DEBUG 01-15 10:09:43.606026.606026 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.606967.606967 lmp.py:1495] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-15 10:09:43.606140.606140 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:43.606512.606512 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-15 10:09:43.606004.606004 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 5.14984130859375e-05 seconds
DEBUG 01-15 10:09:43.606469.606469 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 8.630752563476562e-05 seconds
DEBUG 01-15 10:09:43.606827.606827 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.606637.606637 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.606179.606179 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.606661.606661 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.607773.607773 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.607287.607287 cuda_h.py:19] end allocate_cuda_memory cost 0.0005793571472167969 seconds
DEBUG 01-15 10:09:43.608756.608756 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.608216.608216 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.608233.608233 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.608196.608196 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2c632d0a-437a-4722-a0c3-908aafe737b0
DEBUG 01-15 10:09:43.608304.608304 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.609768.609768 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.610725.610725 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2c632d0a-437a-4722-a0c3-908aafe737b0
DEBUG 01-15 10:09:43.610407.610407 cuda_h.py:19] end load_into_gpu_async cost 0.0025205612182617188 seconds
DEBUG 01-15 10:09:43.610483.610483 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.611875.611875 cuda_h.py:19] end restore_tensors2 cost 0.00017309188842773438 seconds
DEBUG 01-15 10:09:43.611574.611574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003999471664428711 seconds
INFO 01-15 10:09:43.611920.611920 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2c632d0a-437a-4722-a0c3-908aafe737b0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:43.616790.616790 cuda_h.py:19] end self_attn cost 0.0072672367095947266 seconds
DEBUG 01-15 10:09:43.617287.617287 cuda_h.py:19] end iln_self_attn_paln cost 0.010735034942626953 seconds
DEBUG 01-15 10:09:43.617600.617600 cuda_h.py:10] start dense_mlp
INFO 01-15 10:09:43.618331.618331 client.py:127] Model loaded
DEBUG 01-15 10:09:43.619456.619456 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.620169.620169 cuda_h.py:19] end restore2model cost 0.0010046958923339844 seconds
DEBUG 01-15 10:09:43.620802.620802 cuda_h.py:19] end sllm_worker_task cost 0.013336420059204102 seconds
DEBUG 01-15 10:09:43.620967.620967 cuda_h.py:19] end dense_mlp cost 0.0032041072845458984 seconds
DEBUG 01-15 10:09:43.620449.620449 cuda_h.py:19] end prefill_layer cost 0.01439809799194336 seconds
DEBUG 01-15 10:09:43.620450.620450 lmp.py:1552] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-15 10:09:43.620246.620246 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.620472.620472 lmp.py:1495] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-15 10:09:43.620075.620075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:43.620301.620301 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-15 10:09:43.620721.620721 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.337860107421875e-05 seconds
DEBUG 01-15 10:09:43.620430.620430 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 7.081031799316406e-05 seconds
DEBUG 01-15 10:09:43.620842.620842 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.620115.620115 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.621093.621093 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.621971.621971 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.621896.621896 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.621843.621843 cuda_h.py:19] end allocate_cuda_memory cost 0.00036263465881347656 seconds
DEBUG 01-15 10:09:43.622240.622240 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.622132.622132 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.622142.622142 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.622456.622456 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f6b8dfab-fb15-41ee-bd39-6f50c9466a92
DEBUG 01-15 10:09:43.622920.622920 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.622325.622325 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.624499.624499 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f6b8dfab-fb15-41ee-bd39-6f50c9466a92
DEBUG 01-15 10:09:43.624022.624022 cuda_h.py:19] end load_into_gpu_async cost 0.0020551681518554688 seconds
DEBUG 01-15 10:09:43.624529.624529 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.624041.624041 cuda_h.py:19] end restore_tensors2 cost 0.0001373291015625 seconds
DEBUG 01-15 10:09:43.624336.624336 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003499746322631836 seconds
INFO 01-15 10:09:43.624486.624486 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f6b8dfab-fb15-41ee-bd39-6f50c9466a92
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:43.627087.627087 cuda_h.py:19] end self_attn cost 0.004246711730957031 seconds
DEBUG 01-15 10:09:43.627563.627563 cuda_h.py:19] end iln_self_attn_paln cost 0.0066759586334228516 seconds
DEBUG 01-15 10:09:43.627903.627903 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-15 10:09:43.627527.627527 cuda_h.py:10] start gate
DEBUG 01-15 10:09:43.628657.628657 cuda_h.py:19] end gate cost 0.0010750293731689453 seconds
DEBUG 01-15 10:09:43.628692.628692 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:43.629325.629325 lmp.py:1616] 
DEBUG 01-15 10:09:43.629325.629325 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:43.629227.629227 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:43.629069.629069 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:43.629387.629387 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:43.629891.629891 lmp.py:1620] 
DEBUG 01-15 10:09:43.629891.629891 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:43.629972.629972 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:43.629098.629098 lmp.py:1626]   Expert 25 |     64 | CPU
DEBUG 01-15 10:09:43.629033.629033 lmp.py:1626]   Expert 54 |     67 | CPU
DEBUG 01-15 10:09:43.629537.629537 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:43.629756.629756 lmp.py:1626]   Expert 31 |     72 | CPU
DEBUG 01-15 10:09:43.629022.629022 lmp.py:1626]   Expert 55 |     72 | CPU
DEBUG 01-15 10:09:43.629002.629002 lmp.py:1626]   Expert 62 |     87 | CPU
DEBUG 01-15 10:09:43.629745.629745 lmp.py:1626]   Expert 18 |     88 | CPU
DEBUG 01-15 10:09:43.629249.629249 lmp.py:1626]   Expert 52 |     98 | CPU
DEBUG 01-15 10:09:43.629403.629403 lmp.py:1626]   Expert 22 |    100 | CPU
DEBUG 01-15 10:09:43.629589.629589 lmp.py:1626]   Expert 47 |    104 | CPU
DEBUG 01-15 10:09:43.629855.629855 lmp.py:1626]   Expert  0 |    113 | CPU
DEBUG 01-15 10:09:43.629975.629975 lmp.py:1626]   Expert 37 |    117 | CPU
DEBUG 01-15 10:09:43.629379.629379 lmp.py:1626]   Expert 27 |    121 | CPU
DEBUG 01-15 10:09:43.629022.629022 lmp.py:1626]   Expert 32 |    123 | CPU
DEBUG 01-15 10:09:43.629427.629427 lmp.py:1626]   Expert 41 |    130 | CPU
DEBUG 01-15 10:09:43.629070.629070 lmp.py:1626]   Expert 44 |    131 | CPU
DEBUG 01-15 10:09:43.629474.629474 lmp.py:1626]   Expert 28 |    136 | CPU
DEBUG 01-15 10:09:43.629879.629879 lmp.py:1626]   Expert 13 |    138 | CPU
DEBUG 01-15 10:09:43.629283.629283 lmp.py:1626]   Expert 58 |    140 | CPU
DEBUG 01-15 10:09:43.629688.629688 lmp.py:1626]   Expert 60 |    144 | CPU
DEBUG 01-15 10:09:43.629854.629854 lmp.py:1626]   Expert 43 |    147 | CPU
DEBUG 01-15 10:09:43.629020.629020 lmp.py:1626]   Expert  1 |    150 | CPU
DEBUG 01-15 10:09:43.629901.629901 lmp.py:1626]   Expert 38 |    153 | CPU
DEBUG 01-15 10:09:43.630068.630068 lmp.py:1626]   Expert 49 |    154 | CPU
DEBUG 01-15 10:09:43.630472.630472 lmp.py:1626]   Expert 51 |    155 | CPU
DEBUG 01-15 10:09:43.630115.630115 lmp.py:1626]   Expert 34 |    161 | CPU
DEBUG 01-15 10:09:43.630950.630950 lmp.py:1626]   Expert 35 |    164 | CPU
DEBUG 01-15 10:09:43.630024.630024 lmp.py:1626]   Expert 36 |    168 | CPU
DEBUG 01-15 10:09:43.630336.630336 lmp.py:1626]   Expert 11 |    170 | CPU
DEBUG 01-15 10:09:43.630979.630979 lmp.py:1626]   Expert 17 |    170 | CPU
DEBUG 01-15 10:09:43.630145.630145 lmp.py:1626]   Expert 59 |    174 | CPU
DEBUG 01-15 10:09:43.630311.630311 lmp.py:1626]   Expert 10 |    180 | CPU
DEBUG 01-15 10:09:43.630239.630239 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:43.630643.630643 lmp.py:1626]   Expert  2 |    186 | GPU
DEBUG 01-15 10:09:43.630571.630571 lmp.py:1626]   Expert 39 |    189 | GPU
DEBUG 01-15 10:09:43.630022.630022 lmp.py:1626]   Expert 33 |    197 | GPU
DEBUG 01-15 10:09:43.630188.630188 lmp.py:1626]   Expert 12 |    198 | GPU
DEBUG 01-15 10:09:43.630116.630116 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:43.630043.630043 lmp.py:1626]   Expert 48 |    198 | GPU
DEBUG 01-15 10:09:43.630971.630971 lmp.py:1626]   Expert 15 |    199 | GPU
DEBUG 01-15 10:09:43.630660.630660 lmp.py:1626]   Expert 53 |    204 | GPU
DEBUG 01-15 10:09:43.630588.630588 lmp.py:1626]   Expert 19 |    220 | GPU
DEBUG 01-15 10:09:43.630185.630185 lmp.py:1626]   Expert 26 |    221 | GPU
DEBUG 01-15 10:09:43.630351.630351 lmp.py:1626]   Expert 30 |    221 | GPU
DEBUG 01-15 10:09:43.630709.630709 lmp.py:1626]   Expert 45 |    221 | GPU
DEBUG 01-15 10:09:43.630114.630114 lmp.py:1626]   Expert  5 |    227 | GPU
DEBUG 01-15 10:09:43.630280.630280 lmp.py:1626]   Expert  4 |    229 | GPU
DEBUG 01-15 10:09:43.630969.630969 lmp.py:1626]   Expert 24 |    229 | GPU
DEBUG 01-15 10:09:43.630135.630135 lmp.py:1626]   Expert 42 |    242 | GPU
DEBUG 01-15 10:09:43.630301.630301 lmp.py:1626]   Expert 50 |    245 | GPU
DEBUG 01-15 10:09:43.630229.630229 lmp.py:1626]   Expert 29 |    254 | GPU
DEBUG 01-15 10:09:43.630157.630157 lmp.py:1626]   Expert 56 |    262 | GPU
DEBUG 01-15 10:09:43.630323.630323 lmp.py:1626]   Expert 61 |    270 | GPU
DEBUG 01-15 10:09:43.630251.630251 lmp.py:1626]   Expert  8 |    283 | GPU
DEBUG 01-15 10:09:43.630417.630417 lmp.py:1626]   Expert 63 |    285 | GPU
DEBUG 01-15 10:09:43.630583.630583 lmp.py:1626]   Expert 46 |    294 | GPU
DEBUG 01-15 10:09:43.630180.630180 lmp.py:1626]   Expert  9 |    300 | GPU
DEBUG 01-15 10:09:43.630922.630922 lmp.py:1626]   Expert  6 |    316 | GPU
DEBUG 01-15 10:09:43.630327.630327 lmp.py:1626]   Expert 16 |    316 | GPU
DEBUG 01-15 10:09:43.630493.630493 lmp.py:1626]   Expert 40 |    319 | GPU
DEBUG 01-15 10:09:43.630851.630851 lmp.py:1626]   Expert  7 |    322 | GPU
DEBUG 01-15 10:09:43.630448.630448 lmp.py:1626]   Expert 23 |    325 | GPU
DEBUG 01-15 10:09:43.630283.630283 lmp.py:1626]   Expert 14 |    413 | GPU
DEBUG 01-15 10:09:43.630641.630641 lmp.py:1626]   Expert 57 |    464 | GPU
DEBUG 01-15 10:09:43.630191.630191 lmp.py:1627] 
DEBUG 01-15 10:09:43.630191.630191 lmp.py:1627]   CPU total tokens: 4059 (33.0%)
DEBUG 01-15 10:09:43.630218.630218 lmp.py:1628]   GPU total tokens: 8229 (67.0%)
DEBUG 01-15 10:09:43.630074.630074 cuda_h.py:19] end experts_map_get cost 0.0018608570098876953 seconds
DEBUG 01-15 10:09:43.630011.630011 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:43.630105.630105 lmp.py:1636] 
DEBUG 01-15 10:09:43.630105.630105 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:43.630577.630577 cuda_h.py:19] end cpu_experts_submit cost 6.818771362304688e-05 seconds
DEBUG 01-15 10:09:43.630512.630512 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:43.631553.631553 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.631494.631494 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.631881.631881 cuda_h.py:19] end allocate_cuda_memory cost 0.00023293495178222656 seconds
DEBUG 01-15 10:09:43.631076.631076 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.631898.631898 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.631397.631397 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.631722.631722 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 63e1145b-c24c-4338-9f54-95ca9af31793
DEBUG 01-15 10:09:43.632456.632456 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:43.633482.633482 client.py:127] Model loaded
DEBUG 01-15 10:09:43.633121.633121 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.634177.634177 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:43.634113.634113 cuda_h.py:19] end restore2model cost 0.0008618831634521484 seconds
DEBUG 01-15 10:09:43.634700.634700 cuda_h.py:19] end sllm_worker_task cost 0.013586997985839844 seconds
INFO 01-15 10:09:43.634739.634739 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 63e1145b-c24c-4338-9f54-95ca9af31793
DEBUG 01-15 10:09:43.634060.634060 cuda_h.py:19] end load_into_gpu_async cost 0.0032486915588378906 seconds
DEBUG 01-15 10:09:43.634531.634531 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.634903.634903 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:43.635337.635337 cuda_h.py:19] end restore_tensors2 cost 0.0004909038543701172 seconds
DEBUG 01-15 10:09:43.635994.635994 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004439830780029297 seconds
DEBUG 01-15 10:09:43.635586.635586 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.636392.636392 cuda_h.py:19] end move_flatidxs cost 0.0011892318725585938 seconds
DEBUG 01-15 10:09:43.636094.636094 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:43.638425.638425 cuda_h.py:19] end restore2model cost 0.0032761096954345703 seconds
DEBUG 01-15 10:09:43.638865.638865 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007961034774780273 seconds
DEBUG 01-15 10:09:43.639111.639111 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:43.639429.639429 cuda_h.py:19] end gpu_sexperts cost 0.0003402233123779297 seconds
DEBUG 01-15 10:09:43.639364.639364 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:43.642726.642726 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0026388168334960938 seconds
DEBUG 01-15 10:09:43.643039.643039 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:43.643449.643449 cuda_h.py:19] end gpu_group_list cost 0.0003235340118408203 seconds
DEBUG 01-15 10:09:43.643076.643076 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:43.644250.644250 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009899139404296875 seconds
DEBUG 01-15 10:09:43.644410.644410 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:43.644578.644578 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-15 10:09:43.644672.644672 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:43.648344.648344 cuda_h.py:19] end group_tensors cost 0.011926889419555664 seconds
DEBUG 01-15 10:09:43.649717.649717 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:43.655446.655446 cuda_h.py:19] end group pad cost 0.006438732147216797 seconds
DEBUG 01-15 10:09:43.656297.656297 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:43.678979.678979 cuda_h.py:19] end group_einsum cost 0.022245168685913086 seconds
DEBUG 01-15 10:09:43.678488.678488 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:43.683973.683973 cuda_h.py:19] end get_outputs_cpu1 cost 0.005305767059326172 seconds
DEBUG 01-15 10:09:43.684414.684414 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05042624473571777 seconds
DEBUG 01-15 10:09:43.685292.685292 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.04078841209411621 seconds
DEBUG 01-15 10:09:43.685908.685908 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:43.686035.686035 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.687424.687424 cuda_h.py:19] end index_scatter cost 0.00027060508728027344 seconds
DEBUG 01-15 10:09:43.687213.687213 cuda_h.py:19] end cpuoutputsdeal cost 0.0018811225891113281 seconds
DEBUG 01-15 10:09:43.688349.688349 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:43.688478.688478 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 63e1145b-c24c-4338-9f54-95ca9af31793
INFO 01-15 10:09:43.689720.689720 client.py:127] Model loaded
DEBUG 01-15 10:09:43.689591.689591 cuda_h.py:19] end wait_experts cost 0.0014281272888183594 seconds
DEBUG 01-15 10:09:43.689011.689011 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:43.689293.689293 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:43.689389.689389 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:43.691875.691875 cuda_h.py:19] end gpu_group_tensor cost 0.001402139663696289 seconds
DEBUG 01-15 10:09:43.691500.691500 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:43.693523.693523 cuda_h.py:19] end gpu_group_einsum cost 0.0015952587127685547 seconds
DEBUG 01-15 10:09:43.693796.693796 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:43.693760.693760 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:43.694265.694265 cuda_h.py:19] end all_expert_outputs_slices cost 0.0007627010345458984 seconds
DEBUG 01-15 10:09:43.694326.694326 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:43.694914.694914 cuda_h.py:19] end concat_expert_out cost 8.606910705566406e-05 seconds
DEBUG 01-15 10:09:43.694189.694189 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.694856.694856 cuda_h.py:19] end index_scatter cost 8.749961853027344e-05 seconds
DEBUG 01-15 10:09:43.694069.694069 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013434886932373047 seconds
DEBUG 01-15 10:09:43.695967.695967 cuda_h.py:19] end gpu_experts cost 0.005332231521606445 seconds
DEBUG 01-15 10:09:43.695037.695037 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.06744074821472168 seconds
DEBUG 01-15 10:09:43.695862.695862 cuda_h.py:19] end prefill_layer cost 0.07492780685424805 seconds
DEBUG 01-15 10:09:43.695554.695554 lmp.py:1552] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-15 10:09:43.695846.695846 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.695305.695305 lmp.py:1495] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-15 10:09:43.695220.695220 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:43.695758.695758 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-15 10:09:43.696980.696980 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.982948303222656e-05 seconds
DEBUG 01-15 10:09:43.696902.696902 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 0.00010204315185546875 seconds
DEBUG 01-15 10:09:43.696334.696334 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.696132.696132 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.696519.696519 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.696250.696250 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.696721.696721 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.697494.697494 cuda_h.py:19] end allocate_cuda_memory cost 0.00030493736267089844 seconds
DEBUG 01-15 10:09:43.697040.697040 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.697187.697187 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.697123.697123 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.697448.697448 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c98cb649-1b33-49d2-a6c8-a6675d649748
DEBUG 01-15 10:09:43.697498.697498 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.697150.697150 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.698906.698906 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c98cb649-1b33-49d2-a6c8-a6675d649748
DEBUG 01-15 10:09:43.698399.698399 cuda_h.py:19] end load_into_gpu_async cost 0.0011720657348632812 seconds
DEBUG 01-15 10:09:43.698393.698393 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.698980.698980 cuda_h.py:19] end restore_tensors2 cost 8.726119995117188e-05 seconds
DEBUG 01-15 10:09:43.698451.698451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018732547760009766 seconds
INFO 01-15 10:09:43.698361.698361 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c98cb649-1b33-49d2-a6c8-a6675d649748
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-15 10:09:43.705851.705851 client.py:127] Model loaded
DEBUG 01-15 10:09:43.705204.705204 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.706866.706866 cuda_h.py:19] end restore2model cost 0.0007226467132568359 seconds
DEBUG 01-15 10:09:43.706233.706233 cuda_h.py:19] end self_attn cost 0.008297920227050781 seconds
DEBUG 01-15 10:09:43.706752.706752 cuda_h.py:19] end sllm_worker_task cost 0.009865283966064453 seconds
DEBUG 01-15 10:09:43.706080.706080 cuda_h.py:19] end iln_self_attn_paln cost 0.010598897933959961 seconds
DEBUG 01-15 10:09:43.707607.707607 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-15 10:09:43.707714.707714 cuda_h.py:10] start gate
DEBUG 01-15 10:09:43.708490.708490 cuda_h.py:19] end gate cost 0.0009810924530029297 seconds
DEBUG 01-15 10:09:43.708486.708486 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:43.708458.708458 lmp.py:1616] 
DEBUG 01-15 10:09:43.708458.708458 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:43.708459.708459 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:43.708062.708062 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:43.708997.708997 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:43.708309.708309 lmp.py:1620] 
DEBUG 01-15 10:09:43.708309.708309 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:43.708574.708574 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:43.708654.708654 lmp.py:1626]   Expert 58 |     51 | CPU
DEBUG 01-15 10:09:43.708251.708251 lmp.py:1626]   Expert 27 |     56 | CPU
DEBUG 01-15 10:09:43.708132.708132 lmp.py:1626]   Expert  3 |     68 | CPU
DEBUG 01-15 10:09:43.708775.708775 lmp.py:1626]   Expert 17 |     84 | CPU
DEBUG 01-15 10:09:43.708418.708418 lmp.py:1626]   Expert  0 |     88 | CPU
DEBUG 01-15 10:09:43.708585.708585 lmp.py:1626]   Expert 24 |     88 | CPU
DEBUG 01-15 10:09:43.708751.708751 lmp.py:1626]   Expert 28 |    105 | CPU
DEBUG 01-15 10:09:43.708678.708678 lmp.py:1626]   Expert 34 |    114 | CPU
DEBUG 01-15 10:09:43.708083.708083 lmp.py:1626]   Expert 51 |    118 | CPU
DEBUG 01-15 10:09:43.708488.708488 lmp.py:1626]   Expert 32 |    120 | CPU
DEBUG 01-15 10:09:43.709892.709892 lmp.py:1626]   Expert  9 |    129 | CPU
DEBUG 01-15 10:09:43.709297.709297 lmp.py:1626]   Expert 23 |    135 | CPU
DEBUG 01-15 10:09:43.709039.709039 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:43.709874.709874 lmp.py:1626]   Expert 15 |    136 | CPU
DEBUG 01-15 10:09:43.709040.709040 lmp.py:1626]   Expert 26 |    138 | CPU
DEBUG 01-15 10:09:43.709206.709206 lmp.py:1626]   Expert 30 |    144 | CPU
DEBUG 01-15 10:09:43.709134.709134 lmp.py:1626]   Expert 45 |    146 | CPU
DEBUG 01-15 10:09:43.709300.709300 lmp.py:1626]   Expert 62 |    147 | CPU
DEBUG 01-15 10:09:43.709228.709228 lmp.py:1626]   Expert 57 |    151 | CPU
DEBUG 01-15 10:09:43.709633.709633 lmp.py:1626]   Expert  1 |    152 | CPU
DEBUG 01-15 10:09:43.709799.709799 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:43.709726.709726 lmp.py:1626]   Expert  8 |    159 | CPU
DEBUG 01-15 10:09:43.709893.709893 lmp.py:1626]   Expert 29 |    160 | CPU
DEBUG 01-15 10:09:43.709059.709059 lmp.py:1626]   Expert 25 |    164 | CPU
DEBUG 01-15 10:09:43.709986.709986 lmp.py:1626]   Expert 54 |    167 | CPU
DEBUG 01-15 10:09:43.709153.709153 lmp.py:1626]   Expert  6 |    171 | CPU
DEBUG 01-15 10:09:43.709319.709319 lmp.py:1626]   Expert 49 |    171 | CPU
DEBUG 01-15 10:09:43.709723.709723 lmp.py:1626]   Expert 48 |    174 | CPU
DEBUG 01-15 10:09:43.709704.709704 lmp.py:1626]   Expert 35 |    175 | CPU
DEBUG 01-15 10:09:43.709930.709930 lmp.py:1626]   Expert 12 |    176 | CPU
DEBUG 01-15 10:09:43.709004.709004 lmp.py:1626]   Expert 37 |    178 | CPU
DEBUG 01-15 10:09:43.709647.709647 lmp.py:1626]   Expert 60 |    186 | CPU
DEBUG 01-15 10:09:43.709051.709051 lmp.py:1626]   Expert 13 |    188 | GPU
DEBUG 01-15 10:09:43.709217.709217 lmp.py:1626]   Expert 33 |    189 | GPU
DEBUG 01-15 10:09:43.709383.709383 lmp.py:1626]   Expert 53 |    189 | GPU
DEBUG 01-15 10:09:43.709550.709550 lmp.py:1626]   Expert 10 |    194 | GPU
DEBUG 01-15 10:09:43.709477.709477 lmp.py:1626]   Expert 16 |    194 | GPU
DEBUG 01-15 10:09:43.709643.709643 lmp.py:1626]   Expert 21 |    198 | GPU
DEBUG 01-15 10:09:43.709810.709810 lmp.py:1626]   Expert 40 |    200 | GPU
DEBUG 01-15 10:09:43.709214.709214 lmp.py:1626]   Expert 43 |    202 | GPU
DEBUG 01-15 10:09:43.709572.709572 lmp.py:1626]   Expert 38 |    204 | GPU
DEBUG 01-15 10:09:43.709977.709977 lmp.py:1626]   Expert  5 |    208 | GPU
DEBUG 01-15 10:09:43.709574.709574 lmp.py:1626]   Expert 44 |    216 | GPU
DEBUG 01-15 10:09:43.709978.709978 lmp.py:1626]   Expert 19 |    217 | GPU
DEBUG 01-15 10:09:43.709906.709906 lmp.py:1626]   Expert 50 |    217 | GPU
DEBUG 01-15 10:09:43.709072.709072 lmp.py:1626]   Expert 52 |    217 | GPU
DEBUG 01-15 10:09:43.709000.709000 lmp.py:1626]   Expert 41 |    219 | GPU
DEBUG 01-15 10:09:43.709166.709166 lmp.py:1626]   Expert  4 |    221 | GPU
DEBUG 01-15 10:09:43.709093.709093 lmp.py:1626]   Expert 59 |    223 | GPU
DEBUG 01-15 10:09:43.709260.709260 lmp.py:1626]   Expert 55 |    233 | GPU
DEBUG 01-15 10:09:43.709426.709426 lmp.py:1626]   Expert 31 |    241 | GPU
DEBUG 01-15 10:09:43.709592.709592 lmp.py:1626]   Expert 56 |    241 | GPU
DEBUG 01-15 10:09:43.709520.709520 lmp.py:1626]   Expert 20 |    251 | GPU
DEBUG 01-15 10:09:43.709686.709686 lmp.py:1626]   Expert 39 |    252 | GPU
DEBUG 01-15 10:09:43.709806.709806 lmp.py:1626]   Expert 22 |    265 | GPU
DEBUG 01-15 10:09:43.709164.709164 lmp.py:1626]   Expert  2 |    267 | GPU
DEBUG 01-15 10:09:43.709237.709237 lmp.py:1626]   Expert 47 |    276 | GPU
DEBUG 01-15 10:09:43.709642.709642 lmp.py:1626]   Expert 63 |    276 | GPU
DEBUG 01-15 10:09:43.709285.709285 lmp.py:1626]   Expert 42 |    303 | GPU
DEBUG 01-15 10:09:43.709213.709213 lmp.py:1626]   Expert 18 |    314 | GPU
DEBUG 01-15 10:09:43.709379.709379 lmp.py:1626]   Expert 14 |    317 | GPU
DEBUG 01-15 10:09:43.709545.709545 lmp.py:1626]   Expert 46 |    367 | GPU
DEBUG 01-15 10:09:43.709473.709473 lmp.py:1626]   Expert 11 |    387 | GPU
DEBUG 01-15 10:09:43.709639.709639 lmp.py:1626]   Expert 61 |    460 | GPU
DEBUG 01-15 10:09:43.709997.709997 lmp.py:1627] 
DEBUG 01-15 10:09:43.709997.709997 lmp.py:1627]   CPU total tokens: 4342 (35.3%)
DEBUG 01-15 10:09:43.709117.709117 lmp.py:1628]   GPU total tokens: 7946 (64.7%)
DEBUG 01-15 10:09:43.710674.710674 cuda_h.py:19] end experts_map_get cost 0.0018270015716552734 seconds
DEBUG 01-15 10:09:43.710379.710379 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:43.710903.710903 lmp.py:1636] 
DEBUG 01-15 10:09:43.710903.710903 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:43.710038.710038 cuda_h.py:19] end cpu_experts_submit cost 6.4849853515625e-05 seconds
DEBUG 01-15 10:09:43.710973.710973 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:43.710637.710637 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.710075.710075 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.710920.710920 cuda_h.py:19] end allocate_cuda_memory cost 0.0002655982971191406 seconds
DEBUG 01-15 10:09:43.710975.710975 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.711957.711957 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.711807.711807 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.711040.711040 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6dda09be-4330-4f67-b218-acfd359db3cb
DEBUG 01-15 10:09:43.711273.711273 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.712304.712304 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:43.712763.712763 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:43.713871.713871 cuda_h.py:19] end move_flatidxs cost 0.0009770393371582031 seconds
DEBUG 01-15 10:09:43.713429.713429 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:43.715998.715998 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6dda09be-4330-4f67-b218-acfd359db3cb
DEBUG 01-15 10:09:43.715620.715620 cuda_h.py:19] end load_into_gpu_async cost 0.004379749298095703 seconds
DEBUG 01-15 10:09:43.715550.715550 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.716852.716852 cuda_h.py:19] end restore_tensors2 cost 0.0010180473327636719 seconds
DEBUG 01-15 10:09:43.717379.717379 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006691932678222656 seconds
DEBUG 01-15 10:09:43.717580.717580 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.720608.720608 cuda_h.py:19] end group_tensors cost 0.007074594497680664 seconds
DEBUG 01-15 10:09:43.721627.721627 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:43.722622.722622 cuda_h.py:19] end restore2model cost 0.005722999572753906 seconds
DEBUG 01-15 10:09:43.723063.723063 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012744426727294922 seconds
DEBUG 01-15 10:09:43.723700.723700 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:43.723474.723474 cuda_h.py:19] end gpu_sexperts cost 0.0005104541778564453 seconds
DEBUG 01-15 10:09:43.723265.723265 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:43.725352.725352 cuda_h.py:19] end group pad cost 0.003992557525634766 seconds
DEBUG 01-15 10:09:43.725056.725056 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:43.726527.726527 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0024123191833496094 seconds
DEBUG 01-15 10:09:43.727839.727839 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:43.727655.727655 cuda_h.py:19] end gpu_group_list cost 0.0003638267517089844 seconds
DEBUG 01-15 10:09:43.727157.727157 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:43.729315.729315 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011212825775146484 seconds
DEBUG 01-15 10:09:43.729244.729244 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:43.729471.729471 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-15 10:09:43.729505.729505 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:43.744843.744843 cuda_h.py:19] end group_einsum cost 0.01928091049194336 seconds
DEBUG 01-15 10:09:43.745107.745107 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:43.750984.750984 cuda_h.py:19] end get_outputs_cpu1 cost 0.005339860916137695 seconds
DEBUG 01-15 10:09:43.751082.751082 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03917694091796875 seconds
DEBUG 01-15 10:09:43.752302.752302 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.023342132568359375 seconds
DEBUG 01-15 10:09:43.752446.752446 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:43.753171.753171 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.753808.753808 cuda_h.py:19] end index_scatter cost 0.00015878677368164062 seconds
DEBUG 01-15 10:09:43.754891.754891 cuda_h.py:19] end cpuoutputsdeal cost 0.001153707504272461 seconds
DEBUG 01-15 10:09:43.754210.754210 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:43.754417.754417 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6dda09be-4330-4f67-b218-acfd359db3cb
INFO 01-15 10:09:43.767968.767968 client.py:127] Model loaded
DEBUG 01-15 10:09:43.767218.767218 cuda_h.py:19] end wait_experts cost 0.013818979263305664 seconds
DEBUG 01-15 10:09:43.768472.768472 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:43.768623.768623 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:43.768433.768433 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:43.768647.768647 cuda_h.py:19] end gpu_group_tensor cost 0.0003676414489746094 seconds
DEBUG 01-15 10:09:43.768217.768217 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:43.770769.770769 cuda_h.py:19] end gpu_group_einsum cost 0.0009758472442626953 seconds
DEBUG 01-15 10:09:43.770989.770989 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:43.770661.770661 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:43.771685.771685 cuda_h.py:19] end all_expert_outputs_slices cost 0.0008234977722167969 seconds
DEBUG 01-15 10:09:43.771257.771257 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:43.771984.771984 cuda_h.py:19] end concat_expert_out cost 0.0004918575286865234 seconds
DEBUG 01-15 10:09:43.772301.772301 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.772586.772586 cuda_h.py:19] end index_scatter cost 0.00013017654418945312 seconds
DEBUG 01-15 10:09:43.772933.772933 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.002012014389038086 seconds
DEBUG 01-15 10:09:43.772628.772628 cuda_h.py:19] end gpu_experts cost 0.0043566226959228516 seconds
DEBUG 01-15 10:09:43.772587.772587 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.06563234329223633 seconds
DEBUG 01-15 10:09:43.773932.773932 cuda_h.py:19] end prefill_layer cost 0.07745122909545898 seconds
DEBUG 01-15 10:09:43.773095.773095 lmp.py:1552] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-15 10:09:43.773746.773746 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.773927.773927 lmp.py:1495] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-15 10:09:43.773108.773108 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:43.773534.773534 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-15 10:09:43.773903.773903 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.198883056640625e-05 seconds
DEBUG 01-15 10:09:43.773236.773236 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 0.00014281272888183594 seconds
DEBUG 01-15 10:09:43.773264.773264 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.774627.774627 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.774707.774707 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.774602.774602 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.774137.774137 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.775966.775966 cuda_h.py:19] end allocate_cuda_memory cost 0.0005013942718505859 seconds
DEBUG 01-15 10:09:43.775104.775104 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.775041.775041 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.775680.775680 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.775115.775115 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eba1f6ef-9c4e-48b3-8148-fb850e46473c
DEBUG 01-15 10:09:43.776698.776698 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.776411.776411 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.777104.777104 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eba1f6ef-9c4e-48b3-8148-fb850e46473c
DEBUG 01-15 10:09:43.778945.778945 cuda_h.py:19] end load_into_gpu_async cost 0.002489328384399414 seconds
DEBUG 01-15 10:09:43.778438.778438 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.778771.778771 cuda_h.py:19] end restore_tensors2 cost 0.0001690387725830078 seconds
DEBUG 01-15 10:09:43.778934.778934 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038661956787109375 seconds
INFO 01-15 10:09:43.778529.778529 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eba1f6ef-9c4e-48b3-8148-fb850e46473c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:43.782580.782580 cuda_h.py:19] end self_attn cost 0.005883693695068359 seconds
DEBUG 01-15 10:09:43.783538.783538 cuda_h.py:19] end iln_self_attn_paln cost 0.009085655212402344 seconds
DEBUG 01-15 10:09:43.783375.783375 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-15 10:09:43.783834.783834 cuda_h.py:10] start gate
DEBUG 01-15 10:09:43.784314.784314 cuda_h.py:19] end gate cost 0.0010352134704589844 seconds
DEBUG 01-15 10:09:43.784629.784629 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:43.785232.785232 lmp.py:1616] 
DEBUG 01-15 10:09:43.785232.785232 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:43.785260.785260 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:43.785698.785698 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:43.785415.785415 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:43.785827.785827 lmp.py:1620] 
DEBUG 01-15 10:09:43.785827.785827 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:43.785968.785968 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:43.785254.785254 lmp.py:1626]   Expert  1 |     49 | CPU
DEBUG 01-15 10:09:43.785996.785996 lmp.py:1626]   Expert 27 |     62 | CPU
DEBUG 01-15 10:09:43.785023.785023 lmp.py:1626]   Expert  7 |     75 | CPU
DEBUG 01-15 10:09:43.785620.785620 lmp.py:1626]   Expert 48 |     82 | CPU
DEBUG 01-15 10:09:43.785740.785740 lmp.py:1626]   Expert 15 |     97 | CPU
DEBUG 01-15 10:09:43.785383.785383 lmp.py:1626]   Expert 30 |    108 | CPU
DEBUG 01-15 10:09:43.785787.785787 lmp.py:1626]   Expert 61 |    115 | CPU
DEBUG 01-15 10:09:43.785192.785192 lmp.py:1626]   Expert 45 |    118 | CPU
DEBUG 01-15 10:09:43.785311.785311 lmp.py:1626]   Expert 18 |    119 | CPU
DEBUG 01-15 10:09:43.785716.785716 lmp.py:1626]   Expert 32 |    119 | CPU
DEBUG 01-15 10:09:43.785121.785121 lmp.py:1626]   Expert 34 |    133 | CPU
DEBUG 01-15 10:09:43.785002.785002 lmp.py:1626]   Expert 39 |    136 | CPU
DEBUG 01-15 10:09:43.785883.785883 lmp.py:1626]   Expert 36 |    138 | CPU
DEBUG 01-15 10:09:43.785526.785526 lmp.py:1626]   Expert 11 |    139 | CPU
DEBUG 01-15 10:09:43.785169.785169 lmp.py:1626]   Expert  5 |    140 | CPU
DEBUG 01-15 10:09:43.785051.785051 lmp.py:1626]   Expert 26 |    140 | CPU
DEBUG 01-15 10:09:43.785124.785124 lmp.py:1626]   Expert 59 |    142 | CPU
DEBUG 01-15 10:09:43.785006.785006 lmp.py:1626]   Expert  6 |    143 | CPU
DEBUG 01-15 10:09:43.785649.785649 lmp.py:1626]   Expert 51 |    145 | CPU
DEBUG 01-15 10:09:43.785722.785722 lmp.py:1626]   Expert 49 |    155 | CPU
DEBUG 01-15 10:09:43.785557.785557 lmp.py:1626]   Expert 23 |    156 | CPU
DEBUG 01-15 10:09:43.785439.785439 lmp.py:1626]   Expert  2 |    157 | CPU
DEBUG 01-15 10:09:43.785843.785843 lmp.py:1626]   Expert  9 |    158 | CPU
DEBUG 01-15 10:09:43.785009.785009 lmp.py:1626]   Expert 50 |    165 | CPU
DEBUG 01-15 10:09:43.785414.785414 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:43.785057.785057 lmp.py:1626]   Expert 56 |    168 | CPU
DEBUG 01-15 10:09:43.785938.785938 lmp.py:1626]   Expert 40 |    169 | CPU
DEBUG 01-15 10:09:43.785343.785343 lmp.py:1626]   Expert 16 |    171 | CPU
DEBUG 01-15 10:09:43.785893.785893 lmp.py:1626]   Expert 35 |    173 | CPU
DEBUG 01-15 10:09:43.786159.786159 lmp.py:1626]   Expert  4 |    185 | CPU
DEBUG 01-15 10:09:43.786424.786424 lmp.py:1626]   Expert 13 |    191 | CPU
DEBUG 01-15 10:09:43.786120.786120 lmp.py:1626]   Expert 37 |    191 | CPU
DEBUG 01-15 10:09:43.786247.786247 lmp.py:1626]   Expert 42 |    191 | GPU
DEBUG 01-15 10:09:43.786466.786466 lmp.py:1626]   Expert 17 |    197 | GPU
DEBUG 01-15 10:09:43.786255.786255 lmp.py:1626]   Expert 38 |    197 | GPU
DEBUG 01-15 10:09:43.786282.786282 lmp.py:1626]   Expert 62 |    199 | GPU
DEBUG 01-15 10:09:43.786309.786309 lmp.py:1626]   Expert 21 |    202 | GPU
DEBUG 01-15 10:09:43.786336.786336 lmp.py:1626]   Expert  3 |    208 | GPU
DEBUG 01-15 10:09:43.786364.786364 lmp.py:1626]   Expert 44 |    210 | GPU
DEBUG 01-15 10:09:43.786106.786106 lmp.py:1626]   Expert 58 |    211 | GPU
DEBUG 01-15 10:09:43.786895.786895 lmp.py:1626]   Expert 60 |    211 | GPU
DEBUG 01-15 10:09:43.786160.786160 lmp.py:1626]   Expert 28 |    212 | GPU
DEBUG 01-15 10:09:43.786903.786903 lmp.py:1626]   Expert 47 |    214 | GPU
DEBUG 01-15 10:09:43.786645.786645 lmp.py:1626]   Expert 10 |    215 | GPU
DEBUG 01-15 10:09:43.786626.786626 lmp.py:1626]   Expert 53 |    218 | GPU
DEBUG 01-15 10:09:43.786607.786607 lmp.py:1626]   Expert 55 |    220 | GPU
DEBUG 01-15 10:09:43.786634.786634 lmp.py:1626]   Expert 20 |    223 | GPU
DEBUG 01-15 10:09:43.786661.786661 lmp.py:1626]   Expert 57 |    225 | GPU
DEBUG 01-15 10:09:43.786211.786211 lmp.py:1626]   Expert 33 |    228 | GPU
DEBUG 01-15 10:09:43.786477.786477 lmp.py:1626]   Expert 31 |    237 | GPU
DEBUG 01-15 10:09:43.786743.786743 lmp.py:1626]   Expert 46 |    237 | GPU
INFO 01-15 10:09:43.786787.786787 client.py:127] Model loaded
DEBUG 01-15 10:09:43.786408.786408 lmp.py:1626]   Expert  8 |    241 | GPU
DEBUG 01-15 10:09:43.786749.786749 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.786367.786367 lmp.py:1626]   Expert 19 |    242 | GPU
DEBUG 01-15 10:09:43.787358.787358 lmp.py:1626]   Expert 24 |    246 | GPU
DEBUG 01-15 10:09:43.787438.787438 lmp.py:1626]   Expert 14 |    263 | GPU
DEBUG 01-15 10:09:43.787657.787657 lmp.py:1626]   Expert 63 |    267 | GPU
DEBUG 01-15 10:09:43.787923.787923 lmp.py:1626]   Expert 29 |    275 | GPU
DEBUG 01-15 10:09:43.787904.787904 lmp.py:1626]   Expert 12 |    276 | GPU
DEBUG 01-15 10:09:43.787692.787692 lmp.py:1626]   Expert 22 |    278 | GPU
DEBUG 01-15 10:09:43.787389.787389 lmp.py:1626]   Expert  0 |    294 | GPU
DEBUG 01-15 10:09:43.787608.787608 lmp.py:1626]   Expert 43 |    309 | GPU
DEBUG 01-15 10:09:43.787873.787873 lmp.py:1626]   Expert 54 |    340 | GPU
DEBUG 01-15 10:09:43.787662.787662 lmp.py:1626]   Expert 41 |    385 | GPU
DEBUG 01-15 10:09:43.787689.787689 lmp.py:1626]   Expert 25 |    410 | GPU
DEBUG 01-15 10:09:43.787385.787385 lmp.py:1627] 
DEBUG 01-15 10:09:43.787385.787385 lmp.py:1627]   CPU total tokens: 4407 (35.9%)
DEBUG 01-15 10:09:43.787274.787274 lmp.py:1628]   GPU total tokens: 7881 (64.1%)
DEBUG 01-15 10:09:43.787314.787314 cuda_h.py:19] end experts_map_get cost 0.0030159950256347656 seconds
DEBUG 01-15 10:09:43.787307.787307 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:43.787891.787891 lmp.py:1636] 
DEBUG 01-15 10:09:43.787891.787891 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:43.787456.787456 cuda_h.py:19] end cpu_experts_submit cost 6.67572021484375e-05 seconds
DEBUG 01-15 10:09:43.787921.787921 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:43.787817.787817 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.788380.788380 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.788117.788117 cuda_h.py:19] end allocate_cuda_memory cost 0.00022339820861816406 seconds
DEBUG 01-15 10:09:43.788418.788418 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.788042.788042 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.788818.788818 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.788609.788609 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 25f706f3-6988-4733-a8c2-e48c3d9e09f7
DEBUG 01-15 10:09:43.788815.788815 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.789466.789466 cuda_h.py:19] end restore2model cost 0.002813100814819336 seconds
DEBUG 01-15 10:09:43.790465.790465 cuda_h.py:19] end sllm_worker_task cost 0.015511751174926758 seconds
INFO 01-15 10:09:43.790612.790612 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 25f706f3-6988-4733-a8c2-e48c3d9e09f7
DEBUG 01-15 10:09:43.791386.791386 cuda_h.py:19] end load_into_gpu_async cost 0.0025510787963867188 seconds
DEBUG 01-15 10:09:43.791508.791508 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.791349.791349 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:43.791153.791153 cuda_h.py:19] end restore_tensors2 cost 0.00078582763671875 seconds
DEBUG 01-15 10:09:43.792917.792917 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0041544437408447266 seconds
DEBUG 01-15 10:09:43.792760.792760 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.792255.792255 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:43.793838.793838 cuda_h.py:19] end move_flatidxs cost 0.0012242794036865234 seconds
DEBUG 01-15 10:09:43.793670.793670 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:43.795639.795639 cuda_h.py:19] end restore2model cost 0.003282785415649414 seconds
DEBUG 01-15 10:09:43.795019.795019 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076639652252197266 seconds
DEBUG 01-15 10:09:43.795292.795292 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:43.795223.795223 cuda_h.py:19] end gpu_sexperts cost 0.0003046989440917969 seconds
DEBUG 01-15 10:09:43.795152.795152 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:43.797220.797220 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0019800662994384766 seconds
DEBUG 01-15 10:09:43.798354.798354 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:43.799778.799778 cuda_h.py:19] end gpu_group_list cost 0.00031948089599609375 seconds
DEBUG 01-15 10:09:43.799332.799332 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:43.800200.800200 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009827613830566406 seconds
DEBUG 01-15 10:09:43.800553.800553 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:43.800628.800628 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1696090698242188e-05 seconds
DEBUG 01-15 10:09:43.800993.800993 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:43.803581.803581 cuda_h.py:19] end group_tensors cost 0.009928226470947266 seconds
DEBUG 01-15 10:09:43.804520.804520 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:43.809538.809538 cuda_h.py:19] end group pad cost 0.004612922668457031 seconds
DEBUG 01-15 10:09:43.809693.809693 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:43.832243.832243 cuda_h.py:19] end group_einsum cost 0.02268052101135254 seconds
DEBUG 01-15 10:09:43.832686.832686 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:43.837845.837845 cuda_h.py:19] end get_outputs_cpu1 cost 0.0054473876953125 seconds
DEBUG 01-15 10:09:43.838249.838249 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.047113895416259766 seconds
DEBUG 01-15 10:09:43.839840.839840 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03907322883605957 seconds
DEBUG 01-15 10:09:43.839699.839699 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:43.840980.840980 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.840177.840177 cuda_h.py:19] end index_scatter cost 8.7738037109375e-05 seconds
DEBUG 01-15 10:09:43.841236.841236 cuda_h.py:19] end cpuoutputsdeal cost 0.0011584758758544922 seconds
DEBUG 01-15 10:09:43.841940.841940 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:43.841663.841663 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 25f706f3-6988-4733-a8c2-e48c3d9e09f7
INFO 01-15 10:09:43.842006.842006 client.py:127] Model loaded
DEBUG 01-15 10:09:43.842187.842187 cuda_h.py:19] end wait_experts cost 0.0010254383087158203 seconds
DEBUG 01-15 10:09:43.842990.842990 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:43.842700.842700 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:43.842602.842602 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:43.842504.842504 cuda_h.py:19] end gpu_group_tensor cost 0.0002148151397705078 seconds
DEBUG 01-15 10:09:43.842707.842707 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:43.843448.843448 cuda_h.py:19] end gpu_group_einsum cost 0.0005357265472412109 seconds
DEBUG 01-15 10:09:43.843128.843128 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:43.843103.843103 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:43.843742.843742 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002655982971191406 seconds
DEBUG 01-15 10:09:43.843306.843306 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:43.843799.843799 cuda_h.py:19] end concat_expert_out cost 5.269050598144531e-05 seconds
DEBUG 01-15 10:09:43.843211.843211 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.844664.844664 cuda_h.py:19] end index_scatter cost 5.555152893066406e-05 seconds
DEBUG 01-15 10:09:43.844851.844851 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006003379821777344 seconds
DEBUG 01-15 10:09:43.844006.844006 cuda_h.py:19] end gpu_experts cost 0.0018455982208251953 seconds
DEBUG 01-15 10:09:43.844591.844591 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.06099677085876465 seconds
DEBUG 01-15 10:09:43.844537.844537 cuda_h.py:19] end prefill_layer cost 0.07124090194702148 seconds
DEBUG 01-15 10:09:43.844328.844328 lmp.py:1552] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-15 10:09:43.844177.844177 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.844787.844787 lmp.py:1495] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-15 10:09:43.844159.844159 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:43.844584.844584 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-15 10:09:43.845441.845441 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 4.100799560546875e-05 seconds
DEBUG 01-15 10:09:43.845958.845958 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.43865966796875e-05 seconds
DEBUG 01-15 10:09:43.845323.845323 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.845782.845782 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.845152.845152 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.845167.845167 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.845734.845734 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.845368.845368 cuda_h.py:19] end allocate_cuda_memory cost 0.0002856254577636719 seconds
DEBUG 01-15 10:09:43.845701.845701 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.845464.845464 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.846539.846539 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.846579.846579 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5f3690bd-f2af-40f9-a3fe-2e4d0ef9cf33
DEBUG 01-15 10:09:43.846954.846954 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.846766.846766 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.846119.846119 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5f3690bd-f2af-40f9-a3fe-2e4d0ef9cf33
DEBUG 01-15 10:09:43.847122.847122 cuda_h.py:19] end load_into_gpu_async cost 0.0010449886322021484 seconds
DEBUG 01-15 10:09:43.847215.847215 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.847054.847054 cuda_h.py:19] end restore_tensors2 cost 8.702278137207031e-05 seconds
DEBUG 01-15 10:09:43.847963.847963 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017077922821044922 seconds
INFO 01-15 10:09:43.847687.847687 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5f3690bd-f2af-40f9-a3fe-2e4d0ef9cf33
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:43.850579.850579 cuda_h.py:19] end self_attn cost 0.003662109375 seconds
DEBUG 01-15 10:09:43.850854.850854 cuda_h.py:19] end iln_self_attn_paln cost 0.005262851715087891 seconds
DEBUG 01-15 10:09:43.850313.850313 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-15 10:09:43.850169.850169 cuda_h.py:10] start gate
DEBUG 01-15 10:09:43.851908.851908 cuda_h.py:19] end gate cost 0.0006854534149169922 seconds
DEBUG 01-15 10:09:43.851930.851930 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:43.851563.851563 lmp.py:1616] 
DEBUG 01-15 10:09:43.851563.851563 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:43.851849.851849 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:43.851214.851214 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:43.851764.851764 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:43.851646.851646 lmp.py:1620] 
DEBUG 01-15 10:09:43.851646.851646 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:43.851766.851766 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:43.851316.851316 lmp.py:1626]   Expert 14 |     66 | CPU
DEBUG 01-15 10:09:43.851197.851197 lmp.py:1626]   Expert 57 |     73 | CPU
DEBUG 01-15 10:09:43.851363.851363 lmp.py:1626]   Expert 13 |     75 | CPU
DEBUG 01-15 10:09:43.851053.851053 lmp.py:1626]   Expert 26 |     81 | CPU
DEBUG 01-15 10:09:43.851457.851457 lmp.py:1626]   Expert 54 |     91 | CPU
DEBUG 01-15 10:09:43.851147.851147 lmp.py:1626]   Expert 31 |     92 | CPU
DEBUG 01-15 10:09:43.851597.851597 lmp.py:1626]   Expert 11 |     93 | CPU
DEBUG 01-15 10:09:43.851810.851810 lmp.py:1626]   Expert 45 |     93 | CPU
DEBUG 01-15 10:09:43.851499.851499 lmp.py:1626]   Expert 58 |    103 | CPU
DEBUG 01-15 10:09:43.851188.851188 lmp.py:1626]   Expert 30 |    106 | CPU
DEBUG 01-15 10:09:43.851355.851355 lmp.py:1626]   Expert 51 |    108 | CPU
DEBUG 01-15 10:09:43.851282.851282 lmp.py:1626]   Expert 36 |    112 | CPU
DEBUG 01-15 10:09:43.852210.852210 lmp.py:1626]   Expert 10 |    114 | CPU
DEBUG 01-15 10:09:43.852615.852615 lmp.py:1626]   Expert 32 |    115 | CPU
DEBUG 01-15 10:09:43.852065.852065 lmp.py:1626]   Expert 20 |    125 | CPU
DEBUG 01-15 10:09:43.852755.852755 lmp.py:1626]   Expert  8 |    134 | CPU
DEBUG 01-15 10:09:43.852206.852206 lmp.py:1626]   Expert 63 |    137 | CPU
DEBUG 01-15 10:09:43.852657.852657 lmp.py:1626]   Expert  4 |    138 | CPU
DEBUG 01-15 10:09:43.852869.852869 lmp.py:1626]   Expert 53 |    141 | CPU
DEBUG 01-15 10:09:43.852081.852081 lmp.py:1626]   Expert 34 |    143 | CPU
DEBUG 01-15 10:09:43.852532.852532 lmp.py:1626]   Expert 61 |    144 | CPU
DEBUG 01-15 10:09:43.852222.852222 lmp.py:1626]   Expert 16 |    147 | CPU
DEBUG 01-15 10:09:43.852196.852196 lmp.py:1626]   Expert 47 |    148 | CPU
DEBUG 01-15 10:09:43.852647.852647 lmp.py:1626]   Expert 28 |    158 | CPU
DEBUG 01-15 10:09:43.852574.852574 lmp.py:1626]   Expert 60 |    159 | CPU
DEBUG 01-15 10:09:43.852979.852979 lmp.py:1626]   Expert 17 |    162 | CPU
DEBUG 01-15 10:09:43.852145.852145 lmp.py:1626]   Expert 42 |    163 | CPU
DEBUG 01-15 10:09:43.852550.852550 lmp.py:1626]   Expert 29 |    170 | CPU
DEBUG 01-15 10:09:43.852477.852477 lmp.py:1626]   Expert 44 |    171 | CPU
DEBUG 01-15 10:09:43.852928.852928 lmp.py:1626]   Expert 27 |    175 | CPU
DEBUG 01-15 10:09:43.852617.852617 lmp.py:1626]   Expert  7 |    178 | CPU
DEBUG 01-15 10:09:43.852068.852068 lmp.py:1626]   Expert 41 |    179 | CPU
DEBUG 01-15 10:09:43.852758.852758 lmp.py:1626]   Expert 48 |    184 | GPU
DEBUG 01-15 10:09:43.852970.852970 lmp.py:1626]   Expert 56 |    184 | GPU
DEBUG 01-15 10:09:43.852481.852481 lmp.py:1626]   Expert  9 |    185 | GPU
DEBUG 01-15 10:09:43.852124.852124 lmp.py:1626]   Expert  2 |    187 | GPU
DEBUG 01-15 10:09:43.852813.852813 lmp.py:1626]   Expert  3 |    189 | GPU
DEBUG 01-15 10:09:43.852264.852264 lmp.py:1626]   Expert 15 |    191 | GPU
DEBUG 01-15 10:09:43.852477.852477 lmp.py:1626]   Expert 24 |    193 | GPU
DEBUG 01-15 10:09:43.852927.852927 lmp.py:1626]   Expert  0 |    194 | GPU
DEBUG 01-15 10:09:43.852378.852378 lmp.py:1626]   Expert 18 |    200 | GPU
DEBUG 01-15 10:09:43.852591.852591 lmp.py:1626]   Expert 55 |    207 | GPU
DEBUG 01-15 10:09:43.852042.852042 lmp.py:1626]   Expert 40 |    214 | GPU
DEBUG 01-15 10:09:43.852493.852493 lmp.py:1626]   Expert 23 |    215 | GPU
DEBUG 01-15 10:09:43.852467.852467 lmp.py:1626]   Expert 38 |    216 | GPU
DEBUG 01-15 10:09:43.852917.852917 lmp.py:1626]   Expert 22 |    217 | GPU
DEBUG 01-15 10:09:43.852891.852891 lmp.py:1626]   Expert 37 |    222 | GPU
DEBUG 01-15 10:09:43.852104.852104 lmp.py:1626]   Expert  6 |    224 | GPU
DEBUG 01-15 10:09:43.852316.852316 lmp.py:1626]   Expert 46 |    231 | GPU
DEBUG 01-15 10:09:43.852529.852529 lmp.py:1626]   Expert 19 |    242 | GPU
DEBUG 01-15 10:09:43.852503.852503 lmp.py:1626]   Expert 39 |    249 | GPU
DEBUG 01-15 10:09:43.852715.852715 lmp.py:1626]   Expert 25 |    251 | GPU
DEBUG 01-15 10:09:43.852451.852451 lmp.py:1626]   Expert 12 |    258 | GPU
DEBUG 01-15 10:09:43.852425.852425 lmp.py:1626]   Expert 50 |    259 | GPU
DEBUG 01-15 10:09:43.852638.852638 lmp.py:1626]   Expert 62 |    270 | GPU
DEBUG 01-15 10:09:43.852804.852804 lmp.py:1626]   Expert 21 |    279 | GPU
DEBUG 01-15 10:09:43.852970.852970 lmp.py:1626]   Expert 35 |    287 | GPU
DEBUG 01-15 10:09:43.852136.852136 lmp.py:1626]   Expert 49 |    292 | GPU
DEBUG 01-15 10:09:43.852733.852733 lmp.py:1626]   Expert 33 |    298 | GPU
DEBUG 01-15 10:09:43.852137.852137 lmp.py:1626]   Expert 52 |    300 | GPU
DEBUG 01-15 10:09:43.852303.852303 lmp.py:1626]   Expert  1 |    348 | GPU
DEBUG 01-15 10:09:43.852469.852469 lmp.py:1626]   Expert  5 |    385 | GPU
DEBUG 01-15 10:09:43.852397.852397 lmp.py:1626]   Expert 43 |    438 | GPU
DEBUG 01-15 10:09:43.852325.852325 lmp.py:1626]   Expert 59 |    585 | GPU
DEBUG 01-15 10:09:43.852206.852206 lmp.py:1627] 
DEBUG 01-15 10:09:43.852206.852206 lmp.py:1627]   CPU total tokens: 4094 (33.3%)
DEBUG 01-15 10:09:43.852803.852803 lmp.py:1628]   GPU total tokens: 8194 (66.7%)
DEBUG 01-15 10:09:43.852453.852453 cuda_h.py:19] end experts_map_get cost 0.0015511512756347656 seconds
DEBUG 01-15 10:09:43.853071.853071 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:43.853158.853158 lmp.py:1636] 
DEBUG 01-15 10:09:43.853158.853158 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:43.853094.853094 cuda_h.py:19] end cpu_experts_submit cost 5.698204040527344e-05 seconds
DEBUG 01-15 10:09:43.853598.853598 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:43.853725.853725 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.853996.853996 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.854005.854005 cuda_h.py:19] end allocate_cuda_memory cost 0.0010275840759277344 seconds
DEBUG 01-15 10:09:43.854232.854232 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.854750.854750 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.854281.854281 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.854600.854600 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42da29ec-649f-4280-8e96-fc8314ee098a
DEBUG 01-15 10:09:43.854415.854415 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:43.855759.855759 client.py:127] Model loaded
DEBUG 01-15 10:09:43.855708.855708 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.855123.855123 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:43.855460.855460 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:43.855670.855670 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42da29ec-649f-4280-8e96-fc8314ee098a
DEBUG 01-15 10:09:43.855235.855235 cuda_h.py:19] end restore2model cost 0.0004551410675048828 seconds
DEBUG 01-15 10:09:43.855747.855747 cuda_h.py:19] end load_into_gpu_async cost 0.0012919902801513672 seconds
DEBUG 01-15 10:09:43.855510.855510 cuda_h.py:19] end sllm_worker_task cost 0.01044464111328125 seconds
DEBUG 01-15 10:09:43.855001.855001 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.856843.856843 cuda_h.py:19] end restore_tensors2 cost 0.0005245208740234375 seconds
DEBUG 01-15 10:09:43.856592.856592 cuda_h.py:19] end move_flatidxs cost 0.0009198188781738281 seconds
DEBUG 01-15 10:09:43.856276.856276 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:43.856799.856799 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033652782440185547 seconds
DEBUG 01-15 10:09:43.856569.856569 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.859563.859563 cuda_h.py:19] end restore2model cost 0.0027742385864257812 seconds
DEBUG 01-15 10:09:43.859374.859374 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00634455680847168 seconds
DEBUG 01-15 10:09:43.859646.859646 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:43.859835.859835 cuda_h.py:19] end gpu_sexperts cost 0.00028443336486816406 seconds
DEBUG 01-15 10:09:43.859903.859903 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:43.861357.861357 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016336441040039062 seconds
DEBUG 01-15 10:09:43.862064.862064 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:43.861059.861059 cuda_h.py:19] end group_tensors cost 0.005350589752197266 seconds
DEBUG 01-15 10:09:43.862448.862448 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:43.862829.862829 cuda_h.py:19] end gpu_group_list cost 0.0003905296325683594 seconds
DEBUG 01-15 10:09:43.863613.863613 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:43.864668.864668 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0011816024780273438 seconds
DEBUG 01-15 10:09:43.864068.864068 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:43.864388.864388 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-15 10:09:43.864482.864482 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:43.866331.866331 cuda_h.py:19] end group pad cost 0.003971099853515625 seconds
DEBUG 01-15 10:09:43.866121.866121 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:43.887322.887322 cuda_h.py:19] end group_einsum cost 0.020359516143798828 seconds
DEBUG 01-15 10:09:43.887202.887202 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:43.892031.892031 cuda_h.py:19] end get_outputs_cpu1 cost 0.005104541778564453 seconds
DEBUG 01-15 10:09:43.893090.893090 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03789925575256348 seconds
DEBUG 01-15 10:09:43.894287.894287 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.029507875442504883 seconds
DEBUG 01-15 10:09:43.894434.894434 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:43.894960.894960 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.895434.895434 cuda_h.py:19] end index_scatter cost 0.00017547607421875 seconds
DEBUG 01-15 10:09:43.896816.896816 cuda_h.py:19] end cpuoutputsdeal cost 0.0016126632690429688 seconds
DEBUG 01-15 10:09:43.896740.896740 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:43.896620.896620 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42da29ec-649f-4280-8e96-fc8314ee098a
INFO 01-15 10:09:43.906004.906004 client.py:127] Model loaded
DEBUG 01-15 10:09:43.906069.906069 cuda_h.py:19] end wait_experts cost 0.010451078414916992 seconds
DEBUG 01-15 10:09:43.907416.907416 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:43.907222.907222 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:43.907999.907999 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:43.908840.908840 cuda_h.py:19] end gpu_group_tensor cost 0.0014221668243408203 seconds
DEBUG 01-15 10:09:43.909061.909061 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:43.911406.911406 cuda_h.py:19] end gpu_group_einsum cost 0.0016429424285888672 seconds
DEBUG 01-15 10:09:43.911184.911184 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:43.911282.911282 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:43.912974.912974 cuda_h.py:19] end all_expert_outputs_slices cost 0.0010132789611816406 seconds
DEBUG 01-15 10:09:43.912620.912620 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:43.912668.912668 cuda_h.py:19] end concat_expert_out cost 0.00015997886657714844 seconds
DEBUG 01-15 10:09:43.913237.913237 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.913219.913219 cuda_h.py:19] end index_scatter cost 0.00017309188842773438 seconds
DEBUG 01-15 10:09:43.913447.913447 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.002011537551879883 seconds
DEBUG 01-15 10:09:43.913990.913990 cuda_h.py:19] end gpu_experts cost 0.006596803665161133 seconds
DEBUG 01-15 10:09:43.913375.913375 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.06330728530883789 seconds
DEBUG 01-15 10:09:43.914283.914283 cuda_h.py:19] end prefill_layer cost 0.06976056098937988 seconds
DEBUG 01-15 10:09:43.914586.914586 lmp.py:1552] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-15 10:09:43.914065.914065 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.915790.915790 lmp.py:1495] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-15 10:09:43.915799.915799 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:43.915338.915338 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-15 10:09:43.915317.915317 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.2479248046875e-05 seconds
DEBUG 01-15 10:09:43.915474.915474 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.915400.915400 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 0.0003819465637207031 seconds
DEBUG 01-15 10:09:43.915890.915890 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.915013.915013 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.916296.916296 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.916671.916671 cuda_h.py:19] end allocate_cuda_memory cost 0.00032210350036621094 seconds
DEBUG 01-15 10:09:43.916290.916290 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.916736.916736 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.916870.916870 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.916494.916494 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 23001e0c-cc20-4484-ae27-2b839324a6ad
DEBUG 01-15 10:09:43.916333.916333 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.917334.917334 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.917134.917134 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.917000.917000 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 23001e0c-cc20-4484-ae27-2b839324a6ad
DEBUG 01-15 10:09:43.918001.918001 cuda_h.py:19] end load_into_gpu_async cost 0.0013849735260009766 seconds
DEBUG 01-15 10:09:43.918393.918393 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.918868.918868 cuda_h.py:19] end restore_tensors2 cost 0.00010633468627929688 seconds
DEBUG 01-15 10:09:43.918068.918068 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023310184478759766 seconds
INFO 01-15 10:09:43.918065.918065 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 23001e0c-cc20-4484-ae27-2b839324a6ad
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:43.923670.923670 cuda_h.py:19] end self_attn cost 0.005642414093017578 seconds
DEBUG 01-15 10:09:43.924530.924530 cuda_h.py:19] end iln_self_attn_paln cost 0.008051156997680664 seconds
DEBUG 01-15 10:09:43.924427.924427 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-15 10:09:43.924052.924052 cuda_h.py:10] start gate
DEBUG 01-15 10:09:43.925030.925030 cuda_h.py:19] end gate cost 0.001043081283569336 seconds
DEBUG 01-15 10:09:43.925238.925238 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:43.926485.926485 lmp.py:1616] 
DEBUG 01-15 10:09:43.926485.926485 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:43.926136.926136 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:43.926336.926336 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:43.926675.926675 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:43.926498.926498 lmp.py:1620] 
DEBUG 01-15 10:09:43.926498.926498 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:43.926121.926121 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:43.926891.926891 lmp.py:1626]   Expert 34 |     23 | CPU
DEBUG 01-15 10:09:43.926323.926323 lmp.py:1626]   Expert 45 |     65 | CPU
DEBUG 01-15 10:09:43.926324.926324 lmp.py:1626]   Expert 22 |     74 | CPU
DEBUG 01-15 10:09:43.926848.926848 lmp.py:1626]   Expert 57 |     77 | CPU
DEBUG 01-15 10:09:43.926611.926611 lmp.py:1626]   Expert 17 |     95 | CPU
DEBUG 01-15 10:09:43.926136.926136 lmp.py:1626]   Expert 15 |     99 | CPU
DEBUG 01-15 10:09:43.926044.926044 lmp.py:1626]   Expert  4 |    101 | CPU
DEBUG 01-15 10:09:43.927999.927999 lmp.py:1626]   Expert 28 |    106 | CPU
DEBUG 01-15 10:09:43.927715.927715 lmp.py:1626]   Expert 60 |    111 | CPU
DEBUG 01-15 10:09:43.927763.927763 lmp.py:1626]   Expert 32 |    112 | CPU
DEBUG 01-15 10:09:43.927095.927095 lmp.py:1626]   Expert 36 |    124 | CPU
DEBUG 01-15 10:09:43.927143.927143 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:43.927713.927713 lmp.py:1626]   Expert 12 |    128 | CPU
DEBUG 01-15 10:09:43.927238.927238 lmp.py:1626]   Expert 14 |    128 | CPU
DEBUG 01-15 10:09:43.927431.927431 lmp.py:1626]   Expert 52 |    130 | CPU
DEBUG 01-15 10:09:43.927671.927671 lmp.py:1626]   Expert 25 |    131 | CPU
DEBUG 01-15 10:09:43.927718.927718 lmp.py:1626]   Expert  8 |    135 | CPU
DEBUG 01-15 10:09:43.927004.927004 lmp.py:1626]   Expert  2 |    139 | CPU
DEBUG 01-15 10:09:43.927575.927575 lmp.py:1626]   Expert 35 |    143 | CPU
DEBUG 01-15 10:09:43.927384.927384 lmp.py:1626]   Expert  5 |    148 | CPU
DEBUG 01-15 10:09:43.927908.927908 lmp.py:1626]   Expert 23 |    154 | CPU
DEBUG 01-15 10:09:43.927194.927194 lmp.py:1626]   Expert 30 |    154 | CPU
DEBUG 01-15 10:09:43.927003.927003 lmp.py:1626]   Expert 39 |    156 | CPU
DEBUG 01-15 10:09:43.927813.927813 lmp.py:1626]   Expert 61 |    157 | CPU
DEBUG 01-15 10:09:43.927668.927668 lmp.py:1626]   Expert  0 |    158 | CPU
DEBUG 01-15 10:09:43.927503.927503 lmp.py:1626]   Expert  3 |    169 | CPU
DEBUG 01-15 10:09:43.927530.927530 lmp.py:1626]   Expert 13 |    171 | CPU
DEBUG 01-15 10:09:43.927842.927842 lmp.py:1626]   Expert 42 |    171 | CPU
DEBUG 01-15 10:09:43.927439.927439 lmp.py:1626]   Expert 31 |    173 | CPU
DEBUG 01-15 10:09:43.927797.927797 lmp.py:1626]   Expert 44 |    174 | CPU
DEBUG 01-15 10:09:43.927347.927347 lmp.py:1626]   Expert  9 |    176 | CPU
DEBUG 01-15 10:09:43.927182.927182 lmp.py:1626]   Expert 41 |    176 | CPU
DEBUG 01-15 10:09:43.927256.927256 lmp.py:1626]   Expert 46 |    178 | GPU
DEBUG 01-15 10:09:43.927091.927091 lmp.py:1626]   Expert 43 |    182 | GPU
DEBUG 01-15 10:09:43.927926.927926 lmp.py:1626]   Expert 62 |    190 | GPU
DEBUG 01-15 10:09:43.927284.927284 lmp.py:1626]   Expert 26 |    192 | GPU
DEBUG 01-15 10:09:43.927881.927881 lmp.py:1626]   Expert 27 |    192 | GPU
DEBUG 01-15 10:09:43.927716.927716 lmp.py:1626]   Expert 50 |    192 | GPU
DEBUG 01-15 10:09:43.927551.927551 lmp.py:1626]   Expert 18 |    194 | GPU
DEBUG 01-15 10:09:43.927578.927578 lmp.py:1626]   Expert 51 |    194 | GPU
DEBUG 01-15 10:09:43.927367.927367 lmp.py:1626]   Expert 49 |    196 | GPU
DEBUG 01-15 10:09:43.927255.927255 lmp.py:1626]   Expert 11 |    198 | GPU
DEBUG 01-15 10:09:43.927567.927567 lmp.py:1626]   Expert 47 |    202 | GPU
DEBUG 01-15 10:09:43.927164.927164 lmp.py:1626]   Expert 19 |    204 | GPU
DEBUG 01-15 10:09:43.927760.927760 lmp.py:1626]   Expert 20 |    205 | GPU
DEBUG 01-15 10:09:43.928357.928357 lmp.py:1626]   Expert 63 |    207 | GPU
DEBUG 01-15 10:09:43.928477.928477 lmp.py:1626]   Expert 55 |    208 | GPU
DEBUG 01-15 10:09:43.928789.928789 lmp.py:1626]   Expert 56 |    211 | GPU
DEBUG 01-15 10:09:43.928101.928101 lmp.py:1626]   Expert 38 |    217 | GPU
DEBUG 01-15 10:09:43.928889.928889 lmp.py:1626]   Expert 48 |    231 | GPU
DEBUG 01-15 10:09:43.928678.928678 lmp.py:1626]   Expert  1 |    236 | GPU
DEBUG 01-15 10:09:43.928752.928752 lmp.py:1626]   Expert 10 |    240 | GPU
DEBUG 01-15 10:09:43.928348.928348 lmp.py:1626]   Expert  7 |    248 | GPU
DEBUG 01-15 10:09:43.928183.928183 lmp.py:1626]   Expert 54 |    248 | GPU
DEBUG 01-15 10:09:43.928780.928780 lmp.py:1626]   Expert 21 |    249 | GPU
DEBUG 01-15 10:09:43.928615.928615 lmp.py:1626]   Expert 33 |    255 | GPU
DEBUG 01-15 10:09:43.928450.928450 lmp.py:1626]   Expert 29 |    260 | GPU
DEBUG 01-15 10:09:43.928047.928047 lmp.py:1626]   Expert 40 |    265 | GPU
DEBUG 01-15 10:09:43.928359.928359 lmp.py:1626]   Expert 24 |    270 | GPU
DEBUG 01-15 10:09:43.928624.928624 lmp.py:1626]   Expert 59 |    301 | GPU
DEBUG 01-15 10:09:43.928651.928651 lmp.py:1626]   Expert 37 |    332 | GPU
DEBUG 01-15 10:09:43.928917.928917 lmp.py:1626]   Expert 58 |    366 | GPU
DEBUG 01-15 10:09:43.928467.928467 lmp.py:1626]   Expert  6 |    387 | GPU
DEBUG 01-15 10:09:43.928018.928018 lmp.py:1626]   Expert 53 |    854 | GPU
DEBUG 01-15 10:09:43.928806.928806 lmp.py:1627] 
DEBUG 01-15 10:09:43.928806.928806 lmp.py:1627]   CPU total tokens: 4184 (34.0%)
DEBUG 01-15 10:09:43.928940.928940 lmp.py:1628]   GPU total tokens: 8104 (66.0%)
DEBUG 01-15 10:09:43.928378.928378 cuda_h.py:19] end experts_map_get cost 0.0027513504028320312 seconds
INFO 01-15 10:09:43.928925.928925 client.py:127] Model loaded
DEBUG 01-15 10:09:43.928419.928419 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:43.928787.928787 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.928597.928597 lmp.py:1636] 
DEBUG 01-15 10:09:43.928597.928597 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:43.929051.929051 cuda_h.py:19] end cpu_experts_submit cost 0.0003056526184082031 seconds
DEBUG 01-15 10:09:43.929376.929376 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:43.929134.929134 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.929657.929657 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.929363.929363 cuda_h.py:19] end allocate_cuda_memory cost 0.0002684593200683594 seconds
DEBUG 01-15 10:09:43.930360.930360 cuda_h.py:19] end restore2model cost 0.001505136489868164 seconds
DEBUG 01-15 10:09:43.930197.930197 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.931240.931240 cuda_h.py:19] end sllm_worker_task cost 0.01523280143737793 seconds
DEBUG 01-15 10:09:43.931417.931417 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.931893.931893 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.931649.931649 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e03fab3-b5d3-4e06-a058-b84aa24959ee
DEBUG 01-15 10:09:43.931814.931814 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:43.931544.931544 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.931709.931709 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:43.932011.932011 cuda_h.py:19] end move_flatidxs cost 0.0010180473327636719 seconds
DEBUG 01-15 10:09:43.932543.932543 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:43.933377.933377 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e03fab3-b5d3-4e06-a058-b84aa24959ee
DEBUG 01-15 10:09:43.933249.933249 cuda_h.py:19] end load_into_gpu_async cost 0.002114534378051758 seconds
DEBUG 01-15 10:09:43.933934.933934 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.933624.933624 cuda_h.py:19] end restore_tensors2 cost 0.0005426406860351562 seconds
DEBUG 01-15 10:09:43.934474.934474 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0047838687896728516 seconds
DEBUG 01-15 10:09:43.934734.934734 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.942858.942858 cuda_h.py:19] end restore2model cost 0.007900238037109375 seconds
DEBUG 01-15 10:09:43.942903.942903 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.013141155242919922 seconds
DEBUG 01-15 10:09:43.942891.942891 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:43.942447.942447 cuda_h.py:19] end gpu_sexperts cost 0.0005526542663574219 seconds
DEBUG 01-15 10:09:43.943767.943767 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:43.945591.945591 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002004861831665039 seconds
DEBUG 01-15 10:09:43.946541.946541 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:43.946482.946482 cuda_h.py:19] end gpu_group_list cost 0.0003523826599121094 seconds
DEBUG 01-15 10:09:43.946519.946519 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:43.947463.947463 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010387897491455078 seconds
DEBUG 01-15 10:09:43.947227.947227 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:43.947157.947157 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.459785461425781e-05 seconds
DEBUG 01-15 10:09:43.947860.947860 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:43.947134.947134 cuda_h.py:19] end group_tensors cost 0.014812231063842773 seconds
DEBUG 01-15 10:09:43.948168.948168 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:43.952892.952892 cuda_h.py:19] end group pad cost 0.004164934158325195 seconds
DEBUG 01-15 10:09:43.952742.952742 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:43.974089.974089 cuda_h.py:19] end group_einsum cost 0.021542072296142578 seconds
DEBUG 01-15 10:09:43.974730.974730 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:43.979334.979334 cuda_h.py:19] end get_outputs_cpu1 cost 0.004900693893432617 seconds
DEBUG 01-15 10:09:43.980698.980698 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0488736629486084 seconds
DEBUG 01-15 10:09:43.981779.981779 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03372645378112793 seconds
DEBUG 01-15 10:09:43.981247.981247 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:43.982806.982806 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.982778.982778 cuda_h.py:19] end index_scatter cost 9.179115295410156e-05 seconds
DEBUG 01-15 10:09:43.982763.982763 cuda_h.py:19] end cpuoutputsdeal cost 0.0007236003875732422 seconds
DEBUG 01-15 10:09:43.982553.982553 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:43.982707.982707 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e03fab3-b5d3-4e06-a058-b84aa24959ee
INFO 01-15 10:09:43.984556.984556 client.py:127] Model loaded
DEBUG 01-15 10:09:43.984280.984280 cuda_h.py:19] end wait_experts cost 0.0019063949584960938 seconds
DEBUG 01-15 10:09:43.984705.984705 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:43.984814.984814 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:43.984192.984192 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:43.985016.985016 cuda_h.py:19] end gpu_group_tensor cost 0.00022268295288085938 seconds
DEBUG 01-15 10:09:43.985947.985947 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:43.986406.986406 cuda_h.py:19] end gpu_group_einsum cost 0.0012018680572509766 seconds
DEBUG 01-15 10:09:43.986907.986907 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:43.986035.986035 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:43.986648.986648 cuda_h.py:19] end all_expert_outputs_slices cost 0.00026988983154296875 seconds
DEBUG 01-15 10:09:43.986218.986218 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:43.987493.987493 cuda_h.py:19] end concat_expert_out cost 6.270408630371094e-05 seconds
DEBUG 01-15 10:09:43.987336.987336 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:43.987459.987459 cuda_h.py:19] end index_scatter cost 5.626678466796875e-05 seconds
DEBUG 01-15 10:09:43.987221.987221 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006477832794189453 seconds
DEBUG 01-15 10:09:43.987033.987033 cuda_h.py:19] end gpu_experts cost 0.0026345252990722656 seconds
DEBUG 01-15 10:09:43.987606.987606 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06302475929260254 seconds
DEBUG 01-15 10:09:43.988142.988142 cuda_h.py:19] end prefill_layer cost 0.07301878929138184 seconds
DEBUG 01-15 10:09:43.988265.988265 lmp.py:1552] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-15 10:09:43.988591.988591 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:43.988724.988724 lmp.py:1495] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-15 10:09:43.988811.988811 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:43.988335.988335 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-15 10:09:43.988583.988583 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 4.506111145019531e-05 seconds
DEBUG 01-15 10:09:43.988697.988697 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 8.273124694824219e-05 seconds
DEBUG 01-15 10:09:43.988639.988639 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:43.988052.988052 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:43.988499.988499 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.988442.988442 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:43.988008.988008 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.989363.989363 cuda_h.py:19] end allocate_cuda_memory cost 0.000209808349609375 seconds
DEBUG 01-15 10:09:43.989604.989604 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.989844.989844 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.989233.989233 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.989373.989373 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0fec8366-4a92-4896-ad16-a73d9556111e
DEBUG 01-15 10:09:43.989568.989568 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.989089.989089 cuda_h.py:10] start self_attn
INFO 01-15 10:09:43.990462.990462 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0fec8366-4a92-4896-ad16-a73d9556111e
DEBUG 01-15 10:09:43.990497.990497 cuda_h.py:19] end load_into_gpu_async cost 0.0011129379272460938 seconds
DEBUG 01-15 10:09:43.990822.990822 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:43.990502.990502 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-15 10:09:43.990980.990980 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017654895782470703 seconds
INFO 01-15 10:09:43.990114.990114 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0fec8366-4a92-4896-ad16-a73d9556111e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:43.994617.994617 cuda_h.py:19] end self_attn cost 0.004213571548461914 seconds
DEBUG 01-15 10:09:43.994853.994853 cuda_h.py:19] end iln_self_attn_paln cost 0.005990266799926758 seconds
DEBUG 01-15 10:09:43.994750.994750 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-15 10:09:43.994082.994082 cuda_h.py:10] start gate
DEBUG 01-15 10:09:43.995987.995987 cuda_h.py:19] end gate cost 0.0007042884826660156 seconds
DEBUG 01-15 10:09:43.995247.995247 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:43.995464.995464 lmp.py:1616] 
DEBUG 01-15 10:09:43.995464.995464 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:43.995896.995896 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:43.995261.995261 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:43.995049.995049 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:43.995408.995408 lmp.py:1620] 
DEBUG 01-15 10:09:43.995408.995408 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:43.995289.995289 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:43.995416.995416 lmp.py:1626]   Expert  1 |     45 | CPU
DEBUG 01-15 10:09:43.995774.995774 lmp.py:1626]   Expert  7 |     59 | CPU
DEBUG 01-15 10:09:43.995702.995702 lmp.py:1626]   Expert 37 |     70 | CPU
DEBUG 01-15 10:09:43.995152.995152 lmp.py:1626]   Expert 17 |     75 | CPU
DEBUG 01-15 10:09:43.995319.995319 lmp.py:1626]   Expert 54 |     77 | CPU
DEBUG 01-15 10:09:43.995968.995968 lmp.py:1626]   Expert 18 |     83 | CPU
DEBUG 01-15 10:09:43.995903.995903 lmp.py:1626]   Expert 13 |     91 | CPU
DEBUG 01-15 10:09:43.995069.995069 lmp.py:1626]   Expert  9 |     94 | CPU
DEBUG 01-15 10:09:43.995474.995474 lmp.py:1626]   Expert 58 |    101 | CPU
DEBUG 01-15 10:09:43.995024.995024 lmp.py:1626]   Expert 22 |    102 | CPU
DEBUG 01-15 10:09:43.995905.995905 lmp.py:1626]   Expert  0 |    107 | CPU
DEBUG 01-15 10:09:43.996740.996740 lmp.py:1626]   Expert 26 |    116 | CPU
DEBUG 01-15 10:09:43.996622.996622 lmp.py:1626]   Expert 16 |    118 | CPU
DEBUG 01-15 10:09:43.996265.996265 lmp.py:1626]   Expert 10 |    122 | CPU
DEBUG 01-15 10:09:43.996908.996908 lmp.py:1626]   Expert 59 |    128 | CPU
DEBUG 01-15 10:09:43.996312.996312 lmp.py:1626]   Expert 63 |    129 | CPU
DEBUG 01-15 10:09:43.996293.996293 lmp.py:1626]   Expert 62 |    139 | CPU
DEBUG 01-15 10:09:43.996274.996274 lmp.py:1626]   Expert 43 |    145 | CPU
DEBUG 01-15 10:09:43.996394.996394 lmp.py:1626]   Expert 28 |    146 | CPU
DEBUG 01-15 10:09:43.996467.996467 lmp.py:1626]   Expert 33 |    146 | CPU
DEBUG 01-15 10:09:43.996349.996349 lmp.py:1626]   Expert 29 |    147 | CPU
DEBUG 01-15 10:09:43.996992.996992 lmp.py:1626]   Expert  2 |    157 | CPU
DEBUG 01-15 10:09:43.996111.996111 lmp.py:1626]   Expert 51 |    163 | CPU
DEBUG 01-15 10:09:43.996754.996754 lmp.py:1626]   Expert 45 |    165 | CPU
DEBUG 01-15 10:09:43.996682.996682 lmp.py:1626]   Expert 55 |    166 | CPU
DEBUG 01-15 10:09:43.996848.996848 lmp.py:1626]   Expert 11 |    167 | CPU
DEBUG 01-15 10:09:43.996776.996776 lmp.py:1626]   Expert  3 |    168 | CPU
DEBUG 01-15 10:09:43.996942.996942 lmp.py:1626]   Expert 32 |    168 | CPU
DEBUG 01-15 10:09:43.996923.996923 lmp.py:1626]   Expert 53 |    168 | CPU
DEBUG 01-15 10:09:43.996904.996904 lmp.py:1626]   Expert 23 |    170 | CPU
DEBUG 01-15 10:09:43.996024.996024 lmp.py:1626]   Expert 40 |    170 | CPU
DEBUG 01-15 10:09:43.996726.996726 lmp.py:1626]   Expert 34 |    174 | CPU
DEBUG 01-15 10:09:43.996323.996323 lmp.py:1626]   Expert 14 |    177 | GPU
DEBUG 01-15 10:09:43.996966.996966 lmp.py:1626]   Expert 52 |    181 | GPU
DEBUG 01-15 10:09:43.996609.996609 lmp.py:1626]   Expert 41 |    182 | GPU
DEBUG 01-15 10:09:43.996729.996729 lmp.py:1626]   Expert 42 |    184 | GPU
DEBUG 01-15 10:09:43.996372.996372 lmp.py:1626]   Expert 21 |    188 | GPU
DEBUG 01-15 10:09:43.996253.996253 lmp.py:1626]   Expert 57 |    195 | GPU
DEBUG 01-15 10:09:43.996611.996611 lmp.py:1626]   Expert 30 |    196 | GPU
DEBUG 01-15 10:09:43.996778.996778 lmp.py:1626]   Expert 15 |    200 | GPU
DEBUG 01-15 10:09:43.996944.996944 lmp.py:1626]   Expert 35 |    207 | GPU
DEBUG 01-15 10:09:43.996110.996110 lmp.py:1626]   Expert 12 |    217 | GPU
DEBUG 01-15 10:09:43.996276.996276 lmp.py:1626]   Expert  4 |    218 | GPU
DEBUG 01-15 10:09:43.996204.996204 lmp.py:1626]   Expert 19 |    230 | GPU
DEBUG 01-15 10:09:43.996608.996608 lmp.py:1626]   Expert 50 |    230 | GPU
DEBUG 01-15 10:09:43.996781.996781 lmp.py:1626]   Expert 24 |    231 | GPU
DEBUG 01-15 10:09:43.996186.996186 lmp.py:1626]   Expert 46 |    231 | GPU
DEBUG 01-15 10:09:43.996590.996590 lmp.py:1626]   Expert 44 |    233 | GPU
DEBUG 01-15 10:09:43.996518.996518 lmp.py:1626]   Expert 49 |    235 | GPU
DEBUG 01-15 10:09:43.996684.996684 lmp.py:1626]   Expert  8 |    237 | GPU
DEBUG 01-15 10:09:43.996850.996850 lmp.py:1626]   Expert 38 |    237 | GPU
DEBUG 01-15 10:09:43.996778.996778 lmp.py:1626]   Expert 47 |    248 | GPU
DEBUG 01-15 10:09:43.996712.996712 lmp.py:1626]   Expert  6 |    249 | GPU
DEBUG 01-15 10:09:43.996117.996117 lmp.py:1626]   Expert 31 |    254 | GPU
DEBUG 01-15 10:09:43.996760.996760 lmp.py:1626]   Expert 61 |    260 | GPU
DEBUG 01-15 10:09:43.996165.996165 lmp.py:1626]   Expert 39 |    276 | GPU
DEBUG 01-15 10:09:43.996569.996569 lmp.py:1626]   Expert 36 |    303 | GPU
DEBUG 01-15 10:09:43.996212.996212 lmp.py:1626]   Expert  5 |    307 | GPU
DEBUG 01-15 10:09:43.996378.996378 lmp.py:1626]   Expert 27 |    308 | GPU
DEBUG 01-15 10:09:43.996544.996544 lmp.py:1626]   Expert 60 |    337 | GPU
DEBUG 01-15 10:09:43.996711.996711 lmp.py:1626]   Expert 20 |    339 | GPU
DEBUG 01-15 10:09:43.996638.996638 lmp.py:1626]   Expert 48 |    368 | GPU
DEBUG 01-15 10:09:43.996328.996328 lmp.py:1626]   Expert 25 |    398 | GPU
DEBUG 01-15 10:09:43.996547.996547 lmp.py:1626]   Expert 56 |    556 | GPU
DEBUG 01-15 10:09:43.996481.996481 lmp.py:1627] 
DEBUG 01-15 10:09:43.996481.996481 lmp.py:1627]   CPU total tokens: 4076 (33.2%)
DEBUG 01-15 10:09:43.997508.997508 lmp.py:1628]   GPU total tokens: 8212 (66.8%)
DEBUG 01-15 10:09:43.997542.997542 cuda_h.py:19] end experts_map_get cost 0.0016632080078125 seconds
DEBUG 01-15 10:09:43.997445.997445 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:43.997678.997678 lmp.py:1636] 
DEBUG 01-15 10:09:43.997678.997678 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:43.997396.997396 cuda_h.py:19] end cpu_experts_submit cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:43.997145.997145 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:43.997173.997173 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:43.997968.997968 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:43.997229.997229 cuda_h.py:19] end allocate_cuda_memory cost 0.00022220611572265625 seconds
INFO 01-15 10:09:43.997159.997159 client.py:127] Model loaded
DEBUG 01-15 10:09:43.998710.998710 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:43.998375.998375 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:43.998952.998952 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:43.998605.998605 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:43.998677.998677 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:43.998407.998407 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c2876f27-a455-4603-81f2-d8287a54d5fc
DEBUG 01-15 10:09:43.998071.998071 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:43.998496.998496 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:43.999512.999512 cuda_h.py:19] end restore2model cost 0.0008521080017089844 seconds
DEBUG 01-15 10:09:43.999726.999726 cuda_h.py:19] end sllm_worker_task cost 0.010744810104370117 seconds
DEBUG 01-15 10:09:43.999870.999870 cuda_h.py:19] end move_flatidxs cost 0.0008437633514404297 seconds
DEBUG 01-15 10:09:43.999554.999554 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:43.999456.999456 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c2876f27-a455-4603-81f2-d8287a54d5fc
DEBUG 01-15 10:09:44.000637.000637 cuda_h.py:19] end load_into_gpu_async cost 0.0016651153564453125 seconds
DEBUG 01-15 10:09:44.000009.000009 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.000533.000533 cuda_h.py:19] end restore_tensors2 cost 0.000598907470703125 seconds
DEBUG 01-15 10:09:44.000225.000225 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003487825393676758 seconds
DEBUG 01-15 10:09:44.000001.000001 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.003932.003932 cuda_h.py:19] end restore2model cost 0.0028312206268310547 seconds
DEBUG 01-15 10:09:44.003649.003649 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006525278091430664 seconds
DEBUG 01-15 10:09:44.003445.003445 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.004674.004674 cuda_h.py:19] end gpu_sexperts cost 0.000278472900390625 seconds
DEBUG 01-15 10:09:44.004934.004934 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.005041.005041 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015864372253417969 seconds
DEBUG 01-15 10:09:44.006231.006231 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.007310.007310 cuda_h.py:19] end gpu_group_list cost 0.0003337860107421875 seconds
DEBUG 01-15 10:09:44.007507.007507 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.008178.008178 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007956027984619141 seconds
DEBUG 01-15 10:09:44.008339.008339 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.008976.008976 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-15 10:09:44.008626.008626 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.009735.009735 cuda_h.py:19] end group_tensors cost 0.009715557098388672 seconds
DEBUG 01-15 10:09:44.010704.010704 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.014331.014331 cuda_h.py:19] end group pad cost 0.004019975662231445 seconds
DEBUG 01-15 10:09:44.014074.014074 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.034391.034391 cuda_h.py:19] end group_einsum cost 0.01984882354736328 seconds
DEBUG 01-15 10:09:44.034416.034416 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.039684.039684 cuda_h.py:19] end get_outputs_cpu1 cost 0.0047605037689208984 seconds
DEBUG 01-15 10:09:44.040957.040957 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04170107841491699 seconds
DEBUG 01-15 10:09:44.041227.041227 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03351140022277832 seconds
DEBUG 01-15 10:09:44.042499.042499 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.042151.042151 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.042392.042392 cuda_h.py:19] end index_scatter cost 0.00016164779663085938 seconds
DEBUG 01-15 10:09:44.043813.043813 cuda_h.py:19] end cpuoutputsdeal cost 0.0011799335479736328 seconds
DEBUG 01-15 10:09:44.043539.043539 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.043476.043476 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c2876f27-a455-4603-81f2-d8287a54d5fc
INFO 01-15 10:09:44.050451.050451 client.py:127] Model loaded
DEBUG 01-15 10:09:44.050833.050833 cuda_h.py:19] end wait_experts cost 0.007121562957763672 seconds
DEBUG 01-15 10:09:44.050743.050743 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.050343.050343 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.050545.050545 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.051494.051494 cuda_h.py:19] end gpu_group_tensor cost 0.00037550926208496094 seconds
DEBUG 01-15 10:09:44.051514.051514 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.052075.052075 cuda_h.py:19] end gpu_group_einsum cost 0.0010037422180175781 seconds
DEBUG 01-15 10:09:44.052269.052269 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.053677.053677 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.053361.053361 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005645751953125 seconds
DEBUG 01-15 10:09:44.053231.053231 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.054331.054331 cuda_h.py:19] end concat_expert_out cost 0.00013136863708496094 seconds
DEBUG 01-15 10:09:44.054958.054958 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.054959.054959 cuda_h.py:19] end index_scatter cost 0.0001220703125 seconds
DEBUG 01-15 10:09:44.054942.054942 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014111995697021484 seconds
DEBUG 01-15 10:09:44.054219.054219 cuda_h.py:19] end gpu_experts cost 0.003862142562866211 seconds
DEBUG 01-15 10:09:44.054285.054285 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.06025242805480957 seconds
DEBUG 01-15 10:09:44.055218.055218 cuda_h.py:19] end prefill_layer cost 0.06733942031860352 seconds
DEBUG 01-15 10:09:44.055998.055998 lmp.py:1552] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-15 10:09:44.055993.055993 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.055519.055519 lmp.py:1495] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-15 10:09:44.055044.055044 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:44.056723.056723 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-15 10:09:44.056112.056112 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.699562072753906e-05 seconds
DEBUG 01-15 10:09:44.056320.056320 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.0001556873321533203 seconds
DEBUG 01-15 10:09:44.056258.056258 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.056851.056851 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.056348.056348 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.056633.056633 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.057691.057691 cuda_h.py:19] end allocate_cuda_memory cost 0.0003075599670410156 seconds
DEBUG 01-15 10:09:44.057807.057807 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.057715.057715 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.057121.057121 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.057639.057639 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7074170f-1ee0-4ed5-8449-1e8a8cd7ab08
DEBUG 01-15 10:09:44.057881.057881 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.057809.057809 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:44.058819.058819 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7074170f-1ee0-4ed5-8449-1e8a8cd7ab08
DEBUG 01-15 10:09:44.058590.058590 cuda_h.py:19] end load_into_gpu_async cost 0.0012061595916748047 seconds
DEBUG 01-15 10:09:44.058061.058061 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.058178.058178 cuda_h.py:19] end restore_tensors2 cost 9.202957153320312e-05 seconds
DEBUG 01-15 10:09:44.058318.058318 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019116401672363281 seconds
INFO 01-15 10:09:44.058744.058744 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7074170f-1ee0-4ed5-8449-1e8a8cd7ab08
DEBUG 01-15 10:09:44.058676.058676 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.063493.063493 cuda_h.py:19] end self_attn cost 0.004479169845581055 seconds
DEBUG 01-15 10:09:44.064032.064032 cuda_h.py:19] end iln_self_attn_paln cost 0.0072629451751708984 seconds
DEBUG 01-15 10:09:44.064161.064161 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-15 10:09:44.064481.064481 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.065553.065553 cuda_h.py:19] end gate cost 0.0009064674377441406 seconds
DEBUG 01-15 10:09:44.065139.065139 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.065467.065467 lmp.py:1616] 
DEBUG 01-15 10:09:44.065467.065467 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.065642.065642 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.065703.065703 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.065565.065565 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.065374.065374 lmp.py:1620] 
DEBUG 01-15 10:09:44.065374.065374 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.066183.066183 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.066138.066138 lmp.py:1626]   Expert 50 |     43 | CPU
DEBUG 01-15 10:09:44.066186.066186 lmp.py:1626]   Expert  3 |     53 | CPU
DEBUG 01-15 10:09:44.066041.066041 lmp.py:1626]   Expert 46 |     54 | CPU
DEBUG 01-15 10:09:44.066135.066135 lmp.py:1626]   Expert  1 |     76 | CPU
DEBUG 01-15 10:09:44.066182.066182 lmp.py:1626]   Expert 29 |     87 | CPU
DEBUG 01-15 10:09:44.066906.066906 lmp.py:1626]   Expert  4 |     88 | CPU
DEBUG 01-15 10:09:44.066476.066476 lmp.py:1626]   Expert 40 |     94 | CPU
DEBUG 01-15 10:09:44.066855.066855 lmp.py:1626]   Expert 15 |     96 | CPU
DEBUG 01-15 10:09:44.066472.066472 lmp.py:1626]   Expert  8 |    110 | CPU
DEBUG 01-15 10:09:44.066135.066135 lmp.py:1626]   Expert 28 |    112 | CPU
DEBUG 01-15 10:09:44.066421.066421 lmp.py:1626]   Expert 41 |    113 | CPU
DEBUG 01-15 10:09:44.066992.066992 lmp.py:1626]   Expert 16 |    126 | CPU
DEBUG 01-15 10:09:44.066086.066086 lmp.py:1626]   Expert 27 |    127 | CPU
DEBUG 01-15 10:09:44.066703.066703 lmp.py:1626]   Expert  6 |    129 | CPU
DEBUG 01-15 10:09:44.066128.066128 lmp.py:1626]   Expert 48 |    129 | CPU
DEBUG 01-15 10:09:44.066268.066268 lmp.py:1626]   Expert 13 |    131 | CPU
DEBUG 01-15 10:09:44.066315.066315 lmp.py:1626]   Expert 54 |    134 | CPU
DEBUG 01-15 10:09:44.066125.066125 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:44.066695.066695 lmp.py:1626]   Expert 51 |    137 | CPU
DEBUG 01-15 10:09:44.066789.066789 lmp.py:1626]   Expert 39 |    138 | CPU
DEBUG 01-15 10:09:44.066929.066929 lmp.py:1626]   Expert 60 |    138 | CPU
DEBUG 01-15 10:09:44.066831.066831 lmp.py:1626]   Expert 18 |    141 | CPU
DEBUG 01-15 10:09:44.066256.066256 lmp.py:1626]   Expert 14 |    145 | CPU
DEBUG 01-15 10:09:44.066396.066396 lmp.py:1626]   Expert 43 |    148 | CPU
DEBUG 01-15 10:09:44.066490.066490 lmp.py:1626]   Expert 56 |    148 | CPU
DEBUG 01-15 10:09:44.066299.066299 lmp.py:1626]   Expert 36 |    149 | CPU
DEBUG 01-15 10:09:44.066962.066962 lmp.py:1626]   Expert 52 |    150 | CPU
DEBUG 01-15 10:09:44.066772.066772 lmp.py:1626]   Expert 20 |    151 | CPU
DEBUG 01-15 10:09:44.066435.066435 lmp.py:1626]   Expert 55 |    151 | CPU
DEBUG 01-15 10:09:44.067575.067575 lmp.py:1626]   Expert 10 |    156 | CPU
DEBUG 01-15 10:09:44.067669.067669 lmp.py:1626]   Expert 11 |    158 | CPU
DEBUG 01-15 10:09:44.067001.067001 lmp.py:1626]   Expert 45 |    158 | CPU
DEBUG 01-15 10:09:44.067618.067618 lmp.py:1626]   Expert  5 |    163 | GPU
DEBUG 01-15 10:09:44.067520.067520 lmp.py:1626]   Expert 62 |    166 | GPU
DEBUG 01-15 10:09:44.067660.067660 lmp.py:1626]   Expert 57 |    172 | GPU
DEBUG 01-15 10:09:44.067562.067562 lmp.py:1626]   Expert 44 |    174 | GPU
DEBUG 01-15 10:09:44.067464.067464 lmp.py:1626]   Expert 33 |    178 | GPU
DEBUG 01-15 10:09:44.067796.067796 lmp.py:1626]   Expert 58 |    181 | GPU
INFO 01-15 10:09:44.067561.067561 client.py:127] Model loaded
DEBUG 01-15 10:09:44.067572.067572 lmp.py:1626]   Expert 25 |    182 | GPU
DEBUG 01-15 10:09:44.067231.067231 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.067835.067835 lmp.py:1626]   Expert 53 |    183 | GPU
DEBUG 01-15 10:09:44.068215.068215 lmp.py:1626]   Expert  2 |    188 | GPU
DEBUG 01-15 10:09:44.068006.068006 lmp.py:1626]   Expert 32 |    189 | GPU
DEBUG 01-15 10:09:44.068677.068677 lmp.py:1626]   Expert 21 |    200 | GPU
DEBUG 01-15 10:09:44.068805.068805 lmp.py:1626]   Expert 31 |    200 | GPU
DEBUG 01-15 10:09:44.068099.068099 cuda_h.py:19] end restore2model cost 0.0010306835174560547 seconds
DEBUG 01-15 10:09:44.068518.068518 lmp.py:1626]   Expert 35 |    200 | GPU
DEBUG 01-15 10:09:44.068945.068945 cuda_h.py:19] end sllm_worker_task cost 0.012326478958129883 seconds
DEBUG 01-15 10:09:44.069253.069253 lmp.py:1626]   Expert 49 |    204 | GPU
DEBUG 01-15 10:09:44.069933.069933 lmp.py:1626]   Expert 63 |    204 | GPU
DEBUG 01-15 10:09:44.069007.069007 lmp.py:1626]   Expert 17 |    209 | GPU
DEBUG 01-15 10:09:44.069219.069219 lmp.py:1626]   Expert 42 |    218 | GPU
DEBUG 01-15 10:09:44.069955.069955 lmp.py:1626]   Expert 34 |    223 | GPU
DEBUG 01-15 10:09:44.069929.069929 lmp.py:1626]   Expert 37 |    228 | GPU
DEBUG 01-15 10:09:44.069857.069857 lmp.py:1626]   Expert 59 |    230 | GPU
DEBUG 01-15 10:09:44.069692.069692 lmp.py:1626]   Expert 22 |    241 | GPU
DEBUG 01-15 10:09:44.069666.069666 lmp.py:1626]   Expert  0 |    242 | GPU
DEBUG 01-15 10:09:44.069686.069686 lmp.py:1626]   Expert 19 |    258 | GPU
DEBUG 01-15 10:09:44.069707.069707 lmp.py:1626]   Expert 24 |    286 | GPU
DEBUG 01-15 10:09:44.069727.069727 lmp.py:1626]   Expert 61 |    290 | GPU
DEBUG 01-15 10:09:44.069509.069509 lmp.py:1626]   Expert 30 |    302 | GPU
DEBUG 01-15 10:09:44.069291.069291 lmp.py:1626]   Expert 47 |    321 | GPU
DEBUG 01-15 10:09:44.069311.069311 lmp.py:1626]   Expert 38 |    365 | GPU
DEBUG 01-15 10:09:44.069093.069093 lmp.py:1626]   Expert 26 |    374 | GPU
DEBUG 01-15 10:09:44.069114.069114 lmp.py:1626]   Expert 12 |    425 | GPU
DEBUG 01-15 10:09:44.069134.069134 lmp.py:1626]   Expert  9 |    686 | GPU
DEBUG 01-15 10:09:44.069108.069108 lmp.py:1626]   Expert 23 |    700 | GPU
DEBUG 01-15 10:09:44.069513.069513 lmp.py:1627] 
DEBUG 01-15 10:09:44.069513.069513 lmp.py:1627]   CPU total tokens: 3906 (31.8%)
DEBUG 01-15 10:09:44.069871.069871 lmp.py:1628]   GPU total tokens: 8382 (68.2%)
DEBUG 01-15 10:09:44.069435.069435 cuda_h.py:19] end experts_map_get cost 0.004240512847900391 seconds
DEBUG 01-15 10:09:44.069715.069715 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.069087.069087 lmp.py:1636] 
DEBUG 01-15 10:09:44.069087.069087 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.069691.069691 cuda_h.py:19] end cpu_experts_submit cost 5.9604644775390625e-05 seconds
DEBUG 01-15 10:09:44.069195.069195 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.069323.069323 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.069780.069780 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.070744.070744 cuda_h.py:19] end allocate_cuda_memory cost 0.0002548694610595703 seconds
DEBUG 01-15 10:09:44.070640.070640 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.070018.070018 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.070271.070271 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.070166.070166 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c8106920-92ae-4f69-8fa0-541dd60ea764
DEBUG 01-15 10:09:44.070710.070710 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.071271.071271 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:44.071005.071005 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c8106920-92ae-4f69-8fa0-541dd60ea764
DEBUG 01-15 10:09:44.071709.071709 cuda_h.py:19] end load_into_gpu_async cost 0.0014574527740478516 seconds
DEBUG 01-15 10:09:44.071220.071220 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.071426.071426 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.072402.072402 cuda_h.py:19] end restore_tensors2 cost 0.0004589557647705078 seconds
DEBUG 01-15 10:09:44.072670.072670 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00261688232421875 seconds
DEBUG 01-15 10:09:44.072745.072745 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.073447.073447 cuda_h.py:19] end move_flatidxs cost 0.0011126995086669922 seconds
DEBUG 01-15 10:09:44.073330.073330 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.075101.075101 cuda_h.py:19] end restore2model cost 0.0026819705963134766 seconds
DEBUG 01-15 10:09:44.075421.075421 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00551605224609375 seconds
DEBUG 01-15 10:09:44.075547.075547 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.075047.075047 cuda_h.py:19] end gpu_sexperts cost 0.0002677440643310547 seconds
DEBUG 01-15 10:09:44.075069.075069 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.077438.077438 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015015602111816406 seconds
DEBUG 01-15 10:09:44.077987.077987 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.078238.078238 cuda_h.py:19] end gpu_group_list cost 0.0003495216369628906 seconds
DEBUG 01-15 10:09:44.078726.078726 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.079240.079240 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0006897449493408203 seconds
DEBUG 01-15 10:09:44.079871.079871 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.079508.079508 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-15 10:09:44.079727.079727 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.083503.083503 cuda_h.py:19] end group_tensors cost 0.010618925094604492 seconds
DEBUG 01-15 10:09:44.085344.085344 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.089852.089852 cuda_h.py:19] end group pad cost 0.0041751861572265625 seconds
DEBUG 01-15 10:09:44.089125.089125 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.108570.108570 cuda_h.py:19] end group_einsum cost 0.018909931182861328 seconds
DEBUG 01-15 10:09:44.108072.108072 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.113554.113554 cuda_h.py:19] end get_outputs_cpu1 cost 0.004638195037841797 seconds
DEBUG 01-15 10:09:44.114282.114282 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.042551517486572266 seconds
DEBUG 01-15 10:09:44.115643.115643 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0357975959777832 seconds
DEBUG 01-15 10:09:44.115158.115158 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.115994.115994 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.115344.115344 cuda_h.py:19] end index_scatter cost 9.226799011230469e-05 seconds
DEBUG 01-15 10:09:44.116324.116324 cuda_h.py:19] end cpuoutputsdeal cost 0.0007851123809814453 seconds
DEBUG 01-15 10:09:44.116108.116108 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.116069.116069 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c8106920-92ae-4f69-8fa0-541dd60ea764
INFO 01-15 10:09:44.122736.122736 client.py:127] Model loaded
DEBUG 01-15 10:09:44.122785.122785 cuda_h.py:19] end wait_experts cost 0.0067501068115234375 seconds
DEBUG 01-15 10:09:44.122587.122587 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.123166.123166 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.123882.123882 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.123023.123023 cuda_h.py:19] end gpu_group_tensor cost 0.00021314620971679688 seconds
DEBUG 01-15 10:09:44.123318.123318 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.124032.124032 cuda_h.py:19] end gpu_group_einsum cost 0.0006880760192871094 seconds
DEBUG 01-15 10:09:44.124030.124030 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.124238.124238 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.124297.124297 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003533363342285156 seconds
DEBUG 01-15 10:09:44.124338.124338 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.124122.124122 cuda_h.py:19] end concat_expert_out cost 5.650520324707031e-05 seconds
DEBUG 01-15 10:09:44.124581.124581 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.125313.125313 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-15 10:09:44.125645.125645 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007214546203613281 seconds
DEBUG 01-15 10:09:44.125668.125668 cuda_h.py:19] end gpu_experts cost 0.0021741390228271484 seconds
DEBUG 01-15 10:09:44.125498.125498 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.061048030853271484 seconds
DEBUG 01-15 10:09:44.125981.125981 cuda_h.py:19] end prefill_layer cost 0.06997561454772949 seconds
DEBUG 01-15 10:09:44.125937.125937 lmp.py:1552] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-15 10:09:44.125117.125117 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.125012.125012 lmp.py:1495] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-15 10:09:44.125860.125860 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:44.126762.126762 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-15 10:09:44.126473.126473 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.8623809814453125e-05 seconds
DEBUG 01-15 10:09:44.126520.126520 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.62939453125e-05 seconds
DEBUG 01-15 10:09:44.126124.126124 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.126682.126682 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.126460.126460 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.126296.126296 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.126074.126074 cuda_h.py:19] end allocate_cuda_memory cost 0.00025463104248046875 seconds
DEBUG 01-15 10:09:44.126454.126454 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.126117.126117 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.126993.126993 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.126934.126934 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6740a3fb-ec74-407e-9f46-6e9189ced0a5
DEBUG 01-15 10:09:44.126209.126209 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.127101.127101 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.127734.127734 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.127131.127131 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6740a3fb-ec74-407e-9f46-6e9189ced0a5
DEBUG 01-15 10:09:44.127050.127050 cuda_h.py:19] end load_into_gpu_async cost 0.001138448715209961 seconds
DEBUG 01-15 10:09:44.127879.127879 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.128175.128175 cuda_h.py:19] end restore_tensors2 cost 9.751319885253906e-05 seconds
DEBUG 01-15 10:09:44.128747.128747 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018279552459716797 seconds
INFO 01-15 10:09:44.128757.128757 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6740a3fb-ec74-407e-9f46-6e9189ced0a5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.131811.131811 cuda_h.py:19] end self_attn cost 0.004001140594482422 seconds
DEBUG 01-15 10:09:44.131324.131324 cuda_h.py:19] end iln_self_attn_paln cost 0.005556344985961914 seconds
DEBUG 01-15 10:09:44.131406.131406 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-15 10:09:44.131784.131784 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.132212.132212 cuda_h.py:19] end gate cost 0.0006687641143798828 seconds
DEBUG 01-15 10:09:44.132095.132095 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.132774.132774 lmp.py:1616] 
DEBUG 01-15 10:09:44.132774.132774 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.132438.132438 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.132326.132326 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.132591.132591 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.133711.133711 lmp.py:1620] 
DEBUG 01-15 10:09:44.133711.133711 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.133308.133308 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.133620.133620 lmp.py:1626]   Expert 38 |     12 | CPU
DEBUG 01-15 10:09:44.133693.133693 lmp.py:1626]   Expert 39 |     60 | CPU
DEBUG 01-15 10:09:44.133813.133813 lmp.py:1626]   Expert  7 |     71 | CPU
DEBUG 01-15 10:09:44.133456.133456 lmp.py:1626]   Expert 30 |     74 | CPU
DEBUG 01-15 10:09:44.133099.133099 lmp.py:1626]   Expert 14 |     93 | CPU
DEBUG 01-15 10:09:44.133980.133980 lmp.py:1626]   Expert 24 |     93 | CPU
DEBUG 01-15 10:09:44.133908.133908 lmp.py:1626]   Expert 27 |     94 | CPU
DEBUG 01-15 10:09:44.133074.133074 lmp.py:1626]   Expert 36 |     97 | CPU
DEBUG 01-15 10:09:44.133240.133240 lmp.py:1626]   Expert 40 |     98 | CPU
DEBUG 01-15 10:09:44.133407.133407 lmp.py:1626]   Expert 17 |     99 | CPU
DEBUG 01-15 10:09:44.133573.133573 lmp.py:1626]   Expert 16 |    104 | CPU
DEBUG 01-15 10:09:44.133216.133216 lmp.py:1626]   Expert 32 |    106 | CPU
DEBUG 01-15 10:09:44.133859.133859 lmp.py:1626]   Expert 18 |    109 | CPU
DEBUG 01-15 10:09:44.133502.133502 lmp.py:1626]   Expert 48 |    110 | CPU
DEBUG 01-15 10:09:44.133621.133621 lmp.py:1626]   Expert  1 |    115 | CPU
DEBUG 01-15 10:09:44.133026.133026 lmp.py:1626]   Expert 12 |    116 | CPU
DEBUG 01-15 10:09:44.133192.133192 lmp.py:1626]   Expert  6 |    125 | CPU
DEBUG 01-15 10:09:44.133358.133358 lmp.py:1626]   Expert 59 |    130 | CPU
DEBUG 01-15 10:09:44.133286.133286 lmp.py:1626]   Expert 42 |    136 | CPU
DEBUG 01-15 10:09:44.133452.133452 lmp.py:1626]   Expert  0 |    139 | CPU
DEBUG 01-15 10:09:44.133141.133141 lmp.py:1626]   Expert 22 |    145 | CPU
DEBUG 01-15 10:09:44.133069.133069 lmp.py:1626]   Expert 51 |    148 | CPU
DEBUG 01-15 10:09:44.133997.133997 lmp.py:1626]   Expert 53 |    149 | CPU
DEBUG 01-15 10:09:44.133117.133117 lmp.py:1626]   Expert  8 |    164 | CPU
DEBUG 01-15 10:09:44.133521.133521 lmp.py:1626]   Expert 15 |    167 | CPU
DEBUG 01-15 10:09:44.133926.133926 lmp.py:1626]   Expert 44 |    167 | CPU
DEBUG 01-15 10:09:44.133330.133330 lmp.py:1626]   Expert 60 |    168 | CPU
DEBUG 01-15 10:09:44.133735.133735 lmp.py:1626]   Expert 29 |    171 | CPU
DEBUG 01-15 10:09:44.133901.133901 lmp.py:1626]   Expert 54 |    174 | CPU
DEBUG 01-15 10:09:44.133590.133590 lmp.py:1626]   Expert 35 |    180 | CPU
DEBUG 01-15 10:09:44.133280.133280 lmp.py:1626]   Expert 34 |    182 | CPU
DEBUG 01-15 10:09:44.133207.133207 lmp.py:1626]   Expert 33 |    183 | CPU
DEBUG 01-15 10:09:44.133135.133135 lmp.py:1626]   Expert 47 |    187 | GPU
DEBUG 01-15 10:09:44.133063.133063 lmp.py:1626]   Expert 19 |    191 | GPU
DEBUG 01-15 10:09:44.133229.133229 lmp.py:1626]   Expert  9 |    192 | GPU
DEBUG 01-15 10:09:44.133157.133157 lmp.py:1626]   Expert 46 |    197 | GPU
DEBUG 01-15 10:09:44.133276.133276 lmp.py:1626]   Expert 56 |    197 | GPU
DEBUG 01-15 10:09:44.133919.133919 lmp.py:1626]   Expert  3 |    198 | GPU
DEBUG 01-15 10:09:44.133562.133562 lmp.py:1626]   Expert 21 |    199 | GPU
DEBUG 01-15 10:09:44.133967.133967 lmp.py:1626]   Expert 45 |    200 | GPU
DEBUG 01-15 10:09:44.133371.133371 lmp.py:1626]   Expert 20 |    203 | GPU
DEBUG 01-15 10:09:44.133061.133061 lmp.py:1626]   Expert 49 |    204 | GPU
DEBUG 01-15 10:09:44.133989.133989 lmp.py:1626]   Expert 28 |    207 | GPU
DEBUG 01-15 10:09:44.133916.133916 lmp.py:1626]   Expert  2 |    221 | GPU
DEBUG 01-15 10:09:44.133606.133606 lmp.py:1626]   Expert 57 |    224 | GPU
DEBUG 01-15 10:09:44.133533.133533 lmp.py:1626]   Expert 13 |    225 | GPU
DEBUG 01-15 10:09:44.133984.133984 lmp.py:1626]   Expert  4 |    228 | GPU
DEBUG 01-15 10:09:44.133912.133912 lmp.py:1626]   Expert 43 |    228 | GPU
DEBUG 01-15 10:09:44.133601.133601 lmp.py:1626]   Expert 10 |    238 | GPU
DEBUG 01-15 10:09:44.133767.133767 lmp.py:1626]   Expert 50 |    243 | GPU
DEBUG 01-15 10:09:44.133410.133410 lmp.py:1626]   Expert 41 |    245 | GPU
DEBUG 01-15 10:09:44.133576.133576 lmp.py:1626]   Expert 26 |    249 | GPU
DEBUG 01-15 10:09:44.133981.133981 lmp.py:1626]   Expert 63 |    254 | GPU
DEBUG 01-15 10:09:44.133909.133909 lmp.py:1626]   Expert 37 |    258 | GPU
DEBUG 01-15 10:09:44.133836.133836 lmp.py:1626]   Expert 31 |    272 | GPU
DEBUG 01-15 10:09:44.133287.133287 lmp.py:1626]   Expert 61 |    273 | GPU
DEBUG 01-15 10:09:44.134977.134977 lmp.py:1626]   Expert 52 |    305 | GPU
DEBUG 01-15 10:09:44.134666.134666 lmp.py:1626]   Expert 58 |    320 | GPU
DEBUG 01-15 10:09:44.134594.134594 lmp.py:1626]   Expert 62 |    324 | GPU
DEBUG 01-15 10:09:44.134283.134283 lmp.py:1626]   Expert 55 |    340 | GPU
DEBUG 01-15 10:09:44.134972.134972 lmp.py:1626]   Expert 11 |    381 | GPU
DEBUG 01-15 10:09:44.134662.134662 lmp.py:1626]   Expert 23 |    385 | GPU
DEBUG 01-15 10:09:44.134828.134828 lmp.py:1626]   Expert 25 |    406 | GPU
DEBUG 01-15 10:09:44.134709.134709 lmp.py:1626]   Expert  5 |    515 | GPU
DEBUG 01-15 10:09:44.134021.134021 lmp.py:1627] 
DEBUG 01-15 10:09:44.134021.134021 lmp.py:1627]   CPU total tokens: 3979 (32.4%)
DEBUG 01-15 10:09:44.134618.134618 lmp.py:1628]   GPU total tokens: 8309 (67.6%)
DEBUG 01-15 10:09:44.134267.134267 cuda_h.py:19] end experts_map_get cost 0.0015735626220703125 seconds
DEBUG 01-15 10:09:44.134071.134071 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.134443.134443 lmp.py:1636] 
DEBUG 01-15 10:09:44.134443.134443 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.134471.134471 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-15 10:09:44.134313.134313 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.134149.134149 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.134473.134473 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.134170.134170 cuda_h.py:19] end allocate_cuda_memory cost 0.00023508071899414062 seconds
DEBUG 01-15 10:09:44.135950.135950 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.135143.135143 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.135396.135396 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.135145.135145 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1e55697-37b7-4b74-a598-4adc613d99f8
DEBUG 01-15 10:09:44.135345.135345 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.135563.135563 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:44.135449.135449 client.py:127] Model loaded
DEBUG 01-15 10:09:44.135668.135668 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.135537.135537 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.136723.136723 cuda_h.py:19] end restore2model cost 0.0003807544708251953 seconds
DEBUG 01-15 10:09:44.136692.136692 cuda_h.py:19] end sllm_worker_task cost 0.009904861450195312 seconds
INFO 01-15 10:09:44.136449.136449 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1e55697-37b7-4b74-a598-4adc613d99f8
DEBUG 01-15 10:09:44.136261.136261 cuda_h.py:19] end load_into_gpu_async cost 0.0011370182037353516 seconds
DEBUG 01-15 10:09:44.136262.136262 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.136394.136394 cuda_h.py:19] end move_flatidxs cost 0.0008671283721923828 seconds
DEBUG 01-15 10:09:44.136092.136092 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.137582.137582 cuda_h.py:19] end restore_tensors2 cost 0.0006279945373535156 seconds
DEBUG 01-15 10:09:44.137161.137161 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026869773864746094 seconds
DEBUG 01-15 10:09:44.137884.137884 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.139854.139854 cuda_h.py:19] end restore2model cost 0.0026526451110839844 seconds
DEBUG 01-15 10:09:44.139605.139605 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005529880523681641 seconds
DEBUG 01-15 10:09:44.139162.139162 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.140013.140013 cuda_h.py:19] end gpu_sexperts cost 0.00028133392333984375 seconds
DEBUG 01-15 10:09:44.140604.140604 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.142545.142545 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0021293163299560547 seconds
DEBUG 01-15 10:09:44.143838.143838 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.143421.143421 cuda_h.py:19] end gpu_group_list cost 0.0003368854522705078 seconds
DEBUG 01-15 10:09:44.143107.143107 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.144127.144127 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007441043853759766 seconds
DEBUG 01-15 10:09:44.144002.144002 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.144878.144878 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-15 10:09:44.144289.144289 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.147574.147574 cuda_h.py:19] end group_tensors cost 0.010984659194946289 seconds
DEBUG 01-15 10:09:44.148905.148905 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.152430.152430 cuda_h.py:19] end group pad cost 0.00394892692565918 seconds
DEBUG 01-15 10:09:44.152220.152220 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.171175.171175 cuda_h.py:19] end group_einsum cost 0.01933908462524414 seconds
DEBUG 01-15 10:09:44.172915.172915 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.176907.176907 cuda_h.py:19] end get_outputs_cpu1 cost 0.00462794303894043 seconds
DEBUG 01-15 10:09:44.177138.177138 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04202628135681152 seconds
DEBUG 01-15 10:09:44.179531.179531 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03422856330871582 seconds
DEBUG 01-15 10:09:44.179710.179710 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.179394.179394 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.180895.180895 cuda_h.py:19] end index_scatter cost 0.00016498565673828125 seconds
DEBUG 01-15 10:09:44.180258.180258 cuda_h.py:19] end cpuoutputsdeal cost 0.0016319751739501953 seconds
DEBUG 01-15 10:09:44.181845.181845 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.181967.181967 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1e55697-37b7-4b74-a598-4adc613d99f8
INFO 01-15 10:09:44.187920.187920 client.py:127] Model loaded
DEBUG 01-15 10:09:44.187626.187626 cuda_h.py:19] end wait_experts cost 0.006251811981201172 seconds
DEBUG 01-15 10:09:44.187152.187152 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.187514.187514 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.187285.187285 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.188234.188234 cuda_h.py:19] end gpu_group_tensor cost 0.00037598609924316406 seconds
DEBUG 01-15 10:09:44.188765.188765 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.189107.189107 cuda_h.py:19] end gpu_group_einsum cost 0.0011873245239257812 seconds
DEBUG 01-15 10:09:44.189585.189585 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.190040.190040 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.190327.190327 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005846023559570312 seconds
DEBUG 01-15 10:09:44.190920.190920 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.191628.191628 cuda_h.py:19] end concat_expert_out cost 0.00013375282287597656 seconds
DEBUG 01-15 10:09:44.191083.191083 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.191089.191089 cuda_h.py:19] end index_scatter cost 0.00010538101196289062 seconds
DEBUG 01-15 10:09:44.191721.191721 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013701915740966797 seconds
DEBUG 01-15 10:09:44.191501.191501 cuda_h.py:19] end gpu_experts cost 0.0040149688720703125 seconds
DEBUG 01-15 10:09:44.191678.191678 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.0599210262298584 seconds
DEBUG 01-15 10:09:44.192509.192509 cuda_h.py:19] end prefill_layer cost 0.06646609306335449 seconds
DEBUG 01-15 10:09:44.192600.192600 lmp.py:1552] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-15 10:09:44.192205.192205 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.192909.192909 lmp.py:1495] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-15 10:09:44.192229.192229 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:44.192224.192224 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-15 10:09:44.192924.192924 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.793571472167969e-05 seconds
DEBUG 01-15 10:09:44.193850.193850 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.193285.193285 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.0003609657287597656 seconds
DEBUG 01-15 10:09:44.193458.193458 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.193583.193583 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.193236.193236 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.194550.194550 cuda_h.py:19] end allocate_cuda_memory cost 0.0003094673156738281 seconds
DEBUG 01-15 10:09:44.194434.194434 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.194151.194151 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.194987.194987 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.194551.194551 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94de8cfa-4d31-41e9-a01f-a5af7bd8b2f2
DEBUG 01-15 10:09:44.194124.194124 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.194244.194244 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:44.195515.195515 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94de8cfa-4d31-41e9-a01f-a5af7bd8b2f2
DEBUG 01-15 10:09:44.195194.195194 cuda_h.py:19] end load_into_gpu_async cost 0.0010852813720703125 seconds
DEBUG 01-15 10:09:44.195095.195095 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.195119.195119 cuda_h.py:19] end restore_tensors2 cost 9.202957153320312e-05 seconds
DEBUG 01-15 10:09:44.195067.195067 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019176006317138672 seconds
INFO 01-15 10:09:44.195633.195633 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94de8cfa-4d31-41e9-a01f-a5af7bd8b2f2
DEBUG 01-15 10:09:44.196099.196099 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.201946.201946 cuda_h.py:19] end self_attn cost 0.00539851188659668 seconds
DEBUG 01-15 10:09:44.201343.201343 cuda_h.py:19] end iln_self_attn_paln cost 0.008017539978027344 seconds
DEBUG 01-15 10:09:44.201252.201252 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-15 10:09:44.202598.202598 cuda_h.py:10] start gate
INFO 01-15 10:09:44.202552.202552 client.py:127] Model loaded
DEBUG 01-15 10:09:44.202461.202461 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.203813.203813 cuda_h.py:19] end restore2model cost 0.0005667209625244141 seconds
DEBUG 01-15 10:09:44.203702.203702 cuda_h.py:19] end sllm_worker_task cost 0.009706735610961914 seconds
DEBUG 01-15 10:09:44.203954.203954 cuda_h.py:19] end gate cost 0.0012624263763427734 seconds
DEBUG 01-15 10:09:44.203036.203036 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.203056.203056 lmp.py:1616] 
DEBUG 01-15 10:09:44.203056.203056 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.203588.203588 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.203867.203867 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.203139.203139 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.203550.203550 lmp.py:1620] 
DEBUG 01-15 10:09:44.203550.203550 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.203677.203677 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.204234.204234 lmp.py:1626]   Expert 24 |     38 | CPU
DEBUG 01-15 10:09:44.204553.204553 lmp.py:1626]   Expert  2 |     46 | CPU
DEBUG 01-15 10:09:44.204918.204918 lmp.py:1626]   Expert 26 |     64 | CPU
DEBUG 01-15 10:09:44.204521.204521 lmp.py:1626]   Expert 32 |     66 | CPU
DEBUG 01-15 10:09:44.204694.204694 lmp.py:1626]   Expert 19 |     68 | CPU
DEBUG 01-15 10:09:44.204390.204390 lmp.py:1626]   Expert 50 |     70 | CPU
DEBUG 01-15 10:09:44.204325.204325 lmp.py:1626]   Expert 15 |     79 | CPU
DEBUG 01-15 10:09:44.204782.204782 lmp.py:1626]   Expert  4 |     81 | CPU
DEBUG 01-15 10:09:44.204717.204717 lmp.py:1626]   Expert 28 |     82 | CPU
DEBUG 01-15 10:09:44.204844.204844 lmp.py:1626]   Expert 60 |     83 | CPU
DEBUG 01-15 10:09:44.204493.204493 lmp.py:1626]   Expert  7 |     84 | CPU
DEBUG 01-15 10:09:44.204905.204905 lmp.py:1626]   Expert 59 |     89 | CPU
DEBUG 01-15 10:09:44.204601.204601 lmp.py:1626]   Expert 23 |     98 | CPU
DEBUG 01-15 10:09:44.204058.204058 lmp.py:1626]   Expert 49 |    100 | CPU
DEBUG 01-15 10:09:44.204755.204755 lmp.py:1626]   Expert  5 |    104 | CPU
DEBUG 01-15 10:09:44.204451.204451 lmp.py:1626]   Expert 12 |    108 | CPU
DEBUG 01-15 10:09:44.204431.204431 lmp.py:1626]   Expert 10 |    110 | CPU
DEBUG 01-15 10:09:44.204651.204651 lmp.py:1626]   Expert 27 |    112 | CPU
DEBUG 01-15 10:09:44.204029.204029 lmp.py:1626]   Expert 41 |    120 | CPU
DEBUG 01-15 10:09:44.204202.204202 lmp.py:1626]   Expert  3 |    126 | CPU
DEBUG 01-15 10:09:44.204090.204090 lmp.py:1626]   Expert 25 |    127 | CPU
DEBUG 01-15 10:09:44.204032.204032 lmp.py:1626]   Expert 20 |    128 | CPU
DEBUG 01-15 10:09:44.204920.204920 lmp.py:1626]   Expert 40 |    130 | CPU
DEBUG 01-15 10:09:44.204616.204616 lmp.py:1626]   Expert 13 |    131 | CPU
DEBUG 01-15 10:09:44.204074.204074 lmp.py:1626]   Expert 16 |    131 | CPU
DEBUG 01-15 10:09:44.204531.204531 lmp.py:1626]   Expert 37 |    144 | CPU
DEBUG 01-15 10:09:44.204989.204989 lmp.py:1626]   Expert 17 |    145 | CPU
DEBUG 01-15 10:09:44.204208.204208 lmp.py:1626]   Expert 35 |    149 | CPU
DEBUG 01-15 10:09:44.204428.204428 lmp.py:1626]   Expert 47 |    153 | CPU
DEBUG 01-15 10:09:44.204885.204885 lmp.py:1626]   Expert 22 |    160 | CPU
DEBUG 01-15 10:09:44.204297.204297 lmp.py:1626]   Expert 53 |    168 | CPU
DEBUG 01-15 10:09:44.204708.204708 lmp.py:1626]   Expert 39 |    171 | CPU
DEBUG 01-15 10:09:44.204119.204119 lmp.py:1626]   Expert 38 |    176 | GPU
DEBUG 01-15 10:09:44.204815.204815 lmp.py:1626]   Expert 44 |    180 | GPU
DEBUG 01-15 10:09:44.204035.204035 lmp.py:1626]   Expert 36 |    181 | GPU
DEBUG 01-15 10:09:44.204492.204492 lmp.py:1626]   Expert 52 |    182 | GPU
DEBUG 01-15 10:09:44.204712.204712 lmp.py:1626]   Expert 58 |    184 | GPU
DEBUG 01-15 10:09:44.204692.204692 lmp.py:1626]   Expert 18 |    188 | GPU
DEBUG 01-15 10:09:44.204912.204912 lmp.py:1626]   Expert 62 |    196 | GPU
DEBUG 01-15 10:09:44.204369.204369 lmp.py:1626]   Expert 48 |    209 | GPU
DEBUG 01-15 10:09:44.204589.204589 lmp.py:1626]   Expert 11 |    210 | GPU
DEBUG 01-15 10:09:44.204477.204477 lmp.py:1626]   Expert 14 |    217 | GPU
DEBUG 01-15 10:09:44.204126.204126 lmp.py:1626]   Expert 30 |    221 | GPU
DEBUG 01-15 10:09:44.204538.204538 lmp.py:1626]   Expert  1 |    229 | GPU
DEBUG 01-15 10:09:44.204234.204234 lmp.py:1626]   Expert 42 |    235 | GPU
DEBUG 01-15 10:09:44.205692.205692 lmp.py:1626]   Expert 45 |    235 | GPU
DEBUG 01-15 10:09:44.205149.205149 lmp.py:1626]   Expert 31 |    236 | GPU
DEBUG 01-15 10:09:44.205607.205607 lmp.py:1626]   Expert 51 |    241 | GPU
DEBUG 01-15 10:09:44.205065.205065 lmp.py:1626]   Expert  6 |    244 | GPU
DEBUG 01-15 10:09:44.205522.205522 lmp.py:1626]   Expert 29 |    261 | GPU
DEBUG 01-15 10:09:44.205742.205742 lmp.py:1626]   Expert 34 |    264 | GPU
DEBUG 01-15 10:09:44.205391.205391 lmp.py:1626]   Expert 33 |    277 | GPU
DEBUG 01-15 10:09:44.205803.205803 lmp.py:1626]   Expert 57 |    297 | GPU
DEBUG 01-15 10:09:44.205691.205691 lmp.py:1626]   Expert 61 |    302 | GPU
DEBUG 01-15 10:09:44.205148.205148 lmp.py:1626]   Expert 43 |    308 | GPU
DEBUG 01-15 10:09:44.205606.205606 lmp.py:1626]   Expert  0 |    322 | GPU
DEBUG 01-15 10:09:44.205587.205587 lmp.py:1626]   Expert 46 |    355 | GPU
DEBUG 01-15 10:09:44.205045.205045 lmp.py:1626]   Expert  8 |    380 | GPU
DEBUG 01-15 10:09:44.205026.205026 lmp.py:1626]   Expert 56 |    385 | GPU
DEBUG 01-15 10:09:44.205483.205483 lmp.py:1626]   Expert  9 |    392 | GPU
DEBUG 01-15 10:09:44.205702.205702 lmp.py:1626]   Expert 54 |    394 | GPU
DEBUG 01-15 10:09:44.205445.205445 lmp.py:1626]   Expert 63 |    408 | GPU
DEBUG 01-15 10:09:44.205426.205426 lmp.py:1626]   Expert 55 |    424 | GPU
DEBUG 01-15 10:09:44.205599.205599 lmp.py:1626]   Expert 21 |    490 | GPU
DEBUG 01-15 10:09:44.205440.205440 lmp.py:1627] 
DEBUG 01-15 10:09:44.205440.205440 lmp.py:1627]   CPU total tokens: 3465 (28.2%)
DEBUG 01-15 10:09:44.205759.205759 lmp.py:1628]   GPU total tokens: 8823 (71.8%)
DEBUG 01-15 10:09:44.205754.205754 cuda_h.py:19] end experts_map_get cost 0.0019991397857666016 seconds
DEBUG 01-15 10:09:44.205670.205670 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.205387.205387 lmp.py:1636] 
DEBUG 01-15 10:09:44.205387.205387 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.205151.205151 cuda_h.py:19] end cpu_experts_submit cost 7.128715515136719e-05 seconds
DEBUG 01-15 10:09:44.205761.205761 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.205525.205525 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.205969.205969 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.206066.206066 cuda_h.py:19] end allocate_cuda_memory cost 0.00027251243591308594 seconds
DEBUG 01-15 10:09:44.206192.206192 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.206572.206572 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.206926.206926 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.206788.206788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c88fde5-2ab6-4fac-a80d-2750607babf8
DEBUG 01-15 10:09:44.207592.207592 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.207548.207548 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.207032.207032 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:44.208917.208917 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c88fde5-2ab6-4fac-a80d-2750607babf8
DEBUG 01-15 10:09:44.208727.208727 cuda_h.py:19] end load_into_gpu_async cost 0.00186920166015625 seconds
DEBUG 01-15 10:09:44.208537.208537 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.208668.208668 cuda_h.py:19] end move_flatidxs cost 0.001070261001586914 seconds
DEBUG 01-15 10:09:44.208354.208354 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.209218.209218 cuda_h.py:19] end restore_tensors2 cost 0.0005362033843994141 seconds
DEBUG 01-15 10:09:44.209757.209757 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035409927368164062 seconds
DEBUG 01-15 10:09:44.209792.209792 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.212778.212778 cuda_h.py:19] end restore2model cost 0.0028967857360839844 seconds
DEBUG 01-15 10:09:44.212165.212165 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006695270538330078 seconds
DEBUG 01-15 10:09:44.212914.212914 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.212513.212513 cuda_h.py:19] end gpu_sexperts cost 0.0002715587615966797 seconds
DEBUG 01-15 10:09:44.212058.212058 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.214240.214240 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014293193817138672 seconds
DEBUG 01-15 10:09:44.215129.215129 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.215056.215056 cuda_h.py:19] end gpu_group_list cost 0.0003376007080078125 seconds
DEBUG 01-15 10:09:44.215543.215543 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.216827.216827 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007309913635253906 seconds
DEBUG 01-15 10:09:44.216785.216785 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.216714.216714 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2172927856445312e-05 seconds
DEBUG 01-15 10:09:44.216940.216940 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.219032.219032 cuda_h.py:19] end group_tensors cost 0.01028132438659668 seconds
DEBUG 01-15 10:09:44.220087.220087 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.224472.224472 cuda_h.py:19] end group pad cost 0.004289865493774414 seconds
DEBUG 01-15 10:09:44.224097.224097 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.242166.242166 cuda_h.py:19] end group_einsum cost 0.017787933349609375 seconds
DEBUG 01-15 10:09:44.242284.242284 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.246135.246135 cuda_h.py:19] end get_outputs_cpu1 cost 0.004007577896118164 seconds
DEBUG 01-15 10:09:44.247658.247658 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0400998592376709 seconds
DEBUG 01-15 10:09:44.248940.248940 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.031774044036865234 seconds
DEBUG 01-15 10:09:44.248977.248977 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.248967.248967 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.248971.248971 cuda_h.py:19] end index_scatter cost 8.58306884765625e-05 seconds
DEBUG 01-15 10:09:44.249402.249402 cuda_h.py:19] end cpuoutputsdeal cost 0.0007619857788085938 seconds
DEBUG 01-15 10:09:44.249516.249516 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.249808.249808 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c88fde5-2ab6-4fac-a80d-2750607babf8
INFO 01-15 10:09:44.257281.257281 client.py:127] Model loaded
DEBUG 01-15 10:09:44.257508.257508 cuda_h.py:19] end wait_experts cost 0.008249521255493164 seconds
DEBUG 01-15 10:09:44.257165.257165 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.257313.257313 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.257215.257215 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.258686.258686 cuda_h.py:19] end gpu_group_tensor cost 0.00021028518676757812 seconds
DEBUG 01-15 10:09:44.258928.258928 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.258786.258786 cuda_h.py:19] end gpu_group_einsum cost 0.0006551742553710938 seconds
DEBUG 01-15 10:09:44.258824.258824 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.259535.259535 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.259859.259859 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003399848937988281 seconds
DEBUG 01-15 10:09:44.259682.259682 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.259320.259320 cuda_h.py:19] end concat_expert_out cost 5.2928924560546875e-05 seconds
DEBUG 01-15 10:09:44.259210.259210 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.259557.259557 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-15 10:09:44.259313.259313 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006997585296630859 seconds
DEBUG 01-15 10:09:44.259322.259322 cuda_h.py:19] end gpu_experts cost 0.002089977264404297 seconds
DEBUG 01-15 10:09:44.259238.259238 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.057886600494384766 seconds
DEBUG 01-15 10:09:44.260677.260677 cuda_h.py:19] end prefill_layer cost 0.06763696670532227 seconds
DEBUG 01-15 10:09:44.260137.260137 lmp.py:1552] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-15 10:09:44.260263.260263 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.260913.260913 lmp.py:1495] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-15 10:09:44.260755.260755 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:44.260796.260796 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-15 10:09:44.260453.260453 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.719329833984375e-05 seconds
DEBUG 01-15 10:09:44.260588.260588 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.260868.260868 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 0.0001671314239501953 seconds
DEBUG 01-15 10:09:44.260586.260586 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.260654.260654 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.260080.260080 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.261489.261489 cuda_h.py:19] end allocate_cuda_memory cost 0.0002567768096923828 seconds
DEBUG 01-15 10:09:44.261777.261777 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.261130.261130 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.261212.261212 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.261426.261426 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.261414.261414 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 35d86487-42f9-420c-98d4-5aaacd4d8e25
DEBUG 01-15 10:09:44.261013.261013 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.261671.261671 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.262415.262415 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 35d86487-42f9-420c-98d4-5aaacd4d8e25
DEBUG 01-15 10:09:44.262297.262297 cuda_h.py:19] end load_into_gpu_async cost 0.0011522769927978516 seconds
DEBUG 01-15 10:09:44.262616.262616 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.262090.262090 cuda_h.py:19] end restore_tensors2 cost 7.724761962890625e-05 seconds
DEBUG 01-15 10:09:44.262561.262561 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019254684448242188 seconds
INFO 01-15 10:09:44.262589.262589 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 35d86487-42f9-420c-98d4-5aaacd4d8e25
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.265662.265662 cuda_h.py:19] end self_attn cost 0.003010272979736328 seconds
DEBUG 01-15 10:09:44.265122.265122 cuda_h.py:19] end iln_self_attn_paln cost 0.0043735504150390625 seconds
DEBUG 01-15 10:09:44.265488.265488 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-15 10:09:44.265774.265774 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.266811.266811 cuda_h.py:19] end gate cost 0.0006606578826904297 seconds
DEBUG 01-15 10:09:44.266740.266740 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.266214.266214 lmp.py:1616] 
DEBUG 01-15 10:09:44.266214.266214 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.266699.266699 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.266733.266733 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.266998.266998 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.266879.266879 lmp.py:1620] 
DEBUG 01-15 10:09:44.266879.266879 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.266476.266476 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.266311.266311 lmp.py:1626]   Expert 43 |     16 | CPU
DEBUG 01-15 10:09:44.266477.266477 lmp.py:1626]   Expert 27 |     31 | CPU
DEBUG 01-15 10:09:44.266167.266167 lmp.py:1626]   Expert 26 |     52 | CPU
DEBUG 01-15 10:09:44.266856.266856 lmp.py:1626]   Expert 34 |     54 | CPU
DEBUG 01-15 10:09:44.266068.266068 lmp.py:1626]   Expert 56 |     56 | CPU
DEBUG 01-15 10:09:44.266235.266235 lmp.py:1626]   Expert  3 |     57 | CPU
DEBUG 01-15 10:09:44.266401.266401 lmp.py:1626]   Expert  4 |     68 | CPU
DEBUG 01-15 10:09:44.266852.266852 lmp.py:1626]   Expert 61 |     80 | CPU
DEBUG 01-15 10:09:44.266541.266541 lmp.py:1626]   Expert 14 |     96 | CPU
DEBUG 01-15 10:09:44.266707.266707 lmp.py:1626]   Expert 38 |    100 | CPU
DEBUG 01-15 10:09:44.266112.266112 lmp.py:1626]   Expert  2 |    111 | CPU
DEBUG 01-15 10:09:44.266278.266278 lmp.py:1626]   Expert 17 |    118 | CPU
DEBUG 01-15 10:09:44.266444.266444 lmp.py:1626]   Expert 22 |    124 | CPU
DEBUG 01-15 10:09:44.266656.266656 lmp.py:1626]   Expert 47 |    129 | CPU
DEBUG 01-15 10:09:44.266346.266346 lmp.py:1626]   Expert 55 |    130 | CPU
DEBUG 01-15 10:09:44.266796.266796 lmp.py:1626]   Expert 37 |    131 | CPU
DEBUG 01-15 10:09:44.266771.266771 lmp.py:1626]   Expert 28 |    137 | CPU
DEBUG 01-15 10:09:44.266221.266221 lmp.py:1626]   Expert 54 |    138 | CPU
DEBUG 01-15 10:09:44.266672.266672 lmp.py:1626]   Expert 15 |    144 | CPU
DEBUG 01-15 10:09:44.266123.266123 lmp.py:1626]   Expert  5 |    145 | CPU
DEBUG 01-15 10:09:44.266336.266336 lmp.py:1626]   Expert  7 |    145 | CPU
DEBUG 01-15 10:09:44.266548.266548 lmp.py:1626]   Expert 48 |    146 | CPU
DEBUG 01-15 10:09:44.266999.266999 lmp.py:1626]   Expert 51 |    146 | CPU
DEBUG 01-15 10:09:44.267927.267927 lmp.py:1626]   Expert 60 |    150 | CPU
DEBUG 01-15 10:09:44.267854.267854 lmp.py:1626]   Expert 45 |    151 | CPU
DEBUG 01-15 10:09:44.267021.267021 lmp.py:1626]   Expert 63 |    153 | CPU
DEBUG 01-15 10:09:44.267425.267425 lmp.py:1626]   Expert 12 |    155 | CPU
DEBUG 01-15 10:09:44.267830.267830 lmp.py:1626]   Expert 19 |    158 | CPU
DEBUG 01-15 10:09:44.267519.267519 lmp.py:1626]   Expert  6 |    167 | CPU
DEBUG 01-15 10:09:44.267731.267731 lmp.py:1626]   Expert 57 |    169 | CPU
DEBUG 01-15 10:09:44.267944.267944 lmp.py:1626]   Expert 52 |    173 | CPU
DEBUG 01-15 10:09:44.267918.267918 lmp.py:1626]   Expert 50 |    180 | CPU
DEBUG 01-15 10:09:44.267607.267607 lmp.py:1626]   Expert 44 |    181 | GPU
DEBUG 01-15 10:09:44.267058.267058 lmp.py:1626]   Expert 18 |    182 | GPU
DEBUG 01-15 10:09:44.267271.267271 lmp.py:1626]   Expert 31 |    187 | GPU
DEBUG 01-15 10:09:44.267483.267483 lmp.py:1626]   Expert 30 |    189 | GPU
DEBUG 01-15 10:09:44.267696.267696 lmp.py:1626]   Expert 13 |    191 | GPU
DEBUG 01-15 10:09:44.267338.267338 lmp.py:1626]   Expert 23 |    192 | GPU
DEBUG 01-15 10:09:44.267505.267505 lmp.py:1626]   Expert 59 |    195 | GPU
DEBUG 01-15 10:09:44.267432.267432 lmp.py:1626]   Expert 39 |    198 | GPU
DEBUG 01-15 10:09:44.267837.267837 lmp.py:1626]   Expert 20 |    200 | GPU
DEBUG 01-15 10:09:44.267718.267718 lmp.py:1626]   Expert 53 |    200 | GPU
DEBUG 01-15 10:09:44.267931.267931 lmp.py:1626]   Expert 21 |    201 | GPU
DEBUG 01-15 10:09:44.267143.267143 lmp.py:1626]   Expert 29 |    204 | GPU
DEBUG 01-15 10:09:44.267594.267594 lmp.py:1626]   Expert 16 |    209 | GPU
DEBUG 01-15 10:09:44.267807.267807 lmp.py:1626]   Expert 36 |    212 | GPU
DEBUG 01-15 10:09:44.267019.267019 lmp.py:1626]   Expert 41 |    217 | GPU
DEBUG 01-15 10:09:44.267708.267708 lmp.py:1626]   Expert 25 |    219 | GPU
DEBUG 01-15 10:09:44.267159.267159 lmp.py:1626]   Expert 49 |    223 | GPU
DEBUG 01-15 10:09:44.267133.267133 lmp.py:1626]   Expert 32 |    225 | GPU
DEBUG 01-15 10:09:44.267776.267776 lmp.py:1626]   Expert 46 |    233 | GPU
DEBUG 01-15 10:09:44.267704.267704 lmp.py:1626]   Expert  8 |    248 | GPU
DEBUG 01-15 10:09:44.267632.267632 lmp.py:1626]   Expert 42 |    248 | GPU
DEBUG 01-15 10:09:44.267798.267798 lmp.py:1626]   Expert 10 |    251 | GPU
DEBUG 01-15 10:09:44.267202.267202 lmp.py:1626]   Expert 62 |    269 | GPU
DEBUG 01-15 10:09:44.267653.267653 lmp.py:1626]   Expert 35 |    276 | GPU
DEBUG 01-15 10:09:44.267866.267866 lmp.py:1626]   Expert 33 |    288 | GPU
DEBUG 01-15 10:09:44.267078.267078 lmp.py:1626]   Expert  9 |    294 | GPU
DEBUG 01-15 10:09:44.267244.267244 lmp.py:1626]   Expert 58 |    294 | GPU
DEBUG 01-15 10:09:44.267649.267649 lmp.py:1626]   Expert 40 |    390 | GPU
DEBUG 01-15 10:09:44.267577.267577 lmp.py:1626]   Expert 11 |    426 | GPU
DEBUG 01-15 10:09:44.267743.267743 lmp.py:1626]   Expert  0 |    428 | GPU
DEBUG 01-15 10:09:44.267909.267909 lmp.py:1626]   Expert 24 |    560 | GPU
DEBUG 01-15 10:09:44.267075.267075 lmp.py:1626]   Expert  1 |    648 | GPU
DEBUG 01-15 10:09:44.267672.267672 lmp.py:1627] 
DEBUG 01-15 10:09:44.267672.267672 lmp.py:1627]   CPU total tokens: 3810 (31.0%)
DEBUG 01-15 10:09:44.267268.267268 lmp.py:1628]   GPU total tokens: 8478 (69.0%)
DEBUG 01-15 10:09:44.267680.267680 cuda_h.py:19] end experts_map_get cost 0.0015425682067871094 seconds
DEBUG 01-15 10:09:44.267960.267960 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.267762.267762 lmp.py:1636] 
DEBUG 01-15 10:09:44.267762.267762 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.267791.267791 cuda_h.py:19] end cpu_experts_submit cost 5.555152893066406e-05 seconds
DEBUG 01-15 10:09:44.267056.267056 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.267138.267138 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.268123.268123 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.270756.270756 cuda_h.py:19] end allocate_cuda_memory cost 0.0018343925476074219 seconds
DEBUG 01-15 10:09:44.270460.270460 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.270262.270262 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.270786.270786 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.270105.270105 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 10e37dfb-df18-45bd-aea8-60373a53e2f3
DEBUG 01-15 10:09:44.270642.270642 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:44.270485.270485 client.py:127] Model loaded
DEBUG 01-15 10:09:44.270759.270759 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.271030.271030 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.271110.271110 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.271716.271716 cuda_h.py:19] end restore2model cost 0.0004553794860839844 seconds
INFO 01-15 10:09:44.271301.271301 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 10e37dfb-df18-45bd-aea8-60373a53e2f3
DEBUG 01-15 10:09:44.271197.271197 cuda_h.py:19] end sllm_worker_task cost 0.010744810104370117 seconds
DEBUG 01-15 10:09:44.271001.271001 cuda_h.py:19] end load_into_gpu_async cost 0.001485586166381836 seconds
DEBUG 01-15 10:09:44.271526.271526 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.272630.272630 cuda_h.py:19] end restore_tensors2 cost 0.0005059242248535156 seconds
DEBUG 01-15 10:09:44.272580.272580 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004269838333129883 seconds
DEBUG 01-15 10:09:44.272972.272972 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.272169.272169 cuda_h.py:19] end move_flatidxs cost 0.0009298324584960938 seconds
DEBUG 01-15 10:09:44.272529.272529 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.275487.275487 cuda_h.py:19] end restore2model cost 0.002702951431274414 seconds
DEBUG 01-15 10:09:44.275098.275098 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007172346115112305 seconds
DEBUG 01-15 10:09:44.275417.275417 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.275831.275831 cuda_h.py:19] end gpu_sexperts cost 0.0002758502960205078 seconds
DEBUG 01-15 10:09:44.275661.275661 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.280744.280744 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.005157947540283203 seconds
DEBUG 01-15 10:09:44.283994.283994 cuda_h.py:19] end group_tensors cost 0.010692119598388672 seconds
DEBUG 01-15 10:09:44.283190.283190 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.283228.283228 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.284829.284829 cuda_h.py:19] end gpu_group_list cost 0.0009171962738037109 seconds
DEBUG 01-15 10:09:44.285052.285052 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.287570.287570 cuda_h.py:19] end group pad cost 0.0038514137268066406 seconds
DEBUG 01-15 10:09:44.287142.287142 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.287915.287915 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0025360584259033203 seconds
DEBUG 01-15 10:09:44.287899.287899 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.288222.288222 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.6253204345703125e-05 seconds
DEBUG 01-15 10:09:44.288257.288257 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.307846.307846 cuda_h.py:19] end group_einsum cost 0.019538402557373047 seconds
DEBUG 01-15 10:09:44.307778.307778 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.312254.312254 cuda_h.py:19] end get_outputs_cpu1 cost 0.004452943801879883 seconds
DEBUG 01-15 10:09:44.313719.313719 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.041857004165649414 seconds
DEBUG 01-15 10:09:44.313473.313473 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0257112979888916 seconds
DEBUG 01-15 10:09:44.314619.314619 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.314562.314562 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.314863.314863 cuda_h.py:19] end index_scatter cost 0.0001678466796875 seconds
DEBUG 01-15 10:09:44.315644.315644 cuda_h.py:19] end cpuoutputsdeal cost 0.0016357898712158203 seconds
DEBUG 01-15 10:09:44.316376.316376 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.316452.316452 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 10e37dfb-df18-45bd-aea8-60373a53e2f3
INFO 01-15 10:09:44.321863.321863 client.py:127] Model loaded
DEBUG 01-15 10:09:44.321199.321199 cuda_h.py:19] end wait_experts cost 0.005297183990478516 seconds
DEBUG 01-15 10:09:44.321301.321301 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.321100.321100 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.321970.321970 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.322516.322516 cuda_h.py:19] end gpu_group_tensor cost 0.00039386749267578125 seconds
DEBUG 01-15 10:09:44.322981.322981 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.323681.323681 cuda_h.py:19] end gpu_group_einsum cost 0.0010368824005126953 seconds
DEBUG 01-15 10:09:44.323935.323935 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.323065.323065 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.324711.324711 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006031990051269531 seconds
DEBUG 01-15 10:09:44.324727.324727 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.324158.324158 cuda_h.py:19] end concat_expert_out cost 0.00013446807861328125 seconds
DEBUG 01-15 10:09:44.325024.325024 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.325328.325328 cuda_h.py:19] end index_scatter cost 0.00010704994201660156 seconds
DEBUG 01-15 10:09:44.325085.325085 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014162063598632812 seconds
DEBUG 01-15 10:09:44.325567.325567 cuda_h.py:19] end gpu_experts cost 0.003921031951904297 seconds
DEBUG 01-15 10:09:44.325856.325856 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.06020474433898926 seconds
DEBUG 01-15 10:09:44.326450.326450 cuda_h.py:19] end prefill_layer cost 0.06586718559265137 seconds
DEBUG 01-15 10:09:44.326865.326865 lmp.py:1552] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-15 10:09:44.326456.326456 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.326809.326809 lmp.py:1495] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-15 10:09:44.326161.326161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:44.326998.326998 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-15 10:09:44.327238.327238 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.745887756347656e-05 seconds
DEBUG 01-15 10:09:44.327359.327359 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 0.00014400482177734375 seconds
DEBUG 01-15 10:09:44.327486.327486 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.327389.327389 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.327215.327215 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.327991.327991 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.327519.327519 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.327856.327856 cuda_h.py:19] end allocate_cuda_memory cost 0.00031447410583496094 seconds
DEBUG 01-15 10:09:44.328594.328594 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.328118.328118 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.328398.328398 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.328870.328870 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f5245c9b-9b98-4a6a-8719-9373183854b5
DEBUG 01-15 10:09:44.328820.328820 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.328606.328606 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.329454.329454 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f5245c9b-9b98-4a6a-8719-9373183854b5
DEBUG 01-15 10:09:44.329403.329403 cuda_h.py:19] end load_into_gpu_async cost 0.0011916160583496094 seconds
DEBUG 01-15 10:09:44.329219.329219 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.329627.329627 cuda_h.py:19] end restore_tensors2 cost 9.083747863769531e-05 seconds
DEBUG 01-15 10:09:44.329158.329158 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001905202865600586 seconds
INFO 01-15 10:09:44.329658.329658 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f5245c9b-9b98-4a6a-8719-9373183854b5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.332528.332528 cuda_h.py:19] end self_attn cost 0.004120349884033203 seconds
DEBUG 01-15 10:09:44.333667.333667 cuda_h.py:19] end iln_self_attn_paln cost 0.005963325500488281 seconds
DEBUG 01-15 10:09:44.333769.333769 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-15 10:09:44.333591.333591 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.334569.334569 cuda_h.py:19] end gate cost 0.000888824462890625 seconds
DEBUG 01-15 10:09:44.334227.334227 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.334063.334063 lmp.py:1616] 
DEBUG 01-15 10:09:44.334063.334063 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.334462.334462 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.334695.334695 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.334113.334113 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.334909.334909 lmp.py:1620] 
DEBUG 01-15 10:09:44.334909.334909 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.334419.334419 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.334930.334930 lmp.py:1626]   Expert 13 |     15 | CPU
DEBUG 01-15 10:09:44.334772.334772 lmp.py:1626]   Expert 39 |     16 | CPU
DEBUG 01-15 10:09:44.335376.335376 lmp.py:1626]   Expert 49 |     39 | CPU
DEBUG 01-15 10:09:44.335502.335502 lmp.py:1626]   Expert 35 |     54 | CPU
DEBUG 01-15 10:09:44.335390.335390 lmp.py:1626]   Expert 19 |     62 | CPU
DEBUG 01-15 10:09:44.335709.335709 lmp.py:1626]   Expert  9 |     75 | CPU
DEBUG 01-15 10:09:44.335028.335028 lmp.py:1626]   Expert 26 |     75 | CPU
DEBUG 01-15 10:09:44.335108.335108 lmp.py:1626]   Expert 32 |     75 | CPU
DEBUG 01-15 10:09:44.335188.335188 lmp.py:1626]   Expert 41 |     77 | CPU
DEBUG 01-15 10:09:44.335076.335076 lmp.py:1626]   Expert 33 |     80 | CPU
DEBUG 01-15 10:09:44.335726.335726 lmp.py:1626]   Expert 46 |     88 | CPU
DEBUG 01-15 10:09:44.335091.335091 lmp.py:1626]   Expert 23 |     89 | CPU
DEBUG 01-15 10:09:44.335741.335741 lmp.py:1626]   Expert 18 |     91 | CPU
DEBUG 01-15 10:09:44.335152.335152 lmp.py:1626]   Expert 31 |     91 | CPU
DEBUG 01-15 10:09:44.335279.335279 lmp.py:1626]   Expert 38 |    101 | CPU
DEBUG 01-15 10:09:44.335359.335359 lmp.py:1626]   Expert  3 |    104 | CPU
DEBUG 01-15 10:09:44.335678.335678 lmp.py:1626]   Expert 17 |    105 | CPU
DEBUG 01-15 10:09:44.335281.335281 lmp.py:1626]   Expert  6 |    106 | CPU
DEBUG 01-15 10:09:44.335646.335646 lmp.py:1626]   Expert 20 |    119 | CPU
DEBUG 01-15 10:09:44.335535.335535 lmp.py:1626]   Expert 40 |    128 | CPU
DEBUG 01-15 10:09:44.335184.335184 lmp.py:1626]   Expert 61 |    129 | CPU
DEBUG 01-15 10:09:44.335549.335549 lmp.py:1626]   Expert 62 |    133 | CPU
DEBUG 01-15 10:09:44.335391.335391 lmp.py:1626]   Expert 15 |    134 | CPU
DEBUG 01-15 10:09:44.335995.335995 lmp.py:1626]   Expert 43 |    134 | CPU
DEBUG 01-15 10:09:44.335836.335836 lmp.py:1626]   Expert 44 |    135 | CPU
DEBUG 01-15 10:09:44.335970.335970 lmp.py:1626]   Expert 50 |    135 | CPU
DEBUG 01-15 10:09:44.335143.335143 lmp.py:1626]   Expert 16 |    137 | CPU
DEBUG 01-15 10:09:44.335600.335600 lmp.py:1626]   Expert 59 |    140 | CPU
DEBUG 01-15 10:09:44.335058.335058 lmp.py:1626]   Expert 63 |    140 | CPU
DEBUG 01-15 10:09:44.335993.335993 lmp.py:1626]   Expert 42 |    142 | CPU
DEBUG 01-15 10:09:44.335689.335689 lmp.py:1626]   Expert  2 |    146 | CPU
DEBUG 01-15 10:09:44.335146.335146 lmp.py:1626]   Expert 36 |    150 | CPU
DEBUG 01-15 10:09:44.335796.335796 lmp.py:1626]   Expert 10 |    161 | GPU
DEBUG 01-15 10:09:44.335446.335446 lmp.py:1626]   Expert  5 |    180 | GPU
DEBUG 01-15 10:09:44.335573.335573 lmp.py:1626]   Expert 34 |    187 | GPU
DEBUG 01-15 10:09:44.335507.335507 lmp.py:1626]   Expert 52 |    188 | GPU
DEBUG 01-15 10:09:44.335965.335965 lmp.py:1626]   Expert 27 |    189 | GPU
DEBUG 01-15 10:09:44.335661.335661 lmp.py:1626]   Expert 45 |    192 | GPU
DEBUG 01-15 10:09:44.335118.335118 lmp.py:1626]   Expert 60 |    199 | GPU
DEBUG 01-15 10:09:44.335338.335338 lmp.py:1626]   Expert 48 |    207 | GPU
DEBUG 01-15 10:09:44.335034.335034 lmp.py:1626]   Expert 51 |    211 | GPU
DEBUG 01-15 10:09:44.335968.335968 lmp.py:1626]   Expert 56 |    211 | GPU
DEBUG 01-15 10:09:44.335618.335618 lmp.py:1626]   Expert 24 |    231 | GPU
DEBUG 01-15 10:09:44.335506.335506 lmp.py:1626]   Expert 53 |    231 | GPU
DEBUG 01-15 10:09:44.335156.335156 lmp.py:1626]   Expert  7 |    233 | GPU
DEBUG 01-15 10:09:44.335521.335521 lmp.py:1626]   Expert  8 |    244 | GPU
DEBUG 01-15 10:09:44.336217.336217 lmp.py:1626]   Expert 57 |    250 | GPU
DEBUG 01-15 10:09:44.336436.336436 lmp.py:1626]   Expert 47 |    253 | GPU
DEBUG 01-15 10:09:44.336609.336609 lmp.py:1626]   Expert 29 |    261 | GPU
DEBUG 01-15 10:09:44.336067.336067 lmp.py:1626]   Expert 21 |    263 | GPU
DEBUG 01-15 10:09:44.336763.336763 lmp.py:1626]   Expert  0 |    287 | GPU
DEBUG 01-15 10:09:44.336459.336459 lmp.py:1626]   Expert 14 |    289 | GPU
DEBUG 01-15 10:09:44.336347.336347 lmp.py:1626]   Expert  4 |    290 | GPU
DEBUG 01-15 10:09:44.336997.336997 lmp.py:1626]   Expert 22 |    314 | GPU
DEBUG 01-15 10:09:44.336647.336647 lmp.py:1626]   Expert 55 |    317 | GPU
DEBUG 01-15 10:09:44.336058.336058 lmp.py:1626]   Expert 58 |    318 | GPU
DEBUG 01-15 10:09:44.336993.336993 lmp.py:1626]   Expert 37 |    319 | GPU
DEBUG 01-15 10:09:44.336212.336212 lmp.py:1626]   Expert  1 |    322 | GPU
DEBUG 01-15 10:09:44.336670.336670 lmp.py:1626]   Expert 54 |    331 | GPU
DEBUG 01-15 10:09:44.336889.336889 lmp.py:1626]   Expert 28 |    356 | GPU
DEBUG 01-15 10:09:44.336870.336870 lmp.py:1626]   Expert 12 |    380 | GPU
DEBUG 01-15 10:09:44.336089.336089 lmp.py:1626]   Expert 25 |    397 | GPU
DEBUG 01-15 10:09:44.336739.336739 lmp.py:1626]   Expert 11 |    400 | GPU
DEBUG 01-15 10:09:44.336064.336064 lmp.py:1626]   Expert 30 |    832 | GPU
DEBUG 01-15 10:09:44.336529.336529 lmp.py:1627] 
DEBUG 01-15 10:09:44.336529.336529 lmp.py:1627]   CPU total tokens: 3245 (26.4%)
DEBUG 01-15 10:09:44.336847.336847 lmp.py:1628]   GPU total tokens: 9043 (73.6%)
DEBUG 01-15 10:09:44.336696.336696 cuda_h.py:19] end experts_map_get cost 0.0020978450775146484 seconds
DEBUG 01-15 10:09:44.336043.336043 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.336521.336521 lmp.py:1636] 
DEBUG 01-15 10:09:44.336521.336521 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.336477.336477 cuda_h.py:19] end cpu_experts_submit cost 7.152557373046875e-05 seconds
DEBUG 01-15 10:09:44.336849.336849 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.336520.336520 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.336030.336030 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.337664.337664 cuda_h.py:19] end allocate_cuda_memory cost 0.00028324127197265625 seconds
DEBUG 01-15 10:09:44.337067.337067 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.337797.337797 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.337242.337242 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.337475.337475 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ec3eb7c9-3d33-4bc0-9265-75772d288dd8
DEBUG 01-15 10:09:44.337867.337867 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.338478.338478 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.338205.338205 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:44.338405.338405 client.py:127] Model loaded
DEBUG 01-15 10:09:44.338725.338725 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.338550.338550 cuda_h.py:19] end restore2model cost 0.0004630088806152344 seconds
DEBUG 01-15 10:09:44.338618.338618 cuda_h.py:19] end sllm_worker_task cost 0.011393070220947266 seconds
INFO 01-15 10:09:44.338800.338800 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ec3eb7c9-3d33-4bc0-9265-75772d288dd8
DEBUG 01-15 10:09:44.339915.339915 cuda_h.py:19] end load_into_gpu_async cost 0.0013470649719238281 seconds
DEBUG 01-15 10:09:44.339963.339963 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.339853.339853 cuda_h.py:19] end move_flatidxs cost 0.0008990764617919922 seconds
DEBUG 01-15 10:09:44.339147.339147 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.340275.340275 cuda_h.py:19] end restore_tensors2 cost 0.001322031021118164 seconds
DEBUG 01-15 10:09:44.341938.341938 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004462480545043945 seconds
DEBUG 01-15 10:09:44.341047.341047 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.351997.351997 cuda_h.py:19] end restore2model cost 0.009830236434936523 seconds
DEBUG 01-15 10:09:44.351459.351459 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.01501154899597168 seconds
DEBUG 01-15 10:09:44.351336.351336 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.352409.352409 cuda_h.py:19] end group_tensors cost 0.012708425521850586 seconds
DEBUG 01-15 10:09:44.352606.352606 cuda_h.py:19] end gpu_sexperts cost 0.0008513927459716797 seconds
DEBUG 01-15 10:09:44.352006.352006 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.352524.352524 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.355380.355380 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002985239028930664 seconds
DEBUG 01-15 10:09:44.356617.356617 cuda_h.py:19] end group pad cost 0.0039136409759521484 seconds
DEBUG 01-15 10:09:44.356321.356321 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.357662.357662 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.357582.357582 cuda_h.py:19] end gpu_group_list cost 0.00048732757568359375 seconds
DEBUG 01-15 10:09:44.358499.358499 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.359586.359586 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0015499591827392578 seconds
DEBUG 01-15 10:09:44.359602.359602 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.360691.360691 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.029273986816406e-05 seconds
DEBUG 01-15 10:09:44.360931.360931 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.374582.374582 cuda_h.py:19] end group_einsum cost 0.017595291137695312 seconds
DEBUG 01-15 10:09:44.374289.374289 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.379294.379294 cuda_h.py:19] end get_outputs_cpu1 cost 0.004218101501464844 seconds
DEBUG 01-15 10:09:44.379015.379015 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0417330265045166 seconds
DEBUG 01-15 10:09:44.380515.380515 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0205533504486084 seconds
DEBUG 01-15 10:09:44.380301.380301 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.381429.381429 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.381667.381667 cuda_h.py:19] end index_scatter cost 9.560585021972656e-05 seconds
DEBUG 01-15 10:09:44.381242.381242 cuda_h.py:19] end cpuoutputsdeal cost 0.0007493495941162109 seconds
DEBUG 01-15 10:09:44.381171.381171 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.381046.381046 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ec3eb7c9-3d33-4bc0-9265-75772d288dd8
INFO 01-15 10:09:44.389668.389668 client.py:127] Model loaded
DEBUG 01-15 10:09:44.389810.389810 cuda_h.py:19] end wait_experts cost 0.0077664852142333984 seconds
DEBUG 01-15 10:09:44.389102.389102 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.389966.389966 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.389106.389106 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.389657.389657 cuda_h.py:19] end gpu_group_tensor cost 0.00019693374633789062 seconds
DEBUG 01-15 10:09:44.390634.390634 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.390864.390864 cuda_h.py:19] end gpu_group_einsum cost 0.0006785392761230469 seconds
DEBUG 01-15 10:09:44.390730.390730 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.390170.390170 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.391743.391743 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002770423889160156 seconds
DEBUG 01-15 10:09:44.391957.391957 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.391437.391437 cuda_h.py:19] end concat_expert_out cost 6.628036499023438e-05 seconds
DEBUG 01-15 10:09:44.391586.391586 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.391589.391589 cuda_h.py:19] end index_scatter cost 6.604194641113281e-05 seconds
DEBUG 01-15 10:09:44.391750.391750 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007269382476806641 seconds
DEBUG 01-15 10:09:44.391323.391323 cuda_h.py:19] end gpu_experts cost 0.002203702926635742 seconds
DEBUG 01-15 10:09:44.391459.391459 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.05854511260986328 seconds
DEBUG 01-15 10:09:44.392313.392313 cuda_h.py:19] end prefill_layer cost 0.06589055061340332 seconds
DEBUG 01-15 10:09:44.392217.392217 lmp.py:1552] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-15 10:09:44.392271.392271 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.392750.392750 lmp.py:1495] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-15 10:09:44.392459.392459 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:44.392123.392123 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-15 10:09:44.392072.392072 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.647804260253906e-05 seconds
DEBUG 01-15 10:09:44.392066.392066 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.414817810058594e-05 seconds
DEBUG 01-15 10:09:44.392584.392584 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.392216.392216 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.393139.393139 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.393651.393651 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.393415.393415 cuda_h.py:19] end allocate_cuda_memory cost 0.0002455711364746094 seconds
DEBUG 01-15 10:09:44.393870.393870 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.393660.393660 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.393200.393200 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.393937.393937 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.393163.393163 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a9f41b0-612e-445f-9365-d7fe15690b8c
DEBUG 01-15 10:09:44.393762.393762 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.394866.394866 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.394259.394259 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a9f41b0-612e-445f-9365-d7fe15690b8c
DEBUG 01-15 10:09:44.394142.394142 cuda_h.py:19] end load_into_gpu_async cost 0.0012221336364746094 seconds
DEBUG 01-15 10:09:44.394699.394699 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.394311.394311 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-15 10:09:44.395829.395829 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019893646240234375 seconds
INFO 01-15 10:09:44.395103.395103 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a9f41b0-612e-445f-9365-d7fe15690b8c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.398357.398357 cuda_h.py:19] end self_attn cost 0.0041158199310302734 seconds
DEBUG 01-15 10:09:44.398091.398091 cuda_h.py:19] end iln_self_attn_paln cost 0.005807638168334961 seconds
DEBUG 01-15 10:09:44.398193.398193 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-15 10:09:44.398724.398724 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.399034.399034 cuda_h.py:19] end gate cost 0.0007183551788330078 seconds
DEBUG 01-15 10:09:44.399400.399400 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.399803.399803 lmp.py:1616] 
DEBUG 01-15 10:09:44.399803.399803 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.400997.400997 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.400461.400461 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.400773.400773 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.400754.400754 lmp.py:1620] 
DEBUG 01-15 10:09:44.400754.400754 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.400364.400364 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.400829.400829 lmp.py:1626]   Expert 12 |     18 | CPU
DEBUG 01-15 10:09:44.400147.400147 lmp.py:1626]   Expert 47 |     26 | CPU
DEBUG 01-15 10:09:44.400466.400466 lmp.py:1626]   Expert 38 |     31 | CPU
DEBUG 01-15 10:09:44.400447.400447 lmp.py:1626]   Expert 27 |     34 | CPU
DEBUG 01-15 10:09:44.400189.400189 lmp.py:1626]   Expert 16 |     37 | CPU
DEBUG 01-15 10:09:44.400501.400501 lmp.py:1626]   Expert 52 |     38 | CPU
DEBUG 01-15 10:09:44.400429.400429 lmp.py:1626]   Expert 63 |     46 | CPU
DEBUG 01-15 10:09:44.400880.400880 lmp.py:1626]   Expert  4 |     60 | CPU
DEBUG 01-15 10:09:44.400331.400331 lmp.py:1626]   Expert 44 |     64 | CPU
DEBUG 01-15 10:09:44.400450.400450 lmp.py:1626]   Expert 61 |     64 | CPU
DEBUG 01-15 10:09:44.400153.400153 lmp.py:1626]   Expert 43 |     65 | CPU
DEBUG 01-15 10:09:44.400763.400763 lmp.py:1626]   Expert 34 |     76 | CPU
DEBUG 01-15 10:09:44.400036.400036 lmp.py:1626]   Expert 53 |     79 | CPU
DEBUG 01-15 10:09:44.400686.400686 lmp.py:1626]   Expert  0 |     85 | CPU
DEBUG 01-15 10:09:44.400627.400627 lmp.py:1626]   Expert 32 |     90 | CPU
DEBUG 01-15 10:09:44.400376.400376 lmp.py:1626]   Expert 37 |     91 | CPU
DEBUG 01-15 10:09:44.400503.400503 lmp.py:1626]   Expert 13 |    103 | CPU
DEBUG 01-15 10:09:44.400152.400152 lmp.py:1626]   Expert 39 |    112 | CPU
DEBUG 01-15 10:09:44.400279.400279 lmp.py:1626]   Expert 11 |    121 | CPU
DEBUG 01-15 10:09:44.400929.400929 lmp.py:1626]   Expert 21 |    122 | CPU
DEBUG 01-15 10:09:44.400724.400724 lmp.py:1626]   Expert 20 |    127 | CPU
DEBUG 01-15 10:09:44.400851.400851 lmp.py:1626]   Expert  8 |    129 | CPU
DEBUG 01-15 10:09:44.400931.400931 lmp.py:1626]   Expert 60 |    132 | CPU
DEBUG 01-15 10:09:44.400535.400535 lmp.py:1626]   Expert 14 |    135 | CPU
DEBUG 01-15 10:09:44.400423.400423 lmp.py:1626]   Expert 57 |    138 | CPU
DEBUG 01-15 10:09:44.400311.400311 lmp.py:1626]   Expert 22 |    139 | CPU
DEBUG 01-15 10:09:44.400007.400007 lmp.py:1626]   Expert 45 |    152 | CPU
DEBUG 01-15 10:09:44.400942.400942 lmp.py:1626]   Expert  2 |    155 | CPU
DEBUG 01-15 10:09:44.400161.400161 lmp.py:1626]   Expert 18 |    157 | CPU
DEBUG 01-15 10:09:44.400241.400241 lmp.py:1626]   Expert 23 |    159 | CPU
DEBUG 01-15 10:09:44.400845.400845 lmp.py:1626]   Expert 17 |    161 | CPU
DEBUG 01-15 10:09:44.400686.400686 lmp.py:1626]   Expert  7 |    162 | CPU
DEBUG 01-15 10:09:44.400813.400813 lmp.py:1626]   Expert 58 |    162 | GPU
DEBUG 01-15 10:09:44.400940.400940 lmp.py:1626]   Expert 30 |    168 | GPU
DEBUG 01-15 10:09:44.400921.400921 lmp.py:1626]   Expert 42 |    170 | GPU
DEBUG 01-15 10:09:44.400564.400564 lmp.py:1626]   Expert 48 |    177 | GPU
DEBUG 01-15 10:09:44.400730.400730 lmp.py:1626]   Expert 49 |    180 | GPU
DEBUG 01-15 10:09:44.400134.400134 lmp.py:1626]   Expert 55 |    181 | GPU
DEBUG 01-15 10:09:44.400300.400300 lmp.py:1626]   Expert 62 |    181 | GPU
DEBUG 01-15 10:09:44.401705.401705 lmp.py:1626]   Expert 51 |    184 | GPU
DEBUG 01-15 10:09:44.401454.401454 lmp.py:1626]   Expert 35 |    185 | GPU
DEBUG 01-15 10:09:44.401104.401104 lmp.py:1626]   Expert 29 |    188 | GPU
DEBUG 01-15 10:09:44.401707.401707 lmp.py:1626]   Expert 25 |    191 | GPU
DEBUG 01-15 10:09:44.401834.401834 lmp.py:1626]   Expert  6 |    193 | GPU
DEBUG 01-15 10:09:44.401722.401722 lmp.py:1626]   Expert 36 |    194 | GPU
DEBUG 01-15 10:09:44.401180.401180 lmp.py:1626]   Expert  1 |    197 | GPU
DEBUG 01-15 10:09:44.401161.401161 lmp.py:1626]   Expert 31 |    206 | GPU
DEBUG 01-15 10:09:44.401141.401141 lmp.py:1626]   Expert 28 |    223 | GPU
DEBUG 01-15 10:09:44.401838.401838 lmp.py:1626]   Expert  5 |    231 | GPU
DEBUG 01-15 10:09:44.401295.401295 lmp.py:1626]   Expert 41 |    231 | GPU
DEBUG 01-15 10:09:44.401998.401998 lmp.py:1626]   Expert 54 |    231 | GPU
DEBUG 01-15 10:09:44.401363.401363 lmp.py:1626]   Expert  9 |    237 | GPU
DEBUG 01-15 10:09:44.401728.401728 lmp.py:1626]   Expert 19 |    239 | GPU
DEBUG 01-15 10:09:44.401570.401570 lmp.py:1626]   Expert 24 |    255 | GPU
DEBUG 01-15 10:09:44.401458.401458 lmp.py:1626]   Expert 50 |    289 | GPU
DEBUG 01-15 10:09:44.401439.401439 lmp.py:1626]   Expert 46 |    304 | GPU
DEBUG 01-15 10:09:44.401844.401844 lmp.py:1626]   Expert 59 |    311 | GPU
DEBUG 01-15 10:09:44.401010.401010 lmp.py:1626]   Expert 56 |    379 | GPU
DEBUG 01-15 10:09:44.401136.401136 lmp.py:1626]   Expert 26 |    403 | GPU
DEBUG 01-15 10:09:44.401779.401779 lmp.py:1626]   Expert 33 |    423 | GPU
DEBUG 01-15 10:09:44.401191.401191 lmp.py:1626]   Expert  3 |    589 | GPU
DEBUG 01-15 10:09:44.401509.401509 lmp.py:1626]   Expert 10 |    639 | GPU
DEBUG 01-15 10:09:44.401874.401874 lmp.py:1626]   Expert 15 |    648 | GPU
DEBUG 01-15 10:09:44.401001.401001 lmp.py:1626]   Expert 40 |    791 | GPU
DEBUG 01-15 10:09:44.401558.401558 lmp.py:1627] 
DEBUG 01-15 10:09:44.401558.401558 lmp.py:1627]   CPU total tokens: 3108 (25.3%)
DEBUG 01-15 10:09:44.401923.401923 lmp.py:1628]   GPU total tokens: 9180 (74.7%)
DEBUG 01-15 10:09:44.401772.401772 cuda_h.py:19] end experts_map_get cost 0.0019495487213134766 seconds
DEBUG 01-15 10:09:44.401741.401741 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.401087.401087 lmp.py:1636] 
DEBUG 01-15 10:09:44.401087.401087 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.401990.401990 cuda_h.py:19] end cpu_experts_submit cost 7.033348083496094e-05 seconds
DEBUG 01-15 10:09:44.401547.401547 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
INFO 01-15 10:09:44.401656.401656 client.py:127] Model loaded
DEBUG 01-15 10:09:44.402713.402713 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.402321.402321 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.402934.402934 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.402732.402732 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.402246.402246 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.403885.403885 cuda_h.py:19] end allocate_cuda_memory cost 0.0002143383026123047 seconds
DEBUG 01-15 10:09:44.403596.403596 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.403306.403306 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.403453.403453 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.403262.403262 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 76048f5f-b535-47fd-b75b-8793610036c0
DEBUG 01-15 10:09:44.403230.403230 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.403317.403317 cuda_h.py:19] end move_flatidxs cost 0.0008695125579833984 seconds
DEBUG 01-15 10:09:44.403438.403438 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.403345.403345 cuda_h.py:19] end restore2model cost 0.0012288093566894531 seconds
DEBUG 01-15 10:09:44.403896.403896 cuda_h.py:19] end sllm_worker_task cost 0.010959386825561523 seconds
INFO 01-15 10:09:44.405510.405510 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 76048f5f-b535-47fd-b75b-8793610036c0
DEBUG 01-15 10:09:44.405672.405672 cuda_h.py:19] end load_into_gpu_async cost 0.0022318363189697266 seconds
DEBUG 01-15 10:09:44.405064.405064 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.406297.406297 cuda_h.py:19] end restore_tensors2 cost 0.0005898475646972656 seconds
DEBUG 01-15 10:09:44.406704.406704 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003685474395751953 seconds
DEBUG 01-15 10:09:44.406196.406196 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.409261.409261 cuda_h.py:19] end restore2model cost 0.0032753944396972656 seconds
DEBUG 01-15 10:09:44.409992.409992 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007581949234008789 seconds
DEBUG 01-15 10:09:44.409986.409986 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.409979.409979 cuda_h.py:19] end gpu_sexperts cost 0.00033926963806152344 seconds
DEBUG 01-15 10:09:44.410206.410206 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.411858.411858 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001806020736694336 seconds
DEBUG 01-15 10:09:44.412453.412453 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.413866.413866 cuda_h.py:19] end gpu_group_list cost 0.00039124488830566406 seconds
DEBUG 01-15 10:09:44.413871.413871 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.414487.414487 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009322166442871094 seconds
DEBUG 01-15 10:09:44.414662.414662 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.414174.414174 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-15 10:09:44.414592.414592 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.414541.414541 cuda_h.py:19] end group_tensors cost 0.010566234588623047 seconds
DEBUG 01-15 10:09:44.415156.415156 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.419164.419164 cuda_h.py:19] end group pad cost 0.0039212703704833984 seconds
DEBUG 01-15 10:09:44.419477.419477 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.437557.437557 cuda_h.py:19] end group_einsum cost 0.01854228973388672 seconds
DEBUG 01-15 10:09:44.438391.438391 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.442389.442389 cuda_h.py:19] end get_outputs_cpu1 cost 0.00403904914855957 seconds
DEBUG 01-15 10:09:44.442143.442143 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04017782211303711 seconds
DEBUG 01-15 10:09:44.444480.444480 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.029778718948364258 seconds
DEBUG 01-15 10:09:44.444527.444527 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.445876.445876 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.445185.445185 cuda_h.py:19] end index_scatter cost 0.00019621849060058594 seconds
DEBUG 01-15 10:09:44.446542.446542 cuda_h.py:19] end cpuoutputsdeal cost 0.0015511512756347656 seconds
DEBUG 01-15 10:09:44.446222.446222 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.446589.446589 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 76048f5f-b535-47fd-b75b-8793610036c0
INFO 01-15 10:09:44.456720.456720 client.py:127] Model loaded
DEBUG 01-15 10:09:44.456532.456532 cuda_h.py:19] end wait_experts cost 0.009584426879882812 seconds
DEBUG 01-15 10:09:44.456019.456019 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.456097.456097 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.456041.456041 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.457800.457800 cuda_h.py:19] end gpu_group_tensor cost 0.00043654441833496094 seconds
DEBUG 01-15 10:09:44.457299.457299 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.458004.458004 cuda_h.py:19] end gpu_group_einsum cost 0.0011730194091796875 seconds
DEBUG 01-15 10:09:44.458192.458192 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.459945.459945 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.460836.460836 cuda_h.py:19] end all_expert_outputs_slices cost 0.0009872913360595703 seconds
DEBUG 01-15 10:09:44.460282.460282 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.460675.460675 cuda_h.py:19] end concat_expert_out cost 0.0001633167266845703 seconds
DEBUG 01-15 10:09:44.460713.460713 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.460900.460900 cuda_h.py:19] end index_scatter cost 0.00014972686767578125 seconds
DEBUG 01-15 10:09:44.460506.460506 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0019495487213134766 seconds
DEBUG 01-15 10:09:44.461327.461327 cuda_h.py:19] end gpu_experts cost 0.004784584045410156 seconds
DEBUG 01-15 10:09:44.461188.461188 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.0625154972076416 seconds
DEBUG 01-15 10:09:44.462155.462155 cuda_h.py:19] end prefill_layer cost 0.06945204734802246 seconds
DEBUG 01-15 10:09:44.462127.462127 lmp.py:1552] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-15 10:09:44.462521.462521 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.462676.462676 lmp.py:1495] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-15 10:09:44.462493.462493 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:44.462701.462701 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-15 10:09:44.462580.462580 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.081031799316406e-05 seconds
DEBUG 01-15 10:09:44.462240.462240 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.463331.463331 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00033974647521972656 seconds
DEBUG 01-15 10:09:44.463694.463694 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.463023.463023 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.463445.463445 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.463793.463793 cuda_h.py:19] end allocate_cuda_memory cost 0.0003123283386230469 seconds
DEBUG 01-15 10:09:44.464531.464531 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.464817.464817 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.464123.464123 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.464641.464641 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1264840b-e72a-4aa8-906d-65c50c2a1477
DEBUG 01-15 10:09:44.464598.464598 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.464273.464273 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.465398.465398 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.469238.469238 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1264840b-e72a-4aa8-906d-65c50c2a1477
DEBUG 01-15 10:09:44.469209.469209 cuda_h.py:19] end load_into_gpu_async cost 0.00575709342956543 seconds
DEBUG 01-15 10:09:44.469309.469309 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.470732.470732 cuda_h.py:19] end restore_tensors2 cost 0.00013566017150878906 seconds
DEBUG 01-15 10:09:44.470648.470648 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0066852569580078125 seconds
INFO 01-15 10:09:44.470174.470174 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1264840b-e72a-4aa8-906d-65c50c2a1477
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.472020.472020 cuda_h.py:19] end self_attn cost 0.0072002410888671875 seconds
DEBUG 01-15 10:09:44.473054.473054 cuda_h.py:19] end iln_self_attn_paln cost 0.009945392608642578 seconds
DEBUG 01-15 10:09:44.473812.473812 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-15 10:09:44.473868.473868 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.474567.474567 cuda_h.py:19] end gate cost 0.0010561943054199219 seconds
DEBUG 01-15 10:09:44.474132.474132 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.475012.475012 lmp.py:1616] 
DEBUG 01-15 10:09:44.475012.475012 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.475060.475060 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.475902.475902 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.475075.475075 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.475340.475340 lmp.py:1620] 
DEBUG 01-15 10:09:44.475340.475340 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.475844.475844 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.475448.475448 lmp.py:1626]   Expert 19 |     24 | CPU
DEBUG 01-15 10:09:44.475283.475283 lmp.py:1626]   Expert 42 |     24 | CPU
DEBUG 01-15 10:09:44.475403.475403 lmp.py:1626]   Expert 30 |     26 | CPU
DEBUG 01-15 10:09:44.475284.475284 lmp.py:1626]   Expert 32 |     45 | CPU
DEBUG 01-15 10:09:44.475165.475165 lmp.py:1626]   Expert  6 |     58 | CPU
DEBUG 01-15 10:09:44.475808.475808 lmp.py:1626]   Expert 53 |     74 | CPU
DEBUG 01-15 10:09:44.475213.475213 lmp.py:1626]   Expert  5 |     75 | CPU
DEBUG 01-15 10:09:44.475094.475094 lmp.py:1626]   Expert  1 |     77 | CPU
DEBUG 01-15 10:09:44.475737.475737 lmp.py:1626]   Expert 13 |    122 | CPU
DEBUG 01-15 10:09:44.475380.475380 lmp.py:1626]   Expert  9 |    125 | CPU
DEBUG 01-15 10:09:44.475785.475785 lmp.py:1626]   Expert 63 |    127 | CPU
DEBUG 01-15 10:09:44.475428.475428 lmp.py:1626]   Expert 34 |    129 | CPU
DEBUG 01-15 10:09:44.475832.475832 lmp.py:1626]   Expert 58 |    130 | CPU
DEBUG 01-15 10:09:44.475860.475860 lmp.py:1626]   Expert 50 |    131 | CPU
DEBUG 01-15 10:09:44.475894.475894 lmp.py:1626]   Expert 18 |    135 | CPU
DEBUG 01-15 10:09:44.475205.475205 lmp.py:1626]   Expert 11 |    136 | CPU
DEBUG 01-15 10:09:44.475087.475087 lmp.py:1626]   Expert 26 |    137 | CPU
DEBUG 01-15 10:09:44.475491.475491 lmp.py:1626]   Expert 31 |    137 | CPU
DEBUG 01-15 10:09:44.475896.475896 lmp.py:1626]   Expert 59 |    141 | CPU
DEBUG 01-15 10:09:44.475062.475062 lmp.py:1626]   Expert 40 |    143 | CPU
DEBUG 01-15 10:09:44.475467.475467 lmp.py:1626]   Expert 12 |    145 | CPU
DEBUG 01-15 10:09:44.475871.475871 lmp.py:1626]   Expert 46 |    150 | CPU
DEBUG 01-15 10:09:44.476276.476276 lmp.py:1626]   Expert 48 |    151 | CPU
DEBUG 01-15 10:09:44.476680.476680 lmp.py:1626]   Expert 20 |    153 | CPU
DEBUG 01-15 10:09:44.476085.476085 lmp.py:1626]   Expert  2 |    154 | CPU
DEBUG 01-15 10:09:44.476966.476966 lmp.py:1626]   Expert  4 |    154 | CPU
DEBUG 01-15 10:09:44.476609.476609 lmp.py:1626]   Expert 33 |    155 | CPU
DEBUG 01-15 10:09:44.476014.476014 lmp.py:1626]   Expert 61 |    155 | CPU
DEBUG 01-15 10:09:44.476087.476087 lmp.py:1626]   Expert 56 |    156 | CPU
DEBUG 01-15 10:09:44.476730.476730 lmp.py:1626]   Expert 35 |    161 | CPU
DEBUG 01-15 10:09:44.476135.476135 lmp.py:1626]   Expert 10 |    168 | CPU
DEBUG 01-15 10:09:44.476539.476539 lmp.py:1626]   Expert 51 |    171 | CPU
DEBUG 01-15 10:09:44.476421.476421 lmp.py:1626]   Expert 55 |    173 | GPU
DEBUG 01-15 10:09:44.476587.476587 lmp.py:1626]   Expert 36 |    178 | GPU
DEBUG 01-15 10:09:44.476753.476753 lmp.py:1626]   Expert  8 |    183 | GPU
DEBUG 01-15 10:09:44.476919.476919 lmp.py:1626]   Expert 52 |    187 | GPU
DEBUG 01-15 10:09:44.476085.476085 lmp.py:1626]   Expert 37 |    191 | GPU
DEBUG 01-15 10:09:44.476728.476728 lmp.py:1626]   Expert  0 |    203 | GPU
DEBUG 01-15 10:09:44.476894.476894 lmp.py:1626]   Expert 57 |    205 | GPU
DEBUG 01-15 10:09:44.476299.476299 lmp.py:1626]   Expert 39 |    220 | GPU
DEBUG 01-15 10:09:44.476465.476465 lmp.py:1626]   Expert 25 |    226 | GPU
DEBUG 01-15 10:09:44.476631.476631 lmp.py:1626]   Expert 62 |    234 | GPU
DEBUG 01-15 10:09:44.476036.476036 lmp.py:1626]   Expert 38 |    242 | GPU
DEBUG 01-15 10:09:44.476884.476884 lmp.py:1626]   Expert  7 |    245 | GPU
DEBUG 01-15 10:09:44.476243.476243 lmp.py:1626]   Expert  3 |    246 | GPU
DEBUG 01-15 10:09:44.476078.476078 lmp.py:1626]   Expert 24 |    247 | GPU
DEBUG 01-15 10:09:44.476721.476721 lmp.py:1626]   Expert 28 |    254 | GPU
DEBUG 01-15 10:09:44.476125.476125 lmp.py:1626]   Expert 27 |    255 | GPU
DEBUG 01-15 10:09:44.476530.476530 lmp.py:1626]   Expert 60 |    258 | GPU
DEBUG 01-15 10:09:44.476696.476696 lmp.py:1626]   Expert 49 |    259 | GPU
DEBUG 01-15 10:09:44.476101.476101 lmp.py:1626]   Expert 21 |    261 | GPU
DEBUG 01-15 10:09:44.476744.476744 lmp.py:1626]   Expert 16 |    267 | GPU
DEBUG 01-15 10:09:44.476148.476148 lmp.py:1626]   Expert 43 |    269 | GPU
DEBUG 01-15 10:09:44.476553.476553 lmp.py:1626]   Expert 23 |    274 | GPU
DEBUG 01-15 10:09:44.476957.476957 lmp.py:1626]   Expert 29 |    276 | GPU
DEBUG 01-15 10:09:44.476600.476600 lmp.py:1626]   Expert 15 |    291 | GPU
DEBUG 01-15 10:09:44.476005.476005 lmp.py:1626]   Expert 22 |    292 | GPU
DEBUG 01-15 10:09:44.476509.476509 lmp.py:1626]   Expert 41 |    294 | GPU
DEBUG 01-15 10:09:44.476774.476774 lmp.py:1626]   Expert 47 |    294 | GPU
DEBUG 01-15 10:09:44.476609.476609 lmp.py:1626]   Expert 44 |    306 | GPU
DEBUG 01-15 10:09:44.476014.476014 lmp.py:1626]   Expert 54 |    355 | GPU
DEBUG 01-15 10:09:44.476180.476180 lmp.py:1626]   Expert 14 |    375 | GPU
DEBUG 01-15 10:09:44.476823.476823 lmp.py:1626]   Expert 17 |    406 | GPU
DEBUG 01-15 10:09:44.476989.476989 lmp.py:1626]   Expert 45 |    453 | GPU
DEBUG 01-15 10:09:44.476109.476109 lmp.py:1627] 
DEBUG 01-15 10:09:44.476109.476109 lmp.py:1627]   CPU total tokens: 3869 (31.5%)
DEBUG 01-15 10:09:44.476944.476944 lmp.py:1628]   GPU total tokens: 8419 (68.5%)
DEBUG 01-15 10:09:44.476024.476024 cuda_h.py:19] end experts_map_get cost 0.0018901824951171875 seconds
DEBUG 01-15 10:09:44.476424.476424 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.476757.476757 lmp.py:1636] 
DEBUG 01-15 10:09:44.476757.476757 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.476567.476567 cuda_h.py:19] end cpu_experts_submit cost 7.295608520507812e-05 seconds
DEBUG 01-15 10:09:44.477217.477217 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.477305.477305 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.477499.477499 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.477727.477727 cuda_h.py:19] end allocate_cuda_memory cost 0.0004425048828125 seconds
DEBUG 01-15 10:09:44.477465.477465 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.477897.477897 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.477918.477918 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.478621.478621 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40ca29ce-6d94-45d1-bccb-f54a1d43e1d7
DEBUG 01-15 10:09:44.478646.478646 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:44.479290.479290 client.py:127] Model loaded
DEBUG 01-15 10:09:44.479713.479713 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.479775.479775 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:44.479175.479175 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40ca29ce-6d94-45d1-bccb-f54a1d43e1d7
DEBUG 01-15 10:09:44.479173.479173 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.479332.479332 cuda_h.py:19] end load_into_gpu_async cost 0.0019330978393554688 seconds
DEBUG 01-15 10:09:44.479148.479148 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.480760.480760 cuda_h.py:19] end move_flatidxs cost 0.0010306835174560547 seconds
DEBUG 01-15 10:09:44.481656.481656 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.481358.481358 cuda_h.py:19] end restore_tensors2 cost 0.0014090538024902344 seconds
DEBUG 01-15 10:09:44.481897.481897 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004408597946166992 seconds
DEBUG 01-15 10:09:44.481099.481099 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.482852.482852 cuda_h.py:19] end restore2model cost 0.001283407211303711 seconds
DEBUG 01-15 10:09:44.483685.483685 cuda_h.py:19] end sllm_worker_task cost 0.01992201805114746 seconds
DEBUG 01-15 10:09:44.486017.486017 cuda_h.py:19] end restore2model cost 0.00442814826965332 seconds
DEBUG 01-15 10:09:44.486616.486616 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009117603302001953 seconds
DEBUG 01-15 10:09:44.486531.486531 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.486001.486001 cuda_h.py:19] end gpu_sexperts cost 0.00034880638122558594 seconds
DEBUG 01-15 10:09:44.486314.486314 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.489032.489032 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0024225711822509766 seconds
DEBUG 01-15 10:09:44.490985.490985 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.490159.490159 cuda_h.py:19] end gpu_group_list cost 0.0003619194030761719 seconds
DEBUG 01-15 10:09:44.491310.491310 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.492470.492470 cuda_h.py:19] end acpu_expert_weight_slices cost 0.001371622085571289 seconds
DEBUG 01-15 10:09:44.492194.492194 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.492322.492322 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-15 10:09:44.492879.492879 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.493716.493716 cuda_h.py:19] end group_tensors cost 0.012427091598510742 seconds
DEBUG 01-15 10:09:44.494355.494355 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.498195.498195 cuda_h.py:19] end group pad cost 0.004077434539794922 seconds
DEBUG 01-15 10:09:44.498284.498284 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.518945.518945 cuda_h.py:19] end group_einsum cost 0.019670963287353516 seconds
DEBUG 01-15 10:09:44.518725.518725 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.523959.523959 cuda_h.py:19] end get_outputs_cpu1 cost 0.004525899887084961 seconds
DEBUG 01-15 10:09:44.523138.523138 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.044165611267089844 seconds
DEBUG 01-15 10:09:44.524655.524655 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03222036361694336 seconds
DEBUG 01-15 10:09:44.525262.525262 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.525591.525591 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.525538.525538 cuda_h.py:19] end index_scatter cost 0.00012636184692382812 seconds
DEBUG 01-15 10:09:44.526542.526542 cuda_h.py:19] end cpuoutputsdeal cost 0.0011641979217529297 seconds
DEBUG 01-15 10:09:44.526278.526278 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.526969.526969 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40ca29ce-6d94-45d1-bccb-f54a1d43e1d7
INFO 01-15 10:09:44.531908.531908 client.py:127] Model loaded
DEBUG 01-15 10:09:44.531989.531989 cuda_h.py:19] end wait_experts cost 0.00476384162902832 seconds
DEBUG 01-15 10:09:44.531560.531560 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.531337.531337 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.531862.531862 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.531573.531573 cuda_h.py:19] end gpu_group_tensor cost 0.0002429485321044922 seconds
DEBUG 01-15 10:09:44.531379.531379 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.532819.532819 cuda_h.py:19] end gpu_group_einsum cost 0.0010056495666503906 seconds
DEBUG 01-15 10:09:44.532598.532598 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.532733.532733 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.533959.533959 cuda_h.py:19] end all_expert_outputs_slices cost 0.00037479400634765625 seconds
DEBUG 01-15 10:09:44.533867.533867 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.533049.533049 cuda_h.py:19] end concat_expert_out cost 6.508827209472656e-05 seconds
DEBUG 01-15 10:09:44.533747.533747 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.533028.533028 cuda_h.py:19] end index_scatter cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:44.533652.533652 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007638931274414062 seconds
DEBUG 01-15 10:09:44.533265.533265 cuda_h.py:19] end gpu_experts cost 0.002633810043334961 seconds
DEBUG 01-15 10:09:44.533917.533917 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06023573875427246 seconds
DEBUG 01-15 10:09:44.534108.534108 cuda_h.py:19] end prefill_layer cost 0.07206058502197266 seconds
DEBUG 01-15 10:09:44.534007.534007 lmp.py:1552] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-15 10:09:44.534994.534994 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.534598.534598 lmp.py:1495] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-15 10:09:44.534678.534678 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:44.534904.534904 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-15 10:09:44.534284.534284 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 4.4345855712890625e-05 seconds
DEBUG 01-15 10:09:44.534940.534940 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.486343383789062e-05 seconds
DEBUG 01-15 10:09:44.534729.534729 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.534533.534533 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.535615.535615 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.535127.535127 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.535178.535178 cuda_h.py:19] end allocate_cuda_memory cost 0.00045037269592285156 seconds
DEBUG 01-15 10:09:44.535318.535318 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.535923.535923 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.536545.536545 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.536150.536150 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.536052.536052 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1ae0eef5-ef6b-423f-83cc-e4d61bf9bd03
DEBUG 01-15 10:09:44.536784.536784 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.536499.536499 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.537466.537466 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1ae0eef5-ef6b-423f-83cc-e4d61bf9bd03
DEBUG 01-15 10:09:44.537973.537973 cuda_h.py:19] end load_into_gpu_async cost 0.0013034343719482422 seconds
DEBUG 01-15 10:09:44.537967.537967 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.537270.537270 cuda_h.py:19] end restore_tensors2 cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:44.537940.537940 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025594234466552734 seconds
INFO 01-15 10:09:44.537905.537905 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1ae0eef5-ef6b-423f-83cc-e4d61bf9bd03
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.542844.542844 cuda_h.py:19] end self_attn cost 0.005249977111816406 seconds
DEBUG 01-15 10:09:44.542765.542765 cuda_h.py:19] end iln_self_attn_paln cost 0.007577180862426758 seconds
DEBUG 01-15 10:09:44.542582.542582 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-15 10:09:44.542789.542789 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.543367.543367 cuda_h.py:19] end gate cost 0.0007963180541992188 seconds
DEBUG 01-15 10:09:44.543058.543058 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.543434.543434 lmp.py:1616] 
DEBUG 01-15 10:09:44.543434.543434 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.543528.543528 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.543462.543462 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.543966.543966 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.543808.543808 lmp.py:1620] 
DEBUG 01-15 10:09:44.543808.543808 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.543358.543358 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.543385.543385 lmp.py:1626]   Expert 34 |     28 | CPU
DEBUG 01-15 10:09:44.543744.543744 lmp.py:1626]   Expert  7 |     33 | CPU
DEBUG 01-15 10:09:44.544579.544579 lmp.py:1626]   Expert 13 |     42 | CPU
DEBUG 01-15 10:09:44.544507.544507 lmp.py:1626]   Expert 54 |     77 | CPU
DEBUG 01-15 10:09:44.544719.544719 lmp.py:1626]   Expert 18 |     84 | CPU
DEBUG 01-15 10:09:44.544170.544170 lmp.py:1626]   Expert 39 |     86 | CPU
DEBUG 01-15 10:09:44.544621.544621 lmp.py:1626]   Expert 49 |     87 | CPU
DEBUG 01-15 10:09:44.544072.544072 lmp.py:1626]   Expert 59 |    101 | CPU
DEBUG 01-15 10:09:44.544284.544284 lmp.py:1626]   Expert 16 |    106 | CPU
DEBUG 01-15 10:09:44.544735.544735 lmp.py:1626]   Expert  0 |    108 | CPU
DEBUG 01-15 10:09:44.544947.544947 lmp.py:1626]   Expert 21 |    109 | CPU
DEBUG 01-15 10:09:44.544921.544921 lmp.py:1626]   Expert 15 |    116 | CPU
DEBUG 01-15 10:09:44.544810.544810 lmp.py:1626]   Expert 41 |    118 | CPU
DEBUG 01-15 10:09:44.544645.544645 lmp.py:1626]   Expert 45 |    122 | CPU
DEBUG 01-15 10:09:44.544288.544288 lmp.py:1626]   Expert 22 |    124 | CPU
DEBUG 01-15 10:09:44.544692.544692 lmp.py:1626]   Expert 17 |    126 | CPU
DEBUG 01-15 10:09:44.544858.544858 lmp.py:1626]   Expert 52 |    134 | CPU
DEBUG 01-15 10:09:44.544263.544263 lmp.py:1626]   Expert  8 |    136 | CPU
DEBUG 01-15 10:09:44.544575.544575 lmp.py:1626]   Expert 61 |    136 | CPU
DEBUG 01-15 10:09:44.544933.544933 lmp.py:1626]   Expert 35 |    138 | CPU
DEBUG 01-15 10:09:44.544530.544530 lmp.py:1626]   Expert 38 |    141 | CPU
DEBUG 01-15 10:09:44.544650.544650 lmp.py:1626]   Expert 12 |    143 | CPU
DEBUG 01-15 10:09:44.544769.544769 lmp.py:1626]   Expert 48 |    147 | CPU
DEBUG 01-15 10:09:44.544604.544604 lmp.py:1626]   Expert 31 |    150 | CPU
DEBUG 01-15 10:09:44.544096.544096 lmp.py:1626]   Expert 36 |    155 | CPU
DEBUG 01-15 10:09:44.544600.544600 lmp.py:1626]   Expert 53 |    155 | CPU
DEBUG 01-15 10:09:44.544442.544442 lmp.py:1626]   Expert 50 |    158 | CPU
DEBUG 01-15 10:09:44.544085.544085 lmp.py:1626]   Expert 60 |    160 | CPU
DEBUG 01-15 10:09:44.544536.544536 lmp.py:1626]   Expert 40 |    162 | CPU
DEBUG 01-15 10:09:44.544748.544748 lmp.py:1626]   Expert 27 |    175 | CPU
DEBUG 01-15 10:09:44.544961.544961 lmp.py:1626]   Expert 19 |    194 | CPU
DEBUG 01-15 10:09:44.544935.544935 lmp.py:1626]   Expert  4 |    200 | CPU
DEBUG 01-15 10:09:44.544909.544909 lmp.py:1626]   Expert 29 |    202 | GPU
DEBUG 01-15 10:09:44.544883.544883 lmp.py:1626]   Expert 30 |    205 | GPU
DEBUG 01-15 10:09:44.544618.544618 lmp.py:1626]   Expert 11 |    217 | GPU
DEBUG 01-15 10:09:44.544592.544592 lmp.py:1626]   Expert 26 |    219 | GPU
DEBUG 01-15 10:09:44.544235.544235 lmp.py:1626]   Expert 20 |    220 | GPU
DEBUG 01-15 10:09:44.544170.544170 lmp.py:1626]   Expert 57 |    224 | GPU
DEBUG 01-15 10:09:44.544859.544859 lmp.py:1626]   Expert  6 |    225 | GPU
DEBUG 01-15 10:09:44.544264.544264 lmp.py:1626]   Expert 46 |    228 | GPU
DEBUG 01-15 10:09:44.544430.544430 lmp.py:1626]   Expert 43 |    231 | GPU
DEBUG 01-15 10:09:44.544742.544742 lmp.py:1626]   Expert 23 |    239 | GPU
DEBUG 01-15 10:09:44.544908.544908 lmp.py:1626]   Expert  2 |    241 | GPU
DEBUG 01-15 10:09:44.544120.544120 lmp.py:1626]   Expert 33 |    242 | GPU
DEBUG 01-15 10:09:44.544333.544333 lmp.py:1626]   Expert 42 |    246 | GPU
DEBUG 01-15 10:09:44.544830.544830 lmp.py:1626]   Expert 32 |    254 | GPU
DEBUG 01-15 10:09:44.544950.544950 lmp.py:1626]   Expert 55 |    254 | GPU
DEBUG 01-15 10:09:44.544931.544931 lmp.py:1626]   Expert 56 |    254 | GPU
DEBUG 01-15 10:09:44.544812.544812 lmp.py:1626]   Expert  3 |    259 | GPU
DEBUG 01-15 10:09:44.544740.544740 lmp.py:1626]   Expert  9 |    260 | GPU
DEBUG 01-15 10:09:44.544906.544906 lmp.py:1626]   Expert 28 |    261 | GPU
DEBUG 01-15 10:09:44.544787.544787 lmp.py:1626]   Expert 14 |    267 | GPU
DEBUG 01-15 10:09:44.544761.544761 lmp.py:1626]   Expert 51 |    276 | GPU
DEBUG 01-15 10:09:44.544736.544736 lmp.py:1626]   Expert  1 |    278 | GPU
DEBUG 01-15 10:09:44.544471.544471 lmp.py:1626]   Expert 44 |    278 | GPU
DEBUG 01-15 10:09:44.544545.544545 lmp.py:1626]   Expert 58 |    280 | GPU
DEBUG 01-15 10:09:44.544519.544519 lmp.py:1626]   Expert 37 |    288 | GPU
DEBUG 01-15 10:09:44.544493.544493 lmp.py:1626]   Expert 63 |    288 | GPU
DEBUG 01-15 10:09:44.545467.545467 lmp.py:1626]   Expert 47 |    292 | GPU
DEBUG 01-15 10:09:44.545202.545202 lmp.py:1626]   Expert 24 |    302 | GPU
DEBUG 01-15 10:09:44.545514.545514 lmp.py:1626]   Expert 10 |    312 | GPU
DEBUG 01-15 10:09:44.545495.545495 lmp.py:1626]   Expert 62 |    314 | GPU
DEBUG 01-15 10:09:44.545092.545092 lmp.py:1626]   Expert 25 |    316 | GPU
DEBUG 01-15 10:09:44.545496.545496 lmp.py:1626]   Expert  5 |    365 | GPU
DEBUG 01-15 10:09:44.545855.545855 lmp.py:1627] 
DEBUG 01-15 10:09:44.545855.545855 lmp.py:1627]   CPU total tokens: 3951 (32.2%)
INFO 01-15 10:09:44.545010.545010 client.py:127] Model loaded
DEBUG 01-15 10:09:44.545854.545854 lmp.py:1628]   GPU total tokens: 8337 (67.8%)
DEBUG 01-15 10:09:44.545678.545678 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.545812.545812 cuda_h.py:19] end experts_map_get cost 0.0019240379333496094 seconds
DEBUG 01-15 10:09:44.545196.545196 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.545509.545509 lmp.py:1636] 
DEBUG 01-15 10:09:44.545509.545509 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.545465.545465 cuda_h.py:19] end cpu_experts_submit cost 7.414817810058594e-05 seconds
DEBUG 01-15 10:09:44.545930.545930 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.546701.546701 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.546463.546463 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.546956.546956 cuda_h.py:19] end allocate_cuda_memory cost 0.0002522468566894531 seconds
DEBUG 01-15 10:09:44.546382.546382 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.546774.546774 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.547534.547534 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.547025.547025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aab2f965-92b2-43a3-aa86-4b8b9122e171
DEBUG 01-15 10:09:44.547390.547390 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.547844.547844 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.547513.547513 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.548792.548792 cuda_h.py:19] end restore2model cost 0.0026624202728271484 seconds
DEBUG 01-15 10:09:44.548239.548239 cuda_h.py:19] end sllm_worker_task cost 0.013283967971801758 seconds
DEBUG 01-15 10:09:44.548556.548556 cuda_h.py:19] end move_flatidxs cost 0.0008480548858642578 seconds
DEBUG 01-15 10:09:44.548386.548386 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:44.549143.549143 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aab2f965-92b2-43a3-aa86-4b8b9122e171
DEBUG 01-15 10:09:44.549173.549173 cuda_h.py:19] end load_into_gpu_async cost 0.0026197433471679688 seconds
DEBUG 01-15 10:09:44.549505.549505 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.550764.550764 cuda_h.py:19] end restore_tensors2 cost 0.0009605884552001953 seconds
DEBUG 01-15 10:09:44.550145.550145 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00433659553527832 seconds
DEBUG 01-15 10:09:44.550074.550074 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.553826.553826 cuda_h.py:19] end restore2model cost 0.0034356117248535156 seconds
DEBUG 01-15 10:09:44.554651.554651 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008054733276367188 seconds
DEBUG 01-15 10:09:44.554374.554374 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.554426.554426 cuda_h.py:19] end gpu_sexperts cost 0.00032210350036621094 seconds
DEBUG 01-15 10:09:44.554831.554831 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.554056.554056 cuda_h.py:19] end group_tensors cost 0.005548954010009766 seconds
DEBUG 01-15 10:09:44.555703.555703 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.557730.557730 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002463102340698242 seconds
DEBUG 01-15 10:09:44.558825.558825 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.558728.558728 cuda_h.py:19] end gpu_group_list cost 0.00037670135498046875 seconds
DEBUG 01-15 10:09:44.558788.558788 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.559086.559086 cuda_h.py:19] end group pad cost 0.0038814544677734375 seconds
DEBUG 01-15 10:09:44.559876.559876 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.560966.560966 cuda_h.py:19] end acpu_expert_weight_slices cost 0.001260519027709961 seconds
DEBUG 01-15 10:09:44.560340.560340 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.560848.560848 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.316734313964844e-05 seconds
DEBUG 01-15 10:09:44.560087.560087 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.582742.582742 cuda_h.py:19] end group_einsum cost 0.022811174392700195 seconds
DEBUG 01-15 10:09:44.582761.582761 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.587822.587822 cuda_h.py:19] end get_outputs_cpu1 cost 0.0049169063568115234 seconds
DEBUG 01-15 10:09:44.588291.588291 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04030919075012207 seconds
DEBUG 01-15 10:09:44.589652.589652 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.02863454818725586 seconds
DEBUG 01-15 10:09:44.589155.589155 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.590760.590760 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.590810.590810 cuda_h.py:19] end index_scatter cost 0.00017213821411132812 seconds
DEBUG 01-15 10:09:44.591265.591265 cuda_h.py:19] end cpuoutputsdeal cost 0.0016036033630371094 seconds
DEBUG 01-15 10:09:44.591831.591831 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.591132.591132 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aab2f965-92b2-43a3-aa86-4b8b9122e171
INFO 01-15 10:09:44.600713.600713 client.py:127] Model loaded
DEBUG 01-15 10:09:44.600903.600903 cuda_h.py:19] end wait_experts cost 0.008997201919555664 seconds
DEBUG 01-15 10:09:44.600720.600720 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.600943.600943 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.600012.600012 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.601705.601705 cuda_h.py:19] end gpu_group_tensor cost 0.0004284381866455078 seconds
DEBUG 01-15 10:09:44.601991.601991 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.602058.602058 cuda_h.py:19] end gpu_group_einsum cost 0.0010967254638671875 seconds
DEBUG 01-15 10:09:44.603888.603888 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.603389.603389 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.604251.604251 cuda_h.py:19] end all_expert_outputs_slices cost 0.0009353160858154297 seconds
DEBUG 01-15 10:09:44.604737.604737 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.604857.604857 cuda_h.py:19] end concat_expert_out cost 0.0001518726348876953 seconds
DEBUG 01-15 10:09:44.604207.604207 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.604195.604195 cuda_h.py:19] end index_scatter cost 0.00015020370483398438 seconds
DEBUG 01-15 10:09:44.605562.605562 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0018322467803955078 seconds
DEBUG 01-15 10:09:44.605316.605316 cuda_h.py:19] end gpu_experts cost 0.004475116729736328 seconds
DEBUG 01-15 10:09:44.605018.605018 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06281113624572754 seconds
DEBUG 01-15 10:09:44.606691.606691 cuda_h.py:19] end prefill_layer cost 0.07140231132507324 seconds
DEBUG 01-15 10:09:44.606377.606377 lmp.py:1552] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-15 10:09:44.606875.606875 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.606189.606189 lmp.py:1495] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-15 10:09:44.606833.606833 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:44.606961.606961 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-15 10:09:44.606653.606653 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.53131103515625e-05 seconds
DEBUG 01-15 10:09:44.606404.606404 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.00012755393981933594 seconds
DEBUG 01-15 10:09:44.606611.606611 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.606025.606025 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.606455.606455 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.607583.607583 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.607106.607106 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.607857.607857 cuda_h.py:19] end allocate_cuda_memory cost 0.00023508071899414062 seconds
DEBUG 01-15 10:09:44.607898.607898 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.607881.607881 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.607657.607657 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.607598.607598 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4bef3e97-0c8a-45c7-a1b2-5d84e120aff1
DEBUG 01-15 10:09:44.607051.607051 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.608259.608259 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.608694.608694 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4bef3e97-0c8a-45c7-a1b2-5d84e120aff1
DEBUG 01-15 10:09:44.608106.608106 cuda_h.py:19] end load_into_gpu_async cost 0.001010894775390625 seconds
DEBUG 01-15 10:09:44.608094.608094 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.608959.608959 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-15 10:09:44.608715.608715 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016031265258789062 seconds
INFO 01-15 10:09:44.608266.608266 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4bef3e97-0c8a-45c7-a1b2-5d84e120aff1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.615382.615382 cuda_h.py:19] end self_attn cost 0.006718873977661133 seconds
INFO 01-15 10:09:44.615815.615815 client.py:127] Model loaded
DEBUG 01-15 10:09:44.615452.615452 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.616953.616953 cuda_h.py:19] end restore2model cost 0.00047588348388671875 seconds
DEBUG 01-15 10:09:44.616345.616345 cuda_h.py:19] end sllm_worker_task cost 0.009111404418945312 seconds
DEBUG 01-15 10:09:44.616139.616139 cuda_h.py:19] end iln_self_attn_paln cost 0.009484529495239258 seconds
DEBUG 01-15 10:09:44.616549.616549 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-15 10:09:44.616803.616803 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.617871.617871 cuda_h.py:19] end gate cost 0.0007567405700683594 seconds
DEBUG 01-15 10:09:44.617468.617468 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.617240.617240 lmp.py:1616] 
DEBUG 01-15 10:09:44.617240.617240 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.617142.617142 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.618852.618852 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.618217.618217 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.618244.618244 lmp.py:1620] 
DEBUG 01-15 10:09:44.618244.618244 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.618225.618225 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.618729.618729 lmp.py:1626]   Expert 15 |     63 | CPU
DEBUG 01-15 10:09:44.618279.618279 lmp.py:1626]   Expert 41 |     73 | CPU
DEBUG 01-15 10:09:44.618875.618875 lmp.py:1626]   Expert  0 |     76 | CPU
DEBUG 01-15 10:09:44.618711.618711 lmp.py:1626]   Expert 63 |     77 | CPU
DEBUG 01-15 10:09:44.618069.618069 lmp.py:1626]   Expert 20 |     83 | CPU
DEBUG 01-15 10:09:44.618142.618142 lmp.py:1626]   Expert  7 |     89 | CPU
DEBUG 01-15 10:09:44.618262.618262 lmp.py:1626]   Expert 45 |     89 | CPU
DEBUG 01-15 10:09:44.618620.618620 lmp.py:1626]   Expert 28 |     98 | CPU
DEBUG 01-15 10:09:44.618124.618124 lmp.py:1626]   Expert 54 |    105 | CPU
DEBUG 01-15 10:09:44.618913.618913 lmp.py:1626]   Expert 12 |    111 | CPU
DEBUG 01-15 10:09:44.618702.618702 lmp.py:1626]   Expert 40 |    121 | CPU
DEBUG 01-15 10:09:44.618537.618537 lmp.py:1626]   Expert 52 |    121 | CPU
DEBUG 01-15 10:09:44.618657.618657 lmp.py:1626]   Expert 59 |    122 | CPU
DEBUG 01-15 10:09:44.618776.618776 lmp.py:1626]   Expert  5 |    124 | CPU
DEBUG 01-15 10:09:44.618896.618896 lmp.py:1626]   Expert  4 |    129 | CPU
DEBUG 01-15 10:09:44.618255.618255 lmp.py:1626]   Expert 34 |    132 | CPU
DEBUG 01-15 10:09:44.618374.618374 lmp.py:1626]   Expert 61 |    135 | CPU
DEBUG 01-15 10:09:44.618256.618256 lmp.py:1626]   Expert 62 |    135 | CPU
DEBUG 01-15 10:09:44.618376.618376 lmp.py:1626]   Expert 13 |    136 | CPU
DEBUG 01-15 10:09:44.618972.618972 lmp.py:1626]   Expert 55 |    136 | CPU
DEBUG 01-15 10:09:44.618284.618284 lmp.py:1626]   Expert 21 |    141 | CPU
DEBUG 01-15 10:09:44.618311.618311 lmp.py:1626]   Expert 42 |    143 | CPU
DEBUG 01-15 10:09:44.618338.618338 lmp.py:1626]   Expert 14 |    145 | CPU
DEBUG 01-15 10:09:44.618697.618697 lmp.py:1626]   Expert 10 |    147 | CPU
DEBUG 01-15 10:09:44.618816.618816 lmp.py:1626]   Expert 22 |    149 | CPU
DEBUG 01-15 10:09:44.618175.618175 lmp.py:1626]   Expert 51 |    155 | CPU
DEBUG 01-15 10:09:44.618295.618295 lmp.py:1626]   Expert 32 |    158 | CPU
DEBUG 01-15 10:09:44.618176.618176 lmp.py:1626]   Expert 25 |    168 | CPU
DEBUG 01-15 10:09:44.618296.618296 lmp.py:1626]   Expert  1 |    172 | CPU
DEBUG 01-15 10:09:44.618416.618416 lmp.py:1626]   Expert 47 |    175 | CPU
DEBUG 01-15 10:09:44.618774.618774 lmp.py:1626]   Expert 53 |    176 | CPU
DEBUG 01-15 10:09:44.618655.618655 lmp.py:1626]   Expert 19 |    178 | CPU
DEBUG 01-15 10:09:44.618682.618682 lmp.py:1626]   Expert 50 |    178 | GPU
DEBUG 01-15 10:09:44.618994.618994 lmp.py:1626]   Expert  6 |    180 | GPU
DEBUG 01-15 10:09:44.618829.618829 lmp.py:1626]   Expert 26 |    180 | GPU
DEBUG 01-15 10:09:44.618949.618949 lmp.py:1626]   Expert  2 |    182 | GPU
DEBUG 01-15 10:09:44.618830.618830 lmp.py:1626]   Expert 30 |    183 | GPU
DEBUG 01-15 10:09:44.618712.618712 lmp.py:1626]   Expert 35 |    185 | GPU
DEBUG 01-15 10:09:44.618832.618832 lmp.py:1626]   Expert 11 |    189 | GPU
DEBUG 01-15 10:09:44.618952.618952 lmp.py:1626]   Expert 56 |    191 | GPU
DEBUG 01-15 10:09:44.618310.618310 lmp.py:1626]   Expert 57 |    191 | GPU
DEBUG 01-15 10:09:44.618191.618191 lmp.py:1626]   Expert 48 |    203 | GPU
DEBUG 01-15 10:09:44.618073.618073 lmp.py:1626]   Expert 16 |    208 | GPU
DEBUG 01-15 10:09:44.618192.618192 lmp.py:1626]   Expert 24 |    212 | GPU
DEBUG 01-15 10:09:44.618551.618551 lmp.py:1626]   Expert 44 |    212 | GPU
DEBUG 01-15 10:09:44.618909.618909 lmp.py:1626]   Expert 46 |    218 | GPU
DEBUG 01-15 10:09:44.618698.618698 lmp.py:1626]   Expert 18 |    225 | GPU
DEBUG 01-15 10:09:44.618248.618248 lmp.py:1626]   Expert 39 |    227 | GPU
DEBUG 01-15 10:09:44.618275.618275 lmp.py:1626]   Expert 29 |    231 | GPU
DEBUG 01-15 10:09:44.619633.619633 lmp.py:1626]   Expert 37 |    242 | GPU
DEBUG 01-15 10:09:44.619753.619753 lmp.py:1626]   Expert 31 |    253 | GPU
DEBUG 01-15 10:09:44.619634.619634 lmp.py:1626]   Expert 60 |    256 | GPU
DEBUG 01-15 10:09:44.619754.619754 lmp.py:1626]   Expert  3 |    257 | GPU
DEBUG 01-15 10:09:44.619636.619636 lmp.py:1626]   Expert 36 |    257 | GPU
DEBUG 01-15 10:09:44.619517.619517 lmp.py:1626]   Expert 38 |    262 | GPU
DEBUG 01-15 10:09:44.619398.619398 lmp.py:1626]   Expert  9 |    266 | GPU
DEBUG 01-15 10:09:44.619757.619757 lmp.py:1626]   Expert 17 |    266 | GPU
DEBUG 01-15 10:09:44.619400.619400 lmp.py:1626]   Expert 23 |    276 | GPU
DEBUG 01-15 10:09:44.619519.619519 lmp.py:1626]   Expert 27 |    348 | GPU
DEBUG 01-15 10:09:44.619739.619739 lmp.py:1626]   Expert 43 |    365 | GPU
DEBUG 01-15 10:09:44.619527.619527 lmp.py:1626]   Expert  8 |    398 | GPU
DEBUG 01-15 10:09:44.619839.619839 lmp.py:1626]   Expert 33 |    402 | GPU
DEBUG 01-15 10:09:44.619436.619436 lmp.py:1626]   Expert 58 |    443 | GPU
DEBUG 01-15 10:09:44.619317.619317 lmp.py:1626]   Expert 49 |    540 | GPU
DEBUG 01-15 10:09:44.619391.619391 lmp.py:1627] 
DEBUG 01-15 10:09:44.619391.619391 lmp.py:1627]   CPU total tokens: 4062 (33.1%)
DEBUG 01-15 10:09:44.619703.619703 lmp.py:1628]   GPU total tokens: 8226 (66.9%)
DEBUG 01-15 10:09:44.619783.619783 cuda_h.py:19] end experts_map_get cost 0.0018508434295654297 seconds
DEBUG 01-15 10:09:44.619832.619832 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.619257.619257 lmp.py:1636] 
DEBUG 01-15 10:09:44.619257.619257 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.619530.619530 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-15 10:09:44.619465.619465 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.619877.619877 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.619593.619593 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.620251.620251 cuda_h.py:19] end allocate_cuda_memory cost 0.00023412704467773438 seconds
DEBUG 01-15 10:09:44.620772.620772 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.620178.620178 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.620875.620875 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.620393.620393 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ba11312-f5b9-4fb9-9058-8cf4f8841a58
DEBUG 01-15 10:09:44.620239.620239 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.621872.621872 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.621346.621346 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:44.621598.621598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ba11312-f5b9-4fb9-9058-8cf4f8841a58
DEBUG 01-15 10:09:44.621818.621818 cuda_h.py:19] end load_into_gpu_async cost 0.0013141632080078125 seconds
DEBUG 01-15 10:09:44.621713.621713 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.622717.622717 cuda_h.py:19] end move_flatidxs cost 0.0009090900421142578 seconds
DEBUG 01-15 10:09:44.622606.622606 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.622433.622433 cuda_h.py:19] end restore_tensors2 cost 0.00048732757568359375 seconds
DEBUG 01-15 10:09:44.622713.622713 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029754638671875 seconds
DEBUG 01-15 10:09:44.622536.622536 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.626794.626794 cuda_h.py:19] end restore2model cost 0.003523588180541992 seconds
DEBUG 01-15 10:09:44.626261.626261 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006741762161254883 seconds
DEBUG 01-15 10:09:44.626202.626202 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.626314.626314 cuda_h.py:19] end gpu_sexperts cost 0.0003292560577392578 seconds
DEBUG 01-15 10:09:44.626196.626196 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.628465.628465 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0020339488983154297 seconds
DEBUG 01-15 10:09:44.629940.629940 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.630589.630589 cuda_h.py:19] end gpu_group_list cost 0.0003497600555419922 seconds
DEBUG 01-15 10:09:44.630673.630673 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.629100.629100 cuda_h.py:19] end group_tensors cost 0.007792234420776367 seconds
DEBUG 01-15 10:09:44.631203.631203 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.631824.631824 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010867118835449219 seconds
DEBUG 01-15 10:09:44.631097.631097 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.631702.631702 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-15 10:09:44.631657.631657 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.635725.635725 cuda_h.py:19] end group pad cost 0.004420757293701172 seconds
DEBUG 01-15 10:09:44.635422.635422 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.657947.657947 cuda_h.py:19] end group_einsum cost 0.021330595016479492 seconds
DEBUG 01-15 10:09:44.657681.657681 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.662911.662911 cuda_h.py:19] end get_outputs_cpu1 cost 0.004835844039916992 seconds
DEBUG 01-15 10:09:44.662394.662394 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04190993309020996 seconds
DEBUG 01-15 10:09:44.663357.663357 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03212237358093262 seconds
DEBUG 01-15 10:09:44.664474.664474 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.664513.664513 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.664996.664996 cuda_h.py:19] end index_scatter cost 9.179115295410156e-05 seconds
DEBUG 01-15 10:09:44.665838.665838 cuda_h.py:19] end cpuoutputsdeal cost 0.0011394023895263672 seconds
DEBUG 01-15 10:09:44.665866.665866 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.665775.665775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ba11312-f5b9-4fb9-9058-8cf4f8841a58
INFO 01-15 10:09:44.673664.673664 client.py:127] Model loaded
DEBUG 01-15 10:09:44.673283.673283 cuda_h.py:19] end wait_experts cost 0.00785970687866211 seconds
DEBUG 01-15 10:09:44.673846.673846 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.673624.673624 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.673903.673903 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.673243.673243 cuda_h.py:19] end gpu_group_tensor cost 0.0002167224884033203 seconds
DEBUG 01-15 10:09:44.673903.673903 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.674107.674107 cuda_h.py:19] end gpu_group_einsum cost 0.0006947517395019531 seconds
DEBUG 01-15 10:09:44.674595.674595 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.674155.674155 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.675487.675487 cuda_h.py:19] end all_expert_outputs_slices cost 0.00037360191345214844 seconds
DEBUG 01-15 10:09:44.675302.675302 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.675392.675392 cuda_h.py:19] end concat_expert_out cost 6.699562072753906e-05 seconds
DEBUG 01-15 10:09:44.675428.675428 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.675214.675214 cuda_h.py:19] end index_scatter cost 8.058547973632812e-05 seconds
DEBUG 01-15 10:09:44.675700.675700 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009062290191650391 seconds
DEBUG 01-15 10:09:44.675678.675678 cuda_h.py:19] end gpu_experts cost 0.0024449825286865234 seconds
DEBUG 01-15 10:09:44.675005.675005 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.05925917625427246 seconds
DEBUG 01-15 10:09:44.676522.676522 cuda_h.py:19] end prefill_layer cost 0.07006978988647461 seconds
DEBUG 01-15 10:09:44.676189.676189 lmp.py:1552] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-15 10:09:44.676276.676276 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.676125.676125 lmp.py:1495] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-15 10:09:44.676735.676735 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:44.676445.676445 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-15 10:09:44.676030.676030 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.1021575927734375e-05 seconds
DEBUG 01-15 10:09:44.676409.676409 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 8.7738037109375e-05 seconds
DEBUG 01-15 10:09:44.676869.676869 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.676852.676852 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.677533.677533 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.677037.677037 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.677259.677259 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.677833.677833 cuda_h.py:19] end allocate_cuda_memory cost 0.0003349781036376953 seconds
DEBUG 01-15 10:09:44.678802.678802 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.678280.678280 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.678302.678302 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.678919.678919 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3b178b9a-40f0-4d76-b360-a69e6bb5d785
DEBUG 01-15 10:09:44.678545.678545 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.678598.678598 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.679104.679104 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3b178b9a-40f0-4d76-b360-a69e6bb5d785
DEBUG 01-15 10:09:44.679407.679407 cuda_h.py:19] end load_into_gpu_async cost 0.0012145042419433594 seconds
DEBUG 01-15 10:09:44.679501.679501 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.679863.679863 cuda_h.py:19] end restore_tensors2 cost 0.00010013580322265625 seconds
DEBUG 01-15 10:09:44.679049.679049 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021059513092041016 seconds
INFO 01-15 10:09:44.679270.679270 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3b178b9a-40f0-4d76-b360-a69e6bb5d785
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.683990.683990 cuda_h.py:19] end self_attn cost 0.004299163818359375 seconds
DEBUG 01-15 10:09:44.683083.683083 cuda_h.py:19] end iln_self_attn_paln cost 0.0062389373779296875 seconds
DEBUG 01-15 10:09:44.683569.683569 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-15 10:09:44.683664.683664 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.684340.684340 cuda_h.py:19] end gate cost 0.0007719993591308594 seconds
DEBUG 01-15 10:09:44.684137.684137 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.684296.684296 lmp.py:1616] 
DEBUG 01-15 10:09:44.684296.684296 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.684628.684628 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.684516.684516 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.684543.684543 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.684663.684663 lmp.py:1620] 
DEBUG 01-15 10:09:44.684663.684663 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.684598.684598 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.685055.685055 lmp.py:1626]   Expert 58 |     35 | CPU
DEBUG 01-15 10:09:44.685772.685772 lmp.py:1626]   Expert 47 |     60 | CPU
DEBUG 01-15 10:09:44.685845.685845 lmp.py:1626]   Expert 49 |     60 | CPU
DEBUG 01-15 10:09:44.685363.685363 lmp.py:1626]   Expert 31 |     61 | CPU
DEBUG 01-15 10:09:44.685066.685066 lmp.py:1626]   Expert  4 |     65 | CPU
DEBUG 01-15 10:09:44.685662.685662 lmp.py:1626]   Expert 38 |     72 | CPU
DEBUG 01-15 10:09:44.685305.685305 lmp.py:1626]   Expert 45 |     72 | CPU
DEBUG 01-15 10:09:44.685948.685948 lmp.py:1626]   Expert 43 |     81 | CPU
DEBUG 01-15 10:09:44.685353.685353 lmp.py:1626]   Expert 41 |     84 | CPU
DEBUG 01-15 10:09:44.685519.685519 lmp.py:1626]   Expert 33 |     94 | CPU
DEBUG 01-15 10:09:44.685208.685208 lmp.py:1626]   Expert 50 |    102 | CPU
DEBUG 01-15 10:09:44.685898.685898 lmp.py:1626]   Expert 57 |    102 | CPU
DEBUG 01-15 10:09:44.685587.685587 lmp.py:1626]   Expert 11 |    108 | CPU
DEBUG 01-15 10:09:44.685038.685038 lmp.py:1626]   Expert  2 |    112 | CPU
DEBUG 01-15 10:09:44.685833.685833 lmp.py:1626]   Expert 51 |    115 | CPU
DEBUG 01-15 10:09:44.685960.685960 lmp.py:1626]   Expert  0 |    122 | CPU
DEBUG 01-15 10:09:44.685603.685603 lmp.py:1626]   Expert 14 |    122 | CPU
DEBUG 01-15 10:09:44.685769.685769 lmp.py:1626]   Expert 54 |    131 | CPU
DEBUG 01-15 10:09:44.685935.685935 lmp.py:1626]   Expert 26 |    141 | CPU
DEBUG 01-15 10:09:44.685386.685386 lmp.py:1626]   Expert 34 |    144 | CPU
DEBUG 01-15 10:09:44.685029.685029 lmp.py:1626]   Expert 56 |    145 | CPU
DEBUG 01-15 10:09:44.685003.685003 lmp.py:1626]   Expert 27 |    151 | CPU
DEBUG 01-15 10:09:44.685454.685454 lmp.py:1626]   Expert 28 |    157 | CPU
DEBUG 01-15 10:09:44.685905.685905 lmp.py:1626]   Expert 55 |    158 | CPU
DEBUG 01-15 10:09:44.685879.685879 lmp.py:1626]   Expert 10 |    164 | CPU
DEBUG 01-15 10:09:44.685767.685767 lmp.py:1626]   Expert 25 |    164 | CPU
DEBUG 01-15 10:09:44.685178.685178 lmp.py:1626]   Expert 13 |    178 | CPU
DEBUG 01-15 10:09:44.685106.685106 lmp.py:1626]   Expert  9 |    179 | CPU
DEBUG 01-15 10:09:44.685795.685795 lmp.py:1626]   Expert 61 |    187 | CPU
DEBUG 01-15 10:09:44.685723.685723 lmp.py:1626]   Expert  6 |    191 | CPU
DEBUG 01-15 10:09:44.685412.685412 lmp.py:1626]   Expert 48 |    192 | CPU
DEBUG 01-15 10:09:44.685579.685579 lmp.py:1626]   Expert  7 |    194 | CPU
DEBUG 01-15 10:09:44.685791.685791 lmp.py:1626]   Expert 46 |    196 | GPU
DEBUG 01-15 10:09:44.685004.685004 lmp.py:1626]   Expert 24 |    200 | GPU
DEBUG 01-15 10:09:44.685216.685216 lmp.py:1626]   Expert 42 |    203 | GPU
DEBUG 01-15 10:09:44.685190.685190 lmp.py:1626]   Expert 18 |    204 | GPU
DEBUG 01-15 10:09:44.685317.685317 lmp.py:1626]   Expert 40 |    210 | GPU
DEBUG 01-15 10:09:44.685397.685397 lmp.py:1626]   Expert 63 |    214 | GPU
DEBUG 01-15 10:09:44.685325.685325 lmp.py:1626]   Expert 29 |    216 | GPU
DEBUG 01-15 10:09:44.685252.685252 lmp.py:1626]   Expert 59 |    217 | GPU
DEBUG 01-15 10:09:44.685942.685942 lmp.py:1626]   Expert 12 |    218 | GPU
DEBUG 01-15 10:09:44.685108.685108 lmp.py:1626]   Expert 21 |    219 | GPU
DEBUG 01-15 10:09:44.685035.685035 lmp.py:1626]   Expert 22 |    222 | GPU
DEBUG 01-15 10:09:44.685486.685486 lmp.py:1626]   Expert 32 |    222 | GPU
DEBUG 01-15 10:09:44.685699.685699 lmp.py:1626]   Expert 19 |    227 | GPU
DEBUG 01-15 10:09:44.685434.685434 lmp.py:1626]   Expert 36 |    235 | GPU
DEBUG 01-15 10:09:44.685885.685885 lmp.py:1626]   Expert  3 |    241 | GPU
DEBUG 01-15 10:09:44.685859.685859 lmp.py:1626]   Expert 37 |    248 | GPU
DEBUG 01-15 10:09:44.685072.685072 lmp.py:1626]   Expert 16 |    249 | GPU
DEBUG 01-15 10:09:44.685437.685437 lmp.py:1626]   Expert  1 |    250 | GPU
DEBUG 01-15 10:09:44.685279.685279 lmp.py:1626]   Expert 20 |    261 | GPU
DEBUG 01-15 10:09:44.685730.685730 lmp.py:1626]   Expert  5 |    265 | GPU
DEBUG 01-15 10:09:44.685373.685373 lmp.py:1626]   Expert  8 |    265 | GPU
DEBUG 01-15 10:09:44.686823.686823 lmp.py:1626]   Expert 30 |    271 | GPU
DEBUG 01-15 10:09:44.686513.686513 lmp.py:1626]   Expert 15 |    273 | GPU
DEBUG 01-15 10:09:44.686917.686917 lmp.py:1626]   Expert 62 |    273 | GPU
DEBUG 01-15 10:09:44.686891.686891 lmp.py:1626]   Expert 39 |    297 | GPU
DEBUG 01-15 10:09:44.686627.686627 lmp.py:1626]   Expert 35 |    300 | GPU
DEBUG 01-15 10:09:44.686363.686363 lmp.py:1626]   Expert 17 |    308 | GPU
DEBUG 01-15 10:09:44.686098.686098 lmp.py:1626]   Expert 60 |    316 | GPU
DEBUG 01-15 10:09:44.686278.686278 lmp.py:1626]   Expert 52 |    352 | GPU
DEBUG 01-15 10:09:44.686742.686742 lmp.py:1626]   Expert 23 |    358 | GPU
DEBUG 01-15 10:09:44.686578.686578 lmp.py:1626]   Expert 44 |    380 | GPU
DEBUG 01-15 10:09:44.686889.686889 lmp.py:1626]   Expert 53 |    435 | GPU
DEBUG 01-15 10:09:44.686539.686539 lmp.py:1627] 
DEBUG 01-15 10:09:44.686539.686539 lmp.py:1627]   CPU total tokens: 3943 (32.1%)
DEBUG 01-15 10:09:44.686520.686520 lmp.py:1628]   GPU total tokens: 8345 (67.9%)
DEBUG 01-15 10:09:44.686508.686508 cuda_h.py:19] end experts_map_get cost 0.001749277114868164 seconds
INFO 01-15 10:09:44.686935.686935 client.py:127] Model loaded
DEBUG 01-15 10:09:44.686170.686170 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.686233.686233 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.686552.686552 lmp.py:1636] 
DEBUG 01-15 10:09:44.686552.686552 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.687696.687696 cuda_h.py:19] end cpu_experts_submit cost 0.0005295276641845703 seconds
DEBUG 01-15 10:09:44.687717.687717 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.687190.687190 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.687468.687468 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.688193.688193 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.688523.688523 cuda_h.py:19] end allocate_cuda_memory cost 0.00032019615173339844 seconds
DEBUG 01-15 10:09:44.688604.688604 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.688241.688241 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.688919.688919 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.688126.688126 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.688975.688975 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e6bcfb69-af4e-44a6-be26-1c9f6c85b853
DEBUG 01-15 10:09:44.688832.688832 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.689189.689189 cuda_h.py:19] end restore2model cost 0.0023038387298583984 seconds
DEBUG 01-15 10:09:44.689030.689030 cuda_h.py:19] end sllm_worker_task cost 0.012117385864257812 seconds
DEBUG 01-15 10:09:44.689873.689873 cuda_h.py:19] end move_flatidxs cost 0.0008759498596191406 seconds
DEBUG 01-15 10:09:44.689564.689564 cuda_h.py:10] start group_tensors
INFO 01-15 10:09:44.690035.690035 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e6bcfb69-af4e-44a6-be26-1c9f6c85b853
DEBUG 01-15 10:09:44.690615.690615 cuda_h.py:19] end load_into_gpu_async cost 0.0019698143005371094 seconds
DEBUG 01-15 10:09:44.690676.690676 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.691868.691868 cuda_h.py:19] end restore_tensors2 cost 0.0011103153228759766 seconds
DEBUG 01-15 10:09:44.691618.691618 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0046269893646240234 seconds
DEBUG 01-15 10:09:44.692166.692166 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.699219.699219 cuda_h.py:19] end restore2model cost 0.007418632507324219 seconds
DEBUG 01-15 10:09:44.699391.699391 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012573480606079102 seconds
DEBUG 01-15 10:09:44.699195.699195 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.700904.700904 cuda_h.py:19] end gpu_sexperts cost 0.0005292892456054688 seconds
DEBUG 01-15 10:09:44.699003.699003 cuda_h.py:19] end group_tensors cost 0.010495424270629883 seconds
DEBUG 01-15 10:09:44.700556.700556 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.700407.700407 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.704405.704405 cuda_h.py:19] end group pad cost 0.003844022750854492 seconds
DEBUG 01-15 10:09:44.704526.704526 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.705571.705571 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.004485368728637695 seconds
DEBUG 01-15 10:09:44.708217.708217 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.709293.709293 cuda_h.py:19] end gpu_group_list cost 0.0007350444793701172 seconds
DEBUG 01-15 10:09:44.710592.710592 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.711669.711669 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0012288093566894531 seconds
DEBUG 01-15 10:09:44.711633.711633 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.711742.711742 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.790855407714844e-05 seconds
DEBUG 01-15 10:09:44.711160.711160 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.726883.726883 cuda_h.py:19] end group_einsum cost 0.021667957305908203 seconds
DEBUG 01-15 10:09:44.726955.726955 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.731012.731012 cuda_h.py:19] end get_outputs_cpu1 cost 0.004808902740478516 seconds
DEBUG 01-15 10:09:44.732907.732907 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04398465156555176 seconds
DEBUG 01-15 10:09:44.733959.733959 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.021776676177978516 seconds
DEBUG 01-15 10:09:44.733065.733065 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.734079.734079 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.734712.734712 cuda_h.py:19] end index_scatter cost 0.00019288063049316406 seconds
DEBUG 01-15 10:09:44.735729.735729 cuda_h.py:19] end cpuoutputsdeal cost 0.0014882087707519531 seconds
DEBUG 01-15 10:09:44.735593.735593 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.735252.735252 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e6bcfb69-af4e-44a6-be26-1c9f6c85b853
INFO 01-15 10:09:44.741935.741935 client.py:127] Model loaded
DEBUG 01-15 10:09:44.742496.742496 cuda_h.py:19] end wait_experts cost 0.006295680999755859 seconds
DEBUG 01-15 10:09:44.742644.742644 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.742351.742351 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.742943.742943 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.742517.742517 cuda_h.py:19] end gpu_group_tensor cost 0.0004417896270751953 seconds
DEBUG 01-15 10:09:44.743247.743247 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.744231.744231 cuda_h.py:19] end gpu_group_einsum cost 0.0013794898986816406 seconds
DEBUG 01-15 10:09:44.744188.744188 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.745517.745517 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.746819.746819 cuda_h.py:19] end all_expert_outputs_slices cost 0.0010068416595458984 seconds
DEBUG 01-15 10:09:44.746457.746457 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.746346.746346 cuda_h.py:19] end concat_expert_out cost 0.00014853477478027344 seconds
DEBUG 01-15 10:09:44.746186.746186 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.746850.746850 cuda_h.py:19] end index_scatter cost 0.00015115737915039062 seconds
DEBUG 01-15 10:09:44.747840.747840 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0019555091857910156 seconds
DEBUG 01-15 10:09:44.747746.747746 cuda_h.py:19] end gpu_experts cost 0.004954814910888672 seconds
DEBUG 01-15 10:09:44.747361.747361 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.0637519359588623 seconds
DEBUG 01-15 10:09:44.748445.748445 cuda_h.py:19] end prefill_layer cost 0.07146382331848145 seconds
DEBUG 01-15 10:09:44.748111.748111 lmp.py:1552] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-15 10:09:44.748186.748186 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.748552.748552 lmp.py:1495] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-15 10:09:44.748441.748441 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:44.748166.748166 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-15 10:09:44.748488.748488 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.8650970458984375e-05 seconds
DEBUG 01-15 10:09:44.748233.748233 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.748057.748057 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.0002460479736328125 seconds
DEBUG 01-15 10:09:44.748676.748676 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.748016.748016 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.749245.749245 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.749588.749588 cuda_h.py:19] end allocate_cuda_memory cost 0.00024080276489257812 seconds
DEBUG 01-15 10:09:44.749729.749729 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.749823.749823 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.749136.749136 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.749031.749031 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e5b26756-6f0c-499d-bc88-eac60bb549a7
DEBUG 01-15 10:09:44.749293.749293 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.749074.749074 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:44.750131.750131 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e5b26756-6f0c-499d-bc88-eac60bb549a7
DEBUG 01-15 10:09:44.750874.750874 cuda_h.py:19] end load_into_gpu_async cost 0.001127481460571289 seconds
DEBUG 01-15 10:09:44.750054.750054 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.750965.750965 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-15 10:09:44.750529.750529 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017962455749511719 seconds
INFO 01-15 10:09:44.750319.750319 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e5b26756-6f0c-499d-bc88-eac60bb549a7
DEBUG 01-15 10:09:44.750978.750978 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.757847.757847 cuda_h.py:19] end self_attn cost 0.0064601898193359375 seconds
INFO 01-15 10:09:44.757295.757295 client.py:127] Model loaded
DEBUG 01-15 10:09:44.757595.757595 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.758452.758452 cuda_h.py:19] end restore2model cost 0.0006244182586669922 seconds
DEBUG 01-15 10:09:44.758249.758249 cuda_h.py:19] end sllm_worker_task cost 0.009601593017578125 seconds
DEBUG 01-15 10:09:44.758240.758240 cuda_h.py:19] end iln_self_attn_paln cost 0.009465217590332031 seconds
DEBUG 01-15 10:09:44.758872.758872 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-15 10:09:44.758072.758072 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.759258.759258 cuda_h.py:19] end gate cost 0.0007622241973876953 seconds
DEBUG 01-15 10:09:44.759763.759763 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.760735.760735 lmp.py:1616] 
DEBUG 01-15 10:09:44.760735.760735 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.760259.760259 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.760677.760677 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.760042.760042 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.760454.760454 lmp.py:1620] 
DEBUG 01-15 10:09:44.760454.760454 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.760342.760342 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.760992.760992 lmp.py:1626]   Expert  4 |     10 | CPU
DEBUG 01-15 10:09:44.760972.760972 lmp.py:1626]   Expert 28 |     26 | CPU
DEBUG 01-15 10:09:44.760238.760238 lmp.py:1626]   Expert  7 |     48 | CPU
DEBUG 01-15 10:09:44.760742.760742 lmp.py:1626]   Expert 53 |     57 | CPU
DEBUG 01-15 10:09:44.760246.760246 lmp.py:1626]   Expert 52 |     70 | CPU
DEBUG 01-15 10:09:44.760704.760704 lmp.py:1626]   Expert 43 |     71 | CPU
DEBUG 01-15 10:09:44.760161.760161 lmp.py:1626]   Expert 49 |     86 | CPU
DEBUG 01-15 10:09:44.760633.760633 lmp.py:1626]   Expert 12 |     89 | CPU
DEBUG 01-15 10:09:44.760375.760375 lmp.py:1626]   Expert 47 |    103 | CPU
DEBUG 01-15 10:09:44.760402.760402 lmp.py:1626]   Expert 24 |    106 | CPU
DEBUG 01-15 10:09:44.760429.760429 lmp.py:1626]   Expert 33 |    106 | CPU
DEBUG 01-15 10:09:44.760457.760457 lmp.py:1626]   Expert 50 |    107 | CPU
DEBUG 01-15 10:09:44.760722.760722 lmp.py:1626]   Expert  2 |    110 | CPU
DEBUG 01-15 10:09:44.760988.760988 lmp.py:1626]   Expert 15 |    112 | CPU
DEBUG 01-15 10:09:44.760776.760776 lmp.py:1626]   Expert 60 |    113 | CPU
DEBUG 01-15 10:09:44.760804.760804 lmp.py:1626]   Expert 39 |    114 | CPU
DEBUG 01-15 10:09:44.760592.760592 lmp.py:1626]   Expert 36 |    119 | CPU
DEBUG 01-15 10:09:44.760335.760335 lmp.py:1626]   Expert 25 |    125 | CPU
DEBUG 01-15 10:09:44.760316.760316 lmp.py:1626]   Expert  6 |    126 | CPU
DEBUG 01-15 10:09:44.760820.760820 lmp.py:1626]   Expert 61 |    133 | CPU
DEBUG 01-15 10:09:44.760800.760800 lmp.py:1626]   Expert 59 |    138 | CPU
DEBUG 01-15 10:09:44.760066.760066 lmp.py:1626]   Expert  3 |    141 | CPU
DEBUG 01-15 10:09:44.760332.760332 lmp.py:1626]   Expert 27 |    143 | CPU
DEBUG 01-15 10:09:44.760120.760120 lmp.py:1626]   Expert 58 |    145 | CPU
DEBUG 01-15 10:09:44.760147.760147 lmp.py:1626]   Expert  8 |    151 | CPU
DEBUG 01-15 10:09:44.760936.760936 lmp.py:1626]   Expert 30 |    151 | CPU
DEBUG 01-15 10:09:44.760487.760487 lmp.py:1626]   Expert 31 |    152 | CPU
DEBUG 01-15 10:09:44.760275.760275 lmp.py:1626]   Expert 38 |    156 | CPU
DEBUG 01-15 10:09:44.760302.760302 lmp.py:1626]   Expert 10 |    157 | CPU
DEBUG 01-15 10:09:44.760045.760045 lmp.py:1626]   Expert 40 |    159 | CPU
DEBUG 01-15 10:09:44.760264.760264 lmp.py:1626]   Expert 57 |    159 | CPU
DEBUG 01-15 10:09:44.760483.760483 lmp.py:1626]   Expert 14 |    162 | CPU
DEBUG 01-15 10:09:44.760272.760272 lmp.py:1626]   Expert 41 |    162 | GPU
DEBUG 01-15 10:09:44.760822.760822 lmp.py:1626]   Expert 37 |    164 | GPU
DEBUG 01-15 10:09:44.760134.760134 lmp.py:1626]   Expert 46 |    164 | GPU
DEBUG 01-15 10:09:44.760923.760923 lmp.py:1626]   Expert 54 |    165 | GPU
DEBUG 01-15 10:09:44.760473.760473 lmp.py:1626]   Expert 32 |    167 | GPU
DEBUG 01-15 10:09:44.761785.761785 lmp.py:1626]   Expert 19 |    171 | GPU
DEBUG 01-15 10:09:44.761336.761336 lmp.py:1626]   Expert 42 |    172 | GPU
DEBUG 01-15 10:09:44.761363.761363 lmp.py:1626]   Expert 11 |    179 | GPU
DEBUG 01-15 10:09:44.761628.761628 lmp.py:1626]   Expert 34 |    190 | GPU
DEBUG 01-15 10:09:44.761470.761470 lmp.py:1626]   Expert 18 |    191 | GPU
DEBUG 01-15 10:09:44.761213.761213 lmp.py:1626]   Expert 26 |    195 | GPU
DEBUG 01-15 10:09:44.761240.761240 lmp.py:1626]   Expert  0 |    197 | GPU
DEBUG 01-15 10:09:44.761029.761029 lmp.py:1626]   Expert 22 |    198 | GPU
DEBUG 01-15 10:09:44.761817.761817 lmp.py:1626]   Expert 56 |    200 | GPU
DEBUG 01-15 10:09:44.761368.761368 lmp.py:1626]   Expert 44 |    202 | GPU
DEBUG 01-15 10:09:44.761156.761156 lmp.py:1626]   Expert  1 |    204 | GPU
DEBUG 01-15 10:09:44.761945.761945 lmp.py:1626]   Expert 51 |    212 | GPU
DEBUG 01-15 10:09:44.761495.761495 lmp.py:1626]   Expert 20 |    225 | GPU
DEBUG 01-15 10:09:44.761046.761046 lmp.py:1626]   Expert 29 |    232 | GPU
DEBUG 01-15 10:09:44.761742.761742 lmp.py:1626]   Expert 48 |    234 | GPU
DEBUG 01-15 10:09:44.761007.761007 lmp.py:1626]   Expert 21 |    241 | GPU
DEBUG 01-15 10:09:44.761988.761988 lmp.py:1626]   Expert 45 |    243 | GPU
DEBUG 01-15 10:09:44.761969.761969 lmp.py:1626]   Expert 35 |    248 | GPU
DEBUG 01-15 10:09:44.761996.761996 lmp.py:1626]   Expert 16 |    252 | GPU
DEBUG 01-15 10:09:44.761070.761070 lmp.py:1626]   Expert 55 |    253 | GPU
DEBUG 01-15 10:09:44.761097.761097 lmp.py:1626]   Expert  5 |    294 | GPU
DEBUG 01-15 10:09:44.761886.761886 lmp.py:1626]   Expert 23 |    372 | GPU
DEBUG 01-15 10:09:44.761198.761198 lmp.py:1626]   Expert 13 |    382 | GPU
DEBUG 01-15 10:09:44.761748.761748 lmp.py:1626]   Expert 17 |    436 | GPU
DEBUG 01-15 10:09:44.761537.761537 lmp.py:1626]   Expert  9 |    457 | GPU
DEBUG 01-15 10:09:44.761325.761325 lmp.py:1626]   Expert 63 |    461 | GPU
DEBUG 01-15 10:09:44.761783.761783 lmp.py:1626]   Expert 62 |   1180 | GPU
DEBUG 01-15 10:09:44.761956.761956 lmp.py:1627] 
DEBUG 01-15 10:09:44.761956.761956 lmp.py:1627]   CPU total tokens: 3645 (29.7%)
DEBUG 01-15 10:09:44.761890.761890 lmp.py:1628]   GPU total tokens: 8643 (70.3%)
DEBUG 01-15 10:09:44.761878.761878 cuda_h.py:19] end experts_map_get cost 0.0020143985748291016 seconds
DEBUG 01-15 10:09:44.761934.761934 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.761312.761312 lmp.py:1636] 
DEBUG 01-15 10:09:44.761312.761312 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.761162.761162 cuda_h.py:19] end cpu_experts_submit cost 6.4849853515625e-05 seconds
DEBUG 01-15 10:09:44.761958.761958 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.761384.761384 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.762451.762451 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.762864.762864 cuda_h.py:19] end allocate_cuda_memory cost 0.00022864341735839844 seconds
DEBUG 01-15 10:09:44.762959.762959 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.762141.762141 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.762507.762507 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.763740.763740 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2b0117c8-30ac-4f56-873a-a5ff6f3fa045
DEBUG 01-15 10:09:44.763186.763186 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.763470.763470 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.763596.763596 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:44.764822.764822 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2b0117c8-30ac-4f56-873a-a5ff6f3fa045
DEBUG 01-15 10:09:44.764100.764100 cuda_h.py:19] end move_flatidxs cost 0.0009393692016601562 seconds
DEBUG 01-15 10:09:44.764751.764751 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.764387.764387 cuda_h.py:19] end load_into_gpu_async cost 0.0016245841979980469 seconds
DEBUG 01-15 10:09:44.764189.764189 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.765837.765837 cuda_h.py:19] end restore_tensors2 cost 0.0005152225494384766 seconds
DEBUG 01-15 10:09:44.765270.765270 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032880306243896484 seconds
DEBUG 01-15 10:09:44.765953.765953 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.768662.768662 cuda_h.py:19] end restore2model cost 0.0037126541137695312 seconds
DEBUG 01-15 10:09:44.769704.769704 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007231235504150391 seconds
DEBUG 01-15 10:09:44.769499.769499 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.769028.769028 cuda_h.py:19] end gpu_sexperts cost 0.0003204345703125 seconds
DEBUG 01-15 10:09:44.769718.769718 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.771502.771502 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00201416015625 seconds
DEBUG 01-15 10:09:44.772221.772221 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.773718.773718 cuda_h.py:19] end gpu_group_list cost 0.00034046173095703125 seconds
DEBUG 01-15 10:09:44.773848.773848 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.774770.774770 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009889602661132812 seconds
DEBUG 01-15 10:09:44.774699.774699 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.774191.774191 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-15 10:09:44.774410.774410 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.777157.777157 cuda_h.py:19] end group_tensors cost 0.012682199478149414 seconds
DEBUG 01-15 10:09:44.778013.778013 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.782412.782412 cuda_h.py:19] end group pad cost 0.004140138626098633 seconds
DEBUG 01-15 10:09:44.782255.782255 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.800414.800414 cuda_h.py:19] end group_einsum cost 0.018325090408325195 seconds
DEBUG 01-15 10:09:44.800340.800340 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.805197.805197 cuda_h.py:19] end get_outputs_cpu1 cost 0.004558563232421875 seconds
DEBUG 01-15 10:09:44.806773.806773 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04297447204589844 seconds
DEBUG 01-15 10:09:44.807572.807572 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.032851457595825195 seconds
DEBUG 01-15 10:09:44.807271.807271 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.807883.807883 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.807373.807373 cuda_h.py:19] end index_scatter cost 9.107589721679688e-05 seconds
DEBUG 01-15 10:09:44.808927.808927 cuda_h.py:19] end cpuoutputsdeal cost 0.0007600784301757812 seconds
DEBUG 01-15 10:09:44.808703.808703 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.808665.808665 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2b0117c8-30ac-4f56-873a-a5ff6f3fa045
INFO 01-15 10:09:44.815851.815851 client.py:127] Model loaded
DEBUG 01-15 10:09:44.815443.815443 cuda_h.py:19] end wait_experts cost 0.007203578948974609 seconds
DEBUG 01-15 10:09:44.815391.815391 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.815923.815923 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.815263.815263 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.815034.815034 cuda_h.py:19] end gpu_group_tensor cost 0.00024318695068359375 seconds
DEBUG 01-15 10:09:44.816462.816462 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.817958.817958 cuda_h.py:19] end gpu_group_einsum cost 0.001508474349975586 seconds
DEBUG 01-15 10:09:44.817539.817539 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.817959.817959 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.818129.818129 cuda_h.py:19] end all_expert_outputs_slices cost 0.00029969215393066406 seconds
DEBUG 01-15 10:09:44.818475.818475 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.818359.818359 cuda_h.py:19] end concat_expert_out cost 5.841255187988281e-05 seconds
DEBUG 01-15 10:09:44.818824.818824 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.818682.818682 cuda_h.py:19] end index_scatter cost 6.079673767089844e-05 seconds
DEBUG 01-15 10:09:44.818206.818206 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006921291351318359 seconds
DEBUG 01-15 10:09:44.818494.818494 cuda_h.py:19] end gpu_experts cost 0.003033161163330078 seconds
DEBUG 01-15 10:09:44.818410.818410 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.05994701385498047 seconds
DEBUG 01-15 10:09:44.819155.819155 cuda_h.py:19] end prefill_layer cost 0.07081460952758789 seconds
DEBUG 01-15 10:09:44.819224.819224 lmp.py:1552] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-15 10:09:44.819735.819735 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.819576.819576 lmp.py:1495] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-15 10:09:44.819418.819418 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:44.819565.819565 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-15 10:09:44.819422.819422 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.410743713378906e-05 seconds
DEBUG 01-15 10:09:44.819502.819502 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.104873657226562e-05 seconds
DEBUG 01-15 10:09:44.819099.819099 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.819029.819029 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.819430.819430 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.819510.819510 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.819102.819102 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.820440.820440 cuda_h.py:19] end allocate_cuda_memory cost 0.00034236907958984375 seconds
DEBUG 01-15 10:09:44.820065.820065 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.820053.820053 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.820519.820519 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.820752.820752 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c8cd8c19-3eec-4009-ad9d-5011b44575ce
DEBUG 01-15 10:09:44.820093.820093 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.820885.820885 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.821037.821037 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c8cd8c19-3eec-4009-ad9d-5011b44575ce
DEBUG 01-15 10:09:44.821340.821340 cuda_h.py:19] end load_into_gpu_async cost 0.001422882080078125 seconds
DEBUG 01-15 10:09:44.821965.821965 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.822497.822497 cuda_h.py:19] end restore_tensors2 cost 0.00017690658569335938 seconds
DEBUG 01-15 10:09:44.822242.822242 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024106502532958984 seconds
INFO 01-15 10:09:44.822869.822869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c8cd8c19-3eec-4009-ad9d-5011b44575ce
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.825344.825344 cuda_h.py:19] end self_attn cost 0.004528522491455078 seconds
DEBUG 01-15 10:09:44.825966.825966 cuda_h.py:19] end iln_self_attn_paln cost 0.006472587585449219 seconds
DEBUG 01-15 10:09:44.825253.825253 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-15 10:09:44.826347.826347 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.827537.827537 cuda_h.py:19] end gate cost 0.0012946128845214844 seconds
DEBUG 01-15 10:09:44.827745.827745 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.828087.828087 lmp.py:1616] 
DEBUG 01-15 10:09:44.828087.828087 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.828825.828825 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.828252.828252 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.828360.828360 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.828932.828932 lmp.py:1620] 
DEBUG 01-15 10:09:44.828932.828932 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.828794.828794 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.828180.828180 lmp.py:1626]   Expert 32 |     33 | CPU
DEBUG 01-15 10:09:44.828989.828989 lmp.py:1626]   Expert  5 |     52 | CPU
DEBUG 01-15 10:09:44.829367.829367 lmp.py:1626]   Expert 30 |     52 | CPU
DEBUG 01-15 10:09:44.829746.829746 lmp.py:1626]   Expert 46 |     72 | CPU
DEBUG 01-15 10:09:44.829754.829754 lmp.py:1626]   Expert  8 |     88 | CPU
DEBUG 01-15 10:09:44.829179.829179 lmp.py:1626]   Expert 40 |     91 | CPU
DEBUG 01-15 10:09:44.829465.829465 lmp.py:1626]   Expert 12 |    102 | CPU
DEBUG 01-15 10:09:44.829367.829367 lmp.py:1626]   Expert 17 |    105 | CPU
DEBUG 01-15 10:09:44.829342.829342 lmp.py:1626]   Expert 27 |    113 | CPU
DEBUG 01-15 10:09:44.829820.829820 lmp.py:1626]   Expert 60 |    113 | CPU
DEBUG 01-15 10:09:44.829007.829007 lmp.py:1626]   Expert  3 |    116 | CPU
DEBUG 01-15 10:09:44.829816.829816 lmp.py:1626]   Expert 58 |    117 | CPU
DEBUG 01-15 10:09:44.829386.829386 lmp.py:1626]   Expert 21 |    118 | CPU
DEBUG 01-15 10:09:44.829527.829527 lmp.py:1626]   Expert 28 |    121 | CPU
DEBUG 01-15 10:09:44.829826.829826 lmp.py:1626]   Expert 29 |    122 | CPU
DEBUG 01-15 10:09:44.829205.829205 lmp.py:1626]   Expert 41 |    125 | CPU
DEBUG 01-15 10:09:44.829226.829226 lmp.py:1626]   Expert 25 |    127 | CPU
DEBUG 01-15 10:09:44.829512.829512 lmp.py:1626]   Expert 35 |    131 | CPU
DEBUG 01-15 10:09:44.829110.829110 lmp.py:1626]   Expert 19 |    136 | CPU
DEBUG 01-15 10:09:44.829490.829490 lmp.py:1626]   Expert  0 |    142 | CPU
DEBUG 01-15 10:09:44.829306.829306 lmp.py:1626]   Expert  6 |    144 | CPU
DEBUG 01-15 10:09:44.829976.829976 lmp.py:1626]   Expert 52 |    148 | CPU
DEBUG 01-15 10:09:44.829077.829077 lmp.py:1626]   Expert 56 |    149 | CPU
DEBUG 01-15 10:09:44.829078.829078 lmp.py:1626]   Expert 37 |    150 | CPU
DEBUG 01-15 10:09:44.829602.829602 lmp.py:1626]   Expert 54 |    150 | CPU
DEBUG 01-15 10:09:44.829464.829464 lmp.py:1626]   Expert 53 |    157 | CPU
DEBUG 01-15 10:09:44.829857.829857 lmp.py:1626]   Expert 63 |    157 | CPU
DEBUG 01-15 10:09:44.830328.830328 lmp.py:1626]   Expert 48 |    161 | CPU
DEBUG 01-15 10:09:44.830097.830097 lmp.py:1626]   Expert 36 |    163 | CPU
DEBUG 01-15 10:09:44.830099.830099 lmp.py:1626]   Expert 59 |    169 | CPU
DEBUG 01-15 10:09:44.830743.830743 lmp.py:1626]   Expert  9 |    180 | CPU
DEBUG 01-15 10:09:44.830799.830799 lmp.py:1626]   Expert  1 |    188 | CPU
DEBUG 01-15 10:09:44.830006.830006 lmp.py:1626]   Expert 39 |    190 | GPU
DEBUG 01-15 10:09:44.830954.830954 lmp.py:1626]   Expert 20 |    199 | GPU
DEBUG 01-15 10:09:44.830903.830903 lmp.py:1626]   Expert 61 |    201 | GPU
DEBUG 01-15 10:09:44.830672.830672 lmp.py:1626]   Expert  7 |    202 | GPU
DEBUG 01-15 10:09:44.830198.830198 lmp.py:1626]   Expert 42 |    202 | GPU
DEBUG 01-15 10:09:44.830974.830974 lmp.py:1626]   Expert 43 |    203 | GPU
DEBUG 01-15 10:09:44.830333.830333 lmp.py:1626]   Expert 47 |    206 | GPU
DEBUG 01-15 10:09:44.830494.830494 lmp.py:1626]   Expert 34 |    207 | GPU
DEBUG 01-15 10:09:44.830257.830257 lmp.py:1626]   Expert 11 |    208 | GPU
DEBUG 01-15 10:09:44.830112.830112 lmp.py:1626]   Expert 55 |    214 | GPU
DEBUG 01-15 10:09:44.830889.830889 lmp.py:1626]   Expert 57 |    221 | GPU
DEBUG 01-15 10:09:44.830790.830790 lmp.py:1626]   Expert 13 |    222 | GPU
DEBUG 01-15 10:09:44.830905.830905 lmp.py:1626]   Expert 16 |    222 | GPU
DEBUG 01-15 10:09:44.830283.830283 lmp.py:1626]   Expert 18 |    228 | GPU
DEBUG 01-15 10:09:44.830377.830377 lmp.py:1626]   Expert 15 |    233 | GPU
DEBUG 01-15 10:09:44.830901.830901 lmp.py:1626]   Expert  4 |    239 | GPU
DEBUG 01-15 10:09:44.830134.830134 lmp.py:1626]   Expert 22 |    246 | GPU
DEBUG 01-15 10:09:44.831189.831189 lmp.py:1626]   Expert 33 |    246 | GPU
DEBUG 01-15 10:09:44.831919.831919 lmp.py:1626]   Expert 50 |    247 | GPU
DEBUG 01-15 10:09:44.831582.831582 lmp.py:1626]   Expert 45 |    248 | GPU
DEBUG 01-15 10:09:44.831630.831630 lmp.py:1626]   Expert 31 |    250 | GPU
DEBUG 01-15 10:09:44.831850.831850 lmp.py:1626]   Expert 51 |    256 | GPU
DEBUG 01-15 10:09:44.831070.831070 lmp.py:1626]   Expert 49 |    267 | GPU
DEBUG 01-15 10:09:44.831257.831257 lmp.py:1626]   Expert 38 |    277 | GPU
DEBUG 01-15 10:09:44.831027.831027 lmp.py:1626]   Expert 26 |    282 | GPU
DEBUG 01-15 10:09:44.831896.831896 lmp.py:1626]   Expert 10 |    286 | GPU
DEBUG 01-15 10:09:44.831751.831751 lmp.py:1626]   Expert 44 |    298 | GPU
DEBUG 01-15 10:09:44.831368.831368 lmp.py:1626]   Expert  2 |    301 | GPU
DEBUG 01-15 10:09:44.831529.831529 lmp.py:1626]   Expert 24 |    307 | GPU
DEBUG 01-15 10:09:44.831590.831590 lmp.py:1626]   Expert 14 |    313 | GPU
DEBUG 01-15 10:09:44.831015.831015 lmp.py:1626]   Expert 23 |    405 | GPU
DEBUG 01-15 10:09:44.831294.831294 lmp.py:1626]   Expert 62 |    670 | GPU
DEBUG 01-15 10:09:44.831864.831864 lmp.py:1627] 
DEBUG 01-15 10:09:44.831864.831864 lmp.py:1627]   CPU total tokens: 3992 (32.5%)
DEBUG 01-15 10:09:44.831720.831720 lmp.py:1628]   GPU total tokens: 8296 (67.5%)
DEBUG 01-15 10:09:44.831470.831470 cuda_h.py:19] end experts_map_get cost 0.0038487911224365234 seconds
INFO 01-15 10:09:44.831298.831298 client.py:127] Model loaded
DEBUG 01-15 10:09:44.832462.832462 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.832234.832234 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.832444.832444 lmp.py:1636] 
DEBUG 01-15 10:09:44.832444.832444 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.833639.833639 cuda_h.py:19] end cpu_experts_submit cost 0.0008802413940429688 seconds
DEBUG 01-15 10:09:44.833477.833477 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.833442.833442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.834689.834689 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.835107.835107 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.835889.835889 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.835094.835094 cuda_h.py:19] end allocate_cuda_memory cost 0.00028204917907714844 seconds
DEBUG 01-15 10:09:44.836603.836603 cuda_h.py:19] end move_flatidxs cost 0.0008804798126220703 seconds
DEBUG 01-15 10:09:44.836492.836492 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.836407.836407 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.836974.836974 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.837706.837706 cuda_h.py:19] end restore2model cost 0.0047075748443603516 seconds
DEBUG 01-15 10:09:44.837990.837990 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.838721.838721 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 83960dd0-60ad-4053-8337-55d1e579cb8f
DEBUG 01-15 10:09:44.840100.840100 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.837934.837934 cuda_h.py:19] end sllm_worker_task cost 0.017818450927734375 seconds
INFO 01-15 10:09:44.842911.842911 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 83960dd0-60ad-4053-8337-55d1e579cb8f
DEBUG 01-15 10:09:44.843843.843843 cuda_h.py:19] end load_into_gpu_async cost 0.00674748420715332 seconds
DEBUG 01-15 10:09:44.843263.843263 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.844073.844073 cuda_h.py:19] end restore_tensors2 cost 0.0007848739624023438 seconds
DEBUG 01-15 10:09:44.844283.844283 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011012077331542969 seconds
DEBUG 01-15 10:09:44.844655.844655 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.844550.844550 cuda_h.py:19] end group_tensors cost 0.007994890213012695 seconds
DEBUG 01-15 10:09:44.845585.845585 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.849291.849291 cuda_h.py:19] end group pad cost 0.004205465316772461 seconds
DEBUG 01-15 10:09:44.849750.849750 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.849046.849046 cuda_h.py:19] end restore2model cost 0.00456547737121582 seconds
DEBUG 01-15 10:09:44.855890.855890 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0217437744140625 seconds
DEBUG 01-15 10:09:44.859491.859491 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.862619.862619 cuda_h.py:19] end gpu_sexperts cost 0.0007839202880859375 seconds
DEBUG 01-15 10:09:44.862087.862087 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.864105.864105 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016913414001464844 seconds
DEBUG 01-15 10:09:44.865266.865266 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.865967.865967 cuda_h.py:19] end gpu_group_list cost 0.0004987716674804688 seconds
DEBUG 01-15 10:09:44.866398.866398 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.867655.867655 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009183883666992188 seconds
DEBUG 01-15 10:09:44.867293.867293 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.867686.867686 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.410743713378906e-05 seconds
DEBUG 01-15 10:09:44.867528.867528 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.881732.881732 cuda_h.py:19] end group_einsum cost 0.031006336212158203 seconds
DEBUG 01-15 10:09:44.881949.881949 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.888782.888782 cuda_h.py:19] end get_outputs_cpu1 cost 0.007004261016845703 seconds
DEBUG 01-15 10:09:44.889432.889432 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.053931474685668945 seconds
DEBUG 01-15 10:09:44.889313.889313 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.02260112762451172 seconds
DEBUG 01-15 10:09:44.890914.890914 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.890227.890227 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.890530.890530 cuda_h.py:19] end index_scatter cost 9.131431579589844e-05 seconds
DEBUG 01-15 10:09:44.890689.890689 cuda_h.py:19] end cpuoutputsdeal cost 0.0007770061492919922 seconds
DEBUG 01-15 10:09:44.890572.890572 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.890004.890004 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 83960dd0-60ad-4053-8337-55d1e579cb8f
INFO 01-15 10:09:44.893382.893382 client.py:127] Model loaded
DEBUG 01-15 10:09:44.893616.893616 cuda_h.py:19] end wait_experts cost 0.0028839111328125 seconds
DEBUG 01-15 10:09:44.893650.893650 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.893692.893692 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.893448.893448 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.894694.894694 cuda_h.py:19] end gpu_group_tensor cost 0.0001876354217529297 seconds
DEBUG 01-15 10:09:44.894366.894366 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.895969.895969 cuda_h.py:19] end gpu_group_einsum cost 0.0013060569763183594 seconds
DEBUG 01-15 10:09:44.895708.895708 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.896711.896711 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.897827.897827 cuda_h.py:19] end all_expert_outputs_slices cost 0.0009930133819580078 seconds
DEBUG 01-15 10:09:44.897757.897757 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.897737.897737 cuda_h.py:19] end concat_expert_out cost 0.0001347064971923828 seconds
DEBUG 01-15 10:09:44.897152.897152 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.897185.897185 cuda_h.py:19] end index_scatter cost 0.0001342296600341797 seconds
DEBUG 01-15 10:09:44.897995.897995 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0017812252044677734 seconds
DEBUG 01-15 10:09:44.897961.897961 cuda_h.py:19] end gpu_experts cost 0.004095792770385742 seconds
DEBUG 01-15 10:09:44.898986.898986 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.07209539413452148 seconds
DEBUG 01-15 10:09:44.898447.898447 cuda_h.py:19] end prefill_layer cost 0.07959342002868652 seconds
DEBUG 01-15 10:09:44.898492.898492 lmp.py:1552] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-15 10:09:44.899275.899275 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.899396.899396 lmp.py:1495] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-15 10:09:44.899371.899371 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:44.899691.899691 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-15 10:09:44.899622.899622 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.4849853515625e-05 seconds
DEBUG 01-15 10:09:44.899182.899182 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.899105.899105 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 0.0002467632293701172 seconds
DEBUG 01-15 10:09:44.899188.899188 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.899429.899429 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.899273.899273 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.900893.900893 cuda_h.py:19] end allocate_cuda_memory cost 0.00040340423583984375 seconds
DEBUG 01-15 10:09:44.900720.900720 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.900291.900291 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.900389.900389 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.900710.900710 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.900567.900567 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 157fbdf3-5fc6-4269-b637-c7492fc14e69
DEBUG 01-15 10:09:44.901937.901937 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.901509.901509 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.902124.902124 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 157fbdf3-5fc6-4269-b637-c7492fc14e69
DEBUG 01-15 10:09:44.902378.902378 cuda_h.py:19] end load_into_gpu_async cost 0.0014691352844238281 seconds
DEBUG 01-15 10:09:44.902341.902341 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.902347.902347 cuda_h.py:19] end restore_tensors2 cost 0.00011110305786132812 seconds
DEBUG 01-15 10:09:44.902839.902839 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002908468246459961 seconds
INFO 01-15 10:09:44.902154.902154 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 157fbdf3-5fc6-4269-b637-c7492fc14e69
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.905636.905636 cuda_h.py:19] end self_attn cost 0.0045163631439208984 seconds
DEBUG 01-15 10:09:44.906835.906835 cuda_h.py:19] end iln_self_attn_paln cost 0.006414651870727539 seconds
DEBUG 01-15 10:09:44.906592.906592 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-15 10:09:44.906646.906646 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.907018.907018 cuda_h.py:19] end gate cost 0.0007963180541992188 seconds
DEBUG 01-15 10:09:44.907431.907431 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.907277.907277 lmp.py:1616] 
DEBUG 01-15 10:09:44.907277.907277 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.907755.907755 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.907127.907127 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.907400.907400 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.907288.907288 lmp.py:1620] 
DEBUG 01-15 10:09:44.907288.907288 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.907984.907984 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.907157.907157 lmp.py:1626]   Expert 44 |     39 | CPU
DEBUG 01-15 10:09:44.908807.908807 lmp.py:1626]   Expert  1 |     46 | CPU
DEBUG 01-15 10:09:44.908741.908741 lmp.py:1626]   Expert 60 |     64 | CPU
DEBUG 01-15 10:09:44.908676.908676 lmp.py:1626]   Expert 28 |     69 | CPU
DEBUG 01-15 10:09:44.908610.908610 lmp.py:1626]   Expert 48 |     77 | CPU
DEBUG 01-15 10:09:44.908306.908306 lmp.py:1626]   Expert 27 |     85 | CPU
DEBUG 01-15 10:09:44.908479.908479 lmp.py:1626]   Expert  0 |     98 | CPU
DEBUG 01-15 10:09:44.908805.908805 lmp.py:1626]   Expert 62 |    107 | CPU
DEBUG 01-15 10:09:44.908216.908216 lmp.py:1626]   Expert 22 |    113 | CPU
DEBUG 01-15 10:09:44.908866.908866 lmp.py:1626]   Expert 30 |    114 | CPU
DEBUG 01-15 10:09:44.908323.908323 lmp.py:1626]   Expert 59 |    115 | CPU
DEBUG 01-15 10:09:44.908635.908635 lmp.py:1626]   Expert 42 |    116 | CPU
DEBUG 01-15 10:09:44.908709.908709 lmp.py:1626]   Expert 58 |    121 | CPU
DEBUG 01-15 10:09:44.908021.908021 lmp.py:1626]   Expert 16 |    127 | CPU
DEBUG 01-15 10:09:44.908571.908571 lmp.py:1626]   Expert  8 |    128 | CPU
DEBUG 01-15 10:09:44.908406.908406 lmp.py:1626]   Expert 12 |    130 | CPU
DEBUG 01-15 10:09:44.908241.908241 lmp.py:1626]   Expert 50 |    134 | CPU
DEBUG 01-15 10:09:44.908652.908652 lmp.py:1626]   Expert 56 |    142 | CPU
DEBUG 01-15 10:09:44.908825.908825 lmp.py:1626]   Expert  5 |    144 | CPU
DEBUG 01-15 10:09:44.908151.908151 lmp.py:1626]   Expert 55 |    150 | CPU
DEBUG 01-15 10:09:44.908801.908801 lmp.py:1626]   Expert 15 |    151 | CPU
DEBUG 01-15 10:09:44.908305.908305 lmp.py:1626]   Expert 57 |    151 | CPU
DEBUG 01-15 10:09:44.908809.908809 lmp.py:1626]   Expert 26 |    154 | CPU
DEBUG 01-15 10:09:44.908074.908074 lmp.py:1626]   Expert 32 |    157 | CPU
DEBUG 01-15 10:09:44.908340.908340 lmp.py:1626]   Expert 47 |    159 | CPU
DEBUG 01-15 10:09:44.908129.908129 lmp.py:1626]   Expert 34 |    160 | CPU
DEBUG 01-15 10:09:44.908156.908156 lmp.py:1626]   Expert 24 |    165 | CPU
DEBUG 01-15 10:09:44.908183.908183 lmp.py:1626]   Expert  2 |    167 | CPU
DEBUG 01-15 10:09:44.908925.908925 lmp.py:1626]   Expert 52 |    168 | CPU
DEBUG 01-15 10:09:44.908860.908860 lmp.py:1626]   Expert 40 |    169 | CPU
DEBUG 01-15 10:09:44.908510.908510 lmp.py:1626]   Expert  6 |    171 | CPU
DEBUG 01-15 10:09:44.908398.908398 lmp.py:1626]   Expert 18 |    171 | CPU
DEBUG 01-15 10:09:44.908902.908902 lmp.py:1626]   Expert 13 |    173 | GPU
DEBUG 01-15 10:09:44.908167.908167 lmp.py:1626]   Expert  3 |    175 | GPU
DEBUG 01-15 10:09:44.908671.908671 lmp.py:1626]   Expert 41 |    176 | GPU
DEBUG 01-15 10:09:44.908698.908698 lmp.py:1626]   Expert 54 |    176 | GPU
DEBUG 01-15 10:09:44.908964.908964 lmp.py:1626]   Expert 19 |    179 | GPU
DEBUG 01-15 10:09:44.908991.908991 lmp.py:1626]   Expert 20 |    182 | GPU
DEBUG 01-15 10:09:44.908257.908257 lmp.py:1626]   Expert 37 |    184 | GPU
DEBUG 01-15 10:09:44.908761.908761 lmp.py:1626]   Expert 46 |    186 | GPU
DEBUG 01-15 10:09:44.908026.908026 lmp.py:1626]   Expert 25 |    191 | GPU
DEBUG 01-15 10:09:44.908199.908199 lmp.py:1626]   Expert 51 |    194 | GPU
DEBUG 01-15 10:09:44.908849.908849 lmp.py:1626]   Expert 11 |    199 | GPU
DEBUG 01-15 10:09:44.908022.908022 lmp.py:1626]   Expert 17 |    200 | GPU
DEBUG 01-15 10:09:44.908241.908241 lmp.py:1626]   Expert 43 |    201 | GPU
DEBUG 01-15 10:09:44.908745.908745 lmp.py:1626]   Expert 31 |    204 | GPU
DEBUG 01-15 10:09:44.908011.908011 lmp.py:1626]   Expert 35 |    205 | GPU
DEBUG 01-15 10:09:44.908515.908515 lmp.py:1626]   Expert 23 |    211 | GPU
DEBUG 01-15 10:09:44.909019.909019 lmp.py:1626]   Expert 39 |    221 | GPU
DEBUG 01-15 10:09:44.909284.909284 lmp.py:1626]   Expert 49 |    222 | GPU
DEBUG 01-15 10:09:44.909312.909312 lmp.py:1626]   Expert 53 |    229 | GPU
DEBUG 01-15 10:09:44.909339.909339 lmp.py:1626]   Expert 10 |    232 | GPU
DEBUG 01-15 10:09:44.909604.909604 lmp.py:1626]   Expert 33 |    248 | GPU
DEBUG 01-15 10:09:44.909631.909631 lmp.py:1626]   Expert 36 |    263 | GPU
DEBUG 01-15 10:09:44.909374.909374 lmp.py:1626]   Expert 38 |    266 | GPU
DEBUG 01-15 10:09:44.909878.909878 lmp.py:1626]   Expert  4 |    303 | GPU
DEBUG 01-15 10:09:44.909143.909143 lmp.py:1626]   Expert 21 |    334 | GPU
DEBUG 01-15 10:09:44.909316.909316 lmp.py:1626]   Expert 14 |    349 | GPU
DEBUG 01-15 10:09:44.909820.909820 lmp.py:1626]   Expert 63 |    366 | GPU
DEBUG 01-15 10:09:44.909848.909848 lmp.py:1626]   Expert 45 |    374 | GPU
DEBUG 01-15 10:09:44.909113.909113 lmp.py:1626]   Expert  9 |    389 | GPU
DEBUG 01-15 10:09:44.909140.909140 lmp.py:1626]   Expert 61 |    392 | GPU
DEBUG 01-15 10:09:44.909406.909406 lmp.py:1626]   Expert 29 |    485 | GPU
DEBUG 01-15 10:09:44.909910.909910 lmp.py:1626]   Expert  7 |    517 | GPU
DEBUG 01-15 10:09:44.909129.909129 lmp.py:1627] 
DEBUG 01-15 10:09:44.909129.909129 lmp.py:1627]   CPU total tokens: 4062 (33.1%)
DEBUG 01-15 10:09:44.909587.909587 lmp.py:1628]   GPU total tokens: 8226 (66.9%)
DEBUG 01-15 10:09:44.909767.909767 cuda_h.py:19] end experts_map_get cost 0.002074003219604492 seconds
INFO 01-15 10:09:44.909022.909022 client.py:127] Model loaded
DEBUG 01-15 10:09:44.909515.909515 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.909689.909689 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.909227.909227 lmp.py:1636] 
DEBUG 01-15 10:09:44.909227.909227 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.909248.909248 cuda_h.py:19] end cpu_experts_submit cost 0.00022912025451660156 seconds
DEBUG 01-15 10:09:44.909712.909712 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.909132.909132 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.910391.910391 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.910023.910023 cuda_h.py:19] end allocate_cuda_memory cost 0.0002503395080566406 seconds
DEBUG 01-15 10:09:44.910403.910403 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.910404.910404 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.910843.910843 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.910930.910930 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bfcea5f6-825c-49c9-8bb0-7510ccea2338
DEBUG 01-15 10:09:44.910085.910085 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.911591.911591 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.912228.912228 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:44.912196.912196 cuda_h.py:19] end restore2model cost 0.002567768096923828 seconds
INFO 01-15 10:09:44.912315.912315 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bfcea5f6-825c-49c9-8bb0-7510ccea2338
DEBUG 01-15 10:09:44.912391.912391 cuda_h.py:19] end sllm_worker_task cost 0.013002395629882812 seconds
DEBUG 01-15 10:09:44.912666.912666 cuda_h.py:19] end load_into_gpu_async cost 0.00208282470703125 seconds
DEBUG 01-15 10:09:44.912656.912656 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.913269.913269 cuda_h.py:19] end move_flatidxs cost 0.0009834766387939453 seconds
DEBUG 01-15 10:09:44.913417.913417 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.913233.913233 cuda_h.py:19] end restore_tensors2 cost 0.0005686283111572266 seconds
DEBUG 01-15 10:09:44.913473.913473 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003453969955444336 seconds
DEBUG 01-15 10:09:44.913641.913641 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.916478.916478 cuda_h.py:19] end restore2model cost 0.0032165050506591797 seconds
DEBUG 01-15 10:09:44.916004.916004 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006896257400512695 seconds
DEBUG 01-15 10:09:44.916468.916468 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.917567.917567 cuda_h.py:19] end gpu_sexperts cost 0.00035572052001953125 seconds
DEBUG 01-15 10:09:44.917404.917404 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.919193.919193 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001983642578125 seconds
DEBUG 01-15 10:09:44.920746.920746 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.920779.920779 cuda_h.py:19] end group_tensors cost 0.006779909133911133 seconds
DEBUG 01-15 10:09:44.920957.920957 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:44.920169.920169 cuda_h.py:19] end gpu_group_list cost 0.0003275871276855469 seconds
DEBUG 01-15 10:09:44.920028.920028 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.922834.922834 cuda_h.py:19] end acpu_expert_weight_slices cost 0.00107574462890625 seconds
DEBUG 01-15 10:09:44.922087.922087 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.922870.922870 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-15 10:09:44.922474.922474 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.926768.926768 cuda_h.py:19] end group pad cost 0.005391597747802734 seconds
DEBUG 01-15 10:09:44.926141.926141 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:44.945162.945162 cuda_h.py:19] end group_einsum cost 0.01913762092590332 seconds
DEBUG 01-15 10:09:44.945565.945565 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:44.950520.950520 cuda_h.py:19] end get_outputs_cpu1 cost 0.0049130916595458984 seconds
DEBUG 01-15 10:09:44.951109.951109 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03951263427734375 seconds
DEBUG 01-15 10:09:44.952507.952507 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.030602693557739258 seconds
DEBUG 01-15 10:09:44.953958.953958 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:44.953483.953483 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.953353.953353 cuda_h.py:19] end index_scatter cost 0.00015807151794433594 seconds
DEBUG 01-15 10:09:44.954088.954088 cuda_h.py:19] end cpuoutputsdeal cost 0.0012249946594238281 seconds
DEBUG 01-15 10:09:44.954237.954237 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:44.954499.954499 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bfcea5f6-825c-49c9-8bb0-7510ccea2338
INFO 01-15 10:09:44.963018.963018 client.py:127] Model loaded
DEBUG 01-15 10:09:44.963771.963771 cuda_h.py:19] end wait_experts cost 0.008738517761230469 seconds
DEBUG 01-15 10:09:44.963489.963489 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:44.963566.963566 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:44.963198.963198 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:44.964378.964378 cuda_h.py:19] end gpu_group_tensor cost 0.00037169456481933594 seconds
DEBUG 01-15 10:09:44.964392.964392 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:44.965093.965093 cuda_h.py:19] end gpu_group_einsum cost 0.0010368824005126953 seconds
DEBUG 01-15 10:09:44.965009.965009 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:44.965371.965371 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:44.966207.966207 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005702972412109375 seconds
DEBUG 01-15 10:09:44.966746.966746 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:44.966886.966886 cuda_h.py:19] end concat_expert_out cost 0.0001289844512939453 seconds
DEBUG 01-15 10:09:44.966844.966844 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:44.967414.967414 cuda_h.py:19] end index_scatter cost 0.00012159347534179688 seconds
DEBUG 01-15 10:09:44.967397.967397 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014133453369140625 seconds
DEBUG 01-15 10:09:44.967443.967443 cuda_h.py:19] end gpu_experts cost 0.0038971900939941406 seconds
DEBUG 01-15 10:09:44.967701.967701 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06116342544555664 seconds
DEBUG 01-15 10:09:44.968920.968920 cuda_h.py:19] end prefill_layer cost 0.06923127174377441 seconds
DEBUG 01-15 10:09:44.968263.968263 lmp.py:1552] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-15 10:09:44.968882.968882 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:44.968646.968646 lmp.py:1495] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-15 10:09:44.968264.968264 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:44.968889.968889 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-15 10:09:44.968708.968708 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.794929504394531e-05 seconds
DEBUG 01-15 10:09:44.969532.969532 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00016069412231445312 seconds
DEBUG 01-15 10:09:44.969522.969522 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:44.969677.969677 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:44.969489.969489 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.969838.969838 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.969430.969430 cuda_h.py:19] end allocate_cuda_memory cost 0.00022101402282714844 seconds
DEBUG 01-15 10:09:44.969425.969425 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.969042.969042 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.969203.969203 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.969575.969575 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a2432a8d-a350-4733-a31e-4d9ca107418a
DEBUG 01-15 10:09:44.969406.969406 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.970835.970835 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:44.970119.970119 cuda_h.py:10] start self_attn
INFO 01-15 10:09:44.971550.971550 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a2432a8d-a350-4733-a31e-4d9ca107418a
DEBUG 01-15 10:09:44.971115.971115 cuda_h.py:19] end load_into_gpu_async cost 0.0017733573913574219 seconds
DEBUG 01-15 10:09:44.971818.971818 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.971405.971405 cuda_h.py:19] end restore_tensors2 cost 8.893013000488281e-05 seconds
DEBUG 01-15 10:09:44.971068.971068 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023429393768310547 seconds
INFO 01-15 10:09:44.971925.971925 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a2432a8d-a350-4733-a31e-4d9ca107418a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:44.975242.975242 cuda_h.py:19] end self_attn cost 0.005159854888916016 seconds
DEBUG 01-15 10:09:44.976517.976517 cuda_h.py:19] end iln_self_attn_paln cost 0.007091045379638672 seconds
DEBUG 01-15 10:09:44.976084.976084 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-15 10:09:44.976079.976079 cuda_h.py:10] start gate
DEBUG 01-15 10:09:44.977353.977353 cuda_h.py:19] end gate cost 0.0009813308715820312 seconds
DEBUG 01-15 10:09:44.977038.977038 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:44.978606.978606 lmp.py:1616] 
DEBUG 01-15 10:09:44.978606.978606 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:44.978152.978152 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:44.978174.978174 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:44.978612.978612 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:44.978329.978329 lmp.py:1620] 
DEBUG 01-15 10:09:44.978329.978329 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:44.978568.978568 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:44.978729.978729 lmp.py:1626]   Expert 54 |     22 | CPU
INFO 01-15 10:09:44.978215.978215 client.py:127] Model loaded
DEBUG 01-15 10:09:44.978780.978780 lmp.py:1626]   Expert  3 |     33 | CPU
DEBUG 01-15 10:09:44.978530.978530 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.978724.978724 lmp.py:1626]   Expert  8 |     42 | CPU
DEBUG 01-15 10:09:44.979902.979902 lmp.py:1626]   Expert 28 |     44 | CPU
DEBUG 01-15 10:09:44.979631.979631 cuda_h.py:19] end restore2model cost 0.0005404949188232422 seconds
DEBUG 01-15 10:09:44.979540.979540 lmp.py:1626]   Expert 43 |     53 | CPU
DEBUG 01-15 10:09:44.979436.979436 cuda_h.py:19] end sllm_worker_task cost 0.010297536849975586 seconds
DEBUG 01-15 10:09:44.979471.979471 lmp.py:1626]   Expert 63 |     54 | CPU
DEBUG 01-15 10:09:44.979077.979077 lmp.py:1626]   Expert 36 |     72 | CPU
DEBUG 01-15 10:09:44.979032.979032 lmp.py:1626]   Expert 38 |     77 | CPU
DEBUG 01-15 10:09:44.979841.979841 lmp.py:1626]   Expert  6 |     83 | CPU
DEBUG 01-15 10:09:44.979696.979696 lmp.py:1626]   Expert 39 |     96 | CPU
DEBUG 01-15 10:09:44.979744.979744 lmp.py:1626]   Expert 57 |     97 | CPU
DEBUG 01-15 10:09:44.979791.979791 lmp.py:1626]   Expert 41 |    103 | CPU
DEBUG 01-15 10:09:44.979124.979124 lmp.py:1626]   Expert 52 |    108 | CPU
DEBUG 01-15 10:09:44.980807.980807 lmp.py:1626]   Expert 12 |    114 | CPU
DEBUG 01-15 10:09:44.980047.980047 lmp.py:1626]   Expert 19 |    123 | CPU
DEBUG 01-15 10:09:44.980571.980571 lmp.py:1626]   Expert 47 |    126 | CPU
DEBUG 01-15 10:09:44.980334.980334 lmp.py:1626]   Expert 13 |    136 | CPU
DEBUG 01-15 10:09:44.980143.980143 lmp.py:1626]   Expert 22 |    145 | CPU
DEBUG 01-15 10:09:44.980283.980283 lmp.py:1626]   Expert 46 |    147 | CPU
DEBUG 01-15 10:09:44.980424.980424 lmp.py:1626]   Expert 50 |    151 | CPU
DEBUG 01-15 10:09:44.980564.980564 lmp.py:1626]   Expert 40 |    162 | CPU
DEBUG 01-15 10:09:44.980227.980227 lmp.py:1626]   Expert 20 |    164 | CPU
DEBUG 01-15 10:09:44.980798.980798 lmp.py:1626]   Expert 24 |    167 | CPU
DEBUG 01-15 10:09:44.980607.980607 lmp.py:1626]   Expert 55 |    168 | CPU
DEBUG 01-15 10:09:44.980238.980238 lmp.py:1626]   Expert  2 |    171 | CPU
DEBUG 01-15 10:09:44.980331.980331 lmp.py:1626]   Expert 23 |    171 | CPU
DEBUG 01-15 10:09:44.980472.980472 lmp.py:1626]   Expert 37 |    172 | CPU
DEBUG 01-15 10:09:44.980135.980135 lmp.py:1626]   Expert 53 |    173 | CPU
DEBUG 01-15 10:09:44.980421.980421 lmp.py:1626]   Expert 49 |    177 | CPU
DEBUG 01-15 10:09:44.980230.980230 lmp.py:1626]   Expert 61 |    177 | CPU
DEBUG 01-15 10:09:44.980609.980609 lmp.py:1626]   Expert 21 |    178 | CPU
DEBUG 01-15 10:09:44.980219.980219 lmp.py:1626]   Expert 42 |    179 | CPU
DEBUG 01-15 10:09:44.980431.980431 lmp.py:1626]   Expert 33 |    190 | GPU
DEBUG 01-15 10:09:44.980405.980405 lmp.py:1626]   Expert 18 |    191 | GPU
DEBUG 01-15 10:09:44.980379.980379 lmp.py:1626]   Expert 32 |    197 | GPU
DEBUG 01-15 10:09:44.980115.980115 lmp.py:1626]   Expert 14 |    199 | GPU
DEBUG 01-15 10:09:44.980566.980566 lmp.py:1626]   Expert  0 |    200 | GPU
DEBUG 01-15 10:09:44.980778.980778 lmp.py:1626]   Expert 30 |    200 | GPU
DEBUG 01-15 10:09:44.980183.980183 lmp.py:1626]   Expert 16 |    202 | GPU
DEBUG 01-15 10:09:44.980972.980972 lmp.py:1626]   Expert  5 |    203 | GPU
DEBUG 01-15 10:09:44.980615.980615 lmp.py:1626]   Expert  7 |    209 | GPU
DEBUG 01-15 10:09:44.980827.980827 lmp.py:1626]   Expert 34 |    209 | GPU
DEBUG 01-15 10:09:44.980040.980040 lmp.py:1626]   Expert 31 |    212 | GPU
DEBUG 01-15 10:09:44.980252.980252 lmp.py:1626]   Expert 62 |    218 | GPU
DEBUG 01-15 10:09:44.980988.980988 lmp.py:1626]   Expert  9 |    220 | GPU
DEBUG 01-15 10:09:44.980962.980962 lmp.py:1626]   Expert 59 |    221 | GPU
DEBUG 01-15 10:09:44.980936.980936 lmp.py:1626]   Expert 60 |    221 | GPU
DEBUG 01-15 10:09:44.980910.980910 lmp.py:1626]   Expert 10 |    224 | GPU
DEBUG 01-15 10:09:44.980884.980884 lmp.py:1626]   Expert 17 |    224 | GPU
DEBUG 01-15 10:09:44.980619.980619 lmp.py:1626]   Expert 29 |    229 | GPU
DEBUG 01-15 10:09:44.980593.980593 lmp.py:1626]   Expert 58 |    234 | GPU
DEBUG 01-15 10:09:44.980998.980998 lmp.py:1626]   Expert  4 |    236 | GPU
DEBUG 01-15 10:09:44.980403.980403 lmp.py:1626]   Expert 15 |    237 | GPU
DEBUG 01-15 10:09:44.981807.981807 lmp.py:1626]   Expert 26 |    242 | GPU
DEBUG 01-15 10:09:44.981781.981781 lmp.py:1626]   Expert 51 |    255 | GPU
DEBUG 01-15 10:09:44.981232.981232 lmp.py:1626]   Expert 11 |    267 | GPU
DEBUG 01-15 10:09:44.981398.981398 lmp.py:1626]   Expert 44 |    268 | GPU
DEBUG 01-15 10:09:44.981041.981041 lmp.py:1626]   Expert 56 |    287 | GPU
DEBUG 01-15 10:09:44.981923.981923 lmp.py:1626]   Expert 27 |    290 | GPU
DEBUG 01-15 10:09:44.981804.981804 lmp.py:1626]   Expert  1 |    335 | GPU
DEBUG 01-15 10:09:44.981262.981262 lmp.py:1626]   Expert 45 |    364 | GPU
DEBUG 01-15 10:09:44.981958.981958 lmp.py:1626]   Expert 25 |    461 | GPU
DEBUG 01-15 10:09:44.981223.981223 lmp.py:1626]   Expert 35 |    515 | GPU
DEBUG 01-15 10:09:44.981866.981866 lmp.py:1626]   Expert 48 |    643 | GPU
DEBUG 01-15 10:09:44.981224.981224 lmp.py:1627] 
DEBUG 01-15 10:09:44.981224.981224 lmp.py:1627]   CPU total tokens: 3885 (31.6%)
DEBUG 01-15 10:09:44.981536.981536 lmp.py:1628]   GPU total tokens: 8403 (68.4%)
DEBUG 01-15 10:09:44.981570.981570 cuda_h.py:19] end experts_map_get cost 0.0033957958221435547 seconds
DEBUG 01-15 10:09:44.981566.981566 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:44.981984.981984 lmp.py:1636] 
DEBUG 01-15 10:09:44.981984.981984 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:44.981443.981443 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-15 10:09:44.981424.981424 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:44.981459.981459 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:44.981221.981221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:44.981765.981765 cuda_h.py:19] end allocate_cuda_memory cost 0.00019049644470214844 seconds
DEBUG 01-15 10:09:44.981416.981416 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:44.982503.982503 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:44.982380.982380 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:44.982811.982811 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e5553cd-ebb2-4b8c-9a66-add5bc173994
DEBUG 01-15 10:09:44.982145.982145 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:44.982785.982785 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:44.983093.983093 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:44.983810.983810 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e5553cd-ebb2-4b8c-9a66-add5bc173994
DEBUG 01-15 10:09:44.983222.983222 cuda_h.py:19] end load_into_gpu_async cost 0.0018954277038574219 seconds
DEBUG 01-15 10:09:44.983495.983495 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:44.984612.984612 cuda_h.py:19] end move_flatidxs cost 0.0009582042694091797 seconds
DEBUG 01-15 10:09:44.984720.984720 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:44.984101.984101 cuda_h.py:19] end restore_tensors2 cost 0.00048160552978515625 seconds
DEBUG 01-15 10:09:44.984289.984289 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030083656311035156 seconds
DEBUG 01-15 10:09:44.984535.984535 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:44.987991.987991 cuda_h.py:19] end restore2model cost 0.002693653106689453 seconds
DEBUG 01-15 10:09:44.987318.987318 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005902767181396484 seconds
DEBUG 01-15 10:09:44.987398.987398 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:44.987580.987580 cuda_h.py:19] end gpu_sexperts cost 0.0002796649932861328 seconds
DEBUG 01-15 10:09:44.987887.987887 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:44.989112.989112 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015344619750976562 seconds
DEBUG 01-15 10:09:44.990906.990906 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:44.990297.990297 cuda_h.py:19] end gpu_group_list cost 0.0003364086151123047 seconds
DEBUG 01-15 10:09:44.990460.990460 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:44.991162.991162 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007579326629638672 seconds
DEBUG 01-15 10:09:44.991793.991793 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:44.991331.991331 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.811981201171875e-05 seconds
DEBUG 01-15 10:09:44.991742.991742 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:44.996679.996679 cuda_h.py:19] end group_tensors cost 0.012128591537475586 seconds
DEBUG 01-15 10:09:44.997947.997947 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.001678.001678 cuda_h.py:19] end group pad cost 0.0043773651123046875 seconds
DEBUG 01-15 10:09:45.001859.001859 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.024096.024096 cuda_h.py:19] end group_einsum cost 0.022012710571289062 seconds
DEBUG 01-15 10:09:45.024645.024645 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.029666.029666 cuda_h.py:19] end get_outputs_cpu1 cost 0.00471043586730957 seconds
DEBUG 01-15 10:09:45.029627.029627 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04678201675415039 seconds
DEBUG 01-15 10:09:45.030293.030293 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0391237735748291 seconds
DEBUG 01-15 10:09:45.030916.030916 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.031145.031145 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.031784.031784 cuda_h.py:19] end index_scatter cost 0.00016951560974121094 seconds
DEBUG 01-15 10:09:45.032969.032969 cuda_h.py:19] end cpuoutputsdeal cost 0.0016505718231201172 seconds
DEBUG 01-15 10:09:45.032231.032231 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.032737.032737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e5553cd-ebb2-4b8c-9a66-add5bc173994
INFO 01-15 10:09:45.034203.034203 client.py:127] Model loaded
DEBUG 01-15 10:09:45.034910.034910 cuda_h.py:19] end wait_experts cost 0.0017848014831542969 seconds
DEBUG 01-15 10:09:45.034104.034104 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.034572.034572 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.034966.034966 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.035815.035815 cuda_h.py:19] end gpu_group_tensor cost 0.0003752708435058594 seconds
DEBUG 01-15 10:09:45.035266.035266 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.037230.037230 cuda_h.py:19] end gpu_group_einsum cost 0.0017201900482177734 seconds
DEBUG 01-15 10:09:45.037315.037315 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.038294.038294 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.038290.038290 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005769729614257812 seconds
DEBUG 01-15 10:09:45.038306.038306 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.039419.039419 cuda_h.py:19] end concat_expert_out cost 0.00014638900756835938 seconds
DEBUG 01-15 10:09:45.039438.039438 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.039750.039750 cuda_h.py:19] end index_scatter cost 0.00014281272888183594 seconds
DEBUG 01-15 10:09:45.039972.039972 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014920234680175781 seconds
DEBUG 01-15 10:09:45.039514.039514 cuda_h.py:19] end gpu_experts cost 0.004865407943725586 seconds
DEBUG 01-15 10:09:45.039726.039726 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06322288513183594 seconds
DEBUG 01-15 10:09:45.040418.040418 cuda_h.py:19] end prefill_layer cost 0.07211875915527344 seconds
DEBUG 01-15 10:09:45.040610.040610 lmp.py:1552] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-15 10:09:45.041182.041182 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.041469.041469 lmp.py:1495] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-15 10:09:45.041471.041471 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:45.041196.041196 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-15 10:09:45.041353.041353 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.05718994140625e-05 seconds
DEBUG 01-15 10:09:45.041979.041979 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:45.041340.041340 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 0.0002791881561279297 seconds
DEBUG 01-15 10:09:45.041443.041443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.041558.041558 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.041873.041873 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.042365.042365 cuda_h.py:19] end allocate_cuda_memory cost 0.0003483295440673828 seconds
DEBUG 01-15 10:09:45.042513.042513 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.042561.042561 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.042198.042198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.042477.042477 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19c6f088-11af-4129-9c71-edfdbaad5983
DEBUG 01-15 10:09:45.042574.042574 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.042078.042078 mlpmodule.py:393] cuda:1 cuda:1
INFO 01-15 10:09:45.043532.043532 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19c6f088-11af-4129-9c71-edfdbaad5983
DEBUG 01-15 10:09:45.043752.043752 cuda_h.py:19] end load_into_gpu_async cost 0.0011601448059082031 seconds
DEBUG 01-15 10:09:45.043216.043216 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.043949.043949 cuda_h.py:19] end restore_tensors2 cost 9.131431579589844e-05 seconds
DEBUG 01-15 10:09:45.043943.043943 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019459724426269531 seconds
INFO 01-15 10:09:45.043356.043356 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19c6f088-11af-4129-9c71-edfdbaad5983
DEBUG 01-15 10:09:45.043651.043651 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.050277.050277 cuda_h.py:19] end self_attn cost 0.006075620651245117 seconds
INFO 01-15 10:09:45.050694.050694 client.py:127] Model loaded
DEBUG 01-15 10:09:45.050146.050146 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.051925.051925 cuda_h.py:19] end restore2model cost 0.0004725456237792969 seconds
DEBUG 01-15 10:09:45.051986.051986 cuda_h.py:19] end sllm_worker_task cost 0.009511947631835938 seconds
DEBUG 01-15 10:09:45.051750.051750 cuda_h.py:19] end iln_self_attn_paln cost 0.009504079818725586 seconds
DEBUG 01-15 10:09:45.051107.051107 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-15 10:09:45.051090.051090 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.052919.052919 cuda_h.py:19] end gate cost 0.0007476806640625 seconds
DEBUG 01-15 10:09:45.052954.052954 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.053087.053087 lmp.py:1616] 
DEBUG 01-15 10:09:45.053087.053087 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.053095.053095 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.053851.053851 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.053792.053792 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.053396.053396 lmp.py:1620] 
DEBUG 01-15 10:09:45.053396.053396 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.053953.053953 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.053225.053225 lmp.py:1626]   Expert 44 |     28 | CPU
DEBUG 01-15 10:09:45.053590.053590 lmp.py:1626]   Expert  9 |     33 | CPU
DEBUG 01-15 10:09:45.053717.053717 lmp.py:1626]   Expert 11 |     35 | CPU
DEBUG 01-15 10:09:45.053843.053843 lmp.py:1626]   Expert 56 |     59 | CPU
DEBUG 01-15 10:09:45.053732.053732 lmp.py:1626]   Expert 54 |     77 | CPU
DEBUG 01-15 10:09:45.053858.053858 lmp.py:1626]   Expert 62 |     91 | CPU
DEBUG 01-15 10:09:45.053508.053508 lmp.py:1626]   Expert  7 |     92 | CPU
DEBUG 01-15 10:09:45.053158.053158 lmp.py:1626]   Expert 47 |     92 | CPU
DEBUG 01-15 10:09:45.053569.053569 lmp.py:1626]   Expert 51 |    102 | CPU
DEBUG 01-15 10:09:45.053411.053411 lmp.py:1626]   Expert 41 |    109 | CPU
DEBUG 01-15 10:09:45.053061.053061 lmp.py:1626]   Expert 52 |    109 | CPU
DEBUG 01-15 10:09:45.053234.053234 lmp.py:1626]   Expert 60 |    109 | CPU
DEBUG 01-15 10:09:45.053645.053645 lmp.py:1626]   Expert 22 |    110 | CPU
DEBUG 01-15 10:09:45.053295.053295 lmp.py:1626]   Expert 53 |    111 | CPU
DEBUG 01-15 10:09:45.053945.053945 lmp.py:1626]   Expert  1 |    126 | CPU
DEBUG 01-15 10:09:45.053356.053356 lmp.py:1626]   Expert  6 |    126 | CPU
DEBUG 01-15 10:09:45.053767.053767 lmp.py:1626]   Expert 48 |    128 | CPU
DEBUG 01-15 10:09:45.053179.053179 lmp.py:1626]   Expert  2 |    129 | CPU
DEBUG 01-15 10:09:45.053067.053067 lmp.py:1626]   Expert  8 |    129 | CPU
DEBUG 01-15 10:09:45.053240.053240 lmp.py:1626]   Expert 32 |    129 | CPU
DEBUG 01-15 10:09:45.053889.053889 lmp.py:1626]   Expert 59 |    139 | CPU
DEBUG 01-15 10:09:45.053062.053062 lmp.py:1626]   Expert 23 |    142 | CPU
DEBUG 01-15 10:09:45.053997.053997 lmp.py:1626]   Expert 27 |    142 | CPU
DEBUG 01-15 10:09:45.053170.053170 lmp.py:1626]   Expert 35 |    143 | CPU
DEBUG 01-15 10:09:45.053343.053343 lmp.py:1626]   Expert 26 |    144 | CPU
DEBUG 01-15 10:09:45.053516.053516 lmp.py:1626]   Expert 39 |    146 | CPU
DEBUG 01-15 10:09:45.053927.053927 lmp.py:1626]   Expert 50 |    149 | CPU
DEBUG 01-15 10:09:45.053862.053862 lmp.py:1626]   Expert 14 |    158 | CPU
DEBUG 01-15 10:09:45.053273.053273 lmp.py:1626]   Expert 46 |    166 | CPU
DEBUG 01-15 10:09:45.053446.053446 lmp.py:1626]   Expert 24 |    168 | CPU
DEBUG 01-15 10:09:45.053096.053096 lmp.py:1626]   Expert 38 |    170 | CPU
DEBUG 01-15 10:09:45.053269.053269 lmp.py:1626]   Expert 34 |    172 | CPU
DEBUG 01-15 10:09:45.053157.053157 lmp.py:1626]   Expert  0 |    173 | GPU
DEBUG 01-15 10:09:45.053568.053568 lmp.py:1626]   Expert  4 |    175 | GPU
DEBUG 01-15 10:09:45.053979.053979 lmp.py:1626]   Expert 49 |    180 | GPU
DEBUG 01-15 10:09:45.054629.054629 lmp.py:1626]   Expert 40 |    181 | GPU
DEBUG 01-15 10:09:45.054041.054041 lmp.py:1626]   Expert  5 |    184 | GPU
DEBUG 01-15 10:09:45.054929.054929 lmp.py:1626]   Expert 63 |    186 | GPU
DEBUG 01-15 10:09:45.054578.054578 lmp.py:1626]   Expert 19 |    192 | GPU
DEBUG 01-15 10:09:45.054990.054990 lmp.py:1626]   Expert 13 |    196 | GPU
DEBUG 01-15 10:09:45.054878.054878 lmp.py:1626]   Expert 43 |    204 | GPU
DEBUG 01-15 10:09:45.054051.054051 lmp.py:1626]   Expert 29 |    208 | GPU
DEBUG 01-15 10:09:45.054462.054462 lmp.py:1626]   Expert 57 |    209 | GPU
DEBUG 01-15 10:09:45.054112.054112 lmp.py:1626]   Expert 61 |    210 | GPU
DEBUG 01-15 10:09:45.054000.054000 lmp.py:1626]   Expert 31 |    223 | GPU
DEBUG 01-15 10:09:45.054650.054650 lmp.py:1626]   Expert 33 |    224 | GPU
DEBUG 01-15 10:09:45.054061.054061 lmp.py:1626]   Expert 16 |    252 | GPU
DEBUG 01-15 10:09:45.054473.054473 lmp.py:1626]   Expert 20 |    252 | GPU
DEBUG 01-15 10:09:45.054646.054646 lmp.py:1626]   Expert 37 |    253 | GPU
DEBUG 01-15 10:09:45.054064.054064 lmp.py:1626]   Expert  3 |    257 | GPU
DEBUG 01-15 10:09:45.054190.054190 lmp.py:1626]   Expert 15 |    259 | GPU
DEBUG 01-15 10:09:45.054602.054602 lmp.py:1626]   Expert 36 |    274 | GPU
DEBUG 01-15 10:09:45.054490.054490 lmp.py:1626]   Expert 18 |    278 | GPU
DEBUG 01-15 10:09:45.054663.054663 lmp.py:1626]   Expert 12 |    287 | GPU
DEBUG 01-15 10:09:45.054551.054551 lmp.py:1626]   Expert 28 |    299 | GPU
DEBUG 01-15 10:09:45.054962.054962 lmp.py:1626]   Expert 17 |    306 | GPU
DEBUG 01-15 10:09:45.054374.054374 lmp.py:1626]   Expert 55 |    306 | GPU
DEBUG 01-15 10:09:45.054023.054023 lmp.py:1626]   Expert 30 |    317 | GPU
DEBUG 01-15 10:09:45.054150.054150 lmp.py:1626]   Expert 25 |    327 | GPU
DEBUG 01-15 10:09:45.054800.054800 lmp.py:1626]   Expert 58 |    335 | GPU
DEBUG 01-15 10:09:45.054211.054211 lmp.py:1626]   Expert 10 |    361 | GPU
DEBUG 01-15 10:09:45.054861.054861 lmp.py:1626]   Expert 45 |    386 | GPU
DEBUG 01-15 10:09:45.054511.054511 lmp.py:1626]   Expert 21 |    389 | GPU
DEBUG 01-15 10:09:45.054160.054160 lmp.py:1626]   Expert 42 |    642 | GPU
DEBUG 01-15 10:09:45.054764.054764 lmp.py:1627] 
DEBUG 01-15 10:09:45.054764.054764 lmp.py:1627]   CPU total tokens: 3763 (30.6%)
DEBUG 01-15 10:09:45.054036.054036 lmp.py:1628]   GPU total tokens: 8525 (69.4%)
DEBUG 01-15 10:09:45.054362.054362 cuda_h.py:19] end experts_map_get cost 0.002052783966064453 seconds
DEBUG 01-15 10:09:45.054563.054563 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.054710.054710 lmp.py:1636] 
DEBUG 01-15 10:09:45.054710.054710 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.054474.054474 cuda_h.py:19] end cpu_experts_submit cost 7.05718994140625e-05 seconds
DEBUG 01-15 10:09:45.054415.054415 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.055954.055954 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.055970.055970 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.055656.055656 cuda_h.py:19] end allocate_cuda_memory cost 0.0002849102020263672 seconds
DEBUG 01-15 10:09:45.055189.055189 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.055243.055243 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.056061.056061 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.056652.056652 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1213108-1613-4521-ae3e-063f5cf76a1f
DEBUG 01-15 10:09:45.056505.056505 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.057763.057763 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:45.057074.057074 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:45.057552.057552 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1213108-1613-4521-ae3e-063f5cf76a1f
DEBUG 01-15 10:09:45.057455.057455 cuda_h.py:19] end load_into_gpu_async cost 0.002189159393310547 seconds
DEBUG 01-15 10:09:45.057596.057596 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.058107.058107 cuda_h.py:19] end move_flatidxs cost 0.0009243488311767578 seconds
DEBUG 01-15 10:09:45.058281.058281 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.058484.058484 cuda_h.py:19] end restore_tensors2 cost 0.0005855560302734375 seconds
DEBUG 01-15 10:09:45.058884.058884 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036003589630126953 seconds
DEBUG 01-15 10:09:45.058012.058012 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.062628.062628 cuda_h.py:19] end restore2model cost 0.0033347606658935547 seconds
DEBUG 01-15 10:09:45.062378.062378 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0071790218353271484 seconds
DEBUG 01-15 10:09:45.062790.062790 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.062767.062767 cuda_h.py:19] end gpu_sexperts cost 0.0002703666687011719 seconds
DEBUG 01-15 10:09:45.062404.062404 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.064673.064673 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001455545425415039 seconds
DEBUG 01-15 10:09:45.064792.064792 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.065176.065176 cuda_h.py:19] end gpu_group_list cost 0.0003376007080078125 seconds
DEBUG 01-15 10:09:45.065617.065617 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.066642.066642 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007188320159912109 seconds
DEBUG 01-15 10:09:45.066504.066504 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:45.066035.066035 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-15 10:09:45.066347.066347 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.069425.069425 cuda_h.py:19] end group_tensors cost 0.010978460311889648 seconds
DEBUG 01-15 10:09:45.070934.070934 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.075577.075577 cuda_h.py:19] end group pad cost 0.004523277282714844 seconds
DEBUG 01-15 10:09:45.075413.075413 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.095853.095853 cuda_h.py:19] end group_einsum cost 0.020351409912109375 seconds
DEBUG 01-15 10:09:45.095772.095772 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.100839.100839 cuda_h.py:19] end get_outputs_cpu1 cost 0.0048940181732177734 seconds
DEBUG 01-15 10:09:45.101906.101906 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.044320106506347656 seconds
DEBUG 01-15 10:09:45.102891.102891 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03613781929016113 seconds
DEBUG 01-15 10:09:45.102878.102878 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.103444.103444 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.103534.103534 cuda_h.py:19] end index_scatter cost 0.0001881122589111328 seconds
DEBUG 01-15 10:09:45.104267.104267 cuda_h.py:19] end cpuoutputsdeal cost 0.0016245841979980469 seconds
DEBUG 01-15 10:09:45.104498.104498 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.104196.104196 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1213108-1613-4521-ae3e-063f5cf76a1f
INFO 01-15 10:09:45.108351.108351 client.py:127] Model loaded
DEBUG 01-15 10:09:45.108673.108673 cuda_h.py:19] end wait_experts cost 0.004363298416137695 seconds
DEBUG 01-15 10:09:45.108007.108007 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.109614.109614 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.109292.109292 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.109526.109526 cuda_h.py:19] end gpu_group_tensor cost 0.0003757476806640625 seconds
DEBUG 01-15 10:09:45.109308.109308 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.111759.111759 cuda_h.py:19] end gpu_group_einsum cost 0.001459360122680664 seconds
DEBUG 01-15 10:09:45.111697.111697 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.111411.111411 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.112447.112447 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006053447723388672 seconds
DEBUG 01-15 10:09:45.112616.112616 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.112636.112636 cuda_h.py:19] end concat_expert_out cost 0.00014853477478027344 seconds
DEBUG 01-15 10:09:45.113132.113132 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.113106.113106 cuda_h.py:19] end index_scatter cost 0.00013971328735351562 seconds
DEBUG 01-15 10:09:45.113944.113944 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015115737915039062 seconds
DEBUG 01-15 10:09:45.113433.113433 cuda_h.py:19] end gpu_experts cost 0.004564762115478516 seconds
DEBUG 01-15 10:09:45.113877.113877 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06206774711608887 seconds
DEBUG 01-15 10:09:45.114938.114938 cuda_h.py:19] end prefill_layer cost 0.07354617118835449 seconds
DEBUG 01-15 10:09:45.114493.114493 lmp.py:1552] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-15 10:09:45.114012.114012 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.114346.114346 lmp.py:1495] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-15 10:09:45.115593.115593 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:45.115841.115841 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-15 10:09:45.115515.115515 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.866455078125e-05 seconds
DEBUG 01-15 10:09:45.115313.115313 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:45.115766.115766 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.0002601146697998047 seconds
DEBUG 01-15 10:09:45.115008.115008 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.115931.115931 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.115822.115822 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.116208.116208 cuda_h.py:19] end allocate_cuda_memory cost 0.0003273487091064453 seconds
DEBUG 01-15 10:09:45.116965.116965 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.116721.116721 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.116664.116664 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.116480.116480 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e17f0172-5871-488a-bf0c-1dce9976e8ec
DEBUG 01-15 10:09:45.116689.116689 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.116127.116127 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:45.117952.117952 cuda_h.py:10] start self_attn
INFO 01-15 10:09:45.117083.117083 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e17f0172-5871-488a-bf0c-1dce9976e8ec
DEBUG 01-15 10:09:45.117892.117892 cuda_h.py:19] end load_into_gpu_async cost 0.0015289783477783203 seconds
DEBUG 01-15 10:09:45.117879.117879 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.117737.117737 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-15 10:09:45.117348.117348 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022840499877929688 seconds
INFO 01-15 10:09:45.118899.118899 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e17f0172-5871-488a-bf0c-1dce9976e8ec
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.123889.123889 cuda_h.py:19] end self_attn cost 0.0055522918701171875 seconds
DEBUG 01-15 10:09:45.123816.123816 cuda_h.py:19] end iln_self_attn_paln cost 0.00784754753112793 seconds
DEBUG 01-15 10:09:45.123925.123925 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-15 10:09:45.123516.123516 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.124750.124750 cuda_h.py:19] end gate cost 0.000827789306640625 seconds
DEBUG 01-15 10:09:45.124507.124507 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.125920.125920 lmp.py:1616] 
DEBUG 01-15 10:09:45.125920.125920 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.125504.125504 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.125883.125883 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.125685.125685 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.125149.125149 lmp.py:1620] 
DEBUG 01-15 10:09:45.125149.125149 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.125044.125044 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.125847.125847 lmp.py:1626]   Expert 25 |     14 | CPU
DEBUG 01-15 10:09:45.125126.125126 lmp.py:1626]   Expert 48 |     33 | CPU
DEBUG 01-15 10:09:45.125305.125305 lmp.py:1626]   Expert 45 |     36 | CPU
DEBUG 01-15 10:09:45.125247.125247 lmp.py:1626]   Expert  9 |     65 | CPU
INFO 01-15 10:09:45.125388.125388 client.py:127] Model loaded
DEBUG 01-15 10:09:45.125046.125046 lmp.py:1626]   Expert  0 |     85 | CPU
DEBUG 01-15 10:09:45.125498.125498 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.125923.125923 lmp.py:1626]   Expert 54 |     85 | CPU
DEBUG 01-15 10:09:45.125535.125535 lmp.py:1626]   Expert 20 |     88 | CPU
DEBUG 01-15 10:09:45.125622.125622 lmp.py:1626]   Expert 43 |     89 | CPU
DEBUG 01-15 10:09:45.126563.126563 lmp.py:1626]   Expert 57 |     91 | CPU
DEBUG 01-15 10:09:45.126981.126981 lmp.py:1626]   Expert 47 |     93 | CPU
DEBUG 01-15 10:09:45.126399.126399 lmp.py:1626]   Expert  6 |     94 | CPU
DEBUG 01-15 10:09:45.126341.126341 lmp.py:1626]   Expert 36 |     95 | CPU
DEBUG 01-15 10:09:45.126282.126282 lmp.py:1626]   Expert 62 |    102 | CPU
DEBUG 01-15 10:09:45.126747.126747 lmp.py:1626]   Expert 15 |    103 | CPU
DEBUG 01-15 10:09:45.126449.126449 lmp.py:1626]   Expert 50 |    105 | CPU
DEBUG 01-15 10:09:45.126152.126152 lmp.py:1626]   Expert  1 |    106 | CPU
DEBUG 01-15 10:09:45.126378.126378 lmp.py:1626]   Expert 13 |    107 | CPU
DEBUG 01-15 10:09:45.126604.126604 lmp.py:1626]   Expert 61 |    107 | CPU
DEBUG 01-15 10:09:45.126830.126830 lmp.py:1626]   Expert 38 |    113 | CPU
DEBUG 01-15 10:09:45.126056.126056 lmp.py:1626]   Expert 37 |    114 | CPU
DEBUG 01-15 10:09:45.126998.126998 lmp.py:1626]   Expert 46 |    118 | CPU
DEBUG 01-15 10:09:45.126224.126224 lmp.py:1626]   Expert 14 |    120 | CPU
DEBUG 01-15 10:09:45.126927.126927 lmp.py:1626]   Expert 21 |    134 | CPU
DEBUG 01-15 10:09:45.126630.126630 lmp.py:1626]   Expert  7 |    136 | CPU
DEBUG 01-15 10:09:45.126617.126617 lmp.py:1626]   Expert 28 |    139 | CPU
DEBUG 01-15 10:09:45.126559.126559 lmp.py:1626]   Expert 52 |    141 | CPU
DEBUG 01-15 10:09:45.126261.126261 lmp.py:1626]   Expert 44 |    147 | CPU
DEBUG 01-15 10:09:45.126249.126249 lmp.py:1626]   Expert 10 |    152 | CPU
DEBUG 01-15 10:09:45.126713.126713 lmp.py:1626]   Expert 24 |    152 | CPU
DEBUG 01-15 10:09:45.126701.126701 lmp.py:1626]   Expert 42 |    153 | CPU
DEBUG 01-15 10:09:45.126404.126404 lmp.py:1626]   Expert 11 |    157 | CPU
DEBUG 01-15 10:09:45.126107.126107 lmp.py:1626]   Expert  2 |    166 | CPU
DEBUG 01-15 10:09:45.126571.126571 lmp.py:1626]   Expert 35 |    169 | GPU
DEBUG 01-15 10:09:45.126274.126274 lmp.py:1626]   Expert 26 |    172 | GPU
DEBUG 01-15 10:09:45.126500.126500 lmp.py:1626]   Expert 31 |    179 | GPU
DEBUG 01-15 10:09:45.126203.126203 lmp.py:1626]   Expert  3 |    185 | GPU
DEBUG 01-15 10:09:45.126906.126906 lmp.py:1626]   Expert 19 |    185 | GPU
DEBUG 01-15 10:09:45.126370.126370 lmp.py:1626]   Expert 32 |    186 | GPU
DEBUG 01-15 10:09:45.126835.126835 lmp.py:1626]   Expert 12 |    194 | GPU
DEBUG 01-15 10:09:45.126538.126538 lmp.py:1626]   Expert 60 |    206 | GPU
DEBUG 01-15 10:09:45.126002.126002 lmp.py:1626]   Expert 56 |    207 | GPU
DEBUG 01-15 10:09:45.126944.126944 lmp.py:1626]   Expert 40 |    214 | GPU
DEBUG 01-15 10:09:45.126408.126408 lmp.py:1626]   Expert 41 |    218 | GPU
DEBUG 01-15 10:09:45.126873.126873 lmp.py:1626]   Expert 53 |    228 | GPU
DEBUG 01-15 10:09:45.126052.126052 lmp.py:1626]   Expert 16 |    229 | GPU
DEBUG 01-15 10:09:45.126755.126755 lmp.py:1626]   Expert 23 |    231 | GPU
DEBUG 01-15 10:09:45.127696.127696 lmp.py:1626]   Expert  8 |    232 | GPU
DEBUG 01-15 10:09:45.127922.127922 lmp.py:1626]   Expert 58 |    235 | GPU
DEBUG 01-15 10:09:45.127387.127387 lmp.py:1626]   Expert 51 |    236 | GPU
DEBUG 01-15 10:09:45.127613.127613 lmp.py:1626]   Expert 59 |    241 | GPU
DEBUG 01-15 10:09:45.127839.127839 lmp.py:1626]   Expert  4 |    249 | GPU
DEBUG 01-15 10:09:45.127303.127303 lmp.py:1626]   Expert 55 |    264 | GPU
DEBUG 01-15 10:09:45.127291.127291 lmp.py:1626]   Expert 49 |    269 | GPU
DEBUG 01-15 10:09:45.127517.127517 lmp.py:1626]   Expert 29 |    275 | GPU
DEBUG 01-15 10:09:45.127505.127505 lmp.py:1626]   Expert 34 |    282 | GPU
DEBUG 01-15 10:09:45.127492.127492 lmp.py:1626]   Expert 18 |    284 | GPU
DEBUG 01-15 10:09:45.127641.127641 lmp.py:1626]   Expert 63 |    299 | GPU
DEBUG 01-15 10:09:45.127158.127158 lmp.py:1626]   Expert 27 |    356 | GPU
DEBUG 01-15 10:09:45.127384.127384 lmp.py:1626]   Expert 39 |    379 | GPU
DEBUG 01-15 10:09:45.127610.127610 lmp.py:1626]   Expert 17 |    396 | GPU
DEBUG 01-15 10:09:45.127598.127598 lmp.py:1626]   Expert 22 |    426 | GPU
DEBUG 01-15 10:09:45.127824.127824 lmp.py:1626]   Expert 33 |    456 | GPU
DEBUG 01-15 10:09:45.127812.127812 lmp.py:1626]   Expert 30 |    457 | GPU
DEBUG 01-15 10:09:45.127038.127038 lmp.py:1626]   Expert  5 |    709 | GPU
DEBUG 01-15 10:09:45.127171.127171 lmp.py:1627] 
DEBUG 01-15 10:09:45.127171.127171 lmp.py:1627]   CPU total tokens: 3440 (28.0%)
DEBUG 01-15 10:09:45.127258.127258 lmp.py:1628]   GPU total tokens: 8848 (72.0%)
DEBUG 01-15 10:09:45.127259.127259 cuda_h.py:19] end experts_map_get cost 0.0028297901153564453 seconds
DEBUG 01-15 10:09:45.127607.127607 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.127629.127629 lmp.py:1636] 
DEBUG 01-15 10:09:45.127629.127629 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.127354.127354 cuda_h.py:19] end cpu_experts_submit cost 7.677078247070312e-05 seconds
DEBUG 01-15 10:09:45.127494.127494 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.127841.127841 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.128187.128187 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.128874.128874 cuda_h.py:19] end allocate_cuda_memory cost 0.00028014183044433594 seconds
DEBUG 01-15 10:09:45.128108.128108 cuda_h.py:19] end restore2model cost 0.0030989646911621094 seconds
DEBUG 01-15 10:09:45.128150.128150 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.129082.129082 cuda_h.py:19] end sllm_worker_task cost 0.014073848724365234 seconds
DEBUG 01-15 10:09:45.129046.129046 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.129725.129725 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.129203.129203 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24746cd3-f054-44b5-86db-29012737c288
DEBUG 01-15 10:09:45.130923.130923 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.130736.130736 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:45.130152.130152 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:45.131854.131854 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24746cd3-f054-44b5-86db-29012737c288
DEBUG 01-15 10:09:45.131903.131903 cuda_h.py:19] end load_into_gpu_async cost 0.001863718032836914 seconds
DEBUG 01-15 10:09:45.131904.131904 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.131166.131166 cuda_h.py:19] end move_flatidxs cost 0.0010652542114257812 seconds
DEBUG 01-15 10:09:45.131899.131899 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.132738.132738 cuda_h.py:19] end restore_tensors2 cost 0.0005443096160888672 seconds
DEBUG 01-15 10:09:45.132740.132740 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0042803287506103516 seconds
DEBUG 01-15 10:09:45.132139.132139 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.135902.135902 cuda_h.py:19] end restore2model cost 0.0027742385864257812 seconds
DEBUG 01-15 10:09:45.135467.135467 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007287263870239258 seconds
DEBUG 01-15 10:09:45.135832.135832 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.135899.135899 cuda_h.py:19] end gpu_sexperts cost 0.00036907196044921875 seconds
DEBUG 01-15 10:09:45.135635.135635 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.137590.137590 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015811920166015625 seconds
DEBUG 01-15 10:09:45.138795.138795 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.138536.138536 cuda_h.py:19] end gpu_group_list cost 0.00032258033752441406 seconds
DEBUG 01-15 10:09:45.138456.138456 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.139734.139734 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007233619689941406 seconds
DEBUG 01-15 10:09:45.139411.139411 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:45.139611.139611 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-15 10:09:45.139068.139068 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.148437.148437 cuda_h.py:19] end group_tensors cost 0.016393423080444336 seconds
DEBUG 01-15 10:09:45.149427.149427 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.153430.153430 cuda_h.py:19] end group pad cost 0.004400968551635742 seconds
DEBUG 01-15 10:09:45.153134.153134 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.175201.175201 cuda_h.py:19] end group_einsum cost 0.021480560302734375 seconds
DEBUG 01-15 10:09:45.175319.175319 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.180541.180541 cuda_h.py:19] end get_outputs_cpu1 cost 0.00518488883972168 seconds
DEBUG 01-15 10:09:45.181647.181647 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.051197052001953125 seconds
DEBUG 01-15 10:09:45.182989.182989 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0430607795715332 seconds
DEBUG 01-15 10:09:45.182280.182280 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.183692.183692 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.183827.183827 cuda_h.py:19] end index_scatter cost 0.00015544891357421875 seconds
DEBUG 01-15 10:09:45.184307.184307 cuda_h.py:19] end cpuoutputsdeal cost 0.0011131763458251953 seconds
DEBUG 01-15 10:09:45.184881.184881 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.184281.184281 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24746cd3-f054-44b5-86db-29012737c288
INFO 01-15 10:09:45.185492.185492 client.py:127] Model loaded
DEBUG 01-15 10:09:45.185000.185000 cuda_h.py:19] end wait_experts cost 0.0013060569763183594 seconds
DEBUG 01-15 10:09:45.185618.185618 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.185688.185688 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.185075.185075 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.186341.186341 cuda_h.py:19] end gpu_group_tensor cost 0.0003650188446044922 seconds
DEBUG 01-15 10:09:45.186911.186911 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.187781.187781 cuda_h.py:19] end gpu_group_einsum cost 0.0011141300201416016 seconds
DEBUG 01-15 10:09:45.187299.187299 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.188892.188892 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.188650.188650 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005829334259033203 seconds
DEBUG 01-15 10:09:45.188043.188043 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.189944.189944 cuda_h.py:19] end concat_expert_out cost 0.0001316070556640625 seconds
DEBUG 01-15 10:09:45.189995.189995 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.189850.189850 cuda_h.py:19] end index_scatter cost 0.0001220703125 seconds
DEBUG 01-15 10:09:45.189164.189164 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014150142669677734 seconds
DEBUG 01-15 10:09:45.189203.189203 cuda_h.py:19] end gpu_experts cost 0.0039424896240234375 seconds
DEBUG 01-15 10:09:45.189607.189607 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06600141525268555 seconds
DEBUG 01-15 10:09:45.190975.190975 cuda_h.py:19] end prefill_layer cost 0.0755617618560791 seconds
DEBUG 01-15 10:09:45.190325.190325 lmp.py:1552] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-15 10:09:45.190082.190082 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.190892.190892 lmp.py:1495] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-15 10:09:45.190941.190941 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:45.190619.190619 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-15 10:09:45.191909.191909 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.556510925292969e-05 seconds
DEBUG 01-15 10:09:45.191541.191541 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00015425682067871094 seconds
DEBUG 01-15 10:09:45.191814.191814 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.191985.191985 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:45.191031.191031 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:45.191222.191222 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.191882.191882 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.192081.192081 cuda_h.py:19] end allocate_cuda_memory cost 0.0005040168762207031 seconds
DEBUG 01-15 10:09:45.192193.192193 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.192250.192250 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.192361.192361 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.193537.193537 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c1011ffe-ece5-4635-8684-cd74f60ebd4a
DEBUG 01-15 10:09:45.193908.193908 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.193499.193499 cuda_h.py:10] start self_attn
INFO 01-15 10:09:45.194201.194201 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c1011ffe-ece5-4635-8684-cd74f60ebd4a
DEBUG 01-15 10:09:45.194875.194875 cuda_h.py:19] end load_into_gpu_async cost 0.001440286636352539 seconds
DEBUG 01-15 10:09:45.194494.194494 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.194714.194714 cuda_h.py:19] end restore_tensors2 cost 0.00015473365783691406 seconds
DEBUG 01-15 10:09:45.194287.194287 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028367042541503906 seconds
INFO 01-15 10:09:45.194055.194055 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c1011ffe-ece5-4635-8684-cd74f60ebd4a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.198543.198543 cuda_h.py:19] end self_attn cost 0.005176067352294922 seconds
DEBUG 01-15 10:09:45.199861.199861 cuda_h.py:19] end iln_self_attn_paln cost 0.007865667343139648 seconds
DEBUG 01-15 10:09:45.199778.199778 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-15 10:09:45.199654.199654 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.200554.200554 cuda_h.py:19] end gate cost 0.0009324550628662109 seconds
DEBUG 01-15 10:09:45.200788.200788 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.200406.200406 lmp.py:1616] 
DEBUG 01-15 10:09:45.200406.200406 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.200090.200090 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.200283.200283 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.200708.200708 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.200557.200557 lmp.py:1620] 
DEBUG 01-15 10:09:45.200557.200557 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.201405.201405 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.201684.201684 lmp.py:1626]   Expert  5 |     12 | CPU
DEBUG 01-15 10:09:45.201771.201771 lmp.py:1626]   Expert 56 |     34 | CPU
DEBUG 01-15 10:09:45.201428.201428 lmp.py:1626]   Expert 16 |     83 | CPU
DEBUG 01-15 10:09:45.201085.201085 lmp.py:1626]   Expert 27 |     88 | CPU
DEBUG 01-15 10:09:45.201980.201980 lmp.py:1626]   Expert 17 |     90 | CPU
DEBUG 01-15 10:09:45.201113.201113 lmp.py:1626]   Expert 40 |     94 | CPU
DEBUG 01-15 10:09:45.201769.201769 lmp.py:1626]   Expert 63 |    102 | CPU
DEBUG 01-15 10:09:45.201188.201188 lmp.py:1626]   Expert 51 |    104 | CPU
DEBUG 01-15 10:09:45.201036.201036 lmp.py:1626]   Expert 28 |    106 | CPU
DEBUG 01-15 10:09:45.201885.201885 lmp.py:1626]   Expert 49 |    106 | CPU
DEBUG 01-15 10:09:45.201303.201303 lmp.py:1626]   Expert 53 |    107 | CPU
DEBUG 01-15 10:09:45.201483.201483 lmp.py:1626]   Expert  7 |    113 | CPU
DEBUG 01-15 10:09:45.201901.201901 lmp.py:1626]   Expert 47 |    122 | CPU
DEBUG 01-15 10:09:45.201127.201127 lmp.py:1626]   Expert 38 |    123 | CPU
DEBUG 01-15 10:09:45.201830.201830 lmp.py:1626]   Expert 37 |    124 | CPU
DEBUG 01-15 10:09:45.201294.201294 lmp.py:1626]   Expert 62 |    125 | CPU
DEBUG 01-15 10:09:45.201189.201189 lmp.py:1626]   Expert 58 |    128 | CPU
DEBUG 01-15 10:09:45.201846.201846 lmp.py:1626]   Expert 11 |    130 | CPU
DEBUG 01-15 10:09:45.201847.201847 lmp.py:1626]   Expert 57 |    138 | CPU
DEBUG 01-15 10:09:45.201265.201265 lmp.py:1626]   Expert  1 |    147 | CPU
DEBUG 01-15 10:09:45.201730.201730 lmp.py:1626]   Expert 39 |    147 | CPU
DEBUG 01-15 10:09:45.201194.201194 lmp.py:1626]   Expert 14 |    149 | CPU
DEBUG 01-15 10:09:45.201135.201135 lmp.py:1626]   Expert 52 |    156 | CPU
DEBUG 01-15 10:09:45.201838.201838 lmp.py:1626]   Expert 23 |    157 | CPU
DEBUG 01-15 10:09:45.201210.201210 lmp.py:1626]   Expert 25 |    157 | CPU
DEBUG 01-15 10:09:45.201343.201343 lmp.py:1626]   Expert 33 |    157 | CPU
DEBUG 01-15 10:09:45.201285.201285 lmp.py:1626]   Expert 21 |    164 | CPU
DEBUG 01-15 10:09:45.201226.201226 lmp.py:1626]   Expert  6 |    170 | CPU
DEBUG 01-15 10:09:45.201167.201167 lmp.py:1626]   Expert 60 |    170 | CPU
DEBUG 01-15 10:09:45.201109.201109 lmp.py:1626]   Expert 45 |    173 | CPU
DEBUG 01-15 10:09:45.201335.201335 lmp.py:1626]   Expert 19 |    179 | CPU
DEBUG 01-15 10:09:45.201799.201799 lmp.py:1626]   Expert  4 |    184 | CPU
DEBUG 01-15 10:09:45.201740.201740 lmp.py:1626]   Expert 12 |    184 | GPU
DEBUG 01-15 10:09:45.201967.201967 lmp.py:1626]   Expert 44 |    184 | GPU
DEBUG 01-15 10:09:45.201623.201623 lmp.py:1626]   Expert  3 |    196 | GPU
DEBUG 01-15 10:09:45.201518.201518 lmp.py:1626]   Expert 30 |    196 | GPU
DEBUG 01-15 10:09:45.202221.202221 lmp.py:1626]   Expert 31 |    197 | GPU
DEBUG 01-15 10:09:45.202447.202447 lmp.py:1626]   Expert 55 |    197 | GPU
DEBUG 01-15 10:09:45.202435.202435 lmp.py:1626]   Expert 36 |    198 | GPU
DEBUG 01-15 10:09:45.202899.202899 lmp.py:1626]   Expert  9 |    209 | GPU
DEBUG 01-15 10:09:45.202125.202125 lmp.py:1626]   Expert  0 |    218 | GPU
DEBUG 01-15 10:09:45.202113.202113 lmp.py:1626]   Expert 34 |    223 | GPU
DEBUG 01-15 10:09:45.202292.202292 lmp.py:1626]   Expert 22 |    227 | GPU
DEBUG 01-15 10:09:45.202949.202949 lmp.py:1626]   Expert 41 |    231 | GPU
DEBUG 01-15 10:09:45.202652.202652 lmp.py:1626]   Expert 26 |    235 | GPU
DEBUG 01-15 10:09:45.202878.202878 lmp.py:1626]   Expert 54 |    238 | GPU
DEBUG 01-15 10:09:45.202866.202866 lmp.py:1626]   Expert 43 |    240 | GPU
DEBUG 01-15 10:09:45.202330.202330 lmp.py:1626]   Expert 59 |    248 | GPU
DEBUG 01-15 10:09:45.202556.202556 lmp.py:1626]   Expert 20 |    253 | GPU
DEBUG 01-15 10:09:45.202736.202736 lmp.py:1626]   Expert 18 |    254 | GPU
DEBUG 01-15 10:09:45.202154.202154 lmp.py:1626]   Expert 13 |    256 | GPU
DEBUG 01-15 10:09:45.202572.202572 lmp.py:1626]   Expert 50 |    256 | GPU
DEBUG 01-15 10:09:45.202037.202037 lmp.py:1626]   Expert 15 |    261 | GPU
DEBUG 01-15 10:09:45.202024.202024 lmp.py:1626]   Expert 42 |    264 | GPU
DEBUG 01-15 10:09:45.202250.202250 lmp.py:1626]   Expert 24 |    265 | GPU
DEBUG 01-15 10:09:45.202238.202238 lmp.py:1626]   Expert 29 |    268 | GPU
DEBUG 01-15 10:09:45.202702.202702 lmp.py:1626]   Expert 61 |    273 | GPU
DEBUG 01-15 10:09:45.202644.202644 lmp.py:1626]   Expert 35 |    279 | GPU
DEBUG 01-15 10:09:45.202062.202062 lmp.py:1626]   Expert 32 |    307 | GPU
DEBUG 01-15 10:09:45.202480.202480 lmp.py:1626]   Expert  2 |    338 | GPU
DEBUG 01-15 10:09:45.202706.202706 lmp.py:1626]   Expert  8 |    340 | GPU
DEBUG 01-15 10:09:45.202932.202932 lmp.py:1626]   Expert 10 |    343 | GPU
DEBUG 01-15 10:09:45.202158.202158 lmp.py:1626]   Expert 46 |    426 | GPU
DEBUG 01-15 10:09:45.202146.202146 lmp.py:1626]   Expert 48 |    445 | GPU
DEBUG 01-15 10:09:45.202802.202802 lmp.py:1627] 
DEBUG 01-15 10:09:45.202802.202802 lmp.py:1627]   CPU total tokens: 4039 (32.9%)
DEBUG 01-15 10:09:45.202366.202366 lmp.py:1628]   GPU total tokens: 8249 (67.1%)
DEBUG 01-15 10:09:45.202652.202652 cuda_h.py:19] end experts_map_get cost 0.0024099349975585938 seconds
DEBUG 01-15 10:09:45.202536.202536 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.202974.202974 lmp.py:1636] 
DEBUG 01-15 10:09:45.202974.202974 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.203984.203984 cuda_h.py:19] end cpu_experts_submit cost 7.581710815429688e-05 seconds
DEBUG 01-15 10:09:45.203839.203839 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.203848.203848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.203280.203280 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.203714.203714 cuda_h.py:19] end allocate_cuda_memory cost 0.00023937225341796875 seconds
DEBUG 01-15 10:09:45.203557.203557 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.203359.203359 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.203427.203427 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.203037.203037 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f4ac5200-44bb-44be-8a6a-544d64e31e7c
DEBUG 01-15 10:09:45.204760.204760 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:45.204286.204286 client.py:127] Model loaded
DEBUG 01-15 10:09:45.205417.205417 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.205270.205270 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:45.205908.205908 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:45.206130.206130 cuda_h.py:19] end restore2model cost 0.0010249614715576172 seconds
INFO 01-15 10:09:45.206506.206506 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f4ac5200-44bb-44be-8a6a-544d64e31e7c
DEBUG 01-15 10:09:45.206781.206781 cuda_h.py:19] end sllm_worker_task cost 0.014711141586303711 seconds
DEBUG 01-15 10:09:45.206811.206811 cuda_h.py:19] end load_into_gpu_async cost 0.0028028488159179688 seconds
DEBUG 01-15 10:09:45.206278.206278 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.207547.207547 cuda_h.py:19] end restore_tensors2 cost 0.00048542022705078125 seconds
DEBUG 01-15 10:09:45.207927.207927 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00409698486328125 seconds
DEBUG 01-15 10:09:45.207141.207141 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.207192.207192 cuda_h.py:19] end move_flatidxs cost 0.00148773193359375 seconds
DEBUG 01-15 10:09:45.207506.207506 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.210396.210396 cuda_h.py:19] end restore2model cost 0.002650737762451172 seconds
DEBUG 01-15 10:09:45.210246.210246 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0069735050201416016 seconds
DEBUG 01-15 10:09:45.210393.210393 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.210178.210178 cuda_h.py:19] end gpu_sexperts cost 0.00026869773864746094 seconds
DEBUG 01-15 10:09:45.210530.210530 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.212887.212887 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015285015106201172 seconds
DEBUG 01-15 10:09:45.212822.212822 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.213537.213537 cuda_h.py:19] end gpu_group_list cost 0.0003361701965332031 seconds
DEBUG 01-15 10:09:45.213839.213839 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.214336.214336 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007472038269042969 seconds
DEBUG 01-15 10:09:45.214774.214774 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:45.214405.214405 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-15 10:09:45.214339.214339 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.218795.218795 cuda_h.py:19] end group_tensors cost 0.01055288314819336 seconds
DEBUG 01-15 10:09:45.219625.219625 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.223017.223017 cuda_h.py:19] end group pad cost 0.004132747650146484 seconds
DEBUG 01-15 10:09:45.223052.223052 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.245031.245031 cuda_h.py:19] end group_einsum cost 0.02240896224975586 seconds
DEBUG 01-15 10:09:45.246977.246977 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.251958.251958 cuda_h.py:19] end get_outputs_cpu1 cost 0.005108833312988281 seconds
DEBUG 01-15 10:09:45.252726.252726 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04655790328979492 seconds
DEBUG 01-15 10:09:45.253631.253631 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.0389096736907959 seconds
DEBUG 01-15 10:09:45.253769.253769 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.253924.253924 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.254390.254390 cuda_h.py:19] end index_scatter cost 0.00015091896057128906 seconds
DEBUG 01-15 10:09:45.255930.255930 cuda_h.py:19] end cpuoutputsdeal cost 0.0015206336975097656 seconds
DEBUG 01-15 10:09:45.255755.255755 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.255493.255493 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f4ac5200-44bb-44be-8a6a-544d64e31e7c
INFO 01-15 10:09:45.256753.256753 client.py:127] Model loaded
DEBUG 01-15 10:09:45.257552.257552 cuda_h.py:19] end wait_experts cost 0.0017676353454589844 seconds
DEBUG 01-15 10:09:45.257554.257554 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.257479.257479 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.257203.257203 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.257377.257377 cuda_h.py:19] end gpu_group_tensor cost 0.00036716461181640625 seconds
DEBUG 01-15 10:09:45.257623.257623 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.259554.259554 cuda_h.py:19] end gpu_group_einsum cost 0.0009968280792236328 seconds
DEBUG 01-15 10:09:45.259033.259033 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.259149.259149 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.260641.260641 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005648136138916016 seconds
DEBUG 01-15 10:09:45.260842.260842 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.260068.260068 cuda_h.py:19] end concat_expert_out cost 0.00012636184692382812 seconds
DEBUG 01-15 10:09:45.260544.260544 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.260306.260306 cuda_h.py:19] end index_scatter cost 0.00012302398681640625 seconds
DEBUG 01-15 10:09:45.260666.260666 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014219284057617188 seconds
DEBUG 01-15 10:09:45.260142.260142 cuda_h.py:19] end gpu_experts cost 0.0038416385650634766 seconds
DEBUG 01-15 10:09:45.261201.261201 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.061844587326049805 seconds
DEBUG 01-15 10:09:45.261935.261935 cuda_h.py:19] end prefill_layer cost 0.0710909366607666 seconds
DEBUG 01-15 10:09:45.262292.262292 lmp.py:1552] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-15 10:09:45.262433.262433 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.262151.262151 lmp.py:1495] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-15 10:09:45.262153.262153 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:45.262970.262970 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-15 10:09:45.262750.262750 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.700920104980469e-05 seconds
DEBUG 01-15 10:09:45.262503.262503 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:45.262407.262407 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.0003204345703125 seconds
DEBUG 01-15 10:09:45.262201.262201 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.263052.263052 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.263646.263646 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.263509.263509 cuda_h.py:19] end allocate_cuda_memory cost 0.00044035911560058594 seconds
DEBUG 01-15 10:09:45.263879.263879 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:45.264968.264968 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.264259.264259 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.264648.264648 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.264664.264664 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 77aae55b-2e9e-4ec2-a6f5-d4e93352486b
DEBUG 01-15 10:09:45.264578.264578 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.265610.265610 cuda_h.py:10] start self_attn
INFO 01-15 10:09:45.265514.265514 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 77aae55b-2e9e-4ec2-a6f5-d4e93352486b
DEBUG 01-15 10:09:45.265374.265374 cuda_h.py:19] end load_into_gpu_async cost 0.0016620159149169922 seconds
DEBUG 01-15 10:09:45.266676.266676 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.266280.266280 cuda_h.py:19] end restore_tensors2 cost 0.0001552104949951172 seconds
DEBUG 01-15 10:09:45.266687.266687 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034492015838623047 seconds
INFO 01-15 10:09:45.266600.266600 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 77aae55b-2e9e-4ec2-a6f5-d4e93352486b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.269182.269182 cuda_h.py:19] end self_attn cost 0.004761695861816406 seconds
DEBUG 01-15 10:09:45.270482.270482 cuda_h.py:19] end iln_self_attn_paln cost 0.007043600082397461 seconds
DEBUG 01-15 10:09:45.270975.270975 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-15 10:09:45.270188.270188 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.271184.271184 cuda_h.py:19] end gate cost 0.000823974609375 seconds
DEBUG 01-15 10:09:45.271756.271756 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.271282.271282 lmp.py:1616] 
DEBUG 01-15 10:09:45.271282.271282 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.271919.271919 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.271589.271589 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.271968.271968 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.272962.272962 lmp.py:1620] 
DEBUG 01-15 10:09:45.272962.272962 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.272480.272480 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.272189.272189 lmp.py:1626]   Expert 36 |     20 | CPU
DEBUG 01-15 10:09:45.272945.272945 lmp.py:1626]   Expert 35 |     29 | CPU
DEBUG 01-15 10:09:45.272509.272509 lmp.py:1626]   Expert 46 |     47 | CPU
DEBUG 01-15 10:09:45.272312.272312 lmp.py:1626]   Expert 25 |     49 | CPU
DEBUG 01-15 10:09:45.272352.272352 lmp.py:1626]   Expert 51 |     53 | CPU
DEBUG 01-15 10:09:45.272870.272870 lmp.py:1626]   Expert 16 |     60 | CPU
DEBUG 01-15 10:09:45.272719.272719 lmp.py:1626]   Expert 30 |     62 | CPU
DEBUG 01-15 10:09:45.272329.272329 lmp.py:1626]   Expert  0 |     65 | CPU
DEBUG 01-15 10:09:45.272939.272939 lmp.py:1626]   Expert 43 |     69 | CPU
DEBUG 01-15 10:09:45.272788.272788 lmp.py:1626]   Expert 47 |     69 | CPU
DEBUG 01-15 10:09:45.272159.272159 lmp.py:1626]   Expert 42 |     73 | CPU
DEBUG 01-15 10:09:45.272929.272929 lmp.py:1626]   Expert 44 |     73 | CPU
DEBUG 01-15 10:09:45.272539.272539 lmp.py:1626]   Expert 39 |     75 | CPU
DEBUG 01-15 10:09:45.272911.272911 lmp.py:1626]   Expert 55 |     75 | CPU
DEBUG 01-15 10:09:45.272521.272521 lmp.py:1626]   Expert  2 |     82 | CPU
DEBUG 01-15 10:09:45.272370.272370 lmp.py:1626]   Expert  4 |    107 | CPU
DEBUG 01-15 10:09:45.272219.272219 lmp.py:1626]   Expert 33 |    119 | CPU
DEBUG 01-15 10:09:45.272829.272829 lmp.py:1626]   Expert 13 |    122 | CPU
DEBUG 01-15 10:09:45.272631.272631 lmp.py:1626]   Expert  6 |    123 | CPU
DEBUG 01-15 10:09:45.272149.272149 lmp.py:1626]   Expert 48 |    123 | CPU
DEBUG 01-15 10:09:45.272666.272666 lmp.py:1626]   Expert 61 |    125 | CPU
DEBUG 01-15 10:09:45.272515.272515 lmp.py:1626]   Expert 24 |    127 | CPU
DEBUG 01-15 10:09:45.272364.272364 lmp.py:1626]   Expert 29 |    130 | CPU
DEBUG 01-15 10:09:45.272974.272974 lmp.py:1626]   Expert 56 |    131 | CPU
DEBUG 01-15 10:09:45.272061.272061 lmp.py:1626]   Expert 15 |    133 | CPU
DEBUG 01-15 10:09:45.272386.272386 lmp.py:1626]   Expert  9 |    143 | CPU
DEBUG 01-15 10:09:45.272381.272381 lmp.py:1626]   Expert 38 |    143 | CPU
DEBUG 01-15 10:09:45.272468.272468 lmp.py:1626]   Expert 54 |    144 | CPU
DEBUG 01-15 10:09:45.272462.272462 lmp.py:1626]   Expert 20 |    145 | CPU
DEBUG 01-15 10:09:45.272788.272788 lmp.py:1626]   Expert  7 |    146 | CPU
DEBUG 01-15 10:09:45.272113.272113 lmp.py:1626]   Expert 59 |    150 | CPU
DEBUG 01-15 10:09:45.273962.273962 lmp.py:1626]   Expert 62 |    157 | CPU
DEBUG 01-15 10:09:45.273049.273049 lmp.py:1626]   Expert 45 |    158 | GPU
DEBUG 01-15 10:09:45.273136.273136 lmp.py:1626]   Expert 19 |    162 | GPU
DEBUG 01-15 10:09:45.273508.273508 lmp.py:1626]   Expert 34 |    188 | GPU
DEBUG 01-15 10:09:45.273356.273356 lmp.py:1626]   Expert 50 |    190 | GPU
DEBUG 01-15 10:09:45.273967.273967 lmp.py:1626]   Expert 57 |    192 | GPU
DEBUG 01-15 10:09:45.273007.273007 lmp.py:1626]   Expert 10 |    201 | GPU
DEBUG 01-15 10:09:45.273810.273810 lmp.py:1626]   Expert 23 |    204 | GPU
DEBUG 01-15 10:09:45.273135.273135 lmp.py:1626]   Expert 31 |    204 | GPU
DEBUG 01-15 10:09:45.273222.273222 lmp.py:1626]   Expert  8 |    211 | GPU
DEBUG 01-15 10:09:45.273071.273071 lmp.py:1626]   Expert 60 |    213 | GPU
DEBUG 01-15 10:09:45.273920.273920 lmp.py:1626]   Expert 18 |    218 | GPU
DEBUG 01-15 10:09:45.273497.273497 lmp.py:1626]   Expert 22 |    221 | GPU
DEBUG 01-15 10:09:45.273492.273492 lmp.py:1626]   Expert 53 |    224 | GPU
DEBUG 01-15 10:09:45.273340.273340 lmp.py:1626]   Expert 52 |    230 | GPU
DEBUG 01-15 10:09:45.273474.273474 lmp.py:1626]   Expert 37 |    231 | GPU
DEBUG 01-15 10:09:45.273561.273561 lmp.py:1626]   Expert  5 |    239 | GPU
DEBUG 01-15 10:09:45.273886.273886 lmp.py:1626]   Expert 17 |    243 | GPU
DEBUG 01-15 10:09:45.273973.273973 lmp.py:1626]   Expert 11 |    257 | GPU
DEBUG 01-15 10:09:45.273974.273974 lmp.py:1626]   Expert  1 |    271 | GPU
DEBUG 01-15 10:09:45.273048.273048 lmp.py:1626]   Expert 49 |    277 | GPU
DEBUG 01-15 10:09:45.273929.273929 lmp.py:1626]   Expert 41 |    278 | GPU
DEBUG 01-15 10:09:45.273572.273572 lmp.py:1626]   Expert 26 |    289 | GPU
DEBUG 01-15 10:09:45.273454.273454 lmp.py:1626]   Expert 28 |    289 | GPU
DEBUG 01-15 10:09:45.273097.273097 lmp.py:1626]   Expert 32 |    291 | GPU
DEBUG 01-15 10:09:45.273978.273978 lmp.py:1626]   Expert 58 |    296 | GPU
DEBUG 01-15 10:09:45.273906.273906 lmp.py:1626]   Expert 40 |    304 | GPU
DEBUG 01-15 10:09:45.273787.273787 lmp.py:1626]   Expert 14 |    307 | GPU
DEBUG 01-15 10:09:45.273430.273430 lmp.py:1626]   Expert 12 |    328 | GPU
DEBUG 01-15 10:09:45.273265.273265 lmp.py:1626]   Expert 63 |    333 | GPU
DEBUG 01-15 10:09:45.273577.273577 lmp.py:1626]   Expert 21 |    386 | GPU
DEBUG 01-15 10:09:45.273081.273081 lmp.py:1626]   Expert 27 |    668 | GPU
DEBUG 01-15 10:09:45.273486.273486 lmp.py:1626]   Expert  3 |   1016 | GPU
DEBUG 01-15 10:09:45.273844.273844 lmp.py:1627] 
DEBUG 01-15 10:09:45.273844.273844 lmp.py:1627]   CPU total tokens: 3169 (25.8%)
DEBUG 01-15 10:09:45.273917.273917 lmp.py:1628]   GPU total tokens: 9119 (74.2%)
DEBUG 01-15 10:09:45.273998.273998 cuda_h.py:19] end experts_map_get cost 0.0024192333221435547 seconds
DEBUG 01-15 10:09:45.273801.273801 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.273464.273464 lmp.py:1636] 
DEBUG 01-15 10:09:45.273464.273464 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.274162.274162 cuda_h.py:19] end cpu_experts_submit cost 5.698204040527344e-05 seconds
DEBUG 01-15 10:09:45.274096.274096 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.274555.274555 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.274039.274039 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.274703.274703 cuda_h.py:19] end allocate_cuda_memory cost 0.00020837783813476562 seconds
DEBUG 01-15 10:09:45.274069.274069 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.274110.274110 sllm_store_c.py:27] get device uuid map
INFO 01-15 10:09:45.274962.274962 client.py:127] Model loaded
DEBUG 01-15 10:09:45.275418.275418 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.275165.275165 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a301c02-d79c-48ab-8a1b-e28cc8f3336e
DEBUG 01-15 10:09:45.275498.275498 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.275626.275626 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.275647.275647 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-15 10:09:45.276817.276817 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:45.276238.276238 cuda_h.py:19] end restore2model cost 0.0009551048278808594 seconds
DEBUG 01-15 10:09:45.277507.277507 cuda_h.py:19] end sllm_worker_task cost 0.014111518859863281 seconds
DEBUG 01-15 10:09:45.277942.277942 cuda_h.py:19] end move_flatidxs cost 0.0008945465087890625 seconds
INFO 01-15 10:09:45.277062.277062 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a301c02-d79c-48ab-8a1b-e28cc8f3336e
DEBUG 01-15 10:09:45.277779.277779 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.277150.277150 cuda_h.py:19] end load_into_gpu_async cost 0.002589702606201172 seconds
DEBUG 01-15 10:09:45.277668.277668 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.277354.277354 cuda_h.py:19] end restore_tensors2 cost 0.00047850608825683594 seconds
DEBUG 01-15 10:09:45.277641.277641 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037250518798828125 seconds
DEBUG 01-15 10:09:45.277417.277417 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.280824.280824 cuda_h.py:19] end restore2model cost 0.0026235580444335938 seconds
DEBUG 01-15 10:09:45.280873.280873 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0065538883209228516 seconds
DEBUG 01-15 10:09:45.280907.280907 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.280268.280268 cuda_h.py:19] end gpu_sexperts cost 0.0002713203430175781 seconds
DEBUG 01-15 10:09:45.281336.281336 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.282990.282990 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001500844955444336 seconds
DEBUG 01-15 10:09:45.283202.283202 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.283460.283460 cuda_h.py:19] end gpu_group_list cost 0.00035190582275390625 seconds
DEBUG 01-15 10:09:45.283901.283901 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.284795.284795 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0007603168487548828 seconds
DEBUG 01-15 10:09:45.284903.284903 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:45.284772.284772 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-15 10:09:45.284468.284468 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.287119.287119 cuda_h.py:19] end group_tensors cost 0.010527610778808594 seconds
DEBUG 01-15 10:09:45.288711.288711 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.292368.292368 cuda_h.py:19] end group pad cost 0.003943681716918945 seconds
DEBUG 01-15 10:09:45.292873.292873 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.310339.310339 cuda_h.py:19] end group_einsum cost 0.018166303634643555 seconds
DEBUG 01-15 10:09:45.311463.311463 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.315624.315624 cuda_h.py:19] end get_outputs_cpu1 cost 0.004335165023803711 seconds
DEBUG 01-15 10:09:45.316497.316497 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.040337562561035156 seconds
DEBUG 01-15 10:09:45.317999.317999 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.03240227699279785 seconds
DEBUG 01-15 10:09:45.317662.317662 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.317890.317890 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.318376.318376 cuda_h.py:19] end index_scatter cost 0.0001704692840576172 seconds
DEBUG 01-15 10:09:45.319064.319064 cuda_h.py:19] end cpuoutputsdeal cost 0.0016338825225830078 seconds
DEBUG 01-15 10:09:45.319605.319605 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.319873.319873 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a301c02-d79c-48ab-8a1b-e28cc8f3336e
INFO 01-15 10:09:45.328599.328599 client.py:127] Model loaded
DEBUG 01-15 10:09:45.328550.328550 cuda_h.py:19] end wait_experts cost 0.008968114852905273 seconds
DEBUG 01-15 10:09:45.328196.328196 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.328333.328333 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.328441.328441 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.329821.329821 cuda_h.py:19] end gpu_group_tensor cost 0.00037741661071777344 seconds
DEBUG 01-15 10:09:45.329802.329802 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.330310.330310 cuda_h.py:19] end gpu_group_einsum cost 0.0011916160583496094 seconds
DEBUG 01-15 10:09:45.330179.330179 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.330467.330467 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.331653.331653 cuda_h.py:19] end all_expert_outputs_slices cost 0.00021314620971679688 seconds
DEBUG 01-15 10:09:45.331847.331847 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.331102.331102 cuda_h.py:19] end concat_expert_out cost 6.937980651855469e-05 seconds
DEBUG 01-15 10:09:45.331575.331575 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.331009.331009 cuda_h.py:19] end index_scatter cost 7.677078247070312e-05 seconds
DEBUG 01-15 10:09:45.331249.331249 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006313323974609375 seconds
DEBUG 01-15 10:09:45.331331.331331 cuda_h.py:19] end gpu_experts cost 0.0031981468200683594 seconds
DEBUG 01-15 10:09:45.331347.331347 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.061327457427978516 seconds
DEBUG 01-15 10:09:45.332782.332782 cuda_h.py:19] end prefill_layer cost 0.07010030746459961 seconds
DEBUG 01-15 10:09:45.332047.332047 lmp.py:1552] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-15 10:09:45.332419.332419 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.332691.332691 lmp.py:1495] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-15 10:09:45.332156.332156 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:45.332150.332150 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-15 10:09:45.332431.332431 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.0531158447265625e-05 seconds
DEBUG 01-15 10:09:45.332418.332418 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.914138793945312e-05 seconds
DEBUG 01-15 10:09:45.332492.332492 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.332130.332130 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:45.332751.332751 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:45.333852.333852 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.333778.333778 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.333347.333347 cuda_h.py:19] end allocate_cuda_memory cost 0.0004906654357910156 seconds
DEBUG 01-15 10:09:45.334234.334234 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.334071.334071 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.334606.334606 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.334814.334814 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a93340d5-e68d-46c7-9366-52b3243a2bb1
DEBUG 01-15 10:09:45.334100.334100 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.335250.335250 cuda_h.py:10] start self_attn
INFO 01-15 10:09:45.336169.336169 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a93340d5-e68d-46c7-9366-52b3243a2bb1
DEBUG 01-15 10:09:45.336918.336918 cuda_h.py:19] end load_into_gpu_async cost 0.0023391246795654297 seconds
DEBUG 01-15 10:09:45.336431.336431 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.336062.336062 cuda_h.py:19] end restore_tensors2 cost 0.00017547607421875 seconds
DEBUG 01-15 10:09:45.337642.337642 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003709077835083008 seconds
INFO 01-15 10:09:45.337343.337343 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a93340d5-e68d-46c7-9366-52b3243a2bb1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.338910.338910 cuda_h.py:19] end self_attn cost 0.003788471221923828 seconds
DEBUG 01-15 10:09:45.339988.339988 cuda_h.py:19] end iln_self_attn_paln cost 0.006479978561401367 seconds
DEBUG 01-15 10:09:45.339467.339467 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-15 10:09:45.339184.339184 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.340710.340710 cuda_h.py:19] end gate cost 0.0006690025329589844 seconds
DEBUG 01-15 10:09:45.340262.340262 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.340346.340346 lmp.py:1616] 
DEBUG 01-15 10:09:45.340346.340346 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.340010.340010 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.340328.340328 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.340355.340355 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.340760.340760 lmp.py:1620] 
DEBUG 01-15 10:09:45.340760.340760 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.340357.340357 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.340430.340430 lmp.py:1626]   Expert 13 |     26 | CPU
DEBUG 01-15 10:09:45.340596.340596 lmp.py:1626]   Expert  9 |     39 | CPU
DEBUG 01-15 10:09:45.340524.340524 lmp.py:1626]   Expert 44 |     39 | CPU
DEBUG 01-15 10:09:45.340975.340975 lmp.py:1626]   Expert 25 |     42 | CPU
DEBUG 01-15 10:09:45.340426.340426 lmp.py:1626]   Expert 16 |     45 | CPU
DEBUG 01-15 10:09:45.340638.340638 lmp.py:1626]   Expert 38 |     47 | CPU
DEBUG 01-15 10:09:45.340566.340566 lmp.py:1626]   Expert 22 |     53 | CPU
DEBUG 01-15 10:09:45.340778.340778 lmp.py:1626]   Expert  2 |     54 | CPU
DEBUG 01-15 10:09:45.340706.340706 lmp.py:1626]   Expert 33 |     59 | CPU
DEBUG 01-15 10:09:45.340117.340117 lmp.py:1626]   Expert 42 |     59 | CPU
DEBUG 01-15 10:09:45.340145.340145 lmp.py:1626]   Expert  5 |     65 | CPU
DEBUG 01-15 10:09:45.340410.340410 lmp.py:1626]   Expert 23 |     78 | CPU
DEBUG 01-15 10:09:45.340676.340676 lmp.py:1626]   Expert 24 |     81 | CPU
DEBUG 01-15 10:09:45.340465.340465 lmp.py:1626]   Expert 10 |     85 | CPU
DEBUG 01-15 10:09:45.340776.340776 lmp.py:1626]   Expert 59 |    102 | CPU
DEBUG 01-15 10:09:45.340327.340327 lmp.py:1626]   Expert 21 |    108 | CPU
DEBUG 01-15 10:09:45.340162.340162 lmp.py:1626]   Expert 55 |    115 | CPU
DEBUG 01-15 10:09:45.340712.340712 lmp.py:1626]   Expert 46 |    116 | CPU
DEBUG 01-15 10:09:45.340547.340547 lmp.py:1626]   Expert 45 |    119 | CPU
DEBUG 01-15 10:09:45.340382.340382 lmp.py:1626]   Expert 61 |    124 | CPU
DEBUG 01-15 10:09:45.340694.340694 lmp.py:1626]   Expert 31 |    130 | CPU
DEBUG 01-15 10:09:45.340198.340198 lmp.py:1626]   Expert 51 |    139 | CPU
DEBUG 01-15 10:09:45.341987.341987 lmp.py:1626]   Expert 36 |    140 | CPU
DEBUG 01-15 10:09:45.341776.341776 lmp.py:1626]   Expert  6 |    141 | CPU
DEBUG 01-15 10:09:45.341564.341564 lmp.py:1626]   Expert  8 |    147 | CPU
DEBUG 01-15 10:09:45.341876.341876 lmp.py:1626]   Expert  0 |    148 | CPU
DEBUG 01-15 10:09:45.341427.341427 lmp.py:1626]   Expert  3 |    151 | CPU
DEBUG 01-15 10:09:45.341262.341262 lmp.py:1626]   Expert 43 |    151 | CPU
DEBUG 01-15 10:09:45.341574.341574 lmp.py:1626]   Expert 26 |    157 | CPU
DEBUG 01-15 10:09:45.341647.341647 lmp.py:1626]   Expert 48 |    157 | CPU
DEBUG 01-15 10:09:45.341721.341721 lmp.py:1626]   Expert 18 |    161 | CPU
DEBUG 01-15 10:09:45.341317.341317 lmp.py:1626]   Expert 41 |    167 | CPU
DEBUG 01-15 10:09:45.341106.341106 lmp.py:1626]   Expert 12 |    172 | GPU
DEBUG 01-15 10:09:45.341895.341895 lmp.py:1626]   Expert  7 |    180 | GPU
DEBUG 01-15 10:09:45.341333.341333 lmp.py:1626]   Expert 20 |    186 | GPU
DEBUG 01-15 10:09:45.341453.341453 lmp.py:1626]   Expert 28 |    188 | GPU
DEBUG 01-15 10:09:45.341427.341427 lmp.py:1626]   Expert 56 |    189 | GPU
DEBUG 01-15 10:09:45.341401.341401 lmp.py:1626]   Expert  1 |    192 | GPU
DEBUG 01-15 10:09:45.341375.341375 lmp.py:1626]   Expert 27 |    193 | GPU
DEBUG 01-15 10:09:45.341111.341111 lmp.py:1626]   Expert 34 |    195 | GPU
DEBUG 01-15 10:09:45.341085.341085 lmp.py:1626]   Expert 47 |    204 | GPU
DEBUG 01-15 10:09:45.341059.341059 lmp.py:1626]   Expert 11 |    213 | GPU
DEBUG 01-15 10:09:45.341271.341271 lmp.py:1626]   Expert 32 |    213 | GPU
DEBUG 01-15 10:09:45.341484.341484 lmp.py:1626]   Expert 40 |    227 | GPU
DEBUG 01-15 10:09:45.341219.341219 lmp.py:1626]   Expert 49 |    233 | GPU
DEBUG 01-15 10:09:45.341909.341909 lmp.py:1626]   Expert 53 |    236 | GPU
DEBUG 01-15 10:09:45.341360.341360 lmp.py:1626]   Expert 63 |    240 | GPU
DEBUG 01-15 10:09:45.341572.341572 lmp.py:1626]   Expert 15 |    241 | GPU
DEBUG 01-15 10:09:45.341023.341023 lmp.py:1626]   Expert  4 |    244 | GPU
DEBUG 01-15 10:09:45.341474.341474 lmp.py:1626]   Expert 29 |    245 | GPU
DEBUG 01-15 10:09:45.341210.341210 lmp.py:1626]   Expert 50 |    245 | GPU
DEBUG 01-15 10:09:45.341422.341422 lmp.py:1626]   Expert 30 |    248 | GPU
DEBUG 01-15 10:09:45.341396.341396 lmp.py:1626]   Expert 35 |    272 | GPU
DEBUG 01-15 10:09:45.341370.341370 lmp.py:1626]   Expert 14 |    275 | GPU
DEBUG 01-15 10:09:45.341106.341106 lmp.py:1626]   Expert 37 |    302 | GPU
DEBUG 01-15 10:09:45.341272.341272 lmp.py:1626]   Expert 52 |    341 | GPU
DEBUG 01-15 10:09:45.341438.341438 lmp.py:1626]   Expert 17 |    360 | GPU
DEBUG 01-15 10:09:45.341650.341650 lmp.py:1626]   Expert 54 |    378 | GPU
DEBUG 01-15 10:09:45.341340.341340 lmp.py:1626]   Expert 39 |    390 | GPU
DEBUG 01-15 10:09:45.341267.341267 lmp.py:1626]   Expert 57 |    411 | GPU
DEBUG 01-15 10:09:45.341241.341241 lmp.py:1626]   Expert 60 |    458 | GPU
DEBUG 01-15 10:09:45.341739.341739 lmp.py:1626]   Expert 62 |    458 | GPU
DEBUG 01-15 10:09:45.341713.341713 lmp.py:1626]   Expert 19 |    542 | GPU
DEBUG 01-15 10:09:45.341210.341210 lmp.py:1626]   Expert 58 |    572 | GPU
DEBUG 01-15 10:09:45.341138.341138 lmp.py:1627] 
DEBUG 01-15 10:09:45.341138.341138 lmp.py:1627]   CPU total tokens: 3245 (26.4%)
DEBUG 01-15 10:09:45.341542.341542 lmp.py:1628]   GPU total tokens: 9043 (73.6%)
DEBUG 01-15 10:09:45.341715.341715 cuda_h.py:19] end experts_map_get cost 0.0016391277313232422 seconds
DEBUG 01-15 10:09:45.341042.341042 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.341467.341467 lmp.py:1636] 
DEBUG 01-15 10:09:45.341467.341467 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.341217.341217 cuda_h.py:19] end cpu_experts_submit cost 6.246566772460938e-05 seconds
DEBUG 01-15 10:09:45.341152.341152 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.342372.342372 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.342399.342399 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.343736.343736 cuda_h.py:19] end allocate_cuda_memory cost 0.0015442371368408203 seconds
DEBUG 01-15 10:09:45.343838.343838 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.343217.343217 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.343470.343470 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.343319.343319 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43c47eb5-c447-4a4a-9dea-6d7efe0bfb51
DEBUG 01-15 10:09:45.344943.344943 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.344279.344279 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:45.345693.345693 client.py:127] Model loaded
DEBUG 01-15 10:09:45.345559.345559 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.345938.345938 cuda_h.py:10] start move_flatidxs
INFO 01-15 10:09:45.345546.345546 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43c47eb5-c447-4a4a-9dea-6d7efe0bfb51
DEBUG 01-15 10:09:45.345874.345874 cuda_h.py:19] end load_into_gpu_async cost 0.0018126964569091797 seconds
DEBUG 01-15 10:09:45.345974.345974 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.346353.346353 cuda_h.py:19] end move_flatidxs cost 0.0008440017700195312 seconds
DEBUG 01-15 10:09:45.346129.346129 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.346863.346863 cuda_h.py:19] end restore_tensors2 cost 0.000583648681640625 seconds
DEBUG 01-15 10:09:45.346197.346197 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004443168640136719 seconds
DEBUG 01-15 10:09:45.346087.346087 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.347369.347369 cuda_h.py:19] end restore2model cost 0.0010538101196289062 seconds
DEBUG 01-15 10:09:45.347901.347901 cuda_h.py:19] end sllm_worker_task cost 0.014734983444213867 seconds
DEBUG 01-15 10:09:45.351190.351190 cuda_h.py:19] end restore2model cost 0.005003690719604492 seconds
DEBUG 01-15 10:09:45.351651.351651 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009752511978149414 seconds
DEBUG 01-15 10:09:45.351560.351560 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.352660.352660 cuda_h.py:19] end gpu_sexperts cost 0.0003757476806640625 seconds
DEBUG 01-15 10:09:45.352868.352868 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.354788.354788 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002101898193359375 seconds
DEBUG 01-15 10:09:45.355301.355301 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.356577.356577 cuda_h.py:19] end gpu_group_list cost 0.0004558563232421875 seconds
DEBUG 01-15 10:09:45.356774.356774 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.355852.355852 cuda_h.py:19] end group_tensors cost 0.009484291076660156 seconds
DEBUG 01-15 10:09:45.356713.356713 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.357411.357411 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0009794235229492188 seconds
DEBUG 01-15 10:09:45.357686.357686 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:45.357119.357119 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-15 10:09:45.357974.357974 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.360870.360870 cuda_h.py:19] end group pad cost 0.0040318965911865234 seconds
DEBUG 01-15 10:09:45.360945.360945 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.379192.379192 cuda_h.py:19] end group_einsum cost 0.01877760887145996 seconds
DEBUG 01-15 10:09:45.379833.379833 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.384997.384997 cuda_h.py:19] end get_outputs_cpu1 cost 0.004584789276123047 seconds
DEBUG 01-15 10:09:45.385897.385897 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0401308536529541 seconds
DEBUG 01-15 10:09:45.386240.386240 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.028620004653930664 seconds
DEBUG 01-15 10:09:45.386240.386240 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.386323.386323 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.387577.387577 cuda_h.py:19] end index_scatter cost 0.0001704692840576172 seconds
DEBUG 01-15 10:09:45.388569.388569 cuda_h.py:19] end cpuoutputsdeal cost 0.001611471176147461 seconds
DEBUG 01-15 10:09:45.388394.388394 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.388093.388093 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43c47eb5-c447-4a4a-9dea-6d7efe0bfb51
INFO 01-15 10:09:45.396840.396840 client.py:127] Model loaded
DEBUG 01-15 10:09:45.396626.396626 cuda_h.py:19] end wait_experts cost 0.00823068618774414 seconds
DEBUG 01-15 10:09:45.396583.396583 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.396196.396196 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.396875.396875 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.397446.397446 cuda_h.py:19] end gpu_group_tensor cost 0.0003781318664550781 seconds
DEBUG 01-15 10:09:45.397090.397090 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.398688.398688 cuda_h.py:19] end gpu_group_einsum cost 0.0013279914855957031 seconds
DEBUG 01-15 10:09:45.399002.399002 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.399335.399335 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.399150.399150 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035691261291503906 seconds
DEBUG 01-15 10:09:45.399237.399237 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.399955.399955 cuda_h.py:19] end concat_expert_out cost 7.700920104980469e-05 seconds
DEBUG 01-15 10:09:45.399673.399673 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.399803.399803 cuda_h.py:19] end index_scatter cost 9.751319885253906e-05 seconds
DEBUG 01-15 10:09:45.400136.400136 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007894039154052734 seconds
DEBUG 01-15 10:09:45.400503.400503 cuda_h.py:19] end gpu_experts cost 0.0034973621368408203 seconds
DEBUG 01-15 10:09:45.400811.400811 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.06086111068725586 seconds
DEBUG 01-15 10:09:45.400207.400207 cuda_h.py:19] end prefill_layer cost 0.06820940971374512 seconds
DEBUG 01-15 10:09:45.400774.400774 lmp.py:1552] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-15 10:09:45.400000.400000 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.400987.400987 lmp.py:1495] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-15 10:09:45.400213.400213 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:45.400685.400685 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-15 10:09:45.401395.401395 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 4.172325134277344e-05 seconds
DEBUG 01-15 10:09:45.401575.401575 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.104873657226562e-05 seconds
DEBUG 01-15 10:09:45.401887.401887 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.401287.401287 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:45.401397.401397 cuda_h.py:10] start sllm_worker_task
DEBUG 01-15 10:09:45.401013.401013 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.401098.401098 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.402590.402590 cuda_h.py:19] end allocate_cuda_memory cost 0.0005154609680175781 seconds
DEBUG 01-15 10:09:45.402219.402219 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.402600.402600 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.402836.402836 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.402343.402343 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a14745cc-d441-4847-b071-11d22b6c9c88
DEBUG 01-15 10:09:45.402750.402750 cuda_h.py:10] start self_attn
DEBUG 01-15 10:09:45.403995.403995 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:45.404939.404939 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a14745cc-d441-4847-b071-11d22b6c9c88
DEBUG 01-15 10:09:45.404534.404534 cuda_h.py:19] end load_into_gpu_async cost 0.0019843578338623047 seconds
DEBUG 01-15 10:09:45.404133.404133 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.404572.404572 cuda_h.py:19] end restore_tensors2 cost 0.00016236305236816406 seconds
DEBUG 01-15 10:09:45.405357.405357 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003437519073486328 seconds
INFO 01-15 10:09:45.405554.405554 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a14745cc-d441-4847-b071-11d22b6c9c88
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.408854.408854 cuda_h.py:19] end self_attn cost 0.004777431488037109 seconds
DEBUG 01-15 10:09:45.408529.408529 cuda_h.py:19] end iln_self_attn_paln cost 0.0072901248931884766 seconds
DEBUG 01-15 10:09:45.408618.408618 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-15 10:09:45.408096.408096 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.409731.409731 cuda_h.py:19] end gate cost 0.0007483959197998047 seconds
DEBUG 01-15 10:09:45.409515.409515 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.409585.409585 lmp.py:1616] 
DEBUG 01-15 10:09:45.409585.409585 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.409870.409870 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.409527.409527 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.409654.409654 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.409919.409919 lmp.py:1620] 
DEBUG 01-15 10:09:45.409919.409919 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.410483.410483 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.410464.410464 lmp.py:1626]   Expert 20 |     11 | CPU
DEBUG 01-15 10:09:45.410776.410776 lmp.py:1626]   Expert 61 |     11 | CPU
DEBUG 01-15 10:09:45.410372.410372 lmp.py:1626]   Expert 11 |     29 | CPU
DEBUG 01-15 10:09:45.410492.410492 lmp.py:1626]   Expert  7 |     39 | CPU
DEBUG 01-15 10:09:45.410135.410135 lmp.py:1626]   Expert 62 |     41 | CPU
DEBUG 01-15 10:09:45.410494.410494 lmp.py:1626]   Expert  3 |     46 | CPU
DEBUG 01-15 10:09:45.410044.410044 lmp.py:1626]   Expert 51 |     47 | CPU
DEBUG 01-15 10:09:45.410594.410594 lmp.py:1626]   Expert 30 |     52 | CPU
DEBUG 01-15 10:09:45.410668.410668 lmp.py:1626]   Expert 17 |     53 | CPU
DEBUG 01-15 10:09:45.410980.410980 lmp.py:1626]   Expert 29 |     57 | CPU
DEBUG 01-15 10:09:45.410861.410861 lmp.py:1626]   Expert  6 |     62 | CPU
DEBUG 01-15 10:09:45.410742.410742 lmp.py:1626]   Expert  9 |     66 | CPU
DEBUG 01-15 10:09:45.410624.410624 lmp.py:1626]   Expert 38 |     77 | CPU
DEBUG 01-15 10:09:45.410505.410505 lmp.py:1626]   Expert 63 |     77 | CPU
DEBUG 01-15 10:09:45.410387.410387 lmp.py:1626]   Expert 55 |     80 | CPU
DEBUG 01-15 10:09:45.410029.410029 lmp.py:1626]   Expert 59 |     89 | CPU
DEBUG 01-15 10:09:45.410149.410149 lmp.py:1626]   Expert 48 |     91 | CPU
DEBUG 01-15 10:09:45.410031.410031 lmp.py:1626]   Expert 19 |     95 | CPU
DEBUG 01-15 10:09:45.410912.410912 lmp.py:1626]   Expert  8 |     96 | CPU
DEBUG 01-15 10:09:45.410270.410270 lmp.py:1626]   Expert 49 |    101 | CPU
DEBUG 01-15 10:09:45.410344.410344 lmp.py:1626]   Expert 22 |    103 | CPU
DEBUG 01-15 10:09:45.410702.410702 lmp.py:1626]   Expert 24 |    112 | CPU
DEBUG 01-15 10:09:45.410060.410060 lmp.py:1626]   Expert 36 |    115 | CPU
DEBUG 01-15 10:09:45.410180.410180 lmp.py:1626]   Expert 34 |    116 | CPU
DEBUG 01-15 10:09:45.410061.410061 lmp.py:1626]   Expert 42 |    118 | CPU
DEBUG 01-15 10:09:45.410704.410704 lmp.py:1626]   Expert 50 |    120 | CPU
DEBUG 01-15 10:09:45.410586.410586 lmp.py:1626]   Expert 39 |    123 | CPU
DEBUG 01-15 10:09:45.410229.410229 lmp.py:1626]   Expert  4 |    130 | CPU
DEBUG 01-15 10:09:45.410633.410633 lmp.py:1626]   Expert 37 |    143 | CPU
DEBUG 01-15 10:09:45.410753.410753 lmp.py:1626]   Expert 41 |    146 | CPU
DEBUG 01-15 10:09:45.410635.410635 lmp.py:1626]   Expert 15 |    148 | CPU
DEBUG 01-15 10:09:45.410039.410039 lmp.py:1626]   Expert 23 |    156 | CPU
DEBUG 01-15 10:09:45.410113.410113 lmp.py:1626]   Expert 56 |    161 | GPU
DEBUG 01-15 10:09:45.410471.410471 lmp.py:1626]   Expert 16 |    164 | GPU
DEBUG 01-15 10:09:45.410067.410067 lmp.py:1626]   Expert 60 |    166 | GPU
DEBUG 01-15 10:09:45.410426.410426 lmp.py:1626]   Expert 44 |    169 | GPU
DEBUG 01-15 10:09:45.410307.410307 lmp.py:1626]   Expert  1 |    176 | GPU
DEBUG 01-15 10:09:45.410950.410950 lmp.py:1626]   Expert 43 |    180 | GPU
DEBUG 01-15 10:09:45.410355.410355 lmp.py:1626]   Expert 21 |    182 | GPU
DEBUG 01-15 10:09:45.410998.410998 lmp.py:1626]   Expert 47 |    192 | GPU
DEBUG 01-15 10:09:45.410641.410641 lmp.py:1626]   Expert 53 |    192 | GPU
DEBUG 01-15 10:09:45.410045.410045 lmp.py:1626]   Expert 33 |    200 | GPU
DEBUG 01-15 10:09:45.410688.410688 lmp.py:1626]   Expert 12 |    202 | GPU
DEBUG 01-15 10:09:45.410093.410093 lmp.py:1626]   Expert 13 |    208 | GPU
DEBUG 01-15 10:09:45.410736.410736 lmp.py:1626]   Expert 32 |    224 | GPU
DEBUG 01-15 10:09:45.410571.410571 lmp.py:1626]   Expert 28 |    229 | GPU
DEBUG 01-15 10:09:45.410929.410929 lmp.py:1626]   Expert  0 |    253 | GPU
DEBUG 01-15 10:09:45.410241.410241 lmp.py:1626]   Expert 31 |    258 | GPU
DEBUG 01-15 10:09:45.410122.410122 lmp.py:1626]   Expert 54 |    260 | GPU
DEBUG 01-15 10:09:45.410527.410527 lmp.py:1626]   Expert 26 |    262 | GPU
DEBUG 01-15 10:09:45.410931.410931 lmp.py:1626]   Expert 10 |    266 | GPU
DEBUG 01-15 10:09:45.410336.410336 lmp.py:1626]   Expert 18 |    267 | GPU
DEBUG 01-15 10:09:45.410740.410740 lmp.py:1626]   Expert 57 |    273 | GPU
DEBUG 01-15 10:09:45.410383.410383 lmp.py:1626]   Expert  2 |    280 | GPU
DEBUG 01-15 10:09:45.411026.411026 lmp.py:1626]   Expert 58 |    299 | GPU
DEBUG 01-15 10:09:45.411669.411669 lmp.py:1626]   Expert 40 |    341 | GPU
DEBUG 01-15 10:09:45.411836.411836 lmp.py:1626]   Expert 25 |    361 | GPU
DEBUG 01-15 10:09:45.411479.411479 lmp.py:1626]   Expert 45 |    363 | GPU
DEBUG 01-15 10:09:45.411598.411598 lmp.py:1626]   Expert  5 |    441 | GPU
DEBUG 01-15 10:09:45.411864.411864 lmp.py:1626]   Expert 35 |    461 | GPU
DEBUG 01-15 10:09:45.411606.411606 lmp.py:1626]   Expert 27 |    486 | GPU
DEBUG 01-15 10:09:45.411110.411110 lmp.py:1626]   Expert 46 |    554 | GPU
DEBUG 01-15 10:09:45.411899.411899 lmp.py:1626]   Expert 52 |    590 | GPU
DEBUG 01-15 10:09:45.411449.411449 lmp.py:1626]   Expert 14 |    878 | GPU
DEBUG 01-15 10:09:45.411477.411477 lmp.py:1627] 
DEBUG 01-15 10:09:45.411477.411477 lmp.py:1627]   CPU total tokens: 2750 (22.4%)
DEBUG 01-15 10:09:45.411457.411457 lmp.py:1628]   GPU total tokens: 9538 (77.6%)
DEBUG 01-15 10:09:45.411730.411730 cuda_h.py:19] end experts_map_get cost 0.0018486976623535156 seconds
DEBUG 01-15 10:09:45.411878.411878 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.411064.411064 lmp.py:1636] 
DEBUG 01-15 10:09:45.411064.411064 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.411961.411961 cuda_h.py:19] end cpu_experts_submit cost 5.888938903808594e-05 seconds
DEBUG 01-15 10:09:45.411180.411180 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.411983.411983 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.411328.411328 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.412563.412563 cuda_h.py:19] end allocate_cuda_memory cost 0.00023818016052246094 seconds
DEBUG 01-15 10:09:45.412082.412082 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.412937.412937 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.412012.412012 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.412238.412238 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0089bec7-5bbc-4404-8e15-ffe833155deb
DEBUG 01-15 10:09:45.412879.412879 client.py:106] call stub.LoadModelAsync
INFO 01-15 10:09:45.413204.413204 client.py:127] Model loaded
DEBUG 01-15 10:09:45.413434.413434 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.414608.414608 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:45.413120.413120 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0089bec7-5bbc-4404-8e15-ffe833155deb
DEBUG 01-15 10:09:45.414433.414433 cuda_h.py:19] end load_into_gpu_async cost 0.0021514892578125 seconds
DEBUG 01-15 10:09:45.414958.414958 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.414673.414673 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:45.414186.414186 cuda_h.py:19] end restore_tensors2 cost 0.0006620883941650391 seconds
DEBUG 01-15 10:09:45.415308.415308 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003544330596923828 seconds
DEBUG 01-15 10:09:45.415158.415158 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.415306.415306 cuda_h.py:19] end move_flatidxs cost 0.0010218620300292969 seconds
DEBUG 01-15 10:09:45.415864.415864 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.416148.416148 cuda_h.py:19] end restore2model cost 0.0014128684997558594 seconds
DEBUG 01-15 10:09:45.416042.416042 cuda_h.py:19] end sllm_worker_task cost 0.015305519104003906 seconds
DEBUG 01-15 10:09:45.419550.419550 cuda_h.py:19] end restore2model cost 0.004738330841064453 seconds
DEBUG 01-15 10:09:45.420196.420196 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008550167083740234 seconds
DEBUG 01-15 10:09:45.420898.420898 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.420852.420852 cuda_h.py:19] end gpu_sexperts cost 0.0003535747528076172 seconds
DEBUG 01-15 10:09:45.420927.420927 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.422672.422672 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.002057790756225586 seconds
DEBUG 01-15 10:09:45.423563.423563 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.424569.424569 cuda_h.py:19] end gpu_group_list cost 0.00033664703369140625 seconds
DEBUG 01-15 10:09:45.424282.424282 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.425756.425756 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0010423660278320312 seconds
DEBUG 01-15 10:09:45.425440.425440 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-15 10:09:45.425746.425746 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-15 10:09:45.425826.425826 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.428273.428273 cuda_h.py:19] end group_tensors cost 0.012755870819091797 seconds
DEBUG 01-15 10:09:45.429977.429977 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.433595.433595 cuda_h.py:19] end group pad cost 0.004160642623901367 seconds
DEBUG 01-15 10:09:45.433431.433431 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.453045.453045 cuda_h.py:19] end group_einsum cost 0.020033597946166992 seconds
DEBUG 01-15 10:09:45.453447.453447 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.457847.457847 cuda_h.py:19] end get_outputs_cpu1 cost 0.0035643577575683594 seconds
DEBUG 01-15 10:09:45.458262.458262 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.04396843910217285 seconds
DEBUG 01-15 10:09:45.459175.459175 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.033690452575683594 seconds
DEBUG 01-15 10:09:45.459643.459643 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.459003.459003 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.459479.459479 cuda_h.py:19] end index_scatter cost 0.00012612342834472656 seconds
DEBUG 01-15 10:09:45.460928.460928 cuda_h.py:19] end cpuoutputsdeal cost 0.0007636547088623047 seconds
DEBUG 01-15 10:09:45.460049.460049 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.460773.460773 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0089bec7-5bbc-4404-8e15-ffe833155deb
INFO 01-15 10:09:45.463488.463488 client.py:127] Model loaded
DEBUG 01-15 10:09:45.464205.464205 cuda_h.py:19] end wait_experts cost 0.0038390159606933594 seconds
DEBUG 01-15 10:09:45.464723.464723 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.464348.464348 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.464296.464296 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.464212.464212 cuda_h.py:19] end gpu_group_tensor cost 0.0002224445343017578 seconds
DEBUG 01-15 10:09:45.464938.464938 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.465891.465891 cuda_h.py:19] end gpu_group_einsum cost 0.0007219314575195312 seconds
DEBUG 01-15 10:09:45.465319.465319 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.465984.465984 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.465004.465004 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035119056701660156 seconds
DEBUG 01-15 10:09:45.465190.465190 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.466789.466789 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-15 10:09:45.466156.466156 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.466298.466298 cuda_h.py:19] end index_scatter cost 7.081031799316406e-05 seconds
DEBUG 01-15 10:09:45.466299.466299 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007445812225341797 seconds
DEBUG 01-15 10:09:45.466574.466574 cuda_h.py:19] end gpu_experts cost 0.0022504329681396484 seconds
DEBUG 01-15 10:09:45.466305.466305 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.05788445472717285 seconds
DEBUG 01-15 10:09:45.466073.466073 cuda_h.py:19] end prefill_layer cost 0.06603646278381348 seconds
DEBUG 01-15 10:09:45.467327.467327 lmp.py:1552] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-15 10:09:45.467507.467507 cuda_h.py:10] start prefill_layer
DEBUG 01-15 10:09:45.467163.467163 lmp.py:1495] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-15 10:09:45.467058.467058 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-15 10:09:45.467035.467035 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-15 10:09:45.467046.467046 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-15 10:09:45.471256.471256 cuda_h.py:19] end self_attn cost 0.004242658615112305 seconds
DEBUG 01-15 10:09:45.472209.472209 cuda_h.py:19] end iln_self_attn_paln cost 0.005063533782958984 seconds
DEBUG 01-15 10:09:45.472165.472165 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-15 10:09:45.472690.472690 cuda_h.py:10] start gate
DEBUG 01-15 10:09:45.473247.473247 cuda_h.py:19] end gate cost 0.000797271728515625 seconds
DEBUG 01-15 10:09:45.473938.473938 cuda_h.py:10] start experts_map_get
DEBUG 01-15 10:09:45.473274.473274 lmp.py:1616] 
DEBUG 01-15 10:09:45.473274.473274 lmp.py:1616] Expert Token Distribution & Device Allocation:
DEBUG 01-15 10:09:45.473129.473129 lmp.py:1617]   Total experts: 64
DEBUG 01-15 10:09:45.473495.473495 lmp.py:1618]   CPU experts: 32 (50%)
DEBUG 01-15 10:09:45.473045.473045 lmp.py:1619]   GPU experts: 32 (50%)
DEBUG 01-15 10:09:45.473688.473688 lmp.py:1620] 
DEBUG 01-15 10:09:45.473688.473688 lmp.py:1620]   Expert ID | Tokens | Device
DEBUG 01-15 10:09:45.473331.473331 lmp.py:1621]   -----------------------------------
DEBUG 01-15 10:09:45.473166.473166 lmp.py:1626]   Expert 18 |     65 | CPU
DEBUG 01-15 10:09:45.473286.473286 lmp.py:1626]   Expert 54 |     71 | CPU
DEBUG 01-15 10:09:45.473452.473452 lmp.py:1626]   Expert 47 |     73 | CPU
DEBUG 01-15 10:09:45.473141.473141 lmp.py:1626]   Expert 23 |     79 | CPU
DEBUG 01-15 10:09:45.473069.473069 lmp.py:1626]   Expert 48 |     81 | CPU
DEBUG 01-15 10:09:45.473997.473997 lmp.py:1626]   Expert 44 |     85 | CPU
DEBUG 01-15 10:09:45.473686.473686 lmp.py:1626]   Expert 45 |     86 | CPU
DEBUG 01-15 10:09:45.473137.473137 lmp.py:1626]   Expert 20 |     92 | CPU
DEBUG 01-15 10:09:45.473303.473303 lmp.py:1626]   Expert 31 |     96 | CPU
DEBUG 01-15 10:09:45.473515.473515 lmp.py:1626]   Expert 36 |    104 | CPU
DEBUG 01-15 10:09:45.473966.473966 lmp.py:1626]   Expert 61 |    111 | CPU
DEBUG 01-15 10:09:45.473417.473417 lmp.py:1626]   Expert 33 |    118 | CPU
DEBUG 01-15 10:09:45.473630.473630 lmp.py:1626]   Expert 42 |    118 | CPU
DEBUG 01-15 10:09:45.473080.473080 lmp.py:1626]   Expert 10 |    122 | CPU
DEBUG 01-15 10:09:45.473770.473770 lmp.py:1626]   Expert 24 |    123 | CPU
DEBUG 01-15 10:09:45.473221.473221 lmp.py:1626]   Expert 43 |    123 | CPU
DEBUG 01-15 10:09:45.473579.473579 lmp.py:1626]   Expert 49 |    128 | CPU
DEBUG 01-15 10:09:45.474745.474745 lmp.py:1626]   Expert 11 |    129 | CPU
DEBUG 01-15 10:09:45.474196.474196 lmp.py:1626]   Expert 56 |    131 | CPU
DEBUG 01-15 10:09:45.474647.474647 lmp.py:1626]   Expert  6 |    136 | CPU
DEBUG 01-15 10:09:45.474336.474336 lmp.py:1626]   Expert 51 |    144 | CPU
DEBUG 01-15 10:09:45.474549.474549 lmp.py:1626]   Expert  5 |    147 | CPU
DEBUG 01-15 10:09:45.474999.474999 lmp.py:1626]   Expert 17 |    147 | CPU
DEBUG 01-15 10:09:45.474212.474212 lmp.py:1626]   Expert  0 |    150 | CPU
DEBUG 01-15 10:09:45.474424.474424 lmp.py:1626]   Expert 12 |    159 | CPU
DEBUG 01-15 10:09:45.474352.474352 lmp.py:1626]   Expert 40 |    159 | CPU
DEBUG 01-15 10:09:45.474280.474280 lmp.py:1626]   Expert 55 |    160 | CPU
DEBUG 01-15 10:09:45.474254.474254 lmp.py:1626]   Expert 57 |    160 | CPU
DEBUG 01-15 10:09:45.474228.474228 lmp.py:1626]   Expert 59 |    162 | CPU
DEBUG 01-15 10:09:45.474679.474679 lmp.py:1626]   Expert 26 |    166 | CPU
DEBUG 01-15 10:09:45.474891.474891 lmp.py:1626]   Expert 46 |    166 | CPU
DEBUG 01-15 10:09:45.474580.474580 lmp.py:1626]   Expert 13 |    167 | CPU
DEBUG 01-15 10:09:45.474793.474793 lmp.py:1626]   Expert 38 |    168 | GPU
DEBUG 01-15 10:09:45.474529.474529 lmp.py:1626]   Expert 50 |    172 | GPU
DEBUG 01-15 10:09:45.474741.474741 lmp.py:1626]   Expert 35 |    173 | GPU
DEBUG 01-15 10:09:45.474715.474715 lmp.py:1626]   Expert 30 |    174 | GPU
DEBUG 01-15 10:09:45.474451.474451 lmp.py:1626]   Expert 58 |    174 | GPU
DEBUG 01-15 10:09:45.474186.474186 lmp.py:1626]   Expert  7 |    179 | GPU
DEBUG 01-15 10:09:45.474160.474160 lmp.py:1626]   Expert 16 |    184 | GPU
DEBUG 01-15 10:09:45.474611.474611 lmp.py:1626]   Expert 15 |    202 | GPU
DEBUG 01-15 10:09:45.474062.474062 lmp.py:1626]   Expert 32 |    203 | GPU
DEBUG 01-15 10:09:45.474275.474275 lmp.py:1626]   Expert 14 |    204 | GPU
DEBUG 01-15 10:09:45.474487.474487 lmp.py:1626]   Expert  1 |    214 | GPU
DEBUG 01-15 10:09:45.474461.474461 lmp.py:1626]   Expert  3 |    225 | GPU
DEBUG 01-15 10:09:45.474197.474197 lmp.py:1626]   Expert  4 |    225 | GPU
DEBUG 01-15 10:09:45.474171.474171 lmp.py:1626]   Expert 39 |    237 | GPU
DEBUG 01-15 10:09:45.474622.474622 lmp.py:1626]   Expert 34 |    239 | GPU
DEBUG 01-15 10:09:45.474311.474311 lmp.py:1626]   Expert 28 |    244 | GPU
DEBUG 01-15 10:09:45.474239.474239 lmp.py:1626]   Expert 52 |    244 | GPU
DEBUG 01-15 10:09:45.474451.474451 lmp.py:1626]   Expert 25 |    254 | GPU
DEBUG 01-15 10:09:45.474664.474664 lmp.py:1626]   Expert 22 |    259 | GPU
DEBUG 01-15 10:09:45.474876.474876 lmp.py:1626]   Expert  2 |    272 | GPU
DEBUG 01-15 10:09:45.474327.474327 lmp.py:1626]   Expert 21 |    280 | GPU
DEBUG 01-15 10:09:45.474539.474539 lmp.py:1626]   Expert 41 |    280 | GPU
DEBUG 01-15 10:09:45.474513.474513 lmp.py:1626]   Expert 60 |    286 | GPU
DEBUG 01-15 10:09:45.474488.474488 lmp.py:1626]   Expert 63 |    291 | GPU
DEBUG 01-15 10:09:45.474654.474654 lmp.py:1626]   Expert 29 |    295 | GPU
DEBUG 01-15 10:09:45.474343.474343 lmp.py:1626]   Expert 62 |    295 | GPU
DEBUG 01-15 10:09:45.474079.474079 lmp.py:1626]   Expert 27 |    301 | GPU
DEBUG 01-15 10:09:45.474529.474529 lmp.py:1626]   Expert 37 |    331 | GPU
DEBUG 01-15 10:09:45.474265.474265 lmp.py:1626]   Expert 53 |    333 | GPU
DEBUG 01-15 10:09:45.474478.474478 lmp.py:1626]   Expert  8 |    338 | GPU
DEBUG 01-15 10:09:45.474690.474690 lmp.py:1626]   Expert 19 |    441 | GPU
DEBUG 01-15 10:09:45.474664.474664 lmp.py:1626]   Expert  9 |    613 | GPU
DEBUG 01-15 10:09:45.474830.474830 lmp.py:1627] 
DEBUG 01-15 10:09:45.474830.474830 lmp.py:1627]   CPU total tokens: 3958 (32.2%)
DEBUG 01-15 10:09:45.474996.474996 lmp.py:1628]   GPU total tokens: 8330 (67.8%)
DEBUG 01-15 10:09:45.474692.474692 cuda_h.py:19] end experts_map_get cost 0.0015451908111572266 seconds
DEBUG 01-15 10:09:45.474065.474065 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-15 10:09:45.474153.474153 lmp.py:1636] 
DEBUG 01-15 10:09:45.474153.474153 lmp.py:1636]   Computing 32 experts on CPU MP...
DEBUG 01-15 10:09:45.474949.474949 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-15 10:09:45.474692.474692 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-15 10:09:45.475866.475866 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-15 10:09:45.475455.475455 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-15 10:09:45.475931.475931 cuda_h.py:19] end allocate_cuda_memory cost 0.00034928321838378906 seconds
DEBUG 01-15 10:09:45.475834.475834 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-15 10:09:45.475544.475544 sllm_store_c.py:27] get device uuid map
DEBUG 01-15 10:09:45.475797.475797 sllm_store_c.py:29] call client load into gpu
DEBUG 01-15 10:09:45.475070.475070 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e7711fcd-5bf1-4813-b6b7-87aa9518eb91
DEBUG 01-15 10:09:45.476316.476316 client.py:106] call stub.LoadModelAsync
DEBUG 01-15 10:09:45.476744.476744 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-15 10:09:45.477550.477550 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e7711fcd-5bf1-4813-b6b7-87aa9518eb91
DEBUG 01-15 10:09:45.477735.477735 cuda_h.py:10] start move_flatidxs
DEBUG 01-15 10:09:45.477247.477247 cuda_h.py:19] end load_into_gpu_async cost 0.0016069412231445312 seconds
DEBUG 01-15 10:09:45.477950.477950 cuda_h.py:10] start restore_tensors2
DEBUG 01-15 10:09:45.478352.478352 cuda_h.py:19] end move_flatidxs cost 0.0009512901306152344 seconds
DEBUG 01-15 10:09:45.478764.478764 cuda_h.py:10] start group_tensors
DEBUG 01-15 10:09:45.478522.478522 cuda_h.py:19] end restore_tensors2 cost 0.0013849735260009766 seconds
DEBUG 01-15 10:09:45.479546.479546 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004038810729980469 seconds
DEBUG 01-15 10:09:45.479140.479140 cuda_h.py:10] start restore2model
DEBUG 01-15 10:09:45.484439.484439 cuda_h.py:19] end group_tensors cost 0.006455421447753906 seconds
DEBUG 01-15 10:09:45.485484.485484 cuda_h.py:10] start group pad
DEBUG 01-15 10:09:45.487405.487405 cuda_h.py:19] end restore2model cost 0.007999658584594727 seconds
DEBUG 01-15 10:09:45.487980.487980 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012882709503173828 seconds
DEBUG 01-15 10:09:45.488290.488290 cuda_h.py:10] start gpu_sexperts
DEBUG 01-15 10:09:45.489002.489002 cuda_h.py:19] end gpu_sexperts cost 0.0009844303131103516 seconds
DEBUG 01-15 10:09:45.489914.489914 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-15 10:09:45.489882.489882 cuda_h.py:19] end group pad cost 0.0039196014404296875 seconds
DEBUG 01-15 10:09:45.489056.489056 cuda_h.py:10] start group_einsum
DEBUG 01-15 10:09:45.494931.494931 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.004743337631225586 seconds
DEBUG 01-15 10:09:45.496136.496136 cuda_h.py:10] start gpu_group_list
DEBUG 01-15 10:09:45.497959.497959 cuda_h.py:19] end gpu_group_list cost 0.00077056884765625 seconds
DEBUG 01-15 10:09:45.497504.497504 cuda_h.py:10] start acpu_expert_weight_slices
DEBUG 01-15 10:09:45.499949.499949 cuda_h.py:19] end acpu_expert_weight_slices cost 0.0013494491577148438 seconds
DEBUG 01-15 10:09:45.499998.499998 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-15 10:09:45.508138.508138 cuda_h.py:19] end group_einsum cost 0.018365144729614258 seconds
DEBUG 01-15 10:09:45.508727.508727 cuda_h.py:10] start get_outputs_cpu1
DEBUG 01-15 10:09:45.513116.513116 cuda_h.py:19] end get_outputs_cpu1 cost 0.004639625549316406 seconds
DEBUG 01-15 10:09:45.513613.513613 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.03693389892578125 seconds
DEBUG 01-15 10:09:45.514387.514387 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.015690326690673828 seconds
DEBUG 01-15 10:09:45.515001.515001 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-15 10:09:45.515480.515480 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.515015.515015 cuda_h.py:19] end index_scatter cost 8.916854858398438e-05 seconds
DEBUG 01-15 10:09:45.516134.516134 cuda_h.py:19] end cpuoutputsdeal cost 0.0011777877807617188 seconds
DEBUG 01-15 10:09:45.516163.516163 cuda_h.py:10] start wait_experts
INFO 01-15 10:09:45.516782.516782 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e7711fcd-5bf1-4813-b6b7-87aa9518eb91
INFO 01-15 10:09:45.528664.528664 client.py:127] Model loaded
DEBUG 01-15 10:09:45.528244.528244 cuda_h.py:19] end wait_experts cost 0.011886119842529297 seconds
DEBUG 01-15 10:09:45.528398.528398 cuda_h.py:10] start gpu_experts
DEBUG 01-15 10:09:45.528765.528765 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-15 10:09:45.528012.528012 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-15 10:09:45.528406.528406 cuda_h.py:19] end gpu_group_tensor cost 0.0002529621124267578 seconds
DEBUG 01-15 10:09:45.528489.528489 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-15 10:09:45.529410.529410 cuda_h.py:19] end gpu_group_einsum cost 0.0007278919219970703 seconds
DEBUG 01-15 10:09:45.529586.529586 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-15 10:09:45.529913.529913 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-15 10:09:45.530764.530764 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002760887145996094 seconds
DEBUG 01-15 10:09:45.530527.530527 cuda_h.py:10] start concat_expert_out
DEBUG 01-15 10:09:45.530730.530730 cuda_h.py:19] end concat_expert_out cost 7.581710815429688e-05 seconds
DEBUG 01-15 10:09:45.530547.530547 cuda_h.py:10] start index_scatter
DEBUG 01-15 10:09:45.530465.530465 cuda_h.py:19] end index_scatter cost 7.390975952148438e-05 seconds
DEBUG 01-15 10:09:45.530234.530234 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007112026214599609 seconds
DEBUG 01-15 10:09:45.530310.530310 cuda_h.py:19] end gpu_experts cost 0.002286672592163086 seconds
DEBUG 01-15 10:09:45.530962.530962 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.05838418006896973 seconds
DEBUG 01-15 10:09:45.531411.531411 cuda_h.py:19] end prefill_layer cost 0.06415128707885742 seconds
DEBUG 01-15 10:09:45.531169.531169 lmp.py:1552] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-15 10:09:45.531217.531217 cuda_h.py:19] end prefill cost 1.9252209663391113 seconds
Collecting data...
Generating '/tmp/nsys-report-7280.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [10%                         ] report1.nsys-rep[1/1] [14%                         ] report1.nsys-rep[1/1] [=17%                        ] report1.nsys-rep[1/1] [==20%                       ] report1.nsys-rep[1/1] [===23%                      ] report1.nsys-rep[1/1] [====26%                     ] report1.nsys-rep[1/1] [=====30%                    ] report1.nsys-rep[1/1] [======34%                   ] report1.nsys-rep[1/1] [=======38%                  ] report1.nsys-rep[1/1] [========41%                 ] report1.nsys-rep[1/1] [=========45%                ] report1.nsys-rep[1/1] [==========49%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
