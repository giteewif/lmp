here pin
INFO 01-06 08:44:38.651326.651326 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-06 08:44:39.502717.502717 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-06 08:44:39.944677.944677 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-06 08:44:39.944087.944087 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.293s
DEBUG 01-06 08:44:40.097225.097225 cuda_memory_view.py:260] 
DEBUG 01-06 08:44:40.097225.097225 cuda_memory_view.py:260] restore_tensors_from_shared_memory_names time: 0.01368570327758789
DEBUG 01-06 08:44:41.121233.121233 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.1217038631439209 s
DEBUG 01-06 08:44:41.610517.610517 cuda_h.py:19] end generate_input_ids cost 0.4892423152923584 seconds
DEBUG 01-06 08:44:41.611039.611039 cuda_h.py:10] start init_cache
DEBUG 01-06 08:44:41.611687.611687 cuda_h.py:19] end init_cache cost 0.00010728836059570312 seconds
DEBUG 01-06 08:44:44.223652.223652 cuda_h.py:10] start init_weights
DEBUG 01-06 08:44:44.223070.223070 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:44.223860.223860 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:44.224569.224569 cuda_h.py:19] end allocate_cuda_memory cost 0.0005309581756591797 seconds
DEBUG 01-06 08:44:44.224487.224487 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:44.224343.224343 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:44.224214.224214 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:44.224091.224091 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 73457c9f-8568-442d-b7a1-24af674ea454
DEBUG 01-06 08:44:44.224539.224539 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:44.225018.225018 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 73457c9f-8568-442d-b7a1-24af674ea454
DEBUG 01-06 08:44:44.225365.225365 cuda_h.py:19] end load_into_gpu_async cost 0.0016465187072753906 seconds
DEBUG 01-06 08:44:44.225975.225975 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:44.226966.226966 cuda_h.py:19] end restore_tensors2 cost 0.00010228157043457031 seconds
DEBUG 01-06 08:44:44.226882.226882 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026297569274902344 seconds
INFO 01-06 08:44:44.226453.226453 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 73457c9f-8568-442d-b7a1-24af674ea454
INFO 01-06 08:44:44.302139.302139 client.py:127] Model loaded
DEBUG 01-06 08:44:44.302787.302787 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-06 08:44:44.302886.302886 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:44.303732.303732 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:44.303035.303035 cuda_h.py:19] end allocate_cuda_memory cost 0.0004265308380126953 seconds
DEBUG 01-06 08:44:44.303254.303254 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:44.304351.304351 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:44.304123.304123 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:44.304710.304710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9c649fe4-2fb8-4672-8557-7c7f59012b8e
DEBUG 01-06 08:44:44.304493.304493 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:44.306207.306207 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9c649fe4-2fb8-4672-8557-7c7f59012b8e
DEBUG 01-06 08:44:44.306543.306543 cuda_h.py:19] end load_into_gpu_async cost 0.0021741390228271484 seconds
DEBUG 01-06 08:44:44.306911.306911 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:44.306848.306848 cuda_h.py:19] end restore_tensors2 cost 0.0001819133758544922 seconds
DEBUG 01-06 08:44:44.306567.306567 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036118030548095703 seconds
INFO 01-06 08:44:44.306576.306576 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9c649fe4-2fb8-4672-8557-7c7f59012b8e
INFO 01-06 08:44:44.323790.323790 client.py:127] Model loaded
DEBUG 01-06 08:44:44.324928.324928 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02146768569946289 seconds
DEBUG 01-06 08:44:44.324563.324563 cuda_h.py:19] end init_weights cost 0.1011357307434082 seconds
DEBUG 01-06 08:44:44.324262.324262 cuda_h.py:10] start copy_emodel
DEBUG 01-06 08:44:45.243323.243323 cuda_h.py:19] end copy_emodel cost 0.9187991619110107 seconds
DEBUG 01-06 08:44:45.244254.244254 cuda_h.py:10] start init_hmv
DEBUG 01-06 08:44:45.411298.411298 mlpmodule.py:206] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-06 08:44:45.412058.412058 cuda_h.py:19] end init_hmv cost 0.16831469535827637 seconds
DEBUG 01-06 08:44:45.412066.412066 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 08:44:45.489687.489687 cuda_h.py:19] end init_inputs_tokens cost 0.07622861862182617 seconds
DEBUG 01-06 08:44:45.489804.489804 cuda_h.py:10] start multi_layer
DEBUG 01-06 08:44:45.489448.489448 lmp.py:177] -------------------------------- start layer 0 --------------------------------
DEBUG 01-06 08:44:45.489959.489959 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:44:45.489284.489284 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:44:45.489307.489307 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 5.14984130859375e-05 seconds
DEBUG 01-06 08:44:45.489097.489097 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 0.00011277198791503906 seconds
DEBUG 01-06 08:44:45.489701.489701 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:45.489064.489064 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:45.489706.489706 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:45.489386.489386 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:45.490925.490925 cuda_h.py:19] end allocate_cuda_memory cost 0.0003681182861328125 seconds
DEBUG 01-06 08:44:45.490871.490871 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:45.490139.490139 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:45.490812.490812 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:45.490391.490391 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e0d01eb-e65f-4b33-bb17-98673d1ace42
DEBUG 01-06 08:44:45.491007.491007 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:45.492859.492859 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e0d01eb-e65f-4b33-bb17-98673d1ace42
DEBUG 01-06 08:44:45.492472.492472 cuda_h.py:19] end load_into_gpu_async cost 0.0020329952239990234 seconds
DEBUG 01-06 08:44:45.492097.492097 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:45.493543.493543 cuda_h.py:19] end restore_tensors2 cost 0.000179290771484375 seconds
DEBUG 01-06 08:44:45.493818.493818 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00324249267578125 seconds
INFO 01-06 08:44:45.494007.494007 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e0d01eb-e65f-4b33-bb17-98673d1ace42
INFO 01-06 08:44:45.499356.499356 client.py:127] Model loaded
DEBUG 01-06 08:44:45.499102.499102 cuda_h.py:19] end sllm_worker_task cost 0.010068178176879883 seconds
DEBUG 01-06 08:44:45.579615.579615 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:45.824810.824810 cuda_h.py:19] end self_attn cost 0.24477100372314453 seconds
DEBUG 01-06 08:44:45.825775.825775 cuda_h.py:19] end iln_self_attn_paln cost 0.33565282821655273 seconds
DEBUG 01-06 08:44:45.825493.825493 cuda_h.py:10] start dense_mlp
DEBUG 01-06 08:44:45.825508.825508 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:44:45.825119.825119 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.337860107421875e-05 seconds
DEBUG 01-06 08:44:45.825283.825283 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:45.825197.825197 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:45.825433.825433 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:45.826897.826897 cuda_h.py:19] end allocate_cuda_memory cost 0.0004279613494873047 seconds
DEBUG 01-06 08:44:45.826107.826107 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:45.826706.826706 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:45.826948.826948 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:45.826573.826573 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88b36ee3-4118-4f4a-8f96-a0dca87be6d0
DEBUG 01-06 08:44:45.827136.827136 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:45.829374.829374 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88b36ee3-4118-4f4a-8f96-a0dca87be6d0
DEBUG 01-06 08:44:45.829889.829889 cuda_h.py:19] end load_into_gpu_async cost 0.002481698989868164 seconds
DEBUG 01-06 08:44:45.829845.829845 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:45.829375.829375 cuda_h.py:19] end restore_tensors2 cost 0.00013971328735351562 seconds
DEBUG 01-06 08:44:45.829497.829497 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037393569946289062 seconds
INFO 01-06 08:44:45.830516.830516 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88b36ee3-4118-4f4a-8f96-a0dca87be6d0
DEBUG 01-06 08:44:45.832157.832157 cuda_h.py:19] end dense_mlp cost 0.0069408416748046875 seconds
DEBUG 01-06 08:44:45.832161.832161 lmp.py:221] -------------------------------- end layer 0 --------------------------------
DEBUG 01-06 08:44:45.832937.832937 lmp.py:177] -------------------------------- start layer 1 --------------------------------
DEBUG 01-06 08:44:45.832733.832733 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 08:44:45.832873.832873 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 08:44:45.832948.832948 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.1457672119140625e-05 seconds
DEBUG 01-06 08:44:45.832558.832558 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.340576171875e-05 seconds
DEBUG 01-06 08:44:45.832254.832254 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:45.832807.832807 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:45.836734.836734 cuda_h.py:19] end self_attn cost 0.003889322280883789 seconds
DEBUG 01-06 08:44:45.837368.837368 cuda_h.py:19] end iln_self_attn_paln cost 0.004544973373413086 seconds
DEBUG 01-06 08:44:45.837807.837807 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-06 08:44:45.837961.837961 cuda_h.py:10] start gate
INFO 01-06 08:44:45.837546.837546 client.py:127] Model loaded
DEBUG 01-06 08:44:45.837736.837736 cuda_h.py:19] end sllm_worker_task cost 0.011954545974731445 seconds
DEBUG 01-06 08:44:45.837064.837064 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:45.837040.837040 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:45.837044.837044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:45.838005.838005 cuda_h.py:19] end allocate_cuda_memory cost 0.0003364086151123047 seconds
DEBUG 01-06 08:44:45.838103.838103 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:45.838695.838695 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:45.838685.838685 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:45.838164.838164 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f42247b1-ca31-4179-af26-92103d2d0700
DEBUG 01-06 08:44:45.838832.838832 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:45.840439.840439 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f42247b1-ca31-4179-af26-92103d2d0700
DEBUG 01-06 08:44:45.840463.840463 cuda_h.py:19] end load_into_gpu_async cost 0.001965761184692383 seconds
DEBUG 01-06 08:44:45.840796.840796 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:45.840598.840598 cuda_h.py:19] end restore_tensors2 cost 0.00013017654418945312 seconds
DEBUG 01-06 08:44:45.840667.840667 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003021240234375 seconds
INFO 01-06 08:44:45.841183.841183 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f42247b1-ca31-4179-af26-92103d2d0700
INFO 01-06 08:44:45.848622.848622 client.py:127] Model loaded
DEBUG 01-06 08:44:45.848260.848260 cuda_h.py:19] end sllm_worker_task cost 0.01073765754699707 seconds
DEBUG 01-06 08:44:45.932448.932448 cuda_h.py:19] end gate cost 0.09537053108215332 seconds
DEBUG 01-06 08:44:45.932439.932439 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:45.933094.933094 lmp.py:369] 
DEBUG 01-06 08:44:45.933094.933094 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:45.933055.933055 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:45.933997.933997 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:45.933931.933931 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:45.933482.933482 lmp.py:373] 
DEBUG 01-06 08:44:45.933482.933482 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:45.933462.933462 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:45.933880.933880 lmp.py:380]   Expert 22 |     35 | CPU
DEBUG 01-06 08:44:45.933100.933100 lmp.py:380]   Expert 62 |     44 | CPU
DEBUG 01-06 08:44:45.933888.933888 lmp.py:380]   Expert  3 |     53 | CPU
DEBUG 01-06 08:44:45.933962.933962 lmp.py:380]   Expert 48 |     56 | CPU
DEBUG 01-06 08:44:45.933559.933559 lmp.py:380]   Expert 18 |     62 | CPU
DEBUG 01-06 08:44:45.933632.933632 lmp.py:380]   Expert 39 |     78 | CPU
DEBUG 01-06 08:44:45.933229.933229 lmp.py:380]   Expert 13 |     82 | CPU
DEBUG 01-06 08:44:45.933302.933302 lmp.py:380]   Expert 47 |     83 | CPU
DEBUG 01-06 08:44:45.933137.933137 lmp.py:380]   Expert 53 |     88 | CPU
DEBUG 01-06 08:44:45.933972.933972 lmp.py:380]   Expert 51 |     91 | CPU
DEBUG 01-06 08:44:45.933569.933569 lmp.py:380]   Expert 32 |     93 | CPU
DEBUG 01-06 08:44:45.933119.933119 lmp.py:380]   Expert 54 |     94 | CPU
DEBUG 01-06 08:44:45.933054.933054 lmp.py:380]   Expert 36 |    101 | CPU
DEBUG 01-06 08:44:45.933319.933319 lmp.py:380]   Expert 58 |    101 | CPU
DEBUG 01-06 08:44:45.933154.933154 lmp.py:380]   Expert 38 |    105 | CPU
DEBUG 01-06 08:44:45.933751.933751 lmp.py:380]   Expert 37 |    114 | CPU
DEBUG 01-06 08:44:45.933109.933109 lmp.py:380]   Expert 25 |    115 | CPU
DEBUG 01-06 08:44:45.933468.933468 lmp.py:380]   Expert 27 |    118 | CPU
DEBUG 01-06 08:44:45.933826.933826 lmp.py:380]   Expert 21 |    121 | CPU
DEBUG 01-06 08:44:45.933422.933422 lmp.py:380]   Expert 31 |    121 | CPU
DEBUG 01-06 08:44:45.933542.933542 lmp.py:380]   Expert 41 |    121 | CPU
DEBUG 01-06 08:44:45.933901.933901 lmp.py:380]   Expert 30 |    124 | CPU
DEBUG 01-06 08:44:45.933497.933497 lmp.py:380]   Expert 55 |    126 | CPU
DEBUG 01-06 08:44:45.933048.933048 lmp.py:380]   Expert 59 |    127 | CPU
DEBUG 01-06 08:44:45.934075.934075 lmp.py:380]   Expert 28 |    132 | CPU
DEBUG 01-06 08:44:45.934102.934102 lmp.py:380]   Expert 49 |    142 | CPU
DEBUG 01-06 08:44:45.934698.934698 lmp.py:380]   Expert 29 |    154 | CPU
DEBUG 01-06 08:44:45.934057.934057 lmp.py:380]   Expert 12 |    156 | CPU
DEBUG 01-06 08:44:45.934653.934653 lmp.py:380]   Expert 50 |    169 | CPU
DEBUG 01-06 08:44:45.934773.934773 lmp.py:380]   Expert 11 |    173 | CPU
DEBUG 01-06 08:44:45.934131.934131 lmp.py:380]   Expert 56 |    173 | CPU
DEBUG 01-06 08:44:45.934490.934490 lmp.py:380]   Expert 24 |    176 | CPU
DEBUG 01-06 08:44:45.934609.934609 lmp.py:380]   Expert 35 |    179 | GPU
DEBUG 01-06 08:44:45.934935.934935 lmp.py:380]   Expert 60 |    179 | GPU
DEBUG 01-06 08:44:45.934293.934293 lmp.py:380]   Expert 63 |    182 | GPU
DEBUG 01-06 08:44:45.934843.934843 lmp.py:380]   Expert 15 |    189 | GPU
DEBUG 01-06 08:44:45.934725.934725 lmp.py:380]   Expert 61 |    191 | GPU
DEBUG 01-06 08:44:45.934083.934083 lmp.py:380]   Expert 19 |    192 | GPU
DEBUG 01-06 08:44:45.934157.934157 lmp.py:380]   Expert 33 |    194 | GPU
DEBUG 01-06 08:44:45.934276.934276 lmp.py:380]   Expert 23 |    212 | GPU
DEBUG 01-06 08:44:45.934919.934919 lmp.py:380]   Expert 17 |    214 | GPU
DEBUG 01-06 08:44:45.934278.934278 lmp.py:380]   Expert  2 |    222 | GPU
DEBUG 01-06 08:44:45.934921.934921 lmp.py:380]   Expert 52 |    222 | GPU
DEBUG 01-06 08:44:45.934802.934802 lmp.py:380]   Expert  0 |    231 | GPU
DEBUG 01-06 08:44:45.934683.934683 lmp.py:380]   Expert 43 |    231 | GPU
DEBUG 01-06 08:44:45.934565.934565 lmp.py:380]   Expert  1 |    237 | GPU
DEBUG 01-06 08:44:45.934446.934446 lmp.py:380]   Expert 40 |    237 | GPU
DEBUG 01-06 08:44:45.934566.934566 lmp.py:380]   Expert  9 |    250 | GPU
DEBUG 01-06 08:44:45.934686.934686 lmp.py:380]   Expert 44 |    254 | GPU
DEBUG 01-06 08:44:45.934329.934329 lmp.py:380]   Expert 45 |    278 | GPU
DEBUG 01-06 08:44:45.934210.934210 lmp.py:380]   Expert  6 |    287 | GPU
DEBUG 01-06 08:44:45.934092.934092 lmp.py:380]   Expert 14 |    303 | GPU
DEBUG 01-06 08:44:45.934211.934211 lmp.py:380]   Expert  4 |    314 | GPU
DEBUG 01-06 08:44:45.934523.934523 lmp.py:380]   Expert 16 |    314 | GPU
DEBUG 01-06 08:44:45.934074.934074 lmp.py:380]   Expert 26 |    316 | GPU
DEBUG 01-06 08:44:45.934909.934909 lmp.py:380]   Expert  8 |    317 | GPU
DEBUG 01-06 08:44:45.934790.934790 lmp.py:380]   Expert 34 |    327 | GPU
DEBUG 01-06 08:44:45.934671.934671 lmp.py:380]   Expert  7 |    340 | GPU
DEBUG 01-06 08:44:45.934076.934076 lmp.py:380]   Expert  5 |    347 | GPU
DEBUG 01-06 08:44:45.934196.934196 lmp.py:380]   Expert 10 |    357 | GPU
DEBUG 01-06 08:44:45.934839.934839 lmp.py:380]   Expert 46 |    389 | GPU
DEBUG 01-06 08:44:45.934720.934720 lmp.py:380]   Expert 42 |    410 | GPU
DEBUG 01-06 08:44:45.934363.934363 lmp.py:380]   Expert 20 |    422 | GPU
DEBUG 01-06 08:44:45.934245.934245 lmp.py:380]   Expert 57 |    423 | GPU
DEBUG 01-06 08:44:45.934318.934318 lmp.py:381] 
DEBUG 01-06 08:44:45.934318.934318 lmp.py:381]   CPU total tokens: 3528 (28.7%)
DEBUG 01-06 08:44:45.934153.934153 lmp.py:382]   GPU total tokens: 8760 (71.3%)
DEBUG 01-06 08:44:45.934955.934955 cuda_h.py:19] end experts_map_get cost 0.0019278526306152344 seconds
DEBUG 01-06 08:44:45.934936.934936 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:45.934435.934435 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:45.936306.936306 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:45.937161.937161 cuda_h.py:19] end allocate_cuda_memory cost 0.0003402233123779297 seconds
DEBUG 01-06 08:44:45.937660.937660 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:45.937377.937377 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:45.937869.937869 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:45.937287.937287 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c4e64000-d55a-49e1-85a7-37e7b0bf9799
DEBUG 01-06 08:44:45.937724.937724 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:45.940978.940978 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c4e64000-d55a-49e1-85a7-37e7b0bf9799
DEBUG 01-06 08:44:45.940874.940874 cuda_h.py:19] end load_into_gpu_async cost 0.0025773048400878906 seconds
DEBUG 01-06 08:44:45.940577.940577 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:45.940158.940158 cuda_h.py:19] end restore_tensors2 cost 0.0003314018249511719 seconds
DEBUG 01-06 08:44:45.940935.940935 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005608081817626953 seconds
DEBUG 01-06 08:44:45.943624.943624 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008833646774291992 seconds
DEBUG 01-06 08:44:45.943844.943844 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:45.943989.943989 lmp.py:427] 
DEBUG 01-06 08:44:45.943989.943989 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:45.943429.943429 cuda_h.py:19] end cpu_experts_submit cost 0.00022339820861816406 seconds
DEBUG 01-06 08:44:45.944562.944562 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:45.960314.960314 mlpmodule.py:704] group tensors cost 0.01672816276550293 s
DEBUG 01-06 08:44:45.963613.963613 mlpmodule.py:742] pad cost 0.00188446044921875 s
DEBUG 01-06 08:44:45.963253.963253 mlpmodule.py:748] create cpu tensor cost 6.270408630371094e-05 s
DEBUG 01-06 08:44:45.963435.963435 mlpmodule.py:753] move to cpu cost 5.1975250244140625e-05 s
DEBUG 01-06 08:44:46.001223.001223 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.001411.001411 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.010296.010296 mlpmodule.py:773] group_w3 first element: 0.01348876953125
WARNING 01-06 08:44:46.011320.011320 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.034734.034734 mlpmodule.py:793] group einsum cost 0.07074952125549316 s
DEBUG 01-06 08:44:46.035989.035989 mlpmodule.py:801] cpy2cputensor cost 0.0006766319274902344 s
DEBUG 01-06 08:44:46.045449.045449 cuda_h.py:19] end wait_cetm_experts cost 0.10117650032043457 seconds
DEBUG 01-06 08:44:46.045250.045250 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.046019.046019 cuda_h.py:19] end gpu_sexperts cost 0.000579833984375 seconds
DEBUG 01-06 08:44:46.046188.046188 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.046058.046058 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-06 08:44:46.046013.046013 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.046067.046067 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c4e64000-d55a-49e1-85a7-37e7b0bf9799
INFO 01-06 08:44:46.047396.047396 client.py:127] Model loaded
DEBUG 01-06 08:44:46.047505.047505 cuda_h.py:19] end wait_experts cost 0.0012006759643554688 seconds
DEBUG 01-06 08:44:46.047453.047453 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.047639.047639 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.054488.054488 mlpmodule.py:662]  experts func einsum cost 0.11001372337341309 s
DEBUG 01-06 08:44:46.061880.061880 cuda_h.py:19] end gpu_experts cost 0.013899087905883789 seconds
DEBUG 01-06 08:44:46.061295.061295 cuda_h.py:19] end layer_moe_generate_1 cost 0.22437167167663574 seconds
DEBUG 01-06 08:44:46.061751.061751 lmp.py:221] -------------------------------- end layer 1 --------------------------------
DEBUG 01-06 08:44:46.061043.061043 lmp.py:177] -------------------------------- start layer 2 --------------------------------
DEBUG 01-06 08:44:46.061362.061362 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 08:44:46.061025.061025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 08:44:46.061299.061299 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.1948089599609375e-05 seconds
DEBUG 01-06 08:44:46.061122.061122 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 8.130073547363281e-05 seconds
DEBUG 01-06 08:44:46.062533.062533 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.062422.062422 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.062478.062478 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.062130.062130 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.062696.062696 cuda_h.py:19] end allocate_cuda_memory cost 0.00023674964904785156 seconds
DEBUG 01-06 08:44:46.062691.062691 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.062500.062500 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.062277.062277 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.062602.062602 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7a891dd-3477-46b9-b218-43d04c96adaf
DEBUG 01-06 08:44:46.062387.062387 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.063092.063092 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.063366.063366 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7a891dd-3477-46b9-b218-43d04c96adaf
DEBUG 01-06 08:44:46.064600.064600 cuda_h.py:19] end load_into_gpu_async cost 0.0014073848724365234 seconds
DEBUG 01-06 08:44:46.064833.064833 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.064340.064340 cuda_h.py:19] end restore_tensors2 cost 6.365776062011719e-05 seconds
DEBUG 01-06 08:44:46.064096.064096 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001963376998901367 seconds
INFO 01-06 08:44:46.064596.064596 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7a891dd-3477-46b9-b218-43d04c96adaf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.067169.067169 cuda_h.py:19] end self_attn cost 0.004405021667480469 seconds
DEBUG 01-06 08:44:46.067466.067466 cuda_h.py:19] end iln_self_attn_paln cost 0.005881071090698242 seconds
DEBUG 01-06 08:44:46.068184.068184 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-06 08:44:46.068060.068060 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.068086.068086 cuda_h.py:19] end gate cost 0.0007445812225341797 seconds
DEBUG 01-06 08:44:46.068691.068691 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.069167.069167 lmp.py:369] 
DEBUG 01-06 08:44:46.069167.069167 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.069288.069288 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.069713.069713 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.069655.069655 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.069927.069927 lmp.py:373] 
DEBUG 01-06 08:44:46.069927.069927 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.069299.069299 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.069201.069201 lmp.py:380]   Expert  0 |     19 | CPU
DEBUG 01-06 08:44:46.069950.069950 lmp.py:380]   Expert 36 |     23 | CPU
DEBUG 01-06 08:44:46.069792.069792 lmp.py:380]   Expert 10 |     24 | CPU
DEBUG 01-06 08:44:46.069680.069680 lmp.py:380]   Expert 58 |     27 | CPU
DEBUG 01-06 08:44:46.069806.069806 lmp.py:380]   Expert 26 |     33 | CPU
DEBUG 01-06 08:44:46.069171.069171 lmp.py:380]   Expert 34 |     34 | CPU
DEBUG 01-06 08:44:46.069060.069060 lmp.py:380]   Expert 29 |     44 | CPU
DEBUG 01-06 08:44:46.069425.069425 lmp.py:380]   Expert  6 |     51 | CPU
DEBUG 01-06 08:44:46.069551.069551 lmp.py:380]   Expert  3 |     52 | CPU
DEBUG 01-06 08:44:46.069678.069678 lmp.py:380]   Expert  8 |     52 | CPU
DEBUG 01-06 08:44:46.069043.069043 lmp.py:380]   Expert  9 |     52 | CPU
DEBUG 01-06 08:44:46.069123.069123 lmp.py:380]   Expert 27 |     52 | CPU
DEBUG 01-06 08:44:46.069680.069680 lmp.py:380]   Expert 24 |     56 | CPU
DEBUG 01-06 08:44:46.069999.069999 lmp.py:380]   Expert 25 |     66 | CPU
DEBUG 01-06 08:44:46.069602.069602 lmp.py:380]   Expert 21 |     71 | CPU
DEBUG 01-06 08:44:46.069491.069491 lmp.py:380]   Expert  7 |     77 | CPU
DEBUG 01-06 08:44:46.069379.069379 lmp.py:380]   Expert 13 |     90 | CPU
DEBUG 01-06 08:44:46.069505.069505 lmp.py:380]   Expert 28 |     93 | CPU
DEBUG 01-06 08:44:46.069917.069917 lmp.py:380]   Expert 17 |     94 | CPU
DEBUG 01-06 08:44:46.069805.069805 lmp.py:380]   Expert 30 |     99 | CPU
DEBUG 01-06 08:44:46.069885.069885 lmp.py:380]   Expert 60 |    108 | CPU
DEBUG 01-06 08:44:46.069489.069489 lmp.py:380]   Expert 44 |    111 | CPU
DEBUG 01-06 08:44:46.070046.070046 lmp.py:380]   Expert 59 |    113 | CPU
DEBUG 01-06 08:44:46.070172.070172 lmp.py:380]   Expert  1 |    115 | CPU
DEBUG 01-06 08:44:46.070061.070061 lmp.py:380]   Expert 19 |    116 | CPU
DEBUG 01-06 08:44:46.070710.070710 lmp.py:380]   Expert 52 |    117 | CPU
DEBUG 01-06 08:44:46.070837.070837 lmp.py:380]   Expert 40 |    123 | CPU
DEBUG 01-06 08:44:46.070248.070248 lmp.py:380]   Expert 62 |    123 | CPU
DEBUG 01-06 08:44:46.070329.070329 lmp.py:380]   Expert 33 |    125 | CPU
DEBUG 01-06 08:44:46.070647.070647 lmp.py:380]   Expert 54 |    125 | CPU
DEBUG 01-06 08:44:46.070728.070728 lmp.py:380]   Expert 35 |    127 | CPU
DEBUG 01-06 08:44:46.070854.070854 lmp.py:380]   Expert  4 |    146 | CPU
DEBUG 01-06 08:44:46.070981.070981 lmp.py:380]   Expert 49 |    151 | GPU
DEBUG 01-06 08:44:46.070630.070630 lmp.py:380]   Expert 63 |    151 | GPU
DEBUG 01-06 08:44:46.070519.070519 lmp.py:380]   Expert  5 |    155 | GPU
DEBUG 01-06 08:44:46.070361.070361 lmp.py:380]   Expert 38 |    162 | GPU
DEBUG 01-06 08:44:46.070964.070964 lmp.py:380]   Expert 37 |    171 | GPU
DEBUG 01-06 08:44:46.070044.070044 lmp.py:380]   Expert 57 |    176 | GPU
DEBUG 01-06 08:44:46.070409.070409 lmp.py:380]   Expert 16 |    182 | GPU
DEBUG 01-06 08:44:46.070490.070490 lmp.py:380]   Expert 50 |    193 | GPU
DEBUG 01-06 08:44:46.070570.070570 lmp.py:380]   Expert 45 |    198 | GPU
DEBUG 01-06 08:44:46.070412.070412 lmp.py:380]   Expert 56 |    208 | GPU
DEBUG 01-06 08:44:46.070214.070214 lmp.py:380]   Expert 47 |    216 | GPU
DEBUG 01-06 08:44:46.070248.070248 lmp.py:380]   Expert  2 |    227 | GPU
DEBUG 01-06 08:44:46.070851.070851 lmp.py:380]   Expert 31 |    228 | GPU
DEBUG 01-06 08:44:46.070216.070216 lmp.py:380]   Expert 22 |    250 | GPU
DEBUG 01-06 08:44:46.070105.070105 lmp.py:380]   Expert 51 |    251 | GPU
DEBUG 01-06 08:44:46.070993.070993 lmp.py:380]   Expert 55 |    252 | GPU
DEBUG 01-06 08:44:46.070119.070119 lmp.py:380]   Expert 23 |    253 | GPU
DEBUG 01-06 08:44:46.070531.070531 lmp.py:380]   Expert 32 |    256 | GPU
DEBUG 01-06 08:44:46.070373.070373 lmp.py:380]   Expert 46 |    256 | GPU
DEBUG 01-06 08:44:46.070214.070214 lmp.py:380]   Expert 39 |    274 | GPU
DEBUG 01-06 08:44:46.070056.070056 lmp.py:380]   Expert 14 |    279 | GPU
DEBUG 01-06 08:44:46.070183.070183 lmp.py:380]   Expert 12 |    289 | GPU
DEBUG 01-06 08:44:46.070833.070833 lmp.py:380]   Expert 43 |    302 | GPU
DEBUG 01-06 08:44:46.070482.070482 lmp.py:380]   Expert 53 |    313 | GPU
DEBUG 01-06 08:44:46.070371.070371 lmp.py:380]   Expert 20 |    314 | GPU
DEBUG 01-06 08:44:46.070259.070259 lmp.py:380]   Expert 42 |    343 | GPU
DEBUG 01-06 08:44:46.070147.070147 lmp.py:380]   Expert 15 |    389 | GPU
DEBUG 01-06 08:44:46.070989.070989 lmp.py:380]   Expert 41 |    391 | GPU
DEBUG 01-06 08:44:46.070831.070831 lmp.py:380]   Expert 18 |    430 | GPU
DEBUG 01-06 08:44:46.070388.070388 lmp.py:380]   Expert 48 |    490 | GPU
DEBUG 01-06 08:44:46.070707.070707 lmp.py:380]   Expert 11 |    524 | GPU
DEBUG 01-06 08:44:46.070787.070787 lmp.py:380]   Expert 61 |   1456 | GPU
DEBUG 01-06 08:44:46.071059.071059 lmp.py:381] 
DEBUG 01-06 08:44:46.071059.071059 lmp.py:381]   CPU total tokens: 2558 (20.8%)
DEBUG 01-06 08:44:46.071047.071047 lmp.py:382]   GPU total tokens: 9730 (79.2%)
DEBUG 01-06 08:44:46.071041.071041 cuda_h.py:19] end experts_map_get cost 0.0021152496337890625 seconds
DEBUG 01-06 08:44:46.071506.071506 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.071971.071971 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.071599.071599 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.071561.071561 cuda_h.py:19] end allocate_cuda_memory cost 0.0002079010009765625 seconds
INFO 01-06 08:44:46.071842.071842 client.py:127] Model loaded
DEBUG 01-06 08:44:46.071349.071349 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.071583.071583 cuda_h.py:19] end sllm_worker_task cost 0.009663820266723633 seconds
DEBUG 01-06 08:44:46.071021.071021 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.071740.071740 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.071073.071073 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4419b71f-2ea8-4e21-9a30-8390f52d7f47
DEBUG 01-06 08:44:46.072411.072411 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.073658.073658 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4419b71f-2ea8-4e21-9a30-8390f52d7f47
DEBUG 01-06 08:44:46.073561.073561 cuda_h.py:19] end load_into_gpu_async cost 0.0014815330505371094 seconds
DEBUG 01-06 08:44:46.073178.073178 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.073151.073151 cuda_h.py:19] end restore_tensors2 cost 0.00033211708068847656 seconds
DEBUG 01-06 08:44:46.073126.073126 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002609729766845703 seconds
DEBUG 01-06 08:44:46.076416.076416 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005585432052612305 seconds
DEBUG 01-06 08:44:46.076067.076067 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.076983.076983 lmp.py:427] 
DEBUG 01-06 08:44:46.076983.076983 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.076157.076157 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-06 08:44:46.076907.076907 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.091679.091679 mlpmodule.py:704] group tensors cost 0.014772891998291016 s
DEBUG 01-06 08:44:46.095169.095169 mlpmodule.py:742] pad cost 0.0026221275329589844 s
DEBUG 01-06 08:44:46.095597.095597 mlpmodule.py:748] create cpu tensor cost 7.081031799316406e-05 s
DEBUG 01-06 08:44:46.095666.095666 mlpmodule.py:753] move to cpu cost 3.933906555175781e-05 s
DEBUG 01-06 08:44:46.106478.106478 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.106038.106038 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.106321.106321 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-06 08:44:46.107339.107339 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.125972.125972 mlpmodule.py:793] group einsum cost 0.03040003776550293 s
DEBUG 01-06 08:44:46.126606.126606 mlpmodule.py:801] cpy2cputensor cost 0.0006952285766601562 s
DEBUG 01-06 08:44:46.133072.133072 cuda_h.py:19] end wait_cetm_experts cost 0.05611753463745117 seconds
DEBUG 01-06 08:44:46.133578.133578 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.133984.133984 cuda_h.py:19] end gpu_sexperts cost 0.0005896091461181641 seconds
DEBUG 01-06 08:44:46.133901.133901 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.134884.134884 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.719329833984375e-05 seconds
DEBUG 01-06 08:44:46.134693.134693 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.134986.134986 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4419b71f-2ea8-4e21-9a30-8390f52d7f47
INFO 01-06 08:44:46.135252.135252 client.py:127] Model loaded
DEBUG 01-06 08:44:46.135466.135466 cuda_h.py:19] end wait_experts cost 0.0012974739074707031 seconds
DEBUG 01-06 08:44:46.135329.135329 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.135429.135429 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.145941.145941 mlpmodule.py:662]  experts func einsum cost 0.06888651847839355 s
DEBUG 01-06 08:44:46.153828.153828 cuda_h.py:19] end gpu_experts cost 0.01801896095275879 seconds
DEBUG 01-06 08:44:46.153706.153706 cuda_h.py:19] end layer_moe_generate_2 cost 0.08555817604064941 seconds
DEBUG 01-06 08:44:46.153937.153937 lmp.py:221] -------------------------------- end layer 2 --------------------------------
DEBUG 01-06 08:44:46.153176.153176 lmp.py:177] -------------------------------- start layer 3 --------------------------------
DEBUG 01-06 08:44:46.153065.153065 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 08:44:46.153973.153973 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 08:44:46.153862.153862 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:44:46.153016.153016 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.796287536621094e-05 seconds
DEBUG 01-06 08:44:46.154759.154759 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.154119.154119 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.154593.154593 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.154860.154860 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.154351.154351 cuda_h.py:19] end allocate_cuda_memory cost 0.000186920166015625 seconds
DEBUG 01-06 08:44:46.154982.154982 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.154984.154984 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.154661.154661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.154410.154410 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 154263da-747b-4101-8d50-8aed81030219
DEBUG 01-06 08:44:46.154048.154048 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.154256.154256 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.155498.155498 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 154263da-747b-4101-8d50-8aed81030219
DEBUG 01-06 08:44:46.155380.155380 cuda_h.py:19] end load_into_gpu_async cost 0.0011696815490722656 seconds
DEBUG 01-06 08:44:46.156516.156516 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.156928.156928 cuda_h.py:19] end restore_tensors2 cost 0.0002167224884033203 seconds
DEBUG 01-06 08:44:46.156132.156132 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025930404663085938 seconds
INFO 01-06 08:44:46.158788.158788 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 154263da-747b-4101-8d50-8aed81030219
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.161453.161453 cuda_h.py:19] end self_attn cost 0.006190776824951172 seconds
DEBUG 01-06 08:44:46.161434.161434 cuda_h.py:19] end iln_self_attn_paln cost 0.00765681266784668 seconds
DEBUG 01-06 08:44:46.161336.161336 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-06 08:44:46.161344.161344 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.162356.162356 cuda_h.py:19] end gate cost 0.0007073879241943359 seconds
DEBUG 01-06 08:44:46.162676.162676 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.163288.163288 lmp.py:369] 
DEBUG 01-06 08:44:46.163288.163288 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.163243.163243 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.163384.163384 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.163894.163894 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.163021.163021 lmp.py:373] 
DEBUG 01-06 08:44:46.163021.163021 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.163624.163624 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.163711.163711 lmp.py:380]   Expert 37 |     23 | CPU
DEBUG 01-06 08:44:46.163838.163838 lmp.py:380]   Expert 44 |     25 | CPU
DEBUG 01-06 08:44:46.163726.163726 lmp.py:380]   Expert 15 |     30 | CPU
DEBUG 01-06 08:44:46.163330.163330 lmp.py:380]   Expert 59 |     31 | CPU
DEBUG 01-06 08:44:46.163218.163218 lmp.py:380]   Expert  5 |     35 | CPU
DEBUG 01-06 08:44:46.163868.163868 lmp.py:380]   Expert 16 |     45 | CPU
DEBUG 01-06 08:44:46.163279.163279 lmp.py:380]   Expert 18 |     48 | CPU
DEBUG 01-06 08:44:46.163452.163452 lmp.py:380]   Expert  4 |     63 | CPU
DEBUG 01-06 08:44:46.163148.163148 lmp.py:380]   Expert 32 |     65 | CPU
DEBUG 01-06 08:44:46.163275.163275 lmp.py:380]   Expert  7 |     75 | CPU
DEBUG 01-06 08:44:46.163832.163832 lmp.py:380]   Expert  1 |     79 | CPU
DEBUG 01-06 08:44:46.163720.163720 lmp.py:380]   Expert 61 |     82 | CPU
DEBUG 01-06 08:44:46.163654.163654 lmp.py:380]   Expert 35 |     87 | CPU
DEBUG 01-06 08:44:46.163589.163589 lmp.py:380]   Expert 48 |     89 | CPU
DEBUG 01-06 08:44:46.163285.163285 lmp.py:380]   Expert 24 |     92 | CPU
DEBUG 01-06 08:44:46.163696.163696 lmp.py:380]   Expert 40 |     98 | CPU
DEBUG 01-06 08:44:46.163392.163392 lmp.py:380]   Expert 49 |    109 | CPU
DEBUG 01-06 08:44:46.163327.163327 lmp.py:380]   Expert 57 |    114 | CPU
DEBUG 01-06 08:44:46.163261.163261 lmp.py:380]   Expert 63 |    115 | CPU
DEBUG 01-06 08:44:46.163196.163196 lmp.py:380]   Expert 29 |    116 | CPU
DEBUG 01-06 08:44:46.163607.163607 lmp.py:380]   Expert 30 |    130 | CPU
DEBUG 01-06 08:44:46.163224.163224 lmp.py:380]   Expert 58 |    132 | CPU
DEBUG 01-06 08:44:46.163397.163397 lmp.py:380]   Expert 42 |    134 | CPU
DEBUG 01-06 08:44:46.163001.163001 lmp.py:380]   Expert 28 |    135 | CPU
DEBUG 01-06 08:44:46.163458.163458 lmp.py:380]   Expert 55 |    135 | CPU
DEBUG 01-06 08:44:46.163916.163916 lmp.py:380]   Expert 10 |    137 | CPU
DEBUG 01-06 08:44:46.163374.163374 lmp.py:380]   Expert 12 |    137 | CPU
DEBUG 01-06 08:44:46.163354.163354 lmp.py:380]   Expert  6 |    139 | CPU
DEBUG 01-06 08:44:46.163812.163812 lmp.py:380]   Expert 26 |    139 | CPU
DEBUG 01-06 08:44:46.163270.163270 lmp.py:380]   Expert 47 |    141 | CPU
DEBUG 01-06 08:44:46.163728.163728 lmp.py:380]   Expert 38 |    143 | CPU
DEBUG 01-06 08:44:46.163470.163470 lmp.py:380]   Expert 11 |    144 | CPU
DEBUG 01-06 08:44:46.163451.163451 lmp.py:380]   Expert 52 |    144 | GPU
DEBUG 01-06 08:44:46.164193.164193 lmp.py:380]   Expert 23 |    152 | GPU
DEBUG 01-06 08:44:46.164889.164889 lmp.py:380]   Expert 53 |    153 | GPU
DEBUG 01-06 08:44:46.164347.164347 lmp.py:380]   Expert 34 |    159 | GPU
DEBUG 01-06 08:44:46.164281.164281 lmp.py:380]   Expert  2 |    162 | GPU
DEBUG 01-06 08:44:46.164216.164216 lmp.py:380]   Expert 51 |    173 | GPU
DEBUG 01-06 08:44:46.164343.164343 lmp.py:380]   Expert  3 |    187 | GPU
DEBUG 01-06 08:44:46.164562.164562 lmp.py:380]   Expert 36 |    192 | GPU
DEBUG 01-06 08:44:46.164543.164543 lmp.py:380]   Expert  8 |    195 | GPU
DEBUG 01-06 08:44:46.164285.164285 lmp.py:380]   Expert 22 |    196 | GPU
DEBUG 01-06 08:44:46.164027.164027 lmp.py:380]   Expert 31 |    208 | GPU
DEBUG 01-06 08:44:46.164247.164247 lmp.py:380]   Expert 62 |    212 | GPU
DEBUG 01-06 08:44:46.164181.164181 lmp.py:380]   Expert 45 |    218 | GPU
DEBUG 01-06 08:44:46.164877.164877 lmp.py:380]   Expert 39 |    219 | GPU
DEBUG 01-06 08:44:46.164858.164858 lmp.py:380]   Expert 14 |    248 | GPU
DEBUG 01-06 08:44:46.164316.164316 lmp.py:380]   Expert 50 |    250 | GPU
DEBUG 01-06 08:44:46.164535.164535 lmp.py:380]   Expert 27 |    254 | GPU
DEBUG 01-06 08:44:46.164516.164516 lmp.py:380]   Expert 17 |    256 | GPU
DEBUG 01-06 08:44:46.164689.164689 lmp.py:380]   Expert 13 |    258 | GPU
DEBUG 01-06 08:44:46.164134.164134 lmp.py:380]   Expert 21 |    286 | GPU
DEBUG 01-06 08:44:46.164453.164453 lmp.py:380]   Expert  0 |    290 | GPU
DEBUG 01-06 08:44:46.164626.164626 lmp.py:380]   Expert 56 |    319 | GPU
DEBUG 01-06 08:44:46.164083.164083 lmp.py:380]   Expert 46 |    338 | GPU
DEBUG 01-06 08:44:46.164256.164256 lmp.py:380]   Expert 60 |    348 | GPU
DEBUG 01-06 08:44:46.164714.164714 lmp.py:380]   Expert 20 |    350 | GPU
DEBUG 01-06 08:44:46.164649.164649 lmp.py:380]   Expert 33 |    354 | GPU
DEBUG 01-06 08:44:46.164868.164868 lmp.py:380]   Expert  9 |    370 | GPU
DEBUG 01-06 08:44:46.164948.164948 lmp.py:380]   Expert 25 |    460 | GPU
DEBUG 01-06 08:44:46.164359.164359 lmp.py:380]   Expert 19 |    468 | GPU
DEBUG 01-06 08:44:46.164294.164294 lmp.py:380]   Expert 43 |    497 | GPU
DEBUG 01-06 08:44:46.164705.164705 lmp.py:380]   Expert 54 |    592 | GPU
DEBUG 01-06 08:44:46.164163.164163 lmp.py:380]   Expert 41 |    713 | GPU
DEBUG 01-06 08:44:46.164051.164051 lmp.py:381] 
DEBUG 01-06 08:44:46.164051.164051 lmp.py:381]   CPU total tokens: 3067 (25.0%)
DEBUG 01-06 08:44:46.164939.164939 lmp.py:382]   GPU total tokens: 9221 (75.0%)
DEBUG 01-06 08:44:46.164311.164311 cuda_h.py:19] end experts_map_get cost 0.0021178722381591797 seconds
DEBUG 01-06 08:44:46.164676.164676 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.164559.164559 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.164842.164842 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.165174.165174 cuda_h.py:19] end allocate_cuda_memory cost 0.00020575523376464844 seconds
DEBUG 01-06 08:44:46.165415.165415 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.165847.165847 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.165484.165484 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.165002.165002 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3211d180-e47a-4e82-924d-8e71f8076c63
DEBUG 01-06 08:44:46.165968.165968 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.165853.165853 client.py:127] Model loaded
DEBUG 01-06 08:44:46.166553.166553 cuda_h.py:19] end sllm_worker_task cost 0.011861801147460938 seconds
INFO 01-06 08:44:46.166418.166418 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3211d180-e47a-4e82-924d-8e71f8076c63
DEBUG 01-06 08:44:46.166230.166230 cuda_h.py:19] end load_into_gpu_async cost 0.0015397071838378906 seconds
DEBUG 01-06 08:44:46.166039.166039 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.167363.167363 cuda_h.py:19] end restore_tensors2 cost 0.0003478527069091797 seconds
DEBUG 01-06 08:44:46.167470.167470 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002471446990966797 seconds
DEBUG 01-06 08:44:46.170174.170174 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005736827850341797 seconds
DEBUG 01-06 08:44:46.170739.170739 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.170120.170120 lmp.py:427] 
DEBUG 01-06 08:44:46.170120.170120 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.170738.170738 cuda_h.py:19] end cpu_experts_submit cost 0.00012493133544921875 seconds
DEBUG 01-06 08:44:46.170218.170218 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.175822.175822 mlpmodule.py:704] group tensors cost 0.004101991653442383 s
DEBUG 01-06 08:44:46.177895.177895 mlpmodule.py:742] pad cost 0.0020046234130859375 s
DEBUG 01-06 08:44:46.177111.177111 mlpmodule.py:748] create cpu tensor cost 6.151199340820312e-05 s
DEBUG 01-06 08:44:46.177922.177922 mlpmodule.py:753] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-06 08:44:46.188175.188175 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.188294.188294 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.189258.189258 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-06 08:44:46.189786.189786 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.207839.207839 mlpmodule.py:793] group einsum cost 0.02910470962524414 s
DEBUG 01-06 08:44:46.207254.207254 mlpmodule.py:801] cpy2cputensor cost 0.000667572021484375 s
DEBUG 01-06 08:44:46.214206.214206 cuda_h.py:19] end wait_cetm_experts cost 0.0433049201965332 seconds
DEBUG 01-06 08:44:46.214818.214818 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.214777.214777 cuda_h.py:19] end gpu_sexperts cost 0.00048542022705078125 seconds
DEBUG 01-06 08:44:46.214872.214872 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.215775.215775 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:46.215100.215100 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.215525.215525 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3211d180-e47a-4e82-924d-8e71f8076c63
DEBUG 01-06 08:44:46.223173.223173 mlpmodule.py:662]  experts func einsum cost 0.05257987976074219 s
INFO 01-06 08:44:46.224454.224454 client.py:127] Model loaded
DEBUG 01-06 08:44:46.224026.224026 cuda_h.py:19] end wait_experts cost 0.009211540222167969 seconds
DEBUG 01-06 08:44:46.224590.224590 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.224869.224869 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.238689.238689 cuda_h.py:19] end gpu_experts cost 0.014606237411499023 seconds
DEBUG 01-06 08:44:46.239137.239137 cuda_h.py:19] end layer_moe_generate_3 cost 0.07727384567260742 seconds
DEBUG 01-06 08:44:46.239315.239315 lmp.py:221] -------------------------------- end layer 3 --------------------------------
DEBUG 01-06 08:44:46.239078.239078 lmp.py:177] -------------------------------- start layer 4 --------------------------------
DEBUG 01-06 08:44:46.239966.239966 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 08:44:46.239914.239914 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 08:44:46.239803.239803 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0040740966796875e-05 seconds
DEBUG 01-06 08:44:46.239314.239314 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.079673767089844e-05 seconds
DEBUG 01-06 08:44:46.239341.239341 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.239936.239936 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.239124.239124 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.240441.240441 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.240239.240239 cuda_h.py:19] end allocate_cuda_memory cost 0.0005590915679931641 seconds
DEBUG 01-06 08:44:46.240423.240423 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.241367.241367 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.241106.241106 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.241599.241599 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7a55690-4c98-409a-b61d-5d5e30ab1485
DEBUG 01-06 08:44:46.241813.241813 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.242025.242025 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.242086.242086 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7a55690-4c98-409a-b61d-5d5e30ab1485
DEBUG 01-06 08:44:46.243643.243643 cuda_h.py:19] end load_into_gpu_async cost 0.002095460891723633 seconds
DEBUG 01-06 08:44:46.243712.243712 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.243104.243104 cuda_h.py:19] end restore_tensors2 cost 0.00017309188842773438 seconds
DEBUG 01-06 08:44:46.243797.243797 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035784244537353516 seconds
INFO 01-06 08:44:46.245443.245443 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7a55690-4c98-409a-b61d-5d5e30ab1485
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.248729.248729 cuda_h.py:19] end self_attn cost 0.006024599075317383 seconds
DEBUG 01-06 08:44:46.248478.248478 cuda_h.py:19] end iln_self_attn_paln cost 0.009196996688842773 seconds
DEBUG 01-06 08:44:46.248050.248050 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-06 08:44:46.248296.248296 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.249083.249083 cuda_h.py:19] end gate cost 0.0007157325744628906 seconds
DEBUG 01-06 08:44:46.249158.249158 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.250247.250247 lmp.py:369] 
DEBUG 01-06 08:44:46.250247.250247 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.250010.250010 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.250157.250157 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.250906.250906 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.250986.250986 lmp.py:373] 
DEBUG 01-06 08:44:46.250986.250986 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.250828.250828 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.250392.250392 lmp.py:380]   Expert 45 |      3 | CPU
DEBUG 01-06 08:44:46.250472.250472 lmp.py:380]   Expert  9 |     25 | CPU
DEBUG 01-06 08:44:46.250884.250884 lmp.py:380]   Expert 11 |     27 | CPU
DEBUG 01-06 08:44:46.250057.250057 lmp.py:380]   Expert  3 |     32 | CPU
DEBUG 01-06 08:44:46.250468.250468 lmp.py:380]   Expert 60 |     45 | CPU
DEBUG 01-06 08:44:46.250164.250164 lmp.py:380]   Expert 41 |     47 | CPU
DEBUG 01-06 08:44:46.250622.250622 lmp.py:380]   Expert 25 |     56 | CPU
DEBUG 01-06 08:44:46.250556.250556 lmp.py:380]   Expert 48 |     57 | CPU
DEBUG 01-06 08:44:46.250252.250252 lmp.py:380]   Expert 51 |     59 | CPU
DEBUG 01-06 08:44:46.250902.250902 lmp.py:380]   Expert 34 |     63 | CPU
DEBUG 01-06 08:44:46.250744.250744 lmp.py:380]   Expert 36 |     64 | CPU
DEBUG 01-06 08:44:46.250394.250394 lmp.py:380]   Expert 53 |     70 | CPU
DEBUG 01-06 08:44:46.250090.250090 lmp.py:380]   Expert 24 |     71 | CPU
DEBUG 01-06 08:44:46.250786.250786 lmp.py:380]   Expert 14 |     74 | CPU
DEBUG 01-06 08:44:46.250244.250244 lmp.py:380]   Expert  7 |     75 | CPU
DEBUG 01-06 08:44:46.250701.250701 lmp.py:380]   Expert 58 |     76 | CPU
DEBUG 01-06 08:44:46.250397.250397 lmp.py:380]   Expert  6 |     78 | CPU
DEBUG 01-06 08:44:46.250332.250332 lmp.py:380]   Expert 31 |     93 | CPU
DEBUG 01-06 08:44:46.250743.250743 lmp.py:380]   Expert 13 |     98 | CPU
DEBUG 01-06 08:44:46.250916.250916 lmp.py:380]   Expert 55 |     99 | CPU
DEBUG 01-06 08:44:46.250328.250328 lmp.py:380]   Expert 47 |    104 | CPU
DEBUG 01-06 08:44:46.250547.250547 lmp.py:380]   Expert 50 |    112 | CPU
DEBUG 01-06 08:44:46.250004.250004 lmp.py:380]   Expert 56 |    114 | CPU
DEBUG 01-06 08:44:46.250224.250224 lmp.py:380]   Expert  4 |    117 | CPU
DEBUG 01-06 08:44:46.250681.250681 lmp.py:380]   Expert 40 |    117 | CPU
DEBUG 01-06 08:44:46.250093.250093 lmp.py:380]   Expert 23 |    120 | CPU
DEBUG 01-06 08:44:46.250789.250789 lmp.py:380]   Expert  2 |    122 | CPU
DEBUG 01-06 08:44:46.250962.250962 lmp.py:380]   Expert 28 |    124 | CPU
DEBUG 01-06 08:44:46.250896.250896 lmp.py:380]   Expert 33 |    129 | CPU
DEBUG 01-06 08:44:46.250308.250308 lmp.py:380]   Expert 16 |    131 | CPU
INFO 01-06 08:44:46.251199.251199 client.py:127] Model loaded
DEBUG 01-06 08:44:46.251774.251774 lmp.py:380]   Expert  8 |    140 | CPU
DEBUG 01-06 08:44:46.251897.251897 cuda_h.py:19] end sllm_worker_task cost 0.011437177658081055 seconds
DEBUG 01-06 08:44:46.251562.251562 lmp.py:380]   Expert 10 |    145 | CPU
DEBUG 01-06 08:44:46.251542.251542 lmp.py:380]   Expert 44 |    146 | GPU
DEBUG 01-06 08:44:46.251668.251668 lmp.py:380]   Expert 21 |    148 | GPU
DEBUG 01-06 08:44:46.251795.251795 lmp.py:380]   Expert 37 |    151 | GPU
DEBUG 01-06 08:44:46.251868.251868 lmp.py:380]   Expert 54 |    152 | GPU
DEBUG 01-06 08:44:46.251227.251227 lmp.py:380]   Expert 26 |    158 | GPU
DEBUG 01-06 08:44:46.251346.251346 lmp.py:380]   Expert 22 |    161 | GPU
DEBUG 01-06 08:44:46.251513.251513 lmp.py:380]   Expert 57 |    163 | GPU
DEBUG 01-06 08:44:46.251156.251156 lmp.py:380]   Expert 18 |    166 | GPU
DEBUG 01-06 08:44:46.251799.251799 lmp.py:380]   Expert 15 |    178 | GPU
DEBUG 01-06 08:44:46.251965.251965 lmp.py:380]   Expert 61 |    204 | GPU
DEBUG 01-06 08:44:46.251369.251369 lmp.py:380]   Expert 27 |    209 | GPU
DEBUG 01-06 08:44:46.251297.251297 lmp.py:380]   Expert 20 |    210 | GPU
DEBUG 01-06 08:44:46.251463.251463 lmp.py:380]   Expert 46 |    226 | GPU
DEBUG 01-06 08:44:46.251583.251583 lmp.py:380]   Expert 17 |    253 | GPU
DEBUG 01-06 08:44:46.251226.251226 lmp.py:380]   Expert  1 |    256 | GPU
DEBUG 01-06 08:44:46.251107.251107 lmp.py:380]   Expert 63 |    256 | GPU
DEBUG 01-06 08:44:46.251227.251227 lmp.py:380]   Expert 29 |    276 | GPU
DEBUG 01-06 08:44:46.251870.251870 lmp.py:380]   Expert 42 |    285 | GPU
DEBUG 01-06 08:44:46.251275.251275 lmp.py:380]   Expert  0 |    310 | GPU
DEBUG 01-06 08:44:46.251679.251679 lmp.py:380]   Expert 62 |    325 | GPU
DEBUG 01-06 08:44:46.251845.251845 lmp.py:380]   Expert 52 |    328 | GPU
DEBUG 01-06 08:44:46.251011.251011 lmp.py:380]   Expert 32 |    339 | GPU
DEBUG 01-06 08:44:46.251654.251654 lmp.py:380]   Expert 19 |    359 | GPU
DEBUG 01-06 08:44:46.251821.251821 lmp.py:380]   Expert 38 |    361 | GPU
DEBUG 01-06 08:44:46.251748.251748 lmp.py:380]   Expert 35 |    386 | GPU
DEBUG 01-06 08:44:46.252914.252914 lmp.py:380]   Expert 30 |    440 | GPU
DEBUG 01-06 08:44:46.252081.252081 lmp.py:380]   Expert 39 |    443 | GPU
DEBUG 01-06 08:44:46.252962.252962 lmp.py:380]   Expert 49 |    460 | GPU
DEBUG 01-06 08:44:46.252605.252605 lmp.py:380]   Expert 12 |    479 | GPU
DEBUG 01-06 08:44:46.252725.252725 lmp.py:380]   Expert  5 |    486 | GPU
DEBUG 01-06 08:44:46.252083.252083 lmp.py:380]   Expert 43 |    631 | GPU
DEBUG 01-06 08:44:46.252488.252488 lmp.py:380]   Expert 59 |    656 | GPU
DEBUG 01-06 08:44:46.252561.252561 lmp.py:381] 
DEBUG 01-06 08:44:46.252561.252561 lmp.py:381]   CPU total tokens: 2687 (21.9%)
DEBUG 01-06 08:44:46.252873.252873 lmp.py:382]   GPU total tokens: 9601 (78.1%)
DEBUG 01-06 08:44:46.252722.252722 cuda_h.py:19] end experts_map_get cost 0.0025565624237060547 seconds
DEBUG 01-06 08:44:46.252749.252749 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.252532.252532 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.252875.252875 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.252270.252270 cuda_h.py:19] end allocate_cuda_memory cost 0.000263214111328125 seconds
DEBUG 01-06 08:44:46.252703.252703 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.252465.252465 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.252195.252195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.252806.252806 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bfa2304-3534-4134-bdc5-a7fe10d1ff52
DEBUG 01-06 08:44:46.253931.253931 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.254921.254921 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bfa2304-3534-4134-bdc5-a7fe10d1ff52
DEBUG 01-06 08:44:46.254757.254757 cuda_h.py:19] end load_into_gpu_async cost 0.0015857219696044922 seconds
DEBUG 01-06 08:44:46.254937.254937 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.254353.254353 cuda_h.py:19] end restore_tensors2 cost 0.00034928321838378906 seconds
DEBUG 01-06 08:44:46.254275.254275 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002594470977783203 seconds
DEBUG 01-06 08:44:46.258601.258601 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005830287933349609 seconds
DEBUG 01-06 08:44:46.258351.258351 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.258494.258494 lmp.py:427] 
DEBUG 01-06 08:44:46.258494.258494 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.258112.258112 cuda_h.py:19] end cpu_experts_submit cost 0.00012421607971191406 seconds
DEBUG 01-06 08:44:46.258590.258590 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.262996.262996 mlpmodule.py:704] group tensors cost 0.004116058349609375 s
DEBUG 01-06 08:44:46.265731.265731 mlpmodule.py:742] pad cost 0.001961231231689453 s
DEBUG 01-06 08:44:46.265165.265165 mlpmodule.py:748] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-06 08:44:46.265903.265903 mlpmodule.py:753] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-06 08:44:46.276846.276846 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.276151.276151 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.276638.276638 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-06 08:44:46.277682.277682 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.297627.297627 mlpmodule.py:793] group einsum cost 0.03183269500732422 s
DEBUG 01-06 08:44:46.298994.298994 mlpmodule.py:801] cpy2cputensor cost 0.0006427764892578125 s
DEBUG 01-06 08:44:46.304789.304789 cuda_h.py:19] end wait_cetm_experts cost 0.04605913162231445 seconds
DEBUG 01-06 08:44:46.304865.304865 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.305651.305651 cuda_h.py:19] end gpu_sexperts cost 0.00046372413635253906 seconds
DEBUG 01-06 08:44:46.305633.305633 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.305628.305628 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-06 08:44:46.305669.305669 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.305855.305855 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bfa2304-3534-4134-bdc5-a7fe10d1ff52
INFO 01-06 08:44:46.310265.310265 client.py:127] Model loaded
DEBUG 01-06 08:44:46.311367.311367 cuda_h.py:19] end wait_experts cost 0.005783796310424805 seconds
DEBUG 01-06 08:44:46.311123.311123 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.311462.311462 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.314944.314944 mlpmodule.py:662]  experts func einsum cost 0.05616164207458496 s
DEBUG 01-06 08:44:46.323839.323839 cuda_h.py:19] end gpu_experts cost 0.012635469436645508 seconds
DEBUG 01-06 08:44:46.323041.323041 cuda_h.py:19] end layer_moe_generate_4 cost 0.07506227493286133 seconds
DEBUG 01-06 08:44:46.324663.324663 lmp.py:221] -------------------------------- end layer 4 --------------------------------
DEBUG 01-06 08:44:46.324426.324426 lmp.py:177] -------------------------------- start layer 5 --------------------------------
DEBUG 01-06 08:44:46.324314.324314 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 08:44:46.324309.324309 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 08:44:46.324814.324814 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:46.324325.324325 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.9604644775390625e-05 seconds
DEBUG 01-06 08:44:46.324875.324875 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.324827.324827 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.324452.324452 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.324558.324558 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.325188.325188 cuda_h.py:19] end allocate_cuda_memory cost 0.0005278587341308594 seconds
DEBUG 01-06 08:44:46.325414.325414 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.325053.325053 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.325130.325130 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.326551.326551 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf337181-4c51-4ed5-a657-00e2af2ed3c7
DEBUG 01-06 08:44:46.326956.326956 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.326657.326657 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.327600.327600 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf337181-4c51-4ed5-a657-00e2af2ed3c7
DEBUG 01-06 08:44:46.328759.328759 cuda_h.py:19] end load_into_gpu_async cost 0.002274036407470703 seconds
DEBUG 01-06 08:44:46.328682.328682 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.328678.328678 cuda_h.py:19] end restore_tensors2 cost 0.00017595291137695312 seconds
DEBUG 01-06 08:44:46.328364.328364 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037724971771240234 seconds
INFO 01-06 08:44:46.329726.329726 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf337181-4c51-4ed5-a657-00e2af2ed3c7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.332003.332003 cuda_h.py:19] end self_attn cost 0.005552530288696289 seconds
DEBUG 01-06 08:44:46.332790.332790 cuda_h.py:19] end iln_self_attn_paln cost 0.00850820541381836 seconds
DEBUG 01-06 08:44:46.332024.332024 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-06 08:44:46.332363.332363 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.333127.333127 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-06 08:44:46.333957.333957 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.333769.333769 lmp.py:369] 
DEBUG 01-06 08:44:46.333769.333769 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.333240.333240 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.333559.333559 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.333063.333063 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.333182.333182 lmp.py:373] 
DEBUG 01-06 08:44:46.333182.333182 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.334017.334017 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.334575.334575 lmp.py:380]   Expert 14 |     20 | CPU
DEBUG 01-06 08:44:46.334171.334171 lmp.py:380]   Expert 18 |     29 | CPU
DEBUG 01-06 08:44:46.334576.334576 lmp.py:380]   Expert 15 |     36 | CPU
DEBUG 01-06 08:44:46.334742.334742 lmp.py:380]   Expert  2 |     43 | CPU
DEBUG 01-06 08:44:46.334908.334908 lmp.py:380]   Expert 23 |     48 | CPU
DEBUG 01-06 08:44:46.334597.334597 lmp.py:380]   Expert 39 |     48 | CPU
DEBUG 01-06 08:44:46.334525.334525 lmp.py:380]   Expert 60 |     48 | CPU
DEBUG 01-06 08:44:46.334976.334976 lmp.py:380]   Expert 30 |     50 | CPU
DEBUG 01-06 08:44:46.334904.334904 lmp.py:380]   Expert 17 |     54 | CPU
DEBUG 01-06 08:44:46.334785.334785 lmp.py:380]   Expert 45 |     55 | CPU
DEBUG 01-06 08:44:46.334951.334951 lmp.py:380]   Expert 34 |     62 | CPU
DEBUG 01-06 08:44:46.334641.334641 lmp.py:380]   Expert 52 |     77 | CPU
DEBUG 01-06 08:44:46.334330.334330 lmp.py:380]   Expert  9 |     81 | CPU
DEBUG 01-06 08:44:46.334019.334019 lmp.py:380]   Expert 27 |     86 | CPU
DEBUG 01-06 08:44:46.334947.334947 lmp.py:380]   Expert 28 |     93 | CPU
DEBUG 01-06 08:44:46.334159.334159 lmp.py:380]   Expert 47 |     93 | CPU
DEBUG 01-06 08:44:46.334610.334610 lmp.py:380]   Expert 55 |     95 | CPU
DEBUG 01-06 08:44:46.334299.334299 lmp.py:380]   Expert  3 |     99 | CPU
DEBUG 01-06 08:44:46.334989.334989 lmp.py:380]   Expert 22 |     99 | CPU
DEBUG 01-06 08:44:46.334367.334367 lmp.py:380]   Expert 62 |    106 | CPU
DEBUG 01-06 08:44:46.334772.334772 lmp.py:380]   Expert 40 |    112 | CPU
DEBUG 01-06 08:44:46.334700.334700 lmp.py:380]   Expert  8 |    114 | CPU
DEBUG 01-06 08:44:46.334866.334866 lmp.py:380]   Expert  4 |    115 | CPU
DEBUG 01-06 08:44:46.334794.334794 lmp.py:380]   Expert  1 |    118 | CPU
DEBUG 01-06 08:44:46.334960.334960 lmp.py:380]   Expert 19 |    125 | CPU
DEBUG 01-06 08:44:46.334649.334649 lmp.py:380]   Expert 43 |    127 | CPU
DEBUG 01-06 08:44:46.334815.334815 lmp.py:380]   Expert 63 |    127 | CPU
DEBUG 01-06 08:44:46.334696.334696 lmp.py:380]   Expert 26 |    130 | CPU
DEBUG 01-06 08:44:46.334101.334101 lmp.py:380]   Expert 48 |    131 | CPU
DEBUG 01-06 08:44:46.334029.334029 lmp.py:380]   Expert 41 |    136 | CPU
DEBUG 01-06 08:44:46.334195.334195 lmp.py:380]   Expert 24 |    140 | CPU
DEBUG 01-06 08:44:46.334361.334361 lmp.py:380]   Expert 51 |    144 | CPU
DEBUG 01-06 08:44:46.334527.334527 lmp.py:380]   Expert 54 |    145 | GPU
DEBUG 01-06 08:44:46.334216.334216 lmp.py:380]   Expert 58 |    147 | GPU
DEBUG 01-06 08:44:46.334144.334144 lmp.py:380]   Expert 10 |    151 | GPU
DEBUG 01-06 08:44:46.334072.334072 lmp.py:380]   Expert 25 |    159 | GPU
DEBUG 01-06 08:44:46.334000.334000 lmp.py:380]   Expert 11 |    160 | GPU
DEBUG 01-06 08:44:46.334166.334166 lmp.py:380]   Expert 29 |    160 | GPU
DEBUG 01-06 08:44:46.334908.334908 lmp.py:380]   Expert 38 |    160 | GPU
DEBUG 01-06 08:44:46.334889.334889 lmp.py:380]   Expert 44 |    160 | GPU
DEBUG 01-06 08:44:46.334963.334963 lmp.py:380]   Expert 61 |    163 | GPU
DEBUG 01-06 08:44:46.334513.334513 lmp.py:380]   Expert 56 |    164 | GPU
DEBUG 01-06 08:44:46.334778.334778 lmp.py:380]   Expert  0 |    178 | GPU
DEBUG 01-06 08:44:46.334044.334044 lmp.py:380]   Expert 46 |    183 | GPU
DEBUG 01-06 08:44:46.334594.334594 lmp.py:380]   Expert 50 |    202 | GPU
DEBUG 01-06 08:44:46.334006.334006 lmp.py:380]   Expert  5 |    211 | GPU
DEBUG 01-06 08:44:46.334702.334702 lmp.py:380]   Expert 36 |    221 | GPU
DEBUG 01-06 08:44:46.334444.334444 lmp.py:380]   Expert 16 |    229 | GPU
DEBUG 01-06 08:44:46.334471.334471 lmp.py:380]   Expert 32 |    231 | GPU
DEBUG 01-06 08:44:46.334737.334737 lmp.py:380]   Expert 12 |    232 | GPU
DEBUG 01-06 08:44:46.334287.334287 lmp.py:380]   Expert  7 |    249 | GPU
DEBUG 01-06 08:44:46.334838.334838 lmp.py:380]   Expert 35 |    250 | GPU
DEBUG 01-06 08:44:46.334911.334911 lmp.py:380]   Expert 57 |    255 | GPU
DEBUG 01-06 08:44:46.334938.334938 lmp.py:380]   Expert 42 |    277 | GPU
DEBUG 01-06 08:44:46.335442.335442 lmp.py:380]   Expert 21 |    295 | GPU
DEBUG 01-06 08:44:46.335231.335231 lmp.py:380]   Expert 59 |    339 | GPU
DEBUG 01-06 08:44:46.335304.335304 lmp.py:380]   Expert 20 |    377 | GPU
DEBUG 01-06 08:44:46.335285.335285 lmp.py:380]   Expert 13 |    395 | GPU
DEBUG 01-06 08:44:46.335101.335101 lmp.py:380]   Expert 31 |    453 | GPU
DEBUG 01-06 08:44:46.335936.335936 lmp.py:380]   Expert 33 |    455 | GPU
DEBUG 01-06 08:44:46.335102.335102 lmp.py:380]   Expert  6 |    472 | GPU
INFO 01-06 08:44:46.335279.335279 client.py:127] Model loaded
DEBUG 01-06 08:44:46.335191.335191 lmp.py:380]   Expert 49 |    517 | GPU
DEBUG 01-06 08:44:46.335560.335560 cuda_h.py:19] end sllm_worker_task cost 0.010944128036499023 seconds
DEBUG 01-06 08:44:46.335708.335708 lmp.py:380]   Expert 37 |    608 | GPU
DEBUG 01-06 08:44:46.335767.335767 lmp.py:380]   Expert 53 |   1249 | GPU
DEBUG 01-06 08:44:46.335940.335940 lmp.py:381] 
DEBUG 01-06 08:44:46.335940.335940 lmp.py:381]   CPU total tokens: 2841 (23.1%)
DEBUG 01-06 08:44:46.335682.335682 lmp.py:382]   GPU total tokens: 9447 (76.9%)
DEBUG 01-06 08:44:46.335769.335769 cuda_h.py:19] end experts_map_get cost 0.0022683143615722656 seconds
DEBUG 01-06 08:44:46.335512.335512 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.335216.335216 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.336499.336499 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.336859.336859 cuda_h.py:19] end allocate_cuda_memory cost 0.0002319812774658203 seconds
DEBUG 01-06 08:44:46.336173.336173 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.336075.336075 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.336129.336129 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.336832.336832 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 401a6c8a-4d98-4fc5-9af2-3199dc519ee6
DEBUG 01-06 08:44:46.336414.336414 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.337292.337292 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 401a6c8a-4d98-4fc5-9af2-3199dc519ee6
DEBUG 01-06 08:44:46.337175.337175 cuda_h.py:19] end load_into_gpu_async cost 0.0014090538024902344 seconds
DEBUG 01-06 08:44:46.337878.337878 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.338393.338393 cuda_h.py:19] end restore_tensors2 cost 0.00031638145446777344 seconds
DEBUG 01-06 08:44:46.338222.338222 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023331642150878906 seconds
DEBUG 01-06 08:44:46.340157.340157 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0050106048583984375 seconds
DEBUG 01-06 08:44:46.341471.341471 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.341387.341387 lmp.py:427] 
DEBUG 01-06 08:44:46.341387.341387 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.341952.341952 cuda_h.py:19] end cpu_experts_submit cost 0.00011157989501953125 seconds
DEBUG 01-06 08:44:46.341417.341417 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.348616.348616 mlpmodule.py:704] group tensors cost 0.006973981857299805 s
DEBUG 01-06 08:44:46.351450.351450 mlpmodule.py:742] pad cost 0.0022034645080566406 s
DEBUG 01-06 08:44:46.351216.351216 mlpmodule.py:748] create cpu tensor cost 4.887580871582031e-05 s
DEBUG 01-06 08:44:46.351072.351072 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 08:44:46.361928.361928 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.361987.361987 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.362905.362905 mlpmodule.py:773] group_w3 first element: -0.0277099609375
WARNING 01-06 08:44:46.362108.362108 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.380627.380627 mlpmodule.py:793] group einsum cost 0.02893972396850586 s
DEBUG 01-06 08:44:46.381762.381762 mlpmodule.py:801] cpy2cputensor cost 0.0006494522094726562 s
DEBUG 01-06 08:44:46.387668.387668 cuda_h.py:19] end wait_cetm_experts cost 0.046417236328125 seconds
DEBUG 01-06 08:44:46.387260.387260 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.388820.388820 cuda_h.py:19] end gpu_sexperts cost 0.00047469139099121094 seconds
DEBUG 01-06 08:44:46.388279.388279 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.388467.388467 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:46.388628.388628 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.388874.388874 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 401a6c8a-4d98-4fc5-9af2-3199dc519ee6
INFO 01-06 08:44:46.395201.395201 client.py:127] Model loaded
DEBUG 01-06 08:44:46.395403.395403 cuda_h.py:19] end wait_experts cost 0.006885528564453125 seconds
DEBUG 01-06 08:44:46.395212.395212 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.395021.395021 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.399905.399905 mlpmodule.py:662]  experts func einsum cost 0.05816316604614258 s
DEBUG 01-06 08:44:46.407696.407696 cuda_h.py:19] end gpu_experts cost 0.012043952941894531 seconds
DEBUG 01-06 08:44:46.407634.407634 cuda_h.py:19] end layer_moe_generate_5 cost 0.07474613189697266 seconds
DEBUG 01-06 08:44:46.407242.407242 lmp.py:221] -------------------------------- end layer 5 --------------------------------
DEBUG 01-06 08:44:46.407012.407012 lmp.py:177] -------------------------------- start layer 6 --------------------------------
DEBUG 01-06 08:44:46.407999.407999 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 08:44:46.407762.407762 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 08:44:46.407182.407182 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:44:46.407792.407792 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.604194641113281e-05 seconds
DEBUG 01-06 08:44:46.407726.407726 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.408904.408904 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.408279.408279 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.408603.408603 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.409103.409103 cuda_h.py:19] end allocate_cuda_memory cost 0.0005319118499755859 seconds
DEBUG 01-06 08:44:46.409857.409857 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.409039.409039 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.409779.409779 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.409179.409179 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7866ffa-bb22-45f7-b154-adcd00d98ae6
DEBUG 01-06 08:44:46.410478.410478 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.410182.410182 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.411756.411756 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7866ffa-bb22-45f7-b154-adcd00d98ae6
DEBUG 01-06 08:44:46.412432.412432 cuda_h.py:19] end load_into_gpu_async cost 0.0024263858795166016 seconds
DEBUG 01-06 08:44:46.412925.412925 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.412153.412153 cuda_h.py:19] end restore_tensors2 cost 0.0001785755157470703 seconds
DEBUG 01-06 08:44:46.412189.412189 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038909912109375 seconds
INFO 01-06 08:44:46.413080.413080 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7866ffa-bb22-45f7-b154-adcd00d98ae6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.416723.416723 cuda_h.py:19] end self_attn cost 0.006255149841308594 seconds
DEBUG 01-06 08:44:46.417503.417503 cuda_h.py:19] end iln_self_attn_paln cost 0.009697437286376953 seconds
DEBUG 01-06 08:44:46.417817.417817 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-06 08:44:46.417845.417845 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.418363.418363 cuda_h.py:19] end gate cost 0.0007836818695068359 seconds
DEBUG 01-06 08:44:46.418882.418882 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.419128.419128 lmp.py:369] 
DEBUG 01-06 08:44:46.419128.419128 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.419189.419189 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.419475.419475 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.419185.419185 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.419034.419034 lmp.py:373] 
DEBUG 01-06 08:44:46.419034.419034 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.419929.419929 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.419453.419453 lmp.py:380]   Expert  1 |     13 | CPU
DEBUG 01-06 08:44:46.419348.419348 lmp.py:380]   Expert  3 |     14 | CPU
DEBUG 01-06 08:44:46.419528.419528 lmp.py:380]   Expert 14 |     24 | CPU
DEBUG 01-06 08:44:46.419231.419231 lmp.py:380]   Expert 15 |     25 | CPU
DEBUG 01-06 08:44:46.419649.419649 lmp.py:380]   Expert 53 |     30 | CPU
DEBUG 01-06 08:44:46.419782.419782 lmp.py:380]   Expert 47 |     36 | CPU
DEBUG 01-06 08:44:46.419916.419916 lmp.py:380]   Expert 52 |     45 | CPU
DEBUG 01-06 08:44:46.419903.419903 lmp.py:380]   Expert 16 |     60 | CPU
DEBUG 01-06 08:44:46.419891.419891 lmp.py:380]   Expert 26 |     64 | CPU
DEBUG 01-06 08:44:46.419878.419878 lmp.py:380]   Expert 11 |     67 | CPU
DEBUG 01-06 08:44:46.419158.419158 lmp.py:380]   Expert 40 |     67 | CPU
DEBUG 01-06 08:44:46.419722.419722 lmp.py:380]   Expert 44 |     74 | CPU
DEBUG 01-06 08:44:46.419001.419001 lmp.py:380]   Expert 10 |     79 | CPU
DEBUG 01-06 08:44:46.419856.419856 lmp.py:380]   Expert 50 |     80 | CPU
DEBUG 01-06 08:44:46.419420.419420 lmp.py:380]   Expert 49 |     87 | CPU
DEBUG 01-06 08:44:46.419269.419269 lmp.py:380]   Expert  7 |     96 | CPU
DEBUG 01-06 08:44:46.419356.419356 lmp.py:380]   Expert 41 |     97 | CPU
DEBUG 01-06 08:44:46.419681.419681 lmp.py:380]   Expert 25 |    102 | CPU
DEBUG 01-06 08:44:46.419245.419245 lmp.py:380]   Expert 35 |    102 | CPU
DEBUG 01-06 08:44:46.419524.419524 lmp.py:380]   Expert 37 |    103 | CPU
DEBUG 01-06 08:44:46.419803.419803 lmp.py:380]   Expert 59 |    107 | CPU
DEBUG 01-06 08:44:46.420129.420129 lmp.py:380]   Expert 30 |    110 | CPU
DEBUG 01-06 08:44:46.420216.420216 lmp.py:380]   Expert 32 |    118 | CPU
DEBUG 01-06 08:44:46.420541.420541 lmp.py:380]   Expert 31 |    119 | CPU
DEBUG 01-06 08:44:46.420629.420629 lmp.py:380]   Expert 42 |    120 | CPU
DEBUG 01-06 08:44:46.420716.420716 lmp.py:380]   Expert  5 |    121 | CPU
DEBUG 01-06 08:44:46.420710.420710 lmp.py:380]   Expert 22 |    125 | CPU
DEBUG 01-06 08:44:46.420989.420989 lmp.py:380]   Expert 21 |    126 | CPU
DEBUG 01-06 08:44:46.420553.420553 lmp.py:380]   Expert 63 |    131 | CPU
DEBUG 01-06 08:44:46.420402.420402 lmp.py:380]   Expert 34 |    133 | CPU
DEBUG 01-06 08:44:46.420774.420774 lmp.py:380]   Expert 13 |    135 | CPU
DEBUG 01-06 08:44:46.420622.420622 lmp.py:380]   Expert 62 |    135 | CPU
DEBUG 01-06 08:44:46.420232.420232 lmp.py:380]   Expert 58 |    141 | GPU
DEBUG 01-06 08:44:46.420604.420604 lmp.py:380]   Expert 51 |    142 | GPU
DEBUG 01-06 08:44:46.420466.420466 lmp.py:380]   Expert 54 |    144 | GPU
DEBUG 01-06 08:44:46.420699.420699 lmp.py:380]   Expert 61 |    150 | GPU
DEBUG 01-06 08:44:46.420502.420502 lmp.py:380]   Expert  4 |    154 | GPU
DEBUG 01-06 08:44:46.420873.420873 lmp.py:380]   Expert 28 |    160 | GPU
DEBUG 01-06 08:44:46.420914.420914 lmp.py:380]   Expert  8 |    163 | GPU
DEBUG 01-06 08:44:46.420001.420001 lmp.py:380]   Expert 38 |    166 | GPU
DEBUG 01-06 08:44:46.420373.420373 lmp.py:380]   Expert  9 |    170 | GPU
DEBUG 01-06 08:44:46.420699.420699 lmp.py:380]   Expert  6 |    171 | GPU
DEBUG 01-06 08:44:46.420739.420739 lmp.py:380]   Expert  0 |    176 | GPU
DEBUG 01-06 08:44:46.420826.420826 lmp.py:380]   Expert 12 |    179 | GPU
DEBUG 01-06 08:44:46.420152.420152 lmp.py:380]   Expert 57 |    192 | GPU
DEBUG 01-06 08:44:46.420477.420477 lmp.py:380]   Expert 29 |    204 | GPU
DEBUG 01-06 08:44:46.420564.420564 lmp.py:380]   Expert 46 |    221 | GPU
DEBUG 01-06 08:44:46.420175.420175 lmp.py:380]   Expert  2 |    235 | GPU
DEBUG 01-06 08:44:46.420023.420023 lmp.py:380]   Expert 17 |    246 | GPU
DEBUG 01-06 08:44:46.420256.420256 lmp.py:380]   Expert 24 |    261 | GPU
DEBUG 01-06 08:44:46.420297.420297 lmp.py:380]   Expert 45 |    268 | GPU
DEBUG 01-06 08:44:46.420907.420907 lmp.py:380]   Expert 19 |    271 | GPU
DEBUG 01-06 08:44:46.420040.420040 lmp.py:380]   Expert 23 |    273 | GPU
DEBUG 01-06 08:44:46.420412.420412 lmp.py:380]   Expert 43 |    279 | GPU
DEBUG 01-06 08:44:46.420022.420022 lmp.py:380]   Expert 33 |    287 | GPU
DEBUG 01-06 08:44:46.421163.421163 lmp.py:380]   Expert 20 |    301 | GPU
DEBUG 01-06 08:44:46.421965.421965 lmp.py:380]   Expert 55 |    348 | GPU
DEBUG 01-06 08:44:46.421244.421244 lmp.py:380]   Expert 48 |    355 | GPU
DEBUG 01-06 08:44:46.421616.421616 lmp.py:380]   Expert 18 |    438 | GPU
DEBUG 01-06 08:44:46.421703.421703 lmp.py:380]   Expert 27 |    464 | GPU
DEBUG 01-06 08:44:46.421505.421505 lmp.py:380]   Expert 39 |    503 | GPU
DEBUG 01-06 08:44:46.421116.421116 lmp.py:380]   Expert 60 |    742 | GPU
DEBUG 01-06 08:44:46.421348.421348 lmp.py:380]   Expert 56 |    865 | GPU
DEBUG 01-06 08:44:46.421912.421912 lmp.py:380]   Expert 36 |    874 | GPU
DEBUG 01-06 08:44:46.421860.421860 lmp.py:381] 
DEBUG 01-06 08:44:46.421860.421860 lmp.py:381]   CPU total tokens: 2745 (22.3%)
DEBUG 01-06 08:44:46.421808.421808 lmp.py:382]   GPU total tokens: 9543 (77.7%)
DEBUG 01-06 08:44:46.421525.421525 cuda_h.py:19] end experts_map_get cost 0.0025382041931152344 seconds
DEBUG 01-06 08:44:46.421519.421519 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.421184.421184 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.421196.421196 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.421455.421455 cuda_h.py:19] end allocate_cuda_memory cost 0.00019121170043945312 seconds
DEBUG 01-06 08:44:46.421205.421205 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.421160.421160 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.421857.421857 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.422322.422322 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5e0c5897-f651-4898-8da2-d8e1740eff34
DEBUG 01-06 08:44:46.422904.422904 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.422502.422502 client.py:127] Model loaded
DEBUG 01-06 08:44:46.422634.422634 cuda_h.py:19] end sllm_worker_task cost 0.014197111129760742 seconds
INFO 01-06 08:44:46.429976.429976 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5e0c5897-f651-4898-8da2-d8e1740eff34
DEBUG 01-06 08:44:46.429602.429602 cuda_h.py:19] end load_into_gpu_async cost 0.008046388626098633 seconds
DEBUG 01-06 08:44:46.430596.430596 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.430065.430065 cuda_h.py:19] end restore_tensors2 cost 0.0003173351287841797 seconds
DEBUG 01-06 08:44:46.430941.430941 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008920669555664062 seconds
DEBUG 01-06 08:44:46.433432.433432 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011784076690673828 seconds
DEBUG 01-06 08:44:46.433567.433567 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.433974.433974 lmp.py:427] 
DEBUG 01-06 08:44:46.433974.433974 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.433877.433877 cuda_h.py:19] end cpu_experts_submit cost 0.0001232624053955078 seconds
DEBUG 01-06 08:44:46.433918.433918 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.447791.447791 mlpmodule.py:704] group tensors cost 0.01381063461303711 s
DEBUG 01-06 08:44:46.451088.451088 mlpmodule.py:742] pad cost 0.0028374195098876953 s
DEBUG 01-06 08:44:46.451722.451722 mlpmodule.py:748] create cpu tensor cost 7.128715515136719e-05 s
DEBUG 01-06 08:44:46.451858.451858 mlpmodule.py:753] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-06 08:44:46.462736.462736 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.462570.462570 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.462203.462203 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-06 08:44:46.462453.462453 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.482820.482820 mlpmodule.py:793] group einsum cost 0.030806541442871094 s
DEBUG 01-06 08:44:46.482589.482589 mlpmodule.py:801] cpy2cputensor cost 0.0006034374237060547 s
DEBUG 01-06 08:44:46.489185.489185 cuda_h.py:19] end wait_cetm_experts cost 0.05579972267150879 seconds
DEBUG 01-06 08:44:46.489685.489685 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.490790.490790 cuda_h.py:19] end gpu_sexperts cost 0.0007333755493164062 seconds
DEBUG 01-06 08:44:46.490355.490355 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.490781.490781 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:46.490345.490345 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.490969.490969 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5e0c5897-f651-4898-8da2-d8e1740eff34
INFO 01-06 08:44:46.491677.491677 client.py:127] Model loaded
DEBUG 01-06 08:44:46.491991.491991 cuda_h.py:19] end wait_experts cost 0.001041412353515625 seconds
DEBUG 01-06 08:44:46.491124.491124 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.491165.491165 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.501377.501377 mlpmodule.py:662]  experts func einsum cost 0.06792593002319336 s
DEBUG 01-06 08:44:46.505225.505225 cuda_h.py:19] end gpu_experts cost 0.013659000396728516 seconds
DEBUG 01-06 08:44:46.505613.505613 cuda_h.py:19] end layer_moe_generate_6 cost 0.08740592002868652 seconds
DEBUG 01-06 08:44:46.505043.505043 lmp.py:221] -------------------------------- end layer 6 --------------------------------
DEBUG 01-06 08:44:46.505620.505620 lmp.py:177] -------------------------------- start layer 7 --------------------------------
DEBUG 01-06 08:44:46.505369.505369 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 08:44:46.505463.505463 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 08:44:46.505306.505306 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:46.505916.505916 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.270408630371094e-05 seconds
DEBUG 01-06 08:44:46.505626.505626 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.505466.505466 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.506097.506097 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.506077.506077 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.506656.506656 cuda_h.py:19] end allocate_cuda_memory cost 0.0005247592926025391 seconds
DEBUG 01-06 08:44:46.507595.507595 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.507777.507777 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.507656.507656 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.507102.507102 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 33968d06-9b62-4dd2-a907-385946bb6e14
DEBUG 01-06 08:44:46.507646.507646 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.507082.507082 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.509712.509712 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 33968d06-9b62-4dd2-a907-385946bb6e14
DEBUG 01-06 08:44:46.509447.509447 cuda_h.py:19] end load_into_gpu_async cost 0.0019981861114501953 seconds
DEBUG 01-06 08:44:46.509655.509655 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.509472.509472 cuda_h.py:19] end restore_tensors2 cost 0.00017333030700683594 seconds
DEBUG 01-06 08:44:46.509739.509739 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003422260284423828 seconds
INFO 01-06 08:44:46.511614.511614 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 33968d06-9b62-4dd2-a907-385946bb6e14
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.513946.513946 cuda_h.py:19] end self_attn cost 0.005501270294189453 seconds
DEBUG 01-06 08:44:46.513606.513606 cuda_h.py:19] end iln_self_attn_paln cost 0.008274078369140625 seconds
DEBUG 01-06 08:44:46.514555.514555 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-06 08:44:46.514656.514656 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.514626.514626 cuda_h.py:19] end gate cost 0.000640869140625 seconds
DEBUG 01-06 08:44:46.514647.514647 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.515485.515485 lmp.py:369] 
DEBUG 01-06 08:44:46.515485.515485 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.515241.515241 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.515845.515845 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.515587.515587 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.515469.515469 lmp.py:373] 
DEBUG 01-06 08:44:46.515469.515469 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.515065.515065 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.515146.515146 lmp.py:380]   Expert  1 |     22 | CPU
DEBUG 01-06 08:44:46.515027.515027 lmp.py:380]   Expert  3 |     27 | CPU
DEBUG 01-06 08:44:46.515432.515432 lmp.py:380]   Expert 15 |     38 | CPU
DEBUG 01-06 08:44:46.515359.515359 lmp.py:380]   Expert 20 |     39 | CPU
DEBUG 01-06 08:44:46.515525.515525 lmp.py:380]   Expert 25 |     40 | CPU
DEBUG 01-06 08:44:46.515976.515976 lmp.py:380]   Expert 31 |     42 | CPU
DEBUG 01-06 08:44:46.515096.515096 lmp.py:380]   Expert 48 |     47 | CPU
DEBUG 01-06 08:44:46.515554.515554 lmp.py:380]   Expert 49 |     47 | CPU
DEBUG 01-06 08:44:46.515065.515065 lmp.py:380]   Expert  6 |     49 | CPU
DEBUG 01-06 08:44:46.515569.515569 lmp.py:380]   Expert 41 |     55 | CPU
DEBUG 01-06 08:44:46.515927.515927 lmp.py:380]   Expert 33 |     56 | CPU
DEBUG 01-06 08:44:46.515808.515808 lmp.py:380]   Expert  8 |     57 | CPU
DEBUG 01-06 08:44:46.515259.515259 lmp.py:380]   Expert 32 |     59 | CPU
DEBUG 01-06 08:44:46.515710.515710 lmp.py:380]   Expert 40 |     66 | CPU
DEBUG 01-06 08:44:46.515684.515684 lmp.py:380]   Expert 29 |     68 | CPU
DEBUG 01-06 08:44:46.515896.515896 lmp.py:380]   Expert  0 |     70 | CPU
DEBUG 01-06 08:44:46.515632.515632 lmp.py:380]   Expert 16 |     70 | CPU
DEBUG 01-06 08:44:46.515606.515606 lmp.py:380]   Expert 59 |     73 | CPU
DEBUG 01-06 08:44:46.515819.515819 lmp.py:380]   Expert 34 |     83 | CPU
DEBUG 01-06 08:44:46.515793.515793 lmp.py:380]   Expert  7 |     84 | CPU
DEBUG 01-06 08:44:46.515502.515502 lmp.py:380]   Expert  5 |     87 | CPU
DEBUG 01-06 08:44:46.515953.515953 lmp.py:380]   Expert 39 |     96 | CPU
DEBUG 01-06 08:44:46.515642.515642 lmp.py:380]   Expert 57 |     97 | CPU
DEBUG 01-06 08:44:46.515093.515093 lmp.py:380]   Expert 18 |     99 | CPU
DEBUG 01-06 08:44:46.515021.515021 lmp.py:380]   Expert 63 |    101 | CPU
DEBUG 01-06 08:44:46.515472.515472 lmp.py:380]   Expert 58 |    105 | CPU
DEBUG 01-06 08:44:46.515923.515923 lmp.py:380]   Expert 35 |    106 | CPU
DEBUG 01-06 08:44:46.515135.515135 lmp.py:380]   Expert 30 |    108 | CPU
DEBUG 01-06 08:44:46.515017.515017 lmp.py:380]   Expert 60 |    111 | CPU
DEBUG 01-06 08:44:46.515872.515872 lmp.py:380]   Expert 50 |    117 | CPU
DEBUG 01-06 08:44:46.515853.515853 lmp.py:380]   Expert 42 |    124 | CPU
DEBUG 01-06 08:44:46.515304.515304 lmp.py:380]   Expert 45 |    129 | CPU
DEBUG 01-06 08:44:46.515755.515755 lmp.py:380]   Expert 55 |    130 | GPU
DEBUG 01-06 08:44:46.515206.515206 lmp.py:380]   Expert  4 |    145 | GPU
DEBUG 01-06 08:44:46.515895.515895 lmp.py:380]   Expert 37 |    151 | GPU
DEBUG 01-06 08:44:46.515869.515869 lmp.py:380]   Expert 19 |    169 | GPU
DEBUG 01-06 08:44:46.515320.515320 lmp.py:380]   Expert 52 |    169 | GPU
DEBUG 01-06 08:44:46.515532.515532 lmp.py:380]   Expert 53 |    175 | GPU
DEBUG 01-06 08:44:46.515745.515745 lmp.py:380]   Expert 51 |    181 | GPU
DEBUG 01-06 08:44:46.515196.515196 lmp.py:380]   Expert 13 |    183 | GPU
DEBUG 01-06 08:44:46.515123.515123 lmp.py:380]   Expert 54 |    185 | GPU
DEBUG 01-06 08:44:46.515674.515674 lmp.py:380]   Expert 17 |    214 | GPU
DEBUG 01-06 08:44:46.515125.515125 lmp.py:380]   Expert 24 |    214 | GPU
DEBUG 01-06 08:44:46.516827.516827 lmp.py:380]   Expert 36 |    215 | GPU
DEBUG 01-06 08:44:46.516093.516093 lmp.py:380]   Expert 26 |    216 | GPU
DEBUG 01-06 08:44:46.516405.516405 lmp.py:380]   Expert 22 |    217 | GPU
DEBUG 01-06 08:44:46.516955.516955 lmp.py:380]   Expert 10 |    220 | GPU
DEBUG 01-06 08:44:46.516267.516267 lmp.py:380]   Expert 56 |    226 | GPU
DEBUG 01-06 08:44:46.516341.516341 lmp.py:380]   Expert 43 |    249 | GPU
DEBUG 01-06 08:44:46.516891.516891 lmp.py:380]   Expert 62 |    262 | GPU
DEBUG 01-06 08:44:46.516726.516726 lmp.py:380]   Expert  2 |    269 | GPU
DEBUG 01-06 08:44:46.516038.516038 lmp.py:380]   Expert 27 |    272 | GPU
DEBUG 01-06 08:44:46.516588.516588 lmp.py:380]   Expert 21 |    284 | GPU
DEBUG 01-06 08:44:46.516615.516615 lmp.py:380]   Expert 47 |    288 | GPU
DEBUG 01-06 08:44:46.516835.516835 lmp.py:380]   Expert 61 |    306 | GPU
DEBUG 01-06 08:44:46.516577.516577 lmp.py:380]   Expert 11 |    318 | GPU
DEBUG 01-06 08:44:46.516127.516127 lmp.py:380]   Expert 14 |    322 | GPU
DEBUG 01-06 08:44:46.516439.516439 lmp.py:380]   Expert 28 |    330 | GPU
DEBUG 01-06 08:44:46.516036.516036 lmp.py:380]   Expert 38 |    374 | GPU
DEBUG 01-06 08:44:46.516586.516586 lmp.py:380]   Expert 46 |    411 | GPU
DEBUG 01-06 08:44:46.516421.516421 lmp.py:380]   Expert 44 |    419 | GPU
DEBUG 01-06 08:44:46.516495.516495 lmp.py:380]   Expert 12 |    573 | GPU
DEBUG 01-06 08:44:46.516675.516675 lmp.py:380]   Expert  9 |    989 | GPU
DEBUG 01-06 08:44:46.516225.516225 lmp.py:380]   Expert 23 |   1240 | GPU
DEBUG 01-06 08:44:46.516490.516490 lmp.py:381] 
DEBUG 01-06 08:44:46.516490.516490 lmp.py:381]   CPU total tokens: 2372 (19.3%)
DEBUG 01-06 08:44:46.516471.516471 lmp.py:382]   GPU total tokens: 9916 (80.7%)
DEBUG 01-06 08:44:46.516605.516605 cuda_h.py:19] end experts_map_get cost 0.0016582012176513672 seconds
DEBUG 01-06 08:44:46.516778.516778 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.516707.516707 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.516850.516850 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.516912.516912 cuda_h.py:19] end allocate_cuda_memory cost 0.00021982192993164062 seconds
DEBUG 01-06 08:44:46.517477.517477 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.517094.517094 sllm_store_c.py:27] get device uuid map
INFO 01-06 08:44:46.517013.517013 client.py:127] Model loaded
DEBUG 01-06 08:44:46.517086.517086 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.517027.517027 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed2c3b7b-bac8-4cb2-a6be-52c637b114b0
DEBUG 01-06 08:44:46.517817.517817 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.517415.517415 cuda_h.py:19] end sllm_worker_task cost 0.011474609375 seconds
INFO 01-06 08:44:46.519452.519452 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed2c3b7b-bac8-4cb2-a6be-52c637b114b0
DEBUG 01-06 08:44:46.519375.519375 cuda_h.py:19] end load_into_gpu_async cost 0.002062082290649414 seconds
DEBUG 01-06 08:44:46.519416.519416 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.519017.519017 cuda_h.py:19] end restore_tensors2 cost 0.0003123283386230469 seconds
DEBUG 01-06 08:44:46.519946.519946 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029582977294921875 seconds
DEBUG 01-06 08:44:46.522257.522257 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005588531494140625 seconds
DEBUG 01-06 08:44:46.522517.522517 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.522977.522977 lmp.py:427] 
DEBUG 01-06 08:44:46.522977.522977 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.522205.522205 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-06 08:44:46.522093.522093 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.529209.529209 mlpmodule.py:704] group tensors cost 0.0066759586334228516 s
DEBUG 01-06 08:44:46.533973.533973 mlpmodule.py:742] pad cost 0.00328826904296875 s
DEBUG 01-06 08:44:46.533500.533500 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-06 08:44:46.533741.533741 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-06 08:44:46.543158.543158 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.543939.543939 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.543757.543757 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-06 08:44:46.543047.543047 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.563911.563911 mlpmodule.py:793] group einsum cost 0.03030848503112793 s
DEBUG 01-06 08:44:46.564699.564699 mlpmodule.py:801] cpy2cputensor cost 0.0005655288696289062 s
DEBUG 01-06 08:44:46.570756.570756 cuda_h.py:19] end wait_cetm_experts cost 0.048442840576171875 seconds
DEBUG 01-06 08:44:46.570634.570634 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.572765.572765 cuda_h.py:19] end gpu_sexperts cost 0.0012652873992919922 seconds
DEBUG 01-06 08:44:46.572930.572930 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.572337.572337 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-06 08:44:46.572378.572378 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.572233.572233 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed2c3b7b-bac8-4cb2-a6be-52c637b114b0
INFO 01-06 08:44:46.576410.576410 client.py:127] Model loaded
DEBUG 01-06 08:44:46.576110.576110 cuda_h.py:19] end wait_experts cost 0.004227399826049805 seconds
DEBUG 01-06 08:44:46.576794.576794 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.576941.576941 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.583127.583127 mlpmodule.py:662]  experts func einsum cost 0.06081795692443848 s
DEBUG 01-06 08:44:46.589057.589057 cuda_h.py:19] end gpu_experts cost 0.012758970260620117 seconds
DEBUG 01-06 08:44:46.589796.589796 cuda_h.py:19] end layer_moe_generate_7 cost 0.07577323913574219 seconds
DEBUG 01-06 08:44:46.590504.590504 lmp.py:221] -------------------------------- end layer 7 --------------------------------
DEBUG 01-06 08:44:46.590604.590604 lmp.py:177] -------------------------------- start layer 8 --------------------------------
DEBUG 01-06 08:44:46.590161.590161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 08:44:46.590301.590301 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 08:44:46.590906.590906 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:44:46.590377.590377 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.318092346191406e-05 seconds
DEBUG 01-06 08:44:46.590120.590120 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.590152.590152 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.590407.590407 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.590473.590473 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.591998.591998 cuda_h.py:19] end allocate_cuda_memory cost 0.0005409717559814453 seconds
DEBUG 01-06 08:44:46.591296.591296 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.591306.591306 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.591152.591152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.592168.592168 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 441a508f-90db-424c-aab5-ee09deab9fe8
DEBUG 01-06 08:44:46.592686.592686 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.592372.592372 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.593091.593091 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 441a508f-90db-424c-aab5-ee09deab9fe8
DEBUG 01-06 08:44:46.594104.594104 cuda_h.py:19] end load_into_gpu_async cost 0.002268552780151367 seconds
DEBUG 01-06 08:44:46.594981.594981 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.594123.594123 cuda_h.py:19] end restore_tensors2 cost 0.00017547607421875 seconds
DEBUG 01-06 08:44:46.594372.594372 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003771066665649414 seconds
INFO 01-06 08:44:46.595583.595583 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 441a508f-90db-424c-aab5-ee09deab9fe8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.598338.598338 cuda_h.py:19] end self_attn cost 0.005518674850463867 seconds
DEBUG 01-06 08:44:46.598693.598693 cuda_h.py:19] end iln_self_attn_paln cost 0.00839686393737793 seconds
DEBUG 01-06 08:44:46.598259.598259 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-06 08:44:46.598459.598459 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.599931.599931 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-06 08:44:46.599430.599430 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.599883.599883 lmp.py:369] 
DEBUG 01-06 08:44:46.599883.599883 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.599766.599766 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.599754.599754 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.599065.599065 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.599185.599185 lmp.py:373] 
DEBUG 01-06 08:44:46.599185.599185 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.599405.599405 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.599631.599631 lmp.py:380]   Expert 26 |      9 | CPU
DEBUG 01-06 08:44:46.599466.599466 lmp.py:380]   Expert 27 |     23 | CPU
DEBUG 01-06 08:44:46.599870.599870 lmp.py:380]   Expert 30 |     24 | CPU
DEBUG 01-06 08:44:46.599752.599752 lmp.py:380]   Expert 38 |     26 | CPU
DEBUG 01-06 08:44:46.600918.600918 lmp.py:380]   Expert  7 |     28 | CPU
DEBUG 01-06 08:44:46.600607.600607 lmp.py:380]   Expert 14 |     30 | CPU
DEBUG 01-06 08:44:46.600819.600819 lmp.py:380]   Expert 12 |     35 | CPU
DEBUG 01-06 08:44:46.600794.600794 lmp.py:380]   Expert  8 |     38 | CPU
DEBUG 01-06 08:44:46.600768.600768 lmp.py:380]   Expert 34 |     45 | CPU
DEBUG 01-06 08:44:46.600954.600954 lmp.py:380]   Expert 36 |     49 | CPU
DEBUG 01-06 08:44:46.600882.600882 lmp.py:380]   Expert 53 |     49 | CPU
DEBUG 01-06 08:44:46.600810.600810 lmp.py:380]   Expert 33 |     52 | CPU
DEBUG 01-06 08:44:46.600260.600260 lmp.py:380]   Expert 22 |     53 | CPU
DEBUG 01-06 08:44:46.600234.600234 lmp.py:380]   Expert 50 |     69 | CPU
DEBUG 01-06 08:44:46.600970.600970 lmp.py:380]   Expert 13 |     74 | CPU
DEBUG 01-06 08:44:46.600421.600421 lmp.py:380]   Expert 57 |     75 | CPU
DEBUG 01-06 08:44:46.600918.600918 lmp.py:380]   Expert 54 |     76 | CPU
DEBUG 01-06 08:44:46.600654.600654 lmp.py:380]   Expert 15 |     79 | CPU
DEBUG 01-06 08:44:46.600105.600105 lmp.py:380]   Expert  2 |     83 | CPU
DEBUG 01-06 08:44:46.600794.600794 lmp.py:380]   Expert 32 |     88 | CPU
DEBUG 01-06 08:44:46.600245.600245 lmp.py:380]   Expert 18 |     94 | CPU
DEBUG 01-06 08:44:46.600219.600219 lmp.py:380]   Expert 29 |     94 | CPU
DEBUG 01-06 08:44:46.600431.600431 lmp.py:380]   Expert  1 |    101 | CPU
DEBUG 01-06 08:44:46.600405.600405 lmp.py:380]   Expert  9 |    101 | CPU
DEBUG 01-06 08:44:46.600141.600141 lmp.py:380]   Expert 37 |    103 | CPU
DEBUG 01-06 08:44:46.600115.600115 lmp.py:380]   Expert 24 |    117 | CPU
DEBUG 01-06 08:44:46.600957.600957 lmp.py:380]   Expert 56 |    120 | CPU
DEBUG 01-06 08:44:46.600885.600885 lmp.py:380]   Expert 19 |    121 | CPU
DEBUG 01-06 08:44:46.600528.600528 lmp.py:380]   Expert 58 |    126 | CPU
DEBUG 01-06 08:44:46.600979.600979 lmp.py:380]   Expert 16 |    130 | CPU
DEBUG 01-06 08:44:46.600191.600191 lmp.py:380]   Expert 39 |    138 | CPU
DEBUG 01-06 08:44:46.600403.600403 lmp.py:380]   Expert 60 |    147 | CPU
DEBUG 01-06 08:44:46.600139.600139 lmp.py:380]   Expert 51 |    148 | GPU
DEBUG 01-06 08:44:46.600352.600352 lmp.py:380]   Expert 42 |    157 | GPU
DEBUG 01-06 08:44:46.600802.600802 lmp.py:380]   Expert 31 |    161 | GPU
DEBUG 01-06 08:44:46.600538.600538 lmp.py:380]   Expert 59 |    161 | GPU
DEBUG 01-06 08:44:46.600850.600850 lmp.py:380]   Expert 44 |    164 | GPU
DEBUG 01-06 08:44:46.600354.600354 lmp.py:380]   Expert 40 |    170 | GPU
DEBUG 01-06 08:44:46.600858.600858 lmp.py:380]   Expert 10 |    177 | GPU
DEBUG 01-06 08:44:46.600455.600455 lmp.py:380]   Expert 23 |    192 | GPU
DEBUG 01-06 08:44:46.600290.600290 lmp.py:380]   Expert 17 |    193 | GPU
DEBUG 01-06 08:44:46.600125.600125 lmp.py:380]   Expert 46 |    211 | GPU
DEBUG 01-06 08:44:46.600960.600960 lmp.py:380]   Expert 20 |    217 | GPU
DEBUG 01-06 08:44:46.600033.600033 lmp.py:380]   Expert 55 |    223 | GPU
DEBUG 01-06 08:44:46.600868.600868 lmp.py:380]   Expert 49 |    231 | GPU
DEBUG 01-06 08:44:46.600657.600657 lmp.py:380]   Expert  3 |    233 | GPU
DEBUG 01-06 08:44:46.600684.600684 lmp.py:380]   Expert  0 |    247 | GPU
DEBUG 01-06 08:44:46.600473.600473 lmp.py:380]   Expert 41 |    263 | GPU
DEBUG 01-06 08:44:46.600023.600023 lmp.py:380]   Expert 48 |    263 | GPU
DEBUG 01-06 08:44:46.600858.600858 lmp.py:380]   Expert 25 |    264 | GPU
DEBUG 01-06 08:44:46.600693.600693 lmp.py:380]   Expert 43 |    307 | GPU
DEBUG 01-06 08:44:46.600767.600767 lmp.py:380]   Expert 45 |    309 | GPU
DEBUG 01-06 08:44:46.600840.600840 lmp.py:380]   Expert 28 |    320 | GPU
DEBUG 01-06 08:44:46.600960.600960 lmp.py:380]   Expert 52 |    339 | GPU
DEBUG 01-06 08:44:46.600795.600795 lmp.py:380]   Expert  6 |    342 | GPU
DEBUG 01-06 08:44:46.600869.600869 lmp.py:380]   Expert 61 |    350 | GPU
DEBUG 01-06 08:44:46.600419.600419 lmp.py:380]   Expert  4 |    380 | GPU
DEBUG 01-06 08:44:46.600254.600254 lmp.py:380]   Expert 62 |    382 | GPU
DEBUG 01-06 08:44:46.600612.600612 lmp.py:380]   Expert 35 |    428 | GPU
DEBUG 01-06 08:44:46.600640.600640 lmp.py:380]   Expert 47 |    444 | GPU
DEBUG 01-06 08:44:46.601190.601190 lmp.py:380]   Expert 11 |    540 | GPU
DEBUG 01-06 08:44:46.601787.601787 lmp.py:380]   Expert  5 |    624 | GPU
DEBUG 01-06 08:44:46.601860.601860 lmp.py:380]   Expert 63 |    638 | GPU
DEBUG 01-06 08:44:46.601695.601695 lmp.py:380]   Expert 21 |    813 | GPU
DEBUG 01-06 08:44:46.601245.601245 lmp.py:381] 
DEBUG 01-06 08:44:46.601245.601245 lmp.py:381]   CPU total tokens: 2397 (19.5%)
DEBUG 01-06 08:44:46.601465.601465 lmp.py:382]   GPU total tokens: 9891 (80.5%)
DEBUG 01-06 08:44:46.601214.601214 cuda_h.py:19] end experts_map_get cost 0.0016379356384277344 seconds
DEBUG 01-06 08:44:46.601718.601718 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.601647.601647 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.601983.601983 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.601819.601819 cuda_h.py:19] end allocate_cuda_memory cost 0.00023102760314941406 seconds
DEBUG 01-06 08:44:46.601385.601385 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.601048.601048 sllm_store_c.py:27] get device uuid map
INFO 01-06 08:44:46.601602.601602 client.py:127] Model loaded
DEBUG 01-06 08:44:46.601653.601653 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.602865.602865 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea5151d1-a453-4a01-b57e-71cd90ceddfa
DEBUG 01-06 08:44:46.602819.602819 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.602385.602385 cuda_h.py:19] end sllm_worker_task cost 0.011457443237304688 seconds
INFO 01-06 08:44:46.603212.603212 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea5151d1-a453-4a01-b57e-71cd90ceddfa
DEBUG 01-06 08:44:46.603944.603944 cuda_h.py:19] end load_into_gpu_async cost 0.0020225048065185547 seconds
DEBUG 01-06 08:44:46.603415.603415 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.604201.604201 cuda_h.py:19] end restore_tensors2 cost 0.00030803680419921875 seconds
DEBUG 01-06 08:44:46.604408.604408 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029230117797851562 seconds
DEBUG 01-06 08:44:46.606792.606792 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005530357360839844 seconds
DEBUG 01-06 08:44:46.606098.606098 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.606750.606750 lmp.py:427] 
DEBUG 01-06 08:44:46.606750.606750 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.606838.606838 cuda_h.py:19] end cpu_experts_submit cost 0.0001163482666015625 seconds
DEBUG 01-06 08:44:46.606919.606919 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.618214.618214 mlpmodule.py:704] group tensors cost 0.01143336296081543 s
DEBUG 01-06 08:44:46.621593.621593 mlpmodule.py:742] pad cost 0.0021517276763916016 s
DEBUG 01-06 08:44:46.621173.621173 mlpmodule.py:748] create cpu tensor cost 4.9591064453125e-05 s
DEBUG 01-06 08:44:46.621321.621321 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-06 08:44:46.632356.632356 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.632998.632998 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.632985.632985 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-06 08:44:46.632969.632969 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.652874.652874 mlpmodule.py:793] group einsum cost 0.030658483505249023 s
DEBUG 01-06 08:44:46.653704.653704 mlpmodule.py:801] cpy2cputensor cost 0.0006220340728759766 s
DEBUG 01-06 08:44:46.659650.659650 cuda_h.py:19] end wait_cetm_experts cost 0.052460432052612305 seconds
DEBUG 01-06 08:44:46.659296.659296 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.660355.660355 cuda_h.py:19] end gpu_sexperts cost 0.0009391307830810547 seconds
DEBUG 01-06 08:44:46.660967.660967 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.660916.660916 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:44:46.660334.660334 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.660329.660329 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea5151d1-a453-4a01-b57e-71cd90ceddfa
INFO 01-06 08:44:46.662307.662307 client.py:127] Model loaded
DEBUG 01-06 08:44:46.662545.662545 cuda_h.py:19] end wait_experts cost 0.0016863346099853516 seconds
DEBUG 01-06 08:44:46.662222.662222 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.662038.662038 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.671702.671702 mlpmodule.py:662]  experts func einsum cost 0.06479740142822266 s
DEBUG 01-06 08:44:46.677206.677206 cuda_h.py:19] end gpu_experts cost 0.01532435417175293 seconds
DEBUG 01-06 08:44:46.677045.677045 cuda_h.py:19] end layer_moe_generate_8 cost 0.07923126220703125 seconds
DEBUG 01-06 08:44:46.678363.678363 lmp.py:221] -------------------------------- end layer 8 --------------------------------
DEBUG 01-06 08:44:46.678371.678371 lmp.py:177] -------------------------------- start layer 9 --------------------------------
DEBUG 01-06 08:44:46.678643.678643 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 08:44:46.678075.678075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 08:44:46.678078.678078 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 4.029273986816406e-05 seconds
DEBUG 01-06 08:44:46.678317.678317 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 8.249282836914062e-05 seconds
DEBUG 01-06 08:44:46.678391.678391 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.678548.678548 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.678114.678114 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.678231.678231 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.679571.679571 cuda_h.py:19] end allocate_cuda_memory cost 0.0005245208740234375 seconds
DEBUG 01-06 08:44:46.679748.679748 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.679639.679639 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.680848.680848 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.680818.680818 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f22a2e6e-edcc-4f2e-b742-b44ad5dc002a
DEBUG 01-06 08:44:46.680449.680449 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.680955.680955 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.681354.681354 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f22a2e6e-edcc-4f2e-b742-b44ad5dc002a
DEBUG 01-06 08:44:46.682288.682288 cuda_h.py:19] end load_into_gpu_async cost 0.0021581649780273438 seconds
DEBUG 01-06 08:44:46.682403.682403 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.682101.682101 cuda_h.py:19] end restore_tensors2 cost 0.00017189979553222656 seconds
DEBUG 01-06 08:44:46.682442.682442 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003576517105102539 seconds
INFO 01-06 08:44:46.683984.683984 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f22a2e6e-edcc-4f2e-b742-b44ad5dc002a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.686778.686778 cuda_h.py:19] end self_attn cost 0.005861997604370117 seconds
DEBUG 01-06 08:44:46.687791.687791 cuda_h.py:19] end iln_self_attn_paln cost 0.008761882781982422 seconds
DEBUG 01-06 08:44:46.687740.687740 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-06 08:44:46.687748.687748 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.688171.688171 cuda_h.py:19] end gate cost 0.0007317066192626953 seconds
DEBUG 01-06 08:44:46.688677.688677 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.688237.688237 lmp.py:369] 
DEBUG 01-06 08:44:46.688237.688237 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.688861.688861 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.688186.688186 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.688743.688743 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.688393.688393 lmp.py:373] 
DEBUG 01-06 08:44:46.688393.688393 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.688520.688520 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.688130.688130 lmp.py:380]   Expert 35 |     25 | CPU
DEBUG 01-06 08:44:46.688303.688303 lmp.py:380]   Expert 38 |     25 | CPU
DEBUG 01-06 08:44:46.688476.688476 lmp.py:380]   Expert  7 |     27 | CPU
DEBUG 01-06 08:44:46.688695.688695 lmp.py:380]   Expert  5 |     28 | CPU
DEBUG 01-06 08:44:46.688676.688676 lmp.py:380]   Expert  6 |     30 | CPU
DEBUG 01-06 08:44:46.688803.688803 lmp.py:380]   Expert 19 |     36 | CPU
DEBUG 01-06 08:44:46.688691.688691 lmp.py:380]   Expert 13 |     38 | CPU
DEBUG 01-06 08:44:46.688148.688148 lmp.py:380]   Expert 17 |     41 | CPU
DEBUG 01-06 08:44:46.689321.689321 lmp.py:380]   Expert 60 |     56 | CPU
DEBUG 01-06 08:44:46.689779.689779 lmp.py:380]   Expert 39 |     68 | CPU
DEBUG 01-06 08:44:46.689521.689521 lmp.py:380]   Expert 27 |     69 | CPU
DEBUG 01-06 08:44:46.689217.689217 lmp.py:380]   Expert  2 |     70 | CPU
DEBUG 01-06 08:44:46.689198.689198 lmp.py:380]   Expert 48 |     70 | CPU
DEBUG 01-06 08:44:46.689464.689464 lmp.py:380]   Expert 52 |     70 | CPU
DEBUG 01-06 08:44:46.689445.689445 lmp.py:380]   Expert 45 |     76 | CPU
DEBUG 01-06 08:44:46.689949.689949 lmp.py:380]   Expert 42 |     78 | CPU
DEBUG 01-06 08:44:46.689214.689214 lmp.py:380]   Expert 25 |     79 | CPU
DEBUG 01-06 08:44:46.689672.689672 lmp.py:380]   Expert 59 |     80 | CPU
DEBUG 01-06 08:44:46.689653.689653 lmp.py:380]   Expert 54 |     83 | CPU
DEBUG 01-06 08:44:46.689826.689826 lmp.py:380]   Expert 26 |     85 | CPU
DEBUG 01-06 08:44:46.689807.689807 lmp.py:380]   Expert 16 |     86 | CPU
DEBUG 01-06 08:44:46.689072.689072 lmp.py:380]   Expert 20 |     86 | CPU
DEBUG 01-06 08:44:46.689815.689815 lmp.py:380]   Expert 29 |     92 | CPU
DEBUG 01-06 08:44:46.689319.689319 lmp.py:380]   Expert 32 |     92 | CPU
DEBUG 01-06 08:44:46.689823.689823 lmp.py:380]   Expert 62 |     95 | CPU
DEBUG 01-06 08:44:46.689042.689042 lmp.py:380]   Expert 40 |    107 | CPU
DEBUG 01-06 08:44:46.689499.689499 lmp.py:380]   Expert 12 |    108 | CPU
DEBUG 01-06 08:44:46.689003.689003 lmp.py:380]   Expert 23 |    120 | CPU
DEBUG 01-06 08:44:46.689507.689507 lmp.py:380]   Expert 24 |    121 | CPU
DEBUG 01-06 08:44:46.689773.689773 lmp.py:380]   Expert 57 |    124 | CPU
DEBUG 01-06 08:44:46.689277.689277 lmp.py:380]   Expert 31 |    139 | CPU
DEBUG 01-06 08:44:46.689781.689781 lmp.py:380]   Expert 41 |    140 | CPU
DEBUG 01-06 08:44:46.689047.689047 lmp.py:380]   Expert 47 |    151 | GPU
DEBUG 01-06 08:44:46.689504.689504 lmp.py:380]   Expert 22 |    152 | GPU
DEBUG 01-06 08:44:46.689724.689724 lmp.py:380]   Expert 50 |    155 | GPU
INFO 01-06 08:44:46.689298.689298 client.py:127] Model loaded
DEBUG 01-06 08:44:46.689316.689316 lmp.py:380]   Expert 14 |    158 | GPU
DEBUG 01-06 08:44:46.689877.689877 cuda_h.py:19] end sllm_worker_task cost 0.01114511489868164 seconds
DEBUG 01-06 08:44:46.690787.690787 lmp.py:380]   Expert 18 |    159 | GPU
DEBUG 01-06 08:44:46.690853.690853 lmp.py:380]   Expert 28 |    163 | GPU
DEBUG 01-06 08:44:46.690118.690118 lmp.py:380]   Expert 30 |    166 | GPU
DEBUG 01-06 08:44:46.690523.690523 lmp.py:380]   Expert  1 |    168 | GPU
DEBUG 01-06 08:44:46.690212.690212 lmp.py:380]   Expert 51 |    176 | GPU
DEBUG 01-06 08:44:46.690140.690140 lmp.py:380]   Expert 34 |    196 | GPU
DEBUG 01-06 08:44:46.690068.690068 lmp.py:380]   Expert 49 |    204 | GPU
DEBUG 01-06 08:44:46.690757.690757 lmp.py:380]   Expert 58 |    210 | GPU
DEBUG 01-06 08:44:46.690208.690208 lmp.py:380]   Expert 33 |    214 | GPU
DEBUG 01-06 08:44:46.690659.690659 lmp.py:380]   Expert 53 |    223 | GPU
DEBUG 01-06 08:44:46.690348.690348 lmp.py:380]   Expert 44 |    234 | GPU
DEBUG 01-06 08:44:46.690991.690991 lmp.py:380]   Expert 36 |    250 | GPU
DEBUG 01-06 08:44:46.690395.690395 lmp.py:380]   Expert  0 |    254 | GPU
DEBUG 01-06 08:44:46.690562.690562 lmp.py:380]   Expert  8 |    258 | GPU
DEBUG 01-06 08:44:46.690774.690774 lmp.py:380]   Expert  3 |    259 | GPU
DEBUG 01-06 08:44:46.690225.690225 lmp.py:380]   Expert  4 |    270 | GPU
DEBUG 01-06 08:44:46.690676.690676 lmp.py:380]   Expert 55 |    306 | GPU
DEBUG 01-06 08:44:46.690127.690127 lmp.py:380]   Expert 37 |    333 | GPU
DEBUG 01-06 08:44:46.690816.690816 lmp.py:380]   Expert 11 |    347 | GPU
DEBUG 01-06 08:44:46.690982.690982 lmp.py:380]   Expert 43 |    353 | GPU
DEBUG 01-06 08:44:46.690148.690148 lmp.py:380]   Expert 10 |    354 | GPU
DEBUG 01-06 08:44:46.690838.690838 lmp.py:380]   Expert 15 |    381 | GPU
DEBUG 01-06 08:44:46.690288.690288 lmp.py:380]   Expert 61 |    404 | GPU
DEBUG 01-06 08:44:46.690978.690978 lmp.py:380]   Expert  9 |    420 | GPU
DEBUG 01-06 08:44:46.690190.690190 lmp.py:380]   Expert 46 |    443 | GPU
DEBUG 01-06 08:44:46.690641.690641 lmp.py:380]   Expert 63 |    521 | GPU
DEBUG 01-06 08:44:46.690092.690092 lmp.py:380]   Expert 21 |    621 | GPU
DEBUG 01-06 08:44:46.690020.690020 lmp.py:380]   Expert 56 |   1341 | GPU
DEBUG 01-06 08:44:46.690855.690855 lmp.py:381] 
DEBUG 01-06 08:44:46.690855.690855 lmp.py:381]   CPU total tokens: 2444 (19.9%)
DEBUG 01-06 08:44:46.690120.690120 lmp.py:382]   GPU total tokens: 9844 (80.1%)
DEBUG 01-06 08:44:46.690446.690446 cuda_h.py:19] end experts_map_get cost 0.0025510787963867188 seconds
DEBUG 01-06 08:44:46.690235.690235 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.690356.690356 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.690830.690830 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.691852.691852 cuda_h.py:19] end allocate_cuda_memory cost 0.00022530555725097656 seconds
DEBUG 01-06 08:44:46.691563.691563 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.691465.691465 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.691804.691804 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.691553.691553 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26612af9-9720-4c81-b691-159b78c8f97c
DEBUG 01-06 08:44:46.691997.691997 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.692750.692750 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26612af9-9720-4c81-b691-159b78c8f97c
DEBUG 01-06 08:44:46.692500.692500 cuda_h.py:19] end load_into_gpu_async cost 0.0016400814056396484 seconds
DEBUG 01-06 08:44:46.692395.692395 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.693779.693779 cuda_h.py:19] end restore_tensors2 cost 0.0003590583801269531 seconds
DEBUG 01-06 08:44:46.693224.693224 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002582550048828125 seconds
DEBUG 01-06 08:44:46.696978.696978 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005750179290771484 seconds
DEBUG 01-06 08:44:46.696483.696483 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.696652.696652 lmp.py:427] 
DEBUG 01-06 08:44:46.696652.696652 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.696693.696693 cuda_h.py:19] end cpu_experts_submit cost 0.0001232624053955078 seconds
DEBUG 01-06 08:44:46.696489.696489 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.702717.702717 mlpmodule.py:704] group tensors cost 0.005467891693115234 s
DEBUG 01-06 08:44:46.704141.704141 mlpmodule.py:742] pad cost 0.0019028186798095703 s
DEBUG 01-06 08:44:46.705152.705152 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-06 08:44:46.705876.705876 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-06 08:44:46.714515.714515 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.714482.714482 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.714333.714333 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-06 08:44:46.714979.714979 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.734814.734814 mlpmodule.py:793] group einsum cost 0.02950453758239746 s
DEBUG 01-06 08:44:46.735861.735861 mlpmodule.py:801] cpy2cputensor cost 0.0005998611450195312 s
DEBUG 01-06 08:44:46.740897.740897 cuda_h.py:19] end wait_cetm_experts cost 0.04356718063354492 seconds
DEBUG 01-06 08:44:46.740926.740926 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.742224.742224 cuda_h.py:19] end gpu_sexperts cost 0.0015048980712890625 seconds
DEBUG 01-06 08:44:46.742173.742173 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.742367.742367 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:44:46.742170.742170 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.742694.742694 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26612af9-9720-4c81-b691-159b78c8f97c
INFO 01-06 08:44:46.743943.743943 client.py:127] Model loaded
DEBUG 01-06 08:44:46.743283.743283 cuda_h.py:19] end wait_experts cost 0.0013828277587890625 seconds
DEBUG 01-06 08:44:46.743470.743470 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.743994.743994 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.759291.759291 cuda_h.py:19] end gpu_experts cost 0.015380382537841797 seconds
DEBUG 01-06 08:44:46.759196.759196 cuda_h.py:19] end layer_moe_generate_9 cost 0.07192873954772949 seconds
DEBUG 01-06 08:44:46.759077.759077 lmp.py:221] -------------------------------- end layer 9 --------------------------------
DEBUG 01-06 08:44:46.759323.759323 lmp.py:177] -------------------------------- start layer 10 --------------------------------
DEBUG 01-06 08:44:46.759265.759265 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 08:44:46.759220.759220 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 08:44:46.759354.759354 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.24249267578125e-05 seconds
DEBUG 01-06 08:44:46.759263.759263 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.605552673339844e-05 seconds
DEBUG 01-06 08:44:46.759051.759051 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.759500.759500 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.760032.760032 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.760494.760494 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.760219.760219 cuda_h.py:19] end allocate_cuda_memory cost 0.0005340576171875 seconds
DEBUG 01-06 08:44:46.761809.761809 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.761588.761588 mlpmodule.py:662]  experts func einsum cost 0.06433677673339844 s
DEBUG 01-06 08:44:46.761777.761777 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.761363.761363 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.761962.761962 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c30593a6-faef-47f8-8b30-79d5fa672e4c
DEBUG 01-06 08:44:46.761003.761003 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.762915.762915 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.763890.763890 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c30593a6-faef-47f8-8b30-79d5fa672e4c
DEBUG 01-06 08:44:46.763101.763101 cuda_h.py:19] end load_into_gpu_async cost 0.002170085906982422 seconds
DEBUG 01-06 08:44:46.763879.763879 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.763795.763795 cuda_h.py:19] end restore_tensors2 cost 0.00017523765563964844 seconds
DEBUG 01-06 08:44:46.763282.763282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037920475006103516 seconds
INFO 01-06 08:44:46.765322.765322 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c30593a6-faef-47f8-8b30-79d5fa672e4c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.768871.768871 cuda_h.py:19] end self_attn cost 0.005890607833862305 seconds
DEBUG 01-06 08:44:46.768434.768434 cuda_h.py:19] end iln_self_attn_paln cost 0.00902700424194336 seconds
DEBUG 01-06 08:44:46.768721.768721 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-06 08:44:46.768537.768537 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.769166.769166 cuda_h.py:19] end gate cost 0.0007293224334716797 seconds
DEBUG 01-06 08:44:46.769314.769314 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.770927.770927 lmp.py:369] 
DEBUG 01-06 08:44:46.770927.770927 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.770736.770736 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.770584.770584 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.770141.770141 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.770791.770791 lmp.py:373] 
DEBUG 01-06 08:44:46.770791.770791 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.770395.770395 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.770243.770243 lmp.py:380]   Expert 34 |      2 | CPU
DEBUG 01-06 08:44:46.770893.770893 lmp.py:380]   Expert 27 |      9 | CPU
DEBUG 01-06 08:44:46.770828.770828 lmp.py:380]   Expert  3 |     13 | CPU
DEBUG 01-06 08:44:46.770808.770808 lmp.py:380]   Expert 14 |     20 | CPU
DEBUG 01-06 08:44:46.770551.770551 lmp.py:380]   Expert 44 |     20 | CPU
DEBUG 01-06 08:44:46.770293.770293 lmp.py:380]   Expert 55 |     20 | CPU
DEBUG 01-06 08:44:46.770036.770036 lmp.py:380]   Expert 61 |     20 | CPU
DEBUG 01-06 08:44:46.770016.770016 lmp.py:380]   Expert  6 |     22 | CPU
DEBUG 01-06 08:44:46.770997.770997 lmp.py:380]   Expert 47 |     23 | CPU
DEBUG 01-06 08:44:46.770978.770978 lmp.py:380]   Expert 32 |     29 | CPU
DEBUG 01-06 08:44:46.770482.770482 lmp.py:380]   Expert 13 |     37 | CPU
DEBUG 01-06 08:44:46.770463.770463 lmp.py:380]   Expert 46 |     37 | CPU
DEBUG 01-06 08:44:46.770444.770444 lmp.py:380]   Expert 37 |     39 | CPU
DEBUG 01-06 08:44:46.770425.770425 lmp.py:380]   Expert 50 |     47 | CPU
DEBUG 01-06 08:44:46.770929.770929 lmp.py:380]   Expert 15 |     50 | CPU
DEBUG 01-06 08:44:46.770909.770909 lmp.py:380]   Expert 48 |     52 | CPU
DEBUG 01-06 08:44:46.770175.770175 lmp.py:380]   Expert 19 |     56 | CPU
DEBUG 01-06 08:44:46.770917.770917 lmp.py:380]   Expert  7 |     59 | CPU
DEBUG 01-06 08:44:46.770183.770183 lmp.py:380]   Expert 17 |     61 | CPU
DEBUG 01-06 08:44:46.770687.770687 lmp.py:380]   Expert 38 |     62 | CPU
DEBUG 01-06 08:44:46.770191.770191 lmp.py:380]   Expert 12 |     69 | CPU
DEBUG 01-06 08:44:46.770695.770695 lmp.py:380]   Expert 62 |     80 | CPU
DEBUG 01-06 08:44:46.770868.770868 lmp.py:380]   Expert 60 |     81 | CPU
DEBUG 01-06 08:44:46.770326.770326 lmp.py:380]   Expert 35 |     83 | CPU
DEBUG 01-06 08:44:46.770022.770022 lmp.py:380]   Expert 54 |     83 | CPU
DEBUG 01-06 08:44:46.770764.770764 lmp.py:380]   Expert 26 |     85 | CPU
DEBUG 01-06 08:44:46.770507.770507 lmp.py:380]   Expert 56 |    100 | CPU
DEBUG 01-06 08:44:46.770011.770011 lmp.py:380]   Expert 28 |    103 | CPU
DEBUG 01-06 08:44:46.770753.770753 lmp.py:380]   Expert 20 |    106 | CPU
DEBUG 01-06 08:44:46.770257.770257 lmp.py:380]   Expert 43 |    109 | CPU
DEBUG 01-06 08:44:46.770999.770999 lmp.py:380]   Expert 29 |    115 | CPU
DEBUG 01-06 08:44:46.770742.770742 lmp.py:380]   Expert 36 |    128 | CPU
DEBUG 01-06 08:44:46.771676.771676 lmp.py:380]   Expert 25 |    139 | GPU
DEBUG 01-06 08:44:46.771896.771896 lmp.py:380]   Expert 22 |    146 | GPU
DEBUG 01-06 08:44:46.771876.771876 lmp.py:380]   Expert 41 |    146 | GPU
DEBUG 01-06 08:44:46.771857.771857 lmp.py:380]   Expert 52 |    154 | GPU
DEBUG 01-06 08:44:46.771600.771600 lmp.py:380]   Expert  5 |    156 | GPU
DEBUG 01-06 08:44:46.771580.771580 lmp.py:380]   Expert 53 |    175 | GPU
DEBUG 01-06 08:44:46.771244.771244 lmp.py:380]   Expert 59 |    175 | GPU
DEBUG 01-06 08:44:46.771033.771033 lmp.py:380]   Expert 51 |    176 | GPU
DEBUG 01-06 08:44:46.771252.771252 lmp.py:380]   Expert 24 |    186 | GPU
DEBUG 01-06 08:44:46.771517.771517 lmp.py:380]   Expert  9 |    196 | GPU
DEBUG 01-06 08:44:46.771783.771783 lmp.py:380]   Expert 45 |    205 | GPU
DEBUG 01-06 08:44:46.771049.771049 lmp.py:380]   Expert 57 |    213 | GPU
DEBUG 01-06 08:44:46.771268.771268 lmp.py:380]   Expert 30 |    221 | GPU
DEBUG 01-06 08:44:46.771249.771249 lmp.py:380]   Expert 21 |    229 | GPU
DEBUG 01-06 08:44:46.771514.771514 lmp.py:380]   Expert 31 |    246 | GPU
DEBUG 01-06 08:44:46.771462.771462 lmp.py:380]   Expert 63 |    258 | GPU
DEBUG 01-06 08:44:46.771774.771774 lmp.py:380]   Expert  2 |    262 | GPU
DEBUG 01-06 08:44:46.771848.771848 lmp.py:380]   Expert 49 |    262 | GPU
DEBUG 01-06 08:44:46.771160.771160 lmp.py:380]   Expert 18 |    283 | GPU
DEBUG 01-06 08:44:46.771472.771472 lmp.py:380]   Expert 16 |    284 | GPU
INFO 01-06 08:44:46.771794.771794 client.py:127] Model loaded
DEBUG 01-06 08:44:46.771898.771898 lmp.py:380]   Expert  8 |    287 | GPU
DEBUG 01-06 08:44:46.771505.771505 cuda_h.py:19] end sllm_worker_task cost 0.011773824691772461 seconds
DEBUG 01-06 08:44:46.771276.771276 lmp.py:380]   Expert 39 |    293 | GPU
DEBUG 01-06 08:44:46.772964.772964 lmp.py:380]   Expert 10 |    355 | GPU
DEBUG 01-06 08:44:46.772753.772753 lmp.py:380]   Expert 23 |    358 | GPU
DEBUG 01-06 08:44:46.772396.772396 lmp.py:380]   Expert 42 |    360 | GPU
DEBUG 01-06 08:44:46.772708.772708 lmp.py:380]   Expert 40 |    394 | GPU
DEBUG 01-06 08:44:46.772874.772874 lmp.py:380]   Expert  4 |    487 | GPU
DEBUG 01-06 08:44:46.772279.772279 lmp.py:380]   Expert 33 |    542 | GPU
DEBUG 01-06 08:44:46.772922.772922 lmp.py:380]   Expert  0 |    545 | GPU
DEBUG 01-06 08:44:46.772373.772373 lmp.py:380]   Expert 58 |    576 | GPU
DEBUG 01-06 08:44:46.772585.772585 lmp.py:380]   Expert  1 |    955 | GPU
DEBUG 01-06 08:44:46.772036.772036 lmp.py:380]   Expert 11 |   1204 | GPU
DEBUG 01-06 08:44:46.772871.772871 lmp.py:381] 
DEBUG 01-06 08:44:46.772871.772871 lmp.py:381]   CPU total tokens: 1820 (14.8%)
DEBUG 01-06 08:44:46.772898.772898 lmp.py:382]   GPU total tokens: 10468 (85.2%)
DEBUG 01-06 08:44:46.772985.772985 cuda_h.py:19] end experts_map_get cost 0.0026009082794189453 seconds
DEBUG 01-06 08:44:46.772536.772536 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.772174.772174 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.772272.772272 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.772903.772903 cuda_h.py:19] end allocate_cuda_memory cost 0.000217437744140625 seconds
DEBUG 01-06 08:44:46.772283.772283 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.772853.772853 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.772775.772775 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.773955.773955 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 10bda27b-b9b2-4c1c-88d2-16acef0ca26c
DEBUG 01-06 08:44:46.773690.773690 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.774933.774933 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 10bda27b-b9b2-4c1c-88d2-16acef0ca26c
DEBUG 01-06 08:44:46.774949.774949 cuda_h.py:19] end load_into_gpu_async cost 0.0014712810516357422 seconds
DEBUG 01-06 08:44:46.774619.774619 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.774421.774421 cuda_h.py:19] end restore_tensors2 cost 0.0003762245178222656 seconds
DEBUG 01-06 08:44:46.774834.774834 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024585723876953125 seconds
DEBUG 01-06 08:44:46.778095.778095 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006590366363525391 seconds
DEBUG 01-06 08:44:46.779827.779827 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.779334.779334 lmp.py:427] 
DEBUG 01-06 08:44:46.779334.779334 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.779847.779847 cuda_h.py:19] end cpu_experts_submit cost 0.00017333030700683594 seconds
DEBUG 01-06 08:44:46.779001.779001 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.788548.788548 mlpmodule.py:704] group tensors cost 0.009445428848266602 s
DEBUG 01-06 08:44:46.791548.791548 mlpmodule.py:742] pad cost 0.001482248306274414 s
DEBUG 01-06 08:44:46.791313.791313 mlpmodule.py:748] create cpu tensor cost 5.340576171875e-05 s
DEBUG 01-06 08:44:46.791209.791209 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 08:44:46.800103.800103 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.801493.801493 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.801205.801205 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-06 08:44:46.801627.801627 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.819640.819640 mlpmodule.py:793] group einsum cost 0.028012514114379883 s
DEBUG 01-06 08:44:46.820501.820501 mlpmodule.py:801] cpy2cputensor cost 0.0006048679351806641 s
DEBUG 01-06 08:44:46.825207.825207 cuda_h.py:19] end wait_cetm_experts cost 0.04563260078430176 seconds
DEBUG 01-06 08:44:46.825699.825699 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.825226.825226 cuda_h.py:19] end gpu_sexperts cost 0.00045180320739746094 seconds
DEBUG 01-06 08:44:46.825777.825777 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.825058.825058 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:46.825337.825337 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.825762.825762 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 10bda27b-b9b2-4c1c-88d2-16acef0ca26c
INFO 01-06 08:44:46.829467.829467 client.py:127] Model loaded
DEBUG 01-06 08:44:46.829284.829284 cuda_h.py:19] end wait_experts cost 0.0039310455322265625 seconds
DEBUG 01-06 08:44:46.829517.829517 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.829511.829511 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.840253.840253 mlpmodule.py:662]  experts func einsum cost 0.0607905387878418 s
DEBUG 01-06 08:44:46.842399.842399 cuda_h.py:19] end gpu_experts cost 0.012865781784057617 seconds
DEBUG 01-06 08:44:46.842801.842801 cuda_h.py:19] end layer_moe_generate_10 cost 0.07393574714660645 seconds
DEBUG 01-06 08:44:46.842846.842846 lmp.py:221] -------------------------------- end layer 10 --------------------------------
DEBUG 01-06 08:44:46.842470.842470 lmp.py:177] -------------------------------- start layer 11 --------------------------------
DEBUG 01-06 08:44:46.842166.842166 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 08:44:46.843684.843684 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 08:44:46.843951.843951 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.956390380859375e-05 seconds
DEBUG 01-06 08:44:46.843938.843938 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.984306335449219e-05 seconds
DEBUG 01-06 08:44:46.843773.843773 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.843725.843725 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.843509.843509 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.843475.843475 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.844088.844088 cuda_h.py:19] end allocate_cuda_memory cost 0.0005588531494140625 seconds
DEBUG 01-06 08:44:46.844471.844471 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.844449.844449 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.844461.844461 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.844099.844099 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01691288-2436-4d87-94c8-249b558a3a46
DEBUG 01-06 08:44:46.845909.845909 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.845105.845105 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.846338.846338 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01691288-2436-4d87-94c8-249b558a3a46
DEBUG 01-06 08:44:46.846913.846913 cuda_h.py:19] end load_into_gpu_async cost 0.001989126205444336 seconds
DEBUG 01-06 08:44:46.846949.846949 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.847865.847865 cuda_h.py:19] end restore_tensors2 cost 0.00017189979553222656 seconds
DEBUG 01-06 08:44:46.847968.847968 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003504514694213867 seconds
INFO 01-06 08:44:46.848252.848252 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01691288-2436-4d87-94c8-249b558a3a46
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.851767.851767 cuda_h.py:19] end self_attn cost 0.005403757095336914 seconds
DEBUG 01-06 08:44:46.852600.852600 cuda_h.py:19] end iln_self_attn_paln cost 0.009038448333740234 seconds
DEBUG 01-06 08:44:46.852464.852464 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-06 08:44:46.852425.852425 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.853952.853952 cuda_h.py:19] end gate cost 0.0006673336029052734 seconds
DEBUG 01-06 08:44:46.853590.853590 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.853097.853097 lmp.py:369] 
DEBUG 01-06 08:44:46.853097.853097 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.853614.853614 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.853502.853502 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.853291.853291 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.853696.853696 lmp.py:373] 
DEBUG 01-06 08:44:46.853696.853696 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.853339.853339 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.853757.853757 lmp.py:380]   Expert 35 |      7 | CPU
DEBUG 01-06 08:44:46.853499.853499 lmp.py:380]   Expert 59 |     11 | CPU
DEBUG 01-06 08:44:46.853288.853288 lmp.py:380]   Expert 16 |     14 | CPU
DEBUG 01-06 08:44:46.853838.853838 lmp.py:380]   Expert 39 |     15 | CPU
DEBUG 01-06 08:44:46.853912.853912 lmp.py:380]   Expert 19 |     20 | CPU
DEBUG 01-06 08:44:46.853416.853416 lmp.py:380]   Expert  5 |     23 | CPU
DEBUG 01-06 08:44:46.853443.853443 lmp.py:380]   Expert 41 |     36 | CPU
DEBUG 01-06 08:44:46.853993.853993 lmp.py:380]   Expert 23 |     39 | CPU
DEBUG 01-06 08:44:46.853305.853305 lmp.py:380]   Expert 38 |     40 | CPU
DEBUG 01-06 08:44:46.853140.853140 lmp.py:380]   Expert  6 |     42 | CPU
DEBUG 01-06 08:44:46.853690.853690 lmp.py:380]   Expert 49 |     43 | CPU
DEBUG 01-06 08:44:46.853639.853639 lmp.py:380]   Expert 27 |     45 | CPU
DEBUG 01-06 08:44:46.853666.853666 lmp.py:380]   Expert  7 |     46 | CPU
DEBUG 01-06 08:44:46.853501.853501 lmp.py:380]   Expert  3 |     48 | CPU
DEBUG 01-06 08:44:46.853336.853336 lmp.py:380]   Expert  8 |     52 | CPU
DEBUG 01-06 08:44:46.853125.853125 lmp.py:380]   Expert 17 |     52 | CPU
DEBUG 01-06 08:44:46.853436.853436 lmp.py:380]   Expert 15 |     55 | CPU
DEBUG 01-06 08:44:46.853748.853748 lmp.py:380]   Expert 46 |     55 | CPU
DEBUG 01-06 08:44:46.853060.853060 lmp.py:380]   Expert  0 |     66 | CPU
DEBUG 01-06 08:44:46.853372.853372 lmp.py:380]   Expert 20 |     66 | CPU
DEBUG 01-06 08:44:46.853207.853207 lmp.py:380]   Expert 48 |     66 | CPU
DEBUG 01-06 08:44:46.853996.853996 lmp.py:380]   Expert 63 |     70 | CPU
DEBUG 01-06 08:44:46.853831.853831 lmp.py:380]   Expert 32 |     72 | CPU
DEBUG 01-06 08:44:46.853381.853381 lmp.py:380]   Expert 60 |     74 | CPU
DEBUG 01-06 08:44:46.853885.853885 lmp.py:380]   Expert 57 |     77 | CPU
DEBUG 01-06 08:44:46.854436.854436 lmp.py:380]   Expert 36 |     85 | CPU
DEBUG 01-06 08:44:46.854271.854271 lmp.py:380]   Expert 25 |     87 | CPU
DEBUG 01-06 08:44:46.854152.854152 lmp.py:380]   Expert 10 |     89 | CPU
DEBUG 01-06 08:44:46.854226.854226 lmp.py:380]   Expert  4 |     96 | CPU
DEBUG 01-06 08:44:46.854061.854061 lmp.py:380]   Expert 40 |    105 | CPU
DEBUG 01-06 08:44:46.854657.854657 lmp.py:380]   Expert 52 |    109 | CPU
DEBUG 01-06 08:44:46.854446.854446 lmp.py:380]   Expert 62 |    111 | CPU
DEBUG 01-06 08:44:46.854235.854235 lmp.py:380]   Expert 61 |    129 | GPU
DEBUG 01-06 08:44:46.854547.854547 lmp.py:380]   Expert 43 |    134 | GPU
DEBUG 01-06 08:44:46.854097.854097 lmp.py:380]   Expert 51 |    141 | GPU
DEBUG 01-06 08:44:46.854647.854647 lmp.py:380]   Expert 50 |    145 | GPU
DEBUG 01-06 08:44:46.854198.854198 lmp.py:380]   Expert 12 |    157 | GPU
DEBUG 01-06 08:44:46.854748.854748 lmp.py:380]   Expert 13 |    157 | GPU
DEBUG 01-06 08:44:46.854060.854060 lmp.py:380]   Expert  1 |    173 | GPU
DEBUG 01-06 08:44:46.854326.854326 lmp.py:380]   Expert 42 |    177 | GPU
DEBUG 01-06 08:44:46.854399.854399 lmp.py:380]   Expert 47 |    191 | GPU
DEBUG 01-06 08:44:46.854234.854234 lmp.py:380]   Expert 18 |    195 | GPU
DEBUG 01-06 08:44:46.854831.854831 lmp.py:380]   Expert 26 |    204 | GPU
DEBUG 01-06 08:44:46.854189.854189 lmp.py:380]   Expert 34 |    242 | GPU
DEBUG 01-06 08:44:46.854786.854786 lmp.py:380]   Expert 31 |    243 | GPU
DEBUG 01-06 08:44:46.854382.854382 lmp.py:380]   Expert 29 |    245 | GPU
DEBUG 01-06 08:44:46.854740.854740 lmp.py:380]   Expert 55 |    255 | GPU
DEBUG 01-06 08:44:46.854099.854099 lmp.py:380]   Expert 56 |    256 | GPU
DEBUG 01-06 08:44:46.854934.854934 lmp.py:380]   Expert 33 |    282 | GPU
DEBUG 01-06 08:44:46.854484.854484 lmp.py:380]   Expert 45 |    290 | GPU
DEBUG 01-06 08:44:46.854034.854034 lmp.py:380]   Expert 44 |    294 | GPU
DEBUG 01-06 08:44:46.854585.854585 lmp.py:380]   Expert  2 |    301 | GPU
DEBUG 01-06 08:44:46.854897.854897 lmp.py:380]   Expert 14 |    304 | GPU
DEBUG 01-06 08:44:46.854209.854209 lmp.py:380]   Expert 28 |    321 | GPU
DEBUG 01-06 08:44:46.854282.854282 lmp.py:380]   Expert 53 |    337 | GPU
DEBUG 01-06 08:44:46.854594.854594 lmp.py:380]   Expert 24 |    386 | GPU
DEBUG 01-06 08:44:46.854952.854952 lmp.py:380]   Expert 54 |    392 | GPU
DEBUG 01-06 08:44:46.854787.854787 lmp.py:380]   Expert  9 |    413 | GPU
DEBUG 01-06 08:44:46.854590.854590 lmp.py:380]   Expert 21 |    419 | GPU
DEBUG 01-06 08:44:46.854709.854709 lmp.py:380]   Expert 37 |    450 | GPU
DEBUG 01-06 08:44:46.854260.854260 lmp.py:380]   Expert 22 |    479 | GPU
DEBUG 01-06 08:44:46.854095.854095 lmp.py:380]   Expert 58 |    551 | GPU
DEBUG 01-06 08:44:46.854182.854182 lmp.py:380]   Expert 11 |    662 | GPU
INFO 01-06 08:44:46.854722.854722 client.py:127] Model loaded
DEBUG 01-06 08:44:46.854322.854322 lmp.py:380]   Expert 30 |   1547 | GPU
DEBUG 01-06 08:44:46.855009.855009 cuda_h.py:19] end sllm_worker_task cost 0.011593341827392578 seconds
DEBUG 01-06 08:44:46.855243.855243 lmp.py:381] 
DEBUG 01-06 08:44:46.855243.855243 lmp.py:381]   CPU total tokens: 1816 (14.8%)
DEBUG 01-06 08:44:46.855043.855043 lmp.py:382]   GPU total tokens: 10472 (85.2%)
DEBUG 01-06 08:44:46.855514.855514 cuda_h.py:19] end experts_map_get cost 0.002262592315673828 seconds
DEBUG 01-06 08:44:46.855303.855303 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.855848.855848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.855276.855276 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.855786.855786 cuda_h.py:19] end allocate_cuda_memory cost 0.00016927719116210938 seconds
DEBUG 01-06 08:44:46.855199.855199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.855763.855763 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.855194.855194 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.855513.855513 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f0934db-d2b3-46d2-a85c-9ea9f1ad1c87
DEBUG 01-06 08:44:46.856459.856459 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:46.857309.857309 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f0934db-d2b3-46d2-a85c-9ea9f1ad1c87
DEBUG 01-06 08:44:46.857714.857714 cuda_h.py:19] end load_into_gpu_async cost 0.0017197132110595703 seconds
DEBUG 01-06 08:44:46.857795.857795 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.857560.857560 cuda_h.py:19] end restore_tensors2 cost 0.0002942085266113281 seconds
DEBUG 01-06 08:44:46.857429.857429 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025107860565185547 seconds
DEBUG 01-06 08:44:46.860322.860322 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005072832107543945 seconds
DEBUG 01-06 08:44:46.860489.860489 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.860213.860213 lmp.py:427] 
DEBUG 01-06 08:44:46.860213.860213 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.860772.860772 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-06 08:44:46.860090.860090 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.870253.870253 mlpmodule.py:704] group tensors cost 0.009466171264648438 s
DEBUG 01-06 08:44:46.872862.872862 mlpmodule.py:742] pad cost 0.0014717578887939453 s
DEBUG 01-06 08:44:46.872236.872236 mlpmodule.py:748] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-06 08:44:46.872563.872563 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-06 08:44:46.882055.882055 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.882452.882452 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.883648.883648 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-06 08:44:46.883917.883917 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.902287.902287 mlpmodule.py:793] group einsum cost 0.029454946517944336 s
DEBUG 01-06 08:44:46.902007.902007 mlpmodule.py:801] cpy2cputensor cost 0.0005323886871337891 s
DEBUG 01-06 08:44:46.907606.907606 cuda_h.py:19] end wait_cetm_experts cost 0.046998023986816406 seconds
DEBUG 01-06 08:44:46.907192.907192 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.909119.909119 cuda_h.py:19] end gpu_sexperts cost 0.0011661052703857422 seconds
DEBUG 01-06 08:44:46.909486.909486 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.909528.909528 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-06 08:44:46.909853.909853 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.909278.909278 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f0934db-d2b3-46d2-a85c-9ea9f1ad1c87
INFO 01-06 08:44:46.914957.914957 client.py:127] Model loaded
DEBUG 01-06 08:44:46.914052.914052 cuda_h.py:19] end wait_experts cost 0.005310773849487305 seconds
DEBUG 01-06 08:44:46.914715.914715 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.914140.914140 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:46.921243.921243 mlpmodule.py:662]  experts func einsum cost 0.06059885025024414 s
DEBUG 01-06 08:44:46.926065.926065 cuda_h.py:19] end gpu_experts cost 0.012192010879516602 seconds
DEBUG 01-06 08:44:46.926208.926208 cuda_h.py:19] end layer_moe_generate_11 cost 0.07459759712219238 seconds
DEBUG 01-06 08:44:46.927425.927425 lmp.py:221] -------------------------------- end layer 11 --------------------------------
DEBUG 01-06 08:44:46.927049.927049 lmp.py:177] -------------------------------- start layer 12 --------------------------------
DEBUG 01-06 08:44:46.927891.927891 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 08:44:46.927600.927600 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 08:44:46.927867.927867 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.8371810913085938e-05 seconds
DEBUG 01-06 08:44:46.927093.927093 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.936622619628906e-05 seconds
DEBUG 01-06 08:44:46.927882.927882 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:46.927768.927768 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:46.927214.927214 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.927412.927412 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.928588.928588 cuda_h.py:19] end allocate_cuda_memory cost 0.0005433559417724609 seconds
DEBUG 01-06 08:44:46.928534.928534 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.928458.928458 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:46.928310.928310 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.929280.929280 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d6bed787-6093-4be2-8ff3-39f582b25a39
DEBUG 01-06 08:44:46.929103.929103 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.929498.929498 cuda_h.py:10] start self_attn
INFO 01-06 08:44:46.930539.930539 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d6bed787-6093-4be2-8ff3-39f582b25a39
DEBUG 01-06 08:44:46.931936.931936 cuda_h.py:19] end load_into_gpu_async cost 0.0022084712982177734 seconds
DEBUG 01-06 08:44:46.931098.931098 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.931583.931583 cuda_h.py:19] end restore_tensors2 cost 0.00017118453979492188 seconds
DEBUG 01-06 08:44:46.931786.931786 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036962032318115234 seconds
INFO 01-06 08:44:46.932736.932736 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d6bed787-6093-4be2-8ff3-39f582b25a39
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:46.935012.935012 cuda_h.py:19] end self_attn cost 0.005647420883178711 seconds
DEBUG 01-06 08:44:46.935409.935409 cuda_h.py:19] end iln_self_attn_paln cost 0.008572578430175781 seconds
DEBUG 01-06 08:44:46.935689.935689 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-06 08:44:46.935882.935882 cuda_h.py:10] start gate
DEBUG 01-06 08:44:46.936984.936984 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-06 08:44:46.936913.936913 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:46.937758.937758 lmp.py:369] 
DEBUG 01-06 08:44:46.937758.937758 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:46.937852.937852 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:46.937031.937031 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:46.937357.937357 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:46.937622.937622 lmp.py:373] 
DEBUG 01-06 08:44:46.937622.937622 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:46.937365.937365 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:46.937306.937306 lmp.py:380]   Expert 22 |      3 | CPU
DEBUG 01-06 08:44:46.937810.937810 lmp.py:380]   Expert 51 |      4 | CPU
DEBUG 01-06 08:44:46.937837.937837 lmp.py:380]   Expert 44 |     14 | CPU
DEBUG 01-06 08:44:46.937864.937864 lmp.py:380]   Expert  4 |     15 | CPU
DEBUG 01-06 08:44:46.937892.937892 lmp.py:380]   Expert 12 |     17 | CPU
DEBUG 01-06 08:44:46.937727.937727 lmp.py:380]   Expert 34 |     17 | CPU
DEBUG 01-06 08:44:46.937039.937039 lmp.py:380]   Expert  0 |     20 | CPU
DEBUG 01-06 08:44:46.937827.937827 lmp.py:380]   Expert 16 |     24 | CPU
DEBUG 01-06 08:44:46.937901.937901 lmp.py:380]   Expert 11 |     25 | CPU
DEBUG 01-06 08:44:46.937974.937974 lmp.py:380]   Expert 29 |     25 | CPU
DEBUG 01-06 08:44:46.937571.937571 lmp.py:380]   Expert 13 |     28 | CPU
DEBUG 01-06 08:44:46.937644.937644 lmp.py:380]   Expert 27 |     36 | CPU
DEBUG 01-06 08:44:46.937480.937480 lmp.py:380]   Expert 45 |     38 | CPU
DEBUG 01-06 08:44:46.937553.937553 lmp.py:380]   Expert 32 |     42 | CPU
DEBUG 01-06 08:44:46.937626.937626 lmp.py:380]   Expert  8 |     43 | CPU
DEBUG 01-06 08:44:46.937415.937415 lmp.py:380]   Expert 41 |     54 | CPU
DEBUG 01-06 08:44:46.937012.937012 lmp.py:380]   Expert 63 |     60 | CPU
DEBUG 01-06 08:44:46.937085.937085 lmp.py:380]   Expert 23 |     62 | CPU
DEBUG 01-06 08:44:46.937444.937444 lmp.py:380]   Expert  2 |     63 | CPU
DEBUG 01-06 08:44:46.937378.937378 lmp.py:380]   Expert 37 |     65 | CPU
DEBUG 01-06 08:44:46.937452.937452 lmp.py:380]   Expert 47 |     71 | CPU
DEBUG 01-06 08:44:46.937048.937048 lmp.py:380]   Expert 49 |     79 | CPU
DEBUG 01-06 08:44:46.937075.937075 lmp.py:380]   Expert 55 |     87 | CPU
DEBUG 01-06 08:44:46.937910.937910 lmp.py:380]   Expert  3 |     90 | CPU
DEBUG 01-06 08:44:46.937746.937746 lmp.py:380]   Expert 30 |     91 | CPU
DEBUG 01-06 08:44:46.937342.937342 lmp.py:380]   Expert 38 |     93 | CPU
DEBUG 01-06 08:44:46.937939.937939 lmp.py:380]   Expert 62 |     93 | CPU
DEBUG 01-06 08:44:46.937251.937251 lmp.py:380]   Expert 31 |    112 | CPU
DEBUG 01-06 08:44:46.937563.937563 lmp.py:380]   Expert  7 |    118 | CPU
DEBUG 01-06 08:44:46.937398.937398 lmp.py:380]   Expert 35 |    120 | CPU
DEBUG 01-06 08:44:46.937994.937994 lmp.py:380]   Expert 61 |    127 | CPU
DEBUG 01-06 08:44:46.937068.937068 lmp.py:380]   Expert 46 |    129 | CPU
DEBUG 01-06 08:44:46.937426.937426 lmp.py:380]   Expert 14 |    138 | GPU
DEBUG 01-06 08:44:46.937546.937546 lmp.py:380]   Expert 42 |    144 | GPU
DEBUG 01-06 08:44:46.937143.937143 lmp.py:380]   Expert 26 |    147 | GPU
DEBUG 01-06 08:44:46.937216.937216 lmp.py:380]   Expert 53 |    147 | GPU
DEBUG 01-06 08:44:46.937528.937528 lmp.py:380]   Expert 58 |    154 | GPU
DEBUG 01-06 08:44:46.937886.937886 lmp.py:380]   Expert  5 |    155 | GPU
DEBUG 01-06 08:44:46.937006.937006 lmp.py:380]   Expert 57 |    159 | GPU
DEBUG 01-06 08:44:46.937841.937841 lmp.py:380]   Expert 39 |    177 | GPU
DEBUG 01-06 08:44:46.937199.937199 lmp.py:380]   Expert 21 |    181 | GPU
DEBUG 01-06 08:44:46.937557.937557 lmp.py:380]   Expert 60 |    184 | GPU
DEBUG 01-06 08:44:46.937154.937154 lmp.py:380]   Expert 24 |    190 | GPU
DEBUG 01-06 08:44:46.937274.937274 lmp.py:380]   Expert 59 |    200 | GPU
DEBUG 01-06 08:44:46.938063.938063 lmp.py:380]   Expert 18 |    209 | GPU
DEBUG 01-06 08:44:46.938375.938375 lmp.py:380]   Expert 28 |    209 | GPU
DEBUG 01-06 08:44:46.938494.938494 lmp.py:380]   Expert  6 |    222 | GPU
DEBUG 01-06 08:44:46.938329.938329 lmp.py:380]   Expert 19 |    239 | GPU
DEBUG 01-06 08:44:46.938688.938688 lmp.py:380]   Expert 17 |    246 | GPU
DEBUG 01-06 08:44:46.938284.938284 lmp.py:380]   Expert 54 |    267 | GPU
DEBUG 01-06 08:44:46.938119.938119 lmp.py:380]   Expert 43 |    270 | GPU
DEBUG 01-06 08:44:46.938716.938716 lmp.py:380]   Expert 20 |    282 | GPU
DEBUG 01-06 08:44:46.938028.938028 lmp.py:380]   Expert 52 |    282 | GPU
DEBUG 01-06 08:44:46.938340.938340 lmp.py:380]   Expert 50 |    298 | GPU
DEBUG 01-06 08:44:46.938413.938413 lmp.py:380]   Expert 25 |    302 | GPU
DEBUG 01-06 08:44:46.938772.938772 lmp.py:380]   Expert 48 |    312 | GPU
DEBUG 01-06 08:44:46.938368.938368 lmp.py:380]   Expert 40 |    333 | GPU
DEBUG 01-06 08:44:46.938965.938965 lmp.py:380]   Expert  1 |    376 | GPU
DEBUG 01-06 08:44:46.938323.938323 lmp.py:380]   Expert 36 |    402 | GPU
DEBUG 01-06 08:44:46.938681.938681 lmp.py:380]   Expert  9 |    478 | GPU
DEBUG 01-06 08:44:46.938278.938278 lmp.py:380]   Expert 15 |    664 | GPU
DEBUG 01-06 08:44:46.938875.938875 lmp.py:380]   Expert 56 |    740 | GPU
DEBUG 01-06 08:44:46.938948.938948 lmp.py:380]   Expert 33 |    788 | GPU
DEBUG 01-06 08:44:46.938049.938049 lmp.py:380]   Expert 10 |   1528 | GPU
DEBUG 01-06 08:44:46.938361.938361 lmp.py:381] 
DEBUG 01-06 08:44:46.938361.938361 lmp.py:381]   CPU total tokens: 1865 (15.2%)
DEBUG 01-06 08:44:46.938765.938765 lmp.py:382]   GPU total tokens: 10423 (84.8%)
DEBUG 01-06 08:44:46.938276.938276 cuda_h.py:19] end experts_map_get cost 0.0017101764678955078 seconds
DEBUG 01-06 08:44:46.938542.938542 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:46.938709.938709 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:46.938892.938892 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:46.938191.938191 cuda_h.py:19] end allocate_cuda_memory cost 0.00018548965454101562 seconds
DEBUG 01-06 08:44:46.938895.938895 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:46.938526.938526 sllm_store_c.py:27] get device uuid map
INFO 01-06 08:44:46.939066.939066 client.py:127] Model loaded
DEBUG 01-06 08:44:46.939409.939409 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:46.939706.939706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fba86b1e-19d1-4a41-9c78-887d7e54caa9
DEBUG 01-06 08:44:46.939376.939376 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:46.939942.939942 cuda_h.py:19] end sllm_worker_task cost 0.011688470840454102 seconds
INFO 01-06 08:44:46.941066.941066 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fba86b1e-19d1-4a41-9c78-887d7e54caa9
DEBUG 01-06 08:44:46.941327.941327 cuda_h.py:19] end load_into_gpu_async cost 0.0021653175354003906 seconds
DEBUG 01-06 08:44:46.941182.941182 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:46.941941.941941 cuda_h.py:19] end restore_tensors2 cost 0.0002875328063964844 seconds
DEBUG 01-06 08:44:46.941287.941287 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029990673065185547 seconds
DEBUG 01-06 08:44:46.944410.944410 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005525827407836914 seconds
DEBUG 01-06 08:44:46.944809.944809 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:46.944885.944885 lmp.py:427] 
DEBUG 01-06 08:44:46.944885.944885 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:46.944012.944012 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-06 08:44:46.944139.944139 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:46.954235.954235 mlpmodule.py:704] group tensors cost 0.0104217529296875 s
DEBUG 01-06 08:44:46.957182.957182 mlpmodule.py:742] pad cost 0.002077341079711914 s
DEBUG 01-06 08:44:46.957398.957398 mlpmodule.py:748] create cpu tensor cost 5.125999450683594e-05 s
DEBUG 01-06 08:44:46.957520.957520 mlpmodule.py:753] move to cpu cost 3.719329833984375e-05 s
DEBUG 01-06 08:44:46.969552.969552 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:46.969790.969790 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:46.969925.969925 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-06 08:44:46.969572.969572 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:46.988397.988397 mlpmodule.py:793] group einsum cost 0.03065013885498047 s
DEBUG 01-06 08:44:46.989079.989079 mlpmodule.py:801] cpy2cputensor cost 0.0005741119384765625 s
DEBUG 01-06 08:44:46.994768.994768 cuda_h.py:19] end wait_cetm_experts cost 0.04999852180480957 seconds
DEBUG 01-06 08:44:46.994645.994645 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:46.994179.994179 cuda_h.py:19] end gpu_sexperts cost 0.00045609474182128906 seconds
DEBUG 01-06 08:44:46.994830.994830 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:46.994156.994156 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6702880859375e-05 seconds
DEBUG 01-06 08:44:46.995528.995528 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:46.995191.995191 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fba86b1e-19d1-4a41-9c78-887d7e54caa9
INFO 01-06 08:44:46.999121.999121 client.py:127] Model loaded
DEBUG 01-06 08:44:46.999746.999746 cuda_h.py:19] end wait_experts cost 0.0040950775146484375 seconds
DEBUG 01-06 08:44:46.999363.999363 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:46.999788.999788 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.008309.008309 mlpmodule.py:662]  experts func einsum cost 0.06428885459899902 s
DEBUG 01-06 08:44:47.011194.011194 cuda_h.py:19] end gpu_experts cost 0.012722492218017578 seconds
DEBUG 01-06 08:44:47.012052.012052 cuda_h.py:19] end layer_moe_generate_12 cost 0.07607650756835938 seconds
DEBUG 01-06 08:44:47.012753.012753 lmp.py:221] -------------------------------- end layer 12 --------------------------------
DEBUG 01-06 08:44:47.012185.012185 lmp.py:177] -------------------------------- start layer 13 --------------------------------
DEBUG 01-06 08:44:47.012026.012026 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 08:44:47.012736.012736 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 08:44:47.012864.012864 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:47.012342.012342 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.081031799316406e-05 seconds
DEBUG 01-06 08:44:47.012727.012727 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.012409.012409 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.012114.012114 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.013477.013477 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.013327.013327 cuda_h.py:19] end allocate_cuda_memory cost 0.0005309581756591797 seconds
DEBUG 01-06 08:44:47.013643.013643 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.014376.014376 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.014089.014089 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.014748.014748 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 34968e03-77f3-4b57-9dd0-22609ea2cb03
DEBUG 01-06 08:44:47.014769.014769 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.014360.014360 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.016623.016623 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 34968e03-77f3-4b57-9dd0-22609ea2cb03
DEBUG 01-06 08:44:47.016974.016974 cuda_h.py:19] end load_into_gpu_async cost 0.002229452133178711 seconds
DEBUG 01-06 08:44:47.016466.016466 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.016522.016522 cuda_h.py:19] end restore_tensors2 cost 0.00017595291137695312 seconds
DEBUG 01-06 08:44:47.016241.016241 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003704071044921875 seconds
INFO 01-06 08:44:47.018607.018607 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 34968e03-77f3-4b57-9dd0-22609ea2cb03
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.020473.020473 cuda_h.py:19] end self_attn cost 0.005601167678833008 seconds
DEBUG 01-06 08:44:47.021187.021187 cuda_h.py:19] end iln_self_attn_paln cost 0.008549213409423828 seconds
DEBUG 01-06 08:44:47.021282.021282 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-06 08:44:47.021906.021906 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.021876.021876 cuda_h.py:19] end gate cost 0.0006451606750488281 seconds
DEBUG 01-06 08:44:47.021228.021228 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.022921.022921 lmp.py:369] 
DEBUG 01-06 08:44:47.022921.022921 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.022538.022538 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.022048.022048 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.022460.022460 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.022917.022917 lmp.py:373] 
DEBUG 01-06 08:44:47.022917.022917 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.022898.022898 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.022601.022601 lmp.py:380]   Expert  6 |      1 | CPU
DEBUG 01-06 08:44:47.022820.022820 lmp.py:380]   Expert 53 |      1 | CPU
DEBUG 01-06 08:44:47.022609.022609 lmp.py:380]   Expert 50 |     11 | CPU
DEBUG 01-06 08:44:47.022159.022159 lmp.py:380]   Expert  0 |     23 | CPU
DEBUG 01-06 08:44:47.022710.022710 lmp.py:380]   Expert  2 |     28 | CPU
DEBUG 01-06 08:44:47.022498.022498 lmp.py:380]   Expert 31 |     33 | CPU
DEBUG 01-06 08:44:47.022095.022095 lmp.py:380]   Expert 26 |     34 | CPU
DEBUG 01-06 08:44:47.022381.022381 lmp.py:380]   Expert 12 |     35 | CPU
DEBUG 01-06 08:44:47.022931.022931 lmp.py:380]   Expert  8 |     45 | CPU
DEBUG 01-06 08:44:47.022720.022720 lmp.py:380]   Expert 40 |     46 | CPU
DEBUG 01-06 08:44:47.022032.022032 lmp.py:380]   Expert 32 |     47 | CPU
DEBUG 01-06 08:44:47.022821.022821 lmp.py:380]   Expert 34 |     47 | CPU
DEBUG 01-06 08:44:47.022848.022848 lmp.py:380]   Expert 19 |     54 | CPU
DEBUG 01-06 08:44:47.022398.022398 lmp.py:380]   Expert 16 |     55 | CPU
DEBUG 01-06 08:44:47.022949.022949 lmp.py:380]   Expert 20 |     58 | CPU
DEBUG 01-06 08:44:47.022784.022784 lmp.py:380]   Expert 13 |     62 | CPU
DEBUG 01-06 08:44:47.022857.022857 lmp.py:380]   Expert 45 |     65 | CPU
DEBUG 01-06 08:44:47.022931.022931 lmp.py:380]   Expert 28 |     69 | CPU
DEBUG 01-06 08:44:47.022481.022481 lmp.py:380]   Expert 57 |     75 | CPU
DEBUG 01-06 08:44:47.022323.022323 lmp.py:380]   Expert 30 |     76 | CPU
DEBUG 01-06 08:44:47.022873.022873 lmp.py:380]   Expert  9 |     77 | CPU
DEBUG 01-06 08:44:47.022569.022569 lmp.py:380]   Expert 61 |     82 | CPU
DEBUG 01-06 08:44:47.022881.022881 lmp.py:380]   Expert 25 |     87 | CPU
DEBUG 01-06 08:44:47.022431.022431 lmp.py:380]   Expert 63 |     89 | CPU
DEBUG 01-06 08:44:47.022267.022267 lmp.py:380]   Expert 24 |     90 | CPU
DEBUG 01-06 08:44:47.022340.022340 lmp.py:380]   Expert 11 |     91 | CPU
DEBUG 01-06 08:44:47.022175.022175 lmp.py:380]   Expert 35 |     92 | CPU
DEBUG 01-06 08:44:47.022725.022725 lmp.py:380]   Expert  5 |     94 | CPU
DEBUG 01-06 08:44:47.022799.022799 lmp.py:380]   Expert 48 |    102 | CPU
DEBUG 01-06 08:44:47.022111.022111 lmp.py:380]   Expert 58 |    108 | CPU
DEBUG 01-06 08:44:47.022900.022900 lmp.py:380]   Expert 60 |    109 | CPU
DEBUG 01-06 08:44:47.022450.022450 lmp.py:380]   Expert 52 |    134 | CPU
DEBUG 01-06 08:44:47.022762.022762 lmp.py:380]   Expert 49 |    147 | GPU
DEBUG 01-06 08:44:47.022358.022358 lmp.py:380]   Expert 62 |    153 | GPU
DEBUG 01-06 08:44:47.023670.023670 lmp.py:380]   Expert  3 |    160 | GPU
DEBUG 01-06 08:44:47.023744.023744 lmp.py:380]   Expert 42 |    171 | GPU
DEBUG 01-06 08:44:47.023817.023817 lmp.py:380]   Expert 36 |    185 | GPU
DEBUG 01-06 08:44:47.023129.023129 lmp.py:380]   Expert 37 |    185 | GPU
DEBUG 01-06 08:44:47.023441.023441 lmp.py:380]   Expert 44 |    189 | GPU
DEBUG 01-06 08:44:47.023515.023515 lmp.py:380]   Expert 46 |    197 | GPU
DEBUG 01-06 08:44:47.023542.023542 lmp.py:380]   Expert 54 |    198 | GPU
DEBUG 01-06 08:44:47.023092.023092 lmp.py:380]   Expert  4 |    200 | GPU
DEBUG 01-06 08:44:47.023358.023358 lmp.py:380]   Expert  1 |    209 | GPU
DEBUG 01-06 08:44:47.023385.023385 lmp.py:380]   Expert 27 |    209 | GPU
DEBUG 01-06 08:44:47.023412.023412 lmp.py:380]   Expert 51 |    216 | GPU
DEBUG 01-06 08:44:47.023201.023201 lmp.py:380]   Expert 43 |    217 | GPU
DEBUG 01-06 08:44:47.023751.023751 lmp.py:380]   Expert 33 |    236 | GPU
DEBUG 01-06 08:44:47.023540.023540 lmp.py:380]   Expert 15 |    245 | GPU
DEBUG 01-06 08:44:47.023296.023296 lmp.py:380]   Expert 59 |    245 | GPU
DEBUG 01-06 08:44:47.023654.023654 lmp.py:380]   Expert 17 |    293 | GPU
DEBUG 01-06 08:44:47.023297.023297 lmp.py:380]   Expert 39 |    328 | GPU
DEBUG 01-06 08:44:47.023748.023748 lmp.py:380]   Expert 22 |    334 | GPU
DEBUG 01-06 08:44:47.023345.023345 lmp.py:380]   Expert 29 |    343 | GPU
DEBUG 01-06 08:44:47.023180.023180 lmp.py:380]   Expert 47 |    361 | GPU
DEBUG 01-06 08:44:47.023015.023015 lmp.py:380]   Expert  7 |    385 | GPU
DEBUG 01-06 08:44:47.023327.023327 lmp.py:380]   Expert 14 |    417 | GPU
DEBUG 01-06 08:44:47.023115.023115 lmp.py:380]   Expert 10 |    422 | GPU
DEBUG 01-06 08:44:47.023904.023904 lmp.py:380]   Expert 55 |    434 | GPU
DEBUG 01-06 08:44:47.023454.023454 lmp.py:380]   Expert 38 |    435 | GPU
DEBUG 01-06 08:44:47.023051.023051 lmp.py:380]   Expert 21 |    476 | GPU
DEBUG 01-06 08:44:47.023363.023363 lmp.py:380]   Expert 56 |    520 | GPU
DEBUG 01-06 08:44:47.023198.023198 lmp.py:380]   Expert 41 |    584 | GPU
DEBUG 01-06 08:44:47.023510.023510 lmp.py:380]   Expert 18 |    785 | GPU
DEBUG 01-06 08:44:47.023822.023822 lmp.py:380]   Expert 23 |    789 | GPU
DEBUG 01-06 08:44:47.023326.023326 lmp.py:381] 
DEBUG 01-06 08:44:47.023326.023326 lmp.py:381]   CPU total tokens: 2020 (16.4%)
DEBUG 01-06 08:44:47.023591.023591 lmp.py:382]   GPU total tokens: 10268 (83.6%)
DEBUG 01-06 08:44:47.023149.023149 cuda_h.py:19] end experts_map_get cost 0.0017344951629638672 seconds
DEBUG 01-06 08:44:47.023891.023891 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.023105.023105 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.023440.023440 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.024821.024821 cuda_h.py:19] end allocate_cuda_memory cost 0.0002446174621582031 seconds
DEBUG 01-06 08:44:47.024048.024048 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.024234.024234 sllm_store_c.py:27] get device uuid map
INFO 01-06 08:44:47.024987.024987 client.py:127] Model loaded
DEBUG 01-06 08:44:47.024901.024901 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.024848.024848 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e19224b4-fe8a-43f9-a6ca-44db4bf708ab
DEBUG 01-06 08:44:47.024915.024915 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.024070.024070 cuda_h.py:19] end sllm_worker_task cost 0.011779069900512695 seconds
INFO 01-06 08:44:47.026516.026516 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e19224b4-fe8a-43f9-a6ca-44db4bf708ab
DEBUG 01-06 08:44:47.026771.026771 cuda_h.py:19] end load_into_gpu_async cost 0.0019693374633789062 seconds
DEBUG 01-06 08:44:47.026004.026004 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.026253.026253 cuda_h.py:19] end restore_tensors2 cost 0.0002987384796142578 seconds
DEBUG 01-06 08:44:47.026360.026360 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028667449951171875 seconds
DEBUG 01-06 08:44:47.029891.029891 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005512237548828125 seconds
DEBUG 01-06 08:44:47.029251.029251 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.029882.029882 lmp.py:427] 
DEBUG 01-06 08:44:47.029882.029882 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.029679.029679 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-06 08:44:47.029190.029190 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.036224.036224 mlpmodule.py:704] group tensors cost 0.0073964595794677734 s
DEBUG 01-06 08:44:47.040583.040583 mlpmodule.py:742] pad cost 0.0023469924926757812 s
DEBUG 01-06 08:44:47.040587.040587 mlpmodule.py:748] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-06 08:44:47.040483.040483 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 08:44:47.051632.051632 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.051870.051870 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.052820.052820 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-06 08:44:47.052043.052043 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.073579.073579 mlpmodule.py:793] group einsum cost 0.033226728439331055 s
DEBUG 01-06 08:44:47.074089.074089 mlpmodule.py:801] cpy2cputensor cost 0.0005948543548583984 s
DEBUG 01-06 08:44:47.079066.079066 cuda_h.py:19] end wait_cetm_experts cost 0.05003809928894043 seconds
DEBUG 01-06 08:44:47.079188.079188 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.080213.080213 cuda_h.py:19] end gpu_sexperts cost 0.0010981559753417969 seconds
DEBUG 01-06 08:44:47.080824.080824 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.080489.080489 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.765655517578125e-05 seconds
DEBUG 01-06 08:44:47.080006.080006 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.080431.080431 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e19224b4-fe8a-43f9-a6ca-44db4bf708ab
INFO 01-06 08:44:47.083232.083232 client.py:127] Model loaded
DEBUG 01-06 08:44:47.083373.083373 cuda_h.py:19] end wait_experts cost 0.002415180206298828 seconds
DEBUG 01-06 08:44:47.083083.083083 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.083316.083316 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.095206.095206 mlpmodule.py:662]  experts func einsum cost 0.0660085678100586 s
DEBUG 01-06 08:44:47.096688.096688 cuda_h.py:19] end gpu_experts cost 0.012692928314208984 seconds
DEBUG 01-06 08:44:47.096163.096163 cuda_h.py:19] end layer_moe_generate_13 cost 0.0751190185546875 seconds
DEBUG 01-06 08:44:47.096522.096522 lmp.py:221] -------------------------------- end layer 13 --------------------------------
DEBUG 01-06 08:44:47.096557.096557 lmp.py:177] -------------------------------- start layer 14 --------------------------------
DEBUG 01-06 08:44:47.096882.096882 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 08:44:47.096791.096791 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 08:44:47.096032.096032 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.600120544433594e-05 seconds
DEBUG 01-06 08:44:47.096695.096695 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.557868957519531e-05 seconds
DEBUG 01-06 08:44:47.096775.096775 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.096973.096973 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.097969.097969 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.097094.097094 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.098190.098190 cuda_h.py:19] end allocate_cuda_memory cost 0.0005710124969482422 seconds
DEBUG 01-06 08:44:47.098932.098932 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.098426.098426 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.098318.098318 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.098070.098070 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9badc71e-b984-4dcd-bdef-5338e8711353
DEBUG 01-06 08:44:47.098137.098137 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.099796.099796 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.100023.100023 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9badc71e-b984-4dcd-bdef-5338e8711353
DEBUG 01-06 08:44:47.100837.100837 cuda_h.py:19] end load_into_gpu_async cost 0.002371072769165039 seconds
DEBUG 01-06 08:44:47.100304.100304 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.101650.101650 cuda_h.py:19] end restore_tensors2 cost 0.0001709461212158203 seconds
DEBUG 01-06 08:44:47.101899.101899 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003907442092895508 seconds
INFO 01-06 08:44:47.102554.102554 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9badc71e-b984-4dcd-bdef-5338e8711353
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.105568.105568 cuda_h.py:19] end self_attn cost 0.005897998809814453 seconds
DEBUG 01-06 08:44:47.105809.105809 cuda_h.py:19] end iln_self_attn_paln cost 0.008869171142578125 seconds
DEBUG 01-06 08:44:47.105917.105917 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-06 08:44:47.105032.105032 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.106755.106755 cuda_h.py:19] end gate cost 0.0008051395416259766 seconds
DEBUG 01-06 08:44:47.106122.106122 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.107567.107567 lmp.py:369] 
DEBUG 01-06 08:44:47.107567.107567 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.107382.107382 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.107138.107138 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.107080.107080 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.107875.107875 lmp.py:373] 
DEBUG 01-06 08:44:47.107875.107875 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.107101.107101 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.107718.107718 lmp.py:380]   Expert 61 |      2 | CPU
DEBUG 01-06 08:44:47.107421.107421 lmp.py:380]   Expert  7 |      4 | CPU
DEBUG 01-06 08:44:47.107217.107217 lmp.py:380]   Expert 49 |     26 | CPU
DEBUG 01-06 08:44:47.107535.107535 lmp.py:380]   Expert 48 |     27 | CPU
DEBUG 01-06 08:44:47.107139.107139 lmp.py:380]   Expert 59 |     32 | CPU
DEBUG 01-06 08:44:47.107696.107696 lmp.py:380]   Expert 38 |     38 | CPU
DEBUG 01-06 08:44:47.107936.107936 lmp.py:380]   Expert 50 |     38 | CPU
DEBUG 01-06 08:44:47.107777.107777 lmp.py:380]   Expert 55 |     40 | CPU
DEBUG 01-06 08:44:47.107189.107189 lmp.py:380]   Expert 40 |     43 | CPU
DEBUG 01-06 08:44:47.107362.107362 lmp.py:380]   Expert 32 |     44 | CPU
DEBUG 01-06 08:44:47.107296.107296 lmp.py:380]   Expert 17 |     53 | CPU
DEBUG 01-06 08:44:47.107946.107946 lmp.py:380]   Expert 18 |     55 | CPU
DEBUG 01-06 08:44:47.107119.107119 lmp.py:380]   Expert 43 |     64 | CPU
DEBUG 01-06 08:44:47.107530.107530 lmp.py:380]   Expert 20 |     72 | CPU
DEBUG 01-06 08:44:47.107465.107465 lmp.py:380]   Expert 29 |     83 | CPU
DEBUG 01-06 08:44:47.107068.107068 lmp.py:380]   Expert 35 |     83 | CPU
DEBUG 01-06 08:44:47.107910.107910 lmp.py:380]   Expert 42 |     87 | CPU
DEBUG 01-06 08:44:47.107275.107275 lmp.py:380]   Expert 23 |     89 | CPU
DEBUG 01-06 08:44:47.107686.107686 lmp.py:380]   Expert 34 |     89 | CPU
DEBUG 01-06 08:44:47.107621.107621 lmp.py:380]   Expert 54 |     89 | CPU
DEBUG 01-06 08:44:47.107271.107271 lmp.py:380]   Expert  0 |    102 | CPU
DEBUG 01-06 08:44:47.107444.107444 lmp.py:380]   Expert 28 |    103 | CPU
DEBUG 01-06 08:44:47.107617.107617 lmp.py:380]   Expert 60 |    103 | CPU
DEBUG 01-06 08:44:47.107028.107028 lmp.py:380]   Expert 12 |    108 | CPU
DEBUG 01-06 08:44:47.107439.107439 lmp.py:380]   Expert 51 |    112 | CPU
DEBUG 01-06 08:44:47.107327.107327 lmp.py:380]   Expert 52 |    114 | CPU
DEBUG 01-06 08:44:47.107692.107692 lmp.py:380]   Expert  8 |    115 | CPU
DEBUG 01-06 08:44:47.107581.107581 lmp.py:380]   Expert 21 |    132 | CPU
DEBUG 01-06 08:44:47.107992.107992 lmp.py:380]   Expert 41 |    139 | CPU
DEBUG 01-06 08:44:47.107688.107688 lmp.py:380]   Expert 62 |    150 | CPU
DEBUG 01-06 08:44:47.108861.108861 lmp.py:380]   Expert 30 |    161 | CPU
DEBUG 01-06 08:44:47.108272.108272 lmp.py:380]   Expert 57 |    166 | CPU
DEBUG 01-06 08:44:47.108922.108922 lmp.py:380]   Expert 39 |    183 | GPU
DEBUG 01-06 08:44:47.108572.108572 lmp.py:380]   Expert  6 |    186 | GPU
DEBUG 01-06 08:44:47.108745.108745 lmp.py:380]   Expert 16 |    194 | GPU
DEBUG 01-06 08:44:47.108395.108395 lmp.py:380]   Expert 53 |    200 | GPU
DEBUG 01-06 08:44:47.108283.108283 lmp.py:380]   Expert 46 |    207 | GPU
DEBUG 01-06 08:44:47.108694.108694 lmp.py:380]   Expert 27 |    211 | GPU
DEBUG 01-06 08:44:47.108867.108867 lmp.py:380]   Expert 19 |    218 | GPU
DEBUG 01-06 08:44:47.108040.108040 lmp.py:380]   Expert 11 |    224 | GPU
DEBUG 01-06 08:44:47.108213.108213 lmp.py:380]   Expert 33 |    225 | GPU
DEBUG 01-06 08:44:47.108147.108147 lmp.py:380]   Expert 58 |    225 | GPU
DEBUG 01-06 08:44:47.108559.108559 lmp.py:380]   Expert 45 |    243 | GPU
DEBUG 01-06 08:44:47.108493.108493 lmp.py:380]   Expert 14 |    253 | GPU
DEBUG 01-06 08:44:47.108905.108905 lmp.py:380]   Expert  3 |    254 | GPU
DEBUG 01-06 08:44:47.108793.108793 lmp.py:380]   Expert  1 |    262 | GPU
DEBUG 01-06 08:44:47.108158.108158 lmp.py:380]   Expert 37 |    267 | GPU
DEBUG 01-06 08:44:47.108675.108675 lmp.py:380]   Expert 13 |    273 | GPU
DEBUG 01-06 08:44:47.108564.108564 lmp.py:380]   Expert 47 |    273 | GPU
DEBUG 01-06 08:44:47.108737.108737 lmp.py:380]   Expert 31 |    276 | GPU
DEBUG 01-06 08:44:47.108433.108433 lmp.py:380]   Expert 56 |    306 | GPU
DEBUG 01-06 08:44:47.108606.108606 lmp.py:380]   Expert 44 |    312 | GPU
DEBUG 01-06 08:44:47.108017.108017 lmp.py:380]   Expert 63 |    314 | GPU
DEBUG 01-06 08:44:47.108428.108428 lmp.py:380]   Expert 22 |    318 | GPU
DEBUG 01-06 08:44:47.108886.108886 lmp.py:380]   Expert 26 |    348 | GPU
DEBUG 01-06 08:44:47.108297.108297 lmp.py:380]   Expert 15 |    352 | GPU
DEBUG 01-06 08:44:47.108662.108662 lmp.py:380]   Expert  4 |    362 | GPU
DEBUG 01-06 08:44:47.108550.108550 lmp.py:380]   Expert 36 |    369 | GPU
DEBUG 01-06 08:44:47.108677.108677 lmp.py:380]   Expert  2 |    383 | GPU
DEBUG 01-06 08:44:47.108625.108625 lmp.py:380]   Expert  5 |    390 | GPU
DEBUG 01-06 08:44:47.108560.108560 lmp.py:380]   Expert 25 |    427 | GPU
DEBUG 01-06 08:44:47.108971.108971 lmp.py:380]   Expert  9 |    481 | GPU
DEBUG 01-06 08:44:47.108144.108144 lmp.py:380]   Expert 10 |    583 | GPU
DEBUG 01-06 08:44:47.108555.108555 lmp.py:380]   Expert 24 |    606 | GPU
DEBUG 01-06 08:44:47.108159.108159 lmp.py:381] 
DEBUG 01-06 08:44:47.108159.108159 lmp.py:381]   CPU total tokens: 2563 (20.9%)
DEBUG 01-06 08:44:47.108239.108239 lmp.py:382]   GPU total tokens: 9725 (79.1%)
DEBUG 01-06 08:44:47.108757.108757 cuda_h.py:19] end experts_map_get cost 0.002115964889526367 seconds
DEBUG 01-06 08:44:47.108506.108506 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.108939.108939 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.109356.109356 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.109730.109730 cuda_h.py:19] end allocate_cuda_memory cost 0.00023484230041503906 seconds
DEBUG 01-06 08:44:47.109301.109301 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.109018.109018 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.109847.109847 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.109557.109557 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de0cbf19-cfc6-4f47-a26a-c397ca2ff0c7
DEBUG 01-06 08:44:47.109068.109068 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.110813.110813 client.py:127] Model loaded
DEBUG 01-06 08:44:47.110161.110161 cuda_h.py:19] end sllm_worker_task cost 0.013267278671264648 seconds
INFO 01-06 08:44:47.112602.112602 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de0cbf19-cfc6-4f47-a26a-c397ca2ff0c7
DEBUG 01-06 08:44:47.112296.112296 cuda_h.py:19] end load_into_gpu_async cost 0.0027501583099365234 seconds
DEBUG 01-06 08:44:47.112424.112424 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.113629.113629 cuda_h.py:19] end restore_tensors2 cost 0.0007107257843017578 seconds
DEBUG 01-06 08:44:47.113221.113221 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004247426986694336 seconds
DEBUG 01-06 08:44:47.118438.118438 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009979248046875 seconds
DEBUG 01-06 08:44:47.118222.118222 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.119055.119055 lmp.py:427] 
DEBUG 01-06 08:44:47.119055.119055 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.119496.119496 cuda_h.py:19] end cpu_experts_submit cost 0.00021839141845703125 seconds
DEBUG 01-06 08:44:47.119319.119319 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.126557.126557 mlpmodule.py:704] group tensors cost 0.0067369937896728516 s
DEBUG 01-06 08:44:47.129348.129348 mlpmodule.py:742] pad cost 0.0026903152465820312 s
DEBUG 01-06 08:44:47.129360.129360 mlpmodule.py:748] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-06 08:44:47.129595.129595 mlpmodule.py:753] move to cpu cost 4.291534423828125e-05 s
DEBUG 01-06 08:44:47.143639.143639 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.143426.143426 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.143402.143402 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-06 08:44:47.143313.143313 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.163986.163986 mlpmodule.py:793] group einsum cost 0.0337221622467041 s
DEBUG 01-06 08:44:47.164694.164694 mlpmodule.py:801] cpy2cputensor cost 0.0007755756378173828 s
DEBUG 01-06 08:44:47.169001.169001 cuda_h.py:19] end wait_cetm_experts cost 0.05035066604614258 seconds
DEBUG 01-06 08:44:47.169834.169834 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.171260.171260 cuda_h.py:19] end gpu_sexperts cost 0.0015344619750976562 seconds
DEBUG 01-06 08:44:47.171152.171152 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.171488.171488 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.9591064453125e-05 seconds
DEBUG 01-06 08:44:47.171351.171351 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.171214.171214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de0cbf19-cfc6-4f47-a26a-c397ca2ff0c7
INFO 01-06 08:44:47.173303.173303 client.py:127] Model loaded
DEBUG 01-06 08:44:47.173259.173259 cuda_h.py:19] end wait_experts cost 0.0015518665313720703 seconds
DEBUG 01-06 08:44:47.173969.173969 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.173440.173440 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.178314.178314 mlpmodule.py:662]  experts func einsum cost 0.05942535400390625 s
DEBUG 01-06 08:44:47.186360.186360 cuda_h.py:19] end gpu_experts cost 0.012434720993041992 seconds
DEBUG 01-06 08:44:47.186907.186907 cuda_h.py:19] end layer_moe_generate_14 cost 0.08035802841186523 seconds
DEBUG 01-06 08:44:47.186463.186463 lmp.py:221] -------------------------------- end layer 14 --------------------------------
DEBUG 01-06 08:44:47.186225.186225 lmp.py:177] -------------------------------- start layer 15 --------------------------------
DEBUG 01-06 08:44:47.186398.186398 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 08:44:47.186393.186393 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 08:44:47.186090.186090 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0040740966796875e-05 seconds
DEBUG 01-06 08:44:47.186362.186362 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.008148193359375e-05 seconds
DEBUG 01-06 08:44:47.186197.186197 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.186190.186190 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.186484.186484 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.187046.187046 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.187095.187095 cuda_h.py:19] end allocate_cuda_memory cost 0.0005359649658203125 seconds
DEBUG 01-06 08:44:47.187087.187087 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.188170.188170 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.188048.188048 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.188826.188826 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9473fa0a-8df6-4f85-adcc-f34f4c7543cc
DEBUG 01-06 08:44:47.188258.188258 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.188364.188364 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.190428.190428 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9473fa0a-8df6-4f85-adcc-f34f4c7543cc
DEBUG 01-06 08:44:47.190951.190951 cuda_h.py:19] end load_into_gpu_async cost 0.002536773681640625 seconds
DEBUG 01-06 08:44:47.190397.190397 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.190591.190591 cuda_h.py:19] end restore_tensors2 cost 0.00016927719116210938 seconds
DEBUG 01-06 08:44:47.191171.191171 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003972053527832031 seconds
INFO 01-06 08:44:47.192747.192747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9473fa0a-8df6-4f85-adcc-f34f4c7543cc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.194411.194411 cuda_h.py:19] end self_attn cost 0.005049943923950195 seconds
DEBUG 01-06 08:44:47.194621.194621 cuda_h.py:19] end iln_self_attn_paln cost 0.007866144180297852 seconds
DEBUG 01-06 08:44:47.194563.194563 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-06 08:44:47.194233.194233 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.195337.195337 cuda_h.py:19] end gate cost 0.0006742477416992188 seconds
DEBUG 01-06 08:44:47.195259.195259 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.195898.195898 lmp.py:369] 
DEBUG 01-06 08:44:47.195898.195898 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.195938.195938 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.195873.195873 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.195470.195470 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.195636.195636 lmp.py:373] 
DEBUG 01-06 08:44:47.195636.195636 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.195279.195279 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.195644.195644 lmp.py:380]   Expert 63 |      3 | CPU
DEBUG 01-06 08:44:47.195810.195810 lmp.py:380]   Expert 37 |     17 | CPU
DEBUG 01-06 08:44:47.195261.195261 lmp.py:380]   Expert  4 |     27 | CPU
DEBUG 01-06 08:44:47.195996.195996 lmp.py:380]   Expert  5 |     34 | CPU
DEBUG 01-06 08:44:47.195209.195209 lmp.py:380]   Expert 42 |     36 | CPU
DEBUG 01-06 08:44:47.195421.195421 lmp.py:380]   Expert 57 |     37 | CPU
DEBUG 01-06 08:44:47.195395.195395 lmp.py:380]   Expert 34 |     39 | CPU
DEBUG 01-06 08:44:47.195369.195369 lmp.py:380]   Expert 53 |     42 | CPU
DEBUG 01-06 08:44:47.195867.195867 lmp.py:380]   Expert 41 |     47 | CPU
DEBUG 01-06 08:44:47.195556.195556 lmp.py:380]   Expert 22 |     50 | CPU
DEBUG 01-06 08:44:47.195007.195007 lmp.py:380]   Expert 52 |     52 | CPU
DEBUG 01-06 08:44:47.195173.195173 lmp.py:380]   Expert 15 |     55 | CPU
DEBUG 01-06 08:44:47.195385.195385 lmp.py:380]   Expert 48 |     59 | CPU
DEBUG 01-06 08:44:47.195359.195359 lmp.py:380]   Expert 28 |     60 | CPU
DEBUG 01-06 08:44:47.195618.195618 lmp.py:380]   Expert 32 |     63 | CPU
DEBUG 01-06 08:44:47.195115.195115 lmp.py:380]   Expert  7 |     64 | CPU
DEBUG 01-06 08:44:47.195374.195374 lmp.py:380]   Expert 51 |     66 | CPU
DEBUG 01-06 08:44:47.195633.195633 lmp.py:380]   Expert 43 |     72 | CPU
DEBUG 01-06 08:44:47.195892.195892 lmp.py:380]   Expert 40 |     80 | CPU
DEBUG 01-06 08:44:47.195912.195912 lmp.py:380]   Expert 25 |     89 | CPU
DEBUG 01-06 08:44:47.195409.195409 lmp.py:380]   Expert 55 |     95 | CPU
DEBUG 01-06 08:44:47.195145.195145 lmp.py:380]   Expert 29 |     98 | CPU
DEBUG 01-06 08:44:47.196411.196411 lmp.py:380]   Expert  6 |    111 | CPU
DEBUG 01-06 08:44:47.196438.196438 lmp.py:380]   Expert 56 |    117 | CPU
DEBUG 01-06 08:44:47.196558.196558 lmp.py:380]   Expert 14 |    118 | CPU
DEBUG 01-06 08:44:47.196631.196631 lmp.py:380]   Expert 39 |    126 | CPU
DEBUG 01-06 08:44:47.196989.196989 lmp.py:380]   Expert 23 |    127 | CPU
DEBUG 01-06 08:44:47.196348.196348 lmp.py:380]   Expert 58 |    130 | CPU
DEBUG 01-06 08:44:47.196944.196944 lmp.py:380]   Expert 61 |    132 | CPU
DEBUG 01-06 08:44:47.196779.196779 lmp.py:380]   Expert 13 |    138 | CPU
DEBUG 01-06 08:44:47.196137.196137 lmp.py:380]   Expert 33 |    156 | CPU
DEBUG 01-06 08:44:47.196973.196973 lmp.py:380]   Expert 54 |    165 | CPU
DEBUG 01-06 08:44:47.196808.196808 lmp.py:380]   Expert 38 |    166 | GPU
DEBUG 01-06 08:44:47.196358.196358 lmp.py:380]   Expert 31 |    172 | GPU
DEBUG 01-06 08:44:47.196431.196431 lmp.py:380]   Expert 12 |    178 | GPU
DEBUG 01-06 08:44:47.196743.196743 lmp.py:380]   Expert 50 |    182 | GPU
DEBUG 01-06 08:44:47.196817.196817 lmp.py:380]   Expert  1 |    192 | GPU
DEBUG 01-06 08:44:47.196413.196413 lmp.py:380]   Expert  0 |    194 | GPU
DEBUG 01-06 08:44:47.196772.196772 lmp.py:380]   Expert 49 |    195 | GPU
DEBUG 01-06 08:44:47.196130.196130 lmp.py:380]   Expert 36 |    197 | GPU
DEBUG 01-06 08:44:47.196965.196965 lmp.py:380]   Expert 20 |    200 | GPU
DEBUG 01-06 08:44:47.196800.196800 lmp.py:380]   Expert 62 |    208 | GPU
DEBUG 01-06 08:44:47.196100.196100 lmp.py:380]   Expert 35 |    210 | GPU
DEBUG 01-06 08:44:47.196365.196365 lmp.py:380]   Expert 16 |    221 | GPU
DEBUG 01-06 08:44:47.196154.196154 lmp.py:380]   Expert 18 |    221 | GPU
DEBUG 01-06 08:44:47.196227.196227 lmp.py:380]   Expert 59 |    223 | GPU
DEBUG 01-06 08:44:47.196539.196539 lmp.py:380]   Expert 10 |    228 | GPU
DEBUG 01-06 08:44:47.196851.196851 lmp.py:380]   Expert  9 |    274 | GPU
DEBUG 01-06 08:44:47.196402.196402 lmp.py:380]   Expert 44 |    279 | GPU
DEBUG 01-06 08:44:47.196237.196237 lmp.py:380]   Expert 11 |    282 | GPU
DEBUG 01-06 08:44:47.196548.196548 lmp.py:380]   Expert 26 |    282 | GPU
DEBUG 01-06 08:44:47.196337.196337 lmp.py:380]   Expert 19 |    291 | GPU
DEBUG 01-06 08:44:47.196411.196411 lmp.py:380]   Expert 60 |    302 | GPU
DEBUG 01-06 08:44:47.196676.196676 lmp.py:380]   Expert 17 |    310 | GPU
DEBUG 01-06 08:44:47.196465.196465 lmp.py:380]   Expert 45 |    315 | GPU
DEBUG 01-06 08:44:47.196015.196015 lmp.py:380]   Expert 46 |    315 | GPU
DEBUG 01-06 08:44:47.196089.196089 lmp.py:380]   Expert 47 |    330 | GPU
DEBUG 01-06 08:44:47.196401.196401 lmp.py:380]   Expert  3 |    333 | GPU
DEBUG 01-06 08:44:47.196713.196713 lmp.py:380]   Expert 24 |    354 | GPU
DEBUG 01-06 08:44:47.196786.196786 lmp.py:380]   Expert 21 |    370 | GPU
DEBUG 01-06 08:44:47.196575.196575 lmp.py:380]   Expert  2 |    378 | GPU
DEBUG 01-06 08:44:47.196648.196648 lmp.py:380]   Expert 30 |    450 | GPU
DEBUG 01-06 08:44:47.196007.196007 lmp.py:380]   Expert 27 |    597 | GPU
DEBUG 01-06 08:44:47.196557.196557 lmp.py:380]   Expert  8 |   1334 | GPU
DEBUG 01-06 08:44:47.196538.196538 lmp.py:381] 
DEBUG 01-06 08:44:47.196538.196538 lmp.py:381]   CPU total tokens: 2505 (20.4%)
DEBUG 01-06 08:44:47.196803.196803 lmp.py:382]   GPU total tokens: 9783 (79.6%)
DEBUG 01-06 08:44:47.196599.196599 cuda_h.py:19] end experts_map_get cost 0.001627206802368164 seconds
DEBUG 01-06 08:44:47.196388.196388 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.196648.196648 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.197122.197122 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.197031.197031 cuda_h.py:19] end allocate_cuda_memory cost 0.00021409988403320312 seconds
DEBUG 01-06 08:44:47.197166.197166 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.197306.197306 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.197149.197149 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.197329.197329 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 267e5b0a-1788-488f-967c-3b61f9e52a9b
DEBUG 01-06 08:44:47.197527.197527 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.198679.198679 client.py:127] Model loaded
DEBUG 01-06 08:44:47.198655.198655 cuda_h.py:19] end sllm_worker_task cost 0.011430740356445312 seconds
INFO 01-06 08:44:47.199701.199701 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 267e5b0a-1788-488f-967c-3b61f9e52a9b
DEBUG 01-06 08:44:47.199022.199022 cuda_h.py:19] end load_into_gpu_async cost 0.0023832321166992188 seconds
DEBUG 01-06 08:44:47.199208.199208 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.200352.200352 cuda_h.py:19] end restore_tensors2 cost 0.0002894401550292969 seconds
DEBUG 01-06 08:44:47.200790.200790 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003240823745727539 seconds
DEBUG 01-06 08:44:47.202319.202319 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005816936492919922 seconds
DEBUG 01-06 08:44:47.202910.202910 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.202270.202270 lmp.py:427] 
DEBUG 01-06 08:44:47.202270.202270 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.202398.202398 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 08:44:47.202286.202286 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.214855.214855 mlpmodule.py:704] group tensors cost 0.011503458023071289 s
DEBUG 01-06 08:44:47.216689.216689 mlpmodule.py:742] pad cost 0.0015079975128173828 s
DEBUG 01-06 08:44:47.216964.216964 mlpmodule.py:748] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-06 08:44:47.216337.216337 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 08:44:47.227267.227267 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.227359.227359 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.227733.227733 mlpmodule.py:773] group_w3 first element: -0.0186767578125
WARNING 01-06 08:44:47.227956.227956 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.245184.245184 mlpmodule.py:793] group einsum cost 0.028388500213623047 s
DEBUG 01-06 08:44:47.246783.246783 mlpmodule.py:801] cpy2cputensor cost 0.0006577968597412109 s
DEBUG 01-06 08:44:47.251296.251296 cuda_h.py:19] end wait_cetm_experts cost 0.048100948333740234 seconds
DEBUG 01-06 08:44:47.251742.251742 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.252523.252523 cuda_h.py:19] end gpu_sexperts cost 0.0015139579772949219 seconds
DEBUG 01-06 08:44:47.252704.252704 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.252699.252699 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-06 08:44:47.252979.252979 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.252642.252642 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 267e5b0a-1788-488f-967c-3b61f9e52a9b
INFO 01-06 08:44:47.256520.256520 client.py:127] Model loaded
DEBUG 01-06 08:44:47.256601.256601 cuda_h.py:19] end wait_experts cost 0.003342151641845703 seconds
DEBUG 01-06 08:44:47.256357.256357 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.256021.256021 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.260094.260094 mlpmodule.py:662]  experts func einsum cost 0.057029008865356445 s
DEBUG 01-06 08:44:47.267498.267498 cuda_h.py:19] end gpu_experts cost 0.01147603988647461 seconds
DEBUG 01-06 08:44:47.267726.267726 cuda_h.py:19] end layer_moe_generate_15 cost 0.0734717845916748 seconds
DEBUG 01-06 08:44:47.268361.268361 lmp.py:221] -------------------------------- end layer 15 --------------------------------
DEBUG 01-06 08:44:47.268031.268031 lmp.py:177] -------------------------------- start layer 16 --------------------------------
DEBUG 01-06 08:44:47.268012.268012 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 08:44:47.268383.268383 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 08:44:47.268981.268981 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:47.268108.268108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.698204040527344e-05 seconds
DEBUG 01-06 08:44:47.268274.268274 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.268161.268161 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.268310.268310 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.268237.268237 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.269624.269624 cuda_h.py:19] end allocate_cuda_memory cost 0.00042819976806640625 seconds
DEBUG 01-06 08:44:47.269899.269899 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.269252.269252 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.269672.269672 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.269396.269396 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e901971f-52d8-49e3-869c-d2901c2bfb14
DEBUG 01-06 08:44:47.269016.269016 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.270609.270609 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.271037.271037 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e901971f-52d8-49e3-869c-d2901c2bfb14
DEBUG 01-06 08:44:47.271107.271107 cuda_h.py:19] end load_into_gpu_async cost 0.0016112327575683594 seconds
DEBUG 01-06 08:44:47.271923.271923 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.271379.271379 cuda_h.py:19] end restore_tensors2 cost 0.00012373924255371094 seconds
DEBUG 01-06 08:44:47.271725.271725 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025589466094970703 seconds
INFO 01-06 08:44:47.272469.272469 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e901971f-52d8-49e3-869c-d2901c2bfb14
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.274666.274666 cuda_h.py:19] end self_attn cost 0.00456547737121582 seconds
DEBUG 01-06 08:44:47.275478.275478 cuda_h.py:19] end iln_self_attn_paln cost 0.00686192512512207 seconds
DEBUG 01-06 08:44:47.275235.275235 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-06 08:44:47.275144.275144 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.275583.275583 cuda_h.py:19] end gate cost 0.0006048679351806641 seconds
DEBUG 01-06 08:44:47.275604.275604 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.276389.276389 lmp.py:369] 
DEBUG 01-06 08:44:47.276389.276389 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.276238.276238 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.276603.276603 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.276868.276868 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.276511.276511 lmp.py:373] 
DEBUG 01-06 08:44:47.276511.276511 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.276870.276870 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.276368.276368 lmp.py:380]   Expert 58 |     19 | CPU
DEBUG 01-06 08:44:47.276488.276488 lmp.py:380]   Expert 49 |     41 | CPU
DEBUG 01-06 08:44:47.276654.276654 lmp.py:380]   Expert 54 |     41 | CPU
DEBUG 01-06 08:44:47.276343.276343 lmp.py:380]   Expert 14 |     57 | CPU
DEBUG 01-06 08:44:47.276271.276271 lmp.py:380]   Expert 13 |     61 | CPU
DEBUG 01-06 08:44:47.276483.276483 lmp.py:380]   Expert 39 |     64 | CPU
DEBUG 01-06 08:44:47.276696.276696 lmp.py:380]   Expert 59 |     66 | CPU
DEBUG 01-06 08:44:47.276385.276385 lmp.py:380]   Expert 62 |     67 | CPU
DEBUG 01-06 08:44:47.276598.276598 lmp.py:380]   Expert 60 |     68 | CPU
DEBUG 01-06 08:44:47.276048.276048 lmp.py:380]   Expert  6 |     72 | CPU
DEBUG 01-06 08:44:47.276407.276407 lmp.py:380]   Expert 18 |     72 | CPU
DEBUG 01-06 08:44:47.276811.276811 lmp.py:380]   Expert 41 |     74 | CPU
DEBUG 01-06 08:44:47.276216.276216 lmp.py:380]   Expert 32 |     81 | CPU
DEBUG 01-06 08:44:47.276905.276905 lmp.py:380]   Expert 34 |     82 | CPU
DEBUG 01-06 08:44:47.276356.276356 lmp.py:380]   Expert 11 |     88 | CPU
DEBUG 01-06 08:44:47.276568.276568 lmp.py:380]   Expert 31 |     90 | CPU
DEBUG 01-06 08:44:47.276542.276542 lmp.py:380]   Expert 45 |     90 | CPU
DEBUG 01-06 08:44:47.276517.276517 lmp.py:380]   Expert 44 |     93 | CPU
DEBUG 01-06 08:44:47.276729.276729 lmp.py:380]   Expert 61 |     96 | CPU
DEBUG 01-06 08:44:47.276941.276941 lmp.py:380]   Expert  0 |    111 | CPU
DEBUG 01-06 08:44:47.276392.276392 lmp.py:380]   Expert 25 |    111 | CPU
DEBUG 01-06 08:44:47.276605.276605 lmp.py:380]   Expert 15 |    113 | CPU
DEBUG 01-06 08:44:47.276579.276579 lmp.py:380]   Expert 35 |    116 | CPU
DEBUG 01-06 08:44:47.276791.276791 lmp.py:380]   Expert 30 |    123 | CPU
DEBUG 01-06 08:44:47.276057.276057 lmp.py:380]   Expert 42 |    124 | CPU
DEBUG 01-06 08:44:47.276190.276190 lmp.py:380]   Expert 26 |    128 | CPU
DEBUG 01-06 08:44:47.276456.276456 lmp.py:380]   Expert 63 |    131 | CPU
DEBUG 01-06 08:44:47.276529.276529 lmp.py:380]   Expert 12 |    136 | CPU
DEBUG 01-06 08:44:47.276841.276841 lmp.py:380]   Expert 57 |    142 | CPU
DEBUG 01-06 08:44:47.276199.276199 lmp.py:380]   Expert 47 |    144 | CPU
DEBUG 01-06 08:44:47.276035.276035 lmp.py:380]   Expert 28 |    146 | CPU
DEBUG 01-06 08:44:47.276631.276631 lmp.py:380]   Expert 21 |    152 | CPU
DEBUG 01-06 08:44:47.276228.276228 lmp.py:380]   Expert 56 |    152 | GPU
DEBUG 01-06 08:44:47.277063.277063 lmp.py:380]   Expert 48 |    167 | GPU
DEBUG 01-06 08:44:47.277474.277474 lmp.py:380]   Expert 38 |    172 | GPU
DEBUG 01-06 08:44:47.277833.277833 lmp.py:380]   Expert 55 |    191 | GPU
DEBUG 01-06 08:44:47.277668.277668 lmp.py:380]   Expert 50 |    199 | GPU
DEBUG 01-06 08:44:47.277456.277456 lmp.py:380]   Expert 24 |    207 | GPU
DEBUG 01-06 08:44:47.277530.277530 lmp.py:380]   Expert 51 |    208 | GPU
DEBUG 01-06 08:44:47.277080.277080 lmp.py:380]   Expert 43 |    210 | GPU
DEBUG 01-06 08:44:47.277154.277154 lmp.py:380]   Expert 36 |    212 | GPU
DEBUG 01-06 08:44:47.277989.277989 lmp.py:380]   Expert 17 |    227 | GPU
DEBUG 01-06 08:44:47.277585.277585 lmp.py:380]   Expert 20 |    230 | GPU
DEBUG 01-06 08:44:47.277182.277182 lmp.py:380]   Expert  2 |    231 | GPU
DEBUG 01-06 08:44:47.277779.277779 lmp.py:380]   Expert  3 |    240 | GPU
DEBUG 01-06 08:44:47.277375.277375 lmp.py:380]   Expert 40 |    245 | GPU
DEBUG 01-06 08:44:47.277449.277449 lmp.py:380]   Expert  7 |    257 | GPU
DEBUG 01-06 08:44:47.277807.277807 lmp.py:380]   Expert  9 |    274 | GPU
DEBUG 01-06 08:44:47.277073.277073 lmp.py:380]   Expert 37 |    274 | GPU
DEBUG 01-06 08:44:47.277146.277146 lmp.py:380]   Expert  4 |    289 | GPU
DEBUG 01-06 08:44:47.277935.277935 lmp.py:380]   Expert 46 |    295 | GPU
DEBUG 01-06 08:44:47.277247.277247 lmp.py:380]   Expert 53 |    296 | GPU
DEBUG 01-06 08:44:47.277559.277559 lmp.py:380]   Expert  1 |    308 | GPU
DEBUG 01-06 08:44:47.277917.277917 lmp.py:380]   Expert 19 |    316 | GPU
DEBUG 01-06 08:44:47.277513.277513 lmp.py:380]   Expert  8 |    327 | GPU
DEBUG 01-06 08:44:47.277872.277872 lmp.py:380]   Expert 33 |    336 | GPU
DEBUG 01-06 08:44:47.277707.277707 lmp.py:380]   Expert 29 |    367 | GPU
DEBUG 01-06 08:44:47.277827.277827 lmp.py:380]   Expert 10 |    370 | GPU
DEBUG 01-06 08:44:47.277662.277662 lmp.py:380]   Expert 16 |    376 | GPU
DEBUG 01-06 08:44:47.277020.277020 lmp.py:380]   Expert 27 |    385 | GPU
DEBUG 01-06 08:44:47.277570.277570 lmp.py:380]   Expert 22 |    414 | GPU
DEBUG 01-06 08:44:47.277644.277644 lmp.py:380]   Expert 52 |    466 | GPU
DEBUG 01-06 08:44:47.277717.277717 lmp.py:380]   Expert  5 |    500 | GPU
DEBUG 01-06 08:44:47.277964.277964 lmp.py:380]   Expert 23 |    548 | GPU
DEBUG 01-06 08:44:47.277104.277104 lmp.py:381] 
DEBUG 01-06 08:44:47.277104.277104 lmp.py:381]   CPU total tokens: 2999 (24.4%)
DEBUG 01-06 08:44:47.277508.277508 lmp.py:382]   GPU total tokens: 9289 (75.6%)
DEBUG 01-06 08:44:47.277397.277397 cuda_h.py:19] end experts_map_get cost 0.0016791820526123047 seconds
DEBUG 01-06 08:44:47.277040.277040 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.277776.277776 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.277867.277867 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.278862.278862 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-06 08:44:47.278996.278996 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.278183.278183 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.278860.278860 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.278278.278278 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc187467-b3c0-4b79-898b-cd9a3fff4b81
DEBUG 01-06 08:44:47.278198.278198 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.278941.278941 client.py:127] Model loaded
DEBUG 01-06 08:44:47.278216.278216 cuda_h.py:19] end sllm_worker_task cost 0.010083198547363281 seconds
INFO 01-06 08:44:47.279914.279914 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc187467-b3c0-4b79-898b-cd9a3fff4b81
DEBUG 01-06 08:44:47.279308.279308 cuda_h.py:19] end load_into_gpu_async cost 0.001544952392578125 seconds
DEBUG 01-06 08:44:47.279064.279064 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.280784.280784 cuda_h.py:19] end restore_tensors2 cost 0.00029087066650390625 seconds
DEBUG 01-06 08:44:47.280461.280461 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024137496948242188 seconds
DEBUG 01-06 08:44:47.282770.282770 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049686431884765625 seconds
DEBUG 01-06 08:44:47.282599.282599 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.282721.282721 lmp.py:427] 
DEBUG 01-06 08:44:47.282721.282721 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.282849.282849 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-06 08:44:47.282691.282691 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.294409.294409 mlpmodule.py:704] group tensors cost 0.011810302734375 s
DEBUG 01-06 08:44:47.297263.297263 mlpmodule.py:742] pad cost 0.001523733139038086 s
DEBUG 01-06 08:44:47.297869.297869 mlpmodule.py:748] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-06 08:44:47.297957.297957 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-06 08:44:47.308543.308543 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.308979.308979 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.308898.308898 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-06 08:44:47.308313.308313 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.328382.328382 mlpmodule.py:793] group einsum cost 0.0312044620513916 s
DEBUG 01-06 08:44:47.329431.329431 mlpmodule.py:801] cpy2cputensor cost 0.0006761550903320312 s
DEBUG 01-06 08:44:47.334414.334414 cuda_h.py:19] end wait_cetm_experts cost 0.05140209197998047 seconds
DEBUG 01-06 08:44:47.334337.334337 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.336924.336924 cuda_h.py:19] end gpu_sexperts cost 0.0016527175903320312 seconds
DEBUG 01-06 08:44:47.336866.336866 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.336623.336623 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.765655517578125e-05 seconds
DEBUG 01-06 08:44:47.336247.336247 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.336149.336149 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc187467-b3c0-4b79-898b-cd9a3fff4b81
INFO 01-06 08:44:47.337952.337952 client.py:127] Model loaded
DEBUG 01-06 08:44:47.337656.337656 cuda_h.py:19] end wait_experts cost 0.0011124610900878906 seconds
DEBUG 01-06 08:44:47.337790.337790 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.337738.337738 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.342407.342407 mlpmodule.py:662]  experts func einsum cost 0.05943608283996582 s
DEBUG 01-06 08:44:47.350604.350604 cuda_h.py:19] end gpu_experts cost 0.012606620788574219 seconds
DEBUG 01-06 08:44:47.350501.350501 cuda_h.py:19] end layer_moe_generate_16 cost 0.0749518871307373 seconds
DEBUG 01-06 08:44:47.350612.350612 lmp.py:221] -------------------------------- end layer 16 --------------------------------
DEBUG 01-06 08:44:47.350706.350706 lmp.py:177] -------------------------------- start layer 17 --------------------------------
DEBUG 01-06 08:44:47.350687.350687 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 08:44:47.350012.350012 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 08:44:47.350941.350941 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:47.350306.350306 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.53131103515625e-05 seconds
DEBUG 01-06 08:44:47.350711.350711 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.350505.350505 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.351560.351560 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.351362.351362 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.351129.351129 cuda_h.py:19] end allocate_cuda_memory cost 0.0005810260772705078 seconds
DEBUG 01-06 08:44:47.352220.352220 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.352264.352264 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.352533.352533 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.352490.352490 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 90ad4c11-1a10-4bbd-a777-5cee7b9da5eb
DEBUG 01-06 08:44:47.352339.352339 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.353974.353974 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.354344.354344 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 90ad4c11-1a10-4bbd-a777-5cee7b9da5eb
DEBUG 01-06 08:44:47.354695.354695 cuda_h.py:19] end load_into_gpu_async cost 0.0025932788848876953 seconds
DEBUG 01-06 08:44:47.354433.354433 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.355053.355053 cuda_h.py:19] end restore_tensors2 cost 0.00020575523376464844 seconds
DEBUG 01-06 08:44:47.355170.355170 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0041980743408203125 seconds
INFO 01-06 08:44:47.357988.357988 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 90ad4c11-1a10-4bbd-a777-5cee7b9da5eb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.360030.360030 cuda_h.py:19] end self_attn cost 0.00664520263671875 seconds
DEBUG 01-06 08:44:47.360343.360343 cuda_h.py:19] end iln_self_attn_paln cost 0.00994729995727539 seconds
DEBUG 01-06 08:44:47.360320.360320 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-06 08:44:47.360110.360110 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.361139.361139 cuda_h.py:19] end gate cost 0.0008087158203125 seconds
DEBUG 01-06 08:44:47.361657.361657 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.362162.362162 lmp.py:369] 
DEBUG 01-06 08:44:47.362162.362162 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.362323.362323 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.362231.362231 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.362087.362087 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.362320.362320 lmp.py:373] 
DEBUG 01-06 08:44:47.362320.362320 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.362837.362837 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.362461.362461 lmp.py:380]   Expert 28 |     34 | CPU
DEBUG 01-06 08:44:47.362217.362217 lmp.py:380]   Expert 14 |     36 | CPU
DEBUG 01-06 08:44:47.362542.362542 lmp.py:380]   Expert 46 |     42 | CPU
DEBUG 01-06 08:44:47.362630.362630 lmp.py:380]   Expert 40 |     47 | CPU
DEBUG 01-06 08:44:47.362670.362670 lmp.py:380]   Expert 47 |     49 | CPU
DEBUG 01-06 08:44:47.362062.362062 lmp.py:380]   Expert  1 |     51 | CPU
DEBUG 01-06 08:44:47.362103.362103 lmp.py:380]   Expert 36 |     51 | CPU
DEBUG 01-06 08:44:47.362429.362429 lmp.py:380]   Expert 39 |     55 | CPU
DEBUG 01-06 08:44:47.362039.362039 lmp.py:380]   Expert 54 |     64 | CPU
DEBUG 01-06 08:44:47.362649.362649 lmp.py:380]   Expert 25 |     72 | CPU
DEBUG 01-06 08:44:47.362451.362451 lmp.py:380]   Expert 30 |     76 | CPU
DEBUG 01-06 08:44:47.362492.362492 lmp.py:380]   Expert 27 |     78 | CPU
DEBUG 01-06 08:44:47.362056.362056 lmp.py:380]   Expert 31 |     97 | CPU
DEBUG 01-06 08:44:47.362574.362574 lmp.py:380]   Expert  7 |     98 | CPU
DEBUG 01-06 08:44:47.362422.362422 lmp.py:380]   Expert 59 |     99 | CPU
DEBUG 01-06 08:44:47.362033.362033 lmp.py:380]   Expert 21 |    105 | CPU
DEBUG 01-06 08:44:47.362120.362120 lmp.py:380]   Expert 61 |    105 | CPU
DEBUG 01-06 08:44:47.362730.362730 lmp.py:380]   Expert  8 |    109 | CPU
DEBUG 01-06 08:44:47.362055.362055 lmp.py:380]   Expert 16 |    111 | CPU
DEBUG 01-06 08:44:47.362381.362381 lmp.py:380]   Expert 60 |    115 | CPU
DEBUG 01-06 08:44:47.362945.362945 lmp.py:380]   Expert 50 |    118 | CPU
DEBUG 01-06 08:44:47.362032.362032 lmp.py:380]   Expert 34 |    126 | CPU
DEBUG 01-06 08:44:47.362642.362642 lmp.py:380]   Expert 29 |    127 | CPU
DEBUG 01-06 08:44:47.362252.362252 lmp.py:380]   Expert 52 |    129 | CPU
DEBUG 01-06 08:44:47.362624.362624 lmp.py:380]   Expert 24 |    132 | CPU
DEBUG 01-06 08:44:47.363519.363519 lmp.py:380]   Expert  3 |    141 | CPU
DEBUG 01-06 08:44:47.363891.363891 lmp.py:380]   Expert 63 |    145 | CPU
DEBUG 01-06 08:44:47.363501.363501 lmp.py:380]   Expert  2 |    147 | CPU
DEBUG 01-06 08:44:47.363065.363065 lmp.py:380]   Expert  9 |    147 | CPU
DEBUG 01-06 08:44:47.363867.363867 lmp.py:380]   Expert 56 |    148 | CPU
DEBUG 01-06 08:44:47.363001.363001 lmp.py:380]   Expert 58 |    153 | CPU
DEBUG 01-06 08:44:47.363849.363849 lmp.py:380]   Expert 33 |    154 | CPU
DEBUG 01-06 08:44:47.363460.363460 lmp.py:380]   Expert 51 |    154 | GPU
DEBUG 01-06 08:44:47.363308.363308 lmp.py:380]   Expert  6 |    157 | GPU
DEBUG 01-06 08:44:47.363680.363680 lmp.py:380]   Expert 15 |    166 | GPU
DEBUG 01-06 08:44:47.363721.363721 lmp.py:380]   Expert  0 |    175 | GPU
DEBUG 01-06 08:44:47.363046.363046 lmp.py:380]   Expert 18 |    175 | GPU
DEBUG 01-06 08:44:47.363849.363849 lmp.py:380]   Expert 10 |    180 | GPU
DEBUG 01-06 08:44:47.363459.363459 lmp.py:380]   Expert 53 |    185 | GPU
DEBUG 01-06 08:44:47.363592.363592 lmp.py:380]   Expert  4 |    196 | GPU
DEBUG 01-06 08:44:47.363202.363202 lmp.py:380]   Expert 42 |    199 | GPU
DEBUG 01-06 08:44:47.363336.363336 lmp.py:380]   Expert 32 |    201 | GPU
DEBUG 01-06 08:44:47.363184.363184 lmp.py:380]   Expert 35 |    214 | GPU
DEBUG 01-06 08:44:47.363987.363987 lmp.py:380]   Expert  5 |    240 | GPU
DEBUG 01-06 08:44:47.363028.363028 lmp.py:380]   Expert 37 |    246 | GPU
DEBUG 01-06 08:44:47.363399.363399 lmp.py:380]   Expert 23 |    251 | GPU
DEBUG 01-06 08:44:47.363771.363771 lmp.py:380]   Expert 62 |    253 | GPU
DEBUG 01-06 08:44:47.363381.363381 lmp.py:380]   Expert 11 |    258 | GPU
DEBUG 01-06 08:44:47.363753.363753 lmp.py:380]   Expert 45 |    280 | GPU
DEBUG 01-06 08:44:47.363125.363125 lmp.py:380]   Expert 13 |    283 | GPU
DEBUG 01-06 08:44:47.363497.363497 lmp.py:380]   Expert 48 |    288 | GPU
DEBUG 01-06 08:44:47.363730.363730 lmp.py:380]   Expert 43 |    295 | GPU
DEBUG 01-06 08:44:47.363294.363294 lmp.py:380]   Expert 38 |    320 | GPU
DEBUG 01-06 08:44:47.363381.363381 lmp.py:380]   Expert 12 |    321 | GPU
DEBUG 01-06 08:44:47.363752.363752 lmp.py:380]   Expert 49 |    321 | GPU
DEBUG 01-06 08:44:47.363171.363171 lmp.py:380]   Expert 44 |    326 | GPU
DEBUG 01-06 08:44:47.363066.363066 lmp.py:380]   Expert 20 |    330 | GPU
DEBUG 01-06 08:44:47.363960.363960 lmp.py:380]   Expert 22 |    330 | GPU
DEBUG 01-06 08:44:47.363286.363286 lmp.py:380]   Expert 19 |    372 | GPU
DEBUG 01-06 08:44:47.364611.364611 lmp.py:380]   Expert 41 |    381 | GPU
DEBUG 01-06 08:44:47.364983.364983 lmp.py:380]   Expert 57 |    385 | GPU
DEBUG 01-06 08:44:47.364355.364355 lmp.py:380]   Expert 26 |    493 | GPU
DEBUG 01-06 08:44:47.364012.364012 lmp.py:380]   Expert 17 |    556 | GPU
DEBUG 01-06 08:44:47.364244.364244 lmp.py:380]   Expert 55 |    596 | GPU
DEBUG 01-06 08:44:47.364080.364080 lmp.py:381] 
DEBUG 01-06 08:44:47.364080.364080 lmp.py:381]   CPU total tokens: 3161 (25.7%)
DEBUG 01-06 08:44:47.364153.364153 lmp.py:382]   GPU total tokens: 9127 (74.3%)
DEBUG 01-06 08:44:47.364233.364233 cuda_h.py:19] end experts_map_get cost 0.0025262832641601562 seconds
DEBUG 01-06 08:44:47.364022.364022 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.364520.364520 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.364956.364956 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.364746.364746 cuda_h.py:19] end allocate_cuda_memory cost 0.00021386146545410156 seconds
DEBUG 01-06 08:44:47.364834.364834 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.364736.364736 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.364056.364056 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.364097.364097 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 66e18bf6-3623-409b-8c0d-e424c1f92466
DEBUG 01-06 08:44:47.365216.365216 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.365032.365032 client.py:127] Model loaded
DEBUG 01-06 08:44:47.365586.365586 cuda_h.py:19] end sllm_worker_task cost 0.014449834823608398 seconds
INFO 01-06 08:44:47.366115.366115 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 66e18bf6-3623-409b-8c0d-e424c1f92466
DEBUG 01-06 08:44:47.367436.367436 cuda_h.py:19] end load_into_gpu_async cost 0.002301931381225586 seconds
DEBUG 01-06 08:44:47.367907.367907 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.367362.367362 cuda_h.py:19] end restore_tensors2 cost 0.00030994415283203125 seconds
DEBUG 01-06 08:44:47.367039.367039 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032029151916503906 seconds
DEBUG 01-06 08:44:47.370476.370476 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005812644958496094 seconds
DEBUG 01-06 08:44:47.370167.370167 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.370719.370719 lmp.py:427] 
DEBUG 01-06 08:44:47.370719.370719 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.370046.370046 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-06 08:44:47.370126.370126 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.387046.387046 mlpmodule.py:704] group tensors cost 0.016967296600341797 s
DEBUG 01-06 08:44:47.390788.390788 mlpmodule.py:742] pad cost 0.0018911361694335938 s
DEBUG 01-06 08:44:47.390467.390467 mlpmodule.py:748] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-06 08:44:47.390953.390953 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-06 08:44:47.403145.403145 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.403158.403158 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.403440.403440 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-06 08:44:47.403524.403524 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.423793.423793 mlpmodule.py:793] group einsum cost 0.0332942008972168 s
DEBUG 01-06 08:44:47.424206.424206 mlpmodule.py:801] cpy2cputensor cost 0.0006806850433349609 s
DEBUG 01-06 08:44:47.429956.429956 cuda_h.py:19] end wait_cetm_experts cost 0.05896115303039551 seconds
DEBUG 01-06 08:44:47.429734.429734 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.430877.430877 cuda_h.py:19] end gpu_sexperts cost 0.0008673667907714844 seconds
DEBUG 01-06 08:44:47.430627.430627 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.430431.430431 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:47.430326.430326 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.430274.430274 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 66e18bf6-3623-409b-8c0d-e424c1f92466
INFO 01-06 08:44:47.431778.431778 client.py:127] Model loaded
DEBUG 01-06 08:44:47.431568.431568 cuda_h.py:19] end wait_experts cost 0.0012712478637695312 seconds
DEBUG 01-06 08:44:47.431748.431748 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.431789.431789 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.437501.437501 mlpmodule.py:662]  experts func einsum cost 0.0669867992401123 s
DEBUG 01-06 08:44:47.444890.444890 cuda_h.py:19] end gpu_experts cost 0.012323379516601562 seconds
DEBUG 01-06 08:44:47.444549.444549 cuda_h.py:19] end layer_moe_generate_17 cost 0.08355069160461426 seconds
DEBUG 01-06 08:44:47.444820.444820 lmp.py:221] -------------------------------- end layer 17 --------------------------------
DEBUG 01-06 08:44:47.444517.444517 lmp.py:177] -------------------------------- start layer 18 --------------------------------
DEBUG 01-06 08:44:47.444167.444167 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 08:44:47.444923.444923 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 08:44:47.444143.444143 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:44:47.444415.444415 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.91278076171875e-05 seconds
DEBUG 01-06 08:44:47.444012.444012 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.444473.444473 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.444891.444891 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.445529.445529 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.445286.445286 cuda_h.py:19] end allocate_cuda_memory cost 0.0003991127014160156 seconds
DEBUG 01-06 08:44:47.445402.445402 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.445602.445602 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.445538.445538 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.445009.445009 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 288488bb-2717-4b8c-b0fb-6e6f071949fa
DEBUG 01-06 08:44:47.445364.445364 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.446270.446270 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.447357.447357 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 288488bb-2717-4b8c-b0fb-6e6f071949fa
DEBUG 01-06 08:44:47.447981.447981 cuda_h.py:19] end load_into_gpu_async cost 0.001819610595703125 seconds
DEBUG 01-06 08:44:47.447797.447797 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.447980.447980 cuda_h.py:19] end restore_tensors2 cost 0.00010561943054199219 seconds
DEBUG 01-06 08:44:47.447458.447458 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026531219482421875 seconds
INFO 01-06 08:44:47.448709.448709 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 288488bb-2717-4b8c-b0fb-6e6f071949fa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.450708.450708 cuda_h.py:19] end self_attn cost 0.004388332366943359 seconds
DEBUG 01-06 08:44:47.451897.451897 cuda_h.py:19] end iln_self_attn_paln cost 0.0066258907318115234 seconds
DEBUG 01-06 08:44:47.451323.451323 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-06 08:44:47.451232.451232 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.452552.452552 cuda_h.py:19] end gate cost 0.0006222724914550781 seconds
DEBUG 01-06 08:44:47.452666.452666 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.452862.452862 lmp.py:369] 
DEBUG 01-06 08:44:47.452862.452862 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.452738.452738 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.452342.452342 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.452130.452130 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.452773.452773 lmp.py:373] 
DEBUG 01-06 08:44:47.452773.452773 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.452416.452416 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.452781.452781 lmp.py:380]   Expert 54 |     21 | CPU
DEBUG 01-06 08:44:47.452424.452424 lmp.py:380]   Expert 35 |     27 | CPU
DEBUG 01-06 08:44:47.452352.452352 lmp.py:380]   Expert  0 |     29 | CPU
DEBUG 01-06 08:44:47.452280.452280 lmp.py:380]   Expert 19 |     30 | CPU
DEBUG 01-06 08:44:47.452731.452731 lmp.py:380]   Expert 40 |     34 | CPU
DEBUG 01-06 08:44:47.452374.452374 lmp.py:380]   Expert 12 |     43 | CPU
DEBUG 01-06 08:44:47.452540.452540 lmp.py:380]   Expert 20 |     50 | CPU
DEBUG 01-06 08:44:47.452991.452991 lmp.py:380]   Expert  3 |     51 | CPU
DEBUG 01-06 08:44:47.452442.452442 lmp.py:380]   Expert 58 |     51 | CPU
DEBUG 01-06 08:44:47.452416.452416 lmp.py:380]   Expert 53 |     53 | CPU
DEBUG 01-06 08:44:47.452105.452105 lmp.py:380]   Expert 33 |     57 | CPU
DEBUG 01-06 08:44:47.452556.452556 lmp.py:380]   Expert 34 |     57 | CPU
DEBUG 01-06 08:44:47.452768.452768 lmp.py:380]   Expert 32 |     58 | CPU
DEBUG 01-06 08:44:47.452742.452742 lmp.py:380]   Expert 41 |     59 | CPU
DEBUG 01-06 08:44:47.452670.452670 lmp.py:380]   Expert 60 |     61 | CPU
DEBUG 01-06 08:44:47.452359.452359 lmp.py:380]   Expert  8 |     63 | CPU
DEBUG 01-06 08:44:47.452810.452810 lmp.py:380]   Expert 37 |     69 | CPU
DEBUG 01-06 08:44:47.452023.452023 lmp.py:380]   Expert  6 |     71 | CPU
DEBUG 01-06 08:44:47.452950.452950 lmp.py:380]   Expert 63 |     72 | CPU
DEBUG 01-06 08:44:47.452163.452163 lmp.py:380]   Expert 13 |     76 | CPU
DEBUG 01-06 08:44:47.452614.452614 lmp.py:380]   Expert 25 |     78 | CPU
DEBUG 01-06 08:44:47.452118.452118 lmp.py:380]   Expert 48 |     80 | CPU
DEBUG 01-06 08:44:47.452191.452191 lmp.py:380]   Expert 30 |     82 | CPU
DEBUG 01-06 08:44:47.452741.452741 lmp.py:380]   Expert 27 |     93 | CPU
DEBUG 01-06 08:44:47.452292.452292 lmp.py:380]   Expert 24 |     96 | CPU
DEBUG 01-06 08:44:47.452557.452557 lmp.py:380]   Expert 46 |     98 | CPU
DEBUG 01-06 08:44:47.452346.452346 lmp.py:380]   Expert  5 |    113 | CPU
DEBUG 01-06 08:44:47.453181.453181 lmp.py:380]   Expert 45 |    115 | CPU
DEBUG 01-06 08:44:47.453493.453493 lmp.py:380]   Expert 11 |    120 | CPU
DEBUG 01-06 08:44:47.453805.453805 lmp.py:380]   Expert 43 |    124 | CPU
DEBUG 01-06 08:44:47.453640.453640 lmp.py:380]   Expert 29 |    128 | CPU
DEBUG 01-06 08:44:47.453714.453714 lmp.py:380]   Expert 22 |    132 | CPU
DEBUG 01-06 08:44:47.453264.453264 lmp.py:380]   Expert 44 |    140 | GPU
DEBUG 01-06 08:44:47.453814.453814 lmp.py:380]   Expert 56 |    144 | GPU
DEBUG 01-06 08:44:47.453888.453888 lmp.py:380]   Expert 55 |    148 | GPU
DEBUG 01-06 08:44:47.453961.453961 lmp.py:380]   Expert 21 |    155 | GPU
DEBUG 01-06 08:44:47.453511.453511 lmp.py:380]   Expert 16 |    156 | GPU
DEBUG 01-06 08:44:47.453347.453347 lmp.py:380]   Expert  4 |    164 | GPU
DEBUG 01-06 08:44:47.453182.453182 lmp.py:380]   Expert 42 |    166 | GPU
DEBUG 01-06 08:44:47.453017.453017 lmp.py:380]   Expert  9 |    173 | GPU
DEBUG 01-06 08:44:47.453044.453044 lmp.py:380]   Expert 18 |    198 | GPU
DEBUG 01-06 08:44:47.453833.453833 lmp.py:380]   Expert 51 |    206 | GPU
DEBUG 01-06 08:44:47.453906.453906 lmp.py:380]   Expert 39 |    208 | GPU
DEBUG 01-06 08:44:47.453503.453503 lmp.py:380]   Expert 59 |    208 | GPU
DEBUG 01-06 08:44:47.453576.453576 lmp.py:380]   Expert 52 |    211 | GPU
DEBUG 01-06 08:44:47.453365.453365 lmp.py:380]   Expert 31 |    232 | GPU
DEBUG 01-06 08:44:47.453677.453677 lmp.py:380]   Expert 38 |    251 | GPU
DEBUG 01-06 08:44:47.453989.453989 lmp.py:380]   Expert 28 |    252 | GPU
DEBUG 01-06 08:44:47.453062.453062 lmp.py:380]   Expert 10 |    253 | GPU
DEBUG 01-06 08:44:47.453897.453897 lmp.py:380]   Expert  1 |    268 | GPU
DEBUG 01-06 08:44:47.453732.453732 lmp.py:380]   Expert 50 |    287 | GPU
DEBUG 01-06 08:44:47.453044.453044 lmp.py:380]   Expert 14 |    288 | GPU
DEBUG 01-06 08:44:47.453879.453879 lmp.py:380]   Expert  7 |    289 | GPU
DEBUG 01-06 08:44:47.453430.453430 lmp.py:380]   Expert 57 |    298 | GPU
DEBUG 01-06 08:44:47.453218.453218 lmp.py:380]   Expert 36 |    301 | GPU
DEBUG 01-06 08:44:47.453769.453769 lmp.py:380]   Expert 61 |    337 | GPU
DEBUG 01-06 08:44:47.453710.453710 lmp.py:380]   Expert 26 |    376 | GPU
DEBUG 01-06 08:44:47.453545.453545 lmp.py:380]   Expert 15 |    380 | GPU
DEBUG 01-06 08:44:47.453917.453917 lmp.py:380]   Expert 47 |    380 | GPU
DEBUG 01-06 08:44:47.453560.453560 lmp.py:380]   Expert 49 |    421 | GPU
DEBUG 01-06 08:44:47.453680.453680 lmp.py:380]   Expert 17 |    470 | GPU
DEBUG 01-06 08:44:47.453038.453038 lmp.py:380]   Expert  2 |    486 | GPU
DEBUG 01-06 08:44:47.453635.453635 lmp.py:380]   Expert 23 |    746 | GPU
DEBUG 01-06 08:44:47.453754.453754 lmp.py:380]   Expert 62 |   1405 | GPU
DEBUG 01-06 08:44:47.453351.453351 lmp.py:381] 
DEBUG 01-06 08:44:47.453351.453351 lmp.py:381]   CPU total tokens: 2291 (18.6%)
DEBUG 01-06 08:44:47.453140.453140 lmp.py:382]   GPU total tokens: 9997 (81.4%)
DEBUG 01-06 08:44:47.453982.453982 cuda_h.py:19] end experts_map_get cost 0.0016715526580810547 seconds
DEBUG 01-06 08:44:47.453770.453770 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.453130.453130 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.454155.454155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.454913.454913 cuda_h.py:19] end allocate_cuda_memory cost 0.0002422332763671875 seconds
DEBUG 01-06 08:44:47.454378.454378 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.454995.454995 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.454864.454864 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.454521.454521 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0a0a38e7-d20a-4693-8257-aa804205a13c
DEBUG 01-06 08:44:47.454110.454110 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.454335.454335 client.py:127] Model loaded
DEBUG 01-06 08:44:47.454696.454696 cuda_h.py:19] end sllm_worker_task cost 0.010024070739746094 seconds
INFO 01-06 08:44:47.455206.455206 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0a0a38e7-d20a-4693-8257-aa804205a13c
DEBUG 01-06 08:44:47.455865.455865 cuda_h.py:19] end load_into_gpu_async cost 0.0014433860778808594 seconds
DEBUG 01-06 08:44:47.455667.455667 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.456387.456387 cuda_h.py:19] end restore_tensors2 cost 0.0002949237823486328 seconds
DEBUG 01-06 08:44:47.456348.456348 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023484230041503906 seconds
DEBUG 01-06 08:44:47.458294.458294 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004919528961181641 seconds
DEBUG 01-06 08:44:47.458216.458216 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.458007.458007 lmp.py:427] 
DEBUG 01-06 08:44:47.458007.458007 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.458327.458327 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-06 08:44:47.458930.458930 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.465839.465839 mlpmodule.py:704] group tensors cost 0.006426095962524414 s
DEBUG 01-06 08:44:47.467315.467315 mlpmodule.py:742] pad cost 0.001520395278930664 s
DEBUG 01-06 08:44:47.467066.467066 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-06 08:44:47.467393.467393 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 08:44:47.479685.479685 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.479943.479943 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.479224.479224 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-06 08:44:47.479169.479169 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.498080.498080 mlpmodule.py:793] group einsum cost 0.030131816864013672 s
DEBUG 01-06 08:44:47.498769.498769 mlpmodule.py:801] cpy2cputensor cost 0.0005826950073242188 s
DEBUG 01-06 08:44:47.503607.503607 cuda_h.py:19] end wait_cetm_experts cost 0.04469656944274902 seconds
DEBUG 01-06 08:44:47.503445.503445 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.505283.505283 cuda_h.py:19] end gpu_sexperts cost 0.0016632080078125 seconds
DEBUG 01-06 08:44:47.505319.505319 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.505506.505506 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:47.505640.505640 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.505826.505826 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0a0a38e7-d20a-4693-8257-aa804205a13c
DEBUG 01-06 08:44:47.511709.511709 mlpmodule.py:662]  experts func einsum cost 0.05259275436401367 s
INFO 01-06 08:44:47.514753.514753 client.py:127] Model loaded
DEBUG 01-06 08:44:47.514126.514126 cuda_h.py:19] end wait_experts cost 0.008753061294555664 seconds
DEBUG 01-06 08:44:47.514021.514021 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.514962.514962 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.524789.524789 cuda_h.py:19] end gpu_experts cost 0.010421037673950195 seconds
DEBUG 01-06 08:44:47.525792.525792 cuda_h.py:19] end layer_moe_generate_18 cost 0.07369661331176758 seconds
DEBUG 01-06 08:44:47.525354.525354 lmp.py:221] -------------------------------- end layer 18 --------------------------------
DEBUG 01-06 08:44:47.525216.525216 lmp.py:177] -------------------------------- start layer 19 --------------------------------
DEBUG 01-06 08:44:47.525012.525012 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 08:44:47.525152.525152 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 08:44:47.525710.525710 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:44:47.525367.525367 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.318092346191406e-05 seconds
DEBUG 01-06 08:44:47.525109.525109 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.525492.525492 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.525320.525320 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.525125.525125 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.526863.526863 cuda_h.py:19] end allocate_cuda_memory cost 0.00040912628173828125 seconds
DEBUG 01-06 08:44:47.526177.526177 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.526842.526842 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.526811.526811 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.526011.526011 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 981aa614-a1a3-447b-9cd7-61fc91e31691
DEBUG 01-06 08:44:47.526731.526731 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.527280.527280 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.527055.527055 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 981aa614-a1a3-447b-9cd7-61fc91e31691
DEBUG 01-06 08:44:47.528767.528767 cuda_h.py:19] end load_into_gpu_async cost 0.0017354488372802734 seconds
DEBUG 01-06 08:44:47.528166.528166 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.528980.528980 cuda_h.py:19] end restore_tensors2 cost 0.00013756752014160156 seconds
DEBUG 01-06 08:44:47.528425.528425 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002683877944946289 seconds
INFO 01-06 08:44:47.529595.529595 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 981aa614-a1a3-447b-9cd7-61fc91e31691
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.532723.532723 cuda_h.py:19] end self_attn cost 0.0051958560943603516 seconds
DEBUG 01-06 08:44:47.532657.532657 cuda_h.py:19] end iln_self_attn_paln cost 0.00742650032043457 seconds
DEBUG 01-06 08:44:47.532196.532196 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-06 08:44:47.533887.533887 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.533589.533589 cuda_h.py:19] end gate cost 0.0007500648498535156 seconds
DEBUG 01-06 08:44:47.533578.533578 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.534558.534558 lmp.py:369] 
DEBUG 01-06 08:44:47.534558.534558 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.534858.534858 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.534574.534574 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.534807.534807 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.534417.534417 lmp.py:373] 
DEBUG 01-06 08:44:47.534417.534417 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.534180.534180 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.534420.534420 lmp.py:380]   Expert 48 |     30 | CPU
DEBUG 01-06 08:44:47.534792.534792 lmp.py:380]   Expert 56 |     37 | CPU
DEBUG 01-06 08:44:47.534448.534448 lmp.py:380]   Expert 52 |     39 | CPU
DEBUG 01-06 08:44:47.534866.534866 lmp.py:380]   Expert 55 |     39 | CPU
DEBUG 01-06 08:44:47.534338.534338 lmp.py:380]   Expert 44 |     46 | CPU
DEBUG 01-06 08:44:47.534325.534325 lmp.py:380]   Expert  6 |     56 | CPU
DEBUG 01-06 08:44:47.534074.534074 lmp.py:380]   Expert  5 |     59 | CPU
DEBUG 01-06 08:44:47.534393.534393 lmp.py:380]   Expert 27 |     62 | CPU
DEBUG 01-06 08:44:47.534997.534997 lmp.py:380]   Expert 23 |     70 | CPU
DEBUG 01-06 08:44:47.534362.534362 lmp.py:380]   Expert 59 |     72 | CPU
DEBUG 01-06 08:44:47.534727.534727 lmp.py:380]   Expert 30 |     80 | CPU
DEBUG 01-06 08:44:47.534092.534092 lmp.py:380]   Expert 57 |     80 | CPU
DEBUG 01-06 08:44:47.534695.534695 lmp.py:380]   Expert 12 |     87 | CPU
DEBUG 01-06 08:44:47.534967.534967 lmp.py:380]   Expert 40 |     87 | CPU
DEBUG 01-06 08:44:47.534240.534240 lmp.py:380]   Expert 18 |     95 | CPU
DEBUG 01-06 08:44:47.534751.534751 lmp.py:380]   Expert 34 |     95 | CPU
DEBUG 01-06 08:44:47.534354.534354 lmp.py:380]   Expert 16 |     99 | CPU
DEBUG 01-06 08:44:47.534242.534242 lmp.py:380]   Expert 33 |     99 | CPU
DEBUG 01-06 08:44:47.534369.534369 lmp.py:380]   Expert 42 |    106 | CPU
DEBUG 01-06 08:44:47.534257.534257 lmp.py:380]   Expert 26 |    114 | CPU
DEBUG 01-06 08:44:47.535384.535384 lmp.py:380]   Expert 46 |    121 | CPU
DEBUG 01-06 08:44:47.535510.535510 lmp.py:380]   Expert  0 |    123 | CPU
DEBUG 01-06 08:44:47.535637.535637 lmp.py:380]   Expert  8 |    129 | CPU
DEBUG 01-06 08:44:47.535002.535002 lmp.py:380]   Expert 54 |    129 | CPU
DEBUG 01-06 08:44:47.535605.535605 lmp.py:380]   Expert 62 |    131 | CPU
DEBUG 01-06 08:44:47.535732.535732 lmp.py:380]   Expert 15 |    132 | CPU
DEBUG 01-06 08:44:47.535859.535859 lmp.py:380]   Expert 63 |    134 | CPU
DEBUG 01-06 08:44:47.535508.535508 lmp.py:380]   Expert 60 |    135 | CPU
DEBUG 01-06 08:44:47.535873.535873 lmp.py:380]   Expert 37 |    136 | CPU
DEBUG 01-06 08:44:47.535669.535669 lmp.py:380]   Expert 53 |    145 | CPU
DEBUG 01-06 08:44:47.535795.535795 lmp.py:380]   Expert 32 |    147 | CPU
DEBUG 01-06 08:44:47.535445.535445 lmp.py:380]   Expert 39 |    150 | CPU
DEBUG 01-06 08:44:47.535333.535333 lmp.py:380]   Expert 14 |    151 | GPU
DEBUG 01-06 08:44:47.535460.535460 lmp.py:380]   Expert  1 |    154 | GPU
DEBUG 01-06 08:44:47.535110.535110 lmp.py:380]   Expert 13 |    154 | GPU
DEBUG 01-06 08:44:47.535236.535236 lmp.py:380]   Expert 24 |    154 | GPU
DEBUG 01-06 08:44:47.535125.535125 lmp.py:380]   Expert  4 |    156 | GPU
DEBUG 01-06 08:44:47.535013.535013 lmp.py:380]   Expert 58 |    158 | GPU
DEBUG 01-06 08:44:47.535431.535431 lmp.py:380]   Expert 43 |    169 | GPU
DEBUG 01-06 08:44:47.535034.535034 lmp.py:380]   Expert 50 |    174 | GPU
DEBUG 01-06 08:44:47.535161.535161 lmp.py:380]   Expert 47 |    177 | GPU
DEBUG 01-06 08:44:47.535526.535526 lmp.py:380]   Expert 61 |    180 | GPU
DEBUG 01-06 08:44:47.535414.535414 lmp.py:380]   Expert 28 |    206 | GPU
DEBUG 01-06 08:44:47.535302.535302 lmp.py:380]   Expert 20 |    219 | GPU
DEBUG 01-06 08:44:47.535190.535190 lmp.py:380]   Expert 49 |    221 | GPU
DEBUG 01-06 08:44:47.535079.535079 lmp.py:380]   Expert 41 |    241 | GPU
DEBUG 01-06 08:44:47.535967.535967 lmp.py:380]   Expert 17 |    245 | GPU
DEBUG 01-06 08:44:47.535855.535855 lmp.py:380]   Expert 22 |    245 | GPU
DEBUG 01-06 08:44:47.535743.535743 lmp.py:380]   Expert 21 |    264 | GPU
DEBUG 01-06 08:44:47.535631.535631 lmp.py:380]   Expert 25 |    267 | GPU
DEBUG 01-06 08:44:47.535142.535142 lmp.py:380]   Expert 35 |    270 | GPU
DEBUG 01-06 08:44:47.535607.535607 lmp.py:380]   Expert 51 |    271 | GPU
DEBUG 01-06 08:44:47.535879.535879 lmp.py:380]   Expert 38 |    284 | GPU
DEBUG 01-06 08:44:47.535913.535913 lmp.py:380]   Expert 11 |    293 | GPU
DEBUG 01-06 08:44:47.535662.535662 lmp.py:380]   Expert  2 |    329 | GPU
DEBUG 01-06 08:44:47.535935.535935 lmp.py:380]   Expert 31 |    330 | GPU
DEBUG 01-06 08:44:47.535207.535207 lmp.py:380]   Expert 36 |    338 | GPU
DEBUG 01-06 08:44:47.535195.535195 lmp.py:380]   Expert 29 |    392 | GPU
DEBUG 01-06 08:44:47.535944.535944 lmp.py:380]   Expert 10 |    403 | GPU
DEBUG 01-06 08:44:47.535753.535753 lmp.py:380]   Expert 45 |    407 | GPU
DEBUG 01-06 08:44:47.535217.535217 lmp.py:380]   Expert  3 |    442 | GPU
DEBUG 01-06 08:44:47.536728.536728 lmp.py:380]   Expert  9 |    589 | GPU
DEBUG 01-06 08:44:47.536954.536954 lmp.py:380]   Expert 19 |    666 | GPU
DEBUG 01-06 08:44:47.536372.536372 lmp.py:380]   Expert  7 |    675 | GPU
DEBUG 01-06 08:44:47.536314.536314 lmp.py:381] 
DEBUG 01-06 08:44:47.536314.536314 lmp.py:381]   CPU total tokens: 3064 (24.9%)
DEBUG 01-06 08:44:47.536493.536493 lmp.py:382]   GPU total tokens: 9224 (75.1%)
DEBUG 01-06 08:44:47.536395.536395 cuda_h.py:19] end experts_map_get cost 0.0022125244140625 seconds
DEBUG 01-06 08:44:47.536290.536290 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.536339.536339 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.536868.536868 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.536467.536467 cuda_h.py:19] end allocate_cuda_memory cost 0.00025177001953125 seconds
DEBUG 01-06 08:44:47.536907.536907 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.536538.536538 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.536043.536043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.536667.536667 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 413b360d-391d-4c12-8b8c-495aa6e07e20
DEBUG 01-06 08:44:47.537681.537681 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.537973.537973 client.py:127] Model loaded
DEBUG 01-06 08:44:47.537155.537155 cuda_h.py:19] end sllm_worker_task cost 0.01169729232788086 seconds
INFO 01-06 08:44:47.539855.539855 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 413b360d-391d-4c12-8b8c-495aa6e07e20
DEBUG 01-06 08:44:47.539369.539369 cuda_h.py:19] end load_into_gpu_async cost 0.00225830078125 seconds
DEBUG 01-06 08:44:47.539840.539840 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.539784.539784 cuda_h.py:19] end restore_tensors2 cost 0.00028443336486816406 seconds
DEBUG 01-06 08:44:47.539746.539746 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032172203063964844 seconds
DEBUG 01-06 08:44:47.542210.542210 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005871772766113281 seconds
DEBUG 01-06 08:44:47.542801.542801 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.542115.542115 lmp.py:427] 
DEBUG 01-06 08:44:47.542115.542115 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.542766.542766 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-06 08:44:47.542654.542654 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.549651.549651 mlpmodule.py:704] group tensors cost 0.007080554962158203 s
DEBUG 01-06 08:44:47.552184.552184 mlpmodule.py:742] pad cost 0.002513408660888672 s
DEBUG 01-06 08:44:47.552712.552712 mlpmodule.py:748] create cpu tensor cost 5.817413330078125e-05 s
DEBUG 01-06 08:44:47.553655.553655 mlpmodule.py:753] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-06 08:44:47.565742.565742 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.565709.565709 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.565182.565182 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-06 08:44:47.565035.565035 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.584561.584561 mlpmodule.py:793] group einsum cost 0.03189229965209961 s
DEBUG 01-06 08:44:47.585761.585761 mlpmodule.py:801] cpy2cputensor cost 0.0006468296051025391 s
DEBUG 01-06 08:44:47.590479.590479 cuda_h.py:19] end wait_cetm_experts cost 0.04831647872924805 seconds
DEBUG 01-06 08:44:47.590594.590594 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.592673.592673 cuda_h.py:19] end gpu_sexperts cost 0.001314401626586914 seconds
DEBUG 01-06 08:44:47.592754.592754 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.592512.592512 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:47.592506.592506 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.592885.592885 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 413b360d-391d-4c12-8b8c-495aa6e07e20
INFO 01-06 08:44:47.598774.598774 client.py:127] Model loaded
DEBUG 01-06 08:44:47.598908.598908 cuda_h.py:19] end wait_experts cost 0.0064427852630615234 seconds
DEBUG 01-06 08:44:47.598711.598711 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.598851.598851 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.598206.598206 mlpmodule.py:662]  experts func einsum cost 0.05649304389953613 s
DEBUG 01-06 08:44:47.609437.609437 cuda_h.py:19] end gpu_experts cost 0.011171579360961914 seconds
DEBUG 01-06 08:44:47.610832.610832 cuda_h.py:19] end layer_moe_generate_19 cost 0.07707428932189941 seconds
DEBUG 01-06 08:44:47.610658.610658 lmp.py:221] -------------------------------- end layer 19 --------------------------------
DEBUG 01-06 08:44:47.610758.610758 lmp.py:177] -------------------------------- start layer 20 --------------------------------
DEBUG 01-06 08:44:47.610931.610931 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 08:44:47.610211.610211 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 08:44:47.610669.610669 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:47.610227.610227 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.936622619628906e-05 seconds
DEBUG 01-06 08:44:47.610585.610585 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.610994.610994 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.610103.610103 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.611096.611096 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.611112.611112 cuda_h.py:19] end allocate_cuda_memory cost 0.0005817413330078125 seconds
DEBUG 01-06 08:44:47.611078.611078 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.612506.612506 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.612106.612106 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.612705.612705 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4c031f9-431d-447f-a3bb-d2572e7f6330
DEBUG 01-06 08:44:47.612032.612032 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.612919.612919 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.613038.613038 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4c031f9-431d-447f-a3bb-d2572e7f6330
DEBUG 01-06 08:44:47.614740.614740 cuda_h.py:19] end load_into_gpu_async cost 0.0020635128021240234 seconds
DEBUG 01-06 08:44:47.614552.614552 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.614900.614900 cuda_h.py:19] end restore_tensors2 cost 0.00020194053649902344 seconds
DEBUG 01-06 08:44:47.614155.614155 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003606557846069336 seconds
INFO 01-06 08:44:47.616099.616099 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4c031f9-431d-447f-a3bb-d2572e7f6330
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.618468.618468 cuda_h.py:19] end self_attn cost 0.00579071044921875 seconds
DEBUG 01-06 08:44:47.619592.619592 cuda_h.py:19] end iln_self_attn_paln cost 0.008681774139404297 seconds
DEBUG 01-06 08:44:47.619634.619634 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-06 08:44:47.619542.619542 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.619684.619684 cuda_h.py:19] end gate cost 0.0006306171417236328 seconds
DEBUG 01-06 08:44:47.619944.619944 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.620351.620351 lmp.py:369] 
DEBUG 01-06 08:44:47.620351.620351 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.620822.620822 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.620333.620333 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.620745.620745 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.620056.620056 lmp.py:373] 
DEBUG 01-06 08:44:47.620056.620056 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.620648.620648 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.620542.620542 lmp.py:380]   Expert  8 |     15 | CPU
DEBUG 01-06 08:44:47.620046.620046 lmp.py:380]   Expert 13 |     32 | CPU
DEBUG 01-06 08:44:47.620074.620074 lmp.py:380]   Expert 54 |     34 | CPU
DEBUG 01-06 08:44:47.620862.620862 lmp.py:380]   Expert  1 |     63 | CPU
DEBUG 01-06 08:44:47.620651.620651 lmp.py:380]   Expert 28 |     63 | CPU
DEBUG 01-06 08:44:47.620208.620208 lmp.py:380]   Expert 11 |     66 | CPU
DEBUG 01-06 08:44:47.620474.620474 lmp.py:380]   Expert 36 |     66 | CPU
DEBUG 01-06 08:44:47.620263.620263 lmp.py:380]   Expert 33 |     69 | CPU
DEBUG 01-06 08:44:47.620336.620336 lmp.py:380]   Expert 12 |     71 | CPU
DEBUG 01-06 08:44:47.620648.620648 lmp.py:380]   Expert 14 |     71 | CPU
DEBUG 01-06 08:44:47.620721.620721 lmp.py:380]   Expert 43 |     73 | CPU
DEBUG 01-06 08:44:47.620272.620272 lmp.py:380]   Expert 42 |     81 | CPU
DEBUG 01-06 08:44:47.620584.620584 lmp.py:380]   Expert  6 |     86 | CPU
DEBUG 01-06 08:44:47.620896.620896 lmp.py:380]   Expert 10 |     88 | CPU
DEBUG 01-06 08:44:47.620492.620492 lmp.py:380]   Expert 51 |     91 | CPU
DEBUG 01-06 08:44:47.620804.620804 lmp.py:380]   Expert 29 |     93 | CPU
DEBUG 01-06 08:44:47.620547.620547 lmp.py:380]   Expert  3 |     94 | CPU
DEBUG 01-06 08:44:47.620574.620574 lmp.py:380]   Expert 19 |     94 | CPU
DEBUG 01-06 08:44:47.620124.620124 lmp.py:380]   Expert  9 |     95 | CPU
DEBUG 01-06 08:44:47.620913.620913 lmp.py:380]   Expert 46 |    103 | CPU
DEBUG 01-06 08:44:47.620748.620748 lmp.py:380]   Expert 38 |    110 | CPU
DEBUG 01-06 08:44:47.620821.620821 lmp.py:380]   Expert 20 |    119 | CPU
DEBUG 01-06 08:44:47.620656.620656 lmp.py:380]   Expert 61 |    124 | CPU
DEBUG 01-06 08:44:47.620968.620968 lmp.py:380]   Expert  0 |    134 | CPU
DEBUG 01-06 08:44:47.620042.620042 lmp.py:380]   Expert 18 |    135 | CPU
DEBUG 01-06 08:44:47.620354.620354 lmp.py:380]   Expert 17 |    137 | CPU
DEBUG 01-06 08:44:47.620096.620096 lmp.py:380]   Expert 44 |    143 | CPU
DEBUG 01-06 08:44:47.620461.620461 lmp.py:380]   Expert 49 |    147 | CPU
DEBUG 01-06 08:44:47.621011.621011 lmp.py:380]   Expert 63 |    147 | CPU
DEBUG 01-06 08:44:47.621562.621562 lmp.py:380]   Expert 57 |    148 | CPU
DEBUG 01-06 08:44:47.621397.621397 lmp.py:380]   Expert  5 |    153 | CPU
DEBUG 01-06 08:44:47.621709.621709 lmp.py:380]   Expert 26 |    156 | CPU
DEBUG 01-06 08:44:47.621782.621782 lmp.py:380]   Expert 62 |    159 | GPU
DEBUG 01-06 08:44:47.621856.621856 lmp.py:380]   Expert 39 |    163 | GPU
DEBUG 01-06 08:44:47.621929.621929 lmp.py:380]   Expert 21 |    164 | GPU
DEBUG 01-06 08:44:47.621241.621241 lmp.py:380]   Expert 52 |    170 | GPU
DEBUG 01-06 08:44:47.621315.621315 lmp.py:380]   Expert 55 |    176 | GPU
DEBUG 01-06 08:44:47.621819.621819 lmp.py:380]   Expert 50 |    177 | GPU
DEBUG 01-06 08:44:47.621607.621607 lmp.py:380]   Expert 23 |    207 | GPU
DEBUG 01-06 08:44:47.621350.621350 lmp.py:380]   Expert  7 |    209 | GPU
DEBUG 01-06 08:44:47.621662.621662 lmp.py:380]   Expert 47 |    217 | GPU
DEBUG 01-06 08:44:47.621113.621113 lmp.py:380]   Expert 30 |    218 | GPU
DEBUG 01-06 08:44:47.621948.621948 lmp.py:380]   Expert 37 |    220 | GPU
DEBUG 01-06 08:44:47.621544.621544 lmp.py:380]   Expert 45 |    242 | GPU
DEBUG 01-06 08:44:47.621618.621618 lmp.py:380]   Expert 27 |    244 | GPU
DEBUG 01-06 08:44:47.621976.621976 lmp.py:380]   Expert 22 |    245 | GPU
DEBUG 01-06 08:44:47.621825.621825 lmp.py:380]   Expert 16 |    247 | GPU
DEBUG 01-06 08:44:47.621613.621613 lmp.py:380]   Expert 32 |    248 | GPU
DEBUG 01-06 08:44:47.621925.621925 lmp.py:380]   Expert 58 |    248 | GPU
DEBUG 01-06 08:44:47.621237.621237 lmp.py:380]   Expert 53 |    250 | GPU
DEBUG 01-06 08:44:47.621026.621026 lmp.py:380]   Expert 24 |    258 | GPU
DEBUG 01-06 08:44:47.621623.621623 lmp.py:380]   Expert 60 |    267 | GPU
DEBUG 01-06 08:44:47.621219.621219 lmp.py:380]   Expert 41 |    268 | GPU
DEBUG 01-06 08:44:47.621816.621816 lmp.py:380]   Expert 48 |    285 | GPU
DEBUG 01-06 08:44:47.621174.621174 lmp.py:380]   Expert 56 |    286 | GPU
DEBUG 01-06 08:44:47.621771.621771 lmp.py:380]   Expert  4 |    295 | GPU
DEBUG 01-06 08:44:47.621367.621367 lmp.py:380]   Expert  2 |    306 | GPU
DEBUG 01-06 08:44:47.621487.621487 lmp.py:380]   Expert 34 |    318 | GPU
DEBUG 01-06 08:44:47.621322.621322 lmp.py:380]   Expert 15 |    319 | GPU
DEBUG 01-06 08:44:47.621111.621111 lmp.py:380]   Expert 40 |    339 | GPU
DEBUG 01-06 08:44:47.621661.621661 lmp.py:380]   Expert 59 |    356 | GPU
DEBUG 01-06 08:44:47.621735.621735 lmp.py:380]   Expert 31 |    393 | GPU
DEBUG 01-06 08:44:47.621808.621808 lmp.py:380]   Expert 25 |    823 | GPU
DEBUG 01-06 08:44:47.621882.621882 lmp.py:380]   Expert 35 |    870 | GPU
DEBUG 01-06 08:44:47.621671.621671 lmp.py:381] 
DEBUG 01-06 08:44:47.621671.621671 lmp.py:381]   CPU total tokens: 3101 (25.2%)
DEBUG 01-06 08:44:47.621221.621221 lmp.py:382]   GPU total tokens: 9187 (74.8%)
DEBUG 01-06 08:44:47.621493.621493 cuda_h.py:19] end experts_map_get cost 0.001744985580444336 seconds
DEBUG 01-06 08:44:47.621236.621236 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.621549.621549 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.621693.621693 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.622171.622171 cuda_h.py:19] end allocate_cuda_memory cost 0.00021123886108398438 seconds
DEBUG 01-06 08:44:47.622544.622544 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.622353.622353 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.622653.622653 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.622932.622932 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4802782-0de7-4257-a04a-ef26f4d97b79
DEBUG 01-06 08:44:47.622005.622005 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.622968.622968 client.py:127] Model loaded
DEBUG 01-06 08:44:47.623158.623158 cuda_h.py:19] end sllm_worker_task cost 0.01214909553527832 seconds
INFO 01-06 08:44:47.623775.623775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4802782-0de7-4257-a04a-ef26f4d97b79
DEBUG 01-06 08:44:47.623911.623911 cuda_h.py:19] end load_into_gpu_async cost 0.0014235973358154297 seconds
DEBUG 01-06 08:44:47.623097.623097 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.624287.624287 cuda_h.py:19] end restore_tensors2 cost 0.00028443336486816406 seconds
DEBUG 01-06 08:44:47.624725.624725 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022826194763183594 seconds
DEBUG 01-06 08:44:47.626882.626882 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004834651947021484 seconds
DEBUG 01-06 08:44:47.626281.626281 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.626264.626264 lmp.py:427] 
DEBUG 01-06 08:44:47.626264.626264 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.626346.626346 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-06 08:44:47.626949.626949 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.639326.639326 mlpmodule.py:704] group tensors cost 0.012289762496948242 s
DEBUG 01-06 08:44:47.641365.641365 mlpmodule.py:742] pad cost 0.0015189647674560547 s
DEBUG 01-06 08:44:47.641448.641448 mlpmodule.py:748] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-06 08:44:47.641774.641774 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 08:44:47.653682.653682 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.653364.653364 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.653791.653791 mlpmodule.py:773] group_w3 first element: -0.046630859375
WARNING 01-06 08:44:47.653491.653491 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.675958.675958 mlpmodule.py:793] group einsum cost 0.03426003456115723 s
DEBUG 01-06 08:44:47.676393.676393 mlpmodule.py:801] cpy2cputensor cost 0.0006730556488037109 s
DEBUG 01-06 08:44:47.682639.682639 cuda_h.py:19] end wait_cetm_experts cost 0.05516552925109863 seconds
DEBUG 01-06 08:44:47.682589.682589 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.683590.683590 cuda_h.py:19] end gpu_sexperts cost 0.001150369644165039 seconds
DEBUG 01-06 08:44:47.683386.683386 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.683257.683257 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.100799560546875e-05 seconds
DEBUG 01-06 08:44:47.683059.683059 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.683107.683107 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4802782-0de7-4257-a04a-ef26f4d97b79
INFO 01-06 08:44:47.684324.684324 client.py:127] Model loaded
DEBUG 01-06 08:44:47.684975.684975 cuda_h.py:19] end wait_experts cost 0.0010292530059814453 seconds
DEBUG 01-06 08:44:47.684824.684824 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.684580.684580 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.690124.690124 mlpmodule.py:662]  experts func einsum cost 0.06345772743225098 s
DEBUG 01-06 08:44:47.696751.696751 cuda_h.py:19] end gpu_experts cost 0.012022733688354492 seconds
DEBUG 01-06 08:44:47.696835.696835 cuda_h.py:19] end layer_moe_generate_20 cost 0.07757186889648438 seconds
DEBUG 01-06 08:44:47.696443.696443 lmp.py:221] -------------------------------- end layer 20 --------------------------------
DEBUG 01-06 08:44:47.697352.697352 lmp.py:177] -------------------------------- start layer 21 --------------------------------
DEBUG 01-06 08:44:47.697001.697001 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 08:44:47.697950.697950 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 08:44:47.697408.697408 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:44:47.697111.697111 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.127357482910156e-05 seconds
DEBUG 01-06 08:44:47.697423.697423 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.697487.697487 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.697232.697232 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.697181.697181 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.697709.697709 cuda_h.py:19] end allocate_cuda_memory cost 0.000316619873046875 seconds
DEBUG 01-06 08:44:47.697163.697163 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.697548.697548 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.697424.697424 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.698603.698603 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3f4179cf-d121-4a53-89e8-4496eec73c30
DEBUG 01-06 08:44:47.698878.698878 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.698609.698609 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.699050.699050 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3f4179cf-d121-4a53-89e8-4496eec73c30
DEBUG 01-06 08:44:47.699411.699411 cuda_h.py:19] end load_into_gpu_async cost 0.00144195556640625 seconds
DEBUG 01-06 08:44:47.699220.699220 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.699264.699264 cuda_h.py:19] end restore_tensors2 cost 8.487701416015625e-05 seconds
DEBUG 01-06 08:44:47.699650.699650 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021643638610839844 seconds
INFO 01-06 08:44:47.700748.700748 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3f4179cf-d121-4a53-89e8-4496eec73c30
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.702314.702314 cuda_h.py:19] end self_attn cost 0.003773927688598633 seconds
DEBUG 01-06 08:44:47.702410.702410 cuda_h.py:19] end iln_self_attn_paln cost 0.0052988529205322266 seconds
DEBUG 01-06 08:44:47.702253.702253 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-06 08:44:47.702969.702969 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.703973.703973 cuda_h.py:19] end gate cost 0.0006716251373291016 seconds
DEBUG 01-06 08:44:47.703418.703418 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.703428.703428 lmp.py:369] 
DEBUG 01-06 08:44:47.703428.703428 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.703899.703899 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.703602.703602 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.703629.703629 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.703418.703418 lmp.py:373] 
DEBUG 01-06 08:44:47.703418.703418 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.703922.703922 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.703572.703572 lmp.py:380]   Expert 44 |     18 | CPU
DEBUG 01-06 08:44:47.703738.703738 lmp.py:380]   Expert 56 |     28 | CPU
DEBUG 01-06 08:44:47.703189.703189 lmp.py:380]   Expert  9 |     33 | CPU
DEBUG 01-06 08:44:47.703639.703639 lmp.py:380]   Expert 26 |     42 | CPU
DEBUG 01-06 08:44:47.703852.703852 lmp.py:380]   Expert 60 |     51 | CPU
DEBUG 01-06 08:44:47.703064.703064 lmp.py:380]   Expert  1 |     54 | CPU
DEBUG 01-06 08:44:47.703515.703515 lmp.py:380]   Expert 35 |     56 | CPU
DEBUG 01-06 08:44:47.703489.703489 lmp.py:380]   Expert  6 |     64 | CPU
DEBUG 01-06 08:44:47.703463.703463 lmp.py:380]   Expert 19 |     70 | CPU
DEBUG 01-06 08:44:47.703437.703437 lmp.py:380]   Expert 32 |     70 | CPU
DEBUG 01-06 08:44:47.703365.703365 lmp.py:380]   Expert 53 |     72 | CPU
DEBUG 01-06 08:44:47.703339.703339 lmp.py:380]   Expert 57 |     75 | CPU
DEBUG 01-06 08:44:47.703744.703744 lmp.py:380]   Expert 49 |     77 | CPU
DEBUG 01-06 08:44:47.704718.704718 lmp.py:380]   Expert  8 |     78 | CPU
DEBUG 01-06 08:44:47.704453.704453 lmp.py:380]   Expert 23 |     83 | CPU
DEBUG 01-06 08:44:47.704427.704427 lmp.py:380]   Expert 51 |     85 | CPU
DEBUG 01-06 08:44:47.704925.704925 lmp.py:380]   Expert 15 |     89 | CPU
DEBUG 01-06 08:44:47.704899.704899 lmp.py:380]   Expert 20 |     92 | CPU
DEBUG 01-06 08:44:47.704634.704634 lmp.py:380]   Expert  3 |     93 | CPU
DEBUG 01-06 08:44:47.704370.704370 lmp.py:380]   Expert 41 |     95 | CPU
DEBUG 01-06 08:44:47.704106.704106 lmp.py:380]   Expert 52 |     95 | CPU
DEBUG 01-06 08:44:47.704080.704080 lmp.py:380]   Expert 12 |     97 | CPU
DEBUG 01-06 08:44:47.704292.704292 lmp.py:380]   Expert 25 |    101 | CPU
DEBUG 01-06 08:44:47.704458.704458 lmp.py:380]   Expert 28 |    102 | CPU
DEBUG 01-06 08:44:47.704532.704532 lmp.py:380]   Expert 33 |    108 | CPU
DEBUG 01-06 08:44:47.704698.704698 lmp.py:380]   Expert 40 |    109 | CPU
DEBUG 01-06 08:44:47.704910.704910 lmp.py:380]   Expert 24 |    113 | CPU
DEBUG 01-06 08:44:47.704646.704646 lmp.py:380]   Expert 54 |    113 | CPU
DEBUG 01-06 08:44:47.704382.704382 lmp.py:380]   Expert 11 |    115 | CPU
DEBUG 01-06 08:44:47.704879.704879 lmp.py:380]   Expert 13 |    116 | CPU
DEBUG 01-06 08:44:47.704614.704614 lmp.py:380]   Expert 48 |    125 | CPU
DEBUG 01-06 08:44:47.704112.704112 lmp.py:380]   Expert 14 |    126 | CPU
DEBUG 01-06 08:44:47.704847.704847 lmp.py:380]   Expert 59 |    136 | GPU
DEBUG 01-06 08:44:47.704344.704344 lmp.py:380]   Expert 39 |    142 | GPU
DEBUG 01-06 08:44:47.704318.704318 lmp.py:380]   Expert  7 |    149 | GPU
DEBUG 01-06 08:44:47.704054.704054 lmp.py:380]   Expert 58 |    152 | GPU
DEBUG 01-06 08:44:47.704505.704505 lmp.py:380]   Expert 34 |    163 | GPU
DEBUG 01-06 08:44:47.704062.704062 lmp.py:380]   Expert 10 |    164 | GPU
DEBUG 01-06 08:44:47.704725.704725 lmp.py:380]   Expert 18 |    166 | GPU
DEBUG 01-06 08:44:47.704938.704938 lmp.py:380]   Expert 63 |    175 | GPU
DEBUG 01-06 08:44:47.704627.704627 lmp.py:380]   Expert 38 |    212 | GPU
DEBUG 01-06 08:44:47.704601.704601 lmp.py:380]   Expert 47 |    216 | GPU
DEBUG 01-06 08:44:47.704814.704814 lmp.py:380]   Expert  2 |    218 | GPU
DEBUG 01-06 08:44:47.704026.704026 lmp.py:380]   Expert 43 |    227 | GPU
DEBUG 01-06 08:44:47.704239.704239 lmp.py:380]   Expert  5 |    235 | GPU
DEBUG 01-06 08:44:47.704213.704213 lmp.py:380]   Expert 21 |    240 | GPU
DEBUG 01-06 08:44:47.704425.704425 lmp.py:380]   Expert 55 |    256 | GPU
DEBUG 01-06 08:44:47.704399.704399 lmp.py:380]   Expert 61 |    256 | GPU
DEBUG 01-06 08:44:47.704373.704373 lmp.py:380]   Expert 22 |    257 | GPU
DEBUG 01-06 08:44:47.704586.704586 lmp.py:380]   Expert 46 |    280 | GPU
DEBUG 01-06 08:44:47.704798.704798 lmp.py:380]   Expert  4 |    297 | GPU
DEBUG 01-06 08:44:47.704203.704203 lmp.py:380]   Expert 62 |    302 | GPU
DEBUG 01-06 08:44:47.704515.704515 lmp.py:380]   Expert 27 |    304 | GPU
DEBUG 01-06 08:44:47.704727.704727 lmp.py:380]   Expert  0 |    312 | GPU
DEBUG 01-06 08:44:47.704701.704701 lmp.py:380]   Expert 29 |    326 | GPU
DEBUG 01-06 08:44:47.704914.704914 lmp.py:380]   Expert 17 |    337 | GPU
DEBUG 01-06 08:44:47.704888.704888 lmp.py:380]   Expert 31 |    343 | GPU
DEBUG 01-06 08:44:47.704862.704862 lmp.py:380]   Expert 16 |    369 | GPU
DEBUG 01-06 08:44:47.704074.704074 lmp.py:380]   Expert 45 |    390 | GPU
DEBUG 01-06 08:44:47.704479.704479 lmp.py:380]   Expert 50 |    393 | GPU
DEBUG 01-06 08:44:47.704406.704406 lmp.py:380]   Expert 36 |    438 | GPU
DEBUG 01-06 08:44:47.704573.704573 lmp.py:380]   Expert 37 |    605 | GPU
DEBUG 01-06 08:44:47.704739.704739 lmp.py:380]   Expert 30 |    727 | GPU
DEBUG 01-06 08:44:47.704666.704666 lmp.py:380]   Expert 42 |    856 | GPU
DEBUG 01-06 08:44:47.704548.704548 lmp.py:381] 
DEBUG 01-06 08:44:47.704548.704548 lmp.py:381]   CPU total tokens: 2645 (21.5%)
DEBUG 01-06 08:44:47.704860.704860 lmp.py:382]   GPU total tokens: 9643 (78.5%)
DEBUG 01-06 08:44:47.704516.704516 cuda_h.py:19] end experts_map_get cost 0.0015153884887695312 seconds
DEBUG 01-06 08:44:47.704113.704113 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.704320.704320 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.705954.705954 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.706467.706467 cuda_h.py:19] end allocate_cuda_memory cost 0.0012578964233398438 seconds
DEBUG 01-06 08:44:47.706027.706027 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.706949.706949 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.706089.706089 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.706216.706216 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 549a0a69-c955-42df-bf9b-5e6d2fc6b941
DEBUG 01-06 08:44:47.706500.706500 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.707855.707855 client.py:127] Model loaded
DEBUG 01-06 08:44:47.707513.707513 cuda_h.py:19] end sllm_worker_task cost 0.009799480438232422 seconds
INFO 01-06 08:44:47.707599.707599 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 549a0a69-c955-42df-bf9b-5e6d2fc6b941
DEBUG 01-06 08:44:47.707065.707065 cuda_h.py:19] end load_into_gpu_async cost 0.0012760162353515625 seconds
DEBUG 01-06 08:44:47.707768.707768 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.708885.708885 cuda_h.py:19] end restore_tensors2 cost 0.0002994537353515625 seconds
DEBUG 01-06 08:44:47.708184.708184 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003248453140258789 seconds
DEBUG 01-06 08:44:47.710585.710585 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005974292755126953 seconds
DEBUG 01-06 08:44:47.710176.710176 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.711762.711762 lmp.py:427] 
DEBUG 01-06 08:44:47.711762.711762 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.711174.711174 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 08:44:47.711229.711229 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.721184.721184 mlpmodule.py:704] group tensors cost 0.01018524169921875 s
DEBUG 01-06 08:44:47.723589.723589 mlpmodule.py:742] pad cost 0.0014834403991699219 s
DEBUG 01-06 08:44:47.723454.723454 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-06 08:44:47.723019.723019 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 08:44:47.735750.735750 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.735478.735478 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.735621.735621 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-06 08:44:47.735739.735739 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.754373.754373 mlpmodule.py:793] group einsum cost 0.03087139129638672 s
DEBUG 01-06 08:44:47.755537.755537 mlpmodule.py:801] cpy2cputensor cost 0.0005538463592529297 s
DEBUG 01-06 08:44:47.760474.760474 cuda_h.py:19] end wait_cetm_experts cost 0.04901003837585449 seconds
DEBUG 01-06 08:44:47.760258.760258 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.761654.761654 cuda_h.py:19] end gpu_sexperts cost 0.0008807182312011719 seconds
DEBUG 01-06 08:44:47.761265.761265 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.761168.761168 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:47.761540.761540 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.761488.761488 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 549a0a69-c955-42df-bf9b-5e6d2fc6b941
INFO 01-06 08:44:47.767049.767049 client.py:127] Model loaded
DEBUG 01-06 08:44:47.767846.767846 cuda_h.py:19] end wait_experts cost 0.0065500736236572266 seconds
DEBUG 01-06 08:44:47.767695.767695 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.768259.768259 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.768843.768843 mlpmodule.py:662]  experts func einsum cost 0.056999921798706055 s
DEBUG 01-06 08:44:47.779225.779225 cuda_h.py:19] end gpu_experts cost 0.011063575744628906 seconds
DEBUG 01-06 08:44:47.779884.779884 cuda_h.py:19] end layer_moe_generate_21 cost 0.07659077644348145 seconds
DEBUG 01-06 08:44:47.779996.779996 lmp.py:221] -------------------------------- end layer 21 --------------------------------
DEBUG 01-06 08:44:47.779328.779328 lmp.py:177] -------------------------------- start layer 22 --------------------------------
DEBUG 01-06 08:44:47.779547.779547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 08:44:47.779349.779349 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 08:44:47.779371.779371 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.574920654296875e-05 seconds
DEBUG 01-06 08:44:47.779664.779664 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.985664367675781e-05 seconds
DEBUG 01-06 08:44:47.779022.779022 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.779409.779409 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.779901.779901 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.779115.779115 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.780852.780852 cuda_h.py:19] end allocate_cuda_memory cost 0.0002295970916748047 seconds
DEBUG 01-06 08:44:47.780908.780908 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.780240.780240 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.780262.780262 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.780772.780772 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e8c0ef28-d5a7-4354-ba61-02333b72b929
DEBUG 01-06 08:44:47.780927.780927 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.780406.780406 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.781221.781221 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e8c0ef28-d5a7-4354-ba61-02333b72b929
DEBUG 01-06 08:44:47.781371.781371 cuda_h.py:19] end load_into_gpu_async cost 0.0013189315795898438 seconds
DEBUG 01-06 08:44:47.781929.781929 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.781450.781450 cuda_h.py:19] end restore_tensors2 cost 9.703636169433594e-05 seconds
DEBUG 01-06 08:44:47.781889.781889 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001957416534423828 seconds
INFO 01-06 08:44:47.782871.782871 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e8c0ef28-d5a7-4354-ba61-02333b72b929
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.784622.784622 cuda_h.py:19] end self_attn cost 0.003818511962890625 seconds
DEBUG 01-06 08:44:47.784963.784963 cuda_h.py:19] end iln_self_attn_paln cost 0.005123615264892578 seconds
DEBUG 01-06 08:44:47.784706.784706 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-06 08:44:47.784092.784092 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.785988.785988 cuda_h.py:19] end gate cost 0.0006258487701416016 seconds
DEBUG 01-06 08:44:47.785718.785718 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.785602.785602 lmp.py:369] 
DEBUG 01-06 08:44:47.785602.785602 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.785074.785074 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.785869.785869 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.785088.785088 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.785208.785208 lmp.py:373] 
DEBUG 01-06 08:44:47.785208.785208 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.785043.785043 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.785170.785170 lmp.py:380]   Expert 15 |     31 | CPU
DEBUG 01-06 08:44:47.785005.785005 lmp.py:380]   Expert 32 |     46 | CPU
DEBUG 01-06 08:44:47.785409.785409 lmp.py:380]   Expert 49 |     51 | CPU
DEBUG 01-06 08:44:47.785052.785052 lmp.py:380]   Expert 45 |     52 | CPU
DEBUG 01-06 08:44:47.786457.786457 lmp.py:380]   Expert  6 |     55 | CPU
DEBUG 01-06 08:44:47.786391.786391 lmp.py:380]   Expert 46 |     58 | CPU
DEBUG 01-06 08:44:47.786081.786081 lmp.py:380]   Expert 54 |     61 | CPU
DEBUG 01-06 08:44:47.786532.786532 lmp.py:380]   Expert 52 |     62 | CPU
DEBUG 01-06 08:44:47.786506.786506 lmp.py:380]   Expert 37 |     63 | CPU
DEBUG 01-06 08:44:47.786718.786718 lmp.py:380]   Expert 22 |     65 | CPU
DEBUG 01-06 08:44:47.786931.786931 lmp.py:380]   Expert 42 |     65 | CPU
DEBUG 01-06 08:44:47.786666.786666 lmp.py:380]   Expert 44 |     66 | CPU
DEBUG 01-06 08:44:47.786879.786879 lmp.py:380]   Expert 60 |     67 | CPU
DEBUG 01-06 08:44:47.786853.786853 lmp.py:380]   Expert 11 |     74 | CPU
DEBUG 01-06 08:44:47.786549.786549 lmp.py:380]   Expert 48 |     74 | CPU
DEBUG 01-06 08:44:47.786000.786000 lmp.py:380]   Expert 12 |     75 | CPU
DEBUG 01-06 08:44:47.786212.786212 lmp.py:380]   Expert 24 |     77 | CPU
DEBUG 01-06 08:44:47.786186.786186 lmp.py:380]   Expert 30 |     77 | CPU
DEBUG 01-06 08:44:47.786160.786160 lmp.py:380]   Expert 61 |     82 | CPU
DEBUG 01-06 08:44:47.786896.786896 lmp.py:380]   Expert 47 |     85 | CPU
DEBUG 01-06 08:44:47.786632.786632 lmp.py:380]   Expert 63 |     87 | CPU
DEBUG 01-06 08:44:47.786606.786606 lmp.py:380]   Expert 41 |     88 | CPU
DEBUG 01-06 08:44:47.786341.786341 lmp.py:380]   Expert  7 |     91 | CPU
DEBUG 01-06 08:44:47.786507.786507 lmp.py:380]   Expert 58 |    100 | CPU
DEBUG 01-06 08:44:47.786958.786958 lmp.py:380]   Expert  0 |    102 | CPU
DEBUG 01-06 08:44:47.786932.786932 lmp.py:380]   Expert 57 |    109 | CPU
DEBUG 01-06 08:44:47.786429.786429 lmp.py:380]   Expert 13 |    110 | CPU
DEBUG 01-06 08:44:47.786165.786165 lmp.py:380]   Expert 27 |    116 | CPU
DEBUG 01-06 08:44:47.786901.786901 lmp.py:380]   Expert  9 |    117 | CPU
DEBUG 01-06 08:44:47.786636.786636 lmp.py:380]   Expert 10 |    120 | CPU
DEBUG 01-06 08:44:47.786134.786134 lmp.py:380]   Expert 39 |    123 | CPU
DEBUG 01-06 08:44:47.786584.786584 lmp.py:380]   Expert  3 |    125 | CPU
DEBUG 01-06 08:44:47.786797.786797 lmp.py:380]   Expert 38 |    139 | GPU
DEBUG 01-06 08:44:47.786533.786533 lmp.py:380]   Expert 51 |    139 | GPU
DEBUG 01-06 08:44:47.786745.786745 lmp.py:380]   Expert 62 |    139 | GPU
DEBUG 01-06 08:44:47.786481.786481 lmp.py:380]   Expert 28 |    143 | GPU
DEBUG 01-06 08:44:47.786455.786455 lmp.py:380]   Expert 26 |    145 | GPU
DEBUG 01-06 08:44:47.786429.786429 lmp.py:380]   Expert 21 |    150 | GPU
DEBUG 01-06 08:44:47.786164.786164 lmp.py:380]   Expert  2 |    157 | GPU
DEBUG 01-06 08:44:47.786377.786377 lmp.py:380]   Expert 31 |    157 | GPU
DEBUG 01-06 08:44:47.786112.786112 lmp.py:380]   Expert 16 |    185 | GPU
DEBUG 01-06 08:44:47.786325.786325 lmp.py:380]   Expert  1 |    201 | GPU
DEBUG 01-06 08:44:47.786352.786352 lmp.py:380]   Expert 25 |    210 | GPU
DEBUG 01-06 08:44:47.786326.786326 lmp.py:380]   Expert 56 |    217 | GPU
DEBUG 01-06 08:44:47.786539.786539 lmp.py:380]   Expert 17 |    233 | GPU
DEBUG 01-06 08:44:47.786274.786274 lmp.py:380]   Expert 35 |    246 | GPU
DEBUG 01-06 08:44:47.786248.786248 lmp.py:380]   Expert 50 |    255 | GPU
DEBUG 01-06 08:44:47.786222.786222 lmp.py:380]   Expert 40 |    259 | GPU
DEBUG 01-06 08:44:47.786958.786958 lmp.py:380]   Expert 19 |    264 | GPU
DEBUG 01-06 08:44:47.786362.786362 lmp.py:380]   Expert 43 |    265 | GPU
DEBUG 01-06 08:44:47.786336.786336 lmp.py:380]   Expert 20 |    300 | GPU
DEBUG 01-06 08:44:47.786072.786072 lmp.py:380]   Expert 14 |    304 | GPU
DEBUG 01-06 08:44:47.786808.786808 lmp.py:380]   Expert  8 |    320 | GPU
DEBUG 01-06 08:44:47.786782.786782 lmp.py:380]   Expert 29 |    334 | GPU
DEBUG 01-06 08:44:47.786279.786279 lmp.py:380]   Expert 23 |    338 | GPU
DEBUG 01-06 08:44:47.786015.786015 lmp.py:380]   Expert  4 |    355 | GPU
DEBUG 01-06 08:44:47.786750.786750 lmp.py:380]   Expert 18 |    379 | GPU
DEBUG 01-06 08:44:47.786724.786724 lmp.py:380]   Expert 34 |    391 | GPU
DEBUG 01-06 08:44:47.786460.786460 lmp.py:380]   Expert 53 |    399 | GPU
DEBUG 01-06 08:44:47.786626.786626 lmp.py:380]   Expert 55 |    475 | GPU
DEBUG 01-06 08:44:47.786839.786839 lmp.py:380]   Expert 59 |    494 | GPU
DEBUG 01-06 08:44:47.786813.786813 lmp.py:380]   Expert 33 |    621 | GPU
DEBUG 01-06 08:44:47.786787.786787 lmp.py:380]   Expert 36 |    638 | GPU
DEBUG 01-06 08:44:47.786761.786761 lmp.py:380]   Expert  5 |    862 | GPU
DEBUG 01-06 08:44:47.786973.786973 lmp.py:381] 
DEBUG 01-06 08:44:47.786973.786973 lmp.py:381]   CPU total tokens: 2574 (20.9%)
DEBUG 01-06 08:44:47.787901.787901 lmp.py:382]   GPU total tokens: 9714 (79.1%)
DEBUG 01-06 08:44:47.787597.787597 cuda_h.py:19] end experts_map_get cost 0.001497030258178711 seconds
DEBUG 01-06 08:44:47.787955.787955 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.787685.787685 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.787915.787915 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.788026.788026 cuda_h.py:19] end allocate_cuda_memory cost 0.0013108253479003906 seconds
DEBUG 01-06 08:44:47.788300.788300 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.788394.788394 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.788309.788309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.788151.788151 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d5eddd0-c811-478a-aa55-a703ad7d8ea5
DEBUG 01-06 08:44:47.788766.788766 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.789232.789232 client.py:127] Model loaded
DEBUG 01-06 08:44:47.789287.789287 cuda_h.py:19] end sllm_worker_task cost 0.00955343246459961 seconds
INFO 01-06 08:44:47.789091.789091 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d5eddd0-c811-478a-aa55-a703ad7d8ea5
DEBUG 01-06 08:44:47.789126.789126 cuda_h.py:19] end load_into_gpu_async cost 0.0013093948364257812 seconds
DEBUG 01-06 08:44:47.790068.790068 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.790098.790098 cuda_h.py:19] end restore_tensors2 cost 0.0002770423889160156 seconds
DEBUG 01-06 08:44:47.790775.790775 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032389163970947266 seconds
DEBUG 01-06 08:44:47.793527.793527 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005976676940917969 seconds
DEBUG 01-06 08:44:47.793125.793125 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.793611.793611 lmp.py:427] 
DEBUG 01-06 08:44:47.793611.793611 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.793547.793547 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 08:44:47.793435.793435 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.804401.804401 mlpmodule.py:704] group tensors cost 0.011304616928100586 s
DEBUG 01-06 08:44:47.810155.810155 mlpmodule.py:742] pad cost 0.0038161277770996094 s
DEBUG 01-06 08:44:47.811731.811731 mlpmodule.py:748] create cpu tensor cost 7.367134094238281e-05 s
DEBUG 01-06 08:44:47.811649.811649 mlpmodule.py:753] move to cpu cost 5.1975250244140625e-05 s
DEBUG 01-06 08:44:47.823786.823786 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.824032.824032 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.824612.824612 mlpmodule.py:773] group_w3 first element: -0.018798828125
WARNING 01-06 08:44:47.824672.824672 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.844092.844092 mlpmodule.py:793] group einsum cost 0.03269553184509277 s
DEBUG 01-06 08:44:47.844193.844193 mlpmodule.py:801] cpy2cputensor cost 0.0006108283996582031 s
DEBUG 01-06 08:44:47.857675.857675 cuda_h.py:19] end wait_cetm_experts cost 0.06386208534240723 seconds
DEBUG 01-06 08:44:47.857251.857251 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.858989.858989 cuda_h.py:19] end gpu_sexperts cost 0.0010230541229248047 seconds
DEBUG 01-06 08:44:47.858753.858753 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.858371.858371 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-06 08:44:47.858981.858981 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.858167.858167 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d5eddd0-c811-478a-aa55-a703ad7d8ea5
INFO 01-06 08:44:47.859867.859867 client.py:127] Model loaded
DEBUG 01-06 08:44:47.859610.859610 cuda_h.py:19] end wait_experts cost 0.0009586811065673828 seconds
DEBUG 01-06 08:44:47.859883.859883 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.859393.859393 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.867912.867912 mlpmodule.py:662]  experts func einsum cost 0.07383179664611816 s
DEBUG 01-06 08:44:47.870108.870108 cuda_h.py:19] end gpu_experts cost 0.011253833770751953 seconds
DEBUG 01-06 08:44:47.871988.871988 cuda_h.py:19] end layer_moe_generate_22 cost 0.08630084991455078 seconds
DEBUG 01-06 08:44:47.871424.871424 lmp.py:221] -------------------------------- end layer 22 --------------------------------
DEBUG 01-06 08:44:47.871141.871141 lmp.py:177] -------------------------------- start layer 23 --------------------------------
DEBUG 01-06 08:44:47.871314.871314 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 08:44:47.871355.871355 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 08:44:47.871052.871052 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:44:47.871847.871847 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.984306335449219e-05 seconds
DEBUG 01-06 08:44:47.871159.871159 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.871757.871757 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.871338.871338 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.871646.871646 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.872318.872318 cuda_h.py:19] end allocate_cuda_memory cost 0.00023746490478515625 seconds
DEBUG 01-06 08:44:47.872891.872891 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.872912.872912 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.872352.872352 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.872876.872876 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1e7d64b-1b8c-4144-b14d-cd71e6b40a38
DEBUG 01-06 08:44:47.872595.872595 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.872828.872828 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.873452.873452 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1e7d64b-1b8c-4144-b14d-cd71e6b40a38
DEBUG 01-06 08:44:47.873044.873044 cuda_h.py:19] end load_into_gpu_async cost 0.0013594627380371094 seconds
DEBUG 01-06 08:44:47.873091.873091 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.873652.873652 cuda_h.py:19] end restore_tensors2 cost 9.655952453613281e-05 seconds
DEBUG 01-06 08:44:47.873118.873118 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020656585693359375 seconds
INFO 01-06 08:44:47.874901.874901 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1e7d64b-1b8c-4144-b14d-cd71e6b40a38
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.876497.876497 cuda_h.py:19] end self_attn cost 0.004081010818481445 seconds
DEBUG 01-06 08:44:47.877319.877319 cuda_h.py:19] end iln_self_attn_paln cost 0.005740165710449219 seconds
DEBUG 01-06 08:44:47.877401.877401 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-06 08:44:47.877548.877548 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.878358.878358 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-06 08:44:47.878565.878565 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.878621.878621 lmp.py:369] 
DEBUG 01-06 08:44:47.878621.878621 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.878231.878231 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.878404.878404 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.878478.878478 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.878167.878167 lmp.py:373] 
DEBUG 01-06 08:44:47.878167.878167 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.878572.878572 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.878221.878221 lmp.py:380]   Expert  5 |     25 | CPU
DEBUG 01-06 08:44:47.878388.878388 lmp.py:380]   Expert 49 |     25 | CPU
DEBUG 01-06 08:44:47.878838.878838 lmp.py:380]   Expert 44 |     38 | CPU
DEBUG 01-06 08:44:47.878813.878813 lmp.py:380]   Expert 16 |     43 | CPU
DEBUG 01-06 08:44:47.878263.878263 lmp.py:380]   Expert  6 |     44 | CPU
DEBUG 01-06 08:44:47.878430.878430 lmp.py:380]   Expert 27 |     57 | CPU
DEBUG 01-06 08:44:47.878596.878596 lmp.py:380]   Expert 17 |     64 | CPU
DEBUG 01-06 08:44:47.878808.878808 lmp.py:380]   Expert 25 |     71 | CPU
DEBUG 01-06 08:44:47.878544.878544 lmp.py:380]   Expert 19 |     85 | CPU
DEBUG 01-06 08:44:47.878279.878279 lmp.py:380]   Expert 63 |     85 | CPU
DEBUG 01-06 08:44:47.878777.878777 lmp.py:380]   Expert 53 |     86 | CPU
DEBUG 01-06 08:44:47.878274.878274 lmp.py:380]   Expert  1 |     87 | CPU
DEBUG 01-06 08:44:47.878771.878771 lmp.py:380]   Expert 38 |     89 | CPU
DEBUG 01-06 08:44:47.878507.878507 lmp.py:380]   Expert 51 |     90 | CPU
DEBUG 01-06 08:44:47.878434.878434 lmp.py:380]   Expert  7 |     92 | CPU
DEBUG 01-06 08:44:47.878647.878647 lmp.py:380]   Expert 40 |     92 | CPU
DEBUG 01-06 08:44:47.878621.878621 lmp.py:380]   Expert 28 |    108 | CPU
DEBUG 01-06 08:44:47.878118.878118 lmp.py:380]   Expert 45 |    110 | CPU
DEBUG 01-06 08:44:47.878854.878854 lmp.py:380]   Expert 35 |    113 | CPU
DEBUG 01-06 08:44:47.878351.878351 lmp.py:380]   Expert 34 |    117 | CPU
DEBUG 01-06 08:44:47.878087.878087 lmp.py:380]   Expert 52 |    117 | CPU
DEBUG 01-06 08:44:47.878537.878537 lmp.py:380]   Expert  4 |    123 | CPU
DEBUG 01-06 08:44:47.878796.878796 lmp.py:380]   Expert 30 |    130 | CPU
DEBUG 01-06 08:44:47.878293.878293 lmp.py:380]   Expert 55 |    132 | CPU
DEBUG 01-06 08:44:47.878744.878744 lmp.py:380]   Expert 61 |    132 | CPU
DEBUG 01-06 08:44:47.878434.878434 lmp.py:380]   Expert 15 |    133 | CPU
DEBUG 01-06 08:44:47.878931.878931 lmp.py:380]   Expert 24 |    133 | CPU
DEBUG 01-06 08:44:47.878097.878097 lmp.py:380]   Expert 22 |    139 | CPU
DEBUG 01-06 08:44:47.878501.878501 lmp.py:380]   Expert 43 |    139 | CPU
DEBUG 01-06 08:44:47.878952.878952 lmp.py:380]   Expert 47 |    148 | CPU
DEBUG 01-06 08:44:47.878403.878403 lmp.py:380]   Expert 58 |    150 | CPU
DEBUG 01-06 08:44:47.878854.878854 lmp.py:380]   Expert 42 |    157 | CPU
DEBUG 01-06 08:44:47.878067.878067 lmp.py:380]   Expert 36 |    162 | GPU
DEBUG 01-06 08:44:47.878994.878994 lmp.py:380]   Expert  3 |    165 | GPU
DEBUG 01-06 08:44:47.879545.879545 lmp.py:380]   Expert 14 |    166 | GPU
DEBUG 01-06 08:44:47.879188.879188 lmp.py:380]   Expert  9 |    170 | GPU
DEBUG 01-06 08:44:47.879115.879115 lmp.py:380]   Expert 13 |    171 | GPU
DEBUG 01-06 08:44:47.879805.879805 lmp.py:380]   Expert 39 |    173 | GPU
DEBUG 01-06 08:44:47.879779.879779 lmp.py:380]   Expert 60 |    178 | GPU
DEBUG 01-06 08:44:47.879230.879230 lmp.py:380]   Expert 41 |    187 | GPU
DEBUG 01-06 08:44:47.879919.879919 lmp.py:380]   Expert  0 |    196 | GPU
DEBUG 01-06 08:44:47.879085.879085 lmp.py:380]   Expert 37 |    199 | GPU
DEBUG 01-06 08:44:47.879966.879966 lmp.py:380]   Expert 26 |    201 | GPU
DEBUG 01-06 08:44:47.879417.879417 lmp.py:380]   Expert 11 |    208 | GPU
DEBUG 01-06 08:44:47.879868.879868 lmp.py:380]   Expert 23 |    220 | GPU
DEBUG 01-06 08:44:47.879557.879557 lmp.py:380]   Expert  8 |    229 | GPU
DEBUG 01-06 08:44:47.879008.879008 lmp.py:380]   Expert 46 |    232 | GPU
DEBUG 01-06 08:44:47.879413.879413 lmp.py:380]   Expert 33 |    244 | GPU
DEBUG 01-06 08:44:47.879864.879864 lmp.py:380]   Expert 29 |    261 | GPU
DEBUG 01-06 08:44:47.879315.879315 lmp.py:380]   Expert 20 |    280 | GPU
DEBUG 01-06 08:44:47.879242.879242 lmp.py:380]   Expert 56 |    281 | GPU
DEBUG 01-06 08:44:47.879409.879409 lmp.py:380]   Expert 62 |    298 | GPU
DEBUG 01-06 08:44:47.879859.879859 lmp.py:380]   Expert 59 |    300 | GPU
DEBUG 01-06 08:44:47.879310.879310 lmp.py:380]   Expert 57 |    302 | GPU
DEBUG 01-06 08:44:47.879761.879761 lmp.py:380]   Expert 54 |    344 | GPU
DEBUG 01-06 08:44:47.879212.879212 lmp.py:380]   Expert 18 |    367 | GPU
DEBUG 01-06 08:44:47.879663.879663 lmp.py:380]   Expert  2 |    378 | GPU
DEBUG 01-06 08:44:47.879114.879114 lmp.py:380]   Expert 21 |    378 | GPU
DEBUG 01-06 08:44:47.879803.879803 lmp.py:380]   Expert 50 |    387 | GPU
DEBUG 01-06 08:44:47.879731.879731 lmp.py:380]   Expert 32 |    393 | GPU
DEBUG 01-06 08:44:47.879612.879612 lmp.py:380]   Expert 48 |    410 | GPU
DEBUG 01-06 08:44:47.879302.879302 lmp.py:380]   Expert 10 |    465 | GPU
DEBUG 01-06 08:44:47.879514.879514 lmp.py:380]   Expert 31 |    507 | GPU
DEBUG 01-06 08:44:47.879965.879965 lmp.py:380]   Expert 12 |    682 | GPU
DEBUG 01-06 08:44:47.879131.879131 lmp.py:381] 
DEBUG 01-06 08:44:47.879131.879131 lmp.py:381]   CPU total tokens: 3154 (25.7%)
DEBUG 01-06 08:44:47.879774.879774 lmp.py:382]   GPU total tokens: 9134 (74.3%)
DEBUG 01-06 08:44:47.879470.879470 cuda_h.py:19] end experts_map_get cost 0.001482248306274414 seconds
DEBUG 01-06 08:44:47.879351.879351 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.879274.879274 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.879318.879318 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.880532.880532 cuda_h.py:19] end allocate_cuda_memory cost 0.00021386146545410156 seconds
DEBUG 01-06 08:44:47.880866.880866 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.880622.880622 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.880093.880093 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.880266.880266 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d31ca8c-6966-4c69-8722-7e449332ee84
DEBUG 01-06 08:44:47.880781.880781 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.880842.880842 client.py:127] Model loaded
DEBUG 01-06 08:44:47.880024.880024 cuda_h.py:19] end sllm_worker_task cost 0.009006261825561523 seconds
INFO 01-06 08:44:47.881479.881479 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d31ca8c-6966-4c69-8722-7e449332ee84
DEBUG 01-06 08:44:47.881753.881753 cuda_h.py:19] end load_into_gpu_async cost 0.0011475086212158203 seconds
DEBUG 01-06 08:44:47.881694.881694 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.881479.881479 cuda_h.py:19] end restore_tensors2 cost 0.0002720355987548828 seconds
DEBUG 01-06 08:44:47.881679.881679 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001996755599975586 seconds
DEBUG 01-06 08:44:47.884563.884563 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004691362380981445 seconds
DEBUG 01-06 08:44:47.884253.884253 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.884965.884965 lmp.py:427] 
DEBUG 01-06 08:44:47.884965.884965 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.884384.884384 cuda_h.py:19] end cpu_experts_submit cost 0.0001380443572998047 seconds
DEBUG 01-06 08:44:47.884465.884465 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.902517.902517 mlpmodule.py:704] group tensors cost 0.01750349998474121 s
DEBUG 01-06 08:44:47.905052.905052 mlpmodule.py:742] pad cost 0.002574920654296875 s
DEBUG 01-06 08:44:47.905865.905865 mlpmodule.py:748] create cpu tensor cost 6.270408630371094e-05 s
DEBUG 01-06 08:44:47.905265.905265 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-06 08:44:47.918128.918128 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.918121.918121 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.918508.918508 mlpmodule.py:773] group_w3 first element: 0.08447265625
WARNING 01-06 08:44:47.918069.918069 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:47.938122.938122 mlpmodule.py:793] group einsum cost 0.03260326385498047 s
DEBUG 01-06 08:44:47.939241.939241 mlpmodule.py:801] cpy2cputensor cost 0.0006103515625 s
DEBUG 01-06 08:44:47.944583.944583 cuda_h.py:19] end wait_cetm_experts cost 0.060024261474609375 seconds
DEBUG 01-06 08:44:47.944754.944754 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:47.945009.945009 cuda_h.py:19] end gpu_sexperts cost 0.0004620552062988281 seconds
DEBUG 01-06 08:44:47.945759.945759 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:47.945517.945517 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:47.945127.945127 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:47.945267.945267 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d31ca8c-6966-4c69-8722-7e449332ee84
INFO 01-06 08:44:47.946140.946140 client.py:127] Model loaded
DEBUG 01-06 08:44:47.946838.946838 cuda_h.py:19] end wait_experts cost 0.0010194778442382812 seconds
DEBUG 01-06 08:44:47.946494.946494 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:47.946727.946727 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:47.952156.952156 mlpmodule.py:662]  experts func einsum cost 0.06770753860473633 s
DEBUG 01-06 08:44:47.958745.958745 cuda_h.py:19] end gpu_experts cost 0.012400627136230469 seconds
DEBUG 01-06 08:44:47.959730.959730 cuda_h.py:19] end layer_moe_generate_23 cost 0.0817718505859375 seconds
DEBUG 01-06 08:44:47.959291.959291 lmp.py:221] -------------------------------- end layer 23 --------------------------------
DEBUG 01-06 08:44:47.959339.959339 lmp.py:177] -------------------------------- start layer 24 --------------------------------
DEBUG 01-06 08:44:47.959512.959512 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 08:44:47.959791.959791 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 08:44:47.959581.959581 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:47.959661.959661 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.793571472167969e-05 seconds
DEBUG 01-06 08:44:47.959543.959543 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:47.959412.959412 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:47.959368.959368 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.959012.959012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.960859.960859 cuda_h.py:19] end allocate_cuda_memory cost 0.0003437995910644531 seconds
DEBUG 01-06 08:44:47.960232.960232 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.960657.960657 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.960765.960765 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.960229.960229 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc8cfcb5-01e8-4ada-a684-fa1748f899cc
DEBUG 01-06 08:44:47.960152.960152 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:47.960495.960495 cuda_h.py:10] start self_attn
INFO 01-06 08:44:47.961139.961139 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc8cfcb5-01e8-4ada-a684-fa1748f899cc
DEBUG 01-06 08:44:47.961975.961975 cuda_h.py:19] end load_into_gpu_async cost 0.0011811256408691406 seconds
DEBUG 01-06 08:44:47.961770.961770 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.961191.961191 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-06 08:44:47.961616.961616 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018355846405029297 seconds
INFO 01-06 08:44:47.962448.962448 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc8cfcb5-01e8-4ada-a684-fa1748f899cc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:47.964923.964923 cuda_h.py:19] end self_attn cost 0.0034122467041015625 seconds
DEBUG 01-06 08:44:47.964495.964495 cuda_h.py:19] end iln_self_attn_paln cost 0.004888057708740234 seconds
DEBUG 01-06 08:44:47.964909.964909 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-06 08:44:47.964725.964725 cuda_h.py:10] start gate
DEBUG 01-06 08:44:47.965515.965515 cuda_h.py:19] end gate cost 0.00061798095703125 seconds
DEBUG 01-06 08:44:47.965960.965960 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:47.965322.965322 lmp.py:369] 
DEBUG 01-06 08:44:47.965322.965322 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:47.965746.965746 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:47.965588.965588 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:47.965284.965284 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:47.965596.965596 lmp.py:373] 
DEBUG 01-06 08:44:47.965596.965596 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:47.965385.965385 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:47.965373.965373 lmp.py:380]   Expert 47 |     32 | CPU
DEBUG 01-06 08:44:47.965208.965208 lmp.py:380]   Expert 44 |     33 | CPU
DEBUG 01-06 08:44:47.965328.965328 lmp.py:380]   Expert 56 |     34 | CPU
DEBUG 01-06 08:44:47.965971.965971 lmp.py:380]   Expert 42 |     37 | CPU
DEBUG 01-06 08:44:47.965375.965375 lmp.py:380]   Expert 43 |     43 | CPU
DEBUG 01-06 08:44:47.965780.965780 lmp.py:380]   Expert 16 |     45 | CPU
DEBUG 01-06 08:44:47.965184.965184 lmp.py:380]   Expert 48 |     53 | CPU
DEBUG 01-06 08:44:47.965350.965350 lmp.py:380]   Expert 30 |     54 | CPU
DEBUG 01-06 08:44:47.965755.965755 lmp.py:380]   Expert 54 |     67 | CPU
DEBUG 01-06 08:44:47.965159.965159 lmp.py:380]   Expert 22 |     69 | CPU
DEBUG 01-06 08:44:47.965564.965564 lmp.py:380]   Expert  5 |     78 | CPU
DEBUG 01-06 08:44:47.965730.965730 lmp.py:380]   Expert 55 |     80 | CPU
DEBUG 01-06 08:44:47.965327.965327 lmp.py:380]   Expert 25 |     82 | CPU
DEBUG 01-06 08:44:47.965731.965731 lmp.py:380]   Expert  2 |     85 | CPU
DEBUG 01-06 08:44:47.965897.965897 lmp.py:380]   Expert  6 |     88 | CPU
DEBUG 01-06 08:44:47.965064.965064 lmp.py:380]   Expert 62 |     92 | CPU
DEBUG 01-06 08:44:47.965707.965707 lmp.py:380]   Expert 21 |    105 | CPU
DEBUG 01-06 08:44:47.965873.965873 lmp.py:380]   Expert  0 |    109 | CPU
DEBUG 01-06 08:44:47.965800.965800 lmp.py:380]   Expert 51 |    112 | CPU
DEBUG 01-06 08:44:47.965443.965443 lmp.py:380]   Expert 15 |    120 | CPU
DEBUG 01-06 08:44:47.966371.966371 lmp.py:380]   Expert 61 |    121 | CPU
DEBUG 01-06 08:44:47.966299.966299 lmp.py:380]   Expert 28 |    126 | CPU
DEBUG 01-06 08:44:47.966703.966703 lmp.py:380]   Expert 41 |    128 | CPU
DEBUG 01-06 08:44:47.966870.966870 lmp.py:380]   Expert 63 |    136 | CPU
DEBUG 01-06 08:44:47.966036.966036 lmp.py:380]   Expert 20 |    140 | CPU
DEBUG 01-06 08:44:47.966202.966202 lmp.py:380]   Expert 35 |    140 | CPU
DEBUG 01-06 08:44:47.966891.966891 lmp.py:380]   Expert 60 |    141 | CPU
DEBUG 01-06 08:44:47.966819.966819 lmp.py:380]   Expert  3 |    142 | CPU
DEBUG 01-06 08:44:47.966747.966747 lmp.py:380]   Expert  1 |    144 | CPU
DEBUG 01-06 08:44:47.966674.966674 lmp.py:380]   Expert 36 |    146 | CPU
DEBUG 01-06 08:44:47.966602.966602 lmp.py:380]   Expert 59 |    148 | CPU
DEBUG 01-06 08:44:47.966768.966768 lmp.py:380]   Expert 57 |    149 | CPU
DEBUG 01-06 08:44:47.966934.966934 lmp.py:380]   Expert 24 |    156 | GPU
DEBUG 01-06 08:44:47.966624.966624 lmp.py:380]   Expert 29 |    156 | GPU
DEBUG 01-06 08:44:47.966313.966313 lmp.py:380]   Expert  7 |    168 | GPU
DEBUG 01-06 08:44:47.966241.966241 lmp.py:380]   Expert 50 |    175 | GPU
DEBUG 01-06 08:44:47.966168.966168 lmp.py:380]   Expert 19 |    176 | GPU
DEBUG 01-06 08:44:47.966096.966096 lmp.py:380]   Expert 40 |    176 | GPU
DEBUG 01-06 08:44:47.966262.966262 lmp.py:380]   Expert 46 |    182 | GPU
DEBUG 01-06 08:44:47.966190.966190 lmp.py:380]   Expert  4 |    183 | GPU
DEBUG 01-06 08:44:47.966356.966356 lmp.py:380]   Expert 34 |    192 | GPU
DEBUG 01-06 08:44:47.966045.966045 lmp.py:380]   Expert 38 |    196 | GPU
DEBUG 01-06 08:44:47.966973.966973 lmp.py:380]   Expert 17 |    198 | GPU
DEBUG 01-06 08:44:47.966662.966662 lmp.py:380]   Expert 53 |    198 | GPU
DEBUG 01-06 08:44:47.966590.966590 lmp.py:380]   Expert 33 |    200 | GPU
DEBUG 01-06 08:44:47.966041.966041 lmp.py:380]   Expert 39 |    203 | GPU
DEBUG 01-06 08:44:47.966969.966969 lmp.py:380]   Expert 26 |    208 | GPU
DEBUG 01-06 08:44:47.966135.966135 lmp.py:380]   Expert 49 |    219 | GPU
DEBUG 01-06 08:44:47.966301.966301 lmp.py:380]   Expert 12 |    225 | GPU
DEBUG 01-06 08:44:47.966990.966990 lmp.py:380]   Expert 10 |    241 | GPU
DEBUG 01-06 08:44:47.966918.966918 lmp.py:380]   Expert  9 |    245 | GPU
DEBUG 01-06 08:44:47.966607.966607 lmp.py:380]   Expert 45 |    268 | GPU
DEBUG 01-06 08:44:47.966820.966820 lmp.py:380]   Expert 18 |    288 | GPU
DEBUG 01-06 08:44:47.966509.966509 lmp.py:380]   Expert 14 |    292 | GPU
DEBUG 01-06 08:44:47.966437.966437 lmp.py:380]   Expert 37 |    296 | GPU
DEBUG 01-06 08:44:47.966364.966364 lmp.py:380]   Expert 58 |    303 | GPU
DEBUG 01-06 08:44:47.966292.966292 lmp.py:380]   Expert 23 |    304 | GPU
DEBUG 01-06 08:44:47.966981.966981 lmp.py:380]   Expert 52 |    308 | GPU
DEBUG 01-06 08:44:47.966432.966432 lmp.py:380]   Expert 31 |    319 | GPU
DEBUG 01-06 08:44:47.966374.966374 lmp.py:380]   Expert  8 |    482 | GPU
DEBUG 01-06 08:44:47.966301.966301 lmp.py:380]   Expert 11 |    519 | GPU
DEBUG 01-06 08:44:47.966752.966752 lmp.py:380]   Expert 13 |    583 | GPU
DEBUG 01-06 08:44:47.966965.966965 lmp.py:380]   Expert 32 |    754 | GPU
DEBUG 01-06 08:44:47.966892.966892 lmp.py:380]   Expert 27 |    796 | GPU
DEBUG 01-06 08:44:47.966297.966297 lmp.py:381] 
DEBUG 01-06 08:44:47.966297.966297 lmp.py:381]   CPU total tokens: 3079 (25.1%)
DEBUG 01-06 08:44:47.966940.966940 lmp.py:382]   GPU total tokens: 9209 (74.9%)
DEBUG 01-06 08:44:47.966067.966067 cuda_h.py:19] end experts_map_get cost 0.0015592575073242188 seconds
DEBUG 01-06 08:44:47.966378.966378 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:47.966777.966777 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:47.966292.966292 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:47.968987.968987 cuda_h.py:19] end allocate_cuda_memory cost 0.0015311241149902344 seconds
DEBUG 01-06 08:44:47.968751.968751 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:47.968652.968652 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:47.968799.968799 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:47.968880.968880 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 76a50c09-79d4-4f6d-88b8-931b5852c72a
DEBUG 01-06 08:44:47.968972.968972 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:47.969439.969439 client.py:127] Model loaded
DEBUG 01-06 08:44:47.969534.969534 cuda_h.py:19] end sllm_worker_task cost 0.009710073471069336 seconds
INFO 01-06 08:44:47.969955.969955 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 76a50c09-79d4-4f6d-88b8-931b5852c72a
DEBUG 01-06 08:44:47.970228.970228 cuda_h.py:19] end load_into_gpu_async cost 0.0013699531555175781 seconds
DEBUG 01-06 08:44:47.970693.970693 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:47.970438.970438 cuda_h.py:19] end restore_tensors2 cost 0.00027632713317871094 seconds
DEBUG 01-06 08:44:47.970923.970923 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003524303436279297 seconds
DEBUG 01-06 08:44:47.973622.973622 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006259441375732422 seconds
DEBUG 01-06 08:44:47.973313.973313 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:47.973514.973514 lmp.py:427] 
DEBUG 01-06 08:44:47.973514.973514 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:47.973165.973165 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-06 08:44:47.973245.973245 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:47.980247.980247 mlpmodule.py:704] group tensors cost 0.007212638854980469 s
DEBUG 01-06 08:44:47.983590.983590 mlpmodule.py:742] pad cost 0.002175569534301758 s
DEBUG 01-06 08:44:47.983971.983971 mlpmodule.py:748] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-06 08:44:47.983251.983251 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-06 08:44:47.995891.995891 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:47.995937.995937 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:47.995503.995503 mlpmodule.py:773] group_w3 first element: 0.00653076171875
WARNING 01-06 08:44:47.995441.995441 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:48.015098.015098 mlpmodule.py:793] group einsum cost 0.03171515464782715 s
DEBUG 01-06 08:44:48.016831.016831 mlpmodule.py:801] cpy2cputensor cost 0.0007207393646240234 s
DEBUG 01-06 08:44:48.021960.021960 cuda_h.py:19] end wait_cetm_experts cost 0.0479886531829834 seconds
DEBUG 01-06 08:44:48.021982.021982 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:48.022221.022221 cuda_h.py:19] end gpu_sexperts cost 0.0009396076202392578 seconds
DEBUG 01-06 08:44:48.022256.022256 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:48.022728.022728 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:44:48.022338.022338 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:48.022763.022763 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 76a50c09-79d4-4f6d-88b8-931b5852c72a
DEBUG 01-06 08:44:48.029840.029840 mlpmodule.py:662]  experts func einsum cost 0.05560159683227539 s
INFO 01-06 08:44:48.029402.029402 client.py:127] Model loaded
DEBUG 01-06 08:44:48.029735.029735 cuda_h.py:19] end wait_experts cost 0.007071495056152344 seconds
DEBUG 01-06 08:44:48.029730.029730 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:48.029962.029962 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:48.040554.040554 cuda_h.py:19] end gpu_experts cost 0.010926246643066406 seconds
DEBUG 01-06 08:44:48.040266.040266 cuda_h.py:19] end layer_moe_generate_24 cost 0.0762791633605957 seconds
DEBUG 01-06 08:44:48.040053.040053 lmp.py:221] -------------------------------- end layer 24 --------------------------------
DEBUG 01-06 08:44:48.040007.040007 lmp.py:177] -------------------------------- start layer 25 --------------------------------
DEBUG 01-06 08:44:48.041896.041896 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 08:44:48.041460.041460 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 08:44:48.041773.041773 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.7894973754882812e-05 seconds
DEBUG 01-06 08:44:48.041568.041568 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.793571472167969e-05 seconds
DEBUG 01-06 08:44:48.041403.041403 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:48.041042.041042 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:48.041296.041296 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:48.041894.041894 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:48.041221.041221 cuda_h.py:19] end allocate_cuda_memory cost 0.00024127960205078125 seconds
DEBUG 01-06 08:44:48.041853.041853 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:48.041947.041947 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:48.041432.041432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:48.041750.041750 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f12ad79b-99ee-40f2-af8a-5fb952b80c88
DEBUG 01-06 08:44:48.041905.041905 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:48.042688.042688 cuda_h.py:10] start self_attn
INFO 01-06 08:44:48.042860.042860 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f12ad79b-99ee-40f2-af8a-5fb952b80c88
DEBUG 01-06 08:44:48.042300.042300 cuda_h.py:19] end load_into_gpu_async cost 0.001241922378540039 seconds
DEBUG 01-06 08:44:48.043956.043956 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:48.043523.043523 cuda_h.py:19] end restore_tensors2 cost 7.486343383789062e-05 seconds
DEBUG 01-06 08:44:48.043279.043279 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001813650131225586 seconds
INFO 01-06 08:44:48.043441.043441 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f12ad79b-99ee-40f2-af8a-5fb952b80c88
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:48.045480.045480 cuda_h.py:19] end self_attn cost 0.0032095909118652344 seconds
DEBUG 01-06 08:44:48.045390.045390 cuda_h.py:19] end iln_self_attn_paln cost 0.0045261383056640625 seconds
DEBUG 01-06 08:44:48.045134.045134 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-06 08:44:48.045658.045658 cuda_h.py:10] start gate
DEBUG 01-06 08:44:48.046078.046078 cuda_h.py:19] end gate cost 0.0006260871887207031 seconds
DEBUG 01-06 08:44:48.046046.046046 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:48.046056.046056 lmp.py:369] 
DEBUG 01-06 08:44:48.046056.046056 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:48.046858.046858 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:48.046938.046938 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:48.046966.046966 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:48.046132.046132 lmp.py:373] 
DEBUG 01-06 08:44:48.046132.046132 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:48.046536.046536 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:48.046424.046424 lmp.py:380]   Expert 55 |     15 | CPU
DEBUG 01-06 08:44:48.046067.046067 lmp.py:380]   Expert 33 |     19 | CPU
DEBUG 01-06 08:44:48.046234.046234 lmp.py:380]   Expert 42 |     20 | CPU
DEBUG 01-06 08:44:48.046115.046115 lmp.py:380]   Expert  0 |     28 | CPU
DEBUG 01-06 08:44:48.046804.046804 lmp.py:380]   Expert 16 |     34 | CPU
DEBUG 01-06 08:44:48.046162.046162 lmp.py:380]   Expert 22 |     39 | CPU
DEBUG 01-06 08:44:48.047805.047805 lmp.py:380]   Expert 24 |     39 | CPU
DEBUG 01-06 08:44:48.047210.047210 lmp.py:380]   Expert 36 |     39 | CPU
DEBUG 01-06 08:44:48.047615.047615 lmp.py:380]   Expert  2 |     42 | CPU
DEBUG 01-06 08:44:48.047496.047496 lmp.py:380]   Expert 32 |     43 | CPU
DEBUG 01-06 08:44:48.047854.047854 lmp.py:380]   Expert 34 |     58 | CPU
DEBUG 01-06 08:44:48.047259.047259 lmp.py:380]   Expert 59 |     58 | CPU
DEBUG 01-06 08:44:48.047663.047663 lmp.py:380]   Expert 23 |     69 | CPU
DEBUG 01-06 08:44:48.047068.047068 lmp.py:380]   Expert 10 |     71 | CPU
DEBUG 01-06 08:44:48.047234.047234 lmp.py:380]   Expert 20 |     74 | CPU
DEBUG 01-06 08:44:48.047400.047400 lmp.py:380]   Expert 18 |     75 | CPU
DEBUG 01-06 08:44:48.047566.047566 lmp.py:380]   Expert 21 |     80 | CPU
DEBUG 01-06 08:44:48.047971.047971 lmp.py:380]   Expert 38 |     85 | CPU
DEBUG 01-06 08:44:48.047614.047614 lmp.py:380]   Expert 13 |     86 | CPU
DEBUG 01-06 08:44:48.047972.047972 lmp.py:380]   Expert 53 |     91 | CPU
DEBUG 01-06 08:44:48.047138.047138 lmp.py:380]   Expert 47 |     92 | CPU
DEBUG 01-06 08:44:48.047304.047304 lmp.py:380]   Expert 62 |     99 | CPU
DEBUG 01-06 08:44:48.047470.047470 lmp.py:380]   Expert 44 |    100 | CPU
DEBUG 01-06 08:44:48.047637.047637 lmp.py:380]   Expert 27 |    101 | CPU
DEBUG 01-06 08:44:48.047803.047803 lmp.py:380]   Expert 50 |    102 | CPU
DEBUG 01-06 08:44:48.047730.047730 lmp.py:380]   Expert 46 |    103 | CPU
DEBUG 01-06 08:44:48.047135.047135 lmp.py:380]   Expert 14 |    117 | CPU
DEBUG 01-06 08:44:48.047778.047778 lmp.py:380]   Expert 31 |    118 | CPU
DEBUG 01-06 08:44:48.047659.047659 lmp.py:380]   Expert 35 |    131 | CPU
DEBUG 01-06 08:44:48.047302.047302 lmp.py:380]   Expert 43 |    141 | CPU
DEBUG 01-06 08:44:48.047468.047468 lmp.py:380]   Expert 52 |    142 | CPU
DEBUG 01-06 08:44:48.047635.047635 lmp.py:380]   Expert 51 |    149 | CPU
DEBUG 01-06 08:44:48.047324.047324 lmp.py:380]   Expert  8 |    158 | GPU
DEBUG 01-06 08:44:48.047252.047252 lmp.py:380]   Expert 45 |    158 | GPU
DEBUG 01-06 08:44:48.047179.047179 lmp.py:380]   Expert 56 |    161 | GPU
DEBUG 01-06 08:44:48.047299.047299 lmp.py:380]   Expert  4 |    165 | GPU
DEBUG 01-06 08:44:48.047181.047181 lmp.py:380]   Expert 11 |    176 | GPU
DEBUG 01-06 08:44:48.047347.047347 lmp.py:380]   Expert 48 |    178 | GPU
DEBUG 01-06 08:44:48.047036.047036 lmp.py:380]   Expert 12 |    184 | GPU
DEBUG 01-06 08:44:48.047964.047964 lmp.py:380]   Expert 39 |    203 | GPU
DEBUG 01-06 08:44:48.047891.047891 lmp.py:380]   Expert  5 |    206 | GPU
DEBUG 01-06 08:44:48.047581.047581 lmp.py:380]   Expert 15 |    237 | GPU
DEBUG 01-06 08:44:48.047270.047270 lmp.py:380]   Expert 57 |    242 | GPU
DEBUG 01-06 08:44:48.047959.047959 lmp.py:380]   Expert  6 |    244 | GPU
DEBUG 01-06 08:44:48.047125.047125 lmp.py:380]   Expert  3 |    253 | GPU
DEBUG 01-06 08:44:48.047768.047768 lmp.py:380]   Expert 37 |    261 | GPU
DEBUG 01-06 08:44:48.047173.047173 lmp.py:380]   Expert 41 |    265 | GPU
DEBUG 01-06 08:44:48.047339.047339 lmp.py:380]   Expert 61 |    278 | GPU
DEBUG 01-06 08:44:48.047790.047790 lmp.py:380]   Expert 25 |    284 | GPU
DEBUG 01-06 08:44:48.047718.047718 lmp.py:380]   Expert 63 |    287 | GPU
DEBUG 01-06 08:44:48.047645.047645 lmp.py:380]   Expert 26 |    289 | GPU
DEBUG 01-06 08:44:48.047335.047335 lmp.py:380]   Expert 28 |    348 | GPU
DEBUG 01-06 08:44:48.047024.047024 lmp.py:380]   Expert 30 |    371 | GPU
DEBUG 01-06 08:44:48.047952.047952 lmp.py:380]   Expert 40 |    371 | GPU
DEBUG 01-06 08:44:48.047833.047833 lmp.py:380]   Expert 49 |    371 | GPU
DEBUG 01-06 08:44:48.047476.047476 lmp.py:380]   Expert 58 |    372 | GPU
DEBUG 01-06 08:44:48.047642.047642 lmp.py:380]   Expert  7 |    387 | GPU
DEBUG 01-06 08:44:48.047855.047855 lmp.py:380]   Expert 29 |    388 | GPU
DEBUG 01-06 08:44:48.047544.047544 lmp.py:380]   Expert 54 |    409 | GPU
DEBUG 01-06 08:44:48.047472.047472 lmp.py:380]   Expert  9 |    414 | GPU
DEBUG 01-06 08:44:48.047161.047161 lmp.py:380]   Expert  1 |    456 | GPU
DEBUG 01-06 08:44:48.047089.047089 lmp.py:380]   Expert 17 |    466 | GPU
DEBUG 01-06 08:44:48.047778.047778 lmp.py:380]   Expert 60 |    560 | GPU
DEBUG 01-06 08:44:48.047229.047229 lmp.py:380]   Expert 19 |    686 | GPU
DEBUG 01-06 08:44:48.048064.048064 lmp.py:381] 
DEBUG 01-06 08:44:48.048064.048064 lmp.py:381]   CPU total tokens: 2460 (20.0%)
DEBUG 01-06 08:44:48.048899.048899 lmp.py:382]   GPU total tokens: 9828 (80.0%)
DEBUG 01-06 08:44:48.048787.048787 cuda_h.py:19] end experts_map_get cost 0.0015366077423095703 seconds
DEBUG 01-06 08:44:48.048669.048669 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:48.048922.048922 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:48.048443.048443 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:48.050909.050909 cuda_h.py:19] end allocate_cuda_memory cost 0.0018188953399658203 seconds
DEBUG 01-06 08:44:48.050249.050249 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:48.050005.050005 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:48.050152.050152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:48.050663.050663 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 300e81f7-653c-4528-922c-2fd102cda0f4
DEBUG 01-06 08:44:48.050901.050901 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:48.050586.050586 client.py:127] Model loaded
DEBUG 01-06 08:44:48.050635.050635 cuda_h.py:19] end sllm_worker_task cost 0.009520292282104492 seconds
INFO 01-06 08:44:48.051791.051791 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 300e81f7-653c-4528-922c-2fd102cda0f4
DEBUG 01-06 08:44:48.051111.051111 cuda_h.py:19] end load_into_gpu_async cost 0.0013742446899414062 seconds
DEBUG 01-06 08:44:48.051099.051099 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:48.051937.051937 cuda_h.py:19] end restore_tensors2 cost 0.0002758502960205078 seconds
DEBUG 01-06 08:44:48.051183.051183 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038213729858398438 seconds
DEBUG 01-06 08:44:48.054628.054628 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00647282600402832 seconds
DEBUG 01-06 08:44:48.054981.054981 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:48.054057.054057 lmp.py:427] 
DEBUG 01-06 08:44:48.054057.054057 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:48.054476.054476 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-06 08:44:48.054841.054841 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:48.066812.066812 mlpmodule.py:704] group tensors cost 0.011854171752929688 s
DEBUG 01-06 08:44:48.069720.069720 mlpmodule.py:742] pad cost 0.001556396484375 s
DEBUG 01-06 08:44:48.069472.069472 mlpmodule.py:748] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-06 08:44:48.069891.069891 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 08:44:48.081192.081192 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:48.081344.081344 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:48.081910.081910 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-06 08:44:48.081656.081656 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:48.100883.100883 mlpmodule.py:793] group einsum cost 0.030918598175048828 s
DEBUG 01-06 08:44:48.101158.101158 mlpmodule.py:801] cpy2cputensor cost 0.0006968975067138672 s
DEBUG 01-06 08:44:48.106668.106668 cuda_h.py:19] end wait_cetm_experts cost 0.051163673400878906 seconds
DEBUG 01-06 08:44:48.106737.106737 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:48.107248.107248 cuda_h.py:19] end gpu_sexperts cost 0.0011744499206542969 seconds
DEBUG 01-06 08:44:48.107661.107661 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:48.107610.107610 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:44:48.107220.107220 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:48.107029.107029 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 300e81f7-653c-4528-922c-2fd102cda0f4
INFO 01-06 08:44:48.110571.110571 client.py:127] Model loaded
DEBUG 01-06 08:44:48.110844.110844 cuda_h.py:19] end wait_experts cost 0.0033779144287109375 seconds
DEBUG 01-06 08:44:48.110170.110170 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:48.110926.110926 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:48.113983.113983 mlpmodule.py:662]  experts func einsum cost 0.05890607833862305 s
DEBUG 01-06 08:44:48.122211.122211 cuda_h.py:19] end gpu_experts cost 0.011475324630737305 seconds
DEBUG 01-06 08:44:48.122923.122923 cuda_h.py:19] end layer_moe_generate_25 cost 0.07674288749694824 seconds
DEBUG 01-06 08:44:48.122511.122511 lmp.py:221] -------------------------------- end layer 25 --------------------------------
DEBUG 01-06 08:44:48.122082.122082 lmp.py:177] -------------------------------- start layer 26 --------------------------------
DEBUG 01-06 08:44:48.122586.122586 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 08:44:48.122434.122434 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 08:44:48.122741.122741 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.574920654296875e-05 seconds
DEBUG 01-06 08:44:48.122795.122795 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.937980651855469e-05 seconds
DEBUG 01-06 08:44:48.122915.122915 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:48.122838.122838 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:48.123331.123331 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:48.123452.123452 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:48.123542.123542 cuda_h.py:19] end allocate_cuda_memory cost 0.0002772808074951172 seconds
DEBUG 01-06 08:44:48.123273.123273 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:48.123605.123605 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:48.123567.123567 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:48.123886.123886 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 72c684b4-923b-4fdd-b58f-b09080dc5ad2
DEBUG 01-06 08:44:48.123279.123279 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:48.123942.123942 cuda_h.py:10] start self_attn
INFO 01-06 08:44:48.124134.124134 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 72c684b4-923b-4fdd-b58f-b09080dc5ad2
DEBUG 01-06 08:44:48.124971.124971 cuda_h.py:19] end load_into_gpu_async cost 0.0012164115905761719 seconds
DEBUG 01-06 08:44:48.124005.124005 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:48.124518.124518 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-06 08:44:48.124797.124797 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018188953399658203 seconds
INFO 01-06 08:44:48.125827.125827 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 72c684b4-923b-4fdd-b58f-b09080dc5ad2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:48.127005.127005 cuda_h.py:19] end self_attn cost 0.0032148361206054688 seconds
DEBUG 01-06 08:44:48.127207.127207 cuda_h.py:19] end iln_self_attn_paln cost 0.00453948974609375 seconds
DEBUG 01-06 08:44:48.127666.127666 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-06 08:44:48.127429.127429 cuda_h.py:10] start gate
DEBUG 01-06 08:44:48.128279.128279 cuda_h.py:19] end gate cost 0.0006289482116699219 seconds
DEBUG 01-06 08:44:48.128532.128532 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:48.128152.128152 lmp.py:369] 
DEBUG 01-06 08:44:48.128152.128152 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:48.128623.128623 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:48.128226.128226 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:48.128777.128777 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:48.128943.128943 lmp.py:373] 
DEBUG 01-06 08:44:48.128943.128943 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:48.128870.128870 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:48.128520.128520 lmp.py:380]   Expert 62 |      7 | CPU
DEBUG 01-06 08:44:48.128163.128163 lmp.py:380]   Expert 30 |     23 | CPU
DEBUG 01-06 08:44:48.128852.128852 lmp.py:380]   Expert 22 |     24 | CPU
DEBUG 01-06 08:44:48.128449.128449 lmp.py:380]   Expert  7 |     27 | CPU
DEBUG 01-06 08:44:48.128092.128092 lmp.py:380]   Expert  3 |     31 | CPU
DEBUG 01-06 08:44:48.128212.128212 lmp.py:380]   Expert 17 |     34 | CPU
DEBUG 01-06 08:44:48.128332.128332 lmp.py:380]   Expert 15 |     45 | CPU
DEBUG 01-06 08:44:48.128213.128213 lmp.py:380]   Expert 49 |     50 | CPU
DEBUG 01-06 08:44:48.128856.128856 lmp.py:380]   Expert 58 |     50 | CPU
DEBUG 01-06 08:44:48.128976.128976 lmp.py:380]   Expert 27 |     70 | CPU
DEBUG 01-06 08:44:48.128380.128380 lmp.py:380]   Expert 12 |     73 | CPU
DEBUG 01-06 08:44:48.128547.128547 lmp.py:380]   Expert 34 |     76 | CPU
DEBUG 01-06 08:44:48.128474.128474 lmp.py:380]   Expert 53 |     79 | CPU
DEBUG 01-06 08:44:48.128640.128640 lmp.py:380]   Expert 24 |     83 | CPU
DEBUG 01-06 08:44:48.128807.128807 lmp.py:380]   Expert 61 |     85 | CPU
DEBUG 01-06 08:44:48.128734.128734 lmp.py:380]   Expert  6 |     86 | CPU
DEBUG 01-06 08:44:48.128662.128662 lmp.py:380]   Expert 51 |     87 | CPU
DEBUG 01-06 08:44:48.128590.128590 lmp.py:380]   Expert  8 |     88 | CPU
DEBUG 01-06 08:44:48.128233.128233 lmp.py:380]   Expert 21 |     91 | CPU
DEBUG 01-06 08:44:48.129353.129353 lmp.py:380]   Expert 59 |     93 | CPU
DEBUG 01-06 08:44:48.129996.129996 lmp.py:380]   Expert 29 |     94 | CPU
DEBUG 01-06 08:44:48.129639.129639 lmp.py:380]   Expert 56 |     95 | CPU
DEBUG 01-06 08:44:48.129805.129805 lmp.py:380]   Expert 43 |     96 | CPU
DEBUG 01-06 08:44:48.129732.129732 lmp.py:380]   Expert 38 |    107 | CPU
DEBUG 01-06 08:44:48.129899.129899 lmp.py:380]   Expert 13 |    109 | CPU
DEBUG 01-06 08:44:48.129826.129826 lmp.py:380]   Expert 11 |    113 | CPU
DEBUG 01-06 08:44:48.129754.129754 lmp.py:380]   Expert 57 |    119 | CPU
DEBUG 01-06 08:44:48.129920.129920 lmp.py:380]   Expert 28 |    121 | CPU
DEBUG 01-06 08:44:48.129609.129609 lmp.py:380]   Expert 36 |    125 | CPU
DEBUG 01-06 08:44:48.129299.129299 lmp.py:380]   Expert 41 |    128 | CPU
DEBUG 01-06 08:44:48.129988.129988 lmp.py:380]   Expert 26 |    129 | CPU
DEBUG 01-06 08:44:48.129631.129631 lmp.py:380]   Expert  0 |    131 | CPU
DEBUG 01-06 08:44:48.129751.129751 lmp.py:380]   Expert 54 |    133 | GPU
DEBUG 01-06 08:44:48.129586.129586 lmp.py:380]   Expert 20 |    136 | GPU
DEBUG 01-06 08:44:48.129467.129467 lmp.py:380]   Expert  9 |    145 | GPU
DEBUG 01-06 08:44:48.129633.129633 lmp.py:380]   Expert 32 |    152 | GPU
DEBUG 01-06 08:44:48.129323.129323 lmp.py:380]   Expert 60 |    154 | GPU
DEBUG 01-06 08:44:48.129012.129012 lmp.py:380]   Expert 47 |    157 | GPU
DEBUG 01-06 08:44:48.129178.129178 lmp.py:380]   Expert 45 |    158 | GPU
DEBUG 01-06 08:44:48.129867.129867 lmp.py:380]   Expert 42 |    162 | GPU
DEBUG 01-06 08:44:48.129795.129795 lmp.py:380]   Expert  1 |    166 | GPU
DEBUG 01-06 08:44:48.129484.129484 lmp.py:380]   Expert 23 |    169 | GPU
DEBUG 01-06 08:44:48.129412.129412 lmp.py:380]   Expert 19 |    182 | GPU
DEBUG 01-06 08:44:48.129578.129578 lmp.py:380]   Expert 44 |    207 | GPU
DEBUG 01-06 08:44:48.129221.129221 lmp.py:380]   Expert 55 |    211 | GPU
DEBUG 01-06 08:44:48.129864.129864 lmp.py:380]   Expert 37 |    239 | GPU
DEBUG 01-06 08:44:48.129507.129507 lmp.py:380]   Expert  5 |    241 | GPU
DEBUG 01-06 08:44:48.129150.129150 lmp.py:380]   Expert 39 |    245 | GPU
DEBUG 01-06 08:44:48.129316.129316 lmp.py:380]   Expert 10 |    255 | GPU
DEBUG 01-06 08:44:48.129006.129006 lmp.py:380]   Expert 48 |    263 | GPU
DEBUG 01-06 08:44:48.129933.129933 lmp.py:380]   Expert 50 |    268 | GPU
DEBUG 01-06 08:44:48.129384.129384 lmp.py:380]   Expert 16 |    274 | GPU
DEBUG 01-06 08:44:48.129074.129074 lmp.py:380]   Expert 25 |    278 | GPU
DEBUG 01-06 08:44:48.129001.129001 lmp.py:380]   Expert  2 |    279 | GPU
DEBUG 01-06 08:44:48.129896.129896 lmp.py:380]   Expert  4 |    279 | GPU
DEBUG 01-06 08:44:48.129539.129539 lmp.py:380]   Expert 31 |    283 | GPU
DEBUG 01-06 08:44:48.129705.129705 lmp.py:380]   Expert 33 |    285 | GPU
DEBUG 01-06 08:44:48.129633.129633 lmp.py:380]   Expert 18 |    296 | GPU
DEBUG 01-06 08:44:48.129322.129322 lmp.py:380]   Expert 63 |    328 | GPU
DEBUG 01-06 08:44:48.129773.129773 lmp.py:380]   Expert 35 |    456 | GPU
DEBUG 01-06 08:44:48.129986.129986 lmp.py:380]   Expert 40 |    574 | GPU
DEBUG 01-06 08:44:48.129437.129437 lmp.py:380]   Expert 46 |    629 | GPU
DEBUG 01-06 08:44:48.129126.129126 lmp.py:380]   Expert 52 |    852 | GPU
DEBUG 01-06 08:44:48.129815.129815 lmp.py:380]   Expert 14 |   1263 | GPU
DEBUG 01-06 08:44:48.129981.129981 lmp.py:381] 
DEBUG 01-06 08:44:48.129981.129981 lmp.py:381]   CPU total tokens: 2569 (20.9%)
DEBUG 01-06 08:44:48.129386.129386 lmp.py:382]   GPU total tokens: 9719 (79.1%)
DEBUG 01-06 08:44:48.129082.129082 cuda_h.py:19] end experts_map_get cost 0.0015718936920166016 seconds
DEBUG 01-06 08:44:48.129679.129679 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:48.129601.129601 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:48.130506.130506 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:48.131592.131592 cuda_h.py:19] end allocate_cuda_memory cost 0.0017511844635009766 seconds
DEBUG 01-06 08:44:48.131602.131602 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:48.131165.131165 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:48.131306.131306 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:48.131194.131194 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 158e0788-5170-4ef8-a36c-d520c8eeda09
DEBUG 01-06 08:44:48.132756.132756 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:48.132388.132388 client.py:127] Model loaded
DEBUG 01-06 08:44:48.132914.132914 cuda_h.py:19] end sllm_worker_task cost 0.009489774703979492 seconds
INFO 01-06 08:44:48.133262.133262 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 158e0788-5170-4ef8-a36c-d520c8eeda09
DEBUG 01-06 08:44:48.133820.133820 cuda_h.py:19] end load_into_gpu_async cost 0.0013575553894042969 seconds
DEBUG 01-06 08:44:48.133523.133523 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:48.133546.133546 cuda_h.py:19] end restore_tensors2 cost 0.0002727508544921875 seconds
DEBUG 01-06 08:44:48.133270.133270 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037348270416259766 seconds
DEBUG 01-06 08:44:48.136179.136179 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006414651870727539 seconds
DEBUG 01-06 08:44:48.136724.136724 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:48.136052.136052 lmp.py:427] 
DEBUG 01-06 08:44:48.136052.136052 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:48.136087.136087 cuda_h.py:19] end cpu_experts_submit cost 0.000133514404296875 seconds
DEBUG 01-06 08:44:48.136690.136690 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:48.148339.148339 mlpmodule.py:704] group tensors cost 0.011914968490600586 s
DEBUG 01-06 08:44:48.150667.150667 mlpmodule.py:742] pad cost 0.0014760494232177734 s
DEBUG 01-06 08:44:48.150671.150671 mlpmodule.py:748] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-06 08:44:48.150659.150659 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-06 08:44:48.161148.161148 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:48.162307.162307 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:48.162535.162535 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-06 08:44:48.162103.162103 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:48.182322.182322 mlpmodule.py:793] group einsum cost 0.031380414962768555 s
DEBUG 01-06 08:44:48.183542.183542 mlpmodule.py:801] cpy2cputensor cost 0.0006120204925537109 s
DEBUG 01-06 08:44:48.187624.187624 cuda_h.py:19] end wait_cetm_experts cost 0.05138063430786133 seconds
DEBUG 01-06 08:44:48.188786.188786 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:48.189344.189344 cuda_h.py:19] end gpu_sexperts cost 0.0015964508056640625 seconds
DEBUG 01-06 08:44:48.189379.189379 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:48.189898.189898 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6941299438476562e-05 seconds
DEBUG 01-06 08:44:48.189508.189508 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:48.189741.189741 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 158e0788-5170-4ef8-a36c-d520c8eeda09
INFO 01-06 08:44:48.192839.192839 client.py:127] Model loaded
DEBUG 01-06 08:44:48.192821.192821 cuda_h.py:19] end wait_experts cost 0.0029740333557128906 seconds
DEBUG 01-06 08:44:48.192716.192716 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:48.192757.192757 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:48.195454.195454 mlpmodule.py:662]  experts func einsum cost 0.05907082557678223 s
DEBUG 01-06 08:44:48.204747.204747 cuda_h.py:19] end gpu_experts cost 0.011187314987182617 seconds
DEBUG 01-06 08:44:48.204698.204698 cuda_h.py:19] end layer_moe_generate_26 cost 0.0766758918762207 seconds
DEBUG 01-06 08:44:48.204961.204961 lmp.py:221] -------------------------------- end layer 26 --------------------------------
DEBUG 01-06 08:44:48.204023.204023 lmp.py:177] -------------------------------- start layer 27 --------------------------------
DEBUG 01-06 08:44:48.204176.204176 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-06 08:44:48.204483.204483 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.1682510375976562e-05 seconds
DEBUG 01-06 08:44:48.204086.204086 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:48.204970.204970 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:48.207992.207992 cuda_h.py:19] end self_attn cost 0.002380847930908203 seconds
DEBUG 01-06 08:44:48.207498.207498 cuda_h.py:19] end iln_self_attn_paln cost 0.0029764175415039062 seconds
DEBUG 01-06 08:44:48.207050.207050 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-06 08:44:48.207143.207143 cuda_h.py:10] start gate
DEBUG 01-06 08:44:48.208832.208832 cuda_h.py:19] end gate cost 0.0005457401275634766 seconds
DEBUG 01-06 08:44:48.208177.208177 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:48.208698.208698 lmp.py:369] 
DEBUG 01-06 08:44:48.208698.208698 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:48.208931.208931 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:48.208011.208011 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:48.208277.208277 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:48.208158.208158 lmp.py:373] 
DEBUG 01-06 08:44:48.208158.208158 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:48.208231.208231 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:48.208073.208073 lmp.py:380]   Expert 47 |     16 | CPU
DEBUG 01-06 08:44:48.208193.208193 lmp.py:380]   Expert 18 |     19 | CPU
DEBUG 01-06 08:44:48.208598.208598 lmp.py:380]   Expert 58 |     40 | CPU
DEBUG 01-06 08:44:48.208764.208764 lmp.py:380]   Expert 24 |     41 | CPU
DEBUG 01-06 08:44:48.208692.208692 lmp.py:380]   Expert 59 |     62 | CPU
DEBUG 01-06 08:44:48.208666.208666 lmp.py:380]   Expert 50 |     67 | CPU
DEBUG 01-06 08:44:48.208116.208116 lmp.py:380]   Expert 51 |     67 | CPU
DEBUG 01-06 08:44:48.208521.208521 lmp.py:380]   Expert 15 |     71 | CPU
DEBUG 01-06 08:44:48.208687.208687 lmp.py:380]   Expert 32 |     71 | CPU
DEBUG 01-06 08:44:48.208376.208376 lmp.py:380]   Expert 19 |     76 | CPU
DEBUG 01-06 08:44:48.208304.208304 lmp.py:380]   Expert 11 |     78 | CPU
DEBUG 01-06 08:44:48.208517.208517 lmp.py:380]   Expert 40 |     78 | CPU
DEBUG 01-06 08:44:48.208491.208491 lmp.py:380]   Expert 38 |     84 | CPU
DEBUG 01-06 08:44:48.208942.208942 lmp.py:380]   Expert 52 |     91 | CPU
DEBUG 01-06 08:44:48.208916.208916 lmp.py:380]   Expert 39 |    100 | CPU
DEBUG 01-06 08:44:48.208367.208367 lmp.py:380]   Expert  7 |    101 | CPU
DEBUG 01-06 08:44:48.208341.208341 lmp.py:380]   Expert 34 |    104 | CPU
DEBUG 01-06 08:44:48.208315.208315 lmp.py:380]   Expert 48 |    104 | CPU
DEBUG 01-06 08:44:48.208527.208527 lmp.py:380]   Expert 29 |    107 | CPU
DEBUG 01-06 08:44:48.209978.209978 lmp.py:380]   Expert 42 |    107 | CPU
DEBUG 01-06 08:44:48.209429.209429 lmp.py:380]   Expert 44 |    113 | CPU
DEBUG 01-06 08:44:48.209357.209357 lmp.py:380]   Expert 54 |    118 | CPU
DEBUG 01-06 08:44:48.209046.209046 lmp.py:380]   Expert 12 |    119 | CPU
DEBUG 01-06 08:44:48.209450.209450 lmp.py:380]   Expert  6 |    123 | CPU
DEBUG 01-06 08:44:48.209901.209901 lmp.py:380]   Expert 31 |    123 | CPU
DEBUG 01-06 08:44:48.209875.209875 lmp.py:380]   Expert 61 |    124 | CPU
DEBUG 01-06 08:44:48.209088.209088 lmp.py:380]   Expert 46 |    125 | CPU
DEBUG 01-06 08:44:48.209300.209300 lmp.py:380]   Expert  8 |    126 | CPU
DEBUG 01-06 08:44:48.209513.209513 lmp.py:380]   Expert 53 |    136 | CPU
DEBUG 01-06 08:44:48.209487.209487 lmp.py:380]   Expert 25 |    138 | CPU
DEBUG 01-06 08:44:48.209461.209461 lmp.py:380]   Expert 22 |    150 | CPU
DEBUG 01-06 08:44:48.209196.209196 lmp.py:380]   Expert 23 |    153 | CPU
DEBUG 01-06 08:44:48.209647.209647 lmp.py:380]   Expert  4 |    167 | GPU
DEBUG 01-06 08:44:48.209813.209813 lmp.py:380]   Expert 36 |    175 | GPU
DEBUG 01-06 08:44:48.209503.209503 lmp.py:380]   Expert 10 |    176 | GPU
DEBUG 01-06 08:44:48.209954.209954 lmp.py:380]   Expert  1 |    178 | GPU
DEBUG 01-06 08:44:48.209643.209643 lmp.py:380]   Expert 49 |    182 | GPU
DEBUG 01-06 08:44:48.209332.209332 lmp.py:380]   Expert 16 |    183 | GPU
DEBUG 01-06 08:44:48.209545.209545 lmp.py:380]   Expert 56 |    183 | GPU
DEBUG 01-06 08:44:48.209519.209519 lmp.py:380]   Expert 13 |    184 | GPU
DEBUG 01-06 08:44:48.209493.209493 lmp.py:380]   Expert 45 |    190 | GPU
DEBUG 01-06 08:44:48.209228.209228 lmp.py:380]   Expert 17 |    196 | GPU
DEBUG 01-06 08:44:48.209679.209679 lmp.py:380]   Expert  3 |    217 | GPU
DEBUG 01-06 08:44:48.209653.209653 lmp.py:380]   Expert 26 |    218 | GPU
DEBUG 01-06 08:44:48.209389.209389 lmp.py:380]   Expert 33 |    220 | GPU
DEBUG 01-06 08:44:48.209601.209601 lmp.py:380]   Expert 41 |    222 | GPU
DEBUG 01-06 08:44:48.209337.209337 lmp.py:380]   Expert 57 |    224 | GPU
DEBUG 01-06 08:44:48.209026.209026 lmp.py:380]   Expert 62 |    235 | GPU
DEBUG 01-06 08:44:48.209716.209716 lmp.py:380]   Expert 55 |    240 | GPU
DEBUG 01-06 08:44:48.209643.209643 lmp.py:380]   Expert 30 |    250 | GPU
DEBUG 01-06 08:44:48.209810.209810 lmp.py:380]   Expert  5 |    254 | GPU
DEBUG 01-06 08:44:48.209022.209022 lmp.py:380]   Expert 37 |    271 | GPU
DEBUG 01-06 08:44:48.209996.209996 lmp.py:380]   Expert 35 |    273 | GPU
DEBUG 01-06 08:44:48.209447.209447 lmp.py:380]   Expert  0 |    319 | GPU
DEBUG 01-06 08:44:48.209435.209435 lmp.py:380]   Expert 21 |    329 | GPU
DEBUG 01-06 08:44:48.209422.209422 lmp.py:380]   Expert 43 |    353 | GPU
DEBUG 01-06 08:44:48.209204.209204 lmp.py:380]   Expert  2 |    365 | GPU
DEBUG 01-06 08:44:48.209986.209986 lmp.py:380]   Expert 60 |    371 | GPU
DEBUG 01-06 08:44:48.209006.209006 lmp.py:380]   Expert 28 |    404 | GPU
DEBUG 01-06 08:44:48.209265.209265 lmp.py:380]   Expert 63 |    430 | GPU
DEBUG 01-06 08:44:48.209047.209047 lmp.py:380]   Expert 14 |    492 | GPU
DEBUG 01-06 08:44:48.209068.209068 lmp.py:380]   Expert 27 |    509 | GPU
DEBUG 01-06 08:44:48.209088.209088 lmp.py:380]   Expert 20 |    560 | GPU
DEBUG 01-06 08:44:48.209539.209539 lmp.py:380]   Expert  9 |    686 | GPU
DEBUG 01-06 08:44:48.209751.209751 lmp.py:381] 
DEBUG 01-06 08:44:48.209751.209751 lmp.py:381]   CPU total tokens: 3032 (24.7%)
DEBUG 01-06 08:44:48.209156.209156 lmp.py:382]   GPU total tokens: 9256 (75.3%)
DEBUG 01-06 08:44:48.209613.209613 cuda_h.py:19] end experts_map_get cost 0.0015232563018798828 seconds
DEBUG 01-06 08:44:48.209588.209588 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:48.209079.209079 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:48.209839.209839 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:48.210609.210609 cuda_h.py:19] end allocate_cuda_memory cost 0.00022077560424804688 seconds
DEBUG 01-06 08:44:48.210498.210498 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:48.210916.210916 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:48.210394.210394 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:48.210759.210759 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ced800d9-9839-4926-8a23-05915ea965a0
DEBUG 01-06 08:44:48.210143.210143 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:48.211710.211710 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ced800d9-9839-4926-8a23-05915ea965a0
DEBUG 01-06 08:44:48.211162.211162 cuda_h.py:19] end load_into_gpu_async cost 0.0014085769653320312 seconds
DEBUG 01-06 08:44:48.211435.211435 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:48.212962.212962 cuda_h.py:19] end restore_tensors2 cost 0.0002925395965576172 seconds
DEBUG 01-06 08:44:48.212016.212016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022499561309814453 seconds
DEBUG 01-06 08:44:48.214309.214309 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00489497184753418 seconds
DEBUG 01-06 08:44:48.214992.214992 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:48.214545.214545 lmp.py:427] 
DEBUG 01-06 08:44:48.214545.214545 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:48.214958.214958 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-06 08:44:48.214084.214084 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:48.226744.226744 mlpmodule.py:704] group tensors cost 0.011865854263305664 s
DEBUG 01-06 08:44:48.229313.229313 mlpmodule.py:742] pad cost 0.0015926361083984375 s
DEBUG 01-06 08:44:48.229350.229350 mlpmodule.py:748] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-06 08:44:48.229530.229530 mlpmodule.py:753] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-06 08:44:48.241028.241028 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:48.241796.241796 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:48.241124.241124 mlpmodule.py:773] group_w3 first element: -0.000606536865234375
WARNING 01-06 08:44:48.241678.241678 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:48.260576.260576 mlpmodule.py:793] group einsum cost 0.03134727478027344 s
DEBUG 01-06 08:44:48.261777.261777 mlpmodule.py:801] cpy2cputensor cost 0.0006496906280517578 s
DEBUG 01-06 08:44:48.266599.266599 cuda_h.py:19] end wait_cetm_experts cost 0.0515294075012207 seconds
DEBUG 01-06 08:44:48.266953.266953 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:48.268713.268713 cuda_h.py:19] end gpu_sexperts cost 0.0016739368438720703 seconds
DEBUG 01-06 08:44:48.268675.268675 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:48.268048.268048 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1682510375976562e-05 seconds
DEBUG 01-06 08:44:48.268182.268182 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:48.268415.268415 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ced800d9-9839-4926-8a23-05915ea965a0
INFO 01-06 08:44:48.271194.271194 client.py:127] Model loaded
DEBUG 01-06 08:44:48.271037.271037 cuda_h.py:19] end wait_experts cost 0.002950906753540039 seconds
DEBUG 01-06 08:44:48.271408.271408 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:48.271641.271641 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:48.274907.274907 mlpmodule.py:662]  experts func einsum cost 0.059267520904541016 s
DEBUG 01-06 08:44:48.282757.282757 cuda_h.py:19] end gpu_experts cost 0.011175394058227539 seconds
DEBUG 01-06 08:44:48.282370.282370 cuda_h.py:19] end layer_moe_generate_27 cost 0.07520413398742676 seconds
DEBUG 01-06 08:44:48.283946.283946 lmp.py:221] -------------------------------- end layer 27 --------------------------------
DEBUG 01-06 08:44:48.283742.283742 cuda_h.py:19] end multi_layer cost 2.7938146591186523 seconds
DEBUG 01-06 08:44:48.283299.283299 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 08:44:48.385385.385385 cuda_h.py:19] end init_inputs_tokens cost 0.10217881202697754 seconds
DEBUG 01-06 08:44:48.385966.385966 lmp.py:290] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-06 08:44:48.385245.385245 cuda_h.py:10] start dense_mlp
DEBUG 01-06 08:44:48.387189.387189 lmp.py:293] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-06 08:44:48.387338.387338 cuda_h.py:19] end dense_mlp cost 0.0019335746765136719 seconds
DEBUG 01-06 08:44:48.387663.387663 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-06 08:44:48.387088.387088 cuda_h.py:10] start gate
DEBUG 01-06 08:44:48.413190.413190 cuda_h.py:19] end gate cost 0.026161670684814453 seconds
DEBUG 01-06 08:44:48.413232.413232 cuda_h.py:10] start experts_map_get
INFO 01-06 08:44:48.414642.414642 lmp.py:582] 
INFO 01-06 08:44:48.414642.414642 lmp.py:582] Layer 1 Expert Device Distribution:
INFO 01-06 08:44:48.414226.414226 lmp.py:583]   Active experts: 51 (out of 64 total)
INFO 01-06 08:44:48.414922.414922 lmp.py:584] 
INFO 01-06 08:44:48.414922.414922 lmp.py:584]   Detailed Expert Distribution:
INFO 01-06 08:44:48.414049.414049 lmp.py:585]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 08:44:48.414122.414122 lmp.py:586]   ----------------------------------------------------------------------
INFO 01-06 08:44:48.414149.414149 lmp.py:589]   0          | 1          |  cuda:1         
INFO 01-06 08:44:48.414269.414269 lmp.py:589]   9          | 1          |  cuda:1         
INFO 01-06 08:44:48.414197.414197 lmp.py:589]   17         | 1          |  cuda:1         
INFO 01-06 08:44:48.414363.414363 lmp.py:589]   19         | 1          |  cuda:1         
INFO 01-06 08:44:48.414814.414814 lmp.py:589]   21         | 1          |  meta           
INFO 01-06 08:44:48.414788.414788 lmp.py:589]   27         | 1          |  meta           
INFO 01-06 08:44:48.414762.414762 lmp.py:589]   28         | 1          |  meta           
INFO 01-06 08:44:48.414736.414736 lmp.py:589]   29         | 1          |  meta           
INFO 01-06 08:44:48.414710.414710 lmp.py:589]   35         | 1          |  cuda:1         
INFO 01-06 08:44:48.414923.414923 lmp.py:589]   39         | 1          |  meta           
INFO 01-06 08:44:48.414897.414897 lmp.py:589]   53         | 1          |  meta           
INFO 01-06 08:44:48.414871.414871 lmp.py:589]   1          | 2          |  cuda:1         
INFO 01-06 08:44:48.414606.414606 lmp.py:589]   26         | 2          |  cuda:1         
INFO 01-06 08:44:48.414342.414342 lmp.py:589]   36         | 2          |  meta           
INFO 01-06 08:44:48.414316.414316 lmp.py:589]   37         | 2          |  meta           
INFO 01-06 08:44:48.414052.414052 lmp.py:589]   41         | 2          |  meta           
INFO 01-06 08:44:48.414741.414741 lmp.py:589]   43         | 2          |  cuda:1         
INFO 01-06 08:44:48.414953.414953 lmp.py:589]   45         | 2          |  cuda:1         
INFO 01-06 08:44:48.414689.414689 lmp.py:589]   50         | 2          |  meta           
INFO 01-06 08:44:48.414901.414901 lmp.py:589]   52         | 2          |  cuda:1         
INFO 01-06 08:44:48.415399.415399 lmp.py:589]   56         | 2          |  meta           
INFO 01-06 08:44:48.415373.415373 lmp.py:589]   60         | 2          |  cuda:1         
INFO 01-06 08:44:48.415870.415870 lmp.py:589]   8          | 3          |  cuda:1         
INFO 01-06 08:44:48.415082.415082 lmp.py:589]   10         | 3          |  cuda:1         
INFO 01-06 08:44:48.415580.415580 lmp.py:589]   11         | 3          |  meta           
INFO 01-06 08:44:48.415554.415554 lmp.py:589]   12         | 3          |  meta           
INFO 01-06 08:44:48.415528.415528 lmp.py:589]   16         | 3          |  cuda:1         
INFO 01-06 08:44:48.415263.415263 lmp.py:589]   22         | 3          |  meta           
INFO 01-06 08:44:48.415476.415476 lmp.py:589]   33         | 3          |  cuda:1         
INFO 01-06 08:44:48.415211.415211 lmp.py:589]   40         | 3          |  cuda:1         
INFO 01-06 08:44:48.415185.415185 lmp.py:589]   15         | 4          |  cuda:1         
INFO 01-06 08:44:48.415159.415159 lmp.py:589]   23         | 4          |  cuda:1         
INFO 01-06 08:44:48.415134.415134 lmp.py:589]   30         | 4          |  meta           
INFO 01-06 08:44:48.415869.415869 lmp.py:589]   42         | 4          |  cuda:1         
INFO 01-06 08:44:48.415605.415605 lmp.py:589]   44         | 4          |  cuda:1         
INFO 01-06 08:44:48.415817.415817 lmp.py:589]   5          | 5          |  cuda:1         
INFO 01-06 08:44:48.415983.415983 lmp.py:589]   31         | 5          |  meta           
INFO 01-06 08:44:48.415295.415295 lmp.py:589]   46         | 5          |  cuda:1         
INFO 01-06 08:44:48.415508.415508 lmp.py:589]   61         | 5          |  cuda:1         
INFO 01-06 08:44:48.415243.415243 lmp.py:589]   47         | 6          |  meta           
INFO 01-06 08:44:48.415979.415979 lmp.py:589]   59         | 6          |  meta           
INFO 01-06 08:44:48.415715.415715 lmp.py:589]   63         | 6          |  cuda:1         
INFO 01-06 08:44:48.415212.415212 lmp.py:589]   2          | 7          |  cuda:1         
INFO 01-06 08:44:48.415186.415186 lmp.py:589]   7          | 7          |  cuda:1         
INFO 01-06 08:44:48.415921.415921 lmp.py:589]   4          | 8          |  cuda:1         
INFO 01-06 08:44:48.415134.415134 lmp.py:589]   6          | 8          |  cuda:1         
INFO 01-06 08:44:48.415346.415346 lmp.py:589]   20         | 8          |  cuda:1         
INFO 01-06 08:44:48.415320.415320 lmp.py:589]   24         | 8          |  meta           
INFO 01-06 08:44:48.415632.415632 lmp.py:589]   57         | 9          |  cuda:1         
INFO 01-06 08:44:48.415275.415275 lmp.py:589]   14         | 10         |  cuda:1         
INFO 01-06 08:44:48.415488.415488 lmp.py:589]   34         | 12         |  cuda:1         
INFO 01-06 08:44:48.415747.415747 lmp.py:590] ============================================================
INFO 01-06 08:44:48.415747.415747 lmp.py:590] 
INFO 01-06 08:44:48.415158.415158 lmp.py:592] experts_gpu_list: [0, 9, 17, 19, 35, 1, 26, 43, 45, 52, 60, 8, 10, 16, 33, 40, 15, 23, 42, 44, 5, 46, 61, 63, 2, 7, 4, 6, 20, 57, 14, 34]
INFO 01-06 08:44:48.415039.415039 lmp.py:593] experts_cpu_list: [21, 27, 28, 29, 39, 53, 36, 37, 41, 50, 56, 11, 12, 22, 30, 31, 47, 59, 24]
INFO 01-06 08:44:48.415027.415027 lmp.py:594] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 08:44:48.415968.415968 cuda_h.py:19] end experts_map_get cost 0.0017600059509277344 seconds
DEBUG 01-06 08:44:48.415063.415063 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:48.416322.416322 cuda_h.py:19] end gpu_sexperts cost 0.00036072731018066406 seconds
DEBUG 01-06 08:44:48.416496.416496 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:48.417035.417035 mlpmodule.py:531] gpu group tensors cost 0.001199960708618164 s
DEBUG 01-06 08:44:48.418693.418693 mlpmodule.py:564] gpu pad cost 0.0013728141784667969 s
DEBUG 01-06 08:44:48.419916.419916 mlpmodule.py:582] gpu group einsum cost 0.0004901885986328125 s
DEBUG 01-06 08:44:48.422556.422556 mlpmodule.py:611] gpu experts func einsum cost 0.0058705806732177734 s
DEBUG 01-06 08:44:48.422088.422088 cuda_h.py:19] end gpu_experts cost 0.0059909820556640625 seconds
DEBUG 01-06 08:44:48.422222.422222 cuda_h.py:10] start cpu_experts
DEBUG 01-06 08:44:48.428370.428370 cuda_h.py:19] end cpu_experts cost 0.0061740875244140625 seconds
DEBUG 01-06 08:44:48.428022.428022 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.040966033935546875 seconds
DEBUG 01-06 08:44:49.601589.601589 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09741735458374023 s
DEBUG 01-06 08:44:49.937235.937235 cuda_h.py:19] end generate_input_ids cost 0.33561229705810547 seconds
DEBUG 01-06 08:44:49.938449.938449 cuda_h.py:10] start init_cache
DEBUG 01-06 08:44:49.938520.938520 cuda_h.py:19] end init_cache cost 6.318092346191406e-05 seconds
DEBUG 01-06 08:44:52.440785.440785 cuda_h.py:10] start init_weights
DEBUG 01-06 08:44:52.440689.440689 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:52.441248.441248 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:52.443950.443950 cuda_h.py:19] end allocate_cuda_memory cost 0.0015883445739746094 seconds
DEBUG 01-06 08:44:52.443469.443469 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:52.443894.443894 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:52.443929.443929 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:52.443917.443917 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cd215a8b-7b1b-493f-892f-546839cac254
DEBUG 01-06 08:44:52.443860.443860 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:52.445244.445244 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cd215a8b-7b1b-493f-892f-546839cac254
DEBUG 01-06 08:44:52.445318.445318 cuda_h.py:19] end load_into_gpu_async cost 0.0019991397857666016 seconds
DEBUG 01-06 08:44:52.445399.445399 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:52.445567.445567 cuda_h.py:19] end restore_tensors2 cost 6.246566772460938e-05 seconds
DEBUG 01-06 08:44:52.445416.445416 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004255533218383789 seconds
INFO 01-06 08:44:52.445349.445349 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cd215a8b-7b1b-493f-892f-546839cac254
INFO 01-06 08:44:52.524505.524505 client.py:127] Model loaded
DEBUG 01-06 08:44:52.525649.525649 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-06 08:44:52.525242.525242 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:52.525644.525644 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:52.525929.525929 cuda_h.py:19] end allocate_cuda_memory cost 0.00033283233642578125 seconds
DEBUG 01-06 08:44:52.525126.525126 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:52.526526.526526 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:52.526702.526702 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:52.526082.526082 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7284e29-a717-41df-aa01-38a0e7c99a37
DEBUG 01-06 08:44:52.526074.526074 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:52.527756.527756 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7284e29-a717-41df-aa01-38a0e7c99a37
DEBUG 01-06 08:44:52.528351.528351 cuda_h.py:19] end load_into_gpu_async cost 0.002074003219604492 seconds
DEBUG 01-06 08:44:52.528228.528228 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:52.528364.528364 cuda_h.py:19] end restore_tensors2 cost 0.00022792816162109375 seconds
DEBUG 01-06 08:44:52.528354.528354 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003267526626586914 seconds
INFO 01-06 08:44:52.528933.528933 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7284e29-a717-41df-aa01-38a0e7c99a37
INFO 01-06 08:44:52.543866.543866 client.py:127] Model loaded
DEBUG 01-06 08:44:52.544623.544623 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.01929473876953125 seconds
DEBUG 01-06 08:44:52.544084.544084 cuda_h.py:19] end init_weights cost 0.10379958152770996 seconds
DEBUG 01-06 08:44:52.544477.544477 cuda_h.py:10] start copy_emodel
DEBUG 01-06 08:44:53.314434.314434 cuda_h.py:19] end copy_emodel cost 0.7691738605499268 seconds
DEBUG 01-06 08:44:53.314834.314834 cuda_h.py:10] start init_hmv
DEBUG 01-06 08:44:53.453056.453056 mlpmodule.py:206] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-06 08:44:53.454663.454663 cuda_h.py:19] end init_hmv cost 0.13943052291870117 seconds
DEBUG 01-06 08:44:53.454976.454976 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 08:44:53.454610.454610 cuda_h.py:19] end init_inputs_tokens cost 0.0002956390380859375 seconds
DEBUG 01-06 08:44:53.454664.454664 cuda_h.py:10] start multi_layer
DEBUG 01-06 08:44:53.454427.454427 lmp.py:177] -------------------------------- start layer 0 --------------------------------
DEBUG 01-06 08:44:53.454169.454169 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:44:53.454726.454726 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:44:53.454185.454185 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.147125244140625e-05 seconds
DEBUG 01-06 08:44:53.454265.454265 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.127357482910156e-05 seconds
DEBUG 01-06 08:44:53.454101.454101 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.455363.455363 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.455174.455174 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.455371.455371 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.455332.455332 cuda_h.py:19] end allocate_cuda_memory cost 0.000331878662109375 seconds
DEBUG 01-06 08:44:53.456285.456285 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.456686.456686 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.456479.456479 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.456920.456920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 361716e4-df6c-4e7a-95f1-ca0707688374
DEBUG 01-06 08:44:53.456596.456596 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.456870.456870 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.458957.458957 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 361716e4-df6c-4e7a-95f1-ca0707688374
DEBUG 01-06 08:44:53.458783.458783 cuda_h.py:19] end load_into_gpu_async cost 0.0024917125701904297 seconds
DEBUG 01-06 08:44:53.458336.458336 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.459291.459291 cuda_h.py:19] end restore_tensors2 cost 0.00015211105346679688 seconds
DEBUG 01-06 08:44:53.459964.459964 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037164688110351562 seconds
INFO 01-06 08:44:53.460793.460793 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 361716e4-df6c-4e7a-95f1-ca0707688374
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.462217.462217 cuda_h.py:19] end self_attn cost 0.005304813385009766 seconds
DEBUG 01-06 08:44:53.462688.462688 cuda_h.py:19] end iln_self_attn_paln cost 0.007810115814208984 seconds
DEBUG 01-06 08:44:53.462848.462848 cuda_h.py:10] start dense_mlp
DEBUG 01-06 08:44:53.462942.462942 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:44:53.462838.462838 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 2.0265579223632812e-05 seconds
DEBUG 01-06 08:44:53.465722.465722 cuda_h.py:19] end dense_mlp cost 0.002714872360229492 seconds
DEBUG 01-06 08:44:53.465487.465487 lmp.py:221] -------------------------------- end layer 0 --------------------------------
DEBUG 01-06 08:44:53.465435.465435 lmp.py:177] -------------------------------- start layer 1 --------------------------------
DEBUG 01-06 08:44:53.465893.465893 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 08:44:53.465940.465940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 08:44:53.465763.465763 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.8596649169921875e-05 seconds
DEBUG 01-06 08:44:53.465751.465751 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.744529724121094e-05 seconds
DEBUG 01-06 08:44:53.465301.465301 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.466229.466229 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.466466.466466 client.py:127] Model loaded
DEBUG 01-06 08:44:53.466180.466180 cuda_h.py:19] end sllm_worker_task cost 0.011283636093139648 seconds
DEBUG 01-06 08:44:53.466867.466867 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.466512.466512 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.466040.466040 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.467026.467026 cuda_h.py:19] end allocate_cuda_memory cost 0.00026988983154296875 seconds
DEBUG 01-06 08:44:53.467111.467111 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.467497.467497 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.467197.467197 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.468034.468034 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 08215129-4659-48e7-92b7-b412e79888aa
DEBUG 01-06 08:44:53.468729.468729 client.py:106] call stub.LoadModelAsync
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-06 08:44:53.469180.469180 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 08215129-4659-48e7-92b7-b412e79888aa
DEBUG 01-06 08:44:53.469444.469444 cuda_h.py:19] end load_into_gpu_async cost 0.002171754837036133 seconds
DEBUG 01-06 08:44:53.470268.470268 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.470565.470565 cuda_h.py:19] end restore_tensors2 cost 0.00011301040649414062 seconds
DEBUG 01-06 08:44:53.470979.470979 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033605098724365234 seconds
INFO 01-06 08:44:53.471408.471408 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 08215129-4659-48e7-92b7-b412e79888aa
DEBUG 01-06 08:44:53.471803.471803 cuda_h.py:19] end self_attn cost 0.005208730697631836 seconds
DEBUG 01-06 08:44:53.471896.471896 cuda_h.py:19] end iln_self_attn_paln cost 0.0058863162994384766 seconds
DEBUG 01-06 08:44:53.471985.471985 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-06 08:44:53.471754.471754 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.472589.472589 cuda_h.py:19] end gate cost 0.0007503032684326172 seconds
DEBUG 01-06 08:44:53.472941.472941 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.472614.472614 lmp.py:369] 
DEBUG 01-06 08:44:53.472614.472614 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.472224.472224 lmp.py:370]   Total experts: 6
DEBUG 01-06 08:44:53.472682.472682 lmp.py:371]   CPU experts: 3 (50%)
DEBUG 01-06 08:44:53.472278.472278 lmp.py:372]   GPU experts: 3 (50%)
DEBUG 01-06 08:44:53.472683.472683 lmp.py:373] 
DEBUG 01-06 08:44:53.472683.472683 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.472611.472611 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.472353.472353 lmp.py:380]   Expert  0 |   2048 | CPU
DEBUG 01-06 08:44:53.472996.472996 lmp.py:380]   Expert  1 |   2048 | CPU
DEBUG 01-06 08:44:53.473685.473685 lmp.py:380]   Expert  2 |   2048 | CPU
DEBUG 01-06 08:44:53.473136.473136 lmp.py:380]   Expert  3 |   2048 | GPU
DEBUG 01-06 08:44:53.473256.473256 lmp.py:380]   Expert  4 |   2048 | GPU
DEBUG 01-06 08:44:53.473945.473945 lmp.py:380]   Expert  5 |   2048 | GPU
DEBUG 01-06 08:44:53.473111.473111 lmp.py:381] 
DEBUG 01-06 08:44:53.473111.473111 lmp.py:381]   CPU total tokens: 6144 (50.0%)
DEBUG 01-06 08:44:53.473278.473278 lmp.py:382]   GPU total tokens: 6144 (50.0%)
DEBUG 01-06 08:44:53.473258.473258 cuda_h.py:19] end experts_map_get cost 0.0003170967102050781 seconds
DEBUG 01-06 08:44:53.473186.473186 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.473458.473458 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.473029.473029 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.473778.473778 cuda_h.py:19] end allocate_cuda_memory cost 0.0007674694061279297 seconds
DEBUG 01-06 08:44:53.474475.474475 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.474993.474993 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.474325.474325 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.474028.474028 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 78d08fbf-fddb-48f9-bede-644eeac29649
DEBUG 01-06 08:44:53.474447.474447 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.477963.477963 client.py:127] Model loaded
DEBUG 01-06 08:44:53.477941.477941 cuda_h.py:19] end sllm_worker_task cost 0.011023521423339844 seconds
DEBUG 01-06 08:44:53.477010.477010 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.478489.478489 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.478711.478711 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.478717.478717 cuda_h.py:19] end allocate_cuda_memory cost 0.00031495094299316406 seconds
INFO 01-06 08:44:53.478734.478734 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 78d08fbf-fddb-48f9-bede-644eeac29649
DEBUG 01-06 08:44:53.478587.478587 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.478292.478292 cuda_h.py:19] end load_into_gpu_async cost 0.004778385162353516 seconds
DEBUG 01-06 08:44:53.478274.478274 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.478184.478184 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.479625.479625 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.479576.479576 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45bee85e-f4eb-4168-8181-2ba9905c0194
DEBUG 01-06 08:44:53.479457.479457 cuda_h.py:19] end restore_tensors2 cost 5.555152893066406e-05 seconds
DEBUG 01-06 08:44:53.479817.479817 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.479999.479999 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017201900482177734 seconds
DEBUG 01-06 08:44:53.480548.480548 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007222414016723633 seconds
DEBUG 01-06 08:44:53.480278.480278 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.480150.480150 lmp.py:427] 
DEBUG 01-06 08:44:53.480150.480150 lmp.py:427]   Computing 3 experts on CPU...
DEBUG 01-06 08:44:53.480986.480986 cuda_h.py:19] end cpu_experts_submit cost 0.00011157989501953125 seconds
DEBUG 01-06 08:44:53.480874.480874 cuda_h.py:10] start wait_cetm_experts
INFO 01-06 08:44:53.490406.490406 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45bee85e-f4eb-4168-8181-2ba9905c0194
DEBUG 01-06 08:44:53.490609.490609 mlpmodule.py:704] group tensors cost 0.009867668151855469 s
DEBUG 01-06 08:44:53.491874.491874 cuda_h.py:19] end load_into_gpu_async cost 0.01258230209350586 seconds
DEBUG 01-06 08:44:53.491039.491039 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.491145.491145 cuda_h.py:19] end restore_tensors2 cost 0.00013065338134765625 seconds
DEBUG 01-06 08:44:53.492666.492666 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0139312744140625 seconds
INFO 01-06 08:44:53.493016.493016 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45bee85e-f4eb-4168-8181-2ba9905c0194
DEBUG 01-06 08:44:53.493691.493691 mlpmodule.py:742] pad cost 0.0019736289978027344 s
DEBUG 01-06 08:44:53.493027.493027 mlpmodule.py:748] create cpu tensor cost 5.9604644775390625e-05 s
DEBUG 01-06 08:44:53.493123.493123 mlpmodule.py:753] move to cpu cost 4.982948303222656e-05 s
INFO 01-06 08:44:53.494792.494792 client.py:127] Model loaded
DEBUG 01-06 08:44:53.494784.494784 cuda_h.py:19] end sllm_worker_task cost 0.01650238037109375 seconds
DEBUG 01-06 08:44:53.504866.504866 mlpmodule.py:767] group_w3: shape=torch.Size([3, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=8650752
DEBUG 01-06 08:44:53.504139.504139 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.504136.504136 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-06 08:44:53.504117.504117 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.521355.521355 mlpmodule.py:793] group einsum cost 0.02778172492980957 s
DEBUG 01-06 08:44:53.522108.522108 mlpmodule.py:801] cpy2cputensor cost 0.0007326602935791016 s
DEBUG 01-06 08:44:53.523851.523851 cuda_h.py:19] end wait_cetm_experts cost 0.04298734664916992 seconds
DEBUG 01-06 08:44:53.523603.523603 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.524754.524754 cuda_h.py:19] end gpu_sexperts cost 0.0005218982696533203 seconds
DEBUG 01-06 08:44:53.524426.524426 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.524574.524574 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:44:53.524376.524376 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.524709.524709 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 78d08fbf-fddb-48f9-bede-644eeac29649
DEBUG 01-06 08:44:53.524775.524775 mlpmodule.py:662]  experts func einsum cost 0.043906211853027344 s
INFO 01-06 08:44:53.525487.525487 client.py:127] Model loaded
DEBUG 01-06 08:44:53.525052.525052 cuda_h.py:19] end wait_experts cost 0.0009560585021972656 seconds
DEBUG 01-06 08:44:53.525477.525477 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:53.525994.525994 lmp.py:472]   Computing 3 experts on GPU...
DEBUG 01-06 08:44:53.527375.527375 cuda_h.py:19] end gpu_experts cost 0.0014662742614746094 seconds
DEBUG 01-06 08:44:53.527517.527517 cuda_h.py:19] end layer_moe_generate_1 cost 0.0552370548248291 seconds
DEBUG 01-06 08:44:53.527514.527514 lmp.py:221] -------------------------------- end layer 1 --------------------------------
DEBUG 01-06 08:44:53.527847.527847 lmp.py:177] -------------------------------- start layer 2 --------------------------------
DEBUG 01-06 08:44:53.527834.527834 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 08:44:53.527451.527451 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 08:44:53.527771.527771 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.0279159545898438e-05 seconds
DEBUG 01-06 08:44:53.527415.527415 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.527622.527622 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 0.00013065338134765625 seconds
DEBUG 01-06 08:44:53.527247.527247 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.527699.527699 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.527901.527901 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.528095.528095 cuda_h.py:19] end allocate_cuda_memory cost 0.0003254413604736328 seconds
DEBUG 01-06 08:44:53.528143.528143 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.528429.528429 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.528835.528835 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.528637.528637 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2d5085fd-f365-4062-9fb1-5ce1b9772598
DEBUG 01-06 08:44:53.528238.528238 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.528779.528779 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.529448.529448 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2d5085fd-f365-4062-9fb1-5ce1b9772598
DEBUG 01-06 08:44:53.529346.529346 cuda_h.py:19] end load_into_gpu_async cost 0.0010576248168945312 seconds
DEBUG 01-06 08:44:53.529493.529493 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.529385.529385 cuda_h.py:19] end restore_tensors2 cost 9.560585021972656e-05 seconds
DEBUG 01-06 08:44:53.529850.529850 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018839836120605469 seconds
INFO 01-06 08:44:53.530428.530428 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2d5085fd-f365-4062-9fb1-5ce1b9772598
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.533550.533550 cuda_h.py:19] end self_attn cost 0.0045664310455322266 seconds
DEBUG 01-06 08:44:53.533919.533919 cuda_h.py:19] end iln_self_attn_paln cost 0.0060307979583740234 seconds
DEBUG 01-06 08:44:53.533146.533146 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-06 08:44:53.533869.533869 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.534193.534193 cuda_h.py:19] end gate cost 0.0007262229919433594 seconds
DEBUG 01-06 08:44:53.534652.534652 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.535387.535387 lmp.py:369] 
DEBUG 01-06 08:44:53.535387.535387 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.535673.535673 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:53.535330.535330 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:53.535172.535172 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:53.535391.535391 lmp.py:373] 
DEBUG 01-06 08:44:53.535391.535391 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.535849.535849 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.535982.535982 lmp.py:380]   Expert 36 |     21 | CPU
DEBUG 01-06 08:44:53.535678.535678 lmp.py:380]   Expert 34 |     36 | CPU
DEBUG 01-06 08:44:53.535182.535182 lmp.py:380]   Expert 63 |     38 | CPU
DEBUG 01-06 08:44:53.535355.535355 lmp.py:380]   Expert 58 |     40 | CPU
DEBUG 01-06 08:44:53.535051.535051 lmp.py:380]   Expert  3 |     56 | CPU
DEBUG 01-06 08:44:53.535270.535270 lmp.py:380]   Expert 29 |     57 | CPU
DEBUG 01-06 08:44:53.535774.535774 lmp.py:380]   Expert  8 |     60 | CPU
DEBUG 01-06 08:44:53.535278.535278 lmp.py:380]   Expert 10 |     62 | CPU
DEBUG 01-06 08:44:53.535544.535544 lmp.py:380]   Expert 26 |     67 | CPU
DEBUG 01-06 08:44:53.535240.535240 lmp.py:380]   Expert 27 |     67 | CPU
DEBUG 01-06 08:44:53.535221.535221 lmp.py:380]   Expert  7 |     74 | CPU
DEBUG 01-06 08:44:53.535963.535963 lmp.py:380]   Expert 50 |     79 | CPU
DEBUG 01-06 08:44:53.535706.535706 lmp.py:380]   Expert 13 |     85 | CPU
DEBUG 01-06 08:44:53.535448.535448 lmp.py:380]   Expert 21 |     91 | CPU
DEBUG 01-06 08:44:53.535906.535906 lmp.py:380]   Expert 28 |     91 | CPU
DEBUG 01-06 08:44:53.535887.535887 lmp.py:380]   Expert 17 |     96 | CPU
DEBUG 01-06 08:44:53.535629.535629 lmp.py:380]   Expert 25 |     99 | CPU
DEBUG 01-06 08:44:53.535895.535895 lmp.py:380]   Expert 19 |    106 | CPU
DEBUG 01-06 08:44:53.535160.535160 lmp.py:380]   Expert 12 |    117 | CPU
DEBUG 01-06 08:44:53.535426.535426 lmp.py:380]   Expert 37 |    126 | CPU
DEBUG 01-06 08:44:53.535453.535453 lmp.py:380]   Expert 62 |    132 | CPU
DEBUG 01-06 08:44:53.535718.535718 lmp.py:380]   Expert 45 |    135 | CPU
DEBUG 01-06 08:44:53.535176.535176 lmp.py:380]   Expert 14 |    138 | CPU
DEBUG 01-06 08:44:53.535733.535733 lmp.py:380]   Expert  6 |    145 | CPU
DEBUG 01-06 08:44:53.535383.535383 lmp.py:380]   Expert 48 |    146 | CPU
DEBUG 01-06 08:44:53.535364.535364 lmp.py:380]   Expert 35 |    151 | CPU
DEBUG 01-06 08:44:53.535345.535345 lmp.py:380]   Expert 44 |    151 | CPU
DEBUG 01-06 08:44:53.535802.535802 lmp.py:380]   Expert 41 |    155 | CPU
DEBUG 01-06 08:44:53.535260.535260 lmp.py:380]   Expert 16 |    156 | CPU
DEBUG 01-06 08:44:53.535910.535910 lmp.py:380]   Expert 30 |    157 | CPU
DEBUG 01-06 08:44:53.535367.535367 lmp.py:380]   Expert  5 |    163 | CPU
DEBUG 01-06 08:44:53.535587.535587 lmp.py:380]   Expert 42 |    169 | CPU
DEBUG 01-06 08:44:53.535521.535521 lmp.py:380]   Expert 47 |    170 | GPU
DEBUG 01-06 08:44:53.535740.535740 lmp.py:380]   Expert 40 |    176 | GPU
DEBUG 01-06 08:44:53.535198.535198 lmp.py:380]   Expert  9 |    182 | GPU
DEBUG 01-06 08:44:53.536417.536417 lmp.py:380]   Expert 33 |    183 | GPU
DEBUG 01-06 08:44:53.536306.536306 lmp.py:380]   Expert 31 |    192 | GPU
DEBUG 01-06 08:44:53.536717.536717 lmp.py:380]   Expert 46 |    194 | GPU
DEBUG 01-06 08:44:53.536175.536175 lmp.py:380]   Expert 59 |    195 | GPU
DEBUG 01-06 08:44:53.536871.536871 lmp.py:380]   Expert 49 |    196 | GPU
DEBUG 01-06 08:44:53.536328.536328 lmp.py:380]   Expert 61 |    197 | GPU
DEBUG 01-06 08:44:53.536548.536548 lmp.py:380]   Expert 52 |    199 | GPU
DEBUG 01-06 08:44:53.536005.536005 lmp.py:380]   Expert 39 |    207 | GPU
DEBUG 01-06 08:44:53.536655.536655 lmp.py:380]   Expert  1 |    208 | GPU
DEBUG 01-06 08:44:53.536590.536590 lmp.py:380]   Expert 38 |    208 | GPU
DEBUG 01-06 08:44:53.536809.536809 lmp.py:380]   Expert  0 |    226 | GPU
DEBUG 01-06 08:44:53.536266.536266 lmp.py:380]   Expert 57 |    242 | GPU
DEBUG 01-06 08:44:53.536486.536486 lmp.py:380]   Expert 20 |    245 | GPU
DEBUG 01-06 08:44:53.536943.536943 lmp.py:380]   Expert 15 |    254 | GPU
DEBUG 01-06 08:44:53.536640.536640 lmp.py:380]   Expert 18 |    265 | GPU
DEBUG 01-06 08:44:53.536051.536051 lmp.py:380]   Expert 24 |    269 | GPU
DEBUG 01-06 08:44:53.536939.536939 lmp.py:380]   Expert 55 |    297 | GPU
DEBUG 01-06 08:44:53.536132.536132 lmp.py:380]   Expert 51 |    307 | GPU
DEBUG 01-06 08:44:53.536067.536067 lmp.py:380]   Expert  2 |    308 | GPU
DEBUG 01-06 08:44:53.536525.536525 lmp.py:380]   Expert 60 |    320 | GPU
DEBUG 01-06 08:44:53.536505.536505 lmp.py:380]   Expert 53 |    329 | GPU
DEBUG 01-06 08:44:53.536725.536725 lmp.py:380]   Expert 32 |    339 | GPU
DEBUG 01-06 08:44:53.536659.536659 lmp.py:380]   Expert 23 |    355 | GPU
DEBUG 01-06 08:44:53.536878.536878 lmp.py:380]   Expert 54 |    366 | GPU
DEBUG 01-06 08:44:53.536336.536336 lmp.py:380]   Expert 22 |    370 | GPU
DEBUG 01-06 08:44:53.536317.536317 lmp.py:380]   Expert  4 |    396 | GPU
DEBUG 01-06 08:44:53.536298.536298 lmp.py:380]   Expert 11 |    465 | GPU
DEBUG 01-06 08:44:53.536517.536517 lmp.py:380]   Expert 56 |    552 | GPU
DEBUG 01-06 08:44:53.536498.536498 lmp.py:380]   Expert 43 |    610 | GPU
DEBUG 01-06 08:44:53.536671.536671 lmp.py:381] 
DEBUG 01-06 08:44:53.536671.536671 lmp.py:381]   CPU total tokens: 3266 (26.6%)
DEBUG 01-06 08:44:53.536274.536274 lmp.py:382]   GPU total tokens: 9022 (73.4%)
DEBUG 01-06 08:44:53.536454.536454 cuda_h.py:19] end experts_map_get cost 0.0019631385803222656 seconds
DEBUG 01-06 08:44:53.536865.536865 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.536086.536086 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.536687.536687 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.537339.537339 cuda_h.py:19] end allocate_cuda_memory cost 0.0002193450927734375 seconds
INFO 01-06 08:44:53.537845.537845 client.py:127] Model loaded
DEBUG 01-06 08:44:53.537861.537861 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.537234.537234 cuda_h.py:19] end sllm_worker_task cost 0.009894132614135742 seconds
DEBUG 01-06 08:44:53.537434.537434 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.537755.537755 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.537266.537266 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cd292ba9-ba03-4f41-bd7f-a7773ad8a165
DEBUG 01-06 08:44:53.537538.537538 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.538172.538172 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cd292ba9-ba03-4f41-bd7f-a7773ad8a165
DEBUG 01-06 08:44:53.538055.538055 cuda_h.py:19] end load_into_gpu_async cost 0.001127481460571289 seconds
DEBUG 01-06 08:44:53.538281.538281 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.539448.539448 cuda_h.py:19] end restore_tensors2 cost 0.0004057884216308594 seconds
DEBUG 01-06 08:44:53.539814.539814 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023326873779296875 seconds
DEBUG 01-06 08:44:53.541639.541639 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005068302154541016 seconds
DEBUG 01-06 08:44:53.541442.541442 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.541286.541286 lmp.py:427] 
DEBUG 01-06 08:44:53.541286.541286 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:53.542699.542699 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-06 08:44:53.542110.542110 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:53.550060.550060 mlpmodule.py:704] group tensors cost 0.008666515350341797 s
DEBUG 01-06 08:44:53.552668.552668 mlpmodule.py:742] pad cost 0.001524209976196289 s
DEBUG 01-06 08:44:53.553797.553797 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-06 08:44:53.553123.553123 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 08:44:53.564454.564454 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:53.564552.564552 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.564880.564880 mlpmodule.py:773] group_w3 first element: 0.02001953125
WARNING 01-06 08:44:53.564388.564388 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.585239.585239 mlpmodule.py:793] group einsum cost 0.03223896026611328 s
DEBUG 01-06 08:44:53.586402.586402 mlpmodule.py:801] cpy2cputensor cost 0.0007143020629882812 s
DEBUG 01-06 08:44:53.591234.591234 cuda_h.py:19] end wait_cetm_experts cost 0.04913496971130371 seconds
DEBUG 01-06 08:44:53.591680.591680 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.591803.591803 cuda_h.py:19] end gpu_sexperts cost 0.00046253204345703125 seconds
DEBUG 01-06 08:44:53.591070.591070 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.591450.591450 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:53.592345.592345 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.592816.592816 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cd292ba9-ba03-4f41-bd7f-a7773ad8a165
INFO 01-06 08:44:53.597014.597014 client.py:127] Model loaded
DEBUG 01-06 08:44:53.598956.598956 cuda_h.py:19] end wait_experts cost 0.005967378616333008 seconds
DEBUG 01-06 08:44:53.598242.598242 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:53.598952.598952 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:53.600085.600085 mlpmodule.py:662]  experts func einsum cost 0.0584864616394043 s
DEBUG 01-06 08:44:53.609564.609564 cuda_h.py:19] end gpu_experts cost 0.011529922485351562 seconds
DEBUG 01-06 08:44:53.609123.609123 cuda_h.py:19] end layer_moe_generate_2 cost 0.07582402229309082 seconds
DEBUG 01-06 08:44:53.609262.609262 lmp.py:221] -------------------------------- end layer 2 --------------------------------
DEBUG 01-06 08:44:53.609177.609177 lmp.py:177] -------------------------------- start layer 3 --------------------------------
DEBUG 01-06 08:44:53.609396.609396 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 08:44:53.609960.609960 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 08:44:53.610935.610935 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.6226043701171875e-05 seconds
DEBUG 01-06 08:44:53.610751.610751 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.05718994140625e-05 seconds
DEBUG 01-06 08:44:53.610109.610109 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.610316.610316 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.610326.610326 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.610877.610877 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.610171.610171 cuda_h.py:19] end allocate_cuda_memory cost 0.0002105236053466797 seconds
DEBUG 01-06 08:44:53.610664.610664 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.610779.610779 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.610662.610662 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.610948.610948 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c0a0655e-afb1-444b-b6c0-e97fefdb7408
DEBUG 01-06 08:44:53.610568.610568 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.611721.611721 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.611750.611750 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c0a0655e-afb1-444b-b6c0-e97fefdb7408
DEBUG 01-06 08:44:53.612640.612640 cuda_h.py:19] end load_into_gpu_async cost 0.0014047622680664062 seconds
DEBUG 01-06 08:44:53.612979.612979 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.612990.612990 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-06 08:44:53.612694.612694 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020596981048583984 seconds
INFO 01-06 08:44:53.612197.612197 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c0a0655e-afb1-444b-b6c0-e97fefdb7408
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.615212.615212 cuda_h.py:19] end self_attn cost 0.00412440299987793 seconds
DEBUG 01-06 08:44:53.615640.615640 cuda_h.py:19] end iln_self_attn_paln cost 0.0055234432220458984 seconds
DEBUG 01-06 08:44:53.615244.615244 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-06 08:44:53.615199.615199 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.616977.616977 cuda_h.py:19] end gate cost 0.0006439685821533203 seconds
DEBUG 01-06 08:44:53.616376.616376 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.616128.616128 lmp.py:369] 
DEBUG 01-06 08:44:53.616128.616128 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.616030.616030 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:53.616395.616395 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:53.616184.616184 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:53.616111.616111 lmp.py:373] 
DEBUG 01-06 08:44:53.616111.616111 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.616039.616039 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.616166.616166 lmp.py:380]   Expert 16 |     47 | CPU
DEBUG 01-06 08:44:53.616332.616332 lmp.py:380]   Expert 15 |     48 | CPU
DEBUG 01-06 08:44:53.616259.616259 lmp.py:380]   Expert 61 |     51 | CPU
DEBUG 01-06 08:44:53.616949.616949 lmp.py:380]   Expert 59 |     55 | CPU
DEBUG 01-06 08:44:53.616161.616161 lmp.py:380]   Expert  1 |     59 | CPU
DEBUG 01-06 08:44:53.616003.616003 lmp.py:380]   Expert  4 |     61 | CPU
DEBUG 01-06 08:44:53.617123.617123 lmp.py:380]   Expert 32 |     75 | CPU
DEBUG 01-06 08:44:53.617051.617051 lmp.py:380]   Expert 58 |     87 | CPU
DEBUG 01-06 08:44:53.617263.617263 lmp.py:380]   Expert 29 |     89 | CPU
DEBUG 01-06 08:44:53.617476.617476 lmp.py:380]   Expert 56 |     92 | CPU
DEBUG 01-06 08:44:53.617688.617688 lmp.py:380]   Expert 26 |    104 | CPU
DEBUG 01-06 08:44:53.617424.617424 lmp.py:380]   Expert  7 |    106 | CPU
DEBUG 01-06 08:44:53.617398.617398 lmp.py:380]   Expert  6 |    117 | CPU
DEBUG 01-06 08:44:53.617133.617133 lmp.py:380]   Expert  8 |    118 | CPU
DEBUG 01-06 08:44:53.617107.617107 lmp.py:380]   Expert  5 |    119 | CPU
DEBUG 01-06 08:44:53.617605.617605 lmp.py:380]   Expert 19 |    125 | CPU
DEBUG 01-06 08:44:53.617579.617579 lmp.py:380]   Expert 28 |    125 | CPU
DEBUG 01-06 08:44:53.617791.617791 lmp.py:380]   Expert 52 |    127 | CPU
DEBUG 01-06 08:44:53.617719.617719 lmp.py:380]   Expert 30 |    130 | CPU
DEBUG 01-06 08:44:53.617170.617170 lmp.py:380]   Expert 31 |    136 | CPU
DEBUG 01-06 08:44:53.617621.617621 lmp.py:380]   Expert 48 |    143 | CPU
DEBUG 01-06 08:44:53.617548.617548 lmp.py:380]   Expert 24 |    148 | CPU
DEBUG 01-06 08:44:53.617522.617522 lmp.py:380]   Expert 38 |    148 | CPU
DEBUG 01-06 08:44:53.617496.617496 lmp.py:380]   Expert 54 |    153 | CPU
DEBUG 01-06 08:44:53.617139.617139 lmp.py:380]   Expert 10 |    155 | CPU
DEBUG 01-06 08:44:53.617829.617829 lmp.py:380]   Expert 37 |    156 | CPU
DEBUG 01-06 08:44:53.617756.617756 lmp.py:380]   Expert 49 |    159 | CPU
DEBUG 01-06 08:44:53.617684.617684 lmp.py:380]   Expert 12 |    161 | CPU
DEBUG 01-06 08:44:53.617373.617373 lmp.py:380]   Expert 20 |    163 | CPU
DEBUG 01-06 08:44:53.617063.617063 lmp.py:380]   Expert 63 |    165 | CPU
DEBUG 01-06 08:44:53.617229.617229 lmp.py:380]   Expert 11 |    169 | CPU
DEBUG 01-06 08:44:53.617156.617156 lmp.py:380]   Expert 40 |    170 | CPU
DEBUG 01-06 08:44:53.617276.617276 lmp.py:380]   Expert 23 |    172 | GPU
DEBUG 01-06 08:44:53.617681.617681 lmp.py:380]   Expert 35 |    180 | GPU
DEBUG 01-06 08:44:53.617562.617562 lmp.py:380]   Expert 46 |    183 | GPU
DEBUG 01-06 08:44:53.617920.617920 lmp.py:380]   Expert 57 |    185 | GPU
DEBUG 01-06 08:44:53.617087.617087 lmp.py:380]   Expert 36 |    186 | GPU
DEBUG 01-06 08:44:53.617253.617253 lmp.py:380]   Expert 55 |    194 | GPU
DEBUG 01-06 08:44:53.617657.617657 lmp.py:380]   Expert 22 |    195 | GPU
DEBUG 01-06 08:44:53.617062.617062 lmp.py:380]   Expert 18 |    199 | GPU
DEBUG 01-06 08:44:53.617228.617228 lmp.py:380]   Expert 42 |    203 | GPU
DEBUG 01-06 08:44:53.617408.617408 lmp.py:380]   Expert 51 |    206 | GPU
DEBUG 01-06 08:44:53.617620.617620 lmp.py:380]   Expert 62 |    206 | GPU
DEBUG 01-06 08:44:53.617356.617356 lmp.py:380]   Expert 45 |    211 | GPU
DEBUG 01-06 08:44:53.617853.617853 lmp.py:380]   Expert  0 |    214 | GPU
DEBUG 01-06 08:44:53.617589.617589 lmp.py:380]   Expert 17 |    216 | GPU
DEBUG 01-06 08:44:53.617563.617563 lmp.py:380]   Expert 43 |    224 | GPU
DEBUG 01-06 08:44:53.617014.617014 lmp.py:380]   Expert 53 |    244 | GPU
DEBUG 01-06 08:44:53.617464.617464 lmp.py:380]   Expert  2 |    245 | GPU
DEBUG 01-06 08:44:53.617439.617439 lmp.py:380]   Expert  3 |    248 | GPU
DEBUG 01-06 08:44:53.617413.617413 lmp.py:380]   Expert 34 |    252 | GPU
DEBUG 01-06 08:44:53.617671.617671 lmp.py:380]   Expert 27 |    264 | GPU
DEBUG 01-06 08:44:53.617169.617169 lmp.py:380]   Expert 33 |    269 | GPU
DEBUG 01-06 08:44:53.617427.617427 lmp.py:380]   Expert 39 |    280 | GPU
DEBUG 01-06 08:44:53.617163.617163 lmp.py:380]   Expert 41 |    280 | GPU
DEBUG 01-06 08:44:53.617422.617422 lmp.py:380]   Expert 13 |    282 | GPU
DEBUG 01-06 08:44:53.617442.617442 lmp.py:380]   Expert 47 |    317 | GPU
DEBUG 01-06 08:44:53.617939.617939 lmp.py:380]   Expert 44 |    324 | GPU
DEBUG 01-06 08:44:53.617198.617198 lmp.py:380]   Expert 21 |    334 | GPU
DEBUG 01-06 08:44:53.617934.617934 lmp.py:380]   Expert 50 |    338 | GPU
DEBUG 01-06 08:44:53.617193.617193 lmp.py:380]   Expert 25 |    378 | GPU
DEBUG 01-06 08:44:53.617928.617928 lmp.py:380]   Expert  9 |    408 | GPU
DEBUG 01-06 08:44:53.617141.617141 lmp.py:380]   Expert 14 |    528 | GPU
DEBUG 01-06 08:44:53.617592.617592 lmp.py:380]   Expert 60 |    562 | GPU
DEBUG 01-06 08:44:53.617519.617519 lmp.py:381] 
DEBUG 01-06 08:44:53.617519.617519 lmp.py:381]   CPU total tokens: 3761 (30.6%)
DEBUG 01-06 08:44:53.617162.617162 lmp.py:382]   GPU total tokens: 8527 (69.4%)
DEBUG 01-06 08:44:53.618620.618620 cuda_h.py:19] end experts_map_get cost 0.0015208721160888672 seconds
DEBUG 01-06 08:44:53.618309.618309 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.618655.618655 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.618838.618838 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.618430.618430 cuda_h.py:19] end allocate_cuda_memory cost 0.0004379749298095703 seconds
DEBUG 01-06 08:44:53.618194.618194 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.618196.618196 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.618813.618813 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.618178.618178 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a316ef0e-020d-425f-bff9-0e1b4d52e998
DEBUG 01-06 08:44:53.620467.620467 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.621996.621996 client.py:127] Model loaded
DEBUG 01-06 08:44:53.621588.621588 cuda_h.py:19] end sllm_worker_task cost 0.011006355285644531 seconds
INFO 01-06 08:44:53.622194.622194 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a316ef0e-020d-425f-bff9-0e1b4d52e998
DEBUG 01-06 08:44:53.622613.622613 cuda_h.py:19] end load_into_gpu_async cost 0.0035729408264160156 seconds
DEBUG 01-06 08:44:53.622985.622985 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.622336.622336 cuda_h.py:19] end restore_tensors2 cost 0.0003719329833984375 seconds
DEBUG 01-06 08:44:53.622411.622411 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004749298095703125 seconds
DEBUG 01-06 08:44:53.625770.625770 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007399320602416992 seconds
DEBUG 01-06 08:44:53.625851.625851 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.625258.625258 lmp.py:427] 
DEBUG 01-06 08:44:53.625258.625258 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:53.625572.625572 cuda_h.py:19] end cpu_experts_submit cost 0.00011563301086425781 seconds
DEBUG 01-06 08:44:53.625672.625672 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:53.633031.633031 mlpmodule.py:704] group tensors cost 0.007202625274658203 s
DEBUG 01-06 08:44:53.635610.635610 mlpmodule.py:742] pad cost 0.0021550655364990234 s
DEBUG 01-06 08:44:53.636064.636064 mlpmodule.py:748] create cpu tensor cost 5.054473876953125e-05 s
DEBUG 01-06 08:44:53.636756.636756 mlpmodule.py:753] move to cpu cost 3.790855407714844e-05 s
DEBUG 01-06 08:44:53.648863.648863 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:53.648193.648193 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.648951.648951 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-06 08:44:53.649552.649552 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.669643.669643 mlpmodule.py:793] group einsum cost 0.033112525939941406 s
DEBUG 01-06 08:44:53.670892.670892 mlpmodule.py:801] cpy2cputensor cost 0.0007221698760986328 s
DEBUG 01-06 08:44:53.675248.675248 cuda_h.py:19] end wait_cetm_experts cost 0.049391746520996094 seconds
DEBUG 01-06 08:44:53.675761.675761 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.675461.675461 cuda_h.py:19] end gpu_sexperts cost 0.00047135353088378906 seconds
DEBUG 01-06 08:44:53.675503.675503 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.675690.675690 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:44:53.675870.675870 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.675341.675341 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a316ef0e-020d-425f-bff9-0e1b4d52e998
INFO 01-06 08:44:53.681306.681306 client.py:127] Model loaded
DEBUG 01-06 08:44:53.681679.681679 cuda_h.py:19] end wait_experts cost 0.005339384078979492 seconds
DEBUG 01-06 08:44:53.681243.681243 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:53.681714.681714 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:53.684395.684395 mlpmodule.py:662]  experts func einsum cost 0.05882573127746582 s
DEBUG 01-06 08:44:53.692271.692271 cuda_h.py:19] end gpu_experts cost 0.011462688446044922 seconds
DEBUG 01-06 08:44:53.692281.692281 cuda_h.py:19] end layer_moe_generate_3 cost 0.07720375061035156 seconds
DEBUG 01-06 08:44:53.693261.693261 lmp.py:221] -------------------------------- end layer 3 --------------------------------
DEBUG 01-06 08:44:53.693454.693454 lmp.py:177] -------------------------------- start layer 4 --------------------------------
DEBUG 01-06 08:44:53.693389.693389 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 08:44:53.693145.693145 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 08:44:53.693703.693703 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.337860107421875e-05 seconds
DEBUG 01-06 08:44:53.693691.693691 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.461143493652344e-05 seconds
DEBUG 01-06 08:44:53.693003.693003 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.693463.693463 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.693062.693062 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.693428.693428 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.693273.693273 cuda_h.py:19] end allocate_cuda_memory cost 0.0002593994140625 seconds
DEBUG 01-06 08:44:53.693527.693527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.694913.694913 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.694484.694484 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.694479.694479 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3a8e56d4-011a-4892-ac0f-1bab81cac863
DEBUG 01-06 08:44:53.694985.694985 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.694628.694628 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.695741.695741 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3a8e56d4-011a-4892-ac0f-1bab81cac863
DEBUG 01-06 08:44:53.695107.695107 cuda_h.py:19] end load_into_gpu_async cost 0.0012657642364501953 seconds
DEBUG 01-06 08:44:53.695386.695386 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.695337.695337 cuda_h.py:19] end restore_tensors2 cost 7.343292236328125e-05 seconds
DEBUG 01-06 08:44:53.695385.695385 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018846988677978516 seconds
INFO 01-06 08:44:53.695058.695058 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3a8e56d4-011a-4892-ac0f-1bab81cac863
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.698876.698876 cuda_h.py:19] end self_attn cost 0.003962278366088867 seconds
DEBUG 01-06 08:44:53.698919.698919 cuda_h.py:19] end iln_self_attn_paln cost 0.005373954772949219 seconds
DEBUG 01-06 08:44:53.698663.698663 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-06 08:44:53.698949.698949 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.699799.699799 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-06 08:44:53.699052.699052 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.699413.699413 lmp.py:369] 
DEBUG 01-06 08:44:53.699413.699413 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.699977.699977 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:53.699435.699435 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:53.699031.699031 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:53.699436.699436 lmp.py:373] 
DEBUG 01-06 08:44:53.699436.699436 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.699363.699363 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.699013.699013 lmp.py:380]   Expert 45 |     19 | CPU
DEBUG 01-06 08:44:53.699703.699703 lmp.py:380]   Expert 51 |     31 | CPU
DEBUG 01-06 08:44:53.700915.700915 lmp.py:380]   Expert 18 |     35 | CPU
DEBUG 01-06 08:44:53.700651.700651 lmp.py:380]   Expert 60 |     43 | CPU
DEBUG 01-06 08:44:53.700386.700386 lmp.py:380]   Expert 11 |     45 | CPU
DEBUG 01-06 08:44:53.700360.700360 lmp.py:380]   Expert 58 |     46 | CPU
DEBUG 01-06 08:44:53.700096.700096 lmp.py:380]   Expert 36 |     53 | CPU
DEBUG 01-06 08:44:53.700070.700070 lmp.py:380]   Expert  8 |     57 | CPU
DEBUG 01-06 08:44:53.700329.700329 lmp.py:380]   Expert  2 |     63 | CPU
DEBUG 01-06 08:44:53.700826.700826 lmp.py:380]   Expert 14 |     64 | CPU
DEBUG 01-06 08:44:53.700085.700085 lmp.py:380]   Expert  9 |     65 | CPU
DEBUG 01-06 08:44:53.700820.700820 lmp.py:380]   Expert 28 |     65 | CPU
DEBUG 01-06 08:44:53.700271.700271 lmp.py:380]   Expert 13 |     68 | CPU
DEBUG 01-06 08:44:53.700722.700722 lmp.py:380]   Expert  7 |     71 | CPU
DEBUG 01-06 08:44:53.700173.700173 lmp.py:380]   Expert 48 |     75 | CPU
DEBUG 01-06 08:44:53.700624.700624 lmp.py:380]   Expert 41 |     76 | CPU
DEBUG 01-06 08:44:53.700836.700836 lmp.py:380]   Expert 16 |     82 | CPU
DEBUG 01-06 08:44:53.700810.700810 lmp.py:380]   Expert 34 |     84 | CPU
DEBUG 01-06 08:44:53.700308.700308 lmp.py:380]   Expert  6 |     87 | CPU
DEBUG 01-06 08:44:53.700043.700043 lmp.py:380]   Expert  3 |     89 | CPU
DEBUG 01-06 08:44:53.700302.700302 lmp.py:380]   Expert  4 |    102 | CPU
DEBUG 01-06 08:44:53.700799.700799 lmp.py:380]   Expert 25 |    103 | CPU
DEBUG 01-06 08:44:53.700296.700296 lmp.py:380]   Expert 32 |    109 | CPU
DEBUG 01-06 08:44:53.700555.700555 lmp.py:380]   Expert 24 |    115 | CPU
DEBUG 01-06 08:44:53.700814.700814 lmp.py:380]   Expert 55 |    116 | CPU
DEBUG 01-06 08:44:53.700073.700073 lmp.py:380]   Expert 53 |    123 | CPU
DEBUG 01-06 08:44:53.700107.700107 lmp.py:380]   Expert 22 |    124 | CPU
DEBUG 01-06 08:44:53.700201.700201 lmp.py:380]   Expert 33 |    139 | CPU
DEBUG 01-06 08:44:53.700036.700036 lmp.py:380]   Expert 26 |    144 | CPU
DEBUG 01-06 08:44:53.700017.700017 lmp.py:380]   Expert 15 |    147 | CPU
DEBUG 01-06 08:44:53.700660.700660 lmp.py:380]   Expert 27 |    152 | CPU
DEBUG 01-06 08:44:53.700349.700349 lmp.py:380]   Expert 44 |    152 | CPU
DEBUG 01-06 08:44:53.700277.700277 lmp.py:380]   Expert  0 |    156 | GPU
DEBUG 01-06 08:44:53.700251.700251 lmp.py:380]   Expert 63 |    167 | GPU
DEBUG 01-06 08:44:53.700463.700463 lmp.py:380]   Expert 10 |    168 | GPU
DEBUG 01-06 08:44:53.700914.700914 lmp.py:380]   Expert 19 |    171 | GPU
DEBUG 01-06 08:44:53.700650.700650 lmp.py:380]   Expert 54 |    171 | GPU
DEBUG 01-06 08:44:53.700624.700624 lmp.py:380]   Expert 20 |    179 | GPU
DEBUG 01-06 08:44:53.700359.700359 lmp.py:380]   Expert 17 |    187 | GPU
DEBUG 01-06 08:44:53.700095.700095 lmp.py:380]   Expert 21 |    205 | GPU
DEBUG 01-06 08:44:53.700830.700830 lmp.py:380]   Expert 46 |    231 | GPU
DEBUG 01-06 08:44:53.700805.700805 lmp.py:380]   Expert 35 |    233 | GPU
DEBUG 01-06 08:44:53.700540.700540 lmp.py:380]   Expert 56 |    237 | GPU
DEBUG 01-06 08:44:53.700276.700276 lmp.py:380]   Expert 47 |    240 | GPU
DEBUG 01-06 08:44:53.700011.700011 lmp.py:380]   Expert 49 |    248 | GPU
DEBUG 01-06 08:44:53.700462.700462 lmp.py:380]   Expert 61 |    249 | GPU
DEBUG 01-06 08:44:53.700628.700628 lmp.py:380]   Expert 31 |    256 | GPU
DEBUG 01-06 08:44:53.700556.700556 lmp.py:380]   Expert 42 |    267 | GPU
DEBUG 01-06 08:44:53.700245.700245 lmp.py:380]   Expert 29 |    279 | GPU
DEBUG 01-06 08:44:53.700458.700458 lmp.py:380]   Expert 57 |    294 | GPU
DEBUG 01-06 08:44:53.700194.700194 lmp.py:380]   Expert 30 |    303 | GPU
DEBUG 01-06 08:44:53.700929.700929 lmp.py:380]   Expert  1 |    307 | GPU
DEBUG 01-06 08:44:53.700665.700665 lmp.py:380]   Expert 37 |    314 | GPU
DEBUG 01-06 08:44:53.700639.700639 lmp.py:380]   Expert 39 |    315 | GPU
DEBUG 01-06 08:44:53.700374.700374 lmp.py:380]   Expert 40 |    316 | GPU
DEBUG 01-06 08:44:53.700587.700587 lmp.py:380]   Expert 38 |    337 | GPU
DEBUG 01-06 08:44:53.700799.700799 lmp.py:380]   Expert 62 |    339 | GPU
DEBUG 01-06 08:44:53.700535.700535 lmp.py:380]   Expert 50 |    346 | GPU
DEBUG 01-06 08:44:53.700463.700463 lmp.py:380]   Expert 52 |    390 | GPU
DEBUG 01-06 08:44:53.700390.700390 lmp.py:380]   Expert 43 |    412 | GPU
DEBUG 01-06 08:44:53.700795.700795 lmp.py:380]   Expert  5 |    492 | GPU
DEBUG 01-06 08:44:53.700484.700484 lmp.py:380]   Expert 23 |    499 | GPU
DEBUG 01-06 08:44:53.701412.701412 lmp.py:380]   Expert 12 |    609 | GPU
DEBUG 01-06 08:44:53.701386.701386 lmp.py:380]   Expert 59 |    627 | GPU
DEBUG 01-06 08:44:53.701314.701314 lmp.py:381] 
DEBUG 01-06 08:44:53.701314.701314 lmp.py:381]   CPU total tokens: 2744 (22.3%)
DEBUG 01-06 08:44:53.701241.701241 lmp.py:382]   GPU total tokens: 9544 (77.7%)
DEBUG 01-06 08:44:53.701414.701414 cuda_h.py:19] end experts_map_get cost 0.0015027523040771484 seconds
DEBUG 01-06 08:44:53.701342.701342 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.701880.701880 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.701640.701640 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.701411.701411 cuda_h.py:19] end allocate_cuda_memory cost 0.00044989585876464844 seconds
DEBUG 01-06 08:44:53.701731.701731 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.701249.701249 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.701058.701058 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.701807.701807 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9c45bdc-e558-4eaa-b689-dfcc49ac5426
DEBUG 01-06 08:44:53.702588.702588 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.702097.702097 client.py:127] Model loaded
DEBUG 01-06 08:44:53.702616.702616 cuda_h.py:19] end sllm_worker_task cost 0.008838653564453125 seconds
INFO 01-06 08:44:53.703906.703906 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9c45bdc-e558-4eaa-b689-dfcc49ac5426
DEBUG 01-06 08:44:53.703318.703318 cuda_h.py:19] end load_into_gpu_async cost 0.0012767314910888672 seconds
DEBUG 01-06 08:44:53.703783.703783 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.703452.703452 cuda_h.py:19] end restore_tensors2 cost 0.000396728515625 seconds
DEBUG 01-06 08:44:53.703481.703481 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002493143081665039 seconds
DEBUG 01-06 08:44:53.706926.706926 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005143404006958008 seconds
DEBUG 01-06 08:44:53.706246.706246 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.706209.706209 lmp.py:427] 
DEBUG 01-06 08:44:53.706209.706209 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:53.706191.706191 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 08:44:53.706317.706317 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:53.717116.717116 mlpmodule.py:704] group tensors cost 0.010666131973266602 s
DEBUG 01-06 08:44:53.719314.719314 mlpmodule.py:742] pad cost 0.0015933513641357422 s
DEBUG 01-06 08:44:53.719417.719417 mlpmodule.py:748] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 08:44:53.719089.719089 mlpmodule.py:753] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-06 08:44:53.731301.731301 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:53.731638.731638 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.731344.731344 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-06 08:44:53.732560.732560 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.750372.750372 mlpmodule.py:793] group einsum cost 0.030535221099853516 s
DEBUG 01-06 08:44:53.751580.751580 mlpmodule.py:801] cpy2cputensor cost 0.0006542205810546875 s
DEBUG 01-06 08:44:53.756510.756510 cuda_h.py:19] end wait_cetm_experts cost 0.049599647521972656 seconds
DEBUG 01-06 08:44:53.756162.756162 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.756921.756921 cuda_h.py:19] end gpu_sexperts cost 0.00048065185546875 seconds
DEBUG 01-06 08:44:53.756810.756810 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.756998.756998 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-06 08:44:53.756893.756893 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.756364.756364 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9c45bdc-e558-4eaa-b689-dfcc49ac5426
INFO 01-06 08:44:53.762205.762205 client.py:127] Model loaded
DEBUG 01-06 08:44:53.762862.762862 cuda_h.py:19] end wait_experts cost 0.005774497985839844 seconds
DEBUG 01-06 08:44:53.762949.762949 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:53.762944.762944 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:53.766528.766528 mlpmodule.py:662]  experts func einsum cost 0.05997061729431152 s
DEBUG 01-06 08:44:53.774966.774966 cuda_h.py:19] end gpu_experts cost 0.011352062225341797 seconds
DEBUG 01-06 08:44:53.774534.774534 cuda_h.py:19] end layer_moe_generate_4 cost 0.07543349266052246 seconds
DEBUG 01-06 08:44:53.774838.774838 lmp.py:221] -------------------------------- end layer 4 --------------------------------
DEBUG 01-06 08:44:53.774601.774601 lmp.py:177] -------------------------------- start layer 5 --------------------------------
DEBUG 01-06 08:44:53.774820.774820 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 08:44:53.774861.774861 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 08:44:53.774174.774174 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.7894973754882812e-05 seconds
DEBUG 01-06 08:44:53.774970.774970 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.8650970458984375e-05 seconds
DEBUG 01-06 08:44:53.774851.774851 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.774979.774979 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.774857.774857 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.774515.774515 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.775349.775349 cuda_h.py:19] end allocate_cuda_memory cost 0.0003142356872558594 seconds
DEBUG 01-06 08:44:53.775186.775186 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.775148.775148 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.775673.775673 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.775529.775529 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a99cd42-4e03-4928-b169-76684e56f951
DEBUG 01-06 08:44:53.775135.775135 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.775976.775976 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.776003.776003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a99cd42-4e03-4928-b169-76684e56f951
DEBUG 01-06 08:44:53.776900.776900 cuda_h.py:19] end load_into_gpu_async cost 0.0012917518615722656 seconds
DEBUG 01-06 08:44:53.776371.776371 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.776520.776520 cuda_h.py:19] end restore_tensors2 cost 7.700920104980469e-05 seconds
DEBUG 01-06 08:44:53.776713.776713 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001994609832763672 seconds
INFO 01-06 08:44:53.777639.777639 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a99cd42-4e03-4928-b169-76684e56f951
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.779238.779238 cuda_h.py:19] end self_attn cost 0.0040280818939208984 seconds
DEBUG 01-06 08:44:53.780579.780579 cuda_h.py:19] end iln_self_attn_paln cost 0.005494594573974609 seconds
DEBUG 01-06 08:44:53.780515.780515 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-06 08:44:53.780947.780947 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.780347.780347 cuda_h.py:19] end gate cost 0.0006465911865234375 seconds
DEBUG 01-06 08:44:53.780554.780554 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.781431.781431 lmp.py:369] 
DEBUG 01-06 08:44:53.781431.781431 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.781234.781234 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:53.781883.781883 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:53.781195.781195 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:53.781838.781838 lmp.py:373] 
DEBUG 01-06 08:44:53.781838.781838 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.781004.781004 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.781846.781846 lmp.py:380]   Expert 18 |     20 | CPU
DEBUG 01-06 08:44:53.781489.781489 lmp.py:380]   Expert 15 |     36 | CPU
DEBUG 01-06 08:44:53.781178.781178 lmp.py:380]   Expert  2 |     40 | CPU
DEBUG 01-06 08:44:53.781868.781868 lmp.py:380]   Expert 39 |     42 | CPU
DEBUG 01-06 08:44:53.781557.781557 lmp.py:380]   Expert 47 |     44 | CPU
DEBUG 01-06 08:44:53.781008.781008 lmp.py:380]   Expert 48 |     45 | CPU
DEBUG 01-06 08:44:53.781697.781697 lmp.py:380]   Expert  3 |     53 | CPU
DEBUG 01-06 08:44:53.781671.781671 lmp.py:380]   Expert 22 |     60 | CPU
DEBUG 01-06 08:44:53.781884.781884 lmp.py:380]   Expert 42 |     60 | CPU
DEBUG 01-06 08:44:53.781288.781288 lmp.py:380]   Expert  4 |     69 | CPU
DEBUG 01-06 08:44:53.781216.781216 lmp.py:380]   Expert 32 |     69 | CPU
DEBUG 01-06 08:44:53.781621.781621 lmp.py:380]   Expert 52 |     69 | CPU
DEBUG 01-06 08:44:53.781833.781833 lmp.py:380]   Expert 27 |     72 | CPU
DEBUG 01-06 08:44:53.781046.781046 lmp.py:380]   Expert 23 |     77 | CPU
DEBUG 01-06 08:44:53.781258.781258 lmp.py:380]   Expert 24 |     78 | CPU
DEBUG 01-06 08:44:53.781947.781947 lmp.py:380]   Expert 26 |     78 | CPU
DEBUG 01-06 08:44:53.781683.781683 lmp.py:380]   Expert 28 |     82 | CPU
DEBUG 01-06 08:44:53.781895.781895 lmp.py:380]   Expert 51 |     82 | CPU
DEBUG 01-06 08:44:53.781869.781869 lmp.py:380]   Expert 57 |     84 | CPU
DEBUG 01-06 08:44:53.781320.781320 lmp.py:380]   Expert 17 |     86 | CPU
DEBUG 01-06 08:44:53.781533.781533 lmp.py:380]   Expert 49 |     94 | CPU
DEBUG 01-06 08:44:53.781507.781507 lmp.py:380]   Expert 30 |     97 | CPU
DEBUG 01-06 08:44:53.781911.781911 lmp.py:380]   Expert 45 |     98 | CPU
DEBUG 01-06 08:44:53.781316.781316 lmp.py:380]   Expert 62 |    102 | CPU
DEBUG 01-06 08:44:53.781674.781674 lmp.py:380]   Expert 14 |    109 | CPU
DEBUG 01-06 08:44:53.781079.781079 lmp.py:380]   Expert 36 |    111 | CPU
DEBUG 01-06 08:44:53.781483.781483 lmp.py:380]   Expert 46 |    113 | CPU
DEBUG 01-06 08:44:53.781411.781411 lmp.py:380]   Expert 60 |    119 | CPU
DEBUG 01-06 08:44:53.781100.781100 lmp.py:380]   Expert 50 |    123 | CPU
DEBUG 01-06 08:44:53.781982.781982 lmp.py:380]   Expert 12 |    125 | CPU
DEBUG 01-06 08:44:53.781909.781909 lmp.py:380]   Expert 16 |    125 | CPU
DEBUG 01-06 08:44:53.781076.781076 lmp.py:380]   Expert 19 |    133 | GPU
DEBUG 01-06 08:44:53.781480.781480 lmp.py:380]   Expert 59 |    134 | GPU
DEBUG 01-06 08:44:53.781646.781646 lmp.py:380]   Expert 29 |    137 | GPU
DEBUG 01-06 08:44:53.781243.781243 lmp.py:380]   Expert 55 |    137 | GPU
DEBUG 01-06 08:44:53.782840.782840 lmp.py:380]   Expert  1 |    140 | GPU
DEBUG 01-06 08:44:53.782006.782006 lmp.py:380]   Expert 10 |    142 | GPU
DEBUG 01-06 08:44:53.782901.782901 lmp.py:380]   Expert 25 |    148 | GPU
DEBUG 01-06 08:44:53.782590.782590 lmp.py:380]   Expert  8 |    149 | GPU
DEBUG 01-06 08:44:53.782518.782518 lmp.py:380]   Expert 41 |    154 | GPU
DEBUG 01-06 08:44:53.782969.782969 lmp.py:380]   Expert  9 |    155 | GPU
DEBUG 01-06 08:44:53.782658.782658 lmp.py:380]   Expert 43 |    159 | GPU
DEBUG 01-06 08:44:53.782347.782347 lmp.py:380]   Expert 56 |    160 | GPU
DEBUG 01-06 08:44:53.782036.782036 lmp.py:380]   Expert 58 |    161 | GPU
DEBUG 01-06 08:44:53.782203.782203 lmp.py:380]   Expert 61 |    168 | GPU
DEBUG 01-06 08:44:53.782422.782422 lmp.py:380]   Expert 54 |    170 | GPU
DEBUG 01-06 08:44:53.782111.782111 lmp.py:380]   Expert 11 |    172 | GPU
DEBUG 01-06 08:44:53.782847.782847 lmp.py:380]   Expert 44 |    172 | GPU
DEBUG 01-06 08:44:53.782344.782344 lmp.py:380]   Expert 63 |    189 | GPU
DEBUG 01-06 08:44:53.782080.782080 lmp.py:380]   Expert 38 |    195 | GPU
DEBUG 01-06 08:44:53.782054.782054 lmp.py:380]   Expert  0 |    229 | GPU
DEBUG 01-06 08:44:53.782789.782789 lmp.py:380]   Expert 13 |    245 | GPU
DEBUG 01-06 08:44:53.782525.782525 lmp.py:380]   Expert  5 |    305 | GPU
DEBUG 01-06 08:44:53.782784.782784 lmp.py:380]   Expert 35 |    314 | GPU
DEBUG 01-06 08:44:53.782519.782519 lmp.py:380]   Expert 31 |    317 | GPU
DEBUG 01-06 08:44:53.782447.782447 lmp.py:380]   Expert  7 |    339 | GPU
DEBUG 01-06 08:44:53.782136.782136 lmp.py:380]   Expert 33 |    444 | GPU
DEBUG 01-06 08:44:53.782587.782587 lmp.py:380]   Expert 21 |    497 | GPU
DEBUG 01-06 08:44:53.782323.782323 lmp.py:380]   Expert 37 |    532 | GPU
DEBUG 01-06 08:44:53.782582.782582 lmp.py:380]   Expert 20 |    553 | GPU
DEBUG 01-06 08:44:53.782317.782317 lmp.py:380]   Expert 40 |    559 | GPU
DEBUG 01-06 08:44:53.782814.782814 lmp.py:380]   Expert  6 |    946 | GPU
DEBUG 01-06 08:44:53.782312.782312 lmp.py:380]   Expert 53 |   1571 | GPU
DEBUG 01-06 08:44:53.782524.782524 lmp.py:381] 
DEBUG 01-06 08:44:53.782524.782524 lmp.py:381]   CPU total tokens: 2462 (20.0%)
DEBUG 01-06 08:44:53.782975.782975 lmp.py:382]   GPU total tokens: 9826 (80.0%)
DEBUG 01-06 08:44:53.782717.782717 cuda_h.py:19] end experts_map_get cost 0.0014972686767578125 seconds
DEBUG 01-06 08:44:53.782407.782407 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.782898.782898 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.782751.782751 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.783888.783888 cuda_h.py:19] end allocate_cuda_memory cost 0.00049591064453125 seconds
DEBUG 01-06 08:44:53.783116.783116 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.783872.783872 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.783012.783012 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.783900.783900 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e28ab1b7-9d04-43a6-b53f-7d20a484ca35
DEBUG 01-06 08:44:53.783158.783158 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.783931.783931 client.py:127] Model loaded
DEBUG 01-06 08:44:53.783258.783258 cuda_h.py:19] end sllm_worker_task cost 0.009007692337036133 seconds
INFO 01-06 08:44:53.784003.784003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e28ab1b7-9d04-43a6-b53f-7d20a484ca35
DEBUG 01-06 08:44:53.784277.784277 cuda_h.py:19] end load_into_gpu_async cost 0.0012080669403076172 seconds
DEBUG 01-06 08:44:53.784516.784516 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.785226.785226 cuda_h.py:19] end restore_tensors2 cost 0.00039005279541015625 seconds
DEBUG 01-06 08:44:53.785161.785161 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024881362915039062 seconds
DEBUG 01-06 08:44:53.787677.787677 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005089759826660156 seconds
DEBUG 01-06 08:44:53.787421.787421 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.787689.787689 lmp.py:427] 
DEBUG 01-06 08:44:53.787689.787689 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:53.787002.787002 cuda_h.py:19] end cpu_experts_submit cost 0.00010418891906738281 seconds
DEBUG 01-06 08:44:53.787129.787129 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:53.793499.793499 mlpmodule.py:704] group tensors cost 0.0059626102447509766 s
DEBUG 01-06 08:44:53.796381.796381 mlpmodule.py:742] pad cost 0.00145721435546875 s
DEBUG 01-06 08:44:53.796841.796841 mlpmodule.py:748] create cpu tensor cost 3.719329833984375e-05 s
DEBUG 01-06 08:44:53.796784.796784 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 08:44:53.806533.806533 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:53.806354.806354 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.806874.806874 mlpmodule.py:773] group_w3 first element: -0.010498046875
WARNING 01-06 08:44:53.807428.807428 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.822187.822187 mlpmodule.py:793] group einsum cost 0.026195764541625977 s
DEBUG 01-06 08:44:53.823220.823220 mlpmodule.py:801] cpy2cputensor cost 0.0005815029144287109 s
DEBUG 01-06 08:44:53.828418.828418 cuda_h.py:19] end wait_cetm_experts cost 0.04023289680480957 seconds
DEBUG 01-06 08:44:53.828679.828679 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.828286.828286 cuda_h.py:19] end gpu_sexperts cost 0.0004734992980957031 seconds
DEBUG 01-06 08:44:53.828268.828268 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.828078.828078 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:53.828734.828734 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.828921.828921 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e28ab1b7-9d04-43a6-b53f-7d20a484ca35
DEBUG 01-06 08:44:53.839973.839973 mlpmodule.py:662]  experts func einsum cost 0.051801443099975586 s
INFO 01-06 08:44:53.842262.842262 client.py:127] Model loaded
DEBUG 01-06 08:44:53.842641.842641 cuda_h.py:19] end wait_experts cost 0.01320791244506836 seconds
DEBUG 01-06 08:44:53.842775.842775 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:53.842239.842239 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:53.853117.853117 cuda_h.py:19] end gpu_experts cost 0.011557340621948242 seconds
DEBUG 01-06 08:44:53.853650.853650 cuda_h.py:19] end layer_moe_generate_5 cost 0.0736246109008789 seconds
DEBUG 01-06 08:44:53.854637.854637 lmp.py:221] -------------------------------- end layer 5 --------------------------------
DEBUG 01-06 08:44:53.854691.854691 lmp.py:177] -------------------------------- start layer 6 --------------------------------
DEBUG 01-06 08:44:53.854248.854248 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 08:44:53.854865.854865 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 08:44:53.854185.854185 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:44:53.854080.854080 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.29425048828125e-05 seconds
DEBUG 01-06 08:44:53.854776.854776 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.854758.854758 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.854995.854995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.854706.854706 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.854200.854200 cuda_h.py:19] end allocate_cuda_memory cost 0.00028514862060546875 seconds
DEBUG 01-06 08:44:53.854389.854389 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.855450.855450 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.855902.855902 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.855327.855327 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d86691d-14a9-4aa7-b59b-014840f328ba
DEBUG 01-06 08:44:53.855178.855178 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.855174.855174 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.856666.856666 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d86691d-14a9-4aa7-b59b-014840f328ba
DEBUG 01-06 08:44:53.856861.856861 cuda_h.py:19] end load_into_gpu_async cost 0.0013852119445800781 seconds
DEBUG 01-06 08:44:53.856195.856195 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.856206.856206 cuda_h.py:19] end restore_tensors2 cost 9.894371032714844e-05 seconds
DEBUG 01-06 08:44:53.856831.856831 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021839141845703125 seconds
INFO 01-06 08:44:53.857073.857073 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d86691d-14a9-4aa7-b59b-014840f328ba
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.859077.859077 cuda_h.py:19] end self_attn cost 0.0043566226959228516 seconds
DEBUG 01-06 08:44:53.860120.860120 cuda_h.py:19] end iln_self_attn_paln cost 0.005800008773803711 seconds
DEBUG 01-06 08:44:53.860863.860863 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-06 08:44:53.860865.860865 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.860086.860086 cuda_h.py:19] end gate cost 0.0006568431854248047 seconds
DEBUG 01-06 08:44:53.861055.861055 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.861277.861277 lmp.py:369] 
DEBUG 01-06 08:44:53.861277.861277 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.861318.861318 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:53.861014.861014 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:53.861564.861564 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:53.861254.861254 lmp.py:373] 
DEBUG 01-06 08:44:53.861254.861254 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.861658.861658 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.861069.861069 lmp.py:380]   Expert  1 |      8 | CPU
DEBUG 01-06 08:44:53.861236.861236 lmp.py:380]   Expert  3 |      8 | CPU
DEBUG 01-06 08:44:53.861740.861740 lmp.py:380]   Expert 14 |     14 | CPU
DEBUG 01-06 08:44:53.861144.861144 lmp.py:380]   Expert 15 |     18 | CPU
DEBUG 01-06 08:44:53.861072.861072 lmp.py:380]   Expert 52 |     19 | CPU
DEBUG 01-06 08:44:53.861761.861761 lmp.py:380]   Expert 16 |     25 | CPU
DEBUG 01-06 08:44:53.861450.861450 lmp.py:380]   Expert 33 |     26 | CPU
DEBUG 01-06 08:44:53.861901.861901 lmp.py:380]   Expert 30 |     35 | CPU
DEBUG 01-06 08:44:53.861352.861352 lmp.py:380]   Expert 53 |     35 | CPU
DEBUG 01-06 08:44:53.861326.861326 lmp.py:380]   Expert 63 |     57 | CPU
DEBUG 01-06 08:44:53.861539.861539 lmp.py:380]   Expert 21 |     59 | CPU
DEBUG 01-06 08:44:53.861990.861990 lmp.py:380]   Expert 49 |     60 | CPU
DEBUG 01-06 08:44:53.861964.861964 lmp.py:380]   Expert 50 |     61 | CPU
DEBUG 01-06 08:44:53.861176.861176 lmp.py:380]   Expert  7 |     69 | CPU
DEBUG 01-06 08:44:53.861389.861389 lmp.py:380]   Expert 11 |     70 | CPU
DEBUG 01-06 08:44:53.861363.861363 lmp.py:380]   Expert 26 |     75 | CPU
DEBUG 01-06 08:44:53.861337.861337 lmp.py:380]   Expert 35 |     75 | CPU
DEBUG 01-06 08:44:53.861788.861788 lmp.py:380]   Expert 41 |     76 | CPU
DEBUG 01-06 08:44:53.861430.861430 lmp.py:380]   Expert 37 |     80 | CPU
DEBUG 01-06 08:44:53.861073.861073 lmp.py:380]   Expert 40 |     82 | CPU
DEBUG 01-06 08:44:53.861478.861478 lmp.py:380]   Expert 29 |     84 | CPU
DEBUG 01-06 08:44:53.861644.861644 lmp.py:380]   Expert 10 |     91 | CPU
DEBUG 01-06 08:44:53.861333.861333 lmp.py:380]   Expert 25 |     93 | CPU
DEBUG 01-06 08:44:53.861069.861069 lmp.py:380]   Expert 59 |     95 | CPU
DEBUG 01-06 08:44:53.861282.861282 lmp.py:380]   Expert 34 |     96 | CPU
DEBUG 01-06 08:44:53.861017.861017 lmp.py:380]   Expert  5 |    102 | CPU
DEBUG 01-06 08:44:53.861660.861660 lmp.py:380]   Expert  8 |    103 | CPU
DEBUG 01-06 08:44:53.861065.861065 lmp.py:380]   Expert 22 |    105 | CPU
DEBUG 01-06 08:44:53.861992.861992 lmp.py:380]   Expert 44 |    108 | CPU
DEBUG 01-06 08:44:53.861397.861397 lmp.py:380]   Expert 47 |    119 | CPU
DEBUG 01-06 08:44:53.861563.861563 lmp.py:380]   Expert 42 |    121 | CPU
DEBUG 01-06 08:44:53.861968.861968 lmp.py:380]   Expert 31 |    123 | CPU
DEBUG 01-06 08:44:53.862564.862564 lmp.py:380]   Expert 38 |    124 | GPU
DEBUG 01-06 08:44:53.862684.862684 lmp.py:380]   Expert 13 |    128 | GPU
DEBUG 01-06 08:44:53.862612.862612 lmp.py:380]   Expert 45 |    129 | GPU
DEBUG 01-06 08:44:53.862540.862540 lmp.py:380]   Expert 51 |    133 | GPU
DEBUG 01-06 08:44:53.862467.862467 lmp.py:380]   Expert 32 |    136 | GPU
DEBUG 01-06 08:44:53.862633.862633 lmp.py:380]   Expert 61 |    138 | GPU
DEBUG 01-06 08:44:53.862800.862800 lmp.py:380]   Expert 12 |    147 | GPU
DEBUG 01-06 08:44:53.862727.862727 lmp.py:380]   Expert 62 |    154 | GPU
DEBUG 01-06 08:44:53.862893.862893 lmp.py:380]   Expert  6 |    169 | GPU
DEBUG 01-06 08:44:53.862821.862821 lmp.py:380]   Expert 24 |    173 | GPU
DEBUG 01-06 08:44:53.862464.862464 lmp.py:380]   Expert  0 |    175 | GPU
DEBUG 01-06 08:44:53.862346.862346 lmp.py:380]   Expert 54 |    179 | GPU
DEBUG 01-06 08:44:53.862227.862227 lmp.py:380]   Expert 20 |    186 | GPU
DEBUG 01-06 08:44:53.862585.862585 lmp.py:380]   Expert 46 |    189 | GPU
DEBUG 01-06 08:44:53.862513.862513 lmp.py:380]   Expert 58 |    197 | GPU
DEBUG 01-06 08:44:53.862202.862202 lmp.py:380]   Expert 57 |    235 | GPU
DEBUG 01-06 08:44:53.862130.862130 lmp.py:380]   Expert  2 |    238 | GPU
DEBUG 01-06 08:44:53.862058.862058 lmp.py:380]   Expert 28 |    247 | GPU
DEBUG 01-06 08:44:53.862747.862747 lmp.py:380]   Expert 17 |    253 | GPU
DEBUG 01-06 08:44:53.862675.862675 lmp.py:380]   Expert 18 |    258 | GPU
DEBUG 01-06 08:44:53.862841.862841 lmp.py:380]   Expert  9 |    270 | GPU
DEBUG 01-06 08:44:53.862768.862768 lmp.py:380]   Expert 27 |    319 | GPU
DEBUG 01-06 08:44:53.862981.862981 lmp.py:380]   Expert 39 |    324 | GPU
DEBUG 01-06 08:44:53.862909.862909 lmp.py:380]   Expert 60 |    364 | GPU
DEBUG 01-06 08:44:53.862313.862313 lmp.py:380]   Expert 55 |    374 | GPU
DEBUG 01-06 08:44:53.862956.862956 lmp.py:380]   Expert 19 |    375 | GPU
DEBUG 01-06 08:44:53.862335.862335 lmp.py:380]   Expert 23 |    401 | GPU
DEBUG 01-06 08:44:53.862216.862216 lmp.py:380]   Expert  4 |    427 | GPU
DEBUG 01-06 08:44:53.862429.862429 lmp.py:380]   Expert 43 |    455 | GPU
DEBUG 01-06 08:44:53.862164.862164 lmp.py:380]   Expert 36 |    765 | GPU
DEBUG 01-06 08:44:53.862138.862138 lmp.py:380]   Expert 56 |   1055 | GPU
DEBUG 01-06 08:44:53.862874.862874 lmp.py:380]   Expert 48 |   1379 | GPU
DEBUG 01-06 08:44:53.862563.862563 lmp.py:381] 
DEBUG 01-06 08:44:53.862563.862563 lmp.py:381]   CPU total tokens: 2192 (17.8%)
DEBUG 01-06 08:44:53.862491.862491 lmp.py:382]   GPU total tokens: 10096 (82.2%)
DEBUG 01-06 08:44:53.862187.862187 cuda_h.py:19] end experts_map_get cost 0.0015408992767333984 seconds
DEBUG 01-06 08:44:53.862784.862784 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.862752.862752 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.862220.862220 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.863706.863706 cuda_h.py:19] end allocate_cuda_memory cost 0.00021505355834960938 seconds
DEBUG 01-06 08:44:53.863641.863641 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.863444.863444 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.863822.863822 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.863710.863710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fe03bba9-2bd6-421f-a6c0-41df74bbaf35
DEBUG 01-06 08:44:53.863207.863207 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.863325.863325 client.py:127] Model loaded
DEBUG 01-06 08:44:53.863586.863586 cuda_h.py:19] end sllm_worker_task cost 0.009145259857177734 seconds
INFO 01-06 08:44:53.864550.864550 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fe03bba9-2bd6-421f-a6c0-41df74bbaf35
DEBUG 01-06 08:44:53.864453.864453 cuda_h.py:19] end load_into_gpu_async cost 0.001268625259399414 seconds
DEBUG 01-06 08:44:53.864447.864447 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.864925.864925 cuda_h.py:19] end restore_tensors2 cost 0.0003948211669921875 seconds
DEBUG 01-06 08:44:53.864523.864523 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022308826446533203 seconds
DEBUG 01-06 08:44:53.867152.867152 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004843711853027344 seconds
DEBUG 01-06 08:44:53.867611.867611 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.867097.867097 lmp.py:427] 
DEBUG 01-06 08:44:53.867097.867097 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:53.867125.867125 cuda_h.py:19] end cpu_experts_submit cost 0.00010418891906738281 seconds
DEBUG 01-06 08:44:53.867988.867988 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:53.879818.879818 mlpmodule.py:704] group tensors cost 0.011968135833740234 s
DEBUG 01-06 08:44:53.882080.882080 mlpmodule.py:742] pad cost 0.0015559196472167969 s
DEBUG 01-06 08:44:53.882547.882547 mlpmodule.py:748] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 08:44:53.882589.882589 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-06 08:44:53.893452.893452 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:53.893259.893259 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.893634.893634 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-06 08:44:53.894188.894188 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.912680.912680 mlpmodule.py:793] group einsum cost 0.03053450584411621 s
DEBUG 01-06 08:44:53.913487.913487 mlpmodule.py:801] cpy2cputensor cost 0.0005655288696289062 s
DEBUG 01-06 08:44:53.918252.918252 cuda_h.py:19] end wait_cetm_experts cost 0.050783634185791016 seconds
DEBUG 01-06 08:44:53.918851.918851 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.919968.919968 cuda_h.py:19] end gpu_sexperts cost 0.00046539306640625 seconds
DEBUG 01-06 08:44:53.919950.919950 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.919661.919661 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:44:53.919609.919609 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.919703.919703 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fe03bba9-2bd6-421f-a6c0-41df74bbaf35
INFO 01-06 08:44:53.922669.922669 client.py:127] Model loaded
DEBUG 01-06 08:44:53.922042.922042 cuda_h.py:19] end wait_experts cost 0.00362396240234375 seconds
DEBUG 01-06 08:44:53.922991.922991 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:53.923892.923892 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:53.931830.931830 mlpmodule.py:662]  experts func einsum cost 0.06319117546081543 s
DEBUG 01-06 08:44:53.935217.935217 cuda_h.py:19] end gpu_experts cost 0.01244974136352539 seconds
DEBUG 01-06 08:44:53.935102.935102 cuda_h.py:19] end layer_moe_generate_6 cost 0.0753180980682373 seconds
DEBUG 01-06 08:44:53.935684.935684 lmp.py:221] -------------------------------- end layer 6 --------------------------------
DEBUG 01-06 08:44:53.935162.935162 lmp.py:177] -------------------------------- start layer 7 --------------------------------
DEBUG 01-06 08:44:53.935858.935858 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 08:44:53.935137.935137 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 08:44:53.935735.935735 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:53.935577.935577 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 5.626678466796875e-05 seconds
DEBUG 01-06 08:44:53.935174.935174 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:53.936282.936282 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:53.936470.936470 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.936968.936968 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.936278.936278 cuda_h.py:19] end allocate_cuda_memory cost 0.00029921531677246094 seconds
DEBUG 01-06 08:44:53.936724.936724 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.936056.936056 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.936164.936164 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.936390.936390 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20f0f7ba-654e-4d3a-bcec-40356fe8db51
DEBUG 01-06 08:44:53.936744.936744 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:53.937997.937997 cuda_h.py:10] start self_attn
INFO 01-06 08:44:53.937329.937329 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20f0f7ba-654e-4d3a-bcec-40356fe8db51
DEBUG 01-06 08:44:53.937611.937611 cuda_h.py:19] end load_into_gpu_async cost 0.0013165473937988281 seconds
DEBUG 01-06 08:44:53.937380.937380 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.938728.938728 cuda_h.py:19] end restore_tensors2 cost 7.82012939453125e-05 seconds
DEBUG 01-06 08:44:53.938783.938783 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019872188568115234 seconds
INFO 01-06 08:44:53.938650.938650 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20f0f7ba-654e-4d3a-bcec-40356fe8db51
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:53.941223.941223 cuda_h.py:19] end self_attn cost 0.004103422164916992 seconds
DEBUG 01-06 08:44:53.941781.941781 cuda_h.py:19] end iln_self_attn_paln cost 0.0056493282318115234 seconds
DEBUG 01-06 08:44:53.941101.941101 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-06 08:44:53.941056.941056 cuda_h.py:10] start gate
DEBUG 01-06 08:44:53.942065.942065 cuda_h.py:19] end gate cost 0.0006384849548339844 seconds
DEBUG 01-06 08:44:53.942272.942272 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:53.942388.942388 lmp.py:369] 
DEBUG 01-06 08:44:53.942388.942388 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:53.942906.942906 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:53.942078.942078 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:53.942404.942404 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:53.942093.942093 lmp.py:373] 
DEBUG 01-06 08:44:53.942093.942093 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:53.942783.942783 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:53.942955.942955 lmp.py:380]   Expert 55 |      3 | CPU
DEBUG 01-06 08:44:53.942883.942883 lmp.py:380]   Expert 40 |      5 | CPU
DEBUG 01-06 08:44:53.942387.942387 lmp.py:380]   Expert 31 |      8 | CPU
DEBUG 01-06 08:44:53.942030.942030 lmp.py:380]   Expert  3 |     14 | CPU
DEBUG 01-06 08:44:53.942958.942958 lmp.py:380]   Expert 49 |     18 | CPU
DEBUG 01-06 08:44:53.942409.942409 lmp.py:380]   Expert 25 |     19 | CPU
DEBUG 01-06 08:44:53.943336.943336 lmp.py:380]   Expert 20 |     24 | CPU
DEBUG 01-06 08:44:53.943787.943787 lmp.py:380]   Expert 26 |     24 | CPU
DEBUG 01-06 08:44:53.943761.943761 lmp.py:380]   Expert 34 |     24 | CPU
DEBUG 01-06 08:44:53.943259.943259 lmp.py:380]   Expert 41 |     26 | CPU
DEBUG 01-06 08:44:53.943994.943994 lmp.py:380]   Expert 48 |     28 | CPU
DEBUG 01-06 08:44:53.943730.943730 lmp.py:380]   Expert 45 |     29 | CPU
DEBUG 01-06 08:44:53.943704.943704 lmp.py:380]   Expert  1 |     30 | CPU
DEBUG 01-06 08:44:53.943347.943347 lmp.py:380]   Expert 58 |     32 | CPU
DEBUG 01-06 08:44:53.943275.943275 lmp.py:380]   Expert 16 |     37 | CPU
DEBUG 01-06 08:44:53.943487.943487 lmp.py:380]   Expert 63 |     40 | CPU
DEBUG 01-06 08:44:53.943938.943938 lmp.py:380]   Expert 15 |     41 | CPU
DEBUG 01-06 08:44:53.943150.943150 lmp.py:380]   Expert 28 |     47 | CPU
DEBUG 01-06 08:44:53.943032.943032 lmp.py:380]   Expert 29 |     49 | CPU
DEBUG 01-06 08:44:53.943198.943198 lmp.py:380]   Expert 42 |     50 | CPU
DEBUG 01-06 08:44:53.943841.943841 lmp.py:380]   Expert  5 |     51 | CPU
DEBUG 01-06 08:44:53.943245.943245 lmp.py:380]   Expert  6 |     51 | CPU
DEBUG 01-06 08:44:53.943173.943173 lmp.py:380]   Expert 44 |     51 | CPU
DEBUG 01-06 08:44:53.943863.943863 lmp.py:380]   Expert 32 |     53 | CPU
DEBUG 01-06 08:44:53.943075.943075 lmp.py:380]   Expert 57 |     54 | CPU
DEBUG 01-06 08:44:53.943764.943764 lmp.py:380]   Expert  8 |     56 | CPU
DEBUG 01-06 08:44:53.943454.943454 lmp.py:380]   Expert 56 |     66 | CPU
DEBUG 01-06 08:44:53.943904.943904 lmp.py:380]   Expert 60 |     75 | CPU
DEBUG 01-06 08:44:53.943594.943594 lmp.py:380]   Expert 18 |     76 | CPU
DEBUG 01-06 08:44:53.943283.943283 lmp.py:380]   Expert 37 |     77 | CPU
DEBUG 01-06 08:44:53.943972.943972 lmp.py:380]   Expert 59 |     78 | CPU
DEBUG 01-06 08:44:53.943854.943854 lmp.py:380]   Expert 39 |     79 | CPU
DEBUG 01-06 08:44:53.943258.943258 lmp.py:380]   Expert 33 |     83 | GPU
DEBUG 01-06 08:44:53.943424.943424 lmp.py:380]   Expert 30 |     96 | GPU
DEBUG 01-06 08:44:53.943591.943591 lmp.py:380]   Expert  4 |    110 | GPU
DEBUG 01-06 08:44:53.943234.943234 lmp.py:380]   Expert 43 |    118 | GPU
DEBUG 01-06 08:44:53.943161.943161 lmp.py:380]   Expert  7 |    123 | GPU
DEBUG 01-06 08:44:53.943327.943327 lmp.py:380]   Expert 14 |    133 | GPU
DEBUG 01-06 08:44:53.943017.943017 lmp.py:380]   Expert 13 |    143 | GPU
DEBUG 01-06 08:44:53.943706.943706 lmp.py:380]   Expert 19 |    145 | GPU
DEBUG 01-06 08:44:53.943634.943634 lmp.py:380]   Expert 53 |    154 | GPU
DEBUG 01-06 08:44:53.943608.943608 lmp.py:380]   Expert 50 |    180 | GPU
DEBUG 01-06 08:44:53.943297.943297 lmp.py:380]   Expert  0 |    183 | GPU
DEBUG 01-06 08:44:53.943986.943986 lmp.py:380]   Expert 21 |    194 | GPU
DEBUG 01-06 08:44:53.943914.943914 lmp.py:380]   Expert 52 |    202 | GPU
DEBUG 01-06 08:44:53.943319.943319 lmp.py:380]   Expert 51 |    204 | GPU
DEBUG 01-06 08:44:53.943723.943723 lmp.py:380]   Expert 24 |    221 | GPU
DEBUG 01-06 08:44:53.943889.943889 lmp.py:380]   Expert 35 |    223 | GPU
DEBUG 01-06 08:44:53.943294.943294 lmp.py:380]   Expert 36 |    223 | GPU
DEBUG 01-06 08:44:53.943745.943745 lmp.py:380]   Expert 10 |    233 | GPU
DEBUG 01-06 08:44:53.943434.943434 lmp.py:380]   Expert 27 |    236 | GPU
DEBUG 01-06 08:44:53.943123.943123 lmp.py:380]   Expert 11 |    251 | GPU
DEBUG 01-06 08:44:53.943574.943574 lmp.py:380]   Expert 38 |    260 | GPU
DEBUG 01-06 08:44:53.943787.943787 lmp.py:380]   Expert 54 |    260 | GPU
DEBUG 01-06 08:44:53.943714.943714 lmp.py:380]   Expert  2 |    360 | GPU
DEBUG 01-06 08:44:53.943404.943404 lmp.py:380]   Expert 62 |    365 | GPU
DEBUG 01-06 08:44:53.943331.943331 lmp.py:380]   Expert 61 |    396 | GPU
DEBUG 01-06 08:44:53.943021.943021 lmp.py:380]   Expert 46 |    473 | GPU
DEBUG 01-06 08:44:53.943948.943948 lmp.py:380]   Expert 47 |    473 | GPU
DEBUG 01-06 08:44:53.943876.943876 lmp.py:380]   Expert 17 |    601 | GPU
DEBUG 01-06 08:44:53.943804.943804 lmp.py:380]   Expert 22 |    729 | GPU
DEBUG 01-06 08:44:53.943208.943208 lmp.py:380]   Expert  9 |    810 | GPU
DEBUG 01-06 08:44:53.943328.943328 lmp.py:380]   Expert 12 |    940 | GPU
DEBUG 01-06 08:44:53.943494.943494 lmp.py:380]   Expert 23 |   1851 | GPU
DEBUG 01-06 08:44:53.943899.943899 lmp.py:381] 
DEBUG 01-06 08:44:53.943899.943899 lmp.py:381]   CPU total tokens: 1315 (10.7%)
DEBUG 01-06 08:44:53.944304.944304 lmp.py:382]   GPU total tokens: 10973 (89.3%)
DEBUG 01-06 08:44:53.944238.944238 cuda_h.py:19] end experts_map_get cost 0.0015273094177246094 seconds
DEBUG 01-06 08:44:53.944119.944119 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:53.944326.944326 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:53.944602.944602 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:53.944081.944081 cuda_h.py:19] end allocate_cuda_memory cost 0.00020051002502441406 seconds
DEBUG 01-06 08:44:53.944301.944301 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:53.944435.944435 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:53.944906.944906 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:53.944556.944556 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3c9e2b1-7e2a-4633-98a2-1d4a17c72c4d
DEBUG 01-06 08:44:53.944191.944191 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:53.944726.944726 client.py:127] Model loaded
DEBUG 01-06 08:44:53.945483.945483 cuda_h.py:19] end sllm_worker_task cost 0.008893728256225586 seconds
INFO 01-06 08:44:53.945578.945578 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3c9e2b1-7e2a-4633-98a2-1d4a17c72c4d
DEBUG 01-06 08:44:53.945944.945944 cuda_h.py:19] end load_into_gpu_async cost 0.0011806488037109375 seconds
DEBUG 01-06 08:44:53.945455.945455 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:53.946662.946662 cuda_h.py:19] end restore_tensors2 cost 0.0004067420959472656 seconds
DEBUG 01-06 08:44:53.946975.946975 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002141237258911133 seconds
DEBUG 01-06 08:44:53.948227.948227 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004755973815917969 seconds
DEBUG 01-06 08:44:53.948639.948639 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:53.948648.948648 lmp.py:427] 
DEBUG 01-06 08:44:53.948648.948648 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:53.949968.949968 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-06 08:44:53.949002.949002 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:53.955367.955367 mlpmodule.py:704] group tensors cost 0.005814552307128906 s
DEBUG 01-06 08:44:53.957030.957030 mlpmodule.py:742] pad cost 0.0019145011901855469 s
DEBUG 01-06 08:44:53.957874.957874 mlpmodule.py:748] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-06 08:44:53.957340.957340 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 08:44:53.968447.968447 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:53.968300.968300 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:53.968244.968244 mlpmodule.py:773] group_w3 first element: 0.01263427734375
WARNING 01-06 08:44:53.968041.968041 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:53.987917.987917 mlpmodule.py:793] group einsum cost 0.029420852661132812 s
DEBUG 01-06 08:44:53.988626.988626 mlpmodule.py:801] cpy2cputensor cost 0.0004222393035888672 s
DEBUG 01-06 08:44:53.992191.992191 cuda_h.py:19] end wait_cetm_experts cost 0.04377412796020508 seconds
DEBUG 01-06 08:44:53.992128.992128 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:53.993920.993920 cuda_h.py:19] end gpu_sexperts cost 0.00046944618225097656 seconds
DEBUG 01-06 08:44:53.993002.993002 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:53.993580.993580 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7894973754882812e-05 seconds
DEBUG 01-06 08:44:53.993482.993482 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:53.993146.993146 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3c9e2b1-7e2a-4633-98a2-1d4a17c72c4d
INFO 01-06 08:44:54.004190.004190 client.py:127] Model loaded
DEBUG 01-06 08:44:54.004894.004894 cuda_h.py:19] end wait_experts cost 0.01087498664855957 seconds
DEBUG 01-06 08:44:54.004358.004358 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.004776.004776 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.005780.005780 mlpmodule.py:662]  experts func einsum cost 0.05592775344848633 s
DEBUG 01-06 08:44:54.016618.016618 cuda_h.py:19] end gpu_experts cost 0.011674642562866211 seconds
DEBUG 01-06 08:44:54.016138.016138 cuda_h.py:19] end layer_moe_generate_7 cost 0.07463622093200684 seconds
DEBUG 01-06 08:44:54.016979.016979 lmp.py:221] -------------------------------- end layer 7 --------------------------------
DEBUG 01-06 08:44:54.016894.016894 lmp.py:177] -------------------------------- start layer 8 --------------------------------
DEBUG 01-06 08:44:54.016067.016067 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 08:44:54.016823.016823 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 08:44:54.016275.016275 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.6702880859375e-05 seconds
DEBUG 01-06 08:44:54.016217.016217 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.7697296142578125e-05 seconds
DEBUG 01-06 08:44:54.016482.016482 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.016776.016776 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.016110.016110 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.016654.016654 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.017979.017979 cuda_h.py:19] end allocate_cuda_memory cost 0.00017023086547851562 seconds
DEBUG 01-06 08:44:54.017035.017035 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.017890.017890 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.017852.017852 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.017886.017886 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36393c95-a079-4390-b145-d1bbc5f55d59
DEBUG 01-06 08:44:54.017756.017756 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.017625.017625 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.018650.018650 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36393c95-a079-4390-b145-d1bbc5f55d59
DEBUG 01-06 08:44:54.018162.018162 cuda_h.py:19] end load_into_gpu_async cost 0.0009963512420654297 seconds
DEBUG 01-06 08:44:54.018064.018064 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.018598.018598 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-06 08:44:54.018744.018744 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001523733139038086 seconds
INFO 01-06 08:44:54.019068.019068 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36393c95-a079-4390-b145-d1bbc5f55d59
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.021535.021535 cuda_h.py:19] end self_attn cost 0.004149675369262695 seconds
DEBUG 01-06 08:44:54.022796.022796 cuda_h.py:19] end iln_self_attn_paln cost 0.005398273468017578 seconds
DEBUG 01-06 08:44:54.022116.022116 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-06 08:44:54.022025.022025 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.022451.022451 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-06 08:44:54.023420.023420 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.023079.023079 lmp.py:369] 
DEBUG 01-06 08:44:54.023079.023079 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.023928.023928 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.023054.023054 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.023320.023320 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.023678.023678 lmp.py:373] 
DEBUG 01-06 08:44:54.023678.023678 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.023798.023798 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.023209.023209 lmp.py:380]   Expert 14 |      2 | CPU
DEBUG 01-06 08:44:54.023091.023091 lmp.py:380]   Expert 12 |      3 | CPU
DEBUG 01-06 08:44:54.023541.023541 lmp.py:380]   Expert 27 |      3 | CPU
DEBUG 01-06 08:44:54.023231.023231 lmp.py:380]   Expert 32 |     10 | CPU
DEBUG 01-06 08:44:54.023682.023682 lmp.py:380]   Expert  7 |     11 | CPU
DEBUG 01-06 08:44:54.023133.023133 lmp.py:380]   Expert 50 |     16 | CPU
DEBUG 01-06 08:44:54.023868.023868 lmp.py:380]   Expert 34 |     19 | CPU
DEBUG 01-06 08:44:54.023081.023081 lmp.py:380]   Expert 26 |     21 | CPU
DEBUG 01-06 08:44:54.023200.023200 lmp.py:380]   Expert 30 |     27 | CPU
DEBUG 01-06 08:44:54.023320.023320 lmp.py:380]   Expert 33 |     27 | CPU
DEBUG 01-06 08:44:54.023725.023725 lmp.py:380]   Expert 23 |     29 | CPU
DEBUG 01-06 08:44:54.023606.023606 lmp.py:380]   Expert 38 |     43 | CPU
DEBUG 01-06 08:44:54.023249.023249 lmp.py:380]   Expert 22 |     52 | CPU
DEBUG 01-06 08:44:54.023415.023415 lmp.py:380]   Expert 16 |     54 | CPU
DEBUG 01-06 08:44:54.023105.023105 lmp.py:380]   Expert 58 |     55 | CPU
DEBUG 01-06 08:44:54.023555.023555 lmp.py:380]   Expert 54 |     56 | CPU
DEBUG 01-06 08:44:54.023245.023245 lmp.py:380]   Expert 18 |     57 | CPU
DEBUG 01-06 08:44:54.023934.023934 lmp.py:380]   Expert 53 |     58 | CPU
DEBUG 01-06 08:44:54.023147.023147 lmp.py:380]   Expert  1 |     68 | CPU
DEBUG 01-06 08:44:54.023836.023836 lmp.py:380]   Expert 36 |     74 | CPU
DEBUG 01-06 08:44:54.023287.023287 lmp.py:380]   Expert 44 |     76 | CPU
DEBUG 01-06 08:44:54.023499.023499 lmp.py:380]   Expert 25 |     83 | CPU
DEBUG 01-06 08:44:54.023427.023427 lmp.py:380]   Expert 24 |     86 | CPU
DEBUG 01-06 08:44:54.023831.023831 lmp.py:380]   Expert 57 |     87 | CPU
DEBUG 01-06 08:44:54.023951.023951 lmp.py:380]   Expert 42 |     94 | CPU
DEBUG 01-06 08:44:54.023932.023932 lmp.py:380]   Expert  9 |     95 | CPU
DEBUG 01-06 08:44:54.023383.023383 lmp.py:380]   Expert 29 |    106 | CPU
DEBUG 01-06 08:44:54.023357.023357 lmp.py:380]   Expert 55 |    119 | CPU
DEBUG 01-06 08:44:54.023854.023854 lmp.py:380]   Expert 37 |    120 | CPU
DEBUG 01-06 08:44:54.023590.023590 lmp.py:380]   Expert 39 |    128 | CPU
DEBUG 01-06 08:44:54.023087.023087 lmp.py:380]   Expert 19 |    139 | CPU
DEBUG 01-06 08:44:54.023823.023823 lmp.py:380]   Expert 60 |    141 | CPU
DEBUG 01-06 08:44:54.024081.024081 lmp.py:380]   Expert  8 |    145 | GPU
DEBUG 01-06 08:44:54.024817.024817 lmp.py:380]   Expert 46 |    149 | GPU
DEBUG 01-06 08:44:54.024076.024076 lmp.py:380]   Expert 41 |    158 | GPU
DEBUG 01-06 08:44:54.024050.024050 lmp.py:380]   Expert 31 |    160 | GPU
DEBUG 01-06 08:44:54.024978.024978 lmp.py:380]   Expert 56 |    167 | GPU
DEBUG 01-06 08:44:54.024190.024190 lmp.py:380]   Expert 40 |    171 | GPU
DEBUG 01-06 08:44:54.024118.024118 lmp.py:380]   Expert  2 |    172 | GPU
DEBUG 01-06 08:44:54.024807.024807 lmp.py:380]   Expert 51 |    177 | GPU
DEBUG 01-06 08:44:54.024781.024781 lmp.py:380]   Expert  3 |    189 | GPU
DEBUG 01-06 08:44:54.024278.024278 lmp.py:380]   Expert 21 |    198 | GPU
DEBUG 01-06 08:44:54.024014.024014 lmp.py:380]   Expert 15 |    202 | GPU
DEBUG 01-06 08:44:54.024511.024511 lmp.py:380]   Expert 49 |    238 | GPU
DEBUG 01-06 08:44:54.024247.024247 lmp.py:380]   Expert 61 |    238 | GPU
DEBUG 01-06 08:44:54.024744.024744 lmp.py:380]   Expert 13 |    239 | GPU
DEBUG 01-06 08:44:54.024480.024480 lmp.py:380]   Expert 20 |    242 | GPU
DEBUG 01-06 08:44:54.024215.024215 lmp.py:380]   Expert 28 |    245 | GPU
DEBUG 01-06 08:44:54.024189.024189 lmp.py:380]   Expert 35 |    249 | GPU
DEBUG 01-06 08:44:54.024687.024687 lmp.py:380]   Expert  0 |    283 | GPU
DEBUG 01-06 08:44:54.024661.024661 lmp.py:380]   Expert 11 |    316 | GPU
DEBUG 01-06 08:44:54.024396.024396 lmp.py:380]   Expert 10 |    329 | GPU
DEBUG 01-06 08:44:54.024609.024609 lmp.py:380]   Expert 45 |    366 | GPU
DEBUG 01-06 08:44:54.024060.024060 lmp.py:380]   Expert 52 |    367 | GPU
DEBUG 01-06 08:44:54.024510.024510 lmp.py:380]   Expert 47 |    391 | GPU
DEBUG 01-06 08:44:54.024961.024961 lmp.py:380]   Expert 17 |    408 | GPU
DEBUG 01-06 08:44:54.024088.024088 lmp.py:380]   Expert  4 |    434 | GPU
DEBUG 01-06 08:44:54.024274.024274 lmp.py:380]   Expert 48 |    437 | GPU
DEBUG 01-06 08:44:54.024725.024725 lmp.py:380]   Expert 43 |    507 | GPU
DEBUG 01-06 08:44:54.024176.024176 lmp.py:380]   Expert  6 |    508 | GPU
DEBUG 01-06 08:44:54.024150.024150 lmp.py:380]   Expert 59 |    591 | GPU
DEBUG 01-06 08:44:54.024601.024601 lmp.py:380]   Expert 63 |    625 | GPU
DEBUG 01-06 08:44:54.024575.024575 lmp.py:380]   Expert 62 |    641 | GPU
DEBUG 01-06 08:44:54.024026.024026 lmp.py:380]   Expert  5 |    787 | GPU
DEBUG 01-06 08:44:54.024192.024192 lmp.py:381] 
DEBUG 01-06 08:44:54.024192.024192 lmp.py:381]   CPU total tokens: 1959 (15.9%)
DEBUG 01-06 08:44:54.024789.024789 lmp.py:382]   GPU total tokens: 10329 (84.1%)
DEBUG 01-06 08:44:54.024439.024439 cuda_h.py:19] end experts_map_get cost 0.0015306472778320312 seconds
DEBUG 01-06 08:44:54.024558.024558 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.024527.024527 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.024287.024287 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.025299.025299 cuda_h.py:19] end allocate_cuda_memory cost 0.00032782554626464844 seconds
DEBUG 01-06 08:44:54.025394.025394 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.025342.025342 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.025720.025720 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.025085.025085 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fef4dd01-6c3d-4838-81c7-2c6b85f24ca9
DEBUG 01-06 08:44:54.025436.025436 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.025964.025964 client.py:127] Model loaded
DEBUG 01-06 08:44:54.025152.025152 cuda_h.py:19] end sllm_worker_task cost 0.008774757385253906 seconds
INFO 01-06 08:44:54.026558.026558 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fef4dd01-6c3d-4838-81c7-2c6b85f24ca9
DEBUG 01-06 08:44:54.026593.026593 cuda_h.py:19] end load_into_gpu_async cost 0.0011649131774902344 seconds
DEBUG 01-06 08:44:54.026918.026918 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.026250.026250 cuda_h.py:19] end restore_tensors2 cost 0.00039267539978027344 seconds
DEBUG 01-06 08:44:54.026140.026140 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002251148223876953 seconds
DEBUG 01-06 08:44:54.029233.029233 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004893302917480469 seconds
DEBUG 01-06 08:44:54.029699.029699 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.029754.029754 lmp.py:427] 
DEBUG 01-06 08:44:54.029754.029754 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.029306.029306 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-06 08:44:54.029671.029671 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.041772.041772 mlpmodule.py:704] group tensors cost 0.011573314666748047 s
DEBUG 01-06 08:44:54.043794.043794 mlpmodule.py:742] pad cost 0.0015175342559814453 s
DEBUG 01-06 08:44:54.043446.043446 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-06 08:44:54.043058.043058 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 08:44:54.055167.055167 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:54.056604.056604 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.056601.056601 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-06 08:44:54.056963.056963 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.075497.075497 mlpmodule.py:793] group einsum cost 0.03184676170349121 s
DEBUG 01-06 08:44:54.076895.076895 mlpmodule.py:801] cpy2cputensor cost 0.0005857944488525391 s
DEBUG 01-06 08:44:54.081865.081865 cuda_h.py:19] end wait_cetm_experts cost 0.051644325256347656 seconds
DEBUG 01-06 08:44:54.081948.081948 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.082561.082561 cuda_h.py:19] end gpu_sexperts cost 0.00047898292541503906 seconds
DEBUG 01-06 08:44:54.082988.082988 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.082752.082752 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:44:54.082839.082839 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.082787.082787 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fef4dd01-6c3d-4838-81c7-2c6b85f24ca9
INFO 01-06 08:44:54.086111.086111 client.py:127] Model loaded
DEBUG 01-06 08:44:54.086815.086815 cuda_h.py:19] end wait_experts cost 0.003814220428466797 seconds
DEBUG 01-06 08:44:54.086664.086664 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.086704.086704 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.093448.093448 mlpmodule.py:662]  experts func einsum cost 0.06381058692932129 s
DEBUG 01-06 08:44:54.097708.097708 cuda_h.py:19] end gpu_experts cost 0.011582374572753906 seconds
DEBUG 01-06 08:44:54.097547.097547 cuda_h.py:19] end layer_moe_generate_8 cost 0.07552313804626465 seconds
DEBUG 01-06 08:44:54.098958.098958 lmp.py:221] -------------------------------- end layer 8 --------------------------------
DEBUG 01-06 08:44:54.098688.098688 lmp.py:177] -------------------------------- start layer 9 --------------------------------
DEBUG 01-06 08:44:54.098722.098722 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 08:44:54.098862.098862 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 08:44:54.098228.098228 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:54.098077.098077 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.318092346191406e-05 seconds
DEBUG 01-06 08:44:54.098773.098773 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.098203.098203 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.098119.098119 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.098571.098571 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.098138.098138 cuda_h.py:19] end allocate_cuda_memory cost 0.000278472900390625 seconds
DEBUG 01-06 08:44:54.098684.098684 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.098255.098255 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.099647.099647 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.099634.099634 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b8edecdf-d707-4a9e-adb4-c8c0e682c47a
DEBUG 01-06 08:44:54.099558.099558 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.099498.099498 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.100169.100169 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b8edecdf-d707-4a9e-adb4-c8c0e682c47a
DEBUG 01-06 08:44:54.100828.100828 cuda_h.py:19] end load_into_gpu_async cost 0.0012960433959960938 seconds
DEBUG 01-06 08:44:54.100597.100597 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.100105.100105 cuda_h.py:19] end restore_tensors2 cost 8.988380432128906e-05 seconds
DEBUG 01-06 08:44:54.100736.100736 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019638538360595703 seconds
INFO 01-06 08:44:54.101064.101064 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b8edecdf-d707-4a9e-adb4-c8c0e682c47a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.103135.103135 cuda_h.py:19] end self_attn cost 0.004125833511352539 seconds
DEBUG 01-06 08:44:54.104482.104482 cuda_h.py:19] end iln_self_attn_paln cost 0.005707979202270508 seconds
DEBUG 01-06 08:44:54.104040.104040 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-06 08:44:54.104903.104903 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.104402.104402 cuda_h.py:19] end gate cost 0.00064849853515625 seconds
DEBUG 01-06 08:44:54.104609.104609 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.105963.105963 lmp.py:369] 
DEBUG 01-06 08:44:54.105963.105963 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.105766.105766 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.105131.105131 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.105158.105158 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.105039.105039 lmp.py:373] 
DEBUG 01-06 08:44:54.105039.105039 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.105921.105921 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.105047.105047 lmp.py:380]   Expert  7 |      7 | CPU
DEBUG 01-06 08:44:54.105929.105929 lmp.py:380]   Expert 13 |     12 | CPU
DEBUG 01-06 08:44:54.105856.105856 lmp.py:380]   Expert 35 |     20 | CPU
DEBUG 01-06 08:44:54.105069.105069 lmp.py:380]   Expert  6 |     27 | CPU
DEBUG 01-06 08:44:54.105520.105520 lmp.py:380]   Expert 19 |     27 | CPU
DEBUG 01-06 08:44:54.105971.105971 lmp.py:380]   Expert 42 |     27 | CPU
DEBUG 01-06 08:44:54.105945.105945 lmp.py:380]   Expert 14 |     28 | CPU
DEBUG 01-06 08:44:54.105157.105157 lmp.py:380]   Expert 39 |     28 | CPU
DEBUG 01-06 08:44:54.105370.105370 lmp.py:380]   Expert 49 |     28 | CPU
DEBUG 01-06 08:44:54.105105.105105 lmp.py:380]   Expert 20 |     31 | CPU
DEBUG 01-06 08:44:54.105225.105225 lmp.py:380]   Expert 38 |     35 | CPU
DEBUG 01-06 08:44:54.105153.105153 lmp.py:380]   Expert 25 |     37 | CPU
DEBUG 01-06 08:44:54.105988.105988 lmp.py:380]   Expert 40 |     38 | CPU
DEBUG 01-06 08:44:54.105154.105154 lmp.py:380]   Expert  2 |     39 | CPU
DEBUG 01-06 08:44:54.105320.105320 lmp.py:380]   Expert 54 |     46 | CPU
DEBUG 01-06 08:44:54.105009.105009 lmp.py:380]   Expert 11 |     56 | CPU
DEBUG 01-06 08:44:54.105176.105176 lmp.py:380]   Expert 26 |     61 | CPU
DEBUG 01-06 08:44:54.105342.105342 lmp.py:380]   Expert 48 |     62 | CPU
DEBUG 01-06 08:44:54.105508.105508 lmp.py:380]   Expert  5 |     63 | CPU
DEBUG 01-06 08:44:54.105674.105674 lmp.py:380]   Expert 60 |     71 | CPU
DEBUG 01-06 08:44:54.105854.105854 lmp.py:380]   Expert 56 |     73 | CPU
DEBUG 01-06 08:44:54.105305.105305 lmp.py:380]   Expert 33 |     75 | CPU
DEBUG 01-06 08:44:54.105471.105471 lmp.py:380]   Expert 17 |     80 | CPU
DEBUG 01-06 08:44:54.105160.105160 lmp.py:380]   Expert 28 |     81 | CPU
DEBUG 01-06 08:44:54.105373.105373 lmp.py:380]   Expert 16 |     88 | CPU
DEBUG 01-06 08:44:54.105585.105585 lmp.py:380]   Expert 27 |     97 | CPU
DEBUG 01-06 08:44:54.105036.105036 lmp.py:380]   Expert 46 |    101 | CPU
DEBUG 01-06 08:44:54.105248.105248 lmp.py:380]   Expert 47 |    105 | CPU
DEBUG 01-06 08:44:54.105699.105699 lmp.py:380]   Expert 24 |    107 | CPU
DEBUG 01-06 08:44:54.105389.105389 lmp.py:380]   Expert 62 |    107 | CPU
DEBUG 01-06 08:44:54.105363.105363 lmp.py:380]   Expert 50 |    118 | CPU
DEBUG 01-06 08:44:54.105813.105813 lmp.py:380]   Expert 41 |    119 | CPU
DEBUG 01-06 08:44:54.105026.105026 lmp.py:380]   Expert 12 |    121 | GPU
DEBUG 01-06 08:44:54.105477.105477 lmp.py:380]   Expert 52 |    122 | GPU
DEBUG 01-06 08:44:54.105643.105643 lmp.py:380]   Expert 22 |    124 | GPU
DEBUG 01-06 08:44:54.105048.105048 lmp.py:380]   Expert 57 |    137 | GPU
DEBUG 01-06 08:44:54.105498.105498 lmp.py:380]   Expert 45 |    139 | GPU
DEBUG 01-06 08:44:54.105949.105949 lmp.py:380]   Expert 18 |    145 | GPU
DEBUG 01-06 08:44:54.105162.105162 lmp.py:380]   Expert 10 |    148 | GPU
DEBUG 01-06 08:44:54.105374.105374 lmp.py:380]   Expert 59 |    151 | GPU
DEBUG 01-06 08:44:54.105302.105302 lmp.py:380]   Expert 51 |    152 | GPU
DEBUG 01-06 08:44:54.105514.105514 lmp.py:380]   Expert 58 |    189 | GPU
DEBUG 01-06 08:44:54.105965.105965 lmp.py:380]   Expert  8 |    205 | GPU
DEBUG 01-06 08:44:54.105178.105178 lmp.py:380]   Expert 32 |    205 | GPU
DEBUG 01-06 08:44:54.106629.106629 lmp.py:380]   Expert  4 |    206 | GPU
DEBUG 01-06 08:44:54.106795.106795 lmp.py:380]   Expert 31 |    237 | GPU
DEBUG 01-06 08:44:54.106961.106961 lmp.py:380]   Expert 29 |    242 | GPU
DEBUG 01-06 08:44:54.106365.106365 lmp.py:380]   Expert 34 |    277 | GPU
DEBUG 01-06 08:44:54.106055.106055 lmp.py:380]   Expert 30 |    298 | GPU
DEBUG 01-06 08:44:54.106267.106267 lmp.py:380]   Expert 53 |    304 | GPU
DEBUG 01-06 08:44:54.106718.106718 lmp.py:380]   Expert 15 |    310 | GPU
DEBUG 01-06 08:44:54.106169.106169 lmp.py:380]   Expert 55 |    315 | GPU
DEBUG 01-06 08:44:54.106858.106858 lmp.py:380]   Expert 36 |    329 | GPU
DEBUG 01-06 08:44:54.106548.106548 lmp.py:380]   Expert 37 |    338 | GPU
DEBUG 01-06 08:44:54.106760.106760 lmp.py:380]   Expert  3 |    339 | GPU
DEBUG 01-06 08:44:54.106926.106926 lmp.py:380]   Expert  1 |    451 | GPU
DEBUG 01-06 08:44:54.106092.106092 lmp.py:380]   Expert 23 |    484 | GPU
DEBUG 01-06 08:44:54.106497.106497 lmp.py:380]   Expert 63 |    513 | GPU
DEBUG 01-06 08:44:54.106663.106663 lmp.py:380]   Expert  9 |    515 | GPU
DEBUG 01-06 08:44:54.106352.106352 lmp.py:380]   Expert 43 |    575 | GPU
DEBUG 01-06 08:44:54.106803.106803 lmp.py:380]   Expert 44 |    663 | GPU
DEBUG 01-06 08:44:54.106254.106254 lmp.py:380]   Expert  0 |    669 | GPU
DEBUG 01-06 08:44:54.106705.106705 lmp.py:380]   Expert 21 |    697 | GPU
DEBUG 01-06 08:44:54.106156.106156 lmp.py:380]   Expert 61 |    794 | GPU
DEBUG 01-06 08:44:54.106322.106322 lmp.py:381] 
DEBUG 01-06 08:44:54.106322.106322 lmp.py:381]   CPU total tokens: 1894 (15.4%)
DEBUG 01-06 08:44:54.106965.106965 lmp.py:382]   GPU total tokens: 10394 (84.6%)
DEBUG 01-06 08:44:54.106661.106661 cuda_h.py:19] end experts_map_get cost 0.0015201568603515625 seconds
DEBUG 01-06 08:44:54.106781.106781 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.106749.106749 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.106032.106032 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.106259.106259 cuda_h.py:19] end allocate_cuda_memory cost 0.00020384788513183594 seconds
DEBUG 01-06 08:44:54.106487.106487 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.106289.106289 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.106575.106575 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.107848.107848 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1453d646-8c7b-4db5-81bd-ce1bf8ad682b
DEBUG 01-06 08:44:54.107914.107914 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.107073.107073 client.py:127] Model loaded
DEBUG 01-06 08:44:54.107275.107275 cuda_h.py:19] end sllm_worker_task cost 0.008997678756713867 seconds
INFO 01-06 08:44:54.108411.108411 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1453d646-8c7b-4db5-81bd-ce1bf8ad682b
DEBUG 01-06 08:44:54.108671.108671 cuda_h.py:19] end load_into_gpu_async cost 0.0011224746704101562 seconds
DEBUG 01-06 08:44:54.108944.108944 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.108389.108389 cuda_h.py:19] end restore_tensors2 cost 0.0004055500030517578 seconds
DEBUG 01-06 08:44:54.108324.108324 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021207332611083984 seconds
DEBUG 01-06 08:44:54.111125.111125 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004721164703369141 seconds
DEBUG 01-06 08:44:54.111200.111200 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.111732.111732 lmp.py:427] 
DEBUG 01-06 08:44:54.111732.111732 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.111045.111045 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-06 08:44:54.111410.111410 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.117051.117051 mlpmodule.py:704] group tensors cost 0.005942344665527344 s
DEBUG 01-06 08:44:54.120713.120713 mlpmodule.py:742] pad cost 0.0018095970153808594 s
DEBUG 01-06 08:44:54.120842.120842 mlpmodule.py:748] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-06 08:44:54.120262.120262 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-06 08:44:54.129270.129270 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:54.130514.130514 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.130273.130273 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-06 08:44:54.130158.130158 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.148093.148093 mlpmodule.py:793] group einsum cost 0.02792215347290039 s
DEBUG 01-06 08:44:54.148146.148146 mlpmodule.py:801] cpy2cputensor cost 0.0005707740783691406 s
DEBUG 01-06 08:44:54.153360.153360 cuda_h.py:19] end wait_cetm_experts cost 0.042368412017822266 seconds
DEBUG 01-06 08:44:54.153635.153635 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.154758.154758 cuda_h.py:19] end gpu_sexperts cost 0.00046825408935546875 seconds
DEBUG 01-06 08:44:54.154409.154409 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.154928.154928 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-06 08:44:54.154823.154823 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.154248.154248 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1453d646-8c7b-4db5-81bd-ce1bf8ad682b
INFO 01-06 08:44:54.157272.157272 client.py:127] Model loaded
DEBUG 01-06 08:44:54.157022.157022 cuda_h.py:19] end wait_experts cost 0.003345966339111328 seconds
DEBUG 01-06 08:44:54.157871.157871 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.157435.157435 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.170854.170854 cuda_h.py:19] end gpu_experts cost 0.012308359146118164 seconds
DEBUG 01-06 08:44:54.170070.170070 cuda_h.py:19] end layer_moe_generate_9 cost 0.06631278991699219 seconds
DEBUG 01-06 08:44:54.170295.170295 lmp.py:221] -------------------------------- end layer 9 --------------------------------
DEBUG 01-06 08:44:54.170641.170641 lmp.py:177] -------------------------------- start layer 10 --------------------------------
DEBUG 01-06 08:44:54.170960.170960 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 08:44:54.170054.170054 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 08:44:54.170658.170658 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:54.170600.170600 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.175041198730469e-05 seconds
DEBUG 01-06 08:44:54.170104.170104 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.170092.170092 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.170201.170201 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.171800.171800 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.174144.174144 cuda_h.py:19] end allocate_cuda_memory cost 0.0029151439666748047 seconds
DEBUG 01-06 08:44:54.174597.174597 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.174374.174374 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.174529.174529 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.174808.174808 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d7f51ff-4fc8-478c-8535-6481cabc3eae
DEBUG 01-06 08:44:54.174301.174301 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.174808.174808 mlpmodule.py:662]  experts func einsum cost 0.06298041343688965 s
DEBUG 01-06 08:44:54.174234.174234 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.175063.175063 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d7f51ff-4fc8-478c-8535-6481cabc3eae
DEBUG 01-06 08:44:54.175721.175721 cuda_h.py:19] end load_into_gpu_async cost 0.0012736320495605469 seconds
DEBUG 01-06 08:44:54.175331.175331 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.175898.175898 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-06 08:44:54.175130.175130 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045490264892578125 seconds
INFO 01-06 08:44:54.176166.176166 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d7f51ff-4fc8-478c-8535-6481cabc3eae
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.178452.178452 cuda_h.py:19] end self_attn cost 0.0038809776306152344 seconds
DEBUG 01-06 08:44:54.178529.178529 cuda_h.py:19] end iln_self_attn_paln cost 0.008112907409667969 seconds
DEBUG 01-06 08:44:54.179179.179179 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-06 08:44:54.179088.179088 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.179600.179600 cuda_h.py:19] end gate cost 0.0006241798400878906 seconds
DEBUG 01-06 08:44:54.179045.179045 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.180400.180400 lmp.py:369] 
DEBUG 01-06 08:44:54.180400.180400 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.180440.180440 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:54.180567.180567 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:54.180356.180356 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:54.180045.180045 lmp.py:373] 
DEBUG 01-06 08:44:54.180045.180045 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.180450.180450 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.180815.180815 lmp.py:380]   Expert 34 |      1 | CPU
DEBUG 01-06 08:44:54.180219.180219 lmp.py:380]   Expert  6 |      7 | CPU
DEBUG 01-06 08:44:54.180624.180624 lmp.py:380]   Expert 61 |      7 | CPU
DEBUG 01-06 08:44:54.180075.180075 lmp.py:380]   Expert 37 |     10 | CPU
DEBUG 01-06 08:44:54.180764.180764 lmp.py:380]   Expert 14 |     11 | CPU
DEBUG 01-06 08:44:54.180976.180976 lmp.py:380]   Expert  3 |     12 | CPU
DEBUG 01-06 08:44:54.180951.180951 lmp.py:380]   Expert 13 |     17 | CPU
DEBUG 01-06 08:44:54.180401.180401 lmp.py:380]   Expert  7 |     19 | CPU
DEBUG 01-06 08:44:54.180329.180329 lmp.py:380]   Expert 55 |     20 | CPU
DEBUG 01-06 08:44:54.180780.180780 lmp.py:380]   Expert 32 |     22 | CPU
DEBUG 01-06 08:44:54.180754.180754 lmp.py:380]   Expert 48 |     22 | CPU
DEBUG 01-06 08:44:54.180642.180642 lmp.py:380]   Expert 47 |     23 | CPU
DEBUG 01-06 08:44:54.180332.180332 lmp.py:380]   Expert 56 |     23 | CPU
DEBUG 01-06 08:44:54.180306.180306 lmp.py:380]   Expert 11 |     25 | CPU
DEBUG 01-06 08:44:54.180518.180518 lmp.py:380]   Expert 35 |     33 | CPU
DEBUG 01-06 08:44:54.180492.180492 lmp.py:380]   Expert 21 |     38 | CPU
DEBUG 01-06 08:44:54.180466.180466 lmp.py:380]   Expert 41 |     44 | CPU
DEBUG 01-06 08:44:54.180440.180440 lmp.py:380]   Expert 15 |     45 | CPU
DEBUG 01-06 08:44:54.180176.180176 lmp.py:380]   Expert 38 |     47 | CPU
DEBUG 01-06 08:44:54.180150.180150 lmp.py:380]   Expert 20 |     55 | CPU
DEBUG 01-06 08:44:54.180601.180601 lmp.py:380]   Expert 54 |     59 | CPU
DEBUG 01-06 08:44:54.180575.180575 lmp.py:380]   Expert 52 |     64 | CPU
DEBUG 01-06 08:44:54.180264.180264 lmp.py:380]   Expert 44 |     65 | CPU
DEBUG 01-06 08:44:54.180477.180477 lmp.py:380]   Expert 39 |     71 | CPU
DEBUG 01-06 08:44:54.180451.180451 lmp.py:380]   Expert 12 |     80 | CPU
DEBUG 01-06 08:44:54.180663.180663 lmp.py:380]   Expert 46 |     84 | CPU
DEBUG 01-06 08:44:54.180651.180651 lmp.py:380]   Expert 62 |     86 | CPU
DEBUG 01-06 08:44:54.180294.180294 lmp.py:380]   Expert 45 |     90 | CPU
DEBUG 01-06 08:44:54.180983.180983 lmp.py:380]   Expert 43 |    103 | CPU
DEBUG 01-06 08:44:54.180911.180911 lmp.py:380]   Expert  9 |    108 | CPU
DEBUG 01-06 08:44:54.180838.180838 lmp.py:380]   Expert 49 |    117 | CPU
DEBUG 01-06 08:44:54.180005.180005 lmp.py:380]   Expert 59 |    132 | GPU
DEBUG 01-06 08:44:54.180171.180171 lmp.py:380]   Expert 22 |    135 | GPU
DEBUG 01-06 08:44:54.180098.180098 lmp.py:380]   Expert 25 |    139 | GPU
DEBUG 01-06 08:44:54.180741.180741 lmp.py:380]   Expert 28 |    141 | GPU
DEBUG 01-06 08:44:54.180384.180384 lmp.py:380]   Expert 50 |    142 | GPU
DEBUG 01-06 08:44:54.180074.180074 lmp.py:380]   Expert 19 |    145 | GPU
DEBUG 01-06 08:44:54.180001.180001 lmp.py:380]   Expert 36 |    145 | GPU
DEBUG 01-06 08:44:54.180929.180929 lmp.py:380]   Expert 17 |    161 | GPU
DEBUG 01-06 08:44:54.180380.180380 lmp.py:380]   Expert 18 |    166 | GPU
DEBUG 01-06 08:44:54.180308.180308 lmp.py:380]   Expert 63 |    169 | GPU
DEBUG 01-06 08:44:54.180997.180997 lmp.py:380]   Expert 53 |    185 | GPU
DEBUG 01-06 08:44:54.180686.180686 lmp.py:380]   Expert 57 |    190 | GPU
DEBUG 01-06 08:44:54.180614.180614 lmp.py:380]   Expert 26 |    217 | GPU
DEBUG 01-06 08:44:54.180542.180542 lmp.py:380]   Expert 29 |    219 | GPU
DEBUG 01-06 08:44:54.180423.180423 lmp.py:380]   Expert  2 |    228 | GPU
DEBUG 01-06 08:44:54.180543.180543 lmp.py:380]   Expert 31 |    231 | GPU
DEBUG 01-06 08:44:54.181709.181709 lmp.py:380]   Expert 60 |    233 | GPU
DEBUG 01-06 08:44:54.181498.181498 lmp.py:380]   Expert 51 |    265 | GPU
DEBUG 01-06 08:44:54.181949.181949 lmp.py:380]   Expert 30 |    320 | GPU
DEBUG 01-06 08:44:54.181115.181115 lmp.py:380]   Expert 24 |    345 | GPU
DEBUG 01-06 08:44:54.181043.181043 lmp.py:380]   Expert 10 |    346 | GPU
DEBUG 01-06 08:44:54.181970.181970 lmp.py:380]   Expert 23 |    355 | GPU
DEBUG 01-06 08:44:54.181898.181898 lmp.py:380]   Expert  5 |    378 | GPU
DEBUG 01-06 08:44:54.181303.181303 lmp.py:380]   Expert 16 |    378 | GPU
DEBUG 01-06 08:44:54.181422.181422 lmp.py:380]   Expert  4 |    464 | GPU
DEBUG 01-06 08:44:54.181588.181588 lmp.py:380]   Expert  1 |    532 | GPU
DEBUG 01-06 08:44:54.181516.181516 lmp.py:380]   Expert  8 |    537 | GPU
DEBUG 01-06 08:44:54.181682.181682 lmp.py:380]   Expert 58 |    613 | GPU
DEBUG 01-06 08:44:54.181372.181372 lmp.py:380]   Expert 42 |    663 | GPU
DEBUG 01-06 08:44:54.181061.181061 lmp.py:380]   Expert 40 |    749 | GPU
DEBUG 01-06 08:44:54.181227.181227 lmp.py:380]   Expert  0 |    911 | GPU
DEBUG 01-06 08:44:54.181916.181916 lmp.py:380]   Expert 33 |   1046 | GPU
DEBUG 01-06 08:44:54.181036.181036 lmp.py:381] 
DEBUG 01-06 08:44:54.181036.181036 lmp.py:381]   CPU total tokens: 1408 (11.5%)
DEBUG 01-06 08:44:54.181110.181110 lmp.py:382]   GPU total tokens: 10880 (88.5%)
DEBUG 01-06 08:44:54.181428.181428 cuda_h.py:19] end experts_map_get cost 0.0015170574188232422 seconds
DEBUG 01-06 08:44:54.181787.181787 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.181470.181470 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.181892.181892 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.181199.181199 cuda_h.py:19] end allocate_cuda_memory cost 0.00043773651123046875 seconds
DEBUG 01-06 08:44:54.182817.182817 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.182958.182958 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.182290.182290 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.182893.182893 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 86c39726-705e-4d8a-b062-6e419460c3e0
DEBUG 01-06 08:44:54.182675.182675 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.182395.182395 client.py:127] Model loaded
DEBUG 01-06 08:44:54.182059.182059 cuda_h.py:19] end sllm_worker_task cost 0.011589288711547852 seconds
INFO 01-06 08:44:54.183658.183658 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 86c39726-705e-4d8a-b062-6e419460c3e0
DEBUG 01-06 08:44:54.183541.183541 cuda_h.py:19] end load_into_gpu_async cost 0.0012006759643554688 seconds
DEBUG 01-06 08:44:54.183767.183767 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.183814.183814 cuda_h.py:19] end restore_tensors2 cost 0.0003936290740966797 seconds
DEBUG 01-06 08:44:54.183174.183174 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023915767669677734 seconds
DEBUG 01-06 08:44:54.186201.186201 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005017280578613281 seconds
DEBUG 01-06 08:44:54.186560.186560 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.186092.186092 lmp.py:427] 
DEBUG 01-06 08:44:54.186092.186092 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:54.186359.186359 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-06 08:44:54.186963.186963 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.195749.195749 mlpmodule.py:704] group tensors cost 0.008910417556762695 s
DEBUG 01-06 08:44:54.197401.197401 mlpmodule.py:742] pad cost 0.001495361328125 s
DEBUG 01-06 08:44:54.198007.198007 mlpmodule.py:748] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-06 08:44:54.198334.198334 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 08:44:54.207872.207872 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:54.207878.207878 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.207014.207014 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-06 08:44:54.207137.207137 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.223099.223099 mlpmodule.py:793] group einsum cost 0.02495741844177246 s
DEBUG 01-06 08:44:54.223732.223732 mlpmodule.py:801] cpy2cputensor cost 0.0004975795745849609 s
DEBUG 01-06 08:44:54.228398.228398 cuda_h.py:19] end wait_cetm_experts cost 0.042024850845336914 seconds
DEBUG 01-06 08:44:54.228004.228004 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.229305.229305 cuda_h.py:19] end gpu_sexperts cost 0.00045990943908691406 seconds
DEBUG 01-06 08:44:54.229764.229764 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.229521.229521 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:54.229939.229939 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.229272.229272 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 86c39726-705e-4d8a-b062-6e419460c3e0
INFO 01-06 08:44:54.239919.239919 client.py:127] Model loaded
DEBUG 01-06 08:44:54.239875.239875 cuda_h.py:19] end wait_experts cost 0.009715795516967773 seconds
DEBUG 01-06 08:44:54.239916.239916 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.239811.239811 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.241352.241352 mlpmodule.py:662]  experts func einsum cost 0.054628610610961914 s
DEBUG 01-06 08:44:54.250733.250733 cuda_h.py:19] end gpu_experts cost 0.011312484741210938 seconds
DEBUG 01-06 08:44:54.250246.250246 cuda_h.py:19] end layer_moe_generate_10 cost 0.07157421112060547 seconds
DEBUG 01-06 08:44:54.250775.250775 lmp.py:221] -------------------------------- end layer 10 --------------------------------
DEBUG 01-06 08:44:54.250300.250300 lmp.py:177] -------------------------------- start layer 11 --------------------------------
DEBUG 01-06 08:44:54.250804.250804 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 08:44:54.250175.250175 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 08:44:54.250866.250866 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.6226043701171875e-05 seconds
DEBUG 01-06 08:44:54.250397.250397 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.200241088867188e-05 seconds
DEBUG 01-06 08:44:54.251186.251186 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.251294.251294 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.251092.251092 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.251465.251465 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.251794.251794 cuda_h.py:19] end allocate_cuda_memory cost 0.0002677440643310547 seconds
DEBUG 01-06 08:44:54.251916.251916 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.251878.251878 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.251614.251614 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.251755.251755 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e5c30abe-fce4-4071-b989-6ee665de8c68
DEBUG 01-06 08:44:54.251791.251791 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.252614.252614 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.252973.252973 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e5c30abe-fce4-4071-b989-6ee665de8c68
DEBUG 01-06 08:44:54.253056.253056 cuda_h.py:19] end load_into_gpu_async cost 0.0013568401336669922 seconds
DEBUG 01-06 08:44:54.253872.253872 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.253028.253028 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-06 08:44:54.253493.253493 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020432472229003906 seconds
INFO 01-06 08:44:54.253074.253074 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e5c30abe-fce4-4071-b989-6ee665de8c68
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.256891.256891 cuda_h.py:19] end self_attn cost 0.004028797149658203 seconds
DEBUG 01-06 08:44:54.256173.256173 cuda_h.py:19] end iln_self_attn_paln cost 0.005507707595825195 seconds
DEBUG 01-06 08:44:54.256492.256492 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-06 08:44:54.256924.256924 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.257973.257973 cuda_h.py:19] end gate cost 0.0006327629089355469 seconds
DEBUG 01-06 08:44:54.257134.257134 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.257164.257164 lmp.py:369] 
DEBUG 01-06 08:44:54.257164.257164 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.257681.257681 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:54.257569.257569 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:54.257120.257120 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:54.257524.257524 lmp.py:373] 
DEBUG 01-06 08:44:54.257524.257524 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.257167.257167 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.257009.257009 lmp.py:380]   Expert 38 |      1 | CPU
DEBUG 01-06 08:44:54.257367.257367 lmp.py:380]   Expert 35 |      3 | CPU
DEBUG 01-06 08:44:54.257295.257295 lmp.py:380]   Expert  0 |      4 | CPU
DEBUG 01-06 08:44:54.257984.257984 lmp.py:380]   Expert 19 |      4 | CPU
DEBUG 01-06 08:44:54.257197.257197 lmp.py:380]   Expert 49 |      7 | CPU
DEBUG 01-06 08:44:54.257409.257409 lmp.py:380]   Expert 59 |     10 | CPU
DEBUG 01-06 08:44:54.257383.257383 lmp.py:380]   Expert  4 |     15 | CPU
DEBUG 01-06 08:44:54.257119.257119 lmp.py:380]   Expert 41 |     16 | CPU
DEBUG 01-06 08:44:54.257093.257093 lmp.py:380]   Expert 15 |     17 | CPU
DEBUG 01-06 08:44:54.257782.257782 lmp.py:380]   Expert 16 |     19 | CPU
DEBUG 01-06 08:44:54.257472.257472 lmp.py:380]   Expert 43 |     21 | CPU
DEBUG 01-06 08:44:54.257446.257446 lmp.py:380]   Expert 62 |     21 | CPU
DEBUG 01-06 08:44:54.257181.257181 lmp.py:380]   Expert  7 |     22 | CPU
DEBUG 01-06 08:44:54.258678.258678 lmp.py:380]   Expert 39 |     23 | CPU
DEBUG 01-06 08:44:54.258414.258414 lmp.py:380]   Expert  8 |     28 | CPU
DEBUG 01-06 08:44:54.258911.258911 lmp.py:380]   Expert  3 |     36 | CPU
DEBUG 01-06 08:44:54.258408.258408 lmp.py:380]   Expert 23 |     39 | CPU
DEBUG 01-06 08:44:54.258667.258667 lmp.py:380]   Expert 32 |     40 | CPU
DEBUG 01-06 08:44:54.258926.258926 lmp.py:380]   Expert  5 |     45 | CPU
DEBUG 01-06 08:44:54.258900.258900 lmp.py:380]   Expert 36 |     45 | CPU
DEBUG 01-06 08:44:54.258589.258589 lmp.py:380]   Expert 46 |     45 | CPU
DEBUG 01-06 08:44:54.258563.258563 lmp.py:380]   Expert 12 |     50 | CPU
DEBUG 01-06 08:44:54.258299.258299 lmp.py:380]   Expert 57 |     57 | CPU
DEBUG 01-06 08:44:54.258558.258558 lmp.py:380]   Expert 17 |     63 | CPU
DEBUG 01-06 08:44:54.258294.258294 lmp.py:380]   Expert 25 |     71 | CPU
DEBUG 01-06 08:44:54.258552.258552 lmp.py:380]   Expert 42 |     74 | CPU
DEBUG 01-06 08:44:54.258957.258957 lmp.py:380]   Expert 28 |     82 | CPU
DEBUG 01-06 08:44:54.258408.258408 lmp.py:380]   Expert 63 |     82 | CPU
DEBUG 01-06 08:44:54.258097.258097 lmp.py:380]   Expert 52 |     85 | CPU
DEBUG 01-06 08:44:54.258786.258786 lmp.py:380]   Expert 10 |     87 | CPU
DEBUG 01-06 08:44:54.258999.258999 lmp.py:380]   Expert 44 |     88 | CPU
DEBUG 01-06 08:44:54.258927.258927 lmp.py:380]   Expert 27 |    102 | GPU
DEBUG 01-06 08:44:54.258616.258616 lmp.py:380]   Expert 20 |    103 | GPU
DEBUG 01-06 08:44:54.258305.258305 lmp.py:380]   Expert 61 |    103 | GPU
DEBUG 01-06 08:44:54.258279.258279 lmp.py:380]   Expert 13 |    106 | GPU
DEBUG 01-06 08:44:54.258730.258730 lmp.py:380]   Expert 40 |    112 | GPU
DEBUG 01-06 08:44:54.258181.258181 lmp.py:380]   Expert 14 |    114 | GPU
DEBUG 01-06 08:44:54.258870.258870 lmp.py:380]   Expert 31 |    122 | GPU
DEBUG 01-06 08:44:54.258083.258083 lmp.py:380]   Expert 60 |    123 | GPU
DEBUG 01-06 08:44:54.258772.258772 lmp.py:380]   Expert 18 |    125 | GPU
DEBUG 01-06 08:44:54.258984.258984 lmp.py:380]   Expert 51 |    150 | GPU
DEBUG 01-06 08:44:54.258674.258674 lmp.py:380]   Expert  2 |    152 | GPU
DEBUG 01-06 08:44:54.258363.258363 lmp.py:380]   Expert 48 |    170 | GPU
DEBUG 01-06 08:44:54.258291.258291 lmp.py:380]   Expert 29 |    200 | GPU
DEBUG 01-06 08:44:54.258503.258503 lmp.py:380]   Expert 34 |    217 | GPU
DEBUG 01-06 08:44:54.258716.258716 lmp.py:380]   Expert 55 |    249 | GPU
DEBUG 01-06 08:44:54.258451.258451 lmp.py:380]   Expert 22 |    252 | GPU
DEBUG 01-06 08:44:54.258664.258664 lmp.py:380]   Expert 26 |    296 | GPU
DEBUG 01-06 08:44:54.258876.258876 lmp.py:380]   Expert 21 |    298 | GPU
DEBUG 01-06 08:44:54.258850.258850 lmp.py:380]   Expert 53 |    299 | GPU
DEBUG 01-06 08:44:54.258824.258824 lmp.py:380]   Expert 47 |    303 | GPU
DEBUG 01-06 08:44:54.258514.258514 lmp.py:380]   Expert 50 |    322 | GPU
DEBUG 01-06 08:44:54.258918.258918 lmp.py:380]   Expert  1 |    331 | GPU
DEBUG 01-06 08:44:54.258846.258846 lmp.py:380]   Expert 45 |    343 | GPU
DEBUG 01-06 08:44:54.258297.258297 lmp.py:380]   Expert 58 |    359 | GPU
DEBUG 01-06 08:44:54.258748.258748 lmp.py:380]   Expert 54 |    453 | GPU
DEBUG 01-06 08:44:54.258199.258199 lmp.py:380]   Expert  9 |    480 | GPU
DEBUG 01-06 08:44:54.258411.258411 lmp.py:380]   Expert 33 |    523 | GPU
DEBUG 01-06 08:44:54.258100.258100 lmp.py:380]   Expert 56 |    590 | GPU
DEBUG 01-06 08:44:54.258790.258790 lmp.py:380]   Expert 37 |    602 | GPU
DEBUG 01-06 08:44:54.258002.258002 lmp.py:380]   Expert 24 |    764 | GPU
DEBUG 01-06 08:44:54.258453.258453 lmp.py:380]   Expert 11 |   1090 | GPU
DEBUG 01-06 08:44:54.258904.258904 lmp.py:380]   Expert 30 |   1635 | GPU
DEBUG 01-06 08:44:54.258547.258547 lmp.py:381] 
DEBUG 01-06 08:44:54.258547.258547 lmp.py:381]   CPU total tokens: 1200 (9.8%)
DEBUG 01-06 08:44:54.258620.258620 lmp.py:382]   GPU total tokens: 11088 (90.2%)
DEBUG 01-06 08:44:54.258032.258032 cuda_h.py:19] end experts_map_get cost 0.0014760494232177734 seconds
DEBUG 01-06 08:44:54.258913.258913 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.258597.258597 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.259880.259880 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.259929.259929 cuda_h.py:19] end allocate_cuda_memory cost 0.00045943260192871094 seconds
DEBUG 01-06 08:44:54.259216.259216 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.259357.259357 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.259450.259450 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.259577.259577 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36ff80d0-7aec-4007-85f4-76d2dc771745
DEBUG 01-06 08:44:54.259266.259266 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.260608.260608 client.py:127] Model loaded
DEBUG 01-06 08:44:54.260750.260750 cuda_h.py:19] end sllm_worker_task cost 0.008949995040893555 seconds
INFO 01-06 08:44:54.260658.260658 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36ff80d0-7aec-4007-85f4-76d2dc771745
DEBUG 01-06 08:44:54.260455.260455 cuda_h.py:19] end load_into_gpu_async cost 0.0011584758758544922 seconds
DEBUG 01-06 08:44:54.260396.260396 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.261749.261749 cuda_h.py:19] end restore_tensors2 cost 0.00040912628173828125 seconds
DEBUG 01-06 08:44:54.261823.261823 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002391815185546875 seconds
DEBUG 01-06 08:44:54.263365.263365 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004973173141479492 seconds
DEBUG 01-06 08:44:54.263625.263625 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.264158.264158 lmp.py:427] 
DEBUG 01-06 08:44:54.264158.264158 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:54.264140.264140 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-06 08:44:54.264764.264764 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.276679.276679 mlpmodule.py:704] group tensors cost 0.011756181716918945 s
DEBUG 01-06 08:44:54.278695.278695 mlpmodule.py:742] pad cost 0.001512289047241211 s
DEBUG 01-06 08:44:54.278731.278731 mlpmodule.py:748] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-06 08:44:54.278104.278104 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 08:44:54.285930.285930 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:54.286976.286976 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.286926.286926 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-06 08:44:54.286288.286288 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.301100.301100 mlpmodule.py:793] group einsum cost 0.02312445640563965 s
DEBUG 01-06 08:44:54.302962.302962 mlpmodule.py:801] cpy2cputensor cost 0.00042748451232910156 s
DEBUG 01-06 08:44:54.307157.307157 cuda_h.py:19] end wait_cetm_experts cost 0.04293704032897949 seconds
DEBUG 01-06 08:44:54.307524.307524 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.308833.308833 cuda_h.py:19] end gpu_sexperts cost 0.0010602474212646484 seconds
DEBUG 01-06 08:44:54.308437.308437 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.308559.308559 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:54.308600.308600 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.308263.308263 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36ff80d0-7aec-4007-85f4-76d2dc771745
INFO 01-06 08:44:54.315630.315630 client.py:127] Model loaded
DEBUG 01-06 08:44:54.315996.315996 cuda_h.py:19] end wait_experts cost 0.006651401519775391 seconds
DEBUG 01-06 08:44:54.315845.315845 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.315362.315362 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.319632.319632 mlpmodule.py:662]  experts func einsum cost 0.055666446685791016 s
DEBUG 01-06 08:44:54.327114.327114 cuda_h.py:19] end gpu_experts cost 0.012345552444458008 seconds
DEBUG 01-06 08:44:54.327110.327110 cuda_h.py:19] end layer_moe_generate_11 cost 0.07103252410888672 seconds
DEBUG 01-06 08:44:54.327871.327871 lmp.py:221] -------------------------------- end layer 11 --------------------------------
DEBUG 01-06 08:44:54.327680.327680 lmp.py:177] -------------------------------- start layer 12 --------------------------------
DEBUG 01-06 08:44:54.327423.327423 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 08:44:54.327318.327318 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 08:44:54.327770.327770 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.6702880859375e-05 seconds
DEBUG 01-06 08:44:54.328824.328824 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.176399230957031e-05 seconds
DEBUG 01-06 08:44:54.328944.328944 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.328363.328363 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.328732.328732 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.328952.328952 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.328133.328133 cuda_h.py:19] end allocate_cuda_memory cost 0.0002014636993408203 seconds
DEBUG 01-06 08:44:54.328744.328744 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.328738.328738 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.328700.328700 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.328449.328449 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c4a8f8a8-6c8c-4409-a175-11789591f6fd
DEBUG 01-06 08:44:54.328611.328611 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.329952.329952 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.329022.329022 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c4a8f8a8-6c8c-4409-a175-11789591f6fd
DEBUG 01-06 08:44:54.329712.329712 cuda_h.py:19] end load_into_gpu_async cost 0.0009975433349609375 seconds
DEBUG 01-06 08:44:54.329223.329223 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.329114.329114 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-06 08:44:54.329870.329870 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015039443969726562 seconds
INFO 01-06 08:44:54.330151.330151 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c4a8f8a8-6c8c-4409-a175-11789591f6fd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.333921.333921 cuda_h.py:19] end self_attn cost 0.003949880599975586 seconds
DEBUG 01-06 08:44:54.333923.333923 cuda_h.py:19] end iln_self_attn_paln cost 0.005292415618896484 seconds
DEBUG 01-06 08:44:54.333574.333574 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-06 08:44:54.333053.333053 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.334724.334724 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-06 08:44:54.334885.334885 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.334517.334517 lmp.py:369] 
DEBUG 01-06 08:44:54.334517.334517 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.334842.334842 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:54.334492.334492 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:54.334327.334327 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:54.334685.334685 lmp.py:373] 
DEBUG 01-06 08:44:54.334685.334685 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.334567.334567 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.334455.334455 lmp.py:380]   Expert  4 |      1 | CPU
DEBUG 01-06 08:44:54.334575.334575 lmp.py:380]   Expert 51 |      1 | CPU
DEBUG 01-06 08:44:54.334787.334787 lmp.py:380]   Expert 47 |      2 | CPU
DEBUG 01-06 08:44:54.334000.334000 lmp.py:380]   Expert  0 |      6 | CPU
DEBUG 01-06 08:44:54.334689.334689 lmp.py:380]   Expert 44 |      6 | CPU
DEBUG 01-06 08:44:54.334425.334425 lmp.py:380]   Expert 63 |      9 | CPU
DEBUG 01-06 08:44:54.334399.334399 lmp.py:380]   Expert 11 |     15 | CPU
DEBUG 01-06 08:44:54.334373.334373 lmp.py:380]   Expert 16 |     15 | CPU
DEBUG 01-06 08:44:54.334870.334870 lmp.py:380]   Expert 27 |     19 | CPU
DEBUG 01-06 08:44:54.334605.334605 lmp.py:380]   Expert 13 |     21 | CPU
DEBUG 01-06 08:44:54.334103.334103 lmp.py:380]   Expert 34 |     24 | CPU
DEBUG 01-06 08:44:54.334838.334838 lmp.py:380]   Expert 45 |     24 | CPU
DEBUG 01-06 08:44:54.334097.334097 lmp.py:380]   Expert 29 |     26 | CPU
DEBUG 01-06 08:44:54.334594.334594 lmp.py:380]   Expert  8 |     31 | CPU
DEBUG 01-06 08:44:54.334330.334330 lmp.py:380]   Expert 37 |     40 | CPU
DEBUG 01-06 08:44:54.334827.334827 lmp.py:380]   Expert 39 |     42 | CPU
DEBUG 01-06 08:44:54.334516.334516 lmp.py:380]   Expert  6 |     44 | CPU
DEBUG 01-06 08:44:54.334967.334967 lmp.py:380]   Expert  2 |     47 | CPU
DEBUG 01-06 08:44:54.334418.334418 lmp.py:380]   Expert 26 |     50 | CPU
DEBUG 01-06 08:44:54.334015.334015 lmp.py:380]   Expert 41 |     53 | CPU
DEBUG 01-06 08:44:54.334181.334181 lmp.py:380]   Expert 32 |     54 | CPU
DEBUG 01-06 08:44:54.334109.334109 lmp.py:380]   Expert 43 |     58 | CPU
DEBUG 01-06 08:44:54.334798.334798 lmp.py:380]   Expert 23 |     81 | CPU
DEBUG 01-06 08:44:54.334010.334010 lmp.py:380]   Expert 24 |     84 | CPU
DEBUG 01-06 08:44:54.334700.334700 lmp.py:380]   Expert  3 |     96 | CPU
DEBUG 01-06 08:44:54.335389.335389 lmp.py:380]   Expert 38 |     96 | CPU
DEBUG 01-06 08:44:54.335840.335840 lmp.py:380]   Expert 55 |     96 | CPU
DEBUG 01-06 08:44:54.335052.335052 lmp.py:380]   Expert 57 |    101 | CPU
DEBUG 01-06 08:44:54.335503.335503 lmp.py:380]   Expert 61 |    102 | CPU
DEBUG 01-06 08:44:54.335908.335908 lmp.py:380]   Expert 49 |    105 | CPU
DEBUG 01-06 08:44:54.335836.335836 lmp.py:380]   Expert 31 |    109 | CPU
DEBUG 01-06 08:44:54.335002.335002 lmp.py:380]   Expert 54 |    112 | GPU
DEBUG 01-06 08:44:54.335645.335645 lmp.py:380]   Expert 21 |    116 | GPU
DEBUG 01-06 08:44:54.335811.335811 lmp.py:380]   Expert 53 |    139 | GPU
DEBUG 01-06 08:44:54.335500.335500 lmp.py:380]   Expert 22 |    143 | GPU
DEBUG 01-06 08:44:54.335189.335189 lmp.py:380]   Expert 40 |    151 | GPU
DEBUG 01-06 08:44:54.335640.335640 lmp.py:380]   Expert  7 |    164 | GPU
DEBUG 01-06 08:44:54.335091.335091 lmp.py:380]   Expert 62 |    168 | GPU
DEBUG 01-06 08:44:54.335781.335781 lmp.py:380]   Expert 14 |    189 | GPU
DEBUG 01-06 08:44:54.335231.335231 lmp.py:380]   Expert 56 |    189 | GPU
DEBUG 01-06 08:44:54.335682.335682 lmp.py:380]   Expert 58 |    193 | GPU
DEBUG 01-06 08:44:54.335372.335372 lmp.py:380]   Expert 42 |    199 | GPU
DEBUG 01-06 08:44:54.335776.335776 lmp.py:380]   Expert 30 |    225 | GPU
DEBUG 01-06 08:44:54.335465.335465 lmp.py:380]   Expert 20 |    232 | GPU
DEBUG 01-06 08:44:54.335632.335632 lmp.py:380]   Expert  5 |    234 | GPU
DEBUG 01-06 08:44:54.335798.335798 lmp.py:380]   Expert 52 |    248 | GPU
DEBUG 01-06 08:44:54.335487.335487 lmp.py:380]   Expert 19 |    257 | GPU
DEBUG 01-06 08:44:54.335699.335699 lmp.py:380]   Expert 28 |    284 | GPU
DEBUG 01-06 08:44:54.335389.335389 lmp.py:380]   Expert 10 |    299 | GPU
DEBUG 01-06 08:44:54.335840.335840 lmp.py:380]   Expert 35 |    305 | GPU
DEBUG 01-06 08:44:54.335529.335529 lmp.py:380]   Expert 59 |    312 | GPU
DEBUG 01-06 08:44:54.335741.335741 lmp.py:380]   Expert 60 |    316 | GPU
DEBUG 01-06 08:44:54.335160.335160 lmp.py:380]   Expert 17 |    330 | GPU
DEBUG 01-06 08:44:54.335610.335610 lmp.py:380]   Expert 18 |    338 | GPU
DEBUG 01-06 08:44:54.335061.335061 lmp.py:380]   Expert 46 |    344 | GPU
DEBUG 01-06 08:44:54.335751.335751 lmp.py:380]   Expert  9 |    366 | GPU
DEBUG 01-06 08:44:54.335678.335678 lmp.py:380]   Expert  1 |    405 | GPU
DEBUG 01-06 08:44:54.335606.335606 lmp.py:380]   Expert 50 |    467 | GPU
DEBUG 01-06 08:44:54.335772.335772 lmp.py:380]   Expert 48 |    471 | GPU
DEBUG 01-06 08:44:54.335700.335700 lmp.py:380]   Expert 25 |    694 | GPU
DEBUG 01-06 08:44:54.335389.335389 lmp.py:380]   Expert 15 |    830 | GPU
DEBUG 01-06 08:44:54.335079.335079 lmp.py:380]   Expert 33 |   1019 | GPU
DEBUG 01-06 08:44:54.335529.335529 lmp.py:380]   Expert 36 |   1091 | GPU
DEBUG 01-06 08:44:54.335172.335172 lmp.py:381] 
DEBUG 01-06 08:44:54.335172.335172 lmp.py:381]   CPU total tokens: 1458 (11.9%)
DEBUG 01-06 08:44:54.335292.335292 lmp.py:382]   GPU total tokens: 10830 (88.1%)
DEBUG 01-06 08:44:54.335227.335227 cuda_h.py:19] end experts_map_get cost 0.0014889240264892578 seconds
DEBUG 01-06 08:44:54.335870.335870 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.335792.335792 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.335412.335412 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.336470.336470 cuda_h.py:19] end allocate_cuda_memory cost 0.000274658203125 seconds
DEBUG 01-06 08:44:54.336856.336856 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.336566.336566 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.336183.336183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.336893.336893 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba1c64d2-d8c1-4570-af9d-d8bfb189af5b
DEBUG 01-06 08:44:54.336958.336958 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.336540.336540 client.py:127] Model loaded
DEBUG 01-06 08:44:54.336204.336204 cuda_h.py:19] end sllm_worker_task cost 0.008566617965698242 seconds
INFO 01-06 08:44:54.337341.337341 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba1c64d2-d8c1-4570-af9d-d8bfb189af5b
DEBUG 01-06 08:44:54.337184.337184 cuda_h.py:19] end load_into_gpu_async cost 0.0012602806091308594 seconds
DEBUG 01-06 08:44:54.337126.337126 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.338658.338658 cuda_h.py:19] end restore_tensors2 cost 0.00043582916259765625 seconds
DEBUG 01-06 08:44:54.338779.338779 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023546218872070312 seconds
DEBUG 01-06 08:44:54.340620.340620 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00498199462890625 seconds
DEBUG 01-06 08:44:54.340225.340225 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.340857.340857 lmp.py:427] 
DEBUG 01-06 08:44:54.340857.340857 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:54.340985.340985 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-06 08:44:54.340065.340065 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.353279.353279 mlpmodule.py:704] group tensors cost 0.012383460998535156 s
DEBUG 01-06 08:44:54.355689.355689 mlpmodule.py:742] pad cost 0.001432180404663086 s
DEBUG 01-06 08:44:54.355739.355739 mlpmodule.py:748] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-06 08:44:54.355920.355920 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 08:44:54.363852.363852 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:54.363897.363897 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.363556.363556 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-06 08:44:54.363964.363964 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.378296.378296 mlpmodule.py:793] group einsum cost 0.02302384376525879 s
DEBUG 01-06 08:44:54.379614.379614 mlpmodule.py:801] cpy2cputensor cost 0.0005846023559570312 s
DEBUG 01-06 08:44:54.384781.384781 cuda_h.py:19] end wait_cetm_experts cost 0.04349470138549805 seconds
DEBUG 01-06 08:44:54.384387.384387 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.385040.385040 cuda_h.py:19] end gpu_sexperts cost 0.0004723072052001953 seconds
DEBUG 01-06 08:44:54.385221.385221 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.385170.385170 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:54.385542.385542 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.385252.385252 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba1c64d2-d8c1-4570-af9d-d8bfb189af5b
INFO 01-06 08:44:54.392428.392428 client.py:127] Model loaded
DEBUG 01-06 08:44:54.392086.392086 cuda_h.py:19] end wait_experts cost 0.007322549819946289 seconds
DEBUG 01-06 08:44:54.392604.392604 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.392837.392837 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.397404.397404 mlpmodule.py:662]  experts func einsum cost 0.05648636817932129 s
DEBUG 01-06 08:44:54.404894.404894 cuda_h.py:19] end gpu_experts cost 0.011409521102905273 seconds
DEBUG 01-06 08:44:54.404958.404958 cuda_h.py:19] end layer_moe_generate_12 cost 0.0707547664642334 seconds
DEBUG 01-06 08:44:54.404243.404243 lmp.py:221] -------------------------------- end layer 12 --------------------------------
DEBUG 01-06 08:44:54.404821.404821 lmp.py:177] -------------------------------- start layer 13 --------------------------------
DEBUG 01-06 08:44:54.404470.404470 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 08:44:54.404988.404988 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 08:44:54.404255.404255 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:44:54.404719.404719 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.0558319091796875e-05 seconds
DEBUG 01-06 08:44:54.404462.404462 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.404716.404716 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.404660.404660 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.404417.404417 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.405939.405939 cuda_h.py:19] end allocate_cuda_memory cost 0.0003027915954589844 seconds
DEBUG 01-06 08:44:54.405405.405405 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.405990.405990 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.405217.405217 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.405218.405218 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d170e06-8878-4711-aa6e-1a66c9b7ec85
DEBUG 01-06 08:44:54.405215.405215 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.405203.405203 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.406819.406819 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d170e06-8878-4711-aa6e-1a66c9b7ec85
DEBUG 01-06 08:44:54.406054.406054 cuda_h.py:19] end load_into_gpu_async cost 0.0013091564178466797 seconds
DEBUG 01-06 08:44:54.406671.406671 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.406449.406449 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-06 08:44:54.406742.406742 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002018451690673828 seconds
INFO 01-06 08:44:54.407284.407284 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d170e06-8878-4711-aa6e-1a66c9b7ec85
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.409012.409012 cuda_h.py:19] end self_attn cost 0.004113674163818359 seconds
DEBUG 01-06 08:44:54.410975.410975 cuda_h.py:19] end iln_self_attn_paln cost 0.0056154727935791016 seconds
DEBUG 01-06 08:44:54.410196.410196 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-06 08:44:54.410958.410958 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.411762.411762 cuda_h.py:19] end gate cost 0.0006284713745117188 seconds
DEBUG 01-06 08:44:54.411446.411446 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.411263.411263 lmp.py:369] 
DEBUG 01-06 08:44:54.411263.411263 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.411350.411350 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:54.411285.411285 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:54.411835.411835 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:54.411763.411763 lmp.py:373] 
DEBUG 01-06 08:44:54.411763.411763 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.411167.411167 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.411056.411056 lmp.py:380]   Expert  6 |      1 | CPU
DEBUG 01-06 08:44:54.411460.411460 lmp.py:380]   Expert 26 |      2 | CPU
DEBUG 01-06 08:44:54.411150.411150 lmp.py:380]   Expert 19 |      3 | CPU
DEBUG 01-06 08:44:54.411600.411600 lmp.py:380]   Expert 50 |      9 | CPU
DEBUG 01-06 08:44:54.411051.411051 lmp.py:380]   Expert  8 |     12 | CPU
DEBUG 01-06 08:44:54.411456.411456 lmp.py:380]   Expert  0 |     16 | CPU
DEBUG 01-06 08:44:54.411099.411099 lmp.py:380]   Expert  2 |     16 | CPU
DEBUG 01-06 08:44:54.411550.411550 lmp.py:380]   Expert 12 |     16 | CPU
DEBUG 01-06 08:44:54.411762.411762 lmp.py:380]   Expert 63 |     17 | CPU
DEBUG 01-06 08:44:54.411498.411498 lmp.py:380]   Expert 32 |     20 | CPU
DEBUG 01-06 08:44:54.411472.411472 lmp.py:380]   Expert 16 |     21 | CPU
DEBUG 01-06 08:44:54.411446.411446 lmp.py:380]   Expert 40 |     27 | CPU
DEBUG 01-06 08:44:54.411182.411182 lmp.py:380]   Expert 13 |     33 | CPU
DEBUG 01-06 08:44:54.411917.411917 lmp.py:380]   Expert 31 |     59 | CPU
DEBUG 01-06 08:44:54.411130.411130 lmp.py:380]   Expert 20 |     64 | CPU
DEBUG 01-06 08:44:54.411057.411057 lmp.py:380]   Expert 45 |     75 | CPU
DEBUG 01-06 08:44:54.411462.411462 lmp.py:380]   Expert 57 |     82 | CPU
DEBUG 01-06 08:44:54.411913.411913 lmp.py:380]   Expert 52 |     83 | CPU
DEBUG 01-06 08:44:54.411648.411648 lmp.py:380]   Expert  9 |     90 | CPU
DEBUG 01-06 08:44:54.411384.411384 lmp.py:380]   Expert 30 |     97 | CPU
DEBUG 01-06 08:44:54.411120.411120 lmp.py:380]   Expert 61 |    100 | CPU
DEBUG 01-06 08:44:54.411855.411855 lmp.py:380]   Expert 59 |    105 | CPU
DEBUG 01-06 08:44:54.411591.411591 lmp.py:380]   Expert 28 |    106 | CPU
DEBUG 01-06 08:44:54.411234.411234 lmp.py:380]   Expert 58 |    106 | CPU
DEBUG 01-06 08:44:54.411400.411400 lmp.py:380]   Expert 11 |    115 | CPU
DEBUG 01-06 08:44:54.411758.411758 lmp.py:380]   Expert 48 |    116 | CPU
DEBUG 01-06 08:44:54.411686.411686 lmp.py:380]   Expert  5 |    117 | CPU
DEBUG 01-06 08:44:54.411375.411375 lmp.py:380]   Expert 60 |    121 | CPU
DEBUG 01-06 08:44:54.411303.411303 lmp.py:380]   Expert 44 |    122 | CPU
DEBUG 01-06 08:44:54.411992.411992 lmp.py:380]   Expert  1 |    125 | CPU
DEBUG 01-06 08:44:54.411682.411682 lmp.py:380]   Expert  3 |    136 | CPU
DEBUG 01-06 08:44:54.412371.412371 lmp.py:380]   Expert 35 |    141 | GPU
DEBUG 01-06 08:44:54.412822.412822 lmp.py:380]   Expert 36 |    141 | GPU
DEBUG 01-06 08:44:54.412273.412273 lmp.py:380]   Expert 42 |    141 | GPU
DEBUG 01-06 08:44:54.412200.412200 lmp.py:380]   Expert 49 |    157 | GPU
DEBUG 01-06 08:44:54.412843.412843 lmp.py:380]   Expert 24 |    180 | GPU
DEBUG 01-06 08:44:54.412009.412009 lmp.py:380]   Expert 62 |    184 | GPU
DEBUG 01-06 08:44:54.412176.412176 lmp.py:380]   Expert 15 |    185 | GPU
DEBUG 01-06 08:44:54.412103.412103 lmp.py:380]   Expert 34 |    190 | GPU
DEBUG 01-06 08:44:54.412793.412793 lmp.py:380]   Expert 25 |    192 | GPU
DEBUG 01-06 08:44:54.412005.412005 lmp.py:380]   Expert 22 |    202 | GPU
DEBUG 01-06 08:44:54.412933.412933 lmp.py:380]   Expert 18 |    209 | GPU
DEBUG 01-06 08:44:54.412861.412861 lmp.py:380]   Expert 54 |    223 | GPU
DEBUG 01-06 08:44:54.412027.412027 lmp.py:380]   Expert 29 |    238 | GPU
DEBUG 01-06 08:44:54.412670.412670 lmp.py:380]   Expert 43 |    253 | GPU
DEBUG 01-06 08:44:54.412597.412597 lmp.py:380]   Expert  7 |    265 | GPU
DEBUG 01-06 08:44:54.412525.412525 lmp.py:380]   Expert 37 |    266 | GPU
DEBUG 01-06 08:44:54.412214.412214 lmp.py:380]   Expert 51 |    275 | GPU
DEBUG 01-06 08:44:54.412142.412142 lmp.py:380]   Expert 46 |    285 | GPU
DEBUG 01-06 08:44:54.412831.412831 lmp.py:380]   Expert  4 |    300 | GPU
DEBUG 01-06 08:44:54.412521.412521 lmp.py:380]   Expert 33 |    304 | GPU
DEBUG 01-06 08:44:54.412210.412210 lmp.py:380]   Expert 10 |    314 | GPU
DEBUG 01-06 08:44:54.412899.412899 lmp.py:380]   Expert 27 |    338 | GPU
DEBUG 01-06 08:44:54.412589.412589 lmp.py:380]   Expert 41 |    367 | GPU
DEBUG 01-06 08:44:54.412430.412430 lmp.py:380]   Expert 17 |    397 | GPU
DEBUG 01-06 08:44:54.412716.412716 lmp.py:380]   Expert 56 |    448 | GPU
DEBUG 01-06 08:44:54.412883.412883 lmp.py:380]   Expert 39 |    461 | GPU
DEBUG 01-06 08:44:54.412572.412572 lmp.py:380]   Expert 55 |    482 | GPU
DEBUG 01-06 08:44:54.412500.412500 lmp.py:380]   Expert 14 |    498 | GPU
DEBUG 01-06 08:44:54.412427.412427 lmp.py:380]   Expert 47 |    532 | GPU
DEBUG 01-06 08:44:54.412593.412593 lmp.py:380]   Expert 21 |    640 | GPU
DEBUG 01-06 08:44:54.412521.412521 lmp.py:380]   Expert 23 |    710 | GPU
DEBUG 01-06 08:44:54.412687.412687 lmp.py:380]   Expert 38 |    758 | GPU
DEBUG 01-06 08:44:54.412569.412569 lmp.py:381] 
DEBUG 01-06 08:44:54.412569.412569 lmp.py:381]   CPU total tokens: 2012 (16.4%)
DEBUG 01-06 08:44:54.412927.412927 lmp.py:382]   GPU total tokens: 10276 (83.6%)
DEBUG 01-06 08:44:54.412292.412292 cuda_h.py:19] end experts_map_get cost 0.001508474349975586 seconds
DEBUG 01-06 08:44:54.412889.412889 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.412288.412288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.412617.412617 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.413514.413514 cuda_h.py:19] end allocate_cuda_memory cost 0.0004525184631347656 seconds
DEBUG 01-06 08:44:54.413516.413516 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.413941.413941 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.413512.413512 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.413877.413877 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5518f88f-a97c-4a6c-8c2b-201402e141a3
DEBUG 01-06 08:44:54.413989.413989 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.413382.413382 client.py:127] Model loaded
DEBUG 01-06 08:44:54.413514.413514 cuda_h.py:19] end sllm_worker_task cost 0.009091377258300781 seconds
INFO 01-06 08:44:54.414690.414690 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5518f88f-a97c-4a6c-8c2b-201402e141a3
DEBUG 01-06 08:44:54.414202.414202 cuda_h.py:19] end load_into_gpu_async cost 0.0014526844024658203 seconds
DEBUG 01-06 08:44:54.414620.414620 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.415668.415668 cuda_h.py:19] end restore_tensors2 cost 0.0004298686981201172 seconds
DEBUG 01-06 08:44:54.415266.415266 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002700328826904297 seconds
DEBUG 01-06 08:44:54.418685.418685 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005366086959838867 seconds
DEBUG 01-06 08:44:54.418859.418859 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.418843.418843 lmp.py:427] 
DEBUG 01-06 08:44:54.418843.418843 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:54.418633.418633 cuda_h.py:19] end cpu_experts_submit cost 0.00012111663818359375 seconds
DEBUG 01-06 08:44:54.418296.418296 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.428544.428544 mlpmodule.py:704] group tensors cost 0.010436534881591797 s
DEBUG 01-06 08:44:54.431682.431682 mlpmodule.py:742] pad cost 0.0017249584197998047 s
DEBUG 01-06 08:44:54.431778.431778 mlpmodule.py:748] create cpu tensor cost 4.291534423828125e-05 s
DEBUG 01-06 08:44:54.431495.431495 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-06 08:44:54.439405.439405 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:54.439934.439934 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.439024.439024 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-06 08:44:54.439716.439716 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.456680.456680 mlpmodule.py:793] group einsum cost 0.024417877197265625 s
DEBUG 01-06 08:44:54.456483.456483 mlpmodule.py:801] cpy2cputensor cost 0.0006279945373535156 s
DEBUG 01-06 08:44:54.461858.461858 cuda_h.py:19] end wait_cetm_experts cost 0.04323840141296387 seconds
DEBUG 01-06 08:44:54.461802.461802 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.463663.463663 cuda_h.py:19] end gpu_sexperts cost 0.0015337467193603516 seconds
DEBUG 01-06 08:44:54.463188.463188 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.463091.463091 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:44:54.463224.463224 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.463934.463934 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5518f88f-a97c-4a6c-8c2b-201402e141a3
INFO 01-06 08:44:54.470305.470305 client.py:127] Model loaded
DEBUG 01-06 08:44:54.470533.470533 cuda_h.py:19] end wait_experts cost 0.006796598434448242 seconds
DEBUG 01-06 08:44:54.470335.470335 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.470614.470614 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.476685.476685 mlpmodule.py:662]  experts func einsum cost 0.058380842208862305 s
DEBUG 01-06 08:44:54.481919.481919 cuda_h.py:19] end gpu_experts cost 0.011487960815429688 seconds
DEBUG 01-06 08:44:54.481686.481686 cuda_h.py:19] end layer_moe_generate_13 cost 0.07156968116760254 seconds
DEBUG 01-06 08:44:54.482381.482381 lmp.py:221] -------------------------------- end layer 13 --------------------------------
DEBUG 01-06 08:44:54.482813.482813 lmp.py:177] -------------------------------- start layer 14 --------------------------------
DEBUG 01-06 08:44:54.482509.482509 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 08:44:54.482550.482550 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 08:44:54.482956.482956 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:54.482989.482989 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.7220458984375e-05 seconds
DEBUG 01-06 08:44:54.482063.482063 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.482880.482880 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.482598.482598 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.482520.482520 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.482799.482799 cuda_h.py:19] end allocate_cuda_memory cost 0.00020766258239746094 seconds
DEBUG 01-06 08:44:54.482232.482232 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.482611.482611 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.482288.482288 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.482322.482322 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 369d2b28-c0e4-41ba-8b9e-cebe32c552b6
DEBUG 01-06 08:44:54.483099.483099 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.483983.483983 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.484076.484076 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 369d2b28-c0e4-41ba-8b9e-cebe32c552b6
DEBUG 01-06 08:44:54.484363.484363 cuda_h.py:19] end load_into_gpu_async cost 0.0012903213500976562 seconds
DEBUG 01-06 08:44:54.484066.484066 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.484706.484706 cuda_h.py:19] end restore_tensors2 cost 9.250640869140625e-05 seconds
DEBUG 01-06 08:44:54.484475.484475 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018458366394042969 seconds
INFO 01-06 08:44:54.484123.484123 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 369d2b28-c0e4-41ba-8b9e-cebe32c552b6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.487082.487082 cuda_h.py:19] end self_attn cost 0.004081249237060547 seconds
DEBUG 01-06 08:44:54.487341.487341 cuda_h.py:19] end iln_self_attn_paln cost 0.00551152229309082 seconds
DEBUG 01-06 08:44:54.487469.487469 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-06 08:44:54.487424.487424 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.488460.488460 cuda_h.py:19] end gate cost 0.0006592273712158203 seconds
DEBUG 01-06 08:44:54.488098.488098 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.488128.488128 lmp.py:369] 
DEBUG 01-06 08:44:54.488128.488128 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.489122.489122 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.489487.489487 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.489514.489514 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.489157.489157 lmp.py:373] 
DEBUG 01-06 08:44:54.489157.489157 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.489800.489800 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.489927.489927 lmp.py:380]   Expert 35 |      2 | CPU
DEBUG 01-06 08:44:54.489047.489047 lmp.py:380]   Expert  7 |      4 | CPU
DEBUG 01-06 08:44:54.489736.489736 lmp.py:380]   Expert 49 |      5 | CPU
DEBUG 01-06 08:44:54.489664.489664 lmp.py:380]   Expert 59 |      6 | CPU
DEBUG 01-06 08:44:54.489115.489115 lmp.py:380]   Expert 61 |     10 | CPU
DEBUG 01-06 08:44:54.489566.489566 lmp.py:380]   Expert 39 |     26 | CPU
DEBUG 01-06 08:44:54.489540.489540 lmp.py:380]   Expert 50 |     31 | CPU
DEBUG 01-06 08:44:54.489706.489706 lmp.py:380]   Expert 31 |     33 | CPU
DEBUG 01-06 08:44:54.489395.489395 lmp.py:380]   Expert 55 |     33 | CPU
DEBUG 01-06 08:44:54.489323.489323 lmp.py:380]   Expert 60 |     34 | CPU
DEBUG 01-06 08:44:54.489774.489774 lmp.py:380]   Expert 18 |     36 | CPU
DEBUG 01-06 08:44:54.489893.489893 lmp.py:380]   Expert 38 |     44 | CPU
DEBUG 01-06 08:44:54.489060.489060 lmp.py:380]   Expert 52 |     47 | CPU
DEBUG 01-06 08:44:54.489987.489987 lmp.py:380]   Expert 48 |     49 | CPU
DEBUG 01-06 08:44:54.489153.489153 lmp.py:380]   Expert 40 |     50 | CPU
DEBUG 01-06 08:44:54.489796.489796 lmp.py:380]   Expert  0 |     54 | CPU
DEBUG 01-06 08:44:54.489963.489963 lmp.py:380]   Expert 54 |     55 | CPU
DEBUG 01-06 08:44:54.489606.489606 lmp.py:380]   Expert 47 |     62 | CPU
DEBUG 01-06 08:44:54.489010.489010 lmp.py:380]   Expert 51 |     64 | CPU
DEBUG 01-06 08:44:54.489176.489176 lmp.py:380]   Expert 34 |     65 | CPU
DEBUG 01-06 08:44:54.489104.489104 lmp.py:380]   Expert 62 |     79 | CPU
DEBUG 01-06 08:44:54.489555.489555 lmp.py:380]   Expert 32 |     82 | CPU
DEBUG 01-06 08:44:54.489483.489483 lmp.py:380]   Expert 23 |     96 | CPU
DEBUG 01-06 08:44:54.489172.489172 lmp.py:380]   Expert  8 |    106 | CPU
DEBUG 01-06 08:44:54.489576.489576 lmp.py:380]   Expert 29 |    111 | CPU
DEBUG 01-06 08:44:54.489981.489981 lmp.py:380]   Expert 17 |    118 | CPU
DEBUG 01-06 08:44:54.489862.489862 lmp.py:380]   Expert 28 |    120 | CPU
DEBUG 01-06 08:44:54.489029.489029 lmp.py:380]   Expert 12 |    132 | CPU
DEBUG 01-06 08:44:54.489956.489956 lmp.py:380]   Expert 20 |    134 | CPU
DEBUG 01-06 08:44:54.489646.489646 lmp.py:380]   Expert 21 |    136 | CPU
DEBUG 01-06 08:44:54.489825.489825 lmp.py:380]   Expert 43 |    140 | CPU
DEBUG 01-06 08:44:54.489038.489038 lmp.py:380]   Expert  6 |    166 | CPU
DEBUG 01-06 08:44:54.489727.489727 lmp.py:380]   Expert 53 |    166 | GPU
DEBUG 01-06 08:44:54.489655.489655 lmp.py:380]   Expert 58 |    169 | GPU
DEBUG 01-06 08:44:54.489582.489582 lmp.py:380]   Expert 16 |    183 | GPU
DEBUG 01-06 08:44:54.489749.489749 lmp.py:380]   Expert 30 |    189 | GPU
DEBUG 01-06 08:44:54.489438.489438 lmp.py:380]   Expert 42 |    201 | GPU
DEBUG 01-06 08:44:54.489650.489650 lmp.py:380]   Expert 57 |    221 | GPU
DEBUG 01-06 08:44:54.489863.489863 lmp.py:380]   Expert 19 |    225 | GPU
DEBUG 01-06 08:44:54.489075.489075 lmp.py:380]   Expert 45 |    231 | GPU
DEBUG 01-06 08:44:54.489288.489288 lmp.py:380]   Expert 13 |    233 | GPU
DEBUG 01-06 08:44:54.489977.489977 lmp.py:380]   Expert  1 |    237 | GPU
DEBUG 01-06 08:44:54.489190.489190 lmp.py:380]   Expert 41 |    240 | GPU
DEBUG 01-06 08:44:54.489640.489640 lmp.py:380]   Expert 33 |    258 | GPU
DEBUG 01-06 08:44:54.489045.489045 lmp.py:380]   Expert 15 |    273 | GPU
DEBUG 01-06 08:44:54.489734.489734 lmp.py:380]   Expert 22 |    279 | GPU
DEBUG 01-06 08:44:54.489616.489616 lmp.py:380]   Expert 26 |    279 | GPU
DEBUG 01-06 08:44:54.489067.489067 lmp.py:380]   Expert 56 |    279 | GPU
DEBUG 01-06 08:44:54.489517.489517 lmp.py:380]   Expert 44 |    301 | GPU
DEBUG 01-06 08:44:54.489968.489968 lmp.py:380]   Expert 27 |    310 | GPU
DEBUG 01-06 08:44:54.489419.489419 lmp.py:380]   Expert  4 |    313 | GPU
DEBUG 01-06 08:44:54.490870.490870 lmp.py:380]   Expert 24 |    318 | GPU
DEBUG 01-06 08:44:54.490321.490321 lmp.py:380]   Expert 11 |    325 | GPU
DEBUG 01-06 08:44:54.490010.490010 lmp.py:380]   Expert  5 |    358 | GPU
DEBUG 01-06 08:44:54.490415.490415 lmp.py:380]   Expert  9 |    386 | GPU
DEBUG 01-06 08:44:54.490581.490581 lmp.py:380]   Expert  3 |    403 | GPU
DEBUG 01-06 08:44:54.490793.490793 lmp.py:380]   Expert 46 |    412 | GPU
DEBUG 01-06 08:44:54.490244.490244 lmp.py:380]   Expert 25 |    414 | GPU
DEBUG 01-06 08:44:54.490934.490934 lmp.py:380]   Expert  2 |    425 | GPU
DEBUG 01-06 08:44:54.490623.490623 lmp.py:380]   Expert 37 |    443 | GPU
DEBUG 01-06 08:44:54.490312.490312 lmp.py:380]   Expert 36 |    448 | GPU
DEBUG 01-06 08:44:54.490286.490286 lmp.py:380]   Expert 63 |    478 | GPU
DEBUG 01-06 08:44:54.490737.490737 lmp.py:380]   Expert 10 |    527 | GPU
DEBUG 01-06 08:44:54.490426.490426 lmp.py:380]   Expert 14 |    634 | GPU
DEBUG 01-06 08:44:54.490308.490308 lmp.py:381] 
DEBUG 01-06 08:44:54.490308.490308 lmp.py:381]   CPU total tokens: 2130 (17.3%)
DEBUG 01-06 08:44:54.490666.490666 lmp.py:382]   GPU total tokens: 10158 (82.7%)
DEBUG 01-06 08:44:54.490554.490554 cuda_h.py:19] end experts_map_get cost 0.0015368461608886719 seconds
DEBUG 01-06 08:44:54.490436.490436 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.490311.490311 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.490263.490263 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.490821.490821 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-06 08:44:54.490756.490756 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.490036.490036 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.490752.490752 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.490309.490309 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fe226deb-3ff9-443d-bb7f-a01f99b43e31
DEBUG 01-06 08:44:54.491137.491137 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.491044.491044 client.py:127] Model loaded
DEBUG 01-06 08:44:54.491484.491484 cuda_h.py:19] end sllm_worker_task cost 0.00886988639831543 seconds
INFO 01-06 08:44:54.491777.491777 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fe226deb-3ff9-443d-bb7f-a01f99b43e31
DEBUG 01-06 08:44:54.492752.492752 cuda_h.py:19] end load_into_gpu_async cost 0.00122833251953125 seconds
DEBUG 01-06 08:44:54.492978.492978 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.492920.492920 cuda_h.py:19] end restore_tensors2 cost 0.0004208087921142578 seconds
DEBUG 01-06 08:44:54.492664.492664 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022034645080566406 seconds
DEBUG 01-06 08:44:54.495736.495736 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004790782928466797 seconds
DEBUG 01-06 08:44:54.495142.495142 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.495628.495628 lmp.py:427] 
DEBUG 01-06 08:44:54.495628.495628 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.495372.495372 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-06 08:44:54.495711.495711 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.501520.501520 mlpmodule.py:704] group tensors cost 0.0064237117767333984 s
DEBUG 01-06 08:44:54.504249.504249 mlpmodule.py:742] pad cost 0.0022699832916259766 s
DEBUG 01-06 08:44:54.504332.504332 mlpmodule.py:748] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-06 08:44:54.505751.505751 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 08:44:54.516612.516612 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:54.516933.516933 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.516261.516261 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-06 08:44:54.516298.516298 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.535579.535579 mlpmodule.py:793] group einsum cost 0.030375957489013672 s
DEBUG 01-06 08:44:54.536217.536217 mlpmodule.py:801] cpy2cputensor cost 0.0008559226989746094 s
DEBUG 01-06 08:44:54.541354.541354 cuda_h.py:19] end wait_cetm_experts cost 0.04607367515563965 seconds
DEBUG 01-06 08:44:54.541675.541675 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.542514.542514 cuda_h.py:19] end gpu_sexperts cost 0.00046944618225097656 seconds
DEBUG 01-06 08:44:54.542880.542880 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.542876.542876 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:44:54.542009.542009 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.542957.542957 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fe226deb-3ff9-443d-bb7f-a01f99b43e31
DEBUG 01-06 08:44:54.550959.550959 mlpmodule.py:662]  experts func einsum cost 0.055147409439086914 s
INFO 01-06 08:44:54.550417.550417 client.py:127] Model loaded
DEBUG 01-06 08:44:54.550373.550373 cuda_h.py:19] end wait_experts cost 0.008661985397338867 seconds
DEBUG 01-06 08:44:54.550175.550175 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.550024.550024 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.561300.561300 cuda_h.py:19] end gpu_experts cost 0.010412454605102539 seconds
DEBUG 01-06 08:44:54.561643.561643 cuda_h.py:19] end layer_moe_generate_14 cost 0.07358336448669434 seconds
DEBUG 01-06 08:44:54.561523.561523 lmp.py:221] -------------------------------- end layer 14 --------------------------------
DEBUG 01-06 08:44:54.561571.561571 lmp.py:177] -------------------------------- start layer 15 --------------------------------
DEBUG 01-06 08:44:54.561075.561075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 08:44:54.561639.561639 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 08:44:54.561760.561760 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:54.561099.561099 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.2479248046875e-05 seconds
DEBUG 01-06 08:44:54.561695.561695 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.561048.561048 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.562448.562448 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.562662.562662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.562805.562805 cuda_h.py:19] end allocate_cuda_memory cost 0.0002815723419189453 seconds
DEBUG 01-06 08:44:54.562563.562563 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.562803.562803 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.562672.562672 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.562944.562944 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cb51836d-ab95-4fae-ad59-0c4fc6ed4880
DEBUG 01-06 08:44:54.562868.562868 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.563937.563937 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.563972.563972 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cb51836d-ab95-4fae-ad59-0c4fc6ed4880
DEBUG 01-06 08:44:54.563657.563657 cuda_h.py:19] end load_into_gpu_async cost 0.00136566162109375 seconds
DEBUG 01-06 08:44:54.563128.563128 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.564125.564125 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-06 08:44:54.564596.564596 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020067691802978516 seconds
INFO 01-06 08:44:54.564388.564388 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cb51836d-ab95-4fae-ad59-0c4fc6ed4880
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.566732.566732 cuda_h.py:19] end self_attn cost 0.003885030746459961 seconds
DEBUG 01-06 08:44:54.567563.567563 cuda_h.py:19] end iln_self_attn_paln cost 0.00531458854675293 seconds
DEBUG 01-06 08:44:54.567784.567784 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-06 08:44:54.567262.567262 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.568542.568542 cuda_h.py:19] end gate cost 0.000629425048828125 seconds
DEBUG 01-06 08:44:54.568464.568464 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.568421.568421 lmp.py:369] 
DEBUG 01-06 08:44:54.568421.568421 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.568045.568045 lmp.py:370]   Total experts: 62
DEBUG 01-06 08:44:54.568053.568053 lmp.py:371]   CPU experts: 31 (50%)
DEBUG 01-06 08:44:54.568033.568033 lmp.py:372]   GPU experts: 31 (50%)
DEBUG 01-06 08:44:54.568438.568438 lmp.py:373] 
DEBUG 01-06 08:44:54.568438.568438 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.568319.568319 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.568684.568684 lmp.py:380]   Expert  5 |      4 | CPU
DEBUG 01-06 08:44:54.568566.568566 lmp.py:380]   Expert 40 |      7 | CPU
DEBUG 01-06 08:44:54.568494.568494 lmp.py:380]   Expert  4 |     11 | CPU
DEBUG 01-06 08:44:54.568183.568183 lmp.py:380]   Expert 15 |     12 | CPU
DEBUG 01-06 08:44:54.568064.568064 lmp.py:380]   Expert 37 |     27 | CPU
DEBUG 01-06 08:44:54.568184.568184 lmp.py:380]   Expert 57 |     29 | CPU
DEBUG 01-06 08:44:54.568873.568873 lmp.py:380]   Expert 50 |     30 | CPU
DEBUG 01-06 08:44:54.568847.568847 lmp.py:380]   Expert 35 |     31 | CPU
DEBUG 01-06 08:44:54.568060.568060 lmp.py:380]   Expert  7 |     33 | CPU
DEBUG 01-06 08:44:54.568034.568034 lmp.py:380]   Expert 22 |     41 | CPU
DEBUG 01-06 08:44:54.568770.568770 lmp.py:380]   Expert 48 |     46 | CPU
DEBUG 01-06 08:44:54.568982.568982 lmp.py:380]   Expert 42 |     48 | CPU
DEBUG 01-06 08:44:54.568718.568718 lmp.py:380]   Expert 34 |     53 | CPU
DEBUG 01-06 08:44:54.568930.568930 lmp.py:380]   Expert 54 |     56 | CPU
DEBUG 01-06 08:44:54.568143.568143 lmp.py:380]   Expert 12 |     60 | CPU
DEBUG 01-06 08:44:54.568070.568070 lmp.py:380]   Expert 51 |     64 | CPU
DEBUG 01-06 08:44:54.568236.568236 lmp.py:380]   Expert 53 |     64 | CPU
DEBUG 01-06 08:44:54.568449.568449 lmp.py:380]   Expert 52 |     66 | CPU
DEBUG 01-06 08:44:54.568661.568661 lmp.py:380]   Expert 39 |     77 | CPU
DEBUG 01-06 08:44:54.568874.568874 lmp.py:380]   Expert 10 |     82 | CPU
DEBUG 01-06 08:44:54.568848.568848 lmp.py:380]   Expert 43 |     86 | CPU
DEBUG 01-06 08:44:54.568822.568822 lmp.py:380]   Expert  2 |     88 | CPU
DEBUG 01-06 08:44:54.568796.568796 lmp.py:380]   Expert 25 |    110 | CPU
DEBUG 01-06 08:44:54.568770.568770 lmp.py:380]   Expert 61 |    116 | CPU
DEBUG 01-06 08:44:54.568744.568744 lmp.py:380]   Expert 45 |    117 | CPU
DEBUG 01-06 08:44:54.568480.568480 lmp.py:380]   Expert 55 |    120 | CPU
DEBUG 01-06 08:44:54.568169.568169 lmp.py:380]   Expert 32 |    123 | CPU
DEBUG 01-06 08:44:54.568335.568335 lmp.py:380]   Expert 58 |    131 | CPU
DEBUG 01-06 08:44:54.568548.568548 lmp.py:380]   Expert 29 |    141 | CPU
DEBUG 01-06 08:44:54.568283.568283 lmp.py:380]   Expert 49 |    146 | CPU
DEBUG 01-06 08:44:54.569257.569257 lmp.py:380]   Expert 38 |    171 | CPU
DEBUG 01-06 08:44:54.569231.569231 lmp.py:380]   Expert  0 |    172 | GPU
DEBUG 01-06 08:44:54.569205.569205 lmp.py:380]   Expert 13 |    174 | GPU
DEBUG 01-06 08:44:54.569610.569610 lmp.py:380]   Expert 56 |    178 | GPU
DEBUG 01-06 08:44:54.569776.569776 lmp.py:380]   Expert 23 |    188 | GPU
DEBUG 01-06 08:44:54.569704.569704 lmp.py:380]   Expert 31 |    204 | GPU
DEBUG 01-06 08:44:54.569631.569631 lmp.py:380]   Expert 47 |    204 | GPU
DEBUG 01-06 08:44:54.569274.569274 lmp.py:380]   Expert 33 |    206 | GPU
DEBUG 01-06 08:44:54.569679.569679 lmp.py:380]   Expert 14 |    208 | GPU
DEBUG 01-06 08:44:54.569560.569560 lmp.py:380]   Expert 20 |    213 | GPU
DEBUG 01-06 08:44:54.569727.569727 lmp.py:380]   Expert 28 |    227 | GPU
DEBUG 01-06 08:44:54.569416.569416 lmp.py:380]   Expert 11 |    232 | GPU
DEBUG 01-06 08:44:54.569105.569105 lmp.py:380]   Expert  6 |    233 | GPU
DEBUG 01-06 08:44:54.569033.569033 lmp.py:380]   Expert 26 |    244 | GPU
DEBUG 01-06 08:44:54.569961.569961 lmp.py:380]   Expert 59 |    244 | GPU
DEBUG 01-06 08:44:54.569650.569650 lmp.py:380]   Expert 30 |    254 | GPU
DEBUG 01-06 08:44:54.569816.569816 lmp.py:380]   Expert  1 |    275 | GPU
DEBUG 01-06 08:44:54.569744.569744 lmp.py:380]   Expert 36 |    281 | GPU
DEBUG 01-06 08:44:54.569625.569625 lmp.py:380]   Expert 44 |    285 | GPU
DEBUG 01-06 08:44:54.569506.569506 lmp.py:380]   Expert  9 |    310 | GPU
DEBUG 01-06 08:44:54.569434.569434 lmp.py:380]   Expert 62 |    314 | GPU
DEBUG 01-06 08:44:54.569362.569362 lmp.py:380]   Expert 17 |    345 | GPU
DEBUG 01-06 08:44:54.569290.569290 lmp.py:380]   Expert 46 |    347 | GPU
DEBUG 01-06 08:44:54.569456.569456 lmp.py:380]   Expert 24 |    370 | GPU
DEBUG 01-06 08:44:54.569860.569860 lmp.py:380]   Expert 19 |    404 | GPU
DEBUG 01-06 08:44:54.569788.569788 lmp.py:380]   Expert  3 |    423 | GPU
DEBUG 01-06 08:44:54.569239.569239 lmp.py:380]   Expert 60 |    449 | GPU
DEBUG 01-06 08:44:54.569643.569643 lmp.py:380]   Expert 18 |    494 | GPU
DEBUG 01-06 08:44:54.569286.569286 lmp.py:380]   Expert  8 |    629 | GPU
DEBUG 01-06 08:44:54.569691.569691 lmp.py:380]   Expert 21 |    633 | GPU
DEBUG 01-06 08:44:54.569619.569619 lmp.py:380]   Expert 16 |    649 | GPU
DEBUG 01-06 08:44:54.569546.569546 lmp.py:380]   Expert 27 |    709 | GPU
DEBUG 01-06 08:44:54.569666.569666 lmp.py:381] 
DEBUG 01-06 08:44:54.569666.569666 lmp.py:381]   CPU total tokens: 2190 (17.8%)
DEBUG 01-06 08:44:54.569025.569025 lmp.py:382]   GPU total tokens: 10098 (82.2%)
DEBUG 01-06 08:44:54.569674.569674 cuda_h.py:19] end experts_map_get cost 0.0014960765838623047 seconds
DEBUG 01-06 08:44:54.569033.569033 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.569193.569193 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.569476.569476 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.570083.570083 cuda_h.py:19] end allocate_cuda_memory cost 0.0004830360412597656 seconds
DEBUG 01-06 08:44:54.570992.570992 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.570656.570656 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.570273.570273 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.570399.570399 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 366cc01e-72fa-4b5b-a19f-57775d51e63b
DEBUG 01-06 08:44:54.570896.570896 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.570007.570007 client.py:127] Model loaded
DEBUG 01-06 08:44:54.570771.570771 cuda_h.py:19] end sllm_worker_task cost 0.008841514587402344 seconds
INFO 01-06 08:44:54.571077.571077 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 366cc01e-72fa-4b5b-a19f-57775d51e63b
DEBUG 01-06 08:44:54.571874.571874 cuda_h.py:19] end load_into_gpu_async cost 0.0011763572692871094 seconds
DEBUG 01-06 08:44:54.571338.571338 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.572087.572087 cuda_h.py:19] end restore_tensors2 cost 0.0003848075866699219 seconds
DEBUG 01-06 08:44:54.572539.572539 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024085044860839844 seconds
DEBUG 01-06 08:44:54.574240.574240 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049703121185302734 seconds
DEBUG 01-06 08:44:54.574791.574791 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.574821.574821 lmp.py:427] 
DEBUG 01-06 08:44:54.574821.574821 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:54.574756.574756 cuda_h.py:19] end cpu_experts_submit cost 0.00010514259338378906 seconds
DEBUG 01-06 08:44:54.574360.574360 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.582771.582771 mlpmodule.py:704] group tensors cost 0.007367849349975586 s
DEBUG 01-06 08:44:54.585354.585354 mlpmodule.py:742] pad cost 0.002557992935180664 s
DEBUG 01-06 08:44:54.585412.585412 mlpmodule.py:748] create cpu tensor cost 6.008148193359375e-05 s
DEBUG 01-06 08:44:54.586310.586310 mlpmodule.py:753] move to cpu cost 4.458427429199219e-05 s
DEBUG 01-06 08:44:54.596863.596863 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:54.597478.597478 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.597759.597759 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-06 08:44:54.597929.597929 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.613648.613648 mlpmodule.py:793] group einsum cost 0.027025699615478516 s
DEBUG 01-06 08:44:54.614831.614831 mlpmodule.py:801] cpy2cputensor cost 0.0006937980651855469 s
DEBUG 01-06 08:44:54.618942.618942 cuda_h.py:19] end wait_cetm_experts cost 0.04380440711975098 seconds
DEBUG 01-06 08:44:54.618648.618648 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.619889.619889 cuda_h.py:19] end gpu_sexperts cost 0.0008337497711181641 seconds
DEBUG 01-06 08:44:54.619123.619123 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.619549.619549 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:44:54.619636.619636 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.619876.619876 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 366cc01e-72fa-4b5b-a19f-57775d51e63b
INFO 01-06 08:44:54.628632.628632 client.py:127] Model loaded
DEBUG 01-06 08:44:54.628291.628291 cuda_h.py:19] end wait_experts cost 0.008621692657470703 seconds
DEBUG 01-06 08:44:54.628715.628715 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.628803.628803 lmp.py:472]   Computing 31 experts on GPU...
DEBUG 01-06 08:44:54.628119.628119 mlpmodule.py:662]  experts func einsum cost 0.05377840995788574 s
DEBUG 01-06 08:44:54.639177.639177 cuda_h.py:19] end gpu_experts cost 0.011360883712768555 seconds
DEBUG 01-06 08:44:54.640023.640023 cuda_h.py:19] end layer_moe_generate_15 cost 0.07278990745544434 seconds
DEBUG 01-06 08:44:54.640271.640271 lmp.py:221] -------------------------------- end layer 15 --------------------------------
DEBUG 01-06 08:44:54.640048.640048 lmp.py:177] -------------------------------- start layer 16 --------------------------------
DEBUG 01-06 08:44:54.640651.640651 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 08:44:54.640030.640030 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 08:44:54.640681.640681 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:54.640953.640953 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.103515625e-05 seconds
DEBUG 01-06 08:44:54.640788.640788 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.640626.640626 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.640350.640350 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.640339.640339 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.641743.641743 cuda_h.py:19] end allocate_cuda_memory cost 0.0003666877746582031 seconds
DEBUG 01-06 08:44:54.641819.641819 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.641681.641681 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.641087.641087 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.641128.641128 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7938e54e-b78b-477c-98d4-ebbd82416b9f
DEBUG 01-06 08:44:54.641363.641363 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.641182.641182 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.642739.642739 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7938e54e-b78b-477c-98d4-ebbd82416b9f
DEBUG 01-06 08:44:54.642158.642158 cuda_h.py:19] end load_into_gpu_async cost 0.001188516616821289 seconds
DEBUG 01-06 08:44:54.642484.642484 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.642832.642832 cuda_h.py:19] end restore_tensors2 cost 8.702278137207031e-05 seconds
DEBUG 01-06 08:44:54.642449.642449 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019352436065673828 seconds
INFO 01-06 08:44:54.643762.643762 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7938e54e-b78b-477c-98d4-ebbd82416b9f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.646738.646738 cuda_h.py:19] end self_attn cost 0.0042722225189208984 seconds
DEBUG 01-06 08:44:54.646450.646450 cuda_h.py:19] end iln_self_attn_paln cost 0.005901813507080078 seconds
DEBUG 01-06 08:44:54.646148.646148 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-06 08:44:54.646579.646579 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.647823.647823 cuda_h.py:19] end gate cost 0.0007069110870361328 seconds
DEBUG 01-06 08:44:54.647844.647844 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.647423.647423 lmp.py:369] 
DEBUG 01-06 08:44:54.647423.647423 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.647703.647703 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:54.647352.647352 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:54.647664.647664 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:54.647354.647354 lmp.py:373] 
DEBUG 01-06 08:44:54.647354.647354 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.647235.647235 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.647885.647885 lmp.py:380]   Expert 58 |     23 | CPU
DEBUG 01-06 08:44:54.647289.647289 lmp.py:380]   Expert 43 |     24 | CPU
DEBUG 01-06 08:44:54.647979.647979 lmp.py:380]   Expert 47 |     31 | CPU
DEBUG 01-06 08:44:54.647714.647714 lmp.py:380]   Expert 60 |     33 | CPU
DEBUG 01-06 08:44:54.647927.647927 lmp.py:380]   Expert 56 |     38 | CPU
DEBUG 01-06 08:44:54.647901.647901 lmp.py:380]   Expert 10 |     39 | CPU
DEBUG 01-06 08:44:54.647636.647636 lmp.py:380]   Expert 32 |     42 | CPU
DEBUG 01-06 08:44:54.647610.647610 lmp.py:380]   Expert 13 |     53 | CPU
DEBUG 01-06 08:44:54.648253.648253 lmp.py:380]   Expert 62 |     57 | CPU
DEBUG 01-06 08:44:54.648420.648420 lmp.py:380]   Expert 38 |     61 | CPU
DEBUG 01-06 08:44:54.648063.648063 lmp.py:380]   Expert 63 |     62 | CPU
DEBUG 01-06 08:44:54.648182.648182 lmp.py:380]   Expert 39 |     69 | CPU
DEBUG 01-06 08:44:54.648587.648587 lmp.py:380]   Expert 45 |     70 | CPU
DEBUG 01-06 08:44:54.648753.648753 lmp.py:380]   Expert 28 |     74 | CPU
DEBUG 01-06 08:44:54.648681.648681 lmp.py:380]   Expert 34 |     77 | CPU
DEBUG 01-06 08:44:54.648608.648608 lmp.py:380]   Expert 50 |     81 | CPU
DEBUG 01-06 08:44:54.648298.648298 lmp.py:380]   Expert 25 |     82 | CPU
DEBUG 01-06 08:44:54.648464.648464 lmp.py:380]   Expert 49 |     83 | CPU
DEBUG 01-06 08:44:54.648676.648676 lmp.py:380]   Expert 15 |     86 | CPU
DEBUG 01-06 08:44:54.648127.648127 lmp.py:380]   Expert 14 |     92 | CPU
DEBUG 01-06 08:44:54.648817.648817 lmp.py:380]   Expert 54 |     93 | CPU
DEBUG 01-06 08:44:54.648506.648506 lmp.py:380]   Expert 11 |     95 | CPU
DEBUG 01-06 08:44:54.648102.648102 lmp.py:380]   Expert 17 |    102 | CPU
DEBUG 01-06 08:44:54.648984.648984 lmp.py:380]   Expert 35 |    105 | CPU
DEBUG 01-06 08:44:54.648865.648865 lmp.py:380]   Expert  0 |    106 | CPU
DEBUG 01-06 08:44:54.648508.648508 lmp.py:380]   Expert 59 |    107 | CPU
DEBUG 01-06 08:44:54.648436.648436 lmp.py:380]   Expert 18 |    108 | CPU
DEBUG 01-06 08:44:54.648364.648364 lmp.py:380]   Expert 44 |    113 | CPU
DEBUG 01-06 08:44:54.648053.648053 lmp.py:380]   Expert 46 |    117 | CPU
DEBUG 01-06 08:44:54.648219.648219 lmp.py:380]   Expert 36 |    120 | CPU
DEBUG 01-06 08:44:54.648823.648823 lmp.py:380]   Expert 31 |    122 | CPU
DEBUG 01-06 08:44:54.648201.648201 lmp.py:380]   Expert 33 |    122 | GPU
DEBUG 01-06 08:44:54.648321.648321 lmp.py:380]   Expert 42 |    140 | GPU
DEBUG 01-06 08:44:54.648441.648441 lmp.py:380]   Expert 61 |    146 | GPU
DEBUG 01-06 08:44:54.648799.648799 lmp.py:380]   Expert 12 |    147 | GPU
DEBUG 01-06 08:44:54.648396.648396 lmp.py:380]   Expert  6 |    148 | GPU
DEBUG 01-06 08:44:54.648515.648515 lmp.py:380]   Expert  2 |    154 | GPU
DEBUG 01-06 08:44:54.648158.648158 lmp.py:380]   Expert 30 |    159 | GPU
DEBUG 01-06 08:44:54.648325.648325 lmp.py:380]   Expert 24 |    171 | GPU
DEBUG 01-06 08:44:54.648252.648252 lmp.py:380]   Expert 21 |    172 | GPU
DEBUG 01-06 08:44:54.648657.648657 lmp.py:380]   Expert 26 |    183 | GPU
DEBUG 01-06 08:44:54.648346.648346 lmp.py:380]   Expert 53 |    219 | GPU
DEBUG 01-06 08:44:54.648751.648751 lmp.py:380]   Expert  7 |    221 | GPU
DEBUG 01-06 08:44:54.648155.648155 lmp.py:380]   Expert 20 |    231 | GPU
DEBUG 01-06 08:44:54.648083.648083 lmp.py:380]   Expert 55 |    245 | GPU
DEBUG 01-06 08:44:54.648726.648726 lmp.py:380]   Expert 57 |    254 | GPU
DEBUG 01-06 08:44:54.648892.648892 lmp.py:380]   Expert  4 |    275 | GPU
DEBUG 01-06 08:44:54.648535.648535 lmp.py:380]   Expert 48 |    275 | GPU
DEBUG 01-06 08:44:54.648178.648178 lmp.py:380]   Expert  9 |    301 | GPU
DEBUG 01-06 08:44:54.648536.648536 lmp.py:380]   Expert  1 |    318 | GPU
DEBUG 01-06 08:44:54.648941.648941 lmp.py:380]   Expert 37 |    325 | GPU
DEBUG 01-06 08:44:54.648345.648345 lmp.py:380]   Expert 22 |    359 | GPU
DEBUG 01-06 08:44:54.648512.648512 lmp.py:380]   Expert 40 |    377 | GPU
DEBUG 01-06 08:44:54.648678.648678 lmp.py:380]   Expert 51 |    386 | GPU
DEBUG 01-06 08:44:54.648844.648844 lmp.py:380]   Expert  3 |    392 | GPU
DEBUG 01-06 08:44:54.648010.648010 lmp.py:380]   Expert 19 |    396 | GPU
DEBUG 01-06 08:44:54.648938.648938 lmp.py:380]   Expert 16 |    399 | GPU
DEBUG 01-06 08:44:54.648104.648104 lmp.py:380]   Expert 52 |    449 | GPU
DEBUG 01-06 08:44:54.648032.648032 lmp.py:380]   Expert 29 |    485 | GPU
DEBUG 01-06 08:44:54.648675.648675 lmp.py:380]   Expert  5 |    515 | GPU
DEBUG 01-06 08:44:54.648271.648271 lmp.py:380]   Expert 27 |    574 | GPU
DEBUG 01-06 08:44:54.648391.648391 lmp.py:380]   Expert  8 |    658 | GPU
DEBUG 01-06 08:44:54.648749.648749 lmp.py:380]   Expert 23 |    727 | GPU
DEBUG 01-06 08:44:54.648061.648061 lmp.py:381] 
DEBUG 01-06 08:44:54.648061.648061 lmp.py:381]   CPU total tokens: 2365 (19.2%)
DEBUG 01-06 08:44:54.649896.649896 lmp.py:382]   GPU total tokens: 9923 (80.8%)
DEBUG 01-06 08:44:54.649023.649023 cuda_h.py:19] end experts_map_get cost 0.001542806625366211 seconds
DEBUG 01-06 08:44:54.649381.649381 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.649979.649979 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.649097.649097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.649695.649695 cuda_h.py:19] end allocate_cuda_memory cost 0.00023102760314941406 seconds
DEBUG 01-06 08:44:54.649353.649353 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.649109.649109 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.649686.649686 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.649290.649290 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 434ea7ed-e90a-4aa0-a7da-ac2277b7ba3b
DEBUG 01-06 08:44:54.649272.649272 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.650242.650242 client.py:127] Model loaded
DEBUG 01-06 08:44:54.650214.650214 cuda_h.py:19] end sllm_worker_task cost 0.009381532669067383 seconds
INFO 01-06 08:44:54.651487.651487 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 434ea7ed-e90a-4aa0-a7da-ac2277b7ba3b
DEBUG 01-06 08:44:54.651237.651237 cuda_h.py:19] end load_into_gpu_async cost 0.0014600753784179688 seconds
DEBUG 01-06 08:44:54.651609.651609 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.651621.651621 cuda_h.py:19] end restore_tensors2 cost 0.0007171630859375 seconds
DEBUG 01-06 08:44:54.651517.651517 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027925968170166016 seconds
DEBUG 01-06 08:44:54.654149.654149 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0054857730865478516 seconds
DEBUG 01-06 08:44:54.654562.654562 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.654744.654744 lmp.py:427] 
DEBUG 01-06 08:44:54.654744.654744 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:54.654448.654448 cuda_h.py:19] end cpu_experts_submit cost 0.00011754035949707031 seconds
DEBUG 01-06 08:44:54.654814.654814 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.667991.667991 mlpmodule.py:704] group tensors cost 0.012610673904418945 s
DEBUG 01-06 08:44:54.669529.669529 mlpmodule.py:742] pad cost 0.0015170574188232422 s
DEBUG 01-06 08:44:54.669472.669472 mlpmodule.py:748] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-06 08:44:54.670422.670422 mlpmodule.py:753] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-06 08:44:54.678445.678445 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:54.678173.678173 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.678216.678216 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-06 08:44:54.678698.678698 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.694116.694116 mlpmodule.py:793] group einsum cost 0.02402949333190918 s
DEBUG 01-06 08:44:54.694143.694143 mlpmodule.py:801] cpy2cputensor cost 0.0005772113800048828 s
DEBUG 01-06 08:44:54.699718.699718 cuda_h.py:19] end wait_cetm_experts cost 0.0449678897857666 seconds
DEBUG 01-06 08:44:54.699000.699000 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.700296.700296 cuda_h.py:19] end gpu_sexperts cost 0.0004901885986328125 seconds
DEBUG 01-06 08:44:54.700900.700900 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.700009.700009 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-06 08:44:54.700381.700381 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.700375.700375 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 434ea7ed-e90a-4aa0-a7da-ac2277b7ba3b
INFO 01-06 08:44:54.706798.706798 client.py:127] Model loaded
DEBUG 01-06 08:44:54.706218.706218 cuda_h.py:19] end wait_experts cost 0.0061686038970947266 seconds
DEBUG 01-06 08:44:54.706543.706543 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.706537.706537 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.707884.707884 mlpmodule.py:662]  experts func einsum cost 0.05275106430053711 s
DEBUG 01-06 08:44:54.718917.718917 cuda_h.py:19] end gpu_experts cost 0.011123895645141602 seconds
DEBUG 01-06 08:44:54.718119.718119 cuda_h.py:19] end layer_moe_generate_16 cost 0.07150387763977051 seconds
DEBUG 01-06 08:44:54.718264.718264 lmp.py:221] -------------------------------- end layer 16 --------------------------------
DEBUG 01-06 08:44:54.718312.718312 lmp.py:177] -------------------------------- start layer 17 --------------------------------
DEBUG 01-06 08:44:54.718054.718054 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 08:44:54.718618.718618 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 08:44:54.718547.718547 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:54.718363.718363 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.176399230957031e-05 seconds
DEBUG 01-06 08:44:54.718721.718721 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.718307.718307 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.718415.718415 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.718020.718020 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.719945.719945 cuda_h.py:19] end allocate_cuda_memory cost 0.0002913475036621094 seconds
DEBUG 01-06 08:44:54.719438.719438 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.719499.719499 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.719441.719441 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.719436.719436 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 148eb417-ab1a-4beb-9ffa-eff31e06888a
DEBUG 01-06 08:44:54.719134.719134 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.719083.719083 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.720309.720309 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 148eb417-ab1a-4beb-9ffa-eff31e06888a
DEBUG 01-06 08:44:54.720557.720557 cuda_h.py:19] end load_into_gpu_async cost 0.001346588134765625 seconds
DEBUG 01-06 08:44:54.720075.720075 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.720078.720078 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-06 08:44:54.720556.720556 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019974708557128906 seconds
INFO 01-06 08:44:54.721661.721661 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 148eb417-ab1a-4beb-9ffa-eff31e06888a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.723330.723330 cuda_h.py:19] end self_attn cost 0.003943920135498047 seconds
DEBUG 01-06 08:44:54.724115.724115 cuda_h.py:19] end iln_self_attn_paln cost 0.00559544563293457 seconds
DEBUG 01-06 08:44:54.724150.724150 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-06 08:44:54.724012.724012 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.724625.724625 cuda_h.py:19] end gate cost 0.0006613731384277344 seconds
DEBUG 01-06 08:44:54.725454.725454 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.725623.725623 lmp.py:369] 
DEBUG 01-06 08:44:54.725623.725623 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.725141.725141 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.725744.725744 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.725772.725772 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.725653.725653 lmp.py:373] 
DEBUG 01-06 08:44:54.725653.725653 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.725296.725296 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.725184.725184 lmp.py:380]   Expert 52 |     17 | CPU
DEBUG 01-06 08:44:54.725304.725304 lmp.py:380]   Expert 47 |     24 | CPU
DEBUG 01-06 08:44:54.725755.725755 lmp.py:380]   Expert 60 |     43 | CPU
DEBUG 01-06 08:44:54.725206.725206 lmp.py:380]   Expert 28 |     51 | CPU
DEBUG 01-06 08:44:54.725657.725657 lmp.py:380]   Expert 58 |     52 | CPU
DEBUG 01-06 08:44:54.725108.725108 lmp.py:380]   Expert  8 |     54 | CPU
DEBUG 01-06 08:44:54.725512.725512 lmp.py:380]   Expert 40 |     56 | CPU
DEBUG 01-06 08:44:54.725201.725201 lmp.py:380]   Expert 39 |     63 | CPU
DEBUG 01-06 08:44:54.725606.725606 lmp.py:380]   Expert  2 |     66 | CPU
DEBUG 01-06 08:44:54.725070.725070 lmp.py:380]   Expert  7 |     66 | CPU
DEBUG 01-06 08:44:54.725044.725044 lmp.py:380]   Expert  1 |     68 | CPU
DEBUG 01-06 08:44:54.725542.725542 lmp.py:380]   Expert 36 |     77 | CPU
DEBUG 01-06 08:44:54.725277.725277 lmp.py:380]   Expert 31 |     78 | CPU
DEBUG 01-06 08:44:54.725013.725013 lmp.py:380]   Expert 43 |     78 | CPU
DEBUG 01-06 08:44:54.725987.725987 lmp.py:380]   Expert 29 |     86 | CPU
DEBUG 01-06 08:44:54.725484.725484 lmp.py:380]   Expert 14 |     87 | CPU
DEBUG 01-06 08:44:54.725081.725081 lmp.py:380]   Expert 46 |     94 | CPU
DEBUG 01-06 08:44:54.725724.725724 lmp.py:380]   Expert 61 |     94 | CPU
DEBUG 01-06 08:44:54.725890.725890 lmp.py:380]   Expert 54 |    102 | CPU
DEBUG 01-06 08:44:54.725533.725533 lmp.py:380]   Expert  6 |    107 | CPU
DEBUG 01-06 08:44:54.725461.725461 lmp.py:380]   Expert 30 |    117 | CPU
DEBUG 01-06 08:44:54.725673.725673 lmp.py:380]   Expert 32 |    121 | CPU
DEBUG 01-06 08:44:54.725124.725124 lmp.py:380]   Expert 50 |    121 | CPU
DEBUG 01-06 08:44:54.725813.725813 lmp.py:380]   Expert  9 |    127 | CPU
DEBUG 01-06 08:44:54.725503.725503 lmp.py:380]   Expert 37 |    132 | CPU
DEBUG 01-06 08:44:54.725477.725477 lmp.py:380]   Expert 25 |    135 | CPU
DEBUG 01-06 08:44:54.725166.725166 lmp.py:380]   Expert 35 |    143 | CPU
DEBUG 01-06 08:44:54.725855.725855 lmp.py:380]   Expert 51 |    149 | CPU
DEBUG 01-06 08:44:54.725783.725783 lmp.py:380]   Expert  3 |    154 | CPU
DEBUG 01-06 08:44:54.725711.725711 lmp.py:380]   Expert  0 |    159 | CPU
DEBUG 01-06 08:44:54.725115.725115 lmp.py:380]   Expert 34 |    167 | CPU
DEBUG 01-06 08:44:54.725328.725328 lmp.py:380]   Expert 33 |    171 | CPU
DEBUG 01-06 08:44:54.725779.725779 lmp.py:380]   Expert 23 |    177 | GPU
DEBUG 01-06 08:44:54.726229.726229 lmp.py:380]   Expert 56 |    178 | GPU
DEBUG 01-06 08:44:54.726680.726680 lmp.py:380]   Expert 24 |    183 | GPU
DEBUG 01-06 08:44:54.726370.726370 lmp.py:380]   Expert 10 |    187 | GPU
DEBUG 01-06 08:44:54.726059.726059 lmp.py:380]   Expert 63 |    190 | GPU
DEBUG 01-06 08:44:54.726510.726510 lmp.py:380]   Expert 16 |    191 | GPU
DEBUG 01-06 08:44:54.726961.726961 lmp.py:380]   Expert  4 |    206 | GPU
DEBUG 01-06 08:44:54.726173.726173 lmp.py:380]   Expert 18 |    225 | GPU
DEBUG 01-06 08:44:54.726862.726862 lmp.py:380]   Expert 20 |    233 | GPU
DEBUG 01-06 08:44:54.726075.726075 lmp.py:380]   Expert 26 |    238 | GPU
DEBUG 01-06 08:44:54.726526.726526 lmp.py:380]   Expert 44 |    240 | GPU
DEBUG 01-06 08:44:54.726977.726977 lmp.py:380]   Expert 53 |    257 | GPU
DEBUG 01-06 08:44:54.726428.726428 lmp.py:380]   Expert 49 |    265 | GPU
DEBUG 01-06 08:44:54.726071.726071 lmp.py:380]   Expert 27 |    271 | GPU
DEBUG 01-06 08:44:54.726475.726475 lmp.py:380]   Expert 15 |    277 | GPU
DEBUG 01-06 08:44:54.726880.726880 lmp.py:380]   Expert 48 |    280 | GPU
DEBUG 01-06 08:44:54.726807.726807 lmp.py:380]   Expert 38 |    289 | GPU
DEBUG 01-06 08:44:54.726258.726258 lmp.py:380]   Expert 22 |    293 | GPU
DEBUG 01-06 08:44:54.726709.726709 lmp.py:380]   Expert  5 |    296 | GPU
DEBUG 01-06 08:44:54.726398.726398 lmp.py:380]   Expert 11 |    296 | GPU
DEBUG 01-06 08:44:54.726088.726088 lmp.py:380]   Expert 12 |    306 | GPU
DEBUG 01-06 08:44:54.726777.726777 lmp.py:380]   Expert 55 |    309 | GPU
DEBUG 01-06 08:44:54.726228.726228 lmp.py:380]   Expert 59 |    324 | GPU
DEBUG 01-06 08:44:54.726679.726679 lmp.py:380]   Expert 45 |    328 | GPU
DEBUG 01-06 08:44:54.726606.726606 lmp.py:380]   Expert 42 |    335 | GPU
DEBUG 01-06 08:44:54.726773.726773 lmp.py:380]   Expert 21 |    366 | GPU
DEBUG 01-06 08:44:54.726416.726416 lmp.py:380]   Expert 41 |    366 | GPU
DEBUG 01-06 08:44:54.726820.726820 lmp.py:380]   Expert 62 |    367 | GPU
DEBUG 01-06 08:44:54.726271.726271 lmp.py:380]   Expert 13 |    378 | GPU
DEBUG 01-06 08:44:54.726722.726722 lmp.py:380]   Expert 57 |    379 | GPU
DEBUG 01-06 08:44:54.726173.726173 lmp.py:380]   Expert 19 |    396 | GPU
DEBUG 01-06 08:44:54.726624.726624 lmp.py:380]   Expert 17 |    603 | GPU
DEBUG 01-06 08:44:54.726790.726790 lmp.py:381] 
DEBUG 01-06 08:44:54.726790.726790 lmp.py:381]   CPU total tokens: 3059 (24.9%)
DEBUG 01-06 08:44:54.726433.726433 lmp.py:382]   GPU total tokens: 9229 (75.1%)
DEBUG 01-06 08:44:54.726606.726606 cuda_h.py:19] end experts_map_get cost 0.0015223026275634766 seconds
DEBUG 01-06 08:44:54.726202.726202 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.726701.726701 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.726375.726375 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.727873.727873 cuda_h.py:19] end allocate_cuda_memory cost 0.00022864341735839844 seconds
DEBUG 01-06 08:44:54.727670.727670 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.727956.727956 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.727673.727673 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.727991.727991 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fcea98a4-ebd0-4f0f-83ac-b2d1a7dfd73c
DEBUG 01-06 08:44:54.727675.727675 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.727416.727416 client.py:127] Model loaded
DEBUG 01-06 08:44:54.727835.727835 cuda_h.py:19] end sllm_worker_task cost 0.008985519409179688 seconds
INFO 01-06 08:44:54.728930.728930 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fcea98a4-ebd0-4f0f-83ac-b2d1a7dfd73c
DEBUG 01-06 08:44:54.728595.728595 cuda_h.py:19] end load_into_gpu_async cost 0.00128173828125 seconds
DEBUG 01-06 08:44:54.728728.728728 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.729787.729787 cuda_h.py:19] end restore_tensors2 cost 0.00054168701171875 seconds
DEBUG 01-06 08:44:54.729484.729484 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024139881134033203 seconds
DEBUG 01-06 08:44:54.731022.731022 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00507044792175293 seconds
DEBUG 01-06 08:44:54.731886.731886 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.731471.731471 lmp.py:427] 
DEBUG 01-06 08:44:54.731471.731471 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.731314.731314 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 08:44:54.731156.731156 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.744121.744121 mlpmodule.py:704] group tensors cost 0.012024402618408203 s
DEBUG 01-06 08:44:54.747932.747932 mlpmodule.py:742] pad cost 0.002634763717651367 s
DEBUG 01-06 08:44:54.747771.747771 mlpmodule.py:748] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-06 08:44:54.747701.747701 mlpmodule.py:753] move to cpu cost 3.814697265625e-05 s
DEBUG 01-06 08:44:54.760112.760112 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:54.761217.761217 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.761022.761022 mlpmodule.py:773] group_w3 first element: -0.047119140625
WARNING 01-06 08:44:54.761914.761914 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.781974.781974 mlpmodule.py:793] group einsum cost 0.033957719802856445 s
DEBUG 01-06 08:44:54.782574.782574 mlpmodule.py:801] cpy2cputensor cost 0.0007295608520507812 s
DEBUG 01-06 08:44:54.787650.787650 cuda_h.py:19] end wait_cetm_experts cost 0.05565762519836426 seconds
DEBUG 01-06 08:44:54.787467.787467 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.788650.788650 cuda_h.py:19] end gpu_sexperts cost 0.0004775524139404297 seconds
DEBUG 01-06 08:44:54.788447.788447 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.788966.788966 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:54.788881.788881 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.788544.788544 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fcea98a4-ebd0-4f0f-83ac-b2d1a7dfd73c
INFO 01-06 08:44:54.789509.789509 client.py:127] Model loaded
DEBUG 01-06 08:44:54.789683.789683 cuda_h.py:19] end wait_experts cost 0.0009808540344238281 seconds
DEBUG 01-06 08:44:54.789817.789817 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.789096.789096 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.795659.795659 mlpmodule.py:662]  experts func einsum cost 0.06374335289001465 s
DEBUG 01-06 08:44:54.801558.801558 cuda_h.py:19] end gpu_experts cost 0.011816263198852539 seconds
DEBUG 01-06 08:44:54.801536.801536 cuda_h.py:19] end layer_moe_generate_17 cost 0.07714533805847168 seconds
DEBUG 01-06 08:44:54.801960.801960 lmp.py:221] -------------------------------- end layer 17 --------------------------------
DEBUG 01-06 08:44:54.801769.801769 lmp.py:177] -------------------------------- start layer 18 --------------------------------
DEBUG 01-06 08:44:54.801034.801034 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 08:44:54.801360.801360 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 08:44:54.801050.801050 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.765655517578125e-05 seconds
DEBUG 01-06 08:44:54.801820.801820 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.319450378417969e-05 seconds
DEBUG 01-06 08:44:54.801940.801940 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.801042.801042 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.801759.801759 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.802880.802880 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.802162.802162 cuda_h.py:19] end allocate_cuda_memory cost 0.0002796649932861328 seconds
DEBUG 01-06 08:44:54.802609.802609 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.802656.802656 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.802208.802208 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.802864.802864 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5a5577d9-aed4-4ffc-9b56-5dd1b2a91bc9
DEBUG 01-06 08:44:54.802119.802119 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.802232.802232 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.803339.803339 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5a5577d9-aed4-4ffc-9b56-5dd1b2a91bc9
DEBUG 01-06 08:44:54.803745.803745 cuda_h.py:19] end load_into_gpu_async cost 0.0012586116790771484 seconds
DEBUG 01-06 08:44:54.803017.803017 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.803915.803915 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-06 08:44:54.803671.803671 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001867055892944336 seconds
INFO 01-06 08:44:54.804264.804264 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5a5577d9-aed4-4ffc-9b56-5dd1b2a91bc9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.806932.806932 cuda_h.py:19] end self_attn cost 0.0038170814514160156 seconds
DEBUG 01-06 08:44:54.807624.807624 cuda_h.py:19] end iln_self_attn_paln cost 0.00518035888671875 seconds
DEBUG 01-06 08:44:54.807560.807560 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-06 08:44:54.807515.807515 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.807848.807848 cuda_h.py:19] end gate cost 0.0006344318389892578 seconds
DEBUG 01-06 08:44:54.807771.807771 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.808264.808264 lmp.py:369] 
DEBUG 01-06 08:44:54.808264.808264 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.808589.808589 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.808001.808001 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.808266.808266 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.808194.808194 lmp.py:373] 
DEBUG 01-06 08:44:54.808194.808194 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.808314.808314 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.808725.808725 lmp.py:380]   Expert 30 |      3 | CPU
DEBUG 01-06 08:44:54.808891.808891 lmp.py:380]   Expert 58 |      8 | CPU
DEBUG 01-06 08:44:54.808819.808819 lmp.py:380]   Expert  3 |     20 | CPU
DEBUG 01-06 08:44:54.808270.808270 lmp.py:380]   Expert 37 |     27 | CPU
DEBUG 01-06 08:44:54.808482.808482 lmp.py:380]   Expert  0 |     32 | CPU
DEBUG 01-06 08:44:54.808456.808456 lmp.py:380]   Expert 52 |     36 | CPU
DEBUG 01-06 08:44:54.808907.808907 lmp.py:380]   Expert  8 |     40 | CPU
DEBUG 01-06 08:44:54.808073.808073 lmp.py:380]   Expert 43 |     41 | CPU
DEBUG 01-06 08:44:54.808823.808823 lmp.py:380]   Expert 54 |     41 | CPU
DEBUG 01-06 08:44:54.808486.808486 lmp.py:380]   Expert 34 |     48 | CPU
DEBUG 01-06 08:44:54.808573.808573 lmp.py:380]   Expert 12 |     49 | CPU
DEBUG 01-06 08:44:54.808262.808262 lmp.py:380]   Expert 40 |     51 | CPU
DEBUG 01-06 08:44:54.808475.808475 lmp.py:380]   Expert 35 |     52 | CPU
DEBUG 01-06 08:44:54.808687.808687 lmp.py:380]   Expert 53 |     63 | CPU
DEBUG 01-06 08:44:54.808045.808045 lmp.py:380]   Expert 19 |     64 | CPU
DEBUG 01-06 08:44:54.808212.808212 lmp.py:380]   Expert 20 |     66 | CPU
DEBUG 01-06 08:44:54.808662.808662 lmp.py:380]   Expert 41 |     71 | CPU
DEBUG 01-06 08:44:54.808875.808875 lmp.py:380]   Expert 25 |     81 | CPU
DEBUG 01-06 08:44:54.808849.808849 lmp.py:380]   Expert 63 |     84 | CPU
DEBUG 01-06 08:44:54.808585.808585 lmp.py:380]   Expert 48 |     89 | CPU
DEBUG 01-06 08:44:54.808035.808035 lmp.py:380]   Expert 60 |     92 | CPU
DEBUG 01-06 08:44:54.808009.808009 lmp.py:380]   Expert  1 |     95 | CPU
DEBUG 01-06 08:44:54.808984.808984 lmp.py:380]   Expert 11 |     95 | CPU
DEBUG 01-06 08:44:54.808958.808958 lmp.py:380]   Expert 56 |     95 | CPU
DEBUG 01-06 08:44:54.808647.808647 lmp.py:380]   Expert 32 |    105 | CPU
DEBUG 01-06 08:44:54.808859.808859 lmp.py:380]   Expert  7 |    108 | CPU
DEBUG 01-06 08:44:54.808833.808833 lmp.py:380]   Expert  4 |    111 | CPU
DEBUG 01-06 08:44:54.808569.808569 lmp.py:380]   Expert 22 |    117 | CPU
DEBUG 01-06 08:44:54.808543.808543 lmp.py:380]   Expert 13 |    123 | CPU
DEBUG 01-06 08:44:54.808279.808279 lmp.py:380]   Expert 46 |    125 | CPU
DEBUG 01-06 08:44:54.808206.808206 lmp.py:380]   Expert 33 |    126 | CPU
DEBUG 01-06 08:44:54.808134.808134 lmp.py:380]   Expert  6 |    129 | CPU
DEBUG 01-06 08:44:54.808492.808492 lmp.py:380]   Expert 27 |    131 | GPU
DEBUG 01-06 08:44:54.808658.808658 lmp.py:380]   Expert  5 |    149 | GPU
DEBUG 01-06 08:44:54.808586.808586 lmp.py:380]   Expert 29 |    157 | GPU
DEBUG 01-06 08:44:54.808276.808276 lmp.py:380]   Expert 42 |    163 | GPU
DEBUG 01-06 08:44:54.808203.808203 lmp.py:380]   Expert 45 |    164 | GPU
DEBUG 01-06 08:44:54.808369.808369 lmp.py:380]   Expert  9 |    168 | GPU
DEBUG 01-06 08:44:54.808536.808536 lmp.py:380]   Expert 39 |    177 | GPU
DEBUG 01-06 08:44:54.808702.808702 lmp.py:380]   Expert 16 |    188 | GPU
DEBUG 01-06 08:44:54.808106.808106 lmp.py:380]   Expert 21 |    219 | GPU
DEBUG 01-06 08:44:54.808988.808988 lmp.py:380]   Expert 18 |    224 | GPU
DEBUG 01-06 08:44:54.808915.808915 lmp.py:380]   Expert 24 |    225 | GPU
DEBUG 01-06 08:44:54.809605.809605 lmp.py:380]   Expert 50 |    226 | GPU
DEBUG 01-06 08:44:54.809294.809294 lmp.py:380]   Expert 51 |    228 | GPU
DEBUG 01-06 08:44:54.809222.809222 lmp.py:380]   Expert 10 |    229 | GPU
DEBUG 01-06 08:44:54.809149.809149 lmp.py:380]   Expert 61 |    247 | GPU
DEBUG 01-06 08:44:54.809077.809077 lmp.py:380]   Expert 59 |    248 | GPU
DEBUG 01-06 08:44:54.809243.809243 lmp.py:380]   Expert 15 |    252 | GPU
DEBUG 01-06 08:44:54.809178.809178 lmp.py:380]   Expert 28 |    255 | GPU
DEBUG 01-06 08:44:54.809582.809582 lmp.py:380]   Expert 17 |    259 | GPU
DEBUG 01-06 08:44:54.809033.809033 lmp.py:380]   Expert 55 |    265 | GPU
DEBUG 01-06 08:44:54.809484.809484 lmp.py:380]   Expert 36 |    277 | GPU
DEBUG 01-06 08:44:54.809458.809458 lmp.py:380]   Expert 44 |    284 | GPU
DEBUG 01-06 08:44:54.809671.809671 lmp.py:380]   Expert 38 |    296 | GPU
DEBUG 01-06 08:44:54.809883.809883 lmp.py:380]   Expert 26 |    312 | GPU
DEBUG 01-06 08:44:54.809857.809857 lmp.py:380]   Expert 31 |    348 | GPU
DEBUG 01-06 08:44:54.809070.809070 lmp.py:380]   Expert 14 |    355 | GPU
DEBUG 01-06 08:44:54.809759.809759 lmp.py:380]   Expert 47 |    383 | GPU
DEBUG 01-06 08:44:54.809448.809448 lmp.py:380]   Expert 57 |    384 | GPU
DEBUG 01-06 08:44:54.809137.809137 lmp.py:380]   Expert 49 |    630 | GPU
DEBUG 01-06 08:44:54.809588.809588 lmp.py:380]   Expert  2 |    667 | GPU
DEBUG 01-06 08:44:54.809801.809801 lmp.py:380]   Expert 23 |    838 | GPU
DEBUG 01-06 08:44:54.809775.809775 lmp.py:380]   Expert 62 |   1053 | GPU
DEBUG 01-06 08:44:54.809941.809941 lmp.py:381] 
DEBUG 01-06 08:44:54.809941.809941 lmp.py:381]   CPU total tokens: 2287 (18.6%)
DEBUG 01-06 08:44:54.809346.809346 lmp.py:382]   GPU total tokens: 10001 (81.4%)
DEBUG 01-06 08:44:54.809518.809518 cuda_h.py:19] end experts_map_get cost 0.0015418529510498047 seconds
DEBUG 01-06 08:44:54.809685.809685 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.809852.809852 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.809804.809804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.810513.810513 cuda_h.py:19] end allocate_cuda_memory cost 0.00038504600524902344 seconds
DEBUG 01-06 08:44:54.810787.810787 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.810543.810543 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.810729.810729 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.810379.810379 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8a537f22-cc87-4e8e-9de4-c7b32fa3cab3
DEBUG 01-06 08:44:54.810831.810831 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.810381.810381 client.py:127] Model loaded
DEBUG 01-06 08:44:54.810761.810761 cuda_h.py:19] end sllm_worker_task cost 0.00874471664428711 seconds
INFO 01-06 08:44:54.811769.811769 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8a537f22-cc87-4e8e-9de4-c7b32fa3cab3
DEBUG 01-06 08:44:54.811373.811373 cuda_h.py:19] end load_into_gpu_async cost 0.0012772083282470703 seconds
DEBUG 01-06 08:44:54.811553.811553 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.811935.811935 cuda_h.py:19] end restore_tensors2 cost 0.0005004405975341797 seconds
DEBUG 01-06 08:44:54.812010.812010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025157928466796875 seconds
DEBUG 01-06 08:44:54.814049.814049 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005122184753417969 seconds
DEBUG 01-06 08:44:54.814369.814369 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.814021.814021 lmp.py:427] 
DEBUG 01-06 08:44:54.814021.814021 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.814242.814242 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-06 08:44:54.814368.814368 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.821216.821216 mlpmodule.py:704] group tensors cost 0.006384849548339844 s
DEBUG 01-06 08:44:54.824440.824440 mlpmodule.py:742] pad cost 0.002599000930786133 s
DEBUG 01-06 08:44:54.825968.825968 mlpmodule.py:748] create cpu tensor cost 5.745887756347656e-05 s
DEBUG 01-06 08:44:54.825104.825104 mlpmodule.py:753] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-06 08:44:54.836686.836686 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:54.836507.836507 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.836962.836962 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-06 08:44:54.836131.836131 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.854420.854420 mlpmodule.py:793] group einsum cost 0.029314041137695312 s
DEBUG 01-06 08:44:54.855253.855253 mlpmodule.py:801] cpy2cputensor cost 0.0005462169647216797 s
DEBUG 01-06 08:44:54.860410.860410 cuda_h.py:19] end wait_cetm_experts cost 0.045316457748413086 seconds
DEBUG 01-06 08:44:54.860175.860175 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.861930.861930 cuda_h.py:19] end gpu_sexperts cost 0.0015263557434082031 seconds
DEBUG 01-06 08:44:54.861403.861403 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.861829.861829 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:44:54.862677.862677 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.862818.862818 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8a537f22-cc87-4e8e-9de4-c7b32fa3cab3
DEBUG 01-06 08:44:54.868509.868509 mlpmodule.py:662]  experts func einsum cost 0.05314517021179199 s
INFO 01-06 08:44:54.870117.870117 client.py:127] Model loaded
DEBUG 01-06 08:44:54.870735.870735 cuda_h.py:19] end wait_experts cost 0.008227348327636719 seconds
DEBUG 01-06 08:44:54.870584.870584 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.870002.870002 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.881042.881042 cuda_h.py:19] end gpu_experts cost 0.010869979858398438 seconds
DEBUG 01-06 08:44:54.881325.881325 cuda_h.py:19] end layer_moe_generate_18 cost 0.07422971725463867 seconds
DEBUG 01-06 08:44:54.881219.881219 lmp.py:221] -------------------------------- end layer 18 --------------------------------
DEBUG 01-06 08:44:54.881016.881016 lmp.py:177] -------------------------------- start layer 19 --------------------------------
DEBUG 01-06 08:44:54.881619.881619 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 08:44:54.881806.881806 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 08:44:54.881026.881026 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:44:54.881478.881478 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 8.630752563476562e-05 seconds
DEBUG 01-06 08:44:54.881028.881028 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.881614.881614 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.881412.881412 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.882692.882692 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.882848.882848 cuda_h.py:19] end allocate_cuda_memory cost 0.00024628639221191406 seconds
DEBUG 01-06 08:44:54.882208.882208 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.882362.882362 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.882437.882437 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.882100.882100 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aaa3b84b-fedc-4f96-a156-ca91c280bf90
DEBUG 01-06 08:44:54.882190.882190 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.882131.882131 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.883484.883484 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aaa3b84b-fedc-4f96-a156-ca91c280bf90
DEBUG 01-06 08:44:54.883903.883903 cuda_h.py:19] end load_into_gpu_async cost 0.0011353492736816406 seconds
DEBUG 01-06 08:44:54.883852.883852 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.883061.883061 cuda_h.py:19] end restore_tensors2 cost 8.440017700195312e-05 seconds
DEBUG 01-06 08:44:54.883400.883400 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017745494842529297 seconds
INFO 01-06 08:44:54.884735.884735 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aaa3b84b-fedc-4f96-a156-ca91c280bf90
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.887486.887486 cuda_h.py:19] end self_attn cost 0.00419926643371582 seconds
DEBUG 01-06 08:44:54.887569.887569 cuda_h.py:19] end iln_self_attn_paln cost 0.005635738372802734 seconds
DEBUG 01-06 08:44:54.887982.887982 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-06 08:44:54.887460.887460 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.888416.888416 cuda_h.py:19] end gate cost 0.0006356239318847656 seconds
DEBUG 01-06 08:44:54.888245.888245 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.888329.888329 lmp.py:369] 
DEBUG 01-06 08:44:54.888329.888329 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.888230.888230 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.888595.888595 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.888623.888623 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.888027.888027 lmp.py:373] 
DEBUG 01-06 08:44:54.888027.888027 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.888385.888385 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.888273.888273 lmp.py:380]   Expert 27 |     17 | CPU
DEBUG 01-06 08:44:54.888109.888109 lmp.py:380]   Expert 59 |     23 | CPU
DEBUG 01-06 08:44:54.888752.888752 lmp.py:380]   Expert 56 |     26 | CPU
DEBUG 01-06 08:44:54.888156.888156 lmp.py:380]   Expert 42 |     32 | CPU
DEBUG 01-06 08:44:54.888845.888845 lmp.py:380]   Expert 48 |     39 | CPU
DEBUG 01-06 08:44:54.888012.888012 lmp.py:380]   Expert 12 |     45 | CPU
DEBUG 01-06 08:44:54.888654.888654 lmp.py:380]   Expert 16 |     48 | CPU
DEBUG 01-06 08:44:54.888059.888059 lmp.py:380]   Expert  0 |     49 | CPU
DEBUG 01-06 08:44:54.888225.888225 lmp.py:380]   Expert 26 |     49 | CPU
DEBUG 01-06 08:44:54.888391.888391 lmp.py:380]   Expert  6 |     64 | CPU
DEBUG 01-06 08:44:54.888842.888842 lmp.py:380]   Expert 55 |     65 | CPU
DEBUG 01-06 08:44:54.888770.888770 lmp.py:380]   Expert 44 |     67 | CPU
DEBUG 01-06 08:44:54.888698.888698 lmp.py:380]   Expert 60 |     75 | CPU
DEBUG 01-06 08:44:54.888149.888149 lmp.py:380]   Expert 33 |     81 | CPU
DEBUG 01-06 08:44:54.888361.888361 lmp.py:380]   Expert 30 |     92 | CPU
DEBUG 01-06 08:44:54.888335.888335 lmp.py:380]   Expert 54 |     92 | CPU
DEBUG 01-06 08:44:54.888071.888071 lmp.py:380]   Expert 23 |     93 | CPU
DEBUG 01-06 08:44:54.889045.889045 lmp.py:380]   Expert 62 |     97 | CPU
DEBUG 01-06 08:44:54.889257.889257 lmp.py:380]   Expert 58 |     99 | CPU
DEBUG 01-06 08:44:54.889231.889231 lmp.py:380]   Expert 34 |    109 | CPU
DEBUG 01-06 08:44:54.889921.889921 lmp.py:380]   Expert  5 |    110 | CPU
DEBUG 01-06 08:44:54.889087.889087 lmp.py:380]   Expert  1 |    111 | CPU
DEBUG 01-06 08:44:54.889014.889014 lmp.py:380]   Expert 18 |    112 | CPU
DEBUG 01-06 08:44:54.889942.889942 lmp.py:380]   Expert 19 |    113 | CPU
DEBUG 01-06 08:44:54.889631.889631 lmp.py:380]   Expert 13 |    120 | CPU
DEBUG 01-06 08:44:54.889751.889751 lmp.py:380]   Expert 24 |    129 | CPU
DEBUG 01-06 08:44:54.889679.889679 lmp.py:380]   Expert 17 |    132 | CPU
DEBUG 01-06 08:44:54.889607.889607 lmp.py:380]   Expert 39 |    134 | CPU
DEBUG 01-06 08:44:54.889296.889296 lmp.py:380]   Expert 46 |    144 | CPU
DEBUG 01-06 08:44:54.889462.889462 lmp.py:380]   Expert 14 |    150 | CPU
DEBUG 01-06 08:44:54.889151.889151 lmp.py:380]   Expert 22 |    157 | CPU
DEBUG 01-06 08:44:54.889841.889841 lmp.py:380]   Expert 15 |    159 | CPU
DEBUG 01-06 08:44:54.889768.889768 lmp.py:380]   Expert 41 |    162 | GPU
DEBUG 01-06 08:44:54.889458.889458 lmp.py:380]   Expert  3 |    168 | GPU
DEBUG 01-06 08:44:54.889385.889385 lmp.py:380]   Expert 29 |    170 | GPU
DEBUG 01-06 08:44:54.889267.889267 lmp.py:380]   Expert 57 |    177 | GPU
DEBUG 01-06 08:44:54.889910.889910 lmp.py:380]   Expert 43 |    183 | GPU
DEBUG 01-06 08:44:54.889030.889030 lmp.py:380]   Expert 49 |    184 | GPU
DEBUG 01-06 08:44:54.889388.889388 lmp.py:380]   Expert 63 |    185 | GPU
DEBUG 01-06 08:44:54.889316.889316 lmp.py:380]   Expert 25 |    193 | GPU
DEBUG 01-06 08:44:54.889005.889005 lmp.py:380]   Expert 28 |    198 | GPU
DEBUG 01-06 08:44:54.889171.889171 lmp.py:380]   Expert 40 |    198 | GPU
DEBUG 01-06 08:44:54.889860.889860 lmp.py:380]   Expert 51 |    203 | GPU
DEBUG 01-06 08:44:54.889026.889026 lmp.py:380]   Expert  4 |    205 | GPU
DEBUG 01-06 08:44:54.889954.889954 lmp.py:380]   Expert 50 |    216 | GPU
DEBUG 01-06 08:44:54.889120.889120 lmp.py:380]   Expert  8 |    225 | GPU
DEBUG 01-06 08:44:54.889810.889810 lmp.py:380]   Expert 32 |    226 | GPU
DEBUG 01-06 08:44:54.889453.889453 lmp.py:380]   Expert 31 |    227 | GPU
DEBUG 01-06 08:44:54.889857.889857 lmp.py:380]   Expert 53 |    243 | GPU
DEBUG 01-06 08:44:54.889500.889500 lmp.py:380]   Expert 38 |    246 | GPU
DEBUG 01-06 08:44:54.889620.889620 lmp.py:380]   Expert 37 |    259 | GPU
DEBUG 01-06 08:44:54.889548.889548 lmp.py:380]   Expert 52 |    264 | GPU
DEBUG 01-06 08:44:54.889475.889475 lmp.py:380]   Expert 36 |    297 | GPU
DEBUG 01-06 08:44:54.889926.889926 lmp.py:380]   Expert 61 |    324 | GPU
DEBUG 01-06 08:44:54.889854.889854 lmp.py:380]   Expert 11 |    327 | GPU
DEBUG 01-06 08:44:54.889543.889543 lmp.py:380]   Expert 47 |    351 | GPU
DEBUG 01-06 08:44:54.889709.889709 lmp.py:380]   Expert 20 |    383 | GPU
DEBUG 01-06 08:44:54.889637.889637 lmp.py:380]   Expert 21 |    398 | GPU
DEBUG 01-06 08:44:54.889565.889565 lmp.py:380]   Expert 10 |    401 | GPU
DEBUG 01-06 08:44:54.889208.889208 lmp.py:380]   Expert 35 |    430 | GPU
DEBUG 01-06 08:44:54.889328.889328 lmp.py:380]   Expert  2 |    481 | GPU
DEBUG 01-06 08:44:54.889494.889494 lmp.py:380]   Expert  9 |    481 | GPU
DEBUG 01-06 08:44:54.889183.889183 lmp.py:380]   Expert  7 |    720 | GPU
DEBUG 01-06 08:44:54.889872.889872 lmp.py:380]   Expert 45 |    730 | GPU
DEBUG 01-06 08:44:54.889754.889754 lmp.py:381] 
DEBUG 01-06 08:44:54.889754.889754 lmp.py:381]   CPU total tokens: 2833 (23.1%)
DEBUG 01-06 08:44:54.889635.889635 lmp.py:382]   GPU total tokens: 9455 (76.9%)
DEBUG 01-06 08:44:54.889537.889537 cuda_h.py:19] end experts_map_get cost 0.0015559196472167969 seconds
DEBUG 01-06 08:44:54.889657.889657 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.889870.889870 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.890160.890160 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.890608.890608 cuda_h.py:19] end allocate_cuda_memory cost 0.00029540061950683594 seconds
DEBUG 01-06 08:44:54.890981.890981 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.890691.890691 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.890023.890023 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.890819.890819 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94b86037-4569-4792-b23b-b1c8102bf7bd
DEBUG 01-06 08:44:54.890556.890556 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.890250.890250 client.py:127] Model loaded
DEBUG 01-06 08:44:54.891139.891139 cuda_h.py:19] end sllm_worker_task cost 0.009074687957763672 seconds
INFO 01-06 08:44:54.891359.891359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94b86037-4569-4792-b23b-b1c8102bf7bd
DEBUG 01-06 08:44:54.891156.891156 cuda_h.py:19] end load_into_gpu_async cost 0.0014290809631347656 seconds
DEBUG 01-06 08:44:54.891336.891336 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.892519.892519 cuda_h.py:19] end restore_tensors2 cost 0.0004923343658447266 seconds
DEBUG 01-06 08:44:54.892269.892269 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025870800018310547 seconds
DEBUG 01-06 08:44:54.895183.895183 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005203723907470703 seconds
DEBUG 01-06 08:44:54.895158.895158 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.895572.895572 lmp.py:427] 
DEBUG 01-06 08:44:54.895572.895572 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.895269.895269 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-06 08:44:54.895350.895350 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.903682.903682 mlpmodule.py:704] group tensors cost 0.007593870162963867 s
DEBUG 01-06 08:44:54.906997.906997 mlpmodule.py:742] pad cost 0.002887725830078125 s
DEBUG 01-06 08:44:54.906652.906652 mlpmodule.py:748] create cpu tensor cost 7.05718994140625e-05 s
DEBUG 01-06 08:44:54.907046.907046 mlpmodule.py:753] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-06 08:44:54.919754.919754 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:54.919728.919728 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:54.919585.919585 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-06 08:44:54.920908.920908 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:54.939068.939068 mlpmodule.py:793] group einsum cost 0.03239011764526367 s
DEBUG 01-06 08:44:54.940508.940508 mlpmodule.py:801] cpy2cputensor cost 0.0006699562072753906 s
DEBUG 01-06 08:44:54.945253.945253 cuda_h.py:19] end wait_cetm_experts cost 0.04988431930541992 seconds
DEBUG 01-06 08:44:54.945289.945289 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:54.946519.946519 cuda_h.py:19] end gpu_sexperts cost 0.00128173828125 seconds
DEBUG 01-06 08:44:54.946555.946555 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:54.946219.946219 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:44:54.946021.946021 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:54.946930.946930 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94b86037-4569-4792-b23b-b1c8102bf7bd
INFO 01-06 08:44:54.950513.950513 client.py:127] Model loaded
DEBUG 01-06 08:44:54.950740.950740 cuda_h.py:19] end wait_experts cost 0.0038335323333740234 seconds
DEBUG 01-06 08:44:54.950066.950066 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:54.950299.950299 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:54.953210.953210 mlpmodule.py:662]  experts func einsum cost 0.05779695510864258 s
DEBUG 01-06 08:44:54.962314.962314 cuda_h.py:19] end gpu_experts cost 0.011521577835083008 seconds
DEBUG 01-06 08:44:54.962132.962132 cuda_h.py:19] end layer_moe_generate_19 cost 0.07486319541931152 seconds
DEBUG 01-06 08:44:54.962045.962045 lmp.py:221] -------------------------------- end layer 19 --------------------------------
DEBUG 01-06 08:44:54.962570.962570 lmp.py:177] -------------------------------- start layer 20 --------------------------------
DEBUG 01-06 08:44:54.962312.962312 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 08:44:54.962161.962161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 08:44:54.962613.962613 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.6464462280273438e-05 seconds
DEBUG 01-06 08:44:54.962667.962667 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.152557373046875e-05 seconds
DEBUG 01-06 08:44:54.962025.962025 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:54.962755.962755 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:54.962188.962188 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.962502.962502 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.963916.963916 cuda_h.py:19] end allocate_cuda_memory cost 0.00027108192443847656 seconds
DEBUG 01-06 08:44:54.963004.963004 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.963714.963714 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.963106.963106 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.963663.963663 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af6fa3db-5888-45a1-a7b3-eff65c397544
DEBUG 01-06 08:44:54.963825.963825 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:54.963844.963844 cuda_h.py:10] start self_attn
INFO 01-06 08:44:54.964702.964702 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af6fa3db-5888-45a1-a7b3-eff65c397544
DEBUG 01-06 08:44:54.964631.964631 cuda_h.py:19] end load_into_gpu_async cost 0.001096963882446289 seconds
DEBUG 01-06 08:44:54.964142.964142 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.964900.964900 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-06 08:44:54.964941.964941 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016803741455078125 seconds
INFO 01-06 08:44:54.965151.965151 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af6fa3db-5888-45a1-a7b3-eff65c397544
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:54.967383.967383 cuda_h.py:19] end self_attn cost 0.0039844512939453125 seconds
DEBUG 01-06 08:44:54.968406.968406 cuda_h.py:19] end iln_self_attn_paln cost 0.00541234016418457 seconds
DEBUG 01-06 08:44:54.968773.968773 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-06 08:44:54.968727.968727 cuda_h.py:10] start gate
DEBUG 01-06 08:44:54.969505.969505 cuda_h.py:19] end gate cost 0.0006444454193115234 seconds
DEBUG 01-06 08:44:54.969335.969335 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:54.969358.969358 lmp.py:369] 
DEBUG 01-06 08:44:54.969358.969358 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:54.969683.969683 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:54.969810.969810 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:54.969599.969599 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:54.969718.969718 lmp.py:373] 
DEBUG 01-06 08:44:54.969718.969718 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:54.969361.969361 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:54.969726.969726 lmp.py:380]   Expert 36 |      4 | CPU
DEBUG 01-06 08:44:54.969846.969846 lmp.py:380]   Expert 54 |      9 | CPU
DEBUG 01-06 08:44:54.969251.969251 lmp.py:380]   Expert 39 |     16 | CPU
DEBUG 01-06 08:44:54.969609.969609 lmp.py:380]   Expert 13 |     20 | CPU
DEBUG 01-06 08:44:54.969252.969252 lmp.py:380]   Expert  6 |     24 | CPU
DEBUG 01-06 08:44:54.969657.969657 lmp.py:380]   Expert  8 |     24 | CPU
DEBUG 01-06 08:44:54.969823.969823 lmp.py:380]   Expert  4 |     42 | CPU
DEBUG 01-06 08:44:54.969512.969512 lmp.py:380]   Expert 38 |     44 | CPU
DEBUG 01-06 08:44:54.969692.969692 lmp.py:380]   Expert 12 |     47 | CPU
DEBUG 01-06 08:44:54.969666.969666 lmp.py:380]   Expert 42 |     49 | CPU
DEBUG 01-06 08:44:54.969878.969878 lmp.py:380]   Expert 28 |     56 | CPU
DEBUG 01-06 08:44:54.969329.969329 lmp.py:380]   Expert 46 |     59 | CPU
DEBUG 01-06 08:44:54.969780.969780 lmp.py:380]   Expert 50 |     73 | CPU
DEBUG 01-06 08:44:54.969185.969185 lmp.py:380]   Expert 57 |     78 | CPU
DEBUG 01-06 08:44:54.969635.969635 lmp.py:380]   Expert  1 |     84 | CPU
DEBUG 01-06 08:44:54.969755.969755 lmp.py:380]   Expert 11 |     86 | CPU
DEBUG 01-06 08:44:54.969398.969398 lmp.py:380]   Expert 33 |     93 | CPU
DEBUG 01-06 08:44:54.969564.969564 lmp.py:380]   Expert 52 |     94 | CPU
DEBUG 01-06 08:44:54.969492.969492 lmp.py:380]   Expert 61 |     94 | CPU
DEBUG 01-06 08:44:54.969420.969420 lmp.py:380]   Expert  3 |     95 | CPU
DEBUG 01-06 08:44:54.969586.969586 lmp.py:380]   Expert  7 |     99 | CPU
DEBUG 01-06 08:44:54.969467.969467 lmp.py:380]   Expert 20 |    100 | CPU
DEBUG 01-06 08:44:54.969349.969349 lmp.py:380]   Expert 24 |    107 | CPU
DEBUG 01-06 08:44:54.969276.969276 lmp.py:380]   Expert 17 |    112 | CPU
DEBUG 01-06 08:44:54.969204.969204 lmp.py:380]   Expert 49 |    118 | CPU
DEBUG 01-06 08:44:54.969609.969609 lmp.py:380]   Expert  9 |    119 | CPU
DEBUG 01-06 08:44:54.969775.969775 lmp.py:380]   Expert 19 |    130 | CPU
DEBUG 01-06 08:44:54.969703.969703 lmp.py:380]   Expert 29 |    138 | CPU
DEBUG 01-06 08:44:54.969869.969869 lmp.py:380]   Expert 22 |    139 | CPU
DEBUG 01-06 08:44:54.970796.970796 lmp.py:380]   Expert 18 |    141 | CPU
DEBUG 01-06 08:44:54.970439.970439 lmp.py:380]   Expert 51 |    142 | CPU
DEBUG 01-06 08:44:54.970559.970559 lmp.py:380]   Expert 23 |    152 | CPU
DEBUG 01-06 08:44:54.970487.970487 lmp.py:380]   Expert 30 |    153 | GPU
DEBUG 01-06 08:44:54.970415.970415 lmp.py:380]   Expert 10 |    169 | GPU
DEBUG 01-06 08:44:54.970581.970581 lmp.py:380]   Expert 43 |    176 | GPU
DEBUG 01-06 08:44:54.970270.970270 lmp.py:380]   Expert 41 |    183 | GPU
DEBUG 01-06 08:44:54.970198.970198 lmp.py:380]   Expert 21 |    188 | GPU
DEBUG 01-06 08:44:54.970364.970364 lmp.py:380]   Expert 31 |    192 | GPU
DEBUG 01-06 08:44:54.970292.970292 lmp.py:380]   Expert 14 |    201 | GPU
DEBUG 01-06 08:44:54.970511.970511 lmp.py:380]   Expert  5 |    202 | GPU
DEBUG 01-06 08:44:54.970154.970154 lmp.py:380]   Expert 63 |    202 | GPU
DEBUG 01-06 08:44:54.970605.970605 lmp.py:380]   Expert 44 |    210 | GPU
DEBUG 01-06 08:44:54.970817.970817 lmp.py:380]   Expert  0 |    217 | GPU
DEBUG 01-06 08:44:54.970030.970030 lmp.py:380]   Expert 32 |    229 | GPU
DEBUG 01-06 08:44:54.970004.970004 lmp.py:380]   Expert 58 |    230 | GPU
DEBUG 01-06 08:44:54.970216.970216 lmp.py:380]   Expert 48 |    241 | GPU
DEBUG 01-06 08:44:54.970952.970952 lmp.py:380]   Expert 16 |    243 | GPU
DEBUG 01-06 08:44:54.970164.970164 lmp.py:380]   Expert 47 |    245 | GPU
DEBUG 01-06 08:44:54.970138.970138 lmp.py:380]   Expert 62 |    262 | GPU
DEBUG 01-06 08:44:54.970874.970874 lmp.py:380]   Expert 37 |    265 | GPU
DEBUG 01-06 08:44:54.970610.970610 lmp.py:380]   Expert 34 |    266 | GPU
DEBUG 01-06 08:44:54.970776.970776 lmp.py:380]   Expert 55 |    275 | GPU
DEBUG 01-06 08:44:54.970465.970465 lmp.py:380]   Expert 27 |    279 | GPU
DEBUG 01-06 08:44:54.970916.970916 lmp.py:380]   Expert 26 |    284 | GPU
DEBUG 01-06 08:44:54.970128.970128 lmp.py:380]   Expert 60 |    297 | GPU
DEBUG 01-06 08:44:54.970102.970102 lmp.py:380]   Expert 56 |    313 | GPU
DEBUG 01-06 08:44:54.970315.970315 lmp.py:380]   Expert 59 |    325 | GPU
DEBUG 01-06 08:44:54.970289.970289 lmp.py:380]   Expert 53 |    358 | GPU
DEBUG 01-06 08:44:54.970025.970025 lmp.py:380]   Expert 15 |    382 | GPU
DEBUG 01-06 08:44:54.970999.970999 lmp.py:380]   Expert 40 |    391 | GPU
DEBUG 01-06 08:44:54.970734.970734 lmp.py:380]   Expert 25 |    396 | GPU
DEBUG 01-06 08:44:54.970708.970708 lmp.py:380]   Expert 45 |    446 | GPU
DEBUG 01-06 08:44:54.970636.970636 lmp.py:380]   Expert  2 |    652 | GPU
DEBUG 01-06 08:44:54.970564.970564 lmp.py:380]   Expert 35 |   1228 | GPU
DEBUG 01-06 08:44:54.970491.970491 lmp.py:381] 
DEBUG 01-06 08:44:54.970491.970491 lmp.py:381]   CPU total tokens: 2588 (21.1%)
DEBUG 01-06 08:44:54.970181.970181 lmp.py:382]   GPU total tokens: 9700 (78.9%)
DEBUG 01-06 08:44:54.970162.970162 cuda_h.py:19] end experts_map_get cost 0.0015292167663574219 seconds
DEBUG 01-06 08:44:54.970328.970328 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:54.970488.970488 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:54.970778.970778 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:54.971611.971611 cuda_h.py:19] end allocate_cuda_memory cost 0.00031948089599609375 seconds
DEBUG 01-06 08:44:54.971647.971647 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:54.971403.971403 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:54.971496.971496 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:54.971338.971338 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8921aa04-694d-41e7-a051-f6d77f44b1dc
DEBUG 01-06 08:44:54.971268.971268 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:54.971140.971140 client.py:127] Model loaded
DEBUG 01-06 08:44:54.971613.971613 cuda_h.py:19] end sllm_worker_task cost 0.008916616439819336 seconds
INFO 01-06 08:44:54.972817.972817 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8921aa04-694d-41e7-a051-f6d77f44b1dc
DEBUG 01-06 08:44:54.972090.972090 cuda_h.py:19] end load_into_gpu_async cost 0.0013470649719238281 seconds
DEBUG 01-06 08:44:54.972270.972270 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:54.973032.973032 cuda_h.py:19] end restore_tensors2 cost 0.0003952980041503906 seconds
DEBUG 01-06 08:44:54.973961.973961 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024328231811523438 seconds
DEBUG 01-06 08:44:54.975232.975232 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005029201507568359 seconds
DEBUG 01-06 08:44:54.975777.975777 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:54.975263.975263 lmp.py:427] 
DEBUG 01-06 08:44:54.975263.975263 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:54.975245.975245 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 08:44:54.975061.975061 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:54.986187.986187 mlpmodule.py:704] group tensors cost 0.010557174682617188 s
DEBUG 01-06 08:44:54.989971.989971 mlpmodule.py:742] pad cost 0.0019478797912597656 s
DEBUG 01-06 08:44:54.989843.989843 mlpmodule.py:748] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-06 08:44:54.989382.989382 mlpmodule.py:753] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-06 08:44:55.002679.002679 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:55.002870.002870 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.002145.002145 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-06 08:44:55.002884.002884 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.021724.021724 mlpmodule.py:793] group einsum cost 0.03169727325439453 s
DEBUG 01-06 08:44:55.022872.022872 mlpmodule.py:801] cpy2cputensor cost 0.0006401538848876953 s
DEBUG 01-06 08:44:55.027603.027603 cuda_h.py:19] end wait_cetm_experts cost 0.05108475685119629 seconds
DEBUG 01-06 08:44:55.027454.027454 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.028430.028430 cuda_h.py:19] end gpu_sexperts cost 0.001409292221069336 seconds
DEBUG 01-06 08:44:55.028380.028380 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.028773.028773 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:55.028860.028860 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.028954.028954 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8921aa04-694d-41e7-a051-f6d77f44b1dc
INFO 01-06 08:44:55.032641.032641 client.py:127] Model loaded
DEBUG 01-06 08:44:55.032822.032822 cuda_h.py:19] end wait_experts cost 0.0033812522888183594 seconds
DEBUG 01-06 08:44:55.032293.032293 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.032572.032572 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.035005.035005 mlpmodule.py:662]  experts func einsum cost 0.059140682220458984 s
DEBUG 01-06 08:44:55.043979.043979 cuda_h.py:19] end gpu_experts cost 0.011142492294311523 seconds
DEBUG 01-06 08:44:55.043394.043394 cuda_h.py:19] end layer_moe_generate_20 cost 0.07528376579284668 seconds
DEBUG 01-06 08:44:55.043744.043744 lmp.py:221] -------------------------------- end layer 20 --------------------------------
DEBUG 01-06 08:44:55.043554.043554 lmp.py:177] -------------------------------- start layer 21 --------------------------------
DEBUG 01-06 08:44:55.043058.043058 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 08:44:55.043483.043483 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 08:44:55.043935.043935 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:44:55.043373.043373 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.367134094238281e-05 seconds
DEBUG 01-06 08:44:55.044493.044493 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.044607.044607 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:55.044994.044994 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.044353.044353 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.044953.044953 cuda_h.py:19] end allocate_cuda_memory cost 0.0002665519714355469 seconds
DEBUG 01-06 08:44:55.044433.044433 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.044958.044958 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.044827.044827 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.044053.044053 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 451ad596-9c69-4fbd-9550-5537582a748a
DEBUG 01-06 08:44:55.044075.044075 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:55.045648.045648 cuda_h.py:10] start self_attn
INFO 01-06 08:44:55.045682.045682 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 451ad596-9c69-4fbd-9550-5537582a748a
DEBUG 01-06 08:44:55.045088.045088 cuda_h.py:19] end load_into_gpu_async cost 0.0011129379272460938 seconds
DEBUG 01-06 08:44:55.045598.045598 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.045396.045396 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 08:44:55.045960.045960 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017313957214355469 seconds
INFO 01-06 08:44:55.046148.046148 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 451ad596-9c69-4fbd-9550-5537582a748a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.049297.049297 cuda_h.py:19] end self_attn cost 0.0038900375366210938 seconds
DEBUG 01-06 08:44:55.049558.049558 cuda_h.py:19] end iln_self_attn_paln cost 0.005285739898681641 seconds
DEBUG 01-06 08:44:55.049732.049732 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-06 08:44:55.049502.049502 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.050988.050988 cuda_h.py:19] end gate cost 0.0006392002105712891 seconds
DEBUG 01-06 08:44:55.050626.050626 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.050702.050702 lmp.py:369] 
DEBUG 01-06 08:44:55.050702.050702 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.050266.050266 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:55.050154.050154 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:55.050466.050466 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:55.050870.050870 lmp.py:373] 
DEBUG 01-06 08:44:55.050870.050870 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.050798.050798 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.050448.050448 lmp.py:380]   Expert 60 |      7 | CPU
DEBUG 01-06 08:44:55.050852.050852 lmp.py:380]   Expert 56 |      9 | CPU
DEBUG 01-06 08:44:55.050542.050542 lmp.py:380]   Expert 53 |     11 | CPU
DEBUG 01-06 08:44:55.050754.050754 lmp.py:380]   Expert  7 |     15 | CPU
DEBUG 01-06 08:44:55.050444.050444 lmp.py:380]   Expert 47 |     27 | CPU
DEBUG 01-06 08:44:55.050610.050610 lmp.py:380]   Expert  1 |     29 | CPU
DEBUG 01-06 08:44:55.050537.050537 lmp.py:380]   Expert  6 |     33 | CPU
DEBUG 01-06 08:44:55.050750.050750 lmp.py:380]   Expert 44 |     34 | CPU
DEBUG 01-06 08:44:55.050962.050962 lmp.py:380]   Expert 51 |     39 | CPU
DEBUG 01-06 08:44:55.050936.050936 lmp.py:380]   Expert 12 |     53 | CPU
DEBUG 01-06 08:44:55.050672.050672 lmp.py:380]   Expert 26 |     53 | CPU
DEBUG 01-06 08:44:55.050646.050646 lmp.py:380]   Expert 19 |     61 | CPU
DEBUG 01-06 08:44:55.050143.050143 lmp.py:380]   Expert 20 |     74 | CPU
DEBUG 01-06 08:44:55.050356.050356 lmp.py:380]   Expert 15 |     77 | CPU
DEBUG 01-06 08:44:55.050045.050045 lmp.py:380]   Expert 48 |     78 | CPU
DEBUG 01-06 08:44:55.050926.050926 lmp.py:380]   Expert  3 |     80 | CPU
DEBUG 01-06 08:44:55.050616.050616 lmp.py:380]   Expert 35 |     84 | CPU
DEBUG 01-06 08:44:55.050305.050305 lmp.py:380]   Expert 49 |     96 | CPU
DEBUG 01-06 08:44:55.050994.050994 lmp.py:380]   Expert 33 |    103 | CPU
DEBUG 01-06 08:44:55.050207.050207 lmp.py:380]   Expert  9 |    104 | CPU
DEBUG 01-06 08:44:55.050419.050419 lmp.py:380]   Expert 59 |    106 | CPU
DEBUG 01-06 08:44:55.050916.050916 lmp.py:380]   Expert 23 |    107 | CPU
DEBUG 01-06 08:44:55.050891.050891 lmp.py:380]   Expert  8 |    109 | CPU
DEBUG 01-06 08:44:55.050772.050772 lmp.py:380]   Expert 61 |    114 | CPU
DEBUG 01-06 08:44:55.050700.050700 lmp.py:380]   Expert 25 |    115 | CPU
DEBUG 01-06 08:44:55.050627.050627 lmp.py:380]   Expert 32 |    116 | CPU
DEBUG 01-06 08:44:55.051317.051317 lmp.py:380]   Expert 54 |    118 | CPU
DEBUG 01-06 08:44:55.051198.051198 lmp.py:380]   Expert 52 |    125 | CPU
DEBUG 01-06 08:44:55.051841.051841 lmp.py:380]   Expert 57 |    133 | CPU
DEBUG 01-06 08:44:55.051007.051007 lmp.py:380]   Expert  5 |    135 | CPU
DEBUG 01-06 08:44:55.051650.051650 lmp.py:380]   Expert 11 |    142 | CPU
DEBUG 01-06 08:44:55.051055.051055 lmp.py:380]   Expert 50 |    145 | CPU
DEBUG 01-06 08:44:55.051459.051459 lmp.py:380]   Expert 24 |    155 | GPU
DEBUG 01-06 08:44:55.051387.051387 lmp.py:380]   Expert 13 |    159 | GPU
DEBUG 01-06 08:44:55.051315.051315 lmp.py:380]   Expert 58 |    176 | GPU
DEBUG 01-06 08:44:55.051766.051766 lmp.py:380]   Expert 39 |    177 | GPU
DEBUG 01-06 08:44:55.051455.051455 lmp.py:380]   Expert 62 |    178 | GPU
DEBUG 01-06 08:44:55.051144.051144 lmp.py:380]   Expert 14 |    181 | GPU
DEBUG 01-06 08:44:55.051072.051072 lmp.py:380]   Expert 40 |    199 | GPU
DEBUG 01-06 08:44:55.051000.051000 lmp.py:380]   Expert 34 |    200 | GPU
DEBUG 01-06 08:44:55.051927.051927 lmp.py:380]   Expert 41 |    201 | GPU
DEBUG 01-06 08:44:55.051617.051617 lmp.py:380]   Expert  0 |    205 | GPU
DEBUG 01-06 08:44:55.051021.051021 lmp.py:380]   Expert 18 |    205 | GPU
DEBUG 01-06 08:44:55.051903.051903 lmp.py:380]   Expert 38 |    206 | GPU
DEBUG 01-06 08:44:55.051546.051546 lmp.py:380]   Expert 28 |    227 | GPU
DEBUG 01-06 08:44:55.051189.051189 lmp.py:380]   Expert 30 |    227 | GPU
DEBUG 01-06 08:44:55.051593.051593 lmp.py:380]   Expert  2 |    229 | GPU
DEBUG 01-06 08:44:55.051521.051521 lmp.py:380]   Expert 43 |    236 | GPU
DEBUG 01-06 08:44:55.051972.051972 lmp.py:380]   Expert 21 |    245 | GPU
DEBUG 01-06 08:44:55.051661.051661 lmp.py:380]   Expert 27 |    252 | GPU
DEBUG 01-06 08:44:55.051112.051112 lmp.py:380]   Expert 55 |    264 | GPU
DEBUG 01-06 08:44:55.051040.051040 lmp.py:380]   Expert  4 |    272 | GPU
DEBUG 01-06 08:44:55.051444.051444 lmp.py:380]   Expert 46 |    272 | GPU
DEBUG 01-06 08:44:55.051849.051849 lmp.py:380]   Expert 10 |    286 | GPU
DEBUG 01-06 08:44:55.051015.051015 lmp.py:380]   Expert 63 |    335 | GPU
DEBUG 01-06 08:44:55.051419.051419 lmp.py:380]   Expert 22 |    341 | GPU
DEBUG 01-06 08:44:55.051824.051824 lmp.py:380]   Expert 29 |    370 | GPU
DEBUG 01-06 08:44:55.051513.051513 lmp.py:380]   Expert 36 |    374 | GPU
DEBUG 01-06 08:44:55.051964.051964 lmp.py:380]   Expert 17 |    423 | GPU
DEBUG 01-06 08:44:55.051653.051653 lmp.py:380]   Expert 45 |    472 | GPU
DEBUG 01-06 08:44:55.051343.051343 lmp.py:380]   Expert 16 |    477 | GPU
DEBUG 01-06 08:44:55.051032.051032 lmp.py:380]   Expert 31 |    481 | GPU
DEBUG 01-06 08:44:55.051721.051721 lmp.py:380]   Expert 42 |    844 | GPU
DEBUG 01-06 08:44:55.051172.051172 lmp.py:380]   Expert 37 |    887 | GPU
DEBUG 01-06 08:44:55.051815.051815 lmp.py:381] 
DEBUG 01-06 08:44:55.051815.051815 lmp.py:381]   CPU total tokens: 2532 (20.6%)
DEBUG 01-06 08:44:55.051412.051412 lmp.py:382]   GPU total tokens: 9756 (79.4%)
DEBUG 01-06 08:44:55.051062.051062 cuda_h.py:19] end experts_map_get cost 0.0015223026275634766 seconds
DEBUG 01-06 08:44:55.051373.051373 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.051548.051548 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.051506.051506 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.052894.052894 cuda_h.py:19] end allocate_cuda_memory cost 0.00046181678771972656 seconds
DEBUG 01-06 08:44:55.052088.052088 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.052328.052328 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.052375.052375 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.052025.052025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5f428e1d-9e77-4085-9467-944f276cf566
DEBUG 01-06 08:44:55.052756.052756 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.052343.052343 client.py:127] Model loaded
DEBUG 01-06 08:44:55.053438.053438 cuda_h.py:19] end sllm_worker_task cost 0.008931159973144531 seconds
INFO 01-06 08:44:55.053229.053229 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5f428e1d-9e77-4085-9467-944f276cf566
DEBUG 01-06 08:44:55.053072.053072 cuda_h.py:19] end load_into_gpu_async cost 0.0012493133544921875 seconds
DEBUG 01-06 08:44:55.053774.053774 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.054589.054589 cuda_h.py:19] end restore_tensors2 cost 0.00036334991455078125 seconds
DEBUG 01-06 08:44:55.054180.054180 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024442672729492188 seconds
DEBUG 01-06 08:44:55.056803.056803 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005095243453979492 seconds
DEBUG 01-06 08:44:55.056878.056878 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.056556.056556 lmp.py:427] 
DEBUG 01-06 08:44:55.056556.056556 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:55.057638.057638 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-06 08:44:55.057672.057672 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.067218.067218 mlpmodule.py:704] group tensors cost 0.01044321060180664 s
DEBUG 01-06 08:44:55.070240.070240 mlpmodule.py:742] pad cost 0.0019555091857910156 s
DEBUG 01-06 08:44:55.070111.070111 mlpmodule.py:748] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-06 08:44:55.070220.070220 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-06 08:44:55.083475.083475 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:55.083706.083706 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.083888.083888 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-06 08:44:55.083741.083741 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.101386.101386 mlpmodule.py:793] group einsum cost 0.030794858932495117 s
DEBUG 01-06 08:44:55.102692.102692 mlpmodule.py:801] cpy2cputensor cost 0.0006113052368164062 s
DEBUG 01-06 08:44:55.107809.107809 cuda_h.py:19] end wait_cetm_experts cost 0.0501251220703125 seconds
DEBUG 01-06 08:44:55.107607.107607 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.108884.108884 cuda_h.py:19] end gpu_sexperts cost 0.001306772232055664 seconds
DEBUG 01-06 08:44:55.108495.108495 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.108021.108021 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-06 08:44:55.108108.108108 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.108579.108579 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5f428e1d-9e77-4085-9467-944f276cf566
INFO 01-06 08:44:55.113610.113610 client.py:127] Model loaded
DEBUG 01-06 08:44:55.113175.113175 cuda_h.py:19] end wait_experts cost 0.0043370723724365234 seconds
DEBUG 01-06 08:44:55.113216.113216 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.113733.113733 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.115181.115181 mlpmodule.py:662]  experts func einsum cost 0.05801081657409668 s
DEBUG 01-06 08:44:55.124565.124565 cuda_h.py:19] end gpu_experts cost 0.011385917663574219 seconds
DEBUG 01-06 08:44:55.124767.124767 cuda_h.py:19] end layer_moe_generate_21 cost 0.0753781795501709 seconds
DEBUG 01-06 08:44:55.124873.124873 lmp.py:221] -------------------------------- end layer 21 --------------------------------
DEBUG 01-06 08:44:55.125351.125351 lmp.py:177] -------------------------------- start layer 22 --------------------------------
DEBUG 01-06 08:44:55.125478.125478 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 08:44:55.125995.125995 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 08:44:55.125355.125355 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.7179718017578125e-05 seconds
DEBUG 01-06 08:44:55.125912.125912 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.626678466796875e-05 seconds
DEBUG 01-06 08:44:55.125031.125031 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.125140.125140 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:55.125170.125170 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.125052.125052 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.125386.125386 cuda_h.py:19] end allocate_cuda_memory cost 0.00024509429931640625 seconds
DEBUG 01-06 08:44:55.125303.125303 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.125635.125635 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.125075.125075 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.125447.125447 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e8021f18-fd5e-45d5-b507-23f7a07bfa6e
DEBUG 01-06 08:44:55.125847.125847 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:55.126847.126847 cuda_h.py:10] start self_attn
INFO 01-06 08:44:55.126980.126980 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e8021f18-fd5e-45d5-b507-23f7a07bfa6e
DEBUG 01-06 08:44:55.127147.127147 cuda_h.py:19] end load_into_gpu_async cost 0.0012547969818115234 seconds
DEBUG 01-06 08:44:55.127003.127003 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.127000.127000 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-06 08:44:55.127994.127994 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018377304077148438 seconds
INFO 01-06 08:44:55.127892.127892 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e8021f18-fd5e-45d5-b507-23f7a07bfa6e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.130357.130357 cuda_h.py:19] end self_attn cost 0.003891468048095703 seconds
DEBUG 01-06 08:44:55.130209.130209 cuda_h.py:19] end iln_self_attn_paln cost 0.005262851715087891 seconds
DEBUG 01-06 08:44:55.130621.130621 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-06 08:44:55.130099.130099 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.131870.131870 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-06 08:44:55.131508.131508 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.131491.131491 lmp.py:369] 
DEBUG 01-06 08:44:55.131491.131491 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.131578.131578 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:55.131513.131513 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:55.131633.131633 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:55.131845.131845 lmp.py:373] 
DEBUG 01-06 08:44:55.131845.131845 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.131534.131534 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.131707.131707 lmp.py:380]   Expert 48 |      1 | CPU
DEBUG 01-06 08:44:55.131873.131873 lmp.py:380]   Expert  6 |      5 | CPU
DEBUG 01-06 08:44:55.131563.131563 lmp.py:380]   Expert 52 |      8 | CPU
DEBUG 01-06 08:44:55.131775.131775 lmp.py:380]   Expert 54 |     15 | CPU
DEBUG 01-06 08:44:55.131749.131749 lmp.py:380]   Expert 46 |     16 | CPU
DEBUG 01-06 08:44:55.131962.131962 lmp.py:380]   Expert 31 |     27 | CPU
DEBUG 01-06 08:44:55.131174.131174 lmp.py:380]   Expert 47 |     28 | CPU
DEBUG 01-06 08:44:55.131387.131387 lmp.py:380]   Expert 62 |     30 | CPU
DEBUG 01-06 08:44:55.131599.131599 lmp.py:380]   Expert  9 |     39 | CPU
DEBUG 01-06 08:44:55.131335.131335 lmp.py:380]   Expert 30 |     41 | CPU
DEBUG 01-06 08:44:55.131309.131309 lmp.py:380]   Expert 44 |     43 | CPU
DEBUG 01-06 08:44:55.131760.131760 lmp.py:380]   Expert 13 |     44 | CPU
DEBUG 01-06 08:44:55.131449.131449 lmp.py:380]   Expert 60 |     46 | CPU
DEBUG 01-06 08:44:55.131661.131661 lmp.py:380]   Expert 42 |     50 | CPU
DEBUG 01-06 08:44:55.131397.131397 lmp.py:380]   Expert 61 |     52 | CPU
DEBUG 01-06 08:44:55.131133.131133 lmp.py:380]   Expert 45 |     53 | CPU
DEBUG 01-06 08:44:55.131345.131345 lmp.py:380]   Expert 10 |     63 | CPU
DEBUG 01-06 08:44:55.131842.131842 lmp.py:380]   Expert 63 |     65 | CPU
DEBUG 01-06 08:44:55.131816.131816 lmp.py:380]   Expert 41 |     72 | CPU
DEBUG 01-06 08:44:55.132552.132552 lmp.py:380]   Expert 49 |     72 | CPU
DEBUG 01-06 08:44:55.132526.132526 lmp.py:380]   Expert 21 |     75 | CPU
DEBUG 01-06 08:44:55.132739.132739 lmp.py:380]   Expert 12 |     80 | CPU
DEBUG 01-06 08:44:55.132189.132189 lmp.py:380]   Expert 11 |     86 | CPU
DEBUG 01-06 08:44:55.132925.132925 lmp.py:380]   Expert 15 |     94 | CPU
DEBUG 01-06 08:44:55.132899.132899 lmp.py:380]   Expert 32 |     95 | CPU
DEBUG 01-06 08:44:55.132304.132304 lmp.py:380]   Expert 43 |     99 | CPU
DEBUG 01-06 08:44:55.132231.132231 lmp.py:380]   Expert 57 |    104 | CPU
DEBUG 01-06 08:44:55.132682.132682 lmp.py:380]   Expert 28 |    106 | CPU
DEBUG 01-06 08:44:55.132372.132372 lmp.py:380]   Expert 22 |    108 | CPU
DEBUG 01-06 08:44:55.132061.132061 lmp.py:380]   Expert  7 |    109 | CPU
DEBUG 01-06 08:44:55.132989.132989 lmp.py:380]   Expert 37 |    137 | CPU
DEBUG 01-06 08:44:55.132916.132916 lmp.py:380]   Expert 20 |    139 | CPU
DEBUG 01-06 08:44:55.132844.132844 lmp.py:380]   Expert 58 |    139 | GPU
DEBUG 01-06 08:44:55.132295.132295 lmp.py:380]   Expert  1 |    161 | GPU
DEBUG 01-06 08:44:55.132461.132461 lmp.py:380]   Expert 25 |    170 | GPU
DEBUG 01-06 08:44:55.132627.132627 lmp.py:380]   Expert 39 |    178 | GPU
DEBUG 01-06 08:44:55.132316.132316 lmp.py:380]   Expert 16 |    180 | GPU
DEBUG 01-06 08:44:55.132006.132006 lmp.py:380]   Expert  8 |    190 | GPU
DEBUG 01-06 08:44:55.132934.132934 lmp.py:380]   Expert 24 |    200 | GPU
DEBUG 01-06 08:44:55.132384.132384 lmp.py:380]   Expert 38 |    209 | GPU
DEBUG 01-06 08:44:55.132074.132074 lmp.py:380]   Expert 50 |    212 | GPU
DEBUG 01-06 08:44:55.132763.132763 lmp.py:380]   Expert  3 |    225 | GPU
DEBUG 01-06 08:44:55.132605.132605 lmp.py:380]   Expert 35 |    229 | GPU
DEBUG 01-06 08:44:55.132414.132414 lmp.py:380]   Expert 27 |    244 | GPU
DEBUG 01-06 08:44:55.132819.132819 lmp.py:380]   Expert 26 |    253 | GPU
DEBUG 01-06 08:44:55.132269.132269 lmp.py:380]   Expert  2 |    259 | GPU
DEBUG 01-06 08:44:55.132243.132243 lmp.py:380]   Expert 29 |    275 | GPU
DEBUG 01-06 08:44:55.132410.132410 lmp.py:380]   Expert 17 |    284 | GPU
DEBUG 01-06 08:44:55.132099.132099 lmp.py:380]   Expert 56 |    286 | GPU
DEBUG 01-06 08:44:55.132503.132503 lmp.py:380]   Expert 23 |    296 | GPU
DEBUG 01-06 08:44:55.132670.132670 lmp.py:380]   Expert 51 |    299 | GPU
DEBUG 01-06 08:44:55.132597.132597 lmp.py:380]   Expert 19 |    303 | GPU
DEBUG 01-06 08:44:55.132432.132432 lmp.py:380]   Expert 40 |    307 | GPU
DEBUG 01-06 08:44:55.132552.132552 lmp.py:380]   Expert 34 |    315 | GPU
DEBUG 01-06 08:44:55.132957.132957 lmp.py:380]   Expert  4 |    341 | GPU
DEBUG 01-06 08:44:55.132646.132646 lmp.py:380]   Expert 14 |    385 | GPU
DEBUG 01-06 08:44:55.132574.132574 lmp.py:380]   Expert  0 |    392 | GPU
DEBUG 01-06 08:44:55.132501.132501 lmp.py:380]   Expert 55 |    428 | GPU
DEBUG 01-06 08:44:55.132429.132429 lmp.py:380]   Expert 18 |    457 | GPU
DEBUG 01-06 08:44:55.132595.132595 lmp.py:380]   Expert 53 |    476 | GPU
DEBUG 01-06 08:44:55.132523.132523 lmp.py:380]   Expert 36 |    573 | GPU
DEBUG 01-06 08:44:55.132928.132928 lmp.py:380]   Expert 33 |    603 | GPU
DEBUG 01-06 08:44:55.132809.132809 lmp.py:380]   Expert  5 |    681 | GPU
DEBUG 01-06 08:44:55.132737.132737 lmp.py:380]   Expert 59 |    736 | GPU
DEBUG 01-06 08:44:55.132857.132857 lmp.py:381] 
DEBUG 01-06 08:44:55.132857.132857 lmp.py:381]   CPU total tokens: 2002 (16.3%)
DEBUG 01-06 08:44:55.132738.132738 lmp.py:382]   GPU total tokens: 10286 (83.7%)
DEBUG 01-06 08:44:55.132149.132149 cuda_h.py:19] end experts_map_get cost 0.0015339851379394531 seconds
DEBUG 01-06 08:44:55.132507.132507 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.132145.132145 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.133719.133719 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.133788.133788 cuda_h.py:19] end allocate_cuda_memory cost 0.0004372596740722656 seconds
DEBUG 01-06 08:44:55.133598.133598 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.133461.133461 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.133601.133601 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.133250.133250 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3ab64ddf-e223-41e8-b80d-1c437101b943
DEBUG 01-06 08:44:55.133643.133643 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.134854.134854 client.py:127] Model loaded
DEBUG 01-06 08:44:55.134141.134141 cuda_h.py:19] end sllm_worker_task cost 0.008827924728393555 seconds
INFO 01-06 08:44:55.134977.134977 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3ab64ddf-e223-41e8-b80d-1c437101b943
DEBUG 01-06 08:44:55.134728.134728 cuda_h.py:19] end load_into_gpu_async cost 0.0012478828430175781 seconds
DEBUG 01-06 08:44:55.134384.134384 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.135437.135437 cuda_h.py:19] end restore_tensors2 cost 0.0003638267517089844 seconds
DEBUG 01-06 08:44:55.135074.135074 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002416849136352539 seconds
DEBUG 01-06 08:44:55.137427.137427 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00507354736328125 seconds
DEBUG 01-06 08:44:55.138309.138309 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.138531.138531 lmp.py:427] 
DEBUG 01-06 08:44:55.138531.138531 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:55.138559.138559 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-06 08:44:55.138686.138686 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.148863.148863 mlpmodule.py:704] group tensors cost 0.01028132438659668 s
DEBUG 01-06 08:44:55.151771.151771 mlpmodule.py:742] pad cost 0.0018372535705566406 s
DEBUG 01-06 08:44:55.151397.151397 mlpmodule.py:748] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-06 08:44:55.151022.151022 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-06 08:44:55.163986.163986 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:55.163337.163337 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.163996.163996 mlpmodule.py:773] group_w3 first element: -0.025390625
WARNING 01-06 08:44:55.163033.163033 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.184592.184592 mlpmodule.py:793] group einsum cost 0.032567739486694336 s
DEBUG 01-06 08:44:55.184315.184315 mlpmodule.py:801] cpy2cputensor cost 0.0006103515625 s
DEBUG 01-06 08:44:55.189306.189306 cuda_h.py:19] end wait_cetm_experts cost 0.051503658294677734 seconds
DEBUG 01-06 08:44:55.189528.189528 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.191088.191088 cuda_h.py:19] end gpu_sexperts cost 0.0016672611236572266 seconds
DEBUG 01-06 08:44:55.191984.191984 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.191265.191265 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6941299438476562e-05 seconds
DEBUG 01-06 08:44:55.191637.191637 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.191869.191869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3ab64ddf-e223-41e8-b80d-1c437101b943
INFO 01-06 08:44:55.193314.193314 client.py:127] Model loaded
DEBUG 01-06 08:44:55.193587.193587 cuda_h.py:19] end wait_experts cost 0.0018644332885742188 seconds
DEBUG 01-06 08:44:55.193198.193198 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.193238.193238 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.197149.197149 mlpmodule.py:662]  experts func einsum cost 0.059209346771240234 s
DEBUG 01-06 08:44:55.205582.205582 cuda_h.py:19] end gpu_experts cost 0.011446952819824219 seconds
DEBUG 01-06 08:44:55.205129.205129 cuda_h.py:19] end layer_moe_generate_22 cost 0.07467293739318848 seconds
DEBUG 01-06 08:44:55.205964.205964 lmp.py:221] -------------------------------- end layer 22 --------------------------------
DEBUG 01-06 08:44:55.205018.205018 lmp.py:177] -------------------------------- start layer 23 --------------------------------
DEBUG 01-06 08:44:55.205767.205767 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 08:44:55.205146.205146 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 08:44:55.205558.205558 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:44:55.205944.205944 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.176399230957031e-05 seconds
DEBUG 01-06 08:44:55.205700.205700 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.205992.205992 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:55.205481.205481 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.205887.205887 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.206743.206743 cuda_h.py:19] end allocate_cuda_memory cost 0.00021076202392578125 seconds
DEBUG 01-06 08:44:55.206566.206566 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.206852.206852 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.206768.206768 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.206040.206040 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 25bea18c-fd83-462a-b9f2-9ee78f429f64
DEBUG 01-06 08:44:55.206917.206917 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:55.206250.206250 cuda_h.py:10] start self_attn
INFO 01-06 08:44:55.207768.207768 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 25bea18c-fd83-462a-b9f2-9ee78f429f64
DEBUG 01-06 08:44:55.207981.207981 cuda_h.py:19] end load_into_gpu_async cost 0.0010783672332763672 seconds
DEBUG 01-06 08:44:55.207538.207538 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.207767.207767 cuda_h.py:19] end restore_tensors2 cost 7.224082946777344e-05 seconds
DEBUG 01-06 08:44:55.207238.207238 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001613616943359375 seconds
INFO 01-06 08:44:55.208882.208882 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 25bea18c-fd83-462a-b9f2-9ee78f429f64
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.210979.210979 cuda_h.py:19] end self_attn cost 0.003914356231689453 seconds
DEBUG 01-06 08:44:55.210287.210287 cuda_h.py:19] end iln_self_attn_paln cost 0.005167961120605469 seconds
DEBUG 01-06 08:44:55.210176.210176 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-06 08:44:55.211893.211893 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.211273.211273 cuda_h.py:19] end gate cost 0.0006320476531982422 seconds
DEBUG 01-06 08:44:55.211149.211149 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.212324.212324 lmp.py:369] 
DEBUG 01-06 08:44:55.212324.212324 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.212365.212365 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:55.212538.212538 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:55.212612.212612 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:55.212824.212824 lmp.py:373] 
DEBUG 01-06 08:44:55.212824.212824 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.212752.212752 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.212402.212402 lmp.py:380]   Expert 25 |      5 | CPU
DEBUG 01-06 08:44:55.212806.212806 lmp.py:380]   Expert 38 |      7 | CPU
DEBUG 01-06 08:44:55.212257.212257 lmp.py:380]   Expert  7 |     18 | CPU
DEBUG 01-06 08:44:55.212231.212231 lmp.py:380]   Expert 30 |     21 | CPU
DEBUG 01-06 08:44:55.212205.212205 lmp.py:380]   Expert 49 |     26 | CPU
DEBUG 01-06 08:44:55.212941.212941 lmp.py:380]   Expert 27 |     29 | CPU
DEBUG 01-06 08:44:55.212915.212915 lmp.py:380]   Expert 44 |     32 | CPU
DEBUG 01-06 08:44:55.212604.212604 lmp.py:380]   Expert 63 |     33 | CPU
DEBUG 01-06 08:44:55.212578.212578 lmp.py:380]   Expert 47 |     39 | CPU
DEBUG 01-06 08:44:55.212029.212029 lmp.py:380]   Expert 53 |     51 | CPU
DEBUG 01-06 08:44:55.212480.212480 lmp.py:380]   Expert 60 |     51 | CPU
DEBUG 01-06 08:44:55.212215.212215 lmp.py:380]   Expert 28 |     59 | CPU
DEBUG 01-06 08:44:55.212951.212951 lmp.py:380]   Expert 17 |     61 | CPU
DEBUG 01-06 08:44:55.212210.212210 lmp.py:380]   Expert 16 |     64 | CPU
DEBUG 01-06 08:44:55.212813.212813 lmp.py:380]   Expert 12 |     78 | CPU
DEBUG 01-06 08:44:55.212523.212523 lmp.py:380]   Expert 19 |     78 | CPU
DEBUG 01-06 08:44:55.212974.212974 lmp.py:380]   Expert 58 |     80 | CPU
DEBUG 01-06 08:44:55.212186.212186 lmp.py:380]   Expert  0 |     81 | CPU
DEBUG 01-06 08:44:55.212160.212160 lmp.py:380]   Expert 11 |     82 | CPU
DEBUG 01-06 08:44:55.212134.212134 lmp.py:380]   Expert 42 |     84 | CPU
DEBUG 01-06 08:44:55.212062.212062 lmp.py:380]   Expert 35 |     85 | CPU
DEBUG 01-06 08:44:55.212228.212228 lmp.py:380]   Expert  5 |     87 | CPU
DEBUG 01-06 08:44:55.212825.212825 lmp.py:380]   Expert 40 |     92 | CPU
DEBUG 01-06 08:44:55.212229.212229 lmp.py:380]   Expert 36 |     95 | CPU
DEBUG 01-06 08:44:55.212634.212634 lmp.py:380]   Expert 61 |    132 | CPU
DEBUG 01-06 08:44:55.212562.212562 lmp.py:380]   Expert 34 |    135 | CPU
DEBUG 01-06 08:44:55.212251.212251 lmp.py:380]   Expert 15 |    137 | CPU
DEBUG 01-06 08:44:55.212417.212417 lmp.py:380]   Expert 55 |    145 | CPU
DEBUG 01-06 08:44:55.212106.212106 lmp.py:380]   Expert 62 |    157 | CPU
DEBUG 01-06 08:44:55.212034.212034 lmp.py:380]   Expert 14 |    158 | CPU
DEBUG 01-06 08:44:55.212723.212723 lmp.py:380]   Expert  6 |    161 | CPU
DEBUG 01-06 08:44:55.212651.212651 lmp.py:380]   Expert  3 |    163 | GPU
DEBUG 01-06 08:44:55.212817.212817 lmp.py:380]   Expert 41 |    165 | GPU
DEBUG 01-06 08:44:55.212983.212983 lmp.py:380]   Expert 33 |    169 | GPU
DEBUG 01-06 08:44:55.212150.212150 lmp.py:380]   Expert 24 |    195 | GPU
DEBUG 01-06 08:44:55.212554.212554 lmp.py:380]   Expert 37 |    195 | GPU
DEBUG 01-06 08:44:55.212959.212959 lmp.py:380]   Expert 52 |    197 | GPU
DEBUG 01-06 08:44:55.212125.212125 lmp.py:380]   Expert 39 |    199 | GPU
DEBUG 01-06 08:44:55.212814.212814 lmp.py:380]   Expert  1 |    207 | GPU
DEBUG 01-06 08:44:55.212265.212265 lmp.py:380]   Expert 26 |    224 | GPU
DEBUG 01-06 08:44:55.212954.212954 lmp.py:380]   Expert  9 |    229 | GPU
DEBUG 01-06 08:44:55.212644.212644 lmp.py:380]   Expert  2 |    231 | GPU
DEBUG 01-06 08:44:55.212095.212095 lmp.py:380]   Expert 23 |    234 | GPU
DEBUG 01-06 08:44:55.212545.212545 lmp.py:380]   Expert 13 |    235 | GPU
DEBUG 01-06 08:44:55.212996.212996 lmp.py:380]   Expert 22 |    237 | GPU
DEBUG 01-06 08:44:55.212686.212686 lmp.py:380]   Expert  8 |    244 | GPU
DEBUG 01-06 08:44:55.212090.212090 lmp.py:380]   Expert 45 |    282 | GPU
DEBUG 01-06 08:44:55.212256.212256 lmp.py:380]   Expert 43 |    284 | GPU
DEBUG 01-06 08:44:55.212661.212661 lmp.py:380]   Expert 20 |    286 | GPU
DEBUG 01-06 08:44:55.213065.213065 lmp.py:380]   Expert 21 |    296 | GPU
DEBUG 01-06 08:44:55.213470.213470 lmp.py:380]   Expert 46 |    299 | GPU
DEBUG 01-06 08:44:55.213636.213636 lmp.py:380]   Expert 18 |    310 | GPU
DEBUG 01-06 08:44:55.213087.213087 lmp.py:380]   Expert 48 |    312 | GPU
DEBUG 01-06 08:44:55.213538.213538 lmp.py:380]   Expert 57 |    333 | GPU
DEBUG 01-06 08:44:55.213227.213227 lmp.py:380]   Expert 59 |    337 | GPU
DEBUG 01-06 08:44:55.213916.213916 lmp.py:380]   Expert 56 |    362 | GPU
DEBUG 01-06 08:44:55.213606.213606 lmp.py:380]   Expert 32 |    382 | GPU
DEBUG 01-06 08:44:55.213295.213295 lmp.py:380]   Expert 54 |    448 | GPU
DEBUG 01-06 08:44:55.213746.213746 lmp.py:380]   Expert 31 |    455 | GPU
DEBUG 01-06 08:44:55.213912.213912 lmp.py:380]   Expert  4 |    457 | GPU
DEBUG 01-06 08:44:55.213840.213840 lmp.py:380]   Expert 29 |    507 | GPU
DEBUG 01-06 08:44:55.213006.213006 lmp.py:380]   Expert 50 |    530 | GPU
DEBUG 01-06 08:44:55.213411.213411 lmp.py:380]   Expert 10 |    921 | GPU
DEBUG 01-06 08:44:55.213053.213053 lmp.py:381] 
DEBUG 01-06 08:44:55.213053.213053 lmp.py:381]   CPU total tokens: 2363 (19.2%)
DEBUG 01-06 08:44:55.213935.213935 lmp.py:382]   GPU total tokens: 9925 (80.8%)
DEBUG 01-06 08:44:55.213061.213061 cuda_h.py:19] end experts_map_get cost 0.0015218257904052734 seconds
DEBUG 01-06 08:44:55.213420.213420 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.213117.213117 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.213552.213552 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.213048.213048 cuda_h.py:19] end allocate_cuda_memory cost 0.0003139972686767578 seconds
DEBUG 01-06 08:44:55.213289.213289 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.213952.213952 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.214761.214761 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.214126.214126 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1bdd675-3b88-4a34-a56e-87a3ad8f6e4c
DEBUG 01-06 08:44:55.214102.214102 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.214382.214382 client.py:127] Model loaded
DEBUG 01-06 08:44:55.214923.214923 cuda_h.py:19] end sllm_worker_task cost 0.0086517333984375 seconds
INFO 01-06 08:44:55.215938.215938 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1bdd675-3b88-4a34-a56e-87a3ad8f6e4c
DEBUG 01-06 08:44:55.215258.215258 cuda_h.py:19] end load_into_gpu_async cost 0.0012052059173583984 seconds
DEBUG 01-06 08:44:55.215437.215437 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.215953.215953 cuda_h.py:19] end restore_tensors2 cost 0.0003542900085449219 seconds
DEBUG 01-06 08:44:55.215783.215783 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022575855255126953 seconds
DEBUG 01-06 08:44:55.218897.218897 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004923105239868164 seconds
DEBUG 01-06 08:44:55.218726.218726 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.218782.218782 lmp.py:427] 
DEBUG 01-06 08:44:55.218782.218782 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:55.218247.218247 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-06 08:44:55.218587.218587 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.228087.228087 mlpmodule.py:704] group tensors cost 0.009851455688476562 s
DEBUG 01-06 08:44:55.230914.230914 mlpmodule.py:742] pad cost 0.0014536380767822266 s
DEBUG 01-06 08:44:55.230043.230043 mlpmodule.py:748] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 08:44:55.230224.230224 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 08:44:55.241431.241431 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:55.241205.241205 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.241295.241295 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-06 08:44:55.241849.241849 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.258195.258195 mlpmodule.py:793] group einsum cost 0.02753281593322754 s
DEBUG 01-06 08:44:55.259277.259277 mlpmodule.py:801] cpy2cputensor cost 0.0006682872772216797 s
DEBUG 01-06 08:44:55.264051.264051 cuda_h.py:19] end wait_cetm_experts cost 0.04548811912536621 seconds
DEBUG 01-06 08:44:55.264657.264657 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.265281.265281 cuda_h.py:19] end gpu_sexperts cost 0.0015728473663330078 seconds
DEBUG 01-06 08:44:55.265462.265462 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.265411.265411 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-06 08:44:55.265022.265022 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.265923.265923 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1bdd675-3b88-4a34-a56e-87a3ad8f6e4c
INFO 01-06 08:44:55.271374.271374 client.py:127] Model loaded
DEBUG 01-06 08:44:55.271985.271985 cuda_h.py:19] end wait_experts cost 0.005804777145385742 seconds
DEBUG 01-06 08:44:55.271456.271456 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.271405.271405 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.271779.271779 mlpmodule.py:662]  experts func einsum cost 0.053281307220458984 s
DEBUG 01-06 08:44:55.282413.282413 cuda_h.py:19] end gpu_experts cost 0.010533332824707031 seconds
DEBUG 01-06 08:44:55.282708.282708 cuda_h.py:19] end layer_moe_generate_23 cost 0.0714266300201416 seconds
DEBUG 01-06 08:44:55.282906.282906 lmp.py:221] -------------------------------- end layer 23 --------------------------------
DEBUG 01-06 08:44:55.282000.282000 lmp.py:177] -------------------------------- start layer 24 --------------------------------
DEBUG 01-06 08:44:55.282981.282981 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 08:44:55.282114.282114 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 08:44:55.282898.282898 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.574920654296875e-05 seconds
DEBUG 01-06 08:44:55.282475.282475 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.009506225585938e-05 seconds
DEBUG 01-06 08:44:55.282833.282833 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.282610.282610 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:55.282943.282943 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.283019.283019 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.283816.283816 cuda_h.py:19] end allocate_cuda_memory cost 0.0002181529998779297 seconds
DEBUG 01-06 08:44:55.283666.283666 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.283853.283853 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.283365.283365 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.283783.283783 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bba2dbe3-4797-4a4c-89af-2dc8e7d8ddea
DEBUG 01-06 08:44:55.283468.283468 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:55.283992.283992 cuda_h.py:10] start self_attn
INFO 01-06 08:44:55.284283.284283 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bba2dbe3-4797-4a4c-89af-2dc8e7d8ddea
DEBUG 01-06 08:44:55.284795.284795 cuda_h.py:19] end load_into_gpu_async cost 0.0010442733764648438 seconds
DEBUG 01-06 08:44:55.284590.284590 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.284627.284627 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 08:44:55.284144.284144 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015900135040283203 seconds
INFO 01-06 08:44:55.285519.285519 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bba2dbe3-4797-4a4c-89af-2dc8e7d8ddea
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.287484.287484 cuda_h.py:19] end self_attn cost 0.0039501190185546875 seconds
DEBUG 01-06 08:44:55.288302.288302 cuda_h.py:19] end iln_self_attn_paln cost 0.005267143249511719 seconds
DEBUG 01-06 08:44:55.288046.288046 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-06 08:44:55.288570.288570 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.288938.288938 cuda_h.py:19] end gate cost 0.0006587505340576172 seconds
DEBUG 01-06 08:44:55.288290.288290 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.289207.289207 lmp.py:369] 
DEBUG 01-06 08:44:55.289207.289207 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.289533.289533 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:55.289182.289182 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:55.289733.289733 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:55.289899.289899 lmp.py:373] 
DEBUG 01-06 08:44:55.289899.289899 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.289303.289303 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.289668.289668 lmp.py:380]   Expert 47 |      2 | CPU
DEBUG 01-06 08:44:55.289550.289550 lmp.py:380]   Expert 16 |      3 | CPU
DEBUG 01-06 08:44:55.289478.289478 lmp.py:380]   Expert  6 |     11 | CPU
DEBUG 01-06 08:44:55.289405.289405 lmp.py:380]   Expert 30 |     11 | CPU
DEBUG 01-06 08:44:55.289810.289810 lmp.py:380]   Expert 42 |     13 | CPU
DEBUG 01-06 08:44:55.289976.289976 lmp.py:380]   Expert 25 |     22 | CPU
DEBUG 01-06 08:44:55.289904.289904 lmp.py:380]   Expert 35 |     27 | CPU
DEBUG 01-06 08:44:55.289355.289355 lmp.py:380]   Expert 54 |     29 | CPU
DEBUG 01-06 08:44:55.289567.289567 lmp.py:380]   Expert 51 |     37 | CPU
DEBUG 01-06 08:44:55.289018.289018 lmp.py:380]   Expert 13 |     47 | CPU
DEBUG 01-06 08:44:55.289469.289469 lmp.py:380]   Expert  2 |     49 | CPU
DEBUG 01-06 08:44:55.289920.289920 lmp.py:380]   Expert 48 |     63 | CPU
DEBUG 01-06 08:44:55.289132.289132 lmp.py:380]   Expert 46 |     64 | CPU
DEBUG 01-06 08:44:55.289583.289583 lmp.py:380]   Expert 56 |     84 | CPU
DEBUG 01-06 08:44:55.289749.289749 lmp.py:380]   Expert 32 |     90 | CPU
DEBUG 01-06 08:44:55.289915.289915 lmp.py:380]   Expert 60 |     90 | CPU
DEBUG 01-06 08:44:55.289605.289605 lmp.py:380]   Expert 62 |     94 | CPU
DEBUG 01-06 08:44:55.289579.289579 lmp.py:380]   Expert 21 |     96 | CPU
DEBUG 01-06 08:44:55.289030.289030 lmp.py:380]   Expert 59 |     98 | CPU
DEBUG 01-06 08:44:55.289719.289719 lmp.py:380]   Expert  7 |    102 | CPU
DEBUG 01-06 08:44:55.289077.289077 lmp.py:380]   Expert  0 |    109 | CPU
DEBUG 01-06 08:44:55.289720.289720 lmp.py:380]   Expert 28 |    111 | CPU
DEBUG 01-06 08:44:55.289125.289125 lmp.py:380]   Expert 41 |    138 | CPU
DEBUG 01-06 08:44:55.289052.289052 lmp.py:380]   Expert 12 |    143 | CPU
DEBUG 01-06 08:44:55.289411.289411 lmp.py:380]   Expert 36 |    145 | CPU
DEBUG 01-06 08:44:55.289292.289292 lmp.py:380]   Expert  5 |    159 | CPU
DEBUG 01-06 08:44:55.289697.289697 lmp.py:380]   Expert 23 |    167 | CPU
DEBUG 01-06 08:44:55.289863.289863 lmp.py:380]   Expert 55 |    167 | CPU
DEBUG 01-06 08:44:55.289029.289029 lmp.py:380]   Expert 20 |    168 | CPU
DEBUG 01-06 08:44:55.289433.289433 lmp.py:380]   Expert 24 |    168 | CPU
DEBUG 01-06 08:44:55.289361.289361 lmp.py:380]   Expert 61 |    178 | CPU
DEBUG 01-06 08:44:55.289766.289766 lmp.py:380]   Expert 14 |    186 | GPU
DEBUG 01-06 08:44:55.289693.289693 lmp.py:380]   Expert 57 |    193 | GPU
DEBUG 01-06 08:44:55.289336.289336 lmp.py:380]   Expert 15 |    195 | GPU
DEBUG 01-06 08:44:55.289979.289979 lmp.py:380]   Expert 44 |    197 | GPU
DEBUG 01-06 08:44:55.289907.289907 lmp.py:380]   Expert 22 |    198 | GPU
DEBUG 01-06 08:44:55.289835.289835 lmp.py:380]   Expert 31 |    203 | GPU
DEBUG 01-06 08:44:55.289524.289524 lmp.py:380]   Expert 10 |    209 | GPU
DEBUG 01-06 08:44:55.290452.290452 lmp.py:380]   Expert 40 |    213 | GPU
DEBUG 01-06 08:44:55.290379.290379 lmp.py:380]   Expert 39 |    221 | GPU
DEBUG 01-06 08:44:55.290069.290069 lmp.py:380]   Expert 19 |    223 | GPU
DEBUG 01-06 08:44:55.290997.290997 lmp.py:380]   Expert 50 |    232 | GPU
DEBUG 01-06 08:44:55.290924.290924 lmp.py:380]   Expert 53 |    234 | GPU
DEBUG 01-06 08:44:55.290567.290567 lmp.py:380]   Expert  4 |    241 | GPU
DEBUG 01-06 08:44:55.290972.290972 lmp.py:380]   Expert 52 |    242 | GPU
DEBUG 01-06 08:44:55.290138.290138 lmp.py:380]   Expert 33 |    247 | GPU
DEBUG 01-06 08:44:55.290542.290542 lmp.py:380]   Expert 49 |    247 | GPU
DEBUG 01-06 08:44:55.290470.290470 lmp.py:380]   Expert 45 |    252 | GPU
DEBUG 01-06 08:44:55.290398.290398 lmp.py:380]   Expert 63 |    258 | GPU
DEBUG 01-06 08:44:55.290326.290326 lmp.py:380]   Expert 34 |    265 | GPU
DEBUG 01-06 08:44:55.290253.290253 lmp.py:380]   Expert 26 |    273 | GPU
DEBUG 01-06 08:44:55.290181.290181 lmp.py:380]   Expert  3 |    282 | GPU
DEBUG 01-06 08:44:55.290109.290109 lmp.py:380]   Expert  1 |    288 | GPU
DEBUG 01-06 08:44:55.290990.290990 lmp.py:380]   Expert  9 |    292 | GPU
DEBUG 01-06 08:44:55.290918.290918 lmp.py:380]   Expert 37 |    294 | GPU
DEBUG 01-06 08:44:55.290084.290084 lmp.py:380]   Expert 17 |    296 | GPU
DEBUG 01-06 08:44:55.290250.290250 lmp.py:380]   Expert 18 |    360 | GPU
DEBUG 01-06 08:44:55.290178.290178 lmp.py:380]   Expert 38 |    384 | GPU
DEBUG 01-06 08:44:55.290344.290344 lmp.py:380]   Expert  8 |    416 | GPU
DEBUG 01-06 08:44:55.290272.290272 lmp.py:380]   Expert 11 |    450 | GPU
DEBUG 01-06 08:44:55.290438.290438 lmp.py:380]   Expert 29 |    459 | GPU
DEBUG 01-06 08:44:55.290366.290366 lmp.py:380]   Expert 58 |    471 | GPU
DEBUG 01-06 08:44:55.290293.290293 lmp.py:380]   Expert 27 |   1082 | GPU
DEBUG 01-06 08:44:55.290175.290175 lmp.py:381] 
DEBUG 01-06 08:44:55.290175.290175 lmp.py:381]   CPU total tokens: 2685 (21.9%)
DEBUG 01-06 08:44:55.290963.290963 lmp.py:382]   GPU total tokens: 9603 (78.1%)
DEBUG 01-06 08:44:55.290852.290852 cuda_h.py:19] end experts_map_get cost 0.001508951187133789 seconds
DEBUG 01-06 08:44:55.290210.290210 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.290616.290616 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.290481.290481 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.291183.291183 cuda_h.py:19] end allocate_cuda_memory cost 0.00034117698669433594 seconds
DEBUG 01-06 08:44:55.291185.291185 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.291564.291564 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.291850.291850 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.291976.291976 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bd0c637-3638-46de-9369-e78e92e8e03f
DEBUG 01-06 08:44:55.291429.291429 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.291825.291825 client.py:127] Model loaded
DEBUG 01-06 08:44:55.291489.291489 cuda_h.py:19] end sllm_worker_task cost 0.00879526138305664 seconds
INFO 01-06 08:44:55.292882.292882 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bd0c637-3638-46de-9369-e78e92e8e03f
DEBUG 01-06 08:44:55.292500.292500 cuda_h.py:19] end load_into_gpu_async cost 0.0012497901916503906 seconds
DEBUG 01-06 08:44:55.292441.292441 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.292070.292070 cuda_h.py:19] end restore_tensors2 cost 0.0003674030303955078 seconds
DEBUG 01-06 08:44:55.292661.292661 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002327442169189453 seconds
DEBUG 01-06 08:44:55.295992.295992 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004937887191772461 seconds
DEBUG 01-06 08:44:55.295868.295868 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.295613.295613 lmp.py:427] 
DEBUG 01-06 08:44:55.295613.295613 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:55.295310.295310 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-06 08:44:55.295960.295960 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.303685.303685 mlpmodule.py:704] group tensors cost 0.007279157638549805 s
DEBUG 01-06 08:44:55.306722.306722 mlpmodule.py:742] pad cost 0.0024781227111816406 s
DEBUG 01-06 08:44:55.306136.306136 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-06 08:44:55.306384.306384 mlpmodule.py:753] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-06 08:44:55.316284.316284 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:55.316575.316575 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.316340.316340 mlpmodule.py:773] group_w3 first element: 0.00653076171875
WARNING 01-06 08:44:55.317516.317516 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.333417.333417 mlpmodule.py:793] group einsum cost 0.026629924774169922 s
DEBUG 01-06 08:44:55.334595.334595 mlpmodule.py:801] cpy2cputensor cost 0.0007605552673339844 s
DEBUG 01-06 08:44:55.338018.338018 cuda_h.py:19] end wait_cetm_experts cost 0.04322457313537598 seconds
DEBUG 01-06 08:44:55.339788.339788 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.340481.340481 cuda_h.py:19] end gpu_sexperts cost 0.0014464855194091797 seconds
DEBUG 01-06 08:44:55.340046.340046 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.340711.340711 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:44:55.340321.340321 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.340030.340030 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bd0c637-3638-46de-9369-e78e92e8e03f
DEBUG 01-06 08:44:55.346960.346960 mlpmodule.py:662]  experts func einsum cost 0.05072522163391113 s
INFO 01-06 08:44:55.346608.346608 client.py:127] Model loaded
DEBUG 01-06 08:44:55.346472.346472 cuda_h.py:19] end wait_experts cost 0.006258487701416016 seconds
DEBUG 01-06 08:44:55.347989.347989 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.347030.347030 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.357803.357803 cuda_h.py:19] end gpu_experts cost 0.01060342788696289 seconds
DEBUG 01-06 08:44:55.357190.357190 cuda_h.py:19] end layer_moe_generate_24 cost 0.06956052780151367 seconds
DEBUG 01-06 08:44:55.357985.357985 lmp.py:221] -------------------------------- end layer 24 --------------------------------
DEBUG 01-06 08:44:55.357463.357463 lmp.py:177] -------------------------------- start layer 25 --------------------------------
DEBUG 01-06 08:44:55.358398.358398 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 08:44:55.358915.358915 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 08:44:55.358560.358560 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.765655517578125e-05 seconds
DEBUG 01-06 08:44:55.358329.358329 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.2479248046875e-05 seconds
DEBUG 01-06 08:44:55.358403.358403 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.358471.358471 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:55.358526.358526 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.358415.358415 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.358027.358027 cuda_h.py:19] end allocate_cuda_memory cost 0.00023698806762695312 seconds
DEBUG 01-06 08:44:55.358851.358851 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.358806.358806 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.358398.358398 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.358346.358346 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be185c5a-bb0b-4f6c-96b7-8285136c902d
DEBUG 01-06 08:44:55.358945.358945 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:55.359756.359756 cuda_h.py:10] start self_attn
INFO 01-06 08:44:55.359499.359499 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be185c5a-bb0b-4f6c-96b7-8285136c902d
DEBUG 01-06 08:44:55.359766.359766 cuda_h.py:19] end load_into_gpu_async cost 0.0011630058288574219 seconds
DEBUG 01-06 08:44:55.359184.359184 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.360903.360903 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-06 08:44:55.360235.360235 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017485618591308594 seconds
INFO 01-06 08:44:55.360040.360040 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be185c5a-bb0b-4f6c-96b7-8285136c902d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.363595.363595 cuda_h.py:19] end self_attn cost 0.004031181335449219 seconds
DEBUG 01-06 08:44:55.363394.363394 cuda_h.py:19] end iln_self_attn_paln cost 0.005440711975097656 seconds
DEBUG 01-06 08:44:55.363806.363806 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-06 08:44:55.363000.363000 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.364347.364347 cuda_h.py:19] end gate cost 0.0006418228149414062 seconds
DEBUG 01-06 08:44:55.364176.364176 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.364484.364484 lmp.py:369] 
DEBUG 01-06 08:44:55.364484.364484 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.364240.364240 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:44:55.364128.364128 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:44:55.364156.364156 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:44:55.364799.364799 lmp.py:373] 
DEBUG 01-06 08:44:55.364799.364799 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.364680.364680 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.364045.364045 lmp.py:380]   Expert 42 |      1 | CPU
DEBUG 01-06 08:44:55.364926.364926 lmp.py:380]   Expert 10 |      3 | CPU
DEBUG 01-06 08:44:55.364092.364092 lmp.py:380]   Expert 33 |      5 | CPU
DEBUG 01-06 08:44:55.364020.364020 lmp.py:380]   Expert  0 |      6 | CPU
DEBUG 01-06 08:44:55.364948.364948 lmp.py:380]   Expert 16 |      9 | CPU
DEBUG 01-06 08:44:55.364876.364876 lmp.py:380]   Expert 20 |     14 | CPU
DEBUG 01-06 08:44:55.364042.364042 lmp.py:380]   Expert  2 |     23 | CPU
DEBUG 01-06 08:44:55.365446.365446 lmp.py:380]   Expert 23 |     28 | CPU
DEBUG 01-06 08:44:55.365136.365136 lmp.py:380]   Expert 18 |     35 | CPU
DEBUG 01-06 08:44:55.365348.365348 lmp.py:380]   Expert 46 |     36 | CPU
DEBUG 01-06 08:44:55.365561.365561 lmp.py:380]   Expert 36 |     37 | CPU
DEBUG 01-06 08:44:55.365535.365535 lmp.py:380]   Expert 22 |     40 | CPU
DEBUG 01-06 08:44:55.365509.365509 lmp.py:380]   Expert 55 |     41 | CPU
DEBUG 01-06 08:44:55.365244.365244 lmp.py:380]   Expert 27 |     46 | CPU
DEBUG 01-06 08:44:55.365695.365695 lmp.py:380]   Expert  5 |     48 | CPU
DEBUG 01-06 08:44:55.365577.365577 lmp.py:380]   Expert 61 |     48 | CPU
DEBUG 01-06 08:44:55.365743.365743 lmp.py:380]   Expert 38 |     52 | CPU
DEBUG 01-06 08:44:55.365955.365955 lmp.py:380]   Expert 21 |     57 | CPU
DEBUG 01-06 08:44:55.365837.365837 lmp.py:380]   Expert 31 |     57 | CPU
DEBUG 01-06 08:44:55.365764.365764 lmp.py:380]   Expert 43 |     57 | CPU
DEBUG 01-06 08:44:55.365692.365692 lmp.py:380]   Expert  8 |     64 | CPU
DEBUG 01-06 08:44:55.365620.365620 lmp.py:380]   Expert 32 |     64 | CPU
DEBUG 01-06 08:44:55.365547.365547 lmp.py:380]   Expert 13 |     67 | CPU
DEBUG 01-06 08:44:55.365998.365998 lmp.py:380]   Expert 53 |     86 | CPU
DEBUG 01-06 08:44:55.365688.365688 lmp.py:380]   Expert  4 |     87 | CPU
DEBUG 01-06 08:44:55.365092.365092 lmp.py:380]   Expert 45 |     94 | CPU
DEBUG 01-06 08:44:55.365735.365735 lmp.py:380]   Expert 59 |     94 | CPU
DEBUG 01-06 08:44:55.365663.365663 lmp.py:380]   Expert 56 |     96 | CPU
DEBUG 01-06 08:44:55.365352.365352 lmp.py:380]   Expert 24 |     97 | CPU
DEBUG 01-06 08:44:55.365280.365280 lmp.py:380]   Expert 15 |    102 | CPU
DEBUG 01-06 08:44:55.365446.365446 lmp.py:380]   Expert 14 |    106 | CPU
DEBUG 01-06 08:44:55.365135.365135 lmp.py:380]   Expert 44 |    106 | CPU
DEBUG 01-06 08:44:55.365825.365825 lmp.py:380]   Expert 63 |    125 | GPU
DEBUG 01-06 08:44:55.365752.365752 lmp.py:380]   Expert 47 |    131 | GPU
DEBUG 01-06 08:44:55.365680.365680 lmp.py:380]   Expert 34 |    136 | GPU
DEBUG 01-06 08:44:55.365561.365561 lmp.py:380]   Expert 50 |    169 | GPU
DEBUG 01-06 08:44:55.365489.365489 lmp.py:380]   Expert 58 |    172 | GPU
DEBUG 01-06 08:44:55.365178.365178 lmp.py:380]   Expert 12 |    177 | GPU
DEBUG 01-06 08:44:55.365868.365868 lmp.py:380]   Expert 62 |    179 | GPU
DEBUG 01-06 08:44:55.365557.365557 lmp.py:380]   Expert 35 |    208 | GPU
DEBUG 01-06 08:44:55.365246.365246 lmp.py:380]   Expert  3 |    227 | GPU
DEBUG 01-06 08:44:55.365697.365697 lmp.py:380]   Expert 49 |    227 | GPU
DEBUG 01-06 08:44:55.365625.365625 lmp.py:380]   Expert 57 |    242 | GPU
DEBUG 01-06 08:44:55.365076.365076 lmp.py:380]   Expert 48 |    247 | GPU
DEBUG 01-06 08:44:55.365004.365004 lmp.py:380]   Expert 26 |    266 | GPU
DEBUG 01-06 08:44:55.365647.365647 lmp.py:380]   Expert  6 |    278 | GPU
DEBUG 01-06 08:44:55.365528.365528 lmp.py:380]   Expert 11 |    293 | GPU
DEBUG 01-06 08:44:55.365456.365456 lmp.py:380]   Expert 54 |    298 | GPU
DEBUG 01-06 08:44:55.365907.365907 lmp.py:380]   Expert 39 |    308 | GPU
DEBUG 01-06 08:44:55.365596.365596 lmp.py:380]   Expert 30 |    309 | GPU
DEBUG 01-06 08:44:55.365047.365047 lmp.py:380]   Expert 40 |    313 | GPU
DEBUG 01-06 08:44:55.365974.365974 lmp.py:380]   Expert 25 |    338 | GPU
DEBUG 01-06 08:44:55.365141.365141 lmp.py:380]   Expert 28 |    341 | GPU
DEBUG 01-06 08:44:55.365307.365307 lmp.py:380]   Expert 52 |    354 | GPU
DEBUG 01-06 08:44:55.365234.365234 lmp.py:380]   Expert 37 |    371 | GPU
DEBUG 01-06 08:44:55.365685.365685 lmp.py:380]   Expert 17 |    372 | GPU
DEBUG 01-06 08:44:55.365375.365375 lmp.py:380]   Expert  9 |    381 | GPU
DEBUG 01-06 08:44:55.365064.365064 lmp.py:380]   Expert  7 |    389 | GPU
DEBUG 01-06 08:44:55.365753.365753 lmp.py:380]   Expert 51 |    393 | GPU
DEBUG 01-06 08:44:55.365204.365204 lmp.py:380]   Expert 29 |    466 | GPU
DEBUG 01-06 08:44:55.365417.365417 lmp.py:380]   Expert 41 |    483 | GPU
DEBUG 01-06 08:44:55.365867.365867 lmp.py:380]   Expert 60 |    651 | GPU
DEBUG 01-06 08:44:55.365272.365272 lmp.py:380]   Expert  1 |    777 | GPU
DEBUG 01-06 08:44:55.365915.365915 lmp.py:380]   Expert 19 |    961 | GPU
DEBUG 01-06 08:44:55.365558.365558 lmp.py:381] 
DEBUG 01-06 08:44:55.365558.365558 lmp.py:381]   CPU total tokens: 1706 (13.9%)
DEBUG 01-06 08:44:55.365439.365439 lmp.py:382]   GPU total tokens: 10582 (86.1%)
DEBUG 01-06 08:44:55.366089.366089 cuda_h.py:19] end experts_map_get cost 0.0015225410461425781 seconds
DEBUG 01-06 08:44:55.366447.366447 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.366846.366846 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.366143.366143 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.366937.366937 cuda_h.py:19] end allocate_cuda_memory cost 0.00034046173095703125 seconds
DEBUG 01-06 08:44:55.366939.366939 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.366602.366602 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.366266.366266 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.366392.366392 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eee0eb4e-967b-4cc3-aa52-02fa07a999fd
DEBUG 01-06 08:44:55.367063.367063 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.367750.367750 client.py:127] Model loaded
DEBUG 01-06 08:44:55.367739.367739 cuda_h.py:19] end sllm_worker_task cost 0.00893855094909668 seconds
INFO 01-06 08:44:55.368958.368958 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eee0eb4e-967b-4cc3-aa52-02fa07a999fd
DEBUG 01-06 08:44:55.368185.368185 cuda_h.py:19] end load_into_gpu_async cost 0.001374959945678711 seconds
DEBUG 01-06 08:44:55.368603.368603 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.368505.368505 cuda_h.py:19] end restore_tensors2 cost 0.0003921985626220703 seconds
DEBUG 01-06 08:44:55.368572.368572 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024776458740234375 seconds
DEBUG 01-06 08:44:55.371220.371220 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005036592483520508 seconds
DEBUG 01-06 08:44:55.371334.371334 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.371125.371125 lmp.py:427] 
DEBUG 01-06 08:44:55.371125.371125 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:44:55.371676.371676 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-06 08:44:55.371300.371300 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.382398.382398 mlpmodule.py:704] group tensors cost 0.01087498664855957 s
DEBUG 01-06 08:44:55.385540.385540 mlpmodule.py:742] pad cost 0.0019440650939941406 s
DEBUG 01-06 08:44:55.385889.385889 mlpmodule.py:748] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-06 08:44:55.385997.385997 mlpmodule.py:753] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-06 08:44:55.396916.396916 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:44:55.396459.396459 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.396787.396787 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-06 08:44:55.396442.396442 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.416117.416117 mlpmodule.py:793] group einsum cost 0.030794620513916016 s
DEBUG 01-06 08:44:55.416625.416625 mlpmodule.py:801] cpy2cputensor cost 0.0005171298980712891 s
DEBUG 01-06 08:44:55.421035.421035 cuda_h.py:19] end wait_cetm_experts cost 0.050362586975097656 seconds
DEBUG 01-06 08:44:55.421257.421257 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.422291.422291 cuda_h.py:19] end gpu_sexperts cost 0.0009620189666748047 seconds
DEBUG 01-06 08:44:55.422757.422757 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.422322.422322 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-06 08:44:55.423455.423455 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.423926.423926 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eee0eb4e-967b-4cc3-aa52-02fa07a999fd
INFO 01-06 08:44:55.426279.426279 client.py:127] Model loaded
DEBUG 01-06 08:44:55.426883.426883 cuda_h.py:19] end wait_experts cost 0.0032701492309570312 seconds
DEBUG 01-06 08:44:55.426494.426494 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.426773.426773 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.429648.429648 mlpmodule.py:662]  experts func einsum cost 0.058129072189331055 s
DEBUG 01-06 08:44:55.438685.438685 cuda_h.py:19] end gpu_experts cost 0.011621475219726562 seconds
DEBUG 01-06 08:44:55.438258.438258 cuda_h.py:19] end layer_moe_generate_25 cost 0.0743873119354248 seconds
DEBUG 01-06 08:44:55.438139.438139 lmp.py:221] -------------------------------- end layer 25 --------------------------------
DEBUG 01-06 08:44:55.438140.438140 lmp.py:177] -------------------------------- start layer 26 --------------------------------
DEBUG 01-06 08:44:55.438075.438075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 08:44:55.438367.438367 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 08:44:55.438535.438535 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.5987625122070312e-05 seconds
DEBUG 01-06 08:44:55.438330.438330 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.555152893066406e-05 seconds
DEBUG 01-06 08:44:55.438689.438689 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.438895.438895 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:44:55.438567.438567 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.438496.438496 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.438101.438101 cuda_h.py:19] end allocate_cuda_memory cost 0.00023698806762695312 seconds
DEBUG 01-06 08:44:55.439144.439144 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.439145.439145 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.439822.439822 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.439856.439856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 49245c8b-8e06-4456-a4c0-0626e8471978
DEBUG 01-06 08:44:55.439203.439203 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:44:55.439081.439081 cuda_h.py:10] start self_attn
INFO 01-06 08:44:55.440060.440060 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 49245c8b-8e06-4456-a4c0-0626e8471978
DEBUG 01-06 08:44:55.440658.440658 cuda_h.py:19] end load_into_gpu_async cost 0.001079559326171875 seconds
DEBUG 01-06 08:44:55.440977.440977 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.440543.440543 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-06 08:44:55.440107.440107 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001665353775024414 seconds
INFO 01-06 08:44:55.440077.440077 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 49245c8b-8e06-4456-a4c0-0626e8471978
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.443506.443506 cuda_h.py:19] end self_attn cost 0.003937721252441406 seconds
DEBUG 01-06 08:44:55.443614.443614 cuda_h.py:19] end iln_self_attn_paln cost 0.005462646484375 seconds
DEBUG 01-06 08:44:55.444173.444173 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-06 08:44:55.444796.444796 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.445544.445544 cuda_h.py:19] end gate cost 0.0012998580932617188 seconds
DEBUG 01-06 08:44:55.445368.445368 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.445506.445506 lmp.py:369] 
DEBUG 01-06 08:44:55.445506.445506 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.445501.445501 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:55.445151.445151 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:55.445939.445939 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:55.446344.446344 lmp.py:373] 
DEBUG 01-06 08:44:55.446344.446344 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.446510.446510 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.446637.446637 lmp.py:380]   Expert 43 |      1 | CPU
DEBUG 01-06 08:44:55.446564.446564 lmp.py:380]   Expert 59 |      1 | CPU
DEBUG 01-06 08:44:55.446015.446015 lmp.py:380]   Expert 22 |      4 | CPU
DEBUG 01-06 08:44:55.446705.446705 lmp.py:380]   Expert 11 |      6 | CPU
DEBUG 01-06 08:44:55.446917.446917 lmp.py:380]   Expert 51 |      8 | CPU
DEBUG 01-06 08:44:55.446129.446129 lmp.py:380]   Expert 62 |      8 | CPU
DEBUG 01-06 08:44:55.446342.446342 lmp.py:380]   Expert 29 |     11 | CPU
DEBUG 01-06 08:44:55.446554.446554 lmp.py:380]   Expert  6 |     18 | CPU
DEBUG 01-06 08:44:55.446767.446767 lmp.py:380]   Expert 30 |     19 | CPU
DEBUG 01-06 08:44:55.446979.446979 lmp.py:380]   Expert  7 |     20 | CPU
DEBUG 01-06 08:44:55.446384.446384 lmp.py:380]   Expert  8 |     26 | CPU
DEBUG 01-06 08:44:55.446550.446550 lmp.py:380]   Expert 49 |     31 | CPU
DEBUG 01-06 08:44:55.446524.446524 lmp.py:380]   Expert 61 |     32 | CPU
DEBUG 01-06 08:44:55.446498.446498 lmp.py:380]   Expert 27 |     33 | CPU
DEBUG 01-06 08:44:55.446472.446472 lmp.py:380]   Expert 41 |     35 | CPU
DEBUG 01-06 08:44:55.446685.446685 lmp.py:380]   Expert 53 |     37 | CPU
DEBUG 01-06 08:44:55.446659.446659 lmp.py:380]   Expert 38 |     52 | CPU
DEBUG 01-06 08:44:55.446871.446871 lmp.py:380]   Expert 55 |     52 | CPU
DEBUG 01-06 08:44:55.446322.446322 lmp.py:380]   Expert 17 |     55 | CPU
DEBUG 01-06 08:44:55.446534.446534 lmp.py:380]   Expert 15 |     64 | CPU
DEBUG 01-06 08:44:55.446509.446509 lmp.py:380]   Expert 24 |     76 | CPU
DEBUG 01-06 08:44:55.446721.446721 lmp.py:380]   Expert 56 |     80 | CPU
DEBUG 01-06 08:44:55.446933.446933 lmp.py:380]   Expert 26 |    109 | CPU
DEBUG 01-06 08:44:55.446384.446384 lmp.py:380]   Expert 13 |    112 | CPU
DEBUG 01-06 08:44:55.446597.446597 lmp.py:380]   Expert  0 |    113 | CPU
DEBUG 01-06 08:44:55.446809.446809 lmp.py:380]   Expert 21 |    131 | CPU
DEBUG 01-06 08:44:55.446452.446452 lmp.py:380]   Expert 23 |    136 | CPU
DEBUG 01-06 08:44:55.446380.446380 lmp.py:380]   Expert 37 |    142 | CPU
DEBUG 01-06 08:44:55.446069.446069 lmp.py:380]   Expert 28 |    143 | CPU
DEBUG 01-06 08:44:55.446997.446997 lmp.py:380]   Expert 45 |    144 | CPU
DEBUG 01-06 08:44:55.446448.446448 lmp.py:380]   Expert 47 |    147 | CPU
DEBUG 01-06 08:44:55.446614.446614 lmp.py:380]   Expert 58 |    148 | GPU
DEBUG 01-06 08:44:55.446542.446542 lmp.py:380]   Expert 34 |    162 | GPU
DEBUG 01-06 08:44:55.446469.446469 lmp.py:380]   Expert 32 |    163 | GPU
DEBUG 01-06 08:44:55.446874.446874 lmp.py:380]   Expert 19 |    166 | GPU
DEBUG 01-06 08:44:55.446517.446517 lmp.py:380]   Expert 60 |    172 | GPU
DEBUG 01-06 08:44:55.446206.446206 lmp.py:380]   Expert 57 |    188 | GPU
DEBUG 01-06 08:44:55.446896.446896 lmp.py:380]   Expert 54 |    204 | GPU
DEBUG 01-06 08:44:55.446585.446585 lmp.py:380]   Expert 42 |    212 | GPU
DEBUG 01-06 08:44:55.446274.446274 lmp.py:380]   Expert 36 |    217 | GPU
DEBUG 01-06 08:44:55.446725.446725 lmp.py:380]   Expert 20 |    221 | GPU
DEBUG 01-06 08:44:55.446653.446653 lmp.py:380]   Expert  4 |    223 | GPU
DEBUG 01-06 08:44:55.446057.446057 lmp.py:380]   Expert  1 |    238 | GPU
DEBUG 01-06 08:44:55.446939.446939 lmp.py:380]   Expert 12 |    241 | GPU
DEBUG 01-06 08:44:55.446866.446866 lmp.py:380]   Expert 10 |    245 | GPU
DEBUG 01-06 08:44:55.446556.446556 lmp.py:380]   Expert  9 |    248 | GPU
DEBUG 01-06 08:44:55.446483.446483 lmp.py:380]   Expert 33 |    252 | GPU
DEBUG 01-06 08:44:55.446934.446934 lmp.py:380]   Expert 16 |    253 | GPU
DEBUG 01-06 08:44:55.446624.446624 lmp.py:380]   Expert 50 |    304 | GPU
DEBUG 01-06 08:44:55.446313.446313 lmp.py:380]   Expert  2 |    306 | GPU
DEBUG 01-06 08:44:55.446241.446241 lmp.py:380]   Expert 48 |    307 | GPU
DEBUG 01-06 08:44:55.446407.446407 lmp.py:380]   Expert  5 |    316 | GPU
DEBUG 01-06 08:44:55.446573.446573 lmp.py:380]   Expert 39 |    325 | GPU
DEBUG 01-06 08:44:55.446216.446216 lmp.py:380]   Expert 31 |    326 | GPU
DEBUG 01-06 08:44:55.446859.446859 lmp.py:380]   Expert 63 |    353 | GPU
DEBUG 01-06 08:44:55.446787.446787 lmp.py:380]   Expert 18 |    356 | GPU
DEBUG 01-06 08:44:55.446237.446237 lmp.py:380]   Expert 25 |    380 | GPU
DEBUG 01-06 08:44:55.446404.446404 lmp.py:380]   Expert 52 |    400 | GPU
DEBUG 01-06 08:44:55.447570.447570 lmp.py:380]   Expert 44 |    424 | GPU
DEBUG 01-06 08:44:55.447497.447497 lmp.py:380]   Expert 35 |    463 | GPU
DEBUG 01-06 08:44:55.447187.447187 lmp.py:380]   Expert 40 |    567 | GPU
DEBUG 01-06 08:44:55.447353.447353 lmp.py:380]   Expert 46 |    642 | GPU
DEBUG 01-06 08:44:55.447042.447042 lmp.py:380]   Expert 14 |   1420 | GPU
DEBUG 01-06 08:44:55.447447.447447 lmp.py:381] 
DEBUG 01-06 08:44:55.447447.447447 lmp.py:381]   CPU total tokens: 1846 (15.0%)
DEBUG 01-06 08:44:55.447328.447328 lmp.py:382]   GPU total tokens: 10442 (85.0%)
DEBUG 01-06 08:44:55.447693.447693 cuda_h.py:19] end experts_map_get cost 0.0015785694122314453 seconds
DEBUG 01-06 08:44:55.447051.447051 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.447749.447749 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.447794.447794 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.447144.447144 cuda_h.py:19] end allocate_cuda_memory cost 0.00032830238342285156 seconds
DEBUG 01-06 08:44:55.447008.447008 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.447294.447294 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.447348.447348 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.447620.447620 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0d7a4457-08b9-4948-bf9f-255e1be9eef8
DEBUG 01-06 08:44:55.448590.448590 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.448620.448620 client.py:127] Model loaded
DEBUG 01-06 08:44:55.448916.448916 cuda_h.py:19] end sllm_worker_task cost 0.009843826293945312 seconds
INFO 01-06 08:44:55.449166.449166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0d7a4457-08b9-4948-bf9f-255e1be9eef8
DEBUG 01-06 08:44:55.449539.449539 cuda_h.py:19] end load_into_gpu_async cost 0.0014078617095947266 seconds
DEBUG 01-06 08:44:55.449673.449673 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.449381.449381 cuda_h.py:19] end restore_tensors2 cost 0.0005640983581542969 seconds
DEBUG 01-06 08:44:55.449496.449496 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002702951431274414 seconds
DEBUG 01-06 08:44:55.452356.452356 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005497455596923828 seconds
DEBUG 01-06 08:44:55.452523.452523 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.452645.452645 lmp.py:427] 
DEBUG 01-06 08:44:55.452645.452645 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:55.452773.452773 cuda_h.py:19] end cpu_experts_submit cost 0.00012087821960449219 seconds
DEBUG 01-06 08:44:55.452522.452522 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.459987.459987 mlpmodule.py:704] group tensors cost 0.0059735774993896484 s
DEBUG 01-06 08:44:55.461634.461634 mlpmodule.py:742] pad cost 0.0017554759979248047 s
DEBUG 01-06 08:44:55.461758.461758 mlpmodule.py:748] create cpu tensor cost 6.890296936035156e-05 s
DEBUG 01-06 08:44:55.461806.461806 mlpmodule.py:753] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-06 08:44:55.471749.471749 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:55.471477.471477 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.471805.471805 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-06 08:44:55.471108.471108 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.487812.487812 mlpmodule.py:793] group einsum cost 0.025203704833984375 s
DEBUG 01-06 08:44:55.487183.487183 mlpmodule.py:801] cpy2cputensor cost 0.0005843639373779297 s
DEBUG 01-06 08:44:55.492321.492321 cuda_h.py:19] end wait_cetm_experts cost 0.03983592987060547 seconds
DEBUG 01-06 08:44:55.492927.492927 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.493231.493231 cuda_h.py:19] end gpu_sexperts cost 0.0005333423614501953 seconds
DEBUG 01-06 08:44:55.493657.493657 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.493229.493229 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.123283386230469e-05 seconds
DEBUG 01-06 08:44:55.493647.493647 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.493357.493357 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0d7a4457-08b9-4948-bf9f-255e1be9eef8
DEBUG 01-06 08:44:55.500993.500993 mlpmodule.py:662]  experts func einsum cost 0.04711031913757324 s
INFO 01-06 08:44:55.504907.504907 client.py:127] Model loaded
DEBUG 01-06 08:44:55.504895.504895 cuda_h.py:19] end wait_experts cost 0.011142969131469727 seconds
DEBUG 01-06 08:44:55.504168.504168 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.504632.504632 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.516087.516087 cuda_h.py:19] end gpu_experts cost 0.01121377944946289 seconds
DEBUG 01-06 08:44:55.516290.516290 cuda_h.py:19] end layer_moe_generate_26 cost 0.07210206985473633 seconds
DEBUG 01-06 08:44:55.516668.516668 lmp.py:221] -------------------------------- end layer 26 --------------------------------
DEBUG 01-06 08:44:55.516219.516219 lmp.py:177] -------------------------------- start layer 27 --------------------------------
DEBUG 01-06 08:44:55.516108.516108 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-06 08:44:55.516208.516208 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.2874603271484375e-05 seconds
DEBUG 01-06 08:44:55.516427.516427 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:44:55.516326.516326 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:44:55.519446.519446 cuda_h.py:19] end self_attn cost 0.0025255680084228516 seconds
DEBUG 01-06 08:44:55.519330.519330 cuda_h.py:19] end iln_self_attn_paln cost 0.003199338912963867 seconds
DEBUG 01-06 08:44:55.519220.519220 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-06 08:44:55.519698.519698 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.520594.520594 cuda_h.py:19] end gate cost 0.0006270408630371094 seconds
DEBUG 01-06 08:44:55.520947.520947 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:44:55.520725.520725 lmp.py:369] 
DEBUG 01-06 08:44:55.520725.520725 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:44:55.520004.520004 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:44:55.520130.520130 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:44:55.520919.520919 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:44:55.520085.520085 lmp.py:373] 
DEBUG 01-06 08:44:55.520085.520085 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:44:55.520967.520967 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:44:55.520093.520093 lmp.py:380]   Expert 24 |      1 | CPU
DEBUG 01-06 08:44:55.521736.521736 lmp.py:380]   Expert 44 |      2 | CPU
DEBUG 01-06 08:44:55.521426.521426 lmp.py:380]   Expert 11 |      4 | CPU
DEBUG 01-06 08:44:55.521115.521115 lmp.py:380]   Expert 45 |      4 | CPU
DEBUG 01-06 08:44:55.521566.521566 lmp.py:380]   Expert 12 |      5 | CPU
DEBUG 01-06 08:44:55.521778.521778 lmp.py:380]   Expert 51 |      6 | CPU
DEBUG 01-06 08:44:55.521706.521706 lmp.py:380]   Expert 18 |      7 | CPU
DEBUG 01-06 08:44:55.521110.521110 lmp.py:380]   Expert 42 |     13 | CPU
DEBUG 01-06 08:44:55.521561.521561 lmp.py:380]   Expert 17 |     37 | CPU
DEBUG 01-06 08:44:55.521774.521774 lmp.py:380]   Expert 54 |     38 | CPU
DEBUG 01-06 08:44:55.521986.521986 lmp.py:380]   Expert 25 |     39 | CPU
DEBUG 01-06 08:44:55.521960.521960 lmp.py:380]   Expert 61 |     44 | CPU
DEBUG 01-06 08:44:55.521696.521696 lmp.py:380]   Expert 38 |     48 | CPU
DEBUG 01-06 08:44:55.521908.521908 lmp.py:380]   Expert 36 |     54 | CPU
DEBUG 01-06 08:44:55.521644.521644 lmp.py:380]   Expert 15 |     55 | CPU
DEBUG 01-06 08:44:55.521618.521618 lmp.py:380]   Expert 31 |     66 | CPU
DEBUG 01-06 08:44:55.521307.521307 lmp.py:380]   Expert  5 |     70 | CPU
DEBUG 01-06 08:44:55.521235.521235 lmp.py:380]   Expert  7 |     79 | CPU
DEBUG 01-06 08:44:55.521209.521209 lmp.py:380]   Expert 40 |     83 | CPU
DEBUG 01-06 08:44:55.521422.521422 lmp.py:380]   Expert 59 |     86 | CPU
DEBUG 01-06 08:44:55.521396.521396 lmp.py:380]   Expert 58 |     95 | CPU
DEBUG 01-06 08:44:55.521131.521131 lmp.py:380]   Expert 23 |     99 | CPU
DEBUG 01-06 08:44:55.521344.521344 lmp.py:380]   Expert 32 |     99 | CPU
DEBUG 01-06 08:44:55.521079.521079 lmp.py:380]   Expert  4 |    100 | CPU
DEBUG 01-06 08:44:55.521292.521292 lmp.py:380]   Expert 48 |    102 | CPU
DEBUG 01-06 08:44:55.521266.521266 lmp.py:380]   Expert 10 |    105 | CPU
DEBUG 01-06 08:44:55.521955.521955 lmp.py:380]   Expert 39 |    111 | CPU
DEBUG 01-06 08:44:55.521360.521360 lmp.py:380]   Expert 49 |    118 | CPU
DEBUG 01-06 08:44:55.521811.521811 lmp.py:380]   Expert 34 |    137 | CPU
DEBUG 01-06 08:44:55.521023.521023 lmp.py:380]   Expert 46 |    138 | CPU
DEBUG 01-06 08:44:55.521759.521759 lmp.py:380]   Expert 50 |    145 | CPU
DEBUG 01-06 08:44:55.521971.521971 lmp.py:380]   Expert  1 |    146 | GPU
DEBUG 01-06 08:44:55.521945.521945 lmp.py:380]   Expert 33 |    146 | GPU
DEBUG 01-06 08:44:55.521919.521919 lmp.py:380]   Expert 52 |    154 | GPU
DEBUG 01-06 08:44:55.521132.521132 lmp.py:380]   Expert 30 |    161 | GPU
DEBUG 01-06 08:44:55.521344.521344 lmp.py:380]   Expert 62 |    170 | GPU
DEBUG 01-06 08:44:55.521318.521318 lmp.py:380]   Expert 22 |    174 | GPU
DEBUG 01-06 08:44:55.521498.521498 lmp.py:380]   Expert 13 |    175 | GPU
DEBUG 01-06 08:44:55.521995.521995 lmp.py:380]   Expert 19 |    187 | GPU
DEBUG 01-06 08:44:55.521731.521731 lmp.py:380]   Expert 57 |    197 | GPU
DEBUG 01-06 08:44:55.521990.521990 lmp.py:380]   Expert  2 |    200 | GPU
DEBUG 01-06 08:44:55.521725.521725 lmp.py:380]   Expert 16 |    219 | GPU
DEBUG 01-06 08:44:55.521984.521984 lmp.py:380]   Expert 41 |    222 | GPU
DEBUG 01-06 08:44:55.521481.521481 lmp.py:380]   Expert 29 |    229 | GPU
DEBUG 01-06 08:44:55.521740.521740 lmp.py:380]   Expert 55 |    233 | GPU
DEBUG 01-06 08:44:55.521237.521237 lmp.py:380]   Expert 56 |    252 | GPU
DEBUG 01-06 08:44:55.521734.521734 lmp.py:380]   Expert  8 |    256 | GPU
DEBUG 01-06 08:44:55.521470.521470 lmp.py:380]   Expert 53 |    268 | GPU
DEBUG 01-06 08:44:55.521682.521682 lmp.py:380]   Expert 14 |    278 | GPU
DEBUG 01-06 08:44:55.521133.521133 lmp.py:380]   Expert 35 |    281 | GPU
DEBUG 01-06 08:44:55.521107.521107 lmp.py:380]   Expert 26 |    317 | GPU
DEBUG 01-06 08:44:55.521366.521366 lmp.py:380]   Expert 21 |    328 | GPU
DEBUG 01-06 08:44:55.521102.521102 lmp.py:380]   Expert  3 |    364 | GPU
DEBUG 01-06 08:44:55.521361.521361 lmp.py:380]   Expert  6 |    364 | GPU
DEBUG 01-06 08:44:55.521619.521619 lmp.py:380]   Expert 28 |    392 | GPU
DEBUG 01-06 08:44:55.521117.521117 lmp.py:380]   Expert  0 |    417 | GPU
DEBUG 01-06 08:44:55.521614.521614 lmp.py:380]   Expert 27 |    477 | GPU
DEBUG 01-06 08:44:55.521111.521111 lmp.py:380]   Expert 20 |    479 | GPU
DEBUG 01-06 08:44:55.521323.521323 lmp.py:380]   Expert 43 |    515 | GPU
DEBUG 01-06 08:44:55.521536.521536 lmp.py:380]   Expert 63 |    558 | GPU
DEBUG 01-06 08:44:55.521272.521272 lmp.py:380]   Expert 37 |    579 | GPU
DEBUG 01-06 08:44:55.521292.521292 lmp.py:380]   Expert 60 |    666 | GPU
DEBUG 01-06 08:44:55.522551.522551 lmp.py:380]   Expert  9 |    894 | GPU
DEBUG 01-06 08:44:55.522763.522763 lmp.py:381] 
DEBUG 01-06 08:44:55.522763.522763 lmp.py:381]   CPU total tokens: 1990 (16.2%)
DEBUG 01-06 08:44:55.522452.522452 lmp.py:382]   GPU total tokens: 10298 (83.8%)
DEBUG 01-06 08:44:55.522195.522195 cuda_h.py:19] end experts_map_get cost 0.0014536380767822266 seconds
DEBUG 01-06 08:44:55.522123.522123 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:44:55.522813.522813 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:55.522017.522017 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:55.522463.522463 cuda_h.py:19] end allocate_cuda_memory cost 0.00022482872009277344 seconds
DEBUG 01-06 08:44:55.522928.522928 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:55.522969.522969 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:55.522785.522785 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:55.522911.522911 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d3d649f-6c1d-41e9-9981-f9994c4a4018
DEBUG 01-06 08:44:55.522854.522854 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:55.524169.524169 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d3d649f-6c1d-41e9-9981-f9994c4a4018
DEBUG 01-06 08:44:55.524621.524621 cuda_h.py:19] end load_into_gpu_async cost 0.0014629364013671875 seconds
DEBUG 01-06 08:44:55.524416.524416 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:55.524545.524545 cuda_h.py:19] end restore_tensors2 cost 0.0004544258117675781 seconds
DEBUG 01-06 08:44:55.524613.524613 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002496957778930664 seconds
DEBUG 01-06 08:44:55.527913.527913 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005187034606933594 seconds
DEBUG 01-06 08:44:55.527008.527008 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:44:55.527925.527925 lmp.py:427] 
DEBUG 01-06 08:44:55.527925.527925 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:44:55.527437.527437 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-06 08:44:55.527517.527517 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:44:55.540129.540129 mlpmodule.py:704] group tensors cost 0.012578964233398438 s
DEBUG 01-06 08:44:55.542257.542257 mlpmodule.py:742] pad cost 0.0014750957489013672 s
DEBUG 01-06 08:44:55.542386.542386 mlpmodule.py:748] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-06 08:44:55.542375.542375 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 08:44:55.551699.551699 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:44:55.552321.552321 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:44:55.552742.552742 mlpmodule.py:773] group_w3 first element: -0.0020294189453125
WARNING 01-06 08:44:55.552958.552958 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:44:55.568065.568065 mlpmodule.py:793] group einsum cost 0.025081157684326172 s
DEBUG 01-06 08:44:55.568484.568484 mlpmodule.py:801] cpy2cputensor cost 0.0006327629089355469 s
DEBUG 01-06 08:44:55.573150.573150 cuda_h.py:19] end wait_cetm_experts cost 0.04613900184631348 seconds
DEBUG 01-06 08:44:55.573570.573570 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.574892.574892 cuda_h.py:19] end gpu_sexperts cost 0.0004763603210449219 seconds
DEBUG 01-06 08:44:55.574682.574682 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:44:55.574512.574512 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.0967254638671875e-05 seconds
DEBUG 01-06 08:44:55.574976.574976 cuda_h.py:10] start wait_experts
INFO 01-06 08:44:55.574970.574970 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d3d649f-6c1d-41e9-9981-f9994c4a4018
INFO 01-06 08:44:55.578743.578743 client.py:127] Model loaded
DEBUG 01-06 08:44:55.578208.578208 cuda_h.py:19] end wait_experts cost 0.004144191741943359 seconds
DEBUG 01-06 08:44:55.578203.578203 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.578151.578151 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:44:55.581891.581891 mlpmodule.py:662]  experts func einsum cost 0.05354428291320801 s
DEBUG 01-06 08:44:55.590725.590725 cuda_h.py:19] end gpu_experts cost 0.011406183242797852 seconds
DEBUG 01-06 08:44:55.590511.590511 cuda_h.py:19] end layer_moe_generate_27 cost 0.07036995887756348 seconds
DEBUG 01-06 08:44:55.590942.590942 lmp.py:221] -------------------------------- end layer 27 --------------------------------
DEBUG 01-06 08:44:55.590924.590924 cuda_h.py:19] end multi_layer cost 2.1356968879699707 seconds
DEBUG 01-06 08:44:55.590057.590057 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 08:44:55.594825.594825 cuda_h.py:19] end init_inputs_tokens cost 0.003727436065673828 seconds
DEBUG 01-06 08:44:55.594245.594245 lmp.py:290] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-06 08:44:55.594994.594994 cuda_h.py:10] start dense_mlp
DEBUG 01-06 08:44:55.594773.594773 lmp.py:293] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-06 08:44:55.594225.594225 cuda_h.py:19] end dense_mlp cost 0.000354766845703125 seconds
DEBUG 01-06 08:44:55.594836.594836 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-06 08:44:55.594115.594115 cuda_h.py:10] start gate
DEBUG 01-06 08:44:55.595080.595080 cuda_h.py:19] end gate cost 0.0005037784576416016 seconds
DEBUG 01-06 08:44:55.595048.595048 cuda_h.py:10] start experts_map_get
INFO 01-06 08:44:55.596529.596529 lmp.py:582] 
INFO 01-06 08:44:55.596529.596529 lmp.py:582] Layer 1 Expert Device Distribution:
INFO 01-06 08:44:55.596391.596391 lmp.py:583]   Active experts: 50 (out of 64 total)
INFO 01-06 08:44:55.596518.596518 lmp.py:584] 
INFO 01-06 08:44:55.596518.596518 lmp.py:584]   Detailed Expert Distribution:
INFO 01-06 08:44:55.596929.596929 lmp.py:585]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 08:44:55.596572.596572 lmp.py:586]   ----------------------------------------------------------------------
INFO 01-06 08:44:55.596453.596453 lmp.py:589]   2          | 1          |  meta           
INFO 01-06 08:44:55.596619.596619 lmp.py:589]   19         | 1          |  meta           
INFO 01-06 08:44:55.596070.596070 lmp.py:589]   22         | 1          |  meta           
INFO 01-06 08:44:55.596998.596998 lmp.py:589]   29         | 1          |  meta           
INFO 01-06 08:44:55.596449.596449 lmp.py:589]   36         | 1          |  meta           
INFO 01-06 08:44:55.596661.596661 lmp.py:589]   37         | 1          |  meta           
INFO 01-06 08:44:55.596874.596874 lmp.py:589]   40         | 1          |  meta           
INFO 01-06 08:44:55.596848.596848 lmp.py:589]   41         | 1          |  meta           
INFO 01-06 08:44:55.596822.596822 lmp.py:589]   43         | 1          |  meta           
INFO 01-06 08:44:55.596796.596796 lmp.py:589]   50         | 1          |  meta           
INFO 01-06 08:44:55.596684.596684 lmp.py:589]   53         | 1          |  meta           
INFO 01-06 08:44:55.596347.596347 lmp.py:589]   1          | 2          |  meta           
INFO 01-06 08:44:55.596514.596514 lmp.py:589]   6          | 2          |  meta           
INFO 01-06 08:44:55.596680.596680 lmp.py:589]   8          | 2          |  meta           
INFO 01-06 08:44:55.596892.596892 lmp.py:589]   12         | 2          |  meta           
INFO 01-06 08:44:55.596343.596343 lmp.py:589]   30         | 2          |  meta           
INFO 01-06 08:44:55.596556.596556 lmp.py:589]   32         | 2          |  meta           
INFO 01-06 08:44:55.596530.596530 lmp.py:589]   39         | 2          |  meta           
INFO 01-06 08:44:55.596742.596742 lmp.py:589]   47         | 2          |  meta           
INFO 01-06 08:44:55.596955.596955 lmp.py:589]   51         | 2          |  meta           
INFO 01-06 08:44:55.596690.596690 lmp.py:589]   52         | 2          |  meta           
INFO 01-06 08:44:55.596903.596903 lmp.py:589]   55         | 2          |  meta           
INFO 01-06 08:44:55.596354.596354 lmp.py:589]   0          | 3          |  meta           
INFO 01-06 08:44:55.596520.596520 lmp.py:589]   7          | 3          |  meta           
INFO 01-06 08:44:55.596971.596971 lmp.py:589]   44         | 3          |  meta           
INFO 01-06 08:44:55.596421.596421 lmp.py:589]   5          | 4          |  cuda:1         
INFO 01-06 08:44:55.596395.596395 lmp.py:589]   9          | 4          |  meta           
INFO 01-06 08:44:55.596370.596370 lmp.py:589]   16         | 4          |  meta           
INFO 01-06 08:44:55.596344.596344 lmp.py:589]   28         | 4          |  meta           
INFO 01-06 08:44:55.596318.596318 lmp.py:589]   33         | 4          |  meta           
INFO 01-06 08:44:55.596292.596292 lmp.py:589]   42         | 4          |  meta           
INFO 01-06 08:44:55.596504.596504 lmp.py:589]   60         | 4          |  meta           
INFO 01-06 08:44:55.596240.596240 lmp.py:589]   4          | 5          |  cuda:1         
INFO 01-06 08:44:55.596406.596406 lmp.py:589]   11         | 5          |  meta           
INFO 01-06 08:44:55.596334.596334 lmp.py:589]   26         | 5          |  meta           
INFO 01-06 08:44:55.596784.596784 lmp.py:589]   35         | 5          |  meta           
INFO 01-06 08:44:55.596997.596997 lmp.py:589]   45         | 5          |  meta           
INFO 01-06 08:44:55.596733.596733 lmp.py:589]   14         | 6          |  meta           
INFO 01-06 08:44:55.596707.596707 lmp.py:589]   15         | 6          |  meta           
INFO 01-06 08:44:55.596681.596681 lmp.py:589]   23         | 6          |  meta           
INFO 01-06 08:44:55.596655.596655 lmp.py:589]   24         | 6          |  meta           
INFO 01-06 08:44:55.596867.596867 lmp.py:589]   46         | 6          |  meta           
INFO 01-06 08:44:55.596603.596603 lmp.py:589]   10         | 7          |  meta           
INFO 01-06 08:44:55.596815.596815 lmp.py:589]   31         | 7          |  meta           
INFO 01-06 08:44:55.596505.596505 lmp.py:589]   59         | 7          |  meta           
INFO 01-06 08:44:55.596479.596479 lmp.py:589]   20         | 9          |  meta           
INFO 01-06 08:44:55.596691.596691 lmp.py:589]   34         | 9          |  meta           
INFO 01-06 08:44:55.597427.597427 lmp.py:589]   57         | 9          |  meta           
INFO 01-06 08:44:55.597401.597401 lmp.py:589]   61         | 9          |  meta           
INFO 01-06 08:44:55.597852.597852 lmp.py:589]   63         | 10         |  meta           
INFO 01-06 08:44:55.597349.597349 lmp.py:590] ============================================================
INFO 01-06 08:44:55.597349.597349 lmp.py:590] 
INFO 01-06 08:44:55.597237.597237 lmp.py:592] experts_gpu_list: [5, 4]
INFO 01-06 08:44:55.597787.597787 lmp.py:593] experts_cpu_list: [2, 19, 22, 29, 36, 37, 40, 41, 43, 50, 53, 1, 6, 8, 12, 30, 32, 39, 47, 51, 52, 55, 0, 7, 44, 9, 16, 28, 33, 42, 60, 11, 26, 35, 45, 14, 15, 23, 24, 46, 10, 31, 59, 20, 34, 57, 61, 63]
INFO 01-06 08:44:55.597166.597166 lmp.py:594] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 08:44:55.597445.597445 cuda_h.py:19] end experts_map_get cost 0.0017385482788085938 seconds
DEBUG 01-06 08:44:55.597156.597156 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:44:55.597239.597239 cuda_h.py:19] end gpu_sexperts cost 0.00027298927307128906 seconds
DEBUG 01-06 08:44:55.597631.597631 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:44:55.597942.597942 mlpmodule.py:531] gpu group tensors cost 0.00013875961303710938 s
DEBUG 01-06 08:44:55.597969.597969 mlpmodule.py:564] gpu pad cost 0.00015354156494140625 s
DEBUG 01-06 08:44:55.598269.598269 mlpmodule.py:582] gpu group einsum cost 0.0004181861877441406 s
DEBUG 01-06 08:44:55.598863.598863 mlpmodule.py:611] gpu experts func einsum cost 0.0011303424835205078 s
DEBUG 01-06 08:44:55.598018.598018 cuda_h.py:19] end gpu_experts cost 0.0012409687042236328 seconds
DEBUG 01-06 08:44:55.598251.598251 cuda_h.py:10] start cpu_experts
DEBUG 01-06 08:44:55.614025.614025 cuda_h.py:19] end cpu_experts cost 0.015771150588989258 seconds
DEBUG 01-06 08:44:55.614122.614122 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.019986867904663086 seconds
DEBUG 01-06 08:44:56.778273.778273 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09340691566467285 s
DEBUG 01-06 08:44:57.111281.111281 cuda_h.py:19] end generate_input_ids cost 0.3315141201019287 seconds
DEBUG 01-06 08:44:57.111982.111982 cuda_h.py:10] start init_cache
DEBUG 01-06 08:44:57.111018.111018 cuda_h.py:19] end init_cache cost 5.650520324707031e-05 seconds
DEBUG 01-06 08:44:59.377445.377445 cuda_h.py:10] start init_weights
DEBUG 01-06 08:44:59.378931.378931 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:59.378800.378800 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:59.380692.380692 cuda_h.py:19] end allocate_cuda_memory cost 0.0016286373138427734 seconds
DEBUG 01-06 08:44:59.381918.381918 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:59.381595.381595 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:59.381730.381730 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:59.381671.381671 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 51a76e19-e376-4564-aa52-e84305437ebe
DEBUG 01-06 08:44:59.381886.381886 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:59.382892.382892 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 51a76e19-e376-4564-aa52-e84305437ebe
DEBUG 01-06 08:44:59.382013.382013 cuda_h.py:19] end load_into_gpu_async cost 0.0013980865478515625 seconds
DEBUG 01-06 08:44:59.382285.382285 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:59.382440.382440 cuda_h.py:19] end restore_tensors2 cost 5.1975250244140625e-05 seconds
DEBUG 01-06 08:44:59.382666.382666 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037469863891601562 seconds
INFO 01-06 08:44:59.382839.382839 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 51a76e19-e376-4564-aa52-e84305437ebe
INFO 01-06 08:44:59.462450.462450 client.py:127] Model loaded
DEBUG 01-06 08:44:59.462740.462740 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-06 08:44:59.463903.463903 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:44:59.463404.463404 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:44:59.463172.463172 cuda_h.py:19] end allocate_cuda_memory cost 0.0003027915954589844 seconds
DEBUG 01-06 08:44:59.463978.463978 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:44:59.463994.463994 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:44:59.463553.463553 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:44:59.463887.463887 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a63198af-010b-4ae3-b3ea-ee9251fca3e8
DEBUG 01-06 08:44:59.464925.464925 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:44:59.465000.465000 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a63198af-010b-4ae3-b3ea-ee9251fca3e8
DEBUG 01-06 08:44:59.465361.465361 cuda_h.py:19] end load_into_gpu_async cost 0.0018811225891113281 seconds
DEBUG 01-06 08:44:59.465218.465218 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:44:59.465364.465364 cuda_h.py:19] end restore_tensors2 cost 0.0001404285430908203 seconds
DEBUG 01-06 08:44:59.466910.466910 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002910614013671875 seconds
INFO 01-06 08:44:59.466582.466582 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a63198af-010b-4ae3-b3ea-ee9251fca3e8
INFO 01-06 08:44:59.481770.481770 client.py:127] Model loaded
DEBUG 01-06 08:44:59.482082.482082 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.01900792121887207 seconds
DEBUG 01-06 08:44:59.482490.482490 cuda_h.py:19] end init_weights cost 0.10412383079528809 seconds
DEBUG 01-06 08:44:59.482599.482599 cuda_h.py:10] start copy_emodel
DEBUG 01-06 08:45:00.396525.396525 cuda_h.py:19] end copy_emodel cost 0.9140200614929199 seconds
DEBUG 01-06 08:45:00.397394.397394 cuda_h.py:10] start init_hmv
DEBUG 01-06 08:45:00.538484.538484 mlpmodule.py:206] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-06 08:45:00.539181.539181 cuda_h.py:19] end init_hmv cost 0.14231395721435547 seconds
DEBUG 01-06 08:45:00.539156.539156 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 08:45:00.539941.539941 cuda_h.py:19] end init_inputs_tokens cost 0.00026726722717285156 seconds
DEBUG 01-06 08:45:00.540949.540949 cuda_h.py:10] start multi_layer
DEBUG 01-06 08:45:00.540473.540473 lmp.py:177] -------------------------------- start layer 0 --------------------------------
DEBUG 01-06 08:45:00.540169.540169 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:45:00.540203.540203 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:45:00.540192.540192 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.457069396972656e-05 seconds
DEBUG 01-06 08:45:00.540453.540453 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.540761.540761 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 0.00021004676818847656 seconds
DEBUG 01-06 08:45:00.540352.540352 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.540832.540832 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.540097.540097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.542203.542203 cuda_h.py:19] end allocate_cuda_memory cost 0.0009932518005371094 seconds
DEBUG 01-06 08:45:00.542619.542619 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.542405.542405 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.542130.542130 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.542186.542186 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c8e75d7-b55d-4a3c-8d53-04db1f6bb83e
DEBUG 01-06 08:45:00.542836.542836 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.543757.543757 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.544132.544132 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c8e75d7-b55d-4a3c-8d53-04db1f6bb83e
DEBUG 01-06 08:45:00.545504.545504 cuda_h.py:19] end load_into_gpu_async cost 0.002771139144897461 seconds
DEBUG 01-06 08:45:00.545422.545422 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.545146.545146 cuda_h.py:19] end restore_tensors2 cost 0.00015020370483398438 seconds
DEBUG 01-06 08:45:00.545117.545117 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004810810089111328 seconds
INFO 01-06 08:45:00.546494.546494 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c8e75d7-b55d-4a3c-8d53-04db1f6bb83e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:00.548909.548909 cuda_h.py:19] end self_attn cost 0.005655765533447266 seconds
DEBUG 01-06 08:45:00.549369.549369 cuda_h.py:19] end iln_self_attn_paln cost 0.008434534072875977 seconds
DEBUG 01-06 08:45:00.549913.549913 cuda_h.py:10] start dense_mlp
DEBUG 01-06 08:45:00.549054.549054 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 08:45:00.549068.549068 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 1.811981201171875e-05 seconds
DEBUG 01-06 08:45:00.552175.552175 cuda_h.py:19] end dense_mlp cost 0.002651214599609375 seconds
DEBUG 01-06 08:45:00.552953.552953 lmp.py:221] -------------------------------- end layer 0 --------------------------------
DEBUG 01-06 08:45:00.552637.552637 lmp.py:177] -------------------------------- start layer 1 --------------------------------
DEBUG 01-06 08:45:00.552618.552618 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 08:45:00.552036.552036 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 08:45:00.552289.552289 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.4781951904296875e-05 seconds
DEBUG 01-06 08:45:00.552475.552475 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.3392181396484375e-05 seconds
DEBUG 01-06 08:45:00.552787.552787 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.552192.552192 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.553041.553041 client.py:127] Model loaded
DEBUG 01-06 08:45:00.553562.553562 cuda_h.py:19] end sllm_worker_task cost 0.012594461441040039 seconds
DEBUG 01-06 08:45:00.553229.553229 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.553888.553888 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.553893.553893 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.554061.554061 cuda_h.py:19] end allocate_cuda_memory cost 0.0003566741943359375 seconds
DEBUG 01-06 08:45:00.554072.554072 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.554358.554358 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.554256.554256 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.554438.554438 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 49c2f732-10a4-4154-94ef-ae499f119110
DEBUG 01-06 08:45:00.554803.554803 client.py:106] call stub.LoadModelAsync
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-06 08:45:00.556927.556927 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 49c2f732-10a4-4154-94ef-ae499f119110
DEBUG 01-06 08:45:00.556542.556542 cuda_h.py:19] end load_into_gpu_async cost 0.002134084701538086 seconds
DEBUG 01-06 08:45:00.556015.556015 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.556844.556844 cuda_h.py:19] end restore_tensors2 cost 0.00013017654418945312 seconds
DEBUG 01-06 08:45:00.556722.556722 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034530162811279297 seconds
DEBUG 01-06 08:45:00.557311.557311 cuda_h.py:19] end self_attn cost 0.00466156005859375 seconds
INFO 01-06 08:45:00.558975.558975 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 49c2f732-10a4-4154-94ef-ae499f119110
DEBUG 01-06 08:45:00.558420.558420 cuda_h.py:19] end iln_self_attn_paln cost 0.006192684173583984 seconds
DEBUG 01-06 08:45:00.558892.558892 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-06 08:45:00.558801.558801 cuda_h.py:10] start gate
DEBUG 01-06 08:45:00.559254.559254 cuda_h.py:19] end gate cost 0.0006504058837890625 seconds
DEBUG 01-06 08:45:00.559368.559368 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:00.559662.559662 lmp.py:369] 
DEBUG 01-06 08:45:00.559662.559662 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:00.559842.559842 lmp.py:370]   Total experts: 6
DEBUG 01-06 08:45:00.559538.559538 lmp.py:371]   CPU experts: 3 (50%)
DEBUG 01-06 08:45:00.559373.559373 lmp.py:372]   GPU experts: 3 (50%)
DEBUG 01-06 08:45:00.559447.559447 lmp.py:373] 
DEBUG 01-06 08:45:00.559447.559447 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:00.559282.559282 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:00.559455.559455 lmp.py:380]   Expert  0 |   2048 | CPU
DEBUG 01-06 08:45:00.559051.559051 lmp.py:380]   Expert  1 |   2048 | CPU
DEBUG 01-06 08:45:00.559409.559409 lmp.py:380]   Expert  2 |   2048 | CPU
DEBUG 01-06 08:45:00.559768.559768 lmp.py:380]   Expert  3 |   2048 | GPU
DEBUG 01-06 08:45:00.559649.559649 lmp.py:380]   Expert  4 |   2048 | GPU
DEBUG 01-06 08:45:00.559438.559438 lmp.py:380]   Expert  5 |   2048 | GPU
DEBUG 01-06 08:45:00.559750.559750 lmp.py:381] 
DEBUG 01-06 08:45:00.559750.559750 lmp.py:381]   CPU total tokens: 6144 (50.0%)
DEBUG 01-06 08:45:00.559538.559538 lmp.py:382]   GPU total tokens: 6144 (50.0%)
DEBUG 01-06 08:45:00.559427.559427 cuda_h.py:19] end experts_map_get cost 0.00033092498779296875 seconds
DEBUG 01-06 08:45:00.559023.559023 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:00.559203.559203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.559774.559774 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.560088.560088 cuda_h.py:19] end allocate_cuda_memory cost 0.0006570816040039062 seconds
DEBUG 01-06 08:45:00.560170.560170 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.560926.560926 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.560179.560179 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.560736.560736 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 034a988e-375b-4c2e-854c-a4a6a785c373
DEBUG 01-06 08:45:00.560155.560155 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:00.564223.564223 client.py:127] Model loaded
DEBUG 01-06 08:45:00.564625.564625 cuda_h.py:19] end sllm_worker_task cost 0.011321306228637695 seconds
DEBUG 01-06 08:45:00.564839.564839 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.564842.564842 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.565825.565825 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.565215.565215 cuda_h.py:19] end allocate_cuda_memory cost 0.0002827644348144531 seconds
INFO 01-06 08:45:00.565623.565623 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 034a988e-375b-4c2e-854c-a4a6a785c373
DEBUG 01-06 08:45:00.565177.565177 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.565213.565213 cuda_h.py:19] end load_into_gpu_async cost 0.005015850067138672 seconds
DEBUG 01-06 08:45:00.565672.565672 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.565323.565323 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.565580.565580 cuda_h.py:19] end restore_tensors2 cost 5.459785461425781e-05 seconds
DEBUG 01-06 08:45:00.566243.566243 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0010492801666259766 seconds
DEBUG 01-06 08:45:00.566903.566903 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.566947.566947 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f98a2832-7f5e-4756-8ace-651bb2b3088e
DEBUG 01-06 08:45:00.566220.566220 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.566189.566189 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006905317306518555 seconds
DEBUG 01-06 08:45:00.566472.566472 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:00.567250.567250 lmp.py:427] 
DEBUG 01-06 08:45:00.567250.567250 lmp.py:427]   Computing 3 experts on CPU...
DEBUG 01-06 08:45:00.567132.567132 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-06 08:45:00.567736.567736 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:00.575570.575570 mlpmodule.py:704] group tensors cost 0.008458614349365234 s
INFO 01-06 08:45:00.576282.576282 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f98a2832-7f5e-4756-8ace-651bb2b3088e
DEBUG 01-06 08:45:00.577574.577574 cuda_h.py:19] end load_into_gpu_async cost 0.011296987533569336 seconds
DEBUG 01-06 08:45:00.577649.577649 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.577372.577372 cuda_h.py:19] end restore_tensors2 cost 0.0001347064971923828 seconds
DEBUG 01-06 08:45:00.577521.577521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012512922286987305 seconds
INFO 01-06 08:45:00.578328.578328 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f98a2832-7f5e-4756-8ace-651bb2b3088e
DEBUG 01-06 08:45:00.579301.579301 mlpmodule.py:742] pad cost 0.0022954940795898438 s
DEBUG 01-06 08:45:00.579677.579677 mlpmodule.py:748] create cpu tensor cost 7.009506225585938e-05 s
DEBUG 01-06 08:45:00.579808.579808 mlpmodule.py:753] move to cpu cost 5.9604644775390625e-05 s
INFO 01-06 08:45:00.580630.580630 client.py:127] Model loaded
DEBUG 01-06 08:45:00.581953.581953 cuda_h.py:19] end sllm_worker_task cost 0.016104698181152344 seconds
DEBUG 01-06 08:45:00.589547.589547 mlpmodule.py:767] group_w3: shape=torch.Size([3, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=8650752
DEBUG 01-06 08:45:00.590605.590605 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:00.590158.590158 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-06 08:45:00.590944.590944 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:00.604495.604495 mlpmodule.py:793] group einsum cost 0.024957895278930664 s
DEBUG 01-06 08:45:00.605543.605543 mlpmodule.py:801] cpy2cputensor cost 0.0008082389831542969 s
DEBUG 01-06 08:45:00.606980.606980 cuda_h.py:19] end wait_cetm_experts cost 0.039284467697143555 seconds
DEBUG 01-06 08:45:00.606612.606612 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:00.607286.607286 cuda_h.py:19] end gpu_sexperts cost 0.0005228519439697266 seconds
DEBUG 01-06 08:45:00.607421.607421 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:00.607423.607423 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-06 08:45:00.607464.607464 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:00.607750.607750 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 034a988e-375b-4c2e-854c-a4a6a785c373
DEBUG 01-06 08:45:00.614514.614514 mlpmodule.py:662]  experts func einsum cost 0.047568559646606445 s
INFO 01-06 08:45:00.615033.615033 client.py:127] Model loaded
DEBUG 01-06 08:45:00.615611.615611 cuda_h.py:19] end wait_experts cost 0.008324861526489258 seconds
DEBUG 01-06 08:45:00.615559.615559 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:00.615362.615362 lmp.py:472]   Computing 3 experts on GPU...
DEBUG 01-06 08:45:00.616702.616702 cuda_h.py:19] end gpu_experts cost 0.0012619495391845703 seconds
DEBUG 01-06 08:45:00.617944.617944 cuda_h.py:19] end layer_moe_generate_1 cost 0.05829048156738281 seconds
DEBUG 01-06 08:45:00.617418.617418 lmp.py:221] -------------------------------- end layer 1 --------------------------------
DEBUG 01-06 08:45:00.617227.617227 lmp.py:177] -------------------------------- start layer 2 --------------------------------
DEBUG 01-06 08:45:00.617453.617453 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 08:45:00.617547.617547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 08:45:00.617867.617867 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:45:00.617100.617100 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.508827209472656e-05 seconds
DEBUG 01-06 08:45:00.617134.617134 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.617599.617599 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.617555.617555 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.617253.617253 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.617550.617550 cuda_h.py:19] end allocate_cuda_memory cost 0.0003230571746826172 seconds
DEBUG 01-06 08:45:00.617260.617260 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.617023.617023 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.618237.618237 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.618039.618039 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22f6ec9f-5f47-4da1-9d1a-5c0c64bd46ca
DEBUG 01-06 08:45:00.618691.618691 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.618055.618055 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.618998.618998 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22f6ec9f-5f47-4da1-9d1a-5c0c64bd46ca
DEBUG 01-06 08:45:00.618033.618033 cuda_h.py:19] end load_into_gpu_async cost 0.0008845329284667969 seconds
DEBUG 01-06 08:45:00.618597.618597 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.619415.619415 cuda_h.py:19] end restore_tensors2 cost 8.153915405273438e-05 seconds
DEBUG 01-06 08:45:00.619555.619555 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015478134155273438 seconds
INFO 01-06 08:45:00.619524.619524 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22f6ec9f-5f47-4da1-9d1a-5c0c64bd46ca
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:00.622348.622348 cuda_h.py:19] end self_attn cost 0.004145383834838867 seconds
DEBUG 01-06 08:45:00.623438.623438 cuda_h.py:19] end iln_self_attn_paln cost 0.0057027339935302734 seconds
DEBUG 01-06 08:45:00.623474.623474 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-06 08:45:00.623144.623144 cuda_h.py:10] start gate
DEBUG 01-06 08:45:00.623259.623259 cuda_h.py:19] end gate cost 0.0006473064422607422 seconds
DEBUG 01-06 08:45:00.623897.623897 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:00.624729.624729 lmp.py:369] 
DEBUG 01-06 08:45:00.624729.624729 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:00.624598.624598 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:00.624440.624440 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:00.624275.624275 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:00.624203.624203 lmp.py:373] 
DEBUG 01-06 08:45:00.624203.624203 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:00.624846.624846 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:00.624933.624933 lmp.py:380]   Expert 36 |     21 | CPU
DEBUG 01-06 08:45:00.624106.624106 lmp.py:380]   Expert 34 |     36 | CPU
DEBUG 01-06 08:45:00.624033.624033 lmp.py:380]   Expert 63 |     38 | CPU
DEBUG 01-06 08:45:00.624604.624604 lmp.py:380]   Expert 58 |     40 | CPU
DEBUG 01-06 08:45:00.624678.624678 lmp.py:380]   Expert  3 |     56 | CPU
DEBUG 01-06 08:45:00.624367.624367 lmp.py:380]   Expert 29 |     57 | CPU
DEBUG 01-06 08:45:00.624771.624771 lmp.py:380]   Expert  8 |     60 | CPU
DEBUG 01-06 08:45:00.624699.624699 lmp.py:380]   Expert 10 |     62 | CPU
DEBUG 01-06 08:45:00.624673.624673 lmp.py:380]   Expert 26 |     67 | CPU
DEBUG 01-06 08:45:00.624409.624409 lmp.py:380]   Expert 27 |     67 | CPU
DEBUG 01-06 08:45:00.624383.624383 lmp.py:380]   Expert  7 |     74 | CPU
DEBUG 01-06 08:45:00.624880.624880 lmp.py:380]   Expert 50 |     79 | CPU
DEBUG 01-06 08:45:00.624092.624092 lmp.py:380]   Expert 13 |     85 | CPU
DEBUG 01-06 08:45:00.624067.624067 lmp.py:380]   Expert 21 |     91 | CPU
DEBUG 01-06 08:45:00.624802.624802 lmp.py:380]   Expert 28 |     91 | CPU
DEBUG 01-06 08:45:00.624491.624491 lmp.py:380]   Expert 17 |     96 | CPU
DEBUG 01-06 08:45:00.624181.624181 lmp.py:380]   Expert 25 |     99 | CPU
DEBUG 01-06 08:45:00.624155.624155 lmp.py:380]   Expert 19 |    106 | CPU
DEBUG 01-06 08:45:00.624129.624129 lmp.py:380]   Expert 12 |    117 | CPU
DEBUG 01-06 08:45:00.624103.624103 lmp.py:380]   Expert 37 |    126 | CPU
DEBUG 01-06 08:45:00.624600.624600 lmp.py:380]   Expert 62 |    132 | CPU
DEBUG 01-06 08:45:00.624813.624813 lmp.py:380]   Expert 45 |    135 | CPU
DEBUG 01-06 08:45:00.624548.624548 lmp.py:380]   Expert 14 |    138 | CPU
DEBUG 01-06 08:45:00.624999.624999 lmp.py:380]   Expert  6 |    145 | CPU
DEBUG 01-06 08:45:00.624688.624688 lmp.py:380]   Expert 48 |    146 | CPU
DEBUG 01-06 08:45:00.624901.624901 lmp.py:380]   Expert 35 |    151 | CPU
DEBUG 01-06 08:45:00.624875.624875 lmp.py:380]   Expert 44 |    151 | CPU
DEBUG 01-06 08:45:00.624610.624610 lmp.py:380]   Expert 41 |    155 | CPU
DEBUG 01-06 08:45:00.624108.624108 lmp.py:380]   Expert 16 |    156 | CPU
DEBUG 01-06 08:45:00.624843.624843 lmp.py:380]   Expert 30 |    157 | CPU
DEBUG 01-06 08:45:00.624341.624341 lmp.py:380]   Expert  5 |    163 | CPU
DEBUG 01-06 08:45:00.624315.624315 lmp.py:380]   Expert 42 |    169 | CPU
DEBUG 01-06 08:45:00.624289.624289 lmp.py:380]   Expert 47 |    170 | GPU
DEBUG 01-06 08:45:00.624978.624978 lmp.py:380]   Expert 40 |    176 | GPU
DEBUG 01-06 08:45:00.624190.624190 lmp.py:380]   Expert  9 |    182 | GPU
DEBUG 01-06 08:45:00.624926.624926 lmp.py:380]   Expert 33 |    183 | GPU
DEBUG 01-06 08:45:00.624900.624900 lmp.py:380]   Expert 31 |    192 | GPU
DEBUG 01-06 08:45:00.625636.625636 lmp.py:380]   Expert 46 |    194 | GPU
DEBUG 01-06 08:45:00.625610.625610 lmp.py:380]   Expert 59 |    195 | GPU
DEBUG 01-06 08:45:00.625107.625107 lmp.py:380]   Expert 49 |    196 | GPU
DEBUG 01-06 08:45:00.625081.625081 lmp.py:380]   Expert 61 |    197 | GPU
DEBUG 01-06 08:45:00.625293.625293 lmp.py:380]   Expert 52 |    199 | GPU
DEBUG 01-06 08:45:00.625744.625744 lmp.py:380]   Expert 39 |    207 | GPU
DEBUG 01-06 08:45:00.625195.625195 lmp.py:380]   Expert  1 |    208 | GPU
DEBUG 01-06 08:45:00.625169.625169 lmp.py:380]   Expert 38 |    208 | GPU
DEBUG 01-06 08:45:00.625620.625620 lmp.py:380]   Expert  0 |    226 | GPU
DEBUG 01-06 08:45:00.625594.625594 lmp.py:380]   Expert 57 |    242 | GPU
DEBUG 01-06 08:45:00.625568.625568 lmp.py:380]   Expert 20 |    245 | GPU
DEBUG 01-06 08:45:00.625542.625542 lmp.py:380]   Expert 15 |    254 | GPU
DEBUG 01-06 08:45:00.625516.625516 lmp.py:380]   Expert 18 |    265 | GPU
DEBUG 01-06 08:45:00.625444.625444 lmp.py:380]   Expert 24 |    269 | GPU
DEBUG 01-06 08:45:00.625418.625418 lmp.py:380]   Expert 55 |    297 | GPU
DEBUG 01-06 08:45:00.625392.625392 lmp.py:380]   Expert 51 |    307 | GPU
DEBUG 01-06 08:45:00.625366.625366 lmp.py:380]   Expert  2 |    308 | GPU
DEBUG 01-06 08:45:00.625102.625102 lmp.py:380]   Expert 60 |    320 | GPU
DEBUG 01-06 08:45:00.625553.625553 lmp.py:380]   Expert 53 |    329 | GPU
DEBUG 01-06 08:45:00.625004.625004 lmp.py:380]   Expert 32 |    339 | GPU
DEBUG 01-06 08:45:00.625693.625693 lmp.py:380]   Expert 23 |    355 | GPU
DEBUG 01-06 08:45:00.625621.625621 lmp.py:380]   Expert 54 |    366 | GPU
DEBUG 01-06 08:45:00.625548.625548 lmp.py:380]   Expert 22 |    370 | GPU
DEBUG 01-06 08:45:00.625476.625476 lmp.py:380]   Expert  4 |    396 | GPU
DEBUG 01-06 08:45:00.625404.625404 lmp.py:380]   Expert 11 |    465 | GPU
DEBUG 01-06 08:45:00.625570.625570 lmp.py:380]   Expert 56 |    552 | GPU
DEBUG 01-06 08:45:00.625213.625213 lmp.py:380]   Expert 43 |    610 | GPU
DEBUG 01-06 08:45:00.625571.625571 lmp.py:381] 
DEBUG 01-06 08:45:00.625571.625571 lmp.py:381]   CPU total tokens: 3266 (26.6%)
DEBUG 01-06 08:45:00.625452.625452 lmp.py:382]   GPU total tokens: 9022 (73.4%)
DEBUG 01-06 08:45:00.625864.625864 cuda_h.py:19] end experts_map_get cost 0.0015635490417480469 seconds
DEBUG 01-06 08:45:00.625222.625222 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:00.625244.625244 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.625633.625633 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.625066.625066 cuda_h.py:19] end allocate_cuda_memory cost 0.0002503395080566406 seconds
DEBUG 01-06 08:45:00.626009.626009 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.626288.626288 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.626772.626772 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.626614.626614 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 431db1cc-5593-4cba-92b9-7309dec47675
DEBUG 01-06 08:45:00.626363.626363 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:00.626745.626745 client.py:127] Model loaded
DEBUG 01-06 08:45:00.626396.626396 cuda_h.py:19] end sllm_worker_task cost 0.009084701538085938 seconds
INFO 01-06 08:45:00.627430.627430 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 431db1cc-5593-4cba-92b9-7309dec47675
DEBUG 01-06 08:45:00.627326.627326 cuda_h.py:19] end load_into_gpu_async cost 0.001142740249633789 seconds
DEBUG 01-06 08:45:00.627552.627552 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.627263.627263 cuda_h.py:19] end restore_tensors2 cost 0.0004277229309082031 seconds
DEBUG 01-06 08:45:00.627914.627914 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021905899047851562 seconds
DEBUG 01-06 08:45:00.630930.630930 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0048825740814208984 seconds
DEBUG 01-06 08:45:00.630978.630978 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:00.630538.630538 lmp.py:427] 
DEBUG 01-06 08:45:00.630538.630538 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:00.630189.630189 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-06 08:45:00.630031.630031 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:00.640945.640945 mlpmodule.py:704] group tensors cost 0.010184049606323242 s
DEBUG 01-06 08:45:00.643310.643310 mlpmodule.py:742] pad cost 0.0016710758209228516 s
DEBUG 01-06 08:45:00.643486.643486 mlpmodule.py:748] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-06 08:45:00.643382.643382 mlpmodule.py:753] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-06 08:45:00.654090.654090 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:00.654334.654334 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:00.654324.654324 mlpmodule.py:773] group_w3 first element: 0.02001953125
WARNING 01-06 08:45:00.655925.655925 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:00.673620.673620 mlpmodule.py:793] group einsum cost 0.029972314834594727 s
DEBUG 01-06 08:45:00.674804.674804 mlpmodule.py:801] cpy2cputensor cost 0.0007231235504150391 s
DEBUG 01-06 08:45:00.679394.679394 cuda_h.py:19] end wait_cetm_experts cost 0.04878497123718262 seconds
DEBUG 01-06 08:45:00.679748.679748 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:00.680593.680593 cuda_h.py:19] end gpu_sexperts cost 0.00047469139099121094 seconds
DEBUG 01-06 08:45:00.680913.680913 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:00.680293.680293 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-06 08:45:00.680665.680665 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:00.680566.680566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 431db1cc-5593-4cba-92b9-7309dec47675
INFO 01-06 08:45:00.685068.685068 client.py:127] Model loaded
DEBUG 01-06 08:45:00.685540.685540 cuda_h.py:19] end wait_experts cost 0.005353450775146484 seconds
DEBUG 01-06 08:45:00.685250.685250 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:00.685675.685675 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:00.689854.689854 mlpmodule.py:662]  experts func einsum cost 0.05830645561218262 s
DEBUG 01-06 08:45:00.696112.696112 cuda_h.py:19] end gpu_experts cost 0.011060476303100586 seconds
DEBUG 01-06 08:45:00.696698.696698 cuda_h.py:19] end layer_moe_generate_2 cost 0.07372784614562988 seconds
DEBUG 01-06 08:45:00.697764.697764 lmp.py:221] -------------------------------- end layer 2 --------------------------------
DEBUG 01-06 08:45:00.697918.697918 lmp.py:177] -------------------------------- start layer 3 --------------------------------
DEBUG 01-06 08:45:00.697806.697806 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 08:45:00.697039.697039 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 08:45:00.697167.697167 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.1948089599609375e-05 seconds
DEBUG 01-06 08:45:00.697201.697201 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.222724914550781e-05 seconds
DEBUG 01-06 08:45:00.697036.697036 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.697138.697138 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.697332.697332 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.697354.697354 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.697745.697745 cuda_h.py:19] end allocate_cuda_memory cost 0.00018358230590820312 seconds
DEBUG 01-06 08:45:00.697178.697178 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.697034.697034 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.697856.697856 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.697605.697605 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ab6e5cce-93fd-43dc-83b2-4f43d90d8d4d
DEBUG 01-06 08:45:00.697721.697721 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.698921.698921 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.699175.699175 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ab6e5cce-93fd-43dc-83b2-4f43d90d8d4d
DEBUG 01-06 08:45:00.699277.699277 cuda_h.py:19] end load_into_gpu_async cost 0.0013287067413330078 seconds
DEBUG 01-06 08:45:00.699748.699748 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.699646.699646 cuda_h.py:19] end restore_tensors2 cost 7.128715515136719e-05 seconds
DEBUG 01-06 08:45:00.699402.699402 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018439292907714844 seconds
INFO 01-06 08:45:00.699160.699160 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ab6e5cce-93fd-43dc-83b2-4f43d90d8d4d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:00.702233.702233 cuda_h.py:19] end self_attn cost 0.0038852691650390625 seconds
DEBUG 01-06 08:45:00.702355.702355 cuda_h.py:19] end iln_self_attn_paln cost 0.005157470703125 seconds
DEBUG 01-06 08:45:00.702291.702291 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-06 08:45:00.702769.702769 cuda_h.py:10] start gate
DEBUG 01-06 08:45:00.703295.703295 cuda_h.py:19] end gate cost 0.0006341934204101562 seconds
DEBUG 01-06 08:45:00.703502.703502 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:00.703777.703777 lmp.py:369] 
DEBUG 01-06 08:45:00.703777.703777 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:00.703341.703341 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:00.703514.703514 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:00.703825.703825 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:00.703753.703753 lmp.py:373] 
DEBUG 01-06 08:45:00.703753.703753 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:00.703158.703158 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:00.703046.703046 lmp.py:380]   Expert 15 |     48 | CPU
DEBUG 01-06 08:45:00.703927.703927 lmp.py:380]   Expert 16 |     49 | CPU
DEBUG 01-06 08:45:00.703855.703855 lmp.py:380]   Expert 59 |     51 | CPU
DEBUG 01-06 08:45:00.703829.703829 lmp.py:380]   Expert 61 |     51 | CPU
DEBUG 01-06 08:45:00.703803.703803 lmp.py:380]   Expert  1 |     59 | CPU
DEBUG 01-06 08:45:00.703539.703539 lmp.py:380]   Expert  4 |     59 | CPU
DEBUG 01-06 08:45:00.703513.703513 lmp.py:380]   Expert 32 |     75 | CPU
DEBUG 01-06 08:45:00.703487.703487 lmp.py:380]   Expert 29 |     89 | CPU
DEBUG 01-06 08:45:00.703984.703984 lmp.py:380]   Expert 58 |     89 | CPU
DEBUG 01-06 08:45:00.703197.703197 lmp.py:380]   Expert 56 |     92 | CPU
DEBUG 01-06 08:45:00.703886.703886 lmp.py:380]   Expert 26 |    107 | CPU
DEBUG 01-06 08:45:00.703337.703337 lmp.py:380]   Expert  7 |    109 | CPU
DEBUG 01-06 08:45:00.703788.703788 lmp.py:380]   Expert  6 |    117 | CPU
DEBUG 01-06 08:45:00.703715.703715 lmp.py:380]   Expert  8 |    119 | CPU
DEBUG 01-06 08:45:00.703928.703928 lmp.py:380]   Expert 28 |    125 | CPU
DEBUG 01-06 08:45:00.703425.703425 lmp.py:380]   Expert  5 |    127 | CPU
DEBUG 01-06 08:45:00.703399.703399 lmp.py:380]   Expert 19 |    127 | CPU
DEBUG 01-06 08:45:00.703896.703896 lmp.py:380]   Expert 52 |    127 | CPU
DEBUG 01-06 08:45:00.704870.704870 lmp.py:380]   Expert 30 |    130 | CPU
DEBUG 01-06 08:45:00.704367.704367 lmp.py:380]   Expert 31 |    140 | CPU
DEBUG 01-06 08:45:00.704103.704103 lmp.py:380]   Expert 48 |    145 | CPU
DEBUG 01-06 08:45:00.704839.704839 lmp.py:380]   Expert 38 |    148 | CPU
DEBUG 01-06 08:45:00.704574.704574 lmp.py:380]   Expert 54 |    148 | CPU
DEBUG 01-06 08:45:00.704787.704787 lmp.py:380]   Expert 37 |    153 | CPU
DEBUG 01-06 08:45:00.704238.704238 lmp.py:380]   Expert 10 |    156 | CPU
DEBUG 01-06 08:45:00.704689.704689 lmp.py:380]   Expert 24 |    156 | CPU
DEBUG 01-06 08:45:00.704139.704139 lmp.py:380]   Expert 63 |    159 | CPU
DEBUG 01-06 08:45:00.704875.704875 lmp.py:380]   Expert 12 |    161 | CPU
DEBUG 01-06 08:45:00.704611.704611 lmp.py:380]   Expert 20 |    163 | CPU
DEBUG 01-06 08:45:00.704923.704923 lmp.py:380]   Expert 49 |    163 | CPU
DEBUG 01-06 08:45:00.704897.704897 lmp.py:380]   Expert 11 |    168 | CPU
DEBUG 01-06 08:45:00.704155.704155 lmp.py:380]   Expert 23 |    168 | CPU
DEBUG 01-06 08:45:00.704130.704130 lmp.py:380]   Expert 40 |    174 | GPU
DEBUG 01-06 08:45:00.704627.704627 lmp.py:380]   Expert 35 |    175 | GPU
DEBUG 01-06 08:45:00.704362.704362 lmp.py:380]   Expert 46 |    180 | GPU
DEBUG 01-06 08:45:00.704860.704860 lmp.py:380]   Expert 36 |    184 | GPU
DEBUG 01-06 08:45:00.704834.704834 lmp.py:380]   Expert 57 |    185 | GPU
DEBUG 01-06 08:45:00.704284.704284 lmp.py:380]   Expert 22 |    190 | GPU
DEBUG 01-06 08:45:00.704259.704259 lmp.py:380]   Expert 55 |    196 | GPU
DEBUG 01-06 08:45:00.704471.704471 lmp.py:380]   Expert 18 |    200 | GPU
DEBUG 01-06 08:45:00.704922.704922 lmp.py:380]   Expert 42 |    202 | GPU
DEBUG 01-06 08:45:00.704333.704333 lmp.py:380]   Expert 51 |    204 | GPU
DEBUG 01-06 08:45:00.704546.704546 lmp.py:380]   Expert 62 |    204 | GPU
DEBUG 01-06 08:45:00.704971.704971 lmp.py:380]   Expert  0 |    215 | GPU
DEBUG 01-06 08:45:00.704183.704183 lmp.py:380]   Expert 17 |    215 | GPU
DEBUG 01-06 08:45:00.704157.704157 lmp.py:380]   Expert 45 |    215 | GPU
DEBUG 01-06 08:45:00.704131.704131 lmp.py:380]   Expert 43 |    229 | GPU
DEBUG 01-06 08:45:00.704105.704105 lmp.py:380]   Expert 53 |    233 | GPU
DEBUG 01-06 08:45:00.704079.704079 lmp.py:380]   Expert  2 |    247 | GPU
DEBUG 01-06 08:45:00.704292.704292 lmp.py:380]   Expert  3 |    248 | GPU
DEBUG 01-06 08:45:00.704027.704027 lmp.py:380]   Expert 34 |    250 | GPU
DEBUG 01-06 08:45:00.704240.704240 lmp.py:380]   Expert 33 |    265 | GPU
DEBUG 01-06 08:45:00.704214.704214 lmp.py:380]   Expert 27 |    267 | GPU
DEBUG 01-06 08:45:00.704949.704949 lmp.py:380]   Expert 41 |    274 | GPU
DEBUG 01-06 08:45:00.704924.704924 lmp.py:380]   Expert 39 |    279 | GPU
DEBUG 01-06 08:45:00.704851.704851 lmp.py:380]   Expert 13 |    281 | GPU
DEBUG 01-06 08:45:00.704494.704494 lmp.py:380]   Expert 47 |    318 | GPU
DEBUG 01-06 08:45:00.704422.704422 lmp.py:380]   Expert 44 |    331 | GPU
DEBUG 01-06 08:45:00.704350.704350 lmp.py:380]   Expert 21 |    334 | GPU
DEBUG 01-06 08:45:00.704801.704801 lmp.py:380]   Expert 50 |    337 | GPU
DEBUG 01-06 08:45:00.704967.704967 lmp.py:380]   Expert 25 |    376 | GPU
DEBUG 01-06 08:45:00.704418.704418 lmp.py:380]   Expert  9 |    403 | GPU
DEBUG 01-06 08:45:00.704392.704392 lmp.py:380]   Expert 14 |    530 | GPU
DEBUG 01-06 08:45:00.704889.704889 lmp.py:380]   Expert 60 |    569 | GPU
DEBUG 01-06 08:45:00.704055.704055 lmp.py:381] 
DEBUG 01-06 08:45:00.704055.704055 lmp.py:381]   CPU total tokens: 3778 (30.7%)
DEBUG 01-06 08:45:00.704460.704460 lmp.py:382]   GPU total tokens: 8510 (69.3%)
DEBUG 01-06 08:45:00.704156.704156 cuda_h.py:19] end experts_map_get cost 0.0015070438385009766 seconds
DEBUG 01-06 08:45:00.704560.704560 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:00.704390.704390 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.705295.705295 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.705789.705789 cuda_h.py:19] end allocate_cuda_memory cost 0.00046944618225097656 seconds
DEBUG 01-06 08:45:00.705460.705460 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.705170.705170 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.705264.705264 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.705152.705152 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2c0c2d30-1ee5-4dd2-9f57-6b7390e50736
DEBUG 01-06 08:45:00.707730.707730 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:00.707393.707393 client.py:127] Model loaded
DEBUG 01-06 08:45:00.708971.708971 cuda_h.py:19] end sllm_worker_task cost 0.010584115982055664 seconds
INFO 01-06 08:45:00.708210.708210 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2c0c2d30-1ee5-4dd2-9f57-6b7390e50736
DEBUG 01-06 08:45:00.708914.708914 cuda_h.py:19] end load_into_gpu_async cost 0.0032498836517333984 seconds
DEBUG 01-06 08:45:00.708048.708048 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.709088.709088 cuda_h.py:19] end restore_tensors2 cost 0.0003883838653564453 seconds
DEBUG 01-06 08:45:00.709593.709593 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004481077194213867 seconds
DEBUG 01-06 08:45:00.712092.712092 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007141828536987305 seconds
DEBUG 01-06 08:45:00.712418.712418 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:00.712739.712739 lmp.py:427] 
DEBUG 01-06 08:45:00.712739.712739 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:00.712483.712483 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-06 08:45:00.712563.712563 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:00.719663.719663 mlpmodule.py:704] group tensors cost 0.007378339767456055 s
DEBUG 01-06 08:45:00.723954.723954 mlpmodule.py:742] pad cost 0.0024557113647460938 s
DEBUG 01-06 08:45:00.723720.723720 mlpmodule.py:748] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-06 08:45:00.723708.723708 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-06 08:45:00.734318.734318 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:00.734900.734900 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:00.735990.735990 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-06 08:45:00.735067.735067 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:00.755405.755405 mlpmodule.py:793] group einsum cost 0.032595157623291016 s
DEBUG 01-06 08:45:00.756555.756555 mlpmodule.py:801] cpy2cputensor cost 0.0007016658782958984 s
DEBUG 01-06 08:45:00.761116.761116 cuda_h.py:19] end wait_cetm_experts cost 0.049483299255371094 seconds
DEBUG 01-06 08:45:00.761178.761178 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:00.762308.762308 cuda_h.py:19] end gpu_sexperts cost 0.0004754066467285156 seconds
DEBUG 01-06 08:45:00.762866.762866 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:00.762339.762339 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-06 08:45:00.762995.762995 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:00.762897.762897 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2c0c2d30-1ee5-4dd2-9f57-6b7390e50736
INFO 01-06 08:45:00.767924.767924 client.py:127] Model loaded
DEBUG 01-06 08:45:00.767251.767251 cuda_h.py:19] end wait_experts cost 0.005037069320678711 seconds
DEBUG 01-06 08:45:00.767815.767815 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:00.767286.767286 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:00.770847.770847 mlpmodule.py:662]  experts func einsum cost 0.05858731269836426 s
DEBUG 01-06 08:45:00.778663.778663 cuda_h.py:19] end gpu_experts cost 0.011050701141357422 seconds
DEBUG 01-06 08:45:00.778740.778740 cuda_h.py:19] end layer_moe_generate_3 cost 0.07628035545349121 seconds
DEBUG 01-06 08:45:00.779727.779727 lmp.py:221] -------------------------------- end layer 3 --------------------------------
DEBUG 01-06 08:45:00.779596.779596 lmp.py:177] -------------------------------- start layer 4 --------------------------------
DEBUG 01-06 08:45:00.779292.779292 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 08:45:00.779856.779856 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 08:45:00.779931.779931 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.7894973754882812e-05 seconds
DEBUG 01-06 08:45:00.779249.779249 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.793571472167969e-05 seconds
DEBUG 01-06 08:45:00.779059.779059 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.779842.779842 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.779866.779866 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.779510.779510 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.779586.779586 cuda_h.py:19] end allocate_cuda_memory cost 0.00026679039001464844 seconds
DEBUG 01-06 08:45:00.779688.779688 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.779782.779782 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.779572.779572 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.779705.779705 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b1e5682-522a-448f-a680-be94fa116554
DEBUG 01-06 08:45:00.780821.780821 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.780001.780001 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.781308.781308 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b1e5682-522a-448f-a680-be94fa116554
DEBUG 01-06 08:45:00.781859.781859 cuda_h.py:19] end load_into_gpu_async cost 0.0013208389282226562 seconds
DEBUG 01-06 08:45:00.781132.781132 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.781360.781360 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-06 08:45:00.781162.781162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001905202865600586 seconds
INFO 01-06 08:45:00.781967.781967 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b1e5682-522a-448f-a680-be94fa116554
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:00.784406.784406 cuda_h.py:19] end self_attn cost 0.003919124603271484 seconds
DEBUG 01-06 08:45:00.784417.784417 cuda_h.py:19] end iln_self_attn_paln cost 0.0052547454833984375 seconds
DEBUG 01-06 08:45:00.784498.784498 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-06 08:45:00.784275.784275 cuda_h.py:10] start gate
DEBUG 01-06 08:45:00.785191.785191 cuda_h.py:19] end gate cost 0.0006392002105712891 seconds
DEBUG 01-06 08:45:00.785305.785305 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:00.785502.785502 lmp.py:369] 
DEBUG 01-06 08:45:00.785502.785502 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:00.785781.785781 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:00.785431.785431 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:00.785742.785742 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:00.785432.785432 lmp.py:373] 
DEBUG 01-06 08:45:00.785432.785432 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:00.785598.785598 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:00.785771.785771 lmp.py:380]   Expert 45 |     21 | CPU
DEBUG 01-06 08:45:00.785175.785175 lmp.py:380]   Expert 51 |     30 | CPU
DEBUG 01-06 08:45:00.785865.785865 lmp.py:380]   Expert 18 |     32 | CPU
DEBUG 01-06 08:45:00.785077.785077 lmp.py:380]   Expert 60 |     42 | CPU
DEBUG 01-06 08:45:00.785051.785051 lmp.py:380]   Expert 11 |     48 | CPU
DEBUG 01-06 08:45:00.785264.785264 lmp.py:380]   Expert 58 |     49 | CPU
DEBUG 01-06 08:45:00.785668.785668 lmp.py:380]   Expert  8 |     55 | CPU
DEBUG 01-06 08:45:00.786119.786119 lmp.py:380]   Expert 36 |     56 | CPU
DEBUG 01-06 08:45:00.786855.786855 lmp.py:380]   Expert  9 |     59 | CPU
DEBUG 01-06 08:45:00.786829.786829 lmp.py:380]   Expert  2 |     60 | CPU
DEBUG 01-06 08:45:00.786564.786564 lmp.py:380]   Expert 14 |     62 | CPU
DEBUG 01-06 08:45:00.786062.786062 lmp.py:380]   Expert 28 |     64 | CPU
DEBUG 01-06 08:45:00.786797.786797 lmp.py:380]   Expert 13 |     68 | CPU
DEBUG 01-06 08:45:00.786533.786533 lmp.py:380]   Expert  7 |     69 | CPU
DEBUG 01-06 08:45:00.786507.786507 lmp.py:380]   Expert 48 |     73 | CPU
DEBUG 01-06 08:45:00.786481.786481 lmp.py:380]   Expert 41 |     74 | CPU
DEBUG 01-06 08:45:00.786409.786409 lmp.py:380]   Expert 16 |     84 | CPU
DEBUG 01-06 08:45:00.786383.786383 lmp.py:380]   Expert 34 |     85 | CPU
DEBUG 01-06 08:45:00.786118.786118 lmp.py:380]   Expert  6 |     86 | CPU
DEBUG 01-06 08:45:00.786854.786854 lmp.py:380]   Expert  3 |     88 | CPU
DEBUG 01-06 08:45:00.786351.786351 lmp.py:380]   Expert  4 |     99 | CPU
DEBUG 01-06 08:45:00.786325.786325 lmp.py:380]   Expert 25 |    107 | CPU
DEBUG 01-06 08:45:00.786061.786061 lmp.py:380]   Expert 32 |    107 | CPU
DEBUG 01-06 08:45:00.786704.786704 lmp.py:380]   Expert 24 |    114 | CPU
DEBUG 01-06 08:45:00.786108.786108 lmp.py:380]   Expert 55 |    119 | CPU
DEBUG 01-06 08:45:00.786513.786513 lmp.py:380]   Expert 22 |    125 | CPU
DEBUG 01-06 08:45:00.786202.786202 lmp.py:380]   Expert 53 |    126 | CPU
DEBUG 01-06 08:45:00.786892.786892 lmp.py:380]   Expert 26 |    137 | CPU
DEBUG 01-06 08:45:00.786819.786819 lmp.py:380]   Expert 15 |    145 | CPU
DEBUG 01-06 08:45:00.786509.786509 lmp.py:380]   Expert 33 |    145 | CPU
DEBUG 01-06 08:45:00.786675.786675 lmp.py:380]   Expert  0 |    154 | CPU
DEBUG 01-06 08:45:00.786126.786126 lmp.py:380]   Expert 27 |    155 | CPU
DEBUG 01-06 08:45:00.786815.786815 lmp.py:380]   Expert 44 |    156 | GPU
DEBUG 01-06 08:45:00.786743.786743 lmp.py:380]   Expert 54 |    165 | GPU
DEBUG 01-06 08:45:00.786147.786147 lmp.py:380]   Expert 10 |    166 | GPU
DEBUG 01-06 08:45:00.786598.786598 lmp.py:380]   Expert 63 |    169 | GPU
DEBUG 01-06 08:45:00.786287.786287 lmp.py:380]   Expert 19 |    170 | GPU
DEBUG 01-06 08:45:00.786500.786500 lmp.py:380]   Expert 20 |    176 | GPU
DEBUG 01-06 08:45:00.786951.786951 lmp.py:380]   Expert 17 |    181 | GPU
DEBUG 01-06 08:45:00.786640.786640 lmp.py:380]   Expert 21 |    203 | GPU
DEBUG 01-06 08:45:00.786091.786091 lmp.py:380]   Expert 47 |    230 | GPU
DEBUG 01-06 08:45:00.786257.786257 lmp.py:380]   Expert 35 |    231 | GPU
DEBUG 01-06 08:45:00.786662.786662 lmp.py:380]   Expert 46 |    237 | GPU
DEBUG 01-06 08:45:00.786543.786543 lmp.py:380]   Expert 49 |    241 | GPU
DEBUG 01-06 08:45:00.786471.786471 lmp.py:380]   Expert 56 |    242 | GPU
DEBUG 01-06 08:45:00.786922.786922 lmp.py:380]   Expert 61 |    250 | GPU
DEBUG 01-06 08:45:00.786372.786372 lmp.py:380]   Expert 31 |    278 | GPU
DEBUG 01-06 08:45:00.786062.786062 lmp.py:380]   Expert 29 |    282 | GPU
DEBUG 01-06 08:45:00.786751.786751 lmp.py:380]   Expert 42 |    284 | GPU
DEBUG 01-06 08:45:00.786963.786963 lmp.py:380]   Expert 57 |    288 | GPU
DEBUG 01-06 08:45:00.786653.786653 lmp.py:380]   Expert  1 |    303 | GPU
DEBUG 01-06 08:45:00.786580.786580 lmp.py:380]   Expert 30 |    305 | GPU
DEBUG 01-06 08:45:00.786270.786270 lmp.py:380]   Expert 39 |    305 | GPU
DEBUG 01-06 08:45:00.786721.786721 lmp.py:380]   Expert 40 |    310 | GPU
DEBUG 01-06 08:45:00.786933.786933 lmp.py:380]   Expert 37 |    322 | GPU
DEBUG 01-06 08:45:00.786384.786384 lmp.py:380]   Expert 62 |    333 | GPU
DEBUG 01-06 08:45:00.786835.786835 lmp.py:380]   Expert 38 |    345 | GPU
DEBUG 01-06 08:45:00.786047.786047 lmp.py:380]   Expert 50 |    347 | GPU
DEBUG 01-06 08:45:00.786498.786498 lmp.py:380]   Expert 52 |    382 | GPU
DEBUG 01-06 08:45:00.786188.786188 lmp.py:380]   Expert 43 |    412 | GPU
DEBUG 01-06 08:45:00.786354.786354 lmp.py:380]   Expert  5 |    498 | GPU
DEBUG 01-06 08:45:00.786805.786805 lmp.py:380]   Expert 23 |    504 | GPU
DEBUG 01-06 08:45:00.786017.786017 lmp.py:380]   Expert 12 |    610 | GPU
DEBUG 01-06 08:45:00.786706.786706 lmp.py:380]   Expert 59 |    625 | GPU
DEBUG 01-06 08:45:00.786872.786872 lmp.py:381] 
DEBUG 01-06 08:45:00.786872.786872 lmp.py:381]   CPU total tokens: 2738 (22.3%)
DEBUG 01-06 08:45:00.786515.786515 lmp.py:382]   GPU total tokens: 9550 (77.7%)
DEBUG 01-06 08:45:00.786212.786212 cuda_h.py:19] end experts_map_get cost 0.0015170574188232422 seconds
DEBUG 01-06 08:45:00.787570.787570 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:00.787207.787207 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.787444.787444 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.787228.787228 cuda_h.py:19] end allocate_cuda_memory cost 0.0004227161407470703 seconds
DEBUG 01-06 08:45:00.787230.787230 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.787893.787893 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.787941.787941 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.787068.787068 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b908e4d-4792-4025-8cd5-f3a383a0b6f2
DEBUG 01-06 08:45:00.788895.788895 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:00.788198.788198 client.py:127] Model loaded
DEBUG 01-06 08:45:00.788532.788532 cuda_h.py:19] end sllm_worker_task cost 0.008814811706542969 seconds
INFO 01-06 08:45:00.788892.788892 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b908e4d-4792-4025-8cd5-f3a383a0b6f2
DEBUG 01-06 08:45:00.788120.788120 cuda_h.py:19] end load_into_gpu_async cost 0.0012173652648925781 seconds
DEBUG 01-06 08:45:00.789299.789299 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.789592.789592 cuda_h.py:19] end restore_tensors2 cost 0.0003993511199951172 seconds
DEBUG 01-06 08:45:00.789335.789335 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002423524856567383 seconds
DEBUG 01-06 08:45:00.792622.792622 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005102396011352539 seconds
DEBUG 01-06 08:45:00.792134.792134 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:00.792528.792528 lmp.py:427] 
DEBUG 01-06 08:45:00.792528.792528 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:00.792040.792040 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 08:45:00.792882.792882 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:00.804158.804158 mlpmodule.py:704] group tensors cost 0.012273550033569336 s
DEBUG 01-06 08:45:00.807673.807673 mlpmodule.py:742] pad cost 0.0015246868133544922 s
DEBUG 01-06 08:45:00.807538.807538 mlpmodule.py:748] create cpu tensor cost 5.459785461425781e-05 s
DEBUG 01-06 08:45:00.807195.807195 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-06 08:45:00.818421.818421 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:00.818433.818433 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:00.819430.819430 mlpmodule.py:773] group_w3 first element: 0.0111083984375
WARNING 01-06 08:45:00.819223.819223 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:00.839562.839562 mlpmodule.py:793] group einsum cost 0.03242230415344238 s
DEBUG 01-06 08:45:00.840546.840546 mlpmodule.py:801] cpy2cputensor cost 0.0006923675537109375 s
DEBUG 01-06 08:45:00.845819.845819 cuda_h.py:19] end wait_cetm_experts cost 0.05306124687194824 seconds
DEBUG 01-06 08:45:00.845663.845663 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:00.846939.846939 cuda_h.py:19] end gpu_sexperts cost 0.0004754066467285156 seconds
DEBUG 01-06 08:45:00.846120.846120 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:00.846069.846069 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:45:00.846633.846633 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:00.846343.846343 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b908e4d-4792-4025-8cd5-f3a383a0b6f2
INFO 01-06 08:45:00.847135.847135 client.py:127] Model loaded
DEBUG 01-06 08:45:00.847978.847978 cuda_h.py:19] end wait_experts cost 0.0011720657348632812 seconds
DEBUG 01-06 08:45:00.847873.847873 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:00.847390.847390 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:00.856425.856425 mlpmodule.py:662]  experts func einsum cost 0.06357431411743164 s
DEBUG 01-06 08:45:00.858435.858435 cuda_h.py:19] end gpu_experts cost 0.011403322219848633 seconds
DEBUG 01-06 08:45:00.859286.859286 cuda_h.py:19] end layer_moe_generate_4 cost 0.0743100643157959 seconds
DEBUG 01-06 08:45:00.859590.859590 lmp.py:221] -------------------------------- end layer 4 --------------------------------
DEBUG 01-06 08:45:00.859406.859406 lmp.py:177] -------------------------------- start layer 5 --------------------------------
DEBUG 01-06 08:45:00.859910.859910 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 08:45:00.859474.859474 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 08:45:00.859641.859641 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.6941299438476562e-05 seconds
DEBUG 01-06 08:45:00.859888.859888 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.367134094238281e-05 seconds
DEBUG 01-06 08:45:00.859007.859007 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.859017.859017 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.859496.859496 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.859186.859186 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.859064.859064 cuda_h.py:19] end allocate_cuda_memory cost 0.00026226043701171875 seconds
DEBUG 01-06 08:45:00.859934.859934 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.860220.860220 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.860566.860566 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.860792.860792 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 365620e5-6c47-4fcc-b31e-3b36676302dc
DEBUG 01-06 08:45:00.860007.860007 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.860380.860380 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.861343.861343 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 365620e5-6c47-4fcc-b31e-3b36676302dc
DEBUG 01-06 08:45:00.861272.861272 cuda_h.py:19] end load_into_gpu_async cost 0.001161813735961914 seconds
DEBUG 01-06 08:45:00.861306.861306 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.861535.861535 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-06 08:45:00.861099.861099 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017442703247070312 seconds
INFO 01-06 08:45:00.861172.861172 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 365620e5-6c47-4fcc-b31e-3b36676302dc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:00.864067.864067 cuda_h.py:19] end self_attn cost 0.004019498825073242 seconds
DEBUG 01-06 08:45:00.864666.864666 cuda_h.py:19] end iln_self_attn_paln cost 0.005408048629760742 seconds
DEBUG 01-06 08:45:00.864317.864317 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-06 08:45:00.864895.864895 cuda_h.py:10] start gate
DEBUG 01-06 08:45:00.865063.865063 cuda_h.py:19] end gate cost 0.0006501674652099609 seconds
DEBUG 01-06 08:45:00.865701.865701 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:00.865148.865148 lmp.py:369] 
DEBUG 01-06 08:45:00.865148.865148 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:00.866758.866758 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:00.866361.866361 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:00.866150.866150 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:00.866840.866840 lmp.py:373] 
DEBUG 01-06 08:45:00.866840.866840 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:00.866006.866006 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:00.866417.866417 lmp.py:380]   Expert 18 |     16 | CPU
DEBUG 01-06 08:45:00.866060.866060 lmp.py:380]   Expert 15 |     34 | CPU
DEBUG 01-06 08:45:00.866749.866749 lmp.py:380]   Expert 39 |     39 | CPU
DEBUG 01-06 08:45:00.866439.866439 lmp.py:380]   Expert  2 |     40 | CPU
DEBUG 01-06 08:45:00.866651.866651 lmp.py:380]   Expert 48 |     40 | CPU
DEBUG 01-06 08:45:00.866102.866102 lmp.py:380]   Expert 47 |     44 | CPU
DEBUG 01-06 08:45:00.866076.866076 lmp.py:380]   Expert  3 |     51 | CPU
DEBUG 01-06 08:45:00.866242.866242 lmp.py:380]   Expert 42 |     57 | CPU
DEBUG 01-06 08:45:00.866693.866693 lmp.py:380]   Expert 22 |     60 | CPU
DEBUG 01-06 08:45:00.866905.866905 lmp.py:380]   Expert  4 |     64 | CPU
DEBUG 01-06 08:45:00.866118.866118 lmp.py:380]   Expert 32 |     69 | CPU
DEBUG 01-06 08:45:00.866330.866330 lmp.py:380]   Expert 27 |     70 | CPU
DEBUG 01-06 08:45:00.866304.866304 lmp.py:380]   Expert 52 |     70 | CPU
DEBUG 01-06 08:45:00.866517.866517 lmp.py:380]   Expert 23 |     74 | CPU
DEBUG 01-06 08:45:00.866491.866491 lmp.py:380]   Expert 51 |     76 | CPU
DEBUG 01-06 08:45:00.866134.866134 lmp.py:380]   Expert 26 |     77 | CPU
DEBUG 01-06 08:45:00.866538.866538 lmp.py:380]   Expert 24 |     81 | CPU
DEBUG 01-06 08:45:00.866943.866943 lmp.py:380]   Expert 28 |     81 | CPU
DEBUG 01-06 08:45:00.866586.866586 lmp.py:380]   Expert 57 |     84 | CPU
DEBUG 01-06 08:45:00.866514.866514 lmp.py:380]   Expert 30 |     92 | CPU
DEBUG 01-06 08:45:00.866441.866441 lmp.py:380]   Expert 17 |     94 | CPU
DEBUG 01-06 08:45:00.866131.866131 lmp.py:380]   Expert 49 |     94 | CPU
DEBUG 01-06 08:45:00.866058.866058 lmp.py:380]   Expert 45 |    101 | CPU
DEBUG 01-06 08:45:00.866986.866986 lmp.py:380]   Expert 62 |    103 | CPU
DEBUG 01-06 08:45:00.866914.866914 lmp.py:380]   Expert 14 |    114 | CPU
DEBUG 01-06 08:45:00.866080.866080 lmp.py:380]   Expert 36 |    114 | CPU
DEBUG 01-06 08:45:00.866723.866723 lmp.py:380]   Expert 60 |    114 | CPU
DEBUG 01-06 08:45:00.866174.866174 lmp.py:380]   Expert 16 |    121 | CPU
DEBUG 01-06 08:45:00.866102.866102 lmp.py:380]   Expert 46 |    121 | CPU
DEBUG 01-06 08:45:00.866791.866791 lmp.py:380]   Expert 50 |    121 | CPU
DEBUG 01-06 08:45:00.866719.866719 lmp.py:380]   Expert 19 |    125 | CPU
DEBUG 01-06 08:45:00.866646.866646 lmp.py:380]   Expert 12 |    129 | GPU
DEBUG 01-06 08:45:00.866336.866336 lmp.py:380]   Expert 59 |    130 | GPU
DEBUG 01-06 08:45:00.866787.866787 lmp.py:380]   Expert 55 |    131 | GPU
DEBUG 01-06 08:45:00.866714.866714 lmp.py:380]   Expert 29 |    136 | GPU
DEBUG 01-06 08:45:00.866072.866072 lmp.py:380]   Expert  1 |    141 | GPU
DEBUG 01-06 08:45:00.866715.866715 lmp.py:380]   Expert 10 |    145 | GPU
DEBUG 01-06 08:45:00.866166.866166 lmp.py:380]   Expert  8 |    146 | GPU
DEBUG 01-06 08:45:00.866617.866617 lmp.py:380]   Expert 25 |    150 | GPU
DEBUG 01-06 08:45:00.866307.866307 lmp.py:380]   Expert 41 |    154 | GPU
DEBUG 01-06 08:45:00.866519.866519 lmp.py:380]   Expert 43 |    158 | GPU
DEBUG 01-06 08:45:00.866970.866970 lmp.py:380]   Expert  9 |    159 | GPU
DEBUG 01-06 08:45:00.866421.866421 lmp.py:380]   Expert 58 |    161 | GPU
DEBUG 01-06 08:45:00.866110.866110 lmp.py:380]   Expert 56 |    162 | GPU
DEBUG 01-06 08:45:00.866799.866799 lmp.py:380]   Expert 61 |    166 | GPU
DEBUG 01-06 08:45:00.866442.866442 lmp.py:380]   Expert 44 |    171 | GPU
DEBUG 01-06 08:45:00.866847.866847 lmp.py:380]   Expert 54 |    175 | GPU
DEBUG 01-06 08:45:00.866536.866536 lmp.py:380]   Expert 11 |    176 | GPU
DEBUG 01-06 08:45:00.866749.866749 lmp.py:380]   Expert 63 |    187 | GPU
DEBUG 01-06 08:45:00.866438.866438 lmp.py:380]   Expert 38 |    192 | GPU
DEBUG 01-06 08:45:00.866127.866127 lmp.py:380]   Expert  0 |    229 | GPU
DEBUG 01-06 08:45:00.866578.866578 lmp.py:380]   Expert 13 |    241 | GPU
DEBUG 01-06 08:45:00.866791.866791 lmp.py:380]   Expert  5 |    308 | GPU
DEBUG 01-06 08:45:00.866241.866241 lmp.py:380]   Expert 31 |    313 | GPU
DEBUG 01-06 08:45:00.867931.867931 lmp.py:380]   Expert 35 |    315 | GPU
DEBUG 01-06 08:45:00.867097.867097 lmp.py:380]   Expert  7 |    346 | GPU
DEBUG 01-06 08:45:00.867501.867501 lmp.py:380]   Expert 33 |    446 | GPU
DEBUG 01-06 08:45:00.867429.867429 lmp.py:380]   Expert 21 |    503 | GPU
DEBUG 01-06 08:45:00.867880.867880 lmp.py:380]   Expert 37 |    528 | GPU
DEBUG 01-06 08:45:00.867569.867569 lmp.py:380]   Expert 20 |    546 | GPU
DEBUG 01-06 08:45:00.867259.867259 lmp.py:380]   Expert 40 |    564 | GPU
DEBUG 01-06 08:45:00.867710.867710 lmp.py:380]   Expert  6 |    963 | GPU
DEBUG 01-06 08:45:00.867922.867922 lmp.py:380]   Expert 53 |   1576 | GPU
DEBUG 01-06 08:45:00.867803.867803 lmp.py:381] 
DEBUG 01-06 08:45:00.867803.867803 lmp.py:381]   CPU total tokens: 2441 (19.9%)
DEBUG 01-06 08:45:00.867685.867685 lmp.py:382]   GPU total tokens: 9847 (80.1%)
DEBUG 01-06 08:45:00.867573.867573 cuda_h.py:19] end experts_map_get cost 0.001493215560913086 seconds
DEBUG 01-06 08:45:00.867646.867646 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:00.867231.867231 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.867282.867282 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.867568.867568 cuda_h.py:19] end allocate_cuda_memory cost 0.0003871917724609375 seconds
DEBUG 01-06 08:45:00.867570.867570 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.867233.867233 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.867327.867327 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.867454.867454 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 889dfbfd-e135-4087-827f-3803d8afe19d
DEBUG 01-06 08:45:00.868381.868381 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:00.868737.868737 client.py:127] Model loaded
DEBUG 01-06 08:45:00.868117.868117 cuda_h.py:19] end sllm_worker_task cost 0.008851766586303711 seconds
INFO 01-06 08:45:00.869523.869523 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 889dfbfd-e135-4087-827f-3803d8afe19d
DEBUG 01-06 08:45:00.869081.869081 cuda_h.py:19] end load_into_gpu_async cost 0.001184225082397461 seconds
DEBUG 01-06 08:45:00.869499.869499 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.869190.869190 cuda_h.py:19] end restore_tensors2 cost 0.0004475116729736328 seconds
DEBUG 01-06 08:45:00.869795.869795 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023941993713378906 seconds
DEBUG 01-06 08:45:00.872372.872372 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005036830902099609 seconds
DEBUG 01-06 08:45:00.872778.872778 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:00.872902.872902 lmp.py:427] 
DEBUG 01-06 08:45:00.872902.872902 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:00.872414.872414 cuda_h.py:19] end cpu_experts_submit cost 0.00015783309936523438 seconds
DEBUG 01-06 08:45:00.872732.872732 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:00.879822.879822 mlpmodule.py:704] group tensors cost 0.0070841312408447266 s
DEBUG 01-06 08:45:00.883608.883608 mlpmodule.py:742] pad cost 0.0025281906127929688 s
DEBUG 01-06 08:45:00.883381.883381 mlpmodule.py:748] create cpu tensor cost 6.0558319091796875e-05 s
DEBUG 01-06 08:45:00.883570.883570 mlpmodule.py:753] move to cpu cost 4.315376281738281e-05 s
DEBUG 01-06 08:45:00.893327.893327 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:00.893181.893181 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:00.893985.893985 mlpmodule.py:773] group_w3 first element: -0.010498046875
WARNING 01-06 08:45:00.893923.893923 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:00.907729.907729 mlpmodule.py:793] group einsum cost 0.024035215377807617 s
DEBUG 01-06 08:45:00.908518.908518 mlpmodule.py:801] cpy2cputensor cost 0.0006096363067626953 s
DEBUG 01-06 08:45:00.913378.913378 cuda_h.py:19] end wait_cetm_experts cost 0.040599822998046875 seconds
DEBUG 01-06 08:45:00.913083.913083 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:00.913915.913915 cuda_h.py:19] end gpu_sexperts cost 0.00046372413635253906 seconds
DEBUG 01-06 08:45:00.913235.913235 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:00.913621.913621 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-06 08:45:00.913755.913755 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:00.914941.914941 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 889dfbfd-e135-4087-827f-3803d8afe19d
DEBUG 01-06 08:45:00.924213.924213 mlpmodule.py:662]  experts func einsum cost 0.052195072174072266 s
INFO 01-06 08:45:00.925639.925639 client.py:127] Model loaded
DEBUG 01-06 08:45:00.925251.925251 cuda_h.py:19] end wait_experts cost 0.011816263198852539 seconds
DEBUG 01-06 08:45:00.925669.925669 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:00.925372.925372 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:00.936700.936700 cuda_h.py:19] end gpu_experts cost 0.010593652725219727 seconds
DEBUG 01-06 08:45:00.936194.936194 cuda_h.py:19] end layer_moe_generate_5 cost 0.07164335250854492 seconds
DEBUG 01-06 08:45:00.936445.936445 lmp.py:221] -------------------------------- end layer 5 --------------------------------
DEBUG 01-06 08:45:00.936599.936599 lmp.py:177] -------------------------------- start layer 6 --------------------------------
DEBUG 01-06 08:45:00.936487.936487 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 08:45:00.936767.936767 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 08:45:00.936126.936126 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:45:00.936683.936683 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.7697296142578125e-05 seconds
DEBUG 01-06 08:45:00.936518.936518 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:00.937778.937778 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:00.937656.937656 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.937652.937652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.937080.937080 cuda_h.py:19] end allocate_cuda_memory cost 0.00027060508728027344 seconds
DEBUG 01-06 08:45:00.937725.937725 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.937117.937117 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.937000.937000 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.937140.937140 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9939c11-b82d-4710-9ace-8ccd50d27721
DEBUG 01-06 08:45:00.937176.937176 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:00.938298.938298 cuda_h.py:10] start self_attn
INFO 01-06 08:45:00.938669.938669 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9939c11-b82d-4710-9ace-8ccd50d27721
DEBUG 01-06 08:45:00.938281.938281 cuda_h.py:19] end load_into_gpu_async cost 0.0013129711151123047 seconds
DEBUG 01-06 08:45:00.939182.939182 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.939200.939200 cuda_h.py:19] end restore_tensors2 cost 8.320808410644531e-05 seconds
DEBUG 01-06 08:45:00.939374.939374 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019931793212890625 seconds
INFO 01-06 08:45:00.939596.939596 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9939c11-b82d-4710-9ace-8ccd50d27721
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:00.942822.942822 cuda_h.py:19] end self_attn cost 0.004112958908081055 seconds
DEBUG 01-06 08:45:00.942938.942938 cuda_h.py:19] end iln_self_attn_paln cost 0.005581855773925781 seconds
DEBUG 01-06 08:45:00.942158.942158 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-06 08:45:00.942921.942921 cuda_h.py:10] start gate
DEBUG 01-06 08:45:00.943321.943321 cuda_h.py:19] end gate cost 0.0006475448608398438 seconds
DEBUG 01-06 08:45:00.943343.943343 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:00.943711.943711 lmp.py:369] 
DEBUG 01-06 08:45:00.943711.943711 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:00.943275.943275 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:00.943686.943686 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:00.943236.943236 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:00.943879.943879 lmp.py:373] 
DEBUG 01-06 08:45:00.943879.943879 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:00.943522.943522 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:00.943364.943364 lmp.py:380]   Expert  1 |      7 | CPU
DEBUG 01-06 08:45:00.943246.943246 lmp.py:380]   Expert  3 |      9 | CPU
DEBUG 01-06 08:45:00.943412.943412 lmp.py:380]   Expert 14 |     14 | CPU
DEBUG 01-06 08:45:00.943863.943863 lmp.py:380]   Expert 52 |     16 | CPU
DEBUG 01-06 08:45:00.943075.943075 lmp.py:380]   Expert 15 |     21 | CPU
DEBUG 01-06 08:45:00.943003.943003 lmp.py:380]   Expert 16 |     23 | CPU
DEBUG 01-06 08:45:00.943407.943407 lmp.py:380]   Expert 33 |     24 | CPU
DEBUG 01-06 08:45:00.943574.943574 lmp.py:380]   Expert 30 |     35 | CPU
DEBUG 01-06 08:45:00.943740.943740 lmp.py:380]   Expert 53 |     38 | CPU
DEBUG 01-06 08:45:00.943144.943144 lmp.py:380]   Expert 21 |     58 | CPU
DEBUG 01-06 08:45:00.944549.944549 lmp.py:380]   Expert 49 |     59 | CPU
DEBUG 01-06 08:45:00.944238.944238 lmp.py:380]   Expert 63 |     59 | CPU
DEBUG 01-06 08:45:00.944451.944451 lmp.py:380]   Expert 50 |     61 | CPU
DEBUG 01-06 08:45:00.944663.944663 lmp.py:380]   Expert  7 |     69 | CPU
DEBUG 01-06 08:45:00.944875.944875 lmp.py:380]   Expert 11 |     74 | CPU
DEBUG 01-06 08:45:00.944088.944088 lmp.py:380]   Expert 35 |     76 | CPU
DEBUG 01-06 08:45:00.944300.944300 lmp.py:380]   Expert 26 |     77 | CPU
DEBUG 01-06 08:45:00.944751.944751 lmp.py:380]   Expert 40 |     77 | CPU
DEBUG 01-06 08:45:00.944109.944109 lmp.py:380]   Expert 37 |     80 | CPU
DEBUG 01-06 08:45:00.944514.944514 lmp.py:380]   Expert 41 |     81 | CPU
DEBUG 01-06 08:45:00.944872.944872 lmp.py:380]   Expert 29 |     82 | CPU
DEBUG 01-06 08:45:00.944231.944231 lmp.py:380]   Expert 34 |     92 | CPU
DEBUG 01-06 08:45:00.944112.944112 lmp.py:380]   Expert 25 |     93 | CPU
DEBUG 01-06 08:45:00.944993.944993 lmp.py:380]   Expert 10 |     94 | CPU
DEBUG 01-06 08:45:00.944398.944398 lmp.py:380]   Expert  5 |     99 | CPU
DEBUG 01-06 08:45:00.944564.944564 lmp.py:380]   Expert 22 |     99 | CPU
DEBUG 01-06 08:45:00.944730.944730 lmp.py:380]   Expert 59 |     99 | CPU
DEBUG 01-06 08:45:00.944658.944658 lmp.py:380]   Expert  8 |    105 | CPU
DEBUG 01-06 08:45:00.944824.944824 lmp.py:380]   Expert 47 |    108 | CPU
DEBUG 01-06 08:45:00.944990.944990 lmp.py:380]   Expert 44 |    109 | CPU
DEBUG 01-06 08:45:00.944918.944918 lmp.py:380]   Expert 31 |    118 | CPU
DEBUG 01-06 08:45:00.944084.944084 lmp.py:380]   Expert 42 |    124 | CPU
DEBUG 01-06 08:45:00.944880.944880 lmp.py:380]   Expert 38 |    125 | GPU
DEBUG 01-06 08:45:00.944522.944522 lmp.py:380]   Expert 45 |    128 | GPU
DEBUG 01-06 08:45:00.944404.944404 lmp.py:380]   Expert 51 |    130 | GPU
DEBUG 01-06 08:45:00.944524.944524 lmp.py:380]   Expert 13 |    133 | GPU
DEBUG 01-06 08:45:00.944451.944451 lmp.py:380]   Expert 32 |    134 | GPU
DEBUG 01-06 08:45:00.944618.944618 lmp.py:380]   Expert 61 |    141 | GPU
DEBUG 01-06 08:45:00.944545.944545 lmp.py:380]   Expert 12 |    149 | GPU
DEBUG 01-06 08:45:00.944711.944711 lmp.py:380]   Expert 62 |    151 | GPU
DEBUG 01-06 08:45:00.944639.944639 lmp.py:380]   Expert  6 |    169 | GPU
DEBUG 01-06 08:45:00.944567.944567 lmp.py:380]   Expert  0 |    170 | GPU
DEBUG 01-06 08:45:00.944495.944495 lmp.py:380]   Expert 24 |    170 | GPU
DEBUG 01-06 08:45:00.944184.944184 lmp.py:380]   Expert 54 |    182 | GPU
DEBUG 01-06 08:45:00.944350.944350 lmp.py:380]   Expert 20 |    191 | GPU
DEBUG 01-06 08:45:00.944039.944039 lmp.py:380]   Expert 46 |    191 | GPU
DEBUG 01-06 08:45:00.944921.944921 lmp.py:380]   Expert 58 |    191 | GPU
DEBUG 01-06 08:45:00.944564.944564 lmp.py:380]   Expert 57 |    233 | GPU
DEBUG 01-06 08:45:00.944968.944968 lmp.py:380]   Expert  2 |    239 | GPU
DEBUG 01-06 08:45:00.944850.944850 lmp.py:380]   Expert 28 |    248 | GPU
DEBUG 01-06 08:45:00.944539.944539 lmp.py:380]   Expert 17 |    250 | GPU
DEBUG 01-06 08:45:00.944467.944467 lmp.py:380]   Expert 18 |    261 | GPU
DEBUG 01-06 08:45:00.944156.944156 lmp.py:380]   Expert  9 |    270 | GPU
DEBUG 01-06 08:45:00.944084.944084 lmp.py:380]   Expert 39 |    320 | GPU
DEBUG 01-06 08:45:00.944011.944011 lmp.py:380]   Expert 27 |    328 | GPU
DEBUG 01-06 08:45:00.944939.944939 lmp.py:380]   Expert 60 |    353 | GPU
DEBUG 01-06 08:45:00.944390.944390 lmp.py:380]   Expert 19 |    373 | GPU
DEBUG 01-06 08:45:00.944556.944556 lmp.py:380]   Expert 55 |    378 | GPU
DEBUG 01-06 08:45:00.944245.944245 lmp.py:380]   Expert 23 |    396 | GPU
DEBUG 01-06 08:45:00.944173.944173 lmp.py:380]   Expert  4 |    431 | GPU
DEBUG 01-06 08:45:00.944055.944055 lmp.py:380]   Expert 43 |    449 | GPU
DEBUG 01-06 08:45:00.944936.944936 lmp.py:380]   Expert 36 |    767 | GPU
DEBUG 01-06 08:45:00.944579.944579 lmp.py:380]   Expert 56 |   1056 | GPU
DEBUG 01-06 08:45:00.944983.944983 lmp.py:380]   Expert 48 |   1401 | GPU
DEBUG 01-06 08:45:00.944342.944342 lmp.py:381] 
DEBUG 01-06 08:45:00.944342.944342 lmp.py:381]   CPU total tokens: 2180 (17.7%)
DEBUG 01-06 08:45:00.944223.944223 lmp.py:382]   GPU total tokens: 10108 (82.3%)
DEBUG 01-06 08:45:00.944396.944396 cuda_h.py:19] end experts_map_get cost 0.0015559196472167969 seconds
DEBUG 01-06 08:45:00.945754.945754 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:00.945438.945438 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:00.945860.945860 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:00.945144.945144 cuda_h.py:19] end allocate_cuda_memory cost 0.0003504753112792969 seconds
DEBUG 01-06 08:45:00.945862.945862 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:00.945764.945764 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:00.945904.945904 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:00.945030.945030 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a3cfeb30-ebaa-4676-a91f-c8986175c6f2
DEBUG 01-06 08:45:00.945235.945235 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:00.946665.946665 client.py:127] Model loaded
DEBUG 01-06 08:45:00.946330.946330 cuda_h.py:19] end sllm_worker_task cost 0.009032011032104492 seconds
INFO 01-06 08:45:00.947192.947192 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a3cfeb30-ebaa-4676-a91f-c8986175c6f2
DEBUG 01-06 08:45:00.947419.947419 cuda_h.py:19] end load_into_gpu_async cost 0.0017795562744140625 seconds
DEBUG 01-06 08:45:00.947122.947122 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:00.947893.947893 cuda_h.py:19] end restore_tensors2 cost 0.00043582916259765625 seconds
DEBUG 01-06 08:45:00.948020.948020 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002933979034423828 seconds
DEBUG 01-06 08:45:00.950596.950596 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005544185638427734 seconds
DEBUG 01-06 08:45:00.950055.950055 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:00.950231.950231 lmp.py:427] 
DEBUG 01-06 08:45:00.950231.950231 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:00.950497.950497 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-06 08:45:00.950101.950101 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:00.963025.963025 mlpmodule.py:704] group tensors cost 0.012205123901367188 s
DEBUG 01-06 08:45:00.966141.966141 mlpmodule.py:742] pad cost 0.002164125442504883 s
DEBUG 01-06 08:45:00.966265.966265 mlpmodule.py:748] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-06 08:45:00.966479.966479 mlpmodule.py:753] move to cpu cost 3.790855407714844e-05 s
DEBUG 01-06 08:45:00.977493.977493 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:00.977659.977659 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:00.977987.977987 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-06 08:45:00.977408.977408 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:00.997722.997722 mlpmodule.py:793] group einsum cost 0.03126859664916992 s
DEBUG 01-06 08:45:00.998072.998072 mlpmodule.py:801] cpy2cputensor cost 0.0005850791931152344 s
DEBUG 01-06 08:45:01.003201.003201 cuda_h.py:19] end wait_cetm_experts cost 0.05259227752685547 seconds
DEBUG 01-06 08:45:01.003045.003045 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.004546.004546 cuda_h.py:19] end gpu_sexperts cost 0.00046706199645996094 seconds
DEBUG 01-06 08:45:01.004819.004819 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.004206.004206 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.170967102050781e-05 seconds
DEBUG 01-06 08:45:01.004532.004532 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.004433.004433 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a3cfeb30-ebaa-4676-a91f-c8986175c6f2
INFO 01-06 08:45:01.005442.005442 client.py:127] Model loaded
DEBUG 01-06 08:45:01.005762.005762 cuda_h.py:19] end wait_experts cost 0.0015087127685546875 seconds
DEBUG 01-06 08:45:01.005895.005895 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.005651.005651 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.015104.015104 mlpmodule.py:662]  experts func einsum cost 0.06481575965881348 s
DEBUG 01-06 08:45:01.018939.018939 cuda_h.py:19] end gpu_experts cost 0.012530803680419922 seconds
DEBUG 01-06 08:45:01.018662.018662 cuda_h.py:19] end layer_moe_generate_6 cost 0.07593464851379395 seconds
DEBUG 01-06 08:45:01.018536.018536 lmp.py:221] -------------------------------- end layer 6 --------------------------------
DEBUG 01-06 08:45:01.018776.018776 lmp.py:177] -------------------------------- start layer 7 --------------------------------
DEBUG 01-06 08:45:01.018757.018757 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 08:45:01.018605.018605 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 08:45:01.018388.018388 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.574920654296875e-05 seconds
DEBUG 01-06 08:45:01.018204.018204 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.985664367675781e-05 seconds
DEBUG 01-06 08:45:01.018801.018801 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.019162.019162 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.019178.019178 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.019914.019914 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.019845.019845 cuda_h.py:19] end allocate_cuda_memory cost 0.0002655982971191406 seconds
DEBUG 01-06 08:45:01.019470.019470 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.019325.019325 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.019479.019479 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.019275.019275 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1d61af90-eb8b-400c-8faf-fa65275d9e16
DEBUG 01-06 08:45:01.019768.019768 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.020623.020623 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.020114.020114 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1d61af90-eb8b-400c-8faf-fa65275d9e16
DEBUG 01-06 08:45:01.020355.020355 cuda_h.py:19] end load_into_gpu_async cost 0.0012848377227783203 seconds
DEBUG 01-06 08:45:01.020058.020058 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.021432.021432 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-06 08:45:01.021950.021950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018715858459472656 seconds
INFO 01-06 08:45:01.021861.021861 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1d61af90-eb8b-400c-8faf-fa65275d9e16
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.023741.023741 cuda_h.py:19] end self_attn cost 0.0032515525817871094 seconds
DEBUG 01-06 08:45:01.023857.023857 cuda_h.py:19] end iln_self_attn_paln cost 0.004820108413696289 seconds
DEBUG 01-06 08:45:01.023131.023131 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-06 08:45:01.023516.023516 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.024632.024632 cuda_h.py:19] end gate cost 0.0006475448608398438 seconds
DEBUG 01-06 08:45:01.024654.024654 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.024783.024783 lmp.py:369] 
DEBUG 01-06 08:45:01.024783.024783 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.025731.025731 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.025573.025573 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.025077.025077 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.025197.025197 lmp.py:373] 
DEBUG 01-06 08:45:01.025197.025197 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.025793.025793 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.025827.025827 lmp.py:380]   Expert 55 |      2 | CPU
DEBUG 01-06 08:45:01.025662.025662 lmp.py:380]   Expert 40 |      6 | CPU
DEBUG 01-06 08:45:01.025544.025544 lmp.py:380]   Expert 31 |      7 | CPU
DEBUG 01-06 08:45:01.025187.025187 lmp.py:380]   Expert  3 |     14 | CPU
DEBUG 01-06 08:45:01.025068.025068 lmp.py:380]   Expert 49 |     16 | CPU
DEBUG 01-06 08:45:01.025950.025950 lmp.py:380]   Expert 25 |     17 | CPU
DEBUG 01-06 08:45:01.025069.025069 lmp.py:380]   Expert 20 |     21 | CPU
DEBUG 01-06 08:45:01.025189.025189 lmp.py:380]   Expert 26 |     23 | CPU
DEBUG 01-06 08:45:01.025832.025832 lmp.py:380]   Expert 34 |     26 | CPU
DEBUG 01-06 08:45:01.025998.025998 lmp.py:380]   Expert 41 |     26 | CPU
DEBUG 01-06 08:45:01.025403.025403 lmp.py:380]   Expert 45 |     27 | CPU
DEBUG 01-06 08:45:01.025046.025046 lmp.py:380]   Expert  1 |     32 | CPU
DEBUG 01-06 08:45:01.025689.025689 lmp.py:380]   Expert 48 |     32 | CPU
DEBUG 01-06 08:45:01.025093.025093 lmp.py:380]   Expert 58 |     32 | CPU
DEBUG 01-06 08:45:01.025498.025498 lmp.py:380]   Expert 15 |     36 | CPU
DEBUG 01-06 08:45:01.025664.025664 lmp.py:380]   Expert 63 |     38 | CPU
DEBUG 01-06 08:45:01.025069.025069 lmp.py:380]   Expert 16 |     40 | CPU
DEBUG 01-06 08:45:01.025950.025950 lmp.py:380]   Expert 28 |     43 | CPU
DEBUG 01-06 08:45:01.025547.025547 lmp.py:380]   Expert  6 |     46 | CPU
DEBUG 01-06 08:45:01.025190.025190 lmp.py:380]   Expert 44 |     46 | CPU
DEBUG 01-06 08:45:01.025356.025356 lmp.py:380]   Expert 29 |     49 | CPU
DEBUG 01-06 08:45:01.025760.025760 lmp.py:380]   Expert 42 |     49 | CPU
DEBUG 01-06 08:45:01.025926.025926 lmp.py:380]   Expert 57 |     50 | CPU
DEBUG 01-06 08:45:01.025331.025331 lmp.py:380]   Expert  5 |     57 | CPU
DEBUG 01-06 08:45:01.025497.025497 lmp.py:380]   Expert 32 |     57 | CPU
DEBUG 01-06 08:45:01.025663.025663 lmp.py:380]   Expert  8 |     58 | CPU
DEBUG 01-06 08:45:01.025306.025306 lmp.py:380]   Expert 56 |     60 | CPU
DEBUG 01-06 08:45:01.025949.025949 lmp.py:380]   Expert 37 |     73 | CPU
DEBUG 01-06 08:45:01.025354.025354 lmp.py:380]   Expert 59 |     74 | CPU
DEBUG 01-06 08:45:01.025758.025758 lmp.py:380]   Expert 18 |     76 | CPU
DEBUG 01-06 08:45:01.025924.025924 lmp.py:380]   Expert 60 |     78 | CPU
DEBUG 01-06 08:45:01.025091.025091 lmp.py:380]   Expert 39 |     80 | CPU
DEBUG 01-06 08:45:01.025257.025257 lmp.py:380]   Expert 33 |     87 | GPU
DEBUG 01-06 08:45:01.025184.025184 lmp.py:380]   Expert 30 |     98 | GPU
DEBUG 01-06 08:45:01.025112.025112 lmp.py:380]   Expert  4 |    107 | GPU
DEBUG 01-06 08:45:01.025232.025232 lmp.py:380]   Expert 43 |    123 | GPU
DEBUG 01-06 08:45:01.025113.025113 lmp.py:380]   Expert  7 |    124 | GPU
DEBUG 01-06 08:45:01.025280.025280 lmp.py:380]   Expert 14 |    133 | GPU
DEBUG 01-06 08:45:01.025446.025446 lmp.py:380]   Expert 13 |    142 | GPU
DEBUG 01-06 08:45:01.025135.025135 lmp.py:380]   Expert 19 |    147 | GPU
DEBUG 01-06 08:45:01.025063.025063 lmp.py:380]   Expert 53 |    153 | GPU
DEBUG 01-06 08:45:01.025990.025990 lmp.py:380]   Expert 50 |    174 | GPU
DEBUG 01-06 08:45:01.025918.025918 lmp.py:380]   Expert  0 |    187 | GPU
DEBUG 01-06 08:45:01.025846.025846 lmp.py:380]   Expert 21 |    196 | GPU
DEBUG 01-06 08:45:01.025774.025774 lmp.py:380]   Expert 51 |    203 | GPU
DEBUG 01-06 08:45:01.025655.025655 lmp.py:380]   Expert 52 |    203 | GPU
DEBUG 01-06 08:45:01.025298.025298 lmp.py:380]   Expert 36 |    219 | GPU
DEBUG 01-06 08:45:01.025226.025226 lmp.py:380]   Expert 24 |    224 | GPU
DEBUG 01-06 08:45:01.025153.025153 lmp.py:380]   Expert 27 |    232 | GPU
DEBUG 01-06 08:45:01.025843.025843 lmp.py:380]   Expert 35 |    232 | GPU
DEBUG 01-06 08:45:01.025294.025294 lmp.py:380]   Expert 10 |    237 | GPU
DEBUG 01-06 08:45:01.026221.026221 lmp.py:380]   Expert 11 |    251 | GPU
DEBUG 01-06 08:45:01.026387.026387 lmp.py:380]   Expert 38 |    263 | GPU
DEBUG 01-06 08:45:01.026269.026269 lmp.py:380]   Expert 54 |    265 | GPU
DEBUG 01-06 08:45:01.026435.026435 lmp.py:380]   Expert  2 |    365 | GPU
DEBUG 01-06 08:45:01.026124.026124 lmp.py:380]   Expert 62 |    375 | GPU
DEBUG 01-06 08:45:01.026052.026052 lmp.py:380]   Expert 61 |    385 | GPU
DEBUG 01-06 08:45:01.026980.026980 lmp.py:380]   Expert 47 |    467 | GPU
DEBUG 01-06 08:45:01.026907.026907 lmp.py:380]   Expert 46 |    479 | GPU
DEBUG 01-06 08:45:01.026358.026358 lmp.py:380]   Expert 17 |    608 | GPU
DEBUG 01-06 08:45:01.026286.026286 lmp.py:380]   Expert 22 |    715 | GPU
DEBUG 01-06 08:45:01.026452.026452 lmp.py:380]   Expert  9 |    796 | GPU
DEBUG 01-06 08:45:01.026857.026857 lmp.py:380]   Expert 12 |    952 | GPU
DEBUG 01-06 08:45:01.026546.026546 lmp.py:380]   Expert 23 |   1855 | GPU
DEBUG 01-06 08:45:01.026189.026189 lmp.py:381] 
DEBUG 01-06 08:45:01.026189.026189 lmp.py:381]   CPU total tokens: 1291 (10.5%)
DEBUG 01-06 08:45:01.026561.026561 lmp.py:382]   GPU total tokens: 10997 (89.5%)
DEBUG 01-06 08:45:01.026495.026495 cuda_h.py:19] end experts_map_get cost 0.0015757083892822266 seconds
DEBUG 01-06 08:45:01.026900.026900 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.026537.026537 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.026389.026389 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.028845.028845 cuda_h.py:19] end allocate_cuda_memory cost 0.0014948844909667969 seconds
DEBUG 01-06 08:45:01.028106.028106 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.028484.028484 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.028055.028055 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.028659.028659 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99ac1ce6-9b86-4c40-8c6d-b40d6a1dd1ef
DEBUG 01-06 08:45:01.028102.028102 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.028244.028244 client.py:127] Model loaded
DEBUG 01-06 08:45:01.028816.028816 cuda_h.py:19] end sllm_worker_task cost 0.009565353393554688 seconds
INFO 01-06 08:45:01.029884.029884 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99ac1ce6-9b86-4c40-8c6d-b40d6a1dd1ef
DEBUG 01-06 08:45:01.029541.029541 cuda_h.py:19] end load_into_gpu_async cost 0.0013034343719482422 seconds
DEBUG 01-06 08:45:01.029867.029867 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.029015.029015 cuda_h.py:19] end restore_tensors2 cost 0.0004248619079589844 seconds
DEBUG 01-06 08:45:01.029050.029050 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003620624542236328 seconds
DEBUG 01-06 08:45:01.032953.032953 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006296634674072266 seconds
DEBUG 01-06 08:45:01.032902.032902 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.032011.032011 lmp.py:427] 
DEBUG 01-06 08:45:01.032011.032011 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.032900.032900 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-06 08:45:01.032172.032172 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.039958.039958 mlpmodule.py:704] group tensors cost 0.006129026412963867 s
DEBUG 01-06 08:45:01.041560.041560 mlpmodule.py:742] pad cost 0.001901388168334961 s
DEBUG 01-06 08:45:01.041332.041332 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-06 08:45:01.041295.041295 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-06 08:45:01.052210.052210 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:01.052094.052094 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.052515.052515 mlpmodule.py:773] group_w3 first element: 0.01263427734375
WARNING 01-06 08:45:01.052705.052705 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.071495.071495 mlpmodule.py:793] group einsum cost 0.03001236915588379 s
DEBUG 01-06 08:45:01.072563.072563 mlpmodule.py:801] cpy2cputensor cost 0.0004363059997558594 s
DEBUG 01-06 08:45:01.077242.077242 cuda_h.py:19] end wait_cetm_experts cost 0.04456520080566406 seconds
DEBUG 01-06 08:45:01.077086.077086 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.078925.078925 cuda_h.py:19] end gpu_sexperts cost 0.0004696846008300781 seconds
DEBUG 01-06 08:45:01.078622.078622 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.078148.078148 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:45:01.078096.078096 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.078905.078905 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99ac1ce6-9b86-4c40-8c6d-b40d6a1dd1ef
INFO 01-06 08:45:01.087734.087734 client.py:127] Model loaded
DEBUG 01-06 08:45:01.087862.087862 cuda_h.py:19] end wait_experts cost 0.00920557975769043 seconds
DEBUG 01-06 08:45:01.087042.087042 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.087367.087367 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.089819.089819 mlpmodule.py:662]  experts func einsum cost 0.056571245193481445 s
DEBUG 01-06 08:45:01.098382.098382 cuda_h.py:19] end gpu_experts cost 0.011311769485473633 seconds
DEBUG 01-06 08:45:01.098685.098685 cuda_h.py:19] end layer_moe_generate_7 cost 0.07505655288696289 seconds
DEBUG 01-06 08:45:01.099645.099645 lmp.py:221] -------------------------------- end layer 7 --------------------------------
DEBUG 01-06 08:45:01.099620.099620 lmp.py:177] -------------------------------- start layer 8 --------------------------------
DEBUG 01-06 08:45:01.099078.099078 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 08:45:01.099165.099165 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 08:45:01.099809.099809 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.7179718017578125e-05 seconds
DEBUG 01-06 08:45:01.099366.099366 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.6743621826171875e-05 seconds
DEBUG 01-06 08:45:01.099201.099201 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.099574.099574 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.099360.099360 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.099832.099832 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.099907.099907 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-06 08:45:01.099506.099506 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.100852.100852 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.100404.100404 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.100829.100829 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a845888e-8cd6-4b18-9300-2acb4dd547e2
DEBUG 01-06 08:45:01.100488.100488 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.100735.100735 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.101440.101440 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a845888e-8cd6-4b18-9300-2acb4dd547e2
DEBUG 01-06 08:45:01.101243.101243 cuda_h.py:19] end load_into_gpu_async cost 0.0015869140625 seconds
DEBUG 01-06 08:45:01.101430.101430 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.101593.101593 cuda_h.py:19] end restore_tensors2 cost 8.440017700195312e-05 seconds
DEBUG 01-06 08:45:01.101614.101614 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022149085998535156 seconds
INFO 01-06 08:45:01.102812.102812 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a845888e-8cd6-4b18-9300-2acb4dd547e2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.104168.104168 cuda_h.py:19] end self_attn cost 0.003976583480834961 seconds
DEBUG 01-06 08:45:01.104357.104357 cuda_h.py:19] end iln_self_attn_paln cost 0.005421876907348633 seconds
DEBUG 01-06 08:45:01.104677.104677 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-06 08:45:01.104155.104155 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.105306.105306 cuda_h.py:19] end gate cost 0.0007073879241943359 seconds
DEBUG 01-06 08:45:01.105897.105897 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.106477.106477 lmp.py:369] 
DEBUG 01-06 08:45:01.106477.106477 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.106902.106902 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.106075.106075 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.106294.106294 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.106129.106129 lmp.py:373] 
DEBUG 01-06 08:45:01.106129.106129 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.106832.106832 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.106151.106151 lmp.py:380]   Expert 12 |      2 | CPU
DEBUG 01-06 08:45:01.106271.106271 lmp.py:380]   Expert 14 |      2 | CPU
DEBUG 01-06 08:45:01.106483.106483 lmp.py:380]   Expert 27 |      5 | CPU
DEBUG 01-06 08:45:01.106934.106934 lmp.py:380]   Expert  7 |      8 | CPU
DEBUG 01-06 08:45:01.106147.106147 lmp.py:380]   Expert 32 |     10 | CPU
DEBUG 01-06 08:45:01.106121.106121 lmp.py:380]   Expert 50 |     15 | CPU
DEBUG 01-06 08:45:01.106095.106095 lmp.py:380]   Expert 34 |     19 | CPU
DEBUG 01-06 08:45:01.106069.106069 lmp.py:380]   Expert 26 |     22 | CPU
DEBUG 01-06 08:45:01.106043.106043 lmp.py:380]   Expert 23 |     23 | CPU
DEBUG 01-06 08:45:01.106255.106255 lmp.py:380]   Expert 30 |     28 | CPU
DEBUG 01-06 08:45:01.106660.106660 lmp.py:380]   Expert 33 |     29 | CPU
DEBUG 01-06 08:45:01.106064.106064 lmp.py:380]   Expert 38 |     48 | CPU
DEBUG 01-06 08:45:01.106469.106469 lmp.py:380]   Expert 22 |     49 | CPU
DEBUG 01-06 08:45:01.106205.106205 lmp.py:380]   Expert 54 |     54 | CPU
DEBUG 01-06 08:45:01.106940.106940 lmp.py:380]   Expert 16 |     55 | CPU
DEBUG 01-06 08:45:01.106676.106676 lmp.py:380]   Expert 18 |     55 | CPU
DEBUG 01-06 08:45:01.106411.106411 lmp.py:380]   Expert 53 |     57 | CPU
DEBUG 01-06 08:45:01.106670.106670 lmp.py:380]   Expert 58 |     61 | CPU
DEBUG 01-06 08:45:01.106406.106406 lmp.py:380]   Expert  1 |     65 | CPU
DEBUG 01-06 08:45:01.106903.106903 lmp.py:380]   Expert 36 |     72 | CPU
DEBUG 01-06 08:45:01.106639.106639 lmp.py:380]   Expert 44 |     79 | CPU
DEBUG 01-06 08:45:01.106897.106897 lmp.py:380]   Expert 24 |     80 | CPU
DEBUG 01-06 08:45:01.106395.106395 lmp.py:380]   Expert 25 |     82 | CPU
DEBUG 01-06 08:45:01.106892.106892 lmp.py:380]   Expert 57 |     88 | CPU
DEBUG 01-06 08:45:01.106628.106628 lmp.py:380]   Expert 42 |     90 | CPU
DEBUG 01-06 08:45:01.106125.106125 lmp.py:380]   Expert  9 |     91 | CPU
DEBUG 01-06 08:45:01.106099.106099 lmp.py:380]   Expert 29 |    109 | CPU
DEBUG 01-06 08:45:01.106026.106026 lmp.py:380]   Expert 39 |    112 | CPU
DEBUG 01-06 08:45:01.106001.106001 lmp.py:380]   Expert 55 |    116 | CPU
DEBUG 01-06 08:45:01.106213.106213 lmp.py:380]   Expert 37 |    121 | CPU
DEBUG 01-06 08:45:01.106949.106949 lmp.py:380]   Expert 19 |    135 | CPU
DEBUG 01-06 08:45:01.106684.106684 lmp.py:380]   Expert 60 |    143 | CPU
DEBUG 01-06 08:45:01.106181.106181 lmp.py:380]   Expert 46 |    145 | GPU
DEBUG 01-06 08:45:01.106917.106917 lmp.py:380]   Expert  8 |    151 | GPU
DEBUG 01-06 08:45:01.106176.106176 lmp.py:380]   Expert 41 |    156 | GPU
DEBUG 01-06 08:45:01.106673.106673 lmp.py:380]   Expert 31 |    165 | GPU
DEBUG 01-06 08:45:01.106409.106409 lmp.py:380]   Expert 40 |    167 | GPU
DEBUG 01-06 08:45:01.106906.106906 lmp.py:380]   Expert 56 |    167 | GPU
DEBUG 01-06 08:45:01.106403.106403 lmp.py:380]   Expert  2 |    171 | GPU
DEBUG 01-06 08:45:01.106377.106377 lmp.py:380]   Expert 51 |    172 | GPU
DEBUG 01-06 08:45:01.106212.106212 lmp.py:380]   Expert 21 |    180 | GPU
DEBUG 01-06 08:45:01.106140.106140 lmp.py:380]   Expert 15 |    196 | GPU
DEBUG 01-06 08:45:01.106545.106545 lmp.py:380]   Expert  3 |    197 | GPU
DEBUG 01-06 08:45:01.106519.106519 lmp.py:380]   Expert 61 |    237 | GPU
DEBUG 01-06 08:45:01.106016.106016 lmp.py:380]   Expert 20 |    241 | GPU
DEBUG 01-06 08:45:01.106990.106990 lmp.py:380]   Expert 13 |    244 | GPU
DEBUG 01-06 08:45:01.106725.106725 lmp.py:380]   Expert 28 |    249 | GPU
DEBUG 01-06 08:45:01.106461.106461 lmp.py:380]   Expert 49 |    249 | GPU
DEBUG 01-06 08:45:01.106720.106720 lmp.py:380]   Expert 35 |    258 | GPU
DEBUG 01-06 08:45:01.106455.106455 lmp.py:380]   Expert  0 |    277 | GPU
DEBUG 01-06 08:45:01.106714.106714 lmp.py:380]   Expert 11 |    313 | GPU
DEBUG 01-06 08:45:01.107450.107450 lmp.py:380]   Expert 10 |    340 | GPU
DEBUG 01-06 08:45:01.107378.107378 lmp.py:380]   Expert 45 |    371 | GPU
DEBUG 01-06 08:45:01.107544.107544 lmp.py:380]   Expert 52 |    376 | GPU
DEBUG 01-06 08:45:01.107379.107379 lmp.py:380]   Expert 47 |    391 | GPU
DEBUG 01-06 08:45:01.107545.107545 lmp.py:380]   Expert 17 |    400 | GPU
DEBUG 01-06 08:45:01.107757.107757 lmp.py:380]   Expert 48 |    428 | GPU
DEBUG 01-06 08:45:01.107255.107255 lmp.py:380]   Expert  4 |    442 | GPU
DEBUG 01-06 08:45:01.107990.107990 lmp.py:380]   Expert 43 |    508 | GPU
DEBUG 01-06 08:45:01.107726.107726 lmp.py:380]   Expert  6 |    531 | GPU
DEBUG 01-06 08:45:01.107462.107462 lmp.py:380]   Expert 59 |    595 | GPU
DEBUG 01-06 08:45:01.107959.107959 lmp.py:380]   Expert 63 |    626 | GPU
DEBUG 01-06 08:45:01.107456.107456 lmp.py:380]   Expert 62 |    642 | GPU
DEBUG 01-06 08:45:01.107192.107192 lmp.py:380]   Expert  5 |    778 | GPU
DEBUG 01-06 08:45:01.107119.107119 lmp.py:381] 
DEBUG 01-06 08:45:01.107119.107119 lmp.py:381]   CPU total tokens: 1925 (15.7%)
DEBUG 01-06 08:45:01.107431.107431 lmp.py:382]   GPU total tokens: 10363 (84.3%)
DEBUG 01-06 08:45:01.107796.107796 cuda_h.py:19] end experts_map_get cost 0.0015115737915039062 seconds
DEBUG 01-06 08:45:01.107347.107347 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.107269.107269 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.107551.107551 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.108581.108581 cuda_h.py:19] end allocate_cuda_memory cost 0.0006384849548339844 seconds
DEBUG 01-06 08:45:01.108776.108776 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.108962.108962 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.108056.108056 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.108852.108852 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 53a278c1-0659-4b79-ada7-9901ef0ae886
DEBUG 01-06 08:45:01.108699.108699 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.108273.108273 client.py:127] Model loaded
DEBUG 01-06 08:45:01.108368.108368 cuda_h.py:19] end sllm_worker_task cost 0.009349822998046875 seconds
INFO 01-06 08:45:01.110674.110674 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 53a278c1-0659-4b79-ada7-9901ef0ae886
DEBUG 01-06 08:45:01.110524.110524 cuda_h.py:19] end load_into_gpu_async cost 0.0023419857025146484 seconds
DEBUG 01-06 08:45:01.110181.110181 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.111773.111773 cuda_h.py:19] end restore_tensors2 cost 0.0004405975341796875 seconds
DEBUG 01-06 08:45:01.111616.111616 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003815174102783203 seconds
DEBUG 01-06 08:45:01.113412.113412 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0064809322357177734 seconds
DEBUG 01-06 08:45:01.113831.113831 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.113815.113815 lmp.py:427] 
DEBUG 01-06 08:45:01.113815.113815 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.113843.113843 cuda_h.py:19] end cpu_experts_submit cost 0.00010514259338378906 seconds
DEBUG 01-06 08:45:01.114685.114685 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.127504.127504 mlpmodule.py:704] group tensors cost 0.013430595397949219 s
DEBUG 01-06 08:45:01.130518.130518 mlpmodule.py:742] pad cost 0.0018239021301269531 s
DEBUG 01-06 08:45:01.130661.130661 mlpmodule.py:748] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-06 08:45:01.130365.130365 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 08:45:01.143598.143598 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:01.143121.143121 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.143641.143641 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-06 08:45:01.143572.143572 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.163625.163625 mlpmodule.py:793] group einsum cost 0.03301262855529785 s
DEBUG 01-06 08:45:01.164083.164083 mlpmodule.py:801] cpy2cputensor cost 0.0006339550018310547 s
DEBUG 01-06 08:45:01.169403.169403 cuda_h.py:19] end wait_cetm_experts cost 0.05522513389587402 seconds
DEBUG 01-06 08:45:01.169956.169956 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.169072.169072 cuda_h.py:19] end gpu_sexperts cost 0.00046443939208984375 seconds
DEBUG 01-06 08:45:01.169246.169246 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.170341.170341 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-06 08:45:01.170621.170621 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.170999.170999 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 53a278c1-0659-4b79-ada7-9901ef0ae886
INFO 01-06 08:45:01.171993.171993 client.py:127] Model loaded
DEBUG 01-06 08:45:01.171259.171259 cuda_h.py:19] end wait_experts cost 0.0012478828430175781 seconds
DEBUG 01-06 08:45:01.171201.171201 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.171480.171480 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.181216.181216 mlpmodule.py:662]  experts func einsum cost 0.06714105606079102 s
DEBUG 01-06 08:45:01.183978.183978 cuda_h.py:19] end gpu_experts cost 0.01191258430480957 seconds
DEBUG 01-06 08:45:01.183267.183267 cuda_h.py:19] end layer_moe_generate_8 cost 0.0784902572631836 seconds
DEBUG 01-06 08:45:01.183770.183770 lmp.py:221] -------------------------------- end layer 8 --------------------------------
DEBUG 01-06 08:45:01.183752.183752 lmp.py:177] -------------------------------- start layer 9 --------------------------------
DEBUG 01-06 08:45:01.183309.183309 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 08:45:01.183926.183926 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 08:45:01.183531.183531 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.956390380859375e-05 seconds
DEBUG 01-06 08:45:01.183234.183234 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.222724914550781e-05 seconds
DEBUG 01-06 08:45:01.183420.183420 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.183972.183972 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.184433.184433 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.184461.184461 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.184227.184227 cuda_h.py:19] end allocate_cuda_memory cost 0.00027441978454589844 seconds
DEBUG 01-06 08:45:01.184282.184282 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.184853.184853 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.184484.184484 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.184233.184233 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b9ef5017-5e7c-4721-b946-8845f42cffdb
DEBUG 01-06 08:45:01.184064.184064 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.184178.184178 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.186244.186244 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b9ef5017-5e7c-4721-b946-8845f42cffdb
DEBUG 01-06 08:45:01.186842.186842 cuda_h.py:19] end load_into_gpu_async cost 0.0016415119171142578 seconds
DEBUG 01-06 08:45:01.186399.186399 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.186482.186482 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-06 08:45:01.186476.186476 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022432804107666016 seconds
INFO 01-06 08:45:01.186785.186785 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b9ef5017-5e7c-4721-b946-8845f42cffdb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.188443.188443 cuda_h.py:19] end self_attn cost 0.0032901763916015625 seconds
DEBUG 01-06 08:45:01.189176.189176 cuda_h.py:19] end iln_self_attn_paln cost 0.00533604621887207 seconds
DEBUG 01-06 08:45:01.189357.189357 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-06 08:45:01.189219.189219 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.189884.189884 cuda_h.py:19] end gate cost 0.0006299018859863281 seconds
DEBUG 01-06 08:45:01.190760.190760 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.190313.190313 lmp.py:369] 
DEBUG 01-06 08:45:01.190313.190313 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.190546.190546 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.190434.190434 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.190984.190984 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.190627.190627 lmp.py:373] 
DEBUG 01-06 08:45:01.190627.190627 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.190469.190469 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.190357.190357 lmp.py:380]   Expert  7 |      5 | CPU
DEBUG 01-06 08:45:01.190523.190523 lmp.py:380]   Expert 13 |     11 | CPU
DEBUG 01-06 08:45:01.190974.190974 lmp.py:380]   Expert 35 |     18 | CPU
DEBUG 01-06 08:45:01.190710.190710 lmp.py:380]   Expert 42 |     25 | CPU
DEBUG 01-06 08:45:01.190684.190684 lmp.py:380]   Expert  6 |     28 | CPU
DEBUG 01-06 08:45:01.190419.190419 lmp.py:380]   Expert 49 |     28 | CPU
DEBUG 01-06 08:45:01.190393.190393 lmp.py:380]   Expert 19 |     30 | CPU
DEBUG 01-06 08:45:01.190891.190891 lmp.py:380]   Expert 38 |     30 | CPU
DEBUG 01-06 08:45:01.190626.190626 lmp.py:380]   Expert 39 |     30 | CPU
DEBUG 01-06 08:45:01.190124.190124 lmp.py:380]   Expert 14 |     31 | CPU
DEBUG 01-06 08:45:01.190336.190336 lmp.py:380]   Expert 20 |     32 | CPU
DEBUG 01-06 08:45:01.190833.190833 lmp.py:380]   Expert  2 |     37 | CPU
DEBUG 01-06 08:45:01.190807.190807 lmp.py:380]   Expert 25 |     39 | CPU
DEBUG 01-06 08:45:01.190066.190066 lmp.py:380]   Expert 40 |     39 | CPU
DEBUG 01-06 08:45:01.190279.190279 lmp.py:380]   Expert 54 |     47 | CPU
DEBUG 01-06 08:45:01.190259.190259 lmp.py:380]   Expert 11 |     58 | CPU
DEBUG 01-06 08:45:01.190472.190472 lmp.py:380]   Expert 48 |     60 | CPU
DEBUG 01-06 08:45:01.190969.190969 lmp.py:380]   Expert 26 |     62 | CPU
DEBUG 01-06 08:45:01.190705.190705 lmp.py:380]   Expert  5 |     64 | CPU
DEBUG 01-06 08:45:01.190963.190963 lmp.py:380]   Expert 56 |     66 | CPU
DEBUG 01-06 08:45:01.190699.190699 lmp.py:380]   Expert 33 |     71 | CPU
DEBUG 01-06 08:45:01.190196.190196 lmp.py:380]   Expert 60 |     73 | CPU
DEBUG 01-06 08:45:01.190693.190693 lmp.py:380]   Expert 16 |     84 | CPU
DEBUG 01-06 08:45:01.190952.190952 lmp.py:380]   Expert 28 |     85 | CPU
DEBUG 01-06 08:45:01.190211.190211 lmp.py:380]   Expert 17 |     86 | CPU
DEBUG 01-06 08:45:01.190708.190708 lmp.py:380]   Expert 27 |     93 | CPU
DEBUG 01-06 08:45:01.190205.190205 lmp.py:380]   Expert 46 |    100 | CPU
DEBUG 01-06 08:45:01.190703.190703 lmp.py:380]   Expert 47 |    100 | CPU
DEBUG 01-06 08:45:01.190200.190200 lmp.py:380]   Expert 24 |    106 | CPU
DEBUG 01-06 08:45:01.190936.190936 lmp.py:380]   Expert 62 |    110 | CPU
DEBUG 01-06 08:45:01.190671.190671 lmp.py:380]   Expert 50 |    111 | CPU
DEBUG 01-06 08:45:01.190645.190645 lmp.py:380]   Expert 12 |    118 | CPU
DEBUG 01-06 08:45:01.190672.190672 lmp.py:380]   Expert 41 |    120 | GPU
DEBUG 01-06 08:45:01.190408.190408 lmp.py:380]   Expert 52 |    121 | GPU
DEBUG 01-06 08:45:01.191382.191382 lmp.py:380]   Expert 22 |    126 | GPU
DEBUG 01-06 08:45:01.191641.191641 lmp.py:380]   Expert 57 |    134 | GPU
DEBUG 01-06 08:45:01.191376.191376 lmp.py:380]   Expert 45 |    139 | GPU
DEBUG 01-06 08:45:01.191874.191874 lmp.py:380]   Expert 18 |    147 | GPU
DEBUG 01-06 08:45:01.191609.191609 lmp.py:380]   Expert 51 |    148 | GPU
DEBUG 01-06 08:45:01.191868.191868 lmp.py:380]   Expert 59 |    157 | GPU
DEBUG 01-06 08:45:01.191604.191604 lmp.py:380]   Expert 10 |    160 | GPU
DEBUG 01-06 08:45:01.191101.191101 lmp.py:380]   Expert  8 |    187 | GPU
DEBUG 01-06 08:45:01.191837.191837 lmp.py:380]   Expert 58 |    192 | GPU
DEBUG 01-06 08:45:01.191572.191572 lmp.py:380]   Expert 32 |    200 | GPU
DEBUG 01-06 08:45:01.191546.191546 lmp.py:380]   Expert  4 |    205 | GPU
DEBUG 01-06 08:45:01.191043.191043 lmp.py:380]   Expert 31 |    234 | GPU
DEBUG 01-06 08:45:01.191309.191309 lmp.py:380]   Expert 29 |    252 | GPU
DEBUG 01-06 08:45:01.191521.191521 lmp.py:380]   Expert 34 |    281 | GPU
DEBUG 01-06 08:45:01.191257.191257 lmp.py:380]   Expert 30 |    299 | GPU
DEBUG 01-06 08:45:01.191754.191754 lmp.py:380]   Expert 53 |    300 | GPU
DEBUG 01-06 08:45:01.191251.191251 lmp.py:380]   Expert 55 |    309 | GPU
DEBUG 01-06 08:45:01.191987.191987 lmp.py:380]   Expert 15 |    312 | GPU
DEBUG 01-06 08:45:01.191484.191484 lmp.py:380]   Expert 37 |    331 | GPU
DEBUG 01-06 08:45:01.191982.191982 lmp.py:380]   Expert 36 |    345 | GPU
DEBUG 01-06 08:45:01.191479.191479 lmp.py:380]   Expert  3 |    346 | GPU
DEBUG 01-06 08:45:01.191976.191976 lmp.py:380]   Expert  1 |    455 | GPU
DEBUG 01-06 08:45:01.191473.191473 lmp.py:380]   Expert 23 |    499 | GPU
DEBUG 01-06 08:45:01.191209.191209 lmp.py:380]   Expert  9 |    511 | GPU
DEBUG 01-06 08:45:01.191706.191706 lmp.py:380]   Expert 63 |    516 | GPU
DEBUG 01-06 08:45:01.191395.191395 lmp.py:380]   Expert 43 |    566 | GPU
DEBUG 01-06 08:45:01.191892.191892 lmp.py:380]   Expert 44 |    665 | GPU
DEBUG 01-06 08:45:01.191628.191628 lmp.py:380]   Expert  0 |    667 | GPU
DEBUG 01-06 08:45:01.191125.191125 lmp.py:380]   Expert 21 |    700 | GPU
DEBUG 01-06 08:45:01.191861.191861 lmp.py:380]   Expert 61 |    787 | GPU
DEBUG 01-06 08:45:01.191312.191312 lmp.py:381] 
DEBUG 01-06 08:45:01.191312.191312 lmp.py:381]   CPU total tokens: 1877 (15.3%)
DEBUG 01-06 08:45:01.191240.191240 lmp.py:382]   GPU total tokens: 10411 (84.7%)
DEBUG 01-06 08:45:01.191982.191982 cuda_h.py:19] end experts_map_get cost 0.0014712810516357422 seconds
DEBUG 01-06 08:45:01.191433.191433 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.191878.191878 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.191115.191115 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.193655.193655 cuda_h.py:19] end allocate_cuda_memory cost 0.0016639232635498047 seconds
DEBUG 01-06 08:45:01.193896.193896 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.193036.193036 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.193037.193037 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.193356.193356 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3eff97cd-2155-4bcf-8bd4-8691d2399026
DEBUG 01-06 08:45:01.193183.193183 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.194010.194010 client.py:127] Model loaded
DEBUG 01-06 08:45:01.194145.194145 cuda_h.py:19] end sllm_worker_task cost 0.01018381118774414 seconds
INFO 01-06 08:45:01.195008.195008 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3eff97cd-2155-4bcf-8bd4-8691d2399026
DEBUG 01-06 08:45:01.195082.195082 cuda_h.py:19] end load_into_gpu_async cost 0.0021746158599853516 seconds
DEBUG 01-06 08:45:01.195831.195831 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.196925.196925 cuda_h.py:19] end restore_tensors2 cost 0.00039267539978027344 seconds
DEBUG 01-06 08:45:01.196669.196669 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004599332809448242 seconds
DEBUG 01-06 08:45:01.198623.198623 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007241964340209961 seconds
DEBUG 01-06 08:45:01.198374.198374 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.198760.198760 lmp.py:427] 
DEBUG 01-06 08:45:01.198760.198760 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.199597.199597 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-06 08:45:01.199459.199459 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.205374.205374 mlpmodule.py:704] group tensors cost 0.006812572479248047 s
DEBUG 01-06 08:45:01.209054.209054 mlpmodule.py:742] pad cost 0.002332448959350586 s
DEBUG 01-06 08:45:01.209900.209900 mlpmodule.py:748] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-06 08:45:01.209837.209837 mlpmodule.py:753] move to cpu cost 4.482269287109375e-05 s
DEBUG 01-06 08:45:01.218533.218533 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:01.219539.219539 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.219198.219198 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-06 08:45:01.219321.219321 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.236955.236955 mlpmodule.py:793] group einsum cost 0.027187824249267578 s
DEBUG 01-06 08:45:01.237423.237423 mlpmodule.py:801] cpy2cputensor cost 0.0005331039428710938 s
DEBUG 01-06 08:45:01.242559.242559 cuda_h.py:19] end wait_cetm_experts cost 0.04325270652770996 seconds
DEBUG 01-06 08:45:01.242502.242502 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.242672.242672 cuda_h.py:19] end gpu_sexperts cost 0.0004684925079345703 seconds
DEBUG 01-06 08:45:01.243369.243369 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.243318.243318 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-06 08:45:01.243975.243975 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.243969.243969 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3eff97cd-2155-4bcf-8bd4-8691d2399026
INFO 01-06 08:45:01.246260.246260 client.py:127] Model loaded
DEBUG 01-06 08:45:01.246865.246865 cuda_h.py:19] end wait_experts cost 0.0030138492584228516 seconds
DEBUG 01-06 08:45:01.246998.246998 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.246516.246516 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.258709.258709 cuda_h.py:19] end gpu_experts cost 0.011896848678588867 seconds
DEBUG 01-06 08:45:01.258071.258071 cuda_h.py:19] end layer_moe_generate_9 cost 0.06895971298217773 seconds
DEBUG 01-06 08:45:01.258548.258548 lmp.py:221] -------------------------------- end layer 9 --------------------------------
DEBUG 01-06 08:45:01.258272.258272 lmp.py:177] -------------------------------- start layer 10 --------------------------------
DEBUG 01-06 08:45:01.258544.258544 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 08:45:01.258446.258446 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 08:45:01.258574.258574 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.0040740966796875e-05 seconds
DEBUG 01-06 08:45:01.258230.258230 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.222724914550781e-05 seconds
DEBUG 01-06 08:45:01.258449.258449 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.258963.258963 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.258157.258157 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.258516.258516 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.262869.262869 cuda_h.py:19] end allocate_cuda_memory cost 0.003554105758666992 seconds
DEBUG 01-06 08:45:01.262044.262044 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.262059.262059 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.262895.262895 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.262751.262751 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 05daba97-fcdc-426a-a4b4-920303484704
DEBUG 01-06 08:45:01.262595.262595 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.262143.262143 mlpmodule.py:662]  experts func einsum cost 0.06382274627685547 s
DEBUG 01-06 08:45:01.263537.263537 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.263033.263033 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 05daba97-fcdc-426a-a4b4-920303484704
DEBUG 01-06 08:45:01.263989.263989 cuda_h.py:19] end load_into_gpu_async cost 0.00128173828125 seconds
DEBUG 01-06 08:45:01.263129.263129 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.264378.264378 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-06 08:45:01.264717.264717 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00522303581237793 seconds
INFO 01-06 08:45:01.264935.264935 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 05daba97-fcdc-426a-a4b4-920303484704
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.267389.267389 cuda_h.py:19] end self_attn cost 0.004206657409667969 seconds
DEBUG 01-06 08:45:01.267193.267193 cuda_h.py:19] end iln_self_attn_paln cost 0.009117364883422852 seconds
DEBUG 01-06 08:45:01.267559.267559 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-06 08:45:01.267037.267037 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.268557.268557 cuda_h.py:19] end gate cost 0.0006659030914306641 seconds
DEBUG 01-06 08:45:01.268387.268387 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.268317.268317 lmp.py:369] 
DEBUG 01-06 08:45:01.268317.268317 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.269358.269358 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:01.269485.269485 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:01.269797.269797 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:01.269201.269201 lmp.py:373] 
DEBUG 01-06 08:45:01.269201.269201 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.269559.269559 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.269686.269686 lmp.py:380]   Expert 34 |      1 | CPU
DEBUG 01-06 08:45:01.269567.269567 lmp.py:380]   Expert 61 |      7 | CPU
DEBUG 01-06 08:45:01.269495.269495 lmp.py:380]   Expert  6 |      8 | CPU
DEBUG 01-06 08:45:01.269184.269184 lmp.py:380]   Expert 37 |     10 | CPU
DEBUG 01-06 08:45:01.269112.269112 lmp.py:380]   Expert 14 |     13 | CPU
DEBUG 01-06 08:45:01.269325.269325 lmp.py:380]   Expert  3 |     14 | CPU
DEBUG 01-06 08:45:01.269775.269775 lmp.py:380]   Expert 13 |     18 | CPU
DEBUG 01-06 08:45:01.269988.269988 lmp.py:380]   Expert 48 |     18 | CPU
DEBUG 01-06 08:45:01.269200.269200 lmp.py:380]   Expert  7 |     21 | CPU
DEBUG 01-06 08:45:01.269413.269413 lmp.py:380]   Expert 55 |     22 | CPU
DEBUG 01-06 08:45:01.269533.269533 lmp.py:380]   Expert 56 |     22 | CPU
DEBUG 01-06 08:45:01.269414.269414 lmp.py:380]   Expert 32 |     23 | CPU
DEBUG 01-06 08:45:01.269772.269772 lmp.py:380]   Expert 47 |     23 | CPU
DEBUG 01-06 08:45:01.269130.269130 lmp.py:380]   Expert 11 |     26 | CPU
DEBUG 01-06 08:45:01.269489.269489 lmp.py:380]   Expert 21 |     36 | CPU
DEBUG 01-06 08:45:01.269132.269132 lmp.py:380]   Expert 35 |     36 | CPU
DEBUG 01-06 08:45:01.269298.269298 lmp.py:380]   Expert 15 |     44 | CPU
DEBUG 01-06 08:45:01.269226.269226 lmp.py:380]   Expert 41 |     44 | CPU
DEBUG 01-06 08:45:01.269392.269392 lmp.py:380]   Expert 38 |     46 | CPU
DEBUG 01-06 08:45:01.269796.269796 lmp.py:380]   Expert 20 |     56 | CPU
DEBUG 01-06 08:45:01.269201.269201 lmp.py:380]   Expert 52 |     57 | CPU
DEBUG 01-06 08:45:01.269128.269128 lmp.py:380]   Expert 54 |     57 | CPU
DEBUG 01-06 08:45:01.269295.269295 lmp.py:380]   Expert 44 |     62 | CPU
DEBUG 01-06 08:45:01.269461.269461 lmp.py:380]   Expert 39 |     71 | CPU
DEBUG 01-06 08:45:01.269342.269342 lmp.py:380]   Expert 12 |     80 | CPU
DEBUG 01-06 08:45:01.269700.269700 lmp.py:380]   Expert 62 |     84 | CPU
DEBUG 01-06 08:45:01.269582.269582 lmp.py:380]   Expert 46 |     88 | CPU
DEBUG 01-06 08:45:01.269702.269702 lmp.py:380]   Expert 45 |     99 | CPU
DEBUG 01-06 08:45:01.269643.269643 lmp.py:380]   Expert  9 |    100 | CPU
DEBUG 01-06 08:45:01.269571.269571 lmp.py:380]   Expert 43 |    102 | CPU
DEBUG 01-06 08:45:01.269260.269260 lmp.py:380]   Expert 49 |    111 | CPU
DEBUG 01-06 08:45:01.269949.269949 lmp.py:380]   Expert 59 |    130 | GPU
DEBUG 01-06 08:45:01.269639.269639 lmp.py:380]   Expert 50 |    136 | GPU
DEBUG 01-06 08:45:01.269089.269089 lmp.py:380]   Expert 28 |    139 | GPU
DEBUG 01-06 08:45:01.269017.269017 lmp.py:380]   Expert 22 |    140 | GPU
DEBUG 01-06 08:45:01.269945.269945 lmp.py:380]   Expert 25 |    143 | GPU
DEBUG 01-06 08:45:01.269541.269541 lmp.py:380]   Expert 17 |    150 | GPU
DEBUG 01-06 08:45:01.269423.269423 lmp.py:380]   Expert 36 |    152 | GPU
DEBUG 01-06 08:45:01.269304.269304 lmp.py:380]   Expert 19 |    157 | GPU
DEBUG 01-06 08:45:01.269709.269709 lmp.py:380]   Expert 18 |    164 | GPU
DEBUG 01-06 08:45:01.269875.269875 lmp.py:380]   Expert 63 |    169 | GPU
DEBUG 01-06 08:45:01.269803.269803 lmp.py:380]   Expert 53 |    187 | GPU
DEBUG 01-06 08:45:01.269254.269254 lmp.py:380]   Expert 57 |    192 | GPU
DEBUG 01-06 08:45:01.269943.269943 lmp.py:380]   Expert 26 |    212 | GPU
DEBUG 01-06 08:45:01.269394.269394 lmp.py:380]   Expert  2 |    224 | GPU
DEBUG 01-06 08:45:01.269845.269845 lmp.py:380]   Expert 29 |    224 | GPU
DEBUG 01-06 08:45:01.269057.269057 lmp.py:380]   Expert 31 |    231 | GPU
DEBUG 01-06 08:45:01.269508.269508 lmp.py:380]   Expert 60 |    241 | GPU
DEBUG 01-06 08:45:01.269959.269959 lmp.py:380]   Expert 51 |    268 | GPU
DEBUG 01-06 08:45:01.269410.269410 lmp.py:380]   Expert 30 |    315 | GPU
DEBUG 01-06 08:45:01.269576.269576 lmp.py:380]   Expert 24 |    338 | GPU
DEBUG 01-06 08:45:01.269980.269980 lmp.py:380]   Expert 10 |    348 | GPU
DEBUG 01-06 08:45:01.270670.270670 lmp.py:380]   Expert 23 |    356 | GPU
DEBUG 01-06 08:45:01.270074.270074 lmp.py:380]   Expert 16 |    378 | GPU
DEBUG 01-06 08:45:01.270764.270764 lmp.py:380]   Expert  5 |    388 | GPU
DEBUG 01-06 08:45:01.270214.270214 lmp.py:380]   Expert  4 |    456 | GPU
DEBUG 01-06 08:45:01.270904.270904 lmp.py:380]   Expert  1 |    525 | GPU
DEBUG 01-06 08:45:01.270116.270116 lmp.py:380]   Expert  8 |    542 | GPU
DEBUG 01-06 08:45:01.270567.270567 lmp.py:380]   Expert 58 |    613 | GPU
DEBUG 01-06 08:45:01.270256.270256 lmp.py:380]   Expert 42 |    653 | GPU
DEBUG 01-06 08:45:01.270946.270946 lmp.py:380]   Expert 40 |    755 | GPU
DEBUG 01-06 08:45:01.270873.270873 lmp.py:380]   Expert  0 |    904 | GPU
DEBUG 01-06 08:45:01.270563.270563 lmp.py:380]   Expert 33 |   1059 | GPU
DEBUG 01-06 08:45:01.270444.270444 lmp.py:381] 
DEBUG 01-06 08:45:01.270444.270444 lmp.py:381]   CPU total tokens: 1399 (11.4%)
DEBUG 01-06 08:45:01.270802.270802 lmp.py:382]   GPU total tokens: 10889 (88.6%)
DEBUG 01-06 08:45:01.270214.270214 cuda_h.py:19] end experts_map_get cost 0.0015292167663574219 seconds
DEBUG 01-06 08:45:01.270049.270049 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.270547.270547 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.270731.270731 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.270665.270665 cuda_h.py:19] end allocate_cuda_memory cost 0.00019979476928710938 seconds
DEBUG 01-06 08:45:01.270761.270761 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.270947.270947 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.270279.270279 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.270167.270167 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b250b5c-5a3e-40c7-abef-0320f2ec75f6
DEBUG 01-06 08:45:01.271287.271287 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.271267.271267 client.py:127] Model loaded
DEBUG 01-06 08:45:01.271144.271144 cuda_h.py:19] end sllm_worker_task cost 0.012452125549316406 seconds
INFO 01-06 08:45:01.272101.272101 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b250b5c-5a3e-40c7-abef-0320f2ec75f6
DEBUG 01-06 08:45:01.272475.272475 cuda_h.py:19] end load_into_gpu_async cost 0.0015099048614501953 seconds
DEBUG 01-06 08:45:01.272323.272323 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.272842.272842 cuda_h.py:19] end restore_tensors2 cost 0.0004241466522216797 seconds
DEBUG 01-06 08:45:01.272685.272685 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025005340576171875 seconds
DEBUG 01-06 08:45:01.275017.275017 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005144834518432617 seconds
DEBUG 01-06 08:45:01.275561.275561 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.275855.275855 lmp.py:427] 
DEBUG 01-06 08:45:01.275855.275855 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:01.275692.275692 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-06 08:45:01.275554.275554 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.286633.286633 mlpmodule.py:704] group tensors cost 0.010519266128540039 s
DEBUG 01-06 08:45:01.288637.288637 mlpmodule.py:742] pad cost 0.0017075538635253906 s
DEBUG 01-06 08:45:01.288256.288256 mlpmodule.py:748] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-06 08:45:01.288736.288736 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-06 08:45:01.298532.298532 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:01.298538.298538 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.298005.298005 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-06 08:45:01.298082.298082 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.312398.312398 mlpmodule.py:793] group einsum cost 0.02347397804260254 s
DEBUG 01-06 08:45:01.313959.313959 mlpmodule.py:801] cpy2cputensor cost 0.0005195140838623047 s
DEBUG 01-06 08:45:01.318846.318846 cuda_h.py:19] end wait_cetm_experts cost 0.04230475425720215 seconds
DEBUG 01-06 08:45:01.318167.318167 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.318045.318045 cuda_h.py:19] end gpu_sexperts cost 0.0004668235778808594 seconds
DEBUG 01-06 08:45:01.318219.318219 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.318169.318169 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:45:01.318779.318779 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.318727.318727 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b250b5c-5a3e-40c7-abef-0320f2ec75f6
INFO 01-06 08:45:01.327591.327591 client.py:127] Model loaded
DEBUG 01-06 08:45:01.327818.327818 cuda_h.py:19] end wait_experts cost 0.009057044982910156 seconds
DEBUG 01-06 08:45:01.327329.327329 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.327793.327793 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.330007.330007 mlpmodule.py:662]  experts func einsum cost 0.05495023727416992 s
DEBUG 01-06 08:45:01.338614.338614 cuda_h.py:19] end gpu_experts cost 0.010851383209228516 seconds
DEBUG 01-06 08:45:01.338247.338247 cuda_h.py:19] end layer_moe_generate_10 cost 0.07094454765319824 seconds
DEBUG 01-06 08:45:01.339445.339445 lmp.py:221] -------------------------------- end layer 10 --------------------------------
DEBUG 01-06 08:45:01.339691.339691 lmp.py:177] -------------------------------- start layer 11 --------------------------------
DEBUG 01-06 08:45:01.339388.339388 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 08:45:01.339190.339190 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 08:45:01.339218.339218 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:45:01.339775.339775 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.8650970458984375e-05 seconds
DEBUG 01-06 08:45:01.339134.339134 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.339223.339223 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.339941.339941 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.339631.339631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.339555.339555 cuda_h.py:19] end allocate_cuda_memory cost 0.0002601146697998047 seconds
DEBUG 01-06 08:45:01.339902.339902 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.339903.339903 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.339964.339964 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.339190.339190 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff479269-3b97-4c21-b7d1-cb1727b93acc
DEBUG 01-06 08:45:01.340968.340968 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.340976.340976 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
INFO 01-06 08:45:01.342391.342391 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff479269-3b97-4c21-b7d1-cb1727b93acc
DEBUG 01-06 08:45:01.342180.342180 cuda_h.py:19] end load_into_gpu_async cost 0.002346038818359375 seconds
DEBUG 01-06 08:45:01.342214.342214 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.342012.342012 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-06 08:45:01.342007.342007 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029294490814208984 seconds
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
INFO 01-06 08:45:01.342323.342323 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff479269-3b97-4c21-b7d1-cb1727b93acc
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.343624.343624 cuda_h.py:19] end self_attn cost 0.0032567977905273438 seconds
DEBUG 01-06 08:45:01.343773.343773 cuda_h.py:19] end iln_self_attn_paln cost 0.004621028900146484 seconds
DEBUG 01-06 08:45:01.343662.343662 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-06 08:45:01.343332.343332 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.344090.344090 cuda_h.py:19] end gate cost 0.000629425048828125 seconds
DEBUG 01-06 08:45:01.344442.344442 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.345134.345134 lmp.py:369] 
DEBUG 01-06 08:45:01.345134.345134 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.345175.345175 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:01.345540.345540 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:01.345567.345567 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:01.345687.345687 lmp.py:373] 
DEBUG 01-06 08:45:01.345687.345687 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.345807.345807 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.345649.345649 lmp.py:380]   Expert 38 |      1 | CPU
DEBUG 01-06 08:45:01.345007.345007 lmp.py:380]   Expert  0 |      4 | CPU
DEBUG 01-06 08:45:01.345412.345412 lmp.py:380]   Expert 19 |      4 | CPU
DEBUG 01-06 08:45:01.345339.345339 lmp.py:380]   Expert 35 |      5 | CPU
DEBUG 01-06 08:45:01.345790.345790 lmp.py:380]   Expert 49 |      7 | CPU
DEBUG 01-06 08:45:01.345241.345241 lmp.py:380]   Expert 59 |      8 | CPU
DEBUG 01-06 08:45:01.345930.345930 lmp.py:380]   Expert 16 |     16 | CPU
DEBUG 01-06 08:45:01.345527.345527 lmp.py:380]   Expert  4 |     17 | CPU
DEBUG 01-06 08:45:01.345408.345408 lmp.py:380]   Expert  7 |     17 | CPU
DEBUG 01-06 08:45:01.345767.345767 lmp.py:380]   Expert 41 |     17 | CPU
DEBUG 01-06 08:45:01.345886.345886 lmp.py:380]   Expert 15 |     18 | CPU
DEBUG 01-06 08:45:01.345006.345006 lmp.py:380]   Expert 39 |     21 | CPU
DEBUG 01-06 08:45:01.345364.345364 lmp.py:380]   Expert 43 |     22 | CPU
DEBUG 01-06 08:45:01.345769.345769 lmp.py:380]   Expert 62 |     23 | CPU
DEBUG 01-06 08:45:01.345174.345174 lmp.py:380]   Expert  8 |     30 | CPU
DEBUG 01-06 08:45:01.345340.345340 lmp.py:380]   Expert  3 |     37 | CPU
DEBUG 01-06 08:45:01.345506.345506 lmp.py:380]   Expert 23 |     37 | CPU
DEBUG 01-06 08:45:01.345672.345672 lmp.py:380]   Expert 32 |     38 | CPU
DEBUG 01-06 08:45:01.345838.345838 lmp.py:380]   Expert 36 |     43 | CPU
DEBUG 01-06 08:45:01.345243.345243 lmp.py:380]   Expert 46 |     43 | CPU
DEBUG 01-06 08:45:01.345170.345170 lmp.py:380]   Expert  5 |     47 | CPU
DEBUG 01-06 08:45:01.345052.345052 lmp.py:380]   Expert 12 |     47 | CPU
DEBUG 01-06 08:45:01.345933.345933 lmp.py:380]   Expert 57 |     56 | CPU
DEBUG 01-06 08:45:01.345815.345815 lmp.py:380]   Expert 42 |     61 | CPU
DEBUG 01-06 08:45:01.345934.345934 lmp.py:380]   Expert 17 |     62 | CPU
DEBUG 01-06 08:45:01.345339.345339 lmp.py:380]   Expert 25 |     63 | CPU
DEBUG 01-06 08:45:01.345267.345267 lmp.py:380]   Expert 63 |     75 | CPU
DEBUG 01-06 08:45:01.345433.345433 lmp.py:380]   Expert 28 |     81 | CPU
DEBUG 01-06 08:45:01.345122.345122 lmp.py:380]   Expert 10 |     82 | CPU
DEBUG 01-06 08:45:01.345288.345288 lmp.py:380]   Expert 44 |     89 | CPU
DEBUG 01-06 08:45:01.345216.345216 lmp.py:380]   Expert 27 |     93 | CPU
DEBUG 01-06 08:45:01.345382.345382 lmp.py:380]   Expert 52 |     93 | GPU
DEBUG 01-06 08:45:01.345310.345310 lmp.py:380]   Expert 13 |     98 | GPU
DEBUG 01-06 08:45:01.345714.345714 lmp.py:380]   Expert 61 |    100 | GPU
DEBUG 01-06 08:45:01.345596.345596 lmp.py:380]   Expert 20 |    105 | GPU
DEBUG 01-06 08:45:01.345762.345762 lmp.py:380]   Expert 14 |    114 | GPU
DEBUG 01-06 08:45:01.345882.345882 lmp.py:380]   Expert 31 |    116 | GPU
DEBUG 01-06 08:45:01.345763.345763 lmp.py:380]   Expert 40 |    116 | GPU
DEBUG 01-06 08:45:01.345691.345691 lmp.py:380]   Expert 60 |    118 | GPU
DEBUG 01-06 08:45:01.345619.345619 lmp.py:380]   Expert 18 |    125 | GPU
DEBUG 01-06 08:45:01.345546.345546 lmp.py:380]   Expert  2 |    149 | GPU
DEBUG 01-06 08:45:01.345474.345474 lmp.py:380]   Expert 51 |    152 | GPU
DEBUG 01-06 08:45:01.345402.345402 lmp.py:380]   Expert 48 |    171 | GPU
DEBUG 01-06 08:45:01.345091.345091 lmp.py:380]   Expert 29 |    198 | GPU
DEBUG 01-06 08:45:01.345019.345019 lmp.py:380]   Expert 34 |    206 | GPU
DEBUG 01-06 08:45:01.345185.345185 lmp.py:380]   Expert 22 |    245 | GPU
DEBUG 01-06 08:45:01.345066.345066 lmp.py:380]   Expert 55 |    247 | GPU
DEBUG 01-06 08:45:01.345948.345948 lmp.py:380]   Expert 26 |    294 | GPU
DEBUG 01-06 08:45:01.345352.345352 lmp.py:380]   Expert 53 |    294 | GPU
DEBUG 01-06 08:45:01.345234.345234 lmp.py:380]   Expert 21 |    296 | GPU
DEBUG 01-06 08:45:01.346638.346638 lmp.py:380]   Expert 47 |    305 | GPU
DEBUG 01-06 08:45:01.346804.346804 lmp.py:380]   Expert  1 |    336 | GPU
DEBUG 01-06 08:45:01.346732.346732 lmp.py:380]   Expert 50 |    343 | GPU
DEBUG 01-06 08:45:01.346660.346660 lmp.py:380]   Expert 45 |    344 | GPU
DEBUG 01-06 08:45:01.346349.346349 lmp.py:380]   Expert 58 |    354 | GPU
DEBUG 01-06 08:45:01.346800.346800 lmp.py:380]   Expert 54 |    465 | GPU
DEBUG 01-06 08:45:01.346728.346728 lmp.py:380]   Expert  9 |    488 | GPU
DEBUG 01-06 08:45:01.346132.346132 lmp.py:380]   Expert 33 |    531 | GPU
DEBUG 01-06 08:45:01.346775.346775 lmp.py:380]   Expert 56 |    599 | GPU
DEBUG 01-06 08:45:01.346418.346418 lmp.py:380]   Expert 37 |    607 | GPU
DEBUG 01-06 08:45:01.346823.346823 lmp.py:380]   Expert 24 |    759 | GPU
DEBUG 01-06 08:45:01.346750.346750 lmp.py:380]   Expert 11 |   1108 | GPU
DEBUG 01-06 08:45:01.346917.346917 lmp.py:380]   Expert 30 |   1648 | GPU
DEBUG 01-06 08:45:01.346798.346798 lmp.py:381] 
DEBUG 01-06 08:45:01.346798.346798 lmp.py:381]   CPU total tokens: 1164 (9.5%)
DEBUG 01-06 08:45:01.346156.346156 lmp.py:382]   GPU total tokens: 11124 (90.5%)
DEBUG 01-06 08:45:01.346568.346568 cuda_h.py:19] end experts_map_get cost 0.0015385150909423828 seconds
DEBUG 01-06 08:45:01.346687.346687 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.346609.346609 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.346528.346528 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.347144.347144 cuda_h.py:19] end allocate_cuda_memory cost 0.0013322830200195312 seconds
DEBUG 01-06 08:45:01.347325.347325 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.347319.347319 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.347082.347082 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.348685.348685 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4e3c0e18-b40b-4380-b2e7-074aeac7843f
DEBUG 01-06 08:45:01.348990.348990 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.349648.349648 client.py:127] Model loaded
DEBUG 01-06 08:45:01.349505.349505 cuda_h.py:19] end sllm_worker_task cost 0.009932518005371094 seconds
INFO 01-06 08:45:01.350665.350665 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4e3c0e18-b40b-4380-b2e7-074aeac7843f
DEBUG 01-06 08:45:01.350131.350131 cuda_h.py:19] end load_into_gpu_async cost 0.0022809505462646484 seconds
DEBUG 01-06 08:45:01.350264.350264 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.350934.350934 cuda_h.py:19] end restore_tensors2 cost 0.0003962516784667969 seconds
DEBUG 01-06 08:45:01.350485.350485 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004379749298095703 seconds
DEBUG 01-06 08:45:01.353858.353858 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00704503059387207 seconds
DEBUG 01-06 08:45:01.353933.353933 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.353373.353373 lmp.py:427] 
DEBUG 01-06 08:45:01.353373.353373 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:01.353355.353355 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-06 08:45:01.353388.353388 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.365101.365101 mlpmodule.py:704] group tensors cost 0.012029647827148438 s
DEBUG 01-06 08:45:01.367164.367164 mlpmodule.py:742] pad cost 0.0014445781707763672 s
DEBUG 01-06 08:45:01.367691.367691 mlpmodule.py:748] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-06 08:45:01.368441.368441 mlpmodule.py:753] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-06 08:45:01.375466.375466 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:01.376465.376465 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.376223.376223 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-06 08:45:01.376969.376969 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.391280.391280 mlpmodule.py:793] group einsum cost 0.02318549156188965 s
DEBUG 01-06 08:45:01.391449.391449 mlpmodule.py:801] cpy2cputensor cost 0.0004703998565673828 s
DEBUG 01-06 08:45:01.396342.396342 cuda_h.py:19] end wait_cetm_experts cost 0.04307413101196289 seconds
DEBUG 01-06 08:45:01.396802.396802 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.397483.397483 cuda_h.py:19] end gpu_sexperts cost 0.0009152889251708984 seconds
DEBUG 01-06 08:45:01.397333.397333 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.397759.397759 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:45:01.397608.397608 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.397795.397795 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4e3c0e18-b40b-4380-b2e7-074aeac7843f
INFO 01-06 08:45:01.405522.405522 client.py:127] Model loaded
DEBUG 01-06 08:45:01.405080.405080 cuda_h.py:19] end wait_experts cost 0.0073397159576416016 seconds
DEBUG 01-06 08:45:01.405405.405405 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.405453.405453 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.409249.409249 mlpmodule.py:662]  experts func einsum cost 0.0560152530670166 s
DEBUG 01-06 08:45:01.417323.417323 cuda_h.py:19] end gpu_experts cost 0.011939525604248047 seconds
DEBUG 01-06 08:45:01.417519.417519 cuda_h.py:19] end layer_moe_generate_11 cost 0.07341909408569336 seconds
DEBUG 01-06 08:45:01.417248.417248 lmp.py:221] -------------------------------- end layer 11 --------------------------------
DEBUG 01-06 08:45:01.417826.417826 lmp.py:177] -------------------------------- start layer 12 --------------------------------
DEBUG 01-06 08:45:01.417906.417906 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 08:45:01.417139.417139 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 08:45:01.417929.417929 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.7179718017578125e-05 seconds
DEBUG 01-06 08:45:01.417321.417321 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.510185241699219e-05 seconds
DEBUG 01-06 08:45:01.417825.417825 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.417019.417019 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.418593.418593 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.418237.418237 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.418065.418065 cuda_h.py:19] end allocate_cuda_memory cost 0.0001900196075439453 seconds
DEBUG 01-06 08:45:01.418790.418790 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.418884.418884 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.418322.418322 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.418118.418118 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bcb53015-3499-4b96-89c8-1b116fd1a70b
DEBUG 01-06 08:45:01.418558.418558 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.418022.418022 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.419176.419176 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bcb53015-3499-4b96-89c8-1b116fd1a70b
DEBUG 01-06 08:45:01.419535.419535 cuda_h.py:19] end load_into_gpu_async cost 0.0012516975402832031 seconds
DEBUG 01-06 08:45:01.419523.419523 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.419652.419652 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-06 08:45:01.419454.419454 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001760244369506836 seconds
INFO 01-06 08:45:01.420318.420318 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bcb53015-3499-4b96-89c8-1b116fd1a70b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.422604.422604 cuda_h.py:19] end self_attn cost 0.0038313865661621094 seconds
DEBUG 01-06 08:45:01.422222.422222 cuda_h.py:19] end iln_self_attn_paln cost 0.005106925964355469 seconds
DEBUG 01-06 08:45:01.423635.423635 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-06 08:45:01.423398.423398 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.423771.423771 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-06 08:45:01.423454.423454 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.424186.424186 lmp.py:369] 
DEBUG 01-06 08:45:01.424186.424186 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.424512.424512 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:01.424161.424161 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:01.424950.424950 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:01.424831.424831 lmp.py:373] 
DEBUG 01-06 08:45:01.424831.424831 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.424759.424759 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.424932.424932 lmp.py:380]   Expert  4 |      1 | CPU
DEBUG 01-06 08:45:01.424860.424860 lmp.py:380]   Expert 47 |      1 | CPU
DEBUG 01-06 08:45:01.424549.424549 lmp.py:380]   Expert 51 |      1 | CPU
DEBUG 01-06 08:45:01.424238.424238 lmp.py:380]   Expert  0 |      5 | CPU
DEBUG 01-06 08:45:01.424212.424212 lmp.py:380]   Expert 63 |      8 | CPU
DEBUG 01-06 08:45:01.424663.424663 lmp.py:380]   Expert 44 |      9 | CPU
DEBUG 01-06 08:45:01.424114.424114 lmp.py:380]   Expert 11 |     16 | CPU
DEBUG 01-06 08:45:01.424850.424850 lmp.py:380]   Expert 16 |     18 | CPU
DEBUG 01-06 08:45:01.424824.424824 lmp.py:380]   Expert 27 |     22 | CPU
DEBUG 01-06 08:45:01.424798.424798 lmp.py:380]   Expert 13 |     24 | CPU
DEBUG 01-06 08:45:01.424772.424772 lmp.py:380]   Expert 45 |     25 | CPU
DEBUG 01-06 08:45:01.424568.424568 lmp.py:380]   Expert 29 |     26 | CPU
DEBUG 01-06 08:45:01.424231.424231 lmp.py:380]   Expert 34 |     26 | CPU
DEBUG 01-06 08:45:01.424443.424443 lmp.py:380]   Expert  8 |     33 | CPU
DEBUG 01-06 08:45:01.424656.424656 lmp.py:380]   Expert 39 |     37 | CPU
DEBUG 01-06 08:45:01.424630.424630 lmp.py:380]   Expert  6 |     39 | CPU
DEBUG 01-06 08:45:01.424365.424365 lmp.py:380]   Expert 37 |     43 | CPU
DEBUG 01-06 08:45:01.424339.424339 lmp.py:380]   Expert 32 |     44 | CPU
DEBUG 01-06 08:45:01.424314.424314 lmp.py:380]   Expert  2 |     45 | CPU
DEBUG 01-06 08:45:01.424049.424049 lmp.py:380]   Expert 26 |     45 | CPU
DEBUG 01-06 08:45:01.424500.424500 lmp.py:380]   Expert 41 |     50 | CPU
DEBUG 01-06 08:45:01.424997.424997 lmp.py:380]   Expert 43 |     58 | CPU
DEBUG 01-06 08:45:01.424971.424971 lmp.py:380]   Expert 24 |     80 | CPU
DEBUG 01-06 08:45:01.424469.424469 lmp.py:380]   Expert 23 |     84 | CPU
DEBUG 01-06 08:45:01.424681.424681 lmp.py:380]   Expert 38 |     87 | CPU
DEBUG 01-06 08:45:01.424655.424655 lmp.py:380]   Expert  3 |     93 | CPU
DEBUG 01-06 08:45:01.424867.424867 lmp.py:380]   Expert 61 |     95 | CPU
DEBUG 01-06 08:45:01.424080.424080 lmp.py:380]   Expert 55 |     98 | CPU
DEBUG 01-06 08:45:01.424299.424299 lmp.py:380]   Expert 57 |     98 | CPU
DEBUG 01-06 08:45:01.424419.424419 lmp.py:380]   Expert 31 |    103 | CPU
DEBUG 01-06 08:45:01.424824.424824 lmp.py:380]   Expert 49 |    107 | CPU
DEBUG 01-06 08:45:01.424990.424990 lmp.py:380]   Expert 54 |    113 | GPU
DEBUG 01-06 08:45:01.424394.424394 lmp.py:380]   Expert 21 |    114 | GPU
DEBUG 01-06 08:45:01.424322.424322 lmp.py:380]   Expert 53 |    141 | GPU
DEBUG 01-06 08:45:01.424250.424250 lmp.py:380]   Expert 22 |    144 | GPU
DEBUG 01-06 08:45:01.424416.424416 lmp.py:380]   Expert 40 |    149 | GPU
DEBUG 01-06 08:45:01.424582.424582 lmp.py:380]   Expert  7 |    164 | GPU
DEBUG 01-06 08:45:01.424748.424748 lmp.py:380]   Expert 62 |    171 | GPU
DEBUG 01-06 08:45:01.424914.424914 lmp.py:380]   Expert 58 |    187 | GPU
DEBUG 01-06 08:45:01.424080.424080 lmp.py:380]   Expert 56 |    189 | GPU
DEBUG 01-06 08:45:01.424723.424723 lmp.py:380]   Expert 14 |    197 | GPU
DEBUG 01-06 08:45:01.424320.424320 lmp.py:380]   Expert 42 |    201 | GPU
DEBUG 01-06 08:45:01.424155.424155 lmp.py:380]   Expert 20 |    228 | GPU
DEBUG 01-06 08:45:01.424990.424990 lmp.py:380]   Expert 30 |    229 | GPU
DEBUG 01-06 08:45:01.424633.424633 lmp.py:380]   Expert  5 |    240 | GPU
DEBUG 01-06 08:45:01.424561.424561 lmp.py:380]   Expert 19 |    252 | GPU
DEBUG 01-06 08:45:01.425489.425489 lmp.py:380]   Expert 52 |    255 | GPU
DEBUG 01-06 08:45:01.425655.425655 lmp.py:380]   Expert 28 |    285 | GPU
DEBUG 01-06 08:45:01.425059.425059 lmp.py:380]   Expert 10 |    294 | GPU
DEBUG 01-06 08:45:01.425464.425464 lmp.py:380]   Expert 59 |    307 | GPU
DEBUG 01-06 08:45:01.425630.425630 lmp.py:380]   Expert 60 |    312 | GPU
DEBUG 01-06 08:45:01.425796.425796 lmp.py:380]   Expert 35 |    313 | GPU
DEBUG 01-06 08:45:01.425724.425724 lmp.py:380]   Expert 17 |    338 | GPU
DEBUG 01-06 08:45:01.425320.425320 lmp.py:380]   Expert 18 |    341 | GPU
DEBUG 01-06 08:45:01.425679.425679 lmp.py:380]   Expert 46 |    349 | GPU
DEBUG 01-06 08:45:01.425991.425991 lmp.py:380]   Expert  9 |    353 | GPU
DEBUG 01-06 08:45:01.425395.425395 lmp.py:380]   Expert  1 |    405 | GPU
DEBUG 01-06 08:45:01.425084.425084 lmp.py:380]   Expert 50 |    462 | GPU
DEBUG 01-06 08:45:01.425774.425774 lmp.py:380]   Expert 48 |    466 | GPU
DEBUG 01-06 08:45:01.425940.425940 lmp.py:380]   Expert 25 |    711 | GPU
DEBUG 01-06 08:45:01.425868.425868 lmp.py:380]   Expert 15 |    824 | GPU
DEBUG 01-06 08:45:01.425795.425795 lmp.py:380]   Expert 33 |   1032 | GPU
DEBUG 01-06 08:45:01.425961.425961 lmp.py:380]   Expert 36 |   1101 | GPU
DEBUG 01-06 08:45:01.425604.425604 lmp.py:381] 
DEBUG 01-06 08:45:01.425604.425604 lmp.py:381]   CPU total tokens: 1421 (11.6%)
DEBUG 01-06 08:45:01.425486.425486 lmp.py:382]   GPU total tokens: 10867 (88.4%)
DEBUG 01-06 08:45:01.425136.425136 cuda_h.py:19] end experts_map_get cost 0.001527547836303711 seconds
DEBUG 01-06 08:45:01.425971.425971 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.425754.425754 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.425706.425706 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.426186.426186 cuda_h.py:19] end allocate_cuda_memory cost 0.0004608631134033203 seconds
DEBUG 01-06 08:45:01.426711.426711 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.426659.426659 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.426468.426468 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.426549.426549 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f44ed11e-1026-45ec-8984-0bc923dcb873
DEBUG 01-06 08:45:01.426999.426999 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.426283.426283 client.py:127] Model loaded
DEBUG 01-06 08:45:01.426471.426471 cuda_h.py:19] end sllm_worker_task cost 0.00861978530883789 seconds
INFO 01-06 08:45:01.427091.427091 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f44ed11e-1026-45ec-8984-0bc923dcb873
DEBUG 01-06 08:45:01.427126.427126 cuda_h.py:19] end load_into_gpu_async cost 0.00146484375 seconds
DEBUG 01-06 08:45:01.427829.427829 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.428313.428313 cuda_h.py:19] end restore_tensors2 cost 0.00040149688720703125 seconds
DEBUG 01-06 08:45:01.428626.428626 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002690553665161133 seconds
DEBUG 01-06 08:45:01.430886.430886 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005347490310668945 seconds
DEBUG 01-06 08:45:01.430053.430053 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.430752.430752 lmp.py:427] 
DEBUG 01-06 08:45:01.430752.430752 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:01.430972.430972 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-06 08:45:01.430337.430337 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.443119.443119 mlpmodule.py:704] group tensors cost 0.012513399124145508 s
DEBUG 01-06 08:45:01.445608.445608 mlpmodule.py:742] pad cost 0.0014564990997314453 s
DEBUG 01-06 08:45:01.446943.446943 mlpmodule.py:748] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-06 08:45:01.446177.446177 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-06 08:45:01.454603.454603 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:01.454106.454106 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.454242.454242 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-06 08:45:01.454219.454219 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.471465.471465 mlpmodule.py:793] group einsum cost 0.02513408660888672 s
DEBUG 01-06 08:45:01.472384.472384 mlpmodule.py:801] cpy2cputensor cost 0.0005335807800292969 s
DEBUG 01-06 08:45:01.476137.476137 cuda_h.py:19] end wait_cetm_experts cost 0.045981645584106445 seconds
DEBUG 01-06 08:45:01.477550.477550 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.477143.477143 cuda_h.py:19] end gpu_sexperts cost 0.0004658699035644531 seconds
DEBUG 01-06 08:45:01.477987.477987 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.477651.477651 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:45:01.477738.477738 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.477448.477448 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f44ed11e-1026-45ec-8984-0bc923dcb873
INFO 01-06 08:45:01.482388.482388 client.py:127] Model loaded
DEBUG 01-06 08:45:01.482853.482853 cuda_h.py:19] end wait_experts cost 0.004794597625732422 seconds
DEBUG 01-06 08:45:01.482940.482940 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.482696.482696 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.490232.490232 mlpmodule.py:662]  experts func einsum cost 0.05903887748718262 s
DEBUG 01-06 08:45:01.494829.494829 cuda_h.py:19] end gpu_experts cost 0.011854171752929688 seconds
DEBUG 01-06 08:45:01.494534.494534 cuda_h.py:19] end layer_moe_generate_12 cost 0.07152247428894043 seconds
DEBUG 01-06 08:45:01.494156.494156 lmp.py:221] -------------------------------- end layer 12 --------------------------------
DEBUG 01-06 08:45:01.494641.494641 lmp.py:177] -------------------------------- start layer 13 --------------------------------
DEBUG 01-06 08:45:01.494621.494621 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 08:45:01.494947.494947 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 08:45:01.494684.494684 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.6464462280273438e-05 seconds
DEBUG 01-06 08:45:01.494546.494546 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.985664367675781e-05 seconds
DEBUG 01-06 08:45:01.494189.494189 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.495257.495257 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.495081.495081 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.495685.495685 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.495206.495206 cuda_h.py:19] end allocate_cuda_memory cost 0.00027561187744140625 seconds
DEBUG 01-06 08:45:01.495917.495917 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.495534.495534 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.495934.495934 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.495419.495419 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a519a78e-1611-46bd-bfda-fe4567d42b02
DEBUG 01-06 08:45:01.495442.495442 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.496304.496304 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.496066.496066 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a519a78e-1611-46bd-bfda-fe4567d42b02
DEBUG 01-06 08:45:01.496479.496479 cuda_h.py:19] end load_into_gpu_async cost 0.0013287067413330078 seconds
DEBUG 01-06 08:45:01.496420.496420 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.497748.497748 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-06 08:45:01.497173.497173 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019252300262451172 seconds
INFO 01-06 08:45:01.497780.497780 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a519a78e-1611-46bd-bfda-fe4567d42b02
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.500239.500239 cuda_h.py:19] end self_attn cost 0.003909111022949219 seconds
DEBUG 01-06 08:45:01.500288.500288 cuda_h.py:19] end iln_self_attn_paln cost 0.0053098201751708984 seconds
DEBUG 01-06 08:45:01.500986.500986 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-06 08:45:01.500385.500385 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.501579.501579 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-06 08:45:01.501978.501978 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.501439.501439 lmp.py:369] 
DEBUG 01-06 08:45:01.501439.501439 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.501479.501479 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:01.501844.501844 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:01.501872.501872 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:01.501515.501515 lmp.py:373] 
DEBUG 01-06 08:45:01.501515.501515 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.501634.501634 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.501761.501761 lmp.py:380]   Expert  6 |      2 | CPU
DEBUG 01-06 08:45:01.501642.501642 lmp.py:380]   Expert 26 |      3 | CPU
DEBUG 01-06 08:45:01.501061.501061 lmp.py:380]   Expert 19 |      5 | CPU
DEBUG 01-06 08:45:01.501227.501227 lmp.py:380]   Expert 50 |      8 | CPU
DEBUG 01-06 08:45:01.501916.501916 lmp.py:380]   Expert  8 |     12 | CPU
DEBUG 01-06 08:45:01.501367.501367 lmp.py:380]   Expert  2 |     13 | CPU
DEBUG 01-06 08:45:01.501341.501341 lmp.py:380]   Expert 63 |     14 | CPU
DEBUG 01-06 08:45:01.501553.501553 lmp.py:380]   Expert  0 |     15 | CPU
DEBUG 01-06 08:45:01.501004.501004 lmp.py:380]   Expert 12 |     15 | CPU
DEBUG 01-06 08:45:01.501217.501217 lmp.py:380]   Expert 16 |     19 | CPU
DEBUG 01-06 08:45:01.501429.501429 lmp.py:380]   Expert 32 |     21 | CPU
DEBUG 01-06 08:45:01.501642.501642 lmp.py:380]   Expert 40 |     28 | CPU
DEBUG 01-06 08:45:01.501331.501331 lmp.py:380]   Expert 13 |     33 | CPU
DEBUG 01-06 08:45:01.501782.501782 lmp.py:380]   Expert 31 |     60 | CPU
DEBUG 01-06 08:45:01.501471.501471 lmp.py:380]   Expert 20 |     63 | CPU
DEBUG 01-06 08:45:01.501922.501922 lmp.py:380]   Expert 45 |     71 | CPU
DEBUG 01-06 08:45:01.501658.501658 lmp.py:380]   Expert 57 |     79 | CPU
DEBUG 01-06 08:45:01.501393.501393 lmp.py:380]   Expert 52 |     82 | CPU
DEBUG 01-06 08:45:01.501129.501129 lmp.py:380]   Expert  9 |     93 | CPU
DEBUG 01-06 08:45:01.501103.501103 lmp.py:380]   Expert 61 |     98 | CPU
DEBUG 01-06 08:45:01.501839.501839 lmp.py:380]   Expert 28 |     99 | CPU
DEBUG 01-06 08:45:01.501813.501813 lmp.py:380]   Expert 30 |    102 | CPU
DEBUG 01-06 08:45:01.501025.501025 lmp.py:380]   Expert 59 |    102 | CPU
DEBUG 01-06 08:45:01.501999.501999 lmp.py:380]   Expert 58 |    105 | CPU
DEBUG 01-06 08:45:01.501642.501642 lmp.py:380]   Expert 11 |    112 | CPU
DEBUG 01-06 08:45:01.502093.502093 lmp.py:380]   Expert 48 |    117 | CPU
DEBUG 01-06 08:45:01.502021.502021 lmp.py:380]   Expert 60 |    117 | CPU
DEBUG 01-06 08:45:01.502710.502710 lmp.py:380]   Expert  5 |    121 | CPU
DEBUG 01-06 08:45:01.502115.502115 lmp.py:380]   Expert 44 |    121 | CPU
DEBUG 01-06 08:45:01.502281.502281 lmp.py:380]   Expert 42 |    129 | CPU
DEBUG 01-06 08:45:01.502208.502208 lmp.py:380]   Expert  1 |    130 | CPU
DEBUG 01-06 08:45:01.502851.502851 lmp.py:380]   Expert 35 |    140 | GPU
DEBUG 01-06 08:45:01.502541.502541 lmp.py:380]   Expert 36 |    140 | GPU
DEBUG 01-06 08:45:01.502753.502753 lmp.py:380]   Expert  3 |    144 | GPU
DEBUG 01-06 08:45:01.502442.502442 lmp.py:380]   Expert 49 |    146 | GPU
DEBUG 01-06 08:45:01.502893.502893 lmp.py:380]   Expert 62 |    176 | GPU
DEBUG 01-06 08:45:01.502821.502821 lmp.py:380]   Expert 15 |    183 | GPU
DEBUG 01-06 08:45:01.502033.502033 lmp.py:380]   Expert 24 |    184 | GPU
DEBUG 01-06 08:45:01.502961.502961 lmp.py:380]   Expert 25 |    194 | GPU
DEBUG 01-06 08:45:01.502412.502412 lmp.py:380]   Expert 22 |    197 | GPU
DEBUG 01-06 08:45:01.502340.502340 lmp.py:380]   Expert 34 |    199 | GPU
DEBUG 01-06 08:45:01.502983.502983 lmp.py:380]   Expert 18 |    216 | GPU
DEBUG 01-06 08:45:01.502387.502387 lmp.py:380]   Expert 54 |    230 | GPU
DEBUG 01-06 08:45:01.502792.502792 lmp.py:380]   Expert 29 |    245 | GPU
DEBUG 01-06 08:45:01.502958.502958 lmp.py:380]   Expert 43 |    254 | GPU
DEBUG 01-06 08:45:01.502078.502078 lmp.py:380]   Expert  7 |    260 | GPU
DEBUG 01-06 08:45:01.502006.502006 lmp.py:380]   Expert 37 |    272 | GPU
DEBUG 01-06 08:45:01.502933.502933 lmp.py:380]   Expert 51 |    284 | GPU
DEBUG 01-06 08:45:01.502623.502623 lmp.py:380]   Expert 46 |    293 | GPU
DEBUG 01-06 08:45:01.502073.502073 lmp.py:380]   Expert  4 |    299 | GPU
DEBUG 01-06 08:45:01.502763.502763 lmp.py:380]   Expert 10 |    305 | GPU
DEBUG 01-06 08:45:01.502214.502214 lmp.py:380]   Expert 33 |    309 | GPU
DEBUG 01-06 08:45:01.502903.502903 lmp.py:380]   Expert 27 |    333 | GPU
DEBUG 01-06 08:45:01.502115.502115 lmp.py:380]   Expert 41 |    356 | GPU
DEBUG 01-06 08:45:01.502043.502043 lmp.py:380]   Expert 17 |    388 | GPU
DEBUG 01-06 08:45:01.502209.502209 lmp.py:380]   Expert 56 |    424 | GPU
DEBUG 01-06 08:45:01.502614.502614 lmp.py:380]   Expert 39 |    470 | GPU
DEBUG 01-06 08:45:01.502780.502780 lmp.py:380]   Expert 55 |    476 | GPU
DEBUG 01-06 08:45:01.502423.502423 lmp.py:380]   Expert 14 |    501 | GPU
DEBUG 01-06 08:45:01.502112.502112 lmp.py:380]   Expert 47 |    542 | GPU
DEBUG 01-06 08:45:01.502040.502040 lmp.py:380]   Expert 21 |    639 | GPU
DEBUG 01-06 08:45:01.502491.502491 lmp.py:380]   Expert 23 |    712 | GPU
DEBUG 01-06 08:45:01.502942.502942 lmp.py:380]   Expert 38 |    788 | GPU
DEBUG 01-06 08:45:01.502346.502346 lmp.py:381] 
DEBUG 01-06 08:45:01.502346.502346 lmp.py:381]   CPU total tokens: 1989 (16.2%)
DEBUG 01-06 08:45:01.502228.502228 lmp.py:382]   GPU total tokens: 10299 (83.8%)
DEBUG 01-06 08:45:01.502162.502162 cuda_h.py:19] end experts_map_get cost 0.0015120506286621094 seconds
DEBUG 01-06 08:45:01.502805.502805 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.502204.502204 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.502633.502633 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.503889.503889 cuda_h.py:19] end allocate_cuda_memory cost 0.0005054473876953125 seconds
DEBUG 01-06 08:45:01.503468.503468 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.503654.503654 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.503748.503748 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.503590.503590 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2edf519d-7255-4fb9-a53d-9d507fd2ee6a
DEBUG 01-06 08:45:01.503133.503133 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.503052.503052 client.py:127] Model loaded
DEBUG 01-06 08:45:01.503133.503133 cuda_h.py:19] end sllm_worker_task cost 0.008890390396118164 seconds
INFO 01-06 08:45:01.504509.504509 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2edf519d-7255-4fb9-a53d-9d507fd2ee6a
DEBUG 01-06 08:45:01.504782.504782 cuda_h.py:19] end load_into_gpu_async cost 0.0012505054473876953 seconds
DEBUG 01-06 08:45:01.504439.504439 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.505297.505297 cuda_h.py:19] end restore_tensors2 cost 0.00046324729919433594 seconds
DEBUG 01-06 08:45:01.505517.505517 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025949478149414062 seconds
DEBUG 01-06 08:45:01.507510.507510 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005197763442993164 seconds
DEBUG 01-06 08:45:01.507108.507108 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.508309.508309 lmp.py:427] 
DEBUG 01-06 08:45:01.508309.508309 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:01.508576.508576 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-06 08:45:01.508153.508153 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.518122.518122 mlpmodule.py:704] group tensors cost 0.010407686233520508 s
DEBUG 01-06 08:45:01.520860.520860 mlpmodule.py:742] pad cost 0.0014832019805908203 s
DEBUG 01-06 08:45:01.521513.521513 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-06 08:45:01.521170.521170 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 08:45:01.530584.530584 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:01.530306.530306 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.530918.530918 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-06 08:45:01.530850.530850 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.547582.547582 mlpmodule.py:793] group einsum cost 0.02585768699645996 s
DEBUG 01-06 08:45:01.547278.547278 mlpmodule.py:801] cpy2cputensor cost 0.0006151199340820312 s
DEBUG 01-06 08:45:01.552429.552429 cuda_h.py:19] end wait_cetm_experts cost 0.04457259178161621 seconds
DEBUG 01-06 08:45:01.552630.552630 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.554324.554324 cuda_h.py:19] end gpu_sexperts cost 0.0013077259063720703 seconds
DEBUG 01-06 08:45:01.554420.554420 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.554892.554892 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-06 08:45:01.554741.554741 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.554166.554166 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2edf519d-7255-4fb9-a53d-9d507fd2ee6a
INFO 01-06 08:45:01.560396.560396 client.py:127] Model loaded
DEBUG 01-06 08:45:01.560869.560869 cuda_h.py:19] end wait_experts cost 0.006558895111083984 seconds
DEBUG 01-06 08:45:01.560386.560386 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.561142.561142 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.567010.567010 mlpmodule.py:662]  experts func einsum cost 0.05967426300048828 s
DEBUG 01-06 08:45:01.571419.571419 cuda_h.py:19] end gpu_experts cost 0.010838031768798828 seconds
DEBUG 01-06 08:45:01.571131.571131 cuda_h.py:19] end layer_moe_generate_13 cost 0.07155179977416992 seconds
DEBUG 01-06 08:45:01.572290.572290 lmp.py:221] -------------------------------- end layer 13 --------------------------------
DEBUG 01-06 08:45:01.572053.572053 lmp.py:177] -------------------------------- start layer 14 --------------------------------
DEBUG 01-06 08:45:01.572510.572510 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 08:45:01.572074.572074 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 08:45:01.572183.572183 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:45:01.572932.572932 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 8.535385131835938e-05 seconds
DEBUG 01-06 08:45:01.572721.572721 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.572618.572618 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.572574.572574 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.572026.572026 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.572505.572505 cuda_h.py:19] end allocate_cuda_memory cost 0.00021266937255859375 seconds
DEBUG 01-06 08:45:01.572945.572945 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.572277.572277 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.573669.573669 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.573465.573465 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c8e70bba-2905-4ce3-a754-f9ba7ef91605
DEBUG 01-06 08:45:01.573812.573812 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.573959.573959 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.574158.574158 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c8e70bba-2905-4ce3-a754-f9ba7ef91605
DEBUG 01-06 08:45:01.574922.574922 cuda_h.py:19] end load_into_gpu_async cost 0.001283407211303711 seconds
DEBUG 01-06 08:45:01.574672.574672 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.574324.574324 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-06 08:45:01.574557.574557 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018160343170166016 seconds
INFO 01-06 08:45:01.574646.574646 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c8e70bba-2905-4ce3-a754-f9ba7ef91605
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.576830.576830 cuda_h.py:19] end self_attn cost 0.003208637237548828 seconds
DEBUG 01-06 08:45:01.577274.577274 cuda_h.py:19] end iln_self_attn_paln cost 0.00482940673828125 seconds
DEBUG 01-06 08:45:01.577786.577786 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-06 08:45:01.577172.577172 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.578102.578102 cuda_h.py:19] end gate cost 0.0006508827209472656 seconds
DEBUG 01-06 08:45:01.578024.578024 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.578193.578193 lmp.py:369] 
DEBUG 01-06 08:45:01.578193.578193 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.578426.578426 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.578076.578076 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.578865.578865 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.578269.578269 lmp.py:373] 
DEBUG 01-06 08:45:01.578269.578269 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.578389.578389 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.578231.578231 lmp.py:380]   Expert 35 |      2 | CPU
DEBUG 01-06 08:45:01.578874.578874 lmp.py:380]   Expert  7 |      3 | CPU
DEBUG 01-06 08:45:01.578040.578040 lmp.py:380]   Expert 49 |      4 | CPU
DEBUG 01-06 08:45:01.578444.578444 lmp.py:380]   Expert 59 |      7 | CPU
DEBUG 01-06 08:45:01.578611.578611 lmp.py:380]   Expert 61 |     14 | CPU
DEBUG 01-06 08:45:01.578300.578300 lmp.py:380]   Expert 39 |     24 | CPU
DEBUG 01-06 08:45:01.578989.578989 lmp.py:380]   Expert 50 |     33 | CPU
DEBUG 01-06 08:45:01.578155.578155 lmp.py:380]   Expert 31 |     34 | CPU
DEBUG 01-06 08:45:01.578845.578845 lmp.py:380]   Expert 55 |     34 | CPU
DEBUG 01-06 08:45:01.578964.578964 lmp.py:380]   Expert 60 |     34 | CPU
DEBUG 01-06 08:45:01.578654.578654 lmp.py:380]   Expert 18 |     37 | CPU
DEBUG 01-06 08:45:01.578343.578343 lmp.py:380]   Expert 52 |     45 | CPU
DEBUG 01-06 08:45:01.578032.578032 lmp.py:380]   Expert 48 |     47 | CPU
DEBUG 01-06 08:45:01.578960.578960 lmp.py:380]   Expert 38 |     48 | CPU
DEBUG 01-06 08:45:01.578649.578649 lmp.py:380]   Expert 54 |     48 | CPU
DEBUG 01-06 08:45:01.578100.578100 lmp.py:380]   Expert 40 |     50 | CPU
DEBUG 01-06 08:45:01.578028.578028 lmp.py:380]   Expert  0 |     56 | CPU
DEBUG 01-06 08:45:01.578717.578717 lmp.py:380]   Expert 47 |     58 | CPU
DEBUG 01-06 08:45:01.578645.578645 lmp.py:380]   Expert 51 |     64 | CPU
DEBUG 01-06 08:45:01.578334.578334 lmp.py:380]   Expert 34 |     69 | CPU
DEBUG 01-06 08:45:01.578024.578024 lmp.py:380]   Expert 62 |     69 | CPU
DEBUG 01-06 08:45:01.578713.578713 lmp.py:380]   Expert 32 |     84 | CPU
DEBUG 01-06 08:45:01.578594.578594 lmp.py:380]   Expert  8 |     98 | CPU
DEBUG 01-06 08:45:01.578237.578237 lmp.py:380]   Expert 23 |    100 | CPU
DEBUG 01-06 08:45:01.578165.578165 lmp.py:380]   Expert 29 |    115 | CPU
DEBUG 01-06 08:45:01.578616.578616 lmp.py:380]   Expert 17 |    117 | CPU
DEBUG 01-06 08:45:01.578305.578305 lmp.py:380]   Expert 28 |    120 | CPU
DEBUG 01-06 08:45:01.578756.578756 lmp.py:380]   Expert 12 |    132 | CPU
DEBUG 01-06 08:45:01.578445.578445 lmp.py:380]   Expert 21 |    135 | CPU
DEBUG 01-06 08:45:01.578658.578658 lmp.py:380]   Expert 20 |    136 | CPU
DEBUG 01-06 08:45:01.579109.579109 lmp.py:380]   Expert 43 |    144 | CPU
DEBUG 01-06 08:45:01.579036.579036 lmp.py:380]   Expert  6 |    165 | CPU
DEBUG 01-06 08:45:01.579726.579726 lmp.py:380]   Expert 53 |    165 | GPU
DEBUG 01-06 08:45:01.579177.579177 lmp.py:380]   Expert 58 |    175 | GPU
DEBUG 01-06 08:45:01.579820.579820 lmp.py:380]   Expert 16 |    187 | GPU
DEBUG 01-06 08:45:01.579509.579509 lmp.py:380]   Expert 30 |    187 | GPU
DEBUG 01-06 08:45:01.579960.579960 lmp.py:380]   Expert 42 |    201 | GPU
DEBUG 01-06 08:45:01.579411.579411 lmp.py:380]   Expert 57 |    222 | GPU
DEBUG 01-06 08:45:01.579862.579862 lmp.py:380]   Expert 19 |    231 | GPU
DEBUG 01-06 08:45:01.579836.579836 lmp.py:380]   Expert 45 |    235 | GPU
DEBUG 01-06 08:45:01.579286.579286 lmp.py:380]   Expert  1 |    236 | GPU
DEBUG 01-06 08:45:01.579737.579737 lmp.py:380]   Expert 13 |    244 | GPU
DEBUG 01-06 08:45:01.579380.579380 lmp.py:380]   Expert 41 |    244 | GPU
DEBUG 01-06 08:45:01.579546.579546 lmp.py:380]   Expert 33 |    257 | GPU
DEBUG 01-06 08:45:01.579997.579997 lmp.py:380]   Expert 15 |    261 | GPU
DEBUG 01-06 08:45:01.579687.579687 lmp.py:380]   Expert 22 |    271 | GPU
DEBUG 01-06 08:45:01.579138.579138 lmp.py:380]   Expert 26 |    277 | GPU
DEBUG 01-06 08:45:01.579588.579588 lmp.py:380]   Expert 56 |    279 | GPU
DEBUG 01-06 08:45:01.579801.579801 lmp.py:380]   Expert 24 |    309 | GPU
DEBUG 01-06 08:45:01.579252.579252 lmp.py:380]   Expert 27 |    309 | GPU
DEBUG 01-06 08:45:01.579941.579941 lmp.py:380]   Expert  4 |    311 | GPU
DEBUG 01-06 08:45:01.579630.579630 lmp.py:380]   Expert 44 |    311 | GPU
DEBUG 01-06 08:45:01.579843.579843 lmp.py:380]   Expert 11 |    332 | GPU
DEBUG 01-06 08:45:01.579532.579532 lmp.py:380]   Expert  5 |    354 | GPU
DEBUG 01-06 08:45:01.579221.579221 lmp.py:380]   Expert  9 |    377 | GPU
DEBUG 01-06 08:45:01.579864.579864 lmp.py:380]   Expert  3 |    396 | GPU
DEBUG 01-06 08:45:01.579792.579792 lmp.py:380]   Expert 25 |    411 | GPU
DEBUG 01-06 08:45:01.579481.579481 lmp.py:380]   Expert 46 |    417 | GPU
DEBUG 01-06 08:45:01.579694.579694 lmp.py:380]   Expert  2 |    421 | GPU
DEBUG 01-06 08:45:01.579145.579145 lmp.py:380]   Expert 37 |    439 | GPU
DEBUG 01-06 08:45:01.579357.579357 lmp.py:380]   Expert 36 |    450 | GPU
DEBUG 01-06 08:45:01.579047.579047 lmp.py:380]   Expert 63 |    479 | GPU
DEBUG 01-06 08:45:01.579497.579497 lmp.py:380]   Expert 10 |    525 | GPU
DEBUG 01-06 08:45:01.579425.579425 lmp.py:380]   Expert 14 |    649 | GPU
DEBUG 01-06 08:45:01.579783.579783 lmp.py:381] 
DEBUG 01-06 08:45:01.579783.579783 lmp.py:381]   CPU total tokens: 2126 (17.3%)
DEBUG 01-06 08:45:01.579665.579665 lmp.py:382]   GPU total tokens: 10162 (82.7%)
DEBUG 01-06 08:45:01.579361.579361 cuda_h.py:19] end experts_map_get cost 0.0015194416046142578 seconds
DEBUG 01-06 08:45:01.579242.579242 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.579356.579356 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.579739.579739 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.581944.581944 cuda_h.py:19] end allocate_cuda_memory cost 0.0015566349029541016 seconds
DEBUG 01-06 08:45:01.581079.581079 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.581789.581789 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.581598.581598 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.581155.581155 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 51182736-7956-452b-929f-3b06cd9a58a2
DEBUG 01-06 08:45:01.581936.581936 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.582071.582071 client.py:127] Model loaded
DEBUG 01-06 08:45:01.582212.582212 cuda_h.py:19] end sllm_worker_task cost 0.009565353393554688 seconds
INFO 01-06 08:45:01.583296.583296 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 51182736-7956-452b-929f-3b06cd9a58a2
DEBUG 01-06 08:45:01.583106.583106 cuda_h.py:19] end load_into_gpu_async cost 0.0015654563903808594 seconds
DEBUG 01-06 08:45:01.583716.583716 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.583660.583660 cuda_h.py:19] end restore_tensors2 cost 0.00045752525329589844 seconds
DEBUG 01-06 08:45:01.583880.583880 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003943443298339844 seconds
DEBUG 01-06 08:45:01.586768.586768 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006570100784301758 seconds
DEBUG 01-06 08:45:01.586101.586101 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.586111.586111 lmp.py:427] 
DEBUG 01-06 08:45:01.586111.586111 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.586053.586053 cuda_h.py:19] end cpu_experts_submit cost 0.00011157989501953125 seconds
DEBUG 01-06 08:45:01.586631.586631 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.593193.593193 mlpmodule.py:704] group tensors cost 0.00735020637512207 s
DEBUG 01-06 08:45:01.597587.597587 mlpmodule.py:742] pad cost 0.002895832061767578 s
DEBUG 01-06 08:45:01.597432.597432 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-06 08:45:01.597136.597136 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 08:45:01.610856.610856 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:01.610737.610737 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.610826.610826 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-06 08:45:01.610817.610817 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.630383.630383 mlpmodule.py:793] group einsum cost 0.03223085403442383 s
DEBUG 01-06 08:45:01.631316.631316 mlpmodule.py:801] cpy2cputensor cost 0.0007507801055908203 s
DEBUG 01-06 08:45:01.636584.636584 cuda_h.py:19] end wait_cetm_experts cost 0.049604177474975586 seconds
DEBUG 01-06 08:45:01.636501.636501 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.636843.636843 cuda_h.py:19] end gpu_sexperts cost 0.0004885196685791016 seconds
DEBUG 01-06 08:45:01.636117.636117 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.636258.636258 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:45:01.636644.636644 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.636307.636307 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 51182736-7956-452b-929f-3b06cd9a58a2
INFO 01-06 08:45:01.642463.642463 client.py:127] Model loaded
DEBUG 01-06 08:45:01.642458.642458 cuda_h.py:19] end wait_experts cost 0.005307912826538086 seconds
DEBUG 01-06 08:45:01.642420.642420 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.642183.642183 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.645961.645961 mlpmodule.py:662]  experts func einsum cost 0.05878305435180664 s
DEBUG 01-06 08:45:01.653396.653396 cuda_h.py:19] end gpu_experts cost 0.011106014251708984 seconds
DEBUG 01-06 08:45:01.653699.653699 cuda_h.py:19] end layer_moe_generate_14 cost 0.07626891136169434 seconds
DEBUG 01-06 08:45:01.653494.653494 lmp.py:221] -------------------------------- end layer 14 --------------------------------
DEBUG 01-06 08:45:01.653303.653303 lmp.py:177] -------------------------------- start layer 15 --------------------------------
DEBUG 01-06 08:45:01.653807.653807 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 08:45:01.653417.653417 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 08:45:01.653823.653823 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.7418136596679688e-05 seconds
DEBUG 01-06 08:45:01.653592.653592 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.295608520507812e-05 seconds
DEBUG 01-06 08:45:01.654474.654474 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.654337.654337 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.654817.654817 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.654507.654507 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.654537.654537 cuda_h.py:19] end allocate_cuda_memory cost 0.0002677440643310547 seconds
DEBUG 01-06 08:45:01.654123.654123 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.654216.654216 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.654145.654145 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.654802.654802 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e6539b97-99bf-4e5b-92d6-7fb9d46e46a1
DEBUG 01-06 08:45:01.654964.654964 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.655621.655621 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.655800.655800 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e6539b97-99bf-4e5b-92d6-7fb9d46e46a1
DEBUG 01-06 08:45:01.655001.655001 cuda_h.py:19] end load_into_gpu_async cost 0.0012798309326171875 seconds
DEBUG 01-06 08:45:01.655949.655949 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.656244.656244 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-06 08:45:01.656861.656861 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018966197967529297 seconds
INFO 01-06 08:45:01.656600.656600 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e6539b97-99bf-4e5b-92d6-7fb9d46e46a1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.658719.658719 cuda_h.py:19] end self_attn cost 0.0038700103759765625 seconds
DEBUG 01-06 08:45:01.659200.659200 cuda_h.py:19] end iln_self_attn_paln cost 0.0052471160888671875 seconds
DEBUG 01-06 08:45:01.659090.659090 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-06 08:45:01.659521.659521 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.660478.660478 cuda_h.py:19] end gate cost 0.0006358623504638672 seconds
DEBUG 01-06 08:45:01.660592.660592 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.660714.660714 lmp.py:369] 
DEBUG 01-06 08:45:01.660714.660714 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.660067.660067 lmp.py:370]   Total experts: 62
DEBUG 01-06 08:45:01.660624.660624 lmp.py:371]   CPU experts: 31 (50%)
DEBUG 01-06 08:45:01.660128.660128 lmp.py:372]   GPU experts: 31 (50%)
DEBUG 01-06 08:45:01.660533.660533 lmp.py:373] 
DEBUG 01-06 08:45:01.660533.660533 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.660414.660414 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.660494.660494 lmp.py:380]   Expert  5 |      3 | CPU
DEBUG 01-06 08:45:01.660853.660853 lmp.py:380]   Expert 40 |      7 | CPU
DEBUG 01-06 08:45:01.660019.660019 lmp.py:380]   Expert 15 |      8 | CPU
DEBUG 01-06 08:45:01.660946.660946 lmp.py:380]   Expert  4 |     12 | CPU
DEBUG 01-06 08:45:01.660397.660397 lmp.py:380]   Expert 37 |     24 | CPU
DEBUG 01-06 08:45:01.660848.660848 lmp.py:380]   Expert 57 |     27 | CPU
DEBUG 01-06 08:45:01.660061.660061 lmp.py:380]   Expert 35 |     28 | CPU
DEBUG 01-06 08:45:01.660273.660273 lmp.py:380]   Expert  7 |     29 | CPU
DEBUG 01-06 08:45:01.660486.660486 lmp.py:380]   Expert 50 |     30 | CPU
DEBUG 01-06 08:45:01.660175.660175 lmp.py:380]   Expert 48 |     41 | CPU
DEBUG 01-06 08:45:01.660341.660341 lmp.py:380]   Expert 22 |     45 | CPU
DEBUG 01-06 08:45:01.660507.660507 lmp.py:380]   Expert 42 |     50 | CPU
DEBUG 01-06 08:45:01.660673.660673 lmp.py:380]   Expert 54 |     53 | CPU
DEBUG 01-06 08:45:01.660601.660601 lmp.py:380]   Expert 34 |     59 | CPU
DEBUG 01-06 08:45:01.660814.660814 lmp.py:380]   Expert 52 |     59 | CPU
DEBUG 01-06 08:45:01.660264.660264 lmp.py:380]   Expert 12 |     60 | CPU
DEBUG 01-06 08:45:01.660477.660477 lmp.py:380]   Expert 51 |     62 | CPU
DEBUG 01-06 08:45:01.660212.660212 lmp.py:380]   Expert 53 |     63 | CPU
DEBUG 01-06 08:45:01.660425.660425 lmp.py:380]   Expert 39 |     72 | CPU
DEBUG 01-06 08:45:01.660637.660637 lmp.py:380]   Expert  2 |     80 | CPU
DEBUG 01-06 08:45:01.660850.660850 lmp.py:380]   Expert 10 |     83 | CPU
DEBUG 01-06 08:45:01.660062.660062 lmp.py:380]   Expert 43 |     86 | CPU
DEBUG 01-06 08:45:01.660275.660275 lmp.py:380]   Expert 25 |    111 | CPU
DEBUG 01-06 08:45:01.660203.660203 lmp.py:380]   Expert 61 |    119 | CPU
DEBUG 01-06 08:45:01.660130.660130 lmp.py:380]   Expert 45 |    123 | CPU
DEBUG 01-06 08:45:01.660296.660296 lmp.py:380]   Expert 32 |    126 | CPU
DEBUG 01-06 08:45:01.660463.660463 lmp.py:380]   Expert 55 |    126 | CPU
DEBUG 01-06 08:45:01.660582.660582 lmp.py:380]   Expert 58 |    127 | CPU
DEBUG 01-06 08:45:01.661748.661748 lmp.py:380]   Expert 29 |    137 | CPU
DEBUG 01-06 08:45:01.661676.661676 lmp.py:380]   Expert 49 |    141 | CPU
DEBUG 01-06 08:45:01.661842.661842 lmp.py:380]   Expert  0 |    167 | CPU
DEBUG 01-06 08:45:01.661008.661008 lmp.py:380]   Expert 38 |    169 | GPU
DEBUG 01-06 08:45:01.661175.661175 lmp.py:380]   Expert 13 |    176 | GPU
DEBUG 01-06 08:45:01.661341.661341 lmp.py:380]   Expert 56 |    179 | GPU
DEBUG 01-06 08:45:01.661268.661268 lmp.py:380]   Expert 23 |    184 | GPU
DEBUG 01-06 08:45:01.661911.661911 lmp.py:380]   Expert 47 |    201 | GPU
DEBUG 01-06 08:45:01.661793.661793 lmp.py:380]   Expert 33 |    204 | GPU
DEBUG 01-06 08:45:01.661436.661436 lmp.py:380]   Expert 31 |    207 | GPU
DEBUG 01-06 08:45:01.661317.661317 lmp.py:380]   Expert 14 |    210 | GPU
DEBUG 01-06 08:45:01.661483.661483 lmp.py:380]   Expert 20 |    214 | GPU
DEBUG 01-06 08:45:01.661411.661411 lmp.py:380]   Expert 11 |    230 | GPU
DEBUG 01-06 08:45:01.661339.661339 lmp.py:380]   Expert  6 |    240 | GPU
DEBUG 01-06 08:45:01.661266.661266 lmp.py:380]   Expert 28 |    241 | GPU
DEBUG 01-06 08:45:01.661194.661194 lmp.py:380]   Expert 26 |    245 | GPU
DEBUG 01-06 08:45:01.661122.661122 lmp.py:380]   Expert 59 |    247 | GPU
DEBUG 01-06 08:45:01.661811.661811 lmp.py:380]   Expert 30 |    251 | GPU
DEBUG 01-06 08:45:01.661739.661739 lmp.py:380]   Expert  1 |    277 | GPU
DEBUG 01-06 08:45:01.661667.661667 lmp.py:380]   Expert 36 |    280 | GPU
DEBUG 01-06 08:45:01.661310.661310 lmp.py:380]   Expert 44 |    291 | GPU
DEBUG 01-06 08:45:01.661191.661191 lmp.py:380]   Expert  9 |    309 | GPU
DEBUG 01-06 08:45:01.661834.661834 lmp.py:380]   Expert 62 |    316 | GPU
DEBUG 01-06 08:45:01.661715.661715 lmp.py:380]   Expert 17 |    341 | GPU
DEBUG 01-06 08:45:01.661643.661643 lmp.py:380]   Expert 46 |    343 | GPU
DEBUG 01-06 08:45:01.661332.661332 lmp.py:380]   Expert 24 |    371 | GPU
DEBUG 01-06 08:45:01.661260.661260 lmp.py:380]   Expert 19 |    409 | GPU
DEBUG 01-06 08:45:01.661188.661188 lmp.py:380]   Expert  3 |    423 | GPU
DEBUG 01-06 08:45:01.661116.661116 lmp.py:380]   Expert 60 |    453 | GPU
DEBUG 01-06 08:45:01.661043.661043 lmp.py:380]   Expert 18 |    491 | GPU
DEBUG 01-06 08:45:01.661209.661209 lmp.py:380]   Expert  8 |    625 | GPU
DEBUG 01-06 08:45:01.661376.661376 lmp.py:380]   Expert 21 |    627 | GPU
DEBUG 01-06 08:45:01.661826.661826 lmp.py:380]   Expert 16 |    650 | GPU
DEBUG 01-06 08:45:01.661754.661754 lmp.py:380]   Expert 27 |    726 | GPU
DEBUG 01-06 08:45:01.661649.661649 lmp.py:381] 
DEBUG 01-06 08:45:01.661649.661649 lmp.py:381]   CPU total tokens: 2158 (17.6%)
DEBUG 01-06 08:45:01.661438.661438 lmp.py:382]   GPU total tokens: 10130 (82.4%)
DEBUG 01-06 08:45:01.661280.661280 cuda_h.py:19] end experts_map_get cost 0.0015323162078857422 seconds
DEBUG 01-06 08:45:01.661876.661876 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.661514.661514 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.661942.661942 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.662739.662739 cuda_h.py:19] end allocate_cuda_memory cost 0.0004124641418457031 seconds
DEBUG 01-06 08:45:01.662012.662012 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.662199.662199 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.662154.662154 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.662579.662579 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, edf7bcbb-969b-4891-844b-96cbaee05d11
DEBUG 01-06 08:45:01.662982.662982 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.662286.662286 client.py:127] Model loaded
DEBUG 01-06 08:45:01.662142.662142 cuda_h.py:19] end sllm_worker_task cost 0.008737802505493164 seconds
INFO 01-06 08:45:01.663934.663934 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, edf7bcbb-969b-4891-844b-96cbaee05d11
DEBUG 01-06 08:45:01.663684.663684 cuda_h.py:19] end load_into_gpu_async cost 0.0012326240539550781 seconds
DEBUG 01-06 08:45:01.663864.663864 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.664348.664348 cuda_h.py:19] end restore_tensors2 cost 0.0004012584686279297 seconds
DEBUG 01-06 08:45:01.664277.664277 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002400636672973633 seconds
DEBUG 01-06 08:45:01.666984.666984 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004966259002685547 seconds
DEBUG 01-06 08:45:01.666913.666913 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.666684.666684 lmp.py:427] 
DEBUG 01-06 08:45:01.666684.666684 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:01.666527.666527 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-06 08:45:01.666104.666104 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.674334.674334 mlpmodule.py:704] group tensors cost 0.007116079330444336 s
DEBUG 01-06 08:45:01.677592.677592 mlpmodule.py:742] pad cost 0.0025892257690429688 s
DEBUG 01-06 08:45:01.677796.677796 mlpmodule.py:748] create cpu tensor cost 6.031990051269531e-05 s
DEBUG 01-06 08:45:01.677177.677177 mlpmodule.py:753] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-06 08:45:01.687991.687991 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:01.687805.687805 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.687702.687702 mlpmodule.py:773] group_w3 first element: -0.0595703125
WARNING 01-06 08:45:01.688779.688779 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.705577.705577 mlpmodule.py:793] group einsum cost 0.027688264846801758 s
DEBUG 01-06 08:45:01.706794.706794 mlpmodule.py:801] cpy2cputensor cost 0.0007245540618896484 s
DEBUG 01-06 08:45:01.711820.711820 cuda_h.py:19] end wait_cetm_experts cost 0.04426765441894531 seconds
DEBUG 01-06 08:45:01.711783.711783 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.712780.712780 cuda_h.py:19] end gpu_sexperts cost 0.0008654594421386719 seconds
DEBUG 01-06 08:45:01.712584.712584 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.712679.712679 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-06 08:45:01.712051.712051 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.712080.712080 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, edf7bcbb-969b-4891-844b-96cbaee05d11
DEBUG 01-06 08:45:01.719130.719130 mlpmodule.py:662]  experts func einsum cost 0.05245351791381836 s
INFO 01-06 08:45:01.720469.720469 client.py:127] Model loaded
DEBUG 01-06 08:45:01.720856.720856 cuda_h.py:19] end wait_experts cost 0.007735252380371094 seconds
DEBUG 01-06 08:45:01.720850.720850 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.720414.720414 lmp.py:472]   Computing 31 experts on GPU...
DEBUG 01-06 08:45:01.730666.730666 cuda_h.py:19] end gpu_experts cost 0.010080099105834961 seconds
DEBUG 01-06 08:45:01.730590.730590 cuda_h.py:19] end layer_moe_generate_15 cost 0.07108640670776367 seconds
DEBUG 01-06 08:45:01.730795.730795 lmp.py:221] -------------------------------- end layer 15 --------------------------------
DEBUG 01-06 08:45:01.730081.730081 lmp.py:177] -------------------------------- start layer 16 --------------------------------
DEBUG 01-06 08:45:01.730300.730300 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 08:45:01.730626.730626 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 08:45:01.730416.730416 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:45:01.730470.730470 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.462501525878906e-05 seconds
DEBUG 01-06 08:45:01.730590.730590 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.730427.730427 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.731860.731860 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.731266.731266 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.731215.731215 cuda_h.py:19] end allocate_cuda_memory cost 0.0004184246063232422 seconds
DEBUG 01-06 08:45:01.731833.731833 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.731497.731497 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.731842.731842 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.731592.731592 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 66d3be58-f016-4851-b10c-046c837a908f
DEBUG 01-06 08:45:01.731614.731614 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.732286.732286 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.732477.732477 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 66d3be58-f016-4851-b10c-046c837a908f
DEBUG 01-06 08:45:01.732883.732883 cuda_h.py:19] end load_into_gpu_async cost 0.0010564327239990234 seconds
DEBUG 01-06 08:45:01.732632.732632 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.732861.732861 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 08:45:01.732140.732140 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017883777618408203 seconds
INFO 01-06 08:45:01.733838.733838 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 66d3be58-f016-4851-b10c-046c837a908f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.735650.735650 cuda_h.py:19] end self_attn cost 0.003680706024169922 seconds
DEBUG 01-06 08:45:01.736190.736190 cuda_h.py:19] end iln_self_attn_paln cost 0.0052225589752197266 seconds
DEBUG 01-06 08:45:01.736861.736861 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-06 08:45:01.736730.736730 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.736799.736799 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-06 08:45:01.736913.736913 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.737606.737606 lmp.py:369] 
DEBUG 01-06 08:45:01.737606.737606 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.737123.737123 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:01.737250.737250 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:01.737038.737038 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:01.737158.737158 lmp.py:373] 
DEBUG 01-06 08:45:01.737158.737158 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.737040.737040 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.737643.737643 lmp.py:380]   Expert 58 |     21 | CPU
DEBUG 01-06 08:45:01.737763.737763 lmp.py:380]   Expert 43 |     23 | CPU
DEBUG 01-06 08:45:01.737691.737691 lmp.py:380]   Expert 47 |     27 | CPU
DEBUG 01-06 08:45:01.737618.737618 lmp.py:380]   Expert 10 |     34 | CPU
DEBUG 01-06 08:45:01.737308.737308 lmp.py:380]   Expert 60 |     35 | CPU
DEBUG 01-06 08:45:01.737759.737759 lmp.py:380]   Expert 56 |     36 | CPU
DEBUG 01-06 08:45:01.737448.737448 lmp.py:380]   Expert 32 |     44 | CPU
DEBUG 01-06 08:45:01.737614.737614 lmp.py:380]   Expert 62 |     52 | CPU
DEBUG 01-06 08:45:01.737780.737780 lmp.py:380]   Expert 13 |     55 | CPU
DEBUG 01-06 08:45:01.737708.737708 lmp.py:380]   Expert 38 |     56 | CPU
DEBUG 01-06 08:45:01.737920.737920 lmp.py:380]   Expert 63 |     60 | CPU
DEBUG 01-06 08:45:01.737133.737133 lmp.py:380]   Expert 39 |     70 | CPU
DEBUG 01-06 08:45:01.737345.737345 lmp.py:380]   Expert 28 |     73 | CPU
DEBUG 01-06 08:45:01.737319.737319 lmp.py:380]   Expert 50 |     76 | CPU
DEBUG 01-06 08:45:01.737545.737545 lmp.py:380]   Expert 34 |     77 | CPU
DEBUG 01-06 08:45:01.737519.737519 lmp.py:380]   Expert 45 |     77 | CPU
DEBUG 01-06 08:45:01.737255.737255 lmp.py:380]   Expert 49 |     79 | CPU
DEBUG 01-06 08:45:01.737183.737183 lmp.py:380]   Expert 15 |     82 | CPU
DEBUG 01-06 08:45:01.737872.737872 lmp.py:380]   Expert 14 |     85 | CPU
DEBUG 01-06 08:45:01.737323.737323 lmp.py:380]   Expert 25 |     89 | CPU
DEBUG 01-06 08:45:01.737012.737012 lmp.py:380]   Expert 54 |     90 | CPU
DEBUG 01-06 08:45:01.737225.737225 lmp.py:380]   Expert 11 |     97 | CPU
DEBUG 01-06 08:45:01.737437.737437 lmp.py:380]   Expert 44 |     99 | CPU
DEBUG 01-06 08:45:01.737173.737173 lmp.py:380]   Expert 59 |    103 | CPU
DEBUG 01-06 08:45:01.737147.737147 lmp.py:380]   Expert 17 |    104 | CPU
DEBUG 01-06 08:45:01.737121.737121 lmp.py:380]   Expert 35 |    104 | CPU
DEBUG 01-06 08:45:01.737095.737095 lmp.py:380]   Expert  0 |    108 | CPU
DEBUG 01-06 08:45:01.737738.737738 lmp.py:380]   Expert 18 |    112 | CPU
DEBUG 01-06 08:45:01.737666.737666 lmp.py:380]   Expert 46 |    115 | CPU
DEBUG 01-06 08:45:01.737832.737832 lmp.py:380]   Expert 33 |    116 | CPU
DEBUG 01-06 08:45:01.737998.737998 lmp.py:380]   Expert 36 |    117 | CPU
DEBUG 01-06 08:45:01.737402.737402 lmp.py:380]   Expert 31 |    125 | GPU
DEBUG 01-06 08:45:01.737330.737330 lmp.py:380]   Expert 42 |    142 | GPU
DEBUG 01-06 08:45:01.737543.737543 lmp.py:380]   Expert 61 |    143 | GPU
DEBUG 01-06 08:45:01.737232.737232 lmp.py:380]   Expert  2 |    147 | GPU
DEBUG 01-06 08:45:01.737160.737160 lmp.py:380]   Expert 12 |    147 | GPU
DEBUG 01-06 08:45:01.737087.737087 lmp.py:380]   Expert  6 |    153 | GPU
DEBUG 01-06 08:45:01.738015.738015 lmp.py:380]   Expert 30 |    159 | GPU
DEBUG 01-06 08:45:01.738466.738466 lmp.py:380]   Expert 24 |    175 | GPU
DEBUG 01-06 08:45:01.738155.738155 lmp.py:380]   Expert 26 |    181 | GPU
DEBUG 01-06 08:45:01.738083.738083 lmp.py:380]   Expert 21 |    182 | GPU
DEBUG 01-06 08:45:01.738726.738726 lmp.py:380]   Expert 53 |    210 | GPU
DEBUG 01-06 08:45:01.738130.738130 lmp.py:380]   Expert  7 |    220 | GPU
DEBUG 01-06 08:45:01.738773.738773 lmp.py:380]   Expert 20 |    226 | GPU
DEBUG 01-06 08:45:01.738701.738701 lmp.py:380]   Expert 55 |    247 | GPU
DEBUG 01-06 08:45:01.738152.738152 lmp.py:380]   Expert 57 |    255 | GPU
DEBUG 01-06 08:45:01.738841.738841 lmp.py:380]   Expert  4 |    279 | GPU
DEBUG 01-06 08:45:01.738531.738531 lmp.py:380]   Expert 48 |    280 | GPU
DEBUG 01-06 08:45:01.738982.738982 lmp.py:380]   Expert  9 |    302 | GPU
DEBUG 01-06 08:45:01.738671.738671 lmp.py:380]   Expert  1 |    316 | GPU
DEBUG 01-06 08:45:01.738599.738599 lmp.py:380]   Expert 37 |    327 | GPU
DEBUG 01-06 08:45:01.738242.738242 lmp.py:380]   Expert 22 |    368 | GPU
DEBUG 01-06 08:45:01.738884.738884 lmp.py:380]   Expert  3 |    386 | GPU
DEBUG 01-06 08:45:01.738527.738527 lmp.py:380]   Expert 19 |    388 | GPU
DEBUG 01-06 08:45:01.738170.738170 lmp.py:380]   Expert 40 |    389 | GPU
DEBUG 01-06 08:45:01.738860.738860 lmp.py:380]   Expert 51 |    393 | GPU
DEBUG 01-06 08:45:01.738311.738311 lmp.py:380]   Expert 16 |    418 | GPU
DEBUG 01-06 08:45:01.738000.738000 lmp.py:380]   Expert 52 |    443 | GPU
DEBUG 01-06 08:45:01.738166.738166 lmp.py:380]   Expert 29 |    489 | GPU
DEBUG 01-06 08:45:01.738617.738617 lmp.py:380]   Expert  5 |    514 | GPU
DEBUG 01-06 08:45:01.738306.738306 lmp.py:380]   Expert 27 |    583 | GPU
DEBUG 01-06 08:45:01.738996.738996 lmp.py:380]   Expert  8 |    661 | GPU
DEBUG 01-06 08:45:01.738685.738685 lmp.py:380]   Expert 23 |    724 | GPU
DEBUG 01-06 08:45:01.738043.738043 lmp.py:381] 
DEBUG 01-06 08:45:01.738043.738043 lmp.py:381]   CPU total tokens: 2316 (18.8%)
DEBUG 01-06 08:45:01.738640.738640 lmp.py:382]   GPU total tokens: 9972 (81.2%)
DEBUG 01-06 08:45:01.738528.738528 cuda_h.py:19] end experts_map_get cost 0.0015134811401367188 seconds
DEBUG 01-06 08:45:01.738363.738363 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.738954.738954 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.738098.738098 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.739517.739517 cuda_h.py:19] end allocate_cuda_memory cost 0.0012068748474121094 seconds
DEBUG 01-06 08:45:01.740527.740527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.740521.740521 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.740284.740284 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.740841.740841 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c4ea63ef-bf7e-4485-8217-af6ebcee9661
DEBUG 01-06 08:45:01.740622.740622 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.740565.740565 client.py:127] Model loaded
DEBUG 01-06 08:45:01.740660.740660 cuda_h.py:19] end sllm_worker_task cost 0.009649515151977539 seconds
INFO 01-06 08:45:01.741965.741965 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c4ea63ef-bf7e-4485-8217-af6ebcee9661
DEBUG 01-06 08:45:01.741146.741146 cuda_h.py:19] end load_into_gpu_async cost 0.0012657642364501953 seconds
DEBUG 01-06 08:45:01.741518.741518 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.741625.741625 cuda_h.py:19] end restore_tensors2 cost 0.00040411949157714844 seconds
DEBUG 01-06 08:45:01.741461.741461 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032660961151123047 seconds
DEBUG 01-06 08:45:01.744125.744125 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0059051513671875 seconds
DEBUG 01-06 08:45:01.744729.744729 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.744169.744169 lmp.py:427] 
DEBUG 01-06 08:45:01.744169.744169 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:01.744774.744774 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-06 08:45:01.744569.744569 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.755888.755888 mlpmodule.py:704] group tensors cost 0.011152029037475586 s
DEBUG 01-06 08:45:01.759858.759858 mlpmodule.py:742] pad cost 0.002226591110229492 s
DEBUG 01-06 08:45:01.759292.759292 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-06 08:45:01.759711.759711 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-06 08:45:01.767582.767582 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:01.767098.767098 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.767849.767849 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-06 08:45:01.767218.767218 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.781265.781265 mlpmodule.py:793] group einsum cost 0.022591114044189453 s
DEBUG 01-06 08:45:01.782927.782927 mlpmodule.py:801] cpy2cputensor cost 0.0005574226379394531 s
DEBUG 01-06 08:45:01.787349.787349 cuda_h.py:19] end wait_cetm_experts cost 0.04262828826904297 seconds
DEBUG 01-06 08:45:01.787054.787054 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.787038.787038 cuda_h.py:19] end gpu_sexperts cost 0.00047278404235839844 seconds
DEBUG 01-06 08:45:01.788597.788597 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.788977.788977 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:45:01.788110.788110 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.788535.788535 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c4ea63ef-bf7e-4485-8217-af6ebcee9661
DEBUG 01-06 08:45:01.795780.795780 mlpmodule.py:662]  experts func einsum cost 0.050484418869018555 s
INFO 01-06 08:45:01.797680.797680 client.py:127] Model loaded
DEBUG 01-06 08:45:01.797484.797484 cuda_h.py:19] end wait_experts cost 0.008951663970947266 seconds
DEBUG 01-06 08:45:01.797902.797902 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.797366.797366 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.807045.807045 cuda_h.py:19] end gpu_experts cost 0.010780811309814453 seconds
DEBUG 01-06 08:45:01.808407.808407 cuda_h.py:19] end layer_moe_generate_16 cost 0.07185745239257812 seconds
DEBUG 01-06 08:45:01.808321.808321 lmp.py:221] -------------------------------- end layer 16 --------------------------------
DEBUG 01-06 08:45:01.808845.808845 lmp.py:177] -------------------------------- start layer 17 --------------------------------
DEBUG 01-06 08:45:01.808826.808826 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 08:45:01.808390.808390 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 08:45:01.808126.808126 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.7179718017578125e-05 seconds
DEBUG 01-06 08:45:01.808884.808884 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 9.655952453613281e-05 seconds
DEBUG 01-06 08:45:01.808341.808341 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.808827.808827 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.808446.808446 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.808898.808898 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.808252.808252 cuda_h.py:19] end allocate_cuda_memory cost 0.0002617835998535156 seconds
DEBUG 01-06 08:45:01.809148.809148 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.809335.809335 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.809442.809442 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.809953.809953 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8135c3df-268a-463c-aaa8-09b972512110
DEBUG 01-06 08:45:01.809897.809897 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.809190.809190 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.810610.810610 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8135c3df-268a-463c-aaa8-09b972512110
DEBUG 01-06 08:45:01.810745.810745 cuda_h.py:19] end load_into_gpu_async cost 0.0015630722045898438 seconds
DEBUG 01-06 08:45:01.810375.810375 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.810485.810485 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-06 08:45:01.810076.810076 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021851062774658203 seconds
INFO 01-06 08:45:01.811592.811592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8135c3df-268a-463c-aaa8-09b972512110
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.813471.813471 cuda_h.py:19] end self_attn cost 0.003970146179199219 seconds
DEBUG 01-06 08:45:01.814818.814818 cuda_h.py:19] end iln_self_attn_paln cost 0.0056917667388916016 seconds
DEBUG 01-06 08:45:01.814661.814661 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-06 08:45:01.814377.814377 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.814181.814181 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-06 08:45:01.814865.814865 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.815411.815411 lmp.py:369] 
DEBUG 01-06 08:45:01.815411.815411 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.815260.815260 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.815433.815433 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.815983.815983 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.815911.815911 lmp.py:373] 
DEBUG 01-06 08:45:01.815911.815911 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.815554.815554 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.815965.815965 lmp.py:380]   Expert 52 |     19 | CPU
DEBUG 01-06 08:45:01.815131.815131 lmp.py:380]   Expert 47 |     30 | CPU
DEBUG 01-06 08:45:01.815059.815059 lmp.py:380]   Expert 60 |     38 | CPU
DEBUG 01-06 08:45:01.815748.815748 lmp.py:380]   Expert 58 |     44 | CPU
DEBUG 01-06 08:45:01.815961.815961 lmp.py:380]   Expert  8 |     53 | CPU
DEBUG 01-06 08:45:01.815173.815173 lmp.py:380]   Expert 28 |     53 | CPU
DEBUG 01-06 08:45:01.815147.815147 lmp.py:380]   Expert 40 |     57 | CPU
DEBUG 01-06 08:45:01.815598.815598 lmp.py:380]   Expert  1 |     64 | CPU
DEBUG 01-06 08:45:01.815526.815526 lmp.py:380]   Expert  2 |     64 | CPU
DEBUG 01-06 08:45:01.815977.815977 lmp.py:380]   Expert 39 |     65 | CPU
DEBUG 01-06 08:45:01.815904.815904 lmp.py:380]   Expert  7 |     67 | CPU
DEBUG 01-06 08:45:01.815070.815070 lmp.py:380]   Expert 43 |     72 | CPU
DEBUG 01-06 08:45:01.815283.815283 lmp.py:380]   Expert 31 |     79 | CPU
DEBUG 01-06 08:45:01.815257.815257 lmp.py:380]   Expert 36 |     81 | CPU
DEBUG 01-06 08:45:01.815231.815231 lmp.py:380]   Expert 61 |     87 | CPU
DEBUG 01-06 08:45:01.815967.815967 lmp.py:380]   Expert 14 |     91 | CPU
DEBUG 01-06 08:45:01.815702.815702 lmp.py:380]   Expert 29 |     91 | CPU
DEBUG 01-06 08:45:01.815438.815438 lmp.py:380]   Expert 46 |     96 | CPU
DEBUG 01-06 08:45:01.815412.815412 lmp.py:380]   Expert 54 |    104 | CPU
DEBUG 01-06 08:45:01.815909.815909 lmp.py:380]   Expert  6 |    110 | CPU
DEBUG 01-06 08:45:01.815645.815645 lmp.py:380]   Expert 30 |    118 | CPU
DEBUG 01-06 08:45:01.815619.815619 lmp.py:380]   Expert 32 |    118 | CPU
DEBUG 01-06 08:45:01.815116.815116 lmp.py:380]   Expert 50 |    123 | CPU
DEBUG 01-06 08:45:01.815805.815805 lmp.py:380]   Expert  9 |    128 | CPU
DEBUG 01-06 08:45:01.815164.815164 lmp.py:380]   Expert 37 |    128 | CPU
DEBUG 01-06 08:45:01.815568.815568 lmp.py:380]   Expert 25 |    139 | CPU
DEBUG 01-06 08:45:01.815734.815734 lmp.py:380]   Expert 35 |    141 | CPU
DEBUG 01-06 08:45:01.815424.815424 lmp.py:380]   Expert 51 |    147 | CPU
DEBUG 01-06 08:45:01.815113.815113 lmp.py:380]   Expert  0 |    157 | CPU
DEBUG 01-06 08:45:01.815564.815564 lmp.py:380]   Expert  3 |    157 | CPU
DEBUG 01-06 08:45:01.815253.815253 lmp.py:380]   Expert 34 |    164 | CPU
DEBUG 01-06 08:45:01.815942.815942 lmp.py:380]   Expert 24 |    165 | CPU
DEBUG 01-06 08:45:01.815632.815632 lmp.py:380]   Expert 23 |    171 | GPU
DEBUG 01-06 08:45:01.815082.815082 lmp.py:380]   Expert 33 |    174 | GPU
DEBUG 01-06 08:45:01.815772.815772 lmp.py:380]   Expert 56 |    181 | GPU
DEBUG 01-06 08:45:01.816461.816461 lmp.py:380]   Expert 10 |    187 | GPU
DEBUG 01-06 08:45:01.816104.816104 lmp.py:380]   Expert 16 |    196 | GPU
DEBUG 01-06 08:45:01.816509.816509 lmp.py:380]   Expert 63 |    197 | GPU
DEBUG 01-06 08:45:01.816675.816675 lmp.py:380]   Expert  4 |    205 | GPU
DEBUG 01-06 08:45:01.816602.816602 lmp.py:380]   Expert 18 |    224 | GPU
DEBUG 01-06 08:45:01.816292.816292 lmp.py:380]   Expert 20 |    231 | GPU
DEBUG 01-06 08:45:01.816981.816981 lmp.py:380]   Expert 44 |    237 | GPU
DEBUG 01-06 08:45:01.816955.816955 lmp.py:380]   Expert 26 |    245 | GPU
DEBUG 01-06 08:45:01.816168.816168 lmp.py:380]   Expert 53 |    260 | GPU
DEBUG 01-06 08:45:01.816618.816618 lmp.py:380]   Expert 49 |    278 | GPU
DEBUG 01-06 08:45:01.816831.816831 lmp.py:380]   Expert 27 |    279 | GPU
DEBUG 01-06 08:45:01.816520.816520 lmp.py:380]   Expert 48 |    279 | GPU
DEBUG 01-06 08:45:01.816971.816971 lmp.py:380]   Expert 38 |    281 | GPU
DEBUG 01-06 08:45:01.816184.816184 lmp.py:380]   Expert 15 |    285 | GPU
DEBUG 01-06 08:45:01.816065.816065 lmp.py:380]   Expert 11 |    288 | GPU
DEBUG 01-06 08:45:01.816470.816470 lmp.py:380]   Expert 22 |    293 | GPU
DEBUG 01-06 08:45:01.816397.816397 lmp.py:380]   Expert  5 |    297 | GPU
DEBUG 01-06 08:45:01.816563.816563 lmp.py:380]   Expert 12 |    299 | GPU
DEBUG 01-06 08:45:01.816968.816968 lmp.py:380]   Expert 55 |    308 | GPU
DEBUG 01-06 08:45:01.816180.816180 lmp.py:380]   Expert 45 |    326 | GPU
DEBUG 01-06 08:45:01.816631.816631 lmp.py:380]   Expert 59 |    326 | GPU
DEBUG 01-06 08:45:01.816082.816082 lmp.py:380]   Expert 42 |    337 | GPU
DEBUG 01-06 08:45:01.816295.816295 lmp.py:380]   Expert 21 |    361 | GPU
DEBUG 01-06 08:45:01.816613.816613 lmp.py:380]   Expert 41 |    364 | GPU
DEBUG 01-06 08:45:01.816753.816753 lmp.py:380]   Expert 62 |    369 | GPU
DEBUG 01-06 08:45:01.816681.816681 lmp.py:380]   Expert 13 |    378 | GPU
DEBUG 01-06 08:45:01.816086.816086 lmp.py:380]   Expert 57 |    378 | GPU
DEBUG 01-06 08:45:01.816206.816206 lmp.py:380]   Expert 19 |    397 | GPU
DEBUG 01-06 08:45:01.816849.816849 lmp.py:380]   Expert 17 |    607 | GPU
DEBUG 01-06 08:45:01.816684.816684 lmp.py:381] 
DEBUG 01-06 08:45:01.816684.816684 lmp.py:381]   CPU total tokens: 3050 (24.8%)
DEBUG 01-06 08:45:01.816565.816565 lmp.py:382]   GPU total tokens: 9238 (75.2%)
DEBUG 01-06 08:45:01.816215.816215 cuda_h.py:19] end experts_map_get cost 0.0015299320220947266 seconds
DEBUG 01-06 08:45:01.816527.816527 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.816879.816879 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.816030.816030 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.817109.817109 cuda_h.py:19] end allocate_cuda_memory cost 0.0003387928009033203 seconds
DEBUG 01-06 08:45:01.817442.817442 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.817106.817106 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.817723.817723 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.817803.817803 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7740de91-a6ef-4cef-a152-13c0891d9f1d
DEBUG 01-06 08:45:01.817683.817683 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.817405.817405 client.py:127] Model loaded
DEBUG 01-06 08:45:01.817261.817261 cuda_h.py:19] end sllm_worker_task cost 0.009134292602539062 seconds
INFO 01-06 08:45:01.819660.819660 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7740de91-a6ef-4cef-a152-13c0891d9f1d
DEBUG 01-06 08:45:01.819411.819411 cuda_h.py:19] end load_into_gpu_async cost 0.0021889209747314453 seconds
DEBUG 01-06 08:45:01.819782.819782 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.819227.819227 cuda_h.py:19] end restore_tensors2 cost 0.0004062652587890625 seconds
DEBUG 01-06 08:45:01.819348.819348 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033063888549804688 seconds
DEBUG 01-06 08:45:01.822946.822946 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005966663360595703 seconds
DEBUG 01-06 08:45:01.822789.822789 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.822229.822229 lmp.py:427] 
DEBUG 01-06 08:45:01.822229.822229 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.822211.822211 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 08:45:01.822530.822530 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.834836.834836 mlpmodule.py:704] group tensors cost 0.011965513229370117 s
DEBUG 01-06 08:45:01.838761.838761 mlpmodule.py:742] pad cost 0.0024728775024414062 s
DEBUG 01-06 08:45:01.838817.838817 mlpmodule.py:748] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-06 08:45:01.838396.838396 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-06 08:45:01.849062.849062 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:01.849968.849968 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.849958.849958 mlpmodule.py:773] group_w3 first element: -0.047119140625
WARNING 01-06 08:45:01.849367.849367 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.869628.869628 mlpmodule.py:793] group einsum cost 0.030768156051635742 s
DEBUG 01-06 08:45:01.870545.870545 mlpmodule.py:801] cpy2cputensor cost 0.0006885528564453125 s
DEBUG 01-06 08:45:01.875601.875601 cuda_h.py:19] end wait_cetm_experts cost 0.05232524871826172 seconds
DEBUG 01-06 08:45:01.875471.875471 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.875038.875038 cuda_h.py:19] end gpu_sexperts cost 0.00048065185546875 seconds
DEBUG 01-06 08:45:01.875166.875166 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.875592.875592 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-06 08:45:01.875249.875249 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.875435.875435 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7740de91-a6ef-4cef-a152-13c0891d9f1d
INFO 01-06 08:45:01.878985.878985 client.py:127] Model loaded
DEBUG 01-06 08:45:01.878450.878450 cuda_h.py:19] end wait_experts cost 0.0022242069244384766 seconds
DEBUG 01-06 08:45:01.878537.878537 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.878055.878055 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.883223.883223 mlpmodule.py:662]  experts func einsum cost 0.0605168342590332 s
DEBUG 01-06 08:45:01.889296.889296 cuda_h.py:19] end gpu_experts cost 0.010950326919555664 seconds
DEBUG 01-06 08:45:01.889246.889246 cuda_h.py:19] end layer_moe_generate_17 cost 0.0750114917755127 seconds
DEBUG 01-06 08:45:01.889127.889127 lmp.py:221] -------------------------------- end layer 17 --------------------------------
DEBUG 01-06 08:45:01.889512.889512 lmp.py:177] -------------------------------- start layer 18 --------------------------------
DEBUG 01-06 08:45:01.889162.889162 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 08:45:01.889918.889918 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 08:45:01.889543.889543 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.8160552978515625e-05 seconds
DEBUG 01-06 08:45:01.889836.889836 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 9.298324584960938e-05 seconds
DEBUG 01-06 08:45:01.889956.889956 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.889209.889209 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.889165.889165 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.889809.889809 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.890072.890072 cuda_h.py:19] end allocate_cuda_memory cost 0.0002999305725097656 seconds
DEBUG 01-06 08:45:01.890592.890592 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.890355.890355 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.890032.890032 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.890258.890258 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb3fc49f-f284-4476-ba4d-63d2fc74b613
DEBUG 01-06 08:45:01.890989.890989 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.890767.890767 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.891400.891400 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb3fc49f-f284-4476-ba4d-63d2fc74b613
DEBUG 01-06 08:45:01.891283.891283 cuda_h.py:19] end load_into_gpu_async cost 0.001596689224243164 seconds
DEBUG 01-06 08:45:01.891793.891793 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.892691.892691 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-06 08:45:01.892493.892493 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022444725036621094 seconds
INFO 01-06 08:45:01.892675.892675 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb3fc49f-f284-4476-ba4d-63d2fc74b613
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.894042.894042 cuda_h.py:19] end self_attn cost 0.0037899017333984375 seconds
DEBUG 01-06 08:45:01.894727.894727 cuda_h.py:19] end iln_self_attn_paln cost 0.005209684371948242 seconds
DEBUG 01-06 08:45:01.895663.895663 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-06 08:45:01.895903.895903 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.895757.895757 cuda_h.py:19] end gate cost 0.0007717609405517578 seconds
DEBUG 01-06 08:45:01.895633.895633 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.896332.896332 lmp.py:369] 
DEBUG 01-06 08:45:01.896332.896332 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.896565.896565 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.896692.896692 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.896719.896719 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.896792.896792 lmp.py:373] 
DEBUG 01-06 08:45:01.896792.896792 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.896104.896104 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.896423.896423 lmp.py:380]   Expert 30 |      5 | CPU
DEBUG 01-06 08:45:01.896496.896496 lmp.py:380]   Expert 58 |      6 | CPU
DEBUG 01-06 08:45:01.896868.896868 lmp.py:380]   Expert  3 |     21 | CPU
DEBUG 01-06 08:45:01.896942.896942 lmp.py:380]   Expert 37 |     25 | CPU
DEBUG 01-06 08:45:01.896823.896823 lmp.py:380]   Expert  0 |     33 | CPU
DEBUG 01-06 08:45:01.896228.896228 lmp.py:380]   Expert 52 |     33 | CPU
DEBUG 01-06 08:45:01.896917.896917 lmp.py:380]   Expert 43 |     37 | CPU
DEBUG 01-06 08:45:01.896560.896560 lmp.py:380]   Expert 40 |     41 | CPU
DEBUG 01-06 08:45:01.896964.896964 lmp.py:380]   Expert 54 |     42 | CPU
DEBUG 01-06 08:45:01.896369.896369 lmp.py:380]   Expert  8 |     44 | CPU
DEBUG 01-06 08:45:01.896535.896535 lmp.py:380]   Expert 12 |     49 | CPU
DEBUG 01-06 08:45:01.896178.896178 lmp.py:380]   Expert 34 |     53 | CPU
DEBUG 01-06 08:45:01.896536.896536 lmp.py:380]   Expert 35 |     55 | CPU
DEBUG 01-06 08:45:01.896656.896656 lmp.py:380]   Expert 19 |     60 | CPU
DEBUG 01-06 08:45:01.896491.896491 lmp.py:380]   Expert 53 |     65 | CPU
DEBUG 01-06 08:45:01.896611.896611 lmp.py:380]   Expert 20 |     68 | CPU
DEBUG 01-06 08:45:01.896254.896254 lmp.py:380]   Expert 41 |     75 | CPU
DEBUG 01-06 08:45:01.896420.896420 lmp.py:380]   Expert 63 |     79 | CPU
DEBUG 01-06 08:45:01.896586.896586 lmp.py:380]   Expert 48 |     87 | CPU
DEBUG 01-06 08:45:01.896991.896991 lmp.py:380]   Expert 25 |     89 | CPU
DEBUG 01-06 08:45:01.896395.896395 lmp.py:380]   Expert 11 |     91 | CPU
DEBUG 01-06 08:45:01.896561.896561 lmp.py:380]   Expert 60 |     93 | CPU
DEBUG 01-06 08:45:01.896966.896966 lmp.py:380]   Expert 56 |     97 | CPU
DEBUG 01-06 08:45:01.896371.896371 lmp.py:380]   Expert  1 |     98 | CPU
DEBUG 01-06 08:45:01.896014.896014 lmp.py:380]   Expert  7 |     99 | CPU
DEBUG 01-06 08:45:01.896895.896895 lmp.py:380]   Expert  4 |    114 | CPU
DEBUG 01-06 08:45:01.896492.896492 lmp.py:380]   Expert 32 |    116 | CPU
DEBUG 01-06 08:45:01.896611.896611 lmp.py:380]   Expert 22 |    119 | CPU
DEBUG 01-06 08:45:01.896254.896254 lmp.py:380]   Expert 33 |    121 | CPU
DEBUG 01-06 08:45:01.896136.896136 lmp.py:380]   Expert 46 |    126 | CPU
DEBUG 01-06 08:45:01.896779.896779 lmp.py:380]   Expert 13 |    128 | CPU
DEBUG 01-06 08:45:01.896422.896422 lmp.py:380]   Expert 27 |    132 | CPU
DEBUG 01-06 08:45:01.896588.896588 lmp.py:380]   Expert  6 |    140 | GPU
DEBUG 01-06 08:45:01.896754.896754 lmp.py:380]   Expert  5 |    151 | GPU
DEBUG 01-06 08:45:01.896920.896920 lmp.py:380]   Expert 29 |    155 | GPU
DEBUG 01-06 08:45:01.896086.896086 lmp.py:380]   Expert  9 |    162 | GPU
DEBUG 01-06 08:45:01.896491.896491 lmp.py:380]   Expert 42 |    162 | GPU
DEBUG 01-06 08:45:01.897657.897657 lmp.py:380]   Expert 45 |    168 | GPU
DEBUG 01-06 08:45:01.897300.897300 lmp.py:380]   Expert 39 |    174 | GPU
DEBUG 01-06 08:45:01.897181.897181 lmp.py:380]   Expert 16 |    183 | GPU
DEBUG 01-06 08:45:01.897824.897824 lmp.py:380]   Expert 21 |    216 | GPU
DEBUG 01-06 08:45:01.897990.897990 lmp.py:380]   Expert 18 |    218 | GPU
DEBUG 01-06 08:45:01.897395.897395 lmp.py:380]   Expert 50 |    225 | GPU
DEBUG 01-06 08:45:01.897561.897561 lmp.py:380]   Expert 10 |    227 | GPU
DEBUG 01-06 08:45:01.897489.897489 lmp.py:380]   Expert 51 |    228 | GPU
DEBUG 01-06 08:45:01.897417.897417 lmp.py:380]   Expert 24 |    229 | GPU
DEBUG 01-06 08:45:01.897583.897583 lmp.py:380]   Expert 61 |    243 | GPU
DEBUG 01-06 08:45:01.897703.897703 lmp.py:380]   Expert 59 |    245 | GPU
DEBUG 01-06 08:45:01.897345.897345 lmp.py:380]   Expert 15 |    247 | GPU
DEBUG 01-06 08:45:01.897512.897512 lmp.py:380]   Expert 28 |    256 | GPU
DEBUG 01-06 08:45:01.897201.897201 lmp.py:380]   Expert 17 |    261 | GPU
DEBUG 01-06 08:45:01.897605.897605 lmp.py:380]   Expert 36 |    275 | GPU
DEBUG 01-06 08:45:01.897533.897533 lmp.py:380]   Expert 55 |    276 | GPU
DEBUG 01-06 08:45:01.897699.897699 lmp.py:380]   Expert 38 |    290 | GPU
DEBUG 01-06 08:45:01.897627.897627 lmp.py:380]   Expert 44 |    291 | GPU
DEBUG 01-06 08:45:01.897793.897793 lmp.py:380]   Expert 26 |    307 | GPU
DEBUG 01-06 08:45:01.897436.897436 lmp.py:380]   Expert 31 |    342 | GPU
DEBUG 01-06 08:45:01.897841.897841 lmp.py:380]   Expert 14 |    357 | GPU
DEBUG 01-06 08:45:01.897245.897245 lmp.py:380]   Expert 57 |    385 | GPU
DEBUG 01-06 08:45:01.897173.897173 lmp.py:380]   Expert 47 |    389 | GPU
DEBUG 01-06 08:45:01.897101.897101 lmp.py:380]   Expert 49 |    631 | GPU
DEBUG 01-06 08:45:01.897267.897267 lmp.py:380]   Expert  2 |    657 | GPU
DEBUG 01-06 08:45:01.897195.897195 lmp.py:380]   Expert 23 |    843 | GPU
DEBUG 01-06 08:45:01.897838.897838 lmp.py:380]   Expert 62 |   1054 | GPU
DEBUG 01-06 08:45:01.897196.897196 lmp.py:381] 
DEBUG 01-06 08:45:01.897196.897196 lmp.py:381]   CPU total tokens: 2301 (18.7%)
DEBUG 01-06 08:45:01.897316.897316 lmp.py:382]   GPU total tokens: 9987 (81.3%)
DEBUG 01-06 08:45:01.897919.897919 cuda_h.py:19] end experts_map_get cost 0.0015871524810791016 seconds
DEBUG 01-06 08:45:01.897277.897277 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.897491.897491 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.897065.897065 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.898483.898483 cuda_h.py:19] end allocate_cuda_memory cost 0.0007648468017578125 seconds
DEBUG 01-06 08:45:01.898233.898233 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.898181.898181 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.898375.898375 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.898693.898693 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 84458b07-1493-4426-aaa4-4cd3ceadf1c5
DEBUG 01-06 08:45:01.898958.898958 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.899708.899708 client.py:127] Model loaded
DEBUG 01-06 08:45:01.899451.899451 cuda_h.py:19] end sllm_worker_task cost 0.009343862533569336 seconds
INFO 01-06 08:45:01.900671.900671 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 84458b07-1493-4426-aaa4-4cd3ceadf1c5
DEBUG 01-06 08:45:01.900944.900944 cuda_h.py:19] end load_into_gpu_async cost 0.002210378646850586 seconds
DEBUG 01-06 08:45:01.900647.900647 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.901847.901847 cuda_h.py:19] end restore_tensors2 cost 0.00040149688720703125 seconds
DEBUG 01-06 08:45:01.901206.901206 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037343502044677734 seconds
DEBUG 01-06 08:45:01.903511.903511 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006360054016113281 seconds
DEBUG 01-06 08:45:01.903917.903917 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.904509.904509 lmp.py:427] 
DEBUG 01-06 08:45:01.904509.904509 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.904637.904637 cuda_h.py:19] end cpu_experts_submit cost 0.0001163482666015625 seconds
DEBUG 01-06 08:45:01.904453.904453 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.910220.910220 mlpmodule.py:704] group tensors cost 0.0059719085693359375 s
DEBUG 01-06 08:45:01.912263.912263 mlpmodule.py:742] pad cost 0.001710653305053711 s
DEBUG 01-06 08:45:01.912345.912345 mlpmodule.py:748] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-06 08:45:01.912288.912288 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 08:45:01.923392.923392 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:01.923398.923398 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:01.923057.923057 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-06 08:45:01.924565.924565 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:01.942760.942760 mlpmodule.py:793] group einsum cost 0.029238462448120117 s
DEBUG 01-06 08:45:01.943422.943422 mlpmodule.py:801] cpy2cputensor cost 0.0005927085876464844 s
DEBUG 01-06 08:45:01.947208.947208 cuda_h.py:19] end wait_cetm_experts cost 0.04366445541381836 seconds
DEBUG 01-06 08:45:01.947078.947078 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:01.949413.949413 cuda_h.py:19] end gpu_sexperts cost 0.0012538433074951172 seconds
DEBUG 01-06 08:45:01.949263.949263 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:01.949404.949404 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-06 08:45:01.949253.949253 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:01.949678.949678 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 84458b07-1493-4426-aaa4-4cd3ceadf1c5
DEBUG 01-06 08:45:01.955349.955349 mlpmodule.py:662]  experts func einsum cost 0.05155181884765625 s
INFO 01-06 08:45:01.959253.959253 client.py:127] Model loaded
DEBUG 01-06 08:45:01.959626.959626 cuda_h.py:19] end wait_experts cost 0.010532855987548828 seconds
DEBUG 01-06 08:45:01.960614.960614 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:01.960469.960469 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:01.970571.970571 cuda_h.py:19] end gpu_experts cost 0.010143518447875977 seconds
DEBUG 01-06 08:45:01.970952.970952 cuda_h.py:19] end layer_moe_generate_18 cost 0.07524919509887695 seconds
DEBUG 01-06 08:45:01.970124.970124 lmp.py:221] -------------------------------- end layer 18 --------------------------------
DEBUG 01-06 08:45:01.970702.970702 lmp.py:177] -------------------------------- start layer 19 --------------------------------
DEBUG 01-06 08:45:01.970305.970305 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 08:45:01.970253.970253 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 08:45:01.970281.970281 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.8133392333984375e-05 seconds
DEBUG 01-06 08:45:01.970958.970958 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.510185241699219e-05 seconds
DEBUG 01-06 08:45:01.970224.970224 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:01.970007.970007 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:01.970315.970315 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.970151.970151 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.971232.971232 cuda_h.py:19] end allocate_cuda_memory cost 0.0002002716064453125 seconds
DEBUG 01-06 08:45:01.971798.971798 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.971514.971514 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.971430.971430 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.971464.971464 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20447df4-af6b-4f15-be92-e885528a9aeb
DEBUG 01-06 08:45:01.971718.971718 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:01.971635.971635 cuda_h.py:10] start self_attn
INFO 01-06 08:45:01.972753.972753 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20447df4-af6b-4f15-be92-e885528a9aeb
DEBUG 01-06 08:45:01.972205.972205 cuda_h.py:19] end load_into_gpu_async cost 0.0010356903076171875 seconds
DEBUG 01-06 08:45:01.972477.972477 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.972342.972342 cuda_h.py:19] end restore_tensors2 cost 8.320808410644531e-05 seconds
DEBUG 01-06 08:45:01.972243.972243 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015990734100341797 seconds
INFO 01-06 08:45:01.973790.973790 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20447df4-af6b-4f15-be92-e885528a9aeb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:01.975672.975672 cuda_h.py:19] end self_attn cost 0.004001617431640625 seconds
DEBUG 01-06 08:45:01.976337.976337 cuda_h.py:19] end iln_self_attn_paln cost 0.005318880081176758 seconds
DEBUG 01-06 08:45:01.976273.976273 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-06 08:45:01.976035.976035 cuda_h.py:10] start gate
DEBUG 01-06 08:45:01.976205.976205 cuda_h.py:19] end gate cost 0.0006883144378662109 seconds
DEBUG 01-06 08:45:01.976558.976558 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:01.977403.977403 lmp.py:369] 
DEBUG 01-06 08:45:01.977403.977403 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:01.977682.977682 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:01.977047.977047 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:01.977312.977312 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:01.977478.977478 lmp.py:373] 
DEBUG 01-06 08:45:01.977478.977478 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:01.977121.977121 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:01.977771.977771 lmp.py:380]   Expert 27 |     14 | CPU
DEBUG 01-06 08:45:01.977653.977653 lmp.py:380]   Expert 59 |     22 | CPU
DEBUG 01-06 08:45:01.977342.977342 lmp.py:380]   Expert 56 |     25 | CPU
DEBUG 01-06 08:45:01.977508.977508 lmp.py:380]   Expert 42 |     33 | CPU
DEBUG 01-06 08:45:01.977674.977674 lmp.py:380]   Expert 48 |     39 | CPU
DEBUG 01-06 08:45:01.977363.977363 lmp.py:380]   Expert  0 |     43 | CPU
DEBUG 01-06 08:45:01.977814.977814 lmp.py:380]   Expert 12 |     46 | CPU
DEBUG 01-06 08:45:01.977027.977027 lmp.py:380]   Expert 16 |     49 | CPU
DEBUG 01-06 08:45:01.977478.977478 lmp.py:380]   Expert 26 |     54 | CPU
DEBUG 01-06 08:45:01.977167.977167 lmp.py:380]   Expert 55 |     67 | CPU
DEBUG 01-06 08:45:01.977810.977810 lmp.py:380]   Expert  6 |     68 | CPU
DEBUG 01-06 08:45:01.977738.977738 lmp.py:380]   Expert 44 |     68 | CPU
DEBUG 01-06 08:45:01.977189.977189 lmp.py:380]   Expert 60 |     72 | CPU
DEBUG 01-06 08:45:01.977785.977785 lmp.py:380]   Expert 33 |     80 | CPU
DEBUG 01-06 08:45:01.977190.977190 lmp.py:380]   Expert 23 |     91 | CPU
DEBUG 01-06 08:45:01.977356.977356 lmp.py:380]   Expert 30 |     92 | CPU
DEBUG 01-06 08:45:01.977536.977536 lmp.py:380]   Expert 62 |     97 | CPU
DEBUG 01-06 08:45:01.977702.977702 lmp.py:380]   Expert 54 |     99 | CPU
DEBUG 01-06 08:45:01.977868.977868 lmp.py:380]   Expert 58 |    104 | CPU
DEBUG 01-06 08:45:01.977988.977988 lmp.py:380]   Expert 34 |    107 | CPU
DEBUG 01-06 08:45:01.977915.977915 lmp.py:380]   Expert  5 |    110 | CPU
DEBUG 01-06 08:45:01.977843.977843 lmp.py:380]   Expert  1 |    113 | CPU
DEBUG 01-06 08:45:01.977294.977294 lmp.py:380]   Expert 19 |    113 | CPU
DEBUG 01-06 08:45:01.977983.977983 lmp.py:380]   Expert 18 |    124 | CPU
DEBUG 01-06 08:45:01.977673.977673 lmp.py:380]   Expert 24 |    127 | CPU
DEBUG 01-06 08:45:01.977362.977362 lmp.py:380]   Expert 13 |    128 | CPU
DEBUG 01-06 08:45:01.977051.977051 lmp.py:380]   Expert 17 |    130 | CPU
DEBUG 01-06 08:45:01.977456.977456 lmp.py:380]   Expert 39 |    134 | CPU
DEBUG 01-06 08:45:01.977622.977622 lmp.py:380]   Expert 46 |    146 | CPU
DEBUG 01-06 08:45:01.977073.977073 lmp.py:380]   Expert 14 |    147 | CPU
DEBUG 01-06 08:45:01.977762.977762 lmp.py:380]   Expert 22 |    156 | CPU
DEBUG 01-06 08:45:01.977451.977451 lmp.py:380]   Expert  3 |    158 | CPU
DEBUG 01-06 08:45:01.977141.977141 lmp.py:380]   Expert 15 |    161 | GPU
DEBUG 01-06 08:45:01.977830.977830 lmp.py:380]   Expert 29 |    169 | GPU
DEBUG 01-06 08:45:01.977043.977043 lmp.py:380]   Expert 41 |    169 | GPU
DEBUG 01-06 08:45:01.977401.977401 lmp.py:380]   Expert 57 |    170 | GPU
DEBUG 01-06 08:45:01.977044.977044 lmp.py:380]   Expert 49 |    182 | GPU
DEBUG 01-06 08:45:01.977733.977733 lmp.py:380]   Expert 43 |    184 | GPU
DEBUG 01-06 08:45:01.978422.978422 lmp.py:380]   Expert 63 |    186 | GPU
DEBUG 01-06 08:45:01.978112.978112 lmp.py:380]   Expert 40 |    187 | GPU
DEBUG 01-06 08:45:01.978801.978801 lmp.py:380]   Expert 28 |    189 | GPU
DEBUG 01-06 08:45:01.978729.978729 lmp.py:380]   Expert 25 |    190 | GPU
DEBUG 01-06 08:45:01.978418.978418 lmp.py:380]   Expert  4 |    203 | GPU
DEBUG 01-06 08:45:01.978869.978869 lmp.py:380]   Expert 51 |    206 | GPU
DEBUG 01-06 08:45:01.978558.978558 lmp.py:380]   Expert 31 |    223 | GPU
DEBUG 01-06 08:45:01.978963.978963 lmp.py:380]   Expert 50 |    224 | GPU
DEBUG 01-06 08:45:01.978652.978652 lmp.py:380]   Expert 32 |    228 | GPU
DEBUG 01-06 08:45:01.978341.978341 lmp.py:380]   Expert  8 |    229 | GPU
DEBUG 01-06 08:45:01.978554.978554 lmp.py:380]   Expert 53 |    248 | GPU
DEBUG 01-06 08:45:01.978766.978766 lmp.py:380]   Expert 38 |    249 | GPU
DEBUG 01-06 08:45:01.978456.978456 lmp.py:380]   Expert 37 |    263 | GPU
DEBUG 01-06 08:45:01.978906.978906 lmp.py:380]   Expert 52 |    265 | GPU
DEBUG 01-06 08:45:01.978357.978357 lmp.py:380]   Expert 36 |    298 | GPU
DEBUG 01-06 08:45:01.978285.978285 lmp.py:380]   Expert 61 |    327 | GPU
DEBUG 01-06 08:45:01.978974.978974 lmp.py:380]   Expert 11 |    331 | GPU
DEBUG 01-06 08:45:01.978617.978617 lmp.py:380]   Expert 47 |    357 | GPU
DEBUG 01-06 08:45:01.978545.978545 lmp.py:380]   Expert 20 |    376 | GPU
DEBUG 01-06 08:45:01.978996.978996 lmp.py:380]   Expert 10 |    397 | GPU
DEBUG 01-06 08:45:01.978208.978208 lmp.py:380]   Expert 21 |    399 | GPU
DEBUG 01-06 08:45:01.978898.978898 lmp.py:380]   Expert 35 |    423 | GPU
DEBUG 01-06 08:45:01.978587.978587 lmp.py:380]   Expert  9 |    459 | GPU
DEBUG 01-06 08:45:01.978276.978276 lmp.py:380]   Expert  2 |    484 | GPU
DEBUG 01-06 08:45:01.978919.978919 lmp.py:380]   Expert  7 |    715 | GPU
DEBUG 01-06 08:45:01.978324.978324 lmp.py:380]   Expert 45 |    741 | GPU
DEBUG 01-06 08:45:01.978967.978967 lmp.py:381] 
DEBUG 01-06 08:45:01.978967.978967 lmp.py:381]   CPU total tokens: 2856 (23.2%)
DEBUG 01-06 08:45:01.978610.978610 lmp.py:382]   GPU total tokens: 9432 (76.8%)
DEBUG 01-06 08:45:01.978366.978366 cuda_h.py:19] end experts_map_get cost 0.0015406608581542969 seconds
DEBUG 01-06 08:45:01.978439.978439 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:01.978507.978507 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:01.978459.978459 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:01.978493.978493 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-06 08:45:01.979621.979621 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:01.979662.979662 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:01.979471.979471 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:01.979074.979074 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 04a1eba4-a685-470c-8204-98b7d934e8f5
DEBUG 01-06 08:45:01.979717.979717 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:01.979016.979016 client.py:127] Model loaded
DEBUG 01-06 08:45:01.979966.979966 cuda_h.py:19] end sllm_worker_task cost 0.008768081665039062 seconds
INFO 01-06 08:45:01.980873.980873 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 04a1eba4-a685-470c-8204-98b7d934e8f5
DEBUG 01-06 08:45:01.980100.980100 cuda_h.py:19] end load_into_gpu_async cost 0.0012333393096923828 seconds
DEBUG 01-06 08:45:01.980949.980949 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:01.980744.980744 cuda_h.py:19] end restore_tensors2 cost 0.0003833770751953125 seconds
DEBUG 01-06 08:45:01.980581.980581 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002172708511352539 seconds
DEBUG 01-06 08:45:01.983018.983018 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004784822463989258 seconds
DEBUG 01-06 08:45:01.983643.983643 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:01.983129.983129 lmp.py:427] 
DEBUG 01-06 08:45:01.983129.983129 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:01.983826.983826 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 08:45:01.983429.983429 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:01.990631.990631 mlpmodule.py:704] group tensors cost 0.0072591304779052734 s
DEBUG 01-06 08:45:01.993027.993027 mlpmodule.py:742] pad cost 0.0020415782928466797 s
DEBUG 01-06 08:45:01.994316.994316 mlpmodule.py:748] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 08:45:01.994305.994305 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-06 08:45:02.006095.006095 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:02.006684.006684 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.006681.006681 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-06 08:45:02.006911.006911 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.027411.027411 mlpmodule.py:793] group einsum cost 0.03297090530395508 s
DEBUG 01-06 08:45:02.028879.028879 mlpmodule.py:801] cpy2cputensor cost 0.0006968975067138672 s
DEBUG 01-06 08:45:02.032300.032300 cuda_h.py:19] end wait_cetm_experts cost 0.04929804801940918 seconds
DEBUG 01-06 08:45:02.032978.032978 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.034831.034831 cuda_h.py:19] end gpu_sexperts cost 0.0012848377227783203 seconds
DEBUG 01-06 08:45:02.034012.034012 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.034723.034723 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 08:45:02.034379.034379 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.034526.034526 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 04a1eba4-a685-470c-8204-98b7d934e8f5
INFO 01-06 08:45:02.039296.039296 client.py:127] Model loaded
DEBUG 01-06 08:45:02.039768.039768 cuda_h.py:19] end wait_experts cost 0.0050601959228515625 seconds
DEBUG 01-06 08:45:02.039809.039809 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.039088.039088 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.041698.041698 mlpmodule.py:662]  experts func einsum cost 0.05754399299621582 s
DEBUG 01-06 08:45:02.050197.050197 cuda_h.py:19] end gpu_experts cost 0.010747909545898438 seconds
DEBUG 01-06 08:45:02.050545.050545 cuda_h.py:19] end layer_moe_generate_19 cost 0.07436037063598633 seconds
DEBUG 01-06 08:45:02.050717.050717 lmp.py:221] -------------------------------- end layer 19 --------------------------------
DEBUG 01-06 08:45:02.050195.050195 lmp.py:177] -------------------------------- start layer 20 --------------------------------
DEBUG 01-06 08:45:02.050176.050176 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 08:45:02.050501.050501 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 08:45:02.050477.050477 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.6702880859375e-05 seconds
DEBUG 01-06 08:45:02.050054.050054 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.104873657226562e-05 seconds
DEBUG 01-06 08:45:02.050936.050936 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.050719.050719 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.051913.051913 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.051173.051173 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.051402.051402 cuda_h.py:19] end allocate_cuda_memory cost 0.0002751350402832031 seconds
DEBUG 01-06 08:45:02.051492.051492 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.051314.051314 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.051137.051137 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.051409.051409 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a535c3e7-faa4-4dc9-80fb-9e16ae65abd2
DEBUG 01-06 08:45:02.051002.051002 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.051070.051070 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.052707.052707 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a535c3e7-faa4-4dc9-80fb-9e16ae65abd2
DEBUG 01-06 08:45:02.052385.052385 cuda_h.py:19] end load_into_gpu_async cost 0.0013232231140136719 seconds
DEBUG 01-06 08:45:02.052909.052909 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.052760.052760 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-06 08:45:02.053755.053755 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001958131790161133 seconds
INFO 01-06 08:45:02.053701.053701 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a535c3e7-faa4-4dc9-80fb-9e16ae65abd2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.055515.055515 cuda_h.py:19] end self_attn cost 0.003513336181640625 seconds
DEBUG 01-06 08:45:02.055471.055471 cuda_h.py:19] end iln_self_attn_paln cost 0.004895448684692383 seconds
DEBUG 01-06 08:45:02.055407.055407 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-06 08:45:02.055362.055362 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.056471.056471 cuda_h.py:19] end gate cost 0.0006422996520996094 seconds
DEBUG 01-06 08:45:02.056823.056823 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.056668.056668 lmp.py:369] 
DEBUG 01-06 08:45:02.056668.056668 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.056901.056901 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:02.057743.057743 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:02.057008.057008 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:02.057843.057843 lmp.py:373] 
DEBUG 01-06 08:45:02.057843.057843 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.057917.057917 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.057474.057474 lmp.py:380]   Expert 36 |      4 | CPU
DEBUG 01-06 08:45:02.057071.057071 lmp.py:380]   Expert 54 |      8 | CPU
DEBUG 01-06 08:45:02.057952.057952 lmp.py:380]   Expert 13 |     20 | CPU
DEBUG 01-06 08:45:02.057357.057357 lmp.py:380]   Expert 39 |     22 | CPU
DEBUG 01-06 08:45:02.057761.057761 lmp.py:380]   Expert  8 |     23 | CPU
DEBUG 01-06 08:45:02.057166.057166 lmp.py:380]   Expert  6 |     26 | CPU
DEBUG 01-06 08:45:02.057570.057570 lmp.py:380]   Expert  4 |     43 | CPU
DEBUG 01-06 08:45:02.057167.057167 lmp.py:380]   Expert 38 |     46 | CPU
DEBUG 01-06 08:45:02.057525.057525 lmp.py:380]   Expert 12 |     48 | CPU
DEBUG 01-06 08:45:02.057645.057645 lmp.py:380]   Expert 42 |     50 | CPU
DEBUG 01-06 08:45:02.057288.057288 lmp.py:380]   Expert 46 |     55 | CPU
DEBUG 01-06 08:45:02.057454.057454 lmp.py:380]   Expert 28 |     56 | CPU
DEBUG 01-06 08:45:02.057620.057620 lmp.py:380]   Expert 50 |     72 | CPU
DEBUG 01-06 08:45:02.057548.057548 lmp.py:380]   Expert 57 |     77 | CPU
DEBUG 01-06 08:45:02.057476.057476 lmp.py:380]   Expert  1 |     78 | CPU
DEBUG 01-06 08:45:02.057403.057403 lmp.py:380]   Expert 11 |     83 | CPU
DEBUG 01-06 08:45:02.057331.057331 lmp.py:380]   Expert 52 |     89 | CPU
DEBUG 01-06 08:45:02.057259.057259 lmp.py:380]   Expert 20 |     94 | CPU
DEBUG 01-06 08:45:02.057902.057902 lmp.py:380]   Expert 33 |     94 | CPU
DEBUG 01-06 08:45:02.057260.057260 lmp.py:380]   Expert 61 |     95 | CPU
DEBUG 01-06 08:45:02.057380.057380 lmp.py:380]   Expert  7 |     96 | CPU
DEBUG 01-06 08:45:02.057023.057023 lmp.py:380]   Expert  3 |     97 | CPU
DEBUG 01-06 08:45:02.057189.057189 lmp.py:380]   Expert 24 |    109 | CPU
DEBUG 01-06 08:45:02.057355.057355 lmp.py:380]   Expert  9 |    113 | CPU
DEBUG 01-06 08:45:02.057521.057521 lmp.py:380]   Expert 49 |    114 | CPU
DEBUG 01-06 08:45:02.057687.057687 lmp.py:380]   Expert 17 |    116 | CPU
DEBUG 01-06 08:45:02.057377.057377 lmp.py:380]   Expert 22 |    128 | CPU
DEBUG 01-06 08:45:02.057066.057066 lmp.py:380]   Expert 19 |    133 | CPU
DEBUG 01-06 08:45:02.057232.057232 lmp.py:380]   Expert 29 |    137 | CPU
DEBUG 01-06 08:45:02.057114.057114 lmp.py:380]   Expert 18 |    139 | CPU
DEBUG 01-06 08:45:02.057756.057756 lmp.py:380]   Expert 51 |    144 | CPU
DEBUG 01-06 08:45:02.057128.057128 lmp.py:380]   Expert 23 |    156 | CPU
DEBUG 01-06 08:45:02.057533.057533 lmp.py:380]   Expert 30 |    163 | GPU
DEBUG 01-06 08:45:02.057984.057984 lmp.py:380]   Expert 10 |    168 | GPU
DEBUG 01-06 08:45:02.057911.057911 lmp.py:380]   Expert 21 |    176 | GPU
DEBUG 01-06 08:45:02.057124.057124 lmp.py:380]   Expert 43 |    179 | GPU
DEBUG 01-06 08:45:02.057575.057575 lmp.py:380]   Expert 41 |    181 | GPU
DEBUG 01-06 08:45:02.057787.057787 lmp.py:380]   Expert 31 |    193 | GPU
DEBUG 01-06 08:45:02.057238.057238 lmp.py:380]   Expert 63 |    202 | GPU
DEBUG 01-06 08:45:02.057881.057881 lmp.py:380]   Expert  5 |    203 | GPU
DEBUG 01-06 08:45:02.057047.057047 lmp.py:380]   Expert 14 |    206 | GPU
DEBUG 01-06 08:45:02.057975.057975 lmp.py:380]   Expert 44 |    212 | GPU
DEBUG 01-06 08:45:02.057141.057141 lmp.py:380]   Expert  0 |    221 | GPU
DEBUG 01-06 08:45:02.057830.057830 lmp.py:380]   Expert 32 |    224 | GPU
DEBUG 01-06 08:45:02.057804.057804 lmp.py:380]   Expert 58 |    236 | GPU
DEBUG 01-06 08:45:02.057255.057255 lmp.py:380]   Expert 48 |    238 | GPU
DEBUG 01-06 08:45:02.057945.057945 lmp.py:380]   Expert 16 |    245 | GPU
DEBUG 01-06 08:45:02.057396.057396 lmp.py:380]   Expert 47 |    254 | GPU
DEBUG 01-06 08:45:02.057039.057039 lmp.py:380]   Expert 34 |    260 | GPU
DEBUG 01-06 08:45:02.057443.057443 lmp.py:380]   Expert 37 |    268 | GPU
DEBUG 01-06 08:45:02.057609.057609 lmp.py:380]   Expert 62 |    270 | GPU
DEBUG 01-06 08:45:02.057014.057014 lmp.py:380]   Expert 55 |    276 | GPU
DEBUG 01-06 08:45:02.057226.057226 lmp.py:380]   Expert 26 |    280 | GPU
DEBUG 01-06 08:45:02.058916.058916 lmp.py:380]   Expert 27 |    281 | GPU
DEBUG 01-06 08:45:02.058605.058605 lmp.py:380]   Expert 60 |    296 | GPU
DEBUG 01-06 08:45:02.058817.058817 lmp.py:380]   Expert 56 |    309 | GPU
DEBUG 01-06 08:45:02.058030.058030 lmp.py:380]   Expert 59 |    321 | GPU
DEBUG 01-06 08:45:02.058719.058719 lmp.py:380]   Expert 53 |    357 | GPU
DEBUG 01-06 08:45:02.058932.058932 lmp.py:380]   Expert 15 |    374 | GPU
DEBUG 01-06 08:45:02.058859.058859 lmp.py:380]   Expert 40 |    382 | GPU
DEBUG 01-06 08:45:02.058025.058025 lmp.py:380]   Expert 25 |    398 | GPU
DEBUG 01-06 08:45:02.058430.058430 lmp.py:380]   Expert 45 |    448 | GPU
DEBUG 01-06 08:45:02.058834.058834 lmp.py:380]   Expert  2 |    667 | GPU
DEBUG 01-06 08:45:02.058285.058285 lmp.py:380]   Expert 35 |   1235 | GPU
DEBUG 01-06 08:45:02.058451.058451 lmp.py:381] 
DEBUG 01-06 08:45:02.058451.058451 lmp.py:381]   CPU total tokens: 2565 (20.9%)
DEBUG 01-06 08:45:02.058618.058618 lmp.py:382]   GPU total tokens: 9723 (79.1%)
DEBUG 01-06 08:45:02.058552.058552 cuda_h.py:19] end experts_map_get cost 0.0015625953674316406 seconds
DEBUG 01-06 08:45:02.058195.058195 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.058309.058309 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.058076.058076 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.059352.059352 cuda_h.py:19] end allocate_cuda_memory cost 0.0015041828155517578 seconds
DEBUG 01-06 08:45:02.060864.060864 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.060144.060144 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.060237.060237 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.060033.060033 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 75e378c3-7404-4f11-981f-bfdb8abb48b9
DEBUG 01-06 08:45:02.060775.060775 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.060763.060763 client.py:127] Model loaded
DEBUG 01-06 08:45:02.060950.060950 cuda_h.py:19] end sllm_worker_task cost 0.009614706039428711 seconds
INFO 01-06 08:45:02.061506.061506 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 75e378c3-7404-4f11-981f-bfdb8abb48b9
DEBUG 01-06 08:45:02.061687.061687 cuda_h.py:19] end load_into_gpu_async cost 0.0013799667358398438 seconds
DEBUG 01-06 08:45:02.061058.061058 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.061867.061867 cuda_h.py:19] end restore_tensors2 cost 0.0003943443298339844 seconds
DEBUG 01-06 08:45:02.061942.061942 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036385059356689453 seconds
DEBUG 01-06 08:45:02.064811.064811 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006290435791015625 seconds
DEBUG 01-06 08:45:02.064223.064223 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.064424.064424 lmp.py:427] 
DEBUG 01-06 08:45:02.064424.064424 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:02.064268.064268 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-06 08:45:02.064871.064871 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.076732.076732 mlpmodule.py:704] group tensors cost 0.01192331314086914 s
DEBUG 01-06 08:45:02.079309.079309 mlpmodule.py:742] pad cost 0.0014722347259521484 s
DEBUG 01-06 08:45:02.079292.079292 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-06 08:45:02.079758.079758 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 08:45:02.090598.090598 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:02.091088.091088 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.091416.091416 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-06 08:45:02.091499.091499 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.109701.109701 mlpmodule.py:793] group einsum cost 0.030078411102294922 s
DEBUG 01-06 08:45:02.110757.110757 mlpmodule.py:801] cpy2cputensor cost 0.0006678104400634766 s
DEBUG 01-06 08:45:02.115382.115382 cuda_h.py:19] end wait_cetm_experts cost 0.05022764205932617 seconds
DEBUG 01-06 08:45:02.115060.115060 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.116422.116422 cuda_h.py:19] end gpu_sexperts cost 0.0012755393981933594 seconds
DEBUG 01-06 08:45:02.116034.116034 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.116937.116937 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-06 08:45:02.116070.116070 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.116455.116455 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 75e378c3-7404-4f11-981f-bfdb8abb48b9
INFO 01-06 08:45:02.120093.120093 client.py:127] Model loaded
DEBUG 01-06 08:45:02.120513.120513 cuda_h.py:19] end wait_experts cost 0.004080533981323242 seconds
DEBUG 01-06 08:45:02.120315.120315 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.120309.120309 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.123571.123571 mlpmodule.py:662]  experts func einsum cost 0.05855894088745117 s
DEBUG 01-06 08:45:02.131562.131562 cuda_h.py:19] end gpu_experts cost 0.010710716247558594 seconds
DEBUG 01-06 08:45:02.131163.131163 cuda_h.py:19] end layer_moe_generate_20 cost 0.07573413848876953 seconds
DEBUG 01-06 08:45:02.131937.131937 lmp.py:221] -------------------------------- end layer 20 --------------------------------
DEBUG 01-06 08:45:02.131653.131653 lmp.py:177] -------------------------------- start layer 21 --------------------------------
DEBUG 01-06 08:45:02.131350.131350 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 08:45:02.131913.131913 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 08:45:02.131034.131034 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.765655517578125e-05 seconds
DEBUG 01-06 08:45:02.132068.132068 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 5.793571472167969e-05 seconds
DEBUG 01-06 08:45:02.132188.132188 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.132813.132813 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.132352.132352 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.132804.132804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.132258.132258 cuda_h.py:19] end allocate_cuda_memory cost 0.00026488304138183594 seconds
DEBUG 01-06 08:45:02.132513.132513 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.132560.132560 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.132304.132304 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.132484.132484 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80454340-0eae-481c-bff0-8995a3584b8a
DEBUG 01-06 08:45:02.132976.132976 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.133712.133712 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.134274.134274 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80454340-0eae-481c-bff0-8995a3584b8a
DEBUG 01-06 08:45:02.134872.134872 cuda_h.py:19] end load_into_gpu_async cost 0.0015978813171386719 seconds
DEBUG 01-06 08:45:02.134429.134429 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.134326.134326 cuda_h.py:19] end restore_tensors2 cost 7.367134094238281e-05 seconds
DEBUG 01-06 08:45:02.134321.134321 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021910667419433594 seconds
INFO 01-06 08:45:02.134166.134166 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80454340-0eae-481c-bff0-8995a3584b8a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.136001.136001 cuda_h.py:19] end self_attn cost 0.0037980079650878906 seconds
DEBUG 01-06 08:45:02.137626.137626 cuda_h.py:19] end iln_self_attn_paln cost 0.0051403045654296875 seconds
DEBUG 01-06 08:45:02.137900.137900 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-06 08:45:02.137524.137524 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.138617.138617 cuda_h.py:19] end gate cost 0.0007717609405517578 seconds
DEBUG 01-06 08:45:02.138254.138254 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.138370.138370 lmp.py:369] 
DEBUG 01-06 08:45:02.138370.138370 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.138080.138080 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:02.138875.138875 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:02.138856.138856 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:02.138214.138214 lmp.py:373] 
DEBUG 01-06 08:45:02.138214.138214 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.138573.138573 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.138653.138653 lmp.py:380]   Expert 56 |      9 | CPU
DEBUG 01-06 08:45:02.138011.138011 lmp.py:380]   Expert 60 |      9 | CPU
DEBUG 01-06 08:45:02.138369.138369 lmp.py:380]   Expert 53 |     10 | CPU
DEBUG 01-06 08:45:02.138774.138774 lmp.py:380]   Expert  7 |     16 | CPU
DEBUG 01-06 08:45:02.138417.138417 lmp.py:380]   Expert 47 |     25 | CPU
DEBUG 01-06 08:45:02.138821.138821 lmp.py:380]   Expert  1 |     28 | CPU
DEBUG 01-06 08:45:02.138226.138226 lmp.py:380]   Expert  6 |     35 | CPU
DEBUG 01-06 08:45:02.138630.138630 lmp.py:380]   Expert 44 |     38 | CPU
DEBUG 01-06 08:45:02.138797.138797 lmp.py:380]   Expert 51 |     38 | CPU
DEBUG 01-06 08:45:02.138963.138963 lmp.py:380]   Expert 12 |     55 | CPU
DEBUG 01-06 08:45:02.138129.138129 lmp.py:380]   Expert 26 |     56 | CPU
DEBUG 01-06 08:45:02.138057.138057 lmp.py:380]   Expert 19 |     68 | CPU
DEBUG 01-06 08:45:02.138984.138984 lmp.py:380]   Expert 20 |     75 | CPU
DEBUG 01-06 08:45:02.138150.138150 lmp.py:380]   Expert 15 |     77 | CPU
DEBUG 01-06 08:45:02.138555.138555 lmp.py:380]   Expert 35 |     77 | CPU
DEBUG 01-06 08:45:02.138721.138721 lmp.py:380]   Expert  3 |     78 | CPU
DEBUG 01-06 08:45:02.138649.138649 lmp.py:380]   Expert 33 |     96 | CPU
DEBUG 01-06 08:45:02.138338.138338 lmp.py:380]   Expert 48 |     97 | CPU
DEBUG 01-06 08:45:02.138027.138027 lmp.py:380]   Expert 49 |     97 | CPU
DEBUG 01-06 08:45:02.138955.138955 lmp.py:380]   Expert 59 |    106 | CPU
DEBUG 01-06 08:45:02.138883.138883 lmp.py:380]   Expert  8 |    108 | CPU
DEBUG 01-06 08:45:02.138095.138095 lmp.py:380]   Expert 23 |    110 | CPU
DEBUG 01-06 08:45:02.138023.138023 lmp.py:380]   Expert  9 |    114 | CPU
DEBUG 01-06 08:45:02.138189.138189 lmp.py:380]   Expert 61 |    116 | CPU
DEBUG 01-06 08:45:02.138879.138879 lmp.py:380]   Expert 25 |    121 | CPU
DEBUG 01-06 08:45:02.139806.139806 lmp.py:380]   Expert 52 |    124 | CPU
DEBUG 01-06 08:45:02.139688.139688 lmp.py:380]   Expert 57 |    124 | CPU
DEBUG 01-06 08:45:02.139807.139807 lmp.py:380]   Expert 54 |    125 | CPU
DEBUG 01-06 08:45:02.139927.139927 lmp.py:380]   Expert  5 |    130 | CPU
DEBUG 01-06 08:45:02.139524.139524 lmp.py:380]   Expert 32 |    131 | CPU
DEBUG 01-06 08:45:02.139882.139882 lmp.py:380]   Expert 11 |    133 | CPU
DEBUG 01-06 08:45:02.139287.139287 lmp.py:380]   Expert 50 |    144 | CPU
DEBUG 01-06 08:45:02.139407.139407 lmp.py:380]   Expert 24 |    161 | GPU
DEBUG 01-06 08:45:02.139050.139050 lmp.py:380]   Expert 13 |    163 | GPU
DEBUG 01-06 08:45:02.139454.139454 lmp.py:380]   Expert 39 |    163 | GPU
DEBUG 01-06 08:45:02.139620.139620 lmp.py:380]   Expert 58 |    169 | GPU
DEBUG 01-06 08:45:02.139548.139548 lmp.py:380]   Expert 14 |    175 | GPU
DEBUG 01-06 08:45:02.139714.139714 lmp.py:380]   Expert 62 |    176 | GPU
DEBUG 01-06 08:45:02.139880.139880 lmp.py:380]   Expert  0 |    190 | GPU
DEBUG 01-06 08:45:02.139808.139808 lmp.py:380]   Expert 41 |    198 | GPU
DEBUG 01-06 08:45:02.139974.139974 lmp.py:380]   Expert 34 |    200 | GPU
DEBUG 01-06 08:45:02.139617.139617 lmp.py:380]   Expert 18 |    201 | GPU
DEBUG 01-06 08:45:02.139545.139545 lmp.py:380]   Expert 38 |    207 | GPU
DEBUG 01-06 08:45:02.139711.139711 lmp.py:380]   Expert 40 |    208 | GPU
DEBUG 01-06 08:45:02.139639.139639 lmp.py:380]   Expert 30 |    219 | GPU
DEBUG 01-06 08:45:02.139805.139805 lmp.py:380]   Expert  2 |    227 | GPU
DEBUG 01-06 08:45:02.139494.139494 lmp.py:380]   Expert 28 |    227 | GPU
DEBUG 01-06 08:45:02.139422.139422 lmp.py:380]   Expert 21 |    241 | GPU
DEBUG 01-06 08:45:02.139111.139111 lmp.py:380]   Expert 43 |    245 | GPU
DEBUG 01-06 08:45:02.139039.139039 lmp.py:380]   Expert 27 |    257 | GPU
DEBUG 01-06 08:45:02.139443.139443 lmp.py:380]   Expert 55 |    264 | GPU
DEBUG 01-06 08:45:02.139609.139609 lmp.py:380]   Expert 46 |    265 | GPU
DEBUG 01-06 08:45:02.139299.139299 lmp.py:380]   Expert  4 |    273 | GPU
DEBUG 01-06 08:45:02.139227.139227 lmp.py:380]   Expert 10 |    284 | GPU
DEBUG 01-06 08:45:02.139154.139154 lmp.py:380]   Expert 22 |    339 | GPU
DEBUG 01-06 08:45:02.139844.139844 lmp.py:380]   Expert 63 |    339 | GPU
DEBUG 01-06 08:45:02.139771.139771 lmp.py:380]   Expert 36 |    368 | GPU
DEBUG 01-06 08:45:02.139699.139699 lmp.py:380]   Expert 29 |    376 | GPU
DEBUG 01-06 08:45:02.139388.139388 lmp.py:380]   Expert 17 |    429 | GPU
DEBUG 01-06 08:45:02.139793.139793 lmp.py:380]   Expert 31 |    470 | GPU
DEBUG 01-06 08:45:02.139959.139959 lmp.py:380]   Expert 45 |    470 | GPU
DEBUG 01-06 08:45:02.139648.139648 lmp.py:380]   Expert 16 |    471 | GPU
DEBUG 01-06 08:45:02.139338.139338 lmp.py:380]   Expert 42 |    849 | GPU
DEBUG 01-06 08:45:02.139027.139027 lmp.py:380]   Expert 37 |    894 | GPU
DEBUG 01-06 08:45:02.139908.139908 lmp.py:381] 
DEBUG 01-06 08:45:02.139908.139908 lmp.py:381]   CPU total tokens: 2570 (20.9%)
DEBUG 01-06 08:45:02.139551.139551 lmp.py:382]   GPU total tokens: 9718 (79.1%)
DEBUG 01-06 08:45:02.139724.139724 cuda_h.py:19] end experts_map_get cost 0.0015475749969482422 seconds
DEBUG 01-06 08:45:02.139844.139844 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.139435.139435 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.139963.139963 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.140224.140224 cuda_h.py:19] end allocate_cuda_memory cost 0.0008246898651123047 seconds
DEBUG 01-06 08:45:02.140849.140849 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.140227.140227 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.140798.140798 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.140878.140878 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 84be7ef3-ee72-43ac-b1e0-eff9299826fa
DEBUG 01-06 08:45:02.141951.141951 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.141209.141209 client.py:127] Model loaded
DEBUG 01-06 08:45:02.141589.141589 cuda_h.py:19] end sllm_worker_task cost 0.009234905242919922 seconds
INFO 01-06 08:45:02.142462.142462 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 84be7ef3-ee72-43ac-b1e0-eff9299826fa
DEBUG 01-06 08:45:02.143451.143451 cuda_h.py:19] end load_into_gpu_async cost 0.00212860107421875 seconds
DEBUG 01-06 08:45:02.143915.143915 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.143671.143671 cuda_h.py:19] end restore_tensors2 cost 0.0003910064697265625 seconds
DEBUG 01-06 08:45:02.143554.143554 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037162303924560547 seconds
DEBUG 01-06 08:45:02.146951.146951 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00633549690246582 seconds
DEBUG 01-06 08:45:02.146642.146642 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.146055.146055 lmp.py:427] 
DEBUG 01-06 08:45:02.146055.146055 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:02.146276.146276 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-06 08:45:02.146356.146356 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.158676.158676 mlpmodule.py:704] group tensors cost 0.011775493621826172 s
DEBUG 01-06 08:45:02.160805.160805 mlpmodule.py:742] pad cost 0.0015096664428710938 s
DEBUG 01-06 08:45:02.160219.160219 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-06 08:45:02.160685.160685 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 08:45:02.172265.172265 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:02.172677.172677 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.172481.172481 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-06 08:45:02.172572.172572 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.191930.191930 mlpmodule.py:793] group einsum cost 0.030404090881347656 s
DEBUG 01-06 08:45:02.192012.192012 mlpmodule.py:801] cpy2cputensor cost 0.0006613731384277344 s
DEBUG 01-06 08:45:02.196427.196427 cuda_h.py:19] end wait_cetm_experts cost 0.05053544044494629 seconds
DEBUG 01-06 08:45:02.196013.196013 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.198939.198939 cuda_h.py:19] end gpu_sexperts cost 0.0013036727905273438 seconds
DEBUG 01-06 08:45:02.198981.198981 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.198413.198413 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.266334533691406e-05 seconds
DEBUG 01-06 08:45:02.198501.198501 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.198846.198846 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 84be7ef3-ee72-43ac-b1e0-eff9299826fa
INFO 01-06 08:45:02.202054.202054 client.py:127] Model loaded
DEBUG 01-06 08:45:02.202566.202566 cuda_h.py:19] end wait_experts cost 0.003914833068847656 seconds
DEBUG 01-06 08:45:02.202415.202415 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.202648.202648 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.204713.204713 mlpmodule.py:662]  experts func einsum cost 0.0583806037902832 s
DEBUG 01-06 08:45:02.213621.213621 cuda_h.py:19] end gpu_experts cost 0.011058807373046875 seconds
DEBUG 01-06 08:45:02.213135.213135 cuda_h.py:19] end layer_moe_generate_21 cost 0.07640290260314941 seconds
DEBUG 01-06 08:45:02.213041.213041 lmp.py:221] -------------------------------- end layer 21 --------------------------------
DEBUG 01-06 08:45:02.213850.213850 lmp.py:177] -------------------------------- start layer 22 --------------------------------
DEBUG 01-06 08:45:02.213593.213593 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 08:45:02.213726.213726 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 08:45:02.213032.213032 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.5033950805664062e-05 seconds
DEBUG 01-06 08:45:02.214087.214087 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.937980651855469e-05 seconds
DEBUG 01-06 08:45:02.214207.214207 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.214024.214024 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.214046.214046 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.214883.214883 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.214713.214713 cuda_h.py:19] end allocate_cuda_memory cost 0.00022649765014648438 seconds
DEBUG 01-06 08:45:02.214629.214629 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.214008.214008 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.214884.214884 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.214825.214825 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 59130844-cc5f-4365-a8fd-7bcde6fe0830
DEBUG 01-06 08:45:02.214271.214271 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.215630.215630 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.215631.215631 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 59130844-cc5f-4365-a8fd-7bcde6fe0830
DEBUG 01-06 08:45:02.215812.215812 cuda_h.py:19] end load_into_gpu_async cost 0.001257181167602539 seconds
DEBUG 01-06 08:45:02.215137.215137 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.216240.216240 cuda_h.py:19] end restore_tensors2 cost 7.915496826171875e-05 seconds
DEBUG 01-06 08:45:02.216195.216195 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018296241760253906 seconds
INFO 01-06 08:45:02.216650.216650 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 59130844-cc5f-4365-a8fd-7bcde6fe0830
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.219020.219020 cuda_h.py:19] end self_attn cost 0.004049539566040039 seconds
DEBUG 01-06 08:45:02.219360.219360 cuda_h.py:19] end iln_self_attn_paln cost 0.005350351333618164 seconds
DEBUG 01-06 08:45:02.219773.219773 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-06 08:45:02.219012.219012 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.220710.220710 cuda_h.py:19] end gate cost 0.0006208419799804688 seconds
DEBUG 01-06 08:45:02.220155.220155 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.220126.220126 lmp.py:369] 
DEBUG 01-06 08:45:02.220126.220126 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.220313.220313 lmp.py:370]   Total experts: 64
DEBUG 01-06 08:45:02.220678.220678 lmp.py:371]   CPU experts: 32 (50%)
DEBUG 01-06 08:45:02.220182.220182 lmp.py:372]   GPU experts: 32 (50%)
DEBUG 01-06 08:45:02.220587.220587 lmp.py:373] 
DEBUG 01-06 08:45:02.220587.220587 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.220991.220991 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.220595.220595 lmp.py:380]   Expert 48 |      1 | CPU
DEBUG 01-06 08:45:02.220238.220238 lmp.py:380]   Expert  6 |      9 | CPU
DEBUG 01-06 08:45:02.220404.220404 lmp.py:380]   Expert 52 |      9 | CPU
DEBUG 01-06 08:45:02.220331.220331 lmp.py:380]   Expert 54 |     11 | CPU
DEBUG 01-06 08:45:02.220021.220021 lmp.py:380]   Expert 46 |     13 | CPU
DEBUG 01-06 08:45:02.220425.220425 lmp.py:380]   Expert 31 |     25 | CPU
DEBUG 01-06 08:45:02.220115.220115 lmp.py:380]   Expert 47 |     25 | CPU
DEBUG 01-06 08:45:02.220327.220327 lmp.py:380]   Expert 62 |     31 | CPU
DEBUG 01-06 08:45:02.220255.220255 lmp.py:380]   Expert  9 |     35 | CPU
DEBUG 01-06 08:45:02.220467.220467 lmp.py:380]   Expert 30 |     37 | CPU
DEBUG 01-06 08:45:02.220156.220156 lmp.py:380]   Expert 13 |     42 | CPU
DEBUG 01-06 08:45:02.220369.220369 lmp.py:380]   Expert 60 |     45 | CPU
DEBUG 01-06 08:45:02.220297.220297 lmp.py:380]   Expert 42 |     50 | CPU
DEBUG 01-06 08:45:02.220224.220224 lmp.py:380]   Expert 44 |     52 | CPU
DEBUG 01-06 08:45:02.220914.220914 lmp.py:380]   Expert 61 |     52 | CPU
DEBUG 01-06 08:45:02.220603.220603 lmp.py:380]   Expert 45 |     56 | CPU
DEBUG 01-06 08:45:02.220815.220815 lmp.py:380]   Expert 63 |     57 | CPU
DEBUG 01-06 08:45:02.220028.220028 lmp.py:380]   Expert 10 |     63 | CPU
DEBUG 01-06 08:45:02.220479.220479 lmp.py:380]   Expert 49 |     64 | CPU
DEBUG 01-06 08:45:02.221883.221883 lmp.py:380]   Expert 21 |     68 | CPU
DEBUG 01-06 08:45:02.221526.221526 lmp.py:380]   Expert 41 |     72 | CPU
DEBUG 01-06 08:45:02.221646.221646 lmp.py:380]   Expert 12 |     82 | CPU
DEBUG 01-06 08:45:02.221051.221051 lmp.py:380]   Expert 11 |     86 | CPU
DEBUG 01-06 08:45:02.221455.221455 lmp.py:380]   Expert 43 |     94 | CPU
DEBUG 01-06 08:45:02.221621.221621 lmp.py:380]   Expert 15 |     95 | CPU
DEBUG 01-06 08:45:02.221503.221503 lmp.py:380]   Expert 32 |     98 | CPU
DEBUG 01-06 08:45:02.221384.221384 lmp.py:380]   Expert 22 |     99 | CPU
DEBUG 01-06 08:45:02.221789.221789 lmp.py:380]   Expert 57 |     99 | CPU
DEBUG 01-06 08:45:02.221955.221955 lmp.py:380]   Expert  7 |    111 | CPU
DEBUG 01-06 08:45:02.221121.221121 lmp.py:380]   Expert 28 |    114 | CPU
DEBUG 01-06 08:45:02.221287.221287 lmp.py:380]   Expert 20 |    133 | CPU
DEBUG 01-06 08:45:02.221453.221453 lmp.py:380]   Expert 58 |    136 | CPU
DEBUG 01-06 08:45:02.221858.221858 lmp.py:380]   Expert 37 |    138 | GPU
DEBUG 01-06 08:45:02.221454.221454 lmp.py:380]   Expert  1 |    169 | GPU
DEBUG 01-06 08:45:02.221574.221574 lmp.py:380]   Expert 39 |    170 | GPU
DEBUG 01-06 08:45:02.221979.221979 lmp.py:380]   Expert 25 |    171 | GPU
DEBUG 01-06 08:45:02.221383.221383 lmp.py:380]   Expert 16 |    183 | GPU
DEBUG 01-06 08:45:02.221550.221550 lmp.py:380]   Expert  8 |    184 | GPU
DEBUG 01-06 08:45:02.221716.221716 lmp.py:380]   Expert 24 |    202 | GPU
DEBUG 01-06 08:45:02.221120.221120 lmp.py:380]   Expert 50 |    213 | GPU
DEBUG 01-06 08:45:02.221286.221286 lmp.py:380]   Expert 38 |    216 | GPU
DEBUG 01-06 08:45:02.221453.221453 lmp.py:380]   Expert 35 |    224 | GPU
DEBUG 01-06 08:45:02.221334.221334 lmp.py:380]   Expert  3 |    233 | GPU
DEBUG 01-06 08:45:02.221500.221500 lmp.py:380]   Expert 27 |    251 | GPU
DEBUG 01-06 08:45:02.221428.221428 lmp.py:380]   Expert 26 |    255 | GPU
DEBUG 01-06 08:45:02.221355.221355 lmp.py:380]   Expert  2 |    258 | GPU
DEBUG 01-06 08:45:02.221283.221283 lmp.py:380]   Expert 17 |    278 | GPU
DEBUG 01-06 08:45:02.221449.221449 lmp.py:380]   Expert 29 |    279 | GPU
DEBUG 01-06 08:45:02.221377.221377 lmp.py:380]   Expert 56 |    288 | GPU
DEBUG 01-06 08:45:02.221305.221305 lmp.py:380]   Expert 23 |    293 | GPU
DEBUG 01-06 08:45:02.221948.221948 lmp.py:380]   Expert 40 |    298 | GPU
DEBUG 01-06 08:45:02.221829.221829 lmp.py:380]   Expert 51 |    306 | GPU
DEBUG 01-06 08:45:02.221995.221995 lmp.py:380]   Expert 19 |    310 | GPU
DEBUG 01-06 08:45:02.221175.221175 lmp.py:380]   Expert 34 |    317 | GPU
DEBUG 01-06 08:45:02.221103.221103 lmp.py:380]   Expert  4 |    336 | GPU
DEBUG 01-06 08:45:02.221554.221554 lmp.py:380]   Expert 14 |    385 | GPU
DEBUG 01-06 08:45:02.221004.221004 lmp.py:380]   Expert  0 |    409 | GPU
DEBUG 01-06 08:45:02.221171.221171 lmp.py:380]   Expert 55 |    421 | GPU
DEBUG 01-06 08:45:02.221860.221860 lmp.py:380]   Expert 18 |    452 | GPU
DEBUG 01-06 08:45:02.221549.221549 lmp.py:380]   Expert 53 |    480 | GPU
DEBUG 01-06 08:45:02.221715.221715 lmp.py:380]   Expert 36 |    568 | GPU
DEBUG 01-06 08:45:02.221882.221882 lmp.py:380]   Expert 33 |    591 | GPU
DEBUG 01-06 08:45:02.221809.221809 lmp.py:380]   Expert  5 |    701 | GPU
DEBUG 01-06 08:45:02.221022.221022 lmp.py:380]   Expert 59 |    745 | GPU
DEBUG 01-06 08:45:02.221141.221141 lmp.py:381] 
DEBUG 01-06 08:45:02.221141.221141 lmp.py:381]   CPU total tokens: 1964 (16.0%)
DEBUG 01-06 08:45:02.221784.221784 lmp.py:382]   GPU total tokens: 10324 (84.0%)
DEBUG 01-06 08:45:02.221957.221957 cuda_h.py:19] end experts_map_get cost 0.0015821456909179688 seconds
DEBUG 01-06 08:45:02.221839.221839 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.221099.221099 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.222527.222527 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.222509.222509 cuda_h.py:19] end allocate_cuda_memory cost 0.0003933906555175781 seconds
DEBUG 01-06 08:45:02.222942.222942 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.222890.222890 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.222746.222746 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.222111.222111 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7762e0f6-4823-4861-82ad-aa8a481880bb
DEBUG 01-06 08:45:02.222422.222422 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.223771.223771 client.py:127] Model loaded
DEBUG 01-06 08:45:02.223052.223052 cuda_h.py:19] end sllm_worker_task cost 0.008853435516357422 seconds
INFO 01-06 08:45:02.223385.223385 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7762e0f6-4823-4861-82ad-aa8a481880bb
DEBUG 01-06 08:45:02.223765.223765 cuda_h.py:19] end load_into_gpu_async cost 0.0012042522430419922 seconds
DEBUG 01-06 08:45:02.223614.223614 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.224918.224918 cuda_h.py:19] end restore_tensors2 cost 0.0003745555877685547 seconds
DEBUG 01-06 08:45:02.224940.224940 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023527145385742188 seconds
DEBUG 01-06 08:45:02.226305.226305 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049860477447509766 seconds
DEBUG 01-06 08:45:02.226849.226849 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.227097.227097 lmp.py:427] 
DEBUG 01-06 08:45:02.227097.227097 lmp.py:427]   Computing 32 experts on CPU...
DEBUG 01-06 08:45:02.227033.227033 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-06 08:45:02.227113.227113 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.238915.238915 mlpmodule.py:704] group tensors cost 0.011749982833862305 s
DEBUG 01-06 08:45:02.241268.241268 mlpmodule.py:742] pad cost 0.0015246868133544922 s
DEBUG 01-06 08:45:02.241543.241543 mlpmodule.py:748] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 08:45:02.241677.241677 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 08:45:02.252781.252781 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 08:45:02.252118.252118 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.252446.252446 mlpmodule.py:773] group_w3 first element: -0.025390625
WARNING 01-06 08:45:02.252875.252875 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.273749.273749 mlpmodule.py:793] group einsum cost 0.031923532485961914 s
DEBUG 01-06 08:45:02.274612.274612 mlpmodule.py:801] cpy2cputensor cost 0.0006456375122070312 s
DEBUG 01-06 08:45:02.279040.279040 cuda_h.py:19] end wait_cetm_experts cost 0.051972389221191406 seconds
DEBUG 01-06 08:45:02.279579.279579 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.280763.280763 cuda_h.py:19] end gpu_sexperts cost 0.0014929771423339844 seconds
DEBUG 01-06 08:45:02.280666.280666 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.280285.280285 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-06 08:45:02.280226.280226 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.280843.280843 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7762e0f6-4823-4861-82ad-aa8a481880bb
INFO 01-06 08:45:02.283003.283003 client.py:127] Model loaded
DEBUG 01-06 08:45:02.283177.283177 cuda_h.py:19] end wait_experts cost 0.0024611949920654297 seconds
DEBUG 01-06 08:45:02.283741.283741 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.283258.283258 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.287699.287699 mlpmodule.py:662]  experts func einsum cost 0.05988812446594238 s
DEBUG 01-06 08:45:02.294082.294082 cuda_h.py:19] end gpu_experts cost 0.011344432830810547 seconds
DEBUG 01-06 08:45:02.294417.294417 cuda_h.py:19] end layer_moe_generate_22 cost 0.07537078857421875 seconds
DEBUG 01-06 08:45:02.295529.295529 lmp.py:221] -------------------------------- end layer 22 --------------------------------
DEBUG 01-06 08:45:02.295391.295391 lmp.py:177] -------------------------------- start layer 23 --------------------------------
DEBUG 01-06 08:45:02.295995.295995 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 08:45:02.295943.295943 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 08:45:02.295733.295733 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.8371810913085938e-05 seconds
DEBUG 01-06 08:45:02.295933.295933 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.841255187988281e-05 seconds
DEBUG 01-06 08:45:02.295914.295914 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.295220.295220 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.295019.295019 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.295524.295524 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.295435.295435 cuda_h.py:19] end allocate_cuda_memory cost 0.0002505779266357422 seconds
DEBUG 01-06 08:45:02.295305.295305 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.295637.295637 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.295360.295360 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.296917.296917 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ccc4ff2c-d3ea-4823-9ac5-48229875958c
DEBUG 01-06 08:45:02.296980.296980 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.296597.296597 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.297039.297039 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ccc4ff2c-d3ea-4823-9ac5-48229875958c
DEBUG 01-06 08:45:02.297068.297068 cuda_h.py:19] end load_into_gpu_async cost 0.0015811920166015625 seconds
DEBUG 01-06 08:45:02.297532.297532 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.297568.297568 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-06 08:45:02.297371.297371 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021545886993408203 seconds
INFO 01-06 08:45:02.298281.298281 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ccc4ff2c-d3ea-4823-9ac5-48229875958c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.300010.300010 cuda_h.py:19] end self_attn cost 0.003742218017578125 seconds
DEBUG 01-06 08:45:02.300497.300497 cuda_h.py:19] end iln_self_attn_paln cost 0.005064964294433594 seconds
DEBUG 01-06 08:45:02.300963.300963 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-06 08:45:02.300110.300110 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.301757.301757 cuda_h.py:19] end gate cost 0.0006878376007080078 seconds
DEBUG 01-06 08:45:02.301586.301586 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.301954.301954 lmp.py:369] 
DEBUG 01-06 08:45:02.301954.301954 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.301962.301962 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:02.301758.301758 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:02.301023.301023 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:02.301143.301143 lmp.py:373] 
DEBUG 01-06 08:45:02.301143.301143 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.301217.301217 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.301582.301582 lmp.py:380]   Expert 25 |      5 | CPU
DEBUG 01-06 08:45:02.301655.301655 lmp.py:380]   Expert 38 |      6 | CPU
DEBUG 01-06 08:45:02.301490.301490 lmp.py:380]   Expert 30 |     20 | CPU
DEBUG 01-06 08:45:02.301087.301087 lmp.py:380]   Expert  7 |     25 | CPU
DEBUG 01-06 08:45:02.301968.301968 lmp.py:380]   Expert 27 |     28 | CPU
DEBUG 01-06 08:45:02.301134.301134 lmp.py:380]   Expert 49 |     28 | CPU
DEBUG 01-06 08:45:02.301300.301300 lmp.py:380]   Expert 47 |     39 | CPU
DEBUG 01-06 08:45:02.301705.301705 lmp.py:380]   Expert 63 |     39 | CPU
DEBUG 01-06 08:45:02.301586.301586 lmp.py:380]   Expert 44 |     41 | CPU
DEBUG 01-06 08:45:02.301229.301229 lmp.py:380]   Expert 53 |     46 | CPU
DEBUG 01-06 08:45:02.301396.301396 lmp.py:380]   Expert 60 |     52 | CPU
DEBUG 01-06 08:45:02.301562.301562 lmp.py:380]   Expert 28 |     53 | CPU
DEBUG 01-06 08:45:02.302489.302489 lmp.py:380]   Expert 16 |     63 | CPU
DEBUG 01-06 08:45:02.302179.302179 lmp.py:380]   Expert 17 |     64 | CPU
DEBUG 01-06 08:45:02.302583.302583 lmp.py:380]   Expert 19 |     74 | CPU
DEBUG 01-06 08:45:02.302511.302511 lmp.py:380]   Expert 58 |     74 | CPU
DEBUG 01-06 08:45:02.302445.302445 lmp.py:380]   Expert 40 |     77 | CPU
DEBUG 01-06 08:45:02.302327.302327 lmp.py:380]   Expert 42 |     78 | CPU
DEBUG 01-06 08:45:02.302255.302255 lmp.py:380]   Expert 12 |     79 | CPU
DEBUG 01-06 08:45:02.302467.302467 lmp.py:380]   Expert 11 |     80 | CPU
DEBUG 01-06 08:45:02.302679.302679 lmp.py:380]   Expert  0 |     81 | CPU
DEBUG 01-06 08:45:02.302130.302130 lmp.py:380]   Expert 35 |     81 | CPU
DEBUG 01-06 08:45:02.302866.302866 lmp.py:380]   Expert 36 |     88 | CPU
DEBUG 01-06 08:45:02.302078.302078 lmp.py:380]   Expert  5 |     89 | CPU
DEBUG 01-06 08:45:02.302768.302768 lmp.py:380]   Expert 61 |    126 | CPU
DEBUG 01-06 08:45:02.302934.302934 lmp.py:380]   Expert 34 |    129 | CPU
DEBUG 01-06 08:45:02.302862.302862 lmp.py:380]   Expert 15 |    134 | CPU
DEBUG 01-06 08:45:02.302074.302074 lmp.py:380]   Expert 62 |    136 | CPU
DEBUG 01-06 08:45:02.302525.302525 lmp.py:380]   Expert 55 |    150 | CPU
DEBUG 01-06 08:45:02.302737.302737 lmp.py:380]   Expert 14 |    157 | CPU
DEBUG 01-06 08:45:02.302711.302711 lmp.py:380]   Expert  3 |    159 | CPU
DEBUG 01-06 08:45:02.302924.302924 lmp.py:380]   Expert 41 |    165 | GPU
DEBUG 01-06 08:45:02.302136.302136 lmp.py:380]   Expert  6 |    167 | GPU
DEBUG 01-06 08:45:02.302349.302349 lmp.py:380]   Expert 33 |    169 | GPU
DEBUG 01-06 08:45:02.302277.302277 lmp.py:380]   Expert 24 |    193 | GPU
DEBUG 01-06 08:45:02.302443.302443 lmp.py:380]   Expert 37 |    194 | GPU
DEBUG 01-06 08:45:02.302894.302894 lmp.py:380]   Expert 39 |    196 | GPU
DEBUG 01-06 08:45:02.302868.302868 lmp.py:380]   Expert 52 |    205 | GPU
DEBUG 01-06 08:45:02.302080.302080 lmp.py:380]   Expert  1 |    210 | GPU
DEBUG 01-06 08:45:02.302293.302293 lmp.py:380]   Expert 26 |    220 | GPU
DEBUG 01-06 08:45:02.302267.302267 lmp.py:380]   Expert  2 |    223 | GPU
DEBUG 01-06 08:45:02.302479.302479 lmp.py:380]   Expert  9 |    227 | GPU
DEBUG 01-06 08:45:02.302453.302453 lmp.py:380]   Expert 13 |    240 | GPU
DEBUG 01-06 08:45:02.302666.302666 lmp.py:380]   Expert 23 |    244 | GPU
DEBUG 01-06 08:45:02.302355.302355 lmp.py:380]   Expert  8 |    246 | GPU
DEBUG 01-06 08:45:02.302567.302567 lmp.py:380]   Expert 22 |    247 | GPU
DEBUG 01-06 08:45:02.302303.302303 lmp.py:380]   Expert 46 |    283 | GPU
DEBUG 01-06 08:45:02.302767.302767 lmp.py:380]   Expert 20 |    284 | GPU
DEBUG 01-06 08:45:02.302265.302265 lmp.py:380]   Expert 45 |    284 | GPU
DEBUG 01-06 08:45:02.302239.302239 lmp.py:380]   Expert 43 |    294 | GPU
DEBUG 01-06 08:45:02.302213.302213 lmp.py:380]   Expert 21 |    305 | GPU
DEBUG 01-06 08:45:02.302948.302948 lmp.py:380]   Expert 48 |    308 | GPU
DEBUG 01-06 08:45:02.302684.302684 lmp.py:380]   Expert 18 |    314 | GPU
DEBUG 01-06 08:45:02.302612.302612 lmp.py:380]   Expert 59 |    341 | GPU
DEBUG 01-06 08:45:02.302347.302347 lmp.py:380]   Expert 57 |    342 | GPU
DEBUG 01-06 08:45:02.302321.302321 lmp.py:380]   Expert 56 |    378 | GPU
DEBUG 01-06 08:45:02.302819.302819 lmp.py:380]   Expert 32 |    383 | GPU
DEBUG 01-06 08:45:02.302554.302554 lmp.py:380]   Expert 31 |    447 | GPU
DEBUG 01-06 08:45:02.302290.302290 lmp.py:380]   Expert 54 |    453 | GPU
DEBUG 01-06 08:45:02.302264.302264 lmp.py:380]   Expert  4 |    465 | GPU
DEBUG 01-06 08:45:02.302761.302761 lmp.py:380]   Expert 29 |    511 | GPU
DEBUG 01-06 08:45:02.302497.302497 lmp.py:380]   Expert 50 |    532 | GPU
DEBUG 01-06 08:45:02.302994.302994 lmp.py:380]   Expert 10 |    917 | GPU
DEBUG 01-06 08:45:02.302922.302922 lmp.py:381] 
DEBUG 01-06 08:45:02.302922.302922 lmp.py:381]   CPU total tokens: 2301 (18.7%)
DEBUG 01-06 08:45:02.302326.302326 lmp.py:382]   GPU total tokens: 9987 (81.3%)
DEBUG 01-06 08:45:02.302976.302976 cuda_h.py:19] end experts_map_get cost 0.0015223026275634766 seconds
DEBUG 01-06 08:45:02.302381.302381 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.302495.302495 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.303307.303307 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.303218.303218 cuda_h.py:19] end allocate_cuda_memory cost 0.0008335113525390625 seconds
DEBUG 01-06 08:45:02.304260.304260 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.304300.304300 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.304441.304441 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.304044.304044 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d11fe02e-ad34-477b-b636-742b853131f7
INFO 01-06 08:45:02.344489.344489 client.py:127] Model loaded
DEBUG 01-06 08:45:02.344485.344485 cuda_h.py:19] end sllm_worker_task cost 0.04930996894836426 seconds
DEBUG 01-06 08:45:02.344555.344555 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.346667.346667 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d11fe02e-ad34-477b-b636-742b853131f7
DEBUG 01-06 08:45:02.346934.346934 cuda_h.py:19] end load_into_gpu_async cost 0.042845726013183594 seconds
DEBUG 01-06 08:45:02.346875.346875 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.347962.347962 cuda_h.py:19] end restore_tensors2 cost 0.00038814544677734375 seconds
DEBUG 01-06 08:45:02.347745.347745 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.04443955421447754 seconds
DEBUG 01-06 08:45:02.350243.350243 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.04709887504577637 seconds
DEBUG 01-06 08:45:02.350702.350702 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.350123.350123 lmp.py:427] 
DEBUG 01-06 08:45:02.350123.350123 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:02.350919.350919 cuda_h.py:19] end cpu_experts_submit cost 0.00011610984802246094 seconds
DEBUG 01-06 08:45:02.350761.350761 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.365581.365581 mlpmodule.py:704] group tensors cost 0.014784574508666992 s
DEBUG 01-06 08:45:02.368336.368336 mlpmodule.py:742] pad cost 0.0022275447845458984 s
DEBUG 01-06 08:45:02.368439.368439 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-06 08:45:02.368945.368945 mlpmodule.py:753] move to cpu cost 5.7220458984375e-05 s
DEBUG 01-06 08:45:02.379191.379191 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:02.379681.379681 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.380923.380923 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-06 08:45:02.380265.380265 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.398382.398382 mlpmodule.py:793] group einsum cost 0.029979467391967773 s
DEBUG 01-06 08:45:02.399569.399569 mlpmodule.py:801] cpy2cputensor cost 0.0006337165832519531 s
DEBUG 01-06 08:45:02.404309.404309 cuda_h.py:19] end wait_cetm_experts cost 0.0536956787109375 seconds
DEBUG 01-06 08:45:02.404318.404318 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.405457.405457 cuda_h.py:19] end gpu_sexperts cost 0.0009367465972900391 seconds
DEBUG 01-06 08:45:02.405499.405499 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.405163.405163 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-06 08:45:02.405535.405535 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.405722.405722 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d11fe02e-ad34-477b-b636-742b853131f7
INFO 01-06 08:45:02.406888.406888 client.py:127] Model loaded
DEBUG 01-06 08:45:02.406824.406824 cuda_h.py:19] end wait_experts cost 0.0012700557708740234 seconds
DEBUG 01-06 08:45:02.406480.406480 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.406236.406236 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.412150.412150 mlpmodule.py:662]  experts func einsum cost 0.06225109100341797 s
DEBUG 01-06 08:45:02.419747.419747 cuda_h.py:19] end gpu_experts cost 0.012658834457397461 seconds
DEBUG 01-06 08:45:02.423265.423265 cuda_h.py:19] end layer_moe_generate_23 cost 0.12269091606140137 seconds
DEBUG 01-06 08:45:02.423242.423242 lmp.py:221] -------------------------------- end layer 23 --------------------------------
DEBUG 01-06 08:45:02.423641.423641 lmp.py:177] -------------------------------- start layer 24 --------------------------------
DEBUG 01-06 08:45:02.423575.423575 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 08:45:02.423000.423000 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 08:45:02.423790.423790 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.7894973754882812e-05 seconds
DEBUG 01-06 08:45:02.423845.423845 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.414817810058594e-05 seconds
DEBUG 01-06 08:45:02.423964.423964 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.424463.424463 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.424863.424863 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.424792.424792 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.424405.424405 cuda_h.py:19] end allocate_cuda_memory cost 0.00027632713317871094 seconds
DEBUG 01-06 08:45:02.424786.424786 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.424264.424264 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.424517.424517 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.424505.424505 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b2fe7e2-0de8-441b-aecc-94e031ea3dc5
DEBUG 01-06 08:45:02.424912.424912 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.425292.425292 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.425406.425406 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b2fe7e2-0de8-441b-aecc-94e031ea3dc5
DEBUG 01-06 08:45:02.425242.425242 cuda_h.py:19] end load_into_gpu_async cost 0.001318216323852539 seconds
DEBUG 01-06 08:45:02.425514.425514 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.426280.426280 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-06 08:45:02.426704.426704 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019571781158447266 seconds
INFO 01-06 08:45:02.426972.426972 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b2fe7e2-0de8-441b-aecc-94e031ea3dc5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.429578.429578 cuda_h.py:19] end self_attn cost 0.0039386749267578125 seconds
DEBUG 01-06 08:45:02.429608.429608 cuda_h.py:19] end iln_self_attn_paln cost 0.005360841751098633 seconds
DEBUG 01-06 08:45:02.429405.429405 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-06 08:45:02.429598.429598 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.430363.430363 cuda_h.py:19] end gate cost 0.00063323974609375 seconds
DEBUG 01-06 08:45:02.430000.430000 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.430685.430685 lmp.py:369] 
DEBUG 01-06 08:45:02.430685.430685 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.430441.430441 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:02.430614.430614 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:02.430165.430165 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:02.430808.430808 lmp.py:373] 
DEBUG 01-06 08:45:02.430808.430808 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.430166.430166 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.430723.430723 lmp.py:380]   Expert 16 |      2 | CPU
DEBUG 01-06 08:45:02.430081.430081 lmp.py:380]   Expert 47 |      4 | CPU
DEBUG 01-06 08:45:02.430963.430963 lmp.py:380]   Expert  6 |     11 | CPU
DEBUG 01-06 08:45:02.430652.430652 lmp.py:380]   Expert 30 |     13 | CPU
DEBUG 01-06 08:45:02.430341.430341 lmp.py:380]   Expert 42 |     18 | CPU
DEBUG 01-06 08:45:02.430792.430792 lmp.py:380]   Expert 25 |     22 | CPU
DEBUG 01-06 08:45:02.430243.430243 lmp.py:380]   Expert 35 |     26 | CPU
DEBUG 01-06 08:45:02.430694.430694 lmp.py:380]   Expert 54 |     30 | CPU
DEBUG 01-06 08:45:02.430906.430906 lmp.py:380]   Expert 51 |     32 | CPU
DEBUG 01-06 08:45:02.430457.430457 lmp.py:380]   Expert  2 |     47 | CPU
DEBUG 01-06 08:45:02.430338.430338 lmp.py:380]   Expert 13 |     48 | CPU
DEBUG 01-06 08:45:02.430504.430504 lmp.py:380]   Expert 46 |     57 | CPU
DEBUG 01-06 08:45:02.430432.430432 lmp.py:380]   Expert 48 |     69 | CPU
DEBUG 01-06 08:45:02.430644.430644 lmp.py:380]   Expert 32 |     78 | CPU
DEBUG 01-06 08:45:02.430857.430857 lmp.py:380]   Expert 56 |     86 | CPU
DEBUG 01-06 08:45:02.430308.430308 lmp.py:380]   Expert 60 |     91 | CPU
DEBUG 01-06 08:45:02.430043.430043 lmp.py:380]   Expert 21 |     95 | CPU
DEBUG 01-06 08:45:02.430494.430494 lmp.py:380]   Expert 62 |     97 | CPU
DEBUG 01-06 08:45:02.430707.430707 lmp.py:380]   Expert 59 |     98 | CPU
DEBUG 01-06 08:45:02.430681.430681 lmp.py:380]   Expert  7 |     99 | CPU
DEBUG 01-06 08:45:02.430655.430655 lmp.py:380]   Expert  0 |    102 | CPU
DEBUG 01-06 08:45:02.430344.430344 lmp.py:380]   Expert 28 |    109 | CPU
DEBUG 01-06 08:45:02.430464.430464 lmp.py:380]   Expert 41 |    134 | CPU
DEBUG 01-06 08:45:02.431345.431345 lmp.py:380]   Expert 12 |    138 | CPU
DEBUG 01-06 08:45:02.431465.431465 lmp.py:380]   Expert 36 |    150 | CPU
DEBUG 01-06 08:45:02.431585.431585 lmp.py:380]   Expert  5 |    165 | CPU
DEBUG 01-06 08:45:02.431513.431513 lmp.py:380]   Expert 24 |    166 | CPU
DEBUG 01-06 08:45:02.431679.431679 lmp.py:380]   Expert 20 |    173 | CPU
DEBUG 01-06 08:45:02.431606.431606 lmp.py:380]   Expert 23 |    175 | CPU
DEBUG 01-06 08:45:02.431534.431534 lmp.py:380]   Expert 61 |    177 | CPU
DEBUG 01-06 08:45:02.431700.431700 lmp.py:380]   Expert 55 |    186 | CPU
DEBUG 01-06 08:45:02.431628.431628 lmp.py:380]   Expert 14 |    189 | GPU
DEBUG 01-06 08:45:02.431556.431556 lmp.py:380]   Expert 15 |    190 | GPU
DEBUG 01-06 08:45:02.431483.431483 lmp.py:380]   Expert 22 |    198 | GPU
DEBUG 01-06 08:45:02.431411.431411 lmp.py:380]   Expert 57 |    198 | GPU
DEBUG 01-06 08:45:02.431816.431816 lmp.py:380]   Expert 31 |    201 | GPU
DEBUG 01-06 08:45:02.431459.431459 lmp.py:380]   Expert 10 |    206 | GPU
DEBUG 01-06 08:45:02.431102.431102 lmp.py:380]   Expert 44 |    207 | GPU
DEBUG 01-06 08:45:02.431745.431745 lmp.py:380]   Expert 40 |    212 | GPU
DEBUG 01-06 08:45:02.431911.431911 lmp.py:380]   Expert 19 |    215 | GPU
DEBUG 01-06 08:45:02.431077.431077 lmp.py:380]   Expert 39 |    225 | GPU
DEBUG 01-06 08:45:02.431243.431243 lmp.py:380]   Expert 53 |    227 | GPU
DEBUG 01-06 08:45:02.431171.431171 lmp.py:380]   Expert 50 |    230 | GPU
DEBUG 01-06 08:45:02.431098.431098 lmp.py:380]   Expert  4 |    241 | GPU
DEBUG 01-06 08:45:02.431026.431026 lmp.py:380]   Expert 52 |    243 | GPU
DEBUG 01-06 08:45:02.431192.431192 lmp.py:380]   Expert 33 |    245 | GPU
DEBUG 01-06 08:45:02.431120.431120 lmp.py:380]   Expert 45 |    246 | GPU
DEBUG 01-06 08:45:02.431286.431286 lmp.py:380]   Expert 49 |    251 | GPU
DEBUG 01-06 08:45:02.431168.431168 lmp.py:380]   Expert 63 |    252 | GPU
DEBUG 01-06 08:45:02.431049.431049 lmp.py:380]   Expert 34 |    265 | GPU
DEBUG 01-06 08:45:02.431407.431407 lmp.py:380]   Expert 26 |    283 | GPU
DEBUG 01-06 08:45:02.431527.431527 lmp.py:380]   Expert  3 |    288 | GPU
DEBUG 01-06 08:45:02.431455.431455 lmp.py:380]   Expert 37 |    291 | GPU
DEBUG 01-06 08:45:02.431144.431144 lmp.py:380]   Expert  1 |    293 | GPU
DEBUG 01-06 08:45:02.431833.431833 lmp.py:380]   Expert 17 |    298 | GPU
DEBUG 01-06 08:45:02.431523.431523 lmp.py:380]   Expert  9 |    300 | GPU
DEBUG 01-06 08:45:02.431450.431450 lmp.py:380]   Expert 18 |    360 | GPU
DEBUG 01-06 08:45:02.431140.431140 lmp.py:380]   Expert 38 |    367 | GPU
DEBUG 01-06 08:45:02.431067.431067 lmp.py:380]   Expert  8 |    410 | GPU
DEBUG 01-06 08:45:02.431949.431949 lmp.py:380]   Expert 11 |    448 | GPU
DEBUG 01-06 08:45:02.431830.431830 lmp.py:380]   Expert 29 |    467 | GPU
DEBUG 01-06 08:45:02.431473.431473 lmp.py:380]   Expert 58 |    476 | GPU
DEBUG 01-06 08:45:02.431355.431355 lmp.py:380]   Expert 27 |   1068 | GPU
DEBUG 01-06 08:45:02.431236.431236 lmp.py:381] 
DEBUG 01-06 08:45:02.431236.431236 lmp.py:381]   CPU total tokens: 2698 (22.0%)
DEBUG 01-06 08:45:02.431594.431594 lmp.py:382]   GPU total tokens: 9590 (78.0%)
DEBUG 01-06 08:45:02.431482.431482 cuda_h.py:19] end experts_map_get cost 0.001520395278930664 seconds
DEBUG 01-06 08:45:02.431841.431841 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.431385.431385 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.431682.431682 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.432540.432540 cuda_h.py:19] end allocate_cuda_memory cost 0.0004928112030029297 seconds
DEBUG 01-06 08:45:02.432834.432834 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.432451.432451 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.432598.432598 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.432963.432963 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a6c3b83-cfec-4ec3-9601-e396dc0caeff
DEBUG 01-06 08:45:02.432189.432189 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.433459.433459 client.py:127] Model loaded
DEBUG 01-06 08:45:02.433554.433554 cuda_h.py:19] end sllm_worker_task cost 0.008972406387329102 seconds
INFO 01-06 08:45:02.433300.433300 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a6c3b83-cfec-4ec3-9601-e396dc0caeff
DEBUG 01-06 08:45:02.433289.433289 cuda_h.py:19] end load_into_gpu_async cost 0.0012831687927246094 seconds
DEBUG 01-06 08:45:02.433992.433992 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.434058.434058 cuda_h.py:19] end restore_tensors2 cost 0.00037288665771484375 seconds
DEBUG 01-06 08:45:02.434232.434232 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025327205657958984 seconds
DEBUG 01-06 08:45:02.437241.437241 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005217552185058594 seconds
DEBUG 01-06 08:45:02.437330.437330 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.437452.437452 lmp.py:427] 
DEBUG 01-06 08:45:02.437452.437452 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:02.437825.437825 cuda_h.py:19] end cpu_experts_submit cost 0.00012540817260742188 seconds
DEBUG 01-06 08:45:02.437667.437667 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.444751.444751 mlpmodule.py:704] group tensors cost 0.006718635559082031 s
DEBUG 01-06 08:45:02.448842.448842 mlpmodule.py:742] pad cost 0.0032968521118164062 s
DEBUG 01-06 08:45:02.448984.448984 mlpmodule.py:748] create cpu tensor cost 6.651878356933594e-05 s
DEBUG 01-06 08:45:02.448346.448346 mlpmodule.py:753] move to cpu cost 5.125999450683594e-05 s
DEBUG 01-06 08:45:02.458409.458409 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:02.458607.458607 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.458551.458551 mlpmodule.py:773] group_w3 first element: 0.00653076171875
WARNING 01-06 08:45:02.458774.458774 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.477061.477061 mlpmodule.py:793] group einsum cost 0.028977394104003906 s
DEBUG 01-06 08:45:02.478911.478911 mlpmodule.py:801] cpy2cputensor cost 0.0007929801940917969 s
DEBUG 01-06 08:45:02.483308.483308 cuda_h.py:19] end wait_cetm_experts cost 0.04659914970397949 seconds
DEBUG 01-06 08:45:02.483477.483477 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.484194.484194 cuda_h.py:19] end gpu_sexperts cost 0.0006256103515625 seconds
DEBUG 01-06 08:45:02.484806.484806 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.484968.484968 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.38690185546875e-05 seconds
DEBUG 01-06 08:45:02.484863.484863 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.484149.484149 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a6c3b83-cfec-4ec3-9601-e396dc0caeff
INFO 01-06 08:45:02.489569.489569 client.py:127] Model loaded
DEBUG 01-06 08:45:02.489710.489710 cuda_h.py:19] end wait_experts cost 0.004315614700317383 seconds
DEBUG 01-06 08:45:02.489512.489512 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.489507.489507 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.491491.491491 mlpmodule.py:662]  experts func einsum cost 0.05416369438171387 s
DEBUG 01-06 08:45:02.500683.500683 cuda_h.py:19] end gpu_experts cost 0.011565685272216797 seconds
DEBUG 01-06 08:45:02.500389.500389 cuda_h.py:19] end layer_moe_generate_24 cost 0.07147598266601562 seconds
DEBUG 01-06 08:45:02.501788.501788 lmp.py:221] -------------------------------- end layer 24 --------------------------------
DEBUG 01-06 08:45:02.501002.501002 lmp.py:177] -------------------------------- start layer 25 --------------------------------
DEBUG 01-06 08:45:02.501844.501844 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 08:45:02.501315.501315 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 08:45:02.501920.501920 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.1948089599609375e-05 seconds
DEBUG 01-06 08:45:02.501146.501146 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.389617919921875e-05 seconds
DEBUG 01-06 08:45:02.501981.501981 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.501433.501433 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.501628.501628 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.501107.501107 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.502440.502440 cuda_h.py:19] end allocate_cuda_memory cost 0.00042176246643066406 seconds
DEBUG 01-06 08:45:02.502689.502689 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.502789.502789 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.502434.502434 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.502567.502567 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7f7d71e7-5a64-466c-82d3-29431c2f07cd
DEBUG 01-06 08:45:02.502703.502703 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.502689.502689 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.503023.503023 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7f7d71e7-5a64-466c-82d3-29431c2f07cd
DEBUG 01-06 08:45:02.503097.503097 cuda_h.py:19] end load_into_gpu_async cost 0.0012807846069335938 seconds
DEBUG 01-06 08:45:02.503416.503416 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.503142.503142 cuda_h.py:19] end restore_tensors2 cost 8.678436279296875e-05 seconds
DEBUG 01-06 08:45:02.503136.503136 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002086162567138672 seconds
INFO 01-06 08:45:02.504114.504114 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7f7d71e7-5a64-466c-82d3-29431c2f07cd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.507543.507543 cuda_h.py:19] end self_attn cost 0.0042836666107177734 seconds
DEBUG 01-06 08:45:02.508050.508050 cuda_h.py:19] end iln_self_attn_paln cost 0.007184267044067383 seconds
DEBUG 01-06 08:45:02.508754.508754 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-06 08:45:02.508855.508855 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.509271.509271 cuda_h.py:19] end gate cost 0.0007283687591552734 seconds
DEBUG 01-06 08:45:02.509670.509670 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.509451.509451 lmp.py:369] 
DEBUG 01-06 08:45:02.509451.509451 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.509399.509399 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:02.509241.509241 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:02.509745.509745 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:02.510626.510626 lmp.py:373] 
DEBUG 01-06 08:45:02.510626.510626 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.510746.510746 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.510588.510588 lmp.py:380]   Expert 10 |      3 | CPU
DEBUG 01-06 08:45:02.510946.510946 lmp.py:380]   Expert 33 |      3 | CPU
DEBUG 01-06 08:45:02.510351.510351 lmp.py:380]   Expert  0 |      8 | CPU
DEBUG 01-06 08:45:02.510040.510040 lmp.py:380]   Expert 16 |      9 | CPU
DEBUG 01-06 08:45:02.510444.510444 lmp.py:380]   Expert 20 |     17 | CPU
DEBUG 01-06 08:45:02.510372.510372 lmp.py:380]   Expert  2 |     23 | CPU
DEBUG 01-06 08:45:02.510777.510777 lmp.py:380]   Expert 23 |     36 | CPU
DEBUG 01-06 08:45:02.510943.510943 lmp.py:380]   Expert 46 |     36 | CPU
DEBUG 01-06 08:45:02.510632.510632 lmp.py:380]   Expert 18 |     39 | CPU
DEBUG 01-06 08:45:02.510560.510560 lmp.py:380]   Expert 36 |     40 | CPU
DEBUG 01-06 08:45:02.510011.510011 lmp.py:380]   Expert 22 |     42 | CPU
DEBUG 01-06 08:45:02.510177.510177 lmp.py:380]   Expert 38 |     46 | CPU
DEBUG 01-06 08:45:02.510389.510389 lmp.py:380]   Expert 27 |     47 | CPU
DEBUG 01-06 08:45:02.510317.510317 lmp.py:380]   Expert 55 |     47 | CPU
DEBUG 01-06 08:45:02.510768.510768 lmp.py:380]   Expert 61 |     47 | CPU
DEBUG 01-06 08:45:02.510934.510934 lmp.py:380]   Expert 21 |     50 | CPU
DEBUG 01-06 08:45:02.510862.510862 lmp.py:380]   Expert 43 |     54 | CPU
DEBUG 01-06 08:45:02.510790.510790 lmp.py:380]   Expert 31 |     55 | CPU
DEBUG 01-06 08:45:02.510168.510168 lmp.py:380]   Expert  5 |     56 | CPU
DEBUG 01-06 08:45:02.510334.510334 lmp.py:380]   Expert  8 |     60 | CPU
DEBUG 01-06 08:45:02.510500.510500 lmp.py:380]   Expert 13 |     70 | CPU
DEBUG 01-06 08:45:02.510428.510428 lmp.py:380]   Expert 32 |     72 | CPU
DEBUG 01-06 08:45:02.510594.510594 lmp.py:380]   Expert  4 |     89 | CPU
DEBUG 01-06 08:45:02.510522.510522 lmp.py:380]   Expert 24 |     91 | CPU
DEBUG 01-06 08:45:02.510450.510450 lmp.py:380]   Expert 45 |     91 | CPU
DEBUG 01-06 08:45:02.510139.510139 lmp.py:380]   Expert 56 |     91 | CPU
DEBUG 01-06 08:45:02.510259.510259 lmp.py:380]   Expert 53 |     93 | CPU
DEBUG 01-06 08:45:02.510140.510140 lmp.py:380]   Expert 15 |     99 | CPU
DEBUG 01-06 08:45:02.510830.510830 lmp.py:380]   Expert 59 |    100 | CPU
DEBUG 01-06 08:45:02.510519.510519 lmp.py:380]   Expert 44 |    104 | CPU
DEBUG 01-06 08:45:02.510208.510208 lmp.py:380]   Expert 14 |    105 | CPU
DEBUG 01-06 08:45:02.510374.510374 lmp.py:380]   Expert 63 |    123 | GPU
DEBUG 01-06 08:45:02.510302.510302 lmp.py:380]   Expert 34 |    136 | GPU
DEBUG 01-06 08:45:02.510230.510230 lmp.py:380]   Expert 47 |    139 | GPU
DEBUG 01-06 08:45:02.510157.510157 lmp.py:380]   Expert 50 |    166 | GPU
DEBUG 01-06 08:45:02.510324.510324 lmp.py:380]   Expert 62 |    169 | GPU
DEBUG 01-06 08:45:02.510490.510490 lmp.py:380]   Expert 58 |    170 | GPU
DEBUG 01-06 08:45:02.510656.510656 lmp.py:380]   Expert 12 |    176 | GPU
DEBUG 01-06 08:45:02.510060.510060 lmp.py:380]   Expert 35 |    203 | GPU
DEBUG 01-06 08:45:02.510942.510942 lmp.py:380]   Expert 49 |    218 | GPU
DEBUG 01-06 08:45:02.510585.510585 lmp.py:380]   Expert  3 |    230 | GPU
DEBUG 01-06 08:45:02.510751.510751 lmp.py:380]   Expert 48 |    238 | GPU
DEBUG 01-06 08:45:02.510679.510679 lmp.py:380]   Expert 57 |    248 | GPU
DEBUG 01-06 08:45:02.510606.510606 lmp.py:380]   Expert 26 |    268 | GPU
DEBUG 01-06 08:45:02.510296.510296 lmp.py:380]   Expert  6 |    273 | GPU
DEBUG 01-06 08:45:02.510223.510223 lmp.py:380]   Expert 11 |    284 | GPU
DEBUG 01-06 08:45:02.510151.510151 lmp.py:380]   Expert 30 |    306 | GPU
DEBUG 01-06 08:45:02.510079.510079 lmp.py:380]   Expert 54 |    308 | GPU
DEBUG 01-06 08:45:02.510199.510199 lmp.py:380]   Expert 39 |    309 | GPU
DEBUG 01-06 08:45:02.510842.510842 lmp.py:380]   Expert 40 |    311 | GPU
DEBUG 01-06 08:45:02.510485.510485 lmp.py:380]   Expert 25 |    334 | GPU
DEBUG 01-06 08:45:02.510651.510651 lmp.py:380]   Expert 28 |    341 | GPU
DEBUG 01-06 08:45:02.510578.510578 lmp.py:380]   Expert 52 |    354 | GPU
DEBUG 01-06 08:45:02.510506.510506 lmp.py:380]   Expert 37 |    367 | GPU
DEBUG 01-06 08:45:02.510195.510195 lmp.py:380]   Expert 17 |    368 | GPU
DEBUG 01-06 08:45:02.511123.511123 lmp.py:380]   Expert  9 |    387 | GPU
DEBUG 01-06 08:45:02.511289.511289 lmp.py:380]   Expert  7 |    388 | GPU
DEBUG 01-06 08:45:02.511217.511217 lmp.py:380]   Expert 51 |    402 | GPU
DEBUG 01-06 08:45:02.511337.511337 lmp.py:380]   Expert 29 |    449 | GPU
DEBUG 01-06 08:45:02.511980.511980 lmp.py:380]   Expert 41 |    490 | GPU
DEBUG 01-06 08:45:02.511908.511908 lmp.py:380]   Expert 60 |    648 | GPU
DEBUG 01-06 08:45:02.511835.511835 lmp.py:380]   Expert  1 |    803 | GPU
DEBUG 01-06 08:45:02.511001.511001 lmp.py:380]   Expert 19 |    959 | GPU
DEBUG 01-06 08:45:02.511644.511644 lmp.py:381] 
DEBUG 01-06 08:45:02.511644.511644 lmp.py:381]   CPU total tokens: 1723 (14.0%)
DEBUG 01-06 08:45:02.511526.511526 lmp.py:382]   GPU total tokens: 10565 (86.0%)
DEBUG 01-06 08:45:02.511937.511937 cuda_h.py:19] end experts_map_get cost 0.0016069412231445312 seconds
DEBUG 01-06 08:45:02.511534.511534 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.511324.511324 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.511833.511833 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.511688.511688 cuda_h.py:19] end allocate_cuda_memory cost 0.00020742416381835938 seconds
DEBUG 01-06 08:45:02.511538.511538 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.511341.511341 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.511865.511865 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.511468.511468 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7e9e2338-7439-4a33-af41-bc84f934c8db
DEBUG 01-06 08:45:02.512789.512789 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.512309.512309 client.py:127] Model loaded
DEBUG 01-06 08:45:02.512404.512404 cuda_h.py:19] end sllm_worker_task cost 0.010933399200439453 seconds
INFO 01-06 08:45:02.513474.513474 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7e9e2338-7439-4a33-af41-bc84f934c8db
DEBUG 01-06 08:45:02.513231.513231 cuda_h.py:19] end load_into_gpu_async cost 0.0016713142395019531 seconds
DEBUG 01-06 08:45:02.513318.513318 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.514329.514329 cuda_h.py:19] end restore_tensors2 cost 0.0008921623229980469 seconds
DEBUG 01-06 08:45:02.514338.514338 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003179788589477539 seconds
DEBUG 01-06 08:45:02.517945.517945 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0059278011322021484 seconds
DEBUG 01-06 08:45:02.517610.517610 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.517440.517440 lmp.py:427] 
DEBUG 01-06 08:45:02.517440.517440 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:02.517714.517714 cuda_h.py:19] end cpu_experts_submit cost 0.00011658668518066406 seconds
DEBUG 01-06 08:45:02.517986.517986 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.529196.529196 mlpmodule.py:704] group tensors cost 0.011827707290649414 s
DEBUG 01-06 08:45:02.531348.531348 mlpmodule.py:742] pad cost 0.0014541149139404297 s
DEBUG 01-06 08:45:02.531530.531530 mlpmodule.py:748] create cpu tensor cost 4.363059997558594e-05 s
DEBUG 01-06 08:45:02.531764.531764 mlpmodule.py:753] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-06 08:45:02.540263.540263 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:02.540991.540991 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.540274.540274 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-06 08:45:02.540842.540842 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.557883.557883 mlpmodule.py:793] group einsum cost 0.025815486907958984 s
DEBUG 01-06 08:45:02.558005.558005 mlpmodule.py:801] cpy2cputensor cost 0.0004775524139404297 s
DEBUG 01-06 08:45:02.563026.563026 cuda_h.py:19] end wait_cetm_experts cost 0.04563093185424805 seconds
DEBUG 01-06 08:45:02.563453.563453 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.564826.564826 cuda_h.py:19] end gpu_sexperts cost 0.001209259033203125 seconds
DEBUG 01-06 08:45:02.564060.564060 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.564824.564824 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-06 08:45:02.564766.564766 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.564244.564244 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7e9e2338-7439-4a33-af41-bc84f934c8db
INFO 01-06 08:45:02.566991.566991 client.py:127] Model loaded
DEBUG 01-06 08:45:02.566973.566973 cuda_h.py:19] end wait_experts cost 0.0014197826385498047 seconds
DEBUG 01-06 08:45:02.566676.566676 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.566286.566286 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.570423.570423 mlpmodule.py:662]  experts func einsum cost 0.053241729736328125 s
DEBUG 01-06 08:45:02.578119.578119 cuda_h.py:19] end gpu_experts cost 0.012016534805297852 seconds
DEBUG 01-06 08:45:02.578243.578243 cuda_h.py:19] end layer_moe_generate_25 cost 0.06953120231628418 seconds
DEBUG 01-06 08:45:02.578084.578084 lmp.py:221] -------------------------------- end layer 25 --------------------------------
DEBUG 01-06 08:45:02.578529.578529 lmp.py:177] -------------------------------- start layer 26 --------------------------------
DEBUG 01-06 08:45:02.578940.578940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 08:45:02.578981.578981 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 08:45:02.578149.578149 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.7894973754882812e-05 seconds
DEBUG 01-06 08:45:02.578990.578990 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.602836608886719e-05 seconds
DEBUG 01-06 08:45:02.578110.578110 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.578735.578735 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 08:45:02.578546.578546 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.578998.578998 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.579100.579100 cuda_h.py:19] end allocate_cuda_memory cost 0.0002536773681640625 seconds
DEBUG 01-06 08:45:02.579824.579824 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.579680.579680 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.579072.579072 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.579821.579821 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9223eeaf-f4a1-48bf-b847-0d7b907d6a92
DEBUG 01-06 08:45:02.579983.579983 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 08:45:02.579972.579972 cuda_h.py:10] start self_attn
INFO 01-06 08:45:02.580722.580722 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9223eeaf-f4a1-48bf-b847-0d7b907d6a92
DEBUG 01-06 08:45:02.580458.580458 cuda_h.py:19] end load_into_gpu_async cost 0.0011000633239746094 seconds
DEBUG 01-06 08:45:02.580122.580122 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.580563.580563 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-06 08:45:02.580272.580272 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001697540283203125 seconds
INFO 01-06 08:45:02.581851.581851 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9223eeaf-f4a1-48bf-b847-0d7b907d6a92
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.583822.583822 cuda_h.py:19] end self_attn cost 0.00336456298828125 seconds
DEBUG 01-06 08:45:02.583906.583906 cuda_h.py:19] end iln_self_attn_paln cost 0.004736661911010742 seconds
DEBUG 01-06 08:45:02.583603.583603 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-06 08:45:02.583988.583988 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.584893.584893 cuda_h.py:19] end gate cost 0.0006668567657470703 seconds
DEBUG 01-06 08:45:02.584245.584245 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.584462.584462 lmp.py:369] 
DEBUG 01-06 08:45:02.584462.584462 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.584271.584271 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:02.584351.584351 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:02.584332.584332 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:02.584929.584929 lmp.py:373] 
DEBUG 01-06 08:45:02.584929.584929 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.584525.584525 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.584367.584367 lmp.py:380]   Expert 43 |      2 | CPU
DEBUG 01-06 08:45:02.584248.584248 lmp.py:380]   Expert 59 |      5 | CPU
DEBUG 01-06 08:45:02.584415.584415 lmp.py:380]   Expert 22 |      6 | CPU
DEBUG 01-06 08:45:02.584104.584104 lmp.py:380]   Expert 62 |      8 | CPU
DEBUG 01-06 08:45:02.584793.584793 lmp.py:380]   Expert 11 |      9 | CPU
DEBUG 01-06 08:45:02.584244.584244 lmp.py:380]   Expert 29 |     11 | CPU
DEBUG 01-06 08:45:02.584695.584695 lmp.py:380]   Expert 51 |     16 | CPU
DEBUG 01-06 08:45:02.584338.584338 lmp.py:380]   Expert  7 |     17 | CPU
DEBUG 01-06 08:45:02.584981.584981 lmp.py:380]   Expert  6 |     21 | CPU
DEBUG 01-06 08:45:02.584670.584670 lmp.py:380]   Expert  8 |     23 | CPU
DEBUG 01-06 08:45:02.584121.584121 lmp.py:380]   Expert 30 |     23 | CPU
DEBUG 01-06 08:45:02.584572.584572 lmp.py:380]   Expert 61 |     30 | CPU
DEBUG 01-06 08:45:02.584546.584546 lmp.py:380]   Expert 27 |     31 | CPU
DEBUG 01-06 08:45:02.584997.584997 lmp.py:380]   Expert 49 |     31 | CPU
DEBUG 01-06 08:45:02.584448.584448 lmp.py:380]   Expert 53 |     37 | CPU
DEBUG 01-06 08:45:02.585422.585422 lmp.py:380]   Expert 41 |     44 | CPU
DEBUG 01-06 08:45:02.585873.585873 lmp.py:380]   Expert 55 |     50 | CPU
DEBUG 01-06 08:45:02.585085.585085 lmp.py:380]   Expert 17 |     51 | CPU
DEBUG 01-06 08:45:02.585967.585967 lmp.py:380]   Expert 38 |     51 | CPU
DEBUG 01-06 08:45:02.585656.585656 lmp.py:380]   Expert 15 |     55 | CPU
DEBUG 01-06 08:45:02.585630.585630 lmp.py:380]   Expert 24 |     72 | CPU
DEBUG 01-06 08:45:02.585842.585842 lmp.py:380]   Expert 56 |     78 | CPU
DEBUG 01-06 08:45:02.585055.585055 lmp.py:380]   Expert 26 |    103 | CPU
DEBUG 01-06 08:45:02.585267.585267 lmp.py:380]   Expert  0 |    107 | CPU
DEBUG 01-06 08:45:02.585718.585718 lmp.py:380]   Expert 13 |    113 | CPU
DEBUG 01-06 08:45:02.585169.585169 lmp.py:380]   Expert 21 |    133 | CPU
DEBUG 01-06 08:45:02.585858.585858 lmp.py:380]   Expert 23 |    137 | CPU
DEBUG 01-06 08:45:02.585594.585594 lmp.py:380]   Expert 28 |    145 | CPU
DEBUG 01-06 08:45:02.585045.585045 lmp.py:380]   Expert 45 |    146 | CPU
DEBUG 01-06 08:45:02.585449.585449 lmp.py:380]   Expert 37 |    147 | CPU
DEBUG 01-06 08:45:02.585854.585854 lmp.py:380]   Expert 47 |    150 | CPU
DEBUG 01-06 08:45:02.585543.585543 lmp.py:380]   Expert 58 |    153 | GPU
DEBUG 01-06 08:45:02.585517.585517 lmp.py:380]   Expert 19 |    157 | GPU
DEBUG 01-06 08:45:02.585730.585730 lmp.py:380]   Expert 32 |    161 | GPU
DEBUG 01-06 08:45:02.585942.585942 lmp.py:380]   Expert 60 |    166 | GPU
DEBUG 01-06 08:45:02.585678.585678 lmp.py:380]   Expert 34 |    174 | GPU
DEBUG 01-06 08:45:02.585129.585129 lmp.py:380]   Expert 57 |    197 | GPU
DEBUG 01-06 08:45:02.585341.585341 lmp.py:380]   Expert 54 |    200 | GPU
DEBUG 01-06 08:45:02.585315.585315 lmp.py:380]   Expert 42 |    215 | GPU
DEBUG 01-06 08:45:02.585720.585720 lmp.py:380]   Expert 20 |    219 | GPU
DEBUG 01-06 08:45:02.585124.585124 lmp.py:380]   Expert  4 |    226 | GPU
DEBUG 01-06 08:45:02.585814.585814 lmp.py:380]   Expert 36 |    235 | GPU
DEBUG 01-06 08:45:02.585265.585265 lmp.py:380]   Expert 10 |    240 | GPU
DEBUG 01-06 08:45:02.585239.585239 lmp.py:380]   Expert  9 |    241 | GPU
DEBUG 01-06 08:45:02.585451.585451 lmp.py:380]   Expert 33 |    243 | GPU
DEBUG 01-06 08:45:02.585664.585664 lmp.py:380]   Expert  1 |    248 | GPU
DEBUG 01-06 08:45:02.585638.585638 lmp.py:380]   Expert 12 |    254 | GPU
DEBUG 01-06 08:45:02.585088.585088 lmp.py:380]   Expert 16 |    255 | GPU
DEBUG 01-06 08:45:02.585778.585778 lmp.py:380]   Expert 50 |    299 | GPU
DEBUG 01-06 08:45:02.585944.585944 lmp.py:380]   Expert 48 |    301 | GPU
DEBUG 01-06 08:45:02.585633.585633 lmp.py:380]   Expert  2 |    302 | GPU
DEBUG 01-06 08:45:02.585607.585607 lmp.py:380]   Expert  5 |    307 | GPU
DEBUG 01-06 08:45:02.585072.585072 lmp.py:380]   Expert 31 |    326 | GPU
DEBUG 01-06 08:45:02.585807.585807 lmp.py:380]   Expert 39 |    326 | GPU
DEBUG 01-06 08:45:02.585781.585781 lmp.py:380]   Expert 63 |    353 | GPU
DEBUG 01-06 08:45:02.585279.585279 lmp.py:380]   Expert 18 |    354 | GPU
DEBUG 01-06 08:45:02.585253.585253 lmp.py:380]   Expert 25 |    402 | GPU
DEBUG 01-06 08:45:02.585227.585227 lmp.py:380]   Expert 52 |    408 | GPU
DEBUG 01-06 08:45:02.585916.585916 lmp.py:380]   Expert 44 |    416 | GPU
DEBUG 01-06 08:45:02.585844.585844 lmp.py:380]   Expert 35 |    451 | GPU
DEBUG 01-06 08:45:02.585725.585725 lmp.py:380]   Expert 40 |    559 | GPU
DEBUG 01-06 08:45:02.585653.585653 lmp.py:380]   Expert 46 |    639 | GPU
DEBUG 01-06 08:45:02.585342.585342 lmp.py:380]   Expert 14 |   1409 | GPU
DEBUG 01-06 08:45:02.585985.585985 lmp.py:381] 
DEBUG 01-06 08:45:02.585985.585985 lmp.py:381]   CPU total tokens: 1852 (15.1%)
DEBUG 01-06 08:45:02.585866.585866 lmp.py:382]   GPU total tokens: 10436 (84.9%)
DEBUG 01-06 08:45:02.585039.585039 cuda_h.py:19] end experts_map_get cost 0.0015399456024169922 seconds
DEBUG 01-06 08:45:02.585159.585159 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.585850.585850 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.586405.586405 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.587770.587770 cuda_h.py:19] end allocate_cuda_memory cost 0.0015671253204345703 seconds
DEBUG 01-06 08:45:02.587223.587223 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.587410.587410 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.587696.587696 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.587061.587061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ebada4f2-b0fb-4561-966a-21f128f0e937
DEBUG 01-06 08:45:02.588862.588862 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.588651.588651 client.py:127] Model loaded
DEBUG 01-06 08:45:02.588110.588110 cuda_h.py:19] end sllm_worker_task cost 0.009548664093017578 seconds
INFO 01-06 08:45:02.589009.589009 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ebada4f2-b0fb-4561-966a-21f128f0e937
DEBUG 01-06 08:45:02.589806.589806 cuda_h.py:19] end load_into_gpu_async cost 0.0013432502746582031 seconds
DEBUG 01-06 08:45:02.589224.589224 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.589144.589144 cuda_h.py:19] end restore_tensors2 cost 0.00075531005859375 seconds
DEBUG 01-06 08:45:02.590862.590862 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004082202911376953 seconds
DEBUG 01-06 08:45:02.592367.592367 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006759166717529297 seconds
DEBUG 01-06 08:45:02.592296.592296 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.592987.592987 lmp.py:427] 
DEBUG 01-06 08:45:02.592987.592987 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:02.592784.592784 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-06 08:45:02.592341.592341 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.599963.599963 mlpmodule.py:704] group tensors cost 0.0061681270599365234 s
DEBUG 01-06 08:45:02.601375.601375 mlpmodule.py:742] pad cost 0.0021371841430664062 s
DEBUG 01-06 08:45:02.602379.602379 mlpmodule.py:748] create cpu tensor cost 5.269050598144531e-05 s
DEBUG 01-06 08:45:02.602606.602606 mlpmodule.py:753] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-06 08:45:02.611381.611381 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:02.611195.611195 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.611569.611569 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-06 08:45:02.611945.611945 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.629919.629919 mlpmodule.py:793] group einsum cost 0.026871919631958008 s
DEBUG 01-06 08:45:02.630208.630208 mlpmodule.py:801] cpy2cputensor cost 0.0006964206695556641 s
DEBUG 01-06 08:45:02.634591.634591 cuda_h.py:19] end wait_cetm_experts cost 0.04181671142578125 seconds
DEBUG 01-06 08:45:02.634275.634275 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.636430.636430 cuda_h.py:19] end gpu_sexperts cost 0.0013937950134277344 seconds
DEBUG 01-06 08:45:02.636810.636810 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.636263.636263 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.458427429199219e-05 seconds
DEBUG 01-06 08:45:02.636602.636602 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.636656.636656 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ebada4f2-b0fb-4561-966a-21f128f0e937
DEBUG 01-06 08:45:02.642643.642643 mlpmodule.py:662]  experts func einsum cost 0.049034833908081055 s
INFO 01-06 08:45:02.643190.643190 client.py:127] Model loaded
DEBUG 01-06 08:45:02.643570.643570 cuda_h.py:19] end wait_experts cost 0.006715297698974609 seconds
DEBUG 01-06 08:45:02.643180.643180 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.643075.643075 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.653879.653879 cuda_h.py:19] end gpu_experts cost 0.010334968566894531 seconds
DEBUG 01-06 08:45:02.653922.653922 cuda_h.py:19] end layer_moe_generate_26 cost 0.07021355628967285 seconds
DEBUG 01-06 08:45:02.653696.653696 lmp.py:221] -------------------------------- end layer 26 --------------------------------
DEBUG 01-06 08:45:02.653804.653804 lmp.py:177] -------------------------------- start layer 27 --------------------------------
DEBUG 01-06 08:45:02.653023.653023 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-06 08:45:02.654263.654263 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.0967254638671875e-05 seconds
DEBUG 01-06 08:45:02.654336.654336 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 08:45:02.654656.654656 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 08:45:02.656147.656147 cuda_h.py:19] end self_attn cost 0.002516031265258789 seconds
DEBUG 01-06 08:45:02.657362.657362 cuda_h.py:19] end iln_self_attn_paln cost 0.003116607666015625 seconds
DEBUG 01-06 08:45:02.657443.657443 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-06 08:45:02.657398.657398 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.657823.657823 cuda_h.py:19] end gate cost 0.0005965232849121094 seconds
DEBUG 01-06 08:45:02.657461.657461 cuda_h.py:10] start experts_map_get
DEBUG 01-06 08:45:02.658842.658842 lmp.py:369] 
DEBUG 01-06 08:45:02.658842.658842 lmp.py:369] Expert Token Distribution & Device Allocation:
DEBUG 01-06 08:45:02.658929.658929 lmp.py:370]   Total experts: 63
DEBUG 01-06 08:45:02.658387.658387 lmp.py:371]   CPU experts: 31 (49%)
DEBUG 01-06 08:45:02.658222.658222 lmp.py:372]   GPU experts: 32 (51%)
DEBUG 01-06 08:45:02.658196.658196 lmp.py:373] 
DEBUG 01-06 08:45:02.658196.658196 lmp.py:373]   Expert ID | Tokens | Device
DEBUG 01-06 08:45:02.658170.658170 lmp.py:374]   -----------------------------------
DEBUG 01-06 08:45:02.658866.658866 lmp.py:380]   Expert 24 |      2 | CPU
DEBUG 01-06 08:45:02.658317.658317 lmp.py:380]   Expert 45 |      2 | CPU
DEBUG 01-06 08:45:02.658814.658814 lmp.py:380]   Expert 51 |      4 | CPU
DEBUG 01-06 08:45:02.658073.658073 lmp.py:380]   Expert 11 |      6 | CPU
DEBUG 01-06 08:45:02.658809.658809 lmp.py:380]   Expert 18 |     10 | CPU
DEBUG 01-06 08:45:02.658829.658829 lmp.py:380]   Expert 44 |     11 | CPU
DEBUG 01-06 08:45:02.658849.658849 lmp.py:380]   Expert 12 |     12 | CPU
DEBUG 01-06 08:45:02.658539.658539 lmp.py:380]   Expert 42 |     14 | CPU
DEBUG 01-06 08:45:02.658797.658797 lmp.py:380]   Expert 17 |     34 | CPU
DEBUG 01-06 08:45:02.658056.658056 lmp.py:380]   Expert 54 |     38 | CPU
DEBUG 01-06 08:45:02.658838.658838 lmp.py:380]   Expert 25 |     40 | CPU
DEBUG 01-06 08:45:02.658859.658859 lmp.py:380]   Expert 61 |     45 | CPU
DEBUG 01-06 08:45:02.658879.658879 lmp.py:380]   Expert 38 |     50 | CPU
DEBUG 01-06 08:45:02.658661.658661 lmp.py:380]   Expert 36 |     57 | CPU
DEBUG 01-06 08:45:02.658443.658443 lmp.py:380]   Expert 15 |     58 | CPU
DEBUG 01-06 08:45:02.658463.658463 lmp.py:380]   Expert  7 |     73 | CPU
DEBUG 01-06 08:45:02.658484.658484 lmp.py:380]   Expert  5 |     75 | CPU
DEBUG 01-06 08:45:02.658504.658504 lmp.py:380]   Expert 31 |     75 | CPU
DEBUG 01-06 08:45:02.658716.658716 lmp.py:380]   Expert 40 |     84 | CPU
DEBUG 01-06 08:45:02.658737.658737 lmp.py:380]   Expert 59 |     86 | CPU
DEBUG 01-06 08:45:02.658996.658996 lmp.py:380]   Expert 58 |     94 | CPU
DEBUG 01-06 08:45:02.658778.658778 lmp.py:380]   Expert 23 |     96 | CPU
DEBUG 01-06 08:45:02.658560.658560 lmp.py:380]   Expert 32 |     99 | CPU
DEBUG 01-06 08:45:02.658580.658580 lmp.py:380]   Expert  4 |    106 | CPU
DEBUG 01-06 08:45:02.658600.658600 lmp.py:380]   Expert 10 |    106 | CPU
DEBUG 01-06 08:45:02.658382.658382 lmp.py:380]   Expert 39 |    108 | CPU
DEBUG 01-06 08:45:02.658403.658403 lmp.py:380]   Expert 49 |    117 | CPU
DEBUG 01-06 08:45:02.658423.658423 lmp.py:380]   Expert 48 |    118 | CPU
DEBUG 01-06 08:45:02.658205.658205 lmp.py:380]   Expert 46 |    137 | CPU
DEBUG 01-06 08:45:02.658225.658225 lmp.py:380]   Expert 52 |    140 | CPU
DEBUG 01-06 08:45:02.658246.658246 lmp.py:380]   Expert 50 |    141 | CPU
DEBUG 01-06 08:45:02.658266.658266 lmp.py:380]   Expert 34 |    142 | GPU
DEBUG 01-06 08:45:02.658048.658048 lmp.py:380]   Expert  1 |    144 | GPU
DEBUG 01-06 08:45:02.658307.658307 lmp.py:380]   Expert 33 |    146 | GPU
DEBUG 01-06 08:45:02.658089.658089 lmp.py:380]   Expert 30 |    159 | GPU
DEBUG 01-06 08:45:02.658347.658347 lmp.py:380]   Expert 62 |    166 | GPU
DEBUG 01-06 08:45:02.658368.658368 lmp.py:380]   Expert 22 |    173 | GPU
DEBUG 01-06 08:45:02.658388.658388 lmp.py:380]   Expert 13 |    178 | GPU
DEBUG 01-06 08:45:02.658409.658409 lmp.py:380]   Expert 57 |    179 | GPU
DEBUG 01-06 08:45:02.658429.658429 lmp.py:380]   Expert  2 |    193 | GPU
DEBUG 01-06 08:45:02.659449.659449 lmp.py:380]   Expert 19 |    194 | GPU
DEBUG 01-06 08:45:02.659185.659185 lmp.py:380]   Expert 41 |    216 | GPU
DEBUG 01-06 08:45:02.659682.659682 lmp.py:380]   Expert 16 |    222 | GPU
DEBUG 01-06 08:45:02.659464.659464 lmp.py:380]   Expert 55 |    231 | GPU
DEBUG 01-06 08:45:02.659008.659008 lmp.py:380]   Expert 29 |    234 | GPU
DEBUG 01-06 08:45:02.659028.659028 lmp.py:380]   Expert 56 |    248 | GPU
DEBUG 01-06 08:45:02.659810.659810 lmp.py:380]   Expert  8 |    251 | GPU
DEBUG 01-06 08:45:02.659115.659115 lmp.py:380]   Expert 53 |    268 | GPU
DEBUG 01-06 08:45:02.659897.659897 lmp.py:380]   Expert 35 |    273 | GPU
DEBUG 01-06 08:45:02.659156.659156 lmp.py:380]   Expert 14 |    278 | GPU
DEBUG 01-06 08:45:02.659938.659938 lmp.py:380]   Expert 26 |    316 | GPU
DEBUG 01-06 08:45:02.659481.659481 lmp.py:380]   Expert 21 |    317 | GPU
DEBUG 01-06 08:45:02.659263.659263 lmp.py:380]   Expert  3 |    375 | GPU
DEBUG 01-06 08:45:02.659045.659045 lmp.py:380]   Expert  6 |    381 | GPU
DEBUG 01-06 08:45:02.659827.659827 lmp.py:380]   Expert 28 |    385 | GPU
DEBUG 01-06 08:45:02.659848.659848 lmp.py:380]   Expert  0 |    412 | GPU
DEBUG 01-06 08:45:02.659868.659868 lmp.py:380]   Expert 20 |    463 | GPU
DEBUG 01-06 08:45:02.659411.659411 lmp.py:380]   Expert 27 |    477 | GPU
DEBUG 01-06 08:45:02.659193.659193 lmp.py:380]   Expert 43 |    511 | GPU
DEBUG 01-06 08:45:02.659737.659737 lmp.py:380]   Expert 63 |    573 | GPU
DEBUG 01-06 08:45:02.659519.659519 lmp.py:380]   Expert 37 |    574 | GPU
DEBUG 01-06 08:45:02.659592.659592 lmp.py:380]   Expert 60 |    674 | GPU
DEBUG 01-06 08:45:02.659851.659851 lmp.py:380]   Expert  9 |    897 | GPU
DEBUG 01-06 08:45:02.659348.659348 lmp.py:381] 
DEBUG 01-06 08:45:02.659348.659348 lmp.py:381]   CPU total tokens: 2038 (16.6%)
DEBUG 01-06 08:45:02.659084.659084 lmp.py:382]   GPU total tokens: 10250 (83.4%)
DEBUG 01-06 08:45:02.659111.659111 cuda_h.py:19] end experts_map_get cost 0.001397848129272461 seconds
DEBUG 01-06 08:45:02.659562.659562 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 08:45:02.659676.659676 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 08:45:02.659588.659588 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 08:45:02.659181.659181 cuda_h.py:19] end allocate_cuda_memory cost 0.00026416778564453125 seconds
DEBUG 01-06 08:45:02.659839.659839 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 08:45:02.659926.659926 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 08:45:02.660073.660073 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 08:45:02.660961.660961 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 579ca885-9882-4226-8f34-709d1e1aaaa7
DEBUG 01-06 08:45:02.660823.660823 client.py:106] call stub.LoadModelAsync
INFO 01-06 08:45:02.661602.661602 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 579ca885-9882-4226-8f34-709d1e1aaaa7
DEBUG 01-06 08:45:02.661770.661770 cuda_h.py:19] end load_into_gpu_async cost 0.0014638900756835938 seconds
DEBUG 01-06 08:45:02.661757.661757 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 08:45:02.662357.662357 cuda_h.py:19] end restore_tensors2 cost 0.0006594657897949219 seconds
DEBUG 01-06 08:45:02.662398.662398 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027573108673095703 seconds
DEBUG 01-06 08:45:02.664572.664572 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005423069000244141 seconds
DEBUG 01-06 08:45:02.664760.664760 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 08:45:02.665014.665014 lmp.py:427] 
DEBUG 01-06 08:45:02.665014.665014 lmp.py:427]   Computing 31 experts on CPU...
DEBUG 01-06 08:45:02.665480.665480 cuda_h.py:19] end cpu_experts_submit cost 0.00011229515075683594 seconds
DEBUG 01-06 08:45:02.665514.665514 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 08:45:02.674736.674736 mlpmodule.py:704] group tensors cost 0.009471654891967773 s
DEBUG 01-06 08:45:02.676764.676764 mlpmodule.py:742] pad cost 0.0014655590057373047 s
DEBUG 01-06 08:45:02.676847.676847 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-06 08:45:02.676743.676743 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 08:45:02.686175.686175 mlpmodule.py:767] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-06 08:45:02.686141.686141 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 08:45:02.686714.686714 mlpmodule.py:773] group_w3 first element: -0.0020294189453125
WARNING 01-06 08:45:02.686956.686956 mlpmodule.py:783] start einsum2
DEBUG 01-06 08:45:02.702614.702614 mlpmodule.py:793] group einsum cost 0.025316715240478516 s
DEBUG 01-06 08:45:02.703873.703873 mlpmodule.py:801] cpy2cputensor cost 0.0006237030029296875 s
DEBUG 01-06 08:45:02.708296.708296 cuda_h.py:19] end wait_cetm_experts cost 0.042862653732299805 seconds
DEBUG 01-06 08:45:02.708803.708803 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.709894.709894 cuda_h.py:19] end gpu_sexperts cost 0.0016243457794189453 seconds
DEBUG 01-06 08:45:02.709235.709235 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 08:45:02.710080.710080 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-06 08:45:02.710122.710122 cuda_h.py:10] start wait_experts
INFO 01-06 08:45:02.710879.710879 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 579ca885-9882-4226-8f34-709d1e1aaaa7
DEBUG 01-06 08:45:02.715561.715561 mlpmodule.py:662]  experts func einsum cost 0.050119876861572266 s
INFO 01-06 08:45:02.716653.716653 client.py:127] Model loaded
DEBUG 01-06 08:45:02.716320.716320 cuda_h.py:19] end wait_experts cost 0.006043434143066406 seconds
DEBUG 01-06 08:45:02.716468.716468 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.716643.716643 lmp.py:472]   Computing 32 experts on GPU...
DEBUG 01-06 08:45:02.735526.735526 cuda_h.py:19] end gpu_experts cost 0.019073963165283203 seconds
DEBUG 01-06 08:45:02.735576.735576 cuda_h.py:19] end layer_moe_generate_27 cost 0.07829451560974121 seconds
DEBUG 01-06 08:45:02.735119.735119 lmp.py:221] -------------------------------- end layer 27 --------------------------------
DEBUG 01-06 08:45:02.735101.735101 cuda_h.py:19] end multi_layer cost 2.1957669258117676 seconds
DEBUG 01-06 08:45:02.735989.735989 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 08:45:02.739641.739641 cuda_h.py:19] end init_inputs_tokens cost 0.0036096572875976562 seconds
DEBUG 01-06 08:45:02.739636.739636 lmp.py:290] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-06 08:45:02.739101.739101 cuda_h.py:10] start dense_mlp
DEBUG 01-06 08:45:02.739309.739309 lmp.py:293] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-06 08:45:02.739146.739146 cuda_h.py:19] end dense_mlp cost 0.00032258033752441406 seconds
DEBUG 01-06 08:45:02.739372.739372 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-06 08:45:02.739412.739412 cuda_h.py:10] start gate
DEBUG 01-06 08:45:02.740749.740749 cuda_h.py:19] end gate cost 0.0005321502685546875 seconds
DEBUG 01-06 08:45:02.740340.740340 cuda_h.py:10] start experts_map_get
INFO 01-06 08:45:02.741377.741377 lmp.py:582] 
INFO 01-06 08:45:02.741377.741377 lmp.py:582] Layer 1 Expert Device Distribution:
INFO 01-06 08:45:02.741954.741954 lmp.py:583]   Active experts: 53 (out of 64 total)
INFO 01-06 08:45:02.741511.741511 lmp.py:584] 
INFO 01-06 08:45:02.741511.741511 lmp.py:584]   Detailed Expert Distribution:
INFO 01-06 08:45:02.741420.741420 lmp.py:585]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 08:45:02.741732.741732 lmp.py:586]   ----------------------------------------------------------------------
INFO 01-06 08:45:02.741521.741521 lmp.py:589]   0          | 1          |  meta           
INFO 01-06 08:45:02.741879.741879 lmp.py:589]   12         | 1          |  meta           
INFO 01-06 08:45:02.741045.741045 lmp.py:589]   19         | 1          |  meta           
INFO 01-06 08:45:02.741688.741688 lmp.py:589]   21         | 1          |  meta           
INFO 01-06 08:45:02.741377.741377 lmp.py:589]   27         | 1          |  meta           
INFO 01-06 08:45:02.741305.741305 lmp.py:589]   29         | 1          |  meta           
INFO 01-06 08:45:02.741994.741994 lmp.py:589]   36         | 1          |  meta           
INFO 01-06 08:45:02.741922.741922 lmp.py:589]   37         | 1          |  meta           
INFO 01-06 08:45:02.741373.741373 lmp.py:589]   38         | 1          |  meta           
INFO 01-06 08:45:02.741314.741314 lmp.py:589]   49         | 1          |  meta           
INFO 01-06 08:45:02.741765.741765 lmp.py:589]   50         | 1          |  meta           
INFO 01-06 08:45:02.741216.741216 lmp.py:589]   51         | 1          |  meta           
INFO 01-06 08:45:02.741428.741428 lmp.py:589]   52         | 1          |  meta           
INFO 01-06 08:45:02.741661.741661 lmp.py:589]   54         | 1          |  meta           
INFO 01-06 08:45:02.741874.741874 lmp.py:589]   56         | 1          |  meta           
INFO 01-06 08:45:02.741324.741324 lmp.py:589]   60         | 1          |  meta           
INFO 01-06 08:45:02.741299.741299 lmp.py:589]   1          | 2          |  meta           
INFO 01-06 08:45:02.741511.741511 lmp.py:589]   10         | 2          |  meta           
INFO 01-06 08:45:02.741677.741677 lmp.py:589]   11         | 2          |  meta           
INFO 01-06 08:45:02.741605.741605 lmp.py:589]   22         | 2          |  meta           
INFO 01-06 08:45:02.741533.741533 lmp.py:589]   26         | 2          |  meta           
INFO 01-06 08:45:02.741222.741222 lmp.py:589]   35         | 2          |  meta           
INFO 01-06 08:45:02.741434.741434 lmp.py:589]   39         | 2          |  meta           
INFO 01-06 08:45:02.741647.741647 lmp.py:589]   41         | 2          |  meta           
INFO 01-06 08:45:02.741859.741859 lmp.py:589]   43         | 2          |  meta           
INFO 01-06 08:45:02.741595.741595 lmp.py:589]   47         | 2          |  meta           
INFO 01-06 08:45:02.741569.741569 lmp.py:589]   6          | 3          |  meta           
INFO 01-06 08:45:02.741543.741543 lmp.py:589]   8          | 3          |  meta           
INFO 01-06 08:45:02.741517.741517 lmp.py:589]   16         | 3          |  meta           
INFO 01-06 08:45:02.741253.741253 lmp.py:589]   33         | 3          |  meta           
INFO 01-06 08:45:02.741465.741465 lmp.py:589]   40         | 3          |  meta           
INFO 01-06 08:45:02.741201.741201 lmp.py:589]   7          | 4          |  meta           
INFO 01-06 08:45:02.741175.741175 lmp.py:589]   23         | 4          |  meta           
INFO 01-06 08:45:02.741149.741149 lmp.py:589]   28         | 4          |  meta           
INFO 01-06 08:45:02.742646.742646 lmp.py:589]   30         | 4          |  meta           
INFO 01-06 08:45:02.742335.742335 lmp.py:589]   42         | 4          |  meta           
INFO 01-06 08:45:02.742025.742025 lmp.py:589]   59         | 4          |  meta           
INFO 01-06 08:45:02.742952.742952 lmp.py:589]   4          | 5          |  cuda:1         
INFO 01-06 08:45:02.742642.742642 lmp.py:589]   9          | 5          |  meta           
INFO 01-06 08:45:02.742616.742616 lmp.py:589]   44         | 5          |  meta           
INFO 01-06 08:45:02.742351.742351 lmp.py:589]   46         | 5          |  meta           
INFO 01-06 08:45:02.742849.742849 lmp.py:589]   2          | 6          |  meta           
INFO 01-06 08:45:02.742584.742584 lmp.py:589]   45         | 6          |  meta           
INFO 01-06 08:45:02.742843.742843 lmp.py:589]   57         | 6          |  meta           
INFO 01-06 08:45:02.742579.742579 lmp.py:589]   61         | 6          |  meta           
INFO 01-06 08:45:02.742076.742076 lmp.py:589]   5          | 7          |  cuda:1         
INFO 01-06 08:45:02.742811.742811 lmp.py:589]   31         | 7          |  meta           
INFO 01-06 08:45:02.742547.742547 lmp.py:589]   63         | 7          |  meta           
INFO 01-06 08:45:02.742283.742283 lmp.py:589]   14         | 8          |  meta           
INFO 01-06 08:45:02.742257.742257 lmp.py:589]   15         | 9          |  meta           
INFO 01-06 08:45:02.742946.742946 lmp.py:589]   34         | 11         |  meta           
INFO 01-06 08:45:02.742635.742635 lmp.py:589]   20         | 12         |  meta           
INFO 01-06 08:45:02.742325.742325 lmp.py:589]   24         | 12         |  meta           
INFO 01-06 08:45:02.742491.742491 lmp.py:590] ============================================================
INFO 01-06 08:45:02.742491.742491 lmp.py:590] 
INFO 01-06 08:45:02.742379.742379 lmp.py:592] experts_gpu_list: [4, 5]
INFO 01-06 08:45:02.742929.742929 lmp.py:593] experts_cpu_list: [0, 12, 19, 21, 27, 29, 36, 37, 38, 49, 50, 51, 52, 54, 56, 60, 1, 10, 11, 22, 26, 35, 39, 41, 43, 47, 6, 8, 16, 33, 40, 7, 23, 28, 30, 42, 59, 9, 44, 46, 2, 45, 57, 61, 31, 63, 14, 15, 34, 20, 24]
INFO 01-06 08:45:02.742970.742970 lmp.py:594] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 08:45:02.742196.742196 cuda_h.py:19] end experts_map_get cost 0.0017960071563720703 seconds
DEBUG 01-06 08:45:02.742523.742523 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 08:45:02.742374.742374 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-06 08:45:02.742197.742197 cuda_h.py:10] start gpu_experts
DEBUG 01-06 08:45:02.743448.743448 mlpmodule.py:531] gpu group tensors cost 0.00013208389282226562 s
DEBUG 01-06 08:45:02.743143.743143 mlpmodule.py:564] gpu pad cost 0.00015473365783691406 s
DEBUG 01-06 08:45:02.743173.743173 mlpmodule.py:582] gpu group einsum cost 0.0004277229309082031 s
DEBUG 01-06 08:45:02.744111.744111 mlpmodule.py:611] gpu experts func einsum cost 0.0011446475982666016 s
DEBUG 01-06 08:45:02.744273.744273 cuda_h.py:19] end gpu_experts cost 0.0012583732604980469 seconds
DEBUG 01-06 08:45:02.744744.744744 cuda_h.py:10] start cpu_experts
DEBUG 01-06 08:45:02.761731.761731 cuda_h.py:19] end cpu_experts cost 0.01698446273803711 seconds
DEBUG 01-06 08:45:02.761761.761761 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.02129197120666504 seconds
Collecting data...
Generating '/tmp/nsys-report-5b42.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [6%                          ] report1.nsys-rep[1/1] [9%                          ] report1.nsys-rep[1/1] [13%                         ] report1.nsys-rep[1/1] [=17%                        ] report1.nsys-rep[1/1] [==21%                       ] report1.nsys-rep[1/1] [====25%                     ] report1.nsys-rep[1/1] [=====29%                    ] report1.nsys-rep[1/1] [======33%                   ] report1.nsys-rep[1/1] [=======38%                  ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [=========46%                ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
