here pin
INFO 01-05 09:59:00.046778.046778 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-05 09:59:00.904629.904629 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-05 09:59:01.349369.349369 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-05 09:59:01.349103.349103 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.304s
DEBUG 01-05 09:59:01.441030.441030 cuda_memory_view.py:260] 
DEBUG 01-05 09:59:01.441030.441030 cuda_memory_view.py:260] restore_tensors_from_shared_memory_names time: 0.016882658004760742
DEBUG 01-05 09:59:02.464264.464264 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11983180046081543 s
DEBUG 01-05 09:59:02.983423.983423 cuda_h.py:19] end generate_input_ids cost 0.5185434818267822 seconds
DEBUG 01-05 09:59:02.984388.984388 cuda_h.py:10] start init_cache
DEBUG 01-05 09:59:02.984300.984300 cuda_h.py:19] end init_cache cost 0.0001049041748046875 seconds
DEBUG 01-05 09:59:05.623487.623487 cuda_h.py:10] start init_weights
DEBUG 01-05 09:59:05.623986.623986 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:05.623669.623669 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:05.624598.624598 cuda_h.py:19] end allocate_cuda_memory cost 0.0005960464477539062 seconds
DEBUG 01-05 09:59:05.624079.624079 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:05.624498.624498 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:05.624892.624892 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:05.624363.624363 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9cbf0f53-5001-42d9-b14e-28c8e32620f1
DEBUG 01-05 09:59:05.624016.624016 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:05.626815.626815 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9cbf0f53-5001-42d9-b14e-28c8e32620f1
DEBUG 01-05 09:59:05.626613.626613 cuda_h.py:19] end load_into_gpu_async cost 0.0020530223846435547 seconds
DEBUG 01-05 09:59:05.626985.626985 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:05.626460.626460 cuda_h.py:19] end restore_tensors2 cost 8.702278137207031e-05 seconds
DEBUG 01-05 09:59:05.626693.626693 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030863285064697266 seconds
INFO 01-05 09:59:05.627190.627190 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9cbf0f53-5001-42d9-b14e-28c8e32620f1
INFO 01-05 09:59:05.708558.708558 client.py:127] Model loaded
DEBUG 01-05 09:59:05.708511.708511 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 09:59:05.708939.708939 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:05.708407.708407 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:05.709234.709234 cuda_h.py:19] end allocate_cuda_memory cost 0.0004730224609375 seconds
DEBUG 01-05 09:59:05.709690.709690 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:05.709958.709958 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:05.709339.709339 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:05.709401.709401 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b4da86c-f179-45b4-baea-6c00051db8cc
DEBUG 01-05 09:59:05.710759.710759 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:05.711507.711507 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b4da86c-f179-45b4-baea-6c00051db8cc
DEBUG 01-05 09:59:05.711266.711266 cuda_h.py:19] end load_into_gpu_async cost 0.0020821094512939453 seconds
DEBUG 01-05 09:59:05.711084.711084 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:05.712020.712020 cuda_h.py:19] end restore_tensors2 cost 0.00017380714416503906 seconds
DEBUG 01-05 09:59:05.712963.712963 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034050941467285156 seconds
INFO 01-05 09:59:05.712146.712146 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b4da86c-f179-45b4-baea-6c00051db8cc
INFO 01-05 09:59:05.728792.728792 client.py:127] Model loaded
DEBUG 01-05 09:59:05.730536.730536 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.021221637725830078 seconds
DEBUG 01-05 09:59:05.730898.730898 cuda_h.py:19] end init_weights cost 0.10638904571533203 seconds
DEBUG 01-05 09:59:05.730053.730053 cuda_h.py:10] start copy_emodel
DEBUG 01-05 09:59:06.686589.686589 cuda_h.py:19] end copy_emodel cost 0.9557671546936035 seconds
DEBUG 01-05 09:59:06.686997.686997 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:59:06.764102.764102 cuda_h.py:19] end init_inputs_tokens cost 0.07763457298278809 seconds
DEBUG 01-05 09:59:06.764682.764682 cuda_h.py:10] start multi_layer
DEBUG 01-05 09:59:06.764326.764326 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 09:59:06.764645.764645 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:06.764753.764753 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:06.764848.764848 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 4.029273986816406e-05 seconds
DEBUG 01-05 09:59:06.764411.764411 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.486343383789062e-05 seconds
DEBUG 01-05 09:59:06.764108.764108 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:06.765675.765675 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:06.765739.765739 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:06.765887.765887 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:06.765353.765353 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-05 09:59:06.765707.765707 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:06.765861.765861 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:06.765789.765789 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:06.765406.765406 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 47719134-3831-434d-98b0-dc18d5e27557
DEBUG 01-05 09:59:06.765079.765079 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:06.767144.767144 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 47719134-3831-434d-98b0-dc18d5e27557
DEBUG 01-05 09:59:06.767100.767100 cuda_h.py:19] end load_into_gpu_async cost 0.0020003318786621094 seconds
DEBUG 01-05 09:59:06.767571.767571 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:06.767609.767609 cuda_h.py:19] end restore_tensors2 cost 0.00010061264038085938 seconds
DEBUG 01-05 09:59:06.767061.767061 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026504993438720703 seconds
INFO 01-05 09:59:06.768621.768621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 47719134-3831-434d-98b0-dc18d5e27557
INFO 01-05 09:59:06.775764.775764 client.py:127] Model loaded
DEBUG 01-05 09:59:06.775200.775200 cuda_h.py:19] end sllm_worker_task cost 0.010811328887939453 seconds
DEBUG 01-05 09:59:06.854525.854525 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.102869.102869 cuda_h.py:19] end self_attn cost 0.24745845794677734 seconds
DEBUG 01-05 09:59:07.102536.102536 cuda_h.py:19] end iln_self_attn_paln cost 0.3377060890197754 seconds
DEBUG 01-05 09:59:07.102061.102061 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:59:07.102599.102599 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:07.102833.102833 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.62396240234375e-05 seconds
DEBUG 01-05 09:59:07.102984.102984 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.103950.103950 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.103937.103937 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.103866.103866 cuda_h.py:19] end allocate_cuda_memory cost 0.00032973289489746094 seconds
DEBUG 01-05 09:59:07.103692.103692 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.104814.104814 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.104195.104195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.104966.104966 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b3b29afe-280d-4ab1-910f-ebc52f0a8473
DEBUG 01-05 09:59:07.104265.104265 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.106055.106055 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b3b29afe-280d-4ab1-910f-ebc52f0a8473
DEBUG 01-05 09:59:07.106662.106662 cuda_h.py:19] end load_into_gpu_async cost 0.002165079116821289 seconds
DEBUG 01-05 09:59:07.106664.106664 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.106864.106864 cuda_h.py:19] end restore_tensors2 cost 0.000141143798828125 seconds
DEBUG 01-05 09:59:07.106125.106125 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032732486724853516 seconds
INFO 01-05 09:59:07.107667.107667 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b3b29afe-280d-4ab1-910f-ebc52f0a8473
DEBUG 01-05 09:59:07.109157.109157 cuda_h.py:19] end dense_mlp cost 0.007154226303100586 seconds
DEBUG 01-05 09:59:07.110750.110750 lmp.py:217] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 09:59:07.110659.110659 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 09:59:07.110408.110408 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:59:07.110840.110840 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:59:07.110676.110676 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.4080276489257812e-05 seconds
DEBUG 01-05 09:59:07.110478.110478 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.745887756347656e-05 seconds
DEBUG 01-05 09:59:07.110697.110697 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.110310.110310 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.114134.114134 cuda_h.py:19] end self_attn cost 0.0037755966186523438 seconds
DEBUG 01-05 09:59:07.114013.114013 cuda_h.py:19] end iln_self_attn_paln cost 0.004433631896972656 seconds
DEBUG 01-05 09:59:07.114262.114262 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 09:59:07.114753.114753 cuda_h.py:10] start gate
INFO 01-05 09:59:07.115258.115258 client.py:127] Model loaded
DEBUG 01-05 09:59:07.115547.115547 cuda_h.py:19] end sllm_worker_task cost 0.012107133865356445 seconds
DEBUG 01-05 09:59:07.115359.115359 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.115521.115521 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.115286.115286 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.115201.115201 cuda_h.py:19] end allocate_cuda_memory cost 0.0003390312194824219 seconds
DEBUG 01-05 09:59:07.116729.116729 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.116275.116275 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.116735.116735 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.116725.116725 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94045f32-c4af-4fc2-b54e-2f6ac2fa0493
DEBUG 01-05 09:59:07.116300.116300 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.117996.117996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94045f32-c4af-4fc2-b54e-2f6ac2fa0493
DEBUG 01-05 09:59:07.118927.118927 cuda_h.py:19] end load_into_gpu_async cost 0.0018815994262695312 seconds
DEBUG 01-05 09:59:07.118069.118069 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.118486.118486 cuda_h.py:19] end restore_tensors2 cost 0.00012826919555664062 seconds
DEBUG 01-05 09:59:07.118562.118562 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029401779174804688 seconds
INFO 01-05 09:59:07.119025.119025 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94045f32-c4af-4fc2-b54e-2f6ac2fa0493
INFO 01-05 09:59:07.125456.125456 client.py:127] Model loaded
DEBUG 01-05 09:59:07.126917.126917 cuda_h.py:19] end sllm_worker_task cost 0.01064610481262207 seconds
DEBUG 01-05 09:59:07.210141.210141 cuda_h.py:19] end gate cost 0.09537005424499512 seconds
DEBUG 01-05 09:59:07.210145.210145 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.210532.210532 lmp.py:365] 
DEBUG 01-05 09:59:07.210532.210532 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.210249.210249 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.210806.210806 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.211310.211310 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.211668.211668 lmp.py:369] 
DEBUG 01-05 09:59:07.211668.211668 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.211265.211265 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.211060.211060 lmp.py:376]   Expert 22 |     35 | CPU
DEBUG 01-05 09:59:07.211657.211657 lmp.py:376]   Expert 62 |     44 | CPU
DEBUG 01-05 09:59:07.211777.211777 lmp.py:376]   Expert  3 |     53 | CPU
DEBUG 01-05 09:59:07.211658.211658 lmp.py:376]   Expert 48 |     56 | CPU
DEBUG 01-05 09:59:07.211539.211539 lmp.py:376]   Expert 18 |     62 | CPU
DEBUG 01-05 09:59:07.211659.211659 lmp.py:376]   Expert 39 |     78 | CPU
DEBUG 01-05 09:59:07.211971.211971 lmp.py:376]   Expert 13 |     82 | CPU
DEBUG 01-05 09:59:07.211283.211283 lmp.py:376]   Expert 47 |     83 | CPU
DEBUG 01-05 09:59:07.211118.211118 lmp.py:376]   Expert 53 |     88 | CPU
DEBUG 01-05 09:59:07.211761.211761 lmp.py:376]   Expert 51 |     91 | CPU
DEBUG 01-05 09:59:07.211166.211166 lmp.py:376]   Expert 32 |     93 | CPU
DEBUG 01-05 09:59:07.211809.211809 lmp.py:376]   Expert 54 |     94 | CPU
DEBUG 01-05 09:59:07.211213.211213 lmp.py:376]   Expert 36 |    101 | CPU
DEBUG 01-05 09:59:07.211618.211618 lmp.py:376]   Expert 58 |    101 | CPU
DEBUG 01-05 09:59:07.211499.211499 lmp.py:376]   Expert 38 |    105 | CPU
DEBUG 01-05 09:59:07.211427.211427 lmp.py:376]   Expert 37 |    114 | CPU
DEBUG 01-05 09:59:07.211070.211070 lmp.py:376]   Expert 25 |    115 | CPU
DEBUG 01-05 09:59:07.211713.211713 lmp.py:376]   Expert 27 |    118 | CPU
DEBUG 01-05 09:59:07.211117.211117 lmp.py:376]   Expert 21 |    121 | CPU
DEBUG 01-05 09:59:07.211522.211522 lmp.py:376]   Expert 31 |    121 | CPU
DEBUG 01-05 09:59:07.211688.211688 lmp.py:376]   Expert 41 |    121 | CPU
DEBUG 01-05 09:59:07.211093.211093 lmp.py:376]   Expert 30 |    124 | CPU
DEBUG 01-05 09:59:07.211497.211497 lmp.py:376]   Expert 55 |    126 | CPU
DEBUG 01-05 09:59:07.211663.211663 lmp.py:376]   Expert 59 |    127 | CPU
DEBUG 01-05 09:59:07.211306.211306 lmp.py:376]   Expert 28 |    132 | CPU
DEBUG 01-05 09:59:07.211002.211002 lmp.py:376]   Expert 49 |    142 | CPU
DEBUG 01-05 09:59:07.211791.211791 lmp.py:376]   Expert 29 |    154 | CPU
DEBUG 01-05 09:59:07.211865.211865 lmp.py:376]   Expert 12 |    156 | CPU
DEBUG 01-05 09:59:07.211508.211508 lmp.py:376]   Expert 50 |    169 | CPU
DEBUG 01-05 09:59:07.211912.211912 lmp.py:376]   Expert 11 |    173 | CPU
DEBUG 01-05 09:59:07.211317.211317 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 09:59:07.211721.211721 lmp.py:376]   Expert 24 |    176 | CPU
DEBUG 01-05 09:59:07.211126.211126 lmp.py:376]   Expert 35 |    179 | GPU
DEBUG 01-05 09:59:07.211530.211530 lmp.py:376]   Expert 60 |    179 | GPU
DEBUG 01-05 09:59:07.211935.211935 lmp.py:376]   Expert 63 |    182 | GPU
DEBUG 01-05 09:59:07.211101.211101 lmp.py:376]   Expert 15 |    189 | GPU
DEBUG 01-05 09:59:07.211267.211267 lmp.py:376]   Expert 61 |    191 | GPU
DEBUG 01-05 09:59:07.211672.211672 lmp.py:376]   Expert 19 |    192 | GPU
DEBUG 01-05 09:59:07.211076.211076 lmp.py:376]   Expert 33 |    194 | GPU
DEBUG 01-05 09:59:07.211481.211481 lmp.py:376]   Expert 23 |    212 | GPU
DEBUG 01-05 09:59:07.211078.211078 lmp.py:376]   Expert 17 |    214 | GPU
DEBUG 01-05 09:59:07.211535.211535 lmp.py:376]   Expert  2 |    222 | GPU
DEBUG 01-05 09:59:07.211940.211940 lmp.py:376]   Expert 52 |    222 | GPU
DEBUG 01-05 09:59:07.211344.211344 lmp.py:376]   Expert  0 |    231 | GPU
DEBUG 01-05 09:59:07.211749.211749 lmp.py:376]   Expert 43 |    231 | GPU
DEBUG 01-05 09:59:07.211915.211915 lmp.py:376]   Expert  1 |    237 | GPU
DEBUG 01-05 09:59:07.211081.211081 lmp.py:376]   Expert 40 |    237 | GPU
DEBUG 01-05 09:59:07.211486.211486 lmp.py:376]   Expert  9 |    250 | GPU
DEBUG 01-05 09:59:07.211890.211890 lmp.py:376]   Expert 44 |    254 | GPU
DEBUG 01-05 09:59:07.211295.211295 lmp.py:376]   Expert 45 |    278 | GPU
DEBUG 01-05 09:59:07.211461.211461 lmp.py:376]   Expert  6 |    287 | GPU
DEBUG 01-05 09:59:07.211866.211866 lmp.py:376]   Expert 14 |    303 | GPU
DEBUG 01-05 09:59:07.211462.211462 lmp.py:376]   Expert  4 |    314 | GPU
DEBUG 01-05 09:59:07.212774.212774 lmp.py:376]   Expert 16 |    314 | GPU
DEBUG 01-05 09:59:07.212232.212232 lmp.py:376]   Expert 26 |    316 | GPU
DEBUG 01-05 09:59:07.212544.212544 lmp.py:376]   Expert  8 |    317 | GPU
DEBUG 01-05 09:59:07.212948.212948 lmp.py:376]   Expert 34 |    327 | GPU
DEBUG 01-05 09:59:07.212591.212591 lmp.py:376]   Expert  7 |    340 | GPU
DEBUG 01-05 09:59:07.212757.212757 lmp.py:376]   Expert  5 |    347 | GPU
DEBUG 01-05 09:59:07.212923.212923 lmp.py:376]   Expert 10 |    357 | GPU
DEBUG 01-05 09:59:07.212328.212328 lmp.py:376]   Expert 46 |    389 | GPU
DEBUG 01-05 09:59:07.212733.212733 lmp.py:376]   Expert 42 |    410 | GPU
DEBUG 01-05 09:59:07.212137.212137 lmp.py:376]   Expert 20 |    422 | GPU
DEBUG 01-05 09:59:07.212780.212780 lmp.py:376]   Expert 57 |    423 | GPU
DEBUG 01-05 09:59:07.212377.212377 lmp.py:377] 
DEBUG 01-05 09:59:07.212377.212377 lmp.py:377]   CPU total tokens: 3528 (28.7%)
DEBUG 01-05 09:59:07.212404.212404 lmp.py:378]   GPU total tokens: 8760 (71.3%)
DEBUG 01-05 09:59:07.212438.212438 cuda_h.py:19] end experts_map_get cost 0.0018012523651123047 seconds
DEBUG 01-05 09:59:07.212419.212419 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.212533.212533 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.212648.212648 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.212428.212428 cuda_h.py:19] end allocate_cuda_memory cost 0.00031280517578125 seconds
DEBUG 01-05 09:59:07.213325.213325 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.213611.213611 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.213242.213242 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.213706.213706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4258aeb8-22b7-4682-be23-02601ba0799d
DEBUG 01-05 09:59:07.213316.213316 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.215311.215311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4258aeb8-22b7-4682-be23-02601ba0799d
DEBUG 01-05 09:59:07.215091.215091 cuda_h.py:19] end load_into_gpu_async cost 0.0024416446685791016 seconds
DEBUG 01-05 09:59:07.215776.215776 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.216480.216480 cuda_h.py:19] end restore_tensors2 cost 0.0003802776336669922 seconds
DEBUG 01-05 09:59:07.216819.216819 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003769397735595703 seconds
DEBUG 01-05 09:59:07.219787.219787 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007013797760009766 seconds
DEBUG 01-05 09:59:07.219776.219776 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.219437.219437 lmp.py:423] 
DEBUG 01-05 09:59:07.219437.219437 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.219261.219261 cuda_h.py:19] end cpu_experts_submit cost 0.00022029876708984375 seconds
DEBUG 01-05 09:59:07.219679.219679 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.235943.235943 mlpmodule.py:704] group tensors cost 0.015386343002319336 s
DEBUG 01-05 09:59:07.237461.237461 mlpmodule.py:742] pad cost 0.001684427261352539 s
DEBUG 01-05 09:59:07.237988.237988 mlpmodule.py:748] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-05 09:59:07.237328.237328 mlpmodule.py:753] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-05 09:59:07.276762.276762 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.277777.277777 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.277880.277880 mlpmodule.py:773] group_w3 first element: 0.01348876953125
WARNING 01-05 09:59:07.277381.277381 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.311283.311283 mlpmodule.py:793] group einsum cost 0.07410049438476562 s
DEBUG 01-05 09:59:07.312235.312235 mlpmodule.py:801] cpy2cputensor cost 0.0007004737854003906 s
DEBUG 01-05 09:59:07.320803.320803 cuda_h.py:19] end wait_cetm_experts cost 0.10032153129577637 seconds
DEBUG 01-05 09:59:07.320888.320888 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.321780.321780 cuda_h.py:19] end gpu_sexperts cost 0.0011749267578125 seconds
DEBUG 01-05 09:59:07.321540.321540 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.322926.322926 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.703636169433594e-05 seconds
DEBUG 01-05 09:59:07.322203.322203 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.322880.322880 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4258aeb8-22b7-4682-be23-02601ba0799d
INFO 01-05 09:59:07.323616.323616 client.py:127] Model loaded
DEBUG 01-05 09:59:07.323201.323201 cuda_h.py:19] end wait_experts cost 0.0010814666748046875 seconds
DEBUG 01-05 09:59:07.323825.323825 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.323919.323919 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.332363.332363 mlpmodule.py:662]  experts func einsum cost 0.11223459243774414 s
DEBUG 01-05 09:59:07.332919.332919 mlpmodule.py:531] gpu group tensors cost 0.00880122184753418 s
DEBUG 01-05 09:59:07.334064.334064 mlpmodule.py:564] gpu pad cost 0.0020303726196289062 s
DEBUG 01-05 09:59:07.335741.335741 mlpmodule.py:582] gpu group einsum cost 0.0009558200836181641 s
DEBUG 01-05 09:59:07.339091.339091 mlpmodule.py:611] gpu experts func einsum cost 0.015722036361694336 s
DEBUG 01-05 09:59:07.339187.339187 cuda_h.py:19] end gpu_experts cost 0.015928030014038086 seconds
DEBUG 01-05 09:59:07.339793.339793 cuda_h.py:19] end layer_moe_generate_1 cost 0.224684476852417 seconds
DEBUG 01-05 09:59:07.339096.339096 lmp.py:217] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 09:59:07.339813.339813 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 09:59:07.339224.339224 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:59:07.339172.339172 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:59:07.339797.339797 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.673004150390625e-05 seconds
DEBUG 01-05 09:59:07.339858.339858 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 9.608268737792969e-05 seconds
DEBUG 01-05 09:59:07.339223.339223 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.340657.340657 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.340482.340482 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.340862.340862 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.340884.340884 cuda_h.py:19] end allocate_cuda_memory cost 0.00021600723266601562 seconds
DEBUG 01-05 09:59:07.340305.340305 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.340472.340472 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.340382.340382 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.340337.340337 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5d66c11-3cc5-48be-9333-5ec72cb6dfd8
DEBUG 01-05 09:59:07.340903.340903 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.341944.341944 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.341095.341095 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5d66c11-3cc5-48be-9333-5ec72cb6dfd8
DEBUG 01-05 09:59:07.341044.341044 cuda_h.py:19] end load_into_gpu_async cost 0.0010528564453125 seconds
DEBUG 01-05 09:59:07.341946.341946 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.341148.341148 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-05 09:59:07.341978.341978 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016875267028808594 seconds
INFO 01-05 09:59:07.342787.342787 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5d66c11-3cc5-48be-9333-5ec72cb6dfd8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.345876.345876 cuda_h.py:19] end self_attn cost 0.0046215057373046875 seconds
DEBUG 01-05 09:59:07.346398.346398 cuda_h.py:19] end iln_self_attn_paln cost 0.006170511245727539 seconds
DEBUG 01-05 09:59:07.346387.346387 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 09:59:07.346964.346964 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.346976.346976 cuda_h.py:19] end gate cost 0.0007085800170898438 seconds
DEBUG 01-05 09:59:07.347997.347997 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.347032.347032 lmp.py:365] 
DEBUG 01-05 09:59:07.347032.347032 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.347934.347934 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.347922.347922 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.347863.347863 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.347936.347936 lmp.py:369] 
DEBUG 01-05 09:59:07.347936.347936 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.347533.347533 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.347852.347852 lmp.py:376]   Expert  0 |     19 | CPU
DEBUG 01-05 09:59:07.347925.347925 lmp.py:376]   Expert 36 |     23 | CPU
DEBUG 01-05 09:59:07.347283.347283 lmp.py:376]   Expert 10 |     24 | CPU
DEBUG 01-05 09:59:07.347403.347403 lmp.py:376]   Expert 58 |     27 | CPU
DEBUG 01-05 09:59:07.347523.347523 lmp.py:376]   Expert 26 |     33 | CPU
DEBUG 01-05 09:59:07.347120.347120 lmp.py:376]   Expert 34 |     34 | CPU
DEBUG 01-05 09:59:07.347670.347670 lmp.py:376]   Expert 29 |     44 | CPU
DEBUG 01-05 09:59:07.347267.347267 lmp.py:376]   Expert  3 |     52 | CPU
DEBUG 01-05 09:59:07.347910.347910 lmp.py:376]   Expert  6 |     52 | CPU
DEBUG 01-05 09:59:07.347553.347553 lmp.py:376]   Expert  8 |     52 | CPU
DEBUG 01-05 09:59:07.347434.347434 lmp.py:376]   Expert  9 |     52 | CPU
DEBUG 01-05 09:59:07.347315.347315 lmp.py:376]   Expert 27 |     53 | CPU
DEBUG 01-05 09:59:07.347958.347958 lmp.py:376]   Expert 24 |     56 | CPU
DEBUG 01-05 09:59:07.347317.347317 lmp.py:376]   Expert 25 |     66 | CPU
DEBUG 01-05 09:59:07.347152.347152 lmp.py:376]   Expert 21 |     71 | CPU
DEBUG 01-05 09:59:07.347272.347272 lmp.py:376]   Expert  7 |     77 | CPU
DEBUG 01-05 09:59:07.347153.347153 lmp.py:376]   Expert 13 |     90 | CPU
DEBUG 01-05 09:59:07.347034.347034 lmp.py:376]   Expert 28 |     92 | CPU
DEBUG 01-05 09:59:07.347154.347154 lmp.py:376]   Expert 17 |     95 | CPU
DEBUG 01-05 09:59:07.347797.347797 lmp.py:376]   Expert 30 |     99 | CPU
DEBUG 01-05 09:59:07.348678.348678 lmp.py:376]   Expert 60 |    107 | CPU
DEBUG 01-05 09:59:07.348321.348321 lmp.py:376]   Expert 44 |    111 | CPU
DEBUG 01-05 09:59:07.348964.348964 lmp.py:376]   Expert 59 |    112 | CPU
DEBUG 01-05 09:59:07.348607.348607 lmp.py:376]   Expert  1 |    115 | CPU
DEBUG 01-05 09:59:07.348681.348681 lmp.py:376]   Expert 19 |    116 | CPU
DEBUG 01-05 09:59:07.348324.348324 lmp.py:376]   Expert 52 |    118 | CPU
DEBUG 01-05 09:59:07.348205.348205 lmp.py:376]   Expert 40 |    123 | CPU
DEBUG 01-05 09:59:07.348848.348848 lmp.py:376]   Expert 62 |    123 | CPU
DEBUG 01-05 09:59:07.348491.348491 lmp.py:376]   Expert 33 |    125 | CPU
DEBUG 01-05 09:59:07.348134.348134 lmp.py:376]   Expert 35 |    127 | CPU
DEBUG 01-05 09:59:07.348777.348777 lmp.py:376]   Expert 54 |    127 | CPU
DEBUG 01-05 09:59:07.348182.348182 lmp.py:376]   Expert  4 |    146 | CPU
DEBUG 01-05 09:59:07.348302.348302 lmp.py:376]   Expert 63 |    151 | GPU
DEBUG 01-05 09:59:07.348183.348183 lmp.py:376]   Expert 49 |    152 | GPU
DEBUG 01-05 09:59:07.348064.348064 lmp.py:376]   Expert  5 |    155 | GPU
DEBUG 01-05 09:59:07.348899.348899 lmp.py:376]   Expert 38 |    161 | GPU
DEBUG 01-05 09:59:07.348211.348211 lmp.py:376]   Expert 37 |    170 | GPU
DEBUG 01-05 09:59:07.348093.348093 lmp.py:376]   Expert 57 |    176 | GPU
DEBUG 01-05 09:59:07.348736.348736 lmp.py:376]   Expert 16 |    182 | GPU
DEBUG 01-05 09:59:07.348379.348379 lmp.py:376]   Expert 50 |    191 | GPU
DEBUG 01-05 09:59:07.348783.348783 lmp.py:376]   Expert 45 |    198 | GPU
DEBUG 01-05 09:59:07.348248.348248 lmp.py:376]   Expert 56 |    209 | GPU
DEBUG 01-05 09:59:07.348513.348513 lmp.py:376]   Expert 47 |    216 | GPU
DEBUG 01-05 09:59:07.348587.348587 lmp.py:376]   Expert  2 |    227 | GPU
DEBUG 01-05 09:59:07.348468.348468 lmp.py:376]   Expert 31 |    227 | GPU
DEBUG 01-05 09:59:07.348018.348018 lmp.py:376]   Expert 22 |    251 | GPU
DEBUG 01-05 09:59:07.348377.348377 lmp.py:376]   Expert 51 |    251 | GPU
DEBUG 01-05 09:59:07.348781.348781 lmp.py:376]   Expert 23 |    252 | GPU
DEBUG 01-05 09:59:07.348424.348424 lmp.py:376]   Expert 55 |    252 | GPU
DEBUG 01-05 09:59:07.348067.348067 lmp.py:376]   Expert 32 |    256 | GPU
DEBUG 01-05 09:59:07.348187.348187 lmp.py:376]   Expert 46 |    259 | GPU
DEBUG 01-05 09:59:07.348830.348830 lmp.py:376]   Expert 39 |    272 | GPU
DEBUG 01-05 09:59:07.348235.348235 lmp.py:376]   Expert 14 |    278 | GPU
DEBUG 01-05 09:59:07.348116.348116 lmp.py:376]   Expert 12 |    289 | GPU
DEBUG 01-05 09:59:07.348759.348759 lmp.py:376]   Expert 43 |    302 | GPU
DEBUG 01-05 09:59:07.348832.348832 lmp.py:376]   Expert 53 |    313 | GPU
DEBUG 01-05 09:59:07.348336.348336 lmp.py:376]   Expert 20 |    315 | GPU
DEBUG 01-05 09:59:07.348602.348602 lmp.py:376]   Expert 42 |    343 | GPU
DEBUG 01-05 09:59:07.348437.348437 lmp.py:376]   Expert 15 |    389 | GPU
DEBUG 01-05 09:59:07.348272.348272 lmp.py:376]   Expert 41 |    391 | GPU
DEBUG 01-05 09:59:07.348584.348584 lmp.py:376]   Expert 18 |    429 | GPU
DEBUG 01-05 09:59:07.348181.348181 lmp.py:376]   Expert 48 |    488 | GPU
DEBUG 01-05 09:59:07.348731.348731 lmp.py:376]   Expert 11 |    526 | GPU
DEBUG 01-05 09:59:07.348328.348328 lmp.py:376]   Expert 61 |   1456 | GPU
DEBUG 01-05 09:59:07.348355.348355 lmp.py:377] 
DEBUG 01-05 09:59:07.348355.348355 lmp.py:377]   CPU total tokens: 2561 (20.8%)
DEBUG 01-05 09:59:07.348336.348336 lmp.py:378]   GPU total tokens: 9727 (79.2%)
DEBUG 01-05 09:59:07.348469.348469 cuda_h.py:19] end experts_map_get cost 0.0017895698547363281 seconds
DEBUG 01-05 09:59:07.348211.348211 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.348657.348657 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.349502.349502 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.349556.349556 cuda_h.py:19] end allocate_cuda_memory cost 0.00017905235290527344 seconds
DEBUG 01-05 09:59:07.349644.349644 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.349307.349307 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.349454.349454 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.349488.349488 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1c5fd86-bd5d-430e-9faf-4b69cd4a55f9
DEBUG 01-05 09:59:07.349395.349395 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.349798.349798 client.py:127] Model loaded
DEBUG 01-05 09:59:07.350112.350112 cuda_h.py:19] end sllm_worker_task cost 0.009912252426147461 seconds
INFO 01-05 09:59:07.350511.350511 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1c5fd86-bd5d-430e-9faf-4b69cd4a55f9
DEBUG 01-05 09:59:07.350983.350983 cuda_h.py:19] end load_into_gpu_async cost 0.0011966228485107422 seconds
DEBUG 01-05 09:59:07.350878.350878 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.350611.350611 cuda_h.py:19] end restore_tensors2 cost 0.00030231475830078125 seconds
DEBUG 01-05 09:59:07.350719.350719 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020220279693603516 seconds
DEBUG 01-05 09:59:07.354585.354585 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005190610885620117 seconds
DEBUG 01-05 09:59:07.354806.354806 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.354729.354729 lmp.py:423] 
DEBUG 01-05 09:59:07.354729.354729 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.354671.354671 cuda_h.py:19] end cpu_experts_submit cost 0.00011777877807617188 seconds
DEBUG 01-05 09:59:07.354229.354229 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.366104.366104 mlpmodule.py:704] group tensors cost 0.01190042495727539 s
DEBUG 01-05 09:59:07.368795.368795 mlpmodule.py:742] pad cost 0.0016617774963378906 s
DEBUG 01-05 09:59:07.369011.369011 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-05 09:59:07.369219.369219 mlpmodule.py:753] move to cpu cost 3.814697265625e-05 s
DEBUG 01-05 09:59:07.379866.379866 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.379573.379573 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.379577.379577 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 09:59:07.379330.379330 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.397680.397680 mlpmodule.py:793] group einsum cost 0.028516054153442383 s
DEBUG 01-05 09:59:07.398972.398972 mlpmodule.py:801] cpy2cputensor cost 0.0005922317504882812 s
DEBUG 01-05 09:59:07.403685.403685 cuda_h.py:19] end wait_cetm_experts cost 0.04874157905578613 seconds
DEBUG 01-05 09:59:07.403108.403108 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.404264.404264 cuda_h.py:19] end gpu_sexperts cost 0.0006558895111083984 seconds
DEBUG 01-05 09:59:07.404114.404114 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.404123.404123 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:59:07.404356.404356 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.404311.404311 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1c5fd86-bd5d-430e-9faf-4b69cd4a55f9
INFO 01-05 09:59:07.405648.405648 client.py:127] Model loaded
DEBUG 01-05 09:59:07.405213.405213 cuda_h.py:19] end wait_experts cost 0.0010533332824707031 seconds
DEBUG 01-05 09:59:07.405731.405731 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.405355.405355 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.406644.406644 mlpmodule.py:531] gpu group tensors cost 0.0006518363952636719 s
DEBUG 01-05 09:59:07.413576.413576 mlpmodule.py:564] gpu pad cost 0.007192850112915039 s
DEBUG 01-05 09:59:07.415132.415132 mlpmodule.py:662]  experts func einsum cost 0.06102585792541504 s
DEBUG 01-05 09:59:07.416307.416307 mlpmodule.py:582] gpu group einsum cost 0.0031621456146240234 s
DEBUG 01-05 09:59:07.420831.420831 mlpmodule.py:611] gpu experts func einsum cost 0.014728307723999023 s
DEBUG 01-05 09:59:07.420907.420907 cuda_h.py:19] end gpu_experts cost 0.01491546630859375 seconds
DEBUG 01-05 09:59:07.420043.420043 cuda_h.py:19] end layer_moe_generate_2 cost 0.07414007186889648 seconds
DEBUG 01-05 09:59:07.420188.420188 lmp.py:217] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 09:59:07.420282.420282 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 09:59:07.420647.420647 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:59:07.420502.420502 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:59:07.420776.420776 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:59:07.420598.420598 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 8.225440979003906e-05 seconds
DEBUG 01-05 09:59:07.420864.420864 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.420568.420568 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.420573.420573 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.421701.421701 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.421509.421509 cuda_h.py:19] end allocate_cuda_memory cost 0.0001728534698486328 seconds
DEBUG 01-05 09:59:07.421578.421578 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.421864.421864 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.421779.421779 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.421290.421290 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5e12370-6e99-4318-b90d-b2ac50ae1524
DEBUG 01-05 09:59:07.421644.421644 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.421475.421475 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.422187.422187 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5e12370-6e99-4318-b90d-b2ac50ae1524
DEBUG 01-05 09:59:07.422593.422593 cuda_h.py:19] end load_into_gpu_async cost 0.0009932518005371094 seconds
DEBUG 01-05 09:59:07.422196.422196 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.422272.422272 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-05 09:59:07.422213.422213 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014870166778564453 seconds
INFO 01-05 09:59:07.422524.422524 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5e12370-6e99-4318-b90d-b2ac50ae1524
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.426768.426768 cuda_h.py:19] end self_attn cost 0.00432276725769043 seconds
DEBUG 01-05 09:59:07.426197.426197 cuda_h.py:19] end iln_self_attn_paln cost 0.005760669708251953 seconds
DEBUG 01-05 09:59:07.426160.426160 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 09:59:07.426406.426406 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.427591.427591 cuda_h.py:19] end gate cost 0.0007293224334716797 seconds
DEBUG 01-05 09:59:07.427473.427473 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.427244.427244 lmp.py:365] 
DEBUG 01-05 09:59:07.427244.427244 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.428477.428477 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.428941.428941 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.428114.428114 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.428903.428903 lmp.py:369] 
DEBUG 01-05 09:59:07.428903.428903 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.428976.428976 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.428010.428010 lmp.py:376]   Expert 37 |     22 | CPU
DEBUG 01-05 09:59:07.428038.428038 lmp.py:376]   Expert 44 |     25 | CPU
DEBUG 01-05 09:59:07.428349.428349 lmp.py:376]   Expert 15 |     30 | CPU
DEBUG 01-05 09:59:07.428184.428184 lmp.py:376]   Expert 59 |     30 | CPU
DEBUG 01-05 09:59:07.428496.428496 lmp.py:376]   Expert  5 |     33 | CPU
DEBUG 01-05 09:59:07.428875.428875 lmp.py:376]   Expert 16 |     46 | CPU
DEBUG 01-05 09:59:07.428472.428472 lmp.py:376]   Expert 18 |     48 | CPU
DEBUG 01-05 09:59:07.428353.428353 lmp.py:376]   Expert  4 |     63 | CPU
DEBUG 01-05 09:59:07.428234.428234 lmp.py:376]   Expert 32 |     64 | CPU
DEBUG 01-05 09:59:07.428116.428116 lmp.py:376]   Expert  7 |     75 | CPU
DEBUG 01-05 09:59:07.428236.428236 lmp.py:376]   Expert  1 |     79 | CPU
DEBUG 01-05 09:59:07.428594.428594 lmp.py:376]   Expert 61 |     81 | CPU
DEBUG 01-05 09:59:07.428667.428667 lmp.py:376]   Expert 35 |     88 | CPU
DEBUG 01-05 09:59:07.428324.428324 lmp.py:376]   Expert 48 |     89 | CPU
DEBUG 01-05 09:59:07.428159.428159 lmp.py:376]   Expert 24 |     92 | CPU
DEBUG 01-05 09:59:07.428279.428279 lmp.py:376]   Expert 40 |     97 | CPU
DEBUG 01-05 09:59:07.428160.428160 lmp.py:376]   Expert 49 |    109 | CPU
DEBUG 01-05 09:59:07.428042.428042 lmp.py:376]   Expert 57 |    113 | CPU
DEBUG 01-05 09:59:07.428353.428353 lmp.py:376]   Expert 63 |    113 | CPU
DEBUG 01-05 09:59:07.428950.428950 lmp.py:376]   Expert 29 |    115 | CPU
DEBUG 01-05 09:59:07.428832.428832 lmp.py:376]   Expert 30 |    129 | CPU
DEBUG 01-05 09:59:07.428475.428475 lmp.py:376]   Expert 28 |    132 | CPU
DEBUG 01-05 09:59:07.428356.428356 lmp.py:376]   Expert 42 |    133 | CPU
DEBUG 01-05 09:59:07.428237.428237 lmp.py:376]   Expert 58 |    133 | CPU
DEBUG 01-05 09:59:07.428119.428119 lmp.py:376]   Expert 12 |    135 | CPU
DEBUG 01-05 09:59:07.428000.428000 lmp.py:376]   Expert 55 |    135 | CPU
DEBUG 01-05 09:59:07.428027.428027 lmp.py:376]   Expert 10 |    138 | CPU
DEBUG 01-05 09:59:07.428339.428339 lmp.py:376]   Expert  6 |    139 | CPU
DEBUG 01-05 09:59:07.428459.428459 lmp.py:376]   Expert 47 |    139 | CPU
DEBUG 01-05 09:59:07.428579.428579 lmp.py:376]   Expert 26 |    140 | CPU
DEBUG 01-05 09:59:07.428222.428222 lmp.py:376]   Expert 11 |    145 | CPU
DEBUG 01-05 09:59:07.428103.428103 lmp.py:376]   Expert 52 |    145 | CPU
DEBUG 01-05 09:59:07.428223.428223 lmp.py:376]   Expert 38 |    146 | GPU
DEBUG 01-05 09:59:07.428628.428628 lmp.py:376]   Expert 23 |    155 | GPU
DEBUG 01-05 09:59:07.428270.428270 lmp.py:376]   Expert 53 |    155 | GPU
DEBUG 01-05 09:59:07.428582.428582 lmp.py:376]   Expert 34 |    162 | GPU
DEBUG 01-05 09:59:07.428702.428702 lmp.py:376]   Expert  2 |    164 | GPU
DEBUG 01-05 09:59:07.428584.428584 lmp.py:376]   Expert 51 |    180 | GPU
DEBUG 01-05 09:59:07.428465.428465 lmp.py:376]   Expert  3 |    187 | GPU
DEBUG 01-05 09:59:07.428108.428108 lmp.py:376]   Expert 36 |    191 | GPU
DEBUG 01-05 09:59:07.428466.428466 lmp.py:376]   Expert 22 |    195 | GPU
DEBUG 01-05 09:59:07.428109.428109 lmp.py:376]   Expert  8 |    196 | GPU
DEBUG 01-05 09:59:07.428752.428752 lmp.py:376]   Expert 31 |    207 | GPU
DEBUG 01-05 09:59:07.428826.428826 lmp.py:376]   Expert 62 |    213 | GPU
DEBUG 01-05 09:59:07.428138.428138 lmp.py:376]   Expert 45 |    220 | GPU
DEBUG 01-05 09:59:07.428019.428019 lmp.py:376]   Expert 39 |    221 | GPU
DEBUG 01-05 09:59:07.428900.428900 lmp.py:376]   Expert 14 |    245 | GPU
DEBUG 01-05 09:59:07.429543.429543 lmp.py:376]   Expert 50 |    250 | GPU
DEBUG 01-05 09:59:07.429425.429425 lmp.py:376]   Expert 27 |    251 | GPU
DEBUG 01-05 09:59:07.429829.429829 lmp.py:376]   Expert 17 |    253 | GPU
DEBUG 01-05 09:59:07.429711.429711 lmp.py:376]   Expert 13 |    259 | GPU
DEBUG 01-05 09:59:07.429069.429069 lmp.py:376]   Expert 21 |    284 | GPU
DEBUG 01-05 09:59:07.429381.429381 lmp.py:376]   Expert  0 |    290 | GPU
DEBUG 01-05 09:59:07.429739.429739 lmp.py:376]   Expert 56 |    320 | GPU
DEBUG 01-05 09:59:07.429620.429620 lmp.py:376]   Expert 46 |    339 | GPU
DEBUG 01-05 09:59:07.429263.429263 lmp.py:376]   Expert 60 |    348 | GPU
DEBUG 01-05 09:59:07.429145.429145 lmp.py:376]   Expert 20 |    350 | GPU
DEBUG 01-05 09:59:07.429788.429788 lmp.py:376]   Expert 33 |    358 | GPU
DEBUG 01-05 09:59:07.429669.429669 lmp.py:376]   Expert  9 |    370 | GPU
DEBUG 01-05 09:59:07.429551.429551 lmp.py:376]   Expert 25 |    459 | GPU
DEBUG 01-05 09:59:07.429624.429624 lmp.py:376]   Expert 19 |    469 | GPU
DEBUG 01-05 09:59:07.429505.429505 lmp.py:376]   Expert 43 |    497 | GPU
DEBUG 01-05 09:59:07.429387.429387 lmp.py:376]   Expert 54 |    587 | GPU
DEBUG 01-05 09:59:07.429030.429030 lmp.py:376]   Expert 41 |    712 | GPU
DEBUG 01-05 09:59:07.429103.429103 lmp.py:377] 
DEBUG 01-05 09:59:07.429103.429103 lmp.py:377]   CPU total tokens: 3055 (24.9%)
DEBUG 01-05 09:59:07.429938.429938 lmp.py:378]   GPU total tokens: 9233 (75.1%)
DEBUG 01-05 09:59:07.429542.429542 cuda_h.py:19] end experts_map_get cost 0.0018095970153808594 seconds
DEBUG 01-05 09:59:07.429092.429092 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.429299.429299 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.429913.429913 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.429100.429100 cuda_h.py:19] end allocate_cuda_memory cost 0.00020599365234375 seconds
DEBUG 01-05 09:59:07.429519.429519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.429805.429805 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.429568.429568 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.429840.429840 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c84cae40-5cab-4f14-9877-2400c9de08bd
DEBUG 01-05 09:59:07.430839.430839 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.430528.430528 client.py:127] Model loaded
DEBUG 01-05 09:59:07.430338.430338 cuda_h.py:19] end sllm_worker_task cost 0.009419679641723633 seconds
INFO 01-05 09:59:07.431511.431511 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c84cae40-5cab-4f14-9877-2400c9de08bd
DEBUG 01-05 09:59:07.431838.431838 cuda_h.py:19] end load_into_gpu_async cost 0.0011818408966064453 seconds
DEBUG 01-05 09:59:07.431495.431495 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.431903.431903 cuda_h.py:19] end restore_tensors2 cost 0.00030994415283203125 seconds
DEBUG 01-05 09:59:07.431342.431342 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020427703857421875 seconds
DEBUG 01-05 09:59:07.434161.434161 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005178928375244141 seconds
DEBUG 01-05 09:59:07.434858.434858 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.434378.434378 lmp.py:423] 
DEBUG 01-05 09:59:07.434378.434378 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.434228.434228 cuda_h.py:19] end cpu_experts_submit cost 0.00012111663818359375 seconds
DEBUG 01-05 09:59:07.434215.434215 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.441192.441192 mlpmodule.py:704] group tensors cost 0.006203651428222656 s
DEBUG 01-05 09:59:07.444530.444530 mlpmodule.py:742] pad cost 0.0019526481628417969 s
DEBUG 01-05 09:59:07.444137.444137 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:59:07.444828.444828 mlpmodule.py:753] move to cpu cost 3.981590270996094e-05 s
DEBUG 01-05 09:59:07.453067.453067 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.454887.454887 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.454845.454845 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 09:59:07.454611.454611 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.472743.472743 mlpmodule.py:793] group einsum cost 0.027801513671875 s
DEBUG 01-05 09:59:07.473242.473242 mlpmodule.py:801] cpy2cputensor cost 0.0006177425384521484 s
DEBUG 01-05 09:59:07.477001.477001 cuda_h.py:19] end wait_cetm_experts cost 0.04256033897399902 seconds
DEBUG 01-05 09:59:07.477477.477477 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.478076.478076 cuda_h.py:19] end gpu_sexperts cost 0.0006394386291503906 seconds
DEBUG 01-05 09:59:07.478886.478886 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.478180.478180 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 09:59:07.478460.478460 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.478461.478461 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c84cae40-5cab-4f14-9877-2400c9de08bd
INFO 01-05 09:59:07.485557.485557 client.py:127] Model loaded
DEBUG 01-05 09:59:07.485838.485838 cuda_h.py:19] end wait_experts cost 0.006704807281494141 seconds
DEBUG 01-05 09:59:07.485070.485070 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.485595.485595 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.486700.486700 mlpmodule.py:531] gpu group tensors cost 0.00067901611328125 s
DEBUG 01-05 09:59:07.488946.488946 mlpmodule.py:564] gpu pad cost 0.0021190643310546875 s
DEBUG 01-05 09:59:07.488827.488827 mlpmodule.py:582] gpu group einsum cost 0.0005490779876708984 s
DEBUG 01-05 09:59:07.489166.489166 mlpmodule.py:662]  experts func einsum cost 0.054708003997802734 s
DEBUG 01-05 09:59:07.492539.492539 mlpmodule.py:611] gpu experts func einsum cost 0.007330179214477539 s
DEBUG 01-05 09:59:07.492285.492285 cuda_h.py:19] end gpu_experts cost 0.007568836212158203 seconds
DEBUG 01-05 09:59:07.492838.492838 cuda_h.py:19] end layer_moe_generate_3 cost 0.0663003921508789 seconds
DEBUG 01-05 09:59:07.493268.493268 lmp.py:217] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 09:59:07.493838.493838 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 09:59:07.493534.493534 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:59:07.493297.493297 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:59:07.493193.493193 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.3855438232421875e-05 seconds
DEBUG 01-05 09:59:07.493824.493824 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 8.249282836914062e-05 seconds
DEBUG 01-05 09:59:07.493851.493851 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.493754.493754 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.493368.493368 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.493926.493926 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.494210.494210 cuda_h.py:19] end allocate_cuda_memory cost 0.00031065940856933594 seconds
DEBUG 01-05 09:59:07.494848.494848 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.494088.494088 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.494023.494023 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.494157.494157 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b442a2ff-2568-4a54-a2c4-9145959260b4
DEBUG 01-05 09:59:07.494888.494888 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.494459.494459 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.495459.495459 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b442a2ff-2568-4a54-a2c4-9145959260b4
DEBUG 01-05 09:59:07.495296.495296 cuda_h.py:19] end load_into_gpu_async cost 0.0010652542114257812 seconds
DEBUG 01-05 09:59:07.495614.495614 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.495167.495167 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-05 09:59:07.495539.495539 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017018318176269531 seconds
INFO 01-05 09:59:07.496927.496927 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b442a2ff-2568-4a54-a2c4-9145959260b4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.498667.498667 cuda_h.py:19] end self_attn cost 0.004370212554931641 seconds
DEBUG 01-05 09:59:07.499388.499388 cuda_h.py:19] end iln_self_attn_paln cost 0.005910396575927734 seconds
DEBUG 01-05 09:59:07.499523.499523 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 09:59:07.499623.499623 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.500609.500609 cuda_h.py:19] end gate cost 0.0007233619689941406 seconds
DEBUG 01-05 09:59:07.500538.500538 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.500917.500917 lmp.py:365] 
DEBUG 01-05 09:59:07.500917.500917 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.500349.500349 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.500860.500860 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.500033.500033 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.500106.500106 lmp.py:369] 
DEBUG 01-05 09:59:07.500106.500106 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.500895.500895 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.500452.500452 lmp.py:376]   Expert 45 |      3 | CPU
DEBUG 01-05 09:59:07.500764.500764 lmp.py:376]   Expert  9 |     21 | CPU
DEBUG 01-05 09:59:07.500361.500361 lmp.py:376]   Expert 11 |     28 | CPU
DEBUG 01-05 09:59:07.500481.500481 lmp.py:376]   Expert  3 |     29 | CPU
DEBUG 01-05 09:59:07.500600.500600 lmp.py:376]   Expert 60 |     44 | CPU
DEBUG 01-05 09:59:07.500389.500389 lmp.py:376]   Expert 41 |     46 | CPU
DEBUG 01-05 09:59:07.500747.500747 lmp.py:376]   Expert 25 |     55 | CPU
DEBUG 01-05 09:59:07.500867.500867 lmp.py:376]   Expert 48 |     57 | CPU
DEBUG 01-05 09:59:07.501464.501464 lmp.py:376]   Expert 51 |     58 | CPU
DEBUG 01-05 09:59:07.501584.501584 lmp.py:376]   Expert 36 |     61 | CPU
DEBUG 01-05 09:59:07.501703.501703 lmp.py:376]   Expert 34 |     62 | CPU
DEBUG 01-05 09:59:07.501300.501300 lmp.py:376]   Expert 53 |     66 | CPU
DEBUG 01-05 09:59:07.501420.501420 lmp.py:376]   Expert 14 |     73 | CPU
DEBUG 01-05 09:59:07.501778.501778 lmp.py:376]   Expert 24 |     73 | CPU
DEBUG 01-05 09:59:07.501090.501090 lmp.py:376]   Expert 58 |     77 | CPU
DEBUG 01-05 09:59:07.501687.501687 lmp.py:376]   Expert  6 |     79 | CPU
DEBUG 01-05 09:59:07.501806.501806 lmp.py:376]   Expert  7 |     79 | CPU
DEBUG 01-05 09:59:07.501926.501926 lmp.py:376]   Expert 31 |     96 | CPU
DEBUG 01-05 09:59:07.501808.501808 lmp.py:376]   Expert 13 |     98 | CPU
DEBUG 01-05 09:59:07.501927.501927 lmp.py:376]   Expert 55 |    106 | CPU
DEBUG 01-05 09:59:07.501809.501809 lmp.py:376]   Expert 47 |    107 | CPU
DEBUG 01-05 09:59:07.501929.501929 lmp.py:376]   Expert 40 |    114 | CPU
DEBUG 01-05 09:59:07.501572.501572 lmp.py:376]   Expert 56 |    115 | CPU
DEBUG 01-05 09:59:07.501884.501884 lmp.py:376]   Expert  2 |    118 | CPU
DEBUG 01-05 09:59:07.501719.501719 lmp.py:376]   Expert  4 |    118 | CPU
DEBUG 01-05 09:59:07.501077.501077 lmp.py:376]   Expert 23 |    118 | CPU
DEBUG 01-05 09:59:07.501958.501958 lmp.py:376]   Expert 50 |    120 | CPU
DEBUG 01-05 09:59:07.501078.501078 lmp.py:376]   Expert 28 |    122 | CPU
DEBUG 01-05 09:59:07.501959.501959 lmp.py:376]   Expert 16 |    126 | CPU
DEBUG 01-05 09:59:07.501079.501079 lmp.py:376]   Expert 33 |    129 | CPU
DEBUG 01-05 09:59:07.501961.501961 lmp.py:376]   Expert 44 |    144 | CPU
DEBUG 01-05 09:59:07.501080.501080 lmp.py:376]   Expert 21 |    146 | CPU
DEBUG 01-05 09:59:07.501439.501439 lmp.py:376]   Expert  8 |    147 | GPU
DEBUG 01-05 09:59:07.501274.501274 lmp.py:376]   Expert 10 |    147 | GPU
DEBUG 01-05 09:59:07.501394.501394 lmp.py:376]   Expert 54 |    147 | GPU
DEBUG 01-05 09:59:07.501275.501275 lmp.py:376]   Expert 37 |    152 | GPU
DEBUG 01-05 09:59:07.501156.501156 lmp.py:376]   Expert 22 |    160 | GPU
DEBUG 01-05 09:59:07.501038.501038 lmp.py:376]   Expert 26 |    160 | GPU
DEBUG 01-05 09:59:07.501919.501919 lmp.py:376]   Expert 18 |    166 | GPU
DEBUG 01-05 09:59:07.501801.501801 lmp.py:376]   Expert 57 |    166 | GPU
DEBUG 01-05 09:59:07.501159.501159 lmp.py:376]   Expert 15 |    180 | GPU
DEBUG 01-05 09:59:07.501040.501040 lmp.py:376]   Expert 27 |    206 | GPU
DEBUG 01-05 09:59:07.501922.501922 lmp.py:376]   Expert 61 |    208 | GPU
DEBUG 01-05 09:59:07.501995.501995 lmp.py:376]   Expert 20 |    210 | GPU
DEBUG 01-05 09:59:07.501592.501592 lmp.py:376]   Expert 46 |    226 | GPU
DEBUG 01-05 09:59:07.501473.501473 lmp.py:376]   Expert 17 |    254 | GPU
DEBUG 01-05 09:59:07.501593.501593 lmp.py:376]   Expert  1 |    256 | GPU
DEBUG 01-05 09:59:07.501474.501474 lmp.py:376]   Expert 63 |    256 | GPU
DEBUG 01-05 09:59:07.501356.501356 lmp.py:376]   Expert 29 |    281 | GPU
DEBUG 01-05 09:59:07.501475.501475 lmp.py:376]   Expert 42 |    284 | GPU
DEBUG 01-05 09:59:07.501595.501595 lmp.py:376]   Expert  0 |    310 | GPU
DEBUG 01-05 09:59:07.501477.501477 lmp.py:376]   Expert 62 |    325 | GPU
DEBUG 01-05 09:59:07.501120.501120 lmp.py:376]   Expert 52 |    326 | GPU
DEBUG 01-05 09:59:07.501147.501147 lmp.py:376]   Expert 32 |    331 | GPU
DEBUG 01-05 09:59:07.501651.501651 lmp.py:376]   Expert 19 |    360 | GPU
DEBUG 01-05 09:59:07.501678.501678 lmp.py:376]   Expert 38 |    364 | GPU
DEBUG 01-05 09:59:07.501751.501751 lmp.py:376]   Expert 35 |    383 | GPU
DEBUG 01-05 09:59:07.501063.501063 lmp.py:376]   Expert 39 |    443 | GPU
DEBUG 01-05 09:59:07.501898.501898 lmp.py:376]   Expert 30 |    446 | GPU
DEBUG 01-05 09:59:07.501972.501972 lmp.py:376]   Expert 49 |    458 | GPU
DEBUG 01-05 09:59:07.501807.501807 lmp.py:376]   Expert 12 |    480 | GPU
DEBUG 01-05 09:59:07.501404.501404 lmp.py:376]   Expert  5 |    483 | GPU
DEBUG 01-05 09:59:07.502239.502239 lmp.py:376]   Expert 43 |    632 | GPU
DEBUG 01-05 09:59:07.502074.502074 lmp.py:376]   Expert 59 |    653 | GPU
DEBUG 01-05 09:59:07.502816.502816 lmp.py:377] 
DEBUG 01-05 09:59:07.502816.502816 lmp.py:377]   CPU total tokens: 2688 (21.9%)
DEBUG 01-05 09:59:07.502082.502082 lmp.py:378]   GPU total tokens: 9600 (78.1%)
DEBUG 01-05 09:59:07.502354.502354 cuda_h.py:19] end experts_map_get cost 0.0017991065979003906 seconds
DEBUG 01-05 09:59:07.502381.502381 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.502449.502449 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.502818.502818 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.502449.502449 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
INFO 01-05 09:59:07.502233.502233 client.py:127] Model loaded
DEBUG 01-05 09:59:07.502826.502826 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.502622.502622 cuda_h.py:19] end sllm_worker_task cost 0.009181022644042969 seconds
DEBUG 01-05 09:59:07.502723.502723 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.502567.502567 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.502793.502793 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32b0a283-fab9-49fc-aefb-466dca07f647
DEBUG 01-05 09:59:07.503223.503223 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.503059.503059 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32b0a283-fab9-49fc-aefb-466dca07f647
DEBUG 01-05 09:59:07.503802.503802 cuda_h.py:19] end load_into_gpu_async cost 0.0011835098266601562 seconds
DEBUG 01-05 09:59:07.504843.504843 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.504299.504299 cuda_h.py:19] end restore_tensors2 cost 0.0003314018249511719 seconds
DEBUG 01-05 09:59:07.504175.504175 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022656917572021484 seconds
DEBUG 01-05 09:59:07.507753.507753 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053348541259765625 seconds
DEBUG 01-05 09:59:07.507397.507397 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.507725.507725 lmp.py:423] 
DEBUG 01-05 09:59:07.507725.507725 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.507813.507813 cuda_h.py:19] end cpu_experts_submit cost 0.00013566017150878906 seconds
DEBUG 01-05 09:59:07.507755.507755 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.513065.513065 mlpmodule.py:704] group tensors cost 0.005703926086425781 s
DEBUG 01-05 09:59:07.516361.516361 mlpmodule.py:742] pad cost 0.0017697811126708984 s
DEBUG 01-05 09:59:07.516491.516491 mlpmodule.py:748] create cpu tensor cost 6.246566772460938e-05 s
DEBUG 01-05 09:59:07.516494.516494 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-05 09:59:07.525868.525868 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.525728.525728 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.525473.525473 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 09:59:07.525397.525397 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.543103.543103 mlpmodule.py:793] group einsum cost 0.0266268253326416 s
DEBUG 01-05 09:59:07.543890.543890 mlpmodule.py:801] cpy2cputensor cost 0.0005519390106201172 s
DEBUG 01-05 09:59:07.548437.548437 cuda_h.py:19] end wait_cetm_experts cost 0.04048013687133789 seconds
DEBUG 01-05 09:59:07.548484.548484 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.549382.549382 cuda_h.py:19] end gpu_sexperts cost 0.0006475448608398438 seconds
DEBUG 01-05 09:59:07.549523.549523 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.549102.549102 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:07.549096.549096 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.549097.549097 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32b0a283-fab9-49fc-aefb-466dca07f647
INFO 01-05 09:59:07.558295.558295 client.py:127] Model loaded
DEBUG 01-05 09:59:07.558258.558258 cuda_h.py:19] end wait_experts cost 0.008755922317504883 seconds
DEBUG 01-05 09:59:07.558299.558299 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.558817.558817 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.558566.558566 mlpmodule.py:531] gpu group tensors cost 0.0005426406860351562 s
DEBUG 01-05 09:59:07.560023.560023 mlpmodule.py:564] gpu pad cost 0.0019271373748779297 s
DEBUG 01-05 09:59:07.561617.561617 mlpmodule.py:662]  experts func einsum cost 0.053260087966918945 s
DEBUG 01-05 09:59:07.561288.561288 mlpmodule.py:582] gpu group einsum cost 0.0007112026214599609 s
DEBUG 01-05 09:59:07.565063.565063 mlpmodule.py:611] gpu experts func einsum cost 0.00708770751953125 s
DEBUG 01-05 09:59:07.565384.565384 cuda_h.py:19] end gpu_experts cost 0.007266998291015625 seconds
DEBUG 01-05 09:59:07.565175.565175 cuda_h.py:19] end layer_moe_generate_4 cost 0.06614255905151367 seconds
DEBUG 01-05 09:59:07.565513.565513 lmp.py:217] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 09:59:07.565798.565798 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 09:59:07.565210.565210 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:59:07.565132.565132 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:59:07.565213.565213 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:07.565275.565275 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 8.130073547363281e-05 seconds
DEBUG 01-05 09:59:07.566449.566449 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.566086.566086 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.566294.566294 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.566198.566198 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.566025.566025 cuda_h.py:19] end allocate_cuda_memory cost 0.0003218650817871094 seconds
DEBUG 01-05 09:59:07.566082.566082 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.566944.566944 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.566588.566588 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.566006.566006 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2f74df7-c2bc-43de-8a58-8eca463fbec9
DEBUG 01-05 09:59:07.566453.566453 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.567383.567383 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.568200.568200 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2f74df7-c2bc-43de-8a58-8eca463fbec9
DEBUG 01-05 09:59:07.568467.568467 cuda_h.py:19] end load_into_gpu_async cost 0.0015797615051269531 seconds
DEBUG 01-05 09:59:07.568177.568177 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.568736.568736 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-05 09:59:07.568254.568254 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002276897430419922 seconds
INFO 01-05 09:59:07.569907.569907 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2f74df7-c2bc-43de-8a58-8eca463fbec9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.571854.571854 cuda_h.py:19] end self_attn cost 0.0038819313049316406 seconds
DEBUG 01-05 09:59:07.571005.571005 cuda_h.py:19] end iln_self_attn_paln cost 0.005349397659301758 seconds
DEBUG 01-05 09:59:07.571279.571279 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 09:59:07.571618.571618 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.572842.572842 cuda_h.py:19] end gate cost 0.0007250308990478516 seconds
DEBUG 01-05 09:59:07.572625.572625 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.572620.572620 lmp.py:365] 
DEBUG 01-05 09:59:07.572620.572620 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.572138.572138 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.572172.572172 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.573629.573629 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.573418.573418 lmp.py:369] 
DEBUG 01-05 09:59:07.573418.573418 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.573492.573492 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.573002.573002 lmp.py:376]   Expert 14 |     18 | CPU
DEBUG 01-05 09:59:07.573745.573745 lmp.py:376]   Expert 18 |     29 | CPU
DEBUG 01-05 09:59:07.573580.573580 lmp.py:376]   Expert 15 |     41 | CPU
DEBUG 01-05 09:59:07.573700.573700 lmp.py:376]   Expert  2 |     44 | CPU
DEBUG 01-05 09:59:07.573581.573581 lmp.py:376]   Expert 60 |     46 | CPU
DEBUG 01-05 09:59:07.573701.573701 lmp.py:376]   Expert 23 |     47 | CPU
DEBUG 01-05 09:59:07.573059.573059 lmp.py:376]   Expert 39 |     49 | CPU
DEBUG 01-05 09:59:07.573179.573179 lmp.py:376]   Expert 30 |     51 | CPU
DEBUG 01-05 09:59:07.573299.573299 lmp.py:376]   Expert 17 |     53 | CPU
DEBUG 01-05 09:59:07.573419.573419 lmp.py:376]   Expert 45 |     55 | CPU
DEBUG 01-05 09:59:07.573062.573062 lmp.py:376]   Expert 34 |     58 | CPU
DEBUG 01-05 09:59:07.573374.573374 lmp.py:376]   Expert 52 |     79 | CPU
DEBUG 01-05 09:59:07.573685.573685 lmp.py:376]   Expert 27 |     81 | CPU
DEBUG 01-05 09:59:07.573282.573282 lmp.py:376]   Expert  9 |     84 | CPU
DEBUG 01-05 09:59:07.573117.573117 lmp.py:376]   Expert 28 |     90 | CPU
DEBUG 01-05 09:59:07.573952.573952 lmp.py:376]   Expert 47 |     90 | CPU
DEBUG 01-05 09:59:07.573787.573787 lmp.py:376]   Expert 55 |     95 | CPU
DEBUG 01-05 09:59:07.573099.573099 lmp.py:376]   Expert 22 |     99 | CPU
DEBUG 01-05 09:59:07.573457.573457 lmp.py:376]   Expert  3 |    101 | CPU
DEBUG 01-05 09:59:07.573100.573100 lmp.py:376]   Expert 62 |    107 | CPU
DEBUG 01-05 09:59:07.573982.573982 lmp.py:376]   Expert  4 |    115 | CPU
DEBUG 01-05 09:59:07.573625.573625 lmp.py:376]   Expert  8 |    116 | CPU
DEBUG 01-05 09:59:07.573175.573175 lmp.py:376]   Expert  1 |    120 | CPU
DEBUG 01-05 09:59:07.573010.573010 lmp.py:376]   Expert 40 |    120 | CPU
DEBUG 01-05 09:59:07.573845.573845 lmp.py:376]   Expert 63 |    124 | CPU
DEBUG 01-05 09:59:07.573203.573203 lmp.py:376]   Expert 26 |    127 | CPU
DEBUG 01-05 09:59:07.573469.573469 lmp.py:376]   Expert 19 |    129 | CPU
DEBUG 01-05 09:59:07.573019.573019 lmp.py:376]   Expert 43 |    130 | CPU
DEBUG 01-05 09:59:07.573954.573954 lmp.py:376]   Expert 41 |    133 | CPU
DEBUG 01-05 09:59:07.573550.573550 lmp.py:376]   Expert 48 |    137 | CPU
DEBUG 01-05 09:59:07.573147.573147 lmp.py:376]   Expert 24 |    141 | CPU
DEBUG 01-05 09:59:07.573982.573982 lmp.py:376]   Expert 51 |    145 | CPU
DEBUG 01-05 09:59:07.573102.573102 lmp.py:376]   Expert 58 |    147 | GPU
DEBUG 01-05 09:59:07.573745.573745 lmp.py:376]   Expert 54 |    148 | GPU
DEBUG 01-05 09:59:07.573388.573388 lmp.py:376]   Expert 10 |    154 | GPU
DEBUG 01-05 09:59:07.573269.573269 lmp.py:376]   Expert 11 |    156 | GPU
DEBUG 01-05 09:59:07.573912.573912 lmp.py:376]   Expert 25 |    156 | GPU
DEBUG 01-05 09:59:07.573078.573078 lmp.py:376]   Expert 38 |    157 | GPU
DEBUG 01-05 09:59:07.573483.573483 lmp.py:376]   Expert 44 |    161 | GPU
DEBUG 01-05 09:59:07.573888.573888 lmp.py:376]   Expert 29 |    162 | GPU
DEBUG 01-05 09:59:07.573531.573531 lmp.py:376]   Expert 61 |    163 | GPU
DEBUG 01-05 09:59:07.573935.573935 lmp.py:376]   Expert 56 |    164 | GPU
DEBUG 01-05 09:59:07.573055.573055 lmp.py:376]   Expert  0 |    177 | GPU
DEBUG 01-05 09:59:07.573605.573605 lmp.py:376]   Expert 46 |    192 | GPU
DEBUG 01-05 09:59:07.573963.573963 lmp.py:376]   Expert 50 |    198 | GPU
DEBUG 01-05 09:59:07.573322.573322 lmp.py:376]   Expert  5 |    207 | GPU
DEBUG 01-05 09:59:07.573680.573680 lmp.py:376]   Expert 36 |    218 | GPU
DEBUG 01-05 09:59:07.573038.573038 lmp.py:376]   Expert 16 |    233 | GPU
DEBUG 01-05 09:59:07.573873.573873 lmp.py:376]   Expert 32 |    233 | GPU
DEBUG 01-05 09:59:07.573516.573516 lmp.py:376]   Expert 12 |    236 | GPU
DEBUG 01-05 09:59:07.573159.573159 lmp.py:376]   Expert 35 |    247 | GPU
DEBUG 01-05 09:59:07.574802.574802 lmp.py:376]   Expert 57 |    249 | GPU
DEBUG 01-05 09:59:07.574684.574684 lmp.py:376]   Expert  7 |    250 | GPU
DEBUG 01-05 09:59:07.574088.574088 lmp.py:376]   Expert 42 |    278 | GPU
DEBUG 01-05 09:59:07.574493.574493 lmp.py:376]   Expert 21 |    286 | GPU
DEBUG 01-05 09:59:07.574897.574897 lmp.py:376]   Expert 59 |    344 | GPU
DEBUG 01-05 09:59:07.574302.574302 lmp.py:376]   Expert 20 |    384 | GPU
DEBUG 01-05 09:59:07.574422.574422 lmp.py:376]   Expert 13 |    395 | GPU
DEBUG 01-05 09:59:07.574780.574780 lmp.py:376]   Expert 33 |    446 | GPU
DEBUG 01-05 09:59:07.574900.574900 lmp.py:376]   Expert 31 |    451 | GPU
DEBUG 01-05 09:59:07.574735.574735 lmp.py:376]   Expert  6 |    464 | GPU
DEBUG 01-05 09:59:07.574093.574093 lmp.py:376]   Expert 49 |    519 | GPU
DEBUG 01-05 09:59:07.574405.574405 lmp.py:376]   Expert 37 |    611 | GPU
DEBUG 01-05 09:59:07.574240.574240 lmp.py:376]   Expert 53 |   1248 | GPU
DEBUG 01-05 09:59:07.574075.574075 lmp.py:377] 
DEBUG 01-05 09:59:07.574075.574075 lmp.py:377]   CPU total tokens: 2854 (23.2%)
DEBUG 01-05 09:59:07.574148.574148 lmp.py:378]   GPU total tokens: 9434 (76.8%)
DEBUG 01-05 09:59:07.574275.574275 cuda_h.py:19] end experts_map_get cost 0.0017807483673095703 seconds
DEBUG 01-05 09:59:07.574110.574110 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.574171.574171 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.574209.574209 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.575816.575816 cuda_h.py:19] end allocate_cuda_memory cost 0.0010776519775390625 seconds
DEBUG 01-05 09:59:07.575050.575050 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.575620.575620 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.575814.575814 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.575755.575755 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a70fb7b7-41dc-423f-99d3-1498e29755d9
DEBUG 01-05 09:59:07.575377.575377 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.576621.576621 client.py:127] Model loaded
DEBUG 01-05 09:59:07.576868.576868 cuda_h.py:19] end sllm_worker_task cost 0.010227680206298828 seconds
INFO 01-05 09:59:07.577124.577124 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a70fb7b7-41dc-423f-99d3-1498e29755d9
DEBUG 01-05 09:59:07.577286.577286 cuda_h.py:19] end load_into_gpu_async cost 0.002263307571411133 seconds
DEBUG 01-05 09:59:07.578943.578943 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.578989.578989 cuda_h.py:19] end restore_tensors2 cost 0.00035691261291503906 seconds
DEBUG 01-05 09:59:07.578295.578295 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004068851470947266 seconds
DEBUG 01-05 09:59:07.581915.581915 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007200479507446289 seconds
DEBUG 01-05 09:59:07.581911.581911 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.581808.581808 lmp.py:423] 
DEBUG 01-05 09:59:07.581808.581808 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.581565.581565 cuda_h.py:19] end cpu_experts_submit cost 0.0001366138458251953 seconds
DEBUG 01-05 09:59:07.581845.581845 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.586399.586399 mlpmodule.py:704] group tensors cost 0.004922389984130859 s
DEBUG 01-05 09:59:07.589204.589204 mlpmodule.py:742] pad cost 0.0018966197967529297 s
DEBUG 01-05 09:59:07.589240.589240 mlpmodule.py:748] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-05 09:59:07.589898.589898 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-05 09:59:07.599676.599676 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.599563.599563 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.599559.599559 mlpmodule.py:773] group_w3 first element: -0.0277099609375
WARNING 01-05 09:59:07.600583.600583 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.616554.616554 mlpmodule.py:793] group einsum cost 0.027025938034057617 s
DEBUG 01-05 09:59:07.617839.617839 mlpmodule.py:801] cpy2cputensor cost 0.0005974769592285156 s
DEBUG 01-05 09:59:07.628817.628817 cuda_h.py:19] end wait_cetm_experts cost 0.04620957374572754 seconds
DEBUG 01-05 09:59:07.628893.628893 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.628846.628846 cuda_h.py:19] end gpu_sexperts cost 0.0005190372467041016 seconds
DEBUG 01-05 09:59:07.628404.628404 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.628499.628499 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:07.628586.628586 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.628018.628018 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a70fb7b7-41dc-423f-99d3-1498e29755d9
INFO 01-05 09:59:07.632252.632252 client.py:127] Model loaded
DEBUG 01-05 09:59:07.632419.632419 cuda_h.py:19] end wait_experts cost 0.0032885074615478516 seconds
DEBUG 01-05 09:59:07.632976.632976 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.632202.632202 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.632652.632652 mlpmodule.py:531] gpu group tensors cost 0.0005102157592773438 s
DEBUG 01-05 09:59:07.634789.634789 mlpmodule.py:564] gpu pad cost 0.001455545425415039 s
DEBUG 01-05 09:59:07.634679.634679 mlpmodule.py:582] gpu group einsum cost 0.00042438507080078125 s
DEBUG 01-05 09:59:07.637308.637308 mlpmodule.py:611] gpu experts func einsum cost 0.005277395248413086 s
DEBUG 01-05 09:59:07.637086.637086 cuda_h.py:19] end gpu_experts cost 0.005427837371826172 seconds
DEBUG 01-05 09:59:07.637877.637877 cuda_h.py:19] end layer_moe_generate_5 cost 0.06610369682312012 seconds
DEBUG 01-05 09:59:07.637479.637479 lmp.py:217] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 09:59:07.637533.637533 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 09:59:07.637467.637467 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:59:07.638661.638661 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:59:07.638828.638828 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.765655517578125e-05 seconds
DEBUG 01-05 09:59:07.638889.638889 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.295608520507812e-05 seconds
DEBUG 01-05 09:59:07.638632.638632 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.638322.638322 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.638901.638901 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.638361.638361 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.639413.639413 cuda_h.py:19] end allocate_cuda_memory cost 0.0008902549743652344 seconds
DEBUG 01-05 09:59:07.639113.639113 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.639050.639050 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.639817.639817 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.639032.639032 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0278d556-e4cd-4ac4-8279-4c0a88af2ec4
DEBUG 01-05 09:59:07.639720.639720 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.640665.640665 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.641365.641365 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0278d556-e4cd-4ac4-8279-4c0a88af2ec4
DEBUG 01-05 09:59:07.641211.641211 cuda_h.py:19] end load_into_gpu_async cost 0.0016241073608398438 seconds
DEBUG 01-05 09:59:07.641591.641591 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.641790.641790 cuda_h.py:19] end restore_tensors2 cost 0.00014472007751464844 seconds
DEBUG 01-05 09:59:07.641973.641973 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032684803009033203 seconds
INFO 01-05 09:59:07.642302.642302 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0278d556-e4cd-4ac4-8279-4c0a88af2ec4
DEBUG 01-05 09:59:07.644071.644071 mlpmodule.py:662]  experts func einsum cost 0.06258273124694824 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.647803.647803 cuda_h.py:19] end self_attn cost 0.00638890266418457 seconds
DEBUG 01-05 09:59:07.647408.647408 cuda_h.py:19] end iln_self_attn_paln cost 0.009313583374023438 seconds
DEBUG 01-05 09:59:07.647868.647868 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 09:59:07.647771.647771 cuda_h.py:10] start gate
INFO 01-05 09:59:07.647465.647465 client.py:127] Model loaded
DEBUG 01-05 09:59:07.648363.648363 cuda_h.py:19] end sllm_worker_task cost 0.009845972061157227 seconds
DEBUG 01-05 09:59:07.648157.648157 cuda_h.py:19] end gate cost 0.0011692047119140625 seconds
DEBUG 01-05 09:59:07.648180.648180 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.649322.649322 lmp.py:365] 
DEBUG 01-05 09:59:07.649322.649322 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.649793.649793 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.649112.649112 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.649616.649616 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.649497.649497 lmp.py:369] 
DEBUG 01-05 09:59:07.649497.649497 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.649379.649379 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.649982.649982 lmp.py:376]   Expert  1 |     11 | CPU
DEBUG 01-05 09:59:07.649625.649625 lmp.py:376]   Expert  3 |     13 | CPU
DEBUG 01-05 09:59:07.649268.649268 lmp.py:376]   Expert 15 |     22 | CPU
DEBUG 01-05 09:59:07.649434.649434 lmp.py:376]   Expert 14 |     28 | CPU
DEBUG 01-05 09:59:07.649362.649362 lmp.py:376]   Expert 53 |     29 | CPU
DEBUG 01-05 09:59:07.649005.649005 lmp.py:376]   Expert 47 |     37 | CPU
DEBUG 01-05 09:59:07.649648.649648 lmp.py:376]   Expert 52 |     45 | CPU
DEBUG 01-05 09:59:07.649814.649814 lmp.py:376]   Expert 16 |     63 | CPU
DEBUG 01-05 09:59:07.649980.649980 lmp.py:376]   Expert 26 |     64 | CPU
DEBUG 01-05 09:59:07.649908.649908 lmp.py:376]   Expert 40 |     65 | CPU
DEBUG 01-05 09:59:07.649028.649028 lmp.py:376]   Expert 11 |     69 | CPU
DEBUG 01-05 09:59:07.649432.649432 lmp.py:376]   Expert 44 |     74 | CPU
DEBUG 01-05 09:59:07.649598.649598 lmp.py:376]   Expert 50 |     76 | CPU
DEBUG 01-05 09:59:07.649288.649288 lmp.py:376]   Expert 10 |     80 | CPU
DEBUG 01-05 09:59:07.649215.649215 lmp.py:376]   Expert 49 |     84 | CPU
DEBUG 01-05 09:59:07.649143.649143 lmp.py:376]   Expert  7 |     95 | CPU
DEBUG 01-05 09:59:07.649071.649071 lmp.py:376]   Expert 41 |     96 | CPU
DEBUG 01-05 09:59:07.649522.649522 lmp.py:376]   Expert 59 |    103 | CPU
DEBUG 01-05 09:59:07.649211.649211 lmp.py:376]   Expert 37 |    106 | CPU
DEBUG 01-05 09:59:07.649616.649616 lmp.py:376]   Expert 30 |    109 | CPU
DEBUG 01-05 09:59:07.649259.649259 lmp.py:376]   Expert 35 |    110 | CPU
DEBUG 01-05 09:59:07.649186.649186 lmp.py:376]   Expert 25 |    112 | CPU
DEBUG 01-05 09:59:07.649352.649352 lmp.py:376]   Expert 42 |    116 | CPU
DEBUG 01-05 09:59:07.649042.649042 lmp.py:376]   Expert  5 |    119 | CPU
DEBUG 01-05 09:59:07.650208.650208 lmp.py:376]   Expert 31 |    119 | CPU
DEBUG 01-05 09:59:07.650897.650897 lmp.py:376]   Expert 32 |    120 | CPU
DEBUG 01-05 09:59:07.650825.650825 lmp.py:376]   Expert 22 |    126 | CPU
DEBUG 01-05 09:59:07.650514.650514 lmp.py:376]   Expert 21 |    127 | CPU
DEBUG 01-05 09:59:07.650442.650442 lmp.py:376]   Expert 63 |    128 | CPU
DEBUG 01-05 09:59:07.650608.650608 lmp.py:376]   Expert 13 |    135 | CPU
DEBUG 01-05 09:59:07.650013.650013 lmp.py:376]   Expert 62 |    135 | CPU
DEBUG 01-05 09:59:07.650179.650179 lmp.py:376]   Expert 34 |    137 | CPU
DEBUG 01-05 09:59:07.650106.650106 lmp.py:376]   Expert 54 |    140 | GPU
DEBUG 01-05 09:59:07.650796.650796 lmp.py:376]   Expert 58 |    141 | GPU
DEBUG 01-05 09:59:07.650485.650485 lmp.py:376]   Expert 51 |    142 | GPU
DEBUG 01-05 09:59:07.650936.650936 lmp.py:376]   Expert 61 |    149 | GPU
DEBUG 01-05 09:59:07.650625.650625 lmp.py:376]   Expert  4 |    153 | GPU
DEBUG 01-05 09:59:07.650315.650315 lmp.py:376]   Expert  8 |    160 | GPU
DEBUG 01-05 09:59:07.650481.650481 lmp.py:376]   Expert 28 |    162 | GPU
DEBUG 01-05 09:59:07.650885.650885 lmp.py:376]   Expert 38 |    165 | GPU
DEBUG 01-05 09:59:07.650813.650813 lmp.py:376]   Expert  6 |    169 | GPU
DEBUG 01-05 09:59:07.650741.650741 lmp.py:376]   Expert  9 |    172 | GPU
DEBUG 01-05 09:59:07.650953.650953 lmp.py:376]   Expert 12 |    184 | GPU
DEBUG 01-05 09:59:07.650642.650642 lmp.py:376]   Expert  0 |    185 | GPU
DEBUG 01-05 09:59:07.650570.650570 lmp.py:376]   Expert 57 |    195 | GPU
DEBUG 01-05 09:59:07.650259.650259 lmp.py:376]   Expert 29 |    203 | GPU
DEBUG 01-05 09:59:07.650187.650187 lmp.py:376]   Expert 46 |    214 | GPU
DEBUG 01-05 09:59:07.650830.650830 lmp.py:376]   Expert  2 |    235 | GPU
DEBUG 01-05 09:59:07.650235.650235 lmp.py:376]   Expert 17 |    244 | GPU
DEBUG 01-05 09:59:07.650162.650162 lmp.py:376]   Expert 45 |    263 | GPU
DEBUG 01-05 09:59:07.650852.650852 lmp.py:376]   Expert 24 |    264 | GPU
DEBUG 01-05 09:59:07.650303.650303 lmp.py:376]   Expert 23 |    275 | GPU
DEBUG 01-05 09:59:07.650754.650754 lmp.py:376]   Expert 19 |    277 | GPU
DEBUG 01-05 09:59:07.650443.650443 lmp.py:376]   Expert 43 |    280 | GPU
DEBUG 01-05 09:59:07.650132.650132 lmp.py:376]   Expert 33 |    293 | GPU
DEBUG 01-05 09:59:07.650583.650583 lmp.py:376]   Expert 20 |    304 | GPU
DEBUG 01-05 09:59:07.650948.650948 lmp.py:376]   Expert 55 |    339 | GPU
DEBUG 01-05 09:59:07.650829.650829 lmp.py:376]   Expert 48 |    350 | GPU
DEBUG 01-05 09:59:07.650519.650519 lmp.py:376]   Expert 18 |    438 | GPU
DEBUG 01-05 09:59:07.650208.650208 lmp.py:376]   Expert 27 |    465 | GPU
DEBUG 01-05 09:59:07.650659.650659 lmp.py:376]   Expert 39 |    501 | GPU
DEBUG 01-05 09:59:07.650110.650110 lmp.py:376]   Expert 60 |    744 | GPU
DEBUG 01-05 09:59:07.650561.650561 lmp.py:376]   Expert 56 |    856 | GPU
DEBUG 01-05 09:59:07.650250.650250 lmp.py:376]   Expert 36 |    873 | GPU
DEBUG 01-05 09:59:07.650655.650655 lmp.py:377] 
DEBUG 01-05 09:59:07.650655.650655 lmp.py:377]   CPU total tokens: 2753 (22.4%)
DEBUG 01-05 09:59:07.650297.650297 lmp.py:378]   GPU total tokens: 9535 (77.6%)
DEBUG 01-05 09:59:07.650901.650901 cuda_h.py:19] end experts_map_get cost 0.0017135143280029297 seconds
DEBUG 01-05 09:59:07.650498.650498 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.650797.650797 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.650212.650212 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.651107.651107 cuda_h.py:19] end allocate_cuda_memory cost 0.00020241737365722656 seconds
DEBUG 01-05 09:59:07.651566.651566 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.651369.651369 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.651840.651840 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.651251.651251 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c90304f4-e02e-4e41-bac1-bcaf2ab4c030
DEBUG 01-05 09:59:07.651721.651721 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.652562.652562 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c90304f4-e02e-4e41-bac1-bcaf2ab4c030
DEBUG 01-05 09:59:07.652229.652229 cuda_h.py:19] end load_into_gpu_async cost 0.0013532638549804688 seconds
DEBUG 01-05 09:59:07.652007.652007 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.653480.653480 cuda_h.py:19] end restore_tensors2 cost 0.00042366981506347656 seconds
DEBUG 01-05 09:59:07.653177.653177 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002429962158203125 seconds
DEBUG 01-05 09:59:07.655739.655739 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004996299743652344 seconds
DEBUG 01-05 09:59:07.655807.655807 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.655862.655862 lmp.py:423] 
DEBUG 01-05 09:59:07.655862.655862 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.655805.655805 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-05 09:59:07.655984.655984 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.666665.666665 mlpmodule.py:704] group tensors cost 0.010244369506835938 s
DEBUG 01-05 09:59:07.669825.669825 mlpmodule.py:742] pad cost 0.0019378662109375 s
DEBUG 01-05 09:59:07.669220.669220 mlpmodule.py:748] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-05 09:59:07.669719.669719 mlpmodule.py:753] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-05 09:59:07.679329.679329 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.679441.679441 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.679007.679007 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 09:59:07.679859.679859 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.697695.697695 mlpmodule.py:793] group einsum cost 0.02865147590637207 s
DEBUG 01-05 09:59:07.698495.698495 mlpmodule.py:801] cpy2cputensor cost 0.0005567073822021484 s
DEBUG 01-05 09:59:07.703938.703938 cuda_h.py:19] end wait_cetm_experts cost 0.04718375205993652 seconds
DEBUG 01-05 09:59:07.703844.703844 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.704335.704335 cuda_h.py:19] end gpu_sexperts cost 0.0005640983581542969 seconds
DEBUG 01-05 09:59:07.704330.704330 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.704902.704902 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:07.704751.704751 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.704414.704414 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c90304f4-e02e-4e41-bac1-bcaf2ab4c030
INFO 01-05 09:59:07.706441.706441 client.py:127] Model loaded
DEBUG 01-05 09:59:07.706582.706582 cuda_h.py:19] end wait_experts cost 0.0020530223846435547 seconds
DEBUG 01-05 09:59:07.706146.706146 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.706664.706664 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.707860.707860 mlpmodule.py:531] gpu group tensors cost 0.0006208419799804688 s
DEBUG 01-05 09:59:07.708631.708631 mlpmodule.py:564] gpu pad cost 0.0018100738525390625 s
DEBUG 01-05 09:59:07.709254.709254 mlpmodule.py:582] gpu group einsum cost 0.0005140304565429688 s
DEBUG 01-05 09:59:07.713493.713493 mlpmodule.py:611] gpu experts func einsum cost 0.006667137145996094 s
DEBUG 01-05 09:59:07.713378.713378 cuda_h.py:19] end gpu_experts cost 0.006882429122924805 seconds
DEBUG 01-05 09:59:07.713500.713500 cuda_h.py:19] end layer_moe_generate_6 cost 0.06568384170532227 seconds
DEBUG 01-05 09:59:07.713917.713917 lmp.py:217] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 09:59:07.713256.713256 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 09:59:07.713436.713436 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:59:07.713146.713146 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:59:07.713373.713373 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:07.713268.713268 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.175041198730469e-05 seconds
DEBUG 01-05 09:59:07.713772.713772 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.713894.713894 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.713010.713010 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.713508.713508 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.717948.717948 cuda_h.py:19] end allocate_cuda_memory cost 0.0033779144287109375 seconds
DEBUG 01-05 09:59:07.717389.717389 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.717490.717490 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.717504.717504 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.717115.717115 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 63bb8529-07c6-4bee-9934-fcaf64489d22
DEBUG 01-05 09:59:07.717270.717270 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.717166.717166 mlpmodule.py:662]  experts func einsum cost 0.06181788444519043 s
DEBUG 01-05 09:59:07.718014.718014 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.718807.718807 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 63bb8529-07c6-4bee-9934-fcaf64489d22
DEBUG 01-05 09:59:07.718650.718650 cuda_h.py:19] end load_into_gpu_async cost 0.0014162063598632812 seconds
DEBUG 01-05 09:59:07.719492.719492 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.719044.719044 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-05 09:59:07.719184.719184 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005187273025512695 seconds
INFO 01-05 09:59:07.719725.719725 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 63bb8529-07c6-4bee-9934-fcaf64489d22
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.722554.722554 cuda_h.py:19] end self_attn cost 0.0036897659301757812 seconds
DEBUG 01-05 09:59:07.722325.722325 cuda_h.py:19] end iln_self_attn_paln cost 0.008980751037597656 seconds
DEBUG 01-05 09:59:07.722354.722354 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 09:59:07.722216.722216 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.723274.723274 cuda_h.py:19] end gate cost 0.0007107257843017578 seconds
DEBUG 01-05 09:59:07.723481.723481 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.723967.723967 lmp.py:365] 
DEBUG 01-05 09:59:07.723967.723967 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.723816.723816 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.723704.723704 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.723778.723778 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.724182.724182 lmp.py:369] 
DEBUG 01-05 09:59:07.724182.724182 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.724825.724825 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.724859.724859 lmp.py:376]   Expert  1 |     20 | CPU
DEBUG 01-05 09:59:07.724741.724741 lmp.py:376]   Expert  3 |     27 | CPU
DEBUG 01-05 09:59:07.724907.724907 lmp.py:376]   Expert 15 |     36 | CPU
DEBUG 01-05 09:59:07.724834.724834 lmp.py:376]   Expert 20 |     36 | CPU
DEBUG 01-05 09:59:07.724524.724524 lmp.py:376]   Expert 25 |     44 | CPU
DEBUG 01-05 09:59:07.724451.724451 lmp.py:376]   Expert 31 |     44 | CPU
DEBUG 01-05 09:59:07.724141.724141 lmp.py:376]   Expert 49 |     44 | CPU
DEBUG 01-05 09:59:07.724307.724307 lmp.py:376]   Expert 48 |     51 | CPU
DEBUG 01-05 09:59:07.724188.724188 lmp.py:376]   Expert  6 |     52 | CPU
DEBUG 01-05 09:59:07.724831.724831 lmp.py:376]   Expert 33 |     54 | CPU
DEBUG 01-05 09:59:07.724236.724236 lmp.py:376]   Expert 41 |     56 | CPU
DEBUG 01-05 09:59:07.724640.724640 lmp.py:376]   Expert  8 |     59 | CPU
DEBUG 01-05 09:59:07.724568.724568 lmp.py:376]   Expert 32 |     59 | CPU
DEBUG 01-05 09:59:07.724257.724257 lmp.py:376]   Expert 40 |     64 | CPU
DEBUG 01-05 09:59:07.724947.724947 lmp.py:376]   Expert 16 |     66 | CPU
DEBUG 01-05 09:59:07.724874.724874 lmp.py:376]   Expert 29 |     69 | CPU
DEBUG 01-05 09:59:07.724087.724087 lmp.py:376]   Expert 59 |     71 | CPU
DEBUG 01-05 09:59:07.724253.724253 lmp.py:376]   Expert  0 |     72 | CPU
DEBUG 01-05 09:59:07.724181.724181 lmp.py:376]   Expert  5 |     85 | CPU
DEBUG 01-05 09:59:07.724347.724347 lmp.py:376]   Expert  7 |     86 | CPU
DEBUG 01-05 09:59:07.724811.724811 lmp.py:376]   Expert 34 |     87 | CPU
DEBUG 01-05 09:59:07.724216.724216 lmp.py:376]   Expert 39 |     94 | CPU
DEBUG 01-05 09:59:07.724620.724620 lmp.py:376]   Expert 63 |    100 | CPU
DEBUG 01-05 09:59:07.724787.724787 lmp.py:376]   Expert 57 |    101 | CPU
DEBUG 01-05 09:59:07.724237.724237 lmp.py:376]   Expert 18 |    104 | CPU
DEBUG 01-05 09:59:07.724165.724165 lmp.py:376]   Expert 35 |    108 | CPU
DEBUG 01-05 09:59:07.724855.724855 lmp.py:376]   Expert 58 |    108 | CPU
DEBUG 01-05 09:59:07.724067.724067 lmp.py:376]   Expert 30 |    109 | CPU
DEBUG 01-05 09:59:07.724472.724472 lmp.py:376]   Expert 50 |    112 | CPU
DEBUG 01-05 09:59:07.724399.724399 lmp.py:376]   Expert 60 |    115 | CPU
DEBUG 01-05 09:59:07.724850.724850 lmp.py:376]   Expert 42 |    123 | CPU
DEBUG 01-05 09:59:07.724778.724778 lmp.py:376]   Expert 45 |    129 | CPU
DEBUG 01-05 09:59:07.724182.724182 lmp.py:376]   Expert 55 |    135 | GPU
DEBUG 01-05 09:59:07.724587.724587 lmp.py:376]   Expert  4 |    147 | GPU
DEBUG 01-05 09:59:07.724753.724753 lmp.py:376]   Expert 37 |    157 | GPU
DEBUG 01-05 09:59:07.724158.724158 lmp.py:376]   Expert 52 |    166 | GPU
DEBUG 01-05 09:59:07.724085.724085 lmp.py:376]   Expert 53 |    172 | GPU
DEBUG 01-05 09:59:07.724536.724536 lmp.py:376]   Expert 19 |    174 | GPU
DEBUG 01-05 09:59:07.724226.724226 lmp.py:376]   Expert 51 |    181 | GPU
DEBUG 01-05 09:59:07.724438.724438 lmp.py:376]   Expert 54 |    184 | GPU
DEBUG 01-05 09:59:07.724650.724650 lmp.py:376]   Expert 13 |    185 | GPU
DEBUG 01-05 09:59:07.724101.724101 lmp.py:376]   Expert 22 |    206 | GPU
DEBUG 01-05 09:59:07.724314.724314 lmp.py:376]   Expert 26 |    210 | GPU
DEBUG 01-05 09:59:07.724765.724765 lmp.py:376]   Expert 36 |    211 | GPU
DEBUG 01-05 09:59:07.724692.724692 lmp.py:376]   Expert 17 |    215 | GPU
DEBUG 01-05 09:59:07.724620.724620 lmp.py:376]   Expert 24 |    215 | GPU
DEBUG 01-05 09:59:07.724548.724548 lmp.py:376]   Expert 10 |    216 | GPU
DEBUG 01-05 09:59:07.724476.724476 lmp.py:376]   Expert 56 |    228 | GPU
DEBUG 01-05 09:59:07.724688.724688 lmp.py:376]   Expert 43 |    249 | GPU
DEBUG 01-05 09:59:07.724139.724139 lmp.py:376]   Expert  2 |    262 | GPU
DEBUG 01-05 09:59:07.724828.724828 lmp.py:376]   Expert 62 |    265 | GPU
DEBUG 01-05 09:59:07.724041.724041 lmp.py:376]   Expert 27 |    272 | GPU
DEBUG 01-05 09:59:07.724253.724253 lmp.py:376]   Expert 21 |    283 | GPU
DEBUG 01-05 09:59:07.724704.724704 lmp.py:376]   Expert 47 |    286 | GPU
DEBUG 01-05 09:59:07.724155.724155 lmp.py:376]   Expert 61 |    303 | GPU
DEBUG 01-05 09:59:07.724129.724129 lmp.py:376]   Expert 11 |    315 | GPU
DEBUG 01-05 09:59:07.725341.725341 lmp.py:376]   Expert 14 |    323 | GPU
DEBUG 01-05 09:59:07.725792.725792 lmp.py:376]   Expert 28 |    324 | GPU
DEBUG 01-05 09:59:07.725766.725766 lmp.py:376]   Expert 38 |    381 | GPU
DEBUG 01-05 09:59:07.725217.725217 lmp.py:376]   Expert 46 |    405 | GPU
DEBUG 01-05 09:59:07.725145.725145 lmp.py:376]   Expert 44 |    416 | GPU
DEBUG 01-05 09:59:07.725073.725073 lmp.py:376]   Expert 12 |    575 | GPU
DEBUG 01-05 09:59:07.725239.725239 lmp.py:376]   Expert  9 |    998 | GPU
DEBUG 01-05 09:59:07.725167.725167 lmp.py:376]   Expert 23 |   1244 | GPU
DEBUG 01-05 09:59:07.725571.725571 lmp.py:377] 
DEBUG 01-05 09:59:07.725571.725571 lmp.py:377]   CPU total tokens: 2385 (19.4%)
DEBUG 01-05 09:59:07.725452.725452 lmp.py:378]   GPU total tokens: 9903 (80.6%)
DEBUG 01-05 09:59:07.725149.725149 cuda_h.py:19] end experts_map_get cost 0.0015180110931396484 seconds
DEBUG 01-05 09:59:07.725268.725268 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.725151.725151 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.725467.725467 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.726036.726036 cuda_h.py:19] end allocate_cuda_memory cost 0.0009484291076660156 seconds
DEBUG 01-05 09:59:07.726733.726733 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.726973.726973 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.726736.726736 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.726101.726101 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 05513c34-e962-4ae1-bf5c-ec63f850dfd3
DEBUG 01-05 09:59:07.726139.726139 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.727707.727707 client.py:127] Model loaded
DEBUG 01-05 09:59:07.727842.727842 cuda_h.py:19] end sllm_worker_task cost 0.013189315795898438 seconds
INFO 01-05 09:59:07.728207.728207 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 05513c34-e962-4ae1-bf5c-ec63f850dfd3
DEBUG 01-05 09:59:07.728334.728334 cuda_h.py:19] end load_into_gpu_async cost 0.0017042160034179688 seconds
DEBUG 01-05 09:59:07.728561.728561 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.728896.728896 cuda_h.py:19] end restore_tensors2 cost 0.00029206275939941406 seconds
DEBUG 01-05 09:59:07.728480.728480 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032737255096435547 seconds
DEBUG 01-05 09:59:07.730939.730939 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005770683288574219 seconds
DEBUG 01-05 09:59:07.731762.731762 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.731275.731275 lmp.py:423] 
DEBUG 01-05 09:59:07.731275.731275 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.731357.731357 cuda_h.py:19] end cpu_experts_submit cost 0.00012111663818359375 seconds
DEBUG 01-05 09:59:07.731967.731967 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.738335.738335 mlpmodule.py:704] group tensors cost 0.007424354553222656 s
DEBUG 01-05 09:59:07.741134.741134 mlpmodule.py:742] pad cost 0.0018329620361328125 s
DEBUG 01-05 09:59:07.741204.741204 mlpmodule.py:748] create cpu tensor cost 4.9591064453125e-05 s
DEBUG 01-05 09:59:07.741737.741737 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-05 09:59:07.751715.751715 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.751038.751038 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.751829.751829 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 09:59:07.751793.751793 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.769124.769124 mlpmodule.py:793] group einsum cost 0.027902841567993164 s
DEBUG 01-05 09:59:07.770479.770479 mlpmodule.py:801] cpy2cputensor cost 0.0005156993865966797 s
DEBUG 01-05 09:59:07.774597.774597 cuda_h.py:19] end wait_cetm_experts cost 0.04346919059753418 seconds
DEBUG 01-05 09:59:07.774020.774020 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.775895.775895 cuda_h.py:19] end gpu_sexperts cost 0.0005671977996826172 seconds
DEBUG 01-05 09:59:07.775407.775407 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.775827.775827 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:07.775868.775868 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.775161.775161 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 05513c34-e962-4ae1-bf5c-ec63f850dfd3
INFO 01-05 09:59:07.782788.782788 client.py:127] Model loaded
DEBUG 01-05 09:59:07.782360.782360 cuda_h.py:19] end wait_experts cost 0.006932735443115234 seconds
DEBUG 01-05 09:59:07.782064.782064 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.782833.782833 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.783049.783049 mlpmodule.py:531] gpu group tensors cost 0.0006337165832519531 s
DEBUG 01-05 09:59:07.785533.785533 mlpmodule.py:564] gpu pad cost 0.0017380714416503906 s
DEBUG 01-05 09:59:07.785095.785095 mlpmodule.py:582] gpu group einsum cost 0.00047588348388671875 s
DEBUG 01-05 09:59:07.788509.788509 mlpmodule.py:662]  experts func einsum cost 0.05695033073425293 s
DEBUG 01-05 09:59:07.789493.789493 mlpmodule.py:611] gpu experts func einsum cost 0.006148099899291992 s
DEBUG 01-05 09:59:07.789981.789981 cuda_h.py:19] end gpu_experts cost 0.006396293640136719 seconds
DEBUG 01-05 09:59:07.789627.789627 cuda_h.py:19] end layer_moe_generate_7 cost 0.06646156311035156 seconds
DEBUG 01-05 09:59:07.789129.789129 lmp.py:217] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 09:59:07.789554.789554 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 09:59:07.789581.789581 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:59:07.789621.789621 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:59:07.789319.789319 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 09:59:07.789850.789850 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.557868957519531e-05 seconds
DEBUG 01-05 09:59:07.789208.789208 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.789998.789998 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.789267.789267 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.789441.789441 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.790639.790639 cuda_h.py:19] end allocate_cuda_memory cost 0.00031948089599609375 seconds
DEBUG 01-05 09:59:07.790747.790747 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.790510.790510 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.790333.790333 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.790036.790036 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e784e60a-e1d7-4685-8c34-834845f0514d
DEBUG 01-05 09:59:07.790813.790813 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.790220.790220 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.791748.791748 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e784e60a-e1d7-4685-8c34-834845f0514d
DEBUG 01-05 09:59:07.791300.791300 cuda_h.py:19] end load_into_gpu_async cost 0.0010380744934082031 seconds
DEBUG 01-05 09:59:07.791857.791857 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.791509.791509 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-05 09:59:07.791835.791835 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016808509826660156 seconds
INFO 01-05 09:59:07.792937.792937 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e784e60a-e1d7-4685-8c34-834845f0514d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.794480.794480 cuda_h.py:19] end self_attn cost 0.003957986831665039 seconds
DEBUG 01-05 09:59:07.795662.795662 cuda_h.py:19] end iln_self_attn_paln cost 0.00543212890625 seconds
DEBUG 01-05 09:59:07.795406.795406 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 09:59:07.795884.795884 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.795118.795118 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-05 09:59:07.795087.795087 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.796520.796520 lmp.py:365] 
DEBUG 01-05 09:59:07.796520.796520 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.796607.796607 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.796257.796257 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.796284.796284 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.796450.796450 lmp.py:369] 
DEBUG 01-05 09:59:07.796450.796450 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.796616.796616 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.796028.796028 lmp.py:376]   Expert 26 |     10 | CPU
DEBUG 01-05 09:59:07.796148.796148 lmp.py:376]   Expert 27 |     21 | CPU
DEBUG 01-05 09:59:07.796837.796837 lmp.py:376]   Expert 30 |     22 | CPU
DEBUG 01-05 09:59:07.796917.796917 lmp.py:376]   Expert  7 |     26 | CPU
DEBUG 01-05 09:59:07.796845.796845 lmp.py:376]   Expert 38 |     27 | CPU
DEBUG 01-05 09:59:07.796011.796011 lmp.py:376]   Expert 14 |     29 | CPU
DEBUG 01-05 09:59:07.796177.796177 lmp.py:376]   Expert 12 |     34 | CPU
DEBUG 01-05 09:59:07.796628.796628 lmp.py:376]   Expert  8 |     36 | CPU
DEBUG 01-05 09:59:07.796602.796602 lmp.py:376]   Expert 53 |     45 | CPU
DEBUG 01-05 09:59:07.796053.796053 lmp.py:376]   Expert 34 |     50 | CPU
DEBUG 01-05 09:59:07.796504.796504 lmp.py:376]   Expert 36 |     53 | CPU
DEBUG 01-05 09:59:07.796478.796478 lmp.py:376]   Expert 22 |     57 | CPU
DEBUG 01-05 09:59:07.796690.796690 lmp.py:376]   Expert 33 |     57 | CPU
DEBUG 01-05 09:59:07.796903.796903 lmp.py:376]   Expert 13 |     68 | CPU
DEBUG 01-05 09:59:07.796831.796831 lmp.py:376]   Expert 50 |     70 | CPU
DEBUG 01-05 09:59:07.796520.796520 lmp.py:376]   Expert 57 |     73 | CPU
DEBUG 01-05 09:59:07.796494.796494 lmp.py:376]   Expert 54 |     76 | CPU
DEBUG 01-05 09:59:07.796468.796468 lmp.py:376]   Expert 15 |     81 | CPU
DEBUG 01-05 09:59:07.796204.796204 lmp.py:376]   Expert  2 |     85 | CPU
DEBUG 01-05 09:59:07.796178.796178 lmp.py:376]   Expert 32 |     88 | CPU
DEBUG 01-05 09:59:07.796059.796059 lmp.py:376]   Expert 18 |     95 | CPU
DEBUG 01-05 09:59:07.796748.796748 lmp.py:376]   Expert 29 |    101 | CPU
DEBUG 01-05 09:59:07.796676.796676 lmp.py:376]   Expert 37 |    101 | CPU
DEBUG 01-05 09:59:07.796081.796081 lmp.py:376]   Expert  9 |    103 | CPU
DEBUG 01-05 09:59:07.796724.796724 lmp.py:376]   Expert  1 |    104 | CPU
DEBUG 01-05 09:59:07.796174.796174 lmp.py:376]   Expert 24 |    114 | CPU
DEBUG 01-05 09:59:07.796102.796102 lmp.py:376]   Expert 56 |    116 | CPU
DEBUG 01-05 09:59:07.796791.796791 lmp.py:376]   Expert 58 |    118 | CPU
DEBUG 01-05 09:59:07.796481.796481 lmp.py:376]   Expert 19 |    123 | CPU
DEBUG 01-05 09:59:07.796408.796408 lmp.py:376]   Expert 16 |    130 | CPU
DEBUG 01-05 09:59:07.796098.796098 lmp.py:376]   Expert 39 |    142 | CPU
DEBUG 01-05 09:59:07.796787.796787 lmp.py:376]   Expert 51 |    144 | CPU
DEBUG 01-05 09:59:07.796476.796476 lmp.py:376]   Expert 60 |    148 | GPU
DEBUG 01-05 09:59:07.796642.796642 lmp.py:376]   Expert 59 |    156 | GPU
DEBUG 01-05 09:59:07.796809.796809 lmp.py:376]   Expert 42 |    158 | GPU
DEBUG 01-05 09:59:07.796736.796736 lmp.py:376]   Expert 31 |    160 | GPU
DEBUG 01-05 09:59:07.796664.796664 lmp.py:376]   Expert 10 |    167 | GPU
DEBUG 01-05 09:59:07.796353.796353 lmp.py:376]   Expert 40 |    167 | GPU
DEBUG 01-05 09:59:07.796043.796043 lmp.py:376]   Expert 44 |    168 | GPU
DEBUG 01-05 09:59:07.796970.796970 lmp.py:376]   Expert 23 |    196 | GPU
DEBUG 01-05 09:59:07.797898.797898 lmp.py:376]   Expert 17 |    199 | GPU
DEBUG 01-05 09:59:07.797826.797826 lmp.py:376]   Expert 46 |    213 | GPU
DEBUG 01-05 09:59:07.797807.797807 lmp.py:376]   Expert 20 |    221 | GPU
DEBUG 01-05 09:59:07.797496.797496 lmp.py:376]   Expert 55 |    224 | GPU
DEBUG 01-05 09:59:07.797947.797947 lmp.py:376]   Expert  3 |    234 | GPU
DEBUG 01-05 09:59:07.797682.797682 lmp.py:376]   Expert 49 |    235 | GPU
DEBUG 01-05 09:59:07.797895.797895 lmp.py:376]   Expert  0 |    246 | GPU
DEBUG 01-05 09:59:07.797631.797631 lmp.py:376]   Expert 41 |    255 | GPU
DEBUG 01-05 09:59:07.797605.797605 lmp.py:376]   Expert 25 |    261 | GPU
DEBUG 01-05 09:59:07.797055.797055 lmp.py:376]   Expert 48 |    264 | GPU
DEBUG 01-05 09:59:07.797791.797791 lmp.py:376]   Expert 45 |    305 | GPU
DEBUG 01-05 09:59:07.797719.797719 lmp.py:376]   Expert 43 |    307 | GPU
DEBUG 01-05 09:59:07.797693.797693 lmp.py:376]   Expert 28 |    322 | GPU
DEBUG 01-05 09:59:07.797428.797428 lmp.py:376]   Expert 52 |    338 | GPU
DEBUG 01-05 09:59:07.797164.797164 lmp.py:376]   Expert  6 |    340 | GPU
DEBUG 01-05 09:59:07.797900.797900 lmp.py:376]   Expert 61 |    346 | GPU
DEBUG 01-05 09:59:07.797874.797874 lmp.py:376]   Expert  4 |    380 | GPU
DEBUG 01-05 09:59:07.797609.797609 lmp.py:376]   Expert 62 |    386 | GPU
DEBUG 01-05 09:59:07.797583.797583 lmp.py:376]   Expert 35 |    424 | GPU
DEBUG 01-05 09:59:07.797557.797557 lmp.py:376]   Expert 47 |    457 | GPU
DEBUG 01-05 09:59:07.797770.797770 lmp.py:376]   Expert 11 |    537 | GPU
DEBUG 01-05 09:59:07.797221.797221 lmp.py:376]   Expert  5 |    626 | GPU
DEBUG 01-05 09:59:07.797433.797433 lmp.py:376]   Expert 63 |    635 | GPU
DEBUG 01-05 09:59:07.797169.797169 lmp.py:376]   Expert 21 |    814 | GPU
DEBUG 01-05 09:59:07.797858.797858 lmp.py:377] 
DEBUG 01-05 09:59:07.797858.797858 lmp.py:377]   CPU total tokens: 2399 (19.5%)
DEBUG 01-05 09:59:07.797024.797024 lmp.py:378]   GPU total tokens: 9889 (80.5%)
DEBUG 01-05 09:59:07.797482.797482 cuda_h.py:19] end experts_map_get cost 0.0014927387237548828 seconds
DEBUG 01-05 09:59:07.797648.797648 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.797186.797186 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.797641.797641 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.798953.798953 cuda_h.py:19] end allocate_cuda_memory cost 0.00040841102600097656 seconds
DEBUG 01-05 09:59:07.798750.798750 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.798552.798552 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.798169.798169 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.798342.798342 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a7f3151d-1767-4b0e-ba96-ae2ec3282673
DEBUG 01-05 09:59:07.798096.798096 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.798350.798350 client.py:127] Model loaded
DEBUG 01-05 09:59:07.798193.798193 cuda_h.py:19] end sllm_worker_task cost 0.008872509002685547 seconds
INFO 01-05 09:59:07.799602.799602 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a7f3151d-1767-4b0e-ba96-ae2ec3282673
DEBUG 01-05 09:59:07.799922.799922 cuda_h.py:19] end load_into_gpu_async cost 0.0011472702026367188 seconds
DEBUG 01-05 09:59:07.799625.799625 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.799609.799609 cuda_h.py:19] end restore_tensors2 cost 0.0002791881561279297 seconds
DEBUG 01-05 09:59:07.799670.799670 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021572113037109375 seconds
DEBUG 01-05 09:59:07.802106.802106 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00473475456237793 seconds
DEBUG 01-05 09:59:07.802551.802551 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.802176.802176 lmp.py:423] 
DEBUG 01-05 09:59:07.802176.802176 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.802357.802357 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-05 09:59:07.802344.802344 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.812878.812878 mlpmodule.py:704] group tensors cost 0.01001286506652832 s
DEBUG 01-05 09:59:07.814298.814298 mlpmodule.py:742] pad cost 0.0015997886657714844 s
DEBUG 01-05 09:59:07.815262.815262 mlpmodule.py:748] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-05 09:59:07.815656.815656 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 09:59:07.825314.825314 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.825114.825114 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.825806.825806 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 09:59:07.825492.825492 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.842864.842864 mlpmodule.py:793] group einsum cost 0.02770400047302246 s
DEBUG 01-05 09:59:07.843706.843706 mlpmodule.py:801] cpy2cputensor cost 0.0005893707275390625 s
DEBUG 01-05 09:59:07.848351.848351 cuda_h.py:19] end wait_cetm_experts cost 0.0456082820892334 seconds
DEBUG 01-05 09:59:07.848403.848403 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.848245.848245 cuda_h.py:19] end gpu_sexperts cost 0.0005781650543212891 seconds
DEBUG 01-05 09:59:07.848188.848188 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.849376.849376 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:07.849370.849370 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.849894.849894 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a7f3151d-1767-4b0e-ba96-ae2ec3282673
INFO 01-05 09:59:07.853149.853149 client.py:127] Model loaded
DEBUG 01-05 09:59:07.853721.853721 cuda_h.py:19] end wait_experts cost 0.004717111587524414 seconds
DEBUG 01-05 09:59:07.853192.853192 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.853002.853002 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.854357.854357 mlpmodule.py:531] gpu group tensors cost 0.0006330013275146484 s
DEBUG 01-05 09:59:07.856279.856279 mlpmodule.py:564] gpu pad cost 0.0017857551574707031 s
DEBUG 01-05 09:59:07.857843.857843 mlpmodule.py:582] gpu group einsum cost 0.0005385875701904297 s
DEBUG 01-05 09:59:07.860607.860607 mlpmodule.py:611] gpu experts func einsum cost 0.0063283443450927734 s
DEBUG 01-05 09:59:07.860883.860883 cuda_h.py:19] end gpu_experts cost 0.00653529167175293 seconds
DEBUG 01-05 09:59:07.860091.860091 cuda_h.py:19] end layer_moe_generate_8 cost 0.06532645225524902 seconds
DEBUG 01-05 09:59:07.860216.860216 lmp.py:217] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 09:59:07.860979.860979 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 09:59:07.860913.860913 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:59:07.860715.860715 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:59:07.860473.860473 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.8371810913085938e-05 seconds
DEBUG 01-05 09:59:07.860673.860673 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 8.559226989746094e-05 seconds
DEBUG 01-05 09:59:07.860694.860694 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.860755.860755 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.861487.861487 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.861670.861670 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.862557.862557 cuda_h.py:19] end allocate_cuda_memory cost 0.0009264945983886719 seconds
DEBUG 01-05 09:59:07.862314.862314 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.862646.862646 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.862515.862515 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.862695.862695 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7e24cdd3-3122-4e9d-a8ad-0367b528bfaf
DEBUG 01-05 09:59:07.862539.862539 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.862301.862301 mlpmodule.py:662]  experts func einsum cost 0.06005048751831055 s
DEBUG 01-05 09:59:07.863025.863025 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.863917.863917 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7e24cdd3-3122-4e9d-a8ad-0367b528bfaf
DEBUG 01-05 09:59:07.863760.863760 cuda_h.py:19] end load_into_gpu_async cost 0.0014159679412841797 seconds
DEBUG 01-05 09:59:07.863748.863748 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.863161.863161 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-05 09:59:07.863772.863772 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026650428771972656 seconds
INFO 01-05 09:59:07.864199.864199 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7e24cdd3-3122-4e9d-a8ad-0367b528bfaf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.867076.867076 cuda_h.py:19] end self_attn cost 0.003740072250366211 seconds
DEBUG 01-05 09:59:07.867006.867006 cuda_h.py:19] end iln_self_attn_paln cost 0.0063703060150146484 seconds
DEBUG 01-05 09:59:07.867750.867750 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 09:59:07.867228.867228 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.868677.868677 cuda_h.py:19] end gate cost 0.0007195472717285156 seconds
DEBUG 01-05 09:59:07.868467.868467 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.868768.868768 lmp.py:365] 
DEBUG 01-05 09:59:07.868768.868768 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.868332.868332 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.868982.868982 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.868055.868055 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.868460.868460 lmp.py:369] 
DEBUG 01-05 09:59:07.868460.868460 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.868911.868911 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.868561.868561 lmp.py:376]   Expert 35 |     23 | CPU
DEBUG 01-05 09:59:07.868250.868250 lmp.py:376]   Expert 38 |     25 | CPU
DEBUG 01-05 09:59:07.868224.868224 lmp.py:376]   Expert  7 |     27 | CPU
DEBUG 01-05 09:59:07.868436.868436 lmp.py:376]   Expert  5 |     29 | CPU
DEBUG 01-05 09:59:07.868649.868649 lmp.py:376]   Expert  6 |     32 | CPU
DEBUG 01-05 09:59:07.868384.868384 lmp.py:376]   Expert 13 |     35 | CPU
DEBUG 01-05 09:59:07.868266.868266 lmp.py:376]   Expert 19 |     39 | CPU
DEBUG 01-05 09:59:07.868478.868478 lmp.py:376]   Expert 17 |     42 | CPU
DEBUG 01-05 09:59:07.868452.868452 lmp.py:376]   Expert 60 |     53 | CPU
DEBUG 01-05 09:59:07.868711.868711 lmp.py:376]   Expert  2 |     66 | CPU
DEBUG 01-05 09:59:07.868447.868447 lmp.py:376]   Expert 27 |     66 | CPU
DEBUG 01-05 09:59:07.868944.868944 lmp.py:376]   Expert 52 |     67 | CPU
DEBUG 01-05 09:59:07.869203.869203 lmp.py:376]   Expert 45 |     70 | CPU
DEBUG 01-05 09:59:07.869938.869938 lmp.py:376]   Expert 39 |     71 | CPU
DEBUG 01-05 09:59:07.869197.869197 lmp.py:376]   Expert 42 |     75 | CPU
DEBUG 01-05 09:59:07.869694.869694 lmp.py:376]   Expert 48 |     75 | CPU
DEBUG 01-05 09:59:07.869953.869953 lmp.py:376]   Expert 16 |     79 | CPU
DEBUG 01-05 09:59:07.869689.869689 lmp.py:376]   Expert 25 |     82 | CPU
DEBUG 01-05 09:59:07.869901.869901 lmp.py:376]   Expert 54 |     83 | CPU
DEBUG 01-05 09:59:07.869875.869875 lmp.py:376]   Expert 59 |     84 | CPU
DEBUG 01-05 09:59:07.869896.869896 lmp.py:376]   Expert 29 |     86 | CPU
DEBUG 01-05 09:59:07.869631.869631 lmp.py:376]   Expert 20 |     87 | CPU
DEBUG 01-05 09:59:07.869890.869890 lmp.py:376]   Expert 26 |     87 | CPU
DEBUG 01-05 09:59:07.869387.869387 lmp.py:376]   Expert 32 |     87 | CPU
DEBUG 01-05 09:59:07.869646.869646 lmp.py:376]   Expert 62 |     93 | CPU
DEBUG 01-05 09:59:07.869143.869143 lmp.py:376]   Expert 40 |    105 | CPU
DEBUG 01-05 09:59:07.869164.869164 lmp.py:376]   Expert 12 |    109 | CPU
DEBUG 01-05 09:59:07.869615.869615 lmp.py:376]   Expert 23 |    115 | CPU
DEBUG 01-05 09:59:07.869589.869589 lmp.py:376]   Expert 24 |    119 | CPU
DEBUG 01-05 09:59:07.869086.869086 lmp.py:376]   Expert 57 |    126 | CPU
DEBUG 01-05 09:59:07.869583.869583 lmp.py:376]   Expert 31 |    133 | CPU
DEBUG 01-05 09:59:07.869080.869080 lmp.py:376]   Expert 41 |    145 | CPU
DEBUG 01-05 09:59:07.869577.869577 lmp.py:376]   Expert 47 |    152 | GPU
DEBUG 01-05 09:59:07.869075.869075 lmp.py:376]   Expert 18 |    153 | GPU
DEBUG 01-05 09:59:07.869333.869333 lmp.py:376]   Expert 22 |    154 | GPU
DEBUG 01-05 09:59:07.869592.869592 lmp.py:376]   Expert 50 |    160 | GPU
DEBUG 01-05 09:59:07.869089.869089 lmp.py:376]   Expert 14 |    162 | GPU
DEBUG 01-05 09:59:07.869063.869063 lmp.py:376]   Expert 30 |    162 | GPU
DEBUG 01-05 09:59:07.869276.869276 lmp.py:376]   Expert  1 |    168 | GPU
DEBUG 01-05 09:59:07.869012.869012 lmp.py:376]   Expert 28 |    173 | GPU
DEBUG 01-05 09:59:07.869270.869270 lmp.py:376]   Expert 51 |    177 | GPU
DEBUG 01-05 09:59:07.869529.869529 lmp.py:376]   Expert 34 |    193 | GPU
DEBUG 01-05 09:59:07.869788.869788 lmp.py:376]   Expert 49 |    201 | GPU
DEBUG 01-05 09:59:07.869047.869047 lmp.py:376]   Expert 58 |    207 | GPU
DEBUG 01-05 09:59:07.869305.869305 lmp.py:376]   Expert 33 |    218 | GPU
DEBUG 01-05 09:59:07.869326.869326 lmp.py:376]   Expert 53 |    224 | GPU
DEBUG 01-05 09:59:07.869585.869585 lmp.py:376]   Expert 44 |    232 | GPU
DEBUG 01-05 09:59:07.869559.869559 lmp.py:376]   Expert  0 |    250 | GPU
DEBUG 01-05 09:59:07.869771.869771 lmp.py:376]   Expert 36 |    252 | GPU
DEBUG 01-05 09:59:07.869268.869268 lmp.py:376]   Expert  3 |    259 | GPU
DEBUG 01-05 09:59:07.869289.869289 lmp.py:376]   Expert  4 |    265 | GPU
DEBUG 01-05 09:59:07.869548.869548 lmp.py:376]   Expert  8 |    266 | GPU
DEBUG 01-05 09:59:07.869568.869568 lmp.py:376]   Expert 55 |    309 | GPU
DEBUG 01-05 09:59:07.869588.869588 lmp.py:376]   Expert 37 |    330 | GPU
DEBUG 01-05 09:59:07.869847.869847 lmp.py:376]   Expert 11 |    349 | GPU
DEBUG 01-05 09:59:07.869867.869867 lmp.py:376]   Expert 10 |    351 | GPU
DEBUG 01-05 09:59:07.869126.869126 lmp.py:376]   Expert 43 |    358 | GPU
DEBUG 01-05 09:59:07.869385.869385 lmp.py:376]   Expert 15 |    380 | GPU
DEBUG 01-05 09:59:07.869359.869359 lmp.py:376]   Expert 61 |    403 | GPU
DEBUG 01-05 09:59:07.869618.869618 lmp.py:376]   Expert  9 |    427 | GPU
DEBUG 01-05 09:59:07.869638.869638 lmp.py:376]   Expert 46 |    453 | GPU
DEBUG 01-05 09:59:07.869897.869897 lmp.py:376]   Expert 63 |    522 | GPU
DEBUG 01-05 09:59:07.869679.869679 lmp.py:376]   Expert 21 |    620 | GPU
DEBUG 01-05 09:59:07.869938.869938 lmp.py:376]   Expert 56 |   1343 | GPU
DEBUG 01-05 09:59:07.869150.869150 lmp.py:377] 
DEBUG 01-05 09:59:07.869150.869150 lmp.py:377]   CPU total tokens: 2415 (19.7%)
DEBUG 01-05 09:59:07.869601.869601 lmp.py:378]   GPU total tokens: 9873 (80.3%)
DEBUG 01-05 09:59:07.869536.869536 cuda_h.py:19] end experts_map_get cost 0.0014262199401855469 seconds
DEBUG 01-05 09:59:07.869179.869179 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.869717.869717 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.870463.870463 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.871999.871999 cuda_h.py:19] end allocate_cuda_memory cost 0.0009601116180419922 seconds
DEBUG 01-05 09:59:07.871650.871650 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.871691.871691 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.871546.871546 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.871673.871673 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce515373-0564-4e4b-843f-bf4f44c82471
DEBUG 01-05 09:59:07.871797.871797 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.871500.871500 client.py:127] Model loaded
DEBUG 01-05 09:59:07.871912.871912 cuda_h.py:19] end sllm_worker_task cost 0.010541915893554688 seconds
INFO 01-05 09:59:07.872092.872092 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce515373-0564-4e4b-843f-bf4f44c82471
DEBUG 01-05 09:59:07.872127.872127 cuda_h.py:19] end load_into_gpu_async cost 0.0011608600616455078 seconds
DEBUG 01-05 09:59:07.872876.872876 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.872688.872688 cuda_h.py:19] end restore_tensors2 cost 0.00029277801513671875 seconds
DEBUG 01-05 09:59:07.872557.872557 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002739429473876953 seconds
DEBUG 01-05 09:59:07.875923.875923 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005192756652832031 seconds
DEBUG 01-05 09:59:07.875984.875984 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.875556.875556 lmp.py:423] 
DEBUG 01-05 09:59:07.875556.875556 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.875445.875445 cuda_h.py:19] end cpu_experts_submit cost 0.00010251998901367188 seconds
DEBUG 01-05 09:59:07.875618.875618 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.880587.880587 mlpmodule.py:704] group tensors cost 0.005379438400268555 s
DEBUG 01-05 09:59:07.883628.883628 mlpmodule.py:742] pad cost 0.0016591548919677734 s
DEBUG 01-05 09:59:07.883546.883546 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-05 09:59:07.883025.883025 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:59:07.893073.893073 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.893921.893921 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.893163.893163 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:59:07.893876.893876 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.911579.911579 mlpmodule.py:793] group einsum cost 0.02791285514831543 s
DEBUG 01-05 09:59:07.912805.912805 mlpmodule.py:801] cpy2cputensor cost 0.0005939006805419922 s
DEBUG 01-05 09:59:07.917294.917294 cuda_h.py:19] end wait_cetm_experts cost 0.042064666748046875 seconds
DEBUG 01-05 09:59:07.917088.917088 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.918333.918333 cuda_h.py:19] end gpu_sexperts cost 0.0005571842193603516 seconds
DEBUG 01-05 09:59:07.918799.918799 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.918463.918463 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:07.918888.918888 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.918651.918651 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce515373-0564-4e4b-843f-bf4f44c82471
INFO 01-05 09:59:07.926117.926117 client.py:127] Model loaded
DEBUG 01-05 09:59:07.926729.926729 cuda_h.py:19] end wait_experts cost 0.00845193862915039 seconds
DEBUG 01-05 09:59:07.926862.926862 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.926803.926803 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.927200.927200 mlpmodule.py:531] gpu group tensors cost 0.0004944801330566406 s
DEBUG 01-05 09:59:07.929651.929651 mlpmodule.py:564] gpu pad cost 0.0015380382537841797 s
DEBUG 01-05 09:59:07.929132.929132 mlpmodule.py:582] gpu group einsum cost 0.0004553794860839844 s
DEBUG 01-05 09:59:07.931693.931693 mlpmodule.py:662]  experts func einsum cost 0.056433916091918945 s
DEBUG 01-05 09:59:07.932458.932458 mlpmodule.py:611] gpu experts func einsum cost 0.005624532699584961 s
DEBUG 01-05 09:59:07.932748.932748 cuda_h.py:19] end gpu_experts cost 0.005858659744262695 seconds
DEBUG 01-05 09:59:07.932194.932194 cuda_h.py:19] end layer_moe_generate_9 cost 0.06525516510009766 seconds
DEBUG 01-05 09:59:07.932120.932120 lmp.py:217] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 09:59:07.933260.933260 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 09:59:07.933003.933003 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:59:07.933090.933090 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:59:07.933979.933979 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:07.933059.933059 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.0558319091796875e-05 seconds
DEBUG 01-05 09:59:07.933941.933941 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:07.933300.933300 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:07.933384.933384 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.933942.933942 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.933629.933629 cuda_h.py:19] end allocate_cuda_memory cost 0.0002944469451904297 seconds
DEBUG 01-05 09:59:07.933069.933069 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.933593.933593 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.933621.933621 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.933801.933801 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a51a2dd2-5cce-46fa-bf54-fdba2f160ed9
DEBUG 01-05 09:59:07.934248.934248 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:07.934766.934766 cuda_h.py:10] start self_attn
INFO 01-05 09:59:07.934028.934028 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a51a2dd2-5cce-46fa-bf54-fdba2f160ed9
DEBUG 01-05 09:59:07.934579.934579 cuda_h.py:19] end load_into_gpu_async cost 0.0009715557098388672 seconds
DEBUG 01-05 09:59:07.934421.934421 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.934212.934212 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-05 09:59:07.934630.934630 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015823841094970703 seconds
INFO 01-05 09:59:07.935517.935517 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a51a2dd2-5cce-46fa-bf54-fdba2f160ed9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:07.938139.938139 cuda_h.py:19] end self_attn cost 0.003973484039306641 seconds
DEBUG 01-05 09:59:07.938586.938586 cuda_h.py:19] end iln_self_attn_paln cost 0.0053980350494384766 seconds
DEBUG 01-05 09:59:07.938806.938806 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 09:59:07.938953.938953 cuda_h.py:10] start gate
DEBUG 01-05 09:59:07.939220.939220 cuda_h.py:19] end gate cost 0.0006196498870849609 seconds
DEBUG 01-05 09:59:07.939712.939712 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:07.939615.939615 lmp.py:365] 
DEBUG 01-05 09:59:07.939615.939615 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:07.939510.939510 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:07.939683.939683 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:07.939757.939757 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:07.939446.939446 lmp.py:369] 
DEBUG 01-05 09:59:07.939446.939446 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:07.939374.939374 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:07.939024.939024 lmp.py:376]   Expert 34 |      2 | CPU
DEBUG 01-05 09:59:07.939335.939335 lmp.py:376]   Expert 27 |     10 | CPU
DEBUG 01-05 09:59:07.939932.939932 lmp.py:376]   Expert  3 |     12 | CPU
DEBUG 01-05 09:59:07.939813.939813 lmp.py:376]   Expert 14 |     18 | CPU
DEBUG 01-05 09:59:07.939741.939741 lmp.py:376]   Expert 55 |     20 | CPU
DEBUG 01-05 09:59:07.939669.939669 lmp.py:376]   Expert 61 |     20 | CPU
DEBUG 01-05 09:59:07.939597.939597 lmp.py:376]   Expert 47 |     21 | CPU
DEBUG 01-05 09:59:07.939524.939524 lmp.py:376]   Expert  6 |     25 | CPU
DEBUG 01-05 09:59:07.939214.939214 lmp.py:376]   Expert 32 |     26 | CPU
DEBUG 01-05 09:59:07.939903.939903 lmp.py:376]   Expert 13 |     35 | CPU
DEBUG 01-05 09:59:07.939831.939831 lmp.py:376]   Expert 44 |     35 | CPU
DEBUG 01-05 09:59:07.939997.939997 lmp.py:376]   Expert 46 |     36 | CPU
DEBUG 01-05 09:59:07.940448.940448 lmp.py:376]   Expert 37 |     37 | CPU
DEBUG 01-05 09:59:07.940660.940660 lmp.py:376]   Expert 50 |     47 | CPU
DEBUG 01-05 09:59:07.940873.940873 lmp.py:376]   Expert 15 |     48 | CPU
DEBUG 01-05 09:59:07.940324.940324 lmp.py:376]   Expert 48 |     52 | CPU
DEBUG 01-05 09:59:07.940536.940536 lmp.py:376]   Expert 19 |     54 | CPU
DEBUG 01-05 09:59:07.940748.940748 lmp.py:376]   Expert  7 |     61 | CPU
DEBUG 01-05 09:59:07.940438.940438 lmp.py:376]   Expert 38 |     64 | CPU
DEBUG 01-05 09:59:07.940127.940127 lmp.py:376]   Expert 17 |     67 | CPU
DEBUG 01-05 09:59:07.940816.940816 lmp.py:376]   Expert 12 |     69 | CPU
DEBUG 01-05 09:59:07.940506.940506 lmp.py:376]   Expert 54 |     79 | CPU
DEBUG 01-05 09:59:07.940480.940480 lmp.py:376]   Expert 35 |     82 | CPU
DEBUG 01-05 09:59:07.940931.940931 lmp.py:376]   Expert 26 |     89 | CPU
DEBUG 01-05 09:59:07.940143.940143 lmp.py:376]   Expert 60 |     89 | CPU
DEBUG 01-05 09:59:07.940879.940879 lmp.py:376]   Expert 62 |     91 | CPU
DEBUG 01-05 09:59:07.940091.940091 lmp.py:376]   Expert 56 |     95 | CPU
DEBUG 01-05 09:59:07.940304.940304 lmp.py:376]   Expert 43 |    106 | CPU
DEBUG 01-05 09:59:07.940993.940993 lmp.py:376]   Expert 28 |    107 | CPU
DEBUG 01-05 09:59:07.940159.940159 lmp.py:376]   Expert 20 |    111 | CPU
DEBUG 01-05 09:59:07.940371.940371 lmp.py:376]   Expert 29 |    113 | CPU
DEBUG 01-05 09:59:07.940822.940822 lmp.py:376]   Expert 36 |    127 | CPU
DEBUG 01-05 09:59:07.940035.940035 lmp.py:376]   Expert 22 |    142 | GPU
DEBUG 01-05 09:59:07.940486.940486 lmp.py:376]   Expert 41 |    142 | GPU
DEBUG 01-05 09:59:07.940937.940937 lmp.py:376]   Expert 25 |    143 | GPU
DEBUG 01-05 09:59:07.940586.940586 lmp.py:376]   Expert 52 |    149 | GPU
DEBUG 01-05 09:59:07.940183.940183 lmp.py:376]   Expert  5 |    155 | GPU
DEBUG 01-05 09:59:07.940588.940588 lmp.py:376]   Expert 53 |    177 | GPU
DEBUG 01-05 09:59:07.940754.940754 lmp.py:376]   Expert 51 |    178 | GPU
DEBUG 01-05 09:59:07.940728.940728 lmp.py:376]   Expert 59 |    183 | GPU
DEBUG 01-05 09:59:07.940940.940940 lmp.py:376]   Expert 24 |    186 | GPU
DEBUG 01-05 09:59:07.940391.940391 lmp.py:376]   Expert  9 |    200 | GPU
DEBUG 01-05 09:59:07.940365.940365 lmp.py:376]   Expert 45 |    203 | GPU
DEBUG 01-05 09:59:07.940578.940578 lmp.py:376]   Expert 30 |    218 | GPU
DEBUG 01-05 09:59:07.940313.940313 lmp.py:376]   Expert 57 |    218 | GPU
DEBUG 01-05 09:59:07.940287.940287 lmp.py:376]   Expert 21 |    234 | GPU
DEBUG 01-05 09:59:07.940261.940261 lmp.py:376]   Expert 31 |    249 | GPU
DEBUG 01-05 09:59:07.940474.940474 lmp.py:376]   Expert 49 |    253 | GPU
DEBUG 01-05 09:59:07.940686.940686 lmp.py:376]   Expert 63 |    256 | GPU
DEBUG 01-05 09:59:07.940899.940899 lmp.py:376]   Expert  2 |    268 | GPU
DEBUG 01-05 09:59:07.940065.940065 lmp.py:376]   Expert  8 |    279 | GPU
DEBUG 01-05 09:59:07.940754.940754 lmp.py:376]   Expert 16 |    279 | GPU
DEBUG 01-05 09:59:07.940205.940205 lmp.py:376]   Expert 18 |    284 | GPU
DEBUG 01-05 09:59:07.940417.940417 lmp.py:376]   Expert 39 |    285 | GPU
DEBUG 01-05 09:59:07.940153.940153 lmp.py:376]   Expert 42 |    351 | GPU
DEBUG 01-05 09:59:07.940366.940366 lmp.py:376]   Expert 10 |    360 | GPU
DEBUG 01-05 09:59:07.940816.940816 lmp.py:376]   Expert 23 |    370 | GPU
DEBUG 01-05 09:59:07.940221.940221 lmp.py:376]   Expert 40 |    392 | GPU
DEBUG 01-05 09:59:07.940387.940387 lmp.py:376]   Expert  4 |    481 | GPU
DEBUG 01-05 09:59:07.940600.940600 lmp.py:376]   Expert 33 |    540 | GPU
DEBUG 01-05 09:59:07.940289.940289 lmp.py:376]   Expert  0 |    543 | GPU
DEBUG 01-05 09:59:07.940263.940263 lmp.py:376]   Expert 58 |    572 | GPU
DEBUG 01-05 09:59:07.940237.940237 lmp.py:376]   Expert  1 |    948 | GPU
DEBUG 01-05 09:59:07.940449.940449 lmp.py:376]   Expert 11 |   1202 | GPU
DEBUG 01-05 09:59:07.940616.940616 lmp.py:377] 
DEBUG 01-05 09:59:07.940616.940616 lmp.py:377]   CPU total tokens: 1848 (15.0%)
DEBUG 01-05 09:59:07.940259.940259 lmp.py:378]   GPU total tokens: 10440 (85.0%)
DEBUG 01-05 09:59:07.940432.940432 cuda_h.py:19] end experts_map_get cost 0.0014865398406982422 seconds
DEBUG 01-05 09:59:07.940313.940313 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:07.940420.940420 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:07.941021.941021 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:07.941835.941835 cuda_h.py:19] end allocate_cuda_memory cost 0.0003573894500732422 seconds
DEBUG 01-05 09:59:07.941215.941215 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:07.941732.941732 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:07.941157.941157 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:07.941853.941853 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba662bb7-c06d-4083-9fcc-e8ab4f841138
DEBUG 01-05 09:59:07.941548.941548 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:07.941804.941804 client.py:127] Model loaded
DEBUG 01-05 09:59:07.942647.942647 cuda_h.py:19] end sllm_worker_task cost 0.008665800094604492 seconds
INFO 01-05 09:59:07.942239.942239 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba662bb7-c06d-4083-9fcc-e8ab4f841138
DEBUG 01-05 09:59:07.942936.942936 cuda_h.py:19] end load_into_gpu_async cost 0.0011298656463623047 seconds
DEBUG 01-05 09:59:07.942970.942970 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:07.943801.943801 cuda_h.py:19] end restore_tensors2 cost 0.0002715587615966797 seconds
DEBUG 01-05 09:59:07.943332.943332 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020897388458251953 seconds
DEBUG 01-05 09:59:07.945874.945874 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004670858383178711 seconds
DEBUG 01-05 09:59:07.945174.945174 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:07.945746.945746 lmp.py:423] 
DEBUG 01-05 09:59:07.945746.945746 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:07.945158.945158 cuda_h.py:19] end cpu_experts_submit cost 0.00010275840759277344 seconds
DEBUG 01-05 09:59:07.945569.945569 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:07.956508.956508 mlpmodule.py:704] group tensors cost 0.010037899017333984 s
DEBUG 01-05 09:59:07.958586.958586 mlpmodule.py:742] pad cost 0.0017654895782470703 s
DEBUG 01-05 09:59:07.958550.958550 mlpmodule.py:748] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-05 09:59:07.958467.958467 mlpmodule.py:753] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-05 09:59:07.969482.969482 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:07.969329.969329 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:07.969141.969141 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 09:59:07.969046.969046 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:07.987935.987935 mlpmodule.py:793] group einsum cost 0.029117107391357422 s
DEBUG 01-05 09:59:07.988849.988849 mlpmodule.py:801] cpy2cputensor cost 0.0005741119384765625 s
DEBUG 01-05 09:59:07.993772.993772 cuda_h.py:19] end wait_cetm_experts cost 0.047896385192871094 seconds
DEBUG 01-05 09:59:07.993009.993009 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:07.994546.994546 cuda_h.py:19] end gpu_sexperts cost 0.0005631446838378906 seconds
DEBUG 01-05 09:59:07.994343.994343 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:07.994961.994961 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:07.994717.994717 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:07.994924.994924 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba662bb7-c06d-4083-9fcc-e8ab4f841138
INFO 01-05 09:59:07.997489.997489 client.py:127] Model loaded
DEBUG 01-05 09:59:07.997809.997809 cuda_h.py:19] end wait_experts cost 0.0027031898498535156 seconds
DEBUG 01-05 09:59:07.997419.997419 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:07.997460.997460 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:07.998490.998490 mlpmodule.py:531] gpu group tensors cost 0.0006077289581298828 s
DEBUG 01-05 09:59:08.000054.000054 mlpmodule.py:564] gpu pad cost 0.0017657279968261719 s
DEBUG 01-05 09:59:08.000353.000353 mlpmodule.py:582] gpu group einsum cost 0.0005614757537841797 s
DEBUG 01-05 09:59:08.004705.004705 mlpmodule.py:611] gpu experts func einsum cost 0.006453752517700195 s
DEBUG 01-05 09:59:08.004874.004874 cuda_h.py:19] end gpu_experts cost 0.006627082824707031 seconds
DEBUG 01-05 09:59:08.004997.004997 cuda_h.py:19] end layer_moe_generate_10 cost 0.06558799743652344 seconds
DEBUG 01-05 09:59:08.004255.004255 lmp.py:217] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 09:59:08.004985.004985 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 09:59:08.004681.004681 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:59:08.004696.004696 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:59:08.004090.004090 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.054473876953125e-05 seconds
DEBUG 01-05 09:59:08.004574.004574 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 9.72747802734375e-05 seconds
DEBUG 01-05 09:59:08.004694.004694 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.004723.004723 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.004144.004144 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.004464.004464 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.008836.008836 cuda_h.py:19] end allocate_cuda_memory cost 0.0037467479705810547 seconds
DEBUG 01-05 09:59:08.008614.008614 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.008330.008330 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.008345.008345 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.008571.008571 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 30d0bddf-b80d-446f-abb5-26eada7389ab
DEBUG 01-05 09:59:08.009487.009487 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.009394.009394 mlpmodule.py:662]  experts func einsum cost 0.06321072578430176 s
DEBUG 01-05 09:59:08.009000.009000 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.009321.009321 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 30d0bddf-b80d-446f-abb5-26eada7389ab
DEBUG 01-05 09:59:08.009779.009779 cuda_h.py:19] end load_into_gpu_async cost 0.0009608268737792969 seconds
DEBUG 01-05 09:59:08.009529.009529 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.009512.009512 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-05 09:59:08.010533.010533 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005057811737060547 seconds
INFO 01-05 09:59:08.010253.010253 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 30d0bddf-b80d-446f-abb5-26eada7389ab
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.013575.013575 cuda_h.py:19] end self_attn cost 0.0037975311279296875 seconds
DEBUG 01-05 09:59:08.013577.013577 cuda_h.py:19] end iln_self_attn_paln cost 0.008943557739257812 seconds
DEBUG 01-05 09:59:08.013321.013321 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 09:59:08.013369.013369 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.014020.014020 cuda_h.py:19] end gate cost 0.0006220340728759766 seconds
DEBUG 01-05 09:59:08.014988.014988 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.014898.014898 lmp.py:365] 
DEBUG 01-05 09:59:08.014898.014898 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.014224.014224 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.014589.014589 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.014139.014139 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.014828.014828 lmp.py:369] 
DEBUG 01-05 09:59:08.014828.014828 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.014207.014207 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.014572.014572 lmp.py:376]   Expert 35 |      3 | CPU
DEBUG 01-05 09:59:08.014884.014884 lmp.py:376]   Expert 59 |     11 | CPU
DEBUG 01-05 09:59:08.014242.014242 lmp.py:376]   Expert 39 |     16 | CPU
DEBUG 01-05 09:59:08.014885.014885 lmp.py:376]   Expert 16 |     17 | CPU
DEBUG 01-05 09:59:08.014290.014290 lmp.py:376]   Expert 19 |     22 | CPU
DEBUG 01-05 09:59:08.015933.015933 lmp.py:376]   Expert  5 |     24 | CPU
DEBUG 01-05 09:59:08.015337.015337 lmp.py:376]   Expert  6 |     37 | CPU
DEBUG 01-05 09:59:08.015980.015980 lmp.py:376]   Expert 41 |     37 | CPU
DEBUG 01-05 09:59:08.015146.015146 lmp.py:376]   Expert 23 |     39 | CPU
DEBUG 01-05 09:59:08.015505.015505 lmp.py:376]   Expert 38 |     39 | CPU
DEBUG 01-05 09:59:08.015148.015148 lmp.py:376]   Expert 49 |     45 | CPU
DEBUG 01-05 09:59:08.015552.015552 lmp.py:376]   Expert 27 |     47 | CPU
DEBUG 01-05 09:59:08.015957.015957 lmp.py:376]   Expert  3 |     50 | CPU
DEBUG 01-05 09:59:08.015884.015884 lmp.py:376]   Expert 17 |     52 | CPU
DEBUG 01-05 09:59:08.015289.015289 lmp.py:376]   Expert  7 |     53 | CPU
DEBUG 01-05 09:59:08.015455.015455 lmp.py:376]   Expert 15 |     53 | CPU
DEBUG 01-05 09:59:08.015621.015621 lmp.py:376]   Expert 46 |     53 | CPU
DEBUG 01-05 09:59:08.015787.015787 lmp.py:376]   Expert  8 |     54 | CPU
DEBUG 01-05 09:59:08.015907.015907 lmp.py:376]   Expert 48 |     67 | CPU
DEBUG 01-05 09:59:08.015504.015504 lmp.py:376]   Expert  0 |     69 | CPU
DEBUG 01-05 09:59:08.015432.015432 lmp.py:376]   Expert 63 |     69 | CPU
DEBUG 01-05 09:59:08.015836.015836 lmp.py:376]   Expert 20 |     70 | CPU
DEBUG 01-05 09:59:08.015002.015002 lmp.py:376]   Expert 32 |     74 | CPU
DEBUG 01-05 09:59:08.015407.015407 lmp.py:376]   Expert 60 |     76 | CPU
DEBUG 01-05 09:59:08.015335.015335 lmp.py:376]   Expert 57 |     79 | CPU
DEBUG 01-05 09:59:08.015501.015501 lmp.py:376]   Expert 36 |     86 | CPU
DEBUG 01-05 09:59:08.015428.015428 lmp.py:376]   Expert 10 |     90 | CPU
DEBUG 01-05 09:59:08.015356.015356 lmp.py:376]   Expert 25 |     90 | CPU
DEBUG 01-05 09:59:08.015522.015522 lmp.py:376]   Expert  4 |     98 | CPU
DEBUG 01-05 09:59:08.015688.015688 lmp.py:376]   Expert 52 |    110 | CPU
DEBUG 01-05 09:59:08.015570.015570 lmp.py:376]   Expert 40 |    111 | CPU
DEBUG 01-05 09:59:08.015497.015497 lmp.py:376]   Expert 62 |    118 | CPU
DEBUG 01-05 09:59:08.015664.015664 lmp.py:376]   Expert 43 |    131 | GPU
DEBUG 01-05 09:59:08.015591.015591 lmp.py:376]   Expert 61 |    132 | GPU
DEBUG 01-05 09:59:08.015519.015519 lmp.py:376]   Expert 50 |    142 | GPU
DEBUG 01-05 09:59:08.015208.015208 lmp.py:376]   Expert 51 |    143 | GPU
DEBUG 01-05 09:59:08.015136.015136 lmp.py:376]   Expert 13 |    155 | GPU
DEBUG 01-05 09:59:08.015733.015733 lmp.py:376]   Expert 12 |    164 | GPU
DEBUG 01-05 09:59:08.015899.015899 lmp.py:376]   Expert  1 |    177 | GPU
DEBUG 01-05 09:59:08.015588.015588 lmp.py:376]   Expert 42 |    177 | GPU
DEBUG 01-05 09:59:08.015516.015516 lmp.py:376]   Expert 18 |    188 | GPU
DEBUG 01-05 09:59:08.015444.015444 lmp.py:376]   Expert 47 |    190 | GPU
DEBUG 01-05 09:59:08.015371.015371 lmp.py:376]   Expert 26 |    200 | GPU
DEBUG 01-05 09:59:08.015061.015061 lmp.py:376]   Expert 29 |    240 | GPU
DEBUG 01-05 09:59:08.015988.015988 lmp.py:376]   Expert 34 |    243 | GPU
DEBUG 01-05 09:59:08.015201.015201 lmp.py:376]   Expert 31 |    246 | GPU
DEBUG 01-05 09:59:08.015321.015321 lmp.py:376]   Expert 55 |    253 | GPU
DEBUG 01-05 09:59:08.015202.015202 lmp.py:376]   Expert 56 |    255 | GPU
DEBUG 01-05 09:59:08.015891.015891 lmp.py:376]   Expert 33 |    284 | GPU
DEBUG 01-05 09:59:08.015819.015819 lmp.py:376]   Expert 44 |    287 | GPU
DEBUG 01-05 09:59:08.015508.015508 lmp.py:376]   Expert 45 |    290 | GPU
DEBUG 01-05 09:59:08.015913.015913 lmp.py:376]   Expert  2 |    293 | GPU
DEBUG 01-05 09:59:08.015602.015602 lmp.py:376]   Expert 14 |    302 | GPU
DEBUG 01-05 09:59:08.015530.015530 lmp.py:376]   Expert 28 |    324 | GPU
DEBUG 01-05 09:59:08.015219.015219 lmp.py:376]   Expert 53 |    338 | GPU
DEBUG 01-05 09:59:08.015624.015624 lmp.py:376]   Expert 24 |    385 | GPU
DEBUG 01-05 09:59:08.015505.015505 lmp.py:376]   Expert  9 |    398 | GPU
DEBUG 01-05 09:59:08.015433.015433 lmp.py:376]   Expert 54 |    399 | GPU
DEBUG 01-05 09:59:08.015122.015122 lmp.py:376]   Expert 21 |    419 | GPU
DEBUG 01-05 09:59:08.015573.015573 lmp.py:376]   Expert 37 |    452 | GPU
DEBUG 01-05 09:59:08.015262.015262 lmp.py:376]   Expert 22 |    471 | GPU
DEBUG 01-05 09:59:08.015190.015190 lmp.py:376]   Expert 58 |    539 | GPU
DEBUG 01-05 09:59:08.015879.015879 lmp.py:376]   Expert 11 |    659 | GPU
DEBUG 01-05 09:59:08.016807.016807 lmp.py:376]   Expert 30 |   1553 | GPU
DEBUG 01-05 09:59:08.016404.016404 lmp.py:377] 
DEBUG 01-05 09:59:08.016404.016404 lmp.py:377]   CPU total tokens: 1859 (15.1%)
DEBUG 01-05 09:59:08.016000.016000 lmp.py:378]   GPU total tokens: 10429 (84.9%)
DEBUG 01-05 09:59:08.016889.016889 cuda_h.py:19] end experts_map_get cost 0.00154876708984375 seconds
DEBUG 01-05 09:59:08.016008.016008 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.016692.016692 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.016147.016147 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.016466.016466 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-05 09:59:08.016899.016899 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.016608.016608 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.016272.016272 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.016160.016160 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0605b76a-03cb-43c2-bae6-a90080191395
DEBUG 01-05 09:59:08.016868.016868 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.016515.016515 client.py:127] Model loaded
DEBUG 01-05 09:59:08.017849.017849 cuda_h.py:19] end sllm_worker_task cost 0.012148141860961914 seconds
INFO 01-05 09:59:08.017373.017373 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0605b76a-03cb-43c2-bae6-a90080191395
DEBUG 01-05 09:59:08.017024.017024 cuda_h.py:19] end load_into_gpu_async cost 0.0011467933654785156 seconds
DEBUG 01-05 09:59:08.017727.017727 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.018426.018426 cuda_h.py:19] end restore_tensors2 cost 0.00027942657470703125 seconds
DEBUG 01-05 09:59:08.018341.018341 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001965761184692383 seconds
DEBUG 01-05 09:59:08.020289.020289 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004603862762451172 seconds
DEBUG 01-05 09:59:08.020834.020834 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.020744.020744 lmp.py:423] 
DEBUG 01-05 09:59:08.020744.020744 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.020733.020733 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-05 09:59:08.020912.020912 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.031192.031192 mlpmodule.py:704] group tensors cost 0.010125398635864258 s
DEBUG 01-05 09:59:08.033958.033958 mlpmodule.py:742] pad cost 0.001781463623046875 s
DEBUG 01-05 09:59:08.033982.033982 mlpmodule.py:748] create cpu tensor cost 6.175041198730469e-05 s
DEBUG 01-05 09:59:08.033746.033746 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-05 09:59:08.043379.043379 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.044750.044750 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.044038.044038 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 09:59:08.044494.044494 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.062097.062097 mlpmodule.py:793] group einsum cost 0.028571605682373047 s
DEBUG 01-05 09:59:08.063619.063619 mlpmodule.py:801] cpy2cputensor cost 0.0005323886871337891 s
DEBUG 01-05 09:59:08.068439.068439 cuda_h.py:19] end wait_cetm_experts cost 0.0475003719329834 seconds
DEBUG 01-05 09:59:08.068677.068677 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.069922.069922 cuda_h.py:19] end gpu_sexperts cost 0.0005602836608886719 seconds
DEBUG 01-05 09:59:08.069957.069957 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.069052.069052 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:08.069424.069424 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.069088.069088 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0605b76a-03cb-43c2-bae6-a90080191395
INFO 01-05 09:59:08.071168.071168 client.py:127] Model loaded
DEBUG 01-05 09:59:08.071442.071442 cuda_h.py:19] end wait_experts cost 0.0024747848510742188 seconds
DEBUG 01-05 09:59:08.071575.071575 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.072616.072616 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.072223.072223 mlpmodule.py:531] gpu group tensors cost 0.0006413459777832031 s
DEBUG 01-05 09:59:08.081679.081679 mlpmodule.py:564] gpu pad cost 0.008808135986328125 s
DEBUG 01-05 09:59:08.085616.085616 mlpmodule.py:662]  experts func einsum cost 0.06397795677185059 s
DEBUG 01-05 09:59:08.085523.085523 mlpmodule.py:582] gpu group einsum cost 0.0037546157836914062 s
DEBUG 01-05 09:59:08.088175.088175 mlpmodule.py:611] gpu experts func einsum cost 0.016616344451904297 s
DEBUG 01-05 09:59:08.088066.088066 cuda_h.py:19] end gpu_experts cost 0.016799211502075195 seconds
DEBUG 01-05 09:59:08.088281.088281 cuda_h.py:19] end layer_moe_generate_11 cost 0.07511448860168457 seconds
DEBUG 01-05 09:59:08.089989.089989 lmp.py:217] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 09:59:08.089189.089189 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 09:59:08.089507.089507 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:59:08.089171.089171 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:59:08.089206.089206 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:08.089578.089578 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.508827209472656e-05 seconds
DEBUG 01-05 09:59:08.089320.089320 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.089065.089065 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.089518.089518 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.089315.089315 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.089461.089461 cuda_h.py:19] end allocate_cuda_memory cost 0.00017452239990234375 seconds
DEBUG 01-05 09:59:08.089570.089570 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.089902.089902 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.089169.089169 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.089971.089971 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 73e4d103-988d-47a6-b596-9204725b4921
DEBUG 01-05 09:59:08.090563.090563 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.090347.090347 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.090696.090696 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 73e4d103-988d-47a6-b596-9204725b4921
DEBUG 01-05 09:59:08.090155.090155 cuda_h.py:19] end load_into_gpu_async cost 0.001027822494506836 seconds
DEBUG 01-05 09:59:08.090620.090620 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.091371.091371 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-05 09:59:08.091889.091889 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015368461608886719 seconds
INFO 01-05 09:59:08.091947.091947 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 73e4d103-988d-47a6-b596-9204725b4921
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.094698.094698 cuda_h.py:19] end self_attn cost 0.0037031173706054688 seconds
DEBUG 01-05 09:59:08.094265.094265 cuda_h.py:19] end iln_self_attn_paln cost 0.005053043365478516 seconds
DEBUG 01-05 09:59:08.094208.094208 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 09:59:08.094454.094454 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.095219.095219 cuda_h.py:19] end gate cost 0.0006666183471679688 seconds
DEBUG 01-05 09:59:08.095433.095433 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.095398.095398 lmp.py:365] 
DEBUG 01-05 09:59:08.095398.095398 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.095061.095061 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.095241.095241 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.095129.095129 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.095679.095679 lmp.py:369] 
DEBUG 01-05 09:59:08.095679.095679 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.095991.095991 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.095740.095740 lmp.py:376]   Expert 51 |      3 | CPU
DEBUG 01-05 09:59:08.095767.095767 lmp.py:376]   Expert 22 |      4 | CPU
DEBUG 01-05 09:59:08.095364.095364 lmp.py:376]   Expert 34 |     14 | CPU
DEBUG 01-05 09:59:08.095722.095722 lmp.py:376]   Expert 44 |     15 | CPU
DEBUG 01-05 09:59:08.095796.095796 lmp.py:376]   Expert  0 |     17 | CPU
DEBUG 01-05 09:59:08.095392.095392 lmp.py:376]   Expert  4 |     18 | CPU
DEBUG 01-05 09:59:08.095989.095989 lmp.py:376]   Expert 12 |     18 | CPU
DEBUG 01-05 09:59:08.095109.095109 lmp.py:376]   Expert 11 |     24 | CPU
DEBUG 01-05 09:59:08.095242.095242 lmp.py:376]   Expert 16 |     24 | CPU
DEBUG 01-05 09:59:08.095740.095740 lmp.py:376]   Expert 29 |     26 | CPU
DEBUG 01-05 09:59:08.095714.095714 lmp.py:376]   Expert 13 |     30 | CPU
DEBUG 01-05 09:59:08.095211.095211 lmp.py:376]   Expert 27 |     34 | CPU
DEBUG 01-05 09:59:08.095946.095946 lmp.py:376]   Expert 45 |     39 | CPU
DEBUG 01-05 09:59:08.095967.095967 lmp.py:376]   Expert 32 |     43 | CPU
DEBUG 01-05 09:59:08.095464.095464 lmp.py:376]   Expert  8 |     47 | CPU
DEBUG 01-05 09:59:08.095961.095961 lmp.py:376]   Expert 63 |     54 | CPU
DEBUG 01-05 09:59:08.095697.095697 lmp.py:376]   Expert 41 |     55 | CPU
DEBUG 01-05 09:59:08.095717.095717 lmp.py:376]   Expert 37 |     58 | CPU
DEBUG 01-05 09:59:08.096453.096453 lmp.py:376]   Expert 23 |     63 | CPU
DEBUG 01-05 09:59:08.096473.096473 lmp.py:376]   Expert  2 |     64 | CPU
DEBUG 01-05 09:59:08.096732.096732 lmp.py:376]   Expert 47 |     77 | CPU
DEBUG 01-05 09:59:08.096468.096468 lmp.py:376]   Expert 49 |     77 | CPU
DEBUG 01-05 09:59:08.096488.096488 lmp.py:376]   Expert 38 |     89 | CPU
DEBUG 01-05 09:59:08.096985.096985 lmp.py:376]   Expert 30 |     90 | CPU
DEBUG 01-05 09:59:08.096244.096244 lmp.py:376]   Expert 55 |     90 | CPU
DEBUG 01-05 09:59:08.096980.096980 lmp.py:376]   Expert 62 |     90 | CPU
DEBUG 01-05 09:59:08.096669.096669 lmp.py:376]   Expert  3 |     92 | CPU
DEBUG 01-05 09:59:08.096405.096405 lmp.py:376]   Expert 31 |    112 | CPU
DEBUG 01-05 09:59:08.096663.096663 lmp.py:376]   Expert  7 |    118 | CPU
DEBUG 01-05 09:59:08.096922.096922 lmp.py:376]   Expert 35 |    128 | CPU
DEBUG 01-05 09:59:08.096327.096327 lmp.py:376]   Expert 46 |    132 | CPU
DEBUG 01-05 09:59:08.096539.096539 lmp.py:376]   Expert 61 |    140 | CPU
DEBUG 01-05 09:59:08.096752.096752 lmp.py:376]   Expert 53 |    141 | GPU
DEBUG 01-05 09:59:08.096202.096202 lmp.py:376]   Expert 14 |    144 | GPU
DEBUG 01-05 09:59:08.096653.096653 lmp.py:376]   Expert 42 |    146 | GPU
DEBUG 01-05 09:59:08.096104.096104 lmp.py:376]   Expert 26 |    148 | GPU
DEBUG 01-05 09:59:08.096270.096270 lmp.py:376]   Expert 58 |    152 | GPU
DEBUG 01-05 09:59:08.096960.096960 lmp.py:376]   Expert  5 |    154 | GPU
DEBUG 01-05 09:59:08.096411.096411 lmp.py:376]   Expert 57 |    167 | GPU
DEBUG 01-05 09:59:08.096146.096146 lmp.py:376]   Expert 60 |    179 | GPU
DEBUG 01-05 09:59:08.096359.096359 lmp.py:376]   Expert 39 |    183 | GPU
DEBUG 01-05 09:59:08.096293.096293 lmp.py:376]   Expert 21 |    185 | GPU
DEBUG 01-05 09:59:08.096982.096982 lmp.py:376]   Expert 59 |    192 | GPU
DEBUG 01-05 09:59:08.096195.096195 lmp.py:376]   Expert 24 |    196 | GPU
DEBUG 01-05 09:59:08.096646.096646 lmp.py:376]   Expert 18 |    210 | GPU
DEBUG 01-05 09:59:08.096858.096858 lmp.py:376]   Expert 28 |    216 | GPU
DEBUG 01-05 09:59:08.096501.096501 lmp.py:376]   Expert  6 |    222 | GPU
DEBUG 01-05 09:59:08.096952.096952 lmp.py:376]   Expert 19 |    239 | GPU
DEBUG 01-05 09:59:08.096165.096165 lmp.py:376]   Expert 17 |    249 | GPU
DEBUG 01-05 09:59:08.096377.096377 lmp.py:376]   Expert 54 |    251 | GPU
DEBUG 01-05 09:59:08.096590.096590 lmp.py:376]   Expert 43 |    263 | GPU
DEBUG 01-05 09:59:08.096564.096564 lmp.py:376]   Expert 52 |    276 | GPU
DEBUG 01-05 09:59:08.096299.096299 lmp.py:376]   Expert 20 |    277 | GPU
DEBUG 01-05 09:59:08.096512.096512 lmp.py:376]   Expert 50 |    298 | GPU
DEBUG 01-05 09:59:08.096486.096486 lmp.py:376]   Expert 25 |    307 | GPU
DEBUG 01-05 09:59:08.096937.096937 lmp.py:376]   Expert 48 |    317 | GPU
DEBUG 01-05 09:59:08.096149.096149 lmp.py:376]   Expert 40 |    335 | GPU
DEBUG 01-05 09:59:08.096600.096600 lmp.py:376]   Expert  1 |    379 | GPU
DEBUG 01-05 09:59:08.096812.096812 lmp.py:376]   Expert 36 |    402 | GPU
DEBUG 01-05 09:59:08.096786.096786 lmp.py:376]   Expert  9 |    479 | GPU
DEBUG 01-05 09:59:08.096760.096760 lmp.py:376]   Expert 15 |    663 | GPU
DEBUG 01-05 09:59:08.096735.096735 lmp.py:376]   Expert 56 |    719 | GPU
DEBUG 01-05 09:59:08.096709.096709 lmp.py:376]   Expert 33 |    783 | GPU
DEBUG 01-05 09:59:08.096683.096683 lmp.py:376]   Expert 10 |   1531 | GPU
DEBUG 01-05 09:59:08.096372.096372 lmp.py:377] 
DEBUG 01-05 09:59:08.096372.096372 lmp.py:377]   CPU total tokens: 1885 (15.3%)
DEBUG 01-05 09:59:08.096538.096538 lmp.py:378]   GPU total tokens: 10403 (84.7%)
DEBUG 01-05 09:59:08.096996.096996 cuda_h.py:19] end experts_map_get cost 0.0015420913696289062 seconds
DEBUG 01-05 09:59:08.096592.096592 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.096038.096038 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.096214.096214 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.098724.098724 cuda_h.py:19] end allocate_cuda_memory cost 0.0011513233184814453 seconds
DEBUG 01-05 09:59:08.098421.098421 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.098701.098701 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.098556.098556 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.098729.098729 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c18c595-0c6f-48de-9ad7-90abf832397f
DEBUG 01-05 09:59:08.098761.098761 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.098796.098796 client.py:127] Model loaded
DEBUG 01-05 09:59:08.098137.098137 cuda_h.py:19] end sllm_worker_task cost 0.009378194808959961 seconds
INFO 01-05 09:59:08.099071.099071 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c18c595-0c6f-48de-9ad7-90abf832397f
DEBUG 01-05 09:59:08.099676.099676 cuda_h.py:19] end load_into_gpu_async cost 0.0012431144714355469 seconds
DEBUG 01-05 09:59:08.099425.099425 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.099409.099409 cuda_h.py:19] end restore_tensors2 cost 0.00027942657470703125 seconds
DEBUG 01-05 09:59:08.099940.099940 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002995729446411133 seconds
DEBUG 01-05 09:59:08.102692.102692 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005521535873413086 seconds
DEBUG 01-05 09:59:08.102899.102899 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.102637.102637 lmp.py:423] 
DEBUG 01-05 09:59:08.102637.102637 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.102480.102480 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-05 09:59:08.102322.102322 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.115022.115022 mlpmodule.py:704] group tensors cost 0.012589693069458008 s
DEBUG 01-05 09:59:08.117909.117909 mlpmodule.py:742] pad cost 0.0016350746154785156 s
DEBUG 01-05 09:59:08.117866.117866 mlpmodule.py:748] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-05 09:59:08.117915.117915 mlpmodule.py:753] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-05 09:59:08.128240.128240 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.128789.128789 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.128700.128700 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 09:59:08.128856.128856 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.147185.147185 mlpmodule.py:793] group einsum cost 0.029735803604125977 s
DEBUG 01-05 09:59:08.148121.148121 mlpmodule.py:801] cpy2cputensor cost 0.0006170272827148438 s
DEBUG 01-05 09:59:08.153418.153418 cuda_h.py:19] end wait_cetm_experts cost 0.051044464111328125 seconds
DEBUG 01-05 09:59:08.153026.153026 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.154987.154987 cuda_h.py:19] end gpu_sexperts cost 0.0005600452423095703 seconds
DEBUG 01-05 09:59:08.154115.154115 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.154779.154779 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 09:59:08.154628.154628 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.154291.154291 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c18c595-0c6f-48de-9ad7-90abf832397f
INFO 01-05 09:59:08.155752.155752 client.py:127] Model loaded
DEBUG 01-05 09:59:08.155880.155880 cuda_h.py:19] end wait_experts cost 0.0009624958038330078 seconds
DEBUG 01-05 09:59:08.155536.155536 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.155862.155862 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.156839.156839 mlpmodule.py:531] gpu group tensors cost 0.0006341934204101562 s
DEBUG 01-05 09:59:08.158191.158191 mlpmodule.py:564] gpu pad cost 0.0017468929290771484 s
DEBUG 01-05 09:59:08.158727.158727 mlpmodule.py:582] gpu group einsum cost 0.0004963874816894531 s
DEBUG 01-05 09:59:08.162494.162494 mlpmodule.py:611] gpu experts func einsum cost 0.00652313232421875 s
DEBUG 01-05 09:59:08.162722.162722 cuda_h.py:19] end gpu_experts cost 0.00670933723449707 seconds
DEBUG 01-05 09:59:08.162414.162414 cuda_h.py:19] end layer_moe_generate_12 cost 0.068023681640625 seconds
DEBUG 01-05 09:59:08.162751.162751 lmp.py:217] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 09:59:08.162560.162560 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 09:59:08.162117.162117 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:59:08.162449.162449 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:59:08.162445.162445 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.647804260253906e-05 seconds
DEBUG 01-05 09:59:08.162300.162300 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.462501525878906e-05 seconds
DEBUG 01-05 09:59:08.162096.162096 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.162232.162232 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.163023.163023 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.163098.163098 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.168156.168156 cuda_h.py:19] end allocate_cuda_memory cost 0.005038261413574219 seconds
DEBUG 01-05 09:59:08.168496.168496 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.168399.168399 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.168978.168978 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.168423.168423 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 74501379-23bf-4af6-b908-d60c79813915
DEBUG 01-05 09:59:08.168785.168785 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.169614.169614 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.169130.169130 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 74501379-23bf-4af6-b908-d60c79813915
DEBUG 01-05 09:59:08.169153.169153 cuda_h.py:19] end load_into_gpu_async cost 0.0011532306671142578 seconds
DEBUG 01-05 09:59:08.169453.169453 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.169571.169571 cuda_h.py:19] end restore_tensors2 cost 0.00011134147644042969 seconds
DEBUG 01-05 09:59:08.170494.170494 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0069103240966796875 seconds
INFO 01-05 09:59:08.170681.170681 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 74501379-23bf-4af6-b908-d60c79813915
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.174489.174489 cuda_h.py:19] end self_attn cost 0.0054590702056884766 seconds
DEBUG 01-05 09:59:08.175629.175629 mlpmodule.py:662]  experts func einsum cost 0.07227182388305664 s
DEBUG 01-05 09:59:08.175079.175079 cuda_h.py:19] end iln_self_attn_paln cost 0.012503623962402344 seconds
DEBUG 01-05 09:59:08.175487.175487 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 09:59:08.175231.175231 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.176180.176180 cuda_h.py:19] end gate cost 0.0007927417755126953 seconds
DEBUG 01-05 09:59:08.176486.176486 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.176562.176562 lmp.py:365] 
DEBUG 01-05 09:59:08.176562.176562 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.176080.176080 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.176160.176160 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.176903.176903 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.176784.176784 lmp.py:369] 
DEBUG 01-05 09:59:08.176784.176784 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.176665.176665 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.176030.176030 lmp.py:376]   Expert  6 |      1 | CPU
DEBUG 01-05 09:59:08.176627.176627 lmp.py:376]   Expert 53 |      1 | CPU
DEBUG 01-05 09:59:08.176032.176032 lmp.py:376]   Expert 50 |     10 | CPU
DEBUG 01-05 09:59:08.177483.177483 lmp.py:376]   Expert  2 |     24 | CPU
DEBUG 01-05 09:59:08.177410.177410 lmp.py:376]   Expert  0 |     28 | CPU
DEBUG 01-05 09:59:08.177100.177100 lmp.py:376]   Expert 12 |     32 | CPU
DEBUG 01-05 09:59:08.177027.177027 lmp.py:376]   Expert 26 |     33 | CPU
DEBUG 01-05 09:59:08.177955.177955 lmp.py:376]   Expert 31 |     35 | CPU
DEBUG 01-05 09:59:08.177075.177075 lmp.py:376]   Expert  8 |     45 | CPU
DEBUG 01-05 09:59:08.177003.177003 lmp.py:376]   Expert 40 |     45 | CPU
DEBUG 01-05 09:59:08.177930.177930 lmp.py:376]   Expert 32 |     50 | CPU
DEBUG 01-05 09:59:08.177858.177858 lmp.py:376]   Expert 34 |     52 | CPU
DEBUG 01-05 09:59:08.177309.177309 lmp.py:376]   Expert 16 |     53 | CPU
DEBUG 01-05 09:59:08.177998.177998 lmp.py:376]   Expert 19 |     54 | CPU
DEBUG 01-05 09:59:08.177687.177687 lmp.py:376]   Expert 20 |     60 | CPU
DEBUG 01-05 09:59:08.177138.177138 lmp.py:376]   Expert 13 |     62 | CPU
DEBUG 01-05 09:59:08.177305.177305 lmp.py:376]   Expert  9 |     70 | CPU
DEBUG 01-05 09:59:08.177947.177947 lmp.py:376]   Expert 28 |     71 | CPU
DEBUG 01-05 09:59:08.177875.177875 lmp.py:376]   Expert 30 |     71 | CPU
DEBUG 01-05 09:59:08.177849.177849 lmp.py:376]   Expert 45 |     74 | CPU
DEBUG 01-05 09:59:08.177777.177777 lmp.py:376]   Expert 61 |     81 | CPU
DEBUG 01-05 09:59:08.177228.177228 lmp.py:376]   Expert 57 |     82 | CPU
DEBUG 01-05 09:59:08.177156.177156 lmp.py:376]   Expert 63 |     82 | CPU
DEBUG 01-05 09:59:08.177514.177514 lmp.py:376]   Expert 25 |     88 | CPU
DEBUG 01-05 09:59:08.177634.177634 lmp.py:376]   Expert 35 |     89 | CPU
DEBUG 01-05 09:59:08.177707.177707 lmp.py:376]   Expert 11 |     91 | CPU
DEBUG 01-05 09:59:08.177350.177350 lmp.py:376]   Expert  5 |     93 | CPU
DEBUG 01-05 09:59:08.177231.177231 lmp.py:376]   Expert 24 |     97 | CPU
DEBUG 01-05 09:59:08.177113.177113 lmp.py:376]   Expert 58 |    108 | CPU
DEBUG 01-05 09:59:08.177756.177756 lmp.py:376]   Expert 48 |    111 | CPU
DEBUG 01-05 09:59:08.177399.177399 lmp.py:376]   Expert 60 |    111 | CPU
DEBUG 01-05 09:59:08.177042.177042 lmp.py:376]   Expert 52 |    138 | CPU
DEBUG 01-05 09:59:08.177400.177400 lmp.py:376]   Expert 49 |    145 | GPU
DEBUG 01-05 09:59:08.177043.177043 lmp.py:376]   Expert 62 |    151 | GPU
DEBUG 01-05 09:59:08.177640.177640 lmp.py:376]   Expert  3 |    155 | GPU
DEBUG 01-05 09:59:08.177283.177283 lmp.py:376]   Expert 42 |    174 | GPU
DEBUG 01-05 09:59:08.177687.177687 lmp.py:376]   Expert 36 |    182 | GPU
DEBUG 01-05 09:59:08.177330.177330 lmp.py:376]   Expert 37 |    182 | GPU
DEBUG 01-05 09:59:08.177735.177735 lmp.py:376]   Expert 54 |    191 | GPU
DEBUG 01-05 09:59:08.177901.177901 lmp.py:376]   Expert 44 |    193 | GPU
DEBUG 01-05 09:59:08.177544.177544 lmp.py:376]   Expert  4 |    194 | GPU
DEBUG 01-05 09:59:08.177948.177948 lmp.py:376]   Expert 46 |    196 | GPU
DEBUG 01-05 09:59:08.177830.177830 lmp.py:376]   Expert 27 |    202 | GPU
DEBUG 01-05 09:59:08.177473.177473 lmp.py:376]   Expert  1 |    210 | GPU
DEBUG 01-05 09:59:08.177116.177116 lmp.py:376]   Expert 43 |    219 | GPU
DEBUG 01-05 09:59:08.177520.177520 lmp.py:376]   Expert 51 |    224 | GPU
DEBUG 01-05 09:59:08.177925.177925 lmp.py:376]   Expert 33 |    235 | GPU
DEBUG 01-05 09:59:08.177091.177091 lmp.py:376]   Expert 15 |    239 | GPU
DEBUG 01-05 09:59:08.177972.177972 lmp.py:376]   Expert 59 |    247 | GPU
DEBUG 01-05 09:59:08.177615.177615 lmp.py:376]   Expert 17 |    287 | GPU
DEBUG 01-05 09:59:08.177781.177781 lmp.py:376]   Expert 39 |    327 | GPU
DEBUG 01-05 09:59:08.177424.177424 lmp.py:376]   Expert 22 |    344 | GPU
DEBUG 01-05 09:59:08.177067.177067 lmp.py:376]   Expert 29 |    346 | GPU
DEBUG 01-05 09:59:08.177426.177426 lmp.py:376]   Expert 47 |    362 | GPU
DEBUG 01-05 09:59:08.177830.177830 lmp.py:376]   Expert  7 |    386 | GPU
DEBUG 01-05 09:59:08.177473.177473 lmp.py:376]   Expert 14 |    410 | GPU
DEBUG 01-05 09:59:08.177639.177639 lmp.py:376]   Expert 10 |    424 | GPU
DEBUG 01-05 09:59:08.177044.177044 lmp.py:376]   Expert 38 |    433 | GPU
DEBUG 01-05 09:59:08.177448.177448 lmp.py:376]   Expert 55 |    443 | GPU
DEBUG 01-05 09:59:08.177045.177045 lmp.py:376]   Expert 21 |    477 | GPU
DEBUG 01-05 09:59:08.178688.178688 lmp.py:376]   Expert 56 |    529 | GPU
DEBUG 01-05 09:59:08.178854.178854 lmp.py:376]   Expert 41 |    604 | GPU
DEBUG 01-05 09:59:08.178020.178020 lmp.py:376]   Expert 18 |    749 | GPU
DEBUG 01-05 09:59:08.178186.178186 lmp.py:376]   Expert 23 |    786 | GPU
DEBUG 01-05 09:59:08.178783.178783 lmp.py:377] 
DEBUG 01-05 09:59:08.178783.178783 lmp.py:377]   CPU total tokens: 2042 (16.6%)
DEBUG 01-05 09:59:08.178380.178380 lmp.py:378]   GPU total tokens: 10246 (83.4%)
DEBUG 01-05 09:59:08.178268.178268 cuda_h.py:19] end experts_map_get cost 0.001565694808959961 seconds
DEBUG 01-05 09:59:08.178295.178295 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.178932.178932 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.178685.178685 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.178886.178886 cuda_h.py:19] end allocate_cuda_memory cost 0.0002193450927734375 seconds
DEBUG 01-05 09:59:08.178490.178490 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.178962.178962 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.178692.178692 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.178726.178726 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7642945-a3ee-46ff-a8f9-dbc5e022960f
DEBUG 01-05 09:59:08.178718.178718 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.179905.179905 client.py:127] Model loaded
DEBUG 01-05 09:59:08.179651.179651 cuda_h.py:19] end sllm_worker_task cost 0.01618814468383789 seconds
INFO 01-05 09:59:08.179111.179111 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7642945-a3ee-46ff-a8f9-dbc5e022960f
DEBUG 01-05 09:59:08.180292.180292 cuda_h.py:19] end load_into_gpu_async cost 0.0013637542724609375 seconds
DEBUG 01-05 09:59:08.180234.180234 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.180601.180601 cuda_h.py:19] end restore_tensors2 cost 0.00028061866760253906 seconds
DEBUG 01-05 09:59:08.180584.180584 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022118091583251953 seconds
DEBUG 01-05 09:59:08.182610.182610 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004839181900024414 seconds
DEBUG 01-05 09:59:08.183625.183625 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.183489.183489 lmp.py:423] 
DEBUG 01-05 09:59:08.183489.183489 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.183338.183338 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-05 09:59:08.183611.183611 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.188505.188505 mlpmodule.py:704] group tensors cost 0.0053517818450927734 s
DEBUG 01-05 09:59:08.191355.191355 mlpmodule.py:742] pad cost 0.0020623207092285156 s
DEBUG 01-05 09:59:08.191916.191916 mlpmodule.py:748] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-05 09:59:08.191031.191031 mlpmodule.py:753] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-05 09:59:08.202569.202569 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.202007.202007 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.202156.202156 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 09:59:08.203466.203466 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.221442.221442 mlpmodule.py:793] group einsum cost 0.029386281967163086 s
DEBUG 01-05 09:59:08.222490.222490 mlpmodule.py:801] cpy2cputensor cost 0.0005788803100585938 s
DEBUG 01-05 09:59:08.227143.227143 cuda_h.py:19] end wait_cetm_experts cost 0.04388785362243652 seconds
DEBUG 01-05 09:59:08.227473.227473 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.227248.227248 cuda_h.py:19] end gpu_sexperts cost 0.0005655288696289062 seconds
DEBUG 01-05 09:59:08.228184.228184 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.228418.228418 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 09:59:08.228028.228028 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.228168.228168 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7642945-a3ee-46ff-a8f9-dbc5e022960f
INFO 01-05 09:59:08.234521.234521 client.py:127] Model loaded
DEBUG 01-05 09:59:08.234424.234424 cuda_h.py:19] end wait_experts cost 0.006439924240112305 seconds
DEBUG 01-05 09:59:08.234849.234849 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.234466.234466 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.235509.235509 mlpmodule.py:531] gpu group tensors cost 0.0006136894226074219 s
DEBUG 01-05 09:59:08.237858.237858 mlpmodule.py:564] gpu pad cost 0.0016787052154541016 s
DEBUG 01-05 09:59:08.237711.237711 mlpmodule.py:582] gpu group einsum cost 0.00048542022705078125 s
DEBUG 01-05 09:59:08.240799.240799 mlpmodule.py:611] gpu experts func einsum cost 0.0057048797607421875 s
DEBUG 01-05 09:59:08.240994.240994 cuda_h.py:19] end gpu_experts cost 0.005903959274291992 seconds
DEBUG 01-05 09:59:08.240269.240269 cuda_h.py:19] end layer_moe_generate_13 cost 0.06503152847290039 seconds
DEBUG 01-05 09:59:08.240619.240619 lmp.py:217] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 09:59:08.240858.240858 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 09:59:08.240839.240839 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:59:08.240595.240595 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:59:08.240524.240524 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.6702880859375e-05 seconds
DEBUG 01-05 09:59:08.240796.240796 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.6743621826171875e-05 seconds
DEBUG 01-05 09:59:08.240631.240631 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.241567.241567 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.241764.241764 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.241137.241137 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.241461.241461 cuda_h.py:19] end allocate_cuda_memory cost 0.00033736228942871094 seconds
DEBUG 01-05 09:59:08.241609.241609 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.241326.241326 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.241308.241308 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.241726.241726 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d7677d6-2c34-4901-8963-024976d0c2f7
DEBUG 01-05 09:59:08.241836.241836 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.242263.242263 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.242956.242956 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d7677d6-2c34-4901-8963-024976d0c2f7
DEBUG 01-05 09:59:08.242607.242607 cuda_h.py:19] end load_into_gpu_async cost 0.0010843276977539062 seconds
DEBUG 01-05 09:59:08.242833.242833 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.242784.242784 cuda_h.py:19] end restore_tensors2 cost 7.724761962890625e-05 seconds
DEBUG 01-05 09:59:08.242109.242109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001756906509399414 seconds
INFO 01-05 09:59:08.243671.243671 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d7677d6-2c34-4901-8963-024976d0c2f7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.246752.246752 cuda_h.py:19] end self_attn cost 0.0040547847747802734 seconds
DEBUG 01-05 09:59:08.246815.246815 cuda_h.py:19] end iln_self_attn_paln cost 0.005655527114868164 seconds
DEBUG 01-05 09:59:08.246890.246890 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 09:59:08.246414.246414 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.247866.247866 cuda_h.py:19] end gate cost 0.0006163120269775391 seconds
DEBUG 01-05 09:59:08.247835.247835 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.247275.247275 lmp.py:365] 
DEBUG 01-05 09:59:08.247275.247275 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.247151.247151 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.247662.247662 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.247311.247311 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.247862.247862 lmp.py:369] 
DEBUG 01-05 09:59:08.247862.247862 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.247174.247174 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.247969.247969 lmp.py:376]   Expert 61 |      2 | CPU
DEBUG 01-05 09:59:08.247758.247758 lmp.py:376]   Expert  7 |      3 | CPU
DEBUG 01-05 09:59:08.247785.247785 lmp.py:376]   Expert 49 |     24 | CPU
DEBUG 01-05 09:59:08.247620.247620 lmp.py:376]   Expert 48 |     28 | CPU
DEBUG 01-05 09:59:08.247694.247694 lmp.py:376]   Expert 59 |     36 | CPU
DEBUG 01-05 09:59:08.248290.248290 lmp.py:376]   Expert 38 |     40 | CPU
DEBUG 01-05 09:59:08.248364.248364 lmp.py:376]   Expert 40 |     41 | CPU
DEBUG 01-05 09:59:08.248722.248722 lmp.py:376]   Expert 50 |     41 | CPU
DEBUG 01-05 09:59:08.248080.248080 lmp.py:376]   Expert 55 |     41 | CPU
DEBUG 01-05 09:59:08.248438.248438 lmp.py:376]   Expert 32 |     43 | CPU
DEBUG 01-05 09:59:08.248320.248320 lmp.py:376]   Expert 17 |     52 | CPU
DEBUG 01-05 09:59:08.248248.248248 lmp.py:376]   Expert 18 |     54 | CPU
DEBUG 01-05 09:59:08.248652.248652 lmp.py:376]   Expert 43 |     63 | CPU
DEBUG 01-05 09:59:08.248057.248057 lmp.py:376]   Expert 20 |     75 | CPU
DEBUG 01-05 09:59:08.248653.248653 lmp.py:376]   Expert 29 |     81 | CPU
DEBUG 01-05 09:59:08.248581.248581 lmp.py:376]   Expert 35 |     83 | CPU
DEBUG 01-05 09:59:08.248224.248224 lmp.py:376]   Expert 42 |     86 | CPU
DEBUG 01-05 09:59:08.248152.248152 lmp.py:376]   Expert 23 |     89 | CPU
DEBUG 01-05 09:59:08.248318.248318 lmp.py:376]   Expert 34 |     94 | CPU
DEBUG 01-05 09:59:08.248007.248007 lmp.py:376]   Expert 54 |     96 | CPU
DEBUG 01-05 09:59:08.248127.248127 lmp.py:376]   Expert 28 |     97 | CPU
DEBUG 01-05 09:59:08.248816.248816 lmp.py:376]   Expert  0 |    104 | CPU
DEBUG 01-05 09:59:08.248082.248082 lmp.py:376]   Expert 60 |    106 | CPU
DEBUG 01-05 09:59:08.248486.248486 lmp.py:376]   Expert 12 |    109 | CPU
DEBUG 01-05 09:59:08.248368.248368 lmp.py:376]   Expert  8 |    115 | CPU
DEBUG 01-05 09:59:08.248057.248057 lmp.py:376]   Expert 52 |    115 | CPU
DEBUG 01-05 09:59:08.248700.248700 lmp.py:376]   Expert 51 |    117 | CPU
DEBUG 01-05 09:59:08.248165.248165 lmp.py:376]   Expert 21 |    131 | CPU
DEBUG 01-05 09:59:08.248569.248569 lmp.py:376]   Expert 41 |    142 | CPU
DEBUG 01-05 09:59:08.248258.248258 lmp.py:376]   Expert 62 |    151 | CPU
DEBUG 01-05 09:59:08.248478.248478 lmp.py:376]   Expert 30 |    164 | CPU
DEBUG 01-05 09:59:08.248167.248167 lmp.py:376]   Expert 57 |    171 | CPU
DEBUG 01-05 09:59:08.248002.248002 lmp.py:376]   Expert 39 |    179 | GPU
DEBUG 01-05 09:59:08.248407.248407 lmp.py:376]   Expert  6 |    185 | GPU
DEBUG 01-05 09:59:08.248050.248050 lmp.py:376]   Expert 16 |    199 | GPU
DEBUG 01-05 09:59:08.248977.248977 lmp.py:376]   Expert 46 |    200 | GPU
DEBUG 01-05 09:59:08.248620.248620 lmp.py:376]   Expert 53 |    208 | GPU
DEBUG 01-05 09:59:08.248071.248071 lmp.py:376]   Expert 27 |    211 | GPU
DEBUG 01-05 09:59:08.248952.248952 lmp.py:376]   Expert 19 |    220 | GPU
DEBUG 01-05 09:59:08.248119.248119 lmp.py:376]   Expert 58 |    222 | GPU
DEBUG 01-05 09:59:08.248954.248954 lmp.py:376]   Expert 11 |    224 | GPU
DEBUG 01-05 09:59:08.248881.248881 lmp.py:376]   Expert 33 |    230 | GPU
DEBUG 01-05 09:59:08.248763.248763 lmp.py:376]   Expert 45 |    245 | GPU
DEBUG 01-05 09:59:08.248452.248452 lmp.py:376]   Expert 14 |    249 | GPU
DEBUG 01-05 09:59:08.248857.248857 lmp.py:376]   Expert  3 |    256 | GPU
DEBUG 01-05 09:59:08.248784.248784 lmp.py:376]   Expert  1 |    260 | GPU
DEBUG 01-05 09:59:08.248666.248666 lmp.py:376]   Expert 37 |    262 | GPU
DEBUG 01-05 09:59:08.248309.248309 lmp.py:376]   Expert 47 |    265 | GPU
DEBUG 01-05 09:59:08.248144.248144 lmp.py:376]   Expert 13 |    270 | GPU
DEBUG 01-05 09:59:08.248025.248025 lmp.py:376]   Expert 31 |    275 | GPU
DEBUG 01-05 09:59:08.248907.248907 lmp.py:376]   Expert 44 |    301 | GPU
DEBUG 01-05 09:59:08.248086.248086 lmp.py:376]   Expert 56 |    310 | GPU
DEBUG 01-05 09:59:08.248252.248252 lmp.py:376]   Expert 63 |    312 | GPU
DEBUG 01-05 09:59:08.248703.248703 lmp.py:376]   Expert 22 |    314 | GPU
DEBUG 01-05 09:59:08.248585.248585 lmp.py:376]   Expert 26 |    349 | GPU
DEBUG 01-05 09:59:08.248274.248274 lmp.py:376]   Expert 15 |    356 | GPU
DEBUG 01-05 09:59:08.248155.248155 lmp.py:376]   Expert  4 |    369 | GPU
DEBUG 01-05 09:59:08.248083.248083 lmp.py:376]   Expert 36 |    370 | GPU
DEBUG 01-05 09:59:08.248488.248488 lmp.py:376]   Expert  2 |    389 | GPU
DEBUG 01-05 09:59:08.248939.248939 lmp.py:376]   Expert  5 |    391 | GPU
DEBUG 01-05 09:59:08.248105.248105 lmp.py:376]   Expert 25 |    423 | GPU
DEBUG 01-05 09:59:08.249317.249317 lmp.py:376]   Expert  9 |    483 | GPU
DEBUG 01-05 09:59:08.249960.249960 lmp.py:376]   Expert 10 |    561 | GPU
DEBUG 01-05 09:59:08.249411.249411 lmp.py:376]   Expert 24 |    606 | GPU
DEBUG 01-05 09:59:08.249246.249246 lmp.py:377] 
DEBUG 01-05 09:59:08.249246.249246 lmp.py:377]   CPU total tokens: 2594 (21.1%)
DEBUG 01-05 09:59:08.249128.249128 lmp.py:378]   GPU total tokens: 9694 (78.9%)
DEBUG 01-05 09:59:08.249016.249016 cuda_h.py:19] end experts_map_get cost 0.0016160011291503906 seconds
DEBUG 01-05 09:59:08.249659.249659 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.249534.249534 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.249327.249327 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.249521.249521 cuda_h.py:19] end allocate_cuda_memory cost 0.00021529197692871094 seconds
DEBUG 01-05 09:59:08.249278.249278 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.249749.249749 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.249810.249810 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.249606.249606 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 58560356-6774-45c2-8044-92e0dd160c30
DEBUG 01-05 09:59:08.249452.249452 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.250589.250589 mlpmodule.py:662]  experts func einsum cost 0.06663680076599121 s
INFO 01-05 09:59:08.250279.250279 client.py:127] Model loaded
DEBUG 01-05 09:59:08.250046.250046 cuda_h.py:19] end sllm_worker_task cost 0.009199142456054688 seconds
INFO 01-05 09:59:08.250886.250886 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 58560356-6774-45c2-8044-92e0dd160c30
DEBUG 01-05 09:59:08.250636.250636 cuda_h.py:19] end load_into_gpu_async cost 0.0011777877807617188 seconds
DEBUG 01-05 09:59:08.250816.250816 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.251415.251415 cuda_h.py:19] end restore_tensors2 cost 0.00027561187744140625 seconds
DEBUG 01-05 09:59:08.251092.251092 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020041465759277344 seconds
DEBUG 01-05 09:59:08.253987.253987 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0046389102935791016 seconds
DEBUG 01-05 09:59:08.253432.253432 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.253865.253865 lmp.py:423] 
DEBUG 01-05 09:59:08.253865.253865 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.253947.253947 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 09:59:08.253981.253981 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.258766.258766 mlpmodule.py:704] group tensors cost 0.0042994022369384766 s
DEBUG 01-05 09:59:08.260267.260267 mlpmodule.py:742] pad cost 0.0016798973083496094 s
DEBUG 01-05 09:59:08.260662.260662 mlpmodule.py:748] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-05 09:59:08.260234.260234 mlpmodule.py:753] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-05 09:59:08.272109.272109 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.272308.272308 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.272769.272769 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 09:59:08.273991.273991 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.293391.293391 mlpmodule.py:793] group einsum cost 0.032293081283569336 s
DEBUG 01-05 09:59:08.294408.294408 mlpmodule.py:801] cpy2cputensor cost 0.0006549358367919922 s
DEBUG 01-05 09:59:08.299272.299272 cuda_h.py:19] end wait_cetm_experts cost 0.04522132873535156 seconds
DEBUG 01-05 09:59:08.299159.299159 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.300749.300749 cuda_h.py:19] end gpu_sexperts cost 0.0005636215209960938 seconds
DEBUG 01-05 09:59:08.300883.300883 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.300309.300309 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:08.300443.300443 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.300437.300437 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 58560356-6774-45c2-8044-92e0dd160c30
INFO 01-05 09:59:08.304621.304621 client.py:127] Model loaded
DEBUG 01-05 09:59:08.304617.304617 cuda_h.py:19] end wait_experts cost 0.0043811798095703125 seconds
DEBUG 01-05 09:59:08.304466.304466 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.304268.304268 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.305894.305894 mlpmodule.py:531] gpu group tensors cost 0.0006225109100341797 s
DEBUG 01-05 09:59:08.307325.307325 mlpmodule.py:564] gpu pad cost 0.0017383098602294922 s
DEBUG 01-05 09:59:08.307564.307564 mlpmodule.py:582] gpu group einsum cost 0.000522613525390625 s
DEBUG 01-05 09:59:08.310630.310630 mlpmodule.py:611] gpu experts func einsum cost 0.006186008453369141 s
DEBUG 01-05 09:59:08.311660.311660 cuda_h.py:19] end gpu_experts cost 0.006365060806274414 seconds
DEBUG 01-05 09:59:08.311391.311391 cuda_h.py:19] end layer_moe_generate_14 cost 0.06438255310058594 seconds
DEBUG 01-05 09:59:08.311125.311125 lmp.py:217] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 09:59:08.311457.311457 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 09:59:08.311537.311537 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:59:08.311671.311671 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:59:08.311361.311361 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.8848648071289062e-05 seconds
DEBUG 01-05 09:59:08.311700.311700 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.176399230957031e-05 seconds
DEBUG 01-05 09:59:08.311582.311582 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.311989.311989 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.311932.311932 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.311769.311769 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.312014.312014 cuda_h.py:19] end allocate_cuda_memory cost 0.0005645751953125 seconds
DEBUG 01-05 09:59:08.312324.312324 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.312617.312617 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.312154.312154 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.312003.312003 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 825bbb99-7c78-468e-9b93-0ffa3db4fc7f
DEBUG 01-05 09:59:08.312357.312357 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.312416.312416 mlpmodule.py:662]  experts func einsum cost 0.0587308406829834 s
DEBUG 01-05 09:59:08.313073.313073 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.313047.313047 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 825bbb99-7c78-468e-9b93-0ffa3db4fc7f
DEBUG 01-05 09:59:08.313082.313082 cuda_h.py:19] end load_into_gpu_async cost 0.0010447502136230469 seconds
DEBUG 01-05 09:59:08.313116.313116 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.313245.313245 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-05 09:59:08.313822.313822 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002026796340942383 seconds
INFO 01-05 09:59:08.314760.314760 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 825bbb99-7c78-468e-9b93-0ffa3db4fc7f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.317398.317398 cuda_h.py:19] end self_attn cost 0.0038666725158691406 seconds
DEBUG 01-05 09:59:08.317831.317831 cuda_h.py:19] end iln_self_attn_paln cost 0.005842685699462891 seconds
DEBUG 01-05 09:59:08.317575.317575 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 09:59:08.317245.317245 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.318347.318347 cuda_h.py:19] end gate cost 0.0006387233734130859 seconds
DEBUG 01-05 09:59:08.318554.318554 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.318901.318901 lmp.py:365] 
DEBUG 01-05 09:59:08.318901.318901 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.318035.318035 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.318446.318446 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.318520.318520 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.318970.318970 lmp.py:369] 
DEBUG 01-05 09:59:08.318970.318970 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.318660.318660 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.318071.318071 lmp.py:376]   Expert 63 |      3 | CPU
DEBUG 01-05 09:59:08.318522.318522 lmp.py:376]   Expert 37 |     20 | CPU
DEBUG 01-05 09:59:08.318211.318211 lmp.py:376]   Expert  4 |     28 | CPU
DEBUG 01-05 09:59:08.318947.318947 lmp.py:376]   Expert 42 |     32 | CPU
DEBUG 01-05 09:59:08.318682.318682 lmp.py:376]   Expert  5 |     33 | CPU
DEBUG 01-05 09:59:08.318418.318418 lmp.py:376]   Expert 34 |     37 | CPU
DEBUG 01-05 09:59:08.318154.318154 lmp.py:376]   Expert 57 |     40 | CPU
DEBUG 01-05 09:59:08.318605.318605 lmp.py:376]   Expert 53 |     42 | CPU
DEBUG 01-05 09:59:08.318340.318340 lmp.py:376]   Expert 22 |     48 | CPU
DEBUG 01-05 09:59:08.318837.318837 lmp.py:376]   Expert 41 |     48 | CPU
DEBUG 01-05 09:59:08.318050.318050 lmp.py:376]   Expert 52 |     51 | CPU
DEBUG 01-05 09:59:08.318547.318547 lmp.py:376]   Expert 48 |     54 | CPU
DEBUG 01-05 09:59:08.318283.318283 lmp.py:376]   Expert 28 |     57 | CPU
DEBUG 01-05 09:59:08.318303.318303 lmp.py:376]   Expert 15 |     59 | CPU
DEBUG 01-05 09:59:08.318800.318800 lmp.py:376]   Expert 51 |     63 | CPU
DEBUG 01-05 09:59:08.318059.318059 lmp.py:376]   Expert 32 |     68 | CPU
DEBUG 01-05 09:59:08.318556.318556 lmp.py:376]   Expert  7 |     69 | CPU
DEBUG 01-05 09:59:08.318530.318530 lmp.py:376]   Expert 43 |     75 | CPU
DEBUG 01-05 09:59:08.318220.318220 lmp.py:376]   Expert 40 |     80 | CPU
DEBUG 01-05 09:59:08.318717.318717 lmp.py:376]   Expert 25 |     94 | CPU
DEBUG 01-05 09:59:08.318214.318214 lmp.py:376]   Expert 55 |     94 | CPU
DEBUG 01-05 09:59:08.318711.318711 lmp.py:376]   Expert 29 |     98 | CPU
DEBUG 01-05 09:59:08.318447.318447 lmp.py:376]   Expert 56 |    115 | CPU
DEBUG 01-05 09:59:08.318706.318706 lmp.py:376]   Expert  6 |    116 | CPU
DEBUG 01-05 09:59:08.318203.318203 lmp.py:376]   Expert 14 |    116 | CPU
DEBUG 01-05 09:59:08.318462.318462 lmp.py:376]   Expert 39 |    123 | CPU
DEBUG 01-05 09:59:08.319913.319913 lmp.py:376]   Expert 58 |    128 | CPU
DEBUG 01-05 09:59:08.319887.319887 lmp.py:376]   Expert 23 |    129 | CPU
DEBUG 01-05 09:59:08.319622.319622 lmp.py:376]   Expert 61 |    134 | CPU
DEBUG 01-05 09:59:08.319881.319881 lmp.py:376]   Expert 13 |    146 | CPU
DEBUG 01-05 09:59:08.319378.319378 lmp.py:376]   Expert 33 |    153 | CPU
DEBUG 01-05 09:59:08.319399.319399 lmp.py:376]   Expert 54 |    164 | CPU
DEBUG 01-05 09:59:08.319134.319134 lmp.py:376]   Expert 38 |    165 | GPU
DEBUG 01-05 09:59:08.319393.319393 lmp.py:376]   Expert 50 |    171 | GPU
DEBUG 01-05 09:59:08.319129.319129 lmp.py:376]   Expert 31 |    172 | GPU
DEBUG 01-05 09:59:08.319103.319103 lmp.py:376]   Expert 12 |    182 | GPU
DEBUG 01-05 09:59:08.319792.319792 lmp.py:376]   Expert  1 |    187 | GPU
DEBUG 01-05 09:59:08.319289.319289 lmp.py:376]   Expert  0 |    193 | GPU
DEBUG 01-05 09:59:08.319786.319786 lmp.py:376]   Expert 20 |    197 | GPU
DEBUG 01-05 09:59:08.319522.319522 lmp.py:376]   Expert 35 |    202 | GPU
DEBUG 01-05 09:59:08.319019.319019 lmp.py:376]   Expert 62 |    202 | GPU
DEBUG 01-05 09:59:08.319278.319278 lmp.py:376]   Expert 36 |    203 | GPU
DEBUG 01-05 09:59:08.319014.319014 lmp.py:376]   Expert 49 |    208 | GPU
DEBUG 01-05 09:59:08.319511.319511 lmp.py:376]   Expert 18 |    222 | GPU
DEBUG 01-05 09:59:08.319723.319723 lmp.py:376]   Expert 10 |    223 | GPU
DEBUG 01-05 09:59:08.319174.319174 lmp.py:376]   Expert 16 |    225 | GPU
DEBUG 01-05 09:59:08.319671.319671 lmp.py:376]   Expert 59 |    227 | GPU
DEBUG 01-05 09:59:08.319407.319407 lmp.py:376]   Expert  9 |    275 | GPU
DEBUG 01-05 09:59:08.319904.319904 lmp.py:376]   Expert 26 |    279 | GPU
DEBUG 01-05 09:59:08.319401.319401 lmp.py:376]   Expert 44 |    282 | GPU
DEBUG 01-05 09:59:08.319899.319899 lmp.py:376]   Expert 11 |    283 | GPU
DEBUG 01-05 09:59:08.319919.319919 lmp.py:376]   Expert 19 |    296 | GPU
DEBUG 01-05 09:59:08.319655.319655 lmp.py:376]   Expert 60 |    300 | GPU
DEBUG 01-05 09:59:08.319867.319867 lmp.py:376]   Expert 45 |    307 | GPU
DEBUG 01-05 09:59:08.319080.319080 lmp.py:376]   Expert 17 |    310 | GPU
DEBUG 01-05 09:59:08.319054.319054 lmp.py:376]   Expert 46 |    319 | GPU
DEBUG 01-05 09:59:08.319312.319312 lmp.py:376]   Expert 47 |    329 | GPU
DEBUG 01-05 09:59:08.319810.319810 lmp.py:376]   Expert  3 |    330 | GPU
DEBUG 01-05 09:59:08.319068.319068 lmp.py:376]   Expert 24 |    349 | GPU
DEBUG 01-05 09:59:08.319566.319566 lmp.py:376]   Expert 21 |    365 | GPU
DEBUG 01-05 09:59:08.319824.319824 lmp.py:376]   Expert  2 |    382 | GPU
DEBUG 01-05 09:59:08.319845.319845 lmp.py:376]   Expert 30 |    456 | GPU
DEBUG 01-05 09:59:08.319819.319819 lmp.py:376]   Expert 27 |    597 | GPU
DEBUG 01-05 09:59:08.319270.319270 lmp.py:376]   Expert  8 |   1333 | GPU
DEBUG 01-05 09:59:08.319244.319244 lmp.py:377] 
DEBUG 01-05 09:59:08.319244.319244 lmp.py:377]   CPU total tokens: 2517 (20.5%)
DEBUG 01-05 09:59:08.319695.319695 lmp.py:378]   GPU total tokens: 9771 (79.5%)
DEBUG 01-05 09:59:08.319199.319199 cuda_h.py:19] end experts_map_get cost 0.0014312267303466797 seconds
DEBUG 01-05 09:59:08.319650.319650 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.319995.319995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.319596.319596 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.320530.320530 cuda_h.py:19] end allocate_cuda_memory cost 0.0003743171691894531 seconds
DEBUG 01-05 09:59:08.320824.320824 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.320010.320010 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.320674.320674 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.320238.320238 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9ae16d13-7a24-4498-a32b-24cdf68d23b5
DEBUG 01-05 09:59:08.320363.320363 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.320044.320044 client.py:127] Model loaded
DEBUG 01-05 09:59:08.320887.320887 cuda_h.py:19] end sllm_worker_task cost 0.009138345718383789 seconds
INFO 01-05 09:59:08.321132.321132 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9ae16d13-7a24-4498-a32b-24cdf68d23b5
DEBUG 01-05 09:59:08.321022.321022 cuda_h.py:19] end load_into_gpu_async cost 0.0011293888092041016 seconds
DEBUG 01-05 09:59:08.321248.321248 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.321238.321238 cuda_h.py:19] end restore_tensors2 cost 0.0002841949462890625 seconds
DEBUG 01-05 09:59:08.321293.321293 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00212860107421875 seconds
DEBUG 01-05 09:59:08.324308.324308 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0046041011810302734 seconds
DEBUG 01-05 09:59:08.324323.324323 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.324704.324704 lmp.py:423] 
DEBUG 01-05 09:59:08.324704.324704 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.324646.324646 cuda_h.py:19] end cpu_experts_submit cost 0.0001399517059326172 seconds
DEBUG 01-05 09:59:08.324011.324011 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.334540.334540 mlpmodule.py:704] group tensors cost 0.009678363800048828 s
DEBUG 01-05 09:59:08.337995.337995 mlpmodule.py:742] pad cost 0.002012968063354492 s
DEBUG 01-05 09:59:08.337813.337813 mlpmodule.py:748] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-05 09:59:08.337954.337954 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 09:59:08.347274.347274 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.347506.347506 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.347126.347126 mlpmodule.py:773] group_w3 first element: -0.0186767578125
WARNING 01-05 09:59:08.348409.348409 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.368316.368316 mlpmodule.py:793] group einsum cost 0.03090977668762207 s
DEBUG 01-05 09:59:08.369644.369644 mlpmodule.py:801] cpy2cputensor cost 0.0006339550018310547 s
DEBUG 01-05 09:59:08.374634.374634 cuda_h.py:19] end wait_cetm_experts cost 0.0501704216003418 seconds
DEBUG 01-05 09:59:08.374759.374759 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.375494.375494 cuda_h.py:19] end gpu_sexperts cost 0.0005705356597900391 seconds
DEBUG 01-05 09:59:08.375053.375053 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.375433.375433 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:08.375904.375904 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.375190.375190 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9ae16d13-7a24-4498-a32b-24cdf68d23b5
INFO 01-05 09:59:08.376403.376403 client.py:127] Model loaded
DEBUG 01-05 09:59:08.376498.376498 cuda_h.py:19] end wait_experts cost 0.00110626220703125 seconds
DEBUG 01-05 09:59:08.376016.376016 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.376533.376533 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.377172.377172 mlpmodule.py:531] gpu group tensors cost 0.0005998611450195312 s
DEBUG 01-05 09:59:08.379206.379206 mlpmodule.py:564] gpu pad cost 0.0017600059509277344 s
DEBUG 01-05 09:59:08.380313.380313 mlpmodule.py:582] gpu group einsum cost 0.0005245208740234375 s
DEBUG 01-05 09:59:08.383025.383025 mlpmodule.py:611] gpu experts func einsum cost 0.006494760513305664 s
DEBUG 01-05 09:59:08.383393.383393 cuda_h.py:19] end gpu_experts cost 0.006673574447631836 seconds
DEBUG 01-05 09:59:08.383608.383608 cuda_h.py:19] end layer_moe_generate_15 cost 0.06621336936950684 seconds
DEBUG 01-05 09:59:08.383727.383727 lmp.py:217] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 09:59:08.383681.383681 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 09:59:08.383954.383954 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:59:08.383286.383286 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:59:08.384036.384036 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:59:08.384693.384693 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.437301635742188e-05 seconds
DEBUG 01-05 09:59:08.384720.384720 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.384656.384656 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.384778.384778 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.384230.384230 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.393690.393690 cuda_h.py:19] end allocate_cuda_memory cost 0.008931875228881836 seconds
DEBUG 01-05 09:59:08.393415.393415 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.393516.393516 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.393182.393182 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.393938.393938 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 74a59648-8096-419c-878a-786a0c610dee
DEBUG 01-05 09:59:08.393715.393715 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.393784.393784 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.394279.394279 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 74a59648-8096-419c-878a-786a0c610dee
DEBUG 01-05 09:59:08.394261.394261 cuda_h.py:19] end load_into_gpu_async cost 0.0010771751403808594 seconds
DEBUG 01-05 09:59:08.394010.394010 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.394900.394900 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-05 09:59:08.394226.394226 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0103759765625 seconds
INFO 01-05 09:59:08.395098.395098 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 74a59648-8096-419c-878a-786a0c610dee
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.397037.397037 cuda_h.py:19] end self_attn cost 0.0033295154571533203 seconds
DEBUG 01-05 09:59:08.397517.397517 cuda_h.py:19] end iln_self_attn_paln cost 0.01347970962524414 seconds
DEBUG 01-05 09:59:08.397307.397307 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 09:59:08.397044.397044 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.398278.398278 cuda_h.py:19] end gate cost 0.0006284713745117188 seconds
DEBUG 01-05 09:59:08.398246.398246 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.398885.398885 lmp.py:365] 
DEBUG 01-05 09:59:08.398885.398885 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.398118.398118 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.398298.398298 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.398325.398325 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.398014.398014 lmp.py:369] 
DEBUG 01-05 09:59:08.398014.398014 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.398942.398942 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.398638.398638 lmp.py:376]   Expert 58 |     17 | CPU
DEBUG 01-05 09:59:08.398566.398566 lmp.py:376]   Expert 49 |     39 | CPU
DEBUG 01-05 09:59:08.398494.398494 lmp.py:376]   Expert 54 |     39 | CPU
DEBUG 01-05 09:59:08.398137.398137 lmp.py:376]   Expert 14 |     57 | CPU
DEBUG 01-05 09:59:08.398349.398349 lmp.py:376]   Expert 39 |     62 | CPU
DEBUG 01-05 09:59:08.398085.398085 lmp.py:376]   Expert 13 |     63 | CPU
DEBUG 01-05 09:59:08.398297.398297 lmp.py:376]   Expert 62 |     66 | CPU
DEBUG 01-05 09:59:08.398033.398033 lmp.py:376]   Expert 59 |     68 | CPU
DEBUG 01-05 09:59:08.398768.398768 lmp.py:376]   Expert 18 |     69 | CPU
DEBUG 01-05 09:59:08.398266.398266 lmp.py:376]   Expert 60 |     71 | CPU
DEBUG 01-05 09:59:08.398001.398001 lmp.py:376]   Expert 41 |     73 | CPU
DEBUG 01-05 09:59:08.398737.398737 lmp.py:376]   Expert  6 |     74 | CPU
DEBUG 01-05 09:59:08.399472.399472 lmp.py:376]   Expert 32 |     80 | CPU
DEBUG 01-05 09:59:08.399923.399923 lmp.py:376]   Expert 34 |     82 | CPU
DEBUG 01-05 09:59:08.399659.399659 lmp.py:376]   Expert 11 |     84 | CPU
DEBUG 01-05 09:59:08.399918.399918 lmp.py:376]   Expert 31 |     87 | CPU
DEBUG 01-05 09:59:08.399415.399415 lmp.py:376]   Expert 45 |     95 | CPU
DEBUG 01-05 09:59:08.399912.399912 lmp.py:376]   Expert 44 |     97 | CPU
DEBUG 01-05 09:59:08.399648.399648 lmp.py:376]   Expert 61 |     98 | CPU
DEBUG 01-05 09:59:08.399145.399145 lmp.py:376]   Expert  0 |    103 | CPU
DEBUG 01-05 09:59:08.399881.399881 lmp.py:376]   Expert 25 |    113 | CPU
DEBUG 01-05 09:59:08.399855.399855 lmp.py:376]   Expert 15 |    118 | CPU
DEBUG 01-05 09:59:08.399259.399259 lmp.py:376]   Expert 30 |    121 | CPU
DEBUG 01-05 09:59:08.399425.399425 lmp.py:376]   Expert 42 |    125 | CPU
DEBUG 01-05 09:59:08.399737.399737 lmp.py:376]   Expert 35 |    127 | CPU
DEBUG 01-05 09:59:08.399996.399996 lmp.py:376]   Expert 12 |    130 | CPU
DEBUG 01-05 09:59:08.399493.399493 lmp.py:376]   Expert 57 |    131 | CPU
DEBUG 01-05 09:59:08.399752.399752 lmp.py:376]   Expert 26 |    139 | CPU
DEBUG 01-05 09:59:08.399965.399965 lmp.py:376]   Expert 63 |    139 | CPU
DEBUG 01-05 09:59:08.399462.399462 lmp.py:376]   Expert 28 |    150 | CPU
DEBUG 01-05 09:59:08.399959.399959 lmp.py:376]   Expert 47 |    151 | CPU
DEBUG 01-05 09:59:08.399218.399218 lmp.py:376]   Expert 56 |    151 | CPU
DEBUG 01-05 09:59:08.399953.399953 lmp.py:376]   Expert 21 |    153 | GPU
DEBUG 01-05 09:59:08.399212.399212 lmp.py:376]   Expert 48 |    163 | GPU
DEBUG 01-05 09:59:08.399709.399709 lmp.py:376]   Expert 38 |    164 | GPU
DEBUG 01-05 09:59:08.399968.399968 lmp.py:376]   Expert 55 |    180 | GPU
DEBUG 01-05 09:59:08.399896.399896 lmp.py:376]   Expert 50 |    196 | GPU
DEBUG 01-05 09:59:08.399155.399155 lmp.py:376]   Expert 51 |    197 | GPU
DEBUG 01-05 09:59:08.399413.399413 lmp.py:376]   Expert 24 |    205 | GPU
DEBUG 01-05 09:59:08.399911.399911 lmp.py:376]   Expert 43 |    221 | GPU
DEBUG 01-05 09:59:08.399693.399693 lmp.py:376]   Expert 20 |    223 | GPU
DEBUG 01-05 09:59:08.399951.399951 lmp.py:376]   Expert 17 |    228 | GPU
DEBUG 01-05 09:59:08.399972.399972 lmp.py:376]   Expert  2 |    229 | GPU
DEBUG 01-05 09:59:08.399992.399992 lmp.py:376]   Expert 36 |    229 | GPU
DEBUG 01-05 09:59:08.399489.399489 lmp.py:376]   Expert  3 |    245 | GPU
DEBUG 01-05 09:59:08.399232.399232 lmp.py:376]   Expert 40 |    249 | GPU
DEBUG 01-05 09:59:08.399159.399159 lmp.py:376]   Expert  7 |    250 | GPU
DEBUG 01-05 09:59:08.399657.399657 lmp.py:376]   Expert  9 |    273 | GPU
DEBUG 01-05 09:59:08.399915.399915 lmp.py:376]   Expert 37 |    275 | GPU
DEBUG 01-05 09:59:08.399936.399936 lmp.py:376]   Expert 46 |    298 | GPU
DEBUG 01-05 09:59:08.399718.399718 lmp.py:376]   Expert 53 |    300 | GPU
DEBUG 01-05 09:59:08.399500.399500 lmp.py:376]   Expert  4 |    305 | GPU
DEBUG 01-05 09:59:08.399759.399759 lmp.py:376]   Expert  1 |    314 | GPU
DEBUG 01-05 09:59:08.399779.399779 lmp.py:376]   Expert 19 |    324 | GPU
DEBUG 01-05 09:59:08.399276.399276 lmp.py:376]   Expert  8 |    325 | GPU
DEBUG 01-05 09:59:08.399535.399535 lmp.py:376]   Expert 33 |    326 | GPU
DEBUG 01-05 09:59:08.399794.399794 lmp.py:376]   Expert 16 |    359 | GPU
DEBUG 01-05 09:59:08.399052.399052 lmp.py:376]   Expert 29 |    363 | GPU
DEBUG 01-05 09:59:08.399742.399742 lmp.py:376]   Expert 10 |    364 | GPU
DEBUG 01-05 09:59:08.399001.399001 lmp.py:376]   Expert 27 |    380 | GPU
DEBUG 01-05 09:59:08.399259.399259 lmp.py:376]   Expert 22 |    416 | GPU
DEBUG 01-05 09:59:08.399518.399518 lmp.py:376]   Expert 52 |    464 | GPU
DEBUG 01-05 09:59:08.399015.399015 lmp.py:376]   Expert  5 |    496 | GPU
DEBUG 01-05 09:59:08.399089.399089 lmp.py:376]   Expert 23 |    555 | GPU
DEBUG 01-05 09:59:08.399493.399493 lmp.py:377] 
DEBUG 01-05 09:59:08.399493.399493 lmp.py:377]   CPU total tokens: 3019 (24.6%)
DEBUG 01-05 09:59:08.399852.399852 lmp.py:378]   GPU total tokens: 9269 (75.4%)
DEBUG 01-05 09:59:08.399170.399170 cuda_h.py:19] end experts_map_get cost 0.0014603137969970703 seconds
DEBUG 01-05 09:59:08.399482.399482 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.399974.399974 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.400150.400150 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.401877.401877 cuda_h.py:19] end allocate_cuda_memory cost 0.001697540283203125 seconds
DEBUG 01-05 09:59:08.401051.401051 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.401092.401092 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.401247.401247 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.401281.401281 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7d490ba-0cec-4aa2-9620-38b66fa3cb1c
DEBUG 01-05 09:59:08.402287.402287 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.402996.402996 mlpmodule.py:662]  experts func einsum cost 0.07768511772155762 s
INFO 01-05 09:59:08.402361.402361 client.py:127] Model loaded
DEBUG 01-05 09:59:08.402175.402175 cuda_h.py:19] end sllm_worker_task cost 0.01858687400817871 seconds
INFO 01-05 09:59:08.403705.403705 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7d490ba-0cec-4aa2-9620-38b66fa3cb1c
DEBUG 01-05 09:59:08.403270.403270 cuda_h.py:19] end load_into_gpu_async cost 0.0013566017150878906 seconds
DEBUG 01-05 09:59:08.403642.403642 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.403778.403778 cuda_h.py:19] end restore_tensors2 cost 0.0002853870391845703 seconds
DEBUG 01-05 09:59:08.403978.403978 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036668777465820312 seconds
DEBUG 01-05 09:59:08.406910.406910 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006222248077392578 seconds
DEBUG 01-05 09:59:08.406309.406309 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.406126.406126 lmp.py:423] 
DEBUG 01-05 09:59:08.406126.406126 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.406069.406069 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-05 09:59:08.406910.406910 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.417249.417249 mlpmodule.py:704] group tensors cost 0.010601043701171875 s
DEBUG 01-05 09:59:08.419636.419636 mlpmodule.py:742] pad cost 0.0016689300537109375 s
DEBUG 01-05 09:59:08.419110.419110 mlpmodule.py:748] create cpu tensor cost 4.3392181396484375e-05 s
DEBUG 01-05 09:59:08.419722.419722 mlpmodule.py:753] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-05 09:59:08.430905.430905 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.430645.430645 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.430238.430238 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 09:59:08.430348.430348 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.448639.448639 mlpmodule.py:793] group einsum cost 0.02889704704284668 s
DEBUG 01-05 09:59:08.449898.449898 mlpmodule.py:801] cpy2cputensor cost 0.0006170272827148438 s
DEBUG 01-05 09:59:08.454592.454592 cuda_h.py:19] end wait_cetm_experts cost 0.048181772232055664 seconds
DEBUG 01-05 09:59:08.454472.454472 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.455062.455062 cuda_h.py:19] end gpu_sexperts cost 0.0005671977996826172 seconds
DEBUG 01-05 09:59:08.455004.455004 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.455338.455338 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:08.455994.455994 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.455181.455181 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7d490ba-0cec-4aa2-9620-38b66fa3cb1c
INFO 01-05 09:59:08.458485.458485 client.py:127] Model loaded
DEBUG 01-05 09:59:08.458858.458858 cuda_h.py:19] end wait_experts cost 0.002607583999633789 seconds
DEBUG 01-05 09:59:08.458229.458229 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.458270.458270 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.458996.458996 mlpmodule.py:531] gpu group tensors cost 0.0006296634674072266 s
DEBUG 01-05 09:59:08.460329.460329 mlpmodule.py:564] gpu pad cost 0.0017685890197753906 s
DEBUG 01-05 09:59:08.461296.461296 mlpmodule.py:582] gpu group einsum cost 0.0005273818969726562 s
DEBUG 01-05 09:59:08.464365.464365 mlpmodule.py:611] gpu experts func einsum cost 0.00651860237121582 s
DEBUG 01-05 09:59:08.464925.464925 cuda_h.py:19] end gpu_experts cost 0.006699085235595703 seconds
DEBUG 01-05 09:59:08.465941.465941 cuda_h.py:19] end layer_moe_generate_16 cost 0.06734490394592285 seconds
DEBUG 01-05 09:59:08.465516.465516 lmp.py:217] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 09:59:08.465855.465855 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 09:59:08.465459.465459 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:59:08.465282.465282 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:59:08.465469.465469 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 4.100799560546875e-05 seconds
DEBUG 01-05 09:59:08.465498.465498 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 8.96453857421875e-05 seconds
DEBUG 01-05 09:59:08.465763.465763 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.465647.465647 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.465498.465498 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.465911.465911 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.466870.466870 cuda_h.py:19] end allocate_cuda_memory cost 0.0008940696716308594 seconds
DEBUG 01-05 09:59:08.466126.466126 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.466174.466174 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.466672.466672 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.466806.466806 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c24ae0a5-dddc-4197-9d65-89ff2a5355ed
DEBUG 01-05 09:59:08.467968.467968 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.467610.467610 mlpmodule.py:662]  experts func einsum cost 0.06058835983276367 s
DEBUG 01-05 09:59:08.467726.467726 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.467286.467286 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c24ae0a5-dddc-4197-9d65-89ff2a5355ed
DEBUG 01-05 09:59:08.467990.467990 cuda_h.py:19] end load_into_gpu_async cost 0.0010209083557128906 seconds
DEBUG 01-05 09:59:08.467262.467262 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.467391.467391 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-05 09:59:08.468763.468763 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023355484008789062 seconds
INFO 01-05 09:59:08.468921.468921 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c24ae0a5-dddc-4197-9d65-89ff2a5355ed
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.471923.471923 cuda_h.py:19] end self_attn cost 0.0034067630767822266 seconds
DEBUG 01-05 09:59:08.471032.471032 cuda_h.py:19] end iln_self_attn_paln cost 0.0058214664459228516 seconds
DEBUG 01-05 09:59:08.471537.471537 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 09:59:08.471538.471538 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.472044.472044 cuda_h.py:19] end gate cost 0.0006208419799804688 seconds
DEBUG 01-05 09:59:08.472489.472489 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.472519.472519 lmp.py:365] 
DEBUG 01-05 09:59:08.472519.472519 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.472798.472798 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.472925.472925 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.472475.472475 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.472164.472164 lmp.py:369] 
DEBUG 01-05 09:59:08.472164.472164 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.472854.472854 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.472788.472788 lmp.py:376]   Expert 28 |     31 | CPU
DEBUG 01-05 09:59:08.472716.472716 lmp.py:376]   Expert 14 |     37 | CPU
DEBUG 01-05 09:59:08.472928.472928 lmp.py:376]   Expert 40 |     41 | CPU
DEBUG 01-05 09:59:08.472664.472664 lmp.py:376]   Expert 46 |     44 | CPU
DEBUG 01-05 09:59:08.472638.472638 lmp.py:376]   Expert  1 |     50 | CPU
DEBUG 01-05 09:59:08.472135.472135 lmp.py:376]   Expert 36 |     54 | CPU
DEBUG 01-05 09:59:08.472825.472825 lmp.py:376]   Expert 47 |     54 | CPU
DEBUG 01-05 09:59:08.472799.472799 lmp.py:376]   Expert 39 |     55 | CPU
DEBUG 01-05 09:59:08.472296.472296 lmp.py:376]   Expert 25 |     63 | CPU
DEBUG 01-05 09:59:08.472031.472031 lmp.py:376]   Expert 54 |     64 | CPU
DEBUG 01-05 09:59:08.472529.472529 lmp.py:376]   Expert 30 |     76 | CPU
DEBUG 01-05 09:59:08.472026.472026 lmp.py:376]   Expert 27 |     78 | CPU
DEBUG 01-05 09:59:08.472523.472523 lmp.py:376]   Expert  7 |     92 | CPU
DEBUG 01-05 09:59:08.472020.472020 lmp.py:376]   Expert 31 |     98 | CPU
DEBUG 01-05 09:59:08.472233.472233 lmp.py:376]   Expert 59 |    101 | CPU
DEBUG 01-05 09:59:08.472684.472684 lmp.py:376]   Expert 61 |    102 | CPU
DEBUG 01-05 09:59:08.472658.472658 lmp.py:376]   Expert 16 |    109 | CPU
DEBUG 01-05 09:59:08.472916.472916 lmp.py:376]   Expert  8 |    110 | CPU
DEBUG 01-05 09:59:08.472652.472652 lmp.py:376]   Expert 21 |    110 | CPU
DEBUG 01-05 09:59:08.472672.472672 lmp.py:376]   Expert 60 |    114 | CPU
DEBUG 01-05 09:59:08.472931.472931 lmp.py:376]   Expert 52 |    118 | CPU
DEBUG 01-05 09:59:08.472428.472428 lmp.py:376]   Expert 50 |    120 | CPU
DEBUG 01-05 09:59:08.472687.472687 lmp.py:376]   Expert 29 |    127 | CPU
DEBUG 01-05 09:59:08.472184.472184 lmp.py:376]   Expert 24 |    132 | CPU
DEBUG 01-05 09:59:08.472397.472397 lmp.py:376]   Expert 34 |    132 | CPU
DEBUG 01-05 09:59:08.472371.472371 lmp.py:376]   Expert  3 |    135 | CPU
DEBUG 01-05 09:59:08.472630.472630 lmp.py:376]   Expert 56 |    142 | CPU
DEBUG 01-05 09:59:08.472365.472365 lmp.py:376]   Expert  2 |    146 | CPU
DEBUG 01-05 09:59:08.472624.472624 lmp.py:376]   Expert 51 |    146 | CPU
DEBUG 01-05 09:59:08.472552.472552 lmp.py:376]   Expert 63 |    148 | CPU
DEBUG 01-05 09:59:08.473241.473241 lmp.py:376]   Expert  9 |    150 | CPU
DEBUG 01-05 09:59:08.473930.473930 lmp.py:376]   Expert 33 |    150 | CPU
DEBUG 01-05 09:59:08.473381.473381 lmp.py:376]   Expert  6 |    160 | GPU
DEBUG 01-05 09:59:08.473263.473263 lmp.py:376]   Expert 15 |    163 | GPU
DEBUG 01-05 09:59:08.473952.473952 lmp.py:376]   Expert 58 |    163 | GPU
DEBUG 01-05 09:59:08.473403.473403 lmp.py:376]   Expert 10 |    176 | GPU
DEBUG 01-05 09:59:08.473854.473854 lmp.py:376]   Expert 18 |    181 | GPU
DEBUG 01-05 09:59:08.473066.473066 lmp.py:376]   Expert  0 |    182 | GPU
DEBUG 01-05 09:59:08.473279.473279 lmp.py:376]   Expert 53 |    190 | GPU
DEBUG 01-05 09:59:08.473730.473730 lmp.py:376]   Expert  4 |    193 | GPU
DEBUG 01-05 09:59:08.473896.473896 lmp.py:376]   Expert 32 |    198 | GPU
DEBUG 01-05 09:59:08.473347.473347 lmp.py:376]   Expert 42 |    205 | GPU
DEBUG 01-05 09:59:08.473559.473559 lmp.py:376]   Expert 35 |    217 | GPU
DEBUG 01-05 09:59:08.473010.473010 lmp.py:376]   Expert  5 |    242 | GPU
DEBUG 01-05 09:59:08.473461.473461 lmp.py:376]   Expert 23 |    251 | GPU
DEBUG 01-05 09:59:08.473435.473435 lmp.py:376]   Expert 62 |    252 | GPU
DEBUG 01-05 09:59:08.473647.473647 lmp.py:376]   Expert 11 |    253 | GPU
DEBUG 01-05 09:59:08.473860.473860 lmp.py:376]   Expert 37 |    260 | GPU
DEBUG 01-05 09:59:08.473072.473072 lmp.py:376]   Expert 45 |    286 | GPU
DEBUG 01-05 09:59:08.473000.473000 lmp.py:376]   Expert 13 |    291 | GPU
DEBUG 01-05 09:59:08.473212.473212 lmp.py:376]   Expert 48 |    291 | GPU
DEBUG 01-05 09:59:08.473663.473663 lmp.py:376]   Expert 43 |    299 | GPU
DEBUG 01-05 09:59:08.473637.473637 lmp.py:376]   Expert 49 |    305 | GPU
DEBUG 01-05 09:59:08.473088.473088 lmp.py:376]   Expert 12 |    317 | GPU
DEBUG 01-05 09:59:08.473539.473539 lmp.py:376]   Expert 38 |    324 | GPU
DEBUG 01-05 09:59:08.473513.473513 lmp.py:376]   Expert 20 |    327 | GPU
DEBUG 01-05 09:59:08.473679.473679 lmp.py:376]   Expert 44 |    328 | GPU
DEBUG 01-05 09:59:08.473607.473607 lmp.py:376]   Expert 22 |    336 | GPU
DEBUG 01-05 09:59:08.473820.473820 lmp.py:376]   Expert 19 |    358 | GPU
DEBUG 01-05 09:59:08.473270.473270 lmp.py:376]   Expert 41 |    379 | GPU
DEBUG 01-05 09:59:08.473244.473244 lmp.py:376]   Expert 57 |    387 | GPU
DEBUG 01-05 09:59:08.473457.473457 lmp.py:376]   Expert 26 |    479 | GPU
DEBUG 01-05 09:59:08.473908.473908 lmp.py:376]   Expert 17 |    565 | GPU
DEBUG 01-05 09:59:08.473882.473882 lmp.py:376]   Expert 55 |    601 | GPU
DEBUG 01-05 09:59:08.473048.473048 lmp.py:377] 
DEBUG 01-05 09:59:08.473048.473048 lmp.py:377]   CPU total tokens: 3129 (25.5%)
DEBUG 01-05 09:59:08.473929.473929 lmp.py:378]   GPU total tokens: 9159 (74.5%)
DEBUG 01-05 09:59:08.473625.473625 cuda_h.py:19] end experts_map_get cost 0.0014774799346923828 seconds
DEBUG 01-05 09:59:08.473030.473030 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.473760.473760 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.473890.473890 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.475684.475684 cuda_h.py:19] end allocate_cuda_memory cost 0.001325368881225586 seconds
DEBUG 01-05 09:59:08.475349.475349 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.475628.475628 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.475576.475576 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.475272.475272 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d17ba49-cf42-42e5-ad43-a8855a560a7a
DEBUG 01-05 09:59:08.475357.475357 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.475559.475559 client.py:127] Model loaded
DEBUG 01-05 09:59:08.475163.475163 cuda_h.py:19] end sllm_worker_task cost 0.010188817977905273 seconds
INFO 01-05 09:59:08.476261.476261 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d17ba49-cf42-42e5-ad43-a8855a560a7a
DEBUG 01-05 09:59:08.476442.476442 cuda_h.py:19] end load_into_gpu_async cost 0.001369476318359375 seconds
DEBUG 01-05 09:59:08.476383.476383 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.476348.476348 cuda_h.py:19] end restore_tensors2 cost 0.0002994537353515625 seconds
DEBUG 01-05 09:59:08.477356.477356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033311843872070312 seconds
DEBUG 01-05 09:59:08.479235.479235 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005882978439331055 seconds
DEBUG 01-05 09:59:08.479203.479203 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.479040.479040 lmp.py:423] 
DEBUG 01-05 09:59:08.479040.479040 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.479506.479506 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-05 09:59:08.479924.479924 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.490354.490354 mlpmodule.py:704] group tensors cost 0.010056257247924805 s
DEBUG 01-05 09:59:08.492222.492222 mlpmodule.py:742] pad cost 0.0016088485717773438 s
DEBUG 01-05 09:59:08.492748.492748 mlpmodule.py:748] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-05 09:59:08.492082.492082 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-05 09:59:08.502353.502353 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.502690.502690 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.502620.502620 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 09:59:08.502167.502167 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.520714.520714 mlpmodule.py:793] group einsum cost 0.027691364288330078 s
DEBUG 01-05 09:59:08.520735.520735 mlpmodule.py:801] cpy2cputensor cost 0.0006222724914550781 s
DEBUG 01-05 09:59:08.525104.525104 cuda_h.py:19] end wait_cetm_experts cost 0.04563093185424805 seconds
DEBUG 01-05 09:59:08.525566.525566 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.526693.526693 cuda_h.py:19] end gpu_sexperts cost 0.0005762577056884766 seconds
DEBUG 01-05 09:59:08.526351.526351 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.526684.526684 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:08.526533.526533 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.526911.526911 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d17ba49-cf42-42e5-ad43-a8855a560a7a
INFO 01-05 09:59:08.531952.531952 client.py:127] Model loaded
DEBUG 01-05 09:59:08.531518.531518 cuda_h.py:19] end wait_experts cost 0.005048036575317383 seconds
DEBUG 01-05 09:59:08.531843.531843 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.531837.531837 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.532735.532735 mlpmodule.py:531] gpu group tensors cost 0.0006120204925537109 s
DEBUG 01-05 09:59:08.534903.534903 mlpmodule.py:564] gpu pad cost 0.001787424087524414 s
DEBUG 01-05 09:59:08.534280.534280 mlpmodule.py:582] gpu group einsum cost 0.0005161762237548828 s
DEBUG 01-05 09:59:08.537450.537450 mlpmodule.py:662]  experts func einsum cost 0.057276248931884766 s
DEBUG 01-05 09:59:08.538581.538581 mlpmodule.py:611] gpu experts func einsum cost 0.006493568420410156 s
DEBUG 01-05 09:59:08.538480.538480 cuda_h.py:19] end gpu_experts cost 0.006724357604980469 seconds
DEBUG 01-05 09:59:08.538973.538973 cuda_h.py:19] end layer_moe_generate_17 cost 0.06696867942810059 seconds
DEBUG 01-05 09:59:08.538912.538912 lmp.py:217] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 09:59:08.538105.538105 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 09:59:08.538563.538563 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:59:08.538080.538080 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:59:08.538255.538255 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:08.538481.538481 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.0558319091796875e-05 seconds
DEBUG 01-05 09:59:08.538269.538269 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.538167.538167 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.538289.538289 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.538364.538364 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.539508.539508 cuda_h.py:19] end allocate_cuda_memory cost 0.00031638145446777344 seconds
DEBUG 01-05 09:59:08.539862.539862 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.539532.539532 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.539924.539924 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.539627.539627 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1aa565b3-261c-4738-abb7-853f2190e6ec
DEBUG 01-05 09:59:08.539073.539073 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.539718.539718 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.540420.540420 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1aa565b3-261c-4738-abb7-853f2190e6ec
DEBUG 01-05 09:59:08.540310.540310 cuda_h.py:19] end load_into_gpu_async cost 0.0012750625610351562 seconds
DEBUG 01-05 09:59:08.540297.540297 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.540757.540757 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-05 09:59:08.540321.540321 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019202232360839844 seconds
INFO 01-05 09:59:08.541192.541192 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1aa565b3-261c-4738-abb7-853f2190e6ec
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.543515.543515 cuda_h.py:19] end self_attn cost 0.0037567615509033203 seconds
DEBUG 01-05 09:59:08.543564.543564 cuda_h.py:19] end iln_self_attn_paln cost 0.005209684371948242 seconds
DEBUG 01-05 09:59:08.544831.544831 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 09:59:08.544117.544117 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.544101.544101 cuda_h.py:19] end gate cost 0.0006918907165527344 seconds
DEBUG 01-05 09:59:08.544593.544593 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.545285.545285 lmp.py:365] 
DEBUG 01-05 09:59:08.545285.545285 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.545849.545849 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.545976.545976 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.545526.545526 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.545215.545215 lmp.py:369] 
DEBUG 01-05 09:59:08.545215.545215 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.545381.545381 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.545746.545746 lmp.py:376]   Expert 54 |     22 | CPU
DEBUG 01-05 09:59:08.545913.545913 lmp.py:376]   Expert 35 |     28 | CPU
DEBUG 01-05 09:59:08.545840.545840 lmp.py:376]   Expert 40 |     31 | CPU
DEBUG 01-05 09:59:08.545530.545530 lmp.py:376]   Expert 19 |     32 | CPU
DEBUG 01-05 09:59:08.545980.545980 lmp.py:376]   Expert  0 |     34 | CPU
DEBUG 01-05 09:59:08.545670.545670 lmp.py:376]   Expert 12 |     44 | CPU
DEBUG 01-05 09:59:08.545121.545121 lmp.py:376]   Expert 53 |     50 | CPU
DEBUG 01-05 09:59:08.545571.545571 lmp.py:376]   Expert  3 |     54 | CPU
DEBUG 01-05 09:59:08.545546.545546 lmp.py:376]   Expert 34 |     55 | CPU
DEBUG 01-05 09:59:08.545996.545996 lmp.py:376]   Expert 20 |     56 | CPU
DEBUG 01-05 09:59:08.545209.545209 lmp.py:376]   Expert 32 |     56 | CPU
DEBUG 01-05 09:59:08.545421.545421 lmp.py:376]   Expert  6 |     59 | CPU
DEBUG 01-05 09:59:08.545395.545395 lmp.py:376]   Expert 58 |     59 | CPU
DEBUG 01-05 09:59:08.545608.545608 lmp.py:376]   Expert 60 |     60 | CPU
DEBUG 01-05 09:59:08.545343.545343 lmp.py:376]   Expert 41 |     61 | CPU
DEBUG 01-05 09:59:08.545556.545556 lmp.py:376]   Expert  8 |     66 | CPU
DEBUG 01-05 09:59:08.545484.545484 lmp.py:376]   Expert 33 |     68 | CPU
DEBUG 01-05 09:59:08.545696.545696 lmp.py:376]   Expert 37 |     72 | CPU
DEBUG 01-05 09:59:08.545432.545432 lmp.py:376]   Expert 63 |     77 | CPU
DEBUG 01-05 09:59:08.545644.545644 lmp.py:376]   Expert 48 |     78 | CPU
DEBUG 01-05 09:59:08.545870.545870 lmp.py:376]   Expert 13 |     80 | CPU
DEBUG 01-05 09:59:08.545606.545606 lmp.py:376]   Expert 25 |     80 | CPU
DEBUG 01-05 09:59:08.545865.545865 lmp.py:376]   Expert 30 |     91 | CPU
DEBUG 01-05 09:59:08.545362.545362 lmp.py:376]   Expert 27 |     92 | CPU
DEBUG 01-05 09:59:08.545097.545097 lmp.py:376]   Expert 24 |     96 | CPU
DEBUG 01-05 09:59:08.545025.545025 lmp.py:376]   Expert 46 |     97 | CPU
DEBUG 01-05 09:59:08.545999.545999 lmp.py:376]   Expert 45 |    108 | CPU
DEBUG 01-05 09:59:08.545258.545258 lmp.py:376]   Expert  5 |    115 | CPU
DEBUG 01-05 09:59:08.545517.545517 lmp.py:376]   Expert 11 |    117 | CPU
DEBUG 01-05 09:59:08.545014.545014 lmp.py:376]   Expert 29 |    121 | CPU
DEBUG 01-05 09:59:08.545034.545034 lmp.py:376]   Expert 43 |    126 | CPU
DEBUG 01-05 09:59:08.545532.545532 lmp.py:376]   Expert 44 |    133 | CPU
DEBUG 01-05 09:59:08.545790.545790 lmp.py:376]   Expert 22 |    139 | GPU
DEBUG 01-05 09:59:08.545672.545672 lmp.py:376]   Expert 55 |    141 | GPU
DEBUG 01-05 09:59:08.545361.545361 lmp.py:376]   Expert 56 |    144 | GPU
DEBUG 01-05 09:59:08.545858.545858 lmp.py:376]   Expert 16 |    151 | GPU
DEBUG 01-05 09:59:08.545356.545356 lmp.py:376]   Expert 21 |    158 | GPU
DEBUG 01-05 09:59:08.545614.545614 lmp.py:376]   Expert 42 |    161 | GPU
DEBUG 01-05 09:59:08.545112.545112 lmp.py:376]   Expert  4 |    165 | GPU
DEBUG 01-05 09:59:08.545370.545370 lmp.py:376]   Expert  9 |    167 | GPU
DEBUG 01-05 09:59:08.545868.545868 lmp.py:376]   Expert 18 |    195 | GPU
DEBUG 01-05 09:59:08.545126.545126 lmp.py:376]   Expert 51 |    209 | GPU
DEBUG 01-05 09:59:08.545100.545100 lmp.py:376]   Expert 59 |    209 | GPU
DEBUG 01-05 09:59:08.545074.545074 lmp.py:376]   Expert 39 |    213 | GPU
DEBUG 01-05 09:59:08.545810.545810 lmp.py:376]   Expert 52 |    215 | GPU
DEBUG 01-05 09:59:08.545069.545069 lmp.py:376]   Expert 31 |    237 | GPU
DEBUG 01-05 09:59:08.545804.545804 lmp.py:376]   Expert 28 |    253 | GPU
DEBUG 01-05 09:59:08.546302.546302 lmp.py:376]   Expert 38 |    254 | GPU
DEBUG 01-05 09:59:08.546560.546560 lmp.py:376]   Expert 10 |    255 | GPU
DEBUG 01-05 09:59:08.546819.546819 lmp.py:376]   Expert  1 |    262 | GPU
DEBUG 01-05 09:59:08.546078.546078 lmp.py:376]   Expert 14 |    284 | GPU
DEBUG 01-05 09:59:08.546529.546529 lmp.py:376]   Expert 50 |    291 | GPU
DEBUG 01-05 09:59:08.546265.546265 lmp.py:376]   Expert  7 |    292 | GPU
DEBUG 01-05 09:59:08.546523.546523 lmp.py:376]   Expert 57 |    296 | GPU
DEBUG 01-05 09:59:08.546782.546782 lmp.py:376]   Expert 36 |    309 | GPU
DEBUG 01-05 09:59:08.546279.546279 lmp.py:376]   Expert 61 |    340 | GPU
DEBUG 01-05 09:59:08.546538.546538 lmp.py:376]   Expert 47 |    371 | GPU
DEBUG 01-05 09:59:08.546035.546035 lmp.py:376]   Expert 26 |    374 | GPU
DEBUG 01-05 09:59:08.546533.546533 lmp.py:376]   Expert 15 |    389 | GPU
DEBUG 01-05 09:59:08.546791.546791 lmp.py:376]   Expert 49 |    417 | GPU
DEBUG 01-05 09:59:08.546289.546289 lmp.py:376]   Expert 17 |    458 | GPU
DEBUG 01-05 09:59:08.546501.546501 lmp.py:376]   Expert  2 |    480 | GPU
DEBUG 01-05 09:59:08.546760.546760 lmp.py:376]   Expert 23 |    733 | GPU
DEBUG 01-05 09:59:08.546780.546780 lmp.py:376]   Expert 62 |   1408 | GPU
DEBUG 01-05 09:59:08.546754.546754 lmp.py:377] 
DEBUG 01-05 09:59:08.546754.546754 lmp.py:377]   CPU total tokens: 2318 (18.9%)
DEBUG 01-05 09:59:08.546967.546967 lmp.py:378]   GPU total tokens: 9970 (81.1%)
DEBUG 01-05 09:59:08.546232.546232 cuda_h.py:19] end experts_map_get cost 0.0014615058898925781 seconds
DEBUG 01-05 09:59:08.546160.546160 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.546221.546221 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.546398.546398 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.547273.547273 cuda_h.py:19] end allocate_cuda_memory cost 0.00099945068359375 seconds
DEBUG 01-05 09:59:08.547752.547752 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.547390.547390 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.547768.547768 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.547418.547418 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b788d71-6e76-415b-ae43-b020afb6334e
DEBUG 01-05 09:59:08.547610.547610 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.548542.548542 client.py:127] Model loaded
DEBUG 01-05 09:59:08.548100.548100 cuda_h.py:19] end sllm_worker_task cost 0.009205818176269531 seconds
INFO 01-05 09:59:08.548449.548449 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b788d71-6e76-415b-ae43-b020afb6334e
DEBUG 01-05 09:59:08.548577.548577 cuda_h.py:19] end load_into_gpu_async cost 0.0012235641479492188 seconds
DEBUG 01-05 09:59:08.548564.548564 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.549124.549124 cuda_h.py:19] end restore_tensors2 cost 0.0002830028533935547 seconds
DEBUG 01-05 09:59:08.549847.549847 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028619766235351562 seconds
DEBUG 01-05 09:59:08.551569.551569 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005472898483276367 seconds
DEBUG 01-05 09:59:08.551061.551061 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.551586.551586 lmp.py:423] 
DEBUG 01-05 09:59:08.551586.551586 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.552714.552714 cuda_h.py:19] end cpu_experts_submit cost 0.000102996826171875 seconds
DEBUG 01-05 09:59:08.552271.552271 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.557492.557492 mlpmodule.py:704] group tensors cost 0.0054171085357666016 s
DEBUG 01-05 09:59:08.560648.560648 mlpmodule.py:742] pad cost 0.0020368099212646484 s
DEBUG 01-05 09:59:08.560064.560064 mlpmodule.py:748] create cpu tensor cost 8.821487426757812e-05 s
DEBUG 01-05 09:59:08.560133.560133 mlpmodule.py:753] move to cpu cost 3.8623809814453125e-05 s
DEBUG 01-05 09:59:08.570028.570028 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.571511.571511 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.571124.571124 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 09:59:08.571433.571433 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.589680.589680 mlpmodule.py:793] group einsum cost 0.029102563858032227 s
DEBUG 01-05 09:59:08.590971.590971 mlpmodule.py:801] cpy2cputensor cost 0.0005700588226318359 s
DEBUG 01-05 09:59:08.595617.595617 cuda_h.py:19] end wait_cetm_experts cost 0.04308485984802246 seconds
DEBUG 01-05 09:59:08.595702.595702 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.595623.595623 cuda_h.py:19] end gpu_sexperts cost 0.0005664825439453125 seconds
DEBUG 01-05 09:59:08.596857.596857 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.596429.596429 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:08.596324.596324 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.596988.596988 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b788d71-6e76-415b-ae43-b020afb6334e
INFO 01-05 09:59:08.603036.603036 client.py:127] Model loaded
DEBUG 01-05 09:59:08.603793.603793 cuda_h.py:19] end wait_experts cost 0.00782918930053711 seconds
DEBUG 01-05 09:59:08.604833.604833 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.604927.604927 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.604190.604190 mlpmodule.py:531] gpu group tensors cost 0.0006356239318847656 s
DEBUG 01-05 09:59:08.606449.606449 mlpmodule.py:564] gpu pad cost 0.0015385150909423828 s
DEBUG 01-05 09:59:08.606191.606191 mlpmodule.py:662]  experts func einsum cost 0.054414987564086914 s
DEBUG 01-05 09:59:08.607497.607497 mlpmodule.py:582] gpu group einsum cost 0.0005710124969482422 s
DEBUG 01-05 09:59:08.609661.609661 mlpmodule.py:611] gpu experts func einsum cost 0.005788087844848633 s
DEBUG 01-05 09:59:08.610068.610068 cuda_h.py:19] end gpu_experts cost 0.005972623825073242 seconds
DEBUG 01-05 09:59:08.610938.610938 cuda_h.py:19] end layer_moe_generate_18 cost 0.06606030464172363 seconds
DEBUG 01-05 09:59:08.610447.610447 lmp.py:217] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 09:59:08.610686.610686 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 09:59:08.610475.610475 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:59:08.610131.610131 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:59:08.610782.610782 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.4332275390625e-05 seconds
DEBUG 01-05 09:59:08.610506.610506 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:59:08.610917.610917 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.610707.610707 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.610246.610246 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.610844.610844 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.610656.610656 cuda_h.py:19] end allocate_cuda_memory cost 0.0002834796905517578 seconds
DEBUG 01-05 09:59:08.611322.611322 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.611131.611131 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.611331.611331 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.611842.611842 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 18483a73-ee87-4662-9350-a1dd68695bbe
DEBUG 01-05 09:59:08.611666.611666 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.611298.611298 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.612610.612610 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 18483a73-ee87-4662-9350-a1dd68695bbe
DEBUG 01-05 09:59:08.612347.612347 cuda_h.py:19] end load_into_gpu_async cost 0.0011065006256103516 seconds
DEBUG 01-05 09:59:08.612427.612427 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.612179.612179 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-05 09:59:08.612266.612266 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001737356185913086 seconds
INFO 01-05 09:59:08.612358.612358 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 18483a73-ee87-4662-9350-a1dd68695bbe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.615078.615078 cuda_h.py:19] end self_attn cost 0.004056453704833984 seconds
DEBUG 01-05 09:59:08.615280.615280 cuda_h.py:19] end iln_self_attn_paln cost 0.005469083786010742 seconds
DEBUG 01-05 09:59:08.616262.616262 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 09:59:08.616786.616786 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.616743.616743 cuda_h.py:19] end gate cost 0.0006337165832519531 seconds
DEBUG 01-05 09:59:08.616665.616665 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.617118.617118 lmp.py:365] 
DEBUG 01-05 09:59:08.617118.617118 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.617113.617113 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.617240.617240 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.617790.617790 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.617671.617671 lmp.py:369] 
DEBUG 01-05 09:59:08.617671.617671 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.617222.617222 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.617825.617825 lmp.py:376]   Expert 48 |     29 | CPU
DEBUG 01-05 09:59:08.617660.617660 lmp.py:376]   Expert 55 |     37 | CPU
DEBUG 01-05 09:59:08.617303.617303 lmp.py:376]   Expert 52 |     40 | CPU
DEBUG 01-05 09:59:08.617708.617708 lmp.py:376]   Expert 56 |     44 | CPU
DEBUG 01-05 09:59:08.617112.617112 lmp.py:376]   Expert 44 |     48 | CPU
DEBUG 01-05 09:59:08.617278.617278 lmp.py:376]   Expert  5 |     59 | CPU
DEBUG 01-05 09:59:08.617444.617444 lmp.py:376]   Expert  6 |     59 | CPU
DEBUG 01-05 09:59:08.617611.617611 lmp.py:376]   Expert 23 |     67 | CPU
DEBUG 01-05 09:59:08.617492.617492 lmp.py:376]   Expert 27 |     67 | CPU
DEBUG 01-05 09:59:08.617135.617135 lmp.py:376]   Expert 59 |     68 | CPU
DEBUG 01-05 09:59:08.617493.617493 lmp.py:376]   Expert 57 |     75 | CPU
DEBUG 01-05 09:59:08.617659.617659 lmp.py:376]   Expert 40 |     79 | CPU
DEBUG 01-05 09:59:08.617349.617349 lmp.py:376]   Expert 30 |     80 | CPU
DEBUG 01-05 09:59:08.617276.617276 lmp.py:376]   Expert 18 |     93 | CPU
DEBUG 01-05 09:59:08.617204.617204 lmp.py:376]   Expert 34 |     95 | CPU
DEBUG 01-05 09:59:08.617132.617132 lmp.py:376]   Expert 12 |     98 | CPU
DEBUG 01-05 09:59:08.617821.617821 lmp.py:376]   Expert 16 |     98 | CPU
DEBUG 01-05 09:59:08.617749.617749 lmp.py:376]   Expert 33 |    101 | CPU
DEBUG 01-05 09:59:08.617438.617438 lmp.py:376]   Expert 42 |    110 | CPU
DEBUG 01-05 09:59:08.617843.617843 lmp.py:376]   Expert 26 |    115 | CPU
DEBUG 01-05 09:59:08.617247.617247 lmp.py:376]   Expert 46 |    118 | CPU
DEBUG 01-05 09:59:08.617175.617175 lmp.py:376]   Expert  0 |    122 | CPU
DEBUG 01-05 09:59:08.617056.617056 lmp.py:376]   Expert  8 |    123 | CPU
DEBUG 01-05 09:59:08.617222.617222 lmp.py:376]   Expert 54 |    127 | CPU
DEBUG 01-05 09:59:08.617673.617673 lmp.py:376]   Expert 62 |    130 | CPU
DEBUG 01-05 09:59:08.617363.617363 lmp.py:376]   Expert 60 |    132 | CPU
DEBUG 01-05 09:59:08.617052.617052 lmp.py:376]   Expert 63 |    132 | CPU
DEBUG 01-05 09:59:08.617741.617741 lmp.py:376]   Expert 15 |    134 | CPU
DEBUG 01-05 09:59:08.617192.617192 lmp.py:376]   Expert 37 |    140 | CPU
DEBUG 01-05 09:59:08.617643.617643 lmp.py:376]   Expert 53 |    146 | CPU
DEBUG 01-05 09:59:08.617332.617332 lmp.py:376]   Expert 14 |    147 | CPU
DEBUG 01-05 09:59:08.617498.617498 lmp.py:376]   Expert 24 |    150 | CPU
DEBUG 01-05 09:59:08.617141.617141 lmp.py:376]   Expert 39 |    150 | GPU
DEBUG 01-05 09:59:08.617784.617784 lmp.py:376]   Expert 32 |    151 | GPU
DEBUG 01-05 09:59:08.617712.617712 lmp.py:376]   Expert  4 |    158 | GPU
DEBUG 01-05 09:59:08.617163.617163 lmp.py:376]   Expert 13 |    158 | GPU
DEBUG 01-05 09:59:08.617614.617614 lmp.py:376]   Expert 58 |    160 | GPU
DEBUG 01-05 09:59:08.617065.617065 lmp.py:376]   Expert  1 |    166 | GPU
DEBUG 01-05 09:59:08.617754.617754 lmp.py:376]   Expert 50 |    168 | GPU
DEBUG 01-05 09:59:08.617205.617205 lmp.py:376]   Expert 43 |    172 | GPU
DEBUG 01-05 09:59:08.617133.617133 lmp.py:376]   Expert 61 |    176 | GPU
DEBUG 01-05 09:59:08.617584.617584 lmp.py:376]   Expert 47 |    181 | GPU
DEBUG 01-05 09:59:08.617273.617273 lmp.py:376]   Expert 28 |    213 | GPU
DEBUG 01-05 09:59:08.617439.617439 lmp.py:376]   Expert 20 |    222 | GPU
DEBUG 01-05 09:59:08.617605.617605 lmp.py:376]   Expert 49 |    223 | GPU
DEBUG 01-05 09:59:08.617771.617771 lmp.py:376]   Expert 17 |    239 | GPU
DEBUG 01-05 09:59:08.618699.618699 lmp.py:376]   Expert 41 |    239 | GPU
DEBUG 01-05 09:59:08.618150.618150 lmp.py:376]   Expert 22 |    246 | GPU
DEBUG 01-05 09:59:08.618601.618601 lmp.py:376]   Expert 25 |    261 | GPU
DEBUG 01-05 09:59:08.618052.618052 lmp.py:376]   Expert 21 |    264 | GPU
DEBUG 01-05 09:59:08.618741.618741 lmp.py:376]   Expert 35 |    266 | GPU
DEBUG 01-05 09:59:08.618430.618430 lmp.py:376]   Expert 51 |    272 | GPU
DEBUG 01-05 09:59:08.618881.618881 lmp.py:376]   Expert 38 |    285 | GPU
DEBUG 01-05 09:59:08.618809.618809 lmp.py:376]   Expert 11 |    294 | GPU
DEBUG 01-05 09:59:08.618498.618498 lmp.py:376]   Expert  2 |    324 | GPU
DEBUG 01-05 09:59:08.618426.618426 lmp.py:376]   Expert 31 |    328 | GPU
DEBUG 01-05 09:59:08.618069.618069 lmp.py:376]   Expert 36 |    341 | GPU
DEBUG 01-05 09:59:08.618712.618712 lmp.py:376]   Expert 29 |    381 | GPU
DEBUG 01-05 09:59:08.618116.618116 lmp.py:376]   Expert 10 |    406 | GPU
DEBUG 01-05 09:59:08.618998.618998 lmp.py:376]   Expert 45 |    412 | GPU
DEBUG 01-05 09:59:08.618164.618164 lmp.py:376]   Expert  3 |    440 | GPU
DEBUG 01-05 09:59:08.618092.618092 lmp.py:376]   Expert  9 |    590 | GPU
DEBUG 01-05 09:59:08.618019.618019 lmp.py:376]   Expert 19 |    664 | GPU
DEBUG 01-05 09:59:08.618947.618947 lmp.py:376]   Expert  7 |    675 | GPU
DEBUG 01-05 09:59:08.618352.618352 lmp.py:377] 
DEBUG 01-05 09:59:08.618352.618352 lmp.py:377]   CPU total tokens: 3063 (24.9%)
DEBUG 01-05 09:59:08.618233.618233 lmp.py:378]   GPU total tokens: 9225 (75.1%)
DEBUG 01-05 09:59:08.618167.618167 cuda_h.py:19] end experts_map_get cost 0.0015363693237304688 seconds
DEBUG 01-05 09:59:08.618526.618526 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.618733.618733 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.618485.618485 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.619011.619011 cuda_h.py:19] end allocate_cuda_memory cost 0.00042319297790527344 seconds
DEBUG 01-05 09:59:08.619444.619444 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.619345.619345 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.619300.619300 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.619712.619712 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 175db224-063b-44e3-bcc8-9c6257459145
DEBUG 01-05 09:59:08.619942.619942 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.619239.619239 client.py:127] Model loaded
DEBUG 01-05 09:59:08.619843.619843 cuda_h.py:19] end sllm_worker_task cost 0.008943557739257812 seconds
INFO 01-05 09:59:08.620630.620630 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 175db224-063b-44e3-bcc8-9c6257459145
DEBUG 01-05 09:59:08.620996.620996 cuda_h.py:19] end load_into_gpu_async cost 0.001039266586303711 seconds
DEBUG 01-05 09:59:08.620984.620984 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.620432.620432 cuda_h.py:19] end restore_tensors2 cost 0.00030541419982910156 seconds
DEBUG 01-05 09:59:08.620301.620301 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002115964889526367 seconds
DEBUG 01-05 09:59:08.623783.623783 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0046923160552978516 seconds
DEBUG 01-05 09:59:08.623275.623275 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.623589.623589 lmp.py:423] 
DEBUG 01-05 09:59:08.623589.623589 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.623393.623393 cuda_h.py:19] end cpu_experts_submit cost 0.00011277198791503906 seconds
DEBUG 01-05 09:59:08.623685.623685 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.633720.633720 mlpmodule.py:704] group tensors cost 0.010236024856567383 s
DEBUG 01-05 09:59:08.637540.637540 mlpmodule.py:742] pad cost 0.002710103988647461 s
DEBUG 01-05 09:59:08.637333.637333 mlpmodule.py:748] create cpu tensor cost 6.651878356933594e-05 s
DEBUG 01-05 09:59:08.637337.637337 mlpmodule.py:753] move to cpu cost 4.601478576660156e-05 s
DEBUG 01-05 09:59:08.647741.647741 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.648106.648106 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.648526.648526 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-05 09:59:08.648711.648711 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.665463.665463 mlpmodule.py:793] group einsum cost 0.027587175369262695 s
DEBUG 01-05 09:59:08.666847.666847 mlpmodule.py:801] cpy2cputensor cost 0.0006077289581298828 s
DEBUG 01-05 09:59:08.670530.670530 cuda_h.py:19] end wait_cetm_experts cost 0.04731249809265137 seconds
DEBUG 01-05 09:59:08.670231.670231 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.671404.671404 cuda_h.py:19] end gpu_sexperts cost 0.0005702972412109375 seconds
DEBUG 01-05 09:59:08.671671.671671 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.671720.671720 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 09:59:08.671330.671330 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.671801.671801 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 175db224-063b-44e3-bcc8-9c6257459145
INFO 01-05 09:59:08.674135.674135 client.py:127] Model loaded
DEBUG 01-05 09:59:08.674409.674409 cuda_h.py:19] end wait_experts cost 0.002906322479248047 seconds
DEBUG 01-05 09:59:08.674542.674542 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.674344.674344 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.675785.675785 mlpmodule.py:531] gpu group tensors cost 0.0006208419799804688 s
DEBUG 01-05 09:59:08.677178.677178 mlpmodule.py:564] gpu pad cost 0.0017817020416259766 s
DEBUG 01-05 09:59:08.677337.677337 mlpmodule.py:582] gpu group einsum cost 0.0005309581756591797 s
DEBUG 01-05 09:59:08.681608.681608 mlpmodule.py:611] gpu experts func einsum cost 0.00659942626953125 s
DEBUG 01-05 09:59:08.681783.681783 cuda_h.py:19] end gpu_experts cost 0.006785869598388672 seconds
DEBUG 01-05 09:59:08.681184.681184 cuda_h.py:19] end layer_moe_generate_19 cost 0.06546616554260254 seconds
DEBUG 01-05 09:59:08.681660.681660 lmp.py:217] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 09:59:08.681542.681542 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 09:59:08.681238.681238 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:59:08.681902.681902 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:59:08.681453.681453 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.8848648071289062e-05 seconds
DEBUG 01-05 09:59:08.681216.681216 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.532669067382812e-05 seconds
DEBUG 01-05 09:59:08.681118.681118 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.682293.682293 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.682825.682825 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.682509.682509 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.682142.682142 cuda_h.py:19] end allocate_cuda_memory cost 0.0006766319274902344 seconds
DEBUG 01-05 09:59:08.682616.682616 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.683856.683856 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.683009.683009 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.683520.683520 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 609bb66f-8d73-4db1-9ff8-91f77ec06164
DEBUG 01-05 09:59:08.683013.683013 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.683985.683985 mlpmodule.py:662]  experts func einsum cost 0.059743642807006836 s
DEBUG 01-05 09:59:08.683121.683121 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.684979.684979 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 609bb66f-8d73-4db1-9ff8-91f77ec06164
DEBUG 01-05 09:59:08.684690.684690 cuda_h.py:19] end load_into_gpu_async cost 0.0011744499206542969 seconds
DEBUG 01-05 09:59:08.684393.684393 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.684144.684144 cuda_h.py:19] end restore_tensors2 cost 7.224082946777344e-05 seconds
DEBUG 01-05 09:59:08.684947.684947 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002202272415161133 seconds
INFO 01-05 09:59:08.684203.684203 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 609bb66f-8d73-4db1-9ff8-91f77ec06164
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.687867.687867 cuda_h.py:19] end self_attn cost 0.003963470458984375 seconds
DEBUG 01-05 09:59:08.687300.687300 cuda_h.py:19] end iln_self_attn_paln cost 0.0060040950775146484 seconds
DEBUG 01-05 09:59:08.688567.688567 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 09:59:08.688614.688614 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.688378.688378 cuda_h.py:19] end gate cost 0.0006349086761474609 seconds
DEBUG 01-05 09:59:08.688824.688824 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.689085.689085 lmp.py:365] 
DEBUG 01-05 09:59:08.689085.689085 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.689080.689080 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.689445.689445 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.689472.689472 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.689400.689400 lmp.py:369] 
DEBUG 01-05 09:59:08.689400.689400 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.689327.689327 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.689500.689500 lmp.py:376]   Expert  8 |     19 | CPU
DEBUG 01-05 09:59:08.689666.689666 lmp.py:376]   Expert 13 |     34 | CPU
DEBUG 01-05 09:59:08.689356.689356 lmp.py:376]   Expert 54 |     37 | CPU
DEBUG 01-05 09:59:08.689568.689568 lmp.py:376]   Expert 28 |     52 | CPU
DEBUG 01-05 09:59:08.689257.689257 lmp.py:376]   Expert 11 |     66 | CPU
DEBUG 01-05 09:59:08.689662.689662 lmp.py:376]   Expert 36 |     66 | CPU
DEBUG 01-05 09:59:08.689590.689590 lmp.py:376]   Expert  1 |     67 | CPU
DEBUG 01-05 09:59:08.689279.689279 lmp.py:376]   Expert 33 |     68 | CPU
DEBUG 01-05 09:59:08.689776.689776 lmp.py:376]   Expert 43 |     71 | CPU
DEBUG 01-05 09:59:08.689750.689750 lmp.py:376]   Expert 14 |     73 | CPU
DEBUG 01-05 09:59:08.689247.689247 lmp.py:376]   Expert 12 |     75 | CPU
DEBUG 01-05 09:59:08.689890.689890 lmp.py:376]   Expert 42 |     81 | CPU
DEBUG 01-05 09:59:08.689580.689580 lmp.py:376]   Expert 51 |     86 | CPU
DEBUG 01-05 09:59:08.689269.689269 lmp.py:376]   Expert  6 |     88 | CPU
DEBUG 01-05 09:59:08.689150.689150 lmp.py:376]   Expert 10 |     89 | CPU
DEBUG 01-05 09:59:08.689555.689555 lmp.py:376]   Expert  3 |     92 | CPU
DEBUG 01-05 09:59:08.689244.689244 lmp.py:376]   Expert  9 |     92 | CPU
DEBUG 01-05 09:59:08.689934.689934 lmp.py:376]   Expert 19 |     93 | CPU
DEBUG 01-05 09:59:08.689623.689623 lmp.py:376]   Expert 29 |     97 | CPU
DEBUG 01-05 09:59:08.689835.689835 lmp.py:376]   Expert 46 |    105 | CPU
DEBUG 01-05 09:59:08.689763.689763 lmp.py:376]   Expert 38 |    106 | CPU
DEBUG 01-05 09:59:08.689691.689691 lmp.py:376]   Expert 20 |    121 | CPU
DEBUG 01-05 09:59:08.689142.689142 lmp.py:376]   Expert 61 |    128 | CPU
DEBUG 01-05 09:59:08.689560.689560 lmp.py:376]   Expert 17 |    131 | CPU
DEBUG 01-05 09:59:08.689772.689772 lmp.py:376]   Expert 18 |    136 | CPU
DEBUG 01-05 09:59:08.689985.689985 lmp.py:376]   Expert  0 |    138 | CPU
DEBUG 01-05 09:59:08.689959.689959 lmp.py:376]   Expert 63 |    145 | CPU
DEBUG 01-05 09:59:08.689933.689933 lmp.py:376]   Expert 44 |    147 | CPU
DEBUG 01-05 09:59:08.689907.689907 lmp.py:376]   Expert  5 |    148 | CPU
DEBUG 01-05 09:59:08.689643.689643 lmp.py:376]   Expert 49 |    148 | CPU
DEBUG 01-05 09:59:08.689617.689617 lmp.py:376]   Expert 57 |    149 | CPU
DEBUG 01-05 09:59:08.689829.689829 lmp.py:376]   Expert 62 |    156 | CPU
DEBUG 01-05 09:59:08.689803.689803 lmp.py:376]   Expert 21 |    158 | GPU
DEBUG 01-05 09:59:08.689969.689969 lmp.py:376]   Expert 26 |    158 | GPU
DEBUG 01-05 09:59:08.689659.689659 lmp.py:376]   Expert 39 |    160 | GPU
DEBUG 01-05 09:59:08.689109.689109 lmp.py:376]   Expert 52 |    171 | GPU
DEBUG 01-05 09:59:08.689845.689845 lmp.py:376]   Expert 55 |    174 | GPU
DEBUG 01-05 09:59:08.689819.689819 lmp.py:376]   Expert 50 |    183 | GPU
DEBUG 01-05 09:59:08.689555.689555 lmp.py:376]   Expert 23 |    207 | GPU
DEBUG 01-05 09:59:08.689529.689529 lmp.py:376]   Expert  7 |    211 | GPU
DEBUG 01-05 09:59:08.689264.689264 lmp.py:376]   Expert 47 |    214 | GPU
DEBUG 01-05 09:59:08.689477.689477 lmp.py:376]   Expert 30 |    220 | GPU
DEBUG 01-05 09:59:08.689928.689928 lmp.py:376]   Expert 37 |    223 | GPU
DEBUG 01-05 09:59:08.689094.689094 lmp.py:376]   Expert 27 |    243 | GPU
DEBUG 01-05 09:59:08.689829.689829 lmp.py:376]   Expert 16 |    245 | GPU
DEBUG 01-05 09:59:08.689042.689042 lmp.py:376]   Expert 22 |    247 | GPU
DEBUG 01-05 09:59:08.689254.689254 lmp.py:376]   Expert 32 |    247 | GPU
DEBUG 01-05 09:59:08.689990.689990 lmp.py:376]   Expert 53 |    249 | GPU
DEBUG 01-05 09:59:08.690964.690964 lmp.py:376]   Expert 58 |    251 | GPU
DEBUG 01-05 09:59:08.690700.690700 lmp.py:376]   Expert 45 |    253 | GPU
DEBUG 01-05 09:59:08.690674.690674 lmp.py:376]   Expert 60 |    260 | GPU
DEBUG 01-05 09:59:08.690648.690648 lmp.py:376]   Expert 24 |    262 | GPU
DEBUG 01-05 09:59:08.690860.690860 lmp.py:376]   Expert 41 |    275 | GPU
DEBUG 01-05 09:59:08.690073.690073 lmp.py:376]   Expert 56 |    282 | GPU
DEBUG 01-05 09:59:08.690808.690808 lmp.py:376]   Expert 48 |    283 | GPU
DEBUG 01-05 09:59:08.690021.690021 lmp.py:376]   Expert  4 |    299 | GPU
DEBUG 01-05 09:59:08.690233.690233 lmp.py:376]   Expert  2 |    314 | GPU
DEBUG 01-05 09:59:08.690207.690207 lmp.py:376]   Expert 34 |    314 | GPU
DEBUG 01-05 09:59:08.690420.690420 lmp.py:376]   Expert 15 |    319 | GPU
DEBUG 01-05 09:59:08.690632.690632 lmp.py:376]   Expert 40 |    330 | GPU
DEBUG 01-05 09:59:08.690606.690606 lmp.py:376]   Expert 59 |    362 | GPU
DEBUG 01-05 09:59:08.690580.690580 lmp.py:376]   Expert 31 |    388 | GPU
DEBUG 01-05 09:59:08.690031.690031 lmp.py:376]   Expert 25 |    818 | GPU
DEBUG 01-05 09:59:08.690721.690721 lmp.py:376]   Expert 35 |    864 | GPU
DEBUG 01-05 09:59:08.690648.690648 lmp.py:377] 
DEBUG 01-05 09:59:08.690648.690648 lmp.py:377]   CPU total tokens: 3104 (25.3%)
DEBUG 01-05 09:59:08.690576.690576 lmp.py:378]   GPU total tokens: 9184 (74.7%)
DEBUG 01-05 09:59:08.690557.690557 cuda_h.py:19] end experts_map_get cost 0.0014963150024414062 seconds
DEBUG 01-05 09:59:08.690961.690961 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.690645.690645 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.690292.690292 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.690002.690002 cuda_h.py:19] end allocate_cuda_memory cost 0.0004210472106933594 seconds
DEBUG 01-05 09:59:08.691548.691548 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.691258.691258 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.691875.691875 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.691525.691525 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d6144659-3a8f-4c85-8c15-e7e236bfb43a
DEBUG 01-05 09:59:08.691524.691524 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.691416.691416 client.py:127] Model loaded
DEBUG 01-05 09:59:08.691689.691689 cuda_h.py:19] end sllm_worker_task cost 0.009385347366333008 seconds
INFO 01-05 09:59:08.692038.692038 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d6144659-3a8f-4c85-8c15-e7e236bfb43a
DEBUG 01-05 09:59:08.692735.692735 cuda_h.py:19] end load_into_gpu_async cost 0.0017883777618408203 seconds
DEBUG 01-05 09:59:08.692199.692199 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.693780.693780 cuda_h.py:19] end restore_tensors2 cost 0.0002980232238769531 seconds
DEBUG 01-05 09:59:08.693549.693549 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028564929962158203 seconds
DEBUG 01-05 09:59:08.695837.695837 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005360126495361328 seconds
DEBUG 01-05 09:59:08.695137.695137 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.695875.695875 lmp.py:423] 
DEBUG 01-05 09:59:08.695875.695875 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.695294.695294 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-05 09:59:08.695897.695897 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.705215.705215 mlpmodule.py:704] group tensors cost 0.009523630142211914 s
DEBUG 01-05 09:59:08.707724.707724 mlpmodule.py:742] pad cost 0.0013804435729980469 s
DEBUG 01-05 09:59:08.707177.707177 mlpmodule.py:748] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-05 09:59:08.707259.707259 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-05 09:59:08.717531.717531 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.717431.717431 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.717036.717036 mlpmodule.py:773] group_w3 first element: -0.046630859375
WARNING 01-05 09:59:08.717776.717776 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.736898.736898 mlpmodule.py:793] group einsum cost 0.028699398040771484 s
DEBUG 01-05 09:59:08.737368.737368 mlpmodule.py:801] cpy2cputensor cost 0.0006008148193359375 s
DEBUG 01-05 09:59:08.742202.742202 cuda_h.py:19] end wait_cetm_experts cost 0.04603862762451172 seconds
DEBUG 01-05 09:59:08.742635.742635 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.742062.742062 cuda_h.py:19] end gpu_sexperts cost 0.0004496574401855469 seconds
DEBUG 01-05 09:59:08.742660.742660 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.742417.742417 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7894973754882812e-05 seconds
DEBUG 01-05 09:59:08.742266.742266 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.742498.742498 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d6144659-3a8f-4c85-8c15-e7e236bfb43a
INFO 01-05 09:59:08.747189.747189 client.py:127] Model loaded
DEBUG 01-05 09:59:08.747655.747655 cuda_h.py:19] end wait_experts cost 0.00468134880065918 seconds
DEBUG 01-05 09:59:08.747742.747742 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.747498.747498 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.748799.748799 mlpmodule.py:531] gpu group tensors cost 0.0006029605865478516 s
DEBUG 01-05 09:59:08.749110.749110 mlpmodule.py:564] gpu pad cost 0.0017218589782714844 s
DEBUG 01-05 09:59:08.750685.750685 mlpmodule.py:582] gpu group einsum cost 0.0004901885986328125 s
DEBUG 01-05 09:59:08.753196.753196 mlpmodule.py:611] gpu experts func einsum cost 0.006125926971435547 s
DEBUG 01-05 09:59:08.753776.753776 cuda_h.py:19] end gpu_experts cost 0.006316184997558594 seconds
DEBUG 01-05 09:59:08.753838.753838 cuda_h.py:19] end layer_moe_generate_20 cost 0.06582927703857422 seconds
DEBUG 01-05 09:59:08.754585.754585 lmp.py:217] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 09:59:08.754302.754302 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 09:59:08.754044.754044 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:59:08.754562.754562 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:59:08.754160.754160 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.6941299438476562e-05 seconds
DEBUG 01-05 09:59:08.754147.754147 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 5.91278076171875e-05 seconds
DEBUG 01-05 09:59:08.754221.754221 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.754873.754873 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.754770.754770 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.754621.754621 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.759282.759282 cuda_h.py:19] end allocate_cuda_memory cost 0.0052220821380615234 seconds
DEBUG 01-05 09:59:08.759982.759982 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.759937.759937 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.760283.760283 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.760509.760509 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36b65793-ecdb-4d2a-b37e-cd5d0bcfc556
DEBUG 01-05 09:59:08.760624.760624 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.760603.760603 mlpmodule.py:662]  experts func einsum cost 0.06424880027770996 s
DEBUG 01-05 09:59:08.760313.760313 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.761598.761598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36b65793-ecdb-4d2a-b37e-cd5d0bcfc556
DEBUG 01-05 09:59:08.761819.761819 cuda_h.py:19] end load_into_gpu_async cost 0.0014224052429199219 seconds
DEBUG 01-05 09:59:08.761853.761853 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.761598.761598 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-05 09:59:08.761162.761162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007062435150146484 seconds
INFO 01-05 09:59:08.762516.762516 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36b65793-ecdb-4d2a-b37e-cd5d0bcfc556
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.763071.763071 cuda_h.py:19] end self_attn cost 0.003193378448486328 seconds
DEBUG 01-05 09:59:08.764134.764134 cuda_h.py:19] end iln_self_attn_paln cost 0.009842872619628906 seconds
DEBUG 01-05 09:59:08.764355.764355 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 09:59:08.764071.764071 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.768919.768919 cuda_h.py:19] end gate cost 0.004291534423828125 seconds
DEBUG 01-05 09:59:08.768928.768928 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.769272.769272 lmp.py:365] 
DEBUG 01-05 09:59:08.769272.769272 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.769035.769035 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.769830.769830 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.769096.769096 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.769977.769977 lmp.py:369] 
DEBUG 01-05 09:59:08.769977.769977 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.769620.769620 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.769939.769939 lmp.py:376]   Expert 44 |     19 | CPU
DEBUG 01-05 09:59:08.769059.769059 lmp.py:376]   Expert 56 |     30 | CPU
DEBUG 01-05 09:59:08.769225.769225 lmp.py:376]   Expert  9 |     36 | CPU
DEBUG 01-05 09:59:08.769153.769153 lmp.py:376]   Expert 26 |     45 | CPU
DEBUG 01-05 09:59:08.769319.769319 lmp.py:376]   Expert 60 |     50 | CPU
DEBUG 01-05 09:59:08.769247.769247 lmp.py:376]   Expert  1 |     57 | CPU
DEBUG 01-05 09:59:08.769936.769936 lmp.py:376]   Expert 35 |     62 | CPU
DEBUG 01-05 09:59:08.769625.769625 lmp.py:376]   Expert  6 |     64 | CPU
DEBUG 01-05 09:59:08.769076.769076 lmp.py:376]   Expert 32 |     67 | CPU
DEBUG 01-05 09:59:08.769527.769527 lmp.py:376]   Expert 53 |     70 | CPU
DEBUG 01-05 09:59:08.769216.769216 lmp.py:376]   Expert 19 |     71 | CPU
DEBUG 01-05 09:59:08.769906.769906 lmp.py:376]   Expert 57 |     75 | CPU
DEBUG 01-05 09:59:08.769595.769595 lmp.py:376]   Expert 49 |     79 | CPU
DEBUG 01-05 09:59:08.769238.769238 lmp.py:376]   Expert  8 |     80 | CPU
DEBUG 01-05 09:59:08.769927.769927 lmp.py:376]   Expert 15 |     86 | CPU
DEBUG 01-05 09:59:08.769616.769616 lmp.py:376]   Expert 23 |     87 | CPU
DEBUG 01-05 09:59:08.769067.769067 lmp.py:376]   Expert 51 |     88 | CPU
DEBUG 01-05 09:59:08.769757.769757 lmp.py:376]   Expert 12 |     92 | CPU
DEBUG 01-05 09:59:08.769446.769446 lmp.py:376]   Expert 20 |     92 | CPU
DEBUG 01-05 09:59:08.769897.769897 lmp.py:376]   Expert 52 |     92 | CPU
DEBUG 01-05 09:59:08.769348.769348 lmp.py:376]   Expert  3 |     93 | CPU
DEBUG 01-05 09:59:08.769037.769037 lmp.py:376]   Expert 33 |    101 | CPU
DEBUG 01-05 09:59:08.769726.769726 lmp.py:376]   Expert 28 |    102 | CPU
DEBUG 01-05 09:59:08.769654.769654 lmp.py:376]   Expert 25 |    103 | CPU
DEBUG 01-05 09:59:08.769582.769582 lmp.py:376]   Expert 41 |    103 | CPU
DEBUG 01-05 09:59:08.769271.769271 lmp.py:376]   Expert 40 |    105 | CPU
DEBUG 01-05 09:59:08.769960.769960 lmp.py:376]   Expert 11 |    117 | CPU
DEBUG 01-05 09:59:08.769173.769173 lmp.py:376]   Expert 24 |    118 | CPU
DEBUG 01-05 09:59:08.769862.769862 lmp.py:376]   Expert 13 |    119 | CPU
DEBUG 01-05 09:59:08.769075.769075 lmp.py:376]   Expert 54 |    123 | CPU
DEBUG 01-05 09:59:08.769764.769764 lmp.py:376]   Expert 14 |    124 | CPU
DEBUG 01-05 09:59:08.769215.769215 lmp.py:376]   Expert 48 |    128 | CPU
DEBUG 01-05 09:59:08.769904.769904 lmp.py:376]   Expert 39 |    131 | GPU
DEBUG 01-05 09:59:08.769832.769832 lmp.py:376]   Expert 59 |    138 | GPU
DEBUG 01-05 09:59:08.769760.769760 lmp.py:376]   Expert  7 |    150 | GPU
DEBUG 01-05 09:59:08.769210.769210 lmp.py:376]   Expert 58 |    151 | GPU
DEBUG 01-05 09:59:08.769661.769661 lmp.py:376]   Expert 10 |    167 | GPU
DEBUG 01-05 09:59:08.769635.769635 lmp.py:376]   Expert 34 |    168 | GPU
DEBUG 01-05 09:59:08.769086.769086 lmp.py:376]   Expert 18 |    171 | GPU
DEBUG 01-05 09:59:08.769537.769537 lmp.py:376]   Expert 63 |    186 | GPU
DEBUG 01-05 09:59:08.769988.769988 lmp.py:376]   Expert 47 |    210 | GPU
DEBUG 01-05 09:59:08.769962.769962 lmp.py:376]   Expert 38 |    214 | GPU
DEBUG 01-05 09:59:08.769651.769651 lmp.py:376]   Expert  2 |    217 | GPU
DEBUG 01-05 09:59:08.769579.769579 lmp.py:376]   Expert 43 |    226 | GPU
DEBUG 01-05 09:59:08.769745.769745 lmp.py:376]   Expert 21 |    231 | GPU
DEBUG 01-05 09:59:08.769434.769434 lmp.py:376]   Expert  5 |    239 | GPU
DEBUG 01-05 09:59:08.769409.769409 lmp.py:376]   Expert 22 |    253 | GPU
DEBUG 01-05 09:59:08.769859.769859 lmp.py:376]   Expert 55 |    257 | GPU
DEBUG 01-05 09:59:08.769310.769310 lmp.py:376]   Expert 61 |    257 | GPU
DEBUG 01-05 09:59:08.769523.769523 lmp.py:376]   Expert 46 |    274 | GPU
DEBUG 01-05 09:59:08.769974.769974 lmp.py:376]   Expert  4 |    296 | GPU
DEBUG 01-05 09:59:08.770186.770186 lmp.py:376]   Expert 27 |    298 | GPU
DEBUG 01-05 09:59:08.770829.770829 lmp.py:376]   Expert 62 |    299 | GPU
DEBUG 01-05 09:59:08.770757.770757 lmp.py:376]   Expert  0 |    314 | GPU
DEBUG 01-05 09:59:08.770161.770161 lmp.py:376]   Expert 29 |    325 | GPU
DEBUG 01-05 09:59:08.770851.770851 lmp.py:376]   Expert 31 |    330 | GPU
DEBUG 01-05 09:59:08.770825.770825 lmp.py:376]   Expert 17 |    339 | GPU
DEBUG 01-05 09:59:08.770037.770037 lmp.py:376]   Expert 16 |    376 | GPU
DEBUG 01-05 09:59:08.770488.770488 lmp.py:376]   Expert 45 |    390 | GPU
DEBUG 01-05 09:59:08.770462.770462 lmp.py:376]   Expert 50 |    393 | GPU
DEBUG 01-05 09:59:08.770675.770675 lmp.py:376]   Expert 36 |    441 | GPU
DEBUG 01-05 09:59:08.770649.770649 lmp.py:376]   Expert 37 |    610 | GPU
DEBUG 01-05 09:59:08.770099.770099 lmp.py:376]   Expert 30 |    711 | GPU
DEBUG 01-05 09:59:08.770027.770027 lmp.py:376]   Expert 42 |    848 | GPU
DEBUG 01-05 09:59:08.770670.770670 lmp.py:377] 
DEBUG 01-05 09:59:08.770670.770670 lmp.py:377]   CPU total tokens: 2678 (21.8%)
DEBUG 01-05 09:59:08.770313.770313 lmp.py:378]   GPU total tokens: 9610 (78.2%)
DEBUG 01-05 09:59:08.770486.770486 cuda_h.py:19] end experts_map_get cost 0.001611471176147461 seconds
DEBUG 01-05 09:59:08.770129.770129 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.770866.770866 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.770176.770176 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.770308.770308 cuda_h.py:19] end allocate_cuda_memory cost 0.00034356117248535156 seconds
DEBUG 01-05 09:59:08.770396.770396 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.770582.770582 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.771590.771590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.771909.771909 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b55ca764-1dea-4e18-9bf5-0ee403aef099
DEBUG 01-05 09:59:08.771320.771320 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.771945.771945 client.py:127] Model loaded
DEBUG 01-05 09:59:08.771783.771783 cuda_h.py:19] end sllm_worker_task cost 0.01717996597290039 seconds
INFO 01-05 09:59:08.772044.772044 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b55ca764-1dea-4e18-9bf5-0ee403aef099
DEBUG 01-05 09:59:08.772033.772033 cuda_h.py:19] end load_into_gpu_async cost 0.001383066177368164 seconds
DEBUG 01-05 09:59:08.772696.772696 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.772264.772264 cuda_h.py:19] end restore_tensors2 cost 0.00032210350036621094 seconds
DEBUG 01-05 09:59:08.772133.772133 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002421855926513672 seconds
DEBUG 01-05 09:59:08.775230.775230 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005170345306396484 seconds
DEBUG 01-05 09:59:08.775298.775298 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.775950.775950 lmp.py:423] 
DEBUG 01-05 09:59:08.775950.775950 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.775774.775774 cuda_h.py:19] end cpu_experts_submit cost 0.00014519691467285156 seconds
DEBUG 01-05 09:59:08.775570.775570 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.788400.788400 mlpmodule.py:704] group tensors cost 0.011903524398803711 s
DEBUG 01-05 09:59:08.790949.790949 mlpmodule.py:742] pad cost 0.00185394287109375 s
DEBUG 01-05 09:59:08.790325.790325 mlpmodule.py:748] create cpu tensor cost 7.104873657226562e-05 s
DEBUG 01-05 09:59:08.790613.790613 mlpmodule.py:753] move to cpu cost 6.699562072753906e-05 s
DEBUG 01-05 09:59:08.801258.801258 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.801174.801174 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.802304.802304 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 09:59:08.802205.802205 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.821363.821363 mlpmodule.py:793] group einsum cost 0.030234575271606445 s
DEBUG 01-05 09:59:08.822106.822106 mlpmodule.py:801] cpy2cputensor cost 0.0005905628204345703 s
DEBUG 01-05 09:59:08.827149.827149 cuda_h.py:19] end wait_cetm_experts cost 0.051435232162475586 seconds
DEBUG 01-05 09:59:08.827526.827526 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.828609.828609 cuda_h.py:19] end gpu_sexperts cost 0.0006504058837890625 seconds
DEBUG 01-05 09:59:08.828644.828644 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.828699.828699 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.62396240234375e-05 seconds
DEBUG 01-05 09:59:08.828786.828786 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.828926.828926 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b55ca764-1dea-4e18-9bf5-0ee403aef099
INFO 01-05 09:59:08.829615.829615 client.py:127] Model loaded
DEBUG 01-05 09:59:08.829121.829121 cuda_h.py:19] end wait_experts cost 0.0012657642364501953 seconds
DEBUG 01-05 09:59:08.829169.829169 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.829455.829455 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.830913.830913 mlpmodule.py:531] gpu group tensors cost 0.000736236572265625 s
DEBUG 01-05 09:59:08.832378.832378 mlpmodule.py:564] gpu pad cost 0.002347707748413086 s
DEBUG 01-05 09:59:08.833900.833900 mlpmodule.py:582] gpu group einsum cost 0.0006818771362304688 s
DEBUG 01-05 09:59:08.838138.838138 mlpmodule.py:611] gpu experts func einsum cost 0.008450746536254883 s
DEBUG 01-05 09:59:08.838480.838480 cuda_h.py:19] end gpu_experts cost 0.008658647537231445 seconds
DEBUG 01-05 09:59:08.838768.838768 cuda_h.py:19] end layer_moe_generate_21 cost 0.0742185115814209 seconds
DEBUG 01-05 09:59:08.838225.838225 lmp.py:217] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 09:59:08.838272.838272 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 09:59:08.838730.838730 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:59:08.838678.838678 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:59:08.838283.838283 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.218650817871094e-05 seconds
DEBUG 01-05 09:59:08.838913.838913 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:59:08.838616.838616 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.838837.838837 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.838362.838362 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.839252.839252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.840751.840751 cuda_h.py:19] end allocate_cuda_memory cost 0.0014181137084960938 seconds
DEBUG 01-05 09:59:08.840561.840561 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.840463.840463 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.840809.840809 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.840465.840465 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 06761ca3-dd7c-4f51-bb77-8a08c73851bf
DEBUG 01-05 09:59:08.840402.840402 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.841558.841558 mlpmodule.py:662]  experts func einsum cost 0.06490349769592285 s
DEBUG 01-05 09:59:08.841494.841494 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.842729.842729 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 06761ca3-dd7c-4f51-bb77-8a08c73851bf
DEBUG 01-05 09:59:08.842003.842003 cuda_h.py:19] end load_into_gpu_async cost 0.0014829635620117188 seconds
DEBUG 01-05 09:59:08.842752.842752 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.842550.842550 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-05 09:59:08.842160.842160 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032243728637695312 seconds
INFO 01-05 09:59:08.842333.842333 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 06761ca3-dd7c-4f51-bb77-8a08c73851bf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.846891.846891 cuda_h.py:19] end self_attn cost 0.004598140716552734 seconds
DEBUG 01-05 09:59:08.846287.846287 cuda_h.py:19] end iln_self_attn_paln cost 0.007726907730102539 seconds
DEBUG 01-05 09:59:08.846653.846653 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 09:59:08.846231.846231 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.847230.847230 cuda_h.py:19] end gate cost 0.0007350444793701172 seconds
DEBUG 01-05 09:59:08.847728.847728 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.847585.847585 lmp.py:365] 
DEBUG 01-05 09:59:08.847585.847585 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.848625.848625 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.848467.848467 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.848971.848971 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.848614.848614 lmp.py:369] 
DEBUG 01-05 09:59:08.848614.848614 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.848496.848496 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.848384.848384 lmp.py:376]   Expert 15 |     35 | CPU
DEBUG 01-05 09:59:08.848742.848742 lmp.py:376]   Expert 32 |     48 | CPU
DEBUG 01-05 09:59:08.848147.848147 lmp.py:376]   Expert  6 |     52 | CPU
DEBUG 01-05 09:59:08.848790.848790 lmp.py:376]   Expert 45 |     55 | CPU
DEBUG 01-05 09:59:08.848956.848956 lmp.py:376]   Expert 49 |     55 | CPU
DEBUG 01-05 09:59:08.848599.848599 lmp.py:376]   Expert 22 |     59 | CPU
DEBUG 01-05 09:59:08.848526.848526 lmp.py:376]   Expert 54 |     62 | CPU
DEBUG 01-05 09:59:08.848454.848454 lmp.py:376]   Expert 46 |     63 | CPU
DEBUG 01-05 09:59:08.848143.848143 lmp.py:376]   Expert 52 |     63 | CPU
DEBUG 01-05 09:59:08.848071.848071 lmp.py:376]   Expert 42 |     64 | CPU
DEBUG 01-05 09:59:08.848237.848237 lmp.py:376]   Expert 37 |     65 | CPU
DEBUG 01-05 09:59:08.848165.848165 lmp.py:376]   Expert 44 |     66 | CPU
DEBUG 01-05 09:59:08.848093.848093 lmp.py:376]   Expert 60 |     72 | CPU
DEBUG 01-05 09:59:08.848020.848020 lmp.py:376]   Expert 12 |     73 | CPU
DEBUG 01-05 09:59:08.848710.848710 lmp.py:376]   Expert 24 |     76 | CPU
DEBUG 01-05 09:59:08.848022.848022 lmp.py:376]   Expert 48 |     76 | CPU
DEBUG 01-05 09:59:08.848579.848579 lmp.py:376]   Expert 11 |     77 | CPU
DEBUG 01-05 09:59:08.848175.848175 lmp.py:376]   Expert 30 |     80 | CPU
DEBUG 01-05 09:59:08.848342.848342 lmp.py:376]   Expert 61 |     82 | CPU
DEBUG 01-05 09:59:08.848197.848197 lmp.py:376]   Expert 41 |     89 | CPU
DEBUG 01-05 09:59:08.848317.848317 lmp.py:376]   Expert 47 |     93 | CPU
DEBUG 01-05 09:59:08.848244.848244 lmp.py:376]   Expert 63 |     93 | CPU
DEBUG 01-05 09:59:08.848795.848795 lmp.py:376]   Expert  7 |     94 | CPU
DEBUG 01-05 09:59:08.848153.848153 lmp.py:376]   Expert 13 |    105 | CPU
DEBUG 01-05 09:59:08.848511.848511 lmp.py:376]   Expert  0 |    106 | CPU
DEBUG 01-05 09:59:08.848108.848108 lmp.py:376]   Expert 57 |    107 | CPU
DEBUG 01-05 09:59:08.848228.848228 lmp.py:376]   Expert 58 |    110 | CPU
DEBUG 01-05 09:59:08.848824.848824 lmp.py:376]   Expert  3 |    119 | CPU
DEBUG 01-05 09:59:08.848136.848136 lmp.py:376]   Expert 27 |    122 | CPU
DEBUG 01-05 09:59:08.848971.848971 lmp.py:376]   Expert 39 |    122 | CPU
DEBUG 01-05 09:59:08.848330.848330 lmp.py:376]   Expert  9 |    123 | CPU
DEBUG 01-05 09:59:08.848926.848926 lmp.py:376]   Expert 10 |    123 | CPU
DEBUG 01-05 09:59:08.848523.848523 lmp.py:376]   Expert 51 |    134 | GPU
DEBUG 01-05 09:59:08.848643.848643 lmp.py:376]   Expert 26 |    140 | GPU
DEBUG 01-05 09:59:08.848763.848763 lmp.py:376]   Expert 38 |    140 | GPU
DEBUG 01-05 09:59:08.848644.848644 lmp.py:376]   Expert 28 |    143 | GPU
DEBUG 01-05 09:59:08.848764.848764 lmp.py:376]   Expert 62 |    146 | GPU
DEBUG 01-05 09:59:08.848122.848122 lmp.py:376]   Expert  2 |    154 | GPU
DEBUG 01-05 09:59:08.848242.848242 lmp.py:376]   Expert 21 |    157 | GPU
DEBUG 01-05 09:59:08.848554.848554 lmp.py:376]   Expert 31 |    157 | GPU
DEBUG 01-05 09:59:08.848627.848627 lmp.py:376]   Expert 16 |    183 | GPU
DEBUG 01-05 09:59:08.848985.848985 lmp.py:376]   Expert  1 |    202 | GPU
DEBUG 01-05 09:59:08.848867.848867 lmp.py:376]   Expert 25 |    206 | GPU
DEBUG 01-05 09:59:08.848225.848225 lmp.py:376]   Expert 56 |    218 | GPU
DEBUG 01-05 09:59:08.848345.848345 lmp.py:376]   Expert 17 |    232 | GPU
DEBUG 01-05 09:59:08.848226.848226 lmp.py:376]   Expert 35 |    242 | GPU
DEBUG 01-05 09:59:08.848108.848108 lmp.py:376]   Expert 50 |    251 | GPU
DEBUG 01-05 09:59:08.848227.848227 lmp.py:376]   Expert 40 |    255 | GPU
DEBUG 01-05 09:59:08.848824.848824 lmp.py:376]   Expert 19 |    264 | GPU
DEBUG 01-05 09:59:08.849944.849944 lmp.py:376]   Expert 43 |    272 | GPU
DEBUG 01-05 09:59:08.849302.849302 lmp.py:376]   Expert 14 |    302 | GPU
DEBUG 01-05 09:59:08.849614.849614 lmp.py:376]   Expert 20 |    302 | GPU
DEBUG 01-05 09:59:08.849449.849449 lmp.py:376]   Expert  8 |    315 | GPU
DEBUG 01-05 09:59:08.849046.849046 lmp.py:376]   Expert 29 |    331 | GPU
DEBUG 01-05 09:59:08.849404.849404 lmp.py:376]   Expert 23 |    334 | GPU
DEBUG 01-05 09:59:08.849524.849524 lmp.py:376]   Expert  4 |    353 | GPU
DEBUG 01-05 09:59:08.849405.849405 lmp.py:376]   Expert 18 |    371 | GPU
DEBUG 01-05 09:59:08.849287.849287 lmp.py:376]   Expert 53 |    390 | GPU
DEBUG 01-05 09:59:08.849645.849645 lmp.py:376]   Expert 34 |    391 | GPU
DEBUG 01-05 09:59:08.849718.849718 lmp.py:376]   Expert 55 |    469 | GPU
DEBUG 01-05 09:59:08.849553.849553 lmp.py:376]   Expert 59 |    485 | GPU
DEBUG 01-05 09:59:08.849673.849673 lmp.py:376]   Expert 33 |    617 | GPU
DEBUG 01-05 09:59:08.849555.849555 lmp.py:376]   Expert 36 |    640 | GPU
DEBUG 01-05 09:59:08.849674.849674 lmp.py:376]   Expert  5 |    863 | GPU
DEBUG 01-05 09:59:08.849748.849748 lmp.py:377] 
DEBUG 01-05 09:59:08.849748.849748 lmp.py:377]   CPU total tokens: 2629 (21.4%)
DEBUG 01-05 09:59:08.849583.849583 lmp.py:378]   GPU total tokens: 9659 (78.6%)
DEBUG 01-05 09:59:08.849425.849425 cuda_h.py:19] end experts_map_get cost 0.001783132553100586 seconds
DEBUG 01-05 09:59:08.849690.849690 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.849712.849712 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.849816.849816 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.849382.849382 cuda_h.py:19] end allocate_cuda_memory cost 0.00023984909057617188 seconds
DEBUG 01-05 09:59:08.849153.849153 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.849531.849531 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.849248.849248 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.849089.849089 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 06df5439-7ff7-40c6-a45f-c378f22c2dde
DEBUG 01-05 09:59:08.850433.850433 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.850197.850197 client.py:127] Model loaded
DEBUG 01-05 09:59:08.850367.850367 cuda_h.py:19] end sllm_worker_task cost 0.011417865753173828 seconds
INFO 01-05 09:59:08.851893.851893 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 06df5439-7ff7-40c6-a45f-c378f22c2dde
DEBUG 01-05 09:59:08.851551.851551 cuda_h.py:19] end load_into_gpu_async cost 0.00138092041015625 seconds
DEBUG 01-05 09:59:08.851208.851208 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.851279.851279 cuda_h.py:19] end restore_tensors2 cost 0.00034117698669433594 seconds
DEBUG 01-05 09:59:08.851149.851149 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023343563079833984 seconds
DEBUG 01-05 09:59:08.854971.854971 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0055828094482421875 seconds
DEBUG 01-05 09:59:08.855277.855277 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.855585.855585 lmp.py:423] 
DEBUG 01-05 09:59:08.855585.855585 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.855104.855104 cuda_h.py:19] end cpu_experts_submit cost 0.00012183189392089844 seconds
DEBUG 01-05 09:59:08.855138.855138 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.866353.866353 mlpmodule.py:704] group tensors cost 0.010757923126220703 s
DEBUG 01-05 09:59:08.868444.868444 mlpmodule.py:742] pad cost 0.0016982555389404297 s
DEBUG 01-05 09:59:08.868739.868739 mlpmodule.py:748] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-05 09:59:08.868503.868503 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-05 09:59:08.881145.881145 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.881609.881609 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.881182.881182 mlpmodule.py:773] group_w3 first element: -0.018798828125
WARNING 01-05 09:59:08.881133.881133 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.899211.899211 mlpmodule.py:793] group einsum cost 0.030945301055908203 s
DEBUG 01-05 09:59:08.900311.900311 mlpmodule.py:801] cpy2cputensor cost 0.0005564689636230469 s
DEBUG 01-05 09:59:08.905269.905269 cuda_h.py:19] end wait_cetm_experts cost 0.05071282386779785 seconds
DEBUG 01-05 09:59:08.906361.906361 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.906677.906677 cuda_h.py:19] end gpu_sexperts cost 0.0006771087646484375 seconds
DEBUG 01-05 09:59:08.906911.906911 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.907536.907536 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.218650817871094e-05 seconds
DEBUG 01-05 09:59:08.907815.907815 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.907862.907862 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 06df5439-7ff7-40c6-a45f-c378f22c2dde
INFO 01-05 09:59:08.908246.908246 client.py:127] Model loaded
DEBUG 01-05 09:59:08.908904.908904 cuda_h.py:19] end wait_experts cost 0.0010497570037841797 seconds
DEBUG 01-05 09:59:08.908422.908422 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.908323.908323 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.908501.908501 mlpmodule.py:531] gpu group tensors cost 0.0006754398345947266 s
DEBUG 01-05 09:59:08.911719.911719 mlpmodule.py:564] gpu pad cost 0.0022783279418945312 s
DEBUG 01-05 09:59:08.911682.911682 mlpmodule.py:582] gpu group einsum cost 0.0005927085876464844 s
DEBUG 01-05 09:59:08.916137.916137 mlpmodule.py:611] gpu experts func einsum cost 0.008375406265258789 s
DEBUG 01-05 09:59:08.916372.916372 cuda_h.py:19] end gpu_experts cost 0.008570194244384766 seconds
DEBUG 01-05 09:59:08.916600.916600 cuda_h.py:19] end layer_moe_generate_22 cost 0.07018685340881348 seconds
DEBUG 01-05 09:59:08.917613.917613 lmp.py:217] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 09:59:08.917469.917469 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 09:59:08.917834.917834 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:59:08.917504.917504 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:59:08.917062.917062 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:59:08.917931.917931 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 8.082389831542969e-05 seconds
DEBUG 01-05 09:59:08.917627.917627 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.917185.917185 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.917699.917699 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.917119.917119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.919395.919395 cuda_h.py:19] end allocate_cuda_memory cost 0.0014634132385253906 seconds
DEBUG 01-05 09:59:08.919152.919152 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.919326.919326 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.919910.919910 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.919090.919090 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2de3cd1c-a9ce-4deb-b81d-5ed51ab2eefa
DEBUG 01-05 09:59:08.919437.919437 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.919072.919072 mlpmodule.py:662]  experts func einsum cost 0.06412816047668457 s
DEBUG 01-05 09:59:08.919177.919177 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.920956.920956 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2de3cd1c-a9ce-4deb-b81d-5ed51ab2eefa
DEBUG 01-05 09:59:08.920350.920350 cuda_h.py:19] end load_into_gpu_async cost 0.001104116439819336 seconds
DEBUG 01-05 09:59:08.920245.920245 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.920010.920010 cuda_h.py:19] end restore_tensors2 cost 8.130073547363281e-05 seconds
DEBUG 01-05 09:59:08.920720.920720 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002923727035522461 seconds
INFO 01-05 09:59:08.921289.921289 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2de3cd1c-a9ce-4deb-b81d-5ed51ab2eefa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.924362.924362 cuda_h.py:19] end self_attn cost 0.004408359527587891 seconds
DEBUG 01-05 09:59:08.924905.924905 cuda_h.py:19] end iln_self_attn_paln cost 0.007474422454833984 seconds
DEBUG 01-05 09:59:08.924331.924331 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 09:59:08.924260.924260 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.925247.925247 cuda_h.py:19] end gate cost 0.000759124755859375 seconds
DEBUG 01-05 09:59:08.925984.925984 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.926833.926833 lmp.py:365] 
DEBUG 01-05 09:59:08.926833.926833 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.926119.926119 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.926975.926975 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.926962.926962 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.926751.926751 lmp.py:369] 
DEBUG 01-05 09:59:08.926751.926751 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.926394.926394 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.926759.926759 lmp.py:376]   Expert 49 |     23 | CPU
DEBUG 01-05 09:59:08.926641.926641 lmp.py:376]   Expert  5 |     29 | CPU
DEBUG 01-05 09:59:08.926045.926045 lmp.py:376]   Expert  6 |     40 | CPU
DEBUG 01-05 09:59:08.926211.926211 lmp.py:376]   Expert 16 |     45 | CPU
DEBUG 01-05 09:59:08.926901.926901 lmp.py:376]   Expert 44 |     45 | CPU
DEBUG 01-05 09:59:08.926351.926351 lmp.py:376]   Expert 17 |     60 | CPU
DEBUG 01-05 09:59:08.926802.926802 lmp.py:376]   Expert 27 |     62 | CPU
DEBUG 01-05 09:59:08.926015.926015 lmp.py:376]   Expert 25 |     77 | CPU
DEBUG 01-05 09:59:08.926466.926466 lmp.py:376]   Expert 63 |     82 | CPU
DEBUG 01-05 09:59:08.926155.926155 lmp.py:376]   Expert 38 |     83 | CPU
DEBUG 01-05 09:59:08.926129.926129 lmp.py:376]   Expert  1 |     86 | CPU
DEBUG 01-05 09:59:08.926580.926580 lmp.py:376]   Expert 53 |     87 | CPU
DEBUG 01-05 09:59:08.926846.926846 lmp.py:376]   Expert 19 |     88 | CPU
DEBUG 01-05 09:59:08.926548.926548 lmp.py:376]   Expert 40 |     89 | CPU
DEBUG 01-05 09:59:08.926244.926244 lmp.py:376]   Expert  7 |     90 | CPU
DEBUG 01-05 09:59:08.926649.926649 lmp.py:376]   Expert 51 |     94 | CPU
DEBUG 01-05 09:59:08.926815.926815 lmp.py:376]   Expert 28 |    102 | CPU
DEBUG 01-05 09:59:08.926504.926504 lmp.py:376]   Expert 45 |    107 | CPU
DEBUG 01-05 09:59:08.926671.926671 lmp.py:376]   Expert 35 |    115 | CPU
DEBUG 01-05 09:59:08.926837.926837 lmp.py:376]   Expert 34 |    116 | CPU
DEBUG 01-05 09:59:08.926003.926003 lmp.py:376]   Expert 52 |    116 | CPU
DEBUG 01-05 09:59:08.926407.926407 lmp.py:376]   Expert  4 |    118 | CPU
DEBUG 01-05 09:59:08.926050.926050 lmp.py:376]   Expert 61 |    121 | CPU
DEBUG 01-05 09:59:08.926661.926661 lmp.py:376]   Expert 30 |    131 | CPU
DEBUG 01-05 09:59:08.926364.926364 lmp.py:376]   Expert 55 |    133 | CPU
DEBUG 01-05 09:59:08.926344.926344 lmp.py:376]   Expert 24 |    135 | CPU
DEBUG 01-05 09:59:08.926987.926987 lmp.py:376]   Expert 43 |    137 | CPU
DEBUG 01-05 09:59:08.926153.926153 lmp.py:376]   Expert 15 |    139 | CPU
DEBUG 01-05 09:59:08.926558.926558 lmp.py:376]   Expert 22 |    145 | CPU
DEBUG 01-05 09:59:08.926963.926963 lmp.py:376]   Expert 58 |    152 | CPU
DEBUG 01-05 09:59:08.926367.926367 lmp.py:376]   Expert 47 |    154 | CPU
DEBUG 01-05 09:59:08.926533.926533 lmp.py:376]   Expert 42 |    156 | CPU
DEBUG 01-05 09:59:08.926938.926938 lmp.py:376]   Expert 14 |    163 | GPU
DEBUG 01-05 09:59:08.926594.926594 lmp.py:376]   Expert  3 |    166 | GPU
DEBUG 01-05 09:59:08.927628.927628 lmp.py:376]   Expert 36 |    167 | GPU
DEBUG 01-05 09:59:08.927656.927656 lmp.py:376]   Expert 13 |    172 | GPU
DEBUG 01-05 09:59:08.927060.927060 lmp.py:376]   Expert 39 |    174 | GPU
DEBUG 01-05 09:59:08.927465.927465 lmp.py:376]   Expert 60 |    176 | GPU
DEBUG 01-05 09:59:08.927631.927631 lmp.py:376]   Expert  9 |    181 | GPU
DEBUG 01-05 09:59:08.927797.927797 lmp.py:376]   Expert 41 |    186 | GPU
DEBUG 01-05 09:59:08.927201.927201 lmp.py:376]   Expert  0 |    196 | GPU
DEBUG 01-05 09:59:08.927368.927368 lmp.py:376]   Expert 26 |    202 | GPU
DEBUG 01-05 09:59:08.927733.927733 lmp.py:376]   Expert 37 |    208 | GPU
DEBUG 01-05 09:59:08.927767.927767 lmp.py:376]   Expert 11 |    210 | GPU
DEBUG 01-05 09:59:08.927555.927555 lmp.py:376]   Expert 23 |    216 | GPU
DEBUG 01-05 09:59:08.927960.927960 lmp.py:376]   Expert  8 |    225 | GPU
DEBUG 01-05 09:59:08.927126.927126 lmp.py:376]   Expert 46 |    237 | GPU
DEBUG 01-05 09:59:08.927292.927292 lmp.py:376]   Expert 33 |    241 | GPU
DEBUG 01-05 09:59:08.927220.927220 lmp.py:376]   Expert 29 |    259 | GPU
DEBUG 01-05 09:59:08.927624.927624 lmp.py:376]   Expert 20 |    275 | GPU
DEBUG 01-05 09:59:08.927791.927791 lmp.py:376]   Expert 56 |    284 | GPU
DEBUG 01-05 09:59:08.927718.927718 lmp.py:376]   Expert 62 |    298 | GPU
DEBUG 01-05 09:59:08.927183.927183 lmp.py:376]   Expert 59 |    300 | GPU
DEBUG 01-05 09:59:08.927309.927309 lmp.py:376]   Expert 57 |    304 | GPU
DEBUG 01-05 09:59:08.927575.927575 lmp.py:376]   Expert 54 |    343 | GPU
DEBUG 01-05 09:59:08.927979.927979 lmp.py:376]   Expert 18 |    365 | GPU
DEBUG 01-05 09:59:08.927622.927622 lmp.py:376]   Expert  2 |    375 | GPU
DEBUG 01-05 09:59:08.927027.927027 lmp.py:376]   Expert 21 |    377 | GPU
DEBUG 01-05 09:59:08.927670.927670 lmp.py:376]   Expert 50 |    387 | GPU
DEBUG 01-05 09:59:08.927075.927075 lmp.py:376]   Expert 32 |    393 | GPU
DEBUG 01-05 09:59:08.927479.927479 lmp.py:376]   Expert 48 |    419 | GPU
DEBUG 01-05 09:59:08.927884.927884 lmp.py:376]   Expert 10 |    450 | GPU
DEBUG 01-05 09:59:08.927633.927633 lmp.py:376]   Expert 31 |    517 | GPU
DEBUG 01-05 09:59:08.927972.927972 lmp.py:376]   Expert 12 |    665 | GPU
DEBUG 01-05 09:59:08.927383.927383 lmp.py:377] 
DEBUG 01-05 09:59:08.927383.927383 lmp.py:377]   CPU total tokens: 3157 (25.7%)
DEBUG 01-05 09:59:08.927695.927695 lmp.py:378]   GPU total tokens: 9131 (74.3%)
DEBUG 01-05 09:59:08.927444.927444 cuda_h.py:19] end experts_map_get cost 0.0018434524536132812 seconds
DEBUG 01-05 09:59:08.927279.927279 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:08.927507.927507 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.927062.927062 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.928986.928986 cuda_h.py:19] end allocate_cuda_memory cost 0.000232696533203125 seconds
DEBUG 01-05 09:59:08.928419.928419 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.928281.928281 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.928189.928189 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.928270.928270 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9036a5f5-f3c1-4ffd-8b3f-48d540a853b7
DEBUG 01-05 09:59:08.928337.928337 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:08.928883.928883 client.py:127] Model loaded
DEBUG 01-05 09:59:08.928682.928682 cuda_h.py:19] end sllm_worker_task cost 0.011371374130249023 seconds
INFO 01-05 09:59:08.929045.929045 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9036a5f5-f3c1-4ffd-8b3f-48d540a853b7
DEBUG 01-05 09:59:08.929584.929584 cuda_h.py:19] end load_into_gpu_async cost 0.0013432502746582031 seconds
DEBUG 01-05 09:59:08.929678.929678 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.930473.930473 cuda_h.py:19] end restore_tensors2 cost 0.0003771781921386719 seconds
DEBUG 01-05 09:59:08.930502.930502 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023870468139648438 seconds
DEBUG 01-05 09:59:08.933658.933658 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00572514533996582 seconds
DEBUG 01-05 09:59:08.933494.933494 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:08.933027.933027 lmp.py:423] 
DEBUG 01-05 09:59:08.933027.933027 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:08.933759.933759 cuda_h.py:19] end cpu_experts_submit cost 0.00015211105346679688 seconds
DEBUG 01-05 09:59:08.933793.933793 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:08.943003.943003 mlpmodule.py:704] group tensors cost 0.009624242782592773 s
DEBUG 01-05 09:59:08.946078.946078 mlpmodule.py:742] pad cost 0.0018992424011230469 s
DEBUG 01-05 09:59:08.946241.946241 mlpmodule.py:748] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-05 09:59:08.946925.946925 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 09:59:08.955221.955221 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:08.955559.955559 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:08.956371.956371 mlpmodule.py:773] group_w3 first element: 0.08447265625
WARNING 01-05 09:59:08.956859.956859 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:08.973938.973938 mlpmodule.py:793] group einsum cost 0.026989459991455078 s
DEBUG 01-05 09:59:08.974227.974227 mlpmodule.py:801] cpy2cputensor cost 0.0006766319274902344 s
DEBUG 01-05 09:59:08.979498.979498 cuda_h.py:19] end wait_cetm_experts cost 0.04569816589355469 seconds
DEBUG 01-05 09:59:08.979523.979523 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:08.980136.980136 cuda_h.py:19] end gpu_sexperts cost 0.0006511211395263672 seconds
DEBUG 01-05 09:59:08.980603.980603 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:08.980281.980281 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4809112548828125e-05 seconds
DEBUG 01-05 09:59:08.980752.980752 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:08.980992.980992 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9036a5f5-f3c1-4ffd-8b3f-48d540a853b7
INFO 01-05 09:59:08.984271.984271 client.py:127] Model loaded
DEBUG 01-05 09:59:08.984313.984313 cuda_h.py:19] end wait_experts cost 0.0036804676055908203 seconds
DEBUG 01-05 09:59:08.984785.984785 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:08.984925.984925 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:08.985202.985202 mlpmodule.py:531] gpu group tensors cost 0.0006663799285888672 s
DEBUG 01-05 09:59:08.987989.987989 mlpmodule.py:564] gpu pad cost 0.002275705337524414 s
DEBUG 01-05 09:59:08.988258.988258 mlpmodule.py:582] gpu group einsum cost 0.0006415843963623047 s
DEBUG 01-05 09:59:08.992232.992232 mlpmodule.py:662]  experts func einsum cost 0.058413028717041016 s
DEBUG 01-05 09:59:08.992047.992047 mlpmodule.py:611] gpu experts func einsum cost 0.008087158203125 s
DEBUG 01-05 09:59:08.992006.992006 cuda_h.py:19] end gpu_experts cost 0.00834798812866211 seconds
DEBUG 01-05 09:59:08.992572.992572 cuda_h.py:19] end layer_moe_generate_23 cost 0.06786370277404785 seconds
DEBUG 01-05 09:59:08.992538.992538 lmp.py:217] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 09:59:08.992070.992070 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 09:59:08.993150.993150 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:59:08.993290.993290 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:59:08.993371.993371 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:08.993505.993505 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.341934204101562e-05 seconds
DEBUG 01-05 09:59:08.993678.993678 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:08.993282.993282 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:08.993206.993206 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:08.993103.993103 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:08.993731.993731 cuda_h.py:19] end allocate_cuda_memory cost 0.0003123283386230469 seconds
DEBUG 01-05 09:59:08.993085.993085 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:08.993609.993609 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:08.993478.993478 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:08.993227.993227 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 47712eaa-81d0-4c33-9cd3-d8b30e506870
DEBUG 01-05 09:59:08.994436.994436 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:08.994432.994432 cuda_h.py:10] start self_attn
INFO 01-05 09:59:08.995217.995217 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 47712eaa-81d0-4c33-9cd3-d8b30e506870
DEBUG 01-05 09:59:08.995245.995245 cuda_h.py:19] end load_into_gpu_async cost 0.0013799667358398438 seconds
DEBUG 01-05 09:59:08.995279.995279 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:08.995600.995600 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 09:59:08.995925.995925 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002041339874267578 seconds
INFO 01-05 09:59:08.995686.995686 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 47712eaa-81d0-4c33-9cd3-d8b30e506870
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:08.998424.998424 cuda_h.py:19] end self_attn cost 0.003648519515991211 seconds
DEBUG 01-05 09:59:08.998323.998323 cuda_h.py:19] end iln_self_attn_paln cost 0.005183219909667969 seconds
DEBUG 01-05 09:59:08.998404.998404 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 09:59:08.998313.998313 cuda_h.py:10] start gate
DEBUG 01-05 09:59:08.999689.999689 cuda_h.py:19] end gate cost 0.0007326602935791016 seconds
DEBUG 01-05 09:59:08.999473.999473 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:08.999137.999137 lmp.py:365] 
DEBUG 01-05 09:59:08.999137.999137 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:08.999893.999893 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:08.999927.999927 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:08.999146.999146 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:08.999220.999220 lmp.py:369] 
DEBUG 01-05 09:59:08.999220.999220 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:08.999770.999770 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:08.999281.999281 lmp.py:376]   Expert 56 |     28 | CPU
DEBUG 01-05 09:59:08.999354.999354 lmp.py:376]   Expert 47 |     30 | CPU
DEBUG 01-05 09:59:08.999189.999189 lmp.py:376]   Expert 44 |     31 | CPU
DEBUG 01-05 09:59:08.999547.999547 lmp.py:376]   Expert 42 |     38 | CPU
DEBUG 01-05 09:59:08.999667.999667 lmp.py:376]   Expert 43 |     40 | CPU
DEBUG 01-05 09:59:08.999549.999549 lmp.py:376]   Expert 16 |     45 | CPU
DEBUG 01-05 09:59:09.000430.000430 lmp.py:376]   Expert 48 |     55 | CPU
DEBUG 01-05 09:59:09.000027.000027 lmp.py:376]   Expert 30 |     59 | CPU
DEBUG 01-05 09:59:09.000385.000385 lmp.py:376]   Expert 22 |     66 | CPU
DEBUG 01-05 09:59:09.000028.000028 lmp.py:376]   Expert 25 |     79 | CPU
DEBUG 01-05 09:59:09.000148.000148 lmp.py:376]   Expert  5 |     80 | CPU
DEBUG 01-05 09:59:09.000698.000698 lmp.py:376]   Expert 55 |     80 | CPU
DEBUG 01-05 09:59:09.000533.000533 lmp.py:376]   Expert 54 |     85 | CPU
DEBUG 01-05 09:59:09.000130.000130 lmp.py:376]   Expert  2 |     87 | CPU
DEBUG 01-05 09:59:09.000488.000488 lmp.py:376]   Expert  6 |     90 | CPU
DEBUG 01-05 09:59:09.000369.000369 lmp.py:376]   Expert 62 |     95 | CPU
DEBUG 01-05 09:59:09.000251.000251 lmp.py:376]   Expert 21 |    103 | CPU
DEBUG 01-05 09:59:09.000371.000371 lmp.py:376]   Expert 51 |    108 | CPU
DEBUG 01-05 09:59:09.000014.000014 lmp.py:376]   Expert  0 |    114 | CPU
DEBUG 01-05 09:59:09.000895.000895 lmp.py:376]   Expert 61 |    117 | CPU
DEBUG 01-05 09:59:09.000299.000299 lmp.py:376]   Expert 41 |    123 | CPU
DEBUG 01-05 09:59:09.000942.000942 lmp.py:376]   Expert 15 |    127 | CPU
DEBUG 01-05 09:59:09.000016.000016 lmp.py:376]   Expert 28 |    128 | CPU
DEBUG 01-05 09:59:09.000613.000613 lmp.py:376]   Expert  1 |    135 | CPU
DEBUG 01-05 09:59:09.000448.000448 lmp.py:376]   Expert 20 |    135 | CPU
DEBUG 01-05 09:59:09.000521.000521 lmp.py:376]   Expert 35 |    136 | CPU
DEBUG 01-05 09:59:09.000164.000164 lmp.py:376]   Expert 63 |    139 | CPU
DEBUG 01-05 09:59:09.000013.000013 lmp.py:376]   Expert 60 |    140 | CPU
DEBUG 01-05 09:59:09.000776.000776 lmp.py:376]   Expert 57 |    141 | CPU
DEBUG 01-05 09:59:09.000611.000611 lmp.py:376]   Expert  3 |    143 | CPU
DEBUG 01-05 09:59:09.000730.000730 lmp.py:376]   Expert 36 |    145 | CPU
DEBUG 01-05 09:59:09.000850.000850 lmp.py:376]   Expert 59 |    152 | CPU
DEBUG 01-05 09:59:09.000447.000447 lmp.py:376]   Expert 29 |    155 | GPU
DEBUG 01-05 09:59:09.000282.000282 lmp.py:376]   Expert 24 |    164 | GPU
DEBUG 01-05 09:59:09.000594.000594 lmp.py:376]   Expert  7 |    171 | GPU
DEBUG 01-05 09:59:09.000144.000144 lmp.py:376]   Expert 40 |    174 | GPU
DEBUG 01-05 09:59:09.000933.000933 lmp.py:376]   Expert 19 |    175 | GPU
DEBUG 01-05 09:59:09.000291.000291 lmp.py:376]   Expert 46 |    180 | GPU
DEBUG 01-05 09:59:09.000411.000411 lmp.py:376]   Expert 50 |    185 | GPU
DEBUG 01-05 09:59:09.000769.000769 lmp.py:376]   Expert  4 |    186 | GPU
DEBUG 01-05 09:59:09.000651.000651 lmp.py:376]   Expert 38 |    186 | GPU
DEBUG 01-05 09:59:09.000532.000532 lmp.py:376]   Expert 33 |    197 | GPU
DEBUG 01-05 09:59:09.000413.000413 lmp.py:376]   Expert 34 |    198 | GPU
DEBUG 01-05 09:59:09.000295.000295 lmp.py:376]   Expert 53 |    198 | GPU
DEBUG 01-05 09:59:09.000415.000415 lmp.py:376]   Expert 39 |    201 | GPU
DEBUG 01-05 09:59:09.000534.000534 lmp.py:376]   Expert 17 |    203 | GPU
DEBUG 01-05 09:59:09.000893.000893 lmp.py:376]   Expert 26 |    206 | GPU
DEBUG 01-05 09:59:09.000443.000443 lmp.py:376]   Expert 49 |    216 | GPU
DEBUG 01-05 09:59:09.000278.000278 lmp.py:376]   Expert 12 |    230 | GPU
DEBUG 01-05 09:59:09.000875.000875 lmp.py:376]   Expert 10 |    236 | GPU
DEBUG 01-05 09:59:09.000710.000710 lmp.py:376]   Expert  9 |    250 | GPU
DEBUG 01-05 09:59:09.000830.000830 lmp.py:376]   Expert 45 |    260 | GPU
DEBUG 01-05 09:59:09.000711.000711 lmp.py:376]   Expert 14 |    291 | GPU
DEBUG 01-05 09:59:09.000592.000592 lmp.py:376]   Expert 23 |    297 | GPU
DEBUG 01-05 09:59:09.000712.000712 lmp.py:376]   Expert 37 |    297 | GPU
DEBUG 01-05 09:59:09.000832.000832 lmp.py:376]   Expert 52 |    298 | GPU
DEBUG 01-05 09:59:09.000952.000952 lmp.py:376]   Expert 58 |    298 | GPU
DEBUG 01-05 09:59:09.000833.000833 lmp.py:376]   Expert 18 |    301 | GPU
DEBUG 01-05 09:59:09.000715.000715 lmp.py:376]   Expert 31 |    312 | GPU
DEBUG 01-05 09:59:09.001788.001788 lmp.py:376]   Expert  8 |    492 | GPU
DEBUG 01-05 09:59:09.001385.001385 lmp.py:376]   Expert 11 |    523 | GPU
DEBUG 01-05 09:59:09.001935.001935 lmp.py:376]   Expert 13 |    608 | GPU
DEBUG 01-05 09:59:09.001293.001293 lmp.py:376]   Expert 32 |    745 | GPU
DEBUG 01-05 09:59:09.001651.001651 lmp.py:376]   Expert 27 |    781 | GPU
DEBUG 01-05 09:59:09.001963.001963 lmp.py:377] 
DEBUG 01-05 09:59:09.001963.001963 lmp.py:377]   CPU total tokens: 3074 (25.0%)
DEBUG 01-05 09:59:09.001514.001514 lmp.py:378]   GPU total tokens: 9214 (75.0%)
DEBUG 01-05 09:59:09.001594.001594 cuda_h.py:19] end experts_map_get cost 0.0018138885498046875 seconds
DEBUG 01-05 09:59:09.001667.001667 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:09.001212.001212 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:09.001787.001787 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:09.002986.002986 cuda_h.py:19] end allocate_cuda_memory cost 0.0013756752014160156 seconds
DEBUG 01-05 09:59:09.002518.002518 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:09.002182.002182 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:09.002945.002945 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:09.002429.002429 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2e15f2f7-af54-41b3-87fb-2374102b764c
DEBUG 01-05 09:59:09.003614.003614 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:09.003938.003938 client.py:127] Model loaded
DEBUG 01-05 09:59:09.003563.003563 cuda_h.py:19] end sllm_worker_task cost 0.010275602340698242 seconds
INFO 01-05 09:59:09.004905.004905 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2e15f2f7-af54-41b3-87fb-2374102b764c
DEBUG 01-05 09:59:09.004185.004185 cuda_h.py:19] end load_into_gpu_async cost 0.0014736652374267578 seconds
DEBUG 01-05 09:59:09.004557.004557 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:09.004033.004033 cuda_h.py:19] end restore_tensors2 cost 0.00035119056701660156 seconds
DEBUG 01-05 09:59:09.004810.004810 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003575563430786133 seconds
DEBUG 01-05 09:59:09.008533.008533 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006822824478149414 seconds
DEBUG 01-05 09:59:09.008124.008124 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:09.008074.008074 lmp.py:423] 
DEBUG 01-05 09:59:09.008074.008074 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:09.008116.008116 cuda_h.py:19] end cpu_experts_submit cost 0.0001227855682373047 seconds
DEBUG 01-05 09:59:09.008865.008865 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:09.019228.019228 mlpmodule.py:704] group tensors cost 0.010529518127441406 s
DEBUG 01-05 09:59:09.022462.022462 mlpmodule.py:742] pad cost 0.0022592544555664062 s
DEBUG 01-05 09:59:09.022420.022420 mlpmodule.py:748] create cpu tensor cost 5.841255187988281e-05 s
DEBUG 01-05 09:59:09.022967.022967 mlpmodule.py:753] move to cpu cost 6.985664367675781e-05 s
DEBUG 01-05 09:59:09.032044.032044 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:09.032495.032495 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:09.032221.032221 mlpmodule.py:773] group_w3 first element: 0.00653076171875
WARNING 01-05 09:59:09.032225.032225 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:09.051881.051881 mlpmodule.py:793] group einsum cost 0.028551101684570312 s
DEBUG 01-05 09:59:09.051971.051971 mlpmodule.py:801] cpy2cputensor cost 0.0006673336029052734 s
DEBUG 01-05 09:59:09.057632.057632 cuda_h.py:19] end wait_cetm_experts cost 0.04872632026672363 seconds
DEBUG 01-05 09:59:09.057247.057247 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:09.057702.057702 cuda_h.py:19] end gpu_sexperts cost 0.0006742477416992188 seconds
DEBUG 01-05 09:59:09.058505.058505 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:09.058223.058223 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:09.058217.058217 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:09.058980.058980 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2e15f2f7-af54-41b3-87fb-2374102b764c
INFO 01-05 09:59:09.059118.059118 client.py:127] Model loaded
DEBUG 01-05 09:59:09.059916.059916 cuda_h.py:19] end wait_experts cost 0.0016374588012695312 seconds
DEBUG 01-05 09:59:09.059771.059771 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:09.059150.059150 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:09.060373.060373 mlpmodule.py:531] gpu group tensors cost 0.0006365776062011719 s
DEBUG 01-05 09:59:09.062798.062798 mlpmodule.py:564] gpu pad cost 0.00176239013671875 s
DEBUG 01-05 09:59:09.063998.063998 mlpmodule.py:582] gpu group einsum cost 0.0005533695220947266 s
DEBUG 01-05 09:59:09.066544.066544 mlpmodule.py:611] gpu experts func einsum cost 0.006730079650878906 s
DEBUG 01-05 09:59:09.066971.066971 cuda_h.py:19] end gpu_experts cost 0.006927967071533203 seconds
DEBUG 01-05 09:59:09.066517.066517 cuda_h.py:19] end layer_moe_generate_24 cost 0.06841468811035156 seconds
DEBUG 01-05 09:59:09.067278.067278 lmp.py:217] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 09:59:09.067187.067187 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 09:59:09.067459.067459 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:59:09.067314.067314 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:59:09.067197.067197 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.86102294921875e-05 seconds
DEBUG 01-05 09:59:09.067927.067927 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:09.067604.067604 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.00011777877807617188 seconds
DEBUG 01-05 09:59:09.067275.067275 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:09.067906.067906 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:09.067948.067948 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:09.069838.069838 cuda_h.py:19] end allocate_cuda_memory cost 0.0017666816711425781 seconds
DEBUG 01-05 09:59:09.069021.069021 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:09.069929.069929 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:09.069421.069421 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:09.069601.069601 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 69f1d8a5-8c5e-472e-a0cd-98a25e858ab7
DEBUG 01-05 09:59:09.069855.069855 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:09.069590.069590 mlpmodule.py:662]  experts func einsum cost 0.06133103370666504 s
DEBUG 01-05 09:59:09.070925.070925 cuda_h.py:10] start self_attn
INFO 01-05 09:59:09.070449.070449 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 69f1d8a5-8c5e-472e-a0cd-98a25e858ab7
DEBUG 01-05 09:59:09.070345.070345 cuda_h.py:19] end load_into_gpu_async cost 0.0011463165283203125 seconds
DEBUG 01-05 09:59:09.070856.070856 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:09.070839.070839 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-05 09:59:09.070808.070808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033593177795410156 seconds
INFO 01-05 09:59:09.071025.071025 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 69f1d8a5-8c5e-472e-a0cd-98a25e858ab7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:09.073632.073632 cuda_h.py:19] end self_attn cost 0.0031991004943847656 seconds
DEBUG 01-05 09:59:09.073032.073032 cuda_h.py:19] end iln_self_attn_paln cost 0.006228446960449219 seconds
DEBUG 01-05 09:59:09.073776.073776 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 09:59:09.073684.073684 cuda_h.py:10] start gate
DEBUG 01-05 09:59:09.074865.074865 cuda_h.py:19] end gate cost 0.0006258487701416016 seconds
DEBUG 01-05 09:59:09.074072.074072 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:09.074288.074288 lmp.py:365] 
DEBUG 01-05 09:59:09.074288.074288 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:09.074249.074249 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:09.074376.074376 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:09.074403.074403 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:09.074284.074284 lmp.py:369] 
DEBUG 01-05 09:59:09.074284.074284 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:09.074643.074643 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:09.075769.075769 lmp.py:376]   Expert 42 |     15 | CPU
DEBUG 01-05 09:59:09.075697.075697 lmp.py:376]   Expert 55 |     16 | CPU
DEBUG 01-05 09:59:09.075671.075671 lmp.py:376]   Expert 33 |     20 | CPU
DEBUG 01-05 09:59:09.075883.075883 lmp.py:376]   Expert  0 |     31 | CPU
DEBUG 01-05 09:59:09.075858.075858 lmp.py:376]   Expert 16 |     39 | CPU
DEBUG 01-05 09:59:09.075593.075593 lmp.py:376]   Expert 24 |     41 | CPU
DEBUG 01-05 09:59:09.075090.075090 lmp.py:376]   Expert  2 |     43 | CPU
DEBUG 01-05 09:59:09.075064.075064 lmp.py:376]   Expert 32 |     43 | CPU
DEBUG 01-05 09:59:09.075038.075038 lmp.py:376]   Expert 22 |     44 | CPU
DEBUG 01-05 09:59:09.075536.075536 lmp.py:376]   Expert 36 |     46 | CPU
DEBUG 01-05 09:59:09.075271.075271 lmp.py:376]   Expert 34 |     58 | CPU
DEBUG 01-05 09:59:09.075768.075768 lmp.py:376]   Expert 59 |     59 | CPU
DEBUG 01-05 09:59:09.075504.075504 lmp.py:376]   Expert 23 |     66 | CPU
DEBUG 01-05 09:59:09.075670.075670 lmp.py:376]   Expert 10 |     68 | CPU
DEBUG 01-05 09:59:09.075505.075505 lmp.py:376]   Expert 18 |     72 | CPU
DEBUG 01-05 09:59:09.075433.075433 lmp.py:376]   Expert 20 |     79 | CPU
DEBUG 01-05 09:59:09.075222.075222 lmp.py:376]   Expert 21 |     83 | CPU
DEBUG 01-05 09:59:09.075434.075434 lmp.py:376]   Expert 53 |     85 | CPU
DEBUG 01-05 09:59:09.075931.075931 lmp.py:376]   Expert 38 |     88 | CPU
DEBUG 01-05 09:59:09.075952.075952 lmp.py:376]   Expert 13 |     89 | CPU
DEBUG 01-05 09:59:09.075211.075211 lmp.py:376]   Expert 47 |     90 | CPU
DEBUG 01-05 09:59:09.075946.075946 lmp.py:376]   Expert 27 |     93 | CPU
DEBUG 01-05 09:59:09.075205.075205 lmp.py:376]   Expert 46 |     96 | CPU
DEBUG 01-05 09:59:09.075702.075702 lmp.py:376]   Expert 62 |     96 | CPU
DEBUG 01-05 09:59:09.075199.075199 lmp.py:376]   Expert 44 |    101 | CPU
DEBUG 01-05 09:59:09.075697.075697 lmp.py:376]   Expert 50 |    103 | CPU
DEBUG 01-05 09:59:09.075293.075293 lmp.py:376]   Expert 14 |    115 | CPU
DEBUG 01-05 09:59:09.075459.075459 lmp.py:376]   Expert 31 |    130 | CPU
DEBUG 01-05 09:59:09.075149.075149 lmp.py:376]   Expert 35 |    138 | CPU
DEBUG 01-05 09:59:09.075176.075176 lmp.py:376]   Expert 52 |    146 | CPU
DEBUG 01-05 09:59:09.075673.075673 lmp.py:376]   Expert 43 |    147 | CPU
DEBUG 01-05 09:59:09.075409.075409 lmp.py:376]   Expert 51 |    150 | CPU
DEBUG 01-05 09:59:09.075906.075906 lmp.py:376]   Expert 45 |    152 | GPU
DEBUG 01-05 09:59:09.075642.075642 lmp.py:376]   Expert 56 |    161 | GPU
DEBUG 01-05 09:59:09.075139.075139 lmp.py:376]   Expert  4 |    164 | GPU
DEBUG 01-05 09:59:09.075113.075113 lmp.py:376]   Expert  8 |    166 | GPU
DEBUG 01-05 09:59:09.075610.075610 lmp.py:376]   Expert 11 |    168 | GPU
DEBUG 01-05 09:59:09.075107.075107 lmp.py:376]   Expert 48 |    176 | GPU
DEBUG 01-05 09:59:09.075604.075604 lmp.py:376]   Expert 12 |    181 | GPU
DEBUG 01-05 09:59:09.075578.075578 lmp.py:376]   Expert  5 |    201 | GPU
DEBUG 01-05 09:59:09.075076.075076 lmp.py:376]   Expert 39 |    204 | GPU
DEBUG 01-05 09:59:09.075911.075911 lmp.py:376]   Expert  6 |    236 | GPU
DEBUG 01-05 09:59:09.075646.075646 lmp.py:376]   Expert 15 |    241 | GPU
DEBUG 01-05 09:59:09.075382.075382 lmp.py:376]   Expert 57 |    255 | GPU
DEBUG 01-05 09:59:09.075641.075641 lmp.py:376]   Expert 37 |    259 | GPU
DEBUG 01-05 09:59:09.075376.075376 lmp.py:376]   Expert  3 |    266 | GPU
DEBUG 01-05 09:59:09.075397.075397 lmp.py:376]   Expert 41 |    266 | GPU
DEBUG 01-05 09:59:09.075656.075656 lmp.py:376]   Expert 25 |    281 | GPU
DEBUG 01-05 09:59:09.075153.075153 lmp.py:376]   Expert 61 |    282 | GPU
DEBUG 01-05 09:59:09.075412.075412 lmp.py:376]   Expert 26 |    284 | GPU
DEBUG 01-05 09:59:09.075909.075909 lmp.py:376]   Expert 63 |    291 | GPU
DEBUG 01-05 09:59:09.075168.075168 lmp.py:376]   Expert 28 |    343 | GPU
DEBUG 01-05 09:59:09.075426.075426 lmp.py:376]   Expert 40 |    367 | GPU
DEBUG 01-05 09:59:09.075924.075924 lmp.py:376]   Expert 49 |    368 | GPU
DEBUG 01-05 09:59:09.075944.075944 lmp.py:376]   Expert 30 |    373 | GPU
DEBUG 01-05 09:59:09.075203.075203 lmp.py:376]   Expert 58 |    374 | GPU
DEBUG 01-05 09:59:09.075223.075223 lmp.py:376]   Expert  7 |    381 | GPU
DEBUG 01-05 09:59:09.075912.075912 lmp.py:376]   Expert 29 |    391 | GPU
DEBUG 01-05 09:59:09.075747.075747 lmp.py:376]   Expert  9 |    409 | GPU
DEBUG 01-05 09:59:09.075675.075675 lmp.py:376]   Expert 54 |    415 | GPU
DEBUG 01-05 09:59:09.075795.075795 lmp.py:376]   Expert  1 |    446 | GPU
DEBUG 01-05 09:59:09.075484.075484 lmp.py:376]   Expert 17 |    462 | GPU
DEBUG 01-05 09:59:09.076935.076935 lmp.py:376]   Expert 60 |    565 | GPU
DEBUG 01-05 09:59:09.076909.076909 lmp.py:376]   Expert 19 |    670 | GPU
DEBUG 01-05 09:59:09.076837.076837 lmp.py:377] 
DEBUG 01-05 09:59:09.076837.076837 lmp.py:377]   CPU total tokens: 2490 (20.3%)
DEBUG 01-05 09:59:09.076003.076003 lmp.py:378]   GPU total tokens: 9798 (79.7%)
DEBUG 01-05 09:59:09.076938.076938 cuda_h.py:19] end experts_map_get cost 0.001485586166381836 seconds
DEBUG 01-05 09:59:09.076581.076581 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:09.076503.076503 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:09.076176.076176 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:09.078097.078097 cuda_h.py:19] end allocate_cuda_memory cost 0.0019350051879882812 seconds
DEBUG 01-05 09:59:09.078847.078847 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:09.078101.078101 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:09.078294.078294 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:09.078897.078897 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 248178ba-c30a-4678-a2b8-533172ff22f1
DEBUG 01-05 09:59:09.078480.078480 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:09.078060.078060 client.py:127] Model loaded
DEBUG 01-05 09:59:09.079586.079586 cuda_h.py:19] end sllm_worker_task cost 0.011642217636108398 seconds
INFO 01-05 09:59:09.079360.079360 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 248178ba-c30a-4678-a2b8-533172ff22f1
DEBUG 01-05 09:59:09.079634.079634 cuda_h.py:19] end load_into_gpu_async cost 0.0014791488647460938 seconds
DEBUG 01-05 09:59:09.079191.079191 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:09.080851.080851 cuda_h.py:19] end restore_tensors2 cost 0.00032138824462890625 seconds
DEBUG 01-05 09:59:09.080575.080575 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004100799560546875 seconds
DEBUG 01-05 09:59:09.082538.082538 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0068242549896240234 seconds
DEBUG 01-05 09:59:09.082414.082414 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:09.083092.083092 lmp.py:423] 
DEBUG 01-05 09:59:09.083092.083092 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:09.083128.083128 cuda_h.py:19] end cpu_experts_submit cost 0.00011157989501953125 seconds
DEBUG 01-05 09:59:09.083493.083493 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:09.092410.092410 mlpmodule.py:704] group tensors cost 0.008992910385131836 s
DEBUG 01-05 09:59:09.094408.094408 mlpmodule.py:742] pad cost 0.0016245841979980469 s
DEBUG 01-05 09:59:09.094312.094312 mlpmodule.py:748] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-05 09:59:09.094428.094428 mlpmodule.py:753] move to cpu cost 4.9114227294921875e-05 s
DEBUG 01-05 09:59:09.104273.104273 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:09.104473.104473 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:09.105138.105138 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 09:59:09.105275.105275 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:09.121739.121739 mlpmodule.py:793] group einsum cost 0.026613473892211914 s
DEBUG 01-05 09:59:09.122233.122233 mlpmodule.py:801] cpy2cputensor cost 0.0006437301635742188 s
DEBUG 01-05 09:59:09.127364.127364 cuda_h.py:19] end wait_cetm_experts cost 0.04435110092163086 seconds
DEBUG 01-05 09:59:09.127906.127906 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:09.128278.128278 cuda_h.py:19] end gpu_sexperts cost 0.0005803108215332031 seconds
DEBUG 01-05 09:59:09.128380.128380 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:09.128813.128813 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 09:59:09.128423.128423 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:09.128609.128609 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 248178ba-c30a-4678-a2b8-533172ff22f1
INFO 01-05 09:59:09.135683.135683 client.py:127] Model loaded
DEBUG 01-05 09:59:09.135811.135811 cuda_h.py:19] end wait_experts cost 0.006821632385253906 seconds
DEBUG 01-05 09:59:09.135991.135991 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:09.135316.135316 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:09.136181.136181 mlpmodule.py:531] gpu group tensors cost 0.0006239414215087891 s
DEBUG 01-05 09:59:09.137596.137596 mlpmodule.py:564] gpu pad cost 0.0016560554504394531 s
DEBUG 01-05 09:59:09.138429.138429 mlpmodule.py:582] gpu group einsum cost 0.0006744861602783203 s
DEBUG 01-05 09:59:09.141335.141335 mlpmodule.py:611] gpu experts func einsum cost 0.006003856658935547 s
DEBUG 01-05 09:59:09.141663.141663 cuda_h.py:19] end gpu_experts cost 0.00619053840637207 seconds
DEBUG 01-05 09:59:09.141341.141341 cuda_h.py:19] end layer_moe_generate_25 cost 0.06786942481994629 seconds
DEBUG 01-05 09:59:09.141685.141685 lmp.py:217] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 09:59:09.141825.141825 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 09:59:09.141567.141567 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:59:09.141654.141654 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:59:09.142299.142299 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.86102294921875e-05 seconds
DEBUG 01-05 09:59:09.142332.142332 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.7220458984375e-05 seconds
DEBUG 01-05 09:59:09.142406.142406 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:09.142237.142237 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:09.142484.142484 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:09.142029.142029 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:09.144140.144140 cuda_h.py:19] end allocate_cuda_memory cost 0.0016684532165527344 seconds
DEBUG 01-05 09:59:09.144709.144709 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:09.144348.144348 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:09.144049.144049 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:09.144044.144044 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 223bb565-c4dd-4a1b-82a0-341ca769b757
DEBUG 01-05 09:59:09.144914.144914 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:09.144352.144352 mlpmodule.py:662]  experts func einsum cost 0.061448097229003906 s
DEBUG 01-05 09:59:09.145855.145855 cuda_h.py:10] start self_attn
INFO 01-05 09:59:09.145448.145448 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 223bb565-c4dd-4a1b-82a0-341ca769b757
DEBUG 01-05 09:59:09.145385.145385 cuda_h.py:19] end load_into_gpu_async cost 0.0013074874877929688 seconds
DEBUG 01-05 09:59:09.145956.145956 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:09.145628.145628 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-05 09:59:09.145372.145372 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035371780395507812 seconds
INFO 01-05 09:59:09.146843.146843 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 223bb565-c4dd-4a1b-82a0-341ca769b757
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:09.149455.149455 cuda_h.py:19] end self_attn cost 0.003950834274291992 seconds
DEBUG 01-05 09:59:09.149173.149173 cuda_h.py:19] end iln_self_attn_paln cost 0.0074541568756103516 seconds
DEBUG 01-05 09:59:09.149870.149870 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 09:59:09.149918.149918 cuda_h.py:10] start gate
DEBUG 01-05 09:59:09.150013.150013 cuda_h.py:19] end gate cost 0.0006341934204101562 seconds
DEBUG 01-05 09:59:09.150174.150174 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:09.150965.150965 lmp.py:365] 
DEBUG 01-05 09:59:09.150965.150965 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:09.150244.150244 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:09.150656.150656 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:09.150444.150444 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:09.150611.150611 lmp.py:369] 
DEBUG 01-05 09:59:09.150611.150611 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:09.150777.150777 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:09.150711.150711 lmp.py:376]   Expert 62 |      6 | CPU
DEBUG 01-05 09:59:09.150877.150877 lmp.py:376]   Expert 30 |     25 | CPU
DEBUG 01-05 09:59:09.150567.150567 lmp.py:376]   Expert 22 |     28 | CPU
DEBUG 01-05 09:59:09.150779.150779 lmp.py:376]   Expert  3 |     29 | CPU
DEBUG 01-05 09:59:09.150853.150853 lmp.py:376]   Expert  7 |     31 | CPU
DEBUG 01-05 09:59:09.150304.150304 lmp.py:376]   Expert 17 |     36 | CPU
DEBUG 01-05 09:59:09.150470.150470 lmp.py:376]   Expert 15 |     46 | CPU
DEBUG 01-05 09:59:09.150682.150682 lmp.py:376]   Expert 49 |     47 | CPU
DEBUG 01-05 09:59:09.150895.150895 lmp.py:376]   Expert 58 |     52 | CPU
DEBUG 01-05 09:59:09.150630.150630 lmp.py:376]   Expert 27 |     67 | CPU
DEBUG 01-05 09:59:09.150127.150127 lmp.py:376]   Expert 12 |     75 | CPU
DEBUG 01-05 09:59:09.150863.150863 lmp.py:376]   Expert 34 |     81 | CPU
DEBUG 01-05 09:59:09.151360.151360 lmp.py:376]   Expert 53 |     81 | CPU
DEBUG 01-05 09:59:09.151096.151096 lmp.py:376]   Expert 24 |     84 | CPU
DEBUG 01-05 09:59:09.151832.151832 lmp.py:376]   Expert  6 |     89 | CPU
DEBUG 01-05 09:59:09.151567.151567 lmp.py:376]   Expert 21 |     90 | CPU
DEBUG 01-05 09:59:09.151064.151064 lmp.py:376]   Expert  8 |     91 | CPU
DEBUG 01-05 09:59:09.151992.151992 lmp.py:376]   Expert 56 |     91 | CPU
DEBUG 01-05 09:59:09.151966.151966 lmp.py:376]   Expert 59 |     91 | CPU
DEBUG 01-05 09:59:09.151463.151463 lmp.py:376]   Expert 61 |     92 | CPU
DEBUG 01-05 09:59:09.151199.151199 lmp.py:376]   Expert 29 |     96 | CPU
DEBUG 01-05 09:59:09.151458.151458 lmp.py:376]   Expert 51 |     96 | CPU
DEBUG 01-05 09:59:09.151193.151193 lmp.py:376]   Expert 43 |     98 | CPU
DEBUG 01-05 09:59:09.151691.151691 lmp.py:376]   Expert 11 |    101 | CPU
DEBUG 01-05 09:59:09.151426.151426 lmp.py:376]   Expert 13 |    110 | CPU
DEBUG 01-05 09:59:09.151685.151685 lmp.py:376]   Expert 38 |    110 | CPU
DEBUG 01-05 09:59:09.151182.151182 lmp.py:376]   Expert 57 |    120 | CPU
DEBUG 01-05 09:59:09.151918.151918 lmp.py:376]   Expert 26 |    124 | CPU
DEBUG 01-05 09:59:09.151607.151607 lmp.py:376]   Expert 28 |    125 | CPU
DEBUG 01-05 09:59:09.151104.151104 lmp.py:376]   Expert 36 |    126 | CPU
DEBUG 01-05 09:59:09.151078.151078 lmp.py:376]   Expert  0 |    129 | CPU
DEBUG 01-05 09:59:09.151814.151814 lmp.py:376]   Expert 41 |    129 | CPU
DEBUG 01-05 09:59:09.151788.151788 lmp.py:376]   Expert 54 |    133 | GPU
DEBUG 01-05 09:59:09.151047.151047 lmp.py:376]   Expert 20 |    137 | GPU
DEBUG 01-05 09:59:09.151021.151021 lmp.py:376]   Expert  9 |    144 | GPU
DEBUG 01-05 09:59:09.151280.151280 lmp.py:376]   Expert 60 |    152 | GPU
DEBUG 01-05 09:59:09.151731.151731 lmp.py:376]   Expert 32 |    154 | GPU
DEBUG 01-05 09:59:09.151181.151181 lmp.py:376]   Expert 47 |    154 | GPU
DEBUG 01-05 09:59:09.151917.151917 lmp.py:376]   Expert 45 |    162 | GPU
DEBUG 01-05 09:59:09.151414.151414 lmp.py:376]   Expert  1 |    163 | GPU
DEBUG 01-05 09:59:09.151911.151911 lmp.py:376]   Expert 42 |    168 | GPU
DEBUG 01-05 09:59:09.151409.151409 lmp.py:376]   Expert 23 |    169 | GPU
DEBUG 01-05 09:59:09.151429.151429 lmp.py:376]   Expert 19 |    178 | GPU
DEBUG 01-05 09:59:09.151926.151926 lmp.py:376]   Expert 55 |    198 | GPU
DEBUG 01-05 09:59:09.151185.151185 lmp.py:376]   Expert 44 |    199 | GPU
DEBUG 01-05 09:59:09.151444.151444 lmp.py:376]   Expert 37 |    231 | GPU
DEBUG 01-05 09:59:09.151418.151418 lmp.py:376]   Expert  5 |    243 | GPU
DEBUG 01-05 09:59:09.151929.151929 lmp.py:376]   Expert 39 |    250 | GPU
DEBUG 01-05 09:59:09.151380.151380 lmp.py:376]   Expert 10 |    255 | GPU
DEBUG 01-05 09:59:09.151638.151638 lmp.py:376]   Expert 16 |    266 | GPU
DEBUG 01-05 09:59:09.151374.151374 lmp.py:376]   Expert 48 |    270 | GPU
DEBUG 01-05 09:59:09.151633.151633 lmp.py:376]   Expert  2 |    276 | GPU
DEBUG 01-05 09:59:09.151130.151130 lmp.py:376]   Expert  4 |    276 | GPU
DEBUG 01-05 09:59:09.151389.151389 lmp.py:376]   Expert 25 |    276 | GPU
DEBUG 01-05 09:59:09.151124.151124 lmp.py:376]   Expert 50 |    276 | GPU
DEBUG 01-05 09:59:09.151383.151383 lmp.py:376]   Expert 33 |    283 | GPU
DEBUG 01-05 09:59:09.151357.151357 lmp.py:376]   Expert 31 |    284 | GPU
DEBUG 01-05 09:59:09.151570.151570 lmp.py:376]   Expert 18 |    287 | GPU
DEBUG 01-05 09:59:09.151782.151782 lmp.py:376]   Expert 63 |    329 | GPU
DEBUG 01-05 09:59:09.151802.151802 lmp.py:376]   Expert 35 |    457 | GPU
DEBUG 01-05 09:59:09.151061.151061 lmp.py:376]   Expert 40 |    554 | GPU
DEBUG 01-05 09:59:09.151320.151320 lmp.py:376]   Expert 46 |    647 | GPU
DEBUG 01-05 09:59:09.151817.151817 lmp.py:376]   Expert 52 |    848 | GPU
DEBUG 01-05 09:59:09.151076.151076 lmp.py:376]   Expert 14 |   1273 | GPU
DEBUG 01-05 09:59:09.151527.151527 lmp.py:377] 
DEBUG 01-05 09:59:09.151527.151527 lmp.py:377]   CPU total tokens: 2596 (21.1%)
DEBUG 01-05 09:59:09.151978.151978 lmp.py:378]   GPU total tokens: 9692 (78.9%)
DEBUG 01-05 09:59:09.151482.151482 cuda_h.py:19] end experts_map_get cost 0.001463174819946289 seconds
DEBUG 01-05 09:59:09.151840.151840 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:09.151239.151239 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:09.152621.152621 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:09.152349.152349 cuda_h.py:19] end allocate_cuda_memory cost 0.00032591819763183594 seconds
DEBUG 01-05 09:59:09.152907.152907 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:09.152663.152663 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:09.152532.152532 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:09.152851.152851 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54593270-a963-4bbb-b01f-7e7b8038026c
DEBUG 01-05 09:59:09.152850.152850 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:09.153116.153116 client.py:127] Model loaded
DEBUG 01-05 09:59:09.153695.153695 cuda_h.py:19] end sllm_worker_task cost 0.010831356048583984 seconds
INFO 01-05 09:59:09.153119.153119 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54593270-a963-4bbb-b01f-7e7b8038026c
DEBUG 01-05 09:59:09.153439.153439 cuda_h.py:19] end load_into_gpu_async cost 0.0014119148254394531 seconds
DEBUG 01-05 09:59:09.153142.153142 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:09.154430.154430 cuda_h.py:19] end restore_tensors2 cost 0.00029206275939941406 seconds
DEBUG 01-05 09:59:09.154154.154154 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023717880249023438 seconds
DEBUG 01-05 09:59:09.157678.157678 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005224466323852539 seconds
DEBUG 01-05 09:59:09.157707.157707 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:09.157193.157193 lmp.py:423] 
DEBUG 01-05 09:59:09.157193.157193 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:09.157089.157089 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 09:59:09.157931.157931 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:09.174909.174909 mlpmodule.py:704] group tensors cost 0.01647663116455078 s
DEBUG 01-05 09:59:09.177695.177695 mlpmodule.py:742] pad cost 0.0021886825561523438 s
DEBUG 01-05 09:59:09.177024.177024 mlpmodule.py:748] create cpu tensor cost 5.817413330078125e-05 s
DEBUG 01-05 09:59:09.177862.177862 mlpmodule.py:753] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-05 09:59:09.186521.186521 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:09.186779.186779 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:09.186723.186723 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 09:59:09.187508.187508 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:09.203247.203247 mlpmodule.py:793] group einsum cost 0.025856971740722656 s
DEBUG 01-05 09:59:09.203048.203048 mlpmodule.py:801] cpy2cputensor cost 0.0005481243133544922 s
DEBUG 01-05 09:59:09.208612.208612 cuda_h.py:19] end wait_cetm_experts cost 0.05112910270690918 seconds
DEBUG 01-05 09:59:09.208114.208114 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:09.209486.209486 cuda_h.py:19] end gpu_sexperts cost 0.0005822181701660156 seconds
DEBUG 01-05 09:59:09.209329.209329 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:09.209994.209994 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 09:59:09.209081.209081 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:09.209744.209744 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54593270-a963-4bbb-b01f-7e7b8038026c
INFO 01-05 09:59:09.210416.210416 client.py:127] Model loaded
DEBUG 01-05 09:59:09.210114.210114 cuda_h.py:19] end wait_experts cost 0.00115203857421875 seconds
DEBUG 01-05 09:59:09.210532.210532 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:09.210102.210102 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:09.211960.211960 mlpmodule.py:531] gpu group tensors cost 0.0006163120269775391 s
DEBUG 01-05 09:59:09.213903.213903 mlpmodule.py:564] gpu pad cost 0.0017998218536376953 s
DEBUG 01-05 09:59:09.213924.213924 mlpmodule.py:582] gpu group einsum cost 0.0005371570587158203 s
DEBUG 01-05 09:59:09.217750.217750 mlpmodule.py:611] gpu experts func einsum cost 0.006604671478271484 s
DEBUG 01-05 09:59:09.217178.217178 cuda_h.py:19] end gpu_experts cost 0.0067980289459228516 seconds
DEBUG 01-05 09:59:09.217585.217585 cuda_h.py:19] end layer_moe_generate_26 cost 0.06798124313354492 seconds
DEBUG 01-05 09:59:09.217678.217678 lmp.py:217] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 09:59:09.217732.217732 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 09:59:09.217720.217720 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 09:59:09.217443.217443 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.1205673217773438e-05 seconds
DEBUG 01-05 09:59:09.217762.217762 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:09.218421.218421 cuda_h.py:10] start self_attn
DEBUG 01-05 09:59:09.218027.218027 mlpmodule.py:662]  experts func einsum cost 0.06137490272521973 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:09.221255.221255 cuda_h.py:19] end self_attn cost 0.003072977066040039 seconds
DEBUG 01-05 09:59:09.221849.221849 cuda_h.py:19] end iln_self_attn_paln cost 0.0037512779235839844 seconds
DEBUG 01-05 09:59:09.221314.221314 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 09:59:09.221600.221600 cuda_h.py:10] start gate
DEBUG 01-05 09:59:09.222501.222501 cuda_h.py:19] end gate cost 0.0005595684051513672 seconds
DEBUG 01-05 09:59:09.222138.222138 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:09.222903.222903 lmp.py:365] 
DEBUG 01-05 09:59:09.222903.222903 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:09.222844.222844 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:09.222779.222779 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:09.222422.222422 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:09.222396.222396 lmp.py:369] 
DEBUG 01-05 09:59:09.222396.222396 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:09.222085.222085 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:09.222735.222735 lmp.py:376]   Expert 47 |     16 | CPU
DEBUG 01-05 09:59:09.222947.222947 lmp.py:376]   Expert 18 |     20 | CPU
DEBUG 01-05 09:59:09.222683.222683 lmp.py:376]   Expert 58 |     43 | CPU
DEBUG 01-05 09:59:09.222465.222465 lmp.py:376]   Expert 24 |     53 | CPU
DEBUG 01-05 09:59:09.222724.222724 lmp.py:376]   Expert 50 |     60 | CPU
DEBUG 01-05 09:59:09.222506.222506 lmp.py:376]   Expert 59 |     62 | CPU
DEBUG 01-05 09:59:09.222811.222811 lmp.py:376]   Expert 32 |     70 | CPU
DEBUG 01-05 09:59:09.223593.223593 lmp.py:376]   Expert 51 |     71 | CPU
DEBUG 01-05 09:59:09.223328.223328 lmp.py:376]   Expert 19 |     72 | CPU
DEBUG 01-05 09:59:09.223349.223349 lmp.py:376]   Expert 15 |     73 | CPU
DEBUG 01-05 09:59:09.223846.223846 lmp.py:376]   Expert 40 |     78 | CPU
DEBUG 01-05 09:59:09.223866.223866 lmp.py:376]   Expert 11 |     80 | CPU
DEBUG 01-05 09:59:09.223125.223125 lmp.py:376]   Expert 38 |     85 | CPU
DEBUG 01-05 09:59:09.223145.223145 lmp.py:376]   Expert 52 |     88 | CPU
DEBUG 01-05 09:59:09.223689.223689 lmp.py:376]   Expert 48 |     95 | CPU
DEBUG 01-05 09:59:09.223471.223471 lmp.py:376]   Expert 34 |     98 | CPU
DEBUG 01-05 09:59:09.223253.223253 lmp.py:376]   Expert  7 |    101 | CPU
DEBUG 01-05 09:59:09.223273.223273 lmp.py:376]   Expert 39 |    104 | CPU
DEBUG 01-05 09:59:09.223055.223055 lmp.py:376]   Expert 42 |    104 | CPU
DEBUG 01-05 09:59:09.223599.223599 lmp.py:376]   Expert 29 |    110 | CPU
DEBUG 01-05 09:59:09.223381.223381 lmp.py:376]   Expert 44 |    110 | CPU
DEBUG 01-05 09:59:09.223163.223163 lmp.py:376]   Expert 31 |    115 | CPU
DEBUG 01-05 09:59:09.223183.223183 lmp.py:376]   Expert  8 |    119 | CPU
DEBUG 01-05 09:59:09.223442.223442 lmp.py:376]   Expert 54 |    119 | CPU
DEBUG 01-05 09:59:09.223939.223939 lmp.py:376]   Expert 12 |    122 | CPU
DEBUG 01-05 09:59:09.223959.223959 lmp.py:376]   Expert 46 |    123 | CPU
DEBUG 01-05 09:59:09.223741.223741 lmp.py:376]   Expert  6 |    124 | CPU
DEBUG 01-05 09:59:09.223523.223523 lmp.py:376]   Expert 61 |    127 | CPU
DEBUG 01-05 09:59:09.223067.223067 lmp.py:376]   Expert 25 |    137 | CPU
DEBUG 01-05 09:59:09.223610.223610 lmp.py:376]   Expert 53 |    142 | CPU
DEBUG 01-05 09:59:09.223154.223154 lmp.py:376]   Expert 23 |    147 | CPU
DEBUG 01-05 09:59:09.223697.223697 lmp.py:376]   Expert 22 |    151 | CPU
DEBUG 01-05 09:59:09.223479.223479 lmp.py:376]   Expert 45 |    163 | GPU
DEBUG 01-05 09:59:09.223784.223784 lmp.py:376]   Expert  4 |    173 | GPU
DEBUG 01-05 09:59:09.223090.223090 lmp.py:376]   Expert 36 |    175 | GPU
DEBUG 01-05 09:59:09.223633.223633 lmp.py:376]   Expert 13 |    177 | GPU
DEBUG 01-05 09:59:09.223415.223415 lmp.py:376]   Expert  1 |    180 | GPU
DEBUG 01-05 09:59:09.223674.223674 lmp.py:376]   Expert 49 |    181 | GPU
DEBUG 01-05 09:59:09.223933.223933 lmp.py:376]   Expert 16 |    182 | GPU
DEBUG 01-05 09:59:09.223715.223715 lmp.py:376]   Expert 10 |    186 | GPU
DEBUG 01-05 09:59:09.223212.223212 lmp.py:376]   Expert 56 |    186 | GPU
DEBUG 01-05 09:59:09.223755.223755 lmp.py:376]   Expert 17 |    203 | GPU
DEBUG 01-05 09:59:09.223060.223060 lmp.py:376]   Expert 33 |    210 | GPU
DEBUG 01-05 09:59:09.223365.223365 lmp.py:376]   Expert 26 |    219 | GPU
DEBUG 01-05 09:59:09.223147.223147 lmp.py:376]   Expert 41 |    221 | GPU
DEBUG 01-05 09:59:09.223691.223691 lmp.py:376]   Expert 57 |    223 | GPU
DEBUG 01-05 09:59:09.223235.223235 lmp.py:376]   Expert  3 |    224 | GPU
DEBUG 01-05 09:59:09.223778.223778 lmp.py:376]   Expert 62 |    232 | GPU
DEBUG 01-05 09:59:09.223322.223322 lmp.py:376]   Expert 30 |    242 | GPU
DEBUG 01-05 09:59:09.223580.223580 lmp.py:376]   Expert 55 |    243 | GPU
DEBUG 01-05 09:59:09.223554.223554 lmp.py:376]   Expert  5 |    261 | GPU
DEBUG 01-05 09:59:09.223052.223052 lmp.py:376]   Expert 37 |    272 | GPU
DEBUG 01-05 09:59:09.223549.223549 lmp.py:376]   Expert 35 |    279 | GPU
DEBUG 01-05 09:59:09.223046.223046 lmp.py:376]   Expert  0 |    321 | GPU
DEBUG 01-05 09:59:09.223305.223305 lmp.py:376]   Expert 21 |    342 | GPU
DEBUG 01-05 09:59:09.223325.223325 lmp.py:376]   Expert  2 |    350 | GPU
DEBUG 01-05 09:59:09.223584.223584 lmp.py:376]   Expert 43 |    361 | GPU
DEBUG 01-05 09:59:09.223128.223128 lmp.py:376]   Expert 60 |    380 | GPU
DEBUG 01-05 09:59:09.223671.223671 lmp.py:376]   Expert 28 |    394 | GPU
DEBUG 01-05 09:59:09.223976.223976 lmp.py:376]   Expert 63 |    436 | GPU
DEBUG 01-05 09:59:09.223281.223281 lmp.py:376]   Expert 27 |    491 | GPU
DEBUG 01-05 09:59:09.223825.223825 lmp.py:376]   Expert 14 |    499 | GPU
DEBUG 01-05 09:59:09.223130.223130 lmp.py:376]   Expert 20 |    563 | GPU
DEBUG 01-05 09:59:09.223673.223673 lmp.py:376]   Expert  9 |    700 | GPU
DEBUG 01-05 09:59:09.223694.223694 lmp.py:377] 
DEBUG 01-05 09:59:09.223694.223694 lmp.py:377]   CPU total tokens: 3019 (24.6%)
DEBUG 01-05 09:59:09.223429.223429 lmp.py:378]   GPU total tokens: 9269 (75.4%)
DEBUG 01-05 09:59:09.223457.223457 cuda_h.py:19] end experts_map_get cost 0.0013670921325683594 seconds
DEBUG 01-05 09:59:09.223908.223908 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:09.223445.223445 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:09.224298.224298 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:09.224866.224866 cuda_h.py:19] end allocate_cuda_memory cost 0.0003147125244140625 seconds
DEBUG 01-05 09:59:09.224192.224192 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:09.224995.224995 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:09.224380.224380 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:09.224222.224222 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c472ce8c-3fe1-4c77-a90b-a39dd0bfb656
DEBUG 01-05 09:59:09.224089.224089 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:09.226103.226103 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c472ce8c-3fe1-4c77-a90b-a39dd0bfb656
DEBUG 01-05 09:59:09.226525.226525 cuda_h.py:19] end load_into_gpu_async cost 0.0017774105072021484 seconds
DEBUG 01-05 09:59:09.226196.226196 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:09.226424.226424 cuda_h.py:19] end restore_tensors2 cost 0.0004220008850097656 seconds
DEBUG 01-05 09:59:09.226016.226016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029616355895996094 seconds
DEBUG 01-05 09:59:09.229253.229253 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005741119384765625 seconds
DEBUG 01-05 09:59:09.229321.229321 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:09.229251.229251 lmp.py:423] 
DEBUG 01-05 09:59:09.229251.229251 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:09.229909.229909 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-05 09:59:09.229751.229751 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:09.240185.240185 mlpmodule.py:704] group tensors cost 0.010782003402709961 s
DEBUG 01-05 09:59:09.243887.243887 mlpmodule.py:742] pad cost 0.001638174057006836 s
DEBUG 01-05 09:59:09.243957.243957 mlpmodule.py:748] create cpu tensor cost 5.555152893066406e-05 s
DEBUG 01-05 09:59:09.243768.243768 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 09:59:09.252332.252332 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:09.252352.252352 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:09.252580.252580 mlpmodule.py:773] group_w3 first element: -0.000606536865234375
WARNING 01-05 09:59:09.252426.252426 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:09.269396.269396 mlpmodule.py:793] group einsum cost 0.02579784393310547 s
DEBUG 01-05 09:59:09.270305.270305 mlpmodule.py:801] cpy2cputensor cost 0.0006427764892578125 s
DEBUG 01-05 09:59:09.274993.274993 cuda_h.py:19] end wait_cetm_experts cost 0.044728994369506836 seconds
DEBUG 01-05 09:59:09.274826.274826 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:09.275853.275853 cuda_h.py:19] end gpu_sexperts cost 0.0005750656127929688 seconds
DEBUG 01-05 09:59:09.275742.275742 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:09.275526.275526 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1920928955078125e-05 seconds
DEBUG 01-05 09:59:09.275944.275944 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:09.275130.275130 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c472ce8c-3fe1-4c77-a90b-a39dd0bfb656
INFO 01-05 09:59:09.281466.281466 client.py:127] Model loaded
DEBUG 01-05 09:59:09.281700.281700 cuda_h.py:19] end wait_experts cost 0.0059337615966796875 seconds
DEBUG 01-05 09:59:09.281310.281310 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:09.281589.281589 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:09.282852.282852 mlpmodule.py:531] gpu group tensors cost 0.0006287097930908203 s
DEBUG 01-05 09:59:09.284780.284780 mlpmodule.py:564] gpu pad cost 0.0017495155334472656 s
DEBUG 01-05 09:59:09.284630.284630 mlpmodule.py:582] gpu group einsum cost 0.0005855560302734375 s
DEBUG 01-05 09:59:09.285910.285910 mlpmodule.py:662]  experts func einsum cost 0.055411577224731445 s
DEBUG 01-05 09:59:09.287092.287092 mlpmodule.py:611] gpu experts func einsum cost 0.006207466125488281 s
DEBUG 01-05 09:59:09.288215.288215 cuda_h.py:19] end gpu_experts cost 0.006432771682739258 seconds
DEBUG 01-05 09:59:09.288085.288085 cuda_h.py:19] end layer_moe_generate_27 cost 0.06630373001098633 seconds
DEBUG 01-05 09:59:09.288971.288971 lmp.py:217] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 09:59:09.288026.288026 cuda_h.py:19] end multi_layer cost 2.523679494857788 seconds
DEBUG 01-05 09:59:09.288305.288305 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:59:09.341102.341102 cuda_h.py:19] end init_inputs_tokens cost 0.05300712585449219 seconds
DEBUG 01-05 09:59:09.341973.341973 lmp.py:286] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:59:09.341345.341345 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:59:09.344197.344197 lmp.py:289] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:59:09.344477.344477 cuda_h.py:19] end dense_mlp cost 0.002526521682739258 seconds
INFO 01-05 09:59:09.344076.344076 lmp.py:522] 
INFO 01-05 09:59:09.344076.344076 lmp.py:522] ============================================================
INFO 01-05 09:59:09.344985.344985 lmp.py:523] Layer 1 Expert Device Distribution:
INFO 01-05 09:59:09.344840.344840 lmp.py:532]   Total experts: 64
INFO 01-05 09:59:09.344304.344304 lmp.py:534]   cuda:1: 32 experts - Expert IDs: [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 19, 20, 23, 26, 33, 34, 35, 40, 42, 43, 44, 45, 46, 52, 57, 60, 61, 63]
INFO 01-05 09:59:09.344285.344285 lmp.py:534]   meta: 32 experts - Expert IDs: [3, 11, 12, 13, 18, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 41, 47, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 62]
INFO 01-05 09:59:09.344213.344213 lmp.py:537] 
INFO 01-05 09:59:09.344213.344213 lmp.py:537]   Detailed Expert Device Map:
INFO 01-05 09:59:09.344571.344571 lmp.py:538]   Expert ID  | Device         
INFO 01-05 09:59:09.344545.344545 lmp.py:539]   ------------------------------
INFO 01-05 09:59:09.344619.344619 lmp.py:542]   0          | cuda:1         
INFO 01-05 09:59:09.344023.344023 lmp.py:542]   1          | cuda:1         
INFO 01-05 09:59:09.344997.344997 lmp.py:542]   2          | cuda:1         
INFO 01-05 09:59:09.344210.344210 lmp.py:542]   3          | meta           
INFO 01-05 09:59:09.344707.344707 lmp.py:542]   4          | cuda:1         
INFO 01-05 09:59:09.344727.344727 lmp.py:542]   5          | cuda:1         
INFO 01-05 09:59:09.344271.344271 lmp.py:542]   6          | cuda:1         
INFO 01-05 09:59:09.344291.344291 lmp.py:542]   7          | cuda:1         
INFO 01-05 09:59:09.344835.344835 lmp.py:542]   8          | cuda:1         
INFO 01-05 09:59:09.344140.344140 lmp.py:542]   9          | cuda:1         
INFO 01-05 09:59:09.344922.344922 lmp.py:542]   10         | cuda:1         
INFO 01-05 09:59:09.345704.345704 lmp.py:542]   11         | meta           
INFO 01-05 09:59:09.345486.345486 lmp.py:542]   12         | meta           
INFO 01-05 09:59:09.345029.345029 lmp.py:542]   13         | meta           
INFO 01-05 09:59:09.345811.345811 lmp.py:542]   14         | cuda:1         
INFO 01-05 09:59:09.345024.345024 lmp.py:542]   15         | cuda:1         
INFO 01-05 09:59:09.345806.345806 lmp.py:542]   16         | cuda:1         
INFO 01-05 09:59:09.345018.345018 lmp.py:542]   17         | cuda:1         
INFO 01-05 09:59:09.345800.345800 lmp.py:542]   18         | meta           
INFO 01-05 09:59:09.345251.345251 lmp.py:542]   19         | cuda:1         
INFO 01-05 09:59:09.345033.345033 lmp.py:542]   20         | cuda:1         
INFO 01-05 09:59:09.345576.345576 lmp.py:542]   21         | meta           
INFO 01-05 09:59:09.345358.345358 lmp.py:542]   22         | meta           
INFO 01-05 09:59:09.345902.345902 lmp.py:542]   23         | cuda:1         
INFO 01-05 09:59:09.345207.345207 lmp.py:542]   24         | meta           
INFO 01-05 09:59:09.345751.345751 lmp.py:542]   25         | meta           
INFO 01-05 09:59:09.345056.345056 lmp.py:542]   26         | cuda:1         
INFO 01-05 09:59:09.345361.345361 lmp.py:542]   27         | meta           
INFO 01-05 09:59:09.345381.345381 lmp.py:542]   28         | meta           
INFO 01-05 09:59:09.345925.345925 lmp.py:542]   29         | meta           
INFO 01-05 09:59:09.345468.345468 lmp.py:542]   30         | meta           
INFO 01-05 09:59:09.345012.345012 lmp.py:542]   31         | meta           
INFO 01-05 09:59:09.345794.345794 lmp.py:542]   32         | meta           
INFO 01-05 09:59:09.345914.345914 lmp.py:542]   33         | cuda:1         
INFO 01-05 09:59:09.345510.345510 lmp.py:542]   34         | cuda:1         
INFO 01-05 09:59:09.345107.345107 lmp.py:542]   35         | cuda:1         
INFO 01-05 09:59:09.345319.345319 lmp.py:542]   36         | meta           
INFO 01-05 09:59:09.345770.345770 lmp.py:542]   37         | meta           
INFO 01-05 09:59:09.345791.345791 lmp.py:542]   38         | meta           
INFO 01-05 09:59:09.345334.345334 lmp.py:542]   39         | meta           
INFO 01-05 09:59:09.345116.345116 lmp.py:542]   40         | cuda:1         
INFO 01-05 09:59:09.345898.345898 lmp.py:542]   41         | meta           
INFO 01-05 09:59:09.345442.345442 lmp.py:542]   42         | cuda:1         
INFO 01-05 09:59:09.345985.345985 lmp.py:542]   43         | cuda:1         
INFO 01-05 09:59:09.345529.345529 lmp.py:542]   44         | cuda:1         
INFO 01-05 09:59:09.345549.345549 lmp.py:542]   45         | cuda:1         
INFO 01-05 09:59:09.345093.345093 lmp.py:542]   46         | cuda:1         
INFO 01-05 09:59:09.345874.345874 lmp.py:542]   47         | meta           
INFO 01-05 09:59:09.345418.345418 lmp.py:542]   48         | meta           
INFO 01-05 09:59:09.345438.345438 lmp.py:542]   49         | meta           
INFO 01-05 09:59:09.345743.345743 lmp.py:542]   50         | meta           
INFO 01-05 09:59:09.345863.345863 lmp.py:542]   51         | meta           
INFO 01-05 09:59:09.345745.345745 lmp.py:542]   52         | cuda:1         
INFO 01-05 09:59:09.345527.345527 lmp.py:542]   53         | meta           
INFO 01-05 09:59:09.345739.345739 lmp.py:542]   54         | meta           
INFO 01-05 09:59:09.345521.345521 lmp.py:542]   55         | meta           
INFO 01-05 09:59:09.345065.345065 lmp.py:542]   56         | meta           
INFO 01-05 09:59:09.345608.345608 lmp.py:542]   57         | cuda:1         
INFO 01-05 09:59:09.345152.345152 lmp.py:542]   58         | meta           
INFO 01-05 09:59:09.345695.345695 lmp.py:542]   59         | meta           
INFO 01-05 09:59:09.345762.345762 lmp.py:542]   60         | cuda:1         
INFO 01-05 09:59:09.345305.345305 lmp.py:542]   61         | cuda:1         
INFO 01-05 09:59:09.345849.345849 lmp.py:542]   62         | meta           
INFO 01-05 09:59:09.345154.345154 lmp.py:542]   63         | cuda:1         
INFO 01-05 09:59:09.345698.345698 lmp.py:543] ============================================================
INFO 01-05 09:59:09.345698.345698 lmp.py:543] 
DEBUG 01-05 09:59:09.345579.345579 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 09:59:09.345474.345474 cuda_h.py:10] start gate
DEBUG 01-05 09:59:09.372811.372811 cuda_h.py:19] end gate cost 0.026443004608154297 seconds
DEBUG 01-05 09:59:09.372191.372191 cuda_h.py:10] start experts_map_get
INFO 01-05 09:59:09.372842.372842 lmp.py:607] 
INFO 01-05 09:59:09.372842.372842 lmp.py:607] Layer 1 Expert Device Distribution:
INFO 01-05 09:59:09.372936.372936 lmp.py:608]   Active experts: 46 (out of 64 total)
INFO 01-05 09:59:09.372639.372639 lmp.py:609]   CPU experts: 23 (50%) - Expert IDs: [0, 1, 3, 8, 9, 12, 17, 22, 23, 26, 28, 32, 33, 35, 36, 37, 40, 41, 43, 52, 53, 59, 60]
INFO 01-05 09:59:09.372004.372004 lmp.py:610]   GPU experts: 23 (50%) - Expert IDs: [2, 4, 5, 6, 7, 10, 11, 14, 15, 16, 20, 24, 30, 31, 34, 42, 44, 45, 46, 47, 57, 61, 63]
INFO 01-05 09:59:09.372031.372031 lmp.py:611]   CPU tokens: 46 (24.0%)
INFO 01-05 09:59:09.372674.372674 lmp.py:612]   GPU tokens: 146 (76.0%)
INFO 01-05 09:59:09.372410.372410 lmp.py:613] 
INFO 01-05 09:59:09.372410.372410 lmp.py:613]   Detailed Expert Distribution:
INFO 01-05 09:59:09.372053.372053 lmp.py:614]   Expert ID  | Tokens     | Device       | Token %   
INFO 01-05 09:59:09.372742.372742 lmp.py:615]   --------------------------------------------------
INFO 01-05 09:59:09.372577.372577 lmp.py:619]   3          | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372220.372220 lmp.py:619]   9          | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372624.372624 lmp.py:619]   12         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372029.372029 lmp.py:619]   28         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372387.372387 lmp.py:619]   32         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372553.372553 lmp.py:619]   36         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372720.372720 lmp.py:619]   37         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.372647.372647 lmp.py:619]   41         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.373575.373575 lmp.py:619]   52         | 1          | CPU          |   0.52%
INFO 01-05 09:59:09.373026.373026 lmp.py:619]   0          | 2          | CPU          |   1.04%
INFO 01-05 09:59:09.373192.373192 lmp.py:619]   17         | 2          | CPU          |   1.04%
INFO 01-05 09:59:09.373358.373358 lmp.py:619]   26         | 2          | CPU          |   1.04%
INFO 01-05 09:59:09.373047.373047 lmp.py:619]   40         | 2          | CPU          |   1.04%
INFO 01-05 09:59:09.373737.373737 lmp.py:619]   60         | 2          | CPU          |   1.04%
INFO 01-05 09:59:09.373426.373426 lmp.py:619]   1          | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373638.373638 lmp.py:619]   8          | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373328.373328 lmp.py:619]   22         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373494.373494 lmp.py:619]   23         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373614.373614 lmp.py:619]   33         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373541.373541 lmp.py:619]   35         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373661.373661 lmp.py:619]   43         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373066.373066 lmp.py:619]   53         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373755.373755 lmp.py:619]   59         | 3          | CPU          |   1.56%
INFO 01-05 09:59:09.373398.373398 lmp.py:619]   11         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:09.373041.373041 lmp.py:619]   16         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:09.373207.373207 lmp.py:619]   30         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:09.373135.373135 lmp.py:619]   45         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:09.373824.373824 lmp.py:619]   47         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:09.373752.373752 lmp.py:619]   2          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:09.373680.373680 lmp.py:619]   4          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:09.373846.373846 lmp.py:619]   5          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:09.373204.373204 lmp.py:619]   10         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:09.373708.373708 lmp.py:619]   44         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:09.373113.373113 lmp.py:619]   63         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:09.373756.373756 lmp.py:619]   7          | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:09.373922.373922 lmp.py:619]   15         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:09.373088.373088 lmp.py:619]   42         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:09.373016.373016 lmp.py:619]   61         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:09.373943.373943 lmp.py:619]   6          | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:59:09.373633.373633 lmp.py:619]   46         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:59:09.373560.373560 lmp.py:619]   14         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:59:09.373488.373488 lmp.py:619]   20         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:59:09.373416.373416 lmp.py:619]   31         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:59:09.373582.373582 lmp.py:619]   24         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:59:09.373510.373510 lmp.py:619]   34         | 11         | GPU(cuda:1)  |   5.73%
INFO 01-05 09:59:09.373629.373629 lmp.py:619]   57         | 12         | GPU(cuda:1)  |   6.25%
INFO 01-05 09:59:09.373140.373140 lmp.py:620] ============================================================
INFO 01-05 09:59:09.373140.373140 lmp.py:620] 
DEBUG 01-05 09:59:09.373598.373598 cuda_h.py:19] end experts_map_get cost 0.0012540817260742188 seconds
DEBUG 01-05 09:59:09.373671.373671 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.027857542037963867 seconds
DEBUG 01-05 09:59:10.536053.536053 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09447932243347168 s
DEBUG 01-05 09:59:10.869843.869843 cuda_h.py:19] end generate_input_ids cost 0.3323068618774414 seconds
DEBUG 01-05 09:59:10.869862.869862 cuda_h.py:10] start init_cache
DEBUG 01-05 09:59:10.869799.869799 cuda_h.py:19] end init_cache cost 5.7220458984375e-05 seconds
DEBUG 01-05 09:59:13.306460.306460 cuda_h.py:10] start init_weights
DEBUG 01-05 09:59:13.307514.307514 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:13.307524.307524 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:13.309959.309959 cuda_h.py:19] end allocate_cuda_memory cost 0.002070188522338867 seconds
DEBUG 01-05 09:59:13.309293.309293 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:13.310102.310102 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:13.310567.310567 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:13.310317.310317 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7ef6f5b-1362-47ad-a1a8-ba50c49d5f74
DEBUG 01-05 09:59:13.310293.310293 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:13.312508.312508 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7ef6f5b-1362-47ad-a1a8-ba50c49d5f74
DEBUG 01-05 09:59:13.312414.312414 cuda_h.py:19] end load_into_gpu_async cost 0.0021820068359375 seconds
DEBUG 01-05 09:59:13.312747.312747 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:13.312156.312156 cuda_h.py:19] end restore_tensors2 cost 9.679794311523438e-05 seconds
DEBUG 01-05 09:59:13.312528.312528 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0046885013580322266 seconds
INFO 01-05 09:59:13.312872.312872 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7ef6f5b-1362-47ad-a1a8-ba50c49d5f74
INFO 01-05 09:59:13.392797.392797 client.py:127] Model loaded
DEBUG 01-05 09:59:13.392829.392829 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 09:59:13.392794.392794 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:13.392950.392950 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:13.392263.392263 cuda_h.py:19] end allocate_cuda_memory cost 0.0003523826599121094 seconds
DEBUG 01-05 09:59:13.393645.393645 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:13.393185.393185 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:13.393936.393936 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:13.393409.393409 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f4e41f70-d023-41e2-a217-839591f07c05
DEBUG 01-05 09:59:13.393024.393024 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:13.395454.395454 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f4e41f70-d023-41e2-a217-839591f07c05
DEBUG 01-05 09:59:13.395526.395526 cuda_h.py:19] end load_into_gpu_async cost 0.0020678043365478516 seconds
DEBUG 01-05 09:59:13.395734.395734 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:13.395443.395443 cuda_h.py:19] end restore_tensors2 cost 0.0001285076141357422 seconds
DEBUG 01-05 09:59:13.395611.395611 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003153085708618164 seconds
INFO 01-05 09:59:13.395806.395806 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f4e41f70-d023-41e2-a217-839591f07c05
INFO 01-05 09:59:13.412635.412635 client.py:127] Model loaded
DEBUG 01-05 09:59:13.413378.413378 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02104973793029785 seconds
DEBUG 01-05 09:59:13.413118.413118 cuda_h.py:19] end init_weights cost 0.10585975646972656 seconds
DEBUG 01-05 09:59:13.413458.413458 cuda_h.py:10] start copy_emodel
DEBUG 01-05 09:59:14.181309.181309 cuda_h.py:19] end copy_emodel cost 0.7675876617431641 seconds
DEBUG 01-05 09:59:14.182884.182884 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:59:14.182611.182611 cuda_h.py:19] end init_inputs_tokens cost 0.0002989768981933594 seconds
DEBUG 01-05 09:59:14.182825.182825 cuda_h.py:10] start multi_layer
DEBUG 01-05 09:59:14.182396.182396 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 09:59:14.182138.182138 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:14.182503.182503 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:14.182916.182916 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.218650817871094e-05 seconds
DEBUG 01-05 09:59:14.182593.182593 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:59:14.182005.182005 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.182603.182603 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.182018.182018 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.183155.183155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.183904.183904 cuda_h.py:19] end allocate_cuda_memory cost 0.00036525726318359375 seconds
DEBUG 01-05 09:59:14.183805.183805 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.183720.183720 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.183219.183219 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.183856.183856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1538a760-bb26-4427-b9d6-995297d33cd9
DEBUG 01-05 09:59:14.183860.183860 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.184506.184506 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.185500.185500 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1538a760-bb26-4427-b9d6-995297d33cd9
DEBUG 01-05 09:59:14.185900.185900 cuda_h.py:19] end load_into_gpu_async cost 0.001987934112548828 seconds
DEBUG 01-05 09:59:14.185669.185669 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.185442.185442 cuda_h.py:19] end restore_tensors2 cost 9.131431579589844e-05 seconds
DEBUG 01-05 09:59:14.185147.185147 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029273033142089844 seconds
INFO 01-05 09:59:14.186050.186050 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1538a760-bb26-4427-b9d6-995297d33cd9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.188637.188637 cuda_h.py:19] end self_attn cost 0.004243612289428711 seconds
DEBUG 01-05 09:59:14.189304.189304 cuda_h.py:19] end iln_self_attn_paln cost 0.006508827209472656 seconds
DEBUG 01-05 09:59:14.189226.189226 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:59:14.189605.189605 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:14.189904.189904 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 1.9073486328125e-05 seconds
DEBUG 01-05 09:59:14.190818.190818 cuda_h.py:19] end dense_mlp cost 0.001032114028930664 seconds
DEBUG 01-05 09:59:14.190165.190165 lmp.py:217] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 09:59:14.190067.190067 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 09:59:14.190287.190287 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:59:14.190181.190181 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:59:14.190050.190050 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.52587890625e-05 seconds
DEBUG 01-05 09:59:14.190561.190561 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.6253204345703125e-05 seconds
DEBUG 01-05 09:59:14.190396.190396 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.191755.191755 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-05 09:59:14.194856.194856 client.py:127] Model loaded
DEBUG 01-05 09:59:14.194621.194621 cuda_h.py:19] end sllm_worker_task cost 0.011686086654663086 seconds
DEBUG 01-05 09:59:14.194610.194610 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.194340.194340 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.194733.194733 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.195577.195577 cuda_h.py:19] end allocate_cuda_memory cost 0.0002186298370361328 seconds
DEBUG 01-05 09:59:14.195375.195375 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.195059.195059 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.195571.195571 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.195579.195579 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d0a1c99-7853-4561-aaf0-0d43f1a9feb6
DEBUG 01-05 09:59:14.195953.195953 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.195426.195426 cuda_h.py:19] end self_attn cost 0.004536628723144531 seconds
DEBUG 01-05 09:59:14.195621.195621 cuda_h.py:19] end iln_self_attn_paln cost 0.005088090896606445 seconds
DEBUG 01-05 09:59:14.196464.196464 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 09:59:14.196180.196180 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.196384.196384 cuda_h.py:19] end gate cost 0.0007090568542480469 seconds
DEBUG 01-05 09:59:14.196975.196975 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.197998.197998 lmp.py:365] 
DEBUG 01-05 09:59:14.197998.197998 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.197900.197900 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.197788.197788 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.197769.197769 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.197604.197604 lmp.py:369] 
DEBUG 01-05 09:59:14.197604.197604 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.197201.197201 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.197758.197758 lmp.py:376]   Expert 62 |     66 | CPU
DEBUG 01-05 09:59:14.197116.197116 lmp.py:376]   Expert 18 |     68 | CPU
DEBUG 01-05 09:59:14.197521.197521 lmp.py:376]   Expert 22 |     73 | CPU
DEBUG 01-05 09:59:14.197925.197925 lmp.py:376]   Expert 32 |     83 | CPU
DEBUG 01-05 09:59:14.197615.197615 lmp.py:376]   Expert 52 |     94 | CPU
DEBUG 01-05 09:59:14.197542.197542 lmp.py:376]   Expert  3 |    104 | CPU
DEBUG 01-05 09:59:14.197470.197470 lmp.py:376]   Expert 27 |    114 | CPU
DEBUG 01-05 09:59:14.197398.197398 lmp.py:376]   Expert 38 |    114 | CPU
DEBUG 01-05 09:59:14.197325.197325 lmp.py:376]   Expert 13 |    118 | CPU
DEBUG 01-05 09:59:14.197445.197445 lmp.py:376]   Expert 54 |    118 | CPU
DEBUG 01-05 09:59:14.197327.197327 lmp.py:376]   Expert 17 |    121 | CPU
DEBUG 01-05 09:59:14.197685.197685 lmp.py:376]   Expert 11 |    124 | CPU
DEBUG 01-05 09:59:14.197328.197328 lmp.py:376]   Expert 28 |    124 | CPU
DEBUG 01-05 09:59:14.197686.197686 lmp.py:376]   Expert 37 |    125 | CPU
DEBUG 01-05 09:59:14.197806.197806 lmp.py:376]   Expert 58 |    129 | CPU
DEBUG 01-05 09:59:14.197879.197879 lmp.py:376]   Expert 39 |    131 | CPU
DEBUG 01-05 09:59:14.197761.197761 lmp.py:376]   Expert 25 |    135 | CPU
DEBUG 01-05 09:59:14.197834.197834 lmp.py:376]   Expert 41 |    136 | CPU
DEBUG 01-05 09:59:14.197491.197491 lmp.py:376]   Expert 21 |    150 | CPU
DEBUG 01-05 09:59:14.197134.197134 lmp.py:376]   Expert  4 |    151 | CPU
DEBUG 01-05 09:59:14.197254.197254 lmp.py:376]   Expert 30 |    152 | CPU
DEBUG 01-05 09:59:14.197897.197897 lmp.py:376]   Expert 29 |    155 | CPU
DEBUG 01-05 09:59:14.197778.197778 lmp.py:376]   Expert 53 |    155 | CPU
DEBUG 01-05 09:59:14.197182.197182 lmp.py:376]   Expert 49 |    156 | CPU
DEBUG 01-05 09:59:14.197110.197110 lmp.py:376]   Expert 47 |    157 | CPU
DEBUG 01-05 09:59:14.197323.197323 lmp.py:376]   Expert 31 |    168 | CPU
DEBUG 01-05 09:59:14.197774.197774 lmp.py:376]   Expert 33 |    168 | CPU
DEBUG 01-05 09:59:14.197986.197986 lmp.py:376]   Expert 55 |    173 | CPU
DEBUG 01-05 09:59:14.197198.197198 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 09:59:14.197649.197649 lmp.py:376]   Expert 15 |    177 | CPU
DEBUG 01-05 09:59:14.197292.197292 lmp.py:376]   Expert  0 |    178 | CPU
DEBUG 01-05 09:59:14.197935.197935 lmp.py:376]   Expert  1 |    178 | CPU
DEBUG 01-05 09:59:14.197101.197101 lmp.py:376]   Expert 24 |    180 | GPU
DEBUG 01-05 09:59:14.197983.197983 lmp.py:376]   Expert 50 |    182 | GPU
DEBUG 01-05 09:59:14.197434.197434 lmp.py:376]   Expert 51 |    184 | GPU
DEBUG 01-05 09:59:14.197646.197646 lmp.py:376]   Expert 19 |    185 | GPU
DEBUG 01-05 09:59:14.197097.197097 lmp.py:376]   Expert  6 |    186 | GPU
DEBUG 01-05 09:59:14.197548.197548 lmp.py:376]   Expert 10 |    189 | GPU
DEBUG 01-05 09:59:14.197760.197760 lmp.py:376]   Expert 34 |    191 | GPU
DEBUG 01-05 09:59:14.197973.197973 lmp.py:376]   Expert  2 |    195 | GPU
DEBUG 01-05 09:59:14.197947.197947 lmp.py:376]   Expert 45 |    195 | GPU
DEBUG 01-05 09:59:14.198159.198159 lmp.py:376]   Expert 35 |    197 | GPU
DEBUG 01-05 09:59:14.198610.198610 lmp.py:376]   Expert 36 |    198 | GPU
DEBUG 01-05 09:59:14.198776.198776 lmp.py:376]   Expert 61 |    209 | GPU
DEBUG 01-05 09:59:14.198419.198419 lmp.py:376]   Expert 44 |    214 | GPU
DEBUG 01-05 09:59:14.198824.198824 lmp.py:376]   Expert 12 |    223 | GPU
DEBUG 01-05 09:59:14.198229.198229 lmp.py:376]   Expert  5 |    227 | GPU
DEBUG 01-05 09:59:14.198441.198441 lmp.py:376]   Expert 23 |    235 | GPU
DEBUG 01-05 09:59:14.198653.198653 lmp.py:376]   Expert 60 |    235 | GPU
DEBUG 01-05 09:59:14.198104.198104 lmp.py:376]   Expert 43 |    239 | GPU
DEBUG 01-05 09:59:14.198078.198078 lmp.py:376]   Expert  9 |    246 | GPU
DEBUG 01-05 09:59:14.198291.198291 lmp.py:376]   Expert 48 |    252 | GPU
DEBUG 01-05 09:59:14.198742.198742 lmp.py:376]   Expert  8 |    262 | GPU
DEBUG 01-05 09:59:14.198477.198477 lmp.py:376]   Expert 20 |    273 | GPU
DEBUG 01-05 09:59:14.198928.198928 lmp.py:376]   Expert 26 |    285 | GPU
DEBUG 01-05 09:59:14.198094.198094 lmp.py:376]   Expert 57 |    292 | GPU
DEBUG 01-05 09:59:14.198499.198499 lmp.py:376]   Expert  7 |    308 | GPU
DEBUG 01-05 09:59:14.198665.198665 lmp.py:376]   Expert 59 |    308 | GPU
DEBUG 01-05 09:59:14.198070.198070 lmp.py:376]   Expert 16 |    310 | GPU
DEBUG 01-05 09:59:14.198282.198282 lmp.py:376]   Expert 63 |    313 | GPU
DEBUG 01-05 09:59:14.198256.198256 lmp.py:376]   Expert 40 |    320 | GPU
DEBUG 01-05 09:59:14.198707.198707 lmp.py:376]   Expert 46 |    320 | GPU
DEBUG 01-05 09:59:14.198158.198158 lmp.py:376]   Expert 42 |    342 | GPU
DEBUG 01-05 09:59:14.198370.198370 lmp.py:376]   Expert 14 |    525 | GPU
DEBUG 01-05 09:59:14.198536.198536 lmp.py:377] 
DEBUG 01-05 09:59:14.198536.198536 lmp.py:377]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 09:59:14.198941.198941 lmp.py:378]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 09:59:14.198114.198114 cuda_h.py:19] end experts_map_get cost 0.00154876708984375 seconds
DEBUG 01-05 09:59:14.198995.198995 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.198533.198533 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.198988.198988 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.199666.199666 cuda_h.py:19] end allocate_cuda_memory cost 0.0012409687042236328 seconds
DEBUG 01-05 09:59:14.199695.199695 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.199305.199305 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.200306.200306 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.200433.200433 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 617cd595-8e55-4603-a8e8-3cd28e64d13c
DEBUG 01-05 09:59:14.200719.200719 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.200706.200706 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d0a1c99-7853-4561-aaf0-0d43f1a9feb6
DEBUG 01-05 09:59:14.200948.200948 cuda_h.py:19] end load_into_gpu_async cost 0.0006008148193359375 seconds
DEBUG 01-05 09:59:14.200407.200407 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.200001.200001 cuda_h.py:19] end restore_tensors2 cost 9.822845458984375e-05 seconds
DEBUG 01-05 09:59:14.200043.200043 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002346515655517578 seconds
INFO 01-05 09:59:14.201100.201100 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d0a1c99-7853-4561-aaf0-0d43f1a9feb6
INFO 01-05 09:59:14.202635.202635 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 617cd595-8e55-4603-a8e8-3cd28e64d13c
DEBUG 01-05 09:59:14.202762.202762 cuda_h.py:19] end load_into_gpu_async cost 0.0021932125091552734 seconds
DEBUG 01-05 09:59:14.202989.202989 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.202762.202762 cuda_h.py:19] end restore_tensors2 cost 0.0003349781036376953 seconds
DEBUG 01-05 09:59:14.202598.202598 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004096508026123047 seconds
DEBUG 01-05 09:59:14.205292.205292 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006860971450805664 seconds
DEBUG 01-05 09:59:14.205712.205712 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.205012.205012 lmp.py:423] 
DEBUG 01-05 09:59:14.205012.205012 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.205909.205909 cuda_h.py:19] end cpu_experts_submit cost 0.00011587142944335938 seconds
DEBUG 01-05 09:59:14.205658.205658 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.220075.220075 mlpmodule.py:704] group tensors cost 0.01468205451965332 s
DEBUG 01-05 09:59:14.223327.223327 mlpmodule.py:742] pad cost 0.0021331310272216797 s
DEBUG 01-05 09:59:14.223895.223895 mlpmodule.py:748] create cpu tensor cost 6.198883056640625e-05 s
DEBUG 01-05 09:59:14.223447.223447 mlpmodule.py:753] move to cpu cost 4.458427429199219e-05 s
DEBUG 01-05 09:59:14.236317.236317 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.236820.236820 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.236883.236883 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 09:59:14.236802.236802 mlpmodule.py:783] start einsum2
INFO 01-05 09:59:14.256250.256250 client.py:127] Model loaded
DEBUG 01-05 09:59:14.256342.256342 cuda_h.py:19] end sllm_worker_task cost 0.06195855140686035 seconds
DEBUG 01-05 09:59:14.256516.256516 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.256902.256902 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.256361.256361 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.257097.257097 cuda_h.py:19] end allocate_cuda_memory cost 0.00039887428283691406 seconds
DEBUG 01-05 09:59:14.257590.257590 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.257626.257626 mlpmodule.py:793] group einsum cost 0.033545494079589844 s
DEBUG 01-05 09:59:14.257577.257577 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.258772.258772 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.258988.258988 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 10aafd22-3600-4dcb-8a49-8680e4bbfada
DEBUG 01-05 09:59:14.258005.258005 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.258135.258135 mlpmodule.py:801] cpy2cputensor cost 0.0008835792541503906 s
INFO 01-05 09:59:14.259704.259704 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 10aafd22-3600-4dcb-8a49-8680e4bbfada
DEBUG 01-05 09:59:14.259052.259052 cuda_h.py:19] end load_into_gpu_async cost 0.0019333362579345703 seconds
DEBUG 01-05 09:59:14.259769.259769 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.259952.259952 cuda_h.py:19] end restore_tensors2 cost 9.918212890625e-05 seconds
DEBUG 01-05 09:59:14.259999.259999 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002888917922973633 seconds
INFO 01-05 09:59:14.260012.260012 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 10aafd22-3600-4dcb-8a49-8680e4bbfada
INFO 01-05 09:59:14.266515.266515 client.py:127] Model loaded
DEBUG 01-05 09:59:14.266849.266849 cuda_h.py:19] end sllm_worker_task cost 0.009690523147583008 seconds
DEBUG 01-05 09:59:14.269929.269929 cuda_h.py:19] end wait_cetm_experts cost 0.06423401832580566 seconds
DEBUG 01-05 09:59:14.269820.269820 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.270147.270147 cuda_h.py:19] end gpu_sexperts cost 0.000446319580078125 seconds
DEBUG 01-05 09:59:14.270083.270083 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.270165.270165 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-05 09:59:14.270775.270775 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.270577.270577 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 617cd595-8e55-4603-a8e8-3cd28e64d13c
INFO 01-05 09:59:14.271904.271904 client.py:127] Model loaded
DEBUG 01-05 09:59:14.271594.271594 cuda_h.py:19] end wait_experts cost 0.0005040168762207031 seconds
DEBUG 01-05 09:59:14.271297.271297 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.271960.271960 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.292699.292699 mlpmodule.py:662]  experts func einsum cost 0.08619999885559082 s
DEBUG 01-05 09:59:14.292527.292527 mlpmodule.py:531] gpu group tensors cost 0.021192550659179688 s
DEBUG 01-05 09:59:14.295471.295471 mlpmodule.py:564] gpu pad cost 0.002776622772216797 s
DEBUG 01-05 09:59:14.297733.297733 mlpmodule.py:582] gpu group einsum cost 0.0015988349914550781 s
DEBUG 01-05 09:59:14.301362.301362 mlpmodule.py:611] gpu experts func einsum cost 0.029925823211669922 s
DEBUG 01-05 09:59:14.301174.301174 cuda_h.py:19] end gpu_experts cost 0.030106067657470703 seconds
DEBUG 01-05 09:59:14.301469.301469 cuda_h.py:19] end layer_moe_generate_1 cost 0.10533738136291504 seconds
DEBUG 01-05 09:59:14.301747.301747 lmp.py:217] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 09:59:14.301723.301723 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 09:59:14.301717.301717 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:59:14.301440.301440 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:59:14.301251.301251 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:59:14.301205.301205 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.367134094238281e-05 seconds
DEBUG 01-05 09:59:14.301816.301816 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.301322.301322 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.302229.302229 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.302954.302954 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.302278.302278 cuda_h.py:19] end allocate_cuda_memory cost 0.0002808570861816406 seconds
DEBUG 01-05 09:59:14.302468.302468 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.302186.302186 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.302248.302248 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.303556.303556 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6cd7fc98-78d2-4ad6-818d-7848ab3945ec
DEBUG 01-05 09:59:14.303475.303475 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.303312.303312 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.304479.304479 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6cd7fc98-78d2-4ad6-818d-7848ab3945ec
DEBUG 01-05 09:59:14.304470.304470 cuda_h.py:19] end load_into_gpu_async cost 0.001961231231689453 seconds
DEBUG 01-05 09:59:14.304982.304982 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.305928.305928 cuda_h.py:19] end restore_tensors2 cost 0.00011396408081054688 seconds
DEBUG 01-05 09:59:14.305991.305991 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029010772705078125 seconds
INFO 01-05 09:59:14.306193.306193 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6cd7fc98-78d2-4ad6-818d-7848ab3945ec
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.308023.308023 cuda_h.py:19] end self_attn cost 0.0049419403076171875 seconds
DEBUG 01-05 09:59:14.308145.308145 cuda_h.py:19] end iln_self_attn_paln cost 0.006841182708740234 seconds
DEBUG 01-05 09:59:14.308889.308889 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 09:59:14.308129.308129 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.309502.309502 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-05 09:59:14.309570.309570 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.309526.309526 lmp.py:365] 
DEBUG 01-05 09:59:14.309526.309526 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.309997.309997 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.309886.309886 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.309151.309151 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.309225.309225 lmp.py:369] 
DEBUG 01-05 09:59:14.309225.309225 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.309583.309583 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.309663.309663 lmp.py:376]   Expert 34 |     42 | CPU
DEBUG 01-05 09:59:14.309545.309545 lmp.py:376]   Expert 36 |     49 | CPU
DEBUG 01-05 09:59:14.310949.310949 lmp.py:376]   Expert 58 |     65 | CPU
DEBUG 01-05 09:59:14.310830.310830 lmp.py:376]   Expert  3 |     67 | CPU
DEBUG 01-05 09:59:14.310758.310758 lmp.py:376]   Expert 26 |     69 | CPU
DEBUG 01-05 09:59:14.310924.310924 lmp.py:376]   Expert 27 |     77 | CPU
DEBUG 01-05 09:59:14.310090.310090 lmp.py:376]   Expert  8 |     78 | CPU
DEBUG 01-05 09:59:14.310210.310210 lmp.py:376]   Expert 29 |     80 | CPU
DEBUG 01-05 09:59:14.310615.310615 lmp.py:376]   Expert  7 |     94 | CPU
DEBUG 01-05 09:59:14.310735.310735 lmp.py:376]   Expert 10 |     99 | CPU
DEBUG 01-05 09:59:14.310616.310616 lmp.py:376]   Expert 28 |    107 | CPU
DEBUG 01-05 09:59:14.310544.310544 lmp.py:376]   Expert 21 |    108 | CPU
DEBUG 01-05 09:59:14.310471.310471 lmp.py:376]   Expert 13 |    109 | CPU
DEBUG 01-05 09:59:14.310399.310399 lmp.py:376]   Expert 19 |    114 | CPU
DEBUG 01-05 09:59:14.310804.310804 lmp.py:376]   Expert 62 |    126 | CPU
DEBUG 01-05 09:59:14.310970.310970 lmp.py:376]   Expert 40 |    133 | CPU
DEBUG 01-05 09:59:14.310136.310136 lmp.py:376]   Expert  5 |    140 | CPU
DEBUG 01-05 09:59:14.310302.310302 lmp.py:376]   Expert 52 |    141 | CPU
DEBUG 01-05 09:59:14.310230.310230 lmp.py:376]   Expert 63 |    141 | CPU
DEBUG 01-05 09:59:14.310396.310396 lmp.py:376]   Expert  9 |    148 | CPU
DEBUG 01-05 09:59:14.310801.310801 lmp.py:376]   Expert 25 |    149 | CPU
DEBUG 01-05 09:59:14.310444.310444 lmp.py:376]   Expert 50 |    153 | CPU
DEBUG 01-05 09:59:14.310848.310848 lmp.py:376]   Expert 59 |    153 | CPU
DEBUG 01-05 09:59:14.310776.310776 lmp.py:376]   Expert 33 |    154 | CPU
DEBUG 01-05 09:59:14.310227.310227 lmp.py:376]   Expert 17 |    157 | CPU
DEBUG 01-05 09:59:14.310678.310678 lmp.py:376]   Expert 49 |    157 | CPU
DEBUG 01-05 09:59:14.310605.310605 lmp.py:376]   Expert 16 |    160 | CPU
DEBUG 01-05 09:59:14.310771.310771 lmp.py:376]   Expert 60 |    165 | CPU
DEBUG 01-05 09:59:14.310222.310222 lmp.py:376]   Expert 24 |    166 | CPU
DEBUG 01-05 09:59:14.310627.310627 lmp.py:376]   Expert  0 |    167 | CPU
DEBUG 01-05 09:59:14.310555.310555 lmp.py:376]   Expert 30 |    170 | CPU
DEBUG 01-05 09:59:14.310005.310005 lmp.py:376]   Expert 35 |    170 | CPU
DEBUG 01-05 09:59:14.310695.310695 lmp.py:376]   Expert  1 |    173 | GPU
DEBUG 01-05 09:59:14.310576.310576 lmp.py:376]   Expert 38 |    178 | GPU
DEBUG 01-05 09:59:14.310219.310219 lmp.py:376]   Expert  6 |    180 | GPU
DEBUG 01-05 09:59:14.310101.310101 lmp.py:376]   Expert 45 |    180 | GPU
DEBUG 01-05 09:59:14.310505.310505 lmp.py:376]   Expert 44 |    184 | GPU
DEBUG 01-05 09:59:14.310148.310148 lmp.py:376]   Expert 31 |    199 | GPU
DEBUG 01-05 09:59:14.310076.310076 lmp.py:376]   Expert 48 |    206 | GPU
DEBUG 01-05 09:59:14.310765.310765 lmp.py:376]   Expert 39 |    228 | GPU
DEBUG 01-05 09:59:14.310216.310216 lmp.py:376]   Expert 37 |    237 | GPU
DEBUG 01-05 09:59:14.310144.310144 lmp.py:376]   Expert 55 |    238 | GPU
DEBUG 01-05 09:59:14.310310.310310 lmp.py:376]   Expert  4 |    239 | GPU
DEBUG 01-05 09:59:14.310476.310476 lmp.py:376]   Expert 22 |    241 | GPU
DEBUG 01-05 09:59:14.310642.310642 lmp.py:376]   Expert 14 |    242 | GPU
DEBUG 01-05 09:59:14.310570.310570 lmp.py:376]   Expert 51 |    248 | GPU
DEBUG 01-05 09:59:14.310213.310213 lmp.py:376]   Expert 57 |    253 | GPU
DEBUG 01-05 09:59:14.310094.310094 lmp.py:376]   Expert  2 |    254 | GPU
DEBUG 01-05 09:59:14.310499.310499 lmp.py:376]   Expert 41 |    255 | GPU
DEBUG 01-05 09:59:14.310380.310380 lmp.py:376]   Expert 12 |    263 | GPU
DEBUG 01-05 09:59:14.310785.310785 lmp.py:376]   Expert 47 |    269 | GPU
DEBUG 01-05 09:59:14.310712.310712 lmp.py:376]   Expert 20 |    272 | GPU
DEBUG 01-05 09:59:14.310640.310640 lmp.py:376]   Expert 15 |    275 | GPU
DEBUG 01-05 09:59:14.310329.310329 lmp.py:376]   Expert 42 |    281 | GPU
DEBUG 01-05 09:59:14.310463.310463 lmp.py:376]   Expert 23 |    287 | GPU
DEBUG 01-05 09:59:14.310344.310344 lmp.py:376]   Expert 53 |    304 | GPU
DEBUG 01-05 09:59:14.310510.310510 lmp.py:376]   Expert 61 |    306 | GPU
DEBUG 01-05 09:59:14.310915.310915 lmp.py:376]   Expert 56 |    312 | GPU
DEBUG 01-05 09:59:14.310319.310319 lmp.py:376]   Expert 18 |    314 | GPU
DEBUG 01-05 09:59:14.310439.310439 lmp.py:376]   Expert 54 |    315 | GPU
DEBUG 01-05 09:59:14.311082.311082 lmp.py:376]   Expert 46 |    330 | GPU
DEBUG 01-05 09:59:14.311917.311917 lmp.py:376]   Expert 32 |    338 | GPU
DEBUG 01-05 09:59:14.311845.311845 lmp.py:376]   Expert 43 |    364 | GPU
DEBUG 01-05 09:59:14.311058.311058 lmp.py:376]   Expert 11 |    415 | GPU
DEBUG 01-05 09:59:14.311654.311654 lmp.py:377] 
DEBUG 01-05 09:59:14.311654.311654 lmp.py:377]   CPU total tokens: 3908 (31.8%)
DEBUG 01-05 09:59:14.311297.311297 lmp.py:378]   GPU total tokens: 8380 (68.2%)
DEBUG 01-05 09:59:14.311470.311470 cuda_h.py:19] end experts_map_get cost 0.0015490055084228516 seconds
DEBUG 01-05 09:59:14.311351.311351 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.311128.311128 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.311828.311828 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.311817.311817 cuda_h.py:19] end allocate_cuda_memory cost 0.00045180320739746094 seconds
DEBUG 01-05 09:59:14.311276.311276 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.311032.311032 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.311808.311808 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.311889.311889 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 11bd01e0-478c-45ca-8d5f-ffd762fe8149
DEBUG 01-05 09:59:14.312239.312239 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.312004.312004 client.py:127] Model loaded
DEBUG 01-05 09:59:14.312963.312963 cuda_h.py:19] end sllm_worker_task cost 0.01065206527709961 seconds
INFO 01-05 09:59:14.314720.314720 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 11bd01e0-478c-45ca-8d5f-ffd762fe8149
DEBUG 01-05 09:59:14.314685.314685 cuda_h.py:19] end load_into_gpu_async cost 0.0024619102478027344 seconds
DEBUG 01-05 09:59:14.314555.314555 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.314869.314869 cuda_h.py:19] end restore_tensors2 cost 0.00041174888610839844 seconds
DEBUG 01-05 09:59:14.314228.314228 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037736892700195312 seconds
DEBUG 01-05 09:59:14.317383.317383 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0064563751220703125 seconds
DEBUG 01-05 09:59:14.317034.317034 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.317560.317560 lmp.py:423] 
DEBUG 01-05 09:59:14.317560.317560 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.317065.317065 cuda_h.py:19] end cpu_experts_submit cost 0.00010061264038085938 seconds
DEBUG 01-05 09:59:14.317907.317907 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.329717.329717 mlpmodule.py:704] group tensors cost 0.011206388473510742 s
DEBUG 01-05 09:59:14.331193.331193 mlpmodule.py:742] pad cost 0.0013861656188964844 s
DEBUG 01-05 09:59:14.331283.331283 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-05 09:59:14.331332.331332 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 09:59:14.341638.341638 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.341862.341862 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.341475.341475 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 09:59:14.342758.342758 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.362146.362146 mlpmodule.py:793] group einsum cost 0.030958175659179688 s
DEBUG 01-05 09:59:14.363982.363982 mlpmodule.py:801] cpy2cputensor cost 0.0006380081176757812 s
DEBUG 01-05 09:59:14.368279.368279 cuda_h.py:19] end wait_cetm_experts cost 0.05061483383178711 seconds
DEBUG 01-05 09:59:14.368440.368440 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.369200.369200 cuda_h.py:19] end gpu_sexperts cost 0.0004813671112060547 seconds
DEBUG 01-05 09:59:14.369804.369804 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.369144.369144 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.6716461181640625e-05 seconds
DEBUG 01-05 09:59:14.369947.369947 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.369656.369656 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 11bd01e0-478c-45ca-8d5f-ffd762fe8149
INFO 01-05 09:59:14.370114.370114 client.py:127] Model loaded
DEBUG 01-05 09:59:14.370195.370195 cuda_h.py:19] end wait_experts cost 0.001065969467163086 seconds
DEBUG 01-05 09:59:14.370852.370852 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.370370.370370 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.371361.371361 mlpmodule.py:531] gpu group tensors cost 0.0006496906280517578 s
DEBUG 01-05 09:59:14.372811.372811 mlpmodule.py:564] gpu pad cost 0.0017173290252685547 s
DEBUG 01-05 09:59:14.373130.373130 mlpmodule.py:582] gpu group einsum cost 0.0005481243133544922 s
DEBUG 01-05 09:59:14.377127.377127 mlpmodule.py:611] gpu experts func einsum cost 0.007111072540283203 s
DEBUG 01-05 09:59:14.377813.377813 cuda_h.py:19] end gpu_experts cost 0.0073146820068359375 seconds
DEBUG 01-05 09:59:14.377651.377651 cuda_h.py:19] end layer_moe_generate_2 cost 0.06899905204772949 seconds
DEBUG 01-05 09:59:14.378452.378452 lmp.py:217] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 09:59:14.378752.378752 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 09:59:14.378163.378163 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:59:14.378634.378634 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:59:14.378570.378570 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.218650817871094e-05 seconds
DEBUG 01-05 09:59:14.378233.378233 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.699562072753906e-05 seconds
DEBUG 01-05 09:59:14.378453.378453 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.378812.378812 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.378384.378384 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.378068.378068 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.381389.381389 cuda_h.py:19] end allocate_cuda_memory cost 0.002593517303466797 seconds
DEBUG 01-05 09:59:14.381068.381068 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.381023.381023 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.381084.381084 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.381979.381979 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9a45fd3-6010-447f-8ff6-ca190429b497
DEBUG 01-05 09:59:14.381803.381803 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.386491.386491 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9a45fd3-6010-447f-8ff6-ca190429b497
DEBUG 01-05 09:59:14.386426.386426 mlpmodule.py:662]  experts func einsum cost 0.06857419013977051 s
DEBUG 01-05 09:59:14.386339.386339 cuda_h.py:19] end load_into_gpu_async cost 0.00548863410949707 seconds
DEBUG 01-05 09:59:14.386265.386265 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.386845.386845 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-05 09:59:14.387555.387555 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008629083633422852 seconds
DEBUG 01-05 09:59:14.387358.387358 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.387500.387500 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9a45fd3-6010-447f-8ff6-ca190429b497
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
INFO 01-05 09:59:14.390394.390394 client.py:127] Model loaded
DEBUG 01-05 09:59:14.390674.390674 cuda_h.py:19] end sllm_worker_task cost 0.01222372055053711 seconds
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.391329.391329 cuda_h.py:19] end self_attn cost 0.003529787063598633 seconds
DEBUG 01-05 09:59:14.391951.391951 cuda_h.py:19] end iln_self_attn_paln cost 0.013255834579467773 seconds
DEBUG 01-05 09:59:14.391615.391615 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 09:59:14.391868.391868 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.392011.392011 cuda_h.py:19] end gate cost 0.0006597042083740234 seconds
DEBUG 01-05 09:59:14.392060.392060 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.392370.392370 lmp.py:365] 
DEBUG 01-05 09:59:14.392370.392370 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.392517.392517 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.392843.392843 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.392592.392592 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.392049.392049 lmp.py:369] 
DEBUG 01-05 09:59:14.392049.392049 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.392984.392984 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.392309.392309 lmp.py:376]   Expert 61 |     56 | CPU
DEBUG 01-05 09:59:14.392006.392006 lmp.py:376]   Expert 32 |     68 | CPU
DEBUG 01-05 09:59:14.393463.393463 lmp.py:376]   Expert 15 |     73 | CPU
DEBUG 01-05 09:59:14.393067.393067 lmp.py:376]   Expert  4 |     82 | CPU
DEBUG 01-05 09:59:14.393716.393716 lmp.py:376]   Expert 59 |     88 | CPU
DEBUG 01-05 09:59:14.393220.393220 lmp.py:376]   Expert 16 |     89 | CPU
DEBUG 01-05 09:59:14.393724.393724 lmp.py:376]   Expert 37 |     89 | CPU
DEBUG 01-05 09:59:14.393228.393228 lmp.py:376]   Expert  1 |     96 | CPU
DEBUG 01-05 09:59:14.393686.393686 lmp.py:376]   Expert  6 |    105 | CPU
DEBUG 01-05 09:59:14.393382.393382 lmp.py:376]   Expert  5 |    107 | CPU
DEBUG 01-05 09:59:14.393886.393886 lmp.py:376]   Expert 28 |    109 | CPU
DEBUG 01-05 09:59:14.393675.393675 lmp.py:376]   Expert  7 |    119 | CPU
DEBUG 01-05 09:59:14.393702.393702 lmp.py:376]   Expert  8 |    125 | CPU
DEBUG 01-05 09:59:14.393206.393206 lmp.py:376]   Expert 44 |    129 | CPU
DEBUG 01-05 09:59:14.393664.393664 lmp.py:376]   Expert 36 |    131 | CPU
DEBUG 01-05 09:59:14.393929.393929 lmp.py:376]   Expert 63 |    134 | CPU
DEBUG 01-05 09:59:14.393957.393957 lmp.py:376]   Expert 24 |    136 | CPU
DEBUG 01-05 09:59:14.393222.393222 lmp.py:376]   Expert 42 |    139 | CPU
DEBUG 01-05 09:59:14.393011.393011 lmp.py:376]   Expert 52 |    140 | CPU
DEBUG 01-05 09:59:14.393276.393276 lmp.py:376]   Expert 10 |    143 | CPU
DEBUG 01-05 09:59:14.393542.393542 lmp.py:376]   Expert 38 |    144 | CPU
DEBUG 01-05 09:59:14.393000.393000 lmp.py:376]   Expert 29 |    147 | CPU
DEBUG 01-05 09:59:14.393219.393219 lmp.py:376]   Expert 49 |    148 | CPU
DEBUG 01-05 09:59:14.393723.393723 lmp.py:376]   Expert 55 |    148 | CPU
DEBUG 01-05 09:59:14.393512.393512 lmp.py:376]   Expert 12 |    149 | CPU
DEBUG 01-05 09:59:14.393539.393539 lmp.py:376]   Expert 30 |    155 | CPU
DEBUG 01-05 09:59:14.393328.393328 lmp.py:376]   Expert 23 |    158 | CPU
DEBUG 01-05 09:59:14.393116.393116 lmp.py:376]   Expert 57 |    167 | CPU
DEBUG 01-05 09:59:14.393336.393336 lmp.py:376]   Expert 26 |    168 | CPU
DEBUG 01-05 09:59:14.393316.393316 lmp.py:376]   Expert 56 |    170 | CPU
DEBUG 01-05 09:59:14.393344.393344 lmp.py:376]   Expert 58 |    174 | CPU
DEBUG 01-05 09:59:14.393609.393609 lmp.py:376]   Expert 11 |    178 | CPU
DEBUG 01-05 09:59:14.393636.393636 lmp.py:376]   Expert 18 |    178 | GPU
DEBUG 01-05 09:59:14.393425.393425 lmp.py:376]   Expert 62 |    185 | GPU
DEBUG 01-05 09:59:14.393214.393214 lmp.py:376]   Expert 48 |    186 | GPU
DEBUG 01-05 09:59:14.393241.393241 lmp.py:376]   Expert 40 |    187 | GPU
DEBUG 01-05 09:59:14.393222.393222 lmp.py:376]   Expert 31 |    191 | GPU
DEBUG 01-05 09:59:14.393726.393726 lmp.py:376]   Expert  2 |    193 | GPU
DEBUG 01-05 09:59:14.393515.393515 lmp.py:376]   Expert 47 |    194 | GPU
DEBUG 01-05 09:59:14.393542.393542 lmp.py:376]   Expert 35 |    195 | GPU
DEBUG 01-05 09:59:14.393569.393569 lmp.py:376]   Expert 13 |    197 | GPU
DEBUG 01-05 09:59:14.393358.393358 lmp.py:376]   Expert 20 |    211 | GPU
DEBUG 01-05 09:59:14.393146.393146 lmp.py:376]   Expert 45 |    215 | GPU
DEBUG 01-05 09:59:14.393842.393842 lmp.py:376]   Expert  0 |    218 | GPU
DEBUG 01-05 09:59:14.393406.393406 lmp.py:376]   Expert 17 |    222 | GPU
DEBUG 01-05 09:59:14.393149.393149 lmp.py:376]   Expert 46 |    225 | GPU
DEBUG 01-05 09:59:14.393414.393414 lmp.py:376]   Expert 39 |    228 | GPU
DEBUG 01-05 09:59:14.393680.393680 lmp.py:376]   Expert 33 |    229 | GPU
DEBUG 01-05 09:59:14.393469.393469 lmp.py:376]   Expert 22 |    232 | GPU
DEBUG 01-05 09:59:14.393496.393496 lmp.py:376]   Expert 19 |    235 | GPU
DEBUG 01-05 09:59:14.393715.393715 lmp.py:376]   Expert 51 |    241 | GPU
DEBUG 01-05 09:59:14.394650.394650 lmp.py:376]   Expert 53 |    248 | GPU
DEBUG 01-05 09:59:14.394677.394677 lmp.py:376]   Expert 34 |    249 | GPU
DEBUG 01-05 09:59:14.394704.394704 lmp.py:376]   Expert 27 |    267 | GPU
DEBUG 01-05 09:59:14.394969.394969 lmp.py:376]   Expert  3 |    272 | GPU
DEBUG 01-05 09:59:14.394520.394520 lmp.py:376]   Expert 54 |    295 | GPU
DEBUG 01-05 09:59:14.394309.394309 lmp.py:376]   Expert 50 |    307 | GPU
DEBUG 01-05 09:59:14.394336.394336 lmp.py:376]   Expert 60 |    312 | GPU
DEBUG 01-05 09:59:14.394555.394555 lmp.py:376]   Expert 21 |    328 | GPU
DEBUG 01-05 09:59:14.394821.394821 lmp.py:376]   Expert 14 |    343 | GPU
DEBUG 01-05 09:59:14.394848.394848 lmp.py:376]   Expert 43 |    378 | GPU
DEBUG 01-05 09:59:14.394113.394113 lmp.py:376]   Expert  9 |    397 | GPU
DEBUG 01-05 09:59:14.394617.394617 lmp.py:376]   Expert 41 |    403 | GPU
DEBUG 01-05 09:59:14.394406.394406 lmp.py:376]   Expert 25 |    463 | GPU
DEBUG 01-05 09:59:14.394625.394625 lmp.py:377] 
DEBUG 01-05 09:59:14.394625.394625 lmp.py:377]   CPU total tokens: 4064 (33.1%)
DEBUG 01-05 09:59:14.394321.394321 lmp.py:378]   GPU total tokens: 8224 (66.9%)
DEBUG 01-05 09:59:14.394455.394455 cuda_h.py:19] end experts_map_get cost 0.0018696784973144531 seconds
DEBUG 01-05 09:59:14.394343.394343 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.394325.394325 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.394807.394807 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.394504.394504 cuda_h.py:19] end allocate_cuda_memory cost 0.0002295970916748047 seconds
DEBUG 01-05 09:59:14.394308.394308 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.394879.394879 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.394602.394602 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.394497.394497 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a7b9f686-4a73-4f8f-a29c-5dcfb6167c4f
DEBUG 01-05 09:59:14.395147.395147 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.396094.396094 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a7b9f686-4a73-4f8f-a29c-5dcfb6167c4f
DEBUG 01-05 09:59:14.396037.396037 cuda_h.py:19] end load_into_gpu_async cost 0.0015532970428466797 seconds
DEBUG 01-05 09:59:14.396746.396746 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.397081.397081 cuda_h.py:19] end restore_tensors2 cost 0.00045990943908691406 seconds
DEBUG 01-05 09:59:14.397553.397553 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002631664276123047 seconds
DEBUG 01-05 09:59:14.399977.399977 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005458354949951172 seconds
DEBUG 01-05 09:59:14.399290.399290 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.399769.399769 lmp.py:423] 
DEBUG 01-05 09:59:14.399769.399769 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.400089.400089 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-05 09:59:14.400739.400739 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.406758.406758 mlpmodule.py:704] group tensors cost 0.006089448928833008 s
DEBUG 01-05 09:59:14.408915.408915 mlpmodule.py:742] pad cost 0.00182342529296875 s
DEBUG 01-05 09:59:14.408163.408163 mlpmodule.py:748] create cpu tensor cost 4.8160552978515625e-05 s
DEBUG 01-05 09:59:14.409828.409828 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 09:59:14.420250.420250 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.420587.420587 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.420656.420656 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 09:59:14.420925.420925 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.439653.439653 mlpmodule.py:793] group einsum cost 0.03029918670654297 s
DEBUG 01-05 09:59:14.440001.440001 mlpmodule.py:801] cpy2cputensor cost 0.0006728172302246094 s
DEBUG 01-05 09:59:14.444887.444887 cuda_h.py:19] end wait_cetm_experts cost 0.04469704627990723 seconds
DEBUG 01-05 09:59:14.444919.444919 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.445099.445099 cuda_h.py:19] end gpu_sexperts cost 0.0005788803100585938 seconds
DEBUG 01-05 09:59:14.445187.445187 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.445236.445236 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:14.445561.445561 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.445271.445271 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a7b9f686-4a73-4f8f-a29c-5dcfb6167c4f
INFO 01-05 09:59:14.450357.450357 client.py:127] Model loaded
DEBUG 01-05 09:59:14.450598.450598 cuda_h.py:19] end wait_experts cost 0.004805088043212891 seconds
DEBUG 01-05 09:59:14.450592.450592 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.450871.450871 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.451015.451015 mlpmodule.py:531] gpu group tensors cost 0.0006511211395263672 s
DEBUG 01-05 09:59:14.453348.453348 mlpmodule.py:564] gpu pad cost 0.0017642974853515625 s
DEBUG 01-05 09:59:14.453970.453970 mlpmodule.py:582] gpu group einsum cost 0.00052642822265625 s
DEBUG 01-05 09:59:14.461528.461528 mlpmodule.py:662]  experts func einsum cost 0.061569929122924805 s
DEBUG 01-05 09:59:14.462241.462241 mlpmodule.py:611] gpu experts func einsum cost 0.011939525604248047 s
DEBUG 01-05 09:59:14.462948.462948 cuda_h.py:19] end gpu_experts cost 0.012171268463134766 seconds
DEBUG 01-05 09:59:14.462725.462725 cuda_h.py:19] end layer_moe_generate_3 cost 0.07128500938415527 seconds
DEBUG 01-05 09:59:14.463863.463863 lmp.py:217] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 09:59:14.463580.463580 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 09:59:14.463415.463415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:59:14.463025.463025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:59:14.463577.463577 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:14.463061.463061 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.534027099609375e-05 seconds
DEBUG 01-05 09:59:14.463658.463658 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.463163.463163 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.463625.463625 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.463845.463845 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.463876.463876 cuda_h.py:19] end allocate_cuda_memory cost 0.00030231475830078125 seconds
DEBUG 01-05 09:59:14.463415.463415 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.464463.464463 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.464425.464425 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.464220.464220 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 83f17e8a-32cd-4dbf-962a-7de0fa775fa6
DEBUG 01-05 09:59:14.464236.464236 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.464582.464582 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.465815.465815 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 83f17e8a-32cd-4dbf-962a-7de0fa775fa6
DEBUG 01-05 09:59:14.465889.465889 cuda_h.py:19] end load_into_gpu_async cost 0.0012619495391845703 seconds
DEBUG 01-05 09:59:14.465446.465446 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.465046.465046 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-05 09:59:14.465848.465848 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018835067749023438 seconds
INFO 01-05 09:59:14.465838.465838 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 83f17e8a-32cd-4dbf-962a-7de0fa775fa6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.468341.468341 cuda_h.py:19] end self_attn cost 0.0037975311279296875 seconds
DEBUG 01-05 09:59:14.468305.468305 cuda_h.py:19] end iln_self_attn_paln cost 0.0052585601806640625 seconds
DEBUG 01-05 09:59:14.468572.468572 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 09:59:14.468097.468097 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.469854.469854 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-05 09:59:14.469061.469061 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.469256.469256 lmp.py:365] 
DEBUG 01-05 09:59:14.469256.469256 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.469820.469820 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.469754.469754 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.469351.469351 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.469517.469517 lmp.py:369] 
DEBUG 01-05 09:59:14.469517.469517 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.469968.469968 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.469902.469902 lmp.py:376]   Expert 13 |     41 | CPU
DEBUG 01-05 09:59:14.469830.469830 lmp.py:376]   Expert 60 |     48 | CPU
DEBUG 01-05 09:59:14.469042.469042 lmp.py:376]   Expert 11 |     61 | CPU
DEBUG 01-05 09:59:14.469016.469016 lmp.py:376]   Expert 26 |     77 | CPU
DEBUG 01-05 09:59:14.469991.469991 lmp.py:376]   Expert 56 |     78 | CPU
DEBUG 01-05 09:59:14.469726.469726 lmp.py:376]   Expert 25 |     83 | CPU
DEBUG 01-05 09:59:14.469415.469415 lmp.py:376]   Expert  3 |     86 | CPU
DEBUG 01-05 09:59:14.469343.469343 lmp.py:376]   Expert 58 |     86 | CPU
DEBUG 01-05 09:59:14.469032.469032 lmp.py:376]   Expert 36 |     89 | CPU
DEBUG 01-05 09:59:14.469768.469768 lmp.py:376]   Expert  7 |     90 | CPU
DEBUG 01-05 09:59:14.469265.469265 lmp.py:376]   Expert 51 |     91 | CPU
DEBUG 01-05 09:59:14.469286.469286 lmp.py:376]   Expert 34 |     92 | CPU
DEBUG 01-05 09:59:14.469783.469783 lmp.py:376]   Expert 28 |     96 | CPU
DEBUG 01-05 09:59:14.470803.470803 lmp.py:376]   Expert  6 |     98 | CPU
DEBUG 01-05 09:59:14.470539.470539 lmp.py:376]   Expert 48 |    100 | CPU
DEBUG 01-05 09:59:14.470798.470798 lmp.py:376]   Expert 45 |    101 | CPU
DEBUG 01-05 09:59:14.470818.470818 lmp.py:376]   Expert 41 |    103 | CPU
DEBUG 01-05 09:59:14.470792.470792 lmp.py:376]   Expert 16 |    109 | CPU
DEBUG 01-05 09:59:14.470766.470766 lmp.py:376]   Expert 33 |    110 | CPU
DEBUG 01-05 09:59:14.470740.470740 lmp.py:376]   Expert 55 |    125 | CPU
DEBUG 01-05 09:59:14.470237.470237 lmp.py:376]   Expert  9 |    127 | CPU
DEBUG 01-05 09:59:14.470496.470496 lmp.py:376]   Expert 18 |    129 | CPU
DEBUG 01-05 09:59:14.470517.470517 lmp.py:376]   Expert 24 |    130 | CPU
DEBUG 01-05 09:59:14.470014.470014 lmp.py:376]   Expert 17 |    132 | CPU
DEBUG 01-05 09:59:14.470273.470273 lmp.py:376]   Expert 14 |    134 | CPU
DEBUG 01-05 09:59:14.470770.470770 lmp.py:376]   Expert 50 |    138 | CPU
DEBUG 01-05 09:59:14.470267.470267 lmp.py:376]   Expert  2 |    144 | CPU
DEBUG 01-05 09:59:14.470003.470003 lmp.py:376]   Expert  4 |    145 | CPU
DEBUG 01-05 09:59:14.470738.470738 lmp.py:376]   Expert 44 |    151 | CPU
DEBUG 01-05 09:59:14.470428.470428 lmp.py:376]   Expert 47 |    153 | CPU
DEBUG 01-05 09:59:14.470640.470640 lmp.py:376]   Expert 22 |    166 | CPU
DEBUG 01-05 09:59:14.470998.470998 lmp.py:376]   Expert 10 |    173 | CPU
DEBUG 01-05 09:59:14.470972.470972 lmp.py:376]   Expert 54 |    175 | GPU
DEBUG 01-05 09:59:14.470469.470469 lmp.py:376]   Expert 31 |    188 | GPU
DEBUG 01-05 09:59:14.470967.470967 lmp.py:376]   Expert 37 |    191 | GPU
DEBUG 01-05 09:59:14.470987.470987 lmp.py:376]   Expert 40 |    193 | GPU
DEBUG 01-05 09:59:14.470484.470484 lmp.py:376]   Expert 21 |    197 | GPU
DEBUG 01-05 09:59:14.470981.470981 lmp.py:376]   Expert 46 |    199 | GPU
DEBUG 01-05 09:59:14.470479.470479 lmp.py:376]   Expert 61 |    200 | GPU
DEBUG 01-05 09:59:14.470930.470930 lmp.py:376]   Expert 15 |    203 | GPU
DEBUG 01-05 09:59:14.470619.470619 lmp.py:376]   Expert 42 |    209 | GPU
DEBUG 01-05 09:59:14.470116.470116 lmp.py:376]   Expert  8 |    210 | GPU
DEBUG 01-05 09:59:14.470852.470852 lmp.py:376]   Expert 53 |    212 | GPU
DEBUG 01-05 09:59:14.470872.470872 lmp.py:376]   Expert 63 |    218 | GPU
DEBUG 01-05 09:59:14.470369.470369 lmp.py:376]   Expert 27 |    219 | GPU
DEBUG 01-05 09:59:14.470390.470390 lmp.py:376]   Expert 29 |    226 | GPU
DEBUG 01-05 09:59:14.470648.470648 lmp.py:376]   Expert 20 |    228 | GPU
DEBUG 01-05 09:59:14.470146.470146 lmp.py:376]   Expert 57 |    233 | GPU
DEBUG 01-05 09:59:14.470643.470643 lmp.py:376]   Expert 32 |    234 | GPU
DEBUG 01-05 09:59:14.470140.470140 lmp.py:376]   Expert  0 |    269 | GPU
DEBUG 01-05 09:59:14.470399.470399 lmp.py:376]   Expert 23 |    269 | GPU
DEBUG 01-05 09:59:14.470896.470896 lmp.py:376]   Expert 38 |    269 | GPU
DEBUG 01-05 09:59:14.470109.470109 lmp.py:376]   Expert 19 |    272 | GPU
DEBUG 01-05 09:59:14.470559.470559 lmp.py:376]   Expert  1 |    275 | GPU
DEBUG 01-05 09:59:14.470295.470295 lmp.py:376]   Expert 12 |    296 | GPU
DEBUG 01-05 09:59:14.470554.470554 lmp.py:376]   Expert 62 |    301 | GPU
DEBUG 01-05 09:59:14.470574.470574 lmp.py:376]   Expert 30 |    310 | GPU
DEBUG 01-05 09:59:14.470071.470071 lmp.py:376]   Expert 35 |    325 | GPU
DEBUG 01-05 09:59:14.470569.470569 lmp.py:376]   Expert 49 |    325 | GPU
DEBUG 01-05 09:59:14.470066.470066 lmp.py:376]   Expert 52 |    399 | GPU
DEBUG 01-05 09:59:14.470325.470325 lmp.py:376]   Expert  5 |    425 | GPU
DEBUG 01-05 09:59:14.470822.470822 lmp.py:376]   Expert 39 |    429 | GPU
DEBUG 01-05 09:59:14.470319.470319 lmp.py:376]   Expert 43 |    481 | GPU
DEBUG 01-05 09:59:14.470293.470293 lmp.py:376]   Expert 59 |    622 | GPU
DEBUG 01-05 09:59:14.470744.470744 lmp.py:377] 
DEBUG 01-05 09:59:14.470744.470744 lmp.py:377]   CPU total tokens: 3486 (28.4%)
DEBUG 01-05 09:59:14.470195.470195 lmp.py:378]   GPU total tokens: 8802 (71.6%)
DEBUG 01-05 09:59:14.470699.470699 cuda_h.py:19] end experts_map_get cost 0.0014262199401855469 seconds
DEBUG 01-05 09:59:14.470150.470150 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.470780.470780 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.471049.471049 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.471036.471036 cuda_h.py:19] end allocate_cuda_memory cost 0.0005550384521484375 seconds
DEBUG 01-05 09:59:14.471025.471025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.471311.471311 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.471358.471358 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.471723.471723 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aea0adbe-2372-4454-aded-ca40e1093a76
DEBUG 01-05 09:59:14.471551.471551 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.472763.472763 client.py:127] Model loaded
DEBUG 01-05 09:59:14.472904.472904 cuda_h.py:19] end sllm_worker_task cost 0.008743762969970703 seconds
INFO 01-05 09:59:14.473037.473037 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aea0adbe-2372-4454-aded-ca40e1093a76
DEBUG 01-05 09:59:14.473979.473979 cuda_h.py:19] end load_into_gpu_async cost 0.0013723373413085938 seconds
DEBUG 01-05 09:59:14.473636.473636 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.473540.473540 cuda_h.py:19] end restore_tensors2 cost 0.0004639625549316406 seconds
DEBUG 01-05 09:59:14.473105.473105 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002744913101196289 seconds
DEBUG 01-05 09:59:14.476555.476555 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005364894866943359 seconds
DEBUG 01-05 09:59:14.476776.476776 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.476745.476745 lmp.py:423] 
DEBUG 01-05 09:59:14.476745.476745 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.476496.476496 cuda_h.py:19] end cpu_experts_submit cost 0.00011491775512695312 seconds
DEBUG 01-05 09:59:14.476576.476576 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.481868.481868 mlpmodule.py:704] group tensors cost 0.005147695541381836 s
DEBUG 01-05 09:59:14.484747.484747 mlpmodule.py:742] pad cost 0.002070903778076172 s
DEBUG 01-05 09:59:14.484585.484585 mlpmodule.py:748] create cpu tensor cost 5.125999450683594e-05 s
DEBUG 01-05 09:59:14.484032.484032 mlpmodule.py:753] move to cpu cost 3.695487976074219e-05 s
DEBUG 01-05 09:59:14.496834.496834 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.496462.496462 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.496784.496784 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 09:59:14.496615.496615 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.516729.516729 mlpmodule.py:793] group einsum cost 0.031810760498046875 s
DEBUG 01-05 09:59:14.517222.517222 mlpmodule.py:801] cpy2cputensor cost 0.0006542205810546875 s
DEBUG 01-05 09:59:14.522030.522030 cuda_h.py:19] end wait_cetm_experts cost 0.04551863670349121 seconds
DEBUG 01-05 09:59:14.522254.522254 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.522202.522202 cuda_h.py:19] end gpu_sexperts cost 0.0005855560302734375 seconds
DEBUG 01-05 09:59:14.522906.522906 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.523154.523154 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.790855407714844e-05 seconds
DEBUG 01-05 09:59:14.523049.523049 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.523997.523997 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aea0adbe-2372-4454-aded-ca40e1093a76
INFO 01-05 09:59:14.527933.527933 client.py:127] Model loaded
DEBUG 01-05 09:59:14.527690.527690 cuda_h.py:19] end wait_experts cost 0.004690647125244141 seconds
DEBUG 01-05 09:59:14.527493.527493 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.527487.527487 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.528235.528235 mlpmodule.py:531] gpu group tensors cost 0.0006701946258544922 s
DEBUG 01-05 09:59:14.532686.532686 mlpmodule.py:564] gpu pad cost 0.0041353702545166016 s
DEBUG 01-05 09:59:14.535369.535369 mlpmodule.py:662]  experts func einsum cost 0.05891156196594238 s
DEBUG 01-05 09:59:14.535409.535409 mlpmodule.py:582] gpu group einsum cost 0.0031156539916992188 s
DEBUG 01-05 09:59:14.538623.538623 mlpmodule.py:611] gpu experts func einsum cost 0.01089334487915039 s
DEBUG 01-05 09:59:14.538269.538269 cuda_h.py:19] end gpu_experts cost 0.011076688766479492 seconds
DEBUG 01-05 09:59:14.538616.538616 cuda_h.py:19] end layer_moe_generate_4 cost 0.0702967643737793 seconds
DEBUG 01-05 09:59:14.539476.539476 lmp.py:217] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 09:59:14.539385.539385 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 09:59:14.539173.539173 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:59:14.539307.539307 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:59:14.539951.539951 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.7894973754882812e-05 seconds
DEBUG 01-05 09:59:14.539767.539767 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.2479248046875e-05 seconds
DEBUG 01-05 09:59:14.539648.539648 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.539531.539531 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.539886.539886 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.539914.539914 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.539008.539008 cuda_h.py:19] end allocate_cuda_memory cost 0.000209808349609375 seconds
DEBUG 01-05 09:59:14.539117.539117 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.539496.539496 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.539332.539332 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.540035.540035 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b65e574d-d6f5-4c59-91de-1a6ddda75400
DEBUG 01-05 09:59:14.540190.540190 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.540104.540104 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.541981.541981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b65e574d-d6f5-4c59-91de-1a6ddda75400
DEBUG 01-05 09:59:14.541811.541811 cuda_h.py:19] end load_into_gpu_async cost 0.0013175010681152344 seconds
DEBUG 01-05 09:59:14.541475.541475 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.541485.541485 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-05 09:59:14.541109.541109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018837451934814453 seconds
INFO 01-05 09:59:14.541816.541816 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b65e574d-d6f5-4c59-91de-1a6ddda75400
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.544958.544958 cuda_h.py:19] end self_attn cost 0.0040607452392578125 seconds
DEBUG 01-05 09:59:14.544180.544180 cuda_h.py:19] end iln_self_attn_paln cost 0.005383491516113281 seconds
DEBUG 01-05 09:59:14.544216.544216 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 09:59:14.544647.544647 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.545789.545789 cuda_h.py:19] end gate cost 0.0006318092346191406 seconds
DEBUG 01-05 09:59:14.545155.545155 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.545257.545257 lmp.py:365] 
DEBUG 01-05 09:59:14.545257.545257 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.545060.545060 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.545186.545186 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.545737.545737 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.545664.545664 lmp.py:369] 
DEBUG 01-05 09:59:14.545664.545664 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.545069.545069 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.546195.546195 lmp.py:376]   Expert 34 |     22 | CPU
DEBUG 01-05 09:59:14.546838.546838 lmp.py:376]   Expert 15 |     47 | CPU
DEBUG 01-05 09:59:14.546051.546051 lmp.py:376]   Expert 47 |     48 | CPU
DEBUG 01-05 09:59:14.546025.546025 lmp.py:376]   Expert 39 |     50 | CPU
DEBUG 01-05 09:59:14.546999.546999 lmp.py:376]   Expert  2 |     57 | CPU
DEBUG 01-05 09:59:14.546496.546496 lmp.py:376]   Expert 18 |     73 | CPU
DEBUG 01-05 09:59:14.546470.546470 lmp.py:376]   Expert 23 |     86 | CPU
DEBUG 01-05 09:59:14.546967.546967 lmp.py:376]   Expert  3 |     89 | CPU
DEBUG 01-05 09:59:14.546703.546703 lmp.py:376]   Expert 27 |     93 | CPU
DEBUG 01-05 09:59:14.546200.546200 lmp.py:376]   Expert 30 |     99 | CPU
DEBUG 01-05 09:59:14.546936.546936 lmp.py:376]   Expert 28 |    110 | CPU
DEBUG 01-05 09:59:14.546625.546625 lmp.py:376]   Expert 45 |    110 | CPU
DEBUG 01-05 09:59:14.546599.546599 lmp.py:376]   Expert 17 |    111 | CPU
DEBUG 01-05 09:59:14.546050.546050 lmp.py:376]   Expert 52 |    111 | CPU
DEBUG 01-05 09:59:14.546501.546501 lmp.py:376]   Expert  4 |    113 | CPU
DEBUG 01-05 09:59:14.546190.546190 lmp.py:376]   Expert  0 |    118 | CPU
DEBUG 01-05 09:59:14.546926.546926 lmp.py:376]   Expert 63 |    121 | CPU
DEBUG 01-05 09:59:14.546662.546662 lmp.py:376]   Expert  8 |    122 | CPU
DEBUG 01-05 09:59:14.546920.546920 lmp.py:376]   Expert 22 |    123 | CPU
DEBUG 01-05 09:59:14.546418.546418 lmp.py:376]   Expert 62 |    124 | CPU
DEBUG 01-05 09:59:14.546676.546676 lmp.py:376]   Expert 60 |    128 | CPU
DEBUG 01-05 09:59:14.546935.546935 lmp.py:376]   Expert  9 |    129 | CPU
DEBUG 01-05 09:59:14.546432.546432 lmp.py:376]   Expert 14 |    135 | CPU
DEBUG 01-05 09:59:14.546691.546691 lmp.py:376]   Expert 48 |    141 | CPU
DEBUG 01-05 09:59:14.546188.546188 lmp.py:376]   Expert 51 |    141 | CPU
DEBUG 01-05 09:59:14.546686.546686 lmp.py:376]   Expert 41 |    148 | CPU
DEBUG 01-05 09:59:14.546421.546421 lmp.py:376]   Expert 54 |    149 | CPU
DEBUG 01-05 09:59:14.546349.546349 lmp.py:376]   Expert 46 |    152 | CPU
DEBUG 01-05 09:59:14.546469.546469 lmp.py:376]   Expert 10 |    154 | CPU
DEBUG 01-05 09:59:14.546396.546396 lmp.py:376]   Expert 57 |    160 | CPU
DEBUG 01-05 09:59:14.546324.546324 lmp.py:376]   Expert 25 |    161 | CPU
DEBUG 01-05 09:59:14.546013.546013 lmp.py:376]   Expert  1 |    163 | CPU
DEBUG 01-05 09:59:14.546464.546464 lmp.py:376]   Expert 36 |    166 | GPU
DEBUG 01-05 09:59:14.546915.546915 lmp.py:376]   Expert 38 |    167 | GPU
DEBUG 01-05 09:59:14.546889.546889 lmp.py:376]   Expert 24 |    170 | GPU
DEBUG 01-05 09:59:14.546102.546102 lmp.py:376]   Expert 43 |    170 | GPU
DEBUG 01-05 09:59:14.546314.546314 lmp.py:376]   Expert 26 |    177 | GPU
DEBUG 01-05 09:59:14.546288.546288 lmp.py:376]   Expert 11 |    193 | GPU
DEBUG 01-05 09:59:14.546262.546262 lmp.py:376]   Expert 56 |    197 | GPU
DEBUG 01-05 09:59:14.546713.546713 lmp.py:376]   Expert 16 |    199 | GPU
DEBUG 01-05 09:59:14.546449.546449 lmp.py:376]   Expert 32 |    200 | GPU
DEBUG 01-05 09:59:14.546661.546661 lmp.py:376]   Expert 58 |    205 | GPU
DEBUG 01-05 09:59:14.546635.546635 lmp.py:376]   Expert 29 |    207 | GPU
DEBUG 01-05 09:59:14.546848.546848 lmp.py:376]   Expert 12 |    217 | GPU
DEBUG 01-05 09:59:14.546299.546299 lmp.py:376]   Expert 50 |    222 | GPU
DEBUG 01-05 09:59:14.546326.546326 lmp.py:376]   Expert 44 |    226 | GPU
DEBUG 01-05 09:59:14.546538.546538 lmp.py:376]   Expert 55 |    229 | GPU
DEBUG 01-05 09:59:14.546512.546512 lmp.py:376]   Expert 61 |    230 | GPU
DEBUG 01-05 09:59:14.546248.546248 lmp.py:376]   Expert 19 |    231 | GPU
DEBUG 01-05 09:59:14.546745.546745 lmp.py:376]   Expert  7 |    236 | GPU
DEBUG 01-05 09:59:14.546004.546004 lmp.py:376]   Expert 42 |    238 | GPU
DEBUG 01-05 09:59:14.546501.546501 lmp.py:376]   Expert 35 |    241 | GPU
DEBUG 01-05 09:59:14.546521.546521 lmp.py:376]   Expert 59 |    262 | GPU
DEBUG 01-05 09:59:14.546542.546542 lmp.py:376]   Expert 21 |    272 | GPU
DEBUG 01-05 09:59:14.546039.546039 lmp.py:376]   Expert  5 |    286 | GPU
DEBUG 01-05 09:59:14.546536.546536 lmp.py:376]   Expert 20 |    293 | GPU
DEBUG 01-05 09:59:14.546795.546795 lmp.py:376]   Expert 40 |    298 | GPU
DEBUG 01-05 09:59:14.546815.546815 lmp.py:376]   Expert 31 |    321 | GPU
DEBUG 01-05 09:59:14.546597.546597 lmp.py:376]   Expert 13 |    354 | GPU
DEBUG 01-05 09:59:14.546856.546856 lmp.py:376]   Expert 33 |    357 | GPU
DEBUG 01-05 09:59:14.546353.546353 lmp.py:376]   Expert  6 |    376 | GPU
DEBUG 01-05 09:59:14.546327.546327 lmp.py:376]   Expert 49 |    392 | GPU
DEBUG 01-05 09:59:14.546063.546063 lmp.py:376]   Expert 37 |    490 | GPU
DEBUG 01-05 09:59:14.547514.547514 lmp.py:376]   Expert 53 |    878 | GPU
DEBUG 01-05 09:59:14.547918.547918 lmp.py:377] 
DEBUG 01-05 09:59:14.547918.547918 lmp.py:377]   CPU total tokens: 3588 (29.2%)
DEBUG 01-05 09:59:14.547608.547608 lmp.py:378]   GPU total tokens: 8700 (70.8%)
DEBUG 01-05 09:59:14.547350.547350 cuda_h.py:19] end experts_map_get cost 0.0014503002166748047 seconds
DEBUG 01-05 09:59:14.547039.547039 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.547101.547101 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.547754.547754 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.547735.547735 cuda_h.py:19] end allocate_cuda_memory cost 0.0005850791931152344 seconds
DEBUG 01-05 09:59:14.547207.547207 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.547917.547917 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.548104.548104 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.548230.548230 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d8b25fe-1a3a-4464-8a48-260a363a55f3
DEBUG 01-05 09:59:14.548032.548032 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.548936.548936 client.py:127] Model loaded
DEBUG 01-05 09:59:14.548237.548237 cuda_h.py:19] end sllm_worker_task cost 0.009110212326049805 seconds
INFO 01-05 09:59:14.549030.549030 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d8b25fe-1a3a-4464-8a48-260a363a55f3
DEBUG 01-05 09:59:14.549250.549250 cuda_h.py:19] end load_into_gpu_async cost 0.0014371871948242188 seconds
DEBUG 01-05 09:59:14.549238.549238 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.549112.549112 cuda_h.py:19] end restore_tensors2 cost 0.0003724098205566406 seconds
DEBUG 01-05 09:59:14.549902.549902 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027463436126708984 seconds
DEBUG 01-05 09:59:14.552227.552227 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053784847259521484 seconds
DEBUG 01-05 09:59:14.552063.552063 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.552404.552404 lmp.py:423] 
DEBUG 01-05 09:59:14.552404.552404 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.552108.552108 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-05 09:59:14.552148.552148 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.561026.561026 mlpmodule.py:704] group tensors cost 0.008519172668457031 s
DEBUG 01-05 09:59:14.564980.564980 mlpmodule.py:742] pad cost 0.0026578903198242188 s
DEBUG 01-05 09:59:14.565773.565773 mlpmodule.py:748] create cpu tensor cost 6.651878356933594e-05 s
DEBUG 01-05 09:59:14.565532.565532 mlpmodule.py:753] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-05 09:59:14.575091.575091 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.576368.576368 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.576106.576106 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 09:59:14.576892.576892 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.594967.594967 mlpmodule.py:793] group einsum cost 0.029117584228515625 s
DEBUG 01-05 09:59:14.595738.595738 mlpmodule.py:801] cpy2cputensor cost 0.00067901611328125 s
DEBUG 01-05 09:59:14.599187.599187 cuda_h.py:19] end wait_cetm_experts cost 0.04696202278137207 seconds
DEBUG 01-05 09:59:14.599041.599041 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.600579.600579 cuda_h.py:19] end gpu_sexperts cost 0.0005970001220703125 seconds
DEBUG 01-05 09:59:14.600905.600905 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.600477.600477 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:14.600849.600849 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.600996.600996 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d8b25fe-1a3a-4464-8a48-260a363a55f3
INFO 01-05 09:59:14.603120.603120 client.py:127] Model loaded
DEBUG 01-05 09:59:14.603771.603771 cuda_h.py:19] end wait_experts cost 0.0031766891479492188 seconds
DEBUG 01-05 09:59:14.603666.603666 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.603707.603707 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.604593.604593 mlpmodule.py:531] gpu group tensors cost 0.0006723403930664062 s
DEBUG 01-05 09:59:14.610747.610747 mlpmodule.py:564] gpu pad cost 0.005915164947509766 s
DEBUG 01-05 09:59:14.613444.613444 mlpmodule.py:662]  experts func einsum cost 0.0609893798828125 s
DEBUG 01-05 09:59:14.614487.614487 mlpmodule.py:582] gpu group einsum cost 0.0036025047302246094 s
DEBUG 01-05 09:59:14.617653.617653 mlpmodule.py:611] gpu experts func einsum cost 0.013146162033081055 s
DEBUG 01-05 09:59:14.617252.617252 cuda_h.py:19] end gpu_experts cost 0.013324737548828125 seconds
DEBUG 01-05 09:59:14.617076.617076 cuda_h.py:19] end layer_moe_generate_5 cost 0.07254767417907715 seconds
DEBUG 01-05 09:59:14.617983.617983 lmp.py:217] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 09:59:14.617898.617898 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 09:59:14.617448.617448 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:59:14.617397.617397 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:59:14.617710.617710 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.9087066650390625e-05 seconds
DEBUG 01-05 09:59:14.617764.617764 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.343292236328125e-05 seconds
DEBUG 01-05 09:59:14.617645.617645 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.617066.617066 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.617334.617334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.618508.618508 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.618489.618489 cuda_h.py:19] end allocate_cuda_memory cost 0.0001964569091796875 seconds
DEBUG 01-05 09:59:14.618413.618413 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.618175.618175 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.618091.618091 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.618555.618555 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 701d878f-1527-4814-9b30-3b151abc4c48
DEBUG 01-05 09:59:14.618863.618863 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.618506.618506 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.619752.619752 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 701d878f-1527-4814-9b30-3b151abc4c48
DEBUG 01-05 09:59:14.619734.619734 cuda_h.py:19] end load_into_gpu_async cost 0.0012531280517578125 seconds
DEBUG 01-05 09:59:14.619483.619483 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.619864.619864 cuda_h.py:19] end restore_tensors2 cost 7.724761962890625e-05 seconds
DEBUG 01-05 09:59:14.619051.619051 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017898082733154297 seconds
INFO 01-05 09:59:14.620288.620288 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 701d878f-1527-4814-9b30-3b151abc4c48
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.622245.622245 cuda_h.py:19] end self_attn cost 0.003994941711425781 seconds
DEBUG 01-05 09:59:14.623672.623672 cuda_h.py:19] end iln_self_attn_paln cost 0.0053272247314453125 seconds
DEBUG 01-05 09:59:14.623131.623131 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 09:59:14.623417.623417 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.623751.623751 cuda_h.py:19] end gate cost 0.0006344318389892578 seconds
DEBUG 01-05 09:59:14.623388.623388 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.624298.624298 lmp.py:365] 
DEBUG 01-05 09:59:14.624298.624298 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.624101.624101 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.624751.624751 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.624062.624062 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.624705.624705 lmp.py:369] 
DEBUG 01-05 09:59:14.624705.624705 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.624395.624395 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.624091.624091 lmp.py:376]   Expert  1 |      4 | CPU
DEBUG 01-05 09:59:14.624602.624602 lmp.py:376]   Expert  3 |     31 | CPU
DEBUG 01-05 09:59:14.624742.624742 lmp.py:376]   Expert 14 |     48 | CPU
DEBUG 01-05 09:59:14.624670.624670 lmp.py:376]   Expert 53 |     56 | CPU
DEBUG 01-05 09:59:14.624120.624120 lmp.py:376]   Expert 52 |     58 | CPU
DEBUG 01-05 09:59:14.624571.624571 lmp.py:376]   Expert 35 |     70 | CPU
DEBUG 01-05 09:59:14.624022.624022 lmp.py:376]   Expert 15 |     72 | CPU
DEBUG 01-05 09:59:14.624904.624904 lmp.py:376]   Expert 44 |     79 | CPU
DEBUG 01-05 09:59:14.624308.624308 lmp.py:376]   Expert 11 |     83 | CPU
DEBUG 01-05 09:59:14.624236.624236 lmp.py:376]   Expert 10 |     84 | CPU
DEBUG 01-05 09:59:14.624164.624164 lmp.py:376]   Expert 63 |     85 | CPU
DEBUG 01-05 09:59:14.624138.624138 lmp.py:376]   Expert 26 |     99 | CPU
DEBUG 01-05 09:59:14.624588.624588 lmp.py:376]   Expert 50 |    101 | CPU
DEBUG 01-05 09:59:14.624801.624801 lmp.py:376]   Expert 49 |    104 | CPU
DEBUG 01-05 09:59:14.624537.624537 lmp.py:376]   Expert 34 |    109 | CPU
DEBUG 01-05 09:59:14.624987.624987 lmp.py:376]   Expert  7 |    114 | CPU
DEBUG 01-05 09:59:14.624200.624200 lmp.py:376]   Expert 37 |    117 | CPU
DEBUG 01-05 09:59:14.624936.624936 lmp.py:376]   Expert 16 |    118 | CPU
DEBUG 01-05 09:59:14.624148.624148 lmp.py:376]   Expert 40 |    118 | CPU
DEBUG 01-05 09:59:14.624360.624360 lmp.py:376]   Expert 47 |    119 | CPU
DEBUG 01-05 09:59:14.624096.624096 lmp.py:376]   Expert 22 |    123 | CPU
DEBUG 01-05 09:59:14.624309.624309 lmp.py:376]   Expert 28 |    127 | CPU
DEBUG 01-05 09:59:14.624475.624475 lmp.py:376]   Expert 62 |    132 | CPU
DEBUG 01-05 09:59:14.624402.624402 lmp.py:376]   Expert 32 |    133 | CPU
DEBUG 01-05 09:59:14.624237.624237 lmp.py:376]   Expert 30 |    148 | CPU
DEBUG 01-05 09:59:14.624880.624880 lmp.py:376]   Expert  4 |    150 | CPU
DEBUG 01-05 09:59:14.624047.624047 lmp.py:376]   Expert 41 |    153 | CPU
DEBUG 01-05 09:59:14.624974.624974 lmp.py:376]   Expert 31 |    154 | CPU
DEBUG 01-05 09:59:14.624664.624664 lmp.py:376]   Expert 51 |    157 | CPU
DEBUG 01-05 09:59:14.624353.624353 lmp.py:376]   Expert 57 |    157 | CPU
DEBUG 01-05 09:59:14.624804.624804 lmp.py:376]   Expert 58 |    159 | CPU
DEBUG 01-05 09:59:14.624493.624493 lmp.py:376]   Expert 54 |    168 | CPU
DEBUG 01-05 09:59:14.624421.624421 lmp.py:376]   Expert 25 |    175 | GPU
DEBUG 01-05 09:59:14.624110.624110 lmp.py:376]   Expert 45 |    178 | GPU
DEBUG 01-05 09:59:14.624753.624753 lmp.py:376]   Expert 59 |    178 | GPU
DEBUG 01-05 09:59:14.624873.624873 lmp.py:376]   Expert  9 |    187 | GPU
DEBUG 01-05 09:59:14.624754.624754 lmp.py:376]   Expert 55 |    191 | GPU
DEBUG 01-05 09:59:14.625874.625874 lmp.py:376]   Expert 21 |    193 | GPU
DEBUG 01-05 09:59:14.625517.625517 lmp.py:376]   Expert  0 |    195 | GPU
DEBUG 01-05 09:59:14.625206.625206 lmp.py:376]   Expert 38 |    196 | GPU
DEBUG 01-05 09:59:14.625134.625134 lmp.py:376]   Expert 12 |    209 | GPU
DEBUG 01-05 09:59:14.625062.625062 lmp.py:376]   Expert 29 |    211 | GPU
DEBUG 01-05 09:59:14.625228.625228 lmp.py:376]   Expert  5 |    217 | GPU
DEBUG 01-05 09:59:14.625394.625394 lmp.py:376]   Expert 19 |    218 | GPU
DEBUG 01-05 09:59:14.625083.625083 lmp.py:376]   Expert  6 |    219 | GPU
DEBUG 01-05 09:59:14.625011.625011 lmp.py:376]   Expert 33 |    219 | GPU
DEBUG 01-05 09:59:14.625131.625131 lmp.py:376]   Expert  8 |    221 | GPU
DEBUG 01-05 09:59:14.625012.625012 lmp.py:376]   Expert 13 |    221 | GPU
DEBUG 01-05 09:59:14.625623.625623 lmp.py:376]   Expert 46 |    224 | GPU
DEBUG 01-05 09:59:14.625219.625219 lmp.py:376]   Expert 43 |    229 | GPU
DEBUG 01-05 09:59:14.625670.625670 lmp.py:376]   Expert  2 |    236 | GPU
DEBUG 01-05 09:59:14.625121.625121 lmp.py:376]   Expert 42 |    239 | GPU
DEBUG 01-05 09:59:14.625095.625095 lmp.py:376]   Expert 24 |    250 | GPU
DEBUG 01-05 09:59:14.625069.625069 lmp.py:376]   Expert 17 |    259 | GPU
DEBUG 01-05 09:59:14.625805.625805 lmp.py:376]   Expert 23 |    268 | GPU
DEBUG 01-05 09:59:14.625779.625779 lmp.py:376]   Expert 61 |    279 | GPU
DEBUG 01-05 09:59:14.625753.625753 lmp.py:376]   Expert 27 |    343 | GPU
DEBUG 01-05 09:59:14.625727.625727 lmp.py:376]   Expert 20 |    352 | GPU
DEBUG 01-05 09:59:14.625701.625701 lmp.py:376]   Expert 18 |    375 | GPU
DEBUG 01-05 09:59:14.625913.625913 lmp.py:376]   Expert 48 |    386 | GPU
DEBUG 01-05 09:59:14.625841.625841 lmp.py:376]   Expert 39 |    412 | GPU
DEBUG 01-05 09:59:14.625769.625769 lmp.py:376]   Expert 60 |    482 | GPU
DEBUG 01-05 09:59:14.625696.625696 lmp.py:376]   Expert 56 |    617 | GPU
DEBUG 01-05 09:59:14.625671.625671 lmp.py:376]   Expert 36 |    679 | GPU
DEBUG 01-05 09:59:14.625598.625598 lmp.py:377] 
DEBUG 01-05 09:59:14.625598.625598 lmp.py:377]   CPU total tokens: 3430 (27.9%)
DEBUG 01-05 09:59:14.625526.625526 lmp.py:378]   GPU total tokens: 8858 (72.1%)
DEBUG 01-05 09:59:14.625222.625222 cuda_h.py:19] end experts_map_get cost 0.0015347003936767578 seconds
DEBUG 01-05 09:59:14.625150.625150 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.625463.625463 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.625917.625917 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.626092.626092 cuda_h.py:19] end allocate_cuda_memory cost 0.00044798851013183594 seconds
DEBUG 01-05 09:59:14.626406.626406 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.626016.626016 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.626586.626586 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.626667.626667 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 959d7702-c2ae-405a-a305-cad5a02cccc0
DEBUG 01-05 09:59:14.626806.626806 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.626251.626251 client.py:127] Model loaded
DEBUG 01-05 09:59:14.626922.626922 cuda_h.py:19] end sllm_worker_task cost 0.008864402770996094 seconds
INFO 01-05 09:59:14.627382.627382 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 959d7702-c2ae-405a-a305-cad5a02cccc0
DEBUG 01-05 09:59:14.627040.627040 cuda_h.py:19] end load_into_gpu_async cost 0.0013134479522705078 seconds
DEBUG 01-05 09:59:14.627743.627743 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.628617.628617 cuda_h.py:19] end restore_tensors2 cost 0.0003724098205566406 seconds
DEBUG 01-05 09:59:14.628407.628407 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024657249450683594 seconds
DEBUG 01-05 09:59:14.630182.630182 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005089759826660156 seconds
DEBUG 01-05 09:59:14.630595.630595 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.630955.630955 lmp.py:423] 
DEBUG 01-05 09:59:14.630955.630955 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.630752.630752 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-05 09:59:14.630216.630216 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.646270.646270 mlpmodule.py:704] group tensors cost 0.01571798324584961 s
DEBUG 01-05 09:59:14.650951.650951 mlpmodule.py:742] pad cost 0.002511262893676758 s
DEBUG 01-05 09:59:14.650134.650134 mlpmodule.py:748] create cpu tensor cost 6.0558319091796875e-05 s
DEBUG 01-05 09:59:14.650991.650991 mlpmodule.py:753] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-05 09:59:14.661848.661848 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.661331.661331 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.661738.661738 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 09:59:14.662199.662199 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.680318.680318 mlpmodule.py:793] group einsum cost 0.029846906661987305 s
DEBUG 01-05 09:59:14.681200.681200 mlpmodule.py:801] cpy2cputensor cost 0.0006237030029296875 s
DEBUG 01-05 09:59:14.685417.685417 cuda_h.py:19] end wait_cetm_experts cost 0.05477619171142578 seconds
DEBUG 01-05 09:59:14.685151.685151 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.686516.686516 cuda_h.py:19] end gpu_sexperts cost 0.000576019287109375 seconds
DEBUG 01-05 09:59:14.686889.686889 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.686938.686938 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:59:14.686263.686263 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.686973.686973 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 959d7702-c2ae-405a-a305-cad5a02cccc0
INFO 01-05 09:59:14.687287.687287 client.py:127] Model loaded
DEBUG 01-05 09:59:14.687806.687806 cuda_h.py:19] end wait_experts cost 0.0011410713195800781 seconds
DEBUG 01-05 09:59:14.687939.687939 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.687742.687742 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.688767.688767 mlpmodule.py:531] gpu group tensors cost 0.0006701946258544922 s
DEBUG 01-05 09:59:14.690188.690188 mlpmodule.py:564] gpu pad cost 0.001833200454711914 s
DEBUG 01-05 09:59:14.691369.691369 mlpmodule.py:582] gpu group einsum cost 0.0005643367767333984 s
DEBUG 01-05 09:59:14.695555.695555 mlpmodule.py:611] gpu experts func einsum cost 0.007394075393676758 s
DEBUG 01-05 09:59:14.695790.695790 cuda_h.py:19] end gpu_experts cost 0.0075855255126953125 seconds
DEBUG 01-05 09:59:14.695727.695727 cuda_h.py:19] end layer_moe_generate_6 cost 0.07235240936279297 seconds
DEBUG 01-05 09:59:14.695304.695304 lmp.py:217] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 09:59:14.695027.695027 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 09:59:14.695015.695015 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:59:14.695824.695824 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:59:14.695528.695528 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.361701965332031e-05 seconds
DEBUG 01-05 09:59:14.696947.696947 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.696108.696108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.0001442432403564453 seconds
DEBUG 01-05 09:59:14.696978.696978 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.696708.696708 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.696326.696326 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.699377.699377 cuda_h.py:19] end allocate_cuda_memory cost 0.0032012462615966797 seconds
DEBUG 01-05 09:59:14.699449.699449 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.699172.699172 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.699108.699108 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.699764.699764 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 66086a3f-8239-445c-a8a8-635662dbcc3e
DEBUG 01-05 09:59:14.699787.699787 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.700338.700338 mlpmodule.py:662]  experts func einsum cost 0.06899261474609375 s
DEBUG 01-05 09:59:14.700737.700737 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.700324.700324 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 66086a3f-8239-445c-a8a8-635662dbcc3e
DEBUG 01-05 09:59:14.701650.701650 cuda_h.py:19] end load_into_gpu_async cost 0.0012288093566894531 seconds
DEBUG 01-05 09:59:14.701307.701307 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.701311.701311 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-05 09:59:14.701020.701020 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00492405891418457 seconds
INFO 01-05 09:59:14.701846.701846 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 66086a3f-8239-445c-a8a8-635662dbcc3e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.704334.704334 cuda_h.py:19] end self_attn cost 0.004096269607543945 seconds
DEBUG 01-05 09:59:14.705603.705603 cuda_h.py:19] end iln_self_attn_paln cost 0.008784294128417969 seconds
DEBUG 01-05 09:59:14.705823.705823 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 09:59:14.705924.705924 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.705396.705396 cuda_h.py:19] end gate cost 0.0006308555603027344 seconds
DEBUG 01-05 09:59:14.705749.705749 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.706096.706096 lmp.py:365] 
DEBUG 01-05 09:59:14.706096.706096 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.706091.706091 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.706694.706694 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.706960.706960 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.706603.706603 lmp.py:369] 
DEBUG 01-05 09:59:14.706603.706603 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.706246.706246 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.706896.706896 lmp.py:376]   Expert  1 |     23 | CPU
DEBUG 01-05 09:59:14.706539.706539 lmp.py:376]   Expert  3 |     26 | CPU
DEBUG 01-05 09:59:14.706466.706466 lmp.py:376]   Expert 25 |     47 | CPU
DEBUG 01-05 09:59:14.706156.706156 lmp.py:376]   Expert 40 |     57 | CPU
DEBUG 01-05 09:59:14.706083.706083 lmp.py:376]   Expert 41 |     57 | CPU
DEBUG 01-05 09:59:14.706011.706011 lmp.py:376]   Expert 49 |     57 | CPU
DEBUG 01-05 09:59:14.706892.706892 lmp.py:376]   Expert  8 |     65 | CPU
DEBUG 01-05 09:59:14.706297.706297 lmp.py:376]   Expert 15 |     66 | CPU
DEBUG 01-05 09:59:14.706463.706463 lmp.py:376]   Expert 20 |     67 | CPU
DEBUG 01-05 09:59:14.706106.706106 lmp.py:376]   Expert 31 |     73 | CPU
DEBUG 01-05 09:59:14.706034.706034 lmp.py:376]   Expert 48 |     80 | CPU
DEBUG 01-05 09:59:14.706723.706723 lmp.py:376]   Expert 29 |     82 | CPU
DEBUG 01-05 09:59:14.706174.706174 lmp.py:376]   Expert 16 |     84 | CPU
DEBUG 01-05 09:59:14.706863.706863 lmp.py:376]   Expert 39 |     84 | CPU
DEBUG 01-05 09:59:14.706837.706837 lmp.py:376]   Expert 63 |     90 | CPU
DEBUG 01-05 09:59:14.706527.706527 lmp.py:376]   Expert  5 |     92 | CPU
DEBUG 01-05 09:59:14.706977.706977 lmp.py:376]   Expert  6 |     96 | CPU
DEBUG 01-05 09:59:14.706190.706190 lmp.py:376]   Expert 32 |     98 | CPU
DEBUG 01-05 09:59:14.706879.706879 lmp.py:376]   Expert 18 |    103 | CPU
DEBUG 01-05 09:59:14.706330.706330 lmp.py:376]   Expert 57 |    108 | CPU
DEBUG 01-05 09:59:14.706496.706496 lmp.py:376]   Expert 58 |    113 | CPU
DEBUG 01-05 09:59:14.706662.706662 lmp.py:376]   Expert 59 |    129 | CPU
DEBUG 01-05 09:59:14.706829.706829 lmp.py:376]   Expert 30 |    145 | CPU
DEBUG 01-05 09:59:14.706518.706518 lmp.py:376]   Expert 35 |    145 | CPU
DEBUG 01-05 09:59:14.706922.706922 lmp.py:376]   Expert 53 |    147 | CPU
DEBUG 01-05 09:59:14.706373.706373 lmp.py:376]   Expert 55 |    154 | CPU
DEBUG 01-05 09:59:14.706824.706824 lmp.py:376]   Expert  4 |    161 | CPU
DEBUG 01-05 09:59:14.706037.706037 lmp.py:376]   Expert 34 |    162 | CPU
DEBUG 01-05 09:59:14.706011.706011 lmp.py:376]   Expert 45 |    162 | CPU
DEBUG 01-05 09:59:14.706462.706462 lmp.py:376]   Expert 52 |    164 | CPU
DEBUG 01-05 09:59:14.706436.706436 lmp.py:376]   Expert 26 |    168 | CPU
DEBUG 01-05 09:59:14.706648.706648 lmp.py:376]   Expert  0 |    176 | CPU
DEBUG 01-05 09:59:14.706099.706099 lmp.py:376]   Expert 50 |    180 | GPU
DEBUG 01-05 09:59:14.706265.706265 lmp.py:376]   Expert 54 |    189 | GPU
DEBUG 01-05 09:59:14.706193.706193 lmp.py:376]   Expert  7 |    192 | GPU
DEBUG 01-05 09:59:14.706458.706458 lmp.py:376]   Expert 33 |    197 | GPU
DEBUG 01-05 09:59:14.706386.706386 lmp.py:376]   Expert 19 |    200 | GPU
DEBUG 01-05 09:59:14.706360.706360 lmp.py:376]   Expert 28 |    202 | GPU
DEBUG 01-05 09:59:14.706096.706096 lmp.py:376]   Expert 42 |    203 | GPU
DEBUG 01-05 09:59:14.707831.707831 lmp.py:376]   Expert 21 |    205 | GPU
DEBUG 01-05 09:59:14.707090.707090 lmp.py:376]   Expert 24 |    207 | GPU
DEBUG 01-05 09:59:14.707349.707349 lmp.py:376]   Expert 51 |    210 | GPU
DEBUG 01-05 09:59:14.707846.707846 lmp.py:376]   Expert 17 |    212 | GPU
DEBUG 01-05 09:59:14.707867.707867 lmp.py:376]   Expert 43 |    213 | GPU
DEBUG 01-05 09:59:14.707125.707125 lmp.py:376]   Expert 60 |    214 | GPU
DEBUG 01-05 09:59:14.707623.707623 lmp.py:376]   Expert 27 |    218 | GPU
DEBUG 01-05 09:59:14.707643.707643 lmp.py:376]   Expert 36 |    223 | GPU
DEBUG 01-05 09:59:14.707379.707379 lmp.py:376]   Expert 13 |    227 | GPU
DEBUG 01-05 09:59:14.707114.707114 lmp.py:376]   Expert 10 |    248 | GPU
DEBUG 01-05 09:59:14.707803.707803 lmp.py:376]   Expert 37 |    250 | GPU
DEBUG 01-05 09:59:14.707539.707539 lmp.py:376]   Expert 62 |    254 | GPU
DEBUG 01-05 09:59:14.707752.707752 lmp.py:376]   Expert 47 |    258 | GPU
DEBUG 01-05 09:59:14.707202.707202 lmp.py:376]   Expert 11 |    270 | GPU
DEBUG 01-05 09:59:14.707700.707700 lmp.py:376]   Expert 22 |    279 | GPU
DEBUG 01-05 09:59:14.707958.707958 lmp.py:376]   Expert  2 |    313 | GPU
DEBUG 01-05 09:59:14.707217.707217 lmp.py:376]   Expert 56 |    317 | GPU
DEBUG 01-05 09:59:14.707714.707714 lmp.py:376]   Expert 61 |    322 | GPU
DEBUG 01-05 09:59:14.707735.707735 lmp.py:376]   Expert 14 |    350 | GPU
DEBUG 01-05 09:59:14.707517.707517 lmp.py:376]   Expert 44 |    352 | GPU
DEBUG 01-05 09:59:14.707491.707491 lmp.py:376]   Expert 38 |    355 | GPU
DEBUG 01-05 09:59:14.707988.707988 lmp.py:376]   Expert 46 |    366 | GPU
DEBUG 01-05 09:59:14.707962.707962 lmp.py:376]   Expert 12 |    570 | GPU
DEBUG 01-05 09:59:14.707698.707698 lmp.py:376]   Expert  9 |    572 | GPU
DEBUG 01-05 09:59:14.707910.707910 lmp.py:376]   Expert 23 |    639 | GPU
DEBUG 01-05 09:59:14.707123.707123 lmp.py:377] 
DEBUG 01-05 09:59:14.707123.707123 lmp.py:377]   CPU total tokens: 3281 (26.7%)
DEBUG 01-05 09:59:14.707097.707097 lmp.py:378]   GPU total tokens: 9007 (73.3%)
DEBUG 01-05 09:59:14.707839.707839 cuda_h.py:19] end experts_map_get cost 0.001478433609008789 seconds
DEBUG 01-05 09:59:14.707052.707052 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.707113.707113 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.707243.707243 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.707496.707496 cuda_h.py:19] end allocate_cuda_memory cost 0.00022292137145996094 seconds
DEBUG 01-05 09:59:14.707797.707797 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.707931.707931 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.708932.708932 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.708058.708058 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 09f6f4c7-57f5-4442-a5c7-f91d7f6d8b6e
DEBUG 01-05 09:59:14.708661.708661 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.708483.708483 client.py:127] Model loaded
DEBUG 01-05 09:59:14.708346.708346 cuda_h.py:19] end sllm_worker_task cost 0.012392759323120117 seconds
INFO 01-05 09:59:14.709340.709340 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 09f6f4c7-57f5-4442-a5c7-f91d7f6d8b6e
DEBUG 01-05 09:59:14.709375.709375 cuda_h.py:19] end load_into_gpu_async cost 0.0012021064758300781 seconds
DEBUG 01-05 09:59:14.709839.709839 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.709171.709171 cuda_h.py:19] end restore_tensors2 cost 0.0003936290740966797 seconds
DEBUG 01-05 09:59:14.709915.709915 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021843910217285156 seconds
DEBUG 01-05 09:59:14.712850.712850 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004847288131713867 seconds
DEBUG 01-05 09:59:14.712117.712117 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.712445.712445 lmp.py:423] 
DEBUG 01-05 09:59:14.712445.712445 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.712779.712779 cuda_h.py:19] end cpu_experts_submit cost 0.0001347064971923828 seconds
DEBUG 01-05 09:59:14.712325.712325 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.720789.720789 mlpmodule.py:704] group tensors cost 0.007655143737792969 s
DEBUG 01-05 09:59:14.723782.723782 mlpmodule.py:742] pad cost 0.0016925334930419922 s
DEBUG 01-05 09:59:14.723216.723216 mlpmodule.py:748] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-05 09:59:14.723616.723616 mlpmodule.py:753] move to cpu cost 4.839897155761719e-05 s
DEBUG 01-05 09:59:14.732636.732636 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.732781.732781 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.733479.733479 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 09:59:14.733894.733894 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.750521.750521 mlpmodule.py:793] group einsum cost 0.02695155143737793 s
DEBUG 01-05 09:59:14.751544.751544 mlpmodule.py:801] cpy2cputensor cost 0.0006887912750244141 s
DEBUG 01-05 09:59:14.755848.755848 cuda_h.py:19] end wait_cetm_experts cost 0.04302859306335449 seconds
DEBUG 01-05 09:59:14.755118.755118 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.756358.756358 cuda_h.py:19] end gpu_sexperts cost 0.0005900859832763672 seconds
DEBUG 01-05 09:59:14.756539.756539 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.756111.756111 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:14.756198.756198 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.756623.756623 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 09f6f4c7-57f5-4442-a5c7-f91d7f6d8b6e
INFO 01-05 09:59:14.763267.763267 client.py:127] Model loaded
DEBUG 01-05 09:59:14.763733.763733 cuda_h.py:19] end wait_experts cost 0.006859302520751953 seconds
DEBUG 01-05 09:59:14.763251.763251 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.763530.763530 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.764826.764826 mlpmodule.py:531] gpu group tensors cost 0.000659942626953125 s
DEBUG 01-05 09:59:14.766386.766386 mlpmodule.py:564] gpu pad cost 0.0018317699432373047 s
DEBUG 01-05 09:59:14.766878.766878 mlpmodule.py:582] gpu group einsum cost 0.0005536079406738281 s
DEBUG 01-05 09:59:14.769227.769227 mlpmodule.py:662]  experts func einsum cost 0.05679774284362793 s
DEBUG 01-05 09:59:14.770604.770604 mlpmodule.py:611] gpu experts func einsum cost 0.0066661834716796875 s
DEBUG 01-05 09:59:14.770304.770304 cuda_h.py:19] end gpu_experts cost 0.00689244270324707 seconds
DEBUG 01-05 09:59:14.770459.770459 cuda_h.py:19] end layer_moe_generate_7 cost 0.0654306411743164 seconds
DEBUG 01-05 09:59:14.770557.770557 lmp.py:217] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 09:59:14.770744.770744 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 09:59:14.770294.770294 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:59:14.770620.770620 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:59:14.770833.770833 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.7418136596679688e-05 seconds
DEBUG 01-05 09:59:14.770172.770172 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.128715515136719e-05 seconds
DEBUG 01-05 09:59:14.771292.771292 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.771128.771128 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.771199.771199 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.771419.771419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.771310.771310 cuda_h.py:19] end allocate_cuda_memory cost 0.0002696514129638672 seconds
DEBUG 01-05 09:59:14.771273.771273 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.771605.771605 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.771157.771157 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.771767.771767 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e35e6e59-074b-4645-a2ab-9152d91be670
DEBUG 01-05 09:59:14.771545.771545 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.772406.772406 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.772976.772976 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e35e6e59-074b-4645-a2ab-9152d91be670
DEBUG 01-05 09:59:14.772574.772574 cuda_h.py:19] end load_into_gpu_async cost 0.0012404918670654297 seconds
DEBUG 01-05 09:59:14.772654.772654 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.773214.773214 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-05 09:59:14.773778.773778 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018303394317626953 seconds
INFO 01-05 09:59:14.773556.773556 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e35e6e59-074b-4645-a2ab-9152d91be670
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.775396.775396 cuda_h.py:19] end self_attn cost 0.003774881362915039 seconds
DEBUG 01-05 09:59:14.776618.776618 cuda_h.py:19] end iln_self_attn_paln cost 0.005162239074707031 seconds
DEBUG 01-05 09:59:14.776123.776123 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 09:59:14.776933.776933 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.777429.777429 cuda_h.py:19] end gate cost 0.0007541179656982422 seconds
DEBUG 01-05 09:59:14.777828.777828 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.777129.777129 lmp.py:365] 
DEBUG 01-05 09:59:14.777129.777129 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.777216.777216 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.777628.777628 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.777701.777701 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.777629.777629 lmp.py:369] 
DEBUG 01-05 09:59:14.777629.777629 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.777557.777557 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.777206.777206 lmp.py:376]   Expert  7 |     19 | CPU
DEBUG 01-05 09:59:14.777134.777134 lmp.py:376]   Expert 14 |     27 | CPU
DEBUG 01-05 09:59:14.777347.777347 lmp.py:376]   Expert 27 |     27 | CPU
DEBUG 01-05 09:59:14.777811.777811 lmp.py:376]   Expert 30 |     36 | CPU
DEBUG 01-05 09:59:14.777308.777308 lmp.py:376]   Expert 38 |     43 | CPU
DEBUG 01-05 09:59:14.777044.777044 lmp.py:376]   Expert 12 |     51 | CPU
DEBUG 01-05 09:59:14.777972.777972 lmp.py:376]   Expert 53 |     65 | CPU
DEBUG 01-05 09:59:14.777707.777707 lmp.py:376]   Expert 34 |     66 | CPU
DEBUG 01-05 09:59:14.777966.777966 lmp.py:376]   Expert 36 |     66 | CPU
DEBUG 01-05 09:59:14.777225.777225 lmp.py:376]   Expert 22 |     67 | CPU
DEBUG 01-05 09:59:14.777245.777245 lmp.py:376]   Expert  8 |     71 | CPU
DEBUG 01-05 09:59:14.777981.777981 lmp.py:376]   Expert 26 |     78 | CPU
DEBUG 01-05 09:59:14.777001.777001 lmp.py:376]   Expert 54 |     82 | CPU
DEBUG 01-05 09:59:14.777737.777737 lmp.py:376]   Expert 33 |     90 | CPU
DEBUG 01-05 09:59:14.777996.777996 lmp.py:376]   Expert  1 |     92 | CPU
DEBUG 01-05 09:59:14.777016.777016 lmp.py:376]   Expert 40 |     96 | CPU
DEBUG 01-05 09:59:14.777752.777752 lmp.py:376]   Expert 57 |     97 | CPU
DEBUG 01-05 09:59:14.777249.777249 lmp.py:376]   Expert 13 |    107 | CPU
DEBUG 01-05 09:59:14.777461.777461 lmp.py:376]   Expert  9 |    115 | CPU
DEBUG 01-05 09:59:14.777197.777197 lmp.py:376]   Expert 50 |    115 | CPU
DEBUG 01-05 09:59:14.777456.777456 lmp.py:376]   Expert 29 |    117 | CPU
DEBUG 01-05 09:59:14.777714.777714 lmp.py:376]   Expert 32 |    120 | CPU
DEBUG 01-05 09:59:14.777973.777973 lmp.py:376]   Expert 59 |    124 | CPU
DEBUG 01-05 09:59:14.777755.777755 lmp.py:376]   Expert 17 |    127 | CPU
DEBUG 01-05 09:59:14.777014.777014 lmp.py:376]   Expert 44 |    143 | CPU
DEBUG 01-05 09:59:14.777750.777750 lmp.py:376]   Expert 60 |    146 | CPU
DEBUG 01-05 09:59:14.777247.777247 lmp.py:376]   Expert 24 |    147 | CPU
DEBUG 01-05 09:59:14.777651.777651 lmp.py:376]   Expert 10 |    157 | CPU
DEBUG 01-05 09:59:14.777818.777818 lmp.py:376]   Expert 15 |    164 | CPU
DEBUG 01-05 09:59:14.778507.778507 lmp.py:376]   Expert 16 |    165 | CPU
DEBUG 01-05 09:59:14.778958.778958 lmp.py:376]   Expert 51 |    166 | CPU
DEBUG 01-05 09:59:14.778409.778409 lmp.py:376]   Expert  2 |    168 | CPU
DEBUG 01-05 09:59:14.778383.778383 lmp.py:376]   Expert 56 |    171 | GPU
DEBUG 01-05 09:59:14.778834.778834 lmp.py:376]   Expert 37 |    174 | GPU
DEBUG 01-05 09:59:14.778046.778046 lmp.py:376]   Expert 31 |    188 | GPU
DEBUG 01-05 09:59:14.778782.778782 lmp.py:376]   Expert 39 |    190 | GPU
DEBUG 01-05 09:59:14.778232.778232 lmp.py:376]   Expert 18 |    195 | GPU
DEBUG 01-05 09:59:14.778160.778160 lmp.py:376]   Expert 19 |    203 | GPU
DEBUG 01-05 09:59:14.778611.778611 lmp.py:376]   Expert 58 |    217 | GPU
DEBUG 01-05 09:59:14.778585.778585 lmp.py:376]   Expert 61 |    225 | GPU
DEBUG 01-05 09:59:14.778798.778798 lmp.py:376]   Expert 49 |    232 | GPU
DEBUG 01-05 09:59:14.778772.778772 lmp.py:376]   Expert 41 |    238 | GPU
DEBUG 01-05 09:59:14.778984.778984 lmp.py:376]   Expert 35 |    240 | GPU
DEBUG 01-05 09:59:14.778197.778197 lmp.py:376]   Expert 46 |    246 | GPU
DEBUG 01-05 09:59:14.778409.778409 lmp.py:376]   Expert  0 |    252 | GPU
DEBUG 01-05 09:59:14.778860.778860 lmp.py:376]   Expert 42 |    256 | GPU
DEBUG 01-05 09:59:14.778602.778602 lmp.py:376]   Expert 23 |    260 | GPU
DEBUG 01-05 09:59:14.778576.778576 lmp.py:376]   Expert  6 |    262 | GPU
DEBUG 01-05 09:59:14.778835.778835 lmp.py:376]   Expert  3 |    274 | GPU
DEBUG 01-05 09:59:14.778571.778571 lmp.py:376]   Expert  4 |    281 | GPU
DEBUG 01-05 09:59:14.778830.778830 lmp.py:376]   Expert 28 |    282 | GPU
DEBUG 01-05 09:59:14.778088.778088 lmp.py:376]   Expert 55 |    292 | GPU
DEBUG 01-05 09:59:14.778824.778824 lmp.py:376]   Expert 43 |    299 | GPU
DEBUG 01-05 09:59:14.778083.778083 lmp.py:376]   Expert 20 |    320 | GPU
DEBUG 01-05 09:59:14.778580.778580 lmp.py:376]   Expert 45 |    323 | GPU
DEBUG 01-05 09:59:14.778077.778077 lmp.py:376]   Expert 52 |    327 | GPU
DEBUG 01-05 09:59:14.778051.778051 lmp.py:376]   Expert 48 |    337 | GPU
DEBUG 01-05 09:59:14.778310.778310 lmp.py:376]   Expert 25 |    345 | GPU
DEBUG 01-05 09:59:14.778807.778807 lmp.py:376]   Expert 47 |    345 | GPU
DEBUG 01-05 09:59:14.778589.778589 lmp.py:376]   Expert 11 |    384 | GPU
DEBUG 01-05 09:59:14.778848.778848 lmp.py:376]   Expert 63 |    405 | GPU
DEBUG 01-05 09:59:14.778107.778107 lmp.py:376]   Expert 62 |    410 | GPU
DEBUG 01-05 09:59:14.778366.778366 lmp.py:376]   Expert 21 |    424 | GPU
DEBUG 01-05 09:59:14.778863.778863 lmp.py:376]   Expert  5 |    537 | GPU
DEBUG 01-05 09:59:14.778837.778837 lmp.py:377] 
DEBUG 01-05 09:59:14.778837.778837 lmp.py:377]   CPU total tokens: 3154 (25.7%)
DEBUG 01-05 09:59:14.778049.778049 lmp.py:378]   GPU total tokens: 9134 (74.3%)
DEBUG 01-05 09:59:14.778792.778792 cuda_h.py:19] end experts_map_get cost 0.0014557838439941406 seconds
DEBUG 01-05 09:59:14.778349.778349 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.778648.778648 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.778302.778302 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.779447.779447 cuda_h.py:19] end allocate_cuda_memory cost 0.0007431507110595703 seconds
DEBUG 01-05 09:59:14.779244.779244 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.779569.779569 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.779538.779538 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.779234.779234 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6c39b3c7-8813-4d62-8937-e0cb7e2ab718
DEBUG 01-05 09:59:14.779631.779631 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.780659.780659 client.py:127] Model loaded
DEBUG 01-05 09:59:14.780516.780516 cuda_h.py:19] end sllm_worker_task cost 0.009088754653930664 seconds
INFO 01-05 09:59:14.780095.780095 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6c39b3c7-8813-4d62-8937-e0cb7e2ab718
DEBUG 01-05 09:59:14.780368.780368 cuda_h.py:19] end load_into_gpu_async cost 0.0013229846954345703 seconds
DEBUG 01-05 09:59:14.781310.781310 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.781000.781000 cuda_h.py:19] end restore_tensors2 cost 0.00041294097900390625 seconds
DEBUG 01-05 09:59:14.781936.781936 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002820730209350586 seconds
DEBUG 01-05 09:59:14.784194.784194 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005443096160888672 seconds
DEBUG 01-05 09:59:14.784454.784454 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.784364.784364 lmp.py:423] 
DEBUG 01-05 09:59:14.784364.784364 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.784445.784445 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 09:59:14.784810.784810 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.800406.800406 mlpmodule.py:704] group tensors cost 0.01607680320739746 s
DEBUG 01-05 09:59:14.803133.803133 mlpmodule.py:742] pad cost 0.0018486976623535156 s
DEBUG 01-05 09:59:14.803588.803588 mlpmodule.py:748] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-05 09:59:14.803298.803298 mlpmodule.py:753] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-05 09:59:14.814109.814109 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.814969.814969 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.814528.814528 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 09:59:14.814056.814056 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.831235.831235 mlpmodule.py:793] group einsum cost 0.027679443359375 s
DEBUG 01-05 09:59:14.832841.832841 mlpmodule.py:801] cpy2cputensor cost 0.000698089599609375 s
DEBUG 01-05 09:59:14.836497.836497 cuda_h.py:19] end wait_cetm_experts cost 0.05246543884277344 seconds
DEBUG 01-05 09:59:14.837860.837860 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.837563.837563 cuda_h.py:19] end gpu_sexperts cost 0.000568389892578125 seconds
DEBUG 01-05 09:59:14.837221.837221 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.837269.837269 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:59:14.837926.837926 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.837874.837874 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6c39b3c7-8813-4d62-8937-e0cb7e2ab718
INFO 01-05 09:59:14.838638.838638 client.py:127] Model loaded
DEBUG 01-05 09:59:14.838435.838435 cuda_h.py:19] end wait_experts cost 0.0011172294616699219 seconds
DEBUG 01-05 09:59:14.838330.838330 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.839132.839132 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.839839.839839 mlpmodule.py:531] gpu group tensors cost 0.0006439685821533203 s
DEBUG 01-05 09:59:14.841185.841185 mlpmodule.py:564] gpu pad cost 0.0017788410186767578 s
DEBUG 01-05 09:59:14.842749.842749 mlpmodule.py:582] gpu group einsum cost 0.0005533695220947266 s
DEBUG 01-05 09:59:14.845793.845793 mlpmodule.py:611] gpu experts func einsum cost 0.006613492965698242 s
DEBUG 01-05 09:59:14.845644.845644 cuda_h.py:19] end gpu_experts cost 0.006803989410400391 seconds
DEBUG 01-05 09:59:14.845820.845820 cuda_h.py:19] end layer_moe_generate_8 cost 0.06961846351623535 seconds
DEBUG 01-05 09:59:14.846936.846936 lmp.py:217] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 09:59:14.846136.846136 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 09:59:14.846600.846600 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:59:14.846014.846014 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:59:14.846202.846202 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.409385681152344e-05 seconds
DEBUG 01-05 09:59:14.846528.846528 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.846365.846365 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.00015425682067871094 seconds
DEBUG 01-05 09:59:14.846281.846281 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.846111.846111 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.846060.846060 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.850287.850287 cuda_h.py:19] end allocate_cuda_memory cost 0.003725767135620117 seconds
DEBUG 01-05 09:59:14.850608.850608 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.850656.850656 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.850905.850905 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.850853.850853 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b2c23070-d49e-4a1e-b6f4-efa113deaac7
DEBUG 01-05 09:59:14.850061.850061 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.851896.851896 mlpmodule.py:662]  experts func einsum cost 0.06653618812561035 s
DEBUG 01-05 09:59:14.851102.851102 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.851001.851001 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b2c23070-d49e-4a1e-b6f4-efa113deaac7
DEBUG 01-05 09:59:14.851129.851129 cuda_h.py:19] end load_into_gpu_async cost 0.001260995864868164 seconds
DEBUG 01-05 09:59:14.851355.851355 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.852338.852338 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-05 09:59:14.852948.852948 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005381584167480469 seconds
INFO 01-05 09:59:14.852796.852796 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b2c23070-d49e-4a1e-b6f4-efa113deaac7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.855899.855899 cuda_h.py:19] end self_attn cost 0.003920793533325195 seconds
DEBUG 01-05 09:59:14.855670.855670 cuda_h.py:19] end iln_self_attn_paln cost 0.009068965911865234 seconds
DEBUG 01-05 09:59:14.855891.855891 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 09:59:14.855130.855130 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.856716.856716 cuda_h.py:19] end gate cost 0.0006449222564697266 seconds
DEBUG 01-05 09:59:14.856068.856068 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.856714.856714 lmp.py:365] 
DEBUG 01-05 09:59:14.856714.856714 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.857470.857470 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.857358.857358 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.857147.857147 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.857313.857313 lmp.py:369] 
DEBUG 01-05 09:59:14.857313.857313 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.857241.857241 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.857560.857560 lmp.py:376]   Expert 35 |     29 | CPU
DEBUG 01-05 09:59:14.857156.857156 lmp.py:376]   Expert  7 |     36 | CPU
DEBUG 01-05 09:59:14.857038.857038 lmp.py:376]   Expert 26 |     45 | CPU
DEBUG 01-05 09:59:14.857442.857442 lmp.py:376]   Expert  6 |     47 | CPU
DEBUG 01-05 09:59:14.857608.857608 lmp.py:376]   Expert  2 |     48 | CPU
DEBUG 01-05 09:59:14.857775.857775 lmp.py:376]   Expert  5 |     52 | CPU
DEBUG 01-05 09:59:14.857702.857702 lmp.py:376]   Expert 60 |     56 | CPU
DEBUG 01-05 09:59:14.857868.857868 lmp.py:376]   Expert 13 |     59 | CPU
DEBUG 01-05 09:59:14.857035.857035 lmp.py:376]   Expert 38 |     61 | CPU
DEBUG 01-05 09:59:14.857962.857962 lmp.py:376]   Expert 19 |     65 | CPU
DEBUG 01-05 09:59:14.857890.857890 lmp.py:376]   Expert 48 |     72 | CPU
DEBUG 01-05 09:59:14.857056.857056 lmp.py:376]   Expert 25 |     74 | CPU
DEBUG 01-05 09:59:14.857222.857222 lmp.py:376]   Expert 39 |     78 | CPU
DEBUG 01-05 09:59:14.857342.857342 lmp.py:376]   Expert 17 |     81 | CPU
DEBUG 01-05 09:59:14.857270.857270 lmp.py:376]   Expert 45 |     91 | CPU
DEBUG 01-05 09:59:14.857959.857959 lmp.py:376]   Expert 52 |     92 | CPU
DEBUG 01-05 09:59:14.857887.857887 lmp.py:376]   Expert 54 |     94 | CPU
DEBUG 01-05 09:59:14.857053.857053 lmp.py:376]   Expert 27 |    101 | CPU
DEBUG 01-05 09:59:14.857981.857981 lmp.py:376]   Expert 59 |    122 | CPU
DEBUG 01-05 09:59:14.857670.857670 lmp.py:376]   Expert 29 |    130 | CPU
DEBUG 01-05 09:59:14.857359.857359 lmp.py:376]   Expert 24 |    134 | CPU
DEBUG 01-05 09:59:14.857572.857572 lmp.py:376]   Expert 16 |    148 | CPU
DEBUG 01-05 09:59:14.857261.857261 lmp.py:376]   Expert 57 |    151 | CPU
DEBUG 01-05 09:59:14.857189.857189 lmp.py:376]   Expert 49 |    155 | CPU
DEBUG 01-05 09:59:14.857878.857878 lmp.py:376]   Expert 40 |    156 | CPU
DEBUG 01-05 09:59:14.857806.857806 lmp.py:376]   Expert 62 |    157 | CPU
DEBUG 01-05 09:59:14.857495.857495 lmp.py:376]   Expert 14 |    160 | CPU
DEBUG 01-05 09:59:14.857184.857184 lmp.py:376]   Expert 20 |    161 | CPU
DEBUG 01-05 09:59:14.857795.857795 lmp.py:376]   Expert 12 |    166 | CPU
DEBUG 01-05 09:59:14.857246.857246 lmp.py:376]   Expert 30 |    166 | CPU
DEBUG 01-05 09:59:14.857935.857935 lmp.py:376]   Expert 32 |    168 | CPU
DEBUG 01-05 09:59:14.857386.857386 lmp.py:376]   Expert 22 |    171 | CPU
DEBUG 01-05 09:59:14.857075.857075 lmp.py:376]   Expert 42 |    172 | GPU
DEBUG 01-05 09:59:14.857049.857049 lmp.py:376]   Expert 28 |    174 | GPU
DEBUG 01-05 09:59:14.857500.857500 lmp.py:376]   Expert 31 |    179 | GPU
DEBUG 01-05 09:59:14.857712.857712 lmp.py:376]   Expert 18 |    183 | GPU
DEBUG 01-05 09:59:14.857402.857402 lmp.py:376]   Expert  1 |    185 | GPU
DEBUG 01-05 09:59:14.857329.857329 lmp.py:376]   Expert 11 |    185 | GPU
DEBUG 01-05 09:59:14.857496.857496 lmp.py:376]   Expert 41 |    187 | GPU
DEBUG 01-05 09:59:14.857185.857185 lmp.py:376]   Expert 23 |    188 | GPU
DEBUG 01-05 09:59:14.857874.857874 lmp.py:376]   Expert 33 |    190 | GPU
DEBUG 01-05 09:59:14.857087.857087 lmp.py:376]   Expert 43 |    190 | GPU
DEBUG 01-05 09:59:14.857538.857538 lmp.py:376]   Expert 58 |    190 | GPU
DEBUG 01-05 09:59:14.857988.857988 lmp.py:376]   Expert 10 |    206 | GPU
DEBUG 01-05 09:59:14.857439.857439 lmp.py:376]   Expert 34 |    207 | GPU
DEBUG 01-05 09:59:14.857129.857129 lmp.py:376]   Expert  3 |    208 | GPU
DEBUG 01-05 09:59:14.857579.857579 lmp.py:376]   Expert 50 |    216 | GPU
DEBUG 01-05 09:59:14.857984.857984 lmp.py:376]   Expert  4 |    228 | GPU
DEBUG 01-05 09:59:14.857912.857912 lmp.py:376]   Expert 51 |    228 | GPU
DEBUG 01-05 09:59:14.857601.857601 lmp.py:376]   Expert 47 |    231 | GPU
DEBUG 01-05 09:59:14.857814.857814 lmp.py:376]   Expert 53 |    238 | GPU
DEBUG 01-05 09:59:14.857026.857026 lmp.py:376]   Expert 36 |    252 | GPU
DEBUG 01-05 09:59:14.858477.858477 lmp.py:376]   Expert 44 |    284 | GPU
DEBUG 01-05 09:59:14.858689.858689 lmp.py:376]   Expert  0 |    297 | GPU
DEBUG 01-05 09:59:14.858902.858902 lmp.py:376]   Expert 61 |    311 | GPU
DEBUG 01-05 09:59:14.858114.858114 lmp.py:376]   Expert 37 |    341 | GPU
DEBUG 01-05 09:59:14.858565.858565 lmp.py:376]   Expert 55 |    353 | GPU
DEBUG 01-05 09:59:14.858493.858493 lmp.py:376]   Expert  9 |    368 | GPU
DEBUG 01-05 09:59:14.858182.858182 lmp.py:376]   Expert  8 |    381 | GPU
DEBUG 01-05 09:59:14.858395.858395 lmp.py:376]   Expert 63 |    470 | GPU
DEBUG 01-05 09:59:14.858845.858845 lmp.py:376]   Expert 46 |    489 | GPU
DEBUG 01-05 09:59:14.858058.858058 lmp.py:376]   Expert 15 |    493 | GPU
DEBUG 01-05 09:59:14.858270.858270 lmp.py:376]   Expert 21 |    557 | GPU
DEBUG 01-05 09:59:14.858721.858721 lmp.py:376]   Expert 56 |    581 | GPU
DEBUG 01-05 09:59:14.858887.858887 lmp.py:377] 
DEBUG 01-05 09:59:14.858887.858887 lmp.py:377]   CPU total tokens: 3326 (27.1%)
DEBUG 01-05 09:59:14.858292.858292 lmp.py:378]   GPU total tokens: 8962 (72.9%)
DEBUG 01-05 09:59:14.858465.858465 cuda_h.py:19] end experts_map_get cost 0.0015273094177246094 seconds
DEBUG 01-05 09:59:14.858538.858538 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.858699.858699 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.858968.858968 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.858878.858878 cuda_h.py:19] end allocate_cuda_memory cost 0.0002522468566894531 seconds
DEBUG 01-05 09:59:14.858689.858689 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.858729.858729 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.858916.858916 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.858327.858327 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32373821-440a-4f9c-a4b7-2cc6cdf31729
DEBUG 01-05 09:59:14.859976.859976 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.859432.859432 client.py:127] Model loaded
DEBUG 01-05 09:59:14.859573.859573 cuda_h.py:19] end sllm_worker_task cost 0.01268625259399414 seconds
INFO 01-05 09:59:14.860667.860667 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32373821-440a-4f9c-a4b7-2cc6cdf31729
DEBUG 01-05 09:59:14.860139.860139 cuda_h.py:19] end load_into_gpu_async cost 0.0015568733215332031 seconds
DEBUG 01-05 09:59:14.860379.860379 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.860403.860403 cuda_h.py:19] end restore_tensors2 cost 0.0004773139953613281 seconds
DEBUG 01-05 09:59:14.860007.860007 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026636123657226562 seconds
DEBUG 01-05 09:59:14.863953.863953 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005228757858276367 seconds
DEBUG 01-05 09:59:14.863643.863643 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.863361.863361 lmp.py:423] 
DEBUG 01-05 09:59:14.863361.863361 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.863972.863972 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-05 09:59:14.863622.863622 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.869357.869357 mlpmodule.py:704] group tensors cost 0.0059087276458740234 s
DEBUG 01-05 09:59:14.872039.872039 mlpmodule.py:742] pad cost 0.002105712890625 s
DEBUG 01-05 09:59:14.872560.872560 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:59:14.873391.873391 mlpmodule.py:753] move to cpu cost 3.814697265625e-05 s
DEBUG 01-05 09:59:14.882973.882973 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.882263.882263 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.882002.882002 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:59:14.883065.883065 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.899975.899975 mlpmodule.py:793] group einsum cost 0.026849746704101562 s
DEBUG 01-05 09:59:14.900368.900368 mlpmodule.py:801] cpy2cputensor cost 0.0006482601165771484 s
DEBUG 01-05 09:59:14.905809.905809 cuda_h.py:19] end wait_cetm_experts cost 0.041493892669677734 seconds
DEBUG 01-05 09:59:14.905556.905556 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.906722.906722 cuda_h.py:19] end gpu_sexperts cost 0.0005674362182617188 seconds
DEBUG 01-05 09:59:14.906903.906903 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.906521.906521 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:14.906238.906238 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.906617.906617 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32373821-440a-4f9c-a4b7-2cc6cdf31729
INFO 01-05 09:59:14.915302.915302 client.py:127] Model loaded
DEBUG 01-05 09:59:14.915436.915436 cuda_h.py:19] end wait_experts cost 0.009454727172851562 seconds
DEBUG 01-05 09:59:14.915616.915616 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.915796.915796 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.916916.916916 mlpmodule.py:531] gpu group tensors cost 0.0005371570587158203 s
DEBUG 01-05 09:59:14.917795.917795 mlpmodule.py:564] gpu pad cost 0.0014679431915283203 s
DEBUG 01-05 09:59:14.918514.918514 mlpmodule.py:582] gpu group einsum cost 0.0004730224609375 s
DEBUG 01-05 09:59:14.918378.918378 mlpmodule.py:662]  experts func einsum cost 0.054834842681884766 s
DEBUG 01-05 09:59:14.921972.921972 mlpmodule.py:611] gpu experts func einsum cost 0.005979299545288086 s
DEBUG 01-05 09:59:14.921566.921566 cuda_h.py:19] end gpu_experts cost 0.0061872005462646484 seconds
DEBUG 01-05 09:59:14.922297.922297 cuda_h.py:19] end layer_moe_generate_9 cost 0.06610441207885742 seconds
DEBUG 01-05 09:59:14.922819.922819 lmp.py:217] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 09:59:14.922721.922721 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 09:59:14.922510.922510 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:59:14.922643.922643 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:59:14.922956.922956 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 09:59:14.922024.922024 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.43865966796875e-05 seconds
DEBUG 01-05 09:59:14.922528.922528 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.922517.922517 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.922799.922799 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.922604.922604 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.923511.923511 cuda_h.py:19] end allocate_cuda_memory cost 0.00033926963806152344 seconds
DEBUG 01-05 09:59:14.923977.923977 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.923608.923608 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.923630.923630 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.923339.923339 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dcb97ab8-e43c-47dd-8b14-670689d0dc60
DEBUG 01-05 09:59:14.923641.923641 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.923053.923053 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.924458.924458 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dcb97ab8-e43c-47dd-8b14-670689d0dc60
DEBUG 01-05 09:59:14.924215.924215 cuda_h.py:19] end load_into_gpu_async cost 0.0013246536254882812 seconds
DEBUG 01-05 09:59:14.924402.924402 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.924505.924505 cuda_h.py:19] end restore_tensors2 cost 7.772445678710938e-05 seconds
DEBUG 01-05 09:59:14.924221.924221 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020601749420166016 seconds
INFO 01-05 09:59:14.925088.925088 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dcb97ab8-e43c-47dd-8b14-670689d0dc60
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.927254.927254 cuda_h.py:19] end self_attn cost 0.0035619735717773438 seconds
DEBUG 01-05 09:59:14.927853.927853 cuda_h.py:19] end iln_self_attn_paln cost 0.005126953125 seconds
DEBUG 01-05 09:59:14.927643.927643 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 09:59:14.927406.927406 cuda_h.py:10] start gate
DEBUG 01-05 09:59:14.928388.928388 cuda_h.py:19] end gate cost 0.0006134510040283203 seconds
DEBUG 01-05 09:59:14.928039.928039 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:14.928002.928002 lmp.py:365] 
DEBUG 01-05 09:59:14.928002.928002 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:14.928805.928805 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:14.928216.928216 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:14.928813.928813 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:14.928502.928502 lmp.py:369] 
DEBUG 01-05 09:59:14.928502.928502 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:14.928622.928622 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:14.928987.928987 lmp.py:376]   Expert 34 |      5 | CPU
DEBUG 01-05 09:59:14.928630.928630 lmp.py:376]   Expert  3 |     21 | CPU
DEBUG 01-05 09:59:14.928796.928796 lmp.py:376]   Expert 61 |     23 | CPU
DEBUG 01-05 09:59:14.928485.928485 lmp.py:376]   Expert 14 |     26 | CPU
DEBUG 01-05 09:59:14.928698.928698 lmp.py:376]   Expert 48 |     39 | CPU
DEBUG 01-05 09:59:14.928341.928341 lmp.py:376]   Expert 32 |     49 | CPU
DEBUG 01-05 09:59:14.928745.928745 lmp.py:376]   Expert 55 |     51 | CPU
DEBUG 01-05 09:59:14.928435.928435 lmp.py:376]   Expert 47 |     52 | CPU
DEBUG 01-05 09:59:14.928124.928124 lmp.py:376]   Expert 15 |     67 | CPU
DEBUG 01-05 09:59:14.928575.928575 lmp.py:376]   Expert 27 |     68 | CPU
DEBUG 01-05 09:59:14.928787.928787 lmp.py:376]   Expert 13 |     69 | CPU
DEBUG 01-05 09:59:14.929000.929000 lmp.py:376]   Expert 44 |     78 | CPU
DEBUG 01-05 09:59:14.929451.929451 lmp.py:376]   Expert 12 |     79 | CPU
DEBUG 01-05 09:59:14.929140.929140 lmp.py:376]   Expert  7 |     82 | CPU
DEBUG 01-05 09:59:14.929591.929591 lmp.py:376]   Expert 19 |     83 | CPU
DEBUG 01-05 09:59:14.929995.929995 lmp.py:376]   Expert  6 |     84 | CPU
DEBUG 01-05 09:59:14.929685.929685 lmp.py:376]   Expert 54 |    101 | CPU
DEBUG 01-05 09:59:14.929374.929374 lmp.py:376]   Expert 50 |    103 | CPU
DEBUG 01-05 09:59:14.929825.929825 lmp.py:376]   Expert 26 |    104 | CPU
DEBUG 01-05 09:59:14.929276.929276 lmp.py:376]   Expert 28 |    109 | CPU
DEBUG 01-05 09:59:14.929727.929727 lmp.py:376]   Expert 56 |    112 | CPU
DEBUG 01-05 09:59:14.929939.929939 lmp.py:376]   Expert 38 |    113 | CPU
DEBUG 01-05 09:59:14.929628.929628 lmp.py:376]   Expert 62 |    116 | CPU
DEBUG 01-05 09:59:14.929795.929795 lmp.py:376]   Expert 20 |    117 | CPU
DEBUG 01-05 09:59:14.929245.929245 lmp.py:376]   Expert 46 |    120 | CPU
DEBUG 01-05 09:59:14.929935.929935 lmp.py:376]   Expert 37 |    131 | CPU
DEBUG 01-05 09:59:14.929147.929147 lmp.py:376]   Expert 43 |    133 | CPU
DEBUG 01-05 09:59:14.929836.929836 lmp.py:376]   Expert 35 |    143 | CPU
DEBUG 01-05 09:59:14.929049.929049 lmp.py:376]   Expert 36 |    155 | CPU
DEBUG 01-05 09:59:14.929261.929261 lmp.py:376]   Expert 52 |    160 | CPU
DEBUG 01-05 09:59:14.929712.929712 lmp.py:376]   Expert 60 |    160 | CPU
DEBUG 01-05 09:59:14.929355.929355 lmp.py:376]   Expert 45 |    163 | CPU
DEBUG 01-05 09:59:14.929521.929521 lmp.py:376]   Expert 29 |    169 | GPU
DEBUG 01-05 09:59:14.929449.929449 lmp.py:376]   Expert 17 |    170 | GPU
DEBUG 01-05 09:59:14.929900.929900 lmp.py:376]   Expert 25 |    172 | GPU
DEBUG 01-05 09:59:14.929112.929112 lmp.py:376]   Expert 41 |    178 | GPU
DEBUG 01-05 09:59:14.929802.929802 lmp.py:376]   Expert 22 |    183 | GPU
DEBUG 01-05 09:59:14.929776.929776 lmp.py:376]   Expert 24 |    185 | GPU
DEBUG 01-05 09:59:14.929227.929227 lmp.py:376]   Expert 51 |    190 | GPU
DEBUG 01-05 09:59:14.929678.929678 lmp.py:376]   Expert 63 |    191 | GPU
DEBUG 01-05 09:59:14.929128.929128 lmp.py:376]   Expert  2 |    199 | GPU
DEBUG 01-05 09:59:14.929341.929341 lmp.py:376]   Expert 42 |    208 | GPU
DEBUG 01-05 09:59:14.929620.929620 lmp.py:376]   Expert 57 |    212 | GPU
DEBUG 01-05 09:59:14.929548.929548 lmp.py:376]   Expert  5 |    224 | GPU
DEBUG 01-05 09:59:14.929045.929045 lmp.py:376]   Expert 21 |    235 | GPU
DEBUG 01-05 09:59:14.929542.929542 lmp.py:376]   Expert 31 |    240 | GPU
DEBUG 01-05 09:59:14.929039.929039 lmp.py:376]   Expert 59 |    240 | GPU
DEBUG 01-05 09:59:14.929537.929537 lmp.py:376]   Expert 18 |    248 | GPU
DEBUG 01-05 09:59:14.929795.929795 lmp.py:376]   Expert 53 |    257 | GPU
DEBUG 01-05 09:59:14.929293.929293 lmp.py:376]   Expert 30 |    262 | GPU
DEBUG 01-05 09:59:14.929551.929551 lmp.py:376]   Expert 39 |    266 | GPU
DEBUG 01-05 09:59:14.929810.929810 lmp.py:376]   Expert 16 |    278 | GPU
DEBUG 01-05 09:59:14.929069.929069 lmp.py:376]   Expert  8 |    291 | GPU
DEBUG 01-05 09:59:14.929566.929566 lmp.py:376]   Expert  9 |    300 | GPU
DEBUG 01-05 09:59:14.929779.929779 lmp.py:376]   Expert 10 |    310 | GPU
DEBUG 01-05 09:59:14.929991.929991 lmp.py:376]   Expert 33 |    350 | GPU
DEBUG 01-05 09:59:14.929488.929488 lmp.py:376]   Expert 49 |    353 | GPU
DEBUG 01-05 09:59:14.929747.929747 lmp.py:376]   Expert 23 |    367 | GPU
DEBUG 01-05 09:59:14.929006.929006 lmp.py:376]   Expert 40 |    417 | GPU
DEBUG 01-05 09:59:14.929265.929265 lmp.py:376]   Expert  0 |    443 | GPU
DEBUG 01-05 09:59:14.929000.929000 lmp.py:376]   Expert 58 |    512 | GPU
DEBUG 01-05 09:59:14.929021.929021 lmp.py:376]   Expert 11 |    520 | GPU
DEBUG 01-05 09:59:14.929756.929756 lmp.py:376]   Expert  1 |    585 | GPU
DEBUG 01-05 09:59:14.929015.929015 lmp.py:376]   Expert  4 |    617 | GPU
DEBUG 01-05 09:59:14.929658.929658 lmp.py:377] 
DEBUG 01-05 09:59:14.929658.929658 lmp.py:377]   CPU total tokens: 2916 (23.7%)
DEBUG 01-05 09:59:14.929347.929347 lmp.py:378]   GPU total tokens: 9372 (76.3%)
DEBUG 01-05 09:59:14.929090.929090 cuda_h.py:19] end experts_map_get cost 0.0014827251434326172 seconds
DEBUG 01-05 09:59:14.929779.929779 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:14.929224.929224 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.930686.930686 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.931371.931371 cuda_h.py:19] end allocate_cuda_memory cost 0.0016293525695800781 seconds
DEBUG 01-05 09:59:14.931280.931280 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.931606.931606 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.931461.931461 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.931065.931065 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 75957dee-88c5-4e35-84a9-a1916a61f0fd
DEBUG 01-05 09:59:14.932561.932561 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:14.932275.932275 client.py:127] Model loaded
DEBUG 01-05 09:59:14.932582.932582 cuda_h.py:19] end sllm_worker_task cost 0.009956836700439453 seconds
INFO 01-05 09:59:14.933259.933259 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 75957dee-88c5-4e35-84a9-a1916a61f0fd
DEBUG 01-05 09:59:14.933725.933725 cuda_h.py:19] end load_into_gpu_async cost 0.0013837814331054688 seconds
DEBUG 01-05 09:59:14.933905.933905 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.933847.933847 cuda_h.py:19] end restore_tensors2 cost 0.0004215240478515625 seconds
DEBUG 01-05 09:59:14.933683.933683 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003793001174926758 seconds
DEBUG 01-05 09:59:14.936866.936866 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006323814392089844 seconds
DEBUG 01-05 09:59:14.936795.936795 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:14.936785.936785 lmp.py:423] 
DEBUG 01-05 09:59:14.936785.936785 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:14.936019.936019 cuda_h.py:19] end cpu_experts_submit cost 0.00013780593872070312 seconds
DEBUG 01-05 09:59:14.936483.936483 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:14.948386.948386 mlpmodule.py:704] group tensors cost 0.011538505554199219 s
DEBUG 01-05 09:59:14.950545.950545 mlpmodule.py:742] pad cost 0.0014262199401855469 s
DEBUG 01-05 09:59:14.950190.950190 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-05 09:59:14.950987.950987 mlpmodule.py:753] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-05 09:59:14.959954.959954 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:14.959808.959808 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:14.959129.959129 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 09:59:14.959875.959875 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:14.976492.976492 mlpmodule.py:793] group einsum cost 0.02568960189819336 s
DEBUG 01-05 09:59:14.977766.977766 mlpmodule.py:801] cpy2cputensor cost 0.0006773471832275391 s
DEBUG 01-05 09:59:14.981238.981238 cuda_h.py:19] end wait_cetm_experts cost 0.04523897171020508 seconds
DEBUG 01-05 09:59:14.981162.981162 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:14.982695.982695 cuda_h.py:19] end gpu_sexperts cost 0.0004558563232421875 seconds
DEBUG 01-05 09:59:14.982677.982677 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:14.982480.982480 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.765655517578125e-05 seconds
DEBUG 01-05 09:59:14.982898.982898 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:14.982085.982085 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 75957dee-88c5-4e35-84a9-a1916a61f0fd
INFO 01-05 09:59:14.988870.988870 client.py:127] Model loaded
DEBUG 01-05 09:59:14.988290.988290 cuda_h.py:19] end wait_experts cost 0.005524635314941406 seconds
DEBUG 01-05 09:59:14.988615.988615 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:14.988894.988894 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:14.988502.988502 mlpmodule.py:531] gpu group tensors cost 0.0006508827209472656 s
DEBUG 01-05 09:59:14.990645.990645 mlpmodule.py:564] gpu pad cost 0.001665353775024414 s
DEBUG 01-05 09:59:14.991613.991613 mlpmodule.py:582] gpu group einsum cost 0.0005435943603515625 s
DEBUG 01-05 09:59:14.994105.994105 mlpmodule.py:611] gpu experts func einsum cost 0.006011247634887695 s
DEBUG 01-05 09:59:14.994248.994248 cuda_h.py:19] end gpu_experts cost 0.006195545196533203 seconds
DEBUG 01-05 09:59:14.994310.994310 cuda_h.py:19] end layer_moe_generate_10 cost 0.06675314903259277 seconds
DEBUG 01-05 09:59:14.994024.994024 lmp.py:217] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 09:59:14.994880.994880 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 09:59:14.994622.994622 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:59:14.994239.994239 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:59:14.994937.994937 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.8133392333984375e-05 seconds
DEBUG 01-05 09:59:14.994355.994355 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.246566772460938e-05 seconds
DEBUG 01-05 09:59:14.994998.994998 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:14.994655.994655 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:14.994519.994519 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:14.994401.994401 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:14.995678.995678 cuda_h.py:19] end allocate_cuda_memory cost 0.00030803680419921875 seconds
DEBUG 01-05 09:59:14.995563.995563 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:14.995233.995233 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:14.995102.995102 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:14.995805.995805 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6c985be6-14a4-4bef-9e64-18086943978d
DEBUG 01-05 09:59:14.995444.995444 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:14.995036.995036 cuda_h.py:10] start self_attn
INFO 01-05 09:59:14.996584.996584 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6c985be6-14a4-4bef-9e64-18086943978d
DEBUG 01-05 09:59:14.996421.996421 cuda_h.py:19] end load_into_gpu_async cost 0.001050710678100586 seconds
DEBUG 01-05 09:59:14.996216.996216 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:14.996530.996530 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-05 09:59:14.996094.996094 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017244815826416016 seconds
INFO 01-05 09:59:14.997476.997476 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6c985be6-14a4-4bef-9e64-18086943978d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:14.999905.999905 cuda_h.py:19] end self_attn cost 0.0035266876220703125 seconds
DEBUG 01-05 09:59:14.999378.999378 cuda_h.py:19] end iln_self_attn_paln cost 0.00499272346496582 seconds
DEBUG 01-05 09:59:14.999929.999929 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 09:59:14.999407.999407 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.000934.000934 cuda_h.py:19] end gate cost 0.0006694793701171875 seconds
DEBUG 01-05 09:59:15.000810.000810 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.000972.000972 lmp.py:365] 
DEBUG 01-05 09:59:15.000972.000972 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.000728.000728 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.001808.001808 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.001312.001312 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.001955.001955 lmp.py:369] 
DEBUG 01-05 09:59:15.001955.001955 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.001598.001598 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.001963.001963 lmp.py:376]   Expert 19 |     15 | CPU
DEBUG 01-05 09:59:15.001845.001845 lmp.py:376]   Expert 35 |     15 | CPU
DEBUG 01-05 09:59:15.001249.001249 lmp.py:376]   Expert 39 |     23 | CPU
DEBUG 01-05 09:59:15.001654.001654 lmp.py:376]   Expert 16 |     31 | CPU
DEBUG 01-05 09:59:15.001058.001058 lmp.py:376]   Expert 59 |     38 | CPU
DEBUG 01-05 09:59:15.001894.001894 lmp.py:376]   Expert 49 |     47 | CPU
DEBUG 01-05 09:59:15.001298.001298 lmp.py:376]   Expert 41 |     54 | CPU
DEBUG 01-05 09:59:15.001703.001703 lmp.py:376]   Expert 17 |     57 | CPU
DEBUG 01-05 09:59:15.001107.001107 lmp.py:376]   Expert  5 |     70 | CPU
DEBUG 01-05 09:59:15.001796.001796 lmp.py:376]   Expert  7 |     75 | CPU
DEBUG 01-05 09:59:15.001963.001963 lmp.py:376]   Expert  3 |     77 | CPU
DEBUG 01-05 09:59:15.001890.001890 lmp.py:376]   Expert  8 |     77 | CPU
DEBUG 01-05 09:59:15.001056.001056 lmp.py:376]   Expert  0 |     81 | CPU
DEBUG 01-05 09:59:15.001984.001984 lmp.py:376]   Expert 23 |     81 | CPU
DEBUG 01-05 09:59:15.001673.001673 lmp.py:376]   Expert 15 |     83 | CPU
DEBUG 01-05 09:59:15.001601.001601 lmp.py:376]   Expert  6 |     88 | CPU
DEBUG 01-05 09:59:15.001767.001767 lmp.py:376]   Expert 44 |     99 | CPU
DEBUG 01-05 09:59:15.001172.001172 lmp.py:376]   Expert  4 |    100 | CPU
DEBUG 01-05 09:59:15.001245.001245 lmp.py:376]   Expert 38 |    106 | CPU
DEBUG 01-05 09:59:15.001034.001034 lmp.py:376]   Expert 62 |    106 | CPU
DEBUG 01-05 09:59:15.001723.001723 lmp.py:376]   Expert 63 |    106 | CPU
DEBUG 01-05 09:59:15.001651.001651 lmp.py:376]   Expert 10 |    107 | CPU
DEBUG 01-05 09:59:15.001102.001102 lmp.py:376]   Expert 40 |    112 | CPU
DEBUG 01-05 09:59:15.001553.001553 lmp.py:376]   Expert 46 |    112 | CPU
DEBUG 01-05 09:59:15.001004.001004 lmp.py:376]   Expert 52 |    115 | CPU
DEBUG 01-05 09:59:15.001170.001170 lmp.py:376]   Expert 27 |    120 | CPU
DEBUG 01-05 09:59:15.001574.001574 lmp.py:376]   Expert 32 |    127 | CPU
DEBUG 01-05 09:59:15.001502.001502 lmp.py:376]   Expert 50 |    127 | CPU
DEBUG 01-05 09:59:15.001953.001953 lmp.py:376]   Expert  1 |    135 | CPU
DEBUG 01-05 09:59:15.001642.001642 lmp.py:376]   Expert 60 |    138 | CPU
DEBUG 01-05 09:59:15.001093.001093 lmp.py:376]   Expert 25 |    139 | CPU
DEBUG 01-05 09:59:15.001783.001783 lmp.py:376]   Expert 48 |    143 | CPU
DEBUG 01-05 09:59:15.001995.001995 lmp.py:376]   Expert 31 |    145 | GPU
DEBUG 01-05 09:59:15.001923.001923 lmp.py:376]   Expert 20 |    155 | GPU
DEBUG 01-05 09:59:15.001374.001374 lmp.py:376]   Expert 36 |    166 | GPU
DEBUG 01-05 09:59:15.001030.001030 lmp.py:376]   Expert 51 |    174 | GPU
DEBUG 01-05 09:59:15.001435.001435 lmp.py:376]   Expert 13 |    176 | GPU
DEBUG 01-05 09:59:15.001362.001362 lmp.py:376]   Expert 57 |    176 | GPU
DEBUG 01-05 09:59:15.001813.001813 lmp.py:376]   Expert 61 |    182 | GPU
DEBUG 01-05 09:59:15.001026.001026 lmp.py:376]   Expert 56 |    188 | GPU
DEBUG 01-05 09:59:15.001000.001000 lmp.py:376]   Expert 18 |    199 | GPU
DEBUG 01-05 09:59:15.001212.001212 lmp.py:376]   Expert 42 |    201 | GPU
DEBUG 01-05 09:59:15.001948.001948 lmp.py:376]   Expert 26 |    217 | GPU
DEBUG 01-05 09:59:15.001399.001399 lmp.py:376]   Expert  2 |    220 | GPU
DEBUG 01-05 09:59:15.001134.001134 lmp.py:376]   Expert 43 |    245 | GPU
DEBUG 01-05 09:59:15.001824.001824 lmp.py:376]   Expert 47 |    252 | GPU
DEBUG 01-05 09:59:15.001513.001513 lmp.py:376]   Expert 33 |    260 | GPU
DEBUG 01-05 09:59:15.001156.001156 lmp.py:376]   Expert 53 |    274 | GPU
DEBUG 01-05 09:59:15.001607.001607 lmp.py:376]   Expert 12 |    290 | GPU
DEBUG 01-05 09:59:15.001058.001058 lmp.py:376]   Expert 55 |    290 | GPU
DEBUG 01-05 09:59:15.001270.001270 lmp.py:376]   Expert 45 |    306 | GPU
DEBUG 01-05 09:59:15.001721.001721 lmp.py:376]   Expert 14 |    318 | GPU
DEBUG 01-05 09:59:15.001934.001934 lmp.py:376]   Expert 58 |    319 | GPU
DEBUG 01-05 09:59:15.002146.002146 lmp.py:376]   Expert 29 |    326 | GPU
DEBUG 01-05 09:59:15.002359.002359 lmp.py:376]   Expert 24 |    336 | GPU
DEBUG 01-05 09:59:15.002525.002525 lmp.py:376]   Expert 37 |    337 | GPU
DEBUG 01-05 09:59:15.002214.002214 lmp.py:376]   Expert 34 |    362 | GPU
DEBUG 01-05 09:59:15.002426.002426 lmp.py:376]   Expert 54 |    369 | GPU
DEBUG 01-05 09:59:15.002639.002639 lmp.py:376]   Expert 21 |    375 | GPU
DEBUG 01-05 09:59:15.002851.002851 lmp.py:376]   Expert 28 |    393 | GPU
DEBUG 01-05 09:59:15.002587.002587 lmp.py:376]   Expert  9 |    410 | GPU
DEBUG 01-05 09:59:15.002038.002038 lmp.py:376]   Expert 11 |    410 | GPU
DEBUG 01-05 09:59:15.002489.002489 lmp.py:376]   Expert 22 |    454 | GPU
DEBUG 01-05 09:59:15.002463.002463 lmp.py:376]   Expert 30 |    959 | GPU
DEBUG 01-05 09:59:15.002629.002629 lmp.py:377] 
DEBUG 01-05 09:59:15.002629.002629 lmp.py:377]   CPU total tokens: 2804 (22.8%)
DEBUG 01-05 09:59:15.002987.002987 lmp.py:378]   GPU total tokens: 9484 (77.2%)
DEBUG 01-05 09:59:15.002783.002783 cuda_h.py:19] end experts_map_get cost 0.0015273094177246094 seconds
DEBUG 01-05 09:59:15.002141.002141 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.002825.002825 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.002518.002518 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.003826.003826 cuda_h.py:19] end allocate_cuda_memory cost 0.0014536380767822266 seconds
DEBUG 01-05 09:59:15.003080.003080 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.004697.004697 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.004553.004553 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.004679.004679 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff9d6df3-c376-497c-8291-0e19881557bc
DEBUG 01-05 09:59:15.004500.004500 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.004226.004226 mlpmodule.py:662]  experts func einsum cost 0.06770205497741699 s
INFO 01-05 09:59:15.004146.004146 client.py:127] Model loaded
DEBUG 01-05 09:59:15.004671.004671 cuda_h.py:19] end sllm_worker_task cost 0.009699821472167969 seconds
INFO 01-05 09:59:15.005914.005914 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff9d6df3-c376-497c-8291-0e19881557bc
DEBUG 01-05 09:59:15.005188.005188 cuda_h.py:19] end load_into_gpu_async cost 0.001201629638671875 seconds
DEBUG 01-05 09:59:15.005175.005175 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.005727.005727 cuda_h.py:19] end restore_tensors2 cost 0.0004112720489501953 seconds
DEBUG 01-05 09:59:15.005801.005801 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003437042236328125 seconds
DEBUG 01-05 09:59:15.008966.008966 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006025075912475586 seconds
DEBUG 01-05 09:59:15.008941.008941 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.008534.008534 lmp.py:423] 
DEBUG 01-05 09:59:15.008534.008534 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.008020.008020 cuda_h.py:19] end cpu_experts_submit cost 0.0001354217529296875 seconds
DEBUG 01-05 09:59:15.008815.008815 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.021247.021247 mlpmodule.py:704] group tensors cost 0.012783050537109375 s
DEBUG 01-05 09:59:15.023260.023260 mlpmodule.py:742] pad cost 0.001401662826538086 s
DEBUG 01-05 09:59:15.023144.023144 mlpmodule.py:748] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-05 09:59:15.023748.023748 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-05 09:59:15.032919.032919 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.032190.032190 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.033471.033471 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 09:59:15.033641.033641 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.050890.050890 mlpmodule.py:793] group einsum cost 0.02689194679260254 s
DEBUG 01-05 09:59:15.051546.051546 mlpmodule.py:801] cpy2cputensor cost 0.0005996227264404297 s
DEBUG 01-05 09:59:15.056618.056618 cuda_h.py:19] end wait_cetm_experts cost 0.0476686954498291 seconds
DEBUG 01-05 09:59:15.056958.056958 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.056387.056387 cuda_h.py:19] end gpu_sexperts cost 0.00047469139099121094 seconds
DEBUG 01-05 09:59:15.056183.056183 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.056086.056086 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-05 09:59:15.057696.057696 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.057691.057691 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff9d6df3-c376-497c-8291-0e19881557bc
INFO 01-05 09:59:15.059249.059249 client.py:127] Model loaded
DEBUG 01-05 09:59:15.059238.059238 cuda_h.py:19] end wait_experts cost 0.0020885467529296875 seconds
DEBUG 01-05 09:59:15.059325.059325 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.059127.059127 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.059316.059316 mlpmodule.py:531] gpu group tensors cost 0.0006215572357177734 s
DEBUG 01-05 09:59:15.072097.072097 mlpmodule.py:564] gpu pad cost 0.01298666000366211 s
DEBUG 01-05 09:59:15.078775.078775 mlpmodule.py:662]  experts func einsum cost 0.06950521469116211 s
DEBUG 01-05 09:59:15.078794.078794 mlpmodule.py:582] gpu group einsum cost 0.0055005550384521484 s
DEBUG 01-05 09:59:15.081166.081166 mlpmodule.py:611] gpu experts func einsum cost 0.022243738174438477 s
DEBUG 01-05 09:59:15.081434.081434 cuda_h.py:19] end gpu_experts cost 0.022417545318603516 seconds
DEBUG 01-05 09:59:15.081748.081748 cuda_h.py:19] end layer_moe_generate_11 cost 0.08178591728210449 seconds
DEBUG 01-05 09:59:15.081053.081053 lmp.py:217] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 09:59:15.081438.081438 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 09:59:15.081757.081757 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:59:15.081089.081089 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:59:15.082985.082985 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.86102294921875e-05 seconds
DEBUG 01-05 09:59:15.082741.082741 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.937980651855469e-05 seconds
DEBUG 01-05 09:59:15.082775.082775 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.082990.082990 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.082291.082291 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.082617.082617 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.082268.082268 cuda_h.py:19] end allocate_cuda_memory cost 0.0001900196075439453 seconds
DEBUG 01-05 09:59:15.082198.082198 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.082398.082398 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.082850.082850 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.082275.082275 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 726f346f-2729-4ef5-a713-2f009ad7d009
DEBUG 01-05 09:59:15.082934.082934 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.083129.083129 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.083442.083442 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 726f346f-2729-4ef5-a713-2f009ad7d009
DEBUG 01-05 09:59:15.083676.083676 cuda_h.py:19] end load_into_gpu_async cost 0.0011868476867675781 seconds
DEBUG 01-05 09:59:15.083101.083101 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.084634.084634 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:59:15.084100.084100 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017819404602050781 seconds
INFO 01-05 09:59:15.084485.084485 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 726f346f-2729-4ef5-a713-2f009ad7d009
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.087311.087311 cuda_h.py:19] end self_attn cost 0.003787517547607422 seconds
DEBUG 01-05 09:59:15.087799.087799 cuda_h.py:19] end iln_self_attn_paln cost 0.005216121673583984 seconds
DEBUG 01-05 09:59:15.087172.087172 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 09:59:15.087418.087418 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.088037.088037 cuda_h.py:19] end gate cost 0.0006642341613769531 seconds
DEBUG 01-05 09:59:15.088205.088205 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.088951.088951 lmp.py:365] 
DEBUG 01-05 09:59:15.088951.088951 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.088098.088098 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.088516.088516 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.088643.088643 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.088385.088385 lmp.py:369] 
DEBUG 01-05 09:59:15.088385.088385 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.088413.088413 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.088877.088877 lmp.py:376]   Expert 51 |     13 | CPU
DEBUG 01-05 09:59:15.088096.088096 lmp.py:376]   Expert 63 |     13 | CPU
DEBUG 01-05 09:59:15.088362.088362 lmp.py:376]   Expert 34 |     21 | CPU
DEBUG 01-05 09:59:15.088151.088151 lmp.py:376]   Expert 47 |     29 | CPU
DEBUG 01-05 09:59:15.088939.088939 lmp.py:376]   Expert 11 |     31 | CPU
DEBUG 01-05 09:59:15.088967.088967 lmp.py:376]   Expert 22 |     31 | CPU
DEBUG 01-05 09:59:15.088947.088947 lmp.py:376]   Expert 12 |     32 | CPU
DEBUG 01-05 09:59:15.088928.088928 lmp.py:376]   Expert 16 |     34 | CPU
DEBUG 01-05 09:59:15.088717.088717 lmp.py:376]   Expert  4 |     46 | CPU
DEBUG 01-05 09:59:15.088790.088790 lmp.py:376]   Expert 44 |     49 | CPU
DEBUG 01-05 09:59:15.088579.088579 lmp.py:376]   Expert  0 |     55 | CPU
DEBUG 01-05 09:59:15.088891.088891 lmp.py:376]   Expert 29 |     60 | CPU
DEBUG 01-05 09:59:15.088965.088965 lmp.py:376]   Expert 32 |     65 | CPU
DEBUG 01-05 09:59:15.088276.088276 lmp.py:376]   Expert 27 |     75 | CPU
DEBUG 01-05 09:59:15.088112.088112 lmp.py:376]   Expert 13 |     77 | CPU
DEBUG 01-05 09:59:15.089423.089423 lmp.py:376]   Expert 41 |     81 | CPU
DEBUG 01-05 09:59:15.089497.089497 lmp.py:376]   Expert 37 |     86 | CPU
DEBUG 01-05 09:59:15.089286.089286 lmp.py:376]   Expert  8 |     88 | CPU
DEBUG 01-05 09:59:15.089074.089074 lmp.py:376]   Expert 49 |     99 | CPU
DEBUG 01-05 09:59:15.089386.089386 lmp.py:376]   Expert 23 |    100 | CPU
DEBUG 01-05 09:59:15.089937.089937 lmp.py:376]   Expert  2 |    108 | CPU
DEBUG 01-05 09:59:15.089772.089772 lmp.py:376]   Expert 43 |    109 | CPU
DEBUG 01-05 09:59:15.089322.089322 lmp.py:376]   Expert 21 |    113 | CPU
DEBUG 01-05 09:59:15.089396.089396 lmp.py:376]   Expert 62 |    133 | CPU
DEBUG 01-05 09:59:15.089707.089707 lmp.py:376]   Expert  3 |    134 | CPU
DEBUG 01-05 09:59:15.089019.089019 lmp.py:376]   Expert 39 |    140 | CPU
DEBUG 01-05 09:59:15.089285.089285 lmp.py:376]   Expert 14 |    144 | CPU
DEBUG 01-05 09:59:15.089550.089550 lmp.py:376]   Expert 30 |    146 | CPU
DEBUG 01-05 09:59:15.089101.089101 lmp.py:376]   Expert  7 |    148 | CPU
DEBUG 01-05 09:59:15.089936.089936 lmp.py:376]   Expert 55 |    149 | CPU
DEBUG 01-05 09:59:15.089248.089248 lmp.py:376]   Expert 42 |    153 | CPU
DEBUG 01-05 09:59:15.089321.089321 lmp.py:376]   Expert 61 |    158 | CPU
DEBUG 01-05 09:59:15.089872.089872 lmp.py:376]   Expert 45 |    164 | GPU
DEBUG 01-05 09:59:15.089945.089945 lmp.py:376]   Expert 58 |    164 | GPU
DEBUG 01-05 09:59:15.089257.089257 lmp.py:376]   Expert 53 |    184 | GPU
DEBUG 01-05 09:59:15.089444.089444 lmp.py:376]   Expert  5 |    188 | GPU
DEBUG 01-05 09:59:15.089186.089186 lmp.py:376]   Expert 18 |    188 | GPU
DEBUG 01-05 09:59:15.089021.089021 lmp.py:376]   Expert 38 |    203 | GPU
DEBUG 01-05 09:59:15.089379.089379 lmp.py:376]   Expert 31 |    205 | GPU
DEBUG 01-05 09:59:15.089737.089737 lmp.py:376]   Expert 35 |    206 | GPU
DEBUG 01-05 09:59:15.089573.089573 lmp.py:376]   Expert  6 |    211 | GPU
DEBUG 01-05 09:59:15.089169.089169 lmp.py:376]   Expert 17 |    214 | GPU
DEBUG 01-05 09:59:15.089527.089527 lmp.py:376]   Expert  1 |    228 | GPU
DEBUG 01-05 09:59:15.089124.089124 lmp.py:376]   Expert 19 |    232 | GPU
DEBUG 01-05 09:59:15.089151.089151 lmp.py:376]   Expert 20 |    242 | GPU
DEBUG 01-05 09:59:15.089702.089702 lmp.py:376]   Expert 50 |    242 | GPU
DEBUG 01-05 09:59:15.089166.089166 lmp.py:376]   Expert 46 |    249 | GPU
DEBUG 01-05 09:59:15.089239.089239 lmp.py:376]   Expert 57 |    258 | GPU
DEBUG 01-05 09:59:15.089598.089598 lmp.py:376]   Expert 59 |    279 | GPU
DEBUG 01-05 09:59:15.089956.089956 lmp.py:376]   Expert 52 |    283 | GPU
DEBUG 01-05 09:59:15.089314.089314 lmp.py:376]   Expert 26 |    294 | GPU
DEBUG 01-05 09:59:15.089672.089672 lmp.py:376]   Expert 48 |    309 | GPU
DEBUG 01-05 09:59:15.089031.089031 lmp.py:376]   Expert 60 |    311 | GPU
DEBUG 01-05 09:59:15.089150.089150 lmp.py:376]   Expert 25 |    314 | GPU
DEBUG 01-05 09:59:15.089224.089224 lmp.py:376]   Expert 28 |    319 | GPU
DEBUG 01-05 09:59:15.089536.089536 lmp.py:376]   Expert 54 |    319 | GPU
DEBUG 01-05 09:59:15.089894.089894 lmp.py:376]   Expert 24 |    346 | GPU
DEBUG 01-05 09:59:15.089252.089252 lmp.py:376]   Expert 36 |    346 | GPU
DEBUG 01-05 09:59:15.089611.089611 lmp.py:376]   Expert 40 |    387 | GPU
DEBUG 01-05 09:59:15.089730.089730 lmp.py:376]   Expert 33 |    420 | GPU
DEBUG 01-05 09:59:15.089850.089850 lmp.py:376]   Expert  9 |    450 | GPU
DEBUG 01-05 09:59:15.089493.089493 lmp.py:376]   Expert 15 |    524 | GPU
DEBUG 01-05 09:59:15.089613.089613 lmp.py:376]   Expert 56 |    560 | GPU
DEBUG 01-05 09:59:15.089210.089210 lmp.py:376]   Expert 10 |    729 | GPU
DEBUG 01-05 09:59:15.089283.089283 lmp.py:377] 
DEBUG 01-05 09:59:15.089283.089283 lmp.py:377]   CPU total tokens: 2720 (22.1%)
DEBUG 01-05 09:59:15.089264.089264 lmp.py:378]   GPU total tokens: 9568 (77.9%)
DEBUG 01-05 09:59:15.090013.090013 cuda_h.py:19] end experts_map_get cost 0.0017545223236083984 seconds
DEBUG 01-05 09:59:15.090563.090563 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.090446.090446 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.090590.090590 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.091950.091950 cuda_h.py:19] end allocate_cuda_memory cost 0.0010385513305664062 seconds
DEBUG 01-05 09:59:15.091409.091409 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.091450.091450 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.091451.091451 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.091816.091816 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8f9ceead-2a8d-4990-ae4d-5672292c677e
DEBUG 01-05 09:59:15.091028.091028 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.091575.091575 client.py:127] Model loaded
DEBUG 01-05 09:59:15.092651.092651 cuda_h.py:19] end sllm_worker_task cost 0.009782075881958008 seconds
INFO 01-05 09:59:15.092954.092954 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8f9ceead-2a8d-4990-ae4d-5672292c677e
DEBUG 01-05 09:59:15.093158.093158 cuda_h.py:19] end load_into_gpu_async cost 0.001730203628540039 seconds
DEBUG 01-05 09:59:15.093120.093120 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.093306.093306 cuda_h.py:19] end restore_tensors2 cost 0.0005278587341308594 seconds
DEBUG 01-05 09:59:15.093950.093950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037529468536376953 seconds
DEBUG 01-05 09:59:15.096304.096304 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006277799606323242 seconds
DEBUG 01-05 09:59:15.096564.096564 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.096422.096422 lmp.py:423] 
DEBUG 01-05 09:59:15.096422.096422 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.096981.096981 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-05 09:59:15.096014.096014 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.107110.107110 mlpmodule.py:704] group tensors cost 0.011010408401489258 s
DEBUG 01-05 09:59:15.110174.110174 mlpmodule.py:742] pad cost 0.0023794174194335938 s
DEBUG 01-05 09:59:15.110834.110834 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:59:15.111156.111156 mlpmodule.py:753] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-05 09:59:15.121389.121389 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.121467.121467 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.121079.121079 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 09:59:15.121064.121064 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.139083.139083 mlpmodule.py:793] group einsum cost 0.028789281845092773 s
DEBUG 01-05 09:59:15.140260.140260 mlpmodule.py:801] cpy2cputensor cost 0.0007162094116210938 s
DEBUG 01-05 09:59:15.146698.146698 cuda_h.py:19] end wait_cetm_experts cost 0.04942893981933594 seconds
DEBUG 01-05 09:59:15.146377.146377 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.146986.146986 cuda_h.py:19] end gpu_sexperts cost 0.0005440711975097656 seconds
DEBUG 01-05 09:59:15.146929.146929 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.146786.146786 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 09:59:15.146396.146396 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.146582.146582 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8f9ceead-2a8d-4990-ae4d-5672292c677e
INFO 01-05 09:59:15.147853.147853 client.py:127] Model loaded
DEBUG 01-05 09:59:15.147365.147365 cuda_h.py:19] end wait_experts cost 0.0010347366333007812 seconds
DEBUG 01-05 09:59:15.148499.148499 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.148778.148778 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.148577.148577 mlpmodule.py:531] gpu group tensors cost 0.0006492137908935547 s
DEBUG 01-05 09:59:15.150795.150795 mlpmodule.py:564] gpu pad cost 0.0017211437225341797 s
DEBUG 01-05 09:59:15.151206.151206 mlpmodule.py:582] gpu group einsum cost 0.0005183219909667969 s
DEBUG 01-05 09:59:15.154549.154549 mlpmodule.py:611] gpu experts func einsum cost 0.006526470184326172 s
DEBUG 01-05 09:59:15.154969.154969 cuda_h.py:19] end gpu_experts cost 0.006707906723022461 seconds
DEBUG 01-05 09:59:15.154230.154230 cuda_h.py:19] end layer_moe_generate_12 cost 0.06738901138305664 seconds
DEBUG 01-05 09:59:15.155383.155383 lmp.py:217] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 09:59:15.155153.155153 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 09:59:15.155710.155710 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:59:15.155281.155281 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:59:15.155985.155985 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:15.155502.155502 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.556510925292969e-05 seconds
DEBUG 01-05 09:59:15.155391.155391 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.155890.155890 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.155846.155846 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.155630.155630 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.160960.160960 cuda_h.py:19] end allocate_cuda_memory cost 0.00483250617980957 seconds
DEBUG 01-05 09:59:15.160530.160530 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.160630.160630 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.160168.160168 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.160063.160063 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a904573f-5ca0-46fb-9eb9-601e4a653d30
DEBUG 01-05 09:59:15.160702.160702 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.161515.161515 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.161678.161678 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a904573f-5ca0-46fb-9eb9-601e4a653d30
DEBUG 01-05 09:59:15.161627.161627 cuda_h.py:19] end load_into_gpu_async cost 0.0010838508605957031 seconds
DEBUG 01-05 09:59:15.161290.161290 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.161254.161254 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-05 09:59:15.161514.161514 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006464719772338867 seconds
INFO 01-05 09:59:15.162904.162904 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a904573f-5ca0-46fb-9eb9-601e4a653d30
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.165115.165115 cuda_h.py:19] end self_attn cost 0.0038123130798339844 seconds
DEBUG 01-05 09:59:15.165933.165933 cuda_h.py:19] end iln_self_attn_paln cost 0.010023117065429688 seconds
DEBUG 01-05 09:59:15.165438.165438 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 09:59:15.165439.165439 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.166481.166481 cuda_h.py:19] end gate cost 0.0006299018859863281 seconds
DEBUG 01-05 09:59:15.166450.166450 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.166360.166360 lmp.py:365] 
DEBUG 01-05 09:59:15.166360.166360 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.166924.166924 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.166335.166335 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.166409.166409 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.166621.166621 lmp.py:369] 
DEBUG 01-05 09:59:15.166621.166621 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.166072.166072 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.166245.166245 lmp.py:376]   Expert  6 |     12 | CPU
DEBUG 01-05 09:59:15.166173.166173 lmp.py:376]   Expert 53 |     12 | CPU
DEBUG 01-05 09:59:15.166385.166385 lmp.py:376]   Expert 19 |     21 | CPU
DEBUG 01-05 09:59:15.166597.166597 lmp.py:376]   Expert 50 |     27 | CPU
DEBUG 01-05 09:59:15.166333.166333 lmp.py:376]   Expert 26 |     42 | CPU
DEBUG 01-05 09:59:15.166499.166499 lmp.py:376]   Expert  2 |     52 | CPU
DEBUG 01-05 09:59:15.166950.166950 lmp.py:376]   Expert  0 |     53 | CPU
DEBUG 01-05 09:59:15.166163.166163 lmp.py:376]   Expert  8 |     63 | CPU
DEBUG 01-05 09:59:15.166898.166898 lmp.py:376]   Expert 12 |     64 | CPU
DEBUG 01-05 09:59:15.166872.166872 lmp.py:376]   Expert 31 |     80 | CPU
DEBUG 01-05 09:59:15.166846.166846 lmp.py:376]   Expert 20 |     81 | CPU
DEBUG 01-05 09:59:15.166582.166582 lmp.py:376]   Expert 16 |     90 | CPU
DEBUG 01-05 09:59:15.166079.166079 lmp.py:376]   Expert 40 |     96 | CPU
DEBUG 01-05 09:59:15.166292.166292 lmp.py:376]   Expert 30 |    103 | CPU
DEBUG 01-05 09:59:15.166789.166789 lmp.py:376]   Expert 32 |    108 | CPU
DEBUG 01-05 09:59:15.166524.166524 lmp.py:376]   Expert 28 |    110 | CPU
DEBUG 01-05 09:59:15.166359.166359 lmp.py:376]   Expert 35 |    114 | CPU
DEBUG 01-05 09:59:15.166195.166195 lmp.py:376]   Expert 57 |    116 | CPU
DEBUG 01-05 09:59:15.166692.166692 lmp.py:376]   Expert 48 |    120 | CPU
DEBUG 01-05 09:59:15.166427.166427 lmp.py:376]   Expert 63 |    123 | CPU
DEBUG 01-05 09:59:15.166925.166925 lmp.py:376]   Expert 18 |    124 | CPU
DEBUG 01-05 09:59:15.166899.166899 lmp.py:376]   Expert 61 |    126 | CPU
DEBUG 01-05 09:59:15.166396.166396 lmp.py:376]   Expert 11 |    128 | CPU
DEBUG 01-05 09:59:15.166708.166708 lmp.py:376]   Expert  5 |    130 | CPU
DEBUG 01-05 09:59:15.166828.166828 lmp.py:376]   Expert 60 |    131 | CPU
DEBUG 01-05 09:59:15.166093.166093 lmp.py:376]   Expert 13 |    137 | CPU
DEBUG 01-05 09:59:15.166690.166690 lmp.py:376]   Expert 34 |    137 | CPU
DEBUG 01-05 09:59:15.166048.166048 lmp.py:376]   Expert 24 |    149 | CPU
DEBUG 01-05 09:59:15.167929.167929 lmp.py:376]   Expert 52 |    155 | CPU
DEBUG 01-05 09:59:15.167049.167049 lmp.py:376]   Expert  9 |    160 | CPU
DEBUG 01-05 09:59:15.167169.167169 lmp.py:376]   Expert 58 |    162 | CPU
DEBUG 01-05 09:59:15.167050.167050 lmp.py:376]   Expert 45 |    170 | CPU
DEBUG 01-05 09:59:15.167693.167693 lmp.py:376]   Expert 37 |    171 | GPU
DEBUG 01-05 09:59:15.167813.167813 lmp.py:376]   Expert  3 |    173 | GPU
DEBUG 01-05 09:59:15.167218.167218 lmp.py:376]   Expert 42 |    174 | GPU
DEBUG 01-05 09:59:15.167099.167099 lmp.py:376]   Expert 25 |    178 | GPU
DEBUG 01-05 09:59:15.167742.167742 lmp.py:376]   Expert  4 |    204 | GPU
DEBUG 01-05 09:59:15.167431.167431 lmp.py:376]   Expert 17 |    214 | GPU
DEBUG 01-05 09:59:15.167836.167836 lmp.py:376]   Expert 46 |    214 | GPU
DEBUG 01-05 09:59:15.167048.167048 lmp.py:376]   Expert 27 |    217 | GPU
DEBUG 01-05 09:59:15.167168.167168 lmp.py:376]   Expert  7 |    220 | GPU
DEBUG 01-05 09:59:15.167381.167381 lmp.py:376]   Expert 39 |    221 | GPU
DEBUG 01-05 09:59:15.167024.167024 lmp.py:376]   Expert 51 |    225 | GPU
DEBUG 01-05 09:59:15.167190.167190 lmp.py:376]   Expert 22 |    227 | GPU
DEBUG 01-05 09:59:15.167071.167071 lmp.py:376]   Expert 33 |    228 | GPU
DEBUG 01-05 09:59:15.167761.167761 lmp.py:376]   Expert 43 |    229 | GPU
DEBUG 01-05 09:59:15.167927.167927 lmp.py:376]   Expert 62 |    239 | GPU
DEBUG 01-05 09:59:15.167616.167616 lmp.py:376]   Expert 54 |    255 | GPU
DEBUG 01-05 09:59:15.167259.167259 lmp.py:376]   Expert 49 |    257 | GPU
DEBUG 01-05 09:59:15.167710.167710 lmp.py:376]   Expert  1 |    260 | GPU
DEBUG 01-05 09:59:15.167353.167353 lmp.py:376]   Expert 36 |    265 | GPU
DEBUG 01-05 09:59:15.167042.167042 lmp.py:376]   Expert 29 |    282 | GPU
DEBUG 01-05 09:59:15.167924.167924 lmp.py:376]   Expert 44 |    286 | GPU
DEBUG 01-05 09:59:15.167898.167898 lmp.py:376]   Expert 59 |    315 | GPU
DEBUG 01-05 09:59:15.167541.167541 lmp.py:376]   Expert 47 |    319 | GPU
DEBUG 01-05 09:59:15.167991.167991 lmp.py:376]   Expert 15 |    327 | GPU
DEBUG 01-05 09:59:15.167350.167350 lmp.py:376]   Expert 38 |    337 | GPU
DEBUG 01-05 09:59:15.167754.167754 lmp.py:376]   Expert 23 |    384 | GPU
DEBUG 01-05 09:59:15.167159.167159 lmp.py:376]   Expert 14 |    389 | GPU
DEBUG 01-05 09:59:15.167133.167133 lmp.py:376]   Expert 55 |    406 | GPU
DEBUG 01-05 09:59:15.167299.167299 lmp.py:376]   Expert 41 |    407 | GPU
DEBUG 01-05 09:59:15.167511.167511 lmp.py:376]   Expert 21 |    414 | GPU
DEBUG 01-05 09:59:15.167154.167154 lmp.py:376]   Expert 10 |    466 | GPU
DEBUG 01-05 09:59:15.167605.167605 lmp.py:376]   Expert 56 |    589 | GPU
DEBUG 01-05 09:59:15.167725.167725 lmp.py:377] 
DEBUG 01-05 09:59:15.167725.167725 lmp.py:377]   CPU total tokens: 3196 (26.0%)
DEBUG 01-05 09:59:15.167083.167083 lmp.py:378]   GPU total tokens: 9092 (74.0%)
DEBUG 01-05 09:59:15.167177.167177 cuda_h.py:19] end experts_map_get cost 0.0015263557434082031 seconds
DEBUG 01-05 09:59:15.167535.167535 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.167458.167458 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.167018.167018 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.169025.169025 cuda_h.py:19] end allocate_cuda_memory cost 0.001165628433227539 seconds
DEBUG 01-05 09:59:15.169630.169630 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.169101.169101 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.169387.169387 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.169514.169514 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4272b0c4-7155-4338-999e-faa3dd3291ff
DEBUG 01-05 09:59:15.169547.169547 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.169222.169222 mlpmodule.py:662]  experts func einsum cost 0.07287716865539551 s
INFO 01-05 09:59:15.169466.169466 client.py:127] Model loaded
DEBUG 01-05 09:59:15.169160.169160 cuda_h.py:19] end sllm_worker_task cost 0.014518022537231445 seconds
INFO 01-05 09:59:15.170946.170946 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4272b0c4-7155-4338-999e-faa3dd3291ff
DEBUG 01-05 09:59:15.170650.170650 cuda_h.py:19] end load_into_gpu_async cost 0.0013494491577148438 seconds
DEBUG 01-05 09:59:15.170399.170399 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.170949.170949 cuda_h.py:19] end restore_tensors2 cost 0.0003809928894042969 seconds
DEBUG 01-05 09:59:15.171593.171593 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003238201141357422 seconds
DEBUG 01-05 09:59:15.173154.173154 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005800962448120117 seconds
DEBUG 01-05 09:59:15.173759.173759 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.173761.173761 lmp.py:423] 
DEBUG 01-05 09:59:15.173761.173761 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.173035.173035 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 09:59:15.173731.173731 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.178348.178348 mlpmodule.py:704] group tensors cost 0.0045642852783203125 s
DEBUG 01-05 09:59:15.180794.180794 mlpmodule.py:742] pad cost 0.0016717910766601562 s
DEBUG 01-05 09:59:15.180951.180951 mlpmodule.py:748] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-05 09:59:15.180238.180238 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 09:59:15.191859.191859 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.191713.191713 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.191286.191286 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 09:59:15.191145.191145 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.208038.208038 mlpmodule.py:793] group einsum cost 0.02718353271484375 s
DEBUG 01-05 09:59:15.209450.209450 mlpmodule.py:801] cpy2cputensor cost 0.0007348060607910156 s
DEBUG 01-05 09:59:15.214883.214883 cuda_h.py:19] end wait_cetm_experts cost 0.040450334548950195 seconds
DEBUG 01-05 09:59:15.214776.214776 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.215041.215041 cuda_h.py:19] end gpu_sexperts cost 0.0005731582641601562 seconds
DEBUG 01-05 09:59:15.215984.215984 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.215841.215841 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:15.215974.215974 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.215399.215399 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4272b0c4-7155-4338-999e-faa3dd3291ff
INFO 01-05 09:59:15.225609.225609 client.py:127] Model loaded
DEBUG 01-05 09:59:15.226236.226236 cuda_h.py:19] end wait_experts cost 0.010750532150268555 seconds
DEBUG 01-05 09:59:15.226292.226292 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.226586.226586 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.226681.226681 mlpmodule.py:531] gpu group tensors cost 0.0005304813385009766 s
DEBUG 01-05 09:59:15.228227.228227 mlpmodule.py:564] gpu pad cost 0.0014395713806152344 s
DEBUG 01-05 09:59:15.228843.228843 mlpmodule.py:582] gpu group einsum cost 0.0005207061767578125 s
DEBUG 01-05 09:59:15.231215.231215 mlpmodule.py:611] gpu experts func einsum cost 0.005419254302978516 s
DEBUG 01-05 09:59:15.231001.231001 cuda_h.py:19] end gpu_experts cost 0.0056915283203125 seconds
DEBUG 01-05 09:59:15.231825.231825 cuda_h.py:19] end layer_moe_generate_13 cost 0.06651091575622559 seconds
DEBUG 01-05 09:59:15.232162.232162 lmp.py:217] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 09:59:15.232017.232017 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 09:59:15.232237.232237 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:59:15.232277.232277 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:59:15.232637.232637 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.7894973754882812e-05 seconds
DEBUG 01-05 09:59:15.232432.232432 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.745887756347656e-05 seconds
DEBUG 01-05 09:59:15.232075.232075 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.232417.232417 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.232705.232705 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.232939.232939 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.233963.233963 cuda_h.py:19] end allocate_cuda_memory cost 0.0010390281677246094 seconds
DEBUG 01-05 09:59:15.233550.233550 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.233048.233048 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.233931.233931 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.233263.233263 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e64962fa-a336-45d6-81a4-cc40ac64c79a
DEBUG 01-05 09:59:15.234922.234922 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.234134.234134 mlpmodule.py:662]  experts func einsum cost 0.0602877140045166 s
DEBUG 01-05 09:59:15.234290.234290 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.234236.234236 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e64962fa-a336-45d6-81a4-cc40ac64c79a
DEBUG 01-05 09:59:15.234192.234192 cuda_h.py:19] end load_into_gpu_async cost 0.00112152099609375 seconds
DEBUG 01-05 09:59:15.235001.235001 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.235018.235018 cuda_h.py:19] end restore_tensors2 cost 8.249282836914062e-05 seconds
DEBUG 01-05 09:59:15.235311.235311 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002612590789794922 seconds
INFO 01-05 09:59:15.235876.235876 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e64962fa-a336-45d6-81a4-cc40ac64c79a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.238685.238685 cuda_h.py:19] end self_attn cost 0.003979682922363281 seconds
DEBUG 01-05 09:59:15.238570.238570 cuda_h.py:19] end iln_self_attn_paln cost 0.006621360778808594 seconds
DEBUG 01-05 09:59:15.238028.238028 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 09:59:15.239791.239791 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.239972.239972 cuda_h.py:19] end gate cost 0.0006260871887207031 seconds
DEBUG 01-05 09:59:15.239702.239702 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.240374.240374 lmp.py:365] 
DEBUG 01-05 09:59:15.240374.240374 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.240461.240461 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.240111.240111 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.240946.240946 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.240635.240635 lmp.py:369] 
DEBUG 01-05 09:59:15.240635.240635 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.240325.240325 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.240021.240021 lmp.py:376]   Expert 61 |      8 | CPU
DEBUG 01-05 09:59:15.240425.240425 lmp.py:376]   Expert  7 |     12 | CPU
DEBUG 01-05 09:59:15.240638.240638 lmp.py:376]   Expert 59 |     38 | CPU
DEBUG 01-05 09:59:15.240373.240373 lmp.py:376]   Expert 34 |     51 | CPU
DEBUG 01-05 09:59:15.240871.240871 lmp.py:376]   Expert 49 |     58 | CPU
DEBUG 01-05 09:59:15.240368.240368 lmp.py:376]   Expert 50 |     58 | CPU
DEBUG 01-05 09:59:15.240626.240626 lmp.py:376]   Expert 38 |     59 | CPU
DEBUG 01-05 09:59:15.240316.240316 lmp.py:376]   Expert 48 |     66 | CPU
DEBUG 01-05 09:59:15.240912.240912 lmp.py:376]   Expert 40 |     68 | CPU
DEBUG 01-05 09:59:15.240794.240794 lmp.py:376]   Expert 32 |     70 | CPU
DEBUG 01-05 09:59:15.240722.240722 lmp.py:376]   Expert 55 |     72 | CPU
DEBUG 01-05 09:59:15.240934.240934 lmp.py:376]   Expert  0 |     97 | CPU
DEBUG 01-05 09:59:15.240385.240385 lmp.py:376]   Expert 43 |     97 | CPU
DEBUG 01-05 09:59:15.240597.240597 lmp.py:376]   Expert 18 |    104 | CPU
DEBUG 01-05 09:59:15.240810.240810 lmp.py:376]   Expert 60 |    105 | CPU
DEBUG 01-05 09:59:15.240413.240413 lmp.py:376]   Expert 39 |    107 | CPU
DEBUG 01-05 09:59:15.240864.240864 lmp.py:376]   Expert 35 |    108 | CPU
DEBUG 01-05 09:59:15.240792.240792 lmp.py:376]   Expert 23 |    111 | CPU
DEBUG 01-05 09:59:15.240720.240720 lmp.py:376]   Expert 29 |    111 | CPU
DEBUG 01-05 09:59:15.240601.240601 lmp.py:376]   Expert  8 |    115 | CPU
DEBUG 01-05 09:59:15.240529.240529 lmp.py:376]   Expert 44 |    116 | CPU
DEBUG 01-05 09:59:15.240741.240741 lmp.py:376]   Expert 20 |    117 | CPU
DEBUG 01-05 09:59:15.240954.240954 lmp.py:376]   Expert 28 |    119 | CPU
DEBUG 01-05 09:59:15.240166.240166 lmp.py:376]   Expert 41 |    125 | CPU
DEBUG 01-05 09:59:15.240379.240379 lmp.py:376]   Expert 51 |    127 | CPU
DEBUG 01-05 09:59:15.240829.240829 lmp.py:376]   Expert 17 |    133 | CPU
DEBUG 01-05 09:59:15.240042.240042 lmp.py:376]   Expert 21 |    144 | CPU
DEBUG 01-05 09:59:15.240254.240254 lmp.py:376]   Expert 54 |    145 | CPU
DEBUG 01-05 09:59:15.240467.240467 lmp.py:376]   Expert 12 |    156 | CPU
DEBUG 01-05 09:59:15.240679.240679 lmp.py:376]   Expert 45 |    173 | CPU
DEBUG 01-05 09:59:15.240653.240653 lmp.py:376]   Expert 42 |    176 | CPU
DEBUG 01-05 09:59:15.240581.240581 lmp.py:376]   Expert 57 |    176 | CPU
DEBUG 01-05 09:59:15.240509.240509 lmp.py:376]   Expert 52 |    178 | GPU
DEBUG 01-05 09:59:15.240960.240960 lmp.py:376]   Expert 62 |    193 | GPU
DEBUG 01-05 09:59:15.240411.240411 lmp.py:376]   Expert  6 |    198 | GPU
DEBUG 01-05 09:59:15.240385.240385 lmp.py:376]   Expert 31 |    199 | GPU
DEBUG 01-05 09:59:15.240597.240597 lmp.py:376]   Expert 13 |    209 | GPU
DEBUG 01-05 09:59:15.240810.240810 lmp.py:376]   Expert  3 |    211 | GPU
DEBUG 01-05 09:59:15.240784.240784 lmp.py:376]   Expert 30 |    220 | GPU
DEBUG 01-05 09:59:15.240234.240234 lmp.py:376]   Expert 26 |    221 | GPU
DEBUG 01-05 09:59:15.240162.240162 lmp.py:376]   Expert 36 |    221 | GPU
DEBUG 01-05 09:59:15.240328.240328 lmp.py:376]   Expert 11 |    225 | GPU
DEBUG 01-05 09:59:15.240256.240256 lmp.py:376]   Expert 14 |    226 | GPU
DEBUG 01-05 09:59:15.240230.240230 lmp.py:376]   Expert 19 |    233 | GPU
DEBUG 01-05 09:59:15.240443.240443 lmp.py:376]   Expert 46 |    233 | GPU
DEBUG 01-05 09:59:15.240417.240417 lmp.py:376]   Expert 27 |    249 | GPU
DEBUG 01-05 09:59:15.240629.240629 lmp.py:376]   Expert 22 |    270 | GPU
DEBUG 01-05 09:59:15.240080.240080 lmp.py:376]   Expert  2 |    277 | GPU
DEBUG 01-05 09:59:15.240531.240531 lmp.py:376]   Expert  4 |    280 | GPU
DEBUG 01-05 09:59:15.240505.240505 lmp.py:376]   Expert  5 |    287 | GPU
DEBUG 01-05 09:59:15.240956.240956 lmp.py:376]   Expert 33 |    291 | GPU
DEBUG 01-05 09:59:15.240645.240645 lmp.py:376]   Expert 37 |    293 | GPU
DEBUG 01-05 09:59:15.241573.241573 lmp.py:376]   Expert 56 |    298 | GPU
DEBUG 01-05 09:59:15.241547.241547 lmp.py:376]   Expert  1 |    307 | GPU
DEBUG 01-05 09:59:15.241759.241759 lmp.py:376]   Expert 16 |    309 | GPU
DEBUG 01-05 09:59:15.241972.241972 lmp.py:376]   Expert 53 |    312 | GPU
DEBUG 01-05 09:59:15.241707.241707 lmp.py:376]   Expert 58 |    315 | GPU
DEBUG 01-05 09:59:15.241920.241920 lmp.py:376]   Expert 10 |    339 | GPU
DEBUG 01-05 09:59:15.241655.241655 lmp.py:376]   Expert 63 |    361 | GPU
DEBUG 01-05 09:59:15.241629.241629 lmp.py:376]   Expert 24 |    377 | GPU
DEBUG 01-05 09:59:15.241842.241842 lmp.py:376]   Expert 15 |    382 | GPU
DEBUG 01-05 09:59:15.241816.241816 lmp.py:376]   Expert 47 |    385 | GPU
DEBUG 01-05 09:59:15.241505.241505 lmp.py:376]   Expert 25 |    477 | GPU
DEBUG 01-05 09:59:15.241195.241195 lmp.py:376]   Expert  9 |    490 | GPU
DEBUG 01-05 09:59:15.241838.241838 lmp.py:377] 
DEBUG 01-05 09:59:15.241838.241838 lmp.py:377]   CPU total tokens: 3222 (26.2%)
DEBUG 01-05 09:59:15.241004.241004 lmp.py:378]   GPU total tokens: 9066 (73.8%)
DEBUG 01-05 09:59:15.241938.241938 cuda_h.py:19] end experts_map_get cost 0.0014805793762207031 seconds
DEBUG 01-05 09:59:15.241343.241343 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.241834.241834 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.241342.241342 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.241379.241379 cuda_h.py:19] end allocate_cuda_memory cost 0.00027632713317871094 seconds
DEBUG 01-05 09:59:15.241090.241090 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.241084.241084 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.241747.241747 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.241159.241159 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65f1062d-a5fc-40b7-b071-a6a455d80374
DEBUG 01-05 09:59:15.242563.242563 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.242734.242734 client.py:127] Model loaded
DEBUG 01-05 09:59:15.242451.242451 cuda_h.py:19] end sllm_worker_task cost 0.009827375411987305 seconds
INFO 01-05 09:59:15.242540.242540 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65f1062d-a5fc-40b7-b071-a6a455d80374
DEBUG 01-05 09:59:15.243383.243383 cuda_h.py:19] end load_into_gpu_async cost 0.0012006759643554688 seconds
DEBUG 01-05 09:59:15.243370.243370 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.243972.243972 cuda_h.py:19] end restore_tensors2 cost 0.00034880638122558594 seconds
DEBUG 01-05 09:59:15.243040.243040 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002166748046875 seconds
DEBUG 01-05 09:59:15.246608.246608 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004734516143798828 seconds
DEBUG 01-05 09:59:15.246815.246815 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.246148.246148 lmp.py:423] 
DEBUG 01-05 09:59:15.246148.246148 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.246561.246561 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-05 09:59:15.246734.246734 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.251429.251429 mlpmodule.py:704] group tensors cost 0.004923343658447266 s
DEBUG 01-05 09:59:15.254044.254044 mlpmodule.py:742] pad cost 0.002099752426147461 s
DEBUG 01-05 09:59:15.254605.254605 mlpmodule.py:748] create cpu tensor cost 5.3882598876953125e-05 s
DEBUG 01-05 09:59:15.254343.254343 mlpmodule.py:753] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-05 09:59:15.264485.264485 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.265148.265148 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.265191.265191 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 09:59:15.265003.265003 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.282248.282248 mlpmodule.py:793] group einsum cost 0.027922391891479492 s
DEBUG 01-05 09:59:15.283982.283982 mlpmodule.py:801] cpy2cputensor cost 0.0007088184356689453 s
DEBUG 01-05 09:59:15.288270.288270 cuda_h.py:19] end wait_cetm_experts cost 0.04203438758850098 seconds
DEBUG 01-05 09:59:15.288892.288892 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.289125.289125 cuda_h.py:19] end gpu_sexperts cost 0.0005838871002197266 seconds
DEBUG 01-05 09:59:15.289782.289782 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.289208.289208 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 09:59:15.289580.289580 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.289720.289720 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65f1062d-a5fc-40b7-b071-a6a455d80374
INFO 01-05 09:59:15.297292.297292 client.py:127] Model loaded
DEBUG 01-05 09:59:15.297711.297711 cuda_h.py:19] end wait_experts cost 0.008422374725341797 seconds
DEBUG 01-05 09:59:15.297652.297652 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.297355.297355 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.298163.298163 mlpmodule.py:531] gpu group tensors cost 0.0005209445953369141 s
DEBUG 01-05 09:59:15.299154.299154 mlpmodule.py:564] gpu pad cost 0.0014472007751464844 s
DEBUG 01-05 09:59:15.300451.300451 mlpmodule.py:582] gpu group einsum cost 0.0005102157592773438 s
DEBUG 01-05 09:59:15.301740.301740 mlpmodule.py:662]  experts func einsum cost 0.0545811653137207 s
DEBUG 01-05 09:59:15.304511.304511 mlpmodule.py:611] gpu experts func einsum cost 0.0063517093658447266 s
DEBUG 01-05 09:59:15.304489.304489 cuda_h.py:19] end gpu_experts cost 0.006560325622558594 seconds
DEBUG 01-05 09:59:15.304511.304511 cuda_h.py:19] end layer_moe_generate_14 cost 0.06542396545410156 seconds
DEBUG 01-05 09:59:15.304464.304464 lmp.py:217] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 09:59:15.304320.304320 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 09:59:15.304870.304870 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:59:15.304196.304196 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:59:15.304986.304986 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:15.304517.304517 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.984306335449219e-05 seconds
DEBUG 01-05 09:59:15.304637.304637 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.304594.304594 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.305288.305288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.305147.305147 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.305364.305364 cuda_h.py:19] end allocate_cuda_memory cost 0.00043702125549316406 seconds
DEBUG 01-05 09:59:15.305991.305991 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.306206.306206 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.306474.306474 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.306914.306914 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2d75fed3-39f6-45ad-932f-2a5605e935a0
DEBUG 01-05 09:59:15.306270.306270 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.306693.306693 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.307956.307956 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2d75fed3-39f6-45ad-932f-2a5605e935a0
DEBUG 01-05 09:59:15.307119.307119 cuda_h.py:19] end load_into_gpu_async cost 0.0015485286712646484 seconds
DEBUG 01-05 09:59:15.307552.307552 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.307320.307320 cuda_h.py:19] end restore_tensors2 cost 0.00011849403381347656 seconds
DEBUG 01-05 09:59:15.307097.307097 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027010440826416016 seconds
INFO 01-05 09:59:15.308408.308408 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2d75fed3-39f6-45ad-932f-2a5605e935a0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.311475.311475 cuda_h.py:19] end self_attn cost 0.004690647125244141 seconds
DEBUG 01-05 09:59:15.311743.311743 cuda_h.py:19] end iln_self_attn_paln cost 0.006722688674926758 seconds
DEBUG 01-05 09:59:15.311772.311772 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 09:59:15.311819.311819 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.312431.312431 cuda_h.py:19] end gate cost 0.0006291866302490234 seconds
DEBUG 01-05 09:59:15.312353.312353 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.312283.312283 lmp.py:365] 
DEBUG 01-05 09:59:15.312283.312283 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.312755.312755 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.312597.312597 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.312862.312862 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.312267.312267 lmp.py:369] 
DEBUG 01-05 09:59:15.312267.312267 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.312625.312625 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.312275.312275 lmp.py:376]   Expert 63 |     13 | CPU
DEBUG 01-05 09:59:15.312395.312395 lmp.py:376]   Expert 34 |     49 | CPU
DEBUG 01-05 09:59:15.312561.312561 lmp.py:376]   Expert 37 |     55 | CPU
DEBUG 01-05 09:59:15.312488.312488 lmp.py:376]   Expert 42 |     64 | CPU
DEBUG 01-05 09:59:15.312655.312655 lmp.py:376]   Expert  4 |     66 | CPU
DEBUG 01-05 09:59:15.312582.312582 lmp.py:376]   Expert 48 |     69 | CPU
DEBUG 01-05 09:59:15.312033.312033 lmp.py:376]   Expert 28 |     72 | CPU
DEBUG 01-05 09:59:15.312438.312438 lmp.py:376]   Expert 22 |     75 | CPU
DEBUG 01-05 09:59:15.312127.312127 lmp.py:376]   Expert 53 |     80 | CPU
DEBUG 01-05 09:59:15.312293.312293 lmp.py:376]   Expert 51 |     81 | CPU
DEBUG 01-05 09:59:15.312744.312744 lmp.py:376]   Expert 57 |     84 | CPU
DEBUG 01-05 09:59:15.312433.312433 lmp.py:376]   Expert 40 |     87 | CPU
DEBUG 01-05 09:59:15.313884.313884 lmp.py:376]   Expert 15 |     94 | CPU
DEBUG 01-05 09:59:15.313335.313335 lmp.py:376]   Expert  5 |     96 | CPU
DEBUG 01-05 09:59:15.313024.313024 lmp.py:376]   Expert 43 |     99 | CPU
DEBUG 01-05 09:59:15.313475.313475 lmp.py:376]   Expert 41 |    101 | CPU
DEBUG 01-05 09:59:15.313926.313926 lmp.py:376]   Expert  6 |    120 | CPU
DEBUG 01-05 09:59:15.313092.313092 lmp.py:376]   Expert  7 |    125 | CPU
DEBUG 01-05 09:59:15.313974.313974 lmp.py:376]   Expert 55 |    129 | CPU
DEBUG 01-05 09:59:15.313663.313663 lmp.py:376]   Expert 29 |    130 | CPU
DEBUG 01-05 09:59:15.313875.313875 lmp.py:376]   Expert 32 |    132 | CPU
DEBUG 01-05 09:59:15.313326.313326 lmp.py:376]   Expert 56 |    138 | CPU
DEBUG 01-05 09:59:15.313300.313300 lmp.py:376]   Expert 44 |    144 | CPU
DEBUG 01-05 09:59:15.313751.313751 lmp.py:376]   Expert 52 |    144 | CPU
DEBUG 01-05 09:59:15.313202.313202 lmp.py:376]   Expert 25 |    157 | CPU
DEBUG 01-05 09:59:15.313415.313415 lmp.py:376]   Expert  2 |    160 | CPU
DEBUG 01-05 09:59:15.313104.313104 lmp.py:376]   Expert 14 |    160 | CPU
DEBUG 01-05 09:59:15.313270.313270 lmp.py:376]   Expert 61 |    164 | CPU
DEBUG 01-05 09:59:15.313721.313721 lmp.py:376]   Expert 33 |    173 | CPU
DEBUG 01-05 09:59:15.313172.313172 lmp.py:376]   Expert 12 |    183 | CPU
DEBUG 01-05 09:59:15.313384.313384 lmp.py:376]   Expert 35 |    188 | CPU
DEBUG 01-05 09:59:15.313597.313597 lmp.py:376]   Expert 54 |    191 | CPU
DEBUG 01-05 09:59:15.313286.313286 lmp.py:376]   Expert 62 |    191 | GPU
DEBUG 01-05 09:59:15.313498.313498 lmp.py:376]   Expert 39 |    194 | GPU
DEBUG 01-05 09:59:15.313949.313949 lmp.py:376]   Expert 50 |    202 | GPU
DEBUG 01-05 09:59:15.313400.313400 lmp.py:376]   Expert 11 |    206 | GPU
DEBUG 01-05 09:59:15.313090.313090 lmp.py:376]   Expert 31 |    214 | GPU
DEBUG 01-05 09:59:15.313494.313494 lmp.py:376]   Expert 20 |    215 | GPU
DEBUG 01-05 09:59:15.313183.313183 lmp.py:376]   Expert 58 |    216 | GPU
DEBUG 01-05 09:59:15.313396.313396 lmp.py:376]   Expert 45 |    217 | GPU
DEBUG 01-05 09:59:15.313847.313847 lmp.py:376]   Expert 23 |    230 | GPU
DEBUG 01-05 09:59:15.313298.313298 lmp.py:376]   Expert 59 |    230 | GPU
DEBUG 01-05 09:59:15.313272.313272 lmp.py:376]   Expert 10 |    231 | GPU
DEBUG 01-05 09:59:15.313723.313723 lmp.py:376]   Expert 47 |    232 | GPU
DEBUG 01-05 09:59:15.313412.313412 lmp.py:376]   Expert  1 |    238 | GPU
DEBUG 01-05 09:59:15.313101.313101 lmp.py:376]   Expert 13 |    242 | GPU
DEBUG 01-05 09:59:15.313744.313744 lmp.py:376]   Expert 24 |    244 | GPU
DEBUG 01-05 09:59:15.313957.313957 lmp.py:376]   Expert  0 |    249 | GPU
DEBUG 01-05 09:59:15.313407.313407 lmp.py:376]   Expert 36 |    251 | GPU
DEBUG 01-05 09:59:15.313620.313620 lmp.py:376]   Expert  9 |    253 | GPU
DEBUG 01-05 09:59:15.313594.313594 lmp.py:376]   Expert 38 |    261 | GPU
DEBUG 01-05 09:59:15.313806.313806 lmp.py:376]   Expert 16 |    268 | GPU
DEBUG 01-05 09:59:15.313019.313019 lmp.py:376]   Expert 18 |    275 | GPU
DEBUG 01-05 09:59:15.313231.313231 lmp.py:376]   Expert 46 |    292 | GPU
DEBUG 01-05 09:59:15.313682.313682 lmp.py:376]   Expert 60 |    296 | GPU
DEBUG 01-05 09:59:15.313133.313133 lmp.py:376]   Expert  3 |    306 | GPU
DEBUG 01-05 09:59:15.313584.313584 lmp.py:376]   Expert 49 |    311 | GPU
DEBUG 01-05 09:59:15.313558.313558 lmp.py:376]   Expert 30 |    318 | GPU
DEBUG 01-05 09:59:15.313771.313771 lmp.py:376]   Expert 19 |    324 | GPU
DEBUG 01-05 09:59:15.313983.313983 lmp.py:376]   Expert 26 |    338 | GPU
DEBUG 01-05 09:59:15.313195.313195 lmp.py:376]   Expert 21 |    342 | GPU
DEBUG 01-05 09:59:15.313408.313408 lmp.py:376]   Expert 27 |    352 | GPU
DEBUG 01-05 09:59:15.313620.313620 lmp.py:376]   Expert 17 |    372 | GPU
DEBUG 01-05 09:59:15.313833.313833 lmp.py:376]   Expert  8 |    555 | GPU
DEBUG 01-05 09:59:15.313237.313237 lmp.py:377] 
DEBUG 01-05 09:59:15.313237.313237 lmp.py:377]   CPU total tokens: 3623 (29.5%)
DEBUG 01-05 09:59:15.313880.313880 lmp.py:378]   GPU total tokens: 8665 (70.5%)
DEBUG 01-05 09:59:15.313245.313245 cuda_h.py:19] end experts_map_get cost 0.0014982223510742188 seconds
DEBUG 01-05 09:59:15.313127.313127 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.313572.313572 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.314749.314749 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.314294.314294 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-05 09:59:15.314952.314952 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.314231.314231 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.314391.314391 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.314710.314710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41ac2c41-3a54-4994-baca-f8c446e98014
DEBUG 01-05 09:59:15.314683.314683 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.314025.314025 client.py:127] Model loaded
DEBUG 01-05 09:59:15.315065.315065 cuda_h.py:19] end sllm_worker_task cost 0.009952783584594727 seconds
INFO 01-05 09:59:15.315327.315327 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41ac2c41-3a54-4994-baca-f8c446e98014
DEBUG 01-05 09:59:15.315554.315554 cuda_h.py:19] end load_into_gpu_async cost 0.0013589859008789062 seconds
DEBUG 01-05 09:59:15.315781.315781 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.316787.316787 cuda_h.py:19] end restore_tensors2 cost 0.0003654956817626953 seconds
DEBUG 01-05 09:59:15.316047.316047 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002293109893798828 seconds
DEBUG 01-05 09:59:15.318676.318676 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004908323287963867 seconds
DEBUG 01-05 09:59:15.318267.318267 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.319436.319436 lmp.py:423] 
DEBUG 01-05 09:59:15.319436.319436 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.319186.319186 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-05 09:59:15.319266.319266 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.331402.331402 mlpmodule.py:704] group tensors cost 0.012102842330932617 s
DEBUG 01-05 09:59:15.333351.333351 mlpmodule.py:742] pad cost 0.0016942024230957031 s
DEBUG 01-05 09:59:15.333560.333560 mlpmodule.py:748] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-05 09:59:15.334655.334655 mlpmodule.py:753] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-05 09:59:15.343055.343055 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.343625.343625 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.343006.343006 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:59:15.344911.344911 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.363155.363155 mlpmodule.py:793] group einsum cost 0.029491424560546875 s
DEBUG 01-05 09:59:15.364381.364381 mlpmodule.py:801] cpy2cputensor cost 0.0007634162902832031 s
DEBUG 01-05 09:59:15.369694.369694 cuda_h.py:19] end wait_cetm_experts cost 0.050657033920288086 seconds
DEBUG 01-05 09:59:15.370508.370508 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.370423.370423 cuda_h.py:19] end gpu_sexperts cost 0.0005967617034912109 seconds
DEBUG 01-05 09:59:15.370465.370465 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.370891.370891 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-05 09:59:15.370025.370025 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.370880.370880 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41ac2c41-3a54-4994-baca-f8c446e98014
INFO 01-05 09:59:15.371324.371324 client.py:127] Model loaded
DEBUG 01-05 09:59:15.371174.371174 cuda_h.py:19] end wait_experts cost 0.0010616779327392578 seconds
DEBUG 01-05 09:59:15.371261.371261 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.371255.371255 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.372552.372552 mlpmodule.py:531] gpu group tensors cost 0.0006613731384277344 s
DEBUG 01-05 09:59:15.374303.374303 mlpmodule.py:564] gpu pad cost 0.0017919540405273438 s
DEBUG 01-05 09:59:15.375261.375261 mlpmodule.py:582] gpu group einsum cost 0.0004401206970214844 s
DEBUG 01-05 09:59:15.378701.378701 mlpmodule.py:611] gpu experts func einsum cost 0.006493806838989258 s
DEBUG 01-05 09:59:15.378268.378268 cuda_h.py:19] end gpu_experts cost 0.006716728210449219 seconds
DEBUG 01-05 09:59:15.378630.378630 cuda_h.py:19] end layer_moe_generate_15 cost 0.06713604927062988 seconds
DEBUG 01-05 09:59:15.379267.379267 lmp.py:217] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 09:59:15.379460.379460 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 09:59:15.379256.379256 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:59:15.379349.379349 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:59:15.379292.379292 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.266334533691406e-05 seconds
DEBUG 01-05 09:59:15.379002.379002 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.866455078125e-05 seconds
DEBUG 01-05 09:59:15.379512.379512 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.379647.379647 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.379101.379101 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.379415.379415 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.383783.383783 cuda_h.py:19] end allocate_cuda_memory cost 0.0036001205444335938 seconds
DEBUG 01-05 09:59:15.383982.383982 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.383051.383051 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.383020.383020 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.383676.383676 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 30131bcc-2824-496c-bfda-7ec4369c1f7b
DEBUG 01-05 09:59:15.383646.383646 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.383076.383076 mlpmodule.py:662]  experts func einsum cost 0.06449484825134277 s
DEBUG 01-05 09:59:15.384994.384994 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.386562.386562 cuda_h.py:19] end self_attn cost 0.0024178028106689453 seconds
DEBUG 01-05 09:59:15.386631.386631 cuda_h.py:19] end iln_self_attn_paln cost 0.007674694061279297 seconds
DEBUG 01-05 09:59:15.387521.387521 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 09:59:15.387522.387522 cuda_h.py:10] start gate
INFO 01-05 09:59:15.387806.387806 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 30131bcc-2824-496c-bfda-7ec4369c1f7b
DEBUG 01-05 09:59:15.387994.387994 cuda_h.py:19] end load_into_gpu_async cost 0.004030466079711914 seconds
DEBUG 01-05 09:59:15.387326.387326 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.387860.387860 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:59:15.387768.387768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008217573165893555 seconds
INFO 01-05 09:59:15.388948.388948 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 30131bcc-2824-496c-bfda-7ec4369c1f7b
DEBUG 01-05 09:59:15.388858.388858 cuda_h.py:19] end gate cost 0.0013010501861572266 seconds
DEBUG 01-05 09:59:15.388902.388902 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.388608.388608 lmp.py:365] 
DEBUG 01-05 09:59:15.388608.388608 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.388318.388318 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.388683.388683 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.388756.388756 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.388207.388207 lmp.py:369] 
DEBUG 01-05 09:59:15.388207.388207 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.388897.388897 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.388831.388831 lmp.py:376]   Expert 58 |     24 | CPU
DEBUG 01-05 09:59:15.388759.388759 lmp.py:376]   Expert 43 |     54 | CPU
DEBUG 01-05 09:59:15.388971.388971 lmp.py:376]   Expert 14 |     59 | CPU
DEBUG 01-05 09:59:15.389707.389707 lmp.py:376]   Expert 13 |     76 | CPU
DEBUG 01-05 09:59:15.389442.389442 lmp.py:376]   Expert 54 |     80 | CPU
DEBUG 01-05 09:59:15.389609.389609 lmp.py:376]   Expert 45 |     86 | CPU
DEBUG 01-05 09:59:15.389059.389059 lmp.py:376]   Expert 39 |     88 | CPU
DEBUG 01-05 09:59:15.389795.389795 lmp.py:376]   Expert 11 |     90 | CPU
DEBUG 01-05 09:59:15.389769.389769 lmp.py:376]   Expert 59 |    101 | CPU
DEBUG 01-05 09:59:15.389028.389028 lmp.py:376]   Expert 60 |    102 | CPU
DEBUG 01-05 09:59:15.389764.389764 lmp.py:376]   Expert 57 |    111 | CPU
DEBUG 01-05 09:59:15.389261.389261 lmp.py:376]   Expert  6 |    117 | CPU
DEBUG 01-05 09:59:15.389235.389235 lmp.py:376]   Expert 18 |    117 | CPU
DEBUG 01-05 09:59:15.389494.389494 lmp.py:376]   Expert 34 |    118 | CPU
DEBUG 01-05 09:59:15.389229.389229 lmp.py:376]   Expert 28 |    119 | CPU
DEBUG 01-05 09:59:15.389442.389442 lmp.py:376]   Expert 61 |    120 | CPU
DEBUG 01-05 09:59:15.389177.389177 lmp.py:376]   Expert  0 |    128 | CPU
DEBUG 01-05 09:59:15.389675.389675 lmp.py:376]   Expert 41 |    130 | CPU
DEBUG 01-05 09:59:15.389410.389410 lmp.py:376]   Expert 49 |    130 | CPU
DEBUG 01-05 09:59:15.389146.389146 lmp.py:376]   Expert 25 |    132 | CPU
DEBUG 01-05 09:59:15.389120.389120 lmp.py:376]   Expert 51 |    134 | CPU
DEBUG 01-05 09:59:15.389094.389094 lmp.py:376]   Expert 62 |    135 | CPU
DEBUG 01-05 09:59:15.389591.389591 lmp.py:376]   Expert 35 |    139 | CPU
DEBUG 01-05 09:59:15.389565.389565 lmp.py:376]   Expert 32 |    145 | CPU
DEBUG 01-05 09:59:15.389539.389539 lmp.py:376]   Expert 50 |    146 | CPU
DEBUG 01-05 09:59:15.389275.389275 lmp.py:376]   Expert 30 |    148 | CPU
DEBUG 01-05 09:59:15.389534.389534 lmp.py:376]   Expert 12 |    150 | CPU
DEBUG 01-05 09:59:15.389269.389269 lmp.py:376]   Expert 38 |    160 | CPU
DEBUG 01-05 09:59:15.389766.389766 lmp.py:376]   Expert 15 |    164 | CPU
DEBUG 01-05 09:59:15.389264.389264 lmp.py:376]   Expert 37 |    169 | CPU
DEBUG 01-05 09:59:15.389761.389761 lmp.py:376]   Expert 26 |    176 | CPU
DEBUG 01-05 09:59:15.389258.389258 lmp.py:376]   Expert 31 |    178 | CPU
DEBUG 01-05 09:59:15.389755.389755 lmp.py:376]   Expert 48 |    184 | GPU
DEBUG 01-05 09:59:15.389014.389014 lmp.py:376]   Expert 42 |    189 | GPU
DEBUG 01-05 09:59:15.389750.389750 lmp.py:376]   Expert 63 |    192 | GPU
DEBUG 01-05 09:59:15.389724.389724 lmp.py:376]   Expert 56 |    193 | GPU
DEBUG 01-05 09:59:15.389698.389698 lmp.py:376]   Expert 10 |    199 | GPU
DEBUG 01-05 09:59:15.389433.389433 lmp.py:376]   Expert 44 |    201 | GPU
DEBUG 01-05 09:59:15.389692.389692 lmp.py:376]   Expert 55 |    204 | GPU
DEBUG 01-05 09:59:15.389428.389428 lmp.py:376]   Expert  3 |    207 | GPU
DEBUG 01-05 09:59:15.389687.389687 lmp.py:376]   Expert 21 |    208 | GPU
DEBUG 01-05 09:59:15.389945.389945 lmp.py:376]   Expert 40 |    211 | GPU
DEBUG 01-05 09:59:15.389443.389443 lmp.py:376]   Expert 33 |    224 | GPU
DEBUG 01-05 09:59:15.389609.389609 lmp.py:376]   Expert  1 |    229 | GPU
DEBUG 01-05 09:59:15.389536.389536 lmp.py:376]   Expert  9 |    231 | GPU
DEBUG 01-05 09:59:15.389987.389987 lmp.py:376]   Expert 47 |    231 | GPU
DEBUG 01-05 09:59:15.389869.389869 lmp.py:376]   Expert 16 |    232 | GPU
DEBUG 01-05 09:59:15.389320.389320 lmp.py:376]   Expert 19 |    245 | GPU
DEBUG 01-05 09:59:15.389009.389009 lmp.py:376]   Expert 46 |    251 | GPU
DEBUG 01-05 09:59:15.389175.389175 lmp.py:376]   Expert 36 |    252 | GPU
DEBUG 01-05 09:59:15.389864.389864 lmp.py:376]   Expert  2 |    259 | GPU
DEBUG 01-05 09:59:15.389554.389554 lmp.py:376]   Expert 24 |    262 | GPU
DEBUG 01-05 09:59:15.389766.389766 lmp.py:376]   Expert 20 |    265 | GPU
DEBUG 01-05 09:59:15.389217.389217 lmp.py:376]   Expert 22 |    275 | GPU
DEBUG 01-05 09:59:15.389668.389668 lmp.py:376]   Expert 53 |    275 | GPU
DEBUG 01-05 09:59:15.389311.389311 lmp.py:376]   Expert  7 |    287 | GPU
DEBUG 01-05 09:59:15.389762.389762 lmp.py:376]   Expert  8 |    288 | GPU
DEBUG 01-05 09:59:15.389974.389974 lmp.py:376]   Expert 29 |    304 | GPU
DEBUG 01-05 09:59:15.389663.389663 lmp.py:376]   Expert  4 |    345 | GPU
DEBUG 01-05 09:59:15.389876.389876 lmp.py:376]   Expert 23 |    347 | GPU
DEBUG 01-05 09:59:15.389088.389088 lmp.py:376]   Expert 17 |    373 | GPU
DEBUG 01-05 09:59:15.389778.389778 lmp.py:376]   Expert 27 |    425 | GPU
DEBUG 01-05 09:59:15.389229.389229 lmp.py:376]   Expert 52 |    436 | GPU
DEBUG 01-05 09:59:15.389918.389918 lmp.py:376]   Expert  5 |    438 | GPU
DEBUG 01-05 09:59:15.389038.389038 lmp.py:377] 
DEBUG 01-05 09:59:15.389038.389038 lmp.py:377]   CPU total tokens: 3826 (31.1%)
DEBUG 01-05 09:59:15.390681.390681 lmp.py:378]   GPU total tokens: 8462 (68.9%)
DEBUG 01-05 09:59:15.390377.390377 cuda_h.py:19] end experts_map_get cost 0.0014660358428955078 seconds
DEBUG 01-05 09:59:15.390020.390020 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.390419.390419 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.390172.390172 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.391186.391186 cuda_h.py:19] end allocate_cuda_memory cost 0.0007855892181396484 seconds
DEBUG 01-05 09:59:15.391121.391121 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.391877.391877 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.391687.391687 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.391813.391813 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54a95ba5-1606-4a35-ac9e-f6a922004a69
DEBUG 01-05 09:59:15.391840.391840 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.394327.394327 client.py:127] Model loaded
DEBUG 01-05 09:59:15.394716.394716 cuda_h.py:19] end sllm_worker_task cost 0.015366792678833008 seconds
INFO 01-05 09:59:15.395633.395633 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54a95ba5-1606-4a35-ac9e-f6a922004a69
DEBUG 01-05 09:59:15.395677.395677 cuda_h.py:19] end load_into_gpu_async cost 0.004476308822631836 seconds
DEBUG 01-05 09:59:15.395314.395314 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.396751.396751 cuda_h.py:19] end restore_tensors2 cost 0.0005545616149902344 seconds
DEBUG 01-05 09:59:15.396774.396774 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0062389373779296875 seconds
DEBUG 01-05 09:59:15.401810.401810 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011116504669189453 seconds
DEBUG 01-05 09:59:15.401588.401588 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.401042.401042 lmp.py:423] 
DEBUG 01-05 09:59:15.401042.401042 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.401947.401947 cuda_h.py:19] end cpu_experts_submit cost 0.0001766681671142578 seconds
DEBUG 01-05 09:59:15.401061.401061 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.413282.413282 mlpmodule.py:704] group tensors cost 0.011265993118286133 s
DEBUG 01-05 09:59:15.415980.415980 mlpmodule.py:742] pad cost 0.0016472339630126953 s
DEBUG 01-05 09:59:15.415838.415838 mlpmodule.py:748] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-05 09:59:15.415172.415172 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-05 09:59:15.425595.425595 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.425681.425681 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.425824.425824 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 09:59:15.425060.425060 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.443177.443177 mlpmodule.py:793] group einsum cost 0.02737259864807129 s
DEBUG 01-05 09:59:15.443672.443672 mlpmodule.py:801] cpy2cputensor cost 0.0006804466247558594 s
DEBUG 01-05 09:59:15.448166.448166 cuda_h.py:19] end wait_cetm_experts cost 0.04734945297241211 seconds
DEBUG 01-05 09:59:15.449682.449682 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.449630.449630 cuda_h.py:19] end gpu_sexperts cost 0.0005815029144287109 seconds
DEBUG 01-05 09:59:15.449433.449433 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.449528.449528 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:15.449423.449423 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.449087.449087 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54a95ba5-1606-4a35-ac9e-f6a922004a69
INFO 01-05 09:59:15.451182.451182 client.py:127] Model loaded
DEBUG 01-05 09:59:15.451740.451740 cuda_h.py:19] end wait_experts cost 0.0013270378112792969 seconds
DEBUG 01-05 09:59:15.451351.451351 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.451153.451153 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.452561.452561 mlpmodule.py:531] gpu group tensors cost 0.0006392002105712891 s
DEBUG 01-05 09:59:15.454254.454254 mlpmodule.py:564] gpu pad cost 0.0018620491027832031 s
DEBUG 01-05 09:59:15.454878.454878 mlpmodule.py:582] gpu group einsum cost 0.0005433559417724609 s
DEBUG 01-05 09:59:15.458022.458022 mlpmodule.py:611] gpu experts func einsum cost 0.006873607635498047 s
DEBUG 01-05 09:59:15.458257.458257 cuda_h.py:19] end gpu_experts cost 0.007064104080200195 seconds
DEBUG 01-05 09:59:15.458995.458995 cuda_h.py:19] end layer_moe_generate_16 cost 0.07149028778076172 seconds
DEBUG 01-05 09:59:15.458234.458234 lmp.py:217] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 09:59:15.458765.458765 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 09:59:15.458422.458422 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:59:15.458085.458085 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:59:15.458736.458736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:15.458346.458346 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.413459777832031e-05 seconds
DEBUG 01-05 09:59:15.458896.458896 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.459501.459501 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.459047.459047 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.459115.459115 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.462277.462277 cuda_h.py:19] end allocate_cuda_memory cost 0.003194570541381836 seconds
DEBUG 01-05 09:59:15.462532.462532 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.462348.462348 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.462078.462078 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.462496.462496 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f97cc1ba-0d3a-4122-833f-7b9860315a8a
DEBUG 01-05 09:59:15.462989.462989 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.462957.462957 mlpmodule.py:662]  experts func einsum cost 0.061126708984375 s
DEBUG 01-05 09:59:15.463703.463703 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.464753.464753 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f97cc1ba-0d3a-4122-833f-7b9860315a8a
DEBUG 01-05 09:59:15.464211.464211 cuda_h.py:19] end load_into_gpu_async cost 0.0016558170318603516 seconds
DEBUG 01-05 09:59:15.464722.464722 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.464990.464990 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-05 09:59:15.464839.464839 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005223751068115234 seconds
INFO 01-05 09:59:15.464279.464279 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f97cc1ba-0d3a-4122-833f-7b9860315a8a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.467786.467786 cuda_h.py:19] end self_attn cost 0.0037488937377929688 seconds
DEBUG 01-05 09:59:15.467246.467246 cuda_h.py:19] end iln_self_attn_paln cost 0.008443355560302734 seconds
DEBUG 01-05 09:59:15.467275.467275 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 09:59:15.467084.467084 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.468938.468938 cuda_h.py:19] end gate cost 0.0007364749908447266 seconds
DEBUG 01-05 09:59:15.468191.468191 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.468015.468015 lmp.py:365] 
DEBUG 01-05 09:59:15.468015.468015 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.468533.468533 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.468421.468421 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.468256.468256 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.468184.468184 lmp.py:369] 
DEBUG 01-05 09:59:15.468184.468184 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.468634.468634 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.468807.468807 lmp.py:376]   Expert 39 |     49 | CPU
DEBUG 01-05 09:59:15.468735.468735 lmp.py:376]   Expert 28 |     57 | CPU
DEBUG 01-05 09:59:15.468186.468186 lmp.py:376]   Expert 36 |     64 | CPU
DEBUG 01-05 09:59:15.468922.468922 lmp.py:376]   Expert 47 |     64 | CPU
DEBUG 01-05 09:59:15.468896.468896 lmp.py:376]   Expert 14 |     66 | CPU
DEBUG 01-05 09:59:15.468870.468870 lmp.py:376]   Expert  7 |     76 | CPU
DEBUG 01-05 09:59:15.468321.468321 lmp.py:376]   Expert  1 |     81 | CPU
DEBUG 01-05 09:59:15.468109.468109 lmp.py:376]   Expert  8 |     85 | CPU
DEBUG 01-05 09:59:15.468322.468322 lmp.py:376]   Expert 27 |     86 | CPU
DEBUG 01-05 09:59:15.468296.468296 lmp.py:376]   Expert 40 |     93 | CPU
DEBUG 01-05 09:59:15.468508.468508 lmp.py:376]   Expert 25 |     98 | CPU
DEBUG 01-05 09:59:15.468244.468244 lmp.py:376]   Expert 52 |     98 | CPU
DEBUG 01-05 09:59:15.468456.468456 lmp.py:376]   Expert  3 |    116 | CPU
DEBUG 01-05 09:59:15.468954.468954 lmp.py:376]   Expert 54 |    116 | CPU
DEBUG 01-05 09:59:15.468928.468928 lmp.py:376]   Expert 31 |    119 | CPU
DEBUG 01-05 09:59:15.468902.468902 lmp.py:376]   Expert 60 |    127 | CPU
DEBUG 01-05 09:59:15.469783.469783 lmp.py:376]   Expert 30 |    128 | CPU
DEBUG 01-05 09:59:15.469519.469519 lmp.py:376]   Expert 46 |    134 | CPU
DEBUG 01-05 09:59:15.469493.469493 lmp.py:376]   Expert 24 |    145 | CPU
DEBUG 01-05 09:59:15.469228.469228 lmp.py:376]   Expert 50 |    147 | CPU
DEBUG 01-05 09:59:15.469964.469964 lmp.py:376]   Expert 63 |    149 | CPU
DEBUG 01-05 09:59:15.469700.469700 lmp.py:376]   Expert  6 |    150 | CPU
DEBUG 01-05 09:59:15.469435.469435 lmp.py:376]   Expert 56 |    151 | CPU
DEBUG 01-05 09:59:15.469694.469694 lmp.py:376]   Expert 61 |    152 | CPU
DEBUG 01-05 09:59:15.469430.469430 lmp.py:376]   Expert 59 |    157 | CPU
DEBUG 01-05 09:59:15.469927.469927 lmp.py:376]   Expert  2 |    158 | CPU
DEBUG 01-05 09:59:15.469855.469855 lmp.py:376]   Expert 58 |    159 | CPU
DEBUG 01-05 09:59:15.469305.469305 lmp.py:376]   Expert 49 |    160 | CPU
DEBUG 01-05 09:59:15.469803.469803 lmp.py:376]   Expert 53 |    165 | CPU
DEBUG 01-05 09:59:15.469777.469777 lmp.py:376]   Expert 34 |    168 | CPU
DEBUG 01-05 09:59:15.469512.469512 lmp.py:376]   Expert 16 |    170 | CPU
DEBUG 01-05 09:59:15.469010.469010 lmp.py:376]   Expert 11 |    177 | CPU
DEBUG 01-05 09:59:15.469222.469222 lmp.py:376]   Expert 15 |    186 | GPU
DEBUG 01-05 09:59:15.469150.469150 lmp.py:376]   Expert 43 |    188 | GPU
DEBUG 01-05 09:59:15.469601.469601 lmp.py:376]   Expert 18 |    189 | GPU
DEBUG 01-05 09:59:15.469244.469244 lmp.py:376]   Expert 10 |    191 | GPU
DEBUG 01-05 09:59:15.469933.469933 lmp.py:376]   Expert 37 |    195 | GPU
DEBUG 01-05 09:59:15.469622.469622 lmp.py:376]   Expert 33 |    198 | GPU
DEBUG 01-05 09:59:15.469312.469312 lmp.py:376]   Expert 29 |    201 | GPU
DEBUG 01-05 09:59:15.469762.469762 lmp.py:376]   Expert 21 |    203 | GPU
DEBUG 01-05 09:59:15.469975.469975 lmp.py:376]   Expert 32 |    222 | GPU
DEBUG 01-05 09:59:15.469664.469664 lmp.py:376]   Expert 44 |    223 | GPU
DEBUG 01-05 09:59:15.469069.469069 lmp.py:376]   Expert 20 |    226 | GPU
DEBUG 01-05 09:59:15.469758.469758 lmp.py:376]   Expert 13 |    234 | GPU
DEBUG 01-05 09:59:15.469447.469447 lmp.py:376]   Expert 57 |    238 | GPU
DEBUG 01-05 09:59:15.469898.469898 lmp.py:376]   Expert  0 |    240 | GPU
DEBUG 01-05 09:59:15.469588.469588 lmp.py:376]   Expert 35 |    241 | GPU
DEBUG 01-05 09:59:15.469277.469277 lmp.py:376]   Expert 42 |    244 | GPU
DEBUG 01-05 09:59:15.469205.469205 lmp.py:376]   Expert  9 |    255 | GPU
DEBUG 01-05 09:59:15.469132.469132 lmp.py:376]   Expert 51 |    255 | GPU
DEBUG 01-05 09:59:15.469060.469060 lmp.py:376]   Expert 22 |    272 | GPU
DEBUG 01-05 09:59:15.469226.469226 lmp.py:376]   Expert  5 |    275 | GPU
DEBUG 01-05 09:59:15.469915.469915 lmp.py:376]   Expert 38 |    275 | GPU
DEBUG 01-05 09:59:15.469366.469366 lmp.py:376]   Expert 19 |    278 | GPU
DEBUG 01-05 09:59:15.469817.469817 lmp.py:376]   Expert 23 |    280 | GPU
DEBUG 01-05 09:59:15.469506.469506 lmp.py:376]   Expert 62 |    295 | GPU
DEBUG 01-05 09:59:15.469719.469719 lmp.py:376]   Expert 48 |    305 | GPU
DEBUG 01-05 09:59:15.469170.469170 lmp.py:376]   Expert  4 |    314 | GPU
DEBUG 01-05 09:59:15.469621.469621 lmp.py:376]   Expert 12 |    321 | GPU
DEBUG 01-05 09:59:15.469072.469072 lmp.py:376]   Expert 45 |    322 | GPU
DEBUG 01-05 09:59:15.469284.469284 lmp.py:376]   Expert 41 |    352 | GPU
DEBUG 01-05 09:59:15.469450.469450 lmp.py:376]   Expert 26 |    353 | GPU
DEBUG 01-05 09:59:15.469855.469855 lmp.py:376]   Expert 55 |    380 | GPU
DEBUG 01-05 09:59:15.469544.469544 lmp.py:376]   Expert 17 |    472 | GPU
DEBUG 01-05 09:59:15.469710.469710 lmp.py:377] 
DEBUG 01-05 09:59:15.469710.469710 lmp.py:377]   CPU total tokens: 3865 (31.5%)
DEBUG 01-05 09:59:15.469115.469115 lmp.py:378]   GPU total tokens: 8423 (68.5%)
DEBUG 01-05 09:59:15.469049.469049 cuda_h.py:19] end experts_map_get cost 0.0014832019805908203 seconds
DEBUG 01-05 09:59:15.469407.469407 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.469422.469422 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.470698.470698 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.470698.470698 cuda_h.py:19] end allocate_cuda_memory cost 0.0007388591766357422 seconds
DEBUG 01-05 09:59:15.470587.470587 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.470105.470105 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.470198.470198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.470087.470087 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97c95598-fd69-4c1c-99c3-61087c39053e
DEBUG 01-05 09:59:15.471219.471219 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.471173.471173 client.py:127] Model loaded
DEBUG 01-05 09:59:15.471553.471553 cuda_h.py:19] end sllm_worker_task cost 0.012350082397460938 seconds
INFO 01-05 09:59:15.472089.472089 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97c95598-fd69-4c1c-99c3-61087c39053e
DEBUG 01-05 09:59:15.473077.473077 cuda_h.py:19] end load_into_gpu_async cost 0.0021545886993408203 seconds
DEBUG 01-05 09:59:15.473496.473496 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.473389.473389 cuda_h.py:19] end restore_tensors2 cost 0.0003516674041748047 seconds
DEBUG 01-05 09:59:15.473980.473980 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035829544067382812 seconds
DEBUG 01-05 09:59:15.475724.475724 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006071329116821289 seconds
DEBUG 01-05 09:59:15.476931.476931 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.476669.476669 lmp.py:423] 
DEBUG 01-05 09:59:15.476669.476669 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.476181.476181 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-05 09:59:15.476546.476546 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.486763.486763 mlpmodule.py:704] group tensors cost 0.009814023971557617 s
DEBUG 01-05 09:59:15.488125.488125 mlpmodule.py:742] pad cost 0.0017092227935791016 s
DEBUG 01-05 09:59:15.488512.488512 mlpmodule.py:748] create cpu tensor cost 5.030632019042969e-05 s
DEBUG 01-05 09:59:15.488422.488422 mlpmodule.py:753] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-05 09:59:15.497018.497018 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.498979.498979 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.498744.498744 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 09:59:15.498603.498603 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.516596.516596 mlpmodule.py:793] group einsum cost 0.027462005615234375 s
DEBUG 01-05 09:59:15.517871.517871 mlpmodule.py:801] cpy2cputensor cost 0.0007004737854003906 s
DEBUG 01-05 09:59:15.522776.522776 cuda_h.py:19] end wait_cetm_experts cost 0.0461575984954834 seconds
DEBUG 01-05 09:59:15.522153.522153 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.523605.523605 cuda_h.py:19] end gpu_sexperts cost 0.0006043910980224609 seconds
DEBUG 01-05 09:59:15.523886.523886 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.523934.523934 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:15.523260.523260 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.523923.523923 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97c95598-fd69-4c1c-99c3-61087c39053e
INFO 01-05 09:59:15.528921.528921 client.py:127] Model loaded
DEBUG 01-05 09:59:15.528539.528539 cuda_h.py:19] end wait_experts cost 0.004738330841064453 seconds
DEBUG 01-05 09:59:15.528818.528818 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.528336.528336 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.528831.528831 mlpmodule.py:531] gpu group tensors cost 0.0006625652313232422 s
DEBUG 01-05 09:59:15.530734.530734 mlpmodule.py:564] gpu pad cost 0.001802682876586914 s
DEBUG 01-05 09:59:15.531676.531676 mlpmodule.py:582] gpu group einsum cost 0.0005321502685546875 s
DEBUG 01-05 09:59:15.534758.534758 mlpmodule.py:611] gpu experts func einsum cost 0.006191730499267578 s
DEBUG 01-05 09:59:15.534595.534595 cuda_h.py:19] end gpu_experts cost 0.006373405456542969 seconds
DEBUG 01-05 09:59:15.534254.534254 cuda_h.py:19] end layer_moe_generate_17 cost 0.06719374656677246 seconds
DEBUG 01-05 09:59:15.534916.534916 lmp.py:217] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 09:59:15.534824.534824 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 09:59:15.534090.534090 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:59:15.534415.534415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:59:15.535013.535013 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.86102294921875e-05 seconds
DEBUG 01-05 09:59:15.535829.535829 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.319450378417969e-05 seconds
DEBUG 01-05 09:59:15.535187.535187 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.535454.535454 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.535869.535869 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.535328.535328 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.535428.535428 cuda_h.py:19] end allocate_cuda_memory cost 0.00038814544677734375 seconds
DEBUG 01-05 09:59:15.535902.535902 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.535572.535572 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.535918.535918 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.535144.535144 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ddaecaa7-0d90-4c8e-91f5-5a266c610f65
DEBUG 01-05 09:59:15.536683.536683 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.536947.536947 mlpmodule.py:662]  experts func einsum cost 0.059836387634277344 s
DEBUG 01-05 09:59:15.536977.536977 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.536648.536648 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ddaecaa7-0d90-4c8e-91f5-5a266c610f65
DEBUG 01-05 09:59:15.537345.537345 cuda_h.py:19] end load_into_gpu_async cost 0.001130819320678711 seconds
DEBUG 01-05 09:59:15.537048.537048 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.537489.537489 cuda_h.py:19] end restore_tensors2 cost 8.559226989746094e-05 seconds
DEBUG 01-05 09:59:15.537351.537351 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018968582153320312 seconds
INFO 01-05 09:59:15.537204.537204 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ddaecaa7-0d90-4c8e-91f5-5a266c610f65
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.540195.540195 cuda_h.py:19] end self_attn cost 0.0036466121673583984 seconds
DEBUG 01-05 09:59:15.540404.540404 cuda_h.py:19] end iln_self_attn_paln cost 0.005467891693115234 seconds
DEBUG 01-05 09:59:15.540817.540817 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 09:59:15.540295.540295 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.541721.541721 cuda_h.py:19] end gate cost 0.0006320476531982422 seconds
DEBUG 01-05 09:59:15.541882.541882 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.541329.541329 lmp.py:365] 
DEBUG 01-05 09:59:15.541329.541329 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.541131.541131 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.541781.541781 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.541570.541570 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.541497.541497 lmp.py:369] 
DEBUG 01-05 09:59:15.541497.541497 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.541425.541425 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.541313.541313 lmp.py:376]   Expert 35 |     52 | CPU
DEBUG 01-05 09:59:15.541956.541956 lmp.py:376]   Expert  0 |     60 | CPU
DEBUG 01-05 09:59:15.541884.541884 lmp.py:376]   Expert 53 |     62 | CPU
DEBUG 01-05 09:59:15.541573.541573 lmp.py:376]   Expert 19 |     65 | CPU
DEBUG 01-05 09:59:15.541786.541786 lmp.py:376]   Expert 58 |     66 | CPU
DEBUG 01-05 09:59:15.541236.541236 lmp.py:376]   Expert 54 |     67 | CPU
DEBUG 01-05 09:59:15.541164.541164 lmp.py:376]   Expert  3 |     69 | CPU
DEBUG 01-05 09:59:15.541046.541046 lmp.py:376]   Expert  6 |     76 | CPU
DEBUG 01-05 09:59:15.541973.541973 lmp.py:376]   Expert 12 |     89 | CPU
DEBUG 01-05 09:59:15.541424.541424 lmp.py:376]   Expert 34 |     89 | CPU
DEBUG 01-05 09:59:15.541875.541875 lmp.py:376]   Expert 37 |     89 | CPU
DEBUG 01-05 09:59:15.541088.541088 lmp.py:376]   Expert 20 |     91 | CPU
DEBUG 01-05 09:59:15.542538.542538 lmp.py:376]   Expert 60 |     92 | CPU
DEBUG 01-05 09:59:15.542512.542512 lmp.py:376]   Expert 41 |     93 | CPU
DEBUG 01-05 09:59:15.542202.542202 lmp.py:376]   Expert 40 |     98 | CPU
DEBUG 01-05 09:59:15.542891.542891 lmp.py:376]   Expert 63 |    104 | CPU
DEBUG 01-05 09:59:15.542104.542104 lmp.py:376]   Expert 48 |    105 | CPU
DEBUG 01-05 09:59:15.542078.542078 lmp.py:376]   Expert  8 |    113 | CPU
DEBUG 01-05 09:59:15.542528.542528 lmp.py:376]   Expert 46 |    113 | CPU
DEBUG 01-05 09:59:15.542741.542741 lmp.py:376]   Expert 30 |    119 | CPU
DEBUG 01-05 09:59:15.542715.542715 lmp.py:376]   Expert 44 |    119 | CPU
DEBUG 01-05 09:59:15.542927.542927 lmp.py:376]   Expert 32 |    120 | CPU
DEBUG 01-05 09:59:15.542140.542140 lmp.py:376]   Expert 43 |    123 | CPU
DEBUG 01-05 09:59:15.542783.542783 lmp.py:376]   Expert 13 |    132 | CPU
DEBUG 01-05 09:59:15.542380.542380 lmp.py:376]   Expert 45 |    132 | CPU
DEBUG 01-05 09:59:15.542499.542499 lmp.py:376]   Expert 33 |    139 | CPU
DEBUG 01-05 09:59:15.542427.542427 lmp.py:376]   Expert 29 |    142 | CPU
DEBUG 01-05 09:59:15.542593.542593 lmp.py:376]   Expert  4 |    147 | CPU
DEBUG 01-05 09:59:15.542759.542759 lmp.py:376]   Expert  5 |    147 | CPU
DEBUG 01-05 09:59:15.542925.542925 lmp.py:376]   Expert 55 |    147 | CPU
DEBUG 01-05 09:59:15.542853.542853 lmp.py:376]   Expert 17 |    148 | CPU
DEBUG 01-05 09:59:15.542781.542781 lmp.py:376]   Expert 25 |    161 | CPU
DEBUG 01-05 09:59:15.542947.542947 lmp.py:376]   Expert 11 |    170 | GPU
DEBUG 01-05 09:59:15.542067.542067 lmp.py:376]   Expert 18 |    171 | GPU
DEBUG 01-05 09:59:15.542948.542948 lmp.py:376]   Expert 39 |    173 | GPU
DEBUG 01-05 09:59:15.542114.542114 lmp.py:376]   Expert 27 |    174 | GPU
DEBUG 01-05 09:59:15.542042.542042 lmp.py:376]   Expert 42 |    190 | GPU
DEBUG 01-05 09:59:15.542208.542208 lmp.py:376]   Expert 56 |    193 | GPU
DEBUG 01-05 09:59:15.542374.542374 lmp.py:376]   Expert 52 |    194 | GPU
DEBUG 01-05 09:59:15.542064.542064 lmp.py:376]   Expert 22 |    205 | GPU
DEBUG 01-05 09:59:15.542230.542230 lmp.py:376]   Expert 24 |    211 | GPU
DEBUG 01-05 09:59:15.542919.542919 lmp.py:376]   Expert 51 |    213 | GPU
DEBUG 01-05 09:59:15.542085.542085 lmp.py:376]   Expert  9 |    214 | GPU
DEBUG 01-05 09:59:15.542444.542444 lmp.py:376]   Expert  1 |    216 | GPU
DEBUG 01-05 09:59:15.542325.542325 lmp.py:376]   Expert  7 |    216 | GPU
DEBUG 01-05 09:59:15.542491.542491 lmp.py:376]   Expert 50 |    221 | GPU
DEBUG 01-05 09:59:15.542419.542419 lmp.py:376]   Expert 59 |    227 | GPU
DEBUG 01-05 09:59:15.542108.542108 lmp.py:376]   Expert 61 |    239 | GPU
DEBUG 01-05 09:59:15.542036.542036 lmp.py:376]   Expert 16 |    268 | GPU
DEBUG 01-05 09:59:15.542202.542202 lmp.py:376]   Expert 28 |    269 | GPU
DEBUG 01-05 09:59:15.542130.542130 lmp.py:376]   Expert 31 |    273 | GPU
DEBUG 01-05 09:59:15.542057.542057 lmp.py:376]   Expert 47 |    273 | GPU
DEBUG 01-05 09:59:15.542223.542223 lmp.py:376]   Expert 57 |    274 | GPU
DEBUG 01-05 09:59:15.542105.542105 lmp.py:376]   Expert 21 |    291 | GPU
DEBUG 01-05 09:59:15.542986.542986 lmp.py:376]   Expert 14 |    305 | GPU
DEBUG 01-05 09:59:15.542391.542391 lmp.py:376]   Expert 38 |    313 | GPU
DEBUG 01-05 09:59:15.542319.542319 lmp.py:376]   Expert 10 |    337 | GPU
DEBUG 01-05 09:59:15.542246.542246 lmp.py:376]   Expert  2 |    340 | GPU
DEBUG 01-05 09:59:15.542412.542412 lmp.py:376]   Expert 15 |    351 | GPU
DEBUG 01-05 09:59:15.542340.542340 lmp.py:376]   Expert 49 |    367 | GPU
DEBUG 01-05 09:59:15.542268.542268 lmp.py:376]   Expert 36 |    410 | GPU
DEBUG 01-05 09:59:15.542196.542196 lmp.py:376]   Expert 23 |    433 | GPU
DEBUG 01-05 09:59:15.542646.542646 lmp.py:376]   Expert 26 |    466 | GPU
DEBUG 01-05 09:59:15.542574.542574 lmp.py:376]   Expert 62 |    722 | GPU
DEBUG 01-05 09:59:15.542409.542409 lmp.py:377] 
DEBUG 01-05 09:59:15.542409.542409 lmp.py:377]   CPU total tokens: 3369 (27.4%)
DEBUG 01-05 09:59:15.542244.542244 lmp.py:378]   GPU total tokens: 8919 (72.6%)
DEBUG 01-05 09:59:15.542417.542417 cuda_h.py:19] end experts_map_get cost 0.00152587890625 seconds
DEBUG 01-05 09:59:15.542775.542775 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.543221.543221 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.543450.543450 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.544219.544219 cuda_h.py:19] end allocate_cuda_memory cost 0.0011658668518066406 seconds
DEBUG 01-05 09:59:15.544360.544360 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.544753.544753 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.544039.544039 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.544894.544894 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb0ad15e-74ac-42ca-b440-d002c567677f
DEBUG 01-05 09:59:15.544682.544682 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.545701.545701 client.py:127] Model loaded
DEBUG 01-05 09:59:15.545412.545412 cuda_h.py:19] end sllm_worker_task cost 0.009887456893920898 seconds
INFO 01-05 09:59:15.545303.545303 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb0ad15e-74ac-42ca-b440-d002c567677f
DEBUG 01-05 09:59:15.545723.545723 cuda_h.py:19] end load_into_gpu_async cost 0.001280069351196289 seconds
DEBUG 01-05 09:59:15.545949.545949 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.546491.546491 cuda_h.py:19] end restore_tensors2 cost 0.00033926963806152344 seconds
DEBUG 01-05 09:59:15.546697.546697 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031366348266601562 seconds
DEBUG 01-05 09:59:15.548598.548598 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0057408809661865234 seconds
DEBUG 01-05 09:59:15.548904.548904 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.548026.548026 lmp.py:423] 
DEBUG 01-05 09:59:15.548026.548026 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.548730.548730 cuda_h.py:19] end cpu_experts_submit cost 0.0001246929168701172 seconds
DEBUG 01-05 09:59:15.548956.548956 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.553757.553757 mlpmodule.py:704] group tensors cost 0.004703044891357422 s
DEBUG 01-05 09:59:15.556932.556932 mlpmodule.py:742] pad cost 0.0017194747924804688 s
DEBUG 01-05 09:59:15.556856.556856 mlpmodule.py:748] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-05 09:59:15.556389.556389 mlpmodule.py:753] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-05 09:59:15.565181.565181 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.565559.565559 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.565940.565940 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 09:59:15.566991.566991 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.583144.583144 mlpmodule.py:793] group einsum cost 0.027396202087402344 s
DEBUG 01-05 09:59:15.584374.584374 mlpmodule.py:801] cpy2cputensor cost 0.0006957054138183594 s
DEBUG 01-05 09:59:15.589627.589627 cuda_h.py:19] end wait_cetm_experts cost 0.040723323822021484 seconds
DEBUG 01-05 09:59:15.589805.589805 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.590872.590872 cuda_h.py:19] end gpu_sexperts cost 0.0005669593811035156 seconds
DEBUG 01-05 09:59:15.590013.590013 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.590585.590585 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:15.590434.590434 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.590336.590336 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb0ad15e-74ac-42ca-b440-d002c567677f
INFO 01-05 09:59:15.601040.601040 client.py:127] Model loaded
DEBUG 01-05 09:59:15.601721.601721 cuda_h.py:19] end wait_experts cost 0.010698795318603516 seconds
DEBUG 01-05 09:59:15.601492.601492 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.601024.601024 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.602320.602320 mlpmodule.py:531] gpu group tensors cost 0.0005967617034912109 s
DEBUG 01-05 09:59:15.602990.602990 mlpmodule.py:662]  experts func einsum cost 0.05342292785644531 s
DEBUG 01-05 09:59:15.604237.604237 mlpmodule.py:564] gpu pad cost 0.0015976428985595703 s
DEBUG 01-05 09:59:15.604616.604616 mlpmodule.py:582] gpu group einsum cost 0.0005044937133789062 s
DEBUG 01-05 09:59:15.607126.607126 mlpmodule.py:611] gpu experts func einsum cost 0.005685329437255859 s
DEBUG 01-05 09:59:15.607672.607672 cuda_h.py:19] end gpu_experts cost 0.005934000015258789 seconds
DEBUG 01-05 09:59:15.607093.607093 cuda_h.py:19] end layer_moe_generate_18 cost 0.0669558048248291 seconds
DEBUG 01-05 09:59:15.607847.607847 lmp.py:217] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 09:59:15.607464.607464 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 09:59:15.607968.607968 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:59:15.607294.607294 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:59:15.607368.607368 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 09:59:15.607184.607184 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.462501525878906e-05 seconds
DEBUG 01-05 09:59:15.607066.607066 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.608043.608043 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.608911.608911 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.608255.608255 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.609569.609569 cuda_h.py:19] end allocate_cuda_memory cost 0.0005395412445068359 seconds
DEBUG 01-05 09:59:15.609952.609952 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.609168.609168 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.609497.609497 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.609739.609739 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 38c1227e-8d7c-4d7d-a0c3-00218c03499c
DEBUG 01-05 09:59:15.609369.609369 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.610651.610651 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.611603.611603 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 38c1227e-8d7c-4d7d-a0c3-00218c03499c
DEBUG 01-05 09:59:15.611913.611913 cuda_h.py:19] end load_into_gpu_async cost 0.002267122268676758 seconds
DEBUG 01-05 09:59:15.611294.611294 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.612992.612992 cuda_h.py:19] end restore_tensors2 cost 0.00016689300537109375 seconds
DEBUG 01-05 09:59:15.612340.612340 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037546157836914062 seconds
INFO 01-05 09:59:15.613747.613747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 38c1227e-8d7c-4d7d-a0c3-00218c03499c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.615041.615041 cuda_h.py:19] end self_attn cost 0.004939079284667969 seconds
DEBUG 01-05 09:59:15.615277.615277 cuda_h.py:19] end iln_self_attn_paln cost 0.0074656009674072266 seconds
DEBUG 01-05 09:59:15.615497.615497 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 09:59:15.615452.615452 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.616701.616701 cuda_h.py:19] end gate cost 0.0006766319274902344 seconds
DEBUG 01-05 09:59:15.616862.616862 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.616170.616170 lmp.py:365] 
DEBUG 01-05 09:59:15.616170.616170 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.616548.616548 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.616152.616152 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.616417.616417 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.616491.616491 lmp.py:369] 
DEBUG 01-05 09:59:15.616491.616491 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.616372.616372 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.616214.616214 lmp.py:376]   Expert 60 |     56 | CPU
DEBUG 01-05 09:59:15.616572.616572 lmp.py:376]   Expert 56 |     58 | CPU
DEBUG 01-05 09:59:15.616453.616453 lmp.py:376]   Expert 12 |     61 | CPU
DEBUG 01-05 09:59:15.616573.616573 lmp.py:376]   Expert  5 |     76 | CPU
DEBUG 01-05 09:59:15.616693.616693 lmp.py:376]   Expert 55 |     77 | CPU
DEBUG 01-05 09:59:15.616528.616528 lmp.py:376]   Expert 59 |     81 | CPU
DEBUG 01-05 09:59:15.616410.616410 lmp.py:376]   Expert 44 |     84 | CPU
DEBUG 01-05 09:59:15.616814.616814 lmp.py:376]   Expert 48 |     86 | CPU
DEBUG 01-05 09:59:15.616696.616696 lmp.py:376]   Expert 18 |     87 | CPU
DEBUG 01-05 09:59:15.616339.616339 lmp.py:376]   Expert  6 |     88 | CPU
DEBUG 01-05 09:59:15.616743.616743 lmp.py:376]   Expert 30 |     97 | CPU
DEBUG 01-05 09:59:15.616386.616386 lmp.py:376]   Expert 23 |    100 | CPU
DEBUG 01-05 09:59:15.616029.616029 lmp.py:376]   Expert 52 |    102 | CPU
DEBUG 01-05 09:59:15.616864.616864 lmp.py:376]   Expert 42 |    105 | CPU
DEBUG 01-05 09:59:15.617699.617699 lmp.py:376]   Expert 33 |    110 | CPU
DEBUG 01-05 09:59:15.617342.617342 lmp.py:376]   Expert 34 |    118 | CPU
DEBUG 01-05 09:59:15.617508.617508 lmp.py:376]   Expert 27 |    119 | CPU
DEBUG 01-05 09:59:15.617151.617151 lmp.py:376]   Expert 32 |    130 | CPU
DEBUG 01-05 09:59:15.617556.617556 lmp.py:376]   Expert 24 |    136 | CPU
DEBUG 01-05 09:59:15.617960.617960 lmp.py:376]   Expert 54 |    136 | CPU
DEBUG 01-05 09:59:15.617126.617126 lmp.py:376]   Expert 57 |    146 | CPU
DEBUG 01-05 09:59:15.617531.617531 lmp.py:376]   Expert 63 |    147 | CPU
DEBUG 01-05 09:59:15.617174.617174 lmp.py:376]   Expert 15 |    150 | CPU
DEBUG 01-05 09:59:15.617294.617294 lmp.py:376]   Expert 58 |    151 | CPU
DEBUG 01-05 09:59:15.617937.617937 lmp.py:376]   Expert 13 |    152 | CPU
DEBUG 01-05 09:59:15.617103.617103 lmp.py:376]   Expert 62 |    153 | CPU
DEBUG 01-05 09:59:15.617507.617507 lmp.py:376]   Expert 16 |    155 | CPU
DEBUG 01-05 09:59:15.617150.617150 lmp.py:376]   Expert  1 |    156 | CPU
DEBUG 01-05 09:59:15.617555.617555 lmp.py:376]   Expert  8 |    159 | CPU
DEBUG 01-05 09:59:15.617960.617960 lmp.py:376]   Expert 17 |    159 | CPU
DEBUG 01-05 09:59:15.617364.617364 lmp.py:376]   Expert 26 |    159 | CPU
DEBUG 01-05 09:59:15.617722.617722 lmp.py:376]   Expert 46 |    163 | CPU
DEBUG 01-05 09:59:15.617842.617842 lmp.py:376]   Expert  0 |    165 | GPU
DEBUG 01-05 09:59:15.617485.617485 lmp.py:376]   Expert 19 |    167 | GPU
DEBUG 01-05 09:59:15.617890.617890 lmp.py:376]   Expert 49 |    173 | GPU
DEBUG 01-05 09:59:15.617294.617294 lmp.py:376]   Expert 39 |    178 | GPU
DEBUG 01-05 09:59:15.617699.617699 lmp.py:376]   Expert 43 |    179 | GPU
DEBUG 01-05 09:59:15.617103.617103 lmp.py:376]   Expert 47 |    185 | GPU
DEBUG 01-05 09:59:15.617746.617746 lmp.py:376]   Expert  4 |    195 | GPU
DEBUG 01-05 09:59:15.617389.617389 lmp.py:376]   Expert 25 |    199 | GPU
DEBUG 01-05 09:59:15.617032.617032 lmp.py:376]   Expert 40 |    202 | GPU
DEBUG 01-05 09:59:15.617106.617106 lmp.py:376]   Expert 53 |    203 | GPU
DEBUG 01-05 09:59:15.617510.617510 lmp.py:376]   Expert 50 |    206 | GPU
DEBUG 01-05 09:59:15.617153.617153 lmp.py:376]   Expert 37 |    219 | GPU
DEBUG 01-05 09:59:15.617319.617319 lmp.py:376]   Expert 22 |    222 | GPU
DEBUG 01-05 09:59:15.617724.617724 lmp.py:376]   Expert 20 |    223 | GPU
DEBUG 01-05 09:59:15.617890.617890 lmp.py:376]   Expert 35 |    228 | GPU
DEBUG 01-05 09:59:15.617579.617579 lmp.py:376]   Expert 14 |    236 | GPU
DEBUG 01-05 09:59:15.617222.617222 lmp.py:376]   Expert 11 |    244 | GPU
DEBUG 01-05 09:59:15.617627.617627 lmp.py:376]   Expert 41 |    259 | GPU
DEBUG 01-05 09:59:15.617270.617270 lmp.py:376]   Expert 51 |    262 | GPU
DEBUG 01-05 09:59:15.617675.617675 lmp.py:376]   Expert 38 |    277 | GPU
DEBUG 01-05 09:59:15.617556.617556 lmp.py:376]   Expert 36 |    285 | GPU
DEBUG 01-05 09:59:15.617437.617437 lmp.py:376]   Expert 28 |    300 | GPU
DEBUG 01-05 09:59:15.617080.617080 lmp.py:376]   Expert 21 |    301 | GPU
DEBUG 01-05 09:59:15.617723.617723 lmp.py:376]   Expert 45 |    317 | GPU
DEBUG 01-05 09:59:15.617128.617128 lmp.py:376]   Expert 10 |    319 | GPU
DEBUG 01-05 09:59:15.617009.617009 lmp.py:376]   Expert  2 |    357 | GPU
DEBUG 01-05 09:59:15.617891.617891 lmp.py:376]   Expert  9 |    357 | GPU
DEBUG 01-05 09:59:15.617772.617772 lmp.py:376]   Expert  3 |    362 | GPU
DEBUG 01-05 09:59:15.617461.617461 lmp.py:376]   Expert 61 |    375 | GPU
DEBUG 01-05 09:59:15.617820.617820 lmp.py:376]   Expert 29 |    402 | GPU
DEBUG 01-05 09:59:15.617939.617939 lmp.py:376]   Expert 31 |    411 | GPU
DEBUG 01-05 09:59:15.617582.617582 lmp.py:376]   Expert  7 |    523 | GPU
DEBUG 01-05 09:59:15.617941.617941 lmp.py:377] 
DEBUG 01-05 09:59:15.617941.617941 lmp.py:377]   CPU total tokens: 3757 (30.6%)
DEBUG 01-05 09:59:15.617776.617776 lmp.py:378]   GPU total tokens: 8531 (69.4%)
DEBUG 01-05 09:59:15.617425.617425 cuda_h.py:19] end experts_map_get cost 0.0015828609466552734 seconds
DEBUG 01-05 09:59:15.617545.617545 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.618990.618990 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.618035.618035 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.618189.618189 cuda_h.py:19] end allocate_cuda_memory cost 0.0008177757263183594 seconds
DEBUG 01-05 09:59:15.619271.619271 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.619503.619503 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.619373.619373 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.619453.619453 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c06cb91d-2f5f-40cd-9357-e1174cb4db65
DEBUG 01-05 09:59:15.619472.619472 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.619163.619163 client.py:127] Model loaded
DEBUG 01-05 09:59:15.619842.619842 cuda_h.py:19] end sllm_worker_task cost 0.011585235595703125 seconds
INFO 01-05 09:59:15.621939.621939 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c06cb91d-2f5f-40cd-9357-e1174cb4db65
DEBUG 01-05 09:59:15.621228.621228 cuda_h.py:19] end load_into_gpu_async cost 0.002462148666381836 seconds
DEBUG 01-05 09:59:15.621753.621753 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.621070.621070 cuda_h.py:19] end restore_tensors2 cost 0.00033354759216308594 seconds
DEBUG 01-05 09:59:15.622038.622038 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003980159759521484 seconds
DEBUG 01-05 09:59:15.624368.624368 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0065441131591796875 seconds
DEBUG 01-05 09:59:15.624575.624575 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.624174.624174 lmp.py:423] 
DEBUG 01-05 09:59:15.624174.624174 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.624832.624832 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-05 09:59:15.624727.624727 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.632808.632808 mlpmodule.py:704] group tensors cost 0.007114887237548828 s
DEBUG 01-05 09:59:15.634807.634807 mlpmodule.py:742] pad cost 0.0019333362579345703 s
DEBUG 01-05 09:59:15.634771.634771 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-05 09:59:15.635912.635912 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-05 09:59:15.644011.644011 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.644767.644767 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.644155.644155 mlpmodule.py:773] group_w3 first element: 0.051513671875
WARNING 01-05 09:59:15.644782.644782 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.661966.661966 mlpmodule.py:793] group einsum cost 0.026249408721923828 s
DEBUG 01-05 09:59:15.662309.662309 mlpmodule.py:801] cpy2cputensor cost 0.0007069110870361328 s
DEBUG 01-05 09:59:15.667571.667571 cuda_h.py:19] end wait_cetm_experts cost 0.042537689208984375 seconds
DEBUG 01-05 09:59:15.667947.667947 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.668253.668253 cuda_h.py:19] end gpu_sexperts cost 0.0005640983581542969 seconds
DEBUG 01-05 09:59:15.668387.668387 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.668482.668482 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:15.668331.668331 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.668756.668756 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c06cb91d-2f5f-40cd-9357-e1174cb4db65
INFO 01-05 09:59:15.676011.676011 client.py:127] Model loaded
DEBUG 01-05 09:59:15.676960.676960 cuda_h.py:19] end wait_experts cost 0.007876873016357422 seconds
DEBUG 01-05 09:59:15.676716.676716 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.676949.676949 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.676323.676323 mlpmodule.py:531] gpu group tensors cost 0.0006067752838134766 s
DEBUG 01-05 09:59:15.678304.678304 mlpmodule.py:564] gpu pad cost 0.0015423297882080078 s
DEBUG 01-05 09:59:15.679543.679543 mlpmodule.py:582] gpu group einsum cost 0.0005238056182861328 s
DEBUG 01-05 09:59:15.680088.680088 mlpmodule.py:662]  experts func einsum cost 0.05546116828918457 s
DEBUG 01-05 09:59:15.682677.682677 mlpmodule.py:611] gpu experts func einsum cost 0.006024360656738281 s
DEBUG 01-05 09:59:15.682358.682358 cuda_h.py:19] end gpu_experts cost 0.006272315979003906 seconds
DEBUG 01-05 09:59:15.682850.682850 cuda_h.py:19] end layer_moe_generate_19 cost 0.06708240509033203 seconds
DEBUG 01-05 09:59:15.682439.682439 lmp.py:217] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 09:59:15.682871.682871 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 09:59:15.682614.682614 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:59:15.682177.682177 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:59:15.682113.682113 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:15.683624.683624 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.175041198730469e-05 seconds
DEBUG 01-05 09:59:15.683128.683128 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.683668.683668 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.683976.683976 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.683886.683886 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.683805.683805 cuda_h.py:19] end allocate_cuda_memory cost 0.00032329559326171875 seconds
DEBUG 01-05 09:59:15.683728.683728 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.683730.683730 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.683168.683168 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.683633.683633 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ebc6fd3b-57d4-4058-9ec6-6ac57f014314
DEBUG 01-05 09:59:15.683887.683887 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.684570.684570 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.685720.685720 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ebc6fd3b-57d4-4058-9ec6-6ac57f014314
DEBUG 01-05 09:59:15.685749.685749 cuda_h.py:19] end load_into_gpu_async cost 0.0015587806701660156 seconds
DEBUG 01-05 09:59:15.685544.685544 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.685720.685720 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-05 09:59:15.685807.685807 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022115707397460938 seconds
INFO 01-05 09:59:15.685194.685194 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ebc6fd3b-57d4-4058-9ec6-6ac57f014314
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.687349.687349 cuda_h.py:19] end self_attn cost 0.0032155513763427734 seconds
DEBUG 01-05 09:59:15.687279.687279 cuda_h.py:19] end iln_self_attn_paln cost 0.004679679870605469 seconds
DEBUG 01-05 09:59:15.687261.687261 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 09:59:15.687739.687739 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.688251.688251 cuda_h.py:19] end gate cost 0.0006251335144042969 seconds
DEBUG 01-05 09:59:15.688697.688697 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.688991.688991 lmp.py:365] 
DEBUG 01-05 09:59:15.688991.688991 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.688555.688555 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.688728.688728 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.688040.688040 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.688444.688444 lmp.py:369] 
DEBUG 01-05 09:59:15.688444.688444 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.688087.688087 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.688214.688214 lmp.py:376]   Expert 54 |     45 | CPU
DEBUG 01-05 09:59:15.688618.688618 lmp.py:376]   Expert  8 |     53 | CPU
DEBUG 01-05 09:59:15.688308.688308 lmp.py:376]   Expert 28 |     55 | CPU
DEBUG 01-05 09:59:15.689520.689520 lmp.py:376]   Expert 13 |     71 | CPU
DEBUG 01-05 09:59:15.689733.689733 lmp.py:376]   Expert 43 |     75 | CPU
DEBUG 01-05 09:59:15.689137.689137 lmp.py:376]   Expert  1 |     79 | CPU
DEBUG 01-05 09:59:15.689065.689065 lmp.py:376]   Expert  6 |     80 | CPU
DEBUG 01-05 09:59:15.689754.689754 lmp.py:376]   Expert 12 |     92 | CPU
DEBUG 01-05 09:59:15.689967.689967 lmp.py:376]   Expert 36 |     96 | CPU
DEBUG 01-05 09:59:15.689179.689179 lmp.py:376]   Expert 42 |     96 | CPU
DEBUG 01-05 09:59:15.689392.689392 lmp.py:376]   Expert 19 |    101 | CPU
DEBUG 01-05 09:59:15.689366.689366 lmp.py:376]   Expert 33 |    102 | CPU
DEBUG 01-05 09:59:15.689340.689340 lmp.py:376]   Expert 10 |    114 | CPU
DEBUG 01-05 09:59:15.689314.689314 lmp.py:376]   Expert 51 |    116 | CPU
DEBUG 01-05 09:59:15.689811.689811 lmp.py:376]   Expert 30 |    120 | CPU
DEBUG 01-05 09:59:15.689785.689785 lmp.py:376]   Expert 38 |    121 | CPU
DEBUG 01-05 09:59:15.689521.689521 lmp.py:376]   Expert 14 |    124 | CPU
DEBUG 01-05 09:59:15.689495.689495 lmp.py:376]   Expert 57 |    125 | CPU
DEBUG 01-05 09:59:15.689992.689992 lmp.py:376]   Expert 39 |    129 | CPU
DEBUG 01-05 09:59:15.689966.689966 lmp.py:376]   Expert 50 |    130 | CPU
DEBUG 01-05 09:59:15.689463.689463 lmp.py:376]   Expert  9 |    132 | CPU
DEBUG 01-05 09:59:15.689437.689437 lmp.py:376]   Expert 46 |    133 | CPU
DEBUG 01-05 09:59:15.689934.689934 lmp.py:376]   Expert 11 |    136 | CPU
DEBUG 01-05 09:59:15.689054.689054 lmp.py:376]   Expert  7 |    150 | CPU
DEBUG 01-05 09:59:15.689982.689982 lmp.py:376]   Expert 52 |    151 | CPU
DEBUG 01-05 09:59:15.689102.689102 lmp.py:376]   Expert 29 |    152 | CPU
DEBUG 01-05 09:59:15.689506.689506 lmp.py:376]   Expert 49 |    158 | CPU
DEBUG 01-05 09:59:15.689957.689957 lmp.py:376]   Expert 63 |    161 | CPU
DEBUG 01-05 09:59:15.689646.689646 lmp.py:376]   Expert 20 |    165 | CPU
DEBUG 01-05 09:59:15.689336.689336 lmp.py:376]   Expert  5 |    166 | CPU
DEBUG 01-05 09:59:15.689787.689787 lmp.py:376]   Expert 22 |    167 | CPU
DEBUG 01-05 09:59:15.689476.689476 lmp.py:376]   Expert 61 |    168 | CPU
DEBUG 01-05 09:59:15.689165.689165 lmp.py:376]   Expert 44 |    174 | GPU
DEBUG 01-05 09:59:15.689331.689331 lmp.py:376]   Expert  3 |    175 | GPU
DEBUG 01-05 09:59:15.689021.689021 lmp.py:376]   Expert 53 |    175 | GPU
DEBUG 01-05 09:59:15.689948.689948 lmp.py:376]   Expert 62 |    189 | GPU
DEBUG 01-05 09:59:15.689638.689638 lmp.py:376]   Expert 18 |    196 | GPU
DEBUG 01-05 09:59:15.689327.689327 lmp.py:376]   Expert 17 |    203 | GPU
DEBUG 01-05 09:59:15.689778.689778 lmp.py:376]   Expert  0 |    205 | GPU
DEBUG 01-05 09:59:15.689706.689706 lmp.py:376]   Expert 37 |    209 | GPU
DEBUG 01-05 09:59:15.689395.689395 lmp.py:376]   Expert 47 |    213 | GPU
DEBUG 01-05 09:59:15.689084.689084 lmp.py:376]   Expert  2 |    214 | GPU
DEBUG 01-05 09:59:15.689966.689966 lmp.py:376]   Expert 23 |    231 | GPU
DEBUG 01-05 09:59:15.689847.689847 lmp.py:376]   Expert 26 |    231 | GPU
DEBUG 01-05 09:59:15.689536.689536 lmp.py:376]   Expert 55 |    235 | GPU
DEBUG 01-05 09:59:15.689226.689226 lmp.py:376]   Expert 32 |    238 | GPU
DEBUG 01-05 09:59:15.689915.689915 lmp.py:376]   Expert 45 |    238 | GPU
DEBUG 01-05 09:59:15.689127.689127 lmp.py:376]   Expert 60 |    238 | GPU
DEBUG 01-05 09:59:15.689817.689817 lmp.py:376]   Expert 16 |    251 | GPU
DEBUG 01-05 09:59:15.689506.689506 lmp.py:376]   Expert 34 |    272 | GPU
DEBUG 01-05 09:59:15.689195.689195 lmp.py:376]   Expert 15 |    274 | GPU
DEBUG 01-05 09:59:15.689646.689646 lmp.py:376]   Expert 21 |    281 | GPU
DEBUG 01-05 09:59:15.689574.689574 lmp.py:376]   Expert 58 |    281 | GPU
DEBUG 01-05 09:59:15.689263.689263 lmp.py:376]   Expert 24 |    289 | GPU
DEBUG 01-05 09:59:15.689906.689906 lmp.py:376]   Expert 31 |    296 | GPU
DEBUG 01-05 09:59:15.689311.689311 lmp.py:376]   Expert  4 |    303 | GPU
DEBUG 01-05 09:59:15.689238.689238 lmp.py:376]   Expert 27 |    305 | GPU
DEBUG 01-05 09:59:15.689166.689166 lmp.py:376]   Expert 59 |    309 | GPU
DEBUG 01-05 09:59:15.689094.689094 lmp.py:376]   Expert 56 |    314 | GPU
DEBUG 01-05 09:59:15.689783.689783 lmp.py:376]   Expert 40 |    325 | GPU
DEBUG 01-05 09:59:15.689472.689472 lmp.py:376]   Expert 41 |    331 | GPU
DEBUG 01-05 09:59:15.689162.689162 lmp.py:376]   Expert 48 |    341 | GPU
DEBUG 01-05 09:59:15.689851.689851 lmp.py:376]   Expert 25 |    457 | GPU
DEBUG 01-05 09:59:15.690779.690779 lmp.py:376]   Expert 35 |    532 | GPU
DEBUG 01-05 09:59:15.690375.690375 lmp.py:377] 
DEBUG 01-05 09:59:15.690375.690375 lmp.py:377]   CPU total tokens: 3763 (30.6%)
DEBUG 01-05 09:59:15.690257.690257 lmp.py:378]   GPU total tokens: 8525 (69.4%)
DEBUG 01-05 09:59:15.690191.690191 cuda_h.py:19] end experts_map_get cost 0.0014963150024414062 seconds
DEBUG 01-05 09:59:15.690073.690073 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.690756.690756 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.690509.690509 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.691236.691236 cuda_h.py:19] end allocate_cuda_memory cost 0.0013108253479003906 seconds
DEBUG 01-05 09:59:15.691603.691603 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.691359.691359 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.691406.691406 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.691010.691010 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b6d6504-338c-4c5b-be32-988cb67a879d
DEBUG 01-05 09:59:15.691705.691705 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.693722.693722 client.py:127] Model loaded
DEBUG 01-05 09:59:15.693387.693387 cuda_h.py:19] end sllm_worker_task cost 0.010104179382324219 seconds
INFO 01-05 09:59:15.694355.694355 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b6d6504-338c-4c5b-be32-988cb67a879d
DEBUG 01-05 09:59:15.694205.694205 cuda_h.py:19] end load_into_gpu_async cost 0.003113985061645508 seconds
DEBUG 01-05 09:59:15.694908.694908 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.695151.695151 cuda_h.py:19] end restore_tensors2 cost 0.0003304481506347656 seconds
DEBUG 01-05 09:59:15.695358.695358 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005091428756713867 seconds
DEBUG 01-05 09:59:15.697445.697445 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007726907730102539 seconds
DEBUG 01-05 09:59:15.697890.697890 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.697205.697205 lmp.py:423] 
DEBUG 01-05 09:59:15.697205.697205 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.698855.698855 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-05 09:59:15.698982.698982 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.709578.709578 mlpmodule.py:704] group tensors cost 0.011223316192626953 s
DEBUG 01-05 09:59:15.711294.711294 mlpmodule.py:742] pad cost 0.00176239013671875 s
DEBUG 01-05 09:59:15.712774.712774 mlpmodule.py:748] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-05 09:59:15.712730.712730 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-05 09:59:15.721647.721647 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.721687.721687 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.721491.721491 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 09:59:15.721357.721357 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.738591.738591 mlpmodule.py:793] group einsum cost 0.0260007381439209 s
DEBUG 01-05 09:59:15.739967.739967 mlpmodule.py:801] cpy2cputensor cost 0.0006968975067138672 s
DEBUG 01-05 09:59:15.744720.744720 cuda_h.py:19] end wait_cetm_experts cost 0.04606175422668457 seconds
DEBUG 01-05 09:59:15.744182.744182 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.745899.745899 cuda_h.py:19] end gpu_sexperts cost 0.0005719661712646484 seconds
DEBUG 01-05 09:59:15.745119.745119 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.745876.745876 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-05 09:59:15.745341.745341 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.745527.745527 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b6d6504-338c-4c5b-be32-988cb67a879d
INFO 01-05 09:59:15.749470.749470 client.py:127] Model loaded
DEBUG 01-05 09:59:15.749174.749174 cuda_h.py:19] end wait_experts cost 0.004481315612792969 seconds
DEBUG 01-05 09:59:15.749546.749546 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.749871.749871 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.750180.750180 mlpmodule.py:531] gpu group tensors cost 0.0006308555603027344 s
DEBUG 01-05 09:59:15.752678.752678 mlpmodule.py:564] gpu pad cost 0.0017538070678710938 s
DEBUG 01-05 09:59:15.752401.752401 mlpmodule.py:582] gpu group einsum cost 0.0005595684051513672 s
DEBUG 01-05 09:59:15.756202.756202 mlpmodule.py:611] gpu experts func einsum cost 0.006228923797607422 s
DEBUG 01-05 09:59:15.756192.756192 cuda_h.py:19] end gpu_experts cost 0.006418466567993164 seconds
DEBUG 01-05 09:59:15.756155.756155 cuda_h.py:19] end layer_moe_generate_20 cost 0.06839609146118164 seconds
DEBUG 01-05 09:59:15.756923.756923 lmp.py:217] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 09:59:15.756163.756163 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 09:59:15.756144.756144 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:59:15.756423.756423 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:59:15.756790.756790 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:15.756016.756016 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.437301635742188e-05 seconds
DEBUG 01-05 09:59:15.756089.756089 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.756548.756548 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.756314.756314 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.756581.756581 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.757872.757872 cuda_h.py:19] end allocate_cuda_memory cost 0.0005280971527099609 seconds
DEBUG 01-05 09:59:15.757775.757775 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.757676.757676 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.757307.757307 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.757248.757248 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b26ebc9c-976a-40fc-858c-ef7013bf043e
DEBUG 01-05 09:59:15.757026.757026 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.757541.757541 mlpmodule.py:662]  experts func einsum cost 0.05961108207702637 s
DEBUG 01-05 09:59:15.758050.758050 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.759002.759002 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b26ebc9c-976a-40fc-858c-ef7013bf043e
DEBUG 01-05 09:59:15.759819.759819 cuda_h.py:19] end load_into_gpu_async cost 0.0016827583312988281 seconds
DEBUG 01-05 09:59:15.759522.759522 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.759287.759287 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-05 09:59:15.759242.759242 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025408267974853516 seconds
INFO 01-05 09:59:15.759299.759299 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b26ebc9c-976a-40fc-858c-ef7013bf043e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.762255.762255 cuda_h.py:19] end self_attn cost 0.0040585994720458984 seconds
DEBUG 01-05 09:59:15.762066.762066 cuda_h.py:19] end iln_self_attn_paln cost 0.0059926509857177734 seconds
DEBUG 01-05 09:59:15.762902.762902 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 09:59:15.762426.762426 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.763084.763084 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-05 09:59:15.763622.763622 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.763440.763440 lmp.py:365] 
DEBUG 01-05 09:59:15.763440.763440 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.763142.763142 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.763646.763646 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.763766.763766 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.763740.763740 lmp.py:369] 
DEBUG 01-05 09:59:15.763740.763740 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.763714.763714 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.763649.763649 lmp.py:376]   Expert  9 |     36 | CPU
DEBUG 01-05 09:59:15.763338.763338 lmp.py:376]   Expert 44 |     54 | CPU
DEBUG 01-05 09:59:15.763074.763074 lmp.py:376]   Expert 60 |     55 | CPU
DEBUG 01-05 09:59:15.763286.763286 lmp.py:376]   Expert 20 |     63 | CPU
DEBUG 01-05 09:59:15.763260.763260 lmp.py:376]   Expert 26 |     70 | CPU
DEBUG 01-05 09:59:15.763996.763996 lmp.py:376]   Expert 56 |     72 | CPU
DEBUG 01-05 09:59:15.763970.763970 lmp.py:376]   Expert  1 |     79 | CPU
DEBUG 01-05 09:59:15.763467.763467 lmp.py:376]   Expert 19 |     79 | CPU
DEBUG 01-05 09:59:15.763964.763964 lmp.py:376]   Expert 32 |     81 | CPU
DEBUG 01-05 09:59:15.763462.763462 lmp.py:376]   Expert 54 |     85 | CPU
DEBUG 01-05 09:59:15.764959.764959 lmp.py:376]   Expert 57 |    101 | CPU
DEBUG 01-05 09:59:15.764218.764218 lmp.py:376]   Expert 51 |    102 | CPU
DEBUG 01-05 09:59:15.764476.764476 lmp.py:376]   Expert  8 |    109 | CPU
DEBUG 01-05 09:59:15.764212.764212 lmp.py:376]   Expert 12 |    117 | CPU
DEBUG 01-05 09:59:15.764471.764471 lmp.py:376]   Expert 25 |    118 | CPU
DEBUG 01-05 09:59:15.764730.764730 lmp.py:376]   Expert  3 |    119 | CPU
DEBUG 01-05 09:59:15.764988.764988 lmp.py:376]   Expert 48 |    122 | CPU
DEBUG 01-05 09:59:15.764486.764486 lmp.py:376]   Expert 14 |    128 | CPU
DEBUG 01-05 09:59:15.764744.764744 lmp.py:376]   Expert  6 |    129 | CPU
DEBUG 01-05 09:59:15.764003.764003 lmp.py:376]   Expert 33 |    130 | CPU
DEBUG 01-05 09:59:15.764739.764739 lmp.py:376]   Expert 52 |    134 | CPU
DEBUG 01-05 09:59:15.764759.764759 lmp.py:376]   Expert 15 |    137 | CPU
DEBUG 01-05 09:59:15.764256.764256 lmp.py:376]   Expert 23 |    140 | CPU
DEBUG 01-05 09:59:15.764515.764515 lmp.py:376]   Expert 49 |    140 | CPU
DEBUG 01-05 09:59:15.764774.764774 lmp.py:376]   Expert 13 |    144 | CPU
DEBUG 01-05 09:59:15.764086.764086 lmp.py:376]   Expert  7 |    146 | CPU
DEBUG 01-05 09:59:15.764060.764060 lmp.py:376]   Expert 34 |    151 | CPU
DEBUG 01-05 09:59:15.764319.764319 lmp.py:376]   Expert 40 |    151 | CPU
DEBUG 01-05 09:59:15.764578.764578 lmp.py:376]   Expert 53 |    152 | CPU
DEBUG 01-05 09:59:15.764836.764836 lmp.py:376]   Expert 35 |    158 | CPU
DEBUG 01-05 09:59:15.764095.764095 lmp.py:376]   Expert 50 |    159 | CPU
DEBUG 01-05 09:59:15.764831.764831 lmp.py:376]   Expert 59 |    164 | CPU
DEBUG 01-05 09:59:15.764089.764089 lmp.py:376]   Expert 61 |    169 | GPU
DEBUG 01-05 09:59:15.764971.764971 lmp.py:376]   Expert 39 |    182 | GPU
DEBUG 01-05 09:59:15.764336.764336 lmp.py:376]   Expert 58 |    182 | GPU
DEBUG 01-05 09:59:15.764025.764025 lmp.py:376]   Expert 24 |    183 | GPU
DEBUG 01-05 09:59:15.764953.764953 lmp.py:376]   Expert 28 |    192 | GPU
DEBUG 01-05 09:59:15.764404.764404 lmp.py:376]   Expert 27 |    200 | GPU
DEBUG 01-05 09:59:15.764855.764855 lmp.py:376]   Expert 41 |    202 | GPU
DEBUG 01-05 09:59:15.764067.764067 lmp.py:376]   Expert  2 |    205 | GPU
DEBUG 01-05 09:59:15.764756.764756 lmp.py:376]   Expert 38 |    217 | GPU
DEBUG 01-05 09:59:15.764207.764207 lmp.py:376]   Expert 37 |    221 | GPU
DEBUG 01-05 09:59:15.764658.764658 lmp.py:376]   Expert 18 |    223 | GPU
DEBUG 01-05 09:59:15.764109.764109 lmp.py:376]   Expert 43 |    230 | GPU
DEBUG 01-05 09:59:15.764560.764560 lmp.py:376]   Expert 11 |    237 | GPU
DEBUG 01-05 09:59:15.764296.764296 lmp.py:376]   Expert 62 |    247 | GPU
DEBUG 01-05 09:59:15.764985.764985 lmp.py:376]   Expert  4 |    249 | GPU
DEBUG 01-05 09:59:15.764674.764674 lmp.py:376]   Expert 17 |    259 | GPU
DEBUG 01-05 09:59:15.764887.764887 lmp.py:376]   Expert 10 |    263 | GPU
DEBUG 01-05 09:59:15.764338.764338 lmp.py:376]   Expert 47 |    268 | GPU
DEBUG 01-05 09:59:15.764027.764027 lmp.py:376]   Expert 29 |    269 | GPU
DEBUG 01-05 09:59:15.764239.764239 lmp.py:376]   Expert 22 |    270 | GPU
DEBUG 01-05 09:59:15.764452.764452 lmp.py:376]   Expert 63 |    275 | GPU
DEBUG 01-05 09:59:15.764903.764903 lmp.py:376]   Expert  5 |    278 | GPU
DEBUG 01-05 09:59:15.764115.764115 lmp.py:376]   Expert 30 |    284 | GPU
DEBUG 01-05 09:59:15.764328.764328 lmp.py:376]   Expert 31 |    284 | GPU
DEBUG 01-05 09:59:15.764540.764540 lmp.py:376]   Expert 21 |    294 | GPU
DEBUG 01-05 09:59:15.764991.764991 lmp.py:376]   Expert 55 |    294 | GPU
DEBUG 01-05 09:59:15.764203.764203 lmp.py:376]   Expert 16 |    335 | GPU
DEBUG 01-05 09:59:15.764654.764654 lmp.py:376]   Expert 46 |    362 | GPU
DEBUG 01-05 09:59:15.764867.764867 lmp.py:376]   Expert 36 |    383 | GPU
DEBUG 01-05 09:59:15.764318.764318 lmp.py:376]   Expert 45 |    419 | GPU
DEBUG 01-05 09:59:15.764530.764530 lmp.py:376]   Expert  0 |    430 | GPU
DEBUG 01-05 09:59:15.764743.764743 lmp.py:376]   Expert 42 |    557 | GPU
DEBUG 01-05 09:59:15.764147.764147 lmp.py:377] 
DEBUG 01-05 09:59:15.764147.764147 lmp.py:377]   CPU total tokens: 3625 (29.5%)
DEBUG 01-05 09:59:15.764313.764313 lmp.py:378]   GPU total tokens: 8663 (70.5%)
DEBUG 01-05 09:59:15.764771.764771 cuda_h.py:19] end experts_map_get cost 0.0014524459838867188 seconds
DEBUG 01-05 09:59:15.764414.764414 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.764906.764906 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.765652.765652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.765319.765319 cuda_h.py:19] end allocate_cuda_memory cost 0.0005314350128173828 seconds
DEBUG 01-05 09:59:15.765209.765209 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.765534.765534 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.765343.765343 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.765185.765185 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7693861-7335-43f9-9b20-4d691988d82d
DEBUG 01-05 09:59:15.766682.766682 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.766480.766480 client.py:127] Model loaded
DEBUG 01-05 09:59:15.766052.766052 cuda_h.py:19] end sllm_worker_task cost 0.009575843811035156 seconds
INFO 01-05 09:59:15.767611.767611 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7693861-7335-43f9-9b20-4d691988d82d
DEBUG 01-05 09:59:15.767646.767646 cuda_h.py:19] end load_into_gpu_async cost 0.0021512508392333984 seconds
DEBUG 01-05 09:59:15.767395.767395 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.768109.768109 cuda_h.py:19] end restore_tensors2 cost 0.00032591819763183594 seconds
DEBUG 01-05 09:59:15.768024.768024 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003331422805786133 seconds
DEBUG 01-05 09:59:15.770754.770754 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005983114242553711 seconds
DEBUG 01-05 09:59:15.771676.771676 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.771394.771394 lmp.py:423] 
DEBUG 01-05 09:59:15.771394.771394 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.771191.771191 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-05 09:59:15.771364.771364 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.781689.781689 mlpmodule.py:704] group tensors cost 0.009893655776977539 s
DEBUG 01-05 09:59:15.783985.783985 mlpmodule.py:742] pad cost 0.0017004013061523438 s
DEBUG 01-05 09:59:15.783889.783889 mlpmodule.py:748] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-05 09:59:15.783700.783700 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-05 09:59:15.793820.793820 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.793191.793191 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.793380.793380 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 09:59:15.793617.793617 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.810778.810778 mlpmodule.py:793] group einsum cost 0.02637338638305664 s
DEBUG 01-05 09:59:15.811008.811008 mlpmodule.py:801] cpy2cputensor cost 0.0006940364837646484 s
DEBUG 01-05 09:59:15.816475.816475 cuda_h.py:19] end wait_cetm_experts cost 0.04498624801635742 seconds
DEBUG 01-05 09:59:15.816779.816779 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.817112.817112 cuda_h.py:19] end gpu_sexperts cost 0.0005862712860107422 seconds
DEBUG 01-05 09:59:15.817246.817246 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.817342.817342 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:15.817190.817190 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.817615.817615 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7693861-7335-43f9-9b20-4d691988d82d
INFO 01-05 09:59:15.823895.823895 client.py:127] Model loaded
DEBUG 01-05 09:59:15.823699.823699 cuda_h.py:19] end wait_experts cost 0.0058557987213134766 seconds
DEBUG 01-05 09:59:15.823501.823501 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.823303.823303 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.823096.823096 mlpmodule.py:531] gpu group tensors cost 0.0006401538848876953 s
DEBUG 01-05 09:59:15.825382.825382 mlpmodule.py:564] gpu pad cost 0.0017681121826171875 s
DEBUG 01-05 09:59:15.826091.826091 mlpmodule.py:582] gpu group einsum cost 0.0005140304565429688 s
DEBUG 01-05 09:59:15.829483.829483 mlpmodule.py:611] gpu experts func einsum cost 0.006087541580200195 s
DEBUG 01-05 09:59:15.829820.829820 mlpmodule.py:662]  experts func einsum cost 0.058142662048339844 s
DEBUG 01-05 09:59:15.829336.829336 cuda_h.py:19] end gpu_experts cost 0.006509304046630859 seconds
DEBUG 01-05 09:59:15.829357.829357 cuda_h.py:19] end layer_moe_generate_21 cost 0.06715250015258789 seconds
DEBUG 01-05 09:59:15.830654.830654 lmp.py:217] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 09:59:15.830570.830570 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 09:59:15.830789.830789 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:59:15.830068.830068 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:59:15.830812.830812 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.956390380859375e-05 seconds
DEBUG 01-05 09:59:15.830038.830038 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.079673767089844e-05 seconds
DEBUG 01-05 09:59:15.830549.830549 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.830293.830293 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.830668.830668 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.830742.830742 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.830478.830478 cuda_h.py:19] end allocate_cuda_memory cost 0.0003657341003417969 seconds
DEBUG 01-05 09:59:15.831070.831070 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.831217.831217 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.831046.831046 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.831511.831511 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 102c01cc-3e4b-4e3f-8f1e-aa6f530e4702
DEBUG 01-05 09:59:15.831434.831434 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.831335.831335 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.832435.832435 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 102c01cc-3e4b-4e3f-8f1e-aa6f530e4702
DEBUG 01-05 09:59:15.832940.832940 cuda_h.py:19] end load_into_gpu_async cost 0.0016217231750488281 seconds
DEBUG 01-05 09:59:15.832782.832782 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.832480.832480 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-05 09:59:15.832521.832521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023152828216552734 seconds
INFO 01-05 09:59:15.833439.833439 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 102c01cc-3e4b-4e3f-8f1e-aa6f530e4702
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.835769.835769 cuda_h.py:19] end self_attn cost 0.0035948753356933594 seconds
DEBUG 01-05 09:59:15.835885.835885 cuda_h.py:19] end iln_self_attn_paln cost 0.0050656795501708984 seconds
DEBUG 01-05 09:59:15.835344.835344 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 09:59:15.835345.835345 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.836202.836202 cuda_h.py:19] end gate cost 0.0006341934204101562 seconds
DEBUG 01-05 09:59:15.836408.836408 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.836282.836282 lmp.py:365] 
DEBUG 01-05 09:59:15.836282.836282 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.836806.836806 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.836694.836694 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.836483.836483 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.836649.836649 lmp.py:369] 
DEBUG 01-05 09:59:15.836649.836649 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.836484.836484 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.836041.836041 lmp.py:376]   Expert 11 |     58 | CPU
DEBUG 01-05 09:59:15.836876.836876 lmp.py:376]   Expert 49 |     62 | CPU
DEBUG 01-05 09:59:15.836758.836758 lmp.py:376]   Expert 32 |     66 | CPU
DEBUG 01-05 09:59:15.836401.836401 lmp.py:376]   Expert  1 |     75 | CPU
DEBUG 01-05 09:59:15.836044.836044 lmp.py:376]   Expert  6 |     79 | CPU
DEBUG 01-05 09:59:15.836448.836448 lmp.py:376]   Expert  7 |     81 | CPU
DEBUG 01-05 09:59:15.836614.836614 lmp.py:376]   Expert 45 |     85 | CPU
DEBUG 01-05 09:59:15.836780.836780 lmp.py:376]   Expert 54 |     87 | CPU
DEBUG 01-05 09:59:15.836947.836947 lmp.py:376]   Expert 12 |     88 | CPU
DEBUG 01-05 09:59:15.836543.836543 lmp.py:376]   Expert 22 |     89 | CPU
DEBUG 01-05 09:59:15.836425.836425 lmp.py:376]   Expert 41 |     89 | CPU
DEBUG 01-05 09:59:15.836591.836591 lmp.py:376]   Expert 44 |     94 | CPU
DEBUG 01-05 09:59:15.836995.836995 lmp.py:376]   Expert 46 |     94 | CPU
DEBUG 01-05 09:59:15.836161.836161 lmp.py:376]   Expert 42 |     99 | CPU
DEBUG 01-05 09:59:15.836566.836566 lmp.py:376]   Expert 63 |    100 | CPU
DEBUG 01-05 09:59:15.836971.836971 lmp.py:376]   Expert 52 |    101 | CPU
DEBUG 01-05 09:59:15.836375.836375 lmp.py:376]   Expert 60 |    109 | CPU
DEBUG 01-05 09:59:15.836303.836303 lmp.py:376]   Expert 61 |    109 | CPU
DEBUG 01-05 09:59:15.837184.837184 lmp.py:376]   Expert 15 |    110 | CPU
DEBUG 01-05 09:59:15.837542.837542 lmp.py:376]   Expert 24 |    112 | CPU
DEBUG 01-05 09:59:15.837709.837709 lmp.py:376]   Expert 10 |    113 | CPU
DEBUG 01-05 09:59:15.837159.837159 lmp.py:376]   Expert 37 |    113 | CPU
DEBUG 01-05 09:59:15.837326.837326 lmp.py:376]   Expert 28 |    126 | CPU
DEBUG 01-05 09:59:15.837253.837253 lmp.py:376]   Expert 57 |    126 | CPU
DEBUG 01-05 09:59:15.837181.837181 lmp.py:376]   Expert  9 |    127 | CPU
DEBUG 01-05 09:59:15.837586.837586 lmp.py:376]   Expert 62 |    127 | CPU
DEBUG 01-05 09:59:15.837513.837513 lmp.py:376]   Expert 13 |    128 | CPU
DEBUG 01-05 09:59:15.837679.837679 lmp.py:376]   Expert  3 |    132 | CPU
DEBUG 01-05 09:59:15.837084.837084 lmp.py:376]   Expert 21 |    132 | CPU
DEBUG 01-05 09:59:15.837204.837204 lmp.py:376]   Expert 31 |    132 | CPU
DEBUG 01-05 09:59:15.837370.837370 lmp.py:376]   Expert 48 |    141 | CPU
DEBUG 01-05 09:59:15.837298.837298 lmp.py:376]   Expert 30 |    142 | CPU
DEBUG 01-05 09:59:15.837464.837464 lmp.py:376]   Expert 27 |    152 | GPU
DEBUG 01-05 09:59:15.837392.837392 lmp.py:376]   Expert  0 |    157 | GPU
DEBUG 01-05 09:59:15.837558.837558 lmp.py:376]   Expert 47 |    159 | GPU
DEBUG 01-05 09:59:15.837009.837009 lmp.py:376]   Expert 26 |    162 | GPU
DEBUG 01-05 09:59:15.837175.837175 lmp.py:376]   Expert 43 |    174 | GPU
DEBUG 01-05 09:59:15.837341.837341 lmp.py:376]   Expert 51 |    192 | GPU
DEBUG 01-05 09:59:15.837699.837699 lmp.py:376]   Expert 50 |    196 | GPU
DEBUG 01-05 09:59:15.837388.837388 lmp.py:376]   Expert 58 |    197 | GPU
DEBUG 01-05 09:59:15.837078.837078 lmp.py:376]   Expert  8 |    216 | GPU
DEBUG 01-05 09:59:15.837005.837005 lmp.py:376]   Expert 16 |    219 | GPU
DEBUG 01-05 09:59:15.837172.837172 lmp.py:376]   Expert 39 |    219 | GPU
DEBUG 01-05 09:59:15.837099.837099 lmp.py:376]   Expert 38 |    221 | GPU
DEBUG 01-05 09:59:15.837027.837027 lmp.py:376]   Expert  2 |    229 | GPU
DEBUG 01-05 09:59:15.837955.837955 lmp.py:376]   Expert 19 |    231 | GPU
DEBUG 01-05 09:59:15.837882.837882 lmp.py:376]   Expert 33 |    246 | GPU
DEBUG 01-05 09:59:15.837572.837572 lmp.py:376]   Expert  4 |    256 | GPU
DEBUG 01-05 09:59:15.837738.837738 lmp.py:376]   Expert 34 |    259 | GPU
DEBUG 01-05 09:59:15.837858.837858 lmp.py:376]   Expert 56 |    264 | GPU
DEBUG 01-05 09:59:15.837547.837547 lmp.py:376]   Expert 35 |    272 | GPU
DEBUG 01-05 09:59:15.837236.837236 lmp.py:376]   Expert 17 |    280 | GPU
DEBUG 01-05 09:59:15.837164.837164 lmp.py:376]   Expert 23 |    286 | GPU
DEBUG 01-05 09:59:15.837853.837853 lmp.py:376]   Expert 20 |    302 | GPU
DEBUG 01-05 09:59:15.837543.837543 lmp.py:376]   Expert 53 |    316 | GPU
DEBUG 01-05 09:59:15.837755.837755 lmp.py:376]   Expert 59 |    339 | GPU
DEBUG 01-05 09:59:15.837398.837398 lmp.py:376]   Expert 25 |    344 | GPU
DEBUG 01-05 09:59:15.837564.837564 lmp.py:376]   Expert 29 |    348 | GPU
DEBUG 01-05 09:59:15.837253.837253 lmp.py:376]   Expert 18 |    350 | GPU
DEBUG 01-05 09:59:15.837466.837466 lmp.py:376]   Expert 55 |    360 | GPU
DEBUG 01-05 09:59:15.837917.837917 lmp.py:376]   Expert 40 |    371 | GPU
DEBUG 01-05 09:59:15.837368.837368 lmp.py:376]   Expert 14 |    457 | GPU
DEBUG 01-05 09:59:15.837819.837819 lmp.py:376]   Expert 36 |    571 | GPU
DEBUG 01-05 09:59:15.837508.837508 lmp.py:376]   Expert  5 |    617 | GPU
DEBUG 01-05 09:59:15.837151.837151 lmp.py:377] 
DEBUG 01-05 09:59:15.837151.837151 lmp.py:377]   CPU total tokens: 3326 (27.1%)
DEBUG 01-05 09:59:15.837794.837794 lmp.py:378]   GPU total tokens: 8962 (72.9%)
DEBUG 01-05 09:59:15.837159.837159 cuda_h.py:19] end experts_map_get cost 0.0016133785247802734 seconds
DEBUG 01-05 09:59:15.837755.837755 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.837201.837201 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.838437.838437 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.839390.839390 cuda_h.py:19] end allocate_cuda_memory cost 0.0011246204376220703 seconds
DEBUG 01-05 09:59:15.839392.839392 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.839009.839009 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.839342.839342 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.839276.839276 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a15d09ce-f0bb-43d8-8c0c-c5fa24a7db8d
DEBUG 01-05 09:59:15.839773.839773 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.839364.839364 client.py:127] Model loaded
DEBUG 01-05 09:59:15.839015.839015 cuda_h.py:19] end sllm_worker_task cost 0.009392261505126953 seconds
INFO 01-05 09:59:15.841975.841975 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a15d09ce-f0bb-43d8-8c0c-c5fa24a7db8d
DEBUG 01-05 09:59:15.841918.841918 cuda_h.py:19] end load_into_gpu_async cost 0.002213001251220703 seconds
DEBUG 01-05 09:59:15.841621.841621 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.841328.841328 cuda_h.py:19] end restore_tensors2 cost 0.0003204345703125 seconds
DEBUG 01-05 09:59:15.841296.841296 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004015684127807617 seconds
DEBUG 01-05 09:59:15.844476.844476 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006648540496826172 seconds
DEBUG 01-05 09:59:15.844305.844305 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.844553.844553 lmp.py:423] 
DEBUG 01-05 09:59:15.844553.844553 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.844734.844734 cuda_h.py:19] end cpu_experts_submit cost 0.00011229515075683594 seconds
DEBUG 01-05 09:59:15.844390.844390 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.855828.855828 mlpmodule.py:704] group tensors cost 0.010893106460571289 s
DEBUG 01-05 09:59:15.858186.858186 mlpmodule.py:742] pad cost 0.0021810531616210938 s
DEBUG 01-05 09:59:15.858018.858018 mlpmodule.py:748] create cpu tensor cost 6.580352783203125e-05 s
DEBUG 01-05 09:59:15.859027.859027 mlpmodule.py:753] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-05 09:59:15.868260.868260 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.868506.868506 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.868602.868602 mlpmodule.py:773] group_w3 first element: 0.025390625
WARNING 01-05 09:59:15.868931.868931 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.886797.886797 mlpmodule.py:793] group einsum cost 0.02705860137939453 s
DEBUG 01-05 09:59:15.887282.887282 mlpmodule.py:801] cpy2cputensor cost 0.0006103515625 s
DEBUG 01-05 09:59:15.892166.892166 cuda_h.py:19] end wait_cetm_experts cost 0.04740476608276367 seconds
DEBUG 01-05 09:59:15.892000.892000 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.893657.893657 cuda_h.py:19] end gpu_sexperts cost 0.0005767345428466797 seconds
DEBUG 01-05 09:59:15.893222.893222 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.893933.893933 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-05 09:59:15.893212.893212 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.893829.893829 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a15d09ce-f0bb-43d8-8c0c-c5fa24a7db8d
INFO 01-05 09:59:15.895363.895363 client.py:127] Model loaded
DEBUG 01-05 09:59:15.895113.895113 cuda_h.py:19] end wait_experts cost 0.002565145492553711 seconds
DEBUG 01-05 09:59:15.895723.895723 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.895764.895764 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.896723.896723 mlpmodule.py:531] gpu group tensors cost 0.0006587505340576172 s
DEBUG 01-05 09:59:15.898592.898592 mlpmodule.py:564] gpu pad cost 0.0017757415771484375 s
DEBUG 01-05 09:59:15.898238.898238 mlpmodule.py:582] gpu group einsum cost 0.0004360675811767578 s
DEBUG 01-05 09:59:15.902919.902919 mlpmodule.py:611] gpu experts func einsum cost 0.006314277648925781 s
DEBUG 01-05 09:59:15.902200.902200 cuda_h.py:19] end gpu_experts cost 0.00650334358215332 seconds
DEBUG 01-05 09:59:15.902077.902077 cuda_h.py:19] end layer_moe_generate_22 cost 0.06697773933410645 seconds
DEBUG 01-05 09:59:15.902977.902977 lmp.py:217] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 09:59:15.902508.902508 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 09:59:15.902489.902489 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:59:15.902815.902815 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:59:15.902274.902274 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:15.902256.902256 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 9.250640869140625e-05 seconds
DEBUG 01-05 09:59:15.902283.902283 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.902789.902789 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.903263.903263 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.903530.903530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.905265.905265 cuda_h.py:19] end allocate_cuda_memory cost 0.0021562576293945312 seconds
DEBUG 01-05 09:59:15.905368.905368 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.905754.905754 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.905292.905292 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.905756.905756 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 72f558cf-d1ba-436d-89a8-37b6c5ca12fe
DEBUG 01-05 09:59:15.905587.905587 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.905992.905992 mlpmodule.py:662]  experts func einsum cost 0.06090235710144043 s
DEBUG 01-05 09:59:15.906231.906231 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.906581.906581 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 72f558cf-d1ba-436d-89a8-37b6c5ca12fe
DEBUG 01-05 09:59:15.907377.907377 cuda_h.py:19] end load_into_gpu_async cost 0.001617431640625 seconds
DEBUG 01-05 09:59:15.907173.907173 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.907256.907256 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-05 09:59:15.907581.907581 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004131793975830078 seconds
INFO 01-05 09:59:15.907816.907816 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 72f558cf-d1ba-436d-89a8-37b6c5ca12fe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.909820.909820 cuda_h.py:19] end self_attn cost 0.0032501220703125 seconds
DEBUG 01-05 09:59:15.909491.909491 cuda_h.py:19] end iln_self_attn_paln cost 0.006797313690185547 seconds
DEBUG 01-05 09:59:15.909142.909142 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 09:59:15.909574.909574 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.910007.910007 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-05 09:59:15.910645.910645 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.910992.910992 lmp.py:365] 
DEBUG 01-05 09:59:15.910992.910992 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.910794.910794 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.910490.910490 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.910326.910326 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.910776.910776 lmp.py:369] 
DEBUG 01-05 09:59:15.910776.910776 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.910466.910466 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.910639.910639 lmp.py:376]   Expert  5 |     58 | CPU
DEBUG 01-05 09:59:15.910566.910566 lmp.py:376]   Expert 49 |     67 | CPU
DEBUG 01-05 09:59:15.910540.910540 lmp.py:376]   Expert 27 |     69 | CPU
DEBUG 01-05 09:59:15.910276.910276 lmp.py:376]   Expert 19 |     82 | CPU
DEBUG 01-05 09:59:15.910250.910250 lmp.py:376]   Expert 44 |     83 | CPU
DEBUG 01-05 09:59:15.910416.910416 lmp.py:376]   Expert  7 |     91 | CPU
DEBUG 01-05 09:59:15.910106.910106 lmp.py:376]   Expert 17 |     93 | CPU
DEBUG 01-05 09:59:15.911080.911080 lmp.py:376]   Expert 55 |    102 | CPU
DEBUG 01-05 09:59:15.911723.911723 lmp.py:376]   Expert 53 |    108 | CPU
DEBUG 01-05 09:59:15.911127.911127 lmp.py:376]   Expert 40 |    119 | CPU
DEBUG 01-05 09:59:15.911816.911816 lmp.py:376]   Expert 58 |    119 | CPU
DEBUG 01-05 09:59:15.911506.911506 lmp.py:376]   Expert 52 |    120 | CPU
DEBUG 01-05 09:59:15.911195.911195 lmp.py:376]   Expert 25 |    121 | CPU
DEBUG 01-05 09:59:15.911407.911407 lmp.py:376]   Expert  4 |    123 | CPU
DEBUG 01-05 09:59:15.911335.911335 lmp.py:376]   Expert 34 |    123 | CPU
DEBUG 01-05 09:59:15.911978.911978 lmp.py:376]   Expert 35 |    123 | CPU
DEBUG 01-05 09:59:15.911667.911667 lmp.py:376]   Expert 22 |    124 | CPU
DEBUG 01-05 09:59:15.911118.911118 lmp.py:376]   Expert 43 |    124 | CPU
DEBUG 01-05 09:59:15.911808.911808 lmp.py:376]   Expert 38 |    131 | CPU
DEBUG 01-05 09:59:15.911782.911782 lmp.py:376]   Expert  1 |    139 | CPU
DEBUG 01-05 09:59:15.911233.911233 lmp.py:376]   Expert  6 |    139 | CPU
DEBUG 01-05 09:59:15.911922.911922 lmp.py:376]   Expert 16 |    139 | CPU
DEBUG 01-05 09:59:15.911134.911134 lmp.py:376]   Expert 63 |    155 | CPU
DEBUG 01-05 09:59:15.911585.911585 lmp.py:376]   Expert 42 |    156 | CPU
DEBUG 01-05 09:59:15.911274.911274 lmp.py:376]   Expert 51 |    156 | CPU
DEBUG 01-05 09:59:15.911202.911202 lmp.py:376]   Expert 47 |    161 | CPU
DEBUG 01-05 09:59:15.911130.911130 lmp.py:376]   Expert  9 |    164 | CPU
DEBUG 01-05 09:59:15.911581.911581 lmp.py:376]   Expert 13 |    177 | CPU
DEBUG 01-05 09:59:15.911793.911793 lmp.py:376]   Expert 46 |    177 | CPU
DEBUG 01-05 09:59:15.911483.911483 lmp.py:376]   Expert 36 |    179 | CPU
DEBUG 01-05 09:59:15.911172.911172 lmp.py:376]   Expert 45 |    180 | CPU
DEBUG 01-05 09:59:15.911861.911861 lmp.py:376]   Expert 26 |    187 | CPU
DEBUG 01-05 09:59:15.911743.911743 lmp.py:376]   Expert 30 |    187 | GPU
DEBUG 01-05 09:59:15.911147.911147 lmp.py:376]   Expert 23 |    189 | GPU
DEBUG 01-05 09:59:15.911313.911313 lmp.py:376]   Expert  0 |    190 | GPU
DEBUG 01-05 09:59:15.911003.911003 lmp.py:376]   Expert 28 |    194 | GPU
DEBUG 01-05 09:59:15.911453.911453 lmp.py:376]   Expert 62 |    194 | GPU
DEBUG 01-05 09:59:15.911381.911381 lmp.py:376]   Expert  2 |    195 | GPU
DEBUG 01-05 09:59:15.911832.911832 lmp.py:376]   Expert 11 |    197 | GPU
DEBUG 01-05 09:59:15.911521.911521 lmp.py:376]   Expert 39 |    211 | GPU
DEBUG 01-05 09:59:15.911734.911734 lmp.py:376]   Expert 60 |    217 | GPU
DEBUG 01-05 09:59:15.911423.911423 lmp.py:376]   Expert 12 |    221 | GPU
DEBUG 01-05 09:59:15.911066.911066 lmp.py:376]   Expert 15 |    222 | GPU
DEBUG 01-05 09:59:15.911994.911994 lmp.py:376]   Expert 24 |    223 | GPU
DEBUG 01-05 09:59:15.911445.911445 lmp.py:376]   Expert  3 |    224 | GPU
DEBUG 01-05 09:59:15.911134.911134 lmp.py:376]   Expert 61 |    224 | GPU
DEBUG 01-05 09:59:15.911346.911346 lmp.py:376]   Expert 41 |    229 | GPU
DEBUG 01-05 09:59:15.911036.911036 lmp.py:376]   Expert 29 |    245 | GPU
DEBUG 01-05 09:59:15.911725.911725 lmp.py:376]   Expert 14 |    260 | GPU
DEBUG 01-05 09:59:15.911414.911414 lmp.py:376]   Expert 10 |    262 | GPU
DEBUG 01-05 09:59:15.911865.911865 lmp.py:376]   Expert 21 |    271 | GPU
DEBUG 01-05 09:59:15.911793.911793 lmp.py:376]   Expert 20 |    276 | GPU
DEBUG 01-05 09:59:15.911959.911959 lmp.py:376]   Expert 33 |    277 | GPU
DEBUG 01-05 09:59:15.911648.911648 lmp.py:376]   Expert 31 |    278 | GPU
DEBUG 01-05 09:59:15.911861.911861 lmp.py:376]   Expert 32 |    287 | GPU
DEBUG 01-05 09:59:15.911312.911312 lmp.py:376]   Expert  8 |    289 | GPU
DEBUG 01-05 09:59:15.911763.911763 lmp.py:376]   Expert 50 |    292 | GPU
DEBUG 01-05 09:59:15.911214.911214 lmp.py:376]   Expert 57 |    293 | GPU
DEBUG 01-05 09:59:15.911141.911141 lmp.py:376]   Expert 37 |    294 | GPU
DEBUG 01-05 09:59:15.911354.911354 lmp.py:376]   Expert 59 |    303 | GPU
DEBUG 01-05 09:59:15.911235.911235 lmp.py:376]   Expert 18 |    304 | GPU
DEBUG 01-05 09:59:15.911984.911984 lmp.py:376]   Expert 56 |    361 | GPU
DEBUG 01-05 09:59:15.911912.911912 lmp.py:376]   Expert 48 |    389 | GPU
DEBUG 01-05 09:59:15.911840.911840 lmp.py:376]   Expert 54 |    401 | GPU
DEBUG 01-05 09:59:15.911006.911006 lmp.py:377] 
DEBUG 01-05 09:59:15.911006.911006 lmp.py:377]   CPU total tokens: 4089 (33.3%)
DEBUG 01-05 09:59:15.911887.911887 lmp.py:378]   GPU total tokens: 8199 (66.7%)
DEBUG 01-05 09:59:15.912583.912583 cuda_h.py:19] end experts_map_get cost 0.0015070438385009766 seconds
DEBUG 01-05 09:59:15.912226.912226 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.912579.912579 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.912716.912716 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.914639.914639 cuda_h.py:19] end allocate_cuda_memory cost 0.002017974853515625 seconds
DEBUG 01-05 09:59:15.914297.914297 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.914861.914861 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.914651.914651 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.914208.914208 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce3634ba-1404-46d5-a678-3275389b33e2
DEBUG 01-05 09:59:15.914625.914625 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.914378.914378 client.py:127] Model loaded
DEBUG 01-05 09:59:15.915473.915473 cuda_h.py:19] end sllm_worker_task cost 0.012028694152832031 seconds
INFO 01-05 09:59:15.916504.916504 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce3634ba-1404-46d5-a678-3275389b33e2
DEBUG 01-05 09:59:15.916685.916685 cuda_h.py:19] end load_into_gpu_async cost 0.002254962921142578 seconds
DEBUG 01-05 09:59:15.916626.916626 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.916955.916955 cuda_h.py:19] end restore_tensors2 cost 0.0003223419189453125 seconds
DEBUG 01-05 09:59:15.917970.917970 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004935026168823242 seconds
DEBUG 01-05 09:59:15.919891.919891 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007555723190307617 seconds
DEBUG 01-05 09:59:15.919005.919005 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.919153.919153 lmp.py:423] 
DEBUG 01-05 09:59:15.919153.919153 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.919401.919401 cuda_h.py:19] end cpu_experts_submit cost 0.00012350082397460938 seconds
DEBUG 01-05 09:59:15.919766.919766 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:15.930899.930899 mlpmodule.py:704] group tensors cost 0.01010441780090332 s
DEBUG 01-05 09:59:15.932294.932294 mlpmodule.py:742] pad cost 0.0016396045684814453 s
DEBUG 01-05 09:59:15.932874.932874 mlpmodule.py:748] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-05 09:59:15.932307.932307 mlpmodule.py:753] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-05 09:59:15.943800.943800 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:15.944940.944940 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:15.944897.944897 mlpmodule.py:773] group_w3 first element: 0.08447265625
WARNING 01-05 09:59:15.944379.944379 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:15.963317.963317 mlpmodule.py:793] group einsum cost 0.030673742294311523 s
DEBUG 01-05 09:59:15.964846.964846 mlpmodule.py:801] cpy2cputensor cost 0.0007121562957763672 s
DEBUG 01-05 09:59:15.969122.969122 cuda_h.py:19] end wait_cetm_experts cost 0.04951882362365723 seconds
DEBUG 01-05 09:59:15.969538.969538 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:15.970227.970227 cuda_h.py:19] end gpu_sexperts cost 0.0005698204040527344 seconds
DEBUG 01-05 09:59:15.970892.970892 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:15.970702.970702 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:59:15.970597.970597 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:15.970261.970261 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce3634ba-1404-46d5-a678-3275389b33e2
INFO 01-05 09:59:15.971108.971108 client.py:127] Model loaded
DEBUG 01-05 09:59:15.971765.971765 cuda_h.py:19] end wait_experts cost 0.0014276504516601562 seconds
DEBUG 01-05 09:59:15.971899.971899 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:15.971747.971747 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:15.972534.972534 mlpmodule.py:531] gpu group tensors cost 0.0006716251373291016 s
DEBUG 01-05 09:59:15.974953.974953 mlpmodule.py:564] gpu pad cost 0.0017573833465576172 s
DEBUG 01-05 09:59:15.975855.975855 mlpmodule.py:582] gpu group einsum cost 0.0005495548248291016 s
DEBUG 01-05 09:59:15.978278.978278 mlpmodule.py:611] gpu experts func einsum cost 0.006661415100097656 s
DEBUG 01-05 09:59:15.978851.978851 cuda_h.py:19] end gpu_experts cost 0.0068531036376953125 seconds
DEBUG 01-05 09:59:15.978735.978735 cuda_h.py:19] end layer_moe_generate_23 cost 0.06908369064331055 seconds
DEBUG 01-05 09:59:15.979450.979450 lmp.py:217] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 09:59:15.979127.979127 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 09:59:15.979353.979353 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:59:15.979408.979408 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:59:15.979258.979258 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.4332275390625e-05 seconds
DEBUG 01-05 09:59:15.979629.979629 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.628036499023438e-05 seconds
DEBUG 01-05 09:59:15.979657.979657 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:15.979977.979977 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:15.979007.979007 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.979605.979605 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.982468.982468 cuda_h.py:19] end allocate_cuda_memory cost 0.0025916099548339844 seconds
DEBUG 01-05 09:59:15.982313.982313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.982857.982857 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.982111.982111 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.982767.982767 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81af4c5f-3f44-4b2e-b595-e384038d2f32
DEBUG 01-05 09:59:15.982658.982658 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:15.982942.982942 mlpmodule.py:662]  experts func einsum cost 0.0626225471496582 s
DEBUG 01-05 09:59:15.982695.982695 cuda_h.py:10] start self_attn
INFO 01-05 09:59:15.983813.983813 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81af4c5f-3f44-4b2e-b595-e384038d2f32
DEBUG 01-05 09:59:15.984471.984471 cuda_h.py:19] end load_into_gpu_async cost 0.0017158985137939453 seconds
DEBUG 01-05 09:59:15.984982.984982 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.984210.984210 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-05 09:59:15.984821.984821 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0046727657318115234 seconds
INFO 01-05 09:59:15.984844.984844 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81af4c5f-3f44-4b2e-b595-e384038d2f32
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:15.986841.986841 cuda_h.py:19] end self_attn cost 0.003267049789428711 seconds
DEBUG 01-05 09:59:15.986646.986646 cuda_h.py:19] end iln_self_attn_paln cost 0.007371187210083008 seconds
DEBUG 01-05 09:59:15.986582.986582 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 09:59:15.986298.986298 cuda_h.py:10] start gate
DEBUG 01-05 09:59:15.987393.987393 cuda_h.py:19] end gate cost 0.0006341934204101562 seconds
DEBUG 01-05 09:59:15.987124.987124 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:15.987716.987716 lmp.py:365] 
DEBUG 01-05 09:59:15.987716.987716 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:15.987234.987234 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:15.987122.987122 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:15.987911.987911 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:15.987554.987554 lmp.py:369] 
DEBUG 01-05 09:59:15.987554.987554 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:15.987197.987197 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:15.987039.987039 lmp.py:376]   Expert 47 |     67 | CPU
DEBUG 01-05 09:59:15.987158.987158 lmp.py:376]   Expert 42 |     70 | CPU
DEBUG 01-05 09:59:15.987325.987325 lmp.py:376]   Expert 43 |     71 | CPU
DEBUG 01-05 09:59:15.987252.987252 lmp.py:376]   Expert 44 |     71 | CPU
DEBUG 01-05 09:59:15.987942.987942 lmp.py:376]   Expert 35 |     79 | CPU
DEBUG 01-05 09:59:15.988346.988346 lmp.py:376]   Expert 25 |     81 | CPU
DEBUG 01-05 09:59:15.988989.988989 lmp.py:376]   Expert  6 |     84 | CPU
DEBUG 01-05 09:59:15.988347.988347 lmp.py:376]   Expert 48 |     87 | CPU
DEBUG 01-05 09:59:15.988752.988752 lmp.py:376]   Expert 62 |     89 | CPU
DEBUG 01-05 09:59:15.988918.988918 lmp.py:376]   Expert 60 |     95 | CPU
DEBUG 01-05 09:59:15.988084.988084 lmp.py:376]   Expert  5 |    100 | CPU
DEBUG 01-05 09:59:15.988727.988727 lmp.py:376]   Expert 55 |    103 | CPU
DEBUG 01-05 09:59:15.988132.988132 lmp.py:376]   Expert 29 |    105 | CPU
DEBUG 01-05 09:59:15.988059.988059 lmp.py:376]   Expert 54 |    106 | CPU
DEBUG 01-05 09:59:15.988464.988464 lmp.py:376]   Expert 16 |    107 | CPU
DEBUG 01-05 09:59:15.988630.988630 lmp.py:376]   Expert 22 |    125 | CPU
DEBUG 01-05 09:59:15.988796.988796 lmp.py:376]   Expert 30 |    128 | CPU
DEBUG 01-05 09:59:15.988201.988201 lmp.py:376]   Expert 56 |    133 | CPU
DEBUG 01-05 09:59:15.988321.988321 lmp.py:376]   Expert 51 |    139 | CPU
DEBUG 01-05 09:59:15.988440.988440 lmp.py:376]   Expert 36 |    151 | CPU
DEBUG 01-05 09:59:15.988368.988368 lmp.py:376]   Expert 61 |    154 | CPU
DEBUG 01-05 09:59:15.988773.988773 lmp.py:376]   Expert  4 |    156 | CPU
DEBUG 01-05 09:59:15.988462.988462 lmp.py:376]   Expert 28 |    158 | CPU
DEBUG 01-05 09:59:15.988628.988628 lmp.py:376]   Expert  7 |    160 | CPU
DEBUG 01-05 09:59:15.988556.988556 lmp.py:376]   Expert 49 |    162 | CPU
DEBUG 01-05 09:59:15.988722.988722 lmp.py:376]   Expert  1 |    165 | CPU
DEBUG 01-05 09:59:15.988650.988650 lmp.py:376]   Expert 38 |    169 | CPU
DEBUG 01-05 09:59:15.988306.988306 lmp.py:376]   Expert 59 |    169 | CPU
DEBUG 01-05 09:59:15.988949.988949 lmp.py:376]   Expert 31 |    172 | CPU
DEBUG 01-05 09:59:15.988639.988639 lmp.py:376]   Expert 17 |    177 | CPU
DEBUG 01-05 09:59:15.988328.988328 lmp.py:376]   Expert 21 |    178 | CPU
DEBUG 01-05 09:59:15.988779.988779 lmp.py:376]   Expert 20 |    183 | CPU
DEBUG 01-05 09:59:15.988945.988945 lmp.py:376]   Expert 34 |    185 | GPU
DEBUG 01-05 09:59:15.988873.988873 lmp.py:376]   Expert 46 |    185 | GPU
DEBUG 01-05 09:59:15.988562.988562 lmp.py:376]   Expert 14 |    195 | GPU
DEBUG 01-05 09:59:15.988490.988490 lmp.py:376]   Expert  0 |    196 | GPU
DEBUG 01-05 09:59:15.988940.988940 lmp.py:376]   Expert 15 |    196 | GPU
DEBUG 01-05 09:59:15.988630.988630 lmp.py:376]   Expert  3 |    200 | GPU
DEBUG 01-05 09:59:15.988511.988511 lmp.py:376]   Expert 53 |    200 | GPU
DEBUG 01-05 09:59:15.988916.988916 lmp.py:376]   Expert 41 |    203 | GPU
DEBUG 01-05 09:59:15.988843.988843 lmp.py:376]   Expert 40 |    206 | GPU
DEBUG 01-05 09:59:15.988771.988771 lmp.py:376]   Expert 24 |    213 | GPU
DEBUG 01-05 09:59:15.988460.988460 lmp.py:376]   Expert 63 |    214 | GPU
DEBUG 01-05 09:59:15.988150.988150 lmp.py:376]   Expert  2 |    215 | GPU
DEBUG 01-05 09:59:15.988077.988077 lmp.py:376]   Expert 19 |    216 | GPU
DEBUG 01-05 09:59:15.988528.988528 lmp.py:376]   Expert 37 |    224 | GPU
DEBUG 01-05 09:59:15.988218.988218 lmp.py:376]   Expert 57 |    227 | GPU
DEBUG 01-05 09:59:15.988861.988861 lmp.py:376]   Expert 10 |    233 | GPU
DEBUG 01-05 09:59:15.988027.988027 lmp.py:376]   Expert 50 |    237 | GPU
DEBUG 01-05 09:59:15.988716.988716 lmp.py:376]   Expert 26 |    240 | GPU
DEBUG 01-05 09:59:15.988405.988405 lmp.py:376]   Expert 45 |    247 | GPU
DEBUG 01-05 09:59:15.988618.988618 lmp.py:376]   Expert 23 |    250 | GPU
DEBUG 01-05 09:59:15.988069.988069 lmp.py:376]   Expert 58 |    250 | GPU
DEBUG 01-05 09:59:15.988520.988520 lmp.py:376]   Expert 32 |    258 | GPU
DEBUG 01-05 09:59:15.988970.988970 lmp.py:376]   Expert  9 |    271 | GPU
DEBUG 01-05 09:59:15.988183.988183 lmp.py:376]   Expert 52 |    271 | GPU
DEBUG 01-05 09:59:15.988064.988064 lmp.py:376]   Expert 12 |    282 | GPU
DEBUG 01-05 09:59:15.988469.988469 lmp.py:376]   Expert 18 |    284 | GPU
DEBUG 01-05 09:59:15.988158.988158 lmp.py:376]   Expert 13 |    320 | GPU
DEBUG 01-05 09:59:15.988847.988847 lmp.py:376]   Expert 33 |    336 | GPU
DEBUG 01-05 09:59:15.988537.988537 lmp.py:376]   Expert 39 |    343 | GPU
DEBUG 01-05 09:59:15.988988.988988 lmp.py:376]   Expert  8 |    367 | GPU
DEBUG 01-05 09:59:15.988200.988200 lmp.py:376]   Expert 11 |    374 | GPU
DEBUG 01-05 09:59:15.988889.988889 lmp.py:376]   Expert 27 |    656 | GPU
DEBUG 01-05 09:59:15.989771.989771 lmp.py:377] 
DEBUG 01-05 09:59:15.989771.989771 lmp.py:377]   CPU total tokens: 3994 (32.5%)
DEBUG 01-05 09:59:15.989891.989891 lmp.py:378]   GPU total tokens: 8294 (67.5%)
DEBUG 01-05 09:59:15.989779.989779 cuda_h.py:19] end experts_map_get cost 0.0015430450439453125 seconds
DEBUG 01-05 09:59:15.989329.989329 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:15.989159.989159 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:15.989018.989018 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:15.990928.990928 cuda_h.py:19] end allocate_cuda_memory cost 0.001233816146850586 seconds
DEBUG 01-05 09:59:15.990201.990201 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:15.990242.990242 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:15.990528.990528 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:15.990893.990893 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dd07035e-31d5-44f9-a24a-da0233043326
DEBUG 01-05 09:59:15.990264.990264 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:15.992492.992492 client.py:127] Model loaded
DEBUG 01-05 09:59:15.992281.992281 cuda_h.py:19] end sllm_worker_task cost 0.012744665145874023 seconds
INFO 01-05 09:59:15.993658.993658 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dd07035e-31d5-44f9-a24a-da0233043326
DEBUG 01-05 09:59:15.993617.993617 cuda_h.py:19] end load_into_gpu_async cost 0.0030670166015625 seconds
DEBUG 01-05 09:59:15.993918.993918 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:15.994568.994568 cuda_h.py:19] end restore_tensors2 cost 0.0003814697265625 seconds
DEBUG 01-05 09:59:15.994060.994060 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005136251449584961 seconds
DEBUG 01-05 09:59:15.996047.996047 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007770061492919922 seconds
DEBUG 01-05 09:59:15.996453.996453 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:15.997747.997747 lmp.py:423] 
DEBUG 01-05 09:59:15.997747.997747 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:15.997643.997643 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 09:59:15.997154.997154 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:16.006241.006241 mlpmodule.py:704] group tensors cost 0.009520292282104492 s
DEBUG 01-05 09:59:16.009720.009720 mlpmodule.py:742] pad cost 0.0020761489868164062 s
DEBUG 01-05 09:59:16.009936.009936 mlpmodule.py:748] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-05 09:59:16.009767.009767 mlpmodule.py:753] move to cpu cost 3.933906555175781e-05 s
DEBUG 01-05 09:59:16.019416.019416 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:16.019092.019092 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:16.019426.019426 mlpmodule.py:773] group_w3 first element: -0.019287109375
WARNING 01-05 09:59:16.020021.020021 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:16.037290.037290 mlpmodule.py:793] group einsum cost 0.027181148529052734 s
DEBUG 01-05 09:59:16.038310.038310 mlpmodule.py:801] cpy2cputensor cost 0.0007424354553222656 s
DEBUG 01-05 09:59:16.043844.043844 cuda_h.py:19] end wait_cetm_experts cost 0.04604363441467285 seconds
DEBUG 01-05 09:59:16.043022.043022 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:16.043380.043380 cuda_h.py:19] end gpu_sexperts cost 0.0005741119384765625 seconds
DEBUG 01-05 09:59:16.044693.044693 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:16.044165.044165 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 09:59:16.044014.044014 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:16.044201.044201 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dd07035e-31d5-44f9-a24a-da0233043326
INFO 01-05 09:59:16.048795.048795 client.py:127] Model loaded
DEBUG 01-05 09:59:16.048890.048890 cuda_h.py:19] end wait_experts cost 0.0041599273681640625 seconds
DEBUG 01-05 09:59:16.048692.048692 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:16.048515.048515 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:16.049453.049453 mlpmodule.py:531] gpu group tensors cost 0.0006415843963623047 s
DEBUG 01-05 09:59:16.050367.050367 mlpmodule.py:564] gpu pad cost 0.0017435550689697266 s
DEBUG 01-05 09:59:16.051786.051786 mlpmodule.py:582] gpu group einsum cost 0.0005474090576171875 s
DEBUG 01-05 09:59:16.054131.054131 mlpmodule.py:611] gpu experts func einsum cost 0.006266355514526367 s
DEBUG 01-05 09:59:16.054313.054313 cuda_h.py:19] end gpu_experts cost 0.006456851959228516 seconds
DEBUG 01-05 09:59:16.054727.054727 cuda_h.py:19] end layer_moe_generate_24 cost 0.06819343566894531 seconds
DEBUG 01-05 09:59:16.055470.055470 mlpmodule.py:662]  experts func einsum cost 0.05792236328125 s
DEBUG 01-05 09:59:16.055165.055165 lmp.py:217] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 09:59:16.055625.055625 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 09:59:16.055037.055037 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:59:16.055939.055939 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:59:16.055258.055258 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:16.055459.055459 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 8.034706115722656e-05 seconds
DEBUG 01-05 09:59:16.055294.055294 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:16.055084.055084 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:16.055598.055598 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:16.055918.055918 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:16.056832.056832 cuda_h.py:19] end allocate_cuda_memory cost 0.0003561973571777344 seconds
DEBUG 01-05 09:59:16.056318.056318 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:16.056140.056140 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:16.056771.056771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:16.056759.056759 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af938e81-0f5b-4e7e-902e-2974714d6a45
DEBUG 01-05 09:59:16.056490.056490 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:16.056580.056580 cuda_h.py:10] start self_attn
INFO 01-05 09:59:16.057290.057290 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af938e81-0f5b-4e7e-902e-2974714d6a45
DEBUG 01-05 09:59:16.057318.057318 cuda_h.py:19] end load_into_gpu_async cost 0.0011494159698486328 seconds
DEBUG 01-05 09:59:16.057067.057067 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:16.057150.057150 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 09:59:16.057191.057191 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018377304077148438 seconds
INFO 01-05 09:59:16.058358.058358 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af938e81-0f5b-4e7e-902e-2974714d6a45
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:16.060225.060225 cuda_h.py:19] end self_attn cost 0.003188610076904297 seconds
DEBUG 01-05 09:59:16.060846.060846 cuda_h.py:19] end iln_self_attn_paln cost 0.0048024654388427734 seconds
DEBUG 01-05 09:59:16.060782.060782 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 09:59:16.060260.060260 cuda_h.py:10] start gate
DEBUG 01-05 09:59:16.061587.061587 cuda_h.py:19] end gate cost 0.0006270408630371094 seconds
DEBUG 01-05 09:59:16.061555.061555 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:16.061956.061956 lmp.py:365] 
DEBUG 01-05 09:59:16.061956.061956 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:16.061520.061520 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:16.061931.061931 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:16.061958.061958 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:16.061886.061886 lmp.py:369] 
DEBUG 01-05 09:59:16.061886.061886 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:16.061290.061290 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:16.061563.061563 lmp.py:376]   Expert 36 |     45 | CPU
DEBUG 01-05 09:59:16.061444.061444 lmp.py:376]   Expert 33 |     50 | CPU
DEBUG 01-05 09:59:16.061372.061372 lmp.py:376]   Expert 18 |     57 | CPU
DEBUG 01-05 09:59:16.061061.061061 lmp.py:376]   Expert 42 |     57 | CPU
DEBUG 01-05 09:59:16.061989.061989 lmp.py:376]   Expert 13 |     69 | CPU
DEBUG 01-05 09:59:16.061917.061917 lmp.py:376]   Expert  0 |     70 | CPU
DEBUG 01-05 09:59:16.061606.061606 lmp.py:376]   Expert 16 |     80 | CPU
DEBUG 01-05 09:59:16.061580.061580 lmp.py:376]   Expert 22 |     82 | CPU
DEBUG 01-05 09:59:16.061792.061792 lmp.py:376]   Expert 47 |     86 | CPU
DEBUG 01-05 09:59:16.061243.061243 lmp.py:376]   Expert 21 |     92 | CPU
DEBUG 01-05 09:59:16.061886.061886 lmp.py:376]   Expert 62 |     92 | CPU
DEBUG 01-05 09:59:16.061099.061099 lmp.py:376]   Expert 10 |     96 | CPU
DEBUG 01-05 09:59:16.061550.061550 lmp.py:376]   Expert 38 |    102 | CPU
DEBUG 01-05 09:59:16.061001.061001 lmp.py:376]   Expert 59 |    110 | CPU
DEBUG 01-05 09:59:16.061736.061736 lmp.py:376]   Expert 43 |    111 | CPU
DEBUG 01-05 09:59:16.061187.061187 lmp.py:376]   Expert 27 |    116 | CPU
DEBUG 01-05 09:59:16.061638.061638 lmp.py:376]   Expert  5 |    118 | CPU
DEBUG 01-05 09:59:16.062612.062612 lmp.py:376]   Expert 50 |    118 | CPU
DEBUG 01-05 09:59:16.062824.062824 lmp.py:376]   Expert 53 |    119 | CPU
DEBUG 01-05 09:59:16.062275.062275 lmp.py:376]   Expert 34 |    121 | CPU
DEBUG 01-05 09:59:16.062965.062965 lmp.py:376]   Expert  2 |    124 | CPU
DEBUG 01-05 09:59:16.062177.062177 lmp.py:376]   Expert 41 |    126 | CPU
DEBUG 01-05 09:59:16.062151.062151 lmp.py:376]   Expert 14 |    127 | CPU
DEBUG 01-05 09:59:16.062648.062648 lmp.py:376]   Expert 44 |    127 | CPU
DEBUG 01-05 09:59:16.062622.062622 lmp.py:376]   Expert 31 |    135 | CPU
DEBUG 01-05 09:59:16.062596.062596 lmp.py:376]   Expert 56 |    135 | CPU
DEBUG 01-05 09:59:16.062094.062094 lmp.py:376]   Expert 48 |    136 | CPU
DEBUG 01-05 09:59:16.062068.062068 lmp.py:376]   Expert 20 |    139 | CPU
DEBUG 01-05 09:59:16.062565.062565 lmp.py:376]   Expert 24 |    139 | CPU
DEBUG 01-05 09:59:16.062254.062254 lmp.py:376]   Expert 32 |    140 | CPU
DEBUG 01-05 09:59:16.062990.062990 lmp.py:376]   Expert  4 |    149 | CPU
DEBUG 01-05 09:59:16.062725.062725 lmp.py:376]   Expert 23 |    155 | CPU
DEBUG 01-05 09:59:16.062700.062700 lmp.py:376]   Expert  3 |    159 | GPU
DEBUG 01-05 09:59:16.062197.062197 lmp.py:376]   Expert 45 |    160 | GPU
DEBUG 01-05 09:59:16.062171.062171 lmp.py:376]   Expert 46 |    167 | GPU
DEBUG 01-05 09:59:16.062906.062906 lmp.py:376]   Expert 55 |    168 | GPU
DEBUG 01-05 09:59:16.062880.062880 lmp.py:376]   Expert  6 |    178 | GPU
DEBUG 01-05 09:59:16.062378.062378 lmp.py:376]   Expert 39 |    184 | GPU
DEBUG 01-05 09:59:16.062113.062113 lmp.py:376]   Expert 61 |    194 | GPU
DEBUG 01-05 09:59:16.062803.062803 lmp.py:376]   Expert  1 |    196 | GPU
DEBUG 01-05 09:59:16.062538.062538 lmp.py:376]   Expert 51 |    200 | GPU
DEBUG 01-05 09:59:16.062274.062274 lmp.py:376]   Expert 52 |    202 | GPU
DEBUG 01-05 09:59:16.062009.062009 lmp.py:376]   Expert  8 |    210 | GPU
DEBUG 01-05 09:59:16.062984.062984 lmp.py:376]   Expert 40 |    219 | GPU
DEBUG 01-05 09:59:16.062719.062719 lmp.py:376]   Expert 12 |    220 | GPU
DEBUG 01-05 09:59:16.062455.062455 lmp.py:376]   Expert 11 |    229 | GPU
DEBUG 01-05 09:59:16.062714.062714 lmp.py:376]   Expert 35 |    229 | GPU
DEBUG 01-05 09:59:16.062688.062688 lmp.py:376]   Expert  7 |    240 | GPU
DEBUG 01-05 09:59:16.062185.062185 lmp.py:376]   Expert 15 |    249 | GPU
DEBUG 01-05 09:59:16.062920.062920 lmp.py:376]   Expert 37 |    254 | GPU
DEBUG 01-05 09:59:16.062610.062610 lmp.py:376]   Expert 49 |    262 | GPU
DEBUG 01-05 09:59:16.062345.062345 lmp.py:376]   Expert 57 |    286 | GPU
DEBUG 01-05 09:59:16.062081.062081 lmp.py:376]   Expert 28 |    294 | GPU
DEBUG 01-05 09:59:16.062578.062578 lmp.py:376]   Expert 26 |    300 | GPU
DEBUG 01-05 09:59:16.062075.062075 lmp.py:376]   Expert 30 |    309 | GPU
DEBUG 01-05 09:59:16.062811.062811 lmp.py:376]   Expert 58 |    324 | GPU
DEBUG 01-05 09:59:16.062547.062547 lmp.py:376]   Expert 63 |    324 | GPU
DEBUG 01-05 09:59:16.062044.062044 lmp.py:376]   Expert 54 |    365 | GPU
DEBUG 01-05 09:59:16.062779.062779 lmp.py:376]   Expert 25 |    377 | GPU
DEBUG 01-05 09:59:16.062230.062230 lmp.py:376]   Expert  9 |    399 | GPU
DEBUG 01-05 09:59:16.062920.062920 lmp.py:376]   Expert 17 |    436 | GPU
DEBUG 01-05 09:59:16.062655.062655 lmp.py:376]   Expert 60 |    465 | GPU
DEBUG 01-05 09:59:16.062914.062914 lmp.py:376]   Expert 29 |    493 | GPU
DEBUG 01-05 09:59:16.062411.062411 lmp.py:376]   Expert 19 |    573 | GPU
DEBUG 01-05 09:59:16.062862.062862 lmp.py:377] 
DEBUG 01-05 09:59:16.062862.062862 lmp.py:377]   CPU total tokens: 3423 (27.9%)
DEBUG 01-05 09:59:16.062551.062551 lmp.py:378]   GPU total tokens: 8865 (72.1%)
DEBUG 01-05 09:59:16.062963.062963 cuda_h.py:19] end experts_map_get cost 0.0014674663543701172 seconds
DEBUG 01-05 09:59:16.062844.062844 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:16.062813.062813 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:16.062526.062526 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:16.064838.064838 cuda_h.py:19] end allocate_cuda_memory cost 0.0011801719665527344 seconds
DEBUG 01-05 09:59:16.064602.064602 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:16.064550.064550 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:16.064690.064690 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:16.064817.064817 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 09dc4bd6-6aec-4c7d-8973-79cfc9cabaf2
DEBUG 01-05 09:59:16.064234.064234 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:16.065566.065566 client.py:127] Model loaded
DEBUG 01-05 09:59:16.065860.065860 cuda_h.py:19] end sllm_worker_task cost 0.00999593734741211 seconds
INFO 01-05 09:59:16.066774.066774 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 09dc4bd6-6aec-4c7d-8973-79cfc9cabaf2
DEBUG 01-05 09:59:16.066299.066299 cuda_h.py:19] end load_into_gpu_async cost 0.0021996498107910156 seconds
DEBUG 01-05 09:59:16.066718.066718 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:16.066047.066047 cuda_h.py:19] end restore_tensors2 cost 0.0003230571746826172 seconds
DEBUG 01-05 09:59:16.066870.066870 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0040569305419921875 seconds
DEBUG 01-05 09:59:16.069559.069559 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006679534912109375 seconds
DEBUG 01-05 09:59:16.069131.069131 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:16.069810.069810 lmp.py:423] 
DEBUG 01-05 09:59:16.069810.069810 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:16.069084.069084 cuda_h.py:19] end cpu_experts_submit cost 0.0001327991485595703 seconds
DEBUG 01-05 09:59:16.069926.069926 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:16.080315.080315 mlpmodule.py:704] group tensors cost 0.010231256484985352 s
DEBUG 01-05 09:59:16.082351.082351 mlpmodule.py:742] pad cost 0.0016889572143554688 s
DEBUG 01-05 09:59:16.082256.082256 mlpmodule.py:748] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-05 09:59:16.082443.082443 mlpmodule.py:753] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-05 09:59:16.092982.092982 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:16.092652.092652 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:16.092841.092841 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 09:59:16.092734.092734 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:16.110158.110158 mlpmodule.py:793] group einsum cost 0.02719283103942871 s
DEBUG 01-05 09:59:16.111135.111135 mlpmodule.py:801] cpy2cputensor cost 0.00064849853515625 s
DEBUG 01-05 09:59:16.116754.116754 cuda_h.py:19] end wait_cetm_experts cost 0.046216726303100586 seconds
DEBUG 01-05 09:59:16.116362.116362 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:16.116231.116231 cuda_h.py:19] end gpu_sexperts cost 0.0005960464477539062 seconds
DEBUG 01-05 09:59:16.116796.116796 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:16.117938.117938 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:16.117786.117786 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:16.117734.117734 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 09dc4bd6-6aec-4c7d-8973-79cfc9cabaf2
INFO 01-05 09:59:16.122373.122373 client.py:127] Model loaded
DEBUG 01-05 09:59:16.122753.122753 cuda_h.py:19] end wait_experts cost 0.00549006462097168 seconds
DEBUG 01-05 09:59:16.122701.122701 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:16.122980.122980 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:16.123381.123381 mlpmodule.py:531] gpu group tensors cost 0.0006330013275146484 s
DEBUG 01-05 09:59:16.125942.125942 mlpmodule.py:564] gpu pad cost 0.0018649101257324219 s
DEBUG 01-05 09:59:16.125141.125141 mlpmodule.py:582] gpu group einsum cost 0.0005297660827636719 s
DEBUG 01-05 09:59:16.128608.128608 mlpmodule.py:662]  experts func einsum cost 0.058367252349853516 s
DEBUG 01-05 09:59:16.129918.129918 mlpmodule.py:611] gpu experts func einsum cost 0.006354093551635742 s
DEBUG 01-05 09:59:16.129677.129677 cuda_h.py:19] end gpu_experts cost 0.006590604782104492 seconds
DEBUG 01-05 09:59:16.129647.129647 cuda_h.py:19] end layer_moe_generate_25 cost 0.06872415542602539 seconds
DEBUG 01-05 09:59:16.129931.129931 lmp.py:217] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 09:59:16.129502.129502 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 09:59:16.129244.129244 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:59:16.129762.129762 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:59:16.129505.129505 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.075599670410156e-05 seconds
DEBUG 01-05 09:59:16.129321.129321 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.534027099609375e-05 seconds
DEBUG 01-05 09:59:16.129594.129594 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:16.129006.129006 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:16.129183.129183 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:16.129662.129662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:16.130804.130804 cuda_h.py:19] end allocate_cuda_memory cost 0.0004520416259765625 seconds
DEBUG 01-05 09:59:16.130691.130691 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:16.130123.130123 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:16.130323.130323 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:16.130549.130549 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1a7797df-b143-4aeb-a376-3033f4501be8
DEBUG 01-05 09:59:16.130088.130088 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:16.131712.131712 cuda_h.py:10] start self_attn
INFO 01-05 09:59:16.132259.132259 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1a7797df-b143-4aeb-a376-3033f4501be8
DEBUG 01-05 09:59:16.132778.132778 cuda_h.py:19] end load_into_gpu_async cost 0.0015728473663330078 seconds
DEBUG 01-05 09:59:16.132527.132527 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:16.132563.132563 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-05 09:59:16.132174.132174 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002646207809448242 seconds
INFO 01-05 09:59:16.133660.133660 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1a7797df-b143-4aeb-a376-3033f4501be8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:16.134101.134101 cuda_h.py:19] end self_attn cost 0.0036308765411376953 seconds
DEBUG 01-05 09:59:16.135362.135362 cuda_h.py:19] end iln_self_attn_paln cost 0.005523681640625 seconds
DEBUG 01-05 09:59:16.135821.135821 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 09:59:16.135584.135584 cuda_h.py:10] start gate
DEBUG 01-05 09:59:16.135772.135772 cuda_h.py:19] end gate cost 0.0006320476531982422 seconds
DEBUG 01-05 09:59:16.136979.136979 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:16.136518.136518 lmp.py:365] 
DEBUG 01-05 09:59:16.136518.136518 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:16.136082.136082 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:16.136507.136507 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:16.136726.136726 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:16.136608.136608 lmp.py:369] 
DEBUG 01-05 09:59:16.136608.136608 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:16.136727.136727 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:16.136093.136093 lmp.py:376]   Expert 17 |     51 | CPU
DEBUG 01-05 09:59:16.136451.136451 lmp.py:376]   Expert  3 |     60 | CPU
DEBUG 01-05 09:59:16.136094.136094 lmp.py:376]   Expert 49 |     65 | CPU
DEBUG 01-05 09:59:16.136498.136498 lmp.py:376]   Expert 62 |     70 | CPU
DEBUG 01-05 09:59:16.136426.136426 lmp.py:376]   Expert 59 |     73 | CPU
DEBUG 01-05 09:59:16.136354.136354 lmp.py:376]   Expert 30 |     74 | CPU
DEBUG 01-05 09:59:16.136712.136712 lmp.py:376]   Expert 58 |     75 | CPU
DEBUG 01-05 09:59:16.136878.136878 lmp.py:376]   Expert 55 |     78 | CPU
DEBUG 01-05 09:59:16.136044.136044 lmp.py:376]   Expert 51 |     80 | CPU
DEBUG 01-05 09:59:16.136210.136210 lmp.py:376]   Expert 61 |     82 | CPU
DEBUG 01-05 09:59:16.136138.136138 lmp.py:376]   Expert 24 |     84 | CPU
DEBUG 01-05 09:59:16.136066.136066 lmp.py:376]   Expert  8 |     85 | CPU
DEBUG 01-05 09:59:16.136232.136232 lmp.py:376]   Expert  9 |     86 | CPU
DEBUG 01-05 09:59:16.136683.136683 lmp.py:376]   Expert 19 |     87 | CPU
DEBUG 01-05 09:59:16.136849.136849 lmp.py:376]   Expert  7 |     92 | CPU
DEBUG 01-05 09:59:16.136015.136015 lmp.py:376]   Expert 15 |     96 | CPU
DEBUG 01-05 09:59:16.136135.136135 lmp.py:376]   Expert  6 |    100 | CPU
DEBUG 01-05 09:59:16.136255.136255 lmp.py:376]   Expert 56 |    101 | CPU
DEBUG 01-05 09:59:16.136421.136421 lmp.py:376]   Expert 60 |    108 | CPU
DEBUG 01-05 09:59:16.136872.136872 lmp.py:376]   Expert 21 |    109 | CPU
DEBUG 01-05 09:59:16.136799.136799 lmp.py:376]   Expert 11 |    116 | CPU
DEBUG 01-05 09:59:16.136727.136727 lmp.py:376]   Expert 43 |    117 | CPU
DEBUG 01-05 09:59:16.136655.136655 lmp.py:376]   Expert 13 |    120 | CPU
DEBUG 01-05 09:59:16.136821.136821 lmp.py:376]   Expert 12 |    122 | CPU
DEBUG 01-05 09:59:16.136226.136226 lmp.py:376]   Expert  0 |    133 | CPU
DEBUG 01-05 09:59:16.136392.136392 lmp.py:376]   Expert 26 |    136 | CPU
DEBUG 01-05 09:59:16.136319.136319 lmp.py:376]   Expert 41 |    138 | CPU
DEBUG 01-05 09:59:16.136486.136486 lmp.py:376]   Expert 53 |    138 | CPU
DEBUG 01-05 09:59:16.136936.136936 lmp.py:376]   Expert 38 |    140 | CPU
DEBUG 01-05 09:59:16.136864.136864 lmp.py:376]   Expert 29 |    143 | CPU
DEBUG 01-05 09:59:16.136030.136030 lmp.py:376]   Expert 22 |    146 | CPU
DEBUG 01-05 09:59:16.137912.137912 lmp.py:376]   Expert 27 |    146 | CPU
DEBUG 01-05 09:59:16.137316.137316 lmp.py:376]   Expert 28 |    146 | GPU
DEBUG 01-05 09:59:16.137767.137767 lmp.py:376]   Expert 47 |    146 | GPU
DEBUG 01-05 09:59:16.137695.137695 lmp.py:376]   Expert 45 |    152 | GPU
DEBUG 01-05 09:59:16.137384.137384 lmp.py:376]   Expert 34 |    153 | GPU
DEBUG 01-05 09:59:16.137073.137073 lmp.py:376]   Expert 37 |    180 | GPU
DEBUG 01-05 09:59:16.137286.137286 lmp.py:376]   Expert 57 |    183 | GPU
DEBUG 01-05 09:59:16.137975.137975 lmp.py:376]   Expert 32 |    186 | GPU
DEBUG 01-05 09:59:16.137857.137857 lmp.py:376]   Expert 48 |    190 | GPU
DEBUG 01-05 09:59:16.137261.137261 lmp.py:376]   Expert 23 |    197 | GPU
DEBUG 01-05 09:59:16.137189.137189 lmp.py:376]   Expert  1 |    199 | GPU
DEBUG 01-05 09:59:16.137117.137117 lmp.py:376]   Expert 36 |    200 | GPU
DEBUG 01-05 09:59:16.137806.137806 lmp.py:376]   Expert 42 |    204 | GPU
DEBUG 01-05 09:59:16.137257.137257 lmp.py:376]   Expert  4 |    224 | GPU
DEBUG 01-05 09:59:16.137946.137946 lmp.py:376]   Expert 54 |    227 | GPU
DEBUG 01-05 09:59:16.137635.137635 lmp.py:376]   Expert 39 |    228 | GPU
DEBUG 01-05 09:59:16.137086.137086 lmp.py:376]   Expert 31 |    242 | GPU
DEBUG 01-05 09:59:16.137776.137776 lmp.py:376]   Expert 20 |    251 | GPU
DEBUG 01-05 09:59:16.137180.137180 lmp.py:376]   Expert 16 |    255 | GPU
DEBUG 01-05 09:59:16.137393.137393 lmp.py:376]   Expert 33 |    260 | GPU
DEBUG 01-05 09:59:16.137082.137082 lmp.py:376]   Expert  2 |    284 | GPU
DEBUG 01-05 09:59:16.137771.137771 lmp.py:376]   Expert 44 |    303 | GPU
DEBUG 01-05 09:59:16.137460.137460 lmp.py:376]   Expert 18 |    309 | GPU
DEBUG 01-05 09:59:16.137150.137150 lmp.py:376]   Expert 25 |    309 | GPU
DEBUG 01-05 09:59:16.137601.137601 lmp.py:376]   Expert  5 |    330 | GPU
DEBUG 01-05 09:59:16.137528.137528 lmp.py:376]   Expert 50 |    330 | GPU
DEBUG 01-05 09:59:16.137218.137218 lmp.py:376]   Expert 10 |    362 | GPU
DEBUG 01-05 09:59:16.137861.137861 lmp.py:376]   Expert 35 |    370 | GPU
DEBUG 01-05 09:59:16.137504.137504 lmp.py:376]   Expert 63 |    397 | GPU
DEBUG 01-05 09:59:16.137955.137955 lmp.py:376]   Expert 40 |    454 | GPU
DEBUG 01-05 09:59:16.137644.137644 lmp.py:376]   Expert 46 |    460 | GPU
DEBUG 01-05 09:59:16.137856.137856 lmp.py:376]   Expert 52 |    513 | GPU
DEBUG 01-05 09:59:16.137546.137546 lmp.py:376]   Expert 14 |    793 | GPU
DEBUG 01-05 09:59:16.137950.137950 lmp.py:377] 
DEBUG 01-05 09:59:16.137950.137950 lmp.py:377]   CPU total tokens: 3251 (26.5%)
DEBUG 01-05 09:59:16.137355.137355 lmp.py:378]   GPU total tokens: 9037 (73.5%)
DEBUG 01-05 09:59:16.137766.137766 cuda_h.py:19] end experts_map_get cost 0.0015361309051513672 seconds
DEBUG 01-05 09:59:16.137601.137601 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:16.137808.137808 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:16.137991.137991 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:16.139333.139333 cuda_h.py:19] end allocate_cuda_memory cost 0.0012729167938232422 seconds
DEBUG 01-05 09:59:16.139143.139143 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:16.139899.139899 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:16.139729.139729 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:16.139571.139571 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8aa178a1-30d7-46c6-b1b8-7aa67b2332fe
DEBUG 01-05 09:59:16.139312.139312 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:16.139258.139258 client.py:127] Model loaded
DEBUG 01-05 09:59:16.139916.139916 cuda_h.py:19] end sllm_worker_task cost 0.009853363037109375 seconds
INFO 01-05 09:59:16.140298.140298 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8aa178a1-30d7-46c6-b1b8-7aa67b2332fe
DEBUG 01-05 09:59:16.140333.140333 cuda_h.py:19] end load_into_gpu_async cost 0.0010898113250732422 seconds
DEBUG 01-05 09:59:16.140606.140606 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:16.140763.140763 cuda_h.py:19] end restore_tensors2 cost 0.0003368854522705078 seconds
DEBUG 01-05 09:59:16.140017.140017 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030450820922851562 seconds
DEBUG 01-05 09:59:16.143711.143711 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005636930465698242 seconds
DEBUG 01-05 09:59:16.143256.143256 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:16.143451.143451 lmp.py:423] 
DEBUG 01-05 09:59:16.143451.143451 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:16.143652.143652 cuda_h.py:19] end cpu_experts_submit cost 0.00012302398681640625 seconds
DEBUG 01-05 09:59:16.143494.143494 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:16.152681.152681 mlpmodule.py:704] group tensors cost 0.008697986602783203 s
DEBUG 01-05 09:59:16.155382.155382 mlpmodule.py:742] pad cost 0.0019485950469970703 s
DEBUG 01-05 09:59:16.155552.155552 mlpmodule.py:748] create cpu tensor cost 5.054473876953125e-05 s
DEBUG 01-05 09:59:16.155667.155667 mlpmodule.py:753] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-05 09:59:16.163541.163541 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:16.164118.164118 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:16.164168.164168 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 09:59:16.164066.164066 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:16.180308.180308 mlpmodule.py:793] group einsum cost 0.025161027908325195 s
DEBUG 01-05 09:59:16.181867.181867 mlpmodule.py:801] cpy2cputensor cost 0.0006270408630371094 s
DEBUG 01-05 09:59:16.186504.186504 cuda_h.py:19] end wait_cetm_experts cost 0.04276871681213379 seconds
DEBUG 01-05 09:59:16.186927.186927 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:16.187200.187200 cuda_h.py:19] end gpu_sexperts cost 0.0005807876586914062 seconds
DEBUG 01-05 09:59:16.187897.187897 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:16.187893.187893 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-05 09:59:16.187503.187503 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:16.187213.187213 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8aa178a1-30d7-46c6-b1b8-7aa67b2332fe
INFO 01-05 09:59:16.196081.196081 client.py:127] Model loaded
DEBUG 01-05 09:59:16.196469.196469 cuda_h.py:19] end wait_experts cost 0.009026050567626953 seconds
DEBUG 01-05 09:59:16.196239.196239 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:16.196849.196849 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:16.197994.197994 mlpmodule.py:531] gpu group tensors cost 0.0006659030914306641 s
DEBUG 01-05 09:59:16.199972.199972 mlpmodule.py:564] gpu pad cost 0.002238035202026367 s
DEBUG 01-05 09:59:16.200262.200262 mlpmodule.py:582] gpu group einsum cost 0.0008704662322998047 s
DEBUG 01-05 09:59:16.202462.202462 mlpmodule.py:662]  experts func einsum cost 0.05836009979248047 s
DEBUG 01-05 09:59:16.204308.204308 mlpmodule.py:611] gpu experts func einsum cost 0.007466316223144531 s
DEBUG 01-05 09:59:16.204544.204544 cuda_h.py:19] end gpu_experts cost 0.007710695266723633 seconds
DEBUG 01-05 09:59:16.204515.204515 cuda_h.py:19] end layer_moe_generate_26 cost 0.06894826889038086 seconds
DEBUG 01-05 09:59:16.204158.204158 lmp.py:217] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 09:59:16.204173.204173 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 09:59:16.204061.204061 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 09:59:16.204037.204037 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.430511474609375e-05 seconds
DEBUG 01-05 09:59:16.204064.204064 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:16.205057.205057 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:16.207082.207082 cuda_h.py:19] end self_attn cost 0.0026655197143554688 seconds
DEBUG 01-05 09:59:16.208436.208436 cuda_h.py:19] end iln_self_attn_paln cost 0.003371715545654297 seconds
DEBUG 01-05 09:59:16.208802.208802 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 09:59:16.208042.208042 cuda_h.py:10] start gate
DEBUG 01-05 09:59:16.208583.208583 cuda_h.py:19] end gate cost 0.0007176399230957031 seconds
DEBUG 01-05 09:59:16.208221.208221 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:16.209787.209787 lmp.py:365] 
DEBUG 01-05 09:59:16.209787.209787 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:16.209828.209828 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:16.209716.209716 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:16.209790.209790 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:16.209479.209479 lmp.py:369] 
DEBUG 01-05 09:59:16.209479.209479 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:16.209407.209407 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:16.209057.209057 lmp.py:376]   Expert 47 |     33 | CPU
DEBUG 01-05 09:59:16.209700.209700 lmp.py:376]   Expert 18 |     40 | CPU
DEBUG 01-05 09:59:16.209389.209389 lmp.py:376]   Expert 54 |     58 | CPU
DEBUG 01-05 09:59:16.209601.209601 lmp.py:376]   Expert 15 |     69 | CPU
DEBUG 01-05 09:59:16.209814.209814 lmp.py:376]   Expert 58 |     69 | CPU
DEBUG 01-05 09:59:16.209742.209742 lmp.py:376]   Expert 59 |     79 | CPU
DEBUG 01-05 09:59:16.209146.209146 lmp.py:376]   Expert  7 |     80 | CPU
DEBUG 01-05 09:59:16.209359.209359 lmp.py:376]   Expert 32 |     80 | CPU
DEBUG 01-05 09:59:16.209333.209333 lmp.py:376]   Expert 24 |     83 | CPU
DEBUG 01-05 09:59:16.209068.209068 lmp.py:376]   Expert 38 |     85 | CPU
DEBUG 01-05 09:59:16.209042.209042 lmp.py:376]   Expert 12 |     90 | CPU
DEBUG 01-05 09:59:16.209778.209778 lmp.py:376]   Expert 11 |     92 | CPU
DEBUG 01-05 09:59:16.209752.209752 lmp.py:376]   Expert 42 |    104 | CPU
DEBUG 01-05 09:59:16.209501.209501 lmp.py:376]   Expert 61 |    104 | CPU
DEBUG 01-05 09:59:16.209952.209952 lmp.py:376]   Expert 23 |    115 | CPU
DEBUG 01-05 09:59:16.209641.209641 lmp.py:376]   Expert 40 |    115 | CPU
DEBUG 01-05 09:59:16.209092.209092 lmp.py:376]   Expert  6 |    118 | CPU
DEBUG 01-05 09:59:16.209828.209828 lmp.py:376]   Expert 45 |    128 | CPU
DEBUG 01-05 09:59:16.209564.209564 lmp.py:376]   Expert 46 |    130 | CPU
DEBUG 01-05 09:59:16.209822.209822 lmp.py:376]   Expert 34 |    132 | CPU
DEBUG 01-05 09:59:16.209081.209081 lmp.py:376]   Expert 52 |    133 | CPU
DEBUG 01-05 09:59:16.209578.209578 lmp.py:376]   Expert 39 |    134 | CPU
DEBUG 01-05 09:59:16.209837.209837 lmp.py:376]   Expert 48 |    138 | CPU
DEBUG 01-05 09:59:16.209334.209334 lmp.py:376]   Expert 44 |    139 | CPU
DEBUG 01-05 09:59:16.209593.209593 lmp.py:376]   Expert 51 |    146 | CPU
DEBUG 01-05 09:59:16.209329.209329 lmp.py:376]   Expert 30 |    155 | CPU
DEBUG 01-05 09:59:16.209018.209018 lmp.py:376]   Expert 10 |    164 | CPU
DEBUG 01-05 09:59:16.209992.209992 lmp.py:376]   Expert  3 |    166 | CPU
DEBUG 01-05 09:59:16.209489.209489 lmp.py:376]   Expert 16 |    167 | CPU
DEBUG 01-05 09:59:16.209986.209986 lmp.py:376]   Expert 31 |    173 | CPU
DEBUG 01-05 09:59:16.209245.209245 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 09:59:16.209504.209504 lmp.py:376]   Expert 29 |    183 | CPU
DEBUG 01-05 09:59:16.209001.209001 lmp.py:376]   Expert  4 |    186 | GPU
DEBUG 01-05 09:59:16.209975.209975 lmp.py:376]   Expert 50 |    186 | GPU
DEBUG 01-05 09:59:16.209473.209473 lmp.py:376]   Expert 19 |    188 | GPU
DEBUG 01-05 09:59:16.209208.209208 lmp.py:376]   Expert 22 |    192 | GPU
DEBUG 01-05 09:59:16.209467.209467 lmp.py:376]   Expert  1 |    193 | GPU
DEBUG 01-05 09:59:16.209872.209872 lmp.py:376]   Expert 25 |    193 | GPU
DEBUG 01-05 09:59:16.209846.209846 lmp.py:376]   Expert 13 |    194 | GPU
DEBUG 01-05 09:59:16.210581.210581 lmp.py:376]   Expert 17 |    202 | GPU
DEBUG 01-05 09:59:16.210840.210840 lmp.py:376]   Expert 36 |    206 | GPU
DEBUG 01-05 09:59:16.210099.210099 lmp.py:376]   Expert 57 |    207 | GPU
DEBUG 01-05 09:59:16.210596.210596 lmp.py:376]   Expert 62 |    213 | GPU
DEBUG 01-05 09:59:16.210855.210855 lmp.py:376]   Expert 33 |    217 | GPU
DEBUG 01-05 09:59:16.210352.210352 lmp.py:376]   Expert 55 |    232 | GPU
DEBUG 01-05 09:59:16.210611.210611 lmp.py:376]   Expert  5 |    233 | GPU
DEBUG 01-05 09:59:16.210870.210870 lmp.py:376]   Expert  8 |    235 | GPU
DEBUG 01-05 09:59:16.210082.210082 lmp.py:376]   Expert 53 |    237 | GPU
DEBUG 01-05 09:59:16.210294.210294 lmp.py:376]   Expert 26 |    244 | GPU
DEBUG 01-05 09:59:16.210792.210792 lmp.py:376]   Expert  0 |    245 | GPU
DEBUG 01-05 09:59:16.210527.210527 lmp.py:376]   Expert 49 |    246 | GPU
DEBUG 01-05 09:59:16.210786.210786 lmp.py:376]   Expert 41 |    259 | GPU
DEBUG 01-05 09:59:16.210283.210283 lmp.py:376]   Expert 35 |    266 | GPU
DEBUG 01-05 09:59:16.210542.210542 lmp.py:376]   Expert 28 |    270 | GPU
DEBUG 01-05 09:59:16.210278.210278 lmp.py:376]   Expert 37 |    294 | GPU
DEBUG 01-05 09:59:16.210537.210537 lmp.py:376]   Expert 14 |    316 | GPU
DEBUG 01-05 09:59:16.210795.210795 lmp.py:376]   Expert 27 |    338 | GPU
DEBUG 01-05 09:59:16.210531.210531 lmp.py:376]   Expert  2 |    356 | GPU
DEBUG 01-05 09:59:16.210267.210267 lmp.py:376]   Expert 21 |    365 | GPU
DEBUG 01-05 09:59:16.210479.210479 lmp.py:376]   Expert  9 |    373 | GPU
DEBUG 01-05 09:59:16.210215.210215 lmp.py:376]   Expert 60 |    375 | GPU
DEBUG 01-05 09:59:16.210473.210473 lmp.py:376]   Expert 43 |    397 | GPU
DEBUG 01-05 09:59:16.210732.210732 lmp.py:376]   Expert 63 |    455 | GPU
DEBUG 01-05 09:59:16.210229.210229 lmp.py:376]   Expert 20 |    500 | GPU
DEBUG 01-05 09:59:16.210680.210680 lmp.py:377] 
DEBUG 01-05 09:59:16.210680.210680 lmp.py:377]   CPU total tokens: 3675 (29.9%)
DEBUG 01-05 09:59:16.210654.210654 lmp.py:378]   GPU total tokens: 8613 (70.1%)
DEBUG 01-05 09:59:16.210920.210920 cuda_h.py:19] end experts_map_get cost 0.001470327377319336 seconds
DEBUG 01-05 09:59:16.210609.210609 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:16.210200.210200 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:16.210954.210954 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:16.211039.211039 cuda_h.py:19] end allocate_cuda_memory cost 0.0005199909210205078 seconds
DEBUG 01-05 09:59:16.211227.211227 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:16.211698.211698 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:16.211759.211759 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:16.211793.211793 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df017d82-5ea8-4869-8ed4-6fe8e3d45e0d
DEBUG 01-05 09:59:16.211850.211850 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:16.213605.213605 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df017d82-5ea8-4869-8ed4-6fe8e3d45e0d
DEBUG 01-05 09:59:16.214318.214318 cuda_h.py:19] end load_into_gpu_async cost 0.002688169479370117 seconds
DEBUG 01-05 09:59:16.214136.214136 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:16.214693.214693 cuda_h.py:19] end restore_tensors2 cost 0.0005574226379394531 seconds
DEBUG 01-05 09:59:16.214569.214569 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004252195358276367 seconds
DEBUG 01-05 09:59:16.217520.217520 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0069997310638427734 seconds
DEBUG 01-05 09:59:16.217687.217687 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:16.217650.217650 lmp.py:423] 
DEBUG 01-05 09:59:16.217650.217650 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:16.217368.217368 cuda_h.py:19] end cpu_experts_submit cost 0.00012183189392089844 seconds
DEBUG 01-05 09:59:16.217448.217448 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:16.228373.228373 mlpmodule.py:704] group tensors cost 0.01031947135925293 s
DEBUG 01-05 09:59:16.231392.231392 mlpmodule.py:742] pad cost 0.0020411014556884766 s
DEBUG 01-05 09:59:16.231012.231012 mlpmodule.py:748] create cpu tensor cost 6.794929504394531e-05 s
DEBUG 01-05 09:59:16.231109.231109 mlpmodule.py:753] move to cpu cost 5.7220458984375e-05 s
DEBUG 01-05 09:59:16.240612.240612 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:16.241984.241984 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:16.241849.241849 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 09:59:16.241603.241603 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:16.258956.258956 mlpmodule.py:793] group einsum cost 0.026788949966430664 s
DEBUG 01-05 09:59:16.259200.259200 mlpmodule.py:801] cpy2cputensor cost 0.0006990432739257812 s
DEBUG 01-05 09:59:16.264715.264715 cuda_h.py:19] end wait_cetm_experts cost 0.04662775993347168 seconds
DEBUG 01-05 09:59:16.264131.264131 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:16.265669.265669 cuda_h.py:19] end gpu_sexperts cost 0.000598907470703125 seconds
DEBUG 01-05 09:59:16.265419.265419 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:16.265633.265633 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-05 09:59:16.265051.265051 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:16.265714.265714 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df017d82-5ea8-4869-8ed4-6fe8e3d45e0d
INFO 01-05 09:59:16.268734.268734 client.py:127] Model loaded
DEBUG 01-05 09:59:16.268127.268127 cuda_h.py:19] end wait_experts cost 0.003044605255126953 seconds
DEBUG 01-05 09:59:16.268738.268738 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:16.268540.268540 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:16.269612.269612 mlpmodule.py:531] gpu group tensors cost 0.0006670951843261719 s
DEBUG 01-05 09:59:16.271831.271831 mlpmodule.py:564] gpu pad cost 0.0017580986022949219 s
DEBUG 01-05 09:59:16.271593.271593 mlpmodule.py:582] gpu group einsum cost 0.0005204677581787109 s
DEBUG 01-05 09:59:16.275477.275477 mlpmodule.py:611] gpu experts func einsum cost 0.0065343379974365234 s
DEBUG 01-05 09:59:16.275388.275388 cuda_h.py:19] end gpu_experts cost 0.0067369937896728516 seconds
DEBUG 01-05 09:59:16.275709.275709 cuda_h.py:19] end layer_moe_generate_27 cost 0.06721091270446777 seconds
DEBUG 01-05 09:59:16.275046.275046 lmp.py:217] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 09:59:16.275816.275816 cuda_h.py:19] end multi_layer cost 2.0930495262145996 seconds
DEBUG 01-05 09:59:16.275035.275035 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:59:16.276606.276606 mlpmodule.py:662]  experts func einsum cost 0.05826210975646973 s
DEBUG 01-05 09:59:16.278039.278039 cuda_h.py:19] end init_inputs_tokens cost 0.0032291412353515625 seconds
DEBUG 01-05 09:59:16.278505.278505 lmp.py:286] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:59:16.278685.278685 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:59:16.279343.279343 lmp.py:289] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:59:16.279425.279425 cuda_h.py:19] end dense_mlp cost 0.0006937980651855469 seconds
INFO 01-05 09:59:16.280435.280435 lmp.py:522] 
INFO 01-05 09:59:16.280435.280435 lmp.py:522] ============================================================
INFO 01-05 09:59:16.280813.280813 lmp.py:523] Layer 1 Expert Device Distribution:
INFO 01-05 09:59:16.280145.280145 lmp.py:532]   Total experts: 64
INFO 01-05 09:59:16.280564.280564 lmp.py:534]   meta: 32 experts - Expert IDs: [0, 1, 3, 4, 11, 13, 15, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 47, 49, 52, 53, 54, 55, 56, 58, 62]
INFO 01-05 09:59:16.280544.280544 lmp.py:534]   cuda:1: 32 experts - Expert IDs: [2, 5, 6, 7, 8, 9, 10, 12, 14, 16, 19, 20, 23, 24, 26, 34, 35, 36, 40, 42, 43, 44, 45, 46, 48, 50, 51, 57, 59, 60, 61, 63]
INFO 01-05 09:59:16.280995.280995 lmp.py:537] 
INFO 01-05 09:59:16.280995.280995 lmp.py:537]   Detailed Expert Device Map:
INFO 01-05 09:59:16.280307.280307 lmp.py:538]   Expert ID  | Device         
INFO 01-05 09:59:16.280758.280758 lmp.py:539]   ------------------------------
INFO 01-05 09:59:16.280223.280223 lmp.py:542]   0          | meta           
INFO 01-05 09:59:16.280058.280058 lmp.py:542]   1          | meta           
INFO 01-05 09:59:16.280939.280939 lmp.py:542]   2          | cuda:1         
INFO 01-05 09:59:16.280105.280105 lmp.py:542]   3          | meta           
INFO 01-05 09:59:16.280841.280841 lmp.py:542]   4          | meta           
INFO 01-05 09:59:16.280815.280815 lmp.py:542]   5          | cuda:1         
INFO 01-05 09:59:16.280027.280027 lmp.py:542]   6          | cuda:1         
INFO 01-05 09:59:16.280001.280001 lmp.py:542]   7          | cuda:1         
INFO 01-05 09:59:16.280975.280975 lmp.py:542]   8          | cuda:1         
INFO 01-05 09:59:16.280473.280473 lmp.py:542]   9          | cuda:1         
INFO 01-05 09:59:16.280208.280208 lmp.py:542]   10         | cuda:1         
INFO 01-05 09:59:16.280944.280944 lmp.py:542]   11         | meta           
INFO 01-05 09:59:16.280395.280395 lmp.py:542]   12         | cuda:1         
INFO 01-05 09:59:16.280607.280607 lmp.py:542]   13         | meta           
INFO 01-05 09:59:16.280343.280343 lmp.py:542]   14         | cuda:1         
INFO 01-05 09:59:16.280840.280840 lmp.py:542]   15         | meta           
INFO 01-05 09:59:16.280337.280337 lmp.py:542]   16         | cuda:1         
INFO 01-05 09:59:16.280073.280073 lmp.py:542]   17         | meta           
INFO 01-05 09:59:16.280332.280332 lmp.py:542]   18         | meta           
INFO 01-05 09:59:16.280067.280067 lmp.py:542]   19         | cuda:1         
INFO 01-05 09:59:16.280326.280326 lmp.py:542]   20         | cuda:1         
INFO 01-05 09:59:16.280585.280585 lmp.py:542]   21         | meta           
INFO 01-05 09:59:16.280844.280844 lmp.py:542]   22         | meta           
INFO 01-05 09:59:16.280341.280341 lmp.py:542]   23         | cuda:1         
INFO 01-05 09:59:16.280315.280315 lmp.py:542]   24         | cuda:1         
INFO 01-05 09:59:16.280574.280574 lmp.py:542]   25         | meta           
INFO 01-05 09:59:16.280071.280071 lmp.py:542]   26         | cuda:1         
INFO 01-05 09:59:16.280330.280330 lmp.py:542]   27         | meta           
INFO 01-05 09:59:16.280588.280588 lmp.py:542]   28         | meta           
INFO 01-05 09:59:16.280609.280609 lmp.py:542]   29         | meta           
INFO 01-05 09:59:16.280106.280106 lmp.py:542]   30         | meta           
INFO 01-05 09:59:16.280603.280603 lmp.py:542]   31         | meta           
INFO 01-05 09:59:16.280624.280624 lmp.py:542]   32         | meta           
INFO 01-05 09:59:16.280644.280644 lmp.py:542]   33         | meta           
INFO 01-05 09:59:16.280141.280141 lmp.py:542]   34         | cuda:1         
INFO 01-05 09:59:16.280162.280162 lmp.py:542]   35         | cuda:1         
INFO 01-05 09:59:16.280897.280897 lmp.py:542]   36         | cuda:1         
INFO 01-05 09:59:16.280110.280110 lmp.py:542]   37         | meta           
INFO 01-05 09:59:16.280322.280322 lmp.py:542]   38         | meta           
INFO 01-05 09:59:16.281058.281058 lmp.py:542]   39         | meta           
INFO 01-05 09:59:16.281555.281555 lmp.py:542]   40         | cuda:1         
INFO 01-05 09:59:16.281575.281575 lmp.py:542]   41         | meta           
INFO 01-05 09:59:16.281073.281073 lmp.py:542]   42         | cuda:1         
INFO 01-05 09:59:16.281331.281331 lmp.py:542]   43         | cuda:1         
INFO 01-05 09:59:16.281829.281829 lmp.py:542]   44         | cuda:1         
INFO 01-05 09:59:16.281849.281849 lmp.py:542]   45         | cuda:1         
INFO 01-05 09:59:16.281346.281346 lmp.py:542]   46         | cuda:1         
INFO 01-05 09:59:16.281605.281605 lmp.py:542]   47         | meta           
INFO 01-05 09:59:16.281864.281864 lmp.py:542]   48         | cuda:1         
INFO 01-05 09:59:16.281361.281361 lmp.py:542]   49         | meta           
INFO 01-05 09:59:16.281050.281050 lmp.py:542]   50         | cuda:1         
INFO 01-05 09:59:16.281263.281263 lmp.py:542]   51         | cuda:1         
INFO 01-05 09:59:16.281760.281760 lmp.py:542]   52         | meta           
INFO 01-05 09:59:16.281257.281257 lmp.py:542]   53         | meta           
INFO 01-05 09:59:16.281754.281754 lmp.py:542]   54         | meta           
INFO 01-05 09:59:16.281775.281775 lmp.py:542]   55         | meta           
INFO 01-05 09:59:16.281033.281033 lmp.py:542]   56         | meta           
INFO 01-05 09:59:16.281531.281531 lmp.py:542]   57         | cuda:1         
INFO 01-05 09:59:16.281551.281551 lmp.py:542]   58         | meta           
INFO 01-05 09:59:16.281810.281810 lmp.py:542]   59         | cuda:1         
INFO 01-05 09:59:16.281784.281784 lmp.py:542]   60         | cuda:1         
INFO 01-05 09:59:16.281235.281235 lmp.py:542]   61         | cuda:1         
INFO 01-05 09:59:16.281732.281732 lmp.py:542]   62         | meta           
INFO 01-05 09:59:16.281991.281991 lmp.py:542]   63         | cuda:1         
INFO 01-05 09:59:16.281773.281773 lmp.py:543] ============================================================
INFO 01-05 09:59:16.281773.281773 lmp.py:543] 
DEBUG 01-05 09:59:16.281700.281700 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 09:59:16.281119.281119 cuda_h.py:10] start gate
DEBUG 01-05 09:59:16.282376.282376 cuda_h.py:19] end gate cost 0.000545501708984375 seconds
DEBUG 01-05 09:59:16.282113.282113 cuda_h.py:10] start experts_map_get
INFO 01-05 09:59:16.282314.282314 lmp.py:607] 
INFO 01-05 09:59:16.282314.282314 lmp.py:607] Layer 1 Expert Device Distribution:
INFO 01-05 09:59:16.282553.282553 lmp.py:608]   Active experts: 47 (out of 64 total)
INFO 01-05 09:59:16.282495.282495 lmp.py:609]   CPU experts: 23 (49%) - Expert IDs: [0, 1, 2, 8, 9, 10, 12, 16, 17, 19, 22, 28, 30, 36, 41, 45, 47, 49, 50, 52, 53, 56, 60]
INFO 01-05 09:59:16.282052.282052 lmp.py:610]   GPU experts: 24 (51%) - Expert IDs: [4, 5, 6, 7, 11, 14, 15, 20, 23, 24, 26, 31, 33, 34, 35, 40, 42, 43, 44, 46, 57, 59, 61, 63]
INFO 01-05 09:59:16.282079.282079 lmp.py:611]   CPU tokens: 44 (22.9%)
INFO 01-05 09:59:16.282722.282722 lmp.py:612]   GPU tokens: 148 (77.1%)
INFO 01-05 09:59:16.282934.282934 lmp.py:613] 
INFO 01-05 09:59:16.282934.282934 lmp.py:613]   Detailed Expert Distribution:
INFO 01-05 09:59:16.282054.282054 lmp.py:614]   Expert ID  | Tokens     | Device       | Token %   
INFO 01-05 09:59:16.282982.282982 lmp.py:615]   --------------------------------------------------
INFO 01-05 09:59:16.282055.282055 lmp.py:619]   17         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282937.282937 lmp.py:619]   19         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282341.282341 lmp.py:619]   22         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282746.282746 lmp.py:619]   28         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282150.282150 lmp.py:619]   36         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282985.282985 lmp.py:619]   49         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282390.282390 lmp.py:619]   50         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282556.282556 lmp.py:619]   56         | 1          | CPU          |   0.52%
INFO 01-05 09:59:16.282961.282961 lmp.py:619]   12         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282127.282127 lmp.py:619]   16         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282531.282531 lmp.py:619]   30         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282936.282936 lmp.py:619]   41         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282625.282625 lmp.py:619]   45         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282791.282791 lmp.py:619]   47         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282957.282957 lmp.py:619]   52         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282885.282885 lmp.py:619]   53         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282574.282574 lmp.py:619]   60         | 2          | CPU          |   1.04%
INFO 01-05 09:59:16.282741.282741 lmp.py:619]   0          | 3          | CPU          |   1.56%
INFO 01-05 09:59:16.282099.282099 lmp.py:619]   1          | 3          | CPU          |   1.56%
INFO 01-05 09:59:16.282696.282696 lmp.py:619]   2          | 3          | CPU          |   1.56%
INFO 01-05 09:59:16.282623.282623 lmp.py:619]   8          | 3          | CPU          |   1.56%
INFO 01-05 09:59:16.282551.282551 lmp.py:619]   9          | 3          | CPU          |   1.56%
INFO 01-05 09:59:16.282717.282717 lmp.py:619]   10         | 3          | CPU          |   1.56%
INFO 01-05 09:59:16.282598.282598 lmp.py:619]   40         | 3          | GPU(cuda:1)  |   1.56%
INFO 01-05 09:59:16.282480.282480 lmp.py:619]   43         | 3          | GPU(cuda:1)  |   1.56%
INFO 01-05 09:59:16.282884.282884 lmp.py:619]   4          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.282812.282812 lmp.py:619]   7          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.282694.282694 lmp.py:619]   11         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.283575.283575 lmp.py:619]   35         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.283695.283695 lmp.py:619]   42         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.283861.283861 lmp.py:619]   44         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.283265.283265 lmp.py:619]   59         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:16.283193.283193 lmp.py:619]   5          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:16.283359.283359 lmp.py:619]   26         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:16.283525.283525 lmp.py:619]   33         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:16.283453.283453 lmp.py:619]   46         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:16.283381.283381 lmp.py:619]   61         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:16.283978.283978 lmp.py:619]   23         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:16.283336.283336 lmp.py:619]   63         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:16.283992.283992 lmp.py:619]   6          | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:59:16.283682.283682 lmp.py:619]   15         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:59:16.283371.283371 lmp.py:619]   24         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:59:16.283822.283822 lmp.py:619]   34         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:59:16.283511.283511 lmp.py:619]   14         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:59:16.283200.283200 lmp.py:619]   20         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:59:16.283128.283128 lmp.py:619]   31         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:59:16.283010.283010 lmp.py:619]   57         | 15         | GPU(cuda:1)  |   7.81%
INFO 01-05 09:59:16.283984.283984 lmp.py:620] ============================================================
INFO 01-05 09:59:16.283984.283984 lmp.py:620] 
DEBUG 01-05 09:59:16.283964.283964 cuda_h.py:19] end experts_map_get cost 0.0012669563293457031 seconds
DEBUG 01-05 09:59:16.283753.283753 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.001950979232788086 seconds
DEBUG 01-05 09:59:17.455462.455462 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09205007553100586 s
DEBUG 01-05 09:59:17.792918.792918 cuda_h.py:19] end generate_input_ids cost 0.3354990482330322 seconds
DEBUG 01-05 09:59:17.792971.792971 cuda_h.py:10] start init_cache
DEBUG 01-05 09:59:17.792551.792551 cuda_h.py:19] end init_cache cost 7.152557373046875e-05 seconds
DEBUG 01-05 09:59:20.207739.207739 cuda_h.py:10] start init_weights
DEBUG 01-05 09:59:20.208092.208092 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:20.208708.208708 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:20.210984.210984 cuda_h.py:19] end allocate_cuda_memory cost 0.002094745635986328 seconds
DEBUG 01-05 09:59:20.211642.211642 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:20.211968.211968 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:20.211519.211519 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:20.211791.211791 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1d0851f4-3844-49eb-91a5-8e3c8c74d6a0
DEBUG 01-05 09:59:20.211000.211000 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:20.212567.212567 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1d0851f4-3844-49eb-91a5-8e3c8c74d6a0
DEBUG 01-05 09:59:20.212512.212512 cuda_h.py:19] end load_into_gpu_async cost 0.0016126632690429688 seconds
DEBUG 01-05 09:59:20.212369.212369 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:20.212375.212375 cuda_h.py:19] end restore_tensors2 cost 9.775161743164062e-05 seconds
DEBUG 01-05 09:59:20.212409.212409 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004148721694946289 seconds
INFO 01-05 09:59:20.213362.213362 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1d0851f4-3844-49eb-91a5-8e3c8c74d6a0
INFO 01-05 09:59:20.292516.292516 client.py:127] Model loaded
DEBUG 01-05 09:59:20.292203.292203 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 09:59:20.292169.292169 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:20.292325.292325 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:20.292585.292585 cuda_h.py:19] end allocate_cuda_memory cost 0.0003478527069091797 seconds
DEBUG 01-05 09:59:20.293728.293728 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:20.293698.293698 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:20.293112.293112 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:20.293538.293538 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5a903160-ac92-4c30-a4de-c30b0efe2925
DEBUG 01-05 09:59:20.293338.293338 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:20.295934.295934 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5a903160-ac92-4c30-a4de-c30b0efe2925
DEBUG 01-05 09:59:20.295482.295482 cuda_h.py:19] end load_into_gpu_async cost 0.0020437240600585938 seconds
DEBUG 01-05 09:59:20.295167.295167 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:20.295975.295975 cuda_h.py:19] end restore_tensors2 cost 0.0001308917999267578 seconds
DEBUG 01-05 09:59:20.295190.295190 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031280517578125 seconds
INFO 01-05 09:59:20.295908.295908 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5a903160-ac92-4c30-a4de-c30b0efe2925
INFO 01-05 09:59:20.312196.312196 client.py:127] Model loaded
DEBUG 01-05 09:59:20.313673.313673 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02084970474243164 seconds
DEBUG 01-05 09:59:20.313366.313366 cuda_h.py:19] end init_weights cost 0.10471463203430176 seconds
DEBUG 01-05 09:59:20.313422.313422 cuda_h.py:10] start copy_emodel
DEBUG 01-05 09:59:21.074328.074328 cuda_h.py:19] end copy_emodel cost 0.7613451480865479 seconds
DEBUG 01-05 09:59:21.075000.075000 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:59:21.076879.076879 cuda_h.py:19] end init_inputs_tokens cost 0.0002903938293457031 seconds
DEBUG 01-05 09:59:21.076172.076172 cuda_h.py:10] start multi_layer
DEBUG 01-05 09:59:21.076504.076504 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 09:59:21.076054.076054 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:21.076658.076658 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:21.076739.076739 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.3855438232421875e-05 seconds
DEBUG 01-05 09:59:21.076555.076555 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.915496826171875e-05 seconds
DEBUG 01-05 09:59:21.076436.076436 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.076334.076334 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.076930.076930 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.076627.076627 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.077797.077797 cuda_h.py:19] end allocate_cuda_memory cost 0.00029659271240234375 seconds
DEBUG 01-05 09:59:21.077115.077115 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.077646.077646 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.077807.077807 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.077086.077086 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1e2c5193-c785-4c90-8009-b424398037b3
DEBUG 01-05 09:59:21.077175.077175 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.077291.077291 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.079186.079186 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1e2c5193-c785-4c90-8009-b424398037b3
DEBUG 01-05 09:59:21.079566.079566 cuda_h.py:19] end load_into_gpu_async cost 0.0019409656524658203 seconds
DEBUG 01-05 09:59:21.079659.079659 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.079074.079074 cuda_h.py:19] end restore_tensors2 cost 9.72747802734375e-05 seconds
DEBUG 01-05 09:59:21.079315.079315 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027704238891601562 seconds
INFO 01-05 09:59:21.080111.080111 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1e2c5193-c785-4c90-8009-b424398037b3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.082385.082385 cuda_h.py:19] end self_attn cost 0.004918575286865234 seconds
DEBUG 01-05 09:59:21.083628.083628 cuda_h.py:19] end iln_self_attn_paln cost 0.0065457820892333984 seconds
DEBUG 01-05 09:59:21.083120.083120 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:59:21.083260.083260 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:59:21.083420.083420 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 2.09808349609375e-05 seconds
DEBUG 01-05 09:59:21.084797.084797 cuda_h.py:19] end dense_mlp cost 0.0010263919830322266 seconds
DEBUG 01-05 09:59:21.084860.084860 lmp.py:217] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 09:59:21.084285.084285 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 09:59:21.084266.084266 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:59:21.084684.084684 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:59:21.084453.084453 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.5974044799804688e-05 seconds
DEBUG 01-05 09:59:21.084309.084309 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.363059997558594e-05 seconds
DEBUG 01-05 09:59:21.084621.084621 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.084873.084873 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-05 09:59:21.088593.088593 client.py:127] Model loaded
DEBUG 01-05 09:59:21.088371.088371 cuda_h.py:19] end sllm_worker_task cost 0.01160120964050293 seconds
DEBUG 01-05 09:59:21.088876.088876 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.088792.088792 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.088741.088741 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.088312.088312 cuda_h.py:19] end allocate_cuda_memory cost 0.00019812583923339844 seconds
DEBUG 01-05 09:59:21.088719.088719 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.088350.088350 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.088848.088848 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.088134.088134 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2e28faab-6f14-4355-a675-a42936756b82
DEBUG 01-05 09:59:21.088402.088402 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.089858.089858 cuda_h.py:19] end self_attn cost 0.004640102386474609 seconds
DEBUG 01-05 09:59:21.089199.089199 cuda_h.py:19] end iln_self_attn_paln cost 0.005173921585083008 seconds
DEBUG 01-05 09:59:21.089942.089942 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 09:59:21.089420.089420 cuda_h.py:10] start gate
INFO 01-05 09:59:21.090306.090306 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2e28faab-6f14-4355-a675-a42936756b82
DEBUG 01-05 09:59:21.090018.090018 cuda_h.py:19] end load_into_gpu_async cost 0.0015742778778076172 seconds
DEBUG 01-05 09:59:21.090047.090047 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.090517.090517 cuda_h.py:19] end restore_tensors2 cost 9.012222290039062e-05 seconds
DEBUG 01-05 09:59:21.090017.090017 cuda_h.py:19] end gate cost 0.0009622573852539062 seconds
DEBUG 01-05 09:59:21.090416.090416 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023806095123291016 seconds
DEBUG 01-05 09:59:21.090550.090550 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.091821.091821 lmp.py:365] 
DEBUG 01-05 09:59:21.091821.091821 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.091677.091677 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.091234.091234 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.091453.091453 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.091334.091334 lmp.py:369] 
DEBUG 01-05 09:59:21.091334.091334 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.091454.091454 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.091819.091819 lmp.py:376]   Expert 62 |     66 | CPU
DEBUG 01-05 09:59:21.091416.091416 lmp.py:376]   Expert 18 |     68 | CPU
DEBUG 01-05 09:59:21.091059.091059 lmp.py:376]   Expert 22 |     73 | CPU
DEBUG 01-05 09:59:21.091940.091940 lmp.py:376]   Expert 32 |     83 | CPU
DEBUG 01-05 09:59:21.091345.091345 lmp.py:376]   Expert 52 |     94 | CPU
DEBUG 01-05 09:59:21.091749.091749 lmp.py:376]   Expert  3 |    104 | CPU
DEBUG 01-05 09:59:21.091916.091916 lmp.py:376]   Expert 27 |    114 | CPU
DEBUG 01-05 09:59:21.091320.091320 lmp.py:376]   Expert 38 |    114 | CPU
DEBUG 01-05 09:59:21.091440.091440 lmp.py:376]   Expert 13 |    118 | CPU
DEBUG 01-05 09:59:21.091798.091798 lmp.py:376]   Expert 54 |    118 | CPU
DEBUG 01-05 09:59:21.091203.091203 lmp.py:376]   Expert 17 |    121 | CPU
DEBUG 01-05 09:59:21.091846.091846 lmp.py:376]   Expert 11 |    124 | CPU
DEBUG 01-05 09:59:21.091535.091535 lmp.py:376]   Expert 28 |    124 | CPU
DEBUG 01-05 09:59:21.091940.091940 lmp.py:376]   Expert 37 |    125 | CPU
DEBUG 01-05 09:59:21.091106.091106 lmp.py:376]   Expert 58 |    129 | CPU
DEBUG 01-05 09:59:21.091272.091272 lmp.py:376]   Expert 39 |    131 | CPU
DEBUG 01-05 09:59:21.091961.091961 lmp.py:376]   Expert 25 |    135 | CPU
DEBUG 01-05 09:59:21.091127.091127 lmp.py:376]   Expert 41 |    136 | CPU
DEBUG 01-05 09:59:21.091817.091817 lmp.py:376]   Expert 21 |    150 | CPU
DEBUG 01-05 09:59:21.091744.091744 lmp.py:376]   Expert  4 |    151 | CPU
DEBUG 01-05 09:59:21.091672.091672 lmp.py:376]   Expert 30 |    152 | CPU
DEBUG 01-05 09:59:21.091553.091553 lmp.py:376]   Expert 29 |    155 | CPU
DEBUG 01-05 09:59:21.091435.091435 lmp.py:376]   Expert 53 |    155 | CPU
DEBUG 01-05 09:59:21.091601.091601 lmp.py:376]   Expert 49 |    156 | CPU
DEBUG 01-05 09:59:21.091290.091290 lmp.py:376]   Expert 47 |    157 | CPU
DEBUG 01-05 09:59:21.091741.091741 lmp.py:376]   Expert 31 |    168 | CPU
DEBUG 01-05 09:59:21.091430.091430 lmp.py:376]   Expert 33 |    168 | CPU
DEBUG 01-05 09:59:21.091358.091358 lmp.py:376]   Expert 55 |    173 | CPU
DEBUG 01-05 09:59:21.091286.091286 lmp.py:376]   Expert 56 |    173 | CPU
DEBUG 01-05 09:59:21.091975.091975 lmp.py:376]   Expert 15 |    177 | CPU
DEBUG 01-05 09:59:21.091426.091426 lmp.py:376]   Expert  0 |    178 | CPU
DEBUG 01-05 09:59:21.091115.091115 lmp.py:376]   Expert  1 |    178 | CPU
DEBUG 01-05 09:59:21.091043.091043 lmp.py:376]   Expert 24 |    180 | GPU
DEBUG 01-05 09:59:21.091401.091401 lmp.py:376]   Expert 50 |    182 | GPU
DEBUG 01-05 09:59:21.091760.091760 lmp.py:376]   Expert 51 |    184 | GPU
DEBUG 01-05 09:59:21.091879.091879 lmp.py:376]   Expert 19 |    185 | GPU
DEBUG 01-05 09:59:21.091807.091807 lmp.py:376]   Expert  6 |    186 | GPU
DEBUG 01-05 09:59:21.091496.091496 lmp.py:376]   Expert 10 |    189 | GPU
DEBUG 01-05 09:59:21.091709.091709 lmp.py:376]   Expert 34 |    191 | GPU
DEBUG 01-05 09:59:21.092398.092398 lmp.py:376]   Expert  2 |    195 | GPU
DEBUG 01-05 09:59:21.092849.092849 lmp.py:376]   Expert 45 |    195 | GPU
DEBUG 01-05 09:59:21.092538.092538 lmp.py:376]   Expert 35 |    197 | GPU
DEBUG 01-05 09:59:21.092989.092989 lmp.py:376]   Expert 36 |    198 | GPU
DEBUG 01-05 09:59:21.092440.092440 lmp.py:376]   Expert 61 |    209 | GPU
DEBUG 01-05 09:59:21.092129.092129 lmp.py:376]   Expert 44 |    214 | GPU
DEBUG 01-05 09:59:21.092488.092488 lmp.py:376]   Expert 12 |    223 | GPU
DEBUG 01-05 09:59:21.092607.092607 lmp.py:376]   Expert  5 |    227 | GPU
DEBUG 01-05 09:59:21.092442.092442 lmp.py:376]   Expert 23 |    235 | GPU
DEBUG 01-05 09:59:21.092370.092370 lmp.py:376]   Expert 60 |    235 | GPU
DEBUG 01-05 09:59:21.092583.092583 lmp.py:376]   Expert 43 |    239 | GPU
DEBUG 01-05 09:59:21.092272.092272 lmp.py:376]   Expert  9 |    246 | GPU
DEBUG 01-05 09:59:21.092723.092723 lmp.py:376]   Expert 48 |    252 | GPU
DEBUG 01-05 09:59:21.092412.092412 lmp.py:376]   Expert  8 |    262 | GPU
DEBUG 01-05 09:59:21.092101.092101 lmp.py:376]   Expert 20 |    273 | GPU
DEBUG 01-05 09:59:21.092552.092552 lmp.py:376]   Expert 26 |    285 | GPU
DEBUG 01-05 09:59:21.092480.092480 lmp.py:376]   Expert 57 |    292 | GPU
DEBUG 01-05 09:59:21.092169.092169 lmp.py:376]   Expert  7 |    308 | GPU
DEBUG 01-05 09:59:21.092859.092859 lmp.py:376]   Expert 59 |    308 | GPU
DEBUG 01-05 09:59:21.092455.092455 lmp.py:376]   Expert 16 |    310 | GPU
DEBUG 01-05 09:59:21.092575.092575 lmp.py:376]   Expert 63 |    313 | GPU
DEBUG 01-05 09:59:21.092264.092264 lmp.py:376]   Expert 40 |    320 | GPU
DEBUG 01-05 09:59:21.092583.092583 lmp.py:376]   Expert 46 |    320 | GPU
DEBUG 01-05 09:59:21.092226.092226 lmp.py:376]   Expert 42 |    342 | GPU
DEBUG 01-05 09:59:21.092915.092915 lmp.py:376]   Expert 14 |    525 | GPU
DEBUG 01-05 09:59:21.092320.092320 lmp.py:377] 
DEBUG 01-05 09:59:21.092320.092320 lmp.py:377]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 09:59:21.092724.092724 lmp.py:378]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 09:59:21.092136.092136 cuda_h.py:19] end experts_map_get cost 0.001561880111694336 seconds
DEBUG 01-05 09:59:21.092256.092256 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.092463.092463 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.092778.092778 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.093828.093828 cuda_h.py:19] end allocate_cuda_memory cost 0.0010569095611572266 seconds
DEBUG 01-05 09:59:21.093194.093194 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.093758.093758 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.093805.093805 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.093694.093694 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6c5246f7-c01e-4a79-8c7f-9927e299b963
DEBUG 01-05 09:59:21.094165.094165 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.094958.094958 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2e28faab-6f14-4355-a675-a42936756b82
INFO 01-05 09:59:21.095239.095239 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6c5246f7-c01e-4a79-8c7f-9927e299b963
DEBUG 01-05 09:59:21.096897.096897 cuda_h.py:19] end load_into_gpu_async cost 0.0021648406982421875 seconds
DEBUG 01-05 09:59:21.096600.096600 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.096891.096891 cuda_h.py:19] end restore_tensors2 cost 0.0003631114959716797 seconds
DEBUG 01-05 09:59:21.096158.096158 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039293766021728516 seconds
INFO 01-05 09:59:21.098104.098104 client.py:127] Model loaded
DEBUG 01-05 09:59:21.099719.099719 cuda_h.py:19] end sllm_worker_task cost 0.010884523391723633 seconds
DEBUG 01-05 09:59:21.099557.099557 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.099115.099115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.099166.099166 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.100107.100107 cuda_h.py:19] end allocate_cuda_memory cost 0.0006344318389892578 seconds
DEBUG 01-05 09:59:21.100710.100710 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.100883.100883 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.100316.100316 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008299827575683594 seconds
DEBUG 01-05 09:59:21.100452.100452 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.101216.101216 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.101703.101703 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 041c4a2d-ead1-4bd7-a9c2-4bcb900f4206
DEBUG 01-05 09:59:21.101211.101211 lmp.py:423] 
DEBUG 01-05 09:59:21.101211.101211 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.101676.101676 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.101495.101495 cuda_h.py:19] end cpu_experts_submit cost 0.0004525184631347656 seconds
DEBUG 01-05 09:59:21.101444.101444 cuda_h.py:10] start wait_cetm_experts
INFO 01-05 09:59:21.117100.117100 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 041c4a2d-ead1-4bd7-a9c2-4bcb900f4206
DEBUG 01-05 09:59:21.118020.118020 mlpmodule.py:704] group tensors cost 0.016062021255493164 s
DEBUG 01-05 09:59:21.119761.119761 cuda_h.py:19] end load_into_gpu_async cost 0.018277883529663086 seconds
DEBUG 01-05 09:59:21.119805.119805 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.119938.119938 cuda_h.py:19] end restore_tensors2 cost 0.0001385211944580078 seconds
DEBUG 01-05 09:59:21.119836.119836 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.020219087600708008 seconds
INFO 01-05 09:59:21.121627.121627 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 041c4a2d-ead1-4bd7-a9c2-4bcb900f4206
DEBUG 01-05 09:59:21.122535.122535 mlpmodule.py:742] pad cost 0.003618478775024414 s
DEBUG 01-05 09:59:21.122023.122023 mlpmodule.py:748] create cpu tensor cost 5.9604644775390625e-05 s
DEBUG 01-05 09:59:21.123967.123967 mlpmodule.py:753] move to cpu cost 4.982948303222656e-05 s
DEBUG 01-05 09:59:21.132478.132478 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.132849.132849 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.132038.132038 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 09:59:21.132645.132645 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.148531.148531 mlpmodule.py:793] group einsum cost 0.025849580764770508 s
DEBUG 01-05 09:59:21.149451.149451 mlpmodule.py:801] cpy2cputensor cost 0.0007352828979492188 s
DEBUG 01-05 09:59:21.154402.154402 cuda_h.py:19] end wait_cetm_experts cost 0.052651166915893555 seconds
DEBUG 01-05 09:59:21.154819.154819 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.155695.155695 cuda_h.py:19] end gpu_sexperts cost 0.0006012916564941406 seconds
DEBUG 01-05 09:59:21.155829.155829 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.155116.155116 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:59:21.155680.155680 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.155867.155867 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6c5246f7-c01e-4a79-8c7f-9927e299b963
INFO 01-05 09:59:21.158149.158149 client.py:127] Model loaded
DEBUG 01-05 09:59:21.159331.159331 cuda_h.py:19] end sllm_worker_task cost 0.05963945388793945 seconds
INFO 01-05 09:59:21.159668.159668 client.py:127] Model loaded
DEBUG 01-05 09:59:21.159624.159624 cuda_h.py:19] end wait_experts cost 0.0042095184326171875 seconds
DEBUG 01-05 09:59:21.159433.159433 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.159427.159427 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.166516.166516 mlpmodule.py:662]  experts func einsum cost 0.06417608261108398 s
DEBUG 01-05 09:59:21.166919.166919 mlpmodule.py:531] gpu group tensors cost 0.0066869258880615234 s
DEBUG 01-05 09:59:21.168123.168123 mlpmodule.py:564] gpu pad cost 0.0016257762908935547 s
DEBUG 01-05 09:59:21.169624.169624 mlpmodule.py:582] gpu group einsum cost 0.0010368824005126953 s
DEBUG 01-05 09:59:21.172614.172614 mlpmodule.py:611] gpu experts func einsum cost 0.012411117553710938 s
DEBUG 01-05 09:59:21.172560.172560 cuda_h.py:19] end gpu_experts cost 0.012662172317504883 seconds
DEBUG 01-05 09:59:21.172464.172464 cuda_h.py:19] end layer_moe_generate_1 cost 0.08279561996459961 seconds
DEBUG 01-05 09:59:21.172510.172510 lmp.py:217] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 09:59:21.172272.172272 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 09:59:21.172445.172445 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:59:21.172532.172532 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:59:21.172130.172130 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 2.7894973754882812e-05 seconds
DEBUG 01-05 09:59:21.172946.172946 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.319450378417969e-05 seconds
DEBUG 01-05 09:59:21.172258.172258 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.172135.172135 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.173887.173887 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.173690.173690 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.173618.173618 cuda_h.py:19] end allocate_cuda_memory cost 0.0001857280731201172 seconds
DEBUG 01-05 09:59:21.173363.173363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.173755.173755 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.173539.173539 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.173679.173679 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ae5b7f3d-6559-4ea6-8913-290360beb674
DEBUG 01-05 09:59:21.173861.173861 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.173729.173729 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.175765.175765 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ae5b7f3d-6559-4ea6-8913-290360beb674
DEBUG 01-05 09:59:21.175045.175045 cuda_h.py:19] end load_into_gpu_async cost 0.0017223358154296875 seconds
DEBUG 01-05 09:59:21.175947.175947 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.175003.175003 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-05 09:59:21.175866.175866 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022933483123779297 seconds
INFO 01-05 09:59:21.175592.175592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ae5b7f3d-6559-4ea6-8913-290360beb674
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.177956.177956 cuda_h.py:19] end self_attn cost 0.003931760787963867 seconds
DEBUG 01-05 09:59:21.178827.178827 cuda_h.py:19] end iln_self_attn_paln cost 0.00530695915222168 seconds
DEBUG 01-05 09:59:21.178386.178386 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 09:59:21.178579.178579 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.179110.179110 cuda_h.py:19] end gate cost 0.0007777214050292969 seconds
DEBUG 01-05 09:59:21.179747.179747 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.179101.179101 lmp.py:365] 
DEBUG 01-05 09:59:21.179101.179101 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.179049.179049 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.179414.179414 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.179918.179918 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.179561.179561 lmp.py:369] 
DEBUG 01-05 09:59:21.179561.179561 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.179158.179158 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.179238.179238 lmp.py:376]   Expert 34 |     41 | CPU
DEBUG 01-05 09:59:21.179597.179597 lmp.py:376]   Expert 36 |     49 | CPU
DEBUG 01-05 09:59:21.179001.179001 lmp.py:376]   Expert 26 |     67 | CPU
DEBUG 01-05 09:59:21.179406.179406 lmp.py:376]   Expert 58 |     67 | CPU
DEBUG 01-05 09:59:21.179049.179049 lmp.py:376]   Expert  3 |     68 | CPU
DEBUG 01-05 09:59:21.179645.179645 lmp.py:376]   Expert  8 |     75 | CPU
DEBUG 01-05 09:59:21.179003.179003 lmp.py:376]   Expert 27 |     78 | CPU
DEBUG 01-05 09:59:21.179170.179170 lmp.py:376]   Expert 29 |     82 | CPU
DEBUG 01-05 09:59:21.179574.179574 lmp.py:376]   Expert  7 |     92 | CPU
DEBUG 01-05 09:59:21.179263.179263 lmp.py:376]   Expert 10 |     94 | CPU
DEBUG 01-05 09:59:21.179191.179191 lmp.py:376]   Expert 21 |    105 | CPU
DEBUG 01-05 09:59:21.179357.179357 lmp.py:376]   Expert 13 |    109 | CPU
DEBUG 01-05 09:59:21.179523.179523 lmp.py:376]   Expert 28 |    113 | CPU
DEBUG 01-05 09:59:21.179928.179928 lmp.py:376]   Expert 19 |    114 | CPU
DEBUG 01-05 09:59:21.179571.179571 lmp.py:376]   Expert 62 |    119 | CPU
DEBUG 01-05 09:59:21.179737.179737 lmp.py:376]   Expert 40 |    139 | CPU
DEBUG 01-05 09:59:21.179142.179142 lmp.py:376]   Expert  5 |    140 | CPU
DEBUG 01-05 09:59:21.179069.179069 lmp.py:376]   Expert 63 |    142 | CPU
DEBUG 01-05 09:59:21.179997.179997 lmp.py:376]   Expert 52 |    145 | CPU
DEBUG 01-05 09:59:21.179163.179163 lmp.py:376]   Expert  9 |    148 | CPU
DEBUG 01-05 09:59:21.179853.179853 lmp.py:376]   Expert 25 |    151 | CPU
DEBUG 01-05 09:59:21.179780.179780 lmp.py:376]   Expert 50 |    151 | CPU
DEBUG 01-05 09:59:21.179470.179470 lmp.py:376]   Expert 49 |    152 | CPU
DEBUG 01-05 09:59:21.179636.179636 lmp.py:376]   Expert 59 |    154 | CPU
DEBUG 01-05 09:59:21.180279.180279 lmp.py:376]   Expert 17 |    157 | CPU
DEBUG 01-05 09:59:21.180206.180206 lmp.py:376]   Expert 33 |    157 | CPU
DEBUG 01-05 09:59:21.180896.180896 lmp.py:376]   Expert 16 |    161 | CPU
DEBUG 01-05 09:59:21.180585.180585 lmp.py:376]   Expert 60 |    167 | CPU
DEBUG 01-05 09:59:21.180513.180513 lmp.py:376]   Expert  1 |    168 | CPU
DEBUG 01-05 09:59:21.180440.180440 lmp.py:376]   Expert 24 |    168 | CPU
DEBUG 01-05 09:59:21.180607.180607 lmp.py:376]   Expert 35 |    170 | CPU
DEBUG 01-05 09:59:21.180250.180250 lmp.py:376]   Expert  0 |    172 | CPU
DEBUG 01-05 09:59:21.180177.180177 lmp.py:376]   Expert 30 |    172 | GPU
DEBUG 01-05 09:59:21.180867.180867 lmp.py:376]   Expert 38 |    175 | GPU
DEBUG 01-05 09:59:21.180794.180794 lmp.py:376]   Expert 44 |    181 | GPU
DEBUG 01-05 09:59:21.180960.180960 lmp.py:376]   Expert 45 |    181 | GPU
DEBUG 01-05 09:59:21.180888.180888 lmp.py:376]   Expert  6 |    186 | GPU
DEBUG 01-05 09:59:21.180531.180531 lmp.py:376]   Expert 31 |    195 | GPU
DEBUG 01-05 09:59:21.180936.180936 lmp.py:376]   Expert 48 |    204 | GPU
DEBUG 01-05 09:59:21.180625.180625 lmp.py:376]   Expert 39 |    224 | GPU
DEBUG 01-05 09:59:21.180314.180314 lmp.py:376]   Expert  4 |    235 | GPU
DEBUG 01-05 09:59:21.180004.180004 lmp.py:376]   Expert 37 |    240 | GPU
DEBUG 01-05 09:59:21.180455.180455 lmp.py:376]   Expert 55 |    242 | GPU
DEBUG 01-05 09:59:21.180382.180382 lmp.py:376]   Expert 14 |    244 | GPU
DEBUG 01-05 09:59:21.180072.180072 lmp.py:376]   Expert 57 |    247 | GPU
DEBUG 01-05 09:59:21.180761.180761 lmp.py:376]   Expert 22 |    248 | GPU
DEBUG 01-05 09:59:21.180033.180033 lmp.py:376]   Expert 51 |    248 | GPU
DEBUG 01-05 09:59:21.180391.180391 lmp.py:376]   Expert  2 |    254 | GPU
DEBUG 01-05 09:59:21.180558.180558 lmp.py:376]   Expert 12 |    254 | GPU
DEBUG 01-05 09:59:21.180485.180485 lmp.py:376]   Expert 41 |    257 | GPU
DEBUG 01-05 09:59:21.180175.180175 lmp.py:376]   Expert 47 |    270 | GPU
DEBUG 01-05 09:59:21.180102.180102 lmp.py:376]   Expert 15 |    273 | GPU
DEBUG 01-05 09:59:21.180030.180030 lmp.py:376]   Expert 20 |    274 | GPU
DEBUG 01-05 09:59:21.180196.180196 lmp.py:376]   Expert 42 |    283 | GPU
DEBUG 01-05 09:59:21.180647.180647 lmp.py:376]   Expert 23 |    286 | GPU
DEBUG 01-05 09:59:21.180575.180575 lmp.py:376]   Expert 53 |    304 | GPU
DEBUG 01-05 09:59:21.180171.180171 lmp.py:376]   Expert 56 |    308 | GPU
DEBUG 01-05 09:59:21.180099.180099 lmp.py:376]   Expert 61 |    312 | GPU
DEBUG 01-05 09:59:21.180550.180550 lmp.py:376]   Expert 54 |    314 | GPU
DEBUG 01-05 09:59:21.180478.180478 lmp.py:376]   Expert 18 |    319 | GPU
DEBUG 01-05 09:59:21.180405.180405 lmp.py:376]   Expert 46 |    326 | GPU
DEBUG 01-05 09:59:21.180333.180333 lmp.py:376]   Expert 32 |    330 | GPU
DEBUG 01-05 09:59:21.180261.180261 lmp.py:376]   Expert 43 |    372 | GPU
DEBUG 01-05 09:59:21.180950.180950 lmp.py:376]   Expert 11 |    415 | GPU
DEBUG 01-05 09:59:21.180308.180308 lmp.py:377] 
DEBUG 01-05 09:59:21.180308.180308 lmp.py:377]   CPU total tokens: 3915 (31.9%)
DEBUG 01-05 09:59:21.180667.180667 lmp.py:378]   GPU total tokens: 8373 (68.1%)
DEBUG 01-05 09:59:21.180800.180800 cuda_h.py:19] end experts_map_get cost 0.0015506744384765625 seconds
DEBUG 01-05 09:59:21.180112.180112 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.180365.180365 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.180211.180211 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.181041.181041 cuda_h.py:19] end allocate_cuda_memory cost 0.0008246898651123047 seconds
DEBUG 01-05 09:59:21.181361.181361 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.181593.181593 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.181356.181356 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.181483.181483 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df63c065-44fb-4fc4-8e83-a6e538cd7c2f
DEBUG 01-05 09:59:21.182780.182780 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.182783.182783 client.py:127] Model loaded
DEBUG 01-05 09:59:21.182236.182236 cuda_h.py:19] end sllm_worker_task cost 0.009458303451538086 seconds
INFO 01-05 09:59:21.183589.183589 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df63c065-44fb-4fc4-8e83-a6e538cd7c2f
DEBUG 01-05 09:59:21.183624.183624 cuda_h.py:19] end load_into_gpu_async cost 0.002091646194458008 seconds
DEBUG 01-05 09:59:21.184896.184896 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.184321.184321 cuda_h.py:19] end restore_tensors2 cost 0.0003914833068847656 seconds
DEBUG 01-05 09:59:21.184356.184356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036563873291015625 seconds
DEBUG 01-05 09:59:21.187172.187172 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006303310394287109 seconds
DEBUG 01-05 09:59:21.187723.187723 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.187487.187487 lmp.py:423] 
DEBUG 01-05 09:59:21.187487.187487 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.187397.187397 cuda_h.py:19] end cpu_experts_submit cost 0.00011849403381347656 seconds
DEBUG 01-05 09:59:21.187815.187815 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.197437.197437 mlpmodule.py:704] group tensors cost 0.009876251220703125 s
DEBUG 01-05 09:59:21.199648.199648 mlpmodule.py:742] pad cost 0.0018579959869384766 s
DEBUG 01-05 09:59:21.200580.200580 mlpmodule.py:748] create cpu tensor cost 5.0067901611328125e-05 s
DEBUG 01-05 09:59:21.200873.200873 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-05 09:59:21.209708.209708 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.209800.209800 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.209253.209253 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 09:59:21.209661.209661 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.227219.227219 mlpmodule.py:793] group einsum cost 0.02723979949951172 s
DEBUG 01-05 09:59:21.228281.228281 mlpmodule.py:801] cpy2cputensor cost 0.0008444786071777344 s
DEBUG 01-05 09:59:21.233345.233345 cuda_h.py:19] end wait_cetm_experts cost 0.04560518264770508 seconds
DEBUG 01-05 09:59:21.233615.233615 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.233371.233371 cuda_h.py:19] end gpu_sexperts cost 0.0005838871002197266 seconds
DEBUG 01-05 09:59:21.233552.233552 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.233932.233932 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:21.233496.233496 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.234444.234444 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df63c065-44fb-4fc4-8e83-a6e538cd7c2f
INFO 01-05 09:59:21.238669.238669 client.py:127] Model loaded
DEBUG 01-05 09:59:21.239135.239135 cuda_h.py:19] end wait_experts cost 0.0050051212310791016 seconds
DEBUG 01-05 09:59:21.239460.239460 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.239024.239024 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.239241.239241 mlpmodule.py:531] gpu group tensors cost 0.00067138671875 s
DEBUG 01-05 09:59:21.242109.242109 mlpmodule.py:564] gpu pad cost 0.002126455307006836 s
DEBUG 01-05 09:59:21.242617.242617 mlpmodule.py:582] gpu group einsum cost 0.0004439353942871094 s
DEBUG 01-05 09:59:21.245018.245018 mlpmodule.py:662]  experts func einsum cost 0.057526588439941406 s
DEBUG 01-05 09:59:21.245911.245911 mlpmodule.py:611] gpu experts func einsum cost 0.006807565689086914 s
DEBUG 01-05 09:59:21.246552.246552 cuda_h.py:19] end gpu_experts cost 0.007061481475830078 seconds
DEBUG 01-05 09:59:21.246952.246952 cuda_h.py:19] end layer_moe_generate_2 cost 0.06790661811828613 seconds
DEBUG 01-05 09:59:21.246064.246064 lmp.py:217] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 09:59:21.246072.246072 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 09:59:21.246815.246815 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:59:21.246332.246332 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:59:21.246076.246076 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 09:59:21.246302.246302 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.008148193359375e-05 seconds
DEBUG 01-05 09:59:21.246091.246091 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.246788.246788 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.246302.246302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.246192.246192 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.247618.247618 cuda_h.py:19] end allocate_cuda_memory cost 0.00024318695068359375 seconds
DEBUG 01-05 09:59:21.247945.247945 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.247416.247416 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.247140.247140 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.247412.247412 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8ade87f9-ae84-4ff6-8f06-dd4c96ae0838
DEBUG 01-05 09:59:21.247812.247812 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.247338.247338 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.248441.248441 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8ade87f9-ae84-4ff6-8f06-dd4c96ae0838
DEBUG 01-05 09:59:21.248323.248323 cuda_h.py:19] end load_into_gpu_async cost 0.0009832382202148438 seconds
DEBUG 01-05 09:59:21.248642.248642 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.248910.248910 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-05 09:59:21.248282.248282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015285015106201172 seconds
INFO 01-05 09:59:21.248671.248671 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8ade87f9-ae84-4ff6-8f06-dd4c96ae0838
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.251188.251188 cuda_h.py:19] end self_attn cost 0.00397181510925293 seconds
DEBUG 01-05 09:59:21.252292.252292 cuda_h.py:19] end iln_self_attn_paln cost 0.0053865909576416016 seconds
DEBUG 01-05 09:59:21.252512.252512 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 09:59:21.252706.252706 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.252284.252284 cuda_h.py:19] end gate cost 0.0006382465362548828 seconds
DEBUG 01-05 09:59:21.252160.252160 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.253780.253780 lmp.py:365] 
DEBUG 01-05 09:59:21.253780.253780 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.253344.253344 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.253517.253517 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.253590.253590 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.253280.253280 lmp.py:369] 
DEBUG 01-05 09:59:21.253280.253280 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.253207.253207 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.253619.253619 lmp.py:376]   Expert 61 |     55 | CPU
DEBUG 01-05 09:59:21.253785.253785 lmp.py:376]   Expert 32 |     66 | CPU
DEBUG 01-05 09:59:21.253236.253236 lmp.py:376]   Expert 15 |     67 | CPU
DEBUG 01-05 09:59:21.253687.253687 lmp.py:376]   Expert  4 |     83 | CPU
DEBUG 01-05 09:59:21.253661.253661 lmp.py:376]   Expert 16 |     87 | CPU
DEBUG 01-05 09:59:21.253873.253873 lmp.py:376]   Expert 59 |     87 | CPU
DEBUG 01-05 09:59:21.253609.253609 lmp.py:376]   Expert 37 |     90 | CPU
DEBUG 01-05 09:59:21.253060.253060 lmp.py:376]   Expert  1 |     93 | CPU
DEBUG 01-05 09:59:21.253180.253180 lmp.py:376]   Expert  6 |    102 | CPU
DEBUG 01-05 09:59:21.253346.253346 lmp.py:376]   Expert 28 |    113 | CPU
DEBUG 01-05 09:59:21.253227.253227 lmp.py:376]   Expert  5 |    116 | CPU
DEBUG 01-05 09:59:21.253108.253108 lmp.py:376]   Expert  7 |    119 | CPU
DEBUG 01-05 09:59:21.253275.253275 lmp.py:376]   Expert  8 |    125 | CPU
DEBUG 01-05 09:59:21.253202.253202 lmp.py:376]   Expert 44 |    129 | CPU
DEBUG 01-05 09:59:21.253130.253130 lmp.py:376]   Expert 36 |    131 | CPU
DEBUG 01-05 09:59:21.253581.253581 lmp.py:376]   Expert 24 |    135 | CPU
DEBUG 01-05 09:59:21.253509.253509 lmp.py:376]   Expert 42 |    135 | CPU
DEBUG 01-05 09:59:21.253436.253436 lmp.py:376]   Expert 52 |    137 | CPU
DEBUG 01-05 09:59:21.253649.253649 lmp.py:376]   Expert 63 |    137 | CPU
DEBUG 01-05 09:59:21.253292.253292 lmp.py:376]   Expert 10 |    142 | CPU
DEBUG 01-05 09:59:21.253696.253696 lmp.py:376]   Expert 38 |    143 | CPU
DEBUG 01-05 09:59:21.253147.253147 lmp.py:376]   Expert 29 |    147 | CPU
DEBUG 01-05 09:59:21.253837.253837 lmp.py:376]   Expert 12 |    149 | CPU
DEBUG 01-05 09:59:21.253287.253287 lmp.py:376]   Expert 49 |    149 | CPU
DEBUG 01-05 09:59:21.253738.253738 lmp.py:376]   Expert 55 |    151 | CPU
DEBUG 01-05 09:59:21.253189.253189 lmp.py:376]   Expert 30 |    158 | CPU
DEBUG 01-05 09:59:21.253878.253878 lmp.py:376]   Expert 23 |    160 | CPU
DEBUG 01-05 09:59:21.253568.253568 lmp.py:376]   Expert 26 |    160 | CPU
DEBUG 01-05 09:59:21.253257.253257 lmp.py:376]   Expert 57 |    167 | CPU
DEBUG 01-05 09:59:21.253946.253946 lmp.py:376]   Expert 56 |    172 | CPU
DEBUG 01-05 09:59:21.253874.253874 lmp.py:376]   Expert 11 |    176 | CPU
DEBUG 01-05 09:59:21.253279.253279 lmp.py:376]   Expert 18 |    176 | CPU
DEBUG 01-05 09:59:21.253206.253206 lmp.py:376]   Expert 58 |    177 | GPU
DEBUG 01-05 09:59:21.253134.253134 lmp.py:376]   Expert 62 |    182 | GPU
DEBUG 01-05 09:59:21.253823.253823 lmp.py:376]   Expert 48 |    189 | GPU
DEBUG 01-05 09:59:21.253513.253513 lmp.py:376]   Expert 47 |    190 | GPU
DEBUG 01-05 09:59:21.253202.253202 lmp.py:376]   Expert 40 |    191 | GPU
DEBUG 01-05 09:59:21.253891.253891 lmp.py:376]   Expert 31 |    193 | GPU
DEBUG 01-05 09:59:21.253342.253342 lmp.py:376]   Expert  2 |    195 | GPU
DEBUG 01-05 09:59:21.253270.253270 lmp.py:376]   Expert 13 |    199 | GPU
DEBUG 01-05 09:59:21.253436.253436 lmp.py:376]   Expert 35 |    199 | GPU
DEBUG 01-05 09:59:21.253887.253887 lmp.py:376]   Expert 20 |    208 | GPU
DEBUG 01-05 09:59:21.253099.253099 lmp.py:376]   Expert 45 |    212 | GPU
DEBUG 01-05 09:59:21.253027.253027 lmp.py:376]   Expert  0 |    218 | GPU
DEBUG 01-05 09:59:21.254716.254716 lmp.py:376]   Expert 39 |    224 | GPU
DEBUG 01-05 09:59:21.254406.254406 lmp.py:376]   Expert 46 |    224 | GPU
DEBUG 01-05 09:59:21.254857.254857 lmp.py:376]   Expert 17 |    227 | GPU
DEBUG 01-05 09:59:21.254069.254069 lmp.py:376]   Expert 22 |    233 | GPU
DEBUG 01-05 09:59:21.254474.254474 lmp.py:376]   Expert 33 |    235 | GPU
DEBUG 01-05 09:59:21.254878.254878 lmp.py:376]   Expert 19 |    239 | GPU
DEBUG 01-05 09:59:21.254567.254567 lmp.py:376]   Expert 51 |    240 | GPU
DEBUG 01-05 09:59:21.254018.254018 lmp.py:376]   Expert 34 |    242 | GPU
DEBUG 01-05 09:59:21.254469.254469 lmp.py:376]   Expert 53 |    256 | GPU
DEBUG 01-05 09:59:21.254158.254158 lmp.py:376]   Expert 27 |    267 | GPU
DEBUG 01-05 09:59:21.254609.254609 lmp.py:376]   Expert  3 |    270 | GPU
DEBUG 01-05 09:59:21.254060.254060 lmp.py:376]   Expert 54 |    289 | GPU
DEBUG 01-05 09:59:21.254750.254750 lmp.py:376]   Expert 50 |    306 | GPU
DEBUG 01-05 09:59:21.254200.254200 lmp.py:376]   Expert 60 |    316 | GPU
DEBUG 01-05 09:59:21.254367.254367 lmp.py:376]   Expert 21 |    329 | GPU
DEBUG 01-05 09:59:21.254294.254294 lmp.py:376]   Expert 14 |    344 | GPU
DEBUG 01-05 09:59:21.254984.254984 lmp.py:376]   Expert 43 |    383 | GPU
DEBUG 01-05 09:59:21.254434.254434 lmp.py:376]   Expert  9 |    393 | GPU
DEBUG 01-05 09:59:21.254885.254885 lmp.py:376]   Expert 41 |    398 | GPU
DEBUG 01-05 09:59:21.254098.254098 lmp.py:376]   Expert 25 |    463 | GPU
DEBUG 01-05 09:59:21.254502.254502 lmp.py:377] 
DEBUG 01-05 09:59:21.254502.254502 lmp.py:377]   CPU total tokens: 4057 (33.0%)
DEBUG 01-05 09:59:21.254145.254145 lmp.py:378]   GPU total tokens: 8231 (67.0%)
DEBUG 01-05 09:59:21.254080.254080 cuda_h.py:19] end experts_map_get cost 0.001527547836303711 seconds
DEBUG 01-05 09:59:21.254961.254961 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.254214.254214 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.254629.254629 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.254788.254788 cuda_h.py:19] end allocate_cuda_memory cost 0.0003662109375 seconds
DEBUG 01-05 09:59:21.255916.255916 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.255195.255195 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.255574.255574 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.255701.255701 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94262057-2b6e-4123-afc7-81b81f6cfdbf
DEBUG 01-05 09:59:21.255859.255859 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.255330.255330 client.py:127] Model loaded
DEBUG 01-05 09:59:21.255233.255233 cuda_h.py:19] end sllm_worker_task cost 0.0088043212890625 seconds
INFO 01-05 09:59:21.256274.256274 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94262057-2b6e-4123-afc7-81b81f6cfdbf
DEBUG 01-05 09:59:21.256209.256209 cuda_h.py:19] end load_into_gpu_async cost 0.0012011528015136719 seconds
DEBUG 01-05 09:59:21.256674.256674 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.256959.256959 cuda_h.py:19] end restore_tensors2 cost 0.0003948211669921875 seconds
DEBUG 01-05 09:59:21.256326.256326 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002305269241333008 seconds
DEBUG 01-05 09:59:21.259585.259585 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004963397979736328 seconds
DEBUG 01-05 09:59:21.259183.259183 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.259544.259544 lmp.py:423] 
DEBUG 01-05 09:59:21.259544.259544 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.259864.259864 cuda_h.py:19] end cpu_experts_submit cost 0.00012254714965820312 seconds
DEBUG 01-05 09:59:21.259851.259851 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.265444.265444 mlpmodule.py:704] group tensors cost 0.0054399967193603516 s
DEBUG 01-05 09:59:21.268744.268744 mlpmodule.py:742] pad cost 0.0023369789123535156 s
DEBUG 01-05 09:59:21.268054.268054 mlpmodule.py:748] create cpu tensor cost 6.914138793945312e-05 s
DEBUG 01-05 09:59:21.268852.268852 mlpmodule.py:753] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-05 09:59:21.277082.277082 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.278558.278558 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.278395.278395 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 09:59:21.278565.278565 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.294762.294762 mlpmodule.py:793] group einsum cost 0.026089906692504883 s
DEBUG 01-05 09:59:21.295774.295774 mlpmodule.py:801] cpy2cputensor cost 0.0007443428039550781 s
DEBUG 01-05 09:59:21.300908.300908 cuda_h.py:19] end wait_cetm_experts cost 0.04059028625488281 seconds
DEBUG 01-05 09:59:21.300577.300577 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.301120.301120 cuda_h.py:19] end gpu_sexperts cost 0.0005710124969482422 seconds
DEBUG 01-05 09:59:21.301486.301486 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.301389.301389 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 09:59:21.301046.301046 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.301709.301709 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94262057-2b6e-4123-afc7-81b81f6cfdbf
INFO 01-05 09:59:21.311263.311263 client.py:127] Model loaded
DEBUG 01-05 09:59:21.311967.311967 cuda_h.py:19] end wait_experts cost 0.010654687881469727 seconds
DEBUG 01-05 09:59:21.311762.311762 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.311485.311485 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.312801.312801 mlpmodule.py:662]  experts func einsum cost 0.05270862579345703 s
DEBUG 01-05 09:59:21.312980.312980 mlpmodule.py:531] gpu group tensors cost 0.0006272792816162109 s
DEBUG 01-05 09:59:21.314932.314932 mlpmodule.py:564] gpu pad cost 0.0014507770538330078 s
DEBUG 01-05 09:59:21.314339.314339 mlpmodule.py:582] gpu group einsum cost 0.00041413307189941406 s
DEBUG 01-05 09:59:21.317462.317462 mlpmodule.py:611] gpu experts func einsum cost 0.005558490753173828 s
DEBUG 01-05 09:59:21.317727.317727 cuda_h.py:19] end gpu_experts cost 0.005822420120239258 seconds
DEBUG 01-05 09:59:21.317485.317485 cuda_h.py:19] end layer_moe_generate_3 cost 0.06582045555114746 seconds
DEBUG 01-05 09:59:21.318876.318876 lmp.py:217] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 09:59:21.318069.318069 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 09:59:21.318050.318050 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:59:21.318660.318660 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:59:21.318927.318927 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:21.318220.318220 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.534027099609375e-05 seconds
DEBUG 01-05 09:59:21.318777.318777 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.318196.318196 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.318465.318465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.318083.318083 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.318070.318070 cuda_h.py:19] end allocate_cuda_memory cost 0.00033783912658691406 seconds
DEBUG 01-05 09:59:21.319947.319947 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.319232.319232 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.319386.319386 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.319182.319182 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc7ec2eb-7337-42e0-bed3-505adc300c55
DEBUG 01-05 09:59:21.319483.319483 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.319913.319913 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.319400.319400 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc7ec2eb-7337-42e0-bed3-505adc300c55
DEBUG 01-05 09:59:21.319806.319806 cuda_h.py:19] end load_into_gpu_async cost 0.0009140968322753906 seconds
DEBUG 01-05 09:59:21.320171.320171 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.320307.320307 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-05 09:59:21.320632.320632 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001583099365234375 seconds
INFO 01-05 09:59:21.320008.320008 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc7ec2eb-7337-42e0-bed3-505adc300c55
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.323002.323002 cuda_h.py:19] end self_attn cost 0.003974199295043945 seconds
DEBUG 01-05 09:59:21.323482.323482 cuda_h.py:19] end iln_self_attn_paln cost 0.005406856536865234 seconds
DEBUG 01-05 09:59:21.323934.323934 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 09:59:21.323074.323074 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.324461.324461 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-05 09:59:21.324191.324191 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.324969.324969 lmp.py:365] 
DEBUG 01-05 09:59:21.324969.324969 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.324771.324771 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.324944.324944 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.324018.324018 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.324137.324137 lmp.py:369] 
DEBUG 01-05 09:59:21.324137.324137 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.324496.324496 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.324384.324384 lmp.py:376]   Expert 13 |     41 | CPU
DEBUG 01-05 09:59:21.324742.324742 lmp.py:376]   Expert 60 |     52 | CPU
DEBUG 01-05 09:59:21.325147.325147 lmp.py:376]   Expert 11 |     60 | CPU
DEBUG 01-05 09:59:21.325074.325074 lmp.py:376]   Expert 56 |     75 | CPU
DEBUG 01-05 09:59:21.325240.325240 lmp.py:376]   Expert 25 |     83 | CPU
DEBUG 01-05 09:59:21.325168.325168 lmp.py:376]   Expert  3 |     85 | CPU
DEBUG 01-05 09:59:21.325096.325096 lmp.py:376]   Expert 26 |     85 | CPU
DEBUG 01-05 09:59:21.325785.325785 lmp.py:376]   Expert 58 |     87 | CPU
DEBUG 01-05 09:59:21.325713.325713 lmp.py:376]   Expert  7 |     88 | CPU
DEBUG 01-05 09:59:21.325641.325641 lmp.py:376]   Expert 36 |     89 | CPU
DEBUG 01-05 09:59:21.325330.325330 lmp.py:376]   Expert 51 |     91 | CPU
DEBUG 01-05 09:59:21.325019.325019 lmp.py:376]   Expert 34 |     93 | CPU
DEBUG 01-05 09:59:21.325709.325709 lmp.py:376]   Expert 48 |     99 | CPU
DEBUG 01-05 09:59:21.325398.325398 lmp.py:376]   Expert 28 |    100 | CPU
DEBUG 01-05 09:59:21.325372.325372 lmp.py:376]   Expert  6 |    102 | CPU
DEBUG 01-05 09:59:21.325823.325823 lmp.py:376]   Expert 45 |    103 | CPU
DEBUG 01-05 09:59:21.325274.325274 lmp.py:376]   Expert 41 |    104 | CPU
DEBUG 01-05 09:59:21.325725.325725 lmp.py:376]   Expert 16 |    106 | CPU
DEBUG 01-05 09:59:21.325705.325705 lmp.py:376]   Expert 33 |    109 | CPU
DEBUG 01-05 09:59:21.325679.325679 lmp.py:376]   Expert 55 |    120 | CPU
DEBUG 01-05 09:59:21.325415.325415 lmp.py:376]   Expert  9 |    124 | CPU
DEBUG 01-05 09:59:21.325912.325912 lmp.py:376]   Expert 24 |    127 | CPU
DEBUG 01-05 09:59:21.325886.325886 lmp.py:376]   Expert 14 |    130 | CPU
DEBUG 01-05 09:59:21.325145.325145 lmp.py:376]   Expert 17 |    130 | CPU
DEBUG 01-05 09:59:21.325881.325881 lmp.py:376]   Expert 18 |    130 | CPU
DEBUG 01-05 09:59:21.325378.325378 lmp.py:376]   Expert 50 |    145 | CPU
DEBUG 01-05 09:59:21.325114.325114 lmp.py:376]   Expert  2 |    148 | CPU
DEBUG 01-05 09:59:21.325088.325088 lmp.py:376]   Expert  4 |    148 | CPU
DEBUG 01-05 09:59:21.325062.325062 lmp.py:376]   Expert 47 |    149 | CPU
DEBUG 01-05 09:59:21.325797.325797 lmp.py:376]   Expert 44 |    156 | CPU
DEBUG 01-05 09:59:21.325294.325294 lmp.py:376]   Expert 22 |    167 | CPU
DEBUG 01-05 09:59:21.325269.325269 lmp.py:376]   Expert 10 |    174 | CPU
DEBUG 01-05 09:59:21.325004.325004 lmp.py:376]   Expert 54 |    177 | GPU
DEBUG 01-05 09:59:21.325740.325740 lmp.py:376]   Expert 31 |    185 | GPU
DEBUG 01-05 09:59:21.325475.325475 lmp.py:376]   Expert 37 |    192 | GPU
DEBUG 01-05 09:59:21.325211.325211 lmp.py:376]   Expert 21 |    195 | GPU
DEBUG 01-05 09:59:21.325708.325708 lmp.py:376]   Expert 40 |    195 | GPU
DEBUG 01-05 09:59:21.325205.325205 lmp.py:376]   Expert 46 |    199 | GPU
DEBUG 01-05 09:59:21.325478.325478 lmp.py:376]   Expert 61 |    201 | GPU
DEBUG 01-05 09:59:21.325260.325260 lmp.py:376]   Expert 15 |    207 | GPU
DEBUG 01-05 09:59:21.325042.325042 lmp.py:376]   Expert 42 |    211 | GPU
DEBUG 01-05 09:59:21.325062.325062 lmp.py:376]   Expert 53 |    211 | GPU
DEBUG 01-05 09:59:21.325844.325844 lmp.py:376]   Expert  8 |    212 | GPU
DEBUG 01-05 09:59:21.325864.325864 lmp.py:376]   Expert 63 |    214 | GPU
DEBUG 01-05 09:59:21.325885.325885 lmp.py:376]   Expert 27 |    222 | GPU
DEBUG 01-05 09:59:21.325905.325905 lmp.py:376]   Expert 29 |    225 | GPU
DEBUG 01-05 09:59:21.325687.325687 lmp.py:376]   Expert 20 |    226 | GPU
DEBUG 01-05 09:59:21.325946.325946 lmp.py:376]   Expert 57 |    235 | GPU
DEBUG 01-05 09:59:21.325966.325966 lmp.py:376]   Expert 32 |    239 | GPU
DEBUG 01-05 09:59:21.325987.325987 lmp.py:376]   Expert 23 |    261 | GPU
DEBUG 01-05 09:59:21.325007.325007 lmp.py:376]   Expert 19 |    267 | GPU
DEBUG 01-05 09:59:21.325789.325789 lmp.py:376]   Expert 38 |    267 | GPU
DEBUG 01-05 09:59:21.325571.325571 lmp.py:376]   Expert  0 |    276 | GPU
DEBUG 01-05 09:59:21.325830.325830 lmp.py:376]   Expert  1 |    281 | GPU
DEBUG 01-05 09:59:21.325612.325612 lmp.py:376]   Expert 12 |    289 | GPU
DEBUG 01-05 09:59:21.325394.325394 lmp.py:376]   Expert 30 |    303 | GPU
DEBUG 01-05 09:59:21.325937.325937 lmp.py:376]   Expert 62 |    303 | GPU
DEBUG 01-05 09:59:21.325958.325958 lmp.py:376]   Expert 49 |    320 | GPU
DEBUG 01-05 09:59:21.325739.325739 lmp.py:376]   Expert 35 |    327 | GPU
DEBUG 01-05 09:59:21.325283.325283 lmp.py:376]   Expert 52 |    396 | GPU
DEBUG 01-05 09:59:21.325065.325065 lmp.py:376]   Expert 39 |    417 | GPU
DEBUG 01-05 09:59:21.325085.325085 lmp.py:376]   Expert  5 |    431 | GPU
DEBUG 01-05 09:59:21.325867.325867 lmp.py:376]   Expert 43 |    479 | GPU
DEBUG 01-05 09:59:21.325411.325411 lmp.py:376]   Expert 59 |    625 | GPU
DEBUG 01-05 09:59:21.325908.325908 lmp.py:377] 
DEBUG 01-05 09:59:21.325908.325908 lmp.py:377]   CPU total tokens: 3500 (28.5%)
DEBUG 01-05 09:59:21.326644.326644 lmp.py:378]   GPU total tokens: 8788 (71.5%)
DEBUG 01-05 09:59:21.326432.326432 cuda_h.py:19] end experts_map_get cost 0.0014514923095703125 seconds
DEBUG 01-05 09:59:21.326168.326168 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.326322.326322 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.326545.326545 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.326237.326237 cuda_h.py:19] end allocate_cuda_memory cost 0.00048041343688964844 seconds
DEBUG 01-05 09:59:21.326663.326663 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.326227.326227 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.326983.326983 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.326726.326726 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dfb221c2-c33c-483f-a373-2c2cf7e78469
DEBUG 01-05 09:59:21.327116.327116 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.327294.327294 client.py:127] Model loaded
DEBUG 01-05 09:59:21.327481.327481 cuda_h.py:19] end sllm_worker_task cost 0.008796453475952148 seconds
INFO 01-05 09:59:21.327145.327145 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dfb221c2-c33c-483f-a373-2c2cf7e78469
DEBUG 01-05 09:59:21.327319.327319 cuda_h.py:19] end load_into_gpu_async cost 0.0011539459228515625 seconds
DEBUG 01-05 09:59:21.327114.327114 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.328141.328141 cuda_h.py:19] end restore_tensors2 cost 0.0003802776336669922 seconds
DEBUG 01-05 09:59:21.328554.328554 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023627281188964844 seconds
DEBUG 01-05 09:59:21.330705.330705 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004935503005981445 seconds
DEBUG 01-05 09:59:21.331541.331541 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.331974.331974 lmp.py:423] 
DEBUG 01-05 09:59:21.331974.331974 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.331956.331956 cuda_h.py:19] end cpu_experts_submit cost 0.00010204315185546875 seconds
DEBUG 01-05 09:59:21.331752.331752 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.337601.337601 mlpmodule.py:704] group tensors cost 0.006555795669555664 s
DEBUG 01-05 09:59:21.341146.341146 mlpmodule.py:742] pad cost 0.002621173858642578 s
DEBUG 01-05 09:59:21.341079.341079 mlpmodule.py:748] create cpu tensor cost 6.246566772460938e-05 s
DEBUG 01-05 09:59:21.341029.341029 mlpmodule.py:753] move to cpu cost 4.410743713378906e-05 s
DEBUG 01-05 09:59:21.351981.351981 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.351696.351696 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.351533.351533 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 09:59:21.351312.351312 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.368910.368910 mlpmodule.py:793] group einsum cost 0.026987075805664062 s
DEBUG 01-05 09:59:21.369987.369987 mlpmodule.py:801] cpy2cputensor cost 0.0007216930389404297 s
DEBUG 01-05 09:59:21.374364.374364 cuda_h.py:19] end wait_cetm_experts cost 0.042929887771606445 seconds
DEBUG 01-05 09:59:21.374727.374727 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.374807.374807 cuda_h.py:19] end gpu_sexperts cost 0.0005781650543212891 seconds
DEBUG 01-05 09:59:21.375035.375035 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.375342.375342 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.4345855712890625e-05 seconds
DEBUG 01-05 09:59:21.375429.375429 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.375616.375616 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dfb221c2-c33c-483f-a373-2c2cf7e78469
INFO 01-05 09:59:21.383741.383741 client.py:127] Model loaded
DEBUG 01-05 09:59:21.383313.383313 cuda_h.py:19] end wait_experts cost 0.00795888900756836 seconds
DEBUG 01-05 09:59:21.383738.383738 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.383163.383163 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.383612.383612 mlpmodule.py:531] gpu group tensors cost 0.0006589889526367188 s
DEBUG 01-05 09:59:21.388978.388978 mlpmodule.py:662]  experts func einsum cost 0.05699324607849121 s
DEBUG 01-05 09:59:21.390502.390502 mlpmodule.py:564] gpu pad cost 0.005958080291748047 s
DEBUG 01-05 09:59:21.391323.391323 mlpmodule.py:582] gpu group einsum cost 0.0008747577667236328 s
DEBUG 01-05 09:59:21.393787.393787 mlpmodule.py:611] gpu experts func einsum cost 0.010658979415893555 s
DEBUG 01-05 09:59:21.394674.394674 cuda_h.py:19] end gpu_experts cost 0.010911941528320312 seconds
DEBUG 01-05 09:59:21.394048.394048 cuda_h.py:19] end layer_moe_generate_4 cost 0.0704202651977539 seconds
DEBUG 01-05 09:59:21.394584.394584 lmp.py:217] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 09:59:21.394015.394015 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 09:59:21.394758.394758 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:59:21.394130.394130 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:59:21.394396.394396 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:21.394597.394597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.677078247070312e-05 seconds
DEBUG 01-05 09:59:21.394624.394624 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.394461.394461 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.394564.394564 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.394004.394004 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.395893.395893 cuda_h.py:19] end allocate_cuda_memory cost 0.00018835067749023438 seconds
DEBUG 01-05 09:59:21.395220.395220 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.395182.395182 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.395118.395118 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.395411.395411 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 540af0f8-f0cf-4005-b1c1-64859888ad09
DEBUG 01-05 09:59:21.395401.395401 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.395227.395227 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.396162.396162 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 540af0f8-f0cf-4005-b1c1-64859888ad09
DEBUG 01-05 09:59:21.396727.396727 cuda_h.py:19] end load_into_gpu_async cost 0.0012426376342773438 seconds
DEBUG 01-05 09:59:21.396722.396722 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.396871.396871 cuda_h.py:19] end restore_tensors2 cost 7.700920104980469e-05 seconds
DEBUG 01-05 09:59:21.396111.396111 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018227100372314453 seconds
INFO 01-05 09:59:21.397671.397671 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 540af0f8-f0cf-4005-b1c1-64859888ad09
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.399464.399464 cuda_h.py:19] end self_attn cost 0.003431081771850586 seconds
DEBUG 01-05 09:59:21.399547.399547 cuda_h.py:19] end iln_self_attn_paln cost 0.004795551300048828 seconds
DEBUG 01-05 09:59:21.399052.399052 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 09:59:21.399007.399007 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.400366.400366 cuda_h.py:19] end gate cost 0.00061798095703125 seconds
DEBUG 01-05 09:59:21.400812.400812 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.400934.400934 lmp.py:365] 
DEBUG 01-05 09:59:21.400934.400934 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.400929.400929 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.400340.400340 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.400891.400891 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.400818.400818 lmp.py:369] 
DEBUG 01-05 09:59:21.400818.400818 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.400269.400269 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.400111.400111 lmp.py:376]   Expert 34 |     23 | CPU
DEBUG 01-05 09:59:21.400708.400708 lmp.py:376]   Expert 39 |     44 | CPU
DEBUG 01-05 09:59:21.400112.400112 lmp.py:376]   Expert 15 |     48 | CPU
DEBUG 01-05 09:59:21.400278.400278 lmp.py:376]   Expert 47 |     51 | CPU
DEBUG 01-05 09:59:21.400729.400729 lmp.py:376]   Expert  2 |     54 | CPU
DEBUG 01-05 09:59:21.400419.400419 lmp.py:376]   Expert 18 |     69 | CPU
DEBUG 01-05 09:59:21.400108.400108 lmp.py:376]   Expert 23 |     86 | CPU
DEBUG 01-05 09:59:21.400036.400036 lmp.py:376]   Expert  3 |     90 | CPU
DEBUG 01-05 09:59:21.400725.400725 lmp.py:376]   Expert 27 |     93 | CPU
DEBUG 01-05 09:59:21.400937.400937 lmp.py:376]   Expert 30 |     99 | CPU
DEBUG 01-05 09:59:21.400388.400388 lmp.py:376]   Expert 17 |    108 | CPU
DEBUG 01-05 09:59:21.400839.400839 lmp.py:376]   Expert 28 |    110 | CPU
DEBUG 01-05 09:59:21.400290.400290 lmp.py:376]   Expert 52 |    110 | CPU
DEBUG 01-05 09:59:21.400502.400502 lmp.py:376]   Expert 45 |    111 | CPU
DEBUG 01-05 09:59:21.400192.400192 lmp.py:376]   Expert  4 |    115 | CPU
DEBUG 01-05 09:59:21.400881.400881 lmp.py:376]   Expert  0 |    120 | CPU
DEBUG 01-05 09:59:21.400093.400093 lmp.py:376]   Expert 22 |    120 | CPU
DEBUG 01-05 09:59:21.400783.400783 lmp.py:376]   Expert 62 |    125 | CPU
DEBUG 01-05 09:59:21.400234.400234 lmp.py:376]   Expert 63 |    125 | CPU
DEBUG 01-05 09:59:21.400400.400400 lmp.py:376]   Expert  8 |    126 | CPU
DEBUG 01-05 09:59:21.401089.401089 lmp.py:376]   Expert 60 |    129 | CPU
DEBUG 01-05 09:59:21.401302.401302 lmp.py:376]   Expert  9 |    133 | CPU
DEBUG 01-05 09:59:21.401752.401752 lmp.py:376]   Expert 14 |    138 | CPU
DEBUG 01-05 09:59:21.401442.401442 lmp.py:376]   Expert 48 |    139 | CPU
DEBUG 01-05 09:59:21.401893.401893 lmp.py:376]   Expert 51 |    144 | CPU
DEBUG 01-05 09:59:21.401105.401105 lmp.py:376]   Expert 54 |    145 | CPU
DEBUG 01-05 09:59:21.401556.401556 lmp.py:376]   Expert 46 |    150 | CPU
DEBUG 01-05 09:59:21.401768.401768 lmp.py:376]   Expert 41 |    152 | CPU
DEBUG 01-05 09:59:21.401742.401742 lmp.py:376]   Expert 10 |    154 | CPU
DEBUG 01-05 09:59:21.401955.401955 lmp.py:376]   Expert 25 |    164 | CPU
DEBUG 01-05 09:59:21.401644.401644 lmp.py:376]   Expert 57 |    164 | CPU
DEBUG 01-05 09:59:21.401618.401618 lmp.py:376]   Expert  1 |    165 | CPU
DEBUG 01-05 09:59:21.401308.401308 lmp.py:376]   Expert 36 |    165 | GPU
DEBUG 01-05 09:59:21.401758.401758 lmp.py:376]   Expert 24 |    170 | GPU
DEBUG 01-05 09:59:21.401971.401971 lmp.py:376]   Expert 43 |    170 | GPU
DEBUG 01-05 09:59:21.401945.401945 lmp.py:376]   Expert 38 |    173 | GPU
DEBUG 01-05 09:59:21.401634.401634 lmp.py:376]   Expert 26 |    180 | GPU
DEBUG 01-05 09:59:21.401324.401324 lmp.py:376]   Expert 32 |    188 | GPU
DEBUG 01-05 09:59:21.401774.401774 lmp.py:376]   Expert 11 |    192 | GPU
DEBUG 01-05 09:59:21.401987.401987 lmp.py:376]   Expert 56 |    195 | GPU
DEBUG 01-05 09:59:21.401391.401391 lmp.py:376]   Expert 16 |    196 | GPU
DEBUG 01-05 09:59:21.401319.401319 lmp.py:376]   Expert 58 |    202 | GPU
DEBUG 01-05 09:59:21.401770.401770 lmp.py:376]   Expert 29 |    204 | GPU
DEBUG 01-05 09:59:21.401983.401983 lmp.py:376]   Expert 12 |    215 | GPU
DEBUG 01-05 09:59:21.401195.401195 lmp.py:376]   Expert 19 |    222 | GPU
DEBUG 01-05 09:59:21.401646.401646 lmp.py:376]   Expert 50 |    222 | GPU
DEBUG 01-05 09:59:21.401097.401097 lmp.py:376]   Expert 55 |    224 | GPU
DEBUG 01-05 09:59:21.401309.401309 lmp.py:376]   Expert 44 |    225 | GPU
DEBUG 01-05 09:59:21.401760.401760 lmp.py:376]   Expert 61 |    230 | GPU
DEBUG 01-05 09:59:21.401449.401449 lmp.py:376]   Expert 42 |    231 | GPU
DEBUG 01-05 09:59:21.401900.401900 lmp.py:376]   Expert  7 |    237 | GPU
DEBUG 01-05 09:59:21.401113.401113 lmp.py:376]   Expert 35 |    242 | GPU
DEBUG 01-05 09:59:21.401564.401564 lmp.py:376]   Expert 59 |    259 | GPU
DEBUG 01-05 09:59:21.401253.401253 lmp.py:376]   Expert 21 |    281 | GPU
DEBUG 01-05 09:59:21.401465.401465 lmp.py:376]   Expert  5 |    286 | GPU
DEBUG 01-05 09:59:21.401678.401678 lmp.py:376]   Expert 20 |    301 | GPU
DEBUG 01-05 09:59:21.401129.401129 lmp.py:376]   Expert 40 |    302 | GPU
DEBUG 01-05 09:59:21.401580.401580 lmp.py:376]   Expert 31 |    326 | GPU
DEBUG 01-05 09:59:21.401554.401554 lmp.py:376]   Expert 13 |    354 | GPU
DEBUG 01-05 09:59:21.401766.401766 lmp.py:376]   Expert 33 |    359 | GPU
DEBUG 01-05 09:59:21.401979.401979 lmp.py:376]   Expert  6 |    380 | GPU
DEBUG 01-05 09:59:21.401145.401145 lmp.py:376]   Expert 49 |    393 | GPU
DEBUG 01-05 09:59:21.401834.401834 lmp.py:376]   Expert 37 |    479 | GPU
DEBUG 01-05 09:59:21.401762.401762 lmp.py:376]   Expert 53 |    881 | GPU
DEBUG 01-05 09:59:21.401166.401166 lmp.py:377] 
DEBUG 01-05 09:59:21.401166.401166 lmp.py:377]   CPU total tokens: 3604 (29.3%)
DEBUG 01-05 09:59:21.401332.401332 lmp.py:378]   GPU total tokens: 8684 (70.7%)
DEBUG 01-05 09:59:21.401267.401267 cuda_h.py:19] end experts_map_get cost 0.0015015602111816406 seconds
DEBUG 01-05 09:59:21.401195.401195 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.401017.401017 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.401909.401909 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.403811.403811 cuda_h.py:19] end allocate_cuda_memory cost 0.0017924308776855469 seconds
DEBUG 01-05 09:59:21.403985.403985 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.403788.403788 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.403835.403835 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.403247.403247 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d048206c-bdec-44b0-8789-70958396acb2
DEBUG 01-05 09:59:21.404597.404597 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.404874.404874 client.py:127] Model loaded
DEBUG 01-05 09:59:21.404373.404373 cuda_h.py:19] end sllm_worker_task cost 0.009727954864501953 seconds
INFO 01-05 09:59:21.409664.409664 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d048206c-bdec-44b0-8789-70958396acb2
DEBUG 01-05 09:59:21.409206.409206 cuda_h.py:19] end load_into_gpu_async cost 0.0053441524505615234 seconds
DEBUG 01-05 09:59:21.409997.409997 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.409253.409253 cuda_h.py:19] end restore_tensors2 cost 0.0004730224609375 seconds
DEBUG 01-05 09:59:21.409719.409719 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008079767227172852 seconds
DEBUG 01-05 09:59:21.412526.412526 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010645151138305664 seconds
DEBUG 01-05 09:59:21.412216.412216 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.412649.412649 lmp.py:423] 
DEBUG 01-05 09:59:21.412649.412649 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.412492.412492 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-05 09:59:21.412195.412195 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.421283.421283 mlpmodule.py:704] group tensors cost 0.008306026458740234 s
DEBUG 01-05 09:59:21.425463.425463 mlpmodule.py:742] pad cost 0.0032918453216552734 s
DEBUG 01-05 09:59:21.425235.425235 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-05 09:59:21.425543.425543 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:59:21.434350.434350 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.435701.435701 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.435975.435975 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 09:59:21.435397.435397 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.452342.452342 mlpmodule.py:793] group einsum cost 0.026555299758911133 s
DEBUG 01-05 09:59:21.453267.453267 mlpmodule.py:801] cpy2cputensor cost 0.0006968975067138672 s
DEBUG 01-05 09:59:21.457552.457552 cuda_h.py:19] end wait_cetm_experts cost 0.04498648643493652 seconds
DEBUG 01-05 09:59:21.457220.457220 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.458015.458015 cuda_h.py:19] end gpu_sexperts cost 0.0005767345428466797 seconds
DEBUG 01-05 09:59:21.458580.458580 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.458298.458298 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:59:21.458385.458385 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.458287.458287 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d048206c-bdec-44b0-8789-70958396acb2
INFO 01-05 09:59:21.465253.465253 client.py:127] Model loaded
DEBUG 01-05 09:59:21.465732.465732 cuda_h.py:19] end wait_experts cost 0.006365776062011719 seconds
DEBUG 01-05 09:59:21.465488.465488 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.465290.465290 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.465957.465957 mlpmodule.py:531] gpu group tensors cost 0.0006525516510009766 s
DEBUG 01-05 09:59:21.468064.468064 mlpmodule.py:564] gpu pad cost 0.002722024917602539 s
DEBUG 01-05 09:59:21.471310.471310 mlpmodule.py:662]  experts func einsum cost 0.05898308753967285 s
DEBUG 01-05 09:59:21.472367.472367 mlpmodule.py:582] gpu group einsum cost 0.004025697708129883 s
DEBUG 01-05 09:59:21.475480.475480 mlpmodule.py:611] gpu experts func einsum cost 0.010517358779907227 s
DEBUG 01-05 09:59:21.475200.475200 cuda_h.py:19] end gpu_experts cost 0.010749101638793945 seconds
DEBUG 01-05 09:59:21.476859.476859 cuda_h.py:19] end layer_moe_generate_5 cost 0.07647514343261719 seconds
DEBUG 01-05 09:59:21.476064.476064 lmp.py:217] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 09:59:21.476356.476356 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 09:59:21.476860.476860 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:59:21.476471.476471 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:59:21.476605.476605 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:21.476965.476965 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 9.751319885253906e-05 seconds
DEBUG 01-05 09:59:21.476091.476091 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.476644.476644 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.476442.476442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.476040.476040 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.476663.476663 cuda_h.py:19] end allocate_cuda_memory cost 0.00017905235290527344 seconds
DEBUG 01-05 09:59:21.476818.476818 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.477104.477104 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.477589.477589 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.477530.477530 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99349174-00b1-4439-9cfb-5433107d44e5
DEBUG 01-05 09:59:21.477115.477115 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.477633.477633 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.478097.478097 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99349174-00b1-4439-9cfb-5433107d44e5
DEBUG 01-05 09:59:21.478695.478695 cuda_h.py:19] end load_into_gpu_async cost 0.0012433528900146484 seconds
DEBUG 01-05 09:59:21.478252.478252 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.478474.478474 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-05 09:59:21.478607.478607 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017387866973876953 seconds
INFO 01-05 09:59:21.478955.478955 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99349174-00b1-4439-9cfb-5433107d44e5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.480486.480486 cuda_h.py:19] end self_attn cost 0.0032355785369873047 seconds
DEBUG 01-05 09:59:21.481913.481913 cuda_h.py:19] end iln_self_attn_paln cost 0.004544973373413086 seconds
DEBUG 01-05 09:59:21.481419.481419 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 09:59:21.481135.481135 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.481899.481899 cuda_h.py:19] end gate cost 0.0006346702575683594 seconds
DEBUG 01-05 09:59:21.481298.481298 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.482321.482321 lmp.py:365] 
DEBUG 01-05 09:59:21.482321.482321 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.482885.482885 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.482581.482581 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.482132.482132 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.482059.482059 lmp.py:369] 
DEBUG 01-05 09:59:21.482059.482059 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.482702.482702 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.482591.482591 lmp.py:376]   Expert  1 |      5 | CPU
DEBUG 01-05 09:59:21.482664.482664 lmp.py:376]   Expert  3 |     29 | CPU
DEBUG 01-05 09:59:21.482307.482307 lmp.py:376]   Expert 14 |     49 | CPU
DEBUG 01-05 09:59:21.482473.482473 lmp.py:376]   Expert 53 |     56 | CPU
DEBUG 01-05 09:59:21.482401.482401 lmp.py:376]   Expert 52 |     57 | CPU
DEBUG 01-05 09:59:21.482090.482090 lmp.py:376]   Expert 35 |     69 | CPU
DEBUG 01-05 09:59:21.482018.482018 lmp.py:376]   Expert 15 |     75 | CPU
DEBUG 01-05 09:59:21.482946.482946 lmp.py:376]   Expert 44 |     76 | CPU
DEBUG 01-05 09:59:21.482635.482635 lmp.py:376]   Expert 10 |     81 | CPU
DEBUG 01-05 09:59:21.482324.482324 lmp.py:376]   Expert 11 |     81 | CPU
DEBUG 01-05 09:59:21.482252.482252 lmp.py:376]   Expert 63 |     87 | CPU
DEBUG 01-05 09:59:21.482180.482180 lmp.py:376]   Expert 26 |    100 | CPU
DEBUG 01-05 09:59:21.482107.482107 lmp.py:376]   Expert 49 |    101 | CPU
DEBUG 01-05 09:59:21.482320.482320 lmp.py:376]   Expert 50 |    107 | CPU
DEBUG 01-05 09:59:21.482009.482009 lmp.py:376]   Expert 37 |    111 | CPU
DEBUG 01-05 09:59:21.482937.482937 lmp.py:376]   Expert 16 |    114 | CPU
DEBUG 01-05 09:59:21.482626.482626 lmp.py:376]   Expert  7 |    115 | CPU
DEBUG 01-05 09:59:21.482269.482269 lmp.py:376]   Expert 34 |    115 | CPU
DEBUG 01-05 09:59:21.482150.482150 lmp.py:376]   Expert 40 |    119 | CPU
DEBUG 01-05 09:59:21.482840.482840 lmp.py:376]   Expert 47 |    120 | CPU
DEBUG 01-05 09:59:21.482768.482768 lmp.py:376]   Expert 22 |    122 | CPU
DEBUG 01-05 09:59:21.482980.482980 lmp.py:376]   Expert 32 |    131 | CPU
DEBUG 01-05 09:59:21.482431.482431 lmp.py:376]   Expert 62 |    131 | CPU
DEBUG 01-05 09:59:21.482120.482120 lmp.py:376]   Expert 28 |    134 | CPU
DEBUG 01-05 09:59:21.482809.482809 lmp.py:376]   Expert 30 |    148 | CPU
DEBUG 01-05 09:59:21.482260.482260 lmp.py:376]   Expert  4 |    149 | CPU
DEBUG 01-05 09:59:21.482950.482950 lmp.py:376]   Expert 41 |    150 | CPU
DEBUG 01-05 09:59:21.482401.482401 lmp.py:376]   Expert 31 |    152 | CPU
DEBUG 01-05 09:59:21.482090.482090 lmp.py:376]   Expert 57 |    155 | CPU
DEBUG 01-05 09:59:21.482256.482256 lmp.py:376]   Expert 58 |    156 | CPU
DEBUG 01-05 09:59:21.482661.482661 lmp.py:376]   Expert 51 |    158 | CPU
DEBUG 01-05 09:59:21.482111.482111 lmp.py:376]   Expert 54 |    171 | CPU
DEBUG 01-05 09:59:21.482801.482801 lmp.py:376]   Expert 25 |    172 | GPU
DEBUG 01-05 09:59:21.482252.482252 lmp.py:376]   Expert 45 |    180 | GPU
DEBUG 01-05 09:59:21.482941.482941 lmp.py:376]   Expert 59 |    182 | GPU
DEBUG 01-05 09:59:21.482869.482869 lmp.py:376]   Expert  9 |    189 | GPU
DEBUG 01-05 09:59:21.482081.482081 lmp.py:376]   Expert 55 |    194 | GPU
DEBUG 01-05 09:59:21.482770.482770 lmp.py:376]   Expert 38 |    195 | GPU
DEBUG 01-05 09:59:21.482460.482460 lmp.py:376]   Expert 21 |    197 | GPU
DEBUG 01-05 09:59:21.482149.482149 lmp.py:376]   Expert  0 |    198 | GPU
DEBUG 01-05 09:59:21.482838.482838 lmp.py:376]   Expert 12 |    209 | GPU
DEBUG 01-05 09:59:21.482051.482051 lmp.py:376]   Expert 29 |    210 | GPU
DEBUG 01-05 09:59:21.482217.482217 lmp.py:376]   Expert 13 |    211 | GPU
DEBUG 01-05 09:59:21.482860.482860 lmp.py:376]   Expert 33 |    213 | GPU
DEBUG 01-05 09:59:21.482549.482549 lmp.py:376]   Expert  5 |    215 | GPU
DEBUG 01-05 09:59:21.483000.483000 lmp.py:376]   Expert 19 |    215 | GPU
DEBUG 01-05 09:59:21.483689.483689 lmp.py:376]   Expert  8 |    217 | GPU
DEBUG 01-05 09:59:21.483902.483902 lmp.py:376]   Expert  6 |    220 | GPU
DEBUG 01-05 09:59:21.483353.483353 lmp.py:376]   Expert 43 |    223 | GPU
DEBUG 01-05 09:59:21.483804.483804 lmp.py:376]   Expert 46 |    223 | GPU
DEBUG 01-05 09:59:21.483016.483016 lmp.py:376]   Expert  2 |    232 | GPU
DEBUG 01-05 09:59:21.483467.483467 lmp.py:376]   Expert 42 |    243 | GPU
DEBUG 01-05 09:59:21.483918.483918 lmp.py:376]   Expert 24 |    247 | GPU
DEBUG 01-05 09:59:21.483845.483845 lmp.py:376]   Expert 17 |    262 | GPU
DEBUG 01-05 09:59:21.483058.483058 lmp.py:376]   Expert 23 |    268 | GPU
DEBUG 01-05 09:59:21.483747.483747 lmp.py:376]   Expert 61 |    284 | GPU
DEBUG 01-05 09:59:21.483960.483960 lmp.py:376]   Expert 27 |    345 | GPU
DEBUG 01-05 09:59:21.483411.483411 lmp.py:376]   Expert 20 |    356 | GPU
DEBUG 01-05 09:59:21.483623.483623 lmp.py:376]   Expert 18 |    381 | GPU
DEBUG 01-05 09:59:21.483074.483074 lmp.py:376]   Expert 48 |    390 | GPU
DEBUG 01-05 09:59:21.483286.483286 lmp.py:376]   Expert 39 |    417 | GPU
DEBUG 01-05 09:59:21.483499.483499 lmp.py:376]   Expert 60 |    476 | GPU
DEBUG 01-05 09:59:21.483427.483427 lmp.py:376]   Expert 56 |    613 | GPU
DEBUG 01-05 09:59:21.483593.483593 lmp.py:376]   Expert 36 |    687 | GPU
DEBUG 01-05 09:59:21.483759.483759 lmp.py:377] 
DEBUG 01-05 09:59:21.483759.483759 lmp.py:377]   CPU total tokens: 3424 (27.9%)
DEBUG 01-05 09:59:21.483163.483163 lmp.py:378]   GPU total tokens: 8864 (72.1%)
DEBUG 01-05 09:59:21.483860.483860 cuda_h.py:19] end experts_map_get cost 0.0015099048614501953 seconds
DEBUG 01-05 09:59:21.483502.483502 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.483471.483471 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.483793.483793 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.485505.485505 cuda_h.py:19] end allocate_cuda_memory cost 0.0018258094787597656 seconds
DEBUG 01-05 09:59:21.485461.485461 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.485740.485740 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.485655.485655 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.485497.485497 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5582ebc7-c5ff-4083-bdc0-06949758f912
DEBUG 01-05 09:59:21.485676.485676 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.485728.485728 client.py:127] Model loaded
DEBUG 01-05 09:59:21.486208.486208 cuda_h.py:19] end sllm_worker_task cost 0.009416580200195312 seconds
INFO 01-05 09:59:21.486559.486559 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5582ebc7-c5ff-4083-bdc0-06949758f912
DEBUG 01-05 09:59:21.486071.486071 cuda_h.py:19] end load_into_gpu_async cost 0.0011897087097167969 seconds
DEBUG 01-05 09:59:21.486489.486489 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.487550.487550 cuda_h.py:19] end restore_tensors2 cost 0.00040411949157714844 seconds
DEBUG 01-05 09:59:21.487770.487770 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037796497344970703 seconds
DEBUG 01-05 09:59:21.489341.489341 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006418943405151367 seconds
DEBUG 01-05 09:59:21.489316.489316 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.489293.489293 lmp.py:423] 
DEBUG 01-05 09:59:21.489293.489293 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.490520.490520 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-05 09:59:21.490408.490408 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.500018.500018 mlpmodule.py:704] group tensors cost 0.009881019592285156 s
DEBUG 01-05 09:59:21.502971.502971 mlpmodule.py:742] pad cost 0.0016355514526367188 s
DEBUG 01-05 09:59:21.502160.502160 mlpmodule.py:748] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-05 09:59:21.502679.502679 mlpmodule.py:753] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-05 09:59:21.512676.512676 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.512948.512948 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.512070.512070 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 09:59:21.512955.512955 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.529542.529542 mlpmodule.py:793] group einsum cost 0.026502609252929688 s
DEBUG 01-05 09:59:21.530792.530792 mlpmodule.py:801] cpy2cputensor cost 0.0007088184356689453 s
DEBUG 01-05 09:59:21.534758.534758 cuda_h.py:19] end wait_cetm_experts cost 0.04459810256958008 seconds
DEBUG 01-05 09:59:21.534797.534797 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.535824.535824 cuda_h.py:19] end gpu_sexperts cost 0.0005733966827392578 seconds
DEBUG 01-05 09:59:21.535436.535436 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.535153.535153 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.314018249511719e-05 seconds
DEBUG 01-05 09:59:21.535240.535240 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.535665.535665 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5582ebc7-c5ff-4083-bdc0-06949758f912
INFO 01-05 09:59:21.542006.542006 client.py:127] Model loaded
DEBUG 01-05 09:59:21.542624.542624 cuda_h.py:19] end wait_experts cost 0.006888628005981445 seconds
DEBUG 01-05 09:59:21.542142.542142 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.542852.542852 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.543711.543711 mlpmodule.py:531] gpu group tensors cost 0.0006520748138427734 s
DEBUG 01-05 09:59:21.545929.545929 mlpmodule.py:564] gpu pad cost 0.001722097396850586 s
DEBUG 01-05 09:59:21.545274.545274 mlpmodule.py:582] gpu group einsum cost 0.0005381107330322266 s
DEBUG 01-05 09:59:21.548071.548071 mlpmodule.py:662]  experts func einsum cost 0.058585405349731445 s
DEBUG 01-05 09:59:21.549447.549447 mlpmodule.py:611] gpu experts func einsum cost 0.006801605224609375 s
DEBUG 01-05 09:59:21.549379.549379 cuda_h.py:19] end gpu_experts cost 0.007062435150146484 seconds
DEBUG 01-05 09:59:21.549111.549111 cuda_h.py:19] end layer_moe_generate_6 cost 0.06870174407958984 seconds
DEBUG 01-05 09:59:21.549223.549223 lmp.py:217] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 09:59:21.550085.550085 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 09:59:21.550828.550828 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:59:21.550868.550868 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:59:21.550711.550711 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.361701965332031e-05 seconds
DEBUG 01-05 09:59:21.550673.550673 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 8.0108642578125e-05 seconds
DEBUG 01-05 09:59:21.550793.550793 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.550934.550934 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.550157.550157 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.550093.550093 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.550331.550331 cuda_h.py:19] end allocate_cuda_memory cost 0.0003495216369628906 seconds
DEBUG 01-05 09:59:21.550685.550685 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.550732.550732 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.551853.551853 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.551795.551795 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce67d415-341e-4fc9-b9f3-21f0e15b9b87
DEBUG 01-05 09:59:21.551764.551764 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.551010.551010 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.551770.551770 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce67d415-341e-4fc9-b9f3-21f0e15b9b87
DEBUG 01-05 09:59:21.551938.551938 cuda_h.py:19] end load_into_gpu_async cost 0.0009932518005371094 seconds
DEBUG 01-05 09:59:21.551780.551780 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.552717.552717 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-05 09:59:21.552565.552565 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001668691635131836 seconds
INFO 01-05 09:59:21.552833.552833 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce67d415-341e-4fc9-b9f3-21f0e15b9b87
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.555700.555700 cuda_h.py:19] end self_attn cost 0.003923654556274414 seconds
DEBUG 01-05 09:59:21.555618.555618 cuda_h.py:19] end iln_self_attn_paln cost 0.0054242610931396484 seconds
DEBUG 01-05 09:59:21.555123.555123 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 09:59:21.555409.555409 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.556365.556365 cuda_h.py:19] end gate cost 0.0006361007690429688 seconds
DEBUG 01-05 09:59:21.556003.556003 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.556271.556271 lmp.py:365] 
DEBUG 01-05 09:59:21.556271.556271 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.556073.556073 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.556200.556200 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.556512.556512 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.556963.556963 lmp.py:369] 
DEBUG 01-05 09:59:21.556963.556963 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.556652.556652 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.556779.556779 lmp.py:376]   Expert  1 |     21 | CPU
DEBUG 01-05 09:59:21.556422.556422 lmp.py:376]   Expert  3 |     26 | CPU
DEBUG 01-05 09:59:21.556588.556588 lmp.py:376]   Expert 25 |     48 | CPU
DEBUG 01-05 09:59:21.556039.556039 lmp.py:376]   Expert 40 |     55 | CPU
DEBUG 01-05 09:59:21.556490.556490 lmp.py:376]   Expert 41 |     57 | CPU
DEBUG 01-05 09:59:21.556894.556894 lmp.py:376]   Expert 49 |     60 | CPU
DEBUG 01-05 09:59:21.556537.556537 lmp.py:376]   Expert 15 |     63 | CPU
DEBUG 01-05 09:59:21.557750.557750 lmp.py:376]   Expert  8 |     64 | CPU
DEBUG 01-05 09:59:21.557962.557962 lmp.py:376]   Expert 20 |     65 | CPU
DEBUG 01-05 09:59:21.557698.557698 lmp.py:376]   Expert 31 |     76 | CPU
DEBUG 01-05 09:59:21.557672.557672 lmp.py:376]   Expert 48 |     79 | CPU
DEBUG 01-05 09:59:21.557646.557646 lmp.py:376]   Expert 29 |     83 | CPU
DEBUG 01-05 09:59:21.557381.557381 lmp.py:376]   Expert 16 |     84 | CPU
DEBUG 01-05 09:59:21.557879.557879 lmp.py:376]   Expert 39 |     87 | CPU
DEBUG 01-05 09:59:21.557045.557045 lmp.py:376]   Expert  5 |     88 | CPU
DEBUG 01-05 09:59:21.557972.557972 lmp.py:376]   Expert 63 |     91 | CPU
DEBUG 01-05 09:59:21.557185.557185 lmp.py:376]   Expert  6 |     94 | CPU
DEBUG 01-05 09:59:21.557305.557305 lmp.py:376]   Expert 18 |     99 | CPU
DEBUG 01-05 09:59:21.557471.557471 lmp.py:376]   Expert 32 |    101 | CPU
DEBUG 01-05 09:59:21.557637.557637 lmp.py:376]   Expert 57 |    102 | CPU
DEBUG 01-05 09:59:21.557565.557565 lmp.py:376]   Expert 58 |    112 | CPU
DEBUG 01-05 09:59:21.557731.557731 lmp.py:376]   Expert 59 |    120 | CPU
DEBUG 01-05 09:59:21.557420.557420 lmp.py:376]   Expert 30 |    138 | CPU
DEBUG 01-05 09:59:21.557586.557586 lmp.py:376]   Expert 55 |    149 | CPU
DEBUG 01-05 09:59:21.557468.557468 lmp.py:376]   Expert  4 |    154 | CPU
DEBUG 01-05 09:59:21.557634.557634 lmp.py:376]   Expert 35 |    157 | CPU
DEBUG 01-05 09:59:21.557562.557562 lmp.py:376]   Expert 34 |    159 | CPU
DEBUG 01-05 09:59:21.557012.557012 lmp.py:376]   Expert 26 |    161 | CPU
DEBUG 01-05 09:59:21.557940.557940 lmp.py:376]   Expert 53 |    161 | CPU
DEBUG 01-05 09:59:21.557868.557868 lmp.py:376]   Expert 45 |    164 | CPU
DEBUG 01-05 09:59:21.557796.557796 lmp.py:376]   Expert  0 |    168 | CPU
DEBUG 01-05 09:59:21.557723.557723 lmp.py:376]   Expert 52 |    170 | CPU
DEBUG 01-05 09:59:21.557128.557128 lmp.py:376]   Expert  7 |    180 | GPU
DEBUG 01-05 09:59:21.557771.557771 lmp.py:376]   Expert 33 |    183 | GPU
DEBUG 01-05 09:59:21.557460.557460 lmp.py:376]   Expert 50 |    184 | GPU
DEBUG 01-05 09:59:21.557149.557149 lmp.py:376]   Expert 54 |    191 | GPU
DEBUG 01-05 09:59:21.557839.557839 lmp.py:376]   Expert 28 |    196 | GPU
DEBUG 01-05 09:59:21.557528.557528 lmp.py:376]   Expert 42 |    202 | GPU
DEBUG 01-05 09:59:21.557217.557217 lmp.py:376]   Expert 21 |    203 | GPU
DEBUG 01-05 09:59:21.557907.557907 lmp.py:376]   Expert 19 |    204 | GPU
DEBUG 01-05 09:59:21.557596.557596 lmp.py:376]   Expert 24 |    205 | GPU
DEBUG 01-05 09:59:21.557047.557047 lmp.py:376]   Expert 51 |    209 | GPU
DEBUG 01-05 09:59:21.557213.557213 lmp.py:376]   Expert 60 |    211 | GPU
DEBUG 01-05 09:59:21.557856.557856 lmp.py:376]   Expert 17 |    215 | GPU
DEBUG 01-05 09:59:21.557784.557784 lmp.py:376]   Expert 43 |    217 | GPU
DEBUG 01-05 09:59:21.557473.557473 lmp.py:376]   Expert 27 |    219 | GPU
DEBUG 01-05 09:59:21.557162.557162 lmp.py:376]   Expert 36 |    224 | GPU
DEBUG 01-05 09:59:21.557613.557613 lmp.py:376]   Expert 13 |    231 | GPU
DEBUG 01-05 09:59:21.557541.557541 lmp.py:376]   Expert 10 |    250 | GPU
DEBUG 01-05 09:59:21.557945.557945 lmp.py:376]   Expert 37 |    253 | GPU
DEBUG 01-05 09:59:21.557873.557873 lmp.py:376]   Expert 47 |    253 | GPU
DEBUG 01-05 09:59:21.557562.557562 lmp.py:376]   Expert 62 |    260 | GPU
DEBUG 01-05 09:59:21.557013.557013 lmp.py:376]   Expert 11 |    270 | GPU
DEBUG 01-05 09:59:21.557703.557703 lmp.py:376]   Expert 22 |    281 | GPU
DEBUG 01-05 09:59:21.557915.557915 lmp.py:376]   Expert  2 |    309 | GPU
DEBUG 01-05 09:59:21.557843.557843 lmp.py:376]   Expert 61 |    314 | GPU
DEBUG 01-05 09:59:21.557247.557247 lmp.py:376]   Expert 56 |    317 | GPU
DEBUG 01-05 09:59:21.557937.557937 lmp.py:376]   Expert 44 |    348 | GPU
DEBUG 01-05 09:59:21.557388.557388 lmp.py:376]   Expert 14 |    349 | GPU
DEBUG 01-05 09:59:21.557838.557838 lmp.py:376]   Expert 38 |    350 | GPU
DEBUG 01-05 09:59:21.557051.557051 lmp.py:376]   Expert 46 |    382 | GPU
DEBUG 01-05 09:59:21.557502.557502 lmp.py:376]   Expert 12 |    571 | GPU
DEBUG 01-05 09:59:21.557953.557953 lmp.py:376]   Expert  9 |    596 | GPU
DEBUG 01-05 09:59:21.557165.557165 lmp.py:376]   Expert 23 |    655 | GPU
DEBUG 01-05 09:59:21.557331.557331 lmp.py:377] 
DEBUG 01-05 09:59:21.557331.557331 lmp.py:377]   CPU total tokens: 3256 (26.5%)
DEBUG 01-05 09:59:21.557689.557689 lmp.py:378]   GPU total tokens: 9032 (73.5%)
DEBUG 01-05 09:59:21.558624.558624 cuda_h.py:19] end experts_map_get cost 0.0015184879302978516 seconds
DEBUG 01-05 09:59:21.558744.558744 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.558997.558997 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.558849.558849 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.558335.558335 cuda_h.py:19] end allocate_cuda_memory cost 0.00042366981506347656 seconds
DEBUG 01-05 09:59:21.558529.558529 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.558716.558716 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.558379.558379 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.558506.558506 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 742d5ebc-10ba-45bd-b2e3-e45a06c96c18
DEBUG 01-05 09:59:21.559632.559632 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.559180.559180 client.py:127] Model loaded
DEBUG 01-05 09:59:21.559937.559937 cuda_h.py:19] end sllm_worker_task cost 0.00886845588684082 seconds
INFO 01-05 09:59:21.559309.559309 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 742d5ebc-10ba-45bd-b2e3-e45a06c96c18
DEBUG 01-05 09:59:21.559583.559583 cuda_h.py:19] end load_into_gpu_async cost 0.0011627674102783203 seconds
DEBUG 01-05 09:59:21.559763.559763 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.560771.560771 cuda_h.py:19] end restore_tensors2 cost 0.00043582916259765625 seconds
DEBUG 01-05 09:59:21.560376.560376 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023984909057617188 seconds
DEBUG 01-05 09:59:21.563357.563357 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005025386810302734 seconds
DEBUG 01-05 09:59:21.563140.563140 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.563950.563950 lmp.py:423] 
DEBUG 01-05 09:59:21.563950.563950 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.563244.563244 cuda_h.py:19] end cpu_experts_submit cost 0.00012040138244628906 seconds
DEBUG 01-05 09:59:21.563755.563755 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.568447.568447 mlpmodule.py:704] group tensors cost 0.005437612533569336 s
DEBUG 01-05 09:59:21.571989.571989 mlpmodule.py:742] pad cost 0.0022668838500976562 s
DEBUG 01-05 09:59:21.572040.572040 mlpmodule.py:748] create cpu tensor cost 5.888938903808594e-05 s
DEBUG 01-05 09:59:21.572261.572261 mlpmodule.py:753] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-05 09:59:21.581651.581651 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.581525.581525 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.581084.581084 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 09:59:21.581791.581791 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.598205.598205 mlpmodule.py:793] group einsum cost 0.026090621948242188 s
DEBUG 01-05 09:59:21.599891.599891 mlpmodule.py:801] cpy2cputensor cost 0.0007185935974121094 s
DEBUG 01-05 09:59:21.603041.603041 cuda_h.py:19] end wait_cetm_experts cost 0.040511131286621094 seconds
DEBUG 01-05 09:59:21.604073.604073 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.604426.604426 cuda_h.py:19] end gpu_sexperts cost 0.0006015300750732422 seconds
DEBUG 01-05 09:59:21.604322.604322 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.604702.604702 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:59:21.604074.604074 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.604783.604783 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 742d5ebc-10ba-45bd-b2e3-e45a06c96c18
INFO 01-05 09:59:21.615090.615090 client.py:127] Model loaded
DEBUG 01-05 09:59:21.615894.615894 cuda_h.py:19] end wait_experts cost 0.010616064071655273 seconds
DEBUG 01-05 09:59:21.615663.615663 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.615366.615366 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.616427.616427 mlpmodule.py:531] gpu group tensors cost 0.0005619525909423828 s
DEBUG 01-05 09:59:21.617129.617129 mlpmodule.py:662]  experts func einsum cost 0.05393171310424805 s
DEBUG 01-05 09:59:21.617149.617149 mlpmodule.py:564] gpu pad cost 0.0017011165618896484 s
DEBUG 01-05 09:59:21.618387.618387 mlpmodule.py:582] gpu group einsum cost 0.0004987716674804688 s
DEBUG 01-05 09:59:21.621728.621728 mlpmodule.py:611] gpu experts func einsum cost 0.005980491638183594 s
DEBUG 01-05 09:59:21.621502.621502 cuda_h.py:19] end gpu_experts cost 0.006246328353881836 seconds
DEBUG 01-05 09:59:21.621161.621161 cuda_h.py:19] end layer_moe_generate_7 cost 0.06618380546569824 seconds
DEBUG 01-05 09:59:21.622505.622505 lmp.py:217] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 09:59:21.622175.622175 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 09:59:21.622679.622679 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:59:21.622766.622766 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:59:21.622338.622338 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 4.410743713378906e-05 seconds
DEBUG 01-05 09:59:21.622393.622393 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 8.940696716308594e-05 seconds
DEBUG 01-05 09:59:21.622705.622705 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.622839.622839 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.622089.622089 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.622735.622735 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.623996.623996 cuda_h.py:19] end allocate_cuda_memory cost 0.00041985511779785156 seconds
DEBUG 01-05 09:59:21.623138.623138 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.623995.623995 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.623222.623222 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.623190.623190 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5a9e890b-6de1-416c-bbd1-a374a19e1e8e
DEBUG 01-05 09:59:21.623386.623386 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.623849.623849 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.624923.624923 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5a9e890b-6de1-416c-bbd1-a374a19e1e8e
DEBUG 01-05 09:59:21.624230.624230 cuda_h.py:19] end load_into_gpu_async cost 0.0012843608856201172 seconds
DEBUG 01-05 09:59:21.624377.624377 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.624593.624593 cuda_h.py:19] end restore_tensors2 cost 8.463859558105469e-05 seconds
DEBUG 01-05 09:59:21.624939.624939 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021772384643554688 seconds
INFO 01-05 09:59:21.625946.625946 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5a9e890b-6de1-416c-bbd1-a374a19e1e8e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.627256.627256 cuda_h.py:19] end self_attn cost 0.003783702850341797 seconds
DEBUG 01-05 09:59:21.627134.627134 cuda_h.py:19] end iln_self_attn_paln cost 0.0054836273193359375 seconds
DEBUG 01-05 09:59:21.627639.627639 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 09:59:21.627641.627641 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.628696.628696 cuda_h.py:19] end gate cost 0.0006399154663085938 seconds
DEBUG 01-05 09:59:21.628241.628241 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.628264.628264 lmp.py:365] 
DEBUG 01-05 09:59:21.628264.628264 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.628212.628212 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.629339.629339 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.629320.629320 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.629678.629678 lmp.py:369] 
DEBUG 01-05 09:59:21.629678.629678 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.629275.629275 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.629117.629117 lmp.py:376]   Expert  7 |     21 | CPU
DEBUG 01-05 09:59:21.629236.629236 lmp.py:376]   Expert 27 |     24 | CPU
DEBUG 01-05 09:59:21.629641.629641 lmp.py:376]   Expert 14 |     29 | CPU
DEBUG 01-05 09:59:21.629284.629284 lmp.py:376]   Expert 30 |     34 | CPU
DEBUG 01-05 09:59:21.629450.629450 lmp.py:376]   Expert 38 |     42 | CPU
DEBUG 01-05 09:59:21.629093.629093 lmp.py:376]   Expert 12 |     48 | CPU
DEBUG 01-05 09:59:21.629498.629498 lmp.py:376]   Expert 36 |     63 | CPU
DEBUG 01-05 09:59:21.629664.629664 lmp.py:376]   Expert 22 |     65 | CPU
DEBUG 01-05 09:59:21.629830.629830 lmp.py:376]   Expert 34 |     65 | CPU
DEBUG 01-05 09:59:21.629758.629758 lmp.py:376]   Expert 53 |     68 | CPU
DEBUG 01-05 09:59:21.629685.629685 lmp.py:376]   Expert  8 |     74 | CPU
DEBUG 01-05 09:59:21.629375.629375 lmp.py:376]   Expert 54 |     79 | CPU
DEBUG 01-05 09:59:21.629064.629064 lmp.py:376]   Expert 26 |     81 | CPU
DEBUG 01-05 09:59:21.629230.629230 lmp.py:376]   Expert 40 |     91 | CPU
DEBUG 01-05 09:59:21.629919.629919 lmp.py:376]   Expert 33 |     94 | CPU
DEBUG 01-05 09:59:21.629847.629847 lmp.py:376]   Expert  1 |     95 | CPU
DEBUG 01-05 09:59:21.629775.629775 lmp.py:376]   Expert 57 |     99 | CPU
DEBUG 01-05 09:59:21.629702.629702 lmp.py:376]   Expert 13 |    108 | CPU
DEBUG 01-05 09:59:21.629822.629822 lmp.py:376]   Expert  9 |    113 | CPU
DEBUG 01-05 09:59:21.629988.629988 lmp.py:376]   Expert 32 |    113 | CPU
DEBUG 01-05 09:59:21.629678.629678 lmp.py:376]   Expert 29 |    118 | CPU
DEBUG 01-05 09:59:21.629890.629890 lmp.py:376]   Expert 50 |    118 | CPU
DEBUG 01-05 09:59:21.629818.629818 lmp.py:376]   Expert 17 |    119 | CPU
DEBUG 01-05 09:59:21.629269.629269 lmp.py:376]   Expert 59 |    135 | CPU
DEBUG 01-05 09:59:21.629720.629720 lmp.py:376]   Expert 44 |    144 | CPU
DEBUG 01-05 09:59:21.629409.629409 lmp.py:376]   Expert 60 |    146 | CPU
DEBUG 01-05 09:59:21.629860.629860 lmp.py:376]   Expert 24 |    151 | CPU
DEBUG 01-05 09:59:21.629549.629549 lmp.py:376]   Expert 10 |    163 | CPU
DEBUG 01-05 09:59:21.629238.629238 lmp.py:376]   Expert 51 |    166 | CPU
DEBUG 01-05 09:59:21.629405.629405 lmp.py:376]   Expert 16 |    168 | CPU
DEBUG 01-05 09:59:21.629094.629094 lmp.py:376]   Expert 15 |    169 | CPU
DEBUG 01-05 09:59:21.629306.629306 lmp.py:376]   Expert 56 |    169 | CPU
DEBUG 01-05 09:59:21.629472.629472 lmp.py:376]   Expert  2 |    173 | GPU
DEBUG 01-05 09:59:21.629115.629115 lmp.py:376]   Expert 37 |    175 | GPU
DEBUG 01-05 09:59:21.629758.629758 lmp.py:376]   Expert 31 |    186 | GPU
DEBUG 01-05 09:59:21.629925.629925 lmp.py:376]   Expert 19 |    192 | GPU
DEBUG 01-05 09:59:21.629614.629614 lmp.py:376]   Expert 18 |    195 | GPU
DEBUG 01-05 09:59:21.629542.629542 lmp.py:376]   Expert 39 |    199 | GPU
DEBUG 01-05 09:59:21.629992.629992 lmp.py:376]   Expert 58 |    215 | GPU
DEBUG 01-05 09:59:21.629205.629205 lmp.py:376]   Expert 61 |    223 | GPU
DEBUG 01-05 09:59:21.629133.629133 lmp.py:376]   Expert 49 |    227 | GPU
DEBUG 01-05 09:59:21.629584.629584 lmp.py:376]   Expert 41 |    236 | GPU
DEBUG 01-05 09:59:21.629273.629273 lmp.py:376]   Expert 35 |    243 | GPU
DEBUG 01-05 09:59:21.629962.629962 lmp.py:376]   Expert 46 |    248 | GPU
DEBUG 01-05 09:59:21.629413.629413 lmp.py:376]   Expert 42 |    249 | GPU
DEBUG 01-05 09:59:21.629102.629102 lmp.py:376]   Expert  0 |    257 | GPU
DEBUG 01-05 09:59:21.629792.629792 lmp.py:376]   Expert 23 |    261 | GPU
DEBUG 01-05 09:59:21.629435.629435 lmp.py:376]   Expert  6 |    266 | GPU
DEBUG 01-05 09:59:21.629316.629316 lmp.py:376]   Expert  3 |    267 | GPU
DEBUG 01-05 09:59:21.629005.629005 lmp.py:376]   Expert  4 |    276 | GPU
DEBUG 01-05 09:59:21.629933.629933 lmp.py:376]   Expert 55 |    281 | GPU
DEBUG 01-05 09:59:21.629622.629622 lmp.py:376]   Expert 28 |    283 | GPU
DEBUG 01-05 09:59:21.629073.629073 lmp.py:376]   Expert 43 |    308 | GPU
DEBUG 01-05 09:59:21.629763.629763 lmp.py:376]   Expert 20 |    318 | GPU
DEBUG 01-05 09:59:21.630452.630452 lmp.py:376]   Expert 45 |    321 | GPU
DEBUG 01-05 09:59:21.630903.630903 lmp.py:376]   Expert 52 |    333 | GPU
DEBUG 01-05 09:59:21.630592.630592 lmp.py:376]   Expert 48 |    340 | GPU
DEBUG 01-05 09:59:21.630281.630281 lmp.py:376]   Expert 47 |    344 | GPU
DEBUG 01-05 09:59:21.630924.630924 lmp.py:376]   Expert 25 |    348 | GPU
DEBUG 01-05 09:59:21.630044.630044 lmp.py:376]   Expert 11 |    376 | GPU
DEBUG 01-05 09:59:21.630972.630972 lmp.py:376]   Expert 62 |    403 | GPU
DEBUG 01-05 09:59:21.630423.630423 lmp.py:376]   Expert 63 |    407 | GPU
DEBUG 01-05 09:59:21.630112.630112 lmp.py:376]   Expert 21 |    423 | GPU
DEBUG 01-05 09:59:21.630563.630563 lmp.py:376]   Expert  5 |    543 | GPU
DEBUG 01-05 09:59:21.630206.630206 lmp.py:377] 
DEBUG 01-05 09:59:21.630206.630206 lmp.py:377]   CPU total tokens: 3172 (25.8%)
DEBUG 01-05 09:59:21.630849.630849 lmp.py:378]   GPU total tokens: 9116 (74.2%)
DEBUG 01-05 09:59:21.630068.630068 cuda_h.py:19] end experts_map_get cost 0.001529693603515625 seconds
DEBUG 01-05 09:59:21.630857.630857 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.630395.630395 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.630055.630055 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.631915.631915 cuda_h.py:19] end allocate_cuda_memory cost 0.0013375282287597656 seconds
DEBUG 01-05 09:59:21.631282.631282 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.631846.631846 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.631622.631622 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.631630.631630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 994901e8-1a77-438c-9155-02a9b4060d26
DEBUG 01-05 09:59:21.632511.632511 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.632111.632111 client.py:127] Model loaded
DEBUG 01-05 09:59:21.632962.632962 cuda_h.py:19] end sllm_worker_task cost 0.010057926177978516 seconds
INFO 01-05 09:59:21.633804.633804 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 994901e8-1a77-438c-9155-02a9b4060d26
DEBUG 01-05 09:59:21.633984.633984 cuda_h.py:19] end load_into_gpu_async cost 0.0015740394592285156 seconds
DEBUG 01-05 09:59:21.633164.633164 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.633399.633399 cuda_h.py:19] end restore_tensors2 cost 0.0004620552062988281 seconds
DEBUG 01-05 09:59:21.634487.634487 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037305355072021484 seconds
DEBUG 01-05 09:59:21.636601.636601 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006385087966918945 seconds
DEBUG 01-05 09:59:21.636345.636345 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.636924.636924 lmp.py:423] 
DEBUG 01-05 09:59:21.636924.636924 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.636197.636197 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-05 09:59:21.636854.636854 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.648635.648635 mlpmodule.py:704] group tensors cost 0.0118408203125 s
DEBUG 01-05 09:59:21.651870.651870 mlpmodule.py:742] pad cost 0.0016665458679199219 s
DEBUG 01-05 09:59:21.651689.651689 mlpmodule.py:748] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-05 09:59:21.651844.651844 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-05 09:59:21.662427.662427 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.662817.662817 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.662661.662661 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 09:59:21.662653.662653 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.680264.680264 mlpmodule.py:793] group einsum cost 0.028878211975097656 s
DEBUG 01-05 09:59:21.681918.681918 mlpmodule.py:801] cpy2cputensor cost 0.0007202625274658203 s
DEBUG 01-05 09:59:21.685864.685864 cuda_h.py:19] end wait_cetm_experts cost 0.0488741397857666 seconds
DEBUG 01-05 09:59:21.685472.685472 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.686168.686168 cuda_h.py:19] end gpu_sexperts cost 0.0005724430084228516 seconds
DEBUG 01-05 09:59:21.686018.686018 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.686828.686828 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:59:21.686723.686723 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.686671.686671 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 994901e8-1a77-438c-9155-02a9b4060d26
INFO 01-05 09:59:21.689150.689150 client.py:127] Model loaded
DEBUG 01-05 09:59:21.689662.689662 cuda_h.py:19] end wait_experts cost 0.002276897430419922 seconds
DEBUG 01-05 09:59:21.689795.689795 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.689227.689227 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.689225.689225 mlpmodule.py:531] gpu group tensors cost 0.0006504058837890625 s
DEBUG 01-05 09:59:21.691022.691022 mlpmodule.py:564] gpu pad cost 0.001795053482055664 s
DEBUG 01-05 09:59:21.692880.692880 mlpmodule.py:582] gpu group einsum cost 0.0005674362182617188 s
DEBUG 01-05 09:59:21.696854.696854 mlpmodule.py:611] gpu experts func einsum cost 0.007188081741333008 s
DEBUG 01-05 09:59:21.696203.696203 cuda_h.py:19] end gpu_experts cost 0.007391691207885742 seconds
DEBUG 01-05 09:59:21.696385.696385 cuda_h.py:19] end layer_moe_generate_8 cost 0.06870555877685547 seconds
DEBUG 01-05 09:59:21.696286.696286 lmp.py:217] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 09:59:21.696380.696380 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 09:59:21.696076.696076 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:59:21.696547.696547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:59:21.696814.696814 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:21.697371.697371 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.888938903808594e-05 seconds
DEBUG 01-05 09:59:21.697729.697729 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.697951.697951 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.697723.697723 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.697751.697751 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.699974.699974 cuda_h.py:19] end allocate_cuda_memory cost 0.0026547908782958984 seconds
DEBUG 01-05 09:59:21.700791.700791 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.700548.700548 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.700139.700139 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.700941.700941 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 08045196-e26a-47e3-bbc4-30af30655781
DEBUG 01-05 09:59:21.700554.700554 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.700533.700533 mlpmodule.py:662]  experts func einsum cost 0.06360220909118652 s
DEBUG 01-05 09:59:21.701791.701791 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.701510.701510 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 08045196-e26a-47e3-bbc4-30af30655781
DEBUG 01-05 09:59:21.701207.701207 cuda_h.py:19] end load_into_gpu_async cost 0.00168609619140625 seconds
DEBUG 01-05 09:59:21.701956.701956 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.701701.701701 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-05 09:59:21.701026.701026 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004682064056396484 seconds
INFO 01-05 09:59:21.702187.702187 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 08045196-e26a-47e3-bbc4-30af30655781
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.705596.705596 cuda_h.py:19] end self_attn cost 0.003961801528930664 seconds
DEBUG 01-05 09:59:21.705142.705142 cuda_h.py:19] end iln_self_attn_paln cost 0.008351564407348633 seconds
DEBUG 01-05 09:59:21.705078.705078 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 09:59:21.705033.705033 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.706260.706260 cuda_h.py:19] end gate cost 0.0006248950958251953 seconds
DEBUG 01-05 09:59:21.706421.706421 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.706212.706212 lmp.py:365] 
DEBUG 01-05 09:59:21.706212.706212 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.706776.706776 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.706426.706426 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.706738.706738 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.706666.706666 lmp.py:369] 
DEBUG 01-05 09:59:21.706666.706666 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.706070.706070 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.706481.706481 lmp.py:376]   Expert  7 |     33 | CPU
DEBUG 01-05 09:59:21.706648.706648 lmp.py:376]   Expert 35 |     34 | CPU
DEBUG 01-05 09:59:21.706622.706622 lmp.py:376]   Expert  2 |     43 | CPU
DEBUG 01-05 09:59:21.706834.706834 lmp.py:376]   Expert 26 |     46 | CPU
DEBUG 01-05 09:59:21.706570.706570 lmp.py:376]   Expert  6 |     48 | CPU
DEBUG 01-05 09:59:21.706782.706782 lmp.py:376]   Expert  5 |     54 | CPU
DEBUG 01-05 09:59:21.706710.706710 lmp.py:376]   Expert 60 |     57 | CPU
DEBUG 01-05 09:59:21.706161.706161 lmp.py:376]   Expert 13 |     61 | CPU
DEBUG 01-05 09:59:21.706135.706135 lmp.py:376]   Expert 19 |     62 | CPU
DEBUG 01-05 09:59:21.706870.706870 lmp.py:376]   Expert 38 |     63 | CPU
DEBUG 01-05 09:59:21.706368.706368 lmp.py:376]   Expert 48 |     73 | CPU
DEBUG 01-05 09:59:21.706103.706103 lmp.py:376]   Expert 39 |     77 | CPU
DEBUG 01-05 09:59:21.706362.706362 lmp.py:376]   Expert 25 |     78 | CPU
DEBUG 01-05 09:59:21.706575.706575 lmp.py:376]   Expert 17 |     81 | CPU
DEBUG 01-05 09:59:21.706264.706264 lmp.py:376]   Expert 45 |     97 | CPU
DEBUG 01-05 09:59:21.706761.706761 lmp.py:376]   Expert 52 |     97 | CPU
DEBUG 01-05 09:59:21.706735.706735 lmp.py:376]   Expert 27 |    102 | CPU
DEBUG 01-05 09:59:21.706232.706232 lmp.py:376]   Expert 54 |    102 | CPU
DEBUG 01-05 09:59:21.706968.706968 lmp.py:376]   Expert 16 |    131 | CPU
DEBUG 01-05 09:59:21.706465.706465 lmp.py:376]   Expert 59 |    131 | CPU
DEBUG 01-05 09:59:21.706962.706962 lmp.py:376]   Expert 29 |    133 | CPU
DEBUG 01-05 09:59:21.706460.706460 lmp.py:376]   Expert 24 |    140 | CPU
DEBUG 01-05 09:59:21.706864.706864 lmp.py:376]   Expert 57 |    152 | CPU
DEBUG 01-05 09:59:21.707746.707746 lmp.py:376]   Expert 49 |    155 | CPU
DEBUG 01-05 09:59:21.707912.707912 lmp.py:376]   Expert 62 |    158 | CPU
DEBUG 01-05 09:59:21.707363.707363 lmp.py:376]   Expert 20 |    159 | CPU
DEBUG 01-05 09:59:21.707052.707052 lmp.py:376]   Expert 40 |    159 | CPU
DEBUG 01-05 09:59:21.707741.707741 lmp.py:376]   Expert 32 |    160 | CPU
DEBUG 01-05 09:59:21.707192.707192 lmp.py:376]   Expert 14 |    162 | CPU
DEBUG 01-05 09:59:21.707643.707643 lmp.py:376]   Expert 42 |    165 | CPU
DEBUG 01-05 09:59:21.707094.707094 lmp.py:376]   Expert 12 |    167 | CPU
DEBUG 01-05 09:59:21.707783.707783 lmp.py:376]   Expert 28 |    168 | CPU
DEBUG 01-05 09:59:21.707472.707472 lmp.py:376]   Expert 22 |    170 | GPU
DEBUG 01-05 09:59:21.707400.707400 lmp.py:376]   Expert 30 |    171 | GPU
DEBUG 01-05 09:59:21.707328.707328 lmp.py:376]   Expert 31 |    177 | GPU
DEBUG 01-05 09:59:21.707540.707540 lmp.py:376]   Expert 11 |    178 | GPU
DEBUG 01-05 09:59:21.707230.707230 lmp.py:376]   Expert  1 |    183 | GPU
DEBUG 01-05 09:59:21.707442.707442 lmp.py:376]   Expert 18 |    185 | GPU
DEBUG 01-05 09:59:21.707893.707893 lmp.py:376]   Expert 33 |    185 | GPU
DEBUG 01-05 09:59:21.707344.707344 lmp.py:376]   Expert 58 |    186 | GPU
DEBUG 01-05 09:59:21.707556.707556 lmp.py:376]   Expert 23 |    190 | GPU
DEBUG 01-05 09:59:21.707438.707438 lmp.py:376]   Expert 41 |    190 | GPU
DEBUG 01-05 09:59:21.707604.707604 lmp.py:376]   Expert 43 |    191 | GPU
DEBUG 01-05 09:59:21.707055.707055 lmp.py:376]   Expert  3 |    205 | GPU
DEBUG 01-05 09:59:21.707506.707506 lmp.py:376]   Expert 34 |    207 | GPU
DEBUG 01-05 09:59:21.707956.707956 lmp.py:376]   Expert 10 |    211 | GPU
DEBUG 01-05 09:59:21.707169.707169 lmp.py:376]   Expert 50 |    214 | GPU
DEBUG 01-05 09:59:21.707858.707858 lmp.py:376]   Expert 51 |    226 | GPU
DEBUG 01-05 09:59:21.707071.707071 lmp.py:376]   Expert  4 |    229 | GPU
DEBUG 01-05 09:59:21.707760.707760 lmp.py:376]   Expert 47 |    234 | GPU
DEBUG 01-05 09:59:21.707926.707926 lmp.py:376]   Expert 53 |    247 | GPU
DEBUG 01-05 09:59:21.707377.707377 lmp.py:376]   Expert 36 |    256 | GPU
DEBUG 01-05 09:59:21.707305.707305 lmp.py:376]   Expert  0 |    286 | GPU
DEBUG 01-05 09:59:21.707471.707471 lmp.py:376]   Expert 44 |    288 | GPU
DEBUG 01-05 09:59:21.707637.707637 lmp.py:376]   Expert 61 |    315 | GPU
DEBUG 01-05 09:59:21.707565.707565 lmp.py:376]   Expert 37 |    344 | GPU
DEBUG 01-05 09:59:21.707208.707208 lmp.py:376]   Expert 55 |    356 | GPU
DEBUG 01-05 09:59:21.707612.707612 lmp.py:376]   Expert  9 |    365 | GPU
DEBUG 01-05 09:59:21.707017.707017 lmp.py:376]   Expert  8 |    371 | GPU
DEBUG 01-05 09:59:21.707421.707421 lmp.py:376]   Expert 63 |    464 | GPU
DEBUG 01-05 09:59:21.707349.707349 lmp.py:376]   Expert 46 |    479 | GPU
DEBUG 01-05 09:59:21.707800.707800 lmp.py:376]   Expert 15 |    487 | GPU
DEBUG 01-05 09:59:21.707489.707489 lmp.py:376]   Expert 21 |    556 | GPU
DEBUG 01-05 09:59:21.707702.707702 lmp.py:376]   Expert 56 |    594 | GPU
DEBUG 01-05 09:59:21.707868.707868 lmp.py:377] 
DEBUG 01-05 09:59:21.707868.707868 lmp.py:377]   CPU total tokens: 3348 (27.2%)
DEBUG 01-05 09:59:21.707034.707034 lmp.py:378]   GPU total tokens: 8940 (72.8%)
DEBUG 01-05 09:59:21.707684.707684 cuda_h.py:19] end experts_map_get cost 0.0015003681182861328 seconds
DEBUG 01-05 09:59:21.707804.707804 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.707772.707772 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.707147.707147 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.708999.708999 cuda_h.py:19] end allocate_cuda_memory cost 0.0004887580871582031 seconds
DEBUG 01-05 09:59:21.708511.708511 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.708744.708744 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.708176.708176 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.708018.708018 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24762666-d4ff-4a01-8968-489265ac70fa
DEBUG 01-05 09:59:21.708912.708912 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.709411.709411 client.py:127] Model loaded
DEBUG 01-05 09:59:21.709367.709367 cuda_h.py:19] end sllm_worker_task cost 0.011927366256713867 seconds
INFO 01-05 09:59:21.709107.709107 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24762666-d4ff-4a01-8968-489265ac70fa
DEBUG 01-05 09:59:21.709950.709950 cuda_h.py:19] end load_into_gpu_async cost 0.0012018680572509766 seconds
DEBUG 01-05 09:59:21.709891.709891 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.710561.710561 cuda_h.py:19] end restore_tensors2 cost 0.0003974437713623047 seconds
DEBUG 01-05 09:59:21.710643.710643 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024449825286865234 seconds
DEBUG 01-05 09:59:21.712544.712544 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00508427619934082 seconds
DEBUG 01-05 09:59:21.712712.712712 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.712575.712575 lmp.py:423] 
DEBUG 01-05 09:59:21.712575.712575 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.713087.713087 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-05 09:59:21.713790.713790 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.718717.718717 mlpmodule.py:704] group tensors cost 0.00531768798828125 s
DEBUG 01-05 09:59:21.720730.720730 mlpmodule.py:742] pad cost 0.0017535686492919922 s
DEBUG 01-05 09:59:21.721316.721316 mlpmodule.py:748] create cpu tensor cost 5.173683166503906e-05 s
DEBUG 01-05 09:59:21.721650.721650 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-05 09:59:21.731898.731898 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.731334.731334 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.731132.731132 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:59:21.731024.731024 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.748583.748583 mlpmodule.py:793] group einsum cost 0.026791095733642578 s
DEBUG 01-05 09:59:21.748262.748262 mlpmodule.py:801] cpy2cputensor cost 0.0006730556488037109 s
DEBUG 01-05 09:59:21.753096.753096 cuda_h.py:19] end wait_cetm_experts cost 0.04031562805175781 seconds
DEBUG 01-05 09:59:21.753896.753896 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.754817.754817 cuda_h.py:19] end gpu_sexperts cost 0.0005633831024169922 seconds
DEBUG 01-05 09:59:21.754853.754853 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.754948.754948 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:21.754319.754319 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.754334.754334 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24762666-d4ff-4a01-8968-489265ac70fa
INFO 01-05 09:59:21.765140.765140 client.py:127] Model loaded
DEBUG 01-05 09:59:21.766543.766543 cuda_h.py:19] end wait_experts cost 0.011557579040527344 seconds
DEBUG 01-05 09:59:21.766228.766228 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.766621.766621 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.766343.766343 mlpmodule.py:662]  experts func einsum cost 0.05352497100830078 s
DEBUG 01-05 09:59:21.767882.767882 mlpmodule.py:531] gpu group tensors cost 0.0006864070892333984 s
DEBUG 01-05 09:59:21.768565.768565 mlpmodule.py:564] gpu pad cost 0.0015316009521484375 s
DEBUG 01-05 09:59:21.769983.769983 mlpmodule.py:582] gpu group einsum cost 0.0005252361297607422 s
DEBUG 01-05 09:59:21.772356.772356 mlpmodule.py:611] gpu experts func einsum cost 0.005962848663330078 s
DEBUG 01-05 09:59:21.772191.772191 cuda_h.py:19] end gpu_experts cost 0.006353139877319336 seconds
DEBUG 01-05 09:59:21.772360.772360 cuda_h.py:19] end layer_moe_generate_9 cost 0.06713485717773438 seconds
DEBUG 01-05 09:59:21.772373.772373 lmp.py:217] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 09:59:21.772036.772036 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 09:59:21.772540.772540 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:59:21.772627.772627 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:59:21.772517.772517 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:59:21.772286.772286 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.748603820800781e-05 seconds
DEBUG 01-05 09:59:21.773644.773644 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.773807.773807 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.773057.773057 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.773346.773346 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.773356.773356 cuda_h.py:19] end allocate_cuda_memory cost 0.0004291534423828125 seconds
DEBUG 01-05 09:59:21.774705.774705 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.774761.774761 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.774969.774969 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.774798.774798 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d55ecdc-c6a1-4d84-a062-e2dee6d274dd
DEBUG 01-05 09:59:21.774598.774598 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.774113.774113 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.775081.775081 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d55ecdc-c6a1-4d84-a062-e2dee6d274dd
DEBUG 01-05 09:59:21.775085.775085 cuda_h.py:19] end load_into_gpu_async cost 0.0013608932495117188 seconds
DEBUG 01-05 09:59:21.775152.775152 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.775833.775833 cuda_h.py:19] end restore_tensors2 cost 0.000102996826171875 seconds
DEBUG 01-05 09:59:21.775564.775564 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024018287658691406 seconds
INFO 01-05 09:59:21.776869.776869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d55ecdc-c6a1-4d84-a062-e2dee6d274dd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.778903.778903 cuda_h.py:19] end self_attn cost 0.004134416580200195 seconds
DEBUG 01-05 09:59:21.779934.779934 cuda_h.py:19] end iln_self_attn_paln cost 0.006044149398803711 seconds
DEBUG 01-05 09:59:21.779916.779916 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 09:59:21.779394.779394 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.779820.779820 cuda_h.py:19] end gate cost 0.0006318092346191406 seconds
DEBUG 01-05 09:59:21.779458.779458 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.780163.780163 lmp.py:365] 
DEBUG 01-05 09:59:21.780163.780163 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.780112.780112 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.780238.780238 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.780742.780742 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.780339.780339 lmp.py:369] 
DEBUG 01-05 09:59:21.780339.780339 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.780697.780697 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.780777.780777 lmp.py:376]   Expert 34 |      5 | CPU
DEBUG 01-05 09:59:21.780374.780374 lmp.py:376]   Expert  3 |     19 | CPU
DEBUG 01-05 09:59:21.780581.780581 lmp.py:376]   Expert 61 |     23 | CPU
DEBUG 01-05 09:59:21.780462.780462 lmp.py:376]   Expert 14 |     27 | CPU
DEBUG 01-05 09:59:21.780913.780913 lmp.py:376]   Expert 47 |     43 | CPU
DEBUG 01-05 09:59:21.780126.780126 lmp.py:376]   Expert 48 |     44 | CPU
DEBUG 01-05 09:59:21.780576.780576 lmp.py:376]   Expert 32 |     47 | CPU
DEBUG 01-05 09:59:21.780027.780027 lmp.py:376]   Expert 55 |     55 | CPU
DEBUG 01-05 09:59:21.780909.780909 lmp.py:376]   Expert 27 |     61 | CPU
DEBUG 01-05 09:59:21.780313.780313 lmp.py:376]   Expert 15 |     69 | CPU
DEBUG 01-05 09:59:21.780718.780718 lmp.py:376]   Expert 13 |     77 | CPU
DEBUG 01-05 09:59:21.780930.780930 lmp.py:376]   Expert  7 |     81 | CPU
DEBUG 01-05 09:59:21.780143.780143 lmp.py:376]   Expert 12 |     81 | CPU
DEBUG 01-05 09:59:21.780594.780594 lmp.py:376]   Expert 44 |     81 | CPU
DEBUG 01-05 09:59:21.780568.780568 lmp.py:376]   Expert  6 |     86 | CPU
DEBUG 01-05 09:59:21.780780.780780 lmp.py:376]   Expert 19 |     87 | CPU
DEBUG 01-05 09:59:21.780231.780231 lmp.py:376]   Expert 50 |    101 | CPU
DEBUG 01-05 09:59:21.780205.780205 lmp.py:376]   Expert 56 |    103 | CPU
DEBUG 01-05 09:59:21.780418.780418 lmp.py:376]   Expert 54 |    104 | CPU
DEBUG 01-05 09:59:21.780107.780107 lmp.py:376]   Expert 26 |    108 | CPU
DEBUG 01-05 09:59:21.780511.780511 lmp.py:376]   Expert 38 |    110 | CPU
DEBUG 01-05 09:59:21.780916.780916 lmp.py:376]   Expert 28 |    112 | CPU
DEBUG 01-05 09:59:21.780367.780367 lmp.py:376]   Expert 46 |    114 | CPU
DEBUG 01-05 09:59:21.780102.780102 lmp.py:376]   Expert 20 |    124 | CPU
DEBUG 01-05 09:59:21.780315.780315 lmp.py:376]   Expert 37 |    127 | CPU
DEBUG 01-05 09:59:21.780527.780527 lmp.py:376]   Expert 62 |    129 | CPU
DEBUG 01-05 09:59:21.780025.780025 lmp.py:376]   Expert 43 |    135 | CPU
DEBUG 01-05 09:59:21.780237.780237 lmp.py:376]   Expert 35 |    142 | CPU
DEBUG 01-05 09:59:21.780973.780973 lmp.py:376]   Expert 36 |    148 | CPU
DEBUG 01-05 09:59:21.780947.780947 lmp.py:376]   Expert 52 |    154 | CPU
DEBUG 01-05 09:59:21.780444.780444 lmp.py:376]   Expert 60 |    157 | CPU
DEBUG 01-05 09:59:21.780133.780133 lmp.py:376]   Expert 45 |    161 | CPU
DEBUG 01-05 09:59:21.780346.780346 lmp.py:376]   Expert 29 |    168 | GPU
DEBUG 01-05 09:59:21.780081.780081 lmp.py:376]   Expert 25 |    170 | GPU
DEBUG 01-05 09:59:21.780294.780294 lmp.py:376]   Expert 17 |    173 | GPU
DEBUG 01-05 09:59:21.780791.780791 lmp.py:376]   Expert 41 |    175 | GPU
DEBUG 01-05 09:59:21.780003.780003 lmp.py:376]   Expert 22 |    178 | GPU
DEBUG 01-05 09:59:21.780216.780216 lmp.py:376]   Expert 24 |    181 | GPU
DEBUG 01-05 09:59:21.781190.781190 lmp.py:376]   Expert 51 |    183 | GPU
DEBUG 01-05 09:59:21.781164.781164 lmp.py:376]   Expert  2 |    187 | GPU
DEBUG 01-05 09:59:21.781138.781138 lmp.py:376]   Expert 63 |    194 | GPU
DEBUG 01-05 09:59:21.781112.781112 lmp.py:376]   Expert 42 |    214 | GPU
DEBUG 01-05 09:59:21.781086.781086 lmp.py:376]   Expert 57 |    216 | GPU
DEBUG 01-05 09:59:21.781252.781252 lmp.py:376]   Expert 21 |    228 | GPU
DEBUG 01-05 09:59:21.781418.781418 lmp.py:376]   Expert  5 |    234 | GPU
DEBUG 01-05 09:59:21.781154.781154 lmp.py:376]   Expert 59 |    240 | GPU
DEBUG 01-05 09:59:21.781128.781128 lmp.py:376]   Expert 31 |    244 | GPU
DEBUG 01-05 09:59:21.781864.781864 lmp.py:376]   Expert 18 |    247 | GPU
DEBUG 01-05 09:59:21.781838.781838 lmp.py:376]   Expert 53 |    257 | GPU
DEBUG 01-05 09:59:21.781812.781812 lmp.py:376]   Expert 30 |    261 | GPU
DEBUG 01-05 09:59:21.781309.781309 lmp.py:376]   Expert 39 |    266 | GPU
DEBUG 01-05 09:59:21.781475.781475 lmp.py:376]   Expert 16 |    279 | GPU
DEBUG 01-05 09:59:21.781403.781403 lmp.py:376]   Expert  8 |    295 | GPU
DEBUG 01-05 09:59:21.781377.781377 lmp.py:376]   Expert 10 |    310 | GPU
DEBUG 01-05 09:59:21.781589.781589 lmp.py:376]   Expert  9 |    311 | GPU
DEBUG 01-05 09:59:21.781802.781802 lmp.py:376]   Expert 49 |    354 | GPU
DEBUG 01-05 09:59:21.781537.781537 lmp.py:376]   Expert 33 |    355 | GPU
DEBUG 01-05 09:59:21.781511.781511 lmp.py:376]   Expert 23 |    370 | GPU
DEBUG 01-05 09:59:21.781247.781247 lmp.py:376]   Expert 40 |    420 | GPU
DEBUG 01-05 09:59:21.781460.781460 lmp.py:376]   Expert  0 |    434 | GPU
DEBUG 01-05 09:59:21.781672.781672 lmp.py:376]   Expert 58 |    519 | GPU
DEBUG 01-05 09:59:21.781408.781408 lmp.py:376]   Expert 11 |    520 | GPU
DEBUG 01-05 09:59:21.781335.781335 lmp.py:376]   Expert  1 |    583 | GPU
DEBUG 01-05 09:59:21.781502.781502 lmp.py:376]   Expert  4 |    607 | GPU
DEBUG 01-05 09:59:21.781668.781668 lmp.py:377] 
DEBUG 01-05 09:59:21.781668.781668 lmp.py:377]   CPU total tokens: 2915 (23.7%)
DEBUG 01-05 09:59:21.781834.781834 lmp.py:378]   GPU total tokens: 9373 (76.3%)
DEBUG 01-05 09:59:21.781291.781291 cuda_h.py:19] end experts_map_get cost 0.0015287399291992188 seconds
DEBUG 01-05 09:59:21.781173.781173 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.781526.781526 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.781994.781994 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.782214.782214 cuda_h.py:19] end allocate_cuda_memory cost 0.0012178421020507812 seconds
DEBUG 01-05 09:59:21.782296.782296 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.783098.783098 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.783782.783782 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.783869.783869 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 72d93bca-a8c3-4e95-aec5-57923d2a0be1
DEBUG 01-05 09:59:21.783724.783724 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.783746.783746 client.py:127] Model loaded
DEBUG 01-05 09:59:21.783439.783439 cuda_h.py:19] end sllm_worker_task cost 0.01060628890991211 seconds
INFO 01-05 09:59:21.784144.784144 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 72d93bca-a8c3-4e95-aec5-57923d2a0be1
DEBUG 01-05 09:59:21.785248.785248 cuda_h.py:19] end load_into_gpu_async cost 0.0020918846130371094 seconds
DEBUG 01-05 09:59:21.785926.785926 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.785042.785042 cuda_h.py:19] end restore_tensors2 cost 0.00040793418884277344 seconds
DEBUG 01-05 09:59:21.785693.785693 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00417327880859375 seconds
DEBUG 01-05 09:59:21.788413.788413 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006747007369995117 seconds
DEBUG 01-05 09:59:21.788872.788872 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.788080.788080 lmp.py:423] 
DEBUG 01-05 09:59:21.788080.788080 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.788878.788878 cuda_h.py:19] end cpu_experts_submit cost 0.000152587890625 seconds
DEBUG 01-05 09:59:21.788250.788250 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.804767.804767 mlpmodule.py:704] group tensors cost 0.016169309616088867 s
DEBUG 01-05 09:59:21.807066.807066 mlpmodule.py:742] pad cost 0.0021512508392333984 s
DEBUG 01-05 09:59:21.807104.807104 mlpmodule.py:748] create cpu tensor cost 5.555152893066406e-05 s
DEBUG 01-05 09:59:21.807319.807319 mlpmodule.py:753] move to cpu cost 4.029273986816406e-05 s
DEBUG 01-05 09:59:21.818568.818568 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.818713.818713 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.818419.818419 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 09:59:21.818475.818475 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.835713.835713 mlpmodule.py:793] group einsum cost 0.027514219284057617 s
DEBUG 01-05 09:59:21.836048.836048 mlpmodule.py:801] cpy2cputensor cost 0.0006723403930664062 s
DEBUG 01-05 09:59:21.841762.841762 cuda_h.py:19] end wait_cetm_experts cost 0.05240464210510254 seconds
DEBUG 01-05 09:59:21.841933.841933 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.841060.841060 cuda_h.py:19] end gpu_sexperts cost 0.0005729198455810547 seconds
DEBUG 01-05 09:59:21.841857.841857 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.841521.841521 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:21.841847.841847 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.841748.841748 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 72d93bca-a8c3-4e95-aec5-57923d2a0be1
INFO 01-05 09:59:21.842197.842197 client.py:127] Model loaded
DEBUG 01-05 09:59:21.842371.842371 cuda_h.py:19] end wait_experts cost 0.0009870529174804688 seconds
DEBUG 01-05 09:59:21.842789.842789 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.843876.843876 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.843550.843550 mlpmodule.py:531] gpu group tensors cost 0.0006504058837890625 s
DEBUG 01-05 09:59:21.845243.845243 mlpmodule.py:564] gpu pad cost 0.0018606185913085938 s
DEBUG 01-05 09:59:21.846551.846551 mlpmodule.py:582] gpu group einsum cost 0.0005772113800048828 s
DEBUG 01-05 09:59:21.850629.850629 mlpmodule.py:611] gpu experts func einsum cost 0.006957530975341797 s
DEBUG 01-05 09:59:21.850260.850260 cuda_h.py:19] end gpu_experts cost 0.007304191589355469 seconds
DEBUG 01-05 09:59:21.850117.850117 cuda_h.py:19] end layer_moe_generate_10 cost 0.07125329971313477 seconds
DEBUG 01-05 09:59:21.850661.850661 lmp.py:217] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 09:59:21.850378.850378 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 09:59:21.850366.850366 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:59:21.850274.850274 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:59:21.850886.850886 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.4809112548828125e-05 seconds
DEBUG 01-05 09:59:21.850403.850403 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.842613220214844e-05 seconds
DEBUG 01-05 09:59:21.850768.850768 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.850088.850088 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.851715.851715 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.851836.851836 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.854249.854249 cuda_h.py:19] end allocate_cuda_memory cost 0.003559112548828125 seconds
DEBUG 01-05 09:59:21.854179.854179 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.854247.854247 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.854400.854400 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.854103.854103 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1bdaf8fc-9eb4-479a-8bfa-f2a82dd7b67d
DEBUG 01-05 09:59:21.855311.855311 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.855477.855477 mlpmodule.py:662]  experts func einsum cost 0.06646609306335449 s
DEBUG 01-05 09:59:21.855237.855237 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.855421.855421 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1bdaf8fc-9eb4-479a-8bfa-f2a82dd7b67d
DEBUG 01-05 09:59:21.855893.855893 cuda_h.py:19] end load_into_gpu_async cost 0.001107931137084961 seconds
DEBUG 01-05 09:59:21.856834.856834 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.856155.856155 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 09:59:21.856958.856958 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005027055740356445 seconds
INFO 01-05 09:59:21.856149.856149 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1bdaf8fc-9eb4-479a-8bfa-f2a82dd7b67d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.859428.859428 cuda_h.py:19] end self_attn cost 0.0034279823303222656 seconds
DEBUG 01-05 09:59:21.859896.859896 cuda_h.py:19] end iln_self_attn_paln cost 0.008443832397460938 seconds
DEBUG 01-05 09:59:21.859607.859607 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 09:59:21.859131.859131 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.860604.860604 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-05 09:59:21.860526.860526 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.860178.860178 lmp.py:365] 
DEBUG 01-05 09:59:21.860178.860178 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.860603.860603 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.860253.860253 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.860803.860803 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.860731.860731 lmp.py:369] 
DEBUG 01-05 09:59:21.860731.860731 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.860897.860897 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.860308.860308 lmp.py:376]   Expert 35 |     15 | CPU
DEBUG 01-05 09:59:21.860713.860713 lmp.py:376]   Expert 19 |     17 | CPU
DEBUG 01-05 09:59:21.860164.860164 lmp.py:376]   Expert 39 |     23 | CPU
DEBUG 01-05 09:59:21.860853.860853 lmp.py:376]   Expert 16 |     34 | CPU
DEBUG 01-05 09:59:21.860304.860304 lmp.py:376]   Expert 59 |     38 | CPU
DEBUG 01-05 09:59:21.860662.860662 lmp.py:376]   Expert 49 |     50 | CPU
DEBUG 01-05 09:59:21.860352.860352 lmp.py:376]   Expert 41 |     54 | CPU
DEBUG 01-05 09:59:21.860564.860564 lmp.py:376]   Expert 17 |     58 | CPU
DEBUG 01-05 09:59:21.860538.860538 lmp.py:376]   Expert  5 |     73 | CPU
DEBUG 01-05 09:59:21.860751.860751 lmp.py:376]   Expert  7 |     73 | CPU
DEBUG 01-05 09:59:21.860486.860486 lmp.py:376]   Expert  8 |     76 | CPU
DEBUG 01-05 09:59:21.860460.860460 lmp.py:376]   Expert 15 |     76 | CPU
DEBUG 01-05 09:59:21.860434.860434 lmp.py:376]   Expert  3 |     79 | CPU
DEBUG 01-05 09:59:21.860408.860408 lmp.py:376]   Expert 23 |     82 | CPU
DEBUG 01-05 09:59:21.860621.860621 lmp.py:376]   Expert  0 |     89 | CPU
DEBUG 01-05 09:59:21.860072.860072 lmp.py:376]   Expert  6 |     89 | CPU
DEBUG 01-05 09:59:21.860284.860284 lmp.py:376]   Expert 38 |     94 | CPU
DEBUG 01-05 09:59:21.860450.860450 lmp.py:376]   Expert 44 |     98 | CPU
DEBUG 01-05 09:59:21.860140.860140 lmp.py:376]   Expert 10 |    101 | CPU
DEBUG 01-05 09:59:21.861590.861590 lmp.py:376]   Expert  4 |    105 | CPU
DEBUG 01-05 09:59:21.861565.861565 lmp.py:376]   Expert 46 |    105 | CPU
DEBUG 01-05 09:59:21.861539.861539 lmp.py:376]   Expert 40 |    109 | CPU
DEBUG 01-05 09:59:21.861513.861513 lmp.py:376]   Expert 62 |    111 | CPU
DEBUG 01-05 09:59:21.861248.861248 lmp.py:376]   Expert 63 |    113 | CPU
DEBUG 01-05 09:59:21.861461.861461 lmp.py:376]   Expert 52 |    115 | CPU
DEBUG 01-05 09:59:21.861435.861435 lmp.py:376]   Expert 27 |    123 | CPU
DEBUG 01-05 09:59:21.861555.861555 lmp.py:376]   Expert 32 |    124 | CPU
DEBUG 01-05 09:59:21.861674.861674 lmp.py:376]   Expert 50 |    129 | CPU
DEBUG 01-05 09:59:21.861317.861317 lmp.py:376]   Expert  1 |    133 | CPU
DEBUG 01-05 09:59:21.861483.861483 lmp.py:376]   Expert 60 |    139 | CPU
DEBUG 01-05 09:59:21.861173.861173 lmp.py:376]   Expert 31 |    142 | CPU
DEBUG 01-05 09:59:21.861339.861339 lmp.py:376]   Expert 25 |    143 | CPU
DEBUG 01-05 09:59:21.861028.861028 lmp.py:376]   Expert 48 |    147 | GPU
DEBUG 01-05 09:59:21.861433.861433 lmp.py:376]   Expert 20 |    153 | GPU
DEBUG 01-05 09:59:21.861314.861314 lmp.py:376]   Expert 36 |    157 | GPU
DEBUG 01-05 09:59:21.861719.861719 lmp.py:376]   Expert 51 |    172 | GPU
DEBUG 01-05 09:59:21.861885.861885 lmp.py:376]   Expert 61 |    177 | GPU
DEBUG 01-05 09:59:21.861097.861097 lmp.py:376]   Expert 13 |    178 | GPU
DEBUG 01-05 09:59:21.861263.861263 lmp.py:376]   Expert 57 |    179 | GPU
DEBUG 01-05 09:59:21.861953.861953 lmp.py:376]   Expert 56 |    189 | GPU
DEBUG 01-05 09:59:21.861404.861404 lmp.py:376]   Expert 18 |    191 | GPU
DEBUG 01-05 09:59:21.861616.861616 lmp.py:376]   Expert 42 |    195 | GPU
DEBUG 01-05 09:59:21.861305.861305 lmp.py:376]   Expert  2 |    213 | GPU
DEBUG 01-05 09:59:21.861525.861525 lmp.py:376]   Expert 26 |    215 | GPU
DEBUG 01-05 09:59:21.861452.861452 lmp.py:376]   Expert 43 |    236 | GPU
DEBUG 01-05 09:59:21.861426.861426 lmp.py:376]   Expert 47 |    254 | GPU
DEBUG 01-05 09:59:21.861924.861924 lmp.py:376]   Expert 33 |    261 | GPU
DEBUG 01-05 09:59:21.861659.861659 lmp.py:376]   Expert 53 |    272 | GPU
DEBUG 01-05 09:59:21.861156.861156 lmp.py:376]   Expert 55 |    290 | GPU
DEBUG 01-05 09:59:21.861131.861131 lmp.py:376]   Expert 12 |    291 | GPU
DEBUG 01-05 09:59:21.861628.861628 lmp.py:376]   Expert 58 |    300 | GPU
DEBUG 01-05 09:59:21.861602.861602 lmp.py:376]   Expert 45 |    306 | GPU
DEBUG 01-05 09:59:21.861337.861337 lmp.py:376]   Expert 14 |    309 | GPU
DEBUG 01-05 09:59:21.861265.861265 lmp.py:376]   Expert 29 |    331 | GPU
DEBUG 01-05 09:59:21.861716.861716 lmp.py:376]   Expert 24 |    333 | GPU
DEBUG 01-05 09:59:21.861690.861690 lmp.py:376]   Expert 37 |    343 | GPU
DEBUG 01-05 09:59:21.861187.861187 lmp.py:376]   Expert 34 |    358 | GPU
DEBUG 01-05 09:59:21.861923.861923 lmp.py:376]   Expert 21 |    376 | GPU
DEBUG 01-05 09:59:21.861420.861420 lmp.py:376]   Expert 54 |    376 | GPU
DEBUG 01-05 09:59:21.861917.861917 lmp.py:376]   Expert 28 |    393 | GPU
DEBUG 01-05 09:59:21.861653.861653 lmp.py:376]   Expert  9 |    410 | GPU
DEBUG 01-05 09:59:21.861627.861627 lmp.py:376]   Expert 11 |    427 | GPU
DEBUG 01-05 09:59:21.861124.861124 lmp.py:376]   Expert 22 |    458 | GPU
DEBUG 01-05 09:59:21.861098.861098 lmp.py:376]   Expert 30 |    988 | GPU
DEBUG 01-05 09:59:21.861516.861516 lmp.py:377] 
DEBUG 01-05 09:59:21.861516.861516 lmp.py:377]   CPU total tokens: 2810 (22.9%)
DEBUG 01-05 09:59:21.861159.861159 lmp.py:378]   GPU total tokens: 9478 (77.1%)
DEBUG 01-05 09:59:21.861140.861140 cuda_h.py:19] end experts_map_get cost 0.0015141963958740234 seconds
DEBUG 01-05 09:59:21.861829.861829 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.861275.861275 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.861789.861789 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.863676.863676 cuda_h.py:19] end allocate_cuda_memory cost 0.0013241767883300781 seconds
DEBUG 01-05 09:59:21.863903.863903 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.863420.863420 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.863799.863799 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.863687.863687 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 255bb6ae-3183-47ed-aed7-42a1d8a251b7
DEBUG 01-05 09:59:21.863688.863688 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.863968.863968 client.py:127] Model loaded
DEBUG 01-05 09:59:21.864673.864673 cuda_h.py:19] end sllm_worker_task cost 0.012968778610229492 seconds
INFO 01-05 09:59:21.864545.864545 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 255bb6ae-3183-47ed-aed7-42a1d8a251b7
DEBUG 01-05 09:59:21.864819.864819 cuda_h.py:19] end load_into_gpu_async cost 0.0014147758483886719 seconds
DEBUG 01-05 09:59:21.864522.864522 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.865854.865854 cuda_h.py:19] end restore_tensors2 cost 0.0003941059112548828 seconds
DEBUG 01-05 09:59:21.865935.865935 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034847259521484375 seconds
DEBUG 01-05 09:59:21.867986.867986 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006025075912475586 seconds
DEBUG 01-05 09:59:21.867769.867769 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.867818.867818 lmp.py:423] 
DEBUG 01-05 09:59:21.867818.867818 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.868469.868469 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-05 09:59:21.868430.868430 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.884436.884436 mlpmodule.py:704] group tensors cost 0.01633906364440918 s
DEBUG 01-05 09:59:21.887670.887670 mlpmodule.py:742] pad cost 0.0020971298217773438 s
DEBUG 01-05 09:59:21.887210.887210 mlpmodule.py:748] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-05 09:59:21.887604.887604 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 09:59:21.897766.897766 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.897157.897157 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.898168.898168 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 09:59:21.898994.898994 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.914289.914289 mlpmodule.py:793] group einsum cost 0.026707887649536133 s
DEBUG 01-05 09:59:21.915928.915928 mlpmodule.py:801] cpy2cputensor cost 0.0006384849548339844 s
DEBUG 01-05 09:59:21.920309.920309 cuda_h.py:19] end wait_cetm_experts cost 0.05267739295959473 seconds
DEBUG 01-05 09:59:21.921394.921394 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.921845.921845 cuda_h.py:19] end gpu_sexperts cost 0.0005693435668945312 seconds
DEBUG 01-05 09:59:21.921741.921741 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.921598.921598 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-05 09:59:21.921732.921732 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.921156.921156 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 255bb6ae-3183-47ed-aed7-42a1d8a251b7
INFO 01-05 09:59:21.922936.922936 client.py:127] Model loaded
DEBUG 01-05 09:59:21.922733.922733 cuda_h.py:19] end wait_experts cost 0.0009882450103759766 seconds
DEBUG 01-05 09:59:21.922151.922151 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:21.922715.922715 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:21.923474.923474 mlpmodule.py:531] gpu group tensors cost 0.0006508827209472656 s
DEBUG 01-05 09:59:21.932233.932233 mlpmodule.py:564] gpu pad cost 0.008962154388427734 s
DEBUG 01-05 09:59:21.936405.936405 mlpmodule.py:662]  experts func einsum cost 0.06785941123962402 s
DEBUG 01-05 09:59:21.937043.937043 mlpmodule.py:582] gpu group einsum cost 0.004246711730957031 s
DEBUG 01-05 09:59:21.939624.939624 mlpmodule.py:611] gpu experts func einsum cost 0.016983509063720703 s
DEBUG 01-05 09:59:21.940885.940885 cuda_h.py:19] end gpu_experts cost 0.017156362533569336 seconds
DEBUG 01-05 09:59:21.940252.940252 cuda_h.py:19] end layer_moe_generate_11 cost 0.08057188987731934 seconds
DEBUG 01-05 09:59:21.940596.940596 lmp.py:217] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 09:59:21.940405.940405 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 09:59:21.940625.940625 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:59:21.940665.940665 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:59:21.940899.940899 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:21.940338.940338 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:59:21.940696.940696 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:21.940062.940062 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:21.940285.940285 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.940128.940128 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.941086.941086 cuda_h.py:19] end allocate_cuda_memory cost 0.00027942657470703125 seconds
DEBUG 01-05 09:59:21.941215.941215 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.941607.941607 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.941583.941583 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.941723.941723 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a99471c2-241f-4343-91fe-4129fedd0469
DEBUG 01-05 09:59:21.941164.941164 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:21.941297.941297 cuda_h.py:10] start self_attn
INFO 01-05 09:59:21.942159.942159 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a99471c2-241f-4343-91fe-4129fedd0469
DEBUG 01-05 09:59:21.942347.942347 cuda_h.py:19] end load_into_gpu_async cost 0.0013163089752197266 seconds
DEBUG 01-05 09:59:21.942964.942964 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.942597.942597 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-05 09:59:21.942221.942221 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001985311508178711 seconds
INFO 01-05 09:59:21.943472.943472 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a99471c2-241f-4343-91fe-4129fedd0469
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:21.945402.945402 cuda_h.py:19] end self_attn cost 0.003665924072265625 seconds
DEBUG 01-05 09:59:21.945830.945830 cuda_h.py:19] end iln_self_attn_paln cost 0.005161285400390625 seconds
DEBUG 01-05 09:59:21.945051.945051 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 09:59:21.945290.945290 cuda_h.py:10] start gate
DEBUG 01-05 09:59:21.946902.946902 cuda_h.py:19] end gate cost 0.0006272792816162109 seconds
DEBUG 01-05 09:59:21.946347.946347 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:21.946695.946695 lmp.py:365] 
DEBUG 01-05 09:59:21.946695.946695 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:21.946689.946689 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:21.946339.946339 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:21.946128.946128 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:21.946486.946486 lmp.py:369] 
DEBUG 01-05 09:59:21.946486.946486 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:21.946844.946844 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:21.946163.946163 lmp.py:376]   Expert 51 |      9 | CPU
DEBUG 01-05 09:59:21.946236.946236 lmp.py:376]   Expert 63 |     15 | CPU
DEBUG 01-05 09:59:21.946356.946356 lmp.py:376]   Expert 34 |     23 | CPU
DEBUG 01-05 09:59:21.946237.946237 lmp.py:376]   Expert 47 |     25 | CPU
DEBUG 01-05 09:59:21.946357.946357 lmp.py:376]   Expert 11 |     28 | CPU
DEBUG 01-05 09:59:21.947000.947000 lmp.py:376]   Expert 16 |     29 | CPU
DEBUG 01-05 09:59:21.947120.947120 lmp.py:376]   Expert 22 |     29 | CPU
DEBUG 01-05 09:59:21.947286.947286 lmp.py:376]   Expert 12 |     33 | CPU
DEBUG 01-05 09:59:21.947691.947691 lmp.py:376]   Expert  4 |     42 | CPU
DEBUG 01-05 09:59:21.947618.947618 lmp.py:376]   Expert 44 |     53 | CPU
DEBUG 01-05 09:59:21.947546.947546 lmp.py:376]   Expert  0 |     57 | CPU
DEBUG 01-05 09:59:21.947474.947474 lmp.py:376]   Expert 29 |     63 | CPU
DEBUG 01-05 09:59:21.947402.947402 lmp.py:376]   Expert 27 |     67 | CPU
DEBUG 01-05 09:59:21.947329.947329 lmp.py:376]   Expert 32 |     68 | CPU
DEBUG 01-05 09:59:21.947734.947734 lmp.py:376]   Expert 13 |     71 | CPU
DEBUG 01-05 09:59:21.947138.947138 lmp.py:376]   Expert  8 |     86 | CPU
DEBUG 01-05 09:59:21.947066.947066 lmp.py:376]   Expert 41 |     87 | CPU
DEBUG 01-05 09:59:21.947994.947994 lmp.py:376]   Expert 37 |     89 | CPU
DEBUG 01-05 09:59:21.947683.947683 lmp.py:376]   Expert 23 |     96 | CPU
DEBUG 01-05 09:59:21.947373.947373 lmp.py:376]   Expert 49 |     96 | CPU
DEBUG 01-05 09:59:21.947585.947585 lmp.py:376]   Expert 43 |    106 | CPU
DEBUG 01-05 09:59:21.947513.947513 lmp.py:376]   Expert  2 |    110 | CPU
DEBUG 01-05 09:59:21.947202.947202 lmp.py:376]   Expert 21 |    110 | CPU
DEBUG 01-05 09:59:21.947322.947322 lmp.py:376]   Expert  3 |    134 | CPU
DEBUG 01-05 09:59:21.947203.947203 lmp.py:376]   Expert 39 |    136 | CPU
DEBUG 01-05 09:59:21.947085.947085 lmp.py:376]   Expert 62 |    136 | CPU
DEBUG 01-05 09:59:21.947774.947774 lmp.py:376]   Expert 55 |    145 | CPU
DEBUG 01-05 09:59:21.947702.947702 lmp.py:376]   Expert 14 |    146 | CPU
DEBUG 01-05 09:59:21.947152.947152 lmp.py:376]   Expert 30 |    147 | CPU
DEBUG 01-05 09:59:21.947080.947080 lmp.py:376]   Expert  7 |    148 | CPU
DEBUG 01-05 09:59:21.947770.947770 lmp.py:376]   Expert 42 |    157 | CPU
DEBUG 01-05 09:59:21.947936.947936 lmp.py:376]   Expert 61 |    161 | CPU
DEBUG 01-05 09:59:21.947102.947102 lmp.py:376]   Expert 58 |    169 | GPU
DEBUG 01-05 09:59:21.947506.947506 lmp.py:376]   Expert 45 |    188 | GPU
DEBUG 01-05 09:59:21.947196.947196 lmp.py:376]   Expert 18 |    189 | GPU
DEBUG 01-05 09:59:21.947885.947885 lmp.py:376]   Expert 53 |    189 | GPU
DEBUG 01-05 09:59:21.947574.947574 lmp.py:376]   Expert 31 |    192 | GPU
DEBUG 01-05 09:59:21.947502.947502 lmp.py:376]   Expert  5 |    194 | GPU
DEBUG 01-05 09:59:21.947953.947953 lmp.py:376]   Expert 38 |    197 | GPU
DEBUG 01-05 09:59:21.947404.947404 lmp.py:376]   Expert 17 |    211 | GPU
DEBUG 01-05 09:59:21.947093.947093 lmp.py:376]   Expert  6 |    215 | GPU
DEBUG 01-05 09:59:21.947021.947021 lmp.py:376]   Expert 35 |    220 | GPU
DEBUG 01-05 09:59:21.947187.947187 lmp.py:376]   Expert  1 |    227 | GPU
DEBUG 01-05 09:59:21.947876.947876 lmp.py:376]   Expert 20 |    241 | GPU
DEBUG 01-05 09:59:21.947850.947850 lmp.py:376]   Expert 19 |    242 | GPU
DEBUG 01-05 09:59:21.947301.947301 lmp.py:376]   Expert 50 |    243 | GPU
DEBUG 01-05 09:59:21.947752.947752 lmp.py:376]   Expert 46 |    245 | GPU
DEBUG 01-05 09:59:21.947964.947964 lmp.py:376]   Expert 57 |    258 | GPU
DEBUG 01-05 09:59:21.947177.947177 lmp.py:376]   Expert 52 |    277 | GPU
DEBUG 01-05 09:59:21.947628.947628 lmp.py:376]   Expert 59 |    281 | GPU
DEBUG 01-05 09:59:21.947079.947079 lmp.py:376]   Expert 26 |    299 | GPU
DEBUG 01-05 09:59:21.947245.947245 lmp.py:376]   Expert 48 |    310 | GPU
DEBUG 01-05 09:59:21.947457.947457 lmp.py:376]   Expert 25 |    311 | GPU
DEBUG 01-05 09:59:21.947147.947147 lmp.py:376]   Expert 54 |    315 | GPU
DEBUG 01-05 09:59:21.947836.947836 lmp.py:376]   Expert 28 |    317 | GPU
DEBUG 01-05 09:59:21.947287.947287 lmp.py:376]   Expert 60 |    323 | GPU
DEBUG 01-05 09:59:21.947738.947738 lmp.py:376]   Expert 24 |    336 | GPU
DEBUG 01-05 09:59:21.947427.947427 lmp.py:376]   Expert 36 |    345 | GPU
DEBUG 01-05 09:59:21.947878.947878 lmp.py:376]   Expert 40 |    392 | GPU
DEBUG 01-05 09:59:21.947329.947329 lmp.py:376]   Expert 33 |    419 | GPU
DEBUG 01-05 09:59:21.947495.947495 lmp.py:376]   Expert  9 |    451 | GPU
DEBUG 01-05 09:59:21.947138.947138 lmp.py:376]   Expert 15 |    526 | GPU
DEBUG 01-05 09:59:21.947589.947589 lmp.py:376]   Expert 56 |    537 | GPU
DEBUG 01-05 09:59:21.947278.947278 lmp.py:376]   Expert 10 |    727 | GPU
DEBUG 01-05 09:59:21.948683.948683 lmp.py:377] 
DEBUG 01-05 09:59:21.948683.948683 lmp.py:377]   CPU total tokens: 2702 (22.0%)
DEBUG 01-05 09:59:21.948326.948326 lmp.py:378]   GPU total tokens: 9586 (78.0%)
DEBUG 01-05 09:59:21.948214.948214 cuda_h.py:19] end experts_map_get cost 0.0015239715576171875 seconds
DEBUG 01-05 09:59:21.948049.948049 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:21.948209.948209 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:21.948492.948492 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:21.949008.949008 cuda_h.py:19] end allocate_cuda_memory cost 0.0013301372528076172 seconds
DEBUG 01-05 09:59:21.949156.949156 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:21.949257.949257 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:21.949543.949543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:21.949167.949167 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1aa15967-94af-49e2-bc4f-afab653f8a28
DEBUG 01-05 09:59:21.950339.950339 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:21.950239.950239 client.py:127] Model loaded
DEBUG 01-05 09:59:21.950241.950241 cuda_h.py:19] end sllm_worker_task cost 0.009769439697265625 seconds
INFO 01-05 09:59:21.950908.950908 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1aa15967-94af-49e2-bc4f-afab653f8a28
DEBUG 01-05 09:59:21.951241.951241 cuda_h.py:19] end load_into_gpu_async cost 0.0013225078582763672 seconds
DEBUG 01-05 09:59:21.951090.951090 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:21.951143.951143 cuda_h.py:19] end restore_tensors2 cost 0.00036334991455078125 seconds
DEBUG 01-05 09:59:21.951787.951787 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003387928009033203 seconds
DEBUG 01-05 09:59:21.954250.954250 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005985260009765625 seconds
DEBUG 01-05 09:59:21.954225.954225 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:21.954612.954612 lmp.py:423] 
DEBUG 01-05 09:59:21.954612.954612 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:21.954860.954860 cuda_h.py:19] end cpu_experts_submit cost 0.00012493133544921875 seconds
DEBUG 01-05 09:59:21.954801.954801 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:21.965874.965874 mlpmodule.py:704] group tensors cost 0.01047658920288086 s
DEBUG 01-05 09:59:21.967678.967678 mlpmodule.py:742] pad cost 0.0016353130340576172 s
DEBUG 01-05 09:59:21.967820.967820 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-05 09:59:21.967498.967498 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:59:21.976850.976850 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:21.976180.976180 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:21.977064.977064 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 09:59:21.977366.977366 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:21.993681.993681 mlpmodule.py:793] group einsum cost 0.025928497314453125 s
DEBUG 01-05 09:59:21.994313.994313 mlpmodule.py:801] cpy2cputensor cost 0.0006799697875976562 s
DEBUG 01-05 09:59:21.998266.998266 cuda_h.py:19] end wait_cetm_experts cost 0.044471025466918945 seconds
DEBUG 01-05 09:59:21.999768.999768 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:21.999981.999981 cuda_h.py:19] end gpu_sexperts cost 0.0005702972412109375 seconds
DEBUG 01-05 09:59:21.999831.999831 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:21.999018.999018 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-05 09:59:21.999390.999390 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:21.999577.999577 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1aa15967-94af-49e2-bc4f-afab653f8a28
INFO 01-05 09:59:22.006114.006114 client.py:127] Model loaded
DEBUG 01-05 09:59:22.006348.006348 cuda_h.py:19] end wait_experts cost 0.006819725036621094 seconds
DEBUG 01-05 09:59:22.006389.006389 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.006621.006621 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.007613.007613 mlpmodule.py:531] gpu group tensors cost 0.0006456375122070312 s
DEBUG 01-05 09:59:22.009804.009804 mlpmodule.py:564] gpu pad cost 0.001699209213256836 s
DEBUG 01-05 09:59:22.009200.009200 mlpmodule.py:582] gpu group einsum cost 0.00047278404235839844 s
DEBUG 01-05 09:59:22.012466.012466 mlpmodule.py:611] gpu experts func einsum cost 0.005944490432739258 s
DEBUG 01-05 09:59:22.012893.012893 cuda_h.py:19] end gpu_experts cost 0.0061359405517578125 seconds
DEBUG 01-05 09:59:22.012101.012101 cuda_h.py:19] end layer_moe_generate_12 cost 0.06714057922363281 seconds
DEBUG 01-05 09:59:22.013001.013001 lmp.py:217] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 09:59:22.013578.013578 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 09:59:22.013513.013513 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:59:22.013838.013838 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:59:22.013721.013721 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.8371810913085938e-05 seconds
DEBUG 01-05 09:59:22.013014.013014 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.295608520507812e-05 seconds
DEBUG 01-05 09:59:22.013134.013134 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.013592.013592 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.013430.013430 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.013412.013412 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.017653.017653 cuda_h.py:19] end allocate_cuda_memory cost 0.0043621063232421875 seconds
DEBUG 01-05 09:59:22.018718.018718 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.018288.018288 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.018588.018588 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.018218.018218 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea08ced6-904f-49eb-b5c2-959193ad946a
DEBUG 01-05 09:59:22.018811.018811 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.018441.018441 mlpmodule.py:662]  experts func einsum cost 0.0640103816986084 s
DEBUG 01-05 09:59:22.018287.018287 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.019363.019363 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea08ced6-904f-49eb-b5c2-959193ad946a
DEBUG 01-05 09:59:22.019537.019537 cuda_h.py:19] end load_into_gpu_async cost 0.0010938644409179688 seconds
DEBUG 01-05 09:59:22.019286.019286 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.019839.019839 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-05 09:59:22.019641.019641 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005879640579223633 seconds
INFO 01-05 09:59:22.019381.019381 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea08ced6-904f-49eb-b5c2-959193ad946a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.022475.022475 cuda_h.py:19] end self_attn cost 0.0033380985260009766 seconds
DEBUG 01-05 09:59:22.022703.022703 cuda_h.py:19] end iln_self_attn_paln cost 0.00927281379699707 seconds
DEBUG 01-05 09:59:22.022685.022685 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 09:59:22.022316.022316 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.023550.023550 cuda_h.py:19] end gate cost 0.0006296634674072266 seconds
DEBUG 01-05 09:59:22.023479.023479 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.023111.023111 lmp.py:365] 
DEBUG 01-05 09:59:22.023111.023111 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.023437.023437 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.023848.023848 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.023399.023399 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.023803.023803 lmp.py:369] 
DEBUG 01-05 09:59:22.023803.023803 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.023969.023969 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.023381.023381 lmp.py:376]   Expert  6 |     11 | CPU
DEBUG 01-05 09:59:22.023785.023785 lmp.py:376]   Expert 53 |     13 | CPU
DEBUG 01-05 09:59:22.023998.023998 lmp.py:376]   Expert 19 |     19 | CPU
DEBUG 01-05 09:59:22.023210.023210 lmp.py:376]   Expert 50 |     26 | CPU
DEBUG 01-05 09:59:22.023899.023899 lmp.py:376]   Expert 26 |     42 | CPU
DEBUG 01-05 09:59:22.023304.023304 lmp.py:376]   Expert  2 |     47 | CPU
DEBUG 01-05 09:59:22.023470.023470 lmp.py:376]   Expert  0 |     55 | CPU
DEBUG 01-05 09:59:22.023444.023444 lmp.py:376]   Expert  8 |     65 | CPU
DEBUG 01-05 09:59:22.023418.023418 lmp.py:376]   Expert 12 |     68 | CPU
DEBUG 01-05 09:59:22.023915.023915 lmp.py:376]   Expert 31 |     82 | CPU
DEBUG 01-05 09:59:22.024651.024651 lmp.py:376]   Expert 20 |     88 | CPU
DEBUG 01-05 09:59:22.024148.024148 lmp.py:376]   Expert 16 |     90 | CPU
DEBUG 01-05 09:59:22.024884.024884 lmp.py:376]   Expert 40 |     94 | CPU
DEBUG 01-05 09:59:22.024619.024619 lmp.py:376]   Expert 32 |    102 | CPU
DEBUG 01-05 09:59:22.024355.024355 lmp.py:376]   Expert 30 |    107 | CPU
DEBUG 01-05 09:59:22.024806.024806 lmp.py:376]   Expert 28 |    113 | CPU
DEBUG 01-05 09:59:22.024018.024018 lmp.py:376]   Expert 35 |    116 | CPU
DEBUG 01-05 09:59:22.024992.024992 lmp.py:376]   Expert 61 |    116 | CPU
DEBUG 01-05 09:59:22.024966.024966 lmp.py:376]   Expert 63 |    117 | CPU
DEBUG 01-05 09:59:22.024464.024464 lmp.py:376]   Expert 48 |    123 | CPU
DEBUG 01-05 09:59:22.024722.024722 lmp.py:376]   Expert 18 |    125 | CPU
DEBUG 01-05 09:59:22.024220.024220 lmp.py:376]   Expert 13 |    126 | CPU
DEBUG 01-05 09:59:22.024717.024717 lmp.py:376]   Expert 57 |    127 | CPU
DEBUG 01-05 09:59:22.024214.024214 lmp.py:376]   Expert 60 |    129 | CPU
DEBUG 01-05 09:59:22.024380.024380 lmp.py:376]   Expert 34 |    134 | CPU
DEBUG 01-05 09:59:22.024070.024070 lmp.py:376]   Expert 11 |    135 | CPU
DEBUG 01-05 09:59:22.024044.024044 lmp.py:376]   Expert  5 |    140 | CPU
DEBUG 01-05 09:59:22.024018.024018 lmp.py:376]   Expert 24 |    145 | CPU
DEBUG 01-05 09:59:22.024515.024515 lmp.py:376]   Expert 52 |    153 | CPU
DEBUG 01-05 09:59:22.024489.024489 lmp.py:376]   Expert  9 |    157 | CPU
DEBUG 01-05 09:59:22.024748.024748 lmp.py:376]   Expert 58 |    161 | CPU
DEBUG 01-05 09:59:22.024152.024152 lmp.py:376]   Expert 45 |    171 | CPU
DEBUG 01-05 09:59:22.024318.024318 lmp.py:376]   Expert  3 |    177 | GPU
DEBUG 01-05 09:59:22.024769.024769 lmp.py:376]   Expert 25 |    177 | GPU
DEBUG 01-05 09:59:22.024850.024850 lmp.py:376]   Expert 37 |    177 | GPU
DEBUG 01-05 09:59:22.024539.024539 lmp.py:376]   Expert 42 |    184 | GPU
DEBUG 01-05 09:59:22.024182.024182 lmp.py:376]   Expert  4 |    201 | GPU
DEBUG 01-05 09:59:22.024825.024825 lmp.py:376]   Expert 17 |    206 | GPU
DEBUG 01-05 09:59:22.024991.024991 lmp.py:376]   Expert 46 |    208 | GPU
DEBUG 01-05 09:59:22.024442.024442 lmp.py:376]   Expert  7 |    215 | GPU
DEBUG 01-05 09:59:22.024654.024654 lmp.py:376]   Expert 27 |    221 | GPU
DEBUG 01-05 09:59:22.024344.024344 lmp.py:376]   Expert 33 |    227 | GPU
DEBUG 01-05 09:59:22.024033.024033 lmp.py:376]   Expert 39 |    229 | GPU
DEBUG 01-05 09:59:22.024722.024722 lmp.py:376]   Expert 51 |    229 | GPU
DEBUG 01-05 09:59:22.024173.024173 lmp.py:376]   Expert 22 |    230 | GPU
DEBUG 01-05 09:59:22.024624.024624 lmp.py:376]   Expert 43 |    231 | GPU
DEBUG 01-05 09:59:22.024313.024313 lmp.py:376]   Expert 62 |    236 | GPU
DEBUG 01-05 09:59:22.024479.024479 lmp.py:376]   Expert 49 |    251 | GPU
DEBUG 01-05 09:59:22.024646.024646 lmp.py:376]   Expert 54 |    254 | GPU
DEBUG 01-05 09:59:22.024573.024573 lmp.py:376]   Expert  1 |    261 | GPU
DEBUG 01-05 09:59:22.024786.024786 lmp.py:376]   Expert 36 |    273 | GPU
DEBUG 01-05 09:59:22.024998.024998 lmp.py:376]   Expert 44 |    273 | GPU
DEBUG 01-05 09:59:22.024449.024449 lmp.py:376]   Expert 29 |    275 | GPU
DEBUG 01-05 09:59:22.024138.024138 lmp.py:376]   Expert 59 |    304 | GPU
DEBUG 01-05 09:59:22.024781.024781 lmp.py:376]   Expert 47 |    320 | GPU
DEBUG 01-05 09:59:22.024947.024947 lmp.py:376]   Expert 15 |    326 | GPU
DEBUG 01-05 09:59:22.024398.024398 lmp.py:376]   Expert 38 |    337 | GPU
DEBUG 01-05 09:59:22.024088.024088 lmp.py:376]   Expert 23 |    392 | GPU
DEBUG 01-05 09:59:22.024539.024539 lmp.py:376]   Expert 14 |    394 | GPU
DEBUG 01-05 09:59:22.024989.024989 lmp.py:376]   Expert 55 |    398 | GPU
DEBUG 01-05 09:59:22.024440.024440 lmp.py:376]   Expert 41 |    404 | GPU
DEBUG 01-05 09:59:22.024891.024891 lmp.py:376]   Expert 21 |    417 | GPU
DEBUG 01-05 09:59:22.024342.024342 lmp.py:376]   Expert 10 |    465 | GPU
DEBUG 01-05 09:59:22.024793.024793 lmp.py:376]   Expert 56 |    599 | GPU
DEBUG 01-05 09:59:22.024436.024436 lmp.py:377] 
DEBUG 01-05 09:59:22.024436.024436 lmp.py:377]   CPU total tokens: 3197 (26.0%)
DEBUG 01-05 09:59:22.024271.024271 lmp.py:378]   GPU total tokens: 9091 (74.0%)
DEBUG 01-05 09:59:22.024874.024874 cuda_h.py:19] end experts_map_get cost 0.0014920234680175781 seconds
DEBUG 01-05 09:59:22.024994.024994 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.025916.025916 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.025345.025345 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.026665.026665 cuda_h.py:19] end allocate_cuda_memory cost 0.0014331340789794922 seconds
DEBUG 01-05 09:59:22.026509.026509 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.026741.026741 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.026789.026789 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.026392.026392 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 28828821-d996-4bd4-b9bb-351142983cf6
DEBUG 01-05 09:59:22.026988.026988 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.027157.027157 client.py:127] Model loaded
DEBUG 01-05 09:59:22.027014.027014 cuda_h.py:19] end sllm_worker_task cost 0.013883590698242188 seconds
INFO 01-05 09:59:22.028964.028964 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 28828821-d996-4bd4-b9bb-351142983cf6
DEBUG 01-05 09:59:22.028192.028192 cuda_h.py:19] end load_into_gpu_async cost 0.0013833045959472656 seconds
DEBUG 01-05 09:59:22.028656.028656 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.028127.028127 cuda_h.py:19] end restore_tensors2 cost 0.00039076805114746094 seconds
DEBUG 01-05 09:59:22.028871.028871 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035600662231445312 seconds
DEBUG 01-05 09:59:22.031531.031531 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0061283111572265625 seconds
DEBUG 01-05 09:59:22.031454.031454 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.031979.031979 lmp.py:423] 
DEBUG 01-05 09:59:22.031979.031979 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.031180.031180 cuda_h.py:19] end cpu_experts_submit cost 0.00012254714965820312 seconds
DEBUG 01-05 09:59:22.031168.031168 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.036227.036227 mlpmodule.py:704] group tensors cost 0.005100727081298828 s
DEBUG 01-05 09:59:22.039449.039449 mlpmodule.py:742] pad cost 0.0020694732666015625 s
DEBUG 01-05 09:59:22.039487.039487 mlpmodule.py:748] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-05 09:59:22.039371.039371 mlpmodule.py:753] move to cpu cost 3.719329833984375e-05 s
DEBUG 01-05 09:59:22.049917.049917 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.049500.049500 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.049251.049251 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 09:59:22.049792.049792 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.065650.065650 mlpmodule.py:793] group einsum cost 0.026238203048706055 s
DEBUG 01-05 09:59:22.066321.066321 mlpmodule.py:801] cpy2cputensor cost 0.0006825923919677734 s
DEBUG 01-05 09:59:22.071651.071651 cuda_h.py:19] end wait_cetm_experts cost 0.03984832763671875 seconds
DEBUG 01-05 09:59:22.071213.071213 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.072571.072571 cuda_h.py:19] end gpu_sexperts cost 0.0005710124969482422 seconds
DEBUG 01-05 09:59:22.072752.072752 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.072132.072132 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-05 09:59:22.072980.072980 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.072644.072644 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 28828821-d996-4bd4-b9bb-351142983cf6
INFO 01-05 09:59:22.084489.084489 client.py:127] Model loaded
DEBUG 01-05 09:59:22.084984.084984 cuda_h.py:19] end wait_experts cost 0.011928319931030273 seconds
DEBUG 01-05 09:59:22.084185.084185 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.084970.084970 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.085397.085397 mlpmodule.py:531] gpu group tensors cost 0.0005793571472167969 s
DEBUG 01-05 09:59:22.086834.086834 mlpmodule.py:564] gpu pad cost 0.0015306472778320312 s
DEBUG 01-05 09:59:22.087822.087822 mlpmodule.py:582] gpu group einsum cost 0.0005323886871337891 s
DEBUG 01-05 09:59:22.089571.089571 mlpmodule.py:662]  experts func einsum cost 0.057938337326049805 s
DEBUG 01-05 09:59:22.090872.090872 mlpmodule.py:611] gpu experts func einsum cost 0.006046772003173828 s
DEBUG 01-05 09:59:22.090492.090492 cuda_h.py:19] end gpu_experts cost 0.006340503692626953 seconds
DEBUG 01-05 09:59:22.090224.090224 cuda_h.py:19] end layer_moe_generate_13 cost 0.06806325912475586 seconds
DEBUG 01-05 09:59:22.090177.090177 lmp.py:217] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 09:59:22.090032.090032 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 09:59:22.090013.090013 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:59:22.091577.091577 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:59:22.091989.091989 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:59:22.091977.091977 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.222724914550781e-05 seconds
DEBUG 01-05 09:59:22.091574.091574 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.091835.091835 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.091540.091540 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.091569.091569 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.091252.091252 cuda_h.py:19] end allocate_cuda_memory cost 0.00038051605224609375 seconds
DEBUG 01-05 09:59:22.091175.091175 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.091461.091461 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.091754.091754 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.091026.091026 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fe1c7540-63cc-4355-b236-68613528d79e
DEBUG 01-05 09:59:22.092519.092519 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.092334.092334 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.093944.093944 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fe1c7540-63cc-4355-b236-68613528d79e
DEBUG 01-05 09:59:22.093106.093106 cuda_h.py:19] end load_into_gpu_async cost 0.0012445449829101562 seconds
DEBUG 01-05 09:59:22.093438.093438 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.093356.093356 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-05 09:59:22.093391.093391 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020287036895751953 seconds
INFO 01-05 09:59:22.093244.093244 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fe1c7540-63cc-4355-b236-68613528d79e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.096430.096430 cuda_h.py:19] end self_attn cost 0.003975868225097656 seconds
DEBUG 01-05 09:59:22.096315.096315 cuda_h.py:19] end iln_self_attn_paln cost 0.005503654479980469 seconds
DEBUG 01-05 09:59:22.096966.096966 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 09:59:22.096159.096159 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.097725.097725 cuda_h.py:19] end gate cost 0.0006272792816162109 seconds
DEBUG 01-05 09:59:22.097885.097885 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.097140.097140 lmp.py:365] 
DEBUG 01-05 09:59:22.097140.097140 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.097942.097942 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.097361.097361 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.097388.097388 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.097845.097845 lmp.py:369] 
DEBUG 01-05 09:59:22.097845.097845 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.097250.097250 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.097615.097615 lmp.py:376]   Expert 61 |      9 | CPU
DEBUG 01-05 09:59:22.097258.097258 lmp.py:376]   Expert  7 |     15 | CPU
DEBUG 01-05 09:59:22.097947.097947 lmp.py:376]   Expert 59 |     37 | CPU
DEBUG 01-05 09:59:22.097398.097398 lmp.py:376]   Expert 34 |     54 | CPU
DEBUG 01-05 09:59:22.097611.097611 lmp.py:376]   Expert 48 |     55 | CPU
DEBUG 01-05 09:59:22.097061.097061 lmp.py:376]   Expert 50 |     57 | CPU
DEBUG 01-05 09:59:22.097704.097704 lmp.py:376]   Expert 38 |     63 | CPU
DEBUG 01-05 09:59:22.098155.098155 lmp.py:376]   Expert 49 |     67 | CPU
DEBUG 01-05 09:59:22.098129.098129 lmp.py:376]   Expert 40 |     68 | CPU
DEBUG 01-05 09:59:22.098103.098103 lmp.py:376]   Expert 55 |     68 | CPU
DEBUG 01-05 09:59:22.098077.098077 lmp.py:376]   Expert 32 |     75 | CPU
DEBUG 01-05 09:59:22.098290.098290 lmp.py:376]   Expert 43 |     95 | CPU
DEBUG 01-05 09:59:22.098502.098502 lmp.py:376]   Expert 44 |    104 | CPU
DEBUG 01-05 09:59:22.098476.098476 lmp.py:376]   Expert 18 |    107 | CPU
DEBUG 01-05 09:59:22.098450.098450 lmp.py:376]   Expert  0 |    108 | CPU
DEBUG 01-05 09:59:22.098901.098901 lmp.py:376]   Expert 35 |    108 | CPU
DEBUG 01-05 09:59:22.098875.098875 lmp.py:376]   Expert 29 |    111 | CPU
DEBUG 01-05 09:59:22.098088.098088 lmp.py:376]   Expert 23 |    112 | CPU
DEBUG 01-05 09:59:22.098062.098062 lmp.py:376]   Expert 39 |    112 | CPU
DEBUG 01-05 09:59:22.098036.098036 lmp.py:376]   Expert  8 |    113 | CPU
DEBUG 01-05 09:59:22.098010.098010 lmp.py:376]   Expert 60 |    113 | CPU
DEBUG 01-05 09:59:22.098746.098746 lmp.py:376]   Expert 20 |    121 | CPU
DEBUG 01-05 09:59:22.098720.098720 lmp.py:376]   Expert 28 |    121 | CPU
DEBUG 01-05 09:59:22.098694.098694 lmp.py:376]   Expert 51 |    124 | CPU
DEBUG 01-05 09:59:22.098429.098429 lmp.py:376]   Expert 17 |    131 | CPU
DEBUG 01-05 09:59:22.098403.098403 lmp.py:376]   Expert 41 |    132 | CPU
DEBUG 01-05 09:59:22.098331.098331 lmp.py:376]   Expert 21 |    139 | CPU
DEBUG 01-05 09:59:22.098305.098305 lmp.py:376]   Expert 54 |    140 | CPU
DEBUG 01-05 09:59:22.098279.098279 lmp.py:376]   Expert 12 |    153 | CPU
DEBUG 01-05 09:59:22.098399.098399 lmp.py:376]   Expert 45 |    173 | CPU
DEBUG 01-05 09:59:22.098327.098327 lmp.py:376]   Expert 42 |    181 | CPU
DEBUG 01-05 09:59:22.098778.098778 lmp.py:376]   Expert 52 |    181 | CPU
DEBUG 01-05 09:59:22.098467.098467 lmp.py:376]   Expert 57 |    181 | GPU
DEBUG 01-05 09:59:22.098825.098825 lmp.py:376]   Expert 62 |    192 | GPU
DEBUG 01-05 09:59:22.098753.098753 lmp.py:376]   Expert  6 |    197 | GPU
DEBUG 01-05 09:59:22.098442.098442 lmp.py:376]   Expert 31 |    202 | GPU
DEBUG 01-05 09:59:22.098370.098370 lmp.py:376]   Expert  3 |    210 | GPU
DEBUG 01-05 09:59:22.098821.098821 lmp.py:376]   Expert 13 |    212 | GPU
DEBUG 01-05 09:59:22.098987.098987 lmp.py:376]   Expert 30 |    213 | GPU
DEBUG 01-05 09:59:22.098676.098676 lmp.py:376]   Expert 11 |    225 | GPU
DEBUG 01-05 09:59:22.098604.098604 lmp.py:376]   Expert 36 |    225 | GPU
DEBUG 01-05 09:59:22.098293.098293 lmp.py:376]   Expert 14 |    226 | GPU
DEBUG 01-05 09:59:22.098559.098559 lmp.py:376]   Expert 26 |    228 | GPU
DEBUG 01-05 09:59:22.098771.098771 lmp.py:376]   Expert 46 |    231 | GPU
DEBUG 01-05 09:59:22.098507.098507 lmp.py:376]   Expert 19 |    232 | GPU
DEBUG 01-05 09:59:22.098004.098004 lmp.py:376]   Expert 27 |    253 | GPU
DEBUG 01-05 09:59:22.098740.098740 lmp.py:376]   Expert  2 |    265 | GPU
DEBUG 01-05 09:59:22.098475.098475 lmp.py:376]   Expert 22 |    269 | GPU
DEBUG 01-05 09:59:22.098449.098449 lmp.py:376]   Expert  4 |    274 | GPU
DEBUG 01-05 09:59:22.098947.098947 lmp.py:376]   Expert  5 |    283 | GPU
DEBUG 01-05 09:59:22.098682.098682 lmp.py:376]   Expert 37 |    289 | GPU
DEBUG 01-05 09:59:22.098372.098372 lmp.py:376]   Expert 33 |    290 | GPU
DEBUG 01-05 09:59:22.098445.098445 lmp.py:376]   Expert 56 |    296 | GPU
DEBUG 01-05 09:59:22.098657.098657 lmp.py:376]   Expert  1 |    303 | GPU
DEBUG 01-05 09:59:22.098393.098393 lmp.py:376]   Expert 53 |    305 | GPU
DEBUG 01-05 09:59:22.098367.098367 lmp.py:376]   Expert 58 |    310 | GPU
DEBUG 01-05 09:59:22.098864.098864 lmp.py:376]   Expert 16 |    319 | GPU
DEBUG 01-05 09:59:22.098600.098600 lmp.py:376]   Expert 10 |    338 | GPU
DEBUG 01-05 09:59:22.098097.098097 lmp.py:376]   Expert 63 |    354 | GPU
DEBUG 01-05 09:59:22.098833.098833 lmp.py:376]   Expert 47 |    382 | GPU
DEBUG 01-05 09:59:22.098330.098330 lmp.py:376]   Expert 15 |    384 | GPU
DEBUG 01-05 09:59:22.098066.098066 lmp.py:376]   Expert 24 |    386 | GPU
DEBUG 01-05 09:59:22.098993.098993 lmp.py:376]   Expert 25 |    475 | GPU
DEBUG 01-05 09:59:22.098729.098729 lmp.py:376]   Expert  9 |    492 | GPU
DEBUG 01-05 09:59:22.098180.098180 lmp.py:377] 
DEBUG 01-05 09:59:22.098180.098180 lmp.py:377]   CPU total tokens: 3247 (26.4%)
DEBUG 01-05 09:59:22.098108.098108 lmp.py:378]   GPU total tokens: 9041 (73.6%)
DEBUG 01-05 09:59:22.098612.098612 cuda_h.py:19] end experts_map_get cost 0.0014908313751220703 seconds
DEBUG 01-05 09:59:22.098778.098778 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.099031.099031 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.099784.099784 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.099109.099109 cuda_h.py:19] end allocate_cuda_memory cost 0.00038361549377441406 seconds
DEBUG 01-05 09:59:22.099250.099250 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.099974.099974 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.099419.099419 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.099082.099082 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d6f61e7f-cd42-419b-aa42-3b349ef6b45b
DEBUG 01-05 09:59:22.099407.099407 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.100541.100541 client.py:127] Model loaded
DEBUG 01-05 09:59:22.100782.100782 cuda_h.py:19] end sllm_worker_task cost 0.008996009826660156 seconds
INFO 01-05 09:59:22.101843.101843 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d6f61e7f-cd42-419b-aa42-3b349ef6b45b
DEBUG 01-05 09:59:22.101117.101117 cuda_h.py:19] end load_into_gpu_async cost 0.0015087127685546875 seconds
DEBUG 01-05 09:59:22.101535.101535 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.101495.101495 cuda_h.py:19] end restore_tensors2 cost 0.00036525726318359375 seconds
DEBUG 01-05 09:59:22.101331.101331 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002622365951538086 seconds
DEBUG 01-05 09:59:22.104033.104033 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005218982696533203 seconds
DEBUG 01-05 09:59:22.104385.104385 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.104342.104342 lmp.py:423] 
DEBUG 01-05 09:59:22.104342.104342 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.104841.104841 cuda_h.py:19] end cpu_experts_submit cost 0.0001323223114013672 seconds
DEBUG 01-05 09:59:22.104736.104736 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.109365.109365 mlpmodule.py:704] group tensors cost 0.005318641662597656 s
DEBUG 01-05 09:59:22.112343.112343 mlpmodule.py:742] pad cost 0.002073049545288086 s
DEBUG 01-05 09:59:22.112242.112242 mlpmodule.py:748] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-05 09:59:22.112503.112503 mlpmodule.py:753] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-05 09:59:22.122967.122967 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.122152.122152 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.122128.122128 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 09:59:22.123212.123212 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.140268.140268 mlpmodule.py:793] group einsum cost 0.02789449691772461 s
DEBUG 01-05 09:59:22.141771.141771 mlpmodule.py:801] cpy2cputensor cost 0.0007557868957519531 s
DEBUG 01-05 09:59:22.146656.146656 cuda_h.py:19] end wait_cetm_experts cost 0.04181981086730957 seconds
DEBUG 01-05 09:59:22.146072.146072 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.147099.147099 cuda_h.py:19] end gpu_sexperts cost 0.0005757808685302734 seconds
DEBUG 01-05 09:59:22.147942.147942 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.147229.147229 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:59:22.147078.147078 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.147788.147788 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d6f61e7f-cd42-419b-aa42-3b349ef6b45b
INFO 01-05 09:59:22.156494.156494 client.py:127] Model loaded
DEBUG 01-05 09:59:22.156158.156158 cuda_h.py:19] end wait_experts cost 0.009087324142456055 seconds
DEBUG 01-05 09:59:22.156146.156146 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.156087.156087 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.157862.157862 mlpmodule.py:531] gpu group tensors cost 0.0005304813385009766 s
DEBUG 01-05 09:59:22.157140.157140 mlpmodule.py:662]  experts func einsum cost 0.05321311950683594 s
DEBUG 01-05 09:59:22.158672.158672 mlpmodule.py:564] gpu pad cost 0.0017635822296142578 s
DEBUG 01-05 09:59:22.159202.159202 mlpmodule.py:582] gpu group einsum cost 0.0004699230194091797 s
DEBUG 01-05 09:59:22.162291.162291 mlpmodule.py:611] gpu experts func einsum cost 0.0058329105377197266 s
DEBUG 01-05 09:59:22.162414.162414 cuda_h.py:19] end gpu_experts cost 0.00600123405456543 seconds
DEBUG 01-05 09:59:22.162781.162781 cuda_h.py:19] end layer_moe_generate_14 cost 0.06584334373474121 seconds
DEBUG 01-05 09:59:22.162072.162072 lmp.py:217] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 09:59:22.162166.162166 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 09:59:22.162147.162147 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:59:22.162949.162949 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:59:22.162123.162123 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:59:22.162654.162654 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.700920104980469e-05 seconds
DEBUG 01-05 09:59:22.162774.162774 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.163280.163280 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.163032.163032 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.163537.163537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.163755.163755 cuda_h.py:19] end allocate_cuda_memory cost 0.00033593177795410156 seconds
DEBUG 01-05 09:59:22.163989.163989 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.163891.163891 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.163634.163634 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.163814.163814 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ee70cfb8-b63e-4b46-9f56-0065bd700075
DEBUG 01-05 09:59:22.163784.163784 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.164196.164196 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.164965.164965 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ee70cfb8-b63e-4b46-9f56-0065bd700075
DEBUG 01-05 09:59:22.164993.164993 cuda_h.py:19] end load_into_gpu_async cost 0.0012674331665039062 seconds
DEBUG 01-05 09:59:22.164027.164027 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.165679.165679 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-05 09:59:22.165766.165766 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019104480743408203 seconds
INFO 01-05 09:59:22.165975.165975 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ee70cfb8-b63e-4b46-9f56-0065bd700075
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.167014.167014 cuda_h.py:19] end self_attn cost 0.0038084983825683594 seconds
DEBUG 01-05 09:59:22.168627.168627 cuda_h.py:19] end iln_self_attn_paln cost 0.005266904830932617 seconds
DEBUG 01-05 09:59:22.168086.168086 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 09:59:22.168325.168325 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.169283.169283 cuda_h.py:19] end gate cost 0.0006723403930664062 seconds
DEBUG 01-05 09:59:22.169490.169490 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.169851.169851 lmp.py:365] 
DEBUG 01-05 09:59:22.169851.169851 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.169938.169938 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.169111.169111 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.169946.169946 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.169688.169688 lmp.py:369] 
DEBUG 01-05 09:59:22.169688.169688 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.169616.169616 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.169504.169504 lmp.py:376]   Expert 63 |     14 | CPU
DEBUG 01-05 09:59:22.169432.169432 lmp.py:376]   Expert 34 |     52 | CPU
DEBUG 01-05 09:59:22.169644.169644 lmp.py:376]   Expert 37 |     55 | CPU
DEBUG 01-05 09:59:22.169857.169857 lmp.py:376]   Expert 42 |     59 | CPU
DEBUG 01-05 09:59:22.169308.169308 lmp.py:376]   Expert  4 |     62 | CPU
DEBUG 01-05 09:59:22.169282.169282 lmp.py:376]   Expert 48 |     67 | CPU
DEBUG 01-05 09:59:22.169494.169494 lmp.py:376]   Expert 22 |     76 | CPU
DEBUG 01-05 09:59:22.169707.169707 lmp.py:376]   Expert 57 |     82 | CPU
DEBUG 01-05 09:59:22.169681.169681 lmp.py:376]   Expert 53 |     83 | CPU
DEBUG 01-05 09:59:22.169655.169655 lmp.py:376]   Expert 28 |     85 | CPU
DEBUG 01-05 09:59:22.169059.169059 lmp.py:376]   Expert 15 |     87 | CPU
DEBUG 01-05 09:59:22.169749.169749 lmp.py:376]   Expert 51 |     87 | CPU
DEBUG 01-05 09:59:22.169484.169484 lmp.py:376]   Expert  5 |     90 | CPU
DEBUG 01-05 09:59:22.169458.169458 lmp.py:376]   Expert 40 |     92 | CPU
DEBUG 01-05 09:59:22.169194.169194 lmp.py:376]   Expert 43 |     97 | CPU
DEBUG 01-05 09:59:22.169168.169168 lmp.py:376]   Expert 41 |    103 | CPU
DEBUG 01-05 09:59:22.169619.169619 lmp.py:376]   Expert  6 |    122 | CPU
DEBUG 01-05 09:59:22.169355.169355 lmp.py:376]   Expert  7 |    122 | CPU
DEBUG 01-05 09:59:22.169329.169329 lmp.py:376]   Expert 55 |    125 | CPU
DEBUG 01-05 09:59:22.169733.169733 lmp.py:376]   Expert 32 |    130 | CPU
DEBUG 01-05 09:59:22.169707.169707 lmp.py:376]   Expert 29 |    131 | CPU
DEBUG 01-05 09:59:22.169681.169681 lmp.py:376]   Expert 52 |    143 | CPU
DEBUG 01-05 09:59:22.169655.169655 lmp.py:376]   Expert 56 |    146 | CPU
DEBUG 01-05 09:59:22.169391.169391 lmp.py:376]   Expert 44 |    147 | CPU
DEBUG 01-05 09:59:22.169365.169365 lmp.py:376]   Expert 25 |    153 | CPU
DEBUG 01-05 09:59:22.169339.169339 lmp.py:376]   Expert 14 |    157 | CPU
DEBUG 01-05 09:59:22.169313.169313 lmp.py:376]   Expert  2 |    161 | CPU
DEBUG 01-05 09:59:22.169049.169049 lmp.py:376]   Expert 61 |    163 | CPU
DEBUG 01-05 09:59:22.170553.170553 lmp.py:376]   Expert 12 |    177 | CPU
DEBUG 01-05 09:59:22.170672.170672 lmp.py:376]   Expert 33 |    179 | CPU
DEBUG 01-05 09:59:22.170362.170362 lmp.py:376]   Expert 50 |    179 | CPU
DEBUG 01-05 09:59:22.170051.170051 lmp.py:376]   Expert 54 |    182 | CPU
DEBUG 01-05 09:59:22.170979.170979 lmp.py:376]   Expert 35 |    192 | GPU
DEBUG 01-05 09:59:22.170906.170906 lmp.py:376]   Expert 39 |    193 | GPU
DEBUG 01-05 09:59:22.170596.170596 lmp.py:376]   Expert 62 |    194 | GPU
DEBUG 01-05 09:59:22.170285.170285 lmp.py:376]   Expert 11 |    211 | GPU
DEBUG 01-05 09:59:22.170213.170213 lmp.py:376]   Expert 31 |    213 | GPU
DEBUG 01-05 09:59:22.170094.170094 lmp.py:376]   Expert 20 |    221 | GPU
DEBUG 01-05 09:59:22.170022.170022 lmp.py:376]   Expert 45 |    222 | GPU
DEBUG 01-05 09:59:22.170711.170711 lmp.py:376]   Expert 58 |    223 | GPU
DEBUG 01-05 09:59:22.170639.170639 lmp.py:376]   Expert 10 |    227 | GPU
DEBUG 01-05 09:59:22.170328.170328 lmp.py:376]   Expert 47 |    230 | GPU
DEBUG 01-05 09:59:22.170256.170256 lmp.py:376]   Expert 23 |    233 | GPU
DEBUG 01-05 09:59:22.170945.170945 lmp.py:376]   Expert 59 |    237 | GPU
DEBUG 01-05 09:59:22.170158.170158 lmp.py:376]   Expert 13 |    242 | GPU
DEBUG 01-05 09:59:22.170085.170085 lmp.py:376]   Expert  1 |    245 | GPU
DEBUG 01-05 09:59:22.170205.170205 lmp.py:376]   Expert 24 |    250 | GPU
DEBUG 01-05 09:59:22.170371.170371 lmp.py:376]   Expert  0 |    251 | GPU
DEBUG 01-05 09:59:22.170061.170061 lmp.py:376]   Expert 38 |    256 | GPU
DEBUG 01-05 09:59:22.170512.170512 lmp.py:376]   Expert 36 |    257 | GPU
DEBUG 01-05 09:59:22.170201.170201 lmp.py:376]   Expert  9 |    262 | GPU
DEBUG 01-05 09:59:22.170652.170652 lmp.py:376]   Expert 16 |    263 | GPU
DEBUG 01-05 09:59:22.170103.170103 lmp.py:376]   Expert 18 |    267 | GPU
DEBUG 01-05 09:59:22.170315.170315 lmp.py:376]   Expert 46 |    285 | GPU
DEBUG 01-05 09:59:22.170004.170004 lmp.py:376]   Expert 60 |    295 | GPU
DEBUG 01-05 09:59:22.170455.170455 lmp.py:376]   Expert 49 |    307 | GPU
DEBUG 01-05 09:59:22.170145.170145 lmp.py:376]   Expert  3 |    309 | GPU
DEBUG 01-05 09:59:22.170595.170595 lmp.py:376]   Expert 19 |    310 | GPU
DEBUG 01-05 09:59:22.170046.170046 lmp.py:376]   Expert 30 |    313 | GPU
DEBUG 01-05 09:59:22.170259.170259 lmp.py:376]   Expert 26 |    339 | GPU
DEBUG 01-05 09:59:22.170710.170710 lmp.py:376]   Expert 27 |    350 | GPU
DEBUG 01-05 09:59:22.170399.170399 lmp.py:376]   Expert 21 |    354 | GPU
DEBUG 01-05 09:59:22.170611.170611 lmp.py:376]   Expert 17 |    360 | GPU
DEBUG 01-05 09:59:22.170824.170824 lmp.py:376]   Expert  8 |    569 | GPU
DEBUG 01-05 09:59:22.170990.170990 lmp.py:377] 
DEBUG 01-05 09:59:22.170990.170990 lmp.py:377]   CPU total tokens: 3608 (29.4%)
DEBUG 01-05 09:59:22.170395.170395 lmp.py:378]   GPU total tokens: 8680 (70.6%)
DEBUG 01-05 09:59:22.170998.170998 cuda_h.py:19] end experts_map_get cost 0.0015053749084472656 seconds
DEBUG 01-05 09:59:22.170356.170356 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.170325.170325 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.170078.170078 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.171479.171479 cuda_h.py:19] end allocate_cuda_memory cost 0.0006833076477050781 seconds
DEBUG 01-05 09:59:22.171813.171813 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.171237.171237 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.171901.171901 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.171789.171789 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 27b30164-e5a1-4641-8dfa-cb8ea930c260
DEBUG 01-05 09:59:22.171769.171769 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.172072.172072 client.py:127] Model loaded
DEBUG 01-05 09:59:22.172438.172438 cuda_h.py:19] end sllm_worker_task cost 0.008980512619018555 seconds
INFO 01-05 09:59:22.172139.172139 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 27b30164-e5a1-4641-8dfa-cb8ea930c260
DEBUG 01-05 09:59:22.173244.173244 cuda_h.py:19] end load_into_gpu_async cost 0.0013554096221923828 seconds
DEBUG 01-05 09:59:22.173584.173584 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.173750.173750 cuda_h.py:19] end restore_tensors2 cost 0.0005478858947753906 seconds
DEBUG 01-05 09:59:22.173283.173283 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030689239501953125 seconds
DEBUG 01-05 09:59:22.177892.177892 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0070705413818359375 seconds
DEBUG 01-05 09:59:22.177841.177841 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.177600.177600 lmp.py:423] 
DEBUG 01-05 09:59:22.177600.177600 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.178000.178000 cuda_h.py:19] end cpu_experts_submit cost 0.00014495849609375 seconds
DEBUG 01-05 09:59:22.178955.178955 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.189970.189970 mlpmodule.py:704] group tensors cost 0.011068344116210938 s
DEBUG 01-05 09:59:22.191795.191795 mlpmodule.py:742] pad cost 0.0016598701477050781 s
DEBUG 01-05 09:59:22.191812.191812 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-05 09:59:22.191761.191761 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-05 09:59:22.201736.201736 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.201994.201994 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.201475.201475 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:59:22.202360.202360 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.219364.219364 mlpmodule.py:793] group einsum cost 0.027820825576782227 s
DEBUG 01-05 09:59:22.220866.220866 mlpmodule.py:801] cpy2cputensor cost 0.0007236003875732422 s
DEBUG 01-05 09:59:22.225349.225349 cuda_h.py:19] end wait_cetm_experts cost 0.04707503318786621 seconds
DEBUG 01-05 09:59:22.225003.225003 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.226991.226991 cuda_h.py:19] end gpu_sexperts cost 0.0005788803100585938 seconds
DEBUG 01-05 09:59:22.226410.226410 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.226313.226313 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:22.226685.226685 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.226633.226633 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 27b30164-e5a1-4641-8dfa-cb8ea930c260
INFO 01-05 09:59:22.227638.227638 client.py:127] Model loaded
DEBUG 01-05 09:59:22.227958.227958 cuda_h.py:19] end wait_experts cost 0.001399993896484375 seconds
DEBUG 01-05 09:59:22.227899.227899 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.227225.227225 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.228607.228607 mlpmodule.py:531] gpu group tensors cost 0.0006437301635742188 s
DEBUG 01-05 09:59:22.230125.230125 mlpmodule.py:564] gpu pad cost 0.0017642974853515625 s
DEBUG 01-05 09:59:22.230749.230749 mlpmodule.py:582] gpu group einsum cost 0.0005564689636230469 s
DEBUG 01-05 09:59:22.234676.234676 mlpmodule.py:611] gpu experts func einsum cost 0.006672859191894531 s
DEBUG 01-05 09:59:22.234289.234289 cuda_h.py:19] end gpu_experts cost 0.006860256195068359 seconds
DEBUG 01-05 09:59:22.234219.234219 cuda_h.py:19] end layer_moe_generate_15 cost 0.066253662109375 seconds
DEBUG 01-05 09:59:22.234657.234657 lmp.py:217] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 09:59:22.234380.234380 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 09:59:22.234891.234891 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:59:22.234223.234223 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:59:22.234596.234596 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.314018249511719e-05 seconds
DEBUG 01-05 09:59:22.235266.235266 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.67572021484375e-05 seconds
DEBUG 01-05 09:59:22.235631.235631 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.235342.235342 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.235327.235327 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.235077.235077 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.237082.237082 cuda_h.py:19] end allocate_cuda_memory cost 0.0020630359649658203 seconds
DEBUG 01-05 09:59:22.237066.237066 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.237108.237108 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.237692.237692 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.237680.237680 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 878dc922-710b-4a71-b172-40d4fdf11905
DEBUG 01-05 09:59:22.237080.237080 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.237762.237762 mlpmodule.py:662]  experts func einsum cost 0.05966782569885254 s
DEBUG 01-05 09:59:22.238182.238182 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.238196.238196 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 878dc922-710b-4a71-b172-40d4fdf11905
DEBUG 01-05 09:59:22.238655.238655 cuda_h.py:19] end load_into_gpu_async cost 0.0011055469512939453 seconds
DEBUG 01-05 09:59:22.238643.238643 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.238441.238441 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-05 09:59:22.238766.238766 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003584146499633789 seconds
INFO 01-05 09:59:22.239439.239439 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 878dc922-710b-4a71-b172-40d4fdf11905
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.242706.242706 cuda_h.py:19] end self_attn cost 0.003917217254638672 seconds
DEBUG 01-05 09:59:22.242426.242426 cuda_h.py:19] end iln_self_attn_paln cost 0.007470130920410156 seconds
DEBUG 01-05 09:59:22.242077.242077 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 09:59:22.242078.242078 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.243928.243928 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-05 09:59:22.243373.243373 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.243781.243781 lmp.py:365] 
DEBUG 01-05 09:59:22.243781.243781 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.243344.243344 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.243617.243617 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.243929.243929 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.243856.243856 lmp.py:369] 
DEBUG 01-05 09:59:22.243856.243856 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.243307.243307 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.243242.243242 lmp.py:376]   Expert 58 |     23 | CPU
DEBUG 01-05 09:59:22.243408.243408 lmp.py:376]   Expert 43 |     50 | CPU
DEBUG 01-05 09:59:22.243859.243859 lmp.py:376]   Expert 14 |     60 | CPU
DEBUG 01-05 09:59:22.243594.243594 lmp.py:376]   Expert 13 |     83 | CPU
DEBUG 01-05 09:59:22.243569.243569 lmp.py:376]   Expert 54 |     83 | CPU
DEBUG 01-05 09:59:22.243735.243735 lmp.py:376]   Expert 11 |     85 | CPU
DEBUG 01-05 09:59:22.243901.243901 lmp.py:376]   Expert 45 |     85 | CPU
DEBUG 01-05 09:59:22.243636.243636 lmp.py:376]   Expert 39 |     93 | CPU
DEBUG 01-05 09:59:22.243756.243756 lmp.py:376]   Expert 59 |    103 | CPU
DEBUG 01-05 09:59:22.243446.243446 lmp.py:376]   Expert 60 |    104 | CPU
DEBUG 01-05 09:59:22.243373.243373 lmp.py:376]   Expert 34 |    114 | CPU
DEBUG 01-05 09:59:22.243063.243063 lmp.py:376]   Expert 18 |    115 | CPU
DEBUG 01-05 09:59:22.243467.243467 lmp.py:376]   Expert  6 |    117 | CPU
DEBUG 01-05 09:59:22.244395.244395 lmp.py:376]   Expert 57 |    120 | CPU
DEBUG 01-05 09:59:22.244376.244376 lmp.py:376]   Expert 28 |    122 | CPU
DEBUG 01-05 09:59:22.244588.244588 lmp.py:376]   Expert 61 |    122 | CPU
DEBUG 01-05 09:59:22.244324.244324 lmp.py:376]   Expert 49 |    131 | CPU
DEBUG 01-05 09:59:22.244298.244298 lmp.py:376]   Expert  0 |    132 | CPU
DEBUG 01-05 09:59:22.244795.244795 lmp.py:376]   Expert 25 |    133 | CPU
DEBUG 01-05 09:59:22.244769.244769 lmp.py:376]   Expert 51 |    133 | CPU
DEBUG 01-05 09:59:22.244266.244266 lmp.py:376]   Expert 50 |    136 | CPU
DEBUG 01-05 09:59:22.244240.244240 lmp.py:376]   Expert 62 |    136 | CPU
DEBUG 01-05 09:59:22.244214.244214 lmp.py:376]   Expert 32 |    139 | CPU
DEBUG 01-05 09:59:22.244380.244380 lmp.py:376]   Expert 41 |    140 | CPU
DEBUG 01-05 09:59:22.244355.244355 lmp.py:376]   Expert 30 |    146 | CPU
DEBUG 01-05 09:59:22.244090.244090 lmp.py:376]   Expert 35 |    146 | CPU
DEBUG 01-05 09:59:22.244826.244826 lmp.py:376]   Expert 15 |    154 | CPU
DEBUG 01-05 09:59:22.244800.244800 lmp.py:376]   Expert 38 |    154 | CPU
DEBUG 01-05 09:59:22.244297.244297 lmp.py:376]   Expert 12 |    163 | CPU
DEBUG 01-05 09:59:22.244271.244271 lmp.py:376]   Expert 37 |    169 | CPU
DEBUG 01-05 09:59:22.244768.244768 lmp.py:376]   Expert 56 |    176 | CPU
DEBUG 01-05 09:59:22.244981.244981 lmp.py:376]   Expert 31 |    178 | CPU
DEBUG 01-05 09:59:22.244955.244955 lmp.py:376]   Expert 26 |    181 | GPU
DEBUG 01-05 09:59:22.244452.244452 lmp.py:376]   Expert 63 |    182 | GPU
DEBUG 01-05 09:59:22.244618.244618 lmp.py:376]   Expert 48 |    187 | GPU
DEBUG 01-05 09:59:22.244884.244884 lmp.py:376]   Expert 42 |    192 | GPU
DEBUG 01-05 09:59:22.244202.244202 lmp.py:376]   Expert 10 |    195 | GPU
DEBUG 01-05 09:59:22.244130.244130 lmp.py:376]   Expert 44 |    196 | GPU
DEBUG 01-05 09:59:22.244296.244296 lmp.py:376]   Expert  3 |    201 | GPU
DEBUG 01-05 09:59:22.244323.244323 lmp.py:376]   Expert 55 |    205 | GPU
DEBUG 01-05 09:59:22.244490.244490 lmp.py:376]   Expert 40 |    207 | GPU
DEBUG 01-05 09:59:22.244464.244464 lmp.py:376]   Expert 21 |    218 | GPU
DEBUG 01-05 09:59:22.244438.244438 lmp.py:376]   Expert 16 |    230 | GPU
DEBUG 01-05 09:59:22.244173.244173 lmp.py:376]   Expert 33 |    230 | GPU
DEBUG 01-05 09:59:22.244147.244147 lmp.py:376]   Expert 47 |    230 | GPU
DEBUG 01-05 09:59:22.244883.244883 lmp.py:376]   Expert  1 |    231 | GPU
DEBUG 01-05 09:59:22.244857.244857 lmp.py:376]   Expert  9 |    235 | GPU
DEBUG 01-05 09:59:22.244069.244069 lmp.py:376]   Expert 36 |    241 | GPU
DEBUG 01-05 09:59:22.244474.244474 lmp.py:376]   Expert 19 |    250 | GPU
DEBUG 01-05 09:59:22.244448.244448 lmp.py:376]   Expert 46 |    250 | GPU
DEBUG 01-05 09:59:22.244184.244184 lmp.py:376]   Expert  2 |    260 | GPU
DEBUG 01-05 09:59:22.244919.244919 lmp.py:376]   Expert 24 |    263 | GPU
DEBUG 01-05 09:59:22.244655.244655 lmp.py:376]   Expert 20 |    265 | GPU
DEBUG 01-05 09:59:22.244152.244152 lmp.py:376]   Expert 22 |    272 | GPU
DEBUG 01-05 09:59:22.244888.244888 lmp.py:376]   Expert 53 |    272 | GPU
DEBUG 01-05 09:59:22.244623.244623 lmp.py:376]   Expert  8 |    282 | GPU
DEBUG 01-05 09:59:22.244597.244597 lmp.py:376]   Expert  7 |    285 | GPU
DEBUG 01-05 09:59:22.244764.244764 lmp.py:376]   Expert 29 |    307 | GPU
DEBUG 01-05 09:59:22.244738.244738 lmp.py:376]   Expert  4 |    361 | GPU
DEBUG 01-05 09:59:22.244712.244712 lmp.py:376]   Expert 17 |    362 | GPU
DEBUG 01-05 09:59:22.244447.244447 lmp.py:376]   Expert 23 |    365 | GPU
DEBUG 01-05 09:59:22.244183.244183 lmp.py:376]   Expert 27 |    422 | GPU
DEBUG 01-05 09:59:22.244157.244157 lmp.py:376]   Expert  5 |    431 | GPU
DEBUG 01-05 09:59:22.244893.244893 lmp.py:376]   Expert 52 |    435 | GPU
DEBUG 01-05 09:59:22.244820.244820 lmp.py:377] 
DEBUG 01-05 09:59:22.244820.244820 lmp.py:377]   CPU total tokens: 3845 (31.3%)
DEBUG 01-05 09:59:22.244271.244271 lmp.py:378]   GPU total tokens: 8443 (68.7%)
DEBUG 01-05 09:59:22.244729.244729 cuda_h.py:19] end experts_map_get cost 0.0014982223510742188 seconds
DEBUG 01-05 09:59:22.244087.244087 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.244486.244486 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.245054.245054 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.245219.245219 cuda_h.py:19] end allocate_cuda_memory cost 0.00036907196044921875 seconds
DEBUG 01-05 09:59:22.245255.245255 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.245964.245964 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.245012.245012 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.245377.245377 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c2e84c72-520b-46db-aa6e-9bda6350e752
DEBUG 01-05 09:59:22.245364.245364 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.246932.246932 client.py:127] Model loaded
DEBUG 01-05 09:59:22.246690.246690 cuda_h.py:19] end sllm_worker_task cost 0.010841131210327148 seconds
INFO 01-05 09:59:22.246774.246774 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c2e84c72-520b-46db-aa6e-9bda6350e752
DEBUG 01-05 09:59:22.246094.246094 cuda_h.py:19] end load_into_gpu_async cost 0.0011119842529296875 seconds
DEBUG 01-05 09:59:22.246082.246082 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.247340.247340 cuda_h.py:19] end restore_tensors2 cost 0.00037550926208496094 seconds
DEBUG 01-05 09:59:22.247508.247508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002206563949584961 seconds
DEBUG 01-05 09:59:22.249721.249721 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004864931106567383 seconds
DEBUG 01-05 09:59:22.249412.249412 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.249798.249798 lmp.py:423] 
DEBUG 01-05 09:59:22.249798.249798 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.249072.249072 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-05 09:59:22.250437.250437 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.260260.260260 mlpmodule.py:704] group tensors cost 0.009934425354003906 s
DEBUG 01-05 09:59:22.262135.262135 mlpmodule.py:742] pad cost 0.0016150474548339844 s
DEBUG 01-05 09:59:22.262199.262199 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:59:22.262956.262956 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 09:59:22.273061.273061 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.273106.273106 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.273798.273798 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 09:59:22.273299.273299 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.290866.290866 mlpmodule.py:793] group einsum cost 0.027473926544189453 s
DEBUG 01-05 09:59:22.291626.291626 mlpmodule.py:801] cpy2cputensor cost 0.0007309913635253906 s
DEBUG 01-05 09:59:22.295088.295088 cuda_h.py:19] end wait_cetm_experts cost 0.045471906661987305 seconds
DEBUG 01-05 09:59:22.295544.295544 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.296485.296485 cuda_h.py:19] end gpu_sexperts cost 0.0005786418914794922 seconds
DEBUG 01-05 09:59:22.296541.296541 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.296020.296020 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-05 09:59:22.296630.296630 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.296055.296055 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c2e84c72-520b-46db-aa6e-9bda6350e752
INFO 01-05 09:59:22.302744.302744 client.py:127] Model loaded
DEBUG 01-05 09:59:22.302786.302786 cuda_h.py:19] end wait_experts cost 0.006193399429321289 seconds
DEBUG 01-05 09:59:22.302634.302634 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.302675.302675 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.303713.303713 mlpmodule.py:531] gpu group tensors cost 0.0006465911865234375 s
DEBUG 01-05 09:59:22.305695.305695 mlpmodule.py:564] gpu pad cost 0.0017919540405273438 s
DEBUG 01-05 09:59:22.305358.305358 mlpmodule.py:582] gpu group einsum cost 0.0005245208740234375 s
DEBUG 01-05 09:59:22.307097.307097 mlpmodule.py:662]  experts func einsum cost 0.057486772537231445 s
DEBUG 01-05 09:59:22.309990.309990 mlpmodule.py:611] gpu experts func einsum cost 0.006352663040161133 s
DEBUG 01-05 09:59:22.309770.309770 cuda_h.py:19] end gpu_experts cost 0.006602287292480469 seconds
DEBUG 01-05 09:59:22.309455.309455 cuda_h.py:19] end layer_moe_generate_16 cost 0.06685566902160645 seconds
DEBUG 01-05 09:59:22.309521.309521 lmp.py:217] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 09:59:22.309191.309191 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 09:59:22.309219.309219 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:59:22.309366.309366 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:59:22.309017.309017 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:59:22.309978.309978 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.867813110351562e-05 seconds
DEBUG 01-05 09:59:22.309575.309575 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.309795.309795 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.310633.310633 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.310762.310762 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.310151.310151 cuda_h.py:19] end allocate_cuda_memory cost 0.0003173351287841797 seconds
DEBUG 01-05 09:59:22.310690.310690 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.310168.310168 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.310276.310276 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.310694.310694 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c68fc5e8-0934-40aa-83fb-7280dd829d59
DEBUG 01-05 09:59:22.310002.310002 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.311619.311619 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.312197.312197 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c68fc5e8-0934-40aa-83fb-7280dd829d59
DEBUG 01-05 09:59:22.312511.312511 cuda_h.py:19] end load_into_gpu_async cost 0.0015153884887695312 seconds
DEBUG 01-05 09:59:22.312889.312889 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.312164.312164 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-05 09:59:22.312966.312966 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021734237670898438 seconds
INFO 01-05 09:59:22.312446.312446 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c68fc5e8-0934-40aa-83fb-7280dd829d59
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.314494.314494 cuda_h.py:19] end self_attn cost 0.003710031509399414 seconds
DEBUG 01-05 09:59:22.315537.315537 cuda_h.py:19] end iln_self_attn_paln cost 0.0051746368408203125 seconds
DEBUG 01-05 09:59:22.315566.315566 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 09:59:22.315805.315805 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.315401.315401 cuda_h.py:19] end gate cost 0.0007572174072265625 seconds
DEBUG 01-05 09:59:22.316370.316370 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.316525.316525 lmp.py:365] 
DEBUG 01-05 09:59:22.316525.316525 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.316758.316758 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.316660.316660 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.316124.316124 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.316529.316529 lmp.py:369] 
DEBUG 01-05 09:59:22.316529.316529 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.316695.316695 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.316868.316868 lmp.py:376]   Expert 39 |     44 | CPU
DEBUG 01-05 09:59:22.316272.316272 lmp.py:376]   Expert 28 |     58 | CPU
DEBUG 01-05 09:59:22.316962.316962 lmp.py:376]   Expert 36 |     68 | CPU
DEBUG 01-05 09:59:22.316174.316174 lmp.py:376]   Expert 47 |     69 | CPU
DEBUG 01-05 09:59:22.316148.316148 lmp.py:376]   Expert 14 |     70 | CPU
DEBUG 01-05 09:59:22.316122.316122 lmp.py:376]   Expert  1 |     73 | CPU
DEBUG 01-05 09:59:22.316096.316096 lmp.py:376]   Expert 27 |     86 | CPU
DEBUG 01-05 09:59:22.316547.316547 lmp.py:376]   Expert  8 |     87 | CPU
DEBUG 01-05 09:59:22.316760.316760 lmp.py:376]   Expert 40 |     90 | CPU
DEBUG 01-05 09:59:22.316734.316734 lmp.py:376]   Expert  7 |     91 | CPU
DEBUG 01-05 09:59:22.316184.316184 lmp.py:376]   Expert 52 |     93 | CPU
DEBUG 01-05 09:59:22.316682.316682 lmp.py:376]   Expert 25 |     97 | CPU
DEBUG 01-05 09:59:22.316656.316656 lmp.py:376]   Expert  3 |    114 | CPU
DEBUG 01-05 09:59:22.316868.316868 lmp.py:376]   Expert 31 |    117 | CPU
DEBUG 01-05 09:59:22.316604.316604 lmp.py:376]   Expert 54 |    120 | CPU
DEBUG 01-05 09:59:22.316578.316578 lmp.py:376]   Expert 60 |    125 | CPU
DEBUG 01-05 09:59:22.316552.316552 lmp.py:376]   Expert 30 |    131 | CPU
DEBUG 01-05 09:59:22.316288.316288 lmp.py:376]   Expert 24 |    134 | CPU
DEBUG 01-05 09:59:22.316738.316738 lmp.py:376]   Expert 46 |    137 | CPU
DEBUG 01-05 09:59:22.316474.316474 lmp.py:376]   Expert 50 |    138 | CPU
DEBUG 01-05 09:59:22.316448.316448 lmp.py:376]   Expert 63 |    139 | CPU
DEBUG 01-05 09:59:22.316661.316661 lmp.py:376]   Expert 59 |    145 | CPU
DEBUG 01-05 09:59:22.316396.316396 lmp.py:376]   Expert  6 |    149 | CPU
DEBUG 01-05 09:59:22.316132.316132 lmp.py:376]   Expert 56 |    150 | CPU
DEBUG 01-05 09:59:22.316106.316106 lmp.py:376]   Expert 61 |    152 | CPU
DEBUG 01-05 09:59:22.316080.316080 lmp.py:376]   Expert 58 |    160 | CPU
DEBUG 01-05 09:59:22.316292.316292 lmp.py:376]   Expert  2 |    162 | CPU
DEBUG 01-05 09:59:22.316790.316790 lmp.py:376]   Expert 16 |    164 | CPU
DEBUG 01-05 09:59:22.316525.316525 lmp.py:376]   Expert 53 |    165 | CPU
DEBUG 01-05 09:59:22.316499.316499 lmp.py:376]   Expert 34 |    170 | CPU
DEBUG 01-05 09:59:22.316473.316473 lmp.py:376]   Expert 49 |    173 | CPU
DEBUG 01-05 09:59:22.316209.316209 lmp.py:376]   Expert 18 |    180 | CPU
DEBUG 01-05 09:59:22.316183.316183 lmp.py:376]   Expert 43 |    182 | GPU
DEBUG 01-05 09:59:22.317157.317157 lmp.py:376]   Expert 10 |    184 | GPU
DEBUG 01-05 09:59:22.317893.317893 lmp.py:376]   Expert 11 |    186 | GPU
DEBUG 01-05 09:59:22.317628.317628 lmp.py:376]   Expert 37 |    188 | GPU
DEBUG 01-05 09:59:22.317125.317125 lmp.py:376]   Expert 15 |    192 | GPU
DEBUG 01-05 09:59:22.317530.317530 lmp.py:376]   Expert 33 |    197 | GPU
DEBUG 01-05 09:59:22.317504.317504 lmp.py:376]   Expert 29 |    202 | GPU
DEBUG 01-05 09:59:22.317001.317001 lmp.py:376]   Expert 21 |    203 | GPU
DEBUG 01-05 09:59:22.317975.317975 lmp.py:376]   Expert 32 |    219 | GPU
DEBUG 01-05 09:59:22.317711.317711 lmp.py:376]   Expert 44 |    222 | GPU
DEBUG 01-05 09:59:22.317685.317685 lmp.py:376]   Expert 13 |    226 | GPU
DEBUG 01-05 09:59:22.317659.317659 lmp.py:376]   Expert 20 |    228 | GPU
DEBUG 01-05 09:59:22.317395.317395 lmp.py:376]   Expert 57 |    238 | GPU
DEBUG 01-05 09:59:22.317369.317369 lmp.py:376]   Expert  0 |    241 | GPU
DEBUG 01-05 09:59:22.317343.317343 lmp.py:376]   Expert 35 |    243 | GPU
DEBUG 01-05 09:59:22.317270.317270 lmp.py:376]   Expert 42 |    253 | GPU
DEBUG 01-05 09:59:22.317483.317483 lmp.py:376]   Expert  9 |    255 | GPU
DEBUG 01-05 09:59:22.317980.317980 lmp.py:376]   Expert 51 |    267 | GPU
DEBUG 01-05 09:59:22.317954.317954 lmp.py:376]   Expert  5 |    270 | GPU
DEBUG 01-05 09:59:22.317690.317690 lmp.py:376]   Expert 22 |    273 | GPU
DEBUG 01-05 09:59:22.317425.317425 lmp.py:376]   Expert 38 |    281 | GPU
DEBUG 01-05 09:59:22.317399.317399 lmp.py:376]   Expert 19 |    284 | GPU
DEBUG 01-05 09:59:22.317135.317135 lmp.py:376]   Expert 23 |    287 | GPU
DEBUG 01-05 09:59:22.317109.317109 lmp.py:376]   Expert 62 |    293 | GPU
DEBUG 01-05 09:59:22.317845.317845 lmp.py:376]   Expert 48 |    308 | GPU
DEBUG 01-05 09:59:22.317772.317772 lmp.py:376]   Expert 12 |    309 | GPU
DEBUG 01-05 09:59:22.317985.317985 lmp.py:376]   Expert  4 |    313 | GPU
DEBUG 01-05 09:59:22.317959.317959 lmp.py:376]   Expert 45 |    328 | GPU
DEBUG 01-05 09:59:22.317695.317695 lmp.py:376]   Expert 26 |    341 | GPU
DEBUG 01-05 09:59:22.317430.317430 lmp.py:376]   Expert 41 |    359 | GPU
DEBUG 01-05 09:59:22.317166.317166 lmp.py:376]   Expert 55 |    388 | GPU
DEBUG 01-05 09:59:22.317094.317094 lmp.py:376]   Expert 17 |    477 | GPU
DEBUG 01-05 09:59:22.317975.317975 lmp.py:377] 
DEBUG 01-05 09:59:22.317975.317975 lmp.py:377]   CPU total tokens: 3851 (31.3%)
DEBUG 01-05 09:59:22.317095.317095 lmp.py:378]   GPU total tokens: 8437 (68.7%)
DEBUG 01-05 09:59:22.317937.317937 cuda_h.py:19] end experts_map_get cost 0.0014786720275878906 seconds
DEBUG 01-05 09:59:22.317295.317295 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.317502.317502 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.317069.317069 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.318647.318647 cuda_h.py:19] end allocate_cuda_memory cost 0.0009903907775878906 seconds
DEBUG 01-05 09:59:22.318966.318966 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.318484.318484 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.318008.318008 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.318373.318373 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bea0a80d-aaef-4e2f-85cb-b042d7fbf7bc
DEBUG 01-05 09:59:22.319314.319314 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.319579.319579 client.py:127] Model loaded
DEBUG 01-05 09:59:22.319389.319389 cuda_h.py:19] end sllm_worker_task cost 0.009341239929199219 seconds
INFO 01-05 09:59:22.320288.320288 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bea0a80d-aaef-4e2f-85cb-b042d7fbf7bc
DEBUG 01-05 09:59:22.320476.320476 cuda_h.py:19] end load_into_gpu_async cost 0.0015349388122558594 seconds
DEBUG 01-05 09:59:22.320133.320133 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.320146.320146 cuda_h.py:19] end restore_tensors2 cost 0.0003707408905029297 seconds
DEBUG 01-05 09:59:22.320313.320313 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032448768615722656 seconds
DEBUG 01-05 09:59:22.323199.323199 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0058019161224365234 seconds
DEBUG 01-05 09:59:22.323405.323405 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.323428.323428 lmp.py:423] 
DEBUG 01-05 09:59:22.323428.323428 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.323702.323702 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-05 09:59:22.323305.323305 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.336263.336263 mlpmodule.py:704] group tensors cost 0.012155532836914062 s
DEBUG 01-05 09:59:22.339542.339542 mlpmodule.py:742] pad cost 0.0024580955505371094 s
DEBUG 01-05 09:59:22.339455.339455 mlpmodule.py:748] create cpu tensor cost 6.723403930664062e-05 s
DEBUG 01-05 09:59:22.339172.339172 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 09:59:22.349690.349690 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.349020.349020 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.349473.349473 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 09:59:22.349067.349067 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.367971.367971 mlpmodule.py:793] group einsum cost 0.02792954444885254 s
DEBUG 01-05 09:59:22.368896.368896 mlpmodule.py:801] cpy2cputensor cost 0.0007278919219970703 s
DEBUG 01-05 09:59:22.373595.373595 cuda_h.py:19] end wait_cetm_experts cost 0.049329280853271484 seconds
DEBUG 01-05 09:59:22.373621.373621 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.373298.373298 cuda_h.py:19] end gpu_sexperts cost 0.0005974769592285156 seconds
DEBUG 01-05 09:59:22.373240.373240 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.373004.373004 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:59:22.373091.373091 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.374947.374947 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bea0a80d-aaef-4e2f-85cb-b042d7fbf7bc
INFO 01-05 09:59:22.375182.375182 client.py:127] Model loaded
DEBUG 01-05 09:59:22.375171.375171 cuda_h.py:19] end wait_experts cost 0.0017476081848144531 seconds
DEBUG 01-05 09:59:22.375112.375112 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.375676.375676 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.376264.376264 mlpmodule.py:531] gpu group tensors cost 0.0006620883941650391 s
DEBUG 01-05 09:59:22.378370.378370 mlpmodule.py:564] gpu pad cost 0.001735687255859375 s
DEBUG 01-05 09:59:22.378854.378854 mlpmodule.py:582] gpu group einsum cost 0.0005342960357666016 s
DEBUG 01-05 09:59:22.382596.382596 mlpmodule.py:611] gpu experts func einsum cost 0.0066297054290771484 s
DEBUG 01-05 09:59:22.382871.382871 cuda_h.py:19] end gpu_experts cost 0.00681614875793457 seconds
DEBUG 01-05 09:59:22.382470.382470 cuda_h.py:19] end layer_moe_generate_17 cost 0.06752443313598633 seconds
DEBUG 01-05 09:59:22.382007.382007 lmp.py:217] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 09:59:22.382730.382730 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 09:59:22.383480.383480 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:59:22.383812.383812 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:59:22.383231.383231 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:59:22.383610.383610 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.961822509765625e-05 seconds
DEBUG 01-05 09:59:22.383882.383882 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.383733.383733 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.383147.383147 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.383692.383692 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.385074.385074 cuda_h.py:19] end allocate_cuda_memory cost 0.0016791820526123047 seconds
DEBUG 01-05 09:59:22.385760.385760 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.385099.385099 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.385160.385160 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.385386.385386 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b215c1b-7d55-454d-8c7d-cb745d7dc083
DEBUG 01-05 09:59:22.385416.385416 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.385985.385985 mlpmodule.py:662]  experts func einsum cost 0.06180691719055176 s
DEBUG 01-05 09:59:22.385325.385325 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.386585.386585 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b215c1b-7d55-454d-8c7d-cb745d7dc083
DEBUG 01-05 09:59:22.386613.386613 cuda_h.py:19] end load_into_gpu_async cost 0.001115560531616211 seconds
DEBUG 01-05 09:59:22.386078.386078 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.386352.386352 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-05 09:59:22.386440.386440 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031707286834716797 seconds
INFO 01-05 09:59:22.387338.387338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b215c1b-7d55-454d-8c7d-cb745d7dc083
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.389198.389198 cuda_h.py:19] end self_attn cost 0.003436565399169922 seconds
DEBUG 01-05 09:59:22.389667.389667 cuda_h.py:19] end iln_self_attn_paln cost 0.006585121154785156 seconds
DEBUG 01-05 09:59:22.389364.389364 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 09:59:22.389080.389080 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.390396.390396 cuda_h.py:19] end gate cost 0.0006902217864990234 seconds
DEBUG 01-05 09:59:22.390557.390557 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.390010.390010 lmp.py:365] 
DEBUG 01-05 09:59:22.390010.390010 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.390766.390766 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.391893.391893 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.391682.391682 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.391371.391371 lmp.py:369] 
DEBUG 01-05 09:59:22.391371.391371 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.391014.391014 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.391141.391141 lmp.py:376]   Expert 35 |     49 | CPU
DEBUG 01-05 09:59:22.391260.391260 lmp.py:376]   Expert  0 |     59 | CPU
DEBUG 01-05 09:59:22.391665.391665 lmp.py:376]   Expert  3 |     63 | CPU
DEBUG 01-05 09:59:22.391262.391262 lmp.py:376]   Expert 53 |     63 | CPU
DEBUG 01-05 09:59:22.391189.391189 lmp.py:376]   Expert 19 |     64 | CPU
DEBUG 01-05 09:59:22.391117.391117 lmp.py:376]   Expert 58 |     65 | CPU
DEBUG 01-05 09:59:22.391806.391806 lmp.py:376]   Expert 54 |     73 | CPU
DEBUG 01-05 09:59:22.391257.391257 lmp.py:376]   Expert  6 |     78 | CPU
DEBUG 01-05 09:59:22.391947.391947 lmp.py:376]   Expert 12 |     87 | CPU
DEBUG 01-05 09:59:22.391113.391113 lmp.py:376]   Expert 41 |     87 | CPU
DEBUG 01-05 09:59:22.391802.391802 lmp.py:376]   Expert 34 |     89 | CPU
DEBUG 01-05 09:59:22.391253.391253 lmp.py:376]   Expert 60 |     90 | CPU
DEBUG 01-05 09:59:22.391942.391942 lmp.py:376]   Expert 20 |     91 | CPU
DEBUG 01-05 09:59:22.391393.391393 lmp.py:376]   Expert 37 |     99 | CPU
DEBUG 01-05 09:59:22.391844.391844 lmp.py:376]   Expert 63 |    103 | CPU
DEBUG 01-05 09:59:22.391295.391295 lmp.py:376]   Expert 40 |    106 | CPU
DEBUG 01-05 09:59:22.391746.391746 lmp.py:376]   Expert 43 |    110 | CPU
DEBUG 01-05 09:59:22.391435.391435 lmp.py:376]   Expert 48 |    110 | CPU
DEBUG 01-05 09:59:22.391124.391124 lmp.py:376]   Expert  8 |    113 | CPU
DEBUG 01-05 09:59:22.391006.391006 lmp.py:376]   Expert 30 |    115 | CPU
DEBUG 01-05 09:59:22.391933.391933 lmp.py:376]   Expert 46 |    118 | CPU
DEBUG 01-05 09:59:22.391146.391146 lmp.py:376]   Expert 32 |    119 | CPU
DEBUG 01-05 09:59:22.391358.391358 lmp.py:376]   Expert 44 |    123 | CPU
DEBUG 01-05 09:59:22.391048.391048 lmp.py:376]   Expert 13 |    125 | CPU
DEBUG 01-05 09:59:22.391498.391498 lmp.py:376]   Expert 45 |    131 | CPU
DEBUG 01-05 09:59:22.391949.391949 lmp.py:376]   Expert 33 |    136 | CPU
DEBUG 01-05 09:59:22.391162.391162 lmp.py:376]   Expert 29 |    140 | CPU
DEBUG 01-05 09:59:22.391613.391613 lmp.py:376]   Expert 17 |    142 | CPU
DEBUG 01-05 09:59:22.391256.391256 lmp.py:376]   Expert  4 |    145 | CPU
DEBUG 01-05 09:59:22.391183.391183 lmp.py:376]   Expert  5 |    148 | CPU
DEBUG 01-05 09:59:22.391873.391873 lmp.py:376]   Expert 55 |    152 | CPU
DEBUG 01-05 09:59:22.391085.391085 lmp.py:376]   Expert 25 |    162 | CPU
DEBUG 01-05 09:59:22.391298.391298 lmp.py:376]   Expert 11 |    170 | GPU
DEBUG 01-05 09:59:22.391417.391417 lmp.py:376]   Expert 27 |    170 | GPU
DEBUG 01-05 09:59:22.391822.391822 lmp.py:376]   Expert 18 |    177 | GPU
DEBUG 01-05 09:59:22.391988.391988 lmp.py:376]   Expert 39 |    182 | GPU
DEBUG 01-05 09:59:22.391393.391393 lmp.py:376]   Expert 42 |    187 | GPU
DEBUG 01-05 09:59:22.391559.391559 lmp.py:376]   Expert 56 |    188 | GPU
DEBUG 01-05 09:59:22.391963.391963 lmp.py:376]   Expert 52 |    196 | GPU
DEBUG 01-05 09:59:22.391130.391130 lmp.py:376]   Expert 22 |    204 | GPU
DEBUG 01-05 09:59:22.391534.391534 lmp.py:376]   Expert 24 |    207 | GPU
DEBUG 01-05 09:59:22.391700.391700 lmp.py:376]   Expert  9 |    213 | GPU
DEBUG 01-05 09:59:22.391866.391866 lmp.py:376]   Expert 51 |    214 | GPU
DEBUG 01-05 09:59:22.391794.391794 lmp.py:376]   Expert  7 |    218 | GPU
DEBUG 01-05 09:59:22.391199.391199 lmp.py:376]   Expert 50 |    218 | GPU
DEBUG 01-05 09:59:22.391318.391318 lmp.py:376]   Expert  1 |    219 | GPU
DEBUG 01-05 09:59:22.391961.391961 lmp.py:376]   Expert 59 |    223 | GPU
DEBUG 01-05 09:59:22.391651.391651 lmp.py:376]   Expert 61 |    241 | GPU
DEBUG 01-05 09:59:22.391055.391055 lmp.py:376]   Expert 16 |    265 | GPU
DEBUG 01-05 09:59:22.391221.391221 lmp.py:376]   Expert 31 |    270 | GPU
DEBUG 01-05 09:59:22.391149.391149 lmp.py:376]   Expert 28 |    271 | GPU
DEBUG 01-05 09:59:22.391077.391077 lmp.py:376]   Expert 47 |    272 | GPU
DEBUG 01-05 09:59:22.391766.391766 lmp.py:376]   Expert 57 |    278 | GPU
DEBUG 01-05 09:59:22.391171.391171 lmp.py:376]   Expert 21 |    295 | GPU
DEBUG 01-05 09:59:22.391098.391098 lmp.py:376]   Expert 14 |    304 | GPU
DEBUG 01-05 09:59:22.392695.392695 lmp.py:376]   Expert 38 |    311 | GPU
DEBUG 01-05 09:59:22.392676.392676 lmp.py:376]   Expert 10 |    339 | GPU
DEBUG 01-05 09:59:22.392796.392796 lmp.py:376]   Expert  2 |    352 | GPU
DEBUG 01-05 09:59:22.392584.392584 lmp.py:376]   Expert 15 |    355 | GPU
DEBUG 01-05 09:59:22.392466.392466 lmp.py:376]   Expert 49 |    374 | GPU
DEBUG 01-05 09:59:22.392539.392539 lmp.py:376]   Expert 36 |    399 | GPU
DEBUG 01-05 09:59:22.392898.392898 lmp.py:376]   Expert 23 |    448 | GPU
DEBUG 01-05 09:59:22.392110.392110 lmp.py:376]   Expert 26 |    462 | GPU
DEBUG 01-05 09:59:22.392561.392561 lmp.py:376]   Expert 62 |    711 | GPU
DEBUG 01-05 09:59:22.392489.392489 lmp.py:377] 
DEBUG 01-05 09:59:22.392489.392489 lmp.py:377]   CPU total tokens: 3355 (27.3%)
DEBUG 01-05 09:59:22.392416.392416 lmp.py:378]   GPU total tokens: 8933 (72.7%)
DEBUG 01-05 09:59:22.392589.392589 cuda_h.py:19] end experts_map_get cost 0.0015404224395751953 seconds
DEBUG 01-05 09:59:22.392232.392232 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.392346.392346 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.392020.392020 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.393621.393621 cuda_h.py:19] end allocate_cuda_memory cost 0.0012853145599365234 seconds
DEBUG 01-05 09:59:22.393896.393896 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.393904.393904 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.393613.393613 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.393978.393978 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 74fd48c5-000f-4b72-ba2d-b03fbdef0720
DEBUG 01-05 09:59:22.394370.394370 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.394344.394344 client.py:127] Model loaded
DEBUG 01-05 09:59:22.394710.394710 cuda_h.py:19] end sllm_worker_task cost 0.011095285415649414 seconds
INFO 01-05 09:59:22.395612.395612 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 74fd48c5-000f-4b72-ba2d-b03fbdef0720
DEBUG 01-05 09:59:22.395363.395363 cuda_h.py:19] end load_into_gpu_async cost 0.00125885009765625 seconds
DEBUG 01-05 09:59:22.395542.395542 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.395212.395212 cuda_h.py:19] end restore_tensors2 cost 0.0003972053527832031 seconds
DEBUG 01-05 09:59:22.395479.395479 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003339529037475586 seconds
DEBUG 01-05 09:59:22.398559.398559 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005972146987915039 seconds
DEBUG 01-05 09:59:22.398627.398627 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.398590.398590 lmp.py:423] 
DEBUG 01-05 09:59:22.398590.398590 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.398745.398745 cuda_h.py:19] end cpu_experts_submit cost 0.0001304149627685547 seconds
DEBUG 01-05 09:59:22.398825.398825 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.404619.404619 mlpmodule.py:704] group tensors cost 0.005473136901855469 s
DEBUG 01-05 09:59:22.407294.407294 mlpmodule.py:742] pad cost 0.0021665096282958984 s
DEBUG 01-05 09:59:22.407385.407385 mlpmodule.py:748] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-05 09:59:22.407454.407454 mlpmodule.py:753] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-05 09:59:22.416134.416134 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.416610.416610 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.416064.416064 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 09:59:22.416319.416319 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.433478.433478 mlpmodule.py:793] group einsum cost 0.026332378387451172 s
DEBUG 01-05 09:59:22.434632.434632 mlpmodule.py:801] cpy2cputensor cost 0.0006418228149414062 s
DEBUG 01-05 09:59:22.439646.439646 cuda_h.py:19] end wait_cetm_experts cost 0.04066324234008789 seconds
DEBUG 01-05 09:59:22.439546.439546 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.440534.440534 cuda_h.py:19] end gpu_sexperts cost 0.000579833984375 seconds
DEBUG 01-05 09:59:22.440377.440377 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.440803.440803 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-05 09:59:22.440413.440413 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.440361.440361 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 74fd48c5-000f-4b72-ba2d-b03fbdef0720
DEBUG 01-05 09:59:22.450611.450611 mlpmodule.py:662]  experts func einsum cost 0.051944732666015625 s
INFO 01-05 09:59:22.450896.450896 client.py:127] Model loaded
DEBUG 01-05 09:59:22.450079.450079 cuda_h.py:19] end wait_experts cost 0.010744810104370117 seconds
DEBUG 01-05 09:59:22.450616.450616 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.451604.451604 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.451599.451599 mlpmodule.py:531] gpu group tensors cost 0.0005483627319335938 s
DEBUG 01-05 09:59:22.453021.453021 mlpmodule.py:564] gpu pad cost 0.0014820098876953125 s
DEBUG 01-05 09:59:22.453649.453649 mlpmodule.py:582] gpu group einsum cost 0.0005044937133789062 s
DEBUG 01-05 09:59:22.456048.456048 mlpmodule.py:611] gpu experts func einsum cost 0.005655050277709961 s
DEBUG 01-05 09:59:22.456046.456046 cuda_h.py:19] end gpu_experts cost 0.0058743953704833984 seconds
DEBUG 01-05 09:59:22.456400.456400 cuda_h.py:19] end layer_moe_generate_18 cost 0.06709480285644531 seconds
DEBUG 01-05 09:59:22.457591.457591 lmp.py:217] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 09:59:22.457923.457923 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 09:59:22.457666.457666 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:59:22.457230.457230 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:59:22.457258.457258 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.9325485229492188e-05 seconds
DEBUG 01-05 09:59:22.457338.457338 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.841255187988281e-05 seconds
DEBUG 01-05 09:59:22.457458.457458 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.457958.457958 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.457709.457709 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.457930.457930 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.457692.457692 cuda_h.py:19] end allocate_cuda_memory cost 0.0003821849822998047 seconds
DEBUG 01-05 09:59:22.458735.458735 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.458320.458320 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.458924.458924 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.458303.458303 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26eb9348-761a-4bac-8611-0fe1579a908e
DEBUG 01-05 09:59:22.458154.458154 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.458062.458062 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.459810.459810 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26eb9348-761a-4bac-8611-0fe1579a908e
DEBUG 01-05 09:59:22.459018.459018 cuda_h.py:19] end load_into_gpu_async cost 0.0012853145599365234 seconds
DEBUG 01-05 09:59:22.459351.459351 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.459785.459785 cuda_h.py:19] end restore_tensors2 cost 7.62939453125e-05 seconds
DEBUG 01-05 09:59:22.459693.459693 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020580291748046875 seconds
INFO 01-05 09:59:22.460732.460732 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26eb9348-761a-4bac-8611-0fe1579a908e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.462198.462198 cuda_h.py:19] end self_attn cost 0.0040056705474853516 seconds
DEBUG 01-05 09:59:22.462725.462725 cuda_h.py:19] end iln_self_attn_paln cost 0.005576372146606445 seconds
DEBUG 01-05 09:59:22.462184.462184 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 09:59:22.463185.463185 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.463320.463320 cuda_h.py:19] end gate cost 0.0006279945373535156 seconds
DEBUG 01-05 09:59:22.463242.463242 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.464212.464212 lmp.py:365] 
DEBUG 01-05 09:59:22.464212.464212 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.464776.464776 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.464380.464380 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.464168.464168 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.464334.464334 lmp.py:369] 
DEBUG 01-05 09:59:22.464334.464334 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.464785.464785 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.464197.464197 lmp.py:376]   Expert 60 |     49 | CPU
DEBUG 01-05 09:59:22.464363.464363 lmp.py:376]   Expert 56 |     57 | CPU
DEBUG 01-05 09:59:22.464575.464575 lmp.py:376]   Expert 12 |     69 | CPU
DEBUG 01-05 09:59:22.464026.464026 lmp.py:376]   Expert  5 |     75 | CPU
DEBUG 01-05 09:59:22.464715.464715 lmp.py:376]   Expert 55 |     77 | CPU
DEBUG 01-05 09:59:22.464166.464166 lmp.py:376]   Expert 48 |     85 | CPU
DEBUG 01-05 09:59:22.464140.464140 lmp.py:376]   Expert 18 |     86 | CPU
DEBUG 01-05 09:59:22.464783.464783 lmp.py:376]   Expert 59 |     86 | CPU
DEBUG 01-05 09:59:22.464234.464234 lmp.py:376]   Expert  6 |     87 | CPU
DEBUG 01-05 09:59:22.464208.464208 lmp.py:376]   Expert 44 |     88 | CPU
DEBUG 01-05 09:59:22.464182.464182 lmp.py:376]   Expert 30 |     92 | CPU
DEBUG 01-05 09:59:22.464156.464156 lmp.py:376]   Expert 42 |    106 | CPU
DEBUG 01-05 09:59:22.464892.464892 lmp.py:376]   Expert 52 |    106 | CPU
DEBUG 01-05 09:59:22.464866.464866 lmp.py:376]   Expert 23 |    108 | CPU
DEBUG 01-05 09:59:22.464377.464377 lmp.py:376]   Expert 33 |    110 | CPU
DEBUG 01-05 09:59:22.464305.464305 lmp.py:376]   Expert 27 |    118 | CPU
DEBUG 01-05 09:59:22.464517.464517 lmp.py:376]   Expert 34 |    122 | CPU
DEBUG 01-05 09:59:22.464253.464253 lmp.py:376]   Expert 57 |    124 | CPU
DEBUG 01-05 09:59:22.464227.464227 lmp.py:376]   Expert 24 |    132 | CPU
DEBUG 01-05 09:59:22.464439.464439 lmp.py:376]   Expert 32 |    135 | CPU
DEBUG 01-05 09:59:22.464175.464175 lmp.py:376]   Expert 54 |    140 | CPU
DEBUG 01-05 09:59:22.464149.464149 lmp.py:376]   Expert 62 |    149 | CPU
DEBUG 01-05 09:59:22.464884.464884 lmp.py:376]   Expert 58 |    151 | CPU
DEBUG 01-05 09:59:22.464097.464097 lmp.py:376]   Expert 15 |    152 | CPU
DEBUG 01-05 09:59:22.464071.464071 lmp.py:376]   Expert 26 |    155 | CPU
DEBUG 01-05 09:59:22.464807.464807 lmp.py:376]   Expert 13 |    156 | CPU
DEBUG 01-05 09:59:22.464688.464688 lmp.py:376]   Expert  8 |    157 | CPU
DEBUG 01-05 09:59:22.464854.464854 lmp.py:376]   Expert 46 |    158 | CPU
DEBUG 01-05 09:59:22.464027.464027 lmp.py:376]   Expert 63 |    158 | CPU
DEBUG 01-05 09:59:22.464478.464478 lmp.py:376]   Expert 17 |    160 | CPU
DEBUG 01-05 09:59:22.464929.464929 lmp.py:376]   Expert  0 |    162 | CPU
DEBUG 01-05 09:59:22.464903.464903 lmp.py:376]   Expert 16 |    164 | CPU
DEBUG 01-05 09:59:22.464877.464877 lmp.py:376]   Expert  1 |    165 | GPU
DEBUG 01-05 09:59:22.464089.464089 lmp.py:376]   Expert 39 |    175 | GPU
DEBUG 01-05 09:59:22.464063.464063 lmp.py:376]   Expert 43 |    177 | GPU
DEBUG 01-05 09:59:22.464276.464276 lmp.py:376]   Expert 49 |    177 | GPU
DEBUG 01-05 09:59:22.464488.464488 lmp.py:376]   Expert 47 |    180 | GPU
DEBUG 01-05 09:59:22.464939.464939 lmp.py:376]   Expert 19 |    190 | GPU
DEBUG 01-05 09:59:22.464152.464152 lmp.py:376]   Expert  4 |    193 | GPU
DEBUG 01-05 09:59:22.464364.464364 lmp.py:376]   Expert 40 |    197 | GPU
DEBUG 01-05 09:59:22.464100.464100 lmp.py:376]   Expert 25 |    199 | GPU
DEBUG 01-05 09:59:22.464074.464074 lmp.py:376]   Expert 53 |    200 | GPU
DEBUG 01-05 09:59:22.464048.464048 lmp.py:376]   Expert 50 |    206 | GPU
DEBUG 01-05 09:59:22.464783.464783 lmp.py:376]   Expert 35 |    223 | GPU
DEBUG 01-05 09:59:22.464757.464757 lmp.py:376]   Expert 20 |    224 | GPU
DEBUG 01-05 09:59:22.464970.464970 lmp.py:376]   Expert 22 |    224 | GPU
DEBUG 01-05 09:59:22.464467.464467 lmp.py:376]   Expert 37 |    225 | GPU
DEBUG 01-05 09:59:22.464441.464441 lmp.py:376]   Expert 14 |    231 | GPU
DEBUG 01-05 09:59:22.464177.464177 lmp.py:376]   Expert 11 |    236 | GPU
DEBUG 01-05 09:59:22.464581.464581 lmp.py:376]   Expert 41 |    253 | GPU
DEBUG 01-05 09:59:22.464555.464555 lmp.py:376]   Expert 51 |    266 | GPU
DEBUG 01-05 09:59:22.464291.464291 lmp.py:376]   Expert 38 |    275 | GPU
DEBUG 01-05 09:59:22.465027.465027 lmp.py:376]   Expert 36 |    281 | GPU
DEBUG 01-05 09:59:22.465762.465762 lmp.py:376]   Expert 21 |    292 | GPU
DEBUG 01-05 09:59:22.465736.465736 lmp.py:376]   Expert 28 |    295 | GPU
DEBUG 01-05 09:59:22.465710.465710 lmp.py:376]   Expert 45 |    325 | GPU
DEBUG 01-05 09:59:22.465208.465208 lmp.py:376]   Expert 10 |    326 | GPU
DEBUG 01-05 09:59:22.465420.465420 lmp.py:376]   Expert  2 |    353 | GPU
DEBUG 01-05 09:59:22.465156.465156 lmp.py:376]   Expert  9 |    358 | GPU
DEBUG 01-05 09:59:22.465560.465560 lmp.py:376]   Expert 61 |    364 | GPU
DEBUG 01-05 09:59:22.465773.465773 lmp.py:376]   Expert  3 |    365 | GPU
DEBUG 01-05 09:59:22.465270.465270 lmp.py:376]   Expert 29 |    405 | GPU
DEBUG 01-05 09:59:22.465006.465006 lmp.py:376]   Expert 31 |    412 | GPU
DEBUG 01-05 09:59:22.465980.465980 lmp.py:376]   Expert  7 |    522 | GPU
DEBUG 01-05 09:59:22.465430.465430 lmp.py:377] 
DEBUG 01-05 09:59:22.465430.465430 lmp.py:377]   CPU total tokens: 3774 (30.7%)
DEBUG 01-05 09:59:22.465358.465358 lmp.py:378]   GPU total tokens: 8514 (69.3%)
DEBUG 01-05 09:59:22.465577.465577 cuda_h.py:19] end experts_map_get cost 0.0014829635620117188 seconds
DEBUG 01-05 09:59:22.465982.465982 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.465950.465950 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.465895.465895 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.465553.465553 cuda_h.py:19] end allocate_cuda_memory cost 0.00041675567626953125 seconds
DEBUG 01-05 09:59:22.465396.465396 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.465913.465913 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.466246.466246 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.466849.466849 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ec612a3-53fb-4082-9f5b-76945425fcf5
DEBUG 01-05 09:59:22.466882.466882 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.466564.466564 client.py:127] Model loaded
DEBUG 01-05 09:59:22.466328.466328 cuda_h.py:19] end sllm_worker_task cost 0.00899362564086914 seconds
INFO 01-05 09:59:22.467379.467379 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ec612a3-53fb-4082-9f5b-76945425fcf5
DEBUG 01-05 09:59:22.467176.467176 cuda_h.py:19] end load_into_gpu_async cost 0.0016994476318359375 seconds
DEBUG 01-05 09:59:22.467356.467356 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.468666.468666 cuda_h.py:19] end restore_tensors2 cost 0.00034356117248535156 seconds
DEBUG 01-05 09:59:22.468164.468164 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028035640716552734 seconds
DEBUG 01-05 09:59:22.470535.470535 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005402326583862305 seconds
DEBUG 01-05 09:59:22.470603.470603 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.470533.470533 lmp.py:423] 
DEBUG 01-05 09:59:22.470533.470533 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.470998.470998 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-05 09:59:22.470178.470178 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.478027.478027 mlpmodule.py:704] group tensors cost 0.007292032241821289 s
DEBUG 01-05 09:59:22.481266.481266 mlpmodule.py:742] pad cost 0.0023818016052246094 s
DEBUG 01-05 09:59:22.481297.481297 mlpmodule.py:748] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-05 09:59:22.481816.481816 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-05 09:59:22.491399.491399 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.491729.491729 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.491798.491798 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-05 09:59:22.491286.491286 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.507779.507779 mlpmodule.py:793] group einsum cost 0.025908708572387695 s
DEBUG 01-05 09:59:22.508106.508106 mlpmodule.py:801] cpy2cputensor cost 0.0006661415100097656 s
DEBUG 01-05 09:59:22.513444.513444 cuda_h.py:19] end wait_cetm_experts cost 0.04228520393371582 seconds
DEBUG 01-05 09:59:22.513953.513953 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.514173.514173 cuda_h.py:19] end gpu_sexperts cost 0.0005745887756347656 seconds
DEBUG 01-05 09:59:22.514923.514923 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.514064.514064 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.075599670410156e-05 seconds
DEBUG 01-05 09:59:22.514913.514913 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.514338.514338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ec612a3-53fb-4082-9f5b-76945425fcf5
INFO 01-05 09:59:22.523247.523247 client.py:127] Model loaded
DEBUG 01-05 09:59:22.523626.523626 cuda_h.py:19] end wait_experts cost 0.008817195892333984 seconds
DEBUG 01-05 09:59:22.523283.523283 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.523986.523986 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.523324.523324 mlpmodule.py:531] gpu group tensors cost 0.0005259513854980469 s
DEBUG 01-05 09:59:22.524172.524172 mlpmodule.py:662]  experts func einsum cost 0.053778648376464844 s
DEBUG 01-05 09:59:22.525595.525595 mlpmodule.py:564] gpu pad cost 0.0017161369323730469 s
DEBUG 01-05 09:59:22.526681.526681 mlpmodule.py:582] gpu group einsum cost 0.0004894733428955078 s
DEBUG 01-05 09:59:22.529402.529402 mlpmodule.py:611] gpu experts func einsum cost 0.005814075469970703 s
DEBUG 01-05 09:59:22.529193.529193 cuda_h.py:19] end gpu_experts cost 0.005982875823974609 seconds
DEBUG 01-05 09:59:22.529845.529845 cuda_h.py:19] end layer_moe_generate_19 cost 0.06617546081542969 seconds
DEBUG 01-05 09:59:22.529474.529474 lmp.py:217] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 09:59:22.529567.529567 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 09:59:22.529787.529787 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:59:22.529589.529589 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:59:22.529048.529048 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:22.529035.529035 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.151199340820312e-05 seconds
DEBUG 01-05 09:59:22.529394.529394 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.529516.529516 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.529705.529705 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.529733.529733 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.530368.530368 cuda_h.py:19] end allocate_cuda_memory cost 0.0003256797790527344 seconds
DEBUG 01-05 09:59:22.530715.530715 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.530286.530286 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.530486.530486 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.530189.530189 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 247b31b1-7e1f-462a-b396-59e91fa00bf5
DEBUG 01-05 09:59:22.530489.530489 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.530874.530874 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.531510.531510 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 247b31b1-7e1f-462a-b396-59e91fa00bf5
DEBUG 01-05 09:59:22.531201.531201 cuda_h.py:19] end load_into_gpu_async cost 0.0010251998901367188 seconds
DEBUG 01-05 09:59:22.531758.531758 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.531887.531887 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-05 09:59:22.531736.531736 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001672506332397461 seconds
INFO 01-05 09:59:22.532565.532565 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 247b31b1-7e1f-462a-b396-59e91fa00bf5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.534089.534089 cuda_h.py:19] end self_attn cost 0.003784656524658203 seconds
DEBUG 01-05 09:59:22.534874.534874 cuda_h.py:19] end iln_self_attn_paln cost 0.00520634651184082 seconds
DEBUG 01-05 09:59:22.534571.534571 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 09:59:22.534334.534334 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.535806.535806 cuda_h.py:19] end gate cost 0.0006310939788818359 seconds
DEBUG 01-05 09:59:22.535490.535490 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.535599.535599 lmp.py:365] 
DEBUG 01-05 09:59:22.535599.535599 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.535163.535163 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.535051.535051 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.535363.535363 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.535768.535768 lmp.py:369] 
DEBUG 01-05 09:59:22.535768.535768 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.536695.536695 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.536345.536345 lmp.py:376]   Expert 54 |     51 | CPU
DEBUG 01-05 09:59:22.536511.536511 lmp.py:376]   Expert 28 |     56 | CPU
DEBUG 01-05 09:59:22.536724.536724 lmp.py:376]   Expert  8 |     57 | CPU
DEBUG 01-05 09:59:22.536175.536175 lmp.py:376]   Expert 13 |     66 | CPU
DEBUG 01-05 09:59:22.536341.536341 lmp.py:376]   Expert  6 |     73 | CPU
DEBUG 01-05 09:59:22.536268.536268 lmp.py:376]   Expert 43 |     75 | CPU
DEBUG 01-05 09:59:22.536481.536481 lmp.py:376]   Expert  1 |     78 | CPU
DEBUG 01-05 09:59:22.536455.536455 lmp.py:376]   Expert 36 |     89 | CPU
DEBUG 01-05 09:59:22.536429.536429 lmp.py:376]   Expert 42 |     95 | CPU
DEBUG 01-05 09:59:22.536641.536641 lmp.py:376]   Expert 33 |    102 | CPU
DEBUG 01-05 09:59:22.536377.536377 lmp.py:376]   Expert 12 |    103 | CPU
DEBUG 01-05 09:59:22.536351.536351 lmp.py:376]   Expert 19 |    105 | CPU
DEBUG 01-05 09:59:22.536848.536848 lmp.py:376]   Expert 10 |    109 | CPU
DEBUG 01-05 09:59:22.536822.536822 lmp.py:376]   Expert 51 |    116 | CPU
DEBUG 01-05 09:59:22.536035.536035 lmp.py:376]   Expert 38 |    119 | CPU
DEBUG 01-05 09:59:22.536247.536247 lmp.py:376]   Expert 57 |    119 | CPU
DEBUG 01-05 09:59:22.536221.536221 lmp.py:376]   Expert 30 |    120 | CPU
DEBUG 01-05 09:59:22.536957.536957 lmp.py:376]   Expert 39 |    126 | CPU
DEBUG 01-05 09:59:22.536931.536931 lmp.py:376]   Expert  9 |    130 | CPU
DEBUG 01-05 09:59:22.536428.536428 lmp.py:376]   Expert 11 |    130 | CPU
DEBUG 01-05 09:59:22.536164.536164 lmp.py:376]   Expert 46 |    130 | CPU
DEBUG 01-05 09:59:22.536661.536661 lmp.py:376]   Expert 14 |    134 | CPU
DEBUG 01-05 09:59:22.536741.536741 lmp.py:376]   Expert 50 |    136 | CPU
DEBUG 01-05 09:59:22.536715.536715 lmp.py:376]   Expert  7 |    140 | CPU
DEBUG 01-05 09:59:22.536213.536213 lmp.py:376]   Expert 49 |    152 | CPU
DEBUG 01-05 09:59:22.536664.536664 lmp.py:376]   Expert 29 |    156 | CPU
DEBUG 01-05 09:59:22.536876.536876 lmp.py:376]   Expert 63 |    159 | CPU
DEBUG 01-05 09:59:22.536373.536373 lmp.py:376]   Expert 52 |    164 | CPU
DEBUG 01-05 09:59:22.536109.536109 lmp.py:376]   Expert 20 |    165 | CPU
DEBUG 01-05 09:59:22.536844.536844 lmp.py:376]   Expert  5 |    167 | CPU
DEBUG 01-05 09:59:22.536487.536487 lmp.py:376]   Expert 61 |    167 | CPU
DEBUG 01-05 09:59:22.536415.536415 lmp.py:376]   Expert 53 |    170 | CPU
DEBUG 01-05 09:59:22.536343.536343 lmp.py:376]   Expert  3 |    175 | GPU
DEBUG 01-05 09:59:22.536509.536509 lmp.py:376]   Expert 44 |    176 | GPU
DEBUG 01-05 09:59:22.536675.536675 lmp.py:376]   Expert 22 |    177 | GPU
DEBUG 01-05 09:59:22.536603.536603 lmp.py:376]   Expert 18 |    192 | GPU
DEBUG 01-05 09:59:22.536054.536054 lmp.py:376]   Expert 62 |    193 | GPU
DEBUG 01-05 09:59:22.536743.536743 lmp.py:376]   Expert  0 |    196 | GPU
DEBUG 01-05 09:59:22.536194.536194 lmp.py:376]   Expert 17 |    201 | GPU
DEBUG 01-05 09:59:22.536883.536883 lmp.py:376]   Expert 47 |    207 | GPU
DEBUG 01-05 09:59:22.536334.536334 lmp.py:376]   Expert 37 |    213 | GPU
DEBUG 01-05 09:59:22.536547.536547 lmp.py:376]   Expert  2 |    215 | GPU
DEBUG 01-05 09:59:22.536951.536951 lmp.py:376]   Expert 23 |    229 | GPU
DEBUG 01-05 09:59:22.536117.536117 lmp.py:376]   Expert 55 |    231 | GPU
DEBUG 01-05 09:59:22.536045.536045 lmp.py:376]   Expert 26 |    235 | GPU
DEBUG 01-05 09:59:22.536973.536973 lmp.py:376]   Expert 32 |    235 | GPU
DEBUG 01-05 09:59:22.536662.536662 lmp.py:376]   Expert 60 |    236 | GPU
DEBUG 01-05 09:59:22.536113.536113 lmp.py:376]   Expert 45 |    241 | GPU
DEBUG 01-05 09:59:22.536564.536564 lmp.py:376]   Expert 16 |    254 | GPU
DEBUG 01-05 09:59:22.536015.536015 lmp.py:376]   Expert 15 |    273 | GPU
DEBUG 01-05 09:59:22.536658.536658 lmp.py:376]   Expert 34 |    273 | GPU
DEBUG 01-05 09:59:22.536062.536062 lmp.py:376]   Expert 21 |    278 | GPU
DEBUG 01-05 09:59:22.536990.536990 lmp.py:376]   Expert 58 |    289 | GPU
DEBUG 01-05 09:59:22.536441.536441 lmp.py:376]   Expert 24 |    295 | GPU
DEBUG 01-05 09:59:22.536653.536653 lmp.py:376]   Expert 31 |    299 | GPU
DEBUG 01-05 09:59:22.536343.536343 lmp.py:376]   Expert  4 |    300 | GPU
DEBUG 01-05 09:59:22.536032.536032 lmp.py:376]   Expert 27 |    302 | GPU
DEBUG 01-05 09:59:22.536483.536483 lmp.py:376]   Expert 59 |    312 | GPU
DEBUG 01-05 09:59:22.536172.536172 lmp.py:376]   Expert 56 |    315 | GPU
DEBUG 01-05 09:59:22.537053.537053 lmp.py:376]   Expert 40 |    317 | GPU
DEBUG 01-05 09:59:22.537458.537458 lmp.py:376]   Expert 41 |    323 | GPU
DEBUG 01-05 09:59:22.537386.537386 lmp.py:376]   Expert 48 |    327 | GPU
DEBUG 01-05 09:59:22.537598.537598 lmp.py:376]   Expert 25 |    485 | GPU
DEBUG 01-05 09:59:22.537049.537049 lmp.py:376]   Expert 35 |    535 | GPU
DEBUG 01-05 09:59:22.537454.537454 lmp.py:377] 
DEBUG 01-05 09:59:22.537454.537454 lmp.py:377]   CPU total tokens: 3759 (30.6%)
DEBUG 01-05 09:59:22.537335.537335 lmp.py:378]   GPU total tokens: 8529 (69.4%)
DEBUG 01-05 09:59:22.537269.537269 cuda_h.py:19] end experts_map_get cost 0.0014944076538085938 seconds
DEBUG 01-05 09:59:22.537151.537151 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.537504.537504 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.537634.537634 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.537339.537339 cuda_h.py:19] end allocate_cuda_memory cost 0.0004506111145019531 seconds
DEBUG 01-05 09:59:22.537341.537341 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.537766.537766 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.537383.537383 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.537033.537033 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 275c7c54-ecd0-470d-a96f-f71c7f4f7c5e
DEBUG 01-05 09:59:22.538443.538443 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.538767.538767 client.py:127] Model loaded
DEBUG 01-05 09:59:22.538577.538577 cuda_h.py:19] end sllm_worker_task cost 0.00865316390991211 seconds
INFO 01-05 09:59:22.539659.539659 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 275c7c54-ecd0-470d-a96f-f71c7f4f7c5e
DEBUG 01-05 09:59:22.539171.539171 cuda_h.py:19] end load_into_gpu_async cost 0.0012083053588867188 seconds
DEBUG 01-05 09:59:22.539112.539112 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.539503.539503 cuda_h.py:19] end restore_tensors2 cost 0.0003674030303955078 seconds
DEBUG 01-05 09:59:22.539478.539478 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023810863494873047 seconds
DEBUG 01-05 09:59:22.542869.542869 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049970149993896484 seconds
DEBUG 01-05 09:59:22.542460.542460 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.542701.542701 lmp.py:423] 
DEBUG 01-05 09:59:22.542701.542701 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.542995.542995 cuda_h.py:19] end cpu_experts_submit cost 0.00012087821960449219 seconds
DEBUG 01-05 09:59:22.542505.542505 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.552074.552074 mlpmodule.py:704] group tensors cost 0.01005411148071289 s
DEBUG 01-05 09:59:22.554323.554323 mlpmodule.py:742] pad cost 0.0016689300537109375 s
DEBUG 01-05 09:59:22.555134.555134 mlpmodule.py:748] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-05 09:59:22.555474.555474 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-05 09:59:22.565338.565338 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.565625.565625 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.566728.566728 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 09:59:22.566302.566302 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.582730.582730 mlpmodule.py:793] group einsum cost 0.027529478073120117 s
DEBUG 01-05 09:59:22.583422.583422 mlpmodule.py:801] cpy2cputensor cost 0.0006871223449707031 s
DEBUG 01-05 09:59:22.588092.588092 cuda_h.py:19] end wait_cetm_experts cost 0.04571986198425293 seconds
DEBUG 01-05 09:59:22.588892.588892 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.588549.588549 cuda_h.py:19] end gpu_sexperts cost 0.0005667209625244141 seconds
DEBUG 01-05 09:59:22.589253.589253 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.589348.589348 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:22.589958.589958 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.589098.589098 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 275c7c54-ecd0-470d-a96f-f71c7f4f7c5e
INFO 01-05 09:59:22.594778.594778 client.py:127] Model loaded
DEBUG 01-05 09:59:22.594058.594058 cuda_h.py:19] end wait_experts cost 0.005730867385864258 seconds
DEBUG 01-05 09:59:22.594338.594338 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.594207.594207 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.595490.595490 mlpmodule.py:531] gpu group tensors cost 0.0006477832794189453 s
DEBUG 01-05 09:59:22.597127.597127 mlpmodule.py:564] gpu pad cost 0.0017819404602050781 s
DEBUG 01-05 09:59:22.598319.598319 mlpmodule.py:582] gpu group einsum cost 0.0005285739898681641 s
DEBUG 01-05 09:59:22.599816.599816 mlpmodule.py:662]  experts func einsum cost 0.05736231803894043 s
DEBUG 01-05 09:59:22.601462.601462 mlpmodule.py:611] gpu experts func einsum cost 0.006340980529785156 s
DEBUG 01-05 09:59:22.601824.601824 cuda_h.py:19] end gpu_experts cost 0.006579399108886719 seconds
DEBUG 01-05 09:59:22.601601.601601 cuda_h.py:19] end layer_moe_generate_20 cost 0.06673979759216309 seconds
DEBUG 01-05 09:59:22.601940.601940 lmp.py:217] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 09:59:22.601080.601080 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 09:59:22.601405.601405 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:59:22.601016.601016 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:59:22.601521.601521 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:22.602290.602290 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.581710815429688e-05 seconds
DEBUG 01-05 09:59:22.602841.602841 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.602214.602214 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.602721.602721 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.602419.602419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.602417.602417 cuda_h.py:19] end allocate_cuda_memory cost 0.00031280517578125 seconds
DEBUG 01-05 09:59:22.602651.602651 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.602838.602838 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.602468.602468 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.602741.602741 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e9e80d2-ceb3-4870-abc3-ccda315aebe3
DEBUG 01-05 09:59:22.602233.602233 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.603375.603375 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.603118.603118 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e9e80d2-ceb3-4870-abc3-ccda315aebe3
DEBUG 01-05 09:59:22.603477.603477 cuda_h.py:19] end load_into_gpu_async cost 0.0011026859283447266 seconds
DEBUG 01-05 09:59:22.603034.603034 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.603355.603355 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-05 09:59:22.604204.604204 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017242431640625 seconds
INFO 01-05 09:59:22.604055.604055 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e9e80d2-ceb3-4870-abc3-ccda315aebe3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.606582.606582 cuda_h.py:19] end self_attn cost 0.0031473636627197266 seconds
DEBUG 01-05 09:59:22.606440.606440 cuda_h.py:19] end iln_self_attn_paln cost 0.004625558853149414 seconds
DEBUG 01-05 09:59:22.606138.606138 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 09:59:22.606092.606092 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.607949.607949 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-05 09:59:22.607918.607918 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.607034.607034 lmp.py:365] 
DEBUG 01-05 09:59:22.607034.607034 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.607313.607313 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.607962.607962 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.607513.607513 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.607440.607440 lmp.py:369] 
DEBUG 01-05 09:59:22.607440.607440 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.607368.607368 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.607541.607541 lmp.py:376]   Expert  9 |     29 | CPU
DEBUG 01-05 09:59:22.607707.607707 lmp.py:376]   Expert 60 |     55 | CPU
DEBUG 01-05 09:59:22.607350.607350 lmp.py:376]   Expert 44 |     56 | CPU
DEBUG 01-05 09:59:22.608755.608755 lmp.py:376]   Expert 20 |     62 | CPU
DEBUG 01-05 09:59:22.608206.608206 lmp.py:376]   Expert 56 |     64 | CPU
DEBUG 01-05 09:59:22.608180.608180 lmp.py:376]   Expert 26 |     66 | CPU
DEBUG 01-05 09:59:22.608392.608392 lmp.py:376]   Expert  1 |     74 | CPU
DEBUG 01-05 09:59:22.608274.608274 lmp.py:376]   Expert 32 |     76 | CPU
DEBUG 01-05 09:59:22.608963.608963 lmp.py:376]   Expert 19 |     79 | CPU
DEBUG 01-05 09:59:22.608606.608606 lmp.py:376]   Expert 54 |     85 | CPU
DEBUG 01-05 09:59:22.608010.608010 lmp.py:376]   Expert 51 |     98 | CPU
DEBUG 01-05 09:59:22.608177.608177 lmp.py:376]   Expert  8 |    105 | CPU
DEBUG 01-05 09:59:22.608866.608866 lmp.py:376]   Expert 57 |    108 | CPU
DEBUG 01-05 09:59:22.608794.608794 lmp.py:376]   Expert 12 |    113 | CPU
DEBUG 01-05 09:59:22.608483.608483 lmp.py:376]   Expert  3 |    118 | CPU
DEBUG 01-05 09:59:22.608172.608172 lmp.py:376]   Expert 14 |    122 | CPU
DEBUG 01-05 09:59:22.608861.608861 lmp.py:376]   Expert 48 |    122 | CPU
DEBUG 01-05 09:59:22.608789.608789 lmp.py:376]   Expert  6 |    129 | CPU
DEBUG 01-05 09:59:22.608386.608386 lmp.py:376]   Expert 25 |    130 | CPU
DEBUG 01-05 09:59:22.608790.608790 lmp.py:376]   Expert 52 |    131 | CPU
DEBUG 01-05 09:59:22.608718.608718 lmp.py:376]   Expert  7 |    132 | CPU
DEBUG 01-05 09:59:22.608169.608169 lmp.py:376]   Expert 33 |    137 | CPU
DEBUG 01-05 09:59:22.608097.608097 lmp.py:376]   Expert 13 |    142 | CPU
DEBUG 01-05 09:59:22.608024.608024 lmp.py:376]   Expert 23 |    142 | CPU
DEBUG 01-05 09:59:22.608237.608237 lmp.py:376]   Expert 15 |    145 | CPU
DEBUG 01-05 09:59:22.608926.608926 lmp.py:376]   Expert 49 |    145 | CPU
DEBUG 01-05 09:59:22.608914.608914 lmp.py:376]   Expert 34 |    149 | CPU
DEBUG 01-05 09:59:22.608318.608318 lmp.py:376]   Expert 53 |    149 | CPU
DEBUG 01-05 09:59:22.608723.608723 lmp.py:376]   Expert 40 |    152 | CPU
DEBUG 01-05 09:59:22.608412.608412 lmp.py:376]   Expert 35 |    157 | CPU
DEBUG 01-05 09:59:22.608863.608863 lmp.py:376]   Expert 50 |    165 | CPU
DEBUG 01-05 09:59:22.608791.608791 lmp.py:376]   Expert 61 |    168 | CPU
DEBUG 01-05 09:59:22.608480.608480 lmp.py:376]   Expert 59 |    169 | GPU
DEBUG 01-05 09:59:22.608169.608169 lmp.py:376]   Expert 58 |    180 | GPU
DEBUG 01-05 09:59:22.608859.608859 lmp.py:376]   Expert 28 |    185 | GPU
DEBUG 01-05 09:59:22.608833.608833 lmp.py:376]   Expert 39 |    185 | GPU
DEBUG 01-05 09:59:22.608522.608522 lmp.py:376]   Expert 24 |    186 | GPU
DEBUG 01-05 09:59:22.608927.608927 lmp.py:376]   Expert 41 |    194 | GPU
DEBUG 01-05 09:59:22.608378.608378 lmp.py:376]   Expert 27 |    201 | GPU
DEBUG 01-05 09:59:22.608067.608067 lmp.py:376]   Expert 38 |    205 | GPU
DEBUG 01-05 09:59:22.608518.608518 lmp.py:376]   Expert  2 |    206 | GPU
DEBUG 01-05 09:59:22.608969.608969 lmp.py:376]   Expert 18 |    225 | GPU
DEBUG 01-05 09:59:22.608181.608181 lmp.py:376]   Expert 43 |    231 | GPU
DEBUG 01-05 09:59:22.608109.608109 lmp.py:376]   Expert 37 |    235 | GPU
DEBUG 01-05 09:59:22.608560.608560 lmp.py:376]   Expert 11 |    239 | GPU
DEBUG 01-05 09:59:22.608011.608011 lmp.py:376]   Expert  4 |    250 | GPU
DEBUG 01-05 09:59:22.608177.608177 lmp.py:376]   Expert 17 |    256 | GPU
DEBUG 01-05 09:59:22.608104.608104 lmp.py:376]   Expert 62 |    256 | GPU
DEBUG 01-05 09:59:22.608555.608555 lmp.py:376]   Expert 10 |    263 | GPU
DEBUG 01-05 09:59:22.608768.608768 lmp.py:376]   Expert 29 |    266 | GPU
DEBUG 01-05 09:59:22.608457.608457 lmp.py:376]   Expert 22 |    268 | GPU
DEBUG 01-05 09:59:22.608146.608146 lmp.py:376]   Expert 47 |    268 | GPU
DEBUG 01-05 09:59:22.608836.608836 lmp.py:376]   Expert  5 |    280 | GPU
DEBUG 01-05 09:59:22.608525.608525 lmp.py:376]   Expert 30 |    282 | GPU
DEBUG 01-05 09:59:22.608976.608976 lmp.py:376]   Expert 63 |    282 | GPU
DEBUG 01-05 09:59:22.608380.608380 lmp.py:376]   Expert 31 |    287 | GPU
DEBUG 01-05 09:59:22.608785.608785 lmp.py:376]   Expert 55 |    287 | GPU
DEBUG 01-05 09:59:22.608474.608474 lmp.py:376]   Expert 21 |    298 | GPU
DEBUG 01-05 09:59:22.608164.608164 lmp.py:376]   Expert 16 |    337 | GPU
DEBUG 01-05 09:59:22.608091.608091 lmp.py:376]   Expert 46 |    357 | GPU
DEBUG 01-05 09:59:22.608781.608781 lmp.py:376]   Expert 36 |    391 | GPU
DEBUG 01-05 09:59:22.608231.608231 lmp.py:376]   Expert 45 |    426 | GPU
DEBUG 01-05 09:59:22.609921.609921 lmp.py:376]   Expert  0 |    434 | GPU
DEBUG 01-05 09:59:22.609372.609372 lmp.py:376]   Expert 42 |    554 | GPU
DEBUG 01-05 09:59:22.609776.609776 lmp.py:377] 
DEBUG 01-05 09:59:22.609776.609776 lmp.py:377]   CPU total tokens: 3605 (29.3%)
DEBUG 01-05 09:59:22.609658.609658 lmp.py:378]   GPU total tokens: 8683 (70.7%)
DEBUG 01-05 09:59:22.609784.609784 cuda_h.py:19] end experts_map_get cost 0.0015239715576171875 seconds
DEBUG 01-05 09:59:22.609904.609904 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.609541.609541 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.609155.609155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.611692.611692 cuda_h.py:19] end allocate_cuda_memory cost 0.0019428730010986328 seconds
DEBUG 01-05 09:59:22.611058.611058 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.611311.611311 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.611835.611835 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.611439.611439 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cbce5433-d693-49cb-8c5d-74d197f9dc26
DEBUG 01-05 09:59:22.611386.611386 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.611441.611441 client.py:127] Model loaded
DEBUG 01-05 09:59:22.611251.611251 cuda_h.py:19] end sllm_worker_task cost 0.009701251983642578 seconds
INFO 01-05 09:59:22.612602.612602 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cbce5433-d693-49cb-8c5d-74d197f9dc26
DEBUG 01-05 09:59:22.612590.612590 cuda_h.py:19] end load_into_gpu_async cost 0.0012214183807373047 seconds
DEBUG 01-05 09:59:22.612532.612532 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.613591.613591 cuda_h.py:19] end restore_tensors2 cost 0.0003693103790283203 seconds
DEBUG 01-05 09:59:22.613951.613951 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038955211639404297 seconds
DEBUG 01-05 09:59:22.615208.615208 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006483316421508789 seconds
DEBUG 01-05 09:59:22.615322.615322 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.615755.615755 lmp.py:423] 
DEBUG 01-05 09:59:22.615755.615755 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.615956.615956 cuda_h.py:19] end cpu_experts_submit cost 0.00012350082397460938 seconds
DEBUG 01-05 09:59:22.615183.615183 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.628600.628600 mlpmodule.py:704] group tensors cost 0.01240086555480957 s
DEBUG 01-05 09:59:22.631304.631304 mlpmodule.py:742] pad cost 0.002132415771484375 s
DEBUG 01-05 09:59:22.631805.631805 mlpmodule.py:748] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-05 09:59:22.631636.631636 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 09:59:22.641001.641001 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.641755.641755 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.641738.641738 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 09:59:22.641371.641371 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.657369.657369 mlpmodule.py:793] group einsum cost 0.026362895965576172 s
DEBUG 01-05 09:59:22.658034.658034 mlpmodule.py:801] cpy2cputensor cost 0.0006723403930664062 s
DEBUG 01-05 09:59:22.663940.663940 cuda_h.py:19] end wait_cetm_experts cost 0.04746055603027344 seconds
DEBUG 01-05 09:59:22.663588.663588 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.664099.664099 cuda_h.py:19] end gpu_sexperts cost 0.0005788803100585938 seconds
DEBUG 01-05 09:59:22.664611.664611 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.697960.697960 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.03331613540649414 seconds
DEBUG 01-05 09:59:22.697240.697240 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.697811.697811 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cbce5433-d693-49cb-8c5d-74d197f9dc26
INFO 01-05 09:59:22.698969.698969 client.py:127] Model loaded
DEBUG 01-05 09:59:22.699550.699550 cuda_h.py:19] end wait_experts cost 0.001306772232055664 seconds
DEBUG 01-05 09:59:22.699983.699983 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.699800.699800 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.700751.700751 mlpmodule.py:531] gpu group tensors cost 0.0007605552673339844 s
DEBUG 01-05 09:59:22.701426.701426 mlpmodule.py:564] gpu pad cost 0.0014965534210205078 s
DEBUG 01-05 09:59:22.702478.702478 mlpmodule.py:582] gpu group einsum cost 0.0005059242248535156 s
DEBUG 01-05 09:59:22.705616.705616 mlpmodule.py:611] gpu experts func einsum cost 0.005820274353027344 s
DEBUG 01-05 09:59:22.705785.705785 cuda_h.py:19] end gpu_experts cost 0.006077289581298828 seconds
DEBUG 01-05 09:59:22.705085.705085 cuda_h.py:19] end layer_moe_generate_21 cost 0.09849047660827637 seconds
DEBUG 01-05 09:59:22.705230.705230 lmp.py:217] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 09:59:22.705417.705417 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 09:59:22.705682.705682 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:59:22.705246.705246 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:59:22.705275.705275 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.9087066650390625e-05 seconds
DEBUG 01-05 09:59:22.705713.705713 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.724761962890625e-05 seconds
DEBUG 01-05 09:59:22.705833.705833 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.705345.705345 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.705648.705648 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.705743.705743 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.710808.710808 cuda_h.py:19] end allocate_cuda_memory cost 0.004827260971069336 seconds
DEBUG 01-05 09:59:22.710619.710619 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.711217.711217 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.711222.711222 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.711589.711589 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 37e8fb14-5e28-4964-933c-7a93e45aa128
DEBUG 01-05 09:59:22.711331.711331 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.711924.711924 mlpmodule.py:662]  experts func einsum cost 0.09567737579345703 s
DEBUG 01-05 09:59:22.712836.712836 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.712235.712235 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 37e8fb14-5e28-4964-933c-7a93e45aa128
DEBUG 01-05 09:59:22.712115.712115 cuda_h.py:19] end load_into_gpu_async cost 0.0018756389617919922 seconds
DEBUG 01-05 09:59:22.712820.712820 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.713192.713192 cuda_h.py:19] end restore_tensors2 cost 0.0001442432403564453 seconds
DEBUG 01-05 09:59:22.713568.713568 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007432222366333008 seconds
INFO 01-05 09:59:22.714144.714144 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 37e8fb14-5e28-4964-933c-7a93e45aa128
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.717230.717230 cuda_h.py:19] end self_attn cost 0.005135297775268555 seconds
DEBUG 01-05 09:59:22.717240.717240 cuda_h.py:19] end iln_self_attn_paln cost 0.011928319931030273 seconds
DEBUG 01-05 09:59:22.717745.717745 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 09:59:22.717508.717508 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.718411.718411 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-05 09:59:22.718856.718856 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.718257.718257 lmp.py:365] 
DEBUG 01-05 09:59:22.718257.718257 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.718059.718059 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.718186.718186 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.718783.718783 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.718710.718710 lmp.py:369] 
DEBUG 01-05 09:59:22.718710.718710 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.718400.718400 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.718334.718334 lmp.py:376]   Expert 11 |     55 | CPU
DEBUG 01-05 09:59:22.718500.718500 lmp.py:376]   Expert 49 |     63 | CPU
DEBUG 01-05 09:59:22.718951.718951 lmp.py:376]   Expert 32 |     66 | CPU
DEBUG 01-05 09:59:22.718402.718402 lmp.py:376]   Expert  1 |     67 | CPU
DEBUG 01-05 09:59:22.718138.718138 lmp.py:376]   Expert 12 |     83 | CPU
DEBUG 01-05 09:59:22.718350.718350 lmp.py:376]   Expert  6 |     87 | CPU
DEBUG 01-05 09:59:22.718324.718324 lmp.py:376]   Expert 54 |     87 | CPU
DEBUG 01-05 09:59:22.718298.718298 lmp.py:376]   Expert  7 |     88 | CPU
DEBUG 01-05 09:59:22.718272.718272 lmp.py:376]   Expert 41 |     89 | CPU
DEBUG 01-05 09:59:22.719008.719008 lmp.py:376]   Expert 22 |     92 | CPU
DEBUG 01-05 09:59:22.719459.719459 lmp.py:376]   Expert 63 |     94 | CPU
DEBUG 01-05 09:59:22.719625.719625 lmp.py:376]   Expert 45 |     95 | CPU
DEBUG 01-05 09:59:22.719553.719553 lmp.py:376]   Expert 46 |     95 | CPU
DEBUG 01-05 09:59:22.719765.719765 lmp.py:376]   Expert 52 |     97 | CPU
DEBUG 01-05 09:59:22.719501.719501 lmp.py:376]   Expert 42 |     98 | CPU
DEBUG 01-05 09:59:22.719475.719475 lmp.py:376]   Expert 44 |     99 | CPU
DEBUG 01-05 09:59:22.719210.719210 lmp.py:376]   Expert 61 |     99 | CPU
DEBUG 01-05 09:59:22.719184.719184 lmp.py:376]   Expert 15 |    103 | CPU
DEBUG 01-05 09:59:22.719920.719920 lmp.py:376]   Expert 60 |    103 | CPU
DEBUG 01-05 09:59:22.719894.719894 lmp.py:376]   Expert 24 |    113 | CPU
DEBUG 01-05 09:59:22.719868.719868 lmp.py:376]   Expert 10 |    114 | CPU
DEBUG 01-05 09:59:22.719604.719604 lmp.py:376]   Expert 37 |    119 | CPU
DEBUG 01-05 09:59:22.719578.719578 lmp.py:376]   Expert 62 |    124 | CPU
DEBUG 01-05 09:59:22.719267.719267 lmp.py:376]   Expert 13 |    127 | CPU
DEBUG 01-05 09:59:22.719195.719195 lmp.py:376]   Expert 21 |    132 | CPU
DEBUG 01-05 09:59:22.719646.719646 lmp.py:376]   Expert  9 |    133 | CPU
DEBUG 01-05 09:59:22.719858.719858 lmp.py:376]   Expert 28 |    133 | CPU
DEBUG 01-05 09:59:22.719071.719071 lmp.py:376]   Expert  3 |    134 | CPU
DEBUG 01-05 09:59:22.719045.719045 lmp.py:376]   Expert 31 |    135 | CPU
DEBUG 01-05 09:59:22.719019.719019 lmp.py:376]   Expert 57 |    135 | CPU
DEBUG 01-05 09:59:22.719754.719754 lmp.py:376]   Expert 48 |    140 | CPU
DEBUG 01-05 09:59:22.719967.719967 lmp.py:376]   Expert 30 |    145 | CPU
DEBUG 01-05 09:59:22.719179.719179 lmp.py:376]   Expert  0 |    149 | GPU
DEBUG 01-05 09:59:22.719153.719153 lmp.py:376]   Expert 27 |    154 | GPU
DEBUG 01-05 09:59:22.719366.719366 lmp.py:376]   Expert 47 |    159 | GPU
DEBUG 01-05 09:59:22.719770.719770 lmp.py:376]   Expert 26 |    160 | GPU
DEBUG 01-05 09:59:22.719367.719367 lmp.py:376]   Expert 43 |    177 | GPU
DEBUG 01-05 09:59:22.719533.719533 lmp.py:376]   Expert 50 |    197 | GPU
DEBUG 01-05 09:59:22.719699.719699 lmp.py:376]   Expert 51 |    198 | GPU
DEBUG 01-05 09:59:22.719581.719581 lmp.py:376]   Expert 58 |    202 | GPU
DEBUG 01-05 09:59:22.719224.719224 lmp.py:376]   Expert 38 |    212 | GPU
DEBUG 01-05 09:59:22.719628.719628 lmp.py:376]   Expert 39 |    213 | GPU
DEBUG 01-05 09:59:22.719510.719510 lmp.py:376]   Expert 16 |    217 | GPU
DEBUG 01-05 09:59:22.719437.719437 lmp.py:376]   Expert  8 |    218 | GPU
DEBUG 01-05 09:59:22.719557.719557 lmp.py:376]   Expert  2 |    226 | GPU
DEBUG 01-05 09:59:22.719200.719200 lmp.py:376]   Expert 19 |    232 | GPU
DEBUG 01-05 09:59:22.719035.719035 lmp.py:376]   Expert 33 |    255 | GPU
DEBUG 01-05 09:59:22.719917.719917 lmp.py:376]   Expert 56 |    256 | GPU
DEBUG 01-05 09:59:22.719560.719560 lmp.py:376]   Expert  4 |    261 | GPU
DEBUG 01-05 09:59:22.719203.719203 lmp.py:376]   Expert 34 |    264 | GPU
DEBUG 01-05 09:59:22.719084.719084 lmp.py:376]   Expert 35 |    275 | GPU
DEBUG 01-05 09:59:22.719727.719727 lmp.py:376]   Expert 17 |    280 | GPU
DEBUG 01-05 09:59:22.719370.719370 lmp.py:376]   Expert 23 |    282 | GPU
DEBUG 01-05 09:59:22.719728.719728 lmp.py:376]   Expert 20 |    304 | GPU
DEBUG 01-05 09:59:22.719610.719610 lmp.py:376]   Expert 53 |    309 | GPU
DEBUG 01-05 09:59:22.719253.719253 lmp.py:376]   Expert 29 |    331 | GPU
DEBUG 01-05 09:59:22.719419.719419 lmp.py:376]   Expert 59 |    342 | GPU
DEBUG 01-05 09:59:22.719823.719823 lmp.py:376]   Expert 18 |    349 | GPU
DEBUG 01-05 09:59:22.719228.719228 lmp.py:376]   Expert 25 |    353 | GPU
DEBUG 01-05 09:59:22.719871.719871 lmp.py:376]   Expert 55 |    364 | GPU
DEBUG 01-05 09:59:22.719514.719514 lmp.py:376]   Expert 40 |    377 | GPU
DEBUG 01-05 09:59:22.719395.719395 lmp.py:376]   Expert 14 |    454 | GPU
DEBUG 01-05 09:59:22.719038.719038 lmp.py:376]   Expert 36 |    567 | GPU
DEBUG 01-05 09:59:22.719443.719443 lmp.py:376]   Expert  5 |    607 | GPU
DEBUG 01-05 09:59:22.719039.719039 lmp.py:377] 
DEBUG 01-05 09:59:22.719039.719039 lmp.py:377]   CPU total tokens: 3344 (27.2%)
DEBUG 01-05 09:59:22.719874.719874 lmp.py:378]   GPU total tokens: 8944 (72.8%)
DEBUG 01-05 09:59:22.719763.719763 cuda_h.py:19] end experts_map_get cost 0.00151824951171875 seconds
DEBUG 01-05 09:59:22.719359.719359 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.720281.720281 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.720803.720803 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.720533.720533 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-05 09:59:22.720330.720330 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.720609.720609 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.720464.720464 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.720498.720498 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 56a0927c-9a80-4e7c-96e1-7016656874e1
DEBUG 01-05 09:59:22.720247.720247 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.721560.721560 client.py:127] Model loaded
DEBUG 01-05 09:59:22.721711.721711 cuda_h.py:19] end sllm_worker_task cost 0.015314579010009766 seconds
INFO 01-05 09:59:22.722330.722330 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 56a0927c-9a80-4e7c-96e1-7016656874e1
DEBUG 01-05 09:59:22.722564.722564 cuda_h.py:19] end load_into_gpu_async cost 0.0018246173858642578 seconds
DEBUG 01-05 09:59:22.722413.722413 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.722942.722942 cuda_h.py:19] end restore_tensors2 cost 0.0003647804260253906 seconds
DEBUG 01-05 09:59:22.722871.722871 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002760648727416992 seconds
DEBUG 01-05 09:59:22.725462.725462 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0054204463958740234 seconds
DEBUG 01-05 09:59:22.725292.725292 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.725870.725870 lmp.py:423] 
DEBUG 01-05 09:59:22.725870.725870 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.725859.725859 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-05 09:59:22.725178.725178 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.737284.737284 mlpmodule.py:704] group tensors cost 0.011619806289672852 s
DEBUG 01-05 09:59:22.739221.739221 mlpmodule.py:742] pad cost 0.0016820430755615234 s
DEBUG 01-05 09:59:22.739682.739682 mlpmodule.py:748] create cpu tensor cost 7.104873657226562e-05 s
DEBUG 01-05 09:59:22.740168.740168 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:59:22.752586.752586 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.752400.752400 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.752370.752370 mlpmodule.py:773] group_w3 first element: 0.025390625
WARNING 01-05 09:59:22.753473.753473 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.770075.770075 mlpmodule.py:793] group einsum cost 0.03073573112487793 s
DEBUG 01-05 09:59:22.771591.771591 mlpmodule.py:801] cpy2cputensor cost 0.000553131103515625 s
DEBUG 01-05 09:59:22.776027.776027 cuda_h.py:19] end wait_cetm_experts cost 0.05040740966796875 seconds
DEBUG 01-05 09:59:22.776596.776596 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.776896.776896 cuda_h.py:19] end gpu_sexperts cost 0.0005972385406494141 seconds
DEBUG 01-05 09:59:22.777322.777322 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.777801.777801 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.266334533691406e-05 seconds
DEBUG 01-05 09:59:22.777173.777173 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.777359.777359 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 56a0927c-9a80-4e7c-96e1-7016656874e1
INFO 01-05 09:59:22.778187.778187 client.py:127] Model loaded
DEBUG 01-05 09:59:22.778176.778176 cuda_h.py:19] end wait_experts cost 0.0010595321655273438 seconds
DEBUG 01-05 09:59:22.778502.778502 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.778496.778496 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.779726.779726 mlpmodule.py:531] gpu group tensors cost 0.0006442070007324219 s
DEBUG 01-05 09:59:22.780485.780485 mlpmodule.py:564] gpu pad cost 0.0018222332000732422 s
DEBUG 01-05 09:59:22.781621.781621 mlpmodule.py:582] gpu group einsum cost 0.0004329681396484375 s
DEBUG 01-05 09:59:22.784910.784910 mlpmodule.py:611] gpu experts func einsum cost 0.006536245346069336 s
DEBUG 01-05 09:59:22.785505.785505 cuda_h.py:19] end gpu_experts cost 0.0067827701568603516 seconds
DEBUG 01-05 09:59:22.785965.785965 cuda_h.py:19] end layer_moe_generate_22 cost 0.06744074821472168 seconds
DEBUG 01-05 09:59:22.785833.785833 lmp.py:217] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 09:59:22.785596.785596 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 09:59:22.785107.785107 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:59:22.785346.785346 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:59:22.785004.785004 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.4332275390625e-05 seconds
DEBUG 01-05 09:59:22.785861.785861 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.785651.785651 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00015997886657714844 seconds
DEBUG 01-05 09:59:22.785111.785111 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.785093.785093 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.785678.785678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.788853.788853 cuda_h.py:19] end allocate_cuda_memory cost 0.002343893051147461 seconds
DEBUG 01-05 09:59:22.788476.788476 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.788345.788345 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.788313.788313 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.788447.788447 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba162157-53f3-4d12-816b-8523314f2674
DEBUG 01-05 09:59:22.788039.788039 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.788972.788972 mlpmodule.py:662]  experts func einsum cost 0.0630342960357666 s
DEBUG 01-05 09:59:22.789564.789564 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.789927.789927 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba162157-53f3-4d12-816b-8523314f2674
DEBUG 01-05 09:59:22.789545.789545 cuda_h.py:19] end load_into_gpu_async cost 0.0010254383087158203 seconds
DEBUG 01-05 09:59:22.789579.789579 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.789562.789562 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-05 09:59:22.789603.789603 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039021968841552734 seconds
INFO 01-05 09:59:22.790369.790369 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba162157-53f3-4d12-816b-8523314f2674
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.792158.792158 cuda_h.py:19] end self_attn cost 0.003392457962036133 seconds
DEBUG 01-05 09:59:22.793605.793605 cuda_h.py:19] end iln_self_attn_paln cost 0.007051706314086914 seconds
DEBUG 01-05 09:59:22.793779.793779 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 09:59:22.793257.793257 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.793074.793074 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-05 09:59:22.793996.793996 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.794874.794874 lmp.py:365] 
DEBUG 01-05 09:59:22.794874.794874 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.794961.794961 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.794088.794088 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.794161.794161 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.794850.794850 lmp.py:369] 
DEBUG 01-05 09:59:22.794850.794850 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.794778.794778 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.794713.794713 lmp.py:376]   Expert  5 |     56 | CPU
DEBUG 01-05 09:59:22.794117.794117 lmp.py:376]   Expert 27 |     64 | CPU
DEBUG 01-05 09:59:22.794330.794330 lmp.py:376]   Expert 49 |     66 | CPU
DEBUG 01-05 09:59:22.794781.794781 lmp.py:376]   Expert 19 |     78 | CPU
DEBUG 01-05 09:59:22.794947.794947 lmp.py:376]   Expert 44 |     83 | CPU
DEBUG 01-05 09:59:22.794159.794159 lmp.py:376]   Expert 55 |     90 | CPU
DEBUG 01-05 09:59:22.794133.794133 lmp.py:376]   Expert 17 |     94 | CPU
DEBUG 01-05 09:59:22.794630.794630 lmp.py:376]   Expert  7 |    100 | CPU
DEBUG 01-05 09:59:22.794366.794366 lmp.py:376]   Expert 53 |    105 | CPU
DEBUG 01-05 09:59:22.794863.794863 lmp.py:376]   Expert 52 |    116 | CPU
DEBUG 01-05 09:59:22.794360.794360 lmp.py:376]   Expert 25 |    120 | CPU
DEBUG 01-05 09:59:22.794858.794858 lmp.py:376]   Expert 22 |    121 | CPU
DEBUG 01-05 09:59:22.794593.794593 lmp.py:376]   Expert 40 |    122 | CPU
DEBUG 01-05 09:59:22.794806.794806 lmp.py:376]   Expert 43 |    122 | CPU
DEBUG 01-05 09:59:22.794018.794018 lmp.py:376]   Expert 34 |    125 | CPU
DEBUG 01-05 09:59:22.794231.794231 lmp.py:376]   Expert 35 |    127 | CPU
DEBUG 01-05 09:59:22.794728.794728 lmp.py:376]   Expert 58 |    127 | CPU
DEBUG 01-05 09:59:22.794702.794702 lmp.py:376]   Expert  4 |    128 | CPU
DEBUG 01-05 09:59:22.794199.794199 lmp.py:376]   Expert 38 |    130 | CPU
DEBUG 01-05 09:59:22.794173.794173 lmp.py:376]   Expert  6 |    137 | CPU
DEBUG 01-05 09:59:22.794670.794670 lmp.py:376]   Expert 16 |    138 | CPU
DEBUG 01-05 09:59:22.794644.794644 lmp.py:376]   Expert  1 |    141 | CPU
DEBUG 01-05 09:59:22.794857.794857 lmp.py:376]   Expert 42 |    145 | CPU
DEBUG 01-05 09:59:22.794354.794354 lmp.py:376]   Expert 63 |    145 | CPU
DEBUG 01-05 09:59:22.794090.794090 lmp.py:376]   Expert 51 |    153 | CPU
DEBUG 01-05 09:59:22.794825.794825 lmp.py:376]   Expert 47 |    158 | CPU
DEBUG 01-05 09:59:22.794561.794561 lmp.py:376]   Expert  9 |    163 | CPU
DEBUG 01-05 09:59:22.794058.794058 lmp.py:376]   Expert 13 |    169 | CPU
DEBUG 01-05 09:59:22.794032.794032 lmp.py:376]   Expert  0 |    181 | CPU
DEBUG 01-05 09:59:22.794722.794722 lmp.py:376]   Expert 30 |    181 | CPU
DEBUG 01-05 09:59:22.794841.794841 lmp.py:376]   Expert 36 |    182 | CPU
DEBUG 01-05 09:59:22.794769.794769 lmp.py:376]   Expert 46 |    183 | CPU
DEBUG 01-05 09:59:22.794220.794220 lmp.py:376]   Expert 45 |    187 | GPU
DEBUG 01-05 09:59:22.794671.794671 lmp.py:376]   Expert 26 |    189 | GPU
DEBUG 01-05 09:59:22.794360.794360 lmp.py:376]   Expert 62 |    189 | GPU
DEBUG 01-05 09:59:22.794573.794573 lmp.py:376]   Expert 23 |    198 | GPU
DEBUG 01-05 09:59:22.794785.794785 lmp.py:376]   Expert 28 |    199 | GPU
DEBUG 01-05 09:59:22.794951.794951 lmp.py:376]   Expert 11 |    200 | GPU
DEBUG 01-05 09:59:22.794594.794594 lmp.py:376]   Expert 39 |    204 | GPU
DEBUG 01-05 09:59:22.794283.794283 lmp.py:376]   Expert  2 |    212 | GPU
DEBUG 01-05 09:59:22.794973.794973 lmp.py:376]   Expert 15 |    216 | GPU
DEBUG 01-05 09:59:22.794662.794662 lmp.py:376]   Expert 60 |    216 | GPU
DEBUG 01-05 09:59:22.794875.794875 lmp.py:376]   Expert  3 |    220 | GPU
DEBUG 01-05 09:59:22.794325.794325 lmp.py:376]   Expert 41 |    223 | GPU
DEBUG 01-05 09:59:22.794776.794776 lmp.py:376]   Expert 61 |    223 | GPU
DEBUG 01-05 09:59:22.794466.794466 lmp.py:376]   Expert 12 |    227 | GPU
DEBUG 01-05 09:59:22.794109.794109 lmp.py:376]   Expert 24 |    229 | GPU
DEBUG 01-05 09:59:22.795036.795036 lmp.py:376]   Expert 29 |    246 | GPU
DEBUG 01-05 09:59:22.795249.795249 lmp.py:376]   Expert 14 |    262 | GPU
DEBUG 01-05 09:59:22.795700.795700 lmp.py:376]   Expert 10 |    265 | GPU
DEBUG 01-05 09:59:22.795912.795912 lmp.py:376]   Expert 21 |    267 | GPU
DEBUG 01-05 09:59:22.795125.795125 lmp.py:376]   Expert 20 |    270 | GPU
DEBUG 01-05 09:59:22.795575.795575 lmp.py:376]   Expert 31 |    278 | GPU
DEBUG 01-05 09:59:22.795265.795265 lmp.py:376]   Expert 32 |    278 | GPU
DEBUG 01-05 09:59:22.795192.795192 lmp.py:376]   Expert 33 |    281 | GPU
DEBUG 01-05 09:59:22.795882.795882 lmp.py:376]   Expert  8 |    287 | GPU
DEBUG 01-05 09:59:22.795856.795856 lmp.py:376]   Expert 57 |    289 | GPU
DEBUG 01-05 09:59:22.795307.795307 lmp.py:376]   Expert 59 |    298 | GPU
DEBUG 01-05 09:59:22.795519.795519 lmp.py:376]   Expert 50 |    302 | GPU
DEBUG 01-05 09:59:22.795255.795255 lmp.py:376]   Expert 37 |    303 | GPU
DEBUG 01-05 09:59:22.795706.795706 lmp.py:376]   Expert 18 |    305 | GPU
DEBUG 01-05 09:59:22.795918.795918 lmp.py:376]   Expert 56 |    375 | GPU
DEBUG 01-05 09:59:22.795607.795607 lmp.py:376]   Expert 48 |    394 | GPU
DEBUG 01-05 09:59:22.795297.795297 lmp.py:376]   Expert 54 |    406 | GPU
DEBUG 01-05 09:59:22.795701.795701 lmp.py:377] 
DEBUG 01-05 09:59:22.795701.795701 lmp.py:377]   CPU total tokens: 4050 (33.0%)
DEBUG 01-05 09:59:22.795106.795106 lmp.py:378]   GPU total tokens: 8238 (67.0%)
DEBUG 01-05 09:59:22.795040.795040 cuda_h.py:19] end experts_map_get cost 0.0014801025390625 seconds
DEBUG 01-05 09:59:22.795683.795683 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.795367.795367 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.795981.795981 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.796916.796916 cuda_h.py:19] end allocate_cuda_memory cost 0.0013926029205322266 seconds
DEBUG 01-05 09:59:22.797951.797951 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.797469.797469 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.797039.797039 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.797643.797643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2d0335ea-7bd5-4a20-8015-44ffcee0cba1
DEBUG 01-05 09:59:22.797961.797961 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.797889.797889 client.py:127] Model loaded
DEBUG 01-05 09:59:22.797898.797898 cuda_h.py:19] end sllm_worker_task cost 0.011854410171508789 seconds
INFO 01-05 09:59:22.798571.798571 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2d0335ea-7bd5-4a20-8015-44ffcee0cba1
DEBUG 01-05 09:59:22.798129.798129 cuda_h.py:19] end load_into_gpu_async cost 0.0013270378112792969 seconds
DEBUG 01-05 09:59:22.798070.798070 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.798242.798242 cuda_h.py:19] end restore_tensors2 cost 0.0003452301025390625 seconds
DEBUG 01-05 09:59:22.798263.798263 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003410816192626953 seconds
DEBUG 01-05 09:59:22.801634.801634 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006010770797729492 seconds
DEBUG 01-05 09:59:22.801986.801986 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.801850.801850 lmp.py:423] 
DEBUG 01-05 09:59:22.801850.801850 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.801938.801938 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-05 09:59:22.801826.801826 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.810048.810048 mlpmodule.py:704] group tensors cost 0.008540630340576172 s
DEBUG 01-05 09:59:22.812087.812087 mlpmodule.py:742] pad cost 0.0017747879028320312 s
DEBUG 01-05 09:59:22.812766.812766 mlpmodule.py:748] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-05 09:59:22.812676.812676 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-05 09:59:22.823500.823500 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.823645.823645 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.823727.823727 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-05 09:59:22.823513.823513 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.841804.841804 mlpmodule.py:793] group einsum cost 0.028661251068115234 s
DEBUG 01-05 09:59:22.842939.842939 mlpmodule.py:801] cpy2cputensor cost 0.0006623268127441406 s
DEBUG 01-05 09:59:22.847652.847652 cuda_h.py:19] end wait_cetm_experts cost 0.045548200607299805 seconds
DEBUG 01-05 09:59:22.847253.847253 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.847188.847188 cuda_h.py:19] end gpu_sexperts cost 0.0005774497985839844 seconds
DEBUG 01-05 09:59:22.848276.848276 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.848133.848133 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:22.848458.848458 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.848122.848122 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2d0335ea-7bd5-4a20-8015-44ffcee0cba1
INFO 01-05 09:59:22.853128.853128 client.py:127] Model loaded
DEBUG 01-05 09:59:22.853123.853123 cuda_h.py:19] end wait_experts cost 0.005585432052612305 seconds
DEBUG 01-05 09:59:22.853164.853164 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.853728.853728 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.854872.854872 mlpmodule.py:531] gpu group tensors cost 0.0006527900695800781 s
DEBUG 01-05 09:59:22.856748.856748 mlpmodule.py:564] gpu pad cost 0.001752614974975586 s
DEBUG 01-05 09:59:22.857815.857815 mlpmodule.py:582] gpu group einsum cost 0.0005397796630859375 s
DEBUG 01-05 09:59:22.858976.858976 mlpmodule.py:662]  experts func einsum cost 0.05665731430053711 s
DEBUG 01-05 09:59:22.860235.860235 mlpmodule.py:611] gpu experts func einsum cost 0.006739616394042969 s
DEBUG 01-05 09:59:22.860928.860928 cuda_h.py:19] end gpu_experts cost 0.006960153579711914 seconds
DEBUG 01-05 09:59:22.860613.860613 cuda_h.py:19] end layer_moe_generate_23 cost 0.06778860092163086 seconds
DEBUG 01-05 09:59:22.861996.861996 lmp.py:217] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 09:59:22.861375.861375 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 09:59:22.861402.861402 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:59:22.861012.861012 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:59:22.861041.861041 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.9802322387695312e-05 seconds
DEBUG 01-05 09:59:22.861333.861333 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.414817810058594e-05 seconds
DEBUG 01-05 09:59:22.861890.861890 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.861204.861204 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.861539.861539 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.861383.861383 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.861190.861190 cuda_h.py:19] end allocate_cuda_memory cost 0.0003476142883300781 seconds
DEBUG 01-05 09:59:22.861570.861570 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.862233.862233 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.862433.862433 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.862990.862990 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d430f9ca-a84f-4849-b181-5430a3d0af4a
DEBUG 01-05 09:59:22.862106.862106 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.862340.862340 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.863607.863607 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d430f9ca-a84f-4849-b181-5430a3d0af4a
DEBUG 01-05 09:59:22.863934.863934 cuda_h.py:19] end load_into_gpu_async cost 0.0011458396911621094 seconds
DEBUG 01-05 09:59:22.863644.863644 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.863555.863555 cuda_h.py:19] end restore_tensors2 cost 7.772445678710938e-05 seconds
DEBUG 01-05 09:59:22.863495.863495 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019979476928710938 seconds
INFO 01-05 09:59:22.864254.864254 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d430f9ca-a84f-4849-b181-5430a3d0af4a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.865124.865124 cuda_h.py:19] end self_attn cost 0.003360271453857422 seconds
DEBUG 01-05 09:59:22.866027.866027 cuda_h.py:19] end iln_self_attn_paln cost 0.00484776496887207 seconds
DEBUG 01-05 09:59:22.866771.866771 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 09:59:22.866295.866295 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.866196.866196 cuda_h.py:19] end gate cost 0.0005588531494140625 seconds
DEBUG 01-05 09:59:22.866926.866926 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.867366.867366 lmp.py:365] 
DEBUG 01-05 09:59:22.867366.867366 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.867453.867453 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.867911.867911 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.867461.867461 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.867150.867150 lmp.py:369] 
DEBUG 01-05 09:59:22.867150.867150 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.867555.867555 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.867728.867728 lmp.py:376]   Expert 43 |     66 | CPU
DEBUG 01-05 09:59:22.867656.867656 lmp.py:376]   Expert 47 |     67 | CPU
DEBUG 01-05 09:59:22.867107.867107 lmp.py:376]   Expert 42 |     73 | CPU
DEBUG 01-05 09:59:22.867796.867796 lmp.py:376]   Expert 44 |     77 | CPU
DEBUG 01-05 09:59:22.867485.867485 lmp.py:376]   Expert  6 |     78 | CPU
DEBUG 01-05 09:59:22.867698.867698 lmp.py:376]   Expert 25 |     79 | CPU
DEBUG 01-05 09:59:22.867433.867433 lmp.py:376]   Expert 35 |     89 | CPU
DEBUG 01-05 09:59:22.867361.867361 lmp.py:376]   Expert 62 |     91 | CPU
DEBUG 01-05 09:59:22.867289.867289 lmp.py:376]   Expert 60 |     95 | CPU
DEBUG 01-05 09:59:22.867978.867978 lmp.py:376]   Expert 48 |     97 | CPU
DEBUG 01-05 09:59:22.867859.867859 lmp.py:376]   Expert 55 |     98 | CPU
DEBUG 01-05 09:59:22.867264.867264 lmp.py:376]   Expert 29 |    100 | CPU
DEBUG 01-05 09:59:22.867953.867953 lmp.py:376]   Expert 54 |    100 | CPU
DEBUG 01-05 09:59:22.867404.867404 lmp.py:376]   Expert  5 |    102 | CPU
DEBUG 01-05 09:59:22.867855.867855 lmp.py:376]   Expert 16 |    114 | CPU
DEBUG 01-05 09:59:22.867829.867829 lmp.py:376]   Expert 22 |    128 | CPU
DEBUG 01-05 09:59:22.867042.867042 lmp.py:376]   Expert 30 |    128 | CPU
DEBUG 01-05 09:59:22.867492.867492 lmp.py:376]   Expert 51 |    136 | CPU
DEBUG 01-05 09:59:22.867943.867943 lmp.py:376]   Expert 56 |    137 | CPU
DEBUG 01-05 09:59:22.867109.867109 lmp.py:376]   Expert 36 |    149 | CPU
DEBUG 01-05 09:59:22.867514.867514 lmp.py:376]   Expert 61 |    151 | CPU
DEBUG 01-05 09:59:22.867965.867965 lmp.py:376]   Expert  4 |    152 | CPU
DEBUG 01-05 09:59:22.867177.867177 lmp.py:376]   Expert  7 |    158 | CPU
DEBUG 01-05 09:59:22.867390.867390 lmp.py:376]   Expert 28 |    158 | CPU
DEBUG 01-05 09:59:22.867602.867602 lmp.py:376]   Expert 49 |    159 | CPU
DEBUG 01-05 09:59:22.867053.867053 lmp.py:376]   Expert 59 |    164 | CPU
DEBUG 01-05 09:59:22.867742.867742 lmp.py:376]   Expert  1 |    168 | CPU
DEBUG 01-05 09:59:22.867193.867193 lmp.py:376]   Expert 38 |    172 | CPU
DEBUG 01-05 09:59:22.867598.867598 lmp.py:376]   Expert 20 |    173 | CPU
DEBUG 01-05 09:59:22.867526.867526 lmp.py:376]   Expert 17 |    176 | CPU
DEBUG 01-05 09:59:22.867215.867215 lmp.py:376]   Expert 31 |    178 | CPU
DEBUG 01-05 09:59:22.867666.867666 lmp.py:376]   Expert 46 |    182 | CPU
DEBUG 01-05 09:59:22.867878.867878 lmp.py:376]   Expert 21 |    186 | GPU
DEBUG 01-05 09:59:22.867329.867329 lmp.py:376]   Expert 34 |    189 | GPU
DEBUG 01-05 09:59:22.867780.867780 lmp.py:376]   Expert  0 |    190 | GPU
DEBUG 01-05 09:59:22.867992.867992 lmp.py:376]   Expert 14 |    190 | GPU
DEBUG 01-05 09:59:22.867966.867966 lmp.py:376]   Expert 15 |    192 | GPU
DEBUG 01-05 09:59:22.867656.867656 lmp.py:376]   Expert  3 |    201 | GPU
DEBUG 01-05 09:59:22.867822.867822 lmp.py:376]   Expert 53 |    201 | GPU
DEBUG 01-05 09:59:22.867511.867511 lmp.py:376]   Expert 40 |    202 | GPU
DEBUG 01-05 09:59:22.867962.867962 lmp.py:376]   Expert 19 |    203 | GPU
DEBUG 01-05 09:59:22.867413.867413 lmp.py:376]   Expert 41 |    210 | GPU
DEBUG 01-05 09:59:22.867864.867864 lmp.py:376]   Expert 63 |    211 | GPU
DEBUG 01-05 09:59:22.867076.867076 lmp.py:376]   Expert  2 |    218 | GPU
DEBUG 01-05 09:59:22.868289.868289 lmp.py:376]   Expert 24 |    222 | GPU
DEBUG 01-05 09:59:22.868501.868501 lmp.py:376]   Expert 37 |    223 | GPU
DEBUG 01-05 09:59:22.868714.868714 lmp.py:376]   Expert 10 |    229 | GPU
DEBUG 01-05 09:59:22.868403.868403 lmp.py:376]   Expert 57 |    233 | GPU
DEBUG 01-05 09:59:22.868615.868615 lmp.py:376]   Expert 26 |    237 | GPU
DEBUG 01-05 09:59:22.868066.868066 lmp.py:376]   Expert 50 |    238 | GPU
DEBUG 01-05 09:59:22.868994.868994 lmp.py:376]   Expert 23 |    246 | GPU
DEBUG 01-05 09:59:22.868922.868922 lmp.py:376]   Expert 45 |    246 | GPU
DEBUG 01-05 09:59:22.868373.868373 lmp.py:376]   Expert 58 |    246 | GPU
DEBUG 01-05 09:59:22.868300.868300 lmp.py:376]   Expert 32 |    254 | GPU
DEBUG 01-05 09:59:22.868990.868990 lmp.py:376]   Expert 52 |    268 | GPU
DEBUG 01-05 09:59:22.868394.868394 lmp.py:376]   Expert  9 |    285 | GPU
DEBUG 01-05 09:59:22.868084.868084 lmp.py:376]   Expert 18 |    287 | GPU
DEBUG 01-05 09:59:22.868011.868011 lmp.py:376]   Expert 12 |    291 | GPU
DEBUG 01-05 09:59:22.868985.868985 lmp.py:376]   Expert 13 |    320 | GPU
DEBUG 01-05 09:59:22.868198.868198 lmp.py:376]   Expert 33 |    335 | GPU
DEBUG 01-05 09:59:22.868410.868410 lmp.py:376]   Expert 39 |    338 | GPU
DEBUG 01-05 09:59:22.868384.868384 lmp.py:376]   Expert  8 |    357 | GPU
DEBUG 01-05 09:59:22.868312.868312 lmp.py:376]   Expert 11 |    375 | GPU
DEBUG 01-05 09:59:22.868478.868478 lmp.py:376]   Expert 27 |    670 | GPU
DEBUG 01-05 09:59:22.868406.868406 lmp.py:377] 
DEBUG 01-05 09:59:22.868406.868406 lmp.py:377]   CPU total tokens: 3995 (32.5%)
DEBUG 01-05 09:59:22.868572.868572 lmp.py:378]   GPU total tokens: 8293 (67.5%)
DEBUG 01-05 09:59:22.868090.868090 cuda_h.py:19] end experts_map_get cost 0.0014889240264892578 seconds
DEBUG 01-05 09:59:22.868163.868163 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.868847.868847 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.868792.868792 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.869768.869768 cuda_h.py:19] end allocate_cuda_memory cost 0.001249074935913086 seconds
DEBUG 01-05 09:59:22.869625.869625 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.869573.869573 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.870713.870713 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.870125.870125 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d3628670-9da1-442e-b76c-d4683a4c3c1f
DEBUG 01-05 09:59:22.870813.870813 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.873064.873064 client.py:127] Model loaded
DEBUG 01-05 09:59:22.874034.874034 cuda_h.py:19] end sllm_worker_task cost 0.012586832046508789 seconds
INFO 01-05 09:59:22.874643.874643 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d3628670-9da1-442e-b76c-d4683a4c3c1f
DEBUG 01-05 09:59:22.874870.874870 cuda_h.py:19] end load_into_gpu_async cost 0.004922389984130859 seconds
DEBUG 01-05 09:59:22.874050.874050 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.875540.875540 cuda_h.py:19] end restore_tensors2 cost 0.00037097930908203125 seconds
DEBUG 01-05 09:59:22.875847.875847 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006894111633300781 seconds
DEBUG 01-05 09:59:22.877334.877334 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009439945220947266 seconds
DEBUG 01-05 09:59:22.877018.877018 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.877544.877544 lmp.py:423] 
DEBUG 01-05 09:59:22.877544.877544 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.878956.878956 cuda_h.py:19] end cpu_experts_submit cost 0.000102996826171875 seconds
DEBUG 01-05 09:59:22.878368.878368 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.888175.888175 mlpmodule.py:704] group tensors cost 0.01042032241821289 s
DEBUG 01-05 09:59:22.890456.890456 mlpmodule.py:742] pad cost 0.001688241958618164 s
DEBUG 01-05 09:59:22.891049.891049 mlpmodule.py:748] create cpu tensor cost 6.008148193359375e-05 s
DEBUG 01-05 09:59:22.891714.891714 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-05 09:59:22.901694.901694 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.901501.901501 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.901670.901670 mlpmodule.py:773] group_w3 first element: -0.019287109375
WARNING 01-05 09:59:22.902548.902548 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.919566.919566 mlpmodule.py:793] group einsum cost 0.027757883071899414 s
DEBUG 01-05 09:59:22.919710.919710 mlpmodule.py:801] cpy2cputensor cost 0.000690460205078125 s
DEBUG 01-05 09:59:22.924611.924611 cuda_h.py:19] end wait_cetm_experts cost 0.046346187591552734 seconds
DEBUG 01-05 09:59:22.924788.924788 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:22.925637.925637 cuda_h.py:19] end gpu_sexperts cost 0.0005826950073242188 seconds
DEBUG 01-05 09:59:22.925626.925626 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:22.925483.925483 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0279159545898438e-05 seconds
DEBUG 01-05 09:59:22.925378.925378 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:22.925849.925849 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d3628670-9da1-442e-b76c-d4683a4c3c1f
INFO 01-05 09:59:22.930824.930824 client.py:127] Model loaded
DEBUG 01-05 09:59:22.930296.930296 cuda_h.py:19] end wait_experts cost 0.00545811653137207 seconds
DEBUG 01-05 09:59:22.930860.930860 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:22.931093.931093 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:22.931985.931985 mlpmodule.py:531] gpu group tensors cost 0.0006418228149414062 s
DEBUG 01-05 09:59:22.933683.933683 mlpmodule.py:564] gpu pad cost 0.0017933845520019531 s
DEBUG 01-05 09:59:22.934077.934077 mlpmodule.py:582] gpu group einsum cost 0.0004336833953857422 s
DEBUG 01-05 09:59:22.935817.935817 mlpmodule.py:662]  experts func einsum cost 0.057077646255493164 s
DEBUG 01-05 09:59:22.937434.937434 mlpmodule.py:611] gpu experts func einsum cost 0.00612330436706543 s
DEBUG 01-05 09:59:22.937756.937756 cuda_h.py:19] end gpu_experts cost 0.006354093551635742 seconds
DEBUG 01-05 09:59:22.937203.937203 cuda_h.py:19] end layer_moe_generate_24 cost 0.07121515274047852 seconds
DEBUG 01-05 09:59:22.937799.937799 lmp.py:217] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 09:59:22.937508.937508 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 09:59:22.937297.937297 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:59:22.937351.937351 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:59:22.937141.937141 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.956390380859375e-05 seconds
DEBUG 01-05 09:59:22.937196.937196 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.43865966796875e-05 seconds
DEBUG 01-05 09:59:22.937839.937839 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:22.937544.937544 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:22.938534.938534 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.938370.938370 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.938781.938781 cuda_h.py:19] end allocate_cuda_memory cost 0.00037288665771484375 seconds
DEBUG 01-05 09:59:22.938711.938711 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.938282.938282 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.938681.938681 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.938384.938384 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 57f99fb9-3683-45bb-83eb-a892c554a8b9
DEBUG 01-05 09:59:22.938592.938592 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:22.938208.938208 cuda_h.py:10] start self_attn
INFO 01-05 09:59:22.940633.940633 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 57f99fb9-3683-45bb-83eb-a892c554a8b9
DEBUG 01-05 09:59:22.940562.940562 cuda_h.py:19] end load_into_gpu_async cost 0.001645803451538086 seconds
DEBUG 01-05 09:59:22.940404.940404 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.940255.940255 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-05 09:59:22.940011.940011 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002354860305786133 seconds
INFO 01-05 09:59:22.940173.940173 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 57f99fb9-3683-45bb-83eb-a892c554a8b9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:22.942488.942488 cuda_h.py:19] end self_attn cost 0.003165721893310547 seconds
DEBUG 01-05 09:59:22.942419.942419 cuda_h.py:19] end iln_self_attn_paln cost 0.004649162292480469 seconds
DEBUG 01-05 09:59:22.942686.942686 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 09:59:22.942449.942449 cuda_h.py:10] start gate
DEBUG 01-05 09:59:22.943093.943093 cuda_h.py:19] end gate cost 0.0006167888641357422 seconds
DEBUG 01-05 09:59:22.943346.943346 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:22.943886.943886 lmp.py:365] 
DEBUG 01-05 09:59:22.943886.943886 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:22.943734.943734 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:22.943192.943192 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:22.943504.943504 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:22.943193.943193 lmp.py:369] 
DEBUG 01-05 09:59:22.943193.943193 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:22.943359.943359 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:22.943771.943771 lmp.py:376]   Expert 36 |     43 | CPU
DEBUG 01-05 09:59:22.943698.943698 lmp.py:376]   Expert 33 |     50 | CPU
DEBUG 01-05 09:59:22.943673.943673 lmp.py:376]   Expert 42 |     53 | CPU
DEBUG 01-05 09:59:22.943885.943885 lmp.py:376]   Expert 18 |     55 | CPU
DEBUG 01-05 09:59:22.943382.943382 lmp.py:376]   Expert 13 |     64 | CPU
DEBUG 01-05 09:59:22.943595.943595 lmp.py:376]   Expert  0 |     66 | CPU
DEBUG 01-05 09:59:22.943569.943569 lmp.py:376]   Expert 16 |     73 | CPU
DEBUG 01-05 09:59:22.943020.943020 lmp.py:376]   Expert 47 |     85 | CPU
DEBUG 01-05 09:59:22.943186.943186 lmp.py:376]   Expert 22 |     87 | CPU
DEBUG 01-05 09:59:22.943875.943875 lmp.py:376]   Expert 62 |     89 | CPU
DEBUG 01-05 09:59:22.943326.943326 lmp.py:376]   Expert 21 |     92 | CPU
DEBUG 01-05 09:59:22.943254.943254 lmp.py:376]   Expert 10 |    103 | CPU
DEBUG 01-05 09:59:22.943228.943228 lmp.py:376]   Expert 38 |    103 | CPU
DEBUG 01-05 09:59:22.943963.943963 lmp.py:376]   Expert 50 |    114 | CPU
DEBUG 01-05 09:59:22.943937.943937 lmp.py:376]   Expert 27 |    116 | CPU
DEBUG 01-05 09:59:22.943435.943435 lmp.py:376]   Expert 59 |    117 | CPU
DEBUG 01-05 09:59:22.943409.943409 lmp.py:376]   Expert 43 |    118 | CPU
DEBUG 01-05 09:59:22.943144.943144 lmp.py:376]   Expert  2 |    119 | CPU
DEBUG 01-05 09:59:22.944118.944118 lmp.py:376]   Expert  5 |    119 | CPU
DEBUG 01-05 09:59:22.944615.944615 lmp.py:376]   Expert 34 |    119 | CPU
DEBUG 01-05 09:59:22.944258.944258 lmp.py:376]   Expert 53 |    120 | CPU
DEBUG 01-05 09:59:22.944471.944471 lmp.py:376]   Expert 44 |    127 | CPU
DEBUG 01-05 09:59:22.944922.944922 lmp.py:376]   Expert 14 |    128 | CPU
DEBUG 01-05 09:59:22.944896.944896 lmp.py:376]   Expert 48 |    130 | CPU
DEBUG 01-05 09:59:22.944585.944585 lmp.py:376]   Expert 24 |    136 | CPU
DEBUG 01-05 09:59:22.944321.944321 lmp.py:376]   Expert 41 |    136 | CPU
DEBUG 01-05 09:59:22.944818.944818 lmp.py:376]   Expert  4 |    137 | CPU
DEBUG 01-05 09:59:22.944838.944838 lmp.py:376]   Expert 20 |    138 | CPU
DEBUG 01-05 09:59:22.944574.944574 lmp.py:376]   Expert 56 |    140 | CPU
DEBUG 01-05 09:59:22.944594.944594 lmp.py:376]   Expert 32 |    141 | CPU
DEBUG 01-05 09:59:22.944330.944330 lmp.py:376]   Expert 31 |    147 | CPU
DEBUG 01-05 09:59:22.944589.944589 lmp.py:376]   Expert 45 |    157 | CPU
DEBUG 01-05 09:59:22.944470.944470 lmp.py:376]   Expert 23 |    158 | GPU
DEBUG 01-05 09:59:22.944398.944398 lmp.py:376]   Expert 55 |    159 | GPU
DEBUG 01-05 09:59:22.944710.944710 lmp.py:376]   Expert  3 |    162 | GPU
DEBUG 01-05 09:59:22.944876.944876 lmp.py:376]   Expert 46 |    164 | GPU
DEBUG 01-05 09:59:22.944042.944042 lmp.py:376]   Expert 39 |    185 | GPU
DEBUG 01-05 09:59:22.944447.944447 lmp.py:376]   Expert 61 |    186 | GPU
DEBUG 01-05 09:59:22.944897.944897 lmp.py:376]   Expert  6 |    187 | GPU
DEBUG 01-05 09:59:22.944348.944348 lmp.py:376]   Expert 51 |    197 | GPU
DEBUG 01-05 09:59:22.944561.944561 lmp.py:376]   Expert 52 |    204 | GPU
DEBUG 01-05 09:59:22.944356.944356 lmp.py:376]   Expert  1 |    207 | GPU
DEBUG 01-05 09:59:22.944046.944046 lmp.py:376]   Expert 12 |    212 | GPU
DEBUG 01-05 09:59:22.944973.944973 lmp.py:376]   Expert  8 |    217 | GPU
DEBUG 01-05 09:59:22.944424.944424 lmp.py:376]   Expert 40 |    219 | GPU
DEBUG 01-05 09:59:22.944114.944114 lmp.py:376]   Expert 11 |    224 | GPU
DEBUG 01-05 09:59:22.944564.944564 lmp.py:376]   Expert 35 |    229 | GPU
DEBUG 01-05 09:59:22.944254.944254 lmp.py:376]   Expert  7 |    242 | GPU
DEBUG 01-05 09:59:22.944135.944135 lmp.py:376]   Expert 15 |    251 | GPU
DEBUG 01-05 09:59:22.944301.944301 lmp.py:376]   Expert 49 |    255 | GPU
DEBUG 01-05 09:59:22.944467.944467 lmp.py:376]   Expert 37 |    262 | GPU
DEBUG 01-05 09:59:22.944395.944395 lmp.py:376]   Expert 57 |    285 | GPU
DEBUG 01-05 09:59:22.944369.944369 lmp.py:376]   Expert 26 |    291 | GPU
DEBUG 01-05 09:59:22.944582.944582 lmp.py:376]   Expert 28 |    296 | GPU
DEBUG 01-05 09:59:22.944794.944794 lmp.py:376]   Expert 30 |    302 | GPU
DEBUG 01-05 09:59:22.944530.944530 lmp.py:376]   Expert 63 |    327 | GPU
DEBUG 01-05 09:59:22.944981.944981 lmp.py:376]   Expert 58 |    330 | GPU
DEBUG 01-05 09:59:22.944716.944716 lmp.py:376]   Expert 54 |    366 | GPU
DEBUG 01-05 09:59:22.944929.944929 lmp.py:376]   Expert 25 |    382 | GPU
DEBUG 01-05 09:59:22.944141.944141 lmp.py:376]   Expert  9 |    398 | GPU
DEBUG 01-05 09:59:22.944354.944354 lmp.py:376]   Expert 17 |    431 | GPU
DEBUG 01-05 09:59:22.944997.944997 lmp.py:376]   Expert 60 |    464 | GPU
DEBUG 01-05 09:59:22.944401.944401 lmp.py:376]   Expert 29 |    501 | GPU
DEBUG 01-05 09:59:22.944090.944090 lmp.py:376]   Expert 19 |    573 | GPU
DEBUG 01-05 09:59:22.944449.944449 lmp.py:377] 
DEBUG 01-05 09:59:22.944449.944449 lmp.py:377]   CPU total tokens: 3422 (27.8%)
DEBUG 01-05 09:59:22.944615.944615 lmp.py:378]   GPU total tokens: 8866 (72.2%)
DEBUG 01-05 09:59:22.944072.944072 cuda_h.py:19] end experts_map_get cost 0.0014917850494384766 seconds
DEBUG 01-05 09:59:22.944477.944477 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:22.944638.944638 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:22.945444.945444 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:22.946033.946033 cuda_h.py:19] end allocate_cuda_memory cost 0.0013501644134521484 seconds
DEBUG 01-05 09:59:22.946274.946274 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:22.946791.946791 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:22.946362.946362 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:22.946204.946204 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5ce83e15-fec6-423f-a984-33bc9ae8e19d
DEBUG 01-05 09:59:22.946138.946138 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:22.948403.948403 client.py:127] Model loaded
DEBUG 01-05 09:59:22.948160.948160 cuda_h.py:19] end sllm_worker_task cost 0.010192394256591797 seconds
INFO 01-05 09:59:22.949788.949788 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5ce83e15-fec6-423f-a984-33bc9ae8e19d
DEBUG 01-05 09:59:22.949501.949501 cuda_h.py:19] end load_into_gpu_async cost 0.0033843517303466797 seconds
DEBUG 01-05 09:59:22.949749.949749 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:22.950181.950181 cuda_h.py:19] end restore_tensors2 cost 0.0003960132598876953 seconds
DEBUG 01-05 09:59:22.950011.950011 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0055904388427734375 seconds
DEBUG 01-05 09:59:22.952484.952484 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008089542388916016 seconds
DEBUG 01-05 09:59:22.953452.953452 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:22.953621.953621 lmp.py:423] 
DEBUG 01-05 09:59:22.953621.953621 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:22.953802.953802 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-05 09:59:22.953597.953597 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:22.965044.965044 mlpmodule.py:704] group tensors cost 0.011782407760620117 s
DEBUG 01-05 09:59:22.967809.967809 mlpmodule.py:742] pad cost 0.0014820098876953125 s
DEBUG 01-05 09:59:22.967335.967335 mlpmodule.py:748] create cpu tensor cost 5.3882598876953125e-05 s
DEBUG 01-05 09:59:22.967801.967801 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-05 09:59:22.977754.977754 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:22.978277.978277 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:22.978598.978598 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 09:59:22.978774.978774 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:22.996468.996468 mlpmodule.py:793] group einsum cost 0.029140949249267578 s
DEBUG 01-05 09:59:22.997238.997238 mlpmodule.py:801] cpy2cputensor cost 0.0006551742553710938 s
DEBUG 01-05 09:59:23.002592.002592 cuda_h.py:19] end wait_cetm_experts cost 0.04902958869934082 seconds
DEBUG 01-05 09:59:23.002448.002448 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:23.002326.002326 cuda_h.py:19] end gpu_sexperts cost 0.0004649162292480469 seconds
DEBUG 01-05 09:59:23.002639.002639 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:23.002728.002728 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.765655517578125e-05 seconds
DEBUG 01-05 09:59:23.002623.002623 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:23.003332.003332 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5ce83e15-fec6-423f-a984-33bc9ae8e19d
INFO 01-05 09:59:23.004354.004354 client.py:127] Model loaded
DEBUG 01-05 09:59:23.004959.004959 cuda_h.py:19] end wait_experts cost 0.0016922950744628906 seconds
DEBUG 01-05 09:59:23.004377.004377 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:23.004941.004941 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:23.005965.005965 mlpmodule.py:531] gpu group tensors cost 0.0006361007690429688 s
DEBUG 01-05 09:59:23.007910.007910 mlpmodule.py:564] gpu pad cost 0.0016622543334960938 s
DEBUG 01-05 09:59:23.007800.007800 mlpmodule.py:582] gpu group einsum cost 0.00042057037353515625 s
DEBUG 01-05 09:59:23.011097.011097 mlpmodule.py:611] gpu experts func einsum cost 0.006173849105834961 s
DEBUG 01-05 09:59:23.011995.011995 cuda_h.py:19] end gpu_experts cost 0.006360530853271484 seconds
DEBUG 01-05 09:59:23.011925.011925 cuda_h.py:19] end layer_moe_generate_25 cost 0.06861329078674316 seconds
DEBUG 01-05 09:59:23.011303.011303 lmp.py:217] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 09:59:23.011781.011781 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 09:59:23.011099.011099 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:59:23.011624.011624 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:59:23.011719.011719 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.886222839355469e-05 seconds
DEBUG 01-05 09:59:23.011759.011759 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.200241088867188e-05 seconds
DEBUG 01-05 09:59:23.011124.011124 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:23.011386.011386 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:59:23.011388.011388 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:23.011456.011456 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:23.013434.013434 cuda_h.py:19] end allocate_cuda_memory cost 0.0020859241485595703 seconds
DEBUG 01-05 09:59:23.014299.014299 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:23.014784.014784 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:23.014342.014342 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:23.014999.014999 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e6cad2e7-2715-4d18-89c7-b815c709a54b
DEBUG 01-05 09:59:23.014876.014876 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:59:23.014219.014219 cuda_h.py:10] start self_attn
INFO 01-05 09:59:23.015855.015855 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e6cad2e7-2715-4d18-89c7-b815c709a54b
DEBUG 01-05 09:59:23.015772.015772 cuda_h.py:19] end load_into_gpu_async cost 0.0012133121490478516 seconds
DEBUG 01-05 09:59:23.015488.015488 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:23.015353.015353 cuda_h.py:19] end restore_tensors2 cost 7.772445678710938e-05 seconds
DEBUG 01-05 09:59:23.015587.015587 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037300586700439453 seconds
INFO 01-05 09:59:23.016201.016201 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e6cad2e7-2715-4d18-89c7-b815c709a54b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:23.018624.018624 cuda_h.py:19] end self_attn cost 0.0041272640228271484 seconds
DEBUG 01-05 09:59:23.019489.019489 cuda_h.py:19] end iln_self_attn_paln cost 0.0075037479400634766 seconds
DEBUG 01-05 09:59:23.019333.019333 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 09:59:23.019956.019956 cuda_h.py:10] start gate
DEBUG 01-05 09:59:23.019595.019595 mlpmodule.py:662]  experts func einsum cost 0.06603121757507324 s
DEBUG 01-05 09:59:23.019504.019504 cuda_h.py:19] end gate cost 0.0006818771362304688 seconds
DEBUG 01-05 09:59:23.020817.020817 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:23.020078.020078 lmp.py:365] 
DEBUG 01-05 09:59:23.020078.020078 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:23.020510.020510 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:23.020398.020398 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:23.020902.020902 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:23.020830.020830 lmp.py:369] 
DEBUG 01-05 09:59:23.020830.020830 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:23.020758.020758 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:23.020931.020931 lmp.py:376]   Expert 17 |     55 | CPU
DEBUG 01-05 09:59:23.020858.020858 lmp.py:376]   Expert 62 |     56 | CPU
DEBUG 01-05 09:59:23.020071.020071 lmp.py:376]   Expert  3 |     61 | CPU
DEBUG 01-05 09:59:23.020999.020999 lmp.py:376]   Expert 49 |     66 | CPU
DEBUG 01-05 09:59:23.020211.020211 lmp.py:376]   Expert 58 |     68 | CPU
DEBUG 01-05 09:59:23.020423.020423 lmp.py:376]   Expert 30 |     72 | CPU
DEBUG 01-05 09:59:23.020636.020636 lmp.py:376]   Expert 59 |     72 | CPU
DEBUG 01-05 09:59:23.020372.020372 lmp.py:376]   Expert 24 |     79 | CPU
DEBUG 01-05 09:59:23.020584.020584 lmp.py:376]   Expert 55 |     80 | CPU
DEBUG 01-05 09:59:23.020512.020512 lmp.py:376]   Expert 51 |     81 | CPU
DEBUG 01-05 09:59:23.020247.020247 lmp.py:376]   Expert 19 |     83 | CPU
DEBUG 01-05 09:59:23.020221.020221 lmp.py:376]   Expert 61 |     86 | CPU
DEBUG 01-05 09:59:23.020957.020957 lmp.py:376]   Expert  8 |     88 | CPU
DEBUG 01-05 09:59:23.020931.020931 lmp.py:376]   Expert  9 |     88 | CPU
DEBUG 01-05 09:59:23.020190.020190 lmp.py:376]   Expert  7 |     90 | CPU
DEBUG 01-05 09:59:23.020164.020164 lmp.py:376]   Expert 56 |     94 | CPU
DEBUG 01-05 09:59:23.020661.020661 lmp.py:376]   Expert 15 |     97 | CPU
DEBUG 01-05 09:59:23.020542.020542 lmp.py:376]   Expert 60 |    101 | CPU
DEBUG 01-05 09:59:23.020232.020232 lmp.py:376]   Expert  6 |    102 | CPU
DEBUG 01-05 09:59:23.020067.020067 lmp.py:376]   Expert 21 |    103 | CPU
DEBUG 01-05 09:59:23.020471.020471 lmp.py:376]   Expert 11 |    111 | CPU
DEBUG 01-05 09:59:23.020638.020638 lmp.py:376]   Expert 12 |    115 | CPU
DEBUG 01-05 09:59:23.020565.020565 lmp.py:376]   Expert 43 |    116 | CPU
DEBUG 01-05 09:59:23.020016.020016 lmp.py:376]   Expert 13 |    123 | CPU
DEBUG 01-05 09:59:23.020705.020705 lmp.py:376]   Expert 38 |    136 | CPU
DEBUG 01-05 09:59:23.020156.020156 lmp.py:376]   Expert 26 |    137 | CPU
DEBUG 01-05 09:59:23.020276.020276 lmp.py:376]   Expert 27 |    138 | CPU
DEBUG 01-05 09:59:23.020442.020442 lmp.py:376]   Expert  0 |    139 | CPU
DEBUG 01-05 09:59:23.020370.020370 lmp.py:376]   Expert 29 |    140 | CPU
DEBUG 01-05 09:59:23.020059.020059 lmp.py:376]   Expert 28 |    141 | CPU
DEBUG 01-05 09:59:23.020749.020749 lmp.py:376]   Expert 41 |    141 | CPU
DEBUG 01-05 09:59:23.021961.021961 lmp.py:376]   Expert 47 |    142 | CPU
DEBUG 01-05 09:59:23.021650.021650 lmp.py:376]   Expert 53 |    144 | GPU
DEBUG 01-05 09:59:23.021101.021101 lmp.py:376]   Expert 22 |    146 | GPU
DEBUG 01-05 09:59:23.021791.021791 lmp.py:376]   Expert 45 |    146 | GPU
DEBUG 01-05 09:59:23.021480.021480 lmp.py:376]   Expert 34 |    154 | GPU
DEBUG 01-05 09:59:23.021646.021646 lmp.py:376]   Expert 37 |    174 | GPU
DEBUG 01-05 09:59:23.021335.021335 lmp.py:376]   Expert 57 |    176 | GPU
DEBUG 01-05 09:59:23.021786.021786 lmp.py:376]   Expert 48 |    182 | GPU
DEBUG 01-05 09:59:23.021237.021237 lmp.py:376]   Expert 32 |    188 | GPU
DEBUG 01-05 09:59:23.021165.021165 lmp.py:376]   Expert 23 |    196 | GPU
DEBUG 01-05 09:59:23.021616.021616 lmp.py:376]   Expert  1 |    201 | GPU
DEBUG 01-05 09:59:23.021305.021305 lmp.py:376]   Expert 42 |    201 | GPU
DEBUG 01-05 09:59:23.021994.021994 lmp.py:376]   Expert 36 |    209 | GPU
DEBUG 01-05 09:59:23.021922.021922 lmp.py:376]   Expert 54 |    226 | GPU
DEBUG 01-05 09:59:23.021327.021327 lmp.py:376]   Expert  4 |    227 | GPU
DEBUG 01-05 09:59:23.021016.021016 lmp.py:376]   Expert 39 |    230 | GPU
DEBUG 01-05 09:59:23.021705.021705 lmp.py:376]   Expert 31 |    242 | GPU
DEBUG 01-05 09:59:23.021156.021156 lmp.py:376]   Expert 16 |    252 | GPU
DEBUG 01-05 09:59:23.021845.021845 lmp.py:376]   Expert 20 |    261 | GPU
DEBUG 01-05 09:59:23.021535.021535 lmp.py:376]   Expert 33 |    270 | GPU
DEBUG 01-05 09:59:23.021224.021224 lmp.py:376]   Expert  2 |    289 | GPU
DEBUG 01-05 09:59:23.021436.021436 lmp.py:376]   Expert 44 |    299 | GPU
DEBUG 01-05 09:59:23.021364.021364 lmp.py:376]   Expert 18 |    313 | GPU
DEBUG 01-05 09:59:23.021053.021053 lmp.py:376]   Expert 25 |    316 | GPU
DEBUG 01-05 09:59:23.021935.021935 lmp.py:376]   Expert 50 |    326 | GPU
DEBUG 01-05 09:59:23.021578.021578 lmp.py:376]   Expert  5 |    333 | GPU
DEBUG 01-05 09:59:23.021505.021505 lmp.py:376]   Expert 35 |    365 | GPU
DEBUG 01-05 09:59:23.021433.021433 lmp.py:376]   Expert 10 |    367 | GPU
DEBUG 01-05 09:59:23.021123.021123 lmp.py:376]   Expert 63 |    410 | GPU
DEBUG 01-05 09:59:23.021573.021573 lmp.py:376]   Expert 40 |    455 | GPU
DEBUG 01-05 09:59:23.021501.021501 lmp.py:376]   Expert 46 |    471 | GPU
DEBUG 01-05 09:59:23.021429.021429 lmp.py:376]   Expert 52 |    512 | GPU
DEBUG 01-05 09:59:23.021357.021357 lmp.py:376]   Expert 14 |    806 | GPU
DEBUG 01-05 09:59:23.021000.021000 lmp.py:377] 
DEBUG 01-05 09:59:23.021000.021000 lmp.py:377]   CPU total tokens: 3201 (26.0%)
DEBUG 01-05 09:59:23.021881.021881 lmp.py:378]   GPU total tokens: 9087 (74.0%)
DEBUG 01-05 09:59:23.021531.021531 cuda_h.py:19] end experts_map_get cost 0.001516103744506836 seconds
DEBUG 01-05 09:59:23.021889.021889 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:23.021242.021242 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:23.021425.021425 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:23.022831.022831 cuda_h.py:19] end allocate_cuda_memory cost 0.00022411346435546875 seconds
DEBUG 01-05 09:59:23.022482.022482 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:23.022476.022476 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:23.022855.022855 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:23.022505.022505 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f3fb9edb-78c8-4279-bcf2-1d4b34e00a82
DEBUG 01-05 09:59:23.022108.022108 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:23.022001.022001 client.py:127] Model loaded
DEBUG 01-05 09:59:23.022811.022811 cuda_h.py:19] end sllm_worker_task cost 0.010846138000488281 seconds
INFO 01-05 09:59:23.023532.023532 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f3fb9edb-78c8-4279-bcf2-1d4b34e00a82
DEBUG 01-05 09:59:23.023282.023282 cuda_h.py:19] end load_into_gpu_async cost 0.0011181831359863281 seconds
DEBUG 01-05 09:59:23.023224.023224 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:23.023057.023057 cuda_h.py:19] end restore_tensors2 cost 0.0003428459167480469 seconds
DEBUG 01-05 09:59:23.023125.023125 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020329952239990234 seconds
DEBUG 01-05 09:59:23.026548.026548 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004637718200683594 seconds
DEBUG 01-05 09:59:23.026424.026424 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:23.026878.026878 lmp.py:423] 
DEBUG 01-05 09:59:23.026878.026878 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:23.026098.026098 cuda_h.py:19] end cpu_experts_submit cost 0.00010275840759277344 seconds
DEBUG 01-05 09:59:23.026417.026417 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:23.030603.030603 mlpmodule.py:704] group tensors cost 0.004262685775756836 s
DEBUG 01-05 09:59:23.032150.032150 mlpmodule.py:742] pad cost 0.0015265941619873047 s
DEBUG 01-05 09:59:23.033133.033133 mlpmodule.py:748] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-05 09:59:23.033645.033645 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-05 09:59:23.041731.041731 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:23.041803.041803 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:23.042985.042985 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 09:59:23.042824.042824 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:23.058203.058203 mlpmodule.py:793] group einsum cost 0.02488112449645996 s
DEBUG 01-05 09:59:23.058560.058560 mlpmodule.py:801] cpy2cputensor cost 0.0005898475646972656 s
DEBUG 01-05 09:59:23.063300.063300 cuda_h.py:19] end wait_cetm_experts cost 0.03723001480102539 seconds
DEBUG 01-05 09:59:23.063157.063157 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:23.064207.064207 cuda_h.py:19] end gpu_sexperts cost 0.0004546642303466797 seconds
DEBUG 01-05 09:59:23.064593.064593 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:23.064781.064781 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-05 09:59:23.064914.064914 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:23.064101.064101 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f3fb9edb-78c8-4279-bcf2-1d4b34e00a82
DEBUG 01-05 09:59:23.078381.078381 mlpmodule.py:662]  experts func einsum cost 0.05221080780029297 s
INFO 01-05 09:59:23.079759.079759 client.py:127] Model loaded
DEBUG 01-05 09:59:23.079563.079563 cuda_h.py:19] end wait_experts cost 0.014983654022216797 seconds
DEBUG 01-05 09:59:23.079504.079504 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:23.079445.079445 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:23.080234.080234 mlpmodule.py:531] gpu group tensors cost 0.0005478858947753906 s
DEBUG 01-05 09:59:23.081338.081338 mlpmodule.py:564] gpu pad cost 0.0014662742614746094 s
DEBUG 01-05 09:59:23.082020.082020 mlpmodule.py:582] gpu group einsum cost 0.0005028247833251953 s
DEBUG 01-05 09:59:23.085391.085391 mlpmodule.py:611] gpu experts func einsum cost 0.005438327789306641 s
DEBUG 01-05 09:59:23.085057.085057 cuda_h.py:19] end gpu_experts cost 0.005614519119262695 seconds
DEBUG 01-05 09:59:23.085120.085120 cuda_h.py:19] end layer_moe_generate_26 cost 0.06599664688110352 seconds
DEBUG 01-05 09:59:23.085616.085616 lmp.py:217] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 09:59:23.085995.085995 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 09:59:23.085737.085737 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 09:59:23.085838.085838 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.1920928955078125e-05 seconds
DEBUG 01-05 09:59:23.085626.085626 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:59:23.085569.085569 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:59:23.088688.088688 cuda_h.py:19] end self_attn cost 0.002318859100341797 seconds
DEBUG 01-05 09:59:23.088461.088461 cuda_h.py:19] end iln_self_attn_paln cost 0.0029380321502685547 seconds
DEBUG 01-05 09:59:23.088158.088158 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 09:59:23.088444.088444 cuda_h.py:10] start gate
DEBUG 01-05 09:59:23.089974.089974 cuda_h.py:19] end gate cost 0.0005674362182617188 seconds
DEBUG 01-05 09:59:23.089466.089466 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:59:23.089952.089952 lmp.py:365] 
DEBUG 01-05 09:59:23.089952.089952 lmp.py:365] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:59:23.089516.089516 lmp.py:366]   Total experts: 64
DEBUG 01-05 09:59:23.089689.089689 lmp.py:367]   CPU experts: 32 (50%)
DEBUG 01-05 09:59:23.089001.089001 lmp.py:368]   GPU experts: 32 (50%)
DEBUG 01-05 09:59:23.089167.089167 lmp.py:369] 
DEBUG 01-05 09:59:23.089167.089167 lmp.py:369]   Expert ID | Tokens | Device
DEBUG 01-05 09:59:23.089333.089333 lmp.py:370]   -----------------------------------
DEBUG 01-05 09:59:23.089745.089745 lmp.py:376]   Expert 18 |     38 | CPU
DEBUG 01-05 09:59:23.089149.089149 lmp.py:376]   Expert 47 |     38 | CPU
DEBUG 01-05 09:59:23.089839.089839 lmp.py:376]   Expert 54 |     62 | CPU
DEBUG 01-05 09:59:23.089289.089289 lmp.py:376]   Expert 15 |     67 | CPU
DEBUG 01-05 09:59:23.089740.089740 lmp.py:376]   Expert 58 |     70 | CPU
DEBUG 01-05 09:59:23.089714.089714 lmp.py:376]   Expert  7 |     74 | CPU
DEBUG 01-05 09:59:23.089927.089927 lmp.py:376]   Expert 24 |     74 | CPU
DEBUG 01-05 09:59:23.089093.089093 lmp.py:376]   Expert 32 |     75 | CPU
DEBUG 01-05 09:59:23.089544.089544 lmp.py:376]   Expert 59 |     79 | CPU
DEBUG 01-05 09:59:23.089518.089518 lmp.py:376]   Expert 38 |     82 | CPU
DEBUG 01-05 09:59:23.089492.089492 lmp.py:376]   Expert 12 |     91 | CPU
DEBUG 01-05 09:59:23.089466.089466 lmp.py:376]   Expert 11 |     96 | CPU
DEBUG 01-05 09:59:23.089440.089440 lmp.py:376]   Expert 61 |     98 | CPU
DEBUG 01-05 09:59:23.089176.089176 lmp.py:376]   Expert 42 |    104 | CPU
DEBUG 01-05 09:59:23.089150.089150 lmp.py:376]   Expert 40 |    112 | CPU
DEBUG 01-05 09:59:23.089124.089124 lmp.py:376]   Expert 23 |    122 | CPU
DEBUG 01-05 09:59:23.089859.089859 lmp.py:376]   Expert 45 |    122 | CPU
DEBUG 01-05 09:59:23.089787.089787 lmp.py:376]   Expert 46 |    125 | CPU
DEBUG 01-05 09:59:23.089238.089238 lmp.py:376]   Expert  6 |    128 | CPU
DEBUG 01-05 09:59:23.090450.090450 lmp.py:376]   Expert 39 |    129 | CPU
DEBUG 01-05 09:59:23.090663.090663 lmp.py:376]   Expert 34 |    130 | CPU
DEBUG 01-05 09:59:23.090637.090637 lmp.py:376]   Expert 52 |    132 | CPU
DEBUG 01-05 09:59:23.090611.090611 lmp.py:376]   Expert 48 |    141 | CPU
DEBUG 01-05 09:59:23.090823.090823 lmp.py:376]   Expert 44 |    142 | CPU
DEBUG 01-05 09:59:23.090797.090797 lmp.py:376]   Expert 51 |    146 | CPU
DEBUG 01-05 09:59:23.090772.090772 lmp.py:376]   Expert 30 |    156 | CPU
DEBUG 01-05 09:59:23.090746.090746 lmp.py:376]   Expert  3 |    160 | CPU
DEBUG 01-05 09:59:23.090481.090481 lmp.py:376]   Expert 10 |    166 | CPU
DEBUG 01-05 09:59:23.090217.090217 lmp.py:376]   Expert 16 |    170 | CPU
DEBUG 01-05 09:59:23.090429.090429 lmp.py:376]   Expert 31 |    173 | CPU
DEBUG 01-05 09:59:23.090403.090403 lmp.py:376]   Expert 56 |    175 | CPU
DEBUG 01-05 09:59:23.090854.090854 lmp.py:376]   Expert 19 |    177 | CPU
DEBUG 01-05 09:59:23.090305.090305 lmp.py:376]   Expert 22 |    184 | GPU
DEBUG 01-05 09:59:23.090041.090041 lmp.py:376]   Expert 25 |    184 | GPU
DEBUG 01-05 09:59:23.090492.090492 lmp.py:376]   Expert  4 |    188 | GPU
DEBUG 01-05 09:59:23.090466.090466 lmp.py:376]   Expert 50 |    190 | GPU
DEBUG 01-05 09:59:23.090963.090963 lmp.py:376]   Expert 29 |    191 | GPU
DEBUG 01-05 09:59:23.090175.090175 lmp.py:376]   Expert  1 |    192 | GPU
DEBUG 01-05 09:59:23.090911.090911 lmp.py:376]   Expert 13 |    196 | GPU
DEBUG 01-05 09:59:23.090123.090123 lmp.py:376]   Expert 17 |    202 | GPU
DEBUG 01-05 09:59:23.090574.090574 lmp.py:376]   Expert 36 |    203 | GPU
DEBUG 01-05 09:59:23.090516.090516 lmp.py:376]   Expert 62 |    205 | GPU
DEBUG 01-05 09:59:23.090490.090490 lmp.py:376]   Expert 57 |    207 | GPU
DEBUG 01-05 09:59:23.090225.090225 lmp.py:376]   Expert 33 |    220 | GPU
DEBUG 01-05 09:59:23.090484.090484 lmp.py:376]   Expert  5 |    229 | GPU
DEBUG 01-05 09:59:23.090981.090981 lmp.py:376]   Expert 55 |    229 | GPU
DEBUG 01-05 09:59:23.090717.090717 lmp.py:376]   Expert  8 |    235 | GPU
DEBUG 01-05 09:59:23.090214.090214 lmp.py:376]   Expert 53 |    235 | GPU
DEBUG 01-05 09:59:23.090950.090950 lmp.py:376]   Expert  0 |    245 | GPU
DEBUG 01-05 09:59:23.090208.090208 lmp.py:376]   Expert 26 |    250 | GPU
DEBUG 01-05 09:59:23.090944.090944 lmp.py:376]   Expert 41 |    253 | GPU
DEBUG 01-05 09:59:23.090395.090395 lmp.py:376]   Expert 49 |    261 | GPU
DEBUG 01-05 09:59:23.090892.090892 lmp.py:376]   Expert 35 |    268 | GPU
DEBUG 01-05 09:59:23.090628.090628 lmp.py:376]   Expert 28 |    270 | GPU
DEBUG 01-05 09:59:23.090125.090125 lmp.py:376]   Expert 37 |    284 | GPU
DEBUG 01-05 09:59:23.090622.090622 lmp.py:376]   Expert 14 |    310 | GPU
DEBUG 01-05 09:59:23.090643.090643 lmp.py:376]   Expert 27 |    340 | GPU
DEBUG 01-05 09:59:23.090378.090378 lmp.py:376]   Expert 21 |    357 | GPU
DEBUG 01-05 09:59:23.090875.090875 lmp.py:376]   Expert  2 |    366 | GPU
DEBUG 01-05 09:59:23.090134.090134 lmp.py:376]   Expert 60 |    381 | GPU
DEBUG 01-05 09:59:23.090108.090108 lmp.py:376]   Expert  9 |    393 | GPU
DEBUG 01-05 09:59:23.090321.090321 lmp.py:376]   Expert 43 |    402 | GPU
DEBUG 01-05 09:59:23.090295.090295 lmp.py:376]   Expert 63 |    460 | GPU
DEBUG 01-05 09:59:23.090792.090792 lmp.py:376]   Expert 20 |    504 | GPU
DEBUG 01-05 09:59:23.090004.090004 lmp.py:377] 
DEBUG 01-05 09:59:23.090004.090004 lmp.py:377]   CPU total tokens: 3654 (29.7%)
DEBUG 01-05 09:59:23.090932.090932 lmp.py:378]   GPU total tokens: 8634 (70.3%)
DEBUG 01-05 09:59:23.090436.090436 cuda_h.py:19] end experts_map_get cost 0.0014607906341552734 seconds
DEBUG 01-05 09:59:23.090125.090125 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:59:23.090001.090001 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:59:23.090476.090476 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:59:23.091938.091938 cuda_h.py:19] end allocate_cuda_memory cost 0.000308990478515625 seconds
DEBUG 01-05 09:59:23.091927.091927 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:59:23.091729.091729 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:59:23.091591.091591 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:59:23.091195.091195 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9eaa9109-cea8-454e-b007-7fe271927892
DEBUG 01-05 09:59:23.091857.091857 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:59:23.092345.092345 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9eaa9109-cea8-454e-b007-7fe271927892
DEBUG 01-05 09:59:23.093704.093704 cuda_h.py:19] end load_into_gpu_async cost 0.001631021499633789 seconds
DEBUG 01-05 09:59:23.093215.093215 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:59:23.093995.093995 cuda_h.py:19] end restore_tensors2 cost 0.000339508056640625 seconds
DEBUG 01-05 09:59:23.093646.093646 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026297569274902344 seconds
DEBUG 01-05 09:59:23.095035.095035 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0051746368408203125 seconds
DEBUG 01-05 09:59:23.096003.096003 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:59:23.096933.096933 lmp.py:423] 
DEBUG 01-05 09:59:23.096933.096933 lmp.py:423]   Computing 32 experts on CPU...
DEBUG 01-05 09:59:23.096061.096061 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-05 09:59:23.096592.096592 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:59:23.106448.106448 mlpmodule.py:704] group tensors cost 0.010185956954956055 s
DEBUG 01-05 09:59:23.108957.108957 mlpmodule.py:742] pad cost 0.0015363693237304688 s
DEBUG 01-05 09:59:23.108610.108610 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-05 09:59:23.108791.108791 mlpmodule.py:753] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-05 09:59:23.118517.118517 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:59:23.119509.119509 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:59:23.119307.119307 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 09:59:23.119007.119007 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:59:23.135373.135373 mlpmodule.py:793] group einsum cost 0.02700662612915039 s
DEBUG 01-05 09:59:23.136324.136324 mlpmodule.py:801] cpy2cputensor cost 0.0007007122039794922 s
DEBUG 01-05 09:59:23.141821.141821 cuda_h.py:19] end wait_cetm_experts cost 0.0453488826751709 seconds
DEBUG 01-05 09:59:23.141731.141731 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:59:23.142178.142178 cuda_h.py:19] end gpu_sexperts cost 0.00046324729919433594 seconds
DEBUG 01-05 09:59:23.142829.142829 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:59:23.142135.142135 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.2159347534179688e-05 seconds
DEBUG 01-05 09:59:23.142838.142838 cuda_h.py:10] start wait_experts
INFO 01-05 09:59:23.142833.142833 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9eaa9109-cea8-454e-b007-7fe271927892
INFO 01-05 09:59:23.148835.148835 client.py:127] Model loaded
DEBUG 01-05 09:59:23.149639.149639 cuda_h.py:19] end wait_experts cost 0.006669759750366211 seconds
DEBUG 01-05 09:59:23.149918.149918 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:59:23.149674.149674 lmp.py:468]   Computing 32 experts on GPU...
DEBUG 01-05 09:59:23.149963.149963 mlpmodule.py:531] gpu group tensors cost 0.0006618499755859375 s
DEBUG 01-05 09:59:23.151769.151769 mlpmodule.py:564] gpu pad cost 0.0016636848449707031 s
DEBUG 01-05 09:59:23.152556.152556 mlpmodule.py:582] gpu group einsum cost 0.0004703998565673828 s
DEBUG 01-05 09:59:23.155243.155243 mlpmodule.py:611] gpu experts func einsum cost 0.005853176116943359 s
DEBUG 01-05 09:59:23.155154.155154 cuda_h.py:19] end gpu_experts cost 0.006044149398803711 seconds
DEBUG 01-05 09:59:23.155409.155409 cuda_h.py:19] end layer_moe_generate_27 cost 0.06658673286437988 seconds
DEBUG 01-05 09:59:23.155097.155097 lmp.py:217] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 09:59:23.155675.155675 cuda_h.py:19] end multi_layer cost 2.0792782306671143 seconds
DEBUG 01-05 09:59:23.155848.155848 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:59:23.156462.156462 mlpmodule.py:662]  experts func einsum cost 0.06028342247009277 s
DEBUG 01-05 09:59:23.158472.158472 cuda_h.py:19] end init_inputs_tokens cost 0.0029935836791992188 seconds
DEBUG 01-05 09:59:23.158746.158746 lmp.py:286] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:59:23.158541.158541 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:59:23.158816.158816 lmp.py:289] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:59:23.158123.158123 cuda_h.py:19] end dense_mlp cost 0.0003330707550048828 seconds
INFO 01-05 09:59:23.159648.159648 lmp.py:522] 
INFO 01-05 09:59:23.159648.159648 lmp.py:522] ============================================================
INFO 01-05 09:59:23.159165.159165 lmp.py:523] Layer 1 Expert Device Distribution:
INFO 01-05 09:59:23.159544.159544 lmp.py:532]   Total experts: 64
INFO 01-05 09:59:23.159770.159770 lmp.py:534]   meta: 32 experts - Expert IDs: [0, 1, 3, 4, 11, 13, 15, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 47, 49, 52, 53, 54, 55, 56, 58, 62]
INFO 01-05 09:59:23.159466.159466 lmp.py:534]   cuda:1: 32 experts - Expert IDs: [2, 5, 6, 7, 8, 9, 10, 12, 14, 16, 19, 20, 23, 24, 26, 34, 35, 36, 40, 42, 43, 44, 45, 46, 48, 50, 51, 57, 59, 60, 61, 63]
INFO 01-05 09:59:23.159348.159348 lmp.py:537] 
INFO 01-05 09:59:23.159348.159348 lmp.py:537]   Detailed Expert Device Map:
INFO 01-05 09:59:23.159660.159660 lmp.py:538]   Expert ID  | Device         
INFO 01-05 09:59:23.159349.159349 lmp.py:539]   ------------------------------
INFO 01-05 09:59:23.159376.159376 lmp.py:542]   0          | meta           
INFO 01-05 09:59:23.159734.159734 lmp.py:542]   1          | meta           
INFO 01-05 09:59:23.159424.159424 lmp.py:542]   2          | cuda:1         
INFO 01-05 09:59:23.159636.159636 lmp.py:542]   3          | meta           
INFO 01-05 09:59:23.159848.159848 lmp.py:542]   4          | meta           
INFO 01-05 09:59:23.159346.159346 lmp.py:542]   5          | cuda:1         
INFO 01-05 09:59:23.159081.159081 lmp.py:542]   6          | cuda:1         
INFO 01-05 09:59:23.159294.159294 lmp.py:542]   7          | cuda:1         
INFO 01-05 09:59:23.159268.159268 lmp.py:542]   8          | cuda:1         
INFO 01-05 09:59:23.159003.159003 lmp.py:542]   9          | cuda:1         
INFO 01-05 09:59:23.159739.159739 lmp.py:542]   10         | cuda:1         
INFO 01-05 09:59:23.159097.159097 lmp.py:542]   11         | meta           
INFO 01-05 09:59:23.159787.159787 lmp.py:542]   12         | cuda:1         
INFO 01-05 09:59:23.159522.159522 lmp.py:542]   13         | meta           
INFO 01-05 09:59:23.159019.159019 lmp.py:542]   14         | cuda:1         
INFO 01-05 09:59:23.159755.159755 lmp.py:542]   15         | meta           
INFO 01-05 09:59:23.159014.159014 lmp.py:542]   16         | cuda:1         
INFO 01-05 09:59:23.159511.159511 lmp.py:542]   17         | meta           
INFO 01-05 09:59:23.159770.159770 lmp.py:542]   18         | meta           
INFO 01-05 09:59:23.159029.159029 lmp.py:542]   19         | cuda:1         
INFO 01-05 09:59:23.159764.159764 lmp.py:542]   20         | cuda:1         
INFO 01-05 09:59:23.159023.159023 lmp.py:542]   21         | meta           
INFO 01-05 09:59:23.159712.159712 lmp.py:542]   22         | meta           
INFO 01-05 09:59:23.159163.159163 lmp.py:542]   23         | cuda:1         
INFO 01-05 09:59:23.159899.159899 lmp.py:542]   24         | cuda:1         
INFO 01-05 09:59:23.159158.159158 lmp.py:542]   25         | meta           
INFO 01-05 09:59:23.159416.159416 lmp.py:542]   26         | cuda:1         
INFO 01-05 09:59:23.160914.160914 lmp.py:542]   27         | meta           
INFO 01-05 09:59:23.160172.160172 lmp.py:542]   28         | meta           
INFO 01-05 09:59:23.160908.160908 lmp.py:542]   29         | meta           
INFO 01-05 09:59:23.160167.160167 lmp.py:542]   30         | meta           
INFO 01-05 09:59:23.160426.160426 lmp.py:542]   31         | meta           
INFO 01-05 09:59:23.160400.160400 lmp.py:542]   32         | meta           
INFO 01-05 09:59:23.160374.160374 lmp.py:542]   33         | meta           
INFO 01-05 09:59:23.160871.160871 lmp.py:542]   34         | cuda:1         
INFO 01-05 09:59:23.160130.160130 lmp.py:542]   35         | cuda:1         
INFO 01-05 09:59:23.160865.160865 lmp.py:542]   36         | cuda:1         
INFO 01-05 09:59:23.160124.160124 lmp.py:542]   37         | meta           
INFO 01-05 09:59:23.160621.160621 lmp.py:542]   38         | meta           
INFO 01-05 09:59:23.160642.160642 lmp.py:542]   39         | meta           
INFO 01-05 09:59:23.160629.160629 lmp.py:542]   40         | cuda:1         
INFO 01-05 09:59:23.160173.160173 lmp.py:542]   41         | meta           
INFO 01-05 09:59:23.160193.160193 lmp.py:542]   42         | cuda:1         
INFO 01-05 09:59:23.160452.160452 lmp.py:542]   43         | cuda:1         
INFO 01-05 09:59:23.160949.160949 lmp.py:542]   44         | cuda:1         
INFO 01-05 09:59:23.160685.160685 lmp.py:542]   45         | cuda:1         
INFO 01-05 09:59:23.160705.160705 lmp.py:542]   46         | cuda:1         
INFO 01-05 09:59:23.160487.160487 lmp.py:542]   47         | meta           
INFO 01-05 09:59:23.160269.160269 lmp.py:542]   48         | cuda:1         
INFO 01-05 09:59:23.160289.160289 lmp.py:542]   49         | meta           
INFO 01-05 09:59:23.160071.160071 lmp.py:542]   50         | cuda:1         
INFO 01-05 09:59:23.160629.160629 lmp.py:542]   51         | cuda:1         
INFO 01-05 09:59:23.160100.160100 lmp.py:542]   52         | meta           
INFO 01-05 09:59:23.160597.160597 lmp.py:542]   53         | meta           
INFO 01-05 09:59:23.160809.160809 lmp.py:542]   54         | meta           
INFO 01-05 09:59:23.160737.160737 lmp.py:542]   55         | meta           
INFO 01-05 09:59:23.160473.160473 lmp.py:542]   56         | meta           
INFO 01-05 09:59:23.160493.160493 lmp.py:542]   57         | cuda:1         
INFO 01-05 09:59:23.160752.160752 lmp.py:542]   58         | meta           
INFO 01-05 09:59:23.160011.160011 lmp.py:542]   59         | cuda:1         
INFO 01-05 09:59:23.160508.160508 lmp.py:542]   60         | cuda:1         
INFO 01-05 09:59:23.160767.160767 lmp.py:542]   61         | cuda:1         
INFO 01-05 09:59:23.160026.160026 lmp.py:542]   62         | meta           
INFO 01-05 09:59:23.160284.160284 lmp.py:542]   63         | cuda:1         
INFO 01-05 09:59:23.160543.160543 lmp.py:543] ============================================================
INFO 01-05 09:59:23.160543.160543 lmp.py:543] 
DEBUG 01-05 09:59:23.160471.160471 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 09:59:23.160433.160433 cuda_h.py:10] start gate
DEBUG 01-05 09:59:23.161743.161743 cuda_h.py:19] end gate cost 0.0005495548248291016 seconds
DEBUG 01-05 09:59:23.161427.161427 cuda_h.py:10] start experts_map_get
INFO 01-05 09:59:23.161104.161104 lmp.py:607] 
INFO 01-05 09:59:23.161104.161104 lmp.py:607] Layer 1 Expert Device Distribution:
INFO 01-05 09:59:23.161668.161668 lmp.py:608]   Active experts: 49 (out of 64 total)
INFO 01-05 09:59:23.161325.161325 lmp.py:609]   CPU experts: 24 (49%) - Expert IDs: [1, 4, 8, 12, 19, 22, 27, 28, 30, 33, 35, 37, 38, 40, 41, 45, 48, 49, 50, 51, 52, 53, 55, 60]
INFO 01-05 09:59:23.161644.161644 lmp.py:610]   GPU experts: 25 (51%) - Expert IDs: [0, 2, 5, 6, 7, 10, 11, 14, 15, 16, 20, 23, 24, 26, 31, 34, 42, 43, 44, 46, 47, 57, 59, 61, 63]
INFO 01-05 09:59:23.161432.161432 lmp.py:611]   CPU tokens: 42 (21.9%)
INFO 01-05 09:59:23.161314.161314 lmp.py:612]   GPU tokens: 150 (78.1%)
INFO 01-05 09:59:23.161765.161765 lmp.py:613] 
INFO 01-05 09:59:23.161765.161765 lmp.py:613]   Detailed Expert Distribution:
INFO 01-05 09:59:23.161361.161361 lmp.py:614]   Expert ID  | Tokens     | Device       | Token %   
INFO 01-05 09:59:23.161051.161051 lmp.py:615]   --------------------------------------------------
INFO 01-05 09:59:23.161078.161078 lmp.py:619]   12         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161628.161628 lmp.py:619]   22         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161178.161178 lmp.py:619]   27         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161537.161537 lmp.py:619]   30         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161418.161418 lmp.py:619]   37         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161538.161538 lmp.py:619]   38         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161658.161658 lmp.py:619]   41         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161539.161539 lmp.py:619]   48         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161420.161420 lmp.py:619]   50         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161063.161063 lmp.py:619]   52         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161945.161945 lmp.py:619]   55         | 1          | CPU          |   0.52%
INFO 01-05 09:59:23.161826.161826 lmp.py:619]   4          | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.161184.161184 lmp.py:619]   8          | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.161304.161304 lmp.py:619]   19         | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.162947.162947 lmp.py:619]   45         | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.162352.162352 lmp.py:619]   49         | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.162995.162995 lmp.py:619]   51         | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.162638.162638 lmp.py:619]   53         | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.162294.162294 lmp.py:619]   60         | 2          | CPU          |   1.04%
INFO 01-05 09:59:23.162222.162222 lmp.py:619]   1          | 3          | CPU          |   1.56%
INFO 01-05 09:59:23.162911.162911 lmp.py:619]   28         | 3          | CPU          |   1.56%
INFO 01-05 09:59:23.162554.162554 lmp.py:619]   33         | 3          | CPU          |   1.56%
INFO 01-05 09:59:23.162720.162720 lmp.py:619]   35         | 3          | CPU          |   1.56%
INFO 01-05 09:59:23.162410.162410 lmp.py:619]   40         | 3          | CPU          |   1.56%
INFO 01-05 09:59:23.162576.162576 lmp.py:619]   43         | 3          | GPU(cuda:1)  |   1.56%
INFO 01-05 09:59:23.162742.162742 lmp.py:619]   44         | 3          | GPU(cuda:1)  |   1.56%
INFO 01-05 09:59:23.162670.162670 lmp.py:619]   0          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:23.162121.162121 lmp.py:619]   10         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:23.162048.162048 lmp.py:619]   11         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:23.162499.162499 lmp.py:619]   16         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:23.162665.162665 lmp.py:619]   42         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:59:23.162308.162308 lmp.py:619]   2          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162759.162759 lmp.py:619]   7          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162972.162972 lmp.py:619]   15         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162422.162422 lmp.py:619]   20         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162873.162873 lmp.py:619]   26         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162324.162324 lmp.py:619]   47         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162775.162775 lmp.py:619]   59         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162226.162226 lmp.py:619]   61         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162677.162677 lmp.py:619]   63         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:59:23.162320.162320 lmp.py:619]   5          | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:23.162724.162724 lmp.py:619]   23         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:59:23.162414.162414 lmp.py:619]   6          | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:59:23.162626.162626 lmp.py:619]   31         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:59:23.162077.162077 lmp.py:619]   24         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:59:23.162766.162766 lmp.py:619]   46         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:59:23.162217.162217 lmp.py:619]   14         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:59:23.162430.162430 lmp.py:619]   57         | 11         | GPU(cuda:1)  |   5.73%
INFO 01-05 09:59:23.162119.162119 lmp.py:619]   34         | 12         | GPU(cuda:1)  |   6.25%
INFO 01-05 09:59:23.162378.162378 lmp.py:620] ============================================================
INFO 01-05 09:59:23.162378.162378 lmp.py:620] 
DEBUG 01-05 09:59:23.162597.162597 cuda_h.py:19] end experts_map_get cost 0.0012922286987304688 seconds
DEBUG 01-05 09:59:23.162101.162101 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.001976490020751953 seconds
Collecting data...
Generating '/tmp/nsys-report-3610.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [11%                         ] report1.nsys-rep[1/1] [=15%                        ] report1.nsys-rep[1/1] [==20%                       ] report1.nsys-rep[1/1] [====25%                     ] report1.nsys-rep[1/1] [=====30%                    ] report1.nsys-rep[1/1] [======35%                   ] report1.nsys-rep[1/1] [========40%                 ] report1.nsys-rep[1/1] [=========45%                ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
