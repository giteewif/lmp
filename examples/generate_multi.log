here pin
INFO 01-05 09:19:27.811540.811540 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-05 09:19:28.640434.640434 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-05 09:19:29.086354.086354 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-05 09:19:29.086857.086857 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.275s
DEBUG 01-05 09:19:29.162232.162232 cuda_memory_view.py:260] 
DEBUG 01-05 09:19:29.162232.162232 cuda_memory_view.py:260] restore_tensors_from_shared_memory_names time: 0.013574838638305664
DEBUG 01-05 09:19:30.184250.184250 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11453890800476074 s
DEBUG 01-05 09:19:30.679953.679953 cuda_h.py:19] end generate_input_ids cost 0.4945526123046875 seconds
DEBUG 01-05 09:19:30.679997.679997 cuda_h.py:10] start init_cache
DEBUG 01-05 09:19:30.679929.679929 cuda_h.py:19] end init_cache cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:19:33.107224.107224 cuda_h.py:10] start init_weights
DEBUG 01-05 09:19:33.107879.107879 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:33.107463.107463 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:33.108300.108300 cuda_h.py:19] end allocate_cuda_memory cost 0.0004138946533203125 seconds
DEBUG 01-05 09:19:33.108628.108628 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:33.108649.108649 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:33.108724.108724 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:33.108957.108957 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a7cb9604-0eb8-4f64-a7e9-f5e5bac4f736
DEBUG 01-05 09:19:33.108232.108232 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:33.109170.109170 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a7cb9604-0eb8-4f64-a7e9-f5e5bac4f736
DEBUG 01-05 09:19:33.109695.109695 cuda_h.py:19] end load_into_gpu_async cost 0.0013742446899414062 seconds
DEBUG 01-05 09:19:33.109352.109352 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:33.109216.109216 cuda_h.py:19] end restore_tensors2 cost 8.034706115722656e-05 seconds
DEBUG 01-05 09:19:33.109211.109211 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021789073944091797 seconds
INFO 01-05 09:19:33.110522.110522 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a7cb9604-0eb8-4f64-a7e9-f5e5bac4f736
INFO 01-05 09:19:33.186997.186997 client.py:127] Model loaded
DEBUG 01-05 09:19:33.186539.186539 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 09:19:33.187914.187914 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:33.187567.187567 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:33.187914.187914 cuda_h.py:19] end allocate_cuda_memory cost 0.00036835670471191406 seconds
DEBUG 01-05 09:19:33.187025.187025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:33.187724.187724 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:33.188336.188336 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:33.188769.188769 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d90af560-3aa5-4919-b9f5-eeff21fd7916
DEBUG 01-05 09:19:33.188928.188928 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:33.189761.189761 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d90af560-3aa5-4919-b9f5-eeff21fd7916
DEBUG 01-05 09:19:33.189793.189793 cuda_h.py:19] end load_into_gpu_async cost 0.0018718242645263672 seconds
DEBUG 01-05 09:19:33.189492.189492 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:33.190526.190526 cuda_h.py:19] end restore_tensors2 cost 0.00015282630920410156 seconds
DEBUG 01-05 09:19:33.190523.190523 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030646324157714844 seconds
INFO 01-05 09:19:33.190055.190055 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d90af560-3aa5-4919-b9f5-eeff21fd7916
INFO 01-05 09:19:33.206518.206518 client.py:127] Model loaded
DEBUG 01-05 09:19:33.207023.207023 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020896434783935547 seconds
DEBUG 01-05 09:19:33.208200.208200 cuda_h.py:19] end init_weights cost 0.10037970542907715 seconds
DEBUG 01-05 09:19:33.208216.208216 cuda_h.py:10] start copy_emodel
DEBUG 01-05 09:19:34.076342.076342 cuda_h.py:19] end copy_emodel cost 0.8681797981262207 seconds
DEBUG 01-05 09:19:34.077062.077062 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:19:34.153951.153951 cuda_h.py:19] end init_inputs_tokens cost 0.07608985900878906 seconds
DEBUG 01-05 09:19:34.153253.153253 cuda_h.py:10] start multi_layer
DEBUG 01-05 09:19:34.153632.153632 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 09:19:34.153680.153680 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:34.243001.243001 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:34.491090.491090 cuda_h.py:19] end self_attn cost 0.24772405624389648 seconds
DEBUG 01-05 09:19:34.491985.491985 cuda_h.py:19] end iln_self_attn_paln cost 0.3380007743835449 seconds
DEBUG 01-05 09:19:34.491273.491273 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:19:34.491804.491804 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:19:34.491389.491389 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.6716461181640625e-05 seconds
DEBUG 01-05 09:19:34.492025.492025 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:34.492859.492859 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:34.492335.492335 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:34.493973.493973 cuda_h.py:19] end allocate_cuda_memory cost 0.00044417381286621094 seconds
DEBUG 01-05 09:19:34.493011.493011 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:34.493187.493187 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:34.493429.493429 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:34.493815.493815 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc7bde8b-8a77-4e24-b855-59b4ddf14678
DEBUG 01-05 09:19:34.493047.493047 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:34.495397.495397 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc7bde8b-8a77-4e24-b855-59b4ddf14678
DEBUG 01-05 09:19:34.495342.495342 cuda_h.py:19] end load_into_gpu_async cost 0.0024633407592773438 seconds
DEBUG 01-05 09:19:34.495490.495490 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:34.496842.496842 cuda_h.py:19] end restore_tensors2 cost 0.00014853477478027344 seconds
DEBUG 01-05 09:19:34.496388.496388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003838062286376953 seconds
INFO 01-05 09:19:34.497338.497338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc7bde8b-8a77-4e24-b855-59b4ddf14678
INFO 01-05 09:19:34.503421.503421 client.py:127] Model loaded
DEBUG 01-05 09:19:34.503931.503931 cuda_h.py:19] end sllm_worker_task cost 0.011250495910644531 seconds
DEBUG 01-05 09:19:34.503595.503595 cuda_h.py:19] end dense_mlp cost 0.011952638626098633 seconds
DEBUG 01-05 09:19:34.503778.503778 lmp.py:214] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 09:19:34.503164.503164 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 09:19:34.503290.503290 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:34.504683.504683 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:34.506828.506828 cuda_h.py:19] end self_attn cost 0.0026824474334716797 seconds
DEBUG 01-05 09:19:34.507791.507791 cuda_h.py:19] end iln_self_attn_paln cost 0.0032520294189453125 seconds
DEBUG 01-05 09:19:34.507833.507833 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 09:19:34.507934.507934 cuda_h.py:10] start gate
DEBUG 01-05 09:19:34.604495.604495 cuda_h.py:19] end gate cost 0.09718036651611328 seconds
DEBUG 01-05 09:19:34.604989.604989 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:34.605272.605272 lmp.py:361] 
DEBUG 01-05 09:19:34.605272.605272 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:34.605372.605372 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:34.605691.605691 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:34.605718.605718 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:34.605123.605123 lmp.py:365] 
DEBUG 01-05 09:19:34.605123.605123 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:34.605004.605004 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:34.605323.605323 lmp.py:372]   Expert 62 |     66 | CPU
DEBUG 01-05 09:19:34.605920.605920 lmp.py:372]   Expert 18 |     68 | CPU
DEBUG 01-05 09:19:34.605609.605609 lmp.py:372]   Expert 22 |     73 | CPU
DEBUG 01-05 09:19:34.605537.605537 lmp.py:372]   Expert 32 |     83 | CPU
DEBUG 01-05 09:19:34.605226.605226 lmp.py:372]   Expert 52 |     94 | CPU
DEBUG 01-05 09:19:34.605651.605651 lmp.py:372]   Expert  3 |    104 | CPU
DEBUG 01-05 09:19:34.605817.605817 lmp.py:372]   Expert 27 |    114 | CPU
DEBUG 01-05 09:19:34.605745.605745 lmp.py:372]   Expert 38 |    114 | CPU
DEBUG 01-05 09:19:34.605434.605434 lmp.py:372]   Expert 13 |    118 | CPU
DEBUG 01-05 09:19:34.605362.605362 lmp.py:372]   Expert 54 |    118 | CPU
DEBUG 01-05 09:19:34.605051.605051 lmp.py:372]   Expert 17 |    121 | CPU
DEBUG 01-05 09:19:34.605979.605979 lmp.py:372]   Expert 11 |    124 | CPU
DEBUG 01-05 09:19:34.605430.605430 lmp.py:372]   Expert 28 |    124 | CPU
DEBUG 01-05 09:19:34.605788.605788 lmp.py:372]   Expert 37 |    125 | CPU
DEBUG 01-05 09:19:34.605431.605431 lmp.py:372]   Expert 58 |    129 | CPU
DEBUG 01-05 09:19:34.605551.605551 lmp.py:372]   Expert 39 |    131 | CPU
DEBUG 01-05 09:19:34.605432.605432 lmp.py:372]   Expert 25 |    135 | CPU
DEBUG 01-05 09:19:34.605890.605890 lmp.py:372]   Expert 41 |    136 | CPU
DEBUG 01-05 09:19:34.605009.605009 lmp.py:372]   Expert 21 |    150 | CPU
DEBUG 01-05 09:19:34.605606.605606 lmp.py:372]   Expert  4 |    151 | CPU
DEBUG 01-05 09:19:34.605488.605488 lmp.py:372]   Expert 30 |    152 | CPU
DEBUG 01-05 09:19:34.605415.605415 lmp.py:372]   Expert 29 |    155 | CPU
DEBUG 01-05 09:19:34.605105.605105 lmp.py:372]   Expert 53 |    155 | CPU
DEBUG 01-05 09:19:34.605555.605555 lmp.py:372]   Expert 49 |    156 | CPU
DEBUG 01-05 09:19:34.605245.605245 lmp.py:372]   Expert 47 |    157 | CPU
DEBUG 01-05 09:19:34.605172.605172 lmp.py:372]   Expert 31 |    168 | CPU
DEBUG 01-05 09:19:34.605862.605862 lmp.py:372]   Expert 33 |    168 | CPU
DEBUG 01-05 09:19:34.605551.605551 lmp.py:372]   Expert 55 |    173 | CPU
DEBUG 01-05 09:19:34.605002.605002 lmp.py:372]   Expert 56 |    173 | CPU
DEBUG 01-05 09:19:34.605691.605691 lmp.py:372]   Expert 15 |    177 | CPU
DEBUG 01-05 09:19:34.605619.605619 lmp.py:372]   Expert  0 |    178 | CPU
DEBUG 01-05 09:19:34.605547.605547 lmp.py:372]   Expert  1 |    178 | CPU
DEBUG 01-05 09:19:34.605474.605474 lmp.py:372]   Expert 24 |    180 | GPU
DEBUG 01-05 09:19:34.605925.605925 lmp.py:372]   Expert 50 |    182 | GPU
DEBUG 01-05 09:19:34.605138.605138 lmp.py:372]   Expert 51 |    184 | GPU
DEBUG 01-05 09:19:34.605304.605304 lmp.py:372]   Expert 19 |    185 | GPU
DEBUG 01-05 09:19:34.605232.605232 lmp.py:372]   Expert  6 |    186 | GPU
DEBUG 01-05 09:19:34.605159.605159 lmp.py:372]   Expert 10 |    189 | GPU
DEBUG 01-05 09:19:34.605041.605041 lmp.py:372]   Expert 34 |    191 | GPU
DEBUG 01-05 09:19:34.605922.605922 lmp.py:372]   Expert  2 |    195 | GPU
DEBUG 01-05 09:19:34.605088.605088 lmp.py:372]   Expert 45 |    195 | GPU
DEBUG 01-05 09:19:34.605778.605778 lmp.py:372]   Expert 35 |    197 | GPU
DEBUG 01-05 09:19:34.605467.605467 lmp.py:372]   Expert 36 |    198 | GPU
DEBUG 01-05 09:19:34.605156.605156 lmp.py:372]   Expert 61 |    209 | GPU
DEBUG 01-05 09:19:34.605607.605607 lmp.py:372]   Expert 44 |    214 | GPU
DEBUG 01-05 09:19:34.605535.605535 lmp.py:372]   Expert 12 |    223 | GPU
DEBUG 01-05 09:19:34.605224.605224 lmp.py:372]   Expert  5 |    227 | GPU
DEBUG 01-05 09:19:34.606913.606913 lmp.py:372]   Expert 23 |    235 | GPU
DEBUG 01-05 09:19:34.606603.606603 lmp.py:372]   Expert 60 |    235 | GPU
DEBUG 01-05 09:19:34.606530.606530 lmp.py:372]   Expert 43 |    239 | GPU
DEBUG 01-05 09:19:34.606743.606743 lmp.py:372]   Expert  9 |    246 | GPU
DEBUG 01-05 09:19:34.606432.606432 lmp.py:372]   Expert 48 |    252 | GPU
DEBUG 01-05 09:19:34.606121.606121 lmp.py:372]   Expert  8 |    262 | GPU
DEBUG 01-05 09:19:34.606049.606049 lmp.py:372]   Expert 20 |    273 | GPU
DEBUG 01-05 09:19:34.606931.606931 lmp.py:372]   Expert 26 |    285 | GPU
DEBUG 01-05 09:19:34.606812.606812 lmp.py:372]   Expert 57 |    292 | GPU
DEBUG 01-05 09:19:34.606932.606932 lmp.py:372]   Expert  7 |    308 | GPU
DEBUG 01-05 09:19:34.606813.606813 lmp.py:372]   Expert 59 |    308 | GPU
DEBUG 01-05 09:19:34.606741.606741 lmp.py:372]   Expert 16 |    310 | GPU
DEBUG 01-05 09:19:34.606430.606430 lmp.py:372]   Expert 63 |    313 | GPU
DEBUG 01-05 09:19:34.606881.606881 lmp.py:372]   Expert 40 |    320 | GPU
DEBUG 01-05 09:19:34.606570.606570 lmp.py:372]   Expert 46 |    320 | GPU
DEBUG 01-05 09:19:34.606783.606783 lmp.py:372]   Expert 42 |    342 | GPU
DEBUG 01-05 09:19:34.606472.606472 lmp.py:372]   Expert 14 |    525 | GPU
DEBUG 01-05 09:19:34.606877.606877 lmp.py:373] 
DEBUG 01-05 09:19:34.606877.606877 lmp.py:373]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 09:19:34.606520.606520 lmp.py:374]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 09:19:34.606123.606123 cuda_h.py:19] end experts_map_get cost 0.001598358154296875 seconds
DEBUG 01-05 09:19:34.606673.606673 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:34.606218.606218 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:34.606518.606518 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:34.607470.607470 cuda_h.py:19] end allocate_cuda_memory cost 0.0003025531768798828 seconds
DEBUG 01-05 09:19:34.607579.607579 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:34.607765.607765 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:34.607734.607734 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:34.607198.607198 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e45181b1-107a-4909-acf3-42e6303db367
DEBUG 01-05 09:19:34.607576.607576 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:34.609426.609426 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e45181b1-107a-4909-acf3-42e6303db367
DEBUG 01-05 09:19:34.609137.609137 cuda_h.py:19] end load_into_gpu_async cost 0.002588987350463867 seconds
DEBUG 01-05 09:19:34.609932.609932 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:34.610347.610347 cuda_h.py:19] end restore_tensors2 cost 0.0002803802490234375 seconds
DEBUG 01-05 09:19:34.610878.610878 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036530494689941406 seconds
DEBUG 01-05 09:19:34.612845.612845 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006484508514404297 seconds
DEBUG 01-05 09:19:34.612364.612364 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:34.613998.613998 lmp.py:419] 
DEBUG 01-05 09:19:34.613998.613998 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:34.613306.613306 cuda_h.py:19] end cpu_experts_submit cost 0.00020623207092285156 seconds
DEBUG 01-05 09:19:34.613678.613678 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:34.630526.630526 mlpmodule.py:704] group tensors cost 0.016644954681396484 s
DEBUG 01-05 09:19:34.632644.632644 mlpmodule.py:742] pad cost 0.0020940303802490234 s
DEBUG 01-05 09:19:34.632536.632536 mlpmodule.py:748] create cpu tensor cost 5.888938903808594e-05 s
DEBUG 01-05 09:19:34.633281.633281 mlpmodule.py:753] move to cpu cost 4.220008850097656e-05 s
DEBUG 01-05 09:19:34.672146.672146 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:34.673029.673029 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:34.673835.673835 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 09:19:34.687128.687128 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:34.712838.712838 mlpmodule.py:793] group einsum cost 0.07904434204101562 s
DEBUG 01-05 09:19:34.713130.713130 mlpmodule.py:801] cpy2cputensor cost 0.0007994174957275391 s
DEBUG 01-05 09:19:34.784748.784748 cuda_h.py:19] end wait_cetm_experts cost 0.17095661163330078 seconds
DEBUG 01-05 09:19:34.784487.784487 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:34.784866.784866 cuda_h.py:19] end gpu_sexperts cost 0.0005779266357421875 seconds
DEBUG 01-05 09:19:34.785558.785558 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:19:34.785348.785348 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:19:34.785900.785900 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.7206878662109375e-05 seconds
DEBUG 01-05 09:19:34.785723.785723 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 9.655952453613281e-05 seconds
DEBUG 01-05 09:19:34.785307.785307 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:34.785176.785176 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e45181b1-107a-4909-acf3-42e6303db367
DEBUG 01-05 09:19:34.785812.785812 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:34.785420.785420 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:34.785085.785085 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:34.789989.789989 cuda_h.py:19] end allocate_cuda_memory cost 0.003219127655029297 seconds
INFO 01-05 09:19:34.789827.789827 client.py:127] Model loaded
DEBUG 01-05 09:19:34.789030.789030 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:34.789226.789226 cuda_h.py:19] end wait_experts cost 0.004038095474243164 seconds
DEBUG 01-05 09:19:34.789194.789194 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:34.789984.789984 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:34.789497.789497 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:34.789177.789177 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb15d976-46df-417e-a931-1cd7f6db910d
DEBUG 01-05 09:19:34.789770.789770 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:34.789148.789148 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:34.790338.790338 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb15d976-46df-417e-a931-1cd7f6db910d
DEBUG 01-05 09:19:34.790334.790334 cuda_h.py:19] end load_into_gpu_async cost 0.0014069080352783203 seconds
DEBUG 01-05 09:19:34.790090.790090 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:34.794140.794140 cuda_h.py:19] end restore_tensors2 cost 0.0034368038177490234 seconds
DEBUG 01-05 09:19:34.794196.794196 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008841991424560547 seconds
INFO 01-05 09:19:34.795400.795400 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb15d976-46df-417e-a931-1cd7f6db910d
INFO 01-05 09:19:34.799020.799020 client.py:127] Model loaded
DEBUG 01-05 09:19:34.799390.799390 mlpmodule.py:531] gpu group tensors cost 0.009433746337890625 s
DEBUG 01-05 09:19:34.799037.799037 mlpmodule.py:662]  experts func einsum cost 0.18624305725097656 s
DEBUG 01-05 09:19:34.799351.799351 cuda_h.py:19] end sllm_worker_task cost 0.013957977294921875 seconds
DEBUG 01-05 09:19:34.801883.801883 mlpmodule.py:564] gpu pad cost 0.0015811920166015625 s
DEBUG 01-05 09:19:34.802968.802968 mlpmodule.py:582] gpu group einsum cost 0.001054525375366211 s
DEBUG 01-05 09:19:34.805508.805508 mlpmodule.py:611] gpu experts func einsum cost 0.01532602310180664 s
DEBUG 01-05 09:19:34.805338.805338 cuda_h.py:19] end gpu_experts cost 0.015769481658935547 seconds
DEBUG 01-05 09:19:34.805717.805717 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:34.805937.805937 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-05 09:19:34.805565.805565 cuda_h.py:19] end layer_moe_generate_1 cost 0.2983276844024658 seconds
DEBUG 01-05 09:19:34.805352.805352 lmp.py:214] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 09:19:34.805452.805452 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 09:19:34.805625.805625 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:34.806436.806436 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:34.808123.808123 cuda_h.py:19] end self_attn cost 0.002449512481689453 seconds
DEBUG 01-05 09:19:34.808093.808093 cuda_h.py:19] end iln_self_attn_paln cost 0.0030519962310791016 seconds
DEBUG 01-05 09:19:34.809320.809320 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 09:19:34.809659.809659 cuda_h.py:10] start gate
DEBUG 01-05 09:19:34.809156.809156 cuda_h.py:19] end gate cost 0.0005741119384765625 seconds
DEBUG 01-05 09:19:34.809509.809509 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:34.810910.810910 lmp.py:361] 
DEBUG 01-05 09:19:34.810910.810910 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:34.810811.810811 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:34.810892.810892 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:34.810588.810588 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:34.810092.810092 lmp.py:365] 
DEBUG 01-05 09:19:34.810092.810092 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:34.810927.810927 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:34.810769.810769 lmp.py:372]   Expert 34 |     42 | CPU
DEBUG 01-05 09:19:34.810127.810127 lmp.py:372]   Expert 36 |     49 | CPU
DEBUG 01-05 09:19:34.810723.810723 lmp.py:372]   Expert 58 |     65 | CPU
DEBUG 01-05 09:19:34.810989.810989 lmp.py:372]   Expert  3 |     67 | CPU
DEBUG 01-05 09:19:34.810824.810824 lmp.py:372]   Expert 26 |     69 | CPU
DEBUG 01-05 09:19:34.810467.810467 lmp.py:372]   Expert 27 |     77 | CPU
DEBUG 01-05 09:19:34.810872.810872 lmp.py:372]   Expert  8 |     78 | CPU
DEBUG 01-05 09:19:34.810276.810276 lmp.py:372]   Expert 29 |     80 | CPU
DEBUG 01-05 09:19:34.810065.810065 lmp.py:372]   Expert  7 |     94 | CPU
DEBUG 01-05 09:19:34.810708.810708 lmp.py:372]   Expert 10 |     99 | CPU
DEBUG 01-05 09:19:34.810636.810636 lmp.py:372]   Expert 28 |    107 | CPU
DEBUG 01-05 09:19:34.810802.810802 lmp.py:372]   Expert 21 |    108 | CPU
DEBUG 01-05 09:19:34.810160.810160 lmp.py:372]   Expert 13 |    109 | CPU
DEBUG 01-05 09:19:34.810041.810041 lmp.py:372]   Expert 19 |    114 | CPU
DEBUG 01-05 09:19:34.810876.810876 lmp.py:372]   Expert 62 |    126 | CPU
DEBUG 01-05 09:19:34.810281.810281 lmp.py:372]   Expert 40 |    133 | CPU
DEBUG 01-05 09:19:34.810447.810447 lmp.py:372]   Expert  5 |    140 | CPU
DEBUG 01-05 09:19:34.810375.810375 lmp.py:372]   Expert 52 |    141 | CPU
DEBUG 01-05 09:19:34.810303.810303 lmp.py:372]   Expert 63 |    141 | CPU
DEBUG 01-05 09:19:34.810230.810230 lmp.py:372]   Expert  9 |    148 | CPU
DEBUG 01-05 09:19:34.810304.810304 lmp.py:372]   Expert 25 |    149 | CPU
DEBUG 01-05 09:19:34.810232.810232 lmp.py:372]   Expert 50 |    153 | CPU
DEBUG 01-05 09:19:34.810636.810636 lmp.py:372]   Expert 59 |    153 | CPU
DEBUG 01-05 09:19:34.810279.810279 lmp.py:372]   Expert 33 |    154 | CPU
DEBUG 01-05 09:19:34.810445.810445 lmp.py:372]   Expert 17 |    157 | CPU
DEBUG 01-05 09:19:34.810280.810280 lmp.py:372]   Expert 49 |    157 | CPU
DEBUG 01-05 09:19:34.810685.810685 lmp.py:372]   Expert 16 |    160 | CPU
DEBUG 01-05 09:19:34.810851.810851 lmp.py:372]   Expert 60 |    165 | CPU
DEBUG 01-05 09:19:34.810540.810540 lmp.py:372]   Expert 24 |    166 | CPU
DEBUG 01-05 09:19:34.810706.810706 lmp.py:372]   Expert  0 |    167 | CPU
DEBUG 01-05 09:19:34.810634.810634 lmp.py:372]   Expert 30 |    170 | CPU
DEBUG 01-05 09:19:34.810562.810562 lmp.py:372]   Expert 35 |    170 | CPU
DEBUG 01-05 09:19:34.810966.810966 lmp.py:372]   Expert  1 |    173 | GPU
DEBUG 01-05 09:19:34.810609.810609 lmp.py:372]   Expert 38 |    178 | GPU
DEBUG 01-05 09:19:34.810683.810683 lmp.py:372]   Expert  6 |    180 | GPU
DEBUG 01-05 09:19:34.810611.810611 lmp.py:372]   Expert 45 |    180 | GPU
DEBUG 01-05 09:19:34.810015.810015 lmp.py:372]   Expert 44 |    184 | GPU
DEBUG 01-05 09:19:34.810704.810704 lmp.py:372]   Expert 31 |    199 | GPU
DEBUG 01-05 09:19:34.810586.810586 lmp.py:372]   Expert 48 |    206 | GPU
DEBUG 01-05 09:19:34.810229.810229 lmp.py:372]   Expert 39 |    228 | GPU
DEBUG 01-05 09:19:34.810302.810302 lmp.py:372]   Expert 37 |    237 | GPU
DEBUG 01-05 09:19:34.810468.810468 lmp.py:372]   Expert 55 |    238 | GPU
DEBUG 01-05 09:19:34.810396.810396 lmp.py:372]   Expert  4 |    239 | GPU
DEBUG 01-05 09:19:34.810562.810562 lmp.py:372]   Expert 22 |    241 | GPU
DEBUG 01-05 09:19:34.810490.810490 lmp.py:372]   Expert 14 |    242 | GPU
DEBUG 01-05 09:19:34.810656.810656 lmp.py:372]   Expert 51 |    248 | GPU
DEBUG 01-05 09:19:34.810206.810206 lmp.py:372]   Expert 57 |    253 | GPU
DEBUG 01-05 09:19:34.810849.810849 lmp.py:372]   Expert  2 |    254 | GPU
DEBUG 01-05 09:19:34.811016.811016 lmp.py:372]   Expert 41 |    255 | GPU
DEBUG 01-05 09:19:34.811943.811943 lmp.py:372]   Expert 12 |    263 | GPU
DEBUG 01-05 09:19:34.811871.811871 lmp.py:372]   Expert 47 |    269 | GPU
DEBUG 01-05 09:19:34.811944.811944 lmp.py:372]   Expert 20 |    272 | GPU
DEBUG 01-05 09:19:34.811111.811111 lmp.py:372]   Expert 15 |    275 | GPU
DEBUG 01-05 09:19:34.811800.811800 lmp.py:372]   Expert 42 |    281 | GPU
DEBUG 01-05 09:19:34.811443.811443 lmp.py:372]   Expert 23 |    287 | GPU
DEBUG 01-05 09:19:34.811324.811324 lmp.py:372]   Expert 53 |    304 | GPU
DEBUG 01-05 09:19:34.811490.811490 lmp.py:372]   Expert 61 |    306 | GPU
DEBUG 01-05 09:19:34.811326.811326 lmp.py:372]   Expert 56 |    312 | GPU
DEBUG 01-05 09:19:34.811492.811492 lmp.py:372]   Expert 18 |    314 | GPU
DEBUG 01-05 09:19:34.811181.811181 lmp.py:372]   Expert 54 |    315 | GPU
DEBUG 01-05 09:19:34.811347.811347 lmp.py:372]   Expert 46 |    330 | GPU
DEBUG 01-05 09:19:34.811798.811798 lmp.py:372]   Expert 32 |    338 | GPU
DEBUG 01-05 09:19:34.811726.811726 lmp.py:372]   Expert 43 |    364 | GPU
DEBUG 01-05 09:19:34.811369.811369 lmp.py:372]   Expert 11 |    415 | GPU
DEBUG 01-05 09:19:34.811157.811157 lmp.py:373] 
DEBUG 01-05 09:19:34.811157.811157 lmp.py:373]   CPU total tokens: 3908 (31.8%)
DEBUG 01-05 09:19:34.811185.811185 lmp.py:374]   GPU total tokens: 8380 (68.2%)
DEBUG 01-05 09:19:34.811834.811834 cuda_h.py:19] end experts_map_get cost 0.0015797615051269531 seconds
DEBUG 01-05 09:19:34.811193.811193 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:34.811168.811168 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:34.811252.811252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:34.811398.811398 cuda_h.py:19] end allocate_cuda_memory cost 0.00017571449279785156 seconds
DEBUG 01-05 09:19:34.811340.811340 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:34.811673.811673 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:34.811058.811058 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:34.811092.811092 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d4aadce-d286-480b-8701-156da4d6e64b
DEBUG 01-05 09:19:34.812336.812336 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:34.814402.814402 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d4aadce-d286-480b-8701-156da4d6e64b
DEBUG 01-05 09:19:34.814138.814138 cuda_h.py:19] end load_into_gpu_async cost 0.002242565155029297 seconds
DEBUG 01-05 09:19:34.814670.814670 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:34.814242.814242 cuda_h.py:19] end restore_tensors2 cost 0.0002524852752685547 seconds
DEBUG 01-05 09:19:34.814819.814819 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003019094467163086 seconds
DEBUG 01-05 09:19:34.817679.817679 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005807638168334961 seconds
DEBUG 01-05 09:19:34.817622.817622 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:34.817446.817446 lmp.py:419] 
DEBUG 01-05 09:19:34.817446.817446 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:34.817243.817243 cuda_h.py:19] end cpu_experts_submit cost 0.00011181831359863281 seconds
DEBUG 01-05 09:19:34.817515.817515 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:34.827507.827507 mlpmodule.py:704] group tensors cost 0.009734869003295898 s
DEBUG 01-05 09:19:34.829939.829939 mlpmodule.py:742] pad cost 0.0015769004821777344 s
DEBUG 01-05 09:19:34.829420.829420 mlpmodule.py:748] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-05 09:19:34.829906.829906 mlpmodule.py:753] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-05 09:19:34.841359.841359 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:34.842359.842359 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:34.842316.842316 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 09:19:34.842347.842347 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:34.863121.863121 mlpmodule.py:793] group einsum cost 0.03424692153930664 s
DEBUG 01-05 09:19:34.865775.865775 mlpmodule.py:801] cpy2cputensor cost 0.000949859619140625 s
DEBUG 01-05 09:19:34.905689.905689 cuda_h.py:19] end wait_cetm_experts cost 0.08761835098266602 seconds
DEBUG 01-05 09:19:34.905473.905473 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:34.905219.905219 cuda_h.py:19] end gpu_sexperts cost 0.00047087669372558594 seconds
DEBUG 01-05 09:19:34.905062.905062 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:19:34.905606.905606 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:19:34.905231.905231 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.528594970703125e-05 seconds
DEBUG 01-05 09:19:34.905948.905948 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:19:34.905170.905170 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:34.906928.906928 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:34.906732.906732 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d4aadce-d286-480b-8701-156da4d6e64b
DEBUG 01-05 09:19:34.906284.906284 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:34.906761.906761 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:34.910881.910881 cuda_h.py:19] end allocate_cuda_memory cost 0.0036110877990722656 seconds
DEBUG 01-05 09:19:34.910708.910708 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:34.910261.910261 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:34.911834.911834 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:34.911260.911260 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 377fe5b8-9f43-4930-b7d4-417b70ecdfe9
DEBUG 01-05 09:19:34.911882.911882 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:34.911080.911080 client.py:127] Model loaded
DEBUG 01-05 09:19:34.911150.911150 cuda_h.py:19] end wait_experts cost 0.005377292633056641 seconds
DEBUG 01-05 09:19:34.911628.911628 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:34.911530.911530 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:34.912721.912721 mlpmodule.py:531] gpu group tensors cost 0.0006883144378662109 s
INFO 01-05 09:19:34.912278.912278 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 377fe5b8-9f43-4930-b7d4-417b70ecdfe9
DEBUG 01-05 09:19:34.913107.913107 cuda_h.py:19] end load_into_gpu_async cost 0.0022821426391601562 seconds
DEBUG 01-05 09:19:34.913906.913906 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:34.913297.913297 cuda_h.py:19] end restore_tensors2 cost 0.00021910667419433594 seconds
DEBUG 01-05 09:19:34.913282.913282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007123470306396484 seconds
INFO 01-05 09:19:34.915859.915859 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 377fe5b8-9f43-4930-b7d4-417b70ecdfe9
DEBUG 01-05 09:19:34.919670.919670 mlpmodule.py:564] gpu pad cost 0.007073879241943359 s
DEBUG 01-05 09:19:34.920749.920749 mlpmodule.py:662]  experts func einsum cost 0.10300421714782715 s
INFO 01-05 09:19:34.921290.921290 client.py:127] Model loaded
DEBUG 01-05 09:19:34.921944.921944 mlpmodule.py:582] gpu group einsum cost 0.0015032291412353516 s
DEBUG 01-05 09:19:34.921956.921956 cuda_h.py:19] end sllm_worker_task cost 0.015312433242797852 seconds
DEBUG 01-05 09:19:34.924850.924850 mlpmodule.py:611] gpu experts func einsum cost 0.012644052505493164 s
DEBUG 01-05 09:19:34.924941.924941 cuda_h.py:19] end gpu_experts cost 0.012873649597167969 seconds
DEBUG 01-05 09:19:34.924419.924419 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:34.924639.924639 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-05 09:19:34.924975.924975 cuda_h.py:19] end layer_moe_generate_2 cost 0.11586332321166992 seconds
DEBUG 01-05 09:19:34.925882.925882 lmp.py:214] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 09:19:34.925406.925406 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 09:19:34.925579.925579 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:34.925536.925536 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:34.927555.927555 cuda_h.py:19] end self_attn cost 0.002482175827026367 seconds
DEBUG 01-05 09:19:34.928605.928605 cuda_h.py:19] end iln_self_attn_paln cost 0.0031082630157470703 seconds
DEBUG 01-05 09:19:34.928071.928071 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 09:19:34.928278.928278 cuda_h.py:10] start gate
DEBUG 01-05 09:19:34.929358.929358 cuda_h.py:19] end gate cost 0.0005834102630615234 seconds
DEBUG 01-05 09:19:34.929002.929002 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:34.929933.929933 lmp.py:361] 
DEBUG 01-05 09:19:34.929933.929933 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:34.929166.929166 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:34.929769.929769 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:34.929511.929511 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:34.929631.929631 lmp.py:365] 
DEBUG 01-05 09:19:34.929631.929631 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:34.929989.929989 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:34.929308.929308 lmp.py:372]   Expert 61 |     54 | CPU
DEBUG 01-05 09:19:34.929382.929382 lmp.py:372]   Expert 15 |     70 | CPU
DEBUG 01-05 09:19:34.929025.929025 lmp.py:372]   Expert 32 |     70 | CPU
DEBUG 01-05 09:19:34.929144.929144 lmp.py:372]   Expert  4 |     82 | CPU
DEBUG 01-05 09:19:34.929218.929218 lmp.py:372]   Expert 59 |     88 | CPU
DEBUG 01-05 09:19:34.929622.929622 lmp.py:372]   Expert 16 |     91 | CPU
DEBUG 01-05 09:19:34.929789.929789 lmp.py:372]   Expert  1 |     92 | CPU
DEBUG 01-05 09:19:34.929955.929955 lmp.py:372]   Expert 37 |     95 | CPU
DEBUG 01-05 09:19:34.929644.929644 lmp.py:372]   Expert  5 |    101 | CPU
DEBUG 01-05 09:19:34.929049.929049 lmp.py:372]   Expert  6 |    102 | CPU
DEBUG 01-05 09:19:34.929215.929215 lmp.py:372]   Expert 28 |    113 | CPU
DEBUG 01-05 09:19:34.929381.929381 lmp.py:372]   Expert  7 |    119 | CPU
DEBUG 01-05 09:19:34.929547.929547 lmp.py:372]   Expert  8 |    124 | CPU
DEBUG 01-05 09:19:34.929144.929144 lmp.py:372]   Expert 36 |    130 | CPU
DEBUG 01-05 09:19:34.929025.929025 lmp.py:372]   Expert 42 |    136 | CPU
DEBUG 01-05 09:19:34.929430.929430 lmp.py:372]   Expert 44 |    136 | CPU
DEBUG 01-05 09:19:34.929357.929357 lmp.py:372]   Expert 63 |    136 | CPU
DEBUG 01-05 09:19:34.929762.929762 lmp.py:372]   Expert 52 |    139 | CPU
DEBUG 01-05 09:19:34.929690.929690 lmp.py:372]   Expert 24 |    140 | CPU
DEBUG 01-05 09:19:34.929617.929617 lmp.py:372]   Expert 10 |    141 | CPU
DEBUG 01-05 09:19:34.929499.929499 lmp.py:372]   Expert 29 |    144 | CPU
DEBUG 01-05 09:19:34.929142.929142 lmp.py:372]   Expert 38 |    145 | CPU
DEBUG 01-05 09:19:34.929785.929785 lmp.py:372]   Expert 55 |    145 | CPU
DEBUG 01-05 09:19:34.929712.929712 lmp.py:372]   Expert 12 |    146 | CPU
DEBUG 01-05 09:19:34.929879.929879 lmp.py:372]   Expert 49 |    150 | CPU
DEBUG 01-05 09:19:34.929045.929045 lmp.py:372]   Expert 23 |    160 | CPU
DEBUG 01-05 09:19:34.929972.929972 lmp.py:372]   Expert 30 |    160 | CPU
DEBUG 01-05 09:19:34.929900.929900 lmp.py:372]   Expert 26 |    162 | CPU
DEBUG 01-05 09:19:34.930782.930782 lmp.py:372]   Expert 56 |    170 | CPU
DEBUG 01-05 09:19:34.930901.930901 lmp.py:372]   Expert 57 |    174 | CPU
DEBUG 01-05 09:19:34.930067.930067 lmp.py:372]   Expert 58 |    175 | CPU
DEBUG 01-05 09:19:34.930757.930757 lmp.py:372]   Expert 18 |    178 | CPU
DEBUG 01-05 09:19:34.930684.930684 lmp.py:372]   Expert 11 |    179 | GPU
DEBUG 01-05 09:19:34.930851.930851 lmp.py:372]   Expert 62 |    182 | GPU
DEBUG 01-05 09:19:34.930778.930778 lmp.py:372]   Expert  2 |    190 | GPU
DEBUG 01-05 09:19:34.930706.930706 lmp.py:372]   Expert 48 |    190 | GPU
DEBUG 01-05 09:19:34.930349.930349 lmp.py:372]   Expert 40 |    192 | GPU
DEBUG 01-05 09:19:34.930992.930992 lmp.py:372]   Expert 31 |    194 | GPU
DEBUG 01-05 09:19:34.930158.930158 lmp.py:372]   Expert 35 |    194 | GPU
DEBUG 01-05 09:19:34.930086.930086 lmp.py:372]   Expert 13 |    196 | GPU
DEBUG 01-05 09:19:34.930014.930014 lmp.py:372]   Expert 47 |    197 | GPU
DEBUG 01-05 09:19:34.930180.930180 lmp.py:372]   Expert 20 |    211 | GPU
DEBUG 01-05 09:19:34.930346.930346 lmp.py:372]   Expert 45 |    212 | GPU
DEBUG 01-05 09:19:34.930274.930274 lmp.py:372]   Expert 39 |    220 | GPU
DEBUG 01-05 09:19:34.930632.930632 lmp.py:372]   Expert  0 |    221 | GPU
DEBUG 01-05 09:19:34.930851.930851 lmp.py:372]   Expert 17 |    224 | GPU
DEBUG 01-05 09:19:34.930017.930017 lmp.py:372]   Expert 46 |    225 | GPU
DEBUG 01-05 09:19:34.930183.930183 lmp.py:372]   Expert 33 |    227 | GPU
DEBUG 01-05 09:19:34.930349.930349 lmp.py:372]   Expert 22 |    233 | GPU
DEBUG 01-05 09:19:34.930277.930277 lmp.py:372]   Expert 19 |    237 | GPU
DEBUG 01-05 09:19:34.930205.930205 lmp.py:372]   Expert 53 |    240 | GPU
DEBUG 01-05 09:19:34.930894.930894 lmp.py:372]   Expert 51 |    244 | GPU
DEBUG 01-05 09:19:34.930060.930060 lmp.py:372]   Expert 34 |    252 | GPU
DEBUG 01-05 09:19:34.930465.930465 lmp.py:372]   Expert 27 |    266 | GPU
DEBUG 01-05 09:19:34.930631.930631 lmp.py:372]   Expert  3 |    275 | GPU
DEBUG 01-05 09:19:34.930797.930797 lmp.py:372]   Expert 54 |    288 | GPU
DEBUG 01-05 09:19:34.930963.930963 lmp.py:372]   Expert 50 |    304 | GPU
DEBUG 01-05 09:19:34.930891.930891 lmp.py:372]   Expert 60 |    313 | GPU
DEBUG 01-05 09:19:34.930057.930057 lmp.py:372]   Expert 21 |    330 | GPU
DEBUG 01-05 09:19:34.930985.930985 lmp.py:372]   Expert 14 |    343 | GPU
DEBUG 01-05 09:19:34.930151.930151 lmp.py:372]   Expert 43 |    382 | GPU
DEBUG 01-05 09:19:34.930317.930317 lmp.py:372]   Expert  9 |    396 | GPU
DEBUG 01-05 09:19:34.930722.930722 lmp.py:372]   Expert 41 |    397 | GPU
DEBUG 01-05 09:19:34.930126.930126 lmp.py:372]   Expert 25 |    466 | GPU
DEBUG 01-05 09:19:34.930246.930246 lmp.py:373] 
DEBUG 01-05 09:19:34.930246.930246 lmp.py:373]   CPU total tokens: 4068 (33.1%)
DEBUG 01-05 09:19:34.930127.930127 lmp.py:374]   GPU total tokens: 8220 (66.9%)
DEBUG 01-05 09:19:34.930539.930539 cuda_h.py:19] end experts_map_get cost 0.0015594959259033203 seconds
DEBUG 01-05 09:19:34.930659.930659 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:34.930296.930296 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:34.930195.930195 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:34.931836.931836 cuda_h.py:19] end allocate_cuda_memory cost 0.00033402442932128906 seconds
DEBUG 01-05 09:19:34.931024.931024 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:34.931171.931171 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:34.931947.931947 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:34.931650.931650 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf167bfb-0942-4c86-bb11-f2ec42ce5d6f
DEBUG 01-05 09:19:34.931014.931014 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:34.932804.932804 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf167bfb-0942-4c86-bb11-f2ec42ce5d6f
DEBUG 01-05 09:19:34.933617.933617 cuda_h.py:19] end load_into_gpu_async cost 0.0016522407531738281 seconds
DEBUG 01-05 09:19:34.933726.933726 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:34.933349.933349 cuda_h.py:19] end restore_tensors2 cost 0.0007331371307373047 seconds
DEBUG 01-05 09:19:34.933219.933219 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032205581665039062 seconds
DEBUG 01-05 09:19:34.936011.936011 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005952358245849609 seconds
DEBUG 01-05 09:19:34.936709.936709 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:34.936056.936056 lmp.py:419] 
DEBUG 01-05 09:19:34.936056.936056 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:34.936760.936760 cuda_h.py:19] end cpu_experts_submit cost 0.00011277198791503906 seconds
DEBUG 01-05 09:19:34.936078.936078 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:34.943453.943453 mlpmodule.py:704] group tensors cost 0.006491661071777344 s
DEBUG 01-05 09:19:34.946896.946896 mlpmodule.py:742] pad cost 0.002643108367919922 s
DEBUG 01-05 09:19:34.947245.947245 mlpmodule.py:748] create cpu tensor cost 6.008148193359375e-05 s
DEBUG 01-05 09:19:34.947011.947011 mlpmodule.py:753] move to cpu cost 4.410743713378906e-05 s
DEBUG 01-05 09:19:34.961012.961012 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:34.961250.961250 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:34.961439.961439 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 09:19:34.961185.961185 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:34.982625.982625 mlpmodule.py:793] group einsum cost 0.03525590896606445 s
DEBUG 01-05 09:19:34.983691.983691 mlpmodule.py:801] cpy2cputensor cost 0.0009660720825195312 s
DEBUG 01-05 09:19:35.023869.023869 cuda_h.py:19] end wait_cetm_experts cost 0.08705353736877441 seconds
DEBUG 01-05 09:19:35.024422.024422 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.024878.024878 cuda_h.py:19] end gpu_sexperts cost 0.0005390644073486328 seconds
DEBUG 01-05 09:19:35.024867.024867 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:19:35.024743.024743 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:19:35.024414.024414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.314018249511719e-05 seconds
DEBUG 01-05 09:19:35.024700.024700 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.724761962890625e-05 seconds
DEBUG 01-05 09:19:35.024026.024026 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.024789.024789 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf167bfb-0942-4c86-bb11-f2ec42ce5d6f
DEBUG 01-05 09:19:35.025763.025763 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.025852.025852 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.025215.025215 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.029018.029018 cuda_h.py:19] end allocate_cuda_memory cost 0.003881692886352539 seconds
INFO 01-05 09:19:35.029032.029032 client.py:127] Model loaded
DEBUG 01-05 09:19:35.030569.030569 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.030687.030687 cuda_h.py:19] end wait_experts cost 0.005245208740234375 seconds
DEBUG 01-05 09:19:35.030942.030942 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.030059.030059 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.030906.030906 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.030729.030729 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29dac6c3-ea45-408f-8dcd-baedc189d077
DEBUG 01-05 09:19:35.031087.031087 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.030267.030267 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.032948.032948 mlpmodule.py:531] gpu group tensors cost 0.0006275177001953125 s
INFO 01-05 09:19:35.032146.032146 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29dac6c3-ea45-408f-8dcd-baedc189d077
DEBUG 01-05 09:19:35.032308.032308 cuda_h.py:19] end load_into_gpu_async cost 0.002239227294921875 seconds
DEBUG 01-05 09:19:35.032669.032669 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.032578.032578 cuda_h.py:19] end restore_tensors2 cost 0.00016164779663085938 seconds
DEBUG 01-05 09:19:35.033496.033496 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00745701789855957 seconds
INFO 01-05 09:19:35.034728.034728 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29dac6c3-ea45-408f-8dcd-baedc189d077
DEBUG 01-05 09:19:35.036543.036543 mlpmodule.py:564] gpu pad cost 0.003777742385864258 s
DEBUG 01-05 09:19:35.036540.036540 mlpmodule.py:582] gpu group einsum cost 0.0005698204040527344 s
DEBUG 01-05 09:19:35.039690.039690 mlpmodule.py:662]  experts func einsum cost 0.1020195484161377 s
DEBUG 01-05 09:19:35.040387.040387 mlpmodule.py:611] gpu experts func einsum cost 0.008789539337158203 s
DEBUG 01-05 09:19:35.040967.040967 cuda_h.py:19] end gpu_experts cost 0.009627342224121094 seconds
DEBUG 01-05 09:19:35.040597.040597 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:35.042765.042765 client.py:127] Model loaded
DEBUG 01-05 09:19:35.042452.042452 cuda_h.py:19] end sllm_worker_task cost 0.017350435256958008 seconds
DEBUG 01-05 09:19:35.043083.043083 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0025877952575683594 seconds
DEBUG 01-05 09:19:35.043886.043886 cuda_h.py:19] end layer_moe_generate_3 cost 0.11489009857177734 seconds
DEBUG 01-05 09:19:35.043422.043422 lmp.py:214] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 09:19:35.043522.043522 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 09:19:35.043172.043172 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.043606.043606 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.046983.046983 cuda_h.py:19] end self_attn cost 0.0025014877319335938 seconds
DEBUG 01-05 09:19:35.046291.046291 cuda_h.py:19] end iln_self_attn_paln cost 0.003109455108642578 seconds
DEBUG 01-05 09:19:35.046326.046326 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 09:19:35.046426.046426 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.047354.047354 cuda_h.py:19] end gate cost 0.0005779266357421875 seconds
DEBUG 01-05 09:19:35.047137.047137 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.047274.047274 lmp.py:361] 
DEBUG 01-05 09:19:35.047274.047274 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.047937.047937 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.047256.047256 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.047475.047475 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.047833.047833 lmp.py:365] 
DEBUG 01-05 09:19:35.047833.047833 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.047715.047715 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.047080.047080 lmp.py:372]   Expert 13 |     43 | CPU
DEBUG 01-05 09:19:35.047153.047153 lmp.py:372]   Expert 60 |     53 | CPU
DEBUG 01-05 09:19:35.047796.047796 lmp.py:372]   Expert 11 |     60 | CPU
DEBUG 01-05 09:19:35.047201.047201 lmp.py:372]   Expert 26 |     77 | CPU
DEBUG 01-05 09:19:35.047128.047128 lmp.py:372]   Expert 56 |     81 | CPU
DEBUG 01-05 09:19:35.047294.047294 lmp.py:372]   Expert 58 |     83 | CPU
DEBUG 01-05 09:19:35.047222.047222 lmp.py:372]   Expert 25 |     84 | CPU
DEBUG 01-05 09:19:35.048150.048150 lmp.py:372]   Expert  3 |     85 | CPU
DEBUG 01-05 09:19:35.048793.048793 lmp.py:372]   Expert  7 |     89 | CPU
DEBUG 01-05 09:19:35.048197.048197 lmp.py:372]   Expert 34 |     91 | CPU
DEBUG 01-05 09:19:35.048364.048364 lmp.py:372]   Expert 51 |     93 | CPU
DEBUG 01-05 09:19:35.048291.048291 lmp.py:372]   Expert 36 |     97 | CPU
DEBUG 01-05 09:19:35.048742.048742 lmp.py:372]   Expert 48 |     98 | CPU
DEBUG 01-05 09:19:35.048670.048670 lmp.py:372]   Expert 41 |    101 | CPU
DEBUG 01-05 09:19:35.048598.048598 lmp.py:372]   Expert 45 |    101 | CPU
DEBUG 01-05 09:19:35.048525.048525 lmp.py:372]   Expert 16 |    104 | CPU
DEBUG 01-05 09:19:35.048930.048930 lmp.py:372]   Expert 28 |    105 | CPU
DEBUG 01-05 09:19:35.048573.048573 lmp.py:372]   Expert  6 |    108 | CPU
DEBUG 01-05 09:19:35.048262.048262 lmp.py:372]   Expert 33 |    116 | CPU
DEBUG 01-05 09:19:35.048951.048951 lmp.py:372]   Expert  9 |    129 | CPU
DEBUG 01-05 09:19:35.048641.048641 lmp.py:372]   Expert 24 |    129 | CPU
DEBUG 01-05 09:19:35.048092.048092 lmp.py:372]   Expert 55 |    129 | CPU
DEBUG 01-05 09:19:35.048019.048019 lmp.py:372]   Expert 18 |    134 | CPU
DEBUG 01-05 09:19:35.048947.048947 lmp.py:372]   Expert 17 |    135 | CPU
DEBUG 01-05 09:19:35.048590.048590 lmp.py:372]   Expert 14 |    136 | CPU
DEBUG 01-05 09:19:35.048995.048995 lmp.py:372]   Expert  4 |    145 | CPU
DEBUG 01-05 09:19:35.048922.048922 lmp.py:372]   Expert  2 |    147 | CPU
DEBUG 01-05 09:19:35.048612.048612 lmp.py:372]   Expert 50 |    150 | CPU
DEBUG 01-05 09:19:35.048539.048539 lmp.py:372]   Expert 47 |    154 | CPU
DEBUG 01-05 09:19:35.048229.048229 lmp.py:372]   Expert 44 |    155 | CPU
DEBUG 01-05 09:19:35.048024.048024 lmp.py:372]   Expert 22 |    166 | CPU
DEBUG 01-05 09:19:35.048190.048190 lmp.py:372]   Expert 54 |    175 | CPU
DEBUG 01-05 09:19:35.048549.048549 lmp.py:372]   Expert 10 |    176 | GPU
DEBUG 01-05 09:19:35.048192.048192 lmp.py:372]   Expert 31 |    177 | GPU
DEBUG 01-05 09:19:35.048119.048119 lmp.py:372]   Expert 37 |    191 | GPU
DEBUG 01-05 09:19:35.048047.048047 lmp.py:372]   Expert 40 |    193 | GPU
DEBUG 01-05 09:19:35.048736.048736 lmp.py:372]   Expert 15 |    195 | GPU
DEBUG 01-05 09:19:35.048187.048187 lmp.py:372]   Expert 21 |    198 | GPU
DEBUG 01-05 09:19:35.048876.048876 lmp.py:372]   Expert 61 |    198 | GPU
DEBUG 01-05 09:19:35.048566.048566 lmp.py:372]   Expert 46 |    200 | GPU
DEBUG 01-05 09:19:35.048493.048493 lmp.py:372]   Expert 42 |    203 | GPU
DEBUG 01-05 09:19:35.048898.048898 lmp.py:372]   Expert 53 |    209 | GPU
DEBUG 01-05 09:19:35.048064.048064 lmp.py:372]   Expert  8 |    211 | GPU
DEBUG 01-05 09:19:35.048230.048230 lmp.py:372]   Expert 27 |    219 | GPU
DEBUG 01-05 09:19:35.048681.048681 lmp.py:372]   Expert 63 |    219 | GPU
DEBUG 01-05 09:19:35.048370.048370 lmp.py:372]   Expert 29 |    221 | GPU
DEBUG 01-05 09:19:35.048298.048298 lmp.py:372]   Expert 20 |    223 | GPU
DEBUG 01-05 09:19:35.048226.048226 lmp.py:372]   Expert 57 |    229 | GPU
DEBUG 01-05 09:19:35.048154.048154 lmp.py:372]   Expert 32 |    231 | GPU
DEBUG 01-05 09:19:35.048843.048843 lmp.py:372]   Expert 19 |    259 | GPU
DEBUG 01-05 09:19:35.048486.048486 lmp.py:372]   Expert 38 |    270 | GPU
DEBUG 01-05 09:19:35.048890.048890 lmp.py:372]   Expert 23 |    272 | GPU
DEBUG 01-05 09:19:35.048818.048818 lmp.py:372]   Expert  0 |    273 | GPU
DEBUG 01-05 09:19:35.048269.048269 lmp.py:372]   Expert 12 |    274 | GPU
DEBUG 01-05 09:19:35.048197.048197 lmp.py:372]   Expert  1 |    281 | GPU
DEBUG 01-05 09:19:35.048886.048886 lmp.py:372]   Expert 62 |    294 | GPU
DEBUG 01-05 09:19:35.048291.048291 lmp.py:372]   Expert 30 |    305 | GPU
DEBUG 01-05 09:19:35.048218.048218 lmp.py:372]   Expert 49 |    321 | GPU
DEBUG 01-05 09:19:35.048146.048146 lmp.py:372]   Expert 35 |    326 | GPU
DEBUG 01-05 09:19:35.048835.048835 lmp.py:372]   Expert 52 |    403 | GPU
DEBUG 01-05 09:19:35.048286.048286 lmp.py:372]   Expert 39 |    426 | GPU
DEBUG 01-05 09:19:35.048976.048976 lmp.py:372]   Expert  5 |    428 | GPU
DEBUG 01-05 09:19:35.048142.048142 lmp.py:372]   Expert 43 |    486 | GPU
DEBUG 01-05 09:19:35.048069.048069 lmp.py:372]   Expert 59 |    624 | GPU
DEBUG 01-05 09:19:35.048189.048189 lmp.py:373] 
DEBUG 01-05 09:19:35.048189.048189 lmp.py:373]   CPU total tokens: 3553 (28.9%)
DEBUG 01-05 09:19:35.048309.048309 lmp.py:374]   GPU total tokens: 8735 (71.1%)
DEBUG 01-05 09:19:35.049720.049720 cuda_h.py:19] end experts_map_get cost 0.0015587806701660156 seconds
DEBUG 01-05 09:19:35.049602.049602 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.049524.049524 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.049661.049661 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.049831.049831 cuda_h.py:19] end allocate_cuda_memory cost 0.0002999305725097656 seconds
DEBUG 01-05 09:19:35.049588.049588 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.049967.049967 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.049690.049690 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.049393.049393 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c2806fdb-6e7c-4f2e-b8d0-85694c1239a7
DEBUG 01-05 09:19:35.049406.049406 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.051618.051618 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c2806fdb-6e7c-4f2e-b8d0-85694c1239a7
DEBUG 01-05 09:19:35.051977.051977 cuda_h.py:19] end load_into_gpu_async cost 0.0022907257080078125 seconds
DEBUG 01-05 09:19:35.051224.051224 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.052254.052254 cuda_h.py:19] end restore_tensors2 cost 0.00027632713317871094 seconds
DEBUG 01-05 09:19:35.052030.052030 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032296180725097656 seconds
DEBUG 01-05 09:19:35.054284.054284 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005917549133300781 seconds
DEBUG 01-05 09:19:35.055167.055167 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.055560.055560 lmp.py:419] 
DEBUG 01-05 09:19:35.055560.055560 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.055139.055139 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-05 09:19:35.055127.055127 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.060035.060035 mlpmodule.py:704] group tensors cost 0.0056247711181640625 s
DEBUG 01-05 09:19:35.063120.063120 mlpmodule.py:742] pad cost 0.002307415008544922 s
DEBUG 01-05 09:19:35.064549.064549 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:19:35.064962.064962 mlpmodule.py:753] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-05 09:19:35.074387.074387 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.075187.075187 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.075807.075807 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 09:19:35.075560.075560 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.093752.093752 mlpmodule.py:793] group einsum cost 0.029633522033691406 s
DEBUG 01-05 09:19:35.095982.095982 mlpmodule.py:801] cpy2cputensor cost 0.0009107589721679688 s
DEBUG 01-05 09:19:35.136767.136767 cuda_h.py:19] end wait_cetm_experts cost 0.08118629455566406 seconds
DEBUG 01-05 09:19:35.136075.136075 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.137198.137198 cuda_h.py:19] end gpu_sexperts cost 0.0004622936248779297 seconds
DEBUG 01-05 09:19:35.137849.137849 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:19:35.137333.137333 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:19:35.137051.137051 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.457069396972656e-05 seconds
DEBUG 01-05 09:19:35.137476.137476 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.462501525878906e-05 seconds
DEBUG 01-05 09:19:35.137748.137748 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.137657.137657 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c2806fdb-6e7c-4f2e-b8d0-85694c1239a7
DEBUG 01-05 09:19:35.137115.137115 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.137873.137873 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.137766.137766 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.142781.142781 cuda_h.py:19] end allocate_cuda_memory cost 0.0042841434478759766 seconds
INFO 01-05 09:19:35.142093.142093 client.py:127] Model loaded
DEBUG 01-05 09:19:35.142318.142318 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.142198.142198 cuda_h.py:19] end wait_experts cost 0.005655050277709961 seconds
DEBUG 01-05 09:19:35.143387.143387 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.143927.143927 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.143900.143900 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.143231.143231 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.144660.144660 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20f4ed8b-cf16-403f-a237-f50f7e24429f
DEBUG 01-05 09:19:35.144025.144025 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.144214.144214 mlpmodule.py:531] gpu group tensors cost 0.0011429786682128906 s
INFO 01-05 09:19:35.145639.145639 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20f4ed8b-cf16-403f-a237-f50f7e24429f
DEBUG 01-05 09:19:35.145711.145711 cuda_h.py:19] end load_into_gpu_async cost 0.0025599002838134766 seconds
DEBUG 01-05 09:19:35.145773.145773 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.148728.148728 cuda_h.py:19] end restore_tensors2 cost 0.002732515335083008 seconds
DEBUG 01-05 09:19:35.148109.148109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01069784164428711 seconds
INFO 01-05 09:19:35.150575.150575 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20f4ed8b-cf16-403f-a237-f50f7e24429f
DEBUG 01-05 09:19:35.151121.151121 mlpmodule.py:564] gpu pad cost 0.007002115249633789 s
INFO 01-05 09:19:35.153078.153078 client.py:127] Model loaded
DEBUG 01-05 09:19:35.153441.153441 cuda_h.py:19] end sllm_worker_task cost 0.015819549560546875 seconds
DEBUG 01-05 09:19:35.153362.153362 mlpmodule.py:662]  experts func einsum cost 0.09846663475036621 s
DEBUG 01-05 09:19:35.154821.154821 mlpmodule.py:582] gpu group einsum cost 0.002192974090576172 s
DEBUG 01-05 09:19:35.156454.156454 mlpmodule.py:611] gpu experts func einsum cost 0.013486146926879883 s
DEBUG 01-05 09:19:35.157100.157100 cuda_h.py:19] end gpu_experts cost 0.013672590255737305 seconds
DEBUG 01-05 09:19:35.157955.157955 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:35.157930.157930 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1696090698242188e-05 seconds
DEBUG 01-05 09:19:35.157729.157729 cuda_h.py:19] end layer_moe_generate_4 cost 0.11051607131958008 seconds
DEBUG 01-05 09:19:35.157099.157099 lmp.py:214] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 09:19:35.157577.157577 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 09:19:35.157273.157273 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.157170.157170 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.160346.160346 cuda_h.py:19] end self_attn cost 0.002418994903564453 seconds
DEBUG 01-05 09:19:35.160727.160727 cuda_h.py:19] end iln_self_attn_paln cost 0.0030422210693359375 seconds
DEBUG 01-05 09:19:35.160431.160431 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 09:19:35.160009.160009 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.161122.161122 cuda_h.py:19] end gate cost 0.0005736351013183594 seconds
DEBUG 01-05 09:19:35.161382.161382 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.161889.161889 lmp.py:361] 
DEBUG 01-05 09:19:35.161889.161889 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.161598.161598 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.161679.161679 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.161421.161421 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.161541.161541 lmp.py:365] 
DEBUG 01-05 09:19:35.161541.161541 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.161661.161661 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.161264.161264 lmp.py:372]   Expert 34 |     23 | CPU
DEBUG 01-05 09:19:35.161622.161622 lmp.py:372]   Expert 15 |     46 | CPU
DEBUG 01-05 09:19:35.161742.161742 lmp.py:372]   Expert 47 |     49 | CPU
DEBUG 01-05 09:19:35.161147.161147 lmp.py:372]   Expert 39 |     51 | CPU
DEBUG 01-05 09:19:35.161028.161028 lmp.py:372]   Expert  2 |     57 | CPU
DEBUG 01-05 09:19:35.161148.161148 lmp.py:372]   Expert 18 |     69 | CPU
DEBUG 01-05 09:19:35.161083.161083 lmp.py:372]   Expert  3 |     80 | CPU
DEBUG 01-05 09:19:35.161964.161964 lmp.py:372]   Expert 23 |     90 | CPU
DEBUG 01-05 09:19:35.161130.161130 lmp.py:372]   Expert 27 |     95 | CPU
DEBUG 01-05 09:19:35.161535.161535 lmp.py:372]   Expert 30 |     99 | CPU
DEBUG 01-05 09:19:35.161939.161939 lmp.py:372]   Expert 45 |    106 | CPU
DEBUG 01-05 09:19:35.161344.161344 lmp.py:372]   Expert 17 |    109 | CPU
DEBUG 01-05 09:19:35.161510.161510 lmp.py:372]   Expert 28 |    110 | CPU
DEBUG 01-05 09:19:35.162630.162630 lmp.py:372]   Expert 52 |    113 | CPU
DEBUG 01-05 09:19:35.162511.162511 lmp.py:372]   Expert  4 |    115 | CPU
DEBUG 01-05 09:19:35.162916.162916 lmp.py:372]   Expert  0 |    117 | CPU
DEBUG 01-05 09:19:35.162082.162082 lmp.py:372]   Expert 22 |    121 | CPU
DEBUG 01-05 09:19:35.162486.162486 lmp.py:372]   Expert 63 |    123 | CPU
DEBUG 01-05 09:19:35.162414.162414 lmp.py:372]   Expert 62 |    124 | CPU
DEBUG 01-05 09:19:35.162342.162342 lmp.py:372]   Expert  9 |    126 | CPU
DEBUG 01-05 09:19:35.162508.162508 lmp.py:372]   Expert 60 |    126 | CPU
DEBUG 01-05 09:19:35.162436.162436 lmp.py:372]   Expert  8 |    128 | CPU
DEBUG 01-05 09:19:35.162079.162079 lmp.py:372]   Expert 14 |    136 | CPU
DEBUG 01-05 09:19:35.162245.162245 lmp.py:372]   Expert 48 |    140 | CPU
DEBUG 01-05 09:19:35.162172.162172 lmp.py:372]   Expert 51 |    143 | CPU
DEBUG 01-05 09:19:35.162100.162100 lmp.py:372]   Expert 41 |    147 | CPU
DEBUG 01-05 09:19:35.162789.162789 lmp.py:372]   Expert 46 |    148 | CPU
DEBUG 01-05 09:19:35.162671.162671 lmp.py:372]   Expert 54 |    151 | CPU
DEBUG 01-05 09:19:35.162837.162837 lmp.py:372]   Expert 10 |    154 | CPU
DEBUG 01-05 09:19:35.162765.162765 lmp.py:372]   Expert 36 |    165 | CPU
DEBUG 01-05 09:19:35.162692.162692 lmp.py:372]   Expert 43 |    165 | CPU
DEBUG 01-05 09:19:35.162143.162143 lmp.py:372]   Expert 57 |    166 | CPU
DEBUG 01-05 09:19:35.162309.162309 lmp.py:372]   Expert 25 |    167 | GPU
DEBUG 01-05 09:19:35.162237.162237 lmp.py:372]   Expert  1 |    171 | GPU
DEBUG 01-05 09:19:35.162403.162403 lmp.py:372]   Expert 38 |    171 | GPU
DEBUG 01-05 09:19:35.162046.162046 lmp.py:372]   Expert 24 |    174 | GPU
DEBUG 01-05 09:19:35.162928.162928 lmp.py:372]   Expert 26 |    181 | GPU
DEBUG 01-05 09:19:35.162094.162094 lmp.py:372]   Expert 11 |    188 | GPU
DEBUG 01-05 09:19:35.162260.162260 lmp.py:372]   Expert 32 |    193 | GPU
DEBUG 01-05 09:19:35.162188.162188 lmp.py:372]   Expert 16 |    195 | GPU
DEBUG 01-05 09:19:35.162115.162115 lmp.py:372]   Expert 29 |    204 | GPU
DEBUG 01-05 09:19:35.162043.162043 lmp.py:372]   Expert 56 |    204 | GPU
DEBUG 01-05 09:19:35.162971.162971 lmp.py:372]   Expert 58 |    205 | GPU
DEBUG 01-05 09:19:35.162614.162614 lmp.py:372]   Expert 12 |    220 | GPU
DEBUG 01-05 09:19:35.162257.162257 lmp.py:372]   Expert 19 |    221 | GPU
DEBUG 01-05 09:19:35.162184.162184 lmp.py:372]   Expert 55 |    223 | GPU
DEBUG 01-05 09:19:35.162351.162351 lmp.py:372]   Expert 50 |    228 | GPU
DEBUG 01-05 09:19:35.162278.162278 lmp.py:372]   Expert 44 |    229 | GPU
DEBUG 01-05 09:19:35.162729.162729 lmp.py:372]   Expert 42 |    231 | GPU
DEBUG 01-05 09:19:35.162657.162657 lmp.py:372]   Expert 61 |    231 | GPU
DEBUG 01-05 09:19:35.162346.162346 lmp.py:372]   Expert  7 |    243 | GPU
DEBUG 01-05 09:19:35.162274.162274 lmp.py:372]   Expert 35 |    243 | GPU
DEBUG 01-05 09:19:35.162917.162917 lmp.py:372]   Expert 59 |    254 | GPU
DEBUG 01-05 09:19:35.162798.162798 lmp.py:372]   Expert 21 |    284 | GPU
DEBUG 01-05 09:19:35.162964.162964 lmp.py:372]   Expert  5 |    285 | GPU
DEBUG 01-05 09:19:35.162654.162654 lmp.py:372]   Expert 20 |    296 | GPU
DEBUG 01-05 09:19:35.162343.162343 lmp.py:372]   Expert 40 |    296 | GPU
DEBUG 01-05 09:19:35.162032.162032 lmp.py:372]   Expert 31 |    306 | GPU
DEBUG 01-05 09:19:35.162483.162483 lmp.py:372]   Expert 13 |    348 | GPU
DEBUG 01-05 09:19:35.162173.162173 lmp.py:372]   Expert 33 |    355 | GPU
DEBUG 01-05 09:19:35.162769.162769 lmp.py:372]   Expert 49 |    391 | GPU
DEBUG 01-05 09:19:35.162889.162889 lmp.py:372]   Expert  6 |    394 | GPU
DEBUG 01-05 09:19:35.162817.162817 lmp.py:372]   Expert 37 |    484 | GPU
DEBUG 01-05 09:19:35.162268.162268 lmp.py:372]   Expert 53 |    881 | GPU
DEBUG 01-05 09:19:35.162672.162672 lmp.py:373] 
DEBUG 01-05 09:19:35.162672.162672 lmp.py:373]   CPU total tokens: 3592 (29.2%)
DEBUG 01-05 09:19:35.162554.162554 lmp.py:374]   GPU total tokens: 8696 (70.8%)
DEBUG 01-05 09:19:35.162965.162965 cuda_h.py:19] end experts_map_get cost 0.0015587806701660156 seconds
DEBUG 01-05 09:19:35.162846.162846 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.162292.162292 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.163766.163766 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.163165.163165 cuda_h.py:19] end allocate_cuda_memory cost 0.00019025802612304688 seconds
DEBUG 01-05 09:19:35.163591.163591 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.163969.163969 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.163262.163262 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.163157.163157 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f2d9a5ec-3121-472c-9f96-091fc383b8dc
DEBUG 01-05 09:19:35.163700.163700 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.165169.165169 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f2d9a5ec-3121-472c-9f96-091fc383b8dc
DEBUG 01-05 09:19:35.165820.165820 cuda_h.py:19] end load_into_gpu_async cost 0.0016815662384033203 seconds
DEBUG 01-05 09:19:35.165477.165477 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.165632.165632 cuda_h.py:19] end restore_tensors2 cost 0.00026488304138183594 seconds
DEBUG 01-05 09:19:35.165117.165117 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002482175827026367 seconds
DEBUG 01-05 09:19:35.168444.168444 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00515294075012207 seconds
DEBUG 01-05 09:19:35.168803.168803 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.168455.168455 lmp.py:419] 
DEBUG 01-05 09:19:35.168455.168455 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.168729.168729 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-05 09:19:35.168332.168332 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.173239.173239 mlpmodule.py:704] group tensors cost 0.0046083927154541016 s
DEBUG 01-05 09:19:35.175354.175354 mlpmodule.py:742] pad cost 0.0018773078918457031 s
DEBUG 01-05 09:19:35.175848.175848 mlpmodule.py:748] create cpu tensor cost 4.8160552978515625e-05 s
DEBUG 01-05 09:19:35.175242.175242 mlpmodule.py:753] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-05 09:19:35.186310.186310 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.186786.186786 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.186221.186221 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 09:19:35.186298.186298 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.206610.206610 mlpmodule.py:793] group einsum cost 0.03031325340270996 s
DEBUG 01-05 09:19:35.207450.207450 mlpmodule.py:801] cpy2cputensor cost 0.0007336139678955078 s
DEBUG 01-05 09:19:35.248772.248772 cuda_h.py:19] end wait_cetm_experts cost 0.08011698722839355 seconds
DEBUG 01-05 09:19:35.248602.248602 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.249288.249288 cuda_h.py:19] end gpu_sexperts cost 0.0004630088806152344 seconds
DEBUG 01-05 09:19:35.249323.249323 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:19:35.249477.249477 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:19:35.249241.249241 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 09:19:35.249772.249772 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.295608520507812e-05 seconds
DEBUG 01-05 09:19:35.249998.249998 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.249536.249536 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f2d9a5ec-3121-472c-9f96-091fc383b8dc
DEBUG 01-05 09:19:35.249709.249709 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.249122.249122 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.250247.250247 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.254075.254075 cuda_h.py:19] end allocate_cuda_memory cost 0.0044286251068115234 seconds
INFO 01-05 09:19:35.254195.254195 client.py:127] Model loaded
DEBUG 01-05 09:19:35.255844.255844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.255916.255916 cuda_h.py:19] end wait_experts cost 0.005774497985839844 seconds
DEBUG 01-05 09:19:35.255204.255204 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.255698.255698 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.255664.255664 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.255932.255932 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80c53958-b2e6-4e61-8589-496a70a2dcd6
DEBUG 01-05 09:19:35.255795.255795 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.256571.256571 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.257779.257779 mlpmodule.py:531] gpu group tensors cost 0.0007166862487792969 s
INFO 01-05 09:19:35.257667.257667 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80c53958-b2e6-4e61-8589-496a70a2dcd6
DEBUG 01-05 09:19:35.258838.258838 cuda_h.py:19] end load_into_gpu_async cost 0.002718687057495117 seconds
DEBUG 01-05 09:19:35.258085.258085 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.260471.260471 cuda_h.py:19] end restore_tensors2 cost 0.0027294158935546875 seconds
DEBUG 01-05 09:19:35.261998.261998 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010998010635375977 seconds
INFO 01-05 09:19:35.262032.262032 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80c53958-b2e6-4e61-8589-496a70a2dcd6
DEBUG 01-05 09:19:35.264155.264155 mlpmodule.py:564] gpu pad cost 0.00693964958190918 s
INFO 01-05 09:19:35.265947.265947 client.py:127] Model loaded
DEBUG 01-05 09:19:35.265787.265787 cuda_h.py:19] end sllm_worker_task cost 0.016098976135253906 seconds
DEBUG 01-05 09:19:35.266607.266607 mlpmodule.py:662]  experts func einsum cost 0.09769010543823242 s
DEBUG 01-05 09:19:35.266875.266875 mlpmodule.py:582] gpu group einsum cost 0.0022072792053222656 s
DEBUG 01-05 09:19:35.269176.269176 mlpmodule.py:611] gpu experts func einsum cost 0.012958526611328125 s
DEBUG 01-05 09:19:35.269226.269226 cuda_h.py:19] end gpu_experts cost 0.013677835464477539 seconds
DEBUG 01-05 09:19:35.269366.269366 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:35.269632.269632 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-05 09:19:35.269472.269472 cuda_h.py:19] end layer_moe_generate_5 cost 0.10898447036743164 seconds
DEBUG 01-05 09:19:35.269564.269564 lmp.py:214] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 09:19:35.269327.269327 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 09:19:35.269738.269738 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.270681.270681 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.272309.272309 cuda_h.py:19] end self_attn cost 0.0024759769439697266 seconds
DEBUG 01-05 09:19:35.272809.272809 cuda_h.py:19] end iln_self_attn_paln cost 0.0030755996704101562 seconds
DEBUG 01-05 09:19:35.273844.273844 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 09:19:35.273945.273945 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.273681.273681 cuda_h.py:19] end gate cost 0.0005764961242675781 seconds
DEBUG 01-05 09:19:35.273464.273464 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.274110.274110 lmp.py:361] 
DEBUG 01-05 09:19:35.274110.274110 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.274581.274581 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.274423.274423 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.274927.274927 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.274570.274570 lmp.py:365] 
DEBUG 01-05 09:19:35.274570.274570 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.274451.274451 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.274055.274055 lmp.py:372]   Expert  1 |      6 | CPU
DEBUG 01-05 09:19:35.274890.274890 lmp.py:372]   Expert  3 |     30 | CPU
DEBUG 01-05 09:19:35.274533.274533 lmp.py:372]   Expert 14 |     50 | CPU
DEBUG 01-05 09:19:35.274937.274937 lmp.py:372]   Expert 53 |     59 | CPU
DEBUG 01-05 09:19:35.274104.274104 lmp.py:372]   Expert 52 |     60 | CPU
DEBUG 01-05 09:19:35.274270.274270 lmp.py:372]   Expert 35 |     70 | CPU
DEBUG 01-05 09:19:35.274151.274151 lmp.py:372]   Expert 15 |     71 | CPU
DEBUG 01-05 09:19:35.274317.274317 lmp.py:372]   Expert 44 |     80 | CPU
DEBUG 01-05 09:19:35.274006.274006 lmp.py:372]   Expert 10 |     83 | CPU
DEBUG 01-05 09:19:35.274173.274173 lmp.py:372]   Expert 63 |     87 | CPU
DEBUG 01-05 09:19:35.274862.274862 lmp.py:372]   Expert 11 |     88 | CPU
DEBUG 01-05 09:19:35.274551.274551 lmp.py:372]   Expert 26 |    102 | CPU
DEBUG 01-05 09:19:35.274002.274002 lmp.py:372]   Expert 50 |    102 | CPU
DEBUG 01-05 09:19:35.274930.274930 lmp.py:372]   Expert 49 |    103 | CPU
DEBUG 01-05 09:19:35.274858.274858 lmp.py:372]   Expert 37 |    111 | CPU
DEBUG 01-05 09:19:35.274785.274785 lmp.py:372]   Expert  7 |    112 | CPU
DEBUG 01-05 09:19:35.274528.274528 lmp.py:372]   Expert 40 |    112 | CPU
DEBUG 01-05 09:19:35.274409.274409 lmp.py:372]   Expert 22 |    116 | CPU
DEBUG 01-05 09:19:35.274575.274575 lmp.py:372]   Expert 34 |    118 | CPU
DEBUG 01-05 09:19:35.274264.274264 lmp.py:372]   Expert 16 |    119 | CPU
DEBUG 01-05 09:19:35.274192.274192 lmp.py:372]   Expert 47 |    121 | CPU
DEBUG 01-05 09:19:35.274120.274120 lmp.py:372]   Expert 62 |    127 | CPU
DEBUG 01-05 09:19:35.274571.274571 lmp.py:372]   Expert 28 |    130 | CPU
DEBUG 01-05 09:19:35.274499.274499 lmp.py:372]   Expert 32 |    131 | CPU
DEBUG 01-05 09:19:35.274903.274903 lmp.py:372]   Expert 31 |    148 | CPU
DEBUG 01-05 09:19:35.274308.274308 lmp.py:372]   Expert 30 |    150 | CPU
DEBUG 01-05 09:19:35.274474.274474 lmp.py:372]   Expert  4 |    152 | CPU
DEBUG 01-05 09:19:35.274163.274163 lmp.py:372]   Expert 57 |    153 | CPU
DEBUG 01-05 09:19:35.274091.274091 lmp.py:372]   Expert 51 |    156 | CPU
DEBUG 01-05 09:19:35.274019.274019 lmp.py:372]   Expert 41 |    157 | CPU
DEBUG 01-05 09:19:35.274946.274946 lmp.py:372]   Expert 58 |    157 | CPU
DEBUG 01-05 09:19:35.274636.274636 lmp.py:372]   Expert 25 |    166 | CPU
DEBUG 01-05 09:19:35.274325.274325 lmp.py:372]   Expert 54 |    176 | GPU
DEBUG 01-05 09:19:35.274445.274445 lmp.py:372]   Expert 59 |    176 | GPU
DEBUG 01-05 09:19:35.274088.274088 lmp.py:372]   Expert 45 |    179 | GPU
DEBUG 01-05 09:19:35.274254.274254 lmp.py:372]   Expert  9 |    187 | GPU
DEBUG 01-05 09:19:35.274705.274705 lmp.py:372]   Expert  0 |    194 | GPU
DEBUG 01-05 09:19:35.274632.274632 lmp.py:372]   Expert 55 |    194 | GPU
DEBUG 01-05 09:19:35.274083.274083 lmp.py:372]   Expert 21 |    199 | GPU
DEBUG 01-05 09:19:35.274011.274011 lmp.py:372]   Expert 38 |    201 | GPU
DEBUG 01-05 09:19:35.274700.274700 lmp.py:372]   Expert 46 |    202 | GPU
DEBUG 01-05 09:19:35.274105.274105 lmp.py:372]   Expert 12 |    205 | GPU
DEBUG 01-05 09:19:35.274509.274509 lmp.py:372]   Expert 29 |    205 | GPU
DEBUG 01-05 09:19:35.274676.274676 lmp.py:372]   Expert 33 |    212 | GPU
DEBUG 01-05 09:19:35.274126.274126 lmp.py:372]   Expert  6 |    214 | GPU
DEBUG 01-05 09:19:35.274054.274054 lmp.py:372]   Expert  8 |    215 | GPU
DEBUG 01-05 09:19:35.274743.274743 lmp.py:372]   Expert 13 |    216 | GPU
DEBUG 01-05 09:19:35.275433.275433 lmp.py:372]   Expert  5 |    220 | GPU
DEBUG 01-05 09:19:35.275884.275884 lmp.py:372]   Expert 43 |    223 | GPU
DEBUG 01-05 09:19:35.275334.275334 lmp.py:372]   Expert 19 |    227 | GPU
DEBUG 01-05 09:19:35.275739.275739 lmp.py:372]   Expert 42 |    232 | GPU
DEBUG 01-05 09:19:35.275097.275097 lmp.py:372]   Expert  2 |    233 | GPU
DEBUG 01-05 09:19:35.275263.275263 lmp.py:372]   Expert 24 |    248 | GPU
DEBUG 01-05 09:19:35.275714.275714 lmp.py:372]   Expert 17 |    263 | GPU
DEBUG 01-05 09:19:35.275404.275404 lmp.py:372]   Expert 23 |    268 | GPU
DEBUG 01-05 09:19:35.275093.275093 lmp.py:372]   Expert 61 |    280 | GPU
DEBUG 01-05 09:19:35.275782.275782 lmp.py:372]   Expert 27 |    347 | GPU
DEBUG 01-05 09:19:35.275233.275233 lmp.py:372]   Expert 20 |    359 | GPU
DEBUG 01-05 09:19:35.275922.275922 lmp.py:372]   Expert 18 |    379 | GPU
DEBUG 01-05 09:19:35.275089.275089 lmp.py:372]   Expert 48 |    395 | GPU
DEBUG 01-05 09:19:35.275016.275016 lmp.py:372]   Expert 39 |    415 | GPU
DEBUG 01-05 09:19:35.275467.275467 lmp.py:372]   Expert 60 |    469 | GPU
DEBUG 01-05 09:19:35.275156.275156 lmp.py:372]   Expert 56 |    609 | GPU
DEBUG 01-05 09:19:35.275369.275369 lmp.py:372]   Expert 36 |    719 | GPU
DEBUG 01-05 09:19:35.275012.275012 lmp.py:373] 
DEBUG 01-05 09:19:35.275012.275012 lmp.py:373]   CPU total tokens: 3427 (27.9%)
DEBUG 01-05 09:19:35.275370.275370 lmp.py:374]   GPU total tokens: 8861 (72.1%)
DEBUG 01-05 09:19:35.275305.275305 cuda_h.py:19] end experts_map_get cost 0.0015385150909423828 seconds
DEBUG 01-05 09:19:35.275186.275186 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.275777.275777 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.275583.275583 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.275008.275008 cuda_h.py:19] end allocate_cuda_memory cost 0.00020933151245117188 seconds
DEBUG 01-05 09:19:35.275289.275289 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.275667.275667 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.275198.275198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.275471.275471 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 64a35a6a-7325-45de-913c-204069240f31
DEBUG 01-05 09:19:35.276159.276159 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.277143.277143 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 64a35a6a-7325-45de-913c-204069240f31
DEBUG 01-05 09:19:35.277956.277956 cuda_h.py:19] end load_into_gpu_async cost 0.0018832683563232422 seconds
DEBUG 01-05 09:19:35.277403.277403 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.278600.278600 cuda_h.py:19] end restore_tensors2 cost 0.0006737709045410156 seconds
DEBUG 01-05 09:19:35.278753.278753 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003223896026611328 seconds
DEBUG 01-05 09:19:35.281584.281584 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00591731071472168 seconds
DEBUG 01-05 09:19:35.281036.281036 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.281429.281429 lmp.py:419] 
DEBUG 01-05 09:19:35.281429.281429 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.281988.281988 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-05 09:19:35.281022.281022 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.293756.293756 mlpmodule.py:704] group tensors cost 0.012102603912353516 s
DEBUG 01-05 09:19:35.295865.295865 mlpmodule.py:742] pad cost 0.0015065670013427734 s
DEBUG 01-05 09:19:35.295570.295570 mlpmodule.py:748] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-05 09:19:35.296003.296003 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-05 09:19:35.306825.306825 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.306533.306533 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.306199.306199 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 09:19:35.306230.306230 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.323355.323355 mlpmodule.py:793] group einsum cost 0.02742934226989746 s
DEBUG 01-05 09:19:35.324660.324660 mlpmodule.py:801] cpy2cputensor cost 0.0007901191711425781 s
DEBUG 01-05 09:19:35.364495.364495 cuda_h.py:19] end wait_cetm_experts cost 0.08330941200256348 seconds
DEBUG 01-05 09:19:35.364471.364471 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.365680.365680 cuda_h.py:19] end gpu_sexperts cost 0.00046181678771972656 seconds
DEBUG 01-05 09:19:35.365715.365715 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:19:35.365399.365399 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:19:35.365547.365547 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.552436828613281e-05 seconds
DEBUG 01-05 09:19:35.365926.365926 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.653236389160156e-05 seconds
DEBUG 01-05 09:19:35.365960.365960 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.365669.365669 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 64a35a6a-7325-45de-913c-204069240f31
DEBUG 01-05 09:19:35.365505.365505 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.366302.366302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.366135.366135 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.370412.370412 cuda_h.py:19] end allocate_cuda_memory cost 0.004407644271850586 seconds
INFO 01-05 09:19:35.371572.371572 client.py:127] Model loaded
DEBUG 01-05 09:19:35.371274.371274 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.371008.371008 cuda_h.py:19] end wait_experts cost 0.00574493408203125 seconds
DEBUG 01-05 09:19:35.371012.371012 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.371082.371082 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.371724.371724 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.372223.372223 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.372227.372227 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 637ac464-7f35-426d-9fa1-fd03e5fa0f10
DEBUG 01-05 09:19:35.372142.372142 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.373349.373349 mlpmodule.py:531] gpu group tensors cost 0.0011570453643798828 s
DEBUG 01-05 09:19:35.374516.374516 mlpmodule.py:564] gpu pad cost 0.001691579818725586 s
DEBUG 01-05 09:19:35.375947.375947 mlpmodule.py:582] gpu group einsum cost 0.0005145072937011719 s
INFO 01-05 09:19:35.377163.377163 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 637ac464-7f35-426d-9fa1-fd03e5fa0f10
DEBUG 01-05 09:19:35.377923.377923 cuda_h.py:19] end load_into_gpu_async cost 0.005872488021850586 seconds
DEBUG 01-05 09:19:35.377893.377893 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.377411.377411 cuda_h.py:19] end restore_tensors2 cost 0.0001633167266845703 seconds
DEBUG 01-05 09:19:35.377919.377919 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01158452033996582 seconds
INFO 01-05 09:19:35.379879.379879 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 637ac464-7f35-426d-9fa1-fd03e5fa0f10
DEBUG 01-05 09:19:35.380021.380021 mlpmodule.py:662]  experts func einsum cost 0.0993499755859375 s
DEBUG 01-05 09:19:35.381857.381857 mlpmodule.py:611] gpu experts func einsum cost 0.009409666061401367 s
DEBUG 01-05 09:19:35.381046.381046 cuda_h.py:19] end gpu_experts cost 0.009620189666748047 seconds
DEBUG 01-05 09:19:35.381948.381948 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:35.385557.385557 client.py:127] Model loaded
DEBUG 01-05 09:19:35.385714.385714 cuda_h.py:19] end sllm_worker_task cost 0.019249916076660156 seconds
DEBUG 01-05 09:19:35.385622.385622 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0040547847747802734 seconds
DEBUG 01-05 09:19:35.385937.385937 cuda_h.py:19] end layer_moe_generate_6 cost 0.11287522315979004 seconds
DEBUG 01-05 09:19:35.386005.386005 lmp.py:214] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 09:19:35.386146.386146 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 09:19:35.386870.386870 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.386791.386791 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.390029.390029 cuda_h.py:19] end self_attn cost 0.003630399703979492 seconds
DEBUG 01-05 09:19:35.390044.390044 cuda_h.py:19] end iln_self_attn_paln cost 0.004569530487060547 seconds
DEBUG 01-05 09:19:35.391412.391412 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 09:19:35.391407.391407 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.392948.392948 cuda_h.py:19] end gate cost 0.0008635520935058594 seconds
DEBUG 01-05 09:19:35.392772.392772 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.392300.392300 lmp.py:361] 
DEBUG 01-05 09:19:35.392300.392300 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.392712.392712 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.392105.392105 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.392682.392682 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.392299.392299 lmp.py:365] 
DEBUG 01-05 09:19:35.392299.392299 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.392155.392155 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.392785.392785 lmp.py:372]   Expert  1 |     19 | CPU
DEBUG 01-05 09:19:35.392786.392786 lmp.py:372]   Expert  3 |     27 | CPU
DEBUG 01-05 09:19:35.392595.392595 lmp.py:372]   Expert 25 |     46 | CPU
DEBUG 01-05 09:19:35.393259.393259 lmp.py:372]   Expert 40 |     49 | CPU
DEBUG 01-05 09:19:35.393445.393445 lmp.py:372]   Expert 49 |     57 | CPU
DEBUG 01-05 09:19:35.393632.393632 lmp.py:372]   Expert 41 |     59 | CPU
DEBUG 01-05 09:19:35.393580.393580 lmp.py:372]   Expert 20 |     66 | CPU
DEBUG 01-05 09:19:35.393197.393197 lmp.py:372]   Expert 15 |     67 | CPU
DEBUG 01-05 09:19:35.393291.393291 lmp.py:372]   Expert 31 |     67 | CPU
DEBUG 01-05 09:19:35.393954.393954 lmp.py:372]   Expert  8 |     74 | CPU
DEBUG 01-05 09:19:35.393664.393664 lmp.py:372]   Expert 29 |     76 | CPU
DEBUG 01-05 09:19:35.393612.393612 lmp.py:372]   Expert 48 |     81 | CPU
DEBUG 01-05 09:19:35.393798.393798 lmp.py:372]   Expert 16 |     86 | CPU
DEBUG 01-05 09:19:35.393654.393654 lmp.py:372]   Expert 39 |     86 | CPU
DEBUG 01-05 09:19:35.393509.393509 lmp.py:372]   Expert  6 |     87 | CPU
DEBUG 01-05 09:19:35.393649.393649 lmp.py:372]   Expert  5 |     90 | CPU
DEBUG 01-05 09:19:35.393121.393121 lmp.py:372]   Expert 63 |     95 | CPU
DEBUG 01-05 09:19:35.393830.393830 lmp.py:372]   Expert 32 |    105 | CPU
DEBUG 01-05 09:19:35.393732.393732 lmp.py:372]   Expert 58 |    105 | CPU
DEBUG 01-05 09:19:35.393919.393919 lmp.py:372]   Expert 18 |    106 | CPU
DEBUG 01-05 09:19:35.393059.393059 lmp.py:372]   Expert 57 |    106 | CPU
DEBUG 01-05 09:19:35.393391.393391 lmp.py:372]   Expert 59 |    121 | CPU
DEBUG 01-05 09:19:35.393101.393101 lmp.py:372]   Expert 30 |    141 | CPU
DEBUG 01-05 09:19:35.393049.393049 lmp.py:372]   Expert 55 |    141 | CPU
DEBUG 01-05 09:19:35.393043.393043 lmp.py:372]   Expert 34 |    156 | CPU
DEBUG 01-05 09:19:35.393945.393945 lmp.py:372]   Expert 53 |    156 | CPU
DEBUG 01-05 09:19:35.393046.393046 lmp.py:372]   Expert  4 |    158 | CPU
DEBUG 01-05 09:19:35.393584.393584 lmp.py:372]   Expert 35 |    159 | CPU
DEBUG 01-05 09:19:35.393254.393254 lmp.py:372]   Expert 26 |    163 | CPU
DEBUG 01-05 09:19:35.393871.393871 lmp.py:372]   Expert 45 |    166 | CPU
DEBUG 01-05 09:19:35.393249.393249 lmp.py:372]   Expert  0 |    169 | CPU
DEBUG 01-05 09:19:35.393674.393674 lmp.py:372]   Expert 52 |    180 | CPU
DEBUG 01-05 09:19:35.393079.393079 lmp.py:372]   Expert 33 |    181 | GPU
DEBUG 01-05 09:19:35.394007.394007 lmp.py:372]   Expert  7 |    183 | GPU
DEBUG 01-05 09:19:35.394457.394457 lmp.py:372]   Expert 50 |    184 | GPU
DEBUG 01-05 09:19:35.394385.394385 lmp.py:372]   Expert 54 |    194 | GPU
DEBUG 01-05 09:19:35.394313.394313 lmp.py:372]   Expert 21 |    196 | GPU
DEBUG 01-05 09:19:35.394002.394002 lmp.py:372]   Expert 28 |    196 | GPU
DEBUG 01-05 09:19:35.394692.394692 lmp.py:372]   Expert 19 |    202 | GPU
DEBUG 01-05 09:19:35.394619.394619 lmp.py:372]   Expert 17 |    203 | GPU
DEBUG 01-05 09:19:35.394832.394832 lmp.py:372]   Expert 42 |    207 | GPU
DEBUG 01-05 09:19:35.394521.394521 lmp.py:372]   Expert 51 |    207 | GPU
DEBUG 01-05 09:19:35.394449.394449 lmp.py:372]   Expert 60 |    211 | GPU
DEBUG 01-05 09:19:35.394138.394138 lmp.py:372]   Expert 24 |    213 | GPU
DEBUG 01-05 09:19:35.394019.394019 lmp.py:372]   Expert 36 |    213 | GPU
DEBUG 01-05 09:19:35.394901.394901 lmp.py:372]   Expert 27 |    214 | GPU
DEBUG 01-05 09:19:35.394590.394590 lmp.py:372]   Expert 43 |    218 | GPU
DEBUG 01-05 09:19:35.394041.394041 lmp.py:372]   Expert 13 |    223 | GPU
DEBUG 01-05 09:19:35.394253.394253 lmp.py:372]   Expert 37 |    249 | GPU
DEBUG 01-05 09:19:35.394943.394943 lmp.py:372]   Expert 10 |    251 | GPU
DEBUG 01-05 09:19:35.394155.394155 lmp.py:372]   Expert 62 |    252 | GPU
DEBUG 01-05 09:19:35.394368.394368 lmp.py:372]   Expert 47 |    266 | GPU
DEBUG 01-05 09:19:35.394057.394057 lmp.py:372]   Expert 11 |    276 | GPU
DEBUG 01-05 09:19:35.394508.394508 lmp.py:372]   Expert 22 |    277 | GPU
DEBUG 01-05 09:19:35.394720.394720 lmp.py:372]   Expert  2 |    301 | GPU
DEBUG 01-05 09:19:35.394694.394694 lmp.py:372]   Expert 56 |    302 | GPU
DEBUG 01-05 09:19:35.394145.394145 lmp.py:372]   Expert 61 |    318 | GPU
DEBUG 01-05 09:19:35.394358.394358 lmp.py:372]   Expert 14 |    348 | GPU
DEBUG 01-05 09:19:35.394332.394332 lmp.py:372]   Expert 44 |    349 | GPU
DEBUG 01-05 09:19:35.394021.394021 lmp.py:372]   Expert 38 |    352 | GPU
DEBUG 01-05 09:19:35.394141.394141 lmp.py:372]   Expert 46 |    370 | GPU
DEBUG 01-05 09:19:35.394784.394784 lmp.py:372]   Expert 12 |    573 | GPU
DEBUG 01-05 09:19:35.394427.394427 lmp.py:372]   Expert  9 |    624 | GPU
DEBUG 01-05 09:19:35.394355.394355 lmp.py:372]   Expert 23 |    671 | GPU
DEBUG 01-05 09:19:35.394236.394236 lmp.py:373] 
DEBUG 01-05 09:19:35.394236.394236 lmp.py:373]   CPU total tokens: 3264 (26.6%)
DEBUG 01-05 09:19:35.394594.394594 lmp.py:374]   GPU total tokens: 9024 (73.4%)
DEBUG 01-05 09:19:35.394529.394529 cuda_h.py:19] end experts_map_get cost 0.0023713111877441406 seconds
DEBUG 01-05 09:19:35.394172.394172 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.394855.394855 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.394853.394853 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.395574.395574 cuda_h.py:19] end allocate_cuda_memory cost 0.00032210350036621094 seconds
DEBUG 01-05 09:19:35.395185.395185 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.395418.395418 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.395426.395426 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.395460.395460 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 117c10c4-fb64-41de-a4ce-cd46a359a8a2
DEBUG 01-05 09:19:35.395526.395526 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.397304.397304 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 117c10c4-fb64-41de-a4ce-cd46a359a8a2
DEBUG 01-05 09:19:35.397187.397187 cuda_h.py:19] end load_into_gpu_async cost 0.0023925304412841797 seconds
DEBUG 01-05 09:19:35.397790.397790 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.397158.397158 cuda_h.py:19] end restore_tensors2 cost 0.00028252601623535156 seconds
DEBUG 01-05 09:19:35.397882.397882 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003331422805786133 seconds
DEBUG 01-05 09:19:35.400539.400539 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005995750427246094 seconds
DEBUG 01-05 09:19:35.400753.400753 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.400954.400954 lmp.py:419] 
DEBUG 01-05 09:19:35.400954.400954 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.400559.400559 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-05 09:19:35.400646.400646 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.410808.410808 mlpmodule.py:704] group tensors cost 0.009402751922607422 s
DEBUG 01-05 09:19:35.414798.414798 mlpmodule.py:742] pad cost 0.0033867359161376953 s
DEBUG 01-05 09:19:35.414425.414425 mlpmodule.py:748] create cpu tensor cost 4.3392181396484375e-05 s
DEBUG 01-05 09:19:35.415427.415427 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-05 09:19:35.426716.426716 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.426702.426702 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.426506.426506 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 09:19:35.426968.426968 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.445868.445868 mlpmodule.py:793] group einsum cost 0.030675888061523438 s
DEBUG 01-05 09:19:35.447955.447955 mlpmodule.py:801] cpy2cputensor cost 0.0014111995697021484 s
DEBUG 01-05 09:19:35.487710.487710 cuda_h.py:19] end wait_cetm_experts cost 0.08647727966308594 seconds
DEBUG 01-05 09:19:35.487679.487679 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.487173.487173 cuda_h.py:19] end gpu_sexperts cost 0.0004622936248779297 seconds
DEBUG 01-05 09:19:35.488725.488725 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:19:35.488733.488733 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:19:35.488212.488212 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.504753112792969e-05 seconds
DEBUG 01-05 09:19:35.488206.488206 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.367134094238281e-05 seconds
DEBUG 01-05 09:19:35.488810.488810 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.488327.488327 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 117c10c4-fb64-41de-a4ce-cd46a359a8a2
DEBUG 01-05 09:19:35.488567.488567 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.488855.488855 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.488702.488702 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.493721.493721 cuda_h.py:19] end allocate_cuda_memory cost 0.004607200622558594 seconds
INFO 01-05 09:19:35.493013.493013 client.py:127] Model loaded
DEBUG 01-05 09:19:35.494377.494377 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.494203.494203 cuda_h.py:19] end wait_experts cost 0.005964517593383789 seconds
DEBUG 01-05 09:19:35.494068.494068 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.494462.494462 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.494686.494686 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.494549.494549 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1260605e-1f43-4b99-b0a3-3f687cab5fd1
DEBUG 01-05 09:19:35.494187.494187 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.495871.495871 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.499175.499175 mlpmodule.py:531] gpu group tensors cost 0.0037682056427001953 s
INFO 01-05 09:19:35.499361.499361 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1260605e-1f43-4b99-b0a3-3f687cab5fd1
DEBUG 01-05 09:19:35.500931.500931 cuda_h.py:19] end load_into_gpu_async cost 0.0058019161224365234 seconds
DEBUG 01-05 09:19:35.500424.500424 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.500055.500055 cuda_h.py:19] end restore_tensors2 cost 0.00017547607421875 seconds
DEBUG 01-05 09:19:35.500376.500376 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011679649353027344 seconds
INFO 01-05 09:19:35.501044.501044 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1260605e-1f43-4b99-b0a3-3f687cab5fd1
DEBUG 01-05 09:19:35.503713.503713 mlpmodule.py:564] gpu pad cost 0.003900766372680664 s
DEBUG 01-05 09:19:35.503539.503539 mlpmodule.py:662]  experts func einsum cost 0.10267400741577148 s
DEBUG 01-05 09:19:35.503487.503487 mlpmodule.py:582] gpu group einsum cost 0.0006315708160400391 s
DEBUG 01-05 09:19:35.507217.507217 mlpmodule.py:611] gpu experts func einsum cost 0.011746406555175781 s
DEBUG 01-05 09:19:35.507392.507392 cuda_h.py:19] end gpu_experts cost 0.012456893920898438 seconds
DEBUG 01-05 09:19:35.507002.507002 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:35.510700.510700 client.py:127] Model loaded
DEBUG 01-05 09:19:35.510255.510255 cuda_h.py:19] end sllm_worker_task cost 0.022046804428100586 seconds
DEBUG 01-05 09:19:35.510340.510340 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0036995410919189453 seconds
DEBUG 01-05 09:19:35.511195.511195 cuda_h.py:19] end layer_moe_generate_7 cost 0.12004423141479492 seconds
DEBUG 01-05 09:19:35.511995.511995 lmp.py:214] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 09:19:35.511380.511380 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 09:19:35.511123.511123 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.511450.511450 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.514476.514476 cuda_h.py:19] end self_attn cost 0.002488851547241211 seconds
DEBUG 01-05 09:19:35.514864.514864 cuda_h.py:19] end iln_self_attn_paln cost 0.0031137466430664062 seconds
DEBUG 01-05 09:19:35.514707.514707 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 09:19:35.514616.514616 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.515729.515729 cuda_h.py:19] end gate cost 0.0005741119384765625 seconds
DEBUG 01-05 09:19:35.515604.515604 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.515912.515912 lmp.py:361] 
DEBUG 01-05 09:19:35.515912.515912 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.515953.515953 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.515841.515841 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.515392.515392 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.515319.515319 lmp.py:365] 
DEBUG 01-05 09:19:35.515319.515319 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.515201.515201 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.515566.515566 lmp.py:372]   Expert  7 |     21 | CPU
DEBUG 01-05 09:19:35.515209.515209 lmp.py:372]   Expert 27 |     26 | CPU
DEBUG 01-05 09:19:35.515375.515375 lmp.py:372]   Expert 14 |     27 | CPU
DEBUG 01-05 09:19:35.515826.515826 lmp.py:372]   Expert 30 |     36 | CPU
DEBUG 01-05 09:19:35.515992.515992 lmp.py:372]   Expert 38 |     43 | CPU
DEBUG 01-05 09:19:35.515635.515635 lmp.py:372]   Expert 12 |     50 | CPU
DEBUG 01-05 09:19:35.515563.515563 lmp.py:372]   Expert 36 |     58 | CPU
DEBUG 01-05 09:19:35.515775.515775 lmp.py:372]   Expert 22 |     63 | CPU
DEBUG 01-05 09:19:35.515464.515464 lmp.py:372]   Expert 53 |     65 | CPU
DEBUG 01-05 09:19:35.515915.515915 lmp.py:372]   Expert  8 |     67 | CPU
DEBUG 01-05 09:19:35.515605.515605 lmp.py:372]   Expert 34 |     68 | CPU
DEBUG 01-05 09:19:35.515817.515817 lmp.py:372]   Expert 26 |     81 | CPU
DEBUG 01-05 09:19:35.515983.515983 lmp.py:372]   Expert 54 |     89 | CPU
DEBUG 01-05 09:19:35.515865.515865 lmp.py:372]   Expert 33 |     90 | CPU
DEBUG 01-05 09:19:35.515554.515554 lmp.py:372]   Expert  1 |     94 | CPU
DEBUG 01-05 09:19:35.515005.515005 lmp.py:372]   Expert 40 |     94 | CPU
DEBUG 01-05 09:19:35.515932.515932 lmp.py:372]   Expert 57 |    103 | CPU
DEBUG 01-05 09:19:35.516383.516383 lmp.py:372]   Expert  9 |    109 | CPU
DEBUG 01-05 09:19:35.516596.516596 lmp.py:372]   Expert 13 |    109 | CPU
DEBUG 01-05 09:19:35.516047.516047 lmp.py:372]   Expert 50 |    111 | CPU
DEBUG 01-05 09:19:35.516736.516736 lmp.py:372]   Expert 32 |    115 | CPU
DEBUG 01-05 09:19:35.516425.516425 lmp.py:372]   Expert 29 |    118 | CPU
DEBUG 01-05 09:19:35.516830.516830 lmp.py:372]   Expert 17 |    123 | CPU
DEBUG 01-05 09:19:35.516758.516758 lmp.py:372]   Expert 44 |    139 | CPU
DEBUG 01-05 09:19:35.516970.516970 lmp.py:372]   Expert 59 |    140 | CPU
DEBUG 01-05 09:19:35.516421.516421 lmp.py:372]   Expert 24 |    146 | CPU
DEBUG 01-05 09:19:35.516633.516633 lmp.py:372]   Expert 60 |    148 | CPU
DEBUG 01-05 09:19:35.516607.516607 lmp.py:372]   Expert 16 |    159 | CPU
DEBUG 01-05 09:19:35.516820.516820 lmp.py:372]   Expert  2 |    165 | CPU
DEBUG 01-05 09:19:35.516794.516794 lmp.py:372]   Expert 51 |    167 | CPU
DEBUG 01-05 09:19:35.516006.516006 lmp.py:372]   Expert 10 |    171 | CPU
DEBUG 01-05 09:19:35.516980.516980 lmp.py:372]   Expert 56 |    171 | CPU
DEBUG 01-05 09:19:35.516776.516776 lmp.py:372]   Expert 15 |    172 | GPU
DEBUG 01-05 09:19:35.516419.516419 lmp.py:372]   Expert 37 |    179 | GPU
DEBUG 01-05 09:19:35.516870.516870 lmp.py:372]   Expert 31 |    186 | GPU
DEBUG 01-05 09:19:35.516321.516321 lmp.py:372]   Expert 39 |    193 | GPU
DEBUG 01-05 09:19:35.516295.516295 lmp.py:372]   Expert 18 |    194 | GPU
DEBUG 01-05 09:19:35.516507.516507 lmp.py:372]   Expert 19 |    195 | GPU
DEBUG 01-05 09:19:35.516481.516481 lmp.py:372]   Expert 58 |    218 | GPU
DEBUG 01-05 09:19:35.516623.516623 lmp.py:372]   Expert 61 |    230 | GPU
DEBUG 01-05 09:19:35.516888.516888 lmp.py:372]   Expert 41 |    240 | GPU
DEBUG 01-05 09:19:35.516578.516578 lmp.py:372]   Expert 49 |    240 | GPU
DEBUG 01-05 09:19:35.516552.516552 lmp.py:372]   Expert 35 |    244 | GPU
DEBUG 01-05 09:19:35.516241.516241 lmp.py:372]   Expert  0 |    245 | GPU
DEBUG 01-05 09:19:35.516692.516692 lmp.py:372]   Expert 46 |    247 | GPU
DEBUG 01-05 09:19:35.516904.516904 lmp.py:372]   Expert 23 |    252 | GPU
DEBUG 01-05 09:19:35.516355.516355 lmp.py:372]   Expert 42 |    255 | GPU
DEBUG 01-05 09:19:35.516568.516568 lmp.py:372]   Expert  3 |    260 | GPU
DEBUG 01-05 09:19:35.516780.516780 lmp.py:372]   Expert  6 |    267 | GPU
DEBUG 01-05 09:19:35.516993.516993 lmp.py:372]   Expert 55 |    276 | GPU
DEBUG 01-05 09:19:35.516728.516728 lmp.py:372]   Expert 28 |    283 | GPU
DEBUG 01-05 09:19:35.516471.516471 lmp.py:372]   Expert  4 |    284 | GPU
DEBUG 01-05 09:19:35.516921.516921 lmp.py:372]   Expert 43 |    302 | GPU
DEBUG 01-05 09:19:35.516372.516372 lmp.py:372]   Expert 20 |    314 | GPU
DEBUG 01-05 09:19:35.516346.516346 lmp.py:372]   Expert 45 |    323 | GPU
DEBUG 01-05 09:19:35.516559.516559 lmp.py:372]   Expert 47 |    329 | GPU
DEBUG 01-05 09:19:35.516010.516010 lmp.py:372]   Expert 25 |    334 | GPU
DEBUG 01-05 09:19:35.516222.516222 lmp.py:372]   Expert 52 |    335 | GPU
DEBUG 01-05 09:19:35.516673.516673 lmp.py:372]   Expert 48 |    349 | GPU
DEBUG 01-05 09:19:35.516124.516124 lmp.py:372]   Expert 11 |    392 | GPU
DEBUG 01-05 09:19:35.516098.516098 lmp.py:372]   Expert 62 |    400 | GPU
DEBUG 01-05 09:19:35.516310.516310 lmp.py:372]   Expert 63 |    413 | GPU
DEBUG 01-05 09:19:35.516477.516477 lmp.py:372]   Expert 21 |    424 | GPU
DEBUG 01-05 09:19:35.516689.516689 lmp.py:372]   Expert  5 |    547 | GPU
DEBUG 01-05 09:19:35.516617.516617 lmp.py:373] 
DEBUG 01-05 09:19:35.516617.516617 lmp.py:373]   CPU total tokens: 3166 (25.8%)
DEBUG 01-05 09:19:35.516783.516783 lmp.py:374]   GPU total tokens: 9122 (74.2%)
DEBUG 01-05 09:19:35.516194.516194 cuda_h.py:19] end experts_map_get cost 0.0015647411346435547 seconds
DEBUG 01-05 09:19:35.516837.516837 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.516998.516998 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.517512.517512 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.517994.517994 cuda_h.py:19] end allocate_cuda_memory cost 0.0003218650817871094 seconds
DEBUG 01-05 09:19:35.517990.517990 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.517746.517746 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.517039.517039 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.517841.517841 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 27803b64-02ee-4a69-be97-ccb77233bc0e
DEBUG 01-05 09:19:35.517662.517662 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.519132.519132 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 27803b64-02ee-4a69-be97-ccb77233bc0e
DEBUG 01-05 09:19:35.519839.519839 cuda_h.py:19] end load_into_gpu_async cost 0.0017733573913574219 seconds
DEBUG 01-05 09:19:35.519716.519716 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.520390.520390 cuda_h.py:19] end restore_tensors2 cost 0.0006804466247558594 seconds
DEBUG 01-05 09:19:35.520590.520590 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003222227096557617 seconds
DEBUG 01-05 09:19:35.522114.522114 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005861043930053711 seconds
DEBUG 01-05 09:19:35.522659.522659 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.522927.522927 lmp.py:419] 
DEBUG 01-05 09:19:35.522927.522927 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.523816.523816 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-05 09:19:35.523632.523632 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.534877.534877 mlpmodule.py:704] group tensors cost 0.01173257827758789 s
DEBUG 01-05 09:19:35.537373.537373 mlpmodule.py:742] pad cost 0.0015404224395751953 s
DEBUG 01-05 09:19:35.537754.537754 mlpmodule.py:748] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-05 09:19:35.537842.537842 mlpmodule.py:753] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-05 09:19:35.549346.549346 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.549623.549623 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.549043.549043 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 09:19:35.550167.550167 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.571920.571920 mlpmodule.py:793] group einsum cost 0.03351545333862305 s
DEBUG 01-05 09:19:35.572705.572705 mlpmodule.py:801] cpy2cputensor cost 0.0012900829315185547 s
DEBUG 01-05 09:19:35.612435.612435 cuda_h.py:19] end wait_cetm_experts cost 0.08920717239379883 seconds
DEBUG 01-05 09:19:35.612504.612504 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.612581.612581 cuda_h.py:19] end gpu_sexperts cost 0.00045990943908691406 seconds
DEBUG 01-05 09:19:35.612325.612325 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:19:35.612617.612617 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:19:35.613520.613520 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:19:35.613038.613038 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.081031799316406e-05 seconds
DEBUG 01-05 09:19:35.613164.613164 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.613205.613205 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 27803b64-02ee-4a69-be97-ccb77233bc0e
DEBUG 01-05 09:19:35.613233.613233 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.613414.613414 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.613247.613247 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.618694.618694 cuda_h.py:19] end allocate_cuda_memory cost 0.004537105560302734 seconds
INFO 01-05 09:19:35.618264.618264 client.py:127] Model loaded
DEBUG 01-05 09:19:35.618536.618536 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.619408.619408 cuda_h.py:19] end wait_experts cost 0.0058557987213134766 seconds
DEBUG 01-05 09:19:35.619366.619366 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.619906.619906 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.619687.619687 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.620840.620840 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.620076.620076 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f7b31cfe-280b-4a5e-9d89-433e471d2c8f
DEBUG 01-05 09:19:35.620449.620449 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.624261.624261 mlpmodule.py:531] gpu group tensors cost 0.004570722579956055 s
INFO 01-05 09:19:35.625982.625982 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f7b31cfe-280b-4a5e-9d89-433e471d2c8f
DEBUG 01-05 09:19:35.625835.625835 cuda_h.py:19] end load_into_gpu_async cost 0.006106853485107422 seconds
DEBUG 01-05 09:19:35.625374.625374 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.625362.625362 cuda_h.py:19] end restore_tensors2 cost 0.00015878677368164062 seconds
DEBUG 01-05 09:19:35.625200.625200 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011886119842529297 seconds
INFO 01-05 09:19:35.627929.627929 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f7b31cfe-280b-4a5e-9d89-433e471d2c8f
DEBUG 01-05 09:19:35.628741.628741 mlpmodule.py:564] gpu pad cost 0.003915071487426758 s
DEBUG 01-05 09:19:35.628900.628900 mlpmodule.py:662]  experts func einsum cost 0.1055917739868164 s
DEBUG 01-05 09:19:35.628492.628492 mlpmodule.py:582] gpu group einsum cost 0.0005772113800048828 s
DEBUG 01-05 09:19:35.631841.631841 mlpmodule.py:611] gpu experts func einsum cost 0.012208700180053711 s
DEBUG 01-05 09:19:35.631175.631175 cuda_h.py:19] end gpu_experts cost 0.01240992546081543 seconds
DEBUG 01-05 09:19:35.631269.631269 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:35.635373.635373 client.py:127] Model loaded
DEBUG 01-05 09:19:35.635868.635868 cuda_h.py:19] end sllm_worker_task cost 0.021878480911254883 seconds
DEBUG 01-05 09:19:35.635161.635161 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0038123130798339844 seconds
DEBUG 01-05 09:19:35.636513.636513 cuda_h.py:19] end layer_moe_generate_8 cost 0.12153744697570801 seconds
DEBUG 01-05 09:19:35.636595.636595 lmp.py:214] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 09:19:35.636749.636749 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 09:19:35.636160.636160 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.636096.636096 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.641176.641176 cuda_h.py:19] end self_attn cost 0.004065752029418945 seconds
DEBUG 01-05 09:19:35.641094.641094 cuda_h.py:19] end iln_self_attn_paln cost 0.005106449127197266 seconds
DEBUG 01-05 09:19:35.641906.641906 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 09:19:35.641577.641577 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.642638.642638 cuda_h.py:19] end gate cost 0.0009601116180419922 seconds
DEBUG 01-05 09:19:35.642899.642899 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.643654.643654 lmp.py:361] 
DEBUG 01-05 09:19:35.643654.643654 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.643928.643928 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.643373.643373 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.643096.643096 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.643482.643482 lmp.py:365] 
DEBUG 01-05 09:19:35.643482.643482 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.643913.643913 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.643882.643882 lmp.py:372]   Expert 35 |     32 | CPU
DEBUG 01-05 09:19:35.643075.643075 lmp.py:372]   Expert  7 |     39 | CPU
DEBUG 01-05 09:19:35.643792.643792 lmp.py:372]   Expert  6 |     48 | CPU
DEBUG 01-05 09:19:35.643316.643316 lmp.py:372]   Expert 26 |     50 | CPU
DEBUG 01-05 09:19:35.643748.643748 lmp.py:372]   Expert  2 |     52 | CPU
DEBUG 01-05 09:19:35.644703.644703 lmp.py:372]   Expert  5 |     52 | CPU
DEBUG 01-05 09:19:35.644465.644465 lmp.py:372]   Expert 60 |     58 | CPU
DEBUG 01-05 09:19:35.644513.644513 lmp.py:372]   Expert 38 |     59 | CPU
DEBUG 01-05 09:19:35.644561.644561 lmp.py:372]   Expert 19 |     60 | CPU
DEBUG 01-05 09:19:35.644370.644370 lmp.py:372]   Expert 13 |     67 | CPU
DEBUG 01-05 09:19:35.644417.644417 lmp.py:372]   Expert 48 |     74 | CPU
DEBUG 01-05 09:19:35.644657.644657 lmp.py:372]   Expert 17 |     77 | CPU
DEBUG 01-05 09:19:35.644135.644135 lmp.py:372]   Expert 25 |     79 | CPU
DEBUG 01-05 09:19:35.644944.644944 lmp.py:372]   Expert 39 |     81 | CPU
DEBUG 01-05 09:19:35.644276.644276 lmp.py:372]   Expert 54 |     88 | CPU
DEBUG 01-05 09:19:35.644847.644847 lmp.py:372]   Expert 27 |     94 | CPU
DEBUG 01-05 09:19:35.644007.644007 lmp.py:372]   Expert 45 |     97 | CPU
DEBUG 01-05 09:19:35.644201.644201 lmp.py:372]   Expert 52 |    102 | CPU
DEBUG 01-05 09:19:35.644440.644440 lmp.py:372]   Expert 59 |    127 | CPU
DEBUG 01-05 09:19:35.644965.644965 lmp.py:372]   Expert 16 |    134 | CPU
DEBUG 01-05 09:19:35.644774.644774 lmp.py:372]   Expert 24 |    141 | CPU
DEBUG 01-05 09:19:35.644821.644821 lmp.py:372]   Expert 20 |    144 | CPU
DEBUG 01-05 09:19:35.644684.644684 lmp.py:372]   Expert 49 |    147 | CPU
DEBUG 01-05 09:19:35.644639.644639 lmp.py:372]   Expert 57 |    147 | CPU
DEBUG 01-05 09:19:35.644832.644832 lmp.py:372]   Expert 29 |    150 | CPU
DEBUG 01-05 09:19:35.644879.644879 lmp.py:372]   Expert 40 |    153 | CPU
DEBUG 01-05 09:19:35.644927.644927 lmp.py:372]   Expert 42 |    159 | CPU
DEBUG 01-05 09:19:35.644498.644498 lmp.py:372]   Expert 12 |    161 | CPU
DEBUG 01-05 09:19:35.644214.644214 lmp.py:372]   Expert 32 |    165 | CPU
DEBUG 01-05 09:19:35.644930.644930 lmp.py:372]   Expert 62 |    165 | CPU
DEBUG 01-05 09:19:35.644885.644885 lmp.py:372]   Expert 22 |    169 | CPU
DEBUG 01-05 09:19:35.644694.644694 lmp.py:372]   Expert 31 |    170 | CPU
DEBUG 01-05 09:19:35.644504.644504 lmp.py:372]   Expert 14 |    171 | GPU
DEBUG 01-05 09:19:35.645313.645313 lmp.py:372]   Expert 28 |    172 | GPU
DEBUG 01-05 09:19:35.645837.645837 lmp.py:372]   Expert 30 |    176 | GPU
DEBUG 01-05 09:19:35.645792.645792 lmp.py:372]   Expert 41 |    179 | GPU
DEBUG 01-05 09:19:35.645508.645508 lmp.py:372]   Expert 58 |    179 | GPU
DEBUG 01-05 09:19:35.645556.645556 lmp.py:372]   Expert 11 |    183 | GPU
DEBUG 01-05 09:19:35.645603.645603 lmp.py:372]   Expert  1 |    189 | GPU
DEBUG 01-05 09:19:35.645174.645174 lmp.py:372]   Expert 18 |    189 | GPU
DEBUG 01-05 09:19:35.645699.645699 lmp.py:372]   Expert 33 |    192 | GPU
DEBUG 01-05 09:19:35.645415.645415 lmp.py:372]   Expert 23 |    193 | GPU
DEBUG 01-05 09:19:35.645131.645131 lmp.py:372]   Expert 10 |    198 | GPU
DEBUG 01-05 09:19:35.645656.645656 lmp.py:372]   Expert 43 |    199 | GPU
DEBUG 01-05 09:19:35.645465.645465 lmp.py:372]   Expert  3 |    207 | GPU
DEBUG 01-05 09:19:35.645989.645989 lmp.py:372]   Expert 34 |    214 | GPU
DEBUG 01-05 09:19:35.645514.645514 lmp.py:372]   Expert 47 |    220 | GPU
DEBUG 01-05 09:19:35.645469.645469 lmp.py:372]   Expert 50 |    224 | GPU
DEBUG 01-05 09:19:35.645423.645423 lmp.py:372]   Expert 51 |    225 | GPU
DEBUG 01-05 09:19:35.645425.645425 lmp.py:372]   Expert  4 |    230 | GPU
DEBUG 01-05 09:19:35.645234.645234 lmp.py:372]   Expert 53 |    235 | GPU
DEBUG 01-05 09:19:35.645281.645281 lmp.py:372]   Expert 36 |    262 | GPU
DEBUG 01-05 09:19:35.645329.645329 lmp.py:372]   Expert 44 |    279 | GPU
DEBUG 01-05 09:19:35.645244.645244 lmp.py:372]   Expert  0 |    299 | GPU
DEBUG 01-05 09:19:35.645153.645153 lmp.py:372]   Expert 61 |    316 | GPU
DEBUG 01-05 09:19:35.645108.645108 lmp.py:372]   Expert 37 |    339 | GPU
DEBUG 01-05 09:19:35.645155.645155 lmp.py:372]   Expert 55 |    346 | GPU
DEBUG 01-05 09:19:35.645203.645203 lmp.py:372]   Expert  8 |    370 | GPU
DEBUG 01-05 09:19:35.645012.645012 lmp.py:372]   Expert  9 |    376 | GPU
DEBUG 01-05 09:19:35.645967.645967 lmp.py:372]   Expert 63 |    468 | GPU
DEBUG 01-05 09:19:35.646398.646398 lmp.py:372]   Expert 15 |    474 | GPU
DEBUG 01-05 09:19:35.646446.646446 lmp.py:372]   Expert 46 |    506 | GPU
DEBUG 01-05 09:19:35.646493.646493 lmp.py:372]   Expert 21 |    563 | GPU
DEBUG 01-05 09:19:35.646971.646971 lmp.py:372]   Expert 56 |    574 | GPU
DEBUG 01-05 09:19:35.646072.646072 lmp.py:373] 
DEBUG 01-05 09:19:35.646072.646072 lmp.py:373]   CPU total tokens: 3341 (27.2%)
DEBUG 01-05 09:19:35.646458.646458 lmp.py:374]   GPU total tokens: 8947 (72.8%)
DEBUG 01-05 09:19:35.646280.646280 cuda_h.py:19] end experts_map_get cost 0.003206491470336914 seconds
DEBUG 01-05 09:19:35.646997.646997 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.646788.646788 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.646941.646941 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.647633.647633 cuda_h.py:19] end allocate_cuda_memory cost 0.0004565715789794922 seconds
DEBUG 01-05 09:19:35.647675.647675 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.647147.647147 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.647585.647585 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.647957.647957 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e16e8e2-ff0c-4992-b8c1-69323c6eae94
DEBUG 01-05 09:19:35.647321.647321 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.649913.649913 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e16e8e2-ff0c-4992-b8c1-69323c6eae94
DEBUG 01-05 09:19:35.649379.649379 cuda_h.py:19] end load_into_gpu_async cost 0.0023741722106933594 seconds
DEBUG 01-05 09:19:35.649267.649267 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.649178.649178 cuda_h.py:19] end restore_tensors2 cost 0.00028204917907714844 seconds
DEBUG 01-05 09:19:35.649816.649816 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035593509674072266 seconds
DEBUG 01-05 09:19:35.652494.652494 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062923431396484375 seconds
DEBUG 01-05 09:19:35.652330.652330 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.652723.652723 lmp.py:419] 
DEBUG 01-05 09:19:35.652723.652723 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.652851.652851 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-05 09:19:35.652931.652931 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.664844.664844 mlpmodule.py:704] group tensors cost 0.011394023895263672 s
DEBUG 01-05 09:19:35.668908.668908 mlpmodule.py:742] pad cost 0.003002166748046875 s
DEBUG 01-05 09:19:35.668402.668402 mlpmodule.py:748] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-05 09:19:35.668888.668888 mlpmodule.py:753] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-05 09:19:35.681341.681341 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.682466.682466 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.682224.682224 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:19:35.682123.682123 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.702085.702085 mlpmodule.py:793] group einsum cost 0.03349184989929199 s
DEBUG 01-05 09:19:35.703705.703705 mlpmodule.py:801] cpy2cputensor cost 0.0007171630859375 s
DEBUG 01-05 09:19:35.742189.742189 cuda_h.py:19] end wait_cetm_experts cost 0.08992648124694824 seconds
DEBUG 01-05 09:19:35.742258.742258 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.743328.743328 cuda_h.py:19] end gpu_sexperts cost 0.0004668235778808594 seconds
DEBUG 01-05 09:19:35.743118.743118 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:19:35.743080.743080 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:19:35.743036.743036 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.4332275390625e-05 seconds
DEBUG 01-05 09:19:35.743269.743269 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.414817810058594e-05 seconds
DEBUG 01-05 09:19:35.743587.743587 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.743582.743582 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e16e8e2-ff0c-4992-b8c1-69323c6eae94
DEBUG 01-05 09:19:35.743477.743477 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.744128.744128 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.744061.744061 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.748769.748769 cuda_h.py:19] end allocate_cuda_memory cost 0.00439453125 seconds
INFO 01-05 09:19:35.749021.749021 client.py:127] Model loaded
DEBUG 01-05 09:19:35.749631.749631 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.749788.749788 cuda_h.py:19] end wait_experts cost 0.005751371383666992 seconds
DEBUG 01-05 09:19:35.749799.749799 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.749769.749769 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.749901.749901 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.750902.750902 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e93d09b-58cf-4aac-ab81-8fec4ae92f17
DEBUG 01-05 09:19:35.750983.750983 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.749117.749117 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.754837.754837 mlpmodule.py:531] gpu group tensors cost 0.0006213188171386719 s
INFO 01-05 09:19:35.755116.755116 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e93d09b-58cf-4aac-ab81-8fec4ae92f17
DEBUG 01-05 09:19:35.755249.755249 cuda_h.py:19] end load_into_gpu_async cost 0.005743741989135742 seconds
DEBUG 01-05 09:19:35.755695.755695 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.755637.755637 cuda_h.py:19] end restore_tensors2 cost 0.00016045570373535156 seconds
DEBUG 01-05 09:19:35.755886.755886 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011426687240600586 seconds
INFO 01-05 09:19:35.757594.757594 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e93d09b-58cf-4aac-ab81-8fec4ae92f17
DEBUG 01-05 09:19:35.758363.758363 mlpmodule.py:564] gpu pad cost 0.0037691593170166016 s
DEBUG 01-05 09:19:35.759793.759793 mlpmodule.py:662]  experts func einsum cost 0.10624146461486816 s
DEBUG 01-05 09:19:35.759263.759263 mlpmodule.py:582] gpu group einsum cost 0.0006542205810546875 s
DEBUG 01-05 09:19:35.762831.762831 mlpmodule.py:611] gpu experts func einsum cost 0.008176565170288086 s
DEBUG 01-05 09:19:35.762291.762291 cuda_h.py:19] end gpu_experts cost 0.012541055679321289 seconds
DEBUG 01-05 09:19:35.762140.762140 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:35.765784.765784 client.py:127] Model loaded
DEBUG 01-05 09:19:35.766087.766087 cuda_h.py:19] end sllm_worker_task cost 0.02193427085876465 seconds
DEBUG 01-05 09:19:35.766672.766672 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0037615299224853516 seconds
DEBUG 01-05 09:19:35.766632.766632 cuda_h.py:19] end layer_moe_generate_9 cost 0.1248776912689209 seconds
DEBUG 01-05 09:19:35.766036.766036 lmp.py:214] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 09:19:35.766945.766945 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 09:19:35.766833.766833 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.767028.767028 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.769656.769656 cuda_h.py:19] end self_attn cost 0.002477884292602539 seconds
DEBUG 01-05 09:19:35.770394.770394 cuda_h.py:19] end iln_self_attn_paln cost 0.003086566925048828 seconds
DEBUG 01-05 09:19:35.770760.770760 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 09:19:35.770431.770431 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.770080.770080 cuda_h.py:19] end gate cost 0.0005855560302734375 seconds
DEBUG 01-05 09:19:35.770718.770718 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.771324.771324 lmp.py:361] 
DEBUG 01-05 09:19:35.771324.771324 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.771842.771842 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.771491.771491 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.771803.771803 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.771970.771970 lmp.py:365] 
DEBUG 01-05 09:19:35.771970.771970 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.771136.771136 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.771501.771501 lmp.py:372]   Expert 34 |      6 | CPU
DEBUG 01-05 09:19:35.771144.771144 lmp.py:372]   Expert  3 |     21 | CPU
DEBUG 01-05 09:19:35.771071.771071 lmp.py:372]   Expert 14 |     22 | CPU
DEBUG 01-05 09:19:35.771999.771999 lmp.py:372]   Expert 61 |     23 | CPU
DEBUG 01-05 09:19:35.771688.771688 lmp.py:372]   Expert 48 |     43 | CPU
DEBUG 01-05 09:19:35.771855.771855 lmp.py:372]   Expert 47 |     46 | CPU
DEBUG 01-05 09:19:35.771259.771259 lmp.py:372]   Expert 32 |     48 | CPU
DEBUG 01-05 09:19:35.771472.771472 lmp.py:372]   Expert 55 |     49 | CPU
DEBUG 01-05 09:19:35.771161.771161 lmp.py:372]   Expert 27 |     65 | CPU
DEBUG 01-05 09:19:35.771612.771612 lmp.py:372]   Expert 15 |     66 | CPU
DEBUG 01-05 09:19:35.771063.771063 lmp.py:372]   Expert 13 |     70 | CPU
DEBUG 01-05 09:19:35.771275.771275 lmp.py:372]   Expert 12 |     74 | CPU
DEBUG 01-05 09:19:35.771726.771726 lmp.py:372]   Expert  7 |     81 | CPU
DEBUG 01-05 09:19:35.771938.771938 lmp.py:372]   Expert  6 |     83 | CPU
DEBUG 01-05 09:19:35.771674.771674 lmp.py:372]   Expert 19 |     84 | CPU
DEBUG 01-05 09:19:35.771886.771886 lmp.py:372]   Expert 44 |     89 | CPU
DEBUG 01-05 09:19:35.771622.771622 lmp.py:372]   Expert 56 |     97 | CPU
DEBUG 01-05 09:19:35.771027.771027 lmp.py:372]   Expert 54 |    100 | CPU
DEBUG 01-05 09:19:35.771908.771908 lmp.py:372]   Expert 50 |    102 | CPU
DEBUG 01-05 09:19:35.771882.771882 lmp.py:372]   Expert 46 |    109 | CPU
DEBUG 01-05 09:19:35.771333.771333 lmp.py:372]   Expert 38 |    110 | CPU
DEBUG 01-05 09:19:35.771545.771545 lmp.py:372]   Expert 26 |    111 | CPU
DEBUG 01-05 09:19:35.771281.771281 lmp.py:372]   Expert 28 |    116 | CPU
DEBUG 01-05 09:19:35.771494.771494 lmp.py:372]   Expert 37 |    118 | CPU
DEBUG 01-05 09:19:35.771229.771229 lmp.py:372]   Expert 20 |    120 | CPU
DEBUG 01-05 09:19:35.771442.771442 lmp.py:372]   Expert 62 |    127 | CPU
DEBUG 01-05 09:19:35.771131.771131 lmp.py:372]   Expert 43 |    140 | CPU
DEBUG 01-05 09:19:35.771820.771820 lmp.py:372]   Expert 35 |    141 | CPU
DEBUG 01-05 09:19:35.771033.771033 lmp.py:372]   Expert 60 |    146 | CPU
DEBUG 01-05 09:19:35.771245.771245 lmp.py:372]   Expert 36 |    151 | CPU
DEBUG 01-05 09:19:35.771219.771219 lmp.py:372]   Expert 29 |    158 | CPU
DEBUG 01-05 09:19:35.771670.771670 lmp.py:372]   Expert 52 |    158 | CPU
DEBUG 01-05 09:19:35.771121.771121 lmp.py:372]   Expert 45 |    162 | GPU
DEBUG 01-05 09:19:35.771095.771095 lmp.py:372]   Expert 25 |    167 | GPU
DEBUG 01-05 09:19:35.771069.771069 lmp.py:372]   Expert 41 |    173 | GPU
DEBUG 01-05 09:19:35.771282.771282 lmp.py:372]   Expert 17 |    180 | GPU
DEBUG 01-05 09:19:35.771448.771448 lmp.py:372]   Expert 22 |    180 | GPU
DEBUG 01-05 09:19:35.771422.771422 lmp.py:372]   Expert 24 |    183 | GPU
DEBUG 01-05 09:19:35.771634.771634 lmp.py:372]   Expert 51 |    185 | GPU
DEBUG 01-05 09:19:35.771085.771085 lmp.py:372]   Expert  2 |    188 | GPU
DEBUG 01-05 09:19:35.771536.771536 lmp.py:372]   Expert 63 |    191 | GPU
DEBUG 01-05 09:19:35.771510.771510 lmp.py:372]   Expert 42 |    208 | GPU
DEBUG 01-05 09:19:35.771484.771484 lmp.py:372]   Expert 57 |    211 | GPU
DEBUG 01-05 09:19:35.772458.772458 lmp.py:372]   Expert 59 |    228 | GPU
DEBUG 01-05 09:19:35.772909.772909 lmp.py:372]   Expert  5 |    232 | GPU
DEBUG 01-05 09:19:35.772883.772883 lmp.py:372]   Expert 21 |    237 | GPU
DEBUG 01-05 09:19:35.772095.772095 lmp.py:372]   Expert 53 |    237 | GPU
DEBUG 01-05 09:19:35.772308.772308 lmp.py:372]   Expert 31 |    244 | GPU
DEBUG 01-05 09:19:35.772474.772474 lmp.py:372]   Expert 18 |    254 | GPU
DEBUG 01-05 09:19:35.772879.772879 lmp.py:372]   Expert 30 |    258 | GPU
DEBUG 01-05 09:19:35.772330.772330 lmp.py:372]   Expert 39 |    268 | GPU
DEBUG 01-05 09:19:35.772065.772065 lmp.py:372]   Expert 16 |    279 | GPU
DEBUG 01-05 09:19:35.772516.772516 lmp.py:372]   Expert  8 |    291 | GPU
DEBUG 01-05 09:19:35.772728.772728 lmp.py:372]   Expert  9 |    299 | GPU
DEBUG 01-05 09:19:35.772703.772703 lmp.py:372]   Expert 10 |    311 | GPU
DEBUG 01-05 09:19:35.772630.772630 lmp.py:372]   Expert 49 |    335 | GPU
DEBUG 01-05 09:19:35.772796.772796 lmp.py:372]   Expert 33 |    370 | GPU
DEBUG 01-05 09:19:35.772247.772247 lmp.py:372]   Expert 23 |    377 | GPU
DEBUG 01-05 09:19:35.772698.772698 lmp.py:372]   Expert 40 |    425 | GPU
DEBUG 01-05 09:19:35.772911.772911 lmp.py:372]   Expert  0 |    447 | GPU
DEBUG 01-05 09:19:35.772123.772123 lmp.py:372]   Expert 58 |    511 | GPU
DEBUG 01-05 09:19:35.772336.772336 lmp.py:372]   Expert 11 |    569 | GPU
DEBUG 01-05 09:19:35.772071.772071 lmp.py:372]   Expert  4 |    603 | GPU
DEBUG 01-05 09:19:35.772522.772522 lmp.py:372]   Expert  1 |    611 | GPU
DEBUG 01-05 09:19:35.772688.772688 lmp.py:373] 
DEBUG 01-05 09:19:35.772688.772688 lmp.py:373]   CPU total tokens: 2874 (23.4%)
DEBUG 01-05 09:19:35.772570.772570 lmp.py:374]   GPU total tokens: 9414 (76.6%)
DEBUG 01-05 09:19:35.772610.772610 cuda_h.py:19] end experts_map_get cost 0.001506805419921875 seconds
DEBUG 01-05 09:19:35.772730.772730 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.772798.772798 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.772081.772081 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.772714.772714 cuda_h.py:19] end allocate_cuda_memory cost 0.00029397010803222656 seconds
DEBUG 01-05 09:19:35.772372.772372 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.773605.773605 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.773659.773659 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.773170.773170 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d716e37-73de-4cb3-bd2b-46d0ddf23022
DEBUG 01-05 09:19:35.773057.773057 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.775365.775365 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d716e37-73de-4cb3-bd2b-46d0ddf23022
DEBUG 01-05 09:19:35.775154.775154 cuda_h.py:19] end load_into_gpu_async cost 0.0023717880249023438 seconds
DEBUG 01-05 09:19:35.775619.775619 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.775491.775491 cuda_h.py:19] end restore_tensors2 cost 0.0003020763397216797 seconds
DEBUG 01-05 09:19:35.775691.775691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003304719924926758 seconds
DEBUG 01-05 09:19:35.778151.778151 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005999326705932617 seconds
DEBUG 01-05 09:19:35.778503.778503 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.778705.778705 lmp.py:419] 
DEBUG 01-05 09:19:35.778705.778705 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.778237.778237 cuda_h.py:19] end cpu_experts_submit cost 0.00012636184692382812 seconds
DEBUG 01-05 09:19:35.778317.778317 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.790840.790840 mlpmodule.py:704] group tensors cost 0.011876821517944336 s
DEBUG 01-05 09:19:35.792954.792954 mlpmodule.py:742] pad cost 0.0015141963958740234 s
DEBUG 01-05 09:19:35.793474.793474 mlpmodule.py:748] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-05 09:19:35.793801.793801 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-05 09:19:35.803387.803387 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.804949.804949 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.804800.804800 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 09:19:35.804023.804023 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.823507.823507 mlpmodule.py:793] group einsum cost 0.030500173568725586 s
DEBUG 01-05 09:19:35.824718.824718 mlpmodule.py:801] cpy2cputensor cost 0.0007700920104980469 s
DEBUG 01-05 09:19:35.864862.864862 cuda_h.py:19] end wait_cetm_experts cost 0.0860300064086914 seconds
DEBUG 01-05 09:19:35.864269.864269 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.865815.865815 cuda_h.py:19] end gpu_sexperts cost 0.0004661083221435547 seconds
DEBUG 01-05 09:19:35.865990.865990 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:19:35.865713.865713 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:19:35.865708.865708 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:19:35.865988.865988 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.842613220214844e-05 seconds
DEBUG 01-05 09:19:35.865399.865399 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.865778.865778 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d716e37-73de-4cb3-bd2b-46d0ddf23022
DEBUG 01-05 09:19:35.865666.865666 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.866179.866179 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.866164.866164 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.871999.871999 cuda_h.py:19] end allocate_cuda_memory cost 0.004649162292480469 seconds
INFO 01-05 09:19:35.871344.871344 client.py:127] Model loaded
DEBUG 01-05 09:19:35.871093.871093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.871965.871965 cuda_h.py:19] end wait_experts cost 0.00598597526550293 seconds
DEBUG 01-05 09:19:35.871207.871207 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.871086.871086 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.872635.872635 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.872186.872186 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.872561.872561 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 795ce35c-a138-402d-8a64-b6be860dc528
DEBUG 01-05 09:19:35.872906.872906 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:35.876745.876745 mlpmodule.py:531] gpu group tensors cost 0.004154205322265625 s
INFO 01-05 09:19:35.877835.877835 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 795ce35c-a138-402d-8a64-b6be860dc528
DEBUG 01-05 09:19:35.877403.877403 cuda_h.py:19] end load_into_gpu_async cost 0.005663394927978516 seconds
DEBUG 01-05 09:19:35.877201.877201 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.877331.877331 cuda_h.py:19] end restore_tensors2 cost 0.00016355514526367188 seconds
DEBUG 01-05 09:19:35.877082.877082 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011651754379272461 seconds
INFO 01-05 09:19:35.879784.879784 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 795ce35c-a138-402d-8a64-b6be860dc528
DEBUG 01-05 09:19:35.880703.880703 mlpmodule.py:564] gpu pad cost 0.003945827484130859 s
DEBUG 01-05 09:19:35.881202.881202 mlpmodule.py:662]  experts func einsum cost 0.10222744941711426 s
DEBUG 01-05 09:19:35.881729.881729 mlpmodule.py:582] gpu group einsum cost 0.0006334781646728516 s
DEBUG 01-05 09:19:35.884542.884542 mlpmodule.py:611] gpu experts func einsum cost 0.011954307556152344 s
DEBUG 01-05 09:19:35.884816.884816 cuda_h.py:19] end gpu_experts cost 0.01215052604675293 seconds
DEBUG 01-05 09:19:35.884533.884533 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:35.887258.887258 client.py:127] Model loaded
DEBUG 01-05 09:19:35.887038.887038 cuda_h.py:19] end sllm_worker_task cost 0.021719932556152344 seconds
DEBUG 01-05 09:19:35.888947.888947 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0037779808044433594 seconds
DEBUG 01-05 09:19:35.888472.888472 cuda_h.py:19] end layer_moe_generate_10 cost 0.11830687522888184 seconds
DEBUG 01-05 09:19:35.888308.888308 lmp.py:214] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 09:19:35.889782.889782 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 09:19:35.889400.889400 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:35.889067.889067 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:35.891846.891846 cuda_h.py:19] end self_attn cost 0.002448558807373047 seconds
DEBUG 01-05 09:19:35.892976.892976 cuda_h.py:19] end iln_self_attn_paln cost 0.0030946731567382812 seconds
DEBUG 01-05 09:19:35.892057.892057 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 09:19:35.892357.892357 cuda_h.py:10] start gate
DEBUG 01-05 09:19:35.893868.893868 cuda_h.py:19] end gate cost 0.0005867481231689453 seconds
DEBUG 01-05 09:19:35.893505.893505 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:35.893058.893058 lmp.py:361] 
DEBUG 01-05 09:19:35.893058.893058 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:35.893814.893814 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:35.893179.893179 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:35.893445.893445 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:35.893850.893850 lmp.py:365] 
DEBUG 01-05 09:19:35.893850.893850 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:35.893254.893254 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:35.893096.893096 lmp.py:372]   Expert 35 |     16 | CPU
DEBUG 01-05 09:19:35.893977.893977 lmp.py:372]   Expert 39 |     21 | CPU
DEBUG 01-05 09:19:35.893143.893143 lmp.py:372]   Expert 19 |     22 | CPU
DEBUG 01-05 09:19:35.893310.893310 lmp.py:372]   Expert 16 |     27 | CPU
DEBUG 01-05 09:19:35.893953.893953 lmp.py:372]   Expert 59 |     34 | CPU
DEBUG 01-05 09:19:35.893072.893072 lmp.py:372]   Expert 49 |     44 | CPU
DEBUG 01-05 09:19:35.893477.893477 lmp.py:372]   Expert 41 |     51 | CPU
DEBUG 01-05 09:19:35.893405.893405 lmp.py:372]   Expert 17 |     62 | CPU
DEBUG 01-05 09:19:35.893571.893571 lmp.py:372]   Expert  5 |     71 | CPU
DEBUG 01-05 09:19:35.893022.893022 lmp.py:372]   Expert  8 |     72 | CPU
DEBUG 01-05 09:19:35.893473.893473 lmp.py:372]   Expert 15 |     75 | CPU
DEBUG 01-05 09:19:35.893923.893923 lmp.py:372]   Expert  3 |     77 | CPU
DEBUG 01-05 09:19:35.893090.893090 lmp.py:372]   Expert  7 |     78 | CPU
DEBUG 01-05 09:19:35.893256.893256 lmp.py:372]   Expert 23 |     78 | CPU
DEBUG 01-05 09:19:35.893945.893945 lmp.py:372]   Expert 38 |     82 | CPU
DEBUG 01-05 09:19:35.893634.893634 lmp.py:372]   Expert  6 |     83 | CPU
DEBUG 01-05 09:19:35.893608.893608 lmp.py:372]   Expert  0 |     88 | CPU
DEBUG 01-05 09:19:35.893059.893059 lmp.py:372]   Expert  4 |     97 | CPU
DEBUG 01-05 09:19:35.893510.893510 lmp.py:372]   Expert 44 |    100 | CPU
DEBUG 01-05 09:19:35.893723.893723 lmp.py:372]   Expert 46 |    101 | CPU
DEBUG 01-05 09:19:35.893935.893935 lmp.py:372]   Expert 10 |    104 | CPU
DEBUG 01-05 09:19:35.893148.893148 lmp.py:372]   Expert 63 |    105 | CPU
DEBUG 01-05 09:19:35.893598.893598 lmp.py:372]   Expert 40 |    110 | CPU
DEBUG 01-05 09:19:35.893811.893811 lmp.py:372]   Expert 32 |    115 | CPU
DEBUG 01-05 09:19:35.893023.893023 lmp.py:372]   Expert 62 |    115 | CPU
DEBUG 01-05 09:19:35.893997.893997 lmp.py:372]   Expert 52 |    118 | CPU
DEBUG 01-05 09:19:35.893448.893448 lmp.py:372]   Expert 60 |    120 | CPU
DEBUG 01-05 09:19:35.893661.893661 lmp.py:372]   Expert 27 |    123 | CPU
DEBUG 01-05 09:19:35.893396.893396 lmp.py:372]   Expert  1 |    136 | CPU
DEBUG 01-05 09:19:35.893609.893609 lmp.py:372]   Expert 48 |    138 | CPU
DEBUG 01-05 09:19:35.894583.894583 lmp.py:372]   Expert 50 |    140 | CPU
DEBUG 01-05 09:19:35.894557.894557 lmp.py:372]   Expert 25 |    143 | CPU
DEBUG 01-05 09:19:35.894531.894531 lmp.py:372]   Expert 31 |    143 | GPU
DEBUG 01-05 09:19:35.894267.894267 lmp.py:372]   Expert 20 |    149 | GPU
DEBUG 01-05 09:19:35.894241.894241 lmp.py:372]   Expert 36 |    153 | GPU
DEBUG 01-05 09:19:35.894453.894453 lmp.py:372]   Expert 57 |    167 | GPU
DEBUG 01-05 09:19:35.894189.894189 lmp.py:372]   Expert 61 |    176 | GPU
DEBUG 01-05 09:19:35.894878.894878 lmp.py:372]   Expert 51 |    179 | GPU
DEBUG 01-05 09:19:35.894090.894090 lmp.py:372]   Expert 13 |    180 | GPU
DEBUG 01-05 09:19:35.894065.894065 lmp.py:372]   Expert 18 |    194 | GPU
DEBUG 01-05 09:19:35.894039.894039 lmp.py:372]   Expert 56 |    196 | GPU
DEBUG 01-05 09:19:35.894013.894013 lmp.py:372]   Expert 42 |    198 | GPU
DEBUG 01-05 09:19:35.894225.894225 lmp.py:372]   Expert  2 |    218 | GPU
DEBUG 01-05 09:19:35.894438.894438 lmp.py:372]   Expert 26 |    224 | GPU
DEBUG 01-05 09:19:35.894173.894173 lmp.py:372]   Expert 43 |    230 | GPU
DEBUG 01-05 09:19:35.894386.894386 lmp.py:372]   Expert 47 |    256 | GPU
DEBUG 01-05 09:19:35.894360.894360 lmp.py:372]   Expert 33 |    261 | GPU
DEBUG 01-05 09:19:35.894095.894095 lmp.py:372]   Expert 53 |    275 | GPU
DEBUG 01-05 09:19:35.894546.894546 lmp.py:372]   Expert 55 |    286 | GPU
DEBUG 01-05 09:19:35.894474.894474 lmp.py:372]   Expert 12 |    292 | GPU
DEBUG 01-05 09:19:35.894640.894640 lmp.py:372]   Expert 45 |    307 | GPU
DEBUG 01-05 09:19:35.894614.894614 lmp.py:372]   Expert 14 |    314 | GPU
DEBUG 01-05 09:19:35.894065.894065 lmp.py:372]   Expert 58 |    326 | GPU
DEBUG 01-05 09:19:35.894277.894277 lmp.py:372]   Expert 29 |    327 | GPU
DEBUG 01-05 09:19:35.894490.894490 lmp.py:372]   Expert 24 |    328 | GPU
DEBUG 01-05 09:19:35.894464.894464 lmp.py:372]   Expert 37 |    346 | GPU
DEBUG 01-05 09:19:35.894676.894676 lmp.py:372]   Expert 34 |    353 | GPU
DEBUG 01-05 09:19:35.894650.894650 lmp.py:372]   Expert 54 |    369 | GPU
DEBUG 01-05 09:19:35.894340.894340 lmp.py:372]   Expert 21 |    378 | GPU
DEBUG 01-05 09:19:35.894267.894267 lmp.py:372]   Expert  9 |    395 | GPU
DEBUG 01-05 09:19:35.894718.894718 lmp.py:372]   Expert 28 |    396 | GPU
DEBUG 01-05 09:19:35.894692.894692 lmp.py:372]   Expert 11 |    438 | GPU
DEBUG 01-05 09:19:35.894666.894666 lmp.py:372]   Expert 22 |    457 | GPU
DEBUG 01-05 09:19:35.894640.894640 lmp.py:372]   Expert 30 |   1031 | GPU
DEBUG 01-05 09:19:35.894568.894568 lmp.py:373] 
DEBUG 01-05 09:19:35.894568.894568 lmp.py:373]   CPU total tokens: 2746 (22.3%)
DEBUG 01-05 09:19:35.894734.894734 lmp.py:374]   GPU total tokens: 9542 (77.7%)
DEBUG 01-05 09:19:35.894384.894384 cuda_h.py:19] end experts_map_get cost 0.0014977455139160156 seconds
DEBUG 01-05 09:19:35.894504.894504 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:35.894141.894141 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.894378.894378 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.895343.895343 cuda_h.py:19] end allocate_cuda_memory cost 0.0003275871276855469 seconds
DEBUG 01-05 09:19:35.895955.895955 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.895665.895665 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.895719.895719 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.895230.895230 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3136e18f-9b73-4bb8-ad24-afe17aefdaee
DEBUG 01-05 09:19:35.895985.895985 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:35.897578.897578 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3136e18f-9b73-4bb8-ad24-afe17aefdaee
DEBUG 01-05 09:19:35.897825.897825 cuda_h.py:19] end load_into_gpu_async cost 0.002222299575805664 seconds
DEBUG 01-05 09:19:35.897495.897495 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:35.897443.897443 cuda_h.py:19] end restore_tensors2 cost 0.0003807544708251953 seconds
DEBUG 01-05 09:19:35.898055.898055 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003316640853881836 seconds
DEBUG 01-05 09:19:35.901691.901691 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007328987121582031 seconds
DEBUG 01-05 09:19:35.902661.902661 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:35.902069.902069 lmp.py:419] 
DEBUG 01-05 09:19:35.902069.902069 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:35.902013.902013 cuda_h.py:19] end cpu_experts_submit cost 0.00017333030700683594 seconds
DEBUG 01-05 09:19:35.902935.902935 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:35.915852.915852 mlpmodule.py:704] group tensors cost 0.013211488723754883 s
DEBUG 01-05 09:19:35.918930.918930 mlpmodule.py:742] pad cost 0.001497030258178711 s
DEBUG 01-05 09:19:35.918749.918749 mlpmodule.py:748] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-05 09:19:35.918712.918712 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-05 09:19:35.928692.928692 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:35.929678.929678 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:35.929059.929059 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 09:19:35.929209.929209 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:35.948135.948135 mlpmodule.py:793] group einsum cost 0.029978275299072266 s
DEBUG 01-05 09:19:35.949721.949721 mlpmodule.py:801] cpy2cputensor cost 0.0006701946258544922 s
DEBUG 01-05 09:19:35.988068.988068 cuda_h.py:19] end wait_cetm_experts cost 0.08620214462280273 seconds
DEBUG 01-05 09:19:35.988614.988614 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:35.989585.989585 cuda_h.py:19] end gpu_sexperts cost 0.00046253204345703125 seconds
DEBUG 01-05 09:19:35.989567.989567 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:19:35.989098.989098 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:19:35.989100.989100 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.361701965332031e-05 seconds
DEBUG 01-05 09:19:35.989618.989618 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.176399230957031e-05 seconds
DEBUG 01-05 09:19:35.989705.989705 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:35.989037.989037 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3136e18f-9b73-4bb8-ad24-afe17aefdaee
DEBUG 01-05 09:19:35.989628.989628 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:35.989432.989432 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:35.990491.990491 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:35.995275.995275 cuda_h.py:19] end allocate_cuda_memory cost 0.005308389663696289 seconds
INFO 01-05 09:19:35.995481.995481 client.py:127] Model loaded
DEBUG 01-05 09:19:35.995898.995898 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:35.996533.996533 cuda_h.py:19] end wait_experts cost 0.006668567657470703 seconds
DEBUG 01-05 09:19:35.996245.996245 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:35.996785.996785 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:35.996494.996494 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:35.997964.997964 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:35.997081.997081 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4e8ff46-d7f0-4f5c-a494-36b1a39390a2
DEBUG 01-05 09:19:35.997227.997227 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.001870.001870 mlpmodule.py:531] gpu group tensors cost 0.004807233810424805 s
DEBUG 01-05 09:19:36.006428.006428 mlpmodule.py:662]  experts func einsum cost 0.1042032241821289 s
INFO 01-05 09:19:36.007934.007934 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4e8ff46-d7f0-4f5c-a494-36b1a39390a2
DEBUG 01-05 09:19:36.007273.007273 cuda_h.py:19] end load_into_gpu_async cost 0.011713743209838867 seconds
DEBUG 01-05 09:19:36.008501.008501 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.008456.008456 cuda_h.py:19] end restore_tensors2 cost 0.00016355514526367188 seconds
DEBUG 01-05 09:19:36.008004.008004 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01834273338317871 seconds
INFO 01-05 09:19:36.009917.009917 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4e8ff46-d7f0-4f5c-a494-36b1a39390a2
DEBUG 01-05 09:19:36.010545.010545 mlpmodule.py:564] gpu pad cost 0.008942604064941406 s
DEBUG 01-05 09:19:36.012306.012306 mlpmodule.py:582] gpu group einsum cost 0.001630544662475586 s
DEBUG 01-05 09:19:36.015721.015721 mlpmodule.py:611] gpu experts func einsum cost 0.01854562759399414 s
DEBUG 01-05 09:19:36.015651.015651 cuda_h.py:19] end gpu_experts cost 0.018732786178588867 seconds
DEBUG 01-05 09:19:36.015076.015076 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:36.019307.019307 client.py:127] Model loaded
DEBUG 01-05 09:19:36.019836.019836 cuda_h.py:19] end sllm_worker_task cost 0.029494047164916992 seconds
DEBUG 01-05 09:19:36.019981.019981 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004226207733154297 seconds
DEBUG 01-05 09:19:36.019391.019391 cuda_h.py:19] end layer_moe_generate_11 cost 0.127579927444458 seconds
DEBUG 01-05 09:19:36.020757.020757 lmp.py:214] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 09:19:36.020342.020342 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 09:19:36.020322.020322 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.020094.020094 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.023602.023602 cuda_h.py:19] end self_attn cost 0.0024504661560058594 seconds
DEBUG 01-05 09:19:36.023453.023453 cuda_h.py:19] end iln_self_attn_paln cost 0.0030846595764160156 seconds
DEBUG 01-05 09:19:36.023535.023535 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 09:19:36.023589.023589 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.024776.024776 cuda_h.py:19] end gate cost 0.0005948543548583984 seconds
DEBUG 01-05 09:19:36.024413.024413 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.024967.024967 lmp.py:361] 
DEBUG 01-05 09:19:36.024967.024967 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.024015.024015 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.024857.024857 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.024884.024884 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.024004.024004 lmp.py:365] 
DEBUG 01-05 09:19:36.024004.024004 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.024508.024508 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.024396.024396 lmp.py:372]   Expert 51 |     10 | CPU
DEBUG 01-05 09:19:36.024039.024039 lmp.py:372]   Expert 63 |     19 | CPU
DEBUG 01-05 09:19:36.024967.024967 lmp.py:372]   Expert 11 |     26 | CPU
DEBUG 01-05 09:19:36.024417.024417 lmp.py:372]   Expert 22 |     26 | CPU
DEBUG 01-05 09:19:36.024014.024014 lmp.py:372]   Expert 34 |     26 | CPU
DEBUG 01-05 09:19:36.024227.024227 lmp.py:372]   Expert 12 |     30 | CPU
DEBUG 01-05 09:19:36.024393.024393 lmp.py:372]   Expert 47 |     30 | CPU
DEBUG 01-05 09:19:36.024559.024559 lmp.py:372]   Expert 16 |     31 | CPU
DEBUG 01-05 09:19:36.024248.024248 lmp.py:372]   Expert  4 |     41 | CPU
DEBUG 01-05 09:19:36.024699.024699 lmp.py:372]   Expert 44 |     43 | CPU
DEBUG 01-05 09:19:36.024296.024296 lmp.py:372]   Expert  0 |     54 | CPU
DEBUG 01-05 09:19:36.024747.024747 lmp.py:372]   Expert 29 |     62 | CPU
DEBUG 01-05 09:19:36.024721.024721 lmp.py:372]   Expert 27 |     63 | CPU
DEBUG 01-05 09:19:36.024695.024695 lmp.py:372]   Expert 32 |     66 | CPU
DEBUG 01-05 09:19:36.024907.024907 lmp.py:372]   Expert 13 |     75 | CPU
DEBUG 01-05 09:19:36.024881.024881 lmp.py:372]   Expert 41 |     84 | CPU
DEBUG 01-05 09:19:36.024855.024855 lmp.py:372]   Expert  8 |     85 | CPU
DEBUG 01-05 09:19:36.024352.024352 lmp.py:372]   Expert 37 |     87 | CPU
DEBUG 01-05 09:19:36.024280.024280 lmp.py:372]   Expert 23 |     92 | CPU
DEBUG 01-05 09:19:36.025208.025208 lmp.py:372]   Expert 49 |     95 | CPU
DEBUG 01-05 09:19:36.025612.025612 lmp.py:372]   Expert 21 |    104 | CPU
DEBUG 01-05 09:19:36.025779.025779 lmp.py:372]   Expert  2 |    107 | CPU
DEBUG 01-05 09:19:36.025991.025991 lmp.py:372]   Expert 43 |    112 | CPU
DEBUG 01-05 09:19:36.025488.025488 lmp.py:372]   Expert  3 |    126 | CPU
DEBUG 01-05 09:19:36.025462.025462 lmp.py:372]   Expert 39 |    138 | CPU
DEBUG 01-05 09:19:36.025198.025198 lmp.py:372]   Expert 55 |    139 | CPU
DEBUG 01-05 09:19:36.025841.025841 lmp.py:372]   Expert 62 |    139 | CPU
DEBUG 01-05 09:19:36.025292.025292 lmp.py:372]   Expert 30 |    143 | CPU
DEBUG 01-05 09:19:36.025458.025458 lmp.py:372]   Expert  7 |    150 | CPU
DEBUG 01-05 09:19:36.025147.025147 lmp.py:372]   Expert 14 |    151 | CPU
DEBUG 01-05 09:19:36.025360.025360 lmp.py:372]   Expert 61 |    159 | CPU
DEBUG 01-05 09:19:36.025857.025857 lmp.py:372]   Expert 42 |    161 | CPU
DEBUG 01-05 09:19:36.025023.025023 lmp.py:372]   Expert 58 |    169 | GPU
DEBUG 01-05 09:19:36.025712.025712 lmp.py:372]   Expert 45 |    178 | GPU
DEBUG 01-05 09:19:36.025686.025686 lmp.py:372]   Expert 18 |    184 | GPU
DEBUG 01-05 09:19:36.025660.025660 lmp.py:372]   Expert 53 |    185 | GPU
DEBUG 01-05 09:19:36.025396.025396 lmp.py:372]   Expert 38 |    194 | GPU
DEBUG 01-05 09:19:36.025893.025893 lmp.py:372]   Expert 31 |    197 | GPU
DEBUG 01-05 09:19:36.025059.025059 lmp.py:372]   Expert 35 |    199 | GPU
DEBUG 01-05 09:19:36.025226.025226 lmp.py:372]   Expert  5 |    202 | GPU
DEBUG 01-05 09:19:36.025392.025392 lmp.py:372]   Expert  6 |    211 | GPU
DEBUG 01-05 09:19:36.025796.025796 lmp.py:372]   Expert 17 |    221 | GPU
DEBUG 01-05 09:19:36.025532.025532 lmp.py:372]   Expert  1 |    233 | GPU
DEBUG 01-05 09:19:36.025744.025744 lmp.py:372]   Expert 19 |    237 | GPU
DEBUG 01-05 09:19:36.025718.025718 lmp.py:372]   Expert 50 |    238 | GPU
DEBUG 01-05 09:19:36.025216.025216 lmp.py:372]   Expert 46 |    239 | GPU
DEBUG 01-05 09:19:36.025382.025382 lmp.py:372]   Expert 20 |    244 | GPU
DEBUG 01-05 09:19:36.025071.025071 lmp.py:372]   Expert 57 |    256 | GPU
DEBUG 01-05 09:19:36.025283.025283 lmp.py:372]   Expert 59 |    282 | GPU
DEBUG 01-05 09:19:36.025019.025019 lmp.py:372]   Expert 52 |    285 | GPU
DEBUG 01-05 09:19:36.025185.025185 lmp.py:372]   Expert 26 |    286 | GPU
DEBUG 01-05 09:19:36.025113.025113 lmp.py:372]   Expert 54 |    304 | GPU
DEBUG 01-05 09:19:36.025849.025849 lmp.py:372]   Expert 48 |    313 | GPU
DEBUG 01-05 09:19:36.025968.025968 lmp.py:372]   Expert 60 |    315 | GPU
DEBUG 01-05 09:19:36.025704.025704 lmp.py:372]   Expert 25 |    316 | GPU
DEBUG 01-05 09:19:36.025916.025916 lmp.py:372]   Expert 28 |    316 | GPU
DEBUG 01-05 09:19:36.025414.025414 lmp.py:372]   Expert 36 |    343 | GPU
DEBUG 01-05 09:19:36.025388.025388 lmp.py:372]   Expert 24 |    350 | GPU
DEBUG 01-05 09:19:36.025044.025044 lmp.py:372]   Expert 40 |    379 | GPU
DEBUG 01-05 09:19:36.025780.025780 lmp.py:372]   Expert 33 |    412 | GPU
DEBUG 01-05 09:19:36.025231.025231 lmp.py:372]   Expert  9 |    450 | GPU
DEBUG 01-05 09:19:36.025920.025920 lmp.py:372]   Expert 15 |    545 | GPU
DEBUG 01-05 09:19:36.025417.025417 lmp.py:372]   Expert 56 |    564 | GPU
DEBUG 01-05 09:19:36.025915.025915 lmp.py:372]   Expert 10 |    767 | GPU
DEBUG 01-05 09:19:36.025557.025557 lmp.py:373] 
DEBUG 01-05 09:19:36.025557.025557 lmp.py:373]   CPU total tokens: 2674 (21.8%)
DEBUG 01-05 09:19:36.025724.025724 lmp.py:374]   GPU total tokens: 9614 (78.2%)
DEBUG 01-05 09:19:36.025420.025420 cuda_h.py:19] end experts_map_get cost 0.0015566349029541016 seconds
DEBUG 01-05 09:19:36.025109.025109 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.025793.025793 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.026990.026990 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.026057.026057 cuda_h.py:19] end allocate_cuda_memory cost 0.0001914501190185547 seconds
DEBUG 01-05 09:19:36.026258.026258 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.026968.026968 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.026360.026360 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.026394.026394 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b9725a7-3169-4b77-aad9-30d0fc9cfbcd
DEBUG 01-05 09:19:36.026890.026890 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.028996.028996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b9725a7-3169-4b77-aad9-30d0fc9cfbcd
DEBUG 01-05 09:19:36.028786.028786 cuda_h.py:19] end load_into_gpu_async cost 0.0022895336151123047 seconds
DEBUG 01-05 09:19:36.028251.028251 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.028785.028785 cuda_h.py:19] end restore_tensors2 cost 0.0002961158752441406 seconds
DEBUG 01-05 09:19:36.029892.029892 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003141164779663086 seconds
DEBUG 01-05 09:19:36.031794.031794 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005780458450317383 seconds
DEBUG 01-05 09:19:36.031861.031861 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.031440.031440 lmp.py:419] 
DEBUG 01-05 09:19:36.031440.031440 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.031661.031661 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-05 09:19:36.031384.031384 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.043642.043642 mlpmodule.py:704] group tensors cost 0.01190328598022461 s
DEBUG 01-05 09:19:36.046850.046850 mlpmodule.py:742] pad cost 0.0015017986297607422 s
DEBUG 01-05 09:19:36.046941.046941 mlpmodule.py:748] create cpu tensor cost 5.555152893066406e-05 s
DEBUG 01-05 09:19:36.046996.046996 mlpmodule.py:753] move to cpu cost 4.363059997558594e-05 s
DEBUG 01-05 09:19:36.057753.057753 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.057454.057454 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.057166.057166 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 09:19:36.057197.057197 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.077309.077309 mlpmodule.py:793] group einsum cost 0.03063201904296875 s
DEBUG 01-05 09:19:36.078320.078320 mlpmodule.py:801] cpy2cputensor cost 0.0007250308990478516 s
DEBUG 01-05 09:19:36.118977.118977 cuda_h.py:19] end wait_cetm_experts cost 0.08627200126647949 seconds
DEBUG 01-05 09:19:36.118239.118239 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.118547.118547 cuda_h.py:19] end gpu_sexperts cost 0.00046753883361816406 seconds
DEBUG 01-05 09:19:36.118198.118198 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:19:36.118729.118729 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:19:36.118301.118301 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.314018249511719e-05 seconds
DEBUG 01-05 09:19:36.119295.119295 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.176399230957031e-05 seconds
DEBUG 01-05 09:19:36.119184.119184 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.119609.119609 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b9725a7-3169-4b77-aad9-30d0fc9cfbcd
DEBUG 01-05 09:19:36.119914.119914 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.119089.119089 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.119181.119181 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.127421.127421 cuda_h.py:19] end allocate_cuda_memory cost 0.007254362106323242 seconds
INFO 01-05 09:19:36.127746.127746 client.py:127] Model loaded
DEBUG 01-05 09:19:36.127282.127282 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.127724.127724 cuda_h.py:19] end wait_experts cost 0.008563756942749023 seconds
DEBUG 01-05 09:19:36.127336.127336 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.127307.127307 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.128857.128857 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.128315.128315 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.128048.128048 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cf9ed20b-fe09-436a-8c02-5095e0e74760
DEBUG 01-05 09:19:36.129585.129585 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.133009.133009 mlpmodule.py:531] gpu group tensors cost 0.005836963653564453 s
INFO 01-05 09:19:36.135458.135458 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cf9ed20b-fe09-436a-8c02-5095e0e74760
DEBUG 01-05 09:19:36.135425.135425 cuda_h.py:19] end load_into_gpu_async cost 0.00817728042602539 seconds
DEBUG 01-05 09:19:36.136925.136925 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.136411.136411 cuda_h.py:19] end restore_tensors2 cost 0.0001647472381591797 seconds
DEBUG 01-05 09:19:36.136349.136349 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01675701141357422 seconds
DEBUG 01-05 09:19:36.136201.136201 mlpmodule.py:564] gpu pad cost 0.0024166107177734375 s
INFO 01-05 09:19:36.137782.137782 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cf9ed20b-fe09-436a-8c02-5095e0e74760
DEBUG 01-05 09:19:36.138020.138020 mlpmodule.py:582] gpu group einsum cost 0.0017688274383544922 s
DEBUG 01-05 09:19:36.140130.140130 mlpmodule.py:662]  experts func einsum cost 0.10837912559509277 s
DEBUG 01-05 09:19:36.141726.141726 mlpmodule.py:611] gpu experts func einsum cost 0.013397693634033203 s
DEBUG 01-05 09:19:36.141988.141988 cuda_h.py:19] end gpu_experts cost 0.013622760772705078 seconds
DEBUG 01-05 09:19:36.141989.141989 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:36.144524.144524 client.py:127] Model loaded
DEBUG 01-05 09:19:36.144827.144827 cuda_h.py:19] end sllm_worker_task cost 0.025037050247192383 seconds
DEBUG 01-05 09:19:36.144051.144051 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0029740333557128906 seconds
DEBUG 01-05 09:19:36.144449.144449 cuda_h.py:19] end layer_moe_generate_12 cost 0.12142252922058105 seconds
DEBUG 01-05 09:19:36.145985.145985 lmp.py:214] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 09:19:36.145331.145331 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 09:19:36.145173.145173 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.145083.145083 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.148697.148697 cuda_h.py:19] end self_attn cost 0.002465486526489258 seconds
DEBUG 01-05 09:19:36.148753.148753 cuda_h.py:19] end iln_self_attn_paln cost 0.0030651092529296875 seconds
DEBUG 01-05 09:19:36.148842.148842 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 09:19:36.148433.148433 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.149374.149374 cuda_h.py:19] end gate cost 0.0005862712860107422 seconds
DEBUG 01-05 09:19:36.149535.149535 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.149386.149386 lmp.py:361] 
DEBUG 01-05 09:19:36.149386.149386 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.149858.149858 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.149984.149984 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.149250.149250 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.149038.149038 lmp.py:365] 
DEBUG 01-05 09:19:36.149038.149038 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.149443.149443 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.149331.149331 lmp.py:372]   Expert 53 |     11 | CPU
DEBUG 01-05 09:19:36.149974.149974 lmp.py:372]   Expert  6 |     12 | CPU
DEBUG 01-05 09:19:36.149617.149617 lmp.py:372]   Expert 19 |     20 | CPU
DEBUG 01-05 09:19:36.149783.149783 lmp.py:372]   Expert 50 |     24 | CPU
DEBUG 01-05 09:19:36.149857.149857 lmp.py:372]   Expert 26 |     36 | CPU
DEBUG 01-05 09:19:36.149784.149784 lmp.py:372]   Expert  0 |     50 | CPU
DEBUG 01-05 09:19:36.149997.149997 lmp.py:372]   Expert  2 |     52 | CPU
DEBUG 01-05 09:19:36.149686.149686 lmp.py:372]   Expert  8 |     57 | CPU
DEBUG 01-05 09:19:36.149137.149137 lmp.py:372]   Expert 12 |     62 | CPU
DEBUG 01-05 09:19:36.149588.149588 lmp.py:372]   Expert 31 |     83 | CPU
DEBUG 01-05 09:19:36.149185.149185 lmp.py:372]   Expert 16 |     86 | CPU
DEBUG 01-05 09:19:36.149828.149828 lmp.py:372]   Expert 20 |     91 | CPU
DEBUG 01-05 09:19:36.149232.149232 lmp.py:372]   Expert 40 |     95 | CPU
DEBUG 01-05 09:19:36.149683.149683 lmp.py:372]   Expert 30 |     97 | CPU
DEBUG 01-05 09:19:36.149896.149896 lmp.py:372]   Expert 32 |     97 | CPU
DEBUG 01-05 09:19:36.149585.149585 lmp.py:372]   Expert 28 |    112 | CPU
DEBUG 01-05 09:19:36.149989.149989 lmp.py:372]   Expert 35 |    119 | CPU
DEBUG 01-05 09:19:36.149963.149963 lmp.py:372]   Expert 57 |    120 | CPU
DEBUG 01-05 09:19:36.149937.149937 lmp.py:372]   Expert 48 |    122 | CPU
DEBUG 01-05 09:19:36.149627.149627 lmp.py:372]   Expert 63 |    124 | CPU
DEBUG 01-05 09:19:36.149031.149031 lmp.py:372]   Expert 13 |    125 | CPU
DEBUG 01-05 09:19:36.149151.149151 lmp.py:372]   Expert 61 |    126 | CPU
DEBUG 01-05 09:19:36.149840.149840 lmp.py:372]   Expert 34 |    132 | CPU
DEBUG 01-05 09:19:36.149053.149053 lmp.py:372]   Expert 18 |    134 | CPU
DEBUG 01-05 09:19:36.149504.149504 lmp.py:372]   Expert  5 |    136 | CPU
DEBUG 01-05 09:19:36.149955.149955 lmp.py:372]   Expert 60 |    136 | CPU
DEBUG 01-05 09:19:36.149690.149690 lmp.py:372]   Expert 11 |    141 | CPU
DEBUG 01-05 09:19:36.150095.150095 lmp.py:372]   Expert 52 |    151 | CPU
DEBUG 01-05 09:19:36.150499.150499 lmp.py:372]   Expert 45 |    154 | CPU
DEBUG 01-05 09:19:36.150904.150904 lmp.py:372]   Expert  9 |    155 | CPU
DEBUG 01-05 09:19:36.150116.150116 lmp.py:372]   Expert 24 |    159 | CPU
DEBUG 01-05 09:19:36.150090.150090 lmp.py:372]   Expert 58 |    159 | CPU
DEBUG 01-05 09:19:36.150541.150541 lmp.py:372]   Expert 42 |    172 | GPU
DEBUG 01-05 09:19:36.150661.150661 lmp.py:372]   Expert  3 |    176 | GPU
DEBUG 01-05 09:19:36.150112.150112 lmp.py:372]   Expert 25 |    180 | GPU
DEBUG 01-05 09:19:36.150086.150086 lmp.py:372]   Expert 37 |    185 | GPU
DEBUG 01-05 09:19:36.150299.150299 lmp.py:372]   Expert 46 |    207 | GPU
DEBUG 01-05 09:19:36.150988.150988 lmp.py:372]   Expert  4 |    210 | GPU
DEBUG 01-05 09:19:36.150677.150677 lmp.py:372]   Expert 17 |    215 | GPU
DEBUG 01-05 09:19:36.150035.150035 lmp.py:372]   Expert 27 |    218 | GPU
DEBUG 01-05 09:19:36.150009.150009 lmp.py:372]   Expert  7 |    220 | GPU
DEBUG 01-05 09:19:36.150460.150460 lmp.py:372]   Expert 33 |    221 | GPU
DEBUG 01-05 09:19:36.150958.150958 lmp.py:372]   Expert 39 |    225 | GPU
DEBUG 01-05 09:19:36.150455.150455 lmp.py:372]   Expert 22 |    227 | GPU
DEBUG 01-05 09:19:36.150190.150190 lmp.py:372]   Expert 43 |    230 | GPU
DEBUG 01-05 09:19:36.150164.150164 lmp.py:372]   Expert 62 |    230 | GPU
DEBUG 01-05 09:19:36.150662.150662 lmp.py:372]   Expert 51 |    232 | GPU
DEBUG 01-05 09:19:36.150113.150113 lmp.py:372]   Expert 54 |    249 | GPU
DEBUG 01-05 09:19:36.150040.150040 lmp.py:372]   Expert 49 |    254 | GPU
DEBUG 01-05 09:19:36.150922.150922 lmp.py:372]   Expert  1 |    259 | GPU
DEBUG 01-05 09:19:36.150373.150373 lmp.py:372]   Expert 36 |    265 | GPU
DEBUG 01-05 09:19:36.150108.150108 lmp.py:372]   Expert 44 |    270 | GPU
DEBUG 01-05 09:19:36.150082.150082 lmp.py:372]   Expert 29 |    279 | GPU
DEBUG 01-05 09:19:36.150056.150056 lmp.py:372]   Expert 59 |    303 | GPU
DEBUG 01-05 09:19:36.150030.150030 lmp.py:372]   Expert 47 |    318 | GPU
DEBUG 01-05 09:19:36.150720.150720 lmp.py:372]   Expert 15 |    327 | GPU
DEBUG 01-05 09:19:36.150647.150647 lmp.py:372]   Expert 38 |    347 | GPU
DEBUG 01-05 09:19:36.150529.150529 lmp.py:372]   Expert 23 |    396 | GPU
DEBUG 01-05 09:19:36.150503.150503 lmp.py:372]   Expert 14 |    400 | GPU
DEBUG 01-05 09:19:36.150715.150715 lmp.py:372]   Expert 41 |    412 | GPU
DEBUG 01-05 09:19:36.150928.150928 lmp.py:372]   Expert 55 |    413 | GPU
DEBUG 01-05 09:19:36.150902.150902 lmp.py:372]   Expert 21 |    416 | GPU
DEBUG 01-05 09:19:36.150114.150114 lmp.py:372]   Expert 10 |    462 | GPU
DEBUG 01-05 09:19:36.150996.150996 lmp.py:372]   Expert 56 |    592 | GPU
DEBUG 01-05 09:19:36.150115.150115 lmp.py:373] 
DEBUG 01-05 09:19:36.150115.150115 lmp.py:373]   CPU total tokens: 3178 (25.9%)
DEBUG 01-05 09:19:36.150474.150474 lmp.py:374]   GPU total tokens: 9110 (74.1%)
DEBUG 01-05 09:19:36.150170.150170 cuda_h.py:19] end experts_map_get cost 0.001529693603515625 seconds
DEBUG 01-05 09:19:36.150574.150574 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.150927.150927 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.150740.150740 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.151292.151292 cuda_h.py:19] end allocate_cuda_memory cost 0.00023293495178222656 seconds
DEBUG 01-05 09:19:36.151280.151280 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.151513.151513 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.151190.151190 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.151178.151178 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e026b5bf-e69f-45ec-8e63-35cac2197401
DEBUG 01-05 09:19:36.151721.151721 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.152632.152632 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e026b5bf-e69f-45ec-8e63-35cac2197401
DEBUG 01-05 09:19:36.152998.152998 cuda_h.py:19] end load_into_gpu_async cost 0.0016217231750488281 seconds
DEBUG 01-05 09:19:36.152078.152078 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.153964.153964 cuda_h.py:19] end restore_tensors2 cost 0.0003116130828857422 seconds
DEBUG 01-05 09:19:36.153263.153263 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002507448196411133 seconds
DEBUG 01-05 09:19:36.155471.155471 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005198478698730469 seconds
DEBUG 01-05 09:19:36.155446.155446 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.156171.156171 lmp.py:419] 
DEBUG 01-05 09:19:36.156171.156171 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.156014.156014 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-05 09:19:36.156048.156048 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.161052.161052 mlpmodule.py:704] group tensors cost 0.005724191665649414 s
DEBUG 01-05 09:19:36.164636.164636 mlpmodule.py:742] pad cost 0.002004384994506836 s
DEBUG 01-05 09:19:36.164401.164401 mlpmodule.py:748] create cpu tensor cost 4.220008850097656e-05 s
DEBUG 01-05 09:19:36.164874.164874 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-05 09:19:36.176022.176022 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.176014.176014 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.176033.176033 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 09:19:36.176170.176170 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.195944.195944 mlpmodule.py:793] group einsum cost 0.03091144561767578 s
DEBUG 01-05 09:19:36.196013.196013 mlpmodule.py:801] cpy2cputensor cost 0.0008628368377685547 s
DEBUG 01-05 09:19:36.238397.238397 cuda_h.py:19] end wait_cetm_experts cost 0.08237624168395996 seconds
DEBUG 01-05 09:19:36.238565.238565 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.239642.239642 cuda_h.py:19] end gpu_sexperts cost 0.0004699230194091797 seconds
DEBUG 01-05 09:19:36.239724.239724 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:19:36.239970.239970 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:19:36.239211.239211 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.4809112548828125e-05 seconds
DEBUG 01-05 09:19:36.239205.239205 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.367134094238281e-05 seconds
DEBUG 01-05 09:19:36.239332.239332 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.239611.239611 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e026b5bf-e69f-45ec-8e63-35cac2197401
DEBUG 01-05 09:19:36.239539.239539 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.239144.239144 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.240475.240475 cuda_h.py:10] start allocate_cuda_memory
INFO 01-05 09:19:36.247017.247017 client.py:127] Model loaded
DEBUG 01-05 09:19:36.247380.247380 cuda_h.py:19] end allocate_cuda_memory cost 0.007150411605834961 seconds
DEBUG 01-05 09:19:36.247671.247671 cuda_h.py:19] end wait_experts cost 0.008099794387817383 seconds
DEBUG 01-05 09:19:36.247305.247305 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.247098.247098 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.247977.247977 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.248716.248716 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.248033.248033 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.248872.248872 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d83c18bd-4a51-48a0-8cb5-30f05c7a1298
DEBUG 01-05 09:19:36.249462.249462 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.249763.249763 mlpmodule.py:531] gpu group tensors cost 0.0010540485382080078 s
DEBUG 01-05 09:19:36.251328.251328 mlpmodule.py:564] gpu pad cost 0.00170135498046875 s
DEBUG 01-05 09:19:36.251561.251561 mlpmodule.py:582] gpu group einsum cost 0.0005402565002441406 s
DEBUG 01-05 09:19:36.255785.255785 mlpmodule.py:611] gpu experts func einsum cost 0.006666898727416992 s
DEBUG 01-05 09:19:36.255245.255245 cuda_h.py:19] end gpu_experts cost 0.0071141719818115234 seconds
DEBUG 01-05 09:19:36.255525.255525 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:36.255637.255637 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d83c18bd-4a51-48a0-8cb5-30f05c7a1298
DEBUG 01-05 09:19:36.255370.255370 cuda_h.py:19] end load_into_gpu_async cost 0.007597923278808594 seconds
DEBUG 01-05 09:19:36.255095.255095 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.255421.255421 cuda_h.py:19] end restore_tensors2 cost 0.00016570091247558594 seconds
DEBUG 01-05 09:19:36.255066.255066 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015940189361572266 seconds
INFO 01-05 09:19:36.257045.257045 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d83c18bd-4a51-48a0-8cb5-30f05c7a1298
DEBUG 01-05 09:19:36.259258.259258 mlpmodule.py:662]  experts func einsum cost 0.10346364974975586 s
INFO 01-05 09:19:36.262318.262318 client.py:127] Model loaded
DEBUG 01-05 09:19:36.262383.262383 cuda_h.py:19] end sllm_worker_task cost 0.02256298065185547 seconds
DEBUG 01-05 09:19:36.262709.262709 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0074193477630615234 seconds
DEBUG 01-05 09:19:36.262525.262525 cuda_h.py:19] end layer_moe_generate_13 cost 0.1145026683807373 seconds
DEBUG 01-05 09:19:36.263942.263942 lmp.py:214] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 09:19:36.263142.263142 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 09:19:36.263746.263746 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.263153.263153 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.266625.266625 cuda_h.py:19] end self_attn cost 0.002744913101196289 seconds
DEBUG 01-05 09:19:36.266246.266246 cuda_h.py:19] end iln_self_attn_paln cost 0.0034148693084716797 seconds
DEBUG 01-05 09:19:36.266672.266672 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 09:19:36.266256.266256 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.267353.267353 cuda_h.py:19] end gate cost 0.0006606578826904297 seconds
DEBUG 01-05 09:19:36.267096.267096 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.267103.267103 lmp.py:361] 
DEBUG 01-05 09:19:36.267103.267103 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.267349.267349 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.267913.267913 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.268185.268185 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.268597.268597 lmp.py:365] 
DEBUG 01-05 09:19:36.268597.268597 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.268392.268392 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.268764.268764 lmp.py:372]   Expert 61 |      9 | CPU
DEBUG 01-05 09:19:36.268460.268460 lmp.py:372]   Expert  7 |     16 | CPU
DEBUG 01-05 09:19:36.268202.268202 lmp.py:372]   Expert 59 |     39 | CPU
DEBUG 01-05 09:19:36.268190.268190 lmp.py:372]   Expert 48 |     54 | CPU
DEBUG 01-05 09:19:36.268363.268363 lmp.py:372]   Expert 50 |     58 | CPU
DEBUG 01-05 09:19:36.268105.268105 lmp.py:372]   Expert 34 |     60 | CPU
DEBUG 01-05 09:19:36.268371.268371 lmp.py:372]   Expert 38 |     63 | CPU
DEBUG 01-05 09:19:36.268259.268259 lmp.py:372]   Expert 49 |     63 | CPU
DEBUG 01-05 09:19:36.268955.268955 lmp.py:372]   Expert 55 |     63 | CPU
DEBUG 01-05 09:19:36.268744.268744 lmp.py:372]   Expert 40 |     65 | CPU
DEBUG 01-05 09:19:36.268010.268010 lmp.py:372]   Expert 32 |     79 | CPU
DEBUG 01-05 09:19:36.268706.268706 lmp.py:372]   Expert 44 |     97 | CPU
DEBUG 01-05 09:19:36.268786.268786 lmp.py:372]   Expert 18 |     98 | CPU
DEBUG 01-05 09:19:36.268767.268767 lmp.py:372]   Expert 43 |    102 | CPU
DEBUG 01-05 09:19:36.268046.268046 lmp.py:372]   Expert 35 |    103 | CPU
DEBUG 01-05 09:19:36.268504.268504 lmp.py:372]   Expert  0 |    106 | CPU
DEBUG 01-05 09:19:36.268591.268591 lmp.py:372]   Expert 60 |    112 | CPU
DEBUG 01-05 09:19:36.268095.268095 lmp.py:372]   Expert 20 |    114 | CPU
DEBUG 01-05 09:19:36.268076.268076 lmp.py:372]   Expert 23 |    114 | CPU
DEBUG 01-05 09:19:36.268580.268580 lmp.py:372]   Expert 29 |    116 | CPU
DEBUG 01-05 09:19:36.268229.268229 lmp.py:372]   Expert  8 |    119 | CPU
DEBUG 01-05 09:19:36.268164.268164 lmp.py:372]   Expert 28 |    119 | CPU
DEBUG 01-05 09:19:36.268668.268668 lmp.py:372]   Expert 39 |    119 | CPU
DEBUG 01-05 09:19:36.268172.268172 lmp.py:372]   Expert 17 |    121 | CPU
DEBUG 01-05 09:19:36.268437.268437 lmp.py:372]   Expert 51 |    123 | CPU
DEBUG 01-05 09:19:36.268802.268802 lmp.py:372]   Expert 41 |    131 | CPU
DEBUG 01-05 09:19:36.268545.268545 lmp.py:372]   Expert 21 |    135 | CPU
DEBUG 01-05 09:19:36.268810.268810 lmp.py:372]   Expert 54 |    141 | CPU
DEBUG 01-05 09:19:36.268599.268599 lmp.py:372]   Expert 12 |    155 | CPU
DEBUG 01-05 09:19:36.268580.268580 lmp.py:372]   Expert 45 |    171 | CPU
DEBUG 01-05 09:19:36.268276.268276 lmp.py:372]   Expert 57 |    173 | CPU
DEBUG 01-05 09:19:36.268495.268495 lmp.py:372]   Expert 42 |    177 | CPU
DEBUG 01-05 09:19:36.268715.268715 lmp.py:372]   Expert 52 |    177 | GPU
DEBUG 01-05 09:19:36.268980.268980 lmp.py:372]   Expert 62 |    186 | GPU
DEBUG 01-05 09:19:36.268630.268630 lmp.py:372]   Expert  6 |    201 | GPU
DEBUG 01-05 09:19:36.268372.268372 lmp.py:372]   Expert 13 |    212 | GPU
DEBUG 01-05 09:19:36.268638.268638 lmp.py:372]   Expert 31 |    212 | GPU
DEBUG 01-05 09:19:36.268904.268904 lmp.py:372]   Expert  3 |    213 | GPU
DEBUG 01-05 09:19:36.268884.268884 lmp.py:372]   Expert 30 |    219 | GPU
DEBUG 01-05 09:19:36.268488.268488 lmp.py:372]   Expert 26 |    223 | GPU
DEBUG 01-05 09:19:36.268992.268992 lmp.py:372]   Expert 11 |    229 | GPU
DEBUG 01-05 09:19:36.268781.268781 lmp.py:372]   Expert 36 |    229 | GPU
DEBUG 01-05 09:19:36.268808.268808 lmp.py:372]   Expert 46 |    230 | GPU
DEBUG 01-05 09:19:36.269789.269789 lmp.py:372]   Expert 14 |    231 | GPU
DEBUG 01-05 09:19:36.269438.269438 lmp.py:372]   Expert 19 |    231 | GPU
DEBUG 01-05 09:19:36.269465.269465 lmp.py:372]   Expert 27 |    255 | GPU
DEBUG 01-05 09:19:36.269446.269446 lmp.py:372]   Expert 22 |    271 | GPU
DEBUG 01-05 09:19:36.269712.269712 lmp.py:372]   Expert  2 |    274 | GPU
DEBUG 01-05 09:19:36.269885.269885 lmp.py:372]   Expert  4 |    282 | GPU
DEBUG 01-05 09:19:36.269389.269389 lmp.py:372]   Expert 37 |    284 | GPU
DEBUG 01-05 09:19:36.269654.269654 lmp.py:372]   Expert  5 |    289 | GPU
DEBUG 01-05 09:19:36.269920.269920 lmp.py:372]   Expert 33 |    290 | GPU
DEBUG 01-05 09:19:36.269709.269709 lmp.py:372]   Expert 56 |    297 | GPU
DEBUG 01-05 09:19:36.269312.269312 lmp.py:372]   Expert  1 |    302 | GPU
DEBUG 01-05 09:19:36.269293.269293 lmp.py:372]   Expert 16 |    307 | GPU
DEBUG 01-05 09:19:36.269082.269082 lmp.py:372]   Expert 53 |    307 | GPU
DEBUG 01-05 09:19:36.269586.269586 lmp.py:372]   Expert 58 |    316 | GPU
DEBUG 01-05 09:19:36.269090.269090 lmp.py:372]   Expert 10 |    350 | GPU
DEBUG 01-05 09:19:36.269978.269978 lmp.py:372]   Expert 63 |    351 | GPU
DEBUG 01-05 09:19:36.269482.269482 lmp.py:372]   Expert 47 |    372 | GPU
DEBUG 01-05 09:19:36.269747.269747 lmp.py:372]   Expert 15 |    380 | GPU
DEBUG 01-05 09:19:36.269728.269728 lmp.py:372]   Expert 24 |    384 | GPU
DEBUG 01-05 09:19:36.269616.269616 lmp.py:372]   Expert 25 |    477 | GPU
DEBUG 01-05 09:19:36.269359.269359 lmp.py:372]   Expert  9 |    492 | GPU
DEBUG 01-05 09:19:36.269340.269340 lmp.py:373] 
DEBUG 01-05 09:19:36.269340.269340 lmp.py:373]   CPU total tokens: 3215 (26.2%)
DEBUG 01-05 09:19:36.269321.269321 lmp.py:374]   GPU total tokens: 9073 (73.8%)
DEBUG 01-05 09:19:36.269739.269739 cuda_h.py:19] end experts_map_get cost 0.0019447803497314453 seconds
DEBUG 01-05 09:19:36.269342.269342 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.269185.269185 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.269210.269210 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.270300.270300 cuda_h.py:19] end allocate_cuda_memory cost 0.000270843505859375 seconds
DEBUG 01-05 09:19:36.270925.270925 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.270980.270980 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.270710.270710 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.270704.270704 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb817cac-11d9-4f53-a5ec-cb9aa6448a2d
DEBUG 01-05 09:19:36.270672.270672 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.272109.272109 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb817cac-11d9-4f53-a5ec-cb9aa6448a2d
DEBUG 01-05 09:19:36.272483.272483 cuda_h.py:19] end load_into_gpu_async cost 0.0021610260009765625 seconds
DEBUG 01-05 09:19:36.272431.272431 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.272921.272921 cuda_h.py:19] end restore_tensors2 cost 0.00035500526428222656 seconds
DEBUG 01-05 09:19:36.272803.272803 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031986236572265625 seconds
DEBUG 01-05 09:19:36.275360.275360 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006232023239135742 seconds
DEBUG 01-05 09:19:36.275666.275666 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.275391.275391 lmp.py:419] 
DEBUG 01-05 09:19:36.275391.275391 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.275618.275618 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 09:19:36.276029.276029 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.281996.281996 mlpmodule.py:704] group tensors cost 0.005584716796875 s
DEBUG 01-05 09:19:36.284376.284376 mlpmodule.py:742] pad cost 0.0019457340240478516 s
DEBUG 01-05 09:19:36.284136.284136 mlpmodule.py:748] create cpu tensor cost 5.0067901611328125e-05 s
DEBUG 01-05 09:19:36.284106.284106 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 09:19:36.296958.296958 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.296819.296819 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.296452.296452 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 09:19:36.297933.297933 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.317621.317621 mlpmodule.py:793] group einsum cost 0.032318115234375 s
DEBUG 01-05 09:19:36.319110.319110 mlpmodule.py:801] cpy2cputensor cost 0.002334117889404297 s
DEBUG 01-05 09:19:36.360052.360052 cuda_h.py:19] end wait_cetm_experts cost 0.08410477638244629 seconds
DEBUG 01-05 09:19:36.360360.360360 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.360443.360443 cuda_h.py:19] end gpu_sexperts cost 0.00047516822814941406 seconds
DEBUG 01-05 09:19:36.360233.360233 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:19:36.360287.360287 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:19:36.360859.360859 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 09:19:36.360715.360715 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.319450378417969e-05 seconds
DEBUG 01-05 09:19:36.360510.360510 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.361505.361505 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb817cac-11d9-4f53-a5ec-cb9aa6448a2d
DEBUG 01-05 09:19:36.361102.361102 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.361415.361415 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.361732.361732 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.365811.365811 cuda_h.py:19] end allocate_cuda_memory cost 0.0038416385650634766 seconds
INFO 01-05 09:19:36.365282.365282 client.py:127] Model loaded
DEBUG 01-05 09:19:36.366938.366938 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.366426.366426 cuda_h.py:19] end wait_experts cost 0.0051555633544921875 seconds
DEBUG 01-05 09:19:36.366092.366092 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.366202.366202 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.366426.366426 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.366772.366772 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc262456-6824-4cc9-a83f-2217b2694fac
DEBUG 01-05 09:19:36.367224.367224 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.366404.366404 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.370302.370302 mlpmodule.py:531] gpu group tensors cost 0.0006337165832519531 s
INFO 01-05 09:19:36.371036.371036 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc262456-6824-4cc9-a83f-2217b2694fac
DEBUG 01-05 09:19:36.371149.371149 cuda_h.py:19] end load_into_gpu_async cost 0.005453348159790039 seconds
DEBUG 01-05 09:19:36.371688.371688 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.372398.372398 cuda_h.py:19] end restore_tensors2 cost 0.0001647472381591797 seconds
DEBUG 01-05 09:19:36.372427.372427 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01053929328918457 seconds
INFO 01-05 09:19:36.373216.373216 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc262456-6824-4cc9-a83f-2217b2694fac
DEBUG 01-05 09:19:36.374577.374577 mlpmodule.py:662]  experts func einsum cost 0.09868478775024414 s
DEBUG 01-05 09:19:36.375256.375256 mlpmodule.py:564] gpu pad cost 0.004090547561645508 s
DEBUG 01-05 09:19:36.375269.375269 mlpmodule.py:582] gpu group einsum cost 0.0004906654357910156 s
DEBUG 01-05 09:19:36.378739.378739 mlpmodule.py:611] gpu experts func einsum cost 0.00837564468383789 s
INFO 01-05 09:19:36.378222.378222 client.py:127] Model loaded
DEBUG 01-05 09:19:36.379559.379559 cuda_h.py:19] end sllm_worker_task cost 0.01757502555847168 seconds
DEBUG 01-05 09:19:36.379530.379530 cuda_h.py:19] end gpu_experts cost 0.012489557266235352 seconds
DEBUG 01-05 09:19:36.379734.379734 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:36.379100.379100 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-05 09:19:36.379337.379337 cuda_h.py:19] end layer_moe_generate_14 cost 0.11277484893798828 seconds
DEBUG 01-05 09:19:36.379502.379502 lmp.py:214] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 09:19:36.379225.379225 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 09:19:36.379683.379683 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.380209.380209 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.382981.382981 cuda_h.py:19] end self_attn cost 0.002443552017211914 seconds
DEBUG 01-05 09:19:36.382058.382058 cuda_h.py:19] end iln_self_attn_paln cost 0.003054380416870117 seconds
DEBUG 01-05 09:19:36.382947.382947 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 09:19:36.382379.382379 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.383897.383897 cuda_h.py:19] end gate cost 0.000591278076171875 seconds
DEBUG 01-05 09:19:36.383819.383819 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.383531.383531 lmp.py:361] 
DEBUG 01-05 09:19:36.383531.383531 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.383433.383433 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.384752.384752 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.384779.384779 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.384044.384044 lmp.py:365] 
DEBUG 01-05 09:19:36.384044.384044 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.384926.384926 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.384052.384052 lmp.py:372]   Expert 63 |     15 | CPU
DEBUG 01-05 09:19:36.384934.384934 lmp.py:372]   Expert 37 |     56 | CPU
DEBUG 01-05 09:19:36.384100.384100 lmp.py:372]   Expert 34 |     57 | CPU
DEBUG 01-05 09:19:36.384173.384173 lmp.py:372]   Expert 42 |     59 | CPU
DEBUG 01-05 09:19:36.384293.384293 lmp.py:372]   Expert  4 |     62 | CPU
DEBUG 01-05 09:19:36.384698.384698 lmp.py:372]   Expert 48 |     65 | CPU
DEBUG 01-05 09:19:36.384626.384626 lmp.py:372]   Expert 22 |     72 | CPU
DEBUG 01-05 09:19:36.384838.384838 lmp.py:372]   Expert 28 |     75 | CPU
DEBUG 01-05 09:19:36.384435.384435 lmp.py:372]   Expert 57 |     76 | CPU
DEBUG 01-05 09:19:36.384601.384601 lmp.py:372]   Expert 53 |     80 | CPU
DEBUG 01-05 09:19:36.384813.384813 lmp.py:372]   Expert 51 |     82 | CPU
DEBUG 01-05 09:19:36.384503.384503 lmp.py:372]   Expert  5 |     86 | CPU
DEBUG 01-05 09:19:36.384192.384192 lmp.py:372]   Expert 15 |     86 | CPU
DEBUG 01-05 09:19:36.384643.384643 lmp.py:372]   Expert 40 |     91 | CPU
DEBUG 01-05 09:19:36.384617.384617 lmp.py:372]   Expert 43 |     96 | CPU
DEBUG 01-05 09:19:36.384068.384068 lmp.py:372]   Expert 41 |    115 | CPU
DEBUG 01-05 09:19:36.384519.384519 lmp.py:372]   Expert 55 |    124 | CPU
DEBUG 01-05 09:19:36.384360.384360 lmp.py:372]   Expert  7 |    125 | CPU
DEBUG 01-05 09:19:36.384765.384765 lmp.py:372]   Expert  6 |    129 | CPU
DEBUG 01-05 09:19:36.384408.384408 lmp.py:372]   Expert 32 |    129 | CPU
DEBUG 01-05 09:19:36.384813.384813 lmp.py:372]   Expert 29 |    132 | CPU
DEBUG 01-05 09:19:36.384648.384648 lmp.py:372]   Expert 56 |    144 | CPU
DEBUG 01-05 09:19:36.384337.384337 lmp.py:372]   Expert 52 |    146 | CPU
DEBUG 01-05 09:19:36.384788.384788 lmp.py:372]   Expert 44 |    148 | CPU
DEBUG 01-05 09:19:36.384762.384762 lmp.py:372]   Expert 25 |    156 | CPU
DEBUG 01-05 09:19:36.384213.384213 lmp.py:372]   Expert 61 |    157 | CPU
DEBUG 01-05 09:19:36.384140.384140 lmp.py:372]   Expert  2 |    158 | CPU
DEBUG 01-05 09:19:36.384499.384499 lmp.py:372]   Expert 14 |    159 | CPU
DEBUG 01-05 09:19:36.384903.384903 lmp.py:372]   Expert 54 |    161 | CPU
DEBUG 01-05 09:19:36.384308.384308 lmp.py:372]   Expert 12 |    175 | CPU
DEBUG 01-05 09:19:36.384997.384997 lmp.py:372]   Expert 33 |    184 | CPU
DEBUG 01-05 09:19:36.384686.384686 lmp.py:372]   Expert 50 |    186 | CPU
DEBUG 01-05 09:19:36.384806.384806 lmp.py:372]   Expert 35 |    187 | GPU
DEBUG 01-05 09:19:36.384972.384972 lmp.py:372]   Expert 62 |    192 | GPU
DEBUG 01-05 09:19:36.384662.384662 lmp.py:372]   Expert 39 |    198 | GPU
DEBUG 01-05 09:19:36.384113.384113 lmp.py:372]   Expert 31 |    214 | GPU
DEBUG 01-05 09:19:36.384802.384802 lmp.py:372]   Expert 20 |    216 | GPU
DEBUG 01-05 09:19:36.384922.384922 lmp.py:372]   Expert 58 |    216 | GPU
DEBUG 01-05 09:19:36.384041.384041 lmp.py:372]   Expert 11 |    217 | GPU
DEBUG 01-05 09:19:36.384208.384208 lmp.py:372]   Expert 45 |    223 | GPU
DEBUG 01-05 09:19:36.384420.384420 lmp.py:372]   Expert 23 |    227 | GPU
DEBUG 01-05 09:19:36.384632.384632 lmp.py:372]   Expert 47 |    229 | GPU
DEBUG 01-05 09:19:36.384845.384845 lmp.py:372]   Expert 59 |    230 | GPU
DEBUG 01-05 09:19:36.384819.384819 lmp.py:372]   Expert 10 |    233 | GPU
DEBUG 01-05 09:19:36.384462.384462 lmp.py:372]   Expert  1 |    240 | GPU
DEBUG 01-05 09:19:36.384151.384151 lmp.py:372]   Expert 13 |    242 | GPU
DEBUG 01-05 09:19:36.384602.384602 lmp.py:372]   Expert 24 |    243 | GPU
DEBUG 01-05 09:19:36.384815.384815 lmp.py:372]   Expert  9 |    252 | GPU
DEBUG 01-05 09:19:36.384789.384789 lmp.py:372]   Expert 36 |    255 | GPU
DEBUG 01-05 09:19:36.384240.384240 lmp.py:372]   Expert  0 |    257 | GPU
DEBUG 01-05 09:19:36.384452.384452 lmp.py:372]   Expert 38 |    257 | GPU
DEBUG 01-05 09:19:36.384095.384095 lmp.py:372]   Expert 16 |    272 | GPU
DEBUG 01-05 09:19:36.384215.384215 lmp.py:372]   Expert 18 |    272 | GPU
DEBUG 01-05 09:19:36.385335.385335 lmp.py:372]   Expert 46 |    285 | GPU
DEBUG 01-05 09:19:36.385785.385785 lmp.py:372]   Expert 60 |    296 | GPU
DEBUG 01-05 09:19:36.385998.385998 lmp.py:372]   Expert 49 |    304 | GPU
DEBUG 01-05 09:19:36.385972.385972 lmp.py:372]   Expert  3 |    307 | GPU
DEBUG 01-05 09:19:36.385423.385423 lmp.py:372]   Expert 19 |    311 | GPU
DEBUG 01-05 09:19:36.385066.385066 lmp.py:372]   Expert 30 |    312 | GPU
DEBUG 01-05 09:19:36.385232.385232 lmp.py:372]   Expert 26 |    340 | GPU
DEBUG 01-05 09:19:36.385398.385398 lmp.py:372]   Expert 21 |    349 | GPU
DEBUG 01-05 09:19:36.385326.385326 lmp.py:372]   Expert 27 |    350 | GPU
DEBUG 01-05 09:19:36.385538.385538 lmp.py:372]   Expert 17 |    374 | GPU
DEBUG 01-05 09:19:36.385751.385751 lmp.py:372]   Expert  8 |    602 | GPU
DEBUG 01-05 09:19:36.385063.385063 lmp.py:373] 
DEBUG 01-05 09:19:36.385063.385063 lmp.py:373]   CPU total tokens: 3586 (29.2%)
DEBUG 01-05 09:19:36.385421.385421 lmp.py:374]   GPU total tokens: 8702 (70.8%)
DEBUG 01-05 09:19:36.385594.385594 cuda_h.py:19] end experts_map_get cost 0.0015614032745361328 seconds
DEBUG 01-05 09:19:36.385237.385237 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.385828.385828 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.385402.385402 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.385479.385479 cuda_h.py:19] end allocate_cuda_memory cost 0.00026679039001464844 seconds
DEBUG 01-05 09:19:36.385375.385375 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.385323.385323 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.385092.385092 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.385795.385795 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b415c70-e5f8-418c-a8e3-163ce4cbb985
DEBUG 01-05 09:19:36.386961.386961 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.387713.387713 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b415c70-e5f8-418c-a8e3-163ce4cbb985
DEBUG 01-05 09:19:36.387927.387927 cuda_h.py:19] end load_into_gpu_async cost 0.0014297962188720703 seconds
DEBUG 01-05 09:19:36.387769.387769 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.387488.387488 cuda_h.py:19] end restore_tensors2 cost 0.0002942085266113281 seconds
DEBUG 01-05 09:19:36.387748.387748 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023391246795654297 seconds
DEBUG 01-05 09:19:36.390956.390956 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005032062530517578 seconds
DEBUG 01-05 09:19:36.390931.390931 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.390464.390464 lmp.py:419] 
DEBUG 01-05 09:19:36.390464.390464 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.390783.390783 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-05 09:19:36.390625.390625 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.400710.400710 mlpmodule.py:704] group tensors cost 0.009893417358398438 s
DEBUG 01-05 09:19:36.402484.402484 mlpmodule.py:742] pad cost 0.0014994144439697266 s
DEBUG 01-05 09:19:36.402978.402978 mlpmodule.py:748] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-05 09:19:36.402941.402941 mlpmodule.py:753] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-05 09:19:36.414963.414963 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.414863.414863 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.414575.414575 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:19:36.415089.415089 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.435124.435124 mlpmodule.py:793] group einsum cost 0.03229355812072754 s
DEBUG 01-05 09:19:36.436689.436689 mlpmodule.py:801] cpy2cputensor cost 0.0012743473052978516 s
DEBUG 01-05 09:19:36.477953.477953 cuda_h.py:19] end wait_cetm_experts cost 0.08689093589782715 seconds
DEBUG 01-05 09:19:36.477022.477022 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.478622.478622 cuda_h.py:19] end gpu_sexperts cost 0.00046372413635253906 seconds
DEBUG 01-05 09:19:36.478843.478843 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:19:36.478374.478374 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:19:36.478191.478191 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.8623809814453125e-05 seconds
DEBUG 01-05 09:19:36.478139.478139 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.772445678710938e-05 seconds
DEBUG 01-05 09:19:36.478650.478650 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.478982.478982 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b415c70-e5f8-418c-a8e3-163ce4cbb985
DEBUG 01-05 09:19:36.478049.478049 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.478853.478853 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.478501.478501 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.483418.483418 cuda_h.py:19] end allocate_cuda_memory cost 0.003933906555175781 seconds
INFO 01-05 09:19:36.483889.483889 client.py:127] Model loaded
DEBUG 01-05 09:19:36.483121.483121 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.483086.483086 cuda_h.py:19] end wait_experts cost 0.005257129669189453 seconds
DEBUG 01-05 09:19:36.483421.483421 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.483776.483776 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.484404.484404 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.484087.484087 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.484370.484370 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af8f4fca-25ae-4a72-86f5-0036a91b2579
DEBUG 01-05 09:19:36.484476.484476 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.487524.487524 mlpmodule.py:531] gpu group tensors cost 0.003671884536743164 s
INFO 01-05 09:19:36.489778.489778 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af8f4fca-25ae-4a72-86f5-0036a91b2579
DEBUG 01-05 09:19:36.489300.489300 cuda_h.py:19] end load_into_gpu_async cost 0.005707740783691406 seconds
DEBUG 01-05 09:19:36.489171.489171 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.489258.489258 cuda_h.py:19] end restore_tensors2 cost 0.0001621246337890625 seconds
DEBUG 01-05 09:19:36.489223.489223 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010941028594970703 seconds
INFO 01-05 09:19:36.491489.491489 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af8f4fca-25ae-4a72-86f5-0036a91b2579
DEBUG 01-05 09:19:36.491999.491999 mlpmodule.py:564] gpu pad cost 0.003971576690673828 s
DEBUG 01-05 09:19:36.492799.492799 mlpmodule.py:662]  experts func einsum cost 0.10158276557922363 s
DEBUG 01-05 09:19:36.492728.492728 mlpmodule.py:582] gpu group einsum cost 0.0006556510925292969 s
DEBUG 01-05 09:19:36.495844.495844 mlpmodule.py:611] gpu experts func einsum cost 0.011472463607788086 s
DEBUG 01-05 09:19:36.495305.495305 cuda_h.py:19] end gpu_experts cost 0.011661767959594727 seconds
DEBUG 01-05 09:19:36.495206.495206 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:36.499922.499922 client.py:127] Model loaded
DEBUG 01-05 09:19:36.499742.499742 cuda_h.py:19] end sllm_worker_task cost 0.020619869232177734 seconds
DEBUG 01-05 09:19:36.499689.499689 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0038635730743408203 seconds
DEBUG 01-05 09:19:36.499849.499849 cuda_h.py:19] end layer_moe_generate_15 cost 0.11688446998596191 seconds
DEBUG 01-05 09:19:36.500736.500736 lmp.py:214] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 09:19:36.500466.500466 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 09:19:36.500116.500116 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.500517.500517 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.502712.502712 cuda_h.py:19] end self_attn cost 0.002404451370239258 seconds
DEBUG 01-05 09:19:36.503821.503821 cuda_h.py:19] end iln_self_attn_paln cost 0.003016233444213867 seconds
DEBUG 01-05 09:19:36.503425.503425 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 09:19:36.503685.503685 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.503030.503030 cuda_h.py:19] end gate cost 0.00057220458984375 seconds
DEBUG 01-05 09:19:36.503952.503952 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.504466.504466 lmp.py:361] 
DEBUG 01-05 09:19:36.504466.504466 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.504937.504937 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.504349.504349 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.504137.504137 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.504780.504780 lmp.py:365] 
DEBUG 01-05 09:19:36.504780.504780 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.504854.504854 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.504504.504504 lmp.py:372]   Expert 58 |     20 | CPU
DEBUG 01-05 09:19:36.504822.504822 lmp.py:372]   Expert 43 |     56 | CPU
DEBUG 01-05 09:19:36.504750.504750 lmp.py:372]   Expert 14 |     71 | CPU
DEBUG 01-05 09:19:36.504108.504108 lmp.py:372]   Expert 54 |     79 | CPU
DEBUG 01-05 09:19:36.504513.504513 lmp.py:372]   Expert 13 |     83 | CPU
DEBUG 01-05 09:19:36.504964.504964 lmp.py:372]   Expert 45 |     90 | CPU
DEBUG 01-05 09:19:36.504176.504176 lmp.py:372]   Expert 11 |     95 | CPU
DEBUG 01-05 09:19:36.504389.504389 lmp.py:372]   Expert 39 |     96 | CPU
DEBUG 01-05 09:19:36.504555.504555 lmp.py:372]   Expert 60 |     98 | CPU
DEBUG 01-05 09:19:36.504721.504721 lmp.py:372]   Expert 59 |    106 | CPU
DEBUG 01-05 09:19:36.504172.504172 lmp.py:372]   Expert 34 |    108 | CPU
DEBUG 01-05 09:19:36.504007.504007 lmp.py:372]   Expert  6 |    113 | CPU
DEBUG 01-05 09:19:36.504458.504458 lmp.py:372]   Expert 18 |    114 | CPU
DEBUG 01-05 09:19:36.504909.504909 lmp.py:372]   Expert 28 |    119 | CPU
DEBUG 01-05 09:19:36.504359.504359 lmp.py:372]   Expert 57 |    119 | CPU
DEBUG 01-05 09:19:36.504572.504572 lmp.py:372]   Expert 61 |    120 | CPU
DEBUG 01-05 09:19:36.504453.504453 lmp.py:372]   Expert 49 |    130 | CPU
DEBUG 01-05 09:19:36.504381.504381 lmp.py:372]   Expert 32 |    131 | CPU
DEBUG 01-05 09:19:36.504309.504309 lmp.py:372]   Expert 25 |    132 | CPU
DEBUG 01-05 09:19:36.504236.504236 lmp.py:372]   Expert 51 |    134 | CPU
DEBUG 01-05 09:19:36.504926.504926 lmp.py:372]   Expert 41 |    136 | CPU
DEBUG 01-05 09:19:36.504377.504377 lmp.py:372]   Expert  0 |    138 | CPU
DEBUG 01-05 09:19:36.504496.504496 lmp.py:372]   Expert 35 |    139 | CPU
DEBUG 01-05 09:19:36.504663.504663 lmp.py:372]   Expert 62 |    141 | CPU
DEBUG 01-05 09:19:36.504637.504637 lmp.py:372]   Expert 30 |    145 | CPU
DEBUG 01-05 09:19:36.504611.504611 lmp.py:372]   Expert 38 |    146 | CPU
DEBUG 01-05 09:19:36.504823.504823 lmp.py:372]   Expert 50 |    148 | CPU
DEBUG 01-05 09:19:36.504559.504559 lmp.py:372]   Expert 15 |    161 | CPU
DEBUG 01-05 09:19:36.504010.504010 lmp.py:372]   Expert 12 |    164 | CPU
DEBUG 01-05 09:19:36.504414.504414 lmp.py:372]   Expert 37 |    169 | CPU
DEBUG 01-05 09:19:36.504342.504342 lmp.py:372]   Expert 31 |    178 | CPU
DEBUG 01-05 09:19:36.504316.504316 lmp.py:372]   Expert 56 |    180 | CPU
DEBUG 01-05 09:19:36.504389.504389 lmp.py:372]   Expert 26 |    182 | GPU
DEBUG 01-05 09:19:36.504840.504840 lmp.py:372]   Expert 42 |    186 | GPU
DEBUG 01-05 09:19:36.504576.504576 lmp.py:372]   Expert 63 |    187 | GPU
DEBUG 01-05 09:19:36.504550.504550 lmp.py:372]   Expert 48 |    192 | GPU
DEBUG 01-05 09:19:36.504524.504524 lmp.py:372]   Expert 10 |    201 | GPU
DEBUG 01-05 09:19:36.505452.505452 lmp.py:372]   Expert  3 |    202 | GPU
DEBUG 01-05 09:19:36.505618.505618 lmp.py:372]   Expert 44 |    203 | GPU
DEBUG 01-05 09:19:36.505830.505830 lmp.py:372]   Expert 40 |    207 | GPU
DEBUG 01-05 09:19:36.505043.505043 lmp.py:372]   Expert 55 |    210 | GPU
DEBUG 01-05 09:19:36.505255.505255 lmp.py:372]   Expert 21 |    212 | GPU
DEBUG 01-05 09:19:36.505383.505383 lmp.py:372]   Expert 33 |    222 | GPU
DEBUG 01-05 09:19:36.505549.505549 lmp.py:372]   Expert 47 |    224 | GPU
DEBUG 01-05 09:19:36.505762.505762 lmp.py:372]   Expert 16 |    225 | GPU
DEBUG 01-05 09:19:36.505974.505974 lmp.py:372]   Expert 36 |    230 | GPU
DEBUG 01-05 09:19:36.505948.505948 lmp.py:372]   Expert  9 |    231 | GPU
DEBUG 01-05 09:19:36.505922.505922 lmp.py:372]   Expert  1 |    232 | GPU
DEBUG 01-05 09:19:36.505804.505804 lmp.py:372]   Expert 46 |    243 | GPU
DEBUG 01-05 09:19:36.505016.505016 lmp.py:372]   Expert 19 |    244 | GPU
DEBUG 01-05 09:19:36.505229.505229 lmp.py:372]   Expert  2 |    258 | GPU
DEBUG 01-05 09:19:36.505441.505441 lmp.py:372]   Expert 24 |    266 | GPU
DEBUG 01-05 09:19:36.505177.505177 lmp.py:372]   Expert 20 |    274 | GPU
DEBUG 01-05 09:19:36.505389.505389 lmp.py:372]   Expert 22 |    276 | GPU
DEBUG 01-05 09:19:36.505363.505363 lmp.py:372]   Expert 53 |    279 | GPU
DEBUG 01-05 09:19:36.505431.505431 lmp.py:372]   Expert  7 |    284 | GPU
DEBUG 01-05 09:19:36.505597.505597 lmp.py:372]   Expert  8 |    284 | GPU
DEBUG 01-05 09:19:36.505240.505240 lmp.py:372]   Expert 29 |    303 | GPU
DEBUG 01-05 09:19:36.505645.505645 lmp.py:372]   Expert  4 |    347 | GPU
DEBUG 01-05 09:19:36.505096.505096 lmp.py:372]   Expert 17 |    360 | GPU
DEBUG 01-05 09:19:36.505547.505547 lmp.py:372]   Expert 23 |    362 | GPU
DEBUG 01-05 09:19:36.505759.505759 lmp.py:372]   Expert 27 |    424 | GPU
DEBUG 01-05 09:19:36.505971.505971 lmp.py:372]   Expert 52 |    438 | GPU
DEBUG 01-05 09:19:36.505614.505614 lmp.py:372]   Expert  5 |    441 | GPU
DEBUG 01-05 09:19:36.505257.505257 lmp.py:373] 
DEBUG 01-05 09:19:36.505257.505257 lmp.py:373]   CPU total tokens: 3859 (31.4%)
DEBUG 01-05 09:19:36.505900.505900 lmp.py:374]   GPU total tokens: 8429 (68.6%)
DEBUG 01-05 09:19:36.505789.505789 cuda_h.py:19] end experts_map_get cost 0.0016055107116699219 seconds
DEBUG 01-05 09:19:36.505432.505432 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.505407.505407 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.505166.505166 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.506111.506111 cuda_h.py:19] end allocate_cuda_memory cost 0.0002753734588623047 seconds
DEBUG 01-05 09:19:36.506199.506199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.506147.506147 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.506678.506678 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.506235.506235 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1d67792-a19c-4d47-9521-6e8b9a1dfda3
DEBUG 01-05 09:19:36.506202.506202 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.508059.508059 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1d67792-a19c-4d47-9521-6e8b9a1dfda3
DEBUG 01-05 09:19:36.508034.508034 cuda_h.py:19] end load_into_gpu_async cost 0.0021653175354003906 seconds
DEBUG 01-05 09:19:36.508353.508353 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.508907.508907 cuda_h.py:19] end restore_tensors2 cost 0.00030040740966796875 seconds
DEBUG 01-05 09:19:36.508014.508014 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030934810638427734 seconds
DEBUG 01-05 09:19:36.511341.511341 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005763053894042969 seconds
DEBUG 01-05 09:19:36.511031.511031 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.511756.511756 lmp.py:419] 
DEBUG 01-05 09:19:36.511756.511756 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.511414.511414 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-05 09:19:36.511971.511971 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.521438.521438 mlpmodule.py:704] group tensors cost 0.01005244255065918 s
DEBUG 01-05 09:19:36.523343.523343 mlpmodule.py:742] pad cost 0.0015301704406738281 s
DEBUG 01-05 09:19:36.524009.524009 mlpmodule.py:748] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-05 09:19:36.524144.524144 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-05 09:19:36.541517.541517 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.542663.542663 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.542250.542250 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 09:19:36.542069.542069 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.563106.563106 mlpmodule.py:793] group einsum cost 0.03931164741516113 s
DEBUG 01-05 09:19:36.565254.565254 mlpmodule.py:801] cpy2cputensor cost 0.0015947818756103516 s
DEBUG 01-05 09:19:36.605788.605788 cuda_h.py:19] end wait_cetm_experts cost 0.09396910667419434 seconds
DEBUG 01-05 09:19:36.605813.605813 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.606387.606387 cuda_h.py:19] end gpu_sexperts cost 0.00048422813415527344 seconds
DEBUG 01-05 09:19:36.606714.606714 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:19:36.606484.606484 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:19:36.606308.606308 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.695487976074219e-05 seconds
DEBUG 01-05 09:19:36.606209.606209 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 8.082389831542969e-05 seconds
DEBUG 01-05 09:19:36.606766.606766 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.606715.606715 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1d67792-a19c-4d47-9521-6e8b9a1dfda3
DEBUG 01-05 09:19:36.606550.606550 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.607778.607778 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.607326.607326 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.611358.611358 cuda_h.py:19] end allocate_cuda_memory cost 0.003810882568359375 seconds
DEBUG 01-05 09:19:36.611722.611722 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.611388.611388 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.611458.611458 sllm_store_c.py:29] call client load into gpu
INFO 01-05 09:19:36.611285.611285 client.py:127] Model loaded
DEBUG 01-05 09:19:36.612386.612386 cuda_h.py:19] end wait_experts cost 0.005394458770751953 seconds
DEBUG 01-05 09:19:36.612196.612196 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.612197.612197 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.611111.611111 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e8df948-e0d5-4191-ba85-fce17f972dc3
DEBUG 01-05 09:19:36.612236.612236 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.613645.613645 mlpmodule.py:531] gpu group tensors cost 0.0010035037994384766 s
DEBUG 01-05 09:19:36.615645.615645 mlpmodule.py:564] gpu pad cost 0.0016770362854003906 s
DEBUG 01-05 09:19:36.615750.615750 mlpmodule.py:582] gpu group einsum cost 0.0006654262542724609 s
DEBUG 01-05 09:19:36.619609.619609 mlpmodule.py:611] gpu experts func einsum cost 0.0070648193359375 s
DEBUG 01-05 09:19:36.619553.619553 cuda_h.py:19] end gpu_experts cost 0.007251739501953125 seconds
DEBUG 01-05 09:19:36.619554.619554 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:36.620305.620305 mlpmodule.py:662]  experts func einsum cost 0.10873794555664062 s
INFO 01-05 09:19:36.621699.621699 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e8df948-e0d5-4191-ba85-fce17f972dc3
DEBUG 01-05 09:19:36.622421.622421 cuda_h.py:19] end load_into_gpu_async cost 0.01065516471862793 seconds
DEBUG 01-05 09:19:36.622821.622821 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.622968.622968 cuda_h.py:19] end restore_tensors2 cost 0.00016736984252929688 seconds
DEBUG 01-05 09:19:36.622521.622521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015364408493041992 seconds
INFO 01-05 09:19:36.623306.623306 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e8df948-e0d5-4191-ba85-fce17f972dc3
INFO 01-05 09:19:36.628982.628982 client.py:127] Model loaded
DEBUG 01-05 09:19:36.628033.628033 cuda_h.py:19] end sllm_worker_task cost 0.02187061309814453 seconds
DEBUG 01-05 09:19:36.629326.629326 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00974893569946289 seconds
DEBUG 01-05 09:19:36.629732.629732 cuda_h.py:19] end layer_moe_generate_16 cost 0.12618780136108398 seconds
DEBUG 01-05 09:19:36.629957.629957 lmp.py:214] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 09:19:36.629157.629157 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 09:19:36.629046.629046 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.630985.630985 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.633543.633543 cuda_h.py:19] end self_attn cost 0.002939939498901367 seconds
DEBUG 01-05 09:19:36.633171.633171 cuda_h.py:19] end iln_self_attn_paln cost 0.0037097930908203125 seconds
DEBUG 01-05 09:19:36.633558.633558 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 09:19:36.633387.633387 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.634524.634524 cuda_h.py:19] end gate cost 0.0006890296936035156 seconds
DEBUG 01-05 09:19:36.634805.634805 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.634434.634434 lmp.py:361] 
DEBUG 01-05 09:19:36.634434.634434 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.634918.634918 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.634913.634913 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.634477.634477 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.634034.634034 lmp.py:365] 
DEBUG 01-05 09:19:36.634034.634034 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.634353.634353 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.634585.634585 lmp.py:372]   Expert 39 |     46 | CPU
DEBUG 01-05 09:19:36.635527.635527 lmp.py:372]   Expert 28 |     54 | CPU
DEBUG 01-05 09:19:36.635369.635369 lmp.py:372]   Expert 47 |     66 | CPU
DEBUG 01-05 09:19:36.635780.635780 lmp.py:372]   Expert 36 |     69 | CPU
DEBUG 01-05 09:19:36.635191.635191 lmp.py:372]   Expert 14 |     70 | CPU
DEBUG 01-05 09:19:36.635179.635179 lmp.py:372]   Expert  1 |     81 | CPU
DEBUG 01-05 09:19:36.635590.635590 lmp.py:372]   Expert  7 |     83 | CPU
DEBUG 01-05 09:19:36.635002.635002 lmp.py:372]   Expert  8 |     87 | CPU
DEBUG 01-05 09:19:36.635082.635082 lmp.py:372]   Expert 40 |     88 | CPU
DEBUG 01-05 09:19:36.635354.635354 lmp.py:372]   Expert 27 |     94 | CPU
DEBUG 01-05 09:19:36.635958.635958 lmp.py:372]   Expert 52 |     94 | CPU
DEBUG 01-05 09:19:36.635846.635846 lmp.py:372]   Expert 25 |     99 | CPU
DEBUG 01-05 09:19:36.635257.635257 lmp.py:372]   Expert 54 |    117 | CPU
DEBUG 01-05 09:19:36.635907.635907 lmp.py:372]   Expert  3 |    121 | CPU
DEBUG 01-05 09:19:36.635179.635179 lmp.py:372]   Expert 60 |    125 | CPU
DEBUG 01-05 09:19:36.635783.635783 lmp.py:372]   Expert 31 |    127 | CPU
DEBUG 01-05 09:19:36.635956.635956 lmp.py:372]   Expert 30 |    132 | CPU
DEBUG 01-05 09:19:36.635605.635605 lmp.py:372]   Expert 46 |    135 | CPU
DEBUG 01-05 09:19:36.635639.635639 lmp.py:372]   Expert 50 |    140 | CPU
DEBUG 01-05 09:19:36.635528.635528 lmp.py:372]   Expert 63 |    143 | CPU
DEBUG 01-05 09:19:36.635939.635939 lmp.py:372]   Expert 24 |    147 | CPU
DEBUG 01-05 09:19:36.635589.635589 lmp.py:372]   Expert 61 |    147 | CPU
DEBUG 01-05 09:19:36.635954.635954 lmp.py:372]   Expert  6 |    151 | CPU
DEBUG 01-05 09:19:36.635703.635703 lmp.py:372]   Expert 56 |    152 | CPU
DEBUG 01-05 09:19:36.635114.635114 lmp.py:372]   Expert 59 |    155 | CPU
DEBUG 01-05 09:19:36.635002.635002 lmp.py:372]   Expert 49 |    159 | CPU
DEBUG 01-05 09:19:36.635652.635652 lmp.py:372]   Expert 58 |    161 | CPU
DEBUG 01-05 09:19:36.635448.635448 lmp.py:372]   Expert  2 |    162 | CPU
DEBUG 01-05 09:19:36.635859.635859 lmp.py:372]   Expert 16 |    163 | CPU
DEBUG 01-05 09:19:36.635463.635463 lmp.py:372]   Expert 34 |    165 | CPU
DEBUG 01-05 09:19:36.635828.635828 lmp.py:372]   Expert 53 |    170 | CPU
DEBUG 01-05 09:19:36.635146.635146 lmp.py:372]   Expert 11 |    178 | CPU
DEBUG 01-05 09:19:36.635796.635796 lmp.py:372]   Expert 15 |    188 | GPU
DEBUG 01-05 09:19:36.635969.635969 lmp.py:372]   Expert 10 |    189 | GPU
DEBUG 01-05 09:19:36.635380.635380 lmp.py:372]   Expert 18 |    190 | GPU
DEBUG 01-05 09:19:36.635984.635984 lmp.py:372]   Expert 21 |    194 | GPU
DEBUG 01-05 09:19:36.635779.635779 lmp.py:372]   Expert 33 |    194 | GPU
DEBUG 01-05 09:19:36.635191.635191 lmp.py:372]   Expert 29 |    195 | GPU
DEBUG 01-05 09:19:36.635602.635602 lmp.py:372]   Expert 37 |    195 | GPU
DEBUG 01-05 09:19:36.635775.635775 lmp.py:372]   Expert 43 |    195 | GPU
DEBUG 01-05 09:19:36.635855.635855 lmp.py:372]   Expert 32 |    211 | GPU
DEBUG 01-05 09:19:36.635174.635174 lmp.py:372]   Expert 13 |    227 | GPU
DEBUG 01-05 09:19:36.635016.635016 lmp.py:372]   Expert 44 |    232 | GPU
DEBUG 01-05 09:19:36.635665.635665 lmp.py:372]   Expert 20 |    233 | GPU
DEBUG 01-05 09:19:36.636223.636223 lmp.py:372]   Expert  0 |    235 | GPU
DEBUG 01-05 09:19:36.636064.636064 lmp.py:372]   Expert 42 |    237 | GPU
DEBUG 01-05 09:19:36.636714.636714 lmp.py:372]   Expert 35 |    238 | GPU
DEBUG 01-05 09:19:36.636602.636602 lmp.py:372]   Expert 57 |    243 | GPU
DEBUG 01-05 09:19:36.636967.636967 lmp.py:372]   Expert 51 |    256 | GPU
DEBUG 01-05 09:19:36.636240.636240 lmp.py:372]   Expert  9 |    257 | GPU
DEBUG 01-05 09:19:36.636651.636651 lmp.py:372]   Expert  5 |    273 | GPU
DEBUG 01-05 09:19:36.636062.636062 lmp.py:372]   Expert 38 |    274 | GPU
DEBUG 01-05 09:19:36.636474.636474 lmp.py:372]   Expert 22 |    276 | GPU
DEBUG 01-05 09:19:36.636269.636269 lmp.py:372]   Expert 19 |    279 | GPU
DEBUG 01-05 09:19:36.636588.636588 lmp.py:372]   Expert 23 |    285 | GPU
DEBUG 01-05 09:19:36.636192.636192 lmp.py:372]   Expert 62 |    298 | GPU
DEBUG 01-05 09:19:36.636603.636603 lmp.py:372]   Expert 48 |    300 | GPU
DEBUG 01-05 09:19:36.636206.636206 lmp.py:372]   Expert 12 |    312 | GPU
DEBUG 01-05 09:19:36.636094.636094 lmp.py:372]   Expert  4 |    318 | GPU
DEBUG 01-05 09:19:36.636267.636267 lmp.py:372]   Expert 45 |    328 | GPU
DEBUG 01-05 09:19:36.636593.636593 lmp.py:372]   Expert 26 |    330 | GPU
DEBUG 01-05 09:19:36.636719.636719 lmp.py:372]   Expert 41 |    362 | GPU
DEBUG 01-05 09:19:36.636561.636561 lmp.py:372]   Expert 55 |    390 | GPU
DEBUG 01-05 09:19:36.636118.636118 lmp.py:372]   Expert 17 |    473 | GPU
DEBUG 01-05 09:19:36.636437.636437 lmp.py:373] 
DEBUG 01-05 09:19:36.636437.636437 lmp.py:373]   CPU total tokens: 3881 (31.6%)
DEBUG 01-05 09:19:36.636802.636802 lmp.py:374]   GPU total tokens: 8407 (68.4%)
DEBUG 01-05 09:19:36.636366.636366 cuda_h.py:19] end experts_map_get cost 0.0020971298217773438 seconds
DEBUG 01-05 09:19:36.636354.636354 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.636819.636819 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.636620.636620 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.637054.637054 cuda_h.py:19] end allocate_cuda_memory cost 0.0002765655517578125 seconds
DEBUG 01-05 09:19:36.637540.637540 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.637217.637217 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.637239.637239 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.637571.637571 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ed94fc4-c706-4018-a8b8-51388ec36497
DEBUG 01-05 09:19:36.637883.637883 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.639254.639254 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ed94fc4-c706-4018-a8b8-51388ec36497
DEBUG 01-05 09:19:36.639912.639912 cuda_h.py:19] end load_into_gpu_async cost 0.0021622180938720703 seconds
DEBUG 01-05 09:19:36.639337.639337 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.639119.639119 cuda_h.py:19] end restore_tensors2 cost 0.0003676414489746094 seconds
DEBUG 01-05 09:19:36.639478.639478 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00322723388671875 seconds
DEBUG 01-05 09:19:36.642137.642137 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005952358245849609 seconds
DEBUG 01-05 09:19:36.642635.642635 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.642426.642426 lmp.py:419] 
DEBUG 01-05 09:19:36.642426.642426 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.642462.642462 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-05 09:19:36.642065.642065 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.654632.654632 mlpmodule.py:704] group tensors cost 0.011627912521362305 s
DEBUG 01-05 09:19:36.657694.657694 mlpmodule.py:742] pad cost 0.0017402172088623047 s
DEBUG 01-05 09:19:36.657850.657850 mlpmodule.py:748] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-05 09:19:36.657614.657614 mlpmodule.py:753] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-05 09:19:36.672361.672361 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.672592.672592 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.673396.673396 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 09:19:36.673957.673957 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.694764.694764 mlpmodule.py:793] group einsum cost 0.03682756423950195 s
DEBUG 01-05 09:19:36.695191.695191 mlpmodule.py:801] cpy2cputensor cost 0.0008864402770996094 s
DEBUG 01-05 09:19:36.738962.738962 cuda_h.py:19] end wait_cetm_experts cost 0.09598183631896973 seconds
DEBUG 01-05 09:19:36.738038.738038 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.739971.739971 cuda_h.py:19] end gpu_sexperts cost 0.0005033016204833984 seconds
DEBUG 01-05 09:19:36.739098.739098 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:19:36.739345.739345 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:19:36.739592.739592 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.4809112548828125e-05 seconds
DEBUG 01-05 09:19:36.739302.739302 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.43865966796875e-05 seconds
DEBUG 01-05 09:19:36.739906.739906 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.739423.739423 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ed94fc4-c706-4018-a8b8-51388ec36497
DEBUG 01-05 09:19:36.739372.739372 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.740063.740063 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.740611.740611 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.744497.744497 cuda_h.py:19] end allocate_cuda_memory cost 0.0035538673400878906 seconds
INFO 01-05 09:19:36.744259.744259 client.py:127] Model loaded
DEBUG 01-05 09:19:36.744021.744021 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.744562.744562 cuda_h.py:19] end wait_experts cost 0.004930973052978516 seconds
DEBUG 01-05 09:19:36.744619.744619 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.744544.744544 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.745152.745152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.745889.745889 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 231d1cb3-472f-409a-8610-61490e5f7308
DEBUG 01-05 09:19:36.745963.745963 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.745322.745322 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.749123.749123 mlpmodule.py:531] gpu group tensors cost 0.0006191730499267578 s
DEBUG 01-05 09:19:36.751971.751971 mlpmodule.py:564] gpu pad cost 0.0017008781433105469 s
DEBUG 01-05 09:19:36.751991.751991 mlpmodule.py:582] gpu group einsum cost 0.0005309581756591797 s
DEBUG 01-05 09:19:36.753847.753847 mlpmodule.py:662]  experts func einsum cost 0.1108255386352539 s
INFO 01-05 09:19:36.754571.754571 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 231d1cb3-472f-409a-8610-61490e5f7308
DEBUG 01-05 09:19:36.754299.754299 cuda_h.py:19] end load_into_gpu_async cost 0.009420156478881836 seconds
DEBUG 01-05 09:19:36.754316.754316 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.754563.754563 cuda_h.py:19] end restore_tensors2 cost 0.0001671314239501953 seconds
DEBUG 01-05 09:19:36.754911.754911 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014351844787597656 seconds
INFO 01-05 09:19:36.756116.756116 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 231d1cb3-472f-409a-8610-61490e5f7308
DEBUG 01-05 09:19:36.757717.757717 mlpmodule.py:611] gpu experts func einsum cost 0.008677959442138672 s
DEBUG 01-05 09:19:36.757463.757463 cuda_h.py:19] end gpu_experts cost 0.012550115585327148 seconds
DEBUG 01-05 09:19:36.757888.757888 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:36.758553.758553 client.py:127] Model loaded
DEBUG 01-05 09:19:36.758240.758240 cuda_h.py:19] end sllm_worker_task cost 0.01798558235168457 seconds
DEBUG 01-05 09:19:36.758187.758187 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0005626678466796875 seconds
DEBUG 01-05 09:19:36.758750.758750 cuda_h.py:19] end layer_moe_generate_17 cost 0.12495779991149902 seconds
DEBUG 01-05 09:19:36.758908.758908 lmp.py:214] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 09:19:36.758870.758870 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 09:19:36.758328.758328 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.759358.759358 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.761013.761013 cuda_h.py:19] end self_attn cost 0.002494335174560547 seconds
DEBUG 01-05 09:19:36.761228.761228 cuda_h.py:19] end iln_self_attn_paln cost 0.003126859664916992 seconds
DEBUG 01-05 09:19:36.762807.762807 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 09:19:36.762523.762523 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.762127.762127 cuda_h.py:19] end gate cost 0.0005857944488525391 seconds
DEBUG 01-05 09:19:36.762287.762287 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.763708.763708 lmp.py:361] 
DEBUG 01-05 09:19:36.763708.763708 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.763895.763895 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.763498.763498 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.763241.763241 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.763268.763268 lmp.py:365] 
DEBUG 01-05 09:19:36.763268.763268 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.763911.763911 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.763276.763276 lmp.py:372]   Expert 35 |     49 | CPU
DEBUG 01-05 09:19:36.763157.763157 lmp.py:372]   Expert  0 |     51 | CPU
DEBUG 01-05 09:19:36.763846.763846 lmp.py:372]   Expert 58 |     65 | CPU
DEBUG 01-05 09:19:36.763920.763920 lmp.py:372]   Expert 53 |     66 | CPU
DEBUG 01-05 09:19:36.763609.763609 lmp.py:372]   Expert 19 |     67 | CPU
DEBUG 01-05 09:19:36.763014.763014 lmp.py:372]   Expert 54 |     70 | CPU
DEBUG 01-05 09:19:36.763180.763180 lmp.py:372]   Expert  3 |     74 | CPU
DEBUG 01-05 09:19:36.763631.763631 lmp.py:372]   Expert 20 |     81 | CPU
DEBUG 01-05 09:19:36.763559.763559 lmp.py:372]   Expert 34 |     87 | CPU
DEBUG 01-05 09:19:36.763155.763155 lmp.py:372]   Expert 41 |     91 | CPU
DEBUG 01-05 09:19:36.763368.763368 lmp.py:372]   Expert 12 |     92 | CPU
DEBUG 01-05 09:19:36.763819.763819 lmp.py:372]   Expert 37 |     93 | CPU
DEBUG 01-05 09:19:36.763269.763269 lmp.py:372]   Expert 40 |     93 | CPU
DEBUG 01-05 09:19:36.763959.763959 lmp.py:372]   Expert 63 |     96 | CPU
DEBUG 01-05 09:19:36.763363.763363 lmp.py:372]   Expert  6 |     98 | CPU
DEBUG 01-05 09:19:36.763529.763529 lmp.py:372]   Expert 60 |    101 | CPU
DEBUG 01-05 09:19:36.763888.763888 lmp.py:372]   Expert 43 |    107 | CPU
DEBUG 01-05 09:19:36.763815.763815 lmp.py:372]   Expert  8 |    110 | CPU
DEBUG 01-05 09:19:36.763789.763789 lmp.py:372]   Expert 32 |    110 | CPU
DEBUG 01-05 09:19:36.763763.763763 lmp.py:372]   Expert 46 |    110 | CPU
DEBUG 01-05 09:19:36.763214.763214 lmp.py:372]   Expert 30 |    114 | CPU
DEBUG 01-05 09:19:36.763188.763188 lmp.py:372]   Expert 48 |    121 | CPU
DEBUG 01-05 09:19:36.763547.763547 lmp.py:372]   Expert 44 |    124 | CPU
DEBUG 01-05 09:19:36.763759.763759 lmp.py:372]   Expert 17 |    126 | CPU
DEBUG 01-05 09:19:36.763972.763972 lmp.py:372]   Expert 33 |    136 | CPU
DEBUG 01-05 09:19:36.763138.763138 lmp.py:372]   Expert 29 |    138 | CPU
DEBUG 01-05 09:19:36.763304.763304 lmp.py:372]   Expert 45 |    141 | CPU
DEBUG 01-05 09:19:36.763278.763278 lmp.py:372]   Expert  5 |    142 | CPU
DEBUG 01-05 09:19:36.763875.763875 lmp.py:372]   Expert  4 |    147 | CPU
DEBUG 01-05 09:19:36.763087.763087 lmp.py:372]   Expert 13 |    147 | CPU
DEBUG 01-05 09:19:36.763538.763538 lmp.py:372]   Expert 25 |    152 | CPU
DEBUG 01-05 09:19:36.763750.763750 lmp.py:372]   Expert 55 |    152 | CPU
DEBUG 01-05 09:19:36.763201.763201 lmp.py:372]   Expert 11 |    168 | GPU
DEBUG 01-05 09:19:36.763414.763414 lmp.py:372]   Expert 27 |    170 | GPU
DEBUG 01-05 09:19:36.763341.763341 lmp.py:372]   Expert 39 |    174 | GPU
DEBUG 01-05 09:19:36.763269.763269 lmp.py:372]   Expert 18 |    176 | GPU
DEBUG 01-05 09:19:36.763866.763866 lmp.py:372]   Expert 42 |    186 | GPU
DEBUG 01-05 09:19:36.763078.763078 lmp.py:372]   Expert 52 |    192 | GPU
DEBUG 01-05 09:19:36.763052.763052 lmp.py:372]   Expert 56 |    195 | GPU
DEBUG 01-05 09:19:36.763788.763788 lmp.py:372]   Expert 24 |    200 | GPU
DEBUG 01-05 09:19:36.763000.763000 lmp.py:372]   Expert 22 |    207 | GPU
DEBUG 01-05 09:19:36.763974.763974 lmp.py:372]   Expert 50 |    211 | GPU
DEBUG 01-05 09:19:36.763094.763094 lmp.py:372]   Expert  9 |    212 | GPU
DEBUG 01-05 09:19:36.763783.763783 lmp.py:372]   Expert  1 |    215 | GPU
DEBUG 01-05 09:19:36.763473.763473 lmp.py:372]   Expert  7 |    215 | GPU
DEBUG 01-05 09:19:36.763924.763924 lmp.py:372]   Expert 51 |    221 | GPU
DEBUG 01-05 09:19:36.763136.763136 lmp.py:372]   Expert 59 |    226 | GPU
DEBUG 01-05 09:19:36.763872.763872 lmp.py:372]   Expert 61 |    247 | GPU
DEBUG 01-05 09:19:36.764468.764468 lmp.py:372]   Expert 16 |    254 | GPU
DEBUG 01-05 09:19:36.764442.764442 lmp.py:372]   Expert 31 |    258 | GPU
DEBUG 01-05 09:19:36.764417.764417 lmp.py:372]   Expert 47 |    273 | GPU
DEBUG 01-05 09:19:36.764152.764152 lmp.py:372]   Expert 57 |    277 | GPU
DEBUG 01-05 09:19:36.764318.764318 lmp.py:372]   Expert 28 |    278 | GPU
DEBUG 01-05 09:19:36.764008.764008 lmp.py:372]   Expert 21 |    285 | GPU
DEBUG 01-05 09:19:36.764366.764366 lmp.py:372]   Expert 14 |    309 | GPU
DEBUG 01-05 09:19:36.764340.764340 lmp.py:372]   Expert 38 |    313 | GPU
DEBUG 01-05 09:19:36.764791.764791 lmp.py:372]   Expert 10 |    343 | GPU
DEBUG 01-05 09:19:36.764765.764765 lmp.py:372]   Expert  2 |    349 | GPU
DEBUG 01-05 09:19:36.764739.764739 lmp.py:372]   Expert 15 |    351 | GPU
DEBUG 01-05 09:19:36.764190.764190 lmp.py:372]   Expert 49 |    372 | GPU
DEBUG 01-05 09:19:36.764071.764071 lmp.py:372]   Expert 36 |    399 | GPU
DEBUG 01-05 09:19:36.764760.764760 lmp.py:372]   Expert 26 |    465 | GPU
DEBUG 01-05 09:19:36.764734.764734 lmp.py:372]   Expert 23 |    482 | GPU
DEBUG 01-05 09:19:36.764708.764708 lmp.py:372]   Expert 62 |    714 | GPU
DEBUG 01-05 09:19:36.764636.764636 lmp.py:373] 
DEBUG 01-05 09:19:36.764636.764636 lmp.py:373]   CPU total tokens: 3351 (27.3%)
DEBUG 01-05 09:19:36.764994.764994 lmp.py:374]   GPU total tokens: 8937 (72.7%)
DEBUG 01-05 09:19:36.764929.764929 cuda_h.py:19] end experts_map_get cost 0.00153350830078125 seconds
DEBUG 01-05 09:19:36.764810.764810 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.764640.764640 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.764175.764175 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.764337.764337 cuda_h.py:19] end allocate_cuda_memory cost 0.00026154518127441406 seconds
DEBUG 01-05 09:19:36.764663.764663 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.764850.764850 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.764666.764666 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.764938.764938 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 39c97702-2846-4936-b7eb-a7d0c9506f0b
DEBUG 01-05 09:19:36.765534.765534 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.766708.766708 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 39c97702-2846-4936-b7eb-a7d0c9506f0b
DEBUG 01-05 09:19:36.766968.766968 cuda_h.py:19] end load_into_gpu_async cost 0.0013527870178222656 seconds
DEBUG 01-05 09:19:36.766525.766525 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.766821.766821 cuda_h.py:19] end restore_tensors2 cost 0.0002980232238769531 seconds
DEBUG 01-05 09:19:36.766451.766451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002252817153930664 seconds
DEBUG 01-05 09:19:36.769759.769759 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00495457649230957 seconds
DEBUG 01-05 09:19:36.769780.769780 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.769849.769849 lmp.py:419] 
DEBUG 01-05 09:19:36.769849.769849 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.769507.769507 cuda_h.py:19] end cpu_experts_submit cost 0.0001201629638671875 seconds
DEBUG 01-05 09:19:36.769541.769541 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.775657.775657 mlpmodule.py:704] group tensors cost 0.006296873092651367 s
DEBUG 01-05 09:19:36.779379.779379 mlpmodule.py:742] pad cost 0.0023064613342285156 s
DEBUG 01-05 09:19:36.779954.779954 mlpmodule.py:748] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-05 09:19:36.779175.779175 mlpmodule.py:753] move to cpu cost 3.886222839355469e-05 s
DEBUG 01-05 09:19:36.791818.791818 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.792241.792241 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.792430.792430 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 09:19:36.792315.792315 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.812194.812194 mlpmodule.py:793] group einsum cost 0.03331589698791504 s
DEBUG 01-05 09:19:36.813223.813223 mlpmodule.py:801] cpy2cputensor cost 0.0006654262542724609 s
DEBUG 01-05 09:19:36.854059.854059 cuda_h.py:19] end wait_cetm_experts cost 0.0848531723022461 seconds
DEBUG 01-05 09:19:36.854744.854744 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.855099.855099 cuda_h.py:19] end gpu_sexperts cost 0.0004665851593017578 seconds
DEBUG 01-05 09:19:36.855035.855035 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:19:36.855804.855804 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:19:36.855045.855045 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.4809112548828125e-05 seconds
DEBUG 01-05 09:19:36.855377.855377 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.367134094238281e-05 seconds
DEBUG 01-05 09:19:36.855126.855126 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.855167.855167 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 39c97702-2846-4936-b7eb-a7d0c9506f0b
DEBUG 01-05 09:19:36.855956.855956 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.855052.855052 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.855084.855084 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.859266.859266 cuda_h.py:19] end allocate_cuda_memory cost 0.003742694854736328 seconds
DEBUG 01-05 09:19:36.860392.860392 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.860919.860919 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.860611.860611 sllm_store_c.py:29] call client load into gpu
INFO 01-05 09:19:36.860405.860405 client.py:127] Model loaded
DEBUG 01-05 09:19:36.860606.860606 cuda_h.py:19] end wait_experts cost 0.0053594112396240234 seconds
DEBUG 01-05 09:19:36.860654.860654 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:36.860748.860748 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:36.860616.860616 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 52ece2ad-be20-4916-9a73-e57877c290ae
DEBUG 01-05 09:19:36.861753.861753 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:36.864186.864186 mlpmodule.py:531] gpu group tensors cost 0.004088640213012695 s
INFO 01-05 09:19:36.865989.865989 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 52ece2ad-be20-4916-9a73-e57877c290ae
DEBUG 01-05 09:19:36.865962.865962 cuda_h.py:19] end load_into_gpu_async cost 0.005645751953125 seconds
DEBUG 01-05 09:19:36.865031.865031 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.866788.866788 cuda_h.py:19] end restore_tensors2 cost 0.00016045570373535156 seconds
DEBUG 01-05 09:19:36.866725.866725 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010288000106811523 seconds
INFO 01-05 09:19:36.867321.867321 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 52ece2ad-be20-4916-9a73-e57877c290ae
DEBUG 01-05 09:19:36.868339.868339 mlpmodule.py:564] gpu pad cost 0.0038590431213378906 s
DEBUG 01-05 09:19:36.869518.869518 mlpmodule.py:662]  experts func einsum cost 0.09946990013122559 s
DEBUG 01-05 09:19:36.869534.869534 mlpmodule.py:582] gpu group einsum cost 0.0005440711975097656 s
DEBUG 01-05 09:19:36.872725.872725 mlpmodule.py:611] gpu experts func einsum cost 0.011695146560668945 s
DEBUG 01-05 09:19:36.872424.872424 cuda_h.py:19] end gpu_experts cost 0.01187753677368164 seconds
DEBUG 01-05 09:19:36.872134.872134 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:36.883510.883510 client.py:127] Model loaded
DEBUG 01-05 09:19:36.883255.883255 cuda_h.py:19] end sllm_worker_task cost 0.027841806411743164 seconds
DEBUG 01-05 09:19:36.883566.883566 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.011093616485595703 seconds
DEBUG 01-05 09:19:36.884904.884904 cuda_h.py:19] end layer_moe_generate_18 cost 0.1219472885131836 seconds
DEBUG 01-05 09:19:36.884946.884946 lmp.py:214] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 09:19:36.884903.884903 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 09:19:36.884475.884475 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:36.885109.885109 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:36.891862.891862 cuda_h.py:19] end self_attn cost 0.005919933319091797 seconds
DEBUG 01-05 09:19:36.892557.892557 cuda_h.py:19] end iln_self_attn_paln cost 0.007479190826416016 seconds
DEBUG 01-05 09:19:36.892847.892847 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 09:19:36.892672.892672 cuda_h.py:10] start gate
DEBUG 01-05 09:19:36.894041.894041 cuda_h.py:19] end gate cost 0.00139617919921875 seconds
DEBUG 01-05 09:19:36.894249.894249 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:36.894771.894771 lmp.py:361] 
DEBUG 01-05 09:19:36.894771.894771 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:36.894541.894541 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:36.894867.894867 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:36.894424.894424 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:36.894358.894358 lmp.py:365] 
DEBUG 01-05 09:19:36.894358.894358 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:36.894769.894769 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:36.894287.894287 lmp.py:372]   Expert 60 |     45 | CPU
DEBUG 01-05 09:19:36.894844.894844 lmp.py:372]   Expert 56 |     57 | CPU
DEBUG 01-05 09:19:36.894686.894686 lmp.py:372]   Expert 12 |     68 | CPU
DEBUG 01-05 09:19:36.894097.894097 lmp.py:372]   Expert  5 |     69 | CPU
DEBUG 01-05 09:19:36.894270.894270 lmp.py:372]   Expert 55 |     73 | CPU
DEBUG 01-05 09:19:36.894304.894304 lmp.py:372]   Expert 44 |     79 | CPU
DEBUG 01-05 09:19:36.894239.894239 lmp.py:372]   Expert  6 |     85 | CPU
DEBUG 01-05 09:19:36.894696.894696 lmp.py:372]   Expert 48 |     86 | CPU
DEBUG 01-05 09:19:36.894393.894393 lmp.py:372]   Expert 59 |     91 | CPU
DEBUG 01-05 09:19:36.894234.894234 lmp.py:372]   Expert 18 |     93 | CPU
DEBUG 01-05 09:19:36.894407.894407 lmp.py:372]   Expert 23 |    101 | CPU
DEBUG 01-05 09:19:36.894103.894103 lmp.py:372]   Expert 30 |    104 | CPU
DEBUG 01-05 09:19:36.894515.894515 lmp.py:372]   Expert 42 |    105 | CPU
DEBUG 01-05 09:19:36.894641.894641 lmp.py:372]   Expert 52 |    106 | CPU
DEBUG 01-05 09:19:36.894006.894006 lmp.py:372]   Expert 27 |    108 | CPU
DEBUG 01-05 09:19:36.895941.895941 lmp.py:372]   Expert 33 |    110 | CPU
DEBUG 01-05 09:19:36.895260.895260 lmp.py:372]   Expert 34 |    119 | CPU
DEBUG 01-05 09:19:36.895717.895717 lmp.py:372]   Expert 24 |    128 | CPU
DEBUG 01-05 09:19:36.895175.895175 lmp.py:372]   Expert 32 |    141 | CPU
DEBUG 01-05 09:19:36.895109.895109 lmp.py:372]   Expert 54 |    143 | CPU
DEBUG 01-05 09:19:36.895190.895190 lmp.py:372]   Expert 15 |    144 | CPU
DEBUG 01-05 09:19:36.895647.895647 lmp.py:372]   Expert 57 |    145 | CPU
DEBUG 01-05 09:19:36.895536.895536 lmp.py:372]   Expert 62 |    145 | CPU
DEBUG 01-05 09:19:36.895662.895662 lmp.py:372]   Expert 58 |    151 | CPU
DEBUG 01-05 09:19:36.895550.895550 lmp.py:372]   Expert 63 |    152 | CPU
DEBUG 01-05 09:19:36.895246.895246 lmp.py:372]   Expert  8 |    154 | CPU
DEBUG 01-05 09:19:36.895327.895327 lmp.py:372]   Expert 17 |    154 | CPU
DEBUG 01-05 09:19:36.895546.895546 lmp.py:372]   Expert 13 |    157 | CPU
DEBUG 01-05 09:19:36.895527.895527 lmp.py:372]   Expert 26 |    158 | CPU
DEBUG 01-05 09:19:36.895508.895508 lmp.py:372]   Expert 46 |    158 | CPU
DEBUG 01-05 09:19:36.895350.895350 lmp.py:372]   Expert 16 |    160 | CPU
DEBUG 01-05 09:19:36.895284.895284 lmp.py:372]   Expert  1 |    161 | CPU
DEBUG 01-05 09:19:36.895695.895695 lmp.py:372]   Expert  0 |    163 | GPU
DEBUG 01-05 09:19:36.895584.895584 lmp.py:372]   Expert 49 |    164 | GPU
DEBUG 01-05 09:19:36.895518.895518 lmp.py:372]   Expert 43 |    177 | GPU
DEBUG 01-05 09:19:36.895499.895499 lmp.py:372]   Expert 47 |    184 | GPU
DEBUG 01-05 09:19:36.895533.895533 lmp.py:372]   Expert 39 |    185 | GPU
DEBUG 01-05 09:19:36.895183.895183 lmp.py:372]   Expert 19 |    189 | GPU
DEBUG 01-05 09:19:36.895071.895071 lmp.py:372]   Expert  4 |    194 | GPU
DEBUG 01-05 09:19:36.895959.895959 lmp.py:372]   Expert 40 |    197 | GPU
DEBUG 01-05 09:19:36.895231.895231 lmp.py:372]   Expert 25 |    201 | GPU
DEBUG 01-05 09:19:36.895881.895881 lmp.py:372]   Expert 53 |    206 | GPU
DEBUG 01-05 09:19:36.895292.895292 lmp.py:372]   Expert 50 |    210 | GPU
DEBUG 01-05 09:19:36.895942.895942 lmp.py:372]   Expert 37 |    215 | GPU
DEBUG 01-05 09:19:36.895354.895354 lmp.py:372]   Expert 35 |    221 | GPU
DEBUG 01-05 09:19:36.895195.895195 lmp.py:372]   Expert 22 |    224 | GPU
DEBUG 01-05 09:19:36.895415.895415 lmp.py:372]   Expert 20 |    226 | GPU
DEBUG 01-05 09:19:36.895396.895396 lmp.py:372]   Expert 14 |    227 | GPU
DEBUG 01-05 09:19:36.895376.895376 lmp.py:372]   Expert 11 |    244 | GPU
DEBUG 01-05 09:19:36.895457.895457 lmp.py:372]   Expert 41 |    254 | GPU
DEBUG 01-05 09:19:36.895630.895630 lmp.py:372]   Expert 51 |    268 | GPU
DEBUG 01-05 09:19:36.895279.895279 lmp.py:372]   Expert 38 |    275 | GPU
DEBUG 01-05 09:19:36.895691.895691 lmp.py:372]   Expert 28 |    282 | GPU
DEBUG 01-05 09:19:36.895771.895771 lmp.py:372]   Expert 21 |    293 | GPU
DEBUG 01-05 09:19:36.895752.895752 lmp.py:372]   Expert 36 |    298 | GPU
DEBUG 01-05 09:19:36.895733.895733 lmp.py:372]   Expert 10 |    321 | GPU
DEBUG 01-05 09:19:36.895713.895713 lmp.py:372]   Expert 45 |    329 | GPU
DEBUG 01-05 09:19:36.895363.895363 lmp.py:372]   Expert  2 |    353 | GPU
DEBUG 01-05 09:19:36.895298.895298 lmp.py:372]   Expert  9 |    362 | GPU
DEBUG 01-05 09:19:36.895279.895279 lmp.py:372]   Expert 61 |    364 | GPU
DEBUG 01-05 09:19:36.896259.896259 lmp.py:372]   Expert  3 |    378 | GPU
DEBUG 01-05 09:19:36.896671.896671 lmp.py:372]   Expert 31 |    401 | GPU
DEBUG 01-05 09:19:36.896082.896082 lmp.py:372]   Expert 29 |    402 | GPU
DEBUG 01-05 09:19:36.896493.896493 lmp.py:372]   Expert  7 |    531 | GPU
DEBUG 01-05 09:19:36.896335.896335 lmp.py:373] 
DEBUG 01-05 09:19:36.896335.896335 lmp.py:373]   CPU total tokens: 3750 (30.5%)
DEBUG 01-05 09:19:36.896462.896462 lmp.py:374]   GPU total tokens: 8538 (69.5%)
DEBUG 01-05 09:19:36.896880.896880 cuda_h.py:19] end experts_map_get cost 0.002010822296142578 seconds
DEBUG 01-05 09:19:36.896768.896768 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:36.896803.896803 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.896511.896511 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.896285.896285 cuda_h.py:19] end allocate_cuda_memory cost 0.0003135204315185547 seconds
DEBUG 01-05 09:19:36.896102.896102 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.896202.896202 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.896747.896747 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.896364.896364 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4b94fd5e-8c51-4a88-8fd4-bcdc35492f52
DEBUG 01-05 09:19:36.897438.897438 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:36.899369.899369 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4b94fd5e-8c51-4a88-8fd4-bcdc35492f52
DEBUG 01-05 09:19:36.899503.899503 cuda_h.py:19] end load_into_gpu_async cost 0.002257823944091797 seconds
DEBUG 01-05 09:19:36.899643.899643 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:36.899796.899796 cuda_h.py:19] end restore_tensors2 cost 0.00035953521728515625 seconds
DEBUG 01-05 09:19:36.899109.899109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003355264663696289 seconds
DEBUG 01-05 09:19:36.902871.902871 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006783246994018555 seconds
DEBUG 01-05 09:19:36.903621.903621 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:36.903604.903604 lmp.py:419] 
DEBUG 01-05 09:19:36.903604.903604 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:36.903653.903653 cuda_h.py:19] end cpu_experts_submit cost 0.00012731552124023438 seconds
DEBUG 01-05 09:19:36.903455.903455 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:36.914506.914506 mlpmodule.py:704] group tensors cost 0.011363983154296875 s
DEBUG 01-05 09:19:36.917506.917506 mlpmodule.py:742] pad cost 0.0020341873168945312 s
DEBUG 01-05 09:19:36.917106.917106 mlpmodule.py:748] create cpu tensor cost 4.982948303222656e-05 s
DEBUG 01-05 09:19:36.917029.917029 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-05 09:19:36.931241.931241 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:36.931134.931134 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:36.931846.931846 mlpmodule.py:773] group_w3 first element: 0.051513671875
WARNING 01-05 09:19:36.931353.931353 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:36.952328.952328 mlpmodule.py:793] group einsum cost 0.03416299819946289 s
DEBUG 01-05 09:19:36.953280.953280 mlpmodule.py:801] cpy2cputensor cost 0.0009093284606933594 s
DEBUG 01-05 09:19:36.993774.993774 cuda_h.py:19] end wait_cetm_experts cost 0.08975768089294434 seconds
DEBUG 01-05 09:19:36.993558.993558 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:36.993118.993118 cuda_h.py:19] end gpu_sexperts cost 0.0004773139953613281 seconds
DEBUG 01-05 09:19:36.993293.993293 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:19:36.993493.993493 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:19:36.993588.993588 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 09:19:36.993450.993450 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.796287536621094e-05 seconds
DEBUG 01-05 09:19:36.993722.993722 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:36.993008.993008 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4b94fd5e-8c51-4a88-8fd4-bcdc35492f52
DEBUG 01-05 09:19:36.994894.994894 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:36.994771.994771 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:36.994184.994184 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:36.998825.998825 cuda_h.py:19] end allocate_cuda_memory cost 0.0038726329803466797 seconds
DEBUG 01-05 09:19:36.998695.998695 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:36.998365.998365 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:36.998387.998387 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:36.998712.998712 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3bc6d3f0-daf3-4837-9eea-aee1a3e66f27
DEBUG 01-05 09:19:36.998656.998656 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.002607.002607 client.py:127] Model loaded
DEBUG 01-05 09:19:37.002887.002887 cuda_h.py:19] end wait_experts cost 0.00904226303100586 seconds
DEBUG 01-05 09:19:37.003736.003736 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.003776.003776 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:37.003192.003192 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3bc6d3f0-daf3-4837-9eea-aee1a3e66f27
DEBUG 01-05 09:19:37.003917.003917 cuda_h.py:19] end load_into_gpu_async cost 0.005387544631958008 seconds
DEBUG 01-05 09:19:37.003726.003726 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.003035.003035 cuda_h.py:19] end restore_tensors2 cost 9.131431579589844e-05 seconds
DEBUG 01-05 09:19:37.003605.003605 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009640932083129883 seconds
DEBUG 01-05 09:19:37.004612.004612 mlpmodule.py:531] gpu group tensors cost 0.001129150390625 s
INFO 01-05 09:19:37.004611.004611 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3bc6d3f0-daf3-4837-9eea-aee1a3e66f27
DEBUG 01-05 09:19:37.006932.006932 mlpmodule.py:564] gpu pad cost 0.0019481182098388672 s
DEBUG 01-05 09:19:37.006641.006641 mlpmodule.py:582] gpu group einsum cost 0.0005023479461669922 s
DEBUG 01-05 09:19:37.010355.010355 mlpmodule.py:611] gpu experts func einsum cost 0.006908893585205078 s
DEBUG 01-05 09:19:37.010465.010465 cuda_h.py:19] end gpu_experts cost 0.0071103572845458984 seconds
DEBUG 01-05 09:19:37.010036.010036 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:37.010171.010171 mlpmodule.py:662]  experts func einsum cost 0.10721683502197266 s
INFO 01-05 09:19:37.013537.013537 client.py:127] Model loaded
DEBUG 01-05 09:19:37.013903.013903 cuda_h.py:19] end sllm_worker_task cost 0.01895594596862793 seconds
DEBUG 01-05 09:19:37.013428.013428 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0029938220977783203 seconds
DEBUG 01-05 09:19:37.013606.013606 cuda_h.py:19] end layer_moe_generate_19 cost 0.12086963653564453 seconds
DEBUG 01-05 09:19:37.013003.013003 lmp.py:214] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 09:19:37.013249.013249 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 09:19:37.013469.013469 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.013003.013003 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.016427.016427 cuda_h.py:19] end self_attn cost 0.0025365352630615234 seconds
DEBUG 01-05 09:19:37.016060.016060 cuda_h.py:19] end iln_self_attn_paln cost 0.0031785964965820312 seconds
DEBUG 01-05 09:19:37.016618.016618 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 09:19:37.016242.016242 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.017244.017244 cuda_h.py:19] end gate cost 0.0006339550018310547 seconds
DEBUG 01-05 09:19:37.017405.017405 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.017528.017528 lmp.py:361] 
DEBUG 01-05 09:19:37.017528.017528 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.017714.017714 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.018079.018079 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.018345.018345 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.018418.018418 lmp.py:365] 
DEBUG 01-05 09:19:37.018418.018418 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.018300.018300 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.018526.018526 lmp.py:372]   Expert 54 |     47 | CPU
DEBUG 01-05 09:19:37.018884.018884 lmp.py:372]   Expert 28 |     54 | CPU
DEBUG 01-05 09:19:37.018573.018573 lmp.py:372]   Expert  8 |     66 | CPU
DEBUG 01-05 09:19:37.018931.018931 lmp.py:372]   Expert 13 |     74 | CPU
DEBUG 01-05 09:19:37.018859.018859 lmp.py:372]   Expert 43 |     75 | CPU
DEBUG 01-05 09:19:37.018072.018072 lmp.py:372]   Expert  1 |     79 | CPU
DEBUG 01-05 09:19:37.018761.018761 lmp.py:372]   Expert  6 |     79 | CPU
DEBUG 01-05 09:19:37.018212.018212 lmp.py:372]   Expert 36 |     90 | CPU
DEBUG 01-05 09:19:37.018616.018616 lmp.py:372]   Expert 42 |     90 | CPU
DEBUG 01-05 09:19:37.018590.018590 lmp.py:372]   Expert 12 |     96 | CPU
DEBUG 01-05 09:19:37.018710.018710 lmp.py:372]   Expert 33 |     96 | CPU
DEBUG 01-05 09:19:37.018399.018399 lmp.py:372]   Expert 10 |    109 | CPU
DEBUG 01-05 09:19:37.018612.018612 lmp.py:372]   Expert 51 |    111 | CPU
DEBUG 01-05 09:19:37.018824.018824 lmp.py:372]   Expert 19 |    113 | CPU
DEBUG 01-05 09:19:37.018037.018037 lmp.py:372]   Expert 14 |    114 | CPU
DEBUG 01-05 09:19:37.018726.018726 lmp.py:372]   Expert 11 |    125 | CPU
DEBUG 01-05 09:19:37.018607.018607 lmp.py:372]   Expert 46 |    125 | CPU
DEBUG 01-05 09:19:37.018535.018535 lmp.py:372]   Expert 57 |    125 | CPU
DEBUG 01-05 09:19:37.018748.018748 lmp.py:372]   Expert 30 |    128 | CPU
DEBUG 01-05 09:19:37.018199.018199 lmp.py:372]   Expert 38 |    129 | CPU
DEBUG 01-05 09:19:37.018411.018411 lmp.py:372]   Expert 39 |    131 | CPU
DEBUG 01-05 09:19:37.018623.018623 lmp.py:372]   Expert  9 |    135 | CPU
DEBUG 01-05 09:19:37.018790.018790 lmp.py:372]   Expert 50 |    135 | CPU
DEBUG 01-05 09:19:37.018909.018909 lmp.py:372]   Expert 49 |    148 | CPU
DEBUG 01-05 09:19:37.018599.018599 lmp.py:372]   Expert  7 |    153 | CPU
DEBUG 01-05 09:19:37.018811.018811 lmp.py:372]   Expert 29 |    155 | CPU
DEBUG 01-05 09:19:37.018024.018024 lmp.py:372]   Expert 52 |    157 | CPU
DEBUG 01-05 09:19:37.018475.018475 lmp.py:372]   Expert 63 |    157 | CPU
DEBUG 01-05 09:19:37.018925.018925 lmp.py:372]   Expert  3 |    162 | CPU
DEBUG 01-05 09:19:37.018807.018807 lmp.py:372]   Expert 20 |    166 | CPU
DEBUG 01-05 09:19:37.018258.018258 lmp.py:372]   Expert 61 |    166 | CPU
DEBUG 01-05 09:19:37.018232.018232 lmp.py:372]   Expert  5 |    170 | CPU
DEBUG 01-05 09:19:37.018398.018398 lmp.py:372]   Expert 22 |    174 | GPU
DEBUG 01-05 09:19:37.018326.018326 lmp.py:372]   Expert 53 |    179 | GPU
DEBUG 01-05 09:19:37.018300.018300 lmp.py:372]   Expert 44 |    182 | GPU
DEBUG 01-05 09:19:37.018658.018658 lmp.py:372]   Expert 18 |    186 | GPU
DEBUG 01-05 09:19:37.018870.018870 lmp.py:372]   Expert 62 |    189 | GPU
DEBUG 01-05 09:19:37.018606.018606 lmp.py:372]   Expert 17 |    192 | GPU
DEBUG 01-05 09:19:37.018057.018057 lmp.py:372]   Expert 47 |    202 | GPU
DEBUG 01-05 09:19:37.018508.018508 lmp.py:372]   Expert  0 |    203 | GPU
DEBUG 01-05 09:19:37.018243.018243 lmp.py:372]   Expert 37 |    208 | GPU
DEBUG 01-05 09:19:37.018456.018456 lmp.py:372]   Expert  2 |    221 | GPU
DEBUG 01-05 09:19:37.018384.018384 lmp.py:372]   Expert 45 |    228 | GPU
DEBUG 01-05 09:19:37.018550.018550 lmp.py:372]   Expert 23 |    234 | GPU
DEBUG 01-05 09:19:37.018669.018669 lmp.py:372]   Expert 55 |    234 | GPU
DEBUG 01-05 09:19:37.018359.018359 lmp.py:372]   Expert 60 |    234 | GPU
DEBUG 01-05 09:19:37.018333.018333 lmp.py:372]   Expert 26 |    236 | GPU
DEBUG 01-05 09:19:37.018784.018784 lmp.py:372]   Expert 32 |    236 | GPU
DEBUG 01-05 09:19:37.018996.018996 lmp.py:372]   Expert 16 |    259 | GPU
DEBUG 01-05 09:19:37.018970.018970 lmp.py:372]   Expert 21 |    269 | GPU
DEBUG 01-05 09:19:37.018090.018090 lmp.py:372]   Expert 15 |    275 | GPU
DEBUG 01-05 09:19:37.018779.018779 lmp.py:372]   Expert 34 |    277 | GPU
DEBUG 01-05 09:19:37.018945.018945 lmp.py:372]   Expert 24 |    296 | GPU
DEBUG 01-05 09:19:37.018635.018635 lmp.py:372]   Expert 58 |    297 | GPU
DEBUG 01-05 09:19:37.018847.018847 lmp.py:372]   Expert 31 |    299 | GPU
DEBUG 01-05 09:19:37.019298.019298 lmp.py:372]   Expert 27 |    300 | GPU
DEBUG 01-05 09:19:37.019895.019895 lmp.py:372]   Expert  4 |    302 | GPU
DEBUG 01-05 09:19:37.019107.019107 lmp.py:372]   Expert 59 |    310 | GPU
DEBUG 01-05 09:19:37.019081.019081 lmp.py:372]   Expert 41 |    326 | GPU
DEBUG 01-05 09:19:37.019771.019771 lmp.py:372]   Expert 56 |    327 | GPU
DEBUG 01-05 09:19:37.019983.019983 lmp.py:372]   Expert 48 |    329 | GPU
DEBUG 01-05 09:19:37.019149.019149 lmp.py:372]   Expert 40 |    330 | GPU
DEBUG 01-05 09:19:37.019554.019554 lmp.py:372]   Expert 25 |    468 | GPU
DEBUG 01-05 09:19:37.019766.019766 lmp.py:372]   Expert 35 |    526 | GPU
DEBUG 01-05 09:19:37.019078.019078 lmp.py:373] 
DEBUG 01-05 09:19:37.019078.019078 lmp.py:373]   CPU total tokens: 3760 (30.6%)
DEBUG 01-05 09:19:37.019483.019483 lmp.py:374]   GPU total tokens: 8528 (69.4%)
DEBUG 01-05 09:19:37.019417.019417 cuda_h.py:19] end experts_map_get cost 0.0015256404876708984 seconds
DEBUG 01-05 09:19:37.019822.019822 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.019698.019698 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.019119.019119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.019884.019884 cuda_h.py:19] end allocate_cuda_memory cost 0.00024962425231933594 seconds
DEBUG 01-05 09:19:37.019396.019396 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.019105.019105 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.019657.019657 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.019307.019307 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ab6590c4-90fe-48f1-8dd8-6707420701f3
DEBUG 01-05 09:19:37.020544.020544 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.020364.020364 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ab6590c4-90fe-48f1-8dd8-6707420701f3
DEBUG 01-05 09:19:37.021817.021817 cuda_h.py:19] end load_into_gpu_async cost 0.0012621879577636719 seconds
DEBUG 01-05 09:19:37.021519.021519 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.021239.021239 cuda_h.py:19] end restore_tensors2 cost 0.0002925395965576172 seconds
DEBUG 01-05 09:19:37.021777.021777 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002141237258911133 seconds
DEBUG 01-05 09:19:37.024216.024216 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004828929901123047 seconds
DEBUG 01-05 09:19:37.024761.024761 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.024989.024989 lmp.py:419] 
DEBUG 01-05 09:19:37.024989.024989 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.024640.024640 cuda_h.py:19] end cpu_experts_submit cost 0.00011205673217773438 seconds
DEBUG 01-05 09:19:37.024197.024197 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.034376.034376 mlpmodule.py:704] group tensors cost 0.010126113891601562 s
DEBUG 01-05 09:19:37.036116.036116 mlpmodule.py:742] pad cost 0.0015668869018554688 s
DEBUG 01-05 09:19:37.037497.037497 mlpmodule.py:748] create cpu tensor cost 4.220008850097656e-05 s
DEBUG 01-05 09:19:37.037493.037493 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-05 09:19:37.050653.050653 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.050692.050692 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.050358.050358 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 09:19:37.050435.050435 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.071226.071226 mlpmodule.py:793] group einsum cost 0.03466200828552246 s
DEBUG 01-05 09:19:37.073018.073018 mlpmodule.py:801] cpy2cputensor cost 0.0011172294616699219 s
DEBUG 01-05 09:19:37.113832.113832 cuda_h.py:19] end wait_cetm_experts cost 0.0887293815612793 seconds
DEBUG 01-05 09:19:37.113378.113378 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.113064.113064 cuda_h.py:19] end gpu_sexperts cost 0.00046253204345703125 seconds
DEBUG 01-05 09:19:37.113715.113715 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:19:37.113677.113677 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:19:37.113295.113295 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:19:37.113958.113958 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.271766662597656e-05 seconds
DEBUG 01-05 09:19:37.113992.113992 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.113338.113338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ab6590c4-90fe-48f1-8dd8-6707420701f3
DEBUG 01-05 09:19:37.114701.114701 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.114624.114624 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.114037.114037 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.118830.118830 cuda_h.py:19] end allocate_cuda_memory cost 0.003879070281982422 seconds
DEBUG 01-05 09:19:37.118270.118270 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.118510.118510 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.118962.118962 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.118898.118898 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a2e3b41b-03c7-4902-9a0e-b6f644b23f20
DEBUG 01-05 09:19:37.118695.118695 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.122726.122726 client.py:127] Model loaded
DEBUG 01-05 09:19:37.123914.123914 cuda_h.py:19] end wait_experts cost 0.009107828140258789 seconds
DEBUG 01-05 09:19:37.123478.123478 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.123234.123234 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:37.123372.123372 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a2e3b41b-03c7-4902-9a0e-b6f644b23f20
DEBUG 01-05 09:19:37.123805.123805 cuda_h.py:19] end load_into_gpu_async cost 0.0054471492767333984 seconds
DEBUG 01-05 09:19:37.123561.123561 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.123008.123008 cuda_h.py:19] end restore_tensors2 cost 8.845329284667969e-05 seconds
DEBUG 01-05 09:19:37.123056.123056 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00969552993774414 seconds
DEBUG 01-05 09:19:37.124279.124279 mlpmodule.py:531] gpu group tensors cost 0.00107574462890625 s
INFO 01-05 09:19:37.124024.124024 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a2e3b41b-03c7-4902-9a0e-b6f644b23f20
DEBUG 01-05 09:19:37.126648.126648 mlpmodule.py:564] gpu pad cost 0.0019807815551757812 s
DEBUG 01-05 09:19:37.126866.126866 mlpmodule.py:582] gpu group einsum cost 0.0005052089691162109 s
DEBUG 01-05 09:19:37.127595.127595 mlpmodule.py:662]  experts func einsum cost 0.10271978378295898 s
DEBUG 01-05 09:19:37.130746.130746 mlpmodule.py:611] gpu experts func einsum cost 0.0069005489349365234 s
DEBUG 01-05 09:19:37.130669.130669 cuda_h.py:19] end gpu_experts cost 0.0070650577545166016 seconds
DEBUG 01-05 09:19:37.130763.130763 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:37.133362.133362 client.py:127] Model loaded
DEBUG 01-05 09:19:37.133139.133139 cuda_h.py:19] end sllm_worker_task cost 0.01892399787902832 seconds
DEBUG 01-05 09:19:37.133141.133141 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0029404163360595703 seconds
DEBUG 01-05 09:19:37.133001.133001 cuda_h.py:19] end layer_moe_generate_20 cost 0.11643385887145996 seconds
DEBUG 01-05 09:19:37.133398.133398 lmp.py:214] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 09:19:37.133406.133406 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 09:19:37.133533.133533 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.133814.133814 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.136217.136217 cuda_h.py:19] end self_attn cost 0.002471923828125 seconds
DEBUG 01-05 09:19:37.136001.136001 cuda_h.py:19] end iln_self_attn_paln cost 0.003088712692260742 seconds
DEBUG 01-05 09:19:37.136083.136083 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 09:19:37.136515.136515 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.137396.137396 cuda_h.py:19] end gate cost 0.0005791187286376953 seconds
DEBUG 01-05 09:19:37.137987.137987 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.137110.137110 lmp.py:361] 
DEBUG 01-05 09:19:37.137110.137110 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.137674.137674 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.137039.137039 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.137304.137304 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.137709.137709 lmp.py:365] 
DEBUG 01-05 09:19:37.137709.137709 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.137875.137875 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.137525.137525 lmp.py:372]   Expert  9 |     28 | CPU
DEBUG 01-05 09:19:37.137168.137168 lmp.py:372]   Expert 60 |     51 | CPU
DEBUG 01-05 09:19:37.137857.137857 lmp.py:372]   Expert 44 |     57 | CPU
DEBUG 01-05 09:19:37.137546.137546 lmp.py:372]   Expert 20 |     62 | CPU
DEBUG 01-05 09:19:37.137997.137997 lmp.py:372]   Expert 26 |     67 | CPU
DEBUG 01-05 09:19:37.138971.138971 lmp.py:372]   Expert 56 |     70 | CPU
DEBUG 01-05 09:19:37.138184.138184 lmp.py:372]   Expert 32 |     74 | CPU
DEBUG 01-05 09:19:37.138635.138635 lmp.py:372]   Expert  1 |     75 | CPU
DEBUG 01-05 09:19:37.138278.138278 lmp.py:372]   Expert 19 |     83 | CPU
DEBUG 01-05 09:19:37.138205.138205 lmp.py:372]   Expert 54 |     91 | CPU
DEBUG 01-05 09:19:37.138179.138179 lmp.py:372]   Expert 51 |     97 | CPU
DEBUG 01-05 09:19:37.138630.138630 lmp.py:372]   Expert 57 |     99 | CPU
DEBUG 01-05 09:19:37.138843.138843 lmp.py:372]   Expert  8 |    108 | CPU
DEBUG 01-05 09:19:37.138578.138578 lmp.py:372]   Expert 12 |    114 | CPU
DEBUG 01-05 09:19:37.138791.138791 lmp.py:372]   Expert  3 |    116 | CPU
DEBUG 01-05 09:19:37.138765.138765 lmp.py:372]   Expert 52 |    119 | CPU
DEBUG 01-05 09:19:37.138977.138977 lmp.py:372]   Expert 25 |    124 | CPU
DEBUG 01-05 09:19:37.138428.138428 lmp.py:372]   Expert 48 |    125 | CPU
DEBUG 01-05 09:19:37.138164.138164 lmp.py:372]   Expert  6 |    126 | CPU
DEBUG 01-05 09:19:37.138376.138376 lmp.py:372]   Expert 14 |    126 | CPU
DEBUG 01-05 09:19:37.138543.138543 lmp.py:372]   Expert 33 |    134 | CPU
DEBUG 01-05 09:19:37.138947.138947 lmp.py:372]   Expert 15 |    135 | CPU
DEBUG 01-05 09:19:37.138160.138160 lmp.py:372]   Expert 23 |    138 | CPU
DEBUG 01-05 09:19:37.138372.138372 lmp.py:372]   Expert  7 |    143 | CPU
DEBUG 01-05 09:19:37.138346.138346 lmp.py:372]   Expert 49 |    143 | CPU
DEBUG 01-05 09:19:37.138559.138559 lmp.py:372]   Expert 53 |    146 | CPU
DEBUG 01-05 09:19:37.138533.138533 lmp.py:372]   Expert 13 |    147 | CPU
DEBUG 01-05 09:19:37.138745.138745 lmp.py:372]   Expert 35 |    152 | CPU
DEBUG 01-05 09:19:37.138481.138481 lmp.py:372]   Expert 34 |    156 | CPU
DEBUG 01-05 09:19:37.138693.138693 lmp.py:372]   Expert 40 |    158 | CPU
DEBUG 01-05 09:19:37.138621.138621 lmp.py:372]   Expert 59 |    161 | CPU
DEBUG 01-05 09:19:37.138549.138549 lmp.py:372]   Expert 50 |    166 | CPU
DEBUG 01-05 09:19:37.138761.138761 lmp.py:372]   Expert 58 |    170 | GPU
DEBUG 01-05 09:19:37.138735.138735 lmp.py:372]   Expert 61 |    174 | GPU
DEBUG 01-05 09:19:37.138471.138471 lmp.py:372]   Expert 28 |    182 | GPU
DEBUG 01-05 09:19:37.138445.138445 lmp.py:372]   Expert 39 |    186 | GPU
DEBUG 01-05 09:19:37.138419.138419 lmp.py:372]   Expert 41 |    190 | GPU
DEBUG 01-05 09:19:37.138154.138154 lmp.py:372]   Expert 24 |    194 | GPU
DEBUG 01-05 09:19:37.138128.138128 lmp.py:372]   Expert 27 |    194 | GPU
DEBUG 01-05 09:19:37.138341.138341 lmp.py:372]   Expert  2 |    203 | GPU
DEBUG 01-05 09:19:37.138077.138077 lmp.py:372]   Expert 18 |    218 | GPU
DEBUG 01-05 09:19:37.138766.138766 lmp.py:372]   Expert 38 |    228 | GPU
DEBUG 01-05 09:19:37.138455.138455 lmp.py:372]   Expert 37 |    230 | GPU
DEBUG 01-05 09:19:37.138668.138668 lmp.py:372]   Expert 43 |    230 | GPU
DEBUG 01-05 09:19:37.138403.138403 lmp.py:372]   Expert 11 |    234 | GPU
DEBUG 01-05 09:19:37.138616.138616 lmp.py:372]   Expert  4 |    248 | GPU
DEBUG 01-05 09:19:37.138113.138113 lmp.py:372]   Expert 17 |    250 | GPU
DEBUG 01-05 09:19:37.138325.138325 lmp.py:372]   Expert 62 |    259 | GPU
DEBUG 01-05 09:19:37.138061.138061 lmp.py:372]   Expert 10 |    265 | GPU
DEBUG 01-05 09:19:37.138273.138273 lmp.py:372]   Expert 29 |    265 | GPU
DEBUG 01-05 09:19:37.138486.138486 lmp.py:372]   Expert 22 |    267 | GPU
DEBUG 01-05 09:19:37.138460.138460 lmp.py:372]   Expert 47 |    275 | GPU
DEBUG 01-05 09:19:37.138911.138911 lmp.py:372]   Expert 63 |    277 | GPU
DEBUG 01-05 09:19:37.138839.138839 lmp.py:372]   Expert 55 |    280 | GPU
DEBUG 01-05 09:19:37.138574.138574 lmp.py:372]   Expert  5 |    288 | GPU
DEBUG 01-05 09:19:37.138787.138787 lmp.py:372]   Expert 30 |    288 | GPU
DEBUG 01-05 09:19:37.138761.138761 lmp.py:372]   Expert 21 |    294 | GPU
DEBUG 01-05 09:19:37.138496.138496 lmp.py:372]   Expert 31 |    298 | GPU
DEBUG 01-05 09:19:37.138470.138470 lmp.py:372]   Expert 16 |    349 | GPU
DEBUG 01-05 09:19:37.138444.138444 lmp.py:372]   Expert 46 |    362 | GPU
DEBUG 01-05 09:19:37.138418.138418 lmp.py:372]   Expert 36 |    385 | GPU
DEBUG 01-05 09:19:37.138631.138631 lmp.py:372]   Expert 45 |    410 | GPU
DEBUG 01-05 09:19:37.138797.138797 lmp.py:372]   Expert  0 |    439 | GPU
DEBUG 01-05 09:19:37.138248.138248 lmp.py:372]   Expert 42 |    565 | GPU
DEBUG 01-05 09:19:37.138176.138176 lmp.py:373] 
DEBUG 01-05 09:19:37.138176.138176 lmp.py:373]   CPU total tokens: 3591 (29.2%)
DEBUG 01-05 09:19:37.138342.138342 lmp.py:374]   GPU total tokens: 8697 (70.8%)
DEBUG 01-05 09:19:37.139561.139561 cuda_h.py:19] end experts_map_get cost 0.0014836788177490234 seconds
DEBUG 01-05 09:19:37.139966.139966 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.139934.139934 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.139733.139733 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.139404.139404 cuda_h.py:19] end allocate_cuda_memory cost 0.0002167224884033203 seconds
DEBUG 01-05 09:19:37.139439.139439 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.139003.139003 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.139150.139150 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.139561.139561 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88139b88-e273-4674-9e3b-f5a82920f196
DEBUG 01-05 09:19:37.139130.139130 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.140709.140709 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88139b88-e273-4674-9e3b-f5a82920f196
DEBUG 01-05 09:19:37.140559.140559 cuda_h.py:19] end load_into_gpu_async cost 0.001180410385131836 seconds
DEBUG 01-05 09:19:37.140931.140931 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.141789.141789 cuda_h.py:19] end restore_tensors2 cost 0.00029015541076660156 seconds
DEBUG 01-05 09:19:37.141565.141565 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020227432250976562 seconds
DEBUG 01-05 09:19:37.143870.143870 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004643440246582031 seconds
DEBUG 01-05 09:19:37.143223.143223 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.143114.143114 lmp.py:419] 
DEBUG 01-05 09:19:37.143114.143114 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.143096.143096 cuda_h.py:19] end cpu_experts_submit cost 0.00012302398681640625 seconds
DEBUG 01-05 09:19:37.143368.143368 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.156373.156373 mlpmodule.py:704] group tensors cost 0.012073755264282227 s
DEBUG 01-05 09:19:37.158245.158245 mlpmodule.py:742] pad cost 0.001493692398071289 s
DEBUG 01-05 09:19:37.158871.158871 mlpmodule.py:748] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-05 09:19:37.158602.158602 mlpmodule.py:753] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-05 09:19:37.171299.171299 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.172960.172960 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.172288.172288 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 09:19:37.172604.172604 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.193898.193898 mlpmodule.py:793] group einsum cost 0.034657955169677734 s
DEBUG 01-05 09:19:37.194712.194712 mlpmodule.py:801] cpy2cputensor cost 0.0011739730834960938 s
DEBUG 01-05 09:19:37.234735.234735 cuda_h.py:19] end wait_cetm_experts cost 0.09022021293640137 seconds
DEBUG 01-05 09:19:37.234950.234950 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.234907.234907 cuda_h.py:19] end gpu_sexperts cost 0.0004527568817138672 seconds
DEBUG 01-05 09:19:37.234226.234226 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:19:37.234711.234711 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:19:37.234475.234475 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.409385681152344e-05 seconds
DEBUG 01-05 09:19:37.234569.234569 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.605552673339844e-05 seconds
DEBUG 01-05 09:19:37.234126.234126 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.235366.235366 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88139b88-e273-4674-9e3b-f5a82920f196
DEBUG 01-05 09:19:37.235875.235875 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.235752.235752 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.235164.235164 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.239576.239576 cuda_h.py:19] end allocate_cuda_memory cost 0.003948211669921875 seconds
DEBUG 01-05 09:19:37.239778.239778 cuda_h.py:10] start load_into_gpu_async
INFO 01-05 09:19:37.239854.239854 client.py:127] Model loaded
DEBUG 01-05 09:19:37.239764.239764 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.239568.239568 cuda_h.py:19] end wait_experts cost 0.004644155502319336 seconds
DEBUG 01-05 09:19:37.239172.239172 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.239322.239322 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1c049b9-3c99-44f2-8b18-f663f2961e44
DEBUG 01-05 09:19:37.239941.239941 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:37.239770.239770 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.244193.244193 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.244826.244826 mlpmodule.py:531] gpu group tensors cost 0.0006210803985595703 s
INFO 01-05 09:19:37.244955.244955 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1c049b9-3c99-44f2-8b18-f663f2961e44
DEBUG 01-05 09:19:37.245708.245708 cuda_h.py:19] end load_into_gpu_async cost 0.005435943603515625 seconds
DEBUG 01-05 09:19:37.245755.245755 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.245203.245203 cuda_h.py:19] end restore_tensors2 cost 8.726119995117188e-05 seconds
DEBUG 01-05 09:19:37.245919.245919 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009922027587890625 seconds
INFO 01-05 09:19:37.245869.245869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1c049b9-3c99-44f2-8b18-f663f2961e44
DEBUG 01-05 09:19:37.247213.247213 mlpmodule.py:564] gpu pad cost 0.0024967193603515625 s
DEBUG 01-05 09:19:37.248419.248419 mlpmodule.py:582] gpu group einsum cost 0.0005252361297607422 s
DEBUG 01-05 09:19:37.248195.248195 mlpmodule.py:662]  experts func einsum cost 0.1048731803894043 s
DEBUG 01-05 09:19:37.251498.251498 mlpmodule.py:611] gpu experts func einsum cost 0.0070497989654541016 s
DEBUG 01-05 09:19:37.251535.251535 cuda_h.py:19] end gpu_experts cost 0.007245540618896484 seconds
DEBUG 01-05 09:19:37.251436.251436 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:37.254345.254345 client.py:127] Model loaded
DEBUG 01-05 09:19:37.254195.254195 cuda_h.py:19] end sllm_worker_task cost 0.019185304641723633 seconds
DEBUG 01-05 09:19:37.254985.254985 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.003106832504272461 seconds
DEBUG 01-05 09:19:37.254619.254619 cuda_h.py:19] end layer_moe_generate_21 cost 0.11784791946411133 seconds
DEBUG 01-05 09:19:37.254235.254235 lmp.py:214] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 09:19:37.254666.254666 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 09:19:37.254170.254170 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.255875.255875 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.257383.257383 cuda_h.py:19] end self_attn cost 0.0024597644805908203 seconds
DEBUG 01-05 09:19:37.257161.257161 cuda_h.py:19] end iln_self_attn_paln cost 0.0030527114868164062 seconds
DEBUG 01-05 09:19:37.258904.258904 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 09:19:37.258118.258118 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.258410.258410 cuda_h.py:19] end gate cost 0.0005674362182617188 seconds
DEBUG 01-05 09:19:37.258570.258570 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.259938.259938 lmp.py:361] 
DEBUG 01-05 09:19:37.259938.259938 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.259078.259078 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.259159.259159 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.259947.259947 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.259975.259975 lmp.py:365] 
DEBUG 01-05 09:19:37.259975.259975 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.259141.259141 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.259267.259267 lmp.py:372]   Expert 11 |     59 | CPU
DEBUG 01-05 09:19:37.259387.259387 lmp.py:372]   Expert 49 |     66 | CPU
DEBUG 01-05 09:19:37.259553.259553 lmp.py:372]   Expert 32 |     67 | CPU
DEBUG 01-05 09:19:37.259865.259865 lmp.py:372]   Expert  1 |     68 | CPU
DEBUG 01-05 09:19:37.259985.259985 lmp.py:372]   Expert 22 |     79 | CPU
DEBUG 01-05 09:19:37.259390.259390 lmp.py:372]   Expert 54 |     79 | CPU
DEBUG 01-05 09:19:37.259079.259079 lmp.py:372]   Expert 45 |     83 | CPU
DEBUG 01-05 09:19:37.259007.259007 lmp.py:372]   Expert  6 |     86 | CPU
DEBUG 01-05 09:19:37.259650.259650 lmp.py:372]   Expert 12 |     86 | CPU
DEBUG 01-05 09:19:37.259008.259008 lmp.py:372]   Expert  7 |     92 | CPU
DEBUG 01-05 09:19:37.259982.259982 lmp.py:372]   Expert 63 |     92 | CPU
DEBUG 01-05 09:19:37.259433.259433 lmp.py:372]   Expert 42 |     94 | CPU
DEBUG 01-05 09:19:37.259645.259645 lmp.py:372]   Expert 46 |     95 | CPU
DEBUG 01-05 09:19:37.259096.259096 lmp.py:372]   Expert 44 |     97 | CPU
DEBUG 01-05 09:19:37.259024.259024 lmp.py:372]   Expert 41 |     98 | CPU
DEBUG 01-05 09:19:37.259667.259667 lmp.py:372]   Expert 60 |     98 | CPU
DEBUG 01-05 09:19:37.259594.259594 lmp.py:372]   Expert 52 |    102 | CPU
DEBUG 01-05 09:19:37.259807.259807 lmp.py:372]   Expert 61 |    106 | CPU
DEBUG 01-05 09:19:37.259543.259543 lmp.py:372]   Expert 15 |    112 | CPU
DEBUG 01-05 09:19:37.259755.259755 lmp.py:372]   Expert 24 |    114 | CPU
DEBUG 01-05 09:19:37.259206.259206 lmp.py:372]   Expert 37 |    114 | CPU
DEBUG 01-05 09:19:37.259564.259564 lmp.py:372]   Expert 10 |    118 | CPU
DEBUG 01-05 09:19:37.259253.259253 lmp.py:372]   Expert 13 |    123 | CPU
DEBUG 01-05 09:19:37.259420.259420 lmp.py:372]   Expert 48 |    123 | CPU
DEBUG 01-05 09:19:37.259109.259109 lmp.py:372]   Expert 30 |    131 | CPU
DEBUG 01-05 09:19:37.259083.259083 lmp.py:372]   Expert 57 |    131 | CPU
DEBUG 01-05 09:19:37.259534.259534 lmp.py:372]   Expert  9 |    132 | CPU
DEBUG 01-05 09:19:37.259892.259892 lmp.py:372]   Expert 21 |    133 | CPU
DEBUG 01-05 09:19:37.259343.259343 lmp.py:372]   Expert  3 |    134 | CPU
DEBUG 01-05 09:19:37.259317.259317 lmp.py:372]   Expert 31 |    135 | CPU
DEBUG 01-05 09:19:37.259291.259291 lmp.py:372]   Expert 62 |    136 | CPU
DEBUG 01-05 09:19:37.259503.259503 lmp.py:372]   Expert 28 |    137 | CPU
DEBUG 01-05 09:19:37.259193.259193 lmp.py:372]   Expert 27 |    154 | GPU
DEBUG 01-05 09:19:37.259405.259405 lmp.py:372]   Expert 47 |    154 | GPU
DEBUG 01-05 09:19:37.259525.259525 lmp.py:372]   Expert  0 |    172 | GPU
DEBUG 01-05 09:19:37.259976.259976 lmp.py:372]   Expert 26 |    174 | GPU
DEBUG 01-05 09:19:37.259188.259188 lmp.py:372]   Expert 43 |    176 | GPU
DEBUG 01-05 09:19:37.259639.259639 lmp.py:372]   Expert 51 |    192 | GPU
DEBUG 01-05 09:19:37.259613.259613 lmp.py:372]   Expert 58 |    202 | GPU
DEBUG 01-05 09:19:37.259064.259064 lmp.py:372]   Expert 39 |    203 | GPU
DEBUG 01-05 09:19:37.259946.259946 lmp.py:372]   Expert 38 |    208 | GPU
DEBUG 01-05 09:19:37.259350.259350 lmp.py:372]   Expert 50 |    208 | GPU
DEBUG 01-05 09:19:37.259516.259516 lmp.py:372]   Expert 16 |    218 | GPU
DEBUG 01-05 09:19:37.259729.259729 lmp.py:372]   Expert  8 |    224 | GPU
DEBUG 01-05 09:19:37.259464.259464 lmp.py:372]   Expert 19 |    224 | GPU
DEBUG 01-05 09:19:37.259677.259677 lmp.py:372]   Expert  2 |    231 | GPU
DEBUG 01-05 09:19:37.259797.259797 lmp.py:372]   Expert 33 |    242 | GPU
DEBUG 01-05 09:19:37.259248.259248 lmp.py:372]   Expert 34 |    255 | GPU
DEBUG 01-05 09:19:37.259652.259652 lmp.py:372]   Expert 56 |    259 | GPU
DEBUG 01-05 09:19:37.260818.260818 lmp.py:372]   Expert  4 |    266 | GPU
DEBUG 01-05 09:19:37.260269.260269 lmp.py:372]   Expert 35 |    277 | GPU
DEBUG 01-05 09:19:37.260243.260243 lmp.py:372]   Expert 23 |    285 | GPU
DEBUG 01-05 09:19:37.260363.260363 lmp.py:372]   Expert 17 |    291 | GPU
DEBUG 01-05 09:19:37.260337.260337 lmp.py:372]   Expert 20 |    302 | GPU
DEBUG 01-05 09:19:37.260026.260026 lmp.py:372]   Expert 53 |    312 | GPU
DEBUG 01-05 09:19:37.260431.260431 lmp.py:372]   Expert 59 |    341 | GPU
DEBUG 01-05 09:19:37.260882.260882 lmp.py:372]   Expert 29 |    342 | GPU
DEBUG 01-05 09:19:37.260809.260809 lmp.py:372]   Expert 25 |    349 | GPU
DEBUG 01-05 09:19:37.260214.260214 lmp.py:372]   Expert 18 |    351 | GPU
DEBUG 01-05 09:19:37.260427.260427 lmp.py:372]   Expert 55 |    368 | GPU
DEBUG 01-05 09:19:37.260639.260639 lmp.py:372]   Expert 40 |    370 | GPU
DEBUG 01-05 09:19:37.260613.260613 lmp.py:372]   Expert 14 |    454 | GPU
DEBUG 01-05 09:19:37.260349.260349 lmp.py:372]   Expert 36 |    563 | GPU
DEBUG 01-05 09:19:37.260515.260515 lmp.py:372]   Expert  5 |    601 | GPU
DEBUG 01-05 09:19:37.260158.260158 lmp.py:373] 
DEBUG 01-05 09:19:37.260158.260158 lmp.py:373]   CPU total tokens: 3320 (27.0%)
DEBUG 01-05 09:19:37.260946.260946 lmp.py:374]   GPU total tokens: 8968 (73.0%)
DEBUG 01-05 09:19:37.260643.260643 cuda_h.py:19] end experts_map_get cost 0.001535177230834961 seconds
DEBUG 01-05 09:19:37.260047.260047 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.260638.260638 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.260020.260020 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.260989.260989 cuda_h.py:19] end allocate_cuda_memory cost 0.0002238750457763672 seconds
DEBUG 01-05 09:19:37.260932.260932 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.260780.260780 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.260881.260881 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.260292.260292 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c0c546df-5e72-4899-bbd1-d02c31652b64
DEBUG 01-05 09:19:37.261815.261815 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.262896.262896 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c0c546df-5e72-4899-bbd1-d02c31652b64
DEBUG 01-05 09:19:37.262202.262202 cuda_h.py:19] end load_into_gpu_async cost 0.0013279914855957031 seconds
DEBUG 01-05 09:19:37.262998.262998 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.262042.262042 cuda_h.py:19] end restore_tensors2 cost 0.0002880096435546875 seconds
DEBUG 01-05 09:19:37.262672.262672 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002170085906982422 seconds
DEBUG 01-05 09:19:37.265052.265052 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004856586456298828 seconds
DEBUG 01-05 09:19:37.265835.265835 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.265559.265559 lmp.py:419] 
DEBUG 01-05 09:19:37.265559.265559 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.265687.265687 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-05 09:19:37.265529.265529 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.277020.277020 mlpmodule.py:704] group tensors cost 0.011951923370361328 s
DEBUG 01-05 09:19:37.279393.279393 mlpmodule.py:742] pad cost 0.0015058517456054688 s
DEBUG 01-05 09:19:37.279244.279244 mlpmodule.py:748] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-05 09:19:37.279425.279425 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-05 09:19:37.292616.292616 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.292896.292896 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.292747.292747 mlpmodule.py:773] group_w3 first element: 0.025390625
WARNING 01-05 09:19:37.292446.292446 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.315459.315459 mlpmodule.py:793] group einsum cost 0.0357670783996582 s
DEBUG 01-05 09:19:37.316748.316748 mlpmodule.py:801] cpy2cputensor cost 0.0007216930389404297 s
DEBUG 01-05 09:19:37.355367.355367 cuda_h.py:19] end wait_cetm_experts cost 0.09025263786315918 seconds
DEBUG 01-05 09:19:37.355337.355337 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.356585.356585 cuda_h.py:19] end gpu_sexperts cost 0.0004570484161376953 seconds
DEBUG 01-05 09:19:37.356759.356759 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:19:37.356496.356496 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:19:37.356399.356399 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:19:37.356255.356255 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.343292236328125e-05 seconds
DEBUG 01-05 09:19:37.356812.356812 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.356713.356713 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c0c546df-5e72-4899-bbd1-d02c31652b64
DEBUG 01-05 09:19:37.356699.356699 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.356483.356483 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.356546.356546 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.360919.360919 cuda_h.py:19] end allocate_cuda_memory cost 0.003989696502685547 seconds
DEBUG 01-05 09:19:37.361882.361882 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.361314.361314 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.361097.361097 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.361614.361614 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9f9b6ad2-ebd8-43e8-b248-355963e9c217
DEBUG 01-05 09:19:37.361028.361028 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.361816.361816 client.py:127] Model loaded
DEBUG 01-05 09:19:37.361527.361527 cuda_h.py:19] end wait_experts cost 0.004921436309814453 seconds
DEBUG 01-05 09:19:37.361045.361045 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.361324.361324 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.362863.362863 mlpmodule.py:531] gpu group tensors cost 0.0006015300750732422 s
INFO 01-05 09:19:37.362957.362957 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9f9b6ad2-ebd8-43e8-b248-355963e9c217
DEBUG 01-05 09:19:37.362138.362138 cuda_h.py:19] end load_into_gpu_async cost 0.0014836788177490234 seconds
DEBUG 01-05 09:19:37.362464.362464 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.362236.362236 cuda_h.py:19] end restore_tensors2 cost 8.249282836914062e-05 seconds
DEBUG 01-05 09:19:37.362283.362283 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005838632583618164 seconds
INFO 01-05 09:19:37.363180.363180 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9f9b6ad2-ebd8-43e8-b248-355963e9c217
DEBUG 01-05 09:19:37.364534.364534 mlpmodule.py:564] gpu pad cost 0.002580881118774414 s
DEBUG 01-05 09:19:37.365151.365151 mlpmodule.py:582] gpu group einsum cost 0.0005497932434082031 s
DEBUG 01-05 09:19:37.368958.368958 mlpmodule.py:611] gpu experts func einsum cost 0.00737452507019043 s
DEBUG 01-05 09:19:37.369948.369948 cuda_h.py:19] end gpu_experts cost 0.007553577423095703 seconds
DEBUG 01-05 09:19:37.369518.369518 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:37.370701.370701 mlpmodule.py:662]  experts func einsum cost 0.10471463203430176 s
INFO 01-05 09:19:37.371570.371570 client.py:127] Model loaded
DEBUG 01-05 09:19:37.371321.371321 cuda_h.py:19] end sllm_worker_task cost 0.01512289047241211 seconds
DEBUG 01-05 09:19:37.371210.371210 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002828836441040039 seconds
DEBUG 01-05 09:19:37.372421.372421 cuda_h.py:19] end layer_moe_generate_22 cost 0.11407828330993652 seconds
DEBUG 01-05 09:19:37.372320.372320 lmp.py:214] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 09:19:37.372944.372944 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 09:19:37.372554.372554 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.372187.372187 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.375680.375680 cuda_h.py:19] end self_attn cost 0.002413511276245117 seconds
DEBUG 01-05 09:19:37.375333.375333 cuda_h.py:19] end iln_self_attn_paln cost 0.0030221939086914062 seconds
DEBUG 01-05 09:19:37.375414.375414 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 09:19:37.375846.375846 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.376575.376575 cuda_h.py:19] end gate cost 0.0005736351013183594 seconds
DEBUG 01-05 09:19:37.376974.376974 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.376825.376825 lmp.py:361] 
DEBUG 01-05 09:19:37.376825.376825 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.376204.376204 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.376569.376569 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.376265.376265 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.376385.376385 lmp.py:365] 
DEBUG 01-05 09:19:37.376385.376385 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.376789.376789 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.376154.376154 lmp.py:372]   Expert  5 |     62 | CPU
DEBUG 01-05 09:19:37.376274.376274 lmp.py:372]   Expert 49 |     64 | CPU
DEBUG 01-05 09:19:37.376632.376632 lmp.py:372]   Expert 27 |     65 | CPU
DEBUG 01-05 09:19:37.376468.376468 lmp.py:372]   Expert 44 |     68 | CPU
DEBUG 01-05 09:19:37.376872.376872 lmp.py:372]   Expert 19 |     86 | CPU
DEBUG 01-05 09:19:37.376561.376561 lmp.py:372]   Expert 17 |     87 | CPU
DEBUG 01-05 09:19:37.376012.376012 lmp.py:372]   Expert  7 |     99 | CPU
DEBUG 01-05 09:19:37.376940.376940 lmp.py:372]   Expert 53 |    110 | CPU
DEBUG 01-05 09:19:37.376298.376298 lmp.py:372]   Expert 55 |    111 | CPU
DEBUG 01-05 09:19:37.376749.376749 lmp.py:372]   Expert 25 |    118 | CPU
DEBUG 01-05 09:19:37.376962.376962 lmp.py:372]   Expert 38 |    118 | CPU
DEBUG 01-05 09:19:37.376128.376128 lmp.py:372]   Expert 52 |    119 | CPU
DEBUG 01-05 09:19:37.376817.376817 lmp.py:372]   Expert 43 |    121 | CPU
DEBUG 01-05 09:19:37.376029.376029 lmp.py:372]   Expert 40 |    122 | CPU
DEBUG 01-05 09:19:37.376865.376865 lmp.py:372]   Expert 58 |    122 | CPU
DEBUG 01-05 09:19:37.376554.376554 lmp.py:372]   Expert 34 |    125 | CPU
DEBUG 01-05 09:19:37.376766.376766 lmp.py:372]   Expert 35 |    125 | CPU
DEBUG 01-05 09:19:37.376979.376979 lmp.py:372]   Expert  4 |    126 | CPU
DEBUG 01-05 09:19:37.376191.376191 lmp.py:372]   Expert 22 |    128 | CPU
DEBUG 01-05 09:19:37.376927.376927 lmp.py:372]   Expert 16 |    134 | CPU
DEBUG 01-05 09:19:37.376139.376139 lmp.py:372]   Expert  1 |    135 | CPU
DEBUG 01-05 09:19:37.377305.377305 lmp.py:372]   Expert  6 |    135 | CPU
DEBUG 01-05 09:19:37.377187.377187 lmp.py:372]   Expert 42 |    137 | CPU
DEBUG 01-05 09:19:37.377115.377115 lmp.py:372]   Expert 63 |    142 | CPU
DEBUG 01-05 09:19:37.377327.377327 lmp.py:372]   Expert 51 |    153 | CPU
DEBUG 01-05 09:19:37.377539.377539 lmp.py:372]   Expert  9 |    156 | CPU
DEBUG 01-05 09:19:37.377752.377752 lmp.py:372]   Expert 47 |    163 | CPU
DEBUG 01-05 09:19:37.377726.377726 lmp.py:372]   Expert 13 |    176 | CPU
DEBUG 01-05 09:19:37.377607.377607 lmp.py:372]   Expert 36 |    180 | CPU
DEBUG 01-05 09:19:37.377297.377297 lmp.py:372]   Expert  0 |    182 | CPU
DEBUG 01-05 09:19:37.377986.377986 lmp.py:372]   Expert 30 |    182 | CPU
DEBUG 01-05 09:19:37.377675.377675 lmp.py:372]   Expert 45 |    185 | CPU
DEBUG 01-05 09:19:37.377126.377126 lmp.py:372]   Expert 46 |    188 | GPU
DEBUG 01-05 09:19:37.377577.377577 lmp.py:372]   Expert 26 |    189 | GPU
DEBUG 01-05 09:19:37.377697.377697 lmp.py:372]   Expert 11 |    196 | GPU
DEBUG 01-05 09:19:37.377148.377148 lmp.py:372]   Expert 23 |    197 | GPU
DEBUG 01-05 09:19:37.377075.377075 lmp.py:372]   Expert 28 |    200 | GPU
DEBUG 01-05 09:19:37.377765.377765 lmp.py:372]   Expert 39 |    202 | GPU
DEBUG 01-05 09:19:37.377454.377454 lmp.py:372]   Expert  2 |    204 | GPU
DEBUG 01-05 09:19:37.377428.377428 lmp.py:372]   Expert 60 |    208 | GPU
DEBUG 01-05 09:19:37.377786.377786 lmp.py:372]   Expert  3 |    213 | GPU
DEBUG 01-05 09:19:37.377999.377999 lmp.py:372]   Expert 41 |    213 | GPU
DEBUG 01-05 09:19:37.377211.377211 lmp.py:372]   Expert 62 |    216 | GPU
DEBUG 01-05 09:19:37.377424.377424 lmp.py:372]   Expert 24 |    221 | GPU
DEBUG 01-05 09:19:37.377828.377828 lmp.py:372]   Expert 61 |    223 | GPU
DEBUG 01-05 09:19:37.377233.377233 lmp.py:372]   Expert 15 |    225 | GPU
DEBUG 01-05 09:19:37.377114.377114 lmp.py:372]   Expert 12 |    230 | GPU
DEBUG 01-05 09:19:37.377565.377565 lmp.py:372]   Expert 29 |    241 | GPU
DEBUG 01-05 09:19:37.377539.377539 lmp.py:372]   Expert 21 |    265 | GPU
DEBUG 01-05 09:19:37.377513.377513 lmp.py:372]   Expert 10 |    268 | GPU
DEBUG 01-05 09:19:37.377487.377487 lmp.py:372]   Expert 14 |    270 | GPU
DEBUG 01-05 09:19:37.377223.377223 lmp.py:372]   Expert 20 |    271 | GPU
DEBUG 01-05 09:19:37.377912.377912 lmp.py:372]   Expert  8 |    287 | GPU
DEBUG 01-05 09:19:37.377601.377601 lmp.py:372]   Expert 31 |    288 | GPU
DEBUG 01-05 09:19:37.377960.377960 lmp.py:372]   Expert 33 |    288 | GPU
DEBUG 01-05 09:19:37.377934.377934 lmp.py:372]   Expert 32 |    291 | GPU
DEBUG 01-05 09:19:37.377669.377669 lmp.py:372]   Expert 57 |    295 | GPU
DEBUG 01-05 09:19:37.377882.377882 lmp.py:372]   Expert 59 |    295 | GPU
DEBUG 01-05 09:19:37.377856.377856 lmp.py:372]   Expert 37 |    300 | GPU
DEBUG 01-05 09:19:37.377591.377591 lmp.py:372]   Expert 50 |    301 | GPU
DEBUG 01-05 09:19:37.377903.377903 lmp.py:372]   Expert 18 |    307 | GPU
DEBUG 01-05 09:19:37.377831.377831 lmp.py:372]   Expert 56 |    357 | GPU
DEBUG 01-05 09:19:37.377805.377805 lmp.py:372]   Expert 48 |    396 | GPU
DEBUG 01-05 09:19:37.377779.377779 lmp.py:372]   Expert 54 |    407 | GPU
DEBUG 01-05 09:19:37.377707.377707 lmp.py:373] 
DEBUG 01-05 09:19:37.377707.377707 lmp.py:373]   CPU total tokens: 4036 (32.8%)
DEBUG 01-05 09:19:37.377635.377635 lmp.py:374]   GPU total tokens: 8252 (67.2%)
DEBUG 01-05 09:19:37.377953.377953 cuda_h.py:19] end experts_map_get cost 0.0015366077423095703 seconds
DEBUG 01-05 09:19:37.377358.377358 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.377995.377995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.377179.377179 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.378154.378154 cuda_h.py:19] end allocate_cuda_memory cost 0.00022912025451660156 seconds
DEBUG 01-05 09:19:37.378143.378143 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.378853.378853 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.378046.378046 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.378650.378650 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d469f6e0-267d-4e4b-9165-079f2b7bcc5f
DEBUG 01-05 09:19:37.378543.378543 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.380088.380088 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d469f6e0-267d-4e4b-9165-079f2b7bcc5f
DEBUG 01-05 09:19:37.380824.380824 cuda_h.py:19] end load_into_gpu_async cost 0.002119302749633789 seconds
DEBUG 01-05 09:19:37.380905.380905 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.380995.380995 cuda_h.py:19] end restore_tensors2 cost 0.0002872943878173828 seconds
DEBUG 01-05 09:19:37.380433.380433 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002968311309814453 seconds
DEBUG 01-05 09:19:37.383506.383506 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0055942535400390625 seconds
DEBUG 01-05 09:19:37.383290.383290 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.383729.383729 lmp.py:419] 
DEBUG 01-05 09:19:37.383729.383729 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.383142.383142 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-05 09:19:37.383699.383699 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.393441.393441 mlpmodule.py:704] group tensors cost 0.009952306747436523 s
DEBUG 01-05 09:19:37.396585.396585 mlpmodule.py:742] pad cost 0.0016050338745117188 s
DEBUG 01-05 09:19:37.396727.396727 mlpmodule.py:748] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-05 09:19:37.396154.396154 mlpmodule.py:753] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-05 09:19:37.411346.411346 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.411753.411753 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.412996.412996 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-05 09:19:37.412809.412809 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.435092.435092 mlpmodule.py:793] group einsum cost 0.03881645202636719 s
DEBUG 01-05 09:19:37.436063.436063 mlpmodule.py:801] cpy2cputensor cost 0.0013031959533691406 s
DEBUG 01-05 09:19:37.475081.475081 cuda_h.py:19] end wait_cetm_experts cost 0.09226322174072266 seconds
DEBUG 01-05 09:19:37.476866.476866 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.476621.476621 cuda_h.py:19] end gpu_sexperts cost 0.0005481243133544922 seconds
DEBUG 01-05 09:19:37.476271.476271 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:19:37.476902.476902 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:19:37.476004.476004 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.62396240234375e-05 seconds
DEBUG 01-05 09:19:37.476336.476336 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.867813110351562e-05 seconds
DEBUG 01-05 09:19:37.476324.476324 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.476904.476904 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d469f6e0-267d-4e4b-9165-079f2b7bcc5f
DEBUG 01-05 09:19:37.476014.476014 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.477388.477388 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.477198.477198 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.480954.480954 cuda_h.py:19] end allocate_cuda_memory cost 0.003534078598022461 seconds
DEBUG 01-05 09:19:37.480208.480208 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.480117.480117 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.481814.481814 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.481762.481762 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 39a42fb8-6455-4d01-b994-da5ffb8b7031
DEBUG 01-05 09:19:37.481944.481944 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.485506.485506 client.py:127] Model loaded
DEBUG 01-05 09:19:37.485932.485932 cuda_h.py:19] end wait_experts cost 0.008770227432250977 seconds
DEBUG 01-05 09:19:37.485211.485211 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.485444.485444 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.486832.486832 mlpmodule.py:531] gpu group tensors cost 0.0006115436553955078 s
INFO 01-05 09:19:37.486321.486321 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 39a42fb8-6455-4d01-b994-da5ffb8b7031
DEBUG 01-05 09:19:37.486317.486317 cuda_h.py:19] end load_into_gpu_async cost 0.005974769592285156 seconds
DEBUG 01-05 09:19:37.486788.486788 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.487944.487944 cuda_h.py:19] end restore_tensors2 cost 8.416175842285156e-05 seconds
DEBUG 01-05 09:19:37.487436.487436 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009894847869873047 seconds
INFO 01-05 09:19:37.487974.487974 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 39a42fb8-6455-4d01-b994-da5ffb8b7031
DEBUG 01-05 09:19:37.489101.489101 mlpmodule.py:564] gpu pad cost 0.002635478973388672 s
DEBUG 01-05 09:19:37.489111.489111 mlpmodule.py:662]  experts func einsum cost 0.10593318939208984 s
DEBUG 01-05 09:19:37.489087.489087 mlpmodule.py:582] gpu group einsum cost 0.0006480216979980469 s
DEBUG 01-05 09:19:37.493812.493812 mlpmodule.py:611] gpu experts func einsum cost 0.007127046585083008 s
DEBUG 01-05 09:19:37.493670.493670 cuda_h.py:19] end gpu_experts cost 0.007318973541259766 seconds
DEBUG 01-05 09:19:37.493095.493095 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:37.495955.495955 client.py:127] Model loaded
DEBUG 01-05 09:19:37.495520.495520 cuda_h.py:19] end sllm_worker_task cost 0.01818704605102539 seconds
DEBUG 01-05 09:19:37.495846.495846 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0022368431091308594 seconds
DEBUG 01-05 09:19:37.495747.495747 cuda_h.py:19] end layer_moe_generate_23 cost 0.12008547782897949 seconds
DEBUG 01-05 09:19:37.495800.495800 lmp.py:214] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 09:19:37.495331.495331 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 09:19:37.495789.495789 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.496560.496560 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.498461.498461 cuda_h.py:19] end self_attn cost 0.002540111541748047 seconds
DEBUG 01-05 09:19:37.499339.499339 cuda_h.py:19] end iln_self_attn_paln cost 0.003148794174194336 seconds
DEBUG 01-05 09:19:37.499255.499255 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 09:19:37.499786.499786 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.499868.499868 cuda_h.py:19] end gate cost 0.0006206035614013672 seconds
DEBUG 01-05 09:19:37.499790.499790 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.500542.500542 lmp.py:361] 
DEBUG 01-05 09:19:37.500542.500542 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.500252.500252 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.500379.500379 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.500836.500836 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.500956.500956 lmp.py:365] 
DEBUG 01-05 09:19:37.500956.500956 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.500122.500122 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.500918.500918 lmp.py:372]   Expert 47 |     57 | CPU
DEBUG 01-05 09:19:37.500799.500799 lmp.py:372]   Expert 42 |     67 | CPU
DEBUG 01-05 09:19:37.500442.500442 lmp.py:372]   Expert  6 |     72 | CPU
DEBUG 01-05 09:19:37.500323.500323 lmp.py:372]   Expert 43 |     72 | CPU
DEBUG 01-05 09:19:37.500596.500596 lmp.py:372]   Expert 44 |     72 | CPU
DEBUG 01-05 09:19:37.500808.500808 lmp.py:372]   Expert 25 |     84 | CPU
DEBUG 01-05 09:19:37.500213.500213 lmp.py:372]   Expert  5 |     89 | CPU
DEBUG 01-05 09:19:37.500141.500141 lmp.py:372]   Expert 35 |     89 | CPU
DEBUG 01-05 09:19:37.500499.500499 lmp.py:372]   Expert 48 |     89 | CPU
DEBUG 01-05 09:19:37.500950.500950 lmp.py:372]   Expert 62 |     89 | CPU
DEBUG 01-05 09:19:37.500401.500401 lmp.py:372]   Expert 55 |     97 | CPU
DEBUG 01-05 09:19:37.500613.500613 lmp.py:372]   Expert 16 |     98 | CPU
DEBUG 01-05 09:19:37.500256.500256 lmp.py:372]   Expert 60 |    106 | CPU
DEBUG 01-05 09:19:37.500137.500137 lmp.py:372]   Expert 29 |    109 | CPU
DEBUG 01-05 09:19:37.500542.500542 lmp.py:372]   Expert 54 |    111 | CPU
DEBUG 01-05 09:19:37.500754.500754 lmp.py:372]   Expert 56 |    117 | CPU
DEBUG 01-05 09:19:37.500967.500967 lmp.py:372]   Expert 30 |    128 | CPU
DEBUG 01-05 09:19:37.500941.500941 lmp.py:372]   Expert 22 |    132 | CPU
DEBUG 01-05 09:19:37.500630.500630 lmp.py:372]   Expert 36 |    148 | CPU
DEBUG 01-05 09:19:37.500035.500035 lmp.py:372]   Expert 51 |    154 | CPU
DEBUG 01-05 09:19:37.500155.500155 lmp.py:372]   Expert 61 |    156 | CPU
DEBUG 01-05 09:19:37.500890.500890 lmp.py:372]   Expert 28 |    157 | CPU
DEBUG 01-05 09:19:37.500864.500864 lmp.py:372]   Expert  7 |    158 | CPU
DEBUG 01-05 09:19:37.500077.500077 lmp.py:372]   Expert  4 |    161 | CPU
DEBUG 01-05 09:19:37.500051.500051 lmp.py:372]   Expert 20 |    165 | CPU
DEBUG 01-05 09:19:37.500932.500932 lmp.py:372]   Expert  1 |    166 | CPU
DEBUG 01-05 09:19:37.500052.500052 lmp.py:372]   Expert 49 |    168 | CPU
DEBUG 01-05 09:19:37.500741.500741 lmp.py:372]   Expert 59 |    173 | CPU
DEBUG 01-05 09:19:37.500192.500192 lmp.py:372]   Expert 21 |    178 | CPU
DEBUG 01-05 09:19:37.500166.500166 lmp.py:372]   Expert 17 |    179 | CPU
DEBUG 01-05 09:19:37.500902.500902 lmp.py:372]   Expert 31 |    179 | CPU
DEBUG 01-05 09:19:37.500498.500498 lmp.py:372]   Expert 38 |    179 | CPU
DEBUG 01-05 09:19:37.500711.500711 lmp.py:372]   Expert 15 |    186 | GPU
DEBUG 01-05 09:19:37.500162.500162 lmp.py:372]   Expert 46 |    190 | GPU
DEBUG 01-05 09:19:37.500613.500613 lmp.py:372]   Expert  0 |    191 | GPU
DEBUG 01-05 09:19:37.500825.500825 lmp.py:372]   Expert  3 |    195 | GPU
DEBUG 01-05 09:19:37.500799.500799 lmp.py:372]   Expert 14 |    197 | GPU
DEBUG 01-05 09:19:37.500965.500965 lmp.py:372]   Expert 34 |    203 | GPU
DEBUG 01-05 09:19:37.500655.500655 lmp.py:372]   Expert 41 |    203 | GPU
DEBUG 01-05 09:19:37.500536.500536 lmp.py:372]   Expert 40 |    204 | GPU
DEBUG 01-05 09:19:37.501749.501749 lmp.py:372]   Expert 19 |    205 | GPU
DEBUG 01-05 09:19:37.501484.501484 lmp.py:372]   Expert 53 |    208 | GPU
DEBUG 01-05 09:19:37.501458.501458 lmp.py:372]   Expert 63 |    208 | GPU
DEBUG 01-05 09:19:37.501955.501955 lmp.py:372]   Expert  2 |    219 | GPU
DEBUG 01-05 09:19:37.501929.501929 lmp.py:372]   Expert 10 |    224 | GPU
DEBUG 01-05 09:19:37.501811.501811 lmp.py:372]   Expert 24 |    225 | GPU
DEBUG 01-05 09:19:37.501500.501500 lmp.py:372]   Expert 57 |    225 | GPU
DEBUG 01-05 09:19:37.501428.501428 lmp.py:372]   Expert 37 |    227 | GPU
DEBUG 01-05 09:19:37.501640.501640 lmp.py:372]   Expert 26 |    236 | GPU
DEBUG 01-05 09:19:37.501376.501376 lmp.py:372]   Expert 50 |    243 | GPU
DEBUG 01-05 09:19:37.501112.501112 lmp.py:372]   Expert 45 |    249 | GPU
DEBUG 01-05 09:19:37.501470.501470 lmp.py:372]   Expert 32 |    250 | GPU
DEBUG 01-05 09:19:37.501682.501682 lmp.py:372]   Expert 23 |    251 | GPU
DEBUG 01-05 09:19:37.501656.501656 lmp.py:372]   Expert 58 |    256 | GPU
DEBUG 01-05 09:19:37.501869.501869 lmp.py:372]   Expert 52 |    262 | GPU
DEBUG 01-05 09:19:37.501320.501320 lmp.py:372]   Expert  9 |    267 | GPU
DEBUG 01-05 09:19:37.501009.501009 lmp.py:372]   Expert 12 |    290 | GPU
DEBUG 01-05 09:19:37.501844.501844 lmp.py:372]   Expert 18 |    292 | GPU
DEBUG 01-05 09:19:37.501818.501818 lmp.py:372]   Expert 13 |    312 | GPU
DEBUG 01-05 09:19:37.501031.501031 lmp.py:372]   Expert 33 |    334 | GPU
DEBUG 01-05 09:19:37.501005.501005 lmp.py:372]   Expert 39 |    337 | GPU
DEBUG 01-05 09:19:37.501979.501979 lmp.py:372]   Expert  8 |    359 | GPU
DEBUG 01-05 09:19:37.501191.501191 lmp.py:372]   Expert 11 |    375 | GPU
DEBUG 01-05 09:19:37.501834.501834 lmp.py:372]   Expert 27 |    666 | GPU
DEBUG 01-05 09:19:37.501000.501000 lmp.py:373] 
DEBUG 01-05 09:19:37.501000.501000 lmp.py:373]   CPU total tokens: 3999 (32.5%)
DEBUG 01-05 09:19:37.501405.501405 lmp.py:374]   GPU total tokens: 8289 (67.5%)
DEBUG 01-05 09:19:37.501578.501578 cuda_h.py:19] end experts_map_get cost 0.0015361309051513672 seconds
DEBUG 01-05 09:19:37.501982.501982 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.501527.501527 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.501770.501770 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.501475.501475 cuda_h.py:19] end allocate_cuda_memory cost 0.0002396106719970703 seconds
DEBUG 01-05 09:19:37.501702.501702 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.502081.502081 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.502989.502989 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.502400.502400 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65a66853-23da-4500-8591-0d5b9a5f4838
DEBUG 01-05 09:19:37.502969.502969 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.503635.503635 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65a66853-23da-4500-8591-0d5b9a5f4838
DEBUG 01-05 09:19:37.503848.503848 cuda_h.py:19] end load_into_gpu_async cost 0.0013766288757324219 seconds
DEBUG 01-05 09:19:37.503167.503167 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.503734.503734 cuda_h.py:19] end restore_tensors2 cost 0.0002875328063964844 seconds
DEBUG 01-05 09:19:37.503603.503603 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022406578063964844 seconds
DEBUG 01-05 09:19:37.506355.506355 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004987239837646484 seconds
DEBUG 01-05 09:19:37.506615.506615 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.506870.506870 lmp.py:419] 
DEBUG 01-05 09:19:37.506870.506870 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.506428.506428 cuda_h.py:19] end cpu_experts_submit cost 0.00011324882507324219 seconds
DEBUG 01-05 09:19:37.506793.506793 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.517794.517794 mlpmodule.py:704] group tensors cost 0.010956764221191406 s
DEBUG 01-05 09:19:37.520263.520263 mlpmodule.py:742] pad cost 0.0022885799407958984 s
DEBUG 01-05 09:19:37.521498.521498 mlpmodule.py:748] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-05 09:19:37.521586.521586 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-05 09:19:37.535180.535180 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.535464.535464 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.535554.535554 mlpmodule.py:773] group_w3 first element: -0.019287109375
WARNING 01-05 09:19:37.535591.535591 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.557822.557822 mlpmodule.py:793] group einsum cost 0.036054134368896484 s
DEBUG 01-05 09:19:37.558264.558264 mlpmodule.py:801] cpy2cputensor cost 0.0009393692016601562 s
DEBUG 01-05 09:19:37.597355.597355 cuda_h.py:19] end wait_cetm_experts cost 0.09109711647033691 seconds
DEBUG 01-05 09:19:37.597040.597040 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.598626.598626 cuda_h.py:19] end gpu_sexperts cost 0.0004603862762451172 seconds
DEBUG 01-05 09:19:37.598416.598416 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:19:37.598424.598424 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:19:37.598241.598241 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.7670135498046875e-05 seconds
DEBUG 01-05 09:19:37.598249.598249 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 8.487701416015625e-05 seconds
DEBUG 01-05 09:19:37.598475.598475 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.598192.598192 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65a66853-23da-4500-8591-0d5b9a5f4838
DEBUG 01-05 09:19:37.598860.598860 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.599388.599388 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.599378.599378 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.602638.602638 cuda_h.py:19] end allocate_cuda_memory cost 0.003725290298461914 seconds
INFO 01-05 09:19:37.603545.603545 client.py:127] Model loaded
DEBUG 01-05 09:19:37.603609.603609 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.603858.603858 cuda_h.py:19] end wait_experts cost 0.004665374755859375 seconds
DEBUG 01-05 09:19:37.603615.603615 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.603664.603664 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.603258.603258 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.604694.604694 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.604717.604717 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3202205e-fe9c-48d0-b373-fde37f6bb34b
DEBUG 01-05 09:19:37.604286.604286 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:37.604869.604869 mlpmodule.py:531] gpu group tensors cost 0.0009605884552001953 s
DEBUG 01-05 09:19:37.606159.606159 mlpmodule.py:564] gpu pad cost 0.00168609619140625 s
DEBUG 01-05 09:19:37.607749.607749 mlpmodule.py:582] gpu group einsum cost 0.0005381107330322266 s
INFO 01-05 09:19:37.608138.608138 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3202205e-fe9c-48d0-b373-fde37f6bb34b
DEBUG 01-05 09:19:37.608236.608236 cuda_h.py:19] end load_into_gpu_async cost 0.0048809051513671875 seconds
DEBUG 01-05 09:19:37.608532.608532 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.608235.608235 cuda_h.py:19] end restore_tensors2 cost 0.00014019012451171875 seconds
DEBUG 01-05 09:19:37.608975.608975 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009734630584716797 seconds
INFO 01-05 09:19:37.609641.609641 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3202205e-fe9c-48d0-b373-fde37f6bb34b
DEBUG 01-05 09:19:37.611110.611110 mlpmodule.py:662]  experts func einsum cost 0.10467934608459473 s
DEBUG 01-05 09:19:37.612288.612288 mlpmodule.py:611] gpu experts func einsum cost 0.008926153182983398 s
DEBUG 01-05 09:19:37.612947.612947 cuda_h.py:19] end gpu_experts cost 0.009111166000366211 seconds
DEBUG 01-05 09:19:37.612471.612471 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:37.616967.616967 client.py:127] Model loaded
DEBUG 01-05 09:19:37.616184.616184 cuda_h.py:19] end sllm_worker_task cost 0.017436504364013672 seconds
DEBUG 01-05 09:19:37.616221.616221 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0037865638732910156 seconds
DEBUG 01-05 09:19:37.616651.616651 cuda_h.py:19] end layer_moe_generate_24 cost 0.11760091781616211 seconds
DEBUG 01-05 09:19:37.616458.616458 lmp.py:214] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 09:19:37.616142.616142 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 09:19:37.617553.617553 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.617549.617549 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.619109.619109 cuda_h.py:19] end self_attn cost 0.002427339553833008 seconds
DEBUG 01-05 09:19:37.620431.620431 cuda_h.py:19] end iln_self_attn_paln cost 0.0030357837677001953 seconds
DEBUG 01-05 09:19:37.620651.620651 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 09:19:37.620991.620991 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.620779.620779 cuda_h.py:19] end gate cost 0.0005815029144287109 seconds
DEBUG 01-05 09:19:37.620417.620417 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.621447.621447 lmp.py:361] 
DEBUG 01-05 09:19:37.621447.621447 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.621395.621395 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.621760.621760 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.621171.621171 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.621768.621768 lmp.py:365] 
DEBUG 01-05 09:19:37.621768.621768 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.621411.621411 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.621299.621299 lmp.py:372]   Expert 36 |     43 | CPU
DEBUG 01-05 09:19:37.621180.621180 lmp.py:372]   Expert 33 |     44 | CPU
DEBUG 01-05 09:19:37.621016.621016 lmp.py:372]   Expert 18 |     62 | CPU
DEBUG 01-05 09:19:37.621897.621897 lmp.py:372]   Expert 13 |     65 | CPU
DEBUG 01-05 09:19:37.621778.621778 lmp.py:372]   Expert  0 |     66 | CPU
DEBUG 01-05 09:19:37.621706.621706 lmp.py:372]   Expert 42 |     66 | CPU
DEBUG 01-05 09:19:37.621395.621395 lmp.py:372]   Expert 16 |     83 | CPU
DEBUG 01-05 09:19:37.621846.621846 lmp.py:372]   Expert 47 |     85 | CPU
DEBUG 01-05 09:19:37.621204.621204 lmp.py:372]   Expert 21 |     90 | CPU
DEBUG 01-05 09:19:37.621655.621655 lmp.py:372]   Expert 62 |     94 | CPU
DEBUG 01-05 09:19:37.621106.621106 lmp.py:372]   Expert 10 |     95 | CPU
DEBUG 01-05 09:19:37.621319.621319 lmp.py:372]   Expert 22 |    104 | CPU
DEBUG 01-05 09:19:37.621246.621246 lmp.py:372]   Expert 27 |    105 | CPU
DEBUG 01-05 09:19:37.621936.621936 lmp.py:372]   Expert 34 |    109 | CPU
DEBUG 01-05 09:19:37.621055.621055 lmp.py:372]   Expert 38 |    112 | CPU
DEBUG 01-05 09:19:37.621506.621506 lmp.py:372]   Expert 43 |    114 | CPU
DEBUG 01-05 09:19:37.621719.621719 lmp.py:372]   Expert  2 |    116 | CPU
DEBUG 01-05 09:19:37.621454.621454 lmp.py:372]   Expert 59 |    116 | CPU
DEBUG 01-05 09:19:37.621667.621667 lmp.py:372]   Expert 20 |    117 | CPU
DEBUG 01-05 09:19:37.621641.621641 lmp.py:372]   Expert 53 |    117 | CPU
DEBUG 01-05 09:19:37.621238.621238 lmp.py:372]   Expert 50 |    119 | CPU
DEBUG 01-05 09:19:37.621404.621404 lmp.py:372]   Expert  5 |    120 | CPU
DEBUG 01-05 09:19:37.621331.621331 lmp.py:372]   Expert 14 |    126 | CPU
DEBUG 01-05 09:19:37.621306.621306 lmp.py:372]   Expert 48 |    132 | CPU
DEBUG 01-05 09:19:37.621518.621518 lmp.py:372]   Expert  4 |    135 | CPU
DEBUG 01-05 09:19:37.621254.621254 lmp.py:372]   Expert 32 |    136 | CPU
DEBUG 01-05 09:19:37.621089.621089 lmp.py:372]   Expert 56 |    138 | CPU
DEBUG 01-05 09:19:37.621063.621063 lmp.py:372]   Expert 44 |    140 | CPU
DEBUG 01-05 09:19:37.621275.621275 lmp.py:372]   Expert 24 |    147 | CPU
DEBUG 01-05 09:19:37.621203.621203 lmp.py:372]   Expert 31 |    150 | CPU
DEBUG 01-05 09:19:37.621131.621131 lmp.py:372]   Expert 41 |    155 | CPU
DEBUG 01-05 09:19:37.621058.621058 lmp.py:372]   Expert 23 |    157 | CPU
DEBUG 01-05 09:19:37.621178.621178 lmp.py:372]   Expert 45 |    157 | GPU
DEBUG 01-05 09:19:37.621629.621629 lmp.py:372]   Expert 55 |    159 | GPU
DEBUG 01-05 09:19:37.621842.621842 lmp.py:372]   Expert  3 |    166 | GPU
DEBUG 01-05 09:19:37.621292.621292 lmp.py:372]   Expert 39 |    170 | GPU
DEBUG 01-05 09:19:37.621505.621505 lmp.py:372]   Expert 46 |    174 | GPU
DEBUG 01-05 09:19:37.621194.621194 lmp.py:372]   Expert 52 |    188 | GPU
DEBUG 01-05 09:19:37.621552.621552 lmp.py:372]   Expert  6 |    190 | GPU
DEBUG 01-05 09:19:37.621719.621719 lmp.py:372]   Expert 51 |    195 | GPU
DEBUG 01-05 09:19:37.621693.621693 lmp.py:372]   Expert 61 |    201 | GPU
DEBUG 01-05 09:19:37.621667.621667 lmp.py:372]   Expert  8 |    206 | GPU
DEBUG 01-05 09:19:37.621117.621117 lmp.py:372]   Expert  1 |    210 | GPU
DEBUG 01-05 09:19:37.622853.622853 lmp.py:372]   Expert 12 |    215 | GPU
DEBUG 01-05 09:19:37.622258.622258 lmp.py:372]   Expert 35 |    224 | GPU
DEBUG 01-05 09:19:37.622709.622709 lmp.py:372]   Expert 40 |    224 | GPU
DEBUG 01-05 09:19:37.622159.622159 lmp.py:372]   Expert 11 |    233 | GPU
DEBUG 01-05 09:19:37.622849.622849 lmp.py:372]   Expert  7 |    239 | GPU
DEBUG 01-05 09:19:37.622823.622823 lmp.py:372]   Expert 49 |    256 | GPU
DEBUG 01-05 09:19:37.622035.622035 lmp.py:372]   Expert 15 |    259 | GPU
DEBUG 01-05 09:19:37.622678.622678 lmp.py:372]   Expert 37 |    262 | GPU
DEBUG 01-05 09:19:37.622368.622368 lmp.py:372]   Expert 57 |    287 | GPU
DEBUG 01-05 09:19:37.622534.622534 lmp.py:372]   Expert 28 |    294 | GPU
DEBUG 01-05 09:19:37.622461.622461 lmp.py:372]   Expert 26 |    302 | GPU
DEBUG 01-05 09:19:37.622674.622674 lmp.py:372]   Expert 30 |    311 | GPU
DEBUG 01-05 09:19:37.622648.622648 lmp.py:372]   Expert 58 |    316 | GPU
DEBUG 01-05 09:19:37.622768.622768 lmp.py:372]   Expert 63 |    327 | GPU
DEBUG 01-05 09:19:37.622980.622980 lmp.py:372]   Expert 54 |    357 | GPU
DEBUG 01-05 09:19:37.622954.622954 lmp.py:372]   Expert 25 |    365 | GPU
DEBUG 01-05 09:19:37.622928.622928 lmp.py:372]   Expert  9 |    391 | GPU
DEBUG 01-05 09:19:37.622141.622141 lmp.py:372]   Expert 17 |    426 | GPU
DEBUG 01-05 09:19:37.622115.622115 lmp.py:372]   Expert 60 |    465 | GPU
DEBUG 01-05 09:19:37.622327.622327 lmp.py:372]   Expert 29 |    489 | GPU
DEBUG 01-05 09:19:37.622540.622540 lmp.py:372]   Expert 19 |    572 | GPU
DEBUG 01-05 09:19:37.622183.622183 lmp.py:373] 
DEBUG 01-05 09:19:37.622183.622183 lmp.py:373]   CPU total tokens: 3458 (28.1%)
DEBUG 01-05 09:19:37.622779.622779 lmp.py:374]   GPU total tokens: 8830 (71.9%)
DEBUG 01-05 09:19:37.622191.622191 cuda_h.py:19] end experts_map_get cost 0.0015254020690917969 seconds
DEBUG 01-05 09:19:37.622357.622357 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.622848.622848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.622469.622469 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.622400.622400 cuda_h.py:19] end allocate_cuda_memory cost 0.0002655982971191406 seconds
DEBUG 01-05 09:19:37.622104.622104 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.623144.623144 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.623484.623484 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.623418.623418 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4039e70e-8518-4055-8429-9fa240ef9ff4
DEBUG 01-05 09:19:37.623901.623901 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.624981.624981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4039e70e-8518-4055-8429-9fa240ef9ff4
DEBUG 01-05 09:19:37.624625.624625 cuda_h.py:19] end load_into_gpu_async cost 0.0013015270233154297 seconds
DEBUG 01-05 09:19:37.624898.624898 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.624869.624869 cuda_h.py:19] end restore_tensors2 cost 0.0003039836883544922 seconds
DEBUG 01-05 09:19:37.624837.624837 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002214670181274414 seconds
DEBUG 01-05 09:19:37.627812.627812 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004873752593994141 seconds
DEBUG 01-05 09:19:37.627165.627165 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.627413.627413 lmp.py:419] 
DEBUG 01-05 09:19:37.627413.627413 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.627825.627825 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-05 09:19:37.627713.627713 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.637219.637219 mlpmodule.py:704] group tensors cost 0.01002645492553711 s
DEBUG 01-05 09:19:37.640473.640473 mlpmodule.py:742] pad cost 0.0017809867858886719 s
DEBUG 01-05 09:19:37.640960.640960 mlpmodule.py:748] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-05 09:19:37.640870.640870 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-05 09:19:37.653445.653445 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.653014.653014 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.654441.654441 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 09:19:37.654863.654863 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.675987.675987 mlpmodule.py:793] group einsum cost 0.034871578216552734 s
DEBUG 01-05 09:19:37.676761.676761 mlpmodule.py:801] cpy2cputensor cost 0.000762939453125 s
DEBUG 01-05 09:19:37.716613.716613 cuda_h.py:19] end wait_cetm_experts cost 0.08854150772094727 seconds
DEBUG 01-05 09:19:37.716444.716444 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.716143.716143 cuda_h.py:19] end gpu_sexperts cost 0.00047135353088378906 seconds
DEBUG 01-05 09:19:37.716079.716079 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:19:37.716564.716564 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:19:37.716089.716089 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:19:37.716535.716535 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 8.654594421386719e-05 seconds
DEBUG 01-05 09:19:37.716191.716191 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.716239.716239 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4039e70e-8518-4055-8429-9fa240ef9ff4
DEBUG 01-05 09:19:37.717682.717682 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.717469.717469 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.717526.717526 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.721907.721907 cuda_h.py:19] end allocate_cuda_memory cost 0.0036046504974365234 seconds
INFO 01-05 09:19:37.721873.721873 client.py:127] Model loaded
DEBUG 01-05 09:19:37.721440.721440 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.721516.721516 cuda_h.py:19] end wait_experts cost 0.004520416259765625 seconds
DEBUG 01-05 09:19:37.721644.721644 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.721255.721255 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.721411.721411 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.722788.722788 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.722890.722890 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 772258e5-df06-454c-8f3d-1ad84ebe9075
DEBUG 01-05 09:19:37.722882.722882 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:37.725873.725873 mlpmodule.py:531] gpu group tensors cost 0.0036258697509765625 s
INFO 01-05 09:19:37.726369.726369 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 772258e5-df06-454c-8f3d-1ad84ebe9075
DEBUG 01-05 09:19:37.726245.726245 cuda_h.py:19] end load_into_gpu_async cost 0.004895210266113281 seconds
DEBUG 01-05 09:19:37.726580.726580 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.726986.726986 cuda_h.py:19] end restore_tensors2 cost 0.0001494884490966797 seconds
DEBUG 01-05 09:19:37.726798.726798 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009535789489746094 seconds
INFO 01-05 09:19:37.728110.728110 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 772258e5-df06-454c-8f3d-1ad84ebe9075
DEBUG 01-05 09:19:37.729028.729028 mlpmodule.py:564] gpu pad cost 0.003936052322387695 s
DEBUG 01-05 09:19:37.729408.729408 mlpmodule.py:662]  experts func einsum cost 0.10210776329040527 s
DEBUG 01-05 09:19:37.730514.730514 mlpmodule.py:582] gpu group einsum cost 0.0005877017974853516 s
DEBUG 01-05 09:19:37.733570.733570 mlpmodule.py:611] gpu experts func einsum cost 0.011376380920410156 s
DEBUG 01-05 09:19:37.733653.733653 cuda_h.py:19] end gpu_experts cost 0.011558055877685547 seconds
DEBUG 01-05 09:19:37.733647.733647 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:37.736987.736987 client.py:127] Model loaded
DEBUG 01-05 09:19:37.736244.736244 cuda_h.py:19] end sllm_worker_task cost 0.0191800594329834 seconds
DEBUG 01-05 09:19:37.736129.736129 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.003270387649536133 seconds
DEBUG 01-05 09:19:37.736101.736101 cuda_h.py:19] end layer_moe_generate_25 cost 0.11662530899047852 seconds
DEBUG 01-05 09:19:37.736107.736107 lmp.py:214] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 09:19:37.737154.737154 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 09:19:37.737373.737373 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.737793.737793 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.739571.739571 cuda_h.py:19] end self_attn cost 0.0024149417877197266 seconds
DEBUG 01-05 09:19:37.740270.740270 cuda_h.py:19] end iln_self_attn_paln cost 0.003018617630004883 seconds
DEBUG 01-05 09:19:37.740206.740206 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 09:19:37.740161.740161 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.740003.740003 cuda_h.py:19] end gate cost 0.0005850791931152344 seconds
DEBUG 01-05 09:19:37.740640.740640 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.741524.741524 lmp.py:361] 
DEBUG 01-05 09:19:37.741524.741524 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.741426.741426 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.741030.741030 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.741534.741534 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.741799.741799 lmp.py:365] 
DEBUG 01-05 09:19:37.741799.741799 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.741681.741681 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.741284.741284 lmp.py:372]   Expert 17 |     51 | CPU
DEBUG 01-05 09:19:37.741404.741404 lmp.py:372]   Expert  3 |     63 | CPU
DEBUG 01-05 09:19:37.741570.741570 lmp.py:372]   Expert 49 |     65 | CPU
DEBUG 01-05 09:19:37.741167.741167 lmp.py:372]   Expert 30 |     66 | CPU
DEBUG 01-05 09:19:37.741525.741525 lmp.py:372]   Expert 62 |     66 | CPU
DEBUG 01-05 09:19:37.741929.741929 lmp.py:372]   Expert 58 |     67 | CPU
DEBUG 01-05 09:19:37.741142.741142 lmp.py:372]   Expert 55 |     75 | CPU
DEBUG 01-05 09:19:37.741308.741308 lmp.py:372]   Expert 59 |     77 | CPU
DEBUG 01-05 09:19:37.741474.741474 lmp.py:372]   Expert 51 |     78 | CPU
DEBUG 01-05 09:19:37.741356.741356 lmp.py:372]   Expert 19 |     80 | CPU
DEBUG 01-05 09:19:37.741522.741522 lmp.py:372]   Expert 61 |     85 | CPU
DEBUG 01-05 09:19:37.741973.741973 lmp.py:372]   Expert  9 |     86 | CPU
DEBUG 01-05 09:19:37.741662.741662 lmp.py:372]   Expert 24 |     87 | CPU
DEBUG 01-05 09:19:37.741590.741590 lmp.py:372]   Expert  6 |     92 | CPU
DEBUG 01-05 09:19:37.741517.741517 lmp.py:372]   Expert  8 |     95 | CPU
DEBUG 01-05 09:19:37.741068.741068 lmp.py:372]   Expert  7 |     98 | CPU
DEBUG 01-05 09:19:37.741187.741187 lmp.py:372]   Expert 56 |     98 | CPU
DEBUG 01-05 09:19:37.741069.741069 lmp.py:372]   Expert 15 |    100 | CPU
DEBUG 01-05 09:19:37.741950.741950 lmp.py:372]   Expert 21 |    101 | CPU
DEBUG 01-05 09:19:37.741832.741832 lmp.py:372]   Expert 60 |    101 | CPU
DEBUG 01-05 09:19:37.741667.741667 lmp.py:372]   Expert 43 |    115 | CPU
DEBUG 01-05 09:19:37.741787.741787 lmp.py:372]   Expert 13 |    117 | CPU
DEBUG 01-05 09:19:37.741291.741291 lmp.py:372]   Expert 11 |    126 | CPU
DEBUG 01-05 09:19:37.741980.741980 lmp.py:372]   Expert 12 |    127 | CPU
DEBUG 01-05 09:19:37.741431.741431 lmp.py:372]   Expert 41 |    133 | CPU
DEBUG 01-05 09:19:37.741882.741882 lmp.py:372]   Expert 53 |    134 | CPU
DEBUG 01-05 09:19:37.741001.741001 lmp.py:372]   Expert 26 |    136 | CPU
DEBUG 01-05 09:19:37.741644.741644 lmp.py:372]   Expert 27 |    139 | CPU
DEBUG 01-05 09:19:37.741526.741526 lmp.py:372]   Expert  0 |    144 | CPU
DEBUG 01-05 09:19:37.741215.741215 lmp.py:372]   Expert 38 |    144 | CPU
DEBUG 01-05 09:19:37.741904.741904 lmp.py:372]   Expert 28 |    147 | CPU
DEBUG 01-05 09:19:37.741786.741786 lmp.py:372]   Expert 47 |    147 | CPU
DEBUG 01-05 09:19:37.741713.741713 lmp.py:372]   Expert 22 |    149 | GPU
DEBUG 01-05 09:19:37.741164.741164 lmp.py:372]   Expert 29 |    149 | GPU
DEBUG 01-05 09:19:37.741569.741569 lmp.py:372]   Expert 45 |    152 | GPU
DEBUG 01-05 09:19:37.741973.741973 lmp.py:372]   Expert 34 |    156 | GPU
DEBUG 01-05 09:19:37.741424.741424 lmp.py:372]   Expert 57 |    166 | GPU
DEBUG 01-05 09:19:37.741783.741783 lmp.py:372]   Expert 37 |    170 | GPU
DEBUG 01-05 09:19:37.741949.741949 lmp.py:372]   Expert 32 |    192 | GPU
DEBUG 01-05 09:19:37.741923.741923 lmp.py:372]   Expert  1 |    194 | GPU
DEBUG 01-05 09:19:37.741135.741135 lmp.py:372]   Expert 23 |    195 | GPU
DEBUG 01-05 09:19:37.742348.742348 lmp.py:372]   Expert 48 |    204 | GPU
DEBUG 01-05 09:19:37.742514.742514 lmp.py:372]   Expert 36 |    205 | GPU
DEBUG 01-05 09:19:37.742157.742157 lmp.py:372]   Expert 42 |    212 | GPU
DEBUG 01-05 09:19:37.742753.742753 lmp.py:372]   Expert  4 |    218 | GPU
DEBUG 01-05 09:19:37.742681.742681 lmp.py:372]   Expert 54 |    225 | GPU
DEBUG 01-05 09:19:37.742132.742132 lmp.py:372]   Expert 39 |    232 | GPU
DEBUG 01-05 09:19:37.742583.742583 lmp.py:372]   Expert 31 |    241 | GPU
DEBUG 01-05 09:19:37.742034.742034 lmp.py:372]   Expert 16 |    254 | GPU
DEBUG 01-05 09:19:37.742246.742246 lmp.py:372]   Expert 20 |    261 | GPU
DEBUG 01-05 09:19:37.742366.742366 lmp.py:372]   Expert 33 |    269 | GPU
DEBUG 01-05 09:19:37.742532.742532 lmp.py:372]   Expert  2 |    277 | GPU
DEBUG 01-05 09:19:37.742698.742698 lmp.py:372]   Expert  5 |    305 | GPU
DEBUG 01-05 09:19:37.742388.742388 lmp.py:372]   Expert 44 |    306 | GPU
DEBUG 01-05 09:19:37.742600.742600 lmp.py:372]   Expert 18 |    313 | GPU
DEBUG 01-05 09:19:37.742813.742813 lmp.py:372]   Expert 50 |    327 | GPU
DEBUG 01-05 09:19:37.742171.742171 lmp.py:372]   Expert 25 |    341 | GPU
DEBUG 01-05 09:19:37.742622.742622 lmp.py:372]   Expert 10 |    354 | GPU
DEBUG 01-05 09:19:37.742834.742834 lmp.py:372]   Expert 35 |    361 | GPU
DEBUG 01-05 09:19:37.742000.742000 lmp.py:372]   Expert 63 |    393 | GPU
DEBUG 01-05 09:19:37.742690.742690 lmp.py:372]   Expert 40 |    445 | GPU
DEBUG 01-05 09:19:37.742617.742617 lmp.py:372]   Expert 46 |    487 | GPU
DEBUG 01-05 09:19:37.742022.742022 lmp.py:372]   Expert 52 |    527 | GPU
DEBUG 01-05 09:19:37.742234.742234 lmp.py:372]   Expert 14 |    768 | GPU
DEBUG 01-05 09:19:37.742401.742401 lmp.py:373] 
DEBUG 01-05 09:19:37.742401.742401 lmp.py:373]   CPU total tokens: 3240 (26.4%)
DEBUG 01-05 09:19:37.742567.742567 lmp.py:374]   GPU total tokens: 9048 (73.6%)
DEBUG 01-05 09:19:37.742501.742501 cuda_h.py:19] end experts_map_get cost 0.0015544891357421875 seconds
DEBUG 01-05 09:19:37.742098.742098 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.742119.742119 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.742687.742687 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.742709.742709 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-05 09:19:37.742221.742221 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.742500.742500 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.743693.743693 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.743866.743866 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dab657c9-c2a0-4d46-8688-d89de5bd4ab1
DEBUG 01-05 09:19:37.743687.743687 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.744863.744863 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dab657c9-c2a0-4d46-8688-d89de5bd4ab1
DEBUG 01-05 09:19:37.744792.744792 cuda_h.py:19] end load_into_gpu_async cost 0.0011973381042480469 seconds
DEBUG 01-05 09:19:37.744402.744402 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.744427.744427 cuda_h.py:19] end restore_tensors2 cost 0.00030517578125 seconds
DEBUG 01-05 09:19:37.744249.744249 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020749568939208984 seconds
DEBUG 01-05 09:19:37.747032.747032 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00473332405090332 seconds
DEBUG 01-05 09:19:37.747100.747100 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.747348.747348 lmp.py:419] 
DEBUG 01-05 09:19:37.747348.747348 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.747330.747330 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 09:19:37.747456.747456 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.753525.753525 mlpmodule.py:704] group tensors cost 0.005663633346557617 s
DEBUG 01-05 09:19:37.755029.755029 mlpmodule.py:742] pad cost 0.0017714500427246094 s
DEBUG 01-05 09:19:37.755450.755450 mlpmodule.py:748] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-05 09:19:37.755698.755698 mlpmodule.py:753] move to cpu cost 4.38690185546875e-05 s
DEBUG 01-05 09:19:37.767997.767997 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.767512.767512 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.767363.767363 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 09:19:37.767202.767202 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.786866.786866 mlpmodule.py:793] group einsum cost 0.031052350997924805 s
DEBUG 01-05 09:19:37.788513.788513 mlpmodule.py:801] cpy2cputensor cost 0.001531839370727539 s
DEBUG 01-05 09:19:37.830754.830754 cuda_h.py:19] end wait_cetm_experts cost 0.0830087661743164 seconds
DEBUG 01-05 09:19:37.830339.830339 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.831349.831349 cuda_h.py:19] end gpu_sexperts cost 0.0004570484161376953 seconds
DEBUG 01-05 09:19:37.831570.831570 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:19:37.831862.831862 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:19:37.831633.831633 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.4332275390625e-05 seconds
DEBUG 01-05 09:19:37.831954.831954 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:37.831653.831653 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.0002281665802001953 seconds
DEBUG 01-05 09:19:37.831995.831995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.831813.831813 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.831542.831542 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dab657c9-c2a0-4d46-8688-d89de5bd4ab1
DEBUG 01-05 09:19:37.831764.831764 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.835346.835346 cuda_h.py:19] end allocate_cuda_memory cost 0.003187417984008789 seconds
DEBUG 01-05 09:19:37.835473.835473 cuda_h.py:10] start load_into_gpu_async
INFO 01-05 09:19:37.835047.835047 client.py:127] Model loaded
DEBUG 01-05 09:19:37.835567.835567 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.835180.835180 cuda_h.py:19] end wait_experts cost 0.004017829895019531 seconds
DEBUG 01-05 09:19:37.835110.835110 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.836634.836634 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.836958.836958 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.836645.836645 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24c33e7a-62da-457d-aff3-1fc866d79d9a
DEBUG 01-05 09:19:37.836321.836321 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:37.837311.837311 mlpmodule.py:531] gpu group tensors cost 0.0009355545043945312 s
DEBUG 01-05 09:19:37.838195.838195 mlpmodule.py:564] gpu pad cost 0.001697540283203125 s
DEBUG 01-05 09:19:37.839117.839117 mlpmodule.py:582] gpu group einsum cost 0.0005609989166259766 s
INFO 01-05 09:19:37.839868.839868 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24c33e7a-62da-457d-aff3-1fc866d79d9a
DEBUG 01-05 09:19:37.839546.839546 cuda_h.py:19] end load_into_gpu_async cost 0.004142045974731445 seconds
DEBUG 01-05 09:19:37.839879.839879 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.840134.840134 cuda_h.py:19] end restore_tensors2 cost 8.487701416015625e-05 seconds
DEBUG 01-05 09:19:37.840520.840520 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008371114730834961 seconds
INFO 01-05 09:19:37.840528.840528 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24c33e7a-62da-457d-aff3-1fc866d79d9a
DEBUG 01-05 09:19:37.843726.843726 mlpmodule.py:662]  experts func einsum cost 0.09554028511047363 s
DEBUG 01-05 09:19:37.844678.844678 mlpmodule.py:611] gpu experts func einsum cost 0.007948637008666992 s
DEBUG 01-05 09:19:37.844735.844735 cuda_h.py:19] end gpu_experts cost 0.008151531219482422 seconds
DEBUG 01-05 09:19:37.844213.844213 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:37.847776.847776 client.py:127] Model loaded
DEBUG 01-05 09:19:37.847613.847613 cuda_h.py:19] end sllm_worker_task cost 0.01627969741821289 seconds
DEBUG 01-05 09:19:37.847670.847670 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.003737211227416992 seconds
DEBUG 01-05 09:19:37.848757.848757 cuda_h.py:19] end layer_moe_generate_26 cost 0.10799121856689453 seconds
DEBUG 01-05 09:19:37.848790.848790 lmp.py:214] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 09:19:37.848619.848619 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 09:19:37.848031.848031 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:37.848649.848649 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:37.851932.851932 cuda_h.py:19] end self_attn cost 0.0024335384368896484 seconds
DEBUG 01-05 09:19:37.851293.851293 cuda_h.py:19] end iln_self_attn_paln cost 0.0030400753021240234 seconds
DEBUG 01-05 09:19:37.851897.851897 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 09:19:37.851852.851852 cuda_h.py:10] start gate
DEBUG 01-05 09:19:37.852548.852548 cuda_h.py:19] end gate cost 0.0005810260772705078 seconds
DEBUG 01-05 09:19:37.852947.852947 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:37.852699.852699 lmp.py:361] 
DEBUG 01-05 09:19:37.852699.852699 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:37.852840.852840 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:37.852205.852205 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:37.852993.852993 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:37.852020.852020 lmp.py:365] 
DEBUG 01-05 09:19:37.852020.852020 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:37.852094.852094 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:37.852704.852704 lmp.py:372]   Expert 18 |     35 | CPU
DEBUG 01-05 09:19:37.852016.852016 lmp.py:372]   Expert 47 |     40 | CPU
DEBUG 01-05 09:19:37.852805.852805 lmp.py:372]   Expert 54 |     57 | CPU
DEBUG 01-05 09:19:37.852402.852402 lmp.py:372]   Expert 58 |     67 | CPU
DEBUG 01-05 09:19:37.852760.852760 lmp.py:372]   Expert 15 |     74 | CPU
DEBUG 01-05 09:19:37.852641.852641 lmp.py:372]   Expert 32 |     74 | CPU
DEBUG 01-05 09:19:37.852523.852523 lmp.py:372]   Expert  7 |     80 | CPU
DEBUG 01-05 09:19:37.852927.852927 lmp.py:372]   Expert 59 |     80 | CPU
DEBUG 01-05 09:19:37.852524.852524 lmp.py:372]   Expert 12 |     83 | CPU
DEBUG 01-05 09:19:37.852213.852213 lmp.py:372]   Expert 38 |     84 | CPU
DEBUG 01-05 09:19:37.852141.852141 lmp.py:372]   Expert 24 |     85 | CPU
DEBUG 01-05 09:19:37.852830.852830 lmp.py:372]   Expert 11 |     86 | CPU
DEBUG 01-05 09:19:37.852235.852235 lmp.py:372]   Expert 61 |     98 | CPU
DEBUG 01-05 09:19:37.852878.852878 lmp.py:372]   Expert 42 |    102 | CPU
DEBUG 01-05 09:19:37.852805.852805 lmp.py:372]   Expert 40 |    113 | CPU
DEBUG 01-05 09:19:37.852779.852779 lmp.py:372]   Expert 46 |    119 | CPU
DEBUG 01-05 09:19:37.853230.853230 lmp.py:372]   Expert 23 |    120 | CPU
DEBUG 01-05 09:19:37.853396.853396 lmp.py:372]   Expert  6 |    123 | CPU
DEBUG 01-05 09:19:37.853563.853563 lmp.py:372]   Expert 39 |    126 | CPU
DEBUG 01-05 09:19:37.853636.853636 lmp.py:372]   Expert 52 |    127 | CPU
DEBUG 01-05 09:19:37.853087.853087 lmp.py:372]   Expert 45 |    129 | CPU
DEBUG 01-05 09:19:37.853776.853776 lmp.py:372]   Expert 34 |    135 | CPU
DEBUG 01-05 09:19:37.853989.853989 lmp.py:372]   Expert 51 |    138 | CPU
DEBUG 01-05 09:19:37.853201.853201 lmp.py:372]   Expert 48 |    140 | CPU
DEBUG 01-05 09:19:37.853414.853414 lmp.py:372]   Expert 30 |    149 | CPU
DEBUG 01-05 09:19:37.853626.853626 lmp.py:372]   Expert  3 |    157 | CPU
DEBUG 01-05 09:19:37.853031.853031 lmp.py:372]   Expert 10 |    161 | CPU
DEBUG 01-05 09:19:37.853866.853866 lmp.py:372]   Expert 44 |    161 | CPU
DEBUG 01-05 09:19:37.853317.853317 lmp.py:372]   Expert 16 |    169 | CPU
DEBUG 01-05 09:19:37.853767.853767 lmp.py:372]   Expert 56 |    174 | CPU
DEBUG 01-05 09:19:37.853741.853741 lmp.py:372]   Expert 31 |    176 | CPU
DEBUG 01-05 09:19:37.853431.853431 lmp.py:372]   Expert 29 |    180 | CPU
DEBUG 01-05 09:19:37.853120.853120 lmp.py:372]   Expert 19 |    181 | GPU
DEBUG 01-05 09:19:37.853478.853478 lmp.py:372]   Expert 25 |    184 | GPU
DEBUG 01-05 09:19:37.853552.853552 lmp.py:372]   Expert  4 |    187 | GPU
DEBUG 01-05 09:19:37.853479.853479 lmp.py:372]   Expert 22 |    187 | GPU
DEBUG 01-05 09:19:37.853454.853454 lmp.py:372]   Expert  1 |    194 | GPU
DEBUG 01-05 09:19:37.853904.853904 lmp.py:372]   Expert 13 |    194 | GPU
DEBUG 01-05 09:19:37.853786.853786 lmp.py:372]   Expert 50 |    199 | GPU
DEBUG 01-05 09:19:37.853714.853714 lmp.py:372]   Expert 36 |    203 | GPU
DEBUG 01-05 09:19:37.853926.853926 lmp.py:372]   Expert 17 |    205 | GPU
DEBUG 01-05 09:19:37.853138.853138 lmp.py:372]   Expert 33 |    211 | GPU
DEBUG 01-05 09:19:37.853543.853543 lmp.py:372]   Expert 57 |    211 | GPU
DEBUG 01-05 09:19:37.853232.853232 lmp.py:372]   Expert 62 |    223 | GPU
DEBUG 01-05 09:19:37.853591.853591 lmp.py:372]   Expert 53 |    224 | GPU
DEBUG 01-05 09:19:37.853041.853041 lmp.py:372]   Expert 55 |    231 | GPU
DEBUG 01-05 09:19:37.853492.853492 lmp.py:372]   Expert  8 |    236 | GPU
DEBUG 01-05 09:19:37.853943.853943 lmp.py:372]   Expert  0 |    249 | GPU
DEBUG 01-05 09:19:37.853917.853917 lmp.py:372]   Expert 26 |    250 | GPU
DEBUG 01-05 09:19:37.853368.853368 lmp.py:372]   Expert  5 |    251 | GPU
DEBUG 01-05 09:19:37.853773.853773 lmp.py:372]   Expert 41 |    255 | GPU
DEBUG 01-05 09:19:37.853608.853608 lmp.py:372]   Expert 49 |    257 | GPU
DEBUG 01-05 09:19:37.853059.853059 lmp.py:372]   Expert 35 |    264 | GPU
DEBUG 01-05 09:19:37.853510.853510 lmp.py:372]   Expert 28 |    278 | GPU
DEBUG 01-05 09:19:37.853484.853484 lmp.py:372]   Expert 37 |    283 | GPU
DEBUG 01-05 09:19:37.853696.853696 lmp.py:372]   Expert 14 |    312 | GPU
DEBUG 01-05 09:19:37.853908.853908 lmp.py:372]   Expert 27 |    338 | GPU
DEBUG 01-05 09:19:37.853267.853267 lmp.py:372]   Expert  2 |    347 | GPU
DEBUG 01-05 09:19:37.853671.853671 lmp.py:372]   Expert 21 |    361 | GPU
DEBUG 01-05 09:19:37.853122.853122 lmp.py:372]   Expert 60 |    379 | GPU
DEBUG 01-05 09:19:37.853811.853811 lmp.py:372]   Expert  9 |    391 | GPU
DEBUG 01-05 09:19:37.853785.853785 lmp.py:372]   Expert 43 |    396 | GPU
DEBUG 01-05 09:19:37.853713.853713 lmp.py:372]   Expert 63 |    447 | GPU
DEBUG 01-05 09:19:37.853356.853356 lmp.py:372]   Expert 20 |    518 | GPU
DEBUG 01-05 09:19:37.853522.853522 lmp.py:373] 
DEBUG 01-05 09:19:37.853522.853522 lmp.py:373]   CPU total tokens: 3642 (29.6%)
DEBUG 01-05 09:19:37.853927.853927 lmp.py:374]   GPU total tokens: 8646 (70.4%)
DEBUG 01-05 09:19:37.853100.853100 cuda_h.py:19] end experts_map_get cost 0.0015587806701660156 seconds
DEBUG 01-05 09:19:37.853458.853458 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:37.853572.853572 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:37.854716.854716 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:37.854606.854606 cuda_h.py:19] end allocate_cuda_memory cost 0.00023651123046875 seconds
DEBUG 01-05 09:19:37.854641.854641 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:37.854920.854920 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:37.854021.854021 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:37.854432.854432 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 085c4603-63f2-485e-9ca8-2d6b5742b3a7
DEBUG 01-05 09:19:37.854598.854598 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:37.855092.855092 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 085c4603-63f2-485e-9ca8-2d6b5742b3a7
DEBUG 01-05 09:19:37.855399.855399 cuda_h.py:19] end load_into_gpu_async cost 0.0012302398681640625 seconds
DEBUG 01-05 09:19:37.855479.855479 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:37.856119.856119 cuda_h.py:19] end restore_tensors2 cost 0.0003039836883544922 seconds
DEBUG 01-05 09:19:37.856465.856465 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002110719680786133 seconds
DEBUG 01-05 09:19:37.858440.858440 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004767417907714844 seconds
DEBUG 01-05 09:19:37.858031.858031 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:37.858776.858776 lmp.py:419] 
DEBUG 01-05 09:19:37.858776.858776 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:37.858758.858758 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-05 09:19:37.858361.858361 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:37.869722.869722 mlpmodule.py:704] group tensors cost 0.010027408599853516 s
DEBUG 01-05 09:19:37.871994.871994 mlpmodule.py:742] pad cost 0.0015244483947753906 s
DEBUG 01-05 09:19:37.871951.871951 mlpmodule.py:748] create cpu tensor cost 4.935264587402344e-05 s
DEBUG 01-05 09:19:37.871132.871132 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-05 09:19:37.883406.883406 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:37.884206.884206 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:37.884534.884534 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 09:19:37.884797.884797 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:37.901083.901083 mlpmodule.py:793] group einsum cost 0.030298709869384766 s
DEBUG 01-05 09:19:37.904163.904163 mlpmodule.py:801] cpy2cputensor cost 0.0025997161865234375 s
DEBUG 01-05 09:19:37.945150.945150 cuda_h.py:19] end wait_cetm_experts cost 0.08680605888366699 seconds
DEBUG 01-05 09:19:37.945941.945941 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:37.946773.946773 cuda_h.py:19] end gpu_sexperts cost 0.0004642009735107422 seconds
DEBUG 01-05 09:19:37.946424.946424 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 09:19:37.946260.946260 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.2159347534179688e-05 seconds
DEBUG 01-05 09:19:37.946539.946539 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:37.946249.946249 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 085c4603-63f2-485e-9ca8-2d6b5742b3a7
INFO 01-05 09:19:37.947762.947762 client.py:127] Model loaded
DEBUG 01-05 09:19:37.947452.947452 cuda_h.py:19] end wait_experts cost 0.0009236335754394531 seconds
DEBUG 01-05 09:19:37.947109.947109 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:37.947580.947580 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:37.948172.948172 mlpmodule.py:531] gpu group tensors cost 0.0006012916564941406 s
DEBUG 01-05 09:19:37.949205.949205 mlpmodule.py:564] gpu pad cost 0.0017266273498535156 s
DEBUG 01-05 09:19:37.950265.950265 mlpmodule.py:582] gpu group einsum cost 0.0005295276641845703 s
DEBUG 01-05 09:19:37.954012.954012 mlpmodule.py:611] gpu experts func einsum cost 0.0064847469329833984 s
DEBUG 01-05 09:19:37.954149.954149 cuda_h.py:19] end gpu_experts cost 0.006705284118652344 seconds
DEBUG 01-05 09:19:37.954104.954104 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:37.954588.954588 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.5367431640625e-06 seconds
DEBUG 01-05 09:19:37.954216.954216 cuda_h.py:19] end layer_moe_generate_27 cost 0.10283565521240234 seconds
DEBUG 01-05 09:19:37.954932.954932 lmp.py:214] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 09:19:37.954085.954085 cuda_h.py:19] end multi_layer cost 3.8011295795440674 seconds
DEBUG 01-05 09:19:37.954464.954464 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:19:37.958045.958045 mlpmodule.py:662]  experts func einsum cost 0.09901046752929688 s
DEBUG 01-05 09:19:38.031664.031664 cuda_h.py:19] end init_inputs_tokens cost 0.07673501968383789 seconds
DEBUG 01-05 09:19:38.031920.031920 lmp.py:283] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:19:38.031623.031623 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:19:38.034534.034534 lmp.py:286] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:19:38.034543.034543 cuda_h.py:19] end dense_mlp cost 0.0027205944061279297 seconds
INFO 01-05 09:19:38.034500.034500 lmp.py:523] 
INFO 01-05 09:19:38.034500.034500 lmp.py:523] ============================================================
INFO 01-05 09:19:38.034269.034269 lmp.py:524] Layer 1 Expert Device Distribution:
INFO 01-05 09:19:38.034940.034940 lmp.py:533]   Total experts: 64
INFO 01-05 09:19:38.035934.035934 lmp.py:535]   meta: 32 experts - Expert IDs: [0, 1, 3, 4, 11, 13, 15, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 47, 49, 52, 53, 54, 55, 56, 58, 62]
INFO 01-05 09:19:38.035014.035014 lmp.py:535]   cuda:1: 32 experts - Expert IDs: [2, 5, 6, 7, 8, 9, 10, 12, 14, 16, 19, 20, 23, 24, 26, 34, 35, 36, 40, 42, 43, 44, 45, 46, 48, 50, 51, 57, 59, 60, 61, 63]
INFO 01-05 09:19:38.035372.035372 lmp.py:538] 
INFO 01-05 09:19:38.035372.035372 lmp.py:538]   Detailed Expert Device Map:
INFO 01-05 09:19:38.035830.035830 lmp.py:539]   Expert ID  | Device         
INFO 01-05 09:19:38.035473.035473 lmp.py:540]   ------------------------------
INFO 01-05 09:19:38.035169.035169 lmp.py:543]   0          | meta           
INFO 01-05 09:19:38.035673.035673 lmp.py:543]   1          | meta           
INFO 01-05 09:19:38.035839.035839 lmp.py:543]   2          | cuda:1         
INFO 01-05 09:19:38.035721.035721 lmp.py:543]   3          | meta           
INFO 01-05 09:19:38.035841.035841 lmp.py:543]   4          | meta           
INFO 01-05 09:19:38.035768.035768 lmp.py:543]   5          | cuda:1         
INFO 01-05 09:19:38.035650.035650 lmp.py:543]   6          | cuda:1         
INFO 01-05 09:19:38.035816.035816 lmp.py:543]   7          | cuda:1         
INFO 01-05 09:19:38.035505.035505 lmp.py:543]   8          | cuda:1         
INFO 01-05 09:19:38.035718.035718 lmp.py:543]   9          | cuda:1         
INFO 01-05 09:19:38.035692.035692 lmp.py:543]   10         | cuda:1         
INFO 01-05 09:19:38.035143.035143 lmp.py:543]   11         | meta           
INFO 01-05 09:19:38.035832.035832 lmp.py:543]   12         | cuda:1         
INFO 01-05 09:19:38.035044.035044 lmp.py:543]   13         | meta           
INFO 01-05 09:19:38.035210.035210 lmp.py:543]   14         | cuda:1         
INFO 01-05 09:19:38.035045.035045 lmp.py:543]   15         | meta           
INFO 01-05 09:19:38.035496.035496 lmp.py:543]   16         | cuda:1         
INFO 01-05 09:19:38.035232.035232 lmp.py:543]   17         | meta           
INFO 01-05 09:19:38.035683.035683 lmp.py:543]   18         | meta           
INFO 01-05 09:19:38.035657.035657 lmp.py:543]   19         | cuda:1         
INFO 01-05 09:19:38.035869.035869 lmp.py:543]   20         | cuda:1         
INFO 01-05 09:19:38.035751.035751 lmp.py:543]   21         | meta           
INFO 01-05 09:19:38.035725.035725 lmp.py:543]   22         | meta           
INFO 01-05 09:19:38.035460.035460 lmp.py:543]   23         | cuda:1         
INFO 01-05 09:19:38.035434.035434 lmp.py:543]   24         | cuda:1         
INFO 01-05 09:19:38.035932.035932 lmp.py:543]   25         | meta           
INFO 01-05 09:19:38.035859.035859 lmp.py:543]   26         | cuda:1         
INFO 01-05 09:19:38.035264.035264 lmp.py:543]   27         | meta           
INFO 01-05 09:19:38.035622.035622 lmp.py:543]   28         | meta           
INFO 01-05 09:19:38.035358.035358 lmp.py:543]   29         | meta           
INFO 01-05 09:19:38.035332.035332 lmp.py:543]   30         | meta           
INFO 01-05 09:19:38.035829.035829 lmp.py:543]   31         | meta           
INFO 01-05 09:19:38.035803.035803 lmp.py:543]   32         | meta           
INFO 01-05 09:19:38.035300.035300 lmp.py:543]   33         | meta           
INFO 01-05 09:19:38.035943.035943 lmp.py:543]   34         | cuda:1         
INFO 01-05 09:19:38.035732.035732 lmp.py:543]   35         | cuda:1         
INFO 01-05 09:19:38.035898.035898 lmp.py:543]   36         | cuda:1         
INFO 01-05 09:19:38.035872.035872 lmp.py:543]   37         | meta           
INFO 01-05 09:19:38.035846.035846 lmp.py:543]   38         | meta           
INFO 01-05 09:19:38.035820.035820 lmp.py:543]   39         | meta           
INFO 01-05 09:19:38.035702.035702 lmp.py:543]   40         | cuda:1         
INFO 01-05 09:19:38.035676.035676 lmp.py:543]   41         | meta           
INFO 01-05 09:19:38.035411.035411 lmp.py:543]   42         | cuda:1         
INFO 01-05 09:19:38.035385.035385 lmp.py:543]   43         | cuda:1         
INFO 01-05 09:19:38.035359.035359 lmp.py:543]   44         | cuda:1         
INFO 01-05 09:19:38.035764.035764 lmp.py:543]   45         | cuda:1         
INFO 01-05 09:19:38.035930.035930 lmp.py:543]   46         | cuda:1         
INFO 01-05 09:19:38.035335.035335 lmp.py:543]   47         | meta           
INFO 01-05 09:19:38.035931.035931 lmp.py:543]   48         | cuda:1         
INFO 01-05 09:19:38.035667.035667 lmp.py:543]   49         | meta           
INFO 01-05 09:19:38.035164.035164 lmp.py:543]   50         | cuda:1         
INFO 01-05 09:19:38.035661.035661 lmp.py:543]   51         | cuda:1         
INFO 01-05 09:19:38.036635.036635 lmp.py:543]   52         | meta           
INFO 01-05 09:19:38.036894.036894 lmp.py:543]   53         | meta           
INFO 01-05 09:19:38.036776.036776 lmp.py:543]   54         | meta           
INFO 01-05 09:19:38.036849.036849 lmp.py:543]   55         | meta           
INFO 01-05 09:19:38.036638.036638 lmp.py:543]   56         | meta           
INFO 01-05 09:19:38.036850.036850 lmp.py:543]   57         | cuda:1         
INFO 01-05 09:19:38.036348.036348 lmp.py:543]   58         | meta           
INFO 01-05 09:19:38.036083.036083 lmp.py:543]   59         | cuda:1         
INFO 01-05 09:19:38.036488.036488 lmp.py:543]   60         | cuda:1         
INFO 01-05 09:19:38.036985.036985 lmp.py:543]   61         | cuda:1         
INFO 01-05 09:19:38.036244.036244 lmp.py:543]   62         | meta           
INFO 01-05 09:19:38.036218.036218 lmp.py:543]   63         | cuda:1         
INFO 01-05 09:19:38.036715.036715 lmp.py:544] ============================================================
INFO 01-05 09:19:38.036715.036715 lmp.py:544] 
DEBUG 01-05 09:19:38.036073.036073 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 09:19:38.036260.036260 cuda_h.py:10] start gate
DEBUG 01-05 09:19:38.064305.064305 cuda_h.py:19] end gate cost 0.027800321578979492 seconds
DEBUG 01-05 09:19:38.064539.064539 cuda_h.py:10] start experts_map_get
INFO 01-05 09:19:38.064953.064953 lmp.py:608] 
INFO 01-05 09:19:38.064953.064953 lmp.py:608] Layer 1 Expert Device Distribution:
INFO 01-05 09:19:38.064669.064669 lmp.py:609]   Active experts: 47 (out of 64 total)
INFO 01-05 09:19:38.064995.064995 lmp.py:610]   CPU experts: 23 (49%) - Expert IDs: [1, 2, 8, 9, 12, 19, 22, 28, 29, 30, 32, 33, 35, 37, 40, 41, 43, 45, 47, 49, 50, 52, 53]
INFO 01-05 09:19:38.064075.064075 lmp.py:611]   GPU experts: 24 (51%) - Expert IDs: [0, 4, 5, 6, 7, 10, 11, 14, 15, 16, 20, 23, 24, 26, 31, 34, 42, 44, 46, 57, 59, 60, 61, 63]
INFO 01-05 09:19:38.064202.064202 lmp.py:612]   CPU tokens: 41 (21.4%)
INFO 01-05 09:19:38.064560.064560 lmp.py:613]   GPU tokens: 151 (78.6%)
INFO 01-05 09:19:38.064011.064011 lmp.py:614] 
INFO 01-05 09:19:38.064011.064011 lmp.py:614]   Detailed Expert Distribution:
INFO 01-05 09:19:38.064323.064323 lmp.py:615]   Expert ID  | Tokens     | Device       | Token %   
INFO 01-05 09:19:38.064489.064489 lmp.py:616]   --------------------------------------------------
INFO 01-05 09:19:38.064039.064039 lmp.py:620]   22         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064636.064636 lmp.py:620]   30         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064279.064279 lmp.py:620]   32         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064683.064683 lmp.py:620]   37         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064088.064088 lmp.py:620]   40         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064254.064254 lmp.py:620]   41         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064420.064420 lmp.py:620]   47         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064586.064586 lmp.py:620]   49         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064183.064183 lmp.py:620]   53         | 1          | CPU          |   0.52%
INFO 01-05 09:19:38.064018.064018 lmp.py:620]   1          | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064615.064615 lmp.py:620]   8          | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064927.064927 lmp.py:620]   9          | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064331.064331 lmp.py:620]   12         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064358.064358 lmp.py:620]   19         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064763.064763 lmp.py:620]   28         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064167.064167 lmp.py:620]   29         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064857.064857 lmp.py:620]   35         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064023.064023 lmp.py:620]   50         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.064619.064619 lmp.py:620]   52         | 2          | CPU          |   1.04%
INFO 01-05 09:19:38.065262.065262 lmp.py:620]   2          | 3          | CPU          |   1.56%
INFO 01-05 09:19:38.065429.065429 lmp.py:620]   33         | 3          | CPU          |   1.56%
INFO 01-05 09:19:38.065356.065356 lmp.py:620]   43         | 3          | CPU          |   1.56%
INFO 01-05 09:19:38.065284.065284 lmp.py:620]   45         | 3          | CPU          |   1.56%
INFO 01-05 09:19:38.065404.065404 lmp.py:620]   60         | 3          | GPU(cuda:1)  |   1.56%
INFO 01-05 09:19:38.065762.065762 lmp.py:620]   0          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:38.065405.065405 lmp.py:620]   7          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:38.065286.065286 lmp.py:620]   16         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:38.065929.065929 lmp.py:620]   4          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065341.065341 lmp.py:620]   6          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065937.065937 lmp.py:620]   26         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065249.065249 lmp.py:620]   42         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065131.065131 lmp.py:620]   44         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065297.065297 lmp.py:620]   59         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065701.065701 lmp.py:620]   61         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:38.065821.065821 lmp.py:620]   5          | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:38.065848.065848 lmp.py:620]   11         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:38.065491.065491 lmp.py:620]   15         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:38.065657.065657 lmp.py:620]   46         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:38.065062.065062 lmp.py:620]   10         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:38.065705.065705 lmp.py:620]   14         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:38.065971.065971 lmp.py:620]   20         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:38.065567.065567 lmp.py:620]   24         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:19:38.065164.065164 lmp.py:620]   63         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:19:38.065476.065476 lmp.py:620]   23         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:38.065119.065119 lmp.py:620]   34         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:19:38.065285.065285 lmp.py:620]   57         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:19:38.065689.065689 lmp.py:620]   31         | 11         | GPU(cuda:1)  |   5.73%
INFO 01-05 09:19:38.065902.065902 lmp.py:621] ============================================================
INFO 01-05 09:19:38.065902.065902 lmp.py:621] 
DEBUG 01-05 09:19:38.065982.065982 cuda_h.py:19] end experts_map_get cost 0.0013337135314941406 seconds
DEBUG 01-05 09:19:38.065632.065632 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.029323577880859375 seconds
DEBUG 01-05 09:19:39.225319.225319 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11162567138671875 s
DEBUG 01-05 09:19:39.583618.583618 cuda_h.py:19] end generate_input_ids cost 0.35738253593444824 seconds
DEBUG 01-05 09:19:39.583617.583617 cuda_h.py:10] start init_cache
DEBUG 01-05 09:19:39.583085.583085 cuda_h.py:19] end init_cache cost 7.581710815429688e-05 seconds
DEBUG 01-05 09:19:42.040806.040806 cuda_h.py:10] start init_weights
DEBUG 01-05 09:19:42.041754.041754 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:42.041631.041631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:42.043683.043683 cuda_h.py:19] end allocate_cuda_memory cost 0.0021047592163085938 seconds
DEBUG 01-05 09:19:42.043917.043917 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:42.043104.043104 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:42.043285.043285 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:42.043988.043988 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b9bfb61a-25fa-4aad-a7e8-9c82211bf11a
DEBUG 01-05 09:19:42.044149.044149 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:42.045846.045846 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b9bfb61a-25fa-4aad-a7e8-9c82211bf11a
DEBUG 01-05 09:19:42.045828.045828 cuda_h.py:19] end load_into_gpu_async cost 0.0014462471008300781 seconds
DEBUG 01-05 09:19:42.045954.045954 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:42.045547.045547 cuda_h.py:19] end restore_tensors2 cost 5.841255187988281e-05 seconds
DEBUG 01-05 09:19:42.045296.045296 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003838777542114258 seconds
INFO 01-05 09:19:42.045163.045163 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b9bfb61a-25fa-4aad-a7e8-9c82211bf11a
INFO 01-05 09:19:42.120878.120878 client.py:127] Model loaded
DEBUG 01-05 09:19:42.121790.121790 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 09:19:42.121907.121907 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:42.121692.121692 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:42.121631.121631 cuda_h.py:19] end allocate_cuda_memory cost 0.00045871734619140625 seconds
DEBUG 01-05 09:19:42.122358.122358 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:42.122043.122043 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:42.122033.122033 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:42.122082.122082 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6106e59f-324a-4913-9bfb-3856ffec6cef
DEBUG 01-05 09:19:42.122929.122929 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:42.123005.123005 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6106e59f-324a-4913-9bfb-3856ffec6cef
DEBUG 01-05 09:19:42.124314.124314 cuda_h.py:19] end load_into_gpu_async cost 0.0019490718841552734 seconds
DEBUG 01-05 09:19:42.124025.124025 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:42.124681.124681 cuda_h.py:19] end restore_tensors2 cost 0.00013136863708496094 seconds
DEBUG 01-05 09:19:42.124108.124108 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003158092498779297 seconds
INFO 01-05 09:19:42.124303.124303 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6106e59f-324a-4913-9bfb-3856ffec6cef
INFO 01-05 09:19:42.141827.141827 client.py:127] Model loaded
DEBUG 01-05 09:19:42.142417.142417 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.0207979679107666 seconds
DEBUG 01-05 09:19:42.142527.142527 cuda_h.py:19] end init_weights cost 0.10061144828796387 seconds
DEBUG 01-05 09:19:42.142768.142768 cuda_h.py:10] start copy_emodel
DEBUG 01-05 09:19:42.897584.897584 cuda_h.py:19] end copy_emodel cost 0.7554585933685303 seconds
DEBUG 01-05 09:19:42.898803.898803 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:19:42.898775.898775 cuda_h.py:19] end init_inputs_tokens cost 0.00030422210693359375 seconds
DEBUG 01-05 09:19:42.899790.899790 cuda_h.py:10] start multi_layer
DEBUG 01-05 09:19:42.899560.899560 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 09:19:42.899494.899494 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:42.899440.899440 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:42.903541.903541 cuda_h.py:19] end self_attn cost 0.0031371116638183594 seconds
DEBUG 01-05 09:19:42.903836.903836 cuda_h.py:19] end iln_self_attn_paln cost 0.004243612289428711 seconds
DEBUG 01-05 09:19:42.903997.903997 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:19:42.903621.903621 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:19:42.903901.903901 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.6716461181640625e-05 seconds
DEBUG 01-05 09:19:42.903713.903713 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:42.903460.903460 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:42.903562.903562 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:42.904498.904498 cuda_h.py:19] end allocate_cuda_memory cost 0.00022029876708984375 seconds
DEBUG 01-05 09:19:42.904764.904764 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:42.904898.904898 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:42.904417.904417 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:42.904273.904273 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4af2c66-d724-4c5a-be5e-bc0aba7dadea
DEBUG 01-05 09:19:42.904952.904952 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:42.905106.905106 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4af2c66-d724-4c5a-be5e-bc0aba7dadea
DEBUG 01-05 09:19:42.905810.905810 cuda_h.py:19] end load_into_gpu_async cost 0.0013077259063720703 seconds
DEBUG 01-05 09:19:42.905566.905566 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:42.905490.905490 cuda_h.py:19] end restore_tensors2 cost 8.535385131835938e-05 seconds
DEBUG 01-05 09:19:42.905704.905704 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020952224731445312 seconds
INFO 01-05 09:19:42.906151.906151 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4af2c66-d724-4c5a-be5e-bc0aba7dadea
INFO 01-05 09:19:42.913261.913261 client.py:127] Model loaded
DEBUG 01-05 09:19:42.913377.913377 cuda_h.py:19] end sllm_worker_task cost 0.009384393692016602 seconds
DEBUG 01-05 09:19:42.913335.913335 cuda_h.py:19] end dense_mlp cost 0.009862422943115234 seconds
DEBUG 01-05 09:19:42.913498.913498 lmp.py:214] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 09:19:42.913645.913645 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 09:19:42.913818.913818 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:42.913323.913323 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:42.916150.916150 cuda_h.py:19] end self_attn cost 0.002310037612915039 seconds
DEBUG 01-05 09:19:42.916391.916391 cuda_h.py:19] end iln_self_attn_paln cost 0.0028498172760009766 seconds
DEBUG 01-05 09:19:42.916056.916056 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 09:19:42.916680.916680 cuda_h.py:10] start gate
DEBUG 01-05 09:19:42.917202.917202 cuda_h.py:19] end gate cost 0.0007357597351074219 seconds
DEBUG 01-05 09:19:42.917793.917793 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:42.917009.917009 lmp.py:361] 
DEBUG 01-05 09:19:42.917009.917009 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:42.917241.917241 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:42.917845.917845 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:42.917395.917395 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:42.917038.917038 lmp.py:365] 
DEBUG 01-05 09:19:42.917038.917038 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:42.917681.917681 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:42.917808.917808 lmp.py:372]   Expert 62 |     66 | CPU
DEBUG 01-05 09:19:42.917212.917212 lmp.py:372]   Expert 18 |     68 | CPU
DEBUG 01-05 09:19:42.917816.917816 lmp.py:372]   Expert 22 |     73 | CPU
DEBUG 01-05 09:19:42.917505.917505 lmp.py:372]   Expert 32 |     83 | CPU
DEBUG 01-05 09:19:42.917956.917956 lmp.py:372]   Expert 52 |     94 | CPU
DEBUG 01-05 09:19:42.917122.917122 lmp.py:372]   Expert  3 |    104 | CPU
DEBUG 01-05 09:19:42.917527.917527 lmp.py:372]   Expert 27 |    114 | CPU
DEBUG 01-05 09:19:42.917931.917931 lmp.py:372]   Expert 38 |    114 | CPU
DEBUG 01-05 09:19:42.917097.917097 lmp.py:372]   Expert 13 |    118 | CPU
DEBUG 01-05 09:19:42.917787.917787 lmp.py:372]   Expert 54 |    118 | CPU
DEBUG 01-05 09:19:42.917999.917999 lmp.py:372]   Expert 17 |    121 | CPU
DEBUG 01-05 09:19:42.917212.917212 lmp.py:372]   Expert 11 |    124 | CPU
DEBUG 01-05 09:19:42.917424.917424 lmp.py:372]   Expert 28 |    124 | CPU
DEBUG 01-05 09:19:42.917636.917636 lmp.py:372]   Expert 37 |    125 | CPU
DEBUG 01-05 09:19:42.917611.917611 lmp.py:372]   Expert 58 |    129 | CPU
DEBUG 01-05 09:19:42.917823.917823 lmp.py:372]   Expert 39 |    131 | CPU
DEBUG 01-05 09:19:42.918559.918559 lmp.py:372]   Expert 25 |    135 | CPU
DEBUG 01-05 09:19:42.918725.918725 lmp.py:372]   Expert 41 |    136 | CPU
DEBUG 01-05 09:19:42.918414.918414 lmp.py:372]   Expert 21 |    150 | CPU
DEBUG 01-05 09:19:42.918819.918819 lmp.py:372]   Expert  4 |    151 | CPU
DEBUG 01-05 09:19:42.918985.918985 lmp.py:372]   Expert 30 |    152 | CPU
DEBUG 01-05 09:19:42.918197.918197 lmp.py:372]   Expert 29 |    155 | CPU
DEBUG 01-05 09:19:42.918648.918648 lmp.py:372]   Expert 53 |    155 | CPU
DEBUG 01-05 09:19:42.918622.918622 lmp.py:372]   Expert 49 |    156 | CPU
DEBUG 01-05 09:19:42.918835.918835 lmp.py:372]   Expert 47 |    157 | CPU
DEBUG 01-05 09:19:42.918809.918809 lmp.py:372]   Expert 31 |    168 | CPU
DEBUG 01-05 09:19:42.918544.918544 lmp.py:372]   Expert 33 |    168 | CPU
DEBUG 01-05 09:19:42.918234.918234 lmp.py:372]   Expert 55 |    173 | CPU
DEBUG 01-05 09:19:42.918638.918638 lmp.py:372]   Expert 56 |    173 | CPU
DEBUG 01-05 09:19:42.918327.918327 lmp.py:372]   Expert 15 |    177 | CPU
DEBUG 01-05 09:19:42.918255.918255 lmp.py:372]   Expert  0 |    178 | CPU
DEBUG 01-05 09:19:42.918468.918468 lmp.py:372]   Expert  1 |    178 | CPU
DEBUG 01-05 09:19:42.918918.918918 lmp.py:372]   Expert 24 |    180 | GPU
DEBUG 01-05 09:19:42.918893.918893 lmp.py:372]   Expert 50 |    182 | GPU
DEBUG 01-05 09:19:42.918867.918867 lmp.py:372]   Expert 51 |    184 | GPU
DEBUG 01-05 09:19:42.918079.918079 lmp.py:372]   Expert 19 |    185 | GPU
DEBUG 01-05 09:19:42.918815.918815 lmp.py:372]   Expert  6 |    186 | GPU
DEBUG 01-05 09:19:42.918789.918789 lmp.py:372]   Expert 10 |    189 | GPU
DEBUG 01-05 09:19:42.918524.918524 lmp.py:372]   Expert 34 |    191 | GPU
DEBUG 01-05 09:19:42.918498.918498 lmp.py:372]   Expert  2 |    195 | GPU
DEBUG 01-05 09:19:42.918665.918665 lmp.py:372]   Expert 45 |    195 | GPU
DEBUG 01-05 09:19:42.918592.918592 lmp.py:372]   Expert 35 |    197 | GPU
DEBUG 01-05 09:19:42.918282.918282 lmp.py:372]   Expert 36 |    198 | GPU
DEBUG 01-05 09:19:42.918017.918017 lmp.py:372]   Expert 61 |    209 | GPU
DEBUG 01-05 09:19:42.918230.918230 lmp.py:372]   Expert 44 |    214 | GPU
DEBUG 01-05 09:19:42.918204.918204 lmp.py:372]   Expert 12 |    223 | GPU
DEBUG 01-05 09:19:42.918939.918939 lmp.py:372]   Expert  5 |    227 | GPU
DEBUG 01-05 09:19:42.918152.918152 lmp.py:372]   Expert 23 |    235 | GPU
DEBUG 01-05 09:19:42.918887.918887 lmp.py:372]   Expert 60 |    235 | GPU
DEBUG 01-05 09:19:42.918100.918100 lmp.py:372]   Expert 43 |    239 | GPU
DEBUG 01-05 09:19:42.918074.918074 lmp.py:372]   Expert  9 |    246 | GPU
DEBUG 01-05 09:19:42.918048.918048 lmp.py:372]   Expert 48 |    252 | GPU
DEBUG 01-05 09:19:42.918022.918022 lmp.py:372]   Expert  8 |    262 | GPU
DEBUG 01-05 09:19:42.918996.918996 lmp.py:372]   Expert 20 |    273 | GPU
DEBUG 01-05 09:19:42.918685.918685 lmp.py:372]   Expert 26 |    285 | GPU
DEBUG 01-05 09:19:42.918613.918613 lmp.py:372]   Expert 57 |    292 | GPU
DEBUG 01-05 09:19:42.918541.918541 lmp.py:372]   Expert  7 |    308 | GPU
DEBUG 01-05 09:19:42.918468.918468 lmp.py:372]   Expert 59 |    308 | GPU
DEBUG 01-05 09:19:42.918919.918919 lmp.py:372]   Expert 16 |    310 | GPU
DEBUG 01-05 09:19:42.918132.918132 lmp.py:372]   Expert 63 |    313 | GPU
DEBUG 01-05 09:19:42.918106.918106 lmp.py:372]   Expert 40 |    320 | GPU
DEBUG 01-05 09:19:42.918318.918318 lmp.py:372]   Expert 46 |    320 | GPU
DEBUG 01-05 09:19:42.918292.918292 lmp.py:372]   Expert 42 |    342 | GPU
DEBUG 01-05 09:19:42.918266.918266 lmp.py:372]   Expert 14 |    525 | GPU
DEBUG 01-05 09:19:42.918194.918194 lmp.py:373] 
DEBUG 01-05 09:19:42.918194.918194 lmp.py:373]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 09:19:42.918360.918360 lmp.py:374]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 09:19:42.918533.918533 cuda_h.py:19] end experts_map_get cost 0.0015006065368652344 seconds
DEBUG 01-05 09:19:42.918415.918415 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:42.918145.918145 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:42.919467.919467 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:42.919308.919308 cuda_h.py:19] end allocate_cuda_memory cost 0.00016617774963378906 seconds
DEBUG 01-05 09:19:42.919813.919813 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:42.919470.919470 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:42.919087.919087 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:42.919498.919498 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8392e5b6-2415-4787-9b7d-a06f68a41203
DEBUG 01-05 09:19:42.919888.919888 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:42.920386.920386 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8392e5b6-2415-4787-9b7d-a06f68a41203
DEBUG 01-05 09:19:42.921362.921362 cuda_h.py:19] end load_into_gpu_async cost 0.0017082691192626953 seconds
DEBUG 01-05 09:19:42.921919.921919 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:42.921527.921527 cuda_h.py:19] end restore_tensors2 cost 0.0003523826599121094 seconds
DEBUG 01-05 09:19:42.921887.921887 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002561330795288086 seconds
DEBUG 01-05 09:19:42.924804.924804 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005280017852783203 seconds
DEBUG 01-05 09:19:42.924369.924369 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:42.924770.924770 lmp.py:419] 
DEBUG 01-05 09:19:42.924770.924770 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:42.924666.924666 cuda_h.py:19] end cpu_experts_submit cost 0.00011849403381347656 seconds
DEBUG 01-05 09:19:42.924760.924760 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:42.936123.936123 mlpmodule.py:704] group tensors cost 0.011689186096191406 s
DEBUG 01-05 09:19:42.939474.939474 mlpmodule.py:742] pad cost 0.0020668506622314453 s
DEBUG 01-05 09:19:42.939776.939776 mlpmodule.py:748] create cpu tensor cost 5.793571472167969e-05 s
DEBUG 01-05 09:19:42.939209.939209 mlpmodule.py:753] move to cpu cost 3.719329833984375e-05 s
DEBUG 01-05 09:19:42.950956.950956 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:42.951949.951949 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:42.951330.951330 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 09:19:42.951434.951434 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:42.968521.968521 mlpmodule.py:793] group einsum cost 0.02922677993774414 s
DEBUG 01-05 09:19:42.969166.969166 mlpmodule.py:801] cpy2cputensor cost 0.0010371208190917969 s
DEBUG 01-05 09:19:43.010295.010295 cuda_h.py:19] end wait_cetm_experts cost 0.08655285835266113 seconds
DEBUG 01-05 09:19:43.011086.011086 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.011632.011632 cuda_h.py:19] end gpu_sexperts cost 0.0006392002105712891 seconds
DEBUG 01-05 09:19:43.011621.011621 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:19:43.011821.011821 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:19:43.011009.011009 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:19:43.011672.011672 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 7.152557373046875e-05 seconds
DEBUG 01-05 09:19:43.012706.012706 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.012747.012747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8392e5b6-2415-4787-9b7d-a06f68a41203
DEBUG 01-05 09:19:43.012679.012679 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.012603.012603 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.012538.012538 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.024173.024173 cuda_h.py:19] end allocate_cuda_memory cost 0.012574911117553711 seconds
INFO 01-05 09:19:43.025931.025931 client.py:127] Model loaded
DEBUG 01-05 09:19:43.025470.025470 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.025751.025751 cuda_h.py:19] end wait_experts cost 0.013167142868041992 seconds
DEBUG 01-05 09:19:43.025613.025613 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.025628.025628 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.025001.025001 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.025130.025130 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7c8aca55-f4f1-4648-8345-839a479403e5
DEBUG 01-05 09:19:43.025067.025067 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:43.025492.025492 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.026386.026386 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7c8aca55-f4f1-4648-8345-839a479403e5
DEBUG 01-05 09:19:43.026653.026653 cuda_h.py:19] end load_into_gpu_async cost 0.0011913776397705078 seconds
DEBUG 01-05 09:19:43.026210.026210 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.029031.029031 cuda_h.py:19] end restore_tensors2 cost 0.002930879592895508 seconds
DEBUG 01-05 09:19:43.029351.029351 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01716160774230957 seconds
INFO 01-05 09:19:43.029379.029379 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7c8aca55-f4f1-4648-8345-839a479403e5
DEBUG 01-05 09:19:43.033161.033161 mlpmodule.py:662]  experts func einsum cost 0.10935378074645996 s
DEBUG 01-05 09:19:43.034926.034926 mlpmodule.py:531] gpu group tensors cost 0.008306741714477539 s
INFO 01-05 09:19:43.034648.034648 client.py:127] Model loaded
DEBUG 01-05 09:19:43.034915.034915 cuda_h.py:19] end sllm_worker_task cost 0.022179841995239258 seconds
DEBUG 01-05 09:19:43.036929.036929 mlpmodule.py:564] gpu pad cost 0.002165555953979492 s
DEBUG 01-05 09:19:43.037476.037476 mlpmodule.py:582] gpu group einsum cost 0.0012335777282714844 s
DEBUG 01-05 09:19:43.040904.040904 mlpmodule.py:611] gpu experts func einsum cost 0.015178918838500977 s
DEBUG 01-05 09:19:43.041101.041101 cuda_h.py:19] end gpu_experts cost 0.015620708465576172 seconds
DEBUG 01-05 09:19:43.041811.041811 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.041157.041157 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-05 09:19:43.041645.041645 cuda_h.py:19] end layer_moe_generate_1 cost 0.12476825714111328 seconds
DEBUG 01-05 09:19:43.041274.041274 lmp.py:214] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 09:19:43.041805.041805 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 09:19:43.041071.041071 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.041338.041338 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.044646.044646 cuda_h.py:19] end self_attn cost 0.0024175643920898438 seconds
DEBUG 01-05 09:19:43.044433.044433 cuda_h.py:19] end iln_self_attn_paln cost 0.00307464599609375 seconds
DEBUG 01-05 09:19:43.044084.044084 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 09:19:43.044470.044470 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.045490.045490 cuda_h.py:19] end gate cost 0.0005757808685302734 seconds
DEBUG 01-05 09:19:43.045227.045227 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.045588.045588 lmp.py:361] 
DEBUG 01-05 09:19:43.045588.045588 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.045821.045821 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.045947.045947 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.045451.045451 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.045571.045571 lmp.py:365] 
DEBUG 01-05 09:19:43.045571.045571 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.045976.045976 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.045102.045102 lmp.py:372]   Expert 34 |     42 | CPU
DEBUG 01-05 09:19:43.045984.045984 lmp.py:372]   Expert 36 |     49 | CPU
DEBUG 01-05 09:19:43.045150.045150 lmp.py:372]   Expert  3 |     65 | CPU
DEBUG 01-05 09:19:43.045601.045601 lmp.py:372]   Expert 26 |     69 | CPU
DEBUG 01-05 09:19:43.045005.045005 lmp.py:372]   Expert 58 |     69 | CPU
DEBUG 01-05 09:19:43.045887.045887 lmp.py:372]   Expert 27 |     76 | CPU
DEBUG 01-05 09:19:43.045768.045768 lmp.py:372]   Expert  8 |     77 | CPU
DEBUG 01-05 09:19:43.045981.045981 lmp.py:372]   Expert 29 |     79 | CPU
DEBUG 01-05 09:19:43.045431.045431 lmp.py:372]   Expert  7 |     90 | CPU
DEBUG 01-05 09:19:43.045882.045882 lmp.py:372]   Expert 10 |     91 | CPU
DEBUG 01-05 09:19:43.045095.045095 lmp.py:372]   Expert 28 |     99 | CPU
DEBUG 01-05 09:19:43.045307.045307 lmp.py:372]   Expert 21 |    106 | CPU
DEBUG 01-05 09:19:43.045758.045758 lmp.py:372]   Expert 13 |    107 | CPU
DEBUG 01-05 09:19:43.046971.046971 lmp.py:372]   Expert 19 |    120 | CPU
DEBUG 01-05 09:19:43.046567.046567 lmp.py:372]   Expert 62 |    123 | CPU
DEBUG 01-05 09:19:43.046972.046972 lmp.py:372]   Expert 40 |    135 | CPU
DEBUG 01-05 09:19:43.046423.046423 lmp.py:372]   Expert  5 |    139 | CPU
DEBUG 01-05 09:19:43.046397.046397 lmp.py:372]   Expert 63 |    139 | CPU
DEBUG 01-05 09:19:43.046371.046371 lmp.py:372]   Expert  9 |    143 | CPU
DEBUG 01-05 09:19:43.046868.046868 lmp.py:372]   Expert 52 |    146 | CPU
DEBUG 01-05 09:19:43.046604.046604 lmp.py:372]   Expert 25 |    147 | CPU
DEBUG 01-05 09:19:43.046578.046578 lmp.py:372]   Expert 50 |    148 | CPU
DEBUG 01-05 09:19:43.046313.046313 lmp.py:372]   Expert 33 |    149 | CPU
DEBUG 01-05 09:19:43.046287.046287 lmp.py:372]   Expert 17 |    154 | CPU
DEBUG 01-05 09:19:43.046215.046215 lmp.py:372]   Expert 49 |    154 | CPU
DEBUG 01-05 09:19:43.046858.046858 lmp.py:372]   Expert 59 |    157 | CPU
DEBUG 01-05 09:19:43.046832.046832 lmp.py:372]   Expert  1 |    163 | CPU
DEBUG 01-05 09:19:43.046044.046044 lmp.py:372]   Expert 16 |    164 | CPU
DEBUG 01-05 09:19:43.046257.046257 lmp.py:372]   Expert  0 |    166 | CPU
DEBUG 01-05 09:19:43.046993.046993 lmp.py:372]   Expert 30 |    166 | CPU
DEBUG 01-05 09:19:43.046728.046728 lmp.py:372]   Expert 24 |    169 | CPU
DEBUG 01-05 09:19:43.046464.046464 lmp.py:372]   Expert 35 |    169 | CPU
DEBUG 01-05 09:19:43.046199.046199 lmp.py:372]   Expert 60 |    169 | GPU
DEBUG 01-05 09:19:43.046174.046174 lmp.py:372]   Expert 38 |    174 | GPU
DEBUG 01-05 09:19:43.046340.046340 lmp.py:372]   Expert 44 |    178 | GPU
DEBUG 01-05 09:19:43.046267.046267 lmp.py:372]   Expert 45 |    178 | GPU
DEBUG 01-05 09:19:43.046718.046718 lmp.py:372]   Expert  6 |    184 | GPU
DEBUG 01-05 09:19:43.046454.046454 lmp.py:372]   Expert 31 |    201 | GPU
DEBUG 01-05 09:19:43.046190.046190 lmp.py:372]   Expert 39 |    222 | GPU
DEBUG 01-05 09:19:43.046164.046164 lmp.py:372]   Expert 48 |    232 | GPU
DEBUG 01-05 09:19:43.046138.046138 lmp.py:372]   Expert 55 |    233 | GPU
DEBUG 01-05 09:19:43.046112.046112 lmp.py:372]   Expert  4 |    240 | GPU
DEBUG 01-05 09:19:43.046847.046847 lmp.py:372]   Expert 57 |    244 | GPU
DEBUG 01-05 09:19:43.046583.046583 lmp.py:372]   Expert 37 |    245 | GPU
DEBUG 01-05 09:19:43.046319.046319 lmp.py:372]   Expert 14 |    246 | GPU
DEBUG 01-05 09:19:43.046293.046293 lmp.py:372]   Expert 22 |    249 | GPU
DEBUG 01-05 09:19:43.046505.046505 lmp.py:372]   Expert 51 |    251 | GPU
DEBUG 01-05 09:19:43.046241.046241 lmp.py:372]   Expert  2 |    259 | GPU
DEBUG 01-05 09:19:43.046930.046930 lmp.py:372]   Expert 12 |    260 | GPU
DEBUG 01-05 09:19:43.046904.046904 lmp.py:372]   Expert 41 |    260 | GPU
DEBUG 01-05 09:19:43.046163.046163 lmp.py:372]   Expert 47 |    260 | GPU
DEBUG 01-05 09:19:43.046375.046375 lmp.py:372]   Expert 15 |    271 | GPU
DEBUG 01-05 09:19:43.046111.046111 lmp.py:372]   Expert 20 |    282 | GPU
DEBUG 01-05 09:19:43.046085.046085 lmp.py:372]   Expert 42 |    282 | GPU
DEBUG 01-05 09:19:43.046821.046821 lmp.py:372]   Expert 23 |    285 | GPU
DEBUG 01-05 09:19:43.046556.046556 lmp.py:372]   Expert 53 |    286 | GPU
DEBUG 01-05 09:19:43.046815.046815 lmp.py:372]   Expert 54 |    316 | GPU
DEBUG 01-05 09:19:43.046789.046789 lmp.py:372]   Expert 56 |    321 | GPU
DEBUG 01-05 09:19:43.046240.046240 lmp.py:372]   Expert 46 |    322 | GPU
DEBUG 01-05 09:19:43.046929.046929 lmp.py:372]   Expert 61 |    322 | GPU
DEBUG 01-05 09:19:43.046903.046903 lmp.py:372]   Expert 18 |    324 | GPU
DEBUG 01-05 09:19:43.046162.046162 lmp.py:372]   Expert 32 |    332 | GPU
DEBUG 01-05 09:19:43.046136.046136 lmp.py:372]   Expert 43 |    380 | GPU
DEBUG 01-05 09:19:43.046633.046633 lmp.py:372]   Expert 11 |    410 | GPU
DEBUG 01-05 09:19:43.046323.046323 lmp.py:373] 
DEBUG 01-05 09:19:43.046323.046323 lmp.py:373]   CPU total tokens: 3870 (31.5%)
DEBUG 01-05 09:19:43.046250.046250 lmp.py:374]   GPU total tokens: 8418 (68.5%)
DEBUG 01-05 09:19:43.046185.046185 cuda_h.py:19] end experts_map_get cost 0.0014824867248535156 seconds
DEBUG 01-05 09:19:43.046305.046305 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.046650.046650 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.047827.047827 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.047973.047973 cuda_h.py:19] end allocate_cuda_memory cost 0.00018167495727539062 seconds
DEBUG 01-05 09:19:43.047863.047863 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.047758.047758 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.047997.047997 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.047409.047409 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8879be8a-c244-4faf-8b3f-10cbe1b2b551
DEBUG 01-05 09:19:43.047951.047951 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.048615.048615 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8879be8a-c244-4faf-8b3f-10cbe1b2b551
DEBUG 01-05 09:19:43.048259.048259 cuda_h.py:19] end load_into_gpu_async cost 0.0015261173248291016 seconds
DEBUG 01-05 09:19:43.048055.048055 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.049797.049797 cuda_h.py:19] end restore_tensors2 cost 0.00037932395935058594 seconds
DEBUG 01-05 09:19:43.049163.049163 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024275779724121094 seconds
DEBUG 01-05 09:19:43.052102.052102 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0051958560943603516 seconds
DEBUG 01-05 09:19:43.052959.052959 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.052451.052451 lmp.py:419] 
DEBUG 01-05 09:19:43.052451.052451 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.052579.052579 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-05 09:19:43.052944.052944 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.062084.062084 mlpmodule.py:704] group tensors cost 0.009970426559448242 s
DEBUG 01-05 09:19:43.064622.064622 mlpmodule.py:742] pad cost 0.0015285015106201172 s
DEBUG 01-05 09:19:43.064341.064341 mlpmodule.py:748] create cpu tensor cost 4.4345855712890625e-05 s
DEBUG 01-05 09:19:43.064748.064748 mlpmodule.py:753] move to cpu cost 4.649162292480469e-05 s
DEBUG 01-05 09:19:43.076037.076037 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.076182.076182 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.076086.076086 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 09:19:43.076031.076031 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.095697.095697 mlpmodule.py:793] group einsum cost 0.03102874755859375 s
DEBUG 01-05 09:19:43.096287.096287 mlpmodule.py:801] cpy2cputensor cost 0.0007967948913574219 s
DEBUG 01-05 09:19:43.137765.137765 cuda_h.py:19] end wait_cetm_experts cost 0.08518218994140625 seconds
DEBUG 01-05 09:19:43.137933.137933 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.138427.138427 cuda_h.py:19] end gpu_sexperts cost 0.00046181678771972656 seconds
DEBUG 01-05 09:19:43.138270.138270 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:19:43.138709.138709 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:19:43.138327.138327 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:19:43.138216.138216 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.138337.138337 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 0.00014853477478027344 seconds
DEBUG 01-05 09:19:43.138115.138115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.138997.138997 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.138386.138386 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8879be8a-c244-4faf-8b3f-10cbe1b2b551
DEBUG 01-05 09:19:43.138351.138351 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.142844.142844 cuda_h.py:19] end allocate_cuda_memory cost 0.003591775894165039 seconds
DEBUG 01-05 09:19:43.142006.142006 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.142914.142914 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.142174.142174 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.142692.142692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 70d7c43b-4793-46da-ac0f-5a1a317dbfdf
DEBUG 01-05 09:19:43.142828.142828 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.143682.143682 client.py:127] Model loaded
DEBUG 01-05 09:19:43.143863.143863 cuda_h.py:19] end wait_experts cost 0.004359722137451172 seconds
DEBUG 01-05 09:19:43.143805.143805 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.143177.143177 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.143124.143124 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 70d7c43b-4793-46da-ac0f-5a1a317dbfdf
DEBUG 01-05 09:19:43.143265.143265 cuda_h.py:19] end load_into_gpu_async cost 0.001168966293334961 seconds
DEBUG 01-05 09:19:43.143306.143306 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.143409.143409 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:19:43.143794.143794 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005343198776245117 seconds
DEBUG 01-05 09:19:43.144356.144356 mlpmodule.py:531] gpu group tensors cost 0.0013136863708496094 s
INFO 01-05 09:19:43.144924.144924 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 70d7c43b-4793-46da-ac0f-5a1a317dbfdf
DEBUG 01-05 09:19:43.146926.146926 mlpmodule.py:564] gpu pad cost 0.0018734931945800781 s
DEBUG 01-05 09:19:43.147034.147034 mlpmodule.py:582] gpu group einsum cost 0.0005614757537841797 s
DEBUG 01-05 09:19:43.151340.151340 mlpmodule.py:611] gpu experts func einsum cost 0.007974624633789062 s
DEBUG 01-05 09:19:43.151440.151440 cuda_h.py:19] end gpu_experts cost 0.008270025253295898 seconds
DEBUG 01-05 09:19:43.151587.151587 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.151022.151022 mlpmodule.py:662]  experts func einsum cost 0.09930014610290527 s
INFO 01-05 09:19:43.152923.152923 client.py:127] Model loaded
DEBUG 01-05 09:19:43.152773.152773 cuda_h.py:19] end sllm_worker_task cost 0.014114618301391602 seconds
DEBUG 01-05 09:19:43.152861.152861 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.001220703125 seconds
DEBUG 01-05 09:19:43.152562.152562 cuda_h.py:19] end layer_moe_generate_2 cost 0.10818362236022949 seconds
DEBUG 01-05 09:19:43.153165.153165 lmp.py:214] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 09:19:43.153550.153550 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 09:19:43.153292.153292 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.153489.153489 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.156751.156751 cuda_h.py:19] end self_attn cost 0.0026259422302246094 seconds
DEBUG 01-05 09:19:43.156351.156351 cuda_h.py:19] end iln_self_attn_paln cost 0.003313779830932617 seconds
DEBUG 01-05 09:19:43.156579.156579 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 09:19:43.156772.156772 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.157177.157177 cuda_h.py:19] end gate cost 0.0005786418914794922 seconds
DEBUG 01-05 09:19:43.157291.157291 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.157972.157972 lmp.py:361] 
DEBUG 01-05 09:19:43.157972.157972 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.157026.157026 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.157583.157583 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.157610.157610 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.157015.157015 lmp.py:365] 
DEBUG 01-05 09:19:43.157015.157015 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.157135.157135 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.157738.157738 lmp.py:372]   Expert 61 |     54 | CPU
DEBUG 01-05 09:19:43.157096.157096 lmp.py:372]   Expert 32 |     66 | CPU
DEBUG 01-05 09:19:43.157739.157739 lmp.py:372]   Expert 15 |     68 | CPU
DEBUG 01-05 09:19:43.157667.157667 lmp.py:372]   Expert  4 |     83 | CPU
DEBUG 01-05 09:19:43.157118.157118 lmp.py:372]   Expert 16 |     85 | CPU
DEBUG 01-05 09:19:43.157569.157569 lmp.py:372]   Expert 59 |     88 | CPU
DEBUG 01-05 09:19:43.157258.157258 lmp.py:372]   Expert  1 |     89 | CPU
DEBUG 01-05 09:19:43.157663.157663 lmp.py:372]   Expert 37 |     94 | CPU
DEBUG 01-05 09:19:43.157114.157114 lmp.py:372]   Expert  6 |    100 | CPU
DEBUG 01-05 09:19:43.157326.157326 lmp.py:372]   Expert  7 |    107 | CPU
DEBUG 01-05 09:19:43.157539.157539 lmp.py:372]   Expert 28 |    112 | CPU
DEBUG 01-05 09:19:43.157751.157751 lmp.py:372]   Expert  5 |    121 | CPU
DEBUG 01-05 09:19:43.157487.157487 lmp.py:372]   Expert 36 |    131 | CPU
DEBUG 01-05 09:19:43.157938.157938 lmp.py:372]   Expert 44 |    132 | CPU
DEBUG 01-05 09:19:43.157150.157150 lmp.py:372]   Expert 24 |    133 | CPU
DEBUG 01-05 09:19:43.157078.157078 lmp.py:372]   Expert 42 |    133 | CPU
DEBUG 01-05 09:19:43.158290.158290 lmp.py:372]   Expert  8 |    134 | CPU
DEBUG 01-05 09:19:43.158503.158503 lmp.py:372]   Expert 63 |    136 | CPU
DEBUG 01-05 09:19:43.158238.158238 lmp.py:372]   Expert 10 |    142 | CPU
DEBUG 01-05 09:19:43.158451.158451 lmp.py:372]   Expert 38 |    143 | CPU
DEBUG 01-05 09:19:43.158902.158902 lmp.py:372]   Expert 52 |    144 | CPU
DEBUG 01-05 09:19:43.158637.158637 lmp.py:372]   Expert 29 |    146 | CPU
DEBUG 01-05 09:19:43.158850.158850 lmp.py:372]   Expert 55 |    147 | CPU
DEBUG 01-05 09:19:43.158824.158824 lmp.py:372]   Expert 49 |    148 | CPU
DEBUG 01-05 09:19:43.158036.158036 lmp.py:372]   Expert 12 |    154 | CPU
DEBUG 01-05 09:19:43.158249.158249 lmp.py:372]   Expert 23 |    155 | CPU
DEBUG 01-05 09:19:43.158461.158461 lmp.py:372]   Expert 26 |    159 | CPU
DEBUG 01-05 09:19:43.158150.158150 lmp.py:372]   Expert 30 |    159 | CPU
DEBUG 01-05 09:19:43.158601.158601 lmp.py:372]   Expert 57 |    166 | CPU
DEBUG 01-05 09:19:43.158814.158814 lmp.py:372]   Expert 56 |    167 | CPU
DEBUG 01-05 09:19:43.158549.158549 lmp.py:372]   Expert 18 |    171 | CPU
DEBUG 01-05 09:19:43.158762.158762 lmp.py:372]   Expert 58 |    173 | CPU
DEBUG 01-05 09:19:43.158446.158446 lmp.py:372]   Expert 11 |    176 | GPU
DEBUG 01-05 09:19:43.158565.158565 lmp.py:372]   Expert 62 |    180 | GPU
DEBUG 01-05 09:19:43.158778.158778 lmp.py:372]   Expert 40 |    187 | GPU
DEBUG 01-05 09:19:43.158421.158421 lmp.py:372]   Expert 47 |    189 | GPU
DEBUG 01-05 09:19:43.158633.158633 lmp.py:372]   Expert 13 |    193 | GPU
DEBUG 01-05 09:19:43.158084.158084 lmp.py:372]   Expert 31 |    194 | GPU
DEBUG 01-05 09:19:43.158185.158185 lmp.py:372]   Expert 48 |    194 | GPU
DEBUG 01-05 09:19:43.158735.158735 lmp.py:372]   Expert 35 |    199 | GPU
DEBUG 01-05 09:19:43.158901.158901 lmp.py:372]   Expert  2 |    202 | GPU
DEBUG 01-05 09:19:43.158067.158067 lmp.py:372]   Expert  0 |    207 | GPU
DEBUG 01-05 09:19:43.158757.158757 lmp.py:372]   Expert 20 |    207 | GPU
DEBUG 01-05 09:19:43.158731.158731 lmp.py:372]   Expert 45 |    212 | GPU
DEBUG 01-05 09:19:43.158182.158182 lmp.py:372]   Expert 39 |    226 | GPU
DEBUG 01-05 09:19:43.158633.158633 lmp.py:372]   Expert 46 |    227 | GPU
DEBUG 01-05 09:19:43.158799.158799 lmp.py:372]   Expert 33 |    234 | GPU
DEBUG 01-05 09:19:43.158488.158488 lmp.py:372]   Expert 17 |    235 | GPU
DEBUG 01-05 09:19:43.158462.158462 lmp.py:372]   Expert 51 |    236 | GPU
DEBUG 01-05 09:19:43.158675.158675 lmp.py:372]   Expert 22 |    237 | GPU
DEBUG 01-05 09:19:43.158649.158649 lmp.py:372]   Expert 19 |    238 | GPU
DEBUG 01-05 09:19:43.158861.158861 lmp.py:372]   Expert 34 |    238 | GPU
DEBUG 01-05 09:19:43.158073.158073 lmp.py:372]   Expert 53 |    254 | GPU
DEBUG 01-05 09:19:43.158048.158048 lmp.py:372]   Expert  3 |    266 | GPU
DEBUG 01-05 09:19:43.158552.158552 lmp.py:372]   Expert 27 |    278 | GPU
DEBUG 01-05 09:19:43.158718.158718 lmp.py:372]   Expert 54 |    288 | GPU
DEBUG 01-05 09:19:43.158169.158169 lmp.py:372]   Expert 50 |    307 | GPU
DEBUG 01-05 09:19:43.158984.158984 lmp.py:372]   Expert 60 |    309 | GPU
DEBUG 01-05 09:19:43.158151.158151 lmp.py:372]   Expert 21 |    333 | GPU
DEBUG 01-05 09:19:43.158363.158363 lmp.py:372]   Expert 14 |    352 | GPU
DEBUG 01-05 09:19:43.158814.158814 lmp.py:372]   Expert 43 |    383 | GPU
DEBUG 01-05 09:19:43.158503.158503 lmp.py:372]   Expert  9 |    395 | GPU
DEBUG 01-05 09:19:43.158193.158193 lmp.py:372]   Expert 41 |    406 | GPU
DEBUG 01-05 09:19:43.158405.158405 lmp.py:372]   Expert 25 |    466 | GPU
DEBUG 01-05 09:19:43.158571.158571 lmp.py:373] 
DEBUG 01-05 09:19:43.158571.158571 lmp.py:373]   CPU total tokens: 4040 (32.9%)
DEBUG 01-05 09:19:43.158976.158976 lmp.py:374]   GPU total tokens: 8248 (67.1%)
DEBUG 01-05 09:19:43.158625.158625 cuda_h.py:19] end experts_map_get cost 0.0016570091247558594 seconds
DEBUG 01-05 09:19:43.158030.158030 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.158714.158714 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.159659.159659 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.159667.159667 cuda_h.py:19] end allocate_cuda_memory cost 0.0002200603485107422 seconds
DEBUG 01-05 09:19:43.159610.159610 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.159889.159889 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.159513.159513 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.159924.159924 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 526f77db-c688-4627-a5db-74f3d3a25b70
DEBUG 01-05 09:19:43.159944.159944 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.160730.160730 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 526f77db-c688-4627-a5db-74f3d3a25b70
DEBUG 01-05 09:19:43.160420.160420 cuda_h.py:19] end load_into_gpu_async cost 0.0012335777282714844 seconds
DEBUG 01-05 09:19:43.160931.160931 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.161058.161058 cuda_h.py:19] end restore_tensors2 cost 0.00041866302490234375 seconds
DEBUG 01-05 09:19:43.161087.161087 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022177696228027344 seconds
DEBUG 01-05 09:19:43.163673.163673 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00493931770324707 seconds
DEBUG 01-05 09:19:43.163370.163370 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.164115.164115 lmp.py:419] 
DEBUG 01-05 09:19:43.164115.164115 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.164528.164528 cuda_h.py:19] end cpu_experts_submit cost 0.00012302398681640625 seconds
DEBUG 01-05 09:19:43.164370.164370 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.170147.170147 mlpmodule.py:704] group tensors cost 0.006261348724365234 s
DEBUG 01-05 09:19:43.172342.172342 mlpmodule.py:742] pad cost 0.0016481876373291016 s
DEBUG 01-05 09:19:43.172146.172146 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-05 09:19:43.172566.172566 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-05 09:19:43.184854.184854 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.185754.185754 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.185413.185413 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 09:19:43.185205.185205 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.204418.204418 mlpmodule.py:793] group einsum cost 0.03169870376586914 s
DEBUG 01-05 09:19:43.205873.205873 mlpmodule.py:801] cpy2cputensor cost 0.0009391307830810547 s
DEBUG 01-05 09:19:43.249626.249626 cuda_h.py:19] end wait_cetm_experts cost 0.08575582504272461 seconds
DEBUG 01-05 09:19:43.250881.250881 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.250188.250188 cuda_h.py:19] end gpu_sexperts cost 0.00043320655822753906 seconds
DEBUG 01-05 09:19:43.250117.250117 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:19:43.250463.250463 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:19:43.250373.250373 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.5762786865234375e-05 seconds
DEBUG 01-05 09:19:43.250182.250182 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:19:43.250693.250693 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.250449.250449 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 526f77db-c688-4627-a5db-74f3d3a25b70
DEBUG 01-05 09:19:43.250388.250388 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.251915.251915 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.251096.251096 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.254110.254110 cuda_h.py:19] end allocate_cuda_memory cost 0.0031654834747314453 seconds
DEBUG 01-05 09:19:43.254358.254358 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.254359.254359 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.254904.254904 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.254898.254898 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c8901b8-4e97-42bf-85e0-32b0a4dfb8b1
DEBUG 01-05 09:19:43.254034.254034 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.254471.254471 client.py:127] Model loaded
DEBUG 01-05 09:19:43.254082.254082 cuda_h.py:19] end wait_experts cost 0.0040836334228515625 seconds
DEBUG 01-05 09:19:43.254262.254262 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.254872.254872 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.255296.255296 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c8901b8-4e97-42bf-85e0-32b0a4dfb8b1
DEBUG 01-05 09:19:43.255152.255152 cuda_h.py:19] end load_into_gpu_async cost 0.0011446475982666016 seconds
DEBUG 01-05 09:19:43.255260.255260 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.255370.255370 cuda_h.py:19] end restore_tensors2 cost 8.225440979003906e-05 seconds
DEBUG 01-05 09:19:43.255040.255040 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004691123962402344 seconds
DEBUG 01-05 09:19:43.256242.256242 mlpmodule.py:531] gpu group tensors cost 0.001069784164428711 s
INFO 01-05 09:19:43.256648.256648 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c8901b8-4e97-42bf-85e0-32b0a4dfb8b1
DEBUG 01-05 09:19:43.258048.258048 mlpmodule.py:564] gpu pad cost 0.0020704269409179688 s
DEBUG 01-05 09:19:43.258369.258369 mlpmodule.py:582] gpu group einsum cost 0.0004143714904785156 s
DEBUG 01-05 09:19:43.262317.262317 mlpmodule.py:611] gpu experts func einsum cost 0.0070955753326416016 s
DEBUG 01-05 09:19:43.262017.262017 cuda_h.py:19] end gpu_experts cost 0.007305622100830078 seconds
DEBUG 01-05 09:19:43.262118.262118 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.262540.262540 mlpmodule.py:662]  experts func einsum cost 0.09810662269592285 s
INFO 01-05 09:19:43.264153.264153 client.py:127] Model loaded
DEBUG 01-05 09:19:43.264182.264182 cuda_h.py:19] end sllm_worker_task cost 0.013123750686645508 seconds
DEBUG 01-05 09:19:43.264495.264495 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.001928091049194336 seconds
DEBUG 01-05 09:19:43.264891.264891 cuda_h.py:19] end layer_moe_generate_3 cost 0.10777759552001953 seconds
DEBUG 01-05 09:19:43.264354.264354 lmp.py:214] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 09:19:43.264647.264647 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 09:19:43.264105.264105 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.264929.264929 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.267827.267827 cuda_h.py:19] end self_attn cost 0.0024323463439941406 seconds
DEBUG 01-05 09:19:43.267294.267294 cuda_h.py:19] end iln_self_attn_paln cost 0.0030579566955566406 seconds
DEBUG 01-05 09:19:43.267184.267184 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 09:19:43.267615.267615 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.268497.268497 cuda_h.py:19] end gate cost 0.0005815029144287109 seconds
DEBUG 01-05 09:19:43.268042.268042 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.268019.268019 lmp.py:361] 
DEBUG 01-05 09:19:43.268019.268019 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.268775.268775 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.268901.268901 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.268928.268928 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.268856.268856 lmp.py:365] 
DEBUG 01-05 09:19:43.268856.268856 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.268022.268022 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.268387.268387 lmp.py:372]   Expert 13 |     43 | CPU
DEBUG 01-05 09:19:43.268269.268269 lmp.py:372]   Expert 60 |     49 | CPU
DEBUG 01-05 09:19:43.268958.268958 lmp.py:372]   Expert 11 |     63 | CPU
DEBUG 01-05 09:19:43.268647.268647 lmp.py:372]   Expert 56 |     77 | CPU
DEBUG 01-05 09:19:43.268336.268336 lmp.py:372]   Expert  3 |     79 | CPU
DEBUG 01-05 09:19:43.268503.268503 lmp.py:372]   Expert 58 |     85 | CPU
DEBUG 01-05 09:19:43.268430.268430 lmp.py:372]   Expert  7 |     89 | CPU
DEBUG 01-05 09:19:43.269596.269596 lmp.py:372]   Expert 25 |     89 | CPU
DEBUG 01-05 09:19:43.269763.269763 lmp.py:372]   Expert 36 |     89 | CPU
DEBUG 01-05 09:19:43.269690.269690 lmp.py:372]   Expert 26 |     91 | CPU
DEBUG 01-05 09:19:43.269618.269618 lmp.py:372]   Expert 34 |     91 | CPU
DEBUG 01-05 09:19:43.269499.269499 lmp.py:372]   Expert 51 |     94 | CPU
DEBUG 01-05 09:19:43.269904.269904 lmp.py:372]   Expert 48 |     95 | CPU
DEBUG 01-05 09:19:43.269593.269593 lmp.py:372]   Expert 45 |     96 | CPU
DEBUG 01-05 09:19:43.269283.269283 lmp.py:372]   Expert 28 |     97 | CPU
DEBUG 01-05 09:19:43.269495.269495 lmp.py:372]   Expert  6 |    100 | CPU
DEBUG 01-05 09:19:43.269946.269946 lmp.py:372]   Expert 41 |    104 | CPU
DEBUG 01-05 09:19:43.269920.269920 lmp.py:372]   Expert 16 |    107 | CPU
DEBUG 01-05 09:19:43.269894.269894 lmp.py:372]   Expert 33 |    110 | CPU
DEBUG 01-05 09:19:43.269822.269822 lmp.py:372]   Expert 18 |    120 | CPU
DEBUG 01-05 09:19:43.269273.269273 lmp.py:372]   Expert  9 |    121 | CPU
DEBUG 01-05 09:19:43.269485.269485 lmp.py:372]   Expert 17 |    128 | CPU
DEBUG 01-05 09:19:43.269698.269698 lmp.py:372]   Expert 24 |    130 | CPU
DEBUG 01-05 09:19:43.269672.269672 lmp.py:372]   Expert 55 |    130 | CPU
DEBUG 01-05 09:19:43.269122.269122 lmp.py:372]   Expert 14 |    132 | CPU
DEBUG 01-05 09:19:43.269958.269958 lmp.py:372]   Expert 47 |    137 | CPU
DEBUG 01-05 09:19:43.269362.269362 lmp.py:372]   Expert  2 |    140 | CPU
DEBUG 01-05 09:19:43.269813.269813 lmp.py:372]   Expert  4 |    147 | CPU
DEBUG 01-05 09:19:43.269502.269502 lmp.py:372]   Expert 44 |    154 | CPU
DEBUG 01-05 09:19:43.269715.269715 lmp.py:372]   Expert 50 |    154 | CPU
DEBUG 01-05 09:19:43.269927.269927 lmp.py:372]   Expert 22 |    169 | CPU
DEBUG 01-05 09:19:43.269378.269378 lmp.py:372]   Expert 10 |    178 | CPU
DEBUG 01-05 09:19:43.269829.269829 lmp.py:372]   Expert 54 |    181 | GPU
DEBUG 01-05 09:19:43.269280.269280 lmp.py:372]   Expert 31 |    187 | GPU
DEBUG 01-05 09:19:43.269492.269492 lmp.py:372]   Expert 37 |    189 | GPU
DEBUG 01-05 09:19:43.269182.269182 lmp.py:372]   Expert 61 |    192 | GPU
DEBUG 01-05 09:19:43.269586.269586 lmp.py:372]   Expert 40 |    193 | GPU
DEBUG 01-05 09:19:43.269275.269275 lmp.py:372]   Expert 15 |    195 | GPU
DEBUG 01-05 09:19:43.269726.269726 lmp.py:372]   Expert 21 |    196 | GPU
DEBUG 01-05 09:19:43.269939.269939 lmp.py:372]   Expert 46 |    197 | GPU
DEBUG 01-05 09:19:43.269390.269390 lmp.py:372]   Expert 42 |    204 | GPU
DEBUG 01-05 09:19:43.269841.269841 lmp.py:372]   Expert  8 |    206 | GPU
DEBUG 01-05 09:19:43.269291.269291 lmp.py:372]   Expert 53 |    207 | GPU
DEBUG 01-05 09:19:43.269742.269742 lmp.py:372]   Expert 63 |    216 | GPU
DEBUG 01-05 09:19:43.269670.269670 lmp.py:372]   Expert 27 |    217 | GPU
DEBUG 01-05 09:19:43.269121.269121 lmp.py:372]   Expert 29 |    221 | GPU
DEBUG 01-05 09:19:43.269572.269572 lmp.py:372]   Expert 20 |    226 | GPU
DEBUG 01-05 09:19:43.269546.269546 lmp.py:372]   Expert 32 |    236 | GPU
DEBUG 01-05 09:19:43.269997.269997 lmp.py:372]   Expert 57 |    243 | GPU
DEBUG 01-05 09:19:43.269209.269209 lmp.py:372]   Expert 38 |    260 | GPU
DEBUG 01-05 09:19:43.269422.269422 lmp.py:372]   Expert  0 |    265 | GPU
DEBUG 01-05 09:19:43.269873.269873 lmp.py:372]   Expert 19 |    270 | GPU
DEBUG 01-05 09:19:43.269516.269516 lmp.py:372]   Expert 23 |    271 | GPU
DEBUG 01-05 09:19:43.269966.269966 lmp.py:372]   Expert  1 |    287 | GPU
DEBUG 01-05 09:19:43.269179.269179 lmp.py:372]   Expert 12 |    288 | GPU
DEBUG 01-05 09:19:43.269153.269153 lmp.py:372]   Expert 62 |    296 | GPU
DEBUG 01-05 09:19:43.269365.269365 lmp.py:372]   Expert 49 |    317 | GPU
DEBUG 01-05 09:19:43.269339.269339 lmp.py:372]   Expert 30 |    322 | GPU
DEBUG 01-05 09:19:43.269790.269790 lmp.py:372]   Expert 35 |    332 | GPU
DEBUG 01-05 09:19:43.269241.269241 lmp.py:372]   Expert 52 |    405 | GPU
DEBUG 01-05 09:19:43.269407.269407 lmp.py:372]   Expert 39 |    423 | GPU
DEBUG 01-05 09:19:43.269858.269858 lmp.py:372]   Expert  5 |    435 | GPU
DEBUG 01-05 09:19:43.269309.269309 lmp.py:372]   Expert 43 |    498 | GPU
DEBUG 01-05 09:19:43.269760.269760 lmp.py:372]   Expert 59 |    625 | GPU
DEBUG 01-05 09:19:43.269165.269165 lmp.py:373] 
DEBUG 01-05 09:19:43.269165.269165 lmp.py:373]   CPU total tokens: 3488 (28.4%)
DEBUG 01-05 09:19:43.269569.269569 lmp.py:374]   GPU total tokens: 8800 (71.6%)
DEBUG 01-05 09:19:43.269265.269265 cuda_h.py:19] end experts_map_get cost 0.0015053749084472656 seconds
DEBUG 01-05 09:19:43.270670.270670 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.270877.270877 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.270576.270576 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.270724.270724 cuda_h.py:19] end allocate_cuda_memory cost 0.00021338462829589844 seconds
DEBUG 01-05 09:19:43.270759.270759 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.270608.270608 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.270801.270801 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.270735.270735 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fd8e35dd-259c-4520-ab31-587ce7a4ed63
DEBUG 01-05 09:19:43.270808.270808 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.271117.271117 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fd8e35dd-259c-4520-ab31-587ce7a4ed63
DEBUG 01-05 09:19:43.271808.271808 cuda_h.py:19] end load_into_gpu_async cost 0.0012340545654296875 seconds
DEBUG 01-05 09:19:43.271080.271080 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.272856.272856 cuda_h.py:19] end restore_tensors2 cost 0.00040435791015625 seconds
DEBUG 01-05 09:19:43.272077.272077 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021965503692626953 seconds
DEBUG 01-05 09:19:43.274490.274490 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004896402359008789 seconds
DEBUG 01-05 09:19:43.274227.274227 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.275998.275998 lmp.py:419] 
DEBUG 01-05 09:19:43.275998.275998 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.275278.275278 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 09:19:43.275835.275835 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.280907.280907 mlpmodule.py:704] group tensors cost 0.005556821823120117 s
DEBUG 01-05 09:19:43.283349.283349 mlpmodule.py:742] pad cost 0.0018949508666992188 s
DEBUG 01-05 09:19:43.283769.283769 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-05 09:19:43.283593.283593 mlpmodule.py:753] move to cpu cost 4.553794860839844e-05 s
DEBUG 01-05 09:19:43.295544.295544 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.295258.295258 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.296871.296871 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 09:19:43.296617.296617 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.315075.315075 mlpmodule.py:793] group einsum cost 0.03191494941711426 s
DEBUG 01-05 09:19:43.316800.316800 mlpmodule.py:801] cpy2cputensor cost 0.001071929931640625 s
DEBUG 01-05 09:19:43.358718.358718 cuda_h.py:19] end wait_cetm_experts cost 0.0828409194946289 seconds
DEBUG 01-05 09:19:43.358363.358363 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.358241.358241 cuda_h.py:19] end gpu_sexperts cost 0.0004646778106689453 seconds
DEBUG 01-05 09:19:43.358461.358461 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:19:43.358622.358622 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:19:43.358717.358717 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.266334533691406e-05 seconds
DEBUG 01-05 09:19:43.358619.358619 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.2479248046875e-05 seconds
DEBUG 01-05 09:19:43.358699.358699 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.358886.358886 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fd8e35dd-259c-4520-ab31-587ce7a4ed63
DEBUG 01-05 09:19:43.359448.359448 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.359405.359405 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.359678.359678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.363217.363217 cuda_h.py:19] end allocate_cuda_memory cost 0.004182577133178711 seconds
DEBUG 01-05 09:19:43.363180.363180 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.363373.363373 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.363349.363349 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.363628.363628 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5546ba7-e011-4b45-ada2-1b40f0089229
DEBUG 01-05 09:19:43.363379.363379 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.363385.363385 client.py:127] Model loaded
DEBUG 01-05 09:19:43.364619.364619 cuda_h.py:19] end wait_experts cost 0.005105733871459961 seconds
DEBUG 01-05 09:19:43.364514.364514 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.364317.364317 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.364747.364747 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5546ba7-e011-4b45-ada2-1b40f0089229
DEBUG 01-05 09:19:43.364366.364366 cuda_h.py:19] end load_into_gpu_async cost 0.0011510848999023438 seconds
DEBUG 01-05 09:19:43.364360.364360 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.364940.364940 cuda_h.py:19] end restore_tensors2 cost 8.130073547363281e-05 seconds
DEBUG 01-05 09:19:43.364087.364087 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005698442459106445 seconds
DEBUG 01-05 09:19:43.365020.365020 mlpmodule.py:531] gpu group tensors cost 0.0011374950408935547 s
INFO 01-05 09:19:43.365805.365805 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5546ba7-e011-4b45-ada2-1b40f0089229
DEBUG 01-05 09:19:43.370127.370127 mlpmodule.py:564] gpu pad cost 0.005052804946899414 s
INFO 01-05 09:19:43.372619.372619 client.py:127] Model loaded
DEBUG 01-05 09:19:43.372945.372945 cuda_h.py:19] end sllm_worker_task cost 0.013174772262573242 seconds
DEBUG 01-05 09:19:43.373630.373630 mlpmodule.py:662]  experts func einsum cost 0.09817218780517578 s
DEBUG 01-05 09:19:43.373278.373278 mlpmodule.py:582] gpu group einsum cost 0.0032553672790527344 s
DEBUG 01-05 09:19:43.376063.376063 mlpmodule.py:611] gpu experts func einsum cost 0.012513160705566406 s
DEBUG 01-05 09:19:43.376563.376563 cuda_h.py:19] end gpu_experts cost 0.012682676315307617 seconds
DEBUG 01-05 09:19:43.376749.376749 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.376664.376664 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-05 09:19:43.376417.376417 cuda_h.py:19] end layer_moe_generate_4 cost 0.10919857025146484 seconds
DEBUG 01-05 09:19:43.377536.377536 lmp.py:214] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 09:19:43.377021.377021 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 09:19:43.377479.377479 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.377230.377230 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.380544.380544 cuda_h.py:19] end self_attn cost 0.002418994903564453 seconds
DEBUG 01-05 09:19:43.380164.380164 cuda_h.py:19] end iln_self_attn_paln cost 0.003038167953491211 seconds
DEBUG 01-05 09:19:43.380577.380577 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 09:19:43.380446.380446 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.381652.381652 cuda_h.py:19] end gate cost 0.0005741119384765625 seconds
DEBUG 01-05 09:19:43.381004.381004 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.381842.381842 lmp.py:361] 
DEBUG 01-05 09:19:43.381842.381842 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.381883.381883 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.381056.381056 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.381560.381560 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.381726.381726 lmp.py:365] 
DEBUG 01-05 09:19:43.381726.381726 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.381892.381892 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.381257.381257 lmp.py:372]   Expert 34 |     27 | CPU
DEBUG 01-05 09:19:43.381662.381662 lmp.py:372]   Expert 15 |     42 | CPU
DEBUG 01-05 09:19:43.381874.381874 lmp.py:372]   Expert 47 |     47 | CPU
DEBUG 01-05 09:19:43.381564.381564 lmp.py:372]   Expert 39 |     49 | CPU
DEBUG 01-05 09:19:43.381730.381730 lmp.py:372]   Expert  2 |     52 | CPU
DEBUG 01-05 09:19:43.381942.381942 lmp.py:372]   Expert 18 |     71 | CPU
DEBUG 01-05 09:19:43.381916.381916 lmp.py:372]   Expert  3 |     82 | CPU
DEBUG 01-05 09:19:43.381129.381129 lmp.py:372]   Expert 27 |     89 | CPU
DEBUG 01-05 09:19:43.381341.381341 lmp.py:372]   Expert 23 |     94 | CPU
DEBUG 01-05 09:19:43.381315.381315 lmp.py:372]   Expert 30 |     99 | CPU
DEBUG 01-05 09:19:43.381243.381243 lmp.py:372]   Expert  4 |    103 | CPU
DEBUG 01-05 09:19:43.381455.381455 lmp.py:372]   Expert 17 |    103 | CPU
DEBUG 01-05 09:19:43.381191.381191 lmp.py:372]   Expert 45 |    113 | CPU
DEBUG 01-05 09:19:43.381403.381403 lmp.py:372]   Expert 52 |    114 | CPU
DEBUG 01-05 09:19:43.381616.381616 lmp.py:372]   Expert  0 |    115 | CPU
DEBUG 01-05 09:19:43.381352.381352 lmp.py:372]   Expert 28 |    118 | CPU
DEBUG 01-05 09:19:43.381326.381326 lmp.py:372]   Expert 22 |    119 | CPU
DEBUG 01-05 09:19:43.381538.381538 lmp.py:372]   Expert 62 |    121 | CPU
DEBUG 01-05 09:19:43.381227.381227 lmp.py:372]   Expert 60 |    123 | CPU
DEBUG 01-05 09:19:43.381155.381155 lmp.py:372]   Expert  9 |    124 | CPU
DEBUG 01-05 09:19:43.381368.381368 lmp.py:372]   Expert  8 |    129 | CPU
DEBUG 01-05 09:19:43.381103.381103 lmp.py:372]   Expert 63 |    130 | CPU
DEBUG 01-05 09:19:43.381077.381077 lmp.py:372]   Expert 48 |    131 | CPU
DEBUG 01-05 09:19:43.381813.381813 lmp.py:372]   Expert 51 |    134 | CPU
DEBUG 01-05 09:19:43.381025.381025 lmp.py:372]   Expert 41 |    141 | CPU
DEBUG 01-05 09:19:43.381999.381999 lmp.py:372]   Expert 14 |    142 | CPU
DEBUG 01-05 09:19:43.381450.381450 lmp.py:372]   Expert 54 |    146 | CPU
DEBUG 01-05 09:19:43.381139.381139 lmp.py:372]   Expert 46 |    151 | CPU
DEBUG 01-05 09:19:43.381352.381352 lmp.py:372]   Expert 10 |    159 | CPU
DEBUG 01-05 09:19:43.381849.381849 lmp.py:372]   Expert 43 |    161 | CPU
DEBUG 01-05 09:19:43.381823.381823 lmp.py:372]   Expert 57 |    161 | CPU
DEBUG 01-05 09:19:43.382320.382320 lmp.py:372]   Expert 24 |    167 | CPU
DEBUG 01-05 09:19:43.382533.382533 lmp.py:372]   Expert 25 |    170 | GPU
DEBUG 01-05 09:19:43.382507.382507 lmp.py:372]   Expert 36 |    171 | GPU
DEBUG 01-05 09:19:43.382243.382243 lmp.py:372]   Expert  1 |    172 | GPU
DEBUG 01-05 09:19:43.382693.382693 lmp.py:372]   Expert 38 |    173 | GPU
DEBUG 01-05 09:19:43.382621.382621 lmp.py:372]   Expert 26 |    175 | GPU
DEBUG 01-05 09:19:43.382834.382834 lmp.py:372]   Expert 32 |    185 | GPU
DEBUG 01-05 09:19:43.382569.382569 lmp.py:372]   Expert 11 |    191 | GPU
DEBUG 01-05 09:19:43.382305.382305 lmp.py:372]   Expert 16 |    195 | GPU
DEBUG 01-05 09:19:43.382041.382041 lmp.py:372]   Expert 58 |    202 | GPU
DEBUG 01-05 09:19:43.382253.382253 lmp.py:372]   Expert 56 |    203 | GPU
DEBUG 01-05 09:19:43.382989.382989 lmp.py:372]   Expert 29 |    204 | GPU
DEBUG 01-05 09:19:43.382724.382724 lmp.py:372]   Expert 12 |    211 | GPU
DEBUG 01-05 09:19:43.382652.382652 lmp.py:372]   Expert 19 |    221 | GPU
DEBUG 01-05 09:19:43.382864.382864 lmp.py:372]   Expert 44 |    221 | GPU
DEBUG 01-05 09:19:43.382077.382077 lmp.py:372]   Expert 55 |    223 | GPU
DEBUG 01-05 09:19:43.382812.382812 lmp.py:372]   Expert 42 |    230 | GPU
DEBUG 01-05 09:19:43.382548.382548 lmp.py:372]   Expert 61 |    230 | GPU
DEBUG 01-05 09:19:43.382522.382522 lmp.py:372]   Expert 50 |    231 | GPU
DEBUG 01-05 09:19:43.382019.382019 lmp.py:372]   Expert 35 |    241 | GPU
DEBUG 01-05 09:19:43.382232.382232 lmp.py:372]   Expert  7 |    242 | GPU
DEBUG 01-05 09:19:43.382683.382683 lmp.py:372]   Expert 59 |    258 | GPU
DEBUG 01-05 09:19:43.382657.382657 lmp.py:372]   Expert  5 |    283 | GPU
DEBUG 01-05 09:19:43.382108.382108 lmp.py:372]   Expert 21 |    289 | GPU
DEBUG 01-05 09:19:43.382797.382797 lmp.py:372]   Expert 40 |    305 | GPU
DEBUG 01-05 09:19:43.382533.382533 lmp.py:372]   Expert 20 |    306 | GPU
DEBUG 01-05 09:19:43.382745.382745 lmp.py:372]   Expert 31 |    326 | GPU
DEBUG 01-05 09:19:43.382719.382719 lmp.py:372]   Expert 13 |    348 | GPU
DEBUG 01-05 09:19:43.382216.382216 lmp.py:372]   Expert 33 |    363 | GPU
DEBUG 01-05 09:19:43.382429.382429 lmp.py:372]   Expert  6 |    385 | GPU
DEBUG 01-05 09:19:43.382164.382164 lmp.py:372]   Expert 49 |    387 | GPU
DEBUG 01-05 09:19:43.382138.382138 lmp.py:372]   Expert 37 |    491 | GPU
DEBUG 01-05 09:19:43.382874.382874 lmp.py:372]   Expert 53 |    899 | GPU
DEBUG 01-05 09:19:43.382755.382755 lmp.py:373] 
DEBUG 01-05 09:19:43.382755.382755 lmp.py:373]   CPU total tokens: 3557 (28.9%)
DEBUG 01-05 09:19:43.382160.382160 lmp.py:374]   GPU total tokens: 8731 (71.1%)
DEBUG 01-05 09:19:43.382379.382379 cuda_h.py:19] end experts_map_get cost 0.0014772415161132812 seconds
DEBUG 01-05 09:19:43.382830.382830 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.382845.382845 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.382690.382690 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.382691.382691 cuda_h.py:19] end allocate_cuda_memory cost 0.000179290771484375 seconds
DEBUG 01-05 09:19:43.383011.383011 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.383859.383859 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.383576.383576 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.383226.383226 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 67461f5b-c4d7-43c3-a2df-f5e6b14f1971
DEBUG 01-05 09:19:43.383331.383331 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.384569.384569 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 67461f5b-c4d7-43c3-a2df-f5e6b14f1971
DEBUG 01-05 09:19:43.384306.384306 cuda_h.py:19] end load_into_gpu_async cost 0.0012755393981933594 seconds
DEBUG 01-05 09:19:43.384340.384340 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.384765.384765 cuda_h.py:19] end restore_tensors2 cost 0.0003840923309326172 seconds
DEBUG 01-05 09:19:43.384031.384031 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002187490463256836 seconds
DEBUG 01-05 09:19:43.387302.387302 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049550533294677734 seconds
DEBUG 01-05 09:19:43.387138.387138 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.387008.387008 lmp.py:419] 
DEBUG 01-05 09:19:43.387008.387008 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.387090.387090 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-05 09:19:43.387978.387978 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.394751.394751 mlpmodule.py:704] group tensors cost 0.006153583526611328 s
DEBUG 01-05 09:19:43.396118.396118 mlpmodule.py:742] pad cost 0.0015320777893066406 s
DEBUG 01-05 09:19:43.396115.396115 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-05 09:19:43.396257.396257 mlpmodule.py:753] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-05 09:19:43.407562.407562 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.408614.408614 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.408995.408995 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 09:19:43.408225.408225 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.427945.427945 mlpmodule.py:793] group einsum cost 0.031153440475463867 s
DEBUG 01-05 09:19:43.428502.428502 mlpmodule.py:801] cpy2cputensor cost 0.0008029937744140625 s
DEBUG 01-05 09:19:43.477072.477072 cuda_h.py:19] end wait_cetm_experts cost 0.08960080146789551 seconds
DEBUG 01-05 09:19:43.477909.477909 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.478191.478191 cuda_h.py:19] end gpu_sexperts cost 0.00044465065002441406 seconds
DEBUG 01-05 09:19:43.478034.478034 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:19:43.478519.478519 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:19:43.478766.478766 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.457069396972656e-05 seconds
DEBUG 01-05 09:19:43.478906.478906 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.462501525878906e-05 seconds
DEBUG 01-05 09:19:43.478371.478371 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.478988.478988 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 67461f5b-c4d7-43c3-a2df-f5e6b14f1971
DEBUG 01-05 09:19:43.478709.478709 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.478282.478282 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.478510.478510 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.482278.482278 cuda_h.py:19] end allocate_cuda_memory cost 0.0037212371826171875 seconds
DEBUG 01-05 09:19:43.482241.482241 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.482149.482149 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.482840.482840 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.482642.482642 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9b38af4-2f6e-44e8-83ab-dd94fe388e88
DEBUG 01-05 09:19:43.482063.482063 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.482129.482129 client.py:127] Model loaded
DEBUG 01-05 09:19:43.482985.482985 cuda_h.py:19] end wait_experts cost 0.004669666290283203 seconds
DEBUG 01-05 09:19:43.482026.482026 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.483782.483782 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.483345.483345 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9b38af4-2f6e-44e8-83ab-dd94fe388e88
DEBUG 01-05 09:19:43.483440.483440 cuda_h.py:19] end load_into_gpu_async cost 0.0011603832244873047 seconds
DEBUG 01-05 09:19:43.483957.483957 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.483922.483922 cuda_h.py:19] end restore_tensors2 cost 8.416175842285156e-05 seconds
DEBUG 01-05 09:19:43.483492.483492 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00524592399597168 seconds
DEBUG 01-05 09:19:43.484154.484154 mlpmodule.py:531] gpu group tensors cost 0.00113677978515625 s
INFO 01-05 09:19:43.484602.484602 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9b38af4-2f6e-44e8-83ab-dd94fe388e88
DEBUG 01-05 09:19:43.489032.489032 mlpmodule.py:564] gpu pad cost 0.005338191986083984 s
INFO 01-05 09:19:43.491245.491245 client.py:127] Model loaded
DEBUG 01-05 09:19:43.491657.491657 cuda_h.py:19] end sllm_worker_task cost 0.012779951095581055 seconds
DEBUG 01-05 09:19:43.498222.498222 mlpmodule.py:662]  experts func einsum cost 0.11041545867919922 s
DEBUG 01-05 09:19:43.498520.498520 mlpmodule.py:582] gpu group einsum cost 0.00871419906616211 s
DEBUG 01-05 09:19:43.501885.501885 mlpmodule.py:611] gpu experts func einsum cost 0.018427610397338867 s
DEBUG 01-05 09:19:43.501611.501611 cuda_h.py:19] end gpu_experts cost 0.01860833168029785 seconds
DEBUG 01-05 09:19:43.501135.501135 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.501296.501296 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-05 09:19:43.501307.501307 cuda_h.py:19] end layer_moe_generate_5 cost 0.12146210670471191 seconds
DEBUG 01-05 09:19:43.502095.502095 lmp.py:214] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 09:19:43.502143.502143 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 09:19:43.502515.502515 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.502193.502193 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.504152.504152 cuda_h.py:19] end self_attn cost 0.002476215362548828 seconds
DEBUG 01-05 09:19:43.505659.505659 cuda_h.py:19] end iln_self_attn_paln cost 0.003093242645263672 seconds
DEBUG 01-05 09:19:43.505595.505595 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 09:19:43.505219.505219 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.505146.505146 cuda_h.py:19] end gate cost 0.0005791187286376953 seconds
DEBUG 01-05 09:19:43.506738.506738 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.506907.506907 lmp.py:361] 
DEBUG 01-05 09:19:43.506907.506907 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.506947.506947 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.506359.506359 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.506386.506386 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.506552.506552 lmp.py:365] 
DEBUG 01-05 09:19:43.506552.506552 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.506480.506480 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.506129.506129 lmp.py:372]   Expert  1 |      4 | CPU
DEBUG 01-05 09:19:43.506772.506772 lmp.py:372]   Expert  3 |     29 | CPU
DEBUG 01-05 09:19:43.506177.506177 lmp.py:372]   Expert 14 |     49 | CPU
DEBUG 01-05 09:19:43.506105.506105 lmp.py:372]   Expert 53 |     56 | CPU
DEBUG 01-05 09:19:43.506509.506509 lmp.py:372]   Expert 52 |     60 | CPU
DEBUG 01-05 09:19:43.506675.506675 lmp.py:372]   Expert 35 |     68 | CPU
DEBUG 01-05 09:19:43.506365.506365 lmp.py:372]   Expert 15 |     72 | CPU
DEBUG 01-05 09:19:43.506054.506054 lmp.py:372]   Expert 10 |     77 | CPU
DEBUG 01-05 09:19:43.506982.506982 lmp.py:372]   Expert 11 |     78 | CPU
DEBUG 01-05 09:19:43.506956.506956 lmp.py:372]   Expert 44 |     83 | CPU
DEBUG 01-05 09:19:43.506168.506168 lmp.py:372]   Expert 63 |     93 | CPU
DEBUG 01-05 09:19:43.506857.506857 lmp.py:372]   Expert 37 |     97 | CPU
DEBUG 01-05 09:19:43.506832.506832 lmp.py:372]   Expert 49 |     97 | CPU
DEBUG 01-05 09:19:43.506759.506759 lmp.py:372]   Expert 50 |     99 | CPU
DEBUG 01-05 09:19:43.506925.506925 lmp.py:372]   Expert 26 |    102 | CPU
DEBUG 01-05 09:19:43.506615.506615 lmp.py:372]   Expert  7 |    108 | CPU
DEBUG 01-05 09:19:43.506066.506066 lmp.py:372]   Expert 16 |    113 | CPU
DEBUG 01-05 09:19:43.506278.506278 lmp.py:372]   Expert 40 |    117 | CPU
DEBUG 01-05 09:19:43.506490.506490 lmp.py:372]   Expert 22 |    118 | CPU
DEBUG 01-05 09:19:43.506941.506941 lmp.py:372]   Expert 47 |    120 | CPU
DEBUG 01-05 09:19:43.506392.506392 lmp.py:372]   Expert 34 |    122 | CPU
DEBUG 01-05 09:19:43.506366.506366 lmp.py:372]   Expert 62 |    131 | CPU
DEBUG 01-05 09:19:43.506340.506340 lmp.py:372]   Expert 32 |    135 | CPU
DEBUG 01-05 09:19:43.506268.506268 lmp.py:372]   Expert 28 |    139 | CPU
DEBUG 01-05 09:19:43.506719.506719 lmp.py:372]   Expert 30 |    143 | CPU
DEBUG 01-05 09:19:43.506170.506170 lmp.py:372]   Expert 41 |    147 | CPU
DEBUG 01-05 09:19:43.506382.506382 lmp.py:372]   Expert  4 |    150 | CPU
DEBUG 01-05 09:19:43.506595.506595 lmp.py:372]   Expert 31 |    153 | CPU
DEBUG 01-05 09:19:43.506807.506807 lmp.py:372]   Expert 57 |    153 | CPU
DEBUG 01-05 09:19:43.506020.506020 lmp.py:372]   Expert 25 |    156 | CPU
DEBUG 01-05 09:19:43.506994.506994 lmp.py:372]   Expert 58 |    157 | CPU
DEBUG 01-05 09:19:43.506445.506445 lmp.py:372]   Expert 51 |    161 | CPU
DEBUG 01-05 09:19:43.506372.506372 lmp.py:372]   Expert 54 |    175 | GPU
DEBUG 01-05 09:19:43.506062.506062 lmp.py:372]   Expert 21 |    181 | GPU
DEBUG 01-05 09:19:43.507513.507513 lmp.py:372]   Expert 59 |    190 | GPU
DEBUG 01-05 09:19:43.507487.507487 lmp.py:372]   Expert  9 |    191 | GPU
DEBUG 01-05 09:19:43.507699.507699 lmp.py:372]   Expert 55 |    192 | GPU
DEBUG 01-05 09:19:43.507435.507435 lmp.py:372]   Expert 45 |    193 | GPU
DEBUG 01-05 09:19:43.507124.507124 lmp.py:372]   Expert  0 |    194 | GPU
DEBUG 01-05 09:19:43.507813.507813 lmp.py:372]   Expert 33 |    199 | GPU
DEBUG 01-05 09:19:43.507264.507264 lmp.py:372]   Expert 38 |    199 | GPU
DEBUG 01-05 09:19:43.507238.507238 lmp.py:372]   Expert 12 |    201 | GPU
DEBUG 01-05 09:19:43.507451.507451 lmp.py:372]   Expert 13 |    208 | GPU
DEBUG 01-05 09:19:43.507425.507425 lmp.py:372]   Expert 29 |    209 | GPU
DEBUG 01-05 09:19:43.507160.507160 lmp.py:372]   Expert  5 |    210 | GPU
DEBUG 01-05 09:19:43.507850.507850 lmp.py:372]   Expert  8 |    211 | GPU
DEBUG 01-05 09:19:43.507539.507539 lmp.py:372]   Expert 19 |    217 | GPU
DEBUG 01-05 09:19:43.507228.507228 lmp.py:372]   Expert 43 |    217 | GPU
DEBUG 01-05 09:19:43.507441.507441 lmp.py:372]   Expert  6 |    218 | GPU
DEBUG 01-05 09:19:43.507653.507653 lmp.py:372]   Expert 46 |    222 | GPU
DEBUG 01-05 09:19:43.507389.507389 lmp.py:372]   Expert  2 |    229 | GPU
DEBUG 01-05 09:19:43.507363.507363 lmp.py:372]   Expert 42 |    239 | GPU
DEBUG 01-05 09:19:43.507575.507575 lmp.py:372]   Expert 24 |    244 | GPU
DEBUG 01-05 09:19:43.507311.507311 lmp.py:372]   Expert 17 |    269 | GPU
DEBUG 01-05 09:19:43.507285.507285 lmp.py:372]   Expert 23 |    274 | GPU
DEBUG 01-05 09:19:43.507259.507259 lmp.py:372]   Expert 61 |    290 | GPU
DEBUG 01-05 09:19:43.507233.507233 lmp.py:372]   Expert 20 |    360 | GPU
DEBUG 01-05 09:19:43.507922.507922 lmp.py:372]   Expert 27 |    370 | GPU
DEBUG 01-05 09:19:43.507612.507612 lmp.py:372]   Expert 18 |    378 | GPU
DEBUG 01-05 09:19:43.507586.507586 lmp.py:372]   Expert 48 |    400 | GPU
DEBUG 01-05 09:19:43.507798.507798 lmp.py:372]   Expert 39 |    420 | GPU
DEBUG 01-05 09:19:43.507534.507534 lmp.py:372]   Expert 60 |    472 | GPU
DEBUG 01-05 09:19:43.507746.507746 lmp.py:372]   Expert 56 |    612 | GPU
DEBUG 01-05 09:19:43.507720.507720 lmp.py:372]   Expert 36 |    717 | GPU
DEBUG 01-05 09:19:43.507648.507648 lmp.py:373] 
DEBUG 01-05 09:19:43.507648.507648 lmp.py:373]   CPU total tokens: 3387 (27.6%)
DEBUG 01-05 09:19:43.507053.507053 lmp.py:374]   GPU total tokens: 8901 (72.4%)
DEBUG 01-05 09:19:43.507225.507225 cuda_h.py:19] end experts_map_get cost 0.0014901161193847656 seconds
DEBUG 01-05 09:19:43.507107.507107 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.507267.507267 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.507252.507252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.508429.508429 cuda_h.py:19] end allocate_cuda_memory cost 0.0003070831298828125 seconds
DEBUG 01-05 09:19:43.508140.508140 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.508373.508373 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.508904.508904 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.508030.508030 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ee408bdb-1113-4457-a4f6-17365d52c793
DEBUG 01-05 09:19:43.508309.508309 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.509192.509192 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ee408bdb-1113-4457-a4f6-17365d52c793
DEBUG 01-05 09:19:43.509313.509313 cuda_h.py:19] end load_into_gpu_async cost 0.0013954639434814453 seconds
DEBUG 01-05 09:19:43.509016.509016 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.510765.510765 cuda_h.py:19] end restore_tensors2 cost 0.00038504600524902344 seconds
DEBUG 01-05 09:19:43.510655.510655 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024394989013671875 seconds
DEBUG 01-05 09:19:43.512241.512241 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005162239074707031 seconds
DEBUG 01-05 09:19:43.512561.512561 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.512001.512001 lmp.py:419] 
DEBUG 01-05 09:19:43.512001.512001 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.512797.512797 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-05 09:19:43.512878.512878 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.526791.526791 mlpmodule.py:704] group tensors cost 0.013088226318359375 s
DEBUG 01-05 09:19:43.529829.529829 mlpmodule.py:742] pad cost 0.0020651817321777344 s
DEBUG 01-05 09:19:43.529423.529423 mlpmodule.py:748] create cpu tensor cost 5.125999450683594e-05 s
DEBUG 01-05 09:19:43.529578.529578 mlpmodule.py:753] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-05 09:19:43.541615.541615 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.541270.541270 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.541512.541512 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 09:19:43.541986.541986 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.559455.559455 mlpmodule.py:793] group einsum cost 0.030058860778808594 s
DEBUG 01-05 09:19:43.560307.560307 mlpmodule.py:801] cpy2cputensor cost 0.0007333755493164062 s
DEBUG 01-05 09:19:43.597562.597562 cuda_h.py:19] end wait_cetm_experts cost 0.08448433876037598 seconds
DEBUG 01-05 09:19:43.597645.597645 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.598893.598893 cuda_h.py:19] end gpu_sexperts cost 0.000453948974609375 seconds
DEBUG 01-05 09:19:43.598452.598452 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:19:43.598036.598036 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:19:43.598668.598668 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.457069396972656e-05 seconds
DEBUG 01-05 09:19:43.598484.598484 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 8.606910705566406e-05 seconds
DEBUG 01-05 09:19:43.598948.598948 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.598373.598373 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ee408bdb-1113-4457-a4f6-17365d52c793
DEBUG 01-05 09:19:43.598984.598984 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.598647.598647 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.598689.598689 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.602606.602606 cuda_h.py:19] end allocate_cuda_memory cost 0.0035970211029052734 seconds
INFO 01-05 09:19:43.602147.602147 client.py:127] Model loaded
DEBUG 01-05 09:19:43.602382.602382 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.602239.602239 cuda_h.py:19] end wait_experts cost 0.004287004470825195 seconds
DEBUG 01-05 09:19:43.602969.602969 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.602096.602096 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.602152.602152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.602262.602262 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a715a68f-fa84-4571-abc8-e47480bbffe9
DEBUG 01-05 09:19:43.603543.603543 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:43.602472.602472 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.603061.603061 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a715a68f-fa84-4571-abc8-e47480bbffe9
DEBUG 01-05 09:19:43.603289.603289 cuda_h.py:19] end load_into_gpu_async cost 0.0012583732604980469 seconds
DEBUG 01-05 09:19:43.603376.603376 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.604194.604194 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-05 09:19:43.604792.604792 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005476236343383789 seconds
DEBUG 01-05 09:19:43.604516.604516 mlpmodule.py:531] gpu group tensors cost 0.0010471343994140625 s
INFO 01-05 09:19:43.604911.604911 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a715a68f-fa84-4571-abc8-e47480bbffe9
DEBUG 01-05 09:19:43.606729.606729 mlpmodule.py:564] gpu pad cost 0.002103090286254883 s
DEBUG 01-05 09:19:43.607150.607150 mlpmodule.py:582] gpu group einsum cost 0.0005834102630615234 s
DEBUG 01-05 09:19:43.610099.610099 mlpmodule.py:611] gpu experts func einsum cost 0.007588863372802734 s
DEBUG 01-05 09:19:43.611316.611316 cuda_h.py:19] end gpu_experts cost 0.008212089538574219 seconds
DEBUG 01-05 09:19:43.611225.611225 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.611795.611795 mlpmodule.py:662]  experts func einsum cost 0.09847259521484375 s
INFO 01-05 09:19:43.614639.614639 client.py:127] Model loaded
DEBUG 01-05 09:19:43.614952.614952 cuda_h.py:19] end sllm_worker_task cost 0.01543426513671875 seconds
DEBUG 01-05 09:19:43.614047.614047 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002959012985229492 seconds
DEBUG 01-05 09:19:43.614257.614257 cuda_h.py:19] end layer_moe_generate_6 cost 0.10895133018493652 seconds
DEBUG 01-05 09:19:43.614953.614953 lmp.py:214] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 09:19:43.614477.614477 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 09:19:43.614981.614981 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.614732.614732 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.617416.617416 cuda_h.py:19] end self_attn cost 0.0025899410247802734 seconds
DEBUG 01-05 09:19:43.617241.617241 cuda_h.py:19] end iln_self_attn_paln cost 0.003180980682373047 seconds
DEBUG 01-05 09:19:43.617130.617130 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 09:19:43.617284.617284 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.618443.618443 cuda_h.py:19] end gate cost 0.0005736351013183594 seconds
DEBUG 01-05 09:19:43.618988.618988 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.618680.618680 lmp.py:361] 
DEBUG 01-05 09:19:43.618680.618680 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.618675.618675 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.618993.618993 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.618451.618451 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.618856.618856 lmp.py:365] 
DEBUG 01-05 09:19:43.618856.618856 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.618022.618022 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.618148.618148 lmp.py:372]   Expert  1 |     22 | CPU
DEBUG 01-05 09:19:43.618030.618030 lmp.py:372]   Expert  3 |     24 | CPU
DEBUG 01-05 09:19:43.618958.618958 lmp.py:372]   Expert 40 |     45 | CPU
DEBUG 01-05 09:19:43.619124.619124 lmp.py:372]   Expert 25 |     48 | CPU
DEBUG 01-05 09:19:43.619290.619290 lmp.py:372]   Expert 41 |     56 | CPU
DEBUG 01-05 09:19:43.619979.619979 lmp.py:372]   Expert 49 |     56 | CPU
DEBUG 01-05 09:19:43.619430.619430 lmp.py:372]   Expert 15 |     57 | CPU
DEBUG 01-05 09:19:43.619881.619881 lmp.py:372]   Expert 20 |     62 | CPU
DEBUG 01-05 09:19:43.619332.619332 lmp.py:372]   Expert  8 |     65 | CPU
DEBUG 01-05 09:19:43.619783.619783 lmp.py:372]   Expert 29 |     73 | CPU
DEBUG 01-05 09:19:43.619234.619234 lmp.py:372]   Expert 31 |     75 | CPU
DEBUG 01-05 09:19:43.619684.619684 lmp.py:372]   Expert 48 |     77 | CPU
DEBUG 01-05 09:19:43.619135.619135 lmp.py:372]   Expert 39 |     84 | CPU
DEBUG 01-05 09:19:43.619586.619586 lmp.py:372]   Expert 16 |     85 | CPU
DEBUG 01-05 09:19:43.619799.619799 lmp.py:372]   Expert  6 |     89 | CPU
DEBUG 01-05 09:19:43.619250.619250 lmp.py:372]   Expert  5 |     90 | CPU
DEBUG 01-05 09:19:43.619700.619700 lmp.py:372]   Expert 63 |     95 | CPU
DEBUG 01-05 09:19:43.619674.619674 lmp.py:372]   Expert 32 |     97 | CPU
DEBUG 01-05 09:19:43.619648.619648 lmp.py:372]   Expert 18 |    100 | CPU
DEBUG 01-05 09:19:43.619861.619861 lmp.py:372]   Expert 57 |    100 | CPU
DEBUG 01-05 09:19:43.619835.619835 lmp.py:372]   Expert 58 |    115 | CPU
DEBUG 01-05 09:19:43.619571.619571 lmp.py:372]   Expert 59 |    126 | CPU
DEBUG 01-05 09:19:43.619260.619260 lmp.py:372]   Expert 30 |    143 | CPU
DEBUG 01-05 09:19:43.619949.619949 lmp.py:372]   Expert  4 |    152 | CPU
DEBUG 01-05 09:19:43.619923.619923 lmp.py:372]   Expert 53 |    156 | CPU
DEBUG 01-05 09:19:43.619136.619136 lmp.py:372]   Expert 55 |    158 | CPU
DEBUG 01-05 09:19:43.619348.619348 lmp.py:372]   Expert 34 |    159 | CPU
DEBUG 01-05 09:19:43.619322.619322 lmp.py:372]   Expert 26 |    163 | CPU
DEBUG 01-05 09:19:43.619296.619296 lmp.py:372]   Expert 45 |    166 | CPU
DEBUG 01-05 09:19:43.619509.619509 lmp.py:372]   Expert 52 |    168 | CPU
DEBUG 01-05 09:19:43.619721.619721 lmp.py:372]   Expert 33 |    171 | CPU
DEBUG 01-05 09:19:43.619411.619411 lmp.py:372]   Expert  0 |    173 | CPU
DEBUG 01-05 09:19:43.619861.619861 lmp.py:372]   Expert  7 |    174 | GPU
DEBUG 01-05 09:19:43.619597.619597 lmp.py:372]   Expert 35 |    176 | GPU
DEBUG 01-05 09:19:43.619809.619809 lmp.py:372]   Expert 50 |    186 | GPU
DEBUG 01-05 09:19:43.619784.619784 lmp.py:372]   Expert 54 |    187 | GPU
DEBUG 01-05 09:19:43.619758.619758 lmp.py:372]   Expert 28 |    192 | GPU
DEBUG 01-05 09:19:43.619970.619970 lmp.py:372]   Expert 42 |    199 | GPU
DEBUG 01-05 09:19:43.619421.619421 lmp.py:372]   Expert 19 |    204 | GPU
DEBUG 01-05 09:19:43.619110.619110 lmp.py:372]   Expert 21 |    204 | GPU
DEBUG 01-05 09:19:43.619561.619561 lmp.py:372]   Expert 17 |    206 | GPU
DEBUG 01-05 09:19:43.619535.619535 lmp.py:372]   Expert 24 |    209 | GPU
DEBUG 01-05 09:19:43.619748.619748 lmp.py:372]   Expert 43 |    210 | GPU
DEBUG 01-05 09:19:43.619960.619960 lmp.py:372]   Expert 60 |    210 | GPU
DEBUG 01-05 09:19:43.619411.619411 lmp.py:372]   Expert 36 |    212 | GPU
DEBUG 01-05 09:19:43.619385.619385 lmp.py:372]   Expert 51 |    218 | GPU
DEBUG 01-05 09:19:43.619313.619313 lmp.py:372]   Expert 13 |    231 | GPU
DEBUG 01-05 09:19:43.619240.619240 lmp.py:372]   Expert 27 |    237 | GPU
DEBUG 01-05 09:19:43.619930.619930 lmp.py:372]   Expert 37 |    239 | GPU
DEBUG 01-05 09:19:43.619142.619142 lmp.py:372]   Expert 10 |    252 | GPU
DEBUG 01-05 09:19:43.619355.619355 lmp.py:372]   Expert 62 |    257 | GPU
DEBUG 01-05 09:19:43.619567.619567 lmp.py:372]   Expert 47 |    265 | GPU
DEBUG 01-05 09:19:43.619541.619541 lmp.py:372]   Expert 22 |    269 | GPU
DEBUG 01-05 09:19:43.619277.619277 lmp.py:372]   Expert 11 |    272 | GPU
DEBUG 01-05 09:19:43.619251.619251 lmp.py:372]   Expert  2 |    303 | GPU
DEBUG 01-05 09:19:43.619940.619940 lmp.py:372]   Expert 56 |    306 | GPU
DEBUG 01-05 09:19:43.619914.619914 lmp.py:372]   Expert 61 |    318 | GPU
DEBUG 01-05 09:19:43.619127.619127 lmp.py:372]   Expert 44 |    341 | GPU
DEBUG 01-05 09:19:43.619101.619101 lmp.py:372]   Expert 14 |    353 | GPU
DEBUG 01-05 09:19:43.619313.619313 lmp.py:372]   Expert 38 |    357 | GPU
DEBUG 01-05 09:19:43.619764.619764 lmp.py:372]   Expert 46 |    373 | GPU
DEBUG 01-05 09:19:43.619215.619215 lmp.py:372]   Expert 12 |    568 | GPU
DEBUG 01-05 09:19:43.619189.619189 lmp.py:372]   Expert  9 |    636 | GPU
DEBUG 01-05 09:19:43.619786.619786 lmp.py:372]   Expert 23 |    674 | GPU
DEBUG 01-05 09:19:43.620190.620190 lmp.py:373] 
DEBUG 01-05 09:19:43.620190.620190 lmp.py:373]   CPU total tokens: 3250 (26.4%)
DEBUG 01-05 09:19:43.620595.620595 lmp.py:374]   GPU total tokens: 9038 (73.6%)
DEBUG 01-05 09:19:43.620291.620291 cuda_h.py:19] end experts_map_get cost 0.0014929771423339844 seconds
DEBUG 01-05 09:19:43.620457.620457 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.620187.620187 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.620940.620940 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.620399.620399 cuda_h.py:19] end allocate_cuda_memory cost 0.0002338886260986328 seconds
DEBUG 01-05 09:19:43.620342.620342 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.620720.620720 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.620390.620390 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.620325.620325 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fef54c30-b3fb-4a95-8a08-47993456030a
DEBUG 01-05 09:19:43.620636.620636 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.621111.621111 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fef54c30-b3fb-4a95-8a08-47993456030a
DEBUG 01-05 09:19:43.621133.621133 cuda_h.py:19] end load_into_gpu_async cost 0.001253366470336914 seconds
DEBUG 01-05 09:19:43.621167.621167 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.622274.622274 cuda_h.py:19] end restore_tensors2 cost 0.00040411949157714844 seconds
DEBUG 01-05 09:19:43.622018.622018 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022351741790771484 seconds
DEBUG 01-05 09:19:43.625367.625367 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004996299743652344 seconds
DEBUG 01-05 09:19:43.625548.625548 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.625518.625518 lmp.py:419] 
DEBUG 01-05 09:19:43.625518.625518 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.625168.625168 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-05 09:19:43.625772.625772 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.632436.632436 mlpmodule.py:704] group tensors cost 0.0074520111083984375 s
DEBUG 01-05 09:19:43.635307.635307 mlpmodule.py:742] pad cost 0.001966714859008789 s
DEBUG 01-05 09:19:43.635430.635430 mlpmodule.py:748] create cpu tensor cost 5.602836608886719e-05 s
DEBUG 01-05 09:19:43.635698.635698 mlpmodule.py:753] move to cpu cost 3.981590270996094e-05 s
DEBUG 01-05 09:19:43.648301.648301 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.648174.648174 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.648886.648886 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 09:19:43.648228.648228 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.667016.667016 mlpmodule.py:793] group einsum cost 0.030983686447143555 s
DEBUG 01-05 09:19:43.668602.668602 mlpmodule.py:801] cpy2cputensor cost 0.001100301742553711 s
DEBUG 01-05 09:19:43.706065.706065 cuda_h.py:19] end wait_cetm_experts cost 0.08128023147583008 seconds
DEBUG 01-05 09:19:43.706624.706624 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.707197.707197 cuda_h.py:19] end gpu_sexperts cost 0.00044846534729003906 seconds
DEBUG 01-05 09:19:43.707285.707285 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:19:43.707008.707008 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:19:43.707355.707355 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.4332275390625e-05 seconds
DEBUG 01-05 09:19:43.707926.707926 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.700920104980469e-05 seconds
DEBUG 01-05 09:19:43.707198.707198 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.707478.707478 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fef54c30-b3fb-4a95-8a08-47993456030a
DEBUG 01-05 09:19:43.707096.707096 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.707951.707951 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.707423.707423 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.711830.711830 cuda_h.py:19] end allocate_cuda_memory cost 0.0038022994995117188 seconds
DEBUG 01-05 09:19:43.711892.711892 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.711609.711609 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.711107.711107 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.711863.711863 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ecc7cc7-4361-4143-87f6-cd2ecbcccebc
DEBUG 01-05 09:19:43.712853.712853 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.712245.712245 client.py:127] Model loaded
DEBUG 01-05 09:19:43.712539.712539 cuda_h.py:19] end wait_experts cost 0.0047833919525146484 seconds
DEBUG 01-05 09:19:43.712771.712771 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.712527.712527 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.712481.712481 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ecc7cc7-4361-4143-87f6-cd2ecbcccebc
DEBUG 01-05 09:19:43.713338.713338 cuda_h.py:19] end load_into_gpu_async cost 0.0012028217315673828 seconds
DEBUG 01-05 09:19:43.713094.713094 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.713727.713727 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-05 09:19:43.713635.713635 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00538182258605957 seconds
DEBUG 01-05 09:19:43.713405.713405 mlpmodule.py:531] gpu group tensors cost 0.0011723041534423828 s
INFO 01-05 09:19:43.713323.713323 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ecc7cc7-4361-4143-87f6-cd2ecbcccebc
DEBUG 01-05 09:19:43.715679.715679 mlpmodule.py:564] gpu pad cost 0.0019500255584716797 s
DEBUG 01-05 09:19:43.716471.716471 mlpmodule.py:582] gpu group einsum cost 0.0005767345428466797 s
DEBUG 01-05 09:19:43.720393.720393 mlpmodule.py:611] gpu experts func einsum cost 0.00755620002746582 s
DEBUG 01-05 09:19:43.720696.720696 cuda_h.py:19] end gpu_experts cost 0.007809162139892578 seconds
DEBUG 01-05 09:19:43.720320.720320 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.720405.720405 mlpmodule.py:662]  experts func einsum cost 0.09554076194763184 s
INFO 01-05 09:19:43.723058.723058 client.py:127] Model loaded
DEBUG 01-05 09:19:43.723279.723279 cuda_h.py:19] end sllm_worker_task cost 0.015345335006713867 seconds
DEBUG 01-05 09:19:43.723691.723691 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0029425621032714844 seconds
DEBUG 01-05 09:19:43.723240.723240 cuda_h.py:19] end layer_moe_generate_7 cost 0.10548663139343262 seconds
DEBUG 01-05 09:19:43.723134.723134 lmp.py:214] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 09:19:43.723658.723658 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 09:19:43.723401.723401 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.723436.723436 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.726269.726269 cuda_h.py:19] end self_attn cost 0.002452373504638672 seconds
DEBUG 01-05 09:19:43.726074.726074 cuda_h.py:19] end iln_self_attn_paln cost 0.0030601024627685547 seconds
DEBUG 01-05 09:19:43.726937.726937 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 09:19:43.726846.726846 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.727158.727158 cuda_h.py:19] end gate cost 0.0005805492401123047 seconds
DEBUG 01-05 09:19:43.727418.727418 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.727017.727017 lmp.py:361] 
DEBUG 01-05 09:19:43.727017.727017 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.727012.727012 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.727423.727423 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.727689.727689 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.727093.727093 lmp.py:365] 
DEBUG 01-05 09:19:43.727093.727093 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.727498.727498 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.727624.727624 lmp.py:372]   Expert 27 |     20 | CPU
DEBUG 01-05 09:19:43.727744.727744 lmp.py:372]   Expert  7 |     24 | CPU
DEBUG 01-05 09:19:43.727626.727626 lmp.py:372]   Expert 14 |     30 | CPU
DEBUG 01-05 09:19:43.727507.727507 lmp.py:372]   Expert 30 |     36 | CPU
DEBUG 01-05 09:19:43.727673.727673 lmp.py:372]   Expert 38 |     43 | CPU
DEBUG 01-05 09:19:43.728886.728886 lmp.py:372]   Expert 12 |     57 | CPU
DEBUG 01-05 09:19:43.728336.728336 lmp.py:372]   Expert 36 |     57 | CPU
DEBUG 01-05 09:19:43.728311.728311 lmp.py:372]   Expert 22 |     60 | CPU
DEBUG 01-05 09:19:43.728523.728523 lmp.py:372]   Expert 53 |     65 | CPU
DEBUG 01-05 09:19:43.728974.728974 lmp.py:372]   Expert 26 |     71 | CPU
DEBUG 01-05 09:19:43.728663.728663 lmp.py:372]   Expert 34 |     73 | CPU
DEBUG 01-05 09:19:43.728114.728114 lmp.py:372]   Expert  8 |     75 | CPU
DEBUG 01-05 09:19:43.728565.728565 lmp.py:372]   Expert 54 |     83 | CPU
DEBUG 01-05 09:19:43.728777.728777 lmp.py:372]   Expert 33 |     91 | CPU
DEBUG 01-05 09:19:43.728751.728751 lmp.py:372]   Expert  1 |     95 | CPU
DEBUG 01-05 09:19:43.728202.728202 lmp.py:372]   Expert 40 |     96 | CPU
DEBUG 01-05 09:19:43.728653.728653 lmp.py:372]   Expert 57 |    100 | CPU
DEBUG 01-05 09:19:43.728627.728627 lmp.py:372]   Expert  9 |    107 | CPU
DEBUG 01-05 09:19:43.728555.728555 lmp.py:372]   Expert 13 |    111 | CPU
DEBUG 01-05 09:19:43.728244.728244 lmp.py:372]   Expert 32 |    111 | CPU
DEBUG 01-05 09:19:43.728457.728457 lmp.py:372]   Expert 50 |    113 | CPU
DEBUG 01-05 09:19:43.728192.728192 lmp.py:372]   Expert 29 |    119 | CPU
DEBUG 01-05 09:19:43.728405.728405 lmp.py:372]   Expert 17 |    135 | CPU
DEBUG 01-05 09:19:43.728617.728617 lmp.py:372]   Expert 59 |    138 | CPU
DEBUG 01-05 09:19:43.728591.728591 lmp.py:372]   Expert 24 |    140 | CPU
DEBUG 01-05 09:19:43.728804.728804 lmp.py:372]   Expert 60 |    146 | CPU
DEBUG 01-05 09:19:43.728539.728539 lmp.py:372]   Expert 44 |    149 | CPU
DEBUG 01-05 09:19:43.728275.728275 lmp.py:372]   Expert 15 |    159 | CPU
DEBUG 01-05 09:19:43.728263.728263 lmp.py:372]   Expert 10 |    163 | CPU
DEBUG 01-05 09:19:43.728859.728859 lmp.py:372]   Expert 16 |    163 | CPU
DEBUG 01-05 09:19:43.728549.728549 lmp.py:372]   Expert 37 |    163 | CPU
DEBUG 01-05 09:19:43.728523.728523 lmp.py:372]   Expert 51 |    165 | CPU
DEBUG 01-05 09:19:43.728497.728497 lmp.py:372]   Expert 56 |    168 | GPU
DEBUG 01-05 09:19:43.728471.728471 lmp.py:372]   Expert  2 |    169 | GPU
DEBUG 01-05 09:19:43.728206.728206 lmp.py:372]   Expert 31 |    184 | GPU
DEBUG 01-05 09:19:43.728419.728419 lmp.py:372]   Expert 19 |    187 | GPU
DEBUG 01-05 09:19:43.728154.728154 lmp.py:372]   Expert 39 |    198 | GPU
DEBUG 01-05 09:19:43.728367.728367 lmp.py:372]   Expert 18 |    204 | GPU
DEBUG 01-05 09:19:43.728103.728103 lmp.py:372]   Expert 58 |    227 | GPU
DEBUG 01-05 09:19:43.728315.728315 lmp.py:372]   Expert 61 |    233 | GPU
DEBUG 01-05 09:19:43.728481.728481 lmp.py:372]   Expert 46 |    239 | GPU
DEBUG 01-05 09:19:43.728647.728647 lmp.py:372]   Expert 41 |    240 | GPU
DEBUG 01-05 09:19:43.728098.728098 lmp.py:372]   Expert 49 |    240 | GPU
DEBUG 01-05 09:19:43.728311.728311 lmp.py:372]   Expert 42 |    249 | GPU
DEBUG 01-05 09:19:43.728523.728523 lmp.py:372]   Expert 35 |    251 | GPU
DEBUG 01-05 09:19:43.728497.728497 lmp.py:372]   Expert  3 |    252 | GPU
DEBUG 01-05 09:19:43.728710.728710 lmp.py:372]   Expert  0 |    257 | GPU
DEBUG 01-05 09:19:43.728922.728922 lmp.py:372]   Expert 23 |    259 | GPU
DEBUG 01-05 09:19:43.728658.728658 lmp.py:372]   Expert  6 |    271 | GPU
DEBUG 01-05 09:19:43.728632.728632 lmp.py:372]   Expert  4 |    278 | GPU
DEBUG 01-05 09:19:43.728321.728321 lmp.py:372]   Expert 55 |    278 | GPU
DEBUG 01-05 09:19:43.728533.728533 lmp.py:372]   Expert 28 |    280 | GPU
DEBUG 01-05 09:19:43.728269.728269 lmp.py:372]   Expert 43 |    304 | GPU
DEBUG 01-05 09:19:43.728482.728482 lmp.py:372]   Expert 45 |    308 | GPU
DEBUG 01-05 09:19:43.728456.728456 lmp.py:372]   Expert 20 |    318 | GPU
DEBUG 01-05 09:19:43.728430.728430 lmp.py:372]   Expert 52 |    329 | GPU
DEBUG 01-05 09:19:43.728642.728642 lmp.py:372]   Expert 47 |    334 | GPU
DEBUG 01-05 09:19:43.728378.728378 lmp.py:372]   Expert 25 |    341 | GPU
DEBUG 01-05 09:19:43.728829.728829 lmp.py:372]   Expert 48 |    348 | GPU
DEBUG 01-05 09:19:43.728041.728041 lmp.py:372]   Expert 11 |    382 | GPU
DEBUG 01-05 09:19:43.728492.728492 lmp.py:372]   Expert 62 |    400 | GPU
DEBUG 01-05 09:19:43.728943.728943 lmp.py:372]   Expert 63 |    421 | GPU
DEBUG 01-05 09:19:43.728917.728917 lmp.py:372]   Expert 21 |    427 | GPU
DEBUG 01-05 09:19:43.728891.728891 lmp.py:372]   Expert  5 |    554 | GPU
DEBUG 01-05 09:19:43.728057.728057 lmp.py:373] 
DEBUG 01-05 09:19:43.728057.728057 lmp.py:373]   CPU total tokens: 3158 (25.7%)
DEBUG 01-05 09:19:43.728462.728462 lmp.py:374]   GPU total tokens: 9130 (74.3%)
DEBUG 01-05 09:19:43.729158.729158 cuda_h.py:19] end experts_map_get cost 0.0015001296997070312 seconds
DEBUG 01-05 09:19:43.729516.729516 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.729008.729008 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.729615.729615 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.729981.729981 cuda_h.py:19] end allocate_cuda_memory cost 0.00023484230041503906 seconds
DEBUG 01-05 09:19:43.729970.729970 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.729580.729580 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.729966.729966 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.729331.729331 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4839b3fc-e0d1-4769-b8df-15f593e2879d
DEBUG 01-05 09:19:43.729019.729019 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.730663.730663 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4839b3fc-e0d1-4769-b8df-15f593e2879d
DEBUG 01-05 09:19:43.730831.730831 cuda_h.py:19] end load_into_gpu_async cost 0.001341104507446289 seconds
DEBUG 01-05 09:19:43.730865.730865 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.731263.731263 cuda_h.py:19] end restore_tensors2 cost 0.000408172607421875 seconds
DEBUG 01-05 09:19:43.731768.731768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002325296401977539 seconds
DEBUG 01-05 09:19:43.734871.734871 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005044698715209961 seconds
DEBUG 01-05 09:19:43.734376.734376 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.734837.734837 lmp.py:419] 
DEBUG 01-05 09:19:43.734837.734837 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.734441.734441 cuda_h.py:19] end cpu_experts_submit cost 0.0001246929168701172 seconds
DEBUG 01-05 09:19:43.734760.734760 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.746171.746171 mlpmodule.py:704] group tensors cost 0.011753320693969727 s
DEBUG 01-05 09:19:43.748278.748278 mlpmodule.py:742] pad cost 0.001720428466796875 s
DEBUG 01-05 09:19:43.748104.748104 mlpmodule.py:748] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-05 09:19:43.749649.749649 mlpmodule.py:753] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-05 09:19:43.762057.762057 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.762837.762837 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.762748.762748 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 09:19:43.762110.762110 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.781061.781061 mlpmodule.py:793] group einsum cost 0.03259921073913574 s
DEBUG 01-05 09:19:43.783636.783636 mlpmodule.py:801] cpy2cputensor cost 0.0015463829040527344 s
DEBUG 01-05 09:19:43.819852.819852 cuda_h.py:19] end wait_cetm_experts cost 0.08478474617004395 seconds
DEBUG 01-05 09:19:43.819835.819835 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.819938.819938 cuda_h.py:19] end gpu_sexperts cost 0.0004477500915527344 seconds
DEBUG 01-05 09:19:43.819350.819350 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:19:43.819835.819835 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:19:43.819646.819646 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.361701965332031e-05 seconds
DEBUG 01-05 09:19:43.819024.819024 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.390975952148438e-05 seconds
DEBUG 01-05 09:19:43.820622.820622 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.820928.820928 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.820463.820463 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4839b3fc-e0d1-4769-b8df-15f593e2879d
DEBUG 01-05 09:19:43.820759.820759 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.820139.820139 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.824126.824126 cuda_h.py:19] end allocate_cuda_memory cost 0.0036783218383789062 seconds
INFO 01-05 09:19:43.824097.824097 client.py:127] Model loaded
DEBUG 01-05 09:19:43.824280.824280 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.824382.824382 cuda_h.py:19] end wait_experts cost 0.0042951107025146484 seconds
DEBUG 01-05 09:19:43.824681.824681 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.824041.824041 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.824242.824242 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.824160.824160 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ca669139-9bfa-4812-818b-7cba9babd80f
DEBUG 01-05 09:19:43.824633.824633 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:43.824509.824509 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.825306.825306 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ca669139-9bfa-4812-818b-7cba9babd80f
DEBUG 01-05 09:19:43.825249.825249 cuda_h.py:19] end load_into_gpu_async cost 0.0011239051818847656 seconds
DEBUG 01-05 09:19:43.825528.825528 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.825253.825253 cuda_h.py:19] end restore_tensors2 cost 8.225440979003906e-05 seconds
DEBUG 01-05 09:19:43.825924.825924 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005454540252685547 seconds
DEBUG 01-05 09:19:43.826358.826358 mlpmodule.py:531] gpu group tensors cost 0.0014927387237548828 s
INFO 01-05 09:19:43.826082.826082 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ca669139-9bfa-4812-818b-7cba9babd80f
DEBUG 01-05 09:19:43.828482.828482 mlpmodule.py:564] gpu pad cost 0.0017709732055664062 s
DEBUG 01-05 09:19:43.829411.829411 mlpmodule.py:582] gpu group einsum cost 0.0005726814270019531 s
DEBUG 01-05 09:19:43.832439.832439 mlpmodule.py:611] gpu experts func einsum cost 0.0076634883880615234 s
DEBUG 01-05 09:19:43.832623.832623 cuda_h.py:19] end gpu_experts cost 0.0081634521484375 seconds
DEBUG 01-05 09:19:43.832340.832340 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.833912.833912 mlpmodule.py:662]  experts func einsum cost 0.09897303581237793 s
INFO 01-05 09:19:43.835132.835132 client.py:127] Model loaded
DEBUG 01-05 09:19:43.835160.835160 cuda_h.py:19] end sllm_worker_task cost 0.01515650749206543 seconds
DEBUG 01-05 09:19:43.835772.835772 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0023920536041259766 seconds
DEBUG 01-05 09:19:43.835221.835221 cuda_h.py:19] end layer_moe_generate_8 cost 0.10870552062988281 seconds
DEBUG 01-05 09:19:43.835340.835340 lmp.py:214] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 09:19:43.835910.835910 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 09:19:43.835653.835653 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.836642.836642 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.838329.838329 cuda_h.py:19] end self_attn cost 0.0024514198303222656 seconds
DEBUG 01-05 09:19:43.838902.838902 cuda_h.py:19] end iln_self_attn_paln cost 0.003067493438720703 seconds
DEBUG 01-05 09:19:43.838984.838984 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 09:19:43.838939.838939 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.839489.839489 cuda_h.py:19] end gate cost 0.0005810260772705078 seconds
DEBUG 01-05 09:19:43.839080.839080 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.839395.839395 lmp.py:361] 
DEBUG 01-05 09:19:43.839395.839395 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.839151.839151 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.839801.839801 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.840113.840113 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.840040.840040 lmp.py:365] 
DEBUG 01-05 09:19:43.840040.840040 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.840445.840445 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.840571.840571 lmp.py:372]   Expert 35 |     36 | CPU
DEBUG 01-05 09:19:43.840214.840214 lmp.py:372]   Expert  7 |     38 | CPU
DEBUG 01-05 09:19:43.840142.840142 lmp.py:372]   Expert  6 |     45 | CPU
DEBUG 01-05 09:19:43.840593.840593 lmp.py:372]   Expert 26 |     48 | CPU
DEBUG 01-05 09:19:43.840521.840521 lmp.py:372]   Expert  5 |     52 | CPU
DEBUG 01-05 09:19:43.840972.840972 lmp.py:372]   Expert  2 |     55 | CPU
DEBUG 01-05 09:19:43.840184.840184 lmp.py:372]   Expert 38 |     55 | CPU
DEBUG 01-05 09:19:43.840397.840397 lmp.py:372]   Expert 60 |     58 | CPU
DEBUG 01-05 09:19:43.840609.840609 lmp.py:372]   Expert 19 |     60 | CPU
DEBUG 01-05 09:19:43.840821.840821 lmp.py:372]   Expert 13 |     64 | CPU
DEBUG 01-05 09:19:43.840034.840034 lmp.py:372]   Expert 17 |     75 | CPU
DEBUG 01-05 09:19:43.840485.840485 lmp.py:372]   Expert 48 |     75 | CPU
DEBUG 01-05 09:19:43.840413.840413 lmp.py:372]   Expert 25 |     77 | CPU
DEBUG 01-05 09:19:43.840817.840817 lmp.py:372]   Expert 39 |     81 | CPU
DEBUG 01-05 09:19:43.840268.840268 lmp.py:372]   Expert 52 |     92 | CPU
DEBUG 01-05 09:19:43.840480.840480 lmp.py:372]   Expert 45 |     94 | CPU
DEBUG 01-05 09:19:43.840693.840693 lmp.py:372]   Expert 27 |     96 | CPU
DEBUG 01-05 09:19:43.840905.840905 lmp.py:372]   Expert 54 |     97 | CPU
DEBUG 01-05 09:19:43.840879.840879 lmp.py:372]   Expert 16 |    125 | CPU
DEBUG 01-05 09:19:43.840853.840853 lmp.py:372]   Expert 24 |    140 | CPU
DEBUG 01-05 09:19:43.840218.840218 lmp.py:372]   Expert 59 |    141 | CPU
DEBUG 01-05 09:19:43.840193.840193 lmp.py:372]   Expert 29 |    147 | CPU
DEBUG 01-05 09:19:43.840359.840359 lmp.py:372]   Expert 57 |    150 | CPU
DEBUG 01-05 09:19:43.840048.840048 lmp.py:372]   Expert 49 |    151 | CPU
DEBUG 01-05 09:19:43.840260.840260 lmp.py:372]   Expert 32 |    153 | CPU
DEBUG 01-05 09:19:43.840473.840473 lmp.py:372]   Expert 40 |    153 | CPU
DEBUG 01-05 09:19:43.840692.840692 lmp.py:372]   Expert 62 |    154 | CPU
DEBUG 01-05 09:19:43.840905.840905 lmp.py:372]   Expert 20 |    156 | CPU
DEBUG 01-05 09:19:43.840879.840879 lmp.py:372]   Expert 22 |    164 | CPU
DEBUG 01-05 09:19:43.840853.840853 lmp.py:372]   Expert 42 |    164 | CPU
DEBUG 01-05 09:19:43.840065.840065 lmp.py:372]   Expert 12 |    165 | CPU
DEBUG 01-05 09:19:43.840516.840516 lmp.py:372]   Expert 14 |    167 | CPU
DEBUG 01-05 09:19:43.840728.840728 lmp.py:372]   Expert 28 |    168 | GPU
DEBUG 01-05 09:19:43.840895.840895 lmp.py:372]   Expert 30 |    172 | GPU
DEBUG 01-05 09:19:43.840584.840584 lmp.py:372]   Expert 31 |    174 | GPU
DEBUG 01-05 09:19:43.840796.840796 lmp.py:372]   Expert 41 |    176 | GPU
DEBUG 01-05 09:19:43.840247.840247 lmp.py:372]   Expert 58 |    178 | GPU
DEBUG 01-05 09:19:43.840460.840460 lmp.py:372]   Expert 18 |    181 | GPU
DEBUG 01-05 09:19:43.840672.840672 lmp.py:372]   Expert 11 |    185 | GPU
DEBUG 01-05 09:19:43.840885.840885 lmp.py:372]   Expert 23 |    188 | GPU
DEBUG 01-05 09:19:43.840859.840859 lmp.py:372]   Expert  1 |    189 | GPU
DEBUG 01-05 09:19:43.840071.840071 lmp.py:372]   Expert 33 |    194 | GPU
DEBUG 01-05 09:19:43.840522.840522 lmp.py:372]   Expert 43 |    200 | GPU
DEBUG 01-05 09:19:43.840735.840735 lmp.py:372]   Expert 10 |    201 | GPU
DEBUG 01-05 09:19:43.840139.840139 lmp.py:372]   Expert  3 |    207 | GPU
DEBUG 01-05 09:19:43.840067.840067 lmp.py:372]   Expert 34 |    213 | GPU
DEBUG 01-05 09:19:43.840756.840756 lmp.py:372]   Expert 50 |    216 | GPU
DEBUG 01-05 09:19:43.840969.840969 lmp.py:372]   Expert 47 |    221 | GPU
DEBUG 01-05 09:19:43.840704.840704 lmp.py:372]   Expert 51 |    222 | GPU
DEBUG 01-05 09:19:43.840917.840917 lmp.py:372]   Expert  4 |    230 | GPU
DEBUG 01-05 09:19:43.840891.840891 lmp.py:372]   Expert 53 |    235 | GPU
DEBUG 01-05 09:19:43.840865.840865 lmp.py:372]   Expert 36 |    254 | GPU
DEBUG 01-05 09:19:43.840031.840031 lmp.py:372]   Expert 44 |    286 | GPU
DEBUG 01-05 09:19:43.840435.840435 lmp.py:372]   Expert  0 |    292 | GPU
DEBUG 01-05 09:19:43.840886.840886 lmp.py:372]   Expert 61 |    335 | GPU
DEBUG 01-05 09:19:43.840860.840860 lmp.py:372]   Expert 37 |    346 | GPU
DEBUG 01-05 09:19:43.840073.840073 lmp.py:372]   Expert 55 |    352 | GPU
DEBUG 01-05 09:19:43.841285.841285 lmp.py:372]   Expert  9 |    372 | GPU
DEBUG 01-05 09:19:43.841259.841259 lmp.py:372]   Expert  8 |    388 | GPU
DEBUG 01-05 09:19:43.841472.841472 lmp.py:372]   Expert 63 |    463 | GPU
DEBUG 01-05 09:19:43.841684.841684 lmp.py:372]   Expert 15 |    472 | GPU
DEBUG 01-05 09:19:43.841089.841089 lmp.py:372]   Expert 46 |    500 | GPU
DEBUG 01-05 09:19:43.841732.841732 lmp.py:372]   Expert 21 |    572 | GPU
DEBUG 01-05 09:19:43.841944.841944 lmp.py:372]   Expert 56 |    578 | GPU
DEBUG 01-05 09:19:43.841349.841349 lmp.py:373] 
DEBUG 01-05 09:19:43.841349.841349 lmp.py:373]   CPU total tokens: 3328 (27.1%)
DEBUG 01-05 09:19:43.841515.841515 lmp.py:374]   GPU total tokens: 8960 (72.9%)
DEBUG 01-05 09:19:43.841072.841072 cuda_h.py:19] end experts_map_get cost 0.0015072822570800781 seconds
DEBUG 01-05 09:19:43.841477.841477 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.841253.841253 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.841993.841993 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.841969.841969 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-05 09:19:43.841819.841819 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.841098.841098 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.841245.841245 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.841895.841895 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 86489f48-eae0-4647-80c3-f0ce0ec25ac0
DEBUG 01-05 09:19:43.842835.842835 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.843313.843313 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 86489f48-eae0-4647-80c3-f0ce0ec25ac0
DEBUG 01-05 09:19:43.843527.843527 cuda_h.py:19] end load_into_gpu_async cost 0.001333475112915039 seconds
DEBUG 01-05 09:19:43.843322.843322 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.843543.843543 cuda_h.py:19] end restore_tensors2 cost 0.00041675567626953125 seconds
DEBUG 01-05 09:19:43.843094.843094 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002352476119995117 seconds
DEBUG 01-05 09:19:43.846185.846185 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005093812942504883 seconds
DEBUG 01-05 09:19:43.846643.846643 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.846514.846514 lmp.py:419] 
DEBUG 01-05 09:19:43.846514.846514 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.846688.846688 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-05 09:19:43.846768.846768 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.854105.854105 mlpmodule.py:704] group tensors cost 0.0073392391204833984 s
DEBUG 01-05 09:19:43.856196.856196 mlpmodule.py:742] pad cost 0.0019838809967041016 s
DEBUG 01-05 09:19:43.856326.856326 mlpmodule.py:748] create cpu tensor cost 5.7220458984375e-05 s
DEBUG 01-05 09:19:43.856025.856025 mlpmodule.py:753] move to cpu cost 4.029273986816406e-05 s
DEBUG 01-05 09:19:43.868575.868575 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.869249.869249 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.869762.869762 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:19:43.869164.869164 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.886127.886127 mlpmodule.py:793] group einsum cost 0.029661178588867188 s
DEBUG 01-05 09:19:43.887375.887375 mlpmodule.py:801] cpy2cputensor cost 0.0007169246673583984 s
DEBUG 01-05 09:19:43.925192.925192 cuda_h.py:19] end wait_cetm_experts cost 0.0792696475982666 seconds
DEBUG 01-05 09:19:43.925798.925798 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:43.926033.926033 cuda_h.py:19] end gpu_sexperts cost 0.0004489421844482422 seconds
DEBUG 01-05 09:19:43.926207.926207 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:19:43.926367.926367 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:19:43.926986.926986 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.266334533691406e-05 seconds
DEBUG 01-05 09:19:43.926695.926695 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.081031799316406e-05 seconds
DEBUG 01-05 09:19:43.926776.926776 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:43.926154.926154 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 86489f48-eae0-4647-80c3-f0ce0ec25ac0
DEBUG 01-05 09:19:43.926286.926286 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:43.926308.926308 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.927443.927443 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.930033.930033 cuda_h.py:19] end allocate_cuda_memory cost 0.0037260055541992188 seconds
DEBUG 01-05 09:19:43.930049.930049 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.930481.930481 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.930025.930025 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.930020.930020 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 122d340f-820c-4c58-bdc4-6640cdf7e97c
DEBUG 01-05 09:19:43.931917.931917 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.931825.931825 client.py:127] Model loaded
DEBUG 01-05 09:19:43.931019.931019 cuda_h.py:19] end wait_experts cost 0.004677772521972656 seconds
DEBUG 01-05 09:19:43.931968.931968 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:43.931962.931962 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:43.932717.932717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 122d340f-820c-4c58-bdc4-6640cdf7e97c
DEBUG 01-05 09:19:43.932409.932409 cuda_h.py:19] end load_into_gpu_async cost 0.0012094974517822266 seconds
DEBUG 01-05 09:19:43.932787.932787 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.932135.932135 cuda_h.py:19] end restore_tensors2 cost 8.463859558105469e-05 seconds
DEBUG 01-05 09:19:43.932282.932282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00531768798828125 seconds
DEBUG 01-05 09:19:43.932689.932689 mlpmodule.py:531] gpu group tensors cost 0.00104522705078125 s
INFO 01-05 09:19:43.933566.933566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 122d340f-820c-4c58-bdc4-6640cdf7e97c
DEBUG 01-05 09:19:43.934536.934536 mlpmodule.py:564] gpu pad cost 0.0019249916076660156 s
DEBUG 01-05 09:19:43.935849.935849 mlpmodule.py:582] gpu group einsum cost 0.0005757808685302734 s
DEBUG 01-05 09:19:43.938126.938126 mlpmodule.py:611] gpu experts func einsum cost 0.00737309455871582 s
DEBUG 01-05 09:19:43.938493.938493 cuda_h.py:19] end gpu_experts cost 0.007555484771728516 seconds
DEBUG 01-05 09:19:43.939779.939779 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:43.939929.939929 mlpmodule.py:662]  experts func einsum cost 0.09328603744506836 s
INFO 01-05 09:19:43.941748.941748 client.py:127] Model loaded
DEBUG 01-05 09:19:43.941823.941823 cuda_h.py:19] end sllm_worker_task cost 0.014780282974243164 seconds
DEBUG 01-05 09:19:43.941103.941103 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0027332305908203125 seconds
DEBUG 01-05 09:19:43.941791.941791 cuda_h.py:19] end layer_moe_generate_9 cost 0.10298538208007812 seconds
DEBUG 01-05 09:19:43.942030.942030 lmp.py:214] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 09:19:43.942554.942554 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 09:19:43.942773.942773 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:43.942730.942730 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:43.945464.945464 cuda_h.py:19] end self_attn cost 0.0024852752685546875 seconds
DEBUG 01-05 09:19:43.945202.945202 cuda_h.py:19] end iln_self_attn_paln cost 0.0030946731567382812 seconds
DEBUG 01-05 09:19:43.945092.945092 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 09:19:43.945338.945338 cuda_h.py:10] start gate
DEBUG 01-05 09:19:43.946782.946782 cuda_h.py:19] end gate cost 0.0005738735198974609 seconds
DEBUG 01-05 09:19:43.946612.946612 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:43.946735.946735 lmp.py:361] 
DEBUG 01-05 09:19:43.946735.946735 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:43.946252.946252 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:43.946663.946663 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:43.946452.946452 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:43.946857.946857 lmp.py:365] 
DEBUG 01-05 09:19:43.946857.946857 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:43.946023.946023 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:43.946388.946388 lmp.py:372]   Expert 34 |      7 | CPU
DEBUG 01-05 09:19:43.946792.946792 lmp.py:372]   Expert  3 |     22 | CPU
DEBUG 01-05 09:19:43.946482.946482 lmp.py:372]   Expert 61 |     23 | CPU
DEBUG 01-05 09:19:43.946171.946171 lmp.py:372]   Expert 14 |     25 | CPU
DEBUG 01-05 09:19:43.946052.946052 lmp.py:372]   Expert 47 |     42 | CPU
DEBUG 01-05 09:19:43.946457.946457 lmp.py:372]   Expert 48 |     45 | CPU
DEBUG 01-05 09:19:43.946385.946385 lmp.py:372]   Expert 32 |     47 | CPU
DEBUG 01-05 09:19:43.946836.946836 lmp.py:372]   Expert 55 |     47 | CPU
DEBUG 01-05 09:19:43.946287.946287 lmp.py:372]   Expert 27 |     64 | CPU
DEBUG 01-05 09:19:43.946261.946261 lmp.py:372]   Expert 15 |     68 | CPU
DEBUG 01-05 09:19:43.946711.946711 lmp.py:372]   Expert 13 |     71 | CPU
DEBUG 01-05 09:19:43.946924.946924 lmp.py:372]   Expert 44 |     79 | CPU
DEBUG 01-05 09:19:43.946898.946898 lmp.py:372]   Expert  6 |     80 | CPU
DEBUG 01-05 09:19:43.946826.946826 lmp.py:372]   Expert  7 |     82 | CPU
DEBUG 01-05 09:19:43.946753.946753 lmp.py:372]   Expert 12 |     82 | CPU
DEBUG 01-05 09:19:43.946966.946966 lmp.py:372]   Expert 19 |     88 | CPU
DEBUG 01-05 09:19:43.946940.946940 lmp.py:372]   Expert 38 |     94 | CPU
DEBUG 01-05 09:19:43.946914.946914 lmp.py:372]   Expert 56 |     94 | CPU
DEBUG 01-05 09:19:43.946411.946411 lmp.py:372]   Expert 54 |     95 | CPU
DEBUG 01-05 09:19:43.946385.946385 lmp.py:372]   Expert 26 |    106 | CPU
DEBUG 01-05 09:19:43.946074.946074 lmp.py:372]   Expert 20 |    110 | CPU
DEBUG 01-05 09:19:43.946764.946764 lmp.py:372]   Expert 62 |    110 | CPU
DEBUG 01-05 09:19:43.946499.946499 lmp.py:372]   Expert 50 |    111 | CPU
DEBUG 01-05 09:19:43.946473.946473 lmp.py:372]   Expert 37 |    113 | CPU
DEBUG 01-05 09:19:43.946209.946209 lmp.py:372]   Expert 46 |    113 | CPU
DEBUG 01-05 09:19:43.946945.946945 lmp.py:372]   Expert 28 |    116 | CPU
DEBUG 01-05 09:19:43.946634.946634 lmp.py:372]   Expert 43 |    147 | CPU
DEBUG 01-05 09:19:43.946085.946085 lmp.py:372]   Expert 60 |    149 | CPU
DEBUG 01-05 09:19:43.946297.946297 lmp.py:372]   Expert 36 |    150 | CPU
DEBUG 01-05 09:19:43.947271.947271 lmp.py:372]   Expert 35 |    151 | CPU
DEBUG 01-05 09:19:43.947007.947007 lmp.py:372]   Expert 52 |    160 | CPU
DEBUG 01-05 09:19:43.947220.947220 lmp.py:372]   Expert 29 |    162 | CPU
DEBUG 01-05 09:19:43.947194.947194 lmp.py:372]   Expert 25 |    164 | GPU
DEBUG 01-05 09:19:43.947406.947406 lmp.py:372]   Expert 45 |    169 | GPU
DEBUG 01-05 09:19:43.947618.947618 lmp.py:372]   Expert 17 |    171 | GPU
DEBUG 01-05 09:19:43.947546.947546 lmp.py:372]   Expert 41 |    175 | GPU
DEBUG 01-05 09:19:43.947997.947997 lmp.py:372]   Expert 22 |    176 | GPU
DEBUG 01-05 09:19:43.947210.947210 lmp.py:372]   Expert 24 |    176 | GPU
DEBUG 01-05 09:19:43.947422.947422 lmp.py:372]   Expert 51 |    176 | GPU
DEBUG 01-05 09:19:43.947158.947158 lmp.py:372]   Expert  2 |    188 | GPU
DEBUG 01-05 09:19:43.947132.947132 lmp.py:372]   Expert 63 |    191 | GPU
DEBUG 01-05 09:19:43.947344.947344 lmp.py:372]   Expert 42 |    210 | GPU
DEBUG 01-05 09:19:43.947080.947080 lmp.py:372]   Expert 57 |    222 | GPU
DEBUG 01-05 09:19:43.947292.947292 lmp.py:372]   Expert  5 |    223 | GPU
DEBUG 01-05 09:19:43.947982.947982 lmp.py:372]   Expert 31 |    239 | GPU
DEBUG 01-05 09:19:43.947432.947432 lmp.py:372]   Expert 59 |    240 | GPU
DEBUG 01-05 09:19:43.947645.947645 lmp.py:372]   Expert 21 |    241 | GPU
DEBUG 01-05 09:19:43.947619.947619 lmp.py:372]   Expert 18 |    245 | GPU
DEBUG 01-05 09:19:43.947593.947593 lmp.py:372]   Expert 53 |    246 | GPU
DEBUG 01-05 09:19:43.947805.947805 lmp.py:372]   Expert 30 |    264 | GPU
DEBUG 01-05 09:19:43.947541.947541 lmp.py:372]   Expert 39 |    266 | GPU
DEBUG 01-05 09:19:43.947754.947754 lmp.py:372]   Expert 16 |    274 | GPU
DEBUG 01-05 09:19:43.947966.947966 lmp.py:372]   Expert  8 |    283 | GPU
DEBUG 01-05 09:19:43.947178.947178 lmp.py:372]   Expert  9 |    305 | GPU
DEBUG 01-05 09:19:43.947106.947106 lmp.py:372]   Expert 10 |    312 | GPU
DEBUG 01-05 09:19:43.947557.947557 lmp.py:372]   Expert 49 |    343 | GPU
DEBUG 01-05 09:19:43.947531.947531 lmp.py:372]   Expert 23 |    376 | GPU
DEBUG 01-05 09:19:43.947267.947267 lmp.py:372]   Expert 33 |    377 | GPU
DEBUG 01-05 09:19:43.947479.947479 lmp.py:372]   Expert 40 |    422 | GPU
DEBUG 01-05 09:19:43.947453.947453 lmp.py:372]   Expert  0 |    445 | GPU
DEBUG 01-05 09:19:43.947427.947427 lmp.py:372]   Expert 58 |    535 | GPU
DEBUG 01-05 09:19:43.947401.947401 lmp.py:372]   Expert 11 |    571 | GPU
DEBUG 01-05 09:19:43.947137.947137 lmp.py:372]   Expert  1 |    604 | GPU
DEBUG 01-05 09:19:43.947349.947349 lmp.py:372]   Expert  4 |    606 | GPU
DEBUG 01-05 09:19:43.947516.947516 lmp.py:373] 
DEBUG 01-05 09:19:43.947516.947516 lmp.py:373]   CPU total tokens: 2853 (23.2%)
DEBUG 01-05 09:19:43.947920.947920 lmp.py:374]   GPU total tokens: 9435 (76.8%)
DEBUG 01-05 09:19:43.947139.947139 cuda_h.py:19] end experts_map_get cost 0.0014846324920654297 seconds
DEBUG 01-05 09:19:43.947305.947305 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:43.947989.947989 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:43.947987.947987 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:43.948208.948208 cuda_h.py:19] end allocate_cuda_memory cost 0.0002346038818359375 seconds
DEBUG 01-05 09:19:43.948389.948389 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:43.948953.948953 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:43.948146.948146 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:43.948796.948796 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fa507588-2c5b-416b-a1f9-9f7faa13f2f8
DEBUG 01-05 09:19:43.948690.948690 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:43.949750.949750 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fa507588-2c5b-416b-a1f9-9f7faa13f2f8
DEBUG 01-05 09:19:43.949109.949109 cuda_h.py:19] end load_into_gpu_async cost 0.0013077259063720703 seconds
DEBUG 01-05 09:19:43.949097.949097 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:43.949708.949708 cuda_h.py:19] end restore_tensors2 cost 0.00042366981506347656 seconds
DEBUG 01-05 09:19:43.950114.950114 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023162364959716797 seconds
DEBUG 01-05 09:19:43.952204.952204 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005059242248535156 seconds
DEBUG 01-05 09:19:43.952332.952332 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:43.952964.952964 lmp.py:419] 
DEBUG 01-05 09:19:43.952964.952964 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:43.952900.952900 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-05 09:19:43.952741.952741 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:43.964409.964409 mlpmodule.py:704] group tensors cost 0.011488199234008789 s
DEBUG 01-05 09:19:43.966579.966579 mlpmodule.py:742] pad cost 0.0015299320220947266 s
DEBUG 01-05 09:19:43.967914.967914 mlpmodule.py:748] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-05 09:19:43.967301.967301 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-05 09:19:43.978822.978822 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:43.978211.978211 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:43.978962.978962 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 09:19:43.978125.978125 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:43.997253.997253 mlpmodule.py:793] group einsum cost 0.02994680404663086 s
DEBUG 01-05 09:19:43.998786.998786 mlpmodule.py:801] cpy2cputensor cost 0.0016758441925048828 s
DEBUG 01-05 09:19:44.035160.035160 cuda_h.py:19] end wait_cetm_experts cost 0.0826728343963623 seconds
DEBUG 01-05 09:19:44.035673.035673 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.036292.036292 cuda_h.py:19] end gpu_sexperts cost 0.0004508495330810547 seconds
DEBUG 01-05 09:19:44.036328.036328 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:19:44.036336.036336 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:19:44.036067.036067 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 4.506111145019531e-05 seconds
DEBUG 01-05 09:19:44.036830.036830 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 8.821487426757812e-05 seconds
DEBUG 01-05 09:19:44.036387.036387 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.036066.036066 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fa507588-2c5b-416b-a1f9-9f7faa13f2f8
DEBUG 01-05 09:19:44.036892.036892 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.036113.036113 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.036208.036208 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.040998.040998 cuda_h.py:19] end allocate_cuda_memory cost 0.0037703514099121094 seconds
DEBUG 01-05 09:19:44.040537.040537 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.040730.040730 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.040229.040229 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.040223.040223 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 728d9216-c2aa-4a77-870d-69943cf44099
DEBUG 01-05 09:19:44.040266.040266 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.041896.041896 client.py:127] Model loaded
DEBUG 01-05 09:19:44.041369.041369 cuda_h.py:19] end wait_experts cost 0.0046885013580322266 seconds
DEBUG 01-05 09:19:44.041171.041171 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.041450.041450 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:44.041013.041013 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 728d9216-c2aa-4a77-870d-69943cf44099
DEBUG 01-05 09:19:44.042870.042870 cuda_h.py:19] end load_into_gpu_async cost 0.0011894702911376953 seconds
DEBUG 01-05 09:19:44.042387.042387 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.042636.042636 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-05 09:19:44.042068.042068 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005331516265869141 seconds
DEBUG 01-05 09:19:44.042775.042775 mlpmodule.py:531] gpu group tensors cost 0.0011043548583984375 s
INFO 01-05 09:19:44.042609.042609 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 728d9216-c2aa-4a77-870d-69943cf44099
DEBUG 01-05 09:19:44.044932.044932 mlpmodule.py:564] gpu pad cost 0.0020029544830322266 s
DEBUG 01-05 09:19:44.045813.045813 mlpmodule.py:582] gpu group einsum cost 0.0005397796630859375 s
DEBUG 01-05 09:19:44.048805.048805 mlpmodule.py:611] gpu experts func einsum cost 0.007342100143432617 s
DEBUG 01-05 09:19:44.048987.048987 cuda_h.py:19] end gpu_experts cost 0.0075244903564453125 seconds
DEBUG 01-05 09:19:44.048803.048803 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:44.049623.049623 mlpmodule.py:662]  experts func einsum cost 0.0966329574584961 s
INFO 01-05 09:19:44.051739.051739 client.py:127] Model loaded
DEBUG 01-05 09:19:44.051204.051204 cuda_h.py:19] end sllm_worker_task cost 0.014997482299804688 seconds
DEBUG 01-05 09:19:44.051292.051292 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002925395965576172 seconds
DEBUG 01-05 09:19:44.052211.052211 cuda_h.py:19] end layer_moe_generate_10 cost 0.10658550262451172 seconds
DEBUG 01-05 09:19:44.052358.052358 lmp.py:214] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 09:19:44.052836.052836 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 09:19:44.052578.052578 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.052694.052694 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.055964.055964 cuda_h.py:19] end self_attn cost 0.002458333969116211 seconds
DEBUG 01-05 09:19:44.055332.055332 cuda_h.py:19] end iln_self_attn_paln cost 0.003088712692260742 seconds
DEBUG 01-05 09:19:44.055175.055175 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 09:19:44.055891.055891 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.056203.056203 cuda_h.py:19] end gate cost 0.0005807876586914062 seconds
DEBUG 01-05 09:19:44.056794.056794 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.056778.056778 lmp.py:361] 
DEBUG 01-05 09:19:44.056778.056778 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.056448.056448 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.056052.056052 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.056556.056556 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.056960.056960 lmp.py:365] 
DEBUG 01-05 09:19:44.056960.056960 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.056365.056365 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.056730.056730 lmp.py:372]   Expert 35 |     15 | CPU
DEBUG 01-05 09:19:44.056373.056373 lmp.py:372]   Expert 19 |     16 | CPU
DEBUG 01-05 09:19:44.056301.056301 lmp.py:372]   Expert 39 |     25 | CPU
DEBUG 01-05 09:19:44.056990.056990 lmp.py:372]   Expert 16 |     31 | CPU
DEBUG 01-05 09:19:44.056633.056633 lmp.py:372]   Expert 59 |     33 | CPU
DEBUG 01-05 09:19:44.056037.056037 lmp.py:372]   Expert 49 |     45 | CPU
DEBUG 01-05 09:19:44.056727.056727 lmp.py:372]   Expert 41 |     55 | CPU
DEBUG 01-05 09:19:44.056416.056416 lmp.py:372]   Expert 17 |     58 | CPU
DEBUG 01-05 09:19:44.056629.056629 lmp.py:372]   Expert  5 |     70 | CPU
DEBUG 01-05 09:19:44.056318.056318 lmp.py:372]   Expert  7 |     70 | CPU
DEBUG 01-05 09:19:44.056769.056769 lmp.py:372]   Expert  3 |     72 | CPU
DEBUG 01-05 09:19:44.057981.057981 lmp.py:372]   Expert 23 |     76 | CPU
DEBUG 01-05 09:19:44.057955.057955 lmp.py:372]   Expert  8 |     77 | CPU
DEBUG 01-05 09:19:44.057406.057406 lmp.py:372]   Expert 15 |     77 | CPU
DEBUG 01-05 09:19:44.057572.057572 lmp.py:372]   Expert  0 |     79 | CPU
DEBUG 01-05 09:19:44.057500.057500 lmp.py:372]   Expert  6 |     85 | CPU
DEBUG 01-05 09:19:44.057189.057189 lmp.py:372]   Expert 38 |     91 | CPU
DEBUG 01-05 09:19:44.057402.057402 lmp.py:372]   Expert 44 |     91 | CPU
DEBUG 01-05 09:19:44.057376.057376 lmp.py:372]   Expert 46 |    101 | CPU
DEBUG 01-05 09:19:44.057827.057827 lmp.py:372]   Expert 10 |    105 | CPU
DEBUG 01-05 09:19:44.057562.057562 lmp.py:372]   Expert  4 |    106 | CPU
DEBUG 01-05 09:19:44.057013.057013 lmp.py:372]   Expert 63 |    106 | CPU
DEBUG 01-05 09:19:44.057226.057226 lmp.py:372]   Expert 40 |    107 | CPU
DEBUG 01-05 09:19:44.057153.057153 lmp.py:372]   Expert 52 |    109 | CPU
DEBUG 01-05 09:19:44.057320.057320 lmp.py:372]   Expert 27 |    112 | CPU
DEBUG 01-05 09:19:44.057770.057770 lmp.py:372]   Expert 32 |    121 | CPU
DEBUG 01-05 09:19:44.057983.057983 lmp.py:372]   Expert 62 |    121 | CPU
DEBUG 01-05 09:19:44.057957.057957 lmp.py:372]   Expert 60 |    125 | CPU
DEBUG 01-05 09:19:44.057169.057169 lmp.py:372]   Expert 50 |    131 | CPU
DEBUG 01-05 09:19:44.057382.057382 lmp.py:372]   Expert 48 |    137 | CPU
DEBUG 01-05 09:19:44.057594.057594 lmp.py:372]   Expert 31 |    139 | CPU
DEBUG 01-05 09:19:44.057568.057568 lmp.py:372]   Expert 36 |    142 | CPU
DEBUG 01-05 09:19:44.057019.057019 lmp.py:372]   Expert  1 |    144 | GPU
DEBUG 01-05 09:19:44.057947.057947 lmp.py:372]   Expert 20 |    150 | GPU
DEBUG 01-05 09:19:44.057113.057113 lmp.py:372]   Expert 25 |    150 | GPU
DEBUG 01-05 09:19:44.057564.057564 lmp.py:372]   Expert 57 |    169 | GPU
DEBUG 01-05 09:19:44.057776.057776 lmp.py:372]   Expert 51 |    171 | GPU
DEBUG 01-05 09:19:44.057227.057227 lmp.py:372]   Expert 13 |    175 | GPU
DEBUG 01-05 09:19:44.057440.057440 lmp.py:372]   Expert 61 |    181 | GPU
DEBUG 01-05 09:19:44.057891.057891 lmp.py:372]   Expert 42 |    195 | GPU
DEBUG 01-05 09:19:44.057103.057103 lmp.py:372]   Expert 18 |    197 | GPU
DEBUG 01-05 09:19:44.057031.057031 lmp.py:372]   Expert 56 |    205 | GPU
DEBUG 01-05 09:19:44.057959.057959 lmp.py:372]   Expert  2 |    207 | GPU
DEBUG 01-05 09:19:44.057648.057648 lmp.py:372]   Expert 26 |    216 | GPU
DEBUG 01-05 09:19:44.057099.057099 lmp.py:372]   Expert 43 |    221 | GPU
DEBUG 01-05 09:19:44.057550.057550 lmp.py:372]   Expert 47 |    258 | GPU
DEBUG 01-05 09:19:44.057524.057524 lmp.py:372]   Expert 53 |    260 | GPU
DEBUG 01-05 09:19:44.057975.057975 lmp.py:372]   Expert 33 |    263 | GPU
DEBUG 01-05 09:19:44.057187.057187 lmp.py:372]   Expert 12 |    288 | GPU
DEBUG 01-05 09:19:44.057161.057161 lmp.py:372]   Expert 55 |    289 | GPU
DEBUG 01-05 09:19:44.057374.057374 lmp.py:372]   Expert 45 |    307 | GPU
DEBUG 01-05 09:19:44.057586.057586 lmp.py:372]   Expert 14 |    316 | GPU
DEBUG 01-05 09:19:44.057275.057275 lmp.py:372]   Expert 29 |    318 | GPU
DEBUG 01-05 09:19:44.057965.057965 lmp.py:372]   Expert 24 |    323 | GPU
DEBUG 01-05 09:19:44.057177.057177 lmp.py:372]   Expert 58 |    327 | GPU
DEBUG 01-05 09:19:44.057628.057628 lmp.py:372]   Expert 37 |    345 | GPU
DEBUG 01-05 09:19:44.057079.057079 lmp.py:372]   Expert 34 |    354 | GPU
DEBUG 01-05 09:19:44.057053.057053 lmp.py:372]   Expert 54 |    368 | GPU
DEBUG 01-05 09:19:44.057981.057981 lmp.py:372]   Expert 21 |    385 | GPU
DEBUG 01-05 09:19:44.057431.057431 lmp.py:372]   Expert  9 |    402 | GPU
DEBUG 01-05 09:19:44.057405.057405 lmp.py:372]   Expert 28 |    406 | GPU
DEBUG 01-05 09:19:44.057856.057856 lmp.py:372]   Expert 22 |    459 | GPU
DEBUG 01-05 09:19:44.057830.057830 lmp.py:372]   Expert 11 |    460 | GPU
DEBUG 01-05 09:19:44.057804.057804 lmp.py:372]   Expert 30 |   1051 | GPU
DEBUG 01-05 09:19:44.057732.057732 lmp.py:373] 
DEBUG 01-05 09:19:44.057732.057732 lmp.py:373]   CPU total tokens: 2728 (22.2%)
DEBUG 01-05 09:19:44.057898.057898 lmp.py:374]   GPU total tokens: 9560 (77.8%)
DEBUG 01-05 09:19:44.057787.057787 cuda_h.py:19] end experts_map_get cost 0.0017209053039550781 seconds
DEBUG 01-05 09:19:44.057668.057668 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.057305.057305 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.058185.058185 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.058869.058869 cuda_h.py:19] end allocate_cuda_memory cost 0.00022220611572265625 seconds
DEBUG 01-05 09:19:44.058003.058003 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.058806.058806 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.058999.058999 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.058172.058172 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a71c28a9-9c2e-4700-8614-41bb411b4589
DEBUG 01-05 09:19:44.058603.058603 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.059382.059382 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a71c28a9-9c2e-4700-8614-41bb411b4589
DEBUG 01-05 09:19:44.059980.059980 cuda_h.py:19] end load_into_gpu_async cost 0.0012502670288085938 seconds
DEBUG 01-05 09:19:44.059968.059968 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.060009.060009 cuda_h.py:19] end restore_tensors2 cost 0.0004248619079589844 seconds
DEBUG 01-05 09:19:44.060607.060607 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022721290588378906 seconds
DEBUG 01-05 09:19:44.062387.062387 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005031585693359375 seconds
DEBUG 01-05 09:19:44.063336.063336 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.063750.063750 lmp.py:419] 
DEBUG 01-05 09:19:44.063750.063750 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.063401.063401 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-05 09:19:44.063197.063197 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.074402.074402 mlpmodule.py:704] group tensors cost 0.011544466018676758 s
DEBUG 01-05 09:19:44.077578.077578 mlpmodule.py:742] pad cost 0.0015728473663330078 s
DEBUG 01-05 09:19:44.077688.077688 mlpmodule.py:748] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-05 09:19:44.077029.077029 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:19:44.088234.088234 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.088761.088761 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.089982.089982 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 09:19:44.089665.089665 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.108366.108366 mlpmodule.py:793] group einsum cost 0.03133821487426758 s
DEBUG 01-05 09:19:44.109357.109357 mlpmodule.py:801] cpy2cputensor cost 0.0006856918334960938 s
DEBUG 01-05 09:19:44.157377.157377 cuda_h.py:19] end wait_cetm_experts cost 0.09450674057006836 seconds
DEBUG 01-05 09:19:44.158899.158899 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.158662.158662 cuda_h.py:19] end gpu_sexperts cost 0.0005867481231689453 seconds
DEBUG 01-05 09:19:44.158135.158135 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:19:44.158196.158196 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:19:44.158828.158828 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 4.0531158447265625e-05 seconds
DEBUG 01-05 09:19:44.158398.158398 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 8.392333984375e-05 seconds
DEBUG 01-05 09:19:44.158147.158147 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.158380.158380 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a71c28a9-9c2e-4700-8614-41bb411b4589
DEBUG 01-05 09:19:44.159373.159373 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.159489.159489 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.159147.159147 cuda_h.py:10] start allocate_cuda_memory
INFO 01-05 09:19:44.165754.165754 client.py:127] Model loaded
DEBUG 01-05 09:19:44.165564.165564 cuda_h.py:19] end wait_experts cost 0.00687718391418457 seconds
DEBUG 01-05 09:19:44.165320.165320 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.165699.165699 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:44.166857.166857 cuda_h.py:19] end allocate_cuda_memory cost 0.007112264633178711 seconds
DEBUG 01-05 09:19:44.166317.166317 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.166656.166656 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.166962.166962 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.166056.166056 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d763605-a966-4da9-871f-53ede389b091
DEBUG 01-05 09:19:44.166046.166046 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.166165.166165 mlpmodule.py:531] gpu group tensors cost 0.0009911060333251953 s
INFO 01-05 09:19:44.167243.167243 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d763605-a966-4da9-871f-53ede389b091
DEBUG 01-05 09:19:44.167431.167431 cuda_h.py:19] end load_into_gpu_async cost 0.0009913444519042969 seconds
DEBUG 01-05 09:19:44.167757.167757 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.174384.174384 cuda_h.py:19] end restore_tensors2 cost 0.006429910659790039 seconds
DEBUG 01-05 09:19:44.174373.174373 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014870166778564453 seconds
INFO 01-05 09:19:44.174759.174759 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d763605-a966-4da9-871f-53ede389b091
INFO 01-05 09:19:44.175985.175985 client.py:127] Model loaded
DEBUG 01-05 09:19:44.175663.175663 cuda_h.py:19] end sllm_worker_task cost 0.016460657119750977 seconds
DEBUG 01-05 09:19:44.176943.176943 mlpmodule.py:564] gpu pad cost 0.009492635726928711 s
DEBUG 01-05 09:19:44.181022.181022 mlpmodule.py:662]  experts func einsum cost 0.11829137802124023 s
DEBUG 01-05 09:19:44.182449.182449 mlpmodule.py:582] gpu group einsum cost 0.005555868148803711 s
DEBUG 01-05 09:19:44.185126.185126 mlpmodule.py:611] gpu experts func einsum cost 0.019186973571777344 s
DEBUG 01-05 09:19:44.185831.185831 cuda_h.py:19] end gpu_experts cost 0.01937723159790039 seconds
DEBUG 01-05 09:19:44.185779.185779 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:44.185986.185986 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-05 09:19:44.185838.185838 cuda_h.py:19] end layer_moe_generate_11 cost 0.12995100021362305 seconds
DEBUG 01-05 09:19:44.185858.185858 lmp.py:214] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 09:19:44.185727.185727 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 09:19:44.185184.185184 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.185750.185750 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.188383.188383 cuda_h.py:19] end self_attn cost 0.0024445056915283203 seconds
DEBUG 01-05 09:19:44.188731.188731 cuda_h.py:19] end iln_self_attn_paln cost 0.0030410289764404297 seconds
DEBUG 01-05 09:19:44.188435.188435 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 09:19:44.188059.188059 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.189417.189417 cuda_h.py:19] end gate cost 0.0005788803100585938 seconds
DEBUG 01-05 09:19:44.189439.189439 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.189985.189985 lmp.py:361] 
DEBUG 01-05 09:19:44.189985.189985 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.189788.189788 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.189437.189437 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.189749.189749 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.189154.189154 lmp.py:365] 
DEBUG 01-05 09:19:44.189154.189154 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.189558.189558 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.189446.189446 lmp.py:372]   Expert 51 |     11 | CPU
DEBUG 01-05 09:19:44.189089.189089 lmp.py:372]   Expert 63 |     18 | CPU
DEBUG 01-05 09:19:44.190494.190494 lmp.py:372]   Expert 34 |     19 | CPU
DEBUG 01-05 09:19:44.190945.190945 lmp.py:372]   Expert 22 |     27 | CPU
DEBUG 01-05 09:19:44.190396.190396 lmp.py:372]   Expert 16 |     28 | CPU
DEBUG 01-05 09:19:44.190370.190370 lmp.py:372]   Expert 12 |     29 | CPU
DEBUG 01-05 09:19:44.190013.190013 lmp.py:372]   Expert 47 |     30 | CPU
DEBUG 01-05 09:19:44.190179.190179 lmp.py:372]   Expert 11 |     31 | CPU
DEBUG 01-05 09:19:44.190107.190107 lmp.py:372]   Expert  4 |     37 | CPU
DEBUG 01-05 09:19:44.190319.190319 lmp.py:372]   Expert 44 |     50 | CPU
DEBUG 01-05 09:19:44.190008.190008 lmp.py:372]   Expert 29 |     52 | CPU
DEBUG 01-05 09:19:44.190982.190982 lmp.py:372]   Expert  0 |     56 | CPU
DEBUG 01-05 09:19:44.190195.190195 lmp.py:372]   Expert 32 |     59 | CPU
DEBUG 01-05 09:19:44.190169.190169 lmp.py:372]   Expert 13 |     65 | CPU
DEBUG 01-05 09:19:44.190381.190381 lmp.py:372]   Expert 27 |     70 | CPU
DEBUG 01-05 09:19:44.190594.190594 lmp.py:372]   Expert 41 |     76 | CPU
DEBUG 01-05 09:19:44.190045.190045 lmp.py:372]   Expert 37 |     78 | CPU
DEBUG 01-05 09:19:44.190019.190019 lmp.py:372]   Expert 23 |     87 | CPU
DEBUG 01-05 09:19:44.190231.190231 lmp.py:372]   Expert  8 |     94 | CPU
DEBUG 01-05 09:19:44.190682.190682 lmp.py:372]   Expert  2 |    100 | CPU
DEBUG 01-05 09:19:44.190087.190087 lmp.py:372]   Expert 49 |    100 | CPU
DEBUG 01-05 09:19:44.190207.190207 lmp.py:372]   Expert 21 |    105 | CPU
DEBUG 01-05 09:19:44.190419.190419 lmp.py:372]   Expert 43 |    107 | CPU
DEBUG 01-05 09:19:44.190631.190631 lmp.py:372]   Expert  3 |    123 | CPU
DEBUG 01-05 09:19:44.190844.190844 lmp.py:372]   Expert 39 |    129 | CPU
DEBUG 01-05 09:19:44.190818.190818 lmp.py:372]   Expert 62 |    131 | CPU
DEBUG 01-05 09:19:44.190792.190792 lmp.py:372]   Expert 55 |    140 | CPU
DEBUG 01-05 09:19:44.190766.190766 lmp.py:372]   Expert  7 |    149 | CPU
DEBUG 01-05 09:19:44.190502.190502 lmp.py:372]   Expert 30 |    151 | CPU
DEBUG 01-05 09:19:44.190476.190476 lmp.py:372]   Expert 42 |    156 | CPU
DEBUG 01-05 09:19:44.190450.190450 lmp.py:372]   Expert 14 |    158 | CPU
DEBUG 01-05 09:19:44.190616.190616 lmp.py:372]   Expert 58 |    162 | CPU
DEBUG 01-05 09:19:44.190067.190067 lmp.py:372]   Expert 61 |    165 | GPU
DEBUG 01-05 09:19:44.190279.190279 lmp.py:372]   Expert 45 |    169 | GPU
DEBUG 01-05 09:19:44.190015.190015 lmp.py:372]   Expert 18 |    184 | GPU
DEBUG 01-05 09:19:44.190989.190989 lmp.py:372]   Expert 38 |    184 | GPU
DEBUG 01-05 09:19:44.190963.190963 lmp.py:372]   Expert  5 |    188 | GPU
DEBUG 01-05 09:19:44.190699.190699 lmp.py:372]   Expert 53 |    190 | GPU
DEBUG 01-05 09:19:44.190911.190911 lmp.py:372]   Expert 31 |    194 | GPU
DEBUG 01-05 09:19:44.190408.190408 lmp.py:372]   Expert 17 |    206 | GPU
DEBUG 01-05 09:19:44.190621.190621 lmp.py:372]   Expert 35 |    213 | GPU
DEBUG 01-05 09:19:44.190595.190595 lmp.py:372]   Expert  6 |    217 | GPU
DEBUG 01-05 09:19:44.190569.190569 lmp.py:372]   Expert  1 |    220 | GPU
DEBUG 01-05 09:19:44.190735.190735 lmp.py:372]   Expert 19 |    236 | GPU
DEBUG 01-05 09:19:44.190186.190186 lmp.py:372]   Expert 20 |    237 | GPU
DEBUG 01-05 09:19:44.190683.190683 lmp.py:372]   Expert 50 |    246 | GPU
DEBUG 01-05 09:19:44.190419.190419 lmp.py:372]   Expert 46 |    253 | GPU
DEBUG 01-05 09:19:44.190154.190154 lmp.py:372]   Expert 57 |    255 | GPU
DEBUG 01-05 09:19:44.190890.190890 lmp.py:372]   Expert 26 |    277 | GPU
DEBUG 01-05 09:19:44.190626.190626 lmp.py:372]   Expert 59 |    277 | GPU
DEBUG 01-05 09:19:44.190361.190361 lmp.py:372]   Expert 52 |    278 | GPU
DEBUG 01-05 09:19:44.190858.190858 lmp.py:372]   Expert 28 |    310 | GPU
DEBUG 01-05 09:19:44.190071.190071 lmp.py:372]   Expert 60 |    310 | GPU
DEBUG 01-05 09:19:44.190475.190475 lmp.py:372]   Expert 48 |    313 | GPU
DEBUG 01-05 09:19:44.190926.190926 lmp.py:372]   Expert 54 |    325 | GPU
DEBUG 01-05 09:19:44.190662.190662 lmp.py:372]   Expert 25 |    327 | GPU
DEBUG 01-05 09:19:44.190636.190636 lmp.py:372]   Expert 24 |    338 | GPU
DEBUG 01-05 09:19:44.190372.190372 lmp.py:372]   Expert 40 |    374 | GPU
DEBUG 01-05 09:19:44.190107.190107 lmp.py:372]   Expert 36 |    377 | GPU
DEBUG 01-05 09:19:44.190081.190081 lmp.py:372]   Expert 33 |    423 | GPU
DEBUG 01-05 09:19:44.190294.190294 lmp.py:372]   Expert  9 |    465 | GPU
DEBUG 01-05 09:19:44.190268.190268 lmp.py:372]   Expert 15 |    542 | GPU
DEBUG 01-05 09:19:44.190434.190434 lmp.py:372]   Expert 56 |    555 | GPU
DEBUG 01-05 09:19:44.190077.190077 lmp.py:372]   Expert 10 |    812 | GPU
DEBUG 01-05 09:19:44.191243.191243 lmp.py:373] 
DEBUG 01-05 09:19:44.191243.191243 lmp.py:373]   CPU total tokens: 2628 (21.4%)
DEBUG 01-05 09:19:44.191409.191409 lmp.py:374]   GPU total tokens: 9660 (78.6%)
DEBUG 01-05 09:19:44.191390.191390 cuda_h.py:19] end experts_map_get cost 0.0014810562133789062 seconds
DEBUG 01-05 09:19:44.191556.191556 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.191856.191856 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.191675.191675 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.191391.191391 cuda_h.py:19] end allocate_cuda_memory cost 0.0001773834228515625 seconds
DEBUG 01-05 09:19:44.191664.191664 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.191990.191990 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.191899.191899 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.191025.191025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d848859-3b48-4c19-ae62-4aa85028f853
DEBUG 01-05 09:19:44.191522.191522 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.192384.192384 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d848859-3b48-4c19-ae62-4aa85028f853
DEBUG 01-05 09:19:44.192313.192313 cuda_h.py:19] end load_into_gpu_async cost 0.0013246536254882812 seconds
DEBUG 01-05 09:19:44.192108.192108 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.193327.193327 cuda_h.py:19] end restore_tensors2 cost 0.0003809928894042969 seconds
DEBUG 01-05 09:19:44.193733.193733 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022382736206054688 seconds
DEBUG 01-05 09:19:44.196484.196484 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004941701889038086 seconds
DEBUG 01-05 09:19:44.196943.196943 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.196674.196674 lmp.py:419] 
DEBUG 01-05 09:19:44.196674.196674 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.196094.196094 cuda_h.py:19] end cpu_experts_submit cost 0.00011348724365234375 seconds
DEBUG 01-05 09:19:44.196459.196459 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.209384.209384 mlpmodule.py:704] group tensors cost 0.012621164321899414 s
DEBUG 01-05 09:19:44.212721.212721 mlpmodule.py:742] pad cost 0.0028047561645507812 s
DEBUG 01-05 09:19:44.213760.213760 mlpmodule.py:748] create cpu tensor cost 6.937980651855469e-05 s
DEBUG 01-05 09:19:44.213557.213557 mlpmodule.py:753] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-05 09:19:44.225942.225942 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.225234.225234 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.226774.226774 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 09:19:44.226468.226468 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.243810.243810 mlpmodule.py:793] group einsum cost 0.030390024185180664 s
DEBUG 01-05 09:19:44.245086.245086 mlpmodule.py:801] cpy2cputensor cost 0.0018465518951416016 s
DEBUG 01-05 09:19:44.293462.293462 cuda_h.py:19] end wait_cetm_experts cost 0.09732937812805176 seconds
DEBUG 01-05 09:19:44.293746.293746 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.294370.294370 cuda_h.py:19] end gpu_sexperts cost 0.0005919933319091797 seconds
DEBUG 01-05 09:19:44.294140.294140 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:19:44.294202.294202 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:19:44.294350.294350 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.814697265625e-05 seconds
DEBUG 01-05 09:19:44.294728.294728 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:19:44.294001.294001 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.294618.294618 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d848859-3b48-4c19-ae62-4aa85028f853
DEBUG 01-05 09:19:44.294663.294663 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.295898.295898 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.295378.295378 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.304114.304114 cuda_h.py:19] end allocate_cuda_memory cost 0.009098291397094727 seconds
INFO 01-05 09:19:44.304794.304794 client.py:127] Model loaded
DEBUG 01-05 09:19:44.304466.304466 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.304085.304085 cuda_h.py:19] end wait_experts cost 0.009786367416381836 seconds
DEBUG 01-05 09:19:44.304907.304907 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.304936.304936 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.304614.304614 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.304962.304962 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b15189fe-e65d-423b-9894-13a306e36858
DEBUG 01-05 09:19:44.304581.304581 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.304549.304549 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:44.305407.305407 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b15189fe-e65d-423b-9894-13a306e36858
DEBUG 01-05 09:19:44.305303.305303 cuda_h.py:19] end load_into_gpu_async cost 0.0011377334594726562 seconds
DEBUG 01-05 09:19:44.305344.305344 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.305507.305507 cuda_h.py:19] end restore_tensors2 cost 8.845329284667969e-05 seconds
DEBUG 01-05 09:19:44.305938.305938 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010843753814697266 seconds
DEBUG 01-05 09:19:44.306675.306675 mlpmodule.py:531] gpu group tensors cost 0.0012297630310058594 s
INFO 01-05 09:19:44.306984.306984 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b15189fe-e65d-423b-9894-13a306e36858
DEBUG 01-05 09:19:44.308273.308273 mlpmodule.py:564] gpu pad cost 0.0017323493957519531 s
DEBUG 01-05 09:19:44.308220.308220 mlpmodule.py:582] gpu group einsum cost 0.0005254745483398438 s
DEBUG 01-05 09:19:44.311995.311995 mlpmodule.py:611] gpu experts func einsum cost 0.006630420684814453 s
DEBUG 01-05 09:19:44.311070.311070 cuda_h.py:19] end gpu_experts cost 0.007061958312988281 seconds
DEBUG 01-05 09:19:44.311303.311303 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:44.316291.316291 client.py:127] Model loaded
DEBUG 01-05 09:19:44.316280.316280 cuda_h.py:19] end sllm_worker_task cost 0.021285295486450195 seconds
DEBUG 01-05 09:19:44.316282.316282 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0044705867767333984 seconds
DEBUG 01-05 09:19:44.316474.316474 cuda_h.py:19] end layer_moe_generate_12 cost 0.12769746780395508 seconds
DEBUG 01-05 09:19:44.316229.316229 lmp.py:214] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 09:19:44.316230.316230 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 09:19:44.316972.316972 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.317975.317975 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.319007.319007 cuda_h.py:19] end self_attn cost 0.002458333969116211 seconds
DEBUG 01-05 09:19:44.319361.319361 cuda_h.py:19] end iln_self_attn_paln cost 0.0030651092529296875 seconds
DEBUG 01-05 09:19:44.319727.319727 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 09:19:44.320397.320397 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.320008.320008 cuda_h.py:19] end gate cost 0.0005915164947509766 seconds
DEBUG 01-05 09:19:44.320791.320791 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.321006.321006 lmp.py:361] 
DEBUG 01-05 09:19:44.321006.321006 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.321285.321285 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.321935.321935 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.321154.321154 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.321559.321559 lmp.py:365] 
DEBUG 01-05 09:19:44.321559.321559 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.321963.321963 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.321090.321090 lmp.py:372]   Expert 53 |      9 | CPU
DEBUG 01-05 09:19:44.321210.321210 lmp.py:372]   Expert  6 |     11 | CPU
DEBUG 01-05 09:19:44.321376.321376 lmp.py:372]   Expert 19 |     21 | CPU
DEBUG 01-05 09:19:44.321065.321065 lmp.py:372]   Expert 50 |     26 | CPU
DEBUG 01-05 09:19:44.321754.321754 lmp.py:372]   Expert 26 |     35 | CPU
DEBUG 01-05 09:19:44.321444.321444 lmp.py:372]   Expert  2 |     53 | CPU
DEBUG 01-05 09:19:44.321895.321895 lmp.py:372]   Expert  0 |     54 | CPU
DEBUG 01-05 09:19:44.321346.321346 lmp.py:372]   Expert 12 |     59 | CPU
DEBUG 01-05 09:19:44.321796.321796 lmp.py:372]   Expert  8 |     61 | CPU
DEBUG 01-05 09:19:44.321486.321486 lmp.py:372]   Expert 31 |     76 | CPU
DEBUG 01-05 09:19:44.321460.321460 lmp.py:372]   Expert 32 |     84 | CPU
DEBUG 01-05 09:19:44.321672.321672 lmp.py:372]   Expert 16 |     90 | CPU
DEBUG 01-05 09:19:44.321408.321408 lmp.py:372]   Expert 20 |     91 | CPU
DEBUG 01-05 09:19:44.321620.321620 lmp.py:372]   Expert 30 |     93 | CPU
DEBUG 01-05 09:19:44.321833.321833 lmp.py:372]   Expert 40 |     93 | CPU
DEBUG 01-05 09:19:44.321237.321237 lmp.py:372]   Expert 35 |    115 | CPU
DEBUG 01-05 09:19:44.321403.321403 lmp.py:372]   Expert 28 |    117 | CPU
DEBUG 01-05 09:19:44.321378.321378 lmp.py:372]   Expert 57 |    117 | CPU
DEBUG 01-05 09:19:44.321828.321828 lmp.py:372]   Expert 13 |    124 | CPU
DEBUG 01-05 09:19:44.321279.321279 lmp.py:372]   Expert 48 |    124 | CPU
DEBUG 01-05 09:19:44.321492.321492 lmp.py:372]   Expert 63 |    127 | CPU
DEBUG 01-05 09:19:44.321704.321704 lmp.py:372]   Expert 34 |    128 | CPU
DEBUG 01-05 09:19:44.321678.321678 lmp.py:372]   Expert 18 |    130 | CPU
DEBUG 01-05 09:19:44.321652.321652 lmp.py:372]   Expert 61 |    130 | CPU
DEBUG 01-05 09:19:44.321580.321580 lmp.py:372]   Expert  5 |    132 | CPU
DEBUG 01-05 09:19:44.321746.321746 lmp.py:372]   Expert 60 |    133 | CPU
DEBUG 01-05 09:19:44.321197.321197 lmp.py:372]   Expert 11 |    145 | CPU
DEBUG 01-05 09:19:44.321171.321171 lmp.py:372]   Expert 45 |    147 | CPU
DEBUG 01-05 09:19:44.321106.321106 lmp.py:372]   Expert  9 |    150 | CPU
DEBUG 01-05 09:19:44.321795.321795 lmp.py:372]   Expert 52 |    150 | CPU
DEBUG 01-05 09:19:44.321769.321769 lmp.py:372]   Expert 24 |    157 | CPU
DEBUG 01-05 09:19:44.321743.321743 lmp.py:372]   Expert 58 |    158 | CPU
DEBUG 01-05 09:19:44.321955.321955 lmp.py:372]   Expert  3 |    182 | GPU
DEBUG 01-05 09:19:44.321598.321598 lmp.py:372]   Expert 42 |    182 | GPU
DEBUG 01-05 09:19:44.321811.321811 lmp.py:372]   Expert 25 |    188 | GPU
DEBUG 01-05 09:19:44.321023.321023 lmp.py:372]   Expert 37 |    191 | GPU
DEBUG 01-05 09:19:44.321236.321236 lmp.py:372]   Expert 46 |    201 | GPU
DEBUG 01-05 09:19:44.321210.321210 lmp.py:372]   Expert 17 |    205 | GPU
DEBUG 01-05 09:19:44.321184.321184 lmp.py:372]   Expert  4 |    213 | GPU
DEBUG 01-05 09:19:44.321940.321940 lmp.py:372]   Expert 27 |    220 | GPU
DEBUG 01-05 09:19:44.321921.321921 lmp.py:372]   Expert 39 |    221 | GPU
DEBUG 01-05 09:19:44.321471.321471 lmp.py:372]   Expert  7 |    222 | GPU
DEBUG 01-05 09:19:44.321021.321021 lmp.py:372]   Expert 33 |    226 | GPU
DEBUG 01-05 09:19:44.321618.321618 lmp.py:372]   Expert 62 |    228 | GPU
DEBUG 01-05 09:19:44.321844.321844 lmp.py:372]   Expert 43 |    229 | GPU
DEBUG 01-05 09:19:44.321918.321918 lmp.py:372]   Expert 22 |    234 | GPU
DEBUG 01-05 09:19:44.321991.321991 lmp.py:372]   Expert 51 |    235 | GPU
DEBUG 01-05 09:19:44.321541.321541 lmp.py:372]   Expert 49 |    247 | GPU
DEBUG 01-05 09:19:44.321330.321330 lmp.py:372]   Expert  1 |    254 | GPU
DEBUG 01-05 09:19:44.321165.321165 lmp.py:372]   Expert 54 |    259 | GPU
DEBUG 01-05 09:19:44.322762.322762 lmp.py:372]   Expert 44 |    268 | GPU
DEBUG 01-05 09:19:44.322120.322120 lmp.py:372]   Expert 36 |    272 | GPU
DEBUG 01-05 09:19:44.322717.322717 lmp.py:372]   Expert 29 |    280 | GPU
DEBUG 01-05 09:19:44.322313.322313 lmp.py:372]   Expert 59 |    301 | GPU
DEBUG 01-05 09:19:44.322433.322433 lmp.py:372]   Expert 15 |    315 | GPU
DEBUG 01-05 09:19:44.322507.322507 lmp.py:372]   Expert 47 |    322 | GPU
DEBUG 01-05 09:19:44.322819.322819 lmp.py:372]   Expert 38 |    348 | GPU
DEBUG 01-05 09:19:44.322892.322892 lmp.py:372]   Expert 14 |    400 | GPU
DEBUG 01-05 09:19:44.322012.322012 lmp.py:372]   Expert 55 |    405 | GPU
DEBUG 01-05 09:19:44.322609.322609 lmp.py:372]   Expert 23 |    409 | GPU
DEBUG 01-05 09:19:44.322444.322444 lmp.py:372]   Expert 41 |    410 | GPU
DEBUG 01-05 09:19:44.322040.322040 lmp.py:372]   Expert 21 |    416 | GPU
DEBUG 01-05 09:19:44.322114.322114 lmp.py:372]   Expert 10 |    468 | GPU
DEBUG 01-05 09:19:44.322187.322187 lmp.py:372]   Expert 56 |    597 | GPU
DEBUG 01-05 09:19:44.322453.322453 lmp.py:373] 
DEBUG 01-05 09:19:44.322453.322453 lmp.py:373]   CPU total tokens: 3140 (25.6%)
DEBUG 01-05 09:19:44.322480.322480 lmp.py:374]   GPU total tokens: 9148 (74.4%)
DEBUG 01-05 09:19:44.322037.322037 cuda_h.py:19] end experts_map_get cost 0.001592397689819336 seconds
DEBUG 01-05 09:19:44.322303.322303 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.322371.322371 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.322932.322932 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.322862.322862 cuda_h.py:19] end allocate_cuda_memory cost 0.00022482872009277344 seconds
DEBUG 01-05 09:19:44.322242.322242 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.322528.322528 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.322920.322920 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.323815.323815 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e47eeb18-e717-4c24-94b0-042cdc87059c
DEBUG 01-05 09:19:44.323604.323604 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.323929.323929 mlpmodule.py:662]  experts func einsum cost 0.12681198120117188 s
INFO 01-05 09:19:44.324665.324665 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e47eeb18-e717-4c24-94b0-042cdc87059c
DEBUG 01-05 09:19:44.324178.324178 cuda_h.py:19] end load_into_gpu_async cost 0.0014216899871826172 seconds
DEBUG 01-05 09:19:44.324186.324186 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.324683.324683 cuda_h.py:19] end restore_tensors2 cost 0.0003745555877685547 seconds
DEBUG 01-05 09:19:44.324804.324804 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002435922622680664 seconds
DEBUG 01-05 09:19:44.327423.327423 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005147218704223633 seconds
DEBUG 01-05 09:19:44.327472.327472 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.327203.327203 lmp.py:419] 
DEBUG 01-05 09:19:44.327203.327203 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.327444.327444 cuda_h.py:19] end cpu_experts_submit cost 0.0001251697540283203 seconds
DEBUG 01-05 09:19:44.327955.327955 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.333372.333372 mlpmodule.py:704] group tensors cost 0.005948543548583984 s
DEBUG 01-05 09:19:44.336214.336214 mlpmodule.py:742] pad cost 0.0020110607147216797 s
DEBUG 01-05 09:19:44.336404.336404 mlpmodule.py:748] create cpu tensor cost 5.7697296142578125e-05 s
DEBUG 01-05 09:19:44.336460.336460 mlpmodule.py:753] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-05 09:19:44.347521.347521 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.348016.348016 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.348974.348974 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 09:19:44.348879.348879 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.365423.365423 mlpmodule.py:793] group einsum cost 0.028696537017822266 s
DEBUG 01-05 09:19:44.366511.366511 mlpmodule.py:801] cpy2cputensor cost 0.000675201416015625 s
DEBUG 01-05 09:19:44.405740.405740 cuda_h.py:19] end wait_cetm_experts cost 0.07721781730651855 seconds
DEBUG 01-05 09:19:44.405260.405260 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.405516.405516 cuda_h.py:19] end gpu_sexperts cost 0.0004608631134033203 seconds
DEBUG 01-05 09:19:44.405266.405266 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:19:44.405897.405897 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:19:44.405945.405945 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:19:44.405847.405847 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.414817810058594e-05 seconds
DEBUG 01-05 09:19:44.405166.405166 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.405399.405399 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e47eeb18-e717-4c24-94b0-042cdc87059c
DEBUG 01-05 09:19:44.406854.406854 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.406666.406666 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.406946.406946 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.411732.411732 cuda_h.py:19] end allocate_cuda_memory cost 0.005031108856201172 seconds
DEBUG 01-05 09:19:44.411033.411033 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.411418.411418 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.411394.411394 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.411342.411342 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bcd1718e-fafd-4806-ad2e-fe963c95854a
DEBUG 01-05 09:19:44.411239.411239 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.411537.411537 client.py:127] Model loaded
DEBUG 01-05 09:19:44.411155.411155 cuda_h.py:19] end wait_experts cost 0.005965471267700195 seconds
DEBUG 01-05 09:19:44.411719.411719 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.411521.411521 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:44.412952.412952 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bcd1718e-fafd-4806-ad2e-fe963c95854a
DEBUG 01-05 09:19:44.412331.412331 cuda_h.py:19] end load_into_gpu_async cost 0.0011627674102783203 seconds
DEBUG 01-05 09:19:44.412849.412849 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.412528.412528 cuda_h.py:19] end restore_tensors2 cost 8.296966552734375e-05 seconds
DEBUG 01-05 09:19:44.412279.412279 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0065937042236328125 seconds
DEBUG 01-05 09:19:44.413850.413850 mlpmodule.py:531] gpu group tensors cost 0.0010342597961425781 s
INFO 01-05 09:19:44.413126.413126 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bcd1718e-fafd-4806-ad2e-fe963c95854a
DEBUG 01-05 09:19:44.415100.415100 mlpmodule.py:564] gpu pad cost 0.0020444393157958984 s
DEBUG 01-05 09:19:44.415804.415804 mlpmodule.py:582] gpu group einsum cost 0.0005846023559570312 s
DEBUG 01-05 09:19:44.419245.419245 mlpmodule.py:611] gpu experts func einsum cost 0.007297039031982422 s
DEBUG 01-05 09:19:44.419129.419129 cuda_h.py:19] end gpu_experts cost 0.007472515106201172 seconds
DEBUG 01-05 09:19:44.419362.419362 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:44.421327.421327 client.py:127] Model loaded
DEBUG 01-05 09:19:44.422078.422078 cuda_h.py:19] end sllm_worker_task cost 0.015861988067626953 seconds
DEBUG 01-05 09:19:44.422875.422875 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0026290416717529297 seconds
DEBUG 01-05 09:19:44.422085.422085 cuda_h.py:19] end layer_moe_generate_13 cost 0.10223174095153809 seconds
DEBUG 01-05 09:19:44.422509.422509 lmp.py:214] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 09:19:44.422034.422034 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 09:19:44.422968.422968 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.422395.422395 cuda_h.py:10] start self_attn
DEBUG 01-05 09:19:44.423665.423665 mlpmodule.py:662]  experts func einsum cost 0.09541177749633789 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.425019.425019 cuda_h.py:19] end self_attn cost 0.0025780200958251953 seconds
DEBUG 01-05 09:19:44.425341.425341 cuda_h.py:19] end iln_self_attn_paln cost 0.0031931400299072266 seconds
DEBUG 01-05 09:19:44.425707.425707 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 09:19:44.425139.425139 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.426683.426683 cuda_h.py:19] end gate cost 0.0005774497985839844 seconds
DEBUG 01-05 09:19:44.426274.426274 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.426780.426780 lmp.py:361] 
DEBUG 01-05 09:19:44.426780.426780 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.426298.426298 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.426709.426709 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.426975.426975 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.426618.426618 lmp.py:365] 
DEBUG 01-05 09:19:44.426618.426618 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.426022.426022 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.426864.426864 lmp.py:372]   Expert 61 |      8 | CPU
DEBUG 01-05 09:19:44.426984.426984 lmp.py:372]   Expert  7 |     14 | CPU
DEBUG 01-05 09:19:44.426389.426389 lmp.py:372]   Expert 59 |     42 | CPU
DEBUG 01-05 09:19:44.426793.426793 lmp.py:372]   Expert 48 |     53 | CPU
DEBUG 01-05 09:19:44.427721.427721 lmp.py:372]   Expert 50 |     57 | CPU
DEBUG 01-05 09:19:44.427172.427172 lmp.py:372]   Expert 38 |     59 | CPU
DEBUG 01-05 09:19:44.427861.427861 lmp.py:372]   Expert 34 |     60 | CPU
DEBUG 01-05 09:19:44.427312.427312 lmp.py:372]   Expert 49 |     61 | CPU
DEBUG 01-05 09:19:44.427001.427001 lmp.py:372]   Expert 40 |     62 | CPU
DEBUG 01-05 09:19:44.427406.427406 lmp.py:372]   Expert 55 |     69 | CPU
DEBUG 01-05 09:19:44.427095.427095 lmp.py:372]   Expert 32 |     73 | CPU
DEBUG 01-05 09:19:44.427785.427785 lmp.py:372]   Expert 44 |     98 | CPU
DEBUG 01-05 09:19:44.427997.427997 lmp.py:372]   Expert 18 |    101 | CPU
DEBUG 01-05 09:19:44.427209.427209 lmp.py:372]   Expert 39 |    102 | CPU
DEBUG 01-05 09:19:44.427422.427422 lmp.py:372]   Expert 43 |    104 | CPU
DEBUG 01-05 09:19:44.427396.427396 lmp.py:372]   Expert 35 |    109 | CPU
DEBUG 01-05 09:19:44.427608.427608 lmp.py:372]   Expert  0 |    110 | CPU
DEBUG 01-05 09:19:44.427298.427298 lmp.py:372]   Expert 23 |    113 | CPU
DEBUG 01-05 09:19:44.427987.427987 lmp.py:372]   Expert 60 |    115 | CPU
DEBUG 01-05 09:19:44.427961.427961 lmp.py:372]   Expert 29 |    117 | CPU
DEBUG 01-05 09:19:44.427935.427935 lmp.py:372]   Expert 20 |    119 | CPU
DEBUG 01-05 09:19:44.427386.427386 lmp.py:372]   Expert 17 |    122 | CPU
DEBUG 01-05 09:19:44.427122.427122 lmp.py:372]   Expert  8 |    123 | CPU
DEBUG 01-05 09:19:44.427334.427334 lmp.py:372]   Expert 28 |    123 | CPU
DEBUG 01-05 09:19:44.427547.427547 lmp.py:372]   Expert 41 |    129 | CPU
DEBUG 01-05 09:19:44.427236.427236 lmp.py:372]   Expert 51 |    132 | CPU
DEBUG 01-05 09:19:44.427164.427164 lmp.py:372]   Expert 21 |    134 | CPU
DEBUG 01-05 09:19:44.427376.427376 lmp.py:372]   Expert 54 |    139 | CPU
DEBUG 01-05 09:19:44.427112.427112 lmp.py:372]   Expert 12 |    144 | CPU
DEBUG 01-05 09:19:44.427324.427324 lmp.py:372]   Expert 52 |    174 | CPU
DEBUG 01-05 09:19:44.427537.427537 lmp.py:372]   Expert 42 |    179 | CPU
DEBUG 01-05 09:19:44.427272.427272 lmp.py:372]   Expert 45 |    179 | CPU
DEBUG 01-05 09:19:44.427485.427485 lmp.py:372]   Expert 57 |    186 | GPU
DEBUG 01-05 09:19:44.427936.427936 lmp.py:372]   Expert 62 |    192 | GPU
DEBUG 01-05 09:19:44.427386.427386 lmp.py:372]   Expert  6 |    197 | GPU
DEBUG 01-05 09:19:44.427837.427837 lmp.py:372]   Expert  3 |    208 | GPU
DEBUG 01-05 09:19:44.427050.427050 lmp.py:372]   Expert 13 |    210 | GPU
DEBUG 01-05 09:19:44.427785.427785 lmp.py:372]   Expert 30 |    210 | GPU
DEBUG 01-05 09:19:44.427998.427998 lmp.py:372]   Expert 31 |    219 | GPU
DEBUG 01-05 09:19:44.427972.427972 lmp.py:372]   Expert 36 |    226 | GPU
DEBUG 01-05 09:19:44.427946.427946 lmp.py:372]   Expert 11 |    227 | GPU
DEBUG 01-05 09:19:44.427158.427158 lmp.py:372]   Expert 26 |    229 | GPU
DEBUG 01-05 09:19:44.427848.427848 lmp.py:372]   Expert 46 |    236 | GPU
DEBUG 01-05 09:19:44.427014.427014 lmp.py:372]   Expert 14 |    245 | GPU
DEBUG 01-05 09:19:44.427988.427988 lmp.py:372]   Expert 19 |    247 | GPU
DEBUG 01-05 09:19:44.427439.427439 lmp.py:372]   Expert 27 |    261 | GPU
DEBUG 01-05 09:19:44.427890.427890 lmp.py:372]   Expert  2 |    263 | GPU
DEBUG 01-05 09:19:44.427625.427625 lmp.py:372]   Expert  4 |    270 | GPU
DEBUG 01-05 09:19:44.427838.427838 lmp.py:372]   Expert 22 |    271 | GPU
DEBUG 01-05 09:19:44.427289.427289 lmp.py:372]   Expert  5 |    279 | GPU
DEBUG 01-05 09:19:44.427024.427024 lmp.py:372]   Expert 33 |    282 | GPU
DEBUG 01-05 09:19:44.427475.427475 lmp.py:372]   Expert 37 |    288 | GPU
DEBUG 01-05 09:19:44.427641.427641 lmp.py:372]   Expert 56 |    296 | GPU
DEBUG 01-05 09:19:44.427807.427807 lmp.py:372]   Expert  1 |    304 | GPU
DEBUG 01-05 09:19:44.427497.427497 lmp.py:372]   Expert 16 |    304 | GPU
DEBUG 01-05 09:19:44.427471.427471 lmp.py:372]   Expert 58 |    307 | GPU
DEBUG 01-05 09:19:44.427445.427445 lmp.py:372]   Expert 53 |    310 | GPU
DEBUG 01-05 09:19:44.427419.427419 lmp.py:372]   Expert 63 |    351 | GPU
DEBUG 01-05 09:19:44.427870.427870 lmp.py:372]   Expert 10 |    352 | GPU
DEBUG 01-05 09:19:44.427082.427082 lmp.py:372]   Expert 15 |    368 | GPU
DEBUG 01-05 09:19:44.427056.427056 lmp.py:372]   Expert 47 |    377 | GPU
DEBUG 01-05 09:19:44.427269.427269 lmp.py:372]   Expert 24 |    387 | GPU
DEBUG 01-05 09:19:44.427243.427243 lmp.py:372]   Expert 25 |    473 | GPU
DEBUG 01-05 09:19:44.427217.427217 lmp.py:372]   Expert  9 |    489 | GPU
DEBUG 01-05 09:19:44.427860.427860 lmp.py:373] 
DEBUG 01-05 09:19:44.427860.427860 lmp.py:373]   CPU total tokens: 3224 (26.2%)
DEBUG 01-05 09:19:44.428980.428980 lmp.py:374]   GPU total tokens: 9064 (73.8%)
DEBUG 01-05 09:19:44.428676.428676 cuda_h.py:19] end experts_map_get cost 0.0014977455139160156 seconds
DEBUG 01-05 09:19:44.428080.428080 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.428194.428194 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.428199.428199 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.428480.428480 cuda_h.py:19] end allocate_cuda_memory cost 0.000244140625 seconds
DEBUG 01-05 09:19:44.428376.428376 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.428225.428225 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.428418.428418 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.428353.428353 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b52599f3-b53f-4729-9534-ab598cd093ae
DEBUG 01-05 09:19:44.428147.428147 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.429277.429277 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b52599f3-b53f-4729-9534-ab598cd093ae
DEBUG 01-05 09:19:44.429822.429822 cuda_h.py:19] end load_into_gpu_async cost 0.001211404800415039 seconds
DEBUG 01-05 09:19:44.429664.429664 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.430598.430598 cuda_h.py:19] end restore_tensors2 cost 0.0003821849822998047 seconds
DEBUG 01-05 09:19:44.430242.430242 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002189159393310547 seconds
DEBUG 01-05 09:19:44.432822.432822 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049076080322265625 seconds
DEBUG 01-05 09:19:44.433704.433704 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.433667.433667 lmp.py:419] 
DEBUG 01-05 09:19:44.433667.433667 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.433795.433795 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-05 09:19:44.433590.433590 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.438202.438202 mlpmodule.py:704] group tensors cost 0.005483150482177734 s
DEBUG 01-05 09:19:44.441477.441477 mlpmodule.py:742] pad cost 0.0015418529510498047 s
DEBUG 01-05 09:19:44.441481.441481 mlpmodule.py:748] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-05 09:19:44.441999.441999 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-05 09:19:44.454026.454026 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.454594.454594 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.454830.454830 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 09:19:44.454291.454291 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.474257.474257 mlpmodule.py:793] group einsum cost 0.032944440841674805 s
DEBUG 01-05 09:19:44.475614.475614 mlpmodule.py:801] cpy2cputensor cost 0.0007495880126953125 s
DEBUG 01-05 09:19:44.515025.515025 cuda_h.py:19] end wait_cetm_experts cost 0.08254361152648926 seconds
DEBUG 01-05 09:19:44.515008.515008 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.516344.516344 cuda_h.py:19] end gpu_sexperts cost 0.00046944618225097656 seconds
DEBUG 01-05 09:19:44.516902.516902 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:19:44.516625.516625 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:19:44.516482.516482 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:19:44.516191.516191 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.152557373046875e-05 seconds
DEBUG 01-05 09:19:44.516941.516941 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.516372.516372 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b52599f3-b53f-4729-9534-ab598cd093ae
DEBUG 01-05 09:19:44.516643.516643 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.516997.516997 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.516416.516416 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.520263.520263 cuda_h.py:19] end allocate_cuda_memory cost 0.0038814544677734375 seconds
DEBUG 01-05 09:19:44.521565.521565 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.521572.521572 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.521740.521740 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.521595.521595 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1e465d23-0d31-41ea-9a3b-548a4d884d59
DEBUG 01-05 09:19:44.521731.521731 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.521751.521751 client.py:127] Model loaded
DEBUG 01-05 09:19:44.521508.521508 cuda_h.py:19] end wait_experts cost 0.004842519760131836 seconds
DEBUG 01-05 09:19:44.521310.521310 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.521113.521113 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:44.522236.522236 mlpmodule.py:531] gpu group tensors cost 0.0006430149078369141 s
INFO 01-05 09:19:44.522274.522274 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1e465d23-0d31-41ea-9a3b-548a4d884d59
DEBUG 01-05 09:19:44.522561.522561 cuda_h.py:19] end load_into_gpu_async cost 0.0014293193817138672 seconds
DEBUG 01-05 09:19:44.522509.522509 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.522294.522294 cuda_h.py:19] end restore_tensors2 cost 9.036064147949219e-05 seconds
DEBUG 01-05 09:19:44.522826.522826 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005735635757446289 seconds
INFO 01-05 09:19:44.523224.523224 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1e465d23-0d31-41ea-9a3b-548a4d884d59
DEBUG 01-05 09:19:44.524505.524505 mlpmodule.py:564] gpu pad cost 0.002633810043334961 s
DEBUG 01-05 09:19:44.525844.525844 mlpmodule.py:582] gpu group einsum cost 0.0005600452423095703 s
DEBUG 01-05 09:19:44.529622.529622 mlpmodule.py:611] gpu experts func einsum cost 0.007422208786010742 s
DEBUG 01-05 09:19:44.529605.529605 cuda_h.py:19] end gpu_experts cost 0.007598400115966797 seconds
DEBUG 01-05 09:19:44.529553.529553 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:44.529105.529105 mlpmodule.py:662]  experts func einsum cost 0.09615612030029297 s
INFO 01-05 09:19:44.531050.531050 client.py:127] Model loaded
DEBUG 01-05 09:19:44.531079.531079 cuda_h.py:19] end sllm_worker_task cost 0.014320850372314453 seconds
DEBUG 01-05 09:19:44.531352.531352 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0020651817321777344 seconds
DEBUG 01-05 09:19:44.531278.531278 cuda_h.py:19] end layer_moe_generate_14 cost 0.10561895370483398 seconds
DEBUG 01-05 09:19:44.531013.531013 lmp.py:214] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 09:19:44.531060.531060 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 09:19:44.531041.531041 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.531554.531554 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.534611.534611 cuda_h.py:19] end self_attn cost 0.002442598342895508 seconds
DEBUG 01-05 09:19:44.534330.534330 cuda_h.py:19] end iln_self_attn_paln cost 0.003062725067138672 seconds
DEBUG 01-05 09:19:44.534696.534696 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 09:19:44.534082.534082 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.535208.535208 cuda_h.py:19] end gate cost 0.0005853176116943359 seconds
DEBUG 01-05 09:19:44.535515.535515 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.535783.535783 lmp.py:361] 
DEBUG 01-05 09:19:44.535783.535783 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.535824.535824 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.535235.535235 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.535501.535501 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.535905.535905 lmp.py:365] 
DEBUG 01-05 09:19:44.535905.535905 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.535833.535833 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.535721.535721 lmp.py:372]   Expert 63 |     15 | CPU
DEBUG 01-05 09:19:44.536126.536126 lmp.py:372]   Expert 34 |     53 | CPU
DEBUG 01-05 09:19:44.536054.536054 lmp.py:372]   Expert 37 |     55 | CPU
DEBUG 01-05 09:19:44.536220.536220 lmp.py:372]   Expert 42 |     56 | CPU
DEBUG 01-05 09:19:44.536909.536909 lmp.py:372]   Expert  4 |     58 | CPU
DEBUG 01-05 09:19:44.536837.536837 lmp.py:372]   Expert 48 |     58 | CPU
DEBUG 01-05 09:19:44.536288.536288 lmp.py:372]   Expert 53 |     73 | CPU
DEBUG 01-05 09:19:44.536977.536977 lmp.py:372]   Expert 28 |     75 | CPU
DEBUG 01-05 09:19:44.536189.536189 lmp.py:372]   Expert 57 |     77 | CPU
DEBUG 01-05 09:19:44.536640.536640 lmp.py:372]   Expert 22 |     80 | CPU
DEBUG 01-05 09:19:44.536091.536091 lmp.py:372]   Expert 51 |     82 | CPU
DEBUG 01-05 09:19:44.536304.536304 lmp.py:372]   Expert  5 |     85 | CPU
DEBUG 01-05 09:19:44.536993.536993 lmp.py:372]   Expert 15 |     86 | CPU
DEBUG 01-05 09:19:44.536921.536921 lmp.py:372]   Expert 40 |     91 | CPU
DEBUG 01-05 09:19:44.536133.536133 lmp.py:372]   Expert 43 |     96 | CPU
DEBUG 01-05 09:19:44.536584.536584 lmp.py:372]   Expert 41 |    105 | CPU
DEBUG 01-05 09:19:44.536558.536558 lmp.py:372]   Expert 55 |    123 | CPU
DEBUG 01-05 09:19:44.536009.536009 lmp.py:372]   Expert 29 |    130 | CPU
DEBUG 01-05 09:19:44.536460.536460 lmp.py:372]   Expert 32 |    131 | CPU
DEBUG 01-05 09:19:44.536195.536195 lmp.py:372]   Expert  7 |    133 | CPU
DEBUG 01-05 09:19:44.536123.536123 lmp.py:372]   Expert 52 |    133 | CPU
DEBUG 01-05 09:19:44.536051.536051 lmp.py:372]   Expert  6 |    135 | CPU
DEBUG 01-05 09:19:44.536740.536740 lmp.py:372]   Expert 56 |    148 | CPU
DEBUG 01-05 09:19:44.536714.536714 lmp.py:372]   Expert 44 |    154 | CPU
DEBUG 01-05 09:19:44.536794.536794 lmp.py:372]   Expert 61 |    155 | CPU
DEBUG 01-05 09:19:44.536007.536007 lmp.py:372]   Expert 25 |    157 | CPU
DEBUG 01-05 09:19:44.536458.536458 lmp.py:372]   Expert 14 |    161 | CPU
DEBUG 01-05 09:19:44.536432.536432 lmp.py:372]   Expert 54 |    161 | CPU
DEBUG 01-05 09:19:44.536883.536883 lmp.py:372]   Expert 50 |    162 | CPU
DEBUG 01-05 09:19:44.536287.536287 lmp.py:372]   Expert  2 |    164 | CPU
DEBUG 01-05 09:19:44.536738.536738 lmp.py:372]   Expert 12 |    165 | CPU
DEBUG 01-05 09:19:44.536474.536474 lmp.py:372]   Expert 33 |    174 | CPU
DEBUG 01-05 09:19:44.536686.536686 lmp.py:372]   Expert 35 |    190 | GPU
DEBUG 01-05 09:19:44.536660.536660 lmp.py:372]   Expert 39 |    192 | GPU
DEBUG 01-05 09:19:44.536634.536634 lmp.py:372]   Expert 62 |    207 | GPU
DEBUG 01-05 09:19:44.536608.536608 lmp.py:372]   Expert 58 |    209 | GPU
DEBUG 01-05 09:19:44.536344.536344 lmp.py:372]   Expert 31 |    215 | GPU
DEBUG 01-05 09:19:44.536318.536318 lmp.py:372]   Expert 11 |    217 | GPU
DEBUG 01-05 09:19:44.536531.536531 lmp.py:372]   Expert 20 |    219 | GPU
DEBUG 01-05 09:19:44.536743.536743 lmp.py:372]   Expert 45 |    221 | GPU
DEBUG 01-05 09:19:44.536671.536671 lmp.py:372]   Expert 59 |    222 | GPU
DEBUG 01-05 09:19:44.536122.536122 lmp.py:372]   Expert 47 |    224 | GPU
DEBUG 01-05 09:19:44.536334.536334 lmp.py:372]   Expert 23 |    226 | GPU
DEBUG 01-05 09:19:44.536070.536070 lmp.py:372]   Expert 13 |    232 | GPU
DEBUG 01-05 09:19:44.536282.536282 lmp.py:372]   Expert 10 |    236 | GPU
DEBUG 01-05 09:19:44.536018.536018 lmp.py:372]   Expert  1 |    240 | GPU
DEBUG 01-05 09:19:44.536992.536992 lmp.py:372]   Expert 38 |    244 | GPU
DEBUG 01-05 09:19:44.536681.536681 lmp.py:372]   Expert 24 |    249 | GPU
DEBUG 01-05 09:19:44.536370.536370 lmp.py:372]   Expert  0 |    251 | GPU
DEBUG 01-05 09:19:44.536344.536344 lmp.py:372]   Expert 36 |    260 | GPU
DEBUG 01-05 09:19:44.536319.536319 lmp.py:372]   Expert  9 |    268 | GPU
DEBUG 01-05 09:19:44.536054.536054 lmp.py:372]   Expert 18 |    274 | GPU
DEBUG 01-05 09:19:44.536028.536028 lmp.py:372]   Expert 46 |    285 | GPU
DEBUG 01-05 09:19:44.536241.536241 lmp.py:372]   Expert 60 |    293 | GPU
DEBUG 01-05 09:19:44.536976.536976 lmp.py:372]   Expert 16 |    294 | GPU
DEBUG 01-05 09:19:44.536142.536142 lmp.py:372]   Expert 30 |    306 | GPU
DEBUG 01-05 09:19:44.536070.536070 lmp.py:372]   Expert 49 |    309 | GPU
DEBUG 01-05 09:19:44.536521.536521 lmp.py:372]   Expert  3 |    311 | GPU
DEBUG 01-05 09:19:44.536257.536257 lmp.py:372]   Expert 19 |    312 | GPU
DEBUG 01-05 09:19:44.536992.536992 lmp.py:372]   Expert 26 |    333 | GPU
DEBUG 01-05 09:19:44.536728.536728 lmp.py:372]   Expert 21 |    347 | GPU
DEBUG 01-05 09:19:44.536702.536702 lmp.py:372]   Expert 27 |    353 | GPU
DEBUG 01-05 09:19:44.537438.537438 lmp.py:372]   Expert 17 |    367 | GPU
DEBUG 01-05 09:19:44.537412.537412 lmp.py:372]   Expert  8 |    651 | GPU
DEBUG 01-05 09:19:44.537816.537816 lmp.py:373] 
DEBUG 01-05 09:19:44.537816.537816 lmp.py:373]   CPU total tokens: 3531 (28.7%)
DEBUG 01-05 09:19:44.537698.537698 lmp.py:374]   GPU total tokens: 8757 (71.3%)
DEBUG 01-05 09:19:44.537394.537394 cuda_h.py:19] end experts_map_get cost 0.0014977455139160156 seconds
DEBUG 01-05 09:19:44.537560.537560 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.537005.537005 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.537891.537891 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.537218.537218 cuda_h.py:19] end allocate_cuda_memory cost 0.00023984909057617188 seconds
DEBUG 01-05 09:19:44.537115.537115 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.537679.537679 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.537633.537633 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.537283.537283 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24b870d2-2a97-4e7f-b75a-46744a51a80f
DEBUG 01-05 09:19:44.537760.537760 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.539686.539686 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24b870d2-2a97-4e7f-b75a-46744a51a80f
DEBUG 01-05 09:19:44.539615.539615 cuda_h.py:19] end load_into_gpu_async cost 0.0016727447509765625 seconds
DEBUG 01-05 09:19:44.539126.539126 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.539107.539107 cuda_h.py:19] end restore_tensors2 cost 0.0003800392150878906 seconds
DEBUG 01-05 09:19:44.539082.539082 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026667118072509766 seconds
DEBUG 01-05 09:19:44.542125.542125 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00537562370300293 seconds
DEBUG 01-05 09:19:44.542100.542100 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.542368.542368 lmp.py:419] 
DEBUG 01-05 09:19:44.542368.542368 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.542973.542973 cuda_h.py:19] end cpu_experts_submit cost 0.0001246929168701172 seconds
DEBUG 01-05 09:19:44.542815.542815 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.553273.553273 mlpmodule.py:704] group tensors cost 0.010589838027954102 s
DEBUG 01-05 09:19:44.555536.555536 mlpmodule.py:742] pad cost 0.0015397071838378906 s
DEBUG 01-05 09:19:44.555215.555215 mlpmodule.py:748] create cpu tensor cost 4.124641418457031e-05 s
DEBUG 01-05 09:19:44.555972.555972 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-05 09:19:44.567543.567543 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.567257.567257 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.567777.567777 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:19:44.567384.567384 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.588773.588773 mlpmodule.py:793] group einsum cost 0.032144784927368164 s
DEBUG 01-05 09:19:44.589828.589828 mlpmodule.py:801] cpy2cputensor cost 0.0012431144714355469 s
DEBUG 01-05 09:19:44.629182.629182 cuda_h.py:19] end wait_cetm_experts cost 0.08649182319641113 seconds
DEBUG 01-05 09:19:44.629113.629113 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.629520.629520 cuda_h.py:19] end gpu_sexperts cost 0.0004696846008300781 seconds
DEBUG 01-05 09:19:44.629310.629310 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:19:44.629318.629318 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:19:44.630745.630745 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:19:44.630408.630408 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.152557373046875e-05 seconds
DEBUG 01-05 09:19:44.630680.630680 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.630781.630781 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24b870d2-2a97-4e7f-b75a-46744a51a80f
DEBUG 01-05 09:19:44.630523.630523 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.630238.630238 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.630649.630649 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.634388.634388 cuda_h.py:19] end allocate_cuda_memory cost 0.0037288665771484375 seconds
INFO 01-05 09:19:44.634116.634116 client.py:127] Model loaded
DEBUG 01-05 09:19:44.634718.634718 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.635059.635059 cuda_h.py:19] end wait_experts cost 0.004944324493408203 seconds
DEBUG 01-05 09:19:44.635207.635207 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.635879.635879 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.635717.635717 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:44.635300.635300 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.636735.636735 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5dca38ac-be6a-4ea1-ac4f-8867847afd47
DEBUG 01-05 09:19:44.636166.636166 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.636838.636838 mlpmodule.py:531] gpu group tensors cost 0.0009310245513916016 s
INFO 01-05 09:19:44.637109.637109 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5dca38ac-be6a-4ea1-ac4f-8867847afd47
DEBUG 01-05 09:19:44.638241.638241 cuda_h.py:19] end load_into_gpu_async cost 0.002973794937133789 seconds
DEBUG 01-05 09:19:44.638079.638079 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.638044.638044 cuda_h.py:19] end restore_tensors2 cost 0.00017595291137695312 seconds
DEBUG 01-05 09:19:44.638361.638361 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008067846298217773 seconds
INFO 01-05 09:19:44.640326.640326 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5dca38ac-be6a-4ea1-ac4f-8867847afd47
DEBUG 01-05 09:19:44.640701.640701 mlpmodule.py:564] gpu pad cost 0.004004478454589844 s
DEBUG 01-05 09:19:44.641809.641809 mlpmodule.py:582] gpu group einsum cost 0.0005660057067871094 s
DEBUG 01-05 09:19:44.644479.644479 mlpmodule.py:662]  experts func einsum cost 0.10141992568969727 s
DEBUG 01-05 09:19:44.644256.644256 mlpmodule.py:611] gpu experts func einsum cost 0.009086847305297852 s
DEBUG 01-05 09:19:44.644438.644438 cuda_h.py:19] end gpu_experts cost 0.00927877426147461 seconds
DEBUG 01-05 09:19:44.644863.644863 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:44.647136.647136 client.py:127] Model loaded
DEBUG 01-05 09:19:44.647252.647252 cuda_h.py:19] end sllm_worker_task cost 0.01744222640991211 seconds
DEBUG 01-05 09:19:44.648038.648038 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.003392457962036133 seconds
DEBUG 01-05 09:19:44.648368.648368 cuda_h.py:19] end layer_moe_generate_15 cost 0.11338186264038086 seconds
DEBUG 01-05 09:19:44.648607.648607 lmp.py:214] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 09:19:44.648231.648231 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 09:19:44.648688.648688 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.648062.648062 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.651656.651656 cuda_h.py:19] end self_attn cost 0.002452850341796875 seconds
DEBUG 01-05 09:19:44.651646.651646 cuda_h.py:19] end iln_self_attn_paln cost 0.0030629634857177734 seconds
DEBUG 01-05 09:19:44.651251.651251 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 09:19:44.651597.651597 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.652200.652200 cuda_h.py:19] end gate cost 0.0005843639373779297 seconds
DEBUG 01-05 09:19:44.652613.652613 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.652120.652120 lmp.py:361] 
DEBUG 01-05 09:19:44.652120.652120 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.652591.652591 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.652194.652194 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.652222.652222 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.652911.652911 lmp.py:365] 
DEBUG 01-05 09:19:44.652911.652911 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.652792.652792 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.652442.652442 lmp.py:372]   Expert 58 |     24 | CPU
DEBUG 01-05 09:19:44.652085.652085 lmp.py:372]   Expert 43 |     61 | CPU
DEBUG 01-05 09:19:44.652490.652490 lmp.py:372]   Expert 14 |     66 | CPU
DEBUG 01-05 09:19:44.652179.652179 lmp.py:372]   Expert 54 |     76 | CPU
DEBUG 01-05 09:19:44.652107.652107 lmp.py:372]   Expert 13 |     82 | CPU
DEBUG 01-05 09:19:44.652511.652511 lmp.py:372]   Expert 11 |     88 | CPU
DEBUG 01-05 09:19:44.652439.652439 lmp.py:372]   Expert 45 |     91 | CPU
DEBUG 01-05 09:19:44.652890.652890 lmp.py:372]   Expert 60 |     99 | CPU
DEBUG 01-05 09:19:44.652102.652102 lmp.py:372]   Expert 59 |    102 | CPU
DEBUG 01-05 09:19:44.653553.653553 lmp.py:372]   Expert 39 |    104 | CPU
DEBUG 01-05 09:19:44.653766.653766 lmp.py:372]   Expert 34 |    106 | CPU
DEBUG 01-05 09:19:44.653216.653216 lmp.py:372]   Expert 18 |    111 | CPU
DEBUG 01-05 09:19:44.653429.653429 lmp.py:372]   Expert 57 |    113 | CPU
DEBUG 01-05 09:19:44.653403.653403 lmp.py:372]   Expert  6 |    116 | CPU
DEBUG 01-05 09:19:44.653377.653377 lmp.py:372]   Expert 49 |    117 | CPU
DEBUG 01-05 09:19:44.653782.653782 lmp.py:372]   Expert 28 |    126 | CPU
DEBUG 01-05 09:19:44.653709.653709 lmp.py:372]   Expert 61 |    127 | CPU
DEBUG 01-05 09:19:44.653922.653922 lmp.py:372]   Expert 25 |    132 | CPU
DEBUG 01-05 09:19:44.653134.653134 lmp.py:372]   Expert 50 |    132 | CPU
DEBUG 01-05 09:19:44.653108.653108 lmp.py:372]   Expert 62 |    132 | CPU
DEBUG 01-05 09:19:44.653082.653082 lmp.py:372]   Expert 32 |    134 | CPU
DEBUG 01-05 09:19:44.653056.653056 lmp.py:372]   Expert 41 |    134 | CPU
DEBUG 01-05 09:19:44.653507.653507 lmp.py:372]   Expert  0 |    137 | CPU
DEBUG 01-05 09:19:44.653720.653720 lmp.py:372]   Expert 51 |    140 | CPU
DEBUG 01-05 09:19:44.653409.653409 lmp.py:372]   Expert 30 |    144 | CPU
DEBUG 01-05 09:19:44.653337.653337 lmp.py:372]   Expert 38 |    147 | CPU
DEBUG 01-05 09:19:44.653311.653311 lmp.py:372]   Expert 35 |    150 | CPU
DEBUG 01-05 09:19:44.653285.653285 lmp.py:372]   Expert 15 |    151 | CPU
DEBUG 01-05 09:19:44.653259.653259 lmp.py:372]   Expert 37 |    163 | CPU
DEBUG 01-05 09:19:44.653471.653471 lmp.py:372]   Expert 12 |    168 | CPU
DEBUG 01-05 09:19:44.653922.653922 lmp.py:372]   Expert 31 |    171 | CPU
DEBUG 01-05 09:19:44.653896.653896 lmp.py:372]   Expert 42 |    178 | CPU
DEBUG 01-05 09:19:44.653347.653347 lmp.py:372]   Expert 56 |    186 | GPU
DEBUG 01-05 09:19:44.653275.653275 lmp.py:372]   Expert 26 |    189 | GPU
DEBUG 01-05 09:19:44.653441.653441 lmp.py:372]   Expert 63 |    193 | GPU
DEBUG 01-05 09:19:44.653130.653130 lmp.py:372]   Expert 10 |    196 | GPU
DEBUG 01-05 09:19:44.653343.653343 lmp.py:372]   Expert 44 |    197 | GPU
DEBUG 01-05 09:19:44.653555.653555 lmp.py:372]   Expert 48 |    199 | GPU
DEBUG 01-05 09:19:44.653529.653529 lmp.py:372]   Expert 40 |    204 | GPU
DEBUG 01-05 09:19:44.653503.653503 lmp.py:372]   Expert  3 |    206 | GPU
DEBUG 01-05 09:19:44.653716.653716 lmp.py:372]   Expert 55 |    209 | GPU
DEBUG 01-05 09:19:44.653928.653928 lmp.py:372]   Expert 21 |    220 | GPU
DEBUG 01-05 09:19:44.653664.653664 lmp.py:372]   Expert 33 |    225 | GPU
DEBUG 01-05 09:19:44.653876.653876 lmp.py:372]   Expert 36 |    226 | GPU
DEBUG 01-05 09:19:44.653804.653804 lmp.py:372]   Expert 47 |    229 | GPU
DEBUG 01-05 09:19:44.653447.653447 lmp.py:372]   Expert  1 |    230 | GPU
DEBUG 01-05 09:19:44.653660.653660 lmp.py:372]   Expert 16 |    235 | GPU
DEBUG 01-05 09:19:44.653872.653872 lmp.py:372]   Expert  9 |    243 | GPU
DEBUG 01-05 09:19:44.653323.653323 lmp.py:372]   Expert 19 |    245 | GPU
DEBUG 01-05 09:19:44.653297.653297 lmp.py:372]   Expert  2 |    256 | GPU
DEBUG 01-05 09:19:44.653748.653748 lmp.py:372]   Expert 24 |    260 | GPU
DEBUG 01-05 09:19:44.653960.653960 lmp.py:372]   Expert 46 |    261 | GPU
DEBUG 01-05 09:19:44.653173.653173 lmp.py:372]   Expert 53 |    271 | GPU
DEBUG 01-05 09:19:44.653862.653862 lmp.py:372]   Expert 20 |    272 | GPU
DEBUG 01-05 09:19:44.653790.653790 lmp.py:372]   Expert  8 |    275 | GPU
DEBUG 01-05 09:19:44.653241.653241 lmp.py:372]   Expert  7 |    278 | GPU
DEBUG 01-05 09:19:44.653453.653453 lmp.py:372]   Expert 22 |    282 | GPU
DEBUG 01-05 09:19:44.653666.653666 lmp.py:372]   Expert 29 |    313 | GPU
DEBUG 01-05 09:19:44.653878.653878 lmp.py:372]   Expert  4 |    340 | GPU
DEBUG 01-05 09:19:44.653090.653090 lmp.py:372]   Expert 17 |    358 | GPU
DEBUG 01-05 09:19:44.653303.653303 lmp.py:372]   Expert 23 |    369 | GPU
DEBUG 01-05 09:19:44.653754.653754 lmp.py:372]   Expert 27 |    428 | GPU
DEBUG 01-05 09:19:44.653443.653443 lmp.py:372]   Expert 52 |    430 | GPU
DEBUG 01-05 09:19:44.653894.653894 lmp.py:372]   Expert  5 |    441 | GPU
DEBUG 01-05 09:19:44.653583.653583 lmp.py:373] 
DEBUG 01-05 09:19:44.653583.653583 lmp.py:373]   CPU total tokens: 3822 (31.1%)
DEBUG 01-05 09:19:44.653749.653749 lmp.py:374]   GPU total tokens: 8466 (68.9%)
DEBUG 01-05 09:19:44.653684.653684 cuda_h.py:19] end experts_map_get cost 0.0014984607696533203 seconds
DEBUG 01-05 09:19:44.653088.653088 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.654295.654295 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.654247.654247 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.654885.654885 cuda_h.py:19] end allocate_cuda_memory cost 0.00022649765014648438 seconds
DEBUG 01-05 09:19:44.654635.654635 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.654199.654199 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.654916.654916 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.654850.654850 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 86fba387-5f55-4a4f-9660-2016fde338f6
DEBUG 01-05 09:19:44.654546.654546 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.655427.655427 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 86fba387-5f55-4a4f-9660-2016fde338f6
DEBUG 01-05 09:19:44.655775.655775 cuda_h.py:19] end load_into_gpu_async cost 0.0011522769927978516 seconds
DEBUG 01-05 09:19:44.655120.655120 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.656336.656336 cuda_h.py:19] end restore_tensors2 cost 0.0004684925079345703 seconds
DEBUG 01-05 09:19:44.656114.656114 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022602081298828125 seconds
DEBUG 01-05 09:19:44.659358.659358 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005856513977050781 seconds
DEBUG 01-05 09:19:44.659731.659731 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.660390.660390 lmp.py:419] 
DEBUG 01-05 09:19:44.660390.660390 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.660823.660823 cuda_h.py:19] end cpu_experts_submit cost 0.00013327598571777344 seconds
DEBUG 01-05 09:19:44.660771.660771 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.671481.671481 mlpmodule.py:704] group tensors cost 0.011172294616699219 s
DEBUG 01-05 09:19:44.673189.673189 mlpmodule.py:742] pad cost 0.001569986343383789 s
DEBUG 01-05 09:19:44.673729.673729 mlpmodule.py:748] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-05 09:19:44.673315.673315 mlpmodule.py:753] move to cpu cost 4.601478576660156e-05 s
DEBUG 01-05 09:19:44.686597.686597 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.686735.686735 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.686348.686348 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 09:19:44.686901.686901 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.705759.705759 mlpmodule.py:793] group einsum cost 0.0317835807800293 s
DEBUG 01-05 09:19:44.706690.706690 mlpmodule.py:801] cpy2cputensor cost 0.0009052753448486328 s
DEBUG 01-05 09:19:44.746552.746552 cuda_h.py:19] end wait_cetm_experts cost 0.08676385879516602 seconds
DEBUG 01-05 09:19:44.747205.747205 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.747506.747506 cuda_h.py:19] end gpu_sexperts cost 0.0004611015319824219 seconds
DEBUG 01-05 09:19:44.747442.747442 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:19:44.747450.747450 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:19:44.747260.747260 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:19:44.747714.747714 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.747657.747657 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.0002231597900390625 seconds
DEBUG 01-05 09:19:44.748742.748742 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.748865.748865 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.748490.748490 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 86fba387-5f55-4a4f-9660-2016fde338f6
DEBUG 01-05 09:19:44.748440.748440 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.752269.752269 cuda_h.py:19] end allocate_cuda_memory cost 0.003604412078857422 seconds
DEBUG 01-05 09:19:44.752901.752901 cuda_h.py:10] start load_into_gpu_async
INFO 01-05 09:19:44.752171.752171 client.py:127] Model loaded
DEBUG 01-05 09:19:44.752520.752520 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.752398.752398 cuda_h.py:19] end wait_experts cost 0.004568576812744141 seconds
DEBUG 01-05 09:19:44.753772.753772 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.753104.753104 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:44.753436.753436 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.753552.753552 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 971618d2-d878-426c-9812-cee0d4616724
DEBUG 01-05 09:19:44.754104.754104 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.754684.754684 mlpmodule.py:531] gpu group tensors cost 0.0010037422180175781 s
INFO 01-05 09:19:44.755724.755724 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 971618d2-d878-426c-9812-cee0d4616724
DEBUG 01-05 09:19:44.755385.755385 cuda_h.py:19] end load_into_gpu_async cost 0.0031027793884277344 seconds
DEBUG 01-05 09:19:44.756880.756880 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.756808.756808 cuda_h.py:19] end restore_tensors2 cost 0.0002617835998535156 seconds
DEBUG 01-05 09:19:44.756011.756011 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0084075927734375 seconds
INFO 01-05 09:19:44.758158.758158 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 971618d2-d878-426c-9812-cee0d4616724
DEBUG 01-05 09:19:44.759348.759348 mlpmodule.py:564] gpu pad cost 0.004776954650878906 s
DEBUG 01-05 09:19:44.759902.759902 mlpmodule.py:582] gpu group einsum cost 0.00044918060302734375 s
DEBUG 01-05 09:19:44.761221.761221 mlpmodule.py:662]  experts func einsum cost 0.10112833976745605 s
INFO 01-05 09:19:44.762392.762392 client.py:127] Model loaded
DEBUG 01-05 09:19:44.763640.763640 cuda_h.py:19] end sllm_worker_task cost 0.014965295791625977 seconds
DEBUG 01-05 09:19:44.763345.763345 mlpmodule.py:611] gpu experts func einsum cost 0.010060548782348633 s
DEBUG 01-05 09:19:44.763020.763020 cuda_h.py:19] end gpu_experts cost 0.010332584381103516 seconds
DEBUG 01-05 09:19:44.763637.763637 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:44.763460.763460 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7642974853515625e-05 seconds
DEBUG 01-05 09:19:44.763113.763113 cuda_h.py:19] end layer_moe_generate_16 cost 0.11194419860839844 seconds
DEBUG 01-05 09:19:44.763086.763086 lmp.py:214] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 09:19:44.763895.763895 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 09:19:44.763353.763353 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.764243.764243 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.766154.766154 cuda_h.py:19] end self_attn cost 0.002441883087158203 seconds
DEBUG 01-05 09:19:44.766767.766767 cuda_h.py:19] end iln_self_attn_paln cost 0.0030488967895507812 seconds
DEBUG 01-05 09:19:44.767087.767087 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 09:19:44.767281.767281 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.767069.767069 cuda_h.py:19] end gate cost 0.0005803108215332031 seconds
DEBUG 01-05 09:19:44.767422.767422 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.768929.768929 lmp.py:361] 
DEBUG 01-05 09:19:44.768929.768929 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.768446.768446 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.768812.768812 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.768839.768839 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.768005.768005 lmp.py:365] 
DEBUG 01-05 09:19:44.768005.768005 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.768409.768409 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.768536.768536 lmp.py:372]   Expert 39 |     47 | CPU
DEBUG 01-05 09:19:44.768656.768656 lmp.py:372]   Expert 28 |     52 | CPU
DEBUG 01-05 09:19:44.768107.768107 lmp.py:372]   Expert 14 |     62 | CPU
DEBUG 01-05 09:19:44.768226.768226 lmp.py:372]   Expert 36 |     67 | CPU
DEBUG 01-05 09:19:44.768631.768631 lmp.py:372]   Expert 47 |     73 | CPU
DEBUG 01-05 09:19:44.768320.768320 lmp.py:372]   Expert  1 |     77 | CPU
DEBUG 01-05 09:19:44.768010.768010 lmp.py:372]   Expert  7 |     77 | CPU
DEBUG 01-05 09:19:44.768461.768461 lmp.py:372]   Expert 27 |     80 | CPU
DEBUG 01-05 09:19:44.768673.768673 lmp.py:372]   Expert 40 |     91 | CPU
DEBUG 01-05 09:19:44.768885.768885 lmp.py:372]   Expert 52 |     94 | CPU
DEBUG 01-05 09:19:44.768336.768336 lmp.py:372]   Expert  8 |     95 | CPU
DEBUG 01-05 09:19:44.768463.768463 lmp.py:372]   Expert 25 |    102 | CPU
DEBUG 01-05 09:19:44.768629.768629 lmp.py:372]   Expert 31 |    120 | CPU
DEBUG 01-05 09:19:44.768842.768842 lmp.py:372]   Expert  3 |    123 | CPU
DEBUG 01-05 09:19:44.768769.768769 lmp.py:372]   Expert 46 |    128 | CPU
DEBUG 01-05 09:19:44.768220.768220 lmp.py:372]   Expert 54 |    128 | CPU
DEBUG 01-05 09:19:44.768671.768671 lmp.py:372]   Expert 30 |    138 | CPU
DEBUG 01-05 09:19:44.768883.768883 lmp.py:372]   Expert 60 |    139 | CPU
DEBUG 01-05 09:19:44.768096.768096 lmp.py:372]   Expert 50 |    142 | CPU
DEBUG 01-05 09:19:44.768547.768547 lmp.py:372]   Expert 24 |    145 | CPU
DEBUG 01-05 09:19:44.768521.768521 lmp.py:372]   Expert 61 |    147 | CPU
DEBUG 01-05 09:19:44.768495.768495 lmp.py:372]   Expert 63 |    150 | CPU
DEBUG 01-05 09:19:44.768423.768423 lmp.py:372]   Expert 58 |    153 | CPU
DEBUG 01-05 09:19:44.768350.768350 lmp.py:372]   Expert  6 |    154 | CPU
DEBUG 01-05 09:19:44.768324.768324 lmp.py:372]   Expert 16 |    154 | CPU
DEBUG 01-05 09:19:44.768537.768537 lmp.py:372]   Expert 59 |    157 | CPU
DEBUG 01-05 09:19:44.768749.768749 lmp.py:372]   Expert  2 |    164 | CPU
DEBUG 01-05 09:19:44.768962.768962 lmp.py:372]   Expert 56 |    164 | CPU
DEBUG 01-05 09:19:44.768174.768174 lmp.py:372]   Expert 53 |    169 | CPU
DEBUG 01-05 09:19:44.768625.768625 lmp.py:372]   Expert 11 |    172 | CPU
DEBUG 01-05 09:19:44.768076.768076 lmp.py:372]   Expert 34 |    174 | CPU
DEBUG 01-05 09:19:44.768004.768004 lmp.py:372]   Expert 49 |    176 | CPU
DEBUG 01-05 09:19:44.768693.768693 lmp.py:372]   Expert 15 |    184 | GPU
DEBUG 01-05 09:19:44.768144.768144 lmp.py:372]   Expert 18 |    184 | GPU
DEBUG 01-05 09:19:44.768595.768595 lmp.py:372]   Expert 10 |    186 | GPU
DEBUG 01-05 09:19:44.768569.768569 lmp.py:372]   Expert 29 |    190 | GPU
DEBUG 01-05 09:19:44.768781.768781 lmp.py:372]   Expert 33 |    194 | GPU
DEBUG 01-05 09:19:44.768755.768755 lmp.py:372]   Expert 43 |    195 | GPU
DEBUG 01-05 09:19:44.768445.768445 lmp.py:372]   Expert 37 |    199 | GPU
DEBUG 01-05 09:19:44.768372.768372 lmp.py:372]   Expert 32 |    203 | GPU
DEBUG 01-05 09:19:44.768585.768585 lmp.py:372]   Expert 21 |    211 | GPU
DEBUG 01-05 09:19:44.768320.768320 lmp.py:372]   Expert 42 |    227 | GPU
DEBUG 01-05 09:19:44.768533.768533 lmp.py:372]   Expert 44 |    228 | GPU
DEBUG 01-05 09:19:44.768745.768745 lmp.py:372]   Expert 57 |    229 | GPU
DEBUG 01-05 09:19:44.768719.768719 lmp.py:372]   Expert 20 |    230 | GPU
DEBUG 01-05 09:19:44.768932.768932 lmp.py:372]   Expert 13 |    235 | GPU
DEBUG 01-05 09:19:44.768144.768144 lmp.py:372]   Expert  9 |    240 | GPU
DEBUG 01-05 09:19:44.768834.768834 lmp.py:372]   Expert  0 |    241 | GPU
DEBUG 01-05 09:19:44.768523.768523 lmp.py:372]   Expert 35 |    246 | GPU
DEBUG 01-05 09:19:44.769259.769259 lmp.py:372]   Expert 51 |    247 | GPU
DEBUG 01-05 09:19:44.769233.769233 lmp.py:372]   Expert  5 |    271 | GPU
DEBUG 01-05 09:19:44.769445.769445 lmp.py:372]   Expert 22 |    271 | GPU
DEBUG 01-05 09:19:44.769419.769419 lmp.py:372]   Expert 38 |    279 | GPU
DEBUG 01-05 09:19:44.769155.769155 lmp.py:372]   Expert 23 |    288 | GPU
DEBUG 01-05 09:19:44.769367.769367 lmp.py:372]   Expert 19 |    292 | GPU
DEBUG 01-05 09:19:44.769103.769103 lmp.py:372]   Expert 62 |    303 | GPU
DEBUG 01-05 09:19:44.769077.769077 lmp.py:372]   Expert  4 |    306 | GPU
DEBUG 01-05 09:19:44.769766.769766 lmp.py:372]   Expert 48 |    307 | GPU
DEBUG 01-05 09:19:44.769979.769979 lmp.py:372]   Expert 12 |    308 | GPU
DEBUG 01-05 09:19:44.769953.769953 lmp.py:372]   Expert 45 |    312 | GPU
DEBUG 01-05 09:19:44.769927.769927 lmp.py:372]   Expert 26 |    331 | GPU
DEBUG 01-05 09:19:44.769662.769662 lmp.py:372]   Expert 41 |    359 | GPU
DEBUG 01-05 09:19:44.769636.769636 lmp.py:372]   Expert 55 |    391 | GPU
DEBUG 01-05 09:19:44.769849.769849 lmp.py:372]   Expert 17 |    487 | GPU
DEBUG 01-05 09:19:44.769446.769446 lmp.py:373] 
DEBUG 01-05 09:19:44.769446.769446 lmp.py:373]   CPU total tokens: 3914 (31.9%)
DEBUG 01-05 09:19:44.769850.769850 lmp.py:374]   GPU total tokens: 8374 (68.1%)
DEBUG 01-05 09:19:44.769546.769546 cuda_h.py:19] end experts_map_get cost 0.0015034675598144531 seconds
DEBUG 01-05 09:19:44.769712.769712 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.769111.769111 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.769388.769388 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.769000.769000 cuda_h.py:19] end allocate_cuda_memory cost 0.00023937225341796875 seconds
DEBUG 01-05 09:19:44.769181.769181 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.769507.769507 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.769177.769177 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.769304.769304 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f6b9b3ba-65d2-473b-9701-e2b436745571
DEBUG 01-05 09:19:44.770258.770258 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.771081.771081 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f6b9b3ba-65d2-473b-9701-e2b436745571
DEBUG 01-05 09:19:44.771487.771487 cuda_h.py:19] end load_into_gpu_async cost 0.0011775493621826172 seconds
DEBUG 01-05 09:19:44.771997.771997 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.771037.771037 cuda_h.py:19] end restore_tensors2 cost 0.0003540515899658203 seconds
DEBUG 01-05 09:19:44.771773.771773 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021507740020751953 seconds
DEBUG 01-05 09:19:44.774917.774917 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004899263381958008 seconds
DEBUG 01-05 09:19:44.774945.774945 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.774670.774670 lmp.py:419] 
DEBUG 01-05 09:19:44.774670.774670 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.774844.774844 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-05 09:19:44.774732.774732 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.785153.785153 mlpmodule.py:704] group tensors cost 0.010845184326171875 s
DEBUG 01-05 09:19:44.787871.787871 mlpmodule.py:742] pad cost 0.001542806625366211 s
DEBUG 01-05 09:19:44.787351.787351 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-05 09:19:44.787082.787082 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-05 09:19:44.799950.799950 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.799618.799618 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.799376.799376 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 09:19:44.799374.799374 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.821590.821590 mlpmodule.py:793] group einsum cost 0.03309345245361328 s
DEBUG 01-05 09:19:44.822294.822294 mlpmodule.py:801] cpy2cputensor cost 0.0008463859558105469 s
DEBUG 01-05 09:19:44.862746.862746 cuda_h.py:19] end wait_cetm_experts cost 0.08778524398803711 seconds
DEBUG 01-05 09:19:44.862437.862437 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.862693.862693 cuda_h.py:19] end gpu_sexperts cost 0.0004642009735107422 seconds
DEBUG 01-05 09:19:44.862344.862344 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:19:44.862544.862544 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:19:44.863791.863791 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 4.076957702636719e-05 seconds
DEBUG 01-05 09:19:44.863397.863397 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.863725.863725 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.00023937225341796875 seconds
DEBUG 01-05 09:19:44.863472.863472 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.863674.863674 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.863848.863848 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f6b9b3ba-65d2-473b-9701-e2b436745571
DEBUG 01-05 09:19:44.863018.863018 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.867005.867005 cuda_h.py:19] end allocate_cuda_memory cost 0.003444671630859375 seconds
DEBUG 01-05 09:19:44.867623.867623 cuda_h.py:10] start load_into_gpu_async
INFO 01-05 09:19:44.867900.867900 client.py:127] Model loaded
DEBUG 01-05 09:19:44.867778.867778 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.868034.868034 cuda_h.py:19] end wait_experts cost 0.004352092742919922 seconds
DEBUG 01-05 09:19:44.868501.868501 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.868071.868071 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:44.868152.868152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.869964.869964 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29ba5ea9-a50e-416c-9568-9e1e8f425207
DEBUG 01-05 09:19:44.869748.869748 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.869269.869269 mlpmodule.py:531] gpu group tensors cost 0.001073598861694336 s
INFO 01-05 09:19:44.870625.870625 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29ba5ea9-a50e-416c-9568-9e1e8f425207
DEBUG 01-05 09:19:44.870088.870088 cuda_h.py:19] end load_into_gpu_async cost 0.002544879913330078 seconds
DEBUG 01-05 09:19:44.870074.870074 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.871861.871861 cuda_h.py:19] end restore_tensors2 cost 0.0002162456512451172 seconds
DEBUG 01-05 09:19:44.871456.871456 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007602691650390625 seconds
INFO 01-05 09:19:44.873775.873775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29ba5ea9-a50e-416c-9568-9e1e8f425207
DEBUG 01-05 09:19:44.874356.874356 mlpmodule.py:564] gpu pad cost 0.004571676254272461 s
DEBUG 01-05 09:19:44.874205.874205 mlpmodule.py:582] gpu group einsum cost 0.0005495548248291016 s
DEBUG 01-05 09:19:44.876649.876649 mlpmodule.py:662]  experts func einsum cost 0.10202932357788086 s
DEBUG 01-05 09:19:44.878408.878408 mlpmodule.py:611] gpu experts func einsum cost 0.009781122207641602 s
DEBUG 01-05 09:19:44.878366.878366 cuda_h.py:19] end gpu_experts cost 0.009980916976928711 seconds
DEBUG 01-05 09:19:44.878837.878837 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:44.880449.880449 client.py:127] Model loaded
DEBUG 01-05 09:19:44.880871.880871 cuda_h.py:19] end sllm_worker_task cost 0.017053604125976562 seconds
DEBUG 01-05 09:19:44.880960.880960 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002271413803100586 seconds
DEBUG 01-05 09:19:44.880740.880740 cuda_h.py:19] end layer_moe_generate_17 cost 0.11361575126647949 seconds
DEBUG 01-05 09:19:44.880628.880628 lmp.py:214] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 09:19:44.880914.880914 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 09:19:44.880371.880371 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.881122.881122 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.883888.883888 cuda_h.py:19] end self_attn cost 0.0024385452270507812 seconds
DEBUG 01-05 09:19:44.884474.884474 cuda_h.py:19] end iln_self_attn_paln cost 0.0030295848846435547 seconds
DEBUG 01-05 09:19:44.884602.884602 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 09:19:44.884795.884795 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.884591.884591 cuda_h.py:19] end gate cost 0.0005879402160644531 seconds
DEBUG 01-05 09:19:44.884851.884851 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.885596.885596 lmp.py:361] 
DEBUG 01-05 09:19:44.885596.885596 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.885113.885113 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.885955.885955 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.885459.885459 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.885625.885625 lmp.py:365] 
DEBUG 01-05 09:19:44.885625.885625 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.885553.885553 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.885680.885680 lmp.py:372]   Expert 35 |     49 | CPU
DEBUG 01-05 09:19:44.885800.885800 lmp.py:372]   Expert  0 |     56 | CPU
DEBUG 01-05 09:19:44.885489.885489 lmp.py:372]   Expert 53 |     60 | CPU
DEBUG 01-05 09:19:44.885417.885417 lmp.py:372]   Expert 19 |     62 | CPU
DEBUG 01-05 09:19:44.885821.885821 lmp.py:372]   Expert  3 |     65 | CPU
DEBUG 01-05 09:19:44.885464.885464 lmp.py:372]   Expert 54 |     65 | CPU
DEBUG 01-05 09:19:44.885153.885153 lmp.py:372]   Expert 58 |     65 | CPU
DEBUG 01-05 09:19:44.885843.885843 lmp.py:372]   Expert 12 |     78 | CPU
DEBUG 01-05 09:19:44.885532.885532 lmp.py:372]   Expert 40 |     81 | CPU
DEBUG 01-05 09:19:44.885506.885506 lmp.py:372]   Expert 20 |     84 | CPU
DEBUG 01-05 09:19:44.885718.885718 lmp.py:372]   Expert 34 |     88 | CPU
DEBUG 01-05 09:19:44.885931.885931 lmp.py:372]   Expert 37 |     96 | CPU
DEBUG 01-05 09:19:44.885905.885905 lmp.py:372]   Expert 60 |     97 | CPU
DEBUG 01-05 09:19:44.885833.885833 lmp.py:372]   Expert  6 |     99 | CPU
DEBUG 01-05 09:19:44.885760.885760 lmp.py:372]   Expert 41 |    103 | CPU
DEBUG 01-05 09:19:44.885450.885450 lmp.py:372]   Expert 63 |    103 | CPU
DEBUG 01-05 09:19:44.885901.885901 lmp.py:372]   Expert 43 |    104 | CPU
DEBUG 01-05 09:19:44.885875.885875 lmp.py:372]   Expert 46 |    109 | CPU
DEBUG 01-05 09:19:44.885087.885087 lmp.py:372]   Expert 44 |    114 | CPU
DEBUG 01-05 09:19:44.885538.885538 lmp.py:372]   Expert 48 |    114 | CPU
DEBUG 01-05 09:19:44.885989.885989 lmp.py:372]   Expert  8 |    116 | CPU
DEBUG 01-05 09:19:44.885440.885440 lmp.py:372]   Expert 32 |    118 | CPU
DEBUG 01-05 09:19:44.885367.885367 lmp.py:372]   Expert 30 |    127 | CPU
DEBUG 01-05 09:19:44.885010.885010 lmp.py:372]   Expert 13 |    134 | CPU
DEBUG 01-05 09:19:44.885938.885938 lmp.py:372]   Expert 33 |    134 | CPU
DEBUG 01-05 09:19:44.885151.885151 lmp.py:372]   Expert 29 |    136 | CPU
DEBUG 01-05 09:19:44.885363.885363 lmp.py:372]   Expert 17 |    139 | CPU
DEBUG 01-05 09:19:44.885576.885576 lmp.py:372]   Expert  5 |    142 | CPU
DEBUG 01-05 09:19:44.885550.885550 lmp.py:372]   Expert  4 |    147 | CPU
DEBUG 01-05 09:19:44.885285.885285 lmp.py:372]   Expert 45 |    149 | CPU
DEBUG 01-05 09:19:44.885259.885259 lmp.py:372]   Expert 55 |    151 | CPU
DEBUG 01-05 09:19:44.885233.885233 lmp.py:372]   Expert 25 |    158 | CPU
DEBUG 01-05 09:19:44.885161.885161 lmp.py:372]   Expert 11 |    160 | GPU
DEBUG 01-05 09:19:44.885612.885612 lmp.py:372]   Expert 27 |    168 | GPU
DEBUG 01-05 09:19:44.885348.885348 lmp.py:372]   Expert 39 |    171 | GPU
DEBUG 01-05 09:19:44.885560.885560 lmp.py:372]   Expert 18 |    175 | GPU
DEBUG 01-05 09:19:44.885534.885534 lmp.py:372]   Expert 42 |    184 | GPU
DEBUG 01-05 09:19:44.885508.885508 lmp.py:372]   Expert 56 |    187 | GPU
DEBUG 01-05 09:19:44.885674.885674 lmp.py:372]   Expert 22 |    194 | GPU
DEBUG 01-05 09:19:44.885364.885364 lmp.py:372]   Expert 52 |    195 | GPU
DEBUG 01-05 09:19:44.885576.885576 lmp.py:372]   Expert 24 |    206 | GPU
DEBUG 01-05 09:19:44.885550.885550 lmp.py:372]   Expert 50 |    208 | GPU
DEBUG 01-05 09:19:44.885763.885763 lmp.py:372]   Expert  9 |    212 | GPU
DEBUG 01-05 09:19:44.885975.885975 lmp.py:372]   Expert 51 |    217 | GPU
DEBUG 01-05 09:19:44.885949.885949 lmp.py:372]   Expert  7 |    220 | GPU
DEBUG 01-05 09:19:44.885923.885923 lmp.py:372]   Expert  1 |    222 | GPU
DEBUG 01-05 09:19:44.885089.885089 lmp.py:372]   Expert 59 |    224 | GPU
DEBUG 01-05 09:19:44.886732.886732 lmp.py:372]   Expert 61 |    237 | GPU
DEBUG 01-05 09:19:44.886421.886421 lmp.py:372]   Expert 16 |    254 | GPU
DEBUG 01-05 09:19:44.886157.886157 lmp.py:372]   Expert 31 |    267 | GPU
DEBUG 01-05 09:19:44.886608.886608 lmp.py:372]   Expert 28 |    273 | GPU
DEBUG 01-05 09:19:44.886582.886582 lmp.py:372]   Expert 57 |    276 | GPU
DEBUG 01-05 09:19:44.886556.886556 lmp.py:372]   Expert 21 |    285 | GPU
DEBUG 01-05 09:19:44.886769.886769 lmp.py:372]   Expert 47 |    287 | GPU
DEBUG 01-05 09:19:44.886266.886266 lmp.py:372]   Expert 38 |    305 | GPU
DEBUG 01-05 09:19:44.886432.886432 lmp.py:372]   Expert 14 |    313 | GPU
DEBUG 01-05 09:19:44.886360.886360 lmp.py:372]   Expert 10 |    341 | GPU
DEBUG 01-05 09:19:44.886334.886334 lmp.py:372]   Expert 15 |    349 | GPU
DEBUG 01-05 09:19:44.886069.886069 lmp.py:372]   Expert  2 |    364 | GPU
DEBUG 01-05 09:19:44.886043.886043 lmp.py:372]   Expert 49 |    365 | GPU
DEBUG 01-05 09:19:44.886256.886256 lmp.py:372]   Expert 36 |    403 | GPU
DEBUG 01-05 09:19:44.886991.886991 lmp.py:372]   Expert 26 |    455 | GPU
DEBUG 01-05 09:19:44.886965.886965 lmp.py:372]   Expert 23 |    518 | GPU
DEBUG 01-05 09:19:44.886701.886701 lmp.py:372]   Expert 62 |    710 | GPU
DEBUG 01-05 09:19:44.886152.886152 lmp.py:373] 
DEBUG 01-05 09:19:44.886152.886152 lmp.py:373]   CPU total tokens: 3343 (27.2%)
DEBUG 01-05 09:19:44.886080.886080 lmp.py:374]   GPU total tokens: 8945 (72.8%)
DEBUG 01-05 09:19:44.886014.886014 cuda_h.py:19] end experts_map_get cost 0.0014967918395996094 seconds
DEBUG 01-05 09:19:44.886657.886657 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.886864.886864 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.886869.886869 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.886421.886421 cuda_h.py:19] end allocate_cuda_memory cost 0.00023245811462402344 seconds
DEBUG 01-05 09:19:44.886887.886887 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.886497.886497 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.886452.886452 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.886625.886625 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e51f7ffd-a046-4eea-abf8-5ae5da7c811f
DEBUG 01-05 09:19:44.887843.887843 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.888794.888794 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e51f7ffd-a046-4eea-abf8-5ae5da7c811f
DEBUG 01-05 09:19:44.888769.888769 cuda_h.py:19] end load_into_gpu_async cost 0.0012178421020507812 seconds
DEBUG 01-05 09:19:44.888042.888042 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.888228.888228 cuda_h.py:19] end restore_tensors2 cost 0.00039076805114746094 seconds
DEBUG 01-05 09:19:44.888064.888064 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002197265625 seconds
DEBUG 01-05 09:19:44.891531.891531 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004901409149169922 seconds
DEBUG 01-05 09:19:44.891983.891983 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:44.891946.891946 lmp.py:419] 
DEBUG 01-05 09:19:44.891946.891946 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:44.891504.891504 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-05 09:19:44.891108.891108 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:44.897790.897790 mlpmodule.py:704] group tensors cost 0.0058019161224365234 s
DEBUG 01-05 09:19:44.900883.900883 mlpmodule.py:742] pad cost 0.002031087875366211 s
DEBUG 01-05 09:19:44.900490.900490 mlpmodule.py:748] create cpu tensor cost 4.935264587402344e-05 s
DEBUG 01-05 09:19:44.900235.900235 mlpmodule.py:753] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-05 09:19:44.913957.913957 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:44.913672.913672 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:44.913761.913761 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 09:19:44.913898.913898 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:44.930716.930716 mlpmodule.py:793] group einsum cost 0.030113935470581055 s
DEBUG 01-05 09:19:44.931763.931763 mlpmodule.py:801] cpy2cputensor cost 0.0008194446563720703 s
DEBUG 01-05 09:19:44.973244.973244 cuda_h.py:19] end wait_cetm_experts cost 0.08197617530822754 seconds
DEBUG 01-05 09:19:44.973228.973228 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:44.974529.974529 cuda_h.py:19] end gpu_sexperts cost 0.0004630088806152344 seconds
DEBUG 01-05 09:19:44.974227.974227 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:19:44.974473.974473 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:19:44.974376.974376 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:19:44.974054.974054 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:44.974653.974653 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.00020241737365722656 seconds
DEBUG 01-05 09:19:44.974838.974838 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.974085.974085 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:44.974829.974829 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e51f7ffd-a046-4eea-abf8-5ae5da7c811f
DEBUG 01-05 09:19:44.974283.974283 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.978821.978821 cuda_h.py:19] end allocate_cuda_memory cost 0.003465414047241211 seconds
DEBUG 01-05 09:19:44.978055.978055 cuda_h.py:10] start load_into_gpu_async
INFO 01-05 09:19:44.979093.979093 client.py:127] Model loaded
DEBUG 01-05 09:19:44.979972.979972 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.979287.979287 cuda_h.py:19] end wait_experts cost 0.004377126693725586 seconds
DEBUG 01-05 09:19:44.979270.979270 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:44.979364.979364 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:44.980848.980848 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.980223.980223 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40d2d2dd-cc1a-4873-9911-7f61761e2e04
DEBUG 01-05 09:19:44.980240.980240 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:44.980861.980861 mlpmodule.py:531] gpu group tensors cost 0.0010840892791748047 s
INFO 01-05 09:19:44.981545.981545 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40d2d2dd-cc1a-4873-9911-7f61761e2e04
DEBUG 01-05 09:19:44.981548.981548 cuda_h.py:19] end load_into_gpu_async cost 0.002415180206298828 seconds
DEBUG 01-05 09:19:44.981311.981311 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.981521.981521 cuda_h.py:19] end restore_tensors2 cost 8.559226989746094e-05 seconds
DEBUG 01-05 09:19:44.981760.981760 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0069849491119384766 seconds
INFO 01-05 09:19:44.982272.982272 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40d2d2dd-cc1a-4873-9911-7f61761e2e04
DEBUG 01-05 09:19:44.983567.983567 mlpmodule.py:564] gpu pad cost 0.00267791748046875 s
DEBUG 01-05 09:19:44.984409.984409 mlpmodule.py:582] gpu group einsum cost 0.0005359649658203125 s
DEBUG 01-05 09:19:44.987982.987982 mlpmodule.py:662]  experts func einsum cost 0.09581518173217773 s
DEBUG 01-05 09:19:44.987147.987147 mlpmodule.py:611] gpu experts func einsum cost 0.008250951766967773 s
DEBUG 01-05 09:19:44.987112.987112 cuda_h.py:19] end gpu_experts cost 0.008488655090332031 seconds
DEBUG 01-05 09:19:44.987252.987252 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:44.990439.990439 client.py:127] Model loaded
DEBUG 01-05 09:19:44.990381.990381 cuda_h.py:19] end sllm_worker_task cost 0.016259431838989258 seconds
DEBUG 01-05 09:19:44.990648.990648 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002894878387451172 seconds
DEBUG 01-05 09:19:44.991898.991898 cuda_h.py:19] end layer_moe_generate_18 cost 0.10692763328552246 seconds
DEBUG 01-05 09:19:44.991203.991203 lmp.py:214] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 09:19:44.991535.991535 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 09:19:44.991277.991277 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:44.991975.991975 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:44.994106.994106 cuda_h.py:19] end self_attn cost 0.0024640560150146484 seconds
DEBUG 01-05 09:19:44.994930.994930 cuda_h.py:19] end iln_self_attn_paln cost 0.003049612045288086 seconds
DEBUG 01-05 09:19:44.994793.994793 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 09:19:44.994272.994272 cuda_h.py:10] start gate
DEBUG 01-05 09:19:44.995769.995769 cuda_h.py:19] end gate cost 0.0005786418914794922 seconds
DEBUG 01-05 09:19:44.995837.995837 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:44.995953.995953 lmp.py:361] 
DEBUG 01-05 09:19:44.995953.995953 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:44.995232.995232 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:44.995358.995358 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:44.995147.995147 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:44.995029.995029 lmp.py:365] 
DEBUG 01-05 09:19:44.995029.995029 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:44.995672.995672 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:44.995560.995560 lmp.py:372]   Expert 60 |     54 | CPU
DEBUG 01-05 09:19:44.995441.995441 lmp.py:372]   Expert 56 |     58 | CPU
DEBUG 01-05 09:19:44.995369.995369 lmp.py:372]   Expert 12 |     71 | CPU
DEBUG 01-05 09:19:44.995535.995535 lmp.py:372]   Expert  5 |     72 | CPU
DEBUG 01-05 09:19:44.995224.995224 lmp.py:372]   Expert 59 |     76 | CPU
DEBUG 01-05 09:19:44.995629.995629 lmp.py:372]   Expert 55 |     78 | CPU
DEBUG 01-05 09:19:44.995318.995318 lmp.py:372]   Expert  6 |     86 | CPU
DEBUG 01-05 09:19:44.995769.995769 lmp.py:372]   Expert 44 |     86 | CPU
DEBUG 01-05 09:19:44.995981.995981 lmp.py:372]   Expert 48 |     86 | CPU
DEBUG 01-05 09:19:44.995432.995432 lmp.py:372]   Expert 18 |     94 | CPU
DEBUG 01-05 09:19:44.995645.995645 lmp.py:372]   Expert 30 |     96 | CPU
DEBUG 01-05 09:19:44.995857.995857 lmp.py:372]   Expert 52 |     96 | CPU
DEBUG 01-05 09:19:44.995308.995308 lmp.py:372]   Expert 42 |    102 | CPU
DEBUG 01-05 09:19:44.995713.995713 lmp.py:372]   Expert 23 |    107 | CPU
DEBUG 01-05 09:19:44.995117.995117 lmp.py:372]   Expert 33 |    110 | CPU
DEBUG 01-05 09:19:44.995807.995807 lmp.py:372]   Expert 27 |    118 | CPU
DEBUG 01-05 09:19:44.995019.995019 lmp.py:372]   Expert 24 |    127 | CPU
DEBUG 01-05 09:19:44.995470.995470 lmp.py:372]   Expert 32 |    134 | CPU
DEBUG 01-05 09:19:44.995682.995682 lmp.py:372]   Expert 34 |    135 | CPU
DEBUG 01-05 09:19:44.995895.995895 lmp.py:372]   Expert 62 |    135 | CPU
DEBUG 01-05 09:19:44.995584.995584 lmp.py:372]   Expert 54 |    139 | CPU
DEBUG 01-05 09:19:44.995042.995042 lmp.py:372]   Expert 16 |    143 | CPU
DEBUG 01-05 09:19:44.995254.995254 lmp.py:372]   Expert 57 |    143 | CPU
DEBUG 01-05 09:19:44.995467.995467 lmp.py:372]   Expert 58 |    148 | CPU
DEBUG 01-05 09:19:44.995918.995918 lmp.py:372]   Expert 15 |    151 | CPU
DEBUG 01-05 09:19:44.995892.995892 lmp.py:372]   Expert 63 |    159 | CPU
DEBUG 01-05 09:19:44.996104.996104 lmp.py:372]   Expert  8 |    160 | CPU
DEBUG 01-05 09:19:44.996555.996555 lmp.py:372]   Expert 17 |    160 | CPU
DEBUG 01-05 09:19:44.996529.996529 lmp.py:372]   Expert  1 |    161 | CPU
DEBUG 01-05 09:19:44.996934.996934 lmp.py:372]   Expert 46 |    161 | CPU
DEBUG 01-05 09:19:44.996100.996100 lmp.py:372]   Expert 13 |    162 | CPU
DEBUG 01-05 09:19:44.996789.996789 lmp.py:372]   Expert 26 |    162 | CPU
DEBUG 01-05 09:19:44.996240.996240 lmp.py:372]   Expert  0 |    166 | GPU
DEBUG 01-05 09:19:44.996691.996691 lmp.py:372]   Expert 49 |    168 | GPU
DEBUG 01-05 09:19:44.996665.996665 lmp.py:372]   Expert 43 |    174 | GPU
DEBUG 01-05 09:19:44.996877.996877 lmp.py:372]   Expert 47 |    188 | GPU
DEBUG 01-05 09:19:44.996851.996851 lmp.py:372]   Expert 39 |    189 | GPU
DEBUG 01-05 09:19:44.996302.996302 lmp.py:372]   Expert  4 |    193 | GPU
DEBUG 01-05 09:19:44.996230.996230 lmp.py:372]   Expert 40 |    193 | GPU
DEBUG 01-05 09:19:44.996873.996873 lmp.py:372]   Expert 25 |    201 | GPU
DEBUG 01-05 09:19:44.996324.996324 lmp.py:372]   Expert 53 |    203 | GPU
DEBUG 01-05 09:19:44.996298.996298 lmp.py:372]   Expert 50 |    205 | GPU
DEBUG 01-05 09:19:44.996510.996510 lmp.py:372]   Expert 37 |    212 | GPU
DEBUG 01-05 09:19:44.996723.996723 lmp.py:372]   Expert 35 |    220 | GPU
DEBUG 01-05 09:19:44.996458.996458 lmp.py:372]   Expert 14 |    221 | GPU
DEBUG 01-05 09:19:44.996671.996671 lmp.py:372]   Expert 19 |    223 | GPU
DEBUG 01-05 09:19:44.996075.996075 lmp.py:372]   Expert 20 |    224 | GPU
DEBUG 01-05 09:19:44.996718.996718 lmp.py:372]   Expert 22 |    227 | GPU
DEBUG 01-05 09:19:44.996169.996169 lmp.py:372]   Expert 11 |    236 | GPU
DEBUG 01-05 09:19:44.996157.996157 lmp.py:372]   Expert 41 |    247 | GPU
DEBUG 01-05 09:19:44.996561.996561 lmp.py:372]   Expert 51 |    265 | GPU
DEBUG 01-05 09:19:44.996774.996774 lmp.py:372]   Expert 28 |    266 | GPU
DEBUG 01-05 09:19:44.996748.996748 lmp.py:372]   Expert 38 |    282 | GPU
DEBUG 01-05 09:19:44.996722.996722 lmp.py:372]   Expert 36 |    292 | GPU
DEBUG 01-05 09:19:44.996934.996934 lmp.py:372]   Expert 21 |    293 | GPU
DEBUG 01-05 09:19:44.996101.996101 lmp.py:372]   Expert 10 |    317 | GPU
DEBUG 01-05 09:19:44.996744.996744 lmp.py:372]   Expert 45 |    329 | GPU
DEBUG 01-05 09:19:44.996956.996956 lmp.py:372]   Expert 61 |    354 | GPU
DEBUG 01-05 09:19:44.996930.996930 lmp.py:372]   Expert  2 |    360 | GPU
DEBUG 01-05 09:19:44.996381.996381 lmp.py:372]   Expert  9 |    369 | GPU
DEBUG 01-05 09:19:44.996117.996117 lmp.py:372]   Expert  3 |    378 | GPU
DEBUG 01-05 09:19:44.996329.996329 lmp.py:372]   Expert 29 |    389 | GPU
DEBUG 01-05 09:19:44.996303.996303 lmp.py:372]   Expert 31 |    393 | GPU
DEBUG 01-05 09:19:44.996277.996277 lmp.py:372]   Expert  7 |    541 | GPU
DEBUG 01-05 09:19:44.996205.996205 lmp.py:373] 
DEBUG 01-05 09:19:44.996205.996205 lmp.py:373]   CPU total tokens: 3770 (30.7%)
DEBUG 01-05 09:19:44.996609.996609 lmp.py:374]   GPU total tokens: 8518 (69.3%)
DEBUG 01-05 09:19:44.996259.996259 cuda_h.py:19] end experts_map_get cost 0.0015125274658203125 seconds
DEBUG 01-05 09:19:44.996617.996617 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:44.996824.996824 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:44.996194.996194 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:44.997051.997051 cuda_h.py:19] end allocate_cuda_memory cost 0.00024437904357910156 seconds
DEBUG 01-05 09:19:44.997663.997663 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:44.997703.997703 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:44.997612.997612 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:44.997785.997785 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af2b3129-d8d3-4b8f-a554-f76970581354
DEBUG 01-05 09:19:44.997110.997110 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:44.998891.998891 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af2b3129-d8d3-4b8f-a554-f76970581354
DEBUG 01-05 09:19:44.998059.998059 cuda_h.py:19] end load_into_gpu_async cost 0.0013134479522705078 seconds
DEBUG 01-05 09:19:44.998093.998093 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:44.998595.998595 cuda_h.py:19] end restore_tensors2 cost 0.0003440380096435547 seconds
DEBUG 01-05 09:19:44.999901.999901 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022819042205810547 seconds
DEBUG 01-05 09:19:45.001884.001884 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004980564117431641 seconds
DEBUG 01-05 09:19:45.001813.001813 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.001797.001797 lmp.py:419] 
DEBUG 01-05 09:19:45.001797.001797 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.001209.001209 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-05 09:19:45.001574.001574 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.008300.008300 mlpmodule.py:704] group tensors cost 0.0060994625091552734 s
DEBUG 01-05 09:19:45.010943.010943 mlpmodule.py:742] pad cost 0.002039670944213867 s
DEBUG 01-05 09:19:45.011080.011080 mlpmodule.py:748] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-05 09:19:45.011673.011673 mlpmodule.py:753] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-05 09:19:45.022712.022712 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.022042.022042 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.022324.022324 mlpmodule.py:773] group_w3 first element: 0.051513671875
WARNING 01-05 09:19:45.022076.022076 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.039913.039913 mlpmodule.py:793] group einsum cost 0.028464317321777344 s
DEBUG 01-05 09:19:45.041522.041522 mlpmodule.py:801] cpy2cputensor cost 0.0013642311096191406 s
DEBUG 01-05 09:19:45.083975.083975 cuda_h.py:19] end wait_cetm_experts cost 0.08149433135986328 seconds
DEBUG 01-05 09:19:45.083388.083388 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.084597.084597 cuda_h.py:19] end gpu_sexperts cost 0.0004639625549316406 seconds
DEBUG 01-05 09:19:45.084063.084063 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:19:45.084786.084786 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:19:45.084259.084259 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:19:45.084876.084876 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.152557373046875e-05 seconds
DEBUG 01-05 09:19:45.084963.084963 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.084388.084388 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af2b3129-d8d3-4b8f-a554-f76970581354
DEBUG 01-05 09:19:45.084016.084016 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.084893.084893 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.084452.084452 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.088831.088831 cuda_h.py:19] end allocate_cuda_memory cost 0.003961086273193359 seconds
DEBUG 01-05 09:19:45.088602.088602 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.088795.088795 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.088055.088055 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.088049.088049 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e328b926-b95f-49f2-b94e-9e88c0cb8d51
DEBUG 01-05 09:19:45.089662.089662 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.089410.089410 client.py:127] Model loaded
DEBUG 01-05 09:19:45.089313.089313 cuda_h.py:19] end wait_experts cost 0.004897356033325195 seconds
DEBUG 01-05 09:19:45.089116.089116 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.089726.089726 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.089381.089381 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e328b926-b95f-49f2-b94e-9e88c0cb8d51
DEBUG 01-05 09:19:45.089185.089185 cuda_h.py:19] end load_into_gpu_async cost 0.0011639595031738281 seconds
DEBUG 01-05 09:19:45.090987.090987 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.090574.090574 cuda_h.py:19] end restore_tensors2 cost 8.654594421386719e-05 seconds
DEBUG 01-05 09:19:45.090098.090098 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054891109466552734 seconds
DEBUG 01-05 09:19:45.090070.090070 mlpmodule.py:531] gpu group tensors cost 0.0010828971862792969 s
INFO 01-05 09:19:45.090520.090520 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e328b926-b95f-49f2-b94e-9e88c0cb8d51
DEBUG 01-05 09:19:45.092855.092855 mlpmodule.py:564] gpu pad cost 0.0018908977508544922 s
DEBUG 01-05 09:19:45.093120.093120 mlpmodule.py:582] gpu group einsum cost 0.00054168701171875 s
DEBUG 01-05 09:19:45.096709.096709 mlpmodule.py:611] gpu experts func einsum cost 0.007313728332519531 s
DEBUG 01-05 09:19:45.096368.096368 cuda_h.py:19] end gpu_experts cost 0.0074956417083740234 seconds
DEBUG 01-05 09:19:45.096130.096130 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:45.097871.097871 mlpmodule.py:662]  experts func einsum cost 0.09554696083068848 s
INFO 01-05 09:19:45.099777.099777 client.py:127] Model loaded
DEBUG 01-05 09:19:45.099183.099183 cuda_h.py:19] end sllm_worker_task cost 0.01457834243774414 seconds
DEBUG 01-05 09:19:45.099311.099311 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002381563186645508 seconds
DEBUG 01-05 09:19:45.099806.099806 cuda_h.py:19] end layer_moe_generate_19 cost 0.10496306419372559 seconds
DEBUG 01-05 09:19:45.099494.099494 lmp.py:214] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 09:19:45.099211.099211 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 09:19:45.099192.099192 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.099095.099095 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.102649.102649 cuda_h.py:19] end self_attn cost 0.0024595260620117188 seconds
DEBUG 01-05 09:19:45.102070.102070 cuda_h.py:19] end iln_self_attn_paln cost 0.0030760765075683594 seconds
DEBUG 01-05 09:19:45.102152.102152 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 09:19:45.102822.102822 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.103935.103935 cuda_h.py:19] end gate cost 0.0005762577056884766 seconds
DEBUG 01-05 09:19:45.103003.103003 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.103841.103841 lmp.py:361] 
DEBUG 01-05 09:19:45.103841.103841 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.103120.103120 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.103247.103247 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.103559.103559 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.103963.103963 lmp.py:365] 
DEBUG 01-05 09:19:45.103963.103963 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.103368.103368 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.103256.103256 lmp.py:372]   Expert 54 |     41 | CPU
DEBUG 01-05 09:19:45.103661.103661 lmp.py:372]   Expert  8 |     48 | CPU
DEBUG 01-05 09:19:45.104588.104588 lmp.py:372]   Expert 28 |     62 | CPU
DEBUG 01-05 09:19:45.104516.104516 lmp.py:372]   Expert 13 |     73 | CPU
DEBUG 01-05 09:19:45.104205.104205 lmp.py:372]   Expert  1 |     75 | CPU
DEBUG 01-05 09:19:45.104179.104179 lmp.py:372]   Expert  6 |     75 | CPU
DEBUG 01-05 09:19:45.104392.104392 lmp.py:372]   Expert 43 |     77 | CPU
DEBUG 01-05 09:19:45.104604.104604 lmp.py:372]   Expert 36 |     89 | CPU
DEBUG 01-05 09:19:45.104817.104817 lmp.py:372]   Expert 12 |     94 | CPU
DEBUG 01-05 09:19:45.104029.104029 lmp.py:372]   Expert 42 |     94 | CPU
DEBUG 01-05 09:19:45.104957.104957 lmp.py:372]   Expert 33 |    100 | CPU
DEBUG 01-05 09:19:45.104885.104885 lmp.py:372]   Expert 10 |    109 | CPU
DEBUG 01-05 09:19:45.104335.104335 lmp.py:372]   Expert 51 |    112 | CPU
DEBUG 01-05 09:19:45.104310.104310 lmp.py:372]   Expert 14 |    114 | CPU
DEBUG 01-05 09:19:45.104522.104522 lmp.py:372]   Expert 57 |    117 | CPU
DEBUG 01-05 09:19:45.104496.104496 lmp.py:372]   Expert 19 |    118 | CPU
DEBUG 01-05 09:19:45.104709.104709 lmp.py:372]   Expert 50 |    120 | CPU
DEBUG 01-05 09:19:45.104683.104683 lmp.py:372]   Expert 46 |    124 | CPU
DEBUG 01-05 09:19:45.104180.104180 lmp.py:372]   Expert 11 |    125 | CPU
DEBUG 01-05 09:19:45.104631.104631 lmp.py:372]   Expert 30 |    125 | CPU
DEBUG 01-05 09:19:45.104558.104558 lmp.py:372]   Expert 38 |    129 | CPU
DEBUG 01-05 09:19:45.104532.104532 lmp.py:372]   Expert  9 |    130 | CPU
DEBUG 01-05 09:19:45.104506.104506 lmp.py:372]   Expert 39 |    139 | CPU
DEBUG 01-05 09:19:45.104004.104004 lmp.py:372]   Expert 29 |    150 | CPU
DEBUG 01-05 09:19:45.104978.104978 lmp.py:372]   Expert 49 |    150 | CPU
DEBUG 01-05 09:19:45.104581.104581 lmp.py:372]   Expert 63 |    153 | CPU
DEBUG 01-05 09:19:45.104555.104555 lmp.py:372]   Expert 20 |    154 | CPU
DEBUG 01-05 09:19:45.104483.104483 lmp.py:372]   Expert  7 |    156 | CPU
DEBUG 01-05 09:19:45.104934.104934 lmp.py:372]   Expert 52 |    161 | CPU
DEBUG 01-05 09:19:45.104146.104146 lmp.py:372]   Expert  5 |    169 | CPU
DEBUG 01-05 09:19:45.104882.104882 lmp.py:372]   Expert 61 |    169 | CPU
DEBUG 01-05 09:19:45.104618.104618 lmp.py:372]   Expert  3 |    170 | CPU
DEBUG 01-05 09:19:45.104592.104592 lmp.py:372]   Expert 44 |    174 | GPU
DEBUG 01-05 09:19:45.104089.104089 lmp.py:372]   Expert 22 |    177 | GPU
DEBUG 01-05 09:19:45.104824.104824 lmp.py:372]   Expert 53 |    182 | GPU
DEBUG 01-05 09:19:45.104037.104037 lmp.py:372]   Expert 17 |    183 | GPU
DEBUG 01-05 09:19:45.104488.104488 lmp.py:372]   Expert 62 |    184 | GPU
DEBUG 01-05 09:19:45.104939.104939 lmp.py:372]   Expert  0 |    193 | GPU
DEBUG 01-05 09:19:45.104197.104197 lmp.py:372]   Expert 18 |    193 | GPU
DEBUG 01-05 09:19:45.104171.104171 lmp.py:372]   Expert 47 |    205 | GPU
DEBUG 01-05 09:19:45.104907.104907 lmp.py:372]   Expert 37 |    210 | GPU
DEBUG 01-05 09:19:45.104404.104404 lmp.py:372]   Expert 26 |    230 | GPU
DEBUG 01-05 09:19:45.104901.104901 lmp.py:372]   Expert 23 |    234 | GPU
DEBUG 01-05 09:19:45.104637.104637 lmp.py:372]   Expert 55 |    235 | GPU
DEBUG 01-05 09:19:45.104850.104850 lmp.py:372]   Expert 32 |    243 | GPU
DEBUG 01-05 09:19:45.104300.104300 lmp.py:372]   Expert 45 |    246 | GPU
DEBUG 01-05 09:19:45.104798.104798 lmp.py:372]   Expert 60 |    252 | GPU
DEBUG 01-05 09:19:45.104772.104772 lmp.py:372]   Expert 16 |    254 | GPU
DEBUG 01-05 09:19:45.104507.104507 lmp.py:372]   Expert  2 |    256 | GPU
DEBUG 01-05 09:19:45.104005.104005 lmp.py:372]   Expert 21 |    273 | GPU
DEBUG 01-05 09:19:45.104979.104979 lmp.py:372]   Expert 34 |    273 | GPU
DEBUG 01-05 09:19:45.104714.104714 lmp.py:372]   Expert 15 |    278 | GPU
DEBUG 01-05 09:19:45.104688.104688 lmp.py:372]   Expert 58 |    281 | GPU
DEBUG 01-05 09:19:45.104424.104424 lmp.py:372]   Expert 24 |    285 | GPU
DEBUG 01-05 09:19:45.104875.104875 lmp.py:372]   Expert 31 |    299 | GPU
DEBUG 01-05 09:19:45.104564.104564 lmp.py:372]   Expert 27 |    302 | GPU
DEBUG 01-05 09:19:45.104300.104300 lmp.py:372]   Expert  4 |    306 | GPU
DEBUG 01-05 09:19:45.104035.104035 lmp.py:372]   Expert 59 |    306 | GPU
DEBUG 01-05 09:19:45.104248.104248 lmp.py:372]   Expert 56 |    312 | GPU
DEBUG 01-05 09:19:45.104745.104745 lmp.py:372]   Expert 40 |    319 | GPU
DEBUG 01-05 09:19:45.104196.104196 lmp.py:372]   Expert 41 |    323 | GPU
DEBUG 01-05 09:19:45.104170.104170 lmp.py:372]   Expert 48 |    329 | GPU
DEBUG 01-05 09:19:45.104144.104144 lmp.py:372]   Expert 25 |    497 | GPU
DEBUG 01-05 09:19:45.105641.105641 lmp.py:372]   Expert 35 |    532 | GPU
DEBUG 01-05 09:19:45.105807.105807 lmp.py:373] 
DEBUG 01-05 09:19:45.105807.105807 lmp.py:373]   CPU total tokens: 3722 (30.3%)
DEBUG 01-05 09:19:45.105735.105735 lmp.py:374]   GPU total tokens: 8566 (69.7%)
DEBUG 01-05 09:19:45.105954.105954 cuda_h.py:19] end experts_map_get cost 0.0014808177947998047 seconds
DEBUG 01-05 09:19:45.105882.105882 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.105089.105089 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.105425.105425 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.105997.105997 cuda_h.py:19] end allocate_cuda_memory cost 0.0002422332763671875 seconds
DEBUG 01-05 09:19:45.105324.105324 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.105172.105172 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.105319.105319 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.105684.105684 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 456e343f-9db3-442c-9463-ac90d4361c7b
DEBUG 01-05 09:19:45.105711.105711 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.106274.106274 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 456e343f-9db3-442c-9463-ac90d4361c7b
DEBUG 01-05 09:19:45.106534.106534 cuda_h.py:19] end load_into_gpu_async cost 0.0011076927185058594 seconds
DEBUG 01-05 09:19:45.106614.106614 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.107045.107045 cuda_h.py:19] end restore_tensors2 cost 0.00036263465881347656 seconds
DEBUG 01-05 09:19:45.107543.107543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00206756591796875 seconds
DEBUG 01-05 09:19:45.109294.109294 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004770994186401367 seconds
DEBUG 01-05 09:19:45.109270.109270 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.110445.110445 lmp.py:419] 
DEBUG 01-05 09:19:45.110445.110445 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.110288.110288 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-05 09:19:45.110891.110891 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.120596.120596 mlpmodule.py:704] group tensors cost 0.010423898696899414 s
DEBUG 01-05 09:19:45.122285.122285 mlpmodule.py:742] pad cost 0.0015282630920410156 s
DEBUG 01-05 09:19:45.122992.122992 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-05 09:19:45.123795.123795 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-05 09:19:45.134623.134623 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.134768.134768 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.134096.134096 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 09:19:45.134293.134293 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.151101.151101 mlpmodule.py:793] group einsum cost 0.028835296630859375 s
DEBUG 01-05 09:19:45.152373.152373 mlpmodule.py:801] cpy2cputensor cost 0.0008008480072021484 s
DEBUG 01-05 09:19:45.194274.194274 cuda_h.py:19] end wait_cetm_experts cost 0.08415675163269043 seconds
DEBUG 01-05 09:19:45.194403.194403 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.194420.194420 cuda_h.py:19] end gpu_sexperts cost 0.0004627704620361328 seconds
DEBUG 01-05 09:19:45.194594.194594 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:19:45.195794.195794 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:19:45.195604.195604 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.337860107421875e-05 seconds
DEBUG 01-05 09:19:45.195413.195413 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.271766662597656e-05 seconds
DEBUG 01-05 09:19:45.195070.195070 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.195495.195495 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 456e343f-9db3-442c-9463-ac90d4361c7b
DEBUG 01-05 09:19:45.195003.195003 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.195881.195881 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.195962.195962 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.199781.199781 cuda_h.py:19] end allocate_cuda_memory cost 0.003864288330078125 seconds
DEBUG 01-05 09:19:45.199268.199268 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.199507.199507 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.199006.199006 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.199808.199808 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 209a1eab-cbfd-49b0-8498-9fe8235a6df4
DEBUG 01-05 09:19:45.199228.199228 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.199831.199831 client.py:127] Model loaded
DEBUG 01-05 09:19:45.199264.199264 cuda_h.py:19] end wait_experts cost 0.0047800540924072266 seconds
DEBUG 01-05 09:19:45.199543.199543 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.200299.200299 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.200591.200591 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 209a1eab-cbfd-49b0-8498-9fe8235a6df4
DEBUG 01-05 09:19:45.200871.200871 cuda_h.py:19] end load_into_gpu_async cost 0.0011796951293945312 seconds
DEBUG 01-05 09:19:45.200912.200912 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.200591.200591 cuda_h.py:19] end restore_tensors2 cost 8.511543273925781e-05 seconds
DEBUG 01-05 09:19:45.200639.200639 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005406379699707031 seconds
DEBUG 01-05 09:19:45.201233.201233 mlpmodule.py:531] gpu group tensors cost 0.0010955333709716797 s
INFO 01-05 09:19:45.201702.201702 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 209a1eab-cbfd-49b0-8498-9fe8235a6df4
DEBUG 01-05 09:19:45.203783.203783 mlpmodule.py:564] gpu pad cost 0.0020825862884521484 s
DEBUG 01-05 09:19:45.204997.204997 mlpmodule.py:582] gpu group einsum cost 0.0005478858947753906 s
DEBUG 01-05 09:19:45.207433.207433 mlpmodule.py:611] gpu experts func einsum cost 0.007459878921508789 s
DEBUG 01-05 09:19:45.207807.207807 cuda_h.py:19] end gpu_experts cost 0.007643699645996094 seconds
DEBUG 01-05 09:19:45.207854.207854 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:45.208222.208222 mlpmodule.py:662]  experts func einsum cost 0.09836530685424805 s
INFO 01-05 09:19:45.209234.209234 client.py:127] Model loaded
DEBUG 01-05 09:19:45.209792.209792 cuda_h.py:19] end sllm_worker_task cost 0.014574527740478516 seconds
DEBUG 01-05 09:19:45.210526.210526 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002420186996459961 seconds
DEBUG 01-05 09:19:45.210446.210446 cuda_h.py:19] end layer_moe_generate_20 cost 0.10745096206665039 seconds
DEBUG 01-05 09:19:45.210394.210394 lmp.py:214] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 09:19:45.210408.210408 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 09:19:45.210727.210727 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.210962.210962 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.213470.213470 cuda_h.py:19] end self_attn cost 0.0024607181549072266 seconds
DEBUG 01-05 09:19:45.213189.213189 cuda_h.py:19] end iln_self_attn_paln cost 0.003083944320678711 seconds
DEBUG 01-05 09:19:45.213509.213509 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 09:19:45.213464.213464 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.214338.214338 cuda_h.py:19] end gate cost 0.0005750656127929688 seconds
DEBUG 01-05 09:19:45.214645.214645 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.214238.214238 lmp.py:361] 
DEBUG 01-05 09:19:45.214238.214238 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.214755.214755 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.214643.214643 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.214432.214432 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.214598.214598 lmp.py:365] 
DEBUG 01-05 09:19:45.214598.214598 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.214526.214526 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.214176.214176 lmp.py:372]   Expert  9 |     30 | CPU
DEBUG 01-05 09:19:45.214580.214580 lmp.py:372]   Expert 44 |     49 | CPU
DEBUG 01-05 09:19:45.214269.214269 lmp.py:372]   Expert 60 |     55 | CPU
DEBUG 01-05 09:19:45.214959.214959 lmp.py:372]   Expert 20 |     64 | CPU
DEBUG 01-05 09:19:45.214887.214887 lmp.py:372]   Expert 26 |     67 | CPU
DEBUG 01-05 09:19:45.214576.214576 lmp.py:372]   Expert 56 |     69 | CPU
DEBUG 01-05 09:19:45.215788.215788 lmp.py:372]   Expert  1 |     71 | CPU
DEBUG 01-05 09:19:45.215001.215001 lmp.py:372]   Expert 32 |     76 | CPU
DEBUG 01-05 09:19:45.215690.215690 lmp.py:372]   Expert 19 |     84 | CPU
DEBUG 01-05 09:19:45.215664.215664 lmp.py:372]   Expert 54 |     90 | CPU
DEBUG 01-05 09:19:45.215877.215877 lmp.py:372]   Expert 51 |     98 | CPU
DEBUG 01-05 09:19:45.215089.215089 lmp.py:372]   Expert 57 |    106 | CPU
DEBUG 01-05 09:19:45.215017.215017 lmp.py:372]   Expert 12 |    112 | CPU
DEBUG 01-05 09:19:45.215706.215706 lmp.py:372]   Expert  8 |    113 | CPU
DEBUG 01-05 09:19:45.215680.215680 lmp.py:372]   Expert  3 |    118 | CPU
DEBUG 01-05 09:19:45.215654.215654 lmp.py:372]   Expert 48 |    120 | CPU
DEBUG 01-05 09:19:45.215390.215390 lmp.py:372]   Expert 33 |    125 | CPU
DEBUG 01-05 09:19:45.215602.215602 lmp.py:372]   Expert 52 |    125 | CPU
DEBUG 01-05 09:19:45.215576.215576 lmp.py:372]   Expert  6 |    127 | CPU
DEBUG 01-05 09:19:45.215550.215550 lmp.py:372]   Expert 25 |    130 | CPU
DEBUG 01-05 09:19:45.215524.215524 lmp.py:372]   Expert  7 |    132 | CPU
DEBUG 01-05 09:19:45.215975.215975 lmp.py:372]   Expert 49 |    132 | CPU
DEBUG 01-05 09:19:45.215665.215665 lmp.py:372]   Expert 23 |    133 | CPU
DEBUG 01-05 09:19:45.215877.215877 lmp.py:372]   Expert 14 |    134 | CPU
DEBUG 01-05 09:19:45.215613.215613 lmp.py:372]   Expert 13 |    140 | CPU
DEBUG 01-05 09:19:45.215587.215587 lmp.py:372]   Expert 35 |    140 | CPU
DEBUG 01-05 09:19:45.215561.215561 lmp.py:372]   Expert 53 |    143 | CPU
DEBUG 01-05 09:19:45.215296.215296 lmp.py:372]   Expert 40 |    149 | CPU
DEBUG 01-05 09:19:45.215270.215270 lmp.py:372]   Expert 34 |    151 | CPU
DEBUG 01-05 09:19:45.215006.215006 lmp.py:372]   Expert 15 |    153 | CPU
DEBUG 01-05 09:19:45.215172.215172 lmp.py:372]   Expert 59 |    165 | CPU
DEBUG 01-05 09:19:45.215623.215623 lmp.py:372]   Expert 58 |    173 | CPU
DEBUG 01-05 09:19:45.215359.215359 lmp.py:372]   Expert 61 |    177 | GPU
DEBUG 01-05 09:19:45.215571.215571 lmp.py:372]   Expert 39 |    178 | GPU
DEBUG 01-05 09:19:45.215307.215307 lmp.py:372]   Expert 24 |    181 | GPU
DEBUG 01-05 09:19:45.215042.215042 lmp.py:372]   Expert 28 |    186 | GPU
DEBUG 01-05 09:19:45.215016.215016 lmp.py:372]   Expert 50 |    190 | GPU
DEBUG 01-05 09:19:45.215229.215229 lmp.py:372]   Expert 41 |    193 | GPU
DEBUG 01-05 09:19:45.215203.215203 lmp.py:372]   Expert 27 |    196 | GPU
DEBUG 01-05 09:19:45.215177.215177 lmp.py:372]   Expert  2 |    203 | GPU
DEBUG 01-05 09:19:45.215913.215913 lmp.py:372]   Expert 38 |    219 | GPU
DEBUG 01-05 09:19:45.215648.215648 lmp.py:372]   Expert 18 |    224 | GPU
DEBUG 01-05 09:19:45.215384.215384 lmp.py:372]   Expert 43 |    232 | GPU
DEBUG 01-05 09:19:45.215358.215358 lmp.py:372]   Expert 37 |    239 | GPU
DEBUG 01-05 09:19:45.215855.215855 lmp.py:372]   Expert 11 |    240 | GPU
DEBUG 01-05 09:19:45.215544.215544 lmp.py:372]   Expert  4 |    248 | GPU
DEBUG 01-05 09:19:45.215234.215234 lmp.py:372]   Expert 17 |    261 | GPU
DEBUG 01-05 09:19:45.215731.215731 lmp.py:372]   Expert 62 |    261 | GPU
DEBUG 01-05 09:19:45.215705.215705 lmp.py:372]   Expert 29 |    262 | GPU
DEBUG 01-05 09:19:45.215202.215202 lmp.py:372]   Expert 10 |    267 | GPU
DEBUG 01-05 09:19:45.215699.215699 lmp.py:372]   Expert 22 |    267 | GPU
DEBUG 01-05 09:19:45.215197.215197 lmp.py:372]   Expert 63 |    272 | GPU
DEBUG 01-05 09:19:45.215932.215932 lmp.py:372]   Expert 47 |    273 | GPU
DEBUG 01-05 09:19:45.215429.215429 lmp.py:372]   Expert 55 |    280 | GPU
DEBUG 01-05 09:19:45.215927.215927 lmp.py:372]   Expert  5 |    286 | GPU
DEBUG 01-05 09:19:45.215424.215424 lmp.py:372]   Expert 30 |    292 | GPU
DEBUG 01-05 09:19:45.215159.215159 lmp.py:372]   Expert 21 |    295 | GPU
DEBUG 01-05 09:19:45.215895.215895 lmp.py:372]   Expert 31 |    302 | GPU
DEBUG 01-05 09:19:45.215637.215637 lmp.py:372]   Expert 16 |    342 | GPU
DEBUG 01-05 09:19:45.215280.215280 lmp.py:372]   Expert 46 |    352 | GPU
DEBUG 01-05 09:19:45.215778.215778 lmp.py:372]   Expert 36 |    387 | GPU
DEBUG 01-05 09:19:45.215275.215275 lmp.py:372]   Expert 45 |    411 | GPU
DEBUG 01-05 09:19:45.215249.215249 lmp.py:372]   Expert  0 |    426 | GPU
DEBUG 01-05 09:19:45.215461.215461 lmp.py:372]   Expert 42 |    572 | GPU
DEBUG 01-05 09:19:45.215912.215912 lmp.py:373] 
DEBUG 01-05 09:19:45.215912.215912 lmp.py:373]   CPU total tokens: 3574 (29.1%)
DEBUG 01-05 09:19:45.215840.215840 lmp.py:374]   GPU total tokens: 8714 (70.9%)
DEBUG 01-05 09:19:45.215059.215059 cuda_h.py:19] end experts_map_get cost 0.0014715194702148438 seconds
DEBUG 01-05 09:19:45.216702.216702 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.216863.216863 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.216756.216756 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.216103.216103 cuda_h.py:19] end allocate_cuda_memory cost 0.0002543926239013672 seconds
DEBUG 01-05 09:19:45.216715.216715 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.216755.216755 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.216618.216618 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.216506.216506 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 604e4a3b-1880-40a2-8062-a60b52dc4442
DEBUG 01-05 09:19:45.216546.216546 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.217275.217275 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 604e4a3b-1880-40a2-8062-a60b52dc4442
DEBUG 01-05 09:19:45.217873.217873 cuda_h.py:19] end load_into_gpu_async cost 0.0011391639709472656 seconds
DEBUG 01-05 09:19:45.217384.217384 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.218886.218886 cuda_h.py:19] end restore_tensors2 cost 0.0003440380096435547 seconds
DEBUG 01-05 09:19:45.218332.218332 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021140575408935547 seconds
DEBUG 01-05 09:19:45.220990.220990 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004819631576538086 seconds
DEBUG 01-05 09:19:45.220542.220542 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.220174.220174 lmp.py:419] 
DEBUG 01-05 09:19:45.220174.220174 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.221348.221348 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-05 09:19:45.221190.221190 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.231965.231965 mlpmodule.py:704] group tensors cost 0.010372400283813477 s
DEBUG 01-05 09:19:45.233829.233829 mlpmodule.py:742] pad cost 0.0015642642974853516 s
DEBUG 01-05 09:19:45.233084.233084 mlpmodule.py:748] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-05 09:19:45.234603.234603 mlpmodule.py:753] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-05 09:19:45.245757.245757 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.245187.245187 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.245853.245853 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 09:19:45.245367.245367 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.262748.262748 mlpmodule.py:793] group einsum cost 0.028574228286743164 s
DEBUG 01-05 09:19:45.263803.263803 mlpmodule.py:801] cpy2cputensor cost 0.0008480548858642578 s
DEBUG 01-05 09:19:45.305000.305000 cuda_h.py:19] end wait_cetm_experts cost 0.08429813385009766 seconds
DEBUG 01-05 09:19:45.305361.305361 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.306100.306100 cuda_h.py:19] end gpu_sexperts cost 0.00046634674072265625 seconds
DEBUG 01-05 09:19:45.306274.306274 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:19:45.306044.306044 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:19:45.306947.306947 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:19:45.306372.306372 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.176399230957031e-05 seconds
DEBUG 01-05 09:19:45.306690.306690 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.306884.306884 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 604e4a3b-1880-40a2-8062-a60b52dc4442
DEBUG 01-05 09:19:45.306485.306485 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.306601.306601 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.306536.306536 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.310126.310126 cuda_h.py:19] end allocate_cuda_memory cost 0.00393986701965332 seconds
DEBUG 01-05 09:19:45.310897.310897 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.310329.310329 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.310874.310874 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.310199.310199 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af3c90e9-524f-405b-a883-f646b209d92b
DEBUG 01-05 09:19:45.310474.310474 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.311660.311660 client.py:127] Model loaded
DEBUG 01-05 09:19:45.311139.311139 cuda_h.py:19] end wait_experts cost 0.004858732223510742 seconds
DEBUG 01-05 09:19:45.311372.311372 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.311128.311128 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.311922.311922 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af3c90e9-524f-405b-a883-f646b209d92b
DEBUG 01-05 09:19:45.311872.311872 cuda_h.py:19] end load_into_gpu_async cost 0.0011706352233886719 seconds
DEBUG 01-05 09:19:45.311674.311674 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.311545.311545 cuda_h.py:19] end restore_tensors2 cost 8.606910705566406e-05 seconds
DEBUG 01-05 09:19:45.312116.312116 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054743289947509766 seconds
DEBUG 01-05 09:19:45.312294.312294 mlpmodule.py:531] gpu group tensors cost 0.0011169910430908203 s
INFO 01-05 09:19:45.312956.312956 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af3c90e9-524f-405b-a883-f646b209d92b
DEBUG 01-05 09:19:45.314747.314747 mlpmodule.py:564] gpu pad cost 0.0019288063049316406 s
DEBUG 01-05 09:19:45.314764.314764 mlpmodule.py:582] gpu group einsum cost 0.0004315376281738281 s
DEBUG 01-05 09:19:45.318011.318011 mlpmodule.py:611] gpu experts func einsum cost 0.00709986686706543 s
DEBUG 01-05 09:19:45.318478.318478 cuda_h.py:19] end gpu_experts cost 0.0072820186614990234 seconds
DEBUG 01-05 09:19:45.318764.318764 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:45.319573.319573 mlpmodule.py:662]  experts func einsum cost 0.09854602813720703 s
INFO 01-05 09:19:45.321215.321215 client.py:127] Model loaded
DEBUG 01-05 09:19:45.321250.321250 cuda_h.py:19] end sllm_worker_task cost 0.014667749404907227 seconds
DEBUG 01-05 09:19:45.321332.321332 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0027022361755371094 seconds
DEBUG 01-05 09:19:45.321827.321827 cuda_h.py:19] end layer_moe_generate_21 cost 0.10757565498352051 seconds
DEBUG 01-05 09:19:45.321132.321132 lmp.py:214] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 09:19:45.321179.321179 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 09:19:45.321445.321445 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.321911.321911 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.324412.324412 cuda_h.py:19] end self_attn cost 0.002439260482788086 seconds
DEBUG 01-05 09:19:45.324621.324621 cuda_h.py:19] end iln_self_attn_paln cost 0.0030493736267089844 seconds
DEBUG 01-05 09:19:45.324748.324748 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 09:19:45.324657.324657 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.325677.325677 cuda_h.py:19] end gate cost 0.0005784034729003906 seconds
DEBUG 01-05 09:19:45.325222.325222 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.325199.325199 lmp.py:361] 
DEBUG 01-05 09:19:45.325199.325199 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.325240.325240 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.325651.325651 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.325155.325155 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.325321.325321 lmp.py:365] 
DEBUG 01-05 09:19:45.325321.325321 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.325487.325487 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.325899.325899 lmp.py:372]   Expert 11 |     59 | CPU
DEBUG 01-05 09:19:45.325303.325303 lmp.py:372]   Expert 49 |     59 | CPU
DEBUG 01-05 09:19:45.325993.325993 lmp.py:372]   Expert 32 |     70 | CPU
DEBUG 01-05 09:19:45.325682.325682 lmp.py:372]   Expert  6 |     74 | CPU
DEBUG 01-05 09:19:45.325610.325610 lmp.py:372]   Expert 22 |     79 | CPU
DEBUG 01-05 09:19:45.325061.325061 lmp.py:372]   Expert 45 |     79 | CPU
DEBUG 01-05 09:19:45.326511.326511 lmp.py:372]   Expert 54 |     85 | CPU
DEBUG 01-05 09:19:45.326201.326201 lmp.py:372]   Expert  1 |     86 | CPU
DEBUG 01-05 09:19:45.326413.326413 lmp.py:372]   Expert  7 |     92 | CPU
DEBUG 01-05 09:19:45.326149.326149 lmp.py:372]   Expert 42 |     92 | CPU
DEBUG 01-05 09:19:45.326361.326361 lmp.py:372]   Expert 63 |     92 | CPU
DEBUG 01-05 09:19:45.326335.326335 lmp.py:372]   Expert 44 |     96 | CPU
DEBUG 01-05 09:19:45.326309.326309 lmp.py:372]   Expert 60 |     96 | CPU
DEBUG 01-05 09:19:45.326522.326522 lmp.py:372]   Expert 12 |     97 | CPU
DEBUG 01-05 09:19:45.326211.326211 lmp.py:372]   Expert 41 |     97 | CPU
DEBUG 01-05 09:19:45.326662.326662 lmp.py:372]   Expert 61 |     98 | CPU
DEBUG 01-05 09:19:45.326875.326875 lmp.py:372]   Expert 52 |    105 | CPU
DEBUG 01-05 09:19:45.326849.326849 lmp.py:372]   Expert 37 |    106 | CPU
DEBUG 01-05 09:19:45.326584.326584 lmp.py:372]   Expert 46 |    107 | CPU
DEBUG 01-05 09:19:45.326558.326558 lmp.py:372]   Expert 15 |    110 | CPU
DEBUG 01-05 09:19:45.326294.326294 lmp.py:372]   Expert 24 |    117 | CPU
DEBUG 01-05 09:19:45.326506.326506 lmp.py:372]   Expert 13 |    120 | CPU
DEBUG 01-05 09:19:45.326196.326196 lmp.py:372]   Expert 48 |    123 | CPU
DEBUG 01-05 09:19:45.326362.326362 lmp.py:372]   Expert  3 |    124 | CPU
DEBUG 01-05 09:19:45.326336.326336 lmp.py:372]   Expert 31 |    126 | CPU
DEBUG 01-05 09:19:45.326548.326548 lmp.py:372]   Expert 10 |    129 | CPU
DEBUG 01-05 09:19:45.326761.326761 lmp.py:372]   Expert 62 |    129 | CPU
DEBUG 01-05 09:19:45.326735.326735 lmp.py:372]   Expert 30 |    130 | CPU
DEBUG 01-05 09:19:45.326947.326947 lmp.py:372]   Expert  9 |    133 | CPU
DEBUG 01-05 09:19:45.326398.326398 lmp.py:372]   Expert 57 |    133 | CPU
DEBUG 01-05 09:19:45.326611.326611 lmp.py:372]   Expert 21 |    142 | CPU
DEBUG 01-05 09:19:45.326300.326300 lmp.py:372]   Expert 28 |    150 | CPU
DEBUG 01-05 09:19:45.326512.326512 lmp.py:372]   Expert 27 |    154 | GPU
DEBUG 01-05 09:19:45.326725.326725 lmp.py:372]   Expert 47 |    163 | GPU
DEBUG 01-05 09:19:45.326460.326460 lmp.py:372]   Expert 26 |    174 | GPU
DEBUG 01-05 09:19:45.326673.326673 lmp.py:372]   Expert  0 |    182 | GPU
DEBUG 01-05 09:19:45.326409.326409 lmp.py:372]   Expert 43 |    183 | GPU
DEBUG 01-05 09:19:45.326621.326621 lmp.py:372]   Expert 58 |    193 | GPU
DEBUG 01-05 09:19:45.326026.326026 lmp.py:372]   Expert 50 |    196 | GPU
DEBUG 01-05 09:19:45.326192.326192 lmp.py:372]   Expert 51 |    202 | GPU
DEBUG 01-05 09:19:45.326643.326643 lmp.py:372]   Expert 39 |    205 | GPU
DEBUG 01-05 09:19:45.326617.326617 lmp.py:372]   Expert 16 |    209 | GPU
DEBUG 01-05 09:19:45.326591.326591 lmp.py:372]   Expert 38 |    212 | GPU
DEBUG 01-05 09:19:45.326326.326326 lmp.py:372]   Expert 19 |    217 | GPU
DEBUG 01-05 09:19:45.326300.326300 lmp.py:372]   Expert  8 |    219 | GPU
DEBUG 01-05 09:19:45.326274.326274 lmp.py:372]   Expert  2 |    228 | GPU
DEBUG 01-05 09:19:45.326772.326772 lmp.py:372]   Expert 34 |    256 | GPU
DEBUG 01-05 09:19:45.326222.326222 lmp.py:372]   Expert 56 |    258 | GPU
DEBUG 01-05 09:19:45.326912.326912 lmp.py:372]   Expert 33 |    259 | GPU
DEBUG 01-05 09:19:45.326886.326886 lmp.py:372]   Expert  4 |    261 | GPU
DEBUG 01-05 09:19:45.326860.326860 lmp.py:372]   Expert 35 |    272 | GPU
DEBUG 01-05 09:19:45.326595.326595 lmp.py:372]   Expert 23 |    284 | GPU
DEBUG 01-05 09:19:45.326808.326808 lmp.py:372]   Expert 17 |    287 | GPU
DEBUG 01-05 09:19:45.326544.326544 lmp.py:372]   Expert 20 |    303 | GPU
DEBUG 01-05 09:19:45.326279.326279 lmp.py:372]   Expert 53 |    327 | GPU
DEBUG 01-05 09:19:45.326730.326730 lmp.py:372]   Expert 29 |    334 | GPU
DEBUG 01-05 09:19:45.326181.326181 lmp.py:372]   Expert 25 |    340 | GPU
DEBUG 01-05 09:19:45.326155.326155 lmp.py:372]   Expert 18 |    346 | GPU
DEBUG 01-05 09:19:45.326891.326891 lmp.py:372]   Expert 59 |    354 | GPU
DEBUG 01-05 09:19:45.326626.326626 lmp.py:372]   Expert 40 |    366 | GPU
DEBUG 01-05 09:19:45.326600.326600 lmp.py:372]   Expert 55 |    372 | GPU
DEBUG 01-05 09:19:45.326336.326336 lmp.py:372]   Expert 14 |    444 | GPU
DEBUG 01-05 09:19:45.326310.326310 lmp.py:372]   Expert 36 |    562 | GPU
DEBUG 01-05 09:19:45.326284.326284 lmp.py:372]   Expert  5 |    591 | GPU
DEBUG 01-05 09:19:45.326735.326735 lmp.py:373] 
DEBUG 01-05 09:19:45.326735.326735 lmp.py:373]   CPU total tokens: 3335 (27.1%)
DEBUG 01-05 09:19:45.326139.326139 lmp.py:374]   GPU total tokens: 8953 (72.9%)
DEBUG 01-05 09:19:45.326074.326074 cuda_h.py:19] end experts_map_get cost 0.001478433609008789 seconds
DEBUG 01-05 09:19:45.327240.327240 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.327401.327401 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.327260.327260 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.327527.327527 cuda_h.py:19] end allocate_cuda_memory cost 0.0002334117889404297 seconds
DEBUG 01-05 09:19:45.327946.327946 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.327272.327272 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.327942.327942 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.327115.327115 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7138f8b1-7418-4f6f-8257-41ed860ab512
DEBUG 01-05 09:19:45.327049.327049 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.328155.328155 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7138f8b1-7418-4f6f-8257-41ed860ab512
DEBUG 01-05 09:19:45.328131.328131 cuda_h.py:19] end load_into_gpu_async cost 0.0011239051818847656 seconds
DEBUG 01-05 09:19:45.328688.328688 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.329429.329429 cuda_h.py:19] end restore_tensors2 cost 0.0003452301025390625 seconds
DEBUG 01-05 09:19:45.329258.329258 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020499229431152344 seconds
DEBUG 01-05 09:19:45.331268.331268 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004769802093505859 seconds
DEBUG 01-05 09:19:45.331581.331581 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.331783.331783 lmp.py:419] 
DEBUG 01-05 09:19:45.331783.331783 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.331149.331149 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-05 09:19:45.332560.332560 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.342155.342155 mlpmodule.py:704] group tensors cost 0.010515928268432617 s
DEBUG 01-05 09:19:45.344114.344114 mlpmodule.py:742] pad cost 0.0015816688537597656 s
DEBUG 01-05 09:19:45.345118.345118 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-05 09:19:45.345014.345014 mlpmodule.py:753] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-05 09:19:45.355355.355355 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.355500.355500 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.356689.356689 mlpmodule.py:773] group_w3 first element: 0.025390625
WARNING 01-05 09:19:45.356925.356925 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.373280.373280 mlpmodule.py:793] group einsum cost 0.028628110885620117 s
DEBUG 01-05 09:19:45.375650.375650 mlpmodule.py:801] cpy2cputensor cost 0.001355886459350586 s
DEBUG 01-05 09:19:45.417548.417548 cuda_h.py:19] end wait_cetm_experts cost 0.08502697944641113 seconds
DEBUG 01-05 09:19:45.417147.417147 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.417025.417025 cuda_h.py:19] end gpu_sexperts cost 0.00046539306640625 seconds
DEBUG 01-05 09:19:45.417298.417298 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:19:45.417783.417783 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:19:45.417309.417309 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.24249267578125e-05 seconds
DEBUG 01-05 09:19:45.417833.417833 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.748603820800781e-05 seconds
DEBUG 01-05 09:19:45.417152.417152 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.417577.417577 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7138f8b1-7418-4f6f-8257-41ed860ab512
DEBUG 01-05 09:19:45.418893.418893 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.418340.418340 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.418137.418137 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.422699.422699 cuda_h.py:19] end allocate_cuda_memory cost 0.003710508346557617 seconds
DEBUG 01-05 09:19:45.422516.422516 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.422948.422948 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.422254.422254 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.422772.422772 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8fc4f6ef-f968-4af0-bf11-7dc98bd0b7a4
DEBUG 01-05 09:19:45.422623.422623 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.422802.422802 client.py:127] Model loaded
DEBUG 01-05 09:19:45.422990.422990 cuda_h.py:19] end wait_experts cost 0.0046236515045166016 seconds
DEBUG 01-05 09:19:45.422838.422838 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.422402.422402 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.423090.423090 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8fc4f6ef-f968-4af0-bf11-7dc98bd0b7a4
DEBUG 01-05 09:19:45.423563.423563 cuda_h.py:19] end load_into_gpu_async cost 0.0011546611785888672 seconds
DEBUG 01-05 09:19:45.423365.423365 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.423899.423899 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-05 09:19:45.423708.423708 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005223751068115234 seconds
DEBUG 01-05 09:19:45.423024.423024 mlpmodule.py:531] gpu group tensors cost 0.0010766983032226562 s
INFO 01-05 09:19:45.424052.424052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8fc4f6ef-f968-4af0-bf11-7dc98bd0b7a4
DEBUG 01-05 09:19:45.425073.425073 mlpmodule.py:564] gpu pad cost 0.001875162124633789 s
DEBUG 01-05 09:19:45.426505.426505 mlpmodule.py:582] gpu group einsum cost 0.0005576610565185547 s
DEBUG 01-05 09:19:45.430498.430498 mlpmodule.py:611] gpu experts func einsum cost 0.007327079772949219 s
DEBUG 01-05 09:19:45.430680.430680 cuda_h.py:19] end gpu_experts cost 0.0075092315673828125 seconds
DEBUG 01-05 09:19:45.430489.430489 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:45.431425.431425 mlpmodule.py:662]  experts func einsum cost 0.09907150268554688 s
INFO 01-05 09:19:45.432070.432070 client.py:127] Model loaded
DEBUG 01-05 09:19:45.432343.432343 cuda_h.py:19] end sllm_worker_task cost 0.014542102813720703 seconds
DEBUG 01-05 09:19:45.432862.432862 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002586841583251953 seconds
DEBUG 01-05 09:19:45.432788.432788 cuda_h.py:19] end layer_moe_generate_22 cost 0.10814213752746582 seconds
DEBUG 01-05 09:19:45.433569.433569 lmp.py:214] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 09:19:45.433776.433776 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 09:19:45.433863.433863 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.433847.433847 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.436613.436613 cuda_h.py:19] end self_attn cost 0.0024721622467041016 seconds
DEBUG 01-05 09:19:45.436445.436445 cuda_h.py:19] end iln_self_attn_paln cost 0.0030972957611083984 seconds
DEBUG 01-05 09:19:45.436546.436546 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 09:19:45.436978.436978 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.437144.437144 cuda_h.py:19] end gate cost 0.0005791187286376953 seconds
DEBUG 01-05 09:19:45.437259.437259 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.437951.437951 lmp.py:361] 
DEBUG 01-05 09:19:45.437951.437951 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.437468.437468 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.437880.437880 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.437907.437907 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.437073.437073 lmp.py:365] 
DEBUG 01-05 09:19:45.437073.437073 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.437716.437716 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.437843.437843 lmp.py:372]   Expert  5 |     63 | CPU
DEBUG 01-05 09:19:45.437247.437247 lmp.py:372]   Expert 49 |     64 | CPU
DEBUG 01-05 09:19:45.437936.437936 lmp.py:372]   Expert 44 |     73 | CPU
DEBUG 01-05 09:19:45.437103.437103 lmp.py:372]   Expert 27 |     74 | CPU
DEBUG 01-05 09:19:45.437269.437269 lmp.py:372]   Expert 19 |     82 | CPU
DEBUG 01-05 09:19:45.437720.437720 lmp.py:372]   Expert  7 |     94 | CPU
DEBUG 01-05 09:19:45.437170.437170 lmp.py:372]   Expert 17 |    101 | CPU
DEBUG 01-05 09:19:45.437621.437621 lmp.py:372]   Expert 53 |    101 | CPU
DEBUG 01-05 09:19:45.437834.437834 lmp.py:372]   Expert 58 |    108 | CPU
DEBUG 01-05 09:19:45.437046.437046 lmp.py:372]   Expert 55 |    115 | CPU
DEBUG 01-05 09:19:45.437736.437736 lmp.py:372]   Expert 38 |    118 | CPU
DEBUG 01-05 09:19:45.437663.437663 lmp.py:372]   Expert 40 |    119 | CPU
DEBUG 01-05 09:19:45.437829.437829 lmp.py:372]   Expert 43 |    119 | CPU
DEBUG 01-05 09:19:45.437519.437519 lmp.py:372]   Expert  4 |    123 | CPU
DEBUG 01-05 09:19:45.437731.437731 lmp.py:372]   Expert 34 |    123 | CPU
DEBUG 01-05 09:19:45.437420.437420 lmp.py:372]   Expert 22 |    125 | CPU
DEBUG 01-05 09:19:45.437871.437871 lmp.py:372]   Expert 25 |    125 | CPU
DEBUG 01-05 09:19:45.437845.437845 lmp.py:372]   Expert 51 |    125 | CPU
DEBUG 01-05 09:19:45.437296.437296 lmp.py:372]   Expert 35 |    127 | CPU
DEBUG 01-05 09:19:45.437462.437462 lmp.py:372]   Expert 52 |    129 | CPU
DEBUG 01-05 09:19:45.437629.437629 lmp.py:372]   Expert  6 |    131 | CPU
DEBUG 01-05 09:19:45.437079.437079 lmp.py:372]   Expert  1 |    144 | CPU
DEBUG 01-05 09:19:45.437292.437292 lmp.py:372]   Expert 16 |    144 | CPU
DEBUG 01-05 09:19:45.437743.437743 lmp.py:372]   Expert 42 |    145 | CPU
DEBUG 01-05 09:19:45.437194.437194 lmp.py:372]   Expert 63 |    150 | CPU
DEBUG 01-05 09:19:45.437645.437645 lmp.py:372]   Expert 47 |    159 | CPU
DEBUG 01-05 09:19:45.437619.437619 lmp.py:372]   Expert 36 |    165 | CPU
DEBUG 01-05 09:19:45.438069.438069 lmp.py:372]   Expert  9 |    169 | CPU
DEBUG 01-05 09:19:45.438236.438236 lmp.py:372]   Expert 13 |    172 | CPU
DEBUG 01-05 09:19:45.438925.438925 lmp.py:372]   Expert 28 |    184 | CPU
DEBUG 01-05 09:19:45.438899.438899 lmp.py:372]   Expert 30 |    186 | CPU
DEBUG 01-05 09:19:45.438111.438111 lmp.py:372]   Expert  0 |    187 | CPU
DEBUG 01-05 09:19:45.438324.438324 lmp.py:372]   Expert 11 |    187 | GPU
DEBUG 01-05 09:19:45.438298.438298 lmp.py:372]   Expert 46 |    189 | GPU
DEBUG 01-05 09:19:45.438510.438510 lmp.py:372]   Expert 45 |    193 | GPU
DEBUG 01-05 09:19:45.438961.438961 lmp.py:372]   Expert 62 |    195 | GPU
DEBUG 01-05 09:19:45.438412.438412 lmp.py:372]   Expert 26 |    196 | GPU
DEBUG 01-05 09:19:45.438578.438578 lmp.py:372]   Expert  2 |    198 | GPU
DEBUG 01-05 09:19:45.438791.438791 lmp.py:372]   Expert 23 |    198 | GPU
DEBUG 01-05 09:19:45.438003.438003 lmp.py:372]   Expert 60 |    203 | GPU
DEBUG 01-05 09:19:45.438977.438977 lmp.py:372]   Expert 61 |    207 | GPU
DEBUG 01-05 09:19:45.438190.438190 lmp.py:372]   Expert 39 |    211 | GPU
DEBUG 01-05 09:19:45.438402.438402 lmp.py:372]   Expert 15 |    212 | GPU
DEBUG 01-05 09:19:45.438376.438376 lmp.py:372]   Expert 24 |    212 | GPU
DEBUG 01-05 09:19:45.438066.438066 lmp.py:372]   Expert  3 |    220 | GPU
DEBUG 01-05 09:19:45.438232.438232 lmp.py:372]   Expert 41 |    224 | GPU
DEBUG 01-05 09:19:45.438159.438159 lmp.py:372]   Expert 12 |    230 | GPU
DEBUG 01-05 09:19:45.438610.438610 lmp.py:372]   Expert 29 |    247 | GPU
DEBUG 01-05 09:19:45.438584.438584 lmp.py:372]   Expert 14 |    263 | GPU
DEBUG 01-05 09:19:45.438797.438797 lmp.py:372]   Expert 21 |    270 | GPU
DEBUG 01-05 09:19:45.438009.438009 lmp.py:372]   Expert 20 |    275 | GPU
DEBUG 01-05 09:19:45.438983.438983 lmp.py:372]   Expert 33 |    279 | GPU
DEBUG 01-05 09:19:45.438434.438434 lmp.py:372]   Expert  8 |    285 | GPU
DEBUG 01-05 09:19:45.438170.438170 lmp.py:372]   Expert 31 |    289 | GPU
DEBUG 01-05 09:19:45.438382.438382 lmp.py:372]   Expert 57 |    290 | GPU
DEBUG 01-05 09:19:45.438356.438356 lmp.py:372]   Expert 59 |    295 | GPU
DEBUG 01-05 09:19:45.438807.438807 lmp.py:372]   Expert 10 |    298 | GPU
DEBUG 01-05 09:19:45.438020.438020 lmp.py:372]   Expert 32 |    300 | GPU
DEBUG 01-05 09:19:45.438994.438994 lmp.py:372]   Expert 18 |    308 | GPU
DEBUG 01-05 09:19:45.438206.438206 lmp.py:372]   Expert 37 |    309 | GPU
DEBUG 01-05 09:19:45.438419.438419 lmp.py:372]   Expert 50 |    312 | GPU
DEBUG 01-05 09:19:45.438393.438393 lmp.py:372]   Expert 56 |    364 | GPU
DEBUG 01-05 09:19:45.438844.438844 lmp.py:372]   Expert 48 |    383 | GPU
DEBUG 01-05 09:19:45.438248.438248 lmp.py:372]   Expert 54 |    402 | GPU
DEBUG 01-05 09:19:45.438414.438414 lmp.py:373] 
DEBUG 01-05 09:19:45.438414.438414 lmp.py:373]   CPU total tokens: 4044 (32.9%)
DEBUG 01-05 09:19:45.438342.438342 lmp.py:374]   GPU total tokens: 8244 (67.1%)
DEBUG 01-05 09:19:45.438800.438800 cuda_h.py:19] end experts_map_get cost 0.0014944076538085938 seconds
DEBUG 01-05 09:19:45.438204.438204 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.438842.438842 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.438304.438304 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.439062.439062 cuda_h.py:19] end allocate_cuda_memory cost 0.00024199485778808594 seconds
DEBUG 01-05 09:19:45.439720.439720 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.439045.439045 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.439192.439192 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.439603.439603 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be1e5ac1-4cb0-457b-b0b9-d6f402c3f99c
DEBUG 01-05 09:19:45.439312.439312 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.440639.440639 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be1e5ac1-4cb0-457b-b0b9-d6f402c3f99c
DEBUG 01-05 09:19:45.440237.440237 cuda_h.py:19] end load_into_gpu_async cost 0.0011930465698242188 seconds
DEBUG 01-05 09:19:45.440033.440033 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.440688.440688 cuda_h.py:19] end restore_tensors2 cost 0.0003509521484375 seconds
DEBUG 01-05 09:19:45.440279.440279 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002160787582397461 seconds
DEBUG 01-05 09:19:45.443573.443573 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0048444271087646484 seconds
DEBUG 01-05 09:19:45.443886.443886 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.443087.443087 lmp.py:419] 
DEBUG 01-05 09:19:45.443087.443087 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.443692.443692 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-05 09:19:45.443341.443341 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.454975.454975 mlpmodule.py:704] group tensors cost 0.010269641876220703 s
DEBUG 01-05 09:19:45.456753.456753 mlpmodule.py:742] pad cost 0.0015437602996826172 s
DEBUG 01-05 09:19:45.456572.456572 mlpmodule.py:748] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-05 09:19:45.456283.456283 mlpmodule.py:753] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-05 09:19:45.468607.468607 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.468361.468361 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.468166.468166 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-05 09:19:45.468985.468985 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.492614.492614 mlpmodule.py:793] group einsum cost 0.03534412384033203 s
DEBUG 01-05 09:19:45.493622.493622 mlpmodule.py:801] cpy2cputensor cost 0.0009949207305908203 s
DEBUG 01-05 09:19:45.538592.538592 cuda_h.py:19] end wait_cetm_experts cost 0.09485960006713867 seconds
DEBUG 01-05 09:19:45.538118.538118 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.539406.539406 cuda_h.py:19] end gpu_sexperts cost 0.0006232261657714844 seconds
DEBUG 01-05 09:19:45.539587.539587 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:19:45.539270.539270 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:19:45.539088.539088 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.62396240234375e-05 seconds
DEBUG 01-05 09:19:45.539751.539751 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:19:45.539023.539023 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.539309.539309 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be1e5ac1-4cb0-457b-b0b9-d6f402c3f99c
DEBUG 01-05 09:19:45.540972.540972 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.540260.540260 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.540355.540355 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.543260.543260 cuda_h.py:19] end allocate_cuda_memory cost 0.0032596588134765625 seconds
DEBUG 01-05 09:19:45.543376.543376 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.543476.543476 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.543558.543558 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.543552.543552 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b99980c-8fd1-4c61-940a-52632ad7efef
DEBUG 01-05 09:19:45.543079.543079 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.544330.544330 client.py:127] Model loaded
DEBUG 01-05 09:19:45.544664.544664 cuda_h.py:19] end wait_experts cost 0.004267454147338867 seconds
DEBUG 01-05 09:19:45.544705.544705 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.544222.544222 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.544595.544595 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b99980c-8fd1-4c61-940a-52632ad7efef
DEBUG 01-05 09:19:45.544021.544021 cuda_h.py:19] end load_into_gpu_async cost 0.0012428760528564453 seconds
DEBUG 01-05 09:19:45.544877.544877 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.545861.545861 cuda_h.py:19] end restore_tensors2 cost 9.822845458984375e-05 seconds
DEBUG 01-05 09:19:45.545909.545909 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004902839660644531 seconds
DEBUG 01-05 09:19:45.545275.545275 mlpmodule.py:531] gpu group tensors cost 0.0012655258178710938 s
INFO 01-05 09:19:45.546481.546481 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b99980c-8fd1-4c61-940a-52632ad7efef
DEBUG 01-05 09:19:45.547047.547047 mlpmodule.py:564] gpu pad cost 0.002157926559448242 s
DEBUG 01-05 09:19:45.548310.548310 mlpmodule.py:582] gpu group einsum cost 0.0008385181427001953 s
INFO 01-05 09:19:45.552667.552667 client.py:127] Model loaded
DEBUG 01-05 09:19:45.552841.552841 cuda_h.py:19] end sllm_worker_task cost 0.012021303176879883 seconds
DEBUG 01-05 09:19:45.552952.552952 mlpmodule.py:662]  experts func einsum cost 0.10868692398071289 s
DEBUG 01-05 09:19:45.552069.552069 mlpmodule.py:611] gpu experts func einsum cost 0.008558511734008789 s
DEBUG 01-05 09:19:45.553079.553079 cuda_h.py:19] end gpu_experts cost 0.00878000259399414 seconds
DEBUG 01-05 09:19:45.553458.553458 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:45.553949.553949 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-05 09:19:45.553835.553835 cuda_h.py:19] end layer_moe_generate_23 cost 0.11678838729858398 seconds
DEBUG 01-05 09:19:45.553368.553368 lmp.py:214] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 09:19:45.553853.553853 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 09:19:45.553834.553834 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.553189.553189 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.556413.556413 cuda_h.py:19] end self_attn cost 0.0026705265045166016 seconds
DEBUG 01-05 09:19:45.556642.556642 cuda_h.py:19] end iln_self_attn_paln cost 0.0033397674560546875 seconds
DEBUG 01-05 09:19:45.557631.557631 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 09:19:45.557016.557016 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.557483.557483 cuda_h.py:19] end gate cost 0.0006601810455322266 seconds
DEBUG 01-05 09:19:45.557836.557836 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.558727.558727 lmp.py:361] 
DEBUG 01-05 09:19:45.558727.558727 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.558960.558960 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.558610.558610 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.558398.558398 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.558803.558803 lmp.py:365] 
DEBUG 01-05 09:19:45.558803.558803 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.558969.558969 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.558619.558619 lmp.py:372]   Expert 43 |     57 | CPU
DEBUG 01-05 09:19:45.558262.558262 lmp.py:372]   Expert 47 |     60 | CPU
DEBUG 01-05 09:19:45.558190.558190 lmp.py:372]   Expert 42 |     66 | CPU
DEBUG 01-05 09:19:45.558640.558640 lmp.py:372]   Expert  6 |     73 | CPU
DEBUG 01-05 09:19:45.558807.558807 lmp.py:372]   Expert 25 |     75 | CPU
DEBUG 01-05 09:19:45.558211.558211 lmp.py:372]   Expert 44 |     78 | CPU
DEBUG 01-05 09:19:45.558900.558900 lmp.py:372]   Expert 35 |     91 | CPU
DEBUG 01-05 09:19:45.558590.558590 lmp.py:372]   Expert 48 |     94 | CPU
DEBUG 01-05 09:19:45.558279.558279 lmp.py:372]   Expert 62 |     95 | CPU
DEBUG 01-05 09:19:45.558207.558207 lmp.py:372]   Expert  5 |    101 | CPU
DEBUG 01-05 09:19:45.558658.558658 lmp.py:372]   Expert 16 |    102 | CPU
DEBUG 01-05 09:19:45.558347.558347 lmp.py:372]   Expert 60 |    111 | CPU
DEBUG 01-05 09:19:45.558798.558798 lmp.py:372]   Expert 54 |    112 | CPU
DEBUG 01-05 09:19:45.558726.558726 lmp.py:372]   Expert 55 |    113 | CPU
DEBUG 01-05 09:19:45.558892.558892 lmp.py:372]   Expert 29 |    122 | CPU
DEBUG 01-05 09:19:45.558343.558343 lmp.py:372]   Expert 30 |    122 | CPU
DEBUG 01-05 09:19:45.558793.558793 lmp.py:372]   Expert 56 |    123 | CPU
DEBUG 01-05 09:19:45.558244.558244 lmp.py:372]   Expert 22 |    124 | CPU
DEBUG 01-05 09:19:45.558695.558695 lmp.py:372]   Expert 51 |    141 | CPU
DEBUG 01-05 09:19:45.558669.558669 lmp.py:372]   Expert 36 |    145 | CPU
DEBUG 01-05 09:19:45.558882.558882 lmp.py:372]   Expert  4 |    154 | CPU
DEBUG 01-05 09:19:45.558478.558478 lmp.py:372]   Expert  7 |    157 | CPU
DEBUG 01-05 09:19:45.558360.558360 lmp.py:372]   Expert 61 |    161 | CPU
DEBUG 01-05 09:19:45.558049.558049 lmp.py:372]   Expert  1 |    164 | CPU
DEBUG 01-05 09:19:45.558738.558738 lmp.py:372]   Expert 21 |    166 | CPU
DEBUG 01-05 09:19:45.558189.558189 lmp.py:372]   Expert 38 |    166 | CPU
DEBUG 01-05 09:19:45.558402.558402 lmp.py:372]   Expert 28 |    167 | CPU
DEBUG 01-05 09:19:45.558091.558091 lmp.py:372]   Expert 59 |    168 | CPU
DEBUG 01-05 09:19:45.558303.558303 lmp.py:372]   Expert 17 |    169 | CPU
DEBUG 01-05 09:19:45.558516.558516 lmp.py:372]   Expert 20 |    171 | CPU
DEBUG 01-05 09:19:45.558490.558490 lmp.py:372]   Expert 49 |    171 | CPU
DEBUG 01-05 09:19:45.558179.558179 lmp.py:372]   Expert 31 |    181 | CPU
DEBUG 01-05 09:19:45.558869.558869 lmp.py:372]   Expert  0 |    186 | GPU
DEBUG 01-05 09:19:45.558843.558843 lmp.py:372]   Expert 15 |    192 | GPU
DEBUG 01-05 09:19:45.558293.558293 lmp.py:372]   Expert 41 |    194 | GPU
DEBUG 01-05 09:19:45.558744.558744 lmp.py:372]   Expert 46 |    194 | GPU
DEBUG 01-05 09:19:45.558195.558195 lmp.py:372]   Expert 40 |    201 | GPU
DEBUG 01-05 09:19:45.558361.558361 lmp.py:372]   Expert  3 |    202 | GPU
DEBUG 01-05 09:19:45.558289.558289 lmp.py:372]   Expert 14 |    203 | GPU
DEBUG 01-05 09:19:45.558740.558740 lmp.py:372]   Expert 63 |    203 | GPU
DEBUG 01-05 09:19:45.558191.558191 lmp.py:372]   Expert 53 |    205 | GPU
DEBUG 01-05 09:19:45.558642.558642 lmp.py:372]   Expert 19 |    206 | GPU
DEBUG 01-05 09:19:45.558616.558616 lmp.py:372]   Expert 34 |    217 | GPU
DEBUG 01-05 09:19:45.558828.558828 lmp.py:372]   Expert 24 |    218 | GPU
DEBUG 01-05 09:19:45.558756.558756 lmp.py:372]   Expert  2 |    220 | GPU
DEBUG 01-05 09:19:45.559684.559684 lmp.py:372]   Expert 10 |    222 | GPU
DEBUG 01-05 09:19:45.559896.559896 lmp.py:372]   Expert 37 |    223 | GPU
DEBUG 01-05 09:19:45.559109.559109 lmp.py:372]   Expert 57 |    223 | GPU
DEBUG 01-05 09:19:45.559321.559321 lmp.py:372]   Expert 32 |    228 | GPU
DEBUG 01-05 09:19:45.559295.559295 lmp.py:372]   Expert 50 |    239 | GPU
DEBUG 01-05 09:19:45.559508.559508 lmp.py:372]   Expert 23 |    241 | GPU
DEBUG 01-05 09:19:45.559720.559720 lmp.py:372]   Expert 26 |    247 | GPU
DEBUG 01-05 09:19:45.559456.559456 lmp.py:372]   Expert 45 |    249 | GPU
DEBUG 01-05 09:19:45.559907.559907 lmp.py:372]   Expert 58 |    255 | GPU
DEBUG 01-05 09:19:45.559596.559596 lmp.py:372]   Expert 52 |    262 | GPU
DEBUG 01-05 09:19:45.559047.559047 lmp.py:372]   Expert  9 |    276 | GPU
DEBUG 01-05 09:19:45.559259.559259 lmp.py:372]   Expert 12 |    283 | GPU
DEBUG 01-05 09:19:45.559710.559710 lmp.py:372]   Expert 18 |    294 | GPU
DEBUG 01-05 09:19:45.559883.559883 lmp.py:372]   Expert 13 |    319 | GPU
DEBUG 01-05 09:19:45.559095.559095 lmp.py:372]   Expert 39 |    329 | GPU
DEBUG 01-05 09:19:45.559546.559546 lmp.py:372]   Expert 33 |    335 | GPU
DEBUG 01-05 09:19:45.559520.559520 lmp.py:372]   Expert  8 |    366 | GPU
DEBUG 01-05 09:19:45.559971.559971 lmp.py:372]   Expert 11 |    386 | GPU
DEBUG 01-05 09:19:45.559899.559899 lmp.py:372]   Expert 27 |    670 | GPU
DEBUG 01-05 09:19:45.559065.559065 lmp.py:373] 
DEBUG 01-05 09:19:45.559065.559065 lmp.py:373]   CPU total tokens: 4000 (32.6%)
DEBUG 01-05 09:19:45.559231.559231 lmp.py:374]   GPU total tokens: 8288 (67.4%)
DEBUG 01-05 09:19:45.559927.559927 cuda_h.py:19] end experts_map_get cost 0.0015139579772949219 seconds
DEBUG 01-05 09:19:45.559332.559332 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.559354.559354 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.559823.559823 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.559541.559541 cuda_h.py:19] end allocate_cuda_memory cost 0.0002512931823730469 seconds
DEBUG 01-05 09:19:45.559391.559391 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.559193.559193 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.560055.560055 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.560228.560228 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, db9d4050-ac6c-4291-b42e-3b14ad79b0ee
DEBUG 01-05 09:19:45.560881.560881 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.561598.561598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, db9d4050-ac6c-4291-b42e-3b14ad79b0ee
DEBUG 01-05 09:19:45.561719.561719 cuda_h.py:19] end load_into_gpu_async cost 0.001264333724975586 seconds
DEBUG 01-05 09:19:45.561991.561991 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.561352.561352 cuda_h.py:19] end restore_tensors2 cost 0.0004506111145019531 seconds
DEBUG 01-05 09:19:45.561380.561380 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002347230911254883 seconds
DEBUG 01-05 09:19:45.564752.564752 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005198001861572266 seconds
DEBUG 01-05 09:19:45.564708.564708 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.564439.564439 lmp.py:419] 
DEBUG 01-05 09:19:45.564439.564439 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.564667.564667 cuda_h.py:19] end cpu_experts_submit cost 0.00011682510375976562 seconds
DEBUG 01-05 09:19:45.564747.564747 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.575309.575309 mlpmodule.py:704] group tensors cost 0.010300397872924805 s
DEBUG 01-05 09:19:45.577233.577233 mlpmodule.py:742] pad cost 0.0015671253204345703 s
DEBUG 01-05 09:19:45.577139.577139 mlpmodule.py:748] create cpu tensor cost 7.295608520507812e-05 s
DEBUG 01-05 09:19:45.577373.577373 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-05 09:19:45.589258.589258 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.589132.589132 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.589460.589460 mlpmodule.py:773] group_w3 first element: -0.019287109375
WARNING 01-05 09:19:45.589352.589352 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.609651.609651 mlpmodule.py:793] group einsum cost 0.031167030334472656 s
DEBUG 01-05 09:19:45.610234.610234 mlpmodule.py:801] cpy2cputensor cost 0.0007894039154052734 s
DEBUG 01-05 09:19:45.651583.651583 cuda_h.py:19] end wait_cetm_experts cost 0.08624887466430664 seconds
DEBUG 01-05 09:19:45.651666.651666 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.651173.651173 cuda_h.py:19] end gpu_sexperts cost 0.0004730224609375 seconds
DEBUG 01-05 09:19:45.651155.651155 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:19:45.651163.651163 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:19:45.651934.651934 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.886222839355469e-05 seconds
DEBUG 01-05 09:19:45.651597.651597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 8.034706115722656e-05 seconds
DEBUG 01-05 09:19:45.651439.651439 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.652401.652401 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, db9d4050-ac6c-4291-b42e-3b14ad79b0ee
DEBUG 01-05 09:19:45.652016.652016 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.652709.652709 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.652652.652652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.656701.656701 cuda_h.py:19] end allocate_cuda_memory cost 0.0037529468536376953 seconds
INFO 01-05 09:19:45.656992.656992 client.py:127] Model loaded
DEBUG 01-05 09:19:45.656765.656765 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.656378.656378 cuda_h.py:19] end wait_experts cost 0.004657745361328125 seconds
DEBUG 01-05 09:19:45.656228.656228 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.656554.656554 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.656042.656042 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:45.657465.657465 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.657190.657190 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 393f1f00-8a07-4a16-b2bd-cb9bdac96bb0
DEBUG 01-05 09:19:45.657666.657666 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:45.657984.657984 mlpmodule.py:531] gpu group tensors cost 0.0009572505950927734 s
INFO 01-05 09:19:45.658206.658206 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 393f1f00-8a07-4a16-b2bd-cb9bdac96bb0
DEBUG 01-05 09:19:45.658470.658470 cuda_h.py:19] end load_into_gpu_async cost 0.0020933151245117188 seconds
DEBUG 01-05 09:19:45.659542.659542 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.659114.659114 cuda_h.py:19] end restore_tensors2 cost 0.00017142295837402344 seconds
DEBUG 01-05 09:19:45.659980.659980 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007050752639770508 seconds
INFO 01-05 09:19:45.660781.660781 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 393f1f00-8a07-4a16-b2bd-cb9bdac96bb0
DEBUG 01-05 09:19:45.661303.661303 mlpmodule.py:564] gpu pad cost 0.00391840934753418 s
DEBUG 01-05 09:19:45.662730.662730 mlpmodule.py:582] gpu group einsum cost 0.0005850791931152344 s
DEBUG 01-05 09:19:45.664191.664191 mlpmodule.py:662]  experts func einsum cost 0.09994173049926758 s
DEBUG 01-05 09:19:45.666563.666563 mlpmodule.py:611] gpu experts func einsum cost 0.009143829345703125 s
DEBUG 01-05 09:19:45.666520.666520 cuda_h.py:19] end gpu_experts cost 0.009345054626464844 seconds
DEBUG 01-05 09:19:45.666514.666514 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:45.669081.669081 client.py:127] Model loaded
DEBUG 01-05 09:19:45.669232.669232 cuda_h.py:19] end sllm_worker_task cost 0.01719832420349121 seconds
DEBUG 01-05 09:19:45.669881.669881 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0033893585205078125 seconds
DEBUG 01-05 09:19:45.669715.669715 cuda_h.py:19] end layer_moe_generate_24 cost 0.11284184455871582 seconds
DEBUG 01-05 09:19:45.670702.670702 lmp.py:214] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 09:19:45.670518.670518 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 09:19:45.670214.670214 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.670515.670515 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.673409.673409 cuda_h.py:19] end self_attn cost 0.002497434616088867 seconds
DEBUG 01-05 09:19:45.673869.673869 cuda_h.py:19] end iln_self_attn_paln cost 0.00312042236328125 seconds
DEBUG 01-05 09:19:45.673235.673235 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 09:19:45.673621.673621 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.674430.674430 cuda_h.py:19] end gate cost 0.0005967617034912109 seconds
DEBUG 01-05 09:19:45.674544.674544 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.674998.674998 lmp.py:361] 
DEBUG 01-05 09:19:45.674998.674998 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.674516.674516 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.674404.674404 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.674193.674193 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.674835.674835 lmp.py:365] 
DEBUG 01-05 09:19:45.674835.674835 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.674240.674240 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.674128.674128 lmp.py:372]   Expert 36 |     46 | CPU
DEBUG 01-05 09:19:45.674248.674248 lmp.py:372]   Expert 33 |     51 | CPU
DEBUG 01-05 09:19:45.674414.674414 lmp.py:372]   Expert 42 |     54 | CPU
DEBUG 01-05 09:19:45.674342.674342 lmp.py:372]   Expert 18 |     61 | CPU
DEBUG 01-05 09:19:45.674031.674031 lmp.py:372]   Expert  0 |     68 | CPU
DEBUG 01-05 09:19:45.674959.674959 lmp.py:372]   Expert 13 |     71 | CPU
DEBUG 01-05 09:19:45.674410.674410 lmp.py:372]   Expert 16 |     80 | CPU
DEBUG 01-05 09:19:45.674530.674530 lmp.py:372]   Expert 21 |     85 | CPU
DEBUG 01-05 09:19:45.674742.674742 lmp.py:372]   Expert 47 |     85 | CPU
DEBUG 01-05 09:19:45.674193.674193 lmp.py:372]   Expert 10 |     89 | CPU
DEBUG 01-05 09:19:45.674644.674644 lmp.py:372]   Expert 22 |     91 | CPU
DEBUG 01-05 09:19:45.674618.674618 lmp.py:372]   Expert 38 |    100 | CPU
DEBUG 01-05 09:19:45.674307.674307 lmp.py:372]   Expert 62 |    101 | CPU
DEBUG 01-05 09:19:45.674520.674520 lmp.py:372]   Expert 27 |    109 | CPU
DEBUG 01-05 09:19:45.674209.674209 lmp.py:372]   Expert  5 |    110 | CPU
DEBUG 01-05 09:19:45.674660.674660 lmp.py:372]   Expert 50 |    114 | CPU
DEBUG 01-05 09:19:45.674064.674064 lmp.py:372]   Expert 59 |    114 | CPU
DEBUG 01-05 09:19:45.674184.674184 lmp.py:372]   Expert 43 |    115 | CPU
DEBUG 01-05 09:19:45.674350.674350 lmp.py:372]   Expert 53 |    117 | CPU
DEBUG 01-05 09:19:45.674563.674563 lmp.py:372]   Expert 34 |    119 | CPU
DEBUG 01-05 09:19:45.674252.674252 lmp.py:372]   Expert 14 |    121 | CPU
DEBUG 01-05 09:19:45.674703.674703 lmp.py:372]   Expert  2 |    122 | CPU
DEBUG 01-05 09:19:45.674108.674108 lmp.py:372]   Expert 56 |    133 | CPU
DEBUG 01-05 09:19:45.674751.674751 lmp.py:372]   Expert 32 |    136 | CPU
DEBUG 01-05 09:19:45.674917.674917 lmp.py:372]   Expert 24 |    138 | CPU
DEBUG 01-05 09:19:45.674368.674368 lmp.py:372]   Expert  4 |    142 | CPU
DEBUG 01-05 09:19:45.674580.674580 lmp.py:372]   Expert 20 |    143 | CPU
DEBUG 01-05 09:19:45.674031.674031 lmp.py:372]   Expert 41 |    145 | CPU
DEBUG 01-05 09:19:45.675720.675720 lmp.py:372]   Expert 48 |    146 | CPU
DEBUG 01-05 09:19:45.675171.675171 lmp.py:372]   Expert 23 |    149 | CPU
DEBUG 01-05 09:19:45.675622.675622 lmp.py:372]   Expert 44 |    150 | CPU
DEBUG 01-05 09:19:45.675788.675788 lmp.py:372]   Expert 55 |    154 | CPU
DEBUG 01-05 09:19:45.675193.675193 lmp.py:372]   Expert 31 |    158 | GPU
DEBUG 01-05 09:19:45.675644.675644 lmp.py:372]   Expert 45 |    164 | GPU
DEBUG 01-05 09:19:45.675856.675856 lmp.py:372]   Expert 46 |    167 | GPU
DEBUG 01-05 09:19:45.675830.675830 lmp.py:372]   Expert  3 |    169 | GPU
DEBUG 01-05 09:19:45.675042.675042 lmp.py:372]   Expert 51 |    182 | GPU
DEBUG 01-05 09:19:45.675255.675255 lmp.py:372]   Expert 39 |    186 | GPU
DEBUG 01-05 09:19:45.675467.675467 lmp.py:372]   Expert  6 |    189 | GPU
DEBUG 01-05 09:19:45.675395.675395 lmp.py:372]   Expert 52 |    194 | GPU
DEBUG 01-05 09:19:45.675800.675800 lmp.py:372]   Expert 61 |    201 | GPU
DEBUG 01-05 09:19:45.675251.675251 lmp.py:372]   Expert  8 |    203 | GPU
DEBUG 01-05 09:19:45.675701.675701 lmp.py:372]   Expert 12 |    219 | GPU
DEBUG 01-05 09:19:45.675676.675676 lmp.py:372]   Expert  1 |    222 | GPU
DEBUG 01-05 09:19:45.675888.675888 lmp.py:372]   Expert 35 |    223 | GPU
DEBUG 01-05 09:19:45.675100.675100 lmp.py:372]   Expert 40 |    227 | GPU
DEBUG 01-05 09:19:45.675313.675313 lmp.py:372]   Expert 11 |    236 | GPU
DEBUG 01-05 09:19:45.675525.675525 lmp.py:372]   Expert  7 |    246 | GPU
DEBUG 01-05 09:19:45.675215.675215 lmp.py:372]   Expert 15 |    255 | GPU
DEBUG 01-05 09:19:45.675381.675381 lmp.py:372]   Expert 49 |    262 | GPU
DEBUG 01-05 09:19:45.675355.675355 lmp.py:372]   Expert 57 |    274 | GPU
DEBUG 01-05 09:19:45.675567.675567 lmp.py:372]   Expert 37 |    276 | GPU
DEBUG 01-05 09:19:45.675541.675541 lmp.py:372]   Expert 26 |    289 | GPU
DEBUG 01-05 09:19:45.675277.675277 lmp.py:372]   Expert 28 |    297 | GPU
DEBUG 01-05 09:19:45.675251.675251 lmp.py:372]   Expert 30 |    303 | GPU
DEBUG 01-05 09:19:45.675225.675225 lmp.py:372]   Expert 58 |    314 | GPU
DEBUG 01-05 09:19:45.675199.675199 lmp.py:372]   Expert 63 |    327 | GPU
DEBUG 01-05 09:19:45.675365.675365 lmp.py:372]   Expert 25 |    349 | GPU
DEBUG 01-05 09:19:45.675293.675293 lmp.py:372]   Expert 54 |    373 | GPU
DEBUG 01-05 09:19:45.675267.675267 lmp.py:372]   Expert  9 |    400 | GPU
DEBUG 01-05 09:19:45.675479.675479 lmp.py:372]   Expert 17 |    421 | GPU
DEBUG 01-05 09:19:45.675692.675692 lmp.py:372]   Expert 60 |    457 | GPU
DEBUG 01-05 09:19:45.675666.675666 lmp.py:372]   Expert 29 |    475 | GPU
DEBUG 01-05 09:19:45.675640.675640 lmp.py:372]   Expert 19 |    571 | GPU
DEBUG 01-05 09:19:45.675806.675806 lmp.py:373] 
DEBUG 01-05 09:19:45.675806.675806 lmp.py:373]   CPU total tokens: 3459 (28.1%)
DEBUG 01-05 09:19:45.675734.675734 lmp.py:374]   GPU total tokens: 8829 (71.9%)
DEBUG 01-05 09:19:45.675715.675715 cuda_h.py:19] end experts_map_get cost 0.0015017986297607422 seconds
DEBUG 01-05 09:19:45.675642.675642 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.675618.675618 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.675279.675279 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.676686.676686 cuda_h.py:19] end allocate_cuda_memory cost 0.0002646446228027344 seconds
DEBUG 01-05 09:19:45.676821.676821 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.676100.676100 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.676486.676486 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.676420.676420 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0bc349bb-dab7-4d63-8023-52a218fe1846
DEBUG 01-05 09:19:45.676960.676960 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.677639.677639 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0bc349bb-dab7-4d63-8023-52a218fe1846
DEBUG 01-05 09:19:45.677045.677045 cuda_h.py:19] end load_into_gpu_async cost 0.0015034675598144531 seconds
DEBUG 01-05 09:19:45.677032.677032 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.678603.678603 cuda_h.py:19] end restore_tensors2 cost 0.0003943443298339844 seconds
DEBUG 01-05 09:19:45.678432.678432 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025434494018554688 seconds
DEBUG 01-05 09:19:45.681247.681247 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053691864013671875 seconds
DEBUG 01-05 09:19:45.681937.681937 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.681377.681377 lmp.py:419] 
DEBUG 01-05 09:19:45.681377.681377 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.681220.681220 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-05 09:19:45.681777.681777 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.693811.693811 mlpmodule.py:704] group tensors cost 0.012132406234741211 s
DEBUG 01-05 09:19:45.695701.695701 mlpmodule.py:742] pad cost 0.0015611648559570312 s
DEBUG 01-05 09:19:45.696181.696181 mlpmodule.py:748] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-05 09:19:45.696389.696389 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-05 09:19:45.706447.706447 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.706791.706791 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.707264.707264 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 09:19:45.707871.707871 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.726150.726150 mlpmodule.py:793] group einsum cost 0.029767990112304688 s
DEBUG 01-05 09:19:45.726518.726518 mlpmodule.py:801] cpy2cputensor cost 0.0006887912750244141 s
DEBUG 01-05 09:19:45.767983.767983 cuda_h.py:19] end wait_cetm_experts cost 0.08599424362182617 seconds
DEBUG 01-05 09:19:45.767198.767198 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.767499.767499 cuda_h.py:19] end gpu_sexperts cost 0.0004611015319824219 seconds
DEBUG 01-05 09:19:45.767104.767104 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:19:45.767781.767781 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:19:45.768452.768452 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.528594970703125e-05 seconds
DEBUG 01-05 09:19:45.768023.768023 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.915496826171875e-05 seconds
DEBUG 01-05 09:19:45.768441.768441 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.768912.768912 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0bc349bb-dab7-4d63-8023-52a218fe1846
DEBUG 01-05 09:19:45.768484.768484 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.768811.768811 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.768556.768556 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.772801.772801 cuda_h.py:19] end allocate_cuda_memory cost 0.0034847259521484375 seconds
DEBUG 01-05 09:19:45.772872.772872 cuda_h.py:10] start load_into_gpu_async
INFO 01-05 09:19:45.772466.772466 client.py:127] Model loaded
DEBUG 01-05 09:19:45.772243.772243 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.772915.772915 cuda_h.py:19] end wait_experts cost 0.00442194938659668 seconds
DEBUG 01-05 09:19:45.772056.772056 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.772934.772934 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 50f34ec3-340f-4dba-ac11-da2efda50a96
DEBUG 01-05 09:19:45.772535.772535 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:45.772515.772515 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.773354.773354 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.773051.773051 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 50f34ec3-340f-4dba-ac11-da2efda50a96
DEBUG 01-05 09:19:45.773968.773968 cuda_h.py:19] end load_into_gpu_async cost 0.0012764930725097656 seconds
DEBUG 01-05 09:19:45.773877.773877 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.773040.773040 cuda_h.py:19] end restore_tensors2 cost 8.797645568847656e-05 seconds
DEBUG 01-05 09:19:45.773716.773716 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005410671234130859 seconds
DEBUG 01-05 09:19:45.774159.774159 mlpmodule.py:531] gpu group tensors cost 0.0012001991271972656 s
INFO 01-05 09:19:45.774657.774657 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 50f34ec3-340f-4dba-ac11-da2efda50a96
DEBUG 01-05 09:19:45.776550.776550 mlpmodule.py:564] gpu pad cost 0.0020704269409179688 s
DEBUG 01-05 09:19:45.777923.777923 mlpmodule.py:582] gpu group einsum cost 0.0005636215209960938 s
DEBUG 01-05 09:19:45.780603.780603 mlpmodule.py:662]  experts func einsum cost 0.09890365600585938 s
DEBUG 01-05 09:19:45.780120.780120 mlpmodule.py:611] gpu experts func einsum cost 0.0077364444732666016 s
DEBUG 01-05 09:19:45.780422.780422 cuda_h.py:19] end gpu_experts cost 0.007955312728881836 seconds
DEBUG 01-05 09:19:45.781231.781231 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:45.783359.783359 client.py:127] Model loaded
DEBUG 01-05 09:19:45.783241.783241 cuda_h.py:19] end sllm_worker_task cost 0.014830589294433594 seconds
DEBUG 01-05 09:19:45.783869.783869 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002395153045654297 seconds
DEBUG 01-05 09:19:45.783689.783689 cuda_h.py:19] end layer_moe_generate_25 cost 0.11023545265197754 seconds
DEBUG 01-05 09:19:45.783007.783007 lmp.py:214] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 09:19:45.783307.783307 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 09:19:45.783718.783718 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.784661.784661 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.786831.786831 cuda_h.py:19] end self_attn cost 0.0024573802947998047 seconds
DEBUG 01-05 09:19:45.787484.787484 cuda_h.py:19] end iln_self_attn_paln cost 0.0030622482299804688 seconds
DEBUG 01-05 09:19:45.787804.787804 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 09:19:45.787997.787997 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.787693.787693 cuda_h.py:19] end gate cost 0.0005853176116943359 seconds
DEBUG 01-05 09:19:45.787476.787476 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.788169.788169 lmp.py:361] 
DEBUG 01-05 09:19:45.788169.788169 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.788163.788163 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.788766.788766 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.788270.788270 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.788675.788675 lmp.py:365] 
DEBUG 01-05 09:19:45.788675.788675 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.788364.788364 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.788491.788491 lmp.py:372]   Expert 17 |     47 | CPU
DEBUG 01-05 09:19:45.788372.788372 lmp.py:372]   Expert 30 |     56 | CPU
DEBUG 01-05 09:19:45.788300.788300 lmp.py:372]   Expert  3 |     60 | CPU
DEBUG 01-05 09:19:45.788513.788513 lmp.py:372]   Expert 62 |     64 | CPU
DEBUG 01-05 09:19:45.788917.788917 lmp.py:372]   Expert 58 |     68 | CPU
DEBUG 01-05 09:19:45.788083.788083 lmp.py:372]   Expert 49 |     69 | CPU
DEBUG 01-05 09:19:45.788534.788534 lmp.py:372]   Expert 59 |     75 | CPU
DEBUG 01-05 09:19:45.788747.788747 lmp.py:372]   Expert 61 |     78 | CPU
DEBUG 01-05 09:19:45.788959.788959 lmp.py:372]   Expert 19 |     80 | CPU
DEBUG 01-05 09:19:45.788933.788933 lmp.py:372]   Expert 24 |     80 | CPU
DEBUG 01-05 09:19:45.788146.788146 lmp.py:372]   Expert 55 |     81 | CPU
DEBUG 01-05 09:19:45.788226.788226 lmp.py:372]   Expert 51 |     84 | CPU
DEBUG 01-05 09:19:45.788392.788392 lmp.py:372]   Expert  9 |     89 | CPU
DEBUG 01-05 09:19:45.788320.788320 lmp.py:372]   Expert  7 |     92 | CPU
DEBUG 01-05 09:19:45.788294.788294 lmp.py:372]   Expert  6 |     95 | CPU
DEBUG 01-05 09:19:45.788268.788268 lmp.py:372]   Expert 56 |    101 | CPU
DEBUG 01-05 09:19:45.788003.788003 lmp.py:372]   Expert  8 |    103 | CPU
DEBUG 01-05 09:19:45.788977.788977 lmp.py:372]   Expert 21 |    103 | CPU
DEBUG 01-05 09:19:45.788951.788951 lmp.py:372]   Expert 15 |    106 | CPU
DEBUG 01-05 09:19:45.788687.788687 lmp.py:372]   Expert 60 |    112 | CPU
DEBUG 01-05 09:19:45.788900.788900 lmp.py:372]   Expert 11 |    113 | CPU
DEBUG 01-05 09:19:45.788827.788827 lmp.py:372]   Expert 12 |    118 | CPU
DEBUG 01-05 09:19:45.788993.788993 lmp.py:372]   Expert 13 |    118 | CPU
DEBUG 01-05 09:19:45.788206.788206 lmp.py:372]   Expert 43 |    119 | CPU
DEBUG 01-05 09:19:45.788180.788180 lmp.py:372]   Expert 27 |    128 | CPU
DEBUG 01-05 09:19:45.788631.788631 lmp.py:372]   Expert  0 |    130 | CPU
DEBUG 01-05 09:19:45.788605.788605 lmp.py:372]   Expert 38 |    132 | CPU
DEBUG 01-05 09:19:45.788579.788579 lmp.py:372]   Expert 53 |    138 | CPU
DEBUG 01-05 09:19:45.788030.788030 lmp.py:372]   Expert 41 |    139 | CPU
DEBUG 01-05 09:19:45.788004.788004 lmp.py:372]   Expert 26 |    142 | CPU
DEBUG 01-05 09:19:45.788932.788932 lmp.py:372]   Expert 29 |    143 | CPU
DEBUG 01-05 09:19:45.788621.788621 lmp.py:372]   Expert 47 |    145 | CPU
DEBUG 01-05 09:19:45.788310.788310 lmp.py:372]   Expert 28 |    146 | GPU
DEBUG 01-05 09:19:45.788284.788284 lmp.py:372]   Expert 22 |    147 | GPU
DEBUG 01-05 09:19:45.788497.788497 lmp.py:372]   Expert 45 |    154 | GPU
DEBUG 01-05 09:19:45.788948.788948 lmp.py:372]   Expert 34 |    163 | GPU
DEBUG 01-05 09:19:45.788922.788922 lmp.py:372]   Expert 48 |    163 | GPU
DEBUG 01-05 09:19:45.788372.788372 lmp.py:372]   Expert 37 |    168 | GPU
DEBUG 01-05 09:19:45.788585.788585 lmp.py:372]   Expert 57 |    168 | GPU
DEBUG 01-05 09:19:45.788559.788559 lmp.py:372]   Expert 32 |    187 | GPU
DEBUG 01-05 09:19:45.788248.788248 lmp.py:372]   Expert 23 |    192 | GPU
DEBUG 01-05 09:19:45.788414.788414 lmp.py:372]   Expert  1 |    193 | GPU
DEBUG 01-05 09:19:45.788865.788865 lmp.py:372]   Expert 42 |    204 | GPU
DEBUG 01-05 09:19:45.788316.788316 lmp.py:372]   Expert 36 |    220 | GPU
DEBUG 01-05 09:19:45.788290.788290 lmp.py:372]   Expert 39 |    226 | GPU
DEBUG 01-05 09:19:45.788503.788503 lmp.py:372]   Expert  4 |    227 | GPU
DEBUG 01-05 09:19:45.788477.788477 lmp.py:372]   Expert 54 |    236 | GPU
DEBUG 01-05 09:19:45.788451.788451 lmp.py:372]   Expert 31 |    244 | GPU
DEBUG 01-05 09:19:45.789140.789140 lmp.py:372]   Expert 20 |    249 | GPU
DEBUG 01-05 09:19:45.789306.789306 lmp.py:372]   Expert 16 |    252 | GPU
DEBUG 01-05 09:19:45.789519.789519 lmp.py:372]   Expert 33 |    269 | GPU
DEBUG 01-05 09:19:45.789254.789254 lmp.py:372]   Expert  2 |    286 | GPU
DEBUG 01-05 09:19:45.789467.789467 lmp.py:372]   Expert 44 |    302 | GPU
DEBUG 01-05 09:19:45.789202.789202 lmp.py:372]   Expert  5 |    312 | GPU
DEBUG 01-05 09:19:45.789415.789415 lmp.py:372]   Expert 18 |    321 | GPU
DEBUG 01-05 09:19:45.789389.789389 lmp.py:372]   Expert 50 |    321 | GPU
DEBUG 01-05 09:19:45.789363.789363 lmp.py:372]   Expert 10 |    343 | GPU
DEBUG 01-05 09:19:45.789337.789337 lmp.py:372]   Expert 25 |    345 | GPU
DEBUG 01-05 09:19:45.789073.789073 lmp.py:372]   Expert 35 |    365 | GPU
DEBUG 01-05 09:19:45.789000.789000 lmp.py:372]   Expert 63 |    396 | GPU
DEBUG 01-05 09:19:45.789166.789166 lmp.py:372]   Expert 40 |    457 | GPU
DEBUG 01-05 09:19:45.789617.789617 lmp.py:372]   Expert 46 |    470 | GPU
DEBUG 01-05 09:19:45.789353.789353 lmp.py:372]   Expert 52 |    540 | GPU
DEBUG 01-05 09:19:45.789565.789565 lmp.py:372]   Expert 14 |    814 | GPU
DEBUG 01-05 09:19:45.789493.789493 lmp.py:373] 
DEBUG 01-05 09:19:45.789493.789493 lmp.py:373]   CPU total tokens: 3208 (26.1%)
DEBUG 01-05 09:19:45.789421.789421 lmp.py:374]   GPU total tokens: 9080 (73.9%)
DEBUG 01-05 09:19:45.789640.789640 cuda_h.py:19] end experts_map_get cost 0.001497030258178711 seconds
DEBUG 01-05 09:19:45.789806.789806 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.789682.789682 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.789594.789594 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.789882.789882 cuda_h.py:19] end allocate_cuda_memory cost 0.000247955322265625 seconds
DEBUG 01-05 09:19:45.789778.789778 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.789580.789580 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.789250.789250 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.789900.789900 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a463d379-a78c-486f-93f0-38ecb0cdf5db
DEBUG 01-05 09:19:45.790876.790876 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.791114.791114 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a463d379-a78c-486f-93f0-38ecb0cdf5db
DEBUG 01-05 09:19:45.791235.791235 cuda_h.py:19] end load_into_gpu_async cost 0.0013589859008789062 seconds
DEBUG 01-05 09:19:45.791223.791223 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.791575.791575 cuda_h.py:19] end restore_tensors2 cost 0.0004074573516845703 seconds
DEBUG 01-05 09:19:45.791742.791742 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002373933792114258 seconds
DEBUG 01-05 09:19:45.794943.794943 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005235433578491211 seconds
DEBUG 01-05 09:19:45.794348.794348 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.794855.794855 lmp.py:419] 
DEBUG 01-05 09:19:45.794855.794855 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.794791.794791 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-05 09:19:45.794394.794394 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.800735.800735 mlpmodule.py:704] group tensors cost 0.005696535110473633 s
DEBUG 01-05 09:19:45.803412.803412 mlpmodule.py:742] pad cost 0.001971006393432617 s
DEBUG 01-05 09:19:45.803549.803549 mlpmodule.py:748] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-05 09:19:45.803757.803757 mlpmodule.py:753] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-05 09:19:45.814858.814858 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.814434.814434 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.814623.814623 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 09:19:45.814084.814084 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.833171.833171 mlpmodule.py:793] group einsum cost 0.029671907424926758 s
DEBUG 01-05 09:19:45.834308.834308 mlpmodule.py:801] cpy2cputensor cost 0.0007507801055908203 s
DEBUG 01-05 09:19:45.875846.875846 cuda_h.py:19] end wait_cetm_experts cost 0.0810847282409668 seconds
DEBUG 01-05 09:19:45.876882.876882 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.876773.876773 cuda_h.py:19] end gpu_sexperts cost 0.00047469139099121094 seconds
DEBUG 01-05 09:19:45.876424.876424 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:19:45.876194.876194 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:19:45.876249.876249 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.3855438232421875e-05 seconds
DEBUG 01-05 09:19:45.876913.876913 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.557868957519531e-05 seconds
DEBUG 01-05 09:19:45.876993.876993 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.876226.876226 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a463d379-a78c-486f-93f0-38ecb0cdf5db
DEBUG 01-05 09:19:45.876066.876066 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:45.877943.877943 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.877117.877117 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.880159.880159 cuda_h.py:19] end allocate_cuda_memory cost 0.003185749053955078 seconds
DEBUG 01-05 09:19:45.880904.880904 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.880766.880766 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.880834.880834 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.880636.880636 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 554dde68-b93b-4597-b30b-1997e3764ab5
DEBUG 01-05 09:19:45.880719.880719 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.884559.884559 client.py:127] Model loaded
DEBUG 01-05 09:19:45.884462.884462 cuda_h.py:19] end wait_experts cost 0.007827281951904297 seconds
DEBUG 01-05 09:19:45.884893.884893 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.884126.884126 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:45.885795.885795 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 554dde68-b93b-4597-b30b-1997e3764ab5
DEBUG 01-05 09:19:45.885082.885082 cuda_h.py:19] end load_into_gpu_async cost 0.0049021244049072266 seconds
DEBUG 01-05 09:19:45.885600.885600 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.885140.885140 cuda_h.py:19] end restore_tensors2 cost 8.749961853027344e-05 seconds
DEBUG 01-05 09:19:45.885426.885426 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008469581604003906 seconds
DEBUG 01-05 09:19:45.885225.885225 mlpmodule.py:531] gpu group tensors cost 0.0010764598846435547 s
INFO 01-05 09:19:45.886592.886592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 554dde68-b93b-4597-b30b-1997e3764ab5
DEBUG 01-05 09:19:45.888647.888647 mlpmodule.py:564] gpu pad cost 0.001971006393432617 s
DEBUG 01-05 09:19:45.888841.888841 mlpmodule.py:662]  experts func einsum cost 0.0933229923248291 s
DEBUG 01-05 09:19:45.888904.888904 mlpmodule.py:582] gpu group einsum cost 0.0006587505340576172 s
DEBUG 01-05 09:19:45.891538.891538 mlpmodule.py:611] gpu experts func einsum cost 0.007068157196044922 s
DEBUG 01-05 09:19:45.891574.891574 cuda_h.py:19] end gpu_experts cost 0.007248878479003906 seconds
DEBUG 01-05 09:19:45.891092.891092 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:45.896904.896904 client.py:127] Model loaded
DEBUG 01-05 09:19:45.896508.896508 cuda_h.py:19] end sllm_worker_task cost 0.019065380096435547 seconds
DEBUG 01-05 09:19:45.896206.896206 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004159688949584961 seconds
DEBUG 01-05 09:19:45.896675.896675 cuda_h.py:19] end layer_moe_generate_26 cost 0.10924744606018066 seconds
DEBUG 01-05 09:19:45.896615.896615 lmp.py:214] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 09:19:45.896809.896809 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 09:19:45.896313.896313 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:45.896925.896925 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:45.899678.899678 cuda_h.py:19] end self_attn cost 0.0024650096893310547 seconds
DEBUG 01-05 09:19:45.899423.899423 cuda_h.py:19] end iln_self_attn_paln cost 0.003071308135986328 seconds
DEBUG 01-05 09:19:45.899312.899312 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 09:19:45.899267.899267 cuda_h.py:10] start gate
DEBUG 01-05 09:19:45.900255.900255 cuda_h.py:19] end gate cost 0.0005886554718017578 seconds
DEBUG 01-05 09:19:45.900277.900277 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:45.900684.900684 lmp.py:361] 
DEBUG 01-05 09:19:45.900684.900684 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:45.900679.900679 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:45.900328.900328 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:45.900879.900879 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:45.900045.900045 lmp.py:365] 
DEBUG 01-05 09:19:45.900045.900045 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:45.900449.900449 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:45.900337.900337 lmp.py:372]   Expert 18 |     33 | CPU
DEBUG 01-05 09:19:45.900742.900742 lmp.py:372]   Expert 47 |     41 | CPU
DEBUG 01-05 09:19:45.900954.900954 lmp.py:372]   Expert 54 |     62 | CPU
DEBUG 01-05 09:19:45.900644.900644 lmp.py:372]   Expert 58 |     66 | CPU
DEBUG 01-05 09:19:45.900095.900095 lmp.py:372]   Expert 15 |     71 | CPU
DEBUG 01-05 09:19:45.901738.901738 lmp.py:372]   Expert 59 |     80 | CPU
DEBUG 01-05 09:19:45.901427.901427 lmp.py:372]   Expert 24 |     81 | CPU
DEBUG 01-05 09:19:45.901163.901163 lmp.py:372]   Expert 12 |     82 | CPU
DEBUG 01-05 09:19:45.901375.901375 lmp.py:372]   Expert 32 |     82 | CPU
DEBUG 01-05 09:19:45.901111.901111 lmp.py:372]   Expert  7 |     84 | CPU
DEBUG 01-05 09:19:45.901323.901323 lmp.py:372]   Expert 38 |     92 | CPU
DEBUG 01-05 09:19:45.901297.901297 lmp.py:372]   Expert 11 |     93 | CPU
DEBUG 01-05 09:19:45.901271.901271 lmp.py:372]   Expert 61 |     95 | CPU
DEBUG 01-05 09:19:45.901722.901722 lmp.py:372]   Expert 42 |    102 | CPU
DEBUG 01-05 09:19:45.901411.901411 lmp.py:372]   Expert 40 |    111 | CPU
DEBUG 01-05 09:19:45.901385.901385 lmp.py:372]   Expert 23 |    118 | CPU
DEBUG 01-05 09:19:45.901598.901598 lmp.py:372]   Expert 39 |    119 | CPU
DEBUG 01-05 09:19:45.901572.901572 lmp.py:372]   Expert 46 |    121 | CPU
DEBUG 01-05 09:19:45.901308.901308 lmp.py:372]   Expert  6 |    124 | CPU
DEBUG 01-05 09:19:45.901282.901282 lmp.py:372]   Expert 52 |    124 | CPU
DEBUG 01-05 09:19:45.901256.901256 lmp.py:372]   Expert 45 |    125 | CPU
DEBUG 01-05 09:19:45.901707.901707 lmp.py:372]   Expert 34 |    131 | CPU
DEBUG 01-05 09:19:45.901396.901396 lmp.py:372]   Expert 44 |    140 | CPU
DEBUG 01-05 09:19:45.901608.901608 lmp.py:372]   Expert 30 |    147 | CPU
DEBUG 01-05 09:19:45.901344.901344 lmp.py:372]   Expert 51 |    149 | CPU
DEBUG 01-05 09:19:45.901318.901318 lmp.py:372]   Expert 48 |    151 | CPU
DEBUG 01-05 09:19:45.901054.901054 lmp.py:372]   Expert 10 |    164 | CPU
DEBUG 01-05 09:19:45.901266.901266 lmp.py:372]   Expert 16 |    170 | CPU
DEBUG 01-05 09:19:45.901240.901240 lmp.py:372]   Expert 19 |    172 | CPU
DEBUG 01-05 09:19:45.901976.901976 lmp.py:372]   Expert  3 |    174 | CPU
DEBUG 01-05 09:19:45.901380.901380 lmp.py:372]   Expert  4 |    175 | CPU
DEBUG 01-05 09:19:45.901546.901546 lmp.py:372]   Expert 25 |    175 | CPU
DEBUG 01-05 09:19:45.901997.901997 lmp.py:372]   Expert 56 |    180 | GPU
DEBUG 01-05 09:19:45.901971.901971 lmp.py:372]   Expert 22 |    186 | GPU
DEBUG 01-05 09:19:45.901184.901184 lmp.py:372]   Expert 29 |    188 | GPU
DEBUG 01-05 09:19:45.901396.901396 lmp.py:372]   Expert 13 |    192 | GPU
DEBUG 01-05 09:19:45.901324.901324 lmp.py:372]   Expert 31 |    195 | GPU
DEBUG 01-05 09:19:45.901775.901775 lmp.py:372]   Expert  1 |    197 | GPU
DEBUG 01-05 09:19:45.901226.901226 lmp.py:372]   Expert 36 |    197 | GPU
DEBUG 01-05 09:19:45.901438.901438 lmp.py:372]   Expert 17 |    201 | GPU
DEBUG 01-05 09:19:45.901651.901651 lmp.py:372]   Expert 33 |    201 | GPU
DEBUG 01-05 09:19:45.901625.901625 lmp.py:372]   Expert 62 |    209 | GPU
DEBUG 01-05 09:19:45.901552.901552 lmp.py:372]   Expert 50 |    212 | GPU
DEBUG 01-05 09:19:45.901480.901480 lmp.py:372]   Expert 57 |    212 | GPU
DEBUG 01-05 09:19:45.901931.901931 lmp.py:372]   Expert  5 |    225 | GPU
DEBUG 01-05 09:19:45.901905.901905 lmp.py:372]   Expert  8 |    227 | GPU
DEBUG 01-05 09:19:45.901356.901356 lmp.py:372]   Expert 55 |    230 | GPU
DEBUG 01-05 09:19:45.901568.901568 lmp.py:372]   Expert 53 |    240 | GPU
DEBUG 01-05 09:19:45.901019.901019 lmp.py:372]   Expert  0 |    245 | GPU
DEBUG 01-05 09:19:45.901709.901709 lmp.py:372]   Expert 26 |    245 | GPU
DEBUG 01-05 09:19:45.901921.901921 lmp.py:372]   Expert 41 |    248 | GPU
DEBUG 01-05 09:19:45.901849.901849 lmp.py:372]   Expert 49 |    254 | GPU
DEBUG 01-05 09:19:45.901538.901538 lmp.py:372]   Expert 35 |    264 | GPU
DEBUG 01-05 09:19:45.901751.901751 lmp.py:372]   Expert 37 |    283 | GPU
DEBUG 01-05 09:19:45.901201.901201 lmp.py:372]   Expert 28 |    286 | GPU
DEBUG 01-05 09:19:45.901414.901414 lmp.py:372]   Expert 14 |    308 | GPU
DEBUG 01-05 09:19:45.901626.901626 lmp.py:372]   Expert 27 |    345 | GPU
DEBUG 01-05 09:19:45.901839.901839 lmp.py:372]   Expert  2 |    352 | GPU
DEBUG 01-05 09:19:45.901051.901051 lmp.py:372]   Expert 21 |    356 | GPU
DEBUG 01-05 09:19:45.901025.901025 lmp.py:372]   Expert 60 |    374 | GPU
DEBUG 01-05 09:19:45.901953.901953 lmp.py:372]   Expert 43 |    400 | GPU
DEBUG 01-05 09:19:45.901881.901881 lmp.py:372]   Expert  9 |    425 | GPU
DEBUG 01-05 09:19:45.901570.901570 lmp.py:372]   Expert 63 |    452 | GPU
DEBUG 01-05 09:19:45.901544.901544 lmp.py:372]   Expert 20 |    505 | GPU
DEBUG 01-05 09:19:45.901472.901472 lmp.py:373] 
DEBUG 01-05 09:19:45.901472.901472 lmp.py:373]   CPU total tokens: 3654 (29.7%)
DEBUG 01-05 09:19:45.901638.901638 lmp.py:374]   GPU total tokens: 8634 (70.3%)
DEBUG 01-05 09:19:45.902857.902857 cuda_h.py:19] end experts_map_get cost 0.0014884471893310547 seconds
DEBUG 01-05 09:19:45.902785.902785 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:45.902807.902807 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:45.902196.902196 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:45.902861.902861 cuda_h.py:19] end allocate_cuda_memory cost 0.0002460479736328125 seconds
DEBUG 01-05 09:19:45.902710.902710 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:45.902990.902990 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:45.902660.902660 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:45.902548.902548 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0728f384-94f4-46c5-9302-f077ead5a301
DEBUG 01-05 09:19:45.902709.902709 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:45.903684.903684 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0728f384-94f4-46c5-9302-f077ead5a301
DEBUG 01-05 09:19:45.903805.903805 cuda_h.py:19] end load_into_gpu_async cost 0.0014083385467529297 seconds
DEBUG 01-05 09:19:45.904839.904839 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:45.904926.904926 cuda_h.py:19] end restore_tensors2 cost 0.00038814544677734375 seconds
DEBUG 01-05 09:19:45.904186.904186 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023984909057617188 seconds
DEBUG 01-05 09:19:45.907603.907603 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005210399627685547 seconds
DEBUG 01-05 09:19:45.907194.907194 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:45.907395.907395 lmp.py:419] 
DEBUG 01-05 09:19:45.907395.907395 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:45.907066.907066 cuda_h.py:19] end cpu_experts_submit cost 0.00012254714965820312 seconds
DEBUG 01-05 09:19:45.907670.907670 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:45.917684.917684 mlpmodule.py:704] group tensors cost 0.010376930236816406 s
DEBUG 01-05 09:19:45.920039.920039 mlpmodule.py:742] pad cost 0.0015208721160888672 s
DEBUG 01-05 09:19:45.920142.920142 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-05 09:19:45.920827.920827 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-05 09:19:45.932657.932657 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:45.932663.932663 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:45.932898.932898 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 09:19:45.933267.933267 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:45.950483.950483 mlpmodule.py:793] group einsum cost 0.02958369255065918 s
DEBUG 01-05 09:19:45.951368.951368 mlpmodule.py:801] cpy2cputensor cost 0.0011038780212402344 s
DEBUG 01-05 09:19:45.992162.992162 cuda_h.py:19] end wait_cetm_experts cost 0.08525967597961426 seconds
DEBUG 01-05 09:19:45.992330.992330 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:45.993109.993109 cuda_h.py:19] end gpu_sexperts cost 0.0004630088806152344 seconds
DEBUG 01-05 09:19:45.993422.993422 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 09:19:45.993781.993781 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.3828277587890625e-05 seconds
DEBUG 01-05 09:19:45.993630.993630 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:45.993161.993161 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0728f384-94f4-46c5-9302-f077ead5a301
INFO 01-05 09:19:45.994866.994866 client.py:127] Model loaded
DEBUG 01-05 09:19:45.994417.994417 cuda_h.py:19] end wait_experts cost 0.0009360313415527344 seconds
DEBUG 01-05 09:19:45.994074.994074 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:45.994161.994161 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:45.995947.995947 mlpmodule.py:531] gpu group tensors cost 0.0006420612335205078 s
DEBUG 01-05 09:19:45.997060.997060 mlpmodule.py:564] gpu pad cost 0.001750946044921875 s
DEBUG 01-05 09:19:45.997822.997822 mlpmodule.py:582] gpu group einsum cost 0.0005118846893310547 s
DEBUG 01-05 09:19:46.001415.001415 mlpmodule.py:611] gpu experts func einsum cost 0.0065326690673828125 s
DEBUG 01-05 09:19:46.001273.001273 cuda_h.py:19] end gpu_experts cost 0.006719112396240234 seconds
DEBUG 01-05 09:19:46.001559.001559 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:46.001614.001614 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.5367431640625e-06 seconds
DEBUG 01-05 09:19:46.001612.001612 cuda_h.py:19] end layer_moe_generate_27 cost 0.10166358947753906 seconds
DEBUG 01-05 09:19:46.001096.001096 lmp.py:214] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 09:19:46.001640.001640 cuda_h.py:19] end multi_layer cost 3.10270619392395 seconds
DEBUG 01-05 09:19:46.001343.001343 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:19:46.004474.004474 mlpmodule.py:662]  experts func einsum cost 0.09728097915649414 s
DEBUG 01-05 09:19:46.005178.005178 cuda_h.py:19] end init_inputs_tokens cost 0.003524303436279297 seconds
DEBUG 01-05 09:19:46.005962.005962 lmp.py:283] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:19:46.005957.005957 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:19:46.006230.006230 lmp.py:286] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:19:46.006319.006319 cuda_h.py:19] end dense_mlp cost 0.0006916522979736328 seconds
INFO 01-05 09:19:46.006108.006108 lmp.py:523] 
INFO 01-05 09:19:46.006108.006108 lmp.py:523] ============================================================
INFO 01-05 09:19:46.006440.006440 lmp.py:524] Layer 1 Expert Device Distribution:
INFO 01-05 09:19:46.006203.006203 lmp.py:533]   Total experts: 64
INFO 01-05 09:19:46.006435.006435 lmp.py:535]   meta: 32 experts - Expert IDs: [0, 1, 3, 4, 11, 13, 15, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 47, 49, 52, 53, 54, 55, 56, 58, 62]
INFO 01-05 09:19:46.006370.006370 lmp.py:535]   cuda:1: 32 experts - Expert IDs: [2, 5, 6, 7, 8, 9, 10, 12, 14, 16, 19, 20, 23, 24, 26, 34, 35, 36, 40, 42, 43, 44, 45, 46, 48, 50, 51, 57, 59, 60, 61, 63]
INFO 01-05 09:19:46.006728.006728 lmp.py:538] 
INFO 01-05 09:19:46.006728.006728 lmp.py:538]   Detailed Expert Device Map:
INFO 01-05 09:19:46.006424.006424 lmp.py:539]   Expert ID  | Device         
INFO 01-05 09:19:46.006829.006829 lmp.py:540]   ------------------------------
INFO 01-05 09:19:46.006810.006810 lmp.py:543]   0          | meta           
INFO 01-05 09:19:46.007691.007691 lmp.py:543]   1          | meta           
INFO 01-05 09:19:46.007619.007619 lmp.py:543]   2          | cuda:1         
INFO 01-05 09:19:46.007308.007308 lmp.py:543]   3          | meta           
INFO 01-05 09:19:46.007759.007759 lmp.py:543]   4          | meta           
INFO 01-05 09:19:46.007210.007210 lmp.py:543]   5          | cuda:1         
INFO 01-05 09:19:46.007899.007899 lmp.py:543]   6          | cuda:1         
INFO 01-05 09:19:46.007588.007588 lmp.py:543]   7          | cuda:1         
INFO 01-05 09:19:46.007993.007993 lmp.py:543]   8          | cuda:1         
INFO 01-05 09:19:46.007318.007318 lmp.py:543]   9          | cuda:1         
INFO 01-05 09:19:46.007531.007531 lmp.py:543]   10         | cuda:1         
INFO 01-05 09:19:46.007743.007743 lmp.py:543]   11         | meta           
INFO 01-05 09:19:46.007717.007717 lmp.py:543]   12         | cuda:1         
INFO 01-05 09:19:46.007930.007930 lmp.py:543]   13         | meta           
INFO 01-05 09:19:46.007427.007427 lmp.py:543]   14         | cuda:1         
INFO 01-05 09:19:46.007163.007163 lmp.py:543]   15         | meta           
INFO 01-05 09:19:46.007137.007137 lmp.py:543]   16         | cuda:1         
INFO 01-05 09:19:46.007588.007588 lmp.py:543]   17         | meta           
INFO 01-05 09:19:46.007800.007800 lmp.py:543]   18         | meta           
INFO 01-05 09:19:46.007536.007536 lmp.py:543]   19         | cuda:1         
INFO 01-05 09:19:46.007748.007748 lmp.py:543]   20         | cuda:1         
INFO 01-05 09:19:46.007484.007484 lmp.py:543]   21         | meta           
INFO 01-05 09:19:46.007219.007219 lmp.py:543]   22         | meta           
INFO 01-05 09:19:46.007670.007670 lmp.py:543]   23         | cuda:1         
INFO 01-05 09:19:46.007406.007406 lmp.py:543]   24         | cuda:1         
INFO 01-05 09:19:46.007380.007380 lmp.py:543]   25         | meta           
INFO 01-05 09:19:46.007354.007354 lmp.py:543]   26         | cuda:1         
INFO 01-05 09:19:46.007328.007328 lmp.py:543]   27         | meta           
INFO 01-05 09:19:46.007541.007541 lmp.py:543]   28         | meta           
INFO 01-05 09:19:46.007038.007038 lmp.py:543]   29         | meta           
INFO 01-05 09:19:46.007250.007250 lmp.py:543]   30         | meta           
INFO 01-05 09:19:46.007940.007940 lmp.py:543]   31         | meta           
INFO 01-05 09:19:46.007675.007675 lmp.py:543]   32         | meta           
INFO 01-05 09:19:46.007649.007649 lmp.py:543]   33         | meta           
INFO 01-05 09:19:46.007623.007623 lmp.py:543]   34         | cuda:1         
INFO 01-05 09:19:46.007359.007359 lmp.py:543]   35         | cuda:1         
INFO 01-05 09:19:46.007333.007333 lmp.py:543]   36         | cuda:1         
INFO 01-05 09:19:46.007069.007069 lmp.py:543]   37         | meta           
INFO 01-05 09:19:46.007281.007281 lmp.py:543]   38         | meta           
INFO 01-05 09:19:46.007778.007778 lmp.py:543]   39         | meta           
INFO 01-05 09:19:46.007752.007752 lmp.py:543]   40         | cuda:1         
INFO 01-05 09:19:46.007680.007680 lmp.py:543]   41         | meta           
INFO 01-05 09:19:46.007608.007608 lmp.py:543]   42         | cuda:1         
INFO 01-05 09:19:46.007820.007820 lmp.py:543]   43         | cuda:1         
INFO 01-05 09:19:46.007794.007794 lmp.py:543]   44         | cuda:1         
INFO 01-05 09:19:46.007768.007768 lmp.py:543]   45         | cuda:1         
INFO 01-05 09:19:46.007742.007742 lmp.py:543]   46         | cuda:1         
INFO 01-05 09:19:46.007955.007955 lmp.py:543]   47         | meta           
INFO 01-05 09:19:46.007406.007406 lmp.py:543]   48         | cuda:1         
INFO 01-05 09:19:46.007572.007572 lmp.py:543]   49         | meta           
INFO 01-05 09:19:46.007546.007546 lmp.py:543]   50         | cuda:1         
INFO 01-05 09:19:46.007758.007758 lmp.py:543]   51         | cuda:1         
INFO 01-05 09:19:46.007494.007494 lmp.py:543]   52         | meta           
INFO 01-05 09:19:46.007468.007468 lmp.py:543]   53         | meta           
INFO 01-05 09:19:46.007442.007442 lmp.py:543]   54         | meta           
INFO 01-05 09:19:46.007178.007178 lmp.py:543]   55         | meta           
INFO 01-05 09:19:46.007152.007152 lmp.py:543]   56         | meta           
INFO 01-05 09:19:46.007126.007126 lmp.py:543]   57         | cuda:1         
INFO 01-05 09:19:46.007577.007577 lmp.py:543]   58         | meta           
INFO 01-05 09:19:46.007789.007789 lmp.py:543]   59         | cuda:1         
INFO 01-05 09:19:46.007286.007286 lmp.py:543]   60         | cuda:1         
INFO 01-05 09:19:46.007260.007260 lmp.py:543]   61         | cuda:1         
INFO 01-05 09:19:46.008758.008758 lmp.py:543]   62         | meta           
INFO 01-05 09:19:46.008970.008970 lmp.py:543]   63         | cuda:1         
INFO 01-05 09:19:46.008467.008467 lmp.py:544] ============================================================
INFO 01-05 09:19:46.008467.008467 lmp.py:544] 
DEBUG 01-05 09:19:46.008872.008872 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 09:19:46.008389.008389 cuda_h.py:10] start gate
DEBUG 01-05 09:19:46.008223.008223 cuda_h.py:19] end gate cost 0.0005486011505126953 seconds
DEBUG 01-05 09:19:46.008099.008099 cuda_h.py:10] start experts_map_get
INFO 01-05 09:19:46.008816.008816 lmp.py:608] 
INFO 01-05 09:19:46.008816.008816 lmp.py:608] Layer 1 Expert Device Distribution:
INFO 01-05 09:19:46.008426.008426 lmp.py:609]   Active experts: 46 (out of 64 total)
INFO 01-05 09:19:46.009368.009368 lmp.py:610]   CPU experts: 23 (50%) - Expert IDs: [1, 8, 9, 11, 12, 16, 19, 22, 28, 30, 32, 35, 38, 40, 41, 43, 45, 47, 48, 50, 51, 52, 61]
INFO 01-05 09:19:46.009017.009017 lmp.py:611]   GPU experts: 23 (50%) - Expert IDs: [0, 2, 4, 5, 6, 7, 10, 14, 15, 20, 23, 24, 26, 31, 33, 34, 42, 44, 46, 57, 59, 60, 63]
INFO 01-05 09:19:46.009568.009568 lmp.py:612]   CPU tokens: 39 (20.3%)
INFO 01-05 09:19:46.009449.009449 lmp.py:613]   GPU tokens: 153 (79.7%)
INFO 01-05 09:19:46.009138.009138 lmp.py:614] 
INFO 01-05 09:19:46.009138.009138 lmp.py:614]   Detailed Expert Distribution:
INFO 01-05 09:19:46.009258.009258 lmp.py:615]   Expert ID  | Tokens     | Device       | Token %   
INFO 01-05 09:19:46.009424.009424 lmp.py:616]   --------------------------------------------------
INFO 01-05 09:19:46.009259.009259 lmp.py:620]   1          | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009379.009379 lmp.py:620]   9          | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009261.009261 lmp.py:620]   12         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009142.009142 lmp.py:620]   22         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009785.009785 lmp.py:620]   30         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009189.009189 lmp.py:620]   32         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009356.009356 lmp.py:620]   35         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009760.009760 lmp.py:620]   38         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009165.009165 lmp.py:620]   41         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009331.009331 lmp.py:620]   48         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009259.009259 lmp.py:620]   50         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009186.009186 lmp.py:620]   51         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009876.009876 lmp.py:620]   52         | 1          | CPU          |   0.52%
INFO 01-05 09:19:46.009803.009803 lmp.py:620]   19         | 2          | CPU          |   1.04%
INFO 01-05 09:19:46.009731.009731 lmp.py:620]   28         | 2          | CPU          |   1.04%
INFO 01-05 09:19:46.009851.009851 lmp.py:620]   40         | 2          | CPU          |   1.04%
INFO 01-05 09:19:46.009017.009017 lmp.py:620]   43         | 2          | CPU          |   1.04%
INFO 01-05 09:19:46.009422.009422 lmp.py:620]   8          | 3          | CPU          |   1.56%
INFO 01-05 09:19:46.009349.009349 lmp.py:620]   11         | 3          | CPU          |   1.56%
INFO 01-05 09:19:46.009039.009039 lmp.py:620]   16         | 3          | CPU          |   1.56%
INFO 01-05 09:19:46.009966.009966 lmp.py:620]   45         | 3          | CPU          |   1.56%
INFO 01-05 09:19:46.009656.009656 lmp.py:620]   47         | 3          | CPU          |   1.56%
INFO 01-05 09:19:46.009106.009106 lmp.py:620]   61         | 3          | CPU          |   1.56%
INFO 01-05 09:19:46.009180.009180 lmp.py:620]   0          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:46.009538.009538 lmp.py:620]   2          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:46.009181.009181 lmp.py:620]   44         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:46.009586.009586 lmp.py:620]   60         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:46.009990.009990 lmp.py:620]   5          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:46.009395.009395 lmp.py:620]   7          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:46.009799.009799 lmp.py:620]   10         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:46.009966.009966 lmp.py:620]   26         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:46.009132.009132 lmp.py:620]   46         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:46.009967.009967 lmp.py:620]   6          | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:46.009087.009087 lmp.py:620]   15         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:46.009730.009730 lmp.py:620]   23         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:46.009657.009657 lmp.py:620]   33         | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:46.009823.009823 lmp.py:620]   14         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:46.009990.009990 lmp.py:620]   42         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:46.009917.009917 lmp.py:620]   59         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:46.009607.009607 lmp.py:620]   31         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:19:46.009773.009773 lmp.py:620]   4          | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:46.009654.009654 lmp.py:620]   20         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:46.009582.009582 lmp.py:620]   24         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:46.009986.009986 lmp.py:620]   34         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:19:46.009152.009152 lmp.py:620]   63         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:19:46.009319.009319 lmp.py:620]   57         | 12         | GPU(cuda:1)  |   6.25%
INFO 01-05 09:19:46.009293.009293 lmp.py:621] ============================================================
INFO 01-05 09:19:46.009293.009293 lmp.py:621] 
DEBUG 01-05 09:19:46.009989.009989 cuda_h.py:19] end experts_map_get cost 0.0012247562408447266 seconds
DEBUG 01-05 09:19:46.009254.009254 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.0019121170043945312 seconds
DEBUG 01-05 09:19:47.182849.182849 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.08917927742004395 s
DEBUG 01-05 09:19:47.525723.525723 cuda_h.py:19] end generate_input_ids cost 0.3426845073699951 seconds
DEBUG 01-05 09:19:47.525616.525616 cuda_h.py:10] start init_cache
DEBUG 01-05 09:19:47.525460.525460 cuda_h.py:19] end init_cache cost 5.698204040527344e-05 seconds
DEBUG 01-05 09:19:49.992756.992756 cuda_h.py:10] start init_weights
DEBUG 01-05 09:19:49.993335.993335 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:49.993837.993837 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:49.995258.995258 cuda_h.py:19] end allocate_cuda_memory cost 0.002058267593383789 seconds
DEBUG 01-05 09:19:49.995015.995015 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:49.995248.995248 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:49.995899.995899 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:49.995172.995172 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a04ee1fc-c68d-4a69-89a1-606922d5a1ab
DEBUG 01-05 09:19:49.995419.995419 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:49.997341.997341 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a04ee1fc-c68d-4a69-89a1-606922d5a1ab
DEBUG 01-05 09:19:49.997892.997892 cuda_h.py:19] end load_into_gpu_async cost 0.0016322135925292969 seconds
DEBUG 01-05 09:19:49.997496.997496 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:49.997412.997412 cuda_h.py:19] end restore_tensors2 cost 5.364418029785156e-05 seconds
DEBUG 01-05 09:19:49.997638.997638 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003976345062255859 seconds
INFO 01-05 09:19:49.997429.997429 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a04ee1fc-c68d-4a69-89a1-606922d5a1ab
INFO 01-05 09:19:50.073778.073778 client.py:127] Model loaded
DEBUG 01-05 09:19:50.073419.073419 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-05 09:19:50.073019.073019 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:50.073851.073851 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:50.074165.074165 cuda_h.py:19] end allocate_cuda_memory cost 0.0003826618194580078 seconds
DEBUG 01-05 09:19:50.074866.074866 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:50.074883.074883 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:50.074238.074238 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:50.074500.074500 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1a179f67-80ea-49a6-8bba-f4fa2265afdf
DEBUG 01-05 09:19:50.074599.074599 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:50.075936.075936 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1a179f67-80ea-49a6-8bba-f4fa2265afdf
DEBUG 01-05 09:19:50.075636.075636 cuda_h.py:19] end load_into_gpu_async cost 0.0015048980712890625 seconds
DEBUG 01-05 09:19:50.076214.076214 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:50.076653.076653 cuda_h.py:19] end restore_tensors2 cost 0.0001518726348876953 seconds
DEBUG 01-05 09:19:50.076943.076943 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002773284912109375 seconds
INFO 01-05 09:19:50.076079.076079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1a179f67-80ea-49a6-8bba-f4fa2265afdf
INFO 01-05 09:19:50.092479.092479 client.py:127] Model loaded
DEBUG 01-05 09:19:50.093045.093045 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020361900329589844 seconds
DEBUG 01-05 09:19:50.094791.094791 cuda_h.py:19] end init_weights cost 0.10067391395568848 seconds
DEBUG 01-05 09:19:50.094423.094423 cuda_h.py:10] start copy_emodel
DEBUG 01-05 09:19:50.840971.840971 cuda_h.py:19] end copy_emodel cost 0.7464544773101807 seconds
DEBUG 01-05 09:19:50.841641.841641 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:19:50.841361.841361 cuda_h.py:19] end init_inputs_tokens cost 0.0002739429473876953 seconds
DEBUG 01-05 09:19:50.841422.841422 cuda_h.py:10] start multi_layer
DEBUG 01-05 09:19:50.841423.841423 lmp.py:173] -------------------------------- start layer 0 --------------------------------
DEBUG 01-05 09:19:50.841742.841742 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:50.842494.842494 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:50.845890.845890 cuda_h.py:19] end self_attn cost 0.003038644790649414 seconds
DEBUG 01-05 09:19:50.846781.846781 cuda_h.py:19] end iln_self_attn_paln cost 0.004091978073120117 seconds
DEBUG 01-05 09:19:50.846372.846372 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:19:50.846989.846989 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-05 09:19:50.846044.846044 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.266334533691406e-05 seconds
DEBUG 01-05 09:19:50.846889.846889 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:50.846305.846305 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:50.846916.846916 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:50.846647.846647 cuda_h.py:19] end allocate_cuda_memory cost 0.000213623046875 seconds
DEBUG 01-05 09:19:50.847575.847575 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:50.847636.847636 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:50.847380.847380 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:50.847235.847235 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 773cb515-11a8-471d-a465-55d880c69f1a
DEBUG 01-05 09:19:50.847331.847331 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:50.848409.848409 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 773cb515-11a8-471d-a465-55d880c69f1a
DEBUG 01-05 09:19:50.848021.848021 cuda_h.py:19] end load_into_gpu_async cost 0.0014064311981201172 seconds
DEBUG 01-05 09:19:50.848446.848446 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:50.848410.848410 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-05 09:19:50.848795.848795 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021431446075439453 seconds
INFO 01-05 09:19:50.849950.849950 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 773cb515-11a8-471d-a465-55d880c69f1a
INFO 01-05 09:19:50.855651.855651 client.py:127] Model loaded
DEBUG 01-05 09:19:50.855787.855787 cuda_h.py:19] end sllm_worker_task cost 0.009449481964111328 seconds
DEBUG 01-05 09:19:50.856651.856651 cuda_h.py:19] end dense_mlp cost 0.009889602661132812 seconds
DEBUG 01-05 09:19:50.856802.856802 lmp.py:214] -------------------------------- end layer 0 --------------------------------
DEBUG 01-05 09:19:50.856247.856247 lmp.py:173] -------------------------------- start layer 1 --------------------------------
DEBUG 01-05 09:19:50.856964.856964 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:50.856498.856498 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:50.859206.859206 cuda_h.py:19] end self_attn cost 0.0027015209197998047 seconds
DEBUG 01-05 09:19:50.859721.859721 cuda_h.py:19] end iln_self_attn_paln cost 0.003398895263671875 seconds
DEBUG 01-05 09:19:50.859154.859154 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-05 09:19:50.859560.859560 cuda_h.py:10] start gate
DEBUG 01-05 09:19:50.860407.860407 cuda_h.py:19] end gate cost 0.0007226467132568359 seconds
DEBUG 01-05 09:19:50.860203.860203 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:50.861342.861342 lmp.py:361] 
DEBUG 01-05 09:19:50.861342.861342 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:50.861304.861304 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:50.861106.861106 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:50.861571.861571 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:50.861843.861843 lmp.py:365] 
DEBUG 01-05 09:19:50.861843.861843 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:50.861970.861970 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:50.861772.861772 lmp.py:372]   Expert 62 |     66 | CPU
DEBUG 01-05 09:19:50.861422.861422 lmp.py:372]   Expert 18 |     68 | CPU
DEBUG 01-05 09:19:50.861932.861932 lmp.py:372]   Expert 22 |     73 | CPU
DEBUG 01-05 09:19:50.861251.861251 lmp.py:372]   Expert 32 |     83 | CPU
DEBUG 01-05 09:19:50.861662.861662 lmp.py:372]   Expert 52 |     94 | CPU
DEBUG 01-05 09:19:50.861120.861120 lmp.py:372]   Expert  3 |    104 | CPU
DEBUG 01-05 09:19:50.861247.861247 lmp.py:372]   Expert 27 |    114 | CPU
DEBUG 01-05 09:19:50.861943.861943 lmp.py:372]   Expert 38 |    114 | CPU
DEBUG 01-05 09:19:50.861685.861685 lmp.py:372]   Expert 13 |    118 | CPU
DEBUG 01-05 09:19:50.861666.861666 lmp.py:372]   Expert 54 |    118 | CPU
DEBUG 01-05 09:19:50.861985.861985 lmp.py:372]   Expert 17 |    121 | CPU
DEBUG 01-05 09:19:50.861065.861065 lmp.py:372]   Expert 11 |    124 | CPU
DEBUG 01-05 09:19:50.861953.861953 lmp.py:372]   Expert 28 |    124 | CPU
DEBUG 01-05 09:19:50.861557.861557 lmp.py:372]   Expert 37 |    125 | CPU
DEBUG 01-05 09:19:50.861014.861014 lmp.py:372]   Expert 58 |    129 | CPU
DEBUG 01-05 09:19:50.861234.861234 lmp.py:372]   Expert 39 |    131 | CPU
DEBUG 01-05 09:19:50.861453.861453 lmp.py:372]   Expert 25 |    135 | CPU
DEBUG 01-05 09:19:50.861672.861672 lmp.py:372]   Expert 41 |    136 | CPU
DEBUG 01-05 09:19:50.861613.861613 lmp.py:372]   Expert 21 |    150 | CPU
DEBUG 01-05 09:19:50.861263.861263 lmp.py:372]   Expert  4 |    151 | CPU
DEBUG 01-05 09:19:50.861675.861675 lmp.py:372]   Expert 30 |    152 | CPU
DEBUG 01-05 09:19:50.861894.861894 lmp.py:372]   Expert 29 |    155 | CPU
DEBUG 01-05 09:19:50.861020.861020 lmp.py:372]   Expert 53 |    155 | CPU
DEBUG 01-05 09:19:50.861001.861001 lmp.py:372]   Expert 49 |    156 | CPU
DEBUG 01-05 09:19:50.861220.861220 lmp.py:372]   Expert 47 |    157 | CPU
DEBUG 01-05 09:19:50.861724.861724 lmp.py:372]   Expert 31 |    168 | CPU
DEBUG 01-05 09:19:50.861043.861043 lmp.py:372]   Expert 33 |    168 | CPU
DEBUG 01-05 09:19:50.861885.861885 lmp.py:372]   Expert 55 |    173 | CPU
DEBUG 01-05 09:19:50.861296.861296 lmp.py:372]   Expert 56 |    173 | CPU
DEBUG 01-05 09:19:50.861185.861185 lmp.py:372]   Expert 15 |    177 | CPU
DEBUG 01-05 09:19:50.861642.861642 lmp.py:372]   Expert  0 |    178 | CPU
DEBUG 01-05 09:19:50.861623.861623 lmp.py:372]   Expert  1 |    178 | CPU
DEBUG 01-05 09:19:50.861365.861365 lmp.py:372]   Expert 24 |    180 | GPU
DEBUG 01-05 09:19:50.862346.862346 lmp.py:372]   Expert 50 |    182 | GPU
DEBUG 01-05 09:19:50.862711.862711 lmp.py:372]   Expert 51 |    184 | GPU
DEBUG 01-05 09:19:50.862692.862692 lmp.py:372]   Expert 19 |    185 | GPU
DEBUG 01-05 09:19:50.862249.862249 lmp.py:372]   Expert  6 |    186 | GPU
DEBUG 01-05 09:19:50.862230.862230 lmp.py:372]   Expert 10 |    189 | GPU
DEBUG 01-05 09:19:50.862165.862165 lmp.py:372]   Expert 34 |    191 | GPU
DEBUG 01-05 09:19:50.862291.862291 lmp.py:372]   Expert  2 |    195 | GPU
DEBUG 01-05 09:19:50.862034.862034 lmp.py:372]   Expert 45 |    195 | GPU
DEBUG 01-05 09:19:50.862538.862538 lmp.py:372]   Expert 35 |    197 | GPU
DEBUG 01-05 09:19:50.862803.862803 lmp.py:372]   Expert 36 |    198 | GPU
DEBUG 01-05 09:19:50.862546.862546 lmp.py:372]   Expert 61 |    209 | GPU
DEBUG 01-05 09:19:50.862195.862195 lmp.py:372]   Expert 44 |    214 | GPU
DEBUG 01-05 09:19:50.862699.862699 lmp.py:372]   Expert 12 |    223 | GPU
DEBUG 01-05 09:19:50.862203.862203 lmp.py:372]   Expert  5 |    227 | GPU
DEBUG 01-05 09:19:50.862946.862946 lmp.py:372]   Expert 23 |    235 | GPU
DEBUG 01-05 09:19:50.862264.862264 lmp.py:372]   Expert 60 |    235 | GPU
DEBUG 01-05 09:19:50.862199.862199 lmp.py:372]   Expert 43 |    239 | GPU
DEBUG 01-05 09:19:50.862372.862372 lmp.py:372]   Expert  9 |    246 | GPU
DEBUG 01-05 09:19:50.862260.862260 lmp.py:372]   Expert 48 |    252 | GPU
DEBUG 01-05 09:19:50.862003.862003 lmp.py:372]   Expert  8 |    262 | GPU
DEBUG 01-05 09:19:50.862745.862745 lmp.py:372]   Expert 20 |    273 | GPU
DEBUG 01-05 09:19:50.862249.862249 lmp.py:372]   Expert 26 |    285 | GPU
DEBUG 01-05 09:19:50.862753.862753 lmp.py:372]   Expert 57 |    292 | GPU
DEBUG 01-05 09:19:50.862164.862164 lmp.py:372]   Expert  7 |    308 | GPU
DEBUG 01-05 09:19:50.862483.862483 lmp.py:372]   Expert 59 |    308 | GPU
DEBUG 01-05 09:19:50.862749.862749 lmp.py:372]   Expert 16 |    310 | GPU
DEBUG 01-05 09:19:50.862206.862206 lmp.py:372]   Expert 63 |    313 | GPU
DEBUG 01-05 09:19:50.862094.862094 lmp.py:372]   Expert 40 |    320 | GPU
DEBUG 01-05 09:19:50.862314.862314 lmp.py:372]   Expert 46 |    320 | GPU
DEBUG 01-05 09:19:50.862579.862579 lmp.py:372]   Expert 42 |    342 | GPU
DEBUG 01-05 09:19:50.862083.862083 lmp.py:372]   Expert 14 |    525 | GPU
DEBUG 01-05 09:19:50.862541.862541 lmp.py:373] 
DEBUG 01-05 09:19:50.862541.862541 lmp.py:373]   CPU total tokens: 4268 (34.7%)
DEBUG 01-05 09:19:50.862721.862721 lmp.py:374]   GPU total tokens: 8020 (65.3%)
DEBUG 01-05 09:19:50.862331.862331 cuda_h.py:19] end experts_map_get cost 0.001989126205444336 seconds
DEBUG 01-05 09:19:50.862934.862934 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:50.862777.862777 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:50.862657.862657 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:50.863460.863460 cuda_h.py:19] end allocate_cuda_memory cost 0.00019693374633789062 seconds
DEBUG 01-05 09:19:50.863270.863270 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:50.863033.863033 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:50.863902.863902 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:50.863035.863035 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d0d1cfe-467e-4efa-837d-dc2e2046a02d
DEBUG 01-05 09:19:50.863016.863016 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:50.865710.865710 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d0d1cfe-467e-4efa-837d-dc2e2046a02d
DEBUG 01-05 09:19:50.865798.865798 cuda_h.py:19] end load_into_gpu_async cost 0.0018949508666992188 seconds
DEBUG 01-05 09:19:50.865508.865508 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:50.865609.865609 cuda_h.py:19] end restore_tensors2 cost 0.0004246234893798828 seconds
DEBUG 01-05 09:19:50.865473.865473 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029413700103759766 seconds
DEBUG 01-05 09:19:50.868432.868432 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005742788314819336 seconds
DEBUG 01-05 09:19:50.868521.868521 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:50.868245.868245 lmp.py:419] 
DEBUG 01-05 09:19:50.868245.868245 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:50.868949.868949 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-05 09:19:50.868791.868791 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:50.883268.883268 mlpmodule.py:704] group tensors cost 0.014418840408325195 s
DEBUG 01-05 09:19:50.886490.886490 mlpmodule.py:742] pad cost 0.002188444137573242 s
DEBUG 01-05 09:19:50.886653.886653 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-05 09:19:50.886378.886378 mlpmodule.py:753] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-05 09:19:50.897738.897738 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:50.898452.898452 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:50.898495.898495 mlpmodule.py:773] group_w3 first element: -0.0107421875
WARNING 01-05 09:19:50.898579.898579 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:50.916069.916069 mlpmodule.py:793] group einsum cost 0.02925872802734375 s
DEBUG 01-05 09:19:50.916340.916340 mlpmodule.py:801] cpy2cputensor cost 0.0007555484771728516 s
DEBUG 01-05 09:19:50.957661.957661 cuda_h.py:19] end wait_cetm_experts cost 0.08904838562011719 seconds
DEBUG 01-05 09:19:50.957705.957705 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:50.958071.958071 cuda_h.py:19] end gpu_sexperts cost 0.0006113052368164062 seconds
DEBUG 01-05 09:19:50.958020.958020 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:19:50.958889.958889 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-05 09:19:50.958461.958461 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.2901763916015625e-05 seconds
DEBUG 01-05 09:19:50.958648.958648 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 7.2479248046875e-05 seconds
DEBUG 01-05 09:19:50.958397.958397 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:50.958345.958345 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d0d1cfe-467e-4efa-837d-dc2e2046a02d
DEBUG 01-05 09:19:50.959576.959576 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:50.959499.959499 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:50.959150.959150 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:50.962534.962534 cuda_h.py:19] end allocate_cuda_memory cost 0.003507852554321289 seconds
DEBUG 01-05 09:19:50.962351.962351 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:50.962544.962544 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:50.962612.962612 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:50.962414.962414 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3494c24-d1c5-4268-8943-7a59a49bb55e
DEBUG 01-05 09:19:50.963736.963736 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:50.963530.963530 client.py:127] Model loaded
DEBUG 01-05 09:19:50.963294.963294 cuda_h.py:19] end wait_experts cost 0.0044209957122802734 seconds
DEBUG 01-05 09:19:50.963812.963812 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:50.963091.963091 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:50.963031.963031 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3494c24-d1c5-4268-8943-7a59a49bb55e
DEBUG 01-05 09:19:50.964927.964927 cuda_h.py:19] end load_into_gpu_async cost 0.0011591911315917969 seconds
DEBUG 01-05 09:19:50.964253.964253 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:50.967694.967694 cuda_h.py:19] end restore_tensors2 cost 0.0034563541412353516 seconds
DEBUG 01-05 09:19:50.967225.967225 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008402585983276367 seconds
INFO 01-05 09:19:50.968197.968197 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3494c24-d1c5-4268-8943-7a59a49bb55e
INFO 01-05 09:19:50.972916.972916 client.py:127] Model loaded
DEBUG 01-05 09:19:50.972422.972422 cuda_h.py:19] end sllm_worker_task cost 0.01311349868774414 seconds
DEBUG 01-05 09:19:50.972948.972948 mlpmodule.py:662]  experts func einsum cost 0.10357666015625 s
DEBUG 01-05 09:19:50.972104.972104 mlpmodule.py:531] gpu group tensors cost 0.009165763854980469 s
DEBUG 01-05 09:19:50.974829.974829 mlpmodule.py:564] gpu pad cost 0.001589059829711914 s
DEBUG 01-05 09:19:50.975417.975417 mlpmodule.py:582] gpu group einsum cost 0.001071929931640625 s
DEBUG 01-05 09:19:50.978284.978284 mlpmodule.py:611] gpu experts func einsum cost 0.014987707138061523 s
DEBUG 01-05 09:19:50.978191.978191 cuda_h.py:19] end gpu_experts cost 0.0152435302734375 seconds
DEBUG 01-05 09:19:50.978755.978755 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:50.978883.978883 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-05 09:19:50.978490.978490 cuda_h.py:19] end layer_moe_generate_1 cost 0.1189584732055664 seconds
DEBUG 01-05 09:19:50.979748.979748 lmp.py:214] -------------------------------- end layer 1 --------------------------------
DEBUG 01-05 09:19:50.979087.979087 lmp.py:173] -------------------------------- start layer 2 --------------------------------
DEBUG 01-05 09:19:50.979213.979213 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:50.979110.979110 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:50.981604.981604 cuda_h.py:19] end self_attn cost 0.0024497509002685547 seconds
DEBUG 01-05 09:19:50.982444.982444 cuda_h.py:19] end iln_self_attn_paln cost 0.00308990478515625 seconds
DEBUG 01-05 09:19:50.982571.982571 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-05 09:19:50.982957.982957 cuda_h.py:10] start gate
DEBUG 01-05 09:19:50.982216.982216 cuda_h.py:19] end gate cost 0.0005772113800048828 seconds
DEBUG 01-05 09:19:50.982045.982045 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:50.983360.983360 lmp.py:361] 
DEBUG 01-05 09:19:50.983360.983360 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:50.983262.983262 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:50.983627.983627 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:50.983654.983654 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:50.983443.983443 lmp.py:365] 
DEBUG 01-05 09:19:50.983443.983443 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:50.983086.983086 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:50.983166.983166 lmp.py:372]   Expert 34 |     41 | CPU
DEBUG 01-05 09:19:50.983047.983047 lmp.py:372]   Expert 36 |     47 | CPU
DEBUG 01-05 09:19:50.983975.983975 lmp.py:372]   Expert 58 |     61 | CPU
DEBUG 01-05 09:19:50.983048.983048 lmp.py:372]   Expert 26 |     63 | CPU
DEBUG 01-05 09:19:50.983930.983930 lmp.py:372]   Expert  3 |     65 | CPU
DEBUG 01-05 09:19:50.983334.983334 lmp.py:372]   Expert 27 |     71 | CPU
DEBUG 01-05 09:19:50.983785.983785 lmp.py:372]   Expert  8 |     77 | CPU
DEBUG 01-05 09:19:50.983475.983475 lmp.py:372]   Expert 29 |     82 | CPU
DEBUG 01-05 09:19:50.983402.983402 lmp.py:372]   Expert  7 |     90 | CPU
DEBUG 01-05 09:19:50.983761.983761 lmp.py:372]   Expert 10 |     91 | CPU
DEBUG 01-05 09:19:50.983211.983211 lmp.py:372]   Expert 28 |     96 | CPU
DEBUG 01-05 09:19:50.983662.983662 lmp.py:372]   Expert 21 |    103 | CPU
DEBUG 01-05 09:19:50.983113.983113 lmp.py:372]   Expert 13 |    109 | CPU
DEBUG 01-05 09:19:50.983087.983087 lmp.py:372]   Expert 19 |    117 | CPU
DEBUG 01-05 09:19:50.983730.983730 lmp.py:372]   Expert 62 |    120 | CPU
DEBUG 01-05 09:19:50.983373.983373 lmp.py:372]   Expert 40 |    134 | CPU
DEBUG 01-05 09:19:50.983447.983447 lmp.py:372]   Expert 63 |    139 | CPU
DEBUG 01-05 09:19:50.983898.983898 lmp.py:372]   Expert  5 |    141 | CPU
DEBUG 01-05 09:19:50.983110.983110 lmp.py:372]   Expert 52 |    144 | CPU
DEBUG 01-05 09:19:50.983561.983561 lmp.py:372]   Expert  9 |    145 | CPU
DEBUG 01-05 09:19:50.983773.983773 lmp.py:372]   Expert 25 |    149 | CPU
DEBUG 01-05 09:19:50.983939.983939 lmp.py:372]   Expert 50 |    152 | CPU
DEBUG 01-05 09:19:50.983344.983344 lmp.py:372]   Expert 59 |    152 | CPU
DEBUG 01-05 09:19:50.983510.983510 lmp.py:372]   Expert 33 |    153 | CPU
DEBUG 01-05 09:19:50.983438.983438 lmp.py:372]   Expert 17 |    154 | CPU
DEBUG 01-05 09:19:50.983889.983889 lmp.py:372]   Expert 49 |    158 | CPU
DEBUG 01-05 09:19:50.983101.983101 lmp.py:372]   Expert 35 |    166 | CPU
DEBUG 01-05 09:19:50.983506.983506 lmp.py:372]   Expert  0 |    168 | CPU
DEBUG 01-05 09:19:50.983195.983195 lmp.py:372]   Expert 16 |    168 | CPU
DEBUG 01-05 09:19:50.983408.983408 lmp.py:372]   Expert 30 |    168 | CPU
DEBUG 01-05 09:19:50.983335.983335 lmp.py:372]   Expert 60 |    168 | CPU
DEBUG 01-05 09:19:50.983548.983548 lmp.py:372]   Expert  1 |    171 | CPU
DEBUG 01-05 09:19:50.983283.983283 lmp.py:372]   Expert 44 |    174 | GPU
DEBUG 01-05 09:19:50.983403.983403 lmp.py:372]   Expert 24 |    177 | GPU
DEBUG 01-05 09:19:50.983616.983616 lmp.py:372]   Expert 38 |    180 | GPU
DEBUG 01-05 09:19:50.984590.984590 lmp.py:372]   Expert 45 |    181 | GPU
DEBUG 01-05 09:19:50.984756.984756 lmp.py:372]   Expert  6 |    189 | GPU
DEBUG 01-05 09:19:50.984684.984684 lmp.py:372]   Expert 31 |    199 | GPU
DEBUG 01-05 09:19:50.984611.984611 lmp.py:372]   Expert 48 |    217 | GPU
DEBUG 01-05 09:19:50.984731.984731 lmp.py:372]   Expert 39 |    222 | GPU
DEBUG 01-05 09:19:50.984705.984705 lmp.py:372]   Expert  4 |    237 | GPU
DEBUG 01-05 09:19:50.984918.984918 lmp.py:372]   Expert 55 |    238 | GPU
DEBUG 01-05 09:19:50.984892.984892 lmp.py:372]   Expert 37 |    242 | GPU
DEBUG 01-05 09:19:50.984866.984866 lmp.py:372]   Expert 14 |    243 | GPU
DEBUG 01-05 09:19:50.984078.984078 lmp.py:372]   Expert 57 |    244 | GPU
DEBUG 01-05 09:19:50.984244.984244 lmp.py:372]   Expert 22 |    250 | GPU
DEBUG 01-05 09:19:50.984172.984172 lmp.py:372]   Expert 51 |    250 | GPU
DEBUG 01-05 09:19:50.984053.984053 lmp.py:372]   Expert 12 |    256 | GPU
DEBUG 01-05 09:19:50.984504.984504 lmp.py:372]   Expert 41 |    256 | GPU
DEBUG 01-05 09:19:50.984478.984478 lmp.py:372]   Expert  2 |    258 | GPU
DEBUG 01-05 09:19:50.984929.984929 lmp.py:372]   Expert 15 |    271 | GPU
DEBUG 01-05 09:19:50.984380.984380 lmp.py:372]   Expert 20 |    273 | GPU
DEBUG 01-05 09:19:50.984116.984116 lmp.py:372]   Expert 47 |    275 | GPU
DEBUG 01-05 09:19:50.984474.984474 lmp.py:372]   Expert 42 |    285 | GPU
DEBUG 01-05 09:19:50.984402.984402 lmp.py:372]   Expert 23 |    290 | GPU
DEBUG 01-05 09:19:50.984568.984568 lmp.py:372]   Expert 53 |    298 | GPU
DEBUG 01-05 09:19:50.984019.984019 lmp.py:372]   Expert 54 |    308 | GPU
DEBUG 01-05 09:19:50.984231.984231 lmp.py:372]   Expert 56 |    317 | GPU
DEBUG 01-05 09:19:50.984027.984027 lmp.py:372]   Expert 46 |    318 | GPU
DEBUG 01-05 09:19:50.984431.984431 lmp.py:372]   Expert 18 |    319 | GPU
DEBUG 01-05 09:19:50.984644.984644 lmp.py:372]   Expert 61 |    327 | GPU
DEBUG 01-05 09:19:50.984095.984095 lmp.py:372]   Expert 32 |    340 | GPU
DEBUG 01-05 09:19:50.984499.984499 lmp.py:372]   Expert 43 |    379 | GPU
DEBUG 01-05 09:19:50.984427.984427 lmp.py:372]   Expert 11 |    412 | GPU
DEBUG 01-05 09:19:50.984891.984891 lmp.py:373] 
DEBUG 01-05 09:19:50.984891.984891 lmp.py:373]   CPU total tokens: 3863 (31.4%)
DEBUG 01-05 09:19:50.984534.984534 lmp.py:374]   GPU total tokens: 8425 (68.6%)
DEBUG 01-05 09:19:50.984469.984469 cuda_h.py:19] end experts_map_get cost 0.0015480518341064453 seconds
DEBUG 01-05 09:19:50.984112.984112 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:50.984988.984988 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:50.984118.984118 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:50.984674.984674 cuda_h.py:19] end allocate_cuda_memory cost 0.00016450881958007812 seconds
DEBUG 01-05 09:19:50.985471.985471 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:50.985988.985988 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:50.985374.985374 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:50.985547.985547 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e4ce87f-0021-4665-8dca-efc502c00215
DEBUG 01-05 09:19:50.985043.985043 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:50.986087.986087 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e4ce87f-0021-4665-8dca-efc502c00215
DEBUG 01-05 09:19:50.986354.986354 cuda_h.py:19] end load_into_gpu_async cost 0.0012173652648925781 seconds
DEBUG 01-05 09:19:50.986818.986818 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:50.986401.986401 cuda_h.py:19] end restore_tensors2 cost 0.0003647804260253906 seconds
DEBUG 01-05 09:19:50.986675.986675 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020978450775146484 seconds
DEBUG 01-05 09:19:50.989064.989064 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004888296127319336 seconds
DEBUG 01-05 09:19:50.989623.989623 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:50.989347.989347 lmp.py:419] 
DEBUG 01-05 09:19:50.989347.989347 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:50.989521.989521 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-05 09:19:50.989125.989125 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.000342.000342 mlpmodule.py:704] group tensors cost 0.010317564010620117 s
DEBUG 01-05 09:19:51.002855.002855 mlpmodule.py:742] pad cost 0.001506805419921875 s
DEBUG 01-05 09:19:51.002965.002965 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-05 09:19:51.002908.002908 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-05 09:19:51.015134.015134 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.015517.015517 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.015322.015322 mlpmodule.py:773] group_w3 first element: -0.0380859375
WARNING 01-05 09:19:51.015783.015783 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.033052.033052 mlpmodule.py:793] group einsum cost 0.03113269805908203 s
DEBUG 01-05 09:19:51.036277.036277 mlpmodule.py:801] cpy2cputensor cost 0.0027353763580322266 s
DEBUG 01-05 09:19:51.077467.077467 cuda_h.py:19] end wait_cetm_experts cost 0.0879213809967041 seconds
DEBUG 01-05 09:19:51.077689.077689 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.078421.078421 cuda_h.py:19] end gpu_sexperts cost 0.0004622936248779297 seconds
DEBUG 01-05 09:19:51.078595.078595 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:19:51.078080.078080 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-05 09:19:51.078745.078745 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:19:51.078257.078257 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.078755.078755 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 0.00014734268188476562 seconds
DEBUG 01-05 09:19:51.078533.078533 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.078462.078462 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.078605.078605 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e4ce87f-0021-4665-8dca-efc502c00215
DEBUG 01-05 09:19:51.078286.078286 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.082379.082379 cuda_h.py:19] end allocate_cuda_memory cost 0.0037202835083007812 seconds
DEBUG 01-05 09:19:51.082110.082110 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.082972.082972 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.082947.082947 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.082703.082703 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f0e39fc7-1057-4088-869e-135815df23fd
DEBUG 01-05 09:19:51.083548.083548 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.083925.083925 client.py:127] Model loaded
DEBUG 01-05 09:19:51.083782.083782 cuda_h.py:19] end wait_experts cost 0.00448918342590332 seconds
DEBUG 01-05 09:19:51.083346.083346 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.083414.083414 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.083632.083632 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f0e39fc7-1057-4088-869e-135815df23fd
DEBUG 01-05 09:19:51.084197.084197 cuda_h.py:19] end load_into_gpu_async cost 0.0011835098266601562 seconds
DEBUG 01-05 09:19:51.084715.084715 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.084248.084248 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-05 09:19:51.084773.084773 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005479574203491211 seconds
DEBUG 01-05 09:19:51.084294.084294 mlpmodule.py:531] gpu group tensors cost 0.00109100341796875 s
INFO 01-05 09:19:51.084043.084043 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f0e39fc7-1057-4088-869e-135815df23fd
DEBUG 01-05 09:19:51.086157.086157 mlpmodule.py:564] gpu pad cost 0.001926422119140625 s
DEBUG 01-05 09:19:51.087656.087656 mlpmodule.py:582] gpu group einsum cost 0.0005750656127929688 s
DEBUG 01-05 09:19:51.090252.090252 mlpmodule.py:611] gpu experts func einsum cost 0.007346391677856445 s
DEBUG 01-05 09:19:51.090998.090998 cuda_h.py:19] end gpu_experts cost 0.007579326629638672 seconds
DEBUG 01-05 09:19:51.090715.090715 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.091058.091058 mlpmodule.py:662]  experts func einsum cost 0.10211682319641113 s
INFO 01-05 09:19:51.092945.092945 client.py:127] Model loaded
DEBUG 01-05 09:19:51.092503.092503 cuda_h.py:19] end sllm_worker_task cost 0.013959646224975586 seconds
DEBUG 01-05 09:19:51.092492.092492 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0016269683837890625 seconds
DEBUG 01-05 09:19:51.092749.092749 cuda_h.py:19] end layer_moe_generate_2 cost 0.1104896068572998 seconds
DEBUG 01-05 09:19:51.092213.092213 lmp.py:214] -------------------------------- end layer 2 --------------------------------
DEBUG 01-05 09:19:51.093850.093850 lmp.py:173] -------------------------------- start layer 3 --------------------------------
DEBUG 01-05 09:19:51.093831.093831 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.093880.093880 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.095944.095944 cuda_h.py:19] end self_attn cost 0.0024497509002685547 seconds
DEBUG 01-05 09:19:51.096981.096981 cuda_h.py:19] end iln_self_attn_paln cost 0.0030641555786132812 seconds
DEBUG 01-05 09:19:51.096393.096393 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-05 09:19:51.096348.096348 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.096125.096125 cuda_h.py:19] end gate cost 0.0006091594696044922 seconds
DEBUG 01-05 09:19:51.096669.096669 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.097037.097037 lmp.py:361] 
DEBUG 01-05 09:19:51.097037.097037 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.097462.097462 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.097066.097066 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.097570.097570 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.097643.097643 lmp.py:365] 
DEBUG 01-05 09:19:51.097643.097643 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.097286.097286 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.097651.097651 lmp.py:372]   Expert 61 |     49 | CPU
DEBUG 01-05 09:19:51.097817.097817 lmp.py:372]   Expert 15 |     63 | CPU
DEBUG 01-05 09:19:51.097745.097745 lmp.py:372]   Expert 32 |     67 | CPU
DEBUG 01-05 09:19:51.097580.097580 lmp.py:372]   Expert  4 |     84 | CPU
DEBUG 01-05 09:19:51.097269.097269 lmp.py:372]   Expert 16 |     85 | CPU
DEBUG 01-05 09:19:51.097436.097436 lmp.py:372]   Expert 59 |     85 | CPU
DEBUG 01-05 09:19:51.097840.097840 lmp.py:372]   Expert  1 |     89 | CPU
DEBUG 01-05 09:19:51.097529.097529 lmp.py:372]   Expert 37 |     98 | CPU
DEBUG 01-05 09:19:51.097411.097411 lmp.py:372]   Expert  6 |    103 | CPU
DEBUG 01-05 09:19:51.097100.097100 lmp.py:372]   Expert 28 |    111 | CPU
DEBUG 01-05 09:19:51.097551.097551 lmp.py:372]   Expert  7 |    112 | CPU
DEBUG 01-05 09:19:51.097002.097002 lmp.py:372]   Expert  5 |    122 | CPU
DEBUG 01-05 09:19:51.097214.097214 lmp.py:372]   Expert 36 |    127 | CPU
DEBUG 01-05 09:19:51.097427.097427 lmp.py:372]   Expert  8 |    130 | CPU
DEBUG 01-05 09:19:51.097639.097639 lmp.py:372]   Expert 44 |    133 | CPU
DEBUG 01-05 09:19:51.097329.097329 lmp.py:372]   Expert 42 |    135 | CPU
DEBUG 01-05 09:19:51.097256.097256 lmp.py:372]   Expert 63 |    137 | CPU
DEBUG 01-05 09:19:51.097615.097615 lmp.py:372]   Expert 24 |    139 | CPU
DEBUG 01-05 09:19:51.097827.097827 lmp.py:372]   Expert 52 |    139 | CPU
DEBUG 01-05 09:19:51.097801.097801 lmp.py:372]   Expert 10 |    142 | CPU
DEBUG 01-05 09:19:51.097775.097775 lmp.py:372]   Expert 29 |    144 | CPU
DEBUG 01-05 09:19:51.097988.097988 lmp.py:372]   Expert 49 |    146 | CPU
DEBUG 01-05 09:19:51.097723.097723 lmp.py:372]   Expert 55 |    151 | CPU
DEBUG 01-05 09:19:51.097797.097797 lmp.py:372]   Expert 12 |    152 | CPU
DEBUG 01-05 09:19:51.097724.097724 lmp.py:372]   Expert 38 |    152 | CPU
DEBUG 01-05 09:19:51.097175.097175 lmp.py:372]   Expert 23 |    156 | CPU
DEBUG 01-05 09:19:51.097388.097388 lmp.py:372]   Expert 26 |    157 | CPU
DEBUG 01-05 09:19:51.097885.097885 lmp.py:372]   Expert 30 |    163 | CPU
DEBUG 01-05 09:19:51.097336.097336 lmp.py:372]   Expert 57 |    166 | CPU
DEBUG 01-05 09:19:51.097217.097217 lmp.py:372]   Expert 11 |    167 | CPU
DEBUG 01-05 09:19:51.097430.097430 lmp.py:372]   Expert 56 |    168 | CPU
DEBUG 01-05 09:19:51.097119.097119 lmp.py:372]   Expert 58 |    173 | CPU
DEBUG 01-05 09:19:51.097047.097047 lmp.py:372]   Expert 18 |    177 | GPU
DEBUG 01-05 09:19:51.097259.097259 lmp.py:372]   Expert 62 |    177 | GPU
DEBUG 01-05 09:19:51.097425.097425 lmp.py:372]   Expert 40 |    179 | GPU
DEBUG 01-05 09:19:51.097353.097353 lmp.py:372]   Expert 48 |    188 | GPU
DEBUG 01-05 09:19:51.097565.097565 lmp.py:372]   Expert 47 |    190 | GPU
DEBUG 01-05 09:19:51.098540.098540 lmp.py:372]   Expert 35 |    192 | GPU
DEBUG 01-05 09:19:51.098275.098275 lmp.py:372]   Expert 31 |    194 | GPU
DEBUG 01-05 09:19:51.098680.098680 lmp.py:372]   Expert  2 |    195 | GPU
DEBUG 01-05 09:19:51.098369.098369 lmp.py:372]   Expert 13 |    195 | GPU
DEBUG 01-05 09:19:51.098489.098489 lmp.py:372]   Expert 20 |    208 | GPU
DEBUG 01-05 09:19:51.098701.098701 lmp.py:372]   Expert  0 |    209 | GPU
DEBUG 01-05 09:19:51.098675.098675 lmp.py:372]   Expert 45 |    217 | GPU
DEBUG 01-05 09:19:51.098888.098888 lmp.py:372]   Expert 46 |    227 | GPU
DEBUG 01-05 09:19:51.098862.098862 lmp.py:372]   Expert 33 |    233 | GPU
DEBUG 01-05 09:19:51.098836.098836 lmp.py:372]   Expert 39 |    233 | GPU
DEBUG 01-05 09:19:51.098148.098148 lmp.py:372]   Expert 19 |    234 | GPU
DEBUG 01-05 09:19:51.098599.098599 lmp.py:372]   Expert 22 |    235 | GPU
DEBUG 01-05 09:19:51.098811.098811 lmp.py:372]   Expert 34 |    238 | GPU
DEBUG 01-05 09:19:51.098024.098024 lmp.py:372]   Expert 51 |    241 | GPU
DEBUG 01-05 09:19:51.098998.098998 lmp.py:372]   Expert 17 |    242 | GPU
DEBUG 01-05 09:19:51.098210.098210 lmp.py:372]   Expert 53 |    249 | GPU
DEBUG 01-05 09:19:51.098568.098568 lmp.py:372]   Expert  3 |    264 | GPU
DEBUG 01-05 09:19:51.098781.098781 lmp.py:372]   Expert 27 |    282 | GPU
DEBUG 01-05 09:19:51.098993.098993 lmp.py:372]   Expert 54 |    294 | GPU
DEBUG 01-05 09:19:51.098206.098206 lmp.py:372]   Expert 50 |    310 | GPU
DEBUG 01-05 09:19:51.098657.098657 lmp.py:372]   Expert 60 |    321 | GPU
DEBUG 01-05 09:19:51.098869.098869 lmp.py:372]   Expert 21 |    334 | GPU
DEBUG 01-05 09:19:51.098989.098989 lmp.py:372]   Expert 14 |    342 | GPU
DEBUG 01-05 09:19:51.098724.098724 lmp.py:372]   Expert  9 |    386 | GPU
DEBUG 01-05 09:19:51.098937.098937 lmp.py:372]   Expert 43 |    392 | GPU
DEBUG 01-05 09:19:51.098911.098911 lmp.py:372]   Expert 41 |    400 | GPU
DEBUG 01-05 09:19:51.098647.098647 lmp.py:372]   Expert 25 |    465 | GPU
DEBUG 01-05 09:19:51.098574.098574 lmp.py:373] 
DEBUG 01-05 09:19:51.098574.098574 lmp.py:373]   CPU total tokens: 4045 (32.9%)
DEBUG 01-05 09:19:51.098694.098694 lmp.py:374]   GPU total tokens: 8243 (67.1%)
DEBUG 01-05 09:19:51.098867.098867 cuda_h.py:19] end experts_map_get cost 0.0015213489532470703 seconds
DEBUG 01-05 09:19:51.098941.098941 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.098578.098578 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.098900.098900 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.098214.098214 cuda_h.py:19] end allocate_cuda_memory cost 0.00023102760314941406 seconds
DEBUG 01-05 09:19:51.099872.099872 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.099151.099151 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.099967.099967 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.099855.099855 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7c66e627-128d-42a8-8285-0e01adc25b72
DEBUG 01-05 09:19:51.099120.099120 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.100313.100313 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7c66e627-128d-42a8-8285-0e01adc25b72
DEBUG 01-05 09:19:51.100917.100917 cuda_h.py:19] end load_into_gpu_async cost 0.0013301372528076172 seconds
DEBUG 01-05 09:19:51.100051.100051 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.100979.100979 cuda_h.py:19] end restore_tensors2 cost 0.0004088878631591797 seconds
DEBUG 01-05 09:19:51.100869.100869 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023338794708251953 seconds
DEBUG 01-05 09:19:51.103139.103139 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00510406494140625 seconds
DEBUG 01-05 09:19:51.103697.103697 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.103183.103183 lmp.py:419] 
DEBUG 01-05 09:19:51.103183.103183 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.103834.103834 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-05 09:19:51.103961.103961 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.108450.108450 mlpmodule.py:704] group tensors cost 0.00478816032409668 s
DEBUG 01-05 09:19:51.110586.110586 mlpmodule.py:742] pad cost 0.001508474349975586 s
DEBUG 01-05 09:19:51.110272.110272 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:19:51.111360.111360 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-05 09:19:51.122715.122715 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.122430.122430 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.122619.122619 mlpmodule.py:773] group_w3 first element: -0.054931640625
WARNING 01-05 09:19:51.123372.123372 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.139609.139609 mlpmodule.py:793] group einsum cost 0.028716087341308594 s
DEBUG 01-05 09:19:51.140847.140847 mlpmodule.py:801] cpy2cputensor cost 0.0007846355438232422 s
DEBUG 01-05 09:19:51.183839.183839 cuda_h.py:19] end wait_cetm_experts cost 0.07999658584594727 seconds
DEBUG 01-05 09:19:51.183101.183101 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.184078.184078 cuda_h.py:19] end gpu_sexperts cost 0.0004696846008300781 seconds
DEBUG 01-05 09:19:51.184219.184219 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:19:51.184135.184135 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-05 09:19:51.184653.184653 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:19:51.184840.184840 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.081031799316406e-05 seconds
DEBUG 01-05 09:19:51.184443.184443 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.184683.184683 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7c66e627-128d-42a8-8285-0e01adc25b72
DEBUG 01-05 09:19:51.184854.184854 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.185493.185493 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.185097.185097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.189070.189070 cuda_h.py:19] end allocate_cuda_memory cost 0.003907918930053711 seconds
DEBUG 01-05 09:19:51.189411.189411 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.189889.189889 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.189195.189195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.189759.189759 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43500ed2-8b4c-43a8-92cb-5f18842949e1
DEBUG 01-05 09:19:51.189696.189696 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.189729.189729 client.py:127] Model loaded
DEBUG 01-05 09:19:51.189109.189109 cuda_h.py:19] end wait_experts cost 0.0048100948333740234 seconds
DEBUG 01-05 09:19:51.189627.189627 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.189714.189714 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.190647.190647 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43500ed2-8b4c-43a8-92cb-5f18842949e1
DEBUG 01-05 09:19:51.190735.190735 cuda_h.py:19] end load_into_gpu_async cost 0.0011489391326904297 seconds
DEBUG 01-05 09:19:51.190538.190538 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.190548.190548 cuda_h.py:19] end restore_tensors2 cost 8.344650268554688e-05 seconds
DEBUG 01-05 09:19:51.190165.190165 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005413532257080078 seconds
DEBUG 01-05 09:19:51.190037.190037 mlpmodule.py:531] gpu group tensors cost 0.0010704994201660156 s
INFO 01-05 09:19:51.191825.191825 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43500ed2-8b4c-43a8-92cb-5f18842949e1
DEBUG 01-05 09:19:51.192120.192120 mlpmodule.py:564] gpu pad cost 0.0019047260284423828 s
DEBUG 01-05 09:19:51.193956.193956 mlpmodule.py:582] gpu group einsum cost 0.0005409717559814453 s
DEBUG 01-05 09:19:51.197549.197549 mlpmodule.py:611] gpu experts func einsum cost 0.007453441619873047 s
DEBUG 01-05 09:19:51.197443.197443 cuda_h.py:19] end gpu_experts cost 0.0077364444732666016 seconds
DEBUG 01-05 09:19:51.197113.197113 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.198017.198017 mlpmodule.py:662]  experts func einsum cost 0.09451079368591309 s
INFO 01-05 09:19:51.198109.198109 client.py:127] Model loaded
DEBUG 01-05 09:19:51.198906.198906 cuda_h.py:19] end sllm_worker_task cost 0.013931512832641602 seconds
DEBUG 01-05 09:19:51.199987.199987 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0015575885772705078 seconds
DEBUG 01-05 09:19:51.199191.199191 cuda_h.py:19] end layer_moe_generate_3 cost 0.10290908813476562 seconds
DEBUG 01-05 09:19:51.199039.199039 lmp.py:214] -------------------------------- end layer 3 --------------------------------
DEBUG 01-05 09:19:51.199100.199100 lmp.py:173] -------------------------------- start layer 4 --------------------------------
DEBUG 01-05 09:19:51.199558.199558 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.199223.199223 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.202983.202983 cuda_h.py:19] end self_attn cost 0.002471446990966797 seconds
DEBUG 01-05 09:19:51.202862.202862 cuda_h.py:19] end iln_self_attn_paln cost 0.003107309341430664 seconds
DEBUG 01-05 09:19:51.202274.202274 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-05 09:19:51.202183.202183 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.203303.203303 cuda_h.py:19] end gate cost 0.0005786418914794922 seconds
DEBUG 01-05 09:19:51.203371.203371 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.203116.203116 lmp.py:361] 
DEBUG 01-05 09:19:51.203116.203116 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.203349.203349 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.203475.203475 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.203741.203741 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.203291.203291 lmp.py:365] 
DEBUG 01-05 09:19:51.203291.203291 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.203696.203696 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.203345.203345 lmp.py:372]   Expert 13 |     41 | CPU
DEBUG 01-05 09:19:51.203227.203227 lmp.py:372]   Expert 60 |     49 | CPU
DEBUG 01-05 09:19:51.203155.203155 lmp.py:372]   Expert 11 |     65 | CPU
DEBUG 01-05 09:19:51.203228.203228 lmp.py:372]   Expert 56 |     79 | CPU
DEBUG 01-05 09:19:51.203633.203633 lmp.py:372]   Expert  3 |     81 | CPU
DEBUG 01-05 09:19:51.203799.203799 lmp.py:372]   Expert 26 |     82 | CPU
DEBUG 01-05 09:19:51.203011.203011 lmp.py:372]   Expert 36 |     84 | CPU
DEBUG 01-05 09:19:51.203701.203701 lmp.py:372]   Expert 58 |     87 | CPU
DEBUG 01-05 09:19:51.203628.203628 lmp.py:372]   Expert  7 |     89 | CPU
DEBUG 01-05 09:19:51.203748.203748 lmp.py:372]   Expert 34 |     91 | CPU
DEBUG 01-05 09:19:51.203722.203722 lmp.py:372]   Expert 25 |     92 | CPU
DEBUG 01-05 09:19:51.203696.203696 lmp.py:372]   Expert 51 |     96 | CPU
DEBUG 01-05 09:19:51.203909.203909 lmp.py:372]   Expert 45 |     97 | CPU
DEBUG 01-05 09:19:51.203598.203598 lmp.py:372]   Expert 48 |     98 | CPU
DEBUG 01-05 09:19:51.204526.204526 lmp.py:372]   Expert 28 |    101 | CPU
DEBUG 01-05 09:19:51.204361.204361 lmp.py:372]   Expert 41 |    104 | CPU
DEBUG 01-05 09:19:51.204335.204335 lmp.py:372]   Expert 16 |    108 | CPU
DEBUG 01-05 09:19:51.204309.204309 lmp.py:372]   Expert  6 |    110 | CPU
DEBUG 01-05 09:19:51.204521.204521 lmp.py:372]   Expert 33 |    113 | CPU
DEBUG 01-05 09:19:51.204257.204257 lmp.py:372]   Expert  9 |    120 | CPU
DEBUG 01-05 09:19:51.204708.204708 lmp.py:372]   Expert 18 |    120 | CPU
DEBUG 01-05 09:19:51.204543.204543 lmp.py:372]   Expert 14 |    128 | CPU
DEBUG 01-05 09:19:51.204471.204471 lmp.py:372]   Expert 55 |    130 | CPU
DEBUG 01-05 09:19:51.204921.204921 lmp.py:372]   Expert 24 |    131 | CPU
DEBUG 01-05 09:19:51.204134.204134 lmp.py:372]   Expert 17 |    137 | CPU
DEBUG 01-05 09:19:51.204108.204108 lmp.py:372]   Expert  4 |    139 | CPU
DEBUG 01-05 09:19:51.204989.204989 lmp.py:372]   Expert 47 |    146 | CPU
DEBUG 01-05 09:19:51.204917.204917 lmp.py:372]   Expert  2 |    151 | CPU
DEBUG 01-05 09:19:51.204130.204130 lmp.py:372]   Expert 44 |    153 | CPU
DEBUG 01-05 09:19:51.204819.204819 lmp.py:372]   Expert 50 |    153 | CPU
DEBUG 01-05 09:19:51.204031.204031 lmp.py:372]   Expert 22 |    167 | CPU
DEBUG 01-05 09:19:51.204959.204959 lmp.py:372]   Expert 54 |    170 | CPU
DEBUG 01-05 09:19:51.204840.204840 lmp.py:372]   Expert 31 |    179 | GPU
DEBUG 01-05 09:19:51.204530.204530 lmp.py:372]   Expert 10 |    183 | GPU
DEBUG 01-05 09:19:51.204742.204742 lmp.py:372]   Expert 37 |    191 | GPU
DEBUG 01-05 09:19:51.204478.204478 lmp.py:372]   Expert 15 |    194 | GPU
DEBUG 01-05 09:19:51.204452.204452 lmp.py:372]   Expert 40 |    195 | GPU
DEBUG 01-05 09:19:51.204578.204578 lmp.py:372]   Expert 21 |    196 | GPU
DEBUG 01-05 09:19:51.204745.204745 lmp.py:372]   Expert 46 |    197 | GPU
DEBUG 01-05 09:19:51.204388.204388 lmp.py:372]   Expert 61 |    199 | GPU
DEBUG 01-05 09:19:51.204984.204984 lmp.py:372]   Expert  8 |    201 | GPU
DEBUG 01-05 09:19:51.204197.204197 lmp.py:372]   Expert 53 |    209 | GPU
DEBUG 01-05 09:19:51.204409.204409 lmp.py:372]   Expert 42 |    210 | GPU
DEBUG 01-05 09:19:51.204860.204860 lmp.py:372]   Expert 63 |    212 | GPU
DEBUG 01-05 09:19:51.204834.204834 lmp.py:372]   Expert 29 |    218 | GPU
DEBUG 01-05 09:19:51.204808.204808 lmp.py:372]   Expert 20 |    223 | GPU
DEBUG 01-05 09:19:51.204166.204166 lmp.py:372]   Expert 27 |    225 | GPU
DEBUG 01-05 09:19:51.204379.204379 lmp.py:372]   Expert 57 |    236 | GPU
DEBUG 01-05 09:19:51.204353.204353 lmp.py:372]   Expert 32 |    239 | GPU
DEBUG 01-05 09:19:51.204042.204042 lmp.py:372]   Expert 38 |    255 | GPU
DEBUG 01-05 09:19:51.204208.204208 lmp.py:372]   Expert 19 |    258 | GPU
DEBUG 01-05 09:19:51.204421.204421 lmp.py:372]   Expert 23 |    269 | GPU
DEBUG 01-05 09:19:51.204017.204017 lmp.py:372]   Expert  0 |    276 | GPU
DEBUG 01-05 09:19:51.204230.204230 lmp.py:372]   Expert 12 |    287 | GPU
DEBUG 01-05 09:19:51.204442.204442 lmp.py:372]   Expert  1 |    294 | GPU
DEBUG 01-05 09:19:51.204655.204655 lmp.py:372]   Expert 62 |    304 | GPU
DEBUG 01-05 09:19:51.204629.204629 lmp.py:372]   Expert 30 |    307 | GPU
DEBUG 01-05 09:19:51.204318.204318 lmp.py:372]   Expert 49 |    325 | GPU
DEBUG 01-05 09:19:51.204007.204007 lmp.py:372]   Expert 35 |    327 | GPU
DEBUG 01-05 09:19:51.204127.204127 lmp.py:372]   Expert 52 |    406 | GPU
DEBUG 01-05 09:19:51.204578.204578 lmp.py:372]   Expert 39 |    420 | GPU
DEBUG 01-05 09:19:51.204314.204314 lmp.py:372]   Expert  5 |    430 | GPU
DEBUG 01-05 09:19:51.204526.204526 lmp.py:372]   Expert 43 |    496 | GPU
DEBUG 01-05 09:19:51.204739.204739 lmp.py:372]   Expert 59 |    615 | GPU
DEBUG 01-05 09:19:51.204666.204666 lmp.py:373] 
DEBUG 01-05 09:19:51.204666.204666 lmp.py:373]   CPU total tokens: 3512 (28.6%)
DEBUG 01-05 09:19:51.204694.204694 lmp.py:374]   GPU total tokens: 8776 (71.4%)
DEBUG 01-05 09:19:51.204582.204582 cuda_h.py:19] end experts_map_get cost 0.0015320777893066406 seconds
DEBUG 01-05 09:19:51.204225.204225 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.204339.204339 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.205668.205668 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.205200.205200 cuda_h.py:19] end allocate_cuda_memory cost 0.00021767616271972656 seconds
DEBUG 01-05 09:19:51.205188.205188 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.205944.205944 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.205853.205853 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.205695.205695 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1e69f6e3-ee47-4080-93b4-6a33b7813827
DEBUG 01-05 09:19:51.205529.205529 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.206982.206982 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1e69f6e3-ee47-4080-93b4-6a33b7813827
DEBUG 01-05 09:19:51.206911.206911 cuda_h.py:19] end load_into_gpu_async cost 0.0013802051544189453 seconds
DEBUG 01-05 09:19:51.206422.206422 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.207615.207615 cuda_h.py:19] end restore_tensors2 cost 0.0003943443298339844 seconds
DEBUG 01-05 09:19:51.207074.207074 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023453235626220703 seconds
DEBUG 01-05 09:19:51.210435.210435 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005079030990600586 seconds
DEBUG 01-05 09:19:51.210610.210610 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.210665.210665 lmp.py:419] 
DEBUG 01-05 09:19:51.210665.210665 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.210052.210052 cuda_h.py:19] end cpu_experts_submit cost 0.0001227855682373047 seconds
DEBUG 01-05 09:19:51.210655.210655 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.215955.215955 mlpmodule.py:704] group tensors cost 0.0054509639739990234 s
DEBUG 01-05 09:19:51.218124.218124 mlpmodule.py:742] pad cost 0.0019669532775878906 s
DEBUG 01-05 09:19:51.218447.218447 mlpmodule.py:748] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-05 09:19:51.218701.218701 mlpmodule.py:753] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-05 09:19:51.229533.229533 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.230624.230624 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.230913.230913 mlpmodule.py:773] group_w3 first element: -0.039794921875
WARNING 01-05 09:19:51.230434.230434 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.247048.247048 mlpmodule.py:793] group einsum cost 0.028849124908447266 s
DEBUG 01-05 09:19:51.248112.248112 mlpmodule.py:801] cpy2cputensor cost 0.0009427070617675781 s
DEBUG 01-05 09:19:51.290967.290967 cuda_h.py:19] end wait_cetm_experts cost 0.08066415786743164 seconds
DEBUG 01-05 09:19:51.291043.291043 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.291344.291344 cuda_h.py:19] end gpu_sexperts cost 0.000461578369140625 seconds
DEBUG 01-05 09:19:51.291518.291518 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:19:51.291526.291526 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-05 09:19:51.291476.291476 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.170967102050781e-05 seconds
DEBUG 01-05 09:19:51.291715.291715 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.152557373046875e-05 seconds
DEBUG 01-05 09:19:51.291372.291372 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.291082.291082 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1e69f6e3-ee47-4080-93b4-6a33b7813827
DEBUG 01-05 09:19:51.291345.291345 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.292268.292268 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.292251.292251 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.296965.296965 cuda_h.py:19] end allocate_cuda_memory cost 0.004277229309082031 seconds
DEBUG 01-05 09:19:51.296259.296259 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.296929.296929 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.296189.296189 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.296991.296991 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5525d503-bbcc-490a-a2e2-5047e80ffbf3
DEBUG 01-05 09:19:51.296888.296888 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.296869.296869 client.py:127] Model loaded
DEBUG 01-05 09:19:51.296056.296056 cuda_h.py:19] end wait_experts cost 0.005178213119506836 seconds
DEBUG 01-05 09:19:51.297574.297574 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.297615.297615 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.297747.297747 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5525d503-bbcc-490a-a2e2-5047e80ffbf3
DEBUG 01-05 09:19:51.297571.297571 cuda_h.py:19] end load_into_gpu_async cost 0.0011746883392333984 seconds
DEBUG 01-05 09:19:51.297817.297817 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.297212.297212 cuda_h.py:19] end restore_tensors2 cost 8.440017700195312e-05 seconds
DEBUG 01-05 09:19:51.297975.297975 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005825042724609375 seconds
DEBUG 01-05 09:19:51.297096.297096 mlpmodule.py:531] gpu group tensors cost 0.0008327960968017578 s
INFO 01-05 09:19:51.298565.298565 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5525d503-bbcc-490a-a2e2-5047e80ffbf3
DEBUG 01-05 09:19:51.303824.303824 mlpmodule.py:564] gpu pad cost 0.005444049835205078 s
INFO 01-05 09:19:51.305939.305939 client.py:127] Model loaded
DEBUG 01-05 09:19:51.305445.305445 cuda_h.py:19] end sllm_worker_task cost 0.013370752334594727 seconds
DEBUG 01-05 09:19:51.306359.306359 mlpmodule.py:662]  experts func einsum cost 0.09624838829040527 s
DEBUG 01-05 09:19:51.307849.307849 mlpmodule.py:582] gpu group einsum cost 0.0034546852111816406 s
DEBUG 01-05 09:19:51.310294.310294 mlpmodule.py:611] gpu experts func einsum cost 0.012884378433227539 s
DEBUG 01-05 09:19:51.310166.310166 cuda_h.py:19] end gpu_experts cost 0.01311945915222168 seconds
DEBUG 01-05 09:19:51.310969.310969 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.310428.310428 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:19:51.310981.310981 cuda_h.py:19] end layer_moe_generate_4 cost 0.10772204399108887 seconds
DEBUG 01-05 09:19:51.310783.310783 lmp.py:214] -------------------------------- end layer 4 --------------------------------
DEBUG 01-05 09:19:51.310175.310175 lmp.py:173] -------------------------------- start layer 5 --------------------------------
DEBUG 01-05 09:19:51.310394.310394 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.310106.310106 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.313871.313871 cuda_h.py:19] end self_attn cost 0.002439737319946289 seconds
DEBUG 01-05 09:19:51.313610.313610 cuda_h.py:19] end iln_self_attn_paln cost 0.003044605255126953 seconds
DEBUG 01-05 09:19:51.313215.313215 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-05 09:19:51.313931.313931 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.314780.314780 cuda_h.py:19] end gate cost 0.0005748271942138672 seconds
DEBUG 01-05 09:19:51.314086.314086 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.314977.314977 lmp.py:361] 
DEBUG 01-05 09:19:51.314977.314977 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.314925.314925 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.314337.314337 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.314649.314649 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.314053.314053 lmp.py:365] 
DEBUG 01-05 09:19:51.314053.314053 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.314080.314080 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.314730.314730 lmp.py:372]   Expert 34 |     27 | CPU
DEBUG 01-05 09:19:51.314135.314135 lmp.py:372]   Expert 15 |     50 | CPU
DEBUG 01-05 09:19:51.314824.314824 lmp.py:372]   Expert 39 |     51 | CPU
DEBUG 01-05 09:19:51.314513.314513 lmp.py:372]   Expert 47 |     53 | CPU
DEBUG 01-05 09:19:51.315110.315110 lmp.py:372]   Expert  2 |     54 | CPU
DEBUG 01-05 09:19:51.315322.315322 lmp.py:372]   Expert 18 |     68 | CPU
DEBUG 01-05 09:19:51.315727.315727 lmp.py:372]   Expert 23 |     82 | CPU
DEBUG 01-05 09:19:51.315131.315131 lmp.py:372]   Expert  3 |     85 | CPU
DEBUG 01-05 09:19:51.315582.315582 lmp.py:372]   Expert 27 |     89 | CPU
DEBUG 01-05 09:19:51.315033.315033 lmp.py:372]   Expert 30 |     99 | CPU
DEBUG 01-05 09:19:51.315391.315391 lmp.py:372]   Expert 52 |    107 | CPU
DEBUG 01-05 09:19:51.315365.315365 lmp.py:372]   Expert  0 |    112 | CPU
DEBUG 01-05 09:19:51.315578.315578 lmp.py:372]   Expert 17 |    113 | CPU
DEBUG 01-05 09:19:51.315790.315790 lmp.py:372]   Expert  4 |    114 | CPU
DEBUG 01-05 09:19:51.315526.315526 lmp.py:372]   Expert 28 |    114 | CPU
DEBUG 01-05 09:19:51.315500.315500 lmp.py:372]   Expert 22 |    116 | CPU
DEBUG 01-05 09:19:51.315474.315474 lmp.py:372]   Expert 62 |    117 | CPU
DEBUG 01-05 09:19:51.315163.315163 lmp.py:372]   Expert 45 |    119 | CPU
DEBUG 01-05 09:19:51.315376.315376 lmp.py:372]   Expert  9 |    123 | CPU
DEBUG 01-05 09:19:51.315734.315734 lmp.py:372]   Expert 60 |    125 | CPU
DEBUG 01-05 09:19:51.315947.315947 lmp.py:372]   Expert  8 |    127 | CPU
DEBUG 01-05 09:19:51.315682.315682 lmp.py:372]   Expert 63 |    127 | CPU
DEBUG 01-05 09:19:51.315895.315895 lmp.py:372]   Expert 48 |    131 | CPU
DEBUG 01-05 09:19:51.315346.315346 lmp.py:372]   Expert 14 |    140 | CPU
DEBUG 01-05 09:19:51.315320.315320 lmp.py:372]   Expert 51 |    142 | CPU
DEBUG 01-05 09:19:51.315678.315678 lmp.py:372]   Expert 54 |    142 | CPU
DEBUG 01-05 09:19:51.315413.315413 lmp.py:372]   Expert 41 |    148 | CPU
DEBUG 01-05 09:19:51.315580.315580 lmp.py:372]   Expert 46 |    153 | CPU
DEBUG 01-05 09:19:51.315507.315507 lmp.py:372]   Expert 10 |    156 | CPU
DEBUG 01-05 09:19:51.315958.315958 lmp.py:372]   Expert 36 |    158 | CPU
DEBUG 01-05 09:19:51.315171.315171 lmp.py:372]   Expert  1 |    161 | CPU
DEBUG 01-05 09:19:51.315529.315529 lmp.py:372]   Expert 57 |    162 | CPU
DEBUG 01-05 09:19:51.315264.315264 lmp.py:372]   Expert 43 |    166 | GPU
DEBUG 01-05 09:19:51.315477.315477 lmp.py:372]   Expert 25 |    169 | GPU
DEBUG 01-05 09:19:51.315166.315166 lmp.py:372]   Expert 38 |    172 | GPU
DEBUG 01-05 09:19:51.315332.315332 lmp.py:372]   Expert 24 |    178 | GPU
DEBUG 01-05 09:19:51.315783.315783 lmp.py:372]   Expert 26 |    181 | GPU
DEBUG 01-05 09:19:51.315426.315426 lmp.py:372]   Expert 32 |    181 | GPU
DEBUG 01-05 09:19:51.315116.315116 lmp.py:372]   Expert 11 |    192 | GPU
DEBUG 01-05 09:19:51.315090.315090 lmp.py:372]   Expert 29 |    196 | GPU
DEBUG 01-05 09:19:51.315064.315064 lmp.py:372]   Expert 56 |    203 | GPU
DEBUG 01-05 09:19:51.315276.315276 lmp.py:372]   Expert 58 |    204 | GPU
DEBUG 01-05 09:19:51.315250.315250 lmp.py:372]   Expert 16 |    207 | GPU
DEBUG 01-05 09:19:51.315132.315132 lmp.py:372]   Expert 12 |    215 | GPU
DEBUG 01-05 09:19:51.315867.315867 lmp.py:372]   Expert 55 |    218 | GPU
DEBUG 01-05 09:19:51.315556.315556 lmp.py:372]   Expert 19 |    225 | GPU
DEBUG 01-05 09:19:51.315246.315246 lmp.py:372]   Expert 42 |    225 | GPU
DEBUG 01-05 09:19:51.315220.315220 lmp.py:372]   Expert 50 |    225 | GPU
DEBUG 01-05 09:19:51.315955.315955 lmp.py:372]   Expert 44 |    226 | GPU
DEBUG 01-05 09:19:51.315598.315598 lmp.py:372]   Expert 61 |    227 | GPU
DEBUG 01-05 09:19:51.315572.315572 lmp.py:372]   Expert  7 |    237 | GPU
DEBUG 01-05 09:19:51.315070.315070 lmp.py:372]   Expert 35 |    238 | GPU
DEBUG 01-05 09:19:51.315044.315044 lmp.py:372]   Expert 59 |    251 | GPU
DEBUG 01-05 09:19:51.315541.315541 lmp.py:372]   Expert  5 |    279 | GPU
DEBUG 01-05 09:19:51.315277.315277 lmp.py:372]   Expert 21 |    288 | GPU
DEBUG 01-05 09:19:51.315443.315443 lmp.py:372]   Expert 40 |    295 | GPU
DEBUG 01-05 09:19:51.315132.315132 lmp.py:372]   Expert 20 |    303 | GPU
DEBUG 01-05 09:19:51.315868.315868 lmp.py:372]   Expert 31 |    322 | GPU
DEBUG 01-05 09:19:51.315511.315511 lmp.py:372]   Expert 13 |    350 | GPU
DEBUG 01-05 09:19:51.315485.315485 lmp.py:372]   Expert 33 |    362 | GPU
DEBUG 01-05 09:19:51.315982.315982 lmp.py:372]   Expert 49 |    384 | GPU
DEBUG 01-05 09:19:51.315717.315717 lmp.py:372]   Expert  6 |    399 | GPU
DEBUG 01-05 09:19:51.315215.315215 lmp.py:372]   Expert 37 |    492 | GPU
DEBUG 01-05 09:19:51.315950.315950 lmp.py:372]   Expert 53 |    913 | GPU
DEBUG 01-05 09:19:51.315309.315309 lmp.py:373] 
DEBUG 01-05 09:19:51.315309.315309 lmp.py:373]   CPU total tokens: 3565 (29.0%)
DEBUG 01-05 09:19:51.316475.316475 lmp.py:374]   GPU total tokens: 8723 (71.0%)
DEBUG 01-05 09:19:51.316171.316171 cuda_h.py:19] end experts_map_get cost 0.0015094280242919922 seconds
DEBUG 01-05 09:19:51.316291.316291 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.316166.316166 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.316065.316065 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.316496.316496 cuda_h.py:19] end allocate_cuda_memory cost 0.0001785755157470703 seconds
DEBUG 01-05 09:19:51.316962.316962 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.316393.316393 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.316779.316779 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.316713.316713 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9db5a3e-6f13-464b-8241-24748c15f111
DEBUG 01-05 09:19:51.316501.316501 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.317509.317509 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9db5a3e-6f13-464b-8241-24748c15f111
DEBUG 01-05 09:19:51.317484.317484 cuda_h.py:19] end load_into_gpu_async cost 0.0013380050659179688 seconds
DEBUG 01-05 09:19:51.317326.317326 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.318260.318260 cuda_h.py:19] end restore_tensors2 cost 0.00038170814514160156 seconds
DEBUG 01-05 09:19:51.318719.318719 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022454261779785156 seconds
DEBUG 01-05 09:19:51.321352.321352 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004969358444213867 seconds
DEBUG 01-05 09:19:51.321288.321288 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.321443.321443 lmp.py:419] 
DEBUG 01-05 09:19:51.321443.321443 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.321809.321809 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-05 09:19:51.321604.321604 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.326932.326932 mlpmodule.py:704] group tensors cost 0.0053141117095947266 s
DEBUG 01-05 09:19:51.329511.329511 mlpmodule.py:742] pad cost 0.001967906951904297 s
DEBUG 01-05 09:19:51.329925.329925 mlpmodule.py:748] create cpu tensor cost 5.030632019042969e-05 s
DEBUG 01-05 09:19:51.329610.329610 mlpmodule.py:753] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-05 09:19:51.341364.341364 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.341780.341780 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.341538.341538 mlpmodule.py:773] group_w3 first element: 0.03369140625
WARNING 01-05 09:19:51.341900.341900 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.360561.360561 mlpmodule.py:793] group einsum cost 0.030886411666870117 s
DEBUG 01-05 09:19:51.362089.362089 mlpmodule.py:801] cpy2cputensor cost 0.002118349075317383 s
DEBUG 01-05 09:19:51.404059.404059 cuda_h.py:19] end wait_cetm_experts cost 0.08294868469238281 seconds
DEBUG 01-05 09:19:51.404850.404850 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.404549.404549 cuda_h.py:19] end gpu_sexperts cost 0.0004737377166748047 seconds
DEBUG 01-05 09:19:51.404492.404492 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:19:51.404692.404692 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-05 09:19:51.405310.405310 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:19:51.405973.405973 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.224082946777344e-05 seconds
DEBUG 01-05 09:19:51.405292.405292 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.405286.405286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9db5a3e-6f13-464b-8241-24748c15f111
DEBUG 01-05 09:19:51.405126.405126 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.405003.405003 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.405370.405370 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.409207.409207 cuda_h.py:19] end allocate_cuda_memory cost 0.004404544830322266 seconds
DEBUG 01-05 09:19:51.409024.409024 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.409456.409456 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.410954.410954 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.410710.410710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be0eeb13-58e4-4bdc-a6db-b322e3b7b459
DEBUG 01-05 09:19:51.410462.410462 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.410780.410780 client.py:127] Model loaded
DEBUG 01-05 09:19:51.410637.410637 cuda_h.py:19] end wait_experts cost 0.005315065383911133 seconds
DEBUG 01-05 09:19:51.410154.410154 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.410718.410718 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.411161.411161 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be0eeb13-58e4-4bdc-a6db-b322e3b7b459
DEBUG 01-05 09:19:51.411064.411064 cuda_h.py:19] end load_into_gpu_async cost 0.0011489391326904297 seconds
DEBUG 01-05 09:19:51.411489.411489 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.411691.411691 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-05 09:19:51.411216.411216 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005917072296142578 seconds
DEBUG 01-05 09:19:51.411047.411047 mlpmodule.py:531] gpu group tensors cost 0.0010395050048828125 s
INFO 01-05 09:19:51.412801.412801 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be0eeb13-58e4-4bdc-a6db-b322e3b7b459
DEBUG 01-05 09:19:51.417436.417436 mlpmodule.py:564] gpu pad cost 0.00609278678894043 s
INFO 01-05 09:19:51.418175.418175 client.py:127] Model loaded
DEBUG 01-05 09:19:51.418972.418972 cuda_h.py:19] end sllm_worker_task cost 0.013498544692993164 seconds
DEBUG 01-05 09:19:51.422755.422755 mlpmodule.py:662]  experts func einsum cost 0.10089397430419922 s
DEBUG 01-05 09:19:51.423160.423160 mlpmodule.py:582] gpu group einsum cost 0.005299806594848633 s
DEBUG 01-05 09:19:51.426591.426591 mlpmodule.py:611] gpu experts func einsum cost 0.015697240829467773 s
DEBUG 01-05 09:19:51.426571.426571 cuda_h.py:19] end gpu_experts cost 0.01597428321838379 seconds
DEBUG 01-05 09:19:51.426062.426062 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.426746.426746 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-05 09:19:51.426029.426029 cuda_h.py:19] end layer_moe_generate_5 cost 0.1128854751586914 seconds
DEBUG 01-05 09:19:51.426844.426844 lmp.py:214] -------------------------------- end layer 5 --------------------------------
DEBUG 01-05 09:19:51.426289.426289 lmp.py:173] -------------------------------- start layer 6 --------------------------------
DEBUG 01-05 09:19:51.426654.426654 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.427313.427313 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.429913.429913 cuda_h.py:19] end self_attn cost 0.0024576187133789062 seconds
DEBUG 01-05 09:19:51.430221.430221 cuda_h.py:19] end iln_self_attn_paln cost 0.0030548572540283203 seconds
DEBUG 01-05 09:19:51.430872.430872 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-05 09:19:51.430040.430040 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.430530.430530 cuda_h.py:19] end gate cost 0.0005733966827392578 seconds
DEBUG 01-05 09:19:51.430598.430598 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.431443.431443 lmp.py:361] 
DEBUG 01-05 09:19:51.431443.431443 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.431106.431106 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.431471.431471 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.431737.431737 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.431572.431572 lmp.py:365] 
DEBUG 01-05 09:19:51.431572.431572 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.431168.431168 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.431818.431818 lmp.py:372]   Expert  1 |      6 | CPU
DEBUG 01-05 09:19:51.431461.431461 lmp.py:372]   Expert  3 |     30 | CPU
DEBUG 01-05 09:19:51.431150.431150 lmp.py:372]   Expert 14 |     48 | CPU
DEBUG 01-05 09:19:51.431555.431555 lmp.py:372]   Expert 53 |     51 | CPU
DEBUG 01-05 09:19:51.431436.431436 lmp.py:372]   Expert 15 |     60 | CPU
DEBUG 01-05 09:19:51.431364.431364 lmp.py:372]   Expert 52 |     67 | CPU
DEBUG 01-05 09:19:51.431007.431007 lmp.py:372]   Expert 35 |     71 | CPU
DEBUG 01-05 09:19:51.431935.431935 lmp.py:372]   Expert 10 |     80 | CPU
DEBUG 01-05 09:19:51.431386.431386 lmp.py:372]   Expert 11 |     82 | CPU
DEBUG 01-05 09:19:51.431505.431505 lmp.py:372]   Expert 63 |     84 | CPU
DEBUG 01-05 09:19:51.431195.431195 lmp.py:372]   Expert 44 |     85 | CPU
DEBUG 01-05 09:19:51.431884.431884 lmp.py:372]   Expert 49 |     91 | CPU
DEBUG 01-05 09:19:51.431812.431812 lmp.py:372]   Expert 50 |     97 | CPU
DEBUG 01-05 09:19:51.431739.431739 lmp.py:372]   Expert 26 |    104 | CPU
DEBUG 01-05 09:19:51.431952.431952 lmp.py:372]   Expert 37 |    105 | CPU
DEBUG 01-05 09:19:51.431549.431549 lmp.py:372]   Expert  7 |    106 | CPU
DEBUG 01-05 09:19:51.431761.431761 lmp.py:372]   Expert 40 |    111 | CPU
DEBUG 01-05 09:19:51.431212.431212 lmp.py:372]   Expert 16 |    116 | CPU
DEBUG 01-05 09:19:51.431186.431186 lmp.py:372]   Expert 47 |    118 | CPU
DEBUG 01-05 09:19:51.431160.431160 lmp.py:372]   Expert 34 |    121 | CPU
DEBUG 01-05 09:19:51.431373.431373 lmp.py:372]   Expert 22 |    122 | CPU
DEBUG 01-05 09:19:51.431300.431300 lmp.py:372]   Expert 32 |    129 | CPU
DEBUG 01-05 09:19:51.431228.431228 lmp.py:372]   Expert 62 |    129 | CPU
DEBUG 01-05 09:19:51.431586.431586 lmp.py:372]   Expert 28 |    136 | CPU
DEBUG 01-05 09:19:51.431322.431322 lmp.py:372]   Expert 31 |    144 | CPU
DEBUG 01-05 09:19:51.431534.431534 lmp.py:372]   Expert 30 |    147 | CPU
DEBUG 01-05 09:19:51.431508.431508 lmp.py:372]   Expert  4 |    150 | CPU
DEBUG 01-05 09:19:51.431006.431006 lmp.py:372]   Expert 41 |    150 | CPU
DEBUG 01-05 09:19:51.431980.431980 lmp.py:372]   Expert 57 |    157 | CPU
DEBUG 01-05 09:19:51.431623.431623 lmp.py:372]   Expert 58 |    157 | CPU
DEBUG 01-05 09:19:51.431550.431550 lmp.py:372]   Expert 51 |    161 | CPU
DEBUG 01-05 09:19:51.431001.431001 lmp.py:372]   Expert 25 |    169 | CPU
DEBUG 01-05 09:19:51.431214.431214 lmp.py:372]   Expert 54 |    171 | GPU
DEBUG 01-05 09:19:51.431188.431188 lmp.py:372]   Expert  9 |    189 | GPU
DEBUG 01-05 09:19:51.431162.431162 lmp.py:372]   Expert 55 |    189 | GPU
DEBUG 01-05 09:19:51.431758.431758 lmp.py:372]   Expert 21 |    190 | GPU
DEBUG 01-05 09:19:51.431494.431494 lmp.py:372]   Expert 45 |    193 | GPU
DEBUG 01-05 09:19:51.431468.431468 lmp.py:372]   Expert 59 |    194 | GPU
DEBUG 01-05 09:19:51.431204.431204 lmp.py:372]   Expert 38 |    195 | GPU
DEBUG 01-05 09:19:51.431893.431893 lmp.py:372]   Expert 33 |    197 | GPU
DEBUG 01-05 09:19:51.431821.431821 lmp.py:372]   Expert 29 |    201 | GPU
DEBUG 01-05 09:19:51.431702.431702 lmp.py:372]   Expert 13 |    202 | GPU
DEBUG 01-05 09:19:51.431915.431915 lmp.py:372]   Expert  8 |    203 | GPU
DEBUG 01-05 09:19:51.432889.432889 lmp.py:372]   Expert  0 |    205 | GPU
DEBUG 01-05 09:19:51.432863.432863 lmp.py:372]   Expert 12 |    209 | GPU
DEBUG 01-05 09:19:51.432075.432075 lmp.py:372]   Expert  6 |    216 | GPU
DEBUG 01-05 09:19:51.432049.432049 lmp.py:372]   Expert 46 |    216 | GPU
DEBUG 01-05 09:19:51.432407.432407 lmp.py:372]   Expert 43 |    218 | GPU
DEBUG 01-05 09:19:51.432097.432097 lmp.py:372]   Expert  5 |    219 | GPU
DEBUG 01-05 09:19:51.432263.432263 lmp.py:372]   Expert  2 |    228 | GPU
DEBUG 01-05 09:19:51.432714.432714 lmp.py:372]   Expert 19 |    228 | GPU
DEBUG 01-05 09:19:51.432688.432688 lmp.py:372]   Expert 42 |    237 | GPU
DEBUG 01-05 09:19:51.432423.432423 lmp.py:372]   Expert 24 |    243 | GPU
DEBUG 01-05 09:19:51.432782.432782 lmp.py:372]   Expert 17 |    266 | GPU
DEBUG 01-05 09:19:51.432994.432994 lmp.py:372]   Expert 23 |    267 | GPU
DEBUG 01-05 09:19:51.432968.432968 lmp.py:372]   Expert 61 |    292 | GPU
DEBUG 01-05 09:19:51.432942.432942 lmp.py:372]   Expert 20 |    345 | GPU
DEBUG 01-05 09:19:51.432347.432347 lmp.py:372]   Expert 27 |    357 | GPU
DEBUG 01-05 09:19:51.432036.432036 lmp.py:372]   Expert 18 |    381 | GPU
DEBUG 01-05 09:19:51.432633.432633 lmp.py:372]   Expert 48 |    420 | GPU
DEBUG 01-05 09:19:51.432368.432368 lmp.py:372]   Expert 39 |    426 | GPU
DEBUG 01-05 09:19:51.432581.432581 lmp.py:372]   Expert 60 |    459 | GPU
DEBUG 01-05 09:19:51.432316.432316 lmp.py:372]   Expert 56 |    614 | GPU
DEBUG 01-05 09:19:51.432290.432290 lmp.py:372]   Expert 36 |    734 | GPU
DEBUG 01-05 09:19:51.432980.432980 lmp.py:373] 
DEBUG 01-05 09:19:51.432980.432980 lmp.py:373]   CPU total tokens: 3384 (27.5%)
DEBUG 01-05 09:19:51.432292.432292 lmp.py:374]   GPU total tokens: 8904 (72.5%)
DEBUG 01-05 09:19:51.432379.432379 cuda_h.py:19] end experts_map_get cost 0.0015301704406738281 seconds
DEBUG 01-05 09:19:51.432022.432022 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.432659.432659 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.432988.432988 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.432313.432313 cuda_h.py:19] end allocate_cuda_memory cost 0.00017213821411132812 seconds
DEBUG 01-05 09:19:51.432063.432063 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.432011.432011 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.432681.432681 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.432616.432616 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 277d93a8-5b27-4010-bcdf-4ebc8e009462
DEBUG 01-05 09:19:51.433941.433941 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.434504.434504 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 277d93a8-5b27-4010-bcdf-4ebc8e009462
DEBUG 01-05 09:19:51.434433.434433 cuda_h.py:19] end load_into_gpu_async cost 0.0013284683227539062 seconds
DEBUG 01-05 09:19:51.434421.434421 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.434343.434343 cuda_h.py:19] end restore_tensors2 cost 0.00040650367736816406 seconds
DEBUG 01-05 09:19:51.434186.434186 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022611618041992188 seconds
DEBUG 01-05 09:19:51.437778.437778 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004954099655151367 seconds
DEBUG 01-05 09:19:51.437237.437237 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.437484.437484 lmp.py:419] 
DEBUG 01-05 09:19:51.437484.437484 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.437665.437665 cuda_h.py:19] end cpu_experts_submit cost 0.00011181831359863281 seconds
DEBUG 01-05 09:19:51.437560.437560 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.454953.454953 mlpmodule.py:704] group tensors cost 0.016382694244384766 s
DEBUG 01-05 09:19:51.456932.456932 mlpmodule.py:742] pad cost 0.0017287731170654297 s
DEBUG 01-05 09:19:51.456400.456400 mlpmodule.py:748] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-05 09:19:51.457978.457978 mlpmodule.py:753] move to cpu cost 3.814697265625e-05 s
DEBUG 01-05 09:19:51.469916.469916 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.470982.470982 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.470886.470886 mlpmodule.py:773] group_w3 first element: 0.036865234375
WARNING 01-05 09:19:51.470076.470076 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.489233.489233 mlpmodule.py:793] group einsum cost 0.03264880180358887 s
DEBUG 01-05 09:19:51.490880.490880 mlpmodule.py:801] cpy2cputensor cost 0.0008544921875 s
DEBUG 01-05 09:19:51.529030.529030 cuda_h.py:19] end wait_cetm_experts cost 0.09226202964782715 seconds
DEBUG 01-05 09:19:51.530936.530936 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.530984.530984 cuda_h.py:19] end gpu_sexperts cost 0.0005877017974853516 seconds
DEBUG 01-05 09:19:51.530834.530834 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:19:51.530795.530795 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-05 09:19:51.530851.530851 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.790855407714844e-05 seconds
DEBUG 01-05 09:19:51.530991.530991 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.867813110351562e-05 seconds
DEBUG 01-05 09:19:51.531263.531263 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.531212.531212 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 277d93a8-5b27-4010-bcdf-4ebc8e009462
DEBUG 01-05 09:19:51.531449.531449 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.531962.531962 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.531428.531428 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.536430.536430 cuda_h.py:19] end allocate_cuda_memory cost 0.0051538944244384766 seconds
DEBUG 01-05 09:19:51.536182.536182 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.536236.536236 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.536973.536973 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.536729.536729 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9be4d869-ff8a-4090-95c7-2d92b974a1df
DEBUG 01-05 09:19:51.536527.536527 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.537440.537440 client.py:127] Model loaded
DEBUG 01-05 09:19:51.537535.537535 cuda_h.py:19] end wait_experts cost 0.006102085113525391 seconds
DEBUG 01-05 09:19:51.537099.537099 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.537332.537332 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.537093.537093 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9be4d869-ff8a-4090-95c7-2d92b974a1df
DEBUG 01-05 09:19:51.537089.537089 cuda_h.py:19] end load_into_gpu_async cost 0.0011551380157470703 seconds
DEBUG 01-05 09:19:51.537130.537130 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.538300.538300 cuda_h.py:19] end restore_tensors2 cost 9.489059448242188e-05 seconds
DEBUG 01-05 09:19:51.538155.538155 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006709098815917969 seconds
DEBUG 01-05 09:19:51.538094.538094 mlpmodule.py:531] gpu group tensors cost 0.0011055469512939453 s
INFO 01-05 09:19:51.538956.538956 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9be4d869-ff8a-4090-95c7-2d92b974a1df
DEBUG 01-05 09:19:51.540113.540113 mlpmodule.py:564] gpu pad cost 0.002037525177001953 s
DEBUG 01-05 09:19:51.541141.541141 mlpmodule.py:582] gpu group einsum cost 0.0005671977996826172 s
DEBUG 01-05 09:19:51.544791.544791 mlpmodule.py:611] gpu experts func einsum cost 0.007486104965209961 s
DEBUG 01-05 09:19:51.544837.544837 cuda_h.py:19] end gpu_experts cost 0.007782936096191406 seconds
DEBUG 01-05 09:19:51.545262.545262 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:51.547755.547755 client.py:127] Model loaded
DEBUG 01-05 09:19:51.547698.547698 cuda_h.py:19] end sllm_worker_task cost 0.016628026962280273 seconds
DEBUG 01-05 09:19:51.548018.548018 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0029478073120117188 seconds
DEBUG 01-05 09:19:51.548705.548705 cuda_h.py:19] end layer_moe_generate_6 cost 0.11799836158752441 seconds
DEBUG 01-05 09:19:51.548122.548122 lmp.py:214] -------------------------------- end layer 6 --------------------------------
DEBUG 01-05 09:19:51.548959.548959 lmp.py:173] -------------------------------- start layer 7 --------------------------------
DEBUG 01-05 09:19:51.548655.548655 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.548002.548002 cuda_h.py:10] start self_attn
DEBUG 01-05 09:19:51.548673.548673 mlpmodule.py:662]  experts func einsum cost 0.11109662055969238 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.551680.551680 cuda_h.py:19] end self_attn cost 0.002575397491455078 seconds
DEBUG 01-05 09:19:51.551593.551593 cuda_h.py:19] end iln_self_attn_paln cost 0.0032591819763183594 seconds
DEBUG 01-05 09:19:51.551866.551866 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-05 09:19:51.551298.551298 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.552385.552385 cuda_h.py:19] end gate cost 0.0005891323089599609 seconds
DEBUG 01-05 09:19:51.552692.552692 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.552629.552629 lmp.py:361] 
DEBUG 01-05 09:19:51.552629.552629 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.552815.552815 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.552704.552704 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.552446.552446 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.552043.552043 lmp.py:365] 
DEBUG 01-05 09:19:51.552043.552043 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.552686.552686 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.552289.552289 lmp.py:372]   Expert  3 |     23 | CPU
DEBUG 01-05 09:19:51.552694.552694 lmp.py:372]   Expert  1 |     26 | CPU
DEBUG 01-05 09:19:51.552098.552098 lmp.py:372]   Expert 25 |     47 | CPU
DEBUG 01-05 09:19:51.553456.553456 lmp.py:372]   Expert 49 |     53 | CPU
DEBUG 01-05 09:19:51.553861.553861 lmp.py:372]   Expert 40 |     54 | CPU
DEBUG 01-05 09:19:51.553550.553550 lmp.py:372]   Expert 20 |     57 | CPU
DEBUG 01-05 09:19:51.553763.553763 lmp.py:372]   Expert 41 |     59 | CPU
DEBUG 01-05 09:19:51.553214.553214 lmp.py:372]   Expert 15 |     62 | CPU
DEBUG 01-05 09:19:51.553095.553095 lmp.py:372]   Expert 31 |     74 | CPU
DEBUG 01-05 09:19:51.553784.553784 lmp.py:372]   Expert  8 |     75 | CPU
DEBUG 01-05 09:19:51.553758.553758 lmp.py:372]   Expert 29 |     75 | CPU
DEBUG 01-05 09:19:51.553971.553971 lmp.py:372]   Expert 39 |     80 | CPU
DEBUG 01-05 09:19:51.553660.553660 lmp.py:372]   Expert 48 |     83 | CPU
DEBUG 01-05 09:19:51.553588.553588 lmp.py:372]   Expert 16 |     84 | CPU
DEBUG 01-05 09:19:51.553708.553708 lmp.py:372]   Expert 63 |     86 | CPU
DEBUG 01-05 09:19:51.553159.553159 lmp.py:372]   Expert  6 |     89 | CPU
DEBUG 01-05 09:19:51.553133.553133 lmp.py:372]   Expert  5 |     90 | CPU
DEBUG 01-05 09:19:51.553583.553583 lmp.py:372]   Expert 18 |     99 | CPU
DEBUG 01-05 09:19:51.553319.553319 lmp.py:372]   Expert 57 |    100 | CPU
DEBUG 01-05 09:19:51.553532.553532 lmp.py:372]   Expert 32 |    102 | CPU
DEBUG 01-05 09:19:51.553459.553459 lmp.py:372]   Expert 58 |    103 | CPU
DEBUG 01-05 09:19:51.553149.553149 lmp.py:372]   Expert 59 |    125 | CPU
DEBUG 01-05 09:19:51.553507.553507 lmp.py:372]   Expert 30 |    142 | CPU
DEBUG 01-05 09:19:51.553958.553958 lmp.py:372]   Expert 55 |    145 | CPU
DEBUG 01-05 09:19:51.553170.553170 lmp.py:372]   Expert  4 |    149 | CPU
DEBUG 01-05 09:19:51.553383.553383 lmp.py:372]   Expert 45 |    150 | CPU
DEBUG 01-05 09:19:51.553357.553357 lmp.py:372]   Expert 34 |    152 | CPU
DEBUG 01-05 09:19:51.553092.553092 lmp.py:372]   Expert 53 |    152 | CPU
DEBUG 01-05 09:19:51.553927.553927 lmp.py:372]   Expert 33 |    163 | CPU
DEBUG 01-05 09:19:51.553140.553140 lmp.py:372]   Expert 26 |    168 | CPU
DEBUG 01-05 09:19:51.553829.553829 lmp.py:372]   Expert  0 |    169 | CPU
DEBUG 01-05 09:19:51.553803.553803 lmp.py:372]   Expert 28 |    177 | CPU
DEBUG 01-05 09:19:51.553016.553016 lmp.py:372]   Expert 35 |    181 | GPU
DEBUG 01-05 09:19:51.553990.553990 lmp.py:372]   Expert 52 |    181 | GPU
DEBUG 01-05 09:19:51.553348.553348 lmp.py:372]   Expert  7 |    184 | GPU
DEBUG 01-05 09:19:51.553322.553322 lmp.py:372]   Expert 50 |    190 | GPU
DEBUG 01-05 09:19:51.553058.553058 lmp.py:372]   Expert 21 |    194 | GPU
DEBUG 01-05 09:19:51.553270.553270 lmp.py:372]   Expert 42 |    197 | GPU
DEBUG 01-05 09:19:51.553721.553721 lmp.py:372]   Expert 54 |    197 | GPU
DEBUG 01-05 09:19:51.553457.553457 lmp.py:372]   Expert 19 |    203 | GPU
DEBUG 01-05 09:19:51.553338.553338 lmp.py:372]   Expert 60 |    208 | GPU
DEBUG 01-05 09:19:51.553074.553074 lmp.py:372]   Expert 36 |    209 | GPU
DEBUG 01-05 09:19:51.553048.553048 lmp.py:372]   Expert 17 |    212 | GPU
DEBUG 01-05 09:19:51.553022.553022 lmp.py:372]   Expert 24 |    214 | GPU
DEBUG 01-05 09:19:51.553996.553996 lmp.py:372]   Expert 43 |    216 | GPU
DEBUG 01-05 09:19:51.553731.553731 lmp.py:372]   Expert 51 |    218 | GPU
DEBUG 01-05 09:19:51.553944.553944 lmp.py:372]   Expert 13 |    224 | GPU
DEBUG 01-05 09:19:51.553918.553918 lmp.py:372]   Expert 27 |    235 | GPU
DEBUG 01-05 09:19:51.553846.553846 lmp.py:372]   Expert 37 |    236 | GPU
DEBUG 01-05 09:19:51.553296.553296 lmp.py:372]   Expert 10 |    241 | GPU
DEBUG 01-05 09:19:51.553178.553178 lmp.py:372]   Expert 62 |    258 | GPU
DEBUG 01-05 09:19:51.553390.553390 lmp.py:372]   Expert 22 |    266 | GPU
DEBUG 01-05 09:19:51.553603.553603 lmp.py:372]   Expert 47 |    268 | GPU
DEBUG 01-05 09:19:51.553338.553338 lmp.py:372]   Expert 11 |    272 | GPU
DEBUG 01-05 09:19:51.553312.553312 lmp.py:372]   Expert  2 |    298 | GPU
DEBUG 01-05 09:19:51.553240.553240 lmp.py:372]   Expert 56 |    300 | GPU
DEBUG 01-05 09:19:51.553883.553883 lmp.py:372]   Expert 61 |    321 | GPU
DEBUG 01-05 09:19:51.553334.553334 lmp.py:372]   Expert 44 |    339 | GPU
DEBUG 01-05 09:19:51.553308.553308 lmp.py:372]   Expert 14 |    342 | GPU
DEBUG 01-05 09:19:51.553521.553521 lmp.py:372]   Expert 38 |    348 | GPU
DEBUG 01-05 09:19:51.553256.553256 lmp.py:372]   Expert 46 |    382 | GPU
DEBUG 01-05 09:19:51.553230.553230 lmp.py:372]   Expert 12 |    576 | GPU
DEBUG 01-05 09:19:51.553396.553396 lmp.py:372]   Expert  9 |    667 | GPU
DEBUG 01-05 09:19:51.553847.553847 lmp.py:372]   Expert 23 |    698 | GPU
DEBUG 01-05 09:19:51.554775.554775 lmp.py:373] 
DEBUG 01-05 09:19:51.554775.554775 lmp.py:373]   CPU total tokens: 3213 (26.1%)
DEBUG 01-05 09:19:51.554895.554895 lmp.py:374]   GPU total tokens: 9075 (73.9%)
DEBUG 01-05 09:19:51.554544.554544 cuda_h.py:19] end experts_map_get cost 0.0015132427215576172 seconds
DEBUG 01-05 09:19:51.554187.554187 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.554255.554255 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.554631.554631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.554421.554421 cuda_h.py:19] end allocate_cuda_memory cost 0.000232696533203125 seconds
DEBUG 01-05 09:19:51.554172.554172 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.554689.554689 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.554406.554406 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.554294.554294 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ac65467b-5abb-47af-8a5a-84d9251e2eb0
DEBUG 01-05 09:19:51.554704.554704 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.556929.556929 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ac65467b-5abb-47af-8a5a-84d9251e2eb0
DEBUG 01-05 09:19:51.556713.556713 cuda_h.py:19] end load_into_gpu_async cost 0.0014905929565429688 seconds
DEBUG 01-05 09:19:51.556270.556270 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.556569.556569 cuda_h.py:19] end restore_tensors2 cost 0.0004031658172607422 seconds
DEBUG 01-05 09:19:51.556511.556511 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024831295013427734 seconds
DEBUG 01-05 09:19:51.559395.559395 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0051801204681396484 seconds
DEBUG 01-05 09:19:51.559708.559708 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.559022.559022 lmp.py:419] 
DEBUG 01-05 09:19:51.559022.559022 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.559826.559826 cuda_h.py:19] end cpu_experts_submit cost 0.00011396408081054688 seconds
DEBUG 01-05 09:19:51.559145.559145 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.564370.564370 mlpmodule.py:704] group tensors cost 0.004921436309814453 s
DEBUG 01-05 09:19:51.567773.567773 mlpmodule.py:742] pad cost 0.001667022705078125 s
DEBUG 01-05 09:19:51.567227.567227 mlpmodule.py:748] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-05 09:19:51.567422.567422 mlpmodule.py:753] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-05 09:19:51.580279.580279 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.580757.580757 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.580531.580531 mlpmodule.py:773] group_w3 first element: -0.053466796875
WARNING 01-05 09:19:51.580927.580927 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.600658.600658 mlpmodule.py:793] group einsum cost 0.033266305923461914 s
DEBUG 01-05 09:19:51.602413.602413 mlpmodule.py:801] cpy2cputensor cost 0.002124309539794922 s
DEBUG 01-05 09:19:51.644103.644103 cuda_h.py:19] end wait_cetm_experts cost 0.08452415466308594 seconds
DEBUG 01-05 09:19:51.644572.644572 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.644887.644887 cuda_h.py:19] end gpu_sexperts cost 0.00046706199645996094 seconds
DEBUG 01-05 09:19:51.644313.644313 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:19:51.644706.644706 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-05 09:19:51.644092.644092 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.5762786865234375e-05 seconds
DEBUG 01-05 09:19:51.645093.645093 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 8.034706115722656e-05 seconds
DEBUG 01-05 09:19:51.645843.645843 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.645791.645791 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ac65467b-5abb-47af-8a5a-84d9251e2eb0
DEBUG 01-05 09:19:51.645730.645730 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.645025.645025 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.645822.645822 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.649104.649104 cuda_h.py:19] end allocate_cuda_memory cost 0.0038170814514160156 seconds
INFO 01-05 09:19:51.649452.649452 client.py:127] Model loaded
DEBUG 01-05 09:19:51.649786.649786 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.649597.649597 cuda_h.py:19] end wait_experts cost 0.004488229751586914 seconds
DEBUG 01-05 09:19:51.649558.649558 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.649633.649633 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.649781.649781 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.649408.649408 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f905dc6-dc38-4f26-b179-174b47dff812
DEBUG 01-05 09:19:51.649596.649596 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:51.649048.649048 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:51.650087.650087 mlpmodule.py:531] gpu group tensors cost 0.0006456375122070312 s
INFO 01-05 09:19:51.651487.651487 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f905dc6-dc38-4f26-b179-174b47dff812
DEBUG 01-05 09:19:51.651052.651052 cuda_h.py:19] end load_into_gpu_async cost 0.0017020702362060547 seconds
DEBUG 01-05 09:19:51.651047.651047 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.651640.651640 cuda_h.py:19] end restore_tensors2 cost 8.487701416015625e-05 seconds
DEBUG 01-05 09:19:51.651403.651403 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0061075687408447266 seconds
INFO 01-05 09:19:51.652377.652377 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f905dc6-dc38-4f26-b179-174b47dff812
DEBUG 01-05 09:19:51.653240.653240 mlpmodule.py:564] gpu pad cost 0.002706766128540039 s
DEBUG 01-05 09:19:51.654091.654091 mlpmodule.py:582] gpu group einsum cost 0.0005972385406494141 s
DEBUG 01-05 09:19:51.657353.657353 mlpmodule.py:611] gpu experts func einsum cost 0.007794380187988281 s
DEBUG 01-05 09:19:51.658771.658771 cuda_h.py:19] end gpu_experts cost 0.008332967758178711 seconds
DEBUG 01-05 09:19:51.658202.658202 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.658716.658716 mlpmodule.py:662]  experts func einsum cost 0.09896278381347656 s
INFO 01-05 09:19:51.660056.660056 client.py:127] Model loaded
DEBUG 01-05 09:19:51.660760.660760 cuda_h.py:19] end sllm_worker_task cost 0.01560831069946289 seconds
DEBUG 01-05 09:19:51.661841.661841 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0028264522552490234 seconds
DEBUG 01-05 09:19:51.661052.661052 cuda_h.py:19] end layer_moe_generate_7 cost 0.10933876037597656 seconds
DEBUG 01-05 09:19:51.661376.661376 lmp.py:214] -------------------------------- end layer 7 --------------------------------
DEBUG 01-05 09:19:51.661530.661530 lmp.py:173] -------------------------------- start layer 8 --------------------------------
DEBUG 01-05 09:19:51.661511.661511 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.661706.661706 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.664758.664758 cuda_h.py:19] end self_attn cost 0.002475261688232422 seconds
DEBUG 01-05 09:19:51.664159.664159 cuda_h.py:19] end iln_self_attn_paln cost 0.003116607666015625 seconds
DEBUG 01-05 09:19:51.664956.664956 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-05 09:19:51.664818.664818 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.665130.665130 cuda_h.py:19] end gate cost 0.0005822181701660156 seconds
DEBUG 01-05 09:19:51.665198.665198 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.665089.665089 lmp.py:361] 
DEBUG 01-05 09:19:51.665089.665089 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.665514.665514 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.665118.665118 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.665052.665052 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.665649.665649 lmp.py:365] 
DEBUG 01-05 09:19:51.665649.665649 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.665292.665292 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.665418.665418 lmp.py:372]   Expert 27 |     23 | CPU
DEBUG 01-05 09:19:51.665061.665061 lmp.py:372]   Expert  7 |     26 | CPU
DEBUG 01-05 09:19:51.665658.665658 lmp.py:372]   Expert 14 |     29 | CPU
DEBUG 01-05 09:19:51.665778.665778 lmp.py:372]   Expert 30 |     34 | CPU
DEBUG 01-05 09:19:51.665182.665182 lmp.py:372]   Expert 38 |     41 | CPU
DEBUG 01-05 09:19:51.665872.665872 lmp.py:372]   Expert 12 |     45 | CPU
DEBUG 01-05 09:19:51.665561.665561 lmp.py:372]   Expert 22 |     62 | CPU
DEBUG 01-05 09:19:51.665535.665535 lmp.py:372]   Expert 36 |     63 | CPU
DEBUG 01-05 09:19:51.665370.665370 lmp.py:372]   Expert 53 |     63 | CPU
DEBUG 01-05 09:19:51.665344.665344 lmp.py:372]   Expert  8 |     68 | CPU
DEBUG 01-05 09:19:51.665795.665795 lmp.py:372]   Expert 26 |     68 | CPU
DEBUG 01-05 09:19:51.665007.665007 lmp.py:372]   Expert 34 |     73 | CPU
DEBUG 01-05 09:19:51.665412.665412 lmp.py:372]   Expert 33 |     87 | CPU
DEBUG 01-05 09:19:51.666625.666625 lmp.py:372]   Expert 54 |     91 | CPU
DEBUG 01-05 09:19:51.666460.666460 lmp.py:372]   Expert  1 |     97 | CPU
DEBUG 01-05 09:19:51.666149.666149 lmp.py:372]   Expert 40 |     97 | CPU
DEBUG 01-05 09:19:51.666600.666600 lmp.py:372]   Expert 57 |    102 | CPU
DEBUG 01-05 09:19:51.666812.666812 lmp.py:372]   Expert 32 |    105 | CPU
DEBUG 01-05 09:19:51.666502.666502 lmp.py:372]   Expert  9 |    109 | CPU
DEBUG 01-05 09:19:51.666237.666237 lmp.py:372]   Expert 50 |    110 | CPU
DEBUG 01-05 09:19:51.666165.666165 lmp.py:372]   Expert 29 |    112 | CPU
DEBUG 01-05 09:19:51.666285.666285 lmp.py:372]   Expert 13 |    121 | CPU
DEBUG 01-05 09:19:51.666689.666689 lmp.py:372]   Expert 17 |    133 | CPU
DEBUG 01-05 09:19:51.666902.666902 lmp.py:372]   Expert 44 |    138 | CPU
DEBUG 01-05 09:19:51.666876.666876 lmp.py:372]   Expert 24 |    139 | CPU
DEBUG 01-05 09:19:51.666327.666327 lmp.py:372]   Expert 60 |    144 | CPU
DEBUG 01-05 09:19:51.666301.666301 lmp.py:372]   Expert 59 |    158 | CPU
DEBUG 01-05 09:19:51.666705.666705 lmp.py:372]   Expert 51 |    161 | CPU
DEBUG 01-05 09:19:51.666395.666395 lmp.py:372]   Expert 15 |    166 | CPU
DEBUG 01-05 09:19:51.666369.666369 lmp.py:372]   Expert 16 |    167 | CPU
DEBUG 01-05 09:19:51.666819.666819 lmp.py:372]   Expert  2 |    169 | CPU
DEBUG 01-05 09:19:51.666270.666270 lmp.py:372]   Expert 56 |    169 | CPU
DEBUG 01-05 09:19:51.666721.666721 lmp.py:372]   Expert 37 |    175 | GPU
DEBUG 01-05 09:19:51.666126.666126 lmp.py:372]   Expert 10 |    179 | GPU
DEBUG 01-05 09:19:51.666815.666815 lmp.py:372]   Expert 31 |    184 | GPU
DEBUG 01-05 09:19:51.666551.666551 lmp.py:372]   Expert 18 |    191 | GPU
DEBUG 01-05 09:19:51.666525.666525 lmp.py:372]   Expert 19 |    198 | GPU
DEBUG 01-05 09:19:51.666260.666260 lmp.py:372]   Expert 39 |    198 | GPU
DEBUG 01-05 09:19:51.666234.666234 lmp.py:372]   Expert 58 |    230 | GPU
DEBUG 01-05 09:19:51.666685.666685 lmp.py:372]   Expert 35 |    240 | GPU
DEBUG 01-05 09:19:51.666567.666567 lmp.py:372]   Expert 42 |    240 | GPU
DEBUG 01-05 09:19:51.666779.666779 lmp.py:372]   Expert 61 |    240 | GPU
DEBUG 01-05 09:19:51.666753.666753 lmp.py:372]   Expert  0 |    244 | GPU
DEBUG 01-05 09:19:51.666489.666489 lmp.py:372]   Expert 23 |    244 | GPU
DEBUG 01-05 09:19:51.666224.666224 lmp.py:372]   Expert 46 |    246 | GPU
DEBUG 01-05 09:19:51.666198.666198 lmp.py:372]   Expert  3 |    248 | GPU
DEBUG 01-05 09:19:51.666080.666080 lmp.py:372]   Expert 49 |    252 | GPU
DEBUG 01-05 09:19:51.666008.666008 lmp.py:372]   Expert 41 |    254 | GPU
DEBUG 01-05 09:19:51.666697.666697 lmp.py:372]   Expert 55 |    269 | GPU
DEBUG 01-05 09:19:51.666433.666433 lmp.py:372]   Expert  6 |    279 | GPU
DEBUG 01-05 09:19:51.666645.666645 lmp.py:372]   Expert  4 |    280 | GPU
DEBUG 01-05 09:19:51.666142.666142 lmp.py:372]   Expert 28 |    284 | GPU
DEBUG 01-05 09:19:51.666785.666785 lmp.py:372]   Expert 43 |    303 | GPU
DEBUG 01-05 09:19:51.666759.666759 lmp.py:372]   Expert 45 |    312 | GPU
DEBUG 01-05 09:19:51.666495.666495 lmp.py:372]   Expert 20 |    315 | GPU
DEBUG 01-05 09:19:51.666423.666423 lmp.py:372]   Expert 47 |    332 | GPU
DEBUG 01-05 09:19:51.666112.666112 lmp.py:372]   Expert 52 |    332 | GPU
DEBUG 01-05 09:19:51.666324.666324 lmp.py:372]   Expert 48 |    345 | GPU
DEBUG 01-05 09:19:51.666206.666206 lmp.py:372]   Expert 25 |    346 | GPU
DEBUG 01-05 09:19:51.666418.666418 lmp.py:372]   Expert 11 |    376 | GPU
DEBUG 01-05 09:19:51.666915.666915 lmp.py:372]   Expert 62 |    397 | GPU
DEBUG 01-05 09:19:51.666889.666889 lmp.py:372]   Expert 21 |    417 | GPU
DEBUG 01-05 09:19:51.666625.666625 lmp.py:372]   Expert 63 |    426 | GPU
DEBUG 01-05 09:19:51.666122.666122 lmp.py:372]   Expert  5 |    542 | GPU
DEBUG 01-05 09:19:51.666050.666050 lmp.py:373] 
DEBUG 01-05 09:19:51.666050.666050 lmp.py:373]   CPU total tokens: 3170 (25.8%)
DEBUG 01-05 09:19:51.666693.666693 lmp.py:374]   GPU total tokens: 9118 (74.2%)
DEBUG 01-05 09:19:51.666820.666820 cuda_h.py:19] end experts_map_get cost 0.0015187263488769531 seconds
DEBUG 01-05 09:19:51.666701.666701 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.666100.666100 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.667105.667105 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.667074.667074 cuda_h.py:19] end allocate_cuda_memory cost 0.00022482872009277344 seconds
DEBUG 01-05 09:19:51.667824.667824 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.667818.667818 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.667204.667204 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.667807.667807 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 72307890-25ca-4194-b5a3-1ed6de3fe81f
DEBUG 01-05 09:19:51.667165.667165 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.668278.668278 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 72307890-25ca-4194-b5a3-1ed6de3fe81f
DEBUG 01-05 09:19:51.668253.668253 cuda_h.py:19] end load_into_gpu_async cost 0.0015130043029785156 seconds
DEBUG 01-05 09:19:51.668810.668810 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.669911.669911 cuda_h.py:19] end restore_tensors2 cost 0.000396728515625 seconds
DEBUG 01-05 09:19:51.669800.669800 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00249481201171875 seconds
DEBUG 01-05 09:19:51.672531.672531 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005185365676879883 seconds
DEBUG 01-05 09:19:51.672937.672937 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.672516.672516 lmp.py:419] 
DEBUG 01-05 09:19:51.672516.672516 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.672928.672928 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-05 09:19:51.672247.672247 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.682982.682982 mlpmodule.py:704] group tensors cost 0.009459972381591797 s
DEBUG 01-05 09:19:51.684142.684142 mlpmodule.py:742] pad cost 0.0015552043914794922 s
DEBUG 01-05 09:19:51.684622.684622 mlpmodule.py:748] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-05 09:19:51.684539.684539 mlpmodule.py:753] move to cpu cost 4.2438507080078125e-05 s
DEBUG 01-05 09:19:51.697701.697701 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.697123.697123 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.697046.697046 mlpmodule.py:773] group_w3 first element: -0.03369140625
WARNING 01-05 09:19:51.697334.697334 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.717505.717505 mlpmodule.py:793] group einsum cost 0.032945871353149414 s
DEBUG 01-05 09:19:51.718727.718727 mlpmodule.py:801] cpy2cputensor cost 0.0007276535034179688 s
DEBUG 01-05 09:19:51.755434.755434 cuda_h.py:19] end wait_cetm_experts cost 0.08267974853515625 seconds
DEBUG 01-05 09:19:51.755503.755503 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.755976.755976 cuda_h.py:19] end gpu_sexperts cost 0.00044798851013183594 seconds
DEBUG 01-05 09:19:51.755866.755866 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:19:51.755443.755443 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-05 09:19:51.755313.755313 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.218650817871094e-05 seconds
DEBUG 01-05 09:19:51.755745.755745 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.700920104980469e-05 seconds
DEBUG 01-05 09:19:51.755210.755210 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.755442.755442 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 72307890-25ca-4194-b5a3-1ed6de3fe81f
DEBUG 01-05 09:19:51.756037.756037 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.756650.756650 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.756109.756109 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.760530.760530 cuda_h.py:19] end allocate_cuda_memory cost 0.0038526058197021484 seconds
DEBUG 01-05 09:19:51.760208.760208 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.760938.760938 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.760198.760198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.760762.760762 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 50fc77eb-c478-49d2-9731-d0c9b518e029
DEBUG 01-05 09:19:51.760481.760481 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.760818.760818 client.py:127] Model loaded
DEBUG 01-05 09:19:51.760291.760291 cuda_h.py:19] end wait_experts cost 0.004768848419189453 seconds
DEBUG 01-05 09:19:51.760332.760332 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.760372.760372 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.761203.761203 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 50fc77eb-c478-49d2-9731-d0c9b518e029
DEBUG 01-05 09:19:51.761768.761768 cuda_h.py:19] end load_into_gpu_async cost 0.0012428760528564453 seconds
DEBUG 01-05 09:19:51.761571.761571 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.761912.761912 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-05 09:19:51.761483.761483 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005461454391479492 seconds
DEBUG 01-05 09:19:51.761187.761187 mlpmodule.py:531] gpu group tensors cost 0.001116037368774414 s
INFO 01-05 09:19:51.762838.762838 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 50fc77eb-c478-49d2-9731-d0c9b518e029
DEBUG 01-05 09:19:51.764518.764518 mlpmodule.py:564] gpu pad cost 0.0020177364349365234 s
DEBUG 01-05 09:19:51.764515.764515 mlpmodule.py:582] gpu group einsum cost 0.000598907470703125 s
DEBUG 01-05 09:19:51.768506.768506 mlpmodule.py:611] gpu experts func einsum cost 0.007672309875488281 s
DEBUG 01-05 09:19:51.768639.768639 cuda_h.py:19] end gpu_experts cost 0.007956981658935547 seconds
DEBUG 01-05 09:19:51.768362.768362 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.769476.769476 mlpmodule.py:662]  experts func einsum cost 0.0969858169555664 s
INFO 01-05 09:19:51.770955.770955 client.py:127] Model loaded
DEBUG 01-05 09:19:51.770090.770090 cuda_h.py:19] end sllm_worker_task cost 0.014724254608154297 seconds
DEBUG 01-05 09:19:51.770608.770608 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002183198928833008 seconds
DEBUG 01-05 09:19:51.771719.771719 cuda_h.py:19] end layer_moe_generate_8 cost 0.10642719268798828 seconds
DEBUG 01-05 09:19:51.771667.771667 lmp.py:214] -------------------------------- end layer 8 --------------------------------
DEBUG 01-05 09:19:51.771337.771337 lmp.py:173] -------------------------------- start layer 9 --------------------------------
DEBUG 01-05 09:19:51.771079.771079 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.771744.771744 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.774425.774425 cuda_h.py:19] end self_attn cost 0.002482891082763672 seconds
DEBUG 01-05 09:19:51.774443.774443 cuda_h.py:19] end iln_self_attn_paln cost 0.003117084503173828 seconds
DEBUG 01-05 09:19:51.774763.774763 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-05 09:19:51.774671.774671 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.775738.775738 cuda_h.py:19] end gate cost 0.0005772113800048828 seconds
DEBUG 01-05 09:19:51.775568.775568 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.775883.775883 lmp.py:361] 
DEBUG 01-05 09:19:51.775883.775883 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.775069.775069 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.775911.775911 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.775938.775938 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.775727.775727 lmp.py:365] 
DEBUG 01-05 09:19:51.775727.775727 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.775893.775893 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.775781.775781 lmp.py:372]   Expert 35 |     34 | CPU
DEBUG 01-05 09:19:51.775186.775186 lmp.py:372]   Expert  7 |     40 | CPU
DEBUG 01-05 09:19:51.775113.775113 lmp.py:372]   Expert 26 |     45 | CPU
DEBUG 01-05 09:19:51.775664.775664 lmp.py:372]   Expert  5 |     49 | CPU
DEBUG 01-05 09:19:51.775115.775115 lmp.py:372]   Expert  2 |     50 | CPU
DEBUG 01-05 09:19:51.775758.775758 lmp.py:372]   Expert  6 |     50 | CPU
DEBUG 01-05 09:19:51.775924.775924 lmp.py:372]   Expert 38 |     58 | CPU
DEBUG 01-05 09:19:51.775375.775375 lmp.py:372]   Expert 60 |     60 | CPU
DEBUG 01-05 09:19:51.775018.775018 lmp.py:372]   Expert 19 |     62 | CPU
DEBUG 01-05 09:19:51.775184.775184 lmp.py:372]   Expert 13 |     63 | CPU
DEBUG 01-05 09:19:51.775635.775635 lmp.py:372]   Expert 48 |     74 | CPU
DEBUG 01-05 09:19:51.775085.775085 lmp.py:372]   Expert 17 |     77 | CPU
DEBUG 01-05 09:19:51.775728.775728 lmp.py:372]   Expert 25 |     78 | CPU
DEBUG 01-05 09:19:51.775418.775418 lmp.py:372]   Expert 39 |     84 | CPU
DEBUG 01-05 09:19:51.775299.775299 lmp.py:372]   Expert 27 |     89 | CPU
DEBUG 01-05 09:19:51.775988.775988 lmp.py:372]   Expert 52 |     92 | CPU
DEBUG 01-05 09:19:51.775724.775724 lmp.py:372]   Expert 54 |     98 | CPU
DEBUG 01-05 09:19:51.776937.776937 lmp.py:372]   Expert 45 |    109 | CPU
DEBUG 01-05 09:19:51.776103.776103 lmp.py:372]   Expert 16 |    120 | CPU
DEBUG 01-05 09:19:51.776030.776030 lmp.py:372]   Expert 59 |    135 | CPU
DEBUG 01-05 09:19:51.776627.776627 lmp.py:372]   Expert 49 |    136 | CPU
DEBUG 01-05 09:19:51.776078.776078 lmp.py:372]   Expert 24 |    139 | CPU
DEBUG 01-05 09:19:51.776052.776052 lmp.py:372]   Expert 57 |    146 | CPU
DEBUG 01-05 09:19:51.776503.776503 lmp.py:372]   Expert 32 |    147 | CPU
DEBUG 01-05 09:19:51.776954.776954 lmp.py:372]   Expert 20 |    150 | CPU
DEBUG 01-05 09:19:51.776166.776166 lmp.py:372]   Expert 29 |    150 | CPU
DEBUG 01-05 09:19:51.776140.776140 lmp.py:372]   Expert 40 |    154 | CPU
DEBUG 01-05 09:19:51.776830.776830 lmp.py:372]   Expert 62 |    154 | CPU
DEBUG 01-05 09:19:51.776280.776280 lmp.py:372]   Expert 12 |    162 | CPU
DEBUG 01-05 09:19:51.776923.776923 lmp.py:372]   Expert 22 |    162 | CPU
DEBUG 01-05 09:19:51.776897.776897 lmp.py:372]   Expert 42 |    167 | CPU
DEBUG 01-05 09:19:51.776871.776871 lmp.py:372]   Expert 14 |    170 | CPU
DEBUG 01-05 09:19:51.776084.776084 lmp.py:372]   Expert 31 |    172 | GPU
DEBUG 01-05 09:19:51.776058.776058 lmp.py:372]   Expert 28 |    177 | GPU
DEBUG 01-05 09:19:51.776270.776270 lmp.py:372]   Expert 41 |    177 | GPU
DEBUG 01-05 09:19:51.776390.776390 lmp.py:372]   Expert 30 |    180 | GPU
DEBUG 01-05 09:19:51.776080.776080 lmp.py:372]   Expert 18 |    182 | GPU
DEBUG 01-05 09:19:51.776246.776246 lmp.py:372]   Expert 58 |    182 | GPU
DEBUG 01-05 09:19:51.776697.776697 lmp.py:372]   Expert 11 |    185 | GPU
DEBUG 01-05 09:19:51.776671.776671 lmp.py:372]   Expert 33 |    191 | GPU
DEBUG 01-05 09:19:51.776758.776758 lmp.py:372]   Expert 23 |    192 | GPU
DEBUG 01-05 09:19:51.776639.776639 lmp.py:372]   Expert  1 |    193 | GPU
DEBUG 01-05 09:19:51.776852.776852 lmp.py:372]   Expert 10 |    201 | GPU
DEBUG 01-05 09:19:51.776064.776064 lmp.py:372]   Expert 43 |    201 | GPU
DEBUG 01-05 09:19:51.776515.776515 lmp.py:372]   Expert  3 |    207 | GPU
DEBUG 01-05 09:19:51.776396.776396 lmp.py:372]   Expert 50 |    215 | GPU
DEBUG 01-05 09:19:51.776039.776039 lmp.py:372]   Expert 34 |    217 | GPU
DEBUG 01-05 09:19:51.776682.776682 lmp.py:372]   Expert 47 |    220 | GPU
DEBUG 01-05 09:19:51.776895.776895 lmp.py:372]   Expert 51 |    224 | GPU
DEBUG 01-05 09:19:51.776869.776869 lmp.py:372]   Expert  4 |    229 | GPU
DEBUG 01-05 09:19:51.776081.776081 lmp.py:372]   Expert 53 |    239 | GPU
DEBUG 01-05 09:19:51.776294.776294 lmp.py:372]   Expert 36 |    253 | GPU
DEBUG 01-05 09:19:51.776175.776175 lmp.py:372]   Expert 44 |    275 | GPU
DEBUG 01-05 09:19:51.776864.776864 lmp.py:372]   Expert  0 |    292 | GPU
DEBUG 01-05 09:19:51.776792.776792 lmp.py:372]   Expert 61 |    321 | GPU
DEBUG 01-05 09:19:51.776528.776528 lmp.py:372]   Expert 37 |    353 | GPU
DEBUG 01-05 09:19:51.776740.776740 lmp.py:372]   Expert 55 |    361 | GPU
DEBUG 01-05 09:19:51.776191.776191 lmp.py:372]   Expert  9 |    366 | GPU
DEBUG 01-05 09:19:51.776072.776072 lmp.py:372]   Expert  8 |    381 | GPU
DEBUG 01-05 09:19:51.776000.776000 lmp.py:372]   Expert 63 |    463 | GPU
DEBUG 01-05 09:19:51.776974.776974 lmp.py:372]   Expert 15 |    464 | GPU
DEBUG 01-05 09:19:51.776187.776187 lmp.py:372]   Expert 46 |    515 | GPU
DEBUG 01-05 09:19:51.776114.776114 lmp.py:372]   Expert 21 |    563 | GPU
DEBUG 01-05 09:19:51.776327.776327 lmp.py:372]   Expert 56 |    593 | GPU
DEBUG 01-05 09:19:51.776639.776639 lmp.py:373] 
DEBUG 01-05 09:19:51.776639.776639 lmp.py:373]   CPU total tokens: 3304 (26.9%)
DEBUG 01-05 09:19:51.776805.776805 lmp.py:374]   GPU total tokens: 8984 (73.1%)
DEBUG 01-05 09:19:51.776501.776501 cuda_h.py:19] end experts_map_get cost 0.0015380382537841797 seconds
DEBUG 01-05 09:19:51.776144.776144 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.776305.776305 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.777594.777594 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.777192.777192 cuda_h.py:19] end allocate_cuda_memory cost 0.0002319812774658203 seconds
DEBUG 01-05 09:19:51.777181.777181 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.777129.777129 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.777753.777753 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.777880.777880 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df69b1e9-e3a4-4ca1-a981-098cab23fe97
DEBUG 01-05 09:19:51.777006.777006 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.778856.778856 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df69b1e9-e3a4-4ca1-a981-098cab23fe97
DEBUG 01-05 09:19:51.778355.778355 cuda_h.py:19] end load_into_gpu_async cost 0.001394033432006836 seconds
DEBUG 01-05 09:19:51.778150.778150 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.779892.779892 cuda_h.py:19] end restore_tensors2 cost 0.000377655029296875 seconds
DEBUG 01-05 09:19:51.779543.779543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002363443374633789 seconds
DEBUG 01-05 09:19:51.782647.782647 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00511932373046875 seconds
DEBUG 01-05 09:19:51.782868.782868 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.782400.782400 lmp.py:419] 
DEBUG 01-05 09:19:51.782400.782400 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.782336.782336 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-05 09:19:51.782131.782131 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.787043.787043 mlpmodule.py:704] group tensors cost 0.005522966384887695 s
DEBUG 01-05 09:19:51.790575.790575 mlpmodule.py:742] pad cost 0.0019233226776123047 s
DEBUG 01-05 09:19:51.790685.790685 mlpmodule.py:748] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-05 09:19:51.790389.790389 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-05 09:19:51.802487.802487 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.802724.802724 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.802362.802362 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:19:51.802697.802697 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.819868.819868 mlpmodule.py:793] group einsum cost 0.028867483139038086 s
DEBUG 01-05 09:19:51.820779.820779 mlpmodule.py:801] cpy2cputensor cost 0.0007486343383789062 s
DEBUG 01-05 09:19:51.859907.859907 cuda_h.py:19] end wait_cetm_experts cost 0.07749271392822266 seconds
DEBUG 01-05 09:19:51.859698.859698 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.860648.860648 cuda_h.py:19] end gpu_sexperts cost 0.0004467964172363281 seconds
DEBUG 01-05 09:19:51.860935.860935 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:19:51.860135.860135 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-05 09:19:51.860614.860614 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.147125244140625e-05 seconds
DEBUG 01-05 09:19:51.860900.860900 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.700920104980469e-05 seconds
DEBUG 01-05 09:19:51.860742.860742 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.860737.860737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df69b1e9-e3a4-4ca1-a981-098cab23fe97
DEBUG 01-05 09:19:51.860861.860861 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.860400.860400 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.860051.860051 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.864973.864973 cuda_h.py:19] end allocate_cuda_memory cost 0.0037636756896972656 seconds
DEBUG 01-05 09:19:51.864500.864500 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.864839.864839 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.864291.864291 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.864617.864617 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f189a4fe-4d09-40e8-9a49-61b6e3354e39
DEBUG 01-05 09:19:51.865892.865892 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.865090.865090 client.py:127] Model loaded
DEBUG 01-05 09:19:51.865801.865801 cuda_h.py:19] end wait_experts cost 0.004683017730712891 seconds
DEBUG 01-05 09:19:51.865649.865649 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.865452.865452 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:51.865200.865200 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f189a4fe-4d09-40e8-9a49-61b6e3354e39
DEBUG 01-05 09:19:51.866765.866765 cuda_h.py:19] end load_into_gpu_async cost 0.0011382102966308594 seconds
DEBUG 01-05 09:19:51.866329.866329 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.866955.866955 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-05 09:19:51.866002.866002 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005291461944580078 seconds
DEBUG 01-05 09:19:51.866549.866549 mlpmodule.py:531] gpu group tensors cost 0.0010418891906738281 s
INFO 01-05 09:19:51.866200.866200 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f189a4fe-4d09-40e8-9a49-61b6e3354e39
DEBUG 01-05 09:19:51.868358.868358 mlpmodule.py:564] gpu pad cost 0.0020093917846679688 s
DEBUG 01-05 09:19:51.869043.869043 mlpmodule.py:582] gpu group einsum cost 0.0005915164947509766 s
DEBUG 01-05 09:19:51.873768.873768 mlpmodule.py:611] gpu experts func einsum cost 0.00759577751159668 s
DEBUG 01-05 09:19:51.873259.873259 cuda_h.py:19] end gpu_experts cost 0.00789785385131836 seconds
DEBUG 01-05 09:19:51.873406.873406 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:51.873149.873149 mlpmodule.py:662]  experts func einsum cost 0.0911870002746582 s
INFO 01-05 09:19:51.875728.875728 client.py:127] Model loaded
DEBUG 01-05 09:19:51.875802.875802 cuda_h.py:19] end sllm_worker_task cost 0.014977216720581055 seconds
DEBUG 01-05 09:19:51.875122.875122 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0025620460510253906 seconds
DEBUG 01-05 09:19:51.876710.876710 cuda_h.py:19] end layer_moe_generate_9 cost 0.10143613815307617 seconds
DEBUG 01-05 09:19:51.876896.876896 lmp.py:214] -------------------------------- end layer 9 --------------------------------
DEBUG 01-05 09:19:51.876659.876659 lmp.py:173] -------------------------------- start layer 10 --------------------------------
DEBUG 01-05 09:19:51.876163.876163 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:51.876033.876033 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:51.879931.879931 cuda_h.py:19] end self_attn cost 0.002424478530883789 seconds
DEBUG 01-05 09:19:51.879002.879002 cuda_h.py:19] end iln_self_attn_paln cost 0.0030808448791503906 seconds
DEBUG 01-05 09:19:51.879415.879415 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-05 09:19:51.879654.879654 cuda_h.py:10] start gate
DEBUG 01-05 09:19:51.880284.880284 cuda_h.py:19] end gate cost 0.0005700588226318359 seconds
DEBUG 01-05 09:19:51.880875.880875 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:51.880534.880534 lmp.py:361] 
DEBUG 01-05 09:19:51.880534.880534 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:51.880151.880151 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:51.880278.880278 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:51.880497.880497 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:51.880809.880809 lmp.py:365] 
DEBUG 01-05 09:19:51.880809.880809 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:51.880214.880214 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:51.880579.880579 lmp.py:372]   Expert 34 |      8 | CPU
DEBUG 01-05 09:19:51.880983.880983 lmp.py:372]   Expert 61 |     21 | CPU
DEBUG 01-05 09:19:51.880149.880149 lmp.py:372]   Expert  3 |     22 | CPU
DEBUG 01-05 09:19:51.880269.880269 lmp.py:372]   Expert 14 |     23 | CPU
DEBUG 01-05 09:19:51.880481.880481 lmp.py:372]   Expert 47 |     37 | CPU
DEBUG 01-05 09:19:51.880932.880932 lmp.py:372]   Expert 32 |     41 | CPU
DEBUG 01-05 09:19:51.880099.880099 lmp.py:372]   Expert 48 |     43 | CPU
DEBUG 01-05 09:19:51.880741.880741 lmp.py:372]   Expert 55 |     51 | CPU
DEBUG 01-05 09:19:51.880338.880338 lmp.py:372]   Expert 15 |     62 | CPU
DEBUG 01-05 09:19:51.880027.880027 lmp.py:372]   Expert 27 |     64 | CPU
DEBUG 01-05 09:19:51.880478.880478 lmp.py:372]   Expert 13 |     67 | CPU
DEBUG 01-05 09:19:51.880214.880214 lmp.py:372]   Expert 12 |     75 | CPU
DEBUG 01-05 09:19:51.880426.880426 lmp.py:372]   Expert  6 |     80 | CPU
DEBUG 01-05 09:19:51.880162.880162 lmp.py:372]   Expert 19 |     84 | CPU
DEBUG 01-05 09:19:51.880375.880375 lmp.py:372]   Expert  7 |     86 | CPU
DEBUG 01-05 09:19:51.880302.880302 lmp.py:372]   Expert 56 |     89 | CPU
DEBUG 01-05 09:19:51.880184.880184 lmp.py:372]   Expert 44 |     94 | CPU
DEBUG 01-05 09:19:51.880873.880873 lmp.py:372]   Expert 38 |     98 | CPU
DEBUG 01-05 09:19:51.880324.880324 lmp.py:372]   Expert 54 |    100 | CPU
DEBUG 01-05 09:19:51.880298.880298 lmp.py:372]   Expert 26 |    105 | CPU
DEBUG 01-05 09:19:51.880510.880510 lmp.py:372]   Expert 37 |    109 | CPU
DEBUG 01-05 09:19:51.880246.880246 lmp.py:372]   Expert 46 |    110 | CPU
DEBUG 01-05 09:19:51.880127.880127 lmp.py:372]   Expert 50 |    111 | CPU
DEBUG 01-05 09:19:51.881532.881532 lmp.py:372]   Expert 28 |    118 | CPU
DEBUG 01-05 09:19:51.881698.881698 lmp.py:372]   Expert 20 |    126 | CPU
DEBUG 01-05 09:19:51.881910.881910 lmp.py:372]   Expert 62 |    132 | CPU
DEBUG 01-05 09:19:51.881885.881885 lmp.py:372]   Expert 35 |    137 | CPU
DEBUG 01-05 09:19:51.881335.881335 lmp.py:372]   Expert 43 |    143 | CPU
DEBUG 01-05 09:19:51.881455.881455 lmp.py:372]   Expert 36 |    149 | CPU
DEBUG 01-05 09:19:51.881668.881668 lmp.py:372]   Expert 52 |    154 | CPU
DEBUG 01-05 09:19:51.881880.881880 lmp.py:372]   Expert 25 |    160 | CPU
DEBUG 01-05 09:19:51.881331.881331 lmp.py:372]   Expert 60 |    160 | CPU
DEBUG 01-05 09:19:51.881259.881259 lmp.py:372]   Expert 45 |    163 | GPU
DEBUG 01-05 09:19:51.881471.881471 lmp.py:372]   Expert 41 |    164 | GPU
DEBUG 01-05 09:19:51.881545.881545 lmp.py:372]   Expert 29 |    165 | GPU
DEBUG 01-05 09:19:51.881996.881996 lmp.py:372]   Expert 22 |    174 | GPU
DEBUG 01-05 09:19:51.881208.881208 lmp.py:372]   Expert 51 |    174 | GPU
DEBUG 01-05 09:19:51.881897.881897 lmp.py:372]   Expert  2 |    183 | GPU
DEBUG 01-05 09:19:51.881825.881825 lmp.py:372]   Expert 24 |    184 | GPU
DEBUG 01-05 09:19:51.881276.881276 lmp.py:372]   Expert 17 |    185 | GPU
DEBUG 01-05 09:19:51.881442.881442 lmp.py:372]   Expert 63 |    189 | GPU
DEBUG 01-05 09:19:51.881370.881370 lmp.py:372]   Expert 42 |    217 | GPU
DEBUG 01-05 09:19:51.881966.881966 lmp.py:372]   Expert 59 |    221 | GPU
DEBUG 01-05 09:19:51.881417.881417 lmp.py:372]   Expert  5 |    228 | GPU
DEBUG 01-05 09:19:51.881630.881630 lmp.py:372]   Expert 57 |    230 | GPU
DEBUG 01-05 09:19:51.881604.881604 lmp.py:372]   Expert 21 |    234 | GPU
DEBUG 01-05 09:19:51.881816.881816 lmp.py:372]   Expert 31 |    235 | GPU
DEBUG 01-05 09:19:51.881221.881221 lmp.py:372]   Expert 53 |    241 | GPU
DEBUG 01-05 09:19:51.881387.881387 lmp.py:372]   Expert 18 |    245 | GPU
DEBUG 01-05 09:19:51.881076.881076 lmp.py:372]   Expert 39 |    254 | GPU
DEBUG 01-05 09:19:51.881110.881110 lmp.py:372]   Expert 30 |    265 | GPU
DEBUG 01-05 09:19:51.881323.881323 lmp.py:372]   Expert 16 |    277 | GPU
DEBUG 01-05 09:19:51.881535.881535 lmp.py:372]   Expert  9 |    292 | GPU
DEBUG 01-05 09:19:51.881748.881748 lmp.py:372]   Expert  8 |    298 | GPU
DEBUG 01-05 09:19:51.881722.881722 lmp.py:372]   Expert 10 |    306 | GPU
DEBUG 01-05 09:19:51.881411.881411 lmp.py:372]   Expert 49 |    348 | GPU
DEBUG 01-05 09:19:51.881339.881339 lmp.py:372]   Expert 23 |    378 | GPU
DEBUG 01-05 09:19:51.881697.881697 lmp.py:372]   Expert 33 |    389 | GPU
DEBUG 01-05 09:19:51.881909.881909 lmp.py:372]   Expert 40 |    404 | GPU
DEBUG 01-05 09:19:51.881883.881883 lmp.py:372]   Expert  0 |    454 | GPU
DEBUG 01-05 09:19:51.881334.881334 lmp.py:372]   Expert 58 |    519 | GPU
DEBUG 01-05 09:19:51.881308.881308 lmp.py:372]   Expert 11 |    589 | GPU
DEBUG 01-05 09:19:51.881998.881998 lmp.py:372]   Expert  4 |    604 | GPU
DEBUG 01-05 09:19:51.881356.881356 lmp.py:372]   Expert  1 |    620 | GPU
DEBUG 01-05 09:19:51.881999.881999 lmp.py:373] 
DEBUG 01-05 09:19:51.881999.881999 lmp.py:373]   CPU total tokens: 2859 (23.3%)
DEBUG 01-05 09:19:51.881119.881119 lmp.py:374]   GPU total tokens: 9429 (76.7%)
DEBUG 01-05 09:19:51.881815.881815 cuda_h.py:19] end experts_map_get cost 0.001542806625366211 seconds
DEBUG 01-05 09:19:51.881219.881219 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:51.881864.881864 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.881954.881954 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.882486.882486 cuda_h.py:19] end allocate_cuda_memory cost 0.0002167224884033203 seconds
DEBUG 01-05 09:19:51.882951.882951 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.882707.882707 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.882047.882047 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.882219.882219 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2c071e92-af9d-42c6-a88b-18c2e8e90994
DEBUG 01-05 09:19:51.882491.882491 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:51.884694.884694 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2c071e92-af9d-42c6-a88b-18c2e8e90994
DEBUG 01-05 09:19:51.884623.884623 cuda_h.py:19] end load_into_gpu_async cost 0.0022199153900146484 seconds
DEBUG 01-05 09:19:51.884610.884610 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.884711.884711 cuda_h.py:19] end restore_tensors2 cost 0.000396728515625 seconds
DEBUG 01-05 09:19:51.885508.885508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031905174255371094 seconds
DEBUG 01-05 09:19:51.887022.887022 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0059337615966796875 seconds
DEBUG 01-05 09:19:51.887242.887242 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:51.887251.887251 lmp.py:419] 
DEBUG 01-05 09:19:51.887251.887251 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:51.887664.887664 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-05 09:19:51.887221.887221 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:51.900714.900714 mlpmodule.py:704] group tensors cost 0.012009859085083008 s
DEBUG 01-05 09:19:51.902564.902564 mlpmodule.py:742] pad cost 0.0019683837890625 s
DEBUG 01-05 09:19:51.903443.903443 mlpmodule.py:748] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-05 09:19:51.903141.903141 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:19:51.914475.914475 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:51.914428.914428 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:51.914425.914425 mlpmodule.py:773] group_w3 first element: 0.0164794921875
WARNING 01-05 09:19:51.914317.914317 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:51.933801.933801 mlpmodule.py:793] group einsum cost 0.03049468994140625 s
DEBUG 01-05 09:19:51.934500.934500 mlpmodule.py:801] cpy2cputensor cost 0.0006933212280273438 s
DEBUG 01-05 09:19:51.983724.983724 cuda_h.py:19] end wait_cetm_experts cost 0.09586620330810547 seconds
DEBUG 01-05 09:19:51.983668.983668 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:51.984574.984574 cuda_h.py:19] end gpu_sexperts cost 0.0005202293395996094 seconds
DEBUG 01-05 09:19:51.984801.984801 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:19:51.984524.984524 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-05 09:19:51.984341.984341 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.8623809814453125e-05 seconds
DEBUG 01-05 09:19:51.984197.984197 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:19:51.984754.984754 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:51.984464.984464 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2c071e92-af9d-42c6-a88b-18c2e8e90994
DEBUG 01-05 09:19:51.984304.984304 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:51.985988.985988 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:51.985977.985977 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:51.994462.994462 cuda_h.py:19] end allocate_cuda_memory cost 0.008881568908691406 seconds
INFO 01-05 09:19:51.994565.994565 client.py:127] Model loaded
DEBUG 01-05 09:19:51.994309.994309 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:51.994259.994259 cuda_h.py:19] end wait_experts cost 0.009501934051513672 seconds
DEBUG 01-05 09:19:51.994081.994081 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:51.994441.994441 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:51.994311.994311 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:51.994798.994798 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a3c129d4-057e-4c21-8582-c7d148be3693
DEBUG 01-05 09:19:51.994126.994126 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:51.994962.994962 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:51.995053.995053 mlpmodule.py:531] gpu group tensors cost 0.0006258487701416016 s
INFO 01-05 09:19:51.996778.996778 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a3c129d4-057e-4c21-8582-c7d148be3693
DEBUG 01-05 09:19:51.996091.996091 cuda_h.py:19] end load_into_gpu_async cost 0.0018734931945800781 seconds
DEBUG 01-05 09:19:51.996602.996602 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:51.996268.996268 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-05 09:19:51.996262.996262 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011298894882202148 seconds
INFO 01-05 09:19:51.996685.996685 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a3c129d4-057e-4c21-8582-c7d148be3693
DEBUG 01-05 09:19:51.997360.997360 mlpmodule.py:564] gpu pad cost 0.002381563186645508 s
DEBUG 01-05 09:19:51.998552.998552 mlpmodule.py:582] gpu group einsum cost 0.0005130767822265625 s
DEBUG 01-05 09:19:52.001879.001879 mlpmodule.py:611] gpu experts func einsum cost 0.006888628005981445 s
DEBUG 01-05 09:19:52.001317.001317 cuda_h.py:19] end gpu_experts cost 0.007429838180541992 seconds
DEBUG 01-05 09:19:52.001742.001742 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:52.005187.005187 client.py:127] Model loaded
DEBUG 01-05 09:19:52.005421.005421 cuda_h.py:19] end sllm_worker_task cost 0.020055532455444336 seconds
DEBUG 01-05 09:19:52.005119.005119 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0031261444091796875 seconds
DEBUG 01-05 09:19:52.005899.005899 cuda_h.py:19] end layer_moe_generate_10 cost 0.12578105926513672 seconds
DEBUG 01-05 09:19:52.005932.005932 lmp.py:214] -------------------------------- end layer 10 --------------------------------
DEBUG 01-05 09:19:52.005172.005172 lmp.py:173] -------------------------------- start layer 11 --------------------------------
DEBUG 01-05 09:19:52.005676.005676 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.005917.005917 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.008387.008387 cuda_h.py:19] end self_attn cost 0.0024924278259277344 seconds
DEBUG 01-05 09:19:52.008265.008265 cuda_h.py:19] end iln_self_attn_paln cost 0.0031447410583496094 seconds
DEBUG 01-05 09:19:52.008539.008539 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-05 09:19:52.008924.008924 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.009157.009157 cuda_h.py:19] end gate cost 0.0005943775177001953 seconds
DEBUG 01-05 09:19:52.009464.009464 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.009924.009924 lmp.py:361] 
DEBUG 01-05 09:19:52.009924.009924 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.009111.009111 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.009714.009714 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.009741.009741 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.009576.009576 lmp.py:365] 
DEBUG 01-05 09:19:52.009576.009576 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.009696.009696 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.009346.009346 lmp.py:372]   Expert 35 |     14 | CPU
DEBUG 01-05 09:19:52.009704.009704 lmp.py:372]   Expert 39 |     21 | CPU
DEBUG 01-05 09:19:52.009870.009870 lmp.py:372]   Expert 19 |     23 | CPU
DEBUG 01-05 09:19:52.009275.009275 lmp.py:372]   Expert 16 |     28 | CPU
DEBUG 01-05 09:19:52.010633.010633 lmp.py:372]   Expert 59 |     33 | CPU
DEBUG 01-05 09:19:52.010322.010322 lmp.py:372]   Expert 49 |     41 | CPU
DEBUG 01-05 09:19:52.010442.010442 lmp.py:372]   Expert 17 |     54 | CPU
DEBUG 01-05 09:19:52.010131.010131 lmp.py:372]   Expert 41 |     57 | CPU
DEBUG 01-05 09:19:52.010821.010821 lmp.py:372]   Expert  7 |     68 | CPU
DEBUG 01-05 09:19:52.010417.010417 lmp.py:372]   Expert  5 |     69 | CPU
DEBUG 01-05 09:19:52.010107.010107 lmp.py:372]   Expert  3 |     76 | CPU
DEBUG 01-05 09:19:52.010796.010796 lmp.py:372]   Expert  8 |     78 | CPU
DEBUG 01-05 09:19:52.010247.010247 lmp.py:372]   Expert 15 |     79 | CPU
DEBUG 01-05 09:19:52.010936.010936 lmp.py:372]   Expert 38 |     79 | CPU
DEBUG 01-05 09:19:52.010910.010910 lmp.py:372]   Expert  6 |     83 | CPU
DEBUG 01-05 09:19:52.010361.010361 lmp.py:372]   Expert 23 |     85 | CPU
DEBUG 01-05 09:19:52.010004.010004 lmp.py:372]   Expert 44 |     87 | CPU
DEBUG 01-05 09:19:52.010932.010932 lmp.py:372]   Expert  0 |     88 | CPU
DEBUG 01-05 09:19:52.010528.010528 lmp.py:372]   Expert 46 |     95 | CPU
DEBUG 01-05 09:19:52.010741.010741 lmp.py:372]   Expert  4 |    102 | CPU
DEBUG 01-05 09:19:52.010953.010953 lmp.py:372]   Expert 10 |    105 | CPU
DEBUG 01-05 09:19:52.010643.010643 lmp.py:372]   Expert 52 |    108 | CPU
DEBUG 01-05 09:19:52.010378.010378 lmp.py:372]   Expert 63 |    109 | CPU
DEBUG 01-05 09:19:52.010591.010591 lmp.py:372]   Expert 40 |    110 | CPU
DEBUG 01-05 09:19:52.010472.010472 lmp.py:372]   Expert 62 |    116 | CPU
DEBUG 01-05 09:19:52.010923.010923 lmp.py:372]   Expert 27 |    120 | CPU
DEBUG 01-05 09:19:52.010374.010374 lmp.py:372]   Expert 32 |    122 | CPU
DEBUG 01-05 09:19:52.010302.010302 lmp.py:372]   Expert 60 |    128 | CPU
DEBUG 01-05 09:19:52.010514.010514 lmp.py:372]   Expert  1 |    135 | CPU
DEBUG 01-05 09:19:52.010680.010680 lmp.py:372]   Expert 20 |    140 | CPU
DEBUG 01-05 09:19:52.010085.010085 lmp.py:372]   Expert 36 |    140 | CPU
DEBUG 01-05 09:19:52.010536.010536 lmp.py:372]   Expert 48 |    140 | CPU
DEBUG 01-05 09:19:52.010748.010748 lmp.py:372]   Expert 50 |    140 | GPU
DEBUG 01-05 09:19:52.010636.010636 lmp.py:372]   Expert 25 |    142 | GPU
DEBUG 01-05 09:19:52.010233.010233 lmp.py:372]   Expert 31 |    142 | GPU
DEBUG 01-05 09:19:52.010922.010922 lmp.py:372]   Expert 57 |    170 | GPU
DEBUG 01-05 09:19:52.010280.010280 lmp.py:372]   Expert 61 |    172 | GPU
DEBUG 01-05 09:19:52.010731.010731 lmp.py:372]   Expert 51 |    173 | GPU
DEBUG 01-05 09:19:52.010182.010182 lmp.py:372]   Expert 13 |    179 | GPU
DEBUG 01-05 09:19:52.010156.010156 lmp.py:372]   Expert 18 |    182 | GPU
DEBUG 01-05 09:19:52.010892.010892 lmp.py:372]   Expert 42 |    191 | GPU
DEBUG 01-05 09:19:52.010343.010343 lmp.py:372]   Expert 56 |    194 | GPU
DEBUG 01-05 09:19:52.010463.010463 lmp.py:372]   Expert 43 |    221 | GPU
DEBUG 01-05 09:19:52.010390.010390 lmp.py:372]   Expert 26 |    223 | GPU
DEBUG 01-05 09:19:52.010556.010556 lmp.py:372]   Expert  2 |    228 | GPU
DEBUG 01-05 09:19:52.010769.010769 lmp.py:372]   Expert 47 |    255 | GPU
DEBUG 01-05 09:19:52.010981.010981 lmp.py:372]   Expert 33 |    257 | GPU
DEBUG 01-05 09:19:52.010909.010909 lmp.py:372]   Expert 53 |    271 | GPU
DEBUG 01-05 09:19:52.010075.010075 lmp.py:372]   Expert 12 |    273 | GPU
DEBUG 01-05 09:19:52.010288.010288 lmp.py:372]   Expert 55 |    289 | GPU
DEBUG 01-05 09:19:52.010262.010262 lmp.py:372]   Expert 45 |    310 | GPU
DEBUG 01-05 09:19:52.010474.010474 lmp.py:372]   Expert 14 |    311 | GPU
DEBUG 01-05 09:19:52.010687.010687 lmp.py:372]   Expert 58 |    317 | GPU
DEBUG 01-05 09:19:52.010091.010091 lmp.py:372]   Expert 29 |    323 | GPU
DEBUG 01-05 09:19:52.010019.010019 lmp.py:372]   Expert 24 |    327 | GPU
DEBUG 01-05 09:19:52.010616.010616 lmp.py:372]   Expert 34 |    347 | GPU
DEBUG 01-05 09:19:52.010305.010305 lmp.py:372]   Expert 37 |    355 | GPU
DEBUG 01-05 09:19:52.010279.010279 lmp.py:372]   Expert 54 |    364 | GPU
DEBUG 01-05 09:19:52.010730.010730 lmp.py:372]   Expert 21 |    390 | GPU
DEBUG 01-05 09:19:52.010942.010942 lmp.py:372]   Expert 28 |    390 | GPU
DEBUG 01-05 09:19:52.010916.010916 lmp.py:372]   Expert  9 |    396 | GPU
DEBUG 01-05 09:19:52.010036.010036 lmp.py:372]   Expert 22 |    452 | GPU
DEBUG 01-05 09:19:52.010917.010917 lmp.py:372]   Expert 11 |    476 | GPU
DEBUG 01-05 09:19:52.011799.011799 lmp.py:372]   Expert 30 |   1095 | GPU
DEBUG 01-05 09:19:52.011203.011203 lmp.py:373] 
DEBUG 01-05 09:19:52.011203.011203 lmp.py:373]   CPU total tokens: 2733 (22.2%)
DEBUG 01-05 09:19:52.011846.011846 lmp.py:374]   GPU total tokens: 9555 (77.8%)
DEBUG 01-05 09:19:52.011211.011211 cuda_h.py:19] end experts_map_get cost 0.0015401840209960938 seconds
DEBUG 01-05 09:19:52.011331.011331 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.011922.011922 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.011543.011543 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.011539.011539 cuda_h.py:19] end allocate_cuda_memory cost 0.0004546642303466797 seconds
DEBUG 01-05 09:19:52.011535.011535 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.011245.011245 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.011213.011213 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.011486.011486 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42adfe7d-e78b-4c91-a3db-1651edac10c0
DEBUG 01-05 09:19:52.012797.012797 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:52.012007.012007 mlpmodule.py:662]  experts func einsum cost 0.12419629096984863 s
INFO 01-05 09:19:52.014840.014840 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42adfe7d-e78b-4c91-a3db-1651edac10c0
DEBUG 01-05 09:19:52.014962.014962 cuda_h.py:19] end load_into_gpu_async cost 0.0022428035736083984 seconds
DEBUG 01-05 09:19:52.014242.014242 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.014759.014759 cuda_h.py:19] end restore_tensors2 cost 0.00038886070251464844 seconds
DEBUG 01-05 09:19:52.014271.014271 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034646987915039062 seconds
DEBUG 01-05 09:19:52.017229.017229 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00621485710144043 seconds
DEBUG 01-05 09:19:52.017211.017211 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.017797.017797 lmp.py:419] 
DEBUG 01-05 09:19:52.017797.017797 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.017077.017077 cuda_h.py:19] end cpu_experts_submit cost 0.00011682510375976562 seconds
DEBUG 01-05 09:19:52.017495.017495 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.033967.033967 mlpmodule.py:704] group tensors cost 0.015269994735717773 s
DEBUG 01-05 09:19:52.035287.035287 mlpmodule.py:742] pad cost 0.0016126632690429688 s
DEBUG 01-05 09:19:52.035424.035424 mlpmodule.py:748] create cpu tensor cost 6.794929504394531e-05 s
DEBUG 01-05 09:19:52.035618.035618 mlpmodule.py:753] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-05 09:19:52.047501.047501 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.047401.047401 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.047967.047967 mlpmodule.py:773] group_w3 first element: -0.07568359375
WARNING 01-05 09:19:52.047296.047296 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.066240.066240 mlpmodule.py:793] group einsum cost 0.030146360397338867 s
DEBUG 01-05 09:19:52.066480.066480 mlpmodule.py:801] cpy2cputensor cost 0.0006146430969238281 s
DEBUG 01-05 09:19:52.101690.101690 cuda_h.py:19] end wait_cetm_experts cost 0.08405089378356934 seconds
DEBUG 01-05 09:19:52.101735.101735 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.102982.102982 cuda_h.py:19] end gpu_sexperts cost 0.0005931854248046875 seconds
DEBUG 01-05 09:19:52.102977.102977 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:19:52.102085.102085 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-05 09:19:52.102425.102425 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.719329833984375e-05 seconds
DEBUG 01-05 09:19:52.102757.102757 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.963180541992188e-05 seconds
DEBUG 01-05 09:19:52.102076.102076 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.102263.102263 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42adfe7d-e78b-4c91-a3db-1651edac10c0
DEBUG 01-05 09:19:52.102778.102778 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.103722.103722 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.103519.103519 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.109329.109329 cuda_h.py:19] end allocate_cuda_memory cost 0.005959987640380859 seconds
DEBUG 01-05 09:19:52.109153.109153 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.109936.109936 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.109673.109673 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.109906.109906 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b654ad7-acde-48f3-a4f7-224422c2367d
DEBUG 01-05 09:19:52.109180.109180 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.109571.109571 client.py:127] Model loaded
DEBUG 01-05 09:19:52.109712.109712 cuda_h.py:19] end wait_experts cost 0.006897926330566406 seconds
DEBUG 01-05 09:19:52.109230.109230 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.109747.109747 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:52.110076.110076 mlpmodule.py:531] gpu group tensors cost 0.0006525516510009766 s
INFO 01-05 09:19:52.110861.110861 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b654ad7-acde-48f3-a4f7-224422c2367d
DEBUG 01-05 09:19:52.110236.110236 cuda_h.py:19] end load_into_gpu_async cost 0.0014481544494628906 seconds
DEBUG 01-05 09:19:52.110661.110661 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.116785.116785 cuda_h.py:19] end restore_tensors2 cost 0.005259275436401367 seconds
DEBUG 01-05 09:19:52.116124.116124 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012973785400390625 seconds
INFO 01-05 09:19:52.116567.116567 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b654ad7-acde-48f3-a4f7-224422c2367d
DEBUG 01-05 09:19:52.118357.118357 mlpmodule.py:564] gpu pad cost 0.007631540298461914 s
INFO 01-05 09:19:52.118947.118947 client.py:127] Model loaded
DEBUG 01-05 09:19:52.118829.118829 cuda_h.py:19] end sllm_worker_task cost 0.01567530632019043 seconds
DEBUG 01-05 09:19:52.123323.123323 mlpmodule.py:662]  experts func einsum cost 0.1054525375366211 s
DEBUG 01-05 09:19:52.123450.123450 mlpmodule.py:582] gpu group einsum cost 0.005239009857177734 s
DEBUG 01-05 09:19:52.126864.126864 mlpmodule.py:611] gpu experts func einsum cost 0.016857385635375977 s
DEBUG 01-05 09:19:52.126592.126592 cuda_h.py:19] end gpu_experts cost 0.01712775230407715 seconds
DEBUG 01-05 09:19:52.126732.126732 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:52.126562.126562 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-05 09:19:52.127176.127176 cuda_h.py:19] end layer_moe_generate_11 cost 0.11827349662780762 seconds
DEBUG 01-05 09:19:52.127500.127500 lmp.py:214] -------------------------------- end layer 11 --------------------------------
DEBUG 01-05 09:19:52.127476.127476 lmp.py:173] -------------------------------- start layer 12 --------------------------------
DEBUG 01-05 09:19:52.127741.127741 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.127698.127698 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.130173.130173 cuda_h.py:19] end self_attn cost 0.0024709701538085938 seconds
DEBUG 01-05 09:19:52.130965.130965 cuda_h.py:19] end iln_self_attn_paln cost 0.0030851364135742188 seconds
DEBUG 01-05 09:19:52.130662.130662 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-05 09:19:52.130140.130140 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.131426.131426 cuda_h.py:19] end gate cost 0.0005965232849121094 seconds
DEBUG 01-05 09:19:52.131971.131971 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.131862.131862 lmp.py:361] 
DEBUG 01-05 09:19:52.131862.131862 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.131525.131525 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.131082.131082 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.131348.131348 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.131229.131229 lmp.py:365] 
DEBUG 01-05 09:19:52.131229.131229 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.131064.131064 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.131383.131383 lmp.py:372]   Expert 51 |     12 | CPU
DEBUG 01-05 09:19:52.131410.131410 lmp.py:372]   Expert 63 |     16 | CPU
DEBUG 01-05 09:19:52.131576.131576 lmp.py:372]   Expert 22 |     21 | CPU
DEBUG 01-05 09:19:52.131027.131027 lmp.py:372]   Expert 11 |     23 | CPU
DEBUG 01-05 09:19:52.131478.131478 lmp.py:372]   Expert 12 |     25 | CPU
DEBUG 01-05 09:19:52.131691.131691 lmp.py:372]   Expert 34 |     27 | CPU
DEBUG 01-05 09:19:52.131141.131141 lmp.py:372]   Expert 47 |     31 | CPU
DEBUG 01-05 09:19:52.131738.131738 lmp.py:372]   Expert  4 |     35 | CPU
DEBUG 01-05 09:19:52.131951.131951 lmp.py:372]   Expert 16 |     35 | CPU
DEBUG 01-05 09:19:52.131686.131686 lmp.py:372]   Expert 44 |     45 | CPU
DEBUG 01-05 09:19:52.131376.131376 lmp.py:372]   Expert  0 |     48 | CPU
DEBUG 01-05 09:19:52.131588.131588 lmp.py:372]   Expert 29 |     59 | CPU
DEBUG 01-05 09:19:52.131800.131800 lmp.py:372]   Expert 32 |     63 | CPU
DEBUG 01-05 09:19:52.131205.131205 lmp.py:372]   Expert 27 |     73 | CPU
DEBUG 01-05 09:19:52.131371.131371 lmp.py:372]   Expert 37 |     73 | CPU
DEBUG 01-05 09:19:52.131776.131776 lmp.py:372]   Expert 13 |     77 | CPU
DEBUG 01-05 09:19:52.131657.131657 lmp.py:372]   Expert 23 |     89 | CPU
DEBUG 01-05 09:19:52.131346.131346 lmp.py:372]   Expert 41 |     90 | CPU
DEBUG 01-05 09:19:52.132420.132420 lmp.py:372]   Expert  8 |     92 | CPU
DEBUG 01-05 09:19:52.132871.132871 lmp.py:372]   Expert 49 |     96 | CPU
DEBUG 01-05 09:19:52.132845.132845 lmp.py:372]   Expert  2 |     99 | CPU
DEBUG 01-05 09:19:52.132057.132057 lmp.py:372]   Expert 21 |    104 | CPU
DEBUG 01-05 09:19:52.132508.132508 lmp.py:372]   Expert 43 |    110 | CPU
DEBUG 01-05 09:19:52.132482.132482 lmp.py:372]   Expert 39 |    129 | CPU
DEBUG 01-05 09:19:52.132602.132602 lmp.py:372]   Expert 62 |    129 | CPU
DEBUG 01-05 09:19:52.132291.132291 lmp.py:372]   Expert  3 |    133 | CPU
DEBUG 01-05 09:19:52.132219.132219 lmp.py:372]   Expert 55 |    141 | CPU
DEBUG 01-05 09:19:52.132862.132862 lmp.py:372]   Expert 30 |    146 | CPU
DEBUG 01-05 09:19:52.132267.132267 lmp.py:372]   Expert 14 |    148 | CPU
DEBUG 01-05 09:19:52.132671.132671 lmp.py:372]   Expert  7 |    151 | CPU
DEBUG 01-05 09:19:52.132884.132884 lmp.py:372]   Expert 42 |    155 | CPU
DEBUG 01-05 09:19:52.132480.132480 lmp.py:372]   Expert 61 |    155 | CPU
DEBUG 01-05 09:19:52.132454.132454 lmp.py:372]   Expert 58 |    161 | GPU
DEBUG 01-05 09:19:52.132428.132428 lmp.py:372]   Expert 45 |    179 | GPU
DEBUG 01-05 09:19:52.132402.132402 lmp.py:372]   Expert 38 |    183 | GPU
DEBUG 01-05 09:19:52.132138.132138 lmp.py:372]   Expert 53 |    185 | GPU
DEBUG 01-05 09:19:52.132112.132112 lmp.py:372]   Expert 31 |    190 | GPU
DEBUG 01-05 09:19:52.132232.132232 lmp.py:372]   Expert 35 |    195 | GPU
DEBUG 01-05 09:19:52.132206.132206 lmp.py:372]   Expert  5 |    202 | GPU
DEBUG 01-05 09:19:52.132657.132657 lmp.py:372]   Expert 18 |    204 | GPU
DEBUG 01-05 09:19:52.132068.132068 lmp.py:372]   Expert 17 |    211 | GPU
DEBUG 01-05 09:19:52.132188.132188 lmp.py:372]   Expert  6 |    212 | GPU
DEBUG 01-05 09:19:52.132116.132116 lmp.py:372]   Expert  1 |    223 | GPU
DEBUG 01-05 09:19:52.132805.132805 lmp.py:372]   Expert 19 |    226 | GPU
DEBUG 01-05 09:19:52.132256.132256 lmp.py:372]   Expert 50 |    241 | GPU
DEBUG 01-05 09:19:52.132945.132945 lmp.py:372]   Expert 20 |    242 | GPU
DEBUG 01-05 09:19:52.132396.132396 lmp.py:372]   Expert 57 |    255 | GPU
DEBUG 01-05 09:19:52.132608.132608 lmp.py:372]   Expert 46 |    258 | GPU
DEBUG 01-05 09:19:52.132728.132728 lmp.py:372]   Expert 59 |    278 | GPU
DEBUG 01-05 09:19:52.132702.132702 lmp.py:372]   Expert 26 |    280 | GPU
DEBUG 01-05 09:19:52.132200.132200 lmp.py:372]   Expert 52 |    280 | GPU
DEBUG 01-05 09:19:52.132174.132174 lmp.py:372]   Expert 54 |    301 | GPU
DEBUG 01-05 09:19:52.132148.132148 lmp.py:372]   Expert 48 |    306 | GPU
DEBUG 01-05 09:19:52.132645.132645 lmp.py:372]   Expert 28 |    307 | GPU
DEBUG 01-05 09:19:52.132288.132288 lmp.py:372]   Expert 60 |    318 | GPU
DEBUG 01-05 09:19:52.132262.132262 lmp.py:372]   Expert 25 |    319 | GPU
DEBUG 01-05 09:19:52.132759.132759 lmp.py:372]   Expert 24 |    339 | GPU
DEBUG 01-05 09:19:52.132495.132495 lmp.py:372]   Expert 36 |    370 | GPU
DEBUG 01-05 09:19:52.132469.132469 lmp.py:372]   Expert 40 |    370 | GPU
DEBUG 01-05 09:19:52.132350.132350 lmp.py:372]   Expert 33 |    414 | GPU
DEBUG 01-05 09:19:52.132039.132039 lmp.py:372]   Expert  9 |    461 | GPU
DEBUG 01-05 09:19:52.132206.132206 lmp.py:372]   Expert 15 |    552 | GPU
DEBUG 01-05 09:19:52.132133.132133 lmp.py:372]   Expert 56 |    578 | GPU
DEBUG 01-05 09:19:52.132823.132823 lmp.py:372]   Expert 10 |    818 | GPU
DEBUG 01-05 09:19:52.132419.132419 lmp.py:373] 
DEBUG 01-05 09:19:52.132419.132419 lmp.py:373]   CPU total tokens: 2630 (21.4%)
DEBUG 01-05 09:19:52.132062.132062 lmp.py:374]   GPU total tokens: 9658 (78.6%)
DEBUG 01-05 09:19:52.132997.132997 cuda_h.py:19] end experts_map_get cost 0.001535177230834961 seconds
DEBUG 01-05 09:19:52.132163.132163 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.132708.132708 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.133613.133613 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.133203.133203 cuda_h.py:19] end allocate_cuda_memory cost 0.00019073486328125 seconds
DEBUG 01-05 09:19:52.133146.133146 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.133617.133617 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.133148.133148 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.133467.133467 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5015e6f7-aeeb-44c4-9817-c938557f6547
DEBUG 01-05 09:19:52.133593.133593 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.135331.135331 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5015e6f7-aeeb-44c4-9817-c938557f6547
DEBUG 01-05 09:19:52.135068.135068 cuda_h.py:19] end load_into_gpu_async cost 0.0021936893463134766 seconds
DEBUG 01-05 09:19:52.135294.135294 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.136070.136070 cuda_h.py:19] end restore_tensors2 cost 0.00040340423583984375 seconds
DEBUG 01-05 09:19:52.136152.136152 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031485557556152344 seconds
DEBUG 01-05 09:19:52.138964.138964 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005899667739868164 seconds
DEBUG 01-05 09:19:52.138277.138277 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.138147.138147 lmp.py:419] 
DEBUG 01-05 09:19:52.138147.138147 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.138759.138759 cuda_h.py:19] end cpu_experts_submit cost 0.0001163482666015625 seconds
DEBUG 01-05 09:19:52.138885.138885 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.158605.158605 mlpmodule.py:704] group tensors cost 0.019230127334594727 s
DEBUG 01-05 09:19:52.161308.161308 mlpmodule.py:742] pad cost 0.001621246337890625 s
DEBUG 01-05 09:19:52.161087.161087 mlpmodule.py:748] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-05 09:19:52.161321.161321 mlpmodule.py:753] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-05 09:19:52.172009.172009 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.172015.172015 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.173662.173662 mlpmodule.py:773] group_w3 first element: -0.0162353515625
WARNING 01-05 09:19:52.173977.173977 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.191253.191253 mlpmodule.py:793] group einsum cost 0.029707670211791992 s
DEBUG 01-05 09:19:52.192284.192284 mlpmodule.py:801] cpy2cputensor cost 0.0007154941558837891 s
DEBUG 01-05 09:19:52.225828.225828 cuda_h.py:19] end wait_cetm_experts cost 0.08622336387634277 seconds
DEBUG 01-05 09:19:52.225496.225496 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.226775.226775 cuda_h.py:19] end gpu_sexperts cost 0.0005834102630615234 seconds
DEBUG 01-05 09:19:52.226533.226533 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:19:52.226779.226779 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-05 09:19:52.226642.226642 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.838539123535156e-05 seconds
DEBUG 01-05 09:19:52.226259.226259 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.939338684082031e-05 seconds
DEBUG 01-05 09:19:52.226101.226101 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.226573.226573 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5015e6f7-aeeb-44c4-9817-c938557f6547
DEBUG 01-05 09:19:52.226803.226803 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.226178.226178 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.226597.226597 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.234983.234983 cuda_h.py:19] end allocate_cuda_memory cost 0.007718801498413086 seconds
INFO 01-05 09:19:52.234755.234755 client.py:127] Model loaded
DEBUG 01-05 09:19:52.234645.234645 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.234595.234595 cuda_h.py:19] end wait_experts cost 0.008370637893676758 seconds
DEBUG 01-05 09:19:52.234556.234556 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.234393.234393 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.234448.234448 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.235266.235266 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1743d92c-a55f-4184-8316-3eb5207979ec
DEBUG 01-05 09:19:52.235217.235217 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:52.234715.234715 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:52.235979.235979 mlpmodule.py:531] gpu group tensors cost 0.000640869140625 s
INFO 01-05 09:19:52.236196.236196 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1743d92c-a55f-4184-8316-3eb5207979ec
DEBUG 01-05 09:19:52.236615.236615 cuda_h.py:19] end load_into_gpu_async cost 0.0015556812286376953 seconds
DEBUG 01-05 09:19:52.236417.236417 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.236839.236839 cuda_h.py:19] end restore_tensors2 cost 9.012222290039062e-05 seconds
DEBUG 01-05 09:19:52.236317.236317 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00986480712890625 seconds
INFO 01-05 09:19:52.237298.237298 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1743d92c-a55f-4184-8316-3eb5207979ec
DEBUG 01-05 09:19:52.238929.238929 mlpmodule.py:564] gpu pad cost 0.0026068687438964844 s
DEBUG 01-05 09:19:52.239658.239658 mlpmodule.py:582] gpu group einsum cost 0.0005295276641845703 s
DEBUG 01-05 09:19:52.242383.242383 mlpmodule.py:611] gpu experts func einsum cost 0.006979942321777344 s
DEBUG 01-05 09:19:52.242565.242565 cuda_h.py:19] end gpu_experts cost 0.007409811019897461 seconds
DEBUG 01-05 09:19:52.242129.242129 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:52.246941.246941 client.py:127] Model loaded
DEBUG 01-05 09:19:52.246506.246506 cuda_h.py:19] end sllm_worker_task cost 0.02008509635925293 seconds
DEBUG 01-05 09:19:52.246448.246448 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004347085952758789 seconds
DEBUG 01-05 09:19:52.246792.246792 cuda_h.py:19] end layer_moe_generate_12 cost 0.11639094352722168 seconds
DEBUG 01-05 09:19:52.247209.247209 lmp.py:214] -------------------------------- end layer 12 --------------------------------
DEBUG 01-05 09:19:52.247403.247403 lmp.py:173] -------------------------------- start layer 13 --------------------------------
DEBUG 01-05 09:19:52.247668.247668 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.247148.247148 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.250570.250570 cuda_h.py:19] end self_attn cost 0.0024671554565429688 seconds
DEBUG 01-05 09:19:52.250175.250175 cuda_h.py:19] end iln_self_attn_paln cost 0.003049135208129883 seconds
DEBUG 01-05 09:19:52.250680.250680 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-05 09:19:52.250728.250728 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.251570.251570 cuda_h.py:19] end gate cost 0.0005850791931152344 seconds
DEBUG 01-05 09:19:52.251015.251015 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.251515.251515 lmp.py:361] 
DEBUG 01-05 09:19:52.251515.251515 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.251510.251510 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.251636.251636 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.251425.251425 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.251353.251353 lmp.py:365] 
DEBUG 01-05 09:19:52.251353.251353 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.251234.251234 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.251553.251553 lmp.py:372]   Expert 53 |     10 | CPU
DEBUG 01-05 09:19:52.251580.251580 lmp.py:372]   Expert  6 |     11 | CPU
DEBUG 01-05 09:19:52.251508.251508 lmp.py:372]   Expert 19 |     24 | CPU
DEBUG 01-05 09:19:52.251482.251482 lmp.py:372]   Expert 50 |     27 | CPU
DEBUG 01-05 09:19:52.251456.251456 lmp.py:372]   Expert 26 |     29 | CPU
DEBUG 01-05 09:19:52.251430.251430 lmp.py:372]   Expert  2 |     39 | CPU
DEBUG 01-05 09:19:52.251881.251881 lmp.py:372]   Expert  0 |     45 | CPU
DEBUG 01-05 09:19:52.251001.251001 lmp.py:372]   Expert  8 |     53 | CPU
DEBUG 01-05 09:19:52.251928.251928 lmp.py:372]   Expert 12 |     60 | CPU
DEBUG 01-05 09:19:52.251618.251618 lmp.py:372]   Expert 31 |     79 | CPU
DEBUG 01-05 09:19:52.251545.251545 lmp.py:372]   Expert 16 |     83 | CPU
DEBUG 01-05 09:19:52.251758.251758 lmp.py:372]   Expert 30 |     91 | CPU
DEBUG 01-05 09:19:52.251209.251209 lmp.py:372]   Expert 32 |     91 | CPU
DEBUG 01-05 09:19:52.251421.251421 lmp.py:372]   Expert 20 |     92 | CPU
DEBUG 01-05 09:19:52.251303.251303 lmp.py:372]   Expert 40 |     95 | CPU
DEBUG 01-05 09:19:52.251283.251283 lmp.py:372]   Expert 28 |    113 | CPU
DEBUG 01-05 09:19:52.251973.251973 lmp.py:372]   Expert 48 |    120 | CPU
DEBUG 01-05 09:19:52.251470.251470 lmp.py:372]   Expert 13 |    122 | CPU
DEBUG 01-05 09:19:52.251967.251967 lmp.py:372]   Expert 35 |    123 | CPU
DEBUG 01-05 09:19:52.251895.251895 lmp.py:372]   Expert 57 |    123 | CPU
DEBUG 01-05 09:19:52.251107.251107 lmp.py:372]   Expert 34 |    127 | CPU
DEBUG 01-05 09:19:52.251035.251035 lmp.py:372]   Expert 61 |    130 | CPU
DEBUG 01-05 09:19:52.251539.251539 lmp.py:372]   Expert 63 |    133 | CPU
DEBUG 01-05 09:19:52.251136.251136 lmp.py:372]   Expert  5 |    134 | CPU
DEBUG 01-05 09:19:52.251209.251209 lmp.py:372]   Expert 18 |    135 | CPU
DEBUG 01-05 09:19:52.251806.251806 lmp.py:372]   Expert 11 |    136 | CPU
DEBUG 01-05 09:19:52.251595.251595 lmp.py:372]   Expert 60 |    138 | CPU
DEBUG 01-05 09:19:52.251953.251953 lmp.py:372]   Expert 52 |    149 | CPU
DEBUG 01-05 09:19:52.251834.251834 lmp.py:372]   Expert  9 |    150 | CPU
DEBUG 01-05 09:19:52.252477.252477 lmp.py:372]   Expert 58 |    151 | CPU
DEBUG 01-05 09:19:52.252120.252120 lmp.py:372]   Expert 24 |    159 | CPU
DEBUG 01-05 09:19:52.252386.252386 lmp.py:372]   Expert 45 |    164 | CPU
DEBUG 01-05 09:19:52.252506.252506 lmp.py:372]   Expert 42 |    177 | GPU
DEBUG 01-05 09:19:52.252341.252341 lmp.py:372]   Expert  3 |    181 | GPU
DEBUG 01-05 09:19:52.252176.252176 lmp.py:372]   Expert 37 |    187 | GPU
DEBUG 01-05 09:19:52.252488.252488 lmp.py:372]   Expert 25 |    189 | GPU
DEBUG 01-05 09:19:52.252084.252084 lmp.py:372]   Expert 46 |    199 | GPU
DEBUG 01-05 09:19:52.252873.252873 lmp.py:372]   Expert  4 |    209 | GPU
DEBUG 01-05 09:19:52.252708.252708 lmp.py:372]   Expert 33 |    216 | GPU
DEBUG 01-05 09:19:52.252066.252066 lmp.py:372]   Expert  7 |    218 | GPU
DEBUG 01-05 09:19:52.252663.252663 lmp.py:372]   Expert 27 |    218 | GPU
DEBUG 01-05 09:19:52.252544.252544 lmp.py:372]   Expert 17 |    224 | GPU
DEBUG 01-05 09:19:52.252426.252426 lmp.py:372]   Expert 62 |    225 | GPU
DEBUG 01-05 09:19:52.252407.252407 lmp.py:372]   Expert 43 |    227 | GPU
DEBUG 01-05 09:19:52.252242.252242 lmp.py:372]   Expert 39 |    229 | GPU
DEBUG 01-05 09:19:52.252553.252553 lmp.py:372]   Expert 22 |    230 | GPU
DEBUG 01-05 09:19:52.252972.252972 lmp.py:372]   Expert 51 |    239 | GPU
DEBUG 01-05 09:19:52.252045.252045 lmp.py:372]   Expert 49 |    253 | GPU
DEBUG 01-05 09:19:52.252119.252119 lmp.py:372]   Expert  1 |    256 | GPU
DEBUG 01-05 09:19:52.252298.252298 lmp.py:372]   Expert 54 |    263 | GPU
DEBUG 01-05 09:19:52.252061.252061 lmp.py:372]   Expert 36 |    266 | GPU
DEBUG 01-05 09:19:52.252135.252135 lmp.py:372]   Expert 29 |    271 | GPU
DEBUG 01-05 09:19:52.252493.252493 lmp.py:372]   Expert 44 |    272 | GPU
DEBUG 01-05 09:19:52.252613.252613 lmp.py:372]   Expert 59 |    298 | GPU
DEBUG 01-05 09:19:52.252209.252209 lmp.py:372]   Expert 15 |    311 | GPU
DEBUG 01-05 09:19:52.252998.252998 lmp.py:372]   Expert 47 |    332 | GPU
DEBUG 01-05 09:19:52.252548.252548 lmp.py:372]   Expert 38 |    361 | GPU
DEBUG 01-05 09:19:52.252622.252622 lmp.py:372]   Expert 14 |    391 | GPU
DEBUG 01-05 09:19:52.252218.252218 lmp.py:372]   Expert 55 |    401 | GPU
DEBUG 01-05 09:19:52.252292.252292 lmp.py:372]   Expert 23 |    406 | GPU
DEBUG 01-05 09:19:52.252034.252034 lmp.py:372]   Expert 41 |    415 | GPU
DEBUG 01-05 09:19:52.252631.252631 lmp.py:372]   Expert 21 |    421 | GPU
DEBUG 01-05 09:19:52.252228.252228 lmp.py:372]   Expert 10 |    474 | GPU
DEBUG 01-05 09:19:52.252301.252301 lmp.py:372]   Expert 56 |    593 | GPU
DEBUG 01-05 09:19:52.252851.252851 lmp.py:373] 
DEBUG 01-05 09:19:52.252851.252851 lmp.py:373]   CPU total tokens: 3136 (25.5%)
DEBUG 01-05 09:19:52.252309.252309 lmp.py:374]   GPU total tokens: 9152 (74.5%)
DEBUG 01-05 09:19:52.252628.252628 cuda_h.py:19] end experts_map_get cost 0.0016522407531738281 seconds
DEBUG 01-05 09:19:52.252086.252086 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.252014.252014 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.252927.252927 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.253750.253750 cuda_h.py:19] end allocate_cuda_memory cost 0.0002200603485107422 seconds
DEBUG 01-05 09:19:52.253713.253713 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.253422.253422 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.253099.253099 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.253756.253756 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 381e83c3-8cf8-4b94-915b-df5fa97bb6b4
DEBUG 01-05 09:19:52.253928.253928 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:52.253006.253006 mlpmodule.py:662]  experts func einsum cost 0.11449790000915527 s
INFO 01-05 09:19:52.254212.254212 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 381e83c3-8cf8-4b94-915b-df5fa97bb6b4
DEBUG 01-05 09:19:52.254003.254003 cuda_h.py:19] end load_into_gpu_async cost 0.0015106201171875 seconds
DEBUG 01-05 09:19:52.254236.254236 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.255283.255283 cuda_h.py:19] end restore_tensors2 cost 0.00039386749267578125 seconds
DEBUG 01-05 09:19:52.255265.255265 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025093555450439453 seconds
DEBUG 01-05 09:19:52.258712.258712 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0052411556243896484 seconds
DEBUG 01-05 09:19:52.258125.258125 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.258300.258300 lmp.py:419] 
DEBUG 01-05 09:19:52.258300.258300 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.258389.258389 cuda_h.py:19] end cpu_experts_submit cost 0.00011491775512695312 seconds
DEBUG 01-05 09:19:52.258615.258615 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.266813.266813 mlpmodule.py:704] group tensors cost 0.00772547721862793 s
DEBUG 01-05 09:19:52.268198.268198 mlpmodule.py:742] pad cost 0.0015845298767089844 s
DEBUG 01-05 09:19:52.268182.268182 mlpmodule.py:748] create cpu tensor cost 6.031990051269531e-05 s
DEBUG 01-05 09:19:52.268749.268749 mlpmodule.py:753] move to cpu cost 5.459785461425781e-05 s
DEBUG 01-05 09:19:52.280623.280623 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.280497.280497 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.280660.280660 mlpmodule.py:773] group_w3 first element: -0.020263671875
WARNING 01-05 09:19:52.281658.281658 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.299520.299520 mlpmodule.py:793] group einsum cost 0.030855417251586914 s
DEBUG 01-05 09:19:52.300406.300406 mlpmodule.py:801] cpy2cputensor cost 0.0007369518280029297 s
DEBUG 01-05 09:19:52.338510.338510 cuda_h.py:19] end wait_cetm_experts cost 0.07965755462646484 seconds
DEBUG 01-05 09:19:52.338601.338601 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.338774.338774 cuda_h.py:19] end gpu_sexperts cost 0.0005750656127929688 seconds
DEBUG 01-05 09:19:52.338624.338624 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:19:52.338540.338540 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-05 09:19:52.338595.338595 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.886222839355469e-05 seconds
DEBUG 01-05 09:19:52.339927.339927 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 8.106231689453125e-05 seconds
DEBUG 01-05 09:19:52.339008.339008 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.339956.339956 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 381e83c3-8cf8-4b94-915b-df5fa97bb6b4
DEBUG 01-05 09:19:52.339471.339471 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.339369.339369 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.339834.339834 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.346997.346997 cuda_h.py:19] end allocate_cuda_memory cost 0.007378101348876953 seconds
INFO 01-05 09:19:52.346246.346246 client.py:127] Model loaded
DEBUG 01-05 09:19:52.347944.347944 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.347370.347370 cuda_h.py:19] end wait_experts cost 0.008027315139770508 seconds
DEBUG 01-05 09:19:52.347286.347286 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.347837.347837 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.347224.347224 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.347804.347804 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f8caa055-f495-4027-8a75-5162ea3cf04b
DEBUG 01-05 09:19:52.347801.347801 client.py:106] call stub.LoadModelAsync
DEBUG 01-05 09:19:52.347491.347491 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:52.348854.348854 mlpmodule.py:531] gpu group tensors cost 0.0006442070007324219 s
DEBUG 01-05 09:19:52.350420.350420 mlpmodule.py:564] gpu pad cost 0.0017952919006347656 s
DEBUG 01-05 09:19:52.350133.350133 mlpmodule.py:582] gpu group einsum cost 0.0004508495330810547 s
INFO 01-05 09:19:52.351155.351155 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f8caa055-f495-4027-8a75-5162ea3cf04b
DEBUG 01-05 09:19:52.351230.351230 cuda_h.py:19] end load_into_gpu_async cost 0.00445866584777832 seconds
DEBUG 01-05 09:19:52.351171.351171 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.351691.351691 cuda_h.py:19] end restore_tensors2 cost 7.557868957519531e-05 seconds
DEBUG 01-05 09:19:52.351401.351401 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012384653091430664 seconds
INFO 01-05 09:19:52.352664.352664 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f8caa055-f495-4027-8a75-5162ea3cf04b
DEBUG 01-05 09:19:52.354125.354125 mlpmodule.py:611] gpu experts func einsum cost 0.00695490837097168 s
DEBUG 01-05 09:19:52.354626.354626 cuda_h.py:19] end gpu_experts cost 0.007409572601318359 seconds
DEBUG 01-05 09:19:52.354859.354859 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:52.359795.359795 client.py:127] Model loaded
DEBUG 01-05 09:19:52.359916.359916 cuda_h.py:19] end sllm_worker_task cost 0.020494699478149414 seconds
DEBUG 01-05 09:19:52.359587.359587 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005097627639770508 seconds
DEBUG 01-05 09:19:52.360819.360819 cuda_h.py:19] end layer_moe_generate_13 cost 0.1097252368927002 seconds
DEBUG 01-05 09:19:52.360602.360602 lmp.py:214] -------------------------------- end layer 13 --------------------------------
DEBUG 01-05 09:19:52.360669.360669 lmp.py:173] -------------------------------- start layer 14 --------------------------------
DEBUG 01-05 09:19:52.360664.360664 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.360363.360363 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.363608.363608 cuda_h.py:19] end self_attn cost 0.0025086402893066406 seconds
DEBUG 01-05 09:19:52.363239.363239 mlpmodule.py:662]  experts func einsum cost 0.10509181022644043 s
DEBUG 01-05 09:19:52.363085.363085 cuda_h.py:19] end iln_self_attn_paln cost 0.0034241676330566406 seconds
DEBUG 01-05 09:19:52.363605.363605 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-05 09:19:52.364421.364421 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.364720.364720 cuda_h.py:19] end gate cost 0.0006070137023925781 seconds
DEBUG 01-05 09:19:52.364980.364980 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.365302.365302 lmp.py:361] 
DEBUG 01-05 09:19:52.365302.365302 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.365919.365919 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.365237.365237 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.365026.365026 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.365908.365908 lmp.py:365] 
DEBUG 01-05 09:19:52.365908.365908 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.365266.365266 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.365492.365492 lmp.py:372]   Expert 61 |     11 | CPU
DEBUG 01-05 09:19:52.365135.365135 lmp.py:372]   Expert  7 |     13 | CPU
DEBUG 01-05 09:19:52.365824.365824 lmp.py:372]   Expert 59 |     37 | CPU
DEBUG 01-05 09:19:52.365275.365275 lmp.py:372]   Expert 48 |     51 | CPU
DEBUG 01-05 09:19:52.365964.365964 lmp.py:372]   Expert 34 |     56 | CPU
DEBUG 01-05 09:19:52.365892.365892 lmp.py:372]   Expert 50 |     57 | CPU
DEBUG 01-05 09:19:52.365727.365727 lmp.py:372]   Expert 49 |     59 | CPU
DEBUG 01-05 09:19:52.365940.365940 lmp.py:372]   Expert 40 |     60 | CPU
DEBUG 01-05 09:19:52.365106.365106 lmp.py:372]   Expert 38 |     63 | CPU
DEBUG 01-05 09:19:52.365033.365033 lmp.py:372]   Expert 55 |     67 | CPU
DEBUG 01-05 09:19:52.365200.365200 lmp.py:372]   Expert 32 |     77 | CPU
DEBUG 01-05 09:19:52.365512.365512 lmp.py:372]   Expert  0 |     96 | CPU
DEBUG 01-05 09:19:52.365439.365439 lmp.py:372]   Expert 44 |     97 | CPU
DEBUG 01-05 09:19:52.365413.365413 lmp.py:372]   Expert 18 |    102 | CPU
DEBUG 01-05 09:19:52.365626.365626 lmp.py:372]   Expert 60 |    103 | CPU
DEBUG 01-05 09:19:52.365361.365361 lmp.py:372]   Expert 35 |    107 | CPU
DEBUG 01-05 09:19:52.365335.365335 lmp.py:372]   Expert 43 |    109 | CPU
DEBUG 01-05 09:19:52.365170.365170 lmp.py:372]   Expert 23 |    113 | CPU
DEBUG 01-05 09:19:52.365860.365860 lmp.py:372]   Expert 39 |    114 | CPU
DEBUG 01-05 09:19:52.365834.365834 lmp.py:372]   Expert 28 |    118 | CPU
DEBUG 01-05 09:19:52.365569.365569 lmp.py:372]   Expert 29 |    119 | CPU
DEBUG 01-05 09:19:52.365259.365259 lmp.py:372]   Expert 51 |    121 | CPU
DEBUG 01-05 09:19:52.365710.365710 lmp.py:372]   Expert 20 |    122 | CPU
DEBUG 01-05 09:19:52.365545.365545 lmp.py:372]   Expert  8 |    123 | CPU
DEBUG 01-05 09:19:52.365234.365234 lmp.py:372]   Expert 17 |    124 | CPU
DEBUG 01-05 09:19:52.365923.365923 lmp.py:372]   Expert 54 |    130 | CPU
DEBUG 01-05 09:19:52.365897.365897 lmp.py:372]   Expert 41 |    132 | CPU
DEBUG 01-05 09:19:52.365110.365110 lmp.py:372]   Expert 21 |    137 | CPU
DEBUG 01-05 09:19:52.365799.365799 lmp.py:372]   Expert 12 |    145 | CPU
DEBUG 01-05 09:19:52.365396.365396 lmp.py:372]   Expert 52 |    163 | CPU
DEBUG 01-05 09:19:52.365370.365370 lmp.py:372]   Expert 45 |    176 | CPU
DEBUG 01-05 09:19:52.365344.365344 lmp.py:372]   Expert 57 |    181 | CPU
DEBUG 01-05 09:19:52.365795.365795 lmp.py:372]   Expert 42 |    182 | GPU
DEBUG 01-05 09:19:52.365530.365530 lmp.py:372]   Expert 62 |    193 | GPU
DEBUG 01-05 09:19:52.365743.365743 lmp.py:372]   Expert  6 |    197 | GPU
DEBUG 01-05 09:19:52.365101.365101 lmp.py:372]   Expert 30 |    212 | GPU
DEBUG 01-05 09:19:52.365790.365790 lmp.py:372]   Expert 13 |    213 | GPU
DEBUG 01-05 09:19:52.365241.365241 lmp.py:372]   Expert  3 |    214 | GPU
DEBUG 01-05 09:19:52.365646.365646 lmp.py:372]   Expert 31 |    216 | GPU
DEBUG 01-05 09:19:52.365335.365335 lmp.py:372]   Expert 11 |    233 | GPU
DEBUG 01-05 09:19:52.365693.365693 lmp.py:372]   Expert 36 |    233 | GPU
DEBUG 01-05 09:19:52.365621.365621 lmp.py:372]   Expert 26 |    237 | GPU
DEBUG 01-05 09:19:52.365833.365833 lmp.py:372]   Expert 46 |    238 | GPU
DEBUG 01-05 09:19:52.365808.365808 lmp.py:372]   Expert 19 |    240 | GPU
DEBUG 01-05 09:19:52.365020.365020 lmp.py:372]   Expert 14 |    244 | GPU
DEBUG 01-05 09:19:52.365232.365232 lmp.py:372]   Expert 27 |    252 | GPU
DEBUG 01-05 09:19:52.365114.365114 lmp.py:372]   Expert  2 |    267 | GPU
DEBUG 01-05 09:19:52.365803.365803 lmp.py:372]   Expert 22 |    267 | GPU
DEBUG 01-05 09:19:52.365777.365777 lmp.py:372]   Expert  4 |    271 | GPU
DEBUG 01-05 09:19:52.366705.366705 lmp.py:372]   Expert  5 |    286 | GPU
DEBUG 01-05 09:19:52.366394.366394 lmp.py:372]   Expert 16 |    288 | GPU
DEBUG 01-05 09:19:52.366322.366322 lmp.py:372]   Expert 33 |    295 | GPU
DEBUG 01-05 09:19:52.366250.366250 lmp.py:372]   Expert 56 |    295 | GPU
DEBUG 01-05 09:19:52.366654.366654 lmp.py:372]   Expert  1 |    299 | GPU
DEBUG 01-05 09:19:52.366774.366774 lmp.py:372]   Expert 37 |    299 | GPU
DEBUG 01-05 09:19:52.366702.366702 lmp.py:372]   Expert 53 |    312 | GPU
DEBUG 01-05 09:19:52.366676.366676 lmp.py:372]   Expert 58 |    314 | GPU
DEBUG 01-05 09:19:52.366888.366888 lmp.py:372]   Expert 47 |    357 | GPU
DEBUG 01-05 09:19:52.366578.366578 lmp.py:372]   Expert 10 |    360 | GPU
DEBUG 01-05 09:19:52.366028.366028 lmp.py:372]   Expert 63 |    363 | GPU
DEBUG 01-05 09:19:52.366387.366387 lmp.py:372]   Expert 15 |    374 | GPU
DEBUG 01-05 09:19:52.366553.366553 lmp.py:372]   Expert 24 |    383 | GPU
DEBUG 01-05 09:19:52.366242.366242 lmp.py:372]   Expert 25 |    469 | GPU
DEBUG 01-05 09:19:52.366647.366647 lmp.py:372]   Expert  9 |    502 | GPU
DEBUG 01-05 09:19:52.366528.366528 lmp.py:373] 
DEBUG 01-05 09:19:52.366528.366528 lmp.py:373]   CPU total tokens: 3183 (25.9%)
DEBUG 01-05 09:19:52.366648.366648 lmp.py:374]   GPU total tokens: 9105 (74.1%)
DEBUG 01-05 09:19:52.366251.366251 cuda_h.py:19] end experts_map_get cost 0.0015404224395751953 seconds
DEBUG 01-05 09:19:52.366610.366610 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.366677.366677 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.366199.366199 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.366049.366049 cuda_h.py:19] end allocate_cuda_memory cost 0.0002396106719970703 seconds
DEBUG 01-05 09:19:52.366230.366230 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.366509.366509 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.366272.366272 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.366114.366114 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dd26b7ef-0f8d-42d5-9417-8b9222c2905f
DEBUG 01-05 09:19:52.367094.367094 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.368297.368297 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dd26b7ef-0f8d-42d5-9417-8b9222c2905f
DEBUG 01-05 09:19:52.368703.368703 cuda_h.py:19] end load_into_gpu_async cost 0.0020380020141601562 seconds
DEBUG 01-05 09:19:52.368691.368691 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.369863.369863 cuda_h.py:19] end restore_tensors2 cost 0.0003814697265625 seconds
DEBUG 01-05 09:19:52.369461.369461 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00301361083984375 seconds
DEBUG 01-05 09:19:52.372596.372596 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005682706832885742 seconds
DEBUG 01-05 09:19:52.372499.372499 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.372031.372031 lmp.py:419] 
DEBUG 01-05 09:19:52.372031.372031 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.372973.372973 cuda_h.py:19] end cpu_experts_submit cost 0.00011229515075683594 seconds
DEBUG 01-05 09:19:52.372862.372862 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.381405.381405 mlpmodule.py:704] group tensors cost 0.00880742073059082 s
DEBUG 01-05 09:19:52.384453.384453 mlpmodule.py:742] pad cost 0.0016798973083496094 s
DEBUG 01-05 09:19:52.384226.384226 mlpmodule.py:748] create cpu tensor cost 6.67572021484375e-05 s
DEBUG 01-05 09:19:52.384216.384216 mlpmodule.py:753] move to cpu cost 5.936622619628906e-05 s
DEBUG 01-05 09:19:52.396795.396795 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.396371.396371 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.397845.397845 mlpmodule.py:773] group_w3 first element: 0.000789642333984375
WARNING 01-05 09:19:52.397465.397465 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.414520.414520 mlpmodule.py:793] group einsum cost 0.02994513511657715 s
DEBUG 01-05 09:19:52.415650.415650 mlpmodule.py:801] cpy2cputensor cost 0.0008881092071533203 s
DEBUG 01-05 09:19:52.453037.453037 cuda_h.py:19] end wait_cetm_experts cost 0.08070826530456543 seconds
DEBUG 01-05 09:19:52.453182.453182 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.453461.453461 cuda_h.py:19] end gpu_sexperts cost 0.0005822181701660156 seconds
DEBUG 01-05 09:19:52.453172.453172 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:19:52.453657.453657 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-05 09:19:52.454381.454381 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.933906555175781e-05 seconds
DEBUG 01-05 09:19:52.454237.454237 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 8.153915405273438e-05 seconds
DEBUG 01-05 09:19:52.454270.454270 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.454265.454265 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dd26b7ef-0f8d-42d5-9417-8b9222c2905f
DEBUG 01-05 09:19:52.454880.454880 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.454016.454016 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.454720.454720 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.459459.459459 cuda_h.py:19] end allocate_cuda_memory cost 0.00481867790222168 seconds
DEBUG 01-05 09:19:52.459899.459899 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.459960.459960 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.459604.459604 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.459552.459552 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 572da0e8-1393-4e08-a8e1-15457dbbfc83
DEBUG 01-05 09:19:52.459734.459734 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.459635.459635 client.py:127] Model loaded
DEBUG 01-05 09:19:52.459253.459253 cuda_h.py:19] end wait_experts cost 0.005784273147583008 seconds
DEBUG 01-05 09:19:52.459817.459817 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.459096.459096 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:52.460232.460232 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 572da0e8-1393-4e08-a8e1-15457dbbfc83
DEBUG 01-05 09:19:52.460413.460413 cuda_h.py:19] end load_into_gpu_async cost 0.00128173828125 seconds
DEBUG 01-05 09:19:52.460977.460977 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.460378.460378 cuda_h.py:19] end restore_tensors2 cost 8.988380432128906e-05 seconds
DEBUG 01-05 09:19:52.460141.460141 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006484270095825195 seconds
DEBUG 01-05 09:19:52.461573.461573 mlpmodule.py:531] gpu group tensors cost 0.0011074542999267578 s
INFO 01-05 09:19:52.461756.461756 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 572da0e8-1393-4e08-a8e1-15457dbbfc83
DEBUG 01-05 09:19:52.463165.463165 mlpmodule.py:564] gpu pad cost 0.002070903778076172 s
DEBUG 01-05 09:19:52.464286.464286 mlpmodule.py:582] gpu group einsum cost 0.0005662441253662109 s
DEBUG 01-05 09:19:52.467340.467340 mlpmodule.py:611] gpu experts func einsum cost 0.007399082183837891 s
DEBUG 01-05 09:19:52.467761.467761 cuda_h.py:19] end gpu_experts cost 0.007585763931274414 seconds
DEBUG 01-05 09:19:52.467563.467563 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:52.469058.469058 client.py:127] Model loaded
DEBUG 01-05 09:19:52.469139.469139 cuda_h.py:19] end sllm_worker_task cost 0.015370607376098633 seconds
DEBUG 01-05 09:19:52.469844.469844 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002205371856689453 seconds
DEBUG 01-05 09:19:52.470512.470512 cuda_h.py:19] end layer_moe_generate_14 cost 0.10596990585327148 seconds
DEBUG 01-05 09:19:52.470132.470132 mlpmodule.py:662]  experts func einsum cost 0.09760355949401855 s
DEBUG 01-05 09:19:52.470209.470209 lmp.py:214] -------------------------------- end layer 14 --------------------------------
DEBUG 01-05 09:19:52.470609.470609 lmp.py:173] -------------------------------- start layer 15 --------------------------------
DEBUG 01-05 09:19:52.470974.470974 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.470805.470805 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.473613.473613 cuda_h.py:19] end self_attn cost 0.002500295639038086 seconds
DEBUG 01-05 09:19:52.473703.473703 cuda_h.py:19] end iln_self_attn_paln cost 0.003130674362182617 seconds
DEBUG 01-05 09:19:52.473592.473592 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-05 09:19:52.473401.473401 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.474423.474423 cuda_h.py:19] end gate cost 0.0006167888641357422 seconds
DEBUG 01-05 09:19:52.474299.474299 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.474666.474666 lmp.py:361] 
DEBUG 01-05 09:19:52.474666.474666 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.474853.474853 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.474980.474980 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.474007.474007 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.474888.474888 lmp.py:365] 
DEBUG 01-05 09:19:52.474888.474888 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.474293.474293 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.474135.474135 lmp.py:372]   Expert 63 |     14 | CPU
DEBUG 01-05 09:19:52.474923.474923 lmp.py:372]   Expert 48 |     50 | CPU
DEBUG 01-05 09:19:52.474328.474328 lmp.py:372]   Expert  4 |     54 | CPU
DEBUG 01-05 09:19:52.475302.475302 lmp.py:372]   Expert 37 |     55 | CPU
DEBUG 01-05 09:19:52.475514.475514 lmp.py:372]   Expert 42 |     56 | CPU
DEBUG 01-05 09:19:52.475488.475488 lmp.py:372]   Expert 34 |     57 | CPU
DEBUG 01-05 09:19:52.475701.475701 lmp.py:372]   Expert 22 |     76 | CPU
DEBUG 01-05 09:19:52.475582.475582 lmp.py:372]   Expert 57 |     76 | CPU
DEBUG 01-05 09:19:52.475033.475033 lmp.py:372]   Expert 53 |     77 | CPU
DEBUG 01-05 09:19:52.475484.475484 lmp.py:372]   Expert  5 |     78 | CPU
DEBUG 01-05 09:19:52.475220.475220 lmp.py:372]   Expert 15 |     79 | CPU
DEBUG 01-05 09:19:52.475194.475194 lmp.py:372]   Expert 51 |     80 | CPU
DEBUG 01-05 09:19:52.475929.475929 lmp.py:372]   Expert 28 |     82 | CPU
DEBUG 01-05 09:19:52.475526.475526 lmp.py:372]   Expert 40 |     82 | CPU
DEBUG 01-05 09:19:52.475692.475692 lmp.py:372]   Expert 43 |     91 | CPU
DEBUG 01-05 09:19:52.475620.475620 lmp.py:372]   Expert 41 |     93 | CPU
DEBUG 01-05 09:19:52.475786.475786 lmp.py:372]   Expert  7 |    119 | CPU
DEBUG 01-05 09:19:52.475714.475714 lmp.py:372]   Expert 29 |    125 | CPU
DEBUG 01-05 09:19:52.475310.475310 lmp.py:372]   Expert 32 |    127 | CPU
DEBUG 01-05 09:19:52.475000.475000 lmp.py:372]   Expert 55 |    127 | CPU
DEBUG 01-05 09:19:52.475212.475212 lmp.py:372]   Expert 52 |    138 | CPU
DEBUG 01-05 09:19:52.475186.475186 lmp.py:372]   Expert  6 |    140 | CPU
DEBUG 01-05 09:19:52.475922.475922 lmp.py:372]   Expert 56 |    152 | CPU
DEBUG 01-05 09:19:52.475896.475896 lmp.py:372]   Expert  2 |    153 | CPU
DEBUG 01-05 09:19:52.475777.475777 lmp.py:372]   Expert 61 |    156 | CPU
DEBUG 01-05 09:19:52.475467.475467 lmp.py:372]   Expert 25 |    158 | CPU
DEBUG 01-05 09:19:52.475156.475156 lmp.py:372]   Expert 44 |    158 | CPU
DEBUG 01-05 09:19:52.475084.475084 lmp.py:372]   Expert 50 |    160 | CPU
DEBUG 01-05 09:19:52.475250.475250 lmp.py:372]   Expert 14 |    162 | CPU
DEBUG 01-05 09:19:52.475939.475939 lmp.py:372]   Expert 33 |    164 | CPU
DEBUG 01-05 09:19:52.475151.475151 lmp.py:372]   Expert 54 |    172 | CPU
DEBUG 01-05 09:19:52.475748.475748 lmp.py:372]   Expert 12 |    185 | CPU
DEBUG 01-05 09:19:52.475961.475961 lmp.py:372]   Expert 35 |    196 | GPU
DEBUG 01-05 09:19:52.475696.475696 lmp.py:372]   Expert 39 |    202 | GPU
DEBUG 01-05 09:19:52.475432.475432 lmp.py:372]   Expert 58 |    204 | GPU
DEBUG 01-05 09:19:52.475406.475406 lmp.py:372]   Expert 62 |    209 | GPU
DEBUG 01-05 09:19:52.475141.475141 lmp.py:372]   Expert 20 |    210 | GPU
DEBUG 01-05 09:19:52.475500.475500 lmp.py:372]   Expert 31 |    216 | GPU
DEBUG 01-05 09:19:52.475189.475189 lmp.py:372]   Expert 11 |    217 | GPU
DEBUG 01-05 09:19:52.475355.475355 lmp.py:372]   Expert 23 |    226 | GPU
DEBUG 01-05 09:19:52.475521.475521 lmp.py:372]   Expert 47 |    226 | GPU
DEBUG 01-05 09:19:52.475211.475211 lmp.py:372]   Expert 59 |    226 | GPU
DEBUG 01-05 09:19:52.475138.475138 lmp.py:372]   Expert 10 |    227 | GPU
DEBUG 01-05 09:19:52.475543.475543 lmp.py:372]   Expert  1 |    230 | GPU
DEBUG 01-05 09:19:52.475947.475947 lmp.py:372]   Expert 13 |    232 | GPU
DEBUG 01-05 09:19:52.475160.475160 lmp.py:372]   Expert 45 |    242 | GPU
DEBUG 01-05 09:19:52.475895.475895 lmp.py:372]   Expert 24 |    250 | GPU
DEBUG 01-05 09:19:52.475631.475631 lmp.py:372]   Expert 36 |    250 | GPU
DEBUG 01-05 09:19:52.475605.475605 lmp.py:372]   Expert 38 |    252 | GPU
DEBUG 01-05 09:19:52.475010.475010 lmp.py:372]   Expert  0 |    253 | GPU
DEBUG 01-05 09:19:52.475937.475937 lmp.py:372]   Expert  9 |    259 | GPU
DEBUG 01-05 09:19:52.475819.475819 lmp.py:372]   Expert 18 |    274 | GPU
DEBUG 01-05 09:19:52.475223.475223 lmp.py:372]   Expert 46 |    276 | GPU
DEBUG 01-05 09:19:52.475628.475628 lmp.py:372]   Expert 16 |    295 | GPU
DEBUG 01-05 09:19:52.475317.475317 lmp.py:372]   Expert 60 |    295 | GPU
DEBUG 01-05 09:19:52.475768.475768 lmp.py:372]   Expert 19 |    303 | GPU
DEBUG 01-05 09:19:52.475888.475888 lmp.py:372]   Expert 49 |    312 | GPU
DEBUG 01-05 09:19:52.475339.475339 lmp.py:372]   Expert  3 |    314 | GPU
DEBUG 01-05 09:19:52.475074.475074 lmp.py:372]   Expert 30 |    317 | GPU
DEBUG 01-05 09:19:52.475048.475048 lmp.py:372]   Expert 26 |    337 | GPU
DEBUG 01-05 09:19:52.475023.475023 lmp.py:372]   Expert 27 |    351 | GPU
DEBUG 01-05 09:19:52.475758.475758 lmp.py:372]   Expert 21 |    356 | GPU
DEBUG 01-05 09:19:52.475640.475640 lmp.py:372]   Expert 17 |    373 | GPU
DEBUG 01-05 09:19:52.476090.476090 lmp.py:372]   Expert  8 |    662 | GPU
DEBUG 01-05 09:19:52.476257.476257 lmp.py:373] 
DEBUG 01-05 09:19:52.476257.476257 lmp.py:373]   CPU total tokens: 3496 (28.5%)
DEBUG 01-05 09:19:52.476661.476661 lmp.py:374]   GPU total tokens: 8792 (71.5%)
DEBUG 01-05 09:19:52.476072.476072 cuda_h.py:19] end experts_map_get cost 0.0015254020690917969 seconds
DEBUG 01-05 09:19:52.476431.476431 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.476452.476452 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.476311.476311 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.476810.476810 cuda_h.py:19] end allocate_cuda_memory cost 0.00022864341735839844 seconds
DEBUG 01-05 09:19:52.476037.476037 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.476886.476886 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.476603.476603 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.476206.476206 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cda0a5e0-6fcf-4cc6-be4a-72124a514613
DEBUG 01-05 09:19:52.476756.476756 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.478840.478840 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cda0a5e0-6fcf-4cc6-be4a-72124a514613
DEBUG 01-05 09:19:52.478769.478769 cuda_h.py:19] end load_into_gpu_async cost 0.0018427371978759766 seconds
DEBUG 01-05 09:19:52.478803.478803 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.478168.478168 cuda_h.py:19] end restore_tensors2 cost 0.00038242340087890625 seconds
DEBUG 01-05 09:19:52.478481.478481 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002805471420288086 seconds
DEBUG 01-05 09:19:52.481378.481378 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005516767501831055 seconds
DEBUG 01-05 09:19:52.481538.481538 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.481376.481376 lmp.py:419] 
DEBUG 01-05 09:19:52.481376.481376 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.481173.481173 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-05 09:19:52.481299.481299 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.495128.495128 mlpmodule.py:704] group tensors cost 0.013044595718383789 s
DEBUG 01-05 09:19:52.497606.497606 mlpmodule.py:742] pad cost 0.0016944408416748047 s
DEBUG 01-05 09:19:52.497988.497988 mlpmodule.py:748] create cpu tensor cost 7.414817810058594e-05 s
DEBUG 01-05 09:19:52.497083.497083 mlpmodule.py:753] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-05 09:19:52.510069.510069 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.510936.510936 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.510721.510721 mlpmodule.py:773] group_w3 first element: 0.0157470703125
WARNING 01-05 09:19:52.510124.510124 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.528057.528057 mlpmodule.py:793] group einsum cost 0.030588865280151367 s
DEBUG 01-05 09:19:52.529109.529109 mlpmodule.py:801] cpy2cputensor cost 0.0009481906890869141 s
DEBUG 01-05 09:19:52.565455.565455 cuda_h.py:19] end wait_cetm_experts cost 0.08329129219055176 seconds
DEBUG 01-05 09:19:52.565547.565547 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.566389.566389 cuda_h.py:19] end gpu_sexperts cost 0.0005769729614257812 seconds
DEBUG 01-05 09:19:52.566139.566139 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:19:52.566869.566869 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-05 09:19:52.566071.566071 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.886222839355469e-05 seconds
DEBUG 01-05 09:19:52.566403.566403 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 8.130073547363281e-05 seconds
DEBUG 01-05 09:19:52.566483.566483 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.566193.566193 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cda0a5e0-6fcf-4cc6-be4a-72124a514613
DEBUG 01-05 09:19:52.566569.566569 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.566944.566944 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.566886.566886 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.570419.570419 cuda_h.py:19] end allocate_cuda_memory cost 0.004212617874145508 seconds
DEBUG 01-05 09:19:52.570236.570236 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.570622.570622 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.571697.571697 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.571929.571929 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9ad2d132-5abe-4bbd-aad1-75412c316335
DEBUG 01-05 09:19:52.571966.571966 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.571390.571390 client.py:127] Model loaded
DEBUG 01-05 09:19:52.571054.571054 cuda_h.py:19] end wait_experts cost 0.0051653385162353516 seconds
DEBUG 01-05 09:19:52.571572.571572 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.571328.571328 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:52.572160.572160 mlpmodule.py:531] gpu group tensors cost 0.0006346702575683594 s
INFO 01-05 09:19:52.572012.572012 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9ad2d132-5abe-4bbd-aad1-75412c316335
DEBUG 01-05 09:19:52.572551.572551 cuda_h.py:19] end load_into_gpu_async cost 0.0014567375183105469 seconds
DEBUG 01-05 09:19:52.572400.572400 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.572225.572225 cuda_h.py:19] end restore_tensors2 cost 8.702278137207031e-05 seconds
DEBUG 01-05 09:19:52.572273.572273 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006037473678588867 seconds
INFO 01-05 09:19:52.573241.573241 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9ad2d132-5abe-4bbd-aad1-75412c316335
DEBUG 01-05 09:19:52.574330.574330 mlpmodule.py:564] gpu pad cost 0.002631664276123047 s
DEBUG 01-05 09:19:52.575478.575478 mlpmodule.py:582] gpu group einsum cost 0.0005714893341064453 s
DEBUG 01-05 09:19:52.579676.579676 mlpmodule.py:611] gpu experts func einsum cost 0.007546663284301758 s
DEBUG 01-05 09:19:52.579894.579894 cuda_h.py:19] end gpu_experts cost 0.007792472839355469 seconds
DEBUG 01-05 09:19:52.579173.579173 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:52.581830.581830 mlpmodule.py:662]  experts func einsum cost 0.09988832473754883 s
INFO 01-05 09:19:52.582320.582320 client.py:127] Model loaded
DEBUG 01-05 09:19:52.582623.582623 cuda_h.py:19] end sllm_worker_task cost 0.015741586685180664 seconds
DEBUG 01-05 09:19:52.582533.582533 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0030066967010498047 seconds
DEBUG 01-05 09:19:52.582942.582942 cuda_h.py:19] end layer_moe_generate_15 cost 0.10872316360473633 seconds
DEBUG 01-05 09:19:52.582605.582605 lmp.py:214] -------------------------------- end layer 15 --------------------------------
DEBUG 01-05 09:19:52.582798.582798 lmp.py:173] -------------------------------- start layer 16 --------------------------------
DEBUG 01-05 09:19:52.582256.582256 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.583828.583828 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.585192.585192 cuda_h.py:19] end self_attn cost 0.00249481201171875 seconds
DEBUG 01-05 09:19:52.585380.585380 cuda_h.py:19] end iln_self_attn_paln cost 0.003081798553466797 seconds
DEBUG 01-05 09:19:52.585216.585216 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-05 09:19:52.586263.586263 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.586152.586152 cuda_h.py:19] end gate cost 0.0005850791931152344 seconds
DEBUG 01-05 09:19:52.586981.586981 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.586534.586534 lmp.py:361] 
DEBUG 01-05 09:19:52.586534.586534 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.587721.587721 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.587655.587655 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.587206.587206 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.587756.587756 lmp.py:365] 
DEBUG 01-05 09:19:52.587756.587756 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.587922.587922 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.587618.587618 lmp.py:372]   Expert 58 |     17 | CPU
DEBUG 01-05 09:19:52.587546.587546 lmp.py:372]   Expert 43 |     66 | CPU
DEBUG 01-05 09:19:52.587759.587759 lmp.py:372]   Expert 14 |     73 | CPU
DEBUG 01-05 09:19:52.587402.587402 lmp.py:372]   Expert 54 |     77 | CPU
DEBUG 01-05 09:19:52.587091.587091 lmp.py:372]   Expert 13 |     78 | CPU
DEBUG 01-05 09:19:52.587495.587495 lmp.py:372]   Expert 45 |     91 | CPU
DEBUG 01-05 09:19:52.587185.587185 lmp.py:372]   Expert 11 |     92 | CPU
DEBUG 01-05 09:19:52.587636.587636 lmp.py:372]   Expert 39 |     99 | CPU
DEBUG 01-05 09:19:52.587325.587325 lmp.py:372]   Expert 59 |     99 | CPU
DEBUG 01-05 09:19:52.587014.587014 lmp.py:372]   Expert 60 |    100 | CPU
DEBUG 01-05 09:19:52.587134.587134 lmp.py:372]   Expert  6 |    101 | CPU
DEBUG 01-05 09:19:52.587346.587346 lmp.py:372]   Expert 18 |    110 | CPU
DEBUG 01-05 09:19:52.587844.587844 lmp.py:372]   Expert 34 |    111 | CPU
DEBUG 01-05 09:19:52.587341.587341 lmp.py:372]   Expert 61 |    115 | CPU
DEBUG 01-05 09:19:52.587600.587600 lmp.py:372]   Expert 49 |    120 | CPU
DEBUG 01-05 09:19:52.587335.587335 lmp.py:372]   Expert 28 |    122 | CPU
DEBUG 01-05 09:19:52.587978.587978 lmp.py:372]   Expert 25 |    123 | CPU
DEBUG 01-05 09:19:52.587714.587714 lmp.py:372]   Expert 57 |    127 | CPU
DEBUG 01-05 09:19:52.587688.587688 lmp.py:372]   Expert 62 |    127 | CPU
DEBUG 01-05 09:19:52.587139.587139 lmp.py:372]   Expert 32 |    129 | CPU
DEBUG 01-05 09:19:52.587351.587351 lmp.py:372]   Expert 35 |    131 | CPU
DEBUG 01-05 09:19:52.587279.587279 lmp.py:372]   Expert  0 |    139 | CPU
DEBUG 01-05 09:19:52.587491.587491 lmp.py:372]   Expert 41 |    139 | CPU
DEBUG 01-05 09:19:52.587373.587373 lmp.py:372]   Expert 50 |    143 | CPU
DEBUG 01-05 09:19:52.587347.587347 lmp.py:372]   Expert 15 |    145 | CPU
DEBUG 01-05 09:19:52.587606.587606 lmp.py:372]   Expert 30 |    145 | CPU
DEBUG 01-05 09:19:52.587103.587103 lmp.py:372]   Expert 51 |    149 | CPU
DEBUG 01-05 09:19:52.587362.587362 lmp.py:372]   Expert 12 |    161 | CPU
DEBUG 01-05 09:19:52.587620.587620 lmp.py:372]   Expert 38 |    163 | CPU
DEBUG 01-05 09:19:52.587548.587548 lmp.py:372]   Expert 37 |    167 | CPU
DEBUG 01-05 09:19:52.587761.587761 lmp.py:372]   Expert 42 |    175 | CPU
DEBUG 01-05 09:19:52.587019.587019 lmp.py:372]   Expert 56 |    175 | CPU
DEBUG 01-05 09:19:52.587993.587993 lmp.py:372]   Expert 31 |    183 | GPU
DEBUG 01-05 09:19:52.587444.587444 lmp.py:372]   Expert 63 |    184 | GPU
DEBUG 01-05 09:19:52.587657.587657 lmp.py:372]   Expert 26 |    193 | GPU
DEBUG 01-05 09:19:52.587346.587346 lmp.py:372]   Expert 44 |    195 | GPU
DEBUG 01-05 09:19:52.587035.587035 lmp.py:372]   Expert 10 |    197 | GPU
DEBUG 01-05 09:19:52.587678.587678 lmp.py:372]   Expert  3 |    201 | GPU
DEBUG 01-05 09:19:52.587891.587891 lmp.py:372]   Expert 40 |    204 | GPU
DEBUG 01-05 09:19:52.587388.587388 lmp.py:372]   Expert 48 |    210 | GPU
DEBUG 01-05 09:19:52.587124.587124 lmp.py:372]   Expert 21 |    215 | GPU
DEBUG 01-05 09:19:52.587621.587621 lmp.py:372]   Expert 55 |    217 | GPU
DEBUG 01-05 09:19:52.587118.587118 lmp.py:372]   Expert 33 |    224 | GPU
DEBUG 01-05 09:19:52.587284.587284 lmp.py:372]   Expert 36 |    229 | GPU
DEBUG 01-05 09:19:52.587020.587020 lmp.py:372]   Expert 47 |    230 | GPU
DEBUG 01-05 09:19:52.587232.587232 lmp.py:372]   Expert 16 |    235 | GPU
DEBUG 01-05 09:19:52.587491.587491 lmp.py:372]   Expert  1 |    239 | GPU
DEBUG 01-05 09:19:52.587419.587419 lmp.py:372]   Expert  9 |    239 | GPU
DEBUG 01-05 09:19:52.587108.587108 lmp.py:372]   Expert 19 |    242 | GPU
DEBUG 01-05 09:19:52.587797.587797 lmp.py:372]   Expert 46 |    249 | GPU
DEBUG 01-05 09:19:52.587248.587248 lmp.py:372]   Expert  2 |    255 | GPU
DEBUG 01-05 09:19:52.587176.587176 lmp.py:372]   Expert 24 |    261 | GPU
DEBUG 01-05 09:19:52.587104.587104 lmp.py:372]   Expert  7 |    277 | GPU
DEBUG 01-05 09:19:52.587270.587270 lmp.py:372]   Expert 22 |    278 | GPU
DEBUG 01-05 09:19:52.587006.587006 lmp.py:372]   Expert 53 |    278 | GPU
DEBUG 01-05 09:19:52.588503.588503 lmp.py:372]   Expert  8 |    279 | GPU
DEBUG 01-05 09:19:52.588238.588238 lmp.py:372]   Expert 20 |    281 | GPU
DEBUG 01-05 09:19:52.588974.588974 lmp.py:372]   Expert 29 |    313 | GPU
DEBUG 01-05 09:19:52.588948.588948 lmp.py:372]   Expert  4 |    342 | GPU
DEBUG 01-05 09:19:52.588876.588876 lmp.py:372]   Expert 17 |    344 | GPU
DEBUG 01-05 09:19:52.588088.588088 lmp.py:372]   Expert 23 |    383 | GPU
DEBUG 01-05 09:19:52.588016.588016 lmp.py:372]   Expert 27 |    426 | GPU
DEBUG 01-05 09:19:52.588705.588705 lmp.py:372]   Expert 52 |    431 | GPU
DEBUG 01-05 09:19:52.588633.588633 lmp.py:372]   Expert  5 |    445 | GPU
DEBUG 01-05 09:19:52.588037.588037 lmp.py:373] 
DEBUG 01-05 09:19:52.588037.588037 lmp.py:373]   CPU total tokens: 3809 (31.0%)
DEBUG 01-05 09:19:52.588634.588634 lmp.py:374]   GPU total tokens: 8479 (69.0%)
DEBUG 01-05 09:19:52.588330.588330 cuda_h.py:19] end experts_map_get cost 0.0014934539794921875 seconds
DEBUG 01-05 09:19:52.588258.588258 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.588895.588895 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.588497.588497 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.588579.588579 cuda_h.py:19] end allocate_cuda_memory cost 0.00023031234741210938 seconds
DEBUG 01-05 09:19:52.588667.588667 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.588754.588754 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.588232.588232 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.588266.588266 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 551b23a7-18e5-4609-979c-1a1701dfc425
DEBUG 01-05 09:19:52.589822.589822 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.590887.590887 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 551b23a7-18e5-4609-979c-1a1701dfc425
DEBUG 01-05 09:19:52.590862.590862 cuda_h.py:19] end load_into_gpu_async cost 0.001447916030883789 seconds
DEBUG 01-05 09:19:52.590611.590611 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.590697.590697 cuda_h.py:19] end restore_tensors2 cost 0.00035262107849121094 seconds
DEBUG 01-05 09:19:52.590772.590772 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024137496948242188 seconds
DEBUG 01-05 09:19:52.593200.593200 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005162239074707031 seconds
DEBUG 01-05 09:19:52.593321.593321 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.593999.593999 lmp.py:419] 
DEBUG 01-05 09:19:52.593999.593999 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.593657.593657 cuda_h.py:19] end cpu_experts_submit cost 0.00011157989501953125 seconds
DEBUG 01-05 09:19:52.593545.593545 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.606834.606834 mlpmodule.py:704] group tensors cost 0.012764453887939453 s
DEBUG 01-05 09:19:52.609988.609988 mlpmodule.py:742] pad cost 0.0016837120056152344 s
DEBUG 01-05 09:19:52.609720.609720 mlpmodule.py:748] create cpu tensor cost 5.2928924560546875e-05 s
DEBUG 01-05 09:19:52.609869.609869 mlpmodule.py:753] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-05 09:19:52.621887.621887 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.621251.621251 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.621963.621963 mlpmodule.py:773] group_w3 first element: -0.02490234375
WARNING 01-05 09:19:52.621100.621100 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.639478.639478 mlpmodule.py:793] group einsum cost 0.030175209045410156 s
DEBUG 01-05 09:19:52.640487.640487 mlpmodule.py:801] cpy2cputensor cost 0.0008366107940673828 s
DEBUG 01-05 09:19:52.677643.677643 cuda_h.py:19] end wait_cetm_experts cost 0.08335351943969727 seconds
DEBUG 01-05 09:19:52.677159.677159 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.677478.677478 cuda_h.py:19] end gpu_sexperts cost 0.0005767345428466797 seconds
DEBUG 01-05 09:19:52.677381.677381 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:19:52.677634.677634 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-05 09:19:52.678597.678597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.910064697265625e-05 seconds
DEBUG 01-05 09:19:52.678214.678214 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 8.106231689453125e-05 seconds
DEBUG 01-05 09:19:52.678532.678532 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.678242.678242 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 551b23a7-18e5-4609-979c-1a1701dfc425
DEBUG 01-05 09:19:52.678003.678003 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.678900.678900 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.678412.678412 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.682454.682454 cuda_h.py:19] end allocate_cuda_memory cost 0.004168033599853516 seconds
DEBUG 01-05 09:19:52.682225.682225 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.682848.682848 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.682446.682446 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.682871.682871 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d8075a5e-63e5-4c7e-882d-a71d64460b80
DEBUG 01-05 09:19:52.682292.682292 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.683385.683385 client.py:127] Model loaded
DEBUG 01-05 09:19:52.683718.683718 cuda_h.py:19] end wait_experts cost 0.005126953125 seconds
DEBUG 01-05 09:19:52.683759.683759 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.683800.683800 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:52.684798.684798 mlpmodule.py:531] gpu group tensors cost 0.000652313232421875 s
INFO 01-05 09:19:52.684450.684450 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d8075a5e-63e5-4c7e-882d-a71d64460b80
DEBUG 01-05 09:19:52.684911.684911 cuda_h.py:19] end load_into_gpu_async cost 0.0014851093292236328 seconds
DEBUG 01-05 09:19:52.684383.684383 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.684751.684751 cuda_h.py:19] end restore_tensors2 cost 0.00010323524475097656 seconds
DEBUG 01-05 09:19:52.684421.684421 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006039619445800781 seconds
INFO 01-05 09:19:52.685946.685946 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d8075a5e-63e5-4c7e-882d-a71d64460b80
DEBUG 01-05 09:19:52.686876.686876 mlpmodule.py:564] gpu pad cost 0.0025627613067626953 s
DEBUG 01-05 09:19:52.687362.687362 mlpmodule.py:582] gpu group einsum cost 0.0005824565887451172 s
DEBUG 01-05 09:19:52.691118.691118 mlpmodule.py:611] gpu experts func einsum cost 0.007628917694091797 s
DEBUG 01-05 09:19:52.691300.691300 cuda_h.py:19] end gpu_experts cost 0.007814407348632812 seconds
DEBUG 01-05 09:19:52.691486.691486 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:52.692293.692293 client.py:127] Model loaded
DEBUG 01-05 09:19:52.692567.692567 cuda_h.py:19] end sllm_worker_task cost 0.014577388763427734 seconds
DEBUG 01-05 09:19:52.693933.693933 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0018410682678222656 seconds
DEBUG 01-05 09:19:52.693859.693859 cuda_h.py:19] end layer_moe_generate_16 cost 0.10718512535095215 seconds
DEBUG 01-05 09:19:52.693137.693137 lmp.py:214] -------------------------------- end layer 16 --------------------------------
DEBUG 01-05 09:19:52.693821.693821 lmp.py:173] -------------------------------- start layer 17 --------------------------------
DEBUG 01-05 09:19:52.693663.693663 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.693993.693993 mlpmodule.py:662]  experts func einsum cost 0.09980607032775879 s
DEBUG 01-05 09:19:52.693733.693733 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.696925.696925 cuda_h.py:19] end self_attn cost 0.0024640560150146484 seconds
DEBUG 01-05 09:19:52.696372.696372 cuda_h.py:19] end iln_self_attn_paln cost 0.0033347606658935547 seconds
DEBUG 01-05 09:19:52.696976.696976 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-05 09:19:52.696123.696123 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.697144.697144 cuda_h.py:19] end gate cost 0.0005781650543212891 seconds
DEBUG 01-05 09:19:52.697496.697496 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.697255.697255 lmp.py:361] 
DEBUG 01-05 09:19:52.697255.697255 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.697680.697680 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.697045.697045 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.697311.697311 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.697477.697477 lmp.py:365] 
DEBUG 01-05 09:19:52.697477.697477 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.698405.698405 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.698770.698770 lmp.py:372]   Expert 39 |     42 | CPU
DEBUG 01-05 09:19:52.698750.698750 lmp.py:372]   Expert 28 |     57 | CPU
DEBUG 01-05 09:19:52.698440.698440 lmp.py:372]   Expert 47 |     60 | CPU
DEBUG 01-05 09:19:52.698129.698129 lmp.py:372]   Expert 14 |     62 | CPU
DEBUG 01-05 09:19:52.698580.698580 lmp.py:372]   Expert  1 |     72 | CPU
DEBUG 01-05 09:19:52.698554.698554 lmp.py:372]   Expert 36 |     73 | CPU
DEBUG 01-05 09:19:52.698959.698959 lmp.py:372]   Expert  7 |     82 | CPU
DEBUG 01-05 09:19:52.698886.698886 lmp.py:372]   Expert 40 |     84 | CPU
DEBUG 01-05 09:19:52.698052.698052 lmp.py:372]   Expert 27 |     91 | CPU
DEBUG 01-05 09:19:52.698980.698980 lmp.py:372]   Expert 52 |     93 | CPU
DEBUG 01-05 09:19:52.698669.698669 lmp.py:372]   Expert 25 |     94 | CPU
DEBUG 01-05 09:19:52.698120.698120 lmp.py:372]   Expert  8 |    100 | CPU
DEBUG 01-05 09:19:52.698048.698048 lmp.py:372]   Expert 31 |    116 | CPU
DEBUG 01-05 09:19:52.698406.698406 lmp.py:372]   Expert 54 |    116 | CPU
DEBUG 01-05 09:19:52.698857.698857 lmp.py:372]   Expert  3 |    124 | CPU
DEBUG 01-05 09:19:52.698831.698831 lmp.py:372]   Expert 60 |    125 | CPU
DEBUG 01-05 09:19:52.698328.698328 lmp.py:372]   Expert 46 |    136 | CPU
DEBUG 01-05 09:19:52.698064.698064 lmp.py:372]   Expert 50 |    136 | CPU
DEBUG 01-05 09:19:52.698276.698276 lmp.py:372]   Expert 30 |    137 | CPU
DEBUG 01-05 09:19:52.698681.698681 lmp.py:372]   Expert 61 |    142 | CPU
DEBUG 01-05 09:19:52.698655.698655 lmp.py:372]   Expert 24 |    149 | CPU
DEBUG 01-05 09:19:52.698629.698629 lmp.py:372]   Expert 56 |    151 | CPU
DEBUG 01-05 09:19:52.698557.698557 lmp.py:372]   Expert 58 |    152 | CPU
DEBUG 01-05 09:19:52.698769.698769 lmp.py:372]   Expert 63 |    152 | CPU
DEBUG 01-05 09:19:52.698459.698459 lmp.py:372]   Expert  6 |    155 | CPU
DEBUG 01-05 09:19:52.698671.698671 lmp.py:372]   Expert 16 |    163 | CPU
DEBUG 01-05 09:19:52.698360.698360 lmp.py:372]   Expert  2 |    165 | CPU
DEBUG 01-05 09:19:52.698573.698573 lmp.py:372]   Expert 59 |    166 | CPU
DEBUG 01-05 09:19:52.698977.698977 lmp.py:372]   Expert 49 |    172 | CPU
DEBUG 01-05 09:19:52.698951.698951 lmp.py:372]   Expert 53 |    172 | CPU
DEBUG 01-05 09:19:52.698449.698449 lmp.py:372]   Expert 11 |    174 | CPU
DEBUG 01-05 09:19:52.698423.698423 lmp.py:372]   Expert 34 |    178 | CPU
DEBUG 01-05 09:19:52.698920.698920 lmp.py:372]   Expert 10 |    187 | GPU
DEBUG 01-05 09:19:52.698371.698371 lmp.py:372]   Expert 18 |    189 | GPU
DEBUG 01-05 09:19:52.698537.698537 lmp.py:372]   Expert 29 |    191 | GPU
DEBUG 01-05 09:19:52.698273.698273 lmp.py:372]   Expert 37 |    193 | GPU
DEBUG 01-05 09:19:52.698770.698770 lmp.py:372]   Expert 43 |    197 | GPU
DEBUG 01-05 09:19:52.698267.698267 lmp.py:372]   Expert 33 |    199 | GPU
DEBUG 01-05 09:19:52.698241.698241 lmp.py:372]   Expert 15 |    200 | GPU
DEBUG 01-05 09:19:52.698692.698692 lmp.py:372]   Expert 21 |    209 | GPU
DEBUG 01-05 09:19:52.698143.698143 lmp.py:372]   Expert 32 |    212 | GPU
DEBUG 01-05 09:19:52.698070.698070 lmp.py:372]   Expert 57 |    222 | GPU
DEBUG 01-05 09:19:52.698521.698521 lmp.py:372]   Expert 42 |    227 | GPU
DEBUG 01-05 09:19:52.698449.698449 lmp.py:372]   Expert 44 |    229 | GPU
DEBUG 01-05 09:19:52.698330.698330 lmp.py:372]   Expert 20 |    231 | GPU
DEBUG 01-05 09:19:52.698781.698781 lmp.py:372]   Expert  0 |    233 | GPU
DEBUG 01-05 09:19:52.698253.698253 lmp.py:372]   Expert 51 |    238 | GPU
DEBUG 01-05 09:19:52.698703.698703 lmp.py:372]   Expert 35 |    242 | GPU
DEBUG 01-05 09:19:52.698439.698439 lmp.py:372]   Expert 13 |    244 | GPU
DEBUG 01-05 09:19:52.698797.698797 lmp.py:372]   Expert  9 |    248 | GPU
DEBUG 01-05 09:19:52.698963.698963 lmp.py:372]   Expert  5 |    268 | GPU
DEBUG 01-05 09:19:52.698653.698653 lmp.py:372]   Expert 22 |    275 | GPU
DEBUG 01-05 09:19:52.698581.698581 lmp.py:372]   Expert 23 |    282 | GPU
DEBUG 01-05 09:19:52.698747.698747 lmp.py:372]   Expert 38 |    289 | GPU
DEBUG 01-05 09:19:52.698151.698151 lmp.py:372]   Expert 62 |    290 | GPU
DEBUG 01-05 09:19:52.698748.698748 lmp.py:372]   Expert 19 |    297 | GPU
DEBUG 01-05 09:19:52.698437.698437 lmp.py:372]   Expert  4 |    298 | GPU
DEBUG 01-05 09:19:52.699888.699888 lmp.py:372]   Expert 12 |    308 | GPU
DEBUG 01-05 09:19:52.699862.699862 lmp.py:372]   Expert 48 |    309 | GPU
DEBUG 01-05 09:19:52.699836.699836 lmp.py:372]   Expert 26 |    322 | GPU
DEBUG 01-05 09:19:52.699810.699810 lmp.py:372]   Expert 45 |    336 | GPU
DEBUG 01-05 09:19:52.699930.699930 lmp.py:372]   Expert 41 |    356 | GPU
DEBUG 01-05 09:19:52.699573.699573 lmp.py:372]   Expert 55 |    389 | GPU
DEBUG 01-05 09:19:52.699501.699501 lmp.py:372]   Expert 17 |    487 | GPU
DEBUG 01-05 09:19:52.699144.699144 lmp.py:373] 
DEBUG 01-05 09:19:52.699144.699144 lmp.py:373]   CPU total tokens: 3891 (31.7%)
DEBUG 01-05 09:19:52.699740.699740 lmp.py:374]   GPU total tokens: 8397 (68.3%)
DEBUG 01-05 09:19:52.699675.699675 cuda_h.py:19] end experts_map_get cost 0.001543283462524414 seconds
DEBUG 01-05 09:19:52.699702.699702 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.699531.699531 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.699867.699867 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.699730.699730 cuda_h.py:19] end allocate_cuda_memory cost 0.0002155303955078125 seconds
DEBUG 01-05 09:19:52.699388.699388 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.699190.699190 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.699953.699953 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.699603.699603 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af9f0043-ab2c-44ce-91cb-367111c0605c
DEBUG 01-05 09:19:52.699543.699543 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.701785.701785 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af9f0043-ab2c-44ce-91cb-367111c0605c
DEBUG 01-05 09:19:52.701283.701283 cuda_h.py:19] end load_into_gpu_async cost 0.0014014244079589844 seconds
DEBUG 01-05 09:19:52.701556.701556 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.701039.701039 cuda_h.py:19] end restore_tensors2 cost 0.00036454200744628906 seconds
DEBUG 01-05 09:19:52.701399.701399 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023374557495117188 seconds
DEBUG 01-05 09:19:52.704236.704236 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005036354064941406 seconds
DEBUG 01-05 09:19:52.704211.704211 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.704003.704003 lmp.py:419] 
DEBUG 01-05 09:19:52.704003.704003 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.704237.704237 cuda_h.py:19] end cpu_experts_submit cost 0.00015044212341308594 seconds
DEBUG 01-05 09:19:52.704179.704179 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.717905.717905 mlpmodule.py:704] group tensors cost 0.012562990188598633 s
DEBUG 01-05 09:19:52.719560.719560 mlpmodule.py:742] pad cost 0.0016684532165527344 s
DEBUG 01-05 09:19:52.719577.719577 mlpmodule.py:748] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-05 09:19:52.720998.720998 mlpmodule.py:753] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-05 09:19:52.731918.731918 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.731401.731401 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.732967.732967 mlpmodule.py:773] group_w3 first element: 0.01104736328125
WARNING 01-05 09:19:52.732257.732257 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.749775.749775 mlpmodule.py:793] group einsum cost 0.028858184814453125 s
DEBUG 01-05 09:19:52.750054.750054 mlpmodule.py:801] cpy2cputensor cost 0.0007798671722412109 s
DEBUG 01-05 09:19:52.786384.786384 cuda_h.py:19] end wait_cetm_experts cost 0.08181405067443848 seconds
DEBUG 01-05 09:19:52.786099.786099 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.787424.787424 cuda_h.py:19] end gpu_sexperts cost 0.0005812644958496094 seconds
DEBUG 01-05 09:19:52.787321.787321 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:19:52.787051.787051 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-05 09:19:52.787106.787106 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.62396240234375e-05 seconds
DEBUG 01-05 09:19:52.787200.787200 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.939338684082031e-05 seconds
DEBUG 01-05 09:19:52.787519.787519 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.787228.787228 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af9f0043-ab2c-44ce-91cb-367111c0605c
DEBUG 01-05 09:19:52.787128.787128 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.787026.787026 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.787776.787776 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.792699.792699 cuda_h.py:19] end allocate_cuda_memory cost 0.004183769226074219 seconds
DEBUG 01-05 09:19:52.792185.792185 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.792047.792047 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.792599.792599 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.792739.792739 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ef58e57f-f796-4684-91ae-344d90051c4f
DEBUG 01-05 09:19:52.792590.792590 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.792295.792295 client.py:127] Model loaded
DEBUG 01-05 09:19:52.792244.792244 cuda_h.py:19] end wait_experts cost 0.005208253860473633 seconds
DEBUG 01-05 09:19:52.792331.792331 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.792610.792610 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:52.793039.793039 mlpmodule.py:531] gpu group tensors cost 0.0006542205810546875 s
INFO 01-05 09:19:52.793371.793371 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ef58e57f-f796-4684-91ae-344d90051c4f
DEBUG 01-05 09:19:52.793056.793056 cuda_h.py:19] end load_into_gpu_async cost 0.00165557861328125 seconds
DEBUG 01-05 09:19:52.793435.793435 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.793075.793075 cuda_h.py:19] end restore_tensors2 cost 8.749961853027344e-05 seconds
DEBUG 01-05 09:19:52.794838.794838 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00621795654296875 seconds
INFO 01-05 09:19:52.794190.794190 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ef58e57f-f796-4684-91ae-344d90051c4f
DEBUG 01-05 09:19:52.796132.796132 mlpmodule.py:564] gpu pad cost 0.002707958221435547 s
DEBUG 01-05 09:19:52.796594.796594 mlpmodule.py:582] gpu group einsum cost 0.0004515647888183594 s
DEBUG 01-05 09:19:52.800569.800569 mlpmodule.py:611] gpu experts func einsum cost 0.007399797439575195 s
DEBUG 01-05 09:19:52.800082.800082 cuda_h.py:19] end gpu_experts cost 0.0075838565826416016 seconds
DEBUG 01-05 09:19:52.800269.800269 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:52.802676.802676 client.py:127] Model loaded
DEBUG 01-05 09:19:52.802903.802903 cuda_h.py:19] end sllm_worker_task cost 0.014732599258422852 seconds
DEBUG 01-05 09:19:52.802031.802031 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0020973682403564453 seconds
DEBUG 01-05 09:19:52.802910.802910 cuda_h.py:19] end layer_moe_generate_17 cost 0.10578346252441406 seconds
DEBUG 01-05 09:19:52.802566.802566 lmp.py:214] -------------------------------- end layer 17 --------------------------------
DEBUG 01-05 09:19:52.802521.802521 lmp.py:173] -------------------------------- start layer 18 --------------------------------
DEBUG 01-05 09:19:52.802978.802978 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.803120.803120 mlpmodule.py:662]  experts func einsum cost 0.09852433204650879 s
DEBUG 01-05 09:19:52.803983.803983 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.806083.806083 cuda_h.py:19] end self_attn cost 0.0024983882904052734 seconds
DEBUG 01-05 09:19:52.806305.806305 cuda_h.py:19] end iln_self_attn_paln cost 0.0034058094024658203 seconds
DEBUG 01-05 09:19:52.806287.806287 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-05 09:19:52.806481.806481 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.807594.807594 cuda_h.py:19] end gate cost 0.0005767345428466797 seconds
DEBUG 01-05 09:19:52.807993.807993 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.807023.807023 lmp.py:361] 
DEBUG 01-05 09:19:52.807023.807023 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.807686.807686 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.807574.807574 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.807602.807602 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.807006.807006 lmp.py:365] 
DEBUG 01-05 09:19:52.807006.807006 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.807649.807649 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.807491.807491 lmp.py:372]   Expert 35 |     56 | CPU
DEBUG 01-05 09:19:52.807326.807326 lmp.py:372]   Expert  0 |     57 | CPU
DEBUG 01-05 09:19:52.807399.807399 lmp.py:372]   Expert 54 |     59 | CPU
DEBUG 01-05 09:19:52.807089.807089 lmp.py:372]   Expert  3 |     62 | CPU
DEBUG 01-05 09:19:52.807778.807778 lmp.py:372]   Expert 19 |     64 | CPU
DEBUG 01-05 09:19:52.807752.807752 lmp.py:372]   Expert 53 |     68 | CPU
DEBUG 01-05 09:19:52.807726.807726 lmp.py:372]   Expert 58 |     70 | CPU
DEBUG 01-05 09:19:52.807131.807131 lmp.py:372]   Expert 12 |     86 | CPU
DEBUG 01-05 09:19:52.807582.807582 lmp.py:372]   Expert 20 |     86 | CPU
DEBUG 01-05 09:19:52.807317.807317 lmp.py:372]   Expert 40 |     86 | CPU
DEBUG 01-05 09:19:52.807053.807053 lmp.py:372]   Expert 34 |     87 | CPU
DEBUG 01-05 09:19:52.807981.807981 lmp.py:372]   Expert 37 |     90 | CPU
DEBUG 01-05 09:19:52.807431.807431 lmp.py:372]   Expert 41 |     95 | CPU
DEBUG 01-05 09:19:52.807882.807882 lmp.py:372]   Expert 43 |     95 | CPU
DEBUG 01-05 09:19:52.807572.807572 lmp.py:372]   Expert 63 |    103 | CPU
DEBUG 01-05 09:19:52.807023.807023 lmp.py:372]   Expert  6 |    106 | CPU
DEBUG 01-05 09:19:52.807381.807381 lmp.py:372]   Expert 60 |    106 | CPU
DEBUG 01-05 09:19:52.807116.807116 lmp.py:372]   Expert  8 |    107 | CPU
DEBUG 01-05 09:19:52.807090.807090 lmp.py:372]   Expert 46 |    112 | CPU
DEBUG 01-05 09:19:52.807064.807064 lmp.py:372]   Expert 30 |    117 | CPU
DEBUG 01-05 09:19:52.807800.807800 lmp.py:372]   Expert 32 |    117 | CPU
DEBUG 01-05 09:19:52.807774.807774 lmp.py:372]   Expert 44 |    121 | CPU
DEBUG 01-05 09:19:52.807417.807417 lmp.py:372]   Expert 33 |    127 | CPU
DEBUG 01-05 09:19:52.807822.807822 lmp.py:372]   Expert 17 |    132 | CPU
DEBUG 01-05 09:19:52.807511.807511 lmp.py:372]   Expert 29 |    132 | CPU
DEBUG 01-05 09:19:52.808962.808962 lmp.py:372]   Expert 13 |    133 | CPU
DEBUG 01-05 09:19:52.808413.808413 lmp.py:372]   Expert 45 |    139 | CPU
DEBUG 01-05 09:19:52.808579.808579 lmp.py:372]   Expert 48 |    139 | CPU
DEBUG 01-05 09:19:52.808937.808937 lmp.py:372]   Expert  4 |    144 | CPU
DEBUG 01-05 09:19:52.808388.808388 lmp.py:372]   Expert  5 |    145 | CPU
DEBUG 01-05 09:19:52.808362.808362 lmp.py:372]   Expert 55 |    157 | CPU
DEBUG 01-05 09:19:52.808098.808098 lmp.py:372]   Expert 25 |    161 | CPU
DEBUG 01-05 09:19:52.808072.808072 lmp.py:372]   Expert 11 |    167 | GPU
DEBUG 01-05 09:19:52.808807.808807 lmp.py:372]   Expert 27 |    173 | GPU
DEBUG 01-05 09:19:52.808212.808212 lmp.py:372]   Expert 39 |    174 | GPU
DEBUG 01-05 09:19:52.808616.808616 lmp.py:372]   Expert 42 |    181 | GPU
DEBUG 01-05 09:19:52.808306.808306 lmp.py:372]   Expert 56 |    186 | GPU
DEBUG 01-05 09:19:52.808995.808995 lmp.py:372]   Expert 22 |    187 | GPU
DEBUG 01-05 09:19:52.808923.808923 lmp.py:372]   Expert 18 |    188 | GPU
DEBUG 01-05 09:19:52.808612.808612 lmp.py:372]   Expert 52 |    191 | GPU
DEBUG 01-05 09:19:52.808017.808017 lmp.py:372]   Expert  7 |    209 | GPU
DEBUG 01-05 09:19:52.808467.808467 lmp.py:372]   Expert 24 |    209 | GPU
DEBUG 01-05 09:19:52.808442.808442 lmp.py:372]   Expert  9 |    213 | GPU
DEBUG 01-05 09:19:52.808416.808416 lmp.py:372]   Expert 50 |    218 | GPU
DEBUG 01-05 09:19:52.808151.808151 lmp.py:372]   Expert 51 |    220 | GPU
DEBUG 01-05 09:19:52.808125.808125 lmp.py:372]   Expert 59 |    222 | GPU
DEBUG 01-05 09:19:52.808291.808291 lmp.py:372]   Expert  1 |    224 | GPU
DEBUG 01-05 09:19:52.808696.808696 lmp.py:372]   Expert 61 |    244 | GPU
DEBUG 01-05 09:19:52.808346.808346 lmp.py:372]   Expert 16 |    246 | GPU
DEBUG 01-05 09:19:52.808692.808692 lmp.py:372]   Expert 31 |    254 | GPU
DEBUG 01-05 09:19:52.808619.808619 lmp.py:372]   Expert 21 |    275 | GPU
DEBUG 01-05 09:19:52.808070.808070 lmp.py:372]   Expert 28 |    275 | GPU
DEBUG 01-05 09:19:52.808667.808667 lmp.py:372]   Expert 57 |    281 | GPU
DEBUG 01-05 09:19:52.808879.808879 lmp.py:372]   Expert 47 |    285 | GPU
DEBUG 01-05 09:19:52.808615.808615 lmp.py:372]   Expert 38 |    302 | GPU
DEBUG 01-05 09:19:52.808827.808827 lmp.py:372]   Expert 14 |    311 | GPU
DEBUG 01-05 09:19:52.808563.808563 lmp.py:372]   Expert 10 |    335 | GPU
DEBUG 01-05 09:19:52.808491.808491 lmp.py:372]   Expert 15 |    349 | GPU
DEBUG 01-05 09:19:52.808657.808657 lmp.py:372]   Expert  2 |    373 | GPU
DEBUG 01-05 09:19:52.808869.808869 lmp.py:372]   Expert 49 |    376 | GPU
DEBUG 01-05 09:19:52.808605.808605 lmp.py:372]   Expert 36 |    404 | GPU
DEBUG 01-05 09:19:52.808009.808009 lmp.py:372]   Expert 26 |    458 | GPU
DEBUG 01-05 09:19:52.808176.808176 lmp.py:372]   Expert 23 |    486 | GPU
DEBUG 01-05 09:19:52.808103.808103 lmp.py:372]   Expert 62 |    713 | GPU
DEBUG 01-05 09:19:52.808985.808985 lmp.py:373] 
DEBUG 01-05 09:19:52.808985.808985 lmp.py:373]   CPU total tokens: 3359 (27.3%)
DEBUG 01-05 09:19:52.808581.808581 lmp.py:374]   GPU total tokens: 8929 (72.7%)
DEBUG 01-05 09:19:52.808708.808708 cuda_h.py:19] end experts_map_get cost 0.0015521049499511719 seconds
DEBUG 01-05 09:19:52.808543.808543 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.808849.808849 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.808470.808470 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.809221.809221 cuda_h.py:19] end allocate_cuda_memory cost 0.00023818016052246094 seconds
DEBUG 01-05 09:19:52.809879.809879 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.809443.809443 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.809682.809682 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.809955.809955 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c56b021-01e8-4b19-aa4e-34d01d256d14
DEBUG 01-05 09:19:52.809749.809749 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.810049.810049 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c56b021-01e8-4b19-aa4e-34d01d256d14
DEBUG 01-05 09:19:52.810832.810832 cuda_h.py:19] end load_into_gpu_async cost 0.0013391971588134766 seconds
DEBUG 01-05 09:19:52.810389.810389 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.811289.811289 cuda_h.py:19] end restore_tensors2 cost 0.0003571510314941406 seconds
DEBUG 01-05 09:19:52.811410.811410 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002286672592163086 seconds
DEBUG 01-05 09:19:52.813520.813520 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0050122737884521484 seconds
DEBUG 01-05 09:19:52.813257.813257 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.813571.813571 lmp.py:419] 
DEBUG 01-05 09:19:52.813571.813571 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.814083.814083 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-05 09:19:52.814640.814640 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.821604.821604 mlpmodule.py:704] group tensors cost 0.0069942474365234375 s
DEBUG 01-05 09:19:52.824312.824312 mlpmodule.py:742] pad cost 0.002033233642578125 s
DEBUG 01-05 09:19:52.824377.824377 mlpmodule.py:748] create cpu tensor cost 6.270408630371094e-05 s
DEBUG 01-05 09:19:52.824474.824474 mlpmodule.py:753] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-05 09:19:52.835174.835174 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.835564.835564 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.835607.835607 mlpmodule.py:773] group_w3 first element: 0.0024871826171875
WARNING 01-05 09:19:52.836989.836989 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.853923.853923 mlpmodule.py:793] group einsum cost 0.02892446517944336 s
DEBUG 01-05 09:19:52.854564.854564 mlpmodule.py:801] cpy2cputensor cost 0.0009119510650634766 s
DEBUG 01-05 09:19:52.892371.892371 cuda_h.py:19] end wait_cetm_experts cost 0.07873010635375977 seconds
DEBUG 01-05 09:19:52.893894.893894 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:52.893511.893511 cuda_h.py:19] end gpu_sexperts cost 0.0005872249603271484 seconds
DEBUG 01-05 09:19:52.893314.893314 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:19:52.893568.893568 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-05 09:19:52.893669.893669 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.6716461181640625e-05 seconds
DEBUG 01-05 09:19:52.893479.893479 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 8.058547973632812e-05 seconds
DEBUG 01-05 09:19:52.893559.893559 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:52.893030.893030 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c56b021-01e8-4b19-aa4e-34d01d256d14
DEBUG 01-05 09:19:52.894420.894420 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:52.894126.894126 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.894545.894545 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.898636.898636 cuda_h.py:19] end allocate_cuda_memory cost 0.004061460494995117 seconds
DEBUG 01-05 09:19:52.898692.898692 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.898123.898123 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.898436.898436 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.898100.898100 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d182be7-4dd2-411a-8b6f-93b60dfed716
DEBUG 01-05 09:19:52.898759.898759 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.898236.898236 client.py:127] Model loaded
DEBUG 01-05 09:19:52.898424.898424 cuda_h.py:19] end wait_experts cost 0.005031108856201172 seconds
DEBUG 01-05 09:19:52.898511.898511 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:52.899313.899313 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:52.899392.899392 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d182be7-4dd2-411a-8b6f-93b60dfed716
DEBUG 01-05 09:19:52.899256.899256 cuda_h.py:19] end load_into_gpu_async cost 0.001184701919555664 seconds
DEBUG 01-05 09:19:52.899926.899926 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.899281.899281 cuda_h.py:19] end restore_tensors2 cost 8.845329284667969e-05 seconds
DEBUG 01-05 09:19:52.899375.899375 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00562739372253418 seconds
DEBUG 01-05 09:19:52.900538.900538 mlpmodule.py:531] gpu group tensors cost 0.0010950565338134766 s
INFO 01-05 09:19:52.900997.900997 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d182be7-4dd2-411a-8b6f-93b60dfed716
DEBUG 01-05 09:19:52.902690.902690 mlpmodule.py:564] gpu pad cost 0.002030611038208008 s
DEBUG 01-05 09:19:52.902492.902492 mlpmodule.py:582] gpu group einsum cost 0.0005288124084472656 s
DEBUG 01-05 09:19:52.906403.906403 mlpmodule.py:611] gpu experts func einsum cost 0.00752711296081543 s
DEBUG 01-05 09:19:52.906877.906877 cuda_h.py:19] end gpu_experts cost 0.0077550411224365234 seconds
DEBUG 01-05 09:19:52.906879.906879 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:52.909670.909670 mlpmodule.py:662]  experts func einsum cost 0.09501767158508301 s
INFO 01-05 09:19:52.909481.909481 client.py:127] Model loaded
DEBUG 01-05 09:19:52.909749.909749 cuda_h.py:19] end sllm_worker_task cost 0.015455007553100586 seconds
DEBUG 01-05 09:19:52.909381.909381 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002900362014770508 seconds
DEBUG 01-05 09:19:52.909704.909704 cuda_h.py:19] end layer_moe_generate_18 cost 0.10339951515197754 seconds
DEBUG 01-05 09:19:52.910082.910082 lmp.py:214] -------------------------------- end layer 18 --------------------------------
DEBUG 01-05 09:19:52.910560.910560 lmp.py:173] -------------------------------- start layer 19 --------------------------------
DEBUG 01-05 09:19:52.910256.910256 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:52.910551.910551 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:52.912344.912344 cuda_h.py:19] end self_attn cost 0.0024590492248535156 seconds
DEBUG 01-05 09:19:52.913314.913314 cuda_h.py:19] end iln_self_attn_paln cost 0.003065347671508789 seconds
DEBUG 01-05 09:19:52.913203.913203 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-05 09:19:52.913396.913396 cuda_h.py:10] start gate
DEBUG 01-05 09:19:52.913609.913609 cuda_h.py:19] end gate cost 0.0005793571472167969 seconds
DEBUG 01-05 09:19:52.914816.914816 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:52.914316.914316 lmp.py:361] 
DEBUG 01-05 09:19:52.914316.914316 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:52.914264.914264 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:52.914914.914914 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:52.914987.914987 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:52.914392.914392 lmp.py:365] 
DEBUG 01-05 09:19:52.914392.914392 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:52.914035.914035 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:52.914400.914400 lmp.py:372]   Expert 60 |     46 | CPU
DEBUG 01-05 09:19:52.914473.914473 lmp.py:372]   Expert 56 |     52 | CPU
DEBUG 01-05 09:19:52.914401.914401 lmp.py:372]   Expert  5 |     75 | CPU
DEBUG 01-05 09:19:52.914613.914613 lmp.py:372]   Expert 12 |     76 | CPU
DEBUG 01-05 09:19:52.914561.914561 lmp.py:372]   Expert  6 |     80 | CPU
DEBUG 01-05 09:19:52.914774.914774 lmp.py:372]   Expert 55 |     81 | CPU
DEBUG 01-05 09:19:52.914655.914655 lmp.py:372]   Expert 48 |     84 | CPU
DEBUG 01-05 09:19:52.914298.914298 lmp.py:372]   Expert 59 |     87 | CPU
DEBUG 01-05 09:19:52.914464.914464 lmp.py:372]   Expert 44 |     90 | CPU
DEBUG 01-05 09:19:52.914154.914154 lmp.py:372]   Expert 18 |     95 | CPU
DEBUG 01-05 09:19:52.914843.914843 lmp.py:372]   Expert 42 |     95 | CPU
DEBUG 01-05 09:19:52.914771.914771 lmp.py:372]   Expert 52 |    103 | CPU
DEBUG 01-05 09:19:52.914222.914222 lmp.py:372]   Expert 23 |    104 | CPU
DEBUG 01-05 09:19:52.914103.914103 lmp.py:372]   Expert 27 |    109 | CPU
DEBUG 01-05 09:19:52.914792.914792 lmp.py:372]   Expert 30 |    110 | CPU
DEBUG 01-05 09:19:52.914005.914005 lmp.py:372]   Expert 33 |    112 | CPU
DEBUG 01-05 09:19:52.914217.914217 lmp.py:372]   Expert 34 |    120 | CPU
DEBUG 01-05 09:19:52.914430.914430 lmp.py:372]   Expert 24 |    121 | CPU
DEBUG 01-05 09:19:52.914642.914642 lmp.py:372]   Expert 57 |    132 | CPU
DEBUG 01-05 09:19:52.914524.914524 lmp.py:372]   Expert 58 |    140 | CPU
DEBUG 01-05 09:19:52.914690.914690 lmp.py:372]   Expert 54 |    145 | CPU
DEBUG 01-05 09:19:52.914856.914856 lmp.py:372]   Expert 15 |    146 | CPU
DEBUG 01-05 09:19:52.914545.914545 lmp.py:372]   Expert 26 |    147 | CPU
DEBUG 01-05 09:19:52.914473.914473 lmp.py:372]   Expert 13 |    148 | CPU
DEBUG 01-05 09:19:52.914401.914401 lmp.py:372]   Expert 32 |    152 | CPU
DEBUG 01-05 09:19:52.914613.914613 lmp.py:372]   Expert 46 |    152 | CPU
DEBUG 01-05 09:19:52.914779.914779 lmp.py:372]   Expert 16 |    153 | CPU
DEBUG 01-05 09:19:52.914469.914469 lmp.py:372]   Expert 62 |    154 | CPU
DEBUG 01-05 09:19:52.914443.914443 lmp.py:372]   Expert 63 |    154 | CPU
DEBUG 01-05 09:19:52.914655.914655 lmp.py:372]   Expert  0 |    161 | CPU
DEBUG 01-05 09:19:52.914867.914867 lmp.py:372]   Expert  1 |    163 | CPU
DEBUG 01-05 09:19:52.914365.914365 lmp.py:372]   Expert  8 |    163 | CPU
DEBUG 01-05 09:19:52.914008.914008 lmp.py:372]   Expert 17 |    170 | GPU
DEBUG 01-05 09:19:52.915935.915935 lmp.py:372]   Expert 49 |    172 | GPU
DEBUG 01-05 09:19:52.915863.915863 lmp.py:372]   Expert 43 |    175 | GPU
DEBUG 01-05 09:19:52.915552.915552 lmp.py:372]   Expert 39 |    180 | GPU
DEBUG 01-05 09:19:52.915003.915003 lmp.py:372]   Expert 47 |    183 | GPU
DEBUG 01-05 09:19:52.915169.915169 lmp.py:372]   Expert 40 |    191 | GPU
DEBUG 01-05 09:19:52.915859.915859 lmp.py:372]   Expert  4 |    192 | GPU
DEBUG 01-05 09:19:52.915310.915310 lmp.py:372]   Expert 37 |    198 | GPU
DEBUG 01-05 09:19:52.915191.915191 lmp.py:372]   Expert 53 |    201 | GPU
DEBUG 01-05 09:19:52.915165.915165 lmp.py:372]   Expert 25 |    203 | GPU
DEBUG 01-05 09:19:52.915901.915901 lmp.py:372]   Expert 50 |    204 | GPU
DEBUG 01-05 09:19:52.915875.915875 lmp.py:372]   Expert 14 |    224 | GPU
DEBUG 01-05 09:19:52.915849.915849 lmp.py:372]   Expert 22 |    231 | GPU
DEBUG 01-05 09:19:52.915823.915823 lmp.py:372]   Expert 35 |    231 | GPU
DEBUG 01-05 09:19:52.915466.915466 lmp.py:372]   Expert 19 |    237 | GPU
DEBUG 01-05 09:19:52.915678.915678 lmp.py:372]   Expert 20 |    237 | GPU
DEBUG 01-05 09:19:52.915414.915414 lmp.py:372]   Expert 11 |    240 | GPU
DEBUG 01-05 09:19:52.915103.915103 lmp.py:372]   Expert 41 |    248 | GPU
DEBUG 01-05 09:19:52.915792.915792 lmp.py:372]   Expert 28 |    252 | GPU
DEBUG 01-05 09:19:52.915482.915482 lmp.py:372]   Expert 51 |    267 | GPU
DEBUG 01-05 09:19:52.915933.915933 lmp.py:372]   Expert 38 |    282 | GPU
DEBUG 01-05 09:19:52.915860.915860 lmp.py:372]   Expert 21 |    283 | GPU
DEBUG 01-05 09:19:52.915073.915073 lmp.py:372]   Expert 36 |    286 | GPU
DEBUG 01-05 09:19:52.915193.915193 lmp.py:372]   Expert 10 |    317 | GPU
DEBUG 01-05 09:19:52.915644.915644 lmp.py:372]   Expert 45 |    345 | GPU
DEBUG 01-05 09:19:52.915618.915618 lmp.py:372]   Expert  2 |    352 | GPU
DEBUG 01-05 09:19:52.915592.915592 lmp.py:372]   Expert 61 |    353 | GPU
DEBUG 01-05 09:19:52.915566.915566 lmp.py:372]   Expert  9 |    366 | GPU
DEBUG 01-05 09:19:52.915301.915301 lmp.py:372]   Expert  3 |    377 | GPU
DEBUG 01-05 09:19:52.915660.915660 lmp.py:372]   Expert 29 |    393 | GPU
DEBUG 01-05 09:19:52.915587.915587 lmp.py:372]   Expert 31 |    398 | GPU
DEBUG 01-05 09:19:52.915753.915753 lmp.py:372]   Expert  7 |    550 | GPU
DEBUG 01-05 09:19:52.915873.915873 lmp.py:373] 
DEBUG 01-05 09:19:52.915873.915873 lmp.py:373]   CPU total tokens: 3750 (30.5%)
DEBUG 01-05 09:19:52.915516.915516 lmp.py:374]   GPU total tokens: 8538 (69.5%)
DEBUG 01-05 09:19:52.915212.915212 cuda_h.py:19] end experts_map_get cost 0.0015294551849365234 seconds
DEBUG 01-05 09:19:52.915094.915094 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:52.915546.915546 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:52.915358.915358 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:52.916082.916082 cuda_h.py:19] end allocate_cuda_memory cost 0.0002186298370361328 seconds
DEBUG 01-05 09:19:52.916217.916217 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:52.916827.916827 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:52.916736.916736 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:52.916339.916339 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3eab551b-9f0c-405b-878c-c22c651e1382
DEBUG 01-05 09:19:52.916002.916002 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:52.917951.917951 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3eab551b-9f0c-405b-878c-c22c651e1382
DEBUG 01-05 09:19:52.917495.917495 cuda_h.py:19] end load_into_gpu_async cost 0.0013689994812011719 seconds
DEBUG 01-05 09:19:52.917814.917814 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:52.917317.917317 cuda_h.py:19] end restore_tensors2 cost 0.0003440380096435547 seconds
DEBUG 01-05 09:19:52.917729.917729 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002283811569213867 seconds
DEBUG 01-05 09:19:52.920480.920480 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0049953460693359375 seconds
DEBUG 01-05 09:19:52.920456.920456 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:52.920180.920180 lmp.py:419] 
DEBUG 01-05 09:19:52.920180.920180 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:52.920076.920076 cuda_h.py:19] end cpu_experts_submit cost 0.0001125335693359375 seconds
DEBUG 01-05 09:19:52.920302.920302 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:52.927091.927091 mlpmodule.py:704] group tensors cost 0.006459236145019531 s
DEBUG 01-05 09:19:52.930835.930835 mlpmodule.py:742] pad cost 0.0016932487487792969 s
DEBUG 01-05 09:19:52.930516.930516 mlpmodule.py:748] create cpu tensor cost 6.508827209472656e-05 s
DEBUG 01-05 09:19:52.930141.930141 mlpmodule.py:753] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-05 09:19:52.941688.941688 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:52.941350.941350 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:52.941101.941101 mlpmodule.py:773] group_w3 first element: -0.0034942626953125
WARNING 01-05 09:19:52.942132.942132 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:52.961663.961663 mlpmodule.py:793] group einsum cost 0.030953168869018555 s
DEBUG 01-05 09:19:52.962125.962125 mlpmodule.py:801] cpy2cputensor cost 0.0007107257843017578 s
DEBUG 01-05 09:19:53.000520.000520 cuda_h.py:19] end wait_cetm_experts cost 0.07961249351501465 seconds
DEBUG 01-05 09:19:53.000235.000235 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.001521.001521 cuda_h.py:19] end gpu_sexperts cost 0.00058746337890625 seconds
DEBUG 01-05 09:19:53.001947.001947 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:19:53.001154.001154 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-05 09:19:53.001494.001494 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.7670135498046875e-05 seconds
DEBUG 01-05 09:19:53.001634.001634 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.891654968261719e-05 seconds
DEBUG 01-05 09:19:53.001430.001430 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.001948.001948 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3eab551b-9f0c-405b-878c-c22c651e1382
DEBUG 01-05 09:19:53.001278.001278 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.001698.001698 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.001210.001210 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.005848.005848 cuda_h.py:19] end allocate_cuda_memory cost 0.003973722457885742 seconds
DEBUG 01-05 09:19:53.006811.006811 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.006912.006912 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.006125.006125 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.006312.006312 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a18cdeb-c55c-4f55-9ac5-e7267b215ccf
DEBUG 01-05 09:19:53.006441.006441 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.006203.006203 client.py:127] Model loaded
DEBUG 01-05 09:19:53.006344.006344 cuda_h.py:19] end wait_experts cost 0.004927396774291992 seconds
DEBUG 01-05 09:19:53.006385.006385 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.006426.006426 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.007882.007882 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a18cdeb-c55c-4f55-9ac5-e7267b215ccf
DEBUG 01-05 09:19:53.007031.007031 cuda_h.py:19] end load_into_gpu_async cost 0.0011751651763916016 seconds
DEBUG 01-05 09:19:53.007509.007509 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.007579.007579 cuda_h.py:19] end restore_tensors2 cost 9.107589721679688e-05 seconds
DEBUG 01-05 09:19:53.007580.007580 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005532503128051758 seconds
DEBUG 01-05 09:19:53.007220.007220 mlpmodule.py:531] gpu group tensors cost 0.001094818115234375 s
INFO 01-05 09:19:53.008334.008334 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a18cdeb-c55c-4f55-9ac5-e7267b215ccf
DEBUG 01-05 09:19:53.009749.009749 mlpmodule.py:564] gpu pad cost 0.002030611038208008 s
DEBUG 01-05 09:19:53.010002.010002 mlpmodule.py:582] gpu group einsum cost 0.0005536079406738281 s
DEBUG 01-05 09:19:53.014573.014573 mlpmodule.py:611] gpu experts func einsum cost 0.007466316223144531 s
DEBUG 01-05 09:19:53.014650.014650 cuda_h.py:19] end gpu_experts cost 0.007680177688598633 seconds
DEBUG 01-05 09:19:53.014651.014651 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:53.016551.016551 client.py:127] Model loaded
DEBUG 01-05 09:19:53.016255.016255 cuda_h.py:19] end sllm_worker_task cost 0.014847755432128906 seconds
DEBUG 01-05 09:19:53.016721.016721 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002438783645629883 seconds
DEBUG 01-05 09:19:53.016427.016427 mlpmodule.py:662]  experts func einsum cost 0.095855712890625 s
DEBUG 01-05 09:19:53.017216.017216 cuda_h.py:19] end layer_moe_generate_19 cost 0.10379195213317871 seconds
DEBUG 01-05 09:19:53.017755.017755 lmp.py:214] -------------------------------- end layer 19 --------------------------------
DEBUG 01-05 09:19:53.017809.017809 lmp.py:173] -------------------------------- start layer 20 --------------------------------
DEBUG 01-05 09:19:53.017267.017267 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.017084.017084 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.020413.020413 cuda_h.py:19] end self_attn cost 0.002432107925415039 seconds
DEBUG 01-05 09:19:53.020298.020298 cuda_h.py:19] end iln_self_attn_paln cost 0.0030825138092041016 seconds
DEBUG 01-05 09:19:53.020380.020380 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-05 09:19:53.020242.020242 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.021130.021130 cuda_h.py:19] end gate cost 0.0005853176116943359 seconds
DEBUG 01-05 09:19:53.021483.021483 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.021612.021612 lmp.py:361] 
DEBUG 01-05 09:19:53.021612.021612 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.021560.021560 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.021925.021925 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.021906.021906 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.021264.021264 lmp.py:365] 
DEBUG 01-05 09:19:53.021264.021264 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.021146.021146 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.021703.021703 lmp.py:372]   Expert 54 |     43 | CPU
DEBUG 01-05 09:19:53.021346.021346 lmp.py:372]   Expert  8 |     49 | CPU
DEBUG 01-05 09:19:53.021704.021704 lmp.py:372]   Expert 28 |     50 | CPU
DEBUG 01-05 09:19:53.021109.021109 lmp.py:372]   Expert 13 |     71 | CPU
DEBUG 01-05 09:19:53.021275.021275 lmp.py:372]   Expert  1 |     75 | CPU
DEBUG 01-05 09:19:53.021487.021487 lmp.py:372]   Expert  6 |     82 | CPU
DEBUG 01-05 09:19:53.021700.021700 lmp.py:372]   Expert 36 |     83 | CPU
DEBUG 01-05 09:19:53.021389.021389 lmp.py:372]   Expert 43 |     90 | CPU
DEBUG 01-05 09:19:53.021032.021032 lmp.py:372]   Expert 12 |     93 | CPU
DEBUG 01-05 09:19:53.021198.021198 lmp.py:372]   Expert 42 |     93 | CPU
DEBUG 01-05 09:19:53.021649.021649 lmp.py:372]   Expert 33 |     99 | CPU
DEBUG 01-05 09:19:53.021100.021100 lmp.py:372]   Expert 10 |    109 | CPU
DEBUG 01-05 09:19:53.022789.022789 lmp.py:372]   Expert 51 |    114 | CPU
DEBUG 01-05 09:19:53.022717.022717 lmp.py:372]   Expert 19 |    115 | CPU
DEBUG 01-05 09:19:53.022314.022314 lmp.py:372]   Expert 57 |    115 | CPU
DEBUG 01-05 09:19:53.022764.022764 lmp.py:372]   Expert 14 |    120 | CPU
DEBUG 01-05 09:19:53.022977.022977 lmp.py:372]   Expert 46 |    120 | CPU
DEBUG 01-05 09:19:53.022428.022428 lmp.py:372]   Expert 11 |    121 | CPU
DEBUG 01-05 09:19:53.022879.022879 lmp.py:372]   Expert 50 |    121 | CPU
DEBUG 01-05 09:19:53.022853.022853 lmp.py:372]   Expert 30 |    122 | CPU
DEBUG 01-05 09:19:53.022304.022304 lmp.py:372]   Expert  9 |    126 | CPU
DEBUG 01-05 09:19:53.022754.022754 lmp.py:372]   Expert 39 |    130 | CPU
DEBUG 01-05 09:19:53.022159.022159 lmp.py:372]   Expert 38 |    138 | CPU
DEBUG 01-05 09:19:53.022802.022802 lmp.py:372]   Expert 49 |    152 | CPU
DEBUG 01-05 09:19:53.022683.022683 lmp.py:372]   Expert 63 |    152 | CPU
DEBUG 01-05 09:19:53.022657.022657 lmp.py:372]   Expert  3 |    155 | CPU
DEBUG 01-05 09:19:53.022347.022347 lmp.py:372]   Expert 52 |    157 | CPU
DEBUG 01-05 09:19:53.022559.022559 lmp.py:372]   Expert 61 |    157 | CPU
DEBUG 01-05 09:19:53.022725.022725 lmp.py:372]   Expert  7 |    158 | CPU
DEBUG 01-05 09:19:53.022130.022130 lmp.py:372]   Expert 29 |    160 | CPU
DEBUG 01-05 09:19:53.022488.022488 lmp.py:372]   Expert  5 |    170 | CPU
DEBUG 01-05 09:19:53.022939.022939 lmp.py:372]   Expert 20 |    171 | CPU
DEBUG 01-05 09:19:53.022390.022390 lmp.py:372]   Expert 18 |    182 | GPU
DEBUG 01-05 09:19:53.022364.022364 lmp.py:372]   Expert 17 |    183 | GPU
DEBUG 01-05 09:19:53.022768.022768 lmp.py:372]   Expert 44 |    183 | GPU
DEBUG 01-05 09:19:53.022935.022935 lmp.py:372]   Expert 22 |    184 | GPU
DEBUG 01-05 09:19:53.022054.022054 lmp.py:372]   Expert 53 |    191 | GPU
DEBUG 01-05 09:19:53.022505.022505 lmp.py:372]   Expert 62 |    191 | GPU
DEBUG 01-05 09:19:53.022718.022718 lmp.py:372]   Expert  0 |    194 | GPU
DEBUG 01-05 09:19:53.022169.022169 lmp.py:372]   Expert 47 |    204 | GPU
DEBUG 01-05 09:19:53.022143.022143 lmp.py:372]   Expert 37 |    211 | GPU
DEBUG 01-05 09:19:53.022355.022355 lmp.py:372]   Expert 26 |    226 | GPU
DEBUG 01-05 09:19:53.022429.022429 lmp.py:372]   Expert 23 |    231 | GPU
DEBUG 01-05 09:19:53.022833.022833 lmp.py:372]   Expert 55 |    234 | GPU
DEBUG 01-05 09:19:53.022046.022046 lmp.py:372]   Expert 45 |    235 | GPU
DEBUG 01-05 09:19:53.022497.022497 lmp.py:372]   Expert 32 |    242 | GPU
DEBUG 01-05 09:19:53.022232.022232 lmp.py:372]   Expert 60 |    248 | GPU
DEBUG 01-05 09:19:53.022921.022921 lmp.py:372]   Expert 16 |    249 | GPU
DEBUG 01-05 09:19:53.022088.022088 lmp.py:372]   Expert  2 |    265 | GPU
DEBUG 01-05 09:19:53.022062.022062 lmp.py:372]   Expert 24 |    269 | GPU
DEBUG 01-05 09:19:53.022797.022797 lmp.py:372]   Expert 21 |    273 | GPU
DEBUG 01-05 09:19:53.022487.022487 lmp.py:372]   Expert 15 |    275 | GPU
DEBUG 01-05 09:19:53.022176.022176 lmp.py:372]   Expert 34 |    276 | GPU
DEBUG 01-05 09:19:53.022865.022865 lmp.py:372]   Expert 31 |    293 | GPU
DEBUG 01-05 09:19:53.022270.022270 lmp.py:372]   Expert 58 |    294 | GPU
DEBUG 01-05 09:19:53.022244.022244 lmp.py:372]   Expert 59 |    301 | GPU
DEBUG 01-05 09:19:53.022979.022979 lmp.py:372]   Expert 27 |    302 | GPU
DEBUG 01-05 09:19:53.022715.022715 lmp.py:372]   Expert  4 |    303 | GPU
DEBUG 01-05 09:19:53.022451.022451 lmp.py:372]   Expert 48 |    314 | GPU
DEBUG 01-05 09:19:53.022902.022902 lmp.py:372]   Expert 56 |    318 | GPU
DEBUG 01-05 09:19:53.022114.022114 lmp.py:372]   Expert 41 |    322 | GPU
DEBUG 01-05 09:19:53.022995.022995 lmp.py:372]   Expert 40 |    327 | GPU
DEBUG 01-05 09:19:53.022208.022208 lmp.py:372]   Expert 25 |    502 | GPU
DEBUG 01-05 09:19:53.022420.022420 lmp.py:372]   Expert 35 |    555 | GPU
DEBUG 01-05 09:19:53.022110.022110 lmp.py:373] 
DEBUG 01-05 09:19:53.022110.022110 lmp.py:373]   CPU total tokens: 3711 (30.2%)
DEBUG 01-05 09:19:53.022037.022037 lmp.py:374]   GPU total tokens: 8577 (69.8%)
DEBUG 01-05 09:19:53.022733.022733 cuda_h.py:19] end experts_map_get cost 0.0015265941619873047 seconds
DEBUG 01-05 09:19:53.022045.022045 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.022352.022352 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.023111.023111 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.023471.023471 cuda_h.py:19] end allocate_cuda_memory cost 0.00023055076599121094 seconds
DEBUG 01-05 09:19:53.023222.023222 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.023978.023978 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.023932.023932 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.023344.023344 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fda6de6e-1f39-4577-ab4a-cfe90a0438f0
DEBUG 01-05 09:19:53.023423.023423 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.024584.024584 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fda6de6e-1f39-4577-ab4a-cfe90a0438f0
DEBUG 01-05 09:19:53.024274.024274 cuda_h.py:19] end load_into_gpu_async cost 0.0013418197631835938 seconds
DEBUG 01-05 09:19:53.024785.024785 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.025035.025035 cuda_h.py:19] end restore_tensors2 cost 0.000331878662109375 seconds
DEBUG 01-05 09:19:53.025388.025388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022521018981933594 seconds
DEBUG 01-05 09:19:53.027787.027787 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004908323287963867 seconds
DEBUG 01-05 09:19:53.027524.027524 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.027387.027387 lmp.py:419] 
DEBUG 01-05 09:19:53.027387.027387 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.028019.028019 cuda_h.py:19] end cpu_experts_submit cost 0.00012683868408203125 seconds
DEBUG 01-05 09:19:53.028530.028530 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.039513.039513 mlpmodule.py:704] group tensors cost 0.011383771896362305 s
DEBUG 01-05 09:19:53.042013.042013 mlpmodule.py:742] pad cost 0.0016324520111083984 s
DEBUG 01-05 09:19:53.042958.042958 mlpmodule.py:748] create cpu tensor cost 6.365776062011719e-05 s
DEBUG 01-05 09:19:53.042967.042967 mlpmodule.py:753] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-05 09:19:53.053492.053492 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.053353.053353 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.053151.053151 mlpmodule.py:773] group_w3 first element: -0.0810546875
WARNING 01-05 09:19:53.053228.053228 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.073697.073697 mlpmodule.py:793] group einsum cost 0.03121495246887207 s
DEBUG 01-05 09:19:53.076087.076087 mlpmodule.py:801] cpy2cputensor cost 0.002318859100341797 s
DEBUG 01-05 09:19:53.112179.112179 cuda_h.py:19] end wait_cetm_experts cost 0.08417987823486328 seconds
DEBUG 01-05 09:19:53.112689.112689 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.113882.113882 cuda_h.py:19] end gpu_sexperts cost 0.0005886554718017578 seconds
DEBUG 01-05 09:19:53.113593.113593 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:19:53.113462.113462 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-05 09:19:53.113656.113656 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.743171691894531e-05 seconds
DEBUG 01-05 09:19:53.113273.113273 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.82012939453125e-05 seconds
DEBUG 01-05 09:19:53.113069.113069 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.113256.113256 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fda6de6e-1f39-4577-ab4a-cfe90a0438f0
DEBUG 01-05 09:19:53.113771.113771 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.113953.113953 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.113942.113942 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.117266.117266 cuda_h.py:19] end allocate_cuda_memory cost 0.004093647003173828 seconds
DEBUG 01-05 09:19:53.118011.118011 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.118158.118158 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.118179.118179 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.118412.118412 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 10dfad26-fc42-4942-bd09-fd0458aaa54c
DEBUG 01-05 09:19:53.118257.118257 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.118039.118039 client.py:127] Model loaded
DEBUG 01-05 09:19:53.118896.118896 cuda_h.py:19] end wait_experts cost 0.005071878433227539 seconds
DEBUG 01-05 09:19:53.118221.118221 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.118931.118931 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.119758.119758 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 10dfad26-fc42-4942-bd09-fd0458aaa54c
DEBUG 01-05 09:19:53.119422.119422 cuda_h.py:19] end load_into_gpu_async cost 0.0011768341064453125 seconds
DEBUG 01-05 09:19:53.119993.119993 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.119679.119679 cuda_h.py:19] end restore_tensors2 cost 8.869171142578125e-05 seconds
DEBUG 01-05 09:19:53.119727.119727 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005664348602294922 seconds
DEBUG 01-05 09:19:53.119443.119443 mlpmodule.py:531] gpu group tensors cost 0.0011663436889648438 s
INFO 01-05 09:19:53.120136.120136 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 10dfad26-fc42-4942-bd09-fd0458aaa54c
DEBUG 01-05 09:19:53.121400.121400 mlpmodule.py:564] gpu pad cost 0.001960277557373047 s
DEBUG 01-05 09:19:53.122965.122965 mlpmodule.py:582] gpu group einsum cost 0.0005629062652587891 s
DEBUG 01-05 09:19:53.126577.126577 mlpmodule.py:611] gpu experts func einsum cost 0.007551908493041992 s
DEBUG 01-05 09:19:53.126250.126250 cuda_h.py:19] end gpu_experts cost 0.007750749588012695 seconds
DEBUG 01-05 09:19:53.126913.126913 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:53.128369.128369 client.py:127] Model loaded
DEBUG 01-05 09:19:53.128119.128119 cuda_h.py:19] end sllm_worker_task cost 0.015050411224365234 seconds
DEBUG 01-05 09:19:53.128678.128678 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0024285316467285156 seconds
DEBUG 01-05 09:19:53.128821.128821 mlpmodule.py:662]  experts func einsum cost 0.10070681571960449 s
DEBUG 01-05 09:19:53.129525.129525 cuda_h.py:19] end layer_moe_generate_20 cost 0.10852241516113281 seconds
DEBUG 01-05 09:19:53.129250.129250 lmp.py:214] -------------------------------- end layer 20 --------------------------------
DEBUG 01-05 09:19:53.129927.129927 lmp.py:173] -------------------------------- start layer 21 --------------------------------
DEBUG 01-05 09:19:53.129861.129861 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.129262.129262 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.132511.132511 cuda_h.py:19] end self_attn cost 0.002445697784423828 seconds
DEBUG 01-05 09:19:53.132290.132290 cuda_h.py:19] end iln_self_attn_paln cost 0.0030946731567382812 seconds
DEBUG 01-05 09:19:53.132041.132041 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-05 09:19:53.132949.132949 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.133870.133870 cuda_h.py:19] end gate cost 0.0005733966827392578 seconds
DEBUG 01-05 09:19:53.133746.133746 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.133107.133107 lmp.py:361] 
DEBUG 01-05 09:19:53.133107.133107 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.133770.133770 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.133897.133897 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.133401.133401 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.133236.133236 lmp.py:365] 
DEBUG 01-05 09:19:53.133236.133236 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.133879.133879 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.133767.133767 lmp.py:372]   Expert  9 |     31 | CPU
DEBUG 01-05 09:19:53.133887.133887 lmp.py:372]   Expert 60 |     48 | CPU
DEBUG 01-05 09:19:53.133576.133576 lmp.py:372]   Expert 44 |     54 | CPU
DEBUG 01-05 09:19:53.133027.133027 lmp.py:372]   Expert 20 |     59 | CPU
DEBUG 01-05 09:19:53.133432.133432 lmp.py:372]   Expert 32 |     69 | CPU
DEBUG 01-05 09:19:53.133360.133360 lmp.py:372]   Expert 26 |     70 | CPU
DEBUG 01-05 09:19:53.133718.133718 lmp.py:372]   Expert 56 |     76 | CPU
DEBUG 01-05 09:19:53.134169.134169 lmp.py:372]   Expert 19 |     79 | CPU
DEBUG 01-05 09:19:53.134143.134143 lmp.py:372]   Expert  1 |     86 | CPU
DEBUG 01-05 09:19:53.134117.134117 lmp.py:372]   Expert 51 |     91 | CPU
DEBUG 01-05 09:19:53.134852.134852 lmp.py:372]   Expert 54 |     98 | CPU
DEBUG 01-05 09:19:53.134065.134065 lmp.py:372]   Expert 57 |    101 | CPU
DEBUG 01-05 09:19:53.134039.134039 lmp.py:372]   Expert 12 |    102 | CPU
DEBUG 01-05 09:19:53.134775.134775 lmp.py:372]   Expert  8 |    109 | CPU
DEBUG 01-05 09:19:53.134987.134987 lmp.py:372]   Expert 48 |    116 | CPU
DEBUG 01-05 09:19:53.134438.134438 lmp.py:372]   Expert 52 |    122 | CPU
DEBUG 01-05 09:19:53.134127.134127 lmp.py:372]   Expert 23 |    123 | CPU
DEBUG 01-05 09:19:53.134247.134247 lmp.py:372]   Expert 49 |    123 | CPU
DEBUG 01-05 09:19:53.134698.134698 lmp.py:372]   Expert  3 |    124 | CPU
DEBUG 01-05 09:19:53.134149.134149 lmp.py:372]   Expert  7 |    124 | CPU
DEBUG 01-05 09:19:53.134361.134361 lmp.py:372]   Expert  6 |    128 | CPU
DEBUG 01-05 09:19:53.134097.134097 lmp.py:372]   Expert 14 |    130 | CPU
DEBUG 01-05 09:19:53.134071.134071 lmp.py:372]   Expert 33 |    131 | CPU
DEBUG 01-05 09:19:53.134191.134191 lmp.py:372]   Expert 25 |    135 | CPU
DEBUG 01-05 09:19:53.134880.134880 lmp.py:372]   Expert 53 |    140 | CPU
DEBUG 01-05 09:19:53.134569.134569 lmp.py:372]   Expert 35 |    144 | CPU
DEBUG 01-05 09:19:53.134543.134543 lmp.py:372]   Expert 13 |    148 | CPU
DEBUG 01-05 09:19:53.134756.134756 lmp.py:372]   Expert 34 |    148 | CPU
DEBUG 01-05 09:19:53.134253.134253 lmp.py:372]   Expert 15 |    149 | CPU
DEBUG 01-05 09:19:53.134134.134134 lmp.py:372]   Expert 40 |    153 | CPU
DEBUG 01-05 09:19:53.134870.134870 lmp.py:372]   Expert 59 |    166 | CPU
DEBUG 01-05 09:19:53.134844.134844 lmp.py:372]   Expert 50 |    173 | CPU
DEBUG 01-05 09:19:53.134580.134580 lmp.py:372]   Expert 58 |    179 | GPU
DEBUG 01-05 09:19:53.134792.134792 lmp.py:372]   Expert 24 |    182 | GPU
DEBUG 01-05 09:19:53.134481.134481 lmp.py:372]   Expert 28 |    184 | GPU
DEBUG 01-05 09:19:53.134694.134694 lmp.py:372]   Expert 39 |    184 | GPU
DEBUG 01-05 09:19:53.134337.134337 lmp.py:372]   Expert 61 |    185 | GPU
DEBUG 01-05 09:19:53.134549.134549 lmp.py:372]   Expert 41 |    195 | GPU
DEBUG 01-05 09:19:53.134523.134523 lmp.py:372]   Expert  2 |    204 | GPU
DEBUG 01-05 09:19:53.134497.134497 lmp.py:372]   Expert 27 |    209 | GPU
DEBUG 01-05 09:19:53.134472.134472 lmp.py:372]   Expert 38 |    209 | GPU
DEBUG 01-05 09:19:53.134684.134684 lmp.py:372]   Expert 18 |    219 | GPU
DEBUG 01-05 09:19:53.134565.134565 lmp.py:372]   Expert 11 |    235 | GPU
DEBUG 01-05 09:19:53.134493.134493 lmp.py:372]   Expert 43 |    243 | GPU
DEBUG 01-05 09:19:53.134944.134944 lmp.py:372]   Expert  4 |    249 | GPU
DEBUG 01-05 09:19:53.134156.134156 lmp.py:372]   Expert 37 |    251 | GPU
DEBUG 01-05 09:19:53.134130.134130 lmp.py:372]   Expert 10 |    254 | GPU
DEBUG 01-05 09:19:53.134105.134105 lmp.py:372]   Expert 62 |    254 | GPU
DEBUG 01-05 09:19:53.134940.134940 lmp.py:372]   Expert 17 |    259 | GPU
DEBUG 01-05 09:19:53.134152.134152 lmp.py:372]   Expert 47 |    260 | GPU
DEBUG 01-05 09:19:53.134888.134888 lmp.py:372]   Expert 29 |    269 | GPU
DEBUG 01-05 09:19:53.134100.134100 lmp.py:372]   Expert 63 |    273 | GPU
DEBUG 01-05 09:19:53.134551.134551 lmp.py:372]   Expert  5 |    274 | GPU
DEBUG 01-05 09:19:53.134240.134240 lmp.py:372]   Expert 22 |    275 | GPU
DEBUG 01-05 09:19:53.134645.134645 lmp.py:372]   Expert 30 |    282 | GPU
DEBUG 01-05 09:19:53.134096.134096 lmp.py:372]   Expert 55 |    292 | GPU
DEBUG 01-05 09:19:53.134070.134070 lmp.py:372]   Expert 21 |    298 | GPU
DEBUG 01-05 09:19:53.134044.134044 lmp.py:372]   Expert 31 |    309 | GPU
DEBUG 01-05 09:19:53.134256.134256 lmp.py:372]   Expert 16 |    346 | GPU
DEBUG 01-05 09:19:53.134992.134992 lmp.py:372]   Expert 46 |    360 | GPU
DEBUG 01-05 09:19:53.134635.134635 lmp.py:372]   Expert 36 |    397 | GPU
DEBUG 01-05 09:19:53.134324.134324 lmp.py:372]   Expert 45 |    408 | GPU
DEBUG 01-05 09:19:53.134537.134537 lmp.py:372]   Expert  0 |    418 | GPU
DEBUG 01-05 09:19:53.134226.134226 lmp.py:372]   Expert 42 |    582 | GPU
DEBUG 01-05 09:19:53.134869.134869 lmp.py:373] 
DEBUG 01-05 09:19:53.134869.134869 lmp.py:373]   CPU total tokens: 3550 (28.9%)
DEBUG 01-05 09:19:53.134274.134274 lmp.py:374]   GPU total tokens: 8738 (71.1%)
DEBUG 01-05 09:19:53.134400.134400 cuda_h.py:19] end experts_map_get cost 0.0015077590942382812 seconds
DEBUG 01-05 09:19:53.135328.135328 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.135012.135012 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.135347.135347 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.135773.135773 cuda_h.py:19] end allocate_cuda_memory cost 0.00020956993103027344 seconds
DEBUG 01-05 09:19:53.135523.135523 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.135041.135041 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.135996.135996 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.135645.135645 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36a2b980-e556-41e9-b2ae-ec4b13cd1402
DEBUG 01-05 09:19:53.135348.135348 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.136005.136005 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36a2b980-e556-41e9-b2ae-ec4b13cd1402
DEBUG 01-05 09:19:53.136649.136649 cuda_h.py:19] end load_into_gpu_async cost 0.0013611316680908203 seconds
DEBUG 01-05 09:19:53.136683.136683 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.137351.137351 cuda_h.py:19] end restore_tensors2 cost 0.0003237724304199219 seconds
DEBUG 01-05 09:19:53.137465.137465 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022423267364501953 seconds
DEBUG 01-05 09:19:53.139263.139263 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004946231842041016 seconds
DEBUG 01-05 09:19:53.140953.140953 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.140791.140791 lmp.py:419] 
DEBUG 01-05 09:19:53.140791.140791 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.140210.140210 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-05 09:19:53.140290.140290 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.151994.151994 mlpmodule.py:704] group tensors cost 0.01108860969543457 s
DEBUG 01-05 09:19:53.154554.154554 mlpmodule.py:742] pad cost 0.0016758441925048828 s
DEBUG 01-05 09:19:53.154154.154154 mlpmodule.py:748] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-05 09:19:53.154395.154395 mlpmodule.py:753] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-05 09:19:53.166977.166977 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.167936.167936 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.167880.167880 mlpmodule.py:773] group_w3 first element: 0.00066375732421875
WARNING 01-05 09:19:53.167480.167480 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.186087.186087 mlpmodule.py:793] group einsum cost 0.03244972229003906 s
DEBUG 01-05 09:19:53.187176.187176 mlpmodule.py:801] cpy2cputensor cost 0.0008647441864013672 s
DEBUG 01-05 09:19:53.223868.223868 cuda_h.py:19] end wait_cetm_experts cost 0.08342194557189941 seconds
DEBUG 01-05 09:19:53.223105.223105 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.224094.224094 cuda_h.py:19] end gpu_sexperts cost 0.0006158351898193359 seconds
DEBUG 01-05 09:19:53.224752.224752 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:19:53.224290.224290 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-05 09:19:53.224345.224345 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.814697265625e-05 seconds
DEBUG 01-05 09:19:53.224962.224962 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.843971252441406e-05 seconds
DEBUG 01-05 09:19:53.224281.224281 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.224514.224514 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36a2b980-e556-41e9-b2ae-ec4b13cd1402
DEBUG 01-05 09:19:53.224136.224136 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.225603.225603 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.225638.225638 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.229888.229888 cuda_h.py:19] end allocate_cuda_memory cost 0.004075765609741211 seconds
DEBUG 01-05 09:19:53.229136.229136 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.229044.229044 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.229689.229689 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.229160.229160 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aef0a802-3cad-4ebf-8c92-8d2086b5ac19
DEBUG 01-05 09:19:53.229057.229057 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.229913.229913 client.py:127] Model loaded
DEBUG 01-05 09:19:53.229147.229147 cuda_h.py:19] end wait_experts cost 0.0050678253173828125 seconds
DEBUG 01-05 09:19:53.229188.229188 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.229229.229229 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.230400.230400 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aef0a802-3cad-4ebf-8c92-8d2086b5ac19
DEBUG 01-05 09:19:53.230125.230125 cuda_h.py:19] end load_into_gpu_async cost 0.0012140274047851562 seconds
DEBUG 01-05 09:19:53.230841.230841 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.230713.230713 cuda_h.py:19] end restore_tensors2 cost 8.606910705566406e-05 seconds
DEBUG 01-05 09:19:53.230760.230760 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0056650638580322266 seconds
DEBUG 01-05 09:19:53.231232.231232 mlpmodule.py:531] gpu group tensors cost 0.0010046958923339844 s
INFO 01-05 09:19:53.231985.231985 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aef0a802-3cad-4ebf-8c92-8d2086b5ac19
DEBUG 01-05 09:19:53.233273.233273 mlpmodule.py:564] gpu pad cost 0.0020835399627685547 s
DEBUG 01-05 09:19:53.233797.233797 mlpmodule.py:582] gpu group einsum cost 0.0005557537078857422 s
DEBUG 01-05 09:19:53.237271.237271 mlpmodule.py:611] gpu experts func einsum cost 0.007494926452636719 s
DEBUG 01-05 09:19:53.237824.237824 cuda_h.py:19] end gpu_experts cost 0.007708549499511719 seconds
DEBUG 01-05 09:19:53.237277.237277 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:53.240563.240563 client.py:127] Model loaded
DEBUG 01-05 09:19:53.240883.240883 cuda_h.py:19] end sllm_worker_task cost 0.015099287033081055 seconds
DEBUG 01-05 09:19:53.240057.240057 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002510547637939453 seconds
DEBUG 01-05 09:19:53.240447.240447 cuda_h.py:19] end layer_moe_generate_21 cost 0.10762786865234375 seconds
DEBUG 01-05 09:19:53.240015.240015 mlpmodule.py:662]  experts func einsum cost 0.10016155242919922 s
DEBUG 01-05 09:19:53.240767.240767 lmp.py:214] -------------------------------- end layer 21 --------------------------------
DEBUG 01-05 09:19:53.240796.240796 lmp.py:173] -------------------------------- start layer 22 --------------------------------
DEBUG 01-05 09:19:53.240069.240069 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.241668.241668 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.243533.243533 cuda_h.py:19] end self_attn cost 0.002437591552734375 seconds
DEBUG 01-05 09:19:53.244788.244788 cuda_h.py:19] end iln_self_attn_paln cost 0.0030601024627685547 seconds
DEBUG 01-05 09:19:53.244916.244916 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-05 09:19:53.244109.244109 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.244806.244806 cuda_h.py:19] end gate cost 0.0005843639373779297 seconds
DEBUG 01-05 09:19:53.244920.244920 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.245480.245480 lmp.py:361] 
DEBUG 01-05 09:19:53.245480.245480 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.245382.245382 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.245747.245747 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.245012.245012 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.245039.245039 lmp.py:365] 
DEBUG 01-05 09:19:53.245039.245039 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.245444.245444 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.245809.245809 lmp.py:372]   Expert 11 |     58 | CPU
DEBUG 01-05 09:19:53.245975.245975 lmp.py:372]   Expert 49 |     61 | CPU
DEBUG 01-05 09:19:53.245903.245903 lmp.py:372]   Expert 32 |     66 | CPU
DEBUG 01-05 09:19:53.245499.245499 lmp.py:372]   Expert  6 |     77 | CPU
DEBUG 01-05 09:19:53.245950.245950 lmp.py:372]   Expert 45 |     77 | CPU
DEBUG 01-05 09:19:53.245878.245878 lmp.py:372]   Expert 63 |     80 | CPU
DEBUG 01-05 09:19:53.245521.245521 lmp.py:372]   Expert 22 |     84 | CPU
DEBUG 01-05 09:19:53.245210.245210 lmp.py:372]   Expert 54 |     84 | CPU
DEBUG 01-05 09:19:53.245184.245184 lmp.py:372]   Expert  1 |     86 | CPU
DEBUG 01-05 09:19:53.245019.245019 lmp.py:372]   Expert  7 |     90 | CPU
DEBUG 01-05 09:19:53.245470.245470 lmp.py:372]   Expert 44 |     90 | CPU
DEBUG 01-05 09:19:53.245444.245444 lmp.py:372]   Expert 12 |     94 | CPU
DEBUG 01-05 09:19:53.245657.245657 lmp.py:372]   Expert 46 |     95 | CPU
DEBUG 01-05 09:19:53.245869.245869 lmp.py:372]   Expert 41 |     96 | CPU
DEBUG 01-05 09:19:53.245082.245082 lmp.py:372]   Expert 42 |     98 | CPU
DEBUG 01-05 09:19:53.245009.245009 lmp.py:372]   Expert 60 |    101 | CPU
DEBUG 01-05 09:19:53.245937.245937 lmp.py:372]   Expert 15 |    105 | CPU
DEBUG 01-05 09:19:53.245818.245818 lmp.py:372]   Expert 52 |    109 | CPU
DEBUG 01-05 09:19:53.245746.245746 lmp.py:372]   Expert 37 |    110 | CPU
DEBUG 01-05 09:19:53.245197.245197 lmp.py:372]   Expert 13 |    112 | CPU
DEBUG 01-05 09:19:53.245324.245324 lmp.py:372]   Expert 10 |    120 | CPU
DEBUG 01-05 09:19:53.245536.245536 lmp.py:372]   Expert 61 |    122 | CPU
DEBUG 01-05 09:19:53.245749.245749 lmp.py:372]   Expert 24 |    124 | CPU
DEBUG 01-05 09:19:53.245107.245107 lmp.py:372]   Expert  3 |    125 | CPU
DEBUG 01-05 09:19:53.245035.245035 lmp.py:372]   Expert 31 |    125 | CPU
DEBUG 01-05 09:19:53.245962.245962 lmp.py:372]   Expert 62 |    127 | CPU
DEBUG 01-05 09:19:53.245936.245936 lmp.py:372]   Expert  9 |    129 | CPU
DEBUG 01-05 09:19:53.245910.245910 lmp.py:372]   Expert 57 |    132 | CPU
DEBUG 01-05 09:19:53.245408.245408 lmp.py:372]   Expert 48 |    134 | CPU
DEBUG 01-05 09:19:53.245243.245243 lmp.py:372]   Expert 30 |    138 | CPU
DEBUG 01-05 09:19:53.245978.245978 lmp.py:372]   Expert 28 |    146 | CPU
DEBUG 01-05 09:19:53.245952.245952 lmp.py:372]   Expert 21 |    147 | CPU
DEBUG 01-05 09:19:53.245165.245165 lmp.py:372]   Expert 47 |    156 | GPU
DEBUG 01-05 09:19:53.245377.245377 lmp.py:372]   Expert 27 |    157 | GPU
DEBUG 01-05 09:19:53.245497.245497 lmp.py:372]   Expert 26 |    170 | GPU
DEBUG 01-05 09:19:53.245425.245425 lmp.py:372]   Expert 58 |    179 | GPU
DEBUG 01-05 09:19:53.245545.245545 lmp.py:372]   Expert  0 |    184 | GPU
DEBUG 01-05 09:19:53.245995.245995 lmp.py:372]   Expert 43 |    184 | GPU
DEBUG 01-05 09:19:53.245208.245208 lmp.py:372]   Expert 51 |    190 | GPU
DEBUG 01-05 09:19:53.245420.245420 lmp.py:372]   Expert 50 |    191 | GPU
DEBUG 01-05 09:19:53.245633.245633 lmp.py:372]   Expert 39 |    202 | GPU
DEBUG 01-05 09:19:53.245845.245845 lmp.py:372]   Expert  8 |    209 | GPU
DEBUG 01-05 09:19:53.246727.246727 lmp.py:372]   Expert 16 |    211 | GPU
DEBUG 01-05 09:19:53.246178.246178 lmp.py:372]   Expert 19 |    212 | GPU
DEBUG 01-05 09:19:53.246628.246628 lmp.py:372]   Expert 38 |    212 | GPU
DEBUG 01-05 09:19:53.246556.246556 lmp.py:372]   Expert  2 |    231 | GPU
DEBUG 01-05 09:19:53.246246.246246 lmp.py:372]   Expert 56 |    253 | GPU
DEBUG 01-05 09:19:53.246696.246696 lmp.py:372]   Expert 34 |    261 | GPU
DEBUG 01-05 09:19:53.246339.246339 lmp.py:372]   Expert 35 |    274 | GPU
DEBUG 01-05 09:19:53.246552.246552 lmp.py:372]   Expert  4 |    275 | GPU
DEBUG 01-05 09:19:53.246003.246003 lmp.py:372]   Expert 17 |    280 | GPU
DEBUG 01-05 09:19:53.246215.246215 lmp.py:372]   Expert 33 |    280 | GPU
DEBUG 01-05 09:19:53.246666.246666 lmp.py:372]   Expert 23 |    281 | GPU
DEBUG 01-05 09:19:53.246355.246355 lmp.py:372]   Expert 20 |    308 | GPU
DEBUG 01-05 09:19:53.246806.246806 lmp.py:372]   Expert 53 |    319 | GPU
DEBUG 01-05 09:19:53.246449.246449 lmp.py:372]   Expert 29 |    333 | GPU
DEBUG 01-05 09:19:53.246662.246662 lmp.py:372]   Expert 18 |    338 | GPU
DEBUG 01-05 09:19:53.246874.246874 lmp.py:372]   Expert 25 |    345 | GPU
DEBUG 01-05 09:19:53.246848.246848 lmp.py:372]   Expert 59 |    366 | GPU
DEBUG 01-05 09:19:53.246584.246584 lmp.py:372]   Expert 40 |    370 | GPU
DEBUG 01-05 09:19:53.246796.246796 lmp.py:372]   Expert 55 |    377 | GPU
DEBUG 01-05 09:19:53.246678.246678 lmp.py:372]   Expert 14 |    438 | GPU
DEBUG 01-05 09:19:53.246129.246129 lmp.py:372]   Expert 36 |    575 | GPU
DEBUG 01-05 09:19:53.246579.246579 lmp.py:372]   Expert  5 |    585 | GPU
DEBUG 01-05 09:19:53.246507.246507 lmp.py:373] 
DEBUG 01-05 09:19:53.246507.246507 lmp.py:373]   CPU total tokens: 3342 (27.2%)
DEBUG 01-05 09:19:53.246912.246912 lmp.py:374]   GPU total tokens: 8946 (72.8%)
DEBUG 01-05 09:19:53.246561.246561 cuda_h.py:19] end experts_map_get cost 0.0015320777893066406 seconds
DEBUG 01-05 09:19:53.246158.246158 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.246703.246703 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.246655.246655 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.246465.246465 cuda_h.py:19] end allocate_cuda_memory cost 0.00024580955505371094 seconds
DEBUG 01-05 09:19:53.246977.246977 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.246826.246826 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.247496.247496 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.247907.247907 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97061233-2646-440a-925f-4690b9847ece
DEBUG 01-05 09:19:53.290571.290571 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.291573.291573 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97061233-2646-440a-925f-4690b9847ece
DEBUG 01-05 09:19:53.291647.291647 cuda_h.py:19] end load_into_gpu_async cost 0.04470467567443848 seconds
DEBUG 01-05 09:19:53.291873.291873 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.292475.292475 cuda_h.py:19] end restore_tensors2 cost 0.00034737586975097656 seconds
DEBUG 01-05 09:19:53.292543.292543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.045644521713256836 seconds
DEBUG 01-05 09:19:53.294592.294592 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.048326730728149414 seconds
DEBUG 01-05 09:19:53.294660.294660 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.294458.294458 lmp.py:419] 
DEBUG 01-05 09:19:53.294458.294458 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.294784.294784 cuda_h.py:19] end cpu_experts_submit cost 0.00011920928955078125 seconds
DEBUG 01-05 09:19:53.295911.295911 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.313813.313813 mlpmodule.py:704] group tensors cost 0.01769733428955078 s
DEBUG 01-05 09:19:53.315926.315926 mlpmodule.py:742] pad cost 0.0016469955444335938 s
DEBUG 01-05 09:19:53.315156.315156 mlpmodule.py:748] create cpu tensor cost 5.030632019042969e-05 s
DEBUG 01-05 09:19:53.315866.315866 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-05 09:19:53.327331.327331 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.327251.327251 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.328950.328950 mlpmodule.py:773] group_w3 first element: 0.025390625
WARNING 01-05 09:19:53.328351.328351 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.348860.348860 mlpmodule.py:793] group einsum cost 0.03256726264953613 s
DEBUG 01-05 09:19:53.349802.349802 mlpmodule.py:801] cpy2cputensor cost 0.0012180805206298828 s
DEBUG 01-05 09:19:53.384878.384878 cuda_h.py:19] end wait_cetm_experts cost 0.0889434814453125 seconds
DEBUG 01-05 09:19:53.384070.384070 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.384575.384575 cuda_h.py:19] end gpu_sexperts cost 0.0006091594696044922 seconds
DEBUG 01-05 09:19:53.384716.384716 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:19:53.384777.384777 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-05 09:19:53.385423.385423 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.9577484130859375e-05 seconds
DEBUG 01-05 09:19:53.385278.385278 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 9.059906005859375e-05 seconds
DEBUG 01-05 09:19:53.385074.385074 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.385022.385022 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97061233-2646-440a-925f-4690b9847ece
DEBUG 01-05 09:19:53.385968.385968 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.385349.385349 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.385907.385907 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.389717.389717 cuda_h.py:19] end allocate_cuda_memory cost 0.004171609878540039 seconds
DEBUG 01-05 09:19:53.389773.389773 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.389251.389251 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.389180.389180 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.389936.389936 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3e0da661-7529-4b44-9615-173eb893d0f6
DEBUG 01-05 09:19:53.390303.390303 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.390595.390595 client.py:127] Model loaded
DEBUG 01-05 09:19:53.390472.390472 cuda_h.py:19] end wait_experts cost 0.005143404006958008 seconds
DEBUG 01-05 09:19:53.390513.390513 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.390315.390315 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.390719.390719 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3e0da661-7529-4b44-9615-173eb893d0f6
DEBUG 01-05 09:19:53.391668.391668 cuda_h.py:19] end load_into_gpu_async cost 0.0011839866638183594 seconds
DEBUG 01-05 09:19:53.391477.391477 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.391448.391448 cuda_h.py:19] end restore_tensors2 cost 8.893013000488281e-05 seconds
DEBUG 01-05 09:19:53.391542.391542 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005727529525756836 seconds
DEBUG 01-05 09:19:53.391772.391772 mlpmodule.py:531] gpu group tensors cost 0.0010905265808105469 s
INFO 01-05 09:19:53.391336.391336 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3e0da661-7529-4b44-9615-173eb893d0f6
DEBUG 01-05 09:19:53.393749.393749 mlpmodule.py:564] gpu pad cost 0.0019731521606445312 s
DEBUG 01-05 09:19:53.394585.394585 mlpmodule.py:582] gpu group einsum cost 0.0005431175231933594 s
DEBUG 01-05 09:19:53.397406.397406 mlpmodule.py:611] gpu experts func einsum cost 0.007353782653808594 s
DEBUG 01-05 09:19:53.397680.397680 cuda_h.py:19] end gpu_experts cost 0.0075380802154541016 seconds
DEBUG 01-05 09:19:53.397251.397251 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:53.400580.400580 client.py:127] Model loaded
DEBUG 01-05 09:19:53.400284.400284 cuda_h.py:19] end sllm_worker_task cost 0.015266895294189453 seconds
DEBUG 01-05 09:19:53.400226.400226 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0027914047241210938 seconds
DEBUG 01-05 09:19:53.400774.400774 mlpmodule.py:662]  experts func einsum cost 0.10556411743164062 s
DEBUG 01-05 09:19:53.401059.401059 cuda_h.py:19] end layer_moe_generate_22 cost 0.1569054126739502 seconds
DEBUG 01-05 09:19:53.401115.401115 lmp.py:214] -------------------------------- end layer 22 --------------------------------
DEBUG 01-05 09:19:53.401361.401361 lmp.py:173] -------------------------------- start layer 23 --------------------------------
DEBUG 01-05 09:19:53.401965.401965 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.401782.401782 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.404601.404601 cuda_h.py:19] end self_attn cost 0.002442598342895508 seconds
DEBUG 01-05 09:19:53.404121.404121 cuda_h.py:19] end iln_self_attn_paln cost 0.003069162368774414 seconds
DEBUG 01-05 09:19:53.404726.404726 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-05 09:19:53.404635.404635 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.405417.405417 cuda_h.py:19] end gate cost 0.0005772113800048828 seconds
DEBUG 01-05 09:19:53.405531.405531 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.405753.405753 lmp.py:361] 
DEBUG 01-05 09:19:53.405753.405753 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.405893.405893 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.405781.405781 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.405808.405808 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.405120.405120 lmp.py:365] 
DEBUG 01-05 09:19:53.405120.405120 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.405002.405002 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.405128.405128 lmp.py:372]   Expert 27 |     66 | CPU
DEBUG 01-05 09:19:53.405771.405771 lmp.py:372]   Expert  5 |     67 | CPU
DEBUG 01-05 09:19:53.405699.405699 lmp.py:372]   Expert 49 |     67 | CPU
DEBUG 01-05 09:19:53.405296.405296 lmp.py:372]   Expert 19 |     76 | CPU
DEBUG 01-05 09:19:53.405223.405223 lmp.py:372]   Expert 44 |     84 | CPU
DEBUG 01-05 09:19:53.405151.405151 lmp.py:372]   Expert  7 |     94 | CPU
DEBUG 01-05 09:19:53.405033.405033 lmp.py:372]   Expert 17 |     98 | CPU
DEBUG 01-05 09:19:53.405722.405722 lmp.py:372]   Expert 53 |    100 | CPU
DEBUG 01-05 09:19:53.405173.405173 lmp.py:372]   Expert 38 |    107 | CPU
DEBUG 01-05 09:19:53.405008.405008 lmp.py:372]   Expert 55 |    109 | CPU
DEBUG 01-05 09:19:53.405220.405220 lmp.py:372]   Expert 34 |    119 | CPU
DEBUG 01-05 09:19:53.405433.405433 lmp.py:372]   Expert 40 |    120 | CPU
DEBUG 01-05 09:19:53.405645.405645 lmp.py:372]   Expert 58 |    121 | CPU
DEBUG 01-05 09:19:53.405619.405619 lmp.py:372]   Expert 43 |    122 | CPU
DEBUG 01-05 09:19:53.405832.405832 lmp.py:372]   Expert  4 |    124 | CPU
DEBUG 01-05 09:19:53.406283.406283 lmp.py:372]   Expert 22 |    124 | CPU
DEBUG 01-05 09:19:53.406733.406733 lmp.py:372]   Expert 25 |    126 | CPU
DEBUG 01-05 09:19:53.406423.406423 lmp.py:372]   Expert 52 |    129 | CPU
DEBUG 01-05 09:19:53.406589.406589 lmp.py:372]   Expert 16 |    131 | CPU
DEBUG 01-05 09:19:53.406563.406563 lmp.py:372]   Expert 35 |    131 | CPU
DEBUG 01-05 09:19:53.406299.406299 lmp.py:372]   Expert  1 |    134 | CPU
DEBUG 01-05 09:19:53.406273.406273 lmp.py:372]   Expert 51 |    135 | CPU
DEBUG 01-05 09:19:53.406008.406008 lmp.py:372]   Expert  6 |    137 | CPU
DEBUG 01-05 09:19:53.406174.406174 lmp.py:372]   Expert 42 |    156 | CPU
DEBUG 01-05 09:19:53.406102.406102 lmp.py:372]   Expert  9 |    157 | CPU
DEBUG 01-05 09:19:53.406791.406791 lmp.py:372]   Expert 30 |    160 | CPU
DEBUG 01-05 09:19:53.406719.406719 lmp.py:372]   Expert 63 |    160 | CPU
DEBUG 01-05 09:19:53.406693.406693 lmp.py:372]   Expert 47 |    161 | CPU
DEBUG 01-05 09:19:53.406144.406144 lmp.py:372]   Expert 13 |    174 | CPU
DEBUG 01-05 09:19:53.406787.406787 lmp.py:372]   Expert 45 |    176 | CPU
DEBUG 01-05 09:19:53.406476.406476 lmp.py:372]   Expert  0 |    177 | CPU
DEBUG 01-05 09:19:53.406689.406689 lmp.py:372]   Expert 36 |    178 | CPU
DEBUG 01-05 09:19:53.406378.406378 lmp.py:372]   Expert 23 |    189 | GPU
DEBUG 01-05 09:19:53.406783.406783 lmp.py:372]   Expert 62 |    190 | GPU
DEBUG 01-05 09:19:53.406757.406757 lmp.py:372]   Expert 46 |    192 | GPU
DEBUG 01-05 09:19:53.406877.406877 lmp.py:372]   Expert 26 |    195 | GPU
DEBUG 01-05 09:19:53.406566.406566 lmp.py:372]   Expert  2 |    197 | GPU
DEBUG 01-05 09:19:53.406540.406540 lmp.py:372]   Expert 28 |    200 | GPU
DEBUG 01-05 09:19:53.406514.406514 lmp.py:372]   Expert 11 |    203 | GPU
DEBUG 01-05 09:19:53.406488.406488 lmp.py:372]   Expert 39 |    205 | GPU
DEBUG 01-05 09:19:53.406700.406700 lmp.py:372]   Expert 60 |    205 | GPU
DEBUG 01-05 09:19:53.406674.406674 lmp.py:372]   Expert  3 |    208 | GPU
DEBUG 01-05 09:19:53.406841.406841 lmp.py:372]   Expert 15 |    208 | GPU
DEBUG 01-05 09:19:53.406768.406768 lmp.py:372]   Expert 24 |    208 | GPU
DEBUG 01-05 09:19:53.406650.406650 lmp.py:372]   Expert 61 |    211 | GPU
DEBUG 01-05 09:19:53.406339.406339 lmp.py:372]   Expert 41 |    218 | GPU
DEBUG 01-05 09:19:53.406313.406313 lmp.py:372]   Expert 12 |    226 | GPU
DEBUG 01-05 09:19:53.406049.406049 lmp.py:372]   Expert 29 |    252 | GPU
DEBUG 01-05 09:19:53.406261.406261 lmp.py:372]   Expert 14 |    256 | GPU
DEBUG 01-05 09:19:53.406235.406235 lmp.py:372]   Expert 20 |    260 | GPU
DEBUG 01-05 09:19:53.406355.406355 lmp.py:372]   Expert 21 |    272 | GPU
DEBUG 01-05 09:19:53.406567.406567 lmp.py:372]   Expert 33 |    280 | GPU
DEBUG 01-05 09:19:53.406257.406257 lmp.py:372]   Expert  8 |    286 | GPU
DEBUG 01-05 09:19:53.406946.406946 lmp.py:372]   Expert 32 |    290 | GPU
DEBUG 01-05 09:19:53.406920.406920 lmp.py:372]   Expert 59 |    294 | GPU
DEBUG 01-05 09:19:53.406894.406894 lmp.py:372]   Expert 57 |    295 | GPU
DEBUG 01-05 09:19:53.406014.406014 lmp.py:372]   Expert 10 |    307 | GPU
DEBUG 01-05 09:19:53.406465.406465 lmp.py:372]   Expert 31 |    310 | GPU
DEBUG 01-05 09:19:53.406439.406439 lmp.py:372]   Expert 37 |    310 | GPU
DEBUG 01-05 09:19:53.406175.406175 lmp.py:372]   Expert 18 |    318 | GPU
DEBUG 01-05 09:19:53.406149.406149 lmp.py:372]   Expert 50 |    318 | GPU
DEBUG 01-05 09:19:53.406123.406123 lmp.py:372]   Expert 56 |    351 | GPU
DEBUG 01-05 09:19:53.406812.406812 lmp.py:372]   Expert 48 |    406 | GPU
DEBUG 01-05 09:19:53.406263.406263 lmp.py:372]   Expert 54 |    408 | GPU
DEBUG 01-05 09:19:53.406098.406098 lmp.py:373] 
DEBUG 01-05 09:19:53.406098.406098 lmp.py:373]   CPU total tokens: 4020 (32.7%)
DEBUG 01-05 09:19:53.406218.406218 lmp.py:374]   GPU total tokens: 8268 (67.3%)
DEBUG 01-05 09:19:53.406675.406675 cuda_h.py:19] end experts_map_get cost 0.0015175342559814453 seconds
DEBUG 01-05 09:19:53.406080.406080 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.406433.406433 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.407437.407437 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.407393.407393 cuda_h.py:19] end allocate_cuda_memory cost 0.0002143383026123047 seconds
DEBUG 01-05 09:19:53.407474.407474 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.407323.407323 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.407086.407086 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.407020.407020 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 315144d9-1acd-48bc-874b-e3f380395535
DEBUG 01-05 09:19:53.407477.407477 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.408482.408482 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 315144d9-1acd-48bc-874b-e3f380395535
DEBUG 01-05 09:19:53.408173.408173 cuda_h.py:19] end load_into_gpu_async cost 0.001257181167602539 seconds
DEBUG 01-05 09:19:53.408922.408922 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.409066.409066 cuda_h.py:19] end restore_tensors2 cost 0.00032639503479003906 seconds
DEBUG 01-05 09:19:53.409419.409419 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00214385986328125 seconds
DEBUG 01-05 09:19:53.411217.411217 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004850149154663086 seconds
DEBUG 01-05 09:19:53.411715.411715 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.411268.411268 lmp.py:419] 
DEBUG 01-05 09:19:53.411268.411268 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.411018.411018 cuda_h.py:19] end cpu_experts_submit cost 0.00012493133544921875 seconds
DEBUG 01-05 09:19:53.411622.411622 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.422524.422524 mlpmodule.py:704] group tensors cost 0.010616540908813477 s
DEBUG 01-05 09:19:53.425549.425549 mlpmodule.py:742] pad cost 0.0017275810241699219 s
DEBUG 01-05 09:19:53.425395.425395 mlpmodule.py:748] create cpu tensor cost 5.2928924560546875e-05 s
DEBUG 01-05 09:19:53.425867.425867 mlpmodule.py:753] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-05 09:19:53.437762.437762 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.437344.437344 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.437389.437389 mlpmodule.py:773] group_w3 first element: -0.0137939453125
WARNING 01-05 09:19:53.437115.437115 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.456577.456577 mlpmodule.py:793] group einsum cost 0.030994415283203125 s
DEBUG 01-05 09:19:53.458630.458630 mlpmodule.py:801] cpy2cputensor cost 0.001210927963256836 s
DEBUG 01-05 09:19:53.498938.498938 cuda_h.py:19] end wait_cetm_experts cost 0.08635592460632324 seconds
DEBUG 01-05 09:19:53.498538.498538 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.498191.498191 cuda_h.py:19] end gpu_sexperts cost 0.0004763603210449219 seconds
DEBUG 01-05 09:19:53.499173.499173 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:19:53.499704.499704 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-05 09:19:53.499560.499560 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.1948089599609375e-05 seconds
DEBUG 01-05 09:19:53.499224.499224 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.200241088867188e-05 seconds
DEBUG 01-05 09:19:53.499496.499496 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.499974.499974 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 315144d9-1acd-48bc-874b-e3f380395535
DEBUG 01-05 09:19:53.499337.499337 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.499115.499115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.499766.499766 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.503860.503860 cuda_h.py:19] end allocate_cuda_memory cost 0.0035698413848876953 seconds
DEBUG 01-05 09:19:53.503439.503439 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.503963.503963 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.503554.503554 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.503642.503642 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 98cee70f-d101-4cdb-a8ea-b67b1a47b5d1
DEBUG 01-05 09:19:53.503301.503301 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.503447.503447 client.py:127] Model loaded
DEBUG 01-05 09:19:53.503250.503250 cuda_h.py:19] end wait_experts cost 0.004488229751586914 seconds
DEBUG 01-05 09:19:53.503099.503099 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.503378.503378 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.504504.504504 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 98cee70f-d101-4cdb-a8ea-b67b1a47b5d1
DEBUG 01-05 09:19:53.504612.504612 cuda_h.py:19] end load_into_gpu_async cost 0.0011794567108154297 seconds
DEBUG 01-05 09:19:53.504176.504176 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.504425.504425 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-05 09:19:53.504426.504426 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005112409591674805 seconds
DEBUG 01-05 09:19:53.505321.505321 mlpmodule.py:531] gpu group tensors cost 0.0011706352233886719 s
INFO 01-05 09:19:53.505524.505524 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 98cee70f-d101-4cdb-a8ea-b67b1a47b5d1
DEBUG 01-05 09:19:53.507894.507894 mlpmodule.py:564] gpu pad cost 0.0019571781158447266 s
DEBUG 01-05 09:19:53.507882.507882 mlpmodule.py:582] gpu group einsum cost 0.0005745887756347656 s
DEBUG 01-05 09:19:53.511299.511299 mlpmodule.py:611] gpu experts func einsum cost 0.007441520690917969 s
DEBUG 01-05 09:19:53.511335.511335 cuda_h.py:19] end gpu_experts cost 0.007623434066772461 seconds
DEBUG 01-05 09:19:53.511191.511191 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:53.512179.512179 mlpmodule.py:662]  experts func einsum cost 0.10005569458007812 s
INFO 01-05 09:19:53.513117.513117 client.py:127] Model loaded
DEBUG 01-05 09:19:53.513914.513914 cuda_h.py:19] end sllm_worker_task cost 0.013583660125732422 seconds
DEBUG 01-05 09:19:53.513493.513493 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0016620159149169922 seconds
DEBUG 01-05 09:19:53.513557.513557 cuda_h.py:19] end layer_moe_generate_23 cost 0.10865545272827148 seconds
DEBUG 01-05 09:19:53.513484.513484 lmp.py:214] -------------------------------- end layer 23 --------------------------------
DEBUG 01-05 09:19:53.513684.513684 lmp.py:173] -------------------------------- start layer 24 --------------------------------
DEBUG 01-05 09:19:53.513665.513665 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.513032.513032 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.516444.516444 cuda_h.py:19] end self_attn cost 0.00235748291015625 seconds
DEBUG 01-05 09:19:53.516149.516149 cuda_h.py:19] end iln_self_attn_paln cost 0.002961874008178711 seconds
DEBUG 01-05 09:19:53.516800.516800 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-05 09:19:53.516517.516517 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.517570.517570 cuda_h.py:19] end gate cost 0.0005679130554199219 seconds
DEBUG 01-05 09:19:53.517976.517976 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.517675.517675 lmp.py:361] 
DEBUG 01-05 09:19:53.517675.517675 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.517206.517206 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.517187.517187 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.517830.517830 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.517565.517565 lmp.py:365] 
DEBUG 01-05 09:19:53.517565.517565 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.517016.517016 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.517236.517236 lmp.py:372]   Expert 43 |     53 | CPU
DEBUG 01-05 09:19:53.517686.517686 lmp.py:372]   Expert 42 |     59 | CPU
DEBUG 01-05 09:19:53.517660.517660 lmp.py:372]   Expert 47 |     60 | CPU
DEBUG 01-05 09:19:53.517919.517919 lmp.py:372]   Expert 25 |     66 | CPU
DEBUG 01-05 09:19:53.517178.517178 lmp.py:372]   Expert  6 |     72 | CPU
DEBUG 01-05 09:19:53.517675.517675 lmp.py:372]   Expert 62 |     86 | CPU
DEBUG 01-05 09:19:53.517696.517696 lmp.py:372]   Expert 44 |     88 | CPU
DEBUG 01-05 09:19:53.517478.517478 lmp.py:372]   Expert  5 |     89 | CPU
DEBUG 01-05 09:19:53.517736.517736 lmp.py:372]   Expert 35 |     94 | CPU
DEBUG 01-05 09:19:53.517280.517280 lmp.py:372]   Expert 16 |     95 | CPU
DEBUG 01-05 09:19:53.517062.517062 lmp.py:372]   Expert 55 |     95 | CPU
DEBUG 01-05 09:19:53.517082.517082 lmp.py:372]   Expert 48 |     96 | CPU
DEBUG 01-05 09:19:53.517864.517864 lmp.py:372]   Expert 60 |     98 | CPU
DEBUG 01-05 09:19:53.517646.517646 lmp.py:372]   Expert 54 |    105 | CPU
DEBUG 01-05 09:19:53.517190.517190 lmp.py:372]   Expert 29 |    113 | CPU
DEBUG 01-05 09:19:53.517972.517972 lmp.py:372]   Expert 30 |    113 | CPU
DEBUG 01-05 09:19:53.517515.517515 lmp.py:372]   Expert 56 |    125 | CPU
DEBUG 01-05 09:19:53.517059.517059 lmp.py:372]   Expert 22 |    132 | CPU
DEBUG 01-05 09:19:53.518986.518986 lmp.py:372]   Expert 51 |    141 | CPU
DEBUG 01-05 09:19:53.518007.518007 lmp.py:372]   Expert 36 |    143 | CPU
DEBUG 01-05 09:19:53.518789.518789 lmp.py:372]   Expert 61 |    149 | CPU
DEBUG 01-05 09:19:53.518571.518571 lmp.py:372]   Expert  7 |    160 | CPU
DEBUG 01-05 09:19:53.518114.518114 lmp.py:372]   Expert 38 |    162 | CPU
DEBUG 01-05 09:19:53.518658.518658 lmp.py:372]   Expert 28 |    163 | CPU
DEBUG 01-05 09:19:53.518440.518440 lmp.py:372]   Expert  1 |    166 | CPU
DEBUG 01-05 09:19:53.518222.518222 lmp.py:372]   Expert 49 |    167 | CPU
DEBUG 01-05 09:19:53.518765.518765 lmp.py:372]   Expert  4 |    169 | CPU
DEBUG 01-05 09:19:53.518309.518309 lmp.py:372]   Expert 20 |    174 | CPU
DEBUG 01-05 09:19:53.518614.518614 lmp.py:372]   Expert 59 |    174 | CPU
DEBUG 01-05 09:19:53.518919.518919 lmp.py:372]   Expert 31 |    177 | CPU
DEBUG 01-05 09:19:53.518462.518462 lmp.py:372]   Expert  0 |    178 | CPU
DEBUG 01-05 09:19:53.518244.518244 lmp.py:372]   Expert 17 |    181 | CPU
DEBUG 01-05 09:19:53.518788.518788 lmp.py:372]   Expert 21 |    186 | GPU
DEBUG 01-05 09:19:53.518570.518570 lmp.py:372]   Expert 14 |    191 | GPU
DEBUG 01-05 09:19:53.518113.518113 lmp.py:372]   Expert 15 |    191 | GPU
DEBUG 01-05 09:19:53.518657.518657 lmp.py:372]   Expert 46 |    192 | GPU
DEBUG 01-05 09:19:53.518201.518201 lmp.py:372]   Expert 53 |    194 | GPU
DEBUG 01-05 09:19:53.518744.518744 lmp.py:372]   Expert 19 |    200 | GPU
DEBUG 01-05 09:19:53.518288.518288 lmp.py:372]   Expert 41 |    200 | GPU
DEBUG 01-05 09:19:53.518831.518831 lmp.py:372]   Expert 40 |    201 | GPU
DEBUG 01-05 09:19:53.518851.518851 lmp.py:372]   Expert  3 |    206 | GPU
DEBUG 01-05 09:19:53.518633.518633 lmp.py:372]   Expert 63 |    207 | GPU
DEBUG 01-05 09:19:53.518177.518177 lmp.py:372]   Expert 10 |    218 | GPU
DEBUG 01-05 09:19:53.518721.518721 lmp.py:372]   Expert 57 |    219 | GPU
DEBUG 01-05 09:19:53.518502.518502 lmp.py:372]   Expert 34 |    222 | GPU
DEBUG 01-05 09:19:53.518046.518046 lmp.py:372]   Expert 24 |    224 | GPU
DEBUG 01-05 09:19:53.518590.518590 lmp.py:372]   Expert 37 |    226 | GPU
DEBUG 01-05 09:19:53.518371.518371 lmp.py:372]   Expert 50 |    234 | GPU
DEBUG 01-05 09:19:53.518915.518915 lmp.py:372]   Expert 26 |    236 | GPU
DEBUG 01-05 09:19:53.518459.518459 lmp.py:372]   Expert  2 |    242 | GPU
DEBUG 01-05 09:19:53.518240.518240 lmp.py:372]   Expert 23 |    242 | GPU
DEBUG 01-05 09:19:53.518022.518022 lmp.py:372]   Expert 32 |    244 | GPU
DEBUG 01-05 09:19:53.518566.518566 lmp.py:372]   Expert 45 |    249 | GPU
DEBUG 01-05 09:19:53.518348.518348 lmp.py:372]   Expert 58 |    250 | GPU
DEBUG 01-05 09:19:53.518368.518368 lmp.py:372]   Expert 52 |    257 | GPU
DEBUG 01-05 09:19:53.518912.518912 lmp.py:372]   Expert  9 |    277 | GPU
DEBUG 01-05 09:19:53.518455.518455 lmp.py:372]   Expert 12 |    298 | GPU
DEBUG 01-05 09:19:53.518999.518999 lmp.py:372]   Expert 18 |    314 | GPU
DEBUG 01-05 09:19:53.518258.518258 lmp.py:372]   Expert 13 |    322 | GPU
DEBUG 01-05 09:19:53.518801.518801 lmp.py:372]   Expert 33 |    332 | GPU
DEBUG 01-05 09:19:53.518822.518822 lmp.py:372]   Expert 39 |    337 | GPU
DEBUG 01-05 09:19:53.518365.518365 lmp.py:372]   Expert  8 |    374 | GPU
DEBUG 01-05 09:19:53.518147.518147 lmp.py:372]   Expert 11 |    388 | GPU
DEBUG 01-05 09:19:53.518691.518691 lmp.py:372]   Expert 27 |    672 | GPU
DEBUG 01-05 09:19:53.518188.518188 lmp.py:373] 
DEBUG 01-05 09:19:53.518188.518188 lmp.py:373]   CPU total tokens: 3943 (32.1%)
DEBUG 01-05 09:19:53.518400.518400 lmp.py:374]   GPU total tokens: 8345 (67.9%)
DEBUG 01-05 09:19:53.518427.518427 cuda_h.py:19] end experts_map_get cost 0.0013937950134277344 seconds
DEBUG 01-05 09:19:53.518401.518401 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.518085.518085 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.518699.518699 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.519959.519959 cuda_h.py:19] end allocate_cuda_memory cost 0.00023221969604492188 seconds
DEBUG 01-05 09:19:53.519902.519902 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.519843.519843 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.519368.519368 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.519348.519348 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c18c949-af50-43d2-ae09-615254e54443
DEBUG 01-05 09:19:53.519653.519653 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.520526.520526 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c18c949-af50-43d2-ae09-615254e54443
DEBUG 01-05 09:19:53.520263.520263 cuda_h.py:19] end load_into_gpu_async cost 0.0012552738189697266 seconds
DEBUG 01-05 09:19:53.520058.520058 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.520600.520600 cuda_h.py:19] end restore_tensors2 cost 0.0003387928009033203 seconds
DEBUG 01-05 09:19:53.520946.520946 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00215911865234375 seconds
DEBUG 01-05 09:19:53.523492.523492 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0048525333404541016 seconds
DEBUG 01-05 09:19:53.523414.523414 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.523231.523231 lmp.py:419] 
DEBUG 01-05 09:19:53.523231.523231 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.523783.523783 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-05 09:19:53.523194.523194 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.543334.543334 mlpmodule.py:704] group tensors cost 0.0190732479095459 s
DEBUG 01-05 09:19:53.545756.545756 mlpmodule.py:742] pad cost 0.0015459060668945312 s
DEBUG 01-05 09:19:53.545667.545667 mlpmodule.py:748] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-05 09:19:53.545755.545755 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-05 09:19:53.558520.558520 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.558135.558135 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.558940.558940 mlpmodule.py:773] group_w3 first element: 0.00653076171875
WARNING 01-05 09:19:53.559209.559209 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.579536.579536 mlpmodule.py:793] group einsum cost 0.03354167938232422 s
DEBUG 01-05 09:19:53.580934.580934 mlpmodule.py:801] cpy2cputensor cost 0.0011887550354003906 s
DEBUG 01-05 09:19:53.618426.618426 cuda_h.py:19] end wait_cetm_experts cost 0.09511089324951172 seconds
DEBUG 01-05 09:19:53.619588.619588 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.619897.619897 cuda_h.py:19] end gpu_sexperts cost 0.000469207763671875 seconds
DEBUG 01-05 09:19:53.619402.619402 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:19:53.619933.619933 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-05 09:19:53.619597.619597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.0994415283203125e-05 seconds
DEBUG 01-05 09:19:53.619652.619652 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.772445678710938e-05 seconds
DEBUG 01-05 09:19:53.619639.619639 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.619587.619587 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c18c949-af50-43d2-ae09-615254e54443
DEBUG 01-05 09:19:53.619990.619990 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.620721.620721 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.620803.620803 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.623718.623718 cuda_h.py:19] end allocate_cuda_memory cost 0.0035305023193359375 seconds
DEBUG 01-05 09:19:53.623588.623588 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.623020.623020 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.623233.623233 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.623943.623943 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 625226c1-ed96-4e2b-ba9a-55d971dd67a4
DEBUG 01-05 09:19:53.624456.624456 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.624397.624397 client.py:127] Model loaded
DEBUG 01-05 09:19:53.624300.624300 cuda_h.py:19] end wait_experts cost 0.00445866584777832 seconds
DEBUG 01-05 09:19:53.624864.624864 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.624951.624951 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.624699.624699 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 625226c1-ed96-4e2b-ba9a-55d971dd67a4
DEBUG 01-05 09:19:53.624787.624787 cuda_h.py:19] end load_into_gpu_async cost 0.0011615753173828125 seconds
DEBUG 01-05 09:19:53.625828.625828 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.625792.625792 cuda_h.py:19] end restore_tensors2 cost 8.368492126464844e-05 seconds
DEBUG 01-05 09:19:53.625124.625124 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005074262619018555 seconds
DEBUG 01-05 09:19:53.625290.625290 mlpmodule.py:531] gpu group tensors cost 0.0011372566223144531 s
INFO 01-05 09:19:53.625049.625049 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 625226c1-ed96-4e2b-ba9a-55d971dd67a4
DEBUG 01-05 09:19:53.627111.627111 mlpmodule.py:564] gpu pad cost 0.0018160343170166016 s
DEBUG 01-05 09:19:53.628363.628363 mlpmodule.py:582] gpu group einsum cost 0.0005326271057128906 s
DEBUG 01-05 09:19:53.631891.631891 mlpmodule.py:611] gpu experts func einsum cost 0.00723576545715332 s
DEBUG 01-05 09:19:53.631074.631074 cuda_h.py:19] end gpu_experts cost 0.007429361343383789 seconds
DEBUG 01-05 09:19:53.631836.631836 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:53.632834.632834 mlpmodule.py:662]  experts func einsum cost 0.10839271545410156 s
INFO 01-05 09:19:53.634159.634159 client.py:127] Model loaded
DEBUG 01-05 09:19:53.634711.634711 cuda_h.py:19] end sllm_worker_task cost 0.014917850494384766 seconds
DEBUG 01-05 09:19:53.635839.635839 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0031957626342773438 seconds
DEBUG 01-05 09:19:53.635341.635341 cuda_h.py:19] end layer_moe_generate_24 cost 0.11855435371398926 seconds
DEBUG 01-05 09:19:53.635844.635844 lmp.py:214] -------------------------------- end layer 24 --------------------------------
DEBUG 01-05 09:19:53.635560.635560 lmp.py:173] -------------------------------- start layer 25 --------------------------------
DEBUG 01-05 09:19:53.635780.635780 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.635637.635637 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.638800.638800 cuda_h.py:19] end self_attn cost 0.0024538040161132812 seconds
DEBUG 01-05 09:19:53.638830.638830 cuda_h.py:19] end iln_self_attn_paln cost 0.0030622482299804688 seconds
DEBUG 01-05 09:19:53.638004.638004 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-05 09:19:53.638767.638767 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.639794.639794 cuda_h.py:19] end gate cost 0.0005841255187988281 seconds
DEBUG 01-05 09:19:53.639670.639670 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.639654.639654 lmp.py:361] 
DEBUG 01-05 09:19:53.639654.639654 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.639840.639840 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.639967.639967 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.639994.639994 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.639114.639114 lmp.py:365] 
DEBUG 01-05 09:19:53.639114.639114 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.639472.639472 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.639837.639837 lmp.py:372]   Expert 36 |     47 | CPU
DEBUG 01-05 09:19:53.639149.639149 lmp.py:372]   Expert 18 |     50 | CPU
DEBUG 01-05 09:19:53.639838.639838 lmp.py:372]   Expert 33 |     50 | CPU
DEBUG 01-05 09:19:53.639289.639289 lmp.py:372]   Expert 42 |     52 | CPU
DEBUG 01-05 09:19:53.639263.639263 lmp.py:372]   Expert 13 |     61 | CPU
DEBUG 01-05 09:19:53.639237.639237 lmp.py:372]   Expert 16 |     76 | CPU
DEBUG 01-05 09:19:53.639450.639450 lmp.py:372]   Expert  0 |     82 | CPU
DEBUG 01-05 09:19:53.639808.639808 lmp.py:372]   Expert 47 |     89 | CPU
DEBUG 01-05 09:19:53.639259.639259 lmp.py:372]   Expert 10 |     90 | CPU
DEBUG 01-05 09:19:53.639663.639663 lmp.py:372]   Expert 22 |     90 | CPU
DEBUG 01-05 09:19:53.639830.639830 lmp.py:372]   Expert 21 |     91 | CPU
DEBUG 01-05 09:19:53.639519.639519 lmp.py:372]   Expert 38 |     98 | CPU
DEBUG 01-05 09:19:53.639685.639685 lmp.py:372]   Expert 27 |    104 | CPU
DEBUG 01-05 09:19:53.639898.639898 lmp.py:372]   Expert  5 |    105 | CPU
DEBUG 01-05 09:19:53.639017.639017 lmp.py:372]   Expert 62 |    107 | CPU
DEBUG 01-05 09:19:53.639468.639468 lmp.py:372]   Expert 43 |    110 | CPU
DEBUG 01-05 09:19:53.640442.640442 lmp.py:372]   Expert 59 |    110 | CPU
DEBUG 01-05 09:19:53.640939.640939 lmp.py:372]   Expert 50 |    114 | CPU
DEBUG 01-05 09:19:53.640914.640914 lmp.py:372]   Expert 53 |    116 | CPU
DEBUG 01-05 09:19:53.640411.640411 lmp.py:372]   Expert  2 |    121 | CPU
DEBUG 01-05 09:19:53.640054.640054 lmp.py:372]   Expert 34 |    124 | CPU
DEBUG 01-05 09:19:53.640266.640266 lmp.py:372]   Expert 14 |    132 | CPU
DEBUG 01-05 09:19:53.640432.640432 lmp.py:372]   Expert 24 |    138 | CPU
DEBUG 01-05 09:19:53.640837.640837 lmp.py:372]   Expert 48 |    138 | CPU
DEBUG 01-05 09:19:53.640003.640003 lmp.py:372]   Expert 32 |    141 | CPU
DEBUG 01-05 09:19:53.640169.640169 lmp.py:372]   Expert 56 |    141 | CPU
DEBUG 01-05 09:19:53.640143.640143 lmp.py:372]   Expert 20 |    143 | CPU
DEBUG 01-05 09:19:53.640832.640832 lmp.py:372]   Expert 44 |    148 | CPU
DEBUG 01-05 09:19:53.640237.640237 lmp.py:372]   Expert 55 |    148 | CPU
DEBUG 01-05 09:19:53.640211.640211 lmp.py:372]   Expert 23 |    149 | CPU
DEBUG 01-05 09:19:53.640708.640708 lmp.py:372]   Expert 31 |    152 | CPU
DEBUG 01-05 09:19:53.640682.640682 lmp.py:372]   Expert 45 |    154 | CPU
DEBUG 01-05 09:19:53.640656.640656 lmp.py:372]   Expert  4 |    158 | GPU
DEBUG 01-05 09:19:53.640107.640107 lmp.py:372]   Expert 41 |    159 | GPU
DEBUG 01-05 09:19:53.640512.640512 lmp.py:372]   Expert  3 |    161 | GPU
DEBUG 01-05 09:19:53.640486.640486 lmp.py:372]   Expert 46 |    166 | GPU
DEBUG 01-05 09:19:53.640890.640890 lmp.py:372]   Expert  6 |    182 | GPU
DEBUG 01-05 09:19:53.640295.640295 lmp.py:372]   Expert 51 |    195 | GPU
DEBUG 01-05 09:19:53.640984.640984 lmp.py:372]   Expert 39 |    197 | GPU
DEBUG 01-05 09:19:53.640349.640349 lmp.py:372]   Expert 52 |    197 | GPU
DEBUG 01-05 09:19:53.640277.640277 lmp.py:372]   Expert  8 |    202 | GPU
DEBUG 01-05 09:19:53.640350.640350 lmp.py:372]   Expert 61 |    205 | GPU
DEBUG 01-05 09:19:53.640325.640325 lmp.py:372]   Expert 12 |    211 | GPU
DEBUG 01-05 09:19:53.640060.640060 lmp.py:372]   Expert  1 |    217 | GPU
DEBUG 01-05 09:19:53.640796.640796 lmp.py:372]   Expert 11 |    223 | GPU
DEBUG 01-05 09:19:53.640531.640531 lmp.py:372]   Expert 35 |    224 | GPU
DEBUG 01-05 09:19:53.640790.640790 lmp.py:372]   Expert 40 |    230 | GPU
DEBUG 01-05 09:19:53.640672.640672 lmp.py:372]   Expert  7 |    240 | GPU
DEBUG 01-05 09:19:53.640407.640407 lmp.py:372]   Expert 15 |    248 | GPU
DEBUG 01-05 09:19:53.640904.640904 lmp.py:372]   Expert 37 |    264 | GPU
DEBUG 01-05 09:19:53.640640.640640 lmp.py:372]   Expert 49 |    265 | GPU
DEBUG 01-05 09:19:53.640329.640329 lmp.py:372]   Expert 57 |    275 | GPU
DEBUG 01-05 09:19:53.640542.640542 lmp.py:372]   Expert 26 |    292 | GPU
DEBUG 01-05 09:19:53.640231.640231 lmp.py:372]   Expert 28 |    294 | GPU
DEBUG 01-05 09:19:53.640397.640397 lmp.py:372]   Expert 30 |    298 | GPU
DEBUG 01-05 09:19:53.640371.640371 lmp.py:372]   Expert 58 |    321 | GPU
DEBUG 01-05 09:19:53.640968.640968 lmp.py:372]   Expert 63 |    321 | GPU
DEBUG 01-05 09:19:53.640704.640704 lmp.py:372]   Expert 25 |    352 | GPU
DEBUG 01-05 09:19:53.640201.640201 lmp.py:372]   Expert 54 |    378 | GPU
DEBUG 01-05 09:19:53.640175.640175 lmp.py:372]   Expert  9 |    402 | GPU
DEBUG 01-05 09:19:53.640910.640910 lmp.py:372]   Expert 17 |    425 | GPU
DEBUG 01-05 09:19:53.640646.640646 lmp.py:372]   Expert 60 |    464 | GPU
DEBUG 01-05 09:19:53.640289.640289 lmp.py:372]   Expert 29 |    472 | GPU
DEBUG 01-05 09:19:53.640217.640217 lmp.py:372]   Expert 19 |    579 | GPU
DEBUG 01-05 09:19:53.640860.640860 lmp.py:373] 
DEBUG 01-05 09:19:53.640860.640860 lmp.py:373]   CPU total tokens: 3471 (28.2%)
DEBUG 01-05 09:19:53.640980.640980 lmp.py:374]   GPU total tokens: 8817 (71.8%)
DEBUG 01-05 09:19:53.640868.640868 cuda_h.py:19] end experts_map_get cost 0.0015215873718261719 seconds
DEBUG 01-05 09:19:53.640749.640749 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.640009.640009 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.641299.641299 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.641513.641513 cuda_h.py:19] end allocate_cuda_memory cost 0.00023031234741210938 seconds
DEBUG 01-05 09:19:53.641025.641025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.641304.641304 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.641597.641597 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.641723.641723 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8729e120-30fb-4bce-92d2-c721624aaa2c
DEBUG 01-05 09:19:53.641895.641895 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.642460.642460 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8729e120-30fb-4bce-92d2-c721624aaa2c
DEBUG 01-05 09:19:53.642813.642813 cuda_h.py:19] end load_into_gpu_async cost 0.0013573169708251953 seconds
DEBUG 01-05 09:19:53.642416.642416 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.643720.643720 cuda_h.py:19] end restore_tensors2 cost 0.00033855438232421875 seconds
DEBUG 01-05 09:19:53.643404.643404 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002270221710205078 seconds
DEBUG 01-05 09:19:53.645407.645407 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00498509407043457 seconds
DEBUG 01-05 09:19:53.645290.645290 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.646345.646345 lmp.py:419] 
DEBUG 01-05 09:19:53.646345.646345 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.646804.646804 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-05 09:19:53.646215.646215 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.657796.657796 mlpmodule.py:704] group tensors cost 0.010854959487915039 s
DEBUG 01-05 09:19:53.659844.659844 mlpmodule.py:742] pad cost 0.00152587890625 s
DEBUG 01-05 09:19:53.659225.659225 mlpmodule.py:748] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-05 09:19:53.659850.659850 mlpmodule.py:753] move to cpu cost 3.8623809814453125e-05 s
DEBUG 01-05 09:19:53.674362.674362 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.674990.674990 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.674272.674272 mlpmodule.py:773] group_w3 first element: 0.007110595703125
WARNING 01-05 09:19:53.674694.674694 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.695529.695529 mlpmodule.py:793] group einsum cost 0.0357968807220459 s
DEBUG 01-05 09:19:53.696863.696863 mlpmodule.py:801] cpy2cputensor cost 0.0006759166717529297 s
DEBUG 01-05 09:19:53.735796.735796 cuda_h.py:19] end wait_cetm_experts cost 0.08950495719909668 seconds
DEBUG 01-05 09:19:53.735104.735104 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.736280.736280 cuda_h.py:19] end gpu_sexperts cost 0.0004773139953613281 seconds
DEBUG 01-05 09:19:53.736547.736547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:19:53.736270.736270 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-05 09:19:53.736525.736525 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.363059997558594e-05 seconds
DEBUG 01-05 09:19:53.736718.736718 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 8.869171142578125e-05 seconds
DEBUG 01-05 09:19:53.736514.736514 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.736131.736131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8729e120-30fb-4bce-92d2-c721624aaa2c
DEBUG 01-05 09:19:53.736255.736255 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.736676.736676 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.736565.736565 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.740898.740898 cuda_h.py:19] end allocate_cuda_memory cost 0.003962516784667969 seconds
DEBUG 01-05 09:19:53.740669.740669 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.740670.740670 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.740453.740453 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.741686.741686 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8826f30f-db7e-4ead-b342-b4d8cfadd648
DEBUG 01-05 09:19:53.741437.741437 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.741721.741721 client.py:127] Model loaded
DEBUG 01-05 09:19:53.741955.741955 cuda_h.py:19] end wait_experts cost 0.004859209060668945 seconds
DEBUG 01-05 09:19:53.741566.741566 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.741083.741083 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.742454.742454 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8826f30f-db7e-4ead-b342-b4d8cfadd648
DEBUG 01-05 09:19:53.742019.742019 cuda_h.py:19] end load_into_gpu_async cost 0.0011334419250488281 seconds
DEBUG 01-05 09:19:53.742537.742537 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.742839.742839 cuda_h.py:19] end restore_tensors2 cost 8.654594421386719e-05 seconds
DEBUG 01-05 09:19:53.742601.742601 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00545954704284668 seconds
DEBUG 01-05 09:19:53.742495.742495 mlpmodule.py:531] gpu group tensors cost 0.0011320114135742188 s
INFO 01-05 09:19:53.742924.742924 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8826f30f-db7e-4ead-b342-b4d8cfadd648
DEBUG 01-05 09:19:53.744397.744397 mlpmodule.py:564] gpu pad cost 0.0019221305847167969 s
DEBUG 01-05 09:19:53.745066.745066 mlpmodule.py:582] gpu group einsum cost 0.0005261898040771484 s
DEBUG 01-05 09:19:53.748596.748596 mlpmodule.py:611] gpu experts func einsum cost 0.007317543029785156 s
DEBUG 01-05 09:19:53.748155.748155 cuda_h.py:19] end gpu_experts cost 0.007497549057006836 seconds
DEBUG 01-05 09:19:53.748680.748680 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:53.749051.749051 mlpmodule.py:662]  experts func einsum cost 0.10375475883483887 s
INFO 01-05 09:19:53.751532.751532 client.py:127] Model loaded
DEBUG 01-05 09:19:53.751745.751745 cuda_h.py:19] end sllm_worker_task cost 0.014943838119506836 seconds
DEBUG 01-05 09:19:53.751681.751681 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0027704238891601562 seconds
DEBUG 01-05 09:19:53.751931.751931 cuda_h.py:19] end layer_moe_generate_25 cost 0.11329269409179688 seconds
DEBUG 01-05 09:19:53.752441.752441 lmp.py:214] -------------------------------- end layer 25 --------------------------------
DEBUG 01-05 09:19:53.752489.752489 lmp.py:173] -------------------------------- start layer 26 --------------------------------
DEBUG 01-05 09:19:53.752900.752900 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.752778.752778 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.754595.754595 cuda_h.py:19] end self_attn cost 0.0024073123931884766 seconds
DEBUG 01-05 09:19:53.755810.755810 cuda_h.py:19] end iln_self_attn_paln cost 0.003029346466064453 seconds
DEBUG 01-05 09:19:53.755528.755528 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-05 09:19:53.755768.755768 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.755166.755166 cuda_h.py:19] end gate cost 0.0005733966827392578 seconds
DEBUG 01-05 09:19:53.755565.755565 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.756694.756694 lmp.py:361] 
DEBUG 01-05 09:19:53.756694.756694 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.756596.756596 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.756438.756438 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.756617.756617 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.756691.756691 lmp.py:365] 
DEBUG 01-05 09:19:53.756691.756691 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.756095.756095 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.756368.756368 lmp.py:372]   Expert  3 |     53 | CPU
DEBUG 01-05 09:19:53.756488.756488 lmp.py:372]   Expert 17 |     55 | CPU
DEBUG 01-05 09:19:53.756276.756276 lmp.py:372]   Expert 30 |     55 | CPU
DEBUG 01-05 09:19:53.756204.756204 lmp.py:372]   Expert 62 |     55 | CPU
DEBUG 01-05 09:19:53.756417.756417 lmp.py:372]   Expert 59 |     64 | CPU
DEBUG 01-05 09:19:53.756867.756867 lmp.py:372]   Expert 61 |     64 | CPU
DEBUG 01-05 09:19:53.756318.756318 lmp.py:372]   Expert 58 |     66 | CPU
DEBUG 01-05 09:19:53.756292.756292 lmp.py:372]   Expert 19 |     71 | CPU
DEBUG 01-05 09:19:53.756889.756889 lmp.py:372]   Expert 49 |     77 | CPU
DEBUG 01-05 09:19:53.756863.756863 lmp.py:372]   Expert 55 |     78 | CPU
DEBUG 01-05 09:19:53.756076.756076 lmp.py:372]   Expert 51 |     80 | CPU
DEBUG 01-05 09:19:53.756288.756288 lmp.py:372]   Expert  7 |     81 | CPU
DEBUG 01-05 09:19:53.756262.756262 lmp.py:372]   Expert 24 |     82 | CPU
DEBUG 01-05 09:19:53.756475.756475 lmp.py:372]   Expert  9 |     88 | CPU
DEBUG 01-05 09:19:53.756449.756449 lmp.py:372]   Expert 56 |     96 | CPU
DEBUG 01-05 09:19:53.756661.756661 lmp.py:372]   Expert  8 |    101 | CPU
DEBUG 01-05 09:19:53.756066.756066 lmp.py:372]   Expert 21 |    103 | CPU
DEBUG 01-05 09:19:53.756808.756808 lmp.py:372]   Expert 60 |    104 | CPU
DEBUG 01-05 09:19:53.756259.756259 lmp.py:372]   Expert 15 |    105 | CPU
DEBUG 01-05 09:19:53.756140.756140 lmp.py:372]   Expert 11 |    111 | CPU
DEBUG 01-05 09:19:53.756591.756591 lmp.py:372]   Expert  6 |    117 | CPU
DEBUG 01-05 09:19:53.756327.756327 lmp.py:372]   Expert 13 |    119 | CPU
DEBUG 01-05 09:19:53.756301.756301 lmp.py:372]   Expert 43 |    120 | CPU
DEBUG 01-05 09:19:53.756275.756275 lmp.py:372]   Expert 12 |    124 | CPU
DEBUG 01-05 09:19:53.756772.756772 lmp.py:372]   Expert 27 |    132 | CPU
DEBUG 01-05 09:19:53.756892.756892 lmp.py:372]   Expert 41 |    136 | CPU
DEBUG 01-05 09:19:53.756866.756866 lmp.py:372]   Expert 26 |    137 | CPU
DEBUG 01-05 09:19:53.756602.756602 lmp.py:372]   Expert 53 |    137 | CPU
DEBUG 01-05 09:19:53.756576.756576 lmp.py:372]   Expert  0 |    138 | CPU
DEBUG 01-05 09:19:53.756788.756788 lmp.py:372]   Expert 28 |    141 | CPU
DEBUG 01-05 09:19:53.756338.756338 lmp.py:372]   Expert 38 |    141 | CPU
DEBUG 01-05 09:19:53.756743.756743 lmp.py:372]   Expert 22 |    145 | CPU
DEBUG 01-05 09:19:53.756909.756909 lmp.py:372]   Expert 29 |    145 | GPU
DEBUG 01-05 09:19:53.757598.757598 lmp.py:372]   Expert 45 |    145 | GPU
DEBUG 01-05 09:19:53.757718.757718 lmp.py:372]   Expert 34 |    156 | GPU
DEBUG 01-05 09:19:53.757931.757931 lmp.py:372]   Expert 47 |    157 | GPU
DEBUG 01-05 09:19:53.757905.757905 lmp.py:372]   Expert 57 |    164 | GPU
DEBUG 01-05 09:19:53.757640.757640 lmp.py:372]   Expert 37 |    171 | GPU
DEBUG 01-05 09:19:53.757614.757614 lmp.py:372]   Expert 32 |    188 | GPU
DEBUG 01-05 09:19:53.757350.757350 lmp.py:372]   Expert 48 |    188 | GPU
DEBUG 01-05 09:19:53.757470.757470 lmp.py:372]   Expert  1 |    189 | GPU
DEBUG 01-05 09:19:53.757444.757444 lmp.py:372]   Expert 23 |    197 | GPU
DEBUG 01-05 09:19:53.757848.757848 lmp.py:372]   Expert 42 |    205 | GPU
DEBUG 01-05 09:19:53.757015.757015 lmp.py:372]   Expert 36 |    219 | GPU
DEBUG 01-05 09:19:53.757803.757803 lmp.py:372]   Expert 54 |    229 | GPU
DEBUG 01-05 09:19:53.757969.757969 lmp.py:372]   Expert  4 |    232 | GPU
DEBUG 01-05 09:19:53.757420.757420 lmp.py:372]   Expert 39 |    232 | GPU
DEBUG 01-05 09:19:53.757302.757302 lmp.py:372]   Expert 20 |    242 | GPU
DEBUG 01-05 09:19:53.757276.757276 lmp.py:372]   Expert 31 |    242 | GPU
DEBUG 01-05 09:19:53.757773.757773 lmp.py:372]   Expert 16 |    253 | GPU
DEBUG 01-05 09:19:53.757509.757509 lmp.py:372]   Expert 33 |    279 | GPU
DEBUG 01-05 09:19:53.757483.757483 lmp.py:372]   Expert  2 |    282 | GPU
DEBUG 01-05 09:19:53.757172.757172 lmp.py:372]   Expert 44 |    305 | GPU
DEBUG 01-05 09:19:53.757815.757815 lmp.py:372]   Expert  5 |    315 | GPU
DEBUG 01-05 09:19:53.757027.757027 lmp.py:372]   Expert 18 |    321 | GPU
DEBUG 01-05 09:19:53.757670.757670 lmp.py:372]   Expert 50 |    330 | GPU
DEBUG 01-05 09:19:53.757075.757075 lmp.py:372]   Expert 10 |    360 | GPU
DEBUG 01-05 09:19:53.757479.757479 lmp.py:372]   Expert 25 |    364 | GPU
DEBUG 01-05 09:19:53.757692.757692 lmp.py:372]   Expert 35 |    371 | GPU
DEBUG 01-05 09:19:53.757096.757096 lmp.py:372]   Expert 63 |    383 | GPU
DEBUG 01-05 09:19:53.757024.757024 lmp.py:372]   Expert 40 |    450 | GPU
DEBUG 01-05 09:19:53.757475.757475 lmp.py:372]   Expert 46 |    467 | GPU
DEBUG 01-05 09:19:53.757449.757449 lmp.py:372]   Expert 52 |    528 | GPU
DEBUG 01-05 09:19:53.757662.757662 lmp.py:372]   Expert 14 |    803 | GPU
DEBUG 01-05 09:19:53.757589.757589 lmp.py:373] 
DEBUG 01-05 09:19:53.757589.757589 lmp.py:373]   CPU total tokens: 3176 (25.8%)
DEBUG 01-05 09:19:53.757186.757186 lmp.py:374]   GPU total tokens: 9112 (74.2%)
DEBUG 01-05 09:19:53.757836.757836 cuda_h.py:19] end experts_map_get cost 0.0015404224395751953 seconds
DEBUG 01-05 09:19:53.757240.757240 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.757739.757739 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.757982.757982 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.758522.758522 cuda_h.py:19] end allocate_cuda_memory cost 0.00025916099548339844 seconds
DEBUG 01-05 09:19:53.758702.758702 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.758313.758313 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.758652.758652 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.758401.758401 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bdc4c8c-e0d2-4939-a0f8-4e01c2baa293
DEBUG 01-05 09:19:53.758196.758196 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.759569.759569 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bdc4c8c-e0d2-4939-a0f8-4e01c2baa293
DEBUG 01-05 09:19:53.759829.759829 cuda_h.py:19] end load_into_gpu_async cost 0.0013613700866699219 seconds
DEBUG 01-05 09:19:53.759624.759624 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.759166.759166 cuda_h.py:19] end restore_tensors2 cost 0.00033783912658691406 seconds
DEBUG 01-05 09:19:53.759565.759565 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023064613342285156 seconds
DEBUG 01-05 09:19:53.762090.762090 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004987478256225586 seconds
DEBUG 01-05 09:19:53.762019.762019 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.762380.762380 lmp.py:419] 
DEBUG 01-05 09:19:53.762380.762380 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.762647.762647 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-05 09:19:53.762727.762727 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.768790.768790 mlpmodule.py:704] group tensors cost 0.005116701126098633 s
DEBUG 01-05 09:19:53.770700.770700 mlpmodule.py:742] pad cost 0.0014891624450683594 s
DEBUG 01-05 09:19:53.770041.770041 mlpmodule.py:748] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-05 09:19:53.770030.770030 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-05 09:19:53.783723.783723 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.783928.783928 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.783666.783666 mlpmodule.py:773] group_w3 first element: 0.07666015625
WARNING 01-05 09:19:53.783657.783657 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.802214.802214 mlpmodule.py:793] group einsum cost 0.03191208839416504 s
DEBUG 01-05 09:19:53.803557.803557 mlpmodule.py:801] cpy2cputensor cost 0.0007622241973876953 s
DEBUG 01-05 09:19:53.844991.844991 cuda_h.py:19] end wait_cetm_experts cost 0.08122944831848145 seconds
DEBUG 01-05 09:19:53.844391.844391 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.844018.844018 cuda_h.py:19] end gpu_sexperts cost 0.000492095947265625 seconds
DEBUG 01-05 09:19:53.844623.844623 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:19:53.844254.844254 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-05 09:19:53.844541.844541 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.123283386230469e-05 seconds
DEBUG 01-05 09:19:53.844715.844715 cuda_h.py:10] start sllm_worker_task
DEBUG 01-05 09:19:53.844452.844452 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.0001468658447265625 seconds
DEBUG 01-05 09:19:53.845084.845084 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.845966.845966 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.845587.845587 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bdc4c8c-e0d2-4939-a0f8-4e01c2baa293
DEBUG 01-05 09:19:53.845744.845744 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.848726.848726 cuda_h.py:19] end allocate_cuda_memory cost 0.0031871795654296875 seconds
DEBUG 01-05 09:19:53.848504.848504 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.848651.848651 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.848911.848911 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.848905.848905 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 47fb6a42-f5c1-430a-a11c-00c1384d8af8
DEBUG 01-05 09:19:53.848465.848465 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.849690.849690 client.py:127] Model loaded
DEBUG 01-05 09:19:53.849732.849732 cuda_h.py:19] end wait_experts cost 0.003939151763916016 seconds
DEBUG 01-05 09:19:53.849534.849534 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.849383.849383 lmp.py:464]   Computing 32 experts on GPU...
INFO 01-05 09:19:53.849839.849839 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 47fb6a42-f5c1-430a-a11c-00c1384d8af8
DEBUG 01-05 09:19:53.849974.849974 cuda_h.py:19] end load_into_gpu_async cost 0.001150369644165039 seconds
DEBUG 01-05 09:19:53.849299.849299 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.850879.850879 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-05 09:19:53.850927.850927 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004905223846435547 seconds
DEBUG 01-05 09:19:53.850646.850646 mlpmodule.py:531] gpu group tensors cost 0.0010595321655273438 s
INFO 01-05 09:19:53.850045.850045 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 47fb6a42-f5c1-430a-a11c-00c1384d8af8
DEBUG 01-05 09:19:53.852683.852683 mlpmodule.py:564] gpu pad cost 0.0019783973693847656 s
DEBUG 01-05 09:19:53.853029.853029 mlpmodule.py:582] gpu group einsum cost 0.00055694580078125 s
DEBUG 01-05 09:19:53.856505.856505 mlpmodule.py:662]  experts func einsum cost 0.09370040893554688 s
DEBUG 01-05 09:19:53.856730.856730 mlpmodule.py:611] gpu experts func einsum cost 0.007508277893066406 s
DEBUG 01-05 09:19:53.856926.856926 cuda_h.py:19] end gpu_experts cost 0.007704019546508789 seconds
DEBUG 01-05 09:19:53.857496.857496 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-05 09:19:53.860535.860535 client.py:127] Model loaded
DEBUG 01-05 09:19:53.860332.860332 cuda_h.py:19] end sllm_worker_task cost 0.015533447265625 seconds
DEBUG 01-05 09:19:53.860215.860215 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.003622770309448242 seconds
DEBUG 01-05 09:19:53.860207.860207 cuda_h.py:19] end layer_moe_generate_26 cost 0.10548949241638184 seconds
DEBUG 01-05 09:19:53.861372.861372 lmp.py:214] -------------------------------- end layer 26 --------------------------------
DEBUG 01-05 09:19:53.861573.861573 lmp.py:173] -------------------------------- start layer 27 --------------------------------
DEBUG 01-05 09:19:53.861315.861315 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-05 09:19:53.861841.861841 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-05 09:19:53.863361.863361 cuda_h.py:19] end self_attn cost 0.002435445785522461 seconds
DEBUG 01-05 09:19:53.864179.864179 cuda_h.py:19] end iln_self_attn_paln cost 0.003031015396118164 seconds
DEBUG 01-05 09:19:53.864260.864260 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-05 09:19:53.864646.864646 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.864388.864388 cuda_h.py:19] end gate cost 0.0005843639373779297 seconds
DEBUG 01-05 09:19:53.864218.864218 cuda_h.py:10] start experts_map_get
DEBUG 01-05 09:19:53.865778.865778 lmp.py:361] 
DEBUG 01-05 09:19:53.865778.865778 lmp.py:361] Expert Token Distribution & Device Allocation:
DEBUG 01-05 09:19:53.865964.865964 lmp.py:362]   Total experts: 64
DEBUG 01-05 09:19:53.865998.865998 lmp.py:363]   CPU experts: 32 (50%)
DEBUG 01-05 09:19:53.865502.865502 lmp.py:364]   GPU experts: 32 (50%)
DEBUG 01-05 09:19:53.865337.865337 lmp.py:365] 
DEBUG 01-05 09:19:53.865337.865337 lmp.py:365]   Expert ID | Tokens | Device
DEBUG 01-05 09:19:53.865696.865696 lmp.py:366]   -----------------------------------
DEBUG 01-05 09:19:53.865869.865869 lmp.py:372]   Expert 18 |     36 | CPU
DEBUG 01-05 09:19:53.865419.865419 lmp.py:372]   Expert 47 |     44 | CPU
DEBUG 01-05 09:19:53.865347.865347 lmp.py:372]   Expert 54 |     59 | CPU
DEBUG 01-05 09:19:53.865797.865797 lmp.py:372]   Expert 58 |     65 | CPU
DEBUG 01-05 09:19:53.865772.865772 lmp.py:372]   Expert 15 |     71 | CPU
DEBUG 01-05 09:19:53.865222.865222 lmp.py:372]   Expert 24 |     75 | CPU
DEBUG 01-05 09:19:53.865150.865150 lmp.py:372]   Expert  7 |     76 | CPU
DEBUG 01-05 09:19:53.865793.865793 lmp.py:372]   Expert 11 |     76 | CPU
DEBUG 01-05 09:19:53.865482.865482 lmp.py:372]   Expert 32 |     78 | CPU
DEBUG 01-05 09:19:53.865887.865887 lmp.py:372]   Expert 59 |     83 | CPU
DEBUG 01-05 09:19:53.865338.865338 lmp.py:372]   Expert 12 |     86 | CPU
DEBUG 01-05 09:19:53.865934.865934 lmp.py:372]   Expert 38 |     87 | CPU
DEBUG 01-05 09:19:53.865385.865385 lmp.py:372]   Expert 61 |     88 | CPU
DEBUG 01-05 09:19:53.865359.865359 lmp.py:372]   Expert 42 |    101 | CPU
DEBUG 01-05 09:19:53.865810.865810 lmp.py:372]   Expert 23 |    108 | CPU
DEBUG 01-05 09:19:53.865023.865023 lmp.py:372]   Expert 40 |    114 | CPU
DEBUG 01-05 09:19:53.865235.865235 lmp.py:372]   Expert 46 |    122 | CPU
DEBUG 01-05 09:19:53.865448.865448 lmp.py:372]   Expert 52 |    124 | CPU
DEBUG 01-05 09:19:53.865614.865614 lmp.py:372]   Expert  6 |    125 | CPU
DEBUG 01-05 09:19:53.865257.865257 lmp.py:372]   Expert 39 |    127 | CPU
DEBUG 01-05 09:19:53.865661.865661 lmp.py:372]   Expert 34 |    133 | CPU
DEBUG 01-05 09:19:53.865066.865066 lmp.py:372]   Expert 45 |    139 | CPU
DEBUG 01-05 09:19:53.865755.865755 lmp.py:372]   Expert 51 |    140 | CPU
DEBUG 01-05 09:19:53.865398.865398 lmp.py:372]   Expert 44 |    151 | CPU
DEBUG 01-05 09:19:53.865134.865134 lmp.py:372]   Expert 48 |    153 | CPU
DEBUG 01-05 09:19:53.865346.865346 lmp.py:372]   Expert 30 |    159 | CPU
DEBUG 01-05 09:19:53.865320.865320 lmp.py:372]   Expert 10 |    167 | CPU
DEBUG 01-05 09:19:53.865056.865056 lmp.py:372]   Expert 16 |    169 | CPU
DEBUG 01-05 09:19:53.865745.865745 lmp.py:372]   Expert 19 |    173 | CPU
DEBUG 01-05 09:19:53.865388.865388 lmp.py:372]   Expert  3 |    175 | CPU
DEBUG 01-05 09:19:53.865601.865601 lmp.py:372]   Expert 25 |    175 | CPU
DEBUG 01-05 09:19:53.865005.865005 lmp.py:372]   Expert 22 |    180 | CPU
DEBUG 01-05 09:19:53.865317.865317 lmp.py:372]   Expert 29 |    180 | GPU
DEBUG 01-05 09:19:53.865722.865722 lmp.py:372]   Expert  4 |    182 | GPU
DEBUG 01-05 09:19:53.865173.865173 lmp.py:372]   Expert 31 |    182 | GPU
DEBUG 01-05 09:19:53.865816.865816 lmp.py:372]   Expert 56 |    184 | GPU
DEBUG 01-05 09:19:53.865028.865028 lmp.py:372]   Expert  1 |    190 | GPU
DEBUG 01-05 09:19:53.865764.865764 lmp.py:372]   Expert 13 |    192 | GPU
DEBUG 01-05 09:19:53.865738.865738 lmp.py:372]   Expert 36 |    195 | GPU
DEBUG 01-05 09:19:53.866712.866712 lmp.py:372]   Expert 33 |    196 | GPU
DEBUG 01-05 09:19:53.866447.866447 lmp.py:372]   Expert 50 |    197 | GPU
DEBUG 01-05 09:19:53.866090.866090 lmp.py:372]   Expert 17 |    204 | GPU
DEBUG 01-05 09:19:53.866064.866064 lmp.py:372]   Expert 57 |    206 | GPU
DEBUG 01-05 09:19:53.866992.866992 lmp.py:372]   Expert  5 |    214 | GPU
DEBUG 01-05 09:19:53.866158.866158 lmp.py:372]   Expert 62 |    218 | GPU
DEBUG 01-05 09:19:53.866232.866232 lmp.py:372]   Expert  8 |    229 | GPU
DEBUG 01-05 09:19:53.866398.866398 lmp.py:372]   Expert 55 |    232 | GPU
DEBUG 01-05 09:19:53.866087.866087 lmp.py:372]   Expert 53 |    235 | GPU
DEBUG 01-05 09:19:53.866492.866492 lmp.py:372]   Expert 49 |    243 | GPU
DEBUG 01-05 09:19:53.866227.866227 lmp.py:372]   Expert 41 |    245 | GPU
DEBUG 01-05 09:19:53.866725.866725 lmp.py:372]   Expert 26 |    248 | GPU
DEBUG 01-05 09:19:53.866460.866460 lmp.py:372]   Expert  0 |    257 | GPU
DEBUG 01-05 09:19:53.866434.866434 lmp.py:372]   Expert 35 |    270 | GPU
DEBUG 01-05 09:19:53.866647.866647 lmp.py:372]   Expert 37 |    286 | GPU
DEBUG 01-05 09:19:53.866290.866290 lmp.py:372]   Expert 28 |    289 | GPU
DEBUG 01-05 09:19:53.866264.866264 lmp.py:372]   Expert 14 |    338 | GPU
DEBUG 01-05 09:19:53.866715.866715 lmp.py:372]   Expert 27 |    354 | GPU
DEBUG 01-05 09:19:53.866881.866881 lmp.py:372]   Expert  2 |    355 | GPU
DEBUG 01-05 09:19:53.866524.866524 lmp.py:372]   Expert 21 |    366 | GPU
DEBUG 01-05 09:19:53.866736.866736 lmp.py:372]   Expert 60 |    376 | GPU
DEBUG 01-05 09:19:53.866618.866618 lmp.py:372]   Expert 43 |    410 | GPU
DEBUG 01-05 09:19:53.866068.866068 lmp.py:372]   Expert  9 |    411 | GPU
DEBUG 01-05 09:19:53.866042.866042 lmp.py:372]   Expert 63 |    441 | GPU
DEBUG 01-05 09:19:53.866255.866255 lmp.py:372]   Expert 20 |    504 | GPU
DEBUG 01-05 09:19:53.866183.866183 lmp.py:373] 
DEBUG 01-05 09:19:53.866183.866183 lmp.py:373]   CPU total tokens: 3659 (29.8%)
DEBUG 01-05 09:19:53.866110.866110 lmp.py:374]   GPU total tokens: 8629 (70.2%)
DEBUG 01-05 09:19:53.866760.866760 cuda_h.py:19] end experts_map_get cost 0.0015308856964111328 seconds
DEBUG 01-05 09:19:53.866926.866926 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-05 09:19:53.866279.866279 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-05 09:19:53.866152.866152 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-05 09:19:53.866333.866333 cuda_h.py:19] end allocate_cuda_memory cost 0.00023818016052246094 seconds
DEBUG 01-05 09:19:53.867514.867514 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-05 09:19:53.867316.867316 sllm_store_c.py:27] get device uuid map
DEBUG 01-05 09:19:53.867702.867702 sllm_store_c.py:29] call client load into gpu
DEBUG 01-05 09:19:53.867974.867974 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 969b7c3e-09fc-4b88-b0aa-19ffb91aa479
DEBUG 01-05 09:19:53.867146.867146 client.py:106] call stub.LoadModelAsync
INFO 01-05 09:19:53.868972.868972 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 969b7c3e-09fc-4b88-b0aa-19ffb91aa479
DEBUG 01-05 09:19:53.868278.868278 cuda_h.py:19] end load_into_gpu_async cost 0.0012350082397460938 seconds
DEBUG 01-05 09:19:53.868312.868312 cuda_h.py:10] start restore_tensors2
DEBUG 01-05 09:19:53.868060.868060 cuda_h.py:19] end restore_tensors2 cost 0.00034928321838378906 seconds
DEBUG 01-05 09:19:53.868128.868128 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021827220916748047 seconds
DEBUG 01-05 09:19:53.871938.871938 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004862308502197266 seconds
DEBUG 01-05 09:19:53.871674.871674 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-05 09:19:53.871227.871227 lmp.py:419] 
DEBUG 01-05 09:19:53.871227.871227 lmp.py:419]   Computing 32 experts on CPU...
DEBUG 01-05 09:19:53.871878.871878 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-05 09:19:53.871243.871243 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-05 09:19:53.888284.888284 mlpmodule.py:704] group tensors cost 0.01656794548034668 s
DEBUG 01-05 09:19:53.891748.891748 mlpmodule.py:742] pad cost 0.001947641372680664 s
DEBUG 01-05 09:19:53.891057.891057 mlpmodule.py:748] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-05 09:19:53.891191.891191 mlpmodule.py:753] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-05 09:19:53.904148.904148 mlpmodule.py:767] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-05 09:19:53.905199.905199 mlpmodule.py:768] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-05 09:19:53.905792.905792 mlpmodule.py:773] group_w3 first element: 0.0191650390625
WARNING 01-05 09:19:53.905457.905457 mlpmodule.py:783] start einsum2
DEBUG 01-05 09:19:53.924704.924704 mlpmodule.py:793] group einsum cost 0.033033132553100586 s
DEBUG 01-05 09:19:53.927157.927157 mlpmodule.py:801] cpy2cputensor cost 0.003071308135986328 s
DEBUG 01-05 09:19:53.963656.963656 cuda_h.py:19] end wait_cetm_experts cost 0.09180068969726562 seconds
DEBUG 01-05 09:19:53.963109.963109 cuda_h.py:10] start gpu_sexperts
DEBUG 01-05 09:19:53.964629.964629 cuda_h.py:19] end gpu_sexperts cost 0.00044798851013183594 seconds
DEBUG 01-05 09:19:53.964757.964757 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-05 09:19:53.964116.964116 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.239776611328125e-05 seconds
DEBUG 01-05 09:19:53.964058.964058 cuda_h.py:10] start wait_experts
INFO 01-05 09:19:53.964291.964291 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 969b7c3e-09fc-4b88-b0aa-19ffb91aa479
INFO 01-05 09:19:53.965367.965367 client.py:127] Model loaded
DEBUG 01-05 09:19:53.965064.965064 cuda_h.py:19] end wait_experts cost 0.0009565353393554688 seconds
DEBUG 01-05 09:19:53.965198.965198 cuda_h.py:10] start gpu_experts
DEBUG 01-05 09:19:53.965238.965238 lmp.py:464]   Computing 32 experts on GPU...
DEBUG 01-05 09:19:53.965746.965746 mlpmodule.py:531] gpu group tensors cost 0.0006461143493652344 s
DEBUG 01-05 09:19:53.967838.967838 mlpmodule.py:564] gpu pad cost 0.0016984939575195312 s
DEBUG 01-05 09:19:53.968380.968380 mlpmodule.py:582] gpu group einsum cost 0.0005013942718505859 s
DEBUG 01-05 09:19:53.971286.971286 mlpmodule.py:611] gpu experts func einsum cost 0.006484270095825195 s
DEBUG 01-05 09:19:53.971322.971322 cuda_h.py:19] end gpu_experts cost 0.006663799285888672 seconds
DEBUG 01-05 09:19:53.971132.971132 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-05 09:19:53.971901.971901 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.298324584960938e-06 seconds
DEBUG 01-05 09:19:53.972999.972999 cuda_h.py:19] end layer_moe_generate_27 cost 0.1078481674194336 seconds
DEBUG 01-05 09:19:53.972337.972337 lmp.py:214] -------------------------------- end layer 27 --------------------------------
DEBUG 01-05 09:19:53.972974.972974 cuda_h.py:19] end multi_layer cost 3.1304008960723877 seconds
DEBUG 01-05 09:19:53.972439.972439 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-05 09:19:53.973558.973558 mlpmodule.py:662]  experts func einsum cost 0.10176515579223633 s
DEBUG 01-05 09:19:53.975896.975896 cuda_h.py:19] end init_inputs_tokens cost 0.003137350082397461 seconds
DEBUG 01-05 09:19:53.975230.975230 lmp.py:283] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:19:53.975032.975032 cuda_h.py:10] start dense_mlp
DEBUG 01-05 09:19:53.976463.976463 lmp.py:286] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-05 09:19:53.976928.976928 cuda_h.py:19] end dense_mlp cost 0.000629425048828125 seconds
INFO 01-05 09:19:53.976710.976710 lmp.py:523] 
INFO 01-05 09:19:53.976710.976710 lmp.py:523] ============================================================
INFO 01-05 09:19:53.976765.976765 lmp.py:524] Layer 1 Expert Device Distribution:
INFO 01-05 09:19:53.977157.977157 lmp.py:533]   Total experts: 64
INFO 01-05 09:19:53.977012.977012 lmp.py:535]   meta: 32 experts - Expert IDs: [0, 1, 3, 4, 11, 13, 15, 17, 18, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 41, 47, 49, 52, 53, 54, 55, 56, 58, 62]
INFO 01-05 09:19:53.977954.977954 lmp.py:535]   cuda:1: 32 experts - Expert IDs: [2, 5, 6, 7, 8, 9, 10, 12, 14, 16, 19, 20, 23, 24, 26, 34, 35, 36, 40, 42, 43, 44, 45, 46, 48, 50, 51, 57, 59, 60, 61, 63]
INFO 01-05 09:19:53.977411.977411 lmp.py:538] 
INFO 01-05 09:19:53.977411.977411 lmp.py:538]   Detailed Expert Device Map:
INFO 01-05 09:19:53.977253.977253 lmp.py:539]   Expert ID  | Device         
INFO 01-05 09:19:53.977472.977472 lmp.py:540]   ------------------------------
INFO 01-05 09:19:53.977506.977506 lmp.py:543]   0          | meta           
INFO 01-05 09:19:53.977156.977156 lmp.py:543]   1          | meta           
INFO 01-05 09:19:53.977137.977137 lmp.py:543]   2          | cuda:1         
INFO 01-05 09:19:53.977879.977879 lmp.py:543]   3          | meta           
INFO 01-05 09:19:53.977383.977383 lmp.py:543]   4          | meta           
INFO 01-05 09:19:53.977172.977172 lmp.py:543]   5          | cuda:1         
INFO 01-05 09:19:53.977438.977438 lmp.py:543]   6          | cuda:1         
INFO 01-05 09:19:53.977703.977703 lmp.py:543]   7          | cuda:1         
INFO 01-05 09:19:53.977969.977969 lmp.py:543]   8          | cuda:1         
INFO 01-05 09:19:53.977711.977711 lmp.py:543]   9          | cuda:1         
INFO 01-05 09:19:53.977454.977454 lmp.py:543]   10         | cuda:1         
INFO 01-05 09:19:53.977719.977719 lmp.py:543]   11         | meta           
INFO 01-05 09:19:53.977746.977746 lmp.py:543]   12         | cuda:1         
INFO 01-05 09:19:53.977250.977250 lmp.py:543]   13         | meta           
INFO 01-05 09:19:53.977993.977993 lmp.py:543]   14         | cuda:1         
INFO 01-05 09:19:53.977258.977258 lmp.py:543]   15         | meta           
INFO 01-05 09:19:53.977193.977193 lmp.py:543]   16         | cuda:1         
INFO 01-05 09:19:53.977935.977935 lmp.py:543]   17         | meta           
INFO 01-05 09:19:53.977439.977439 lmp.py:543]   18         | meta           
INFO 01-05 09:19:53.977182.977182 lmp.py:543]   19         | cuda:1         
INFO 01-05 09:19:53.977209.977209 lmp.py:543]   20         | cuda:1         
INFO 01-05 09:19:53.977190.977190 lmp.py:543]   21         | meta           
INFO 01-05 09:19:53.977694.977694 lmp.py:543]   22         | meta           
INFO 01-05 09:19:53.977959.977959 lmp.py:543]   23         | cuda:1         
INFO 01-05 09:19:53.977702.977702 lmp.py:543]   24         | cuda:1         
INFO 01-05 09:19:53.977636.977636 lmp.py:543]   25         | meta           
INFO 01-05 09:19:53.977802.977802 lmp.py:543]   26         | cuda:1         
INFO 01-05 09:19:53.977253.977253 lmp.py:543]   27         | meta           
INFO 01-05 09:19:53.977466.977466 lmp.py:543]   28         | meta           
INFO 01-05 09:19:53.977917.977917 lmp.py:543]   29         | meta           
INFO 01-05 09:19:53.977560.977560 lmp.py:543]   30         | meta           
INFO 01-05 09:19:53.977395.977395 lmp.py:543]   31         | meta           
INFO 01-05 09:19:53.977846.977846 lmp.py:543]   32         | meta           
INFO 01-05 09:19:53.977058.977058 lmp.py:543]   33         | meta           
INFO 01-05 09:19:53.977509.977509 lmp.py:543]   34         | cuda:1         
INFO 01-05 09:19:53.977245.977245 lmp.py:543]   35         | cuda:1         
INFO 01-05 09:19:53.977457.977457 lmp.py:543]   36         | cuda:1         
INFO 01-05 09:19:53.977338.977338 lmp.py:543]   37         | meta           
INFO 01-05 09:19:53.977505.977505 lmp.py:543]   38         | meta           
INFO 01-05 09:19:53.977955.977955 lmp.py:543]   39         | meta           
INFO 01-05 09:19:53.977406.977406 lmp.py:543]   40         | cuda:1         
INFO 01-05 09:19:53.977619.977619 lmp.py:543]   41         | meta           
INFO 01-05 09:19:53.977070.977070 lmp.py:543]   42         | cuda:1         
INFO 01-05 09:19:53.977680.977680 lmp.py:543]   43         | cuda:1         
INFO 01-05 09:19:53.978892.978892 lmp.py:543]   44         | cuda:1         
INFO 01-05 09:19:53.978866.978866 lmp.py:543]   45         | cuda:1         
INFO 01-05 09:19:53.978602.978602 lmp.py:543]   46         | cuda:1         
INFO 01-05 09:19:53.978576.978576 lmp.py:543]   47         | meta           
INFO 01-05 09:19:53.978550.978550 lmp.py:543]   48         | cuda:1         
INFO 01-05 09:19:53.978193.978193 lmp.py:543]   49         | meta           
INFO 01-05 09:19:53.978167.978167 lmp.py:543]   50         | cuda:1         
INFO 01-05 09:19:53.978380.978380 lmp.py:543]   51         | cuda:1         
INFO 01-05 09:19:53.978115.978115 lmp.py:543]   52         | meta           
INFO 01-05 09:19:53.978089.978089 lmp.py:543]   53         | meta           
INFO 01-05 09:19:53.978825.978825 lmp.py:543]   54         | meta           
INFO 01-05 09:19:53.978183.978183 lmp.py:543]   55         | meta           
INFO 01-05 09:19:53.978588.978588 lmp.py:543]   56         | meta           
INFO 01-05 09:19:53.978323.978323 lmp.py:543]   57         | cuda:1         
INFO 01-05 09:19:53.978297.978297 lmp.py:543]   58         | meta           
INFO 01-05 09:19:53.978795.978795 lmp.py:543]   59         | cuda:1         
INFO 01-05 09:19:53.978769.978769 lmp.py:543]   60         | cuda:1         
INFO 01-05 09:19:53.978650.978650 lmp.py:543]   61         | cuda:1         
INFO 01-05 09:19:53.978862.978862 lmp.py:543]   62         | meta           
INFO 01-05 09:19:53.978360.978360 lmp.py:543]   63         | cuda:1         
INFO 01-05 09:19:53.978095.978095 lmp.py:544] ============================================================
INFO 01-05 09:19:53.978095.978095 lmp.py:544] 
DEBUG 01-05 09:19:53.978738.978738 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-05 09:19:53.978064.978064 cuda_h.py:10] start gate
DEBUG 01-05 09:19:53.978679.978679 cuda_h.py:19] end gate cost 0.0005266666412353516 seconds
DEBUG 01-05 09:19:53.978077.978077 cuda_h.py:10] start experts_map_get
INFO 01-05 09:19:53.979232.979232 lmp.py:608] 
INFO 01-05 09:19:53.979232.979232 lmp.py:608] Layer 1 Expert Device Distribution:
INFO 01-05 09:19:53.979749.979749 lmp.py:609]   Active experts: 48 (out of 64 total)
INFO 01-05 09:19:53.979598.979598 lmp.py:610]   CPU experts: 24 (50%) - Expert IDs: [1, 8, 9, 12, 16, 19, 22, 28, 29, 30, 33, 36, 37, 40, 41, 43, 45, 46, 47, 48, 52, 54, 55, 60]
INFO 01-05 09:19:53.979393.979393 lmp.py:611]   GPU experts: 24 (50%) - Expert IDs: [0, 2, 4, 5, 6, 7, 10, 11, 14, 15, 20, 23, 24, 26, 31, 34, 35, 42, 44, 50, 57, 59, 61, 63]
INFO 01-05 09:19:53.979043.979043 lmp.py:612]   CPU tokens: 45 (23.4%)
INFO 01-05 09:19:53.979878.979878 lmp.py:613]   GPU tokens: 147 (76.6%)
INFO 01-05 09:19:53.979568.979568 lmp.py:614] 
INFO 01-05 09:19:53.979568.979568 lmp.py:614]   Detailed Expert Distribution:
INFO 01-05 09:19:53.979164.979164 lmp.py:615]   Expert ID  | Tokens     | Device       | Token %   
INFO 01-05 09:19:53.979615.979615 lmp.py:616]   --------------------------------------------------
INFO 01-05 09:19:53.979311.979311 lmp.py:620]   12         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979669.979669 lmp.py:620]   22         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979312.979312 lmp.py:620]   29         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979532.979532 lmp.py:620]   36         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979175.979175 lmp.py:620]   37         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979963.979963 lmp.py:620]   48         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979606.979606 lmp.py:620]   52         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979011.979011 lmp.py:620]   54         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979654.979654 lmp.py:620]   55         | 1          | CPU          |   0.52%
INFO 01-05 09:19:53.979535.979535 lmp.py:620]   1          | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979940.979940 lmp.py:620]   8          | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979344.979344 lmp.py:620]   9          | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979749.979749 lmp.py:620]   19         | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979061.979061 lmp.py:620]   28         | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979704.979704 lmp.py:620]   30         | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979108.979108 lmp.py:620]   40         | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979513.979513 lmp.py:620]   45         | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979679.979679 lmp.py:620]   60         | 2          | CPU          |   1.04%
INFO 01-05 09:19:53.979799.979799 lmp.py:620]   16         | 3          | CPU          |   1.56%
INFO 01-05 09:19:53.979442.979442 lmp.py:620]   33         | 3          | CPU          |   1.56%
INFO 01-05 09:19:53.979846.979846 lmp.py:620]   41         | 3          | CPU          |   1.56%
INFO 01-05 09:19:53.979013.979013 lmp.py:620]   43         | 3          | CPU          |   1.56%
INFO 01-05 09:19:53.979417.979417 lmp.py:620]   46         | 3          | CPU          |   1.56%
INFO 01-05 09:19:53.979583.979583 lmp.py:620]   47         | 3          | CPU          |   1.56%
INFO 01-05 09:19:53.979849.979849 lmp.py:620]   50         | 3          | GPU(cuda:1)  |   1.56%
INFO 01-05 09:19:53.979492.979492 lmp.py:620]   0          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.979896.979896 lmp.py:620]   7          | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.979301.979301 lmp.py:620]   11         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.979944.979944 lmp.py:620]   35         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.979541.979541 lmp.py:620]   42         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.979091.979091 lmp.py:620]   44         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.980211.980211 lmp.py:620]   59         | 4          | GPU(cuda:1)  |   2.08%
INFO 01-05 09:19:53.980854.980854 lmp.py:620]   2          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:53.980258.980258 lmp.py:620]   4          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:53.980901.980901 lmp.py:620]   5          | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:53.980736.980736 lmp.py:620]   10         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:53.980810.980810 lmp.py:620]   26         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:53.980214.980214 lmp.py:620]   61         | 5          | GPU(cuda:1)  |   2.60%
INFO 01-05 09:19:53.980334.980334 lmp.py:620]   6          | 6          | GPU(cuda:1)  |   3.12%
INFO 01-05 09:19:53.980500.980500 lmp.py:620]   14         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:53.980905.980905 lmp.py:620]   15         | 7          | GPU(cuda:1)  |   3.65%
INFO 01-05 09:19:53.980309.980309 lmp.py:620]   63         | 8          | GPU(cuda:1)  |   4.17%
INFO 01-05 09:19:53.980383.980383 lmp.py:620]   23         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:53.980456.980456 lmp.py:620]   24         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:53.980861.980861 lmp.py:620]   57         | 9          | GPU(cuda:1)  |   4.69%
INFO 01-05 09:19:53.980265.980265 lmp.py:620]   31         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:19:53.980193.980193 lmp.py:620]   34         | 10         | GPU(cuda:1)  |   5.21%
INFO 01-05 09:19:53.980505.980505 lmp.py:620]   20         | 11         | GPU(cuda:1)  |   5.73%
INFO 01-05 09:19:53.980718.980718 lmp.py:621] ============================================================
INFO 01-05 09:19:53.980718.980718 lmp.py:621] 
DEBUG 01-05 09:19:53.980414.980414 cuda_h.py:19] end experts_map_get cost 0.0013079643249511719 seconds
DEBUG 01-05 09:19:53.980156.980156 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.0019736289978027344 seconds
Collecting data...
Generating '/tmp/nsys-report-5ccf.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [5%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [9%                          ] report1.nsys-rep[1/1] [12%                         ] report1.nsys-rep[1/1] [14%                         ] report1.nsys-rep[1/1] [=16%                        ] report1.nsys-rep[1/1] [==18%                       ] report1.nsys-rep[1/1] [==20%                       ] report1.nsys-rep[1/1] [===22%                      ] report1.nsys-rep[1/1] [====25%                     ] report1.nsys-rep[1/1] [====27%                     ] report1.nsys-rep[1/1] [=====29%                    ] report1.nsys-rep[1/1] [=====31%                    ] report1.nsys-rep[1/1] [======33%                   ] report1.nsys-rep[1/1] [=======36%                  ] report1.nsys-rep[1/1] [=======38%                  ] report1.nsys-rep[1/1] [========40%                 ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [=========45%                ] report1.nsys-rep[1/1] [==========47%               ] report1.nsys-rep[1/1] [==========49%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
