here pin
INFO 01-04 15:35:57.507989.507989 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-04 15:35:58.372225.372225 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-04 15:35:58.815121.815121 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-04 15:35:58.815451.815451 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.309s
DEBUG 01-04 15:35:58.961714.961714 cuda_memory_view.py:260] 
DEBUG 01-04 15:35:58.961714.961714 cuda_memory_view.py:260] restore_tensors_from_shared_memory_names time: 0.01353597640991211
DEBUG 01-04 15:36:01.986162.986162 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11861395835876465 s
DEBUG 01-04 15:36:02.511301.511301 cuda_h.py:19] end generate_input_ids cost 0.5246593952178955 seconds
DEBUG 01-04 15:36:02.511531.511531 cuda_h.py:10] start init_cache
DEBUG 01-04 15:36:02.511941.511941 cuda_h.py:19] end init_cache cost 0.00011777877807617188 seconds
DEBUG 01-04 15:36:05.153090.153090 cuda_h.py:10] start init_weights
DEBUG 01-04 15:36:05.153413.153413 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:05.153044.153044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:05.153811.153811 cuda_h.py:19] end allocate_cuda_memory cost 0.0005161762237548828 seconds
DEBUG 01-04 15:36:05.153371.153371 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:05.153578.153578 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:05.153838.153838 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:05.154978.154978 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f76188b1-6413-442c-b754-206871606c7a
DEBUG 01-04 15:36:05.154578.154578 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:05.155414.155414 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f76188b1-6413-442c-b754-206871606c7a
DEBUG 01-04 15:36:05.155492.155492 cuda_h.py:19] end load_into_gpu_async cost 0.0017881393432617188 seconds
DEBUG 01-04 15:36:05.155793.155793 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:05.156919.156919 cuda_h.py:19] end restore_tensors2 cost 0.00012993812561035156 seconds
DEBUG 01-04 15:36:05.156675.156675 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028295516967773438 seconds
INFO 01-04 15:36:05.156159.156159 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f76188b1-6413-442c-b754-206871606c7a
INFO 01-04 15:36:05.238960.238960 client.py:127] Model loaded
DEBUG 01-04 15:36:05.238581.238581 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-04 15:36:05.238732.238732 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:05.238207.238207 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:05.239489.239489 cuda_h.py:19] end allocate_cuda_memory cost 0.0004189014434814453 seconds
DEBUG 01-04 15:36:05.239912.239912 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:05.239664.239664 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:05.239383.239383 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:05.239346.239346 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0c81463a-ea0e-4ada-b887-c35347fe8e4a
DEBUG 01-04 15:36:05.240710.240710 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:05.241965.241965 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0c81463a-ea0e-4ada-b887-c35347fe8e4a
DEBUG 01-04 15:36:05.242481.242481 cuda_h.py:19] end load_into_gpu_async cost 0.002245664596557617 seconds
DEBUG 01-04 15:36:05.242941.242941 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:05.242771.242771 cuda_h.py:19] end restore_tensors2 cost 0.00017118453979492188 seconds
DEBUG 01-04 15:36:05.242337.242337 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035479068756103516 seconds
INFO 01-04 15:36:05.242731.242731 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0c81463a-ea0e-4ada-b887-c35347fe8e4a
INFO 01-04 15:36:05.259881.259881 client.py:127] Model loaded
DEBUG 01-04 15:36:05.260471.260471 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.0214998722076416 seconds
DEBUG 01-04 15:36:05.260019.260019 cuda_h.py:19] end init_weights cost 0.10729384422302246 seconds
DEBUG 01-04 15:36:05.260618.260618 cuda_h.py:10] start copy_emodel
DEBUG 01-04 15:36:06.256818.256818 cuda_h.py:19] end copy_emodel cost 0.9959509372711182 seconds
DEBUG 01-04 15:36:06.257737.257737 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-04 15:36:06.342408.342408 cuda_h.py:19] end init_inputs_tokens cost 0.0850212574005127 seconds
DEBUG 01-04 15:36:06.342657.342657 cuda_h.py:10] start multi_layer
DEBUG 01-04 15:36:06.342447.342447 lmp.py:169] -------------------------------- start layer 0 --------------------------------
DEBUG 01-04 15:36:06.342004.342004 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:06.431264.431264 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:06.679720.679720 cuda_h.py:19] end self_attn cost 0.2474374771118164 seconds
DEBUG 01-04 15:36:06.679533.679533 cuda_h.py:19] end iln_self_attn_paln cost 0.3371455669403076 seconds
DEBUG 01-04 15:36:06.679058.679058 cuda_h.py:10] start dense_mlp
DEBUG 01-04 15:36:06.680927.680927 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-04 15:36:06.680784.680784 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.9577484130859375e-05 seconds
DEBUG 01-04 15:36:06.680166.680166 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:06.680286.680286 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:06.680697.680697 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:06.681157.681157 cuda_h.py:19] end allocate_cuda_memory cost 0.0003762245178222656 seconds
DEBUG 01-04 15:36:06.681666.681666 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:06.681265.681265 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:06.681361.681361 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:06.681986.681986 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d2e5f413-29a4-4aae-89d5-0b15eacb1eb9
DEBUG 01-04 15:36:06.681980.681980 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:06.683365.683365 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d2e5f413-29a4-4aae-89d5-0b15eacb1eb9
DEBUG 01-04 15:36:06.683555.683555 cuda_h.py:19] end load_into_gpu_async cost 0.002519369125366211 seconds
DEBUG 01-04 15:36:06.683796.683796 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:06.684571.684571 cuda_h.py:19] end restore_tensors2 cost 0.00014662742614746094 seconds
DEBUG 01-04 15:36:06.684548.684548 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003690958023071289 seconds
INFO 01-04 15:36:06.685293.685293 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d2e5f413-29a4-4aae-89d5-0b15eacb1eb9
INFO 01-04 15:36:06.692700.692700 client.py:127] Model loaded
DEBUG 01-04 15:36:06.692202.692202 cuda_h.py:19] end sllm_worker_task cost 0.01195216178894043 seconds
DEBUG 01-04 15:36:06.692085.692085 cuda_h.py:19] end dense_mlp cost 0.01259922981262207 seconds
DEBUG 01-04 15:36:06.692715.692715 lmp.py:207] -------------------------------- end layer 0 --------------------------------
DEBUG 01-04 15:36:06.692194.692194 lmp.py:169] -------------------------------- start layer 1 --------------------------------
DEBUG 01-04 15:36:06.692831.692831 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:06.693100.693100 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:06.698047.698047 cuda_h.py:19] end self_attn cost 0.004843473434448242 seconds
DEBUG 01-04 15:36:06.699557.699557 cuda_h.py:19] end iln_self_attn_paln cost 0.005983829498291016 seconds
DEBUG 01-04 15:36:06.699276.699276 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-04 15:36:06.699855.699855 cuda_h.py:10] start gate
DEBUG 01-04 15:36:06.796438.796438 cuda_h.py:19] end gate cost 0.09724593162536621 seconds
DEBUG 01-04 15:36:06.796680.796680 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:06.797572.797572 lmp.py:281] 
DEBUG 01-04 15:36:06.797572.797572 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:06.797149.797149 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:06.797137.797137 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:06.797879.797879 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:06.797476.797476 lmp.py:285] 
DEBUG 01-04 15:36:06.797476.797476 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:06.797550.797550 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:06.797583.797583 lmp.py:292]   Expert 62 |     66 | CPU
DEBUG 01-04 15:36:06.797134.797134 lmp.py:292]   Expert 18 |     68 | CPU
DEBUG 01-04 15:36:06.797492.797492 lmp.py:292]   Expert 22 |     73 | CPU
DEBUG 01-04 15:36:06.797373.797373 lmp.py:292]   Expert 32 |     83 | CPU
DEBUG 01-04 15:36:06.797255.797255 lmp.py:292]   Expert 52 |     94 | CPU
DEBUG 01-04 15:36:06.797613.797613 lmp.py:292]   Expert  3 |    104 | CPU
DEBUG 01-04 15:36:06.797494.797494 lmp.py:292]   Expert 27 |    114 | CPU
DEBUG 01-04 15:36:06.797045.797045 lmp.py:292]   Expert 38 |    114 | CPU
DEBUG 01-04 15:36:06.797880.797880 lmp.py:292]   Expert 13 |    118 | CPU
DEBUG 01-04 15:36:06.797192.797192 lmp.py:292]   Expert 54 |    118 | CPU
DEBUG 01-04 15:36:06.797457.797457 lmp.py:292]   Expert 17 |    121 | CPU
DEBUG 01-04 15:36:06.797577.797577 lmp.py:292]   Expert 11 |    124 | CPU
DEBUG 01-04 15:36:06.797935.797935 lmp.py:292]   Expert 28 |    124 | CPU
DEBUG 01-04 15:36:06.797817.797817 lmp.py:292]   Expert 37 |    125 | CPU
DEBUG 01-04 15:36:06.797460.797460 lmp.py:292]   Expert 58 |    129 | CPU
DEBUG 01-04 15:36:06.797580.797580 lmp.py:292]   Expert 39 |    131 | CPU
DEBUG 01-04 15:36:06.797461.797461 lmp.py:292]   Expert 25 |    135 | CPU
DEBUG 01-04 15:36:06.797104.797104 lmp.py:292]   Expert 41 |    136 | CPU
DEBUG 01-04 15:36:06.797462.797462 lmp.py:292]   Expert 21 |    150 | CPU
DEBUG 01-04 15:36:06.797105.797105 lmp.py:292]   Expert  4 |    151 | CPU
DEBUG 01-04 15:36:06.797748.797748 lmp.py:292]   Expert 30 |    152 | CPU
DEBUG 01-04 15:36:06.797583.797583 lmp.py:292]   Expert 29 |    155 | CPU
DEBUG 01-04 15:36:06.797895.797895 lmp.py:292]   Expert 53 |    155 | CPU
DEBUG 01-04 15:36:06.797969.797969 lmp.py:292]   Expert 49 |    156 | CPU
DEBUG 01-04 15:36:06.797611.797611 lmp.py:292]   Expert 47 |    157 | CPU
DEBUG 01-04 15:36:06.797731.797731 lmp.py:292]   Expert 31 |    168 | CPU
DEBUG 01-04 15:36:06.797613.797613 lmp.py:292]   Expert 33 |    168 | CPU
DEBUG 01-04 15:36:06.797256.797256 lmp.py:292]   Expert 55 |    173 | CPU
DEBUG 01-04 15:36:06.797899.797899 lmp.py:292]   Expert 56 |    173 | CPU
DEBUG 01-04 15:36:06.797542.797542 lmp.py:292]   Expert 15 |    177 | CPU
DEBUG 01-04 15:36:06.797423.797423 lmp.py:292]   Expert  0 |    178 | CPU
DEBUG 01-04 15:36:06.797066.797066 lmp.py:292]   Expert  1 |    178 | CPU
DEBUG 01-04 15:36:06.797947.797947 lmp.py:292]   Expert 24 |    180 | GPU
DEBUG 01-04 15:36:06.797259.797259 lmp.py:292]   Expert 50 |    182 | GPU
DEBUG 01-04 15:36:06.797141.797141 lmp.py:292]   Expert 51 |    184 | GPU
DEBUG 01-04 15:36:06.797453.797453 lmp.py:292]   Expert 19 |    185 | GPU
DEBUG 01-04 15:36:06.797334.797334 lmp.py:292]   Expert  6 |    186 | GPU
DEBUG 01-04 15:36:06.797977.797977 lmp.py:292]   Expert 10 |    189 | GPU
DEBUG 01-04 15:36:06.797620.797620 lmp.py:292]   Expert 34 |    191 | GPU
DEBUG 01-04 15:36:06.798263.798263 lmp.py:292]   Expert  2 |    195 | GPU
DEBUG 01-04 15:36:06.798667.798667 lmp.py:292]   Expert 45 |    195 | GPU
DEBUG 01-04 15:36:06.798310.798310 lmp.py:292]   Expert 35 |    197 | GPU
DEBUG 01-04 15:36:06.798715.798715 lmp.py:292]   Expert 36 |    198 | GPU
DEBUG 01-04 15:36:06.798120.798120 lmp.py:292]   Expert 61 |    209 | GPU
DEBUG 01-04 15:36:06.798524.798524 lmp.py:292]   Expert 44 |    214 | GPU
DEBUG 01-04 15:36:06.798167.798167 lmp.py:292]   Expert 12 |    223 | GPU
DEBUG 01-04 15:36:06.798002.798002 lmp.py:292]   Expert  5 |    227 | GPU
DEBUG 01-04 15:36:06.798076.798076 lmp.py:292]   Expert 23 |    235 | GPU
DEBUG 01-04 15:36:06.798195.798195 lmp.py:292]   Expert 60 |    235 | GPU
DEBUG 01-04 15:36:06.798315.798315 lmp.py:292]   Expert 43 |    239 | GPU
DEBUG 01-04 15:36:06.798197.798197 lmp.py:292]   Expert  9 |    246 | GPU
DEBUG 01-04 15:36:06.798840.798840 lmp.py:292]   Expert 48 |    252 | GPU
DEBUG 01-04 15:36:06.798483.798483 lmp.py:292]   Expert  8 |    262 | GPU
DEBUG 01-04 15:36:06.798126.798126 lmp.py:292]   Expert 20 |    273 | GPU
DEBUG 01-04 15:36:06.798769.798769 lmp.py:292]   Expert 26 |    285 | GPU
DEBUG 01-04 15:36:06.798412.798412 lmp.py:292]   Expert 57 |    292 | GPU
DEBUG 01-04 15:36:06.798816.798816 lmp.py:292]   Expert  7 |    308 | GPU
DEBUG 01-04 15:36:06.798221.798221 lmp.py:292]   Expert 59 |    308 | GPU
DEBUG 01-04 15:36:06.798625.798625 lmp.py:292]   Expert 16 |    310 | GPU
DEBUG 01-04 15:36:06.798699.798699 lmp.py:292]   Expert 63 |    313 | GPU
DEBUG 01-04 15:36:06.798872.798872 lmp.py:292]   Expert 40 |    320 | GPU
DEBUG 01-04 15:36:06.798184.798184 lmp.py:292]   Expert 46 |    320 | GPU
DEBUG 01-04 15:36:06.798065.798065 lmp.py:292]   Expert 42 |    342 | GPU
DEBUG 01-04 15:36:06.798708.798708 lmp.py:292]   Expert 14 |    525 | GPU
DEBUG 01-04 15:36:06.798232.798232 lmp.py:293] 
DEBUG 01-04 15:36:06.798232.798232 lmp.py:293]   CPU total tokens: 4268 (34.7%)
DEBUG 01-04 15:36:06.798783.798783 lmp.py:294]   GPU total tokens: 8020 (65.3%)
DEBUG 01-04 15:36:06.798962.798962 cuda_h.py:19] end experts_map_get cost 0.0018601417541503906 seconds
DEBUG 01-04 15:36:06.798705.798705 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:06.798011.798011 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:06.798927.798927 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:06.799615.799615 cuda_h.py:19] end allocate_cuda_memory cost 0.00031256675720214844 seconds
DEBUG 01-04 15:36:06.799975.799975 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:06.799169.799169 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:06.799753.799753 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:06.799933.799933 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 89fc3348-2428-4813-9845-dbb514bbcb7c
DEBUG 01-04 15:36:06.799072.799072 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:06.801698.801698 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 89fc3348-2428-4813-9845-dbb514bbcb7c
DEBUG 01-04 15:36:06.802253.802253 cuda_h.py:19] end load_into_gpu_async cost 0.0027120113372802734 seconds
DEBUG 01-04 15:36:06.802607.802607 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:06.802245.802245 cuda_h.py:19] end restore_tensors2 cost 0.00039839744567871094 seconds
DEBUG 01-04 15:36:06.802876.802876 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004050731658935547 seconds
DEBUG 01-04 15:36:06.805243.805243 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0073544979095458984 seconds
DEBUG 01-04 15:36:06.805987.805987 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:06.806840.806840 lmp.py:339] 
DEBUG 01-04 15:36:06.806840.806840 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:06.806095.806095 cuda_h.py:19] end cpu_experts_submit cost 0.00022411346435546875 seconds
DEBUG 01-04 15:36:06.806944.806944 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:06.821643.821643 mlpmodule.py:704] group tensors cost 0.015303850173950195 s
DEBUG 01-04 15:36:06.824288.824288 mlpmodule.py:742] pad cost 0.001956939697265625 s
DEBUG 01-04 15:36:06.824298.824298 mlpmodule.py:748] create cpu tensor cost 5.888938903808594e-05 s
DEBUG 01-04 15:36:06.824440.824440 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-04 15:36:06.860543.860543 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:06.861798.861798 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:06.861823.861823 mlpmodule.py:774] group_w3 first element: -0.0107421875
WARNING 01-04 15:36:06.870151.870151 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:06.880831.880831 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:06.881300.881300 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:06.891370.891370 mlpmodule.py:797] group einsum cost 0.0670626163482666 s
DEBUG 01-04 15:36:06.892403.892403 mlpmodule.py:805] cpy2cputensor cost 0.0007081031799316406 s
DEBUG 01-04 15:36:06.902167.902167 cuda_h.py:19] end wait_cetm_experts cost 0.09618592262268066 seconds
DEBUG 01-04 15:36:06.902616.902616 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:06.903102.903102 cuda_h.py:19] end gpu_sexperts cost 0.00061798095703125 seconds
DEBUG 01-04 15:36:06.903270.903270 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-04 15:36:06.903259.903259 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-04 15:36:06.903249.903249 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.1021575927734375e-05 seconds
DEBUG 01-04 15:36:06.903979.903979 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 0.000102996826171875 seconds
DEBUG 01-04 15:36:06.903073.903073 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:06.903419.903419 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 89fc3348-2428-4813-9845-dbb514bbcb7c
DEBUG 01-04 15:36:06.904920.904920 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:06.904280.904280 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:06.904831.904831 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:06.907689.907689 cuda_h.py:19] end allocate_cuda_memory cost 0.0035941600799560547 seconds
DEBUG 01-04 15:36:06.907811.907811 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:06.907640.907640 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:06.908424.908424 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:06.908418.908418 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 91568c9f-5c9a-47ae-a5bd-a26c45a21cf9
DEBUG 01-04 15:36:06.908494.908494 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:06.908998.908998 client.py:127] Model loaded
DEBUG 01-04 15:36:06.908246.908246 cuda_h.py:19] end wait_experts cost 0.004720926284790039 seconds
DEBUG 01-04 15:36:06.908487.908487 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:06.908587.908587 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:06.909805.909805 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 91568c9f-5c9a-47ae-a5bd-a26c45a21cf9
DEBUG 01-04 15:36:06.909278.909278 cuda_h.py:19] end load_into_gpu_async cost 0.0016274452209472656 seconds
DEBUG 01-04 15:36:06.909981.909981 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:06.914111.914111 cuda_h.py:19] end restore_tensors2 cost 0.004420757293701172 seconds
DEBUG 01-04 15:36:06.914048.914048 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010047435760498047 seconds
INFO 01-04 15:36:06.914199.914199 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 91568c9f-5c9a-47ae-a5bd-a26c45a21cf9
INFO 01-04 15:36:06.917026.917026 client.py:127] Model loaded
DEBUG 01-04 15:36:06.917084.917084 cuda_h.py:19] end sllm_worker_task cost 0.013707876205444336 seconds
DEBUG 01-04 15:36:06.920269.920269 mlpmodule.py:662]  experts func einsum cost 0.11417746543884277 s
DEBUG 01-04 15:36:06.920507.920507 mlpmodule.py:531] gpu group tensors cost 0.012146234512329102 s
DEBUG 01-04 15:36:06.922278.922278 mlpmodule.py:564] gpu pad cost 0.001539468765258789 s
DEBUG 01-04 15:36:06.923070.923070 mlpmodule.py:582] gpu group einsum cost 0.001050710678100586 s
DEBUG 01-04 15:36:06.926626.926626 mlpmodule.py:611] gpu experts func einsum cost 0.017688989639282227 s
DEBUG 01-04 15:36:06.926066.926066 cuda_h.py:19] end gpu_experts cost 0.01784229278564453 seconds
DEBUG 01-04 15:36:06.926960.926960 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:06.926426.926426 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-04 15:36:06.926193.926193 cuda_h.py:19] end layer_moe_generate_1 cost 0.2274770736694336 seconds
DEBUG 01-04 15:36:06.926026.926026 lmp.py:207] -------------------------------- end layer 1 --------------------------------
DEBUG 01-04 15:36:06.926073.926073 lmp.py:169] -------------------------------- start layer 2 --------------------------------
DEBUG 01-04 15:36:06.926531.926531 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:06.927997.927997 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:06.929616.929616 cuda_h.py:19] end self_attn cost 0.002402782440185547 seconds
DEBUG 01-04 15:36:06.929242.929242 cuda_h.py:19] end iln_self_attn_paln cost 0.003022909164428711 seconds
DEBUG 01-04 15:36:06.929655.929655 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-04 15:36:06.930133.930133 cuda_h.py:10] start gate
DEBUG 01-04 15:36:06.930265.930265 cuda_h.py:19] end gate cost 0.0005543231964111328 seconds
DEBUG 01-04 15:36:06.930426.930426 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:06.930568.930568 lmp.py:281] 
DEBUG 01-04 15:36:06.930568.930568 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:06.930185.930185 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:06.930073.930073 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:06.931385.931385 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:06.931551.931551 lmp.py:285] 
DEBUG 01-04 15:36:06.931551.931551 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:06.931386.931386 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:06.931989.931989 lmp.py:292]   Expert 34 |     42 | CPU
DEBUG 01-04 15:36:06.931394.931394 lmp.py:292]   Expert 36 |     49 | CPU
DEBUG 01-04 15:36:06.931606.931606 lmp.py:292]   Expert 58 |     65 | CPU
DEBUG 01-04 15:36:06.931296.931296 lmp.py:292]   Expert  3 |     67 | CPU
DEBUG 01-04 15:36:06.931985.931985 lmp.py:292]   Expert 26 |     69 | CPU
DEBUG 01-04 15:36:06.931674.931674 lmp.py:292]   Expert 27 |     77 | CPU
DEBUG 01-04 15:36:06.931887.931887 lmp.py:292]   Expert  8 |     78 | CPU
DEBUG 01-04 15:36:06.931338.931338 lmp.py:292]   Expert 29 |     80 | CPU
DEBUG 01-04 15:36:06.931550.931550 lmp.py:292]   Expert  7 |     94 | CPU
DEBUG 01-04 15:36:06.931763.931763 lmp.py:292]   Expert 10 |     99 | CPU
DEBUG 01-04 15:36:06.931452.931452 lmp.py:292]   Expert 28 |    107 | CPU
DEBUG 01-04 15:36:06.931618.931618 lmp.py:292]   Expert 21 |    108 | CPU
DEBUG 01-04 15:36:06.931069.931069 lmp.py:292]   Expert 13 |    109 | CPU
DEBUG 01-04 15:36:06.931758.931758 lmp.py:292]   Expert 19 |    114 | CPU
DEBUG 01-04 15:36:06.931971.931971 lmp.py:292]   Expert 62 |    126 | CPU
DEBUG 01-04 15:36:06.931422.931422 lmp.py:292]   Expert 40 |    133 | CPU
DEBUG 01-04 15:36:06.931872.931872 lmp.py:292]   Expert  5 |    140 | CPU
DEBUG 01-04 15:36:06.931085.931085 lmp.py:292]   Expert 52 |    141 | CPU
DEBUG 01-04 15:36:06.931536.931536 lmp.py:292]   Expert 63 |    141 | CPU
DEBUG 01-04 15:36:06.931987.931987 lmp.py:292]   Expert  9 |    148 | CPU
DEBUG 01-04 15:36:06.931438.931438 lmp.py:292]   Expert 25 |    149 | CPU
DEBUG 01-04 15:36:06.931842.931842 lmp.py:292]   Expert 50 |    153 | CPU
DEBUG 01-04 15:36:06.931008.931008 lmp.py:292]   Expert 59 |    153 | CPU
DEBUG 01-04 15:36:06.931936.931936 lmp.py:292]   Expert 33 |    154 | CPU
DEBUG 01-04 15:36:06.931910.931910 lmp.py:292]   Expert 17 |    157 | CPU
DEBUG 01-04 15:36:06.931122.931122 lmp.py:292]   Expert 49 |    157 | CPU
DEBUG 01-04 15:36:06.931858.931858 lmp.py:292]   Expert 16 |    160 | CPU
DEBUG 01-04 15:36:06.931071.931071 lmp.py:292]   Expert 60 |    165 | CPU
DEBUG 01-04 15:36:06.931521.931521 lmp.py:292]   Expert 24 |    166 | CPU
DEBUG 01-04 15:36:06.931211.931211 lmp.py:292]   Expert  0 |    167 | CPU
DEBUG 01-04 15:36:06.931423.931423 lmp.py:292]   Expert 30 |    170 | CPU
DEBUG 01-04 15:36:06.931113.931113 lmp.py:292]   Expert 35 |    170 | CPU
DEBUG 01-04 15:36:06.931325.931325 lmp.py:292]   Expert  1 |    173 | GPU
DEBUG 01-04 15:36:06.931537.931537 lmp.py:292]   Expert 38 |    178 | GPU
DEBUG 01-04 15:36:06.931750.931750 lmp.py:292]   Expert  6 |    180 | GPU
DEBUG 01-04 15:36:06.931201.931201 lmp.py:292]   Expert 45 |    180 | GPU
DEBUG 01-04 15:36:06.931128.931128 lmp.py:292]   Expert 44 |    184 | GPU
DEBUG 01-04 15:36:06.931771.931771 lmp.py:292]   Expert 31 |    199 | GPU
DEBUG 01-04 15:36:06.931222.931222 lmp.py:292]   Expert 48 |    206 | GPU
DEBUG 01-04 15:36:06.931435.931435 lmp.py:292]   Expert 39 |    228 | GPU
DEBUG 01-04 15:36:06.931647.931647 lmp.py:292]   Expert 37 |    237 | GPU
DEBUG 01-04 15:36:06.931098.931098 lmp.py:292]   Expert 55 |    238 | GPU
DEBUG 01-04 15:36:06.931311.931311 lmp.py:292]   Expert  4 |    239 | GPU
DEBUG 01-04 15:36:06.931762.931762 lmp.py:292]   Expert 22 |    241 | GPU
DEBUG 01-04 15:36:06.931974.931974 lmp.py:292]   Expert 14 |    242 | GPU
DEBUG 01-04 15:36:06.931948.931948 lmp.py:292]   Expert 51 |    248 | GPU
DEBUG 01-04 15:36:06.931160.931160 lmp.py:292]   Expert 57 |    253 | GPU
DEBUG 01-04 15:36:06.931611.931611 lmp.py:292]   Expert  2 |    254 | GPU
DEBUG 01-04 15:36:06.931585.931585 lmp.py:292]   Expert 41 |    255 | GPU
DEBUG 01-04 15:36:06.931990.931990 lmp.py:292]   Expert 12 |    263 | GPU
DEBUG 01-04 15:36:06.931395.931395 lmp.py:292]   Expert 47 |    269 | GPU
DEBUG 01-04 15:36:06.931845.931845 lmp.py:292]   Expert 20 |    272 | GPU
DEBUG 01-04 15:36:06.931296.931296 lmp.py:292]   Expert 15 |    275 | GPU
DEBUG 01-04 15:36:06.931270.931270 lmp.py:292]   Expert 42 |    281 | GPU
DEBUG 01-04 15:36:06.931483.931483 lmp.py:292]   Expert 23 |    287 | GPU
DEBUG 01-04 15:36:06.931457.931457 lmp.py:292]   Expert 53 |    304 | GPU
DEBUG 01-04 15:36:06.931669.931669 lmp.py:292]   Expert 61 |    306 | GPU
DEBUG 01-04 15:36:06.932882.932882 lmp.py:292]   Expert 56 |    312 | GPU
DEBUG 01-04 15:36:06.932094.932094 lmp.py:292]   Expert 18 |    314 | GPU
DEBUG 01-04 15:36:06.932068.932068 lmp.py:292]   Expert 54 |    315 | GPU
DEBUG 01-04 15:36:06.932281.932281 lmp.py:292]   Expert 46 |    330 | GPU
DEBUG 01-04 15:36:06.932970.932970 lmp.py:292]   Expert 32 |    338 | GPU
DEBUG 01-04 15:36:06.932898.932898 lmp.py:292]   Expert 43 |    364 | GPU
DEBUG 01-04 15:36:06.932587.932587 lmp.py:292]   Expert 11 |    415 | GPU
DEBUG 01-04 15:36:06.932230.932230 lmp.py:293] 
DEBUG 01-04 15:36:06.932230.932230 lmp.py:293]   CPU total tokens: 3908 (31.8%)
DEBUG 01-04 15:36:06.932158.932158 lmp.py:294]   GPU total tokens: 8380 (68.2%)
DEBUG 01-04 15:36:06.932854.932854 cuda_h.py:19] end experts_map_get cost 0.0014810562133789062 seconds
DEBUG 01-04 15:36:06.932258.932258 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:06.932366.932366 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:06.932244.932244 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:06.932536.932536 cuda_h.py:19] end allocate_cuda_memory cost 0.00018310546875 seconds
DEBUG 01-04 15:36:06.932333.932333 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:06.932658.932658 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:06.932183.932183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:06.932356.932356 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6cd487a7-b1c0-4b51-b92a-a1c81c9bdb53
DEBUG 01-04 15:36:06.932533.932533 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:06.934558.934558 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6cd487a7-b1c0-4b51-b92a-a1c81c9bdb53
DEBUG 01-04 15:36:06.934503.934503 cuda_h.py:19] end load_into_gpu_async cost 0.0022547245025634766 seconds
DEBUG 01-04 15:36:06.934273.934273 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:06.935541.935541 cuda_h.py:19] end restore_tensors2 cost 0.0004105567932128906 seconds
DEBUG 01-04 15:36:06.935669.935669 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00328826904296875 seconds
DEBUG 01-04 15:36:06.939651.939651 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007344961166381836 seconds
DEBUG 01-04 15:36:06.939376.939376 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:06.939108.939108 lmp.py:339] 
DEBUG 01-04 15:36:06.939108.939108 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:06.939707.939707 cuda_h.py:19] end cpu_experts_submit cost 0.0001533031463623047 seconds
DEBUG 01-04 15:36:06.939669.939669 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:06.954955.954955 mlpmodule.py:704] group tensors cost 0.014733076095581055 s
DEBUG 01-04 15:36:06.958294.958294 mlpmodule.py:742] pad cost 0.002653360366821289 s
DEBUG 01-04 15:36:06.958888.958888 mlpmodule.py:748] create cpu tensor cost 7.2479248046875e-05 s
DEBUG 01-04 15:36:06.959170.959170 mlpmodule.py:753] move to cpu cost 5.221366882324219e-05 s
DEBUG 01-04 15:36:06.968148.968148 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:06.968017.968017 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:06.969968.969968 mlpmodule.py:774] group_w3 first element: -0.0380859375
WARNING 01-04 15:36:06.969583.969583 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:06.977695.977695 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:06.977156.977156 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:06.987987.987987 mlpmodule.py:797] group einsum cost 0.028830766677856445 s
DEBUG 01-04 15:36:06.988906.988906 mlpmodule.py:805] cpy2cputensor cost 0.000682830810546875 s
DEBUG 01-04 15:36:06.999910.999910 cuda_h.py:19] end wait_cetm_experts cost 0.05953383445739746 seconds
DEBUG 01-04 15:36:06.999956.999956 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.000865.000865 cuda_h.py:19] end gpu_sexperts cost 0.0005879402160644531 seconds
DEBUG 01-04 15:36:07.000417.000417 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-04 15:36:07.000578.000578 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-04 15:36:07.000415.000415 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.458427429199219e-05 seconds
DEBUG 01-04 15:36:07.000948.000948 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.000808.000808 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.000764.000764 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.000897.000897 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 0.00019311904907226562 seconds
DEBUG 01-04 15:36:07.008026.008026 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.008644.008644 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6cd487a7-b1c0-4b51-b92a-a1c81c9bdb53
DEBUG 01-04 15:36:07.008544.008544 cuda_h.py:19] end allocate_cuda_memory cost 0.007396221160888672 seconds
DEBUG 01-04 15:36:07.008179.008179 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.008982.008982 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.008124.008124 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.008377.008377 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7f87905d-cf22-4929-990b-dcc37d13a7e6
DEBUG 01-04 15:36:07.008017.008017 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.009160.009160 client.py:127] Model loaded
DEBUG 01-04 15:36:07.009357.009357 cuda_h.py:19] end wait_experts cost 0.001714468002319336 seconds
DEBUG 01-04 15:36:07.009750.009750 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.010859.010859 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.010345.010345 mlpmodule.py:531] gpu group tensors cost 0.0005428791046142578 s
INFO 01-04 15:36:07.014913.014913 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7f87905d-cf22-4929-990b-dcc37d13a7e6
DEBUG 01-04 15:36:07.014857.014857 cuda_h.py:19] end load_into_gpu_async cost 0.0057337284088134766 seconds
DEBUG 01-04 15:36:07.014878.014878 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.014733.014733 cuda_h.py:19] end restore_tensors2 cost 0.0005459785461425781 seconds
DEBUG 01-04 15:36:07.015337.015337 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014178037643432617 seconds
INFO 01-04 15:36:07.015757.015757 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7f87905d-cf22-4929-990b-dcc37d13a7e6
DEBUG 01-04 15:36:07.017825.017825 mlpmodule.py:564] gpu pad cost 0.00696563720703125 s
DEBUG 01-04 15:36:07.018470.018470 mlpmodule.py:582] gpu group einsum cost 0.0005712509155273438 s
INFO 01-04 15:36:07.018671.018671 client.py:127] Model loaded
DEBUG 01-04 15:36:07.018158.018158 cuda_h.py:19] end sllm_worker_task cost 0.01816701889038086 seconds
DEBUG 01-04 15:36:07.021163.021163 mlpmodule.py:662]  experts func einsum cost 0.08133769035339355 s
DEBUG 01-04 15:36:07.022193.022193 mlpmodule.py:611] gpu experts func einsum cost 0.012392520904541016 s
DEBUG 01-04 15:36:07.022052.022052 cuda_h.py:19] end gpu_experts cost 0.012689352035522461 seconds
DEBUG 01-04 15:36:07.022298.022298 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.022572.022572 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-04 15:36:07.022497.022497 cuda_h.py:19] end layer_moe_generate_2 cost 0.09296703338623047 seconds
DEBUG 01-04 15:36:07.023802.023802 lmp.py:207] -------------------------------- end layer 2 --------------------------------
DEBUG 01-04 15:36:07.023194.023194 lmp.py:169] -------------------------------- start layer 3 --------------------------------
DEBUG 01-04 15:36:07.023850.023850 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.023822.023822 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.026659.026659 cuda_h.py:19] end self_attn cost 0.0027942657470703125 seconds
DEBUG 01-04 15:36:07.026174.026174 cuda_h.py:19] end iln_self_attn_paln cost 0.003500699996948242 seconds
DEBUG 01-04 15:36:07.026508.026508 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-04 15:36:07.026761.026761 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.027732.027732 cuda_h.py:19] end gate cost 0.0006608963012695312 seconds
DEBUG 01-04 15:36:07.027369.027369 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.027306.027306 lmp.py:281] 
DEBUG 01-04 15:36:07.027306.027306 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.027916.027916 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.027897.027897 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.027255.027255 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.028421.028421 lmp.py:285] 
DEBUG 01-04 15:36:07.028421.028421 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.028872.028872 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.028336.028336 lmp.py:292]   Expert 61 |     10 | CPU
DEBUG 01-04 15:36:07.028933.028933 lmp.py:292]   Expert 63 |     10 | CPU
DEBUG 01-04 15:36:07.028099.028099 lmp.py:292]   Expert 44 |     11 | CPU
DEBUG 01-04 15:36:07.028312.028312 lmp.py:292]   Expert 28 |     12 | CPU
DEBUG 01-04 15:36:07.028286.028286 lmp.py:292]   Expert 32 |     12 | CPU
DEBUG 01-04 15:36:07.028021.028021 lmp.py:292]   Expert  8 |     13 | CPU
DEBUG 01-04 15:36:07.028995.028995 lmp.py:292]   Expert 15 |     13 | CPU
DEBUG 01-04 15:36:07.028492.028492 lmp.py:292]   Expert 10 |     18 | CPU
DEBUG 01-04 15:36:07.028228.028228 lmp.py:292]   Expert 59 |     18 | CPU
DEBUG 01-04 15:36:07.028725.028725 lmp.py:292]   Expert 16 |     19 | CPU
DEBUG 01-04 15:36:07.028699.028699 lmp.py:292]   Expert 37 |     19 | CPU
DEBUG 01-04 15:36:07.028958.028958 lmp.py:292]   Expert 36 |     20 | CPU
DEBUG 01-04 15:36:07.028694.028694 lmp.py:292]   Expert 57 |     23 | CPU
DEBUG 01-04 15:36:07.028953.028953 lmp.py:292]   Expert 12 |     24 | CPU
DEBUG 01-04 15:36:07.028927.028927 lmp.py:292]   Expert 29 |     28 | CPU
DEBUG 01-04 15:36:07.028424.028424 lmp.py:292]   Expert 52 |     32 | CPU
DEBUG 01-04 15:36:07.028352.028352 lmp.py:292]   Expert 38 |     33 | CPU
DEBUG 01-04 15:36:07.028802.028802 lmp.py:292]   Expert  6 |     35 | CPU
DEBUG 01-04 15:36:07.028492.028492 lmp.py:292]   Expert 42 |     37 | CPU
DEBUG 01-04 15:36:07.028704.028704 lmp.py:292]   Expert 55 |     40 | CPU
DEBUG 01-04 15:36:07.028678.028678 lmp.py:292]   Expert 13 |     41 | CPU
DEBUG 01-04 15:36:07.028043.028043 lmp.py:292]   Expert 23 |     43 | CPU
DEBUG 01-04 15:36:07.028230.028230 lmp.py:292]   Expert 62 |     44 | CPU
DEBUG 01-04 15:36:07.028681.028681 lmp.py:292]   Expert 49 |     45 | CPU
DEBUG 01-04 15:36:07.028655.028655 lmp.py:292]   Expert  7 |     46 | CPU
DEBUG 01-04 15:36:07.028344.028344 lmp.py:292]   Expert 26 |     47 | CPU
DEBUG 01-04 15:36:07.028556.028556 lmp.py:292]   Expert 47 |     58 | CPU
DEBUG 01-04 15:36:07.028769.028769 lmp.py:292]   Expert 24 |     59 | CPU
DEBUG 01-04 15:36:07.028981.028981 lmp.py:292]   Expert 17 |     61 | CPU
DEBUG 01-04 15:36:07.028300.028300 lmp.py:292]   Expert 31 |     63 | CPU
DEBUG 01-04 15:36:07.028705.028705 lmp.py:292]   Expert 40 |     63 | CPU
DEBUG 01-04 15:36:07.028871.028871 lmp.py:292]   Expert 48 |     63 | CPU
DEBUG 01-04 15:36:07.028275.028275 lmp.py:292]   Expert 35 |     64 | GPU
DEBUG 01-04 15:36:07.028965.028965 lmp.py:292]   Expert 30 |     67 | GPU
DEBUG 01-04 15:36:07.028416.028416 lmp.py:292]   Expert 58 |     67 | GPU
DEBUG 01-04 15:36:07.028628.028628 lmp.py:292]   Expert 51 |     73 | GPU
DEBUG 01-04 15:36:07.028840.028840 lmp.py:292]   Expert 18 |     74 | GPU
DEBUG 01-04 15:36:07.028053.028053 lmp.py:292]   Expert 45 |     75 | GPU
DEBUG 01-04 15:36:07.028265.028265 lmp.py:292]   Expert 39 |     77 | GPU
DEBUG 01-04 15:36:07.028478.028478 lmp.py:292]   Expert 11 |     81 | GPU
DEBUG 01-04 15:36:07.028929.028929 lmp.py:292]   Expert 33 |     84 | GPU
DEBUG 01-04 15:36:07.028141.028141 lmp.py:292]   Expert 22 |     85 | GPU
DEBUG 01-04 15:36:07.028546.028546 lmp.py:292]   Expert 56 |     88 | GPU
DEBUG 01-04 15:36:07.028473.028473 lmp.py:292]   Expert 20 |     93 | GPU
DEBUG 01-04 15:36:07.028640.028640 lmp.py:292]   Expert 46 |     93 | GPU
DEBUG 01-04 15:36:07.028806.028806 lmp.py:292]   Expert 27 |     94 | GPU
DEBUG 01-04 15:36:07.028495.028495 lmp.py:292]   Expert 34 |    104 | GPU
DEBUG 01-04 15:36:07.028184.028184 lmp.py:292]   Expert 53 |    106 | GPU
DEBUG 01-04 15:36:07.028397.028397 lmp.py:292]   Expert 54 |    107 | GPU
DEBUG 01-04 15:36:07.028086.028086 lmp.py:292]   Expert 19 |    108 | GPU
DEBUG 01-04 15:36:07.028537.028537 lmp.py:292]   Expert 14 |    112 | GPU
DEBUG 01-04 15:36:07.028988.028988 lmp.py:292]   Expert 60 |    131 | GPU
DEBUG 01-04 15:36:07.028439.028439 lmp.py:292]   Expert 41 |    142 | GPU
DEBUG 01-04 15:36:07.028651.028651 lmp.py:292]   Expert 50 |    142 | GPU
DEBUG 01-04 15:36:07.028102.028102 lmp.py:292]   Expert 21 |    160 | GPU
DEBUG 01-04 15:36:07.028414.028414 lmp.py:292]   Expert  9 |    182 | GPU
DEBUG 01-04 15:36:07.029057.029057 lmp.py:292]   Expert 43 |    183 | GPU
DEBUG 01-04 15:36:07.029938.029938 lmp.py:292]   Expert 25 |    208 | GPU
DEBUG 01-04 15:36:07.029343.029343 lmp.py:292]   Expert  4 |   1368 | GPU
DEBUG 01-04 15:36:07.029794.029794 lmp.py:292]   Expert  1 |   1376 | GPU
DEBUG 01-04 15:36:07.029006.029006 lmp.py:292]   Expert  5 |   1391 | GPU
DEBUG 01-04 15:36:07.029457.029457 lmp.py:292]   Expert  2 |   1403 | GPU
DEBUG 01-04 15:36:07.029431.029431 lmp.py:292]   Expert  0 |   1430 | GPU
DEBUG 01-04 15:36:07.029882.029882 lmp.py:292]   Expert  3 |   1460 | GPU
DEBUG 01-04 15:36:07.029287.029287 lmp.py:293] 
DEBUG 01-04 15:36:07.029287.029287 lmp.py:293]   CPU total tokens: 1060 (8.6%)
DEBUG 01-04 15:36:07.029691.029691 lmp.py:294]   GPU total tokens: 11228 (91.4%)
DEBUG 01-04 15:36:07.029387.029387 cuda_h.py:19] end experts_map_get cost 0.0014946460723876953 seconds
DEBUG 01-04 15:36:07.029269.029269 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.029760.029760 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.029983.029983 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.029620.029620 cuda_h.py:19] end allocate_cuda_memory cost 0.00019049644470214844 seconds
DEBUG 01-04 15:36:07.029794.029794 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.029358.029358 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.029882.029882 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.029823.029823 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5003d291-c265-4a5b-943c-435766373224
DEBUG 01-04 15:36:07.029809.029809 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.031313.031313 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5003d291-c265-4a5b-943c-435766373224
DEBUG 01-04 15:36:07.032066.032066 cuda_h.py:19] end load_into_gpu_async cost 0.0023310184478759766 seconds
DEBUG 01-04 15:36:07.032028.032028 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.032137.032137 cuda_h.py:19] end restore_tensors2 cost 0.0004000663757324219 seconds
DEBUG 01-04 15:36:07.032529.032529 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003350973129272461 seconds
DEBUG 01-04 15:36:07.035270.035270 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00593876838684082 seconds
DEBUG 01-04 15:36:07.035013.035013 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.035023.035023 lmp.py:339] 
DEBUG 01-04 15:36:07.035023.035023 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.035151.035151 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-04 15:36:07.035992.035992 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.046928.046928 mlpmodule.py:704] group tensors cost 0.010530233383178711 s
DEBUG 01-04 15:36:07.048345.048345 mlpmodule.py:742] pad cost 0.0019054412841796875 s
DEBUG 01-04 15:36:07.049389.049389 mlpmodule.py:748] create cpu tensor cost 7.224082946777344e-05 s
DEBUG 01-04 15:36:07.049306.049306 mlpmodule.py:753] move to cpu cost 3.981590270996094e-05 s
DEBUG 01-04 15:36:07.054565.054565 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.054998.054998 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.055637.055637 mlpmodule.py:774] group_w3 first element: 0.0206298828125
WARNING 01-04 15:36:07.055946.055946 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.059292.059292 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.059110.059110 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.064796.064796 mlpmodule.py:797] group einsum cost 0.015380382537841797 s
DEBUG 01-04 15:36:07.064518.064518 mlpmodule.py:805] cpy2cputensor cost 0.00032329559326171875 s
DEBUG 01-04 15:36:07.070944.070944 cuda_h.py:19] end wait_cetm_experts cost 0.03468036651611328 seconds
DEBUG 01-04 15:36:07.070814.070814 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.071147.071147 cuda_h.py:19] end gpu_sexperts cost 0.0006012916564941406 seconds
DEBUG 01-04 15:36:07.071237.071237 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-04 15:36:07.071239.071239 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-04 15:36:07.071501.071501 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.814697265625e-05 seconds
DEBUG 01-04 15:36:07.071171.071171 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 8.320808410644531e-05 seconds
DEBUG 01-04 15:36:07.071635.071635 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.071967.071967 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5003d291-c265-4a5b-943c-435766373224
DEBUG 01-04 15:36:07.071027.071027 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.071740.071740 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.071265.071265 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.075866.075866 cuda_h.py:19] end allocate_cuda_memory cost 0.004048347473144531 seconds
DEBUG 01-04 15:36:07.076758.076758 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.076011.076011 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.076847.076847 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.076895.076895 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 02ab509c-18e2-4cee-9ba8-51c2fb39bd87
DEBUG 01-04 15:36:07.076137.076137 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.082044.082044 client.py:127] Model loaded
DEBUG 01-04 15:36:07.082947.082947 cuda_h.py:19] end wait_experts cost 0.010871648788452148 seconds
DEBUG 01-04 15:36:07.082220.082220 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.082638.082638 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.082498.082498 mlpmodule.py:531] gpu group tensors cost 0.0004935264587402344 s
INFO 01-04 15:36:07.083817.083817 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 02ab509c-18e2-4cee-9ba8-51c2fb39bd87
DEBUG 01-04 15:36:07.083336.083336 cuda_h.py:19] end load_into_gpu_async cost 0.007122516632080078 seconds
DEBUG 01-04 15:36:07.083800.083800 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.087903.087903 cuda_h.py:19] end restore_tensors2 cost 0.004218339920043945 seconds
DEBUG 01-04 15:36:07.087753.087753 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015766620635986328 seconds
DEBUG 01-04 15:36:07.087262.087262 mlpmodule.py:662]  experts func einsum cost 0.05237770080566406 s
INFO 01-04 15:36:07.089415.089415 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 02ab509c-18e2-4cee-9ba8-51c2fb39bd87
DEBUG 01-04 15:36:07.091679.091679 mlpmodule.py:564] gpu pad cost 0.008116722106933594 s
INFO 01-04 15:36:07.091832.091832 client.py:127] Model loaded
DEBUG 01-04 15:36:07.091214.091214 cuda_h.py:19] end sllm_worker_task cost 0.019688129425048828 seconds
DEBUG 01-04 15:36:07.092910.092910 mlpmodule.py:582] gpu group einsum cost 0.0012664794921875 s
DEBUG 01-04 15:36:07.095297.095297 mlpmodule.py:611] gpu experts func einsum cost 0.013474225997924805 s
DEBUG 01-04 15:36:07.095240.095240 cuda_h.py:19] end gpu_experts cost 0.013646364212036133 seconds
DEBUG 01-04 15:36:07.096533.096533 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.096608.096608 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-04 15:36:07.097914.097914 cuda_h.py:19] end layer_moe_generate_3 cost 0.0710456371307373 seconds
DEBUG 01-04 15:36:07.098238.098238 lmp.py:207] -------------------------------- end layer 3 --------------------------------
DEBUG 01-04 15:36:07.098716.098716 lmp.py:169] -------------------------------- start layer 4 --------------------------------
DEBUG 01-04 15:36:07.098220.098220 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.098825.098825 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.100488.100488 cuda_h.py:19] end self_attn cost 0.002331256866455078 seconds
DEBUG 01-04 15:36:07.101576.101576 cuda_h.py:19] end iln_self_attn_paln cost 0.0029020309448242188 seconds
DEBUG 01-04 15:36:07.101797.101797 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-04 15:36:07.101037.101037 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.101904.101904 cuda_h.py:19] end gate cost 0.0005702972412109375 seconds
DEBUG 01-04 15:36:07.101065.101065 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.102571.102571 lmp.py:281] 
DEBUG 01-04 15:36:07.102571.102571 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.102466.102466 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.102923.102923 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.102189.102189 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.102786.102786 lmp.py:285] 
DEBUG 01-04 15:36:07.102786.102786 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.102905.102905 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.102324.102324 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:07.102728.102728 lmp.py:292]   Expert 56 |      7 | CPU
DEBUG 01-04 15:36:07.102702.102702 lmp.py:292]   Expert 41 |     12 | CPU
DEBUG 01-04 15:36:07.102676.102676 lmp.py:292]   Expert  6 |     13 | CPU
DEBUG 01-04 15:36:07.102173.102173 lmp.py:292]   Expert 36 |     13 | CPU
DEBUG 01-04 15:36:07.102386.102386 lmp.py:292]   Expert 33 |     15 | CPU
DEBUG 01-04 15:36:07.102360.102360 lmp.py:292]   Expert  7 |     16 | CPU
DEBUG 01-04 15:36:07.102857.102857 lmp.py:292]   Expert 25 |     16 | CPU
DEBUG 01-04 15:36:07.102831.102831 lmp.py:292]   Expert 34 |     17 | CPU
DEBUG 01-04 15:36:07.102567.102567 lmp.py:292]   Expert 13 |     18 | CPU
DEBUG 01-04 15:36:07.102064.102064 lmp.py:292]   Expert 48 |     18 | CPU
DEBUG 01-04 15:36:07.102800.102800 lmp.py:292]   Expert 58 |     18 | CPU
DEBUG 01-04 15:36:07.102535.102535 lmp.py:292]   Expert 24 |     21 | CPU
DEBUG 01-04 15:36:07.102794.102794 lmp.py:292]   Expert 11 |     22 | CPU
DEBUG 01-04 15:36:07.102291.102291 lmp.py:292]   Expert 55 |     22 | CPU
DEBUG 01-04 15:36:07.102027.102027 lmp.py:292]   Expert 50 |     23 | CPU
DEBUG 01-04 15:36:07.102001.102001 lmp.py:292]   Expert 28 |     24 | CPU
DEBUG 01-04 15:36:07.102737.102737 lmp.py:292]   Expert 51 |     24 | CPU
DEBUG 01-04 15:36:07.102711.102711 lmp.py:292]   Expert  9 |     30 | CPU
DEBUG 01-04 15:36:07.102208.102208 lmp.py:292]   Expert 17 |     32 | CPU
DEBUG 01-04 15:36:07.102943.102943 lmp.py:292]   Expert 22 |     33 | CPU
DEBUG 01-04 15:36:07.102441.102441 lmp.py:292]   Expert 44 |     35 | CPU
DEBUG 01-04 15:36:07.102938.102938 lmp.py:292]   Expert 18 |     37 | CPU
DEBUG 01-04 15:36:07.102727.102727 lmp.py:292]   Expert 26 |     38 | CPU
DEBUG 01-04 15:36:07.102654.102654 lmp.py:292]   Expert 21 |     41 | CPU
DEBUG 01-04 15:36:07.102628.102628 lmp.py:292]   Expert 27 |     43 | CPU
DEBUG 01-04 15:36:07.102556.102556 lmp.py:292]   Expert 61 |     43 | CPU
DEBUG 01-04 15:36:07.102292.102292 lmp.py:292]   Expert 45 |     44 | CPU
DEBUG 01-04 15:36:07.102789.102789 lmp.py:292]   Expert 37 |     46 | CPU
DEBUG 01-04 15:36:07.102286.102286 lmp.py:292]   Expert 16 |     49 | CPU
DEBUG 01-04 15:36:07.102022.102022 lmp.py:292]   Expert 47 |     51 | CPU
DEBUG 01-04 15:36:07.102519.102519 lmp.py:292]   Expert 14 |     52 | CPU
DEBUG 01-04 15:36:07.102255.102255 lmp.py:292]   Expert 42 |     59 | GPU
DEBUG 01-04 15:36:07.102752.102752 lmp.py:292]   Expert 31 |     64 | GPU
DEBUG 01-04 15:36:07.102249.102249 lmp.py:292]   Expert 40 |     64 | GPU
DEBUG 01-04 15:36:07.102508.102508 lmp.py:292]   Expert 54 |     64 | GPU
DEBUG 01-04 15:36:07.102767.102767 lmp.py:292]   Expert 10 |     68 | GPU
DEBUG 01-04 15:36:07.102264.102264 lmp.py:292]   Expert 53 |     72 | GPU
DEBUG 01-04 15:36:07.102284.102284 lmp.py:292]   Expert 57 |     73 | GPU
DEBUG 01-04 15:36:07.102781.102781 lmp.py:292]   Expert 15 |     75 | GPU
DEBUG 01-04 15:36:07.102040.102040 lmp.py:292]   Expert 46 |     77 | GPU
DEBUG 01-04 15:36:07.102537.102537 lmp.py:292]   Expert 62 |     79 | GPU
DEBUG 01-04 15:36:07.102035.102035 lmp.py:292]   Expert  8 |     81 | GPU
DEBUG 01-04 15:36:07.102532.102532 lmp.py:292]   Expert 63 |     88 | GPU
DEBUG 01-04 15:36:07.102791.102791 lmp.py:292]   Expert 32 |     91 | GPU
DEBUG 01-04 15:36:07.102526.102526 lmp.py:292]   Expert 20 |     92 | GPU
DEBUG 01-04 15:36:07.102785.102785 lmp.py:292]   Expert 23 |     94 | GPU
DEBUG 01-04 15:36:07.102044.102044 lmp.py:292]   Expert 29 |     97 | GPU
DEBUG 01-04 15:36:07.103594.103594 lmp.py:292]   Expert 12 |    110 | GPU
DEBUG 01-04 15:36:07.103330.103330 lmp.py:292]   Expert 19 |    112 | GPU
DEBUG 01-04 15:36:07.103065.103065 lmp.py:292]   Expert 38 |    121 | GPU
DEBUG 01-04 15:36:07.103801.103801 lmp.py:292]   Expert 35 |    126 | GPU
DEBUG 01-04 15:36:07.103298.103298 lmp.py:292]   Expert 30 |    133 | GPU
DEBUG 01-04 15:36:07.103795.103795 lmp.py:292]   Expert 49 |    150 | GPU
DEBUG 01-04 15:36:07.103293.103293 lmp.py:292]   Expert 52 |    165 | GPU
DEBUG 01-04 15:36:07.103028.103028 lmp.py:292]   Expert 43 |    184 | GPU
DEBUG 01-04 15:36:07.103525.103525 lmp.py:292]   Expert 39 |    222 | GPU
DEBUG 01-04 15:36:07.103261.103261 lmp.py:292]   Expert 59 |    252 | GPU
DEBUG 01-04 15:36:07.103758.103758 lmp.py:292]   Expert  3 |   1367 | GPU
DEBUG 01-04 15:36:07.103494.103494 lmp.py:292]   Expert  4 |   1418 | GPU
DEBUG 01-04 15:36:07.103991.103991 lmp.py:292]   Expert  1 |   1422 | GPU
DEBUG 01-04 15:36:07.103250.103250 lmp.py:292]   Expert  2 |   1424 | GPU
DEBUG 01-04 15:36:07.103224.103224 lmp.py:292]   Expert  0 |   1435 | GPU
DEBUG 01-04 15:36:07.103721.103721 lmp.py:292]   Expert  5 |   1531 | GPU
DEBUG 01-04 15:36:07.103172.103172 lmp.py:293] 
DEBUG 01-04 15:36:07.103172.103172 lmp.py:293]   CPU total tokens: 878 (7.1%)
DEBUG 01-04 15:36:07.103623.103623 lmp.py:294]   GPU total tokens: 11410 (92.9%)
DEBUG 01-04 15:36:07.103365.103365 cuda_h.py:19] end experts_map_get cost 0.001422882080078125 seconds
DEBUG 01-04 15:36:07.103531.103531 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.103208.103208 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.103047.103047 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.103404.103404 cuda_h.py:19] end allocate_cuda_memory cost 0.00015854835510253906 seconds
DEBUG 01-04 15:36:07.103817.103817 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.103712.103712 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.103283.103283 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.103025.103025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 46f4a29c-7474-441e-b5d3-83852ec37a69
DEBUG 01-04 15:36:07.103527.103527 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.105587.105587 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 46f4a29c-7474-441e-b5d3-83852ec37a69
DEBUG 01-04 15:36:07.106207.106207 cuda_h.py:19] end load_into_gpu_async cost 0.002313375473022461 seconds
DEBUG 01-04 15:36:07.106793.106793 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.106370.106370 cuda_h.py:19] end restore_tensors2 cost 0.0003592967987060547 seconds
DEBUG 01-04 15:36:07.106570.106570 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032646656036376953 seconds
DEBUG 01-04 15:36:07.109787.109787 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005814552307128906 seconds
DEBUG 01-04 15:36:07.109623.109623 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.109162.109162 lmp.py:339] 
DEBUG 01-04 15:36:07.109162.109162 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.109628.109628 cuda_h.py:19] end cpu_experts_submit cost 0.00011396408081054688 seconds
DEBUG 01-04 15:36:07.109423.109423 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.119093.119093 mlpmodule.py:704] group tensors cost 0.010037899017333984 s
DEBUG 01-04 15:36:07.124855.124855 mlpmodule.py:742] pad cost 0.0034465789794921875 s
DEBUG 01-04 15:36:07.124106.124106 mlpmodule.py:748] create cpu tensor cost 7.867813110351562e-05 s
DEBUG 01-04 15:36:07.124369.124369 mlpmodule.py:753] move to cpu cost 5.53131103515625e-05 s
DEBUG 01-04 15:36:07.129212.129212 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.129353.129353 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.129601.129601 mlpmodule.py:774] group_w3 first element: -0.0015106201171875
WARNING 01-04 15:36:07.130975.130975 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.134999.134999 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.134937.134937 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.139456.139456 mlpmodule.py:797] group einsum cost 0.014592647552490234 s
DEBUG 01-04 15:36:07.139632.139632 mlpmodule.py:805] cpy2cputensor cost 0.00023865699768066406 s
DEBUG 01-04 15:36:07.144768.144768 cuda_h.py:19] end wait_cetm_experts cost 0.03514361381530762 seconds
DEBUG 01-04 15:36:07.144426.144426 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.145186.145186 cuda_h.py:19] end gpu_sexperts cost 0.0006575584411621094 seconds
DEBUG 01-04 15:36:07.145912.145912 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-04 15:36:07.145491.145491 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-04 15:36:07.145647.145647 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 4.744529724121094e-05 seconds
DEBUG 01-04 15:36:07.145946.145946 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 0.0001010894775390625 seconds
DEBUG 01-04 15:36:07.145848.145848 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.146094.146094 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 46f4a29c-7474-441e-b5d3-83852ec37a69
DEBUG 01-04 15:36:07.146604.146604 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.146239.146239 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.146155.146155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.150766.150766 cuda_h.py:19] end allocate_cuda_memory cost 0.004330635070800781 seconds
DEBUG 01-04 15:36:07.150280.150280 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.151679.151679 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.151277.151277 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.151132.151132 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e07d837d-8cc9-4c8b-a581-74199cf5b9e0
DEBUG 01-04 15:36:07.151566.151566 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.156206.156206 client.py:127] Model loaded
DEBUG 01-04 15:36:07.156632.156632 cuda_h.py:19] end wait_experts cost 0.010123252868652344 seconds
DEBUG 01-04 15:36:07.156812.156812 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.156899.156899 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.156151.156151 mlpmodule.py:531] gpu group tensors cost 0.0005311965942382812 s
INFO 01-04 15:36:07.157173.157173 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e07d837d-8cc9-4c8b-a581-74199cf5b9e0
DEBUG 01-04 15:36:07.157122.157122 cuda_h.py:19] end load_into_gpu_async cost 0.006121158599853516 seconds
DEBUG 01-04 15:36:07.157163.157163 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.163946.163946 cuda_h.py:19] end restore_tensors2 cost 0.0063250064849853516 seconds
DEBUG 01-04 15:36:07.163121.163121 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.017206192016601562 seconds
INFO 01-04 15:36:07.164999.164999 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e07d837d-8cc9-4c8b-a581-74199cf5b9e0
DEBUG 01-04 15:36:07.164356.164356 mlpmodule.py:662]  experts func einsum cost 0.0551149845123291 s
INFO 01-04 15:36:07.165598.165598 client.py:127] Model loaded
DEBUG 01-04 15:36:07.165536.165536 cuda_h.py:19] end sllm_worker_task cost 0.019568443298339844 seconds
DEBUG 01-04 15:36:07.167573.167573 mlpmodule.py:564] gpu pad cost 0.010361433029174805 s
DEBUG 01-04 15:36:07.168915.168915 mlpmodule.py:582] gpu group einsum cost 0.001039743423461914 s
DEBUG 01-04 15:36:07.172789.172789 mlpmodule.py:611] gpu experts func einsum cost 0.016013622283935547 s
DEBUG 01-04 15:36:07.172091.172091 cuda_h.py:19] end gpu_experts cost 0.01622319221496582 seconds
DEBUG 01-04 15:36:07.172821.172821 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.172764.172764 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.09808349609375e-05 seconds
DEBUG 01-04 15:36:07.173139.173139 cuda_h.py:19] end layer_moe_generate_4 cost 0.07268786430358887 seconds
DEBUG 01-04 15:36:07.174948.174948 lmp.py:207] -------------------------------- end layer 4 --------------------------------
DEBUG 01-04 15:36:07.174585.174585 lmp.py:169] -------------------------------- start layer 5 --------------------------------
DEBUG 01-04 15:36:07.174295.174295 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.174022.174022 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.177318.177318 cuda_h.py:19] end self_attn cost 0.0030243396759033203 seconds
DEBUG 01-04 15:36:07.178463.178463 cuda_h.py:19] end iln_self_attn_paln cost 0.003797769546508789 seconds
DEBUG 01-04 15:36:07.178042.178042 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-04 15:36:07.178302.178302 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.178761.178761 cuda_h.py:19] end gate cost 0.0006089210510253906 seconds
DEBUG 01-04 15:36:07.178875.178875 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.179480.179480 lmp.py:281] 
DEBUG 01-04 15:36:07.179480.179480 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.179521.179521 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.179694.179694 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.179006.179006 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.179510.179510 lmp.py:285] 
DEBUG 01-04 15:36:07.179510.179510 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.179199.179199 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.179087.179087 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:07.179253.179253 lmp.py:292]   Expert 47 |      4 | CPU
DEBUG 01-04 15:36:07.179227.179227 lmp.py:292]   Expert 18 |      7 | CPU
DEBUG 01-04 15:36:07.179440.179440 lmp.py:292]   Expert 27 |      7 | CPU
DEBUG 01-04 15:36:07.179652.179652 lmp.py:292]   Expert 34 |      8 | CPU
DEBUG 01-04 15:36:07.179865.179865 lmp.py:292]   Expert 15 |     16 | CPU
DEBUG 01-04 15:36:07.179077.179077 lmp.py:292]   Expert 52 |     16 | CPU
DEBUG 01-04 15:36:07.179290.179290 lmp.py:292]   Expert 63 |     17 | CPU
DEBUG 01-04 15:36:07.179217.179217 lmp.py:292]   Expert 56 |     18 | CPU
DEBUG 01-04 15:36:07.179099.179099 lmp.py:292]   Expert 10 |     23 | CPU
DEBUG 01-04 15:36:07.179311.179311 lmp.py:292]   Expert 23 |     24 | CPU
DEBUG 01-04 15:36:07.179285.179285 lmp.py:292]   Expert 30 |     25 | CPU
DEBUG 01-04 15:36:07.179498.179498 lmp.py:292]   Expert 25 |     26 | CPU
DEBUG 01-04 15:36:07.179995.179995 lmp.py:292]   Expert 58 |     26 | CPU
DEBUG 01-04 15:36:07.179254.179254 lmp.py:292]   Expert 51 |     30 | CPU
DEBUG 01-04 15:36:07.179228.179228 lmp.py:292]   Expert 28 |     32 | CPU
DEBUG 01-04 15:36:07.179964.179964 lmp.py:292]   Expert 43 |     33 | CPU
DEBUG 01-04 15:36:07.179461.179461 lmp.py:292]   Expert 48 |     33 | CPU
DEBUG 01-04 15:36:07.179196.179196 lmp.py:292]   Expert  9 |     34 | CPU
DEBUG 01-04 15:36:07.179409.179409 lmp.py:292]   Expert 54 |     35 | CPU
DEBUG 01-04 15:36:07.179144.179144 lmp.py:292]   Expert  8 |     36 | CPU
DEBUG 01-04 15:36:07.179118.179118 lmp.py:292]   Expert 38 |     39 | CPU
DEBUG 01-04 15:36:07.179808.179808 lmp.py:292]   Expert 62 |     41 | CPU
DEBUG 01-04 15:36:07.179212.179212 lmp.py:292]   Expert 61 |     42 | CPU
DEBUG 01-04 15:36:07.179186.179186 lmp.py:292]   Expert 22 |     45 | CPU
DEBUG 01-04 15:36:07.179684.179684 lmp.py:292]   Expert 17 |     46 | CPU
DEBUG 01-04 15:36:07.179658.179658 lmp.py:292]   Expert 60 |     46 | CPU
DEBUG 01-04 15:36:07.179155.179155 lmp.py:292]   Expert 45 |     50 | CPU
DEBUG 01-04 15:36:07.179890.179890 lmp.py:292]   Expert 24 |     56 | CPU
DEBUG 01-04 15:36:07.179388.179388 lmp.py:292]   Expert 14 |     57 | CPU
DEBUG 01-04 15:36:07.179885.179885 lmp.py:292]   Expert 50 |     58 | CPU
DEBUG 01-04 15:36:07.179144.179144 lmp.py:292]   Expert 41 |     62 | CPU
DEBUG 01-04 15:36:07.179118.179118 lmp.py:292]   Expert 57 |     68 | GPU
DEBUG 01-04 15:36:07.179377.179377 lmp.py:292]   Expert 36 |     69 | GPU
DEBUG 01-04 15:36:07.179351.179351 lmp.py:292]   Expert 16 |     70 | GPU
DEBUG 01-04 15:36:07.179086.179086 lmp.py:292]   Expert 26 |     71 | GPU
DEBUG 01-04 15:36:07.179491.179491 lmp.py:292]   Expert 29 |     72 | GPU
DEBUG 01-04 15:36:07.179942.179942 lmp.py:292]   Expert 40 |     72 | GPU
DEBUG 01-04 15:36:07.179869.179869 lmp.py:292]   Expert 44 |     74 | GPU
DEBUG 01-04 15:36:07.179367.179367 lmp.py:292]   Expert 55 |     79 | GPU
DEBUG 01-04 15:36:07.179102.179102 lmp.py:292]   Expert  6 |     84 | GPU
DEBUG 01-04 15:36:07.179599.179599 lmp.py:292]   Expert  7 |     87 | GPU
DEBUG 01-04 15:36:07.179097.179097 lmp.py:292]   Expert 31 |     88 | GPU
DEBUG 01-04 15:36:07.179355.179355 lmp.py:292]   Expert 11 |     92 | GPU
DEBUG 01-04 15:36:07.179853.179853 lmp.py:292]   Expert 46 |     97 | GPU
DEBUG 01-04 15:36:07.179111.179111 lmp.py:292]   Expert 19 |     99 | GPU
DEBUG 01-04 15:36:07.179609.179609 lmp.py:292]   Expert 35 |    100 | GPU
DEBUG 01-04 15:36:07.179867.179867 lmp.py:292]   Expert 32 |    109 | GPU
DEBUG 01-04 15:36:07.180365.180365 lmp.py:292]   Expert 12 |    110 | GPU
DEBUG 01-04 15:36:07.180100.180100 lmp.py:292]   Expert 42 |    112 | GPU
DEBUG 01-04 15:36:07.180597.180597 lmp.py:292]   Expert 20 |    126 | GPU
DEBUG 01-04 15:36:07.180525.180525 lmp.py:292]   Expert 59 |    127 | GPU
DEBUG 01-04 15:36:07.180214.180214 lmp.py:292]   Expert 13 |    131 | GPU
DEBUG 01-04 15:36:07.180381.180381 lmp.py:292]   Expert 33 |    153 | GPU
DEBUG 01-04 15:36:07.180116.180116 lmp.py:292]   Expert 21 |    192 | GPU
DEBUG 01-04 15:36:07.180613.180613 lmp.py:292]   Expert 37 |    218 | GPU
DEBUG 01-04 15:36:07.180872.180872 lmp.py:292]   Expert 49 |    228 | GPU
DEBUG 01-04 15:36:07.180369.180369 lmp.py:292]   Expert 53 |    274 | GPU
DEBUG 01-04 15:36:07.180628.180628 lmp.py:292]   Expert  2 |   1356 | GPU
DEBUG 01-04 15:36:07.180125.180125 lmp.py:292]   Expert  4 |   1368 | GPU
DEBUG 01-04 15:36:07.180623.180623 lmp.py:292]   Expert  0 |   1374 | GPU
DEBUG 01-04 15:36:07.180120.180120 lmp.py:292]   Expert  1 |   1376 | GPU
DEBUG 01-04 15:36:07.180617.180617 lmp.py:292]   Expert  3 |   1383 | GPU
DEBUG 01-04 15:36:07.180114.180114 lmp.py:292]   Expert  5 |   1434 | GPU
DEBUG 01-04 15:36:07.180327.180327 lmp.py:293] 
DEBUG 01-04 15:36:07.180327.180327 lmp.py:293]   CPU total tokens: 995 (8.1%)
DEBUG 01-04 15:36:07.180016.180016 lmp.py:294]   GPU total tokens: 11293 (91.9%)
DEBUG 01-04 15:36:07.180758.180758 cuda_h.py:19] end experts_map_get cost 0.0014314651489257812 seconds
DEBUG 01-04 15:36:07.180401.180401 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.180747.180747 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.180282.180282 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.180322.180322 cuda_h.py:19] end allocate_cuda_memory cost 0.00017142295837402344 seconds
DEBUG 01-04 15:36:07.180457.180457 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.180597.180597 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.180936.180936 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.180208.180208 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5df41042-918d-4f65-8515-d542e342e375
DEBUG 01-04 15:36:07.181307.181307 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.183379.183379 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5df41042-918d-4f65-8515-d542e342e375
DEBUG 01-04 15:36:07.183238.183238 cuda_h.py:19] end load_into_gpu_async cost 0.002315998077392578 seconds
DEBUG 01-04 15:36:07.183062.183062 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.183499.183499 cuda_h.py:19] end restore_tensors2 cost 0.00032711029052734375 seconds
DEBUG 01-04 15:36:07.183222.183222 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032787322998046875 seconds
DEBUG 01-04 15:36:07.186849.186849 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005814790725708008 seconds
DEBUG 01-04 15:36:07.186870.186870 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.186972.186972 lmp.py:339] 
DEBUG 01-04 15:36:07.186972.186972 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.186861.186861 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-04 15:36:07.186465.186465 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.197380.197380 mlpmodule.py:704] group tensors cost 0.011024951934814453 s
DEBUG 01-04 15:36:07.201019.201019 mlpmodule.py:742] pad cost 0.002678394317626953 s
DEBUG 01-04 15:36:07.201428.201428 mlpmodule.py:748] create cpu tensor cost 6.604194641113281e-05 s
DEBUG 01-04 15:36:07.201133.201133 mlpmodule.py:753] move to cpu cost 4.482269287109375e-05 s
DEBUG 01-04 15:36:07.207845.207845 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.207238.207238 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.207062.207062 mlpmodule.py:774] group_w3 first element: -0.064453125
WARNING 01-04 15:36:07.207874.207874 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.211466.211466 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.211238.211238 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.216608.216608 mlpmodule.py:797] group einsum cost 0.014725923538208008 s
DEBUG 01-04 15:36:07.216212.216212 mlpmodule.py:805] cpy2cputensor cost 0.0003445148468017578 s
DEBUG 01-04 15:36:07.222188.222188 cuda_h.py:19] end wait_cetm_experts cost 0.03556227684020996 seconds
DEBUG 01-04 15:36:07.222784.222784 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.222355.222355 cuda_h.py:19] end gpu_sexperts cost 0.0005862712860107422 seconds
DEBUG 01-04 15:36:07.222536.222536 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-04 15:36:07.222643.222643 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-04 15:36:07.223421.223421 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 4.2438507080078125e-05 seconds
DEBUG 01-04 15:36:07.223861.223861 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.223009.223009 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 0.0002002716064453125 seconds
DEBUG 01-04 15:36:07.223198.223198 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.223180.223180 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.223126.223126 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5df41042-918d-4f65-8515-d542e342e375
DEBUG 01-04 15:36:07.223779.223779 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.229399.229399 cuda_h.py:19] end allocate_cuda_memory cost 0.005357265472412109 seconds
DEBUG 01-04 15:36:07.229151.229151 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.229504.229504 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.229910.229910 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.229288.229288 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b45354b-2655-4593-a025-cb5dd557b06a
DEBUG 01-04 15:36:07.229153.229153 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.233290.233290 client.py:127] Model loaded
DEBUG 01-04 15:36:07.233994.233994 cuda_h.py:19] end wait_experts cost 0.009916543960571289 seconds
DEBUG 01-04 15:36:07.233651.233651 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.233022.233022 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.234831.234831 mlpmodule.py:531] gpu group tensors cost 0.0005116462707519531 s
INFO 01-04 15:36:07.234020.234020 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b45354b-2655-4593-a025-cb5dd557b06a
DEBUG 01-04 15:36:07.234115.234115 cuda_h.py:19] end load_into_gpu_async cost 0.00519251823425293 seconds
DEBUG 01-04 15:36:07.234699.234699 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.234180.234180 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-04 15:36:07.234558.234558 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011249065399169922 seconds
INFO 01-04 15:36:07.235321.235321 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b45354b-2655-4593-a025-cb5dd557b06a
DEBUG 01-04 15:36:07.236938.236938 mlpmodule.py:564] gpu pad cost 0.0025539398193359375 s
DEBUG 01-04 15:36:07.237228.237228 mlpmodule.py:582] gpu group einsum cost 0.0004851818084716797 s
DEBUG 01-04 15:36:07.240739.240739 mlpmodule.py:611] gpu experts func einsum cost 0.006482839584350586 s
DEBUG 01-04 15:36:07.240060.240060 cuda_h.py:19] end gpu_experts cost 0.006666421890258789 seconds
DEBUG 01-04 15:36:07.240863.240863 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.240876.240876 mlpmodule.py:662]  experts func einsum cost 0.054177045822143555 s
INFO 01-04 15:36:07.245868.245868 client.py:127] Model loaded
DEBUG 01-04 15:36:07.245589.245589 cuda_h.py:19] end sllm_worker_task cost 0.022154569625854492 seconds
DEBUG 01-04 15:36:07.245545.245545 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005495548248291016 seconds
DEBUG 01-04 15:36:07.245096.245096 cuda_h.py:19] end layer_moe_generate_5 cost 0.06783175468444824 seconds
DEBUG 01-04 15:36:07.246281.246281 lmp.py:207] -------------------------------- end layer 5 --------------------------------
DEBUG 01-04 15:36:07.246050.246050 lmp.py:169] -------------------------------- start layer 6 --------------------------------
DEBUG 01-04 15:36:07.246462.246462 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.246689.246689 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.248733.248733 cuda_h.py:19] end self_attn cost 0.002435922622680664 seconds
DEBUG 01-04 15:36:07.249689.249689 cuda_h.py:19] end iln_self_attn_paln cost 0.0030164718627929688 seconds
DEBUG 01-04 15:36:07.249255.249255 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-04 15:36:07.249209.249209 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.249541.249541 cuda_h.py:19] end gate cost 0.0005598068237304688 seconds
DEBUG 01-04 15:36:07.249416.249416 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.250227.250227 lmp.py:281] 
DEBUG 01-04 15:36:07.250227.250227 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.250506.250506 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.250110.250110 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.250375.250375 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.250257.250257 lmp.py:285] 
DEBUG 01-04 15:36:07.250257.250257 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.250351.250351 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.250954.250954 lmp.py:292]   Expert 53 |      2 | CPU
DEBUG 01-04 15:36:07.250789.250789 lmp.py:292]   Expert 15 |      4 | CPU
DEBUG 01-04 15:36:07.250909.250909 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:07.250313.250313 lmp.py:292]   Expert 14 |      7 | CPU
DEBUG 01-04 15:36:07.250718.250718 lmp.py:292]   Expert 52 |      7 | CPU
DEBUG 01-04 15:36:07.250646.250646 lmp.py:292]   Expert 50 |     10 | CPU
DEBUG 01-04 15:36:07.250573.250573 lmp.py:292]   Expert 49 |     12 | CPU
DEBUG 01-04 15:36:07.250263.250263 lmp.py:292]   Expert 28 |     13 | CPU
DEBUG 01-04 15:36:07.250144.250144 lmp.py:292]   Expert 47 |     13 | CPU
DEBUG 01-04 15:36:07.250787.250787 lmp.py:292]   Expert 62 |     16 | CPU
DEBUG 01-04 15:36:07.250715.250715 lmp.py:292]   Expert 40 |     17 | CPU
DEBUG 01-04 15:36:07.250643.250643 lmp.py:292]   Expert  7 |     18 | CPU
DEBUG 01-04 15:36:07.250332.250332 lmp.py:292]   Expert 10 |     20 | CPU
DEBUG 01-04 15:36:07.250260.250260 lmp.py:292]   Expert 11 |     21 | CPU
DEBUG 01-04 15:36:07.250187.250187 lmp.py:292]   Expert 34 |     21 | CPU
DEBUG 01-04 15:36:07.250115.250115 lmp.py:292]   Expert 63 |     23 | CPU
DEBUG 01-04 15:36:07.250566.250566 lmp.py:292]   Expert 61 |     24 | CPU
DEBUG 01-04 15:36:07.250017.250017 lmp.py:292]   Expert 22 |     25 | CPU
DEBUG 01-04 15:36:07.250137.250137 lmp.py:292]   Expert 31 |     25 | CPU
DEBUG 01-04 15:36:07.250541.250541 lmp.py:292]   Expert 16 |     26 | CPU
DEBUG 01-04 15:36:07.250469.250469 lmp.py:292]   Expert 32 |     29 | CPU
DEBUG 01-04 15:36:07.250920.250920 lmp.py:292]   Expert 25 |     31 | CPU
DEBUG 01-04 15:36:07.250609.250609 lmp.py:292]   Expert 55 |     31 | CPU
DEBUG 01-04 15:36:07.250060.250060 lmp.py:292]   Expert 57 |     33 | CPU
DEBUG 01-04 15:36:07.250749.250749 lmp.py:292]   Expert 26 |     34 | CPU
DEBUG 01-04 15:36:07.250962.250962 lmp.py:292]   Expert 59 |     35 | CPU
DEBUG 01-04 15:36:07.250413.250413 lmp.py:292]   Expert 44 |     36 | CPU
DEBUG 01-04 15:36:07.250340.250340 lmp.py:292]   Expert  6 |     43 | CPU
DEBUG 01-04 15:36:07.250745.250745 lmp.py:292]   Expert 37 |     48 | CPU
DEBUG 01-04 15:36:07.250149.250149 lmp.py:292]   Expert 38 |     51 | CPU
DEBUG 01-04 15:36:07.250839.250839 lmp.py:292]   Expert 18 |     52 | CPU
DEBUG 01-04 15:36:07.250528.250528 lmp.py:292]   Expert 12 |     55 | CPU
DEBUG 01-04 15:36:07.250979.250979 lmp.py:292]   Expert 30 |     61 | GPU
DEBUG 01-04 15:36:07.250668.250668 lmp.py:292]   Expert 51 |     61 | GPU
DEBUG 01-04 15:36:07.251358.251358 lmp.py:292]   Expert 41 |     62 | GPU
DEBUG 01-04 15:36:07.251808.251808 lmp.py:292]   Expert 58 |     72 | GPU
DEBUG 01-04 15:36:07.251021.251021 lmp.py:292]   Expert 54 |     75 | GPU
DEBUG 01-04 15:36:07.251187.251187 lmp.py:292]   Expert 43 |     76 | GPU
DEBUG 01-04 15:36:07.251592.251592 lmp.py:292]   Expert  9 |     84 | GPU
DEBUG 01-04 15:36:07.251758.251758 lmp.py:292]   Expert 33 |     85 | GPU
DEBUG 01-04 15:36:07.251447.251447 lmp.py:292]   Expert 46 |     86 | GPU
DEBUG 01-04 15:36:07.251136.251136 lmp.py:292]   Expert 45 |     87 | GPU
DEBUG 01-04 15:36:07.251826.251826 lmp.py:292]   Expert  8 |     91 | GPU
DEBUG 01-04 15:36:07.251276.251276 lmp.py:292]   Expert 13 |     91 | GPU
DEBUG 01-04 15:36:07.251727.251727 lmp.py:292]   Expert 19 |     91 | GPU
DEBUG 01-04 15:36:07.251417.251417 lmp.py:292]   Expert 17 |     94 | GPU
DEBUG 01-04 15:36:07.251106.251106 lmp.py:292]   Expert 29 |     95 | GPU
DEBUG 01-04 15:36:07.251795.251795 lmp.py:292]   Expert 48 |    104 | GPU
DEBUG 01-04 15:36:07.251438.251438 lmp.py:292]   Expert 27 |    108 | GPU
DEBUG 01-04 15:36:07.251366.251366 lmp.py:292]   Expert 42 |    108 | GPU
DEBUG 01-04 15:36:07.251817.251817 lmp.py:292]   Expert 23 |    113 | GPU
DEBUG 01-04 15:36:07.251268.251268 lmp.py:292]   Expert 24 |    131 | GPU
DEBUG 01-04 15:36:07.251719.251719 lmp.py:292]   Expert 21 |    134 | GPU
DEBUG 01-04 15:36:07.251931.251931 lmp.py:292]   Expert 20 |    168 | GPU
DEBUG 01-04 15:36:07.251620.251620 lmp.py:292]   Expert 39 |    180 | GPU
DEBUG 01-04 15:36:07.251548.251548 lmp.py:292]   Expert 60 |    208 | GPU
DEBUG 01-04 15:36:07.251999.251999 lmp.py:292]   Expert 56 |    251 | GPU
DEBUG 01-04 15:36:07.251165.251165 lmp.py:292]   Expert 36 |    402 | GPU
DEBUG 01-04 15:36:07.251808.251808 lmp.py:292]   Expert  1 |   1355 | GPU
DEBUG 01-04 15:36:07.251497.251497 lmp.py:292]   Expert  3 |   1358 | GPU
DEBUG 01-04 15:36:07.251948.251948 lmp.py:292]   Expert  5 |   1400 | GPU
DEBUG 01-04 15:36:07.251399.251399 lmp.py:292]   Expert  4 |   1406 | GPU
DEBUG 01-04 15:36:07.251327.251327 lmp.py:292]   Expert  0 |   1413 | GPU
DEBUG 01-04 15:36:07.251778.251778 lmp.py:292]   Expert  2 |   1451 | GPU
DEBUG 01-04 15:36:07.251182.251182 lmp.py:293] 
DEBUG 01-04 15:36:07.251182.251182 lmp.py:293]   CPU total tokens: 787 (6.4%)
DEBUG 01-04 15:36:07.251541.251541 lmp.py:294]   GPU total tokens: 11501 (93.6%)
DEBUG 01-04 15:36:07.251190.251190 cuda_h.py:19] end experts_map_get cost 0.0015249252319335938 seconds
DEBUG 01-04 15:36:07.251310.251310 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.251133.251133 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.251786.251786 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.252650.252650 cuda_h.py:19] end allocate_cuda_memory cost 0.00025272369384765625 seconds
DEBUG 01-04 15:36:07.252785.252785 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.252302.252302 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.252065.252065 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.252668.252668 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65a35d5e-efbb-45d9-b37f-8fc11b2a13c8
DEBUG 01-04 15:36:07.252376.252376 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.254444.254444 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65a35d5e-efbb-45d9-b37f-8fc11b2a13c8
DEBUG 01-04 15:36:07.254681.254681 cuda_h.py:19] end load_into_gpu_async cost 0.002192258834838867 seconds
DEBUG 01-04 15:36:07.254597.254597 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.254822.254822 cuda_h.py:19] end restore_tensors2 cost 0.00031113624572753906 seconds
DEBUG 01-04 15:36:07.254830.254830 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031952857971191406 seconds
DEBUG 01-04 15:36:07.257004.257004 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005851030349731445 seconds
DEBUG 01-04 15:36:07.257694.257694 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.257611.257611 lmp.py:339] 
DEBUG 01-04 15:36:07.257611.257611 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.257600.257600 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-04 15:36:07.257726.257726 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.269974.269974 mlpmodule.py:704] group tensors cost 0.011463165283203125 s
DEBUG 01-04 15:36:07.272446.272446 mlpmodule.py:742] pad cost 0.00185394287109375 s
DEBUG 01-04 15:36:07.272893.272893 mlpmodule.py:748] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-04 15:36:07.272657.272657 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-04 15:36:07.277336.277336 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.277616.277616 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.277778.277778 mlpmodule.py:774] group_w3 first element: 0.0003910064697265625
WARNING 01-04 15:36:07.277615.277615 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.281454.281454 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.281260.281260 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.286715.286715 mlpmodule.py:797] group einsum cost 0.014150381088256836 s
DEBUG 01-04 15:36:07.286349.286349 mlpmodule.py:805] cpy2cputensor cost 0.00025653839111328125 s
DEBUG 01-04 15:36:07.291953.291953 cuda_h.py:19] end wait_cetm_experts cost 0.03417849540710449 seconds
DEBUG 01-04 15:36:07.292028.292028 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.292706.292706 cuda_h.py:19] end gpu_sexperts cost 0.0006105899810791016 seconds
DEBUG 01-04 15:36:07.292571.292571 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-04 15:36:07.293328.293328 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-04 15:36:07.293318.293318 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 4.100799560546875e-05 seconds
DEBUG 01-04 15:36:07.293319.293319 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 8.58306884765625e-05 seconds
DEBUG 01-04 15:36:07.293307.293307 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.293639.293639 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65a35d5e-efbb-45d9-b37f-8fc11b2a13c8
DEBUG 01-04 15:36:07.293599.293599 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.293213.293213 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.293593.293593 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.298893.298893 cuda_h.py:19] end allocate_cuda_memory cost 0.004770517349243164 seconds
DEBUG 01-04 15:36:07.298931.298931 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.298661.298661 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.298259.298259 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.298353.298353 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 053c15c3-45bd-49bf-9ef1-eba0e2c52936
DEBUG 01-04 15:36:07.298879.298879 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.304971.304971 client.py:127] Model loaded
DEBUG 01-04 15:36:07.304586.304586 cuda_h.py:19] end wait_experts cost 0.011250734329223633 seconds
DEBUG 01-04 15:36:07.304133.304133 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.304202.304202 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.305892.305892 mlpmodule.py:531] gpu group tensors cost 0.0004966259002685547 s
DEBUG 01-04 15:36:07.306537.306537 mlpmodule.py:564] gpu pad cost 0.0014061927795410156 s
DEBUG 01-04 15:36:07.307488.307488 mlpmodule.py:582] gpu group einsum cost 0.0004563331604003906 s
DEBUG 01-04 15:36:07.309078.309078 mlpmodule.py:662]  experts func einsum cost 0.05199837684631348 s
DEBUG 01-04 15:36:07.311022.311022 mlpmodule.py:611] gpu experts func einsum cost 0.006333589553833008 s
DEBUG 01-04 15:36:07.311127.311127 cuda_h.py:19] end gpu_experts cost 0.0066585540771484375 seconds
DEBUG 01-04 15:36:07.311255.311255 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:07.311342.311342 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 053c15c3-45bd-49bf-9ef1-eba0e2c52936
DEBUG 01-04 15:36:07.312241.312241 cuda_h.py:19] end load_into_gpu_async cost 0.013367414474487305 seconds
DEBUG 01-04 15:36:07.312933.312933 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.312716.312716 cuda_h.py:19] end restore_tensors2 cost 0.00014400482177734375 seconds
DEBUG 01-04 15:36:07.312534.312534 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01883220672607422 seconds
INFO 01-04 15:36:07.313145.313145 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 053c15c3-45bd-49bf-9ef1-eba0e2c52936
INFO 01-04 15:36:07.319420.319420 client.py:127] Model loaded
DEBUG 01-04 15:36:07.319969.319969 cuda_h.py:19] end sllm_worker_task cost 0.025723934173583984 seconds
DEBUG 01-04 15:36:07.319102.319102 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.008021354675292969 seconds
DEBUG 01-04 15:36:07.319851.319851 cuda_h.py:19] end layer_moe_generate_6 cost 0.07057452201843262 seconds
DEBUG 01-04 15:36:07.320643.320643 lmp.py:207] -------------------------------- end layer 6 --------------------------------
DEBUG 01-04 15:36:07.320254.320254 lmp.py:169] -------------------------------- start layer 7 --------------------------------
DEBUG 01-04 15:36:07.320931.320931 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.320067.320067 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.325431.325431 cuda_h.py:19] end self_attn cost 0.0046384334564208984 seconds
DEBUG 01-04 15:36:07.326889.326889 cuda_h.py:19] end iln_self_attn_paln cost 0.005788326263427734 seconds
DEBUG 01-04 15:36:07.326258.326258 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-04 15:36:07.326473.326473 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.327989.327989 cuda_h.py:19] end gate cost 0.0011048316955566406 seconds
DEBUG 01-04 15:36:07.327245.327245 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.328143.328143 lmp.py:281] 
DEBUG 01-04 15:36:07.328143.328143 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.328629.328629 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.328233.328233 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.328924.328924 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.328415.328415 lmp.py:285] 
DEBUG 01-04 15:36:07.328415.328415 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.328430.328430 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.328227.328227 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:07.328911.328911 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:07.328972.328972 lmp.py:292]   Expert 41 |      5 | CPU
DEBUG 01-04 15:36:07.328556.328556 lmp.py:292]   Expert 63 |      5 | CPU
DEBUG 01-04 15:36:07.328332.328332 lmp.py:292]   Expert  6 |      8 | CPU
DEBUG 01-04 15:36:07.329632.329632 lmp.py:292]   Expert  8 |     10 | CPU
DEBUG 01-04 15:36:07.329931.329931 lmp.py:292]   Expert 25 |     11 | CPU
DEBUG 01-04 15:36:07.329039.329039 lmp.py:292]   Expert 59 |     12 | CPU
DEBUG 01-04 15:36:07.329577.329577 lmp.py:292]   Expert 15 |     13 | CPU
DEBUG 01-04 15:36:07.329684.329684 lmp.py:292]   Expert 20 |     14 | CPU
DEBUG 01-04 15:36:07.329838.329838 lmp.py:292]   Expert 31 |     14 | CPU
DEBUG 01-04 15:36:07.329422.329422 lmp.py:292]   Expert 30 |     19 | CPU
DEBUG 01-04 15:36:07.329245.329245 lmp.py:292]   Expert 40 |     19 | CPU
DEBUG 01-04 15:36:07.329836.329836 lmp.py:292]   Expert 58 |     19 | CPU
DEBUG 01-04 15:36:07.329619.329619 lmp.py:292]   Expert 57 |     20 | CPU
DEBUG 01-04 15:36:07.329846.329846 lmp.py:292]   Expert 50 |     22 | CPU
DEBUG 01-04 15:36:07.329014.329014 lmp.py:292]   Expert 52 |     24 | CPU
DEBUG 01-04 15:36:07.329936.329936 lmp.py:292]   Expert 18 |     25 | CPU
DEBUG 01-04 15:36:07.329520.329520 lmp.py:292]   Expert 29 |     29 | CPU
DEBUG 01-04 15:36:07.329674.329674 lmp.py:292]   Expert 39 |     29 | CPU
DEBUG 01-04 15:36:07.329020.329020 lmp.py:292]   Expert 32 |     30 | CPU
DEBUG 01-04 15:36:07.329366.329366 lmp.py:292]   Expert 34 |     32 | CPU
DEBUG 01-04 15:36:07.329281.329281 lmp.py:292]   Expert 60 |     34 | CPU
DEBUG 01-04 15:36:07.329196.329196 lmp.py:292]   Expert 48 |     38 | CPU
DEBUG 01-04 15:36:07.329396.329396 lmp.py:292]   Expert 19 |     42 | CPU
DEBUG 01-04 15:36:07.329312.329312 lmp.py:292]   Expert 14 |     43 | CPU
DEBUG 01-04 15:36:07.329512.329512 lmp.py:292]   Expert 35 |     46 | CPU
DEBUG 01-04 15:36:07.330474.330474 lmp.py:292]   Expert 24 |     50 | CPU
DEBUG 01-04 15:36:07.330674.330674 lmp.py:292]   Expert 62 |     56 | CPU
DEBUG 01-04 15:36:07.330397.330397 lmp.py:292]   Expert 54 |     61 | CPU
DEBUG 01-04 15:36:07.330359.330359 lmp.py:292]   Expert 53 |     63 | CPU
DEBUG 01-04 15:36:07.330512.330512 lmp.py:292]   Expert 42 |     72 | CPU
DEBUG 01-04 15:36:07.330951.330951 lmp.py:292]   Expert 45 |     74 | GPU
DEBUG 01-04 15:36:07.330674.330674 lmp.py:292]   Expert 47 |     74 | GPU
DEBUG 01-04 15:36:07.330020.330020 lmp.py:292]   Expert 55 |     75 | GPU
DEBUG 01-04 15:36:07.330651.330651 lmp.py:292]   Expert 36 |     77 | GPU
DEBUG 01-04 15:36:07.330089.330089 lmp.py:292]   Expert 11 |     78 | GPU
DEBUG 01-04 15:36:07.330004.330004 lmp.py:292]   Expert 33 |     78 | GPU
DEBUG 01-04 15:36:07.330635.330635 lmp.py:292]   Expert 17 |     79 | GPU
DEBUG 01-04 15:36:07.330073.330073 lmp.py:292]   Expert 51 |     87 | GPU
DEBUG 01-04 15:36:07.330035.330035 lmp.py:292]   Expert  7 |     90 | GPU
DEBUG 01-04 15:36:07.330189.330189 lmp.py:292]   Expert 21 |     90 | GPU
DEBUG 01-04 15:36:07.330627.330627 lmp.py:292]   Expert 28 |     93 | GPU
DEBUG 01-04 15:36:07.330112.330112 lmp.py:292]   Expert 13 |     95 | GPU
DEBUG 01-04 15:36:07.330028.330028 lmp.py:292]   Expert 43 |     96 | GPU
DEBUG 01-04 15:36:07.330705.330705 lmp.py:292]   Expert 27 |    103 | GPU
DEBUG 01-04 15:36:07.330905.330905 lmp.py:292]   Expert 26 |    106 | GPU
DEBUG 01-04 15:36:07.330674.330674 lmp.py:292]   Expert 61 |    108 | GPU
DEBUG 01-04 15:36:07.330113.330113 lmp.py:292]   Expert 22 |    116 | GPU
DEBUG 01-04 15:36:07.330028.330028 lmp.py:292]   Expert 37 |    128 | GPU
DEBUG 01-04 15:36:07.330467.330467 lmp.py:292]   Expert 10 |    135 | GPU
DEBUG 01-04 15:36:07.331428.331428 lmp.py:292]   Expert 38 |    144 | GPU
DEBUG 01-04 15:36:07.331860.331860 lmp.py:292]   Expert 23 |    153 | GPU
DEBUG 01-04 15:36:07.331218.331218 lmp.py:292]   Expert 46 |    163 | GPU
DEBUG 01-04 15:36:07.331292.331292 lmp.py:292]   Expert  9 |    164 | GPU
DEBUG 01-04 15:36:07.331173.331173 lmp.py:292]   Expert 44 |    177 | GPU
DEBUG 01-04 15:36:07.331816.331816 lmp.py:292]   Expert 56 |    218 | GPU
DEBUG 01-04 15:36:07.331697.331697 lmp.py:292]   Expert 12 |    251 | GPU
DEBUG 01-04 15:36:07.331340.331340 lmp.py:292]   Expert  3 |   1360 | GPU
DEBUG 01-04 15:36:07.331222.331222 lmp.py:292]   Expert  1 |   1365 | GPU
DEBUG 01-04 15:36:07.331103.331103 lmp.py:292]   Expert  5 |   1376 | GPU
DEBUG 01-04 15:36:07.331223.331223 lmp.py:292]   Expert  0 |   1382 | GPU
DEBUG 01-04 15:36:07.331820.331820 lmp.py:292]   Expert  4 |   1428 | GPU
DEBUG 01-04 15:36:07.331370.331370 lmp.py:292]   Expert  2 |   1453 | GPU
DEBUG 01-04 15:36:07.331205.331205 lmp.py:293] 
DEBUG 01-04 15:36:07.331205.331205 lmp.py:293]   CPU total tokens: 872 (7.1%)
DEBUG 01-04 15:36:07.331279.331279 lmp.py:294]   GPU total tokens: 11416 (92.9%)
DEBUG 01-04 15:36:07.331405.331405 cuda_h.py:19] end experts_map_get cost 0.003529787063598633 seconds
DEBUG 01-04 15:36:07.331717.331717 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.331831.331831 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.331776.331776 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.331700.331700 cuda_h.py:19] end allocate_cuda_memory cost 0.0002593994140625 seconds
DEBUG 01-04 15:36:07.331881.331881 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.331829.331829 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.331883.331883 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.331679.331679 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3566619b-6dad-4fef-98a8-ea081a138045
DEBUG 01-04 15:36:07.332023.332023 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.334991.334991 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3566619b-6dad-4fef-98a8-ea081a138045
DEBUG 01-04 15:36:07.334498.334498 cuda_h.py:19] end load_into_gpu_async cost 0.002373218536376953 seconds
DEBUG 01-04 15:36:07.334355.334355 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.334093.334093 cuda_h.py:19] end restore_tensors2 cost 0.00041174888610839844 seconds
DEBUG 01-04 15:36:07.334869.334869 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034792423248291016 seconds
DEBUG 01-04 15:36:07.337806.337806 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006391763687133789 seconds
DEBUG 01-04 15:36:07.337927.337927 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.337420.337420 lmp.py:339] 
DEBUG 01-04 15:36:07.337420.337420 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.337270.337270 cuda_h.py:19] end cpu_experts_submit cost 0.00011539459228515625 seconds
DEBUG 01-04 15:36:07.338496.338496 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.349674.349674 mlpmodule.py:704] group tensors cost 0.011137723922729492 s
DEBUG 01-04 15:36:07.353582.353582 mlpmodule.py:742] pad cost 0.002668619155883789 s
DEBUG 01-04 15:36:07.353269.353269 mlpmodule.py:748] create cpu tensor cost 6.246566772460938e-05 s
DEBUG 01-04 15:36:07.353783.353783 mlpmodule.py:753] move to cpu cost 4.5299530029296875e-05 s
DEBUG 01-04 15:36:07.359300.359300 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.359654.359654 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.359809.359809 mlpmodule.py:774] group_w3 first element: -0.08056640625
WARNING 01-04 15:36:07.359143.359143 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.363282.363282 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.363662.363662 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.368534.368534 mlpmodule.py:797] group einsum cost 0.015071868896484375 s
DEBUG 01-04 15:36:07.369647.369647 mlpmodule.py:805] cpy2cputensor cost 0.00033354759216308594 s
DEBUG 01-04 15:36:07.374998.374998 cuda_h.py:19] end wait_cetm_experts cost 0.03606295585632324 seconds
DEBUG 01-04 15:36:07.374156.374156 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.374912.374912 cuda_h.py:19] end gpu_sexperts cost 0.0005838871002197266 seconds
DEBUG 01-04 15:36:07.375232.375232 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-04 15:36:07.375479.375479 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-04 15:36:07.375111.375111 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 4.0531158447265625e-05 seconds
DEBUG 01-04 15:36:07.375827.375827 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 8.606910705566406e-05 seconds
DEBUG 01-04 15:36:07.375623.375623 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.375286.375286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3566619b-6dad-4fef-98a8-ea081a138045
DEBUG 01-04 15:36:07.375484.375484 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.375746.375746 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.375226.375226 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.380753.380753 cuda_h.py:19] end allocate_cuda_memory cost 0.004629850387573242 seconds
DEBUG 01-04 15:36:07.380658.380658 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.380832.380832 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.380808.380808 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.380325.380325 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5e292e8-c129-43a5-a655-82aa39a350e3
DEBUG 01-04 15:36:07.380176.380176 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.386977.386977 client.py:127] Model loaded
DEBUG 01-04 15:36:07.386125.386125 cuda_h.py:19] end wait_experts cost 0.011011123657226562 seconds
DEBUG 01-04 15:36:07.386358.386358 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.386253.386253 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.386908.386908 mlpmodule.py:531] gpu group tensors cost 0.00051116943359375 s
INFO 01-04 15:36:07.387871.387871 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5e292e8-c129-43a5-a655-82aa39a350e3
DEBUG 01-04 15:36:07.387284.387284 cuda_h.py:19] end load_into_gpu_async cost 0.0067596435546875 seconds
DEBUG 01-04 15:36:07.387769.387769 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.387613.387613 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-04 15:36:07.387654.387654 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011828184127807617 seconds
INFO 01-04 15:36:07.387492.387492 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5e292e8-c129-43a5-a655-82aa39a350e3
DEBUG 01-04 15:36:07.389786.389786 mlpmodule.py:564] gpu pad cost 0.002245664596557617 s
DEBUG 01-04 15:36:07.389526.389526 mlpmodule.py:582] gpu group einsum cost 0.00047516822814941406 s
DEBUG 01-04 15:36:07.391416.391416 mlpmodule.py:662]  experts func einsum cost 0.05314183235168457 s
DEBUG 01-04 15:36:07.392799.392799 mlpmodule.py:611] gpu experts func einsum cost 0.006354570388793945 s
DEBUG 01-04 15:36:07.392957.392957 cuda_h.py:19] end gpu_experts cost 0.00659489631652832 seconds
DEBUG 01-04 15:36:07.392044.392044 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:07.397962.397962 client.py:127] Model loaded
DEBUG 01-04 15:36:07.397090.397090 cuda_h.py:19] end sllm_worker_task cost 0.021925926208496094 seconds
DEBUG 01-04 15:36:07.397291.397291 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004576921463012695 seconds
DEBUG 01-04 15:36:07.397541.397541 cuda_h.py:19] end layer_moe_generate_7 cost 0.07127618789672852 seconds
DEBUG 01-04 15:36:07.397804.397804 lmp.py:207] -------------------------------- end layer 7 --------------------------------
DEBUG 01-04 15:36:07.397090.397090 lmp.py:169] -------------------------------- start layer 8 --------------------------------
DEBUG 01-04 15:36:07.397641.397641 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.398868.398868 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.400723.400723 cuda_h.py:19] end self_attn cost 0.002332448959350586 seconds
DEBUG 01-04 15:36:07.400554.400554 cuda_h.py:19] end iln_self_attn_paln cost 0.002927064895629883 seconds
DEBUG 01-04 15:36:07.400583.400583 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-04 15:36:07.400869.400869 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.401968.401968 cuda_h.py:19] end gate cost 0.0005564689636230469 seconds
DEBUG 01-04 15:36:07.401745.401745 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.401396.401396 lmp.py:281] 
DEBUG 01-04 15:36:07.401396.401396 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.401576.401576 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.401080.401080 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.401676.401676 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.401127.401127 lmp.py:285] 
DEBUG 01-04 15:36:07.401127.401127 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.401101.401101 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.401797.401797 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:07.402248.402248 lmp.py:292]   Expert  7 |      2 | CPU
DEBUG 01-04 15:36:07.402984.402984 lmp.py:292]   Expert  9 |      2 | CPU
DEBUG 01-04 15:36:07.402243.402243 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:07.402740.402740 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:07.402237.402237 lmp.py:292]   Expert 57 |      2 | CPU
DEBUG 01-04 15:36:07.402496.402496 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:07.402755.402755 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:07.402490.402490 lmp.py:292]   Expert 53 |      4 | CPU
DEBUG 01-04 15:36:07.402941.402941 lmp.py:292]   Expert 14 |      8 | CPU
DEBUG 01-04 15:36:07.402392.402392 lmp.py:292]   Expert 38 |     11 | CPU
DEBUG 01-04 15:36:07.402412.402412 lmp.py:292]   Expert 54 |     11 | CPU
DEBUG 01-04 15:36:07.402671.402671 lmp.py:292]   Expert 13 |     12 | CPU
DEBUG 01-04 15:36:07.402453.402453 lmp.py:292]   Expert 29 |     12 | CPU
DEBUG 01-04 15:36:07.402235.402235 lmp.py:292]   Expert 36 |     15 | CPU
DEBUG 01-04 15:36:07.402494.402494 lmp.py:292]   Expert 60 |     15 | CPU
DEBUG 01-04 15:36:07.402276.402276 lmp.py:292]   Expert 19 |     16 | CPU
DEBUG 01-04 15:36:07.402296.402296 lmp.py:292]   Expert 59 |     16 | CPU
DEBUG 01-04 15:36:07.402840.402840 lmp.py:292]   Expert 51 |     18 | CPU
DEBUG 01-04 15:36:07.402860.402860 lmp.py:292]   Expert 50 |     19 | CPU
DEBUG 01-04 15:36:07.402642.402642 lmp.py:292]   Expert 34 |     21 | CPU
DEBUG 01-04 15:36:07.402855.402855 lmp.py:292]   Expert 40 |     27 | CPU
DEBUG 01-04 15:36:07.402590.402590 lmp.py:292]   Expert 12 |     29 | CPU
DEBUG 01-04 15:36:07.402849.402849 lmp.py:292]   Expert 46 |     31 | CPU
DEBUG 01-04 15:36:07.402631.402631 lmp.py:292]   Expert 17 |     32 | CPU
DEBUG 01-04 15:36:07.402413.402413 lmp.py:292]   Expert 23 |     33 | CPU
DEBUG 01-04 15:36:07.402195.402195 lmp.py:292]   Expert 32 |     33 | CPU
DEBUG 01-04 15:36:07.402215.402215 lmp.py:292]   Expert 10 |     37 | CPU
DEBUG 01-04 15:36:07.402474.402474 lmp.py:292]   Expert 37 |     38 | CPU
DEBUG 01-04 15:36:07.402494.402494 lmp.py:292]   Expert 22 |     42 | CPU
DEBUG 01-04 15:36:07.402468.402468 lmp.py:292]   Expert 58 |     43 | CPU
DEBUG 01-04 15:36:07.402204.402204 lmp.py:292]   Expert 33 |     44 | CPU
DEBUG 01-04 15:36:07.402224.402224 lmp.py:292]   Expert 31 |     47 | GPU
DEBUG 01-04 15:36:07.402245.402245 lmp.py:292]   Expert 15 |     51 | GPU
DEBUG 01-04 15:36:07.402265.402265 lmp.py:292]   Expert 16 |     52 | GPU
DEBUG 01-04 15:36:07.402047.402047 lmp.py:292]   Expert 39 |     54 | GPU
DEBUG 01-04 15:36:07.402829.402829 lmp.py:292]   Expert 44 |     54 | GPU
DEBUG 01-04 15:36:07.402611.402611 lmp.py:292]   Expert 35 |     59 | GPU
DEBUG 01-04 15:36:07.402631.402631 lmp.py:292]   Expert 56 |     59 | GPU
DEBUG 01-04 15:36:07.402413.402413 lmp.py:292]   Expert  6 |     62 | GPU
DEBUG 01-04 15:36:07.402626.402626 lmp.py:292]   Expert 49 |     76 | GPU
DEBUG 01-04 15:36:07.402123.402123 lmp.py:292]   Expert 42 |     81 | GPU
DEBUG 01-04 15:36:07.402143.402143 lmp.py:292]   Expert 18 |     83 | GPU
DEBUG 01-04 15:36:07.402402.402402 lmp.py:292]   Expert 55 |     86 | GPU
DEBUG 01-04 15:36:07.402184.402184 lmp.py:292]   Expert 41 |     94 | GPU
DEBUG 01-04 15:36:07.402966.402966 lmp.py:292]   Expert 43 |    101 | GPU
DEBUG 01-04 15:36:07.402986.402986 lmp.py:292]   Expert 48 |    105 | GPU
DEBUG 01-04 15:36:07.402007.402007 lmp.py:292]   Expert 25 |    111 | GPU
DEBUG 01-04 15:36:07.402027.402027 lmp.py:292]   Expert 61 |    113 | GPU
DEBUG 01-04 15:36:07.402524.402524 lmp.py:292]   Expert 47 |    123 | GPU
DEBUG 01-04 15:36:07.402306.402306 lmp.py:292]   Expert 45 |    128 | GPU
DEBUG 01-04 15:36:07.402280.402280 lmp.py:292]   Expert 52 |    134 | GPU
DEBUG 01-04 15:36:07.402254.402254 lmp.py:292]   Expert 20 |    135 | GPU
DEBUG 01-04 15:36:07.402513.402513 lmp.py:292]   Expert 28 |    135 | GPU
DEBUG 01-04 15:36:07.402057.402057 lmp.py:292]   Expert 62 |    139 | GPU
DEBUG 01-04 15:36:07.402077.402077 lmp.py:292]   Expert 63 |    153 | GPU
DEBUG 01-04 15:36:07.402097.402097 lmp.py:292]   Expert 11 |    157 | GPU
DEBUG 01-04 15:36:07.402118.402118 lmp.py:292]   Expert 21 |    261 | GPU
DEBUG 01-04 15:36:07.402900.402900 lmp.py:292]   Expert  1 |   1435 | GPU
DEBUG 01-04 15:36:07.402920.402920 lmp.py:292]   Expert  2 |   1475 | GPU
DEBUG 01-04 15:36:07.402179.402179 lmp.py:292]   Expert  0 |   1499 | GPU
DEBUG 01-04 15:36:07.402961.402961 lmp.py:292]   Expert  3 |   1509 | GPU
DEBUG 01-04 15:36:07.402981.402981 lmp.py:292]   Expert  4 |   1523 | GPU
DEBUG 01-04 15:36:07.402194.402194 lmp.py:292]   Expert  5 |   1610 | GPU
DEBUG 01-04 15:36:07.402168.402168 lmp.py:293] 
DEBUG 01-04 15:36:07.402168.402168 lmp.py:293]   CPU total tokens: 584 (4.8%)
DEBUG 01-04 15:36:07.402142.402142 lmp.py:294]   GPU total tokens: 11704 (95.2%)
DEBUG 01-04 15:36:07.403407.403407 cuda_h.py:19] end experts_map_get cost 0.0013744831085205078 seconds
DEBUG 01-04 15:36:07.403381.403381 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.403105.403105 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.403460.403460 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.403675.403675 cuda_h.py:19] end allocate_cuda_memory cost 0.0002682209014892578 seconds
DEBUG 01-04 15:36:07.403896.403896 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.403029.403029 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.403123.403123 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.403342.403342 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d4d735cc-3234-4f03-9224-fb396b6b8319
DEBUG 01-04 15:36:07.403082.403082 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.404241.404241 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d4d735cc-3234-4f03-9224-fb396b6b8319
DEBUG 01-04 15:36:07.405640.405640 cuda_h.py:19] end load_into_gpu_async cost 0.0014328956604003906 seconds
DEBUG 01-04 15:36:07.405528.405528 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.405378.405378 cuda_h.py:19] end restore_tensors2 cost 0.0002529621124267578 seconds
DEBUG 01-04 15:36:07.405717.405717 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022573471069335938 seconds
DEBUG 01-04 15:36:07.407309.407309 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004727602005004883 seconds
DEBUG 01-04 15:36:07.407562.407562 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.407856.407856 lmp.py:339] 
DEBUG 01-04 15:36:07.407856.407856 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.407745.407745 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-04 15:36:07.407918.407918 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.419312.419312 mlpmodule.py:704] group tensors cost 0.011371135711669922 s
DEBUG 01-04 15:36:07.422010.422010 mlpmodule.py:742] pad cost 0.002153635025024414 s
DEBUG 01-04 15:36:07.422411.422411 mlpmodule.py:748] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-04 15:36:07.422652.422652 mlpmodule.py:753] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-04 15:36:07.427308.427308 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.427489.427489 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.427928.427928 mlpmodule.py:774] group_w3 first element: 0.048583984375
WARNING 01-04 15:36:07.428166.428166 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.432142.432142 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.432589.432589 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.436426.436426 mlpmodule.py:797] group einsum cost 0.014150619506835938 s
DEBUG 01-04 15:36:07.437533.437533 mlpmodule.py:805] cpy2cputensor cost 0.00019049644470214844 s
DEBUG 01-04 15:36:07.442499.442499 cuda_h.py:19] end wait_cetm_experts cost 0.03425931930541992 seconds
DEBUG 01-04 15:36:07.442439.442439 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.443170.443170 cuda_h.py:19] end gpu_sexperts cost 0.0006005764007568359 seconds
DEBUG 01-04 15:36:07.443351.443351 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-04 15:36:07.443312.443312 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-04 15:36:07.443805.443805 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 4.38690185546875e-05 seconds
DEBUG 01-04 15:36:07.443329.443329 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 8.797645568847656e-05 seconds
DEBUG 01-04 15:36:07.443648.443648 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.443742.443742 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d4d735cc-3234-4f03-9224-fb396b6b8319
DEBUG 01-04 15:36:07.443271.443271 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.443679.443679 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.443383.443383 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.448833.448833 cuda_h.py:19] end allocate_cuda_memory cost 0.004889965057373047 seconds
DEBUG 01-04 15:36:07.448665.448665 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.448687.448687 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.448185.448185 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.449941.449941 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ac028174-ba72-4ed4-9326-685d58ca6ff8
DEBUG 01-04 15:36:07.449176.449176 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.455431.455431 client.py:127] Model loaded
DEBUG 01-04 15:36:07.455057.455057 cuda_h.py:19] end wait_experts cost 0.011786460876464844 seconds
DEBUG 01-04 15:36:07.455522.455522 cuda_h.py:10] start gpu_experts
INFO 01-04 15:36:07.455670.455670 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ac028174-ba72-4ed4-9326-685d58ca6ff8
DEBUG 01-04 15:36:07.455857.455857 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.455316.455316 cuda_h.py:19] end load_into_gpu_async cost 0.006536245346069336 seconds
DEBUG 01-04 15:36:07.455020.455020 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.456500.456500 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-04 15:36:07.456687.456687 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012261390686035156 seconds
DEBUG 01-04 15:36:07.456928.456928 mlpmodule.py:531] gpu group tensors cost 0.00079345703125 s
INFO 01-04 15:36:07.456163.456163 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ac028174-ba72-4ed4-9326-685d58ca6ff8
DEBUG 01-04 15:36:07.461801.461801 mlpmodule.py:662]  experts func einsum cost 0.05368399620056152 s
DEBUG 01-04 15:36:07.463286.463286 mlpmodule.py:564] gpu pad cost 0.006825447082519531 s
INFO 01-04 15:36:07.463615.463615 client.py:127] Model loaded
DEBUG 01-04 15:36:07.463302.463302 cuda_h.py:19] end sllm_worker_task cost 0.0197756290435791 seconds
DEBUG 01-04 15:36:07.464627.464627 mlpmodule.py:582] gpu group einsum cost 0.0006692409515380859 s
DEBUG 01-04 15:36:07.467594.467594 mlpmodule.py:611] gpu experts func einsum cost 0.011573553085327148 s
DEBUG 01-04 15:36:07.467517.467517 cuda_h.py:19] end gpu_experts cost 0.011795759201049805 seconds
DEBUG 01-04 15:36:07.467558.467558 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.467904.467904 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-04 15:36:07.470374.470374 cuda_h.py:19] end layer_moe_generate_8 cost 0.06947612762451172 seconds
DEBUG 01-04 15:36:07.470942.470942 lmp.py:207] -------------------------------- end layer 8 --------------------------------
DEBUG 01-04 15:36:07.470328.470328 lmp.py:169] -------------------------------- start layer 9 --------------------------------
DEBUG 01-04 15:36:07.470024.470024 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.470418.470418 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.473017.473017 cuda_h.py:19] end self_attn cost 0.002425670623779297 seconds
DEBUG 01-04 15:36:07.473557.473557 cuda_h.py:19] end iln_self_attn_paln cost 0.003031492233276367 seconds
DEBUG 01-04 15:36:07.473678.473678 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-04 15:36:07.473295.473295 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.474083.474083 cuda_h.py:19] end gate cost 0.0005478858947753906 seconds
DEBUG 01-04 15:36:07.474859.474859 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.474589.474589 lmp.py:281] 
DEBUG 01-04 15:36:07.474589.474589 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.474723.474723 lmp.py:282]   Total experts: 62
DEBUG 01-04 15:36:07.474227.474227 lmp.py:283]   CPU experts: 31 (50%)
DEBUG 01-04 15:36:07.474108.474108 lmp.py:284]   GPU experts: 31 (50%)
DEBUG 01-04 15:36:07.474605.474605 lmp.py:285] 
DEBUG 01-04 15:36:07.474605.474605 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.474818.474818 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.474514.474514 lmp.py:292]   Expert 57 |      3 | CPU
DEBUG 01-04 15:36:07.474726.474726 lmp.py:292]   Expert 52 |      5 | CPU
DEBUG 01-04 15:36:07.474985.474985 lmp.py:292]   Expert  6 |      6 | CPU
DEBUG 01-04 15:36:07.474244.474244 lmp.py:292]   Expert 13 |      7 | CPU
DEBUG 01-04 15:36:07.474741.474741 lmp.py:292]   Expert 45 |      7 | CPU
DEBUG 01-04 15:36:07.474954.474954 lmp.py:292]   Expert 48 |      7 | CPU
DEBUG 01-04 15:36:07.474689.474689 lmp.py:292]   Expert 19 |      9 | CPU
DEBUG 01-04 15:36:07.474902.474902 lmp.py:292]   Expert 60 |      9 | CPU
DEBUG 01-04 15:36:07.474637.474637 lmp.py:292]   Expert 17 |     10 | CPU
DEBUG 01-04 15:36:07.474850.474850 lmp.py:292]   Expert 35 |     12 | CPU
DEBUG 01-04 15:36:07.474870.474870 lmp.py:292]   Expert 40 |     13 | CPU
DEBUG 01-04 15:36:07.474891.474891 lmp.py:292]   Expert 20 |     15 | CPU
DEBUG 01-04 15:36:07.475673.475673 lmp.py:292]   Expert 39 |     18 | CPU
DEBUG 01-04 15:36:07.475216.475216 lmp.py:292]   Expert 12 |     20 | CPU
DEBUG 01-04 15:36:07.475998.475998 lmp.py:292]   Expert 25 |     20 | CPU
DEBUG 01-04 15:36:07.475018.475018 lmp.py:292]   Expert 26 |     22 | CPU
DEBUG 01-04 15:36:07.475800.475800 lmp.py:292]   Expert 30 |     23 | CPU
DEBUG 01-04 15:36:07.475582.475582 lmp.py:292]   Expert 47 |     24 | CPU
DEBUG 01-04 15:36:07.475364.475364 lmp.py:292]   Expert 24 |     29 | CPU
DEBUG 01-04 15:36:07.475908.475908 lmp.py:292]   Expert 27 |     29 | CPU
DEBUG 01-04 15:36:07.475451.475451 lmp.py:292]   Expert 14 |     30 | CPU
DEBUG 01-04 15:36:07.475948.475948 lmp.py:292]   Expert 41 |     30 | CPU
DEBUG 01-04 15:36:07.475446.475446 lmp.py:292]   Expert 29 |     34 | CPU
DEBUG 01-04 15:36:07.475466.475466 lmp.py:292]   Expert 32 |     35 | CPU
DEBUG 01-04 15:36:07.475248.475248 lmp.py:292]   Expert 34 |     35 | CPU
DEBUG 01-04 15:36:07.475030.475030 lmp.py:292]   Expert 23 |     37 | CPU
DEBUG 01-04 15:36:07.475335.475335 lmp.py:292]   Expert 58 |     39 | CPU
DEBUG 01-04 15:36:07.475879.475879 lmp.py:292]   Expert 18 |     40 | CPU
DEBUG 01-04 15:36:07.475184.475184 lmp.py:292]   Expert 43 |     41 | CPU
DEBUG 01-04 15:36:07.475727.475727 lmp.py:292]   Expert 28 |     45 | CPU
DEBUG 01-04 15:36:07.475032.475032 lmp.py:292]   Expert 16 |     46 | CPU
DEBUG 01-04 15:36:07.475814.475814 lmp.py:292]   Expert 10 |     47 | GPU
DEBUG 01-04 15:36:07.475596.475596 lmp.py:292]   Expert 54 |     48 | GPU
DEBUG 01-04 15:36:07.475140.475140 lmp.py:292]   Expert 62 |     52 | GPU
DEBUG 01-04 15:36:07.475922.475922 lmp.py:292]   Expert 22 |     54 | GPU
DEBUG 01-04 15:36:07.475704.475704 lmp.py:292]   Expert 59 |     54 | GPU
DEBUG 01-04 15:36:07.475870.475870 lmp.py:292]   Expert 31 |     56 | GPU
DEBUG 01-04 15:36:07.475367.475367 lmp.py:292]   Expert 53 |     57 | GPU
DEBUG 01-04 15:36:07.475341.475341 lmp.py:292]   Expert 49 |     59 | GPU
DEBUG 01-04 15:36:07.475123.475123 lmp.py:292]   Expert 51 |     62 | GPU
DEBUG 01-04 15:36:07.475382.475382 lmp.py:292]   Expert 36 |     65 | GPU
DEBUG 01-04 15:36:07.475402.475402 lmp.py:292]   Expert 42 |     67 | GPU
DEBUG 01-04 15:36:07.475946.475946 lmp.py:292]   Expert 50 |     69 | GPU
DEBUG 01-04 15:36:07.475251.475251 lmp.py:292]   Expert 61 |     69 | GPU
DEBUG 01-04 15:36:07.475033.475033 lmp.py:292]   Expert 44 |     88 | GPU
DEBUG 01-04 15:36:07.475576.475576 lmp.py:292]   Expert 11 |     92 | GPU
DEBUG 01-04 15:36:07.475120.475120 lmp.py:292]   Expert 33 |    107 | GPU
DEBUG 01-04 15:36:07.475663.475663 lmp.py:292]   Expert  9 |    109 | GPU
DEBUG 01-04 15:36:07.475207.475207 lmp.py:292]   Expert 55 |    122 | GPU
DEBUG 01-04 15:36:07.475750.475750 lmp.py:292]   Expert 15 |    144 | GPU
DEBUG 01-04 15:36:07.475056.475056 lmp.py:292]   Expert 37 |    157 | GPU
DEBUG 01-04 15:36:07.475314.475314 lmp.py:292]   Expert 46 |    182 | GPU
DEBUG 01-04 15:36:07.475573.475573 lmp.py:292]   Expert 63 |    206 | GPU
DEBUG 01-04 15:36:07.475885.475885 lmp.py:292]   Expert 21 |    237 | GPU
DEBUG 01-04 15:36:07.475144.475144 lmp.py:292]   Expert 56 |    247 | GPU
DEBUG 01-04 15:36:07.475403.475403 lmp.py:292]   Expert  8 |    335 | GPU
DEBUG 01-04 15:36:07.475423.475423 lmp.py:292]   Expert  5 |   1419 | GPU
DEBUG 01-04 15:36:07.475728.475728 lmp.py:292]   Expert  2 |   1426 | GPU
DEBUG 01-04 15:36:07.475272.475272 lmp.py:292]   Expert  1 |   1447 | GPU
DEBUG 01-04 15:36:07.475577.475577 lmp.py:292]   Expert  4 |   1502 | GPU
DEBUG 01-04 15:36:07.475120.475120 lmp.py:292]   Expert  0 |   1504 | GPU
DEBUG 01-04 15:36:07.475902.475902 lmp.py:292]   Expert  3 |   1505 | GPU
DEBUG 01-04 15:36:07.475923.475923 lmp.py:293] 
DEBUG 01-04 15:36:07.475923.475923 lmp.py:293]   CPU total tokens: 700 (5.7%)
DEBUG 01-04 15:36:07.475181.475181 lmp.py:294]   GPU total tokens: 11588 (94.3%)
DEBUG 01-04 15:36:07.475878.475878 cuda_h.py:19] end experts_map_get cost 0.0013210773468017578 seconds
DEBUG 01-04 15:36:07.475852.475852 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.475813.475813 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.475976.475976 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.476892.476892 cuda_h.py:19] end allocate_cuda_memory cost 0.00022149085998535156 seconds
DEBUG 01-04 15:36:07.476781.476781 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.476875.476875 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.476062.476062 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.476804.476804 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea8d2231-3089-494b-9cc5-e4b5a7461e6b
DEBUG 01-04 15:36:07.476565.476565 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.477292.477292 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea8d2231-3089-494b-9cc5-e4b5a7461e6b
DEBUG 01-04 15:36:07.477130.477130 cuda_h.py:19] end load_into_gpu_async cost 0.0014693737030029297 seconds
DEBUG 01-04 15:36:07.477894.477894 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.478823.478823 cuda_h.py:19] end restore_tensors2 cost 0.0003795623779296875 seconds
DEBUG 01-04 15:36:07.478400.478400 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024826526641845703 seconds
DEBUG 01-04 15:36:07.480684.480684 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004871845245361328 seconds
DEBUG 01-04 15:36:07.480468.480468 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.480139.480139 lmp.py:339] 
DEBUG 01-04 15:36:07.480139.480139 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:07.480790.480790 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-04 15:36:07.480440.480440 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.489670.489670 mlpmodule.py:704] group tensors cost 0.008438825607299805 s
DEBUG 01-04 15:36:07.493805.493805 mlpmodule.py:742] pad cost 0.002878904342651367 s
DEBUG 01-04 15:36:07.493863.493863 mlpmodule.py:748] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-04 15:36:07.493495.493495 mlpmodule.py:753] move to cpu cost 3.790855407714844e-05 s
DEBUG 01-04 15:36:07.498210.498210 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:07.498504.498504 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.498407.498407 mlpmodule.py:774] group_w3 first element: -0.00640869140625
WARNING 01-04 15:36:07.498973.498973 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.502994.502994 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.503897.503897 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.507526.507526 mlpmodule.py:797] group einsum cost 0.013948917388916016 s
DEBUG 01-04 15:36:07.507687.507687 mlpmodule.py:805] cpy2cputensor cost 0.00018143653869628906 s
DEBUG 01-04 15:36:07.512385.512385 cuda_h.py:19] end wait_cetm_experts cost 0.03189373016357422 seconds
DEBUG 01-04 15:36:07.513922.513922 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.513491.513491 cuda_h.py:19] end gpu_sexperts cost 0.0007078647613525391 seconds
DEBUG 01-04 15:36:07.513764.513764 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-04 15:36:07.513872.513872 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-04 15:36:07.514742.514742 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 4.1961669921875e-05 seconds
DEBUG 01-04 15:36:07.514074.514074 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 8.392333984375e-05 seconds
DEBUG 01-04 15:36:07.514585.514585 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.514202.514202 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea8d2231-3089-494b-9cc5-e4b5a7461e6b
DEBUG 01-04 15:36:07.514923.514923 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.514199.514199 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.514857.514857 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.518701.518701 cuda_h.py:19] end allocate_cuda_memory cost 0.004407405853271484 seconds
DEBUG 01-04 15:36:07.519441.519441 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.519893.519893 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.519345.519345 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.519862.519862 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 60a2ce3a-c479-4c63-b168-a5340ee3e1f2
DEBUG 01-04 15:36:07.519714.519714 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.529998.529998 client.py:127] Model loaded
DEBUG 01-04 15:36:07.529838.529838 cuda_h.py:19] end wait_experts cost 0.015023946762084961 seconds
DEBUG 01-04 15:36:07.529669.529669 cuda_h.py:10] start gpu_experts
INFO 01-04 15:36:07.529754.529754 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 60a2ce3a-c479-4c63-b168-a5340ee3e1f2
DEBUG 01-04 15:36:07.529273.529273 lmp.py:384]   Computing 31 experts on GPU...
DEBUG 01-04 15:36:07.529871.529871 cuda_h.py:19] end load_into_gpu_async cost 0.010410785675048828 seconds
DEBUG 01-04 15:36:07.530926.530926 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.530121.530121 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-04 15:36:07.530831.530831 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015671253204345703 seconds
DEBUG 01-04 15:36:07.530482.530482 mlpmodule.py:531] gpu group tensors cost 0.0009658336639404297 s
INFO 01-04 15:36:07.531754.531754 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 60a2ce3a-c479-4c63-b168-a5340ee3e1f2
DEBUG 01-04 15:36:07.531813.531813 mlpmodule.py:662]  experts func einsum cost 0.050121307373046875 s
DEBUG 01-04 15:36:07.532044.532044 mlpmodule.py:564] gpu pad cost 0.0018184185028076172 s
DEBUG 01-04 15:36:07.533904.533904 mlpmodule.py:582] gpu group einsum cost 0.00046133995056152344 s
DEBUG 01-04 15:36:07.535133.535133 mlpmodule.py:611] gpu experts func einsum cost 0.0061893463134765625 s
DEBUG 01-04 15:36:07.535468.535468 cuda_h.py:19] end gpu_experts cost 0.006432056427001953 seconds
DEBUG 01-04 15:36:07.535078.535078 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:07.538473.538473 client.py:127] Model loaded
DEBUG 01-04 15:36:07.538278.538278 cuda_h.py:19] end sllm_worker_task cost 0.02371501922607422 seconds
DEBUG 01-04 15:36:07.538927.538927 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0023779869079589844 seconds
DEBUG 01-04 15:36:07.539444.539444 cuda_h.py:19] end layer_moe_generate_9 cost 0.06538581848144531 seconds
DEBUG 01-04 15:36:07.539053.539053 lmp.py:207] -------------------------------- end layer 9 --------------------------------
DEBUG 01-04 15:36:07.539246.539246 lmp.py:169] -------------------------------- start layer 10 --------------------------------
DEBUG 01-04 15:36:07.539227.539227 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.539746.539746 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.542562.542562 cuda_h.py:19] end self_attn cost 0.0023665428161621094 seconds
DEBUG 01-04 15:36:07.542274.542274 cuda_h.py:19] end iln_self_attn_paln cost 0.002954721450805664 seconds
DEBUG 01-04 15:36:07.542348.542348 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-04 15:36:07.542442.542442 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.543276.543276 cuda_h.py:19] end gate cost 0.0005476474761962891 seconds
DEBUG 01-04 15:36:07.543576.543576 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.543558.543558 lmp.py:281] 
DEBUG 01-04 15:36:07.543558.543558 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.543976.543976 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:07.543480.543480 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:07.543839.543839 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:07.543574.543574 lmp.py:285] 
DEBUG 01-04 15:36:07.543574.543574 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.543787.543787 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.543006.543006 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:07.543934.543934 lmp.py:292]   Expert 62 |      1 | CPU
DEBUG 01-04 15:36:07.543431.543431 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:07.543928.543928 lmp.py:292]   Expert 32 |      3 | CPU
DEBUG 01-04 15:36:07.543425.543425 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:07.543684.543684 lmp.py:292]   Expert 59 |      4 | CPU
DEBUG 01-04 15:36:07.543705.543705 lmp.py:292]   Expert 48 |      5 | CPU
DEBUG 01-04 15:36:07.543725.543725 lmp.py:292]   Expert 61 |      5 | CPU
DEBUG 01-04 15:36:07.543984.543984 lmp.py:292]   Expert 12 |      6 | CPU
DEBUG 01-04 15:36:07.543766.543766 lmp.py:292]   Expert 15 |      6 | CPU
DEBUG 01-04 15:36:07.543548.543548 lmp.py:292]   Expert 37 |     10 | CPU
DEBUG 01-04 15:36:07.543330.543330 lmp.py:292]   Expert 44 |     11 | CPU
DEBUG 01-04 15:36:07.543350.543350 lmp.py:292]   Expert 47 |     11 | CPU
DEBUG 01-04 15:36:07.543132.543132 lmp.py:292]   Expert 54 |     11 | CPU
DEBUG 01-04 15:36:07.543914.543914 lmp.py:292]   Expert 38 |     13 | CPU
DEBUG 01-04 15:36:07.543457.543457 lmp.py:292]   Expert 20 |     14 | CPU
DEBUG 01-04 15:36:07.543716.543716 lmp.py:292]   Expert 28 |     21 | CPU
DEBUG 01-04 15:36:07.543690.543690 lmp.py:292]   Expert 46 |     22 | CPU
DEBUG 01-04 15:36:07.543240.543240 lmp.py:292]   Expert 27 |     24 | CPU
DEBUG 01-04 15:36:07.543215.543215 lmp.py:292]   Expert 22 |     26 | CPU
DEBUG 01-04 15:36:07.543473.543473 lmp.py:292]   Expert 36 |     28 | CPU
DEBUG 01-04 15:36:07.543255.543255 lmp.py:292]   Expert 50 |     31 | CPU
DEBUG 01-04 15:36:07.543514.543514 lmp.py:292]   Expert  6 |     34 | CPU
DEBUG 01-04 15:36:07.543534.543534 lmp.py:292]   Expert 52 |     36 | CPU
DEBUG 01-04 15:36:07.543078.543078 lmp.py:292]   Expert 25 |     40 | CPU
DEBUG 01-04 15:36:07.543575.543575 lmp.py:292]   Expert 26 |     46 | CPU
DEBUG 01-04 15:36:07.543357.543357 lmp.py:292]   Expert 56 |     47 | CPU
DEBUG 01-04 15:36:07.543377.543377 lmp.py:292]   Expert 19 |     50 | CPU
DEBUG 01-04 15:36:07.543352.543352 lmp.py:292]   Expert  7 |     51 | CPU
DEBUG 01-04 15:36:07.543564.543564 lmp.py:292]   Expert 35 |     52 | CPU
DEBUG 01-04 15:36:07.543346.543346 lmp.py:292]   Expert 51 |     52 | CPU
DEBUG 01-04 15:36:07.543128.543128 lmp.py:292]   Expert 29 |     55 | GPU
DEBUG 01-04 15:36:07.543910.543910 lmp.py:292]   Expert  9 |     56 | GPU
DEBUG 01-04 15:36:07.544692.544692 lmp.py:292]   Expert 53 |     59 | GPU
DEBUG 01-04 15:36:07.544474.544474 lmp.py:292]   Expert 41 |     60 | GPU
DEBUG 01-04 15:36:07.544256.544256 lmp.py:292]   Expert 42 |     61 | GPU
DEBUG 01-04 15:36:07.544038.544038 lmp.py:292]   Expert 60 |     63 | GPU
DEBUG 01-04 15:36:07.544820.544820 lmp.py:292]   Expert 57 |     67 | GPU
DEBUG 01-04 15:36:07.544602.544602 lmp.py:292]   Expert 17 |     71 | GPU
DEBUG 01-04 15:36:07.544384.544384 lmp.py:292]   Expert 63 |     72 | GPU
DEBUG 01-04 15:36:07.544165.544165 lmp.py:292]   Expert  8 |     73 | GPU
DEBUG 01-04 15:36:07.544424.544424 lmp.py:292]   Expert 45 |     74 | GPU
DEBUG 01-04 15:36:07.544968.544968 lmp.py:292]   Expert 49 |     74 | GPU
DEBUG 01-04 15:36:07.544511.544511 lmp.py:292]   Expert 24 |     75 | GPU
DEBUG 01-04 15:36:07.544485.544485 lmp.py:292]   Expert 43 |     78 | GPU
DEBUG 01-04 15:36:07.544221.544221 lmp.py:292]   Expert 33 |     92 | GPU
DEBUG 01-04 15:36:07.544718.544718 lmp.py:292]   Expert 31 |     96 | GPU
DEBUG 01-04 15:36:07.544977.544977 lmp.py:292]   Expert 39 |    118 | GPU
DEBUG 01-04 15:36:07.544759.544759 lmp.py:292]   Expert 16 |    119 | GPU
DEBUG 01-04 15:36:07.544018.544018 lmp.py:292]   Expert 21 |    123 | GPU
DEBUG 01-04 15:36:07.544800.544800 lmp.py:292]   Expert 30 |    123 | GPU
DEBUG 01-04 15:36:07.544582.544582 lmp.py:292]   Expert 23 |    130 | GPU
DEBUG 01-04 15:36:07.544602.544602 lmp.py:292]   Expert 40 |    131 | GPU
DEBUG 01-04 15:36:07.544622.544622 lmp.py:292]   Expert 10 |    135 | GPU
DEBUG 01-04 15:36:07.544596.544596 lmp.py:292]   Expert 11 |    140 | GPU
DEBUG 01-04 15:36:07.544570.544570 lmp.py:292]   Expert 18 |    143 | GPU
DEBUG 01-04 15:36:07.544829.544829 lmp.py:292]   Expert 58 |    273 | GPU
DEBUG 01-04 15:36:07.544611.544611 lmp.py:292]   Expert  3 |   1420 | GPU
DEBUG 01-04 15:36:07.544215.544215 lmp.py:292]   Expert  2 |   1463 | GPU
DEBUG 01-04 15:36:07.544401.544401 lmp.py:292]   Expert  5 |   1466 | GPU
DEBUG 01-04 15:36:07.544898.544898 lmp.py:292]   Expert  4 |   1513 | GPU
DEBUG 01-04 15:36:07.544396.544396 lmp.py:292]   Expert  0 |   1565 | GPU
DEBUG 01-04 15:36:07.544893.544893 lmp.py:292]   Expert  1 |   1633 | GPU
DEBUG 01-04 15:36:07.544297.544297 lmp.py:293] 
DEBUG 01-04 15:36:07.544297.544297 lmp.py:293]   CPU total tokens: 667 (5.4%)
DEBUG 01-04 15:36:07.544748.544748 lmp.py:294]   GPU total tokens: 11621 (94.6%)
DEBUG 01-04 15:36:07.544729.544729 cuda_h.py:19] end experts_map_get cost 0.0013849735260009766 seconds
DEBUG 01-04 15:36:07.544657.544657 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.544102.544102 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.544848.544848 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.545533.545533 cuda_h.py:19] end allocate_cuda_memory cost 0.0002627372741699219 seconds
DEBUG 01-04 15:36:07.545615.545615 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.545179.545179 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.545034.545034 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.545492.545492 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4140ff85-3883-449f-9e5b-9ab71a55fbc8
DEBUG 01-04 15:36:07.545531.545531 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.546054.546054 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4140ff85-3883-449f-9e5b-9ab71a55fbc8
DEBUG 01-04 15:36:07.546360.546360 cuda_h.py:19] end load_into_gpu_async cost 0.0012557506561279297 seconds
DEBUG 01-04 15:36:07.546063.546063 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.546688.546688 cuda_h.py:19] end restore_tensors2 cost 0.00026035308837890625 seconds
DEBUG 01-04 15:36:07.546220.546220 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002102375030517578 seconds
DEBUG 01-04 15:36:07.549672.549672 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004584312438964844 seconds
DEBUG 01-04 15:36:07.549925.549925 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.549358.549358 lmp.py:339] 
DEBUG 01-04 15:36:07.549358.549358 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:07.549340.549340 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-04 15:36:07.549275.549275 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.560742.560742 mlpmodule.py:704] group tensors cost 0.011078357696533203 s
DEBUG 01-04 15:36:07.565535.565535 mlpmodule.py:742] pad cost 0.0030777454376220703 s
DEBUG 01-04 15:36:07.565461.565461 mlpmodule.py:748] create cpu tensor cost 6.365776062011719e-05 s
DEBUG 01-04 15:36:07.565974.565974 mlpmodule.py:753] move to cpu cost 4.601478576660156e-05 s
DEBUG 01-04 15:36:07.570464.570464 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:07.570719.570719 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.570490.570490 mlpmodule.py:774] group_w3 first element: -0.06689453125
WARNING 01-04 15:36:07.570963.570963 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.574524.574524 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.575209.575209 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.579218.579218 mlpmodule.py:797] group einsum cost 0.014171600341796875 s
DEBUG 01-04 15:36:07.579508.579508 mlpmodule.py:805] cpy2cputensor cost 0.0002899169921875 s
DEBUG 01-04 15:36:07.584601.584601 cuda_h.py:19] end wait_cetm_experts cost 0.03537726402282715 seconds
DEBUG 01-04 15:36:07.585290.585290 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.585152.585152 cuda_h.py:19] end gpu_sexperts cost 0.0005915164947509766 seconds
DEBUG 01-04 15:36:07.585995.585995 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-04 15:36:07.585195.585195 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-04 15:36:07.585450.585450 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 4.506111145019531e-05 seconds
DEBUG 01-04 15:36:07.585703.585703 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 8.893013000488281e-05 seconds
DEBUG 01-04 15:36:07.585783.585783 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.585923.585923 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4140ff85-3883-449f-9e5b-9ab71a55fbc8
DEBUG 01-04 15:36:07.586843.586843 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.586648.586648 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.586591.586591 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.590066.590066 cuda_h.py:19] end allocate_cuda_memory cost 0.0046539306640625 seconds
DEBUG 01-04 15:36:07.591184.591184 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.591531.591531 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.591791.591791 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.591070.591070 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94edbfd5-9917-412b-9437-ccb9b1db4eb9
DEBUG 01-04 15:36:07.591206.591206 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.596816.596816 client.py:127] Model loaded
DEBUG 01-04 15:36:07.596672.596672 cuda_h.py:19] end wait_experts cost 0.010701179504394531 seconds
DEBUG 01-04 15:36:07.596090.596090 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.596601.596601 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:07.597948.597948 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94edbfd5-9917-412b-9437-ccb9b1db4eb9
DEBUG 01-04 15:36:07.597580.597580 cuda_h.py:19] end load_into_gpu_async cost 0.006007194519042969 seconds
DEBUG 01-04 15:36:07.597905.597905 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.597511.597511 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-04 15:36:07.597505.597505 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011134862899780273 seconds
DEBUG 01-04 15:36:07.597143.597143 mlpmodule.py:531] gpu group tensors cost 0.0008852481842041016 s
INFO 01-04 15:36:07.597717.597717 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94edbfd5-9917-412b-9437-ccb9b1db4eb9
DEBUG 01-04 15:36:07.602270.602270 mlpmodule.py:662]  experts func einsum cost 0.053009986877441406 s
INFO 01-04 15:36:07.603540.603540 client.py:127] Model loaded
DEBUG 01-04 15:36:07.604179.604179 cuda_h.py:19] end sllm_worker_task cost 0.017829179763793945 seconds
DEBUG 01-04 15:36:07.604082.604082 mlpmodule.py:564] gpu pad cost 0.006539583206176758 s
DEBUG 01-04 15:36:07.605120.605120 mlpmodule.py:582] gpu group einsum cost 0.0006809234619140625 s
DEBUG 01-04 15:36:07.607290.607290 mlpmodule.py:611] gpu experts func einsum cost 0.011213541030883789 s
DEBUG 01-04 15:36:07.608373.608373 cuda_h.py:19] end gpu_experts cost 0.011381864547729492 seconds
DEBUG 01-04 15:36:07.608699.608699 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.608091.608091 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-04 15:36:07.611609.611609 cuda_h.py:19] end layer_moe_generate_10 cost 0.06887483596801758 seconds
DEBUG 01-04 15:36:07.611410.611410 lmp.py:207] -------------------------------- end layer 10 --------------------------------
DEBUG 01-04 15:36:07.611934.611934 lmp.py:169] -------------------------------- start layer 11 --------------------------------
DEBUG 01-04 15:36:07.611676.611676 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.611679.611679 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.614445.614445 cuda_h.py:19] end self_attn cost 0.00244140625 seconds
DEBUG 01-04 15:36:07.614957.614957 cuda_h.py:19] end iln_self_attn_paln cost 0.0030221939086914062 seconds
DEBUG 01-04 15:36:07.614847.614847 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-04 15:36:07.614894.614894 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.615258.615258 cuda_h.py:19] end gate cost 0.0005514621734619141 seconds
DEBUG 01-04 15:36:07.615796.615796 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.615163.615163 lmp.py:281] 
DEBUG 01-04 15:36:07.615163.615163 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.615773.615773 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:07.615800.615800 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:07.615159.615159 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:07.615371.615371 lmp.py:285] 
DEBUG 01-04 15:36:07.615371.615371 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.615822.615822 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.615472.615472 lmp.py:292]   Expert 35 |      1 | CPU
DEBUG 01-04 15:36:07.615161.615161 lmp.py:292]   Expert 16 |      2 | CPU
DEBUG 01-04 15:36:07.615658.615658 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:07.615679.615679 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:07.615699.615699 lmp.py:292]   Expert 27 |      4 | CPU
DEBUG 01-04 15:36:07.615481.615481 lmp.py:292]   Expert 19 |      5 | CPU
DEBUG 01-04 15:36:07.615501.615501 lmp.py:292]   Expert 10 |      6 | CPU
DEBUG 01-04 15:36:07.615760.615760 lmp.py:292]   Expert 17 |      7 | CPU
DEBUG 01-04 15:36:07.615780.615780 lmp.py:292]   Expert 23 |      7 | CPU
DEBUG 01-04 15:36:07.615324.615324 lmp.py:292]   Expert 63 |      8 | CPU
DEBUG 01-04 15:36:07.615344.615344 lmp.py:292]   Expert 59 |     10 | CPU
DEBUG 01-04 15:36:07.615126.615126 lmp.py:292]   Expert  8 |     12 | CPU
DEBUG 01-04 15:36:07.615147.615147 lmp.py:292]   Expert 41 |     12 | CPU
DEBUG 01-04 15:36:07.615359.615359 lmp.py:292]   Expert 49 |     15 | CPU
DEBUG 01-04 15:36:07.615618.615618 lmp.py:292]   Expert 25 |     17 | CPU
DEBUG 01-04 15:36:07.615830.615830 lmp.py:292]   Expert 52 |     17 | CPU
DEBUG 01-04 15:36:07.616328.616328 lmp.py:292]   Expert 60 |     17 | CPU
DEBUG 01-04 15:36:07.616348.616348 lmp.py:292]   Expert 40 |     22 | CPU
DEBUG 01-04 15:36:07.616891.616891 lmp.py:292]   Expert 50 |     23 | CPU
DEBUG 01-04 15:36:07.616673.616673 lmp.py:292]   Expert 36 |     25 | CPU
DEBUG 01-04 15:36:07.616217.616217 lmp.py:292]   Expert 62 |     26 | CPU
DEBUG 01-04 15:36:07.616476.616476 lmp.py:292]   Expert 51 |     27 | CPU
DEBUG 01-04 15:36:07.616019.616019 lmp.py:292]   Expert  6 |     28 | CPU
DEBUG 01-04 15:36:07.616040.616040 lmp.py:292]   Expert 48 |     31 | CPU
DEBUG 01-04 15:36:07.616060.616060 lmp.py:292]   Expert 44 |     33 | CPU
DEBUG 01-04 15:36:07.616604.616604 lmp.py:292]   Expert 26 |     34 | CPU
DEBUG 01-04 15:36:07.616385.616385 lmp.py:292]   Expert 56 |     34 | CPU
DEBUG 01-04 15:36:07.616167.616167 lmp.py:292]   Expert 46 |     39 | CPU
DEBUG 01-04 15:36:07.616188.616188 lmp.py:292]   Expert 20 |     40 | CPU
DEBUG 01-04 15:36:07.616731.616731 lmp.py:292]   Expert 38 |     44 | CPU
DEBUG 01-04 15:36:07.616513.616513 lmp.py:292]   Expert 57 |     49 | CPU
DEBUG 01-04 15:36:07.616295.616295 lmp.py:292]   Expert 32 |     51 | GPU
DEBUG 01-04 15:36:07.616077.616077 lmp.py:292]   Expert 42 |     52 | GPU
DEBUG 01-04 15:36:07.616621.616621 lmp.py:292]   Expert 31 |     59 | GPU
DEBUG 01-04 15:36:07.616164.616164 lmp.py:292]   Expert 18 |     62 | GPU
DEBUG 01-04 15:36:07.616423.616423 lmp.py:292]   Expert 43 |     70 | GPU
DEBUG 01-04 15:36:07.616682.616682 lmp.py:292]   Expert 13 |     75 | GPU
DEBUG 01-04 15:36:07.616941.616941 lmp.py:292]   Expert 29 |     75 | GPU
DEBUG 01-04 15:36:07.616961.616961 lmp.py:292]   Expert 61 |     77 | GPU
DEBUG 01-04 15:36:07.616458.616458 lmp.py:292]   Expert 58 |     82 | GPU
DEBUG 01-04 15:36:07.616002.616002 lmp.py:292]   Expert 12 |     84 | GPU
DEBUG 01-04 15:36:07.616784.616784 lmp.py:292]   Expert 33 |     84 | GPU
DEBUG 01-04 15:36:07.616864.616864 lmp.py:292]   Expert 24 |     91 | GPU
DEBUG 01-04 15:36:07.616335.616335 lmp.py:292]   Expert 55 |     93 | GPU
DEBUG 01-04 15:36:07.616832.616832 lmp.py:292]   Expert 14 |     97 | GPU
DEBUG 01-04 15:36:07.616330.616330 lmp.py:292]   Expert 47 |     98 | GPU
DEBUG 01-04 15:36:07.616827.616827 lmp.py:292]   Expert 37 |     99 | GPU
DEBUG 01-04 15:36:07.616324.616324 lmp.py:292]   Expert 11 |    101 | GPU
DEBUG 01-04 15:36:07.616821.616821 lmp.py:292]   Expert 53 |    103 | GPU
DEBUG 01-04 15:36:07.616080.616080 lmp.py:292]   Expert 34 |    112 | GPU
DEBUG 01-04 15:36:07.616816.616816 lmp.py:292]   Expert 45 |    123 | GPU
DEBUG 01-04 15:36:07.616551.616551 lmp.py:292]   Expert 21 |    144 | GPU
DEBUG 01-04 15:36:07.616287.616287 lmp.py:292]   Expert 54 |    154 | GPU
DEBUG 01-04 15:36:07.616499.616499 lmp.py:292]   Expert 22 |    200 | GPU
DEBUG 01-04 15:36:07.616950.616950 lmp.py:292]   Expert  9 |    215 | GPU
DEBUG 01-04 15:36:07.616640.616640 lmp.py:292]   Expert 30 |    277 | GPU
DEBUG 01-04 15:36:07.616475.616475 lmp.py:292]   Expert 28 |    321 | GPU
DEBUG 01-04 15:36:07.616687.616687 lmp.py:292]   Expert  4 |   1419 | GPU
DEBUG 01-04 15:36:07.616184.616184 lmp.py:292]   Expert  0 |   1421 | GPU
DEBUG 01-04 15:36:07.616682.616682 lmp.py:292]   Expert  3 |   1426 | GPU
DEBUG 01-04 15:36:07.616940.616940 lmp.py:292]   Expert  5 |   1435 | GPU
DEBUG 01-04 15:36:07.616438.616438 lmp.py:292]   Expert  1 |   1437 | GPU
DEBUG 01-04 15:36:07.616935.616935 lmp.py:292]   Expert  2 |   1550 | GPU
DEBUG 01-04 15:36:07.616386.616386 lmp.py:293] 
DEBUG 01-04 15:36:07.616386.616386 lmp.py:293]   CPU total tokens: 601 (4.9%)
DEBUG 01-04 15:36:07.616598.616598 lmp.py:294]   GPU total tokens: 11687 (95.1%)
DEBUG 01-04 15:36:07.616340.616340 cuda_h.py:19] end experts_map_get cost 0.0013933181762695312 seconds
DEBUG 01-04 15:36:07.616791.616791 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.616998.616998 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.616883.616883 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.617645.617645 cuda_h.py:19] end allocate_cuda_memory cost 0.00017881393432617188 seconds
DEBUG 01-04 15:36:07.617488.617488 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.617383.617383 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.617477.617477 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.617604.617604 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 543ce973-24ec-49d2-9ac4-1dc6e41de3d8
DEBUG 01-04 15:36:07.617391.617391 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.618933.618933 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 543ce973-24ec-49d2-9ac4-1dc6e41de3d8
DEBUG 01-04 15:36:07.618763.618763 cuda_h.py:19] end load_into_gpu_async cost 0.0014367103576660156 seconds
DEBUG 01-04 15:36:07.618889.618889 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.619554.619554 cuda_h.py:19] end restore_tensors2 cost 0.00025463104248046875 seconds
DEBUG 01-04 15:36:07.619708.619708 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021839141845703125 seconds
DEBUG 01-04 15:36:07.621302.621302 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004738807678222656 seconds
DEBUG 01-04 15:36:07.621178.621178 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.621326.621326 lmp.py:339] 
DEBUG 01-04 15:36:07.621326.621326 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:07.621738.621738 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-04 15:36:07.621673.621673 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.636654.636654 mlpmodule.py:704] group tensors cost 0.014209270477294922 s
DEBUG 01-04 15:36:07.638188.638188 mlpmodule.py:742] pad cost 0.0021126270294189453 s
DEBUG 01-04 15:36:07.639457.639457 mlpmodule.py:748] create cpu tensor cost 5.2928924560546875e-05 s
DEBUG 01-04 15:36:07.639135.639135 mlpmodule.py:753] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-04 15:36:07.643487.643487 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:07.643535.643535 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.644293.644293 mlpmodule.py:774] group_w3 first element: 0.049072265625
WARNING 01-04 15:36:07.644044.644044 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.648870.648870 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.648005.648005 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.652764.652764 mlpmodule.py:797] group einsum cost 0.013794422149658203 s
DEBUG 01-04 15:36:07.653733.653733 mlpmodule.py:805] cpy2cputensor cost 0.00018715858459472656 s
DEBUG 01-04 15:36:07.658214.658214 cuda_h.py:19] end wait_cetm_experts cost 0.03644561767578125 seconds
DEBUG 01-04 15:36:07.658155.658155 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.659946.659946 cuda_h.py:19] end gpu_sexperts cost 0.0006377696990966797 seconds
DEBUG 01-04 15:36:07.659518.659518 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-04 15:36:07.659838.659838 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-04 15:36:07.659052.659052 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 4.553794860839844e-05 seconds
DEBUG 01-04 15:36:07.659724.659724 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.659587.659587 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 0.00019598007202148438 seconds
DEBUG 01-04 15:36:07.659531.659531 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.659659.659659 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.659857.659857 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 543ce973-24ec-49d2-9ac4-1dc6e41de3d8
DEBUG 01-04 15:36:07.659854.659854 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.665799.665799 cuda_h.py:19] end allocate_cuda_memory cost 0.004977703094482422 seconds
DEBUG 01-04 15:36:07.665922.665922 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.665414.665414 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.665078.665078 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.665219.665219 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 21bb8037-b281-492f-8a72-775e1cc0c282
DEBUG 01-04 15:36:07.665070.665070 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.671319.671319 client.py:127] Model loaded
DEBUG 01-04 15:36:07.671076.671076 cuda_h.py:19] end wait_experts cost 0.011299371719360352 seconds
DEBUG 01-04 15:36:07.671117.671117 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.671535.671535 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:07.671003.671003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 21bb8037-b281-492f-8a72-775e1cc0c282
DEBUG 01-04 15:36:07.671164.671164 cuda_h.py:19] end load_into_gpu_async cost 0.006592988967895508 seconds
DEBUG 01-04 15:36:07.671113.671113 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.671864.671864 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:07.672574.672574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012221574783325195 seconds
DEBUG 01-04 15:36:07.672973.672973 mlpmodule.py:531] gpu group tensors cost 0.0009436607360839844 s
INFO 01-04 15:36:07.672332.672332 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 21bb8037-b281-492f-8a72-775e1cc0c282
DEBUG 01-04 15:36:07.674756.674756 mlpmodule.py:564] gpu pad cost 0.00173187255859375 s
DEBUG 01-04 15:36:07.674470.674470 mlpmodule.py:582] gpu group einsum cost 0.0004899501800537109 s
DEBUG 01-04 15:36:07.676102.676102 mlpmodule.py:662]  experts func einsum cost 0.05491471290588379 s
DEBUG 01-04 15:36:07.677362.677362 mlpmodule.py:611] gpu experts func einsum cost 0.00642085075378418 s
DEBUG 01-04 15:36:07.677837.677837 cuda_h.py:19] end gpu_experts cost 0.006645917892456055 seconds
DEBUG 01-04 15:36:07.677355.677355 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:07.682266.682266 client.py:127] Model loaded
DEBUG 01-04 15:36:07.682016.682016 cuda_h.py:19] end sllm_worker_task cost 0.022805213928222656 seconds
DEBUG 01-04 15:36:07.682449.682449 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004569530487060547 seconds
DEBUG 01-04 15:36:07.682030.682030 cuda_h.py:19] end layer_moe_generate_11 cost 0.06794071197509766 seconds
DEBUG 01-04 15:36:07.682877.682877 lmp.py:207] -------------------------------- end layer 11 --------------------------------
DEBUG 01-04 15:36:07.682686.682686 lmp.py:169] -------------------------------- start layer 12 --------------------------------
DEBUG 01-04 15:36:07.682713.682713 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.683517.683517 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.685577.685577 cuda_h.py:19] end self_attn cost 0.002344369888305664 seconds
DEBUG 01-04 15:36:07.685719.685719 cuda_h.py:19] end iln_self_attn_paln cost 0.0029256343841552734 seconds
DEBUG 01-04 15:36:07.685271.685271 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-04 15:36:07.685603.685603 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.686583.686583 cuda_h.py:19] end gate cost 0.00054931640625 seconds
DEBUG 01-04 15:36:07.686074.686074 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.686110.686110 lmp.py:281] 
DEBUG 01-04 15:36:07.686110.686110 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.686243.686243 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:07.686224.686224 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:07.686867.686867 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:07.686080.686080 lmp.py:285] 
DEBUG 01-04 15:36:07.686080.686080 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.686769.686769 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.686273.686273 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:07.686009.686009 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:07.686744.686744 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:07.687957.687957 lmp.py:292]   Expert 11 |      2 | CPU
DEBUG 01-04 15:36:07.687169.687169 lmp.py:292]   Expert 41 |      2 | CPU
DEBUG 01-04 15:36:07.687382.687382 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:07.687117.687117 lmp.py:292]   Expert 37 |      3 | CPU
DEBUG 01-04 15:36:07.687330.687330 lmp.py:292]   Expert 63 |      3 | CPU
DEBUG 01-04 15:36:07.687065.687065 lmp.py:292]   Expert 16 |      4 | CPU
DEBUG 01-04 15:36:07.687086.687086 lmp.py:292]   Expert 47 |      5 | CPU
DEBUG 01-04 15:36:07.687868.687868 lmp.py:292]   Expert 61 |      5 | CPU
DEBUG 01-04 15:36:07.687365.687365 lmp.py:292]   Expert 27 |     12 | CPU
DEBUG 01-04 15:36:07.687147.687147 lmp.py:292]   Expert 49 |     13 | CPU
DEBUG 01-04 15:36:07.687929.687929 lmp.py:292]   Expert 12 |     14 | CPU
DEBUG 01-04 15:36:07.687711.687711 lmp.py:292]   Expert 62 |     16 | CPU
DEBUG 01-04 15:36:07.687493.687493 lmp.py:292]   Expert 23 |     17 | CPU
DEBUG 01-04 15:36:07.687275.687275 lmp.py:292]   Expert 32 |     18 | CPU
DEBUG 01-04 15:36:07.687057.687057 lmp.py:292]   Expert  7 |     21 | CPU
DEBUG 01-04 15:36:07.687607.687607 lmp.py:292]   Expert 14 |     25 | CPU
DEBUG 01-04 15:36:07.687343.687343 lmp.py:292]   Expert 30 |     26 | CPU
DEBUG 01-04 15:36:07.687317.687317 lmp.py:292]   Expert 42 |     26 | CPU
DEBUG 01-04 15:36:07.687814.687814 lmp.py:292]   Expert 21 |     28 | CPU
DEBUG 01-04 15:36:07.687073.687073 lmp.py:292]   Expert 38 |     28 | CPU
DEBUG 01-04 15:36:07.687854.687854 lmp.py:292]   Expert 55 |     29 | CPU
DEBUG 01-04 15:36:07.687875.687875 lmp.py:292]   Expert 52 |     30 | CPU
DEBUG 01-04 15:36:07.687895.687895 lmp.py:292]   Expert 39 |     32 | CPU
DEBUG 01-04 15:36:07.687677.687677 lmp.py:292]   Expert  8 |     42 | CPU
DEBUG 01-04 15:36:07.687221.687221 lmp.py:292]   Expert 43 |     44 | CPU
DEBUG 01-04 15:36:07.687480.687480 lmp.py:292]   Expert 13 |     46 | CPU
DEBUG 01-04 15:36:07.687261.687261 lmp.py:292]   Expert 53 |     48 | CPU
DEBUG 01-04 15:36:07.687043.687043 lmp.py:292]   Expert 18 |     49 | CPU
DEBUG 01-04 15:36:07.687825.687825 lmp.py:292]   Expert 31 |     53 | GPU
DEBUG 01-04 15:36:07.687846.687846 lmp.py:292]   Expert 20 |     61 | GPU
DEBUG 01-04 15:36:07.687581.687581 lmp.py:292]   Expert  6 |     62 | GPU
DEBUG 01-04 15:36:07.687555.687555 lmp.py:292]   Expert 35 |     62 | GPU
DEBUG 01-04 15:36:07.687291.687291 lmp.py:292]   Expert 58 |     66 | GPU
DEBUG 01-04 15:36:07.687265.687265 lmp.py:292]   Expert 46 |     68 | GPU
DEBUG 01-04 15:36:07.687285.687285 lmp.py:292]   Expert 17 |     74 | GPU
DEBUG 01-04 15:36:07.687306.687306 lmp.py:292]   Expert 45 |     74 | GPU
DEBUG 01-04 15:36:07.687088.687088 lmp.py:292]   Expert 54 |     75 | GPU
DEBUG 01-04 15:36:07.687108.687108 lmp.py:292]   Expert 50 |     78 | GPU
DEBUG 01-04 15:36:07.687890.687890 lmp.py:292]   Expert 36 |     89 | GPU
DEBUG 01-04 15:36:07.687910.687910 lmp.py:292]   Expert 25 |     90 | GPU
DEBUG 01-04 15:36:07.687692.687692 lmp.py:292]   Expert 57 |     92 | GPU
DEBUG 01-04 15:36:07.687474.687474 lmp.py:292]   Expert 19 |     97 | GPU
DEBUG 01-04 15:36:07.687495.687495 lmp.py:292]   Expert 33 |     97 | GPU
DEBUG 01-04 15:36:07.687515.687515 lmp.py:292]   Expert 59 |     99 | GPU
DEBUG 01-04 15:36:07.687059.687059 lmp.py:292]   Expert 28 |    102 | GPU
DEBUG 01-04 15:36:07.687556.687556 lmp.py:292]   Expert 24 |    103 | GPU
DEBUG 01-04 15:36:07.687291.687291 lmp.py:292]   Expert 26 |    109 | GPU
DEBUG 01-04 15:36:07.687504.687504 lmp.py:292]   Expert 60 |    112 | GPU
DEBUG 01-04 15:36:07.687240.687240 lmp.py:292]   Expert 48 |    142 | GPU
DEBUG 01-04 15:36:07.687452.687452 lmp.py:292]   Expert 40 |    151 | GPU
DEBUG 01-04 15:36:07.687711.687711 lmp.py:292]   Expert 15 |    167 | GPU
DEBUG 01-04 15:36:07.687731.687731 lmp.py:292]   Expert  9 |    175 | GPU
DEBUG 01-04 15:36:07.687752.687752 lmp.py:292]   Expert 10 |    294 | GPU
DEBUG 01-04 15:36:07.687534.687534 lmp.py:292]   Expert 56 |    326 | GPU
DEBUG 01-04 15:36:07.687792.687792 lmp.py:292]   Expert  0 |   1438 | GPU
DEBUG 01-04 15:36:07.687813.687813 lmp.py:292]   Expert  4 |   1438 | GPU
DEBUG 01-04 15:36:07.687595.687595 lmp.py:292]   Expert  5 |   1439 | GPU
DEBUG 01-04 15:36:07.687853.687853 lmp.py:292]   Expert  2 |   1443 | GPU
DEBUG 01-04 15:36:07.687874.687874 lmp.py:292]   Expert  1 |   1492 | GPU
DEBUG 01-04 15:36:07.687656.687656 lmp.py:292]   Expert  3 |   1527 | GPU
DEBUG 01-04 15:36:07.687391.687391 lmp.py:293] 
DEBUG 01-04 15:36:07.687391.687391 lmp.py:293]   CPU total tokens: 593 (4.8%)
DEBUG 01-04 15:36:07.687889.687889 lmp.py:294]   GPU total tokens: 11695 (95.2%)
DEBUG 01-04 15:36:07.687154.687154 cuda_h.py:19] end experts_map_get cost 0.0013663768768310547 seconds
DEBUG 01-04 15:36:07.687367.687367 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.688236.688236 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.688505.688505 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.688892.688892 cuda_h.py:19] end allocate_cuda_memory cost 0.00025343894958496094 seconds
DEBUG 01-04 15:36:07.688828.688828 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.688246.688246 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.688724.688724 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.688466.688466 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff2a5c4a-3ba0-49a4-83d9-0f9f7225f51b
DEBUG 01-04 15:36:07.688577.688577 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.689482.689482 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff2a5c4a-3ba0-49a4-83d9-0f9f7225f51b
DEBUG 01-04 15:36:07.689143.689143 cuda_h.py:19] end load_into_gpu_async cost 0.0014498233795166016 seconds
DEBUG 01-04 15:36:07.690867.690867 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.690920.690920 cuda_h.py:19] end restore_tensors2 cost 0.000713348388671875 seconds
DEBUG 01-04 15:36:07.690735.690735 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002838611602783203 seconds
DEBUG 01-04 15:36:07.693023.693023 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053348541259765625 seconds
DEBUG 01-04 15:36:07.693144.693144 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.693200.693200 lmp.py:339] 
DEBUG 01-04 15:36:07.693200.693200 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:07.693897.693897 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-04 15:36:07.693785.693785 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.709975.709975 mlpmodule.py:704] group tensors cost 0.016080141067504883 s
DEBUG 01-04 15:36:07.713184.713184 mlpmodule.py:742] pad cost 0.0025925636291503906 s
DEBUG 01-04 15:36:07.713097.713097 mlpmodule.py:748] create cpu tensor cost 6.29425048828125e-05 s
DEBUG 01-04 15:36:07.713133.713133 mlpmodule.py:753] move to cpu cost 4.6253204345703125e-05 s
DEBUG 01-04 15:36:07.717213.717213 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:07.717732.717732 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.717848.717848 mlpmodule.py:774] group_w3 first element: -0.0150146484375
WARNING 01-04 15:36:07.718261.718261 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.721122.721122 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.722390.722390 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.725890.725890 mlpmodule.py:797] group einsum cost 0.012478113174438477 s
DEBUG 01-04 15:36:07.726489.726489 mlpmodule.py:805] cpy2cputensor cost 0.0002014636993408203 s
DEBUG 01-04 15:36:07.731758.731758 cuda_h.py:19] end wait_cetm_experts cost 0.03767800331115723 seconds
DEBUG 01-04 15:36:07.731831.731831 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.732848.732848 cuda_h.py:19] end gpu_sexperts cost 0.0006458759307861328 seconds
DEBUG 01-04 15:36:07.732804.732804 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-04 15:36:07.732409.732409 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-04 15:36:07.732633.732633 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.602836608886719e-05 seconds
DEBUG 01-04 15:36:07.732502.732502 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00010895729064941406 seconds
DEBUG 01-04 15:36:07.732212.732212 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.732458.732458 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff2a5c4a-3ba0-49a4-83d9-0f9f7225f51b
DEBUG 01-04 15:36:07.732997.732997 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.732357.732357 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.733227.733227 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.739624.739624 cuda_h.py:19] end allocate_cuda_memory cost 0.0068399906158447266 seconds
INFO 01-04 15:36:07.740694.740694 client.py:127] Model loaded
DEBUG 01-04 15:36:07.740783.740783 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.740077.740077 cuda_h.py:19] end wait_experts cost 0.007619142532348633 seconds
DEBUG 01-04 15:36:07.740569.740569 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.740121.740121 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.740673.740673 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.740426.740426 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df0214a7-d00f-4ceb-8944-3859709d1c51
DEBUG 01-04 15:36:07.740808.740808 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.740431.740431 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:07.741648.741648 mlpmodule.py:531] gpu group tensors cost 0.0006375312805175781 s
DEBUG 01-04 15:36:07.743998.743998 mlpmodule.py:564] gpu pad cost 0.0016658306121826172 s
DEBUG 01-04 15:36:07.743002.743002 mlpmodule.py:582] gpu group einsum cost 0.00045752525329589844 s
DEBUG 01-04 15:36:07.746832.746832 mlpmodule.py:611] gpu experts func einsum cost 0.005727052688598633 s
DEBUG 01-04 15:36:07.746709.746709 cuda_h.py:19] end gpu_experts cost 0.006150960922241211 seconds
DEBUG 01-04 15:36:07.746081.746081 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.755537.755537 mlpmodule.py:662]  experts func einsum cost 0.061762094497680664 s
INFO 01-04 15:36:07.756829.756829 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df0214a7-d00f-4ceb-8944-3859709d1c51
DEBUG 01-04 15:36:07.757133.757133 cuda_h.py:19] end load_into_gpu_async cost 0.016832590103149414 seconds
DEBUG 01-04 15:36:07.757255.757255 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.757468.757468 cuda_h.py:19] end restore_tensors2 cost 0.00014543533325195312 seconds
DEBUG 01-04 15:36:07.757021.757021 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.024519681930541992 seconds
INFO 01-04 15:36:07.758241.758241 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df0214a7-d00f-4ceb-8944-3859709d1c51
INFO 01-04 15:36:07.764609.764609 client.py:127] Model loaded
DEBUG 01-04 15:36:07.765965.765965 cuda_h.py:19] end sllm_worker_task cost 0.03200674057006836 seconds
DEBUG 01-04 15:36:07.765312.765312 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.018496990203857422 seconds
DEBUG 01-04 15:36:07.765822.765822 cuda_h.py:19] end layer_moe_generate_12 cost 0.07970952987670898 seconds
DEBUG 01-04 15:36:07.766074.766074 lmp.py:207] -------------------------------- end layer 12 --------------------------------
DEBUG 01-04 15:36:07.766601.766601 lmp.py:169] -------------------------------- start layer 13 --------------------------------
DEBUG 01-04 15:36:07.766265.766265 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.766957.766957 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.772474.772474 cuda_h.py:19] end self_attn cost 0.0056171417236328125 seconds
DEBUG 01-04 15:36:07.773870.773870 cuda_h.py:19] end iln_self_attn_paln cost 0.007100820541381836 seconds
DEBUG 01-04 15:36:07.773842.773842 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-04 15:36:07.773846.773846 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.775186.775186 cuda_h.py:19] end gate cost 0.001344919204711914 seconds
DEBUG 01-04 15:36:07.775832.775832 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.776343.776343 lmp.py:281] 
DEBUG 01-04 15:36:07.776343.776343 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.776082.776082 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:07.776892.776892 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:07.776026.776026 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:07.776293.776293 lmp.py:285] 
DEBUG 01-04 15:36:07.776293.776293 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.776680.776680 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.776881.776881 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:07.776863.776863 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:07.776984.776984 lmp.py:292]   Expert 26 |      1 | CPU
DEBUG 01-04 15:36:07.776390.776390 lmp.py:292]   Expert 31 |      1 | CPU
DEBUG 01-04 15:36:07.776465.776465 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:07.776301.776301 lmp.py:292]   Expert 18 |      3 | CPU
DEBUG 01-04 15:36:07.776707.776707 lmp.py:292]   Expert 50 |      4 | CPU
DEBUG 01-04 15:36:07.776112.776112 lmp.py:292]   Expert 16 |      7 | CPU
DEBUG 01-04 15:36:07.776902.776902 lmp.py:292]   Expert 42 |      7 | CPU
DEBUG 01-04 15:36:07.777070.777070 lmp.py:292]   Expert 48 |      7 | CPU
DEBUG 01-04 15:36:07.777833.777833 lmp.py:292]   Expert 28 |      8 | CPU
DEBUG 01-04 15:36:07.777482.777482 lmp.py:292]   Expert 53 |      8 | CPU
DEBUG 01-04 15:36:07.777894.777894 lmp.py:292]   Expert 60 |      8 | CPU
DEBUG 01-04 15:36:07.777305.777305 lmp.py:292]   Expert 19 |     12 | CPU
DEBUG 01-04 15:36:07.777239.777239 lmp.py:292]   Expert 34 |     12 | CPU
DEBUG 01-04 15:36:07.777651.777651 lmp.py:292]   Expert 40 |     13 | CPU
DEBUG 01-04 15:36:07.777585.777585 lmp.py:292]   Expert 35 |     14 | CPU
DEBUG 01-04 15:36:07.777281.777281 lmp.py:292]   Expert 20 |     17 | CPU
DEBUG 01-04 15:36:07.777454.777454 lmp.py:292]   Expert 11 |     19 | CPU
DEBUG 01-04 15:36:07.777627.777627 lmp.py:292]   Expert  8 |     20 | CPU
DEBUG 01-04 15:36:07.777562.777562 lmp.py:292]   Expert 56 |     20 | CPU
DEBUG 01-04 15:36:07.777165.777165 lmp.py:292]   Expert 58 |     20 | CPU
DEBUG 01-04 15:36:07.777530.777530 lmp.py:292]   Expert 61 |     20 | CPU
DEBUG 01-04 15:36:07.777942.777942 lmp.py:292]   Expert 51 |     22 | CPU
DEBUG 01-04 15:36:07.777353.777353 lmp.py:292]   Expert 24 |     23 | CPU
DEBUG 01-04 15:36:07.777287.777287 lmp.py:292]   Expert 25 |     23 | CPU
DEBUG 01-04 15:36:07.777222.777222 lmp.py:292]   Expert 63 |     23 | CPU
DEBUG 01-04 15:36:07.777395.777395 lmp.py:292]   Expert 62 |     24 | CPU
DEBUG 01-04 15:36:07.777568.777568 lmp.py:292]   Expert 37 |     26 | CPU
DEBUG 01-04 15:36:07.777741.777741 lmp.py:292]   Expert 52 |     28 | CPU
DEBUG 01-04 15:36:07.777437.777437 lmp.py:292]   Expert 55 |     28 | CPU
DEBUG 01-04 15:36:07.777848.777848 lmp.py:292]   Expert 45 |     31 | GPU
DEBUG 01-04 15:36:07.777021.777021 lmp.py:292]   Expert 17 |     35 | GPU
DEBUG 01-04 15:36:07.777956.777956 lmp.py:292]   Expert 39 |     36 | GPU
DEBUG 01-04 15:36:07.777082.777082 lmp.py:292]   Expert 15 |     41 | GPU
DEBUG 01-04 15:36:07.777970.777970 lmp.py:292]   Expert 27 |     43 | GPU
DEBUG 01-04 15:36:07.777574.777574 lmp.py:292]   Expert 33 |     43 | GPU
DEBUG 01-04 15:36:07.777508.777508 lmp.py:292]   Expert 32 |     44 | GPU
DEBUG 01-04 15:36:07.777920.777920 lmp.py:292]   Expert 44 |     46 | GPU
DEBUG 01-04 15:36:07.777854.777854 lmp.py:292]   Expert 36 |     52 | GPU
DEBUG 01-04 15:36:07.777266.777266 lmp.py:292]   Expert 43 |     52 | GPU
DEBUG 01-04 15:36:07.777962.777962 lmp.py:292]   Expert 13 |     55 | GPU
DEBUG 01-04 15:36:07.777135.777135 lmp.py:292]   Expert  9 |     57 | GPU
DEBUG 01-04 15:36:07.777546.777546 lmp.py:292]   Expert 54 |     57 | GPU
DEBUG 01-04 15:36:07.777818.777818 lmp.py:292]   Expert 10 |     60 | GPU
DEBUG 01-04 15:36:07.777422.777422 lmp.py:292]   Expert 22 |     61 | GPU
DEBUG 01-04 15:36:07.777025.777025 lmp.py:292]   Expert 23 |     61 | GPU
DEBUG 01-04 15:36:07.777390.777390 lmp.py:292]   Expert  7 |     67 | GPU
DEBUG 01-04 15:36:07.777040.777040 lmp.py:292]   Expert 29 |     68 | GPU
DEBUG 01-04 15:36:07.777451.777451 lmp.py:292]   Expert 59 |     70 | GPU
DEBUG 01-04 15:36:07.777863.777863 lmp.py:292]   Expert 46 |     81 | GPU
DEBUG 01-04 15:36:07.777797.777797 lmp.py:292]   Expert 49 |     85 | GPU
DEBUG 01-04 15:36:07.777732.777732 lmp.py:292]   Expert 47 |     93 | GPU
DEBUG 01-04 15:36:07.778905.778905 lmp.py:292]   Expert 21 |     96 | GPU
DEBUG 01-04 15:36:07.778508.778508 lmp.py:292]   Expert 14 |    107 | GPU
DEBUG 01-04 15:36:07.778635.778635 lmp.py:292]   Expert 38 |    131 | GPU
DEBUG 01-04 15:36:07.778000.778000 lmp.py:292]   Expert 41 |    135 | GPU
DEBUG 01-04 15:36:07.778365.778365 lmp.py:292]   Expert  2 |   1669 | GPU
DEBUG 01-04 15:36:07.778776.778776 lmp.py:292]   Expert  0 |   1679 | GPU
DEBUG 01-04 15:36:07.778187.778187 lmp.py:292]   Expert  1 |   1687 | GPU
DEBUG 01-04 15:36:07.778360.778360 lmp.py:292]   Expert  3 |   1687 | GPU
DEBUG 01-04 15:36:07.778533.778533 lmp.py:292]   Expert  5 |   1709 | GPU
DEBUG 01-04 15:36:07.778229.778229 lmp.py:292]   Expert  4 |   1729 | GPU
DEBUG 01-04 15:36:07.778594.778594 lmp.py:293] 
DEBUG 01-04 15:36:07.778594.778594 lmp.py:293]   CPU total tokens: 421 (3.4%)
DEBUG 01-04 15:36:07.778628.778628 lmp.py:294]   GPU total tokens: 11867 (96.6%)
DEBUG 01-04 15:36:07.778669.778669 cuda_h.py:19] end experts_map_get cost 0.0029611587524414062 seconds
DEBUG 01-04 15:36:07.778465.778465 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.778122.778122 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.778624.778624 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.778880.778880 cuda_h.py:19] end allocate_cuda_memory cost 0.0002872943878173828 seconds
DEBUG 01-04 15:36:07.778982.778982 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.778652.778652 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.779250.779250 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.779675.779675 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c56ba390-b618-4431-9f05-47950cd0a8e0
DEBUG 01-04 15:36:07.779682.779682 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.780832.780832 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c56ba390-b618-4431-9f05-47950cd0a8e0
DEBUG 01-04 15:36:07.780112.780112 cuda_h.py:19] end load_into_gpu_async cost 0.0016703605651855469 seconds
DEBUG 01-04 15:36:07.780491.780491 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.781829.781829 cuda_h.py:19] end restore_tensors2 cost 0.0003554821014404297 seconds
DEBUG 01-04 15:36:07.781095.781095 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002724170684814453 seconds
DEBUG 01-04 15:36:07.784990.784990 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0063517093658447266 seconds
DEBUG 01-04 15:36:07.784363.784363 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.784360.784360 lmp.py:339] 
DEBUG 01-04 15:36:07.784360.784360 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:07.784230.784230 cuda_h.py:19] end cpu_experts_submit cost 0.0001442432403564453 seconds
DEBUG 01-04 15:36:07.785860.785860 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.795133.795133 mlpmodule.py:704] group tensors cost 0.010619878768920898 s
DEBUG 01-04 15:36:07.799857.799857 mlpmodule.py:742] pad cost 0.0025734901428222656 s
DEBUG 01-04 15:36:07.799206.799206 mlpmodule.py:748] create cpu tensor cost 6.127357482910156e-05 s
DEBUG 01-04 15:36:07.799766.799766 mlpmodule.py:753] move to cpu cost 4.6253204345703125e-05 s
DEBUG 01-04 15:36:07.804727.804727 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:07.804161.804161 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.804700.804700 mlpmodule.py:774] group_w3 first element: 0.07275390625
WARNING 01-04 15:36:07.804320.804320 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.808801.808801 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.808742.808742 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.812696.812696 mlpmodule.py:797] group einsum cost 0.013308048248291016 s
DEBUG 01-04 15:36:07.813929.813929 mlpmodule.py:805] cpy2cputensor cost 0.00014138221740722656 s
DEBUG 01-04 15:36:07.818963.818963 cuda_h.py:19] end wait_cetm_experts cost 0.033026695251464844 seconds
DEBUG 01-04 15:36:07.818559.818559 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.818129.818129 cuda_h.py:19] end gpu_sexperts cost 0.0005879402160644531 seconds
DEBUG 01-04 15:36:07.819456.819456 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-04 15:36:07.819193.819193 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-04 15:36:07.819248.819248 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.814697265625e-05 seconds
DEBUG 01-04 15:36:07.819012.819012 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.819108.819108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00018334388732910156 seconds
DEBUG 01-04 15:36:07.819197.819197 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.819093.819093 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.819039.819039 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c56ba390-b618-4431-9f05-47950cd0a8e0
DEBUG 01-04 15:36:07.819130.819130 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.826948.826948 cuda_h.py:19] end allocate_cuda_memory cost 0.006746768951416016 seconds
DEBUG 01-04 15:36:07.826679.826679 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.826018.826018 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.826324.826324 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.826511.826511 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 03fc079b-03dc-4f6b-8cf9-55c868e5e673
DEBUG 01-04 15:36:07.826839.826839 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.834753.834753 client.py:127] Model loaded
DEBUG 01-04 15:36:07.834937.834937 cuda_h.py:19] end wait_experts cost 0.01494145393371582 seconds
DEBUG 01-04 15:36:07.834437.834437 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.834215.834215 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:07.835872.835872 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 03fc079b-03dc-4f6b-8cf9-55c868e5e673
DEBUG 01-04 15:36:07.835371.835371 cuda_h.py:19] end load_into_gpu_async cost 0.008966922760009766 seconds
DEBUG 01-04 15:36:07.835988.835988 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.835151.835151 cuda_h.py:19] end restore_tensors2 cost 8.535385131835938e-05 seconds
DEBUG 01-04 15:36:07.835960.835960 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.016341686248779297 seconds
DEBUG 01-04 15:36:07.836796.836796 mlpmodule.py:531] gpu group tensors cost 0.0011904239654541016 s
INFO 01-04 15:36:07.836749.836749 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 03fc079b-03dc-4f6b-8cf9-55c868e5e673
DEBUG 01-04 15:36:07.842286.842286 mlpmodule.py:662]  experts func einsum cost 0.05678677558898926 s
INFO 01-04 15:36:07.842120.842120 client.py:127] Model loaded
DEBUG 01-04 15:36:07.842833.842833 cuda_h.py:19] end sllm_worker_task cost 0.023157596588134766 seconds
DEBUG 01-04 15:36:07.843039.843039 mlpmodule.py:564] gpu pad cost 0.007686138153076172 s
DEBUG 01-04 15:36:07.844973.844973 mlpmodule.py:582] gpu group einsum cost 0.0007088184356689453 s
DEBUG 01-04 15:36:07.847758.847758 mlpmodule.py:611] gpu experts func einsum cost 0.013102293014526367 s
DEBUG 01-04 15:36:07.848165.848165 cuda_h.py:19] end gpu_experts cost 0.013356208801269531 seconds
DEBUG 01-04 15:36:07.848490.848490 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.848266.848266 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-04 15:36:07.851099.851099 cuda_h.py:19] end layer_moe_generate_13 cost 0.07780623435974121 seconds
DEBUG 01-04 15:36:07.851099.851099 lmp.py:207] -------------------------------- end layer 13 --------------------------------
DEBUG 01-04 15:36:07.851583.851583 lmp.py:169] -------------------------------- start layer 14 --------------------------------
DEBUG 01-04 15:36:07.851279.851279 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.852011.852011 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.854837.854837 cuda_h.py:19] end self_attn cost 0.0024492740631103516 seconds
DEBUG 01-04 15:36:07.854039.854039 cuda_h.py:19] end iln_self_attn_paln cost 0.0030565261840820312 seconds
DEBUG 01-04 15:36:07.854974.854974 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-04 15:36:07.854691.854691 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.855241.855241 cuda_h.py:19] end gate cost 0.0005810260772705078 seconds
DEBUG 01-04 15:36:07.855594.855594 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.855763.855763 lmp.py:281] 
DEBUG 01-04 15:36:07.855763.855763 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.855757.855757 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:07.855930.855930 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:07.855865.855865 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:07.855223.855223 lmp.py:285] 
DEBUG 01-04 15:36:07.855223.855223 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.855819.855819 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.856423.856423 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:07.856496.856496 lmp.py:292]   Expert 15 |      2 | CPU
DEBUG 01-04 15:36:07.856901.856901 lmp.py:292]   Expert 38 |      2 | CPU
DEBUG 01-04 15:36:07.856590.856590 lmp.py:292]   Expert 40 |      2 | CPU
DEBUG 01-04 15:36:07.856041.856041 lmp.py:292]   Expert 48 |      2 | CPU
DEBUG 01-04 15:36:07.856730.856730 lmp.py:292]   Expert 55 |      2 | CPU
DEBUG 01-04 15:36:07.856420.856420 lmp.py:292]   Expert 61 |      2 | CPU
DEBUG 01-04 15:36:07.856871.856871 lmp.py:292]   Expert 23 |      3 | CPU
DEBUG 01-04 15:36:07.856083.856083 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:07.856534.856534 lmp.py:292]   Expert 50 |      3 | CPU
DEBUG 01-04 15:36:07.856223.856223 lmp.py:292]   Expert 62 |      4 | CPU
DEBUG 01-04 15:36:07.856913.856913 lmp.py:292]   Expert 51 |      5 | CPU
DEBUG 01-04 15:36:07.856556.856556 lmp.py:292]   Expert 20 |      6 | CPU
DEBUG 01-04 15:36:07.856960.856960 lmp.py:292]   Expert 34 |      6 | CPU
DEBUG 01-04 15:36:07.856126.856126 lmp.py:292]   Expert 28 |      7 | CPU
DEBUG 01-04 15:36:07.856246.856246 lmp.py:292]   Expert 32 |      7 | CPU
DEBUG 01-04 15:36:07.856174.856174 lmp.py:292]   Expert 41 |      8 | CPU
DEBUG 01-04 15:36:07.856863.856863 lmp.py:292]   Expert 42 |      9 | CPU
DEBUG 01-04 15:36:07.856314.856314 lmp.py:292]   Expert 17 |     10 | CPU
DEBUG 01-04 15:36:07.856003.856003 lmp.py:292]   Expert 59 |     11 | CPU
DEBUG 01-04 15:36:07.856693.856693 lmp.py:292]   Expert 54 |     12 | CPU
DEBUG 01-04 15:36:07.856620.856620 lmp.py:292]   Expert 49 |     18 | CPU
DEBUG 01-04 15:36:07.856071.856071 lmp.py:292]   Expert 44 |     19 | CPU
DEBUG 01-04 15:36:07.856431.856431 lmp.py:292]   Expert 30 |     20 | CPU
DEBUG 01-04 15:36:07.856027.856027 lmp.py:292]   Expert  8 |     21 | CPU
DEBUG 01-04 15:36:07.856147.856147 lmp.py:292]   Expert 18 |     22 | CPU
DEBUG 01-04 15:36:07.856790.856790 lmp.py:292]   Expert  6 |     23 | CPU
DEBUG 01-04 15:36:07.856671.856671 lmp.py:292]   Expert 36 |     24 | CPU
DEBUG 01-04 15:36:07.856599.856599 lmp.py:292]   Expert 60 |     25 | CPU
DEBUG 01-04 15:36:07.856288.856288 lmp.py:292]   Expert 14 |     27 | CPU
DEBUG 01-04 15:36:07.856739.856739 lmp.py:292]   Expert 26 |     29 | CPU
DEBUG 01-04 15:36:07.856952.856952 lmp.py:292]   Expert 52 |     29 | GPU
DEBUG 01-04 15:36:07.856403.856403 lmp.py:292]   Expert 12 |     30 | GPU
DEBUG 01-04 15:36:07.856092.856092 lmp.py:292]   Expert 19 |     30 | GPU
DEBUG 01-04 15:36:07.856304.856304 lmp.py:292]   Expert 35 |     33 | GPU
DEBUG 01-04 15:36:07.856994.856994 lmp.py:292]   Expert 27 |     38 | GPU
DEBUG 01-04 15:36:07.856445.856445 lmp.py:292]   Expert 11 |     39 | GPU
DEBUG 01-04 15:36:07.856896.856896 lmp.py:292]   Expert 21 |     40 | GPU
DEBUG 01-04 15:36:07.856585.856585 lmp.py:292]   Expert 46 |     40 | GPU
DEBUG 01-04 15:36:07.856989.856989 lmp.py:292]   Expert 57 |     42 | GPU
DEBUG 01-04 15:36:07.856917.856917 lmp.py:292]   Expert 45 |     46 | GPU
DEBUG 01-04 15:36:07.856944.856944 lmp.py:292]   Expert 37 |     47 | GPU
DEBUG 01-04 15:36:07.856349.856349 lmp.py:292]   Expert 22 |     49 | GPU
DEBUG 01-04 15:36:07.856800.856800 lmp.py:292]   Expert 16 |     52 | GPU
DEBUG 01-04 15:36:07.856012.856012 lmp.py:292]   Expert 31 |     54 | GPU
DEBUG 01-04 15:36:07.856225.856225 lmp.py:292]   Expert 39 |     55 | GPU
DEBUG 01-04 15:36:07.856675.856675 lmp.py:292]   Expert 13 |     56 | GPU
DEBUG 01-04 15:36:07.856126.856126 lmp.py:292]   Expert 24 |     60 | GPU
DEBUG 01-04 15:36:07.856339.856339 lmp.py:292]   Expert 33 |     76 | GPU
DEBUG 01-04 15:36:07.856551.856551 lmp.py:292]   Expert  9 |     79 | GPU
DEBUG 01-04 15:36:07.856241.856241 lmp.py:292]   Expert 47 |     84 | GPU
DEBUG 01-04 15:36:07.856215.856215 lmp.py:292]   Expert 63 |     89 | GPU
DEBUG 01-04 15:36:07.856427.856427 lmp.py:292]   Expert 10 |     92 | GPU
DEBUG 01-04 15:36:07.856832.856832 lmp.py:292]   Expert 56 |     96 | GPU
DEBUG 01-04 15:36:07.856283.856283 lmp.py:292]   Expert 53 |    119 | GPU
DEBUG 01-04 15:36:07.856687.856687 lmp.py:292]   Expert 58 |    119 | GPU
DEBUG 01-04 15:36:07.856330.856330 lmp.py:292]   Expert 25 |    145 | GPU
DEBUG 01-04 15:36:07.857258.857258 lmp.py:292]   Expert  0 |   1682 | GPU
DEBUG 01-04 15:36:07.857947.857947 lmp.py:292]   Expert  3 |   1701 | GPU
DEBUG 01-04 15:36:07.857160.857160 lmp.py:292]   Expert  2 |   1712 | GPU
DEBUG 01-04 15:36:07.857849.857849 lmp.py:292]   Expert  4 |   1715 | GPU
DEBUG 01-04 15:36:07.857061.857061 lmp.py:292]   Expert  1 |   1737 | GPU
DEBUG 01-04 15:36:07.857512.857512 lmp.py:292]   Expert  5 |   1767 | GPU
DEBUG 01-04 15:36:07.857678.857678 lmp.py:293] 
DEBUG 01-04 15:36:07.857678.857678 lmp.py:293]   CPU total tokens: 335 (2.7%)
DEBUG 01-04 15:36:07.857321.857321 lmp.py:294]   GPU total tokens: 11953 (97.3%)
DEBUG 01-04 15:36:07.857971.857971 cuda_h.py:19] end experts_map_get cost 0.0015475749969482422 seconds
DEBUG 01-04 15:36:07.857966.857966 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.857126.857126 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.857726.857726 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.857548.857548 cuda_h.py:19] end allocate_cuda_memory cost 0.00018715858459472656 seconds
DEBUG 01-04 15:36:07.857305.857305 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.857770.857770 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.857003.857003 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.857460.857460 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 28eb8043-1f0f-44c8-987b-d78943956761
DEBUG 01-04 15:36:07.857770.857770 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.859917.859917 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 28eb8043-1f0f-44c8-987b-d78943956761
DEBUG 01-04 15:36:07.860591.860591 cuda_h.py:19] end load_into_gpu_async cost 0.0023415088653564453 seconds
DEBUG 01-04 15:36:07.860838.860838 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.860463.860463 cuda_h.py:19] end restore_tensors2 cost 0.00039839744567871094 seconds
DEBUG 01-04 15:36:07.860378.860378 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033588409423828125 seconds
DEBUG 01-04 15:36:07.863937.863937 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005850315093994141 seconds
DEBUG 01-04 15:36:07.863575.863575 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.863961.863961 lmp.py:339] 
DEBUG 01-04 15:36:07.863961.863961 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:07.863943.863943 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-04 15:36:07.863739.863739 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.874607.874607 mlpmodule.py:704] group tensors cost 0.010815620422363281 s
DEBUG 01-04 15:36:07.878352.878352 mlpmodule.py:742] pad cost 0.003106832504272461 s
DEBUG 01-04 15:36:07.878986.878986 mlpmodule.py:748] create cpu tensor cost 6.198883056640625e-05 s
DEBUG 01-04 15:36:07.878460.878460 mlpmodule.py:753] move to cpu cost 5.1021575927734375e-05 s
DEBUG 01-04 15:36:07.883009.883009 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:07.883217.883217 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.883942.883942 mlpmodule.py:774] group_w3 first element: 0.064453125
WARNING 01-04 15:36:07.883508.883508 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.887735.887735 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.887007.887007 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.891469.891469 mlpmodule.py:797] group einsum cost 0.013084173202514648 s
DEBUG 01-04 15:36:07.892231.892231 mlpmodule.py:805] cpy2cputensor cost 0.00014448165893554688 s
DEBUG 01-04 15:36:07.897894.897894 cuda_h.py:19] end wait_cetm_experts cost 0.03401327133178711 seconds
DEBUG 01-04 15:36:07.897563.897563 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.898646.898646 cuda_h.py:19] end gpu_sexperts cost 0.0006291866302490234 seconds
DEBUG 01-04 15:36:07.898496.898496 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-04 15:36:07.898842.898842 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-04 15:36:07.898580.898580 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.078315734863281e-05 seconds
DEBUG 01-04 15:36:07.898675.898675 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.898717.898717 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.00019025802612304688 seconds
DEBUG 01-04 15:36:07.898607.898607 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.898228.898228 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.898643.898643 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.903681.903681 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 28eb8043-1f0f-44c8-987b-d78943956761
DEBUG 01-04 15:36:07.903121.903121 cuda_h.py:19] end allocate_cuda_memory cost 0.00447845458984375 seconds
DEBUG 01-04 15:36:07.903504.903504 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.903618.903618 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.903547.903547 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.903018.903018 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 27998f69-1457-4ce7-bb49-da34e3b45f55
DEBUG 01-04 15:36:07.903114.903114 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.909952.909952 client.py:127] Model loaded
DEBUG 01-04 15:36:07.910818.910818 cuda_h.py:19] end wait_experts cost 0.006659269332885742 seconds
DEBUG 01-04 15:36:07.910264.910264 cuda_h.py:10] start gpu_experts
INFO 01-04 15:36:07.910793.910793 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 27998f69-1457-4ce7-bb49-da34e3b45f55
DEBUG 01-04 15:36:07.910598.910598 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:07.910249.910249 cuda_h.py:19] end load_into_gpu_async cost 0.006783962249755859 seconds
DEBUG 01-04 15:36:07.910046.910046 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.911042.911042 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-04 15:36:07.911322.911322 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01233053207397461 seconds
DEBUG 01-04 15:36:07.911940.911940 mlpmodule.py:531] gpu group tensors cost 0.0007686614990234375 s
INFO 01-04 15:36:07.911626.911626 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 27998f69-1457-4ce7-bb49-da34e3b45f55
DEBUG 01-04 15:36:07.914330.914330 mlpmodule.py:662]  experts func einsum cost 0.05125570297241211 s
DEBUG 01-04 15:36:07.916563.916563 mlpmodule.py:564] gpu pad cost 0.0045909881591796875 s
DEBUG 01-04 15:36:07.917191.917191 mlpmodule.py:582] gpu group einsum cost 0.0014591217041015625 s
INFO 01-04 15:36:07.918376.918376 client.py:127] Model loaded
DEBUG 01-04 15:36:07.918981.918981 cuda_h.py:19] end sllm_worker_task cost 0.019669294357299805 seconds
DEBUG 01-04 15:36:07.920157.920157 mlpmodule.py:611] gpu experts func einsum cost 0.010023117065429688 s
DEBUG 01-04 15:36:07.920664.920664 cuda_h.py:19] end gpu_experts cost 0.010271549224853516 seconds
DEBUG 01-04 15:36:07.920751.920751 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:07.920527.920527 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8835067749023438e-05 seconds
DEBUG 01-04 15:36:07.923272.923272 cuda_h.py:19] end layer_moe_generate_14 cost 0.06879663467407227 seconds
DEBUG 01-04 15:36:07.923251.923251 lmp.py:207] -------------------------------- end layer 14 --------------------------------
DEBUG 01-04 15:36:07.923583.923583 lmp.py:169] -------------------------------- start layer 15 --------------------------------
DEBUG 01-04 15:36:07.923611.923611 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.924646.924646 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.926514.926514 cuda_h.py:19] end self_attn cost 0.0023407936096191406 seconds
DEBUG 01-04 15:36:07.926842.926842 cuda_h.py:19] end iln_self_attn_paln cost 0.0029153823852539062 seconds
DEBUG 01-04 15:36:07.926724.926724 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-04 15:36:07.926818.926818 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.927228.927228 cuda_h.py:19] end gate cost 0.0005509853363037109 seconds
DEBUG 01-04 15:36:07.927005.927005 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.927987.927987 lmp.py:281] 
DEBUG 01-04 15:36:07.927987.927987 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.927266.927266 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.927962.927962 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.927321.927321 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.927056.927056 lmp.py:285] 
DEBUG 01-04 15:36:07.927056.927056 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.927269.927269 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.927918.927918 lmp.py:292]   Expert 37 |      1 | CPU
DEBUG 01-04 15:36:07.927131.927131 lmp.py:292]   Expert 42 |      2 | CPU
DEBUG 01-04 15:36:07.927628.927628 lmp.py:292]   Expert 57 |      2 | CPU
DEBUG 01-04 15:36:07.928364.928364 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:07.928623.928623 lmp.py:292]   Expert 34 |      5 | CPU
DEBUG 01-04 15:36:07.928881.928881 lmp.py:292]   Expert 48 |      5 | CPU
DEBUG 01-04 15:36:07.928332.928332 lmp.py:292]   Expert 56 |      5 | CPU
DEBUG 01-04 15:36:07.928022.928022 lmp.py:292]   Expert 29 |      6 | CPU
DEBUG 01-04 15:36:07.928996.928996 lmp.py:292]   Expert 43 |      6 | CPU
DEBUG 01-04 15:36:07.928208.928208 lmp.py:292]   Expert 14 |      8 | CPU
DEBUG 01-04 15:36:07.928182.928182 lmp.py:292]   Expert 25 |      8 | CPU
DEBUG 01-04 15:36:07.928679.928679 lmp.py:292]   Expert 51 |      9 | CPU
DEBUG 01-04 15:36:07.928700.928700 lmp.py:292]   Expert 63 |      9 | CPU
DEBUG 01-04 15:36:07.928958.928958 lmp.py:292]   Expert 44 |     10 | CPU
DEBUG 01-04 15:36:07.928979.928979 lmp.py:292]   Expert 58 |     10 | CPU
DEBUG 01-04 15:36:07.928999.928999 lmp.py:292]   Expert  6 |     11 | CPU
DEBUG 01-04 15:36:07.928020.928020 lmp.py:292]   Expert 22 |     11 | CPU
DEBUG 01-04 15:36:07.928040.928040 lmp.py:292]   Expert 59 |     11 | CPU
DEBUG 01-04 15:36:07.928060.928060 lmp.py:292]   Expert 32 |     12 | CPU
DEBUG 01-04 15:36:07.928081.928081 lmp.py:292]   Expert 62 |     13 | CPU
DEBUG 01-04 15:36:07.928101.928101 lmp.py:292]   Expert 53 |     16 | CPU
DEBUG 01-04 15:36:07.928314.928314 lmp.py:292]   Expert 55 |     17 | CPU
DEBUG 01-04 15:36:07.928288.928288 lmp.py:292]   Expert 11 |     20 | CPU
DEBUG 01-04 15:36:07.928262.928262 lmp.py:292]   Expert 31 |     21 | CPU
DEBUG 01-04 15:36:07.928759.928759 lmp.py:292]   Expert 15 |     23 | CPU
DEBUG 01-04 15:36:07.928733.928733 lmp.py:292]   Expert 38 |     25 | CPU
DEBUG 01-04 15:36:07.928753.928753 lmp.py:292]   Expert 39 |     25 | CPU
DEBUG 01-04 15:36:07.928535.928535 lmp.py:292]   Expert 20 |     26 | CPU
DEBUG 01-04 15:36:07.928139.928139 lmp.py:292]   Expert  7 |     29 | CPU
DEBUG 01-04 15:36:07.928040.928040 lmp.py:292]   Expert 40 |     29 | CPU
DEBUG 01-04 15:36:07.928538.928538 lmp.py:292]   Expert 23 |     30 | CPU
DEBUG 01-04 15:36:07.928273.928273 lmp.py:292]   Expert 41 |     32 | CPU
DEBUG 01-04 15:36:07.928009.928009 lmp.py:292]   Expert 54 |     32 | GPU
DEBUG 01-04 15:36:07.928221.928221 lmp.py:292]   Expert 50 |     37 | GPU
DEBUG 01-04 15:36:07.928864.928864 lmp.py:292]   Expert 13 |     39 | GPU
DEBUG 01-04 15:36:07.928554.928554 lmp.py:292]   Expert 18 |     39 | GPU
DEBUG 01-04 15:36:07.928912.928912 lmp.py:292]   Expert 33 |     39 | GPU
DEBUG 01-04 15:36:07.928078.928078 lmp.py:292]   Expert 16 |     42 | GPU
DEBUG 01-04 15:36:07.928290.928290 lmp.py:292]   Expert 47 |     44 | GPU
DEBUG 01-04 15:36:07.928788.928788 lmp.py:292]   Expert 61 |     46 | GPU
DEBUG 01-04 15:36:07.928523.928523 lmp.py:292]   Expert 27 |     49 | GPU
DEBUG 01-04 15:36:07.928020.928020 lmp.py:292]   Expert 35 |     49 | GPU
DEBUG 01-04 15:36:07.928756.928756 lmp.py:292]   Expert 52 |     50 | GPU
DEBUG 01-04 15:36:07.928253.928253 lmp.py:292]   Expert 36 |     51 | GPU
DEBUG 01-04 15:36:07.928989.928989 lmp.py:292]   Expert 26 |     53 | GPU
DEBUG 01-04 15:36:07.928725.928725 lmp.py:292]   Expert 46 |     61 | GPU
DEBUG 01-04 15:36:07.928222.928222 lmp.py:292]   Expert 24 |     65 | GPU
DEBUG 01-04 15:36:07.928719.928719 lmp.py:292]   Expert  9 |     66 | GPU
DEBUG 01-04 15:36:07.928455.928455 lmp.py:292]   Expert 19 |     77 | GPU
DEBUG 01-04 15:36:07.928905.928905 lmp.py:292]   Expert 21 |     81 | GPU
DEBUG 01-04 15:36:07.928595.928595 lmp.py:292]   Expert 30 |     81 | GPU
DEBUG 01-04 15:36:07.928522.928522 lmp.py:292]   Expert 60 |     84 | GPU
DEBUG 01-04 15:36:07.928881.928881 lmp.py:292]   Expert 10 |     86 | GPU
DEBUG 01-04 15:36:07.928570.928570 lmp.py:292]   Expert 12 |     90 | GPU
DEBUG 01-04 15:36:07.928544.928544 lmp.py:292]   Expert 49 |     92 | GPU
DEBUG 01-04 15:36:07.928280.928280 lmp.py:292]   Expert 45 |     94 | GPU
DEBUG 01-04 15:36:07.928254.928254 lmp.py:292]   Expert  8 |    101 | GPU
DEBUG 01-04 15:36:07.928228.928228 lmp.py:292]   Expert 17 |    105 | GPU
DEBUG 01-04 15:36:07.928963.928963 lmp.py:292]   Expert  4 |   1671 | GPU
DEBUG 01-04 15:36:07.928937.928937 lmp.py:292]   Expert  2 |   1684 | GPU
DEBUG 01-04 15:36:07.928673.928673 lmp.py:292]   Expert  1 |   1685 | GPU
DEBUG 01-04 15:36:07.928647.928647 lmp.py:292]   Expert  5 |   1688 | GPU
DEBUG 01-04 15:36:07.928383.928383 lmp.py:292]   Expert  0 |   1716 | GPU
DEBUG 01-04 15:36:07.928834.928834 lmp.py:292]   Expert  3 |   1750 | GPU
DEBUG 01-04 15:36:07.929000.929000 lmp.py:293] 
DEBUG 01-04 15:36:07.929000.929000 lmp.py:293]   CPU total tokens: 441 (3.6%)
DEBUG 01-04 15:36:07.929643.929643 lmp.py:294]   GPU total tokens: 11847 (96.4%)
DEBUG 01-04 15:36:07.929531.929531 cuda_h.py:19] end experts_map_get cost 0.0014491081237792969 seconds
DEBUG 01-04 15:36:07.929697.929697 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.929473.929473 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.929696.929696 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.929452.929452 cuda_h.py:19] end allocate_cuda_memory cost 0.00017333030700683594 seconds
DEBUG 01-04 15:36:07.929387.929387 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.929521.929521 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.929614.929614 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.929801.929801 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 249de6d2-6594-4785-aace-68f6664319fe
DEBUG 01-04 15:36:07.929065.929065 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.931922.931922 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 249de6d2-6594-4785-aace-68f6664319fe
DEBUG 01-04 15:36:07.931758.931758 cuda_h.py:19] end load_into_gpu_async cost 0.0021398067474365234 seconds
DEBUG 01-04 15:36:07.931884.931884 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.931980.931980 cuda_h.py:19] end restore_tensors2 cost 0.0002579689025878906 seconds
DEBUG 01-04 15:36:07.932557.932557 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028841495513916016 seconds
DEBUG 01-04 15:36:07.934867.934867 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005434989929199219 seconds
DEBUG 01-04 15:36:07.934550.934550 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:07.934175.934175 lmp.py:339] 
DEBUG 01-04 15:36:07.934175.934175 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:07.934926.934926 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-04 15:36:07.934052.934052 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:07.946309.946309 mlpmodule.py:704] group tensors cost 0.011795520782470703 s
DEBUG 01-04 15:36:07.949709.949709 mlpmodule.py:742] pad cost 0.0021386146545410156 s
DEBUG 01-04 15:36:07.949607.949607 mlpmodule.py:748] create cpu tensor cost 7.271766662597656e-05 s
DEBUG 01-04 15:36:07.950239.950239 mlpmodule.py:753] move to cpu cost 4.2438507080078125e-05 s
DEBUG 01-04 15:36:07.954373.954373 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:07.955660.955660 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:07.955491.955491 mlpmodule.py:774] group_w3 first element: -0.004180908203125
WARNING 01-04 15:36:07.955216.955216 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:07.959766.959766 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:07.959429.959429 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:07.963300.963300 mlpmodule.py:797] group einsum cost 0.013834476470947266 s
DEBUG 01-04 15:36:07.964665.964665 mlpmodule.py:805] cpy2cputensor cost 0.00016927719116210938 s
DEBUG 01-04 15:36:07.969217.969217 cuda_h.py:19] end wait_cetm_experts cost 0.03469705581665039 seconds
DEBUG 01-04 15:36:07.969528.969528 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:07.970814.970814 cuda_h.py:19] end gpu_sexperts cost 0.0005879402160644531 seconds
DEBUG 01-04 15:36:07.970233.970233 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-04 15:36:07.970871.970871 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-04 15:36:07.970894.970894 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 4.863739013671875e-05 seconds
DEBUG 01-04 15:36:07.970466.970466 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:07.970236.970236 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.00019979476928710938 seconds
DEBUG 01-04 15:36:07.970557.970557 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.970632.970632 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:07.970796.970796 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 249de6d2-6594-4785-aace-68f6664319fe
DEBUG 01-04 15:36:07.970317.970317 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.976032.976032 cuda_h.py:19] end allocate_cuda_memory cost 0.004845380783081055 seconds
DEBUG 01-04 15:36:07.976271.976271 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.976193.976193 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.976168.976168 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.976521.976521 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d1a6041-08b6-4943-8347-74ee949f1a61
DEBUG 01-04 15:36:07.976425.976425 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:07.981692.981692 client.py:127] Model loaded
DEBUG 01-04 15:36:07.981558.981558 cuda_h.py:19] end wait_experts cost 0.010873794555664062 seconds
DEBUG 01-04 15:36:07.981667.981667 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:07.982914.982914 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:07.982173.982173 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d1a6041-08b6-4943-8347-74ee949f1a61
DEBUG 01-04 15:36:07.982698.982698 cuda_h.py:19] end load_into_gpu_async cost 0.006588459014892578 seconds
DEBUG 01-04 15:36:07.982355.982355 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:07.983252.983252 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-04 15:36:07.983339.983339 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012162923812866211 seconds
DEBUG 01-04 15:36:07.983433.983433 mlpmodule.py:531] gpu group tensors cost 0.0011141300201416016 s
INFO 01-04 15:36:07.983646.983646 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d1a6041-08b6-4943-8347-74ee949f1a61
DEBUG 01-04 15:36:07.985134.985134 mlpmodule.py:564] gpu pad cost 0.0016467571258544922 s
DEBUG 01-04 15:36:07.985986.985986 mlpmodule.py:582] gpu group einsum cost 0.0004532337188720703 s
DEBUG 01-04 15:36:07.986513.986513 mlpmodule.py:662]  experts func einsum cost 0.051732540130615234 s
DEBUG 01-04 15:36:07.988936.988936 mlpmodule.py:611] gpu experts func einsum cost 0.006427288055419922 s
DEBUG 01-04 15:36:07.988862.988862 cuda_h.py:19] end gpu_experts cost 0.006750822067260742 seconds
DEBUG 01-04 15:36:07.988333.988333 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:07.993919.993919 client.py:127] Model loaded
DEBUG 01-04 15:36:07.993822.993822 cuda_h.py:19] end sllm_worker_task cost 0.02274632453918457 seconds
DEBUG 01-04 15:36:07.993023.993023 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0047626495361328125 seconds
DEBUG 01-04 15:36:07.993155.993155 cuda_h.py:19] end layer_moe_generate_15 cost 0.06682419776916504 seconds
DEBUG 01-04 15:36:07.993048.993048 lmp.py:207] -------------------------------- end layer 15 --------------------------------
DEBUG 01-04 15:36:07.993334.993334 lmp.py:169] -------------------------------- start layer 16 --------------------------------
DEBUG 01-04 15:36:07.993884.993884 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:07.994728.994728 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:07.996020.996020 cuda_h.py:19] end self_attn cost 0.002339601516723633 seconds
DEBUG 01-04 15:36:07.996300.996300 cuda_h.py:19] end iln_self_attn_paln cost 0.0029115676879882812 seconds
DEBUG 01-04 15:36:07.996567.996567 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-04 15:36:07.997330.997330 cuda_h.py:10] start gate
DEBUG 01-04 15:36:07.997291.997291 cuda_h.py:19] end gate cost 0.0005698204040527344 seconds
DEBUG 01-04 15:36:07.997067.997067 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:07.997440.997440 lmp.py:281] 
DEBUG 01-04 15:36:07.997440.997440 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:07.997574.997574 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:07.997555.997555 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:07.998198.998198 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:07.998887.998887 lmp.py:285] 
DEBUG 01-04 15:36:07.998887.998887 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:07.998099.998099 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:07.998319.998319 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:07.998054.998054 lmp.py:292]   Expert 15 |      2 | CPU
DEBUG 01-04 15:36:07.998551.998551 lmp.py:292]   Expert 59 |      2 | CPU
DEBUG 01-04 15:36:07.998810.998810 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:07.998307.998307 lmp.py:292]   Expert 58 |      5 | CPU
DEBUG 01-04 15:36:07.998328.998328 lmp.py:292]   Expert 13 |      6 | CPU
DEBUG 01-04 15:36:07.998348.998348 lmp.py:292]   Expert 43 |      6 | CPU
DEBUG 01-04 15:36:07.998845.998845 lmp.py:292]   Expert 57 |      7 | CPU
DEBUG 01-04 15:36:07.998627.998627 lmp.py:292]   Expert 61 |      8 | CPU
DEBUG 01-04 15:36:07.998840.998840 lmp.py:292]   Expert 28 |     10 | CPU
DEBUG 01-04 15:36:07.998337.998337 lmp.py:292]   Expert 51 |     10 | CPU
DEBUG 01-04 15:36:07.998311.998311 lmp.py:292]   Expert 18 |     11 | CPU
DEBUG 01-04 15:36:07.998808.998808 lmp.py:292]   Expert 11 |     12 | CPU
DEBUG 01-04 15:36:07.998305.998305 lmp.py:292]   Expert 14 |     12 | CPU
DEBUG 01-04 15:36:07.998326.998326 lmp.py:292]   Expert 60 |     13 | CPU
DEBUG 01-04 15:36:07.998869.998869 lmp.py:292]   Expert 12 |     14 | CPU
DEBUG 01-04 15:36:07.998651.998651 lmp.py:292]   Expert 31 |     14 | CPU
DEBUG 01-04 15:36:07.998672.998672 lmp.py:292]   Expert 42 |     16 | CPU
DEBUG 01-04 15:36:07.998692.998692 lmp.py:292]   Expert 55 |     18 | CPU
DEBUG 01-04 15:36:07.998474.998474 lmp.py:292]   Expert 33 |     19 | CPU
DEBUG 01-04 15:36:07.998494.998494 lmp.py:292]   Expert 44 |     20 | CPU
DEBUG 01-04 15:36:07.998038.998038 lmp.py:292]   Expert 35 |     22 | CPU
DEBUG 01-04 15:36:07.998820.998820 lmp.py:292]   Expert 45 |     22 | CPU
DEBUG 01-04 15:36:07.998602.998602 lmp.py:292]   Expert 34 |     23 | CPU
DEBUG 01-04 15:36:07.998861.998861 lmp.py:292]   Expert  6 |     25 | CPU
DEBUG 01-04 15:36:07.998643.998643 lmp.py:292]   Expert 22 |     26 | CPU
DEBUG 01-04 15:36:07.998186.998186 lmp.py:292]   Expert 39 |     26 | CPU
DEBUG 01-04 15:36:07.998160.998160 lmp.py:292]   Expert 26 |     28 | CPU
DEBUG 01-04 15:36:07.998896.998896 lmp.py:292]   Expert 49 |     28 | CPU
DEBUG 01-04 15:36:07.998631.998631 lmp.py:292]   Expert 23 |     31 | CPU
DEBUG 01-04 15:36:07.998129.998129 lmp.py:292]   Expert 10 |     32 | CPU
DEBUG 01-04 15:36:07.998149.998149 lmp.py:292]   Expert 50 |     33 | CPU
DEBUG 01-04 15:36:07.998169.998169 lmp.py:292]   Expert 62 |     33 | GPU
DEBUG 01-04 15:36:07.998713.998713 lmp.py:292]   Expert 16 |     34 | GPU
DEBUG 01-04 15:36:07.998495.998495 lmp.py:292]   Expert 38 |     35 | GPU
DEBUG 01-04 15:36:07.998515.998515 lmp.py:292]   Expert 21 |     37 | GPU
DEBUG 01-04 15:36:07.998297.998297 lmp.py:292]   Expert 25 |     37 | GPU
DEBUG 01-04 15:36:07.998841.998841 lmp.py:292]   Expert 40 |     37 | GPU
DEBUG 01-04 15:36:07.998623.998623 lmp.py:292]   Expert 53 |     42 | GPU
DEBUG 01-04 15:36:07.998643.998643 lmp.py:292]   Expert 63 |     44 | GPU
DEBUG 01-04 15:36:07.998187.998187 lmp.py:292]   Expert 32 |     46 | GPU
DEBUG 01-04 15:36:07.998968.998968 lmp.py:292]   Expert  9 |     47 | GPU
DEBUG 01-04 15:36:07.998512.998512 lmp.py:292]   Expert 19 |     48 | GPU
DEBUG 01-04 15:36:07.998294.998294 lmp.py:292]   Expert 48 |     50 | GPU
DEBUG 01-04 15:36:07.998837.998837 lmp.py:292]   Expert 56 |     54 | GPU
DEBUG 01-04 15:36:07.998858.998858 lmp.py:292]   Expert 37 |     55 | GPU
DEBUG 01-04 15:36:07.998117.998117 lmp.py:292]   Expert 41 |     57 | GPU
DEBUG 01-04 15:36:07.998614.998614 lmp.py:292]   Expert 17 |     60 | GPU
DEBUG 01-04 15:36:07.998873.998873 lmp.py:292]   Expert 29 |     60 | GPU
DEBUG 01-04 15:36:07.998131.998131 lmp.py:292]   Expert 24 |     65 | GPU
DEBUG 01-04 15:36:07.998390.998390 lmp.py:292]   Expert 36 |     65 | GPU
DEBUG 01-04 15:36:07.998649.998649 lmp.py:292]   Expert  7 |     77 | GPU
DEBUG 01-04 15:36:07.998193.998193 lmp.py:292]   Expert 20 |     77 | GPU
DEBUG 01-04 15:36:07.998975.998975 lmp.py:292]   Expert 46 |     82 | GPU
DEBUG 01-04 15:36:07.998995.998995 lmp.py:292]   Expert 27 |     87 | GPU
DEBUG 01-04 15:36:07.998777.998777 lmp.py:292]   Expert 47 |     97 | GPU
DEBUG 01-04 15:36:07.998559.998559 lmp.py:292]   Expert  8 |    110 | GPU
DEBUG 01-04 15:36:07.998341.998341 lmp.py:292]   Expert 52 |    126 | GPU
DEBUG 01-04 15:36:07.998884.998884 lmp.py:292]   Expert  4 |   1674 | GPU
DEBUG 01-04 15:36:07.998905.998905 lmp.py:292]   Expert  0 |   1691 | GPU
DEBUG 01-04 15:36:07.998640.998640 lmp.py:292]   Expert  3 |   1691 | GPU
DEBUG 01-04 15:36:07.998137.998137 lmp.py:292]   Expert  1 |   1701 | GPU
DEBUG 01-04 15:36:07.998112.998112 lmp.py:292]   Expert  2 |   1704 | GPU
DEBUG 01-04 15:36:07.999086.999086 lmp.py:292]   Expert  5 |   1760 | GPU
DEBUG 01-04 15:36:07.999775.999775 lmp.py:293] 
DEBUG 01-04 15:36:07.999775.999775 lmp.py:293]   CPU total tokens: 505 (4.1%)
DEBUG 01-04 15:36:07.999749.999749 lmp.py:294]   GPU total tokens: 11783 (95.9%)
DEBUG 01-04 15:36:07.999538.999538 cuda_h.py:19] end experts_map_get cost 0.0013737678527832031 seconds
DEBUG 01-04 15:36:07.999512.999512 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:07.999050.999050 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:07.999835.999835 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:07.999884.999884 cuda_h.py:19] end allocate_cuda_memory cost 0.00025177001953125 seconds
DEBUG 01-04 15:36:07.999059.999059 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:07.999669.999669 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:07.999670.999670 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:07.999174.999174 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cefc4e61-24a0-4dcd-a4c9-758672e2be95
DEBUG 01-04 15:36:07.999815.999815 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.000426.000426 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cefc4e61-24a0-4dcd-a4c9-758672e2be95
DEBUG 01-04 15:36:08.001033.001033 cuda_h.py:19] end load_into_gpu_async cost 0.0013747215270996094 seconds
DEBUG 01-04 15:36:08.001897.001897 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.001402.001402 cuda_h.py:19] end restore_tensors2 cost 0.00038170814514160156 seconds
DEBUG 01-04 15:36:08.001171.001171 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024220943450927734 seconds
DEBUG 01-04 15:36:08.004684.004684 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004906892776489258 seconds
DEBUG 01-04 15:36:08.004652.004652 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.004039.004039 lmp.py:339] 
DEBUG 01-04 15:36:08.004039.004039 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.004643.004643 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-04 15:36:08.004293.004293 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.015723.015723 mlpmodule.py:704] group tensors cost 0.011173009872436523 s
DEBUG 01-04 15:36:08.019778.019778 mlpmodule.py:742] pad cost 0.002933025360107422 s
DEBUG 01-04 15:36:08.019545.019545 mlpmodule.py:748] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-04 15:36:08.019322.019322 mlpmodule.py:753] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-04 15:36:08.024314.024314 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.024747.024747 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.024962.024962 mlpmodule.py:774] group_w3 first element: -0.007537841796875
WARNING 01-04 15:36:08.024410.024410 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.028449.028449 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.029747.029747 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.033781.033781 mlpmodule.py:797] group einsum cost 0.013848304748535156 s
DEBUG 01-04 15:36:08.033598.033598 mlpmodule.py:805] cpy2cputensor cost 0.0002071857452392578 s
DEBUG 01-04 15:36:08.039226.039226 cuda_h.py:19] end wait_cetm_experts cost 0.03508496284484863 seconds
DEBUG 01-04 15:36:08.039345.039345 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.040207.040207 cuda_h.py:19] end gpu_sexperts cost 0.0005917549133300781 seconds
DEBUG 01-04 15:36:08.040957.040957 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-04 15:36:08.040641.040641 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-04 15:36:08.040354.040354 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00010538101196289062 seconds
DEBUG 01-04 15:36:08.040118.040118 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.040215.040215 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.0002803802490234375 seconds
DEBUG 01-04 15:36:08.040662.040662 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.040817.040817 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.041988.041988 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cefc4e61-24a0-4dcd-a4c9-758672e2be95
DEBUG 01-04 15:36:08.040708.040708 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.045335.045335 cuda_h.py:19] end allocate_cuda_memory cost 0.004415273666381836 seconds
DEBUG 01-04 15:36:08.045784.045784 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.045229.045229 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.045250.045250 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.045768.045768 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f5177d55-ed9a-4b10-9781-037bd3238916
DEBUG 01-04 15:36:08.046480.046480 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.051004.051004 client.py:127] Model loaded
DEBUG 01-04 15:36:08.051940.051940 cuda_h.py:19] end wait_experts cost 0.01022481918334961 seconds
DEBUG 01-04 15:36:08.051974.051974 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.051961.051961 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:08.051665.051665 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f5177d55-ed9a-4b10-9781-037bd3238916
DEBUG 01-04 15:36:08.051443.051443 cuda_h.py:19] end load_into_gpu_async cost 0.005986452102661133 seconds
DEBUG 01-04 15:36:08.051457.051457 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.051362.051362 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-04 15:36:08.051356.051356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011081695556640625 seconds
DEBUG 01-04 15:36:08.052093.052093 mlpmodule.py:531] gpu group tensors cost 0.0006866455078125 s
INFO 01-04 15:36:08.052571.052571 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f5177d55-ed9a-4b10-9781-037bd3238916
DEBUG 01-04 15:36:08.054238.054238 mlpmodule.py:564] gpu pad cost 0.0018999576568603516 s
DEBUG 01-04 15:36:08.054083.054083 mlpmodule.py:582] gpu group einsum cost 0.00045180320739746094 s
DEBUG 01-04 15:36:08.056141.056141 mlpmodule.py:662]  experts func einsum cost 0.05158376693725586 s
DEBUG 01-04 15:36:08.057850.057850 mlpmodule.py:611] gpu experts func einsum cost 0.006295680999755859 s
DEBUG 01-04 15:36:08.057596.057596 cuda_h.py:19] end gpu_experts cost 0.006509065628051758 seconds
DEBUG 01-04 15:36:08.057637.057637 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.062768.062768 client.py:127] Model loaded
DEBUG 01-04 15:36:08.062578.062578 cuda_h.py:19] end sllm_worker_task cost 0.021820783615112305 seconds
DEBUG 01-04 15:36:08.062018.062018 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004815578460693359 seconds
DEBUG 01-04 15:36:08.062798.062798 cuda_h.py:19] end layer_moe_generate_16 cost 0.06579804420471191 seconds
DEBUG 01-04 15:36:08.062645.062645 lmp.py:207] -------------------------------- end layer 16 --------------------------------
DEBUG 01-04 15:36:08.063931.063931 lmp.py:169] -------------------------------- start layer 17 --------------------------------
DEBUG 01-04 15:36:08.063958.063958 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.063331.063331 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.065366.065366 cuda_h.py:19] end self_attn cost 0.0023593902587890625 seconds
DEBUG 01-04 15:36:08.065924.065924 cuda_h.py:19] end iln_self_attn_paln cost 0.0029311180114746094 seconds
DEBUG 01-04 15:36:08.066761.066761 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-04 15:36:08.066901.066901 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.066457.066457 cuda_h.py:19] end gate cost 0.0005533695220947266 seconds
DEBUG 01-04 15:36:08.066902.066902 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.066368.066368 lmp.py:281] 
DEBUG 01-04 15:36:08.066368.066368 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.067217.067217 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.067959.067959 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.067602.067602 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.067861.067861 lmp.py:285] 
DEBUG 01-04 15:36:08.067861.067861 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.067835.067835 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.067246.067246 lmp.py:292]   Expert 46 |      1 | CPU
DEBUG 01-04 15:36:08.067651.067651 lmp.py:292]   Expert 14 |      3 | CPU
DEBUG 01-04 15:36:08.067863.067863 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:08.067314.067314 lmp.py:292]   Expert 36 |      3 | CPU
DEBUG 01-04 15:36:08.067573.067573 lmp.py:292]   Expert 39 |      4 | CPU
DEBUG 01-04 15:36:08.067594.067594 lmp.py:292]   Expert 27 |      7 | CPU
DEBUG 01-04 15:36:08.067091.067091 lmp.py:292]   Expert 28 |      8 | CPU
DEBUG 01-04 15:36:08.067350.067350 lmp.py:292]   Expert  7 |      9 | CPU
DEBUG 01-04 15:36:08.067370.067370 lmp.py:292]   Expert 25 |      9 | CPU
DEBUG 01-04 15:36:08.067390.067390 lmp.py:292]   Expert 31 |     11 | CPU
DEBUG 01-04 15:36:08.067172.067172 lmp.py:292]   Expert 40 |     11 | CPU
DEBUG 01-04 15:36:08.067193.067193 lmp.py:292]   Expert  8 |     12 | CPU
DEBUG 01-04 15:36:08.067643.067643 lmp.py:292]   Expert 33 |     12 | CPU
DEBUG 01-04 15:36:08.067379.067379 lmp.py:292]   Expert 42 |     13 | CPU
DEBUG 01-04 15:36:08.067638.067638 lmp.py:292]   Expert 29 |     14 | CPU
DEBUG 01-04 15:36:08.067612.067612 lmp.py:292]   Expert 58 |     14 | CPU
DEBUG 01-04 15:36:08.067348.067348 lmp.py:292]   Expert 56 |     19 | CPU
DEBUG 01-04 15:36:08.067368.067368 lmp.py:292]   Expert 59 |     22 | CPU
DEBUG 01-04 15:36:08.067911.067911 lmp.py:292]   Expert  6 |     23 | CPU
DEBUG 01-04 15:36:08.067932.067932 lmp.py:292]   Expert 10 |     23 | CPU
DEBUG 01-04 15:36:08.067714.067714 lmp.py:292]   Expert 54 |     23 | CPU
DEBUG 01-04 15:36:08.067734.067734 lmp.py:292]   Expert 34 |     24 | CPU
DEBUG 01-04 15:36:08.067516.067516 lmp.py:292]   Expert 37 |     25 | CPU
DEBUG 01-04 15:36:08.067298.067298 lmp.py:292]   Expert 35 |     26 | CPU
DEBUG 01-04 15:36:08.067318.067318 lmp.py:292]   Expert 60 |     26 | CPU
DEBUG 01-04 15:36:08.067862.067862 lmp.py:292]   Expert 15 |     29 | CPU
DEBUG 01-04 15:36:08.067644.067644 lmp.py:292]   Expert 18 |     30 | CPU
DEBUG 01-04 15:36:08.067426.067426 lmp.py:292]   Expert 47 |     31 | CPU
DEBUG 01-04 15:36:08.067685.067685 lmp.py:292]   Expert 11 |     32 | CPU
DEBUG 01-04 15:36:08.067943.067943 lmp.py:292]   Expert 24 |     33 | CPU
DEBUG 01-04 15:36:08.067202.067202 lmp.py:292]   Expert 52 |     33 | CPU
DEBUG 01-04 15:36:08.067938.067938 lmp.py:292]   Expert 22 |     34 | CPU
DEBUG 01-04 15:36:08.067197.067197 lmp.py:292]   Expert 30 |     34 | GPU
DEBUG 01-04 15:36:08.067979.067979 lmp.py:292]   Expert 49 |     36 | GPU
DEBUG 01-04 15:36:08.067284.067284 lmp.py:292]   Expert 45 |     37 | GPU
DEBUG 01-04 15:36:08.067589.067589 lmp.py:292]   Expert 44 |     39 | GPU
DEBUG 01-04 15:36:08.067132.067132 lmp.py:292]   Expert 61 |     39 | GPU
DEBUG 01-04 15:36:08.067153.067153 lmp.py:292]   Expert 63 |     39 | GPU
DEBUG 01-04 15:36:08.067935.067935 lmp.py:292]   Expert 13 |     43 | GPU
DEBUG 01-04 15:36:08.067955.067955 lmp.py:292]   Expert 20 |     51 | GPU
DEBUG 01-04 15:36:08.067737.067737 lmp.py:292]   Expert 19 |     55 | GPU
DEBUG 01-04 15:36:08.067281.067281 lmp.py:292]   Expert 43 |     55 | GPU
DEBUG 01-04 15:36:08.067301.067301 lmp.py:292]   Expert 51 |     55 | GPU
DEBUG 01-04 15:36:08.067083.067083 lmp.py:292]   Expert 57 |     55 | GPU
DEBUG 01-04 15:36:08.067580.067580 lmp.py:292]   Expert 50 |     56 | GPU
DEBUG 01-04 15:36:08.067554.067554 lmp.py:292]   Expert 21 |     57 | GPU
DEBUG 01-04 15:36:08.067813.067813 lmp.py:292]   Expert 53 |     57 | GPU
DEBUG 01-04 15:36:08.067549.067549 lmp.py:292]   Expert 26 |     60 | GPU
DEBUG 01-04 15:36:08.067807.067807 lmp.py:292]   Expert 32 |     61 | GPU
DEBUG 01-04 15:36:08.067828.067828 lmp.py:292]   Expert 38 |     62 | GPU
DEBUG 01-04 15:36:08.067133.067133 lmp.py:292]   Expert 48 |     62 | GPU
DEBUG 01-04 15:36:08.067915.067915 lmp.py:292]   Expert 55 |     65 | GPU
DEBUG 01-04 15:36:08.067220.067220 lmp.py:292]   Expert 12 |     66 | GPU
DEBUG 01-04 15:36:08.067763.067763 lmp.py:292]   Expert 23 |     75 | GPU
DEBUG 01-04 15:36:08.067545.067545 lmp.py:292]   Expert 62 |     90 | GPU
DEBUG 01-04 15:36:08.067089.067089 lmp.py:292]   Expert 41 |     95 | GPU
DEBUG 01-04 15:36:08.067871.067871 lmp.py:292]   Expert 17 |    110 | GPU
DEBUG 01-04 15:36:08.067414.067414 lmp.py:292]   Expert  9 |    148 | GPU
DEBUG 01-04 15:36:08.067435.067435 lmp.py:292]   Expert  4 |   1666 | GPU
DEBUG 01-04 15:36:08.067932.067932 lmp.py:292]   Expert  1 |   1668 | GPU
DEBUG 01-04 15:36:08.068952.068952 lmp.py:292]   Expert  3 |   1687 | GPU
DEBUG 01-04 15:36:08.068450.068450 lmp.py:292]   Expert  5 |   1697 | GPU
DEBUG 01-04 15:36:08.068708.068708 lmp.py:292]   Expert  2 |   1700 | GPU
DEBUG 01-04 15:36:08.068729.068729 lmp.py:292]   Expert  0 |   1701 | GPU
DEBUG 01-04 15:36:08.068987.068987 lmp.py:293] 
DEBUG 01-04 15:36:08.068987.068987 lmp.py:293]   CPU total tokens: 567 (4.6%)
DEBUG 01-04 15:36:08.068485.068485 lmp.py:294]   GPU total tokens: 11721 (95.4%)
DEBUG 01-04 15:36:08.068273.068273 cuda_h.py:19] end experts_map_get cost 0.0013720989227294922 seconds
DEBUG 01-04 15:36:08.068486.068486 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.068070.068070 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.068339.068339 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.068636.068636 cuda_h.py:19] end allocate_cuda_memory cost 0.0003273487091064453 seconds
DEBUG 01-04 15:36:08.068579.068579 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.068666.068666 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.068713.068713 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.068886.068886 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24824117-a8f2-4cfb-a1d0-4f81fd4cfb46
DEBUG 01-04 15:36:08.068018.068018 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.070817.070817 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24824117-a8f2-4cfb-a1d0-4f81fd4cfb46
DEBUG 01-04 15:36:08.070477.070477 cuda_h.py:19] end load_into_gpu_async cost 0.0014569759368896484 seconds
DEBUG 01-04 15:36:08.070963.070963 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.070046.070046 cuda_h.py:19] end restore_tensors2 cost 0.0004570484161376953 seconds
DEBUG 01-04 15:36:08.070339.070339 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026705265045166016 seconds
DEBUG 01-04 15:36:08.073079.073079 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005215644836425781 seconds
DEBUG 01-04 15:36:08.073816.073816 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.073540.073540 lmp.py:339] 
DEBUG 01-04 15:36:08.073540.073540 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.073191.073191 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-04 15:36:08.073364.073364 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.084704.084704 mlpmodule.py:704] group tensors cost 0.010267257690429688 s
DEBUG 01-04 15:36:08.087015.087015 mlpmodule.py:742] pad cost 0.002373933792114258 s
DEBUG 01-04 15:36:08.087060.087060 mlpmodule.py:748] create cpu tensor cost 6.461143493652344e-05 s
DEBUG 01-04 15:36:08.087420.087420 mlpmodule.py:753] move to cpu cost 4.6253204345703125e-05 s
DEBUG 01-04 15:36:08.094533.094533 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.094581.094581 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.094604.094604 mlpmodule.py:774] group_w3 first element: 0.0267333984375
WARNING 01-04 15:36:08.094529.094529 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.098987.098987 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.098002.098002 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.103446.103446 mlpmodule.py:797] group einsum cost 0.015559673309326172 s
DEBUG 01-04 15:36:08.103382.103382 mlpmodule.py:805] cpy2cputensor cost 0.00020241737365722656 s
DEBUG 01-04 15:36:08.108873.108873 cuda_h.py:19] end wait_cetm_experts cost 0.035303592681884766 seconds
DEBUG 01-04 15:36:08.109502.109502 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.109165.109165 cuda_h.py:19] end gpu_sexperts cost 0.0005872249603271484 seconds
DEBUG 01-04 15:36:08.109432.109432 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-04 15:36:08.109824.109824 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-04 15:36:08.109417.109417 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 4.649162292480469e-05 seconds
DEBUG 01-04 15:36:08.110762.110762 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 9.989738464355469e-05 seconds
DEBUG 01-04 15:36:08.110558.110558 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.110566.110566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24824117-a8f2-4cfb-a1d0-4f81fd4cfb46
DEBUG 01-04 15:36:08.110284.110284 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.110172.110172 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.110837.110837 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.115985.115985 cuda_h.py:19] end allocate_cuda_memory cost 0.00457000732421875 seconds
DEBUG 01-04 15:36:08.115585.115585 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.115069.115069 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.115496.115496 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.115205.115205 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88f7c37b-04ad-4e90-943b-3d2e246dc877
DEBUG 01-04 15:36:08.115579.115579 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.120162.120162 client.py:127] Model loaded
DEBUG 01-04 15:36:08.120810.120810 cuda_h.py:19] end wait_experts cost 0.010835886001586914 seconds
DEBUG 01-04 15:36:08.120892.120892 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.121224.121224 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:08.121518.121518 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88f7c37b-04ad-4e90-943b-3d2e246dc877
DEBUG 01-04 15:36:08.121845.121845 cuda_h.py:19] end load_into_gpu_async cost 0.006365776062011719 seconds
DEBUG 01-04 15:36:08.121078.121078 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.121598.121598 cuda_h.py:19] end restore_tensors2 cost 7.367134094238281e-05 seconds
DEBUG 01-04 15:36:08.121354.121354 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011331558227539062 seconds
DEBUG 01-04 15:36:08.121310.121310 mlpmodule.py:531] gpu group tensors cost 0.0008974075317382812 s
INFO 01-04 15:36:08.122030.122030 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88f7c37b-04ad-4e90-943b-3d2e246dc877
DEBUG 01-04 15:36:08.123626.123626 mlpmodule.py:564] gpu pad cost 0.0016129016876220703 s
DEBUG 01-04 15:36:08.124723.124723 mlpmodule.py:582] gpu group einsum cost 0.0004591941833496094 s
DEBUG 01-04 15:36:08.125413.125413 mlpmodule.py:662]  experts func einsum cost 0.05205202102661133 s
DEBUG 01-04 15:36:08.127921.127921 mlpmodule.py:611] gpu experts func einsum cost 0.006291627883911133 s
DEBUG 01-04 15:36:08.127356.127356 cuda_h.py:19] end gpu_experts cost 0.006524562835693359 seconds
DEBUG 01-04 15:36:08.127728.127728 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.132983.132983 client.py:127] Model loaded
DEBUG 01-04 15:36:08.132306.132306 cuda_h.py:19] end sllm_worker_task cost 0.02217721939086914 seconds
DEBUG 01-04 15:36:08.132110.132110 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0050508975982666016 seconds
DEBUG 01-04 15:36:08.132111.132111 cuda_h.py:19] end layer_moe_generate_17 cost 0.06680011749267578 seconds
DEBUG 01-04 15:36:08.133004.133004 lmp.py:207] -------------------------------- end layer 17 --------------------------------
DEBUG 01-04 15:36:08.133005.133005 lmp.py:169] -------------------------------- start layer 18 --------------------------------
DEBUG 01-04 15:36:08.133794.133794 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.133075.133075 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.135048.135048 cuda_h.py:19] end self_attn cost 0.0023136138916015625 seconds
DEBUG 01-04 15:36:08.136507.136507 cuda_h.py:19] end iln_self_attn_paln cost 0.0028853416442871094 seconds
DEBUG 01-04 15:36:08.136582.136582 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-04 15:36:08.136961.136961 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.136551.136551 cuda_h.py:19] end gate cost 0.0005779266357421875 seconds
DEBUG 01-04 15:36:08.136234.136234 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.137145.137145 lmp.py:281] 
DEBUG 01-04 15:36:08.137145.137145 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.137470.137470 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.137928.137928 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.137524.137524 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.137929.137929 lmp.py:285] 
DEBUG 01-04 15:36:08.137929.137929 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.137810.137810 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.137698.137698 lmp.py:292]   Expert 19 |      1 | CPU
DEBUG 01-04 15:36:08.137580.137580 lmp.py:292]   Expert 11 |      2 | CPU
DEBUG 01-04 15:36:08.137031.137031 lmp.py:292]   Expert 24 |      2 | CPU
DEBUG 01-04 15:36:08.137958.137958 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:08.137171.137171 lmp.py:292]   Expert 40 |      5 | CPU
DEBUG 01-04 15:36:08.137145.137145 lmp.py:292]   Expert 53 |      6 | CPU
DEBUG 01-04 15:36:08.137119.137119 lmp.py:292]   Expert 55 |      7 | CPU
DEBUG 01-04 15:36:08.137855.137855 lmp.py:292]   Expert 63 |      7 | CPU
DEBUG 01-04 15:36:08.137829.137829 lmp.py:292]   Expert 20 |      8 | CPU
DEBUG 01-04 15:36:08.137564.137564 lmp.py:292]   Expert 22 |      9 | CPU
DEBUG 01-04 15:36:08.137300.137300 lmp.py:292]   Expert 35 |      9 | CPU
DEBUG 01-04 15:36:08.137797.137797 lmp.py:292]   Expert 58 |     10 | CPU
DEBUG 01-04 15:36:08.137725.137725 lmp.py:292]   Expert 37 |     12 | CPU
DEBUG 01-04 15:36:08.137176.137176 lmp.py:292]   Expert  6 |     13 | CPU
DEBUG 01-04 15:36:08.137150.137150 lmp.py:292]   Expert 60 |     13 | CPU
DEBUG 01-04 15:36:08.137601.137601 lmp.py:292]   Expert 42 |     15 | CPU
DEBUG 01-04 15:36:08.137813.137813 lmp.py:292]   Expert 45 |     15 | CPU
DEBUG 01-04 15:36:08.137549.137549 lmp.py:292]   Expert 48 |     17 | CPU
DEBUG 01-04 15:36:08.137046.137046 lmp.py:292]   Expert 51 |     18 | CPU
DEBUG 01-04 15:36:08.137305.137305 lmp.py:292]   Expert 18 |     19 | CPU
DEBUG 01-04 15:36:08.137802.137802 lmp.py:292]   Expert 46 |     19 | CPU
DEBUG 01-04 15:36:08.137299.137299 lmp.py:292]   Expert 12 |     20 | CPU
DEBUG 01-04 15:36:08.137558.137558 lmp.py:292]   Expert 33 |     21 | CPU
DEBUG 01-04 15:36:08.137055.137055 lmp.py:292]   Expert 13 |     23 | CPU
DEBUG 01-04 15:36:08.137791.137791 lmp.py:292]   Expert 17 |     24 | CPU
DEBUG 01-04 15:36:08.137765.137765 lmp.py:292]   Expert 54 |     25 | CPU
DEBUG 01-04 15:36:08.137752.137752 lmp.py:292]   Expert 41 |     26 | CPU
DEBUG 01-04 15:36:08.137250.137250 lmp.py:292]   Expert 29 |     27 | CPU
DEBUG 01-04 15:36:08.137747.137747 lmp.py:292]   Expert 44 |     28 | CPU
DEBUG 01-04 15:36:08.137244.137244 lmp.py:292]   Expert  7 |     29 | CPU
DEBUG 01-04 15:36:08.137503.137503 lmp.py:292]   Expert 56 |     29 | CPU
DEBUG 01-04 15:36:08.137523.137523 lmp.py:292]   Expert 27 |     31 | CPU
DEBUG 01-04 15:36:08.137544.137544 lmp.py:292]   Expert  9 |     33 | GPU
DEBUG 01-04 15:36:08.137326.137326 lmp.py:292]   Expert 10 |     33 | GPU
DEBUG 01-04 15:36:08.137346.137346 lmp.py:292]   Expert 59 |     36 | GPU
DEBUG 01-04 15:36:08.137889.137889 lmp.py:292]   Expert 52 |     39 | GPU
DEBUG 01-04 15:36:08.137433.137433 lmp.py:292]   Expert 31 |     41 | GPU
DEBUG 01-04 15:36:08.137738.137738 lmp.py:292]   Expert 32 |     42 | GPU
DEBUG 01-04 15:36:08.137520.137520 lmp.py:292]   Expert 39 |     42 | GPU
DEBUG 01-04 15:36:08.137064.137064 lmp.py:292]   Expert 21 |     44 | GPU
DEBUG 01-04 15:36:08.137607.137607 lmp.py:292]   Expert 47 |     45 | GPU
DEBUG 01-04 15:36:08.137866.137866 lmp.py:292]   Expert 28 |     46 | GPU
DEBUG 01-04 15:36:08.137363.137363 lmp.py:292]   Expert 30 |     46 | GPU
DEBUG 01-04 15:36:08.137622.137622 lmp.py:292]   Expert 50 |     48 | GPU
DEBUG 01-04 15:36:08.137881.137881 lmp.py:292]   Expert  8 |     49 | GPU
DEBUG 01-04 15:36:08.137378.137378 lmp.py:292]   Expert 43 |     51 | GPU
DEBUG 01-04 15:36:08.137683.137683 lmp.py:292]   Expert 25 |     56 | GPU
DEBUG 01-04 15:36:08.137227.137227 lmp.py:292]   Expert 61 |     61 | GPU
DEBUG 01-04 15:36:08.137009.137009 lmp.py:292]   Expert 14 |     67 | GPU
DEBUG 01-04 15:36:08.137790.137790 lmp.py:292]   Expert 57 |     69 | GPU
DEBUG 01-04 15:36:08.137334.137334 lmp.py:292]   Expert 16 |     72 | GPU
DEBUG 01-04 15:36:08.137878.137878 lmp.py:292]   Expert 26 |     85 | GPU
DEBUG 01-04 15:36:08.137898.137898 lmp.py:292]   Expert 49 |     87 | GPU
DEBUG 01-04 15:36:08.138157.138157 lmp.py:292]   Expert 38 |     88 | GPU
DEBUG 01-04 15:36:08.138177.138177 lmp.py:292]   Expert 15 |    101 | GPU
DEBUG 01-04 15:36:08.138436.138436 lmp.py:292]   Expert 23 |    103 | GPU
DEBUG 01-04 15:36:08.138456.138456 lmp.py:292]   Expert 62 |    140 | GPU
DEBUG 01-04 15:36:08.138477.138477 lmp.py:292]   Expert 36 |    148 | GPU
DEBUG 01-04 15:36:08.138497.138497 lmp.py:292]   Expert  0 |   1665 | GPU
DEBUG 01-04 15:36:08.138041.138041 lmp.py:292]   Expert  3 |   1672 | GPU
DEBUG 01-04 15:36:08.138346.138346 lmp.py:292]   Expert  4 |   1674 | GPU
DEBUG 01-04 15:36:08.138651.138651 lmp.py:292]   Expert  1 |   1679 | GPU
DEBUG 01-04 15:36:08.138194.138194 lmp.py:292]   Expert  5 |   1684 | GPU
DEBUG 01-04 15:36:08.138976.138976 lmp.py:292]   Expert  2 |   1750 | GPU
DEBUG 01-04 15:36:08.138997.138997 lmp.py:293] 
DEBUG 01-04 15:36:08.138997.138997 lmp.py:293]   CPU total tokens: 492 (4.0%)
DEBUG 01-04 15:36:08.138494.138494 lmp.py:294]   GPU total tokens: 11796 (96.0%)
DEBUG 01-04 15:36:08.138521.138521 cuda_h.py:19] end experts_map_get cost 0.0014133453369140625 seconds
DEBUG 01-04 15:36:08.138257.138257 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.138556.138556 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.138064.138064 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.138907.138907 cuda_h.py:19] end allocate_cuda_memory cost 0.00023889541625976562 seconds
DEBUG 01-04 15:36:08.138936.138936 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.138592.138592 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.138971.138971 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.138144.138144 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c19e8d57-467a-4769-b947-015d36ce5f53
DEBUG 01-04 15:36:08.138454.138454 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.140068.140068 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c19e8d57-467a-4769-b947-015d36ce5f53
DEBUG 01-04 15:36:08.141543.141543 cuda_h.py:19] end load_into_gpu_async cost 0.002263307571411133 seconds
DEBUG 01-04 15:36:08.141982.141982 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.141691.141691 cuda_h.py:19] end restore_tensors2 cost 0.0007405281066894531 seconds
DEBUG 01-04 15:36:08.141315.141315 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003663778305053711 seconds
DEBUG 01-04 15:36:08.144045.144045 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006101131439208984 seconds
DEBUG 01-04 15:36:08.144166.144166 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.144480.144480 lmp.py:339] 
DEBUG 01-04 15:36:08.144480.144480 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.144184.144184 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-04 15:36:08.144264.144264 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.155472.155472 mlpmodule.py:704] group tensors cost 0.010474681854248047 s
DEBUG 01-04 15:36:08.160442.160442 mlpmodule.py:742] pad cost 0.004401206970214844 s
DEBUG 01-04 15:36:08.160294.160294 mlpmodule.py:748] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-04 15:36:08.160018.160018 mlpmodule.py:753] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-04 15:36:08.165016.165016 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.165357.165357 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.165591.165591 mlpmodule.py:774] group_w3 first element: -0.0247802734375
WARNING 01-04 15:36:08.166138.166138 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.170976.170976 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.170585.170585 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.174549.174549 mlpmodule.py:797] group einsum cost 0.013827085494995117 s
DEBUG 01-04 15:36:08.175325.175325 mlpmodule.py:805] cpy2cputensor cost 0.00015163421630859375 s
DEBUG 01-04 15:36:08.180340.180340 cuda_h.py:19] end wait_cetm_experts cost 0.03574633598327637 seconds
DEBUG 01-04 15:36:08.180102.180102 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.181737.181737 cuda_h.py:19] end gpu_sexperts cost 0.0007162094116210938 seconds
DEBUG 01-04 15:36:08.181103.181103 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-04 15:36:08.181588.181588 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-04 15:36:08.181650.181650 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.291534423828125e-05 seconds
DEBUG 01-04 15:36:08.181852.181852 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.181139.181139 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.0001971721649169922 seconds
DEBUG 01-04 15:36:08.181036.181036 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.181377.181377 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.182767.182767 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c19e8d57-467a-4769-b947-015d36ce5f53
DEBUG 01-04 15:36:08.182976.182976 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.186494.186494 cuda_h.py:19] end allocate_cuda_memory cost 0.004297733306884766 seconds
DEBUG 01-04 15:36:08.186737.186737 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.186944.186944 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.186250.186250 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.186291.186291 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d120c4e2-25e3-47b0-ba2d-ed25120299c1
DEBUG 01-04 15:36:08.187910.187910 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.192923.192923 client.py:127] Model loaded
DEBUG 01-04 15:36:08.192051.192051 cuda_h.py:19] end wait_experts cost 0.010084390640258789 seconds
DEBUG 01-04 15:36:08.192277.192277 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.192026.192026 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.192642.192642 mlpmodule.py:531] gpu group tensors cost 0.0005211830139160156 s
INFO 01-04 15:36:08.193719.193719 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d120c4e2-25e3-47b0-ba2d-ed25120299c1
DEBUG 01-04 15:36:08.193377.193377 cuda_h.py:19] end load_into_gpu_async cost 0.0066051483154296875 seconds
DEBUG 01-04 15:36:08.193987.193987 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.193885.193885 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-04 15:36:08.193641.193641 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011584758758544922 seconds
INFO 01-04 15:36:08.194069.194069 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d120c4e2-25e3-47b0-ba2d-ed25120299c1
DEBUG 01-04 15:36:08.195308.195308 mlpmodule.py:564] gpu pad cost 0.0022292137145996094 s
DEBUG 01-04 15:36:08.195316.195316 mlpmodule.py:582] gpu group einsum cost 0.0003581047058105469 s
DEBUG 01-04 15:36:08.196142.196142 mlpmodule.py:662]  experts func einsum cost 0.052101850509643555 s
DEBUG 01-04 15:36:08.198423.198423 mlpmodule.py:611] gpu experts func einsum cost 0.006212472915649414 s
DEBUG 01-04 15:36:08.198328.198328 cuda_h.py:19] end gpu_experts cost 0.006437778472900391 seconds
DEBUG 01-04 15:36:08.198415.198415 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.205461.205461 client.py:127] Model loaded
DEBUG 01-04 15:36:08.205035.205035 cuda_h.py:19] end sllm_worker_task cost 0.024080276489257812 seconds
DEBUG 01-04 15:36:08.206605.206605 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00740504264831543 seconds
DEBUG 01-04 15:36:08.206465.206465 cuda_h.py:19] end layer_moe_generate_18 cost 0.07024693489074707 seconds
DEBUG 01-04 15:36:08.206312.206312 lmp.py:207] -------------------------------- end layer 18 --------------------------------
DEBUG 01-04 15:36:08.206889.206889 lmp.py:169] -------------------------------- start layer 19 --------------------------------
DEBUG 01-04 15:36:08.206393.206393 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.206482.206482 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.209515.209515 cuda_h.py:19] end self_attn cost 0.0023183822631835938 seconds
DEBUG 01-04 15:36:08.209220.209220 cuda_h.py:19] end iln_self_attn_paln cost 0.0028984546661376953 seconds
DEBUG 01-04 15:36:08.209625.209625 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-04 15:36:08.209719.209719 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.210937.210937 cuda_h.py:19] end gate cost 0.00054931640625 seconds
DEBUG 01-04 15:36:08.210760.210760 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.210749.210749 lmp.py:281] 
DEBUG 01-04 15:36:08.210749.210749 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.210168.210168 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.210433.210433 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.210076.210076 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.210812.210812 lmp.py:285] 
DEBUG 01-04 15:36:08.210812.210812 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.210547.210547 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.210767.210767 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:08.210741.210741 lmp.py:292]   Expert 18 |      1 | CPU
DEBUG 01-04 15:36:08.210523.210523 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:08.210781.210781 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:08.210325.210325 lmp.py:292]   Expert 23 |      6 | CPU
DEBUG 01-04 15:36:08.210345.210345 lmp.py:292]   Expert 37 |      6 | CPU
DEBUG 01-04 15:36:08.210319.210319 lmp.py:292]   Expert 56 |      8 | CPU
DEBUG 01-04 15:36:08.210817.210817 lmp.py:292]   Expert 60 |      8 | CPU
DEBUG 01-04 15:36:08.210837.210837 lmp.py:292]   Expert 28 |      9 | CPU
DEBUG 01-04 15:36:08.210096.210096 lmp.py:292]   Expert 12 |     12 | CPU
DEBUG 01-04 15:36:08.210070.210070 lmp.py:292]   Expert 32 |     15 | CPU
DEBUG 01-04 15:36:08.210090.210090 lmp.py:292]   Expert 49 |     15 | CPU
DEBUG 01-04 15:36:08.210872.210872 lmp.py:292]   Expert 14 |     16 | CPU
DEBUG 01-04 15:36:08.210654.210654 lmp.py:292]   Expert 22 |     17 | CPU
DEBUG 01-04 15:36:08.210674.210674 lmp.py:292]   Expert 30 |     17 | CPU
DEBUG 01-04 15:36:08.210218.210218 lmp.py:292]   Expert 43 |     18 | CPU
DEBUG 01-04 15:36:08.210238.210238 lmp.py:292]   Expert 44 |     18 | CPU
DEBUG 01-04 15:36:08.210782.210782 lmp.py:292]   Expert 59 |     19 | CPU
DEBUG 01-04 15:36:08.210802.210802 lmp.py:292]   Expert 15 |     20 | CPU
DEBUG 01-04 15:36:08.210584.210584 lmp.py:292]   Expert 42 |     20 | CPU
DEBUG 01-04 15:36:08.210128.210128 lmp.py:292]   Expert 40 |     22 | CPU
DEBUG 01-04 15:36:08.210148.210148 lmp.py:292]   Expert 46 |     22 | CPU
DEBUG 01-04 15:36:08.210930.210930 lmp.py:292]   Expert 19 |     24 | CPU
DEBUG 01-04 15:36:08.210712.210712 lmp.py:292]   Expert 25 |     24 | CPU
DEBUG 01-04 15:36:08.210255.210255 lmp.py:292]   Expert 34 |     26 | CPU
DEBUG 01-04 15:36:08.210276.210276 lmp.py:292]   Expert 24 |     27 | CPU
DEBUG 01-04 15:36:08.210058.210058 lmp.py:292]   Expert  8 |     29 | CPU
DEBUG 01-04 15:36:08.211555.211555 lmp.py:292]   Expert 52 |     29 | CPU
DEBUG 01-04 15:36:08.211052.211052 lmp.py:292]   Expert 26 |     30 | CPU
DEBUG 01-04 15:36:08.211549.211549 lmp.py:292]   Expert 53 |     31 | CPU
DEBUG 01-04 15:36:08.211047.211047 lmp.py:292]   Expert 58 |     33 | CPU
DEBUG 01-04 15:36:08.211305.211305 lmp.py:292]   Expert 20 |     34 | CPU
DEBUG 01-04 15:36:08.211326.211326 lmp.py:292]   Expert 35 |     36 | GPU
DEBUG 01-04 15:36:08.211108.211108 lmp.py:292]   Expert 39 |     36 | GPU
DEBUG 01-04 15:36:08.211651.211651 lmp.py:292]   Expert 57 |     36 | GPU
DEBUG 01-04 15:36:08.211433.211433 lmp.py:292]   Expert 50 |     37 | GPU
DEBUG 01-04 15:36:08.211215.211215 lmp.py:292]   Expert 48 |     38 | GPU
DEBUG 01-04 15:36:08.211997.211997 lmp.py:292]   Expert 54 |     38 | GPU
DEBUG 01-04 15:36:08.211541.211541 lmp.py:292]   Expert 61 |     42 | GPU
DEBUG 01-04 15:36:08.211323.211323 lmp.py:292]   Expert 62 |     42 | GPU
DEBUG 01-04 15:36:08.211866.211866 lmp.py:292]   Expert 27 |     44 | GPU
DEBUG 01-04 15:36:08.211410.211410 lmp.py:292]   Expert 31 |     44 | GPU
DEBUG 01-04 15:36:08.211192.211192 lmp.py:292]   Expert 63 |     45 | GPU
DEBUG 01-04 15:36:08.211974.211974 lmp.py:292]   Expert 17 |     46 | GPU
DEBUG 01-04 15:36:08.211517.211517 lmp.py:292]   Expert 13 |     47 | GPU
DEBUG 01-04 15:36:08.211299.211299 lmp.py:292]   Expert 16 |     49 | GPU
DEBUG 01-04 15:36:08.211319.211319 lmp.py:292]   Expert 36 |     50 | GPU
DEBUG 01-04 15:36:08.211863.211863 lmp.py:292]   Expert 47 |     51 | GPU
DEBUG 01-04 15:36:08.211122.211122 lmp.py:292]   Expert 21 |     55 | GPU
DEBUG 01-04 15:36:08.211619.211619 lmp.py:292]   Expert 11 |     56 | GPU
DEBUG 01-04 15:36:08.211878.211878 lmp.py:292]   Expert  9 |     60 | GPU
DEBUG 01-04 15:36:08.211137.211137 lmp.py:292]   Expert 10 |     65 | GPU
DEBUG 01-04 15:36:08.211395.211395 lmp.py:292]   Expert 51 |     67 | GPU
DEBUG 01-04 15:36:08.211939.211939 lmp.py:292]   Expert 45 |     75 | GPU
DEBUG 01-04 15:36:08.211482.211482 lmp.py:292]   Expert 41 |     88 | GPU
DEBUG 01-04 15:36:08.211026.211026 lmp.py:292]   Expert 38 |     93 | GPU
DEBUG 01-04 15:36:08.211569.211569 lmp.py:292]   Expert  7 |    100 | GPU
DEBUG 01-04 15:36:08.211113.211113 lmp.py:292]   Expert 29 |    177 | GPU
DEBUG 01-04 15:36:08.211895.211895 lmp.py:292]   Expert  5 |   1670 | GPU
DEBUG 01-04 15:36:08.211200.211200 lmp.py:292]   Expert  4 |   1681 | GPU
DEBUG 01-04 15:36:08.211982.211982 lmp.py:292]   Expert  1 |   1701 | GPU
DEBUG 01-04 15:36:08.211526.211526 lmp.py:292]   Expert  2 |   1708 | GPU
DEBUG 01-04 15:36:08.211069.211069 lmp.py:292]   Expert  0 |   1723 | GPU
DEBUG 01-04 15:36:08.211613.211613 lmp.py:292]   Expert  3 |   1725 | GPU
DEBUG 01-04 15:36:08.211633.211633 lmp.py:293] 
DEBUG 01-04 15:36:08.211633.211633 lmp.py:293]   CPU total tokens: 563 (4.6%)
DEBUG 01-04 15:36:08.211369.211369 lmp.py:294]   GPU total tokens: 11725 (95.4%)
DEBUG 01-04 15:36:08.211396.211396 cuda_h.py:19] end experts_map_get cost 0.001355886459350586 seconds
DEBUG 01-04 15:36:08.211085.211085 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.211385.211385 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.211800.211800 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.212729.212729 cuda_h.py:19] end allocate_cuda_memory cost 0.0002346038818359375 seconds
DEBUG 01-04 15:36:08.212188.212188 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.212606.212606 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.212746.212746 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.212204.212204 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 062e2a10-8c55-4092-825b-09e542581a6f
DEBUG 01-04 15:36:08.212805.212805 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.214022.214022 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 062e2a10-8c55-4092-825b-09e542581a6f
DEBUG 01-04 15:36:08.214682.214682 cuda_h.py:19] end load_into_gpu_async cost 0.0022492408752441406 seconds
DEBUG 01-04 15:36:08.214545.214545 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.215652.215652 cuda_h.py:19] end restore_tensors2 cost 0.0007550716400146484 seconds
DEBUG 01-04 15:36:08.215945.215945 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003657817840576172 seconds
DEBUG 01-04 15:36:08.217539.217539 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006207942962646484 seconds
DEBUG 01-04 15:36:08.217507.217507 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.217940.217940 lmp.py:339] 
DEBUG 01-04 15:36:08.217940.217940 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.218638.218638 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-04 15:36:08.218049.218049 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.229137.229137 mlpmodule.py:704] group tensors cost 0.011030912399291992 s
DEBUG 01-04 15:36:08.234590.234590 mlpmodule.py:742] pad cost 0.003435373306274414 s
DEBUG 01-04 15:36:08.234469.234469 mlpmodule.py:748] create cpu tensor cost 6.437301635742188e-05 s
DEBUG 01-04 15:36:08.234459.234459 mlpmodule.py:753] move to cpu cost 4.57763671875e-05 s
DEBUG 01-04 15:36:08.238797.238797 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.238681.238681 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.238452.238452 mlpmodule.py:774] group_w3 first element: -0.0576171875
WARNING 01-04 15:36:08.238277.238277 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.242322.242322 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.242264.242264 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.246855.246855 mlpmodule.py:797] group einsum cost 0.012175798416137695 s
DEBUG 01-04 15:36:08.246207.246207 mlpmodule.py:805] cpy2cputensor cost 0.00016045570373535156 s
DEBUG 01-04 15:36:08.252485.252485 cuda_h.py:19] end wait_cetm_experts cost 0.03390336036682129 seconds
DEBUG 01-04 15:36:08.252738.252738 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.252004.252004 cuda_h.py:19] end gpu_sexperts cost 0.0006115436553955078 seconds
DEBUG 01-04 15:36:08.252463.252463 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-04 15:36:08.253578.253578 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-04 15:36:08.253971.253971 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 4.220008850097656e-05 seconds
DEBUG 01-04 15:36:08.253655.253655 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 9.72747802734375e-05 seconds
DEBUG 01-04 15:36:08.253642.253642 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.253021.253021 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 062e2a10-8c55-4092-825b-09e542581a6f
DEBUG 01-04 15:36:08.253981.253981 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.253363.253363 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.253259.253259 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.258297.258297 cuda_h.py:19] end allocate_cuda_memory cost 0.005042552947998047 seconds
DEBUG 01-04 15:36:08.258426.258426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.258811.258811 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.258728.258728 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.258391.258391 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c800e632-63db-43fd-8260-28e575df1ea5
DEBUG 01-04 15:36:08.259057.259057 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.264709.264709 client.py:127] Model loaded
DEBUG 01-04 15:36:08.264797.264797 cuda_h.py:19] end wait_experts cost 0.011317253112792969 seconds
DEBUG 01-04 15:36:08.264262.264262 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.264249.264249 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.265342.265342 mlpmodule.py:531] gpu group tensors cost 0.0005207061767578125 s
INFO 01-04 15:36:08.265716.265716 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c800e632-63db-43fd-8260-28e575df1ea5
DEBUG 01-04 15:36:08.265400.265400 cuda_h.py:19] end load_into_gpu_async cost 0.0067043304443359375 seconds
DEBUG 01-04 15:36:08.265342.265342 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.265908.265908 cuda_h.py:19] end restore_tensors2 cost 7.486343383789062e-05 seconds
DEBUG 01-04 15:36:08.265426.265426 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012125730514526367 seconds
INFO 01-04 15:36:08.266848.266848 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c800e632-63db-43fd-8260-28e575df1ea5
DEBUG 01-04 15:36:08.267306.267306 mlpmodule.py:564] gpu pad cost 0.002240419387817383 s
DEBUG 01-04 15:36:08.267668.267668 mlpmodule.py:582] gpu group einsum cost 0.0004439353942871094 s
DEBUG 01-04 15:36:08.269260.269260 mlpmodule.py:662]  experts func einsum cost 0.050751447677612305 s
DEBUG 01-04 15:36:08.270138.270138 mlpmodule.py:611] gpu experts func einsum cost 0.006294965744018555 s
DEBUG 01-04 15:36:08.271752.271752 cuda_h.py:19] end gpu_experts cost 0.006516218185424805 seconds
DEBUG 01-04 15:36:08.271555.271555 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.275439.275439 client.py:127] Model loaded
DEBUG 01-04 15:36:08.276442.276442 cuda_h.py:19] end sllm_worker_task cost 0.02253437042236328 seconds
DEBUG 01-04 15:36:08.276768.276768 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004973173141479492 seconds
DEBUG 01-04 15:36:08.276681.276681 cuda_h.py:19] end layer_moe_generate_19 cost 0.06668758392333984 seconds
DEBUG 01-04 15:36:08.276865.276865 lmp.py:207] -------------------------------- end layer 19 --------------------------------
DEBUG 01-04 15:36:08.276774.276774 lmp.py:169] -------------------------------- start layer 20 --------------------------------
DEBUG 01-04 15:36:08.276562.276562 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.276121.276121 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.279849.279849 cuda_h.py:19] end self_attn cost 0.0023109912872314453 seconds
DEBUG 01-04 15:36:08.279732.279732 cuda_h.py:19] end iln_self_attn_paln cost 0.0028710365295410156 seconds
DEBUG 01-04 15:36:08.279423.279423 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-04 15:36:08.279563.279563 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.280768.280768 cuda_h.py:19] end gate cost 0.0005400180816650391 seconds
DEBUG 01-04 15:36:08.280829.280829 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.280864.280864 lmp.py:281] 
DEBUG 01-04 15:36:08.280864.280864 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.280985.280985 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.280681.280681 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.280040.280040 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.280206.280206 lmp.py:285] 
DEBUG 01-04 15:36:08.280206.280206 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.280134.280134 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.280830.280830 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:08.280996.280996 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:08.280208.280208 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:08.280182.280182 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:08.280348.280348 lmp.py:292]   Expert 61 |      4 | CPU
DEBUG 01-04 15:36:08.280038.280038 lmp.py:292]   Expert 10 |      5 | CPU
DEBUG 01-04 15:36:08.280727.280727 lmp.py:292]   Expert 18 |      6 | CPU
DEBUG 01-04 15:36:08.280178.280178 lmp.py:292]   Expert 33 |      6 | CPU
DEBUG 01-04 15:36:08.280629.280629 lmp.py:292]   Expert 28 |      9 | CPU
DEBUG 01-04 15:36:08.280364.280364 lmp.py:292]   Expert 54 |      9 | CPU
DEBUG 01-04 15:36:08.280338.280338 lmp.py:292]   Expert 63 |      9 | CPU
DEBUG 01-04 15:36:08.280597.280597 lmp.py:292]   Expert 19 |     11 | CPU
DEBUG 01-04 15:36:08.280094.280094 lmp.py:292]   Expert 42 |     11 | CPU
DEBUG 01-04 15:36:08.280068.280068 lmp.py:292]   Expert 50 |     12 | CPU
DEBUG 01-04 15:36:08.280804.280804 lmp.py:292]   Expert 43 |     14 | CPU
DEBUG 01-04 15:36:08.280301.280301 lmp.py:292]   Expert 47 |     16 | CPU
DEBUG 01-04 15:36:08.280037.280037 lmp.py:292]   Expert  9 |     17 | CPU
DEBUG 01-04 15:36:08.280773.280773 lmp.py:292]   Expert 30 |     19 | CPU
DEBUG 01-04 15:36:08.280508.280508 lmp.py:292]   Expert 36 |     20 | CPU
DEBUG 01-04 15:36:08.280959.280959 lmp.py:292]   Expert 37 |     21 | CPU
DEBUG 01-04 15:36:08.280172.280172 lmp.py:292]   Expert  8 |     23 | CPU
DEBUG 01-04 15:36:08.280384.280384 lmp.py:292]   Expert 17 |     24 | CPU
DEBUG 01-04 15:36:08.280358.280358 lmp.py:292]   Expert 23 |     24 | CPU
DEBUG 01-04 15:36:08.280571.280571 lmp.py:292]   Expert 58 |     24 | CPU
DEBUG 01-04 15:36:08.280068.280068 lmp.py:292]   Expert 49 |     25 | CPU
DEBUG 01-04 15:36:08.280803.280803 lmp.py:292]   Expert 13 |     27 | CPU
DEBUG 01-04 15:36:08.280301.280301 lmp.py:292]   Expert 27 |     27 | CPU
DEBUG 01-04 15:36:08.280036.280036 lmp.py:292]   Expert 46 |     27 | CPU
DEBUG 01-04 15:36:08.280533.280533 lmp.py:292]   Expert  7 |     29 | CPU
DEBUG 01-04 15:36:08.280507.280507 lmp.py:292]   Expert 14 |     29 | CPU
DEBUG 01-04 15:36:08.281243.281243 lmp.py:292]   Expert 57 |     29 | CPU
DEBUG 01-04 15:36:08.281217.281217 lmp.py:292]   Expert 39 |     31 | CPU
DEBUG 01-04 15:36:08.281191.281191 lmp.py:292]   Expert 12 |     34 | GPU
DEBUG 01-04 15:36:08.281688.281688 lmp.py:292]   Expert 45 |     34 | GPU
DEBUG 01-04 15:36:08.281662.281662 lmp.py:292]   Expert 11 |     35 | GPU
DEBUG 01-04 15:36:08.281636.281636 lmp.py:292]   Expert 26 |     36 | GPU
DEBUG 01-04 15:36:08.281087.281087 lmp.py:292]   Expert 62 |     36 | GPU
DEBUG 01-04 15:36:08.281538.281538 lmp.py:292]   Expert 20 |     39 | GPU
DEBUG 01-04 15:36:08.281989.281989 lmp.py:292]   Expert 60 |     39 | GPU
DEBUG 01-04 15:36:08.281486.281486 lmp.py:292]   Expert 53 |     48 | GPU
DEBUG 01-04 15:36:08.281222.281222 lmp.py:292]   Expert 21 |     49 | GPU
DEBUG 01-04 15:36:08.281719.281719 lmp.py:292]   Expert 22 |     50 | GPU
DEBUG 01-04 15:36:08.281455.281455 lmp.py:292]   Expert 24 |     53 | GPU
DEBUG 01-04 15:36:08.281714.281714 lmp.py:292]   Expert 40 |     53 | GPU
DEBUG 01-04 15:36:08.281972.281972 lmp.py:292]   Expert 38 |     54 | GPU
DEBUG 01-04 15:36:08.281708.281708 lmp.py:292]   Expert 52 |     54 | GPU
DEBUG 01-04 15:36:08.281967.281967 lmp.py:292]   Expert 16 |     56 | GPU
DEBUG 01-04 15:36:08.281464.281464 lmp.py:292]   Expert 15 |     62 | GPU
DEBUG 01-04 15:36:08.281961.281961 lmp.py:292]   Expert 34 |     64 | GPU
DEBUG 01-04 15:36:08.281650.281650 lmp.py:292]   Expert 59 |     69 | GPU
DEBUG 01-04 15:36:08.281101.281101 lmp.py:292]   Expert 55 |     70 | GPU
DEBUG 01-04 15:36:08.281075.281075 lmp.py:292]   Expert 56 |     74 | GPU
DEBUG 01-04 15:36:08.281765.281765 lmp.py:292]   Expert 32 |     79 | GPU
DEBUG 01-04 15:36:08.281500.281500 lmp.py:292]   Expert 48 |     82 | GPU
DEBUG 01-04 15:36:08.281998.281998 lmp.py:292]   Expert 31 |     83 | GPU
DEBUG 01-04 15:36:08.281495.281495 lmp.py:292]   Expert 35 |     93 | GPU
DEBUG 01-04 15:36:08.281754.281754 lmp.py:292]   Expert 25 |     94 | GPU
DEBUG 01-04 15:36:08.281774.281774 lmp.py:292]   Expert 41 |    133 | GPU
DEBUG 01-04 15:36:08.281510.281510 lmp.py:292]   Expert  5 |   1670 | GPU
DEBUG 01-04 15:36:08.281768.281768 lmp.py:292]   Expert  1 |   1675 | GPU
DEBUG 01-04 15:36:08.281266.281266 lmp.py:292]   Expert  3 |   1675 | GPU
DEBUG 01-04 15:36:08.281763.281763 lmp.py:292]   Expert  2 |   1692 | GPU
DEBUG 01-04 15:36:08.281260.281260 lmp.py:292]   Expert  0 |   1717 | GPU
DEBUG 01-04 15:36:08.281757.281757 lmp.py:292]   Expert  4 |   1769 | GPU
DEBUG 01-04 15:36:08.281877.281877 lmp.py:293] 
DEBUG 01-04 15:36:08.281877.281877 lmp.py:293]   CPU total tokens: 517 (4.2%)
DEBUG 01-04 15:36:08.281043.281043 lmp.py:294]   GPU total tokens: 11771 (95.8%)
DEBUG 01-04 15:36:08.281230.281230 cuda_h.py:19] end experts_map_get cost 0.0014641284942626953 seconds
DEBUG 01-04 15:36:08.281442.281442 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.281834.281834 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.281481.281481 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.282086.282086 cuda_h.py:19] end allocate_cuda_memory cost 0.00024056434631347656 seconds
DEBUG 01-04 15:36:08.282591.282591 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.282248.282248 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.282017.282017 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.282713.282713 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1f0c9aa0-8548-4b37-8e16-ff7a2515f158
DEBUG 01-04 15:36:08.282308.282308 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.284789.284789 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1f0c9aa0-8548-4b37-8e16-ff7a2515f158
DEBUG 01-04 15:36:08.284562.284562 cuda_h.py:19] end load_into_gpu_async cost 0.0022351741790771484 seconds
DEBUG 01-04 15:36:08.284909.284909 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.285962.285962 cuda_h.py:19] end restore_tensors2 cost 0.0007126331329345703 seconds
DEBUG 01-04 15:36:08.285970.285970 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036253929138183594 seconds
DEBUG 01-04 15:36:08.287039.287039 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006138324737548828 seconds
DEBUG 01-04 15:36:08.287961.287961 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.287394.287394 lmp.py:339] 
DEBUG 01-04 15:36:08.287394.287394 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.287045.287045 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-04 15:36:08.287980.287980 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.298670.298670 mlpmodule.py:704] group tensors cost 0.010219097137451172 s
DEBUG 01-04 15:36:08.302017.302017 mlpmodule.py:742] pad cost 0.0029647350311279297 s
DEBUG 01-04 15:36:08.302818.302818 mlpmodule.py:748] create cpu tensor cost 6.747245788574219e-05 s
DEBUG 01-04 15:36:08.302225.302225 mlpmodule.py:753] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-04 15:36:08.306658.306658 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.306031.306031 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.306827.306827 mlpmodule.py:774] group_w3 first element: -0.052734375
WARNING 01-04 15:36:08.307123.307123 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.311620.311620 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.311163.311163 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.314290.314290 mlpmodule.py:797] group einsum cost 0.012399673461914062 s
DEBUG 01-04 15:36:08.315299.315299 mlpmodule.py:805] cpy2cputensor cost 0.0001900196075439453 s
DEBUG 01-04 15:36:08.320976.320976 cuda_h.py:19] end wait_cetm_experts cost 0.03225135803222656 seconds
DEBUG 01-04 15:36:08.320004.320004 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.321036.321036 cuda_h.py:19] end gpu_sexperts cost 0.0007007122039794922 seconds
DEBUG 01-04 15:36:08.321853.321853 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-04 15:36:08.321219.321219 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-04 15:36:08.321402.321402 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 4.673004150390625e-05 seconds
DEBUG 01-04 15:36:08.321337.321337 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00011301040649414062 seconds
DEBUG 01-04 15:36:08.321246.321246 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.321592.321592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1f0c9aa0-8548-4b37-8e16-ff7a2515f158
DEBUG 01-04 15:36:08.321952.321952 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.322763.322763 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.322309.322309 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.326564.326564 cuda_h.py:19] end allocate_cuda_memory cost 0.0042073726654052734 seconds
DEBUG 01-04 15:36:08.326231.326231 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.326292.326292 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.326075.326075 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.326024.326024 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a67e1ab6-c447-4b86-9773-89fa94fe2bf0
DEBUG 01-04 15:36:08.326636.326636 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.334614.334614 client.py:127] Model loaded
DEBUG 01-04 15:36:08.334034.334034 cuda_h.py:19] end wait_experts cost 0.013006448745727539 seconds
DEBUG 01-04 15:36:08.334651.334651 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.334546.334546 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.335426.335426 mlpmodule.py:531] gpu group tensors cost 0.0005064010620117188 s
INFO 01-04 15:36:08.335646.335646 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a67e1ab6-c447-4b86-9773-89fa94fe2bf0
DEBUG 01-04 15:36:08.335204.335204 cuda_h.py:19] end load_into_gpu_async cost 0.009030342102050781 seconds
DEBUG 01-04 15:36:08.335430.335430 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.335089.335089 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-04 15:36:08.335560.335560 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.013671159744262695 seconds
INFO 01-04 15:36:08.336353.336353 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a67e1ab6-c447-4b86-9773-89fa94fe2bf0
DEBUG 01-04 15:36:08.336559.336559 mlpmodule.py:662]  experts func einsum cost 0.048488616943359375 s
DEBUG 01-04 15:36:08.337473.337473 mlpmodule.py:564] gpu pad cost 0.0023250579833984375 s
DEBUG 01-04 15:36:08.338604.338604 mlpmodule.py:582] gpu group einsum cost 0.00043320655822753906 s
DEBUG 01-04 15:36:08.341857.341857 mlpmodule.py:611] gpu experts func einsum cost 0.006265401840209961 s
DEBUG 01-04 15:36:08.341112.341112 cuda_h.py:19] end gpu_experts cost 0.006423234939575195 seconds
DEBUG 01-04 15:36:08.341722.341722 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.346558.346558 client.py:127] Model loaded
DEBUG 01-04 15:36:08.346838.346838 cuda_h.py:19] end sllm_worker_task cost 0.0243990421295166 seconds
DEBUG 01-04 15:36:08.346498.346498 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00532221794128418 seconds
DEBUG 01-04 15:36:08.346796.346796 cuda_h.py:19] end layer_moe_generate_20 cost 0.06746506690979004 seconds
DEBUG 01-04 15:36:08.347094.347094 lmp.py:207] -------------------------------- end layer 20 --------------------------------
DEBUG 01-04 15:36:08.347098.347098 lmp.py:169] -------------------------------- start layer 21 --------------------------------
DEBUG 01-04 15:36:08.347478.347478 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.348248.348248 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.353652.353652 cuda_h.py:19] end self_attn cost 0.005400180816650391 seconds
DEBUG 01-04 15:36:08.354140.354140 cuda_h.py:19] end iln_self_attn_paln cost 0.006661653518676758 seconds
DEBUG 01-04 15:36:08.354375.354375 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-04 15:36:08.354047.354047 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.355717.355717 cuda_h.py:19] end gate cost 0.0009524822235107422 seconds
DEBUG 01-04 15:36:08.355170.355170 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.356136.356136 lmp.py:281] 
DEBUG 01-04 15:36:08.356136.356136 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.356026.356026 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:08.356232.356232 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:08.356479.356479 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:08.356672.356672 lmp.py:285] 
DEBUG 01-04 15:36:08.356672.356672 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.356389.356389 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.356518.356518 lmp.py:292]   Expert 28 |      1 | CPU
DEBUG 01-04 15:36:08.356380.356380 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:08.356427.356427 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:08.356098.356098 lmp.py:292]   Expert  9 |      8 | CPU
DEBUG 01-04 15:36:08.356768.356768 lmp.py:292]   Expert 19 |      9 | CPU
DEBUG 01-04 15:36:08.356246.356246 lmp.py:292]   Expert 58 |      9 | CPU
DEBUG 01-04 15:36:08.356247.356247 lmp.py:292]   Expert  8 |     10 | CPU
DEBUG 01-04 15:36:08.356248.356248 lmp.py:292]   Expert 20 |     11 | CPU
DEBUG 01-04 15:36:08.356534.356534 lmp.py:292]   Expert 10 |     14 | CPU
DEBUG 01-04 15:36:08.356489.356489 lmp.py:292]   Expert 33 |     15 | CPU
DEBUG 01-04 15:36:08.356967.356967 lmp.py:292]   Expert 51 |     15 | CPU
DEBUG 01-04 15:36:08.356207.356207 lmp.py:292]   Expert 32 |     16 | CPU
DEBUG 01-04 15:36:08.356016.356016 lmp.py:292]   Expert 46 |     17 | CPU
DEBUG 01-04 15:36:08.356825.356825 lmp.py:292]   Expert 13 |     18 | CPU
DEBUG 01-04 15:36:08.356396.356396 lmp.py:292]   Expert 27 |     18 | CPU
DEBUG 01-04 15:36:08.356397.356397 lmp.py:292]   Expert 54 |     18 | CPU
DEBUG 01-04 15:36:08.357875.357875 lmp.py:292]   Expert 56 |     19 | CPU
DEBUG 01-04 15:36:08.357353.357353 lmp.py:292]   Expert 18 |     20 | CPU
DEBUG 01-04 15:36:08.357877.357877 lmp.py:292]   Expert 63 |     20 | CPU
DEBUG 01-04 15:36:08.357686.357686 lmp.py:292]   Expert 34 |     22 | CPU
DEBUG 01-04 15:36:08.357495.357495 lmp.py:292]   Expert 37 |     22 | CPU
DEBUG 01-04 15:36:08.357450.357450 lmp.py:292]   Expert 52 |     22 | CPU
DEBUG 01-04 15:36:08.357452.357452 lmp.py:292]   Expert 23 |     23 | CPU
DEBUG 01-04 15:36:08.357976.357976 lmp.py:292]   Expert 30 |     24 | CPU
DEBUG 01-04 15:36:08.357785.357785 lmp.py:292]   Expert 57 |     24 | CPU
DEBUG 01-04 15:36:08.357356.357356 lmp.py:292]   Expert 50 |     27 | CPU
DEBUG 01-04 15:36:08.357450.357450 lmp.py:292]   Expert 40 |     28 | CPU
DEBUG 01-04 15:36:08.357020.357020 lmp.py:292]   Expert 41 |     28 | CPU
DEBUG 01-04 15:36:08.357021.357021 lmp.py:292]   Expert 14 |     29 | CPU
DEBUG 01-04 15:36:08.357023.357023 lmp.py:292]   Expert 15 |     29 | CPU
DEBUG 01-04 15:36:08.357070.357070 lmp.py:292]   Expert 61 |     29 | CPU
DEBUG 01-04 15:36:08.357118.357118 lmp.py:292]   Expert 39 |     30 | GPU
DEBUG 01-04 15:36:08.357688.357688 lmp.py:292]   Expert 59 |     32 | GPU
DEBUG 01-04 15:36:08.357451.357451 lmp.py:292]   Expert 38 |     33 | GPU
DEBUG 01-04 15:36:08.357452.357452 lmp.py:292]   Expert 11 |     35 | GPU
DEBUG 01-04 15:36:08.357023.357023 lmp.py:292]   Expert 12 |     43 | GPU
DEBUG 01-04 15:36:08.357832.357832 lmp.py:292]   Expert 48 |     45 | GPU
DEBUG 01-04 15:36:08.357403.357403 lmp.py:292]   Expert 53 |     45 | GPU
DEBUG 01-04 15:36:08.357404.357404 lmp.py:292]   Expert 17 |     46 | GPU
DEBUG 01-04 15:36:08.357644.357644 lmp.py:292]   Expert 25 |     49 | GPU
DEBUG 01-04 15:36:08.357214.357214 lmp.py:292]   Expert 24 |     52 | GPU
DEBUG 01-04 15:36:08.357500.357500 lmp.py:292]   Expert  7 |     55 | GPU
DEBUG 01-04 15:36:08.357833.357833 lmp.py:292]   Expert 22 |     56 | GPU
DEBUG 01-04 15:36:08.357165.357165 lmp.py:292]   Expert 49 |     56 | GPU
DEBUG 01-04 15:36:08.358928.358928 lmp.py:292]   Expert 55 |     57 | GPU
DEBUG 01-04 15:36:08.358929.358929 lmp.py:292]   Expert 43 |     58 | GPU
DEBUG 01-04 15:36:08.358169.358169 lmp.py:292]   Expert  6 |     59 | GPU
DEBUG 01-04 15:36:08.358978.358978 lmp.py:292]   Expert 31 |     59 | GPU
DEBUG 01-04 15:36:08.358310.358310 lmp.py:292]   Expert 29 |     62 | GPU
DEBUG 01-04 15:36:08.358881.358881 lmp.py:292]   Expert 16 |     63 | GPU
DEBUG 01-04 15:36:08.358643.358643 lmp.py:292]   Expert 21 |     64 | GPU
DEBUG 01-04 15:36:08.358168.358168 lmp.py:292]   Expert 35 |     68 | GPU
DEBUG 01-04 15:36:08.358692.358692 lmp.py:292]   Expert 62 |     88 | GPU
DEBUG 01-04 15:36:08.358263.358263 lmp.py:292]   Expert 47 |     93 | GPU
DEBUG 01-04 15:36:08.358595.358595 lmp.py:292]   Expert 42 |    100 | GPU
DEBUG 01-04 15:36:08.358689.358689 lmp.py:292]   Expert 45 |    105 | GPU
DEBUG 01-04 15:36:08.358452.358452 lmp.py:292]   Expert 36 |    112 | GPU
DEBUG 01-04 15:36:08.358453.358453 lmp.py:292]   Expert  3 |   1668 | GPU
DEBUG 01-04 15:36:08.358739.358739 lmp.py:292]   Expert  2 |   1684 | GPU
DEBUG 01-04 15:36:08.358548.358548 lmp.py:292]   Expert  1 |   1686 | GPU
DEBUG 01-04 15:36:08.358880.358880 lmp.py:292]   Expert  0 |   1699 | GPU
DEBUG 01-04 15:36:08.358213.358213 lmp.py:292]   Expert  4 |   1705 | GPU
DEBUG 01-04 15:36:08.358214.358214 lmp.py:292]   Expert  5 |   1728 | GPU
DEBUG 01-04 15:36:08.358646.358646 lmp.py:293] 
DEBUG 01-04 15:36:08.358646.358646 lmp.py:293]   CPU total tokens: 553 (4.5%)
DEBUG 01-04 15:36:08.358376.358376 lmp.py:294]   GPU total tokens: 11735 (95.5%)
DEBUG 01-04 15:36:08.358106.358106 cuda_h.py:19] end experts_map_get cost 0.0031595230102539062 seconds
DEBUG 01-04 15:36:08.358537.358537 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.358474.358474 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.359912.359912 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.359429.359429 cuda_h.py:19] end allocate_cuda_memory cost 0.0003540515899658203 seconds
DEBUG 01-04 15:36:08.359618.359618 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.359408.359408 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.359450.359450 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.359511.359511 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a8649f98-f53c-4f77-9446-f5a5817c584e
DEBUG 01-04 15:36:08.360906.360906 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.365765.365765 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a8649f98-f53c-4f77-9446-f5a5817c584e
DEBUG 01-04 15:36:08.365883.365883 cuda_h.py:19] end load_into_gpu_async cost 0.0058476924896240234 seconds
DEBUG 01-04 15:36:08.365806.365806 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.366562.366562 cuda_h.py:19] end restore_tensors2 cost 0.0007560253143310547 seconds
DEBUG 01-04 15:36:08.366884.366884 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00762939453125 seconds
DEBUG 01-04 15:36:08.370876.370876 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.01203298568725586 seconds
DEBUG 01-04 15:36:08.370593.370593 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.371703.371703 lmp.py:339] 
DEBUG 01-04 15:36:08.371703.371703 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:08.371408.371408 cuda_h.py:19] end cpu_experts_submit cost 0.00016760826110839844 seconds
DEBUG 01-04 15:36:08.371748.371748 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.383362.383362 mlpmodule.py:704] group tensors cost 0.011699914932250977 s
DEBUG 01-04 15:36:08.386450.386450 mlpmodule.py:742] pad cost 0.0018627643585205078 s
DEBUG 01-04 15:36:08.386918.386918 mlpmodule.py:748] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-04 15:36:08.386802.386802 mlpmodule.py:753] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-04 15:36:08.391814.391814 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:08.391439.391439 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.391865.391865 mlpmodule.py:774] group_w3 first element: 0.0174560546875
WARNING 01-04 15:36:08.391121.391121 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.394290.394290 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.395587.395587 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.398488.398488 mlpmodule.py:797] group einsum cost 0.012115001678466797 s
DEBUG 01-04 15:36:08.398615.398615 mlpmodule.py:805] cpy2cputensor cost 0.00017023086547851562 s
DEBUG 01-04 15:36:08.402519.402519 cuda_h.py:19] end wait_cetm_experts cost 0.031633615493774414 seconds
DEBUG 01-04 15:36:08.403084.403084 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.404729.404729 cuda_h.py:19] end gpu_sexperts cost 0.0008206367492675781 seconds
DEBUG 01-04 15:36:08.404241.404241 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-04 15:36:08.404256.404256 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-04 15:36:08.404272.404272 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 4.1961669921875e-05 seconds
DEBUG 01-04 15:36:08.404850.404850 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 8.96453857421875e-05 seconds
DEBUG 01-04 15:36:08.404029.404029 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.404980.404980 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a8649f98-f53c-4f77-9446-f5a5817c584e
DEBUG 01-04 15:36:08.404768.404768 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.404037.404037 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.404410.404410 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.408234.408234 cuda_h.py:19] end allocate_cuda_memory cost 0.004005908966064453 seconds
DEBUG 01-04 15:36:08.408250.408250 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.409543.409543 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.409379.409379 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.409851.409851 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a10abe3-4b56-43a7-b37e-d9dfd8cc50a8
DEBUG 01-04 15:36:08.409940.409940 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.415386.415386 client.py:127] Model loaded
DEBUG 01-04 15:36:08.415587.415587 cuda_h.py:19] end wait_experts cost 0.011403799057006836 seconds
DEBUG 01-04 15:36:08.415773.415773 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.415106.415106 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.416882.416882 mlpmodule.py:531] gpu group tensors cost 0.0005536079406738281 s
INFO 01-04 15:36:08.416339.416339 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a10abe3-4b56-43a7-b37e-d9dfd8cc50a8
DEBUG 01-04 15:36:08.416997.416997 cuda_h.py:19] end load_into_gpu_async cost 0.007813215255737305 seconds
DEBUG 01-04 15:36:08.416700.416700 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.416882.416882 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-04 15:36:08.417207.417207 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012169122695922852 seconds
INFO 01-04 15:36:08.417776.417776 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a10abe3-4b56-43a7-b37e-d9dfd8cc50a8
DEBUG 01-04 15:36:08.419116.419116 mlpmodule.py:662]  experts func einsum cost 0.04719257354736328 s
DEBUG 01-04 15:36:08.419549.419549 mlpmodule.py:564] gpu pad cost 0.0028464794158935547 s
DEBUG 01-04 15:36:08.420577.420577 mlpmodule.py:582] gpu group einsum cost 0.0005054473876953125 s
DEBUG 01-04 15:36:08.423782.423782 mlpmodule.py:611] gpu experts func einsum cost 0.007853269577026367 s
DEBUG 01-04 15:36:08.423819.423819 cuda_h.py:19] end gpu_experts cost 0.008041858673095703 seconds
DEBUG 01-04 15:36:08.424383.424383 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.428333.428333 client.py:127] Model loaded
DEBUG 01-04 15:36:08.428097.428097 cuda_h.py:19] end sllm_worker_task cost 0.023363828659057617 seconds
DEBUG 01-04 15:36:08.428341.428341 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0042455196380615234 seconds
DEBUG 01-04 15:36:08.428295.428295 cuda_h.py:19] end layer_moe_generate_21 cost 0.07407116889953613 seconds
DEBUG 01-04 15:36:08.428817.428817 lmp.py:207] -------------------------------- end layer 21 --------------------------------
DEBUG 01-04 15:36:08.428964.428964 lmp.py:169] -------------------------------- start layer 22 --------------------------------
DEBUG 01-04 15:36:08.428091.428091 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.429354.429354 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.431059.431059 cuda_h.py:19] end self_attn cost 0.0028171539306640625 seconds
DEBUG 01-04 15:36:08.432006.432006 cuda_h.py:19] end iln_self_attn_paln cost 0.003555774688720703 seconds
DEBUG 01-04 15:36:08.432531.432531 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-04 15:36:08.432824.432824 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.433080.433080 cuda_h.py:19] end gate cost 0.0006771087646484375 seconds
DEBUG 01-04 15:36:08.433578.433578 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.433011.433011 lmp.py:281] 
DEBUG 01-04 15:36:08.433011.433011 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.433528.433528 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.433370.433370 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.433351.433351 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.433948.433948 lmp.py:285] 
DEBUG 01-04 15:36:08.433948.433948 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.433544.433544 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.433625.433625 lmp.py:292]   Expert 36 |      2 | CPU
DEBUG 01-04 15:36:08.433460.433460 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:08.433579.433579 lmp.py:292]   Expert 41 |      5 | CPU
DEBUG 01-04 15:36:08.433461.433461 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:08.433865.433865 lmp.py:292]   Expert 12 |      6 | CPU
DEBUG 01-04 15:36:08.433270.433270 lmp.py:292]   Expert 39 |      6 | CPU
DEBUG 01-04 15:36:08.433674.433674 lmp.py:292]   Expert 45 |      6 | CPU
DEBUG 01-04 15:36:08.433079.433079 lmp.py:292]   Expert 24 |      7 | CPU
DEBUG 01-04 15:36:08.433914.433914 lmp.py:292]   Expert 25 |      8 | CPU
DEBUG 01-04 15:36:08.433034.433034 lmp.py:292]   Expert  7 |      9 | CPU
DEBUG 01-04 15:36:08.433915.433915 lmp.py:292]   Expert 22 |      9 | CPU
DEBUG 01-04 15:36:08.434320.434320 lmp.py:292]   Expert 32 |      9 | CPU
DEBUG 01-04 15:36:08.434724.434724 lmp.py:292]   Expert 51 |      9 | CPU
DEBUG 01-04 15:36:08.434129.434129 lmp.py:292]   Expert 37 |     11 | CPU
DEBUG 01-04 15:36:08.434534.434534 lmp.py:292]   Expert 43 |     11 | CPU
DEBUG 01-04 15:36:08.434177.434177 lmp.py:292]   Expert 11 |     16 | CPU
DEBUG 01-04 15:36:08.434819.434819 lmp.py:292]   Expert 13 |     16 | CPU
DEBUG 01-04 15:36:08.434224.434224 lmp.py:292]   Expert 52 |     16 | CPU
DEBUG 01-04 15:36:08.434867.434867 lmp.py:292]   Expert 42 |     18 | CPU
DEBUG 01-04 15:36:08.434272.434272 lmp.py:292]   Expert 33 |     19 | CPU
DEBUG 01-04 15:36:08.434391.434391 lmp.py:292]   Expert 21 |     20 | CPU
DEBUG 01-04 15:36:08.434750.434750 lmp.py:292]   Expert 50 |     20 | CPU
DEBUG 01-04 15:36:08.434916.434916 lmp.py:292]   Expert 58 |     20 | CPU
DEBUG 01-04 15:36:08.434320.434320 lmp.py:292]   Expert 63 |     20 | CPU
DEBUG 01-04 15:36:08.434486.434486 lmp.py:292]   Expert 57 |     22 | CPU
DEBUG 01-04 15:36:08.434653.434653 lmp.py:292]   Expert  6 |     25 | CPU
DEBUG 01-04 15:36:08.434819.434819 lmp.py:292]   Expert 35 |     25 | CPU
DEBUG 01-04 15:36:08.434223.434223 lmp.py:292]   Expert 54 |     26 | CPU
DEBUG 01-04 15:36:08.434628.434628 lmp.py:292]   Expert 44 |     27 | CPU
DEBUG 01-04 15:36:08.434794.434794 lmp.py:292]   Expert 61 |     27 | CPU
DEBUG 01-04 15:36:08.434629.434629 lmp.py:292]   Expert 46 |     28 | CPU
DEBUG 01-04 15:36:08.434749.434749 lmp.py:292]   Expert 19 |     32 | CPU
DEBUG 01-04 15:36:08.434392.434392 lmp.py:292]   Expert  9 |     36 | GPU
DEBUG 01-04 15:36:08.434796.434796 lmp.py:292]   Expert 31 |     37 | GPU
DEBUG 01-04 15:36:08.434201.434201 lmp.py:292]   Expert 16 |     40 | GPU
DEBUG 01-04 15:36:08.434082.434082 lmp.py:292]   Expert 34 |     40 | GPU
DEBUG 01-04 15:36:08.434487.434487 lmp.py:292]   Expert 10 |     43 | GPU
DEBUG 01-04 15:36:08.434891.434891 lmp.py:292]   Expert 26 |     46 | GPU
DEBUG 01-04 15:36:08.434058.434058 lmp.py:292]   Expert 30 |     46 | GPU
DEBUG 01-04 15:36:08.434462.434462 lmp.py:292]   Expert 28 |     47 | GPU
DEBUG 01-04 15:36:08.434867.434867 lmp.py:292]   Expert 38 |     47 | GPU
DEBUG 01-04 15:36:08.434987.434987 lmp.py:292]   Expert 48 |     47 | GPU
DEBUG 01-04 15:36:08.434629.434629 lmp.py:292]   Expert 15 |     51 | GPU
DEBUG 01-04 15:36:08.434034.434034 lmp.py:292]   Expert  8 |     57 | GPU
DEBUG 01-04 15:36:08.434200.434200 lmp.py:292]   Expert 23 |     58 | GPU
DEBUG 01-04 15:36:08.434605.434605 lmp.py:292]   Expert 47 |     58 | GPU
DEBUG 01-04 15:36:08.434771.434771 lmp.py:292]   Expert 59 |     58 | GPU
DEBUG 01-04 15:36:08.434175.434175 lmp.py:292]   Expert 40 |     59 | GPU
DEBUG 01-04 15:36:08.434580.434580 lmp.py:292]   Expert 53 |     59 | GPU
DEBUG 01-04 15:36:08.434746.434746 lmp.py:292]   Expert 62 |     59 | GPU
DEBUG 01-04 15:36:08.434628.434628 lmp.py:292]   Expert 56 |     71 | GPU
DEBUG 01-04 15:36:08.434986.434986 lmp.py:292]   Expert 20 |     75 | GPU
DEBUG 01-04 15:36:08.434629.434629 lmp.py:292]   Expert 29 |     79 | GPU
DEBUG 01-04 15:36:08.434795.434795 lmp.py:292]   Expert 27 |     81 | GPU
DEBUG 01-04 15:36:08.434723.434723 lmp.py:292]   Expert 55 |     85 | GPU
DEBUG 01-04 15:36:08.434650.434650 lmp.py:292]   Expert 17 |     93 | GPU
DEBUG 01-04 15:36:08.434816.434816 lmp.py:292]   Expert 18 |     93 | GPU
DEBUG 01-04 15:36:08.434744.434744 lmp.py:292]   Expert 14 |    109 | GPU
DEBUG 01-04 15:36:08.434149.434149 lmp.py:292]   Expert  1 |   1670 | GPU
DEBUG 01-04 15:36:08.434553.434553 lmp.py:292]   Expert  0 |   1671 | GPU
DEBUG 01-04 15:36:08.434958.434958 lmp.py:292]   Expert  3 |   1680 | GPU
DEBUG 01-04 15:36:08.434078.434078 lmp.py:292]   Expert  2 |   1711 | GPU
DEBUG 01-04 15:36:08.434721.434721 lmp.py:292]   Expert  4 |   1725 | GPU
DEBUG 01-04 15:36:08.434887.434887 lmp.py:292]   Expert  5 |   1775 | GPU
DEBUG 01-04 15:36:08.434291.434291 lmp.py:293] 
DEBUG 01-04 15:36:08.434291.434291 lmp.py:293]   CPU total tokens: 482 (3.9%)
DEBUG 01-04 15:36:08.434173.434173 lmp.py:294]   GPU total tokens: 11806 (96.1%)
DEBUG 01-04 15:36:08.434061.434061 cuda_h.py:19] end experts_map_get cost 0.0017304420471191406 seconds
DEBUG 01-04 15:36:08.435419.435419 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.435103.435103 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.435332.435332 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.435621.435621 cuda_h.py:19] end allocate_cuda_memory cost 0.00028324127197265625 seconds
DEBUG 01-04 15:36:08.435471.435471 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.435466.435466 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.435851.435851 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.435216.435216 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 394ea494-cb59-4434-90dd-f20ba2d1af81
DEBUG 01-04 15:36:08.435963.435963 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.437311.437311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 394ea494-cb59-4434-90dd-f20ba2d1af81
DEBUG 01-04 15:36:08.437193.437193 cuda_h.py:19] end load_into_gpu_async cost 0.0021500587463378906 seconds
DEBUG 01-04 15:36:08.437227.437227 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.438471.438471 cuda_h.py:19] end restore_tensors2 cost 0.0003287792205810547 seconds
DEBUG 01-04 15:36:08.438863.438863 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030999183654785156 seconds
DEBUG 01-04 15:36:08.441223.441223 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006181955337524414 seconds
DEBUG 01-04 15:36:08.441198.441198 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.441791.441791 lmp.py:339] 
DEBUG 01-04 15:36:08.441791.441791 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.441733.441733 cuda_h.py:19] end cpu_experts_submit cost 0.00011849403381347656 seconds
DEBUG 01-04 15:36:08.441098.441098 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.453919.453919 mlpmodule.py:704] group tensors cost 0.011841297149658203 s
DEBUG 01-04 15:36:08.455236.455236 mlpmodule.py:742] pad cost 0.001552581787109375 s
DEBUG 01-04 15:36:08.455531.455531 mlpmodule.py:748] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-04 15:36:08.456050.456050 mlpmodule.py:753] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-04 15:36:08.460763.460763 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.460189.460189 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.460310.460310 mlpmodule.py:774] group_w3 first element: -0.025390625
WARNING 01-04 15:36:08.460168.460168 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.463688.463688 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.464218.464218 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.467461.467461 mlpmodule.py:797] group einsum cost 0.011638402938842773 s
DEBUG 01-04 15:36:08.467363.467363 mlpmodule.py:805] cpy2cputensor cost 0.00018310546875 s
DEBUG 01-04 15:36:08.472826.472826 cuda_h.py:19] end wait_cetm_experts cost 0.030545473098754883 seconds
DEBUG 01-04 15:36:08.472885.472885 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.472365.472365 cuda_h.py:19] end gpu_sexperts cost 0.0006618499755859375 seconds
DEBUG 01-04 15:36:08.473210.473210 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-04 15:36:08.473655.473655 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-04 15:36:08.473717.473717 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 4.315376281738281e-05 seconds
DEBUG 01-04 15:36:08.473811.473811 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 8.487701416015625e-05 seconds
DEBUG 01-04 15:36:08.473176.473176 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.473793.473793 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 394ea494-cb59-4434-90dd-f20ba2d1af81
DEBUG 01-04 15:36:08.473389.473389 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.473606.473606 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.473550.473550 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.478907.478907 cuda_h.py:19] end allocate_cuda_memory cost 0.004272937774658203 seconds
DEBUG 01-04 15:36:08.478923.478923 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.478501.478501 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.478098.478098 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.478954.478954 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88504f40-21f9-4cc1-b3df-44344e99d927
DEBUG 01-04 15:36:08.478481.478481 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.487159.487159 client.py:127] Model loaded
DEBUG 01-04 15:36:08.487539.487539 cuda_h.py:19] end wait_experts cost 0.014559507369995117 seconds
DEBUG 01-04 15:36:08.487195.487195 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.487852.487852 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.488250.488250 mlpmodule.py:531] gpu group tensors cost 0.0005364418029785156 s
INFO 01-04 15:36:08.488969.488969 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88504f40-21f9-4cc1-b3df-44344e99d927
DEBUG 01-04 15:36:08.488091.488091 cuda_h.py:19] end load_into_gpu_async cost 0.010723114013671875 seconds
DEBUG 01-04 15:36:08.488324.488324 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.489314.489314 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:08.489594.489594 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015384435653686523 seconds
INFO 01-04 15:36:08.489849.489849 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88504f40-21f9-4cc1-b3df-44344e99d927
DEBUG 01-04 15:36:08.490545.490545 mlpmodule.py:564] gpu pad cost 0.0022330284118652344 s
DEBUG 01-04 15:36:08.491126.491126 mlpmodule.py:582] gpu group einsum cost 0.0004622936248779297 s
DEBUG 01-04 15:36:08.491370.491370 mlpmodule.py:662]  experts func einsum cost 0.049884796142578125 s
DEBUG 01-04 15:36:08.494106.494106 mlpmodule.py:611] gpu experts func einsum cost 0.006321430206298828 s
DEBUG 01-04 15:36:08.494236.494236 cuda_h.py:19] end gpu_experts cost 0.006535053253173828 seconds
DEBUG 01-04 15:36:08.494131.494131 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.499104.499104 client.py:127] Model loaded
DEBUG 01-04 15:36:08.499725.499725 cuda_h.py:19] end sllm_worker_task cost 0.025891542434692383 seconds
DEBUG 01-04 15:36:08.499705.499705 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005230426788330078 seconds
DEBUG 01-04 15:36:08.499519.499519 cuda_h.py:19] end layer_moe_generate_22 cost 0.06744050979614258 seconds
DEBUG 01-04 15:36:08.500081.500081 lmp.py:207] -------------------------------- end layer 22 --------------------------------
DEBUG 01-04 15:36:08.500228.500228 lmp.py:169] -------------------------------- start layer 23 --------------------------------
DEBUG 01-04 15:36:08.500116.500116 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.500649.500649 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.502784.502784 cuda_h.py:19] end self_attn cost 0.002398252487182617 seconds
DEBUG 01-04 15:36:08.503833.503833 cuda_h.py:19] end iln_self_attn_paln cost 0.002991914749145508 seconds
DEBUG 01-04 15:36:08.503146.503146 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-04 15:36:08.503194.503194 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.503571.503571 cuda_h.py:19] end gate cost 0.0005502700805664062 seconds
DEBUG 01-04 15:36:08.503156.503156 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.504675.504675 lmp.py:281] 
DEBUG 01-04 15:36:08.504675.504675 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.504285.504285 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.504551.504551 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.504909.504909 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.504645.504645 lmp.py:285] 
DEBUG 01-04 15:36:08.504645.504645 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.504619.504619 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.504076.504076 lmp.py:292]   Expert 19 |      1 | CPU
DEBUG 01-04 15:36:08.504527.504527 lmp.py:292]   Expert  6 |      3 | CPU
DEBUG 01-04 15:36:08.504786.504786 lmp.py:292]   Expert 35 |      3 | CPU
DEBUG 01-04 15:36:08.504045.504045 lmp.py:292]   Expert 34 |      5 | CPU
DEBUG 01-04 15:36:08.504065.504065 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:08.504085.504085 lmp.py:292]   Expert 52 |      7 | CPU
DEBUG 01-04 15:36:08.504344.504344 lmp.py:292]   Expert 22 |      8 | CPU
DEBUG 01-04 15:36:08.504365.504365 lmp.py:292]   Expert 29 |     10 | CPU
DEBUG 01-04 15:36:08.504206.504206 lmp.py:292]   Expert 27 |     11 | CPU
DEBUG 01-04 15:36:08.504465.504465 lmp.py:292]   Expert 43 |     12 | CPU
DEBUG 01-04 15:36:08.504247.504247 lmp.py:292]   Expert 23 |     14 | CPU
DEBUG 01-04 15:36:08.504466.504466 lmp.py:292]   Expert 51 |     14 | CPU
DEBUG 01-04 15:36:08.504441.504441 lmp.py:292]   Expert 53 |     14 | CPU
DEBUG 01-04 15:36:08.504176.504176 lmp.py:292]   Expert 13 |     15 | CPU
DEBUG 01-04 15:36:08.504435.504435 lmp.py:292]   Expert  8 |     16 | CPU
DEBUG 01-04 15:36:08.504932.504932 lmp.py:292]   Expert 55 |     16 | CPU
DEBUG 01-04 15:36:08.504953.504953 lmp.py:292]   Expert 62 |     16 | CPU
DEBUG 01-04 15:36:08.504496.504496 lmp.py:292]   Expert 26 |     20 | CPU
DEBUG 01-04 15:36:08.504278.504278 lmp.py:292]   Expert 49 |     24 | CPU
DEBUG 01-04 15:36:08.504298.504298 lmp.py:292]   Expert  7 |     25 | CPU
DEBUG 01-04 15:36:08.504080.504080 lmp.py:292]   Expert 25 |     26 | CPU
DEBUG 01-04 15:36:08.504862.504862 lmp.py:292]   Expert 44 |     27 | CPU
DEBUG 01-04 15:36:08.504406.504406 lmp.py:292]   Expert 12 |     28 | CPU
DEBUG 01-04 15:36:08.504188.504188 lmp.py:292]   Expert 58 |     28 | CPU
DEBUG 01-04 15:36:08.504970.504970 lmp.py:292]   Expert 17 |     31 | CPU
DEBUG 01-04 15:36:08.504513.504513 lmp.py:292]   Expert 41 |     32 | CPU
DEBUG 01-04 15:36:08.504295.504295 lmp.py:292]   Expert 42 |     34 | CPU
DEBUG 01-04 15:36:08.504316.504316 lmp.py:292]   Expert 38 |     35 | CPU
DEBUG 01-04 15:36:08.504574.504574 lmp.py:292]   Expert 46 |     35 | CPU
DEBUG 01-04 15:36:08.504833.504833 lmp.py:292]   Expert 24 |     36 | CPU
DEBUG 01-04 15:36:08.504330.504330 lmp.py:292]   Expert 31 |     36 | CPU
DEBUG 01-04 15:36:08.504589.504589 lmp.py:292]   Expert 36 |     36 | CPU
DEBUG 01-04 15:36:08.504848.504848 lmp.py:292]   Expert 40 |     37 | GPU
DEBUG 01-04 15:36:08.504391.504391 lmp.py:292]   Expert 39 |     38 | GPU
DEBUG 01-04 15:36:08.504173.504173 lmp.py:292]   Expert 45 |     38 | GPU
DEBUG 01-04 15:36:08.504479.504479 lmp.py:292]   Expert 56 |     38 | GPU
DEBUG 01-04 15:36:08.504022.504022 lmp.py:292]   Expert 20 |     40 | GPU
DEBUG 01-04 15:36:08.504042.504042 lmp.py:292]   Expert 28 |     40 | GPU
DEBUG 01-04 15:36:08.504586.504586 lmp.py:292]   Expert 47 |     43 | GPU
DEBUG 01-04 15:36:08.504891.504891 lmp.py:292]   Expert 48 |     44 | GPU
DEBUG 01-04 15:36:08.504435.504435 lmp.py:292]   Expert 61 |     45 | GPU
DEBUG 01-04 15:36:08.504455.504455 lmp.py:292]   Expert 57 |     50 | GPU
DEBUG 01-04 15:36:08.504760.504760 lmp.py:292]   Expert 18 |     51 | GPU
DEBUG 01-04 15:36:08.504304.504304 lmp.py:292]   Expert  9 |     52 | GPU
DEBUG 01-04 15:36:08.504609.504609 lmp.py:292]   Expert 10 |     53 | GPU
DEBUG 01-04 15:36:08.504152.504152 lmp.py:292]   Expert 50 |     53 | GPU
DEBUG 01-04 15:36:08.504696.504696 lmp.py:292]   Expert 54 |     54 | GPU
DEBUG 01-04 15:36:08.504239.504239 lmp.py:292]   Expert 11 |     57 | GPU
DEBUG 01-04 15:36:08.505544.505544 lmp.py:292]   Expert 63 |     57 | GPU
DEBUG 01-04 15:36:08.505088.505088 lmp.py:292]   Expert 16 |     58 | GPU
DEBUG 01-04 15:36:08.505347.505347 lmp.py:292]   Expert 32 |     65 | GPU
DEBUG 01-04 15:36:08.505367.505367 lmp.py:292]   Expert 21 |     75 | GPU
DEBUG 01-04 15:36:08.505626.505626 lmp.py:292]   Expert 30 |     78 | GPU
DEBUG 01-04 15:36:08.505646.505646 lmp.py:292]   Expert 15 |     79 | GPU
DEBUG 01-04 15:36:08.505428.505428 lmp.py:292]   Expert 14 |     81 | GPU
DEBUG 01-04 15:36:08.505733.505733 lmp.py:292]   Expert 37 |     86 | GPU
DEBUG 01-04 15:36:08.505038.505038 lmp.py:292]   Expert 59 |     93 | GPU
DEBUG 01-04 15:36:08.505820.505820 lmp.py:292]   Expert 33 |    130 | GPU
DEBUG 01-04 15:36:08.505364.505364 lmp.py:292]   Expert  5 |   1669 | GPU
DEBUG 01-04 15:36:08.505384.505384 lmp.py:292]   Expert  1 |   1676 | GPU
DEBUG 01-04 15:36:08.505928.505928 lmp.py:292]   Expert  0 |   1685 | GPU
DEBUG 01-04 15:36:08.505471.505471 lmp.py:292]   Expert  4 |   1685 | GPU
DEBUG 01-04 15:36:08.505777.505777 lmp.py:292]   Expert  2 |   1707 | GPU
DEBUG 01-04 15:36:08.505320.505320 lmp.py:292]   Expert  3 |   1708 | GPU
DEBUG 01-04 15:36:08.505817.505817 lmp.py:293] 
DEBUG 01-04 15:36:08.505817.505817 lmp.py:293]   CPU total tokens: 623 (5.1%)
DEBUG 01-04 15:36:08.505838.505838 lmp.py:294]   GPU total tokens: 11665 (94.9%)
DEBUG 01-04 15:36:08.505626.505626 cuda_h.py:19] end experts_map_get cost 0.0013737678527832031 seconds
DEBUG 01-04 15:36:08.505362.505362 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.505708.505708 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.505977.505977 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.505119.505119 cuda_h.py:19] end allocate_cuda_memory cost 0.00024962425231933594 seconds
DEBUG 01-04 15:36:08.505055.505055 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.505473.505473 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.505043.505043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.505309.505309 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 961f395e-1915-4f9c-831a-ab7202a04a26
DEBUG 01-04 15:36:08.506864.506864 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.507763.507763 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 961f395e-1915-4f9c-831a-ab7202a04a26
DEBUG 01-04 15:36:08.508993.508993 cuda_h.py:19] end load_into_gpu_async cost 0.0022614002227783203 seconds
DEBUG 01-04 15:36:08.508432.508432 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.509421.509421 cuda_h.py:19] end restore_tensors2 cost 0.0007691383361816406 seconds
DEBUG 01-04 15:36:08.509866.509866 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037124156951904297 seconds
DEBUG 01-04 15:36:08.511497.511497 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006185054779052734 seconds
DEBUG 01-04 15:36:08.511989.511989 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.511468.511468 lmp.py:339] 
DEBUG 01-04 15:36:08.511468.511468 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.511165.511165 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-04 15:36:08.511861.511861 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.518492.518492 mlpmodule.py:704] group tensors cost 0.00637507438659668 s
DEBUG 01-04 15:36:08.521970.521970 mlpmodule.py:742] pad cost 0.002742767333984375 s
DEBUG 01-04 15:36:08.522876.522876 mlpmodule.py:748] create cpu tensor cost 6.890296936035156e-05 s
DEBUG 01-04 15:36:08.522079.522079 mlpmodule.py:753] move to cpu cost 4.982948303222656e-05 s
DEBUG 01-04 15:36:08.527633.527633 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.527589.527589 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.527578.527578 mlpmodule.py:774] group_w3 first element: -0.0054931640625
WARNING 01-04 15:36:08.527091.527091 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.531012.531012 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.531115.531115 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.536083.536083 mlpmodule.py:797] group einsum cost 0.013911724090576172 s
DEBUG 01-04 15:36:08.536296.536296 mlpmodule.py:805] cpy2cputensor cost 0.0001533031463623047 s
DEBUG 01-04 15:36:08.540565.540565 cuda_h.py:19] end wait_cetm_experts cost 0.02884507179260254 seconds
DEBUG 01-04 15:36:08.540094.540094 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.541228.541228 cuda_h.py:19] end gpu_sexperts cost 0.0005822181701660156 seconds
DEBUG 01-04 15:36:08.541071.541071 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-04 15:36:08.541224.541224 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-04 15:36:08.541294.541294 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 4.363059997558594e-05 seconds
DEBUG 01-04 15:36:08.541341.541341 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 8.678436279296875e-05 seconds
DEBUG 01-04 15:36:08.541660.541660 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.541131.541131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 961f395e-1915-4f9c-831a-ab7202a04a26
DEBUG 01-04 15:36:08.541892.541892 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.541412.541412 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.542732.542732 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.547694.547694 cuda_h.py:19] end allocate_cuda_memory cost 0.005055427551269531 seconds
DEBUG 01-04 15:36:08.547849.547849 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.547758.547758 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.547633.547633 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.547866.547866 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 85297c3c-5b9e-49f8-9600-eceda2b958ce
DEBUG 01-04 15:36:08.547148.547148 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:08.557521.557521 mlpmodule.py:662]  experts func einsum cost 0.04543709754943848 s
INFO 01-04 15:36:08.558995.558995 client.py:127] Model loaded
DEBUG 01-04 15:36:08.558293.558293 cuda_h.py:19] end wait_experts cost 0.017267227172851562 seconds
DEBUG 01-04 15:36:08.559031.559031 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.559431.559431 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:08.560969.560969 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 85297c3c-5b9e-49f8-9600-eceda2b958ce
DEBUG 01-04 15:36:08.560008.560008 cuda_h.py:19] end load_into_gpu_async cost 0.013192415237426758 seconds
DEBUG 01-04 15:36:08.560322.560322 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.560026.560026 cuda_h.py:19] end restore_tensors2 cost 0.00015473365783691406 seconds
DEBUG 01-04 15:36:08.561347.561347 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01897454261779785 seconds
INFO 01-04 15:36:08.562229.562229 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 85297c3c-5b9e-49f8-9600-eceda2b958ce
DEBUG 01-04 15:36:08.562835.562835 mlpmodule.py:531] gpu group tensors cost 0.003186941146850586 s
DEBUG 01-04 15:36:08.566297.566297 mlpmodule.py:564] gpu pad cost 0.003997802734375 s
DEBUG 01-04 15:36:08.567945.567945 mlpmodule.py:582] gpu group einsum cost 0.000812530517578125 s
INFO 01-04 15:36:08.567520.567520 client.py:127] Model loaded
DEBUG 01-04 15:36:08.568946.568946 cuda_h.py:19] end sllm_worker_task cost 0.026013851165771484 seconds
DEBUG 01-04 15:36:08.574182.574182 mlpmodule.py:611] gpu experts func einsum cost 0.014966964721679688 s
DEBUG 01-04 15:36:08.574473.574473 cuda_h.py:19] end gpu_experts cost 0.015311479568481445 seconds
DEBUG 01-04 15:36:08.574045.574045 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:08.574651.574651 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-04 15:36:08.574262.574262 cuda_h.py:19] end layer_moe_generate_23 cost 0.07163715362548828 seconds
DEBUG 01-04 15:36:08.575100.575100 lmp.py:207] -------------------------------- end layer 23 --------------------------------
DEBUG 01-04 15:36:08.575433.575433 lmp.py:169] -------------------------------- start layer 24 --------------------------------
DEBUG 01-04 15:36:08.575117.575117 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.575631.575631 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.578635.578635 cuda_h.py:19] end self_attn cost 0.0024292469024658203 seconds
DEBUG 01-04 15:36:08.578254.578254 cuda_h.py:19] end iln_self_attn_paln cost 0.0032439231872558594 seconds
DEBUG 01-04 15:36:08.578474.578474 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-04 15:36:08.578475.578475 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.579350.579350 cuda_h.py:19] end gate cost 0.0005750656127929688 seconds
DEBUG 01-04 15:36:08.579749.579749 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.579103.579103 lmp.py:281] 
DEBUG 01-04 15:36:08.579103.579103 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.579098.579098 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:08.579986.579986 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:08.579490.579490 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:08.579325.579325 lmp.py:285] 
DEBUG 01-04 15:36:08.579325.579325 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.579445.579445 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.579525.579525 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:08.579645.579645 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:08.579573.579573 lmp.py:292]   Expert 62 |      3 | CPU
DEBUG 01-04 15:36:08.579500.579500 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:08.579428.579428 lmp.py:292]   Expert 48 |      4 | CPU
DEBUG 01-04 15:36:08.579117.579117 lmp.py:292]   Expert 60 |      4 | CPU
DEBUG 01-04 15:36:08.579568.579568 lmp.py:292]   Expert 17 |      7 | CPU
DEBUG 01-04 15:36:08.579257.579257 lmp.py:292]   Expert 22 |      7 | CPU
DEBUG 01-04 15:36:08.579947.579947 lmp.py:292]   Expert 44 |      7 | CPU
DEBUG 01-04 15:36:08.579636.579636 lmp.py:292]   Expert  7 |      8 | CPU
DEBUG 01-04 15:36:08.579849.579849 lmp.py:292]   Expert 35 |      8 | CPU
DEBUG 01-04 15:36:08.579299.579299 lmp.py:292]   Expert  9 |     10 | CPU
DEBUG 01-04 15:36:08.579750.579750 lmp.py:292]   Expert 42 |     10 | CPU
DEBUG 01-04 15:36:08.579201.579201 lmp.py:292]   Expert 57 |     10 | CPU
DEBUG 01-04 15:36:08.580367.580367 lmp.py:292]   Expert 19 |     13 | CPU
DEBUG 01-04 15:36:08.580010.580010 lmp.py:292]   Expert 49 |     14 | CPU
DEBUG 01-04 15:36:08.580653.580653 lmp.py:292]   Expert  6 |     15 | CPU
DEBUG 01-04 15:36:08.580581.580581 lmp.py:292]   Expert 25 |     15 | CPU
DEBUG 01-04 15:36:08.580747.580747 lmp.py:292]   Expert 52 |     15 | CPU
DEBUG 01-04 15:36:08.580198.580198 lmp.py:292]   Expert 58 |     15 | CPU
DEBUG 01-04 15:36:08.580410.580410 lmp.py:292]   Expert 41 |     17 | CPU
DEBUG 01-04 15:36:08.580861.580861 lmp.py:292]   Expert 47 |     18 | CPU
DEBUG 01-04 15:36:08.580835.580835 lmp.py:292]   Expert 26 |     19 | CPU
DEBUG 01-04 15:36:08.580048.580048 lmp.py:292]   Expert 40 |     20 | CPU
DEBUG 01-04 15:36:08.580260.580260 lmp.py:292]   Expert 16 |     21 | CPU
DEBUG 01-04 15:36:08.580473.580473 lmp.py:292]   Expert 54 |     25 | CPU
DEBUG 01-04 15:36:08.580685.580685 lmp.py:292]   Expert 36 |     27 | CPU
DEBUG 01-04 15:36:08.580898.580898 lmp.py:292]   Expert 43 |     27 | CPU
DEBUG 01-04 15:36:08.580872.580872 lmp.py:292]   Expert 55 |     33 | CPU
DEBUG 01-04 15:36:08.580323.580323 lmp.py:292]   Expert 15 |     34 | CPU
DEBUG 01-04 15:36:08.580774.580774 lmp.py:292]   Expert 31 |     34 | CPU
DEBUG 01-04 15:36:08.580940.580940 lmp.py:292]   Expert 61 |     35 | GPU
DEBUG 01-04 15:36:08.580583.580583 lmp.py:292]   Expert 14 |     36 | GPU
DEBUG 01-04 15:36:08.580987.580987 lmp.py:292]   Expert 32 |     38 | GPU
DEBUG 01-04 15:36:08.580869.580869 lmp.py:292]   Expert 51 |     42 | GPU
DEBUG 01-04 15:36:08.580558.580558 lmp.py:292]   Expert 30 |     43 | GPU
DEBUG 01-04 15:36:08.580247.580247 lmp.py:292]   Expert 45 |     45 | GPU
DEBUG 01-04 15:36:08.580566.580566 lmp.py:292]   Expert 53 |     46 | GPU
DEBUG 01-04 15:36:08.580778.580778 lmp.py:292]   Expert 18 |     47 | GPU
DEBUG 01-04 15:36:08.580468.580468 lmp.py:292]   Expert 20 |     47 | GPU
DEBUG 01-04 15:36:08.580919.580919 lmp.py:292]   Expert 59 |     47 | GPU
DEBUG 01-04 15:36:08.580893.580893 lmp.py:292]   Expert 50 |     48 | GPU
DEBUG 01-04 15:36:08.580774.580774 lmp.py:292]   Expert 24 |     50 | GPU
DEBUG 01-04 15:36:08.580225.580225 lmp.py:292]   Expert 10 |     52 | GPU
DEBUG 01-04 15:36:08.580629.580629 lmp.py:292]   Expert  8 |     53 | GPU
DEBUG 01-04 15:36:08.580272.580272 lmp.py:292]   Expert 38 |     54 | GPU
DEBUG 01-04 15:36:08.580962.580962 lmp.py:292]   Expert 21 |     55 | GPU
DEBUG 01-04 15:36:08.580413.580413 lmp.py:292]   Expert 37 |     63 | GPU
DEBUG 01-04 15:36:08.580102.580102 lmp.py:292]   Expert 23 |     64 | GPU
DEBUG 01-04 15:36:08.580314.580314 lmp.py:292]   Expert 11 |     67 | GPU
DEBUG 01-04 15:36:08.580765.580765 lmp.py:292]   Expert 46 |     67 | GPU
DEBUG 01-04 15:36:08.580216.580216 lmp.py:292]   Expert 34 |     71 | GPU
DEBUG 01-04 15:36:08.580667.580667 lmp.py:292]   Expert 39 |    100 | GPU
DEBUG 01-04 15:36:08.580879.580879 lmp.py:292]   Expert 33 |    118 | GPU
DEBUG 01-04 15:36:08.580092.580092 lmp.py:292]   Expert 13 |    121 | GPU
DEBUG 01-04 15:36:08.580543.580543 lmp.py:292]   Expert 12 |    127 | GPU
DEBUG 01-04 15:36:08.580278.580278 lmp.py:292]   Expert 27 |    139 | GPU
DEBUG 01-04 15:36:08.580968.580968 lmp.py:292]   Expert  1 |   1670 | GPU
DEBUG 01-04 15:36:08.580134.580134 lmp.py:292]   Expert  5 |   1676 | GPU
DEBUG 01-04 15:36:08.580300.580300 lmp.py:292]   Expert  4 |   1683 | GPU
DEBUG 01-04 15:36:08.580705.580705 lmp.py:292]   Expert  3 |   1684 | GPU
DEBUG 01-04 15:36:08.580824.580824 lmp.py:292]   Expert  0 |   1697 | GPU
DEBUG 01-04 15:36:08.580275.580275 lmp.py:292]   Expert  2 |   1755 | GPU
DEBUG 01-04 15:36:08.580203.580203 lmp.py:293] 
DEBUG 01-04 15:36:08.580203.580203 lmp.py:293]   CPU total tokens: 448 (3.6%)
DEBUG 01-04 15:36:08.580607.580607 lmp.py:294]   GPU total tokens: 11840 (96.4%)
DEBUG 01-04 15:36:08.580542.580542 cuda_h.py:19] end experts_map_get cost 0.0015041828155517578 seconds
DEBUG 01-04 15:36:08.580947.580947 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.580869.580869 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.581568.581568 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.581048.581048 cuda_h.py:19] end allocate_cuda_memory cost 0.00025010108947753906 seconds
DEBUG 01-04 15:36:08.581653.581653 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.581978.581978 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.581264.581264 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.581152.581152 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81b9da39-9299-4e2b-aa07-9bc9e2f585e5
DEBUG 01-04 15:36:08.581913.581913 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.582005.582005 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81b9da39-9299-4e2b-aa07-9bc9e2f585e5
DEBUG 01-04 15:36:08.582596.582596 cuda_h.py:19] end load_into_gpu_async cost 0.0014369487762451172 seconds
DEBUG 01-04 15:36:08.582868.582868 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.583773.583773 cuda_h.py:19] end restore_tensors2 cost 0.00029015541076660156 seconds
DEBUG 01-04 15:36:08.583404.583404 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002302885055541992 seconds
DEBUG 01-04 15:36:08.585625.585625 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005003452301025391 seconds
DEBUG 01-04 15:36:08.585355.585355 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.586311.586311 lmp.py:339] 
DEBUG 01-04 15:36:08.586311.586311 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:08.586531.586531 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-04 15:36:08.586704.586704 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.598958.598958 mlpmodule.py:704] group tensors cost 0.01247262954711914 s
DEBUG 01-04 15:36:08.602958.602958 mlpmodule.py:742] pad cost 0.002478361129760742 s
DEBUG 01-04 15:36:08.602672.602672 mlpmodule.py:748] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-04 15:36:08.602887.602887 mlpmodule.py:753] move to cpu cost 4.2438507080078125e-05 s
DEBUG 01-04 15:36:08.607719.607719 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:08.607377.607377 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.607174.607174 mlpmodule.py:774] group_w3 first element: -0.0108642578125
WARNING 01-04 15:36:08.607886.607886 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.610231.610231 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.611186.611186 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.615062.615062 mlpmodule.py:797] group einsum cost 0.013108968734741211 s
DEBUG 01-04 15:36:08.615110.615110 mlpmodule.py:805] cpy2cputensor cost 0.00018286705017089844 s
DEBUG 01-04 15:36:08.620826.620826 cuda_h.py:19] end wait_cetm_experts cost 0.033821821212768555 seconds
DEBUG 01-04 15:36:08.620448.620448 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.620192.620192 cuda_h.py:19] end gpu_sexperts cost 0.0006089210510253906 seconds
DEBUG 01-04 15:36:08.620426.620426 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-04 15:36:08.620726.620726 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-04 15:36:08.621781.621781 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 4.00543212890625e-05 seconds
DEBUG 01-04 15:36:08.621636.621636 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 8.106231689453125e-05 seconds
DEBUG 01-04 15:36:08.621432.621432 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.621619.621619 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81b9da39-9299-4e2b-aa07-9bc9e2f585e5
DEBUG 01-04 15:36:08.621863.621863 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.621470.621470 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.621711.621711 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.625991.625991 cuda_h.py:19] end allocate_cuda_memory cost 0.0041599273681640625 seconds
DEBUG 01-04 15:36:08.625875.625875 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.625843.625843 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.625355.625355 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.625979.625979 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, abdb3679-d1b7-4d0b-bbcd-fb930c29dc48
DEBUG 01-04 15:36:08.626288.626288 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.633098.633098 client.py:127] Model loaded
DEBUG 01-04 15:36:08.633133.633133 cuda_h.py:19] end wait_experts cost 0.012212991714477539 seconds
DEBUG 01-04 15:36:08.633359.633359 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.633731.633731 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.633572.633572 mlpmodule.py:531] gpu group tensors cost 0.0005145072937011719 s
INFO 01-04 15:36:08.634991.634991 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, abdb3679-d1b7-4d0b-bbcd-fb930c29dc48
DEBUG 01-04 15:36:08.634549.634549 cuda_h.py:19] end load_into_gpu_async cost 0.008421897888183594 seconds
DEBUG 01-04 15:36:08.634729.634729 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.634719.634719 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-04 15:36:08.634521.634521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012954235076904297 seconds
INFO 01-04 15:36:08.634393.634393 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, abdb3679-d1b7-4d0b-bbcd-fb930c29dc48
DEBUG 01-04 15:36:08.635334.635334 mlpmodule.py:662]  experts func einsum cost 0.0492398738861084 s
DEBUG 01-04 15:36:08.636191.636191 mlpmodule.py:564] gpu pad cost 0.0023965835571289062 s
DEBUG 01-04 15:36:08.636646.636646 mlpmodule.py:582] gpu group einsum cost 0.00044035911560058594 s
DEBUG 01-04 15:36:08.639812.639812 mlpmodule.py:611] gpu experts func einsum cost 0.0063097476959228516 s
DEBUG 01-04 15:36:08.639988.639988 cuda_h.py:19] end gpu_experts cost 0.006476163864135742 seconds
DEBUG 01-04 15:36:08.639836.639836 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.645856.645856 client.py:127] Model loaded
DEBUG 01-04 15:36:08.645437.645437 cuda_h.py:19] end sllm_worker_task cost 0.02373790740966797 seconds
DEBUG 01-04 15:36:08.645065.645065 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005390167236328125 seconds
DEBUG 01-04 15:36:08.645129.645129 cuda_h.py:19] end layer_moe_generate_24 cost 0.06697201728820801 seconds
DEBUG 01-04 15:36:08.646684.646684 lmp.py:207] -------------------------------- end layer 24 --------------------------------
DEBUG 01-04 15:36:08.646403.646403 lmp.py:169] -------------------------------- start layer 25 --------------------------------
DEBUG 01-04 15:36:08.646624.646624 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.646325.646325 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.651745.651745 cuda_h.py:19] end self_attn cost 0.004897117614746094 seconds
DEBUG 01-04 15:36:08.652171.652171 cuda_h.py:19] end iln_self_attn_paln cost 0.006193637847900391 seconds
DEBUG 01-04 15:36:08.652964.652964 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-04 15:36:08.652324.652324 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.653598.653598 cuda_h.py:19] end gate cost 0.0011620521545410156 seconds
DEBUG 01-04 15:36:08.654125.654125 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.654758.654758 lmp.py:281] 
DEBUG 01-04 15:36:08.654758.654758 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.654006.654006 lmp.py:282]   Total experts: 62
DEBUG 01-04 15:36:08.654756.654756 lmp.py:283]   CPU experts: 31 (50%)
DEBUG 01-04 15:36:08.654115.654115 lmp.py:284]   GPU experts: 31 (50%)
DEBUG 01-04 15:36:08.655322.655322 lmp.py:285] 
DEBUG 01-04 15:36:08.655322.655322 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.655006.655006 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.655326.655326 lmp.py:292]   Expert 47 |      1 | CPU
DEBUG 01-04 15:36:08.655917.655917 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:08.655885.655885 lmp.py:292]   Expert 27 |      3 | CPU
DEBUG 01-04 15:36:08.655900.655900 lmp.py:292]   Expert 53 |      4 | CPU
DEBUG 01-04 15:36:08.655584.655584 lmp.py:292]   Expert 14 |      5 | CPU
DEBUG 01-04 15:36:08.655791.655791 lmp.py:292]   Expert 39 |      7 | CPU
DEBUG 01-04 15:36:08.655044.655044 lmp.py:292]   Expert 36 |      8 | CPU
DEBUG 01-04 15:36:08.655536.655536 lmp.py:292]   Expert 48 |      8 | CPU
DEBUG 01-04 15:36:08.655074.655074 lmp.py:292]   Expert 42 |      9 | CPU
DEBUG 01-04 15:36:08.655612.655612 lmp.py:292]   Expert 11 |     10 | CPU
DEBUG 01-04 15:36:08.655818.655818 lmp.py:292]   Expert 32 |     10 | CPU
DEBUG 01-04 15:36:08.655787.655787 lmp.py:292]   Expert 37 |     11 | CPU
DEBUG 01-04 15:36:08.655848.655848 lmp.py:292]   Expert 12 |     12 | CPU
DEBUG 01-04 15:36:08.655194.655194 lmp.py:292]   Expert 56 |     12 | CPU
DEBUG 01-04 15:36:08.655732.655732 lmp.py:292]   Expert 43 |     13 | CPU
DEBUG 01-04 15:36:08.655747.655747 lmp.py:292]   Expert 45 |     13 | CPU
DEBUG 01-04 15:36:08.655523.655523 lmp.py:292]   Expert 10 |     14 | CPU
DEBUG 01-04 15:36:08.655823.655823 lmp.py:292]   Expert 21 |     14 | CPU
DEBUG 01-04 15:36:08.655884.655884 lmp.py:292]   Expert 38 |     14 | CPU
DEBUG 01-04 15:36:08.655229.655229 lmp.py:292]   Expert 13 |     16 | CPU
DEBUG 01-04 15:36:08.656767.656767 lmp.py:292]   Expert 62 |     16 | CPU
DEBUG 01-04 15:36:08.656021.656021 lmp.py:292]   Expert 33 |     18 | CPU
DEBUG 01-04 15:36:08.656320.656320 lmp.py:292]   Expert 50 |     18 | CPU
DEBUG 01-04 15:36:08.656189.656189 lmp.py:292]   Expert 41 |     19 | CPU
DEBUG 01-04 15:36:08.656820.656820 lmp.py:292]   Expert 35 |     22 | CPU
DEBUG 01-04 15:36:08.656689.656689 lmp.py:292]   Expert 52 |     22 | CPU
DEBUG 01-04 15:36:08.656988.656988 lmp.py:292]   Expert 16 |     24 | CPU
DEBUG 01-04 15:36:08.656526.656526 lmp.py:292]   Expert 40 |     25 | CPU
DEBUG 01-04 15:36:08.656424.656424 lmp.py:292]   Expert 59 |     27 | CPU
DEBUG 01-04 15:36:08.656723.656723 lmp.py:292]   Expert  7 |     31 | CPU
DEBUG 01-04 15:36:08.656215.656215 lmp.py:292]   Expert 24 |     31 | CPU
DEBUG 01-04 15:36:08.656468.656468 lmp.py:292]   Expert 49 |     32 | GPU
DEBUG 01-04 15:36:08.656006.656006 lmp.py:292]   Expert 31 |     33 | GPU
DEBUG 01-04 15:36:08.656352.656352 lmp.py:292]   Expert 23 |     35 | GPU
DEBUG 01-04 15:36:08.656175.656175 lmp.py:292]   Expert 29 |     39 | GPU
DEBUG 01-04 15:36:08.656666.656666 lmp.py:292]   Expert 51 |     39 | GPU
DEBUG 01-04 15:36:08.656396.656396 lmp.py:292]   Expert 44 |     41 | GPU
DEBUG 01-04 15:36:08.656980.656980 lmp.py:292]   Expert 61 |     44 | GPU
DEBUG 01-04 15:36:08.656803.656803 lmp.py:292]   Expert 22 |     49 | GPU
DEBUG 01-04 15:36:08.656387.656387 lmp.py:292]   Expert  6 |     50 | GPU
DEBUG 01-04 15:36:08.657117.657117 lmp.py:292]   Expert 55 |     52 | GPU
DEBUG 01-04 15:36:08.657132.657132 lmp.py:292]   Expert 46 |     53 | GPU
DEBUG 01-04 15:36:08.657842.657842 lmp.py:292]   Expert 15 |     61 | GPU
DEBUG 01-04 15:36:08.657485.657485 lmp.py:292]   Expert 25 |     61 | GPU
DEBUG 01-04 15:36:08.657128.657128 lmp.py:292]   Expert 57 |     65 | GPU
DEBUG 01-04 15:36:08.657009.657009 lmp.py:292]   Expert 30 |     66 | GPU
DEBUG 01-04 15:36:08.657367.657367 lmp.py:292]   Expert  8 |     68 | GPU
DEBUG 01-04 15:36:08.657010.657010 lmp.py:292]   Expert 20 |     78 | GPU
DEBUG 01-04 15:36:08.657653.657653 lmp.py:292]   Expert 28 |     81 | GPU
DEBUG 01-04 15:36:08.657296.657296 lmp.py:292]   Expert 54 |     83 | GPU
DEBUG 01-04 15:36:08.657939.657939 lmp.py:292]   Expert 58 |     90 | GPU
DEBUG 01-04 15:36:08.657582.657582 lmp.py:292]   Expert 60 |    100 | GPU
DEBUG 01-04 15:36:08.657225.657225 lmp.py:292]   Expert 19 |    110 | GPU
DEBUG 01-04 15:36:08.657584.657584 lmp.py:292]   Expert 26 |    113 | GPU
DEBUG 01-04 15:36:08.657134.657134 lmp.py:292]   Expert 63 |    124 | GPU
DEBUG 01-04 15:36:08.657684.657684 lmp.py:292]   Expert 17 |    136 | GPU
DEBUG 01-04 15:36:08.657042.657042 lmp.py:292]   Expert  0 |   1672 | GPU
DEBUG 01-04 15:36:08.657924.657924 lmp.py:292]   Expert  5 |   1684 | GPU
DEBUG 01-04 15:36:08.657805.657805 lmp.py:292]   Expert  3 |   1689 | GPU
DEBUG 01-04 15:36:08.657687.657687 lmp.py:292]   Expert  2 |   1691 | GPU
DEBUG 01-04 15:36:08.657568.657568 lmp.py:292]   Expert  1 |   1705 | GPU
DEBUG 01-04 15:36:08.657211.657211 lmp.py:292]   Expert  4 |   1705 | GPU
DEBUG 01-04 15:36:08.657284.657284 lmp.py:293] 
DEBUG 01-04 15:36:08.657284.657284 lmp.py:293]   CPU total tokens: 439 (3.6%)
DEBUG 01-04 15:36:08.657358.657358 lmp.py:294]   GPU total tokens: 11849 (96.4%)
DEBUG 01-04 15:36:08.657438.657438 cuda_h.py:19] end experts_map_get cost 0.0033626556396484375 seconds
DEBUG 01-04 15:36:08.657465.657465 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.657679.657679 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.657962.657962 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.658337.658337 cuda_h.py:19] end allocate_cuda_memory cost 0.00027489662170410156 seconds
DEBUG 01-04 15:36:08.658471.658471 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.658419.658419 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.658427.658427 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.658938.658938 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0bac985d-470f-4da9-9190-e46c75ccbdfa
DEBUG 01-04 15:36:08.658474.658474 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.660296.660296 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0bac985d-470f-4da9-9190-e46c75ccbdfa
DEBUG 01-04 15:36:08.660086.660086 cuda_h.py:19] end load_into_gpu_async cost 0.0021049976348876953 seconds
DEBUG 01-04 15:36:08.660504.660504 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.660329.660329 cuda_h.py:19] end restore_tensors2 cost 0.00029850006103515625 seconds
DEBUG 01-04 15:36:08.660536.660536 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030298233032226562 seconds
DEBUG 01-04 15:36:08.663564.663564 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005870819091796875 seconds
DEBUG 01-04 15:36:08.663162.663162 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.663701.663701 lmp.py:339] 
DEBUG 01-04 15:36:08.663701.663701 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:08.663458.663458 cuda_h.py:19] end cpu_experts_submit cost 0.00011682510375976562 seconds
DEBUG 01-04 15:36:08.663922.663922 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.680851.680851 mlpmodule.py:704] group tensors cost 0.016199827194213867 s
DEBUG 01-04 15:36:08.682593.682593 mlpmodule.py:742] pad cost 0.0018858909606933594 s
DEBUG 01-04 15:36:08.682915.682915 mlpmodule.py:748] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-04 15:36:08.682070.682070 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-04 15:36:08.687392.687392 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:08.687753.687753 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.687153.687153 mlpmodule.py:774] group_w3 first element: -0.007476806640625
WARNING 01-04 15:36:08.687800.687800 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.691852.691852 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.691044.691044 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.695353.695353 mlpmodule.py:797] group einsum cost 0.01255488395690918 s
DEBUG 01-04 15:36:08.695983.695983 mlpmodule.py:805] cpy2cputensor cost 0.0001575946807861328 s
DEBUG 01-04 15:36:08.699650.699650 cuda_h.py:19] end wait_cetm_experts cost 0.036086082458496094 seconds
DEBUG 01-04 15:36:08.700577.700577 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.700138.700138 cuda_h.py:19] end gpu_sexperts cost 0.0006775856018066406 seconds
DEBUG 01-04 15:36:08.700856.700856 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-04 15:36:08.700592.700592 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-04 15:36:08.700999.700999 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.482269287109375e-05 seconds
DEBUG 01-04 15:36:08.700676.700676 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 9.608268737792969e-05 seconds
DEBUG 01-04 15:36:08.701432.701432 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.701725.701725 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0bac985d-470f-4da9-9190-e46c75ccbdfa
DEBUG 01-04 15:36:08.701228.701228 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.701769.701769 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.701016.701016 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.706112.706112 cuda_h.py:19] end allocate_cuda_memory cost 0.004580259323120117 seconds
DEBUG 01-04 15:36:08.706003.706003 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.706832.706832 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.706920.706920 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.706213.706213 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d46950e7-2470-4db7-94f4-743a311e7bf1
DEBUG 01-04 15:36:08.706614.706614 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.711344.711344 client.py:127] Model loaded
DEBUG 01-04 15:36:08.711837.711837 cuda_h.py:19] end wait_experts cost 0.010653257369995117 seconds
DEBUG 01-04 15:36:08.711831.711831 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.711349.711349 lmp.py:384]   Computing 31 experts on GPU...
DEBUG 01-04 15:36:08.712678.712678 mlpmodule.py:531] gpu group tensors cost 0.0006501674652099609 s
INFO 01-04 15:36:08.712736.712736 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d46950e7-2470-4db7-94f4-743a311e7bf1
DEBUG 01-04 15:36:08.712169.712169 cuda_h.py:19] end load_into_gpu_async cost 0.006499052047729492 seconds
DEBUG 01-04 15:36:08.712494.712494 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.712697.712697 cuda_h.py:19] end restore_tensors2 cost 8.368492126464844e-05 seconds
DEBUG 01-04 15:36:08.712791.712791 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011490106582641602 seconds
INFO 01-04 15:36:08.713242.713242 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d46950e7-2470-4db7-94f4-743a311e7bf1
DEBUG 01-04 15:36:08.714424.714424 mlpmodule.py:564] gpu pad cost 0.002249002456665039 s
DEBUG 01-04 15:36:08.715614.715614 mlpmodule.py:582] gpu group einsum cost 0.0004596710205078125 s
DEBUG 01-04 15:36:08.716074.716074 mlpmodule.py:662]  experts func einsum cost 0.05217432975769043 s
DEBUG 01-04 15:36:08.718905.718905 mlpmodule.py:611] gpu experts func einsum cost 0.006428241729736328 s
DEBUG 01-04 15:36:08.718519.718519 cuda_h.py:19] end gpu_experts cost 0.006658315658569336 seconds
DEBUG 01-04 15:36:08.718321.718321 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.723758.723758 client.py:127] Model loaded
DEBUG 01-04 15:36:08.723694.723694 cuda_h.py:19] end sllm_worker_task cost 0.022110462188720703 seconds
DEBUG 01-04 15:36:08.723028.723028 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005056619644165039 seconds
DEBUG 01-04 15:36:08.723748.723748 cuda_h.py:19] end layer_moe_generate_25 cost 0.0710141658782959 seconds
DEBUG 01-04 15:36:08.723654.723654 lmp.py:207] -------------------------------- end layer 25 --------------------------------
DEBUG 01-04 15:36:08.723894.723894 lmp.py:169] -------------------------------- start layer 26 --------------------------------
DEBUG 01-04 15:36:08.723636.723636 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.724394.724394 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.726533.726533 cuda_h.py:19] end self_attn cost 0.0023322105407714844 seconds
DEBUG 01-04 15:36:08.726423.726423 cuda_h.py:19] end iln_self_attn_paln cost 0.0029039382934570312 seconds
DEBUG 01-04 15:36:08.726544.726544 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-04 15:36:08.726684.726684 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.727273.727273 cuda_h.py:19] end gate cost 0.0005428791046142578 seconds
DEBUG 01-04 15:36:08.727811.727811 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.727800.727800 lmp.py:281] 
DEBUG 01-04 15:36:08.727800.727800 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.727934.727934 lmp.py:282]   Total experts: 63
DEBUG 01-04 15:36:08.727153.727153 lmp.py:283]   CPU experts: 31 (49%)
DEBUG 01-04 15:36:08.727511.727511 lmp.py:284]   GPU experts: 32 (51%)
DEBUG 01-04 15:36:08.727724.727724 lmp.py:285] 
DEBUG 01-04 15:36:08.727724.727724 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.727413.727413 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.727348.727348 lmp.py:292]   Expert 55 |      1 | CPU
DEBUG 01-04 15:36:08.727799.727799 lmp.py:292]   Expert 15 |      2 | CPU
DEBUG 01-04 15:36:08.727057.727057 lmp.py:292]   Expert 17 |      2 | CPU
DEBUG 01-04 15:36:08.728793.728793 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:08.728813.728813 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:08.728834.728834 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:08.728092.728092 lmp.py:292]   Expert 21 |      4 | CPU
DEBUG 01-04 15:36:08.728590.728590 lmp.py:292]   Expert 54 |      4 | CPU
DEBUG 01-04 15:36:08.728610.728610 lmp.py:292]   Expert 56 |      4 | CPU
DEBUG 01-04 15:36:08.728630.728630 lmp.py:292]   Expert 19 |      5 | CPU
DEBUG 01-04 15:36:08.728412.728412 lmp.py:292]   Expert 26 |      5 | CPU
DEBUG 01-04 15:36:08.728671.728671 lmp.py:292]   Expert 24 |      6 | CPU
DEBUG 01-04 15:36:08.728692.728692 lmp.py:292]   Expert 20 |      9 | CPU
DEBUG 01-04 15:36:08.728473.728473 lmp.py:292]   Expert  9 |     10 | CPU
DEBUG 01-04 15:36:08.728686.728686 lmp.py:292]   Expert 47 |     11 | CPU
DEBUG 01-04 15:36:08.728660.728660 lmp.py:292]   Expert  7 |     13 | CPU
DEBUG 01-04 15:36:08.728396.728396 lmp.py:292]   Expert 28 |     13 | CPU
DEBUG 01-04 15:36:08.728370.728370 lmp.py:292]   Expert 53 |     14 | CPU
DEBUG 01-04 15:36:08.728105.728105 lmp.py:292]   Expert 32 |     15 | CPU
DEBUG 01-04 15:36:08.728364.728364 lmp.py:292]   Expert 43 |     16 | CPU
DEBUG 01-04 15:36:08.728623.728623 lmp.py:292]   Expert 45 |     17 | CPU
DEBUG 01-04 15:36:08.728405.728405 lmp.py:292]   Expert 59 |     19 | CPU
DEBUG 01-04 15:36:08.728187.728187 lmp.py:292]   Expert 61 |     19 | CPU
DEBUG 01-04 15:36:08.728969.728969 lmp.py:292]   Expert 62 |     21 | CPU
DEBUG 01-04 15:36:08.728751.728751 lmp.py:292]   Expert 12 |     22 | CPU
DEBUG 01-04 15:36:08.728533.728533 lmp.py:292]   Expert  6 |     24 | CPU
DEBUG 01-04 15:36:08.728315.728315 lmp.py:292]   Expert 30 |     25 | CPU
DEBUG 01-04 15:36:08.728335.728335 lmp.py:292]   Expert 38 |     26 | CPU
DEBUG 01-04 15:36:08.728130.728130 lmp.py:292]   Expert 41 |     28 | CPU
DEBUG 01-04 15:36:08.728079.728079 lmp.py:292]   Expert  8 |     33 | CPU
DEBUG 01-04 15:36:08.728245.728245 lmp.py:292]   Expert 11 |     34 | CPU
DEBUG 01-04 15:36:08.728696.728696 lmp.py:292]   Expert 51 |     34 | GPU
DEBUG 01-04 15:36:08.728385.728385 lmp.py:292]   Expert 14 |     37 | GPU
DEBUG 01-04 15:36:08.728313.728313 lmp.py:292]   Expert 23 |     37 | GPU
DEBUG 01-04 15:36:08.728002.728002 lmp.py:292]   Expert 44 |     38 | GPU
DEBUG 01-04 15:36:08.728691.728691 lmp.py:292]   Expert 25 |     40 | GPU
DEBUG 01-04 15:36:08.728188.728188 lmp.py:292]   Expert 27 |     48 | GPU
DEBUG 01-04 15:36:08.728924.728924 lmp.py:292]   Expert 33 |     48 | GPU
DEBUG 01-04 15:36:08.728660.728660 lmp.py:292]   Expert 39 |     49 | GPU
DEBUG 01-04 15:36:08.728395.728395 lmp.py:292]   Expert 16 |     51 | GPU
DEBUG 01-04 15:36:08.728369.728369 lmp.py:292]   Expert 29 |     53 | GPU
DEBUG 01-04 15:36:08.728105.728105 lmp.py:292]   Expert 31 |     53 | GPU
DEBUG 01-04 15:36:08.728079.728079 lmp.py:292]   Expert 37 |     53 | GPU
DEBUG 01-04 15:36:08.728815.728815 lmp.py:292]   Expert 46 |     54 | GPU
DEBUG 01-04 15:36:08.728981.728981 lmp.py:292]   Expert 57 |     57 | GPU
DEBUG 01-04 15:36:08.728147.728147 lmp.py:292]   Expert 63 |     59 | GPU
DEBUG 01-04 15:36:08.728313.728313 lmp.py:292]   Expert 18 |     60 | GPU
DEBUG 01-04 15:36:08.728479.728479 lmp.py:292]   Expert 48 |     61 | GPU
DEBUG 01-04 15:36:08.728453.728453 lmp.py:292]   Expert 42 |     63 | GPU
DEBUG 01-04 15:36:08.728189.728189 lmp.py:292]   Expert 34 |     66 | GPU
DEBUG 01-04 15:36:08.728401.728401 lmp.py:292]   Expert 22 |     80 | GPU
DEBUG 01-04 15:36:08.728899.728899 lmp.py:292]   Expert 35 |     85 | GPU
DEBUG 01-04 15:36:08.728873.728873 lmp.py:292]   Expert 36 |     85 | GPU
DEBUG 01-04 15:36:08.728085.728085 lmp.py:292]   Expert 52 |    113 | GPU
DEBUG 01-04 15:36:08.728821.728821 lmp.py:292]   Expert 10 |    147 | GPU
DEBUG 01-04 15:36:08.728795.728795 lmp.py:292]   Expert 50 |    151 | GPU
DEBUG 01-04 15:36:08.728530.728530 lmp.py:292]   Expert 40 |    162 | GPU
DEBUG 01-04 15:36:08.728504.728504 lmp.py:292]   Expert  0 |   1668 | GPU
DEBUG 01-04 15:36:08.728240.728240 lmp.py:292]   Expert  1 |   1671 | GPU
DEBUG 01-04 15:36:08.728929.728929 lmp.py:292]   Expert  3 |   1679 | GPU
DEBUG 01-04 15:36:08.728665.728665 lmp.py:292]   Expert  4 |   1684 | GPU
DEBUG 01-04 15:36:08.728162.728162 lmp.py:292]   Expert  5 |   1693 | GPU
DEBUG 01-04 15:36:08.728136.728136 lmp.py:292]   Expert  2 |   1700 | GPU
DEBUG 01-04 15:36:08.728302.728302 lmp.py:293] 
DEBUG 01-04 15:36:08.728302.728302 lmp.py:293]   CPU total tokens: 409 (3.3%)
DEBUG 01-04 15:36:08.728184.728184 lmp.py:294]   GPU total tokens: 11879 (96.7%)
DEBUG 01-04 15:36:08.729595.729595 cuda_h.py:19] end experts_map_get cost 0.001428842544555664 seconds
DEBUG 01-04 15:36:08.729476.729476 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.729637.729637 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.729966.729966 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.729578.729578 cuda_h.py:19] end allocate_cuda_memory cost 0.00024390220642089844 seconds
DEBUG 01-04 15:36:08.729136.729136 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.729223.729223 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.729655.729655 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.729842.729842 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5942ccd6-2497-4ac9-91c8-2932fe2b890e
DEBUG 01-04 15:36:08.729920.729920 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.731430.731430 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5942ccd6-2497-4ac9-91c8-2932fe2b890e
DEBUG 01-04 15:36:08.731465.731465 cuda_h.py:19] end load_into_gpu_async cost 0.0020728111267089844 seconds
DEBUG 01-04 15:36:08.731804.731804 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.731635.731635 cuda_h.py:19] end restore_tensors2 cost 0.0002734661102294922 seconds
DEBUG 01-04 15:36:08.732166.732166 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029311180114746094 seconds
DEBUG 01-04 15:36:08.734824.734824 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005597352981567383 seconds
DEBUG 01-04 15:36:08.734296.734296 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.734021.734021 lmp.py:339] 
DEBUG 01-04 15:36:08.734021.734021 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:08.734579.734579 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-04 15:36:08.734183.734183 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.745582.745582 mlpmodule.py:704] group tensors cost 0.009612798690795898 s
DEBUG 01-04 15:36:08.748544.748544 mlpmodule.py:742] pad cost 0.0025751590728759766 s
DEBUG 01-04 15:36:08.748197.748197 mlpmodule.py:748] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-04 15:36:08.748000.748000 mlpmodule.py:753] move to cpu cost 3.0517578125e-05 s
DEBUG 01-04 15:36:08.754147.754147 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:08.754036.754036 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.754826.754826 mlpmodule.py:774] group_w3 first element: 0.0145263671875
WARNING 01-04 15:36:08.754001.754001 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.759982.759982 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.759301.759301 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.765899.765899 mlpmodule.py:797] group einsum cost 0.016316652297973633 s
DEBUG 01-04 15:36:08.765278.765278 mlpmodule.py:805] cpy2cputensor cost 0.0001857280731201172 s
DEBUG 01-04 15:36:08.769542.769542 cuda_h.py:19] end wait_cetm_experts cost 0.03459310531616211 seconds
DEBUG 01-04 15:36:08.769840.769840 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.770047.770047 cuda_h.py:19] end gpu_sexperts cost 0.0006005764007568359 seconds
DEBUG 01-04 15:36:08.770751.770751 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-04 15:36:08.770143.770143 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-04 15:36:08.770483.770483 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.7670135498046875e-05 seconds
DEBUG 01-04 15:36:08.770292.770292 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 8.0108642578125e-05 seconds
DEBUG 01-04 15:36:08.770326.770326 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.770467.770467 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5942ccd6-2497-4ac9-91c8-2932fe2b890e
DEBUG 01-04 15:36:08.770519.770519 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:08.770159.770159 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.771148.771148 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.774906.774906 cuda_h.py:19] end allocate_cuda_memory cost 0.0036067962646484375 seconds
DEBUG 01-04 15:36:08.774060.774060 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.774876.774876 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.774044.774044 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.774945.774945 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e4dc21a-c313-4408-a5a2-04ad491d7e63
DEBUG 01-04 15:36:08.774803.774803 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.781593.781593 client.py:127] Model loaded
DEBUG 01-04 15:36:08.781628.781628 cuda_h.py:19] end wait_experts cost 0.01076054573059082 seconds
DEBUG 01-04 15:36:08.781960.781960 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.781855.781855 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.782173.782173 mlpmodule.py:531] gpu group tensors cost 0.0005006790161132812 s
INFO 01-04 15:36:08.782729.782729 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e4dc21a-c313-4408-a5a2-04ad491d7e63
DEBUG 01-04 15:36:08.782003.782003 cuda_h.py:19] end load_into_gpu_async cost 0.007536888122558594 seconds
DEBUG 01-04 15:36:08.782944.782944 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.782603.782603 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-04 15:36:08.782882.782882 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011489629745483398 seconds
INFO 01-04 15:36:08.783509.783509 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e4dc21a-c313-4408-a5a2-04ad491d7e63
DEBUG 01-04 15:36:08.783036.783036 mlpmodule.py:662]  experts func einsum cost 0.04823708534240723 s
DEBUG 01-04 15:36:08.784154.784154 mlpmodule.py:564] gpu pad cost 0.002346515655517578 s
DEBUG 01-04 15:36:08.785776.785776 mlpmodule.py:582] gpu group einsum cost 0.000457763671875 s
DEBUG 01-04 15:36:08.787838.787838 mlpmodule.py:611] gpu experts func einsum cost 0.0063283443450927734 s
DEBUG 01-04 15:36:08.787854.787854 cuda_h.py:19] end gpu_experts cost 0.006497621536254883 seconds
DEBUG 01-04 15:36:08.788279.788279 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:08.793378.793378 client.py:127] Model loaded
DEBUG 01-04 15:36:08.793904.793904 cuda_h.py:19] end sllm_worker_task cost 0.02225208282470703 seconds
DEBUG 01-04 15:36:08.793522.793522 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0052411556243896484 seconds
DEBUG 01-04 15:36:08.793818.793818 cuda_h.py:19] end layer_moe_generate_26 cost 0.06649923324584961 seconds
DEBUG 01-04 15:36:08.793566.793566 lmp.py:207] -------------------------------- end layer 26 --------------------------------
DEBUG 01-04 15:36:08.793567.793567 lmp.py:169] -------------------------------- start layer 27 --------------------------------
DEBUG 01-04 15:36:08.793640.793640 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:08.793437.793437 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:08.796683.796683 cuda_h.py:19] end self_attn cost 0.0023407936096191406 seconds
DEBUG 01-04 15:36:08.796905.796905 cuda_h.py:19] end iln_self_attn_paln cost 0.0029404163360595703 seconds
DEBUG 01-04 15:36:08.796887.796887 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-04 15:36:08.796981.796981 cuda_h.py:10] start gate
DEBUG 01-04 15:36:08.797717.797717 cuda_h.py:19] end gate cost 0.0005788803100585938 seconds
DEBUG 01-04 15:36:08.797401.797401 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:08.797331.797331 lmp.py:281] 
DEBUG 01-04 15:36:08.797331.797331 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:08.797372.797372 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:08.797306.797306 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:08.797141.797141 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:08.797308.797308 lmp.py:285] 
DEBUG 01-04 15:36:08.797308.797308 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:08.797189.797189 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:08.797792.797792 lmp.py:292]   Expert  7 |      1 | CPU
DEBUG 01-04 15:36:08.797197.797197 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:08.797409.797409 lmp.py:292]   Expert 38 |      1 | CPU
DEBUG 01-04 15:36:08.797383.797383 lmp.py:292]   Expert 47 |      1 | CPU
DEBUG 01-04 15:36:08.797881.797881 lmp.py:292]   Expert 59 |      1 | CPU
DEBUG 01-04 15:36:08.797855.797855 lmp.py:292]   Expert 61 |      1 | CPU
DEBUG 01-04 15:36:08.797829.797829 lmp.py:292]   Expert 52 |      2 | CPU
DEBUG 01-04 15:36:08.797564.797564 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:08.797300.797300 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:08.797797.797797 lmp.py:292]   Expert 34 |      4 | CPU
DEBUG 01-04 15:36:08.797533.797533 lmp.py:292]   Expert 32 |      5 | CPU
DEBUG 01-04 15:36:08.797792.797792 lmp.py:292]   Expert 39 |      5 | CPU
DEBUG 01-04 15:36:08.798289.798289 lmp.py:292]   Expert 18 |      6 | CPU
DEBUG 01-04 15:36:08.798978.798978 lmp.py:292]   Expert  6 |      7 | CPU
DEBUG 01-04 15:36:08.798429.798429 lmp.py:292]   Expert 10 |      7 | CPU
DEBUG 01-04 15:36:08.798834.798834 lmp.py:292]   Expert 12 |     10 | CPU
DEBUG 01-04 15:36:08.798284.798284 lmp.py:292]   Expert 20 |     12 | CPU
DEBUG 01-04 15:36:08.798259.798259 lmp.py:292]   Expert 22 |     13 | CPU
DEBUG 01-04 15:36:08.798994.798994 lmp.py:292]   Expert 24 |     13 | CPU
DEBUG 01-04 15:36:08.798491.798491 lmp.py:292]   Expert 46 |     14 | CPU
DEBUG 01-04 15:36:08.798227.798227 lmp.py:292]   Expert 63 |     18 | CPU
DEBUG 01-04 15:36:08.798678.798678 lmp.py:292]   Expert 19 |     19 | CPU
DEBUG 01-04 15:36:08.798175.798175 lmp.py:292]   Expert 54 |     20 | CPU
DEBUG 01-04 15:36:08.798388.798388 lmp.py:292]   Expert  8 |     22 | CPU
DEBUG 01-04 15:36:08.798885.798885 lmp.py:292]   Expert 29 |     22 | CPU
DEBUG 01-04 15:36:08.798620.798620 lmp.py:292]   Expert 30 |     22 | CPU
DEBUG 01-04 15:36:08.798879.798879 lmp.py:292]   Expert 33 |     22 | CPU
DEBUG 01-04 15:36:08.798568.798568 lmp.py:292]   Expert 37 |     22 | CPU
DEBUG 01-04 15:36:08.798019.798019 lmp.py:292]   Expert 42 |     22 | CPU
DEBUG 01-04 15:36:08.798185.798185 lmp.py:292]   Expert 11 |     23 | CPU
DEBUG 01-04 15:36:08.798636.798636 lmp.py:292]   Expert 51 |     26 | CPU
DEBUG 01-04 15:36:08.798087.798087 lmp.py:292]   Expert 23 |     28 | CPU
DEBUG 01-04 15:36:08.798300.798300 lmp.py:292]   Expert 26 |     29 | GPU
DEBUG 01-04 15:36:08.798797.798797 lmp.py:292]   Expert 48 |     30 | GPU
DEBUG 01-04 15:36:08.798771.798771 lmp.py:292]   Expert 40 |     35 | GPU
DEBUG 01-04 15:36:08.798268.798268 lmp.py:292]   Expert 45 |     38 | GPU
DEBUG 01-04 15:36:08.798004.798004 lmp.py:292]   Expert 28 |     39 | GPU
DEBUG 01-04 15:36:08.798739.798739 lmp.py:292]   Expert 13 |     40 | GPU
DEBUG 01-04 15:36:08.798952.798952 lmp.py:292]   Expert 31 |     43 | GPU
DEBUG 01-04 15:36:08.798403.798403 lmp.py:292]   Expert 25 |     44 | GPU
DEBUG 01-04 15:36:08.798377.798377 lmp.py:292]   Expert 55 |     44 | GPU
DEBUG 01-04 15:36:08.798828.798828 lmp.py:292]   Expert 57 |     46 | GPU
DEBUG 01-04 15:36:08.798279.798279 lmp.py:292]   Expert 49 |     47 | GPU
DEBUG 01-04 15:36:08.798776.798776 lmp.py:292]   Expert 56 |     49 | GPU
DEBUG 01-04 15:36:08.798511.798511 lmp.py:292]   Expert 16 |     53 | GPU
DEBUG 01-04 15:36:08.798532.798532 lmp.py:292]   Expert 35 |     56 | GPU
DEBUG 01-04 15:36:08.798267.798267 lmp.py:292]   Expert 17 |     60 | GPU
DEBUG 01-04 15:36:08.798526.798526 lmp.py:292]   Expert 62 |     60 | GPU
DEBUG 01-04 15:36:08.798262.798262 lmp.py:292]   Expert 44 |     68 | GPU
DEBUG 01-04 15:36:08.798521.798521 lmp.py:292]   Expert 43 |     69 | GPU
DEBUG 01-04 15:36:08.798256.798256 lmp.py:292]   Expert 36 |     70 | GPU
DEBUG 01-04 15:36:08.798992.798992 lmp.py:292]   Expert  9 |     74 | GPU
DEBUG 01-04 15:36:08.798204.798204 lmp.py:292]   Expert 27 |     74 | GPU
DEBUG 01-04 15:36:08.798417.798417 lmp.py:292]   Expert 41 |     76 | GPU
DEBUG 01-04 15:36:08.798629.798629 lmp.py:292]   Expert 21 |     97 | GPU
DEBUG 01-04 15:36:08.798080.798080 lmp.py:292]   Expert 50 |    101 | GPU
DEBUG 01-04 15:36:08.798577.798577 lmp.py:292]   Expert 14 |    120 | GPU
DEBUG 01-04 15:36:08.798551.798551 lmp.py:292]   Expert 60 |    146 | GPU
DEBUG 01-04 15:36:08.798049.798049 lmp.py:292]   Expert  1 |   1686 | GPU
DEBUG 01-04 15:36:08.798023.798023 lmp.py:292]   Expert  4 |   1687 | GPU
DEBUG 01-04 15:36:08.798758.798758 lmp.py:292]   Expert  3 |   1710 | GPU
DEBUG 01-04 15:36:08.798255.798255 lmp.py:292]   Expert  5 |   1711 | GPU
DEBUG 01-04 15:36:08.798230.798230 lmp.py:292]   Expert  0 |   1726 | GPU
DEBUG 01-04 15:36:08.798727.798727 lmp.py:292]   Expert  2 |   1785 | GPU
DEBUG 01-04 15:36:08.798178.798178 lmp.py:293] 
DEBUG 01-04 15:36:08.798178.798178 lmp.py:293]   CPU total tokens: 375 (3.1%)
DEBUG 01-04 15:36:08.798821.798821 lmp.py:294]   GPU total tokens: 11913 (96.9%)
DEBUG 01-04 15:36:08.798755.798755 cuda_h.py:19] end experts_map_get cost 0.0014622211456298828 seconds
DEBUG 01-04 15:36:08.798398.798398 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:08.798559.798559 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:08.799742.799742 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:08.799302.799302 cuda_h.py:19] end allocate_cuda_memory cost 0.0002758502960205078 seconds
DEBUG 01-04 15:36:08.799099.799099 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:08.799901.799901 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:08.799141.799141 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:08.799267.799267 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45e93e20-8d69-42e0-b319-23aee9e7a4c3
DEBUG 01-04 15:36:08.799306.799306 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:08.801846.801846 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45e93e20-8d69-42e0-b319-23aee9e7a4c3
DEBUG 01-04 15:36:08.801358.801358 cuda_h.py:19] end load_into_gpu_async cost 0.002161741256713867 seconds
DEBUG 01-04 15:36:08.801173.801173 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:08.801190.801190 cuda_h.py:19] end restore_tensors2 cost 0.0002682209014892578 seconds
DEBUG 01-04 15:36:08.802681.802681 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030469894409179688 seconds
DEBUG 01-04 15:36:08.804298.804298 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005689859390258789 seconds
DEBUG 01-04 15:36:08.804611.804611 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:08.804667.804667 lmp.py:339] 
DEBUG 01-04 15:36:08.804667.804667 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:08.804987.804987 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-04 15:36:08.804928.804928 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:08.819608.819608 mlpmodule.py:704] group tensors cost 0.014765739440917969 s
DEBUG 01-04 15:36:08.822972.822972 mlpmodule.py:742] pad cost 0.0015761852264404297 s
DEBUG 01-04 15:36:08.822545.822545 mlpmodule.py:748] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-04 15:36:08.822210.822210 mlpmodule.py:753] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-04 15:36:08.826127.826127 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:08.827354.827354 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:08.827813.827813 mlpmodule.py:774] group_w3 first element: -0.000606536865234375
WARNING 01-04 15:36:08.827903.827903 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:08.830152.830152 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:08.831622.831622 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:08.835998.835998 mlpmodule.py:797] group einsum cost 0.01300358772277832 s
DEBUG 01-04 15:36:08.835084.835084 mlpmodule.py:805] cpy2cputensor cost 0.0001423358917236328 s
DEBUG 01-04 15:36:08.839085.839085 cuda_h.py:19] end wait_cetm_experts cost 0.03486227989196777 seconds
DEBUG 01-04 15:36:08.839091.839091 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:08.840299.840299 cuda_h.py:19] end gpu_sexperts cost 0.0006330013275146484 seconds
DEBUG 01-04 15:36:08.840394.840394 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-04 15:36:08.840615.840615 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.4066696166992188e-05 seconds
DEBUG 01-04 15:36:08.840848.840848 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:08.840326.840326 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45e93e20-8d69-42e0-b319-23aee9e7a4c3
INFO 01-04 15:36:08.852043.852043 client.py:127] Model loaded
DEBUG 01-04 15:36:08.852430.852430 cuda_h.py:19] end wait_experts cost 0.011420011520385742 seconds
DEBUG 01-04 15:36:08.852517.852517 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:08.852365.852365 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:08.852544.852544 mlpmodule.py:531] gpu group tensors cost 0.0005114078521728516 s
DEBUG 01-04 15:36:08.854276.854276 mlpmodule.py:662]  experts func einsum cost 0.04917144775390625 s
DEBUG 01-04 15:36:08.855867.855867 mlpmodule.py:564] gpu pad cost 0.002662181854248047 s
DEBUG 01-04 15:36:08.856508.856508 mlpmodule.py:582] gpu group einsum cost 0.0006480216979980469 s
DEBUG 01-04 15:36:08.859381.859381 mlpmodule.py:611] gpu experts func einsum cost 0.0069217681884765625 s
DEBUG 01-04 15:36:08.859027.859027 cuda_h.py:19] end gpu_experts cost 0.007090091705322266 seconds
DEBUG 01-04 15:36:08.859067.859067 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:08.859453.859453 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.775161743164062e-06 seconds
DEBUG 01-04 15:36:08.863167.863167 cuda_h.py:19] end layer_moe_generate_27 cost 0.06646609306335449 seconds
DEBUG 01-04 15:36:08.863590.863590 lmp.py:207] -------------------------------- end layer 27 --------------------------------
DEBUG 01-04 15:36:08.863697.863697 cuda_h.py:19] end multi_layer cost 2.5207509994506836 seconds
DEBUG 01-04 15:36:12.040000.040000 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09990143775939941 s
DEBUG 01-04 15:36:12.392734.392734 cuda_h.py:19] end generate_input_ids cost 0.35161685943603516 seconds
DEBUG 01-04 15:36:12.392898.392898 cuda_h.py:10] start init_cache
DEBUG 01-04 15:36:12.393716.393716 cuda_h.py:19] end init_cache cost 7.05718994140625e-05 seconds
DEBUG 01-04 15:36:14.828125.828125 cuda_h.py:10] start init_weights
DEBUG 01-04 15:36:14.830003.830003 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:14.830490.830490 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:14.832604.832604 cuda_h.py:19] end allocate_cuda_memory cost 0.0021893978118896484 seconds
DEBUG 01-04 15:36:14.832659.832659 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:14.832800.832800 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:14.832523.832523 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:14.832557.832557 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 291fe616-a837-4434-b5f1-d8330b44fe08
DEBUG 01-04 15:36:14.832156.832156 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:14.834171.834171 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 291fe616-a837-4434-b5f1-d8330b44fe08
DEBUG 01-04 15:36:14.834831.834831 cuda_h.py:19] end load_into_gpu_async cost 0.002113819122314453 seconds
DEBUG 01-04 15:36:14.834972.834972 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:14.834898.834898 cuda_h.py:19] end restore_tensors2 cost 9.274482727050781e-05 seconds
DEBUG 01-04 15:36:14.834694.834694 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004728078842163086 seconds
INFO 01-04 15:36:14.834786.834786 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 291fe616-a837-4434-b5f1-d8330b44fe08
INFO 01-04 15:36:14.914865.914865 client.py:127] Model loaded
DEBUG 01-04 15:36:14.914030.914030 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-04 15:36:14.914405.914405 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:14.914383.914383 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:14.915193.915193 cuda_h.py:19] end allocate_cuda_memory cost 0.0003662109375 seconds
DEBUG 01-04 15:36:14.915005.915005 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:14.915975.915975 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:14.915773.915773 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:14.915914.915914 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0cb1d49f-8010-4903-9586-4329d27b1104
DEBUG 01-04 15:36:14.915430.915430 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:14.917662.917662 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0cb1d49f-8010-4903-9586-4329d27b1104
DEBUG 01-04 15:36:14.917826.917826 cuda_h.py:19] end load_into_gpu_async cost 0.002058267593383789 seconds
DEBUG 01-04 15:36:14.917226.917226 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:14.917034.917034 cuda_h.py:19] end restore_tensors2 cost 0.00012922286987304688 seconds
DEBUG 01-04 15:36:14.918918.918918 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031774044036865234 seconds
INFO 01-04 15:36:14.918351.918351 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0cb1d49f-8010-4903-9586-4329d27b1104
INFO 01-04 15:36:14.934494.934494 client.py:127] Model loaded
DEBUG 01-04 15:36:14.935621.935621 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02089691162109375 seconds
DEBUG 01-04 15:36:14.935645.935645 cuda_h.py:19] end init_weights cost 0.10577845573425293 seconds
DEBUG 01-04 15:36:14.935654.935654 cuda_h.py:10] start copy_emodel
DEBUG 01-04 15:36:15.720715.720715 cuda_h.py:19] end copy_emodel cost 0.784949541091919 seconds
DEBUG 01-04 15:36:15.721450.721450 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-04 15:36:15.722687.722687 cuda_h.py:19] end init_inputs_tokens cost 0.00028967857360839844 seconds
DEBUG 01-04 15:36:15.722364.722364 cuda_h.py:10] start multi_layer
DEBUG 01-04 15:36:15.722570.722570 lmp.py:169] -------------------------------- start layer 0 --------------------------------
DEBUG 01-04 15:36:15.722882.722882 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:15.722280.722280 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:15.725666.725666 cuda_h.py:19] end self_attn cost 0.002961874008178711 seconds
DEBUG 01-04 15:36:15.726583.726583 cuda_h.py:19] end iln_self_attn_paln cost 0.003894805908203125 seconds
DEBUG 01-04 15:36:15.726691.726691 cuda_h.py:10] start dense_mlp
DEBUG 01-04 15:36:15.726831.726831 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-04 15:36:15.726243.726243 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.2901763916015625e-05 seconds
DEBUG 01-04 15:36:15.726446.726446 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:15.726775.726775 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.726638.726638 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.726468.726468 cuda_h.py:19] end allocate_cuda_memory cost 0.0002143383026123047 seconds
DEBUG 01-04 15:36:15.727813.727813 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.727113.727113 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.727175.727175 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.727938.727938 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 52f5c1a6-6dc4-4c25-85b1-7297727bd0e7
DEBUG 01-04 15:36:15.727048.727048 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.729458.729458 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 52f5c1a6-6dc4-4c25-85b1-7297727bd0e7
DEBUG 01-04 15:36:15.729024.729024 cuda_h.py:19] end load_into_gpu_async cost 0.002075672149658203 seconds
DEBUG 01-04 15:36:15.729449.729449 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.729313.729313 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-04 15:36:15.729937.729937 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028145313262939453 seconds
INFO 01-04 15:36:15.729052.729052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 52f5c1a6-6dc4-4c25-85b1-7297727bd0e7
INFO 01-04 15:36:15.737565.737565 client.py:127] Model loaded
DEBUG 01-04 15:36:15.737299.737299 cuda_h.py:19] end sllm_worker_task cost 0.011085033416748047 seconds
DEBUG 01-04 15:36:15.737742.737742 cuda_h.py:19] end dense_mlp cost 0.011583805084228516 seconds
DEBUG 01-04 15:36:15.737852.737852 lmp.py:207] -------------------------------- end layer 0 --------------------------------
DEBUG 01-04 15:36:15.737900.737900 lmp.py:169] -------------------------------- start layer 1 --------------------------------
DEBUG 01-04 15:36:15.737165.737165 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:15.738616.738616 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:15.740563.740563 cuda_h.py:19] end self_attn cost 0.0022957324981689453 seconds
DEBUG 01-04 15:36:15.740413.740413 cuda_h.py:19] end iln_self_attn_paln cost 0.002821683883666992 seconds
DEBUG 01-04 15:36:15.740064.740064 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-04 15:36:15.740019.740019 cuda_h.py:10] start gate
DEBUG 01-04 15:36:15.741068.741068 cuda_h.py:19] end gate cost 0.0006346702575683594 seconds
DEBUG 01-04 15:36:15.741480.741480 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:15.741192.741192 lmp.py:281] 
DEBUG 01-04 15:36:15.741192.741192 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:15.741517.741517 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:15.741736.741736 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:15.741141.741141 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:15.741115.741115 lmp.py:285] 
DEBUG 01-04 15:36:15.741115.741115 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:15.741612.741612 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:15.742831.742831 lmp.py:292]   Expert 62 |     66 | CPU
DEBUG 01-04 15:36:15.742044.742044 lmp.py:292]   Expert 18 |     68 | CPU
DEBUG 01-04 15:36:15.742495.742495 lmp.py:292]   Expert 22 |     73 | CPU
DEBUG 01-04 15:36:15.742184.742184 lmp.py:292]   Expert 32 |     83 | CPU
DEBUG 01-04 15:36:15.742112.742112 lmp.py:292]   Expert 52 |     94 | CPU
DEBUG 01-04 15:36:15.742563.742563 lmp.py:292]   Expert  3 |    104 | CPU
DEBUG 01-04 15:36:15.742252.742252 lmp.py:292]   Expert 27 |    114 | CPU
DEBUG 01-04 15:36:15.742749.742749 lmp.py:292]   Expert 38 |    114 | CPU
DEBUG 01-04 15:36:15.742246.742246 lmp.py:292]   Expert 13 |    118 | CPU
DEBUG 01-04 15:36:15.742505.742505 lmp.py:292]   Expert 54 |    118 | CPU
DEBUG 01-04 15:36:15.742764.742764 lmp.py:292]   Expert 17 |    121 | CPU
DEBUG 01-04 15:36:15.742023.742023 lmp.py:292]   Expert 11 |    124 | CPU
DEBUG 01-04 15:36:15.742043.742043 lmp.py:292]   Expert 28 |    124 | CPU
DEBUG 01-04 15:36:15.742779.742779 lmp.py:292]   Expert 37 |    125 | CPU
DEBUG 01-04 15:36:15.742037.742037 lmp.py:292]   Expert 58 |    129 | CPU
DEBUG 01-04 15:36:15.742296.742296 lmp.py:292]   Expert 39 |    131 | CPU
DEBUG 01-04 15:36:15.742317.742317 lmp.py:292]   Expert 25 |    135 | CPU
DEBUG 01-04 15:36:15.742337.742337 lmp.py:292]   Expert 41 |    136 | CPU
DEBUG 01-04 15:36:15.742357.742357 lmp.py:292]   Expert 21 |    150 | CPU
DEBUG 01-04 15:36:15.742855.742855 lmp.py:292]   Expert  4 |    151 | CPU
DEBUG 01-04 15:36:15.742067.742067 lmp.py:292]   Expert 30 |    152 | CPU
DEBUG 01-04 15:36:15.742279.742279 lmp.py:292]   Expert 29 |    155 | CPU
DEBUG 01-04 15:36:15.742730.742730 lmp.py:292]   Expert 53 |    155 | CPU
DEBUG 01-04 15:36:15.742228.742228 lmp.py:292]   Expert 49 |    156 | CPU
DEBUG 01-04 15:36:15.742248.742248 lmp.py:292]   Expert 47 |    157 | CPU
DEBUG 01-04 15:36:15.742268.742268 lmp.py:292]   Expert 31 |    168 | CPU
DEBUG 01-04 15:36:15.742289.742289 lmp.py:292]   Expert 33 |    168 | CPU
DEBUG 01-04 15:36:15.742071.742071 lmp.py:292]   Expert 55 |    173 | CPU
DEBUG 01-04 15:36:15.742091.742091 lmp.py:292]   Expert 56 |    173 | CPU
DEBUG 01-04 15:36:15.742350.742350 lmp.py:292]   Expert 15 |    177 | CPU
DEBUG 01-04 15:36:15.742609.742609 lmp.py:292]   Expert  0 |    178 | CPU
DEBUG 01-04 15:36:15.742629.742629 lmp.py:292]   Expert  1 |    178 | CPU
DEBUG 01-04 15:36:15.742888.742888 lmp.py:292]   Expert 24 |    180 | GPU
DEBUG 01-04 15:36:15.742670.742670 lmp.py:292]   Expert 50 |    182 | GPU
DEBUG 01-04 15:36:15.742690.742690 lmp.py:292]   Expert 51 |    184 | GPU
DEBUG 01-04 15:36:15.742949.742949 lmp.py:292]   Expert 19 |    185 | GPU
DEBUG 01-04 15:36:15.742208.742208 lmp.py:292]   Expert  6 |    186 | GPU
DEBUG 01-04 15:36:15.742228.742228 lmp.py:292]   Expert 10 |    189 | GPU
DEBUG 01-04 15:36:15.742679.742679 lmp.py:292]   Expert 34 |    191 | GPU
DEBUG 01-04 15:36:15.742891.742891 lmp.py:292]   Expert  2 |    195 | GPU
DEBUG 01-04 15:36:15.742912.742912 lmp.py:292]   Expert 45 |    195 | GPU
DEBUG 01-04 15:36:15.742932.742932 lmp.py:292]   Expert 35 |    197 | GPU
DEBUG 01-04 15:36:15.742191.742191 lmp.py:292]   Expert 36 |    198 | GPU
DEBUG 01-04 15:36:15.742973.742973 lmp.py:292]   Expert 61 |    209 | GPU
DEBUG 01-04 15:36:15.742755.742755 lmp.py:292]   Expert 44 |    214 | GPU
DEBUG 01-04 15:36:15.742014.742014 lmp.py:292]   Expert 12 |    223 | GPU
DEBUG 01-04 15:36:15.742272.742272 lmp.py:292]   Expert  5 |    227 | GPU
DEBUG 01-04 15:36:15.742054.742054 lmp.py:292]   Expert 23 |    235 | GPU
DEBUG 01-04 15:36:15.742552.742552 lmp.py:292]   Expert 60 |    235 | GPU
DEBUG 01-04 15:36:15.742333.742333 lmp.py:292]   Expert 43 |    239 | GPU
DEBUG 01-04 15:36:15.742354.742354 lmp.py:292]   Expert  9 |    246 | GPU
DEBUG 01-04 15:36:15.742374.742374 lmp.py:292]   Expert 48 |    252 | GPU
DEBUG 01-04 15:36:15.742395.742395 lmp.py:292]   Expert  8 |    262 | GPU
DEBUG 01-04 15:36:15.742177.742177 lmp.py:292]   Expert 20 |    273 | GPU
DEBUG 01-04 15:36:15.742197.742197 lmp.py:292]   Expert 26 |    285 | GPU
DEBUG 01-04 15:36:15.742456.742456 lmp.py:292]   Expert 57 |    292 | GPU
DEBUG 01-04 15:36:15.742668.742668 lmp.py:292]   Expert  7 |    308 | GPU
DEBUG 01-04 15:36:15.742642.742642 lmp.py:292]   Expert 59 |    308 | GPU
DEBUG 01-04 15:36:15.742477.742477 lmp.py:292]   Expert 16 |    310 | GPU
DEBUG 01-04 15:36:15.742451.742451 lmp.py:292]   Expert 63 |    313 | GPU
DEBUG 01-04 15:36:15.742710.742710 lmp.py:292]   Expert 40 |    320 | GPU
DEBUG 01-04 15:36:15.742730.742730 lmp.py:292]   Expert 46 |    320 | GPU
DEBUG 01-04 15:36:15.742274.742274 lmp.py:292]   Expert 42 |    342 | GPU
DEBUG 01-04 15:36:15.742294.742294 lmp.py:292]   Expert 14 |    525 | GPU
DEBUG 01-04 15:36:15.743030.743030 lmp.py:293] 
DEBUG 01-04 15:36:15.743030.743030 lmp.py:293]   CPU total tokens: 4268 (34.7%)
DEBUG 01-04 15:36:15.743004.743004 lmp.py:294]   GPU total tokens: 8020 (65.3%)
DEBUG 01-04 15:36:15.743270.743270 cuda_h.py:19] end experts_map_get cost 0.0013976097106933594 seconds
DEBUG 01-04 15:36:15.743005.743005 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:15.743682.743682 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.743667.743667 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.743389.743389 cuda_h.py:19] end allocate_cuda_memory cost 0.00018596649169921875 seconds
DEBUG 01-04 15:36:15.743749.743749 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.743644.743644 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.743068.743068 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.743526.743526 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de0a90dd-55b6-4822-801c-1b099e71be88
DEBUG 01-04 15:36:15.743717.743717 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.745883.745883 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de0a90dd-55b6-4822-801c-1b099e71be88
DEBUG 01-04 15:36:15.745451.745451 cuda_h.py:19] end load_into_gpu_async cost 0.0023322105407714844 seconds
DEBUG 01-04 15:36:15.745222.745222 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.746226.746226 cuda_h.py:19] end restore_tensors2 cost 0.0004658699035644531 seconds
DEBUG 01-04 15:36:15.746917.746917 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034160614013671875 seconds
DEBUG 01-04 15:36:15.749721.749721 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006119251251220703 seconds
DEBUG 01-04 15:36:15.749564.749564 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:15.749388.749388 lmp.py:339] 
DEBUG 01-04 15:36:15.749388.749388 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:15.749138.749138 cuda_h.py:19] end cpu_experts_submit cost 0.00011301040649414062 seconds
DEBUG 01-04 15:36:15.749457.749457 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:15.761326.761326 mlpmodule.py:704] group tensors cost 0.012178897857666016 s
DEBUG 01-04 15:36:15.764041.764041 mlpmodule.py:742] pad cost 0.001836538314819336 s
DEBUG 01-04 15:36:15.764191.764191 mlpmodule.py:748] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-04 15:36:15.764392.764392 mlpmodule.py:753] move to cpu cost 4.1484832763671875e-05 s
DEBUG 01-04 15:36:15.776243.776243 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:15.777349.777349 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:15.777478.777478 mlpmodule.py:774] group_w3 first element: -0.0107421875
WARNING 01-04 15:36:15.777052.777052 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:15.785713.785713 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:15.786472.786472 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:15.795265.795265 mlpmodule.py:797] group einsum cost 0.030942916870117188 s
DEBUG 01-04 15:36:15.796879.796879 mlpmodule.py:805] cpy2cputensor cost 0.0007488727569580078 s
DEBUG 01-04 15:36:15.802091.802091 cuda_h.py:19] end wait_cetm_experts cost 0.053511619567871094 seconds
DEBUG 01-04 15:36:15.803836.803836 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:15.803098.803098 cuda_h.py:19] end gpu_sexperts cost 0.0006392002105712891 seconds
DEBUG 01-04 15:36:15.803332.803332 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-04 15:36:15.803154.803154 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-04 15:36:15.803541.803541 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.504753112792969e-05 seconds
DEBUG 01-04 15:36:15.804861.804861 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:15.804512.804512 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 0.00015997886657714844 seconds
DEBUG 01-04 15:36:15.804097.804097 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.804503.804503 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:15.804031.804031 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de0a90dd-55b6-4822-801c-1b099e71be88
DEBUG 01-04 15:36:15.804188.804188 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.809388.809388 cuda_h.py:19] end allocate_cuda_memory cost 0.004515409469604492 seconds
DEBUG 01-04 15:36:15.809119.809119 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.809697.809697 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.809877.809877 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.809541.809541 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7ecce2f2-6b13-497b-8f4c-940adaae58be
DEBUG 01-04 15:36:15.809915.809915 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.809167.809167 client.py:127] Model loaded
DEBUG 01-04 15:36:15.809501.809501 cuda_h.py:19] end wait_experts cost 0.005337715148925781 seconds
DEBUG 01-04 15:36:15.809588.809588 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:15.809152.809152 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:15.810359.810359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7ecce2f2-6b13-497b-8f4c-940adaae58be
DEBUG 01-04 15:36:15.810738.810738 cuda_h.py:19] end load_into_gpu_async cost 0.0016448497772216797 seconds
DEBUG 01-04 15:36:15.810302.810302 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.816260.816260 cuda_h.py:19] end restore_tensors2 cost 0.0056188106536865234 seconds
DEBUG 01-04 15:36:15.816533.816533 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012326955795288086 seconds
INFO 01-04 15:36:15.817654.817654 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7ecce2f2-6b13-497b-8f4c-940adaae58be
INFO 01-04 15:36:15.818013.818013 client.py:127] Model loaded
DEBUG 01-04 15:36:15.818611.818611 cuda_h.py:19] end sllm_worker_task cost 0.013974905014038086 seconds
DEBUG 01-04 15:36:15.822351.822351 mlpmodule.py:662]  experts func einsum cost 0.07286238670349121 s
DEBUG 01-04 15:36:15.822036.822036 mlpmodule.py:531] gpu group tensors cost 0.012857913970947266 s
DEBUG 01-04 15:36:15.824907.824907 mlpmodule.py:564] gpu pad cost 0.0017969608306884766 s
DEBUG 01-04 15:36:15.825194.825194 mlpmodule.py:582] gpu group einsum cost 0.0011556148529052734 s
DEBUG 01-04 15:36:15.829258.829258 mlpmodule.py:611] gpu experts func einsum cost 0.01969599723815918 s
DEBUG 01-04 15:36:15.829330.829330 cuda_h.py:19] end gpu_experts cost 0.019969701766967773 seconds
DEBUG 01-04 15:36:15.829385.829385 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:15.829844.829844 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1696090698242188e-05 seconds
DEBUG 01-04 15:36:15.829021.829021 cuda_h.py:19] end layer_moe_generate_1 cost 0.08908390998840332 seconds
DEBUG 01-04 15:36:15.830286.830286 lmp.py:207] -------------------------------- end layer 1 --------------------------------
DEBUG 01-04 15:36:15.830778.830778 lmp.py:169] -------------------------------- start layer 2 --------------------------------
DEBUG 01-04 15:36:15.830050.830050 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:15.830876.830876 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:15.833351.833351 cuda_h.py:19] end self_attn cost 0.0028519630432128906 seconds
DEBUG 01-04 15:36:15.833772.833772 cuda_h.py:19] end iln_self_attn_paln cost 0.003518342971801758 seconds
DEBUG 01-04 15:36:15.833370.833370 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-04 15:36:15.833225.833225 cuda_h.py:10] start gate
DEBUG 01-04 15:36:15.834006.834006 cuda_h.py:19] end gate cost 0.0005435943603515625 seconds
DEBUG 01-04 15:36:15.834736.834736 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:15.834765.834765 lmp.py:281] 
DEBUG 01-04 15:36:15.834765.834765 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:15.834706.834706 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:15.834733.834733 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:15.834661.834661 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:15.834635.834635 lmp.py:285] 
DEBUG 01-04 15:36:15.834635.834635 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:15.834371.834371 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:15.834590.834590 lmp.py:292]   Expert 34 |     42 | CPU
DEBUG 01-04 15:36:15.834564.834564 lmp.py:292]   Expert 36 |     49 | CPU
DEBUG 01-04 15:36:15.834300.834300 lmp.py:292]   Expert 58 |     65 | CPU
DEBUG 01-04 15:36:15.834558.834558 lmp.py:292]   Expert  3 |     67 | CPU
DEBUG 01-04 15:36:15.834056.834056 lmp.py:292]   Expert 26 |     68 | CPU
DEBUG 01-04 15:36:15.834791.834791 lmp.py:292]   Expert 27 |     78 | CPU
DEBUG 01-04 15:36:15.834288.834288 lmp.py:292]   Expert  8 |     79 | CPU
DEBUG 01-04 15:36:15.834309.834309 lmp.py:292]   Expert 29 |     80 | CPU
DEBUG 01-04 15:36:15.835568.835568 lmp.py:292]   Expert  7 |     93 | CPU
DEBUG 01-04 15:36:15.835588.835588 lmp.py:292]   Expert 10 |     99 | CPU
DEBUG 01-04 15:36:15.835608.835608 lmp.py:292]   Expert 28 |    106 | CPU
DEBUG 01-04 15:36:15.835390.835390 lmp.py:292]   Expert 21 |    107 | CPU
DEBUG 01-04 15:36:15.835411.835411 lmp.py:292]   Expert 13 |    109 | CPU
DEBUG 01-04 15:36:15.835193.835193 lmp.py:292]   Expert 19 |    114 | CPU
DEBUG 01-04 15:36:15.835451.835451 lmp.py:292]   Expert 62 |    124 | CPU
DEBUG 01-04 15:36:15.835664.835664 lmp.py:292]   Expert 40 |    136 | CPU
DEBUG 01-04 15:36:15.835923.835923 lmp.py:292]   Expert  5 |    139 | CPU
DEBUG 01-04 15:36:15.835897.835897 lmp.py:292]   Expert 52 |    141 | CPU
DEBUG 01-04 15:36:15.835917.835917 lmp.py:292]   Expert 63 |    142 | CPU
DEBUG 01-04 15:36:15.835937.835937 lmp.py:292]   Expert  9 |    148 | CPU
DEBUG 01-04 15:36:15.835719.835719 lmp.py:292]   Expert 25 |    150 | CPU
DEBUG 01-04 15:36:15.835501.835501 lmp.py:292]   Expert 50 |    152 | CPU
DEBUG 01-04 15:36:15.835283.835283 lmp.py:292]   Expert 59 |    152 | CPU
DEBUG 01-04 15:36:15.835065.835065 lmp.py:292]   Expert 33 |    154 | CPU
DEBUG 01-04 15:36:15.835086.835086 lmp.py:292]   Expert 49 |    156 | CPU
DEBUG 01-04 15:36:15.835868.835868 lmp.py:292]   Expert 17 |    158 | CPU
DEBUG 01-04 15:36:15.835888.835888 lmp.py:292]   Expert 16 |    160 | CPU
DEBUG 01-04 15:36:15.835670.835670 lmp.py:292]   Expert 60 |    165 | CPU
DEBUG 01-04 15:36:15.835690.835690 lmp.py:292]   Expert  0 |    167 | CPU
DEBUG 01-04 15:36:15.835472.835472 lmp.py:292]   Expert 24 |    167 | CPU
DEBUG 01-04 15:36:15.835493.835493 lmp.py:292]   Expert 30 |    170 | CPU
DEBUG 01-04 15:36:15.835513.835513 lmp.py:292]   Expert 35 |    170 | CPU
DEBUG 01-04 15:36:15.835725.835725 lmp.py:292]   Expert  1 |    175 | GPU
DEBUG 01-04 15:36:15.835223.835223 lmp.py:292]   Expert 38 |    179 | GPU
DEBUG 01-04 15:36:15.835435.835435 lmp.py:292]   Expert 45 |    180 | GPU
DEBUG 01-04 15:36:15.835171.835171 lmp.py:292]   Expert 44 |    183 | GPU
DEBUG 01-04 15:36:15.835430.835430 lmp.py:292]   Expert  6 |    184 | GPU
DEBUG 01-04 15:36:15.835211.835211 lmp.py:292]   Expert 31 |    199 | GPU
DEBUG 01-04 15:36:15.835993.835993 lmp.py:292]   Expert 48 |    206 | GPU
DEBUG 01-04 15:36:15.835014.835014 lmp.py:292]   Expert 39 |    228 | GPU
DEBUG 01-04 15:36:15.835034.835034 lmp.py:292]   Expert 37 |    237 | GPU
DEBUG 01-04 15:36:15.835816.835816 lmp.py:292]   Expert 55 |    238 | GPU
DEBUG 01-04 15:36:15.835836.835836 lmp.py:292]   Expert 22 |    240 | GPU
DEBUG 01-04 15:36:15.835380.835380 lmp.py:292]   Expert  4 |    242 | GPU
DEBUG 01-04 15:36:15.835924.835924 lmp.py:292]   Expert 14 |    242 | GPU
DEBUG 01-04 15:36:15.835705.835705 lmp.py:292]   Expert 51 |    248 | GPU
DEBUG 01-04 15:36:15.835249.835249 lmp.py:292]   Expert 57 |    251 | GPU
DEBUG 01-04 15:36:15.835269.835269 lmp.py:292]   Expert  2 |    253 | GPU
DEBUG 01-04 15:36:15.835005.835005 lmp.py:292]   Expert 41 |    254 | GPU
DEBUG 01-04 15:36:15.835741.835741 lmp.py:292]   Expert 12 |    263 | GPU
DEBUG 01-04 15:36:15.835761.835761 lmp.py:292]   Expert 47 |    269 | GPU
DEBUG 01-04 15:36:15.835258.835258 lmp.py:292]   Expert 20 |    273 | GPU
DEBUG 01-04 15:36:15.835948.835948 lmp.py:292]   Expert 15 |    275 | GPU
DEBUG 01-04 15:36:15.835968.835968 lmp.py:292]   Expert 42 |    281 | GPU
DEBUG 01-04 15:36:15.835511.835511 lmp.py:292]   Expert 23 |    283 | GPU
DEBUG 01-04 15:36:15.835817.835817 lmp.py:292]   Expert 53 |    304 | GPU
DEBUG 01-04 15:36:15.835360.835360 lmp.py:292]   Expert 61 |    306 | GPU
DEBUG 01-04 15:36:15.835904.835904 lmp.py:292]   Expert 56 |    312 | GPU
DEBUG 01-04 15:36:15.835686.835686 lmp.py:292]   Expert 18 |    314 | GPU
DEBUG 01-04 15:36:15.835229.835229 lmp.py:292]   Expert 54 |    314 | GPU
DEBUG 01-04 15:36:15.835249.835249 lmp.py:292]   Expert 46 |    329 | GPU
DEBUG 01-04 15:36:15.835031.835031 lmp.py:292]   Expert 32 |    339 | GPU
DEBUG 01-04 15:36:15.835052.835052 lmp.py:292]   Expert 43 |    364 | GPU
DEBUG 01-04 15:36:15.835595.835595 lmp.py:292]   Expert 11 |    416 | GPU
DEBUG 01-04 15:36:15.835331.835331 lmp.py:293] 
DEBUG 01-04 15:36:15.835331.835331 lmp.py:293]   CPU total tokens: 3907 (31.8%)
DEBUG 01-04 15:36:15.835497.835497 lmp.py:294]   GPU total tokens: 8381 (68.2%)
DEBUG 01-04 15:36:15.835763.835763 cuda_h.py:19] end experts_map_get cost 0.0013630390167236328 seconds
DEBUG 01-04 15:36:15.835452.835452 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:15.835751.835751 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.836491.836491 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.836140.836140 cuda_h.py:19] end allocate_cuda_memory cost 0.00016760826110839844 seconds
DEBUG 01-04 15:36:15.836075.836075 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.836070.836070 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.836635.836635 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.836762.836762 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2886b7e9-4d2e-499a-8c4a-16dccfc58e32
DEBUG 01-04 15:36:15.836073.836073 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.838679.838679 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2886b7e9-4d2e-499a-8c4a-16dccfc58e32
DEBUG 01-04 15:36:15.838555.838555 cuda_h.py:19] end load_into_gpu_async cost 0.0022177696228027344 seconds
DEBUG 01-04 15:36:15.838205.838205 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.839139.839139 cuda_h.py:19] end restore_tensors2 cost 0.00037598609924316406 seconds
DEBUG 01-04 15:36:15.839213.839213 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003093242645263672 seconds
DEBUG 01-04 15:36:15.841621.841621 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005820512771606445 seconds
DEBUG 01-04 15:36:15.841902.841902 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:15.841149.841149 lmp.py:339] 
DEBUG 01-04 15:36:15.841149.841149 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:15.841847.841847 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-04 15:36:15.841424.841424 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:15.854741.854741 mlpmodule.py:704] group tensors cost 0.012105226516723633 s
DEBUG 01-04 15:36:15.856421.856421 mlpmodule.py:742] pad cost 0.0018239021301269531 s
DEBUG 01-04 15:36:15.856637.856637 mlpmodule.py:748] create cpu tensor cost 6.341934204101562e-05 s
DEBUG 01-04 15:36:15.856401.856401 mlpmodule.py:753] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-04 15:36:15.870087.870087 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:15.870172.870172 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:15.870792.870792 mlpmodule.py:774] group_w3 first element: -0.0380859375
WARNING 01-04 15:36:15.870028.870028 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:15.878387.878387 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:15.879160.879160 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:15.888749.888749 mlpmodule.py:797] group einsum cost 0.031468868255615234 s
DEBUG 01-04 15:36:15.889413.889413 mlpmodule.py:805] cpy2cputensor cost 0.0006422996520996094 s
DEBUG 01-04 15:36:15.895243.895243 cuda_h.py:19] end wait_cetm_experts cost 0.053682804107666016 seconds
DEBUG 01-04 15:36:15.895465.895465 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:15.896475.896475 cuda_h.py:19] end gpu_sexperts cost 0.0004558563232421875 seconds
DEBUG 01-04 15:36:15.896318.896318 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-04 15:36:15.896207.896207 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-04 15:36:15.896017.896017 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.337860107421875e-05 seconds
DEBUG 01-04 15:36:15.896588.896588 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.462501525878906e-05 seconds
DEBUG 01-04 15:36:15.896145.896145 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:15.896570.896570 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2886b7e9-4d2e-499a-8c4a-16dccfc58e32
DEBUG 01-04 15:36:15.896847.896847 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:15.896030.896030 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.896680.896680 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.902748.902748 cuda_h.py:19] end allocate_cuda_memory cost 0.005136728286743164 seconds
DEBUG 01-04 15:36:15.902141.902141 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.902288.902288 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.902118.902118 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.902827.902827 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b58664b0-3a39-4568-b44b-1ff9c00446e0
DEBUG 01-04 15:36:15.902871.902871 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.902520.902520 client.py:127] Model loaded
DEBUG 01-04 15:36:15.902707.902707 cuda_h.py:19] end wait_experts cost 0.006070375442504883 seconds
DEBUG 01-04 15:36:15.902841.902841 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:15.902974.902974 lmp.py:384]   Computing 32 experts on GPU...
DEBUG 01-04 15:36:15.903991.903991 mlpmodule.py:531] gpu group tensors cost 0.0006394386291503906 s
INFO 01-04 15:36:15.903417.903417 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b58664b0-3a39-4568-b44b-1ff9c00446e0
DEBUG 01-04 15:36:15.903683.903683 cuda_h.py:19] end load_into_gpu_async cost 0.0015206336975097656 seconds
DEBUG 01-04 15:36:15.903069.903069 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.903244.903244 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-04 15:36:15.903477.903477 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0070037841796875 seconds
INFO 01-04 15:36:15.904105.904105 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b58664b0-3a39-4568-b44b-1ff9c00446e0
DEBUG 01-04 15:36:15.905150.905150 mlpmodule.py:564] gpu pad cost 0.002309560775756836 s
DEBUG 01-04 15:36:15.906507.906507 mlpmodule.py:582] gpu group einsum cost 0.0005109310150146484 s
DEBUG 01-04 15:36:15.909715.909715 mlpmodule.py:611] gpu experts func einsum cost 0.006613969802856445 s
DEBUG 01-04 15:36:15.909304.909304 cuda_h.py:19] end gpu_experts cost 0.006880283355712891 seconds
DEBUG 01-04 15:36:15.909351.909351 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:15.912696.912696 client.py:127] Model loaded
DEBUG 01-04 15:36:15.912308.912308 cuda_h.py:19] end sllm_worker_task cost 0.015236139297485352 seconds
DEBUG 01-04 15:36:15.912489.912489 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0024933815002441406 seconds
DEBUG 01-04 15:36:15.912600.912600 cuda_h.py:19] end layer_moe_generate_2 cost 0.07843971252441406 seconds
DEBUG 01-04 15:36:15.912381.912381 lmp.py:207] -------------------------------- end layer 2 --------------------------------
DEBUG 01-04 15:36:15.912958.912958 lmp.py:169] -------------------------------- start layer 3 --------------------------------
DEBUG 01-04 15:36:15.912986.912986 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:15.912405.912405 cuda_h.py:10] start self_attn
DEBUG 01-04 15:36:15.912794.912794 mlpmodule.py:662]  experts func einsum cost 0.07086825370788574 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:15.915739.915739 cuda_h.py:19] end self_attn cost 0.0024034976959228516 seconds
DEBUG 01-04 15:36:15.915558.915558 cuda_h.py:19] end iln_self_attn_paln cost 0.003027200698852539 seconds
DEBUG 01-04 15:36:15.915110.915110 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-04 15:36:15.915157.915157 cuda_h.py:10] start gate
DEBUG 01-04 15:36:15.916078.916078 cuda_h.py:19] end gate cost 0.0005662441253662109 seconds
DEBUG 01-04 15:36:15.916716.916716 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:15.916002.916002 lmp.py:281] 
DEBUG 01-04 15:36:15.916002.916002 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:15.916043.916043 lmp.py:282]   Total experts: 50
DEBUG 01-04 15:36:15.916454.916454 lmp.py:283]   CPU experts: 25 (50%)
DEBUG 01-04 15:36:15.916528.916528 lmp.py:284]   GPU experts: 25 (50%)
DEBUG 01-04 15:36:15.916740.916740 lmp.py:285] 
DEBUG 01-04 15:36:15.916740.916740 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:15.916429.916429 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:15.916649.916649 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:15.916576.916576 lmp.py:292]   Expert 39 |      1 | CPU
DEBUG 01-04 15:36:15.916789.916789 lmp.py:292]   Expert 44 |      1 | CPU
DEBUG 01-04 15:36:15.916001.916001 lmp.py:292]   Expert 15 |      2 | CPU
DEBUG 01-04 15:36:15.916975.916975 lmp.py:292]   Expert 23 |      2 | CPU
DEBUG 01-04 15:36:15.916857.916857 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:15.916546.916546 lmp.py:292]   Expert 59 |      2 | CPU
DEBUG 01-04 15:36:15.916997.916997 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:15.916209.916209 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:15.916183.916183 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:15.916157.916157 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:15.916655.916655 lmp.py:292]   Expert  7 |      4 | CPU
DEBUG 01-04 15:36:15.916629.916629 lmp.py:292]   Expert 17 |      4 | CPU
DEBUG 01-04 15:36:15.916126.916126 lmp.py:292]   Expert 26 |      4 | CPU
DEBUG 01-04 15:36:15.916862.916862 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:15.916359.916359 lmp.py:292]   Expert 62 |      4 | CPU
DEBUG 01-04 15:36:15.916856.916856 lmp.py:292]   Expert 13 |      5 | CPU
DEBUG 01-04 15:36:15.917115.917115 lmp.py:292]   Expert 18 |      5 | CPU
DEBUG 01-04 15:36:15.917850.917850 lmp.py:292]   Expert 42 |      5 | CPU
DEBUG 01-04 15:36:15.917493.917493 lmp.py:292]   Expert 47 |      5 | CPU
DEBUG 01-04 15:36:15.917229.917229 lmp.py:292]   Expert 48 |      5 | CPU
DEBUG 01-04 15:36:15.917441.917441 lmp.py:292]   Expert 57 |      5 | CPU
DEBUG 01-04 15:36:15.917415.917415 lmp.py:292]   Expert 11 |      6 | CPU
DEBUG 01-04 15:36:15.917389.917389 lmp.py:292]   Expert 35 |      6 | CPU
DEBUG 01-04 15:36:15.917602.917602 lmp.py:292]   Expert 45 |      6 | CPU
DEBUG 01-04 15:36:15.917861.917861 lmp.py:292]   Expert 56 |      6 | GPU
DEBUG 01-04 15:36:15.917358.917358 lmp.py:292]   Expert 58 |      6 | GPU
DEBUG 01-04 15:36:15.917617.917617 lmp.py:292]   Expert 20 |      8 | GPU
DEBUG 01-04 15:36:15.917114.917114 lmp.py:292]   Expert 54 |      8 | GPU
DEBUG 01-04 15:36:15.917373.917373 lmp.py:292]   Expert 22 |      9 | GPU
DEBUG 01-04 15:36:15.917393.917393 lmp.py:292]   Expert 40 |      9 | GPU
DEBUG 01-04 15:36:15.917652.917652 lmp.py:292]   Expert 46 |      9 | GPU
DEBUG 01-04 15:36:15.917149.917149 lmp.py:292]   Expert 41 |     10 | GPU
DEBUG 01-04 15:36:15.917169.917169 lmp.py:292]   Expert 53 |     10 | GPU
DEBUG 01-04 15:36:15.917382.917382 lmp.py:292]   Expert 50 |     11 | GPU
DEBUG 01-04 15:36:15.917594.917594 lmp.py:292]   Expert 14 |     13 | GPU
DEBUG 01-04 15:36:15.917568.917568 lmp.py:292]   Expert 19 |     13 | GPU
DEBUG 01-04 15:36:15.917542.917542 lmp.py:292]   Expert 27 |     13 | GPU
DEBUG 01-04 15:36:15.917967.917967 lmp.py:292]   Expert 43 |     13 | GPU
DEBUG 01-04 15:36:15.917180.917180 lmp.py:292]   Expert 60 |     14 | GPU
DEBUG 01-04 15:36:15.917916.917916 lmp.py:292]   Expert 34 |     15 | GPU
DEBUG 01-04 15:36:15.917651.917651 lmp.py:292]   Expert 21 |     16 | GPU
DEBUG 01-04 15:36:15.917625.917625 lmp.py:292]   Expert 25 |     18 | GPU
DEBUG 01-04 15:36:15.917122.917122 lmp.py:292]   Expert  9 |     22 | GPU
DEBUG 01-04 15:36:15.917335.917335 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:15.917070.917070 lmp.py:292]   Expert  1 |   1992 | GPU
DEBUG 01-04 15:36:15.917283.917283 lmp.py:292]   Expert  2 |   1992 | GPU
DEBUG 01-04 15:36:15.917449.917449 lmp.py:292]   Expert  0 |   1997 | GPU
DEBUG 01-04 15:36:15.917138.917138 lmp.py:292]   Expert  5 |   2000 | GPU
DEBUG 01-04 15:36:15.917351.917351 lmp.py:292]   Expert  3 |   2002 | GPU
DEBUG 01-04 15:36:15.917517.917517 lmp.py:293] 
DEBUG 01-04 15:36:15.917517.917517 lmp.py:293]   CPU total tokens: 91 (0.7%)
DEBUG 01-04 15:36:15.917398.917398 lmp.py:294]   GPU total tokens: 12197 (99.3%)
DEBUG 01-04 15:36:15.917870.917870 cuda_h.py:19] end experts_map_get cost 0.0012004375457763672 seconds
DEBUG 01-04 15:36:15.917321.917321 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:15.917090.917090 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.917564.917564 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.918685.918685 cuda_h.py:19] end allocate_cuda_memory cost 0.0002334117889404297 seconds
DEBUG 01-04 15:36:15.918051.918051 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.918377.918377 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.918478.918478 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.918651.918651 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 91f0d818-edb9-403b-9a27-7677ffe34bdd
DEBUG 01-04 15:36:15.918821.918821 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.919075.919075 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 91f0d818-edb9-403b-9a27-7677ffe34bdd
DEBUG 01-04 15:36:15.920858.920858 cuda_h.py:19] end load_into_gpu_async cost 0.0018982887268066406 seconds
DEBUG 01-04 15:36:15.920938.920938 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.920386.920386 cuda_h.py:19] end restore_tensors2 cost 0.0003066062927246094 seconds
DEBUG 01-04 15:36:15.920389.920389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027611255645751953 seconds
DEBUG 01-04 15:36:15.922312.922312 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004848957061767578 seconds
DEBUG 01-04 15:36:15.922433.922433 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:15.922865.922865 lmp.py:339] 
DEBUG 01-04 15:36:15.922865.922865 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:15.922463.922463 cuda_h.py:19] end cpu_experts_submit cost 0.00010180473327636719 seconds
DEBUG 01-04 15:36:15.922849.922849 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:15.932404.932404 mlpmodule.py:704] group tensors cost 0.009334802627563477 s
DEBUG 01-04 15:36:15.934273.934273 mlpmodule.py:742] pad cost 0.0018563270568847656 s
DEBUG 01-04 15:36:15.934443.934443 mlpmodule.py:748] create cpu tensor cost 5.602836608886719e-05 s
DEBUG 01-04 15:36:15.934843.934843 mlpmodule.py:753] move to cpu cost 3.886222839355469e-05 s
DEBUG 01-04 15:36:15.938590.938590 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:15.939739.939739 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:15.939285.939285 mlpmodule.py:774] group_w3 first element: -0.031494140625
WARNING 01-04 15:36:15.939356.939356 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:15.942023.942023 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:15.942383.942383 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:15.946403.946403 mlpmodule.py:797] group einsum cost 0.011499881744384766 s
DEBUG 01-04 15:36:15.946922.946922 mlpmodule.py:805] cpy2cputensor cost 9.965896606445312e-05 s
DEBUG 01-04 15:36:15.952349.952349 cuda_h.py:19] end wait_cetm_experts cost 0.029317378997802734 seconds
DEBUG 01-04 15:36:15.952955.952955 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:15.952469.952469 cuda_h.py:19] end gpu_sexperts cost 0.00047659873962402344 seconds
DEBUG 01-04 15:36:15.952835.952835 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-04 15:36:15.952604.952604 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-04 15:36:15.952885.952885 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.4332275390625e-05 seconds
DEBUG 01-04 15:36:15.952979.952979 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.128715515136719e-05 seconds
DEBUG 01-04 15:36:15.952059.952059 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:15.952484.952484 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 91f0d818-edb9-403b-9a27-7677ffe34bdd
DEBUG 01-04 15:36:15.953801.953801 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:15.953724.953724 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.953428.953428 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.957845.957845 cuda_h.py:19] end allocate_cuda_memory cost 0.004690885543823242 seconds
DEBUG 01-04 15:36:15.958993.958993 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.958186.958186 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.958208.958208 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.958964.958964 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4dee04bf-571a-476e-b290-25a36647339b
DEBUG 01-04 15:36:15.958000.958000 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.961036.961036 client.py:127] Model loaded
DEBUG 01-04 15:36:15.961110.961110 cuda_h.py:19] end wait_experts cost 0.008820533752441406 seconds
DEBUG 01-04 15:36:15.961098.961098 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:15.961754.961754 lmp.py:384]   Computing 25 experts on GPU...
INFO 01-04 15:36:15.962179.962179 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4dee04bf-571a-476e-b290-25a36647339b
DEBUG 01-04 15:36:15.962209.962209 cuda_h.py:19] end load_into_gpu_async cost 0.004228115081787109 seconds
DEBUG 01-04 15:36:15.962018.962018 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.962074.962074 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-04 15:36:15.962122.962122 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009280204772949219 seconds
DEBUG 01-04 15:36:15.962382.962382 mlpmodule.py:531] gpu group tensors cost 0.0008826255798339844 s
INFO 01-04 15:36:15.963261.963261 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4dee04bf-571a-476e-b290-25a36647339b
DEBUG 01-04 15:36:15.964150.964150 mlpmodule.py:564] gpu pad cost 0.0013632774353027344 s
DEBUG 01-04 15:36:15.968127.968127 mlpmodule.py:662]  experts func einsum cost 0.045768022537231445 s
INFO 01-04 15:36:15.970237.970237 client.py:127] Model loaded
DEBUG 01-04 15:36:15.970193.970193 mlpmodule.py:582] gpu group einsum cost 0.005584239959716797 s
DEBUG 01-04 15:36:15.970242.970242 cuda_h.py:19] end sllm_worker_task cost 0.01706409454345703 seconds
DEBUG 01-04 15:36:15.972903.972903 mlpmodule.py:611] gpu experts func einsum cost 0.010492801666259766 s
DEBUG 01-04 15:36:15.972555.972555 cuda_h.py:19] end gpu_experts cost 0.010669469833374023 seconds
DEBUG 01-04 15:36:15.972642.972642 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:15.972319.972319 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-04 15:36:15.975913.975913 cuda_h.py:19] end layer_moe_generate_3 cost 0.059549570083618164 seconds
DEBUG 01-04 15:36:15.975361.975361 lmp.py:207] -------------------------------- end layer 3 --------------------------------
DEBUG 01-04 15:36:15.975078.975078 lmp.py:169] -------------------------------- start layer 4 --------------------------------
DEBUG 01-04 15:36:15.975390.975390 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:15.975028.975028 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:15.978805.978805 cuda_h.py:19] end self_attn cost 0.002382040023803711 seconds
DEBUG 01-04 15:36:15.978099.978099 cuda_h.py:19] end iln_self_attn_paln cost 0.0029528141021728516 seconds
DEBUG 01-04 15:36:15.978505.978505 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-04 15:36:15.978122.978122 cuda_h.py:10] start gate
DEBUG 01-04 15:36:15.979201.979201 cuda_h.py:19] end gate cost 0.0005533695220947266 seconds
DEBUG 01-04 15:36:15.979408.979408 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:15.979873.979873 lmp.py:281] 
DEBUG 01-04 15:36:15.979873.979873 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:15.979721.979721 lmp.py:282]   Total experts: 53
DEBUG 01-04 15:36:15.979510.979510 lmp.py:283]   CPU experts: 26 (49%)
DEBUG 01-04 15:36:15.979107.979107 lmp.py:284]   GPU experts: 27 (51%)
DEBUG 01-04 15:36:15.979842.979842 lmp.py:285] 
DEBUG 01-04 15:36:15.979842.979842 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:15.979532.979532 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:15.979751.979751 lmp.py:292]   Expert  7 |      1 | CPU
DEBUG 01-04 15:36:15.979917.979917 lmp.py:292]   Expert  9 |      1 | CPU
DEBUG 01-04 15:36:15.979653.979653 lmp.py:292]   Expert 10 |      1 | CPU
DEBUG 01-04 15:36:15.979911.979911 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:15.979932.979932 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:15.979191.979191 lmp.py:292]   Expert 17 |      1 | CPU
DEBUG 01-04 15:36:15.979211.979211 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:15.979993.979993 lmp.py:292]   Expert 33 |      1 | CPU
DEBUG 01-04 15:36:15.979252.979252 lmp.py:292]   Expert 36 |      1 | CPU
DEBUG 01-04 15:36:15.979034.979034 lmp.py:292]   Expert 37 |      1 | CPU
DEBUG 01-04 15:36:15.979054.979054 lmp.py:292]   Expert 44 |      1 | CPU
DEBUG 01-04 15:36:15.979267.979267 lmp.py:292]   Expert 63 |      2 | CPU
DEBUG 01-04 15:36:15.979241.979241 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:15.979738.979738 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:15.979997.979997 lmp.py:292]   Expert 28 |      3 | CPU
DEBUG 01-04 15:36:15.979494.979494 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:15.979037.979037 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:15.979058.979058 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:15.979078.979078 lmp.py:292]   Expert 18 |      4 | CPU
DEBUG 01-04 15:36:15.979622.979622 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:15.979404.979404 lmp.py:292]   Expert 27 |      4 | CPU
DEBUG 01-04 15:36:15.979185.979185 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:15.979967.979967 lmp.py:292]   Expert 47 |      4 | CPU
DEBUG 01-04 15:36:15.979749.979749 lmp.py:292]   Expert 20 |      5 | CPU
DEBUG 01-04 15:36:15.979293.979293 lmp.py:292]   Expert 21 |      5 | CPU
DEBUG 01-04 15:36:15.979836.979836 lmp.py:292]   Expert 45 |      5 | CPU
DEBUG 01-04 15:36:15.979095.979095 lmp.py:292]   Expert 46 |      5 | GPU
DEBUG 01-04 15:36:15.979831.979831 lmp.py:292]   Expert 40 |      6 | GPU
DEBUG 01-04 15:36:15.979805.979805 lmp.py:292]   Expert 61 |      6 | GPU
DEBUG 01-04 15:36:15.979064.979064 lmp.py:292]   Expert 53 |      7 | GPU
DEBUG 01-04 15:36:15.979799.979799 lmp.py:292]   Expert 62 |      7 | GPU
DEBUG 01-04 15:36:15.979058.979058 lmp.py:292]   Expert 12 |      8 | GPU
DEBUG 01-04 15:36:15.980317.980317 lmp.py:292]   Expert 23 |      8 | GPU
DEBUG 01-04 15:36:15.980860.980860 lmp.py:292]   Expert 29 |      8 | GPU
DEBUG 01-04 15:36:15.980404.980404 lmp.py:292]   Expert 57 |      8 | GPU
DEBUG 01-04 15:36:15.980186.980186 lmp.py:292]   Expert 38 |      9 | GPU
DEBUG 01-04 15:36:15.980206.980206 lmp.py:292]   Expert 42 |      9 | GPU
DEBUG 01-04 15:36:15.980750.980750 lmp.py:292]   Expert 54 |     10 | GPU
DEBUG 01-04 15:36:15.980293.980293 lmp.py:292]   Expert 19 |     11 | GPU
DEBUG 01-04 15:36:15.980075.980075 lmp.py:292]   Expert 35 |     12 | GPU
DEBUG 01-04 15:36:15.980334.980334 lmp.py:292]   Expert  8 |     13 | GPU
DEBUG 01-04 15:36:15.980878.980878 lmp.py:292]   Expert 49 |     14 | GPU
DEBUG 01-04 15:36:15.980375.980375 lmp.py:292]   Expert 32 |     15 | GPU
DEBUG 01-04 15:36:15.980872.980872 lmp.py:292]   Expert 43 |     17 | GPU
DEBUG 01-04 15:36:15.980131.980131 lmp.py:292]   Expert 52 |     18 | GPU
DEBUG 01-04 15:36:15.980628.980628 lmp.py:292]   Expert 59 |     20 | GPU
DEBUG 01-04 15:36:15.980410.980410 lmp.py:292]   Expert 39 |     22 | GPU
DEBUG 01-04 15:36:15.980192.980192 lmp.py:292]   Expert  3 |   1991 | GPU
DEBUG 01-04 15:36:15.980974.980974 lmp.py:292]   Expert  1 |   1994 | GPU
DEBUG 01-04 15:36:15.980756.980756 lmp.py:292]   Expert  4 |   1996 | GPU
DEBUG 01-04 15:36:15.980776.980776 lmp.py:292]   Expert  0 |   2000 | GPU
DEBUG 01-04 15:36:15.980558.980558 lmp.py:292]   Expert  2 |   2002 | GPU
DEBUG 01-04 15:36:15.980102.980102 lmp.py:292]   Expert  5 |   2006 | GPU
DEBUG 01-04 15:36:15.980837.980837 lmp.py:293] 
DEBUG 01-04 15:36:15.980837.980837 lmp.py:293]   CPU total tokens: 66 (0.5%)
DEBUG 01-04 15:36:15.980335.980335 lmp.py:294]   GPU total tokens: 12222 (99.5%)
DEBUG 01-04 15:36:15.980885.980885 cuda_h.py:19] end experts_map_get cost 0.0011692047119140625 seconds
DEBUG 01-04 15:36:15.980097.980097 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:15.980709.980709 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:15.980434.980434 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:15.980288.980288 cuda_h.py:19] end allocate_cuda_memory cost 0.00014257431030273438 seconds
DEBUG 01-04 15:36:15.980078.980078 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:15.980258.980258 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:15.980782.980782 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:15.980478.980478 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 481e5978-991a-4c4c-b54f-f2bcb63b41ac
DEBUG 01-04 15:36:15.981947.981947 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:15.982100.982100 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 481e5978-991a-4c4c-b54f-f2bcb63b41ac
DEBUG 01-04 15:36:15.982276.982276 cuda_h.py:19] end load_into_gpu_async cost 0.0013306140899658203 seconds
DEBUG 01-04 15:36:15.982570.982570 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:15.982998.982998 cuda_h.py:19] end restore_tensors2 cost 0.00046324729919433594 seconds
DEBUG 01-04 15:36:15.982490.982490 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023453235626220703 seconds
DEBUG 01-04 15:36:15.984080.984080 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00458836555480957 seconds
DEBUG 01-04 15:36:15.985486.985486 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:15.985064.985064 lmp.py:339] 
DEBUG 01-04 15:36:15.985064.985064 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:15.985139.985139 cuda_h.py:19] end cpu_experts_submit cost 0.00010251998901367188 seconds
DEBUG 01-04 15:36:15.985981.985981 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:15.996353.996353 mlpmodule.py:704] group tensors cost 0.01117396354675293 s
DEBUG 01-04 15:36:15.998192.998192 mlpmodule.py:742] pad cost 0.0014891624450683594 s
DEBUG 01-04 15:36:15.998520.998520 mlpmodule.py:748] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-04 15:36:15.998324.998324 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-04 15:36:16.002955.002955 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:16.002866.002866 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.002551.002551 mlpmodule.py:774] group_w3 first element: 0.09326171875
WARNING 01-04 15:36:16.002045.002045 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.006291.006291 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.006467.006467 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.010846.010846 mlpmodule.py:797] group einsum cost 0.01158761978149414 s
DEBUG 01-04 15:36:16.010207.010207 mlpmodule.py:805] cpy2cputensor cost 0.00012564659118652344 s
DEBUG 01-04 15:36:16.016436.016436 cuda_h.py:19] end wait_cetm_experts cost 0.030765771865844727 seconds
DEBUG 01-04 15:36:16.016565.016565 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.016709.016709 cuda_h.py:19] end gpu_sexperts cost 0.00048279762268066406 seconds
DEBUG 01-04 15:36:16.016413.016413 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-04 15:36:16.016997.016997 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-04 15:36:16.016523.016523 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.528594970703125e-05 seconds
DEBUG 01-04 15:36:16.016790.016790 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.016096.016096 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 0.0001456737518310547 seconds
DEBUG 01-04 15:36:16.017874.017874 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.017564.017564 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.017006.017006 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 481e5978-991a-4c4c-b54f-f2bcb63b41ac
DEBUG 01-04 15:36:16.017249.017249 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.022283.022283 cuda_h.py:19] end allocate_cuda_memory cost 0.005106925964355469 seconds
DEBUG 01-04 15:36:16.022823.022823 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.022354.022354 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.022184.022184 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.022463.022463 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 47cf8df0-131e-46a6-be23-8bff34437c06
DEBUG 01-04 15:36:16.022884.022884 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.026753.026753 client.py:127] Model loaded
DEBUG 01-04 15:36:16.026927.026927 cuda_h.py:19] end wait_experts cost 0.009709596633911133 seconds
DEBUG 01-04 15:36:16.026650.026650 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.026638.026638 lmp.py:384]   Computing 27 experts on GPU...
DEBUG 01-04 15:36:16.027776.027776 mlpmodule.py:531] gpu group tensors cost 0.0004909038543701172 s
INFO 01-04 15:36:16.028517.028517 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 47cf8df0-131e-46a6-be23-8bff34437c06
DEBUG 01-04 15:36:16.028691.028691 cuda_h.py:19] end load_into_gpu_async cost 0.005517005920410156 seconds
DEBUG 01-04 15:36:16.028394.028394 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.028046.028046 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-04 15:36:16.028802.028802 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011219024658203125 seconds
INFO 01-04 15:36:16.028324.028324 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 47cf8df0-131e-46a6-be23-8bff34437c06
DEBUG 01-04 15:36:16.029375.029375 mlpmodule.py:564] gpu pad cost 0.002214193344116211 s
DEBUG 01-04 15:36:16.032788.032788 mlpmodule.py:662]  experts func einsum cost 0.047149658203125 s
DEBUG 01-04 15:36:16.032595.032595 mlpmodule.py:582] gpu group einsum cost 0.0029420852661132812 s
DEBUG 01-04 15:36:16.035209.035209 mlpmodule.py:611] gpu experts func einsum cost 0.008078575134277344 s
DEBUG 01-04 15:36:16.035146.035146 cuda_h.py:19] end gpu_experts cost 0.008239984512329102 seconds
DEBUG 01-04 15:36:16.035471.035471 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.038753.038753 client.py:127] Model loaded
DEBUG 01-04 15:36:16.038917.038917 cuda_h.py:19] end sllm_worker_task cost 0.021861553192138672 seconds
DEBUG 01-04 15:36:16.039422.039422 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0037975311279296875 seconds
DEBUG 01-04 15:36:16.039733.039733 cuda_h.py:19] end layer_moe_generate_4 cost 0.06096673011779785 seconds
DEBUG 01-04 15:36:16.039288.039288 lmp.py:207] -------------------------------- end layer 4 --------------------------------
DEBUG 01-04 15:36:16.039873.039873 lmp.py:169] -------------------------------- start layer 5 --------------------------------
DEBUG 01-04 15:36:16.039272.039272 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.040086.040086 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.044269.044269 cuda_h.py:19] end self_attn cost 0.00417327880859375 seconds
DEBUG 01-04 15:36:16.045506.045506 cuda_h.py:19] end iln_self_attn_paln cost 0.005341768264770508 seconds
DEBUG 01-04 15:36:16.045556.045556 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-04 15:36:16.045419.045419 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.046513.046513 cuda_h.py:19] end gate cost 0.0009522438049316406 seconds
DEBUG 01-04 15:36:16.046926.046926 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.046837.046837 lmp.py:281] 
DEBUG 01-04 15:36:16.046837.046837 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.047507.047507 lmp.py:282]   Total experts: 53
DEBUG 01-04 15:36:16.047402.047402 lmp.py:283]   CPU experts: 26 (49%)
DEBUG 01-04 15:36:16.047006.047006 lmp.py:284]   GPU experts: 27 (51%)
DEBUG 01-04 15:36:16.047940.047940 lmp.py:285] 
DEBUG 01-04 15:36:16.047940.047940 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.047398.047398 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.047531.047531 lmp.py:292]   Expert 10 |      1 | CPU
DEBUG 01-04 15:36:16.047704.047704 lmp.py:292]   Expert 30 |      1 | CPU
DEBUG 01-04 15:36:16.047162.047162 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:16.047381.047381 lmp.py:292]   Expert 41 |      1 | CPU
DEBUG 01-04 15:36:16.047362.047362 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:16.047343.047343 lmp.py:292]   Expert 58 |      1 | CPU
DEBUG 01-04 15:36:16.047323.047323 lmp.py:292]   Expert 38 |      2 | CPU
DEBUG 01-04 15:36:16.047258.047258 lmp.py:292]   Expert 43 |      2 | CPU
DEBUG 01-04 15:36:16.047669.047669 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:16.047604.047604 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:16.047823.047823 lmp.py:292]   Expert 60 |      2 | CPU
DEBUG 01-04 15:36:16.047565.047565 lmp.py:292]   Expert 14 |      3 | CPU
DEBUG 01-04 15:36:16.047308.047308 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:16.047050.047050 lmp.py:292]   Expert 17 |      3 | CPU
DEBUG 01-04 15:36:16.047793.047793 lmp.py:292]   Expert 28 |      3 | CPU
DEBUG 01-04 15:36:16.047535.047535 lmp.py:292]   Expert 31 |      3 | CPU
DEBUG 01-04 15:36:16.047801.047801 lmp.py:292]   Expert 40 |      3 | CPU
DEBUG 01-04 15:36:16.047305.047305 lmp.py:292]   Expert 25 |      4 | CPU
DEBUG 01-04 15:36:16.047286.047286 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:16.047982.047982 lmp.py:292]   Expert 36 |      5 | CPU
DEBUG 01-04 15:36:16.047916.047916 lmp.py:292]   Expert  6 |      6 | CPU
DEBUG 01-04 15:36:16.047328.047328 lmp.py:292]   Expert 22 |      6 | CPU
DEBUG 01-04 15:36:16.047123.047123 lmp.py:292]   Expert 26 |      6 | CPU
DEBUG 01-04 15:36:16.047104.047104 lmp.py:292]   Expert 62 |      6 | CPU
DEBUG 01-04 15:36:16.047608.047608 lmp.py:292]   Expert  7 |      7 | CPU
DEBUG 01-04 15:36:16.047112.047112 lmp.py:292]   Expert 24 |      7 | CPU
DEBUG 01-04 15:36:16.047616.047616 lmp.py:292]   Expert 46 |      7 | GPU
DEBUG 01-04 15:36:16.047881.047881 lmp.py:292]   Expert 55 |      7 | GPU
DEBUG 01-04 15:36:16.047385.047385 lmp.py:292]   Expert 61 |      7 | GPU
DEBUG 01-04 15:36:16.047889.047889 lmp.py:292]   Expert 11 |      8 | GPU
DEBUG 01-04 15:36:16.047393.047393 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:16.047659.047659 lmp.py:292]   Expert 59 |      8 | GPU
DEBUG 01-04 15:36:16.047163.047163 lmp.py:292]   Expert 29 |      9 | GPU
DEBUG 01-04 15:36:16.047144.047144 lmp.py:292]   Expert 32 |      9 | GPU
DEBUG 01-04 15:36:16.047886.047886 lmp.py:292]   Expert 19 |     10 | GPU
DEBUG 01-04 15:36:16.047629.047629 lmp.py:292]   Expert 42 |     10 | GPU
DEBUG 01-04 15:36:16.047610.047610 lmp.py:292]   Expert 44 |     10 | GPU
DEBUG 01-04 15:36:16.047544.047544 lmp.py:292]   Expert 57 |     10 | GPU
DEBUG 01-04 15:36:16.047717.047717 lmp.py:292]   Expert 21 |     11 | GPU
DEBUG 01-04 15:36:16.047844.047844 lmp.py:292]   Expert 35 |     12 | GPU
DEBUG 01-04 15:36:16.047401.047401 lmp.py:292]   Expert 13 |     14 | GPU
DEBUG 01-04 15:36:16.047905.047905 lmp.py:292]   Expert 20 |     14 | GPU
DEBUG 01-04 15:36:16.048647.048647 lmp.py:292]   Expert 12 |     15 | GPU
DEBUG 01-04 15:36:16.048390.048390 lmp.py:292]   Expert 33 |     16 | GPU
DEBUG 01-04 15:36:16.048894.048894 lmp.py:292]   Expert 49 |     17 | GPU
DEBUG 01-04 15:36:16.048398.048398 lmp.py:292]   Expert 37 |     21 | GPU
DEBUG 01-04 15:36:16.048902.048902 lmp.py:292]   Expert 53 |     22 | GPU
DEBUG 01-04 15:36:16.048406.048406 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:16.048910.048910 lmp.py:292]   Expert  2 |   1991 | GPU
DEBUG 01-04 15:36:16.048414.048414 lmp.py:292]   Expert  0 |   1992 | GPU
DEBUG 01-04 15:36:16.048156.048156 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:16.048329.048329 lmp.py:292]   Expert  4 |   1992 | GPU
DEBUG 01-04 15:36:16.048263.048263 lmp.py:292]   Expert  5 |   1999 | GPU
DEBUG 01-04 15:36:16.048913.048913 lmp.py:293] 
DEBUG 01-04 15:36:16.048913.048913 lmp.py:293]   CPU total tokens: 86 (0.7%)
DEBUG 01-04 15:36:16.048086.048086 lmp.py:294]   GPU total tokens: 12202 (99.3%)
DEBUG 01-04 15:36:16.048266.048266 cuda_h.py:19] end experts_map_get cost 0.0016202926635742188 seconds
DEBUG 01-04 15:36:16.048916.048916 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.048321.048321 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.048750.048750 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.048837.048837 cuda_h.py:19] end allocate_cuda_memory cost 0.0002009868621826172 seconds
DEBUG 01-04 15:36:16.048409.048409 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.048218.048218 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.048233.048233 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.048274.048274 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 998a9214-0997-426b-9a3e-380104cd3e9b
DEBUG 01-04 15:36:16.049022.049022 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.050407.050407 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 998a9214-0997-426b-9a3e-380104cd3e9b
DEBUG 01-04 15:36:16.050680.050680 cuda_h.py:19] end load_into_gpu_async cost 0.002129077911376953 seconds
DEBUG 01-04 15:36:16.051152.051152 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.051146.051146 cuda_h.py:19] end restore_tensors2 cost 0.00038361549377441406 seconds
DEBUG 01-04 15:36:16.051088.051088 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003090381622314453 seconds
DEBUG 01-04 15:36:16.054709.054709 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006064891815185547 seconds
DEBUG 01-04 15:36:16.054075.054075 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.054343.054343 lmp.py:339] 
DEBUG 01-04 15:36:16.054343.054343 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:16.054246.054246 cuda_h.py:19] end cpu_experts_submit cost 0.00012445449829101562 seconds
DEBUG 01-04 15:36:16.054479.054479 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.061246.061246 mlpmodule.py:704] group tensors cost 0.0063474178314208984 s
DEBUG 01-04 15:36:16.064539.064539 mlpmodule.py:742] pad cost 0.0026712417602539062 s
DEBUG 01-04 15:36:16.064903.064903 mlpmodule.py:748] create cpu tensor cost 7.224082946777344e-05 s
DEBUG 01-04 15:36:16.064767.064767 mlpmodule.py:753] move to cpu cost 4.863739013671875e-05 s
DEBUG 01-04 15:36:16.068191.068191 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:16.069777.069777 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.069992.069992 mlpmodule.py:774] group_w3 first element: 0.00872802734375
WARNING 01-04 15:36:16.069294.069294 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.072745.072745 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.072568.072568 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.076442.076442 mlpmodule.py:797] group einsum cost 0.01195979118347168 s
DEBUG 01-04 15:36:16.077850.077850 mlpmodule.py:805] cpy2cputensor cost 0.00013136863708496094 s
DEBUG 01-04 15:36:16.082688.082688 cuda_h.py:19] end wait_cetm_experts cost 0.02773284912109375 seconds
DEBUG 01-04 15:36:16.082532.082532 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.083118.083118 cuda_h.py:19] end gpu_sexperts cost 0.00045752525329589844 seconds
DEBUG 01-04 15:36:16.083061.083061 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-04 15:36:16.083691.083691 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-04 15:36:16.083071.083071 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.2901763916015625e-05 seconds
DEBUG 01-04 15:36:16.083211.083211 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.295608520507812e-05 seconds
DEBUG 01-04 15:36:16.083292.083292 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.083717.083717 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 998a9214-0997-426b-9a3e-380104cd3e9b
DEBUG 01-04 15:36:16.083086.083086 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.083382.083382 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.083437.083437 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.088794.088794 cuda_h.py:19] end allocate_cuda_memory cost 0.005060911178588867 seconds
DEBUG 01-04 15:36:16.088518.088518 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.088427.088427 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.088448.088448 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.088443.088443 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 345ab893-cafd-4417-bc43-5f1e1b94620f
DEBUG 01-04 15:36:16.089578.089578 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.095015.095015 client.py:127] Model loaded
DEBUG 01-04 15:36:16.095534.095534 cuda_h.py:19] end wait_experts cost 0.011945486068725586 seconds
DEBUG 01-04 15:36:16.095257.095257 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.095006.095006 lmp.py:384]   Computing 27 experts on GPU...
DEBUG 01-04 15:36:16.095700.095700 mlpmodule.py:531] gpu group tensors cost 0.0004756450653076172 s
INFO 01-04 15:36:16.096894.096894 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 345ab893-cafd-4417-bc43-5f1e1b94620f
DEBUG 01-04 15:36:16.096790.096790 cuda_h.py:19] end load_into_gpu_async cost 0.00729060173034668 seconds
DEBUG 01-04 15:36:16.096208.096208 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.096006.096006 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-04 15:36:16.096000.096000 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012700319290161133 seconds
INFO 01-04 15:36:16.096495.096495 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 345ab893-cafd-4417-bc43-5f1e1b94620f
DEBUG 01-04 15:36:16.097988.097988 mlpmodule.py:564] gpu pad cost 0.0020194053649902344 s
DEBUG 01-04 15:36:16.098971.098971 mlpmodule.py:662]  experts func einsum cost 0.043631553649902344 s
DEBUG 01-04 15:36:16.098527.098527 mlpmodule.py:582] gpu group einsum cost 0.000598907470703125 s
DEBUG 01-04 15:36:16.101719.101719 mlpmodule.py:611] gpu experts func einsum cost 0.00579071044921875 s
DEBUG 01-04 15:36:16.101036.101036 cuda_h.py:19] end gpu_experts cost 0.0060269832611083984 seconds
DEBUG 01-04 15:36:16.101699.101699 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.108622.108622 client.py:127] Model loaded
DEBUG 01-04 15:36:16.108439.108439 cuda_h.py:19] end sllm_worker_task cost 0.025044679641723633 seconds
DEBUG 01-04 15:36:16.108765.108765 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.007286548614501953 seconds
DEBUG 01-04 15:36:16.108744.108744 cuda_h.py:19] end layer_moe_generate_5 cost 0.06331682205200195 seconds
DEBUG 01-04 15:36:16.109545.109545 lmp.py:207] -------------------------------- end layer 5 --------------------------------
DEBUG 01-04 15:36:16.109923.109923 lmp.py:169] -------------------------------- start layer 6 --------------------------------
DEBUG 01-04 15:36:16.109189.109189 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.109324.109324 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.111271.111271 cuda_h.py:19] end self_attn cost 0.0023314952850341797 seconds
DEBUG 01-04 15:36:16.112234.112234 cuda_h.py:19] end iln_self_attn_paln cost 0.002918243408203125 seconds
DEBUG 01-04 15:36:16.112117.112117 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-04 15:36:16.112496.112496 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.112344.112344 cuda_h.py:19] end gate cost 0.0005929470062255859 seconds
DEBUG 01-04 15:36:16.112412.112412 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.113122.113122 lmp.py:281] 
DEBUG 01-04 15:36:16.113122.113122 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.113210.113210 lmp.py:282]   Total experts: 50
DEBUG 01-04 15:36:16.113382.113382 lmp.py:283]   CPU experts: 25 (50%)
DEBUG 01-04 15:36:16.113456.113456 lmp.py:284]   GPU experts: 25 (50%)
DEBUG 01-04 15:36:16.113384.113384 lmp.py:285] 
DEBUG 01-04 15:36:16.113384.113384 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.113503.113503 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.113392.113392 lmp.py:292]   Expert  7 |      1 | CPU
DEBUG 01-04 15:36:16.113750.113750 lmp.py:292]   Expert 10 |      1 | CPU
DEBUG 01-04 15:36:16.113393.113393 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:16.113082.113082 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:16.113771.113771 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:16.113222.113222 lmp.py:292]   Expert 44 |      1 | CPU
DEBUG 01-04 15:36:16.113673.113673 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:16.113124.113124 lmp.py:292]   Expert  6 |      2 | CPU
DEBUG 01-04 15:36:16.113098.113098 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:16.113311.113311 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:16.113000.113000 lmp.py:292]   Expert 22 |      3 | CPU
DEBUG 01-04 15:36:16.113451.113451 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:16.113902.113902 lmp.py:292]   Expert 31 |      3 | CPU
DEBUG 01-04 15:36:16.113591.113591 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:16.113996.113996 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:16.113923.113923 lmp.py:292]   Expert 30 |      4 | CPU
DEBUG 01-04 15:36:16.113566.113566 lmp.py:292]   Expert 43 |      4 | CPU
DEBUG 01-04 15:36:16.113494.113494 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:16.113945.113945 lmp.py:292]   Expert 46 |      4 | CPU
DEBUG 01-04 15:36:16.113919.113919 lmp.py:292]   Expert 51 |      4 | CPU
DEBUG 01-04 15:36:16.113370.113370 lmp.py:292]   Expert 18 |      5 | CPU
DEBUG 01-04 15:36:16.113582.113582 lmp.py:292]   Expert 38 |      5 | CPU
DEBUG 01-04 15:36:16.113556.113556 lmp.py:292]   Expert 12 |      6 | CPU
DEBUG 01-04 15:36:16.113769.113769 lmp.py:292]   Expert 29 |      6 | CPU
DEBUG 01-04 15:36:16.113995.113995 lmp.py:292]   Expert 37 |      6 | CPU
DEBUG 01-04 15:36:16.113221.113221 lmp.py:292]   Expert 48 |      6 | GPU
DEBUG 01-04 15:36:16.113956.113956 lmp.py:292]   Expert 59 |      6 | GPU
DEBUG 01-04 15:36:16.113692.113692 lmp.py:292]   Expert 41 |      7 | GPU
DEBUG 01-04 15:36:16.113905.113905 lmp.py:292]   Expert 54 |      7 | GPU
DEBUG 01-04 15:36:16.113117.113117 lmp.py:292]   Expert  8 |      8 | GPU
DEBUG 01-04 15:36:16.113614.113614 lmp.py:292]   Expert  9 |      9 | GPU
DEBUG 01-04 15:36:16.113588.113588 lmp.py:292]   Expert 19 |      9 | GPU
DEBUG 01-04 15:36:16.113085.113085 lmp.py:292]   Expert 21 |     11 | GPU
DEBUG 01-04 15:36:16.113106.113106 lmp.py:292]   Expert 33 |     11 | GPU
DEBUG 01-04 15:36:16.113365.113365 lmp.py:292]   Expert 42 |     11 | GPU
DEBUG 01-04 15:36:16.113385.113385 lmp.py:292]   Expert 39 |     12 | GPU
DEBUG 01-04 15:36:16.113644.113644 lmp.py:292]   Expert 17 |     13 | GPU
DEBUG 01-04 15:36:16.113426.113426 lmp.py:292]   Expert 24 |     13 | GPU
DEBUG 01-04 15:36:16.113208.113208 lmp.py:292]   Expert 13 |     14 | GPU
DEBUG 01-04 15:36:16.113990.113990 lmp.py:292]   Expert 20 |     14 | GPU
DEBUG 01-04 15:36:16.113248.113248 lmp.py:292]   Expert 23 |     15 | GPU
DEBUG 01-04 15:36:16.113030.113030 lmp.py:292]   Expert 60 |     18 | GPU
DEBUG 01-04 15:36:16.113812.113812 lmp.py:292]   Expert 56 |     21 | GPU
DEBUG 01-04 15:36:16.113833.113833 lmp.py:292]   Expert 36 |     38 | GPU
DEBUG 01-04 15:36:16.113615.113615 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:16.113873.113873 lmp.py:292]   Expert  3 |   1991 | GPU
DEBUG 01-04 15:36:16.113132.113132 lmp.py:292]   Expert  5 |   1993 | GPU
DEBUG 01-04 15:36:16.113391.113391 lmp.py:292]   Expert  4 |   1995 | GPU
DEBUG 01-04 15:36:16.113603.113603 lmp.py:292]   Expert  0 |   1996 | GPU
DEBUG 01-04 15:36:16.113578.113578 lmp.py:292]   Expert  2 |   2002 | GPU
DEBUG 01-04 15:36:16.113267.113267 lmp.py:293] 
DEBUG 01-04 15:36:16.113267.113267 lmp.py:293]   CPU total tokens: 77 (0.6%)
DEBUG 01-04 15:36:16.114241.114241 lmp.py:294]   GPU total tokens: 12211 (99.4%)
DEBUG 01-04 15:36:16.114030.114030 cuda_h.py:19] end experts_map_get cost 0.0011997222900390625 seconds
DEBUG 01-04 15:36:16.114242.114242 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.114866.114866 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.114101.114101 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.114733.114733 cuda_h.py:19] end allocate_cuda_memory cost 0.00026106834411621094 seconds
DEBUG 01-04 15:36:16.114576.114576 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.114948.114948 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.114949.114949 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.114692.114692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c777d664-c6ce-41e1-923a-ae62eef1dbc7
DEBUG 01-04 15:36:16.114180.114180 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.116624.116624 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c777d664-c6ce-41e1-923a-ae62eef1dbc7
DEBUG 01-04 15:36:16.116376.116376 cuda_h.py:19] end load_into_gpu_async cost 0.0020890235900878906 seconds
DEBUG 01-04 15:36:16.116240.116240 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.117156.117156 cuda_h.py:19] end restore_tensors2 cost 0.0004029273986816406 seconds
DEBUG 01-04 15:36:16.117270.117270 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031571388244628906 seconds
DEBUG 01-04 15:36:16.119771.119771 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005278348922729492 seconds
DEBUG 01-04 15:36:16.119170.119170 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.119769.119769 lmp.py:339] 
DEBUG 01-04 15:36:16.119769.119769 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:16.119605.119605 cuda_h.py:19] end cpu_experts_submit cost 0.000102996826171875 seconds
DEBUG 01-04 15:36:16.119447.119447 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.126138.126138 mlpmodule.py:704] group tensors cost 0.00685429573059082 s
DEBUG 01-04 15:36:16.129906.129906 mlpmodule.py:742] pad cost 0.001837015151977539 s
DEBUG 01-04 15:36:16.129095.129095 mlpmodule.py:748] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-04 15:36:16.129806.129806 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-04 15:36:16.132165.132165 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:16.133937.133937 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.133576.133576 mlpmodule.py:774] group_w3 first element: 0.0003910064697265625
WARNING 01-04 15:36:16.133924.133924 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.136555.136555 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.136108.136108 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.139271.139271 mlpmodule.py:797] group einsum cost 0.01024937629699707 s
DEBUG 01-04 15:36:16.139856.139856 mlpmodule.py:805] cpy2cputensor cost 9.059906005859375e-05 s
DEBUG 01-04 15:36:16.145994.145994 cuda_h.py:19] end wait_cetm_experts cost 0.025393247604370117 seconds
DEBUG 01-04 15:36:16.145077.145077 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.145040.145040 cuda_h.py:19] end gpu_sexperts cost 0.0004563331604003906 seconds
DEBUG 01-04 15:36:16.145076.145076 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-04 15:36:16.145322.145322 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-04 15:36:16.145463.145463 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.7670135498046875e-05 seconds
DEBUG 01-04 15:36:16.145161.145161 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.145666.145666 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 0.00015115737915039062 seconds
DEBUG 01-04 15:36:16.145841.145841 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.146108.146108 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.146001.146001 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c777d664-c6ce-41e1-923a-ae62eef1dbc7
DEBUG 01-04 15:36:16.146429.146429 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.150644.150644 cuda_h.py:19] end allocate_cuda_memory cost 0.004565000534057617 seconds
DEBUG 01-04 15:36:16.151037.151037 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.151244.151244 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.151789.151789 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.151830.151830 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 11ccb043-7355-44d8-9d19-feaa8e5637ad
DEBUG 01-04 15:36:16.151588.151588 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.158611.158611 client.py:127] Model loaded
DEBUG 01-04 15:36:16.158514.158514 cuda_h.py:19] end wait_experts cost 0.01197195053100586 seconds
DEBUG 01-04 15:36:16.158648.158648 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.158351.158351 lmp.py:384]   Computing 25 experts on GPU...
DEBUG 01-04 15:36:16.158343.158343 mlpmodule.py:531] gpu group tensors cost 0.00048613548278808594 s
INFO 01-04 15:36:16.159856.159856 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 11ccb043-7355-44d8-9d19-feaa8e5637ad
DEBUG 01-04 15:36:16.159947.159947 cuda_h.py:19] end load_into_gpu_async cost 0.008133649826049805 seconds
DEBUG 01-04 15:36:16.159346.159346 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.159266.159266 cuda_h.py:19] end restore_tensors2 cost 0.0001442432403564453 seconds
DEBUG 01-04 15:36:16.159425.159425 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.013538837432861328 seconds
DEBUG 01-04 15:36:16.161140.161140 mlpmodule.py:662]  experts func einsum cost 0.04153752326965332 s
INFO 01-04 15:36:16.161320.161320 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 11ccb043-7355-44d8-9d19-feaa8e5637ad
DEBUG 01-04 15:36:16.162706.162706 mlpmodule.py:564] gpu pad cost 0.0038650035858154297 s
DEBUG 01-04 15:36:16.163815.163815 mlpmodule.py:582] gpu group einsum cost 0.0004107952117919922 s
DEBUG 01-04 15:36:16.165412.165412 mlpmodule.py:611] gpu experts func einsum cost 0.007312774658203125 s
DEBUG 01-04 15:36:16.165319.165319 cuda_h.py:19] end gpu_experts cost 0.007562160491943359 seconds
DEBUG 01-04 15:36:16.165790.165790 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.170402.170402 client.py:127] Model loaded
DEBUG 01-04 15:36:16.170284.170284 cuda_h.py:19] end sllm_worker_task cost 0.02491617202758789 seconds
DEBUG 01-04 15:36:16.171885.171885 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005158662796020508 seconds
DEBUG 01-04 15:36:16.171699.171699 cuda_h.py:19] end layer_moe_generate_6 cost 0.05906987190246582 seconds
DEBUG 01-04 15:36:16.171446.171446 lmp.py:207] -------------------------------- end layer 6 --------------------------------
DEBUG 01-04 15:36:16.171255.171255 lmp.py:169] -------------------------------- start layer 7 --------------------------------
DEBUG 01-04 15:36:16.171335.171335 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.171470.171470 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.174335.174335 cuda_h.py:19] end self_attn cost 0.0024483203887939453 seconds
DEBUG 01-04 15:36:16.174630.174630 cuda_h.py:19] end iln_self_attn_paln cost 0.0030319690704345703 seconds
DEBUG 01-04 15:36:16.174274.174274 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-04 15:36:16.174891.174891 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.175056.175056 cuda_h.py:19] end gate cost 0.0005464553833007812 seconds
DEBUG 01-04 15:36:16.175117.175117 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.175039.175039 lmp.py:281] 
DEBUG 01-04 15:36:16.175039.175039 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.175549.175549 lmp.py:282]   Total experts: 50
DEBUG 01-04 15:36:16.175053.175053 lmp.py:283]   CPU experts: 25 (50%)
DEBUG 01-04 15:36:16.175696.175696 lmp.py:284]   GPU experts: 25 (50%)
DEBUG 01-04 15:36:16.175432.175432 lmp.py:285] 
DEBUG 01-04 15:36:16.175432.175432 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.175929.175929 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.175433.175433 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:16.175884.175884 lmp.py:292]   Expert 18 |      1 | CPU
DEBUG 01-04 15:36:16.175858.175858 lmp.py:292]   Expert 30 |      1 | CPU
DEBUG 01-04 15:36:16.175594.175594 lmp.py:292]   Expert 35 |      2 | CPU
DEBUG 01-04 15:36:16.175091.175091 lmp.py:292]   Expert 40 |      2 | CPU
DEBUG 01-04 15:36:16.175588.175588 lmp.py:292]   Expert 57 |      2 | CPU
DEBUG 01-04 15:36:16.175370.175370 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:16.175629.175629 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:16.175888.175888 lmp.py:292]   Expert 21 |      3 | CPU
DEBUG 01-04 15:36:16.175385.175385 lmp.py:292]   Expert 32 |      3 | CPU
DEBUG 01-04 15:36:16.175405.175405 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:16.175426.175426 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:16.175684.175684 lmp.py:292]   Expert 54 |      3 | CPU
DEBUG 01-04 15:36:16.175705.175705 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:16.175487.175487 lmp.py:292]   Expert 60 |      3 | CPU
DEBUG 01-04 15:36:16.175746.175746 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:16.175527.175527 lmp.py:292]   Expert 36 |      4 | CPU
DEBUG 01-04 15:36:16.175548.175548 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:16.175807.175807 lmp.py:292]   Expert 48 |      4 | CPU
DEBUG 01-04 15:36:16.175589.175589 lmp.py:292]   Expert 19 |      5 | CPU
DEBUG 01-04 15:36:16.175371.175371 lmp.py:292]   Expert 24 |      5 | CPU
DEBUG 01-04 15:36:16.175914.175914 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:16.175934.175934 lmp.py:292]   Expert 34 |      5 | CPU
DEBUG 01-04 15:36:16.175716.175716 lmp.py:292]   Expert 47 |      5 | CPU
DEBUG 01-04 15:36:16.175498.175498 lmp.py:292]   Expert 62 |      5 | CPU
DEBUG 01-04 15:36:16.175280.175280 lmp.py:292]   Expert 17 |      6 | GPU
DEBUG 01-04 15:36:16.175062.175062 lmp.py:292]   Expert 33 |      7 | GPU
DEBUG 01-04 15:36:16.175083.175083 lmp.py:292]   Expert 42 |      8 | GPU
DEBUG 01-04 15:36:16.175103.175103 lmp.py:292]   Expert 61 |      8 | GPU
DEBUG 01-04 15:36:16.175123.175123 lmp.py:292]   Expert 43 |      9 | GPU
DEBUG 01-04 15:36:16.175720.175720 lmp.py:292]   Expert 22 |     10 | GPU
DEBUG 01-04 15:36:16.176740.176740 lmp.py:292]   Expert 23 |     10 | GPU
DEBUG 01-04 15:36:16.176999.176999 lmp.py:292]   Expert  7 |     11 | GPU
DEBUG 01-04 15:36:16.176781.176781 lmp.py:292]   Expert 28 |     11 | GPU
DEBUG 01-04 15:36:16.176563.176563 lmp.py:292]   Expert 27 |     12 | GPU
DEBUG 01-04 15:36:16.176107.176107 lmp.py:292]   Expert 37 |     13 | GPU
DEBUG 01-04 15:36:16.176127.176127 lmp.py:292]   Expert 38 |     13 | GPU
DEBUG 01-04 15:36:16.176909.176909 lmp.py:292]   Expert  9 |     14 | GPU
DEBUG 01-04 15:36:16.176691.176691 lmp.py:292]   Expert 51 |     14 | GPU
DEBUG 01-04 15:36:16.176234.176234 lmp.py:292]   Expert 10 |     17 | GPU
DEBUG 01-04 15:36:16.176255.176255 lmp.py:292]   Expert 44 |     17 | GPU
DEBUG 01-04 15:36:16.176037.176037 lmp.py:292]   Expert 46 |     20 | GPU
DEBUG 01-04 15:36:16.176819.176819 lmp.py:292]   Expert 12 |     21 | GPU
DEBUG 01-04 15:36:16.176362.176362 lmp.py:292]   Expert 56 |     26 | GPU
DEBUG 01-04 15:36:16.176383.176383 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:16.176926.176926 lmp.py:292]   Expert  3 |   1991 | GPU
DEBUG 01-04 15:36:16.176470.176470 lmp.py:292]   Expert  0 |   1992 | GPU
DEBUG 01-04 15:36:16.176013.176013 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:16.176795.176795 lmp.py:292]   Expert  2 |   1994 | GPU
DEBUG 01-04 15:36:16.176339.176339 lmp.py:292]   Expert  4 |   2000 | GPU
DEBUG 01-04 15:36:16.176597.176597 lmp.py:293] 
DEBUG 01-04 15:36:16.176597.176597 lmp.py:293]   CPU total tokens: 81 (0.7%)
DEBUG 01-04 15:36:16.176571.176571 lmp.py:294]   GPU total tokens: 12207 (99.3%)
DEBUG 01-04 15:36:16.176599.176599 cuda_h.py:19] end experts_map_get cost 0.0011022090911865234 seconds
DEBUG 01-04 15:36:16.176573.176573 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.176243.176243 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.176234.176234 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.176139.176139 cuda_h.py:19] end allocate_cuda_memory cost 0.0002849102020263672 seconds
DEBUG 01-04 15:36:16.176459.176459 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.176354.176354 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.176501.176501 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.176150.176150 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1060a336-2c2b-4ec6-8c05-0568feb7085f
DEBUG 01-04 15:36:16.177414.177414 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.178049.178049 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1060a336-2c2b-4ec6-8c05-0568feb7085f
DEBUG 01-04 15:36:16.178971.178971 cuda_h.py:19] end load_into_gpu_async cost 0.0012269020080566406 seconds
DEBUG 01-04 15:36:16.178667.178667 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.178764.178764 cuda_h.py:19] end restore_tensors2 cost 0.0002942085266113281 seconds
DEBUG 01-04 15:36:16.178394.178394 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021190643310546875 seconds
DEBUG 01-04 15:36:16.180316.180316 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004173994064331055 seconds
DEBUG 01-04 15:36:16.180106.180106 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.180161.180161 lmp.py:339] 
DEBUG 01-04 15:36:16.180161.180161 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:16.180713.180713 cuda_h.py:19] end cpu_experts_submit cost 0.00010347366333007812 seconds
DEBUG 01-04 15:36:16.180316.180316 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.187569.187569 mlpmodule.py:704] group tensors cost 0.006398916244506836 s
DEBUG 01-04 15:36:16.189282.189282 mlpmodule.py:742] pad cost 0.0016088485717773438 s
DEBUG 01-04 15:36:16.189166.189166 mlpmodule.py:748] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-04 15:36:16.189578.189578 mlpmodule.py:753] move to cpu cost 2.6941299438476562e-05 s
DEBUG 01-04 15:36:16.193510.193510 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:16.193785.193785 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.193980.193980 mlpmodule.py:774] group_w3 first element: -0.030029296875
WARNING 01-04 15:36:16.193606.193606 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.196506.196506 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.196905.196905 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.200117.200117 mlpmodule.py:797] group einsum cost 0.011076688766479492 s
DEBUG 01-04 15:36:16.201185.201185 mlpmodule.py:805] cpy2cputensor cost 9.226799011230469e-05 s
DEBUG 01-04 15:36:16.205522.205522 cuda_h.py:19] end wait_cetm_experts cost 0.024295330047607422 seconds
DEBUG 01-04 15:36:16.205174.205174 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.205604.205604 cuda_h.py:19] end gpu_sexperts cost 0.0005168914794921875 seconds
DEBUG 01-04 15:36:16.205493.205493 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-04 15:36:16.205700.205700 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-04 15:36:16.205610.205610 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.838539123535156e-05 seconds
DEBUG 01-04 15:36:16.205518.205518 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.963180541992188e-05 seconds
DEBUG 01-04 15:36:16.205221.205221 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.206746.206746 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1060a336-2c2b-4ec6-8c05-0568feb7085f
DEBUG 01-04 15:36:16.206977.206977 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.206807.206807 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.206650.206650 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.210160.210160 cuda_h.py:19] end allocate_cuda_memory cost 0.004514932632446289 seconds
DEBUG 01-04 15:36:16.210693.210693 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.211840.211840 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.211192.211192 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.211710.211710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f2a9e9ef-f4a0-4db0-a2ca-427a82305406
DEBUG 01-04 15:36:16.211938.211938 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.219691.219691 client.py:127] Model loaded
DEBUG 01-04 15:36:16.219448.219448 cuda_h.py:19] end wait_experts cost 0.013651847839355469 seconds
DEBUG 01-04 15:36:16.219151.219151 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.219291.219291 lmp.py:384]   Computing 25 experts on GPU...
DEBUG 01-04 15:36:16.220561.220561 mlpmodule.py:531] gpu group tensors cost 0.00047850608825683594 s
DEBUG 01-04 15:36:16.220342.220342 mlpmodule.py:662]  experts func einsum cost 0.03960990905761719 s
INFO 01-04 15:36:16.220651.220651 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f2a9e9ef-f4a0-4db0-a2ca-427a82305406
DEBUG 01-04 15:36:16.220058.220058 cuda_h.py:19] end load_into_gpu_async cost 0.009676694869995117 seconds
DEBUG 01-04 15:36:16.220953.220953 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.220360.220360 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-04 15:36:16.220162.220162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014519453048706055 seconds
INFO 01-04 15:36:16.221822.221822 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f2a9e9ef-f4a0-4db0-a2ca-427a82305406
DEBUG 01-04 15:36:16.222616.222616 mlpmodule.py:564] gpu pad cost 0.0023686885833740234 s
DEBUG 01-04 15:36:16.223975.223975 mlpmodule.py:582] gpu group einsum cost 0.0005583763122558594 s
DEBUG 01-04 15:36:16.226492.226492 mlpmodule.py:611] gpu experts func einsum cost 0.006711244583129883 s
DEBUG 01-04 15:36:16.226002.226002 cuda_h.py:19] end gpu_experts cost 0.006985902786254883 seconds
DEBUG 01-04 15:36:16.226334.226334 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.231943.231943 client.py:127] Model loaded
DEBUG 01-04 15:36:16.231369.231369 cuda_h.py:19] end sllm_worker_task cost 0.0251007080078125 seconds
DEBUG 01-04 15:36:16.231041.231041 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004668235778808594 seconds
DEBUG 01-04 15:36:16.231358.231358 cuda_h.py:19] end layer_moe_generate_7 cost 0.057053327560424805 seconds
DEBUG 01-04 15:36:16.231919.231919 lmp.py:207] -------------------------------- end layer 7 --------------------------------
DEBUG 01-04 15:36:16.231060.231060 lmp.py:169] -------------------------------- start layer 8 --------------------------------
DEBUG 01-04 15:36:16.231802.231802 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.232621.232621 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.235427.235427 cuda_h.py:19] end self_attn cost 0.0028562545776367188 seconds
DEBUG 01-04 15:36:16.235671.235671 cuda_h.py:19] end iln_self_attn_paln cost 0.003558635711669922 seconds
DEBUG 01-04 15:36:16.235699.235699 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-04 15:36:16.235892.235892 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.236021.236021 cuda_h.py:19] end gate cost 0.0006563663482666016 seconds
DEBUG 01-04 15:36:16.236851.236851 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.236268.236268 lmp.py:281] 
DEBUG 01-04 15:36:16.236268.236268 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.236977.236977 lmp.py:282]   Total experts: 47
DEBUG 01-04 15:36:16.236057.236057 lmp.py:283]   CPU experts: 23 (49%)
DEBUG 01-04 15:36:16.236038.236038 lmp.py:284]   GPU experts: 24 (51%)
DEBUG 01-04 15:36:16.236397.236397 lmp.py:285] 
DEBUG 01-04 15:36:16.236397.236397 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.236232.236232 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.236073.236073 lmp.py:292]   Expert 22 |      1 | CPU
DEBUG 01-04 15:36:16.236670.236670 lmp.py:292]   Expert 33 |      1 | CPU
DEBUG 01-04 15:36:16.236313.236313 lmp.py:292]   Expert 50 |      1 | CPU
DEBUG 01-04 15:36:16.236194.236194 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:16.236837.236837 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:16.236004.236004 lmp.py:292]   Expert 10 |      2 | CPU
DEBUG 01-04 15:36:16.236647.236647 lmp.py:292]   Expert 29 |      2 | CPU
DEBUG 01-04 15:36:16.236813.236813 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:16.236740.236740 lmp.py:292]   Expert 37 |      2 | CPU
DEBUG 01-04 15:36:16.236668.236668 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:16.236073.236073 lmp.py:292]   Expert 17 |      3 | CPU
DEBUG 01-04 15:36:16.236908.236908 lmp.py:292]   Expert 23 |      3 | CPU
DEBUG 01-04 15:36:16.236266.236266 lmp.py:292]   Expert 35 |      3 | CPU
DEBUG 01-04 15:36:16.237909.237909 lmp.py:292]   Expert 40 |      3 | CPU
DEBUG 01-04 15:36:16.237029.237029 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:16.237195.237195 lmp.py:292]   Expert 61 |      3 | CPU
DEBUG 01-04 15:36:16.237123.237123 lmp.py:292]   Expert 41 |      4 | CPU
DEBUG 01-04 15:36:16.237812.237812 lmp.py:292]   Expert 32 |      5 | CPU
DEBUG 01-04 15:36:16.237978.237978 lmp.py:292]   Expert 42 |      5 | CPU
DEBUG 01-04 15:36:16.237667.237667 lmp.py:292]   Expert 46 |      5 | CPU
DEBUG 01-04 15:36:16.237834.237834 lmp.py:292]   Expert 31 |      6 | CPU
DEBUG 01-04 15:36:16.237761.237761 lmp.py:292]   Expert 39 |      6 | CPU
DEBUG 01-04 15:36:16.237451.237451 lmp.py:292]   Expert 44 |      6 | CPU
DEBUG 01-04 15:36:16.237140.237140 lmp.py:292]   Expert 56 |      6 | GPU
DEBUG 01-04 15:36:16.237068.237068 lmp.py:292]   Expert 55 |      7 | GPU
DEBUG 01-04 15:36:16.237426.237426 lmp.py:292]   Expert  6 |      8 | GPU
DEBUG 01-04 15:36:16.237022.237022 lmp.py:292]   Expert 16 |      9 | GPU
DEBUG 01-04 15:36:16.237427.237427 lmp.py:292]   Expert 18 |      9 | GPU
DEBUG 01-04 15:36:16.237308.237308 lmp.py:292]   Expert 49 |      9 | GPU
DEBUG 01-04 15:36:16.237190.237190 lmp.py:292]   Expert 25 |     11 | GPU
DEBUG 01-04 15:36:16.237594.237594 lmp.py:292]   Expert 47 |     13 | GPU
DEBUG 01-04 15:36:16.237522.237522 lmp.py:292]   Expert 52 |     13 | GPU
DEBUG 01-04 15:36:16.237688.237688 lmp.py:292]   Expert 63 |     13 | GPU
DEBUG 01-04 15:36:16.237616.237616 lmp.py:292]   Expert 11 |     14 | GPU
DEBUG 01-04 15:36:16.237305.237305 lmp.py:292]   Expert 28 |     14 | GPU
DEBUG 01-04 15:36:16.237995.237995 lmp.py:292]   Expert 43 |     14 | GPU
DEBUG 01-04 15:36:16.237922.237922 lmp.py:292]   Expert 20 |     15 | GPU
DEBUG 01-04 15:36:16.237850.237850 lmp.py:292]   Expert 48 |     15 | GPU
DEBUG 01-04 15:36:16.237731.237731 lmp.py:292]   Expert 62 |     16 | GPU
DEBUG 01-04 15:36:16.237374.237374 lmp.py:292]   Expert 45 |     18 | GPU
DEBUG 01-04 15:36:16.237779.237779 lmp.py:292]   Expert 21 |     23 | GPU
DEBUG 01-04 15:36:16.237137.237137 lmp.py:292]   Expert  3 |   1994 | GPU
DEBUG 01-04 15:36:16.237257.237257 lmp.py:292]   Expert  1 |   1995 | GPU
DEBUG 01-04 15:36:16.237900.237900 lmp.py:292]   Expert  0 |   1998 | GPU
DEBUG 01-04 15:36:16.237589.237589 lmp.py:292]   Expert  2 |   1998 | GPU
DEBUG 01-04 15:36:16.237517.237517 lmp.py:292]   Expert  4 |   1998 | GPU
DEBUG 01-04 15:36:16.237935.237935 lmp.py:292]   Expert  5 |   2007 | GPU
DEBUG 01-04 15:36:16.237624.237624 lmp.py:293] 
DEBUG 01-04 15:36:16.237624.237624 lmp.py:293]   CPU total tokens: 71 (0.6%)
DEBUG 01-04 15:36:16.237552.237552 lmp.py:294]   GPU total tokens: 12217 (99.4%)
DEBUG 01-04 15:36:16.237725.237725 cuda_h.py:19] end experts_map_get cost 0.0013532638549804688 seconds
DEBUG 01-04 15:36:16.237368.237368 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.237376.237376 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.237658.237658 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.238058.238058 cuda_h.py:19] end allocate_cuda_memory cost 0.0002617835998535156 seconds
DEBUG 01-04 15:36:16.238524.238524 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.238849.238849 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.238327.238327 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.238216.238216 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 546493e8-8aa0-47cb-b48a-0fb8a078a940
DEBUG 01-04 15:36:16.238803.238803 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.240579.240579 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 546493e8-8aa0-47cb-b48a-0fb8a078a940
DEBUG 01-04 15:36:16.240809.240809 cuda_h.py:19] end load_into_gpu_async cost 0.0021276473999023438 seconds
DEBUG 01-04 15:36:16.240006.240006 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.241323.241323 cuda_h.py:19] end restore_tensors2 cost 0.0005080699920654297 seconds
DEBUG 01-04 15:36:16.241969.241969 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003427743911743164 seconds
DEBUG 01-04 15:36:16.245553.245553 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007860183715820312 seconds
DEBUG 01-04 15:36:16.245960.245960 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.245335.245335 lmp.py:339] 
DEBUG 01-04 15:36:16.245335.245335 lmp.py:339]   Computing 23 experts on CPU...
DEBUG 01-04 15:36:16.245133.245133 cuda_h.py:19] end cpu_experts_submit cost 0.0001785755157470703 seconds
DEBUG 01-04 15:36:16.245910.245910 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.253094.253094 mlpmodule.py:704] group tensors cost 0.0069124698638916016 s
DEBUG 01-04 15:36:16.255503.255503 mlpmodule.py:742] pad cost 0.0019578933715820312 s
DEBUG 01-04 15:36:16.255667.255667 mlpmodule.py:748] create cpu tensor cost 6.389617919921875e-05 s
DEBUG 01-04 15:36:16.256671.256671 mlpmodule.py:753] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-04 15:36:16.259848.259848 mlpmodule.py:768] group_w3: shape=torch.Size([23, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=66322432
DEBUG 01-04 15:36:16.259388.259388 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.259776.259776 mlpmodule.py:774] group_w3 first element: 0.01373291015625
WARNING 01-04 15:36:16.260589.260589 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.262521.262521 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.263793.263793 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.266428.266428 mlpmodule.py:797] group einsum cost 0.010868072509765625 s
DEBUG 01-04 15:36:16.267735.267735 mlpmodule.py:805] cpy2cputensor cost 0.0001125335693359375 s
DEBUG 01-04 15:36:16.270422.270422 cuda_h.py:19] end wait_cetm_experts cost 0.024927139282226562 seconds
DEBUG 01-04 15:36:16.271220.271220 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.271702.271702 cuda_h.py:19] end gpu_sexperts cost 0.0005173683166503906 seconds
DEBUG 01-04 15:36:16.271360.271360 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-04 15:36:16.271852.271852 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-04 15:36:16.271000.271000 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.552436828613281e-05 seconds
DEBUG 01-04 15:36:16.271909.271909 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.963180541992188e-05 seconds
DEBUG 01-04 15:36:16.271135.271135 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.271566.271566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 546493e8-8aa0-47cb-b48a-0fb8a078a940
DEBUG 01-04 15:36:16.272989.272989 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.272370.272370 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.272975.272975 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.276434.276434 cuda_h.py:19] end allocate_cuda_memory cost 0.0043714046478271484 seconds
DEBUG 01-04 15:36:16.276510.276510 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.276134.276134 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.276201.276201 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.276388.276388 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9755e6c-7e5a-4329-ba86-268797b448b1
DEBUG 01-04 15:36:16.276524.276524 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.278765.278765 client.py:127] Model loaded
DEBUG 01-04 15:36:16.278715.278715 cuda_h.py:19] end wait_experts cost 0.006608247756958008 seconds
DEBUG 01-04 15:36:16.278947.278947 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.278088.278088 lmp.py:384]   Computing 24 experts on GPU...
DEBUG 01-04 15:36:16.279314.279314 mlpmodule.py:531] gpu group tensors cost 0.0005450248718261719 s
INFO 01-04 15:36:16.279419.279419 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9755e6c-7e5a-4329-ba86-268797b448b1
DEBUG 01-04 15:36:16.279845.279845 cuda_h.py:19] end load_into_gpu_async cost 0.002665996551513672 seconds
DEBUG 01-04 15:36:16.279648.279648 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.279181.279181 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-04 15:36:16.279421.279421 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0074121952056884766 seconds
INFO 01-04 15:36:16.280078.280078 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9755e6c-7e5a-4329-ba86-268797b448b1
DEBUG 01-04 15:36:16.281331.281331 mlpmodule.py:564] gpu pad cost 0.002624034881591797 s
DEBUG 01-04 15:36:16.282811.282811 mlpmodule.py:582] gpu group einsum cost 0.0006144046783447266 s
DEBUG 01-04 15:36:16.285886.285886 mlpmodule.py:662]  experts func einsum cost 0.03968548774719238 s
DEBUG 01-04 15:36:16.285096.285096 mlpmodule.py:611] gpu experts func einsum cost 0.007296323776245117 s
DEBUG 01-04 15:36:16.286592.286592 cuda_h.py:19] end gpu_experts cost 0.0075359344482421875 seconds
DEBUG 01-04 15:36:16.286685.286685 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.290148.290148 client.py:127] Model loaded
DEBUG 01-04 15:36:16.290368.290368 cuda_h.py:19] end sllm_worker_task cost 0.018331050872802734 seconds
DEBUG 01-04 15:36:16.290238.290238 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00441431999206543 seconds
DEBUG 01-04 15:36:16.290270.290270 cuda_h.py:19] end layer_moe_generate_8 cost 0.05519890785217285 seconds
DEBUG 01-04 15:36:16.290541.290541 lmp.py:207] -------------------------------- end layer 8 --------------------------------
DEBUG 01-04 15:36:16.290204.290204 lmp.py:169] -------------------------------- start layer 9 --------------------------------
DEBUG 01-04 15:36:16.290185.290185 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.291209.291209 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.294149.294149 cuda_h.py:19] end self_attn cost 0.0028841495513916016 seconds
DEBUG 01-04 15:36:16.294273.294273 cuda_h.py:19] end iln_self_attn_paln cost 0.0035800933837890625 seconds
DEBUG 01-04 15:36:16.294063.294063 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-04 15:36:16.294362.294362 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.295028.295028 cuda_h.py:19] end gate cost 0.0006656646728515625 seconds
DEBUG 01-04 15:36:16.295619.295619 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.295863.295863 lmp.py:281] 
DEBUG 01-04 15:36:16.295863.295863 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.295235.295235 lmp.py:282]   Total experts: 49
DEBUG 01-04 15:36:16.295838.295838 lmp.py:283]   CPU experts: 24 (49%)
DEBUG 01-04 15:36:16.295150.295150 lmp.py:284]   GPU experts: 25 (51%)
DEBUG 01-04 15:36:16.295793.295793 lmp.py:285] 
DEBUG 01-04 15:36:16.295793.295793 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.295151.295151 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.295801.295801 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:16.295682.295682 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:16.295610.295610 lmp.py:292]   Expert 17 |      1 | CPU
DEBUG 01-04 15:36:16.295299.295299 lmp.py:292]   Expert 19 |      1 | CPU
DEBUG 01-04 15:36:16.295750.295750 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:16.295678.295678 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:16.295890.295890 lmp.py:292]   Expert 39 |      1 | CPU
DEBUG 01-04 15:36:16.296341.296341 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:16.296792.296792 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:16.296005.296005 lmp.py:292]   Expert 24 |      2 | CPU
DEBUG 01-04 15:36:16.296932.296932 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:16.296383.296383 lmp.py:292]   Expert 41 |      2 | CPU
DEBUG 01-04 15:36:16.296311.296311 lmp.py:292]   Expert 43 |      2 | CPU
DEBUG 01-04 15:36:16.296477.296477 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:16.296643.296643 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:16.296809.296809 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:16.296737.296737 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:16.296711.296711 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:16.296162.296162 lmp.py:292]   Expert 62 |      4 | CPU
DEBUG 01-04 15:36:16.296613.296613 lmp.py:292]   Expert 10 |      5 | CPU
DEBUG 01-04 15:36:16.296587.296587 lmp.py:292]   Expert 18 |      5 | CPU
DEBUG 01-04 15:36:16.296038.296038 lmp.py:292]   Expert 22 |      5 | CPU
DEBUG 01-04 15:36:16.296727.296727 lmp.py:292]   Expert 23 |      5 | CPU
DEBUG 01-04 15:36:16.296701.296701 lmp.py:292]   Expert 34 |      5 | CPU
DEBUG 01-04 15:36:16.296390.296390 lmp.py:292]   Expert 59 |      5 | GPU
DEBUG 01-04 15:36:16.296603.296603 lmp.py:292]   Expert 61 |      5 | GPU
DEBUG 01-04 15:36:16.296577.296577 lmp.py:292]   Expert 16 |      6 | GPU
DEBUG 01-04 15:36:16.296789.296789 lmp.py:292]   Expert 31 |      6 | GPU
DEBUG 01-04 15:36:16.296002.296002 lmp.py:292]   Expert 49 |      6 | GPU
DEBUG 01-04 15:36:16.296453.296453 lmp.py:292]   Expert 51 |      7 | GPU
DEBUG 01-04 15:36:16.296341.296341 lmp.py:292]   Expert  9 |      8 | GPU
DEBUG 01-04 15:36:16.296243.296243 lmp.py:292]   Expert 36 |      8 | GPU
DEBUG 01-04 15:36:16.296601.296601 lmp.py:292]   Expert 53 |      8 | GPU
DEBUG 01-04 15:36:16.296767.296767 lmp.py:292]   Expert 55 |     10 | GPU
DEBUG 01-04 15:36:16.296695.296695 lmp.py:292]   Expert 42 |     11 | GPU
DEBUG 01-04 15:36:16.296622.296622 lmp.py:292]   Expert 44 |     12 | GPU
DEBUG 01-04 15:36:16.296504.296504 lmp.py:292]   Expert 15 |     15 | GPU
DEBUG 01-04 15:36:16.296908.296908 lmp.py:292]   Expert 37 |     17 | GPU
DEBUG 01-04 15:36:16.296313.296313 lmp.py:292]   Expert 46 |     17 | GPU
DEBUG 01-04 15:36:16.296956.296956 lmp.py:292]   Expert 63 |     19 | GPU
DEBUG 01-04 15:36:16.296122.296122 lmp.py:292]   Expert 21 |     21 | GPU
DEBUG 01-04 15:36:16.296527.296527 lmp.py:292]   Expert 56 |     29 | GPU
DEBUG 01-04 15:36:16.296693.296693 lmp.py:292]   Expert  8 |     38 | GPU
DEBUG 01-04 15:36:16.296859.296859 lmp.py:292]   Expert  2 |   1991 | GPU
DEBUG 01-04 15:36:16.296787.296787 lmp.py:292]   Expert  5 |   1991 | GPU
DEBUG 01-04 15:36:16.296476.296476 lmp.py:292]   Expert  1 |   1996 | GPU
DEBUG 01-04 15:36:16.296404.296404 lmp.py:292]   Expert  4 |   1996 | GPU
DEBUG 01-04 15:36:16.296570.296570 lmp.py:292]   Expert  0 |   2002 | GPU
DEBUG 01-04 15:36:16.296497.296497 lmp.py:292]   Expert  3 |   2002 | GPU
DEBUG 01-04 15:36:16.296140.296140 lmp.py:293] 
DEBUG 01-04 15:36:16.296140.296140 lmp.py:293]   CPU total tokens: 62 (0.5%)
DEBUG 01-04 15:36:16.296260.296260 lmp.py:294]   GPU total tokens: 12226 (99.5%)
DEBUG 01-04 15:36:16.296148.296148 cuda_h.py:19] end experts_map_get cost 0.0013446807861328125 seconds
DEBUG 01-04 15:36:16.296507.296507 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.296568.296568 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.296432.296432 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.297085.297085 cuda_h.py:19] end allocate_cuda_memory cost 0.00027179718017578125 seconds
DEBUG 01-04 15:36:16.297412.297412 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.297168.297168 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.297792.297792 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.297110.297110 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 58bdb65b-3dda-48ed-af31-cfd941891258
DEBUG 01-04 15:36:16.297732.297732 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.299938.299938 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 58bdb65b-3dda-48ed-af31-cfd941891258
DEBUG 01-04 15:36:16.299390.299390 cuda_h.py:19] end load_into_gpu_async cost 0.002094268798828125 seconds
DEBUG 01-04 15:36:16.299709.299709 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.299285.299285 cuda_h.py:19] end restore_tensors2 cost 0.0003631114959716797 seconds
DEBUG 01-04 15:36:16.299300.299300 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030438899993896484 seconds
DEBUG 01-04 15:36:16.302946.302946 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005560159683227539 seconds
DEBUG 01-04 15:36:16.302636.302636 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.302321.302321 lmp.py:339] 
DEBUG 01-04 15:36:16.302321.302321 lmp.py:339]   Computing 24 experts on CPU...
DEBUG 01-04 15:36:16.302872.302872 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-04 15:36:16.302688.302688 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.308942.308942 mlpmodule.py:704] group tensors cost 0.005466938018798828 s
DEBUG 01-04 15:36:16.310673.310673 mlpmodule.py:742] pad cost 0.001390218734741211 s
DEBUG 01-04 15:36:16.310253.310253 mlpmodule.py:748] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-04 15:36:16.310308.310308 mlpmodule.py:753] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-04 15:36:16.314266.314266 mlpmodule.py:768] group_w3: shape=torch.Size([24, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=69206016
DEBUG 01-04 15:36:16.314488.314488 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.314259.314259 mlpmodule.py:774] group_w3 first element: 0.042724609375
WARNING 01-04 15:36:16.314394.314394 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.317766.317766 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.317074.317074 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.321301.321301 mlpmodule.py:797] group einsum cost 0.010981321334838867 s
DEBUG 01-04 15:36:16.321700.321700 mlpmodule.py:805] cpy2cputensor cost 9.512901306152344e-05 s
DEBUG 01-04 15:36:16.325669.325669 cuda_h.py:19] end wait_cetm_experts cost 0.022896289825439453 seconds
DEBUG 01-04 15:36:16.325566.325566 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.326095.326095 cuda_h.py:19] end gpu_sexperts cost 0.0005204677581787109 seconds
DEBUG 01-04 15:36:16.326984.326984 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-04 15:36:16.326522.326522 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-04 15:36:16.326333.326333 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.552436828613281e-05 seconds
DEBUG 01-04 15:36:16.326334.326334 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.510185241699219e-05 seconds
DEBUG 01-04 15:36:16.326560.326560 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.326607.326607 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 58bdb65b-3dda-48ed-af31-cfd941891258
DEBUG 01-04 15:36:16.326130.326130 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.326484.326484 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.326135.326135 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.331171.331171 cuda_h.py:19] end allocate_cuda_memory cost 0.004200935363769531 seconds
DEBUG 01-04 15:36:16.331943.331943 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.331043.331043 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.331965.331965 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.331006.331006 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 96d335a8-a647-47ce-ba5f-815889c28d35
DEBUG 01-04 15:36:16.331235.331235 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:16.340300.340300 mlpmodule.py:662]  experts func einsum cost 0.03752303123474121 s
INFO 01-04 15:36:16.341951.341951 client.py:127] Model loaded
DEBUG 01-04 15:36:16.341400.341400 cuda_h.py:19] end wait_experts cost 0.014964103698730469 seconds
DEBUG 01-04 15:36:16.341416.341416 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.341386.341386 lmp.py:384]   Computing 25 experts on GPU...
INFO 01-04 15:36:16.342892.342892 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 96d335a8-a647-47ce-ba5f-815889c28d35
DEBUG 01-04 15:36:16.342379.342379 cuda_h.py:19] end load_into_gpu_async cost 0.011404037475585938 seconds
DEBUG 01-04 15:36:16.342361.342361 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.342976.342976 cuda_h.py:19] end restore_tensors2 cost 0.00011587142944335938 seconds
DEBUG 01-04 15:36:16.342303.342303 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01611924171447754 seconds
DEBUG 01-04 15:36:16.343529.343529 mlpmodule.py:531] gpu group tensors cost 0.001741170883178711 s
INFO 01-04 15:36:16.344843.344843 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 96d335a8-a647-47ce-ba5f-815889c28d35
DEBUG 01-04 15:36:16.347368.347368 mlpmodule.py:564] gpu pad cost 0.0032968521118164062 s
DEBUG 01-04 15:36:16.348230.348230 mlpmodule.py:582] gpu group einsum cost 0.0007352828979492188 s
INFO 01-04 15:36:16.349553.349553 client.py:127] Model loaded
DEBUG 01-04 15:36:16.349457.349457 cuda_h.py:19] end sllm_worker_task cost 0.022727012634277344 seconds
DEBUG 01-04 15:36:16.353075.353075 mlpmodule.py:611] gpu experts func einsum cost 0.011739492416381836 s
DEBUG 01-04 15:36:16.353820.353820 cuda_h.py:19] end gpu_experts cost 0.011992216110229492 seconds
DEBUG 01-04 15:36:16.353676.353676 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:16.353313.353313 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-04 15:36:16.354074.354074 cuda_h.py:19] end layer_moe_generate_9 cost 0.0596311092376709 seconds
DEBUG 01-04 15:36:16.354172.354172 lmp.py:207] -------------------------------- end layer 9 --------------------------------
DEBUG 01-04 15:36:16.354372.354372 lmp.py:169] -------------------------------- start layer 10 --------------------------------
DEBUG 01-04 15:36:16.354976.354976 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.354796.354796 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.358377.358377 cuda_h.py:19] end self_attn cost 0.003072500228881836 seconds
DEBUG 01-04 15:36:16.358900.358900 cuda_h.py:19] end iln_self_attn_paln cost 0.0038428306579589844 seconds
DEBUG 01-04 15:36:16.358366.358366 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-04 15:36:16.358089.358089 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.359082.359082 cuda_h.py:19] end gate cost 0.0007228851318359375 seconds
DEBUG 01-04 15:36:16.359918.359918 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.359250.359250 lmp.py:281] 
DEBUG 01-04 15:36:16.359250.359250 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.359629.359629 lmp.py:282]   Total experts: 51
DEBUG 01-04 15:36:16.359855.359855 lmp.py:283]   CPU experts: 25 (49%)
DEBUG 01-04 15:36:16.359981.359981 lmp.py:284]   GPU experts: 26 (51%)
DEBUG 01-04 15:36:16.359439.359439 lmp.py:285] 
DEBUG 01-04 15:36:16.359439.359439 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.359758.359758 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.359222.359222 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:16.359441.359441 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:16.359707.359707 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:16.359257.359257 lmp.py:292]   Expert 38 |      1 | CPU
DEBUG 01-04 15:36:16.359808.359808 lmp.py:292]   Expert 47 |      1 | CPU
DEBUG 01-04 15:36:16.359358.359358 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:16.360670.360670 lmp.py:292]   Expert  6 |      2 | CPU
DEBUG 01-04 15:36:16.360982.360982 lmp.py:292]   Expert  7 |      2 | CPU
DEBUG 01-04 15:36:16.360294.360294 lmp.py:292]   Expert  8 |      2 | CPU
DEBUG 01-04 15:36:16.360605.360605 lmp.py:292]   Expert 22 |      2 | CPU
DEBUG 01-04 15:36:16.360679.360679 lmp.py:292]   Expert 25 |      2 | CPU
DEBUG 01-04 15:36:16.360229.360229 lmp.py:292]   Expert 36 |      2 | CPU
DEBUG 01-04 15:36:16.360018.360018 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:16.360330.360330 lmp.py:292]   Expert 60 |      2 | CPU
DEBUG 01-04 15:36:16.360119.360119 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:16.360669.360669 lmp.py:292]   Expert 27 |      3 | CPU
DEBUG 01-04 15:36:16.360981.360981 lmp.py:292]   Expert 57 |      3 | CPU
DEBUG 01-04 15:36:16.360531.360531 lmp.py:292]   Expert 19 |      4 | CPU
DEBUG 01-04 15:36:16.360843.360843 lmp.py:292]   Expert 26 |      4 | CPU
DEBUG 01-04 15:36:16.360586.360586 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:16.360136.360136 lmp.py:292]   Expert 28 |      5 | CPU
DEBUG 01-04 15:36:16.360925.360925 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:16.360760.360760 lmp.py:292]   Expert 41 |      5 | CPU
DEBUG 01-04 15:36:16.360833.360833 lmp.py:292]   Expert 53 |      5 | CPU
DEBUG 01-04 15:36:16.360907.360907 lmp.py:292]   Expert 56 |      5 | CPU
DEBUG 01-04 15:36:16.360219.360219 lmp.py:292]   Expert 21 |      6 | GPU
DEBUG 01-04 15:36:16.360352.360352 lmp.py:292]   Expert 23 |      6 | GPU
DEBUG 01-04 15:36:16.360425.360425 lmp.py:292]   Expert 33 |      6 | GPU
DEBUG 01-04 15:36:16.360737.360737 lmp.py:292]   Expert 51 |      6 | GPU
DEBUG 01-04 15:36:16.360049.360049 lmp.py:292]   Expert 52 |      6 | GPU
DEBUG 01-04 15:36:16.360361.360361 lmp.py:292]   Expert  9 |      7 | GPU
DEBUG 01-04 15:36:16.360150.360150 lmp.py:292]   Expert 42 |      8 | GPU
DEBUG 01-04 15:36:16.360131.360131 lmp.py:292]   Expert 40 |      9 | GPU
DEBUG 01-04 15:36:16.360443.360443 lmp.py:292]   Expert 43 |      9 | GPU
DEBUG 01-04 15:36:16.360947.360947 lmp.py:292]   Expert 45 |      9 | GPU
DEBUG 01-04 15:36:16.360497.360497 lmp.py:292]   Expert 10 |     11 | GPU
DEBUG 01-04 15:36:16.360570.360570 lmp.py:292]   Expert 63 |     11 | GPU
DEBUG 01-04 15:36:16.360882.360882 lmp.py:292]   Expert 17 |     12 | GPU
DEBUG 01-04 15:36:16.360717.360717 lmp.py:292]   Expert 31 |     12 | GPU
DEBUG 01-04 15:36:16.360029.360029 lmp.py:292]   Expert 11 |     13 | GPU
DEBUG 01-04 15:36:16.360341.360341 lmp.py:292]   Expert 39 |     13 | GPU
DEBUG 01-04 15:36:16.360415.360415 lmp.py:292]   Expert 16 |     15 | GPU
DEBUG 01-04 15:36:16.360488.360488 lmp.py:292]   Expert 30 |     15 | GPU
DEBUG 01-04 15:36:16.360231.360231 lmp.py:292]   Expert 18 |     16 | GPU
DEBUG 01-04 15:36:16.360211.360211 lmp.py:292]   Expert 58 |     27 | GPU
DEBUG 01-04 15:36:16.360431.360431 lmp.py:292]   Expert  3 |   1991 | GPU
DEBUG 01-04 15:36:16.360219.360219 lmp.py:292]   Expert  2 |   1997 | GPU
DEBUG 01-04 15:36:16.360770.360770 lmp.py:292]   Expert  5 |   1997 | GPU
DEBUG 01-04 15:36:16.360843.360843 lmp.py:292]   Expert  0 |   2005 | GPU
DEBUG 01-04 15:36:16.360155.360155 lmp.py:292]   Expert  4 |   2006 | GPU
DEBUG 01-04 15:36:16.360944.360944 lmp.py:292]   Expert  1 |   2007 | GPU
DEBUG 01-04 15:36:16.360971.360971 lmp.py:293] 
DEBUG 01-04 15:36:16.360971.360971 lmp.py:293]   CPU total tokens: 68 (0.6%)
DEBUG 01-04 15:36:16.360998.360998 lmp.py:294]   GPU total tokens: 12220 (99.4%)
DEBUG 01-04 15:36:16.360986.360986 cuda_h.py:19] end experts_map_get cost 0.0015974044799804688 seconds
DEBUG 01-04 15:36:16.360682.360682 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.361227.361227 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.361582.361582 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.361380.361380 cuda_h.py:19] end allocate_cuda_memory cost 0.0002720355987548828 seconds
DEBUG 01-04 15:36:16.361237.361237 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.361569.361569 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.361961.361961 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.361426.361426 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0466ab01-e29c-4687-993f-f3d56ed124a4
DEBUG 01-04 15:36:16.361763.361763 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.363764.363764 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0466ab01-e29c-4687-993f-f3d56ed124a4
DEBUG 01-04 15:36:16.363839.363839 cuda_h.py:19] end load_into_gpu_async cost 0.0021295547485351562 seconds
DEBUG 01-04 15:36:16.363158.363158 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.364694.364694 cuda_h.py:19] end restore_tensors2 cost 0.0003695487976074219 seconds
DEBUG 01-04 15:36:16.364663.364663 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00310516357421875 seconds
DEBUG 01-04 15:36:16.366754.366754 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005674600601196289 seconds
DEBUG 01-04 15:36:16.366060.366060 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.366268.366268 lmp.py:339] 
DEBUG 01-04 15:36:16.366268.366268 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:16.366104.366104 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-04 15:36:16.366920.366920 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.376790.376790 mlpmodule.py:704] group tensors cost 0.008984804153442383 s
DEBUG 01-04 15:36:16.379627.379627 mlpmodule.py:742] pad cost 0.002447843551635742 s
DEBUG 01-04 15:36:16.379501.379501 mlpmodule.py:748] create cpu tensor cost 7.295608520507812e-05 s
DEBUG 01-04 15:36:16.379624.379624 mlpmodule.py:753] move to cpu cost 5.078315734863281e-05 s
DEBUG 01-04 15:36:16.383835.383835 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:16.383772.383772 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.383251.383251 mlpmodule.py:774] group_w3 first element: -0.06689453125
WARNING 01-04 15:36:16.383149.383149 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.386263.386263 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.386080.386080 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.389148.389148 mlpmodule.py:797] group einsum cost 0.010018110275268555 s
DEBUG 01-04 15:36:16.390157.390157 mlpmodule.py:805] cpy2cputensor cost 9.059906005859375e-05 s
DEBUG 01-04 15:36:16.394627.394627 cuda_h.py:19] end wait_cetm_experts cost 0.0271914005279541 seconds
DEBUG 01-04 15:36:16.394094.394094 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.394530.394530 cuda_h.py:19] end gpu_sexperts cost 0.0005178451538085938 seconds
DEBUG 01-04 15:36:16.394003.394003 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-04 15:36:16.394494.394494 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-04 15:36:16.394782.394782 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.552436828613281e-05 seconds
DEBUG 01-04 15:36:16.395975.395975 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.581710815429688e-05 seconds
DEBUG 01-04 15:36:16.395962.395962 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.395056.395056 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0466ab01-e29c-4687-993f-f3d56ed124a4
DEBUG 01-04 15:36:16.395824.395824 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.395709.395709 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.395042.395042 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.399959.399959 cuda_h.py:19] end allocate_cuda_memory cost 0.0043849945068359375 seconds
DEBUG 01-04 15:36:16.400333.400333 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.400063.400063 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.400098.400098 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.400438.400438 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8528d44a-76be-431c-8d69-795608de1f0e
DEBUG 01-04 15:36:16.400786.400786 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.407669.407669 client.py:127] Model loaded
DEBUG 01-04 15:36:16.407195.407195 cuda_h.py:19] end wait_experts cost 0.012252569198608398 seconds
DEBUG 01-04 15:36:16.407613.407613 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.407747.407747 lmp.py:384]   Computing 26 experts on GPU...
DEBUG 01-04 15:36:16.407361.407361 mlpmodule.py:531] gpu group tensors cost 0.0004897117614746094 s
INFO 01-04 15:36:16.408299.408299 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8528d44a-76be-431c-8d69-795608de1f0e
DEBUG 01-04 15:36:16.408771.408771 cuda_h.py:19] end load_into_gpu_async cost 0.008281946182250977 seconds
DEBUG 01-04 15:36:16.408812.408812 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.408479.408479 cuda_h.py:19] end restore_tensors2 cost 0.00011277198791503906 seconds
DEBUG 01-04 15:36:16.408904.408904 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.013095855712890625 seconds
INFO 01-04 15:36:16.409678.409678 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8528d44a-76be-431c-8d69-795608de1f0e
DEBUG 01-04 15:36:16.409412.409412 mlpmodule.py:662]  experts func einsum cost 0.04262375831604004 s
DEBUG 01-04 15:36:16.410711.410711 mlpmodule.py:564] gpu pad cost 0.0024847984313964844 s
DEBUG 01-04 15:36:16.411010.411010 mlpmodule.py:582] gpu group einsum cost 0.0005350112915039062 s
DEBUG 01-04 15:36:16.414493.414493 mlpmodule.py:611] gpu experts func einsum cost 0.006800413131713867 s
DEBUG 01-04 15:36:16.414470.414470 cuda_h.py:19] end gpu_experts cost 0.0069599151611328125 seconds
DEBUG 01-04 15:36:16.414941.414941 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.418684.418684 client.py:127] Model loaded
DEBUG 01-04 15:36:16.419858.419858 cuda_h.py:19] end sllm_worker_task cost 0.02364182472229004 seconds
DEBUG 01-04 15:36:16.419270.419270 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004670143127441406 seconds
DEBUG 01-04 15:36:16.419548.419548 cuda_h.py:19] end layer_moe_generate_10 cost 0.06077122688293457 seconds
DEBUG 01-04 15:36:16.419832.419832 lmp.py:207] -------------------------------- end layer 10 --------------------------------
DEBUG 01-04 15:36:16.419171.419171 lmp.py:169] -------------------------------- start layer 11 --------------------------------
DEBUG 01-04 15:36:16.419390.419390 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.419938.419938 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.422812.422812 cuda_h.py:19] end self_attn cost 0.0029048919677734375 seconds
DEBUG 01-04 15:36:16.423505.423505 cuda_h.py:19] end iln_self_attn_paln cost 0.0035996437072753906 seconds
DEBUG 01-04 15:36:16.423533.423533 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-04 15:36:16.423727.423727 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.423837.423837 cuda_h.py:19] end gate cost 0.0006785392761230469 seconds
DEBUG 01-04 15:36:16.423474.423474 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.424538.424538 lmp.py:281] 
DEBUG 01-04 15:36:16.424538.424538 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.424671.424671 lmp.py:282]   Total experts: 45
DEBUG 01-04 15:36:16.424798.424798 lmp.py:283]   CPU experts: 22 (49%)
DEBUG 01-04 15:36:16.424871.424871 lmp.py:284]   GPU experts: 23 (51%)
DEBUG 01-04 15:36:16.424694.424694 lmp.py:285] 
DEBUG 01-04 15:36:16.424694.424694 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.424483.424483 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.424802.424802 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:16.424113.424113 lmp.py:292]   Expert 46 |      1 | CPU
DEBUG 01-04 15:36:16.424233.424233 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:16.424353.424353 lmp.py:292]   Expert 62 |      1 | CPU
DEBUG 01-04 15:36:16.424758.424758 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:16.424924.424924 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:16.424613.424613 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:16.424541.424541 lmp.py:292]   Expert 20 |      3 | CPU
DEBUG 01-04 15:36:16.424469.424469 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:16.424396.424396 lmp.py:292]   Expert 56 |      3 | CPU
DEBUG 01-04 15:36:16.424324.424324 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:16.424013.424013 lmp.py:292]   Expert 11 |      5 | CPU
DEBUG 01-04 15:36:16.424656.424656 lmp.py:292]   Expert 36 |      5 | CPU
DEBUG 01-04 15:36:16.424822.424822 lmp.py:292]   Expert 48 |      5 | CPU
DEBUG 01-04 15:36:16.424181.424181 lmp.py:292]   Expert 51 |      5 | CPU
DEBUG 01-04 15:36:16.424539.424539 lmp.py:292]   Expert 14 |      6 | CPU
DEBUG 01-04 15:36:16.424659.424659 lmp.py:292]   Expert 18 |      6 | CPU
DEBUG 01-04 15:36:16.424302.424302 lmp.py:292]   Expert 21 |      6 | CPU
DEBUG 01-04 15:36:16.424468.424468 lmp.py:292]   Expert 29 |      6 | CPU
DEBUG 01-04 15:36:16.424395.424395 lmp.py:292]   Expert 58 |      6 | CPU
DEBUG 01-04 15:36:16.424323.424323 lmp.py:292]   Expert 61 |      6 | CPU
DEBUG 01-04 15:36:16.424012.424012 lmp.py:292]   Expert 31 |      7 | CPU
DEBUG 01-04 15:36:16.424179.424179 lmp.py:292]   Expert 37 |      7 | GPU
DEBUG 01-04 15:36:16.424868.424868 lmp.py:292]   Expert 43 |      8 | GPU
DEBUG 01-04 15:36:16.424796.424796 lmp.py:292]   Expert 55 |      8 | GPU
DEBUG 01-04 15:36:16.424723.424723 lmp.py:292]   Expert 12 |      9 | GPU
DEBUG 01-04 15:36:16.424413.424413 lmp.py:292]   Expert 38 |      9 | GPU
DEBUG 01-04 15:36:16.424340.424340 lmp.py:292]   Expert 42 |      9 | GPU
DEBUG 01-04 15:36:16.424699.424699 lmp.py:292]   Expert 33 |     10 | GPU
DEBUG 01-04 15:36:16.424342.424342 lmp.py:292]   Expert 34 |     10 | GPU
DEBUG 01-04 15:36:16.424746.424746 lmp.py:292]   Expert 47 |     10 | GPU
DEBUG 01-04 15:36:16.425151.425151 lmp.py:292]   Expert 13 |     11 | GPU
DEBUG 01-04 15:36:16.425271.425271 lmp.py:292]   Expert 53 |     11 | GPU
DEBUG 01-04 15:36:16.425437.425437 lmp.py:292]   Expert 54 |     13 | GPU
DEBUG 01-04 15:36:16.425364.425364 lmp.py:292]   Expert 45 |     14 | GPU
DEBUG 01-04 15:36:16.425292.425292 lmp.py:292]   Expert 22 |     18 | GPU
DEBUG 01-04 15:36:16.425458.425458 lmp.py:292]   Expert  9 |     26 | GPU
DEBUG 01-04 15:36:16.425148.425148 lmp.py:292]   Expert 30 |     28 | GPU
DEBUG 01-04 15:36:16.425314.425314 lmp.py:292]   Expert 28 |     38 | GPU
DEBUG 01-04 15:36:16.425241.425241 lmp.py:292]   Expert  0 |   1991 | GPU
DEBUG 01-04 15:36:16.425408.425408 lmp.py:292]   Expert  3 |   1991 | GPU
DEBUG 01-04 15:36:16.425335.425335 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:16.425263.425263 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:16.425668.425668 lmp.py:292]   Expert  1 |   1993 | GPU
DEBUG 01-04 15:36:16.425072.425072 lmp.py:292]   Expert  2 |   2005 | GPU
DEBUG 01-04 15:36:16.425430.425430 lmp.py:293] 
DEBUG 01-04 15:36:16.425430.425430 lmp.py:293]   CPU total tokens: 86 (0.7%)
DEBUG 01-04 15:36:16.425504.425504 lmp.py:294]   GPU total tokens: 12202 (99.3%)
DEBUG 01-04 15:36:16.425630.425630 cuda_h.py:19] end experts_map_get cost 0.00128173828125 seconds
DEBUG 01-04 15:36:16.425227.425227 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.425473.425473 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.425662.425662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.425819.425819 cuda_h.py:19] end allocate_cuda_memory cost 0.0002932548522949219 seconds
DEBUG 01-04 15:36:16.425238.425238 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.425041.425041 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.425711.425711 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.425599.425599 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b2719f65-e80f-4e0d-aa43-6c5f620234b5
DEBUG 01-04 15:36:16.426418.426418 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.427801.427801 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b2719f65-e80f-4e0d-aa43-6c5f620234b5
DEBUG 01-04 15:36:16.427213.427213 cuda_h.py:19] end load_into_gpu_async cost 0.0019865036010742188 seconds
DEBUG 01-04 15:36:16.427201.427201 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.428532.428532 cuda_h.py:19] end restore_tensors2 cost 0.00035643577575683594 seconds
DEBUG 01-04 15:36:16.428076.428076 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029494762420654297 seconds
DEBUG 01-04 15:36:16.430592.430592 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005332231521606445 seconds
DEBUG 01-04 15:36:16.430759.430759 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.430298.430298 lmp.py:339] 
DEBUG 01-04 15:36:16.430298.430298 lmp.py:339]   Computing 22 experts on CPU...
DEBUG 01-04 15:36:16.430572.430572 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-04 15:36:16.430057.430057 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.437724.437724 mlpmodule.py:704] group tensors cost 0.0063288211822509766 s
DEBUG 01-04 15:36:16.439481.439481 mlpmodule.py:742] pad cost 0.001722574234008789 s
DEBUG 01-04 15:36:16.439340.439340 mlpmodule.py:748] create cpu tensor cost 5.793571472167969e-05 s
DEBUG 01-04 15:36:16.440046.440046 mlpmodule.py:753] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-04 15:36:16.443215.443215 mlpmodule.py:768] group_w3: shape=torch.Size([22, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=63438848
DEBUG 01-04 15:36:16.443920.443920 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.443015.443015 mlpmodule.py:774] group_w3 first element: -0.05419921875
WARNING 01-04 15:36:16.443667.443667 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.446105.446105 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.447954.447954 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.450861.450861 mlpmodule.py:797] group einsum cost 0.010636091232299805 s
DEBUG 01-04 15:36:16.451492.451492 mlpmodule.py:805] cpy2cputensor cost 0.00011897087097167969 s
DEBUG 01-04 15:36:16.454828.454828 cuda_h.py:19] end wait_cetm_experts cost 0.023589134216308594 seconds
DEBUG 01-04 15:36:16.454289.454289 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.455155.455155 cuda_h.py:19] end gpu_sexperts cost 0.0005214214324951172 seconds
DEBUG 01-04 15:36:16.455959.455959 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-04 15:36:16.455119.455119 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-04 15:36:16.455268.455268 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.552436828613281e-05 seconds
DEBUG 01-04 15:36:16.455507.455507 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.796287536621094e-05 seconds
DEBUG 01-04 15:36:16.455495.455495 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.455065.455065 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b2719f65-e80f-4e0d-aa43-6c5f620234b5
DEBUG 01-04 15:36:16.455442.455442 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.455127.455127 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.455116.455116 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.460026.460026 cuda_h.py:19] end allocate_cuda_memory cost 0.004593610763549805 seconds
DEBUG 01-04 15:36:16.460234.460234 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.460620.460620 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.460641.460641 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.460351.460351 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 91d31d4b-84a0-4885-8c8d-87eccf0aa670
DEBUG 01-04 15:36:16.460871.460871 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.465476.465476 client.py:127] Model loaded
DEBUG 01-04 15:36:16.465770.465770 cuda_h.py:19] end wait_experts cost 0.010350704193115234 seconds
DEBUG 01-04 15:36:16.465433.465433 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.465527.465527 lmp.py:384]   Computing 23 experts on GPU...
DEBUG 01-04 15:36:16.466235.466235 mlpmodule.py:531] gpu group tensors cost 0.0005142688751220703 s
INFO 01-04 15:36:16.466825.466825 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 91d31d4b-84a0-4885-8c8d-87eccf0aa670
DEBUG 01-04 15:36:16.466337.466337 cuda_h.py:19] end load_into_gpu_async cost 0.0061817169189453125 seconds
DEBUG 01-04 15:36:16.466039.466039 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.466407.466407 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-04 15:36:16.466878.466878 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011123418807983398 seconds
INFO 01-04 15:36:16.467658.467658 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 91d31d4b-84a0-4885-8c8d-87eccf0aa670
DEBUG 01-04 15:36:16.468059.468059 mlpmodule.py:564] gpu pad cost 0.0022001266479492188 s
DEBUG 01-04 15:36:16.469284.469284 mlpmodule.py:582] gpu group einsum cost 0.0005209445953369141 s
DEBUG 01-04 15:36:16.469893.469893 mlpmodule.py:662]  experts func einsum cost 0.038495779037475586 s
DEBUG 01-04 15:36:16.472123.472123 mlpmodule.py:611] gpu experts func einsum cost 0.006257295608520508 s
DEBUG 01-04 15:36:16.472782.472782 cuda_h.py:19] end gpu_experts cost 0.0064411163330078125 seconds
DEBUG 01-04 15:36:16.472300.472300 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.477960.477960 client.py:127] Model loaded
DEBUG 01-04 15:36:16.477134.477134 cuda_h.py:19] end sllm_worker_task cost 0.021567583084106445 seconds
DEBUG 01-04 15:36:16.477639.477639 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004949331283569336 seconds
DEBUG 01-04 15:36:16.477578.477578 cuda_h.py:19] end layer_moe_generate_11 cost 0.054319143295288086 seconds
DEBUG 01-04 15:36:16.477802.477802 lmp.py:207] -------------------------------- end layer 11 --------------------------------
DEBUG 01-04 15:36:16.477419.477419 lmp.py:169] -------------------------------- start layer 12 --------------------------------
DEBUG 01-04 15:36:16.477923.477923 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.478650.478650 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.480475.480475 cuda_h.py:19] end self_attn cost 0.002833127975463867 seconds
DEBUG 01-04 15:36:16.481559.481559 cuda_h.py:19] end iln_self_attn_paln cost 0.003527402877807617 seconds
DEBUG 01-04 15:36:16.481780.481780 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-04 15:36:16.481450.481450 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.482983.482983 cuda_h.py:19] end gate cost 0.0006723403930664062 seconds
DEBUG 01-04 15:36:16.482528.482528 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.482978.482978 lmp.py:281] 
DEBUG 01-04 15:36:16.482978.482978 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.482541.482541 lmp.py:282]   Total experts: 49
DEBUG 01-04 15:36:16.482906.482906 lmp.py:283]   CPU experts: 24 (49%)
DEBUG 01-04 15:36:16.482457.482457 lmp.py:284]   GPU experts: 25 (51%)
DEBUG 01-04 15:36:16.482861.482861 lmp.py:285] 
DEBUG 01-04 15:36:16.482861.482861 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.482743.482743 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.482393.482393 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:16.482274.482274 lmp.py:292]   Expert 16 |      1 | CPU
DEBUG 01-04 15:36:16.482963.482963 lmp.py:292]   Expert 53 |      1 | CPU
DEBUG 01-04 15:36:16.482653.482653 lmp.py:292]   Expert 61 |      1 | CPU
DEBUG 01-04 15:36:16.482342.482342 lmp.py:292]   Expert 14 |      2 | CPU
DEBUG 01-04 15:36:16.482554.482554 lmp.py:292]   Expert 18 |      2 | CPU
DEBUG 01-04 15:36:16.482767.482767 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:16.482979.482979 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:16.482192.482192 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:16.482119.482119 lmp.py:292]   Expert  7 |      3 | CPU
DEBUG 01-04 15:36:16.482570.482570 lmp.py:292]   Expert 21 |      3 | CPU
DEBUG 01-04 15:36:16.482783.482783 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:16.482995.482995 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:16.482208.482208 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:16.482612.482612 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:16.482017.482017 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:16.482421.482421 lmp.py:292]   Expert 46 |      4 | CPU
DEBUG 01-04 15:36:16.482349.482349 lmp.py:292]   Expert 33 |      5 | CPU
DEBUG 01-04 15:36:16.482562.482562 lmp.py:292]   Expert  6 |      6 | CPU
DEBUG 01-04 15:36:16.482536.482536 lmp.py:292]   Expert  8 |      6 | CPU
DEBUG 01-04 15:36:16.482986.482986 lmp.py:292]   Expert 19 |      6 | CPU
DEBUG 01-04 15:36:16.483199.483199 lmp.py:292]   Expert 20 |      6 | CPU
DEBUG 01-04 15:36:16.483173.483173 lmp.py:292]   Expert 38 |      6 | CPU
DEBUG 01-04 15:36:16.483385.483385 lmp.py:292]   Expert 17 |      7 | CPU
DEBUG 01-04 15:36:16.483836.483836 lmp.py:292]   Expert 25 |      7 | GPU
DEBUG 01-04 15:36:16.483810.483810 lmp.py:292]   Expert 35 |      7 | GPU
DEBUG 01-04 15:36:16.483023.483023 lmp.py:292]   Expert 52 |      7 | GPU
DEBUG 01-04 15:36:16.483235.483235 lmp.py:292]   Expert 36 |      8 | GPU
DEBUG 01-04 15:36:16.483209.483209 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:16.483375.483375 lmp.py:292]   Expert 58 |      8 | GPU
DEBUG 01-04 15:36:16.483303.483303 lmp.py:292]   Expert 59 |      8 | GPU
DEBUG 01-04 15:36:16.483992.483992 lmp.py:292]   Expert 13 |      9 | GPU
DEBUG 01-04 15:36:16.483920.483920 lmp.py:292]   Expert 26 |     10 | GPU
DEBUG 01-04 15:36:16.483371.483371 lmp.py:292]   Expert 28 |     10 | GPU
DEBUG 01-04 15:36:16.483822.483822 lmp.py:292]   Expert 57 |     10 | GPU
DEBUG 01-04 15:36:16.483034.483034 lmp.py:292]   Expert 24 |     12 | GPU
DEBUG 01-04 15:36:16.483008.483008 lmp.py:292]   Expert 15 |     15 | GPU
DEBUG 01-04 15:36:16.483221.483221 lmp.py:292]   Expert 60 |     15 | GPU
DEBUG 01-04 15:36:16.483433.483433 lmp.py:292]   Expert 40 |     16 | GPU
DEBUG 01-04 15:36:16.483169.483169 lmp.py:292]   Expert 48 |     16 | GPU
DEBUG 01-04 15:36:16.483381.483381 lmp.py:292]   Expert  9 |     19 | GPU
DEBUG 01-04 15:36:16.483356.483356 lmp.py:292]   Expert 56 |     26 | GPU
DEBUG 01-04 15:36:16.483330.483330 lmp.py:292]   Expert 10 |     34 | GPU
DEBUG 01-04 15:36:16.483304.483304 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:16.483278.483278 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:16.483205.483205 lmp.py:292]   Expert  0 |   1993 | GPU
DEBUG 01-04 15:36:16.483133.483133 lmp.py:292]   Expert  3 |   1993 | GPU
DEBUG 01-04 15:36:16.483299.483299 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:16.483465.483465 lmp.py:292]   Expert  1 |   1997 | GPU
DEBUG 01-04 15:36:16.483393.483393 lmp.py:293] 
DEBUG 01-04 15:36:16.483393.483393 lmp.py:293]   CPU total tokens: 82 (0.7%)
DEBUG 01-04 15:36:16.483559.483559 lmp.py:294]   GPU total tokens: 12206 (99.3%)
DEBUG 01-04 15:36:16.483255.483255 cuda_h.py:19] end experts_map_get cost 0.0013151168823242188 seconds
DEBUG 01-04 15:36:16.483660.483660 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.483383.483383 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.483049.483049 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.483172.483172 cuda_h.py:19] end allocate_cuda_memory cost 0.0002696514129638672 seconds
DEBUG 01-04 15:36:16.484637.484637 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.484963.484963 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.484633.484633 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.484998.484998 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb047f15-860d-42a2-8f42-77bc98767beb
DEBUG 01-04 15:36:16.484447.484447 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.486089.486089 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb047f15-860d-42a2-8f42-77bc98767beb
DEBUG 01-04 15:36:16.486448.486448 cuda_h.py:19] end load_into_gpu_async cost 0.0020415782928466797 seconds
DEBUG 01-04 15:36:16.486913.486913 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.486019.486019 cuda_h.py:19] end restore_tensors2 cost 0.0003669261932373047 seconds
DEBUG 01-04 15:36:16.486179.486179 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029888153076171875 seconds
DEBUG 01-04 15:36:16.488531.488531 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0054247379302978516 seconds
DEBUG 01-04 15:36:16.489175.489175 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.489437.489437 lmp.py:339] 
DEBUG 01-04 15:36:16.489437.489437 lmp.py:339]   Computing 24 experts on CPU...
DEBUG 01-04 15:36:16.489372.489372 cuda_h.py:19] end cpu_experts_submit cost 0.00011444091796875 seconds
DEBUG 01-04 15:36:16.489645.489645 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.499357.499357 mlpmodule.py:704] group tensors cost 0.010652542114257812 s
DEBUG 01-04 15:36:16.502696.502696 mlpmodule.py:742] pad cost 0.0014553070068359375 s
DEBUG 01-04 15:36:16.502137.502137 mlpmodule.py:748] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-04 15:36:16.502053.502053 mlpmodule.py:753] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-04 15:36:16.506097.506097 mlpmodule.py:768] group_w3: shape=torch.Size([24, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=69206016
DEBUG 01-04 15:36:16.506855.506855 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.506533.506533 mlpmodule.py:774] group_w3 first element: 0.0576171875
WARNING 01-04 15:36:16.506868.506868 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.509234.509234 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.509652.509652 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.513461.513461 mlpmodule.py:797] group einsum cost 0.01132655143737793 s
DEBUG 01-04 15:36:16.514874.514874 mlpmodule.py:805] cpy2cputensor cost 0.00011730194091796875 s
DEBUG 01-04 15:36:16.517186.517186 cuda_h.py:19] end wait_cetm_experts cost 0.028580665588378906 seconds
DEBUG 01-04 15:36:16.517984.517984 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.518274.518274 cuda_h.py:19] end gpu_sexperts cost 0.0005176067352294922 seconds
DEBUG 01-04 15:36:16.518078.518078 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-04 15:36:16.518477.518477 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-04 15:36:16.518340.518340 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.504753112792969e-05 seconds
DEBUG 01-04 15:36:16.518772.518772 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 8.0108642578125e-05 seconds
DEBUG 01-04 15:36:16.518760.518760 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.518330.518330 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb047f15-860d-42a2-8f42-77bc98767beb
DEBUG 01-04 15:36:16.518853.518853 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.519253.519253 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.519573.519573 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.526725.526725 cuda_h.py:19] end allocate_cuda_memory cost 0.007269382476806641 seconds
DEBUG 01-04 15:36:16.526257.526257 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.526451.526451 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.526326.526326 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.526321.526321 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 14b0ae4e-45bc-4230-b308-4746095f4047
DEBUG 01-04 15:36:16.526933.526933 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.527430.527430 client.py:127] Model loaded
DEBUG 01-04 15:36:16.527048.527048 cuda_h.py:19] end wait_experts cost 0.009167909622192383 seconds
DEBUG 01-04 15:36:16.527758.527758 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.528136.528136 lmp.py:384]   Computing 25 experts on GPU...
DEBUG 01-04 15:36:16.528403.528403 mlpmodule.py:531] gpu group tensors cost 0.0005729198455810547 s
INFO 01-04 15:36:16.528988.528988 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 14b0ae4e-45bc-4230-b308-4746095f4047
DEBUG 01-04 15:36:16.528493.528493 cuda_h.py:19] end load_into_gpu_async cost 0.002454519271850586 seconds
DEBUG 01-04 15:36:16.529812.529812 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.529179.529179 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-04 15:36:16.529458.529458 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010055303573608398 seconds
INFO 01-04 15:36:16.529720.529720 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 14b0ae4e-45bc-4230-b308-4746095f4047
DEBUG 01-04 15:36:16.531528.531528 mlpmodule.py:564] gpu pad cost 0.002283811569213867 s
DEBUG 01-04 15:36:16.531621.531621 mlpmodule.py:582] gpu group einsum cost 0.0005297660827636719 s
DEBUG 01-04 15:36:16.534791.534791 mlpmodule.py:611] gpu experts func einsum cost 0.00661468505859375 s
DEBUG 01-04 15:36:16.534483.534483 cuda_h.py:19] end gpu_experts cost 0.006788969039916992 seconds
DEBUG 01-04 15:36:16.534908.534908 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:16.538999.538999 mlpmodule.py:662]  experts func einsum cost 0.04962635040283203 s
INFO 01-04 15:36:16.539062.539062 client.py:127] Model loaded
DEBUG 01-04 15:36:16.539667.539667 cuda_h.py:19] end sllm_worker_task cost 0.020462512969970703 seconds
DEBUG 01-04 15:36:16.539179.539179 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00469660758972168 seconds
DEBUG 01-04 15:36:16.539548.539548 cuda_h.py:19] end layer_moe_generate_12 cost 0.05832839012145996 seconds
DEBUG 01-04 15:36:16.539885.539885 lmp.py:207] -------------------------------- end layer 12 --------------------------------
DEBUG 01-04 15:36:16.539887.539887 lmp.py:169] -------------------------------- start layer 13 --------------------------------
DEBUG 01-04 15:36:16.539060.539060 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.540607.540607 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.543229.543229 cuda_h.py:19] end self_attn cost 0.0028939247131347656 seconds
DEBUG 01-04 15:36:16.543624.543624 cuda_h.py:19] end iln_self_attn_paln cost 0.003579378128051758 seconds
DEBUG 01-04 15:36:16.543653.543653 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-04 15:36:16.543846.543846 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.544512.544512 cuda_h.py:19] end gate cost 0.0006661415100097656 seconds
DEBUG 01-04 15:36:16.544614.544614 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.544303.544303 lmp.py:281] 
DEBUG 01-04 15:36:16.544303.544303 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.544343.544343 lmp.py:282]   Total experts: 54
DEBUG 01-04 15:36:16.544947.544947 lmp.py:283]   CPU experts: 27 (50%)
DEBUG 01-04 15:36:16.544451.544451 lmp.py:284]   GPU experts: 27 (50%)
DEBUG 01-04 15:36:16.544047.544047 lmp.py:285] 
DEBUG 01-04 15:36:16.544047.544047 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.544598.544598 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.544678.544678 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:16.545513.545513 lmp.py:292]   Expert 16 |      1 | CPU
DEBUG 01-04 15:36:16.545918.545918 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:16.545561.545561 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:16.545442.545442 lmp.py:292]   Expert 26 |      1 | CPU
DEBUG 01-04 15:36:16.545370.545370 lmp.py:292]   Expert 28 |      1 | CPU
DEBUG 01-04 15:36:16.545774.545774 lmp.py:292]   Expert 35 |      1 | CPU
DEBUG 01-04 15:36:16.545940.545940 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:16.545345.545345 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:16.545511.545511 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:16.545439.545439 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:16.545843.545843 lmp.py:292]   Expert 58 |      1 | CPU
DEBUG 01-04 15:36:16.545963.545963 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:16.545321.545321 lmp.py:292]   Expert 39 |      2 | CPU
DEBUG 01-04 15:36:16.545203.545203 lmp.py:292]   Expert 61 |      2 | CPU
DEBUG 01-04 15:36:16.545084.545084 lmp.py:292]   Expert 63 |      2 | CPU
DEBUG 01-04 15:36:16.545489.545489 lmp.py:292]   Expert 11 |      3 | CPU
DEBUG 01-04 15:36:16.545655.545655 lmp.py:292]   Expert 17 |      3 | CPU
DEBUG 01-04 15:36:16.545059.545059 lmp.py:292]   Expert 22 |      3 | CPU
DEBUG 01-04 15:36:16.545226.545226 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:16.545630.545630 lmp.py:292]   Expert 37 |      3 | CPU
DEBUG 01-04 15:36:16.545558.545558 lmp.py:292]   Expert 56 |      3 | CPU
DEBUG 01-04 15:36:16.545724.545724 lmp.py:292]   Expert  9 |      4 | CPU
DEBUG 01-04 15:36:16.545890.545890 lmp.py:292]   Expert 15 |      4 | CPU
DEBUG 01-04 15:36:16.545056.545056 lmp.py:292]   Expert 62 |      4 | CPU
DEBUG 01-04 15:36:16.545222.545222 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:16.545865.545865 lmp.py:292]   Expert 32 |      5 | CPU
DEBUG 01-04 15:36:16.545985.545985 lmp.py:292]   Expert 27 |      6 | GPU
DEBUG 01-04 15:36:16.545105.545105 lmp.py:292]   Expert 36 |      6 | GPU
DEBUG 01-04 15:36:16.545986.545986 lmp.py:292]   Expert 55 |      6 | GPU
DEBUG 01-04 15:36:16.545153.545153 lmp.py:292]   Expert 54 |      7 | GPU
DEBUG 01-04 15:36:16.545557.545557 lmp.py:292]   Expert 29 |      8 | GPU
DEBUG 01-04 15:36:16.545246.545246 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:16.545413.545413 lmp.py:292]   Expert 43 |      9 | GPU
DEBUG 01-04 15:36:16.545340.545340 lmp.py:292]   Expert 33 |     10 | GPU
DEBUG 01-04 15:36:16.545235.545235 lmp.py:292]   Expert 10 |     11 | GPU
DEBUG 01-04 15:36:16.545686.545686 lmp.py:292]   Expert 13 |     11 | GPU
DEBUG 01-04 15:36:16.545422.545422 lmp.py:292]   Expert 23 |     11 | GPU
DEBUG 01-04 15:36:16.545634.545634 lmp.py:292]   Expert 44 |     11 | GPU
DEBUG 01-04 15:36:16.545370.545370 lmp.py:292]   Expert 42 |     13 | GPU
DEBUG 01-04 15:36:16.545582.545582 lmp.py:292]   Expert 49 |     13 | GPU
DEBUG 01-04 15:36:16.545748.545748 lmp.py:292]   Expert 21 |     14 | GPU
DEBUG 01-04 15:36:16.545676.545676 lmp.py:292]   Expert 14 |     15 | GPU
DEBUG 01-04 15:36:16.545842.545842 lmp.py:292]   Expert 46 |     15 | GPU
DEBUG 01-04 15:36:16.545532.545532 lmp.py:292]   Expert 47 |     16 | GPU
DEBUG 01-04 15:36:16.545221.545221 lmp.py:292]   Expert 59 |     19 | GPU
DEBUG 01-04 15:36:16.545433.545433 lmp.py:292]   Expert 38 |     23 | GPU
DEBUG 01-04 15:36:16.545407.545407 lmp.py:292]   Expert 41 |     25 | GPU
DEBUG 01-04 15:36:16.545858.545858 lmp.py:292]   Expert  0 |   1991 | GPU
DEBUG 01-04 15:36:16.545071.545071 lmp.py:292]   Expert  2 |   1991 | GPU
DEBUG 01-04 15:36:16.545283.545283 lmp.py:292]   Expert  3 |   1993 | GPU
DEBUG 01-04 15:36:16.545734.545734 lmp.py:292]   Expert  1 |   1995 | GPU
DEBUG 01-04 15:36:16.545947.545947 lmp.py:292]   Expert  5 |   2000 | GPU
DEBUG 01-04 15:36:16.545159.545159 lmp.py:292]   Expert  4 |   2002 | GPU
DEBUG 01-04 15:36:16.545087.545087 lmp.py:293] 
DEBUG 01-04 15:36:16.545087.545087 lmp.py:293]   CPU total tokens: 59 (0.5%)
DEBUG 01-04 15:36:16.545968.545968 lmp.py:294]   GPU total tokens: 12229 (99.5%)
DEBUG 01-04 15:36:16.545141.545141 cuda_h.py:19] end experts_map_get cost 0.0014834403991699219 seconds
DEBUG 01-04 15:36:16.545499.545499 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.546368.546368 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.546048.546048 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.546091.546091 cuda_h.py:19] end allocate_cuda_memory cost 0.0002808570861816406 seconds
DEBUG 01-04 15:36:16.546034.546034 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.546598.546598 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.546268.546268 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.546871.546871 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26ed2830-43f5-4168-93b6-fb2489d18ae0
DEBUG 01-04 15:36:16.546678.546678 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.548241.548241 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26ed2830-43f5-4168-93b6-fb2489d18ae0
DEBUG 01-04 15:36:16.548270.548270 cuda_h.py:19] end load_into_gpu_async cost 0.002074003219604492 seconds
DEBUG 01-04 15:36:16.548827.548827 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.549723.549723 cuda_h.py:19] end restore_tensors2 cost 0.0004057884216308594 seconds
DEBUG 01-04 15:36:16.549698.549698 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030994415283203125 seconds
DEBUG 01-04 15:36:16.551183.551183 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005739688873291016 seconds
DEBUG 01-04 15:36:16.551820.551820 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.551433.551433 lmp.py:339] 
DEBUG 01-04 15:36:16.551433.551433 lmp.py:339]   Computing 27 experts on CPU...
DEBUG 01-04 15:36:16.551653.551653 cuda_h.py:19] end cpu_experts_submit cost 0.00011348724365234375 seconds
DEBUG 01-04 15:36:16.551257.551257 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.557638.557638 mlpmodule.py:704] group tensors cost 0.004929780960083008 s
DEBUG 01-04 15:36:16.559212.559212 mlpmodule.py:742] pad cost 0.001504659652709961 s
DEBUG 01-04 15:36:16.559361.559361 mlpmodule.py:748] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-04 15:36:16.559986.559986 mlpmodule.py:753] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-04 15:36:16.563791.563791 mlpmodule.py:768] group_w3: shape=torch.Size([27, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=77856768
DEBUG 01-04 15:36:16.563033.563033 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.563924.563924 mlpmodule.py:774] group_w3 first element: 0.00183868408203125
WARNING 01-04 15:36:16.563166.563166 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.567808.567808 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.567373.567373 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.571917.571917 mlpmodule.py:797] group einsum cost 0.012093782424926758 s
DEBUG 01-04 15:36:16.571700.571700 mlpmodule.py:805] cpy2cputensor cost 8.988380432128906e-05 s
DEBUG 01-04 15:36:16.575702.575702 cuda_h.py:19] end wait_cetm_experts cost 0.023945093154907227 seconds
DEBUG 01-04 15:36:16.576507.576507 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.576600.576600 cuda_h.py:19] end gpu_sexperts cost 0.0005486011505126953 seconds
DEBUG 01-04 15:36:16.576734.576734 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-04 15:36:16.576418.576418 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-04 15:36:16.576752.576752 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.4809112548828125e-05 seconds
DEBUG 01-04 15:36:16.576164.576164 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.576855.576855 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.0001461505889892578 seconds
DEBUG 01-04 15:36:16.577632.577632 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.577376.577376 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.577526.577526 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26ed2830-43f5-4168-93b6-fb2489d18ae0
DEBUG 01-04 15:36:16.577630.577630 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.584339.584339 cuda_h.py:19] end allocate_cuda_memory cost 0.007249355316162109 seconds
DEBUG 01-04 15:36:16.584355.584355 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.584263.584263 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.584616.584616 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.584372.584372 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc5e56ab-6f2e-47e1-81d7-f25dd908bbf8
DEBUG 01-04 15:36:16.584269.584269 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.593063.593063 client.py:127] Model loaded
DEBUG 01-04 15:36:16.593059.593059 cuda_h.py:19] end wait_experts cost 0.016690492630004883 seconds
DEBUG 01-04 15:36:16.593477.593477 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.593902.593902 lmp.py:384]   Computing 27 experts on GPU...
DEBUG 01-04 15:36:16.594802.594802 mlpmodule.py:531] gpu group tensors cost 0.0005016326904296875 s
INFO 01-04 15:36:16.594438.594438 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc5e56ab-6f2e-47e1-81d7-f25dd908bbf8
DEBUG 01-04 15:36:16.594519.594519 cuda_h.py:19] end load_into_gpu_async cost 0.010021686553955078 seconds
DEBUG 01-04 15:36:16.594984.594984 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.594444.594444 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-04 15:36:16.594961.594961 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.017830848693847656 seconds
INFO 01-04 15:36:16.595700.595700 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc5e56ab-6f2e-47e1-81d7-f25dd908bbf8
DEBUG 01-04 15:36:16.597638.597638 mlpmodule.py:564] gpu pad cost 0.002736806869506836 s
DEBUG 01-04 15:36:16.597867.597867 mlpmodule.py:662]  experts func einsum cost 0.04581141471862793 s
DEBUG 01-04 15:36:16.598930.598930 mlpmodule.py:582] gpu group einsum cost 0.0007319450378417969 s
DEBUG 01-04 15:36:16.602304.602304 mlpmodule.py:611] gpu experts func einsum cost 0.008346319198608398 s
DEBUG 01-04 15:36:16.602976.602976 cuda_h.py:19] end gpu_experts cost 0.008550882339477539 seconds
DEBUG 01-04 15:36:16.602461.602461 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.605274.605274 client.py:127] Model loaded
DEBUG 01-04 15:36:16.605581.605581 cuda_h.py:19] end sllm_worker_task cost 0.028931856155395508 seconds
DEBUG 01-04 15:36:16.606326.606326 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.003427267074584961 seconds
DEBUG 01-04 15:36:16.606656.606656 cuda_h.py:19] end layer_moe_generate_13 cost 0.06257486343383789 seconds
DEBUG 01-04 15:36:16.606093.606093 lmp.py:207] -------------------------------- end layer 13 --------------------------------
DEBUG 01-04 15:36:16.606054.606054 lmp.py:169] -------------------------------- start layer 14 --------------------------------
DEBUG 01-04 15:36:16.606512.606512 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.606265.606265 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.609082.609082 cuda_h.py:19] end self_attn cost 0.0029671192169189453 seconds
DEBUG 01-04 15:36:16.610994.610994 cuda_h.py:19] end iln_self_attn_paln cost 0.003693103790283203 seconds
DEBUG 01-04 15:36:16.610884.610884 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-04 15:36:16.610554.610554 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.611479.611479 cuda_h.py:19] end gate cost 0.0006804466247558594 seconds
DEBUG 01-04 15:36:16.611500.611500 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.611644.611644 lmp.py:281] 
DEBUG 01-04 15:36:16.611644.611644 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.611208.611208 lmp.py:282]   Total experts: 46
DEBUG 01-04 15:36:16.611527.611527 lmp.py:283]   CPU experts: 23 (50%)
DEBUG 01-04 15:36:16.611508.611508 lmp.py:284]   GPU experts: 23 (50%)
DEBUG 01-04 15:36:16.611866.611866 lmp.py:285] 
DEBUG 01-04 15:36:16.611866.611866 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.611224.611224 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.611828.611828 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:16.611424.611424 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:16.611544.611544 lmp.py:292]   Expert 42 |      1 | CPU
DEBUG 01-04 15:36:16.611949.611949 lmp.py:292]   Expert 19 |      2 | CPU
DEBUG 01-04 15:36:16.611592.611592 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:16.611996.611996 lmp.py:292]   Expert 32 |      2 | CPU
DEBUG 01-04 15:36:16.611163.611163 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:16.611567.611567 lmp.py:292]   Expert 12 |      3 | CPU
DEBUG 01-04 15:36:16.611972.611972 lmp.py:292]   Expert 28 |      3 | CPU
DEBUG 01-04 15:36:16.611376.611376 lmp.py:292]   Expert 54 |      3 | CPU
DEBUG 01-04 15:36:16.611973.611973 lmp.py:292]   Expert 13 |      4 | CPU
DEBUG 01-04 15:36:16.611331.611331 lmp.py:292]   Expert 46 |      4 | CPU
DEBUG 01-04 15:36:16.611974.611974 lmp.py:292]   Expert 60 |      4 | CPU
DEBUG 01-04 15:36:16.611140.611140 lmp.py:292]   Expert  6 |      5 | CPU
DEBUG 01-04 15:36:16.611783.611783 lmp.py:292]   Expert 17 |      5 | CPU
DEBUG 01-04 15:36:16.611949.611949 lmp.py:292]   Expert 30 |      5 | CPU
DEBUG 01-04 15:36:16.611115.611115 lmp.py:292]   Expert 39 |      5 | CPU
DEBUG 01-04 15:36:16.611282.611282 lmp.py:292]   Expert 34 |      6 | CPU
DEBUG 01-04 15:36:16.611209.611209 lmp.py:292]   Expert 35 |      6 | CPU
DEBUG 01-04 15:36:16.611375.611375 lmp.py:292]   Expert 36 |      6 | CPU
DEBUG 01-04 15:36:16.611734.611734 lmp.py:292]   Expert 37 |      6 | CPU
DEBUG 01-04 15:36:16.611330.611330 lmp.py:292]   Expert 52 |      6 | CPU
DEBUG 01-04 15:36:16.611496.611496 lmp.py:292]   Expert 57 |      6 | CPU
DEBUG 01-04 15:36:16.611186.611186 lmp.py:292]   Expert 21 |      7 | GPU
DEBUG 01-04 15:36:16.611352.611352 lmp.py:292]   Expert 16 |      8 | GPU
DEBUG 01-04 15:36:16.612518.612518 lmp.py:292]   Expert 22 |      8 | GPU
DEBUG 01-04 15:36:16.612684.612684 lmp.py:292]   Expert 31 |      8 | GPU
DEBUG 01-04 15:36:16.612850.612850 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:16.612778.612778 lmp.py:292]   Expert 11 |      9 | GPU
DEBUG 01-04 15:36:16.612349.612349 lmp.py:292]   Expert 27 |     10 | GPU
DEBUG 01-04 15:36:16.612753.612753 lmp.py:292]   Expert 47 |     10 | GPU
DEBUG 01-04 15:36:16.612827.612827 lmp.py:292]   Expert 24 |     11 | GPU
DEBUG 01-04 15:36:16.612470.612470 lmp.py:292]   Expert 33 |     12 | GPU
DEBUG 01-04 15:36:16.612113.612113 lmp.py:292]   Expert 56 |     12 | GPU
DEBUG 01-04 15:36:16.612756.612756 lmp.py:292]   Expert  9 |     13 | GPU
DEBUG 01-04 15:36:16.612160.612160 lmp.py:292]   Expert 10 |     13 | GPU
DEBUG 01-04 15:36:16.612803.612803 lmp.py:292]   Expert 58 |     14 | GPU
DEBUG 01-04 15:36:16.612969.612969 lmp.py:292]   Expert 53 |     19 | GPU
DEBUG 01-04 15:36:16.612612.612612 lmp.py:292]   Expert 63 |     19 | GPU
DEBUG 01-04 15:36:16.612017.612017 lmp.py:292]   Expert 25 |     23 | GPU
DEBUG 01-04 15:36:16.612567.612567 lmp.py:292]   Expert  0 |   1992 | GPU
DEBUG 01-04 15:36:16.612164.612164 lmp.py:292]   Expert  3 |   1994 | GPU
DEBUG 01-04 15:36:16.612045.612045 lmp.py:292]   Expert  2 |   1999 | GPU
DEBUG 01-04 15:36:16.612450.612450 lmp.py:292]   Expert  1 |   2002 | GPU
DEBUG 01-04 15:36:16.612093.612093 lmp.py:292]   Expert  4 |   2004 | GPU
DEBUG 01-04 15:36:16.612736.612736 lmp.py:292]   Expert  5 |   2005 | GPU
DEBUG 01-04 15:36:16.616855.616855 lmp.py:293] 
DEBUG 01-04 15:36:16.616855.616855 lmp.py:293]   CPU total tokens: 88 (0.7%)
DEBUG 01-04 15:36:16.616293.616293 lmp.py:294]   GPU total tokens: 12200 (99.3%)
DEBUG 01-04 15:36:16.616957.616957 cuda_h.py:19] end experts_map_get cost 0.005292177200317383 seconds
DEBUG 01-04 15:36:16.616865.616865 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.616264.616264 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.616501.616501 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.616770.616770 cuda_h.py:19] end allocate_cuda_memory cost 0.00030303001403808594 seconds
DEBUG 01-04 15:36:16.617481.617481 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.617714.617714 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.617053.617053 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.617133.617133 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ca8c3ac-96fe-42b8-96b0-ee0e94e883c4
DEBUG 01-04 15:36:16.617292.617292 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.619103.619103 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ca8c3ac-96fe-42b8-96b0-ee0e94e883c4
DEBUG 01-04 15:36:16.619701.619701 cuda_h.py:19] end load_into_gpu_async cost 0.001991748809814453 seconds
DEBUG 01-04 15:36:16.619974.619974 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.619345.619345 cuda_h.py:19] end restore_tensors2 cost 0.0003802776336669922 seconds
DEBUG 01-04 15:36:16.619871.619871 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003049135208129883 seconds
DEBUG 01-04 15:36:16.621095.621095 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005441904067993164 seconds
DEBUG 01-04 15:36:16.621778.621778 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.622643.622643 lmp.py:339] 
DEBUG 01-04 15:36:16.622643.622643 lmp.py:339]   Computing 23 experts on CPU...
DEBUG 01-04 15:36:16.622870.622870 cuda_h.py:19] end cpu_experts_submit cost 0.00012755393981933594 seconds
DEBUG 01-04 15:36:16.622594.622594 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.628618.628618 mlpmodule.py:704] group tensors cost 0.006497859954833984 s
DEBUG 01-04 15:36:16.631443.631443 mlpmodule.py:742] pad cost 0.0018627643585205078 s
DEBUG 01-04 15:36:16.631454.631454 mlpmodule.py:748] create cpu tensor cost 6.151199340820312e-05 s
DEBUG 01-04 15:36:16.631259.631259 mlpmodule.py:753] move to cpu cost 4.172325134277344e-05 s
DEBUG 01-04 15:36:16.635305.635305 mlpmodule.py:768] group_w3: shape=torch.Size([23, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=66322432
DEBUG 01-04 15:36:16.635985.635985 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.635028.635028 mlpmodule.py:774] group_w3 first element: 0.064453125
WARNING 01-04 15:36:16.635927.635927 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.638096.638096 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.638508.638508 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.641033.641033 mlpmodule.py:797] group einsum cost 0.009583234786987305 s
DEBUG 01-04 15:36:16.641902.641902 mlpmodule.py:805] cpy2cputensor cost 0.00011491775512695312 s
DEBUG 01-04 15:36:16.645615.645615 cuda_h.py:19] end wait_cetm_experts cost 0.02313709259033203 seconds
DEBUG 01-04 15:36:16.645334.645334 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.646350.646350 cuda_h.py:19] end gpu_sexperts cost 0.0006198883056640625 seconds
DEBUG 01-04 15:36:16.646737.646737 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-04 15:36:16.646911.646911 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-04 15:36:16.646603.646603 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.886222839355469e-05 seconds
DEBUG 01-04 15:36:16.646202.646202 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.646470.646470 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.0002243518829345703 seconds
DEBUG 01-04 15:36:16.646349.646349 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.646418.646418 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.646616.646616 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ca8c3ac-96fe-42b8-96b0-ee0e94e883c4
DEBUG 01-04 15:36:16.646528.646528 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.650431.650431 cuda_h.py:19] end allocate_cuda_memory cost 0.003773927688598633 seconds
DEBUG 01-04 15:36:16.651885.651885 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.651846.651846 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.651967.651967 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.651061.651061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 04f50988-19a8-4221-ba5f-562c8d6f497b
DEBUG 01-04 15:36:16.651065.651065 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.657250.657250 client.py:127] Model loaded
DEBUG 01-04 15:36:16.657861.657861 cuda_h.py:19] end wait_experts cost 0.010684967041015625 seconds
DEBUG 01-04 15:36:16.657995.657995 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.657843.657843 lmp.py:384]   Computing 23 experts on GPU...
INFO 01-04 15:36:16.658141.658141 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 04f50988-19a8-4221-ba5f-562c8d6f497b
DEBUG 01-04 15:36:16.658621.658621 cuda_h.py:19] end load_into_gpu_async cost 0.007101297378540039 seconds
DEBUG 01-04 15:36:16.658853.658853 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.658672.658672 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-04 15:36:16.658242.658242 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01147770881652832 seconds
DEBUG 01-04 15:36:16.658760.658760 mlpmodule.py:531] gpu group tensors cost 0.0009839534759521484 s
INFO 01-04 15:36:16.659008.659008 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 04f50988-19a8-4221-ba5f-562c8d6f497b
DEBUG 01-04 15:36:16.659780.659780 mlpmodule.py:662]  experts func einsum cost 0.03708195686340332 s
DEBUG 01-04 15:36:16.660133.660133 mlpmodule.py:564] gpu pad cost 0.0017247200012207031 s
DEBUG 01-04 15:36:16.661102.661102 mlpmodule.py:582] gpu group einsum cost 0.0004010200500488281 s
DEBUG 01-04 15:36:16.663259.663259 mlpmodule.py:611] gpu experts func einsum cost 0.006025075912475586 s
DEBUG 01-04 15:36:16.663594.663594 cuda_h.py:19] end gpu_experts cost 0.006207704544067383 seconds
DEBUG 01-04 15:36:16.663112.663112 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.668966.668966 client.py:127] Model loaded
DEBUG 01-04 15:36:16.669481.669481 cuda_h.py:19] end sllm_worker_task cost 0.022331714630126953 seconds
DEBUG 01-04 15:36:16.669215.669215 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005219221115112305 seconds
DEBUG 01-04 15:36:16.669497.669497 cuda_h.py:19] end layer_moe_generate_14 cost 0.05922102928161621 seconds
DEBUG 01-04 15:36:16.669540.669540 lmp.py:207] -------------------------------- end layer 14 --------------------------------
DEBUG 01-04 15:36:16.669681.669681 lmp.py:169] -------------------------------- start layer 15 --------------------------------
DEBUG 01-04 15:36:16.669365.669365 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.670456.670456 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.675850.675850 cuda_h.py:19] end self_attn cost 0.004933357238769531 seconds
DEBUG 01-04 15:36:16.676401.676401 cuda_h.py:19] end iln_self_attn_paln cost 0.00614476203918457 seconds
DEBUG 01-04 15:36:16.676205.676205 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-04 15:36:16.676830.676830 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.677947.677947 cuda_h.py:19] end gate cost 0.0010421276092529297 seconds
DEBUG 01-04 15:36:16.677128.677128 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.677950.677950 lmp.py:281] 
DEBUG 01-04 15:36:16.677950.677950 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.677713.677713 lmp.py:282]   Total experts: 49
DEBUG 01-04 15:36:16.677608.677608 lmp.py:283]   CPU experts: 24 (49%)
DEBUG 01-04 15:36:16.678165.678165 lmp.py:284]   GPU experts: 25 (51%)
DEBUG 01-04 15:36:16.678053.678053 lmp.py:285] 
DEBUG 01-04 15:36:16.678053.678053 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.678941.678941 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.678836.678836 lmp.py:292]   Expert 16 |      1 | CPU
DEBUG 01-04 15:36:16.678248.678248 lmp.py:292]   Expert 41 |      1 | CPU
DEBUG 01-04 15:36:16.678228.678228 lmp.py:292]   Expert 56 |      1 | CPU
DEBUG 01-04 15:36:16.678971.678971 lmp.py:292]   Expert 25 |      2 | CPU
DEBUG 01-04 15:36:16.678998.678998 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:16.678264.678264 lmp.py:292]   Expert 55 |      2 | CPU
DEBUG 01-04 15:36:16.678529.678529 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:16.678033.678033 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:16.678537.678537 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:16.678280.678280 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:16.678452.678452 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:16.678864.678864 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:16.678798.678798 lmp.py:292]   Expert 59 |      3 | CPU
DEBUG 01-04 15:36:16.678779.678779 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:16.678283.678283 lmp.py:292]   Expert 38 |      4 | CPU
DEBUG 01-04 15:36:16.678549.678549 lmp.py:292]   Expert 18 |      5 | CPU
DEBUG 01-04 15:36:16.678291.678291 lmp.py:292]   Expert 23 |      5 | CPU
DEBUG 01-04 15:36:16.678795.678795 lmp.py:292]   Expert 27 |      5 | CPU
DEBUG 01-04 15:36:16.678299.678299 lmp.py:292]   Expert 31 |      5 | CPU
DEBUG 01-04 15:36:16.678234.678234 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:16.678930.678930 lmp.py:292]   Expert 13 |      7 | CPU
DEBUG 01-04 15:36:16.678103.678103 lmp.py:292]   Expert 20 |      7 | CPU
DEBUG 01-04 15:36:16.678130.678130 lmp.py:292]   Expert 36 |      7 | CPU
DEBUG 01-04 15:36:16.678395.678395 lmp.py:292]   Expert  7 |      8 | CPU
DEBUG 01-04 15:36:16.678899.678899 lmp.py:292]   Expert  9 |      8 | GPU
DEBUG 01-04 15:36:16.678927.678927 lmp.py:292]   Expert 26 |      8 | GPU
DEBUG 01-04 15:36:16.678192.678192 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:16.678981.678981 lmp.py:292]   Expert 52 |      8 | GPU
DEBUG 01-04 15:36:16.678485.678485 lmp.py:292]   Expert 30 |      9 | GPU
DEBUG 01-04 15:36:16.678750.678750 lmp.py:292]   Expert 47 |      9 | GPU
DEBUG 01-04 15:36:16.678016.678016 lmp.py:292]   Expert 10 |     10 | GPU
DEBUG 01-04 15:36:16.678474.678474 lmp.py:292]   Expert 61 |     10 | GPU
DEBUG 01-04 15:36:16.678978.678978 lmp.py:292]   Expert 40 |     11 | GPU
DEBUG 01-04 15:36:16.678005.678005 lmp.py:292]   Expert 46 |     12 | GPU
DEBUG 01-04 15:36:16.678509.678509 lmp.py:292]   Expert 60 |     12 | GPU
DEBUG 01-04 15:36:16.678013.678013 lmp.py:292]   Expert  8 |     13 | GPU
DEBUG 01-04 15:36:16.678040.678040 lmp.py:292]   Expert 12 |     13 | GPU
DEBUG 01-04 15:36:16.678306.678306 lmp.py:292]   Expert 50 |     13 | GPU
DEBUG 01-04 15:36:16.678094.678094 lmp.py:292]   Expert 17 |     14 | GPU
DEBUG 01-04 15:36:16.678360.678360 lmp.py:292]   Expert 19 |     14 | GPU
DEBUG 01-04 15:36:16.678626.678626 lmp.py:292]   Expert 24 |     14 | GPU
DEBUG 01-04 15:36:16.678083.678083 lmp.py:292]   Expert 49 |     15 | GPU
DEBUG 01-04 15:36:16.678541.678541 lmp.py:292]   Expert 21 |     16 | GPU
DEBUG 01-04 15:36:16.678999.678999 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:16.678503.678503 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:16.679007.679007 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:16.679511.679511 lmp.py:292]   Expert  1 |   1996 | GPU
DEBUG 01-04 15:36:16.679538.679538 lmp.py:292]   Expert  3 |   2001 | GPU
DEBUG 01-04 15:36:16.679565.679565 lmp.py:292]   Expert  0 |   2005 | GPU
DEBUG 01-04 15:36:16.679215.679215 lmp.py:293] 
DEBUG 01-04 15:36:16.679215.679215 lmp.py:293]   CPU total tokens: 91 (0.7%)
DEBUG 01-04 15:36:16.679864.679864 lmp.py:294]   GPU total tokens: 12197 (99.3%)
DEBUG 01-04 15:36:16.679283.679283 cuda_h.py:19] end experts_map_get cost 0.0016238689422607422 seconds
DEBUG 01-04 15:36:16.679455.679455 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.679808.679808 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.679779.679779 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.679929.679929 cuda_h.py:19] end allocate_cuda_memory cost 0.00028228759765625 seconds
DEBUG 01-04 15:36:16.679501.679501 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.679025.679025 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.679278.679278 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.679981.679981 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7392ed8d-e506-440f-8a38-4dc0d035129c
DEBUG 01-04 15:36:16.680286.680286 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.681894.681894 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7392ed8d-e506-440f-8a38-4dc0d035129c
DEBUG 01-04 15:36:16.681223.681223 cuda_h.py:19] end load_into_gpu_async cost 0.0015330314636230469 seconds
DEBUG 01-04 15:36:16.681854.681854 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.681832.681832 cuda_h.py:19] end restore_tensors2 cost 0.0004410743713378906 seconds
DEBUG 01-04 15:36:16.681191.681191 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027132034301757812 seconds
DEBUG 01-04 15:36:16.684545.684545 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005616664886474609 seconds
DEBUG 01-04 15:36:16.684335.684335 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.684272.684272 lmp.py:339] 
DEBUG 01-04 15:36:16.684272.684272 lmp.py:339]   Computing 24 experts on CPU...
DEBUG 01-04 15:36:16.685076.685076 cuda_h.py:19] end cpu_experts_submit cost 0.00012612342834472656 seconds
DEBUG 01-04 15:36:16.685832.685832 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.701663.701663 mlpmodule.py:704] group tensors cost 0.01649641990661621 s
DEBUG 01-04 15:36:16.703774.703774 mlpmodule.py:742] pad cost 0.0014183521270751953 s
DEBUG 01-04 15:36:16.704500.704500 mlpmodule.py:748] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-04 15:36:16.704509.704509 mlpmodule.py:753] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-04 15:36:16.707808.707808 mlpmodule.py:768] group_w3: shape=torch.Size([24, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=69206016
DEBUG 01-04 15:36:16.707414.707414 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.708755.708755 mlpmodule.py:774] group_w3 first element: -0.042236328125
WARNING 01-04 15:36:16.708142.708142 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.711729.711729 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.711195.711195 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.715436.715436 mlpmodule.py:797] group einsum cost 0.011005878448486328 s
DEBUG 01-04 15:36:16.715875.715875 mlpmodule.py:805] cpy2cputensor cost 9.393692016601562e-05 s
DEBUG 01-04 15:36:16.719868.719868 cuda_h.py:19] end wait_cetm_experts cost 0.03406548500061035 seconds
DEBUG 01-04 15:36:16.719573.719573 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.719626.719626 cuda_h.py:19] end gpu_sexperts cost 0.0005168914794921875 seconds
DEBUG 01-04 15:36:16.719945.719945 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-04 15:36:16.719914.719914 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-04 15:36:16.720724.720724 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.528594970703125e-05 seconds
DEBUG 01-04 15:36:16.720945.720945 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.720450.720450 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.00014925003051757812 seconds
DEBUG 01-04 15:36:16.720241.720241 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.720137.720137 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.720435.720435 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7392ed8d-e506-440f-8a38-4dc0d035129c
DEBUG 01-04 15:36:16.720909.720909 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.724724.724724 cuda_h.py:19] end allocate_cuda_memory cost 0.003481626510620117 seconds
DEBUG 01-04 15:36:16.724422.724422 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.724437.724437 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.724711.724711 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.724077.724077 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2289b1b0-bcc9-4b6a-a876-57599b0f22a4
DEBUG 01-04 15:36:16.724472.724472 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.724918.724918 client.py:127] Model loaded
DEBUG 01-04 15:36:16.724583.724583 cuda_h.py:19] end wait_experts cost 0.004435539245605469 seconds
DEBUG 01-04 15:36:16.724816.724816 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.724194.724194 lmp.py:384]   Computing 25 experts on GPU...
DEBUG 01-04 15:36:16.725726.725726 mlpmodule.py:531] gpu group tensors cost 0.0005578994750976562 s
INFO 01-04 15:36:16.725868.725868 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2289b1b0-bcc9-4b6a-a876-57599b0f22a4
DEBUG 01-04 15:36:16.725354.725354 cuda_h.py:19] end load_into_gpu_async cost 0.001657247543334961 seconds
DEBUG 01-04 15:36:16.726739.726739 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.726485.726485 cuda_h.py:19] end restore_tensors2 cost 8.940696716308594e-05 seconds
DEBUG 01-04 15:36:16.726924.726924 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00581812858581543 seconds
INFO 01-04 15:36:16.726667.726667 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2289b1b0-bcc9-4b6a-a876-57599b0f22a4
DEBUG 01-04 15:36:16.728736.728736 mlpmodule.py:564] gpu pad cost 0.0028307437896728516 s
DEBUG 01-04 15:36:16.729310.729310 mlpmodule.py:582] gpu group einsum cost 0.0006222724914550781 s
DEBUG 01-04 15:36:16.732993.732993 mlpmodule.py:611] gpu experts func einsum cost 0.007740020751953125 s
DEBUG 01-04 15:36:16.732350.732350 cuda_h.py:19] end gpu_experts cost 0.008016824722290039 seconds
DEBUG 01-04 15:36:16.733729.733729 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:16.733613.733613 mlpmodule.py:662]  experts func einsum cost 0.047846317291259766 s
INFO 01-04 15:36:16.737703.737703 client.py:127] Model loaded
DEBUG 01-04 15:36:16.737639.737639 cuda_h.py:19] end sllm_worker_task cost 0.01684093475341797 seconds
DEBUG 01-04 15:36:16.737383.737383 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004067182540893555 seconds
DEBUG 01-04 15:36:16.737276.737276 cuda_h.py:19] end layer_moe_generate_15 cost 0.06098294258117676 seconds
DEBUG 01-04 15:36:16.737791.737791 lmp.py:207] -------------------------------- end layer 15 --------------------------------
DEBUG 01-04 15:36:16.737700.737700 lmp.py:169] -------------------------------- start layer 16 --------------------------------
DEBUG 01-04 15:36:16.737634.737634 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.737698.737698 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.740154.740154 cuda_h.py:19] end self_attn cost 0.0028769969940185547 seconds
DEBUG 01-04 15:36:16.741868.741868 cuda_h.py:19] end iln_self_attn_paln cost 0.0035817623138427734 seconds
DEBUG 01-04 15:36:16.741519.741519 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-04 15:36:16.741858.741858 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.741021.741021 cuda_h.py:19] end gate cost 0.0006806850433349609 seconds
DEBUG 01-04 15:36:16.741089.741089 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.742507.742507 lmp.py:281] 
DEBUG 01-04 15:36:16.742507.742507 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.742832.742832 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:16.742244.742244 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:16.742271.742271 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:16.742914.742914 lmp.py:285] 
DEBUG 01-04 15:36:16.742914.742914 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.742795.742795 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.742160.742160 lmp.py:292]   Expert 13 |      1 | CPU
DEBUG 01-04 15:36:16.742803.742803 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:16.742492.742492 lmp.py:292]   Expert 30 |      1 | CPU
DEBUG 01-04 15:36:16.742182.742182 lmp.py:292]   Expert 39 |      1 | CPU
DEBUG 01-04 15:36:16.742871.742871 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:16.742322.742322 lmp.py:292]   Expert  6 |      2 | CPU
DEBUG 01-04 15:36:16.742773.742773 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:16.742985.742985 lmp.py:292]   Expert 16 |      2 | CPU
DEBUG 01-04 15:36:16.742959.742959 lmp.py:292]   Expert 22 |      2 | CPU
DEBUG 01-04 15:36:16.742410.742410 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:16.742623.742623 lmp.py:292]   Expert 61 |      2 | CPU
DEBUG 01-04 15:36:16.742597.742597 lmp.py:292]   Expert 11 |      3 | CPU
DEBUG 01-04 15:36:16.742809.742809 lmp.py:292]   Expert 18 |      3 | CPU
DEBUG 01-04 15:36:16.742452.742452 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:16.742857.742857 lmp.py:292]   Expert 31 |      3 | CPU
DEBUG 01-04 15:36:16.742261.742261 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:16.742189.742189 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:16.742832.742832 lmp.py:292]   Expert 45 |      3 | CPU
DEBUG 01-04 15:36:16.742044.742044 lmp.py:292]   Expert 50 |      3 | CPU
DEBUG 01-04 15:36:16.742495.742495 lmp.py:292]   Expert 51 |      3 | CPU
DEBUG 01-04 15:36:16.742708.742708 lmp.py:292]   Expert 60 |      3 | CPU
DEBUG 01-04 15:36:16.742920.742920 lmp.py:292]   Expert 35 |      4 | CPU
DEBUG 01-04 15:36:16.742894.742894 lmp.py:292]   Expert 55 |      4 | CPU
DEBUG 01-04 15:36:16.742868.742868 lmp.py:292]   Expert 25 |      5 | CPU
DEBUG 01-04 15:36:16.742081.742081 lmp.py:292]   Expert 34 |      5 | CPU
DEBUG 01-04 15:36:16.742293.742293 lmp.py:292]   Expert 42 |      5 | CPU
DEBUG 01-04 15:36:16.742506.742506 lmp.py:292]   Expert 53 |      5 | CPU
DEBUG 01-04 15:36:16.742672.742672 lmp.py:292]   Expert 62 |      5 | CPU
DEBUG 01-04 15:36:16.742076.742076 lmp.py:292]   Expert 63 |      5 | CPU
DEBUG 01-04 15:36:16.743004.743004 lmp.py:292]   Expert 10 |      6 | GPU
DEBUG 01-04 15:36:16.743647.743647 lmp.py:292]   Expert 21 |      6 | GPU
DEBUG 01-04 15:36:16.743098.743098 lmp.py:292]   Expert 37 |      6 | GPU
DEBUG 01-04 15:36:16.743072.743072 lmp.py:292]   Expert 48 |      6 | GPU
DEBUG 01-04 15:36:16.743761.743761 lmp.py:292]   Expert  9 |      7 | GPU
DEBUG 01-04 15:36:16.743974.743974 lmp.py:292]   Expert 28 |      7 | GPU
DEBUG 01-04 15:36:16.743709.743709 lmp.py:292]   Expert 32 |      7 | GPU
DEBUG 01-04 15:36:16.743922.743922 lmp.py:292]   Expert 40 |      7 | GPU
DEBUG 01-04 15:36:16.743896.743896 lmp.py:292]   Expert 56 |      7 | GPU
DEBUG 01-04 15:36:16.743870.743870 lmp.py:292]   Expert 17 |      8 | GPU
DEBUG 01-04 15:36:16.743082.743082 lmp.py:292]   Expert 20 |      8 | GPU
DEBUG 01-04 15:36:16.743295.743295 lmp.py:292]   Expert 23 |      8 | GPU
DEBUG 01-04 15:36:16.743269.743269 lmp.py:292]   Expert 24 |      8 | GPU
DEBUG 01-04 15:36:16.743481.743481 lmp.py:292]   Expert  7 |      9 | GPU
DEBUG 01-04 15:36:16.743647.743647 lmp.py:292]   Expert 29 |      9 | GPU
DEBUG 01-04 15:36:16.743052.743052 lmp.py:292]   Expert 36 |      9 | GPU
DEBUG 01-04 15:36:16.743457.743457 lmp.py:292]   Expert 19 |     10 | GPU
DEBUG 01-04 15:36:16.743338.743338 lmp.py:292]   Expert 46 |     10 | GPU
DEBUG 01-04 15:36:16.743550.743550 lmp.py:292]   Expert 41 |     11 | GPU
DEBUG 01-04 15:36:16.743763.743763 lmp.py:292]   Expert 49 |     13 | GPU
DEBUG 01-04 15:36:16.743975.743975 lmp.py:292]   Expert 47 |     14 | GPU
DEBUG 01-04 15:36:16.743949.743949 lmp.py:292]   Expert  8 |     17 | GPU
DEBUG 01-04 15:36:16.743162.743162 lmp.py:292]   Expert 27 |     17 | GPU
DEBUG 01-04 15:36:16.743613.743613 lmp.py:292]   Expert 52 |     17 | GPU
DEBUG 01-04 15:36:16.743825.743825 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:16.743038.743038 lmp.py:292]   Expert  1 |   1993 | GPU
DEBUG 01-04 15:36:16.743681.743681 lmp.py:292]   Expert  0 |   1994 | GPU
DEBUG 01-04 15:36:16.743608.743608 lmp.py:292]   Expert  4 |   1994 | GPU
DEBUG 01-04 15:36:16.743775.743775 lmp.py:292]   Expert  2 |   1998 | GPU
DEBUG 01-04 15:36:16.743702.743702 lmp.py:292]   Expert  5 |   2005 | GPU
DEBUG 01-04 15:36:16.743345.743345 lmp.py:293] 
DEBUG 01-04 15:36:16.743345.743345 lmp.py:293]   CPU total tokens: 85 (0.7%)
DEBUG 01-04 15:36:16.743511.743511 lmp.py:294]   GPU total tokens: 12203 (99.3%)
DEBUG 01-04 15:36:16.743207.743207 cuda_h.py:19] end experts_map_get cost 0.0015337467193603516 seconds
DEBUG 01-04 15:36:16.743374.743374 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.743481.743481 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.743604.743604 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.744926.744926 cuda_h.py:19] end allocate_cuda_memory cost 0.000274658203125 seconds
DEBUG 01-04 15:36:16.744822.744822 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.744863.744863 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.744248.744248 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.744613.744613 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc360cf2-1bc2-4e25-8781-510f4f06bbb3
DEBUG 01-04 15:36:16.744131.744131 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.746880.746880 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc360cf2-1bc2-4e25-8781-510f4f06bbb3
DEBUG 01-04 15:36:16.746170.746170 cuda_h.py:19] end load_into_gpu_async cost 0.0024182796478271484 seconds
DEBUG 01-04 15:36:16.746186.746186 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.747897.747897 cuda_h.py:19] end restore_tensors2 cost 0.00042176246643066406 seconds
DEBUG 01-04 15:36:16.747965.747965 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003564596176147461 seconds
DEBUG 01-04 15:36:16.750686.750686 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006522417068481445 seconds
DEBUG 01-04 15:36:16.750800.750800 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.750174.750174 lmp.py:339] 
DEBUG 01-04 15:36:16.750174.750174 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:16.750779.750779 cuda_h.py:19] end cpu_experts_submit cost 0.00011515617370605469 seconds
DEBUG 01-04 15:36:16.750336.750336 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.756825.756825 mlpmodule.py:704] group tensors cost 0.0055577754974365234 s
DEBUG 01-04 15:36:16.758327.758327 mlpmodule.py:742] pad cost 0.0015149116516113281 s
DEBUG 01-04 15:36:16.758734.758734 mlpmodule.py:748] create cpu tensor cost 3.5762786865234375e-05 s
DEBUG 01-04 15:36:16.758862.758862 mlpmodule.py:753] move to cpu cost 2.7179718017578125e-05 s
DEBUG 01-04 15:36:16.762639.762639 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:16.762881.762881 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.762460.762460 mlpmodule.py:774] group_w3 first element: -0.007537841796875
WARNING 01-04 15:36:16.762086.762086 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.766286.766286 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.766924.766924 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.770378.770378 mlpmodule.py:797] group einsum cost 0.012182474136352539 s
DEBUG 01-04 15:36:16.770791.770791 mlpmodule.py:805] cpy2cputensor cost 8.988380432128906e-05 s
DEBUG 01-04 15:36:16.775987.775987 cuda_h.py:19] end wait_cetm_experts cost 0.02490711212158203 seconds
DEBUG 01-04 15:36:16.775600.775600 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.776520.776520 cuda_h.py:19] end gpu_sexperts cost 0.00052642822265625 seconds
DEBUG 01-04 15:36:16.776038.776038 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-04 15:36:16.776007.776007 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-04 15:36:16.776963.776963 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.695487976074219e-05 seconds
DEBUG 01-04 15:36:16.776918.776918 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.748603820800781e-05 seconds
DEBUG 01-04 15:36:16.776144.776144 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.776907.776907 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc360cf2-1bc2-4e25-8781-510f4f06bbb3
DEBUG 01-04 15:36:16.776663.776663 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.776779.776779 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.776575.776575 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.782411.782411 cuda_h.py:19] end allocate_cuda_memory cost 0.005351066589355469 seconds
DEBUG 01-04 15:36:16.782971.782971 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.782463.782463 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.782007.782007 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.782240.782240 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a417bf3f-8333-47ca-b5da-bbfa57cd60ff
DEBUG 01-04 15:36:16.782899.782899 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:16.791798.791798 mlpmodule.py:662]  experts func einsum cost 0.04136776924133301 s
INFO 01-04 15:36:16.795466.795466 client.py:127] Model loaded
DEBUG 01-04 15:36:16.795524.795524 cuda_h.py:19] end wait_experts cost 0.019225120544433594 seconds
DEBUG 01-04 15:36:16.795732.795732 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.795464.795464 lmp.py:384]   Computing 30 experts on GPU...
INFO 01-04 15:36:16.796456.796456 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a417bf3f-8333-47ca-b5da-bbfa57cd60ff
DEBUG 01-04 15:36:16.796922.796922 cuda_h.py:19] end load_into_gpu_async cost 0.014111042022705078 seconds
DEBUG 01-04 15:36:16.796340.796340 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.796197.796197 cuda_h.py:19] end restore_tensors2 cost 7.915496826171875e-05 seconds
DEBUG 01-04 15:36:16.796835.796835 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.019846677780151367 seconds
DEBUG 01-04 15:36:16.796847.796847 mlpmodule.py:531] gpu group tensors cost 0.0010457038879394531 s
INFO 01-04 15:36:16.797729.797729 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a417bf3f-8333-47ca-b5da-bbfa57cd60ff
DEBUG 01-04 15:36:16.799945.799945 mlpmodule.py:564] gpu pad cost 0.002395153045654297 s
DEBUG 01-04 15:36:16.800950.800950 mlpmodule.py:582] gpu group einsum cost 0.0012612342834472656 s
DEBUG 01-04 15:36:16.805842.805842 mlpmodule.py:611] gpu experts func einsum cost 0.009398698806762695 s
DEBUG 01-04 15:36:16.805276.805276 cuda_h.py:19] end gpu_experts cost 0.00963592529296875 seconds
DEBUG 01-04 15:36:16.805046.805046 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.808891.808891 client.py:127] Model loaded
DEBUG 01-04 15:36:16.808271.808271 cuda_h.py:19] end sllm_worker_task cost 0.031508684158325195 seconds
DEBUG 01-04 15:36:16.808174.808174 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.002792835235595703 seconds
DEBUG 01-04 15:36:16.808730.808730 cuda_h.py:19] end layer_moe_generate_16 cost 0.06717109680175781 seconds
DEBUG 01-04 15:36:16.808850.808850 lmp.py:207] -------------------------------- end layer 16 --------------------------------
DEBUG 01-04 15:36:16.808673.808673 lmp.py:169] -------------------------------- start layer 17 --------------------------------
DEBUG 01-04 15:36:16.808568.808568 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.809587.809587 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.811227.811227 cuda_h.py:19] end self_attn cost 0.002836942672729492 seconds
DEBUG 01-04 15:36:16.812152.812152 cuda_h.py:19] end iln_self_attn_paln cost 0.0035538673400878906 seconds
DEBUG 01-04 15:36:16.812087.812087 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-04 15:36:16.812294.812294 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.813862.813862 cuda_h.py:19] end gate cost 0.0006797313690185547 seconds
DEBUG 01-04 15:36:16.813883.813883 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.813812.813812 lmp.py:281] 
DEBUG 01-04 15:36:16.813812.813812 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.813899.813899 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:16.813595.813595 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:16.813669.813669 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:16.813596.813596 lmp.py:285] 
DEBUG 01-04 15:36:16.813596.813596 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.813001.813001 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.813843.813843 lmp.py:292]   Expert  7 |      1 | CPU
DEBUG 01-04 15:36:16.813724.813724 lmp.py:292]   Expert 16 |      1 | CPU
DEBUG 01-04 15:36:16.813890.813890 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:16.813818.813818 lmp.py:292]   Expert  8 |      2 | CPU
DEBUG 01-04 15:36:16.813507.813507 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:16.813958.813958 lmp.py:292]   Expert 31 |      2 | CPU
DEBUG 01-04 15:36:16.813171.813171 lmp.py:292]   Expert 39 |      2 | CPU
DEBUG 01-04 15:36:16.813860.813860 lmp.py:292]   Expert 42 |      2 | CPU
DEBUG 01-04 15:36:16.813549.813549 lmp.py:292]   Expert 45 |      2 | CPU
DEBUG 01-04 15:36:16.813623.813623 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:16.813266.813266 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:16.813147.813147 lmp.py:292]   Expert 56 |      2 | CPU
DEBUG 01-04 15:36:16.813790.813790 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:16.813718.813718 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:16.813930.813930 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:16.814143.814143 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:16.814832.814832 lmp.py:292]   Expert 10 |      4 | CPU
DEBUG 01-04 15:36:16.814045.814045 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:16.814734.814734 lmp.py:292]   Expert 30 |      4 | CPU
DEBUG 01-04 15:36:16.814185.814185 lmp.py:292]   Expert 33 |      4 | CPU
DEBUG 01-04 15:36:16.814636.814636 lmp.py:292]   Expert 37 |      4 | CPU
DEBUG 01-04 15:36:16.814610.814610 lmp.py:292]   Expert 38 |      4 | CPU
DEBUG 01-04 15:36:16.814061.814061 lmp.py:292]   Expert 40 |      4 | CPU
DEBUG 01-04 15:36:16.814988.814988 lmp.py:292]   Expert 59 |      4 | CPU
DEBUG 01-04 15:36:16.814154.814154 lmp.py:292]   Expert 11 |      5 | CPU
DEBUG 01-04 15:36:16.814559.814559 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:16.814964.814964 lmp.py:292]   Expert 34 |      5 | CPU
DEBUG 01-04 15:36:16.814368.814368 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:16.814819.814819 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:16.814031.814031 lmp.py:292]   Expert 18 |      6 | GPU
DEBUG 01-04 15:36:16.814721.814721 lmp.py:292]   Expert 21 |      6 | GPU
DEBUG 01-04 15:36:16.814172.814172 lmp.py:292]   Expert 49 |      6 | GPU
DEBUG 01-04 15:36:16.814146.814146 lmp.py:292]   Expert 52 |      6 | GPU
DEBUG 01-04 15:36:16.814597.814597 lmp.py:292]   Expert 61 |      6 | GPU
DEBUG 01-04 15:36:16.814047.814047 lmp.py:292]   Expert 12 |      7 | GPU
DEBUG 01-04 15:36:16.814737.814737 lmp.py:292]   Expert 20 |      7 | GPU
DEBUG 01-04 15:36:16.814949.814949 lmp.py:292]   Expert 32 |      7 | GPU
DEBUG 01-04 15:36:16.814923.814923 lmp.py:292]   Expert 43 |      7 | GPU
DEBUG 01-04 15:36:16.814136.814136 lmp.py:292]   Expert 44 |      7 | GPU
DEBUG 01-04 15:36:16.814779.814779 lmp.py:292]   Expert 63 |      7 | GPU
DEBUG 01-04 15:36:16.814422.814422 lmp.py:292]   Expert 51 |      8 | GPU
DEBUG 01-04 15:36:16.814025.814025 lmp.py:292]   Expert 53 |      8 | GPU
DEBUG 01-04 15:36:16.814145.814145 lmp.py:292]   Expert 23 |      9 | GPU
DEBUG 01-04 15:36:16.814596.814596 lmp.py:292]   Expert 26 |      9 | GPU
DEBUG 01-04 15:36:16.814570.814570 lmp.py:292]   Expert 50 |     10 | GPU
DEBUG 01-04 15:36:16.814782.814782 lmp.py:292]   Expert 19 |     12 | GPU
DEBUG 01-04 15:36:16.814233.814233 lmp.py:292]   Expert 48 |     12 | GPU
DEBUG 01-04 15:36:16.814684.814684 lmp.py:292]   Expert 41 |     13 | GPU
DEBUG 01-04 15:36:16.814896.814896 lmp.py:292]   Expert 57 |     13 | GPU
DEBUG 01-04 15:36:16.814109.814109 lmp.py:292]   Expert 62 |     13 | GPU
DEBUG 01-04 15:36:16.814083.814083 lmp.py:292]   Expert 55 |     14 | GPU
DEBUG 01-04 15:36:16.814726.814726 lmp.py:292]   Expert 17 |     15 | GPU
DEBUG 01-04 15:36:16.814131.814131 lmp.py:292]   Expert  9 |     23 | GPU
DEBUG 01-04 15:36:16.814774.814774 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:16.814940.814940 lmp.py:292]   Expert  4 |   1992 | GPU
DEBUG 01-04 15:36:16.814106.814106 lmp.py:292]   Expert  5 |   1994 | GPU
DEBUG 01-04 15:36:16.814795.814795 lmp.py:292]   Expert  3 |   1995 | GPU
DEBUG 01-04 15:36:16.814008.814008 lmp.py:292]   Expert  0 |   1996 | GPU
DEBUG 01-04 15:36:16.814220.814220 lmp.py:292]   Expert  2 |   1998 | GPU
DEBUG 01-04 15:36:16.814148.814148 lmp.py:293] 
DEBUG 01-04 15:36:16.814148.814148 lmp.py:293]   CPU total tokens: 91 (0.7%)
DEBUG 01-04 15:36:16.814075.814075 lmp.py:294]   GPU total tokens: 12197 (99.3%)
DEBUG 01-04 15:36:16.814772.814772 cuda_h.py:19] end experts_map_get cost 0.0015735626220703125 seconds
DEBUG 01-04 15:36:16.814891.814891 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.814906.814906 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.814652.814652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.815004.815004 cuda_h.py:19] end allocate_cuda_memory cost 0.0001914501190185547 seconds
DEBUG 01-04 15:36:16.815708.815708 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.815272.815272 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.815942.815942 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.815830.815830 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e7a4ff08-dd58-4420-afce-25e0051def49
DEBUG 01-04 15:36:16.815028.815028 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.817729.817729 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e7a4ff08-dd58-4420-afce-25e0051def49
DEBUG 01-04 15:36:16.817541.817541 cuda_h.py:19] end load_into_gpu_async cost 0.0022878646850585938 seconds
DEBUG 01-04 15:36:16.817080.817080 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.818456.818456 cuda_h.py:19] end restore_tensors2 cost 0.0004527568817138672 seconds
DEBUG 01-04 15:36:16.818239.818239 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033822059631347656 seconds
DEBUG 01-04 15:36:16.821045.821045 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006335020065307617 seconds
DEBUG 01-04 15:36:16.821212.821212 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.821494.821494 lmp.py:339] 
DEBUG 01-04 15:36:16.821494.821494 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:16.821529.821529 cuda_h.py:19] end cpu_experts_submit cost 0.0001163482666015625 seconds
DEBUG 01-04 15:36:16.821386.821386 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.831266.831266 mlpmodule.py:704] group tensors cost 0.010287761688232422 s
DEBUG 01-04 15:36:16.835454.835454 mlpmodule.py:742] pad cost 0.002539396286010742 s
DEBUG 01-04 15:36:16.835102.835102 mlpmodule.py:748] create cpu tensor cost 6.67572021484375e-05 s
DEBUG 01-04 15:36:16.835112.835112 mlpmodule.py:753] move to cpu cost 4.601478576660156e-05 s
DEBUG 01-04 15:36:16.841559.841559 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:16.841572.841572 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.841495.841495 mlpmodule.py:774] group_w3 first element: 0.0267333984375
WARNING 01-04 15:36:16.841042.841042 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.844274.844274 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.845310.845310 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.848668.848668 mlpmodule.py:797] group einsum cost 0.012748241424560547 s
DEBUG 01-04 15:36:16.848518.848518 mlpmodule.py:805] cpy2cputensor cost 9.441375732421875e-05 s
DEBUG 01-04 15:36:16.853325.853325 cuda_h.py:19] end wait_cetm_experts cost 0.03174567222595215 seconds
DEBUG 01-04 15:36:16.853381.853381 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.853368.853368 cuda_h.py:19] end gpu_sexperts cost 0.0005419254302978516 seconds
DEBUG 01-04 15:36:16.854979.854979 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-04 15:36:16.854855.854855 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-04 15:36:16.854665.854665 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.552436828613281e-05 seconds
DEBUG 01-04 15:36:16.854097.854097 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.653236389160156e-05 seconds
DEBUG 01-04 15:36:16.854800.854800 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.854424.854424 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e7a4ff08-dd58-4420-afce-25e0051def49
DEBUG 01-04 15:36:16.854112.854112 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.854718.854718 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.854919.854919 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.859377.859377 cuda_h.py:19] end allocate_cuda_memory cost 0.004924774169921875 seconds
DEBUG 01-04 15:36:16.859148.859148 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.859865.859865 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.859231.859231 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.859179.859179 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 752fccb0-213a-4ecb-888c-e8eb4844811c
DEBUG 01-04 15:36:16.859891.859891 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.866094.866094 client.py:127] Model loaded
DEBUG 01-04 15:36:16.866321.866321 cuda_h.py:19] end wait_experts cost 0.012570619583129883 seconds
DEBUG 01-04 15:36:16.866786.866786 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.866641.866641 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:16.867318.867318 mlpmodule.py:531] gpu group tensors cost 0.0005438327789306641 s
INFO 01-04 15:36:16.867947.867947 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 752fccb0-213a-4ecb-888c-e8eb4844811c
DEBUG 01-04 15:36:16.867505.867505 cuda_h.py:19] end load_into_gpu_async cost 0.008056879043579102 seconds
DEBUG 01-04 15:36:16.867254.867254 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.867761.867761 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-04 15:36:16.867609.867609 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01332855224609375 seconds
INFO 01-04 15:36:16.868986.868986 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 752fccb0-213a-4ecb-888c-e8eb4844811c
DEBUG 01-04 15:36:16.869338.869338 mlpmodule.py:662]  experts func einsum cost 0.047890663146972656 s
DEBUG 01-04 15:36:16.870592.870592 mlpmodule.py:564] gpu pad cost 0.002568960189819336 s
DEBUG 01-04 15:36:16.870280.870280 mlpmodule.py:582] gpu group einsum cost 0.0005097389221191406 s
DEBUG 01-04 15:36:16.874046.874046 mlpmodule.py:611] gpu experts func einsum cost 0.0072596073150634766 s
DEBUG 01-04 15:36:16.874673.874673 cuda_h.py:19] end gpu_experts cost 0.0074689388275146484 seconds
DEBUG 01-04 15:36:16.874621.874621 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.878501.878501 client.py:127] Model loaded
DEBUG 01-04 15:36:16.878138.878138 cuda_h.py:19] end sllm_worker_task cost 0.024228572845458984 seconds
DEBUG 01-04 15:36:16.878361.878361 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0044727325439453125 seconds
DEBUG 01-04 15:36:16.879607.879607 cuda_h.py:19] end layer_moe_generate_17 cost 0.06670999526977539 seconds
DEBUG 01-04 15:36:16.879573.879573 lmp.py:207] -------------------------------- end layer 17 --------------------------------
DEBUG 01-04 15:36:16.879913.879913 lmp.py:169] -------------------------------- start layer 18 --------------------------------
DEBUG 01-04 15:36:16.879085.879085 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.879494.879494 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.882138.882138 cuda_h.py:19] end self_attn cost 0.0029449462890625 seconds
DEBUG 01-04 15:36:16.883877.883877 cuda_h.py:19] end iln_self_attn_paln cost 0.0036420822143554688 seconds
DEBUG 01-04 15:36:16.883144.883144 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-04 15:36:16.883145.883145 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.883355.883355 cuda_h.py:19] end gate cost 0.0006811618804931641 seconds
DEBUG 01-04 15:36:16.883946.883946 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.884031.884031 lmp.py:281] 
DEBUG 01-04 15:36:16.884031.884031 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.884595.884595 lmp.py:282]   Total experts: 53
DEBUG 01-04 15:36:16.884483.884483 lmp.py:283]   CPU experts: 26 (49%)
DEBUG 01-04 15:36:16.884795.884795 lmp.py:284]   GPU experts: 27 (51%)
DEBUG 01-04 15:36:16.884200.884200 lmp.py:285] 
DEBUG 01-04 15:36:16.884200.884200 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.884604.884604 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.884360.884360 lmp.py:292]   Expert 11 |      1 | CPU
DEBUG 01-04 15:36:16.884170.884170 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:16.884289.884289 lmp.py:292]   Expert 22 |      1 | CPU
DEBUG 01-04 15:36:16.884694.884694 lmp.py:292]   Expert 37 |      1 | CPU
DEBUG 01-04 15:36:16.884098.884098 lmp.py:292]   Expert 45 |      1 | CPU
DEBUG 01-04 15:36:16.884741.884741 lmp.py:292]   Expert 55 |      1 | CPU
DEBUG 01-04 15:36:16.884338.884338 lmp.py:292]   Expert 59 |      1 | CPU
DEBUG 01-04 15:36:16.884935.884935 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:16.884293.884293 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:16.884174.884174 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:16.884817.884817 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:16.884983.884983 lmp.py:292]   Expert 32 |      2 | CPU
DEBUG 01-04 15:36:16.884673.884673 lmp.py:292]   Expert 42 |      2 | CPU
DEBUG 01-04 15:36:16.884601.884601 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:16.884290.884290 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:16.884979.884979 lmp.py:292]   Expert 48 |      3 | CPU
DEBUG 01-04 15:36:16.884668.884668 lmp.py:292]   Expert 51 |      3 | CPU
DEBUG 01-04 15:36:16.884358.884358 lmp.py:292]   Expert 29 |      4 | CPU
DEBUG 01-04 15:36:16.884285.884285 lmp.py:292]   Expert 54 |      4 | CPU
DEBUG 01-04 15:36:16.884889.884889 lmp.py:292]   Expert  8 |      5 | CPU
DEBUG 01-04 15:36:16.884009.884009 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:16.884128.884128 lmp.py:292]   Expert 27 |      5 | CPU
DEBUG 01-04 15:36:16.884248.884248 lmp.py:292]   Expert 41 |      5 | CPU
DEBUG 01-04 15:36:16.884414.884414 lmp.py:292]   Expert 17 |      6 | CPU
DEBUG 01-04 15:36:16.884342.884342 lmp.py:292]   Expert 30 |      6 | CPU
DEBUG 01-04 15:36:16.884031.884031 lmp.py:292]   Expert 31 |      6 | CPU
DEBUG 01-04 15:36:16.884959.884959 lmp.py:292]   Expert 47 |      6 | GPU
DEBUG 01-04 15:36:16.884887.884887 lmp.py:292]   Expert 52 |      6 | GPU
DEBUG 01-04 15:36:16.884576.884576 lmp.py:292]   Expert 10 |      8 | GPU
DEBUG 01-04 15:36:16.884266.884266 lmp.py:292]   Expert 43 |      8 | GPU
DEBUG 01-04 15:36:16.884716.884716 lmp.py:292]   Expert 50 |      9 | GPU
DEBUG 01-04 15:36:16.884406.884406 lmp.py:292]   Expert 56 |      9 | GPU
DEBUG 01-04 15:36:16.884333.884333 lmp.py:292]   Expert 61 |      9 | GPU
DEBUG 01-04 15:36:16.884976.884976 lmp.py:292]   Expert 16 |     10 | GPU
DEBUG 01-04 15:36:16.885096.885096 lmp.py:292]   Expert 25 |     10 | GPU
DEBUG 01-04 15:36:16.885978.885978 lmp.py:292]   Expert 28 |     10 | GPU
DEBUG 01-04 15:36:16.885859.885859 lmp.py:292]   Expert 14 |     11 | GPU
DEBUG 01-04 15:36:16.885787.885787 lmp.py:292]   Expert 38 |     11 | GPU
DEBUG 01-04 15:36:16.885714.885714 lmp.py:292]   Expert 39 |     11 | GPU
DEBUG 01-04 15:36:16.885404.885404 lmp.py:292]   Expert 15 |     12 | GPU
DEBUG 01-04 15:36:16.885093.885093 lmp.py:292]   Expert 21 |     12 | GPU
DEBUG 01-04 15:36:16.885782.885782 lmp.py:292]   Expert 26 |     12 | GPU
DEBUG 01-04 15:36:16.885233.885233 lmp.py:292]   Expert 57 |     12 | GPU
DEBUG 01-04 15:36:16.885923.885923 lmp.py:292]   Expert 23 |     14 | GPU
DEBUG 01-04 15:36:16.885612.885612 lmp.py:292]   Expert 49 |     14 | GPU
DEBUG 01-04 15:36:16.885301.885301 lmp.py:292]   Expert 62 |     23 | GPU
DEBUG 01-04 15:36:16.885990.885990 lmp.py:292]   Expert 36 |     25 | GPU
DEBUG 01-04 15:36:16.885872.885872 lmp.py:292]   Expert  0 |   1992 | GPU
DEBUG 01-04 15:36:16.885515.885515 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:16.885396.885396 lmp.py:292]   Expert  4 |   1992 | GPU
DEBUG 01-04 15:36:16.885278.885278 lmp.py:292]   Expert  1 |   1994 | GPU
DEBUG 01-04 15:36:16.885205.885205 lmp.py:292]   Expert  5 |   1997 | GPU
DEBUG 01-04 15:36:16.885133.885133 lmp.py:292]   Expert  2 |   2004 | GPU
DEBUG 01-04 15:36:16.885776.885776 lmp.py:293] 
DEBUG 01-04 15:36:16.885776.885776 lmp.py:293]   CPU total tokens: 75 (0.6%)
DEBUG 01-04 15:36:16.885419.885419 lmp.py:294]   GPU total tokens: 12213 (99.4%)
DEBUG 01-04 15:36:16.885592.885592 cuda_h.py:19] end experts_map_get cost 0.0014660358428955078 seconds
DEBUG 01-04 15:36:16.885712.885712 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.885965.885965 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.885075.885075 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.885847.885847 cuda_h.py:19] end allocate_cuda_memory cost 0.00029087066650390625 seconds
DEBUG 01-04 15:36:16.885313.885313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.885877.885877 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.886262.886262 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.886389.886389 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 00520537-f447-4542-abb4-ca11413bed19
DEBUG 01-04 15:36:16.886944.886944 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.887104.887104 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 00520537-f447-4542-abb4-ca11413bed19
DEBUG 01-04 15:36:16.888855.888855 cuda_h.py:19] end load_into_gpu_async cost 0.0021240711212158203 seconds
DEBUG 01-04 15:36:16.888604.888604 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.888691.888691 cuda_h.py:19] end restore_tensors2 cost 0.00038552284240722656 seconds
DEBUG 01-04 15:36:16.888859.888859 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003129243850708008 seconds
DEBUG 01-04 15:36:16.891523.891523 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005801677703857422 seconds
DEBUG 01-04 15:36:16.891875.891875 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.891375.891375 lmp.py:339] 
DEBUG 01-04 15:36:16.891375.891375 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:16.891596.891596 cuda_h.py:19] end cpu_experts_submit cost 0.00011539459228515625 seconds
DEBUG 01-04 15:36:16.891650.891650 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.902896.902896 mlpmodule.py:704] group tensors cost 0.010506153106689453 s
DEBUG 01-04 15:36:16.905689.905689 mlpmodule.py:742] pad cost 0.002148866653442383 s
DEBUG 01-04 15:36:16.905608.905608 mlpmodule.py:748] create cpu tensor cost 6.0558319091796875e-05 s
DEBUG 01-04 15:36:16.905558.905558 mlpmodule.py:753] move to cpu cost 4.267692565917969e-05 s
DEBUG 01-04 15:36:16.909665.909665 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:16.909411.909411 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.909560.909560 mlpmodule.py:774] group_w3 first element: 0.01251220703125
WARNING 01-04 15:36:16.909465.909465 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.912223.912223 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.912463.912463 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.916848.916848 mlpmodule.py:797] group einsum cost 0.011539697647094727 s
DEBUG 01-04 15:36:16.917858.917858 mlpmodule.py:805] cpy2cputensor cost 0.0001289844512939453 s
DEBUG 01-04 15:36:16.921265.921265 cuda_h.py:19] end wait_cetm_experts cost 0.02979302406311035 seconds
DEBUG 01-04 15:36:16.921785.921785 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.921267.921267 cuda_h.py:19] end gpu_sexperts cost 0.0005190372467041016 seconds
DEBUG 01-04 15:36:16.922833.922833 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-04 15:36:16.922278.922278 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-04 15:36:16.922810.922810 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.7670135498046875e-05 seconds
DEBUG 01-04 15:36:16.922480.922480 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 8.177757263183594e-05 seconds
DEBUG 01-04 15:36:16.922706.922706 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.922708.922708 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 00520537-f447-4542-abb4-ca11413bed19
DEBUG 01-04 15:36:16.922568.922568 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.922869.922869 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.922712.922712 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.927319.927319 cuda_h.py:19] end allocate_cuda_memory cost 0.004443168640136719 seconds
DEBUG 01-04 15:36:16.927090.927090 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.927521.927521 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.927543.927543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.927776.927776 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bad326fe-7004-4ea4-87c1-df39033177a5
DEBUG 01-04 15:36:16.927580.927580 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.932348.932348 client.py:127] Model loaded
DEBUG 01-04 15:36:16.932589.932589 cuda_h.py:19] end wait_experts cost 0.010307550430297852 seconds
DEBUG 01-04 15:36:16.932491.932491 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:16.932346.932346 lmp.py:384]   Computing 27 experts on GPU...
DEBUG 01-04 15:36:16.933969.933969 mlpmodule.py:531] gpu group tensors cost 0.0005166530609130859 s
INFO 01-04 15:36:16.933330.933330 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bad326fe-7004-4ea4-87c1-df39033177a5
DEBUG 01-04 15:36:16.933842.933842 cuda_h.py:19] end load_into_gpu_async cost 0.006417274475097656 seconds
DEBUG 01-04 15:36:16.933022.933022 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.933628.933628 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-04 15:36:16.933145.933145 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011196613311767578 seconds
INFO 01-04 15:36:16.934316.934316 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bad326fe-7004-4ea4-87c1-df39033177a5
DEBUG 01-04 15:36:16.935160.935160 mlpmodule.py:564] gpu pad cost 0.0024716854095458984 s
DEBUG 01-04 15:36:16.936826.936826 mlpmodule.py:662]  experts func einsum cost 0.044657230377197266 s
DEBUG 01-04 15:36:16.936139.936139 mlpmodule.py:582] gpu group einsum cost 0.0006647109985351562 s
DEBUG 01-04 15:36:16.939107.939107 mlpmodule.py:611] gpu experts func einsum cost 0.007008552551269531 s
DEBUG 01-04 15:36:16.939436.939436 cuda_h.py:19] end gpu_experts cost 0.007231950759887695 seconds
DEBUG 01-04 15:36:16.939430.939430 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:16.944510.944510 client.py:127] Model loaded
DEBUG 01-04 15:36:16.944360.944360 cuda_h.py:19] end sllm_worker_task cost 0.02199530601501465 seconds
DEBUG 01-04 15:36:16.944395.944395 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004647016525268555 seconds
DEBUG 01-04 15:36:16.944811.944811 cuda_h.py:19] end layer_moe_generate_18 cost 0.06162548065185547 seconds
DEBUG 01-04 15:36:16.944473.944473 lmp.py:207] -------------------------------- end layer 18 --------------------------------
DEBUG 01-04 15:36:16.944904.944904 lmp.py:169] -------------------------------- start layer 19 --------------------------------
DEBUG 01-04 15:36:16.944647.944647 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:16.945711.945711 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:16.948826.948826 cuda_h.py:19] end self_attn cost 0.002803325653076172 seconds
DEBUG 01-04 15:36:16.948468.948468 cuda_h.py:19] end iln_self_attn_paln cost 0.003524303436279297 seconds
DEBUG 01-04 15:36:16.948834.948834 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-04 15:36:16.948696.948696 cuda_h.py:10] start gate
DEBUG 01-04 15:36:16.949449.949449 cuda_h.py:19] end gate cost 0.0006940364837646484 seconds
DEBUG 01-04 15:36:16.949232.949232 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:16.949585.949585 lmp.py:281] 
DEBUG 01-04 15:36:16.949585.949585 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:16.949387.949387 lmp.py:282]   Total experts: 57
DEBUG 01-04 15:36:16.949990.949990 lmp.py:283]   CPU experts: 28 (49%)
DEBUG 01-04 15:36:16.949494.949494 lmp.py:284]   GPU experts: 29 (51%)
DEBUG 01-04 15:36:16.949091.949091 lmp.py:285] 
DEBUG 01-04 15:36:16.949091.949091 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:16.949403.949403 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:16.949245.949245 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:16.949842.949842 lmp.py:292]   Expert 22 |      1 | CPU
DEBUG 01-04 15:36:16.950484.950484 lmp.py:292]   Expert 23 |      1 | CPU
DEBUG 01-04 15:36:16.950651.950651 lmp.py:292]   Expert 59 |      1 | CPU
DEBUG 01-04 15:36:16.950294.950294 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:16.950460.950460 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:16.950864.950864 lmp.py:292]   Expert 14 |      2 | CPU
DEBUG 01-04 15:36:16.950269.950269 lmp.py:292]   Expert 19 |      2 | CPU
DEBUG 01-04 15:36:16.950673.950673 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:16.950840.950840 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:16.950483.950483 lmp.py:292]   Expert 32 |      2 | CPU
DEBUG 01-04 15:36:16.950079.950079 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:16.950199.950199 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:16.950796.950796 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:16.950677.950677 lmp.py:292]   Expert  8 |      3 | CPU
DEBUG 01-04 15:36:16.950843.950843 lmp.py:292]   Expert 25 |      3 | CPU
DEBUG 01-04 15:36:16.950009.950009 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:16.950414.950414 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:16.950580.950580 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:16.950746.950746 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:16.950912.950912 lmp.py:292]   Expert 54 |      3 | CPU
DEBUG 01-04 15:36:16.950078.950078 lmp.py:292]   Expert 57 |      3 | CPU
DEBUG 01-04 15:36:16.950483.950483 lmp.py:292]   Expert 62 |      3 | CPU
DEBUG 01-04 15:36:16.950411.950411 lmp.py:292]   Expert 24 |      4 | CPU
DEBUG 01-04 15:36:16.950577.950577 lmp.py:292]   Expert 39 |      4 | CPU
DEBUG 01-04 15:36:16.950981.950981 lmp.py:292]   Expert 17 |      5 | CPU
DEBUG 01-04 15:36:16.950148.950148 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:16.950552.950552 lmp.py:292]   Expert 48 |      5 | CPU
DEBUG 01-04 15:36:16.950195.950195 lmp.py:292]   Expert 53 |      5 | GPU
DEBUG 01-04 15:36:16.950838.950838 lmp.py:292]   Expert 58 |      5 | GPU
DEBUG 01-04 15:36:16.950481.950481 lmp.py:292]   Expert  9 |      6 | GPU
DEBUG 01-04 15:36:16.950124.950124 lmp.py:292]   Expert 16 |      6 | GPU
DEBUG 01-04 15:36:16.950257.950257 lmp.py:292]   Expert 46 |      6 | GPU
DEBUG 01-04 15:36:16.950708.950708 lmp.py:292]   Expert 63 |      6 | GPU
DEBUG 01-04 15:36:16.950921.950921 lmp.py:292]   Expert 13 |      7 | GPU
DEBUG 01-04 15:36:16.950133.950133 lmp.py:292]   Expert 21 |      7 | GPU
DEBUG 01-04 15:36:16.950346.950346 lmp.py:292]   Expert 27 |      7 | GPU
DEBUG 01-04 15:36:16.950558.950558 lmp.py:292]   Expert 61 |      7 | GPU
DEBUG 01-04 15:36:16.950532.950532 lmp.py:292]   Expert 40 |      8 | GPU
DEBUG 01-04 15:36:16.950745.950745 lmp.py:292]   Expert 45 |      9 | GPU
DEBUG 01-04 15:36:16.950957.950957 lmp.py:292]   Expert 47 |      9 | GPU
DEBUG 01-04 15:36:16.950931.950931 lmp.py:292]   Expert 50 |      9 | GPU
DEBUG 01-04 15:36:16.950097.950097 lmp.py:292]   Expert 31 |     10 | GPU
DEBUG 01-04 15:36:16.950263.950263 lmp.py:292]   Expert 36 |     10 | GPU
DEBUG 01-04 15:36:16.950714.950714 lmp.py:292]   Expert 41 |     10 | GPU
DEBUG 01-04 15:36:16.950642.950642 lmp.py:292]   Expert 51 |     10 | GPU
DEBUG 01-04 15:36:16.950854.950854 lmp.py:292]   Expert 11 |     12 | GPU
DEBUG 01-04 15:36:16.950067.950067 lmp.py:292]   Expert 10 |     14 | GPU
DEBUG 01-04 15:36:16.950518.950518 lmp.py:292]   Expert  7 |     15 | GPU
DEBUG 01-04 15:36:16.950492.950492 lmp.py:292]   Expert 38 |     15 | GPU
DEBUG 01-04 15:36:16.950704.950704 lmp.py:292]   Expert 29 |     26 | GPU
DEBUG 01-04 15:36:16.950917.950917 lmp.py:292]   Expert  5 |   1991 | GPU
DEBUG 01-04 15:36:16.950129.950129 lmp.py:292]   Expert  4 |   1994 | GPU
DEBUG 01-04 15:36:16.950580.950580 lmp.py:292]   Expert  0 |   2001 | GPU
DEBUG 01-04 15:36:16.950031.950031 lmp.py:292]   Expert  2 |   2001 | GPU
DEBUG 01-04 15:36:16.950005.950005 lmp.py:292]   Expert  1 |   2003 | GPU
DEBUG 01-04 15:36:16.950886.950886 lmp.py:292]   Expert  3 |   2006 | GPU
DEBUG 01-04 15:36:16.950006.950006 lmp.py:293] 
DEBUG 01-04 15:36:16.950006.950006 lmp.py:293]   CPU total tokens: 73 (0.6%)
DEBUG 01-04 15:36:16.950364.950364 lmp.py:294]   GPU total tokens: 12215 (99.4%)
DEBUG 01-04 15:36:16.950776.950776 cuda_h.py:19] end experts_map_get cost 0.0015647411346435547 seconds
DEBUG 01-04 15:36:16.951419.951419 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:16.951288.951288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.951319.951319 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.951633.951633 cuda_h.py:19] end allocate_cuda_memory cost 0.0002703666687011719 seconds
DEBUG 01-04 15:36:16.951337.951337 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.951855.951855 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.951002.951002 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.951605.951605 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a37d979-f712-4509-a5e8-d621f180756a
DEBUG 01-04 15:36:16.951512.951512 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:16.953390.953390 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a37d979-f712-4509-a5e8-d621f180756a
DEBUG 01-04 15:36:16.953034.953034 cuda_h.py:19] end load_into_gpu_async cost 0.00199127197265625 seconds
DEBUG 01-04 15:36:16.953591.953591 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:16.953108.953108 cuda_h.py:19] end restore_tensors2 cost 0.00034332275390625 seconds
DEBUG 01-04 15:36:16.954268.954268 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029478073120117188 seconds
DEBUG 01-04 15:36:16.956121.956121 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00571894645690918 seconds
DEBUG 01-04 15:36:16.956547.956547 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:16.956200.956200 lmp.py:339] 
DEBUG 01-04 15:36:16.956200.956200 lmp.py:339]   Computing 28 experts on CPU...
DEBUG 01-04 15:36:16.956950.956950 cuda_h.py:19] end cpu_experts_submit cost 0.00012636184692382812 seconds
DEBUG 01-04 15:36:16.957461.957461 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:16.963110.963110 mlpmodule.py:704] group tensors cost 0.006211042404174805 s
DEBUG 01-04 15:36:16.966997.966997 mlpmodule.py:742] pad cost 0.0021631717681884766 s
DEBUG 01-04 15:36:16.966094.966094 mlpmodule.py:748] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-04 15:36:16.966799.966799 mlpmodule.py:753] move to cpu cost 4.029273986816406e-05 s
DEBUG 01-04 15:36:16.970529.970529 mlpmodule.py:768] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-04 15:36:16.970004.970004 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:16.970061.970061 mlpmodule.py:774] group_w3 first element: 0.04736328125
WARNING 01-04 15:36:16.971721.971721 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:16.974725.974725 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:16.974211.974211 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:16.978635.978635 mlpmodule.py:797] group einsum cost 0.012223243713378906 s
DEBUG 01-04 15:36:16.979983.979983 mlpmodule.py:805] cpy2cputensor cost 0.00012803077697753906 s
DEBUG 01-04 15:36:16.983656.983656 cuda_h.py:19] end wait_cetm_experts cost 0.026357650756835938 seconds
DEBUG 01-04 15:36:16.983415.983415 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:16.984858.984858 cuda_h.py:19] end gpu_sexperts cost 0.0005252361297607422 seconds
DEBUG 01-04 15:36:16.984569.984569 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-04 15:36:16.984014.984014 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-04 15:36:16.984930.984930 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.838539123535156e-05 seconds
DEBUG 01-04 15:36:16.984793.984793 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 8.463859558105469e-05 seconds
DEBUG 01-04 15:36:16.984257.984257 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:16.984770.984770 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a37d979-f712-4509-a5e8-d621f180756a
DEBUG 01-04 15:36:16.984680.984680 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:16.984247.984247 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:16.984328.984328 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:16.989662.989662 cuda_h.py:19] end allocate_cuda_memory cost 0.004762411117553711 seconds
DEBUG 01-04 15:36:16.989195.989195 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:16.989263.989263 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:16.989960.989960 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:16.989531.989531 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44a63f88-cf90-45d2-a690-2f41a871d713
DEBUG 01-04 15:36:16.990224.990224 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:16.999061.999061 mlpmodule.py:662]  experts func einsum cost 0.04253530502319336 s
INFO 01-04 15:36:17.002808.002808 client.py:127] Model loaded
DEBUG 01-04 15:36:17.002192.002192 cuda_h.py:19] end wait_experts cost 0.017771482467651367 seconds
DEBUG 01-04 15:36:17.002307.002307 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.002760.002760 lmp.py:384]   Computing 29 experts on GPU...
INFO 01-04 15:36:17.003880.003880 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44a63f88-cf90-45d2-a690-2f41a871d713
DEBUG 01-04 15:36:17.003083.003083 cuda_h.py:19] end load_into_gpu_async cost 0.014005184173583984 seconds
DEBUG 01-04 15:36:17.003430.003430 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.004028.004028 cuda_h.py:19] end restore_tensors2 cost 0.00015878677368164062 seconds
DEBUG 01-04 15:36:17.004097.004097 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.019403934478759766 seconds
DEBUG 01-04 15:36:17.005886.005886 mlpmodule.py:531] gpu group tensors cost 0.003159761428833008 s
INFO 01-04 15:36:17.005316.005316 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44a63f88-cf90-45d2-a690-2f41a871d713
INFO 01-04 15:36:17.009688.009688 client.py:127] Model loaded
DEBUG 01-04 15:36:17.010712.010712 cuda_h.py:19] end sllm_worker_task cost 0.025163650512695312 seconds
DEBUG 01-04 15:36:17.012097.012097 mlpmodule.py:564] gpu pad cost 0.005992889404296875 s
DEBUG 01-04 15:36:17.013505.013505 mlpmodule.py:582] gpu group einsum cost 0.0010013580322265625 s
DEBUG 01-04 15:36:17.019366.019366 mlpmodule.py:611] gpu experts func einsum cost 0.016518115997314453 s
DEBUG 01-04 15:36:17.019273.019273 cuda_h.py:19] end gpu_experts cost 0.016893863677978516 seconds
DEBUG 01-04 15:36:17.019778.019778 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:17.019840.019840 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-04 15:36:17.019132.019132 cuda_h.py:19] end layer_moe_generate_19 cost 0.07135343551635742 seconds
DEBUG 01-04 15:36:17.020223.020223 lmp.py:207] -------------------------------- end layer 19 --------------------------------
DEBUG 01-04 15:36:17.020735.020735 lmp.py:169] -------------------------------- start layer 20 --------------------------------
DEBUG 01-04 15:36:17.020088.020088 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.021822.021822 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.024218.024218 cuda_h.py:19] end self_attn cost 0.0032241344451904297 seconds
DEBUG 01-04 15:36:17.024145.024145 cuda_h.py:19] end iln_self_attn_paln cost 0.00424647331237793 seconds
DEBUG 01-04 15:36:17.024372.024372 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-04 15:36:17.024142.024142 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.025129.025129 cuda_h.py:19] end gate cost 0.0007605552673339844 seconds
DEBUG 01-04 15:36:17.025641.025641 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.026528.026528 lmp.py:281] 
DEBUG 01-04 15:36:17.026528.026528 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.026138.026138 lmp.py:282]   Total experts: 52
DEBUG 01-04 15:36:17.026264.026264 lmp.py:283]   CPU experts: 26 (50%)
DEBUG 01-04 15:36:17.026292.026292 lmp.py:284]   GPU experts: 26 (50%)
DEBUG 01-04 15:36:17.026935.026935 lmp.py:285] 
DEBUG 01-04 15:36:17.026935.026935 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.026054.026054 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.026658.026658 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:17.026016.026016 lmp.py:292]   Expert 19 |      1 | CPU
DEBUG 01-04 15:36:17.026944.026944 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:17.026633.026633 lmp.py:292]   Expert 58 |      1 | CPU
DEBUG 01-04 15:36:17.026322.026322 lmp.py:292]   Expert 61 |      1 | CPU
DEBUG 01-04 15:36:17.026012.026012 lmp.py:292]   Expert  9 |      2 | CPU
DEBUG 01-04 15:36:17.026701.026701 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:17.026675.026675 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:17.026887.026887 lmp.py:292]   Expert 30 |      2 | CPU
DEBUG 01-04 15:36:17.026338.026338 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:17.026074.026074 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:17.026525.026525 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:17.026737.026737 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:17.026711.026711 lmp.py:292]   Expert 60 |      3 | CPU
DEBUG 01-04 15:36:17.026924.026924 lmp.py:292]   Expert 62 |      3 | CPU
DEBUG 01-04 15:36:17.026567.026567 lmp.py:292]   Expert 63 |      3 | CPU
DEBUG 01-04 15:36:17.026733.026733 lmp.py:292]   Expert 23 |      4 | CPU
DEBUG 01-04 15:36:17.026138.026138 lmp.py:292]   Expert 46 |      4 | CPU
DEBUG 01-04 15:36:17.026542.026542 lmp.py:292]   Expert 17 |      5 | CPU
DEBUG 01-04 15:36:17.026993.026993 lmp.py:292]   Expert 36 |      5 | CPU
DEBUG 01-04 15:36:17.026205.026205 lmp.py:292]   Expert 45 |      5 | CPU
DEBUG 01-04 15:36:17.026418.026418 lmp.py:292]   Expert 12 |      6 | CPU
DEBUG 01-04 15:36:17.026630.026630 lmp.py:292]   Expert 38 |      6 | CPU
DEBUG 01-04 15:36:17.026843.026843 lmp.py:292]   Expert 49 |      6 | CPU
DEBUG 01-04 15:36:17.026817.026817 lmp.py:292]   Expert 16 |      7 | CPU
DEBUG 01-04 15:36:17.026029.026029 lmp.py:292]   Expert 20 |      7 | CPU
DEBUG 01-04 15:36:17.026480.026480 lmp.py:292]   Expert 24 |      7 | GPU
DEBUG 01-04 15:36:17.026454.026454 lmp.py:292]   Expert 26 |      7 | GPU
DEBUG 01-04 15:36:17.026667.026667 lmp.py:292]   Expert 50 |      7 | GPU
DEBUG 01-04 15:36:17.026118.026118 lmp.py:292]   Expert 21 |      8 | GPU
DEBUG 01-04 15:36:17.026092.026092 lmp.py:292]   Expert 39 |      8 | GPU
DEBUG 01-04 15:36:17.026304.026304 lmp.py:292]   Expert 52 |     10 | GPU
DEBUG 01-04 15:36:17.026232.026232 lmp.py:292]   Expert 53 |     10 | GPU
DEBUG 01-04 15:36:17.026398.026398 lmp.py:292]   Expert 25 |     11 | GPU
DEBUG 01-04 15:36:17.026802.026802 lmp.py:292]   Expert 32 |     11 | GPU
DEBUG 01-04 15:36:17.026015.026015 lmp.py:292]   Expert 40 |     11 | GPU
DEBUG 01-04 15:36:17.026466.026466 lmp.py:292]   Expert 55 |     11 | GPU
DEBUG 01-04 15:36:17.026917.026917 lmp.py:292]   Expert 15 |     12 | GPU
DEBUG 01-04 15:36:17.026368.026368 lmp.py:292]   Expert 22 |     12 | GPU
DEBUG 01-04 15:36:17.026342.026342 lmp.py:292]   Expert 31 |     12 | GPU
DEBUG 01-04 15:36:17.026554.026554 lmp.py:292]   Expert 34 |     12 | GPU
DEBUG 01-04 15:36:17.026005.026005 lmp.py:292]   Expert 35 |     12 | GPU
DEBUG 01-04 15:36:17.026217.026217 lmp.py:292]   Expert 59 |     13 | GPU
DEBUG 01-04 15:36:17.026668.026668 lmp.py:292]   Expert 48 |     14 | GPU
DEBUG 01-04 15:36:17.026881.026881 lmp.py:292]   Expert 56 |     14 | GPU
DEBUG 01-04 15:36:17.026855.026855 lmp.py:292]   Expert 41 |     23 | GPU
DEBUG 01-04 15:36:17.026306.026306 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:17.026757.026757 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:17.026731.026731 lmp.py:292]   Expert  3 |   1995 | GPU
DEBUG 01-04 15:36:17.026943.026943 lmp.py:292]   Expert  2 |   1996 | GPU
DEBUG 01-04 15:36:17.027394.027394 lmp.py:292]   Expert  0 |   1998 | GPU
DEBUG 01-04 15:36:17.027368.027368 lmp.py:292]   Expert  4 |   2003 | GPU
DEBUG 01-04 15:36:17.027057.027057 lmp.py:293] 
DEBUG 01-04 15:36:17.027057.027057 lmp.py:293]   CPU total tokens: 88 (0.7%)
DEBUG 01-04 15:36:17.027462.027462 lmp.py:294]   GPU total tokens: 12200 (99.3%)
DEBUG 01-04 15:36:17.027350.027350 cuda_h.py:19] end experts_map_get cost 0.0013723373413085938 seconds
DEBUG 01-04 15:36:17.027231.027231 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.027299.027299 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.027483.027483 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.027495.027495 cuda_h.py:19] end allocate_cuda_memory cost 0.00032639503479003906 seconds
DEBUG 01-04 15:36:17.027821.027821 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.027816.027816 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.027347.027347 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.027474.027474 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 202be88b-ef83-4e24-8114-4668ee076e05
DEBUG 01-04 15:36:17.028865.028865 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.029044.029044 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 202be88b-ef83-4e24-8114-4668ee076e05
DEBUG 01-04 15:36:17.029026.029026 cuda_h.py:19] end load_into_gpu_async cost 0.002120494842529297 seconds
DEBUG 01-04 15:36:17.029060.029060 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.030960.030960 cuda_h.py:19] end restore_tensors2 cost 0.0003566741943359375 seconds
DEBUG 01-04 15:36:17.030882.030882 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031456947326660156 seconds
DEBUG 01-04 15:36:17.032272.032272 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0057239532470703125 seconds
DEBUG 01-04 15:36:17.032631.032631 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.033297.033297 lmp.py:339] 
DEBUG 01-04 15:36:17.033297.033297 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:17.033498.033498 cuda_h.py:19] end cpu_experts_submit cost 0.0001380443572998047 seconds
DEBUG 01-04 15:36:17.033532.033532 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.049033.049033 mlpmodule.py:704] group tensors cost 0.015825986862182617 s
DEBUG 01-04 15:36:17.052841.052841 mlpmodule.py:742] pad cost 0.001959085464477539 s
DEBUG 01-04 15:36:17.052415.052415 mlpmodule.py:748] create cpu tensor cost 6.031990051269531e-05 s
DEBUG 01-04 15:36:17.052035.052035 mlpmodule.py:753] move to cpu cost 4.8160552978515625e-05 s
DEBUG 01-04 15:36:17.055912.055912 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:17.055862.055862 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.055918.055918 mlpmodule.py:774] group_w3 first element: -0.00165557861328125
WARNING 01-04 15:36:17.056988.056988 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.059732.059732 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.059032.059032 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.062472.062472 mlpmodule.py:797] group einsum cost 0.01000356674194336 s
DEBUG 01-04 15:36:17.062771.062771 mlpmodule.py:805] cpy2cputensor cost 0.00011301040649414062 s
DEBUG 01-04 15:36:17.066537.066537 cuda_h.py:19] end wait_cetm_experts cost 0.03352212905883789 seconds
DEBUG 01-04 15:36:17.066289.066289 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.067785.067785 cuda_h.py:19] end gpu_sexperts cost 0.0005292892456054688 seconds
DEBUG 01-04 15:36:17.067065.067065 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-04 15:36:17.067511.067511 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-04 15:36:17.067281.067281 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.719329833984375e-05 seconds
DEBUG 01-04 15:36:17.067428.067428 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 8.249282836914062e-05 seconds
DEBUG 01-04 15:36:17.067608.067608 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.067656.067656 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 202be88b-ef83-4e24-8114-4668ee076e05
DEBUG 01-04 15:36:17.067384.067384 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.067845.067845 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.068238.068238 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.072498.072498 cuda_h.py:19] end allocate_cuda_memory cost 0.004137277603149414 seconds
DEBUG 01-04 15:36:17.072508.072508 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.072862.072862 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.072196.072196 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.072495.072495 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8623eda1-7667-4e08-b119-dba50be55997
DEBUG 01-04 15:36:17.072672.072672 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.073635.073635 client.py:127] Model loaded
DEBUG 01-04 15:36:17.073829.073829 cuda_h.py:19] end wait_experts cost 0.005781888961791992 seconds
DEBUG 01-04 15:36:17.073777.073777 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.073679.073679 lmp.py:384]   Computing 26 experts on GPU...
DEBUG 01-04 15:36:17.074145.074145 mlpmodule.py:531] gpu group tensors cost 0.0005788803100585938 s
INFO 01-04 15:36:17.074581.074581 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8623eda1-7667-4e08-b119-dba50be55997
DEBUG 01-04 15:36:17.074769.074769 cuda_h.py:19] end load_into_gpu_async cost 0.0019800662994384766 seconds
DEBUG 01-04 15:36:17.074333.074333 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.074343.074343 cuda_h.py:19] end restore_tensors2 cost 8.20159912109375e-05 seconds
DEBUG 01-04 15:36:17.074153.074153 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006571054458618164 seconds
INFO 01-04 15:36:17.075759.075759 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8623eda1-7667-4e08-b119-dba50be55997
DEBUG 01-04 15:36:17.076139.076139 mlpmodule.py:564] gpu pad cost 0.00274658203125 s
DEBUG 01-04 15:36:17.077002.077002 mlpmodule.py:582] gpu group einsum cost 0.0005440711975097656 s
DEBUG 01-04 15:36:17.080264.080264 mlpmodule.py:611] gpu experts func einsum cost 0.0073015689849853516 s
DEBUG 01-04 15:36:17.080009.080009 cuda_h.py:19] end gpu_experts cost 0.007478475570678711 seconds
DEBUG 01-04 15:36:17.081149.081149 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:17.081797.081797 mlpmodule.py:662]  experts func einsum cost 0.04837989807128906 s
INFO 01-04 15:36:17.085577.085577 client.py:127] Model loaded
DEBUG 01-04 15:36:17.085374.085374 cuda_h.py:19] end sllm_worker_task cost 0.01739215850830078 seconds
DEBUG 01-04 15:36:17.085601.085601 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0043718814849853516 seconds
DEBUG 01-04 15:36:17.085786.085786 cuda_h.py:19] end layer_moe_generate_20 cost 0.06076812744140625 seconds
DEBUG 01-04 15:36:17.085044.085044 lmp.py:207] -------------------------------- end layer 20 --------------------------------
DEBUG 01-04 15:36:17.085568.085568 lmp.py:169] -------------------------------- start layer 21 --------------------------------
DEBUG 01-04 15:36:17.085503.085503 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.086375.086375 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.089441.089441 cuda_h.py:19] end self_attn cost 0.0029058456420898438 seconds
DEBUG 01-04 15:36:17.089386.089386 cuda_h.py:19] end iln_self_attn_paln cost 0.0036039352416992188 seconds
DEBUG 01-04 15:36:17.089322.089322 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-04 15:36:17.089946.089946 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.090261.090261 cuda_h.py:19] end gate cost 0.0006880760192871094 seconds
DEBUG 01-04 15:36:17.090806.090806 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.090097.090097 lmp.py:281] 
DEBUG 01-04 15:36:17.090097.090097 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.090138.090138 lmp.py:282]   Total experts: 52
DEBUG 01-04 15:36:17.090980.090980 lmp.py:283]   CPU experts: 26 (50%)
DEBUG 01-04 15:36:17.090484.090484 lmp.py:284]   GPU experts: 26 (50%)
DEBUG 01-04 15:36:17.090842.090842 lmp.py:285] 
DEBUG 01-04 15:36:17.090842.090842 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.090677.090677 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.090042.090042 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:17.090400.090400 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:17.090043.090043 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:17.090448.090448 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:17.090852.090852 lmp.py:292]   Expert 14 |      2 | CPU
DEBUG 01-04 15:36:17.090018.090018 lmp.py:292]   Expert 18 |      2 | CPU
DEBUG 01-04 15:36:17.090423.090423 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:17.090589.090589 lmp.py:292]   Expert 57 |      2 | CPU
DEBUG 01-04 15:36:17.091755.091755 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:17.091921.091921 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:17.091088.091088 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:17.091446.091446 lmp.py:292]   Expert 40 |      3 | CPU
DEBUG 01-04 15:36:17.091089.091089 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:17.091970.091970 lmp.py:292]   Expert 61 |      3 | CPU
DEBUG 01-04 15:36:17.091613.091613 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:17.091779.091779 lmp.py:292]   Expert 10 |      4 | CPU
DEBUG 01-04 15:36:17.091661.091661 lmp.py:292]   Expert 38 |      4 | CPU
DEBUG 01-04 15:36:17.091065.091065 lmp.py:292]   Expert 39 |      4 | CPU
DEBUG 01-04 15:36:17.091185.091185 lmp.py:292]   Expert 46 |      4 | CPU
DEBUG 01-04 15:36:17.091828.091828 lmp.py:292]   Expert 48 |      4 | CPU
DEBUG 01-04 15:36:17.091471.091471 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:17.091114.091114 lmp.py:292]   Expert 23 |      5 | CPU
DEBUG 01-04 15:36:17.091519.091519 lmp.py:292]   Expert 25 |      5 | CPU
DEBUG 01-04 15:36:17.091162.091162 lmp.py:292]   Expert 30 |      5 | CPU
DEBUG 01-04 15:36:17.091043.091043 lmp.py:292]   Expert 53 |      5 | CPU
DEBUG 01-04 15:36:17.091686.091686 lmp.py:292]   Expert 12 |      6 | CPU
DEBUG 01-04 15:36:17.091329.091329 lmp.py:292]   Expert 41 |      7 | GPU
DEBUG 01-04 15:36:17.091926.091926 lmp.py:292]   Expert 55 |      7 | GPU
DEBUG 01-04 15:36:17.091092.091092 lmp.py:292]   Expert 11 |      8 | GPU
DEBUG 01-04 15:36:17.091258.091258 lmp.py:292]   Expert 31 |      8 | GPU
DEBUG 01-04 15:36:17.091947.091947 lmp.py:292]   Expert 59 |      8 | GPU
DEBUG 01-04 15:36:17.091636.091636 lmp.py:292]   Expert 15 |      9 | GPU
DEBUG 01-04 15:36:17.091564.091564 lmp.py:292]   Expert 24 |      9 | GPU
DEBUG 01-04 15:36:17.091730.091730 lmp.py:292]   Expert 16 |     10 | GPU
DEBUG 01-04 15:36:17.091420.091420 lmp.py:292]   Expert 29 |     10 | GPU
DEBUG 01-04 15:36:17.091347.091347 lmp.py:292]   Expert  7 |     11 | GPU
DEBUG 01-04 15:36:17.091467.091467 lmp.py:292]   Expert 17 |     11 | GPU
DEBUG 01-04 15:36:17.091348.091348 lmp.py:292]   Expert 22 |     11 | GPU
DEBUG 01-04 15:36:17.091991.091991 lmp.py:292]   Expert 35 |     12 | GPU
DEBUG 01-04 15:36:17.091111.091111 lmp.py:292]   Expert 42 |     12 | GPU
DEBUG 01-04 15:36:17.091516.091516 lmp.py:292]   Expert 43 |     12 | GPU
DEBUG 01-04 15:36:17.091205.091205 lmp.py:292]   Expert 47 |     12 | GPU
DEBUG 01-04 15:36:17.091371.091371 lmp.py:292]   Expert 45 |     14 | GPU
DEBUG 01-04 15:36:17.091061.091061 lmp.py:292]   Expert 21 |     15 | GPU
DEBUG 01-04 15:36:17.091988.091988 lmp.py:292]   Expert 36 |     19 | GPU
DEBUG 01-04 15:36:17.091678.091678 lmp.py:292]   Expert 62 |     24 | GPU
DEBUG 01-04 15:36:17.091367.091367 lmp.py:292]   Expert  1 |   1992 | GPU
DEBUG 01-04 15:36:17.091295.091295 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:17.091938.091938 lmp.py:292]   Expert  2 |   1993 | GPU
DEBUG 01-04 15:36:17.091342.091342 lmp.py:292]   Expert  4 |   1996 | GPU
DEBUG 01-04 15:36:17.091224.091224 lmp.py:292]   Expert  0 |   2001 | GPU
DEBUG 01-04 15:36:17.091867.091867 lmp.py:292]   Expert  5 |   2002 | GPU
DEBUG 01-04 15:36:17.091509.091509 lmp.py:293] 
DEBUG 01-04 15:36:17.091509.091509 lmp.py:293]   CPU total tokens: 83 (0.7%)
DEBUG 01-04 15:36:17.091629.091629 lmp.py:294]   GPU total tokens: 12205 (99.3%)
DEBUG 01-04 15:36:17.091756.091756 cuda_h.py:19] end experts_map_get cost 0.0014426708221435547 seconds
DEBUG 01-04 15:36:17.091114.091114 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.091414.091414 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.091669.091669 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.092720.092720 cuda_h.py:19] end allocate_cuda_memory cost 0.00028324127197265625 seconds
DEBUG 01-04 15:36:17.092046.092046 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.092578.092578 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.092109.092109 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.092235.092235 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5743f2a-f933-4fb7-8667-78dc61ff5ddf
DEBUG 01-04 15:36:17.092242.092242 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.094616.094616 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5743f2a-f933-4fb7-8667-78dc61ff5ddf
DEBUG 01-04 15:36:17.094369.094369 cuda_h.py:19] end load_into_gpu_async cost 0.0022513866424560547 seconds
DEBUG 01-04 15:36:17.094054.094054 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.095661.095661 cuda_h.py:19] end restore_tensors2 cost 0.0008730888366699219 seconds
DEBUG 01-04 15:36:17.095676.095676 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038573741912841797 seconds
DEBUG 01-04 15:36:17.098268.098268 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006545543670654297 seconds
DEBUG 01-04 15:36:17.098104.098104 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.098551.098551 lmp.py:339] 
DEBUG 01-04 15:36:17.098551.098551 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:17.098917.098917 cuda_h.py:19] end cpu_experts_submit cost 0.00011396408081054688 seconds
DEBUG 01-04 15:36:17.098210.098210 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.104572.104572 mlpmodule.py:704] group tensors cost 0.005544185638427734 s
DEBUG 01-04 15:36:17.106344.106344 mlpmodule.py:742] pad cost 0.0016674995422363281 s
DEBUG 01-04 15:36:17.106414.106414 mlpmodule.py:748] create cpu tensor cost 5.054473876953125e-05 s
DEBUG 01-04 15:36:17.106053.106053 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-04 15:36:17.110267.110267 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:17.110032.110032 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.110009.110009 mlpmodule.py:774] group_w3 first element: 0.072265625
WARNING 01-04 15:36:17.110165.110165 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.113940.113940 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.113710.113710 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.116660.116660 mlpmodule.py:797] group einsum cost 0.009959936141967773 s
DEBUG 01-04 15:36:17.117583.117583 mlpmodule.py:805] cpy2cputensor cost 0.00010848045349121094 s
DEBUG 01-04 15:36:17.121898.121898 cuda_h.py:19] end wait_cetm_experts cost 0.022471904754638672 seconds
DEBUG 01-04 15:36:17.121464.121464 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.121258.121258 cuda_h.py:19] end gpu_sexperts cost 0.000537872314453125 seconds
DEBUG 01-04 15:36:17.121678.121678 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-04 15:36:17.121077.121077 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-04 15:36:17.122470.122470 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.6716461181640625e-05 seconds
DEBUG 01-04 15:36:17.122809.122809 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 8.368492126464844e-05 seconds
DEBUG 01-04 15:36:17.122896.122896 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.122374.122374 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5743f2a-f933-4fb7-8667-78dc61ff5ddf
DEBUG 01-04 15:36:17.122771.122771 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.122848.122848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.122719.122719 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.127043.127043 cuda_h.py:19] end allocate_cuda_memory cost 0.0045070648193359375 seconds
DEBUG 01-04 15:36:17.127198.127198 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.127107.127107 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.127936.127936 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.127692.127692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 98c33c70-e05d-49c4-9e2a-9f78c73e94b9
DEBUG 01-04 15:36:17.127828.127828 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:17.136002.136002 mlpmodule.py:662]  experts func einsum cost 0.0377957820892334 s
INFO 01-04 15:36:17.137028.137028 client.py:127] Model loaded
DEBUG 01-04 15:36:17.137145.137145 cuda_h.py:19] end wait_experts cost 0.015299081802368164 seconds
DEBUG 01-04 15:36:17.137546.137546 cuda_h.py:10] start gpu_experts
INFO 01-04 15:36:17.137015.137015 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 98c33c70-e05d-49c4-9e2a-9f78c73e94b9
DEBUG 01-04 15:36:17.137741.137741 lmp.py:384]   Computing 26 experts on GPU...
DEBUG 01-04 15:36:17.137246.137246 cuda_h.py:19] end load_into_gpu_async cost 0.01066899299621582 seconds
DEBUG 01-04 15:36:17.138106.138106 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.138573.138573 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-04 15:36:17.138568.138568 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015899181365966797 seconds
DEBUG 01-04 15:36:17.138689.138689 mlpmodule.py:531] gpu group tensors cost 0.0007061958312988281 s
INFO 01-04 15:36:17.139226.139226 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 98c33c70-e05d-49c4-9e2a-9f78c73e94b9
DEBUG 01-04 15:36:17.140481.140481 mlpmodule.py:564] gpu pad cost 0.0017418861389160156 s
DEBUG 01-04 15:36:17.141838.141838 mlpmodule.py:582] gpu group einsum cost 0.0004994869232177734 s
DEBUG 01-04 15:36:17.144078.144078 mlpmodule.py:611] gpu experts func einsum cost 0.006191730499267578 s
DEBUG 01-04 15:36:17.144267.144267 cuda_h.py:19] end gpu_experts cost 0.006432056427001953 seconds
DEBUG 01-04 15:36:17.144791.144791 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:17.148338.148338 client.py:127] Model loaded
DEBUG 01-04 15:36:17.149912.149912 cuda_h.py:19] end sllm_worker_task cost 0.02661728858947754 seconds
DEBUG 01-04 15:36:17.149593.149593 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0048961639404296875 seconds
DEBUG 01-04 15:36:17.149929.149929 cuda_h.py:19] end layer_moe_generate_21 cost 0.06001710891723633 seconds
DEBUG 01-04 15:36:17.149827.149827 lmp.py:207] -------------------------------- end layer 21 --------------------------------
DEBUG 01-04 15:36:17.149451.149451 lmp.py:169] -------------------------------- start layer 22 --------------------------------
DEBUG 01-04 15:36:17.149908.149908 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.150979.150979 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.153967.153967 cuda_h.py:19] end self_attn cost 0.002953767776489258 seconds
DEBUG 01-04 15:36:17.153655.153655 cuda_h.py:19] end iln_self_attn_paln cost 0.0036787986755371094 seconds
DEBUG 01-04 15:36:17.153876.153876 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-04 15:36:17.153354.153354 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.154629.154629 cuda_h.py:19] end gate cost 0.0006592273712158203 seconds
DEBUG 01-04 15:36:17.154266.154266 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.154008.154008 lmp.py:281] 
DEBUG 01-04 15:36:17.154008.154008 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.154002.154002 lmp.py:282]   Total experts: 51
DEBUG 01-04 15:36:17.154844.154844 lmp.py:283]   CPU experts: 25 (49%)
DEBUG 01-04 15:36:17.154348.154348 lmp.py:284]   GPU experts: 26 (51%)
DEBUG 01-04 15:36:17.155183.155183 lmp.py:285] 
DEBUG 01-04 15:36:17.155183.155183 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.155495.155495 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.155860.155860 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:17.155457.155457 lmp.py:292]   Expert 21 |      1 | CPU
DEBUG 01-04 15:36:17.155100.155100 lmp.py:292]   Expert 39 |      1 | CPU
DEBUG 01-04 15:36:17.155504.155504 lmp.py:292]   Expert 41 |      1 | CPU
DEBUG 01-04 15:36:17.155671.155671 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:17.155075.155075 lmp.py:292]   Expert 25 |      2 | CPU
DEBUG 01-04 15:36:17.155718.155718 lmp.py:292]   Expert 30 |      2 | CPU
DEBUG 01-04 15:36:17.155884.155884 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:17.155050.155050 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:17.155217.155217 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:17.155621.155621 lmp.py:292]   Expert 45 |      3 | CPU
DEBUG 01-04 15:36:17.155787.155787 lmp.py:292]   Expert 57 |      3 | CPU
DEBUG 01-04 15:36:17.155477.155477 lmp.py:292]   Expert 24 |      4 | CPU
DEBUG 01-04 15:36:17.155404.155404 lmp.py:292]   Expert 42 |      4 | CPU
DEBUG 01-04 15:36:17.155094.155094 lmp.py:292]   Expert 44 |      4 | CPU
DEBUG 01-04 15:36:17.155021.155021 lmp.py:292]   Expert 15 |      5 | CPU
DEBUG 01-04 15:36:17.155187.155187 lmp.py:292]   Expert 19 |      5 | CPU
DEBUG 01-04 15:36:17.155354.155354 lmp.py:292]   Expert 46 |      5 | CPU
DEBUG 01-04 15:36:17.155520.155520 lmp.py:292]   Expert 50 |      5 | CPU
DEBUG 01-04 15:36:17.155639.155639 lmp.py:292]   Expert 54 |      5 | CPU
DEBUG 01-04 15:36:17.155759.155759 lmp.py:292]   Expert 34 |      6 | CPU
DEBUG 01-04 15:36:17.155356.155356 lmp.py:292]   Expert 35 |      6 | CPU
DEBUG 01-04 15:36:17.155522.155522 lmp.py:292]   Expert 58 |      6 | CPU
DEBUG 01-04 15:36:17.155211.155211 lmp.py:292]   Expert 10 |      7 | CPU
DEBUG 01-04 15:36:17.155378.155378 lmp.py:292]   Expert 23 |      7 | CPU
DEBUG 01-04 15:36:17.155544.155544 lmp.py:292]   Expert 26 |      7 | GPU
DEBUG 01-04 15:36:17.155471.155471 lmp.py:292]   Expert 28 |      7 | GPU
DEBUG 01-04 15:36:17.155399.155399 lmp.py:292]   Expert 31 |      7 | GPU
DEBUG 01-04 15:36:17.155088.155088 lmp.py:292]   Expert 47 |      7 | GPU
DEBUG 01-04 15:36:17.155255.155255 lmp.py:292]   Expert 48 |      7 | GPU
DEBUG 01-04 15:36:17.155421.155421 lmp.py:292]   Expert 59 |      7 | GPU
DEBUG 01-04 15:36:17.155587.155587 lmp.py:292]   Expert  9 |      8 | GPU
DEBUG 01-04 15:36:17.155753.155753 lmp.py:292]   Expert 38 |      9 | GPU
DEBUG 01-04 15:36:17.155681.155681 lmp.py:292]   Expert 62 |      9 | GPU
DEBUG 01-04 15:36:17.155847.155847 lmp.py:292]   Expert  8 |     10 | GPU
DEBUG 01-04 15:36:17.155775.155775 lmp.py:292]   Expert 20 |     10 | GPU
DEBUG 01-04 15:36:17.155179.155179 lmp.py:292]   Expert 29 |     10 | GPU
DEBUG 01-04 15:36:17.155776.155776 lmp.py:292]   Expert 53 |     10 | GPU
DEBUG 01-04 15:36:17.155372.155372 lmp.py:292]   Expert 40 |     11 | GPU
DEBUG 01-04 15:36:17.155969.155969 lmp.py:292]   Expert 56 |     11 | GPU
DEBUG 01-04 15:36:17.155566.155566 lmp.py:292]   Expert 18 |     13 | GPU
DEBUG 01-04 15:36:17.155209.155209 lmp.py:292]   Expert 27 |     14 | GPU
DEBUG 01-04 15:36:17.155375.155375 lmp.py:292]   Expert 55 |     14 | GPU
DEBUG 01-04 15:36:17.155270.155270 lmp.py:292]   Expert 17 |     15 | GPU
DEBUG 01-04 15:36:17.155959.155959 lmp.py:292]   Expert 14 |     21 | GPU
DEBUG 01-04 15:36:17.155410.155410 lmp.py:292]   Expert  0 |   1991 | GPU
DEBUG 01-04 15:36:17.155861.155861 lmp.py:292]   Expert  1 |   1993 | GPU
DEBUG 01-04 15:36:17.155312.155312 lmp.py:292]   Expert  3 |   1996 | GPU
DEBUG 01-04 15:36:17.155286.155286 lmp.py:292]   Expert  2 |   1999 | GPU
DEBUG 01-04 15:36:17.155498.155498 lmp.py:292]   Expert  4 |   2003 | GPU
DEBUG 01-04 15:36:17.155903.155903 lmp.py:292]   Expert  5 |   2007 | GPU
DEBUG 01-04 15:36:17.155023.155023 lmp.py:293] 
DEBUG 01-04 15:36:17.155023.155023 lmp.py:293]   CPU total tokens: 92 (0.7%)
DEBUG 01-04 15:36:17.155619.155619 lmp.py:294]   GPU total tokens: 12196 (99.3%)
DEBUG 01-04 15:36:17.155507.155507 cuda_h.py:19] end experts_map_get cost 0.0014469623565673828 seconds
DEBUG 01-04 15:36:17.156150.156150 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.156496.156496 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.156845.156845 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.156121.156121 cuda_h.py:19] end allocate_cuda_memory cost 0.0003097057342529297 seconds
DEBUG 01-04 15:36:17.156024.156024 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.156926.156926 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.156980.156980 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.156014.156014 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fed6772b-03bc-4464-a6dd-7d086113753e
DEBUG 01-04 15:36:17.156313.156313 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.158954.158954 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fed6772b-03bc-4464-a6dd-7d086113753e
DEBUG 01-04 15:36:17.158482.158482 cuda_h.py:19] end load_into_gpu_async cost 0.0015490055084228516 seconds
DEBUG 01-04 15:36:17.158418.158418 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.158606.158606 cuda_h.py:19] end restore_tensors2 cost 0.00038433074951171875 seconds
DEBUG 01-04 15:36:17.158568.158568 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026988983154296875 seconds
DEBUG 01-04 15:36:17.161040.161040 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053675174713134766 seconds
DEBUG 01-04 15:36:17.161591.161591 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.161614.161614 lmp.py:339] 
DEBUG 01-04 15:36:17.161614.161614 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:17.161901.161901 cuda_h.py:19] end cpu_experts_submit cost 0.00012826919555664062 seconds
DEBUG 01-04 15:36:17.161923.161923 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.174344.174344 mlpmodule.py:704] group tensors cost 0.012233734130859375 s
DEBUG 01-04 15:36:17.175090.175090 mlpmodule.py:742] pad cost 0.0010750293731689453 s
DEBUG 01-04 15:36:17.175497.175497 mlpmodule.py:748] create cpu tensor cost 3.5762786865234375e-05 s
DEBUG 01-04 15:36:17.175055.175055 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-04 15:36:17.179721.179721 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:17.179314.179314 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.179786.179786 mlpmodule.py:774] group_w3 first element: -0.025390625
WARNING 01-04 15:36:17.179730.179730 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.182603.182603 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.182425.182425 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.186778.186778 mlpmodule.py:797] group einsum cost 0.010448217391967773 s
DEBUG 01-04 15:36:17.186991.186991 mlpmodule.py:805] cpy2cputensor cost 0.00010538101196289062 s
DEBUG 01-04 15:36:17.190969.190969 cuda_h.py:19] end wait_cetm_experts cost 0.028370141983032227 seconds
DEBUG 01-04 15:36:17.190171.190171 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.190358.190358 cuda_h.py:19] end gpu_sexperts cost 0.0005671977996826172 seconds
DEBUG 01-04 15:36:17.190328.190328 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-04 15:36:17.191601.191601 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-04 15:36:17.191499.191499 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 4.7206878662109375e-05 seconds
DEBUG 01-04 15:36:17.191282.191282 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.00010776519775390625 seconds
DEBUG 01-04 15:36:17.191521.191521 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.191821.191821 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fed6772b-03bc-4464-a6dd-7d086113753e
DEBUG 01-04 15:36:17.191086.191086 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.191427.191427 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.191536.191536 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.195273.195273 cuda_h.py:19] end allocate_cuda_memory cost 0.0033702850341796875 seconds
DEBUG 01-04 15:36:17.195522.195522 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.195622.195622 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.195068.195068 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.195585.195585 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc36e73c-74f6-4bc8-996c-dc5f2ce2cb89
DEBUG 01-04 15:36:17.195575.195575 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.200209.200209 client.py:127] Model loaded
DEBUG 01-04 15:36:17.200396.200396 cuda_h.py:19] end wait_experts cost 0.009277820587158203 seconds
DEBUG 01-04 15:36:17.200675.200675 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.200193.200193 lmp.py:384]   Computing 26 experts on GPU...
DEBUG 01-04 15:36:17.201651.201651 mlpmodule.py:531] gpu group tensors cost 0.0005428791046142578 s
INFO 01-04 15:36:17.201725.201725 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc36e73c-74f6-4bc8-996c-dc5f2ce2cb89
DEBUG 01-04 15:36:17.201820.201820 cuda_h.py:19] end load_into_gpu_async cost 0.00628972053527832 seconds
DEBUG 01-04 15:36:17.201053.201053 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.201010.201010 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-04 15:36:17.201773.201773 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010074853897094727 seconds
INFO 01-04 15:36:17.202557.202557 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc36e73c-74f6-4bc8-996c-dc5f2ce2cb89
DEBUG 01-04 15:36:17.203542.203542 mlpmodule.py:662]  experts func einsum cost 0.04150247573852539 s
DEBUG 01-04 15:36:17.203549.203549 mlpmodule.py:564] gpu pad cost 0.00243377685546875 s
DEBUG 01-04 15:36:17.204412.204412 mlpmodule.py:582] gpu group einsum cost 0.00037550926208496094 s
DEBUG 01-04 15:36:17.206257.206257 mlpmodule.py:611] gpu experts func einsum cost 0.005799293518066406 s
DEBUG 01-04 15:36:17.206532.206532 cuda_h.py:19] end gpu_experts cost 0.0059757232666015625 seconds
DEBUG 01-04 15:36:17.206334.206334 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:17.212344.212344 client.py:127] Model loaded
DEBUG 01-04 15:36:17.212088.212088 cuda_h.py:19] end sllm_worker_task cost 0.02072000503540039 seconds
DEBUG 01-04 15:36:17.212527.212527 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005731105804443359 seconds
DEBUG 01-04 15:36:17.212957.212957 cuda_h.py:19] end layer_moe_generate_22 cost 0.058769941329956055 seconds
DEBUG 01-04 15:36:17.212221.212221 lmp.py:207] -------------------------------- end layer 22 --------------------------------
DEBUG 01-04 15:36:17.212460.212460 lmp.py:169] -------------------------------- start layer 23 --------------------------------
DEBUG 01-04 15:36:17.212249.212249 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.213662.213662 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.215822.215822 cuda_h.py:19] end self_attn cost 0.002348184585571289 seconds
DEBUG 01-04 15:36:17.215387.215387 cuda_h.py:19] end iln_self_attn_paln cost 0.002918243408203125 seconds
DEBUG 01-04 15:36:17.215270.215270 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-04 15:36:17.215887.215887 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.216596.216596 cuda_h.py:19] end gate cost 0.000560760498046875 seconds
DEBUG 01-04 15:36:17.216313.216313 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.216428.216428 lmp.py:281] 
DEBUG 01-04 15:36:17.216428.216428 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.216800.216800 lmp.py:282]   Total experts: 55
DEBUG 01-04 15:36:17.216542.216542 lmp.py:283]   CPU experts: 27 (49%)
DEBUG 01-04 15:36:17.216900.216900 lmp.py:284]   GPU experts: 28 (51%)
DEBUG 01-04 15:36:17.216113.216113 lmp.py:285] 
DEBUG 01-04 15:36:17.216113.216113 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.216564.216564 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.216406.216406 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:17.216049.216049 lmp.py:292]   Expert 53 |      1 | CPU
DEBUG 01-04 15:36:17.216215.216215 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:17.216904.216904 lmp.py:292]   Expert  6 |      2 | CPU
DEBUG 01-04 15:36:17.216878.216878 lmp.py:292]   Expert 23 |      2 | CPU
DEBUG 01-04 15:36:17.216852.216852 lmp.py:292]   Expert 31 |      2 | CPU
DEBUG 01-04 15:36:17.216588.216588 lmp.py:292]   Expert 45 |      2 | CPU
DEBUG 01-04 15:36:17.216323.216323 lmp.py:292]   Expert 52 |      2 | CPU
DEBUG 01-04 15:36:17.216821.216821 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:17.216556.216556 lmp.py:292]   Expert  8 |      3 | CPU
DEBUG 01-04 15:36:17.216530.216530 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:17.217027.217027 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:17.217002.217002 lmp.py:292]   Expert 25 |      3 | CPU
DEBUG 01-04 15:36:17.217976.217976 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:17.217188.217188 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:17.217401.217401 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:17.217613.217613 lmp.py:292]   Expert 51 |      4 | CPU
DEBUG 01-04 15:36:17.217825.217825 lmp.py:292]   Expert 58 |      4 | CPU
DEBUG 01-04 15:36:17.217561.217561 lmp.py:292]   Expert 17 |      5 | CPU
DEBUG 01-04 15:36:17.217297.217297 lmp.py:292]   Expert 24 |      5 | CPU
DEBUG 01-04 15:36:17.217555.217555 lmp.py:292]   Expert 36 |      5 | CPU
DEBUG 01-04 15:36:17.217053.217053 lmp.py:292]   Expert 39 |      5 | CPU
DEBUG 01-04 15:36:17.217311.217311 lmp.py:292]   Expert 42 |      5 | CPU
DEBUG 01-04 15:36:17.217047.217047 lmp.py:292]   Expert 47 |      5 | CPU
DEBUG 01-04 15:36:17.217306.217306 lmp.py:292]   Expert 61 |      5 | CPU
DEBUG 01-04 15:36:17.217042.217042 lmp.py:292]   Expert  7 |      6 | CPU
DEBUG 01-04 15:36:17.217300.217300 lmp.py:292]   Expert 44 |      6 | CPU
DEBUG 01-04 15:36:17.217751.217751 lmp.py:292]   Expert  9 |      7 | GPU
DEBUG 01-04 15:36:17.217725.217725 lmp.py:292]   Expert 18 |      7 | GPU
DEBUG 01-04 15:36:17.217415.217415 lmp.py:292]   Expert 41 |      7 | GPU
DEBUG 01-04 15:36:17.217627.217627 lmp.py:292]   Expert 50 |      7 | GPU
DEBUG 01-04 15:36:17.217886.217886 lmp.py:292]   Expert 48 |      8 | GPU
DEBUG 01-04 15:36:17.217621.217621 lmp.py:292]   Expert 56 |      8 | GPU
DEBUG 01-04 15:36:17.217880.217880 lmp.py:292]   Expert 59 |      8 | GPU
DEBUG 01-04 15:36:17.217377.217377 lmp.py:292]   Expert 63 |      8 | GPU
DEBUG 01-04 15:36:17.217636.217636 lmp.py:292]   Expert 14 |      9 | GPU
DEBUG 01-04 15:36:17.217133.217133 lmp.py:292]   Expert 20 |      9 | GPU
DEBUG 01-04 15:36:17.217631.217631 lmp.py:292]   Expert 10 |     10 | GPU
DEBUG 01-04 15:36:17.217366.217366 lmp.py:292]   Expert 12 |     10 | GPU
DEBUG 01-04 15:36:17.217863.217863 lmp.py:292]   Expert 30 |     10 | GPU
DEBUG 01-04 15:36:17.217599.217599 lmp.py:292]   Expert 57 |     10 | GPU
DEBUG 01-04 15:36:17.217004.217004 lmp.py:292]   Expert 15 |     12 | GPU
DEBUG 01-04 15:36:17.217216.217216 lmp.py:292]   Expert 21 |     12 | GPU
DEBUG 01-04 15:36:17.217429.217429 lmp.py:292]   Expert 54 |     12 | GPU
DEBUG 01-04 15:36:17.217879.217879 lmp.py:292]   Expert 32 |     13 | GPU
DEBUG 01-04 15:36:17.217092.217092 lmp.py:292]   Expert 37 |     13 | GPU
DEBUG 01-04 15:36:17.217066.217066 lmp.py:292]   Expert 40 |     14 | GPU
DEBUG 01-04 15:36:17.217563.217563 lmp.py:292]   Expert 11 |     15 | GPU
DEBUG 01-04 15:36:17.217060.217060 lmp.py:292]   Expert 33 |     26 | GPU
DEBUG 01-04 15:36:17.217796.217796 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:17.217532.217532 lmp.py:292]   Expert  5 |   1991 | GPU
DEBUG 01-04 15:36:17.217804.217804 lmp.py:292]   Expert  1 |   1992 | GPU
DEBUG 01-04 15:36:17.217586.217586 lmp.py:292]   Expert  0 |   1995 | GPU
DEBUG 01-04 15:36:17.217606.217606 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:17.217865.217865 lmp.py:292]   Expert  3 |   1997 | GPU
DEBUG 01-04 15:36:17.217316.217316 lmp.py:293] 
DEBUG 01-04 15:36:17.217316.217316 lmp.py:293]   CPU total tokens: 92 (0.7%)
DEBUG 01-04 15:36:17.217767.217767 lmp.py:294]   GPU total tokens: 12196 (99.3%)
DEBUG 01-04 15:36:17.217271.217271 cuda_h.py:19] end experts_map_get cost 0.0012755393981933594 seconds
DEBUG 01-04 15:36:17.217483.217483 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.217544.217544 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.217370.217370 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.218863.218863 cuda_h.py:19] end allocate_cuda_memory cost 0.0002646446228027344 seconds
DEBUG 01-04 15:36:17.218183.218183 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.218316.218316 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.218317.218317 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.218298.218298 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d9be8502-31af-43a5-898b-1ca61ea4bccb
DEBUG 01-04 15:36:17.218981.218981 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.220437.220437 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d9be8502-31af-43a5-898b-1ca61ea4bccb
DEBUG 01-04 15:36:17.220611.220611 cuda_h.py:19] end load_into_gpu_async cost 0.002071380615234375 seconds
DEBUG 01-04 15:36:17.220811.220811 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.220559.220559 cuda_h.py:19] end restore_tensors2 cost 0.00034928321838378906 seconds
DEBUG 01-04 15:36:17.220097.220097 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003019571304321289 seconds
DEBUG 01-04 15:36:17.223584.223584 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053517818450927734 seconds
DEBUG 01-04 15:36:17.223228.223228 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.223615.223615 lmp.py:339] 
DEBUG 01-04 15:36:17.223615.223615 lmp.py:339]   Computing 27 experts on CPU...
DEBUG 01-04 15:36:17.223497.223497 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-04 15:36:17.223883.223883 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.230369.230369 mlpmodule.py:704] group tensors cost 0.0066912174224853516 s
DEBUG 01-04 15:36:17.233077.233077 mlpmodule.py:742] pad cost 0.002359151840209961 s
DEBUG 01-04 15:36:17.233274.233274 mlpmodule.py:748] create cpu tensor cost 5.841255187988281e-05 s
DEBUG 01-04 15:36:17.233939.233939 mlpmodule.py:753] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-04 15:36:17.237640.237640 mlpmodule.py:768] group_w3: shape=torch.Size([27, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=77856768
DEBUG 01-04 15:36:17.237100.237100 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.238241.238241 mlpmodule.py:774] group_w3 first element: -0.0054931640625
WARNING 01-04 15:36:17.238370.238370 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.241625.241625 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.241526.241526 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.245593.245593 mlpmodule.py:797] group einsum cost 0.011323690414428711 s
DEBUG 01-04 15:36:17.245554.245554 mlpmodule.py:805] cpy2cputensor cost 8.988380432128906e-05 s
DEBUG 01-04 15:36:17.249764.249764 cuda_h.py:19] end wait_cetm_experts cost 0.025673866271972656 seconds
DEBUG 01-04 15:36:17.249038.249038 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.249433.249433 cuda_h.py:19] end gpu_sexperts cost 0.0004570484161376953 seconds
DEBUG 01-04 15:36:17.249329.249329 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-04 15:36:17.249767.249767 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-04 15:36:17.249094.249094 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.314018249511719e-05 seconds
DEBUG 01-04 15:36:17.249665.249665 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.033348083496094e-05 seconds
DEBUG 01-04 15:36:17.249222.249222 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.249455.249455 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d9be8502-31af-43a5-898b-1ca61ea4bccb
DEBUG 01-04 15:36:17.250586.250586 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.250868.250868 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.250526.250526 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.253999.253999 cuda_h.py:19] end allocate_cuda_memory cost 0.0036063194274902344 seconds
DEBUG 01-04 15:36:17.254684.254684 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.254752.254752 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.254588.254588 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.254920.254920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f2cf8ae5-aa43-413e-a485-da5e1bf0099a
DEBUG 01-04 15:36:17.254208.254208 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:17.262196.262196 mlpmodule.py:662]  experts func einsum cost 0.039283037185668945 s
INFO 01-04 15:36:17.264686.264686 client.py:127] Model loaded
DEBUG 01-04 15:36:17.265953.265953 cuda_h.py:19] end wait_experts cost 0.015080690383911133 seconds
DEBUG 01-04 15:36:17.265987.265987 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.265783.265783 lmp.py:384]   Computing 28 experts on GPU...
DEBUG 01-04 15:36:17.265529.265529 mlpmodule.py:531] gpu group tensors cost 0.0004875659942626953 s
INFO 01-04 15:36:17.265730.265730 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f2cf8ae5-aa43-413e-a485-da5e1bf0099a
DEBUG 01-04 15:36:17.265904.265904 cuda_h.py:19] end load_into_gpu_async cost 0.011884689331054688 seconds
DEBUG 01-04 15:36:17.265415.265415 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.266921.266921 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-04 15:36:17.266154.266154 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015836477279663086 seconds
INFO 01-04 15:36:17.266052.266052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f2cf8ae5-aa43-413e-a485-da5e1bf0099a
DEBUG 01-04 15:36:17.267704.267704 mlpmodule.py:564] gpu pad cost 0.002009153366088867 s
DEBUG 01-04 15:36:17.268537.268537 mlpmodule.py:582] gpu group einsum cost 0.00047516822814941406 s
DEBUG 01-04 15:36:17.270753.270753 mlpmodule.py:611] gpu experts func einsum cost 0.005566835403442383 s
DEBUG 01-04 15:36:17.270372.270372 cuda_h.py:19] end gpu_experts cost 0.005737781524658203 seconds
DEBUG 01-04 15:36:17.270174.270174 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:17.278545.278545 client.py:127] Model loaded
DEBUG 01-04 15:36:17.278209.278209 cuda_h.py:19] end sllm_worker_task cost 0.028203725814819336 seconds
DEBUG 01-04 15:36:17.278073.278073 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.007620811462402344 seconds
DEBUG 01-04 15:36:17.278045.278045 cuda_h.py:19] end layer_moe_generate_23 cost 0.0628652572631836 seconds
DEBUG 01-04 15:36:17.278653.278653 lmp.py:207] -------------------------------- end layer 23 --------------------------------
DEBUG 01-04 15:36:17.278608.278608 lmp.py:169] -------------------------------- start layer 24 --------------------------------
DEBUG 01-04 15:36:17.278304.278304 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.279175.279175 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.281543.281543 cuda_h.py:19] end self_attn cost 0.002430438995361328 seconds
DEBUG 01-04 15:36:17.281347.281347 cuda_h.py:19] end iln_self_attn_paln cost 0.003022432327270508 seconds
DEBUG 01-04 15:36:17.281421.281421 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-04 15:36:17.282515.282515 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.282787.282787 cuda_h.py:19] end gate cost 0.0005507469177246094 seconds
DEBUG 01-04 15:36:17.282444.282444 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.282638.282638 lmp.py:281] 
DEBUG 01-04 15:36:17.282638.282638 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.282202.282202 lmp.py:282]   Total experts: 53
DEBUG 01-04 15:36:17.282375.282375 lmp.py:283]   CPU experts: 26 (49%)
DEBUG 01-04 15:36:17.282210.282210 lmp.py:284]   GPU experts: 27 (51%)
DEBUG 01-04 15:36:17.283899.283899 lmp.py:285] 
DEBUG 01-04 15:36:17.283899.283899 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.283304.283304 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.283000.283000 lmp.py:292]   Expert  7 |      1 | CPU
DEBUG 01-04 15:36:17.283404.283404 lmp.py:292]   Expert  9 |      1 | CPU
DEBUG 01-04 15:36:17.283855.283855 lmp.py:292]   Expert 16 |      1 | CPU
DEBUG 01-04 15:36:17.283829.283829 lmp.py:292]   Expert 42 |      1 | CPU
DEBUG 01-04 15:36:17.283803.283803 lmp.py:292]   Expert 43 |      1 | CPU
DEBUG 01-04 15:36:17.283731.283731 lmp.py:292]   Expert 49 |      1 | CPU
DEBUG 01-04 15:36:17.283659.283659 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:17.283110.283110 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:17.283322.283322 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:17.283296.283296 lmp.py:292]   Expert 25 |      2 | CPU
DEBUG 01-04 15:36:17.283032.283032 lmp.py:292]   Expert 35 |      2 | CPU
DEBUG 01-04 15:36:17.283767.283767 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:17.283026.283026 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:17.283762.283762 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:17.283021.283021 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:17.283518.283518 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:17.283538.283538 lmp.py:292]   Expert 51 |      3 | CPU
DEBUG 01-04 15:36:17.283797.283797 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:17.283294.283294 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:17.283745.283745 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:17.283481.283481 lmp.py:292]   Expert 32 |      4 | CPU
DEBUG 01-04 15:36:17.283216.283216 lmp.py:292]   Expert 40 |      4 | CPU
DEBUG 01-04 15:36:17.283429.283429 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:17.283641.283641 lmp.py:292]   Expert 18 |      5 | CPU
DEBUG 01-04 15:36:17.283139.283139 lmp.py:292]   Expert 31 |      5 | CPU
DEBUG 01-04 15:36:17.283874.283874 lmp.py:292]   Expert 61 |      5 | CPU
DEBUG 01-04 15:36:17.283895.283895 lmp.py:292]   Expert 30 |      6 | GPU
DEBUG 01-04 15:36:17.283630.283630 lmp.py:292]   Expert 41 |      6 | GPU
DEBUG 01-04 15:36:17.283651.283651 lmp.py:292]   Expert  8 |      7 | GPU
DEBUG 01-04 15:36:17.283386.283386 lmp.py:292]   Expert 10 |      7 | GPU
DEBUG 01-04 15:36:17.283883.283883 lmp.py:292]   Expert 20 |      7 | GPU
DEBUG 01-04 15:36:17.283381.283381 lmp.py:292]   Expert 21 |      7 | GPU
DEBUG 01-04 15:36:17.283401.283401 lmp.py:292]   Expert 23 |      7 | GPU
DEBUG 01-04 15:36:17.283090.283090 lmp.py:292]   Expert 53 |      7 | GPU
DEBUG 01-04 15:36:17.283780.283780 lmp.py:292]   Expert 59 |      7 | GPU
DEBUG 01-04 15:36:17.283992.283992 lmp.py:292]   Expert 14 |      8 | GPU
DEBUG 01-04 15:36:17.283204.283204 lmp.py:292]   Expert 11 |     10 | GPU
DEBUG 01-04 15:36:17.283417.283417 lmp.py:292]   Expert 50 |     10 | GPU
DEBUG 01-04 15:36:17.283914.283914 lmp.py:292]   Expert 37 |     12 | GPU
DEBUG 01-04 15:36:17.283934.283934 lmp.py:292]   Expert 15 |     15 | GPU
DEBUG 01-04 15:36:17.283432.283432 lmp.py:292]   Expert 24 |     16 | GPU
DEBUG 01-04 15:36:17.283690.283690 lmp.py:292]   Expert 39 |     16 | GPU
DEBUG 01-04 15:36:17.283188.283188 lmp.py:292]   Expert 36 |     17 | GPU
DEBUG 01-04 15:36:17.283446.283446 lmp.py:292]   Expert 46 |     17 | GPU
DEBUG 01-04 15:36:17.283944.283944 lmp.py:292]   Expert 33 |     18 | GPU
DEBUG 01-04 15:36:17.283964.283964 lmp.py:292]   Expert 12 |     20 | GPU
DEBUG 01-04 15:36:17.283223.283223 lmp.py:292]   Expert 27 |     25 | GPU
DEBUG 01-04 15:36:17.283720.283720 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:17.283456.283456 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:17.283668.283668 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:17.283119.283119 lmp.py:292]   Expert  4 |   1994 | GPU
DEBUG 01-04 15:36:17.283332.283332 lmp.py:292]   Expert  0 |   1998 | GPU
DEBUG 01-04 15:36:17.283782.283782 lmp.py:292]   Expert  2 |   2009 | GPU
DEBUG 01-04 15:36:17.283756.283756 lmp.py:293] 
DEBUG 01-04 15:36:17.283756.283756 lmp.py:293]   CPU total tokens: 67 (0.5%)
DEBUG 01-04 15:36:17.283207.283207 lmp.py:294]   GPU total tokens: 12221 (99.5%)
DEBUG 01-04 15:36:17.283711.283711 cuda_h.py:19] end experts_map_get cost 0.0012235641479492188 seconds
DEBUG 01-04 15:36:17.283401.283401 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.283362.283362 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.284631.284631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.284589.284589 cuda_h.py:19] end allocate_cuda_memory cost 0.0002722740173339844 seconds
DEBUG 01-04 15:36:17.284293.284293 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.284857.284857 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.284335.284335 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.284747.284747 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b40734ed-6c3d-4e60-80ac-9f30783ad77d
DEBUG 01-04 15:36:17.284469.284469 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.286086.286086 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b40734ed-6c3d-4e60-80ac-9f30783ad77d
DEBUG 01-04 15:36:17.286223.286223 cuda_h.py:19] end load_into_gpu_async cost 0.0022194385528564453 seconds
DEBUG 01-04 15:36:17.286670.286670 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.287520.287520 cuda_h.py:19] end restore_tensors2 cost 0.0003867149353027344 seconds
DEBUG 01-04 15:36:17.287673.287673 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033326148986816406 seconds
DEBUG 01-04 15:36:17.289790.289790 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0056688785552978516 seconds
DEBUG 01-04 15:36:17.289288.289288 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.289244.289244 lmp.py:339] 
DEBUG 01-04 15:36:17.289244.289244 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:17.289842.289842 cuda_h.py:19] end cpu_experts_submit cost 0.0001010894775390625 seconds
DEBUG 01-04 15:36:17.289705.289705 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.301322.301322 mlpmodule.py:704] group tensors cost 0.011959314346313477 s
DEBUG 01-04 15:36:17.304405.304405 mlpmodule.py:742] pad cost 0.0017299652099609375 s
DEBUG 01-04 15:36:17.304621.304621 mlpmodule.py:748] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-04 15:36:17.304406.304406 mlpmodule.py:753] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-04 15:36:17.307905.307905 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:17.307676.307676 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.308334.308334 mlpmodule.py:774] group_w3 first element: -0.0108642578125
WARNING 01-04 15:36:17.308224.308224 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.311788.311788 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.311729.311729 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.314881.314881 mlpmodule.py:797] group einsum cost 0.009581327438354492 s
DEBUG 01-04 15:36:17.314412.314412 mlpmodule.py:805] cpy2cputensor cost 9.608268737792969e-05 s
DEBUG 01-04 15:36:17.318956.318956 cuda_h.py:19] end wait_cetm_experts cost 0.028226375579833984 seconds
DEBUG 01-04 15:36:17.318277.318277 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.318227.318227 cuda_h.py:19] end gpu_sexperts cost 0.00044727325439453125 seconds
DEBUG 01-04 15:36:17.318593.318593 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-04 15:36:17.318224.318224 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-04 15:36:17.318743.318743 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.361701965332031e-05 seconds
DEBUG 01-04 15:36:17.318651.318651 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.534027099609375e-05 seconds
DEBUG 01-04 15:36:17.318970.318970 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.318441.318441 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b40734ed-6c3d-4e60-80ac-9f30783ad77d
DEBUG 01-04 15:36:17.319964.319964 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.319266.319266 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.319414.319414 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.323404.323404 cuda_h.py:19] end allocate_cuda_memory cost 0.004013538360595703 seconds
DEBUG 01-04 15:36:17.323693.323693 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.323575.323575 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.323770.323770 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.323301.323301 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3dc8b57c-b6c8-4861-ac04-80af18b6f8cc
DEBUG 01-04 15:36:17.323464.323464 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.330599.330599 client.py:127] Model loaded
DEBUG 01-04 15:36:17.330396.330396 cuda_h.py:19] end wait_experts cost 0.01169586181640625 seconds
DEBUG 01-04 15:36:17.330913.330913 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.330808.330808 lmp.py:384]   Computing 27 experts on GPU...
DEBUG 01-04 15:36:17.331946.331946 mlpmodule.py:531] gpu group tensors cost 0.000492095947265625 s
INFO 01-04 15:36:17.331803.331803 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3dc8b57c-b6c8-4861-ac04-80af18b6f8cc
DEBUG 01-04 15:36:17.331799.331799 cuda_h.py:19] end load_into_gpu_async cost 0.008067607879638672 seconds
DEBUG 01-04 15:36:17.331078.331078 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.331704.331704 cuda_h.py:19] end restore_tensors2 cost 7.915496826171875e-05 seconds
DEBUG 01-04 15:36:17.331275.331275 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012499332427978516 seconds
INFO 01-04 15:36:17.332759.332759 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3dc8b57c-b6c8-4861-ac04-80af18b6f8cc
DEBUG 01-04 15:36:17.332738.332738 mlpmodule.py:662]  experts func einsum cost 0.04258990287780762 s
DEBUG 01-04 15:36:17.333237.333237 mlpmodule.py:564] gpu pad cost 0.0023026466369628906 s
DEBUG 01-04 15:36:17.334130.334130 mlpmodule.py:582] gpu group einsum cost 0.00046253204345703125 s
DEBUG 01-04 15:36:17.336330.336330 mlpmodule.py:611] gpu experts func einsum cost 0.005830287933349609 s
DEBUG 01-04 15:36:17.336154.336154 cuda_h.py:19] end gpu_experts cost 0.0059795379638671875 seconds
DEBUG 01-04 15:36:17.336056.336056 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:17.342525.342525 client.py:127] Model loaded
DEBUG 01-04 15:36:17.342461.342461 cuda_h.py:19] end sllm_worker_task cost 0.023044347763061523 seconds
DEBUG 01-04 15:36:17.342542.342542 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005597591400146484 seconds
DEBUG 01-04 15:36:17.342216.342216 cuda_h.py:19] end layer_moe_generate_24 cost 0.060492515563964844 seconds
DEBUG 01-04 15:36:17.342195.342195 lmp.py:207] -------------------------------- end layer 24 --------------------------------
DEBUG 01-04 15:36:17.342911.342911 lmp.py:169] -------------------------------- start layer 25 --------------------------------
DEBUG 01-04 15:36:17.342462.342462 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.342875.342875 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.345733.345733 cuda_h.py:19] end self_attn cost 0.002440929412841797 seconds
DEBUG 01-04 15:36:17.345703.345703 cuda_h.py:19] end iln_self_attn_paln cost 0.003027677536010742 seconds
DEBUG 01-04 15:36:17.345732.345732 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-04 15:36:17.345018.345018 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.346640.346640 cuda_h.py:19] end gate cost 0.0005657672882080078 seconds
DEBUG 01-04 15:36:17.346053.346053 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.346080.346080 lmp.py:281] 
DEBUG 01-04 15:36:17.346080.346080 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.346499.346499 lmp.py:282]   Total experts: 51
DEBUG 01-04 15:36:17.346526.346526 lmp.py:283]   CPU experts: 25 (49%)
DEBUG 01-04 15:36:17.346169.346169 lmp.py:284]   GPU experts: 26 (51%)
DEBUG 01-04 15:36:17.346904.346904 lmp.py:285] 
DEBUG 01-04 15:36:17.346904.346904 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.346640.346640 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.346098.346098 lmp.py:292]   Expert 21 |      1 | CPU
DEBUG 01-04 15:36:17.346264.346264 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:17.346476.346476 lmp.py:292]   Expert 39 |      1 | CPU
DEBUG 01-04 15:36:17.346450.346450 lmp.py:292]   Expert 56 |      1 | CPU
DEBUG 01-04 15:36:17.346709.346709 lmp.py:292]   Expert 10 |      2 | CPU
DEBUG 01-04 15:36:17.346491.346491 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:17.346273.346273 lmp.py:292]   Expert 31 |      2 | CPU
DEBUG 01-04 15:36:17.346293.346293 lmp.py:292]   Expert 42 |      2 | CPU
DEBUG 01-04 15:36:17.347075.347075 lmp.py:292]   Expert 43 |      2 | CPU
DEBUG 01-04 15:36:17.347096.347096 lmp.py:292]   Expert 48 |      2 | CPU
DEBUG 01-04 15:36:17.347116.347116 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:17.347660.347660 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:17.347441.347441 lmp.py:292]   Expert 45 |      3 | CPU
DEBUG 01-04 15:36:17.347223.347223 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:17.347244.347244 lmp.py:292]   Expert  7 |      4 | CPU
DEBUG 01-04 15:36:17.347218.347218 lmp.py:292]   Expert 16 |      4 | CPU
DEBUG 01-04 15:36:17.347430.347430 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:17.347166.347166 lmp.py:292]   Expert 23 |      4 | CPU
DEBUG 01-04 15:36:17.347663.347663 lmp.py:292]   Expert 35 |      4 | CPU
DEBUG 01-04 15:36:17.347637.347637 lmp.py:292]   Expert 41 |      4 | CPU
DEBUG 01-04 15:36:17.347419.347419 lmp.py:292]   Expert 50 |      4 | CPU
DEBUG 01-04 15:36:17.347963.347963 lmp.py:292]   Expert 55 |      4 | CPU
DEBUG 01-04 15:36:17.347745.347745 lmp.py:292]   Expert  6 |      5 | CPU
DEBUG 01-04 15:36:17.347050.347050 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:17.347070.347070 lmp.py:292]   Expert 40 |      5 | CPU
DEBUG 01-04 15:36:17.347614.347614 lmp.py:292]   Expert 61 |      5 | GPU
DEBUG 01-04 15:36:17.347396.347396 lmp.py:292]   Expert 13 |      6 | GPU
DEBUG 01-04 15:36:17.347939.347939 lmp.py:292]   Expert 38 |      6 | GPU
DEBUG 01-04 15:36:17.347483.347483 lmp.py:292]   Expert 20 |      7 | GPU
DEBUG 01-04 15:36:17.347026.347026 lmp.py:292]   Expert 15 |      8 | GPU
DEBUG 01-04 15:36:17.347762.347762 lmp.py:292]   Expert 46 |      8 | GPU
DEBUG 01-04 15:36:17.347497.347497 lmp.py:292]   Expert 49 |      8 | GPU
DEBUG 01-04 15:36:17.347756.347756 lmp.py:292]   Expert 57 |     10 | GPU
DEBUG 01-04 15:36:17.347969.347969 lmp.py:292]   Expert 59 |     10 | GPU
DEBUG 01-04 15:36:17.347512.347512 lmp.py:292]   Expert 54 |     11 | GPU
DEBUG 01-04 15:36:17.347056.347056 lmp.py:292]   Expert 28 |     12 | GPU
DEBUG 01-04 15:36:17.347838.347838 lmp.py:292]   Expert 30 |     12 | GPU
DEBUG 01-04 15:36:17.347620.347620 lmp.py:292]   Expert 58 |     12 | GPU
DEBUG 01-04 15:36:17.347163.347163 lmp.py:292]   Expert  8 |     13 | GPU
DEBUG 01-04 15:36:17.347945.347945 lmp.py:292]   Expert 19 |     16 | GPU
DEBUG 01-04 15:36:17.347250.347250 lmp.py:292]   Expert 60 |     16 | GPU
DEBUG 01-04 15:36:17.347032.347032 lmp.py:292]   Expert 26 |     17 | GPU
DEBUG 01-04 15:36:17.347814.347814 lmp.py:292]   Expert 17 |     19 | GPU
DEBUG 01-04 15:36:17.347596.347596 lmp.py:292]   Expert 63 |     23 | GPU
DEBUG 01-04 15:36:17.347140.347140 lmp.py:292]   Expert 25 |     33 | GPU
DEBUG 01-04 15:36:17.347398.347398 lmp.py:292]   Expert  0 |   1991 | GPU
DEBUG 01-04 15:36:17.347180.347180 lmp.py:292]   Expert  2 |   1992 | GPU
DEBUG 01-04 15:36:17.347439.347439 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:17.347175.347175 lmp.py:292]   Expert  1 |   1994 | GPU
DEBUG 01-04 15:36:17.347434.347434 lmp.py:292]   Expert  4 |   1994 | GPU
DEBUG 01-04 15:36:17.347646.347646 lmp.py:292]   Expert  5 |   1998 | GPU
DEBUG 01-04 15:36:17.347620.347620 lmp.py:293] 
DEBUG 01-04 15:36:17.347620.347620 lmp.py:293]   CPU total tokens: 75 (0.6%)
DEBUG 01-04 15:36:17.347117.347117 lmp.py:294]   GPU total tokens: 12213 (99.4%)
DEBUG 01-04 15:36:17.347429.347429 cuda_h.py:19] end experts_map_get cost 0.0011286735534667969 seconds
DEBUG 01-04 15:36:17.347165.347165 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.347696.347696 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.347276.347276 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.348073.348073 cuda_h.py:19] end allocate_cuda_memory cost 0.00024199485778808594 seconds
DEBUG 01-04 15:36:17.348247.348247 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.348381.348381 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.348859.348859 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.348316.348316 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45ae1fa5-cdd4-4725-bd23-0ff104b14947
DEBUG 01-04 15:36:17.348337.348337 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.350761.350761 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45ae1fa5-cdd4-4725-bd23-0ff104b14947
DEBUG 01-04 15:36:17.350560.350560 cuda_h.py:19] end load_into_gpu_async cost 0.002187013626098633 seconds
DEBUG 01-04 15:36:17.350093.350093 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.351675.351675 cuda_h.py:19] end restore_tensors2 cost 0.0005056858062744141 seconds
DEBUG 01-04 15:36:17.351067.351067 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033435821533203125 seconds
DEBUG 01-04 15:36:17.353872.353872 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005653858184814453 seconds
DEBUG 01-04 15:36:17.353953.353953 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.353631.353631 lmp.py:339] 
DEBUG 01-04 15:36:17.353631.353631 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:17.353613.353613 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-04 15:36:17.353707.353707 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.360875.360875 mlpmodule.py:704] group tensors cost 0.006257772445678711 s
DEBUG 01-04 15:36:17.362880.362880 mlpmodule.py:742] pad cost 0.0020294189453125 s
DEBUG 01-04 15:36:17.363700.363700 mlpmodule.py:748] create cpu tensor cost 6.079673767089844e-05 s
DEBUG 01-04 15:36:17.363935.363935 mlpmodule.py:753] move to cpu cost 4.2438507080078125e-05 s
DEBUG 01-04 15:36:17.366711.366711 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:17.366953.366953 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.366366.366366 mlpmodule.py:774] group_w3 first element: -0.01397705078125
WARNING 01-04 15:36:17.366251.366251 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.369443.369443 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.370603.370603 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.372935.372935 mlpmodule.py:797] group einsum cost 0.009617328643798828 s
DEBUG 01-04 15:36:17.373797.373797 mlpmodule.py:805] cpy2cputensor cost 8.106231689453125e-05 s
DEBUG 01-04 15:36:17.376166.376166 cuda_h.py:19] end wait_cetm_experts cost 0.022936582565307617 seconds
DEBUG 01-04 15:36:17.376752.376752 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.377919.377919 cuda_h.py:19] end gpu_sexperts cost 0.0005550384521484375 seconds
DEBUG 01-04 15:36:17.377358.377358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-04 15:36:17.377069.377069 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-04 15:36:17.377298.377298 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.173683166503906e-05 seconds
DEBUG 01-04 15:36:17.377915.377915 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 8.893013000488281e-05 seconds
DEBUG 01-04 15:36:17.377664.377664 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.377566.377566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45ae1fa5-cdd4-4725-bd23-0ff104b14947
DEBUG 01-04 15:36:17.377551.377551 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.377044.377044 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.377364.377364 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.381749.381749 cuda_h.py:19] end allocate_cuda_memory cost 0.003754138946533203 seconds
DEBUG 01-04 15:36:17.382796.382796 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.382705.382705 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.382623.382623 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.382809.382809 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 83d436c5-08a5-4376-878a-08cfcf4d1d24
DEBUG 01-04 15:36:17.382376.382376 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:17.390540.390540 mlpmodule.py:662]  experts func einsum cost 0.03640246391296387 s
INFO 01-04 15:36:17.392284.392284 client.py:127] Model loaded
DEBUG 01-04 15:36:17.393328.393328 cuda_h.py:19] end wait_experts cost 0.015436410903930664 seconds
DEBUG 01-04 15:36:17.393099.393099 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.393823.393823 lmp.py:384]   Computing 26 experts on GPU...
INFO 01-04 15:36:17.393367.393367 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 83d436c5-08a5-4376-878a-08cfcf4d1d24
DEBUG 01-04 15:36:17.393687.393687 cuda_h.py:19] end load_into_gpu_async cost 0.011713981628417969 seconds
DEBUG 01-04 15:36:17.393866.393866 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.394995.394995 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-04 15:36:17.394036.394036 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01614832878112793 seconds
DEBUG 01-04 15:36:17.394576.394576 mlpmodule.py:531] gpu group tensors cost 0.0009791851043701172 s
INFO 01-04 15:36:17.394163.394163 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 83d436c5-08a5-4376-878a-08cfcf4d1d24
DEBUG 01-04 15:36:17.395122.395122 mlpmodule.py:564] gpu pad cost 0.0013995170593261719 s
DEBUG 01-04 15:36:17.396783.396783 mlpmodule.py:582] gpu group einsum cost 0.0004894733428955078 s
DEBUG 01-04 15:36:17.398356.398356 mlpmodule.py:611] gpu experts func einsum cost 0.0054874420166015625 s
DEBUG 01-04 15:36:17.398432.398432 cuda_h.py:19] end gpu_experts cost 0.00572967529296875 seconds
DEBUG 01-04 15:36:17.399380.399380 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:17.404184.404184 client.py:127] Model loaded
DEBUG 01-04 15:36:17.404597.404597 cuda_h.py:19] end sllm_worker_task cost 0.02660536766052246 seconds
DEBUG 01-04 15:36:17.404149.404149 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005521297454833984 seconds
DEBUG 01-04 15:36:17.404697.404697 cuda_h.py:19] end layer_moe_generate_25 cost 0.05886125564575195 seconds
DEBUG 01-04 15:36:17.404921.404921 lmp.py:207] -------------------------------- end layer 25 --------------------------------
DEBUG 01-04 15:36:17.404591.404591 lmp.py:169] -------------------------------- start layer 26 --------------------------------
DEBUG 01-04 15:36:17.404287.404287 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.405767.405767 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.407396.407396 cuda_h.py:19] end self_attn cost 0.0025148391723632812 seconds
DEBUG 01-04 15:36:17.408968.408968 cuda_h.py:19] end iln_self_attn_paln cost 0.0031061172485351562 seconds
DEBUG 01-04 15:36:17.408758.408758 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-04 15:36:17.408044.408044 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.408939.408939 cuda_h.py:19] end gate cost 0.0005841255187988281 seconds
DEBUG 01-04 15:36:17.408815.408815 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.409479.409479 lmp.py:281] 
DEBUG 01-04 15:36:17.409479.409479 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.409804.409804 lmp.py:282]   Total experts: 50
DEBUG 01-04 15:36:17.409785.409785 lmp.py:283]   CPU experts: 25 (50%)
DEBUG 01-04 15:36:17.409143.409143 lmp.py:284]   GPU experts: 25 (50%)
DEBUG 01-04 15:36:17.409356.409356 lmp.py:285] 
DEBUG 01-04 15:36:17.409356.409356 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.409045.409045 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.409887.409887 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:17.409007.409007 lmp.py:292]   Expert 26 |      1 | CPU
DEBUG 01-04 15:36:17.409411.409411 lmp.py:292]   Expert 45 |      1 | CPU
DEBUG 01-04 15:36:17.409339.409339 lmp.py:292]   Expert 49 |      1 | CPU
DEBUG 01-04 15:36:17.409552.409552 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:17.409287.409287 lmp.py:292]   Expert 59 |      1 | CPU
DEBUG 01-04 15:36:17.409023.409023 lmp.py:292]   Expert  8 |      2 | CPU
DEBUG 01-04 15:36:17.409759.409759 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:17.409494.409494 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:17.409230.409230 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:17.409965.409965 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:17.409939.409939 lmp.py:292]   Expert 41 |      2 | CPU
DEBUG 01-04 15:36:17.409437.409437 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:17.409411.409411 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:17.409908.409908 lmp.py:292]   Expert 32 |      3 | CPU
DEBUG 01-04 15:36:17.409644.409644 lmp.py:292]   Expert 47 |      3 | CPU
DEBUG 01-04 15:36:17.409902.409902 lmp.py:292]   Expert 61 |      3 | CPU
DEBUG 01-04 15:36:17.409876.409876 lmp.py:292]   Expert 62 |      3 | CPU
DEBUG 01-04 15:36:17.409089.409089 lmp.py:292]   Expert 23 |      4 | CPU
DEBUG 01-04 15:36:17.409778.409778 lmp.py:292]   Expert 38 |      4 | CPU
DEBUG 01-04 15:36:17.409467.409467 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:17.409395.409395 lmp.py:292]   Expert  6 |      5 | CPU
DEBUG 01-04 15:36:17.409144.409144 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:17.409642.409642 lmp.py:292]   Expert 25 |      6 | CPU
DEBUG 01-04 15:36:17.409662.409662 lmp.py:292]   Expert 29 |      6 | CPU
DEBUG 01-04 15:36:17.409921.409921 lmp.py:292]   Expert 46 |      6 | GPU
DEBUG 01-04 15:36:17.409941.409941 lmp.py:292]   Expert 33 |      7 | GPU
DEBUG 01-04 15:36:17.409961.409961 lmp.py:292]   Expert 16 |      8 | GPU
DEBUG 01-04 15:36:17.409982.409982 lmp.py:292]   Expert 18 |      8 | GPU
DEBUG 01-04 15:36:17.409241.409241 lmp.py:292]   Expert 31 |      8 | GPU
DEBUG 01-04 15:36:17.409261.409261 lmp.py:292]   Expert 37 |      8 | GPU
DEBUG 01-04 15:36:17.409281.409281 lmp.py:292]   Expert 39 |      8 | GPU
DEBUG 01-04 15:36:17.409255.409255 lmp.py:292]   Expert 11 |     10 | GPU
DEBUG 01-04 15:36:17.409514.409514 lmp.py:292]   Expert 44 |     10 | GPU
DEBUG 01-04 15:36:17.409488.409488 lmp.py:292]   Expert 42 |     11 | GPU
DEBUG 01-04 15:36:17.409701.409701 lmp.py:292]   Expert 22 |     13 | GPU
DEBUG 01-04 15:36:17.409913.409913 lmp.py:292]   Expert 35 |     14 | GPU
DEBUG 01-04 15:36:17.409649.409649 lmp.py:292]   Expert 36 |     15 | GPU
DEBUG 01-04 15:36:17.409669.409669 lmp.py:292]   Expert 48 |     15 | GPU
DEBUG 01-04 15:36:17.409690.409690 lmp.py:292]   Expert 52 |     16 | GPU
DEBUG 01-04 15:36:17.409710.409710 lmp.py:292]   Expert 40 |     21 | GPU
DEBUG 01-04 15:36:17.409969.409969 lmp.py:292]   Expert 63 |     21 | GPU
DEBUG 01-04 15:36:17.409227.409227 lmp.py:292]   Expert 10 |     27 | GPU
DEBUG 01-04 15:36:17.409248.409248 lmp.py:292]   Expert 50 |     29 | GPU
DEBUG 01-04 15:36:17.409507.409507 lmp.py:292]   Expert  0 |   1991 | GPU
DEBUG 01-04 15:36:17.409004.409004 lmp.py:292]   Expert  1 |   1992 | GPU
DEBUG 01-04 15:36:17.409024.409024 lmp.py:292]   Expert  2 |   1994 | GPU
DEBUG 01-04 15:36:17.409283.409283 lmp.py:292]   Expert  3 |   1994 | GPU
DEBUG 01-04 15:36:17.409542.409542 lmp.py:292]   Expert  4 |   1996 | GPU
DEBUG 01-04 15:36:17.410754.410754 lmp.py:292]   Expert  5 |   1997 | GPU
DEBUG 01-04 15:36:17.410920.410920 lmp.py:293] 
DEBUG 01-04 15:36:17.410920.410920 lmp.py:293]   CPU total tokens: 69 (0.6%)
DEBUG 01-04 15:36:17.410325.410325 lmp.py:294]   GPU total tokens: 12219 (99.4%)
DEBUG 01-04 15:36:17.410306.410306 cuda_h.py:19] end experts_map_get cost 0.001177072525024414 seconds
DEBUG 01-04 15:36:17.410995.410995 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.410195.410195 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.410013.410013 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.410864.410864 cuda_h.py:19] end allocate_cuda_memory cost 0.00024509429931640625 seconds
DEBUG 01-04 15:36:17.410230.410230 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.410840.410840 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.410841.410841 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.410061.410061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80d59d3a-e97e-49fe-a28e-94d689a00639
DEBUG 01-04 15:36:17.410034.410034 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.412849.412849 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80d59d3a-e97e-49fe-a28e-94d689a00639
DEBUG 01-04 15:36:17.412748.412748 cuda_h.py:19] end load_into_gpu_async cost 0.002161264419555664 seconds
DEBUG 01-04 15:36:17.412426.412426 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.413269.413269 cuda_h.py:19] end restore_tensors2 cost 0.00038433074951171875 seconds
DEBUG 01-04 15:36:17.413230.413230 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032007694244384766 seconds
DEBUG 01-04 15:36:17.415935.415935 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0053026676177978516 seconds
DEBUG 01-04 15:36:17.415049.415049 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.415436.415436 lmp.py:339] 
DEBUG 01-04 15:36:17.415436.415436 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:17.415272.415272 cuda_h.py:19] end cpu_experts_submit cost 0.00010180473327636719 seconds
DEBUG 01-04 15:36:17.415134.415134 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.427107.427107 mlpmodule.py:704] group tensors cost 0.011894702911376953 s
DEBUG 01-04 15:36:17.429766.429766 mlpmodule.py:742] pad cost 0.0011518001556396484 s
DEBUG 01-04 15:36:17.429617.429617 mlpmodule.py:748] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-04 15:36:17.429460.429460 mlpmodule.py:753] move to cpu cost 2.6941299438476562e-05 s
DEBUG 01-04 15:36:17.433632.433632 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:17.433893.433893 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.433942.433942 mlpmodule.py:774] group_w3 first element: 0.0145263671875
WARNING 01-04 15:36:17.433038.433038 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.436114.436114 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.436286.436286 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.439419.439419 mlpmodule.py:797] group einsum cost 0.009397029876708984 s
DEBUG 01-04 15:36:17.439346.439346 mlpmodule.py:805] cpy2cputensor cost 7.748603820800781e-05 s
DEBUG 01-04 15:36:17.443982.443982 cuda_h.py:19] end wait_cetm_experts cost 0.027440786361694336 seconds
DEBUG 01-04 15:36:17.443402.443402 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.443002.443002 cuda_h.py:19] end gpu_sexperts cost 0.0004715919494628906 seconds
DEBUG 01-04 15:36:17.443653.443653 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-04 15:36:17.443284.443284 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-04 15:36:17.443710.443710 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.3855438232421875e-05 seconds
DEBUG 01-04 15:36:17.443095.443095 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.605552673339844e-05 seconds
DEBUG 01-04 15:36:17.443891.443891 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.443362.443362 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80d59d3a-e97e-49fe-a28e-94d689a00639
DEBUG 01-04 15:36:17.444878.444878 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:17.444113.444113 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.444911.444911 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.447464.447464 cuda_h.py:19] end allocate_cuda_memory cost 0.0033845901489257812 seconds
DEBUG 01-04 15:36:17.447660.447660 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.447304.447304 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.448406.448406 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.448812.448812 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c77b6178-4871-4077-b743-8e9b98c55f66
DEBUG 01-04 15:36:17.448040.448040 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.453281.453281 client.py:127] Model loaded
DEBUG 01-04 15:36:17.453561.453561 cuda_h.py:19] end wait_experts cost 0.00969839096069336 seconds
DEBUG 01-04 15:36:17.453032.453032 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.453451.453451 lmp.py:384]   Computing 25 experts on GPU...
DEBUG 01-04 15:36:17.454713.454713 mlpmodule.py:531] gpu group tensors cost 0.0004417896270751953 s
INFO 01-04 15:36:17.454155.454155 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c77b6178-4871-4077-b743-8e9b98c55f66
DEBUG 01-04 15:36:17.454151.454151 cuda_h.py:19] end load_into_gpu_async cost 0.00670170783996582 seconds
DEBUG 01-04 15:36:17.454907.454907 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.454295.454295 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-04 15:36:17.454581.454581 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010532617568969727 seconds
INFO 01-04 15:36:17.455536.455536 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c77b6178-4871-4077-b743-8e9b98c55f66
DEBUG 01-04 15:36:17.455121.455121 mlpmodule.py:662]  experts func einsum cost 0.03983902931213379 s
DEBUG 01-04 15:36:17.456426.456426 mlpmodule.py:564] gpu pad cost 0.0022614002227783203 s
DEBUG 01-04 15:36:17.457083.457083 mlpmodule.py:582] gpu group einsum cost 0.00037384033203125 s
DEBUG 01-04 15:36:17.459170.459170 mlpmodule.py:611] gpu experts func einsum cost 0.005413532257080078 s
DEBUG 01-04 15:36:17.459771.459771 cuda_h.py:19] end gpu_experts cost 0.005609750747680664 seconds
DEBUG 01-04 15:36:17.459811.459811 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:17.464099.464099 client.py:127] Model loaded
DEBUG 01-04 15:36:17.465236.465236 cuda_h.py:19] end sllm_worker_task cost 0.020868778228759766 seconds
DEBUG 01-04 15:36:17.465408.465408 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005914449691772461 seconds
DEBUG 01-04 15:36:17.465189.465189 cuda_h.py:19] end layer_moe_generate_26 cost 0.057341575622558594 seconds
DEBUG 01-04 15:36:17.465559.465559 lmp.py:207] -------------------------------- end layer 26 --------------------------------
DEBUG 01-04 15:36:17.465898.465898 lmp.py:169] -------------------------------- start layer 27 --------------------------------
DEBUG 01-04 15:36:17.465641.465641 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:17.466498.466498 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:17.468904.468904 cuda_h.py:19] end self_attn cost 0.002382993698120117 seconds
DEBUG 01-04 15:36:17.468046.468046 cuda_h.py:19] end iln_self_attn_paln cost 0.0029726028442382812 seconds
DEBUG 01-04 15:36:17.468982.468982 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-04 15:36:17.468267.468267 cuda_h.py:10] start gate
DEBUG 01-04 15:36:17.469135.469135 cuda_h.py:19] end gate cost 0.0005724430084228516 seconds
DEBUG 01-04 15:36:17.469058.469058 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:17.469675.469675 lmp.py:281] 
DEBUG 01-04 15:36:17.469675.469675 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:17.469332.469332 lmp.py:282]   Total experts: 50
DEBUG 01-04 15:36:17.469597.469597 lmp.py:283]   CPU experts: 25 (50%)
DEBUG 01-04 15:36:17.469002.469002 lmp.py:284]   GPU experts: 25 (50%)
DEBUG 01-04 15:36:17.469929.469929 lmp.py:285] 
DEBUG 01-04 15:36:17.469929.469929 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:17.469619.469619 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:17.469076.469076 lmp.py:292]   Expert 19 |      1 | CPU
DEBUG 01-04 15:36:17.469766.469766 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:17.469501.469501 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:17.469999.469999 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:17.469019.469019 lmp.py:292]   Expert 11 |      2 | CPU
DEBUG 01-04 15:36:17.469278.469278 lmp.py:292]   Expert 20 |      2 | CPU
DEBUG 01-04 15:36:17.469536.469536 lmp.py:292]   Expert 22 |      2 | CPU
DEBUG 01-04 15:36:17.469318.469318 lmp.py:292]   Expert 33 |      2 | CPU
DEBUG 01-04 15:36:17.469577.469577 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:17.469598.469598 lmp.py:292]   Expert  6 |      3 | CPU
DEBUG 01-04 15:36:17.470380.470380 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:17.470400.470400 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:17.470136.470136 lmp.py:292]   Expert 31 |      3 | CPU
DEBUG 01-04 15:36:17.470871.470871 lmp.py:292]   Expert 37 |      3 | CPU
DEBUG 01-04 15:36:17.470368.470368 lmp.py:292]   Expert 40 |      3 | CPU
DEBUG 01-04 15:36:17.470866.470866 lmp.py:292]   Expert 46 |      3 | CPU
DEBUG 01-04 15:36:17.470840.470840 lmp.py:292]   Expert 51 |      3 | CPU
DEBUG 01-04 15:36:17.470622.470622 lmp.py:292]   Expert 63 |      3 | CPU
DEBUG 01-04 15:36:17.470404.470404 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:17.470185.470185 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:17.470967.470967 lmp.py:292]   Expert 26 |      5 | CPU
DEBUG 01-04 15:36:17.470273.470273 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:17.470055.470055 lmp.py:292]   Expert  8 |      6 | CPU
DEBUG 01-04 15:36:17.470598.470598 lmp.py:292]   Expert 13 |      6 | CPU
DEBUG 01-04 15:36:17.470142.470142 lmp.py:292]   Expert 23 |      6 | CPU
DEBUG 01-04 15:36:17.470924.470924 lmp.py:292]   Expert 57 |      6 | GPU
DEBUG 01-04 15:36:17.470659.470659 lmp.py:292]   Expert 55 |      7 | GPU
DEBUG 01-04 15:36:17.470918.470918 lmp.py:292]   Expert 56 |      7 | GPU
DEBUG 01-04 15:36:17.470415.470415 lmp.py:292]   Expert 16 |      8 | GPU
DEBUG 01-04 15:36:17.470674.470674 lmp.py:292]   Expert 25 |      8 | GPU
DEBUG 01-04 15:36:17.470456.470456 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:17.470999.470999 lmp.py:292]   Expert 35 |      9 | GPU
DEBUG 01-04 15:36:17.470543.470543 lmp.py:292]   Expert 49 |      9 | GPU
DEBUG 01-04 15:36:17.470325.470325 lmp.py:292]   Expert 17 |     10 | GPU
DEBUG 01-04 15:36:17.470868.470868 lmp.py:292]   Expert 41 |     10 | GPU
DEBUG 01-04 15:36:17.470412.470412 lmp.py:292]   Expert 50 |     11 | GPU
DEBUG 01-04 15:36:17.470432.470432 lmp.py:292]   Expert 27 |     12 | GPU
DEBUG 01-04 15:36:17.470737.470737 lmp.py:292]   Expert 36 |     12 | GPU
DEBUG 01-04 15:36:17.470281.470281 lmp.py:292]   Expert 44 |     12 | GPU
DEBUG 01-04 15:36:17.470825.470825 lmp.py:292]   Expert 62 |     13 | GPU
DEBUG 01-04 15:36:17.470606.470606 lmp.py:292]   Expert 14 |     14 | GPU
DEBUG 01-04 15:36:17.470104.470104 lmp.py:292]   Expert 43 |     14 | GPU
DEBUG 01-04 15:36:17.470601.470601 lmp.py:292]   Expert 21 |     17 | GPU
DEBUG 01-04 15:36:17.470098.470098 lmp.py:292]   Expert 60 |     24 | GPU
DEBUG 01-04 15:36:17.470072.470072 lmp.py:292]   Expert  1 |   1993 | GPU
DEBUG 01-04 15:36:17.470093.470093 lmp.py:292]   Expert  4 |   1994 | GPU
DEBUG 01-04 15:36:17.470874.470874 lmp.py:292]   Expert  3 |   1999 | GPU
DEBUG 01-04 15:36:17.470656.470656 lmp.py:292]   Expert  5 |   1999 | GPU
DEBUG 01-04 15:36:17.470915.470915 lmp.py:292]   Expert  0 |   2007 | GPU
DEBUG 01-04 15:36:17.470697.470697 lmp.py:292]   Expert  2 |   2007 | GPU
DEBUG 01-04 15:36:17.470194.470194 lmp.py:293] 
DEBUG 01-04 15:36:17.470194.470194 lmp.py:293]   CPU total tokens: 78 (0.6%)
DEBUG 01-04 15:36:17.470930.470930 lmp.py:294]   GPU total tokens: 12210 (99.4%)
DEBUG 01-04 15:36:17.470242.470242 cuda_h.py:19] end experts_map_get cost 0.001127004623413086 seconds
DEBUG 01-04 15:36:17.470454.470454 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:17.470509.470509 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:17.470751.470751 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:17.471078.471078 cuda_h.py:19] end allocate_cuda_memory cost 0.0002465248107910156 seconds
DEBUG 01-04 15:36:17.471682.471682 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:17.471816.471816 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:17.471056.471056 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:17.471467.471467 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5e932c62-752a-41ff-8ec8-6a561627d29e
DEBUG 01-04 15:36:17.471599.471599 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:17.473562.473562 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5e932c62-752a-41ff-8ec8-6a561627d29e
DEBUG 01-04 15:36:17.473537.473537 cuda_h.py:19] end load_into_gpu_async cost 0.002146005630493164 seconds
DEBUG 01-04 15:36:17.473571.473571 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:17.473276.473276 cuda_h.py:19] end restore_tensors2 cost 0.0002853870391845703 seconds
DEBUG 01-04 15:36:17.473238.473238 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002974987030029297 seconds
DEBUG 01-04 15:36:17.475134.475134 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005040168762207031 seconds
DEBUG 01-04 15:36:17.475102.475102 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:17.475820.475820 lmp.py:339] 
DEBUG 01-04 15:36:17.475820.475820 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:17.475179.475179 cuda_h.py:19] end cpu_experts_submit cost 9.989738464355469e-05 seconds
DEBUG 01-04 15:36:17.475280.475280 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:17.488585.488585 mlpmodule.py:704] group tensors cost 0.012135505676269531 s
DEBUG 01-04 15:36:17.490676.490676 mlpmodule.py:742] pad cost 0.0011143684387207031 s
DEBUG 01-04 15:36:17.490845.490845 mlpmodule.py:748] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-04 15:36:17.490211.490211 mlpmodule.py:753] move to cpu cost 2.6464462280273438e-05 s
DEBUG 01-04 15:36:17.493314.493314 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:17.493144.493144 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:17.493485.493485 mlpmodule.py:774] group_w3 first element: -0.000606536865234375
WARNING 01-04 15:36:17.493680.493680 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:17.496128.496128 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:17.496810.496810 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:17.499769.499769 mlpmodule.py:797] group einsum cost 0.009313106536865234 s
DEBUG 01-04 15:36:17.499544.499544 mlpmodule.py:805] cpy2cputensor cost 7.033348083496094e-05 s
DEBUG 01-04 15:36:17.503852.503852 cuda_h.py:19] end wait_cetm_experts cost 0.027307748794555664 seconds
DEBUG 01-04 15:36:17.503358.503358 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:17.503600.503600 cuda_h.py:19] end gpu_sexperts cost 0.0004506111145019531 seconds
DEBUG 01-04 15:36:17.503396.503396 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-04 15:36:17.503180.503180 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.4781951904296875e-05 seconds
DEBUG 01-04 15:36:17.504598.504598 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:17.504023.504023 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5e932c62-752a-41ff-8ec8-6a561627d29e
DEBUG 01-04 15:36:17.514532.514532 mlpmodule.py:662]  experts func einsum cost 0.03806424140930176 s
INFO 01-04 15:36:17.514263.514263 client.py:127] Model loaded
DEBUG 01-04 15:36:17.514729.514729 cuda_h.py:19] end wait_experts cost 0.010599136352539062 seconds
DEBUG 01-04 15:36:17.514624.514624 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:17.514373.514373 lmp.py:384]   Computing 25 experts on GPU...
DEBUG 01-04 15:36:17.515860.515860 mlpmodule.py:531] gpu group tensors cost 0.00043702125549316406 s
DEBUG 01-04 15:36:17.516133.516133 mlpmodule.py:564] gpu pad cost 0.0011980533599853516 s
DEBUG 01-04 15:36:17.517820.517820 mlpmodule.py:582] gpu group einsum cost 0.0004677772521972656 s
DEBUG 01-04 15:36:17.519206.519206 mlpmodule.py:611] gpu experts func einsum cost 0.004448652267456055 s
DEBUG 01-04 15:36:17.519652.519652 cuda_h.py:19] end gpu_experts cost 0.0045964717864990234 seconds
DEBUG 01-04 15:36:17.519932.519932 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:17.519979.519979 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 9.775161743164062e-06 seconds
DEBUG 01-04 15:36:17.523400.523400 cuda_h.py:19] end layer_moe_generate_27 cost 0.054384469985961914 seconds
DEBUG 01-04 15:36:17.523392.523392 lmp.py:207] -------------------------------- end layer 27 --------------------------------
DEBUG 01-04 15:36:17.523784.523784 cuda_h.py:19] end multi_layer cost 1.8012938499450684 seconds
DEBUG 01-04 15:36:20.693413.693413 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09085774421691895 s
DEBUG 01-04 15:36:21.020954.020954 cuda_h.py:19] end generate_input_ids cost 0.3254544734954834 seconds
DEBUG 01-04 15:36:21.020442.020442 cuda_h.py:10] start init_cache
DEBUG 01-04 15:36:21.021009.021009 cuda_h.py:19] end init_cache cost 6.461143493652344e-05 seconds
DEBUG 01-04 15:36:23.482390.482390 cuda_h.py:10] start init_weights
DEBUG 01-04 15:36:23.482454.482454 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:23.483195.483195 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:23.484171.484171 cuda_h.py:19] end allocate_cuda_memory cost 0.00183868408203125 seconds
DEBUG 01-04 15:36:23.485764.485764 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:23.485665.485665 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:23.485488.485488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:23.485237.485237 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a8fa900-822a-4446-bb00-b10712880493
DEBUG 01-04 15:36:23.485943.485943 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:23.486377.486377 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a8fa900-822a-4446-bb00-b10712880493
DEBUG 01-04 15:36:23.486021.486021 cuda_h.py:19] end load_into_gpu_async cost 0.0019125938415527344 seconds
DEBUG 01-04 15:36:23.487645.487645 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:23.487846.487846 cuda_h.py:19] end restore_tensors2 cost 5.125999450683594e-05 seconds
DEBUG 01-04 15:36:23.487787.487787 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004065513610839844 seconds
INFO 01-04 15:36:23.487508.487508 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a8fa900-822a-4446-bb00-b10712880493
INFO 01-04 15:36:23.567512.567512 client.py:127] Model loaded
DEBUG 01-04 15:36:23.567365.567365 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-04 15:36:23.567158.567158 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:23.567314.567314 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:23.568013.568013 cuda_h.py:19] end allocate_cuda_memory cost 0.0004227161407470703 seconds
DEBUG 01-04 15:36:23.568886.568886 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:23.568286.568286 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:23.568072.568072 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:23.568889.568889 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 66067647-679b-4126-a4cb-914a1796e50b
DEBUG 01-04 15:36:23.568610.568610 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:23.570135.570135 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 66067647-679b-4126-a4cb-914a1796e50b
DEBUG 01-04 15:36:23.570113.570113 cuda_h.py:19] end load_into_gpu_async cost 0.0019392967224121094 seconds
DEBUG 01-04 15:36:23.570109.570109 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:23.570791.570791 cuda_h.py:19] end restore_tensors2 cost 0.0001506805419921875 seconds
DEBUG 01-04 15:36:23.570907.570907 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031037330627441406 seconds
INFO 01-04 15:36:23.570909.570909 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 66067647-679b-4126-a4cb-914a1796e50b
INFO 01-04 15:36:23.587497.587497 client.py:127] Model loaded
DEBUG 01-04 15:36:23.588348.588348 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.021126747131347656 seconds
DEBUG 01-04 15:36:23.588240.588240 cuda_h.py:19] end init_weights cost 0.10576081275939941 seconds
DEBUG 01-04 15:36:23.588918.588918 cuda_h.py:10] start copy_emodel
DEBUG 01-04 15:36:24.364995.364995 cuda_h.py:19] end copy_emodel cost 0.775731086730957 seconds
DEBUG 01-04 15:36:24.365214.365214 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-04 15:36:24.365345.365345 cuda_h.py:19] end init_inputs_tokens cost 0.0002949237823486328 seconds
DEBUG 01-04 15:36:24.365645.365645 cuda_h.py:10] start multi_layer
DEBUG 01-04 15:36:24.365692.365692 lmp.py:169] -------------------------------- start layer 0 --------------------------------
DEBUG 01-04 15:36:24.365004.365004 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.366937.366937 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.369860.369860 cuda_h.py:19] end self_attn cost 0.0027570724487304688 seconds
DEBUG 01-04 15:36:24.369941.369941 cuda_h.py:19] end iln_self_attn_paln cost 0.0038216114044189453 seconds
DEBUG 01-04 15:36:24.369340.369340 cuda_h.py:10] start dense_mlp
DEBUG 01-04 15:36:24.369003.369003 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-04 15:36:24.369369.369369 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.361701965332031e-05 seconds
DEBUG 01-04 15:36:24.369287.369287 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.370901.370901 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.370559.370559 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.370812.370812 cuda_h.py:19] end allocate_cuda_memory cost 0.00021314620971679688 seconds
DEBUG 01-04 15:36:24.370509.370509 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.370458.370458 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.370110.370110 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.370364.370364 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ae321d83-f5fc-4553-b00f-49513e449b4e
DEBUG 01-04 15:36:24.370044.370044 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.372691.372691 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ae321d83-f5fc-4553-b00f-49513e449b4e
DEBUG 01-04 15:36:24.372607.372607 cuda_h.py:19] end load_into_gpu_async cost 0.0020754337310791016 seconds
DEBUG 01-04 15:36:24.372854.372854 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.372706.372706 cuda_h.py:19] end restore_tensors2 cost 9.322166442871094e-05 seconds
DEBUG 01-04 15:36:24.373582.373582 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002879619598388672 seconds
INFO 01-04 15:36:24.373019.373019 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ae321d83-f5fc-4553-b00f-49513e449b4e
INFO 01-04 15:36:24.381103.381103 client.py:127] Model loaded
DEBUG 01-04 15:36:24.381167.381167 cuda_h.py:19] end sllm_worker_task cost 0.011104583740234375 seconds
DEBUG 01-04 15:36:24.381738.381738 cuda_h.py:19] end dense_mlp cost 0.011641740798950195 seconds
DEBUG 01-04 15:36:24.381158.381158 lmp.py:207] -------------------------------- end layer 0 --------------------------------
DEBUG 01-04 15:36:24.381109.381109 lmp.py:169] -------------------------------- start layer 1 --------------------------------
DEBUG 01-04 15:36:24.381820.381820 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.382721.382721 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.388431.388431 cuda_h.py:19] end self_attn cost 0.005442619323730469 seconds
DEBUG 01-04 15:36:24.388285.388285 cuda_h.py:19] end iln_self_attn_paln cost 0.006893157958984375 seconds
DEBUG 01-04 15:36:24.389204.389204 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-04 15:36:24.389631.389631 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.390918.390918 cuda_h.py:19] end gate cost 0.0015513896942138672 seconds
DEBUG 01-04 15:36:24.390472.390472 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.391855.391855 lmp.py:281] 
DEBUG 01-04 15:36:24.391855.391855 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.391154.391154 lmp.py:282]   Total experts: 64
DEBUG 01-04 15:36:24.391010.391010 lmp.py:283]   CPU experts: 32 (50%)
DEBUG 01-04 15:36:24.391481.391481 lmp.py:284]   GPU experts: 32 (50%)
DEBUG 01-04 15:36:24.391469.391469 lmp.py:285] 
DEBUG 01-04 15:36:24.391469.391469 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.391171.391171 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.391934.391934 lmp.py:292]   Expert 62 |     66 | CPU
DEBUG 01-04 15:36:24.391260.391260 lmp.py:292]   Expert 18 |     68 | CPU
DEBUG 01-04 15:36:24.391486.391486 lmp.py:292]   Expert 22 |     73 | CPU
DEBUG 01-04 15:36:24.391997.391997 lmp.py:292]   Expert 32 |     83 | CPU
DEBUG 01-04 15:36:24.391269.391269 lmp.py:292]   Expert 52 |     94 | CPU
DEBUG 01-04 15:36:24.391780.391780 lmp.py:292]   Expert  3 |    104 | CPU
DEBUG 01-04 15:36:24.391052.391052 lmp.py:292]   Expert 27 |    114 | CPU
DEBUG 01-04 15:36:24.392324.392324 lmp.py:292]   Expert 38 |    114 | CPU
DEBUG 01-04 15:36:24.392358.392358 lmp.py:292]   Expert 13 |    118 | CPU
DEBUG 01-04 15:36:24.392154.392154 lmp.py:292]   Expert 54 |    118 | CPU
DEBUG 01-04 15:36:24.392665.392665 lmp.py:292]   Expert 17 |    121 | CPU
DEBUG 01-04 15:36:24.392129.392129 lmp.py:292]   Expert 11 |    124 | CPU
DEBUG 01-04 15:36:24.392070.392070 lmp.py:292]   Expert 28 |    124 | CPU
DEBUG 01-04 15:36:24.392012.392012 lmp.py:292]   Expert 37 |    125 | CPU
DEBUG 01-04 15:36:24.392046.392046 lmp.py:292]   Expert 58 |    129 | CPU
DEBUG 01-04 15:36:24.392603.392603 lmp.py:292]   Expert 39 |    131 | CPU
DEBUG 01-04 15:36:24.392637.392637 lmp.py:292]   Expert 25 |    135 | CPU
DEBUG 01-04 15:36:24.392194.392194 lmp.py:292]   Expert 41 |    136 | CPU
DEBUG 01-04 15:36:24.392989.392989 lmp.py:292]   Expert 21 |    150 | CPU
DEBUG 01-04 15:36:24.392023.392023 lmp.py:292]   Expert  4 |    151 | CPU
DEBUG 01-04 15:36:24.392249.392249 lmp.py:292]   Expert 30 |    152 | CPU
DEBUG 01-04 15:36:24.392952.392952 lmp.py:292]   Expert 29 |    155 | CPU
DEBUG 01-04 15:36:24.392338.392338 lmp.py:292]   Expert 53 |    155 | CPU
DEBUG 01-04 15:36:24.392133.392133 lmp.py:292]   Expert 49 |    156 | CPU
DEBUG 01-04 15:36:24.392929.392929 lmp.py:292]   Expert 47 |    157 | CPU
DEBUG 01-04 15:36:24.392486.392486 lmp.py:292]   Expert 31 |    168 | CPU
DEBUG 01-04 15:36:24.392805.392805 lmp.py:292]   Expert 33 |    168 | CPU
DEBUG 01-04 15:36:24.392123.392123 lmp.py:292]   Expert 55 |    173 | CPU
DEBUG 01-04 15:36:24.392442.392442 lmp.py:292]   Expert 56 |    173 | CPU
DEBUG 01-04 15:36:24.392906.392906 lmp.py:292]   Expert 15 |    177 | CPU
DEBUG 01-04 15:36:24.392609.392609 lmp.py:292]   Expert  0 |    178 | CPU
DEBUG 01-04 15:36:24.392835.392835 lmp.py:292]   Expert  1 |    178 | CPU
DEBUG 01-04 15:36:24.392300.392300 lmp.py:292]   Expert 24 |    180 | GPU
DEBUG 01-04 15:36:24.392334.392334 lmp.py:292]   Expert 50 |    182 | GPU
DEBUG 01-04 15:36:24.392129.392129 lmp.py:292]   Expert 51 |    184 | GPU
DEBUG 01-04 15:36:24.392686.392686 lmp.py:292]   Expert 19 |    185 | GPU
DEBUG 01-04 15:36:24.392244.392244 lmp.py:292]   Expert  6 |    186 | GPU
DEBUG 01-04 15:36:24.392562.392562 lmp.py:292]   Expert 10 |    189 | GPU
DEBUG 01-04 15:36:24.392881.392881 lmp.py:292]   Expert 34 |    191 | GPU
DEBUG 01-04 15:36:24.392438.392438 lmp.py:292]   Expert  2 |    195 | GPU
DEBUG 01-04 15:36:24.392903.392903 lmp.py:292]   Expert 45 |    195 | GPU
DEBUG 01-04 15:36:24.392129.392129 lmp.py:292]   Expert 35 |    197 | GPU
DEBUG 01-04 15:36:24.392401.392401 lmp.py:292]   Expert 36 |    198 | GPU
DEBUG 01-04 15:36:24.392720.392720 lmp.py:292]   Expert 61 |    209 | GPU
DEBUG 01-04 15:36:24.392515.392515 lmp.py:292]   Expert 44 |    214 | GPU
DEBUG 01-04 15:36:24.392834.392834 lmp.py:292]   Expert 12 |    223 | GPU
DEBUG 01-04 15:36:24.393153.393153 lmp.py:292]   Expert  5 |    227 | GPU
DEBUG 01-04 15:36:24.393471.393471 lmp.py:292]   Expert 23 |    235 | GPU
DEBUG 01-04 15:36:24.393552.393552 lmp.py:292]   Expert 60 |    235 | GPU
DEBUG 01-04 15:36:24.393109.393109 lmp.py:292]   Expert 43 |    239 | GPU
DEBUG 01-04 15:36:24.393427.393427 lmp.py:292]   Expert  9 |    246 | GPU
DEBUG 01-04 15:36:24.393177.393177 lmp.py:292]   Expert 48 |    252 | GPU
DEBUG 01-04 15:36:24.393210.393210 lmp.py:292]   Expert  8 |    262 | GPU
DEBUG 01-04 15:36:24.393529.393529 lmp.py:292]   Expert 20 |    273 | GPU
DEBUG 01-04 15:36:24.393848.393848 lmp.py:292]   Expert 26 |    285 | GPU
DEBUG 01-04 15:36:24.393167.393167 lmp.py:292]   Expert 57 |    292 | GPU
DEBUG 01-04 15:36:24.393962.393962 lmp.py:292]   Expert  7 |    308 | GPU
DEBUG 01-04 15:36:24.393519.393519 lmp.py:292]   Expert 59 |    308 | GPU
DEBUG 01-04 15:36:24.393599.393599 lmp.py:292]   Expert 16 |    310 | GPU
DEBUG 01-04 15:36:24.393633.393633 lmp.py:292]   Expert 63 |    313 | GPU
DEBUG 01-04 15:36:24.393859.393859 lmp.py:292]   Expert 40 |    320 | GPU
DEBUG 01-04 15:36:24.393370.393370 lmp.py:292]   Expert 46 |    320 | GPU
DEBUG 01-04 15:36:24.393404.393404 lmp.py:292]   Expert 42 |    342 | GPU
DEBUG 01-04 15:36:24.393961.393961 lmp.py:292]   Expert 14 |    525 | GPU
DEBUG 01-04 15:36:24.393187.393187 lmp.py:293] 
DEBUG 01-04 15:36:24.393187.393187 lmp.py:293]   CPU total tokens: 4268 (34.7%)
DEBUG 01-04 15:36:24.393175.393175 lmp.py:294]   GPU total tokens: 8020 (65.3%)
DEBUG 01-04 15:36:24.393507.393507 cuda_h.py:19] end experts_map_get cost 0.0025501251220703125 seconds
DEBUG 01-04 15:36:24.393402.393402 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.393643.393643 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.393073.393073 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.394784.394784 cuda_h.py:19] end allocate_cuda_memory cost 0.00023102760314941406 seconds
DEBUG 01-04 15:36:24.394178.394178 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.394854.394854 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.394161.394161 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.394301.394301 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a550a0c8-5423-45eb-a38e-10c43616d523
DEBUG 01-04 15:36:24.394555.394555 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.396648.396648 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a550a0c8-5423-45eb-a38e-10c43616d523
DEBUG 01-04 15:36:24.396116.396116 cuda_h.py:19] end load_into_gpu_async cost 0.0024602413177490234 seconds
DEBUG 01-04 15:36:24.396364.396364 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.397119.397119 cuda_h.py:19] end restore_tensors2 cost 0.0005130767822265625 seconds
DEBUG 01-04 15:36:24.397135.397135 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037691593170166016 seconds
DEBUG 01-04 15:36:24.401410.401410 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00789499282836914 seconds
DEBUG 01-04 15:36:24.401724.401724 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.401237.401237 lmp.py:339] 
DEBUG 01-04 15:36:24.401237.401237 lmp.py:339]   Computing 32 experts on CPU...
DEBUG 01-04 15:36:24.401226.401226 cuda_h.py:19] end cpu_experts_submit cost 0.0001323223114013672 seconds
DEBUG 01-04 15:36:24.401545.401545 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.412288.412288 mlpmodule.py:704] group tensors cost 0.010767698287963867 s
DEBUG 01-04 15:36:24.414259.414259 mlpmodule.py:742] pad cost 0.0014081001281738281 s
DEBUG 01-04 15:36:24.414289.414289 mlpmodule.py:748] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-04 15:36:24.414655.414655 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-04 15:36:24.425051.425051 mlpmodule.py:768] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-04 15:36:24.425042.425042 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.425389.425389 mlpmodule.py:774] group_w3 first element: -0.0107421875
WARNING 01-04 15:36:24.425678.425678 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.434364.434364 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.434112.434112 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.443944.443944 mlpmodule.py:797] group einsum cost 0.028346538543701172 s
DEBUG 01-04 15:36:24.444977.444977 mlpmodule.py:805] cpy2cputensor cost 0.0006415843963623047 s
DEBUG 01-04 15:36:24.448794.448794 cuda_h.py:19] end wait_cetm_experts cost 0.04655647277832031 seconds
DEBUG 01-04 15:36:24.448943.448943 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.449283.449283 cuda_h.py:19] end gpu_sexperts cost 0.0005934238433837891 seconds
DEBUG 01-04 15:36:24.449464.449464 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-04 15:36:24.449664.449664 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-04 15:36:24.449765.449765 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.5762786865234375e-05 seconds
DEBUG 01-04 15:36:24.449051.449051 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 7.867813110351562e-05 seconds
DEBUG 01-04 15:36:24.449085.449085 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.449510.449510 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a550a0c8-5423-45eb-a38e-10c43616d523
DEBUG 01-04 15:36:24.449072.449072 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.449506.449506 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.449780.449780 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.453350.453350 cuda_h.py:19] end allocate_cuda_memory cost 0.003925323486328125 seconds
DEBUG 01-04 15:36:24.453458.453458 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.453235.453235 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.453210.453210 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.453681.453681 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3558ec30-d628-40ad-8559-867accf3036d
DEBUG 01-04 15:36:24.454771.454771 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.454105.454105 client.py:127] Model loaded
DEBUG 01-04 15:36:24.454763.454763 cuda_h.py:19] end wait_experts cost 0.004962921142578125 seconds
DEBUG 01-04 15:36:24.454896.454896 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.454268.454268 lmp.py:384]   Computing 32 experts on GPU...
INFO 01-04 15:36:24.455525.455525 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3558ec30-d628-40ad-8559-867accf3036d
DEBUG 01-04 15:36:24.455250.455250 cuda_h.py:19] end load_into_gpu_async cost 0.0016314983367919922 seconds
DEBUG 01-04 15:36:24.455105.455105 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.460275.460275 cuda_h.py:19] end restore_tensors2 cost 0.005422115325927734 seconds
DEBUG 01-04 15:36:24.461510.461510 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011341333389282227 seconds
INFO 01-04 15:36:24.461727.461727 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3558ec30-d628-40ad-8559-867accf3036d
INFO 01-04 15:36:24.462381.462381 client.py:127] Model loaded
DEBUG 01-04 15:36:24.462661.462661 cuda_h.py:19] end sllm_worker_task cost 0.012932538986206055 seconds
DEBUG 01-04 15:36:24.466793.466793 mlpmodule.py:662]  experts func einsum cost 0.06505656242370605 s
DEBUG 01-04 15:36:24.467333.467333 mlpmodule.py:531] gpu group tensors cost 0.012540340423583984 s
DEBUG 01-04 15:36:24.468176.468176 mlpmodule.py:564] gpu pad cost 0.0015406608581542969 s
DEBUG 01-04 15:36:24.469197.469197 mlpmodule.py:582] gpu group einsum cost 0.0009737014770507812 s
DEBUG 01-04 15:36:24.472048.472048 mlpmodule.py:611] gpu experts func einsum cost 0.018093109130859375 s
DEBUG 01-04 15:36:24.472167.472167 cuda_h.py:19] end gpu_experts cost 0.01836109161376953 seconds
DEBUG 01-04 15:36:24.472592.472592 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:24.472415.472415 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7642974853515625e-05 seconds
DEBUG 01-04 15:36:24.472552.472552 cuda_h.py:19] end layer_moe_generate_1 cost 0.08388495445251465 seconds
DEBUG 01-04 15:36:24.473677.473677 lmp.py:207] -------------------------------- end layer 1 --------------------------------
DEBUG 01-04 15:36:24.473201.473201 lmp.py:169] -------------------------------- start layer 2 --------------------------------
DEBUG 01-04 15:36:24.473705.473705 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.473264.473264 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.475921.475921 cuda_h.py:19] end self_attn cost 0.0023632049560546875 seconds
DEBUG 01-04 15:36:24.476844.476844 cuda_h.py:19] end iln_self_attn_paln cost 0.0029535293579101562 seconds
DEBUG 01-04 15:36:24.476919.476919 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-04 15:36:24.476490.476490 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.476418.476418 cuda_h.py:19] end gate cost 0.0005822181701660156 seconds
DEBUG 01-04 15:36:24.476486.476486 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.477621.477621 lmp.py:281] 
DEBUG 01-04 15:36:24.477621.477621 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.477708.477708 lmp.py:282]   Total experts: 62
DEBUG 01-04 15:36:24.477404.477404 lmp.py:283]   CPU experts: 31 (50%)
DEBUG 01-04 15:36:24.477762.477762 lmp.py:284]   GPU experts: 31 (50%)
DEBUG 01-04 15:36:24.477451.477451 lmp.py:285] 
DEBUG 01-04 15:36:24.477451.477451 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.477902.477902 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.477837.477837 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:24.477764.477764 lmp.py:292]   Expert 10 |      1 | CPU
DEBUG 01-04 15:36:24.477738.477738 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:24.477474.477474 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:24.477210.477210 lmp.py:292]   Expert 35 |      1 | CPU
DEBUG 01-04 15:36:24.477184.477184 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:24.477158.477158 lmp.py:292]   Expert 19 |      2 | CPU
DEBUG 01-04 15:36:24.477417.477417 lmp.py:292]   Expert 21 |      2 | CPU
DEBUG 01-04 15:36:24.477497.477497 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:24.477186.477186 lmp.py:292]   Expert 36 |      2 | CPU
DEBUG 01-04 15:36:24.477160.477160 lmp.py:292]   Expert 40 |      2 | CPU
DEBUG 01-04 15:36:24.477373.477373 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:24.477108.477108 lmp.py:292]   Expert 52 |      2 | CPU
DEBUG 01-04 15:36:24.477606.477606 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:24.477341.477341 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:24.477600.477600 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:24.477349.477349 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:24.477893.477893 lmp.py:292]   Expert 39 |      4 | CPU
DEBUG 01-04 15:36:24.477436.477436 lmp.py:292]   Expert 48 |      4 | CPU
DEBUG 01-04 15:36:24.477980.477980 lmp.py:292]   Expert 51 |      4 | CPU
DEBUG 01-04 15:36:24.477285.477285 lmp.py:292]   Expert 14 |      5 | CPU
DEBUG 01-04 15:36:24.477828.477828 lmp.py:292]   Expert 24 |      5 | CPU
DEBUG 01-04 15:36:24.477564.477564 lmp.py:292]   Expert 28 |      5 | CPU
DEBUG 01-04 15:36:24.477823.477823 lmp.py:292]   Expert 44 |      5 | CPU
DEBUG 01-04 15:36:24.477558.477558 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:24.477294.477294 lmp.py:292]   Expert  7 |      6 | CPU
DEBUG 01-04 15:36:24.477076.477076 lmp.py:292]   Expert 15 |      6 | CPU
DEBUG 01-04 15:36:24.477858.477858 lmp.py:292]   Expert 17 |      6 | CPU
DEBUG 01-04 15:36:24.477640.477640 lmp.py:292]   Expert 33 |      6 | CPU
DEBUG 01-04 15:36:24.477183.477183 lmp.py:292]   Expert 20 |      7 | CPU
DEBUG 01-04 15:36:24.477204.477204 lmp.py:292]   Expert 23 |      7 | CPU
DEBUG 01-04 15:36:24.477986.477986 lmp.py:292]   Expert 37 |      7 | GPU
DEBUG 01-04 15:36:24.477529.477529 lmp.py:292]   Expert 42 |      7 | GPU
DEBUG 01-04 15:36:24.477073.477073 lmp.py:292]   Expert 56 |      7 | GPU
DEBUG 01-04 15:36:24.477093.477093 lmp.py:292]   Expert  9 |      8 | GPU
DEBUG 01-04 15:36:24.477875.477875 lmp.py:292]   Expert 12 |      8 | GPU
DEBUG 01-04 15:36:24.477419.477419 lmp.py:292]   Expert 22 |      8 | GPU
DEBUG 01-04 15:36:24.477201.477201 lmp.py:292]   Expert 30 |      8 | GPU
DEBUG 01-04 15:36:24.477698.477698 lmp.py:292]   Expert 31 |      8 | GPU
DEBUG 01-04 15:36:24.477480.477480 lmp.py:292]   Expert 32 |      8 | GPU
DEBUG 01-04 15:36:24.477500.477500 lmp.py:292]   Expert 41 |      8 | GPU
DEBUG 01-04 15:36:24.477759.477759 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:24.477303.477303 lmp.py:292]   Expert 18 |      9 | GPU
DEBUG 01-04 15:36:24.478608.478608 lmp.py:292]   Expert 50 |      9 | GPU
DEBUG 01-04 15:36:24.478913.478913 lmp.py:292]   Expert 55 |     10 | GPU
DEBUG 01-04 15:36:24.478695.478695 lmp.py:292]   Expert 57 |     10 | GPU
DEBUG 01-04 15:36:24.478238.478238 lmp.py:292]   Expert 59 |     10 | GPU
DEBUG 01-04 15:36:24.478543.478543 lmp.py:292]   Expert 63 |     10 | GPU
DEBUG 01-04 15:36:24.478848.478848 lmp.py:292]   Expert  6 |     11 | GPU
DEBUG 01-04 15:36:24.478392.478392 lmp.py:292]   Expert 47 |     11 | GPU
DEBUG 01-04 15:36:24.478936.478936 lmp.py:292]   Expert 54 |     11 | GPU
DEBUG 01-04 15:36:24.478717.478717 lmp.py:292]   Expert 46 |     12 | GPU
DEBUG 01-04 15:36:24.478261.478261 lmp.py:292]   Expert 43 |     13 | GPU
DEBUG 01-04 15:36:24.478520.478520 lmp.py:292]   Expert 11 |     14 | GPU
DEBUG 01-04 15:36:24.478017.478017 lmp.py:292]   Expert 53 |     15 | GPU
DEBUG 01-04 15:36:24.478276.478276 lmp.py:292]   Expert 61 |     15 | GPU
DEBUG 01-04 15:36:24.478535.478535 lmp.py:292]   Expert  0 |   1986 | GPU
DEBUG 01-04 15:36:24.478032.478032 lmp.py:292]   Expert  3 |   1986 | GPU
DEBUG 01-04 15:36:24.478814.478814 lmp.py:292]   Expert  5 |   1987 | GPU
DEBUG 01-04 15:36:24.478119.478119 lmp.py:292]   Expert  1 |   1989 | GPU
DEBUG 01-04 15:36:24.478901.478901 lmp.py:292]   Expert  4 |   1993 | GPU
DEBUG 01-04 15:36:24.478444.478444 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:24.478465.478465 lmp.py:293] 
DEBUG 01-04 15:36:24.478465.478465 lmp.py:293]   CPU total tokens: 107 (0.9%)
DEBUG 01-04 15:36:24.478200.478200 lmp.py:294]   GPU total tokens: 12181 (99.1%)
DEBUG 01-04 15:36:24.478989.478989 cuda_h.py:19] end experts_map_get cost 0.0013623237609863281 seconds
DEBUG 01-04 15:36:24.478963.478963 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.478594.478594 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.478956.478956 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.478492.478492 cuda_h.py:19] end allocate_cuda_memory cost 0.00015497207641601562 seconds
DEBUG 01-04 15:36:24.478997.478997 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.478461.478461 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.478986.478986 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.478966.478966 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7efbd27c-9d21-4cc3-b099-8e80d36d9f09
DEBUG 01-04 15:36:24.479628.479628 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.481033.481033 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7efbd27c-9d21-4cc3-b099-8e80d36d9f09
DEBUG 01-04 15:36:24.481746.481746 cuda_h.py:19] end load_into_gpu_async cost 0.0023679733276367188 seconds
DEBUG 01-04 15:36:24.481901.481901 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.481185.481185 cuda_h.py:19] end restore_tensors2 cost 0.0004928112030029297 seconds
DEBUG 01-04 15:36:24.481406.481406 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034558773040771484 seconds
DEBUG 01-04 15:36:24.485086.485086 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007397174835205078 seconds
DEBUG 01-04 15:36:24.485486.485486 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.485728.485728 lmp.py:339] 
DEBUG 01-04 15:36:24.485728.485728 lmp.py:339]   Computing 31 experts on CPU...
DEBUG 01-04 15:36:24.486221.486221 cuda_h.py:19] end cpu_experts_submit cost 0.0001468658447265625 seconds
DEBUG 01-04 15:36:24.486891.486891 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.503514.503514 mlpmodule.py:704] group tensors cost 0.016965866088867188 s
DEBUG 01-04 15:36:24.505706.505706 mlpmodule.py:742] pad cost 0.0015454292297363281 s
DEBUG 01-04 15:36:24.505080.505080 mlpmodule.py:748] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-04 15:36:24.505791.505791 mlpmodule.py:753] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-04 15:36:24.510044.510044 mlpmodule.py:768] group_w3: shape=torch.Size([31, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=89391104
DEBUG 01-04 15:36:24.510895.510895 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.510150.510150 mlpmodule.py:774] group_w3 first element: -0.010498046875
WARNING 01-04 15:36:24.510292.510292 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.513990.513990 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.513851.513851 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.518323.518323 mlpmodule.py:797] group einsum cost 0.012653589248657227 s
DEBUG 01-04 15:36:24.518337.518337 mlpmodule.py:805] cpy2cputensor cost 8.416175842285156e-05 s
DEBUG 01-04 15:36:24.522967.522967 cuda_h.py:19] end wait_cetm_experts cost 0.03655862808227539 seconds
DEBUG 01-04 15:36:24.522056.522056 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.523722.523722 cuda_h.py:19] end gpu_sexperts cost 0.0004482269287109375 seconds
DEBUG 01-04 15:36:24.523327.523327 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-04 15:36:24.523573.523573 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-04 15:36:24.523708.523708 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.218650817871094e-05 seconds
DEBUG 01-04 15:36:24.523563.523563 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:24.523643.523643 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.523115.523115 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7efbd27c-9d21-4cc3-b099-8e80d36d9f09
DEBUG 01-04 15:36:24.523922.523922 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.523150.523150 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.523139.523139 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.529698.529698 cuda_h.py:19] end allocate_cuda_memory cost 0.005182027816772461 seconds
DEBUG 01-04 15:36:24.529807.529807 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.529954.529954 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.529783.529783 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.529493.529493 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e4077b3-a896-4bbc-9ca7-465ebdb3b76e
DEBUG 01-04 15:36:24.529344.529344 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.532916.532916 client.py:127] Model loaded
DEBUG 01-04 15:36:24.532249.532249 cuda_h.py:19] end wait_experts cost 0.009159088134765625 seconds
DEBUG 01-04 15:36:24.532959.532959 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.532576.532576 lmp.py:384]   Computing 31 experts on GPU...
DEBUG 01-04 15:36:24.533070.533070 mlpmodule.py:531] gpu group tensors cost 0.0006361007690429688 s
INFO 01-04 15:36:24.533954.533954 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e4077b3-a896-4bbc-9ca7-465ebdb3b76e
DEBUG 01-04 15:36:24.534095.534095 cuda_h.py:19] end load_into_gpu_async cost 0.005404233932495117 seconds
DEBUG 01-04 15:36:24.534242.534242 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.534144.534144 cuda_h.py:19] end restore_tensors2 cost 0.00021314620971679688 seconds
DEBUG 01-04 15:36:24.535284.535284 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.011090517044067383 seconds
INFO 01-04 15:36:24.535375.535375 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e4077b3-a896-4bbc-9ca7-465ebdb3b76e
DEBUG 01-04 15:36:24.536566.536566 mlpmodule.py:564] gpu pad cost 0.002274036407470703 s
DEBUG 01-04 15:36:24.540270.540270 mlpmodule.py:662]  experts func einsum cost 0.05421257019042969 s
INFO 01-04 15:36:24.540383.540383 client.py:127] Model loaded
DEBUG 01-04 15:36:24.540796.540796 cuda_h.py:19] end sllm_worker_task cost 0.016912221908569336 seconds
DEBUG 01-04 15:36:24.541016.541016 mlpmodule.py:582] gpu group einsum cost 0.0044786930084228516 s
DEBUG 01-04 15:36:24.544975.544975 mlpmodule.py:611] gpu experts func einsum cost 0.011239767074584961 s
DEBUG 01-04 15:36:24.544496.544496 cuda_h.py:19] end gpu_experts cost 0.01146078109741211 seconds
DEBUG 01-04 15:36:24.544013.544013 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:24.544690.544690 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-04 15:36:24.548453.548453 cuda_h.py:19] end layer_moe_generate_2 cost 0.07248234748840332 seconds
DEBUG 01-04 15:36:24.548989.548989 lmp.py:207] -------------------------------- end layer 2 --------------------------------
DEBUG 01-04 15:36:24.548759.548759 lmp.py:169] -------------------------------- start layer 3 --------------------------------
DEBUG 01-04 15:36:24.548832.548832 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.549907.549907 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.551530.551530 cuda_h.py:19] end self_attn cost 0.0023386478424072266 seconds
DEBUG 01-04 15:36:24.551195.551195 cuda_h.py:19] end iln_self_attn_paln cost 0.002908468246459961 seconds
DEBUG 01-04 15:36:24.551555.551555 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-04 15:36:24.552649.552649 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.552583.552583 cuda_h.py:19] end gate cost 0.0005867481231689453 seconds
DEBUG 01-04 15:36:24.552651.552651 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.552587.552587 lmp.py:281] 
DEBUG 01-04 15:36:24.552587.552587 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.552674.552674 lmp.py:282]   Total experts: 60
DEBUG 01-04 15:36:24.553894.553894 lmp.py:283]   CPU experts: 30 (50%)
DEBUG 01-04 15:36:24.553490.553490 lmp.py:284]   GPU experts: 30 (50%)
DEBUG 01-04 15:36:24.553895.553895 lmp.py:285] 
DEBUG 01-04 15:36:24.553895.553895 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.553207.553207 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.553810.553810 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:24.553215.553215 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:24.553904.553904 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:24.553878.553878 lmp.py:292]   Expert 42 |      1 | CPU
DEBUG 01-04 15:36:24.553091.553091 lmp.py:292]   Expert 44 |      1 | CPU
DEBUG 01-04 15:36:24.553542.553542 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:24.553277.553277 lmp.py:292]   Expert 10 |      2 | CPU
DEBUG 01-04 15:36:24.553013.553013 lmp.py:292]   Expert 17 |      2 | CPU
DEBUG 01-04 15:36:24.553748.553748 lmp.py:292]   Expert 23 |      2 | CPU
DEBUG 01-04 15:36:24.553484.553484 lmp.py:292]   Expert 40 |      2 | CPU
DEBUG 01-04 15:36:24.553743.553743 lmp.py:292]   Expert 36 |      3 | CPU
DEBUG 01-04 15:36:24.553240.553240 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:24.553737.553737 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:24.553473.553473 lmp.py:292]   Expert 13 |      4 | CPU
DEBUG 01-04 15:36:24.553970.553970 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:24.553183.553183 lmp.py:292]   Expert 30 |      4 | CPU
DEBUG 01-04 15:36:24.553633.553633 lmp.py:292]   Expert 38 |      4 | CPU
DEBUG 01-04 15:36:24.553846.553846 lmp.py:292]   Expert 52 |      4 | CPU
DEBUG 01-04 15:36:24.553343.553343 lmp.py:292]   Expert 55 |      4 | CPU
DEBUG 01-04 15:36:24.553602.553602 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:24.553099.553099 lmp.py:292]   Expert 12 |      5 | CPU
DEBUG 01-04 15:36:24.553358.553358 lmp.py:292]   Expert 20 |      5 | CPU
DEBUG 01-04 15:36:24.553855.553855 lmp.py:292]   Expert 21 |      5 | CPU
DEBUG 01-04 15:36:24.553114.553114 lmp.py:292]   Expert 22 |      5 | CPU
DEBUG 01-04 15:36:24.553373.553373 lmp.py:292]   Expert 33 |      5 | CPU
DEBUG 01-04 15:36:24.553870.553870 lmp.py:292]   Expert 45 |      5 | CPU
DEBUG 01-04 15:36:24.553129.553129 lmp.py:292]   Expert 29 |      6 | CPU
DEBUG 01-04 15:36:24.553626.553626 lmp.py:292]   Expert 62 |      6 | CPU
DEBUG 01-04 15:36:24.553885.553885 lmp.py:292]   Expert  7 |      7 | CPU
DEBUG 01-04 15:36:24.553382.553382 lmp.py:292]   Expert 16 |      7 | CPU
DEBUG 01-04 15:36:24.553879.553879 lmp.py:292]   Expert 31 |      7 | GPU
DEBUG 01-04 15:36:24.553138.553138 lmp.py:292]   Expert 35 |      7 | GPU
DEBUG 01-04 15:36:24.553635.553635 lmp.py:292]   Expert 39 |      7 | GPU
DEBUG 01-04 15:36:24.553907.553907 lmp.py:292]   Expert 46 |      7 | GPU
DEBUG 01-04 15:36:24.553451.553451 lmp.py:292]   Expert 49 |      7 | GPU
DEBUG 01-04 15:36:24.553756.553756 lmp.py:292]   Expert 50 |      7 | GPU
DEBUG 01-04 15:36:24.553492.553492 lmp.py:292]   Expert 14 |      8 | GPU
DEBUG 01-04 15:36:24.553750.553750 lmp.py:292]   Expert 18 |      8 | GPU
DEBUG 01-04 15:36:24.553486.553486 lmp.py:292]   Expert 26 |      8 | GPU
DEBUG 01-04 15:36:24.553745.553745 lmp.py:292]   Expert 27 |      9 | GPU
DEBUG 01-04 15:36:24.553765.553765 lmp.py:292]   Expert 53 |      9 | GPU
DEBUG 01-04 15:36:24.553309.553309 lmp.py:292]   Expert 56 |      9 | GPU
DEBUG 01-04 15:36:24.553614.553614 lmp.py:292]   Expert 58 |      9 | GPU
DEBUG 01-04 15:36:24.553157.553157 lmp.py:292]   Expert 19 |     10 | GPU
DEBUG 01-04 15:36:24.553939.553939 lmp.py:292]   Expert 34 |     10 | GPU
DEBUG 01-04 15:36:24.553960.553960 lmp.py:292]   Expert 48 |     10 | GPU
DEBUG 01-04 15:36:24.553503.553503 lmp.py:292]   Expert 60 |     10 | GPU
DEBUG 01-04 15:36:24.553285.553285 lmp.py:292]   Expert 41 |     13 | GPU
DEBUG 01-04 15:36:24.553829.553829 lmp.py:292]   Expert 51 |     13 | GPU
DEBUG 01-04 15:36:24.553849.553849 lmp.py:292]   Expert 47 |     14 | GPU
DEBUG 01-04 15:36:24.553393.553393 lmp.py:292]   Expert 54 |     14 | GPU
DEBUG 01-04 15:36:24.553936.553936 lmp.py:292]   Expert 43 |     15 | GPU
DEBUG 01-04 15:36:24.553672.553672 lmp.py:292]   Expert 25 |     16 | GPU
DEBUG 01-04 15:36:24.553169.553169 lmp.py:292]   Expert 57 |     16 | GPU
DEBUG 01-04 15:36:24.553382.553382 lmp.py:292]   Expert  1 |   1984 | GPU
DEBUG 01-04 15:36:24.553117.553117 lmp.py:292]   Expert  5 |   1985 | GPU
DEBUG 01-04 15:36:24.553853.553853 lmp.py:292]   Expert  2 |   1987 | GPU
DEBUG 01-04 15:36:24.553873.553873 lmp.py:292]   Expert  4 |   1989 | GPU
DEBUG 01-04 15:36:24.553655.553655 lmp.py:292]   Expert  0 |   1991 | GPU
DEBUG 01-04 15:36:24.554675.554675 lmp.py:292]   Expert  3 |   1999 | GPU
DEBUG 01-04 15:36:24.554934.554934 lmp.py:293] 
DEBUG 01-04 15:36:24.554934.554934 lmp.py:293]   CPU total tokens: 110 (0.9%)
DEBUG 01-04 15:36:24.554670.554670 lmp.py:294]   GPU total tokens: 12178 (99.1%)
DEBUG 01-04 15:36:24.554982.554982 cuda_h.py:19] end experts_map_get cost 0.0013403892517089844 seconds
DEBUG 01-04 15:36:24.554717.554717 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.554918.554918 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.554273.554273 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.554498.554498 cuda_h.py:19] end allocate_cuda_memory cost 0.00017118453979492188 seconds
DEBUG 01-04 15:36:24.554149.554149 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.554090.554090 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.554522.554522 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.554503.554503 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e001bd7c-d583-4152-9234-efa3eb28f406
DEBUG 01-04 15:36:24.554926.554926 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.556865.556865 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e001bd7c-d583-4152-9234-efa3eb28f406
DEBUG 01-04 15:36:24.556479.556479 cuda_h.py:19] end load_into_gpu_async cost 0.002305269241333008 seconds
DEBUG 01-04 15:36:24.556396.556396 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.557687.557687 cuda_h.py:19] end restore_tensors2 cost 0.0005383491516113281 seconds
DEBUG 01-04 15:36:24.557808.557808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003444671630859375 seconds
DEBUG 01-04 15:36:24.560916.560916 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005915403366088867 seconds
DEBUG 01-04 15:36:24.560706.560706 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.560378.560378 lmp.py:339] 
DEBUG 01-04 15:36:24.560378.560378 lmp.py:339]   Computing 30 experts on CPU...
DEBUG 01-04 15:36:24.560975.560975 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-04 15:36:24.560076.560076 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.572804.572804 mlpmodule.py:704] group tensors cost 0.011703252792358398 s
DEBUG 01-04 15:36:24.574634.574634 mlpmodule.py:742] pad cost 0.0015952587127685547 s
DEBUG 01-04 15:36:24.574233.574233 mlpmodule.py:748] create cpu tensor cost 3.719329833984375e-05 s
DEBUG 01-04 15:36:24.574169.574169 mlpmodule.py:753] move to cpu cost 2.6464462280273438e-05 s
DEBUG 01-04 15:36:24.578210.578210 mlpmodule.py:768] group_w3: shape=torch.Size([30, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=86507520
DEBUG 01-04 15:36:24.578637.578637 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.579594.579594 mlpmodule.py:774] group_w3 first element: 0.0206298828125
WARNING 01-04 15:36:24.579729.579729 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.582318.582318 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.582083.582083 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.587463.587463 mlpmodule.py:797] group einsum cost 0.01230764389038086 s
DEBUG 01-04 15:36:24.587325.587325 mlpmodule.py:805] cpy2cputensor cost 7.605552673339844e-05 s
DEBUG 01-04 15:36:24.591764.591764 cuda_h.py:19] end wait_cetm_experts cost 0.030972957611083984 seconds
DEBUG 01-04 15:36:24.591853.591853 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.591519.591519 cuda_h.py:19] end gpu_sexperts cost 0.00044608116149902344 seconds
DEBUG 01-04 15:36:24.591799.591799 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-04 15:36:24.591284.591284 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-04 15:36:24.592087.592087 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.337860107421875e-05 seconds
DEBUG 01-04 15:36:24.592181.592181 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.05718994140625e-05 seconds
DEBUG 01-04 15:36:24.592262.592262 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.592925.592925 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e001bd7c-d583-4152-9234-efa3eb28f406
DEBUG 01-04 15:36:24.592024.592024 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.592526.592526 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.592562.592562 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.597713.597713 cuda_h.py:19] end allocate_cuda_memory cost 0.004440784454345703 seconds
DEBUG 01-04 15:36:24.597166.597166 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.597743.597743 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.597401.597401 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.597442.597442 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9f85a682-0dac-4cb1-b449-650a5fb54f52
DEBUG 01-04 15:36:24.597240.597240 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.607899.607899 client.py:127] Model loaded
DEBUG 01-04 15:36:24.607524.607524 cuda_h.py:19] end wait_experts cost 0.015118837356567383 seconds
DEBUG 01-04 15:36:24.607419.607419 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.607936.607936 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:24.607070.607070 mlpmodule.py:531] gpu group tensors cost 0.0005486011505126953 s
DEBUG 01-04 15:36:24.608585.608585 mlpmodule.py:662]  experts func einsum cost 0.047728538513183594 s
INFO 01-04 15:36:24.608739.608739 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9f85a682-0dac-4cb1-b449-650a5fb54f52
DEBUG 01-04 15:36:24.608066.608066 cuda_h.py:19] end load_into_gpu_async cost 0.011403799057006836 seconds
DEBUG 01-04 15:36:24.608153.608153 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.608096.608096 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-04 15:36:24.608389.608389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.016240596771240234 seconds
INFO 01-04 15:36:24.609434.609434 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9f85a682-0dac-4cb1-b449-650a5fb54f52
DEBUG 01-04 15:36:24.610007.610007 mlpmodule.py:564] gpu pad cost 0.0022025108337402344 s
DEBUG 01-04 15:36:24.610350.610350 mlpmodule.py:582] gpu group einsum cost 0.0005052089691162109 s
DEBUG 01-04 15:36:24.613079.613079 mlpmodule.py:611] gpu experts func einsum cost 0.006174325942993164 s
DEBUG 01-04 15:36:24.613893.613893 cuda_h.py:19] end gpu_experts cost 0.006430625915527344 seconds
DEBUG 01-04 15:36:24.613318.613318 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:24.620264.620264 client.py:127] Model loaded
DEBUG 01-04 15:36:24.620121.620121 cuda_h.py:19] end sllm_worker_task cost 0.028467416763305664 seconds
DEBUG 01-04 15:36:24.620540.620540 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.007191181182861328 seconds
DEBUG 01-04 15:36:24.621698.621698 cuda_h.py:19] end layer_moe_generate_3 cost 0.06910514831542969 seconds
DEBUG 01-04 15:36:24.621127.621127 lmp.py:207] -------------------------------- end layer 3 --------------------------------
DEBUG 01-04 15:36:24.621135.621135 lmp.py:169] -------------------------------- start layer 4 --------------------------------
DEBUG 01-04 15:36:24.621162.621162 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.621973.621973 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.624649.624649 cuda_h.py:19] end self_attn cost 0.0023403167724609375 seconds
DEBUG 01-04 15:36:24.624560.624560 cuda_h.py:19] end iln_self_attn_paln cost 0.0029320716857910156 seconds
DEBUG 01-04 15:36:24.624919.624919 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-04 15:36:24.624001.624001 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.625810.625810 cuda_h.py:19] end gate cost 0.000591278076171875 seconds
DEBUG 01-04 15:36:24.625646.625646 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.625868.625868 lmp.py:281] 
DEBUG 01-04 15:36:24.625868.625868 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.625578.625578 lmp.py:282]   Total experts: 61
DEBUG 01-04 15:36:24.625943.625943 lmp.py:283]   CPU experts: 30 (49%)
DEBUG 01-04 15:36:24.625685.625685 lmp.py:284]   GPU experts: 31 (51%)
DEBUG 01-04 15:36:24.625474.625474 lmp.py:285] 
DEBUG 01-04 15:36:24.625474.625474 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.625501.625501 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.625727.625727 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:24.625754.625754 lmp.py:292]   Expert 26 |      1 | CPU
DEBUG 01-04 15:36:24.625828.625828 lmp.py:292]   Expert 33 |      1 | CPU
DEBUG 01-04 15:36:24.625186.625186 lmp.py:292]   Expert 36 |      1 | CPU
DEBUG 01-04 15:36:24.625544.625544 lmp.py:292]   Expert 45 |      1 | CPU
DEBUG 01-04 15:36:24.625141.625141 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:24.625499.625499 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:24.625619.625619 lmp.py:292]   Expert 22 |      2 | CPU
DEBUG 01-04 15:36:24.625739.625739 lmp.py:292]   Expert 25 |      2 | CPU
DEBUG 01-04 15:36:24.625859.625859 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:24.625740.625740 lmp.py:292]   Expert 37 |      2 | CPU
DEBUG 01-04 15:36:24.625860.625860 lmp.py:292]   Expert 48 |      2 | CPU
DEBUG 01-04 15:36:24.625695.625695 lmp.py:292]   Expert 53 |      2 | CPU
DEBUG 01-04 15:36:24.625768.625768 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:24.625080.625080 lmp.py:292]   Expert 56 |      2 | CPU
DEBUG 01-04 15:36:24.625915.625915 lmp.py:292]   Expert 61 |      2 | CPU
DEBUG 01-04 15:36:24.625797.625797 lmp.py:292]   Expert  7 |      3 | CPU
DEBUG 01-04 15:36:24.625678.625678 lmp.py:292]   Expert 17 |      3 | CPU
DEBUG 01-04 15:36:24.625560.625560 lmp.py:292]   Expert 18 |      3 | CPU
DEBUG 01-04 15:36:24.625441.625441 lmp.py:292]   Expert 21 |      3 | CPU
DEBUG 01-04 15:36:24.625799.625799 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:24.625681.625681 lmp.py:292]   Expert 41 |      3 | CPU
DEBUG 01-04 15:36:24.625562.625562 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:24.625159.625159 lmp.py:292]   Expert 50 |      3 | CPU
DEBUG 01-04 15:36:24.626709.626709 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:24.626306.626306 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:24.626618.626618 lmp.py:292]   Expert 20 |      4 | CPU
DEBUG 01-04 15:36:24.626976.626976 lmp.py:292]   Expert 47 |      4 | CPU
DEBUG 01-04 15:36:24.626334.626334 lmp.py:292]   Expert 12 |      5 | CPU
DEBUG 01-04 15:36:24.626215.626215 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:24.626335.626335 lmp.py:292]   Expert 51 |      5 | GPU
DEBUG 01-04 15:36:24.626978.626978 lmp.py:292]   Expert 62 |      5 | GPU
DEBUG 01-04 15:36:24.626860.626860 lmp.py:292]   Expert 15 |      6 | GPU
DEBUG 01-04 15:36:24.626503.626503 lmp.py:292]   Expert 23 |      6 | GPU
DEBUG 01-04 15:36:24.626384.626384 lmp.py:292]   Expert 35 |      6 | GPU
DEBUG 01-04 15:36:24.626742.626742 lmp.py:292]   Expert 63 |      6 | GPU
DEBUG 01-04 15:36:24.626577.626577 lmp.py:292]   Expert 16 |      7 | GPU
DEBUG 01-04 15:36:24.626174.626174 lmp.py:292]   Expert 19 |      7 | GPU
DEBUG 01-04 15:36:24.626486.626486 lmp.py:292]   Expert 31 |      7 | GPU
DEBUG 01-04 15:36:24.626367.626367 lmp.py:292]   Expert 44 |      7 | GPU
DEBUG 01-04 15:36:24.626249.626249 lmp.py:292]   Expert 46 |      7 | GPU
DEBUG 01-04 15:36:24.626607.626607 lmp.py:292]   Expert 58 |      7 | GPU
DEBUG 01-04 15:36:24.626488.626488 lmp.py:292]   Expert  8 |      8 | GPU
DEBUG 01-04 15:36:24.626370.626370 lmp.py:292]   Expert 14 |      8 | GPU
DEBUG 01-04 15:36:24.626251.626251 lmp.py:292]   Expert 38 |      9 | GPU
DEBUG 01-04 15:36:24.626132.626132 lmp.py:292]   Expert 10 |     11 | GPU
DEBUG 01-04 15:36:24.626014.626014 lmp.py:292]   Expert 32 |     11 | GPU
DEBUG 01-04 15:36:24.626372.626372 lmp.py:292]   Expert 52 |     11 | GPU
DEBUG 01-04 15:36:24.626207.626207 lmp.py:292]   Expert 27 |     13 | GPU
DEBUG 01-04 15:36:24.626281.626281 lmp.py:292]   Expert 49 |     14 | GPU
DEBUG 01-04 15:36:24.626400.626400 lmp.py:292]   Expert 57 |     14 | GPU
DEBUG 01-04 15:36:24.626997.626997 lmp.py:292]   Expert 39 |     19 | GPU
DEBUG 01-04 15:36:24.626117.626117 lmp.py:292]   Expert 43 |     19 | GPU
DEBUG 01-04 15:36:24.626237.626237 lmp.py:292]   Expert 59 |     20 | GPU
DEBUG 01-04 15:36:24.626118.626118 lmp.py:292]   Expert 30 |     23 | GPU
DEBUG 01-04 15:36:24.626238.626238 lmp.py:292]   Expert  3 |   1988 | GPU
DEBUG 01-04 15:36:24.626119.626119 lmp.py:292]   Expert  0 |   1989 | GPU
DEBUG 01-04 15:36:24.626239.626239 lmp.py:292]   Expert  4 |   1989 | GPU
DEBUG 01-04 15:36:24.626120.626120 lmp.py:292]   Expert  2 |   1992 | GPU
DEBUG 01-04 15:36:24.626240.626240 lmp.py:292]   Expert  5 |   1997 | GPU
DEBUG 01-04 15:36:24.626883.626883 lmp.py:292]   Expert  1 |   2002 | GPU
DEBUG 01-04 15:36:24.626195.626195 lmp.py:293] 
DEBUG 01-04 15:36:24.626195.626195 lmp.py:293]   CPU total tokens: 75 (0.6%)
DEBUG 01-04 15:36:24.626699.626699 lmp.py:294]   GPU total tokens: 12213 (99.4%)
DEBUG 01-04 15:36:24.626779.626779 cuda_h.py:19] end experts_map_get cost 0.0015769004821777344 seconds
DEBUG 01-04 15:36:24.626045.626045 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.626590.626590 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.626157.626157 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.627122.627122 cuda_h.py:19] end allocate_cuda_memory cost 0.0002894401550292969 seconds
DEBUG 01-04 15:36:24.627641.627641 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.627741.627741 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.627133.627133 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.627883.627883 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f6547fe5-3a42-49c9-be3f-9345ee4d3039
DEBUG 01-04 15:36:24.627393.627393 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.629384.629384 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f6547fe5-3a42-49c9-be3f-9345ee4d3039
DEBUG 01-04 15:36:24.629843.629843 cuda_h.py:19] end load_into_gpu_async cost 0.002256631851196289 seconds
DEBUG 01-04 15:36:24.629976.629976 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.630123.630123 cuda_h.py:19] end restore_tensors2 cost 0.0003943443298339844 seconds
DEBUG 01-04 15:36:24.630251.630251 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003307819366455078 seconds
DEBUG 01-04 15:36:24.633718.633718 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006225109100341797 seconds
DEBUG 01-04 15:36:24.633091.633091 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.633491.633491 lmp.py:339] 
DEBUG 01-04 15:36:24.633491.633491 lmp.py:339]   Computing 30 experts on CPU...
DEBUG 01-04 15:36:24.633765.633765 cuda_h.py:19] end cpu_experts_submit cost 0.00011396408081054688 seconds
DEBUG 01-04 15:36:24.633183.633183 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.640294.640294 mlpmodule.py:704] group tensors cost 0.006928682327270508 s
DEBUG 01-04 15:36:24.643244.643244 mlpmodule.py:742] pad cost 0.002389669418334961 s
DEBUG 01-04 15:36:24.643540.643540 mlpmodule.py:748] create cpu tensor cost 6.079673767089844e-05 s
DEBUG 01-04 15:36:24.643253.643253 mlpmodule.py:753] move to cpu cost 4.220008850097656e-05 s
DEBUG 01-04 15:36:24.648865.648865 mlpmodule.py:768] group_w3: shape=torch.Size([30, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=86507520
DEBUG 01-04 15:36:24.648196.648196 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.648994.648994 mlpmodule.py:774] group_w3 first element: -0.0015106201171875
WARNING 01-04 15:36:24.648759.648759 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.652934.652934 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.652680.652680 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.656682.656682 mlpmodule.py:797] group einsum cost 0.012737274169921875 s
DEBUG 01-04 15:36:24.656835.656835 mlpmodule.py:805] cpy2cputensor cost 7.128715515136719e-05 s
DEBUG 01-04 15:36:24.660673.660673 cuda_h.py:19] end wait_cetm_experts cost 0.02763056755065918 seconds
DEBUG 01-04 15:36:24.661424.661424 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.661904.661904 cuda_h.py:19] end gpu_sexperts cost 0.00044989585876464844 seconds
DEBUG 01-04 15:36:24.661277.661277 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-04 15:36:24.661146.661146 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-04 15:36:24.661427.661427 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.314018249511719e-05 seconds
DEBUG 01-04 15:36:24.661090.661090 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:24.661886.661886 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.661118.661118 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f6547fe5-3a42-49c9-be3f-9345ee4d3039
DEBUG 01-04 15:36:24.661111.661111 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.662611.662611 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.662553.662553 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.667202.667202 cuda_h.py:19] end allocate_cuda_memory cost 0.00510716438293457 seconds
DEBUG 01-04 15:36:24.667192.667192 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.667101.667101 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.667738.667738 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.667971.667971 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 575b8508-26fb-44a2-ba9b-db1713920b34
DEBUG 01-04 15:36:24.667630.667630 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:24.677051.677051 mlpmodule.py:662]  experts func einsum cost 0.044199466705322266 s
INFO 01-04 15:36:24.681223.681223 client.py:127] Model loaded
DEBUG 01-04 15:36:24.681771.681771 cuda_h.py:19] end wait_experts cost 0.019884109497070312 seconds
DEBUG 01-04 15:36:24.681311.681311 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.681274.681274 lmp.py:384]   Computing 31 experts on GPU...
INFO 01-04 15:36:24.682681.682681 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 575b8508-26fb-44a2-ba9b-db1713920b34
DEBUG 01-04 15:36:24.682670.682670 cuda_h.py:19] end load_into_gpu_async cost 0.015027761459350586 seconds
DEBUG 01-04 15:36:24.682373.682373 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.682595.682595 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-04 15:36:24.682920.682920 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.02048945426940918 seconds
DEBUG 01-04 15:36:24.682306.682306 mlpmodule.py:531] gpu group tensors cost 0.0008525848388671875 s
INFO 01-04 15:36:24.683971.683971 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 575b8508-26fb-44a2-ba9b-db1713920b34
DEBUG 01-04 15:36:24.685414.685414 mlpmodule.py:564] gpu pad cost 0.0021598339080810547 s
DEBUG 01-04 15:36:24.685959.685959 mlpmodule.py:582] gpu group einsum cost 0.0007891654968261719 s
DEBUG 01-04 15:36:24.689139.689139 mlpmodule.py:611] gpu experts func einsum cost 0.007330656051635742 s
DEBUG 01-04 15:36:24.689529.689529 cuda_h.py:19] end gpu_experts cost 0.0076444149017333984 seconds
DEBUG 01-04 15:36:24.689630.689630 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:24.693689.693689 client.py:127] Model loaded
DEBUG 01-04 15:36:24.693499.693499 cuda_h.py:19] end sllm_worker_task cost 0.031485795974731445 seconds
DEBUG 01-04 15:36:24.693270.693270 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004052877426147461 seconds
DEBUG 01-04 15:36:24.693077.693077 cuda_h.py:19] end layer_moe_generate_4 cost 0.0693356990814209 seconds
DEBUG 01-04 15:36:24.693249.693249 lmp.py:207] -------------------------------- end layer 4 --------------------------------
DEBUG 01-04 15:36:24.694979.694979 lmp.py:169] -------------------------------- start layer 5 --------------------------------
DEBUG 01-04 15:36:24.694536.694536 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.694573.694573 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.696341.696341 cuda_h.py:19] end self_attn cost 0.0025060176849365234 seconds
DEBUG 01-04 15:36:24.697550.697550 cuda_h.py:19] end iln_self_attn_paln cost 0.0031387805938720703 seconds
DEBUG 01-04 15:36:24.697101.697101 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-04 15:36:24.697149.697149 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.697348.697348 cuda_h.py:19] end gate cost 0.0005705356597900391 seconds
DEBUG 01-04 15:36:24.697985.697985 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.698028.698028 lmp.py:281] 
DEBUG 01-04 15:36:24.698028.698028 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.698068.698068 lmp.py:282]   Total experts: 58
DEBUG 01-04 15:36:24.698241.698241 lmp.py:283]   CPU experts: 29 (50%)
DEBUG 01-04 15:36:24.698792.698792 lmp.py:284]   GPU experts: 29 (50%)
DEBUG 01-04 15:36:24.698435.698435 lmp.py:285] 
DEBUG 01-04 15:36:24.698435.698435 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.698078.698078 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.698727.698727 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:24.698655.698655 lmp.py:292]   Expert 28 |      1 | CPU
DEBUG 01-04 15:36:24.698868.698868 lmp.py:292]   Expert 30 |      1 | CPU
DEBUG 01-04 15:36:24.698603.698603 lmp.py:292]   Expert 14 |      2 | CPU
DEBUG 01-04 15:36:24.698577.698577 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:24.698790.698790 lmp.py:292]   Expert 39 |      2 | CPU
DEBUG 01-04 15:36:24.698287.698287 lmp.py:292]   Expert 41 |      2 | CPU
DEBUG 01-04 15:36:24.698261.698261 lmp.py:292]   Expert 45 |      2 | CPU
DEBUG 01-04 15:36:24.698520.698520 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:24.698494.698494 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:24.698753.698753 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:24.698250.698250 lmp.py:292]   Expert 47 |      3 | CPU
DEBUG 01-04 15:36:24.698747.698747 lmp.py:292]   Expert 10 |      4 | CPU
DEBUG 01-04 15:36:24.698721.698721 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:24.698410.698410 lmp.py:292]   Expert 12 |      4 | CPU
DEBUG 01-04 15:36:24.698861.698861 lmp.py:292]   Expert 16 |      4 | CPU
DEBUG 01-04 15:36:24.698312.698312 lmp.py:292]   Expert 20 |      4 | CPU
DEBUG 01-04 15:36:24.698763.698763 lmp.py:292]   Expert 21 |      4 | CPU
DEBUG 01-04 15:36:24.698499.698499 lmp.py:292]   Expert 34 |      4 | CPU
DEBUG 01-04 15:36:24.698996.698996 lmp.py:292]   Expert 43 |      4 | CPU
DEBUG 01-04 15:36:24.698731.698731 lmp.py:292]   Expert 56 |      4 | CPU
DEBUG 01-04 15:36:24.698467.698467 lmp.py:292]   Expert 22 |      5 | CPU
DEBUG 01-04 15:36:24.698726.698726 lmp.py:292]   Expert 24 |      5 | CPU
DEBUG 01-04 15:36:24.698223.698223 lmp.py:292]   Expert 29 |      5 | CPU
DEBUG 01-04 15:36:24.698482.698482 lmp.py:292]   Expert 32 |      5 | CPU
DEBUG 01-04 15:36:24.698979.698979 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:24.698715.698715 lmp.py:292]   Expert 38 |      5 | CPU
DEBUG 01-04 15:36:24.698973.698973 lmp.py:292]   Expert 46 |      5 | CPU
DEBUG 01-04 15:36:24.698471.698471 lmp.py:292]   Expert  7 |      6 | CPU
DEBUG 01-04 15:36:24.698968.698968 lmp.py:292]   Expert 26 |      6 | GPU
DEBUG 01-04 15:36:24.698419.698419 lmp.py:292]   Expert 31 |      6 | GPU
DEBUG 01-04 15:36:24.698870.698870 lmp.py:292]   Expert 36 |      6 | GPU
DEBUG 01-04 15:36:24.698844.698844 lmp.py:292]   Expert 40 |      6 | GPU
DEBUG 01-04 15:36:24.698818.698818 lmp.py:292]   Expert 55 |      6 | GPU
DEBUG 01-04 15:36:24.698077.698077 lmp.py:292]   Expert 52 |      7 | GPU
DEBUG 01-04 15:36:24.698574.698574 lmp.py:292]   Expert 58 |      7 | GPU
DEBUG 01-04 15:36:24.698833.698833 lmp.py:292]   Expert 44 |      8 | GPU
DEBUG 01-04 15:36:24.698330.698330 lmp.py:292]   Expert 60 |      8 | GPU
DEBUG 01-04 15:36:24.698589.698589 lmp.py:292]   Expert 50 |      9 | GPU
DEBUG 01-04 15:36:24.698324.698324 lmp.py:292]   Expert 42 |     10 | GPU
DEBUG 01-04 15:36:24.698583.698583 lmp.py:292]   Expert 54 |     10 | GPU
DEBUG 01-04 15:36:24.699842.699842 lmp.py:292]   Expert 57 |     10 | GPU
DEBUG 01-04 15:36:24.699577.699577 lmp.py:292]   Expert 59 |     11 | GPU
DEBUG 01-04 15:36:24.699836.699836 lmp.py:292]   Expert  6 |     12 | GPU
DEBUG 01-04 15:36:24.699333.699333 lmp.py:292]   Expert 19 |     12 | GPU
DEBUG 01-04 15:36:24.699831.699831 lmp.py:292]   Expert 49 |     12 | GPU
DEBUG 01-04 15:36:24.699089.699089 lmp.py:292]   Expert 33 |     15 | GPU
DEBUG 01-04 15:36:24.699971.699971 lmp.py:292]   Expert 48 |     15 | GPU
DEBUG 01-04 15:36:24.699422.699422 lmp.py:292]   Expert 61 |     16 | GPU
DEBUG 01-04 15:36:24.699634.699634 lmp.py:292]   Expert 13 |     21 | GPU
DEBUG 01-04 15:36:24.699608.699608 lmp.py:292]   Expert 37 |     21 | GPU
DEBUG 01-04 15:36:24.699867.699867 lmp.py:292]   Expert 53 |     24 | GPU
DEBUG 01-04 15:36:24.699364.699364 lmp.py:292]   Expert  0 |   1984 | GPU
DEBUG 01-04 15:36:24.699623.699623 lmp.py:292]   Expert  2 |   1984 | GPU
DEBUG 01-04 15:36:24.699643.699643 lmp.py:292]   Expert  4 |   1985 | GPU
DEBUG 01-04 15:36:24.699140.699140 lmp.py:292]   Expert  1 |   1987 | GPU
DEBUG 01-04 15:36:24.699399.699399 lmp.py:292]   Expert  3 |   1988 | GPU
DEBUG 01-04 15:36:24.699658.699658 lmp.py:292]   Expert  5 |   2002 | GPU
DEBUG 01-04 15:36:24.699632.699632 lmp.py:293] 
DEBUG 01-04 15:36:24.699632.699632 lmp.py:293]   CPU total tokens: 100 (0.8%)
DEBUG 01-04 15:36:24.699845.699845 lmp.py:294]   GPU total tokens: 12188 (99.2%)
DEBUG 01-04 15:36:24.699349.699349 cuda_h.py:19] end experts_map_get cost 0.0013129711151123047 seconds
DEBUG 01-04 15:36:24.699515.699515 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.699576.699576 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.699183.699183 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.699746.699746 cuda_h.py:19] end allocate_cuda_memory cost 0.00017523765563964844 seconds
DEBUG 01-04 15:36:24.699966.699966 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.699385.699385 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.699101.699101 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.699082.699082 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc555c38-5bb0-4fc9-83c3-09cae19343c8
DEBUG 01-04 15:36:24.700452.700452 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.701889.701889 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc555c38-5bb0-4fc9-83c3-09cae19343c8
DEBUG 01-04 15:36:24.701719.701719 cuda_h.py:19] end load_into_gpu_async cost 0.002070903778076172 seconds
DEBUG 01-04 15:36:24.701535.701535 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.702832.702832 cuda_h.py:19] end restore_tensors2 cost 0.0003337860107421875 seconds
DEBUG 01-04 15:36:24.702761.702761 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029230117797851562 seconds
DEBUG 01-04 15:36:24.704170.704170 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005301237106323242 seconds
DEBUG 01-04 15:36:24.704960.704960 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.704015.704015 lmp.py:339] 
DEBUG 01-04 15:36:24.704015.704015 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:24.704805.704805 cuda_h.py:19] end cpu_experts_submit cost 0.00010418891906738281 seconds
DEBUG 01-04 15:36:24.704124.704124 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.712646.712646 mlpmodule.py:704] group tensors cost 0.007930994033813477 s
DEBUG 01-04 15:36:24.716842.716842 mlpmodule.py:742] pad cost 0.0023899078369140625 s
DEBUG 01-04 15:36:24.716725.716725 mlpmodule.py:748] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-04 15:36:24.716284.716284 mlpmodule.py:753] move to cpu cost 2.7179718017578125e-05 s
DEBUG 01-04 15:36:24.720189.720189 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:24.720901.720901 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.720725.720725 mlpmodule.py:774] group_w3 first element: 0.0537109375
WARNING 01-04 15:36:24.720629.720629 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.724761.724761 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.724702.724702 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.728196.728196 mlpmodule.py:797] group einsum cost 0.012545347213745117 s
DEBUG 01-04 15:36:24.729946.729946 mlpmodule.py:805] cpy2cputensor cost 0.00010037422180175781 s
DEBUG 01-04 15:36:24.733555.733555 cuda_h.py:19] end wait_cetm_experts cost 0.028256654739379883 seconds
DEBUG 01-04 15:36:24.733029.733029 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.733271.733271 cuda_h.py:19] end gpu_sexperts cost 0.00044989585876464844 seconds
DEBUG 01-04 15:36:24.733597.733597 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-04 15:36:24.733228.733228 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-04 15:36:24.733608.733608 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.24249267578125e-05 seconds
DEBUG 01-04 15:36:24.733178.733178 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.414817810058594e-05 seconds
DEBUG 01-04 15:36:24.734212.734212 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.734876.734876 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc555c38-5bb0-4fc9-83c3-09cae19343c8
DEBUG 01-04 15:36:24.734683.734683 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.734105.734105 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.734650.734650 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.739121.739121 cuda_h.py:19] end allocate_cuda_memory cost 0.005103588104248047 seconds
DEBUG 01-04 15:36:24.739177.739177 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.739370.739370 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.739915.739915 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.739909.739909 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de8efd43-693a-4876-b949-eda9bbc3b048
DEBUG 01-04 15:36:24.739522.739522 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.749246.749246 client.py:127] Model loaded
DEBUG 01-04 15:36:24.749188.749188 cuda_h.py:19] end wait_experts cost 0.01547098159790039 seconds
DEBUG 01-04 15:36:24.749699.749699 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.749971.749971 lmp.py:384]   Computing 29 experts on GPU...
DEBUG 01-04 15:36:24.750037.750037 mlpmodule.py:531] gpu group tensors cost 0.0005080699920654297 s
DEBUG 01-04 15:36:24.750532.750532 mlpmodule.py:662]  experts func einsum cost 0.04530048370361328 s
INFO 01-04 15:36:24.750427.750427 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de8efd43-693a-4876-b949-eda9bbc3b048
DEBUG 01-04 15:36:24.750276.750276 cuda_h.py:19] end load_into_gpu_async cost 0.010850667953491211 seconds
DEBUG 01-04 15:36:24.750456.750456 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.750969.750969 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-04 15:36:24.750248.750248 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.016314029693603516 seconds
INFO 01-04 15:36:24.751459.751459 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de8efd43-693a-4876-b949-eda9bbc3b048
DEBUG 01-04 15:36:24.752940.752940 mlpmodule.py:564] gpu pad cost 0.0021886825561523438 s
DEBUG 01-04 15:36:24.752999.752999 mlpmodule.py:582] gpu group einsum cost 0.0004680156707763672 s
DEBUG 01-04 15:36:24.755772.755772 mlpmodule.py:611] gpu experts func einsum cost 0.006035566329956055 s
DEBUG 01-04 15:36:24.755553.755553 cuda_h.py:19] end gpu_experts cost 0.006293058395385742 seconds
DEBUG 01-04 15:36:24.755170.755170 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:24.760726.760726 client.py:127] Model loaded
DEBUG 01-04 15:36:24.760868.760868 cuda_h.py:19] end sllm_worker_task cost 0.026552915573120117 seconds
DEBUG 01-04 15:36:24.760095.760095 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005041599273681641 seconds
DEBUG 01-04 15:36:24.761398.761398 cuda_h.py:19] end layer_moe_generate_5 cost 0.06381011009216309 seconds
DEBUG 01-04 15:36:24.761450.761450 lmp.py:207] -------------------------------- end layer 5 --------------------------------
DEBUG 01-04 15:36:24.761313.761313 lmp.py:169] -------------------------------- start layer 6 --------------------------------
DEBUG 01-04 15:36:24.761863.761863 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.761945.761945 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.764429.764429 cuda_h.py:19] end self_attn cost 0.002329587936401367 seconds
DEBUG 01-04 15:36:24.764207.764207 cuda_h.py:19] end iln_self_attn_paln cost 0.0029294490814208984 seconds
DEBUG 01-04 15:36:24.764328.764328 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-04 15:36:24.764290.764290 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.765085.765085 cuda_h.py:19] end gate cost 0.0005700588226318359 seconds
DEBUG 01-04 15:36:24.765392.765392 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.765513.765513 lmp.py:281] 
DEBUG 01-04 15:36:24.765513.765513 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.765077.765077 lmp.py:282]   Total experts: 58
DEBUG 01-04 15:36:24.765250.765250 lmp.py:283]   CPU experts: 29 (50%)
DEBUG 01-04 15:36:24.765800.765800 lmp.py:284]   GPU experts: 29 (50%)
DEBUG 01-04 15:36:24.765205.765205 lmp.py:285] 
DEBUG 01-04 15:36:24.765205.765205 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.765371.765371 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.765021.765021 lmp.py:292]   Expert 10 |      1 | CPU
DEBUG 01-04 15:36:24.765617.765617 lmp.py:292]   Expert 37 |      1 | CPU
DEBUG 01-04 15:36:24.765260.765260 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:24.765426.765426 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:24.765069.765069 lmp.py:292]   Expert 53 |      1 | CPU
DEBUG 01-04 15:36:24.765997.765997 lmp.py:292]   Expert 11 |      2 | CPU
DEBUG 01-04 15:36:24.765448.765448 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:24.765912.765912 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:24.765886.765886 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:24.765384.765384 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:24.765119.765119 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:24.765855.765855 lmp.py:292]   Expert 19 |      3 | CPU
DEBUG 01-04 15:36:24.765591.765591 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:24.765088.765088 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:24.765300.765300 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:24.765228.765228 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:24.765679.765679 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:24.765368.765368 lmp.py:292]   Expert 30 |      4 | CPU
DEBUG 01-04 15:36:24.765342.765342 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:24.765555.765555 lmp.py:292]   Expert 43 |      4 | CPU
DEBUG 01-04 15:36:24.765529.765529 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:24.765503.765503 lmp.py:292]   Expert 63 |      4 | CPU
DEBUG 01-04 15:36:24.765000.765000 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:24.765974.765974 lmp.py:292]   Expert 12 |      5 | CPU
DEBUG 01-04 15:36:24.765710.765710 lmp.py:292]   Expert 23 |      5 | CPU
DEBUG 01-04 15:36:24.765684.765684 lmp.py:292]   Expert 48 |      5 | CPU
DEBUG 01-04 15:36:24.765942.765942 lmp.py:292]   Expert 52 |      5 | CPU
DEBUG 01-04 15:36:24.765678.765678 lmp.py:292]   Expert 38 |      6 | CPU
DEBUG 01-04 15:36:24.765175.765175 lmp.py:292]   Expert 41 |      6 | CPU
DEBUG 01-04 15:36:24.765149.765149 lmp.py:292]   Expert 49 |      6 | GPU
DEBUG 01-04 15:36:24.765885.765885 lmp.py:292]   Expert 54 |      7 | GPU
DEBUG 01-04 15:36:24.765621.765621 lmp.py:292]   Expert 57 |      7 | GPU
DEBUG 01-04 15:36:24.765071.765071 lmp.py:292]   Expert  6 |      8 | GPU
DEBUG 01-04 15:36:24.766284.766284 lmp.py:292]   Expert  8 |      8 | GPU
DEBUG 01-04 15:36:24.766973.766973 lmp.py:292]   Expert 17 |      8 | GPU
DEBUG 01-04 15:36:24.766424.766424 lmp.py:292]   Expert 24 |      8 | GPU
DEBUG 01-04 15:36:24.766921.766921 lmp.py:292]   Expert 25 |      8 | GPU
DEBUG 01-04 15:36:24.766657.766657 lmp.py:292]   Expert 13 |      9 | GPU
DEBUG 01-04 15:36:24.766154.766154 lmp.py:292]   Expert  7 |     10 | GPU
DEBUG 01-04 15:36:24.766651.766651 lmp.py:292]   Expert 21 |     10 | GPU
DEBUG 01-04 15:36:24.766910.766910 lmp.py:292]   Expert 46 |     10 | GPU
DEBUG 01-04 15:36:24.766407.766407 lmp.py:292]   Expert 59 |     10 | GPU
DEBUG 01-04 15:36:24.766666.766666 lmp.py:292]   Expert 20 |     11 | GPU
DEBUG 01-04 15:36:24.766879.766879 lmp.py:292]   Expert 27 |     11 | GPU
DEBUG 01-04 15:36:24.766853.766853 lmp.py:292]   Expert 62 |     11 | GPU
DEBUG 01-04 15:36:24.766827.766827 lmp.py:292]   Expert 18 |     15 | GPU
DEBUG 01-04 15:36:24.766039.766039 lmp.py:292]   Expert 33 |     16 | GPU
DEBUG 01-04 15:36:24.766775.766775 lmp.py:292]   Expert 61 |     16 | GPU
DEBUG 01-04 15:36:24.766749.766749 lmp.py:292]   Expert 39 |     17 | GPU
DEBUG 01-04 15:36:24.766008.766008 lmp.py:292]   Expert 36 |     20 | GPU
DEBUG 01-04 15:36:24.766743.766743 lmp.py:292]   Expert 60 |     23 | GPU
DEBUG 01-04 15:36:24.766002.766002 lmp.py:292]   Expert 56 |     24 | GPU
DEBUG 01-04 15:36:24.766976.766976 lmp.py:292]   Expert  1 |   1984 | GPU
DEBUG 01-04 15:36:24.766473.766473 lmp.py:292]   Expert  3 |   1984 | GPU
DEBUG 01-04 15:36:24.766970.766970 lmp.py:292]   Expert  5 |   1986 | GPU
DEBUG 01-04 15:36:24.766706.766706 lmp.py:292]   Expert  2 |   1988 | GPU
DEBUG 01-04 15:36:24.766395.766395 lmp.py:292]   Expert  0 |   1989 | GPU
DEBUG 01-04 15:36:24.766608.766608 lmp.py:292]   Expert  4 |   1990 | GPU
DEBUG 01-04 15:36:24.766297.766297 lmp.py:293] 
DEBUG 01-04 15:36:24.766297.766297 lmp.py:293]   CPU total tokens: 94 (0.8%)
DEBUG 01-04 15:36:24.766417.766417 lmp.py:294]   GPU total tokens: 12194 (99.2%)
DEBUG 01-04 15:36:24.766159.766159 cuda_h.py:19] end experts_map_get cost 0.0013451576232910156 seconds
DEBUG 01-04 15:36:24.766326.766326 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.766195.766195 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.766934.766934 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.766334.766334 cuda_h.py:19] end allocate_cuda_memory cost 0.00026345252990722656 seconds
DEBUG 01-04 15:36:24.766846.766846 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.767457.767457 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.767650.767650 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.767061.767061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2f7e4e6d-c063-43d3-b0f8-b198e932be8e
DEBUG 01-04 15:36:24.767253.767253 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.769913.769913 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2f7e4e6d-c063-43d3-b0f8-b198e932be8e
DEBUG 01-04 15:36:24.770050.770050 cuda_h.py:19] end load_into_gpu_async cost 0.0030524730682373047 seconds
DEBUG 01-04 15:36:24.770105.770105 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.771465.771465 cuda_h.py:19] end restore_tensors2 cost 0.0007834434509277344 seconds
DEBUG 01-04 15:36:24.771673.771673 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004579782485961914 seconds
DEBUG 01-04 15:36:24.773798.773798 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006958961486816406 seconds
DEBUG 01-04 15:36:24.773157.773157 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.773312.773312 lmp.py:339] 
DEBUG 01-04 15:36:24.773312.773312 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:24.773845.773845 cuda_h.py:19] end cpu_experts_submit cost 0.0001266002655029297 seconds
DEBUG 01-04 15:36:24.773230.773230 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.786868.786868 mlpmodule.py:704] group tensors cost 0.012375831604003906 s
DEBUG 01-04 15:36:24.788382.788382 mlpmodule.py:742] pad cost 0.0013456344604492188 s
DEBUG 01-04 15:36:24.788319.788319 mlpmodule.py:748] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-04 15:36:24.788785.788785 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-04 15:36:24.792233.792233 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:24.792345.792345 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.792493.792493 mlpmodule.py:774] group_w3 first element: -0.00604248046875
WARNING 01-04 15:36:24.792543.792543 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.796856.796856 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.796466.796466 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.799130.799130 mlpmodule.py:797] group einsum cost 0.011047124862670898 s
DEBUG 01-04 15:36:24.800019.800019 mlpmodule.py:805] cpy2cputensor cost 0.00011134147644042969 s
DEBUG 01-04 15:36:24.803357.803357 cuda_h.py:19] end wait_cetm_experts cost 0.030242919921875 seconds
DEBUG 01-04 15:36:24.804678.804678 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.804391.804391 cuda_h.py:19] end gpu_sexperts cost 0.0004730224609375 seconds
DEBUG 01-04 15:36:24.804287.804287 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-04 15:36:24.804441.804441 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-04 15:36:24.804582.804582 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.314018249511719e-05 seconds
DEBUG 01-04 15:36:24.804484.804484 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.343292236328125e-05 seconds
DEBUG 01-04 15:36:24.804803.804803 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.804797.804797 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2f7e4e6d-c063-43d3-b0f8-b198e932be8e
DEBUG 01-04 15:36:24.805935.805935 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.805436.805436 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.805207.805207 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.810493.810493 cuda_h.py:19] end allocate_cuda_memory cost 0.0047266483306884766 seconds
DEBUG 01-04 15:36:24.810979.810979 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.810126.810126 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.810478.810478 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.810473.810473 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2db01787-295f-4e2b-8888-a01d55657f29
DEBUG 01-04 15:36:24.810893.810893 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.817601.817601 client.py:127] Model loaded
DEBUG 01-04 15:36:24.817636.817636 cuda_h.py:19] end wait_experts cost 0.012593507766723633 seconds
DEBUG 01-04 15:36:24.817577.817577 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.817850.817850 lmp.py:384]   Computing 29 experts on GPU...
DEBUG 01-04 15:36:24.818186.818186 mlpmodule.py:531] gpu group tensors cost 0.0004968643188476562 s
INFO 01-04 15:36:24.818210.818210 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2db01787-295f-4e2b-8888-a01d55657f29
DEBUG 01-04 15:36:24.818291.818291 cuda_h.py:19] end load_into_gpu_async cost 0.008304595947265625 seconds
DEBUG 01-04 15:36:24.818948.818948 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.818269.818269 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-04 15:36:24.818833.818833 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.013381242752075195 seconds
INFO 01-04 15:36:24.819009.819009 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2db01787-295f-4e2b-8888-a01d55657f29
DEBUG 01-04 15:36:24.820393.820393 mlpmodule.py:564] gpu pad cost 0.0021703243255615234 s
DEBUG 01-04 15:36:24.820631.820631 mlpmodule.py:662]  experts func einsum cost 0.04688072204589844 s
DEBUG 01-04 15:36:24.820409.820409 mlpmodule.py:582] gpu group einsum cost 0.0005764961242675781 s
DEBUG 01-04 15:36:24.823737.823737 mlpmodule.py:611] gpu experts func einsum cost 0.0060634613037109375 s
DEBUG 01-04 15:36:24.823432.823432 cuda_h.py:19] end gpu_experts cost 0.006329059600830078 seconds
DEBUG 01-04 15:36:24.823665.823665 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:24.828214.828214 client.py:127] Model loaded
DEBUG 01-04 15:36:24.828166.828166 cuda_h.py:19] end sllm_worker_task cost 0.023774147033691406 seconds
DEBUG 01-04 15:36:24.829657.829657 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005244016647338867 seconds
DEBUG 01-04 15:36:24.829118.829118 cuda_h.py:19] end layer_moe_generate_6 cost 0.06507611274719238 seconds
DEBUG 01-04 15:36:24.829532.829532 lmp.py:207] -------------------------------- end layer 6 --------------------------------
DEBUG 01-04 15:36:24.829309.829309 lmp.py:169] -------------------------------- start layer 7 --------------------------------
DEBUG 01-04 15:36:24.829470.829470 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.830334.830334 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.834100.834100 cuda_h.py:19] end self_attn cost 0.004187107086181641 seconds
DEBUG 01-04 15:36:24.835868.835868 cuda_h.py:19] end iln_self_attn_paln cost 0.0052869319915771484 seconds
DEBUG 01-04 15:36:24.835302.835302 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-04 15:36:24.835357.835357 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.836208.836208 cuda_h.py:19] end gate cost 0.0010116100311279297 seconds
DEBUG 01-04 15:36:24.836576.836576 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.837833.837833 lmp.py:281] 
DEBUG 01-04 15:36:24.837833.837833 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.837114.837114 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:24.837612.837612 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:24.837726.837726 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:24.837304.837304 lmp.py:285] 
DEBUG 01-04 15:36:24.837304.837304 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.837404.837404 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.837234.837234 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:24.837050.837050 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:24.837872.837872 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:24.837184.837184 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:24.837496.837496 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:24.837570.837570 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:24.837882.837882 lmp.py:292]   Expert 62 |      1 | CPU
DEBUG 01-04 15:36:24.837194.837194 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:24.837698.837698 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:24.837771.837771 lmp.py:292]   Expert 30 |      2 | CPU
DEBUG 01-04 15:36:24.837606.837606 lmp.py:292]   Expert 33 |      2 | CPU
DEBUG 01-04 15:36:24.837680.837680 lmp.py:292]   Expert 39 |      2 | CPU
DEBUG 01-04 15:36:24.837515.837515 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:24.837350.837350 lmp.py:292]   Expert 59 |      2 | CPU
DEBUG 01-04 15:36:24.837946.837946 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:24.837020.837020 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:24.837855.837855 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:24.837452.837452 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:24.837002.837002 lmp.py:292]   Expert 21 |      4 | CPU
DEBUG 01-04 15:36:24.837744.837744 lmp.py:292]   Expert 24 |      4 | CPU
DEBUG 01-04 15:36:24.837010.837010 lmp.py:292]   Expert 50 |      4 | CPU
DEBUG 01-04 15:36:24.837845.837845 lmp.py:292]   Expert 52 |      4 | CPU
DEBUG 01-04 15:36:24.837680.837680 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:24.837515.837515 lmp.py:292]   Expert 10 |      5 | CPU
DEBUG 01-04 15:36:24.838873.838873 lmp.py:292]   Expert 17 |      5 | CPU
DEBUG 01-04 15:36:24.838708.838708 lmp.py:292]   Expert 19 |      5 | CPU
DEBUG 01-04 15:36:24.838543.838543 lmp.py:292]   Expert 36 |      5 | CPU
DEBUG 01-04 15:36:24.838571.838571 lmp.py:292]   Expert 45 |      5 | CPU
DEBUG 01-04 15:36:24.838406.838406 lmp.py:292]   Expert 49 |      5 | CPU
DEBUG 01-04 15:36:24.838479.838479 lmp.py:292]   Expert 53 |      5 | GPU
DEBUG 01-04 15:36:24.838599.838599 lmp.py:292]   Expert 55 |      5 | GPU
DEBUG 01-04 15:36:24.838434.838434 lmp.py:292]   Expert 13 |      6 | GPU
DEBUG 01-04 15:36:24.838792.838792 lmp.py:292]   Expert 27 |      6 | GPU
DEBUG 01-04 15:36:24.838151.838151 lmp.py:292]   Expert 35 |      6 | GPU
DEBUG 01-04 15:36:24.838986.838986 lmp.py:292]   Expert 40 |      6 | GPU
DEBUG 01-04 15:36:24.838582.838582 lmp.py:292]   Expert 47 |      6 | GPU
DEBUG 01-04 15:36:24.838179.838179 lmp.py:292]   Expert 51 |      6 | GPU
DEBUG 01-04 15:36:24.838206.838206 lmp.py:292]   Expert 28 |      7 | GPU
DEBUG 01-04 15:36:24.838948.838948 lmp.py:292]   Expert 31 |      7 | GPU
DEBUG 01-04 15:36:24.838784.838784 lmp.py:292]   Expert 37 |      7 | GPU
DEBUG 01-04 15:36:24.838857.838857 lmp.py:292]   Expert 42 |      7 | GPU
DEBUG 01-04 15:36:24.838454.838454 lmp.py:292]   Expert 43 |      7 | GPU
DEBUG 01-04 15:36:24.838289.838289 lmp.py:292]   Expert 56 |      7 | GPU
DEBUG 01-04 15:36:24.838885.838885 lmp.py:292]   Expert 46 |      9 | GPU
DEBUG 01-04 15:36:24.838959.838959 lmp.py:292]   Expert 22 |     10 | GPU
DEBUG 01-04 15:36:24.838317.838317 lmp.py:292]   Expert 61 |     12 | GPU
DEBUG 01-04 15:36:24.838391.838391 lmp.py:292]   Expert 38 |     14 | GPU
DEBUG 01-04 15:36:24.838656.838656 lmp.py:292]   Expert 12 |     15 | GPU
DEBUG 01-04 15:36:24.838968.838968 lmp.py:292]   Expert 60 |     17 | GPU
DEBUG 01-04 15:36:24.838565.838565 lmp.py:292]   Expert 23 |     18 | GPU
DEBUG 01-04 15:36:24.838923.838923 lmp.py:292]   Expert 44 |     23 | GPU
DEBUG 01-04 15:36:24.838758.838758 lmp.py:292]   Expert 14 |     28 | GPU
DEBUG 01-04 15:36:24.838116.838116 lmp.py:292]   Expert  9 |     32 | GPU
DEBUG 01-04 15:36:24.838713.838713 lmp.py:292]   Expert  5 |   1985 | GPU
DEBUG 01-04 15:36:24.838548.838548 lmp.py:292]   Expert  3 |   1986 | GPU
DEBUG 01-04 15:36:24.838145.838145 lmp.py:292]   Expert  1 |   1987 | GPU
DEBUG 01-04 15:36:24.838741.838741 lmp.py:292]   Expert  4 |   1987 | GPU
DEBUG 01-04 15:36:24.838338.838338 lmp.py:292]   Expert  0 |   1990 | GPU
DEBUG 01-04 15:36:24.838127.838127 lmp.py:292]   Expert  2 |   2003 | GPU
DEBUG 01-04 15:36:24.838677.838677 lmp.py:293] 
DEBUG 01-04 15:36:24.838677.838677 lmp.py:293]   CPU total tokens: 84 (0.7%)
DEBUG 01-04 15:36:24.838466.838466 lmp.py:294]   GPU total tokens: 12204 (99.3%)
DEBUG 01-04 15:36:24.838215.838215 cuda_h.py:19] end experts_map_get cost 0.002031564712524414 seconds
DEBUG 01-04 15:36:24.838196.838196 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.838555.838555 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.838461.838461 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.839902.839902 cuda_h.py:19] end allocate_cuda_memory cost 0.0002887248992919922 seconds
DEBUG 01-04 15:36:24.839043.839043 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.839376.839376 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.839337.839337 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.839325.839325 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b76ee942-0add-4d66-aa2f-d0c2e46157d8
DEBUG 01-04 15:36:24.839226.839226 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.841997.841997 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b76ee942-0add-4d66-aa2f-d0c2e46157d8
DEBUG 01-04 15:36:24.841218.841218 cuda_h.py:19] end load_into_gpu_async cost 0.002199888229370117 seconds
DEBUG 01-04 15:36:24.841874.841874 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.842107.842107 cuda_h.py:19] end restore_tensors2 cost 0.0003871917724609375 seconds
DEBUG 01-04 15:36:24.842572.842572 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032501220703125 seconds
DEBUG 01-04 15:36:24.844967.844967 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006189823150634766 seconds
DEBUG 01-04 15:36:24.845717.845717 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.845932.845932 lmp.py:339] 
DEBUG 01-04 15:36:24.845932.845932 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:24.845590.845590 cuda_h.py:19] end cpu_experts_submit cost 0.00011730194091796875 seconds
DEBUG 01-04 15:36:24.845770.845770 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.856541.856541 mlpmodule.py:704] group tensors cost 0.01154637336730957 s
DEBUG 01-04 15:36:24.859535.859535 mlpmodule.py:742] pad cost 0.0016646385192871094 s
DEBUG 01-04 15:36:24.859354.859354 mlpmodule.py:748] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-04 15:36:24.859264.859264 mlpmodule.py:753] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-04 15:36:24.863292.863292 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:24.863050.863050 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.863305.863305 mlpmodule.py:774] group_w3 first element: -0.08056640625
WARNING 01-04 15:36:24.863639.863639 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.867734.867734 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.867862.867862 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.870789.870789 mlpmodule.py:797] group einsum cost 0.011064529418945312 s
DEBUG 01-04 15:36:24.871796.871796 mlpmodule.py:805] cpy2cputensor cost 7.224082946777344e-05 s
DEBUG 01-04 15:36:24.875983.875983 cuda_h.py:19] end wait_cetm_experts cost 0.029848575592041016 seconds
DEBUG 01-04 15:36:24.875403.875403 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.875022.875022 cuda_h.py:19] end gpu_sexperts cost 0.00044918060302734375 seconds
DEBUG 01-04 15:36:24.875488.875488 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-04 15:36:24.875973.875973 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-04 15:36:24.875823.875823 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.2901763916015625e-05 seconds
DEBUG 01-04 15:36:24.875963.875963 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:24.875758.875758 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.875945.875945 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b76ee942-0add-4d66-aa2f-d0c2e46157d8
DEBUG 01-04 15:36:24.876805.876805 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.876810.876810 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.876555.876555 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.880749.880749 cuda_h.py:19] end allocate_cuda_memory cost 0.004523038864135742 seconds
DEBUG 01-04 15:36:24.881089.881089 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.881236.881236 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.881317.881317 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.881266.881266 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 96bccfac-16f7-4dd1-b678-9cd0cb8e6e81
DEBUG 01-04 15:36:24.881401.881401 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:24.891286.891286 mlpmodule.py:662]  experts func einsum cost 0.0458831787109375 s
INFO 01-04 15:36:24.891288.891288 client.py:127] Model loaded
DEBUG 01-04 15:36:24.891469.891469 cuda_h.py:19] end wait_experts cost 0.01583719253540039 seconds
DEBUG 01-04 15:36:24.891456.891456 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.891967.891967 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:24.892132.892132 mlpmodule.py:531] gpu group tensors cost 0.0005125999450683594 s
INFO 01-04 15:36:24.892499.892499 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 96bccfac-16f7-4dd1-b678-9cd0cb8e6e81
DEBUG 01-04 15:36:24.892911.892911 cuda_h.py:19] end load_into_gpu_async cost 0.011665582656860352 seconds
DEBUG 01-04 15:36:24.892614.892614 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.892141.892141 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-04 15:36:24.892135.892135 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01658320426940918 seconds
INFO 01-04 15:36:24.893179.893179 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 96bccfac-16f7-4dd1-b678-9cd0cb8e6e81
DEBUG 01-04 15:36:24.894682.894682 mlpmodule.py:564] gpu pad cost 0.002138853073120117 s
DEBUG 01-04 15:36:24.895436.895436 mlpmodule.py:582] gpu group einsum cost 0.0004673004150390625 s
DEBUG 01-04 15:36:24.897966.897966 mlpmodule.py:611] gpu experts func einsum cost 0.00604248046875 s
DEBUG 01-04 15:36:24.898291.898291 cuda_h.py:19] end gpu_experts cost 0.006313800811767578 seconds
DEBUG 01-04 15:36:24.898716.898716 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:24.903289.903289 client.py:127] Model loaded
DEBUG 01-04 15:36:24.903907.903907 cuda_h.py:19] end sllm_worker_task cost 0.027046918869018555 seconds
DEBUG 01-04 15:36:24.903612.903612 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005160331726074219 seconds
DEBUG 01-04 15:36:24.903530.903530 cuda_h.py:19] end layer_moe_generate_7 cost 0.06808638572692871 seconds
DEBUG 01-04 15:36:24.903391.903391 lmp.py:207] -------------------------------- end layer 7 --------------------------------
DEBUG 01-04 15:36:24.903253.903253 lmp.py:169] -------------------------------- start layer 8 --------------------------------
DEBUG 01-04 15:36:24.903234.903234 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.904455.904455 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.906218.906218 cuda_h.py:19] end self_attn cost 0.0023708343505859375 seconds
DEBUG 01-04 15:36:24.906758.906758 cuda_h.py:19] end iln_self_attn_paln cost 0.0029556751251220703 seconds
DEBUG 01-04 15:36:24.906163.906163 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-04 15:36:24.906304.906304 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.907973.907973 cuda_h.py:19] end gate cost 0.0005664825439453125 seconds
DEBUG 01-04 15:36:24.907418.907418 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.907433.907433 lmp.py:281] 
DEBUG 01-04 15:36:24.907433.907433 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.907851.907851 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:24.907117.907117 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:24.907998.907998 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:24.907495.907495 lmp.py:285] 
DEBUG 01-04 15:36:24.907495.907495 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.907993.907993 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.907020.907020 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:24.907471.907471 lmp.py:292]   Expert  9 |      1 | CPU
DEBUG 01-04 15:36:24.907922.907922 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:24.907134.907134 lmp.py:292]   Expert 13 |      1 | CPU
DEBUG 01-04 15:36:24.907154.907154 lmp.py:292]   Expert 26 |      1 | CPU
DEBUG 01-04 15:36:24.907175.907175 lmp.py:292]   Expert 30 |      1 | CPU
DEBUG 01-04 15:36:24.907957.907957 lmp.py:292]   Expert 36 |      1 | CPU
DEBUG 01-04 15:36:24.907977.907977 lmp.py:292]   Expert 38 |      1 | CPU
DEBUG 01-04 15:36:24.907759.907759 lmp.py:292]   Expert 29 |      2 | CPU
DEBUG 01-04 15:36:24.907779.907779 lmp.py:292]   Expert 33 |      2 | CPU
DEBUG 01-04 15:36:24.907561.907561 lmp.py:292]   Expert 37 |      2 | CPU
DEBUG 01-04 15:36:24.908343.908343 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:24.908602.908602 lmp.py:292]   Expert 57 |      2 | CPU
DEBUG 01-04 15:36:24.908338.908338 lmp.py:292]   Expert 31 |      3 | CPU
DEBUG 01-04 15:36:24.908358.908358 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:24.908902.908902 lmp.py:292]   Expert 60 |      3 | CPU
DEBUG 01-04 15:36:24.908922.908922 lmp.py:292]   Expert 10 |      4 | CPU
DEBUG 01-04 15:36:24.908466.908466 lmp.py:292]   Expert 15 |      4 | CPU
DEBUG 01-04 15:36:24.908486.908486 lmp.py:292]   Expert 17 |      4 | CPU
DEBUG 01-04 15:36:24.908268.908268 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:24.908050.908050 lmp.py:292]   Expert 23 |      4 | CPU
DEBUG 01-04 15:36:24.908832.908832 lmp.py:292]   Expert 40 |      4 | CPU
DEBUG 01-04 15:36:24.908044.908044 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:24.908780.908780 lmp.py:292]   Expert 54 |      4 | CPU
DEBUG 01-04 15:36:24.908562.908562 lmp.py:292]   Expert 56 |      4 | CPU
DEBUG 01-04 15:36:24.908344.908344 lmp.py:292]   Expert 59 |      4 | CPU
DEBUG 01-04 15:36:24.908126.908126 lmp.py:292]   Expert 14 |      5 | CPU
DEBUG 01-04 15:36:24.908908.908908 lmp.py:292]   Expert 32 |      5 | CPU
DEBUG 01-04 15:36:24.908690.908690 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:24.908472.908472 lmp.py:292]   Expert 43 |      5 | GPU
DEBUG 01-04 15:36:24.908254.908254 lmp.py:292]   Expert 16 |      6 | GPU
DEBUG 01-04 15:36:24.908035.908035 lmp.py:292]   Expert 18 |      6 | GPU
DEBUG 01-04 15:36:24.908533.908533 lmp.py:292]   Expert 19 |      6 | GPU
DEBUG 01-04 15:36:24.908030.908030 lmp.py:292]   Expert 46 |      6 | GPU
DEBUG 01-04 15:36:24.908242.908242 lmp.py:292]   Expert 51 |      7 | GPU
DEBUG 01-04 15:36:24.908263.908263 lmp.py:292]   Expert 48 |      8 | GPU
DEBUG 01-04 15:36:24.908643.908643 lmp.py:292]   Expert 62 |      8 | GPU
DEBUG 01-04 15:36:24.908093.908093 lmp.py:292]   Expert 25 |      9 | GPU
DEBUG 01-04 15:36:24.908591.908591 lmp.py:292]   Expert 49 |      9 | GPU
DEBUG 01-04 15:36:24.908326.908326 lmp.py:292]   Expert 58 |      9 | GPU
DEBUG 01-04 15:36:24.908115.908115 lmp.py:292]   Expert 61 |      9 | GPU
DEBUG 01-04 15:36:24.908566.908566 lmp.py:292]   Expert 28 |     10 | GPU
DEBUG 01-04 15:36:24.908540.908540 lmp.py:292]   Expert 47 |     10 | GPU
DEBUG 01-04 15:36:24.908560.908560 lmp.py:292]   Expert 52 |     10 | GPU
DEBUG 01-04 15:36:24.908057.908057 lmp.py:292]   Expert 50 |     11 | GPU
DEBUG 01-04 15:36:24.908793.908793 lmp.py:292]   Expert 55 |     11 | GPU
DEBUG 01-04 15:36:24.908052.908052 lmp.py:292]   Expert 39 |     13 | GPU
DEBUG 01-04 15:36:24.908311.908311 lmp.py:292]   Expert 41 |     14 | GPU
DEBUG 01-04 15:36:24.908569.908569 lmp.py:292]   Expert 63 |     14 | GPU
DEBUG 01-04 15:36:24.908067.908067 lmp.py:292]   Expert 42 |     15 | GPU
DEBUG 01-04 15:36:24.908756.908756 lmp.py:292]   Expert 21 |     16 | GPU
DEBUG 01-04 15:36:24.908730.908730 lmp.py:292]   Expert 11 |     19 | GPU
DEBUG 01-04 15:36:24.908227.908227 lmp.py:292]   Expert 20 |     19 | GPU
DEBUG 01-04 15:36:24.908963.908963 lmp.py:292]   Expert  1 |   1986 | GPU
DEBUG 01-04 15:36:24.908698.908698 lmp.py:292]   Expert  2 |   1986 | GPU
DEBUG 01-04 15:36:24.908196.908196 lmp.py:292]   Expert  4 |   1990 | GPU
DEBUG 01-04 15:36:24.908931.908931 lmp.py:292]   Expert  3 |   1994 | GPU
DEBUG 01-04 15:36:24.908429.908429 lmp.py:292]   Expert  0 |   1995 | GPU
DEBUG 01-04 15:36:24.908926.908926 lmp.py:292]   Expert  5 |   2005 | GPU
DEBUG 01-04 15:36:24.908138.908138 lmp.py:293] 
DEBUG 01-04 15:36:24.908138.908138 lmp.py:293]   CPU total tokens: 82 (0.7%)
DEBUG 01-04 15:36:24.908589.908589 lmp.py:294]   GPU total tokens: 12206 (99.3%)
DEBUG 01-04 15:36:24.908239.908239 cuda_h.py:19] end experts_map_get cost 0.0013473033905029297 seconds
DEBUG 01-04 15:36:24.908412.908412 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.908665.908665 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.909550.909550 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.909282.909282 cuda_h.py:19] end allocate_cuda_memory cost 0.00026297569274902344 seconds
DEBUG 01-04 15:36:24.909602.909602 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.909973.909973 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.909498.909498 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.909955.909955 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1def5ca5-f32d-4fc4-908c-0fe8046cad91
DEBUG 01-04 15:36:24.909763.909763 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.911986.911986 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1def5ca5-f32d-4fc4-908c-0fe8046cad91
DEBUG 01-04 15:36:24.911454.911454 cuda_h.py:19] end load_into_gpu_async cost 0.002268075942993164 seconds
DEBUG 01-04 15:36:24.911470.911470 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.912469.912469 cuda_h.py:19] end restore_tensors2 cost 0.0004971027374267578 seconds
DEBUG 01-04 15:36:24.912293.912293 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034956932067871094 seconds
DEBUG 01-04 15:36:24.914021.914021 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005901336669921875 seconds
DEBUG 01-04 15:36:24.914566.914566 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.914952.914952 lmp.py:339] 
DEBUG 01-04 15:36:24.914952.914952 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:24.914788.914788 cuda_h.py:19] end cpu_experts_submit cost 0.00010251998901367188 seconds
DEBUG 01-04 15:36:24.915935.915935 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.921130.921130 mlpmodule.py:704] group tensors cost 0.006078958511352539 s
DEBUG 01-04 15:36:24.924547.924547 mlpmodule.py:742] pad cost 0.002110004425048828 s
DEBUG 01-04 15:36:24.924399.924399 mlpmodule.py:748] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-04 15:36:24.924018.924018 mlpmodule.py:753] move to cpu cost 5.030632019042969e-05 s
DEBUG 01-04 15:36:24.928717.928717 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:24.928058.928058 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:24.928135.928135 mlpmodule.py:774] group_w3 first element: -0.0419921875
WARNING 01-04 15:36:24.928497.928497 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:24.932386.932386 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:24.932029.932029 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:24.935949.935949 mlpmodule.py:797] group einsum cost 0.0111083984375 s
DEBUG 01-04 15:36:24.935625.935625 mlpmodule.py:805] cpy2cputensor cost 7.534027099609375e-05 s
DEBUG 01-04 15:36:24.939513.939513 cuda_h.py:19] end wait_cetm_experts cost 0.02471327781677246 seconds
DEBUG 01-04 15:36:24.939364.939364 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:24.940552.940552 cuda_h.py:19] end gpu_sexperts cost 0.0004458427429199219 seconds
DEBUG 01-04 15:36:24.940953.940953 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-04 15:36:24.940391.940391 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-04 15:36:24.940195.940195 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.266334533691406e-05 seconds
DEBUG 01-04 15:36:24.940050.940050 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.05718994140625e-05 seconds
DEBUG 01-04 15:36:24.940607.940607 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:24.940794.940794 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1def5ca5-f32d-4fc4-908c-0fe8046cad91
DEBUG 01-04 15:36:24.940117.940117 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:24.940855.940855 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.940652.940652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.946923.946923 cuda_h.py:19] end allocate_cuda_memory cost 0.0050580501556396484 seconds
DEBUG 01-04 15:36:24.946767.946767 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.946675.946675 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.946551.946551 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.946877.946877 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e5264bf4-6daf-44be-9294-a6409db44629
DEBUG 01-04 15:36:24.946820.946820 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:24.956626.956626 mlpmodule.py:662]  experts func einsum cost 0.041253089904785156 s
INFO 01-04 15:36:24.961753.961753 client.py:127] Model loaded
DEBUG 01-04 15:36:24.961110.961110 cuda_h.py:19] end wait_experts cost 0.02128458023071289 seconds
DEBUG 01-04 15:36:24.962179.962179 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:24.962910.962910 lmp.py:384]   Computing 30 experts on GPU...
INFO 01-04 15:36:24.963996.963996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e5264bf4-6daf-44be-9294-a6409db44629
DEBUG 01-04 15:36:24.963683.963683 cuda_h.py:19] end load_into_gpu_async cost 0.017229080200195312 seconds
DEBUG 01-04 15:36:24.963415.963415 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.963151.963151 cuda_h.py:19] end restore_tensors2 cost 0.0001494884490966797 seconds
DEBUG 01-04 15:36:24.963895.963895 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.022912025451660156 seconds
INFO 01-04 15:36:24.965495.965495 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e5264bf4-6daf-44be-9294-a6409db44629
DEBUG 01-04 15:36:24.965748.965748 mlpmodule.py:531] gpu group tensors cost 0.0031244754791259766 s
DEBUG 01-04 15:36:24.969800.969800 mlpmodule.py:564] gpu pad cost 0.003964424133300781 s
DEBUG 01-04 15:36:24.970861.970861 mlpmodule.py:582] gpu group einsum cost 0.0008513927459716797 s
INFO 01-04 15:36:24.970472.970472 client.py:127] Model loaded
DEBUG 01-04 15:36:24.970993.970993 cuda_h.py:19] end sllm_worker_task cost 0.03000473976135254 seconds
DEBUG 01-04 15:36:24.975058.975058 mlpmodule.py:611] gpu experts func einsum cost 0.013581275939941406 s
DEBUG 01-04 15:36:24.976300.976300 cuda_h.py:19] end gpu_experts cost 0.014025211334228516 seconds
DEBUG 01-04 15:36:24.976143.976143 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:24.976298.976298 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-04 15:36:24.977703.977703 cuda_h.py:19] end layer_moe_generate_8 cost 0.07086586952209473 seconds
DEBUG 01-04 15:36:24.977229.977229 lmp.py:207] -------------------------------- end layer 8 --------------------------------
DEBUG 01-04 15:36:24.978311.978311 lmp.py:169] -------------------------------- start layer 9 --------------------------------
DEBUG 01-04 15:36:24.978934.978934 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:24.978426.978426 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:24.981231.981231 cuda_h.py:19] end self_attn cost 0.003006458282470703 seconds
DEBUG 01-04 15:36:24.981559.981559 cuda_h.py:19] end iln_self_attn_paln cost 0.0037882328033447266 seconds
DEBUG 01-04 15:36:24.981588.981588 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-04 15:36:24.982112.982112 cuda_h.py:10] start gate
DEBUG 01-04 15:36:24.982311.982311 cuda_h.py:19] end gate cost 0.0005702972412109375 seconds
DEBUG 01-04 15:36:24.982902.982902 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:24.982308.982308 lmp.py:281] 
DEBUG 01-04 15:36:24.982308.982308 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:24.982124.982124 lmp.py:282]   Total experts: 57
DEBUG 01-04 15:36:24.982582.982582 lmp.py:283]   CPU experts: 28 (49%)
DEBUG 01-04 15:36:24.982702.982702 lmp.py:284]   GPU experts: 29 (51%)
DEBUG 01-04 15:36:24.983153.983153 lmp.py:285] 
DEBUG 01-04 15:36:24.983153.983153 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:24.983365.983365 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:24.983631.983631 lmp.py:292]   Expert 10 |      1 | CPU
DEBUG 01-04 15:36:24.983605.983605 lmp.py:292]   Expert 17 |      1 | CPU
DEBUG 01-04 15:36:24.983863.983863 lmp.py:292]   Expert 26 |      1 | CPU
DEBUG 01-04 15:36:24.983361.983361 lmp.py:292]   Expert 28 |      1 | CPU
DEBUG 01-04 15:36:24.983143.983143 lmp.py:292]   Expert 38 |      1 | CPU
DEBUG 01-04 15:36:24.983163.983163 lmp.py:292]   Expert 42 |      1 | CPU
DEBUG 01-04 15:36:24.983422.983422 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:24.983442.983442 lmp.py:292]   Expert 49 |      1 | CPU
DEBUG 01-04 15:36:24.983224.983224 lmp.py:292]   Expert 11 |      2 | CPU
DEBUG 01-04 15:36:24.983483.983483 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:24.983934.983934 lmp.py:292]   Expert 22 |      2 | CPU
DEBUG 01-04 15:36:24.983669.983669 lmp.py:292]   Expert 24 |      2 | CPU
DEBUG 01-04 15:36:24.983690.983690 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:24.983472.983472 lmp.py:292]   Expert 36 |      2 | CPU
DEBUG 01-04 15:36:24.983492.983492 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:24.983274.983274 lmp.py:292]   Expert 14 |      3 | CPU
DEBUG 01-04 15:36:24.983294.983294 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:24.983076.983076 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:24.983097.983097 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:24.983356.983356 lmp.py:292]   Expert 60 |      3 | CPU
DEBUG 01-04 15:36:24.983137.983137 lmp.py:292]   Expert 18 |      4 | CPU
DEBUG 01-04 15:36:24.983635.983635 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:24.983046.983046 lmp.py:292]   Expert 35 |      4 | CPU
DEBUG 01-04 15:36:24.983543.983543 lmp.py:292]   Expert 40 |      4 | CPU
DEBUG 01-04 15:36:24.983325.983325 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:24.983107.983107 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:24.983651.983651 lmp.py:292]   Expert 59 |      4 | CPU
DEBUG 01-04 15:36:24.983194.983194 lmp.py:292]   Expert 62 |      4 | CPU
DEBUG 01-04 15:36:24.983976.983976 lmp.py:292]   Expert 16 |      5 | GPU
DEBUG 01-04 15:36:24.983758.983758 lmp.py:292]   Expert 25 |      5 | GPU
DEBUG 01-04 15:36:24.983302.983302 lmp.py:292]   Expert 32 |      5 | GPU
DEBUG 01-04 15:36:24.983084.983084 lmp.py:292]   Expert 44 |      5 | GPU
DEBUG 01-04 15:36:24.983104.983104 lmp.py:292]   Expert 23 |      6 | GPU
DEBUG 01-04 15:36:24.983363.983363 lmp.py:292]   Expert 61 |      6 | GPU
DEBUG 01-04 15:36:24.983098.983098 lmp.py:292]   Expert  8 |      7 | GPU
DEBUG 01-04 15:36:24.983119.983119 lmp.py:292]   Expert 20 |      7 | GPU
DEBUG 01-04 15:36:24.983901.983901 lmp.py:292]   Expert 51 |      7 | GPU
DEBUG 01-04 15:36:24.983683.983683 lmp.py:292]   Expert 33 |      8 | GPU
DEBUG 01-04 15:36:24.983226.983226 lmp.py:292]   Expert 39 |      9 | GPU
DEBUG 01-04 15:36:24.983247.983247 lmp.py:292]   Expert 50 |     10 | GPU
DEBUG 01-04 15:36:24.983790.983790 lmp.py:292]   Expert 37 |     11 | GPU
DEBUG 01-04 15:36:24.983572.983572 lmp.py:292]   Expert 43 |     11 | GPU
DEBUG 01-04 15:36:24.983354.983354 lmp.py:292]   Expert 12 |     13 | GPU
DEBUG 01-04 15:36:24.983136.983136 lmp.py:292]   Expert  9 |     15 | GPU
DEBUG 01-04 15:36:24.983918.983918 lmp.py:292]   Expert 15 |     17 | GPU
DEBUG 01-04 15:36:24.983700.983700 lmp.py:292]   Expert 21 |     17 | GPU
DEBUG 01-04 15:36:24.983243.983243 lmp.py:292]   Expert 47 |     20 | GPU
DEBUG 01-04 15:36:24.983264.983264 lmp.py:292]   Expert 63 |     23 | GPU
DEBUG 01-04 15:36:24.983046.983046 lmp.py:292]   Expert 46 |     25 | GPU
DEBUG 01-04 15:36:24.983066.983066 lmp.py:292]   Expert 55 |     29 | GPU
DEBUG 01-04 15:36:24.983040.983040 lmp.py:292]   Expert 56 |     30 | GPU
DEBUG 01-04 15:36:24.983014.983014 lmp.py:292]   Expert  5 |   1984 | GPU
DEBUG 01-04 15:36:24.983035.983035 lmp.py:292]   Expert  2 |   1985 | GPU
DEBUG 01-04 15:36:24.983055.983055 lmp.py:292]   Expert  4 |   1987 | GPU
DEBUG 01-04 15:36:24.983837.983837 lmp.py:292]   Expert  1 |   1989 | GPU
DEBUG 01-04 15:36:24.983857.983857 lmp.py:292]   Expert  3 |   1989 | GPU
DEBUG 01-04 15:36:24.983878.983878 lmp.py:292]   Expert  0 |   1994 | GPU
DEBUG 01-04 15:36:24.983852.983852 lmp.py:293] 
DEBUG 01-04 15:36:24.983852.983852 lmp.py:293]   CPU total tokens: 69 (0.6%)
DEBUG 01-04 15:36:24.983587.983587 lmp.py:294]   GPU total tokens: 12219 (99.4%)
DEBUG 01-04 15:36:24.983614.983614 cuda_h.py:19] end experts_map_get cost 0.0012700557708740234 seconds
DEBUG 01-04 15:36:24.983827.983827 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:24.984742.984742 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:24.984190.984190 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:24.984121.984121 cuda_h.py:19] end allocate_cuda_memory cost 0.0002522468566894531 seconds
DEBUG 01-04 15:36:24.984633.984633 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:24.984196.984196 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:24.984582.984582 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:24.984232.984232 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 92d04705-fe22-4bdd-9df4-882662df573d
DEBUG 01-04 15:36:24.984900.984900 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:24.986575.986575 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 92d04705-fe22-4bdd-9df4-882662df573d
DEBUG 01-04 15:36:24.986182.986182 cuda_h.py:19] end load_into_gpu_async cost 0.0023255348205566406 seconds
DEBUG 01-04 15:36:24.986046.986046 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:24.987616.987616 cuda_h.py:19] end restore_tensors2 cost 0.0005671977996826172 seconds
DEBUG 01-04 15:36:24.987353.987353 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003589630126953125 seconds
DEBUG 01-04 15:36:24.989312.989312 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005949735641479492 seconds
DEBUG 01-04 15:36:24.989856.989856 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:24.990766.990766 lmp.py:339] 
DEBUG 01-04 15:36:24.990766.990766 lmp.py:339]   Computing 28 experts on CPU...
DEBUG 01-04 15:36:24.990887.990887 cuda_h.py:19] end cpu_experts_submit cost 0.0001010894775390625 seconds
DEBUG 01-04 15:36:24.990511.990511 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:24.999408.999408 mlpmodule.py:704] group tensors cost 0.009023904800415039 s
DEBUG 01-04 15:36:25.001150.001150 mlpmodule.py:742] pad cost 0.0014095306396484375 s
DEBUG 01-04 15:36:25.001279.001279 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-04 15:36:25.001506.001506 mlpmodule.py:753] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-04 15:36:25.006665.006665 mlpmodule.py:768] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-04 15:36:25.006185.006185 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.006532.006532 mlpmodule.py:774] group_w3 first element: 0.042724609375
WARNING 01-04 15:36:25.006682.006682 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.009370.009370 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.009299.009299 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.013611.013611 mlpmodule.py:797] group einsum cost 0.011954307556152344 s
DEBUG 01-04 15:36:25.014796.014796 mlpmodule.py:805] cpy2cputensor cost 7.343292236328125e-05 s
DEBUG 01-04 15:36:25.017240.017240 cuda_h.py:19] end wait_cetm_experts cost 0.027634620666503906 seconds
DEBUG 01-04 15:36:25.017807.017807 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.018479.018479 cuda_h.py:19] end gpu_sexperts cost 0.0004534721374511719 seconds
DEBUG 01-04 15:36:25.018037.018037 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-04 15:36:25.018476.018476 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-04 15:36:25.018326.018326 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.266334533691406e-05 seconds
DEBUG 01-04 15:36:25.018704.018704 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:25.018261.018261 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.018448.018448 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 92d04705-fe22-4bdd-9df4-882662df573d
DEBUG 01-04 15:36:25.018553.018553 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.019803.019803 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.019078.019078 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.024321.024321 cuda_h.py:19] end allocate_cuda_memory cost 0.004823923110961914 seconds
DEBUG 01-04 15:36:25.024714.024714 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.024861.024861 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.024406.024406 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.024639.024639 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff5890ce-3201-44c8-81fa-08432cd7eb01
DEBUG 01-04 15:36:25.024729.024729 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.034602.034602 mlpmodule.py:662]  experts func einsum cost 0.04409646987915039 s
INFO 01-04 15:36:25.035428.035428 client.py:127] Model loaded
DEBUG 01-04 15:36:25.035394.035394 cuda_h.py:19] end wait_experts cost 0.016763687133789062 seconds
DEBUG 01-04 15:36:25.035549.035549 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.035253.035253 lmp.py:384]   Computing 29 experts on GPU...
INFO 01-04 15:36:25.036409.036409 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff5890ce-3201-44c8-81fa-08432cd7eb01
DEBUG 01-04 15:36:25.036590.036590 cuda_h.py:19] end load_into_gpu_async cost 0.012053966522216797 seconds
DEBUG 01-04 15:36:25.036677.036677 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.036667.036667 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-04 15:36:25.036661.036661 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.017254114151000977 seconds
DEBUG 01-04 15:36:25.036969.036969 mlpmodule.py:531] gpu group tensors cost 0.0009527206420898438 s
INFO 01-04 15:36:25.036026.036026 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff5890ce-3201-44c8-81fa-08432cd7eb01
DEBUG 01-04 15:36:25.038634.038634 mlpmodule.py:564] gpu pad cost 0.0015218257904052734 s
DEBUG 01-04 15:36:25.038560.038560 mlpmodule.py:582] gpu group einsum cost 0.00048065185546875 s
DEBUG 01-04 15:36:25.041713.041713 mlpmodule.py:611] gpu experts func einsum cost 0.0059626102447509766 s
DEBUG 01-04 15:36:25.041621.041621 cuda_h.py:19] end gpu_experts cost 0.006240367889404297 seconds
DEBUG 01-04 15:36:25.041761.041761 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.046694.046694 client.py:127] Model loaded
DEBUG 01-04 15:36:25.046227.046227 cuda_h.py:19] end sllm_worker_task cost 0.027877092361450195 seconds
DEBUG 01-04 15:36:25.046692.046692 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0050470829010009766 seconds
DEBUG 01-04 15:36:25.047658.047658 cuda_h.py:19] end layer_moe_generate_9 cost 0.06515336036682129 seconds
DEBUG 01-04 15:36:25.047134.047134 lmp.py:207] -------------------------------- end layer 9 --------------------------------
DEBUG 01-04 15:36:25.047274.047274 lmp.py:169] -------------------------------- start layer 10 --------------------------------
DEBUG 01-04 15:36:25.047824.047824 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.047953.047953 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.050209.050209 cuda_h.py:19] end self_attn cost 0.0024542808532714844 seconds
DEBUG 01-04 15:36:25.050463.050463 cuda_h.py:19] end iln_self_attn_paln cost 0.0030410289764404297 seconds
DEBUG 01-04 15:36:25.050061.050061 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-04 15:36:25.050632.050632 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.051036.051036 cuda_h.py:19] end gate cost 0.0005464553833007812 seconds
DEBUG 01-04 15:36:25.051481.051481 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.051508.051508 lmp.py:281] 
DEBUG 01-04 15:36:25.051508.051508 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.051072.051072 lmp.py:282]   Total experts: 51
DEBUG 01-04 15:36:25.051789.051789 lmp.py:283]   CPU experts: 25 (49%)
DEBUG 01-04 15:36:25.051385.051385 lmp.py:284]   GPU experts: 26 (51%)
DEBUG 01-04 15:36:25.051598.051598 lmp.py:285] 
DEBUG 01-04 15:36:25.051598.051598 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.051526.051526 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.051652.051652 lmp.py:292]   Expert 46 |      1 | CPU
DEBUG 01-04 15:36:25.051772.051772 lmp.py:292]   Expert 59 |      1 | CPU
DEBUG 01-04 15:36:25.051415.051415 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:25.051104.051104 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:25.051555.051555 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:25.051291.051291 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:25.051265.051265 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:25.051000.051000 lmp.py:292]   Expert  9 |      3 | CPU
DEBUG 01-04 15:36:25.051975.051975 lmp.py:292]   Expert 19 |      3 | CPU
DEBUG 01-04 15:36:25.051710.051710 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:25.051446.051446 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:25.051943.051943 lmp.py:292]   Expert 45 |      3 | CPU
DEBUG 01-04 15:36:25.051540.051540 lmp.py:292]   Expert 50 |      3 | CPU
DEBUG 01-04 15:36:25.051467.051467 lmp.py:292]   Expert 16 |      4 | CPU
DEBUG 01-04 15:36:25.051680.051680 lmp.py:292]   Expert 17 |      4 | CPU
DEBUG 01-04 15:36:25.051415.051415 lmp.py:292]   Expert 20 |      4 | CPU
DEBUG 01-04 15:36:25.051866.051866 lmp.py:292]   Expert 25 |      4 | CPU
DEBUG 01-04 15:36:25.051602.051602 lmp.py:292]   Expert 26 |      4 | CPU
DEBUG 01-04 15:36:25.051099.051099 lmp.py:292]   Expert 63 |      4 | CPU
DEBUG 01-04 15:36:25.051596.051596 lmp.py:292]   Expert 30 |      5 | CPU
DEBUG 01-04 15:36:25.051855.051855 lmp.py:292]   Expert 31 |      5 | CPU
DEBUG 01-04 15:36:25.051352.051352 lmp.py:292]   Expert 43 |      5 | CPU
DEBUG 01-04 15:36:25.051850.051850 lmp.py:292]   Expert 52 |      5 | CPU
DEBUG 01-04 15:36:25.051824.051824 lmp.py:292]   Expert 56 |      5 | CPU
DEBUG 01-04 15:36:25.051082.051082 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:25.051056.051056 lmp.py:292]   Expert 35 |      6 | GPU
DEBUG 01-04 15:36:25.051554.051554 lmp.py:292]   Expert 36 |      6 | GPU
DEBUG 01-04 15:36:25.051243.051243 lmp.py:292]   Expert 37 |      6 | GPU
DEBUG 01-04 15:36:25.051932.051932 lmp.py:292]   Expert 42 |      6 | GPU
DEBUG 01-04 15:36:25.052383.052383 lmp.py:292]   Expert 18 |      7 | GPU
DEBUG 01-04 15:36:25.052072.052072 lmp.py:292]   Expert 21 |      7 | GPU
DEBUG 01-04 15:36:25.052046.052046 lmp.py:292]   Expert 29 |      7 | GPU
DEBUG 01-04 15:36:25.052021.052021 lmp.py:292]   Expert 10 |      8 | GPU
DEBUG 01-04 15:36:25.052279.052279 lmp.py:292]   Expert 22 |      8 | GPU
DEBUG 01-04 15:36:25.052253.052253 lmp.py:292]   Expert  8 |      9 | GPU
DEBUG 01-04 15:36:25.052512.052512 lmp.py:292]   Expert 33 |      9 | GPU
DEBUG 01-04 15:36:25.052248.052248 lmp.py:292]   Expert 39 |      9 | GPU
DEBUG 01-04 15:36:25.052699.052699 lmp.py:292]   Expert 40 |     10 | GPU
DEBUG 01-04 15:36:25.052388.052388 lmp.py:292]   Expert 41 |     10 | GPU
DEBUG 01-04 15:36:25.052839.052839 lmp.py:292]   Expert 57 |     13 | GPU
DEBUG 01-04 15:36:25.052290.052290 lmp.py:292]   Expert 53 |     15 | GPU
DEBUG 01-04 15:36:25.052787.052787 lmp.py:292]   Expert 23 |     16 | GPU
DEBUG 01-04 15:36:25.052284.052284 lmp.py:292]   Expert 58 |     17 | GPU
DEBUG 01-04 15:36:25.052543.052543 lmp.py:292]   Expert 49 |     23 | GPU
DEBUG 01-04 15:36:25.052802.052802 lmp.py:292]   Expert 11 |     37 | GPU
DEBUG 01-04 15:36:25.052299.052299 lmp.py:292]   Expert  3 |   1984 | GPU
DEBUG 01-04 15:36:25.052319.052319 lmp.py:292]   Expert  5 |   1984 | GPU
DEBUG 01-04 15:36:25.052817.052817 lmp.py:292]   Expert  2 |   1988 | GPU
DEBUG 01-04 15:36:25.052314.052314 lmp.py:292]   Expert  0 |   1999 | GPU
DEBUG 01-04 15:36:25.052572.052572 lmp.py:292]   Expert  1 |   2008 | GPU
DEBUG 01-04 15:36:25.052547.052547 lmp.py:292]   Expert  4 |   2012 | GPU
DEBUG 01-04 15:36:25.052190.052190 lmp.py:293] 
DEBUG 01-04 15:36:25.052190.052190 lmp.py:293]   CPU total tokens: 84 (0.7%)
DEBUG 01-04 15:36:25.052071.052071 lmp.py:294]   GPU total tokens: 12204 (99.3%)
DEBUG 01-04 15:36:25.052150.052150 cuda_h.py:19] end experts_map_get cost 0.0013778209686279297 seconds
DEBUG 01-04 15:36:25.052323.052323 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.052146.052146 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.052964.052964 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.053458.053458 cuda_h.py:19] end allocate_cuda_memory cost 0.00026345252990722656 seconds
DEBUG 01-04 15:36:25.053731.053731 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.053295.053295 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.053727.053727 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.053900.053900 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 724d9cc6-ec34-4e81-a2d3-1a62838fb5cb
DEBUG 01-04 15:36:25.053601.053601 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.055046.055046 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 724d9cc6-ec34-4e81-a2d3-1a62838fb5cb
DEBUG 01-04 15:36:25.055984.055984 cuda_h.py:19] end load_into_gpu_async cost 0.002177715301513672 seconds
DEBUG 01-04 15:36:25.055179.055179 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.055308.055308 cuda_h.py:19] end restore_tensors2 cost 0.00041866302490234375 seconds
DEBUG 01-04 15:36:25.055137.055137 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032715797424316406 seconds
DEBUG 01-04 15:36:25.058925.058925 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005472898483276367 seconds
DEBUG 01-04 15:36:25.058231.058231 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.058664.058664 lmp.py:339] 
DEBUG 01-04 15:36:25.058664.058664 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:25.058785.058785 cuda_h.py:19] end cpu_experts_submit cost 0.00010085105895996094 seconds
DEBUG 01-04 15:36:25.058409.058409 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.064172.064172 mlpmodule.py:704] group tensors cost 0.006427288055419922 s
DEBUG 01-04 15:36:25.067917.067917 mlpmodule.py:742] pad cost 0.0020093917846679688 s
DEBUG 01-04 15:36:25.067120.067120 mlpmodule.py:748] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-04 15:36:25.067117.067117 mlpmodule.py:753] move to cpu cost 4.267692565917969e-05 s
DEBUG 01-04 15:36:25.071841.071841 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:25.071241.071241 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.071336.071336 mlpmodule.py:774] group_w3 first element: -0.0257568359375
WARNING 01-04 15:36:25.071843.071843 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.074265.074265 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.075663.075663 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.078871.078871 mlpmodule.py:797] group einsum cost 0.01017308235168457 s
DEBUG 01-04 15:36:25.078672.078672 mlpmodule.py:805] cpy2cputensor cost 8.606910705566406e-05 s
DEBUG 01-04 15:36:25.081505.081505 cuda_h.py:19] end wait_cetm_experts cost 0.023585796356201172 seconds
DEBUG 01-04 15:36:25.082495.082495 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.082061.082061 cuda_h.py:19] end gpu_sexperts cost 0.0004439353942871094 seconds
DEBUG 01-04 15:36:25.082142.082142 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-04 15:36:25.082819.082819 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-04 15:36:25.082099.082099 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.314018249511719e-05 seconds
DEBUG 01-04 15:36:25.082147.082147 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.104873657226562e-05 seconds
DEBUG 01-04 15:36:25.082943.082943 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.082606.082606 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 724d9cc6-ec34-4e81-a2d3-1a62838fb5cb
DEBUG 01-04 15:36:25.082307.082307 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.083376.083376 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.083126.083126 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.087721.087721 cuda_h.py:19] end allocate_cuda_memory cost 0.00408482551574707 seconds
DEBUG 01-04 15:36:25.087731.087731 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.087116.087116 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.087707.087707 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.087701.087701 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a885b3b3-8d79-4187-ba34-d5b248b6997d
DEBUG 01-04 15:36:25.087645.087645 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.096971.096971 mlpmodule.py:662]  experts func einsum cost 0.038216352462768555 s
INFO 01-04 15:36:25.098716.098716 client.py:127] Model loaded
DEBUG 01-04 15:36:25.098029.098029 cuda_h.py:19] end wait_experts cost 0.016010046005249023 seconds
DEBUG 01-04 15:36:25.098825.098825 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.098382.098382 lmp.py:384]   Computing 26 experts on GPU...
INFO 01-04 15:36:25.099594.099594 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a885b3b3-8d79-4187-ba34-d5b248b6997d
DEBUG 01-04 15:36:25.099537.099537 cuda_h.py:19] end load_into_gpu_async cost 0.011968851089477539 seconds
DEBUG 01-04 15:36:25.099478.099478 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.099084.099084 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:25.099409.099409 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0163877010345459 seconds
DEBUG 01-04 15:36:25.099272.099272 mlpmodule.py:531] gpu group tensors cost 0.0008032321929931641 s
INFO 01-04 15:36:25.100323.100323 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a885b3b3-8d79-4187-ba34-d5b248b6997d
DEBUG 01-04 15:36:25.101118.101118 mlpmodule.py:564] gpu pad cost 0.0014758110046386719 s
DEBUG 01-04 15:36:25.101192.101192 mlpmodule.py:582] gpu group einsum cost 0.0005474090576171875 s
DEBUG 01-04 15:36:25.104421.104421 mlpmodule.py:611] gpu experts func einsum cost 0.005863666534423828 s
DEBUG 01-04 15:36:25.104309.104309 cuda_h.py:19] end gpu_experts cost 0.006124258041381836 seconds
DEBUG 01-04 15:36:25.105933.105933 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.109083.109083 client.py:127] Model loaded
DEBUG 01-04 15:36:25.109972.109972 cuda_h.py:19] end sllm_worker_task cost 0.026707172393798828 seconds
DEBUG 01-04 15:36:25.109385.109385 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0047571659088134766 seconds
DEBUG 01-04 15:36:25.109947.109947 cuda_h.py:19] end layer_moe_generate_10 cost 0.0594325065612793 seconds
DEBUG 01-04 15:36:25.110244.110244 lmp.py:207] -------------------------------- end layer 10 --------------------------------
DEBUG 01-04 15:36:25.110153.110153 lmp.py:169] -------------------------------- start layer 11 --------------------------------
DEBUG 01-04 15:36:25.110233.110233 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.110939.110939 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.113418.113418 cuda_h.py:19] end self_attn cost 0.002576589584350586 seconds
DEBUG 01-04 15:36:25.113130.113130 cuda_h.py:19] end iln_self_attn_paln cost 0.0032279491424560547 seconds
DEBUG 01-04 15:36:25.113874.113874 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-04 15:36:25.113637.113637 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.114849.114849 cuda_h.py:19] end gate cost 0.000579833984375 seconds
DEBUG 01-04 15:36:25.114725.114725 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.114548.114548 lmp.py:281] 
DEBUG 01-04 15:36:25.114548.114548 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.114681.114681 lmp.py:282]   Total experts: 57
DEBUG 01-04 15:36:25.114139.114139 lmp.py:283]   CPU experts: 28 (49%)
DEBUG 01-04 15:36:25.114974.114974 lmp.py:284]   GPU experts: 29 (51%)
DEBUG 01-04 15:36:25.114187.114187 lmp.py:285] 
DEBUG 01-04 15:36:25.114187.114187 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.114638.114638 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.114095.114095 lmp.py:292]   Expert 38 |      1 | CPU
DEBUG 01-04 15:36:25.114785.114785 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:25.114282.114282 lmp.py:292]   Expert 56 |      1 | CPU
DEBUG 01-04 15:36:25.114779.114779 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:25.114038.114038 lmp.py:292]   Expert 61 |      1 | CPU
DEBUG 01-04 15:36:25.114535.114535 lmp.py:292]   Expert  7 |      2 | CPU
DEBUG 01-04 15:36:25.114986.114986 lmp.py:292]   Expert 10 |      2 | CPU
DEBUG 01-04 15:36:25.114437.114437 lmp.py:292]   Expert 20 |      2 | CPU
DEBUG 01-04 15:36:25.114934.114934 lmp.py:292]   Expert 12 |      3 | CPU
DEBUG 01-04 15:36:25.114193.114193 lmp.py:292]   Expert 17 |      3 | CPU
DEBUG 01-04 15:36:25.114405.114405 lmp.py:292]   Expert 19 |      3 | CPU
DEBUG 01-04 15:36:25.114664.114664 lmp.py:292]   Expert 25 |      3 | CPU
DEBUG 01-04 15:36:25.114446.114446 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:25.114705.114705 lmp.py:292]   Expert 36 |      3 | CPU
DEBUG 01-04 15:36:25.114725.114725 lmp.py:292]   Expert 41 |      3 | CPU
DEBUG 01-04 15:36:25.114745.114745 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:25.114004.114004 lmp.py:292]   Expert 49 |      3 | CPU
DEBUG 01-04 15:36:25.114263.114263 lmp.py:292]   Expert 50 |      3 | CPU
DEBUG 01-04 15:36:25.114045.114045 lmp.py:292]   Expert 59 |      3 | CPU
DEBUG 01-04 15:36:25.114542.114542 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:25.114563.114563 lmp.py:292]   Expert 15 |      4 | CPU
DEBUG 01-04 15:36:25.114821.114821 lmp.py:292]   Expert 18 |      4 | CPU
DEBUG 01-04 15:36:25.114319.114319 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:25.114531.114531 lmp.py:292]   Expert 32 |      4 | CPU
DEBUG 01-04 15:36:25.114743.114743 lmp.py:292]   Expert 47 |      4 | CPU
DEBUG 01-04 15:36:25.114956.114956 lmp.py:292]   Expert 51 |      4 | CPU
DEBUG 01-04 15:36:25.115976.115976 lmp.py:292]   Expert 52 |      4 | CPU
DEBUG 01-04 15:36:25.115997.115997 lmp.py:292]   Expert  8 |      5 | CPU
DEBUG 01-04 15:36:25.115017.115017 lmp.py:292]   Expert 13 |      5 | GPU
DEBUG 01-04 15:36:25.115037.115037 lmp.py:292]   Expert 40 |      5 | GPU
DEBUG 01-04 15:36:25.115296.115296 lmp.py:292]   Expert 46 |      5 | GPU
DEBUG 01-04 15:36:25.115078.115078 lmp.py:292]   Expert 53 |      5 | GPU
DEBUG 01-04 15:36:25.115099.115099 lmp.py:292]   Expert 33 |      6 | GPU
DEBUG 01-04 15:36:25.115311.115311 lmp.py:292]   Expert 44 |      6 | GPU
DEBUG 01-04 15:36:25.115762.115762 lmp.py:292]   Expert 45 |      6 | GPU
DEBUG 01-04 15:36:25.115497.115497 lmp.py:292]   Expert 24 |      7 | GPU
DEBUG 01-04 15:36:25.115710.115710 lmp.py:292]   Expert 62 |      7 | GPU
DEBUG 01-04 15:36:25.115684.115684 lmp.py:292]   Expert 55 |      8 | GPU
DEBUG 01-04 15:36:25.115704.115704 lmp.py:292]   Expert 28 |      9 | GPU
DEBUG 01-04 15:36:25.115725.115725 lmp.py:292]   Expert 37 |     11 | GPU
DEBUG 01-04 15:36:25.115984.115984 lmp.py:292]   Expert 11 |     12 | GPU
DEBUG 01-04 15:36:25.115765.115765 lmp.py:292]   Expert 14 |     12 | GPU
DEBUG 01-04 15:36:25.115786.115786 lmp.py:292]   Expert 21 |     14 | GPU
DEBUG 01-04 15:36:25.115329.115329 lmp.py:292]   Expert 22 |     15 | GPU
DEBUG 01-04 15:36:25.115350.115350 lmp.py:292]   Expert 29 |     15 | GPU
DEBUG 01-04 15:36:25.115132.115132 lmp.py:292]   Expert 43 |     15 | GPU
DEBUG 01-04 15:36:25.115914.115914 lmp.py:292]   Expert 54 |     16 | GPU
DEBUG 01-04 15:36:25.115888.115888 lmp.py:292]   Expert 34 |     17 | GPU
DEBUG 01-04 15:36:25.115385.115385 lmp.py:292]   Expert 58 |     19 | GPU
DEBUG 01-04 15:36:25.115359.115359 lmp.py:292]   Expert  9 |     22 | GPU
DEBUG 01-04 15:36:25.115095.115095 lmp.py:292]   Expert 30 |     42 | GPU
DEBUG 01-04 15:36:25.115069.115069 lmp.py:292]   Expert  3 |   1985 | GPU
DEBUG 01-04 15:36:25.115804.115804 lmp.py:292]   Expert  0 |   1986 | GPU
DEBUG 01-04 15:36:25.115825.115825 lmp.py:292]   Expert  5 |   1987 | GPU
DEBUG 01-04 15:36:25.115607.115607 lmp.py:292]   Expert  2 |   1988 | GPU
DEBUG 01-04 15:36:25.115389.115389 lmp.py:292]   Expert  4 |   1989 | GPU
DEBUG 01-04 15:36:25.115409.115409 lmp.py:292]   Expert  1 |   1993 | GPU
DEBUG 01-04 15:36:25.115906.115906 lmp.py:293] 
DEBUG 01-04 15:36:25.115906.115906 lmp.py:293]   CPU total tokens: 81 (0.7%)
DEBUG 01-04 15:36:25.115880.115880 lmp.py:294]   GPU total tokens: 12207 (99.3%)
DEBUG 01-04 15:36:25.115430.115430 cuda_h.py:19] end experts_map_get cost 0.0012650489807128906 seconds
DEBUG 01-04 15:36:25.115266.115266 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.115996.115996 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.115496.115496 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.116844.116844 cuda_h.py:19] end allocate_cuda_memory cost 0.0002613067626953125 seconds
DEBUG 01-04 15:36:25.116449.116449 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.116297.116297 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.116444.116444 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.116617.116617 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, da84b630-5afe-4899-9ead-4a19bb944bcb
DEBUG 01-04 15:36:25.116994.116994 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.117461.117461 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, da84b630-5afe-4899-9ead-4a19bb944bcb
DEBUG 01-04 15:36:25.117390.117390 cuda_h.py:19] end load_into_gpu_async cost 0.0015766620635986328 seconds
DEBUG 01-04 15:36:25.117708.117708 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.118681.118681 cuda_h.py:19] end restore_tensors2 cost 0.00033974647521972656 seconds
DEBUG 01-04 15:36:25.118325.118325 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025038719177246094 seconds
DEBUG 01-04 15:36:25.120602.120602 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004891395568847656 seconds
DEBUG 01-04 15:36:25.120054.120054 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.120302.120302 lmp.py:339] 
DEBUG 01-04 15:36:25.120302.120302 lmp.py:339]   Computing 28 experts on CPU...
DEBUG 01-04 15:36:25.120569.120569 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-04 15:36:25.120126.120126 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.127537.127537 mlpmodule.py:704] group tensors cost 0.006596088409423828 s
DEBUG 01-04 15:36:25.130110.130110 mlpmodule.py:742] pad cost 0.0021648406982421875 s
DEBUG 01-04 15:36:25.130354.130354 mlpmodule.py:748] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-04 15:36:25.130728.130728 mlpmodule.py:753] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-04 15:36:25.134296.134296 mlpmodule.py:768] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-04 15:36:25.134022.134022 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.134177.134177 mlpmodule.py:774] group_w3 first element: 0.049072265625
WARNING 01-04 15:36:25.134035.134035 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.138140.138140 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.138439.138439 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.141862.141862 mlpmodule.py:797] group einsum cost 0.010835409164428711 s
DEBUG 01-04 15:36:25.141896.141896 mlpmodule.py:805] cpy2cputensor cost 0.00010132789611816406 s
DEBUG 01-04 15:36:25.145368.145368 cuda_h.py:19] end wait_cetm_experts cost 0.024993419647216797 seconds
DEBUG 01-04 15:36:25.145981.145981 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.146507.146507 cuda_h.py:19] end gpu_sexperts cost 0.0004508495330810547 seconds
DEBUG 01-04 15:36:25.146927.146927 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-04 15:36:25.146888.146888 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-04 15:36:25.146891.146891 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.4809112548828125e-05 seconds
DEBUG 01-04 15:36:25.146938.146938 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.724761962890625e-05 seconds
DEBUG 01-04 15:36:25.146019.146019 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.146490.146490 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, da84b630-5afe-4899-9ead-4a19bb944bcb
DEBUG 01-04 15:36:25.146575.146575 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.146850.146850 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.146501.146501 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.151484.151484 cuda_h.py:19] end allocate_cuda_memory cost 0.005004405975341797 seconds
DEBUG 01-04 15:36:25.152686.152686 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.152833.152833 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.152682.152682 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.152869.152869 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 67e5a576-8991-471e-8051-ecc00428eb82
DEBUG 01-04 15:36:25.152289.152289 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.162028.162028 mlpmodule.py:662]  experts func einsum cost 0.04184317588806152 s
INFO 01-04 15:36:25.165130.165130 client.py:127] Model loaded
DEBUG 01-04 15:36:25.165728.165728 cuda_h.py:19] end wait_experts cost 0.019383668899536133 seconds
DEBUG 01-04 15:36:25.165736.165736 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.166247.166247 lmp.py:384]   Computing 29 experts on GPU...
INFO 01-04 15:36:25.166891.166891 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 67e5a576-8991-471e-8051-ecc00428eb82
DEBUG 01-04 15:36:25.166648.166648 cuda_h.py:19] end load_into_gpu_async cost 0.014472007751464844 seconds
DEBUG 01-04 15:36:25.166020.166020 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.166964.166964 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-04 15:36:25.166449.166449 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.019814491271972656 seconds
DEBUG 01-04 15:36:25.166975.166975 mlpmodule.py:531] gpu group tensors cost 0.0008900165557861328 s
INFO 01-04 15:36:25.167277.167277 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 67e5a576-8991-471e-8051-ecc00428eb82
DEBUG 01-04 15:36:25.168898.168898 mlpmodule.py:564] gpu pad cost 0.0014998912811279297 s
DEBUG 01-04 15:36:25.169049.169049 mlpmodule.py:582] gpu group einsum cost 0.00048661231994628906 s
DEBUG 01-04 15:36:25.171411.171411 mlpmodule.py:611] gpu experts func einsum cost 0.0058133602142333984 s
DEBUG 01-04 15:36:25.172762.172762 cuda_h.py:19] end gpu_experts cost 0.00606846809387207 seconds
DEBUG 01-04 15:36:25.172233.172233 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.177198.177198 client.py:127] Model loaded
DEBUG 01-04 15:36:25.177916.177916 cuda_h.py:19] end sllm_worker_task cost 0.03024601936340332 seconds
DEBUG 01-04 15:36:25.177541.177541 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005005836486816406 seconds
DEBUG 01-04 15:36:25.177804.177804 cuda_h.py:19] end layer_moe_generate_11 cost 0.0637509822845459 seconds
DEBUG 01-04 15:36:25.177618.177618 lmp.py:207] -------------------------------- end layer 11 --------------------------------
DEBUG 01-04 15:36:25.177997.177997 lmp.py:169] -------------------------------- start layer 12 --------------------------------
DEBUG 01-04 15:36:25.177262.177262 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.177119.177119 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.180193.180193 cuda_h.py:19] end self_attn cost 0.002353668212890625 seconds
DEBUG 01-04 15:36:25.180787.180787 cuda_h.py:19] end iln_self_attn_paln cost 0.002991199493408203 seconds
DEBUG 01-04 15:36:25.180915.180915 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-04 15:36:25.180916.180916 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.181546.181546 cuda_h.py:19] end gate cost 0.0005702972412109375 seconds
DEBUG 01-04 15:36:25.181614.181614 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.181085.181085 lmp.py:281] 
DEBUG 01-04 15:36:25.181085.181085 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.181676.181676 lmp.py:282]   Total experts: 50
DEBUG 01-04 15:36:25.181657.181657 lmp.py:283]   CPU experts: 25 (50%)
DEBUG 01-04 15:36:25.181062.181062 lmp.py:284]   GPU experts: 25 (50%)
DEBUG 01-04 15:36:25.181513.181513 lmp.py:285] 
DEBUG 01-04 15:36:25.181513.181513 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.181964.181964 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.181183.181183 lmp.py:292]   Expert 23 |      1 | CPU
DEBUG 01-04 15:36:25.181157.181157 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:25.181131.181131 lmp.py:292]   Expert 41 |      1 | CPU
DEBUG 01-04 15:36:25.181390.181390 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:25.181648.181648 lmp.py:292]   Expert 55 |      1 | CPU
DEBUG 01-04 15:36:25.181907.181907 lmp.py:292]   Expert  7 |      2 | CPU
DEBUG 01-04 15:36:25.181689.181689 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:25.181710.181710 lmp.py:292]   Expert 14 |      3 | CPU
DEBUG 01-04 15:36:25.181968.181968 lmp.py:292]   Expert 17 |      3 | CPU
DEBUG 01-04 15:36:25.181704.181704 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:25.181201.181201 lmp.py:292]   Expert 46 |      3 | CPU
DEBUG 01-04 15:36:25.181414.181414 lmp.py:292]   Expert 49 |      3 | CPU
DEBUG 01-04 15:36:25.181149.181149 lmp.py:292]   Expert 51 |      3 | CPU
DEBUG 01-04 15:36:25.181170.181170 lmp.py:292]   Expert 62 |      3 | CPU
DEBUG 01-04 15:36:25.181713.181713 lmp.py:292]   Expert 30 |      4 | CPU
DEBUG 01-04 15:36:25.181495.181495 lmp.py:292]   Expert 58 |      4 | CPU
DEBUG 01-04 15:36:25.181039.181039 lmp.py:292]   Expert 61 |      4 | CPU
DEBUG 01-04 15:36:25.181059.181059 lmp.py:292]   Expert  8 |      5 | CPU
DEBUG 01-04 15:36:25.181079.181079 lmp.py:292]   Expert 20 |      5 | CPU
DEBUG 01-04 15:36:25.181861.181861 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:25.182120.182120 lmp.py:292]   Expert 18 |      6 | CPU
DEBUG 01-04 15:36:25.182902.182902 lmp.py:292]   Expert 43 |      6 | CPU
DEBUG 01-04 15:36:25.182399.182399 lmp.py:292]   Expert 31 |      7 | CPU
DEBUG 01-04 15:36:25.182612.182612 lmp.py:292]   Expert 35 |      7 | CPU
DEBUG 01-04 15:36:25.182586.182586 lmp.py:292]   Expert 40 |      7 | CPU
DEBUG 01-04 15:36:25.182321.182321 lmp.py:292]   Expert  6 |      8 | GPU
DEBUG 01-04 15:36:25.182296.182296 lmp.py:292]   Expert 21 |      8 | GPU
DEBUG 01-04 15:36:25.182554.182554 lmp.py:292]   Expert 25 |      8 | GPU
DEBUG 01-04 15:36:25.182336.182336 lmp.py:292]   Expert 42 |      8 | GPU
DEBUG 01-04 15:36:25.182357.182357 lmp.py:292]   Expert 48 |      8 | GPU
DEBUG 01-04 15:36:25.182139.182139 lmp.py:292]   Expert 57 |      9 | GPU
DEBUG 01-04 15:36:25.182921.182921 lmp.py:292]   Expert 59 |      9 | GPU
DEBUG 01-04 15:36:25.182941.182941 lmp.py:292]   Expert 24 |     10 | GPU
DEBUG 01-04 15:36:25.182723.182723 lmp.py:292]   Expert 50 |     11 | GPU
DEBUG 01-04 15:36:25.182697.182697 lmp.py:292]   Expert 19 |     12 | GPU
DEBUG 01-04 15:36:25.182433.182433 lmp.py:292]   Expert 28 |     12 | GPU
DEBUG 01-04 15:36:25.182691.182691 lmp.py:292]   Expert 33 |     13 | GPU
DEBUG 01-04 15:36:25.182427.182427 lmp.py:292]   Expert 36 |     13 | GPU
DEBUG 01-04 15:36:25.182401.182401 lmp.py:292]   Expert 53 |     13 | GPU
DEBUG 01-04 15:36:25.182421.182421 lmp.py:292]   Expert 56 |     13 | GPU
DEBUG 01-04 15:36:25.182203.182203 lmp.py:292]   Expert  9 |     22 | GPU
DEBUG 01-04 15:36:25.182224.182224 lmp.py:292]   Expert 15 |     26 | GPU
DEBUG 01-04 15:36:25.182482.182482 lmp.py:292]   Expert 54 |     29 | GPU
DEBUG 01-04 15:36:25.182503.182503 lmp.py:292]   Expert 10 |     36 | GPU
DEBUG 01-04 15:36:25.182523.182523 lmp.py:292]   Expert  0 |   1985 | GPU
DEBUG 01-04 15:36:25.182544.182544 lmp.py:292]   Expert  3 |   1987 | GPU
DEBUG 01-04 15:36:25.182326.182326 lmp.py:292]   Expert  5 |   1987 | GPU
DEBUG 01-04 15:36:25.182107.182107 lmp.py:292]   Expert  2 |   1988 | GPU
DEBUG 01-04 15:36:25.182366.182366 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:25.182102.182102 lmp.py:292]   Expert  4 |   1992 | GPU
DEBUG 01-04 15:36:25.182222.182222 lmp.py:293] 
DEBUG 01-04 15:36:25.182222.182222 lmp.py:293]   CPU total tokens: 90 (0.7%)
DEBUG 01-04 15:36:25.182388.182388 lmp.py:294]   GPU total tokens: 12198 (99.3%)
DEBUG 01-04 15:36:25.182130.182130 cuda_h.py:19] end experts_map_get cost 0.0011608600616455078 seconds
DEBUG 01-04 15:36:25.182343.182343 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.182635.182635 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.182732.182732 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.182616.182616 cuda_h.py:19] end allocate_cuda_memory cost 0.000270843505859375 seconds
DEBUG 01-04 15:36:25.183651.183651 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.183261.183261 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.183739.183739 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.183436.183436 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bd7926f0-3997-4e63-9e42-c43b7f9f77fc
DEBUG 01-04 15:36:25.183931.183931 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.184971.184971 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bd7926f0-3997-4e63-9e42-c43b7f9f77fc
DEBUG 01-04 15:36:25.184184.184184 cuda_h.py:19] end load_into_gpu_async cost 0.001451730728149414 seconds
DEBUG 01-04 15:36:25.184980.184980 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.184149.184149 cuda_h.py:19] end restore_tensors2 cost 0.000274658203125 seconds
DEBUG 01-04 15:36:25.184071.184071 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023016929626464844 seconds
DEBUG 01-04 15:36:25.186708.186708 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0043528079986572266 seconds
DEBUG 01-04 15:36:25.186392.186392 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.187348.187348 lmp.py:339] 
DEBUG 01-04 15:36:25.187348.187348 lmp.py:339]   Computing 25 experts on CPU...
DEBUG 01-04 15:36:25.187945.187945 cuda_h.py:19] end cpu_experts_submit cost 9.942054748535156e-05 seconds
DEBUG 01-04 15:36:25.187046.187046 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.202763.202763 mlpmodule.py:704] group tensors cost 0.014693498611450195 s
DEBUG 01-04 15:36:25.204437.204437 mlpmodule.py:742] pad cost 0.0014247894287109375 s
DEBUG 01-04 15:36:25.204447.204447 mlpmodule.py:748] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-04 15:36:25.204820.204820 mlpmodule.py:753] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-04 15:36:25.207308.207308 mlpmodule.py:768] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-04 15:36:25.208636.208636 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.208837.208837 mlpmodule.py:774] group_w3 first element: -0.0150146484375
WARNING 01-04 15:36:25.208503.208503 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.211124.211124 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.211218.211218 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.214245.214245 mlpmodule.py:797] group einsum cost 0.010052919387817383 s
DEBUG 01-04 15:36:25.214154.214154 mlpmodule.py:805] cpy2cputensor cost 0.00012183189392089844 s
DEBUG 01-04 15:36:25.218576.218576 cuda_h.py:19] end wait_cetm_experts cost 0.031163930892944336 seconds
DEBUG 01-04 15:36:25.218235.218235 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.218523.218523 cuda_h.py:19] end gpu_sexperts cost 0.00044918060302734375 seconds
DEBUG 01-04 15:36:25.219982.219982 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-04 15:36:25.219705.219705 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-04 15:36:25.219085.219085 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.314018249511719e-05 seconds
DEBUG 01-04 15:36:25.219464.219464 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.43865966796875e-05 seconds
DEBUG 01-04 15:36:25.219259.219259 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.219207.219207 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bd7926f0-3997-4e63-9e42-c43b7f9f77fc
DEBUG 01-04 15:36:25.219922.219922 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.219913.219913 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.219943.219943 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.225053.225053 cuda_h.py:19] end allocate_cuda_memory cost 0.00560760498046875 seconds
DEBUG 01-04 15:36:25.225780.225780 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.225642.225642 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.225578.225578 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.225334.225334 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 596005ae-30c9-4643-be60-fc8853362b41
DEBUG 01-04 15:36:25.225516.225516 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.225742.225742 client.py:127] Model loaded
DEBUG 01-04 15:36:25.225884.225884 cuda_h.py:19] end wait_experts cost 0.006749868392944336 seconds
DEBUG 01-04 15:36:25.225163.225163 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.226727.226727 lmp.py:384]   Computing 25 experts on GPU...
INFO 01-04 15:36:25.226332.226332 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 596005ae-30c9-4643-be60-fc8853362b41
DEBUG 01-04 15:36:25.226758.226758 cuda_h.py:19] end load_into_gpu_async cost 0.0011022090911865234 seconds
DEBUG 01-04 15:36:25.226753.226753 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.226856.226856 cuda_h.py:19] end restore_tensors2 cost 8.082389831542969e-05 seconds
DEBUG 01-04 15:36:25.226711.226711 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007172822952270508 seconds
DEBUG 01-04 15:36:25.227365.227365 mlpmodule.py:531] gpu group tensors cost 0.0009872913360595703 s
INFO 01-04 15:36:25.227061.227061 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 596005ae-30c9-4643-be60-fc8853362b41
DEBUG 01-04 15:36:25.228205.228205 mlpmodule.py:564] gpu pad cost 0.0016214847564697266 s
DEBUG 01-04 15:36:25.229225.229225 mlpmodule.py:582] gpu group einsum cost 0.0005326271057128906 s
DEBUG 01-04 15:36:25.232017.232017 mlpmodule.py:611] gpu experts func einsum cost 0.006211757659912109 s
DEBUG 01-04 15:36:25.232259.232259 cuda_h.py:19] end gpu_experts cost 0.006398200988769531 seconds
DEBUG 01-04 15:36:25.232637.232637 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.237523.237523 client.py:127] Model loaded
DEBUG 01-04 15:36:25.237081.237081 cuda_h.py:19] end sllm_worker_task cost 0.01768970489501953 seconds
DEBUG 01-04 15:36:25.237243.237243 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0048046112060546875 seconds
DEBUG 01-04 15:36:25.237923.237923 cuda_h.py:19] end layer_moe_generate_12 cost 0.05678534507751465 seconds
DEBUG 01-04 15:36:25.237148.237148 lmp.py:207] -------------------------------- end layer 12 --------------------------------
DEBUG 01-04 15:36:25.237195.237195 lmp.py:169] -------------------------------- start layer 13 --------------------------------
DEBUG 01-04 15:36:25.237176.237176 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.237126.237126 cuda_h.py:10] start self_attn
DEBUG 01-04 15:36:25.238881.238881 mlpmodule.py:662]  experts func einsum cost 0.05125927925109863 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.240854.240854 cuda_h.py:19] end self_attn cost 0.0025169849395751953 seconds
DEBUG 01-04 15:36:25.240579.240579 cuda_h.py:19] end iln_self_attn_paln cost 0.0031120777130126953 seconds
DEBUG 01-04 15:36:25.240323.240323 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-04 15:36:25.240609.240609 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.241662.241662 cuda_h.py:19] end gate cost 0.0005674362182617188 seconds
DEBUG 01-04 15:36:25.241584.241584 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.241208.241208 lmp.py:281] 
DEBUG 01-04 15:36:25.241208.241208 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.241819.241819 lmp.py:282]   Total experts: 53
DEBUG 01-04 15:36:25.241515.241515 lmp.py:283]   CPU experts: 26 (49%)
DEBUG 01-04 15:36:25.241634.241634 lmp.py:284]   GPU experts: 27 (51%)
DEBUG 01-04 15:36:25.241847.241847 lmp.py:285] 
DEBUG 01-04 15:36:25.241847.241847 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.241536.241536 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.241232.241232 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:25.241114.241114 lmp.py:292]   Expert 28 |      1 | CPU
DEBUG 01-04 15:36:25.241803.241803 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:25.241254.241254 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:25.241466.241466 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:25.242679.242679 lmp.py:292]   Expert  8 |      2 | CPU
DEBUG 01-04 15:36:25.242845.242845 lmp.py:292]   Expert 17 |      2 | CPU
DEBUG 01-04 15:36:25.242773.242773 lmp.py:292]   Expert 32 |      2 | CPU
DEBUG 01-04 15:36:25.242985.242985 lmp.py:292]   Expert 33 |      2 | CPU
DEBUG 01-04 15:36:25.242959.242959 lmp.py:292]   Expert 35 |      2 | CPU
DEBUG 01-04 15:36:25.242933.242933 lmp.py:292]   Expert 48 |      2 | CPU
DEBUG 01-04 15:36:25.242669.242669 lmp.py:292]   Expert 52 |      2 | CPU
DEBUG 01-04 15:36:25.242404.242404 lmp.py:292]   Expert 11 |      3 | CPU
DEBUG 01-04 15:36:25.242140.242140 lmp.py:292]   Expert 12 |      3 | CPU
DEBUG 01-04 15:36:25.242829.242829 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:25.242280.242280 lmp.py:292]   Expert 46 |      3 | CPU
DEBUG 01-04 15:36:25.242254.242254 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:25.242751.242751 lmp.py:292]   Expert 61 |      3 | CPU
DEBUG 01-04 15:36:25.242726.242726 lmp.py:292]   Expert 13 |      4 | CPU
DEBUG 01-04 15:36:25.242461.242461 lmp.py:292]   Expert 24 |      4 | CPU
DEBUG 01-04 15:36:25.242435.242435 lmp.py:292]   Expert 30 |      4 | CPU
DEBUG 01-04 15:36:25.242932.242932 lmp.py:292]   Expert 37 |      4 | CPU
DEBUG 01-04 15:36:25.242668.242668 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:25.242642.242642 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:25.242855.242855 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:25.242590.242590 lmp.py:292]   Expert 54 |      5 | CPU
DEBUG 01-04 15:36:25.242849.242849 lmp.py:292]   Expert 55 |      5 | GPU
DEBUG 01-04 15:36:25.242823.242823 lmp.py:292]   Expert 62 |      5 | GPU
DEBUG 01-04 15:36:25.242082.242082 lmp.py:292]   Expert 39 |      6 | GPU
DEBUG 01-04 15:36:25.242056.242056 lmp.py:292]   Expert 43 |      6 | GPU
DEBUG 01-04 15:36:25.242791.242791 lmp.py:292]   Expert 41 |      7 | GPU
DEBUG 01-04 15:36:25.242004.242004 lmp.py:292]   Expert 47 |      7 | GPU
DEBUG 01-04 15:36:25.242216.242216 lmp.py:292]   Expert 51 |      7 | GPU
DEBUG 01-04 15:36:25.242190.242190 lmp.py:292]   Expert 59 |      7 | GPU
DEBUG 01-04 15:36:25.242164.242164 lmp.py:292]   Expert 22 |      8 | GPU
DEBUG 01-04 15:36:25.242662.242662 lmp.py:292]   Expert 44 |      8 | GPU
DEBUG 01-04 15:36:25.242397.242397 lmp.py:292]   Expert 63 |      9 | GPU
DEBUG 01-04 15:36:25.242895.242895 lmp.py:292]   Expert 36 |     12 | GPU
DEBUG 01-04 15:36:25.242630.242630 lmp.py:292]   Expert 29 |     13 | GPU
DEBUG 01-04 15:36:25.242889.242889 lmp.py:292]   Expert 23 |     14 | GPU
DEBUG 01-04 15:36:25.242101.242101 lmp.py:292]   Expert 14 |     16 | GPU
DEBUG 01-04 15:36:25.242075.242075 lmp.py:292]   Expert 21 |     18 | GPU
DEBUG 01-04 15:36:25.242050.242050 lmp.py:292]   Expert 38 |     20 | GPU
DEBUG 01-04 15:36:25.242547.242547 lmp.py:292]   Expert 15 |     25 | GPU
DEBUG 01-04 15:36:25.242282.242282 lmp.py:292]   Expert 18 |     25 | GPU
DEBUG 01-04 15:36:25.242541.242541 lmp.py:292]   Expert 10 |     31 | GPU
DEBUG 01-04 15:36:25.242038.242038 lmp.py:292]   Expert 56 |     38 | GPU
DEBUG 01-04 15:36:25.242774.242774 lmp.py:292]   Expert  0 |   1984 | GPU
DEBUG 01-04 15:36:25.242510.242510 lmp.py:292]   Expert  5 |   1986 | GPU
DEBUG 01-04 15:36:25.242960.242960 lmp.py:292]   Expert  3 |   1987 | GPU
DEBUG 01-04 15:36:25.242935.242935 lmp.py:292]   Expert  1 |   1990 | GPU
DEBUG 01-04 15:36:25.242909.242909 lmp.py:292]   Expert  2 |   1990 | GPU
DEBUG 01-04 15:36:25.242406.242406 lmp.py:292]   Expert  4 |   1992 | GPU
DEBUG 01-04 15:36:25.242618.242618 lmp.py:293] 
DEBUG 01-04 15:36:25.242618.242618 lmp.py:293]   CPU total tokens: 72 (0.6%)
DEBUG 01-04 15:36:25.242308.242308 lmp.py:294]   GPU total tokens: 12216 (99.4%)
DEBUG 01-04 15:36:25.242050.242050 cuda_h.py:19] end experts_map_get cost 0.001230001449584961 seconds
DEBUG 01-04 15:36:25.242501.242501 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.242655.242655 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.242149.242149 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.243806.243806 cuda_h.py:19] end allocate_cuda_memory cost 0.00020742416381835938 seconds
DEBUG 01-04 15:36:25.243079.243079 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.243643.243643 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.243075.243075 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.243486.243486 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bd6ea2e6-11ca-450d-bae0-dd521a54f2bb
DEBUG 01-04 15:36:25.243717.243717 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.244698.244698 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bd6ea2e6-11ca-450d-bae0-dd521a54f2bb
DEBUG 01-04 15:36:25.244434.244434 cuda_h.py:19] end load_into_gpu_async cost 0.0012845993041992188 seconds
DEBUG 01-04 15:36:25.244753.244753 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.244897.244897 cuda_h.py:19] end restore_tensors2 cost 0.0003266334533691406 seconds
DEBUG 01-04 15:36:25.245727.245727 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002138376235961914 seconds
DEBUG 01-04 15:36:25.247636.247636 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004393339157104492 seconds
DEBUG 01-04 15:36:25.247942.247942 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.247018.247018 lmp.py:339] 
DEBUG 01-04 15:36:25.247018.247018 lmp.py:339]   Computing 26 experts on CPU...
DEBUG 01-04 15:36:25.247907.247907 cuda_h.py:19] end cpu_experts_submit cost 0.0001227855682373047 seconds
DEBUG 01-04 15:36:25.247987.247987 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.251204.251204 mlpmodule.py:704] group tensors cost 0.004361391067504883 s
DEBUG 01-04 15:36:25.253896.253896 mlpmodule.py:742] pad cost 0.0012135505676269531 s
DEBUG 01-04 15:36:25.253390.253390 mlpmodule.py:748] create cpu tensor cost 6.365776062011719e-05 s
DEBUG 01-04 15:36:25.254663.254663 mlpmodule.py:753] move to cpu cost 2.7418136596679688e-05 s
DEBUG 01-04 15:36:25.257914.257914 mlpmodule.py:768] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-04 15:36:25.257552.257552 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.257309.257309 mlpmodule.py:774] group_w3 first element: 0.00183868408203125
WARNING 01-04 15:36:25.257154.257154 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.260772.260772 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.261137.261137 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.264013.264013 mlpmodule.py:797] group einsum cost 0.009981632232666016 s
DEBUG 01-04 15:36:25.264359.264359 mlpmodule.py:805] cpy2cputensor cost 0.00013184547424316406 s
DEBUG 01-04 15:36:25.267268.267268 cuda_h.py:19] end wait_cetm_experts cost 0.02037358283996582 seconds
DEBUG 01-04 15:36:25.267006.267006 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.268274.268274 cuda_h.py:19] end gpu_sexperts cost 0.0004742145538330078 seconds
DEBUG 01-04 15:36:25.268502.268502 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-04 15:36:25.268033.268033 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-04 15:36:25.268697.268697 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.24249267578125e-05 seconds
DEBUG 01-04 15:36:25.268918.268918 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.268178.268178 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00014400482177734375 seconds
DEBUG 01-04 15:36:25.268677.268677 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.268037.268037 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.269711.269711 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bd6ea2e6-11ca-450d-bae0-dd521a54f2bb
DEBUG 01-04 15:36:25.269007.269007 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.275987.275987 cuda_h.py:19] end allocate_cuda_memory cost 0.005880594253540039 seconds
DEBUG 01-04 15:36:25.275479.275479 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.275673.275673 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.275549.275549 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.275828.275828 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d82d7f4-8557-461e-8a7f-76ee388da9bf
DEBUG 01-04 15:36:25.275970.275970 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.288030.288030 mlpmodule.py:662]  experts func einsum cost 0.04051351547241211 s
INFO 01-04 15:36:25.289139.289139 client.py:127] Model loaded
DEBUG 01-04 15:36:25.289806.289806 cuda_h.py:19] end wait_experts cost 0.020847797393798828 seconds
DEBUG 01-04 15:36:25.289769.289769 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.290732.290732 lmp.py:384]   Computing 27 experts on GPU...
INFO 01-04 15:36:25.290756.290756 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d82d7f4-8557-461e-8a7f-76ee388da9bf
DEBUG 01-04 15:36:25.290890.290890 cuda_h.py:19] end load_into_gpu_async cost 0.015400171279907227 seconds
DEBUG 01-04 15:36:25.290070.290070 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.290299.290299 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-04 15:36:25.290339.290339 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0218350887298584 seconds
DEBUG 01-04 15:36:25.291481.291481 mlpmodule.py:531] gpu group tensors cost 0.0008709430694580078 s
INFO 01-04 15:36:25.291154.291154 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d82d7f4-8557-461e-8a7f-76ee388da9bf
DEBUG 01-04 15:36:25.292007.292007 mlpmodule.py:564] gpu pad cost 0.001378774642944336 s
DEBUG 01-04 15:36:25.293158.293158 mlpmodule.py:582] gpu group einsum cost 0.0004706382751464844 s
DEBUG 01-04 15:36:25.295374.295374 mlpmodule.py:611] gpu experts func einsum cost 0.005392551422119141 s
DEBUG 01-04 15:36:25.295682.295682 cuda_h.py:19] end gpu_experts cost 0.0056304931640625 seconds
DEBUG 01-04 15:36:25.295391.295391 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.301010.301010 client.py:127] Model loaded
DEBUG 01-04 15:36:25.301299.301299 cuda_h.py:19] end sllm_worker_task cost 0.03240060806274414 seconds
DEBUG 01-04 15:36:25.301695.301695 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005656242370605469 seconds
DEBUG 01-04 15:36:25.301351.301351 cuda_h.py:19] end layer_moe_generate_13 cost 0.06073307991027832 seconds
DEBUG 01-04 15:36:25.301072.301072 lmp.py:207] -------------------------------- end layer 13 --------------------------------
DEBUG 01-04 15:36:25.301120.301120 lmp.py:169] -------------------------------- start layer 14 --------------------------------
DEBUG 01-04 15:36:25.301054.301054 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.302633.302633 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.304043.304043 cuda_h.py:19] end self_attn cost 0.002493143081665039 seconds
DEBUG 01-04 15:36:25.304291.304291 cuda_h.py:19] end iln_self_attn_paln cost 0.003093719482421875 seconds
DEBUG 01-04 15:36:25.305750.305750 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-04 15:36:25.305274.305274 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.305302.305302 cuda_h.py:19] end gate cost 0.0005819797515869141 seconds
DEBUG 01-04 15:36:25.305701.305701 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.306239.306239 lmp.py:281] 
DEBUG 01-04 15:36:25.306239.306239 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.306326.306326 lmp.py:282]   Total experts: 55
DEBUG 01-04 15:36:25.306976.306976 lmp.py:283]   CPU experts: 27 (49%)
DEBUG 01-04 15:36:25.306765.306765 lmp.py:284]   GPU experts: 28 (51%)
DEBUG 01-04 15:36:25.306169.306169 lmp.py:285] 
DEBUG 01-04 15:36:25.306169.306169 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.306574.306574 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.306747.306747 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:25.306913.306913 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:25.306364.306364 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:25.306099.306099 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:25.306550.306550 lmp.py:292]   Expert 16 |      2 | CPU
DEBUG 01-04 15:36:25.306763.306763 lmp.py:292]   Expert 17 |      2 | CPU
DEBUG 01-04 15:36:25.306121.306121 lmp.py:292]   Expert 39 |      2 | CPU
DEBUG 01-04 15:36:25.306810.306810 lmp.py:292]   Expert 42 |      2 | CPU
DEBUG 01-04 15:36:25.306499.306499 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:25.306235.306235 lmp.py:292]   Expert 48 |      2 | CPU
DEBUG 01-04 15:36:25.306209.306209 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:25.306945.306945 lmp.py:292]   Expert  8 |      3 | CPU
DEBUG 01-04 15:36:25.306919.306919 lmp.py:292]   Expert 23 |      3 | CPU
DEBUG 01-04 15:36:25.306416.306416 lmp.py:292]   Expert 30 |      3 | CPU
DEBUG 01-04 15:36:25.306913.306913 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:25.306172.306172 lmp.py:292]   Expert 61 |      3 | CPU
DEBUG 01-04 15:36:25.306623.306623 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:25.306074.306074 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:25.306286.306286 lmp.py:292]   Expert 18 |      4 | CPU
DEBUG 01-04 15:36:25.306260.306260 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:25.306281.306281 lmp.py:292]   Expert 41 |      4 | CPU
DEBUG 01-04 15:36:25.306539.306539 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:25.306798.306798 lmp.py:292]   Expert 46 |      4 | CPU
DEBUG 01-04 15:36:25.306819.306819 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:25.306077.306077 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:25.306575.306575 lmp.py:292]   Expert 36 |      5 | CPU
DEBUG 01-04 15:36:25.306072.306072 lmp.py:292]   Expert 37 |      5 | CPU
DEBUG 01-04 15:36:25.306145.306145 lmp.py:292]   Expert 27 |      6 | GPU
DEBUG 01-04 15:36:25.306596.306596 lmp.py:292]   Expert 60 |      6 | GPU
DEBUG 01-04 15:36:25.306047.306047 lmp.py:292]   Expert 63 |      6 | GPU
DEBUG 01-04 15:36:25.306783.306783 lmp.py:292]   Expert 14 |      7 | GPU
DEBUG 01-04 15:36:25.306280.306280 lmp.py:292]   Expert 33 |      8 | GPU
DEBUG 01-04 15:36:25.306539.306539 lmp.py:292]   Expert 21 |      9 | GPU
DEBUG 01-04 15:36:25.306797.306797 lmp.py:292]   Expert 51 |      9 | GPU
DEBUG 01-04 15:36:25.306295.306295 lmp.py:292]   Expert 58 |      9 | GPU
DEBUG 01-04 15:36:25.306553.306553 lmp.py:292]   Expert 13 |     10 | GPU
DEBUG 01-04 15:36:25.306051.306051 lmp.py:292]   Expert 26 |     10 | GPU
DEBUG 01-04 15:36:25.306071.306071 lmp.py:292]   Expert 52 |     10 | GPU
DEBUG 01-04 15:36:25.306059.306059 lmp.py:292]   Expert 15 |     11 | GPU
DEBUG 01-04 15:36:25.306079.306079 lmp.py:292]   Expert 22 |     11 | GPU
DEBUG 01-04 15:36:25.306338.306338 lmp.py:292]   Expert 56 |     11 | GPU
DEBUG 01-04 15:36:25.306312.306312 lmp.py:292]   Expert 25 |     14 | GPU
DEBUG 01-04 15:36:25.306571.306571 lmp.py:292]   Expert 53 |     14 | GPU
DEBUG 01-04 15:36:25.306591.306591 lmp.py:292]   Expert 10 |     15 | GPU
DEBUG 01-04 15:36:25.306373.306373 lmp.py:292]   Expert 19 |     17 | GPU
DEBUG 01-04 15:36:25.306155.306155 lmp.py:292]   Expert 24 |     17 | GPU
DEBUG 01-04 15:36:25.306414.306414 lmp.py:292]   Expert 47 |     17 | GPU
DEBUG 01-04 15:36:25.306434.306434 lmp.py:292]   Expert 31 |     18 | GPU
DEBUG 01-04 15:36:25.306454.306454 lmp.py:292]   Expert  9 |     23 | GPU
DEBUG 01-04 15:36:25.306713.306713 lmp.py:292]   Expert  2 |   1988 | GPU
DEBUG 01-04 15:36:25.306495.306495 lmp.py:292]   Expert  4 |   1989 | GPU
DEBUG 01-04 15:36:25.306516.306516 lmp.py:292]   Expert  3 |   1990 | GPU
DEBUG 01-04 15:36:25.306774.306774 lmp.py:292]   Expert  0 |   1993 | GPU
DEBUG 01-04 15:36:25.306510.306510 lmp.py:292]   Expert  5 |   1993 | GPU
DEBUG 01-04 15:36:25.306722.306722 lmp.py:292]   Expert  1 |   1996 | GPU
DEBUG 01-04 15:36:25.307458.307458 lmp.py:293] 
DEBUG 01-04 15:36:25.307458.307458 lmp.py:293]   CPU total tokens: 81 (0.7%)
DEBUG 01-04 15:36:25.307432.307432 lmp.py:294]   GPU total tokens: 12207 (99.3%)
DEBUG 01-04 15:36:25.307221.307221 cuda_h.py:19] end experts_map_get cost 0.0012698173522949219 seconds
DEBUG 01-04 15:36:25.307672.307672 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.307302.307302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.307697.307697 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.307813.307813 cuda_h.py:19] end allocate_cuda_memory cost 0.00026607513427734375 seconds
DEBUG 01-04 15:36:25.307133.307133 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.307988.307988 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.307374.307374 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.307831.307831 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 089d2b39-7b04-47fb-9cc0-dbdf7ad20393
DEBUG 01-04 15:36:25.307300.307300 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.308905.308905 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 089d2b39-7b04-47fb-9cc0-dbdf7ad20393
DEBUG 01-04 15:36:25.309373.309373 cuda_h.py:19] end load_into_gpu_async cost 0.001390695571899414 seconds
DEBUG 01-04 15:36:25.309905.309905 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.309418.309418 cuda_h.py:19] end restore_tensors2 cost 0.0004229545593261719 seconds
DEBUG 01-04 15:36:25.309738.309738 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025124549865722656 seconds
DEBUG 01-04 15:36:25.311607.311607 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004773139953613281 seconds
DEBUG 01-04 15:36:25.311914.311914 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.311346.311346 lmp.py:339] 
DEBUG 01-04 15:36:25.311346.311346 lmp.py:339]   Computing 27 experts on CPU...
DEBUG 01-04 15:36:25.312852.312852 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-04 15:36:25.312952.312952 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.318148.318148 mlpmodule.py:704] group tensors cost 0.00650787353515625 s
DEBUG 01-04 15:36:25.321358.321358 mlpmodule.py:742] pad cost 0.0021839141845703125 s
DEBUG 01-04 15:36:25.321323.321323 mlpmodule.py:748] create cpu tensor cost 6.175041198730469e-05 s
DEBUG 01-04 15:36:25.321750.321750 mlpmodule.py:753] move to cpu cost 4.363059997558594e-05 s
DEBUG 01-04 15:36:25.325781.325781 mlpmodule.py:768] group_w3: shape=torch.Size([27, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=77856768
DEBUG 01-04 15:36:25.325148.325148 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.325250.325250 mlpmodule.py:774] group_w3 first element: 0.064453125
WARNING 01-04 15:36:25.325723.325723 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.328670.328670 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.329294.329294 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.332517.332517 mlpmodule.py:797] group einsum cost 0.010353326797485352 s
DEBUG 01-04 15:36:25.332228.332228 mlpmodule.py:805] cpy2cputensor cost 8.0108642578125e-05 s
DEBUG 01-04 15:36:25.336160.336160 cuda_h.py:19] end wait_cetm_experts cost 0.024159669876098633 seconds
DEBUG 01-04 15:36:25.336004.336004 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.336850.336850 cuda_h.py:19] end gpu_sexperts cost 0.0004553794860839844 seconds
DEBUG 01-04 15:36:25.336554.336554 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-04 15:36:25.337707.337707 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-04 15:36:25.337941.337941 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.4332275390625e-05 seconds
DEBUG 01-04 15:36:25.337843.337843 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.05718994140625e-05 seconds
DEBUG 01-04 15:36:25.337447.337447 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.337395.337395 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 089d2b39-7b04-47fb-9cc0-dbdf7ad20393
DEBUG 01-04 15:36:25.337632.337632 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.337358.337358 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.337976.337976 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.341235.341235 cuda_h.py:19] end allocate_cuda_memory cost 0.0039331912994384766 seconds
DEBUG 01-04 15:36:25.341696.341696 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.341949.341949 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.341361.341361 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.341078.341078 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b4908576-2340-49d9-b22b-1a9af562762e
DEBUG 01-04 15:36:25.341803.341803 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.350481.350481 mlpmodule.py:662]  experts func einsum cost 0.03840899467468262 s
INFO 01-04 15:36:25.353522.353522 client.py:127] Model loaded
DEBUG 01-04 15:36:25.353358.353358 cuda_h.py:19] end wait_experts cost 0.01651287078857422 seconds
DEBUG 01-04 15:36:25.353081.353081 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.353023.353023 lmp.py:384]   Computing 28 experts on GPU...
INFO 01-04 15:36:25.354507.354507 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b4908576-2340-49d9-b22b-1a9af562762e
DEBUG 01-04 15:36:25.354642.354642 cuda_h.py:19] end load_into_gpu_async cost 0.012591361999511719 seconds
DEBUG 01-04 15:36:25.354729.354729 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.354719.354719 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-04 15:36:25.354521.354521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.016899585723876953 seconds
DEBUG 01-04 15:36:25.354130.354130 mlpmodule.py:531] gpu group tensors cost 0.0009615421295166016 s
INFO 01-04 15:36:25.354780.354780 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b4908576-2340-49d9-b22b-1a9af562762e
DEBUG 01-04 15:36:25.356961.356961 mlpmodule.py:564] gpu pad cost 0.0013611316680908203 s
DEBUG 01-04 15:36:25.356457.356457 mlpmodule.py:582] gpu group einsum cost 0.0005056858062744141 s
DEBUG 01-04 15:36:25.359813.359813 mlpmodule.py:611] gpu experts func einsum cost 0.005539894104003906 s
DEBUG 01-04 15:36:25.359307.359307 cuda_h.py:19] end gpu_experts cost 0.005724668502807617 seconds
DEBUG 01-04 15:36:25.359494.359494 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.364329.364329 client.py:127] Model loaded
DEBUG 01-04 15:36:25.364557.364557 cuda_h.py:19] end sllm_worker_task cost 0.027293920516967773 seconds
DEBUG 01-04 15:36:25.364823.364823 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005270481109619141 seconds
DEBUG 01-04 15:36:25.364404.364404 cuda_h.py:19] end layer_moe_generate_14 cost 0.0598602294921875 seconds
DEBUG 01-04 15:36:25.365489.365489 lmp.py:207] -------------------------------- end layer 14 --------------------------------
DEBUG 01-04 15:36:25.365391.365391 lmp.py:169] -------------------------------- start layer 15 --------------------------------
DEBUG 01-04 15:36:25.365180.365180 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.365401.365401 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.367905.367905 cuda_h.py:19] end self_attn cost 0.002355337142944336 seconds
DEBUG 01-04 15:36:25.368656.368656 cuda_h.py:19] end iln_self_attn_paln cost 0.0029201507568359375 seconds
DEBUG 01-04 15:36:25.368062.368062 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-04 15:36:25.368394.368394 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.368389.368389 cuda_h.py:19] end gate cost 0.0005953311920166016 seconds
DEBUG 01-04 15:36:25.368695.368695 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.369638.369638 lmp.py:281] 
DEBUG 01-04 15:36:25.369638.369638 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.369394.369394 lmp.py:282]   Total experts: 60
DEBUG 01-04 15:36:25.369044.369044 lmp.py:283]   CPU experts: 30 (50%)
DEBUG 01-04 15:36:25.369833.369833 lmp.py:284]   GPU experts: 30 (50%)
DEBUG 01-04 15:36:25.369952.369952 lmp.py:285] 
DEBUG 01-04 15:36:25.369952.369952 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.369595.369595 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.369007.369007 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:25.369127.369127 lmp.py:292]   Expert 29 |      1 | CPU
DEBUG 01-04 15:36:25.369816.369816 lmp.py:292]   Expert 33 |      1 | CPU
DEBUG 01-04 15:36:25.369505.369505 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:25.369956.369956 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:25.369168.369168 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:25.369381.369381 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:25.369593.369593 lmp.py:292]   Expert  7 |      2 | CPU
DEBUG 01-04 15:36:25.369567.369567 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:25.369780.369780 lmp.py:292]   Expert 32 |      2 | CPU
DEBUG 01-04 15:36:25.369946.369946 lmp.py:292]   Expert 40 |      2 | CPU
DEBUG 01-04 15:36:25.369874.369874 lmp.py:292]   Expert 41 |      2 | CPU
DEBUG 01-04 15:36:25.369801.369801 lmp.py:292]   Expert 42 |      2 | CPU
DEBUG 01-04 15:36:25.369968.369968 lmp.py:292]   Expert 55 |      2 | CPU
DEBUG 01-04 15:36:25.369942.369942 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:25.369154.369154 lmp.py:292]   Expert 56 |      3 | CPU
DEBUG 01-04 15:36:25.369367.369367 lmp.py:292]   Expert 59 |      3 | CPU
DEBUG 01-04 15:36:25.369102.369102 lmp.py:292]   Expert 14 |      4 | CPU
DEBUG 01-04 15:36:25.369553.369553 lmp.py:292]   Expert 23 |      4 | CPU
DEBUG 01-04 15:36:25.369541.369541 lmp.py:292]   Expert 24 |      4 | CPU
DEBUG 01-04 15:36:25.369276.369276 lmp.py:292]   Expert 31 |      4 | CPU
DEBUG 01-04 15:36:25.369774.369774 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:25.369271.369271 lmp.py:292]   Expert 12 |      5 | CPU
DEBUG 01-04 15:36:25.369006.369006 lmp.py:292]   Expert 18 |      5 | CPU
DEBUG 01-04 15:36:25.369742.369742 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:25.369577.369577 lmp.py:292]   Expert 46 |      5 | CPU
DEBUG 01-04 15:36:25.369505.369505 lmp.py:292]   Expert 50 |      5 | CPU
DEBUG 01-04 15:36:25.369194.369194 lmp.py:292]   Expert 53 |      5 | CPU
DEBUG 01-04 15:36:25.369168.369168 lmp.py:292]   Expert 11 |      6 | CPU
DEBUG 01-04 15:36:25.369904.369904 lmp.py:292]   Expert 16 |      6 | CPU
DEBUG 01-04 15:36:25.369639.369639 lmp.py:292]   Expert 22 |      6 | GPU
DEBUG 01-04 15:36:25.369137.369137 lmp.py:292]   Expert 38 |      6 | GPU
DEBUG 01-04 15:36:25.369111.369111 lmp.py:292]   Expert 39 |      6 | GPU
DEBUG 01-04 15:36:25.369608.369608 lmp.py:292]   Expert 45 |      6 | GPU
DEBUG 01-04 15:36:25.369105.369105 lmp.py:292]   Expert 62 |      6 | GPU
DEBUG 01-04 15:36:25.369364.369364 lmp.py:292]   Expert 19 |      7 | GPU
DEBUG 01-04 15:36:25.369099.369099 lmp.py:292]   Expert 61 |      7 | GPU
DEBUG 01-04 15:36:25.369835.369835 lmp.py:292]   Expert 10 |      8 | GPU
DEBUG 01-04 15:36:25.369571.369571 lmp.py:292]   Expert 21 |      8 | GPU
DEBUG 01-04 15:36:25.369068.369068 lmp.py:292]   Expert 25 |      8 | GPU
DEBUG 01-04 15:36:25.369042.369042 lmp.py:292]   Expert 13 |      9 | GPU
DEBUG 01-04 15:36:25.369970.369970 lmp.py:292]   Expert 20 |      9 | GPU
DEBUG 01-04 15:36:25.369897.369897 lmp.py:292]   Expert 27 |      9 | GPU
DEBUG 01-04 15:36:25.369587.369587 lmp.py:292]   Expert 36 |      9 | GPU
DEBUG 01-04 15:36:25.370038.370038 lmp.py:292]   Expert 47 |      9 | GPU
DEBUG 01-04 15:36:25.370250.370250 lmp.py:292]   Expert 49 |      9 | GPU
DEBUG 01-04 15:36:25.370747.370747 lmp.py:292]   Expert 54 |      9 | GPU
DEBUG 01-04 15:36:25.370244.370244 lmp.py:292]   Expert 58 |      9 | GPU
DEBUG 01-04 15:36:25.370742.370742 lmp.py:292]   Expert 60 |      9 | GPU
DEBUG 01-04 15:36:25.370000.370000 lmp.py:292]   Expert 17 |     13 | GPU
DEBUG 01-04 15:36:25.370736.370736 lmp.py:292]   Expert  9 |     16 | GPU
DEBUG 01-04 15:36:25.370995.370995 lmp.py:292]   Expert 26 |     17 | GPU
DEBUG 01-04 15:36:25.370731.370731 lmp.py:292]   Expert 30 |     17 | GPU
DEBUG 01-04 15:36:25.370989.370989 lmp.py:292]   Expert  8 |     32 | GPU
DEBUG 01-04 15:36:25.370725.370725 lmp.py:292]   Expert  5 |   1987 | GPU
DEBUG 01-04 15:36:25.370414.370414 lmp.py:292]   Expert  0 |   1989 | GPU
DEBUG 01-04 15:36:25.370627.370627 lmp.py:292]   Expert  1 |   1989 | GPU
DEBUG 01-04 15:36:25.370078.370078 lmp.py:292]   Expert  4 |   1989 | GPU
DEBUG 01-04 15:36:25.370005.370005 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:25.370218.370218 lmp.py:292]   Expert  2 |   2006 | GPU
DEBUG 01-04 15:36:25.370430.370430 lmp.py:293] 
DEBUG 01-04 15:36:25.370430.370430 lmp.py:293]   CPU total tokens: 92 (0.7%)
DEBUG 01-04 15:36:25.370881.370881 lmp.py:294]   GPU total tokens: 12196 (99.3%)
DEBUG 01-04 15:36:25.370385.370385 cuda_h.py:19] end experts_map_get cost 0.0013933181762695312 seconds
DEBUG 01-04 15:36:25.370074.370074 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.370566.370566 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.370835.370835 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.370539.370539 cuda_h.py:19] end allocate_cuda_memory cost 0.00020647048950195312 seconds
DEBUG 01-04 15:36:25.370097.370097 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.370230.370230 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.370947.370947 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.370358.370358 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b20100ff-e612-496e-8338-3ab045f9ffae
DEBUG 01-04 15:36:25.371563.371563 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.376882.376882 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b20100ff-e612-496e-8338-3ab045f9ffae
DEBUG 01-04 15:36:25.376403.376403 cuda_h.py:19] end load_into_gpu_async cost 0.0053403377532958984 seconds
DEBUG 01-04 15:36:25.376558.376558 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.376263.376263 cuda_h.py:19] end restore_tensors2 cost 0.0006225109100341797 seconds
DEBUG 01-04 15:36:25.377346.377346 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00665736198425293 seconds
DEBUG 01-04 15:36:25.381270.381270 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011556863784790039 seconds
DEBUG 01-04 15:36:25.381101.381101 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.382046.382046 lmp.py:339] 
DEBUG 01-04 15:36:25.382046.382046 lmp.py:339]   Computing 30 experts on CPU...
DEBUG 01-04 15:36:25.382758.382758 cuda_h.py:19] end cpu_experts_submit cost 0.00018215179443359375 seconds
DEBUG 01-04 15:36:25.382634.382634 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.399494.399494 mlpmodule.py:704] group tensors cost 0.01693892478942871 s
DEBUG 01-04 15:36:25.401668.401668 mlpmodule.py:742] pad cost 0.001729726791381836 s
DEBUG 01-04 15:36:25.402540.402540 mlpmodule.py:748] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-04 15:36:25.402787.402787 mlpmodule.py:753] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-04 15:36:25.406015.406015 mlpmodule.py:768] group_w3: shape=torch.Size([30, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=86507520
DEBUG 01-04 15:36:25.406866.406866 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.406643.406643 mlpmodule.py:774] group_w3 first element: -0.042236328125
WARNING 01-04 15:36:25.406263.406263 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.410000.410000 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.410414.410414 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.414841.414841 mlpmodule.py:797] group einsum cost 0.012609004974365234 s
DEBUG 01-04 15:36:25.414623.414623 mlpmodule.py:805] cpy2cputensor cost 8.106231689453125e-05 s
DEBUG 01-04 15:36:25.419018.419018 cuda_h.py:19] end wait_cetm_experts cost 0.036736249923706055 seconds
DEBUG 01-04 15:36:25.419485.419485 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.419303.419303 cuda_h.py:19] end gpu_sexperts cost 0.00045371055603027344 seconds
DEBUG 01-04 15:36:25.419676.419676 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-04 15:36:25.419969.419969 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-04 15:36:25.419296.419296 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.2901763916015625e-05 seconds
DEBUG 01-04 15:36:25.419198.419198 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.937980651855469e-05 seconds
DEBUG 01-04 15:36:25.419470.419470 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.419418.419418 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b20100ff-e612-496e-8338-3ab045f9ffae
DEBUG 01-04 15:36:25.420563.420563 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.420407.420407 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.420026.420026 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.424653.424653 cuda_h.py:19] end allocate_cuda_memory cost 0.004239559173583984 seconds
DEBUG 01-04 15:36:25.424013.424013 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.424266.424266 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.424394.424394 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.424826.424826 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3be8d88-6336-4729-9f5a-ea6afa00bbb9
DEBUG 01-04 15:36:25.424744.424744 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.426007.426007 client.py:127] Model loaded
DEBUG 01-04 15:36:25.426149.426149 cuda_h.py:19] end wait_experts cost 0.006192445755004883 seconds
DEBUG 01-04 15:36:25.426428.426428 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.426707.426707 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:25.426425.426425 mlpmodule.py:531] gpu group tensors cost 0.0005946159362792969 s
INFO 01-04 15:36:25.427765.427765 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3be8d88-6336-4729-9f5a-ea6afa00bbb9
DEBUG 01-04 15:36:25.427853.427853 cuda_h.py:19] end load_into_gpu_async cost 0.0026810169219970703 seconds
DEBUG 01-04 15:36:25.427417.427417 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.427374.427374 cuda_h.py:19] end restore_tensors2 cost 7.963180541992188e-05 seconds
DEBUG 01-04 15:36:25.427229.427229 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007308006286621094 seconds
INFO 01-04 15:36:25.428284.428284 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3be8d88-6336-4729-9f5a-ea6afa00bbb9
DEBUG 01-04 15:36:25.429503.429503 mlpmodule.py:564] gpu pad cost 0.0024955272674560547 s
DEBUG 01-04 15:36:25.430491.430491 mlpmodule.py:582] gpu group einsum cost 0.0005245208740234375 s
DEBUG 01-04 15:36:25.432544.432544 mlpmodule.py:611] gpu experts func einsum cost 0.006720304489135742 s
DEBUG 01-04 15:36:25.433708.433708 cuda_h.py:19] end gpu_experts cost 0.006954669952392578 seconds
DEBUG 01-04 15:36:25.433371.433371 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:25.434297.434297 mlpmodule.py:662]  experts func einsum cost 0.052045345306396484 s
INFO 01-04 15:36:25.437710.437710 client.py:127] Model loaded
DEBUG 01-04 15:36:25.438832.438832 cuda_h.py:19] end sllm_worker_task cost 0.01782512664794922 seconds
DEBUG 01-04 15:36:25.438166.438166 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.0049092769622802734 seconds
DEBUG 01-04 15:36:25.438946.438946 cuda_h.py:19] end layer_moe_generate_15 cost 0.07007312774658203 seconds
DEBUG 01-04 15:36:25.438561.438561 lmp.py:207] -------------------------------- end layer 15 --------------------------------
DEBUG 01-04 15:36:25.438416.438416 lmp.py:169] -------------------------------- start layer 16 --------------------------------
DEBUG 01-04 15:36:25.438205.438205 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.438048.438048 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.441177.441177 cuda_h.py:19] end self_attn cost 0.0023937225341796875 seconds
DEBUG 01-04 15:36:25.441948.441948 cuda_h.py:19] end iln_self_attn_paln cost 0.002977132797241211 seconds
DEBUG 01-04 15:36:25.441692.441692 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-04 15:36:25.441514.441514 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.442825.442825 cuda_h.py:19] end gate cost 0.0005488395690917969 seconds
DEBUG 01-04 15:36:25.442032.442032 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.442994.442994 lmp.py:281] 
DEBUG 01-04 15:36:25.442994.442994 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.442128.442128 lmp.py:282]   Total experts: 57
DEBUG 01-04 15:36:25.442632.442632 lmp.py:283]   CPU experts: 28 (49%)
DEBUG 01-04 15:36:25.442274.442274 lmp.py:284]   GPU experts: 29 (51%)
DEBUG 01-04 15:36:25.442772.442772 lmp.py:285] 
DEBUG 01-04 15:36:25.442772.442772 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.442746.442746 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.442396.442396 lmp.py:292]   Expert 39 |      1 | CPU
DEBUG 01-04 15:36:25.442846.442846 lmp.py:292]   Expert 45 |      1 | CPU
DEBUG 01-04 15:36:25.442344.442344 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:25.442602.442602 lmp.py:292]   Expert  9 |      2 | CPU
DEBUG 01-04 15:36:25.442623.442623 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:25.442643.442643 lmp.py:292]   Expert 34 |      2 | CPU
DEBUG 01-04 15:36:25.442664.442664 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:25.442684.442684 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:25.442704.442704 lmp.py:292]   Expert 60 |      2 | CPU
DEBUG 01-04 15:36:25.442725.442725 lmp.py:292]   Expert 14 |      3 | CPU
DEBUG 01-04 15:36:25.442222.442222 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:25.442719.442719 lmp.py:292]   Expert 25 |      3 | CPU
DEBUG 01-04 15:36:25.442501.442501 lmp.py:292]   Expert 28 |      3 | CPU
DEBUG 01-04 15:36:25.442045.442045 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:25.442542.442542 lmp.py:292]   Expert 46 |      3 | CPU
DEBUG 01-04 15:36:25.442085.442085 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:25.442867.442867 lmp.py:292]   Expert  8 |      4 | CPU
DEBUG 01-04 15:36:25.442888.442888 lmp.py:292]   Expert 18 |      4 | CPU
DEBUG 01-04 15:36:25.442431.442431 lmp.py:292]   Expert 21 |      4 | CPU
DEBUG 01-04 15:36:25.442213.442213 lmp.py:292]   Expert 40 |      4 | CPU
DEBUG 01-04 15:36:25.442995.442995 lmp.py:292]   Expert 41 |      4 | CPU
DEBUG 01-04 15:36:25.442731.442731 lmp.py:292]   Expert 48 |      4 | CPU
DEBUG 01-04 15:36:25.442513.442513 lmp.py:292]   Expert 19 |      5 | CPU
DEBUG 01-04 15:36:25.442056.442056 lmp.py:292]   Expert 32 |      5 | CPU
DEBUG 01-04 15:36:25.442076.442076 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:25.442858.442858 lmp.py:292]   Expert 42 |      5 | CPU
DEBUG 01-04 15:36:25.442640.442640 lmp.py:292]   Expert 56 |      5 | CPU
DEBUG 01-04 15:36:25.443184.443184 lmp.py:292]   Expert 61 |      5 | CPU
DEBUG 01-04 15:36:25.443681.443681 lmp.py:292]   Expert 17 |      6 | GPU
DEBUG 01-04 15:36:25.443225.443225 lmp.py:292]   Expert 30 |      6 | GPU
DEBUG 01-04 15:36:25.443245.443245 lmp.py:292]   Expert 33 |      6 | GPU
DEBUG 01-04 15:36:25.443219.443219 lmp.py:292]   Expert 37 |      6 | GPU
DEBUG 01-04 15:36:25.443478.443478 lmp.py:292]   Expert 38 |      6 | GPU
DEBUG 01-04 15:36:25.443737.443737 lmp.py:292]   Expert 62 |      6 | GPU
DEBUG 01-04 15:36:25.443280.443280 lmp.py:292]   Expert 11 |      7 | GPU
DEBUG 01-04 15:36:25.443062.443062 lmp.py:292]   Expert 55 |      7 | GPU
DEBUG 01-04 15:36:25.443844.443844 lmp.py:292]   Expert  7 |      8 | GPU
DEBUG 01-04 15:36:25.443103.443103 lmp.py:292]   Expert 26 |      8 | GPU
DEBUG 01-04 15:36:25.443885.443885 lmp.py:292]   Expert 12 |      9 | GPU
DEBUG 01-04 15:36:25.443428.443428 lmp.py:292]   Expert 36 |      9 | GPU
DEBUG 01-04 15:36:25.443210.443210 lmp.py:292]   Expert 16 |     10 | GPU
DEBUG 01-04 15:36:25.443992.443992 lmp.py:292]   Expert 24 |     10 | GPU
DEBUG 01-04 15:36:25.443536.443536 lmp.py:292]   Expert 20 |     12 | GPU
DEBUG 01-04 15:36:25.443841.443841 lmp.py:292]   Expert 22 |     12 | GPU
DEBUG 01-04 15:36:25.443623.443623 lmp.py:292]   Expert 23 |     12 | GPU
DEBUG 01-04 15:36:25.443120.443120 lmp.py:292]   Expert 29 |     13 | GPU
DEBUG 01-04 15:36:25.443379.443379 lmp.py:292]   Expert 52 |     14 | GPU
DEBUG 01-04 15:36:25.443922.443922 lmp.py:292]   Expert 63 |     14 | GPU
DEBUG 01-04 15:36:25.443228.443228 lmp.py:292]   Expert 10 |     16 | GPU
DEBUG 01-04 15:36:25.443009.443009 lmp.py:292]   Expert 27 |     16 | GPU
DEBUG 01-04 15:36:25.443791.443791 lmp.py:292]   Expert 47 |     26 | GPU
DEBUG 01-04 15:36:25.443335.443335 lmp.py:292]   Expert  0 |   1985 | GPU
DEBUG 01-04 15:36:25.443117.443117 lmp.py:292]   Expert  3 |   1986 | GPU
DEBUG 01-04 15:36:25.443137.443137 lmp.py:292]   Expert  1 |   1989 | GPU
DEBUG 01-04 15:36:25.443681.443681 lmp.py:292]   Expert  2 |   1996 | GPU
DEBUG 01-04 15:36:25.443224.443224 lmp.py:292]   Expert  4 |   1996 | GPU
DEBUG 01-04 15:36:25.443006.443006 lmp.py:292]   Expert  5 |   2007 | GPU
DEBUG 01-04 15:36:25.443457.443457 lmp.py:293] 
DEBUG 01-04 15:36:25.443457.443457 lmp.py:293]   CPU total tokens: 90 (0.7%)
DEBUG 01-04 15:36:25.443908.443908 lmp.py:294]   GPU total tokens: 12198 (99.3%)
DEBUG 01-04 15:36:25.443174.443174 cuda_h.py:19] end experts_map_get cost 0.0012373924255371094 seconds
DEBUG 01-04 15:36:25.443386.443386 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.443209.443209 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.443564.443564 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.443647.443647 cuda_h.py:19] end allocate_cuda_memory cost 0.00027561187744140625 seconds
DEBUG 01-04 15:36:25.444636.444636 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.444769.444769 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.444532.444532 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.444751.444751 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b0a5a1d-3d67-4ca0-acae-1df05be30816
DEBUG 01-04 15:36:25.444109.444109 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.446334.446334 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b0a5a1d-3d67-4ca0-acae-1df05be30816
DEBUG 01-04 15:36:25.446119.446119 cuda_h.py:19] end load_into_gpu_async cost 0.0023212432861328125 seconds
DEBUG 01-04 15:36:25.446849.446849 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.446251.446251 cuda_h.py:19] end restore_tensors2 cost 0.0004925727844238281 seconds
DEBUG 01-04 15:36:25.447320.447320 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003496885299682617 seconds
DEBUG 01-04 15:36:25.451431.451431 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008040666580200195 seconds
DEBUG 01-04 15:36:25.451355.451355 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.451339.451339 lmp.py:339] 
DEBUG 01-04 15:36:25.451339.451339 lmp.py:339]   Computing 28 experts on CPU...
DEBUG 01-04 15:36:25.451044.451044 cuda_h.py:19] end cpu_experts_submit cost 0.00017333030700683594 seconds
DEBUG 01-04 15:36:25.451743.451743 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.457264.457264 mlpmodule.py:704] group tensors cost 0.005720376968383789 s
DEBUG 01-04 15:36:25.460721.460721 mlpmodule.py:742] pad cost 0.0016655921936035156 s
DEBUG 01-04 15:36:25.460400.460400 mlpmodule.py:748] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-04 15:36:25.460661.460661 mlpmodule.py:753] move to cpu cost 4.124641418457031e-05 s
DEBUG 01-04 15:36:25.464045.464045 mlpmodule.py:768] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-04 15:36:25.464565.464565 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.464528.464528 mlpmodule.py:774] group_w3 first element: 0.01385498046875
WARNING 01-04 15:36:25.464689.464689 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.467421.467421 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.468084.468084 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.471714.471714 mlpmodule.py:797] group einsum cost 0.010821342468261719 s
DEBUG 01-04 15:36:25.471325.471325 mlpmodule.py:805] cpy2cputensor cost 0.00011157989501953125 s
DEBUG 01-04 15:36:25.475111.475111 cuda_h.py:19] end wait_cetm_experts cost 0.023365497589111328 seconds
DEBUG 01-04 15:36:25.475816.475816 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.476946.476946 cuda_h.py:19] end gpu_sexperts cost 0.00046324729919433594 seconds
DEBUG 01-04 15:36:25.476604.476604 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-04 15:36:25.476996.476996 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-04 15:36:25.476283.476283 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.3855438232421875e-05 seconds
DEBUG 01-04 15:36:25.476662.476662 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.534027099609375e-05 seconds
DEBUG 01-04 15:36:25.476219.476219 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.476644.476644 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b0a5a1d-3d67-4ca0-acae-1df05be30816
DEBUG 01-04 15:36:25.476716.476716 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.476926.476926 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.476127.476127 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.480622.480622 cuda_h.py:19] end allocate_cuda_memory cost 0.0038628578186035156 seconds
DEBUG 01-04 15:36:25.480923.480923 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.480308.480308 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.480661.480661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.480417.480417 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 09522493-2de8-4d73-9c96-74cde482ffd3
DEBUG 01-04 15:36:25.480122.480122 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.490623.490623 mlpmodule.py:662]  experts func einsum cost 0.038023948669433594 s
INFO 01-04 15:36:25.494524.494524 client.py:127] Model loaded
DEBUG 01-04 15:36:25.494076.494076 cuda_h.py:19] end wait_experts cost 0.018439054489135742 seconds
DEBUG 01-04 15:36:25.494083.494083 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.494356.494356 lmp.py:384]   Computing 29 experts on GPU...
DEBUG 01-04 15:36:25.495103.495103 mlpmodule.py:531] gpu group tensors cost 0.0004875659942626953 s
INFO 01-04 15:36:25.495311.495311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 09522493-2de8-4d73-9c96-74cde482ffd3
DEBUG 01-04 15:36:25.495247.495247 cuda_h.py:19] end load_into_gpu_async cost 0.014983654022216797 seconds
DEBUG 01-04 15:36:25.495950.495950 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.495079.495079 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-04 15:36:25.495881.495881 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.019199371337890625 seconds
INFO 01-04 15:36:25.496978.496978 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 09522493-2de8-4d73-9c96-74cde482ffd3
DEBUG 01-04 15:36:25.497438.497438 mlpmodule.py:564] gpu pad cost 0.002057790756225586 s
DEBUG 01-04 15:36:25.498036.498036 mlpmodule.py:582] gpu group einsum cost 0.0005602836608886719 s
DEBUG 01-04 15:36:25.501850.501850 mlpmodule.py:611] gpu experts func einsum cost 0.006582736968994141 s
DEBUG 01-04 15:36:25.501893.501893 cuda_h.py:19] end gpu_experts cost 0.006750583648681641 seconds
DEBUG 01-04 15:36:25.501616.501616 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.505994.505994 client.py:127] Model loaded
DEBUG 01-04 15:36:25.506367.506367 cuda_h.py:19] end sllm_worker_task cost 0.029402971267700195 seconds
DEBUG 01-04 15:36:25.506682.506682 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004494190216064453 seconds
DEBUG 01-04 15:36:25.506643.506643 cuda_h.py:19] end layer_moe_generate_16 cost 0.06477046012878418 seconds
DEBUG 01-04 15:36:25.506028.506028 lmp.py:207] -------------------------------- end layer 16 --------------------------------
DEBUG 01-04 15:36:25.506473.506473 lmp.py:169] -------------------------------- start layer 17 --------------------------------
DEBUG 01-04 15:36:25.506037.506037 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.507161.507161 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.509577.509577 cuda_h.py:19] end self_attn cost 0.0024521350860595703 seconds
DEBUG 01-04 15:36:25.509778.509778 cuda_h.py:19] end iln_self_attn_paln cost 0.003108501434326172 seconds
DEBUG 01-04 15:36:25.509760.509760 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-04 15:36:25.509000.509000 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.510914.510914 cuda_h.py:19] end gate cost 0.0005698204040527344 seconds
DEBUG 01-04 15:36:25.510028.510028 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.510501.510501 lmp.py:281] 
DEBUG 01-04 15:36:25.510501.510501 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.510734.510734 lmp.py:282]   Total experts: 60
DEBUG 01-04 15:36:25.510444.510444 lmp.py:283]   CPU experts: 30 (50%)
DEBUG 01-04 15:36:25.510994.510994 lmp.py:284]   GPU experts: 30 (50%)
DEBUG 01-04 15:36:25.510399.510399 lmp.py:285] 
DEBUG 01-04 15:36:25.510399.510399 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.510803.510803 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.510453.510453 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:25.510858.510858 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:25.511547.511547 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:25.511759.511759 lmp.py:292]   Expert 36 |      1 | CPU
DEBUG 01-04 15:36:25.511972.511972 lmp.py:292]   Expert 47 |      1 | CPU
DEBUG 01-04 15:36:25.511184.511184 lmp.py:292]   Expert 63 |      1 | CPU
DEBUG 01-04 15:36:25.511827.511827 lmp.py:292]   Expert  8 |      2 | CPU
DEBUG 01-04 15:36:25.511232.511232 lmp.py:292]   Expert 10 |      2 | CPU
DEBUG 01-04 15:36:25.511683.511683 lmp.py:292]   Expert 46 |      2 | CPU
DEBUG 01-04 15:36:25.511895.511895 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:25.511108.511108 lmp.py:292]   Expert 59 |      2 | CPU
DEBUG 01-04 15:36:25.511558.511558 lmp.py:292]   Expert 60 |      2 | CPU
DEBUG 01-04 15:36:25.511771.511771 lmp.py:292]   Expert  9 |      3 | CPU
DEBUG 01-04 15:36:25.511983.511983 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:25.511196.511196 lmp.py:292]   Expert 37 |      3 | CPU
DEBUG 01-04 15:36:25.511408.511408 lmp.py:292]   Expert 40 |      3 | CPU
DEBUG 01-04 15:36:25.511813.511813 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:25.511979.511979 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:25.511430.511430 lmp.py:292]   Expert 56 |      3 | CPU
DEBUG 01-04 15:36:25.511642.511642 lmp.py:292]   Expert 34 |      4 | CPU
DEBUG 01-04 15:36:25.511616.511616 lmp.py:292]   Expert 53 |      4 | CPU
DEBUG 01-04 15:36:25.511829.511829 lmp.py:292]   Expert  6 |      5 | CPU
DEBUG 01-04 15:36:25.511280.511280 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:25.511254.511254 lmp.py:292]   Expert 50 |      5 | CPU
DEBUG 01-04 15:36:25.511466.511466 lmp.py:292]   Expert 52 |      5 | CPU
DEBUG 01-04 15:36:25.511679.511679 lmp.py:292]   Expert 57 |      5 | CPU
DEBUG 01-04 15:36:25.511414.511414 lmp.py:292]   Expert 61 |      5 | CPU
DEBUG 01-04 15:36:25.511865.511865 lmp.py:292]   Expert 18 |      6 | CPU
DEBUG 01-04 15:36:25.511316.511316 lmp.py:292]   Expert 21 |      6 | CPU
DEBUG 01-04 15:36:25.511482.511482 lmp.py:292]   Expert 24 |      6 | CPU
DEBUG 01-04 15:36:25.511456.511456 lmp.py:292]   Expert 31 |      6 | GPU
DEBUG 01-04 15:36:25.511669.511669 lmp.py:292]   Expert 11 |      7 | GPU
DEBUG 01-04 15:36:25.511404.511404 lmp.py:292]   Expert 32 |      7 | GPU
DEBUG 01-04 15:36:25.511378.511378 lmp.py:292]   Expert 35 |      7 | GPU
DEBUG 01-04 15:36:25.511114.511114 lmp.py:292]   Expert 38 |      7 | GPU
DEBUG 01-04 15:36:25.511850.511850 lmp.py:292]   Expert 51 |      7 | GPU
DEBUG 01-04 15:36:25.511824.511824 lmp.py:292]   Expert 54 |      7 | GPU
DEBUG 01-04 15:36:25.511559.511559 lmp.py:292]   Expert 19 |      8 | GPU
DEBUG 01-04 15:36:25.511772.511772 lmp.py:292]   Expert 26 |      8 | GPU
DEBUG 01-04 15:36:25.511507.511507 lmp.py:292]   Expert 58 |      8 | GPU
DEBUG 01-04 15:36:25.511674.511674 lmp.py:292]   Expert 15 |      9 | GPU
DEBUG 01-04 15:36:25.511601.511601 lmp.py:292]   Expert 13 |     10 | GPU
DEBUG 01-04 15:36:25.511814.511814 lmp.py:292]   Expert 22 |     10 | GPU
DEBUG 01-04 15:36:25.511026.511026 lmp.py:292]   Expert 41 |     10 | GPU
DEBUG 01-04 15:36:25.511239.511239 lmp.py:292]   Expert 62 |     11 | GPU
DEBUG 01-04 15:36:25.511451.511451 lmp.py:292]   Expert 48 |     12 | GPU
DEBUG 01-04 15:36:25.511425.511425 lmp.py:292]   Expert 20 |     13 | GPU
DEBUG 01-04 15:36:25.511399.511399 lmp.py:292]   Expert 43 |     13 | GPU
DEBUG 01-04 15:36:25.511373.511373 lmp.py:292]   Expert 33 |     14 | GPU
DEBUG 01-04 15:36:25.511871.511871 lmp.py:292]   Expert 23 |     15 | GPU
DEBUG 01-04 15:36:25.511083.511083 lmp.py:292]   Expert 45 |     17 | GPU
DEBUG 01-04 15:36:25.511295.511295 lmp.py:292]   Expert 12 |     19 | GPU
DEBUG 01-04 15:36:25.511269.511269 lmp.py:292]   Expert 17 |     21 | GPU
DEBUG 01-04 15:36:25.511482.511482 lmp.py:292]   Expert 55 |     21 | GPU
DEBUG 01-04 15:36:25.511840.511840 lmp.py:292]   Expert  3 |   1984 | GPU
DEBUG 01-04 15:36:25.511245.511245 lmp.py:292]   Expert  4 |   1984 | GPU
DEBUG 01-04 15:36:25.511696.511696 lmp.py:292]   Expert  0 |   1988 | GPU
DEBUG 01-04 15:36:25.511431.511431 lmp.py:292]   Expert  1 |   1990 | GPU
DEBUG 01-04 15:36:25.511644.511644 lmp.py:292]   Expert  2 |   1990 | GPU
DEBUG 01-04 15:36:25.511618.511618 lmp.py:292]   Expert  5 |   1990 | GPU
DEBUG 01-04 15:36:25.511545.511545 lmp.py:293] 
DEBUG 01-04 15:36:25.511545.511545 lmp.py:293]   CPU total tokens: 95 (0.8%)
DEBUG 01-04 15:36:25.511235.511235 lmp.py:294]   GPU total tokens: 12193 (99.2%)
DEBUG 01-04 15:36:25.511931.511931 cuda_h.py:19] end experts_map_get cost 0.0014085769653320312 seconds
DEBUG 01-04 15:36:25.512097.512097 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.512827.512827 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.512434.512434 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.512517.512517 cuda_h.py:19] end allocate_cuda_memory cost 0.00027561187744140625 seconds
DEBUG 01-04 15:36:25.512937.512937 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.512977.512977 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.512171.512171 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.512297.512297 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f9ee5cbe-6fab-401b-8112-c7217c78152c
DEBUG 01-04 15:36:25.512840.512840 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.514419.514419 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f9ee5cbe-6fab-401b-8112-c7217c78152c
DEBUG 01-04 15:36:25.514348.514348 cuda_h.py:19] end load_into_gpu_async cost 0.002168416976928711 seconds
DEBUG 01-04 15:36:25.514859.514859 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.515341.515341 cuda_h.py:19] end restore_tensors2 cost 0.00032973289489746094 seconds
DEBUG 01-04 15:36:25.515124.515124 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031104087829589844 seconds
DEBUG 01-04 15:36:25.517056.517056 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005667448043823242 seconds
DEBUG 01-04 15:36:25.517700.517700 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.517087.517087 lmp.py:339] 
DEBUG 01-04 15:36:25.517087.517087 lmp.py:339]   Computing 30 experts on CPU...
DEBUG 01-04 15:36:25.517923.517923 cuda_h.py:19] end cpu_experts_submit cost 0.00010251998901367188 seconds
DEBUG 01-04 15:36:25.517547.517547 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.529853.529853 mlpmodule.py:704] group tensors cost 0.011759519577026367 s
DEBUG 01-04 15:36:25.531850.531850 mlpmodule.py:742] pad cost 0.0012722015380859375 s
DEBUG 01-04 15:36:25.531972.531972 mlpmodule.py:748] create cpu tensor cost 3.6716461181640625e-05 s
DEBUG 01-04 15:36:25.531100.531100 mlpmodule.py:753] move to cpu cost 2.6702880859375e-05 s
DEBUG 01-04 15:36:25.535894.535894 mlpmodule.py:768] group_w3: shape=torch.Size([30, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=86507520
DEBUG 01-04 15:36:25.535884.535884 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.535694.535694 mlpmodule.py:774] group_w3 first element: 0.0267333984375
WARNING 01-04 15:36:25.536969.536969 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.539998.539998 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.539032.539032 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.543292.543292 mlpmodule.py:797] group einsum cost 0.011215925216674805 s
DEBUG 01-04 15:36:25.543591.543591 mlpmodule.py:805] cpy2cputensor cost 8.034706115722656e-05 s
DEBUG 01-04 15:36:25.547179.547179 cuda_h.py:19] end wait_cetm_experts cost 0.02951526641845703 seconds
DEBUG 01-04 15:36:25.547653.547653 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.548352.548352 cuda_h.py:19] end gpu_sexperts cost 0.0004687309265136719 seconds
DEBUG 01-04 15:36:25.548586.548586 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-04 15:36:25.548886.548886 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-04 15:36:25.548266.548266 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.4809112548828125e-05 seconds
DEBUG 01-04 15:36:25.548366.548366 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.724761962890625e-05 seconds
DEBUG 01-04 15:36:25.548069.548069 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.548906.548906 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f9ee5cbe-6fab-401b-8112-c7217c78152c
DEBUG 01-04 15:36:25.548256.548256 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.548008.548008 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.548805.548805 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.553800.553800 cuda_h.py:19] end allocate_cuda_memory cost 0.005151987075805664 seconds
DEBUG 01-04 15:36:25.554809.554809 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.554479.554479 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.554555.554555 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.554788.554788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26586bf7-05e5-43a5-9e5f-3997d6bd6f1e
DEBUG 01-04 15:36:25.554447.554447 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.564358.564358 mlpmodule.py:662]  experts func einsum cost 0.04603266716003418 s
INFO 01-04 15:36:25.565869.565869 client.py:127] Model loaded
DEBUG 01-04 15:36:25.565072.565072 cuda_h.py:19] end wait_experts cost 0.017032146453857422 seconds
DEBUG 01-04 15:36:25.565572.565572 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.565151.565151 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:25.566449.566449 mlpmodule.py:531] gpu group tensors cost 0.0004980564117431641 s
INFO 01-04 15:36:25.566830.566830 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26586bf7-05e5-43a5-9e5f-3997d6bd6f1e
DEBUG 01-04 15:36:25.566033.566033 cuda_h.py:19] end load_into_gpu_async cost 0.012380838394165039 seconds
DEBUG 01-04 15:36:25.566027.566027 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.566825.566825 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-04 15:36:25.566058.566058 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.017874956130981445 seconds
INFO 01-04 15:36:25.567520.567520 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26586bf7-05e5-43a5-9e5f-3997d6bd6f1e
DEBUG 01-04 15:36:25.568494.568494 mlpmodule.py:564] gpu pad cost 0.001969575881958008 s
DEBUG 01-04 15:36:25.568428.568428 mlpmodule.py:582] gpu group einsum cost 0.0005009174346923828 s
DEBUG 01-04 15:36:25.571977.571977 mlpmodule.py:611] gpu experts func einsum cost 0.00618743896484375 s
DEBUG 01-04 15:36:25.572053.572053 cuda_h.py:19] end gpu_experts cost 0.006402492523193359 seconds
DEBUG 01-04 15:36:25.572386.572386 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.576742.576742 client.py:127] Model loaded
DEBUG 01-04 15:36:25.576976.576976 cuda_h.py:19] end sllm_worker_task cost 0.02813863754272461 seconds
DEBUG 01-04 15:36:25.576065.576065 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00482177734375 seconds
DEBUG 01-04 15:36:25.577997.577997 cuda_h.py:19] end layer_moe_generate_17 cost 0.06717109680175781 seconds
DEBUG 01-04 15:36:25.577586.577586 lmp.py:207] -------------------------------- end layer 17 --------------------------------
DEBUG 01-04 15:36:25.577495.577495 lmp.py:169] -------------------------------- start layer 18 --------------------------------
DEBUG 01-04 15:36:25.577145.577145 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.577307.577307 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.580807.580807 cuda_h.py:19] end self_attn cost 0.002418994903564453 seconds
DEBUG 01-04 15:36:25.580379.580379 cuda_h.py:19] end iln_self_attn_paln cost 0.003020763397216797 seconds
DEBUG 01-04 15:36:25.580541.580541 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-04 15:36:25.580589.580589 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.581026.581026 cuda_h.py:19] end gate cost 0.0005671977996826172 seconds
DEBUG 01-04 15:36:25.581876.581876 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.581971.581971 lmp.py:281] 
DEBUG 01-04 15:36:25.581971.581971 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.581774.581774 lmp.py:282]   Total experts: 60
DEBUG 01-04 15:36:25.581424.581424 lmp.py:283]   CPU experts: 30 (50%)
DEBUG 01-04 15:36:25.581735.581735 lmp.py:284]   GPU experts: 30 (50%)
DEBUG 01-04 15:36:25.581140.581140 lmp.py:285] 
DEBUG 01-04 15:36:25.581140.581140 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.581545.581545 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.581194.581194 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:25.581328.581328 lmp.py:292]   Expert 35 |      1 | CPU
DEBUG 01-04 15:36:25.581540.581540 lmp.py:292]   Expert 37 |      1 | CPU
DEBUG 01-04 15:36:25.581276.581276 lmp.py:292]   Expert 53 |      1 | CPU
DEBUG 01-04 15:36:25.581535.581535 lmp.py:292]   Expert 55 |      1 | CPU
DEBUG 01-04 15:36:25.581793.581793 lmp.py:292]   Expert  9 |      2 | CPU
DEBUG 01-04 15:36:25.581529.581529 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:25.581218.581218 lmp.py:292]   Expert 29 |      2 | CPU
DEBUG 01-04 15:36:25.581384.581384 lmp.py:292]   Expert 30 |      2 | CPU
DEBUG 01-04 15:36:25.581120.581120 lmp.py:292]   Expert 41 |      2 | CPU
DEBUG 01-04 15:36:25.581856.581856 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:25.581591.581591 lmp.py:292]   Expert 46 |      2 | CPU
DEBUG 01-04 15:36:25.581089.581089 lmp.py:292]   Expert 56 |      2 | CPU
DEBUG 01-04 15:36:25.581063.581063 lmp.py:292]   Expert 63 |      2 | CPU
DEBUG 01-04 15:36:25.581798.581798 lmp.py:292]   Expert  6 |      3 | CPU
DEBUG 01-04 15:36:25.581295.581295 lmp.py:292]   Expert  8 |      3 | CPU
DEBUG 01-04 15:36:25.581793.581793 lmp.py:292]   Expert 20 |      3 | CPU
DEBUG 01-04 15:36:25.581290.581290 lmp.py:292]   Expert 24 |      3 | CPU
DEBUG 01-04 15:36:25.581787.581787 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:25.581284.581284 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:25.581781.581781 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:25.581755.581755 lmp.py:292]   Expert 48 |      3 | CPU
DEBUG 01-04 15:36:25.581730.581730 lmp.py:292]   Expert 51 |      3 | CPU
DEBUG 01-04 15:36:25.581227.581227 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:25.581724.581724 lmp.py:292]   Expert 33 |      4 | CPU
DEBUG 01-04 15:36:25.581983.581983 lmp.py:292]   Expert 40 |      4 | CPU
DEBUG 01-04 15:36:25.581242.581242 lmp.py:292]   Expert 45 |      5 | CPU
DEBUG 01-04 15:36:25.582500.582500 lmp.py:292]   Expert 58 |      5 | CPU
DEBUG 01-04 15:36:25.582236.582236 lmp.py:292]   Expert 60 |      5 | CPU
DEBUG 01-04 15:36:25.582495.582495 lmp.py:292]   Expert 25 |      6 | CPU
DEBUG 01-04 15:36:25.582992.582992 lmp.py:292]   Expert 57 |      6 | GPU
DEBUG 01-04 15:36:25.582681.582681 lmp.py:292]   Expert 61 |      6 | GPU
DEBUG 01-04 15:36:25.582178.582178 lmp.py:292]   Expert 18 |      7 | GPU
DEBUG 01-04 15:36:25.582676.582676 lmp.py:292]   Expert 28 |      7 | GPU
DEBUG 01-04 15:36:25.582173.582173 lmp.py:292]   Expert 42 |      7 | GPU
DEBUG 01-04 15:36:25.582670.582670 lmp.py:292]   Expert 52 |      7 | GPU
DEBUG 01-04 15:36:25.582929.582929 lmp.py:292]   Expert 27 |      8 | GPU
DEBUG 01-04 15:36:25.582426.582426 lmp.py:292]   Expert 50 |      8 | GPU
DEBUG 01-04 15:36:25.582923.582923 lmp.py:292]   Expert 59 |      8 | GPU
DEBUG 01-04 15:36:25.582659.582659 lmp.py:292]   Expert 38 |      9 | GPU
DEBUG 01-04 15:36:25.582156.582156 lmp.py:292]   Expert 49 |      9 | GPU
DEBUG 01-04 15:36:25.582369.582369 lmp.py:292]   Expert  7 |     10 | GPU
DEBUG 01-04 15:36:25.582581.582581 lmp.py:292]   Expert 10 |     10 | GPU
DEBUG 01-04 15:36:25.582555.582555 lmp.py:292]   Expert 31 |     10 | GPU
DEBUG 01-04 15:36:25.582529.582529 lmp.py:292]   Expert 47 |     10 | GPU
DEBUG 01-04 15:36:25.582788.582788 lmp.py:292]   Expert 14 |     11 | GPU
DEBUG 01-04 15:36:25.582524.582524 lmp.py:292]   Expert 15 |     12 | GPU
DEBUG 01-04 15:36:25.582782.582782 lmp.py:292]   Expert 16 |     12 | GPU
DEBUG 01-04 15:36:25.582518.582518 lmp.py:292]   Expert 21 |     14 | GPU
DEBUG 01-04 15:36:25.582538.582538 lmp.py:292]   Expert 26 |     17 | GPU
DEBUG 01-04 15:36:25.582036.582036 lmp.py:292]   Expert 17 |     18 | GPU
DEBUG 01-04 15:36:25.582294.582294 lmp.py:292]   Expert 23 |     21 | GPU
DEBUG 01-04 15:36:25.582507.582507 lmp.py:292]   Expert 36 |     23 | GPU
DEBUG 01-04 15:36:25.582719.582719 lmp.py:292]   Expert 62 |     24 | GPU
DEBUG 01-04 15:36:25.582170.582170 lmp.py:292]   Expert  5 |   1985 | GPU
DEBUG 01-04 15:36:25.582906.582906 lmp.py:292]   Expert  0 |   1986 | GPU
DEBUG 01-04 15:36:25.582165.582165 lmp.py:292]   Expert  1 |   1988 | GPU
DEBUG 01-04 15:36:25.582423.582423 lmp.py:292]   Expert  3 |   1989 | GPU
DEBUG 01-04 15:36:25.582921.582921 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:25.582193.582193 lmp.py:292]   Expert  2 |   1992 | GPU
DEBUG 01-04 15:36:25.582929.582929 lmp.py:293] 
DEBUG 01-04 15:36:25.582929.582929 lmp.py:293]   CPU total tokens: 83 (0.7%)
DEBUG 01-04 15:36:25.582426.582426 lmp.py:294]   GPU total tokens: 12205 (99.3%)
DEBUG 01-04 15:36:25.582976.582976 cuda_h.py:19] end experts_map_get cost 0.0013804435729980469 seconds
DEBUG 01-04 15:36:25.582904.582904 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.582442.582442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.582949.582949 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.583264.583264 cuda_h.py:19] end allocate_cuda_memory cost 0.0002722740173339844 seconds
DEBUG 01-04 15:36:25.583061.583061 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.583671.583671 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.583195.583195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.583415.583415 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 658f6d18-9cd6-4fe9-9869-103c88b0380d
DEBUG 01-04 15:36:25.583507.583507 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.584778.584778 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 658f6d18-9cd6-4fe9-9869-103c88b0380d
DEBUG 01-04 15:36:25.584762.584762 cuda_h.py:19] end load_into_gpu_async cost 0.0015246868133544922 seconds
DEBUG 01-04 15:36:25.584050.584050 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.585411.585411 cuda_h.py:19] end restore_tensors2 cost 0.00045108795166015625 seconds
DEBUG 01-04 15:36:25.585525.585525 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026743412017822266 seconds
DEBUG 01-04 15:36:25.587266.587266 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005052089691162109 seconds
DEBUG 01-04 15:36:25.587950.587950 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.587336.587336 lmp.py:339] 
DEBUG 01-04 15:36:25.587336.587336 lmp.py:339]   Computing 30 experts on CPU...
DEBUG 01-04 15:36:25.587219.587219 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-04 15:36:25.587843.587843 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.599262.599262 mlpmodule.py:704] group tensors cost 0.01114964485168457 s
DEBUG 01-04 15:36:25.601372.601372 mlpmodule.py:742] pad cost 0.0017380714416503906 s
DEBUG 01-04 15:36:25.601336.601336 mlpmodule.py:748] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-04 15:36:25.601345.601345 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-04 15:36:25.605457.605457 mlpmodule.py:768] group_w3: shape=torch.Size([30, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=86507520
DEBUG 01-04 15:36:25.605077.605077 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.605563.605563 mlpmodule.py:774] group_w3 first element: -0.0247802734375
WARNING 01-04 15:36:25.605050.605050 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.609952.609952 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.609695.609695 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.612763.612763 mlpmodule.py:797] group einsum cost 0.011232137680053711 s
DEBUG 01-04 15:36:25.613432.613432 mlpmodule.py:805] cpy2cputensor cost 7.557868957519531e-05 s
DEBUG 01-04 15:36:25.617125.617125 cuda_h.py:19] end wait_cetm_experts cost 0.029341459274291992 seconds
DEBUG 01-04 15:36:25.617837.617837 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.617747.617747 cuda_h.py:19] end gpu_sexperts cost 0.0004527568817138672 seconds
DEBUG 01-04 15:36:25.617736.617736 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-04 15:36:25.617221.617221 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-04 15:36:25.618548.618548 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.24249267578125e-05 seconds
DEBUG 01-04 15:36:25.618523.618523 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 8.678436279296875e-05 seconds
DEBUG 01-04 15:36:25.618272.618272 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.618697.618697 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 658f6d18-9cd6-4fe9-9869-103c88b0380d
DEBUG 01-04 15:36:25.618379.618379 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.618735.618735 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.618838.618838 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.622202.622202 cuda_h.py:19] end allocate_cuda_memory cost 0.004061698913574219 seconds
DEBUG 01-04 15:36:25.622218.622218 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.622364.622364 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.622956.622956 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.622996.622996 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99ccb2a0-8625-41b7-a37e-648e40b80a9c
DEBUG 01-04 15:36:25.623417.623417 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.632279.632279 mlpmodule.py:662]  experts func einsum cost 0.044719696044921875 s
INFO 01-04 15:36:25.634211.634211 client.py:127] Model loaded
DEBUG 01-04 15:36:25.634617.634617 cuda_h.py:19] end wait_experts cost 0.016798734664916992 seconds
DEBUG 01-04 15:36:25.634671.634671 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.635613.635613 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:25.635611.635611 mlpmodule.py:531] gpu group tensors cost 0.0004966259002685547 s
INFO 01-04 15:36:25.635302.635302 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99ccb2a0-8625-41b7-a37e-648e40b80a9c
DEBUG 01-04 15:36:25.635523.635523 cuda_h.py:19] end load_into_gpu_async cost 0.013039112091064453 seconds
DEBUG 01-04 15:36:25.635749.635749 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.636924.636924 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-04 15:36:25.636773.636773 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.017484426498413086 seconds
INFO 01-04 15:36:25.636957.636957 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99ccb2a0-8625-41b7-a37e-648e40b80a9c
DEBUG 01-04 15:36:25.637691.637691 mlpmodule.py:564] gpu pad cost 0.002115011215209961 s
DEBUG 01-04 15:36:25.638657.638657 mlpmodule.py:582] gpu group einsum cost 0.0004913806915283203 s
DEBUG 01-04 15:36:25.641715.641715 mlpmodule.py:611] gpu experts func einsum cost 0.006537675857543945 s
DEBUG 01-04 15:36:25.641188.641188 cuda_h.py:19] end gpu_experts cost 0.0067081451416015625 seconds
DEBUG 01-04 15:36:25.641527.641527 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.646376.646376 client.py:127] Model loaded
DEBUG 01-04 15:36:25.646842.646842 cuda_h.py:19] end sllm_worker_task cost 0.027935504913330078 seconds
DEBUG 01-04 15:36:25.646919.646919 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004734516143798828 seconds
DEBUG 01-04 15:36:25.646728.646728 cuda_h.py:19] end layer_moe_generate_18 cost 0.066253662109375 seconds
DEBUG 01-04 15:36:25.646973.646973 lmp.py:207] -------------------------------- end layer 18 --------------------------------
DEBUG 01-04 15:36:25.647703.647703 lmp.py:169] -------------------------------- start layer 19 --------------------------------
DEBUG 01-04 15:36:25.647029.647029 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.647146.647146 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.650554.650554 cuda_h.py:19] end self_attn cost 0.002835512161254883 seconds
DEBUG 01-04 15:36:25.650670.650670 cuda_h.py:19] end iln_self_attn_paln cost 0.0034911632537841797 seconds
DEBUG 01-04 15:36:25.650367.650367 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-04 15:36:25.650706.650706 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.651873.651873 cuda_h.py:19] end gate cost 0.000579833984375 seconds
DEBUG 01-04 15:36:25.651179.651179 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.651758.651758 lmp.py:281] 
DEBUG 01-04 15:36:25.651758.651758 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.651753.651753 lmp.py:282]   Total experts: 60
DEBUG 01-04 15:36:25.651356.651356 lmp.py:283]   CPU experts: 30 (50%)
DEBUG 01-04 15:36:25.651906.651906 lmp.py:284]   GPU experts: 30 (50%)
DEBUG 01-04 15:36:25.651311.651311 lmp.py:285] 
DEBUG 01-04 15:36:25.651311.651311 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.651669.651669 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.651273.651273 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:25.651154.651154 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:25.651320.651320 lmp.py:292]   Expert 17 |      1 | CPU
DEBUG 01-04 15:36:25.651248.651248 lmp.py:292]   Expert 27 |      1 | CPU
DEBUG 01-04 15:36:25.651176.651176 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:25.651865.651865 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:25.651077.651077 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:25.651528.651528 lmp.py:292]   Expert 60 |      1 | CPU
DEBUG 01-04 15:36:25.651217.651217 lmp.py:292]   Expert 23 |      2 | CPU
DEBUG 01-04 15:36:25.651622.651622 lmp.py:292]   Expert 30 |      2 | CPU
DEBUG 01-04 15:36:25.651265.651265 lmp.py:292]   Expert 36 |      2 | CPU
DEBUG 01-04 15:36:25.651670.651670 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:25.651836.651836 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:25.651048.651048 lmp.py:292]   Expert 59 |      2 | CPU
DEBUG 01-04 15:36:25.651499.651499 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:25.651711.651711 lmp.py:292]   Expert 32 |      3 | CPU
DEBUG 01-04 15:36:25.652924.652924 lmp.py:292]   Expert 46 |      3 | CPU
DEBUG 01-04 15:36:25.652136.652136 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:25.652587.652587 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:25.652800.652800 lmp.py:292]   Expert 56 |      3 | CPU
DEBUG 01-04 15:36:25.652012.652012 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:25.652417.652417 lmp.py:292]   Expert 18 |      4 | CPU
DEBUG 01-04 15:36:25.652345.652345 lmp.py:292]   Expert 43 |      4 | CPU
DEBUG 01-04 15:36:25.652511.652511 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:25.652677.652677 lmp.py:292]   Expert 33 |      5 | CPU
DEBUG 01-04 15:36:25.652843.652843 lmp.py:292]   Expert 35 |      5 | CPU
DEBUG 01-04 15:36:25.652294.652294 lmp.py:292]   Expert 47 |      5 | CPU
DEBUG 01-04 15:36:25.652506.652506 lmp.py:292]   Expert 52 |      5 | CPU
DEBUG 01-04 15:36:25.652242.652242 lmp.py:292]   Expert  8 |      6 | CPU
DEBUG 01-04 15:36:25.652216.652216 lmp.py:292]   Expert 10 |      6 | CPU
DEBUG 01-04 15:36:25.652190.652190 lmp.py:292]   Expert 25 |      6 | GPU
DEBUG 01-04 15:36:25.652641.652641 lmp.py:292]   Expert 51 |      6 | GPU
DEBUG 01-04 15:36:25.652853.652853 lmp.py:292]   Expert 54 |      6 | GPU
DEBUG 01-04 15:36:25.652589.652589 lmp.py:292]   Expert 63 |      6 | GPU
DEBUG 01-04 15:36:25.652801.652801 lmp.py:292]   Expert 11 |      7 | GPU
DEBUG 01-04 15:36:25.652775.652775 lmp.py:292]   Expert 26 |      7 | GPU
DEBUG 01-04 15:36:25.652750.652750 lmp.py:292]   Expert 42 |      7 | GPU
DEBUG 01-04 15:36:25.652677.652677 lmp.py:292]   Expert 62 |      7 | GPU
DEBUG 01-04 15:36:25.652843.652843 lmp.py:292]   Expert 14 |      8 | GPU
DEBUG 01-04 15:36:25.652023.652023 lmp.py:292]   Expert 61 |      8 | GPU
DEBUG 01-04 15:36:25.652236.652236 lmp.py:292]   Expert 16 |      9 | GPU
DEBUG 01-04 15:36:25.652547.652547 lmp.py:292]   Expert 21 |      9 | GPU
DEBUG 01-04 15:36:25.652714.652714 lmp.py:292]   Expert 24 |      9 | GPU
DEBUG 01-04 15:36:25.652926.652926 lmp.py:292]   Expert  9 |     10 | GPU
DEBUG 01-04 15:36:25.652662.652662 lmp.py:292]   Expert 20 |     10 | GPU
DEBUG 01-04 15:36:25.652636.652636 lmp.py:292]   Expert 38 |     10 | GPU
DEBUG 01-04 15:36:25.652610.652610 lmp.py:292]   Expert 39 |     11 | GPU
DEBUG 01-04 15:36:25.652822.652822 lmp.py:292]   Expert 31 |     12 | GPU
DEBUG 01-04 15:36:25.652035.652035 lmp.py:292]   Expert 45 |     12 | GPU
DEBUG 01-04 15:36:25.652009.652009 lmp.py:292]   Expert 19 |     13 | GPU
DEBUG 01-04 15:36:25.652460.652460 lmp.py:292]   Expert 29 |     13 | GPU
DEBUG 01-04 15:36:25.652910.652910 lmp.py:292]   Expert 41 |     13 | GPU
DEBUG 01-04 15:36:25.652838.652838 lmp.py:292]   Expert 22 |     15 | GPU
DEBUG 01-04 15:36:25.652766.652766 lmp.py:292]   Expert  7 |     30 | GPU
DEBUG 01-04 15:36:25.652932.652932 lmp.py:292]   Expert  4 |   1987 | GPU
DEBUG 01-04 15:36:25.652860.652860 lmp.py:292]   Expert  5 |   1987 | GPU
DEBUG 01-04 15:36:25.652549.652549 lmp.py:292]   Expert  0 |   1992 | GPU
DEBUG 01-04 15:36:25.652762.652762 lmp.py:292]   Expert  1 |   1992 | GPU
DEBUG 01-04 15:36:25.652974.652974 lmp.py:292]   Expert  2 |   1996 | GPU
DEBUG 01-04 15:36:25.652948.652948 lmp.py:292]   Expert  3 |   2005 | GPU
DEBUG 01-04 15:36:25.652353.652353 lmp.py:293] 
DEBUG 01-04 15:36:25.652353.652353 lmp.py:293]   CPU total tokens: 85 (0.7%)
DEBUG 01-04 15:36:25.652757.652757 lmp.py:294]   GPU total tokens: 12203 (99.3%)
DEBUG 01-04 15:36:25.652930.652930 cuda_h.py:19] end experts_map_get cost 0.001436471939086914 seconds
DEBUG 01-04 15:36:25.652573.652573 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.652794.652794 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.653215.653215 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.653623.653623 cuda_h.py:19] end allocate_cuda_memory cost 0.00026702880859375 seconds
DEBUG 01-04 15:36:25.653949.653949 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.653467.653467 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.653806.653806 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.653886.653886 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 53aadd6f-48eb-4822-b481-423576e57445
DEBUG 01-04 15:36:25.653906.653906 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.655264.655264 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 53aadd6f-48eb-4822-b481-423576e57445
DEBUG 01-04 15:36:25.655162.655162 cuda_h.py:19] end load_into_gpu_async cost 0.0023555755615234375 seconds
DEBUG 01-04 15:36:25.655125.655125 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.656491.656491 cuda_h.py:19] end restore_tensors2 cost 0.00038170814514160156 seconds
DEBUG 01-04 15:36:25.656797.656797 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003454446792602539 seconds
DEBUG 01-04 15:36:25.658511.658511 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0060291290283203125 seconds
DEBUG 01-04 15:36:25.658155.658155 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.659026.659026 lmp.py:339] 
DEBUG 01-04 15:36:25.659026.659026 lmp.py:339]   Computing 30 experts on CPU...
DEBUG 01-04 15:36:25.659677.659677 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-04 15:36:25.659234.659234 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.666575.666575 mlpmodule.py:704] group tensors cost 0.0070726871490478516 s
DEBUG 01-04 15:36:25.669774.669774 mlpmodule.py:742] pad cost 0.002402782440185547 s
DEBUG 01-04 15:36:25.669142.669142 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-04 15:36:25.669031.669031 mlpmodule.py:753] move to cpu cost 2.6464462280273438e-05 s
DEBUG 01-04 15:36:25.673418.673418 mlpmodule.py:768] group_w3: shape=torch.Size([30, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=86507520
DEBUG 01-04 15:36:25.673984.673984 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.673947.673947 mlpmodule.py:774] group_w3 first element: -0.0576171875
WARNING 01-04 15:36:25.673136.673136 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.677532.677532 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.677488.677488 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.681791.681791 mlpmodule.py:797] group einsum cost 0.011563539505004883 s
DEBUG 01-04 15:36:25.681507.681507 mlpmodule.py:805] cpy2cputensor cost 7.390975952148438e-05 s
DEBUG 01-04 15:36:25.685218.685218 cuda_h.py:19] end wait_cetm_experts cost 0.026381969451904297 seconds
DEBUG 01-04 15:36:25.685731.685731 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.686403.686403 cuda_h.py:19] end gpu_sexperts cost 0.0004520416259765625 seconds
DEBUG 01-04 15:36:25.686915.686915 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-04 15:36:25.686400.686400 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-04 15:36:25.686965.686965 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.2901763916015625e-05 seconds
DEBUG 01-04 15:36:25.686822.686822 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.686850.686850 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 0.0001583099365234375 seconds
DEBUG 01-04 15:36:25.686801.686801 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.686551.686551 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.686590.686590 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 53aadd6f-48eb-4822-b481-423576e57445
DEBUG 01-04 15:36:25.686356.686356 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.691910.691910 cuda_h.py:19] end allocate_cuda_memory cost 0.004221677780151367 seconds
DEBUG 01-04 15:36:25.691972.691972 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.691642.691642 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.691949.691949 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.691182.691182 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be276abb-16c2-4ffa-84b6-dfaa5512f09c
DEBUG 01-04 15:36:25.691317.691317 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.701260.701260 mlpmodule.py:662]  experts func einsum cost 0.04196977615356445 s
INFO 01-04 15:36:25.705027.705027 client.py:127] Model loaded
DEBUG 01-04 15:36:25.706171.706171 cuda_h.py:19] end wait_experts cost 0.01930999755859375 seconds
DEBUG 01-04 15:36:25.706180.706180 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.706235.706235 lmp.py:384]   Computing 30 experts on GPU...
INFO 01-04 15:36:25.706056.706056 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be276abb-16c2-4ffa-84b6-dfaa5512f09c
DEBUG 01-04 15:36:25.706329.706329 cuda_h.py:19] end load_into_gpu_async cost 0.015569925308227539 seconds
DEBUG 01-04 15:36:25.706555.706555 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.706539.706539 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-04 15:36:25.706387.706387 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.020356178283691406 seconds
DEBUG 01-04 15:36:25.707798.707798 mlpmodule.py:531] gpu group tensors cost 0.0008707046508789062 s
INFO 01-04 15:36:25.707766.707766 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be276abb-16c2-4ffa-84b6-dfaa5512f09c
DEBUG 01-04 15:36:25.708495.708495 mlpmodule.py:564] gpu pad cost 0.0015785694122314453 s
DEBUG 01-04 15:36:25.709158.709158 mlpmodule.py:582] gpu group einsum cost 0.0003592967987060547 s
DEBUG 01-04 15:36:25.711840.711840 mlpmodule.py:611] gpu experts func einsum cost 0.005677700042724609 s
DEBUG 01-04 15:36:25.712346.712346 cuda_h.py:19] end gpu_experts cost 0.005887746810913086 seconds
DEBUG 01-04 15:36:25.712963.712963 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.717680.717680 client.py:127] Model loaded
DEBUG 01-04 15:36:25.717059.717059 cuda_h.py:19] end sllm_worker_task cost 0.030677318572998047 seconds
DEBUG 01-04 15:36:25.717194.717194 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005090475082397461 seconds
DEBUG 01-04 15:36:25.717696.717696 cuda_h.py:19] end layer_moe_generate_19 cost 0.06674671173095703 seconds
DEBUG 01-04 15:36:25.717054.717054 lmp.py:207] -------------------------------- end layer 19 --------------------------------
DEBUG 01-04 15:36:25.717724.717724 lmp.py:169] -------------------------------- start layer 20 --------------------------------
DEBUG 01-04 15:36:25.717612.717612 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.717337.717337 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.720857.720857 cuda_h.py:19] end self_attn cost 0.002604961395263672 seconds
DEBUG 01-04 15:36:25.720780.720780 cuda_h.py:19] end iln_self_attn_paln cost 0.003218412399291992 seconds
DEBUG 01-04 15:36:25.720285.720285 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-04 15:36:25.720810.720810 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.721453.721453 cuda_h.py:19] end gate cost 0.0005815029144287109 seconds
DEBUG 01-04 15:36:25.721375.721375 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.721119.721119 lmp.py:281] 
DEBUG 01-04 15:36:25.721119.721119 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.721683.721683 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:25.721664.721664 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:25.721784.721784 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:25.722235.722235 lmp.py:285] 
DEBUG 01-04 15:36:25.722235.722235 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.722924.722924 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.722335.722335 lmp.py:292]   Expert 14 |      1 | CPU
DEBUG 01-04 15:36:25.722263.722263 lmp.py:292]   Expert 28 |      1 | CPU
DEBUG 01-04 15:36:25.722443.722443 lmp.py:292]   Expert 51 |      1 | CPU
DEBUG 01-04 15:36:25.722655.722655 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:25.722391.722391 lmp.py:292]   Expert 29 |      2 | CPU
DEBUG 01-04 15:36:25.722650.722650 lmp.py:292]   Expert 38 |      2 | CPU
DEBUG 01-04 15:36:25.722908.722908 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:25.722690.722690 lmp.py:292]   Expert 19 |      3 | CPU
DEBUG 01-04 15:36:25.722472.722472 lmp.py:292]   Expert 20 |      3 | CPU
DEBUG 01-04 15:36:25.722493.722493 lmp.py:292]   Expert 36 |      3 | CPU
DEBUG 01-04 15:36:25.722036.722036 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:25.722295.722295 lmp.py:292]   Expert 46 |      3 | CPU
DEBUG 01-04 15:36:25.722554.722554 lmp.py:292]   Expert 49 |      3 | CPU
DEBUG 01-04 15:36:25.722336.722336 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:25.722118.722118 lmp.py:292]   Expert  9 |      4 | CPU
DEBUG 01-04 15:36:25.722900.722900 lmp.py:292]   Expert 10 |      4 | CPU
DEBUG 01-04 15:36:25.722920.722920 lmp.py:292]   Expert 33 |      4 | CPU
DEBUG 01-04 15:36:25.722463.722463 lmp.py:292]   Expert 39 |      4 | CPU
DEBUG 01-04 15:36:25.722484.722484 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:25.722266.722266 lmp.py:292]   Expert 53 |      4 | CPU
DEBUG 01-04 15:36:25.722286.722286 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:25.722022.722022 lmp.py:292]   Expert 63 |      4 | CPU
DEBUG 01-04 15:36:25.722757.722757 lmp.py:292]   Expert  6 |      5 | CPU
DEBUG 01-04 15:36:25.722016.722016 lmp.py:292]   Expert 11 |      5 | CPU
DEBUG 01-04 15:36:25.722990.722990 lmp.py:292]   Expert 15 |      5 | CPU
DEBUG 01-04 15:36:25.722011.722011 lmp.py:292]   Expert 44 |      5 | CPU
DEBUG 01-04 15:36:25.722793.722793 lmp.py:292]   Expert 23 |      6 | CPU
DEBUG 01-04 15:36:25.722813.722813 lmp.py:292]   Expert 30 |      6 | CPU
DEBUG 01-04 15:36:25.722356.722356 lmp.py:292]   Expert 59 |      6 | CPU
DEBUG 01-04 15:36:25.722138.722138 lmp.py:292]   Expert  7 |      7 | GPU
DEBUG 01-04 15:36:25.722920.722920 lmp.py:292]   Expert 17 |      7 | GPU
DEBUG 01-04 15:36:25.722702.722702 lmp.py:292]   Expert 50 |      7 | GPU
DEBUG 01-04 15:36:25.722246.722246 lmp.py:292]   Expert 55 |      7 | GPU
DEBUG 01-04 15:36:25.722028.722028 lmp.py:292]   Expert 61 |      7 | GPU
DEBUG 01-04 15:36:25.722287.722287 lmp.py:292]   Expert 16 |      8 | GPU
DEBUG 01-04 15:36:25.722069.722069 lmp.py:292]   Expert 26 |      8 | GPU
DEBUG 01-04 15:36:25.722851.722851 lmp.py:292]   Expert 27 |      8 | GPU
DEBUG 01-04 15:36:25.722586.722586 lmp.py:292]   Expert 32 |      8 | GPU
DEBUG 01-04 15:36:25.722322.722322 lmp.py:292]   Expert 34 |      8 | GPU
DEBUG 01-04 15:36:25.722057.722057 lmp.py:292]   Expert 37 |      8 | GPU
DEBUG 01-04 15:36:25.722793.722793 lmp.py:292]   Expert 21 |     10 | GPU
DEBUG 01-04 15:36:25.722813.722813 lmp.py:292]   Expert 22 |     10 | GPU
DEBUG 01-04 15:36:25.722357.722357 lmp.py:292]   Expert 40 |     10 | GPU
DEBUG 01-04 15:36:25.722139.722139 lmp.py:292]   Expert 47 |     10 | GPU
DEBUG 01-04 15:36:25.722682.722682 lmp.py:292]   Expert 41 |     11 | GPU
DEBUG 01-04 15:36:25.722226.722226 lmp.py:292]   Expert 48 |     11 | GPU
DEBUG 01-04 15:36:25.722485.722485 lmp.py:292]   Expert 56 |     11 | GPU
DEBUG 01-04 15:36:25.722267.722267 lmp.py:292]   Expert 24 |     12 | GPU
DEBUG 01-04 15:36:25.722810.722810 lmp.py:292]   Expert 60 |     12 | GPU
DEBUG 01-04 15:36:25.722831.722831 lmp.py:292]   Expert 31 |     13 | GPU
DEBUG 01-04 15:36:25.722613.722613 lmp.py:292]   Expert 58 |     15 | GPU
DEBUG 01-04 15:36:25.722395.722395 lmp.py:292]   Expert 25 |     20 | GPU
DEBUG 01-04 15:36:25.722938.722938 lmp.py:292]   Expert 35 |     23 | GPU
DEBUG 01-04 15:36:25.722958.722958 lmp.py:292]   Expert  0 |   1984 | GPU
DEBUG 01-04 15:36:25.722740.722740 lmp.py:292]   Expert  1 |   1984 | GPU
DEBUG 01-04 15:36:25.722476.722476 lmp.py:292]   Expert  2 |   1987 | GPU
DEBUG 01-04 15:36:25.722212.722212 lmp.py:292]   Expert  5 |   1988 | GPU
DEBUG 01-04 15:36:25.722947.722947 lmp.py:292]   Expert  3 |   1989 | GPU
DEBUG 01-04 15:36:25.722206.722206 lmp.py:292]   Expert  4 |   2003 | GPU
DEBUG 01-04 15:36:25.722703.722703 lmp.py:293] 
DEBUG 01-04 15:36:25.722703.722703 lmp.py:293]   CPU total tokens: 102 (0.8%)
DEBUG 01-04 15:36:25.722439.722439 lmp.py:294]   GPU total tokens: 12186 (99.2%)
DEBUG 01-04 15:36:25.722751.722751 cuda_h.py:19] end experts_map_get cost 0.0013027191162109375 seconds
DEBUG 01-04 15:36:25.723963.723963 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.723263.723263 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.723578.723578 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.723231.723231 cuda_h.py:19] end allocate_cuda_memory cost 0.000274658203125 seconds
DEBUG 01-04 15:36:25.723789.723789 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.723638.723638 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.723354.723354 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.723766.723766 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a47e8160-fef6-43a0-bf51-bbfa3f9df2d1
DEBUG 01-04 15:36:25.723573.723573 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.725548.725548 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a47e8160-fef6-43a0-bf51-bbfa3f9df2d1
DEBUG 01-04 15:36:25.725000.725000 cuda_h.py:19] end load_into_gpu_async cost 0.0017044544219970703 seconds
DEBUG 01-04 15:36:25.725034.725034 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.725138.725138 cuda_h.py:19] end restore_tensors2 cost 0.00033283233642578125 seconds
DEBUG 01-04 15:36:25.725822.725822 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002639293670654297 seconds
DEBUG 01-04 15:36:25.728410.728410 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005010366439819336 seconds
DEBUG 01-04 15:36:25.728332.728332 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.728527.728527 lmp.py:339] 
DEBUG 01-04 15:36:25.728527.728527 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:25.728317.728317 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-04 15:36:25.728702.728702 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.742615.742615 mlpmodule.py:704] group tensors cost 0.01385354995727539 s
DEBUG 01-04 15:36:25.744254.744254 mlpmodule.py:742] pad cost 0.001287698745727539 s
DEBUG 01-04 15:36:25.744237.744237 mlpmodule.py:748] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-04 15:36:25.744557.744557 mlpmodule.py:753] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-04 15:36:25.748098.748098 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:25.748850.748850 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.748567.748567 mlpmodule.py:774] group_w3 first element: -0.052734375
WARNING 01-04 15:36:25.748365.748365 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.751146.751146 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.751041.751041 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.755775.755775 mlpmodule.py:797] group einsum cost 0.010810375213623047 s
DEBUG 01-04 15:36:25.755035.755035 mlpmodule.py:805] cpy2cputensor cost 9.393692016601562e-05 s
DEBUG 01-04 15:36:25.759061.759061 cuda_h.py:19] end wait_cetm_experts cost 0.03104567527770996 seconds
DEBUG 01-04 15:36:25.759773.759773 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.759896.759896 cuda_h.py:19] end gpu_sexperts cost 0.00046634674072265625 seconds
DEBUG 01-04 15:36:25.760176.760176 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-04 15:36:25.760522.760522 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-04 15:36:25.760472.760472 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.457069396972656e-05 seconds
DEBUG 01-04 15:36:25.760519.760519 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.2479248046875e-05 seconds
DEBUG 01-04 15:36:25.760745.760745 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.760885.760885 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a47e8160-fef6-43a0-bf51-bbfa3f9df2d1
DEBUG 01-04 15:36:25.760395.760395 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.760162.760162 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.760834.760834 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.765416.765416 cuda_h.py:19] end allocate_cuda_memory cost 0.0042650699615478516 seconds
DEBUG 01-04 15:36:25.765902.765902 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.765288.765288 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.765832.765832 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.765257.765257 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81ed9780-e5dd-4dc8-a4c7-33b84b6b3a59
DEBUG 01-04 15:36:25.765916.765916 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.774225.774225 mlpmodule.py:662]  experts func einsum cost 0.04652833938598633 s
INFO 01-04 15:36:25.775715.775715 client.py:127] Model loaded
DEBUG 01-04 15:36:25.775373.775373 cuda_h.py:19] end wait_experts cost 0.015142440795898438 seconds
DEBUG 01-04 15:36:25.775837.775837 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.775348.775348 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:25.776374.776374 mlpmodule.py:531] gpu group tensors cost 0.0005133152008056641 s
INFO 01-04 15:36:25.776445.776445 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81ed9780-e5dd-4dc8-a4c7-33b84b6b3a59
DEBUG 01-04 15:36:25.776447.776447 cuda_h.py:19] end load_into_gpu_async cost 0.011284112930297852 seconds
DEBUG 01-04 15:36:25.776580.776580 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.776140.776140 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-04 15:36:25.776657.776657 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01593327522277832 seconds
INFO 01-04 15:36:25.777543.777543 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81ed9780-e5dd-4dc8-a4c7-33b84b6b3a59
DEBUG 01-04 15:36:25.778996.778996 mlpmodule.py:564] gpu pad cost 0.0021278858184814453 s
DEBUG 01-04 15:36:25.778945.778945 mlpmodule.py:582] gpu group einsum cost 0.0003783702850341797 s
DEBUG 01-04 15:36:25.781668.781668 mlpmodule.py:611] gpu experts func einsum cost 0.005751132965087891 s
DEBUG 01-04 15:36:25.781453.781453 cuda_h.py:19] end gpu_experts cost 0.005907773971557617 seconds
DEBUG 01-04 15:36:25.781447.781447 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.786393.786393 client.py:127] Model loaded
DEBUG 01-04 15:36:25.786726.786726 cuda_h.py:19] end sllm_worker_task cost 0.02616119384765625 seconds
DEBUG 01-04 15:36:25.786305.786305 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005412578582763672 seconds
DEBUG 01-04 15:36:25.786747.786747 cuda_h.py:19] end layer_moe_generate_20 cost 0.06596875190734863 seconds
DEBUG 01-04 15:36:25.787071.787071 lmp.py:207] -------------------------------- end layer 20 --------------------------------
DEBUG 01-04 15:36:25.787456.787456 lmp.py:169] -------------------------------- start layer 21 --------------------------------
DEBUG 01-04 15:36:25.787245.787245 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.787565.787565 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.789575.789575 cuda_h.py:19] end self_attn cost 0.002412557601928711 seconds
DEBUG 01-04 15:36:25.790610.790610 cuda_h.py:19] end iln_self_attn_paln cost 0.0029783248901367188 seconds
DEBUG 01-04 15:36:25.790970.790970 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-04 15:36:25.790587.790587 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.790891.790891 cuda_h.py:19] end gate cost 0.0005433559417724609 seconds
DEBUG 01-04 15:36:25.790906.790906 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.791338.791338 lmp.py:281] 
DEBUG 01-04 15:36:25.791338.791338 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.791471.791471 lmp.py:282]   Total experts: 58
DEBUG 01-04 15:36:25.791452.791452 lmp.py:283]   CPU experts: 29 (50%)
DEBUG 01-04 15:36:25.791095.791095 lmp.py:284]   GPU experts: 29 (50%)
DEBUG 01-04 15:36:25.791307.791307 lmp.py:285] 
DEBUG 01-04 15:36:25.791307.791307 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.791719.791719 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.791938.791938 lmp.py:292]   Expert  6 |      1 | CPU
DEBUG 01-04 15:36:25.791151.791151 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:25.791648.791648 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:25.791668.791668 lmp.py:292]   Expert 49 |      1 | CPU
DEBUG 01-04 15:36:25.791165.791165 lmp.py:292]   Expert 57 |      1 | CPU
DEBUG 01-04 15:36:25.791186.791186 lmp.py:292]   Expert 12 |      2 | CPU
DEBUG 01-04 15:36:25.791444.791444 lmp.py:292]   Expert 13 |      2 | CPU
DEBUG 01-04 15:36:25.791657.791657 lmp.py:292]   Expert 14 |      2 | CPU
DEBUG 01-04 15:36:25.791108.791108 lmp.py:292]   Expert 23 |      2 | CPU
DEBUG 01-04 15:36:25.791320.791320 lmp.py:292]   Expert 26 |      2 | CPU
DEBUG 01-04 15:36:25.791294.791294 lmp.py:292]   Expert  8 |      3 | CPU
DEBUG 01-04 15:36:25.791268.791268 lmp.py:292]   Expert 18 |      3 | CPU
DEBUG 01-04 15:36:25.791978.791978 lmp.py:292]   Expert 32 |      3 | CPU
DEBUG 01-04 15:36:25.791237.791237 lmp.py:292]   Expert 35 |      3 | CPU
DEBUG 01-04 15:36:25.791211.791211 lmp.py:292]   Expert 55 |      3 | CPU
DEBUG 01-04 15:36:25.791470.791470 lmp.py:292]   Expert 56 |      3 | CPU
DEBUG 01-04 15:36:25.791205.791205 lmp.py:292]   Expert 15 |      4 | CPU
DEBUG 01-04 15:36:25.791464.791464 lmp.py:292]   Expert 19 |      4 | CPU
DEBUG 01-04 15:36:25.791961.791961 lmp.py:292]   Expert 28 |      4 | CPU
DEBUG 01-04 15:36:25.791220.791220 lmp.py:292]   Expert 43 |      4 | CPU
DEBUG 01-04 15:36:25.791717.791717 lmp.py:292]   Expert 48 |      4 | CPU
DEBUG 01-04 15:36:25.791930.791930 lmp.py:292]   Expert 50 |      4 | CPU
DEBUG 01-04 15:36:25.791619.791619 lmp.py:292]   Expert 53 |      4 | CPU
DEBUG 01-04 15:36:25.791070.791070 lmp.py:292]   Expert 33 |      5 | CPU
DEBUG 01-04 15:36:25.791759.791759 lmp.py:292]   Expert 40 |      5 | CPU
DEBUG 01-04 15:36:25.791210.791210 lmp.py:292]   Expert 58 |      5 | CPU
DEBUG 01-04 15:36:25.791946.791946 lmp.py:292]   Expert 63 |      5 | CPU
DEBUG 01-04 15:36:25.791205.791205 lmp.py:292]   Expert  7 |      6 | CPU
DEBUG 01-04 15:36:25.791702.791702 lmp.py:292]   Expert 16 |      6 | CPU
DEBUG 01-04 15:36:25.791199.791199 lmp.py:292]   Expert 24 |      6 | GPU
DEBUG 01-04 15:36:25.791935.791935 lmp.py:292]   Expert 29 |      6 | GPU
DEBUG 01-04 15:36:25.791193.791193 lmp.py:292]   Expert 52 |      6 | GPU
DEBUG 01-04 15:36:25.791452.791452 lmp.py:292]   Expert 59 |      6 | GPU
DEBUG 01-04 15:36:25.791711.791711 lmp.py:292]   Expert 10 |      7 | GPU
DEBUG 01-04 15:36:25.791731.791731 lmp.py:292]   Expert 17 |      7 | GPU
DEBUG 01-04 15:36:25.791229.791229 lmp.py:292]   Expert 27 |      7 | GPU
DEBUG 01-04 15:36:25.791726.791726 lmp.py:292]   Expert 38 |      7 | GPU
DEBUG 01-04 15:36:25.791415.791415 lmp.py:292]   Expert 41 |      7 | GPU
DEBUG 01-04 15:36:25.791866.791866 lmp.py:292]   Expert 62 |      7 | GPU
DEBUG 01-04 15:36:25.791363.791363 lmp.py:292]   Expert 22 |      8 | GPU
DEBUG 01-04 15:36:25.791576.791576 lmp.py:292]   Expert 31 |      8 | GPU
DEBUG 01-04 15:36:25.791788.791788 lmp.py:292]   Expert 39 |      9 | GPU
DEBUG 01-04 15:36:25.791524.791524 lmp.py:292]   Expert 11 |     10 | GPU
DEBUG 01-04 15:36:25.791544.791544 lmp.py:292]   Expert 21 |     10 | GPU
DEBUG 01-04 15:36:25.791803.791803 lmp.py:292]   Expert 37 |     11 | GPU
DEBUG 01-04 15:36:25.792823.792823 lmp.py:292]   Expert 30 |     14 | GPU
DEBUG 01-04 15:36:25.792082.792082 lmp.py:292]   Expert 36 |     14 | GPU
DEBUG 01-04 15:36:25.792102.792102 lmp.py:292]   Expert 61 |     15 | GPU
DEBUG 01-04 15:36:25.792361.792361 lmp.py:292]   Expert 45 |     17 | GPU
DEBUG 01-04 15:36:25.792620.792620 lmp.py:292]   Expert 46 |     22 | GPU
DEBUG 01-04 15:36:25.792640.792640 lmp.py:292]   Expert 47 |     24 | GPU
DEBUG 01-04 15:36:25.792661.792661 lmp.py:292]   Expert 42 |     26 | GPU
DEBUG 01-04 15:36:25.792158.792158 lmp.py:292]   Expert  1 |   1984 | GPU
DEBUG 01-04 15:36:25.792178.792178 lmp.py:292]   Expert  3 |   1986 | GPU
DEBUG 01-04 15:36:25.792675.792675 lmp.py:292]   Expert  2 |   1991 | GPU
DEBUG 01-04 15:36:25.792649.792649 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:25.792862.792862 lmp.py:292]   Expert  4 |   1993 | GPU
DEBUG 01-04 15:36:25.792313.792313 lmp.py:292]   Expert  0 |   1995 | GPU
DEBUG 01-04 15:36:25.792002.792002 lmp.py:293] 
DEBUG 01-04 15:36:25.792002.792002 lmp.py:293]   CPU total tokens: 93 (0.8%)
DEBUG 01-04 15:36:25.792691.792691 lmp.py:294]   GPU total tokens: 12195 (99.2%)
DEBUG 01-04 15:36:25.792719.792719 cuda_h.py:19] end experts_map_get cost 0.001310110092163086 seconds
DEBUG 01-04 15:36:25.792408.792408 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.792754.792754 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.792957.792957 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.792742.792742 cuda_h.py:19] end allocate_cuda_memory cost 0.00026345252990722656 seconds
DEBUG 01-04 15:36:25.792208.792208 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.792295.792295 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.792965.792965 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.792615.792615 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4224446e-b31a-4de3-851e-5af8a1b25aa4
DEBUG 01-04 15:36:25.793806.793806 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.794492.794492 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4224446e-b31a-4de3-851e-5af8a1b25aa4
DEBUG 01-04 15:36:25.795860.795860 cuda_h.py:19] end load_into_gpu_async cost 0.002226591110229492 seconds
DEBUG 01-04 15:36:25.795008.795008 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.795652.795652 cuda_h.py:19] end restore_tensors2 cost 0.00037670135498046875 seconds
DEBUG 01-04 15:36:25.795806.795806 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033185482025146484 seconds
DEBUG 01-04 15:36:25.797255.797255 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005690574645996094 seconds
DEBUG 01-04 15:36:25.798654.798654 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.798848.798848 lmp.py:339] 
DEBUG 01-04 15:36:25.798848.798848 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:25.798446.798446 cuda_h.py:19] end cpu_experts_submit cost 0.00010132789611816406 seconds
DEBUG 01-04 15:36:25.798070.798070 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.803662.803662 mlpmodule.py:704] group tensors cost 0.00567626953125 s
DEBUG 01-04 15:36:25.806032.806032 mlpmodule.py:742] pad cost 0.002234935760498047 s
DEBUG 01-04 15:36:25.807037.807037 mlpmodule.py:748] create cpu tensor cost 5.7697296142578125e-05 s
DEBUG 01-04 15:36:25.807219.807219 mlpmodule.py:753] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-04 15:36:25.811427.811427 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:25.811497.811497 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.811434.811434 mlpmodule.py:774] group_w3 first element: 0.072265625
WARNING 01-04 15:36:25.811988.811988 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.814984.814984 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.815269.815269 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.818380.818380 mlpmodule.py:797] group einsum cost 0.011066913604736328 s
DEBUG 01-04 15:36:25.818090.818090 mlpmodule.py:805] cpy2cputensor cost 0.00010085105895996094 s
DEBUG 01-04 15:36:25.822488.822488 cuda_h.py:19] end wait_cetm_experts cost 0.024314165115356445 seconds
DEBUG 01-04 15:36:25.822909.822909 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.823336.823336 cuda_h.py:19] end gpu_sexperts cost 0.0004470348358154297 seconds
DEBUG 01-04 15:36:25.823848.823848 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-04 15:36:25.823571.823571 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-04 15:36:25.823428.823428 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.3855438232421875e-05 seconds
DEBUG 01-04 15:36:25.823052.823052 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.963180541992188e-05 seconds
DEBUG 01-04 15:36:25.823324.823324 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.823987.823987 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4224446e-b31a-4de3-851e-5af8a1b25aa4
DEBUG 01-04 15:36:25.823794.823794 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.823235.823235 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.823330.823330 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.827522.827522 cuda_h.py:19] end allocate_cuda_memory cost 0.004096269607543945 seconds
DEBUG 01-04 15:36:25.828287.828287 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.828349.828349 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.828569.828569 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.828762.828762 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fde6e012-69c4-4cf3-a50d-0e0af31c8064
DEBUG 01-04 15:36:25.828726.828726 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.837876.837876 mlpmodule.py:662]  experts func einsum cost 0.038999080657958984 s
INFO 01-04 15:36:25.843013.843013 client.py:127] Model loaded
DEBUG 01-04 15:36:25.843839.843839 cuda_h.py:19] end wait_experts cost 0.020265817642211914 seconds
DEBUG 01-04 15:36:25.843325.843325 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.843526.843526 lmp.py:384]   Computing 29 experts on GPU...
INFO 01-04 15:36:25.844782.844782 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fde6e012-69c4-4cf3-a50d-0e0af31c8064
DEBUG 01-04 15:36:25.845400.845400 cuda_h.py:19] end load_into_gpu_async cost 0.01696324348449707 seconds
DEBUG 01-04 15:36:25.845580.845580 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.845106.845106 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-04 15:36:25.845790.845790 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.021472930908203125 seconds
INFO 01-04 15:36:25.845687.845687 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fde6e012-69c4-4cf3-a50d-0e0af31c8064
DEBUG 01-04 15:36:25.845132.845132 mlpmodule.py:531] gpu group tensors cost 0.0019066333770751953 s
DEBUG 01-04 15:36:25.849821.849821 mlpmodule.py:564] gpu pad cost 0.00384521484375 s
DEBUG 01-04 15:36:25.851835.851835 mlpmodule.py:582] gpu group einsum cost 0.0010259151458740234 s
INFO 01-04 15:36:25.852981.852981 client.py:127] Model loaded
DEBUG 01-04 15:36:25.852116.852116 cuda_h.py:19] end sllm_worker_task cost 0.029059171676635742 seconds
DEBUG 01-04 15:36:25.855681.855681 mlpmodule.py:611] gpu experts func einsum cost 0.011979103088378906 s
DEBUG 01-04 15:36:25.856354.856354 cuda_h.py:19] end gpu_experts cost 0.012278079986572266 seconds
DEBUG 01-04 15:36:25.856422.856422 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:25.856100.856100 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-04 15:36:25.857751.857751 cuda_h.py:19] end layer_moe_generate_21 cost 0.06760501861572266 seconds
DEBUG 01-04 15:36:25.858640.858640 lmp.py:207] -------------------------------- end layer 21 --------------------------------
DEBUG 01-04 15:36:25.858913.858913 lmp.py:169] -------------------------------- start layer 22 --------------------------------
DEBUG 01-04 15:36:25.858246.858246 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.858775.858775 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.861067.861067 cuda_h.py:19] end self_attn cost 0.003292560577392578 seconds
DEBUG 01-04 15:36:25.862413.862413 cuda_h.py:19] end iln_self_attn_paln cost 0.0041501522064208984 seconds
DEBUG 01-04 15:36:25.862667.862667 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-04 15:36:25.862219.862219 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.863308.863308 cuda_h.py:19] end gate cost 0.0006513595581054688 seconds
DEBUG 01-04 15:36:25.863946.863946 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.863458.863458 lmp.py:281] 
DEBUG 01-04 15:36:25.863458.863458 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.863115.863115 lmp.py:282]   Total experts: 58
DEBUG 01-04 15:36:25.863334.863334 lmp.py:283]   CPU experts: 29 (50%)
DEBUG 01-04 15:36:25.863169.863169 lmp.py:284]   GPU experts: 29 (50%)
DEBUG 01-04 15:36:25.863858.863858 lmp.py:285] 
DEBUG 01-04 15:36:25.863858.863858 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.863309.863309 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.863482.863482 lmp.py:292]   Expert 12 |      1 | CPU
DEBUG 01-04 15:36:25.863456.863456 lmp.py:292]   Expert 24 |      1 | CPU
DEBUG 01-04 15:36:25.863715.863715 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:25.863735.863735 lmp.py:292]   Expert 32 |      1 | CPU
DEBUG 01-04 15:36:25.863517.863517 lmp.py:292]   Expert 45 |      1 | CPU
DEBUG 01-04 15:36:25.863538.863538 lmp.py:292]   Expert  7 |      2 | CPU
DEBUG 01-04 15:36:25.863319.863319 lmp.py:292]   Expert  9 |      2 | CPU
DEBUG 01-04 15:36:25.863101.863101 lmp.py:292]   Expert 19 |      2 | CPU
DEBUG 01-04 15:36:25.863075.863075 lmp.py:292]   Expert 22 |      2 | CPU
DEBUG 01-04 15:36:25.863526.863526 lmp.py:292]   Expert 28 |      2 | CPU
DEBUG 01-04 15:36:25.863262.863262 lmp.py:292]   Expert 31 |      2 | CPU
DEBUG 01-04 15:36:25.863759.863759 lmp.py:292]   Expert 61 |      2 | CPU
DEBUG 01-04 15:36:25.863256.863256 lmp.py:292]   Expert 10 |      3 | CPU
DEBUG 01-04 15:36:25.863515.863515 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:25.863297.863297 lmp.py:292]   Expert 39 |      3 | CPU
DEBUG 01-04 15:36:25.863079.863079 lmp.py:292]   Expert 43 |      3 | CPU
DEBUG 01-04 15:36:25.863099.863099 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:25.863120.863120 lmp.py:292]   Expert 49 |      3 | CPU
DEBUG 01-04 15:36:25.863902.863902 lmp.py:292]   Expert 50 |      3 | CPU
DEBUG 01-04 15:36:25.863684.863684 lmp.py:292]   Expert 52 |      3 | CPU
DEBUG 01-04 15:36:25.864466.864466 lmp.py:292]   Expert 60 |      3 | CPU
DEBUG 01-04 15:36:25.864109.864109 lmp.py:292]   Expert 62 |      3 | CPU
DEBUG 01-04 15:36:25.864321.864321 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:25.864534.864534 lmp.py:292]   Expert 41 |      4 | CPU
DEBUG 01-04 15:36:25.864269.864269 lmp.py:292]   Expert 47 |      4 | CPU
DEBUG 01-04 15:36:25.864528.864528 lmp.py:292]   Expert 58 |      4 | CPU
DEBUG 01-04 15:36:25.864264.864264 lmp.py:292]   Expert 63 |      4 | CPU
DEBUG 01-04 15:36:25.864238.864238 lmp.py:292]   Expert 15 |      5 | CPU
DEBUG 01-04 15:36:25.864212.864212 lmp.py:292]   Expert 37 |      5 | CPU
DEBUG 01-04 15:36:25.864186.864186 lmp.py:292]   Expert 48 |      5 | GPU
DEBUG 01-04 15:36:25.864160.864160 lmp.py:292]   Expert  8 |      6 | GPU
DEBUG 01-04 15:36:25.864657.864657 lmp.py:292]   Expert 35 |      6 | GPU
DEBUG 01-04 15:36:25.864393.864393 lmp.py:292]   Expert 51 |      6 | GPU
DEBUG 01-04 15:36:25.864890.864890 lmp.py:292]   Expert 54 |      6 | GPU
DEBUG 01-04 15:36:25.864625.864625 lmp.py:292]   Expert 13 |      7 | GPU
DEBUG 01-04 15:36:25.864361.864361 lmp.py:292]   Expert 16 |      7 | GPU
DEBUG 01-04 15:36:25.864097.864097 lmp.py:292]   Expert 23 |      8 | GPU
DEBUG 01-04 15:36:25.864832.864832 lmp.py:292]   Expert 38 |      8 | GPU
DEBUG 01-04 15:36:25.864568.864568 lmp.py:292]   Expert 56 |      8 | GPU
DEBUG 01-04 15:36:25.864542.864542 lmp.py:292]   Expert 21 |      9 | GPU
DEBUG 01-04 15:36:25.864801.864801 lmp.py:292]   Expert 53 |      9 | GPU
DEBUG 01-04 15:36:25.864344.864344 lmp.py:292]   Expert 33 |     10 | GPU
DEBUG 01-04 15:36:25.864126.864126 lmp.py:292]   Expert 14 |     11 | GPU
DEBUG 01-04 15:36:25.864147.864147 lmp.py:292]   Expert 34 |     12 | GPU
DEBUG 01-04 15:36:25.864690.864690 lmp.py:292]   Expert 59 |     13 | GPU
DEBUG 01-04 15:36:25.864770.864770 lmp.py:292]   Expert 20 |     14 | GPU
DEBUG 01-04 15:36:25.864242.864242 lmp.py:292]   Expert 29 |     14 | GPU
DEBUG 01-04 15:36:25.864461.864461 lmp.py:292]   Expert 55 |     14 | GPU
DEBUG 01-04 15:36:25.864389.864389 lmp.py:292]   Expert 17 |     16 | GPU
DEBUG 01-04 15:36:25.864316.864316 lmp.py:292]   Expert 18 |     16 | GPU
DEBUG 01-04 15:36:25.864006.864006 lmp.py:292]   Expert 40 |     18 | GPU
DEBUG 01-04 15:36:25.864218.864218 lmp.py:292]   Expert 36 |     48 | GPU
DEBUG 01-04 15:36:25.864431.864431 lmp.py:292]   Expert  0 |   1984 | GPU
DEBUG 01-04 15:36:25.864166.864166 lmp.py:292]   Expert  1 |   1986 | GPU
DEBUG 01-04 15:36:25.864902.864902 lmp.py:292]   Expert  3 |   1987 | GPU
DEBUG 01-04 15:36:25.864638.864638 lmp.py:292]   Expert  4 |   1991 | GPU
DEBUG 01-04 15:36:25.864612.864612 lmp.py:292]   Expert  2 |   1992 | GPU
DEBUG 01-04 15:36:25.864109.864109 lmp.py:292]   Expert  5 |   1998 | GPU
DEBUG 01-04 15:36:25.864560.864560 lmp.py:293] 
DEBUG 01-04 15:36:25.864560.864560 lmp.py:293]   CPU total tokens: 79 (0.6%)
DEBUG 01-04 15:36:25.864249.864249 lmp.py:294]   GPU total tokens: 12209 (99.4%)
DEBUG 01-04 15:36:25.864468.864468 cuda_h.py:19] end experts_map_get cost 0.0013401508331298828 seconds
DEBUG 01-04 15:36:25.864396.864396 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.864126.864126 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.864879.864879 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.865698.865698 cuda_h.py:19] end allocate_cuda_memory cost 0.0002899169921875 seconds
DEBUG 01-04 15:36:25.865402.865402 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.865681.865681 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.865020.865020 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.865862.865862 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba9cb018-72ad-4b5e-944e-824da4ef7ff8
DEBUG 01-04 15:36:25.865206.865206 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.867285.867285 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba9cb018-72ad-4b5e-944e-824da4ef7ff8
DEBUG 01-04 15:36:25.867068.867068 cuda_h.py:19] end load_into_gpu_async cost 0.0020759105682373047 seconds
DEBUG 01-04 15:36:25.867817.867817 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.867689.867689 cuda_h.py:19] end restore_tensors2 cost 0.000301361083984375 seconds
DEBUG 01-04 15:36:25.867558.867558 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029997825622558594 seconds
DEBUG 01-04 15:36:25.870173.870173 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005393028259277344 seconds
DEBUG 01-04 15:36:25.870334.870334 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.870959.870959 lmp.py:339] 
DEBUG 01-04 15:36:25.870959.870959 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:25.870795.870795 cuda_h.py:19] end cpu_experts_submit cost 0.00010275840759277344 seconds
DEBUG 01-04 15:36:25.870657.870657 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.878451.878451 mlpmodule.py:704] group tensors cost 0.008109807968139648 s
DEBUG 01-04 15:36:25.882815.882815 mlpmodule.py:742] pad cost 0.0030710697174072266 s
DEBUG 01-04 15:36:25.882451.882451 mlpmodule.py:748] create cpu tensor cost 7.557868957519531e-05 s
DEBUG 01-04 15:36:25.882627.882627 mlpmodule.py:753] move to cpu cost 5.221366882324219e-05 s
DEBUG 01-04 15:36:25.886126.886126 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:25.886222.886222 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.887960.887960 mlpmodule.py:774] group_w3 first element: 0.01336669921875
WARNING 01-04 15:36:25.887865.887865 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.890077.890077 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.890754.890754 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.894172.894172 mlpmodule.py:797] group einsum cost 0.011228561401367188 s
DEBUG 01-04 15:36:25.894100.894100 mlpmodule.py:805] cpy2cputensor cost 7.653236389160156e-05 s
DEBUG 01-04 15:36:25.898869.898869 cuda_h.py:19] end wait_cetm_experts cost 0.02799224853515625 seconds
DEBUG 01-04 15:36:25.898720.898720 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.898385.898385 cuda_h.py:19] end gpu_sexperts cost 0.00044727325439453125 seconds
DEBUG 01-04 15:36:25.899758.899758 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-04 15:36:25.899720.899720 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-04 15:36:25.899524.899524 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.337860107421875e-05 seconds
DEBUG 01-04 15:36:25.899810.899810 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.200241088867188e-05 seconds
DEBUG 01-04 15:36:25.899128.899128 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.899076.899076 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba9cb018-72ad-4b5e-944e-824da4ef7ff8
DEBUG 01-04 15:36:25.899022.899022 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.899774.899774 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.899293.899293 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.903856.903856 cuda_h.py:19] end allocate_cuda_memory cost 0.004128932952880859 seconds
DEBUG 01-04 15:36:25.903913.903913 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.903060.903060 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.903174.903174 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.903692.903692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81b0d897-0137-48cc-b0c9-effea2f3dbc5
DEBUG 01-04 15:36:25.904020.904020 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:25.913522.913522 mlpmodule.py:662]  experts func einsum cost 0.04270601272583008 s
INFO 01-04 15:36:25.915050.915050 client.py:127] Model loaded
DEBUG 01-04 15:36:25.915456.915456 cuda_h.py:19] end wait_experts cost 0.01667928695678711 seconds
DEBUG 01-04 15:36:25.915464.915464 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.915975.915975 lmp.py:384]   Computing 29 experts on GPU...
DEBUG 01-04 15:36:25.916173.916173 mlpmodule.py:531] gpu group tensors cost 0.0004930496215820312 s
INFO 01-04 15:36:25.916580.916580 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81b0d897-0137-48cc-b0c9-effea2f3dbc5
DEBUG 01-04 15:36:25.916992.916992 cuda_h.py:19] end load_into_gpu_async cost 0.013013124465942383 seconds
DEBUG 01-04 15:36:25.916980.916980 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.917294.917294 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-04 15:36:25.917574.917574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01751112937927246 seconds
INFO 01-04 15:36:25.917678.917678 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81b0d897-0137-48cc-b0c9-effea2f3dbc5
DEBUG 01-04 15:36:25.918308.918308 mlpmodule.py:564] gpu pad cost 0.0020127296447753906 s
DEBUG 01-04 15:36:25.919246.919246 mlpmodule.py:582] gpu group einsum cost 0.0004527568817138672 s
DEBUG 01-04 15:36:25.921896.921896 mlpmodule.py:611] gpu experts func einsum cost 0.005696296691894531 s
DEBUG 01-04 15:36:25.921430.921430 cuda_h.py:19] end gpu_experts cost 0.00588536262512207 seconds
DEBUG 01-04 15:36:25.921471.921471 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.927781.927781 client.py:127] Model loaded
DEBUG 01-04 15:36:25.927399.927399 cuda_h.py:19] end sllm_worker_task cost 0.027570724487304688 seconds
DEBUG 01-04 15:36:25.927832.927832 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005223751068115234 seconds
DEBUG 01-04 15:36:25.927936.927936 cuda_h.py:19] end layer_moe_generate_22 cost 0.06475973129272461 seconds
DEBUG 01-04 15:36:25.927505.927505 lmp.py:207] -------------------------------- end layer 22 --------------------------------
DEBUG 01-04 15:36:25.927168.927168 lmp.py:169] -------------------------------- start layer 23 --------------------------------
DEBUG 01-04 15:36:25.927719.927719 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.927509.927509 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.930704.930704 cuda_h.py:19] end self_attn cost 0.002407550811767578 seconds
DEBUG 01-04 15:36:25.930608.930608 cuda_h.py:19] end iln_self_attn_paln cost 0.002979278564453125 seconds
DEBUG 01-04 15:36:25.930490.930490 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-04 15:36:25.930107.930107 cuda_h.py:10] start gate
DEBUG 01-04 15:36:25.931656.931656 cuda_h.py:19] end gate cost 0.0005483627319335938 seconds
DEBUG 01-04 15:36:25.931863.931863 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:25.931263.931263 lmp.py:281] 
DEBUG 01-04 15:36:25.931263.931263 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:25.931158.931158 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:25.931900.931900 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:25.931305.931305 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:25.931994.931994 lmp.py:285] 
DEBUG 01-04 15:36:25.931994.931994 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:25.931922.931922 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:25.931571.931571 lmp.py:292]   Expert 19 |      1 | CPU
DEBUG 01-04 15:36:25.931261.931261 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:25.931996.931996 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:25.931255.931255 lmp.py:292]   Expert 44 |      1 | CPU
DEBUG 01-04 15:36:25.931752.931752 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:25.931011.931011 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:25.931270.931270 lmp.py:292]   Expert 55 |      2 | CPU
DEBUG 01-04 15:36:25.931290.931290 lmp.py:292]   Expert 63 |      2 | CPU
DEBUG 01-04 15:36:25.931549.931549 lmp.py:292]   Expert  6 |      3 | CPU
DEBUG 01-04 15:36:25.931569.931569 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:25.931351.931351 lmp.py:292]   Expert 25 |      3 | CPU
DEBUG 01-04 15:36:25.931133.931133 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:25.931631.931631 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:25.931412.931412 lmp.py:292]   Expert 47 |      3 | CPU
DEBUG 01-04 15:36:25.931194.931194 lmp.py:292]   Expert 58 |      3 | CPU
DEBUG 01-04 15:36:25.931453.931453 lmp.py:292]   Expert 13 |      4 | CPU
DEBUG 01-04 15:36:25.931288.931288 lmp.py:292]   Expert 35 |      4 | CPU
DEBUG 01-04 15:36:25.931262.931262 lmp.py:292]   Expert 36 |      4 | CPU
DEBUG 01-04 15:36:25.931403.931403 lmp.py:292]   Expert 43 |      4 | CPU
DEBUG 01-04 15:36:25.931377.931377 lmp.py:292]   Expert 52 |      4 | CPU
DEBUG 01-04 15:36:25.931874.931874 lmp.py:292]   Expert 56 |      4 | CPU
DEBUG 01-04 15:36:25.931609.931609 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:25.931868.931868 lmp.py:292]   Expert 21 |      5 | CPU
DEBUG 01-04 15:36:25.932842.932842 lmp.py:292]   Expert 17 |      6 | CPU
DEBUG 01-04 15:36:25.932101.932101 lmp.py:292]   Expert 32 |      6 | CPU
DEBUG 01-04 15:36:25.932837.932837 lmp.py:292]   Expert 33 |      6 | CPU
DEBUG 01-04 15:36:25.932334.932334 lmp.py:292]   Expert 22 |      7 | CPU
DEBUG 01-04 15:36:25.932069.932069 lmp.py:292]   Expert 23 |      7 | CPU
DEBUG 01-04 15:36:25.932805.932805 lmp.py:292]   Expert 53 |      7 | CPU
DEBUG 01-04 15:36:25.932494.932494 lmp.py:292]   Expert  9 |      8 | GPU
DEBUG 01-04 15:36:25.932945.932945 lmp.py:292]   Expert 11 |      8 | GPU
DEBUG 01-04 15:36:25.932158.932158 lmp.py:292]   Expert 30 |      8 | GPU
DEBUG 01-04 15:36:25.932370.932370 lmp.py:292]   Expert 42 |      8 | GPU
DEBUG 01-04 15:36:25.932444.932444 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:25.932564.932564 lmp.py:292]   Expert 57 |      8 | GPU
DEBUG 01-04 15:36:25.932061.932061 lmp.py:292]   Expert 61 |      8 | GPU
DEBUG 01-04 15:36:25.932796.932796 lmp.py:292]   Expert 18 |      9 | GPU
DEBUG 01-04 15:36:25.932294.932294 lmp.py:292]   Expert 41 |      9 | GPU
DEBUG 01-04 15:36:25.932791.932791 lmp.py:292]   Expert 50 |      9 | GPU
DEBUG 01-04 15:36:25.932050.932050 lmp.py:292]   Expert 59 |     10 | GPU
DEBUG 01-04 15:36:25.932785.932785 lmp.py:292]   Expert  8 |     11 | GPU
DEBUG 01-04 15:36:25.932044.932044 lmp.py:292]   Expert 10 |     11 | GPU
DEBUG 01-04 15:36:25.932256.932256 lmp.py:292]   Expert 37 |     11 | GPU
DEBUG 01-04 15:36:25.932230.932230 lmp.py:292]   Expert 46 |     11 | GPU
DEBUG 01-04 15:36:25.932443.932443 lmp.py:292]   Expert 12 |     12 | GPU
DEBUG 01-04 15:36:25.932655.932655 lmp.py:292]   Expert 20 |     12 | GPU
DEBUG 01-04 15:36:25.932305.932305 lmp.py:292]   Expert 48 |     12 | GPU
DEBUG 01-04 15:36:25.932253.932253 lmp.py:292]   Expert 14 |     13 | GPU
DEBUG 01-04 15:36:25.932419.932419 lmp.py:292]   Expert 29 |     13 | GPU
DEBUG 01-04 15:36:25.932632.932632 lmp.py:292]   Expert 31 |     13 | GPU
DEBUG 01-04 15:36:25.932844.932844 lmp.py:292]   Expert 39 |     13 | GPU
DEBUG 01-04 15:36:25.932580.932580 lmp.py:292]   Expert 54 |     14 | GPU
DEBUG 01-04 15:36:25.932316.932316 lmp.py:292]   Expert 62 |     18 | GPU
DEBUG 01-04 15:36:25.932051.932051 lmp.py:292]   Expert  5 |   1984 | GPU
DEBUG 01-04 15:36:25.932264.932264 lmp.py:292]   Expert  1 |   1987 | GPU
DEBUG 01-04 15:36:25.932953.932953 lmp.py:292]   Expert  4 |   1987 | GPU
DEBUG 01-04 15:36:25.932642.932642 lmp.py:292]   Expert  0 |   1988 | GPU
DEBUG 01-04 15:36:25.932855.932855 lmp.py:292]   Expert  2 |   1988 | GPU
DEBUG 01-04 15:36:25.932544.932544 lmp.py:292]   Expert  3 |   1991 | GPU
DEBUG 01-04 15:36:25.932472.932472 lmp.py:293] 
DEBUG 01-04 15:36:25.932472.932472 lmp.py:293]   CPU total tokens: 106 (0.9%)
DEBUG 01-04 15:36:25.932399.932399 lmp.py:294]   GPU total tokens: 12182 (99.1%)
DEBUG 01-04 15:36:25.932857.932857 cuda_h.py:19] end experts_map_get cost 0.0013725757598876953 seconds
DEBUG 01-04 15:36:25.932546.932546 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:25.932184.932184 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.932367.932367 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.933675.933675 cuda_h.py:19] end allocate_cuda_memory cost 0.00026488304138183594 seconds
DEBUG 01-04 15:36:25.933141.933141 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.933420.933420 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.933090.933090 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.933263.933263 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 722a484a-b5a4-42e1-bd18-a0e92201fea0
DEBUG 01-04 15:36:25.933037.933037 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.935292.935292 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 722a484a-b5a4-42e1-bd18-a0e92201fea0
DEBUG 01-04 15:36:25.935807.935807 cuda_h.py:19] end load_into_gpu_async cost 0.0022344589233398438 seconds
DEBUG 01-04 15:36:25.935385.935385 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.936712.936712 cuda_h.py:19] end restore_tensors2 cost 0.0003910064697265625 seconds
DEBUG 01-04 15:36:25.936627.936627 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033254623413085938 seconds
DEBUG 01-04 15:36:25.938848.938848 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005815029144287109 seconds
DEBUG 01-04 15:36:25.938485.938485 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:25.938918.938918 lmp.py:339] 
DEBUG 01-04 15:36:25.938918.938918 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:25.938562.938562 cuda_h.py:19] end cpu_experts_submit cost 0.00010156631469726562 seconds
DEBUG 01-04 15:36:25.938948.938948 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:25.951280.951280 mlpmodule.py:704] group tensors cost 0.012320756912231445 s
DEBUG 01-04 15:36:25.953790.953790 mlpmodule.py:742] pad cost 0.0019807815551757812 s
DEBUG 01-04 15:36:25.954389.954389 mlpmodule.py:748] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-04 15:36:25.954232.954232 mlpmodule.py:753] move to cpu cost 2.7894973754882812e-05 s
DEBUG 01-04 15:36:25.958867.958867 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:25.958009.958009 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:25.958449.958449 mlpmodule.py:774] group_w3 first element: -0.0054931640625
WARNING 01-04 15:36:25.958022.958022 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:25.961937.961937 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:25.962772.962772 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:25.966463.966463 mlpmodule.py:797] group einsum cost 0.0121917724609375 s
DEBUG 01-04 15:36:25.966511.966511 mlpmodule.py:805] cpy2cputensor cost 9.274482727050781e-05 s
DEBUG 01-04 15:36:25.970445.970445 cuda_h.py:19] end wait_cetm_experts cost 0.03176093101501465 seconds
DEBUG 01-04 15:36:25.970535.970535 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:25.971107.971107 cuda_h.py:19] end gpu_sexperts cost 0.0004477500915527344 seconds
DEBUG 01-04 15:36:25.971626.971626 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-04 15:36:25.971542.971542 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-04 15:36:25.971060.971060 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.3855438232421875e-05 seconds
DEBUG 01-04 15:36:25.971108.971108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.224082946777344e-05 seconds
DEBUG 01-04 15:36:25.971903.971903 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:25.971567.971567 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 722a484a-b5a4-42e1-bd18-a0e92201fea0
DEBUG 01-04 15:36:25.971559.971559 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:25.971722.971722 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:25.971771.971771 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:25.976664.976664 cuda_h.py:19] end allocate_cuda_memory cost 0.004685401916503906 seconds
DEBUG 01-04 15:36:25.976819.976819 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:25.976443.976443 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:25.976180.976180 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:25.976367.976367 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 63b90fc0-77d5-47e5-a6cd-d981de539d72
DEBUG 01-04 15:36:25.976072.976072 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:25.985855.985855 client.py:127] Model loaded
DEBUG 01-04 15:36:25.985036.985036 cuda_h.py:19] end wait_experts cost 0.014005661010742188 seconds
DEBUG 01-04 15:36:25.985977.985977 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:25.985772.985772 lmp.py:384]   Computing 30 experts on GPU...
DEBUG 01-04 15:36:25.986511.986511 mlpmodule.py:662]  experts func einsum cost 0.04713749885559082 s
DEBUG 01-04 15:36:25.986073.986073 mlpmodule.py:531] gpu group tensors cost 0.0006041526794433594 s
INFO 01-04 15:36:25.986397.986397 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 63b90fc0-77d5-47e5-a6cd-d981de539d72
DEBUG 01-04 15:36:25.986432.986432 cuda_h.py:19] end load_into_gpu_async cost 0.009753704071044922 seconds
DEBUG 01-04 15:36:25.986135.986135 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:25.986310.986310 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-04 15:36:25.986828.986828 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014786005020141602 seconds
INFO 01-04 15:36:25.987759.987759 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 63b90fc0-77d5-47e5-a6cd-d981de539d72
DEBUG 01-04 15:36:25.988183.988183 mlpmodule.py:564] gpu pad cost 0.0020210742950439453 s
DEBUG 01-04 15:36:25.988367.988367 mlpmodule.py:582] gpu group einsum cost 0.0004858970642089844 s
DEBUG 01-04 15:36:25.991269.991269 mlpmodule.py:611] gpu experts func einsum cost 0.005842447280883789 s
DEBUG 01-04 15:36:25.991735.991735 cuda_h.py:19] end gpu_experts cost 0.006012916564941406 seconds
DEBUG 01-04 15:36:25.991015.991015 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:25.996641.996641 client.py:127] Model loaded
DEBUG 01-04 15:36:25.996875.996875 cuda_h.py:19] end sllm_worker_task cost 0.02494215965270996 seconds
DEBUG 01-04 15:36:25.996294.996294 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.00516200065612793 seconds
DEBUG 01-04 15:36:25.996213.996213 cuda_h.py:19] end layer_moe_generate_23 cost 0.0662679672241211 seconds
DEBUG 01-04 15:36:25.997729.997729 lmp.py:207] -------------------------------- end layer 23 --------------------------------
DEBUG 01-04 15:36:25.997346.997346 lmp.py:169] -------------------------------- start layer 24 --------------------------------
DEBUG 01-04 15:36:25.997850.997850 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:25.997501.997501 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:25.999005.999005 cuda_h.py:19] end self_attn cost 0.0023109912872314453 seconds
DEBUG 01-04 15:36:26.000325.000325 cuda_h.py:19] end iln_self_attn_paln cost 0.0028848648071289062 seconds
DEBUG 01-04 15:36:26.000446.000446 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-04 15:36:26.000778.000778 cuda_h.py:10] start gate
DEBUG 01-04 15:36:26.000852.000852 cuda_h.py:19] end gate cost 0.000583648681640625 seconds
DEBUG 01-04 15:36:26.000966.000966 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:26.001902.001902 lmp.py:281] 
DEBUG 01-04 15:36:26.001902.001902 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:26.001228.001228 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:26.001924.001924 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:26.001236.001236 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:26.001402.001402 lmp.py:285] 
DEBUG 01-04 15:36:26.001402.001402 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:26.001568.001568 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:26.001741.001741 lmp.py:292]   Expert 16 |      1 | CPU
DEBUG 01-04 15:36:26.001430.001430 lmp.py:292]   Expert 42 |      1 | CPU
DEBUG 01-04 15:36:26.001643.001643 lmp.py:292]   Expert 48 |      1 | CPU
DEBUG 01-04 15:36:26.001332.001332 lmp.py:292]   Expert  9 |      2 | CPU
DEBUG 01-04 15:36:26.001068.001068 lmp.py:292]   Expert 25 |      2 | CPU
DEBUG 01-04 15:36:26.001042.001042 lmp.py:292]   Expert 44 |      2 | CPU
DEBUG 01-04 15:36:26.001016.001016 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:26.001705.001705 lmp.py:292]   Expert 49 |      2 | CPU
DEBUG 01-04 15:36:26.001394.001394 lmp.py:292]   Expert 51 |      2 | CPU
DEBUG 01-04 15:36:26.001845.001845 lmp.py:292]   Expert 54 |      2 | CPU
DEBUG 01-04 15:36:26.001296.001296 lmp.py:292]   Expert 55 |      2 | CPU
DEBUG 01-04 15:36:26.001747.001747 lmp.py:292]   Expert 60 |      2 | CPU
DEBUG 01-04 15:36:26.001959.001959 lmp.py:292]   Expert 62 |      2 | CPU
DEBUG 01-04 15:36:26.001218.001218 lmp.py:292]   Expert 15 |      3 | CPU
DEBUG 01-04 15:36:26.001192.001192 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:26.001166.001166 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:26.001664.001664 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:26.001114.001114 lmp.py:292]   Expert 40 |      3 | CPU
DEBUG 01-04 15:36:26.001042.001042 lmp.py:292]   Expert 63 |      3 | CPU
DEBUG 01-04 15:36:26.001970.001970 lmp.py:292]   Expert 20 |      4 | CPU
DEBUG 01-04 15:36:26.001182.001182 lmp.py:292]   Expert 36 |      4 | CPU
DEBUG 01-04 15:36:26.001872.001872 lmp.py:292]   Expert 37 |      4 | CPU
DEBUG 01-04 15:36:26.001846.001846 lmp.py:292]   Expert 41 |      4 | CPU
DEBUG 01-04 15:36:26.001343.001343 lmp.py:292]   Expert 53 |      4 | CPU
DEBUG 01-04 15:36:26.001840.001840 lmp.py:292]   Expert 57 |      4 | CPU
DEBUG 01-04 15:36:26.001099.001099 lmp.py:292]   Expert  7 |      5 | CPU
DEBUG 01-04 15:36:26.001834.001834 lmp.py:292]   Expert 17 |      5 | CPU
DEBUG 01-04 15:36:26.001107.001107 lmp.py:292]   Expert 21 |      5 | CPU
DEBUG 01-04 15:36:26.001650.001650 lmp.py:292]   Expert 24 |      5 | CPU
DEBUG 01-04 15:36:26.001909.001909 lmp.py:292]   Expert 50 |      5 | GPU
DEBUG 01-04 15:36:26.001406.001406 lmp.py:292]   Expert 59 |      5 | GPU
DEBUG 01-04 15:36:26.001142.001142 lmp.py:292]   Expert 61 |      5 | GPU
DEBUG 01-04 15:36:26.001878.001878 lmp.py:292]   Expert  6 |      6 | GPU
DEBUG 01-04 15:36:26.001898.001898 lmp.py:292]   Expert 12 |      6 | GPU
DEBUG 01-04 15:36:26.001157.001157 lmp.py:292]   Expert 28 |      6 | GPU
DEBUG 01-04 15:36:26.001939.001939 lmp.py:292]   Expert 46 |      6 | GPU
DEBUG 01-04 15:36:26.001721.001721 lmp.py:292]   Expert 10 |      7 | GPU
DEBUG 01-04 15:36:26.001503.001503 lmp.py:292]   Expert 23 |      7 | GPU
DEBUG 01-04 15:36:26.001523.001523 lmp.py:292]   Expert 38 |      7 | GPU
DEBUG 01-04 15:36:26.001305.001305 lmp.py:292]   Expert 39 |      7 | GPU
DEBUG 01-04 15:36:26.001087.001087 lmp.py:292]   Expert 35 |      8 | GPU
DEBUG 01-04 15:36:26.001107.001107 lmp.py:292]   Expert 45 |      8 | GPU
DEBUG 01-04 15:36:26.001128.001128 lmp.py:292]   Expert 18 |      9 | GPU
DEBUG 01-04 15:36:26.001102.001102 lmp.py:292]   Expert 33 |     10 | GPU
DEBUG 01-04 15:36:26.001599.001599 lmp.py:292]   Expert 11 |     12 | GPU
DEBUG 01-04 15:36:26.001858.001858 lmp.py:292]   Expert 14 |     13 | GPU
DEBUG 01-04 15:36:26.001593.001593 lmp.py:292]   Expert 31 |     13 | GPU
DEBUG 01-04 15:36:26.001375.001375 lmp.py:292]   Expert 32 |     13 | GPU
DEBUG 01-04 15:36:26.001157.001157 lmp.py:292]   Expert  8 |     18 | GPU
DEBUG 01-04 15:36:26.001178.001178 lmp.py:292]   Expert 19 |     18 | GPU
DEBUG 01-04 15:36:26.001960.001960 lmp.py:292]   Expert 52 |     23 | GPU
DEBUG 01-04 15:36:26.001503.001503 lmp.py:292]   Expert 27 |     24 | GPU
DEBUG 01-04 15:36:26.002047.002047 lmp.py:292]   Expert 13 |     30 | GPU
DEBUG 01-04 15:36:26.002067.002067 lmp.py:292]   Expert  4 |   1984 | GPU
DEBUG 01-04 15:36:26.002849.002849 lmp.py:292]   Expert  5 |   1985 | GPU
DEBUG 01-04 15:36:26.002823.002823 lmp.py:292]   Expert  0 |   1988 | GPU
DEBUG 01-04 15:36:26.002082.002082 lmp.py:292]   Expert  2 |   1990 | GPU
DEBUG 01-04 15:36:26.002579.002579 lmp.py:292]   Expert  1 |   1993 | GPU
DEBUG 01-04 15:36:26.002315.002315 lmp.py:292]   Expert  3 |   1997 | GPU
DEBUG 01-04 15:36:26.002004.002004 lmp.py:293] 
DEBUG 01-04 15:36:26.002004.002004 lmp.py:293]   CPU total tokens: 85 (0.7%)
DEBUG 01-04 15:36:26.002740.002740 lmp.py:294]   GPU total tokens: 12203 (99.3%)
DEBUG 01-04 15:36:26.002767.002767 cuda_h.py:19] end experts_map_get cost 0.0013356208801269531 seconds
DEBUG 01-04 15:36:26.002741.002741 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:26.002325.002325 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.002356.002356 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.002346.002346 cuda_h.py:19] end allocate_cuda_memory cost 0.00027823448181152344 seconds
DEBUG 01-04 15:36:26.002620.002620 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.002753.002753 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.002231.002231 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.002927.002927 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1f85e65d-21df-45f8-b8b8-088e71a1a44a
DEBUG 01-04 15:36:26.002688.002688 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:26.003792.003792 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1f85e65d-21df-45f8-b8b8-088e71a1a44a
DEBUG 01-04 15:36:26.003052.003052 cuda_h.py:19] end load_into_gpu_async cost 0.001201629638671875 seconds
DEBUG 01-04 15:36:26.003708.003708 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.004945.004945 cuda_h.py:19] end restore_tensors2 cost 0.0003254413604736328 seconds
DEBUG 01-04 15:36:26.004291.004291 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021314620971679688 seconds
DEBUG 01-04 15:36:26.006665.006665 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004624366760253906 seconds
DEBUG 01-04 15:36:26.006064.006064 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:26.006689.006689 lmp.py:339] 
DEBUG 01-04 15:36:26.006689.006689 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:26.006333.006333 cuda_h.py:19] end cpu_experts_submit cost 0.00010085105895996094 seconds
DEBUG 01-04 15:36:26.007718.007718 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:26.013836.013836 mlpmodule.py:704] group tensors cost 0.006159305572509766 s
DEBUG 01-04 15:36:26.015336.015336 mlpmodule.py:742] pad cost 0.0016455650329589844 s
DEBUG 01-04 15:36:26.015419.015419 mlpmodule.py:748] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-04 15:36:26.015885.015885 mlpmodule.py:753] move to cpu cost 2.7418136596679688e-05 s
DEBUG 01-04 15:36:26.019504.019504 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:26.019256.019256 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:26.019397.019397 mlpmodule.py:774] group_w3 first element: -0.00152587890625
WARNING 01-04 15:36:26.019526.019526 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:26.023096.023096 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:26.023123.023123 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:26.026373.026373 mlpmodule.py:797] group einsum cost 0.010975122451782227 s
DEBUG 01-04 15:36:26.026897.026897 mlpmodule.py:805] cpy2cputensor cost 7.557868957519531e-05 s
DEBUG 01-04 15:36:26.030929.030929 cuda_h.py:19] end wait_cetm_experts cost 0.02384495735168457 seconds
DEBUG 01-04 15:36:26.031449.031449 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:26.031174.031174 cuda_h.py:19] end gpu_sexperts cost 0.00045752525329589844 seconds
DEBUG 01-04 15:36:26.031448.031448 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-04 15:36:26.031125.031125 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-04 15:36:26.031736.031736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.266334533691406e-05 seconds
DEBUG 01-04 15:36:26.031195.031195 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:26.031131.031131 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00014638900756835938 seconds
DEBUG 01-04 15:36:26.031068.031068 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.031526.031526 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:26.032114.032114 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1f85e65d-21df-45f8-b8b8-088e71a1a44a
DEBUG 01-04 15:36:26.032933.032933 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.036328.036328 cuda_h.py:19] end allocate_cuda_memory cost 0.0038290023803710938 seconds
DEBUG 01-04 15:36:26.036391.036391 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.036538.036538 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.036945.036945 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.036654.036654 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b9890eab-fab4-470e-abc5-48745dcb0246
DEBUG 01-04 15:36:26.036109.036109 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:26.045885.045885 mlpmodule.py:662]  experts func einsum cost 0.03809499740600586 s
INFO 01-04 15:36:26.053543.053543 client.py:127] Model loaded
DEBUG 01-04 15:36:26.053310.053310 cuda_h.py:19] end wait_experts cost 0.021060705184936523 seconds
DEBUG 01-04 15:36:26.053511.053511 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:26.053520.053520 lmp.py:384]   Computing 30 experts on GPU...
INFO 01-04 15:36:26.053360.053360 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b9890eab-fab4-470e-abc5-48745dcb0246
DEBUG 01-04 15:36:26.053634.053634 cuda_h.py:19] end load_into_gpu_async cost 0.017697811126708984 seconds
DEBUG 01-04 15:36:26.053290.053290 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.054803.054803 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-04 15:36:26.054890.054890 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.022088050842285156 seconds
DEBUG 01-04 15:36:26.054715.054715 mlpmodule.py:531] gpu group tensors cost 0.0009679794311523438 s
INFO 01-04 15:36:26.054858.054858 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b9890eab-fab4-470e-abc5-48745dcb0246
DEBUG 01-04 15:36:26.056671.056671 mlpmodule.py:564] gpu pad cost 0.001766204833984375 s
DEBUG 01-04 15:36:26.056885.056885 mlpmodule.py:582] gpu group einsum cost 0.0005674362182617188 s
DEBUG 01-04 15:36:26.060057.060057 mlpmodule.py:611] gpu experts func einsum cost 0.006837606430053711 s
DEBUG 01-04 15:36:26.060007.060007 cuda_h.py:19] end gpu_experts cost 0.007042646408081055 seconds
DEBUG 01-04 15:36:26.060883.060883 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:26.064671.064671 client.py:127] Model loaded
DEBUG 01-04 15:36:26.064289.064289 cuda_h.py:19] end sllm_worker_task cost 0.032929182052612305 seconds
DEBUG 01-04 15:36:26.064669.064669 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.004437923431396484 seconds
DEBUG 01-04 15:36:26.065377.065377 cuda_h.py:19] end layer_moe_generate_24 cost 0.06494355201721191 seconds
DEBUG 01-04 15:36:26.065887.065887 lmp.py:207] -------------------------------- end layer 24 --------------------------------
DEBUG 01-04 15:36:26.065040.065040 lmp.py:169] -------------------------------- start layer 25 --------------------------------
DEBUG 01-04 15:36:26.065505.065505 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:26.065993.065993 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:26.068517.068517 cuda_h.py:19] end self_attn cost 0.0023703575134277344 seconds
DEBUG 01-04 15:36:26.068712.068712 cuda_h.py:19] end iln_self_attn_paln cost 0.0029985904693603516 seconds
DEBUG 01-04 15:36:26.068636.068636 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-04 15:36:26.068591.068591 cuda_h.py:10] start gate
DEBUG 01-04 15:36:26.069697.069697 cuda_h.py:19] end gate cost 0.0005714893341064453 seconds
DEBUG 01-04 15:36:26.069526.069526 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:26.069138.069138 lmp.py:281] 
DEBUG 01-04 15:36:26.069138.069138 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:26.069702.069702 lmp.py:282]   Total experts: 59
DEBUG 01-04 15:36:26.069160.069160 lmp.py:283]   CPU experts: 29 (49%)
DEBUG 01-04 15:36:26.069757.069757 lmp.py:284]   GPU experts: 30 (51%)
DEBUG 01-04 15:36:26.069161.069161 lmp.py:285] 
DEBUG 01-04 15:36:26.069161.069161 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:26.069042.069042 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:26.069421.069421 lmp.py:292]   Expert 20 |      1 | CPU
DEBUG 01-04 15:36:26.069779.069779 lmp.py:292]   Expert 22 |      1 | CPU
DEBUG 01-04 15:36:26.069230.069230 lmp.py:292]   Expert 33 |      1 | CPU
DEBUG 01-04 15:36:26.069966.069966 lmp.py:292]   Expert 34 |      1 | CPU
DEBUG 01-04 15:36:26.069701.069701 lmp.py:292]   Expert 43 |      1 | CPU
DEBUG 01-04 15:36:26.069675.069675 lmp.py:292]   Expert 56 |      1 | CPU
DEBUG 01-04 15:36:26.069934.069934 lmp.py:292]   Expert 14 |      2 | CPU
DEBUG 01-04 15:36:26.069193.069193 lmp.py:292]   Expert 47 |      2 | CPU
DEBUG 01-04 15:36:26.069406.069406 lmp.py:292]   Expert 50 |      2 | CPU
DEBUG 01-04 15:36:26.069141.069141 lmp.py:292]   Expert 10 |      3 | CPU
DEBUG 01-04 15:36:26.069400.069400 lmp.py:292]   Expert 12 |      3 | CPU
DEBUG 01-04 15:36:26.069659.069659 lmp.py:292]   Expert 13 |      3 | CPU
DEBUG 01-04 15:36:26.069633.069633 lmp.py:292]   Expert 31 |      3 | CPU
DEBUG 01-04 15:36:26.069322.069322 lmp.py:292]   Expert 32 |      3 | CPU
DEBUG 01-04 15:36:26.069535.069535 lmp.py:292]   Expert 35 |      3 | CPU
DEBUG 01-04 15:36:26.069985.069985 lmp.py:292]   Expert 36 |      3 | CPU
DEBUG 01-04 15:36:26.069675.069675 lmp.py:292]   Expert 37 |      3 | CPU
DEBUG 01-04 15:36:26.069649.069649 lmp.py:292]   Expert 44 |      3 | CPU
DEBUG 01-04 15:36:26.069908.069908 lmp.py:292]   Expert 48 |      3 | CPU
DEBUG 01-04 15:36:26.069405.069405 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:26.069902.069902 lmp.py:292]   Expert 57 |      3 | CPU
DEBUG 01-04 15:36:26.069399.069399 lmp.py:292]   Expert 63 |      3 | CPU
DEBUG 01-04 15:36:26.069135.069135 lmp.py:292]   Expert  6 |      4 | CPU
DEBUG 01-04 15:36:26.069632.069632 lmp.py:292]   Expert 11 |      4 | CPU
DEBUG 01-04 15:36:26.069129.069129 lmp.py:292]   Expert 38 |      4 | CPU
DEBUG 01-04 15:36:26.069626.069626 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:26.069600.069600 lmp.py:292]   Expert 52 |      4 | CPU
DEBUG 01-04 15:36:26.069813.069813 lmp.py:292]   Expert 55 |      4 | CPU
DEBUG 01-04 15:36:26.069025.069025 lmp.py:292]   Expert 23 |      5 | CPU
DEBUG 01-04 15:36:26.070715.070715 lmp.py:292]   Expert 39 |      5 | GPU
DEBUG 01-04 15:36:26.070404.070404 lmp.py:292]   Expert 41 |      5 | GPU
DEBUG 01-04 15:36:26.070901.070901 lmp.py:292]   Expert 59 |      5 | GPU
DEBUG 01-04 15:36:26.070637.070637 lmp.py:292]   Expert  8 |      6 | GPU
DEBUG 01-04 15:36:26.070896.070896 lmp.py:292]   Expert 21 |      6 | GPU
DEBUG 01-04 15:36:26.070393.070393 lmp.py:292]   Expert 25 |      6 | GPU
DEBUG 01-04 15:36:26.070890.070890 lmp.py:292]   Expert 28 |      6 | GPU
DEBUG 01-04 15:36:26.070387.070387 lmp.py:292]   Expert 61 |      6 | GPU
DEBUG 01-04 15:36:26.070646.070646 lmp.py:292]   Expert 15 |      7 | GPU
DEBUG 01-04 15:36:26.070382.070382 lmp.py:292]   Expert 46 |      7 | GPU
DEBUG 01-04 15:36:26.070640.070640 lmp.py:292]   Expert 24 |      8 | GPU
DEBUG 01-04 15:36:26.070138.070138 lmp.py:292]   Expert 40 |      8 | GPU
DEBUG 01-04 15:36:26.070827.070827 lmp.py:292]   Expert  7 |      9 | GPU
DEBUG 01-04 15:36:26.070278.070278 lmp.py:292]   Expert 26 |      9 | GPU
DEBUG 01-04 15:36:26.070729.070729 lmp.py:292]   Expert 30 |      9 | GPU
DEBUG 01-04 15:36:26.070180.070180 lmp.py:292]   Expert 45 |     10 | GPU
DEBUG 01-04 15:36:26.070154.070154 lmp.py:292]   Expert 58 |     10 | GPU
DEBUG 01-04 15:36:26.070889.070889 lmp.py:292]   Expert 17 |     13 | GPU
DEBUG 01-04 15:36:26.070386.070386 lmp.py:292]   Expert 51 |     15 | GPU
DEBUG 01-04 15:36:26.070645.070645 lmp.py:292]   Expert 60 |     17 | GPU
DEBUG 01-04 15:36:26.070142.070142 lmp.py:292]   Expert 19 |     18 | GPU
DEBUG 01-04 15:36:26.070401.070401 lmp.py:292]   Expert 54 |     22 | GPU
DEBUG 01-04 15:36:26.070898.070898 lmp.py:292]   Expert 29 |     25 | GPU
DEBUG 01-04 15:36:26.070919.070919 lmp.py:292]   Expert  9 |     28 | GPU
DEBUG 01-04 15:36:26.070939.070939 lmp.py:292]   Expert  0 |   1985 | GPU
DEBUG 01-04 15:36:26.070436.070436 lmp.py:292]   Expert  3 |   1989 | GPU
DEBUG 01-04 15:36:26.070934.070934 lmp.py:292]   Expert  1 |   1991 | GPU
DEBUG 01-04 15:36:26.070385.070385 lmp.py:292]   Expert  4 |   1992 | GPU
DEBUG 01-04 15:36:26.070074.070074 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:26.070763.070763 lmp.py:292]   Expert  5 |   1996 | GPU
DEBUG 01-04 15:36:26.070929.070929 lmp.py:293] 
DEBUG 01-04 15:36:26.070929.070929 lmp.py:293]   CPU total tokens: 80 (0.7%)
DEBUG 01-04 15:36:26.070142.070142 lmp.py:294]   GPU total tokens: 12208 (99.3%)
DEBUG 01-04 15:36:26.070646.070646 cuda_h.py:19] end experts_map_get cost 0.0013594627380371094 seconds
DEBUG 01-04 15:36:26.070097.070097 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:26.070396.070396 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.070480.070480 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.071232.071232 cuda_h.py:19] end allocate_cuda_memory cost 0.00027632713317871094 seconds
DEBUG 01-04 15:36:26.071790.071790 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.071685.071685 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.071594.071594 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.071052.071052 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f3bea3fd-9adf-4035-917d-8fb524f06042
DEBUG 01-04 15:36:26.071435.071435 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:26.073946.073946 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f3bea3fd-9adf-4035-917d-8fb524f06042
DEBUG 01-04 15:36:26.073637.073637 cuda_h.py:19] end load_into_gpu_async cost 0.002104520797729492 seconds
DEBUG 01-04 15:36:26.073671.073671 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.073841.073841 cuda_h.py:19] end restore_tensors2 cost 0.0003108978271484375 seconds
DEBUG 01-04 15:36:26.073439.073439 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003030061721801758 seconds
DEBUG 01-04 15:36:26.076009.076009 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00545811653137207 seconds
DEBUG 01-04 15:36:26.076600.076600 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:26.076794.076794 lmp.py:339] 
DEBUG 01-04 15:36:26.076794.076794 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:26.076346.076346 cuda_h.py:19] end cpu_experts_submit cost 0.00010228157043457031 seconds
DEBUG 01-04 15:36:26.076970.076970 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:26.089805.089805 mlpmodule.py:704] group tensors cost 0.01348733901977539 s
DEBUG 01-04 15:36:26.092329.092329 mlpmodule.py:742] pad cost 0.001535177230834961 s
DEBUG 01-04 15:36:26.092141.092141 mlpmodule.py:748] create cpu tensor cost 4.291534423828125e-05 s
DEBUG 01-04 15:36:26.092190.092190 mlpmodule.py:753] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-04 15:36:26.096639.096639 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:26.096437.096437 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:26.096811.096811 mlpmodule.py:774] group_w3 first element: -0.01397705078125
WARNING 01-04 15:36:26.096013.096013 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:26.099716.099716 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:26.100492.100492 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:26.103628.103628 mlpmodule.py:797] group einsum cost 0.011040210723876953 s
DEBUG 01-04 15:36:26.103211.103211 mlpmodule.py:805] cpy2cputensor cost 8.058547973632812e-05 s
DEBUG 01-04 15:36:26.107145.107145 cuda_h.py:19] end wait_cetm_experts cost 0.031298160552978516 seconds
DEBUG 01-04 15:36:26.107426.107426 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:26.108953.108953 cuda_h.py:19] end gpu_sexperts cost 0.00044989585876464844 seconds
DEBUG 01-04 15:36:26.108180.108180 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-04 15:36:26.108811.108811 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-04 15:36:26.108913.108913 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.291534423828125e-05 seconds
DEBUG 01-04 15:36:26.108272.108272 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.00010085105895996094 seconds
DEBUG 01-04 15:36:26.108306.108306 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:26.108300.108300 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f3bea3fd-9adf-4035-917d-8fb524f06042
DEBUG 01-04 15:36:26.108730.108730 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:26.108648.108648 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.108935.108935 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.113737.113737 cuda_h.py:19] end allocate_cuda_memory cost 0.0041239261627197266 seconds
DEBUG 01-04 15:36:26.113303.113303 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.113332.113332 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.113698.113698 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.113176.113176 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 59edfbec-9557-4880-8068-2650035e4f3c
DEBUG 01-04 15:36:26.113140.113140 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:26.122740.122740 mlpmodule.py:662]  experts func einsum cost 0.045990943908691406 s
INFO 01-04 15:36:26.123959.123959 client.py:127] Model loaded
DEBUG 01-04 15:36:26.123163.123163 cuda_h.py:19] end wait_experts cost 0.01505136489868164 seconds
DEBUG 01-04 15:36:26.123318.123318 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:26.123135.123135 lmp.py:384]   Computing 30 experts on GPU...
INFO 01-04 15:36:26.124312.124312 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 59edfbec-9557-4880-8068-2650035e4f3c
DEBUG 01-04 15:36:26.124301.124301 cuda_h.py:19] end load_into_gpu_async cost 0.011145830154418945 seconds
DEBUG 01-04 15:36:26.124242.124242 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.124564.124564 cuda_h.py:19] end restore_tensors2 cost 0.0001068115234375 seconds
DEBUG 01-04 15:36:26.124989.124989 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.015695810317993164 seconds
DEBUG 01-04 15:36:26.124126.124126 mlpmodule.py:531] gpu group tensors cost 0.001024007797241211 s
INFO 01-04 15:36:26.125612.125612 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 59edfbec-9557-4880-8068-2650035e4f3c
DEBUG 01-04 15:36:26.126875.126875 mlpmodule.py:564] gpu pad cost 0.0014772415161132812 s
DEBUG 01-04 15:36:26.126774.126774 mlpmodule.py:582] gpu group einsum cost 0.0004863739013671875 s
DEBUG 01-04 15:36:26.129479.129479 mlpmodule.py:611] gpu experts func einsum cost 0.005851030349731445 s
DEBUG 01-04 15:36:26.129423.129423 cuda_h.py:19] end gpu_experts cost 0.006055593490600586 seconds
DEBUG 01-04 15:36:26.129272.129272 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:26.135163.135163 client.py:127] Model loaded
DEBUG 01-04 15:36:26.135668.135668 cuda_h.py:19] end sllm_worker_task cost 0.02631998062133789 seconds
DEBUG 01-04 15:36:26.135194.135194 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005356311798095703 seconds
DEBUG 01-04 15:36:26.135921.135921 cuda_h.py:19] end layer_moe_generate_25 cost 0.06682038307189941 seconds
DEBUG 01-04 15:36:26.135721.135721 lmp.py:207] -------------------------------- end layer 25 --------------------------------
DEBUG 01-04 15:36:26.135053.135053 lmp.py:169] -------------------------------- start layer 26 --------------------------------
DEBUG 01-04 15:36:26.135557.135557 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:26.135440.135440 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:26.138491.138491 cuda_h.py:19] end self_attn cost 0.002442598342895508 seconds
DEBUG 01-04 15:36:26.138699.138699 cuda_h.py:19] end iln_self_attn_paln cost 0.003025054931640625 seconds
DEBUG 01-04 15:36:26.138443.138443 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-04 15:36:26.138252.138252 cuda_h.py:10] start gate
DEBUG 01-04 15:36:26.139907.139907 cuda_h.py:19] end gate cost 0.0005555152893066406 seconds
DEBUG 01-04 15:36:26.139922.139922 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:26.139838.139838 lmp.py:281] 
DEBUG 01-04 15:36:26.139838.139838 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:26.139971.139971 lmp.py:282]   Total experts: 58
DEBUG 01-04 15:36:26.139191.139191 lmp.py:283]   CPU experts: 29 (50%)
DEBUG 01-04 15:36:26.139026.139026 lmp.py:284]   GPU experts: 29 (50%)
DEBUG 01-04 15:36:26.139000.139000 lmp.py:285] 
DEBUG 01-04 15:36:26.139000.139000 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:26.139974.139974 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:26.139431.139431 lmp.py:292]   Expert  7 |      1 | CPU
DEBUG 01-04 15:36:26.139405.139405 lmp.py:292]   Expert  8 |      1 | CPU
DEBUG 01-04 15:36:26.139664.139664 lmp.py:292]   Expert 22 |      1 | CPU
DEBUG 01-04 15:36:26.139161.139161 lmp.py:292]   Expert 61 |      1 | CPU
DEBUG 01-04 15:36:26.139182.139182 lmp.py:292]   Expert 62 |      1 | CPU
DEBUG 01-04 15:36:26.139441.139441 lmp.py:292]   Expert 11 |      2 | CPU
DEBUG 01-04 15:36:26.139653.139653 lmp.py:292]   Expert 15 |      2 | CPU
DEBUG 01-04 15:36:26.139627.139627 lmp.py:292]   Expert 27 |      2 | CPU
DEBUG 01-04 15:36:26.139647.139647 lmp.py:292]   Expert 43 |      2 | CPU
DEBUG 01-04 15:36:26.139429.139429 lmp.py:292]   Expert 45 |      2 | CPU
DEBUG 01-04 15:36:26.139450.139450 lmp.py:292]   Expert 55 |      2 | CPU
DEBUG 01-04 15:36:26.139232.139232 lmp.py:292]   Expert 59 |      2 | CPU
DEBUG 01-04 15:36:26.139252.139252 lmp.py:292]   Expert  9 |      3 | CPU
DEBUG 01-04 15:36:26.139511.139511 lmp.py:292]   Expert 20 |      3 | CPU
DEBUG 01-04 15:36:26.139293.139293 lmp.py:292]   Expert 21 |      3 | CPU
DEBUG 01-04 15:36:26.139075.139075 lmp.py:292]   Expert 26 |      3 | CPU
DEBUG 01-04 15:36:26.139095.139095 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:26.139116.139116 lmp.py:292]   Expert 34 |      3 | CPU
DEBUG 01-04 15:36:26.139136.139136 lmp.py:292]   Expert 36 |      3 | CPU
DEBUG 01-04 15:36:26.139918.139918 lmp.py:292]   Expert 41 |      3 | CPU
DEBUG 01-04 15:36:26.139130.139130 lmp.py:292]   Expert 47 |      3 | CPU
DEBUG 01-04 15:36:26.139912.139912 lmp.py:292]   Expert 53 |      3 | CPU
DEBUG 01-04 15:36:26.140886.140886 lmp.py:292]   Expert 57 |      3 | CPU
DEBUG 01-04 15:36:26.140668.140668 lmp.py:292]   Expert 19 |      4 | CPU
DEBUG 01-04 15:36:26.140450.140450 lmp.py:292]   Expert 32 |      4 | CPU
DEBUG 01-04 15:36:26.140471.140471 lmp.py:292]   Expert 39 |      4 | CPU
DEBUG 01-04 15:36:26.140491.140491 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:26.140273.140273 lmp.py:292]   Expert 54 |      4 | CPU
DEBUG 01-04 15:36:26.140293.140293 lmp.py:292]   Expert 60 |      4 | CPU
DEBUG 01-04 15:36:26.140075.140075 lmp.py:292]   Expert  6 |      5 | GPU
DEBUG 01-04 15:36:26.140857.140857 lmp.py:292]   Expert 12 |      6 | GPU
DEBUG 01-04 15:36:26.140785.140785 lmp.py:292]   Expert 13 |      6 | GPU
DEBUG 01-04 15:36:26.140282.140282 lmp.py:292]   Expert 24 |      6 | GPU
DEBUG 01-04 15:36:26.140779.140779 lmp.py:292]   Expert 28 |      6 | GPU
DEBUG 01-04 15:36:26.140323.140323 lmp.py:292]   Expert 63 |      6 | GPU
DEBUG 01-04 15:36:26.140105.140105 lmp.py:292]   Expert 23 |      7 | GPU
DEBUG 01-04 15:36:26.140125.140125 lmp.py:292]   Expert 42 |      7 | GPU
DEBUG 01-04 15:36:26.140907.140907 lmp.py:292]   Expert 37 |      8 | GPU
DEBUG 01-04 15:36:26.140928.140928 lmp.py:292]   Expert 33 |      9 | GPU
DEBUG 01-04 15:36:26.140663.140663 lmp.py:292]   Expert 16 |     10 | GPU
DEBUG 01-04 15:36:26.140160.140160 lmp.py:292]   Expert 38 |     11 | GPU
DEBUG 01-04 15:36:26.140658.140658 lmp.py:292]   Expert 48 |     11 | GPU
DEBUG 01-04 15:36:26.140440.140440 lmp.py:292]   Expert 31 |     12 | GPU
DEBUG 01-04 15:36:26.140221.140221 lmp.py:292]   Expert 50 |     12 | GPU
DEBUG 01-04 15:36:26.140957.140957 lmp.py:292]   Expert 44 |     14 | GPU
DEBUG 01-04 15:36:26.140739.140739 lmp.py:292]   Expert 52 |     14 | GPU
DEBUG 01-04 15:36:26.140521.140521 lmp.py:292]   Expert 25 |     16 | GPU
DEBUG 01-04 15:36:26.140171.140171 lmp.py:292]   Expert 18 |     18 | GPU
DEBUG 01-04 15:36:26.140191.140191 lmp.py:292]   Expert 35 |     19 | GPU
DEBUG 01-04 15:36:26.140165.140165 lmp.py:292]   Expert 46 |     20 | GPU
DEBUG 01-04 15:36:26.140662.140662 lmp.py:292]   Expert 40 |     24 | GPU
DEBUG 01-04 15:36:26.140921.140921 lmp.py:292]   Expert 14 |     29 | GPU
DEBUG 01-04 15:36:26.140942.140942 lmp.py:292]   Expert  1 |   1984 | GPU
DEBUG 01-04 15:36:26.140724.140724 lmp.py:292]   Expert  3 |   1985 | GPU
DEBUG 01-04 15:36:26.140982.140982 lmp.py:292]   Expert  0 |   1987 | GPU
DEBUG 01-04 15:36:26.140003.140003 lmp.py:292]   Expert  5 |   1992 | GPU
DEBUG 01-04 15:36:26.140261.140261 lmp.py:292]   Expert  4 |   1993 | GPU
DEBUG 01-04 15:36:26.140282.140282 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:26.140017.140017 lmp.py:293] 
DEBUG 01-04 15:36:26.140017.140017 lmp.py:293]   CPU total tokens: 76 (0.6%)
DEBUG 01-04 15:36:26.140992.140992 lmp.py:294]   GPU total tokens: 12212 (99.4%)
DEBUG 01-04 15:36:26.140734.140734 cuda_h.py:19] end experts_map_get cost 0.0012743473052978516 seconds
DEBUG 01-04 15:36:26.140900.140900 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:26.140007.140007 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.140369.140369 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.141049.141049 cuda_h.py:19] end allocate_cuda_memory cost 0.00029397010803222656 seconds
DEBUG 01-04 15:36:26.141992.141992 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.141602.141602 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.141557.141557 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.141968.141968 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c0851f4d-5123-4387-94f4-fc895fd64e31
DEBUG 01-04 15:36:26.141113.141113 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:26.143249.143249 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c0851f4d-5123-4387-94f4-fc895fd64e31
DEBUG 01-04 15:36:26.143995.143995 cuda_h.py:19] end load_into_gpu_async cost 0.002239704132080078 seconds
DEBUG 01-04 15:36:26.143336.143336 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.144171.144171 cuda_h.py:19] end restore_tensors2 cost 0.0007462501525878906 seconds
DEBUG 01-04 15:36:26.144478.144478 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037314891815185547 seconds
DEBUG 01-04 15:36:26.146652.146652 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0060079097747802734 seconds
DEBUG 01-04 15:36:26.146620.146620 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:26.146053.146053 lmp.py:339] 
DEBUG 01-04 15:36:26.146053.146053 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:26.146174.146174 cuda_h.py:19] end cpu_experts_submit cost 0.00010180473327636719 seconds
DEBUG 01-04 15:36:26.146778.146778 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:26.158825.158825 mlpmodule.py:704] group tensors cost 0.011544942855834961 s
DEBUG 01-04 15:36:26.160500.160500 mlpmodule.py:742] pad cost 0.0012307167053222656 s
DEBUG 01-04 15:36:26.160980.160980 mlpmodule.py:748] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-04 15:36:26.160367.160367 mlpmodule.py:753] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-04 15:36:26.164469.164469 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:26.164003.164003 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:26.164576.164576 mlpmodule.py:774] group_w3 first element: -0.033935546875
WARNING 01-04 15:36:26.165838.165838 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:26.168581.168581 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:26.168271.168271 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:26.172820.172820 mlpmodule.py:797] group einsum cost 0.012104988098144531 s
DEBUG 01-04 15:36:26.172033.172033 mlpmodule.py:805] cpy2cputensor cost 8.440017700195312e-05 s
DEBUG 01-04 15:36:26.176486.176486 cuda_h.py:19] end wait_cetm_experts cost 0.03000497817993164 seconds
DEBUG 01-04 15:36:26.176092.176092 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:26.177313.177313 cuda_h.py:19] end gpu_sexperts cost 0.00043654441833496094 seconds
DEBUG 01-04 15:36:26.177063.177063 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-04 15:36:26.177263.177263 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-04 15:36:26.177544.177544 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.3855438232421875e-05 seconds
DEBUG 01-04 15:36:26.177399.177399 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.05718994140625e-05 seconds
DEBUG 01-04 15:36:26.177480.177480 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:26.177150.177150 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c0851f4d-5123-4387-94f4-fc895fd64e31
DEBUG 01-04 15:36:26.177135.177135 cuda_h.py:10] start sllm_worker_task
DEBUG 01-04 15:36:26.178841.178841 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.178730.178730 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.181642.181642 cuda_h.py:19] end allocate_cuda_memory cost 0.0036509037017822266 seconds
DEBUG 01-04 15:36:26.181081.181081 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.181228.181228 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.181343.181343 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.181860.181860 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22a2229e-2062-4a4b-84c8-708517dd4b54
DEBUG 01-04 15:36:26.182089.182089 client.py:106] call stub.LoadModelAsync
DEBUG 01-04 15:36:26.190742.190742 mlpmodule.py:662]  experts func einsum cost 0.04369521141052246 s
INFO 01-04 15:36:26.191674.191674 client.py:127] Model loaded
DEBUG 01-04 15:36:26.191616.191616 cuda_h.py:19] end wait_experts cost 0.013338088989257812 seconds
DEBUG 01-04 15:36:26.191081.191081 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:26.191876.191876 lmp.py:384]   Computing 29 experts on GPU...
DEBUG 01-04 15:36:26.191199.191199 mlpmodule.py:531] gpu group tensors cost 0.0004887580871582031 s
INFO 01-04 15:36:26.191829.191829 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22a2229e-2062-4a4b-84c8-708517dd4b54
DEBUG 01-04 15:36:26.191401.191401 cuda_h.py:19] end load_into_gpu_async cost 0.010099649429321289 seconds
DEBUG 01-04 15:36:26.192150.192150 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.192471.192471 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-04 15:36:26.192512.192512 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014086008071899414 seconds
INFO 01-04 15:36:26.192849.192849 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22a2229e-2062-4a4b-84c8-708517dd4b54
DEBUG 01-04 15:36:26.193774.193774 mlpmodule.py:564] gpu pad cost 0.0020918846130371094 s
DEBUG 01-04 15:36:26.194929.194929 mlpmodule.py:582] gpu group einsum cost 0.0003955364227294922 s
DEBUG 01-04 15:36:26.196542.196542 mlpmodule.py:611] gpu experts func einsum cost 0.005586147308349609 s
DEBUG 01-04 15:36:26.196942.196942 cuda_h.py:19] end gpu_experts cost 0.005738496780395508 seconds
DEBUG 01-04 15:36:26.196758.196758 cuda_h.py:10] start wait_load_qkvogn_s_weight
INFO 01-04 15:36:26.202347.202347 client.py:127] Model loaded
DEBUG 01-04 15:36:26.202488.202488 cuda_h.py:19] end sllm_worker_task cost 0.024284839630126953 seconds
DEBUG 01-04 15:36:26.202782.202782 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 0.005427837371826172 seconds
DEBUG 01-04 15:36:26.202224.202224 cuda_h.py:19] end layer_moe_generate_26 cost 0.06385254859924316 seconds
DEBUG 01-04 15:36:26.202541.202541 lmp.py:207] -------------------------------- end layer 26 --------------------------------
DEBUG 01-04 15:36:26.202496.202496 lmp.py:169] -------------------------------- start layer 27 --------------------------------
DEBUG 01-04 15:36:26.202523.202523 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-04 15:36:26.203883.203883 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-04 15:36:26.205130.205130 cuda_h.py:19] end self_attn cost 0.0023763179779052734 seconds
DEBUG 01-04 15:36:26.205325.205325 cuda_h.py:19] end iln_self_attn_paln cost 0.0029511451721191406 seconds
DEBUG 01-04 15:36:26.205446.205446 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-04 15:36:26.205063.205063 cuda_h.py:10] start gate
DEBUG 01-04 15:36:26.206658.206658 cuda_h.py:19] end gate cost 0.0005476474761962891 seconds
DEBUG 01-04 15:36:26.206912.206912 cuda_h.py:10] start experts_map_get
DEBUG 01-04 15:36:26.206682.206682 lmp.py:281] 
DEBUG 01-04 15:36:26.206682.206682 lmp.py:281] Expert Token Distribution & Device Allocation:
DEBUG 01-04 15:36:26.206100.206100 lmp.py:282]   Total experts: 58
DEBUG 01-04 15:36:26.206081.206081 lmp.py:283]   CPU experts: 29 (50%)
DEBUG 01-04 15:36:26.206439.206439 lmp.py:284]   GPU experts: 29 (50%)
DEBUG 01-04 15:36:26.206413.206413 lmp.py:285] 
DEBUG 01-04 15:36:26.206413.206413 lmp.py:285]   Expert ID | Tokens | Device
DEBUG 01-04 15:36:26.206910.206910 lmp.py:286]   -----------------------------------
DEBUG 01-04 15:36:26.206129.206129 lmp.py:292]   Expert 15 |      1 | CPU
DEBUG 01-04 15:36:26.206342.206342 lmp.py:292]   Expert 25 |      1 | CPU
DEBUG 01-04 15:36:26.206077.206077 lmp.py:292]   Expert 40 |      1 | CPU
DEBUG 01-04 15:36:26.206575.206575 lmp.py:292]   Expert 52 |      1 | CPU
DEBUG 01-04 15:36:26.206356.206356 lmp.py:292]   Expert 54 |      1 | CPU
DEBUG 01-04 15:36:26.206854.206854 lmp.py:292]   Expert 59 |      1 | CPU
DEBUG 01-04 15:36:26.206874.206874 lmp.py:292]   Expert  8 |      2 | CPU
DEBUG 01-04 15:36:26.206133.206133 lmp.py:292]   Expert 19 |      2 | CPU
DEBUG 01-04 15:36:26.206868.206868 lmp.py:292]   Expert 32 |      2 | CPU
DEBUG 01-04 15:36:26.206889.206889 lmp.py:292]   Expert 39 |      2 | CPU
DEBUG 01-04 15:36:26.206671.206671 lmp.py:292]   Expert 46 |      2 | CPU
DEBUG 01-04 15:36:26.206930.206930 lmp.py:292]   Expert 53 |      2 | CPU
DEBUG 01-04 15:36:26.206473.206473 lmp.py:292]   Expert 58 |      2 | CPU
DEBUG 01-04 15:36:26.207255.207255 lmp.py:292]   Expert  6 |      3 | CPU
DEBUG 01-04 15:36:26.207514.207514 lmp.py:292]   Expert 11 |      3 | CPU
DEBUG 01-04 15:36:26.207296.207296 lmp.py:292]   Expert 16 |      3 | CPU
DEBUG 01-04 15:36:26.207078.207078 lmp.py:292]   Expert 29 |      3 | CPU
DEBUG 01-04 15:36:26.207575.207575 lmp.py:292]   Expert 33 |      3 | CPU
DEBUG 01-04 15:36:26.207311.207311 lmp.py:292]   Expert 38 |      3 | CPU
DEBUG 01-04 15:36:26.207093.207093 lmp.py:292]   Expert 42 |      3 | CPU
DEBUG 01-04 15:36:26.207113.207113 lmp.py:292]   Expert 12 |      4 | CPU
DEBUG 01-04 15:36:26.207895.207895 lmp.py:292]   Expert 22 |      4 | CPU
DEBUG 01-04 15:36:26.207677.207677 lmp.py:292]   Expert 34 |      4 | CPU
DEBUG 01-04 15:36:26.207697.207697 lmp.py:292]   Expert 45 |      4 | CPU
DEBUG 01-04 15:36:26.207718.207718 lmp.py:292]   Expert 49 |      4 | CPU
DEBUG 01-04 15:36:26.207500.207500 lmp.py:292]   Expert 50 |      4 | CPU
DEBUG 01-04 15:36:26.207997.207997 lmp.py:292]   Expert 61 |      4 | CPU
DEBUG 01-04 15:36:26.207256.207256 lmp.py:292]   Expert  9 |      5 | CPU
DEBUG 01-04 15:36:26.207514.207514 lmp.py:292]   Expert 30 |      5 | CPU
DEBUG 01-04 15:36:26.207773.207773 lmp.py:292]   Expert 51 |      5 | GPU
DEBUG 01-04 15:36:26.207793.207793 lmp.py:292]   Expert 56 |      5 | GPU
DEBUG 01-04 15:36:26.207575.207575 lmp.py:292]   Expert 62 |      5 | GPU
DEBUG 01-04 15:36:26.207834.207834 lmp.py:292]   Expert 17 |      6 | GPU
DEBUG 01-04 15:36:26.207855.207855 lmp.py:292]   Expert 48 |      6 | GPU
DEBUG 01-04 15:36:26.207875.207875 lmp.py:292]   Expert 13 |      7 | GPU
DEBUG 01-04 15:36:26.207895.207895 lmp.py:292]   Expert 31 |      7 | GPU
DEBUG 01-04 15:36:26.207677.207677 lmp.py:292]   Expert 57 |      7 | GPU
DEBUG 01-04 15:36:26.207413.207413 lmp.py:292]   Expert 28 |      8 | GPU
DEBUG 01-04 15:36:26.207149.207149 lmp.py:292]   Expert 55 |      8 | GPU
DEBUG 01-04 15:36:26.207884.207884 lmp.py:292]   Expert 36 |      9 | GPU
DEBUG 01-04 15:36:26.207905.207905 lmp.py:292]   Expert 10 |     10 | GPU
DEBUG 01-04 15:36:26.207686.207686 lmp.py:292]   Expert 35 |     10 | GPU
DEBUG 01-04 15:36:26.207230.207230 lmp.py:292]   Expert 41 |     10 | GPU
DEBUG 01-04 15:36:26.207012.207012 lmp.py:292]   Expert 63 |     11 | GPU
DEBUG 01-04 15:36:26.207794.207794 lmp.py:292]   Expert 27 |     12 | GPU
DEBUG 01-04 15:36:26.207576.207576 lmp.py:292]   Expert 26 |     13 | GPU
DEBUG 01-04 15:36:26.207119.207119 lmp.py:292]   Expert 21 |     14 | GPU
DEBUG 01-04 15:36:26.207140.207140 lmp.py:292]   Expert 60 |     14 | GPU
DEBUG 01-04 15:36:26.207160.207160 lmp.py:292]   Expert 43 |     15 | GPU
DEBUG 01-04 15:36:26.207896.207896 lmp.py:292]   Expert 37 |     20 | GPU
DEBUG 01-04 15:36:26.207155.207155 lmp.py:292]   Expert 14 |     21 | GPU
DEBUG 01-04 15:36:26.207937.207937 lmp.py:292]   Expert 20 |     40 | GPU
DEBUG 01-04 15:36:26.207957.207957 lmp.py:292]   Expert  0 |   1987 | GPU
DEBUG 01-04 15:36:26.207739.207739 lmp.py:292]   Expert  4 |   1988 | GPU
DEBUG 01-04 15:36:26.207521.207521 lmp.py:292]   Expert  1 |   1989 | GPU
DEBUG 01-04 15:36:26.207064.207064 lmp.py:292]   Expert  3 |   1992 | GPU
DEBUG 01-04 15:36:26.207608.207608 lmp.py:292]   Expert  2 |   1995 | GPU
DEBUG 01-04 15:36:26.207628.207628 lmp.py:292]   Expert  5 |   1995 | GPU
DEBUG 01-04 15:36:26.207887.207887 lmp.py:293] 
DEBUG 01-04 15:36:26.207887.207887 lmp.py:293]   CPU total tokens: 79 (0.6%)
DEBUG 01-04 15:36:26.207623.207623 lmp.py:294]   GPU total tokens: 12209 (99.4%)
DEBUG 01-04 15:36:26.207127.207127 cuda_h.py:19] end experts_map_get cost 0.0012557506561279297 seconds
DEBUG 01-04 15:36:26.207339.207339 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-04 15:36:26.207539.207539 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-04 15:36:26.207947.207947 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-04 15:36:26.208892.208892 cuda_h.py:19] end allocate_cuda_memory cost 0.0002799034118652344 seconds
DEBUG 01-04 15:36:26.208119.208119 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-04 15:36:26.208491.208491 sllm_store_c.py:27] get device uuid map
DEBUG 01-04 15:36:26.208538.208538 sllm_store_c.py:29] call client load into gpu
DEBUG 01-04 15:36:26.208042.208042 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e637206-c7aa-4118-b4b5-6879f82baf2e
DEBUG 01-04 15:36:26.233076.233076 client.py:106] call stub.LoadModelAsync
INFO 01-04 15:36:26.235165.235165 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e637206-c7aa-4118-b4b5-6879f82baf2e
DEBUG 01-04 15:36:26.235618.235618 cuda_h.py:19] end load_into_gpu_async cost 0.02712869644165039 seconds
DEBUG 01-04 15:36:26.235651.235651 cuda_h.py:10] start restore_tensors2
DEBUG 01-04 15:36:26.235642.235642 cuda_h.py:19] end restore_tensors2 cost 0.0002849102020263672 seconds
DEBUG 01-04 15:36:26.235127.235127 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.028011083602905273 seconds
DEBUG 01-04 15:36:26.238251.238251 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.030387401580810547 seconds
DEBUG 01-04 15:36:26.238127.238127 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-04 15:36:26.238660.238660 lmp.py:339] 
DEBUG 01-04 15:36:26.238660.238660 lmp.py:339]   Computing 29 experts on CPU...
DEBUG 01-04 15:36:26.238450.238450 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-04 15:36:26.238099.238099 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-04 15:36:26.254166.254166 mlpmodule.py:704] group tensors cost 0.016025304794311523 s
DEBUG 01-04 15:36:26.257197.257197 mlpmodule.py:742] pad cost 0.0020287036895751953 s
DEBUG 01-04 15:36:26.257731.257731 mlpmodule.py:748] create cpu tensor cost 6.747245788574219e-05 s
DEBUG 01-04 15:36:26.257781.257781 mlpmodule.py:753] move to cpu cost 4.696846008300781e-05 s
DEBUG 01-04 15:36:26.262915.262915 mlpmodule.py:768] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-04 15:36:26.262429.262429 mlpmodule.py:769] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-04 15:36:26.262034.262034 mlpmodule.py:774] group_w3 first element: -0.000606536865234375
WARNING 01-04 15:36:26.262806.262806 mlpmodule.py:784] start einsum2
WARNING 01-04 15:36:26.265544.265544 mlpmodule.py:789] intermediate
WARNING 01-04 15:36:26.265839.265839 mlpmodule.py:793] start einsum3
DEBUG 01-04 15:36:26.269644.269644 mlpmodule.py:797] group einsum cost 0.011441469192504883 s
DEBUG 01-04 15:36:26.269691.269691 mlpmodule.py:805] cpy2cputensor cost 7.987022399902344e-05 s
DEBUG 01-04 15:36:26.273717.273717 cuda_h.py:19] end wait_cetm_experts cost 0.034819841384887695 seconds
DEBUG 01-04 15:36:26.273608.273608 cuda_h.py:10] start gpu_sexperts
DEBUG 01-04 15:36:26.273160.273160 cuda_h.py:19] end gpu_sexperts cost 0.00043702125549316406 seconds
DEBUG 01-04 15:36:26.273427.273427 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-04 15:36:26.273111.273111 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.3113021850585938e-05 seconds
DEBUG 01-04 15:36:26.273290.273290 cuda_h.py:10] start wait_experts
INFO 01-04 15:36:26.273238.273238 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e637206-c7aa-4118-b4b5-6879f82baf2e
INFO 01-04 15:36:26.283455.283455 client.py:127] Model loaded
DEBUG 01-04 15:36:26.284060.284060 cuda_h.py:19] end wait_experts cost 0.010087966918945312 seconds
DEBUG 01-04 15:36:26.284239.284239 cuda_h.py:10] start gpu_experts
DEBUG 01-04 15:36:26.284988.284988 lmp.py:384]   Computing 29 experts on GPU...
DEBUG 01-04 15:36:26.284253.284253 mlpmodule.py:531] gpu group tensors cost 0.0005104541778564453 s
DEBUG 01-04 15:36:26.286664.286664 mlpmodule.py:662]  experts func einsum cost 0.04753541946411133 s
DEBUG 01-04 15:36:26.286358.286358 mlpmodule.py:564] gpu pad cost 0.0014944076538085938 s
DEBUG 01-04 15:36:26.286055.286055 mlpmodule.py:582] gpu group einsum cost 0.0003631114959716797 s
DEBUG 01-04 15:36:26.289130.289130 mlpmodule.py:611] gpu experts func einsum cost 0.0049495697021484375 s
DEBUG 01-04 15:36:26.289385.289385 cuda_h.py:19] end gpu_experts cost 0.0051038265228271484 seconds
DEBUG 01-04 15:36:26.289948.289948 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-04 15:36:26.289565.289565 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 8.821487426757812e-06 seconds
DEBUG 01-04 15:36:26.293582.293582 cuda_h.py:19] end layer_moe_generate_27 cost 0.08809661865234375 seconds
DEBUG 01-04 15:36:26.294813.294813 lmp.py:207] -------------------------------- end layer 27 --------------------------------
DEBUG 01-04 15:36:26.294006.294006 cuda_h.py:19] end multi_layer cost 1.9282970428466797 seconds
Collecting data...
Generating '/tmp/nsys-report-3b90.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [11%                         ] report1.nsys-rep[1/1] [=15%                        ] report1.nsys-rep[1/1] [==20%                       ] report1.nsys-rep[1/1] [====26%                     ] report1.nsys-rep[1/1] [=====31%                    ] report1.nsys-rep[1/1] [=======36%                  ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [==========47%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
