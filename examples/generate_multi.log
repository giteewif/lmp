here pin
INFO 01-07 14:54:24.803183.803183 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-07 14:54:25.634840.634840 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-07 14:54:26.074375.074375 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-07 14:54:26.074421.074421 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.271s
DEBUG 01-07 14:54:26.231805.231805 cuda_memory_view.py:389] 
DEBUG 01-07 14:54:26.231805.231805 cuda_memory_view.py:389] restore_tensors_from_shared_memory_names time: 0.014693975448608398
DEBUG 01-07 14:54:28.254281.254281 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11885237693786621 s
DEBUG 01-07 14:54:28.755917.755917 cuda_h.py:19] end generate_input_ids cost 0.4999818801879883 seconds
DEBUG 01-07 14:54:28.755519.755519 cuda_h.py:10] start init_cache
DEBUG 01-07 14:54:28.755193.755193 cuda_h.py:19] end init_cache cost 0.00011301040649414062 seconds
DEBUG 01-07 14:54:31.180525.180525 cuda_h.py:10] start init_weights
DEBUG 01-07 14:54:31.180196.180196 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:31.180025.180025 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:31.181974.181974 cuda_h.py:19] end allocate_cuda_memory cost 0.0005559921264648438 seconds
DEBUG 01-07 14:54:31.181771.181771 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:31.181700.181700 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:31.181670.181670 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:31.181333.181333 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4cc14165-27b4-4914-9ea0-8473a7365676
DEBUG 01-07 14:54:31.181006.181006 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:31.183995.183995 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4cc14165-27b4-4914-9ea0-8473a7365676
DEBUG 01-07 14:54:31.183289.183289 cuda_h.py:19] end load_into_gpu_async cost 0.0013580322265625 seconds
DEBUG 01-07 14:54:31.183614.183614 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:31.183976.183976 cuda_h.py:19] end restore_tensors2 cost 8.7738037109375e-05 seconds
DEBUG 01-07 14:54:31.183745.183745 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023331642150878906 seconds
DEBUG 01-07 14:54:31.183833.183833 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:31.183774.183774 cuda_h.py:19] end restore2model cost 0.0002002716064453125 seconds
INFO 01-07 14:54:31.183518.183518 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4cc14165-27b4-4914-9ea0-8473a7365676
INFO 01-07 14:54:31.259606.259606 client.py:127] Model loaded
DEBUG 01-07 14:54:31.259446.259446 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-07 14:54:31.259941.259941 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:31.260191.260191 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:31.260673.260673 cuda_h.py:19] end allocate_cuda_memory cost 0.0004322528839111328 seconds
DEBUG 01-07 14:54:31.260281.260281 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:31.260583.260583 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:31.261832.261832 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:31.261630.261630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 23921d39-3897-40cb-bea6-ddf8e03b6a51
DEBUG 01-07 14:54:31.261789.261789 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:31.262940.262940 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 23921d39-3897-40cb-bea6-ddf8e03b6a51
DEBUG 01-07 14:54:31.262925.262925 cuda_h.py:19] end load_into_gpu_async cost 0.0018982887268066406 seconds
DEBUG 01-07 14:54:31.262808.262808 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:31.263241.263241 cuda_h.py:19] end restore_tensors2 cost 0.00015616416931152344 seconds
DEBUG 01-07 14:54:31.263721.263721 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032112598419189453 seconds
INFO 01-07 14:54:31.263426.263426 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 23921d39-3897-40cb-bea6-ddf8e03b6a51
INFO 01-07 14:54:31.279643.279643 client.py:127] Model loaded
DEBUG 01-07 14:54:31.279925.279925 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:31.280293.280293 cuda_h.py:19] end restore2model cost 0.000972747802734375 seconds
DEBUG 01-07 14:54:31.281026.281026 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02118539810180664 seconds
DEBUG 01-07 14:54:31.281732.281732 cuda_h.py:19] end init_weights cost 0.1002652645111084 seconds
DEBUG 01-07 14:54:31.281993.281993 cuda_h.py:10] start copy_emodel
DEBUG 01-07 14:54:32.088498.088498 cuda_h.py:19] end copy_emodel cost 0.8071098327636719 seconds
DEBUG 01-07 14:54:32.089987.089987 cuda_h.py:10] start init_hmv
DEBUG 01-07 14:54:32.230595.230595 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-07 14:54:32.231658.231658 cuda_h.py:19] end init_hmv cost 0.1423966884613037 seconds
DEBUG 01-07 14:54:32.231243.231243 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-07 14:54:32.306688.306688 cuda_h.py:19] end init_inputs_tokens cost 0.0751650333404541 seconds
DEBUG 01-07 14:54:32.307176.307176 cuda_h.py:10] start prefill_layer
DEBUG 01-07 14:54:32.307720.307720 lmp.py:153] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-07 14:54:32.307085.307085 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 14:54:32.307332.307332 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 14:54:32.307420.307420 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.814697265625e-05 seconds
DEBUG 01-07 14:54:32.307507.307507 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.818771362304688e-05 seconds
DEBUG 01-07 14:54:32.307296.307296 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:32.307962.307962 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:32.307562.307562 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:32.307977.307977 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:32.307377.307377 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:32.308402.308402 cuda_h.py:19] end allocate_cuda_memory cost 0.00027370452880859375 seconds
DEBUG 01-07 14:54:32.308544.308544 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:32.308096.308096 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:32.308714.308714 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:32.308775.308775 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d9341b6-4d1b-4e9e-8afd-5ebb1bc0e8cb
DEBUG 01-07 14:54:32.308118.308118 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:32.310063.310063 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d9341b6-4d1b-4e9e-8afd-5ebb1bc0e8cb
DEBUG 01-07 14:54:32.310271.310271 cuda_h.py:19] end load_into_gpu_async cost 0.0020585060119628906 seconds
DEBUG 01-07 14:54:32.310663.310663 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:32.310297.310297 cuda_h.py:19] end restore_tensors2 cost 0.00010800361633300781 seconds
DEBUG 01-07 14:54:32.310988.310988 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00283050537109375 seconds
INFO 01-07 14:54:32.310486.310486 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d9341b6-4d1b-4e9e-8afd-5ebb1bc0e8cb
INFO 01-07 14:54:32.318418.318418 client.py:127] Model loaded
DEBUG 01-07 14:54:32.318825.318825 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:32.319379.319379 cuda_h.py:19] end restore2model cost 0.0008628368377685547 seconds
DEBUG 01-07 14:54:32.319807.319807 cuda_h.py:19] end sllm_worker_task cost 0.01154327392578125 seconds
DEBUG 01-07 14:54:32.397406.397406 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:32.643838.643838 cuda_h.py:19] end self_attn cost 0.24552488327026367 seconds
DEBUG 01-07 14:54:32.643999.643999 cuda_h.py:19] end iln_self_attn_paln cost 0.33643531799316406 seconds
DEBUG 01-07 14:54:32.643856.643856 cuda_h.py:10] start dense_mlp
DEBUG 01-07 14:54:32.650217.650217 cuda_h.py:19] end dense_mlp cost 0.006580829620361328 seconds
DEBUG 01-07 14:54:32.650664.650664 lmp.py:194] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-07 14:54:32.650143.650143 lmp.py:153] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-07 14:54:32.650554.650554 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 14:54:32.650363.650363 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 14:54:32.650829.650829 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.457069396972656e-05 seconds
DEBUG 01-07 14:54:32.650221.650221 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 8.130073547363281e-05 seconds
DEBUG 01-07 14:54:32.650010.650010 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:32.650979.650979 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:32.651010.651010 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:32.651327.651327 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:32.651507.651507 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:32.651455.651455 cuda_h.py:19] end allocate_cuda_memory cost 0.00029277801513671875 seconds
DEBUG 01-07 14:54:32.652380.652380 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:32.652298.652298 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:32.652674.652674 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:32.652220.652220 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9ed669ce-faea-4773-9654-d70585f0f7d3
DEBUG 01-07 14:54:32.652671.652671 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:32.652443.652443 cuda_h.py:10] start self_attn
INFO 01-07 14:54:32.654937.654937 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9ed669ce-faea-4773-9654-d70585f0f7d3
DEBUG 01-07 14:54:32.654670.654670 cuda_h.py:19] end load_into_gpu_async cost 0.0024118423461914062 seconds
DEBUG 01-07 14:54:32.654654.654654 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:32.654880.654880 cuda_h.py:19] end restore_tensors2 cost 0.0001418590545654297 seconds
DEBUG 01-07 14:54:32.654453.654453 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003591775894165039 seconds
INFO 01-07 14:54:32.655988.655988 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9ed669ce-faea-4773-9654-d70585f0f7d3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:32.656469.656469 cuda_h.py:19] end self_attn cost 0.003445148468017578 seconds
DEBUG 01-07 14:54:32.656485.656485 cuda_h.py:19] end iln_self_attn_paln cost 0.0057277679443359375 seconds
DEBUG 01-07 14:54:32.656984.656984 cuda_h.py:10] start layer_moe_generate_multi_device_1
DEBUG 01-07 14:54:32.656316.656316 cuda_h.py:10] start gate
INFO 01-07 14:54:32.662215.662215 client.py:127] Model loaded
DEBUG 01-07 14:54:32.662510.662510 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:32.663501.663501 cuda_h.py:19] end restore2model cost 0.0010230541229248047 seconds
DEBUG 01-07 14:54:32.663949.663949 cuda_h.py:19] end sllm_worker_task cost 0.012659788131713867 seconds
DEBUG 01-07 14:54:32.753386.753386 cuda_h.py:19] end gate cost 0.09696006774902344 seconds
DEBUG 01-07 14:54:32.753602.753602 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:32.754000.754000 lmp.py:744] 
DEBUG 01-07 14:54:32.754000.754000 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:32.754677.754677 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:32.754472.754472 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:32.754738.754738 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:32.754381.754381 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:32.754785.754785 lmp.py:749] 
DEBUG 01-07 14:54:32.754785.754785 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:32.754905.754905 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:32.754654.754654 lmp.py:767]   Expert 25 |     64 | CPU
DEBUG 01-07 14:54:32.754012.754012 lmp.py:767]   Expert 54 |     67 | CPU
DEBUG 01-07 14:54:32.754609.754609 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 14:54:32.754683.754683 lmp.py:767]   Expert 31 |     72 | CPU
DEBUG 01-07 14:54:32.754948.754948 lmp.py:767]   Expert 55 |     72 | CPU
DEBUG 01-07 14:54:32.754306.754306 lmp.py:767]   Expert 62 |     87 | CPU
DEBUG 01-07 14:54:32.754234.754234 lmp.py:767]   Expert 18 |     88 | CPU
DEBUG 01-07 14:54:32.754162.754162 lmp.py:767]   Expert 52 |     98 | CPU
DEBUG 01-07 14:54:32.754328.754328 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 14:54:32.754779.754779 lmp.py:767]   Expert 47 |    104 | CPU
DEBUG 01-07 14:54:32.754707.754707 lmp.py:767]   Expert  0 |    113 | CPU
DEBUG 01-07 14:54:32.754634.754634 lmp.py:767]   Expert 37 |    117 | CPU
DEBUG 01-07 14:54:32.754324.754324 lmp.py:767]   Expert 27 |    121 | CPU
DEBUG 01-07 14:54:32.754013.754013 lmp.py:767]   Expert 32 |    123 | CPU
DEBUG 01-07 14:54:32.754941.754941 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 14:54:32.754391.754391 lmp.py:767]   Expert 44 |    131 | CPU
DEBUG 01-07 14:54:32.754842.754842 lmp.py:767]   Expert 28 |    136 | CPU
DEBUG 01-07 14:54:32.754724.754724 lmp.py:767]   Expert 13 |    138 | CPU
DEBUG 01-07 14:54:32.754651.754651 lmp.py:767]   Expert 58 |    140 | CPU
DEBUG 01-07 14:54:32.754202.754202 lmp.py:767]   Expert 60 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.754798.754798 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.754680.754680 lmp.py:767]   Expert  1 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.754323.754323 lmp.py:767]   Expert 38 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.754966.754966 lmp.py:767]   Expert 49 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.754370.754370 lmp.py:767]   Expert 51 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.754013.754013 lmp.py:767]   Expert 34 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.754895.754895 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.754538.754538 lmp.py:767]   Expert 36 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755181.755181 lmp.py:767]   Expert 11 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755539.755539 lmp.py:767]   Expert 17 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755612.755612 lmp.py:767]   Expert 59 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755686.755686 lmp.py:767]   Expert 10 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755567.755567 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755210.755210 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755615.755615 lmp.py:767]   Expert 39 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755258.755258 lmp.py:767]   Expert 33 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755901.755901 lmp.py:767]   Expert 12 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755305.755305 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755710.755710 lmp.py:767]   Expert 48 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755114.755114 lmp.py:767]   Expert 15 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755757.755757 lmp.py:767]   Expert 53 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755400.755400 lmp.py:767]   Expert 19 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755282.755282 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755878.755878 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755190.755190 lmp.py:767]   Expert 45 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755072.755072 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755715.755715 lmp.py:767]   Expert  4 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755119.755119 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755001.755001 lmp.py:767]   Expert 42 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755405.755405 lmp.py:767]   Expert 50 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755048.755048 lmp.py:767]   Expert 29 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755453.755453 lmp.py:767]   Expert 56 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755857.755857 lmp.py:767]   Expert 61 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755500.755500 lmp.py:767]   Expert  8 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755243.755243 lmp.py:767]   Expert 63 |    285 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755793.755793 lmp.py:767]   Expert 46 |    294 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755628.755628 lmp.py:767]   Expert  9 |    300 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755509.755509 lmp.py:767]   Expert  6 |    316 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755676.755676 lmp.py:767]   Expert 16 |    316 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755080.755080 lmp.py:767]   Expert 40 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755723.755723 lmp.py:767]   Expert  7 |    322 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755128.755128 lmp.py:767]   Expert 23 |    325 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755532.755532 lmp.py:767]   Expert 14 |    413 | GPU1(cuda:2)
DEBUG 01-07 14:54:32.755937.755937 lmp.py:767]   Expert 57 |    464 | GPU0(cuda:1)
DEBUG 01-07 14:54:32.755580.755580 lmp.py:769] 
DEBUG 01-07 14:54:32.755580.755580 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:32.755938.755938 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 14:54:32.755965.755965 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 14:54:32.755608.755608 lmp.py:774]   cuda:2:   5088 tokens (22 experts)
DEBUG 01-07 14:54:32.755536.755536 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 14:54:32.755748.755748 lmp.py:776] ============================================================
DEBUG 01-07 14:54:32.755748.755748 lmp.py:776] 
DEBUG 01-07 14:54:32.755021.755021 cuda_h.py:19] end experts_map_get cost 0.0017862319946289062 seconds
DEBUG 01-07 14:54:32.755379.755379 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:32.755347.755347 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:32.757849.757849 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:32.758538.758538 cuda_h.py:19] end allocate_cuda_memory cost 0.0003142356872558594 seconds
DEBUG 01-07 14:54:32.758408.758408 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:32.758787.758787 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:32.758133.758133 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:32.758312.758312 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95d62219-c0b3-47ad-a03e-e4d1fb51516e
DEBUG 01-07 14:54:32.758305.758305 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:32.760374.760374 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95d62219-c0b3-47ad-a03e-e4d1fb51516e
DEBUG 01-07 14:54:32.760985.760985 cuda_h.py:19] end load_into_gpu_async cost 0.002357006072998047 seconds
DEBUG 01-07 14:54:32.760734.760734 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:32.761722.761722 cuda_h.py:19] end restore_tensors2 cost 0.00021195411682128906 seconds
DEBUG 01-07 14:54:32.761584.761584 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005279064178466797 seconds
DEBUG 01-07 14:54:32.761956.761956 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:32.763527.763527 cuda_h.py:19] end restore2model cost 0.0019712448120117188 seconds
DEBUG 01-07 14:54:32.763867.763867 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:32.763559.763559 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:32.910756.910756 cuda_h.py:19] end allocate_cuda_memory cost 0.1472015380859375 seconds
DEBUG 01-07 14:54:32.910111.910111 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:32.911075.911075 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:32.911185.911185 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:32.911578.911578 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 78c44941-4ba9-4c34-ab3c-5f660523b59e
DEBUG 01-07 14:54:32.911103.911103 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:32.913067.913067 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 78c44941-4ba9-4c34-ab3c-5f660523b59e
DEBUG 01-07 14:54:32.913315.913315 cuda_h.py:19] end load_into_gpu_async cost 0.002613067626953125 seconds
DEBUG 01-07 14:54:32.913309.913309 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:32.913000.913000 cuda_h.py:19] end restore_tensors2 cost 0.0002353191375732422 seconds
DEBUG 01-07 14:54:32.914531.914531 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.150742769241333 seconds
DEBUG 01-07 14:54:32.914678.914678 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:32.915769.915769 cuda_h.py:19] end restore2model cost 0.0018966197967529297 seconds
DEBUG 01-07 14:54:32.916950.916950 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.1602308750152588 seconds
DEBUG 01-07 14:54:32.916938.916938 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:32.926595.926595 lmp.py:816] 
DEBUG 01-07 14:54:32.926595.926595 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:32.926725.926725 cuda_h.py:19] end cpu_experts_submit cost 0.010628223419189453 seconds
DEBUG 01-07 14:54:32.926289.926289 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:32.939308.939308 mlpmodule.py:749] group tensors cost 0.01295018196105957 s
DEBUG 01-07 14:54:32.942695.942695 mlpmodule.py:787] pad cost 0.0014231204986572266 s
DEBUG 01-07 14:54:32.942911.942911 mlpmodule.py:793] create cpu tensor cost 5.602836608886719e-05 s
DEBUG 01-07 14:54:32.942040.942040 mlpmodule.py:798] move to cpu cost 4.482269287109375e-05 s
DEBUG 01-07 14:54:32.977574.977574 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:32.978888.978888 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:32.978877.978877 mlpmodule.py:818] group_w3 first element: -0.0107421875
WARNING 01-07 14:54:32.978157.978157 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.010894.010894 mlpmodule.py:838] group einsum cost 0.06773805618286133 s
DEBUG 01-07 14:54:33.011664.011664 mlpmodule.py:846] cpy2cputensor cost 0.00040793418884277344 s
DEBUG 01-07 14:54:33.016987.016987 cuda_h.py:19] end wait_cetm_experts cost 0.0899808406829834 seconds
DEBUG 01-07 14:54:33.017093.017093 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.017917.017917 cuda_h.py:19] end gpu_sexperts cost 0.0006220340728759766 seconds
DEBUG 01-07 14:54:33.017523.017523 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.017340.017340 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-07 14:54:33.017341.017341 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.017111.017111 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95d62219-c0b3-47ad-a03e-e4d1fb51516e
INFO 01-07 14:54:33.018493.018493 client.py:127] Model loaded
INFO 01-07 14:54:33.018191.018191 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 78c44941-4ba9-4c34-ab3c-5f660523b59e
INFO 01-07 14:54:33.019568.019568 client.py:127] Model loaded
DEBUG 01-07 14:54:33.019927.019927 cuda_h.py:19] end wait_experts_multi_device cost 0.0014462471008300781 seconds
DEBUG 01-07 14:54:33.019776.019776 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.019506.019506 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:33.024002.024002 mlpmodule.py:707]  experts func einsum cost 0.0972597599029541 s
DEBUG 01-07 14:54:33.038451.038451 mlpmodule.py:533] gpu group tensors cost 0.002828359603881836 s
DEBUG 01-07 14:54:33.049182.049182 mlpmodule.py:566] gpu pad cost 0.011286497116088867 s
DEBUG 01-07 14:54:33.107777.107777 mlpmodule.py:584] gpu group einsum cost 0.057665109634399414 s
DEBUG 01-07 14:54:33.111980.111980 mlpmodule.py:656] gpu experts func einsum cost 0.07600688934326172 s
DEBUG 01-07 14:54:33.111555.111555 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:33.113332.113332 mlpmodule.py:533] gpu group tensors cost 0.0009021759033203125 s
DEBUG 01-07 14:54:33.114383.114383 mlpmodule.py:566] gpu pad cost 0.0010652542114257812 s
DEBUG 01-07 14:54:33.115284.115284 mlpmodule.py:584] gpu group einsum cost 0.0007374286651611328 s
DEBUG 01-07 14:54:33.116076.116076 mlpmodule.py:656] gpu experts func einsum cost 0.0045435428619384766 s
DEBUG 01-07 14:54:33.116298.116298 cuda_h.py:19] end gpu_experts_multi_device cost 0.09744024276733398 seconds
DEBUG 01-07 14:54:33.116698.116698 cuda_h.py:19] end layer_moe_generate_multi_device_1 cost 0.460186243057251 seconds
DEBUG 01-07 14:54:33.117002.117002 lmp.py:194] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-07 14:54:33.117057.117057 lmp.py:153] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-07 14:54:33.117706.117706 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 14:54:33.117893.117893 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 14:54:33.117021.117021 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.337860107421875e-05 seconds
DEBUG 01-07 14:54:33.117585.117585 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.341934204101562e-05 seconds
DEBUG 01-07 14:54:33.117327.117327 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.117660.117660 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.117890.117890 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.117865.117865 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.117493.117493 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.118960.118960 cuda_h.py:19] end allocate_cuda_memory cost 0.00023627281188964844 seconds
DEBUG 01-07 14:54:33.118633.118633 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.118503.118503 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.118267.118267 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.118043.118043 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e792d21f-6f32-4d6a-9cce-e3db6d0d074d
DEBUG 01-07 14:54:33.118882.118882 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.118910.118910 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.120258.120258 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e792d21f-6f32-4d6a-9cce-e3db6d0d074d
DEBUG 01-07 14:54:33.120725.120725 cuda_h.py:19] end load_into_gpu_async cost 0.001882791519165039 seconds
DEBUG 01-07 14:54:33.120038.120038 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.120864.120864 cuda_h.py:19] end restore_tensors2 cost 9.5367431640625e-05 seconds
DEBUG 01-07 14:54:33.120542.120542 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026960372924804688 seconds
INFO 01-07 14:54:33.120029.120029 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e792d21f-6f32-4d6a-9cce-e3db6d0d074d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.122549.122549 cuda_h.py:19] end self_attn cost 0.0032122135162353516 seconds
DEBUG 01-07 14:54:33.122262.122262 cuda_h.py:19] end iln_self_attn_paln cost 0.004937410354614258 seconds
DEBUG 01-07 14:54:33.122568.122568 cuda_h.py:10] start layer_moe_generate_multi_device_2
DEBUG 01-07 14:54:33.122231.122231 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.123831.123831 cuda_h.py:19] end gate cost 0.0006480216979980469 seconds
DEBUG 01-07 14:54:33.123137.123137 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.123171.123171 lmp.py:744] 
DEBUG 01-07 14:54:33.123171.123171 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.123172.123172 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.123967.123967 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.123663.123663 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.123691.123691 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.123049.123049 lmp.py:749] 
DEBUG 01-07 14:54:33.123049.123049 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.123930.123930 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.123534.123534 lmp.py:767]   Expert 58 |     50 | CPU
DEBUG 01-07 14:54:33.123415.123415 lmp.py:767]   Expert 27 |     56 | CPU
DEBUG 01-07 14:54:33.123820.123820 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 14:54:33.123986.123986 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 14:54:33.123152.123152 lmp.py:767]   Expert 24 |     86 | CPU
DEBUG 01-07 14:54:33.123556.123556 lmp.py:767]   Expert  0 |     88 | CPU
DEBUG 01-07 14:54:33.123484.123484 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 14:54:33.123173.123173 lmp.py:767]   Expert 34 |    116 | CPU
DEBUG 01-07 14:54:33.123578.123578 lmp.py:767]   Expert 51 |    118 | CPU
DEBUG 01-07 14:54:33.123459.123459 lmp.py:767]   Expert 32 |    120 | CPU
DEBUG 01-07 14:54:33.123917.123917 lmp.py:767]   Expert  9 |    130 | CPU
DEBUG 01-07 14:54:33.123752.123752 lmp.py:767]   Expert 15 |    134 | CPU
DEBUG 01-07 14:54:33.123064.123064 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 14:54:33.123422.123422 lmp.py:767]   Expert 23 |    136 | CPU
DEBUG 01-07 14:54:33.123065.123065 lmp.py:767]   Expert 26 |    138 | CPU
DEBUG 01-07 14:54:33.124423.124423 lmp.py:767]   Expert 30 |    144 | CPU
DEBUG 01-07 14:54:33.124305.124305 lmp.py:767]   Expert 45 |    146 | CPU
DEBUG 01-07 14:54:33.124425.124425 lmp.py:767]   Expert 62 |    147 | CPU
DEBUG 01-07 14:54:33.124306.124306 lmp.py:767]   Expert 57 |    150 | CPU
DEBUG 01-07 14:54:33.124095.124095 lmp.py:767]   Expert  1 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124407.124407 lmp.py:767]   Expert 36 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124149.124149 lmp.py:767]   Expert  8 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124653.124653 lmp.py:767]   Expert 29 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124919.124919 lmp.py:767]   Expert 25 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124681.124681 lmp.py:767]   Expert 54 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124755.124755 lmp.py:767]   Expert  6 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124636.124636 lmp.py:767]   Expert 49 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124041.124041 lmp.py:767]   Expert 48 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124161.124161 lmp.py:767]   Expert 12 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124804.124804 lmp.py:767]   Expert 35 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124447.124447 lmp.py:767]   Expert 37 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124851.124851 lmp.py:767]   Expert 60 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124971.124971 lmp.py:767]   Expert 13 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124283.124283 lmp.py:767]   Expert 53 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124277.124277 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124543.124543 lmp.py:767]   Expert 10 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124186.124186 lmp.py:767]   Expert 16 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124359.124359 lmp.py:767]   Expert 21 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124240.124240 lmp.py:767]   Expert 40 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124122.124122 lmp.py:767]   Expert 43 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124526.124526 lmp.py:767]   Expert 38 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124931.124931 lmp.py:767]   Expert  5 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124097.124097 lmp.py:767]   Expert 44 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124501.124501 lmp.py:767]   Expert 52 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124906.124906 lmp.py:767]   Expert 41 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124549.124549 lmp.py:767]   Expert 50 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124953.124953 lmp.py:767]   Expert 19 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124120.124120 lmp.py:767]   Expert  4 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124524.124524 lmp.py:767]   Expert 59 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124690.124690 lmp.py:767]   Expert 55 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124095.124095 lmp.py:767]   Expert 31 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124738.124738 lmp.py:767]   Expert 56 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124335.124335 lmp.py:767]   Expert 20 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124170.124170 lmp.py:767]   Expert 39 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124866.124866 lmp.py:767]   Expert 22 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124701.124701 lmp.py:767]   Expert  2 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124344.124344 lmp.py:767]   Expert 63 |    275 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124748.124748 lmp.py:767]   Expert 47 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124153.124153 lmp.py:767]   Expert 42 |    303 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124557.124557 lmp.py:767]   Expert 18 |    315 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124962.124962 lmp.py:767]   Expert 14 |    319 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124366.124366 lmp.py:767]   Expert 46 |    367 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124771.124771 lmp.py:767]   Expert 11 |    388 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.124414.124414 lmp.py:767]   Expert 61 |    460 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.124626.124626 lmp.py:769] 
DEBUG 01-07 14:54:33.124626.124626 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.124177.124177 lmp.py:770]   CPU:   2151 tokens
DEBUG 01-07 14:54:33.124204.124204 lmp.py:774]   cuda:1:   4994 tokens (22 experts)
DEBUG 01-07 14:54:33.124277.124277 lmp.py:774]   cuda:2:   5143 tokens (23 experts)
DEBUG 01-07 14:54:33.125682.125682 lmp.py:775]   Total GPU:  10137 tokens
DEBUG 01-07 14:54:33.125133.125133 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.125133.125133 lmp.py:776] 
DEBUG 01-07 14:54:33.125736.125736 cuda_h.py:19] end experts_map_get cost 0.001850128173828125 seconds
DEBUG 01-07 14:54:33.125618.125618 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.125056.125056 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.125901.125901 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.126165.126165 cuda_h.py:19] end allocate_cuda_memory cost 0.0011453628540039062 seconds
DEBUG 01-07 14:54:33.126346.126346 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.126294.126294 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.126825.126825 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.126574.126574 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 315767c7-f5e2-490b-8c73-640668cad8b7
DEBUG 01-07 14:54:33.126904.126904 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.128795.128795 client.py:127] Model loaded
DEBUG 01-07 14:54:33.128593.128593 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.129065.129065 cuda_h.py:19] end restore2model cost 0.0007638931274414062 seconds
DEBUG 01-07 14:54:33.129624.129624 cuda_h.py:19] end sllm_worker_task cost 0.011592864990234375 seconds
INFO 01-07 14:54:33.129288.129288 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 315767c7-f5e2-490b-8c73-640668cad8b7
DEBUG 01-07 14:54:33.129807.129807 cuda_h.py:19] end load_into_gpu_async cost 0.0030438899993896484 seconds
DEBUG 01-07 14:54:33.129748.129748 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.129225.129225 cuda_h.py:19] end restore_tensors2 cost 0.0001862049102783203 seconds
DEBUG 01-07 14:54:33.129180.129180 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004668712615966797 seconds
DEBUG 01-07 14:54:33.129605.129605 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.131051.131051 cuda_h.py:19] end restore2model cost 0.001810312271118164 seconds
DEBUG 01-07 14:54:33.131815.131815 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.131805.131805 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.132037.132037 cuda_h.py:19] end allocate_cuda_memory cost 0.0001704692840576172 seconds
DEBUG 01-07 14:54:33.132211.132211 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.132298.132298 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.132246.132246 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.132472.132472 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80488a02-cc74-49d0-bb23-8f833de142d4
DEBUG 01-07 14:54:33.132503.132503 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.133635.133635 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80488a02-cc74-49d0-bb23-8f833de142d4
DEBUG 01-07 14:54:33.133134.133134 cuda_h.py:19] end load_into_gpu_async cost 0.0018074512481689453 seconds
DEBUG 01-07 14:54:33.133691.133691 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.134420.134420 cuda_h.py:19] end restore_tensors2 cost 0.0001976490020751953 seconds
DEBUG 01-07 14:54:33.134328.134328 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024573802947998047 seconds
DEBUG 01-07 14:54:33.134177.134177 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.136996.136996 cuda_h.py:19] end restore2model cost 0.0018742084503173828 seconds
DEBUG 01-07 14:54:33.136163.136163 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.011125326156616211 seconds
DEBUG 01-07 14:54:33.136959.136959 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.136644.136644 lmp.py:816] 
DEBUG 01-07 14:54:33.136644.136644 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.136686.136686 cuda_h.py:19] end cpu_experts_submit cost 0.00011563301086425781 seconds
DEBUG 01-07 14:54:33.136243.136243 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.145789.145789 mlpmodule.py:749] group tensors cost 0.008792638778686523 s
DEBUG 01-07 14:54:33.147540.147540 mlpmodule.py:787] pad cost 0.001760244369506836 s
DEBUG 01-07 14:54:33.148559.148559 mlpmodule.py:793] create cpu tensor cost 6.318092346191406e-05 s
DEBUG 01-07 14:54:33.148046.148046 mlpmodule.py:798] move to cpu cost 4.935264587402344e-05 s
DEBUG 01-07 14:54:33.157356.157356 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.157322.157322 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.157419.157419 mlpmodule.py:818] group_w3 first element: -0.0380859375
WARNING 01-07 14:54:33.158079.158079 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.174314.174314 mlpmodule.py:838] group einsum cost 0.026287555694580078 s
DEBUG 01-07 14:54:33.175672.175672 mlpmodule.py:846] cpy2cputensor cost 0.0003898143768310547 s
DEBUG 01-07 14:54:33.177348.177348 cuda_h.py:19] end wait_cetm_experts cost 0.041464805603027344 seconds
DEBUG 01-07 14:54:33.178232.178232 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.178224.178224 cuda_h.py:19] end gpu_sexperts cost 0.0005104541778564453 seconds
DEBUG 01-07 14:54:33.178643.178643 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.178606.178606 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4809112548828125e-05 seconds
DEBUG 01-07 14:54:33.178647.178647 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.178548.178548 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 315767c7-f5e2-490b-8c73-640668cad8b7
INFO 01-07 14:54:33.179453.179453 client.py:127] Model loaded
INFO 01-07 14:54:33.179097.179097 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80488a02-cc74-49d0-bb23-8f833de142d4
INFO 01-07 14:54:33.180521.180521 client.py:127] Model loaded
DEBUG 01-07 14:54:33.180065.180065 cuda_h.py:19] end wait_experts_multi_device cost 0.0014009475708007812 seconds
DEBUG 01-07 14:54:33.180868.180868 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.180982.180982 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.185578.185578 mlpmodule.py:707]  experts func einsum cost 0.04919290542602539 s
DEBUG 01-07 14:54:33.186331.186331 mlpmodule.py:533] gpu group tensors cost 0.005172014236450195 s
DEBUG 01-07 14:54:33.187250.187250 mlpmodule.py:566] gpu pad cost 0.0012657642364501953 s
DEBUG 01-07 14:54:33.188648.188648 mlpmodule.py:584] gpu group einsum cost 0.0005424022674560547 s
DEBUG 01-07 14:54:33.190511.190511 mlpmodule.py:656] gpu experts func einsum cost 0.009172439575195312 s
DEBUG 01-07 14:54:33.190785.190785 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.191594.191594 mlpmodule.py:533] gpu group tensors cost 0.0003750324249267578 s
DEBUG 01-07 14:54:33.192955.192955 mlpmodule.py:566] gpu pad cost 0.0010170936584472656 s
DEBUG 01-07 14:54:33.192125.192125 mlpmodule.py:584] gpu group einsum cost 0.0006635189056396484 s
DEBUG 01-07 14:54:33.194782.194782 mlpmodule.py:656] gpu experts func einsum cost 0.0038149356842041016 s
DEBUG 01-07 14:54:33.194183.194183 cuda_h.py:19] end gpu_experts_multi_device cost 0.014317989349365234 seconds
DEBUG 01-07 14:54:33.194550.194550 cuda_h.py:19] end layer_moe_generate_multi_device_2 cost 0.07221841812133789 seconds
DEBUG 01-07 14:54:33.194232.194232 lmp.py:194] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-07 14:54:33.194300.194300 lmp.py:153] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-07 14:54:33.194519.194519 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 14:54:33.194136.194136 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 14:54:33.194072.194072 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:33.195821.195821 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.888938903808594e-05 seconds
DEBUG 01-07 14:54:33.195418.195418 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.195214.195214 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.195826.195826 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.195126.195126 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.195817.195817 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.195904.195904 cuda_h.py:19] end allocate_cuda_memory cost 0.00020599365234375 seconds
DEBUG 01-07 14:54:33.195132.195132 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.195841.195841 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.195995.195995 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.195791.195791 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea3241e9-f7f2-48eb-98db-80bb09199de4
DEBUG 01-07 14:54:33.195608.195608 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.196285.196285 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.196677.196677 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea3241e9-f7f2-48eb-98db-80bb09199de4
DEBUG 01-07 14:54:33.196036.196036 cuda_h.py:19] end load_into_gpu_async cost 0.0008797645568847656 seconds
DEBUG 01-07 14:54:33.196739.196739 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.196769.196769 cuda_h.py:19] end restore_tensors2 cost 6.341934204101562e-05 seconds
DEBUG 01-07 14:54:33.196002.196002 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013835430145263672 seconds
INFO 01-07 14:54:33.196745.196745 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea3241e9-f7f2-48eb-98db-80bb09199de4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.199252.199252 cuda_h.py:19] end self_attn cost 0.0037000179290771484 seconds
DEBUG 01-07 14:54:33.200766.200766 cuda_h.py:19] end iln_self_attn_paln cost 0.0050373077392578125 seconds
DEBUG 01-07 14:54:33.200072.200072 cuda_h.py:10] start layer_moe_generate_multi_device_3
DEBUG 01-07 14:54:33.200643.200643 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.200448.200448 cuda_h.py:19] end gate cost 0.0006630420684814453 seconds
DEBUG 01-07 14:54:33.200470.200470 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.201841.201841 lmp.py:744] 
DEBUG 01-07 14:54:33.201841.201841 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.201696.201696 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.201730.201730 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.201950.201950 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.201785.201785 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.201143.201143 lmp.py:749] 
DEBUG 01-07 14:54:33.201143.201143 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.201501.201501 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.201535.201535 lmp.py:767]   Expert  1 |     50 | CPU
DEBUG 01-07 14:54:33.201370.201370 lmp.py:767]   Expert 27 |     62 | CPU
DEBUG 01-07 14:54:33.201967.201967 lmp.py:767]   Expert  7 |     75 | CPU
DEBUG 01-07 14:54:33.201563.201563 lmp.py:767]   Expert 48 |     82 | CPU
DEBUG 01-07 14:54:33.201683.201683 lmp.py:767]   Expert 15 |     98 | CPU
DEBUG 01-07 14:54:33.201326.201326 lmp.py:767]   Expert 30 |    110 | CPU
DEBUG 01-07 14:54:33.201208.201208 lmp.py:767]   Expert 32 |    117 | CPU
DEBUG 01-07 14:54:33.201612.201612 lmp.py:767]   Expert 61 |    117 | CPU
DEBUG 01-07 14:54:33.201255.201255 lmp.py:767]   Expert 45 |    118 | CPU
DEBUG 01-07 14:54:33.201898.201898 lmp.py:767]   Expert 18 |    119 | CPU
DEBUG 01-07 14:54:33.201780.201780 lmp.py:767]   Expert 34 |    133 | CPU
DEBUG 01-07 14:54:33.201423.201423 lmp.py:767]   Expert 39 |    134 | CPU
DEBUG 01-07 14:54:33.201589.201589 lmp.py:767]   Expert 36 |    138 | CPU
DEBUG 01-07 14:54:33.201755.201755 lmp.py:767]   Expert 11 |    139 | CPU
DEBUG 01-07 14:54:33.201159.201159 lmp.py:767]   Expert 26 |    139 | CPU
DEBUG 01-07 14:54:33.201564.201564 lmp.py:767]   Expert  5 |    140 | CPU
DEBUG 01-07 14:54:33.201730.201730 lmp.py:767]   Expert  6 |    143 | CPU
DEBUG 01-07 14:54:33.201611.201611 lmp.py:767]   Expert 59 |    143 | CPU
DEBUG 01-07 14:54:33.201493.201493 lmp.py:767]   Expert 51 |    145 | CPU
DEBUG 01-07 14:54:33.201805.201805 lmp.py:767]   Expert 49 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.201163.201163 lmp.py:767]   Expert 23 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.201998.201998 lmp.py:767]   Expert  2 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.201310.201310 lmp.py:767]   Expert  9 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.201145.201145 lmp.py:767]   Expert 50 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.201742.201742 lmp.py:767]   Expert 56 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.201054.201054 lmp.py:767]   Expert 40 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.201889.201889 lmp.py:767]   Expert 52 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202247.202247 lmp.py:767]   Expert 16 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202844.202844 lmp.py:767]   Expert 35 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202202.202202 lmp.py:767]   Expert  4 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202560.202560 lmp.py:767]   Expert 13 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202395.202395 lmp.py:767]   Expert 37 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202230.202230 lmp.py:767]   Expert 42 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202304.202304 lmp.py:767]   Expert 17 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202900.202900 lmp.py:767]   Expert 38 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202258.202258 lmp.py:767]   Expert 62 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202855.202855 lmp.py:767]   Expert 21 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202213.202213 lmp.py:767]   Expert  3 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202095.202095 lmp.py:767]   Expert 44 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202453.202453 lmp.py:767]   Expert 28 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202288.202288 lmp.py:767]   Expert 60 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202123.202123 lmp.py:767]   Expert 58 |    213 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202481.202481 lmp.py:767]   Expert 10 |    214 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202840.202840 lmp.py:767]   Expert 47 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202959.202959 lmp.py:767]   Expert 53 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202318.202318 lmp.py:767]   Expert 55 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202206.202206 lmp.py:767]   Expert 20 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202326.202326 lmp.py:767]   Expert 57 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202730.202730 lmp.py:767]   Expert 33 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202135.202135 lmp.py:767]   Expert 31 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202539.202539 lmp.py:767]   Expert 46 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202944.202944 lmp.py:767]   Expert  8 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202348.202348 lmp.py:767]   Expert 19 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202230.202230 lmp.py:767]   Expert 24 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202111.202111 lmp.py:767]   Expert 14 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202516.202516 lmp.py:767]   Expert 63 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202920.202920 lmp.py:767]   Expert 29 |    275 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202325.202325 lmp.py:767]   Expert 12 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202491.202491 lmp.py:767]   Expert 22 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202896.202896 lmp.py:767]   Expert  0 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202777.202777 lmp.py:767]   Expert 43 |    311 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202658.202658 lmp.py:767]   Expert 54 |    341 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202063.202063 lmp.py:767]   Expert 41 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.202467.202467 lmp.py:767]   Expert 25 |    413 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.202680.202680 lmp.py:769] 
DEBUG 01-07 14:54:33.202680.202680 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.202846.202846 lmp.py:770]   CPU:   2202 tokens
DEBUG 01-07 14:54:33.202204.202204 lmp.py:774]   cuda:1:   4967 tokens (22 experts)
DEBUG 01-07 14:54:33.202370.202370 lmp.py:774]   cuda:2:   5119 tokens (23 experts)
DEBUG 01-07 14:54:33.202060.202060 lmp.py:775]   Total GPU:  10086 tokens
DEBUG 01-07 14:54:33.202226.202226 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.202226.202226 lmp.py:776] 
DEBUG 01-07 14:54:33.202114.202114 cuda_h.py:19] end experts_map_get cost 0.0018155574798583984 seconds
DEBUG 01-07 14:54:33.202995.202995 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.202957.202957 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.202947.202947 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.203450.203450 cuda_h.py:19] end allocate_cuda_memory cost 0.00016379356384277344 seconds
DEBUG 01-07 14:54:33.203486.203486 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.203288.203288 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.203812.203812 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.203893.203893 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, faf3ec60-7d61-4d06-880d-40dbcf3e2b22
DEBUG 01-07 14:54:33.203930.203930 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.203173.203173 client.py:127] Model loaded
DEBUG 01-07 14:54:33.203963.203963 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.203962.203962 cuda_h.py:19] end restore2model cost 0.0003170967102050781 seconds
DEBUG 01-07 14:54:33.204824.204824 cuda_h.py:19] end sllm_worker_task cost 0.008771896362304688 seconds
INFO 01-07 14:54:33.204220.204220 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, faf3ec60-7d61-4d06-880d-40dbcf3e2b22
DEBUG 01-07 14:54:33.204963.204963 cuda_h.py:19] end load_into_gpu_async cost 0.0009870529174804688 seconds
DEBUG 01-07 14:54:33.204520.204520 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.204356.204356 cuda_h.py:19] end restore_tensors2 cost 0.00020575523376464844 seconds
DEBUG 01-07 14:54:33.204795.204795 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016450881958007812 seconds
DEBUG 01-07 14:54:33.204789.204789 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.206711.206711 cuda_h.py:19] end restore2model cost 0.0018110275268554688 seconds
DEBUG 01-07 14:54:33.206760.206760 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.206459.206459 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.206685.206685 cuda_h.py:19] end allocate_cuda_memory cost 0.00020265579223632812 seconds
DEBUG 01-07 14:54:33.206621.206621 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.206423.206423 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.206610.206610 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.206021.206021 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 020b0bd6-02dd-4934-a41d-635daed884cc
DEBUG 01-07 14:54:33.207476.207476 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.208786.208786 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 020b0bd6-02dd-4934-a41d-635daed884cc
DEBUG 01-07 14:54:33.208662.208662 cuda_h.py:19] end load_into_gpu_async cost 0.001191854476928711 seconds
DEBUG 01-07 14:54:33.208219.208219 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.208856.208856 cuda_h.py:19] end restore_tensors2 cost 0.00019478797912597656 seconds
DEBUG 01-07 14:54:33.208671.208671 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018723011016845703 seconds
DEBUG 01-07 14:54:33.208957.208957 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.210994.210994 cuda_h.py:19] end restore2model cost 0.0018572807312011719 seconds
DEBUG 01-07 14:54:33.210016.210016 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0075070858001708984 seconds
DEBUG 01-07 14:54:33.210765.210765 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.210397.210397 lmp.py:816] 
DEBUG 01-07 14:54:33.210397.210397 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.210471.210471 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-07 14:54:33.210598.210598 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.215480.215480 mlpmodule.py:749] group tensors cost 0.0046694278717041016 s
DEBUG 01-07 14:54:33.217319.217319 mlpmodule.py:787] pad cost 0.00135040283203125 s
DEBUG 01-07 14:54:33.217151.217151 mlpmodule.py:793] create cpu tensor cost 4.9591064453125e-05 s
DEBUG 01-07 14:54:33.217949.217949 mlpmodule.py:798] move to cpu cost 4.57763671875e-05 s
DEBUG 01-07 14:54:33.227807.227807 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.227674.227674 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.227863.227863 mlpmodule.py:818] group_w3 first element: -0.054931640625
WARNING 01-07 14:54:33.227808.227808 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.243956.243956 mlpmodule.py:838] group einsum cost 0.025824785232543945 s
DEBUG 01-07 14:54:33.244077.244077 mlpmodule.py:846] cpy2cputensor cost 0.00044655799865722656 s
DEBUG 01-07 14:54:33.246582.246582 cuda_h.py:19] end wait_cetm_experts cost 0.036249399185180664 seconds
DEBUG 01-07 14:54:33.246174.246174 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.247285.247285 cuda_h.py:19] end gpu_sexperts cost 0.0004944801330566406 seconds
DEBUG 01-07 14:54:33.247697.247697 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.247686.247686 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.288818359375e-05 seconds
DEBUG 01-07 14:54:33.247919.247919 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.247443.247443 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, faf3ec60-7d61-4d06-880d-40dbcf3e2b22
INFO 01-07 14:54:33.248571.248571 client.py:127] Model loaded
INFO 01-07 14:54:33.248169.248169 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 020b0bd6-02dd-4934-a41d-635daed884cc
INFO 01-07 14:54:33.249622.249622 client.py:127] Model loaded
DEBUG 01-07 14:54:33.249068.249068 cuda_h.py:19] end wait_experts_multi_device cost 0.0014467239379882812 seconds
DEBUG 01-07 14:54:33.249678.249678 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.249355.249355 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.250122.250122 mlpmodule.py:533] gpu group tensors cost 0.0004942417144775391 s
DEBUG 01-07 14:54:33.251452.251452 mlpmodule.py:566] gpu pad cost 0.0012693405151367188 s
DEBUG 01-07 14:54:33.252095.252095 mlpmodule.py:584] gpu group einsum cost 0.0005490779876708984 s
DEBUG 01-07 14:54:33.254384.254384 mlpmodule.py:656] gpu experts func einsum cost 0.004550457000732422 s
DEBUG 01-07 14:54:33.254917.254917 mlpmodule.py:707]  experts func einsum cost 0.04401803016662598 s
DEBUG 01-07 14:54:33.254742.254742 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.255078.255078 mlpmodule.py:533] gpu group tensors cost 0.00043582916259765625 s
DEBUG 01-07 14:54:33.256869.256869 mlpmodule.py:566] gpu pad cost 0.001226663589477539 s
DEBUG 01-07 14:54:33.257151.257151 mlpmodule.py:584] gpu group einsum cost 0.0006306171417236328 s
DEBUG 01-07 14:54:33.259033.259033 mlpmodule.py:656] gpu experts func einsum cost 0.004230499267578125 s
DEBUG 01-07 14:54:33.259440.259440 cuda_h.py:19] end gpu_experts_multi_device cost 0.010259389877319336 seconds
DEBUG 01-07 14:54:33.259694.259694 cuda_h.py:19] end layer_moe_generate_multi_device_3 cost 0.059274911880493164 seconds
DEBUG 01-07 14:54:33.259614.259614 lmp.py:194] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-07 14:54:33.259953.259953 lmp.py:153] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-07 14:54:33.259603.259603 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 14:54:33.259935.259935 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 14:54:33.259481.259481 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 14:54:33.259184.259184 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 8.988380432128906e-05 seconds
DEBUG 01-07 14:54:33.259403.259403 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.259147.259147 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.260288.260288 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.260827.260827 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.260273.260273 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.260003.260003 cuda_h.py:19] end allocate_cuda_memory cost 0.0002124309539794922 seconds
DEBUG 01-07 14:54:33.260986.260986 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.260034.260034 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.260141.260141 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.260129.260129 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a0d6dff6-f496-46f5-b50a-715337fc7371
DEBUG 01-07 14:54:33.260092.260092 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.260000.260000 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.261219.261219 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a0d6dff6-f496-46f5-b50a-715337fc7371
DEBUG 01-07 14:54:33.261578.261578 cuda_h.py:19] end load_into_gpu_async cost 0.0008220672607421875 seconds
DEBUG 01-07 14:54:33.261182.261182 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.261317.261317 cuda_h.py:19] end restore_tensors2 cost 6.222724914550781e-05 seconds
DEBUG 01-07 14:54:33.261120.261120 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013794898986816406 seconds
INFO 01-07 14:54:33.261519.261519 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a0d6dff6-f496-46f5-b50a-715337fc7371
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.264210.264210 cuda_h.py:19] end self_attn cost 0.003637552261352539 seconds
DEBUG 01-07 14:54:33.264247.264247 cuda_h.py:19] end iln_self_attn_paln cost 0.004981040954589844 seconds
DEBUG 01-07 14:54:33.264460.264460 cuda_h.py:10] start layer_moe_generate_multi_device_4
DEBUG 01-07 14:54:33.264362.264362 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.265378.265378 cuda_h.py:19] end gate cost 0.0006458759307861328 seconds
DEBUG 01-07 14:54:33.265969.265969 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.266049.266049 lmp.py:744] 
DEBUG 01-07 14:54:33.266049.266049 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.266381.266381 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.266177.266177 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.266158.266158 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.266754.266754 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.266636.266636 lmp.py:749] 
DEBUG 01-07 14:54:33.266636.266636 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.266994.266994 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.266505.266505 lmp.py:767]   Expert 14 |     63 | CPU
DEBUG 01-07 14:54:33.266578.266578 lmp.py:767]   Expert 57 |     72 | CPU
DEBUG 01-07 14:54:33.266937.266937 lmp.py:767]   Expert 13 |     76 | CPU
DEBUG 01-07 14:54:33.266295.266295 lmp.py:767]   Expert 26 |     82 | CPU
DEBUG 01-07 14:54:33.266176.266176 lmp.py:767]   Expert 31 |     91 | CPU
DEBUG 01-07 14:54:33.266819.266819 lmp.py:767]   Expert 54 |     91 | CPU
DEBUG 01-07 14:54:33.266224.266224 lmp.py:767]   Expert 11 |     93 | CPU
DEBUG 01-07 14:54:33.266628.266628 lmp.py:767]   Expert 45 |     94 | CPU
DEBUG 01-07 14:54:33.266271.266271 lmp.py:767]   Expert 58 |    103 | CPU
DEBUG 01-07 14:54:33.266676.266676 lmp.py:767]   Expert 51 |    107 | CPU
DEBUG 01-07 14:54:33.266796.266796 lmp.py:767]   Expert 30 |    109 | CPU
DEBUG 01-07 14:54:33.266200.266200 lmp.py:767]   Expert 36 |    110 | CPU
DEBUG 01-07 14:54:33.266605.266605 lmp.py:767]   Expert 10 |    114 | CPU
DEBUG 01-07 14:54:33.266009.266009 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 14:54:33.266652.266652 lmp.py:767]   Expert 20 |    126 | CPU
DEBUG 01-07 14:54:33.266057.266057 lmp.py:767]   Expert  8 |    136 | CPU
DEBUG 01-07 14:54:33.266461.266461 lmp.py:767]   Expert  4 |    138 | CPU
DEBUG 01-07 14:54:33.266104.266104 lmp.py:767]   Expert 63 |    139 | CPU
DEBUG 01-07 14:54:33.266224.266224 lmp.py:767]   Expert 53 |    140 | CPU
DEBUG 01-07 14:54:33.266298.266298 lmp.py:767]   Expert 34 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266086.266086 lmp.py:767]   Expert 61 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266160.266160 lmp.py:767]   Expert 16 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266757.266757 lmp.py:767]   Expert 47 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266876.266876 lmp.py:767]   Expert 28 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266235.266235 lmp.py:767]   Expert 60 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266308.266308 lmp.py:767]   Expert 17 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266905.266905 lmp.py:767]   Expert 42 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266263.266263 lmp.py:767]   Expert 29 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266621.266621 lmp.py:767]   Expert 44 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266979.266979 lmp.py:767]   Expert 27 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266814.266814 lmp.py:767]   Expert  7 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266411.266411 lmp.py:767]   Expert 41 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266292.266292 lmp.py:767]   Expert 48 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266174.266174 lmp.py:767]   Expert 56 |    184 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266532.266532 lmp.py:767]   Expert  9 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266890.266890 lmp.py:767]   Expert  3 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266487.266487 lmp.py:767]   Expert  2 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266084.266084 lmp.py:767]   Expert 15 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.266680.266680 lmp.py:767]   Expert 24 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.266039.266039 lmp.py:767]   Expert  0 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267158.267158 lmp.py:767]   Expert 18 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267278.267278 lmp.py:767]   Expert 55 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267636.267636 lmp.py:767]   Expert 40 |    213 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267233.267233 lmp.py:767]   Expert 23 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267307.267307 lmp.py:767]   Expert 38 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267426.267426 lmp.py:767]   Expert 22 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267785.267785 lmp.py:767]   Expert  6 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267143.267143 lmp.py:767]   Expert 37 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267263.267263 lmp.py:767]   Expert 46 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267813.267813 lmp.py:767]   Expert 19 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267410.267410 lmp.py:767]   Expert 39 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267006.267006 lmp.py:767]   Expert 25 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267841.267841 lmp.py:767]   Expert 12 |    260 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267438.267438 lmp.py:767]   Expert 50 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267796.267796 lmp.py:767]   Expert 62 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267678.267678 lmp.py:767]   Expert 21 |    280 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267797.267797 lmp.py:767]   Expert 35 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267917.267917 lmp.py:767]   Expert 49 |    291 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267037.267037 lmp.py:767]   Expert 33 |    298 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267634.267634 lmp.py:767]   Expert 52 |    299 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267992.267992 lmp.py:767]   Expert  1 |    349 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267112.267112 lmp.py:767]   Expert  5 |    380 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267231.267231 lmp.py:767]   Expert 43 |    438 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.267590.267590 lmp.py:767]   Expert 59 |    585 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.267756.267756 lmp.py:769] 
DEBUG 01-07 14:54:33.267756.267756 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.267637.267637 lmp.py:770]   CPU:   1998 tokens
DEBUG 01-07 14:54:33.267711.267711 lmp.py:774]   cuda:1:   5092 tokens (22 experts)
DEBUG 01-07 14:54:33.267546.267546 lmp.py:774]   cuda:2:   5198 tokens (23 experts)
DEBUG 01-07 14:54:33.267189.267189 lmp.py:775]   Total GPU:  10290 tokens
DEBUG 01-07 14:54:33.267593.267593 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.267593.267593 lmp.py:776] 
DEBUG 01-07 14:54:33.267197.267197 cuda_h.py:19] end experts_map_get cost 0.0018243789672851562 seconds
DEBUG 01-07 14:54:33.267270.267270 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.267139.267139 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.267560.267560 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.267415.267415 cuda_h.py:19] end allocate_cuda_memory cost 0.0001780986785888672 seconds
DEBUG 01-07 14:54:33.268317.268317 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.268550.268550 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.268359.268359 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.268201.268201 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c0fbdfe1-2c4c-4af8-a095-3e7f8cfdd080
DEBUG 01-07 14:54:33.268285.268285 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.268559.268559 client.py:127] Model loaded
DEBUG 01-07 14:54:33.268239.268239 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.268220.268220 cuda_h.py:19] end restore2model cost 0.0003714561462402344 seconds
DEBUG 01-07 14:54:33.268420.268420 cuda_h.py:19] end sllm_worker_task cost 0.00879979133605957 seconds
INFO 01-07 14:54:33.268429.268429 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c0fbdfe1-2c4c-4af8-a095-3e7f8cfdd080
DEBUG 01-07 14:54:33.269987.269987 cuda_h.py:19] end load_into_gpu_async cost 0.0009860992431640625 seconds
DEBUG 01-07 14:54:33.269167.269167 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.269903.269903 cuda_h.py:19] end restore_tensors2 cost 0.000202178955078125 seconds
DEBUG 01-07 14:54:33.269620.269620 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016644001007080078 seconds
DEBUG 01-07 14:54:33.269806.269806 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.271483.271483 cuda_h.py:19] end restore2model cost 0.0018055438995361328 seconds
DEBUG 01-07 14:54:33.271340.271340 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.271291.271291 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.271855.271855 cuda_h.py:19] end allocate_cuda_memory cost 0.00020694732666015625 seconds
DEBUG 01-07 14:54:33.271360.271360 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.271162.271162 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.271587.271587 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.271237.271237 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cd4961b6-3ff4-473f-bbbb-1f76e1825cca
DEBUG 01-07 14:54:33.271069.271069 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.272057.272057 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cd4961b6-3ff4-473f-bbbb-1f76e1825cca
DEBUG 01-07 14:54:33.272224.272224 cuda_h.py:19] end load_into_gpu_async cost 0.0008502006530761719 seconds
DEBUG 01-07 14:54:33.272735.272735 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.272941.272941 cuda_h.py:19] end restore_tensors2 cost 0.0001976490020751953 seconds
DEBUG 01-07 14:54:33.272803.272803 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015366077423095703 seconds
DEBUG 01-07 14:54:33.272175.272175 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.274370.274370 cuda_h.py:19] end restore2model cost 0.0018355846405029297 seconds
DEBUG 01-07 14:54:33.274815.274815 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007157087326049805 seconds
DEBUG 01-07 14:54:33.274849.274849 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.274143.274143 lmp.py:816] 
DEBUG 01-07 14:54:33.274143.274143 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.274086.274086 cuda_h.py:19] end cpu_experts_submit cost 0.00011467933654785156 seconds
DEBUG 01-07 14:54:33.274166.274166 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.279831.279831 mlpmodule.py:749] group tensors cost 0.004720211029052734 s
DEBUG 01-07 14:54:33.281075.281075 mlpmodule.py:787] pad cost 0.0012557506561279297 s
DEBUG 01-07 14:54:33.281708.281708 mlpmodule.py:793] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-07 14:54:33.281108.281108 mlpmodule.py:798] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-07 14:54:33.291820.291820 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.291926.291926 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.291784.291784 mlpmodule.py:818] group_w3 first element: 0.0086669921875
WARNING 01-07 14:54:33.291761.291761 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.305040.305040 mlpmodule.py:838] group einsum cost 0.02398395538330078 s
DEBUG 01-07 14:54:33.306870.306870 mlpmodule.py:846] cpy2cputensor cost 0.0004405975341796875 s
DEBUG 01-07 14:54:33.309340.309340 cuda_h.py:19] end wait_cetm_experts cost 0.03442645072937012 seconds
DEBUG 01-07 14:54:33.309886.309886 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.310249.310249 cuda_h.py:19] end gpu_sexperts cost 0.0005040168762207031 seconds
DEBUG 01-07 14:54:33.310522.310522 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.310425.310425 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-07 14:54:33.310559.310559 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.310321.310321 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c0fbdfe1-2c4c-4af8-a095-3e7f8cfdd080
INFO 01-07 14:54:33.311737.311737 client.py:127] Model loaded
INFO 01-07 14:54:33.312236.312236 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cd4961b6-3ff4-473f-bbbb-1f76e1825cca
INFO 01-07 14:54:33.312773.312773 client.py:127] Model loaded
DEBUG 01-07 14:54:33.312033.312033 cuda_h.py:19] end wait_experts_multi_device cost 0.0022852420806884766 seconds
DEBUG 01-07 14:54:33.312313.312313 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.312990.312990 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.313637.313637 mlpmodule.py:533] gpu group tensors cost 0.00048065185546875 s
DEBUG 01-07 14:54:33.315867.315867 mlpmodule.py:566] gpu pad cost 0.0012679100036621094 s
DEBUG 01-07 14:54:33.315351.315351 mlpmodule.py:584] gpu group einsum cost 0.0005333423614501953 s
DEBUG 01-07 14:54:33.317773.317773 mlpmodule.py:656] gpu experts func einsum cost 0.004549503326416016 s
DEBUG 01-07 14:54:33.318259.318259 mlpmodule.py:707]  experts func einsum cost 0.043005943298339844 s
DEBUG 01-07 14:54:33.318939.318939 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.318792.318792 mlpmodule.py:533] gpu group tensors cost 0.00043702125549316406 s
DEBUG 01-07 14:54:33.320579.320579 mlpmodule.py:566] gpu pad cost 0.001504659652709961 s
DEBUG 01-07 14:54:33.321094.321094 mlpmodule.py:584] gpu group einsum cost 0.0006546974182128906 s
DEBUG 01-07 14:54:33.323518.323518 mlpmodule.py:656] gpu experts func einsum cost 0.004519462585449219 s
DEBUG 01-07 14:54:33.323249.323249 cuda_h.py:19] end gpu_experts_multi_device cost 0.010528564453125 seconds
DEBUG 01-07 14:54:33.323901.323901 cuda_h.py:19] end layer_moe_generate_multi_device_4 cost 0.058229684829711914 seconds
DEBUG 01-07 14:54:33.323166.323166 lmp.py:194] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-07 14:54:33.323935.323935 lmp.py:153] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-07 14:54:33.323632.323632 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 14:54:33.323672.323672 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 14:54:33.323601.323601 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.6464462280273438e-05 seconds
DEBUG 01-07 14:54:33.323688.323688 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.650520324707031e-05 seconds
DEBUG 01-07 14:54:33.323000.323000 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.323274.323274 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.323216.323216 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.323901.323901 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.323069.323069 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.324672.324672 cuda_h.py:19] end allocate_cuda_memory cost 0.0001983642578125 seconds
DEBUG 01-07 14:54:33.324728.324728 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.324299.324299 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.324976.324976 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.324009.324009 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c427d3e9-bddc-4621-917f-7f4e3f0a0974
DEBUG 01-07 14:54:33.324588.324588 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.324410.324410 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.324728.324728 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c427d3e9-bddc-4621-917f-7f4e3f0a0974
DEBUG 01-07 14:54:33.325326.325326 cuda_h.py:19] end load_into_gpu_async cost 0.000827789306640625 seconds
DEBUG 01-07 14:54:33.325407.325407 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.325052.325052 cuda_h.py:19] end restore_tensors2 cost 6.318092346191406e-05 seconds
DEBUG 01-07 14:54:33.325139.325139 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013341903686523438 seconds
INFO 01-07 14:54:33.325061.325061 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c427d3e9-bddc-4621-917f-7f4e3f0a0974
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.328871.328871 cuda_h.py:19] end self_attn cost 0.003609895706176758 seconds
DEBUG 01-07 14:54:33.328829.328829 cuda_h.py:19] end iln_self_attn_paln cost 0.004931449890136719 seconds
DEBUG 01-07 14:54:33.328420.328420 cuda_h.py:10] start layer_moe_generate_multi_device_5
DEBUG 01-07 14:54:33.328944.328944 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.329536.329536 cuda_h.py:19] end gate cost 0.0006487369537353516 seconds
DEBUG 01-07 14:54:33.329366.329366 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.329631.329631 lmp.py:744] 
DEBUG 01-07 14:54:33.329631.329631 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.329487.329487 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.329044.329044 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.329263.329263 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.329860.329860 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.329503.329503 lmp.py:749] 
DEBUG 01-07 14:54:33.329503.329503 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.329861.329861 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.329656.329656 lmp.py:767]   Expert 34 |     24 | CPU
DEBUG 01-07 14:54:33.329491.329491 lmp.py:767]   Expert 45 |     64 | CPU
DEBUG 01-07 14:54:33.329611.329611 lmp.py:767]   Expert 22 |     74 | CPU
DEBUG 01-07 14:54:33.329208.329208 lmp.py:767]   Expert 57 |     76 | CPU
DEBUG 01-07 14:54:33.330043.330043 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 14:54:33.330163.330163 lmp.py:767]   Expert 15 |     97 | CPU
DEBUG 01-07 14:54:33.330044.330044 lmp.py:767]   Expert  4 |    101 | CPU
DEBUG 01-07 14:54:33.330164.330164 lmp.py:767]   Expert 28 |    106 | CPU
DEBUG 01-07 14:54:33.330045.330045 lmp.py:767]   Expert 32 |    112 | CPU
DEBUG 01-07 14:54:33.330927.330927 lmp.py:767]   Expert 60 |    113 | CPU
DEBUG 01-07 14:54:33.330523.330523 lmp.py:767]   Expert 36 |    125 | CPU
DEBUG 01-07 14:54:33.330120.330120 lmp.py:767]   Expert 14 |    126 | CPU
DEBUG 01-07 14:54:33.330240.330240 lmp.py:767]   Expert 16 |    127 | CPU
DEBUG 01-07 14:54:33.330883.330883 lmp.py:767]   Expert 12 |    128 | CPU
DEBUG 01-07 14:54:33.330526.330526 lmp.py:767]   Expert 52 |    130 | CPU
DEBUG 01-07 14:54:33.330169.330169 lmp.py:767]   Expert  8 |    131 | CPU
DEBUG 01-07 14:54:33.330573.330573 lmp.py:767]   Expert 25 |    133 | CPU
DEBUG 01-07 14:54:33.330216.330216 lmp.py:767]   Expert  2 |    138 | CPU
DEBUG 01-07 14:54:33.330621.330621 lmp.py:767]   Expert  5 |    144 | CPU
DEBUG 01-07 14:54:33.330933.330933 lmp.py:767]   Expert 35 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330529.330529 lmp.py:767]   Expert 23 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330841.330841 lmp.py:767]   Expert 30 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330915.330915 lmp.py:767]   Expert 39 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330750.330750 lmp.py:767]   Expert 61 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330108.330108 lmp.py:767]   Expert  0 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330466.330466 lmp.py:767]   Expert 13 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330825.330825 lmp.py:767]   Expert 42 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330660.330660 lmp.py:767]   Expert  3 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330256.330256 lmp.py:767]   Expert 31 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330853.330853 lmp.py:767]   Expert 44 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330973.330973 lmp.py:767]   Expert  9 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330331.330331 lmp.py:767]   Expert 46 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330451.330451 lmp.py:767]   Expert 41 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330048.330048 lmp.py:767]   Expert 43 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330644.330644 lmp.py:767]   Expert 62 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330718.330718 lmp.py:767]   Expert 27 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330553.330553 lmp.py:767]   Expert 26 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330149.330149 lmp.py:767]   Expert 50 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330508.330508 lmp.py:767]   Expert 49 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330866.330866 lmp.py:767]   Expert 51 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330986.330986 lmp.py:767]   Expert 18 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330105.330105 lmp.py:767]   Expert 11 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330179.330179 lmp.py:767]   Expert 47 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330776.330776 lmp.py:767]   Expert 19 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330895.330895 lmp.py:767]   Expert 20 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330492.330492 lmp.py:767]   Expert 55 |    207 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330373.330373 lmp.py:767]   Expert 63 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330255.330255 lmp.py:767]   Expert 56 |    211 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330613.330613 lmp.py:767]   Expert 38 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330971.330971 lmp.py:767]   Expert 48 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330568.330568 lmp.py:767]   Expert  1 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330165.330165 lmp.py:767]   Expert 10 |    242 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330000.330000 lmp.py:767]   Expert 54 |    249 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330596.330596 lmp.py:767]   Expert  7 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330478.330478 lmp.py:767]   Expert 21 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330359.330359 lmp.py:767]   Expert 33 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.330479.330479 lmp.py:767]   Expert 29 |    261 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.330599.330599 lmp.py:767]   Expert 40 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.331195.331195 lmp.py:767]   Expert 24 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.331030.331030 lmp.py:767]   Expert 59 |    297 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.331389.331389 lmp.py:767]   Expert 37 |    332 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.331508.331508 lmp.py:767]   Expert 58 |    367 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.331867.331867 lmp.py:767]   Expert  6 |    387 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.331463.331463 lmp.py:767]   Expert 53 |    854 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.331630.331630 lmp.py:769] 
DEBUG 01-07 14:54:33.331630.331630 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.331988.331988 lmp.py:770]   CPU:   2045 tokens
DEBUG 01-07 14:54:33.331538.331538 lmp.py:774]   cuda:1:   5119 tokens (22 experts)
DEBUG 01-07 14:54:33.331373.331373 lmp.py:774]   cuda:2:   5124 tokens (23 experts)
DEBUG 01-07 14:54:33.331016.331016 lmp.py:775]   Total GPU:  10243 tokens
DEBUG 01-07 14:54:33.331421.331421 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.331421.331421 lmp.py:776] 
DEBUG 01-07 14:54:33.331547.331547 cuda_h.py:19] end experts_map_get cost 0.001825571060180664 seconds
DEBUG 01-07 14:54:33.331621.331621 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.331728.331728 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.331533.331533 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.331408.331408 cuda_h.py:19] end allocate_cuda_memory cost 0.0001914501190185547 seconds
DEBUG 01-07 14:54:33.331642.331642 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.331736.331736 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.331783.331783 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.331433.331433 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b9b762b9-4f57-4a13-b960-4d3f97ac9264
DEBUG 01-07 14:54:33.331616.331616 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.331797.331797 client.py:127] Model loaded
DEBUG 01-07 14:54:33.332417.332417 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.332072.332072 cuda_h.py:19] end restore2model cost 0.00034308433532714844 seconds
DEBUG 01-07 14:54:33.332795.332795 cuda_h.py:19] end sllm_worker_task cost 0.008707523345947266 seconds
INFO 01-07 14:54:33.332749.332749 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b9b762b9-4f57-4a13-b960-4d3f97ac9264
DEBUG 01-07 14:54:33.332500.332500 cuda_h.py:19] end load_into_gpu_async cost 0.001055002212524414 seconds
DEBUG 01-07 14:54:33.332441.332441 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.333436.333436 cuda_h.py:19] end restore_tensors2 cost 0.00021791458129882812 seconds
DEBUG 01-07 14:54:33.333821.333821 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017664432525634766 seconds
DEBUG 01-07 14:54:33.333723.333723 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.334526.334526 cuda_h.py:19] end restore2model cost 0.0017931461334228516 seconds
DEBUG 01-07 14:54:33.335475.335475 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.335796.335796 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.335460.335460 cuda_h.py:19] end allocate_cuda_memory cost 0.0002067089080810547 seconds
DEBUG 01-07 14:54:33.335250.335250 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.335529.335529 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.335431.335431 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.335319.335319 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 47a1a04d-8110-40b3-9a9d-ad7337079ab6
DEBUG 01-07 14:54:33.335820.335820 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.336793.336793 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 47a1a04d-8110-40b3-9a9d-ad7337079ab6
DEBUG 01-07 14:54:33.336815.336815 cuda_h.py:19] end load_into_gpu_async cost 0.0010156631469726562 seconds
DEBUG 01-07 14:54:33.336087.336087 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.336830.336830 cuda_h.py:19] end restore_tensors2 cost 0.0002071857452392578 seconds
DEBUG 01-07 14:54:33.336500.336500 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001711130142211914 seconds
DEBUG 01-07 14:54:33.336349.336349 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.338590.338590 cuda_h.py:19] end restore2model cost 0.0018343925476074219 seconds
DEBUG 01-07 14:54:33.338227.338227 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0074117183685302734 seconds
DEBUG 01-07 14:54:33.338023.338023 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.338794.338794 lmp.py:816] 
DEBUG 01-07 14:54:33.338794.338794 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.338199.338199 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 14:54:33.338326.338326 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.343534.343534 mlpmodule.py:749] group tensors cost 0.004701137542724609 s
DEBUG 01-07 14:54:33.345338.345338 mlpmodule.py:787] pad cost 0.0013082027435302734 s
DEBUG 01-07 14:54:33.345732.345732 mlpmodule.py:793] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-07 14:54:33.345278.345278 mlpmodule.py:798] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-07 14:54:33.355734.355734 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.355455.355455 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.355789.355789 mlpmodule.py:818] group_w3 first element: -0.010498046875
WARNING 01-07 14:54:33.355794.355794 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.371194.371194 mlpmodule.py:838] group einsum cost 0.0252687931060791 s
DEBUG 01-07 14:54:33.371540.371540 mlpmodule.py:846] cpy2cputensor cost 0.00044536590576171875 s
DEBUG 01-07 14:54:33.374259.374259 cuda_h.py:19] end wait_cetm_experts cost 0.03554582595825195 seconds
DEBUG 01-07 14:54:33.374044.374044 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.375545.375545 cuda_h.py:19] end gpu_sexperts cost 0.0004994869232177734 seconds
DEBUG 01-07 14:54:33.375581.375581 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.375192.375192 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 14:54:33.375564.375564 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.375227.375227 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b9b762b9-4f57-4a13-b960-4d3f97ac9264
INFO 01-07 14:54:33.376673.376673 client.py:127] Model loaded
INFO 01-07 14:54:33.376648.376648 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 47a1a04d-8110-40b3-9a9d-ad7337079ab6
INFO 01-07 14:54:33.376543.376543 client.py:127] Model loaded
DEBUG 01-07 14:54:33.376664.376664 cuda_h.py:19] end wait_experts_multi_device cost 0.001377105712890625 seconds
DEBUG 01-07 14:54:33.376036.376036 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.376289.376289 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.377108.377108 mlpmodule.py:533] gpu group tensors cost 0.0004773139953613281 s
DEBUG 01-07 14:54:33.379875.379875 mlpmodule.py:566] gpu pad cost 0.0012743473052978516 s
DEBUG 01-07 14:54:33.379379.379379 mlpmodule.py:584] gpu group einsum cost 0.0005445480346679688 s
DEBUG 01-07 14:54:33.381471.381471 mlpmodule.py:656] gpu experts func einsum cost 0.004571437835693359 s
DEBUG 01-07 14:54:33.382904.382904 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.382703.382703 mlpmodule.py:533] gpu group tensors cost 0.0004506111145019531 s
DEBUG 01-07 14:54:33.384666.384666 mlpmodule.py:707]  experts func einsum cost 0.04526376724243164 s
DEBUG 01-07 14:54:33.385384.385384 mlpmodule.py:566] gpu pad cost 0.002477884292602539 s
DEBUG 01-07 14:54:33.386521.386521 mlpmodule.py:584] gpu group einsum cost 0.0008256435394287109 s
DEBUG 01-07 14:54:33.388094.388094 mlpmodule.py:656] gpu experts func einsum cost 0.005584716796875 s
DEBUG 01-07 14:54:33.388540.388540 cuda_h.py:19] end gpu_experts_multi_device cost 0.011472463607788086 seconds
DEBUG 01-07 14:54:33.388278.388278 cuda_h.py:19] end layer_moe_generate_multi_device_5 cost 0.05962657928466797 seconds
DEBUG 01-07 14:54:33.388570.388570 lmp.py:194] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-07 14:54:33.388916.388916 lmp.py:153] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-07 14:54:33.388327.388327 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 14:54:33.388799.388799 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 14:54:33.388873.388873 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 14:54:33.388815.388815 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.8650970458984375e-05 seconds
DEBUG 01-07 14:54:33.388603.388603 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.388824.388824 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.388674.388674 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.388246.388246 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.388744.388744 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.389712.389712 cuda_h.py:19] end allocate_cuda_memory cost 0.00018739700317382812 seconds
DEBUG 01-07 14:54:33.389913.389913 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.389676.389676 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.389068.389068 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.389532.389532 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 12cc8e47-2a7a-4736-8624-a808e97f6f79
DEBUG 01-07 14:54:33.389157.389157 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.389444.389444 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.389859.389859 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 12cc8e47-2a7a-4736-8624-a808e97f6f79
DEBUG 01-07 14:54:33.390503.390503 cuda_h.py:19] end load_into_gpu_async cost 0.00078582763671875 seconds
DEBUG 01-07 14:54:33.390060.390060 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.390713.390713 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-07 14:54:33.390522.390522 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0012946128845214844 seconds
INFO 01-07 14:54:33.390895.390895 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 12cc8e47-2a7a-4736-8624-a808e97f6f79
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.393289.393289 cuda_h.py:19] end self_attn cost 0.0036149024963378906 seconds
DEBUG 01-07 14:54:33.393041.393041 cuda_h.py:19] end iln_self_attn_paln cost 0.0049283504486083984 seconds
DEBUG 01-07 14:54:33.393407.393407 cuda_h.py:10] start layer_moe_generate_multi_device_6
DEBUG 01-07 14:54:33.393455.393455 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.394471.394471 cuda_h.py:19] end gate cost 0.0006456375122070312 seconds
DEBUG 01-07 14:54:33.394393.394393 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.394281.394281 lmp.py:744] 
DEBUG 01-07 14:54:33.394281.394281 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.394898.394898 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.394978.394978 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.394244.394244 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.394840.394840 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.394483.394483 lmp.py:749] 
DEBUG 01-07 14:54:33.394483.394483 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.395365.395365 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.395968.395968 lmp.py:767]   Expert  1 |     45 | CPU
DEBUG 01-07 14:54:33.395326.395326 lmp.py:767]   Expert  7 |     63 | CPU
DEBUG 01-07 14:54:33.395969.395969 lmp.py:767]   Expert 37 |     70 | CPU
DEBUG 01-07 14:54:33.395566.395566 lmp.py:767]   Expert 54 |     77 | CPU
DEBUG 01-07 14:54:33.395447.395447 lmp.py:767]   Expert 17 |     79 | CPU
DEBUG 01-07 14:54:33.395852.395852 lmp.py:767]   Expert 18 |     83 | CPU
DEBUG 01-07 14:54:33.395780.395780 lmp.py:767]   Expert  9 |     92 | CPU
DEBUG 01-07 14:54:33.395469.395469 lmp.py:767]   Expert 13 |     92 | CPU
DEBUG 01-07 14:54:33.395397.395397 lmp.py:767]   Expert 22 |     99 | CPU
DEBUG 01-07 14:54:33.395040.395040 lmp.py:767]   Expert 58 |    102 | CPU
DEBUG 01-07 14:54:33.395398.395398 lmp.py:767]   Expert  0 |    106 | CPU
DEBUG 01-07 14:54:33.395087.395087 lmp.py:767]   Expert 26 |    117 | CPU
DEBUG 01-07 14:54:33.395015.395015 lmp.py:767]   Expert 16 |    118 | CPU
DEBUG 01-07 14:54:33.395943.395943 lmp.py:767]   Expert 10 |    123 | CPU
DEBUG 01-07 14:54:33.395632.395632 lmp.py:767]   Expert 63 |    128 | CPU
DEBUG 01-07 14:54:33.395798.395798 lmp.py:767]   Expert 59 |    132 | CPU
DEBUG 01-07 14:54:33.395964.395964 lmp.py:767]   Expert 43 |    142 | CPU
DEBUG 01-07 14:54:33.395653.395653 lmp.py:767]   Expert 62 |    142 | CPU
DEBUG 01-07 14:54:33.395104.395104 lmp.py:767]   Expert 28 |    146 | CPU
DEBUG 01-07 14:54:33.395224.395224 lmp.py:767]   Expert 33 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395582.395582 lmp.py:767]   Expert 29 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395702.395702 lmp.py:767]   Expert  2 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395345.395345 lmp.py:767]   Expert 51 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395942.395942 lmp.py:767]   Expert 23 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395062.395062 lmp.py:767]   Expert 11 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395705.395705 lmp.py:767]   Expert 45 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395109.395109 lmp.py:767]   Expert 53 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395514.395514 lmp.py:767]   Expert 55 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395918.395918 lmp.py:767]   Expert  3 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395561.395561 lmp.py:767]   Expert 32 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395204.395204 lmp.py:767]   Expert 34 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395562.395562 lmp.py:767]   Expert 40 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395159.395159 lmp.py:767]   Expert 14 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395802.395802 lmp.py:767]   Expert 42 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395207.395207 lmp.py:767]   Expert 52 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395611.395611 lmp.py:767]   Expert 41 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395777.395777 lmp.py:767]   Expert 21 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395182.395182 lmp.py:767]   Expert 57 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395586.395586 lmp.py:767]   Expert 30 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395468.395468 lmp.py:767]   Expert 15 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395588.395588 lmp.py:767]   Expert 35 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395231.395231 lmp.py:767]   Expert 12 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395397.395397 lmp.py:767]   Expert  4 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395801.395801 lmp.py:767]   Expert 19 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395967.395967 lmp.py:767]   Expert 46 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395895.395895 lmp.py:767]   Expert 50 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395300.395300 lmp.py:767]   Expert 24 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395943.395943 lmp.py:767]   Expert 44 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395824.395824 lmp.py:767]   Expert  8 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395229.395229 lmp.py:767]   Expert 49 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395633.395633 lmp.py:767]   Expert 38 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395799.395799 lmp.py:767]   Expert  6 |    244 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395965.395965 lmp.py:767]   Expert 47 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395370.395370 lmp.py:767]   Expert 31 |    254 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.395536.395536 lmp.py:767]   Expert 61 |    262 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.395179.395179 lmp.py:767]   Expert 39 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.396822.396822 lmp.py:767]   Expert 36 |    299 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.396227.396227 lmp.py:767]   Expert  5 |    305 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.396393.396393 lmp.py:767]   Expert 27 |    308 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.396559.396559 lmp.py:767]   Expert 60 |    333 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.396487.396487 lmp.py:767]   Expert 20 |    339 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.396653.396653 lmp.py:767]   Expert 48 |    367 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.396296.396296 lmp.py:767]   Expert 25 |    397 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.396700.396700 lmp.py:767]   Expert 56 |    554 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.396151.396151 lmp.py:769] 
DEBUG 01-07 14:54:33.396151.396151 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.396317.396317 lmp.py:770]   CPU:   1956 tokens
DEBUG 01-07 14:54:33.396199.396199 lmp.py:774]   cuda:1:   5101 tokens (22 experts)
DEBUG 01-07 14:54:33.396365.396365 lmp.py:774]   cuda:2:   5231 tokens (23 experts)
DEBUG 01-07 14:54:33.396531.396531 lmp.py:775]   Total GPU:  10332 tokens
DEBUG 01-07 14:54:33.396220.396220 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.396220.396220 lmp.py:776] 
DEBUG 01-07 14:54:33.396870.396870 cuda_h.py:19] end experts_map_get cost 0.0017631053924560547 seconds
DEBUG 01-07 14:54:33.396513.396513 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.396190.396190 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.396525.396525 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.396121.396121 cuda_h.py:19] end allocate_cuda_memory cost 0.00016164779663085938 seconds
DEBUG 01-07 14:54:33.396686.396686 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.396726.396726 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.396151.396151 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.396086.396086 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2cdce24f-b1e8-4223-9a60-7d9bec8e8dac
DEBUG 01-07 14:54:33.396693.396693 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.397598.397598 client.py:127] Model loaded
DEBUG 01-07 14:54:33.397819.397819 cuda_h.py:10] start restore2model
INFO 01-07 14:54:33.397151.397151 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2cdce24f-b1e8-4223-9a60-7d9bec8e8dac
DEBUG 01-07 14:54:33.397033.397033 cuda_h.py:19] end load_into_gpu_async cost 0.0008561611175537109 seconds
DEBUG 01-07 14:54:33.397498.397498 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.397685.397685 cuda_h.py:19] end restore_tensors2 cost 0.00021767616271972656 seconds
DEBUG 01-07 14:54:33.397832.397832 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015399456024169922 seconds
DEBUG 01-07 14:54:33.397979.397979 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.398685.398685 cuda_h.py:19] end restore2model cost 9.441375732421875e-05 seconds
DEBUG 01-07 14:54:33.398449.398449 cuda_h.py:19] end sllm_worker_task cost 0.009247541427612305 seconds
DEBUG 01-07 14:54:33.399105.399105 cuda_h.py:19] end restore2model cost 0.0019576549530029297 seconds
DEBUG 01-07 14:54:33.399637.399637 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.400150.400150 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.400085.400085 cuda_h.py:19] end allocate_cuda_memory cost 0.0001995563507080078 seconds
DEBUG 01-07 14:54:33.400875.400875 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.400784.400784 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.400255.400255 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.400190.400190 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba036443-a5d8-40e2-9291-76e80d97f566
DEBUG 01-07 14:54:33.400690.400690 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.401717.401717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba036443-a5d8-40e2-9291-76e80d97f566
DEBUG 01-07 14:54:33.401924.401924 cuda_h.py:19] end load_into_gpu_async cost 0.00101470947265625 seconds
DEBUG 01-07 14:54:33.401243.401243 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.401363.401363 cuda_h.py:19] end restore_tensors2 cost 0.0002048015594482422 seconds
DEBUG 01-07 14:54:33.401794.401794 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017037391662597656 seconds
DEBUG 01-07 14:54:33.401451.401451 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.403931.403931 cuda_h.py:19] end restore2model cost 0.0018362998962402344 seconds
DEBUG 01-07 14:54:33.403422.403422 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007355451583862305 seconds
DEBUG 01-07 14:54:33.403549.403549 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.403174.403174 lmp.py:816] 
DEBUG 01-07 14:54:33.403174.403174 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.403533.403533 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 14:54:33.403514.403514 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.408488.408488 mlpmodule.py:749] group tensors cost 0.005019426345825195 s
DEBUG 01-07 14:54:33.410330.410330 mlpmodule.py:787] pad cost 0.0013551712036132812 s
DEBUG 01-07 14:54:33.411016.411016 mlpmodule.py:793] create cpu tensor cost 4.887580871582031e-05 s
DEBUG 01-07 14:54:33.411278.411278 mlpmodule.py:798] move to cpu cost 3.981590270996094e-05 s
DEBUG 01-07 14:54:33.421860.421860 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.421111.421111 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.421207.421207 mlpmodule.py:818] group_w3 first element: -0.003631591796875
WARNING 01-07 14:54:33.421861.421861 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.437403.437403 mlpmodule.py:838] group einsum cost 0.026586055755615234 s
DEBUG 01-07 14:54:33.438626.438626 mlpmodule.py:846] cpy2cputensor cost 0.00036787986755371094 s
DEBUG 01-07 14:54:33.441232.441232 cuda_h.py:19] end wait_cetm_experts cost 0.03721141815185547 seconds
DEBUG 01-07 14:54:33.441341.441341 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.441465.441465 cuda_h.py:19] end gpu_sexperts cost 0.0005054473876953125 seconds
DEBUG 01-07 14:54:33.441930.441930 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.441588.441588 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 14:54:33.441768.441768 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.441670.441670 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2cdce24f-b1e8-4223-9a60-7d9bec8e8dac
INFO 01-07 14:54:33.442243.442243 client.py:127] Model loaded
INFO 01-07 14:54:33.442961.442961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba036443-a5d8-40e2-9291-76e80d97f566
INFO 01-07 14:54:33.443194.443194 client.py:127] Model loaded
DEBUG 01-07 14:54:33.443553.443553 cuda_h.py:19] end wait_experts_multi_device cost 0.0014591217041015625 seconds
DEBUG 01-07 14:54:33.443978.443978 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.443324.443324 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.444755.444755 mlpmodule.py:533] gpu group tensors cost 0.0005173683166503906 s
DEBUG 01-07 14:54:33.445502.445502 mlpmodule.py:566] gpu pad cost 0.0012936592102050781 s
DEBUG 01-07 14:54:33.446847.446847 mlpmodule.py:584] gpu group einsum cost 0.0005354881286621094 s
DEBUG 01-07 14:54:33.448621.448621 mlpmodule.py:656] gpu experts func einsum cost 0.004632711410522461 s
DEBUG 01-07 14:54:33.449075.449075 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.449020.449020 mlpmodule.py:533] gpu group tensors cost 0.0004456043243408203 s
DEBUG 01-07 14:54:33.450871.450871 mlpmodule.py:707]  experts func einsum cost 0.046155452728271484 s
DEBUG 01-07 14:54:33.451583.451583 mlpmodule.py:566] gpu pad cost 0.0013363361358642578 s
DEBUG 01-07 14:54:33.451641.451641 mlpmodule.py:584] gpu group einsum cost 0.0004551410675048828 s
DEBUG 01-07 14:54:33.453290.453290 mlpmodule.py:656] gpu experts func einsum cost 0.004367351531982422 s
DEBUG 01-07 14:54:33.453220.453220 cuda_h.py:19] end gpu_experts_multi_device cost 0.010367393493652344 seconds
DEBUG 01-07 14:54:33.453236.453236 cuda_h.py:19] end layer_moe_generate_multi_device_6 cost 0.06012916564941406 seconds
DEBUG 01-07 14:54:33.454177.454177 lmp.py:194] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-07 14:54:33.454946.454946 lmp.py:153] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-07 14:54:33.454119.454119 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 14:54:33.454544.454544 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 14:54:33.454553.454553 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.9325485229492188e-05 seconds
DEBUG 01-07 14:54:33.454826.454826 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 8.0108642578125e-05 seconds
DEBUG 01-07 14:54:33.454899.454899 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.454974.454974 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.454969.454969 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.454680.454680 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.454033.454033 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.454811.454811 cuda_h.py:19] end allocate_cuda_memory cost 0.0002601146697998047 seconds
DEBUG 01-07 14:54:33.454628.454628 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.454245.454245 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.454160.454160 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.454241.454241 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d54b17c-ee49-48c2-8abf-1d377e7f84cb
DEBUG 01-07 14:54:33.455535.455535 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.455040.455040 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.455772.455772 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d54b17c-ee49-48c2-8abf-1d377e7f84cb
DEBUG 01-07 14:54:33.455324.455324 cuda_h.py:19] end load_into_gpu_async cost 0.0009703636169433594 seconds
DEBUG 01-07 14:54:33.455358.455358 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.456003.456003 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-07 14:54:33.456567.456567 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015363693237304688 seconds
INFO 01-07 14:54:33.456403.456403 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d54b17c-ee49-48c2-8abf-1d377e7f84cb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.459758.459758 cuda_h.py:19] end self_attn cost 0.003764629364013672 seconds
DEBUG 01-07 14:54:33.459093.459093 cuda_h.py:19] end iln_self_attn_paln cost 0.005170106887817383 seconds
DEBUG 01-07 14:54:33.459446.459446 cuda_h.py:10] start layer_moe_generate_multi_device_7
DEBUG 01-07 14:54:33.459871.459871 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.460808.460808 cuda_h.py:19] end gate cost 0.0006575584411621094 seconds
DEBUG 01-07 14:54:33.460876.460876 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.460532.460532 lmp.py:744] 
DEBUG 01-07 14:54:33.460532.460532 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.460686.460686 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.460243.460243 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.460793.460793 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.460482.460482 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.460695.460695 lmp.py:749] 
DEBUG 01-07 14:54:33.460695.460695 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.460384.460384 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.460749.460749 lmp.py:767]   Expert 50 |     45 | CPU
DEBUG 01-07 14:54:33.460630.460630 lmp.py:767]   Expert  3 |     54 | CPU
DEBUG 01-07 14:54:33.460081.460081 lmp.py:767]   Expert 46 |     55 | CPU
DEBUG 01-07 14:54:33.460771.460771 lmp.py:767]   Expert  1 |     78 | CPU
DEBUG 01-07 14:54:33.460745.460745 lmp.py:767]   Expert 29 |     86 | CPU
DEBUG 01-07 14:54:33.460719.460719 lmp.py:767]   Expert  4 |     87 | CPU
DEBUG 01-07 14:54:33.460454.460454 lmp.py:767]   Expert 40 |     95 | CPU
DEBUG 01-07 14:54:33.460667.460667 lmp.py:767]   Expert 15 |     97 | CPU
DEBUG 01-07 14:54:33.461118.461118 lmp.py:767]   Expert  8 |    109 | CPU
DEBUG 01-07 14:54:33.461092.461092 lmp.py:767]   Expert 28 |    113 | CPU
DEBUG 01-07 14:54:33.461589.461589 lmp.py:767]   Expert 41 |    113 | CPU
DEBUG 01-07 14:54:33.461325.461325 lmp.py:767]   Expert 16 |    125 | CPU
DEBUG 01-07 14:54:33.461583.461583 lmp.py:767]   Expert 27 |    127 | CPU
DEBUG 01-07 14:54:33.461081.461081 lmp.py:767]   Expert 48 |    128 | CPU
DEBUG 01-07 14:54:33.461055.461055 lmp.py:767]   Expert  6 |    129 | CPU
DEBUG 01-07 14:54:33.461790.461790 lmp.py:767]   Expert 54 |    133 | CPU
DEBUG 01-07 14:54:33.461764.461764 lmp.py:767]   Expert 13 |    134 | CPU
DEBUG 01-07 14:54:33.461215.461215 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 14:54:33.461951.461951 lmp.py:767]   Expert 51 |    136 | CPU
DEBUG 01-07 14:54:33.461117.461117 lmp.py:767]   Expert 39 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461045.461045 lmp.py:767]   Expert 60 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461211.461211 lmp.py:767]   Expert 18 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461900.461900 lmp.py:767]   Expert 14 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461828.461828 lmp.py:767]   Expert 20 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461994.461994 lmp.py:767]   Expert 43 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461160.461160 lmp.py:767]   Expert 52 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461088.461088 lmp.py:767]   Expert 56 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461300.461300 lmp.py:767]   Expert 36 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461990.461990 lmp.py:767]   Expert 55 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461679.461679 lmp.py:767]   Expert 11 |    157 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461368.461368 lmp.py:767]   Expert 10 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461296.461296 lmp.py:767]   Expert 45 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461747.461747 lmp.py:767]   Expert  5 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461913.461913 lmp.py:767]   Expert 62 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461841.461841 lmp.py:767]   Expert 57 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461292.461292 lmp.py:767]   Expert 44 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461981.461981 lmp.py:767]   Expert 33 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461909.461909 lmp.py:767]   Expert 53 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461359.461359 lmp.py:767]   Expert 58 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461049.461049 lmp.py:767]   Expert 25 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461976.461976 lmp.py:767]   Expert  2 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461143.461143 lmp.py:767]   Expert 32 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461832.461832 lmp.py:767]   Expert 31 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461044.461044 lmp.py:767]   Expert 63 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461495.461495 lmp.py:767]   Expert 35 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461185.461185 lmp.py:767]   Expert 21 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461635.461635 lmp.py:767]   Expert 49 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461848.461848 lmp.py:767]   Expert 17 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461299.461299 lmp.py:767]   Expert 42 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461226.461226 lmp.py:767]   Expert 34 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461916.461916 lmp.py:767]   Expert 37 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461367.461367 lmp.py:767]   Expert 59 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461579.461579 lmp.py:767]   Expert 22 |    243 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461030.461030 lmp.py:767]   Expert  0 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461719.461719 lmp.py:767]   Expert 19 |    257 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461885.461885 lmp.py:767]   Expert 24 |    284 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461336.461336 lmp.py:767]   Expert 61 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461502.461502 lmp.py:767]   Expert 30 |    302 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461907.461907 lmp.py:767]   Expert 47 |    320 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461073.461073 lmp.py:767]   Expert 38 |    366 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461716.461716 lmp.py:767]   Expert 26 |    374 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461121.461121 lmp.py:767]   Expert 12 |    424 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461002.461002 lmp.py:767]   Expert  9 |    679 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.461883.461883 lmp.py:767]   Expert 23 |    702 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.461573.461573 lmp.py:769] 
DEBUG 01-07 14:54:33.461573.461573 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.461501.461501 lmp.py:770]   CPU:   1979 tokens
DEBUG 01-07 14:54:33.461382.461382 lmp.py:774]   cuda:1:   5223 tokens (23 experts)
DEBUG 01-07 14:54:33.461786.461786 lmp.py:774]   cuda:2:   5086 tokens (22 experts)
DEBUG 01-07 14:54:33.462999.462999 lmp.py:775]   Total GPU:  10309 tokens
DEBUG 01-07 14:54:33.462450.462450 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.462450.462450 lmp.py:776] 
DEBUG 01-07 14:54:33.462623.462623 cuda_h.py:19] end experts_map_get cost 0.0017168521881103516 seconds
DEBUG 01-07 14:54:33.462266.462266 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.462612.462612 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.462039.462039 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.462205.462205 cuda_h.py:19] end allocate_cuda_memory cost 0.00019669532775878906 seconds
DEBUG 01-07 14:54:33.462453.462453 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.462686.462686 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.462972.462972 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.462383.462383 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df6059cb-cdd1-4a20-a342-51df4ceac791
DEBUG 01-07 14:54:33.462613.462613 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.462856.462856 client.py:127] Model loaded
DEBUG 01-07 14:54:33.462593.462593 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.463015.463015 cuda_h.py:19] end restore2model cost 0.0003147125244140625 seconds
DEBUG 01-07 14:54:33.463924.463924 cuda_h.py:19] end sllm_worker_task cost 0.008858680725097656 seconds
INFO 01-07 14:54:33.463423.463423 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df6059cb-cdd1-4a20-a342-51df4ceac791
DEBUG 01-07 14:54:33.463359.463359 cuda_h.py:19] end load_into_gpu_async cost 0.0009152889251708984 seconds
DEBUG 01-07 14:54:33.463678.463678 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.463110.463110 cuda_h.py:19] end restore_tensors2 cost 0.00022482872009277344 seconds
DEBUG 01-07 14:54:33.463972.463972 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016472339630126953 seconds
DEBUG 01-07 14:54:33.463397.463397 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.465315.465315 cuda_h.py:19] end restore2model cost 0.0018780231475830078 seconds
DEBUG 01-07 14:54:33.465602.465602 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.465255.465255 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.466256.466256 cuda_h.py:19] end allocate_cuda_memory cost 0.00021409988403320312 seconds
DEBUG 01-07 14:54:33.466761.466761 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.466087.466087 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.466750.466750 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.466208.466208 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1bb4b84a-1e60-4cd5-a7cf-c521bced979f
DEBUG 01-07 14:54:33.466947.466947 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.467184.467184 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1bb4b84a-1e60-4cd5-a7cf-c521bced979f
DEBUG 01-07 14:54:33.467583.467583 cuda_h.py:19] end load_into_gpu_async cost 0.0009603500366210938 seconds
DEBUG 01-07 14:54:33.467186.467186 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.467677.467677 cuda_h.py:19] end restore_tensors2 cost 0.00019788742065429688 seconds
DEBUG 01-07 14:54:33.467016.467016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016467571258544922 seconds
DEBUG 01-07 14:54:33.467626.467626 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.469840.469840 cuda_h.py:19] end restore2model cost 0.0018131732940673828 seconds
DEBUG 01-07 14:54:33.469147.469147 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007299184799194336 seconds
DEBUG 01-07 14:54:33.469465.469465 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.469143.469143 lmp.py:816] 
DEBUG 01-07 14:54:33.469143.469143 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.469834.469834 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 14:54:33.469245.469245 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.474924.474924 mlpmodule.py:749] group tensors cost 0.004920482635498047 s
DEBUG 01-07 14:54:33.476418.476418 mlpmodule.py:787] pad cost 0.0013017654418945312 s
DEBUG 01-07 14:54:33.476144.476144 mlpmodule.py:793] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-07 14:54:33.476498.476498 mlpmodule.py:798] move to cpu cost 3.719329833984375e-05 s
DEBUG 01-07 14:54:33.486025.486025 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.486454.486454 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.486405.486405 mlpmodule.py:818] group_w3 first element: 0.01263427734375
WARNING 01-07 14:54:33.486303.486303 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.502329.502329 mlpmodule.py:838] group einsum cost 0.02514171600341797 s
DEBUG 01-07 14:54:33.502343.502343 mlpmodule.py:846] cpy2cputensor cost 0.0003993511199951172 s
DEBUG 01-07 14:54:33.505613.505613 cuda_h.py:19] end wait_cetm_experts cost 0.03586411476135254 seconds
DEBUG 01-07 14:54:33.505643.505643 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.506681.506681 cuda_h.py:19] end gpu_sexperts cost 0.0005118846893310547 seconds
DEBUG 01-07 14:54:33.506670.506670 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.506520.506520 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 14:54:33.506700.506700 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.506840.506840 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df6059cb-cdd1-4a20-a342-51df4ceac791
INFO 01-07 14:54:33.507363.507363 client.py:127] Model loaded
INFO 01-07 14:54:33.507505.507505 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1bb4b84a-1e60-4cd5-a7cf-c521bced979f
INFO 01-07 14:54:33.507339.507339 client.py:127] Model loaded
DEBUG 01-07 14:54:33.508553.508553 cuda_h.py:19] end wait_experts_multi_device cost 0.0017209053039550781 seconds
DEBUG 01-07 14:54:33.508594.508594 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.508178.508178 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:33.509939.509939 mlpmodule.py:533] gpu group tensors cost 0.0004622936248779297 s
DEBUG 01-07 14:54:33.510498.510498 mlpmodule.py:566] gpu pad cost 0.0012221336364746094 s
DEBUG 01-07 14:54:33.511347.511347 mlpmodule.py:584] gpu group einsum cost 0.00055694580078125 s
DEBUG 01-07 14:54:33.513661.513661 mlpmodule.py:656] gpu experts func einsum cost 0.0044367313385009766 s
DEBUG 01-07 14:54:33.513631.513631 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:33.514391.514391 mlpmodule.py:533] gpu group tensors cost 0.0004477500915527344 s
DEBUG 01-07 14:54:33.514653.514653 mlpmodule.py:707]  experts func einsum cost 0.04472613334655762 s
DEBUG 01-07 14:54:33.515870.515870 mlpmodule.py:566] gpu pad cost 0.0013782978057861328 s
DEBUG 01-07 14:54:33.516927.516927 mlpmodule.py:584] gpu group einsum cost 0.00045228004455566406 s
DEBUG 01-07 14:54:33.518923.518923 mlpmodule.py:656] gpu experts func einsum cost 0.004456043243408203 s
DEBUG 01-07 14:54:33.518562.518562 cuda_h.py:19] end gpu_experts_multi_device cost 0.010306358337402344 seconds
DEBUG 01-07 14:54:33.518055.518055 cuda_h.py:19] end layer_moe_generate_multi_device_7 cost 0.05891704559326172 seconds
DEBUG 01-07 14:54:33.518453.518453 lmp.py:194] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-07 14:54:33.518415.518415 lmp.py:153] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-07 14:54:33.518396.518396 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 14:54:33.518913.518913 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 14:54:33.518988.518988 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 14:54:33.518022.518022 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.793571472167969e-05 seconds
DEBUG 01-07 14:54:33.518142.518142 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.518124.518124 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.519259.519259 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.519162.519162 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.519037.519037 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.519431.519431 cuda_h.py:19] end allocate_cuda_memory cost 0.0002574920654296875 seconds
DEBUG 01-07 14:54:33.519540.519540 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.519395.519395 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.519595.519595 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.519391.519391 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9b1d568c-8232-4a60-a820-de7e6d7d1a9a
DEBUG 01-07 14:54:33.519923.519923 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.519383.519383 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.520527.520527 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9b1d568c-8232-4a60-a820-de7e6d7d1a9a
DEBUG 01-07 14:54:33.520940.520940 cuda_h.py:19] end load_into_gpu_async cost 0.0010325908660888672 seconds
DEBUG 01-07 14:54:33.520497.520497 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.520189.520189 cuda_h.py:19] end restore_tensors2 cost 6.365776062011719e-05 seconds
DEBUG 01-07 14:54:33.520560.520560 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015981197357177734 seconds
INFO 01-07 14:54:33.520350.520350 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9b1d568c-8232-4a60-a820-de7e6d7d1a9a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.523536.523536 cuda_h.py:19] end self_attn cost 0.0037348270416259766 seconds
DEBUG 01-07 14:54:33.524295.524295 cuda_h.py:19] end iln_self_attn_paln cost 0.005138874053955078 seconds
DEBUG 01-07 14:54:33.524317.524317 cuda_h.py:10] start layer_moe_generate_multi_device_8
DEBUG 01-07 14:54:33.524364.524364 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.524970.524970 cuda_h.py:19] end gate cost 0.0006580352783203125 seconds
DEBUG 01-07 14:54:33.524753.524753 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.525403.525403 lmp.py:744] 
DEBUG 01-07 14:54:33.525403.525403 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.525020.525020 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.525577.525577 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.525081.525081 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.525439.525439 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.525367.525367 lmp.py:749] 
DEBUG 01-07 14:54:33.525367.525367 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.525010.525010 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.525329.525329 lmp.py:767]   Expert 38 |     12 | CPU
DEBUG 01-07 14:54:33.525210.525210 lmp.py:767]   Expert 39 |     59 | CPU
DEBUG 01-07 14:54:33.525091.525091 lmp.py:767]   Expert  7 |     71 | CPU
DEBUG 01-07 14:54:33.525734.525734 lmp.py:767]   Expert 30 |     77 | CPU
DEBUG 01-07 14:54:33.525377.525377 lmp.py:767]   Expert 24 |     93 | CPU
DEBUG 01-07 14:54:33.525543.525543 lmp.py:767]   Expert 27 |     93 | CPU
DEBUG 01-07 14:54:33.525471.525471 lmp.py:767]   Expert 14 |     94 | CPU
DEBUG 01-07 14:54:33.525399.525399 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 14:54:33.525565.525565 lmp.py:767]   Expert 36 |     96 | CPU
DEBUG 01-07 14:54:33.525970.525970 lmp.py:767]   Expert 40 |     96 | CPU
DEBUG 01-07 14:54:33.525374.525374 lmp.py:767]   Expert 16 |    103 | CPU
DEBUG 01-07 14:54:33.525017.525017 lmp.py:767]   Expert 32 |    104 | CPU
DEBUG 01-07 14:54:33.525183.525183 lmp.py:767]   Expert 48 |    111 | CPU
DEBUG 01-07 14:54:33.525111.525111 lmp.py:767]   Expert 18 |    114 | CPU
DEBUG 01-07 14:54:33.525277.525277 lmp.py:767]   Expert 12 |    115 | CPU
DEBUG 01-07 14:54:33.525205.525205 lmp.py:767]   Expert  1 |    117 | CPU
DEBUG 01-07 14:54:33.525371.525371 lmp.py:767]   Expert  6 |    126 | CPU
DEBUG 01-07 14:54:33.525299.525299 lmp.py:767]   Expert 59 |    132 | CPU
DEBUG 01-07 14:54:33.525465.525465 lmp.py:767]   Expert 42 |    136 | CPU
DEBUG 01-07 14:54:33.525300.525300 lmp.py:767]   Expert  0 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525135.525135 lmp.py:767]   Expert 22 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525732.525732 lmp.py:767]   Expert 53 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.525613.525613 lmp.py:767]   Expert 51 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.525494.525494 lmp.py:767]   Expert  8 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525376.525376 lmp.py:767]   Expert 44 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.525019.525019 lmp.py:767]   Expert 60 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525615.525615 lmp.py:767]   Expert 15 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525497.525497 lmp.py:767]   Expert 29 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.525901.525901 lmp.py:767]   Expert 54 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.525544.525544 lmp.py:767]   Expert 35 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525949.525949 lmp.py:767]   Expert 33 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.525592.525592 lmp.py:767]   Expert 34 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526996.526996 lmp.py:767]   Expert  9 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526401.526401 lmp.py:767]   Expert 19 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526044.526044 lmp.py:767]   Expert 47 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526687.526687 lmp.py:767]   Expert 56 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526091.526091 lmp.py:767]   Expert 46 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526734.526734 lmp.py:767]   Expert  3 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526901.526901 lmp.py:767]   Expert 45 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526305.526305 lmp.py:767]   Expert 21 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526710.526710 lmp.py:767]   Expert 20 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526114.526114 lmp.py:767]   Expert 49 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526519.526519 lmp.py:767]   Expert 28 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526400.526400 lmp.py:767]   Expert 57 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526758.526758 lmp.py:767]   Expert  2 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526163.526163 lmp.py:767]   Expert 43 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526568.526568 lmp.py:767]   Expert  4 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526972.526972 lmp.py:767]   Expert 13 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526377.526377 lmp.py:767]   Expert 10 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526020.526020 lmp.py:767]   Expert 50 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526424.526424 lmp.py:767]   Expert 41 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526782.526782 lmp.py:767]   Expert 26 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526187.526187 lmp.py:767]   Expert 63 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526353.526353 lmp.py:767]   Expert 37 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526758.526758 lmp.py:767]   Expert 61 |    268 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526162.526162 lmp.py:767]   Expert 31 |    272 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526328.526328 lmp.py:767]   Expert 52 |    306 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526495.526495 lmp.py:767]   Expert 58 |    322 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526091.526091 lmp.py:767]   Expert 62 |    322 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526449.526449 lmp.py:767]   Expert 55 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526854.526854 lmp.py:767]   Expert 11 |    379 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526020.526020 lmp.py:767]   Expert 23 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526425.526425 lmp.py:767]   Expert 25 |    409 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.526829.526829 lmp.py:767]   Expert  5 |    513 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.526042.526042 lmp.py:769] 
DEBUG 01-07 14:54:33.526042.526042 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.526446.526446 lmp.py:770]   CPU:   1845 tokens
DEBUG 01-07 14:54:33.526043.526043 lmp.py:774]   cuda:1:   5152 tokens (22 experts)
DEBUG 01-07 14:54:33.526163.526163 lmp.py:774]   cuda:2:   5291 tokens (23 experts)
DEBUG 01-07 14:54:33.526090.526090 lmp.py:775]   Total GPU:  10443 tokens
DEBUG 01-07 14:54:33.526780.526780 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.526780.526780 lmp.py:776] 
DEBUG 01-07 14:54:33.526191.526191 cuda_h.py:19] end experts_map_get cost 0.0017693042755126953 seconds
DEBUG 01-07 14:54:33.526311.526311 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.526511.526511 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.526177.526177 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.527727.527727 cuda_h.py:19] end allocate_cuda_memory cost 0.0001983642578125 seconds
DEBUG 01-07 14:54:33.527299.527299 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.527532.527532 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.527626.527626 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.527845.527845 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16911b3b-bf86-4315-bec4-f659022927ac
DEBUG 01-07 14:54:33.527651.527651 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.527186.527186 client.py:127] Model loaded
DEBUG 01-07 14:54:33.527300.527300 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.527868.527868 cuda_h.py:19] end restore2model cost 0.00031757354736328125 seconds
DEBUG 01-07 14:54:33.527062.527062 cuda_h.py:19] end sllm_worker_task cost 0.00888681411743164 seconds
INFO 01-07 14:54:33.528802.528802 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16911b3b-bf86-4315-bec4-f659022927ac
DEBUG 01-07 14:54:33.528738.528738 cuda_h.py:19] end load_into_gpu_async cost 0.0009918212890625 seconds
DEBUG 01-07 14:54:33.528010.528010 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.528264.528264 cuda_h.py:19] end restore_tensors2 cost 0.00022554397583007812 seconds
DEBUG 01-07 14:54:33.528080.528080 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017299652099609375 seconds
DEBUG 01-07 14:54:33.528266.528266 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.530798.530798 cuda_h.py:19] end restore2model cost 0.0018033981323242188 seconds
DEBUG 01-07 14:54:33.530224.530224 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.530598.530598 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.530957.530957 cuda_h.py:19] end allocate_cuda_memory cost 0.0001971721649169922 seconds
DEBUG 01-07 14:54:33.530270.530270 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.530118.530118 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.530067.530067 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.530763.530763 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 84db1ded-642d-4997-abc6-6642a6e7d8a6
DEBUG 01-07 14:54:33.531310.531310 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.532975.532975 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 84db1ded-642d-4997-abc6-6642a6e7d8a6
DEBUG 01-07 14:54:33.532566.532566 cuda_h.py:19] end load_into_gpu_async cost 0.0013113021850585938 seconds
DEBUG 01-07 14:54:33.532693.532693 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.532489.532489 cuda_h.py:19] end restore_tensors2 cost 0.00021195411682128906 seconds
DEBUG 01-07 14:54:33.532735.532735 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019996166229248047 seconds
DEBUG 01-07 14:54:33.532015.532015 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.534110.534110 cuda_h.py:19] end restore2model cost 0.0018334388732910156 seconds
DEBUG 01-07 14:54:33.534224.534224 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007673978805541992 seconds
DEBUG 01-07 14:54:33.534351.534351 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.534598.534598 lmp.py:816] 
DEBUG 01-07 14:54:33.534598.534598 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.534004.534004 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 14:54:33.534892.534892 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.543119.543119 mlpmodule.py:749] group tensors cost 0.009213924407958984 s
DEBUG 01-07 14:54:33.545566.545566 mlpmodule.py:787] pad cost 0.0010993480682373047 s
DEBUG 01-07 14:54:33.545656.545656 mlpmodule.py:793] create cpu tensor cost 4.124641418457031e-05 s
DEBUG 01-07 14:54:33.545235.545235 mlpmodule.py:798] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-07 14:54:33.554972.554972 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.554401.554401 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.554498.554498 mlpmodule.py:818] group_w3 first element: -0.03369140625
WARNING 01-07 14:54:33.554290.554290 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.568726.568726 mlpmodule.py:838] group einsum cost 0.022893905639648438 s
DEBUG 01-07 14:54:33.569930.569930 mlpmodule.py:846] cpy2cputensor cost 0.00036978721618652344 s
DEBUG 01-07 14:54:33.571404.571404 cuda_h.py:19] end wait_cetm_experts cost 0.03737759590148926 seconds
DEBUG 01-07 14:54:33.572142.572142 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.572869.572869 cuda_h.py:19] end gpu_sexperts cost 0.0005285739898681641 seconds
DEBUG 01-07 14:54:33.572858.572858 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.572423.572423 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 14:54:33.572841.572841 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.572266.572266 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16911b3b-bf86-4315-bec4-f659022927ac
INFO 01-07 14:54:33.573964.573964 client.py:127] Model loaded
INFO 01-07 14:54:33.573940.573940 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 84db1ded-642d-4997-abc6-6642a6e7d8a6
INFO 01-07 14:54:33.574515.574515 client.py:127] Model loaded
DEBUG 01-07 14:54:33.574914.574914 cuda_h.py:19] end wait_experts_multi_device cost 0.0013573169708251953 seconds
DEBUG 01-07 14:54:33.574048.574048 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.574440.574440 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.575288.575288 mlpmodule.py:533] gpu group tensors cost 0.0004980564117431641 s
DEBUG 01-07 14:54:33.576945.576945 mlpmodule.py:566] gpu pad cost 0.0013661384582519531 s
DEBUG 01-07 14:54:33.577787.577787 mlpmodule.py:584] gpu group einsum cost 0.0005435943603515625 s
DEBUG 01-07 14:54:33.579188.579188 mlpmodule.py:656] gpu experts func einsum cost 0.004639387130737305 s
DEBUG 01-07 14:54:33.579390.579390 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.580118.580118 mlpmodule.py:533] gpu group tensors cost 0.0004966259002685547 s
DEBUG 01-07 14:54:33.581178.581178 mlpmodule.py:707]  experts func einsum cost 0.046808481216430664 s
DEBUG 01-07 14:54:33.582873.582873 mlpmodule.py:566] gpu pad cost 0.0013346672058105469 s
DEBUG 01-07 14:54:33.582454.582454 mlpmodule.py:584] gpu group einsum cost 0.0004513263702392578 s
DEBUG 01-07 14:54:33.584812.584812 mlpmodule.py:656] gpu experts func einsum cost 0.004415035247802734 s
DEBUG 01-07 14:54:33.584888.584888 cuda_h.py:19] end gpu_experts_multi_device cost 0.010422706604003906 seconds
DEBUG 01-07 14:54:33.584619.584619 cuda_h.py:19] end layer_moe_generate_multi_device_8 cost 0.06061959266662598 seconds
DEBUG 01-07 14:54:33.584036.584036 lmp.py:194] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-07 14:54:33.585660.585660 lmp.py:153] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-07 14:54:33.585072.585072 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 14:54:33.585066.585066 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 14:54:33.585286.585286 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.123283386230469e-05 seconds
DEBUG 01-07 14:54:33.585526.585526 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.079673767089844e-05 seconds
DEBUG 01-07 14:54:33.585838.585838 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.585674.585674 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.585047.585047 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.585096.585096 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.585164.585164 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.585995.585995 cuda_h.py:19] end allocate_cuda_memory cost 0.0002644062042236328 seconds
DEBUG 01-07 14:54:33.585673.585673 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.585244.585244 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.585682.585682 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.585001.585001 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9ce6710-3996-4921-9eee-c0a02dd80e71
DEBUG 01-07 14:54:33.585772.585772 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.586681.586681 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.586501.586501 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9ce6710-3996-4921-9eee-c0a02dd80e71
DEBUG 01-07 14:54:33.586622.586622 cuda_h.py:19] end load_into_gpu_async cost 0.0008053779602050781 seconds
DEBUG 01-07 14:54:33.586656.586656 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.586255.586255 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-07 14:54:33.586627.586627 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013775825500488281 seconds
INFO 01-07 14:54:33.586940.586940 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9ce6710-3996-4921-9eee-c0a02dd80e71
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.589924.589924 cuda_h.py:19] end self_attn cost 0.0036280155181884766 seconds
DEBUG 01-07 14:54:33.590994.590994 cuda_h.py:19] end iln_self_attn_paln cost 0.005036592483520508 seconds
DEBUG 01-07 14:54:33.590109.590109 cuda_h.py:10] start layer_moe_generate_multi_device_9
DEBUG 01-07 14:54:33.590249.590249 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.591186.591186 cuda_h.py:19] end gate cost 0.0006566047668457031 seconds
DEBUG 01-07 14:54:33.591446.591446 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.591287.591287 lmp.py:744] 
DEBUG 01-07 14:54:33.591287.591287 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.591428.591428 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.591031.591031 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.591773.591773 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.591370.591370 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.591536.591536 lmp.py:749] 
DEBUG 01-07 14:54:33.591536.591536 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.591179.591179 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.591736.591736 lmp.py:767]   Expert 24 |     40 | CPU
DEBUG 01-07 14:54:33.591856.591856 lmp.py:767]   Expert  2 |     45 | CPU
DEBUG 01-07 14:54:33.591976.591976 lmp.py:767]   Expert 26 |     63 | CPU
DEBUG 01-07 14:54:33.591619.591619 lmp.py:767]   Expert 32 |     65 | CPU
DEBUG 01-07 14:54:33.591785.591785 lmp.py:767]   Expert 19 |     70 | CPU
DEBUG 01-07 14:54:33.591951.591951 lmp.py:767]   Expert 50 |     72 | CPU
DEBUG 01-07 14:54:33.591879.591879 lmp.py:767]   Expert 15 |     79 | CPU
DEBUG 01-07 14:54:33.591807.591807 lmp.py:767]   Expert 28 |     82 | CPU
DEBUG 01-07 14:54:33.591734.591734 lmp.py:767]   Expert 60 |     82 | CPU
DEBUG 01-07 14:54:33.591424.591424 lmp.py:767]   Expert  7 |     84 | CPU
DEBUG 01-07 14:54:33.591828.591828 lmp.py:767]   Expert  4 |     85 | CPU
DEBUG 01-07 14:54:33.591756.591756 lmp.py:767]   Expert 59 |     90 | CPU
DEBUG 01-07 14:54:33.591445.591445 lmp.py:767]   Expert 23 |     99 | CPU
DEBUG 01-07 14:54:33.591134.591134 lmp.py:767]   Expert 49 |     99 | CPU
DEBUG 01-07 14:54:33.591062.591062 lmp.py:767]   Expert  5 |    105 | CPU
DEBUG 01-07 14:54:33.591228.591228 lmp.py:767]   Expert 12 |    105 | CPU
DEBUG 01-07 14:54:33.591918.591918 lmp.py:767]   Expert 27 |    112 | CPU
DEBUG 01-07 14:54:33.591845.591845 lmp.py:767]   Expert 10 |    114 | CPU
DEBUG 01-07 14:54:33.591773.591773 lmp.py:767]   Expert 41 |    121 | CPU
DEBUG 01-07 14:54:33.591370.591370 lmp.py:767]   Expert  3 |    124 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.591490.591490 lmp.py:767]   Expert 20 |    128 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.591371.591371 lmp.py:767]   Expert 25 |    128 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592014.592014 lmp.py:767]   Expert 13 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592611.592611 lmp.py:767]   Expert 40 |    130 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592254.592254 lmp.py:767]   Expert 16 |    133 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592135.592135 lmp.py:767]   Expert 37 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592255.592255 lmp.py:767]   Expert 35 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592851.592851 lmp.py:767]   Expert 17 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592733.592733 lmp.py:767]   Expert 47 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592376.592376 lmp.py:767]   Expert 22 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592019.592019 lmp.py:767]   Expert 53 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592139.592139 lmp.py:767]   Expert 39 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592497.592497 lmp.py:767]   Expert 38 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592617.592617 lmp.py:767]   Expert 44 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592260.592260 lmp.py:767]   Expert 36 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592903.592903 lmp.py:767]   Expert 52 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592546.592546 lmp.py:767]   Expert 58 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592188.592188 lmp.py:767]   Expert 18 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592308.592308 lmp.py:767]   Expert 62 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592190.592190 lmp.py:767]   Expert 11 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592548.592548 lmp.py:767]   Expert 48 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592429.592429 lmp.py:767]   Expert 14 |    218 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592072.592072 lmp.py:767]   Expert 30 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592629.592629 lmp.py:767]   Expert  1 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592988.592988 lmp.py:767]   Expert 45 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592107.592107 lmp.py:767]   Expert 42 |    236 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592466.592466 lmp.py:767]   Expert 31 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592109.592109 lmp.py:767]   Expert  6 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592752.592752 lmp.py:767]   Expert 51 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592156.592156 lmp.py:767]   Expert 29 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592038.592038 lmp.py:767]   Expert 34 |    264 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592681.592681 lmp.py:767]   Expert 33 |    276 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592324.592324 lmp.py:767]   Expert 57 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592443.592443 lmp.py:767]   Expert 43 |    305 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592325.592325 lmp.py:767]   Expert 61 |    306 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592206.592206 lmp.py:767]   Expert  0 |    320 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592849.592849 lmp.py:767]   Expert 46 |    350 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592492.592492 lmp.py:767]   Expert  8 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592897.592897 lmp.py:767]   Expert 56 |    385 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592301.592301 lmp.py:767]   Expert  9 |    391 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592421.592421 lmp.py:767]   Expert 54 |    396 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592541.592541 lmp.py:767]   Expert 63 |    406 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592661.592661 lmp.py:767]   Expert 55 |    425 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.592065.592065 lmp.py:767]   Expert 21 |    490 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.592516.592516 lmp.py:769] 
DEBUG 01-07 14:54:33.592516.592516 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.592921.592921 lmp.py:770]   CPU:   1612 tokens
DEBUG 01-07 14:54:33.592040.592040 lmp.py:774]   cuda:1:   5281 tokens (22 experts)
DEBUG 01-07 14:54:33.592637.592637 lmp.py:774]   cuda:2:   5395 tokens (23 experts)
DEBUG 01-07 14:54:33.592042.592042 lmp.py:775]   Total GPU:  10676 tokens
DEBUG 01-07 14:54:33.592969.592969 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.592969.592969 lmp.py:776] 
DEBUG 01-07 14:54:33.592858.592858 cuda_h.py:19] end experts_map_get cost 0.0017848014831542969 seconds
DEBUG 01-07 14:54:33.592739.592739 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.592893.592893 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.593790.593790 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.593963.593963 cuda_h.py:19] end allocate_cuda_memory cost 0.00020122528076171875 seconds
DEBUG 01-07 14:54:33.593535.593535 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.593483.593483 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.593246.593246 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.593658.593658 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 131f1217-ffa5-4f84-937b-7b5093e3cc02
DEBUG 01-07 14:54:33.593172.593172 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.593415.593415 client.py:127] Model loaded
DEBUG 01-07 14:54:33.593529.593529 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.594958.594958 cuda_h.py:19] end restore2model cost 0.0003190040588378906 seconds
DEBUG 01-07 14:54:33.594198.594198 cuda_h.py:19] end sllm_worker_task cost 0.008790969848632812 seconds
INFO 01-07 14:54:33.594876.594876 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 131f1217-ffa5-4f84-937b-7b5093e3cc02
DEBUG 01-07 14:54:33.594050.594050 cuda_h.py:19] end load_into_gpu_async cost 0.0009074211120605469 seconds
DEBUG 01-07 14:54:33.594323.594323 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.594602.594602 cuda_h.py:19] end restore_tensors2 cost 0.000217437744140625 seconds
DEBUG 01-07 14:54:33.594319.594319 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016262531280517578 seconds
DEBUG 01-07 14:54:33.594598.594598 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.596891.596891 cuda_h.py:19] end restore2model cost 0.0018036365509033203 seconds
DEBUG 01-07 14:54:33.596893.596893 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.596221.596221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.596309.596309 cuda_h.py:19] end allocate_cuda_memory cost 0.0002071857452392578 seconds
DEBUG 01-07 14:54:33.596814.596814 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.596140.596140 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.596803.596803 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.596737.596737 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5558ae43-897a-4a3c-bec7-77ad83a86e74
DEBUG 01-07 14:54:33.597477.597477 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.597016.597016 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5558ae43-897a-4a3c-bec7-77ad83a86e74
DEBUG 01-07 14:54:33.597653.597653 cuda_h.py:19] end load_into_gpu_async cost 0.0009036064147949219 seconds
DEBUG 01-07 14:54:33.597972.597972 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.598470.598470 cuda_h.py:19] end restore_tensors2 cost 0.0002033710479736328 seconds
DEBUG 01-07 14:54:33.598378.598378 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015938282012939453 seconds
DEBUG 01-07 14:54:33.598512.598512 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.600118.600118 cuda_h.py:19] end restore2model cost 0.0018589496612548828 seconds
DEBUG 01-07 14:54:33.600470.600470 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007189750671386719 seconds
DEBUG 01-07 14:54:33.600028.600028 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.600798.600798 lmp.py:816] 
DEBUG 01-07 14:54:33.600798.600798 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.600443.600443 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-07 14:54:33.600615.600615 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.605198.605198 mlpmodule.py:749] group tensors cost 0.005022525787353516 s
DEBUG 01-07 14:54:33.607792.607792 mlpmodule.py:787] pad cost 0.001251220703125 s
DEBUG 01-07 14:54:33.607710.607710 mlpmodule.py:793] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-07 14:54:33.607394.607394 mlpmodule.py:798] move to cpu cost 3.814697265625e-05 s
DEBUG 01-07 14:54:33.616802.616802 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.616663.616663 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.616316.616316 mlpmodule.py:818] group_w3 first element: 0.0157470703125
WARNING 01-07 14:54:33.616493.616493 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.632751.632751 mlpmodule.py:838] group einsum cost 0.02440643310546875 s
DEBUG 01-07 14:54:33.632434.632434 mlpmodule.py:846] cpy2cputensor cost 0.00041413307189941406 s
DEBUG 01-07 14:54:33.635410.635410 cuda_h.py:19] end wait_cetm_experts cost 0.03495073318481445 seconds
DEBUG 01-07 14:54:33.635486.635486 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.635425.635425 cuda_h.py:19] end gpu_sexperts cost 0.0005080699920654297 seconds
DEBUG 01-07 14:54:33.635082.635082 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.636886.636886 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 14:54:33.636735.636735 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.636590.636590 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 131f1217-ffa5-4f84-937b-7b5093e3cc02
INFO 01-07 14:54:33.637191.637191 client.py:127] Model loaded
INFO 01-07 14:54:33.637524.637524 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5558ae43-897a-4a3c-bec7-77ad83a86e74
INFO 01-07 14:54:33.637035.637035 client.py:127] Model loaded
DEBUG 01-07 14:54:33.637017.637017 cuda_h.py:19] end wait_experts_multi_device cost 0.001474142074584961 seconds
DEBUG 01-07 14:54:33.637534.637534 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.637880.637880 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.638740.638740 mlpmodule.py:533] gpu group tensors cost 0.0004904270172119141 s
DEBUG 01-07 14:54:33.640627.640627 mlpmodule.py:566] gpu pad cost 0.0012905597686767578 s
DEBUG 01-07 14:54:33.640000.640000 mlpmodule.py:584] gpu group einsum cost 0.0005893707275390625 s
DEBUG 01-07 14:54:33.642474.642474 mlpmodule.py:656] gpu experts func einsum cost 0.004614353179931641 s
DEBUG 01-07 14:54:33.643537.643537 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.643158.643158 mlpmodule.py:533] gpu group tensors cost 0.000453948974609375 s
DEBUG 01-07 14:54:33.644541.644541 mlpmodule.py:707]  experts func einsum cost 0.044371604919433594 s
DEBUG 01-07 14:54:33.645352.645352 mlpmodule.py:566] gpu pad cost 0.0013799667358398438 s
DEBUG 01-07 14:54:33.645926.645926 mlpmodule.py:584] gpu group einsum cost 0.0004467964172363281 s
DEBUG 01-07 14:54:33.647018.647018 mlpmodule.py:656] gpu experts func einsum cost 0.004389762878417969 s
DEBUG 01-07 14:54:33.647425.647425 cuda_h.py:19] end gpu_experts_multi_device cost 0.01035451889038086 seconds
DEBUG 01-07 14:54:33.648772.648772 cuda_h.py:19] end layer_moe_generate_multi_device_9 cost 0.05776262283325195 seconds
DEBUG 01-07 14:54:33.648521.648521 lmp.py:194] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-07 14:54:33.648052.648052 lmp.py:153] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-07 14:54:33.648986.648986 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 14:54:33.648411.648411 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 14:54:33.648931.648931 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.817413330078125e-05 seconds
DEBUG 01-07 14:54:33.648111.648111 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 9.799003601074219e-05 seconds
DEBUG 01-07 14:54:33.648184.648184 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.648974.648974 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.648500.648500 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.648641.648641 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.648517.648517 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.649401.649401 cuda_h.py:19] end allocate_cuda_memory cost 0.0002682209014892578 seconds
DEBUG 01-07 14:54:33.649033.649033 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.649127.649127 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.649758.649758 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.649030.649030 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5f5be3e-759d-49e7-b380-5c2d2d6a8e50
DEBUG 01-07 14:54:33.649324.649324 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.649499.649499 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.650036.650036 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5f5be3e-759d-49e7-b380-5c2d2d6a8e50
DEBUG 01-07 14:54:33.650078.650078 cuda_h.py:19] end load_into_gpu_async cost 0.0009100437164306641 seconds
DEBUG 01-07 14:54:33.650450.650450 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.650864.650864 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 14:54:33.650904.650904 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001497030258178711 seconds
INFO 01-07 14:54:33.650880.650880 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5f5be3e-759d-49e7-b380-5c2d2d6a8e50
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.653008.653008 cuda_h.py:19] end self_attn cost 0.003685474395751953 seconds
DEBUG 01-07 14:54:33.653614.653614 cuda_h.py:19] end iln_self_attn_paln cost 0.005099058151245117 seconds
DEBUG 01-07 14:54:33.653113.653113 cuda_h.py:10] start layer_moe_generate_multi_device_10
DEBUG 01-07 14:54:33.653445.653445 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.654375.654375 cuda_h.py:19] end gate cost 0.0006535053253173828 seconds
DEBUG 01-07 14:54:33.654728.654728 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.654762.654762 lmp.py:744] 
DEBUG 01-07 14:54:33.654762.654762 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.654902.654902 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.654267.654267 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.654532.654532 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.654937.654937 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.654103.654103 lmp.py:749] 
DEBUG 01-07 14:54:33.654103.654103 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.655746.655746 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.655349.655349 lmp.py:767]   Expert 43 |     17 | CPU
DEBUG 01-07 14:54:33.655992.655992 lmp.py:767]   Expert 27 |     33 | CPU
DEBUG 01-07 14:54:33.655635.655635 lmp.py:767]   Expert 26 |     53 | CPU
DEBUG 01-07 14:54:33.655278.655278 lmp.py:767]   Expert 34 |     53 | CPU
DEBUG 01-07 14:54:33.655206.655206 lmp.py:767]   Expert 56 |     54 | CPU
DEBUG 01-07 14:54:33.655134.655134 lmp.py:767]   Expert  3 |     55 | CPU
DEBUG 01-07 14:54:33.655062.655062 lmp.py:767]   Expert  4 |     66 | CPU
DEBUG 01-07 14:54:33.655228.655228 lmp.py:767]   Expert 61 |     79 | CPU
DEBUG 01-07 14:54:33.655155.655155 lmp.py:767]   Expert 14 |     94 | CPU
DEBUG 01-07 14:54:33.655083.655083 lmp.py:767]   Expert 38 |    102 | CPU
DEBUG 01-07 14:54:33.655772.655772 lmp.py:767]   Expert  2 |    116 | CPU
DEBUG 01-07 14:54:33.655415.655415 lmp.py:767]   Expert 22 |    119 | CPU
DEBUG 01-07 14:54:33.655343.655343 lmp.py:767]   Expert 17 |    124 | CPU
DEBUG 01-07 14:54:33.655032.655032 lmp.py:767]   Expert 47 |    127 | CPU
DEBUG 01-07 14:54:33.655199.655199 lmp.py:767]   Expert 37 |    131 | CPU
DEBUG 01-07 14:54:33.655888.655888 lmp.py:767]   Expert 55 |    132 | CPU
DEBUG 01-07 14:54:33.655577.655577 lmp.py:767]   Expert 54 |    133 | CPU
DEBUG 01-07 14:54:33.655505.655505 lmp.py:767]   Expert 28 |    142 | CPU
DEBUG 01-07 14:54:33.655956.655956 lmp.py:767]   Expert  7 |    143 | CPU
DEBUG 01-07 14:54:33.655599.655599 lmp.py:767]   Expert 15 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655434.655434 lmp.py:767]   Expert  5 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655030.655030 lmp.py:767]   Expert 48 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655150.655150 lmp.py:767]   Expert 12 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655793.655793 lmp.py:767]   Expert 45 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655913.655913 lmp.py:767]   Expert 51 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655556.655556 lmp.py:767]   Expert 60 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655437.655437 lmp.py:767]   Expert 63 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655842.655842 lmp.py:767]   Expert 19 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655485.655485 lmp.py:767]   Expert  6 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655651.655651 lmp.py:767]   Expert 57 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655294.655294 lmp.py:767]   Expert 52 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655937.655937 lmp.py:767]   Expert 18 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655342.655342 lmp.py:767]   Expert 50 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655700.655700 lmp.py:767]   Expert 44 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655058.655058 lmp.py:767]   Expert 31 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655701.655701 lmp.py:767]   Expert 13 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655106.655106 lmp.py:767]   Expert 30 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655510.655510 lmp.py:767]   Expert 23 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655915.655915 lmp.py:767]   Expert 59 |    195 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655081.655081 lmp.py:767]   Expert 53 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655724.655724 lmp.py:767]   Expert 39 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655844.655844 lmp.py:767]   Expert 21 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655725.655725 lmp.py:767]   Expert 20 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655368.655368 lmp.py:767]   Expert 29 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655773.655773 lmp.py:767]   Expert 36 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655177.655177 lmp.py:767]   Expert 16 |    211 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655582.655582 lmp.py:767]   Expert 25 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655986.655986 lmp.py:767]   Expert 41 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655391.655391 lmp.py:767]   Expert 49 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655511.655511 lmp.py:767]   Expert 32 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655154.655154 lmp.py:767]   Expert 46 |    236 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655558.655558 lmp.py:767]   Expert  8 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655724.655724 lmp.py:767]   Expert 42 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.655129.655129 lmp.py:767]   Expert 10 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655533.655533 lmp.py:767]   Expert 62 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.655938.655938 lmp.py:767]   Expert 35 |    279 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.656058.656058 lmp.py:767]   Expert 33 |    290 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.656939.656939 lmp.py:767]   Expert 58 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.656582.656582 lmp.py:767]   Expert  9 |    298 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.656987.656987 lmp.py:767]   Expert 40 |    391 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.656868.656868 lmp.py:767]   Expert 11 |    427 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.656511.656511 lmp.py:767]   Expert  0 |    432 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.656154.656154 lmp.py:767]   Expert 24 |    565 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.656797.656797 lmp.py:767]   Expert  1 |    649 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.656725.656725 lmp.py:769] 
DEBUG 01-07 14:54:33.656725.656725 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.656129.656129 lmp.py:770]   CPU:   1773 tokens
DEBUG 01-07 14:54:33.656249.656249 lmp.py:774]   cuda:1:   5330 tokens (23 experts)
DEBUG 01-07 14:54:33.656654.656654 lmp.py:774]   cuda:2:   5185 tokens (22 experts)
DEBUG 01-07 14:54:33.656866.656866 lmp.py:775]   Total GPU:  10515 tokens
DEBUG 01-07 14:54:33.656317.656317 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.656317.656317 lmp.py:776] 
DEBUG 01-07 14:54:33.656251.656251 cuda_h.py:19] end experts_map_get cost 0.00176239013671875 seconds
DEBUG 01-07 14:54:33.656371.656371 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.656956.656956 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.656827.656827 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.656657.656657 cuda_h.py:19] end allocate_cuda_memory cost 0.00022673606872558594 seconds
DEBUG 01-07 14:54:33.656666.656666 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.656899.656899 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.656185.656185 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.656596.656596 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 789b91fc-e6ed-46c5-a7f4-955c65b8f65d
DEBUG 01-07 14:54:33.657117.657117 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.657937.657937 client.py:127] Model loaded
DEBUG 01-07 14:54:33.657111.657111 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.657766.657766 cuda_h.py:19] end restore2model cost 0.00033736228942871094 seconds
INFO 01-07 14:54:33.657497.657497 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 789b91fc-e6ed-46c5-a7f4-955c65b8f65d
DEBUG 01-07 14:54:33.657479.657479 cuda_h.py:19] end sllm_worker_task cost 0.009012699127197266 seconds
DEBUG 01-07 14:54:33.657799.657799 cuda_h.py:19] end load_into_gpu_async cost 0.0009746551513671875 seconds
DEBUG 01-07 14:54:33.657888.657888 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.658459.658459 cuda_h.py:19] end restore_tensors2 cost 0.0002193450927734375 seconds
DEBUG 01-07 14:54:33.658083.658083 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001791238784790039 seconds
DEBUG 01-07 14:54:33.658653.658653 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.660949.660949 cuda_h.py:19] end restore2model cost 0.0018754005432128906 seconds
DEBUG 01-07 14:54:33.660567.660567 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.660411.660411 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.660698.660698 cuda_h.py:19] end allocate_cuda_memory cost 0.0002110004425048828 seconds
DEBUG 01-07 14:54:33.660872.660872 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.660151.660151 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.660530.660530 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.660464.660464 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c39c292e-0787-4ed8-8ad2-0031b9b6d302
DEBUG 01-07 14:54:33.660965.660965 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.661116.661116 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c39c292e-0787-4ed8-8ad2-0031b9b6d302
DEBUG 01-07 14:54:33.661276.661276 cuda_h.py:19] end load_into_gpu_async cost 0.0009682178497314453 seconds
DEBUG 01-07 14:54:33.661880.661880 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.661840.661840 cuda_h.py:19] end restore_tensors2 cost 0.0001938343048095703 seconds
DEBUG 01-07 14:54:33.661987.661987 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016522407531738281 seconds
DEBUG 01-07 14:54:33.661121.661121 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.663188.663188 cuda_h.py:19] end restore2model cost 0.0017771720886230469 seconds
DEBUG 01-07 14:54:33.663441.663441 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00740361213684082 seconds
DEBUG 01-07 14:54:33.663237.663237 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.663769.663769 lmp.py:816] 
DEBUG 01-07 14:54:33.663769.663769 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.663029.663029 cuda_h.py:19] end cpu_experts_submit cost 0.000102996826171875 seconds
DEBUG 01-07 14:54:33.663679.663679 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.673541.673541 mlpmodule.py:749] group tensors cost 0.009820938110351562 s
DEBUG 01-07 14:54:33.675829.675829 mlpmodule.py:787] pad cost 0.0009844303131103516 s
DEBUG 01-07 14:54:33.675050.675050 mlpmodule.py:793] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-07 14:54:33.675953.675953 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 14:54:33.684791.684791 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.684089.684089 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.684755.684755 mlpmodule.py:818] group_w3 first element: -0.0213623046875
WARNING 01-07 14:54:33.685262.685262 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.703343.703343 mlpmodule.py:838] group einsum cost 0.027387142181396484 s
DEBUG 01-07 14:54:33.703614.703614 mlpmodule.py:846] cpy2cputensor cost 0.00038695335388183594 s
DEBUG 01-07 14:54:33.706618.706618 cuda_h.py:19] end wait_cetm_experts cost 0.043028831481933594 seconds
DEBUG 01-07 14:54:33.707740.707740 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.707089.707089 cuda_h.py:19] end gpu_sexperts cost 0.0004961490631103516 seconds
DEBUG 01-07 14:54:33.707601.707601 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.707544.707544 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 14:54:33.707485.707485 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.707433.707433 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 789b91fc-e6ed-46c5-a7f4-955c65b8f65d
INFO 01-07 14:54:33.708556.708556 client.py:127] Model loaded
INFO 01-07 14:54:33.708776.708776 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c39c292e-0787-4ed8-8ad2-0031b9b6d302
INFO 01-07 14:54:33.709146.709146 client.py:127] Model loaded
DEBUG 01-07 14:54:33.709976.709976 cuda_h.py:19] end wait_experts_multi_device cost 0.0013840198516845703 seconds
DEBUG 01-07 14:54:33.709109.709109 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.709025.709025 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:33.710758.710758 mlpmodule.py:533] gpu group tensors cost 0.0004813671112060547 s
DEBUG 01-07 14:54:33.711781.711781 mlpmodule.py:566] gpu pad cost 0.001216888427734375 s
DEBUG 01-07 14:54:33.712272.712272 mlpmodule.py:584] gpu group einsum cost 0.0005402565002441406 s
DEBUG 01-07 14:54:33.714381.714381 mlpmodule.py:656] gpu experts func einsum cost 0.004452705383300781 s
DEBUG 01-07 14:54:33.714106.714106 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:33.715965.715965 mlpmodule.py:533] gpu group tensors cost 0.0004582405090332031 s
DEBUG 01-07 14:54:33.716023.716023 mlpmodule.py:707]  experts func einsum cost 0.05228877067565918 s
DEBUG 01-07 14:54:33.716299.716299 mlpmodule.py:566] gpu pad cost 0.0014133453369140625 s
DEBUG 01-07 14:54:33.717489.717489 mlpmodule.py:584] gpu group einsum cost 0.0004420280456542969 s
DEBUG 01-07 14:54:33.719310.719310 mlpmodule.py:656] gpu experts func einsum cost 0.004435300827026367 s
DEBUG 01-07 14:54:33.719187.719187 cuda_h.py:19] end gpu_experts_multi_device cost 0.01021265983581543 seconds
DEBUG 01-07 14:54:33.719117.719117 cuda_h.py:19] end layer_moe_generate_multi_device_10 cost 0.06577301025390625 seconds
DEBUG 01-07 14:54:33.719641.719641 lmp.py:194] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-07 14:54:33.719172.719172 lmp.py:153] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-07 14:54:33.719107.719107 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 14:54:33.719147.719147 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 14:54:33.719414.719414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.9802322387695312e-05 seconds
DEBUG 01-07 14:54:33.719163.719163 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.9604644775390625e-05 seconds
DEBUG 01-07 14:54:33.719522.719522 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.719663.719663 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.720374.720374 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.720992.720992 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.720961.720961 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.720793.720793 cuda_h.py:19] end allocate_cuda_memory cost 0.0002987384796142578 seconds
DEBUG 01-07 14:54:33.720763.720763 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.720810.720810 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.720918.720918 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.720475.720475 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99dd18f4-9ea5-4b16-8d6c-2ba90fdba7f5
DEBUG 01-07 14:54:33.720199.720199 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.721678.721678 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.721759.721759 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99dd18f4-9ea5-4b16-8d6c-2ba90fdba7f5
DEBUG 01-07 14:54:33.721271.721271 cuda_h.py:19] end load_into_gpu_async cost 0.0009005069732666016 seconds
DEBUG 01-07 14:54:33.721212.721212 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.721288.721288 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:33.721329.721329 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00151824951171875 seconds
INFO 01-07 14:54:33.721681.721681 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99dd18f4-9ea5-4b16-8d6c-2ba90fdba7f5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.724928.724928 cuda_h.py:19] end self_attn cost 0.0036728382110595703 seconds
DEBUG 01-07 14:54:33.725634.725634 cuda_h.py:19] end iln_self_attn_paln cost 0.005110740661621094 seconds
DEBUG 01-07 14:54:33.725079.725079 cuda_h.py:10] start layer_moe_generate_multi_device_11
DEBUG 01-07 14:54:33.725935.725935 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.725905.725905 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-07 14:54:33.725781.725781 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.726946.726946 lmp.py:744] 
DEBUG 01-07 14:54:33.726946.726946 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.726563.726563 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.726120.726120 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.726863.726863 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.726744.726744 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.726672.726672 lmp.py:749] 
DEBUG 01-07 14:54:33.726672.726672 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.726077.726077 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.726395.726395 lmp.py:767]   Expert 39 |     15 | CPU
DEBUG 01-07 14:54:33.726376.726376 lmp.py:767]   Expert 13 |     16 | CPU
DEBUG 01-07 14:54:33.726065.726065 lmp.py:767]   Expert 49 |     38 | CPU
DEBUG 01-07 14:54:33.726470.726470 lmp.py:767]   Expert 35 |     54 | CPU
DEBUG 01-07 14:54:33.726041.726041 lmp.py:767]   Expert 19 |     64 | CPU
DEBUG 01-07 14:54:33.726160.726160 lmp.py:767]   Expert  9 |     73 | CPU
DEBUG 01-07 14:54:33.726088.726088 lmp.py:767]   Expert 26 |     75 | CPU
DEBUG 01-07 14:54:33.726777.726777 lmp.py:767]   Expert 32 |     75 | CPU
DEBUG 01-07 14:54:33.726467.726467 lmp.py:767]   Expert 41 |     76 | CPU
DEBUG 01-07 14:54:33.726156.726156 lmp.py:767]   Expert 33 |     81 | CPU
DEBUG 01-07 14:54:33.726845.726845 lmp.py:767]   Expert 23 |     87 | CPU
DEBUG 01-07 14:54:33.726250.726250 lmp.py:767]   Expert 46 |     90 | CPU
DEBUG 01-07 14:54:33.726939.726939 lmp.py:767]   Expert 18 |     92 | CPU
DEBUG 01-07 14:54:33.726867.726867 lmp.py:767]   Expert 31 |     92 | CPU
DEBUG 01-07 14:54:33.726079.726079 lmp.py:767]   Expert 38 |     93 | CPU
DEBUG 01-07 14:54:33.726246.726246 lmp.py:767]   Expert  3 |    103 | CPU
DEBUG 01-07 14:54:33.726412.726412 lmp.py:767]   Expert 17 |    104 | CPU
DEBUG 01-07 14:54:33.726055.726055 lmp.py:767]   Expert  6 |    106 | CPU
DEBUG 01-07 14:54:33.726221.726221 lmp.py:767]   Expert 20 |    116 | CPU
DEBUG 01-07 14:54:33.726102.726102 lmp.py:767]   Expert 40 |    129 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726699.726699 lmp.py:767]   Expert 61 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.726342.726342 lmp.py:767]   Expert 15 |    133 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.726985.726985 lmp.py:767]   Expert 62 |    133 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726389.726389 lmp.py:767]   Expert 44 |    135 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.726701.726701 lmp.py:767]   Expert 43 |    137 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726821.726821 lmp.py:767]   Expert 50 |    137 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.726702.726702 lmp.py:767]   Expert 59 |    137 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726107.726107 lmp.py:767]   Expert 63 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.726512.726512 lmp.py:767]   Expert 16 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726393.726393 lmp.py:767]   Expert 42 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.726798.726798 lmp.py:767]   Expert  2 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726202.726202 lmp.py:767]   Expert 36 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.726322.726322 lmp.py:767]   Expert 10 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727965.727965 lmp.py:767]   Expert  5 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727369.727369 lmp.py:767]   Expert 34 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727774.727774 lmp.py:767]   Expert 27 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727179.727179 lmp.py:767]   Expert 45 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727060.727060 lmp.py:767]   Expert 52 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727464.727464 lmp.py:767]   Expert 60 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727346.727346 lmp.py:767]   Expert 48 |    207 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727943.727943 lmp.py:767]   Expert 51 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727585.727585 lmp.py:767]   Expert 56 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727467.727467 lmp.py:767]   Expert 24 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727110.727110 lmp.py:767]   Expert 53 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727991.727991 lmp.py:767]   Expert  7 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727396.727396 lmp.py:767]   Expert  8 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727800.727800 lmp.py:767]   Expert 47 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727159.727159 lmp.py:767]   Expert 57 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727802.727802 lmp.py:767]   Expert 29 |    260 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727445.727445 lmp.py:767]   Expert 21 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727088.727088 lmp.py:767]   Expert  0 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727730.727730 lmp.py:767]   Expert 14 |    290 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727135.727135 lmp.py:767]   Expert  4 |    291 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727540.727540 lmp.py:767]   Expert 22 |    314 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727944.727944 lmp.py:767]   Expert 37 |    318 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727302.727302 lmp.py:767]   Expert 55 |    318 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727945.727945 lmp.py:767]   Expert 58 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727588.727588 lmp.py:767]   Expert  1 |    322 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727993.727993 lmp.py:767]   Expert 54 |    333 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727159.727159 lmp.py:767]   Expert 28 |    359 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727802.727802 lmp.py:767]   Expert 12 |    378 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727207.727207 lmp.py:767]   Expert 11 |    398 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727088.727088 lmp.py:767]   Expert 25 |    398 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.727731.727731 lmp.py:767]   Expert 30 |    836 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.727374.727374 lmp.py:769] 
DEBUG 01-07 14:54:33.727374.727374 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.727017.727017 lmp.py:770]   CPU:   1450 tokens
DEBUG 01-07 14:54:33.727614.727614 lmp.py:774]   cuda:1:   5419 tokens (22 experts)
DEBUG 01-07 14:54:33.727018.727018 lmp.py:774]   cuda:2:   5419 tokens (23 experts)
DEBUG 01-07 14:54:33.727946.727946 lmp.py:775]   Total GPU:  10838 tokens
DEBUG 01-07 14:54:33.727827.727827 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.727827.727827 lmp.py:776] 
DEBUG 01-07 14:54:33.727431.727431 cuda_h.py:19] end experts_map_get cost 0.0017859935760498047 seconds
DEBUG 01-07 14:54:33.727789.727789 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.727181.727181 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.727509.727509 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.728530.728530 cuda_h.py:19] end allocate_cuda_memory cost 0.00019049644470214844 seconds
DEBUG 01-07 14:54:33.728194.728194 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.728427.728427 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.728475.728475 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.728694.728694 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d230680d-dfcc-4e69-a0ae-462b66d8f14f
DEBUG 01-07 14:54:33.728162.728162 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.728307.728307 client.py:127] Model loaded
DEBUG 01-07 14:54:33.728958.728958 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.728155.728155 cuda_h.py:19] end restore2model cost 0.00032138824462890625 seconds
DEBUG 01-07 14:54:33.728256.728256 cuda_h.py:19] end sllm_worker_task cost 0.008873224258422852 seconds
INFO 01-07 14:54:33.729630.729630 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d230680d-dfcc-4e69-a0ae-462b66d8f14f
DEBUG 01-07 14:54:33.729043.729043 cuda_h.py:19] end load_into_gpu_async cost 0.000978231430053711 seconds
DEBUG 01-07 14:54:33.729315.729315 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.729456.729456 cuda_h.py:19] end restore_tensors2 cost 0.00021409988403320312 seconds
DEBUG 01-07 14:54:33.729510.729510 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016942024230957031 seconds
DEBUG 01-07 14:54:33.729650.729650 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.731863.731863 cuda_h.py:19] end restore2model cost 0.001779317855834961 seconds
DEBUG 01-07 14:54:33.731004.731004 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.731856.731856 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.731135.731135 cuda_h.py:19] end allocate_cuda_memory cost 0.00020813941955566406 seconds
DEBUG 01-07 14:54:33.731687.731687 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.731820.731820 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.731483.731483 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.731372.731372 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e97edc66-8b0a-4987-8ee2-f7307b573a90
DEBUG 01-07 14:54:33.731018.731018 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.732378.732378 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e97edc66-8b0a-4987-8ee2-f7307b573a90
DEBUG 01-07 14:54:33.732684.732684 cuda_h.py:19] end load_into_gpu_async cost 0.0008802413940429688 seconds
DEBUG 01-07 14:54:33.732003.732003 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.732924.732924 cuda_h.py:19] end restore_tensors2 cost 0.00019788742065429688 seconds
DEBUG 01-07 14:54:33.732071.732071 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015673637390136719 seconds
DEBUG 01-07 14:54:33.732589.732589 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.734228.734228 cuda_h.py:19] end restore2model cost 0.0018475055694580078 seconds
DEBUG 01-07 14:54:33.734011.734011 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007199764251708984 seconds
DEBUG 01-07 14:54:33.734614.734614 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.735908.735908 lmp.py:816] 
DEBUG 01-07 14:54:33.735908.735908 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.735076.735076 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:33.735964.735964 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.740696.740696 mlpmodule.py:749] group tensors cost 0.005124807357788086 s
DEBUG 01-07 14:54:33.742311.742311 mlpmodule.py:787] pad cost 0.0012617111206054688 s
DEBUG 01-07 14:54:33.742037.742037 mlpmodule.py:793] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-07 14:54:33.742622.742622 mlpmodule.py:798] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-07 14:54:33.750514.750514 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.751520.751520 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.751855.751855 mlpmodule.py:818] group_w3 first element: 0.01373291015625
WARNING 01-07 14:54:33.751648.751648 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.766779.766779 mlpmodule.py:838] group einsum cost 0.023977041244506836 s
DEBUG 01-07 14:54:33.767858.767858 mlpmodule.py:846] cpy2cputensor cost 0.00038504600524902344 s
DEBUG 01-07 14:54:33.769935.769935 cuda_h.py:19] end wait_cetm_experts cost 0.03469491004943848 seconds
DEBUG 01-07 14:54:33.769203.769203 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.770188.770188 cuda_h.py:19] end gpu_sexperts cost 0.000507354736328125 seconds
DEBUG 01-07 14:54:33.770131.770131 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.770173.770173 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-07 14:54:33.770114.770114 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.770254.770254 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d230680d-dfcc-4e69-a0ae-462b66d8f14f
INFO 01-07 14:54:33.771022.771022 client.py:127] Model loaded
INFO 01-07 14:54:33.771805.771805 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e97edc66-8b0a-4987-8ee2-f7307b573a90
INFO 01-07 14:54:33.772527.772527 client.py:127] Model loaded
DEBUG 01-07 14:54:33.772072.772072 cuda_h.py:19] end wait_experts_multi_device cost 0.0014834403991699219 seconds
DEBUG 01-07 14:54:33.772967.772967 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.772690.772690 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:33.773981.773981 mlpmodule.py:533] gpu group tensors cost 0.0004715919494628906 s
DEBUG 01-07 14:54:33.774191.774191 mlpmodule.py:566] gpu pad cost 0.0012803077697753906 s
DEBUG 01-07 14:54:33.775529.775529 mlpmodule.py:584] gpu group einsum cost 0.0005304813385009766 s
DEBUG 01-07 14:54:33.777302.777302 mlpmodule.py:656] gpu experts func einsum cost 0.004537343978881836 s
DEBUG 01-07 14:54:33.777550.777550 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:33.778660.778660 mlpmodule.py:533] gpu group tensors cost 0.0004336833953857422 s
DEBUG 01-07 14:54:33.778834.778834 mlpmodule.py:707]  experts func einsum cost 0.04347848892211914 s
DEBUG 01-07 14:54:33.779442.779442 mlpmodule.py:566] gpu pad cost 0.0013201236724853516 s
DEBUG 01-07 14:54:33.780731.780731 mlpmodule.py:584] gpu group einsum cost 0.00045037269592285156 s
DEBUG 01-07 14:54:33.782228.782228 mlpmodule.py:656] gpu experts func einsum cost 0.004328727722167969 s
DEBUG 01-07 14:54:33.782727.782727 cuda_h.py:19] end gpu_experts_multi_device cost 0.01022481918334961 seconds
DEBUG 01-07 14:54:33.782551.782551 cuda_h.py:19] end layer_moe_generate_multi_device_11 cost 0.05737423896789551 seconds
DEBUG 01-07 14:54:33.782154.782154 lmp.py:194] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-07 14:54:33.782400.782400 lmp.py:153] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-07 14:54:33.782096.782096 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 14:54:33.782091.782091 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 14:54:33.782212.782212 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 14:54:33.782961.782961 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.793571472167969e-05 seconds
DEBUG 01-07 14:54:33.782704.782704 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.782713.782713 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.783702.783702 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.783412.783412 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.783381.783381 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.783689.783689 cuda_h.py:19] end allocate_cuda_memory cost 0.0002639293670654297 seconds
DEBUG 01-07 14:54:33.783036.783036 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.783891.783891 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.783568.783568 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.783649.783649 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9007d5a-d72d-4e8b-ad80-b949a6cb57c6
DEBUG 01-07 14:54:33.783373.783373 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.783786.783786 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.784408.784408 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9007d5a-d72d-4e8b-ad80-b949a6cb57c6
DEBUG 01-07 14:54:33.784159.784159 cuda_h.py:19] end load_into_gpu_async cost 0.0008628368377685547 seconds
DEBUG 01-07 14:54:33.784146.784146 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.784514.784514 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-07 14:54:33.784362.784362 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014448165893554688 seconds
INFO 01-07 14:54:33.784576.784576 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9007d5a-d72d-4e8b-ad80-b949a6cb57c6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.787233.787233 cuda_h.py:19] end self_attn cost 0.0036034584045410156 seconds
DEBUG 01-07 14:54:33.787270.787270 cuda_h.py:19] end iln_self_attn_paln cost 0.005022287368774414 seconds
DEBUG 01-07 14:54:33.787815.787815 cuda_h.py:10] start layer_moe_generate_multi_device_12
DEBUG 01-07 14:54:33.788670.788670 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.788978.788978 cuda_h.py:19] end gate cost 0.0006499290466308594 seconds
DEBUG 01-07 14:54:33.788807.788807 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.789603.789603 lmp.py:744] 
DEBUG 01-07 14:54:33.789603.789603 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.789504.789504 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.789585.789585 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.789850.789850 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.789970.789970 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.789898.789898 lmp.py:749] 
DEBUG 01-07 14:54:33.789898.789898 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.789541.789541 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.789859.789859 lmp.py:767]   Expert 12 |     23 | CPU
DEBUG 01-07 14:54:33.789933.789933 lmp.py:767]   Expert 47 |     26 | CPU
DEBUG 01-07 14:54:33.789337.789337 lmp.py:767]   Expert 38 |     30 | CPU
DEBUG 01-07 14:54:33.789027.789027 lmp.py:767]   Expert 16 |     35 | CPU
DEBUG 01-07 14:54:33.789193.789193 lmp.py:767]   Expert 27 |     35 | CPU
DEBUG 01-07 14:54:33.789121.789121 lmp.py:767]   Expert 52 |     39 | CPU
DEBUG 01-07 14:54:33.789525.789525 lmp.py:767]   Expert 63 |     42 | CPU
DEBUG 01-07 14:54:33.789407.789407 lmp.py:767]   Expert 43 |     60 | CPU
DEBUG 01-07 14:54:33.789811.789811 lmp.py:767]   Expert  4 |     61 | CPU
DEBUG 01-07 14:54:33.789262.789262 lmp.py:767]   Expert 44 |     64 | CPU
DEBUG 01-07 14:54:33.789190.789190 lmp.py:767]   Expert 61 |     64 | CPU
DEBUG 01-07 14:54:33.789879.789879 lmp.py:767]   Expert 34 |     78 | CPU
DEBUG 01-07 14:54:33.789807.789807 lmp.py:767]   Expert 53 |     81 | CPU
DEBUG 01-07 14:54:33.789973.789973 lmp.py:767]   Expert  0 |     87 | CPU
DEBUG 01-07 14:54:33.789139.789139 lmp.py:767]   Expert 32 |     87 | CPU
DEBUG 01-07 14:54:33.789020.789020 lmp.py:767]   Expert 37 |     92 | CPU
DEBUG 01-07 14:54:33.789948.789948 lmp.py:767]   Expert 13 |    102 | CPU
DEBUG 01-07 14:54:33.789161.789161 lmp.py:767]   Expert 39 |    110 | CPU
DEBUG 01-07 14:54:33.789611.789611 lmp.py:767]   Expert 21 |    119 | CPU
DEBUG 01-07 14:54:33.789970.789970 lmp.py:767]   Expert 11 |    121 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789805.789805 lmp.py:767]   Expert 20 |    125 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789925.789925 lmp.py:767]   Expert  8 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789283.789283 lmp.py:767]   Expert 60 |    133 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789403.789403 lmp.py:767]   Expert 57 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789807.789807 lmp.py:767]   Expert 14 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789212.789212 lmp.py:767]   Expert 22 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789093.789093 lmp.py:767]   Expert 45 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789736.789736 lmp.py:767]   Expert 18 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789379.789379 lmp.py:767]   Expert  2 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789022.789022 lmp.py:767]   Expert  7 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789142.789142 lmp.py:767]   Expert 23 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789785.789785 lmp.py:767]   Expert 17 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789189.789189 lmp.py:767]   Expert 58 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789594.789594 lmp.py:767]   Expert 30 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789760.789760 lmp.py:767]   Expert 42 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789165.789165 lmp.py:767]   Expert 48 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.789092.789092 lmp.py:767]   Expert 55 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789974.789974 lmp.py:767]   Expert 49 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.789617.789617 lmp.py:767]   Expert 62 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790260.790260 lmp.py:767]   Expert 35 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790187.790187 lmp.py:767]   Expert 29 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790354.790354 lmp.py:767]   Expert 51 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790997.790997 lmp.py:767]   Expert 25 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790401.790401 lmp.py:767]   Expert  6 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790567.790567 lmp.py:767]   Expert 36 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790733.790733 lmp.py:767]   Expert  1 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790615.790615 lmp.py:767]   Expert 31 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790496.790496 lmp.py:767]   Expert 28 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790901.790901 lmp.py:767]   Expert  5 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790305.790305 lmp.py:767]   Expert 54 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790948.790948 lmp.py:767]   Expert 41 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790876.790876 lmp.py:767]   Expert 19 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790280.790280 lmp.py:767]   Expert  9 |    239 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790162.790162 lmp.py:767]   Expert 24 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790090.790090 lmp.py:767]   Expert 50 |    288 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790448.790448 lmp.py:767]   Expert 46 |    302 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790091.790091 lmp.py:767]   Expert 59 |    311 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790495.790495 lmp.py:767]   Expert 56 |    380 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790662.790662 lmp.py:767]   Expert 26 |    408 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790828.790828 lmp.py:767]   Expert 33 |    423 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790232.790232 lmp.py:767]   Expert  3 |    583 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790637.790637 lmp.py:767]   Expert 10 |    635 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790803.790803 lmp.py:767]   Expert 15 |    651 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.790684.790684 lmp.py:767]   Expert 40 |    794 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.790612.790612 lmp.py:769] 
DEBUG 01-07 14:54:33.790612.790612 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.790017.790017 lmp.py:770]   CPU:   1235 tokens
DEBUG 01-07 14:54:33.790898.790898 lmp.py:774]   cuda:1:   5586 tokens (23 experts)
DEBUG 01-07 14:54:33.790826.790826 lmp.py:774]   cuda:2:   5467 tokens (22 experts)
DEBUG 01-07 14:54:33.790515.790515 lmp.py:775]   Total GPU:  11053 tokens
DEBUG 01-07 14:54:33.790727.790727 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.790727.790727 lmp.py:776] 
DEBUG 01-07 14:54:33.790139.790139 cuda_h.py:19] end experts_map_get cost 0.0017616748809814453 seconds
DEBUG 01-07 14:54:33.790974.790974 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.790273.790273 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.790032.790032 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.790138.790138 cuda_h.py:19] end allocate_cuda_memory cost 0.000186920166015625 seconds
DEBUG 01-07 14:54:33.791518.791518 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.791466.791466 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.791752.791752 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.791210.791210 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 160c9781-2ce6-481d-bcb8-28e10cf76f33
DEBUG 01-07 14:54:33.791354.791354 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.791835.791835 client.py:127] Model loaded
DEBUG 01-07 14:54:33.791857.791857 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.791001.791001 cuda_h.py:19] end restore2model cost 0.00031948089599609375 seconds
DEBUG 01-07 14:54:33.791148.791148 cuda_h.py:19] end sllm_worker_task cost 0.008729934692382812 seconds
INFO 01-07 14:54:33.791529.791529 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 160c9781-2ce6-481d-bcb8-28e10cf76f33
DEBUG 01-07 14:54:33.791988.791988 cuda_h.py:19] end load_into_gpu_async cost 0.0009453296661376953 seconds
DEBUG 01-07 14:54:33.792976.792976 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.792031.792031 cuda_h.py:19] end restore_tensors2 cost 0.0002269744873046875 seconds
DEBUG 01-07 14:54:33.792370.792370 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016639232635498047 seconds
DEBUG 01-07 14:54:33.792940.792940 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.794925.794925 cuda_h.py:19] end restore2model cost 0.0018906593322753906 seconds
DEBUG 01-07 14:54:33.794927.794927 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.794057.794057 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.794038.794038 cuda_h.py:19] end allocate_cuda_memory cost 0.0001990795135498047 seconds
DEBUG 01-07 14:54:33.794066.794066 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.794868.794868 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.794485.794485 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.794420.794420 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d94a9dfe-4930-4590-9afe-b4f2d61604b4
DEBUG 01-07 14:54:33.794351.794351 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.795441.795441 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d94a9dfe-4930-4590-9afe-b4f2d61604b4
DEBUG 01-07 14:54:33.795078.795078 cuda_h.py:19] end load_into_gpu_async cost 0.0009255409240722656 seconds
DEBUG 01-07 14:54:33.795635.795635 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.795457.795457 cuda_h.py:19] end restore_tensors2 cost 0.0001957416534423828 seconds
DEBUG 01-07 14:54:33.795128.795128 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00159454345703125 seconds
DEBUG 01-07 14:54:33.795022.795022 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.797036.797036 cuda_h.py:19] end restore2model cost 0.0017728805541992188 seconds
DEBUG 01-07 14:54:33.797820.797820 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007237672805786133 seconds
DEBUG 01-07 14:54:33.797854.797854 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.797578.797578 lmp.py:816] 
DEBUG 01-07 14:54:33.797578.797578 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.797176.797176 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 14:54:33.798587.798587 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.807901.807901 mlpmodule.py:749] group tensors cost 0.009451627731323242 s
DEBUG 01-07 14:54:33.809647.809647 mlpmodule.py:787] pad cost 0.0010654926300048828 s
DEBUG 01-07 14:54:33.809922.809922 mlpmodule.py:793] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-07 14:54:33.809971.809971 mlpmodule.py:798] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-07 14:54:33.818711.818711 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.818956.818956 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.818628.818628 mlpmodule.py:818] group_w3 first element: -0.0162353515625
WARNING 01-07 14:54:33.818136.818136 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.834104.834104 mlpmodule.py:838] group einsum cost 0.024672508239746094 s
DEBUG 01-07 14:54:33.834744.834744 mlpmodule.py:846] cpy2cputensor cost 0.0003631114959716797 s
DEBUG 01-07 14:54:33.837290.837290 cuda_h.py:19] end wait_cetm_experts cost 0.039343833923339844 seconds
DEBUG 01-07 14:54:33.837545.837545 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.838748.838748 cuda_h.py:19] end gpu_sexperts cost 0.0004937648773193359 seconds
DEBUG 01-07 14:54:33.838684.838684 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.838865.838865 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-07 14:54:33.838567.838567 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.838277.838277 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 160c9781-2ce6-481d-bcb8-28e10cf76f33
INFO 01-07 14:54:33.839235.839235 client.py:127] Model loaded
INFO 01-07 14:54:33.839568.839568 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d94a9dfe-4930-4590-9afe-b4f2d61604b4
INFO 01-07 14:54:33.839065.839065 client.py:127] Model loaded
DEBUG 01-07 14:54:33.839471.839471 cuda_h.py:19] end wait_experts_multi_device cost 0.0014421939849853516 seconds
DEBUG 01-07 14:54:33.839181.839181 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.839003.839003 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:33.840234.840234 mlpmodule.py:533] gpu group tensors cost 0.00048089027404785156 s
DEBUG 01-07 14:54:33.842417.842417 mlpmodule.py:566] gpu pad cost 0.0012314319610595703 s
DEBUG 01-07 14:54:33.842477.842477 mlpmodule.py:584] gpu group einsum cost 0.000537872314453125 s
DEBUG 01-07 14:54:33.844054.844054 mlpmodule.py:656] gpu experts func einsum cost 0.00438690185546875 s
DEBUG 01-07 14:54:33.845202.845202 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:33.845718.845718 mlpmodule.py:533] gpu group tensors cost 0.0004856586456298828 s
DEBUG 01-07 14:54:33.847173.847173 mlpmodule.py:566] gpu pad cost 0.001260519027709961 s
DEBUG 01-07 14:54:33.847190.847190 mlpmodule.py:584] gpu group einsum cost 0.0004398822784423828 s
DEBUG 01-07 14:54:33.849246.849246 mlpmodule.py:656] gpu experts func einsum cost 0.004384756088256836 s
DEBUG 01-07 14:54:33.849329.849329 cuda_h.py:19] end gpu_experts_multi_device cost 0.010122060775756836 seconds
DEBUG 01-07 14:54:33.849543.849543 mlpmodule.py:707]  experts func einsum cost 0.051795244216918945 s
DEBUG 01-07 14:54:33.850918.850918 cuda_h.py:19] end layer_moe_generate_multi_device_12 cost 0.06197690963745117 seconds
DEBUG 01-07 14:54:33.850216.850216 lmp.py:194] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-07 14:54:33.850370.850370 lmp.py:153] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-07 14:54:33.850066.850066 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 14:54:33.850822.850822 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 14:54:33.850990.850990 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 14:54:33.850977.850977 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.650520324707031e-05 seconds
DEBUG 01-07 14:54:33.850289.850289 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.850841.850841 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.850407.850407 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.850118.850118 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.850563.850563 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.851408.851408 cuda_h.py:19] end allocate_cuda_memory cost 0.0002734661102294922 seconds
DEBUG 01-07 14:54:33.851000.851000 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.851478.851478 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.851347.851347 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.851620.851620 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 562a56bc-29f0-42ef-8458-bfa41f543c9d
DEBUG 01-07 14:54:33.851821.851821 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.851194.851194 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.852620.852620 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 562a56bc-29f0-42ef-8458-bfa41f543c9d
DEBUG 01-07 14:54:33.852456.852456 cuda_h.py:19] end load_into_gpu_async cost 0.0009322166442871094 seconds
DEBUG 01-07 14:54:33.852252.852252 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.852282.852282 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 14:54:33.852892.852892 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015254020690917969 seconds
INFO 01-07 14:54:33.852721.852721 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 562a56bc-29f0-42ef-8458-bfa41f543c9d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.855637.855637 cuda_h.py:19] end self_attn cost 0.003671884536743164 seconds
DEBUG 01-07 14:54:33.855045.855045 cuda_h.py:19] end iln_self_attn_paln cost 0.005127429962158203 seconds
DEBUG 01-07 14:54:33.855351.855351 cuda_h.py:10] start layer_moe_generate_multi_device_13
DEBUG 01-07 14:54:33.855537.855537 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.856924.856924 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-07 14:54:33.856568.856568 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.856748.856748 lmp.py:744] 
DEBUG 01-07 14:54:33.856748.856748 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.856425.856425 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.856459.856459 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.856771.856771 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.856937.856937 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.856149.856149 lmp.py:749] 
DEBUG 01-07 14:54:33.856149.856149 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.856838.856838 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.856488.856488 lmp.py:767]   Expert 19 |     23 | CPU
DEBUG 01-07 14:54:33.856416.856416 lmp.py:767]   Expert 42 |     25 | CPU
DEBUG 01-07 14:54:33.856582.856582 lmp.py:767]   Expert 30 |     26 | CPU
DEBUG 01-07 14:54:33.857510.857510 lmp.py:767]   Expert 32 |     45 | CPU
DEBUG 01-07 14:54:33.857722.857722 lmp.py:767]   Expert  6 |     57 | CPU
DEBUG 01-07 14:54:33.857696.857696 lmp.py:767]   Expert 53 |     73 | CPU
DEBUG 01-07 14:54:33.857909.857909 lmp.py:767]   Expert  5 |     74 | CPU
DEBUG 01-07 14:54:33.857644.857644 lmp.py:767]   Expert  1 |     77 | CPU
DEBUG 01-07 14:54:33.857618.857618 lmp.py:767]   Expert  9 |    120 | CPU
DEBUG 01-07 14:54:33.857592.857592 lmp.py:767]   Expert 13 |    123 | CPU
DEBUG 01-07 14:54:33.857043.857043 lmp.py:767]   Expert 34 |    125 | CPU
DEBUG 01-07 14:54:33.857971.857971 lmp.py:767]   Expert 58 |    129 | CPU
DEBUG 01-07 14:54:33.857945.857945 lmp.py:767]   Expert 63 |    129 | CPU
DEBUG 01-07 14:54:33.857919.857919 lmp.py:767]   Expert 50 |    131 | CPU
DEBUG 01-07 14:54:33.857893.857893 lmp.py:767]   Expert 11 |    136 | CPU
DEBUG 01-07 14:54:33.857106.857106 lmp.py:767]   Expert 31 |    137 | CPU
DEBUG 01-07 14:54:33.857080.857080 lmp.py:767]   Expert 26 |    139 | CPU
DEBUG 01-07 14:54:33.857292.857292 lmp.py:767]   Expert 18 |    140 | CPU
DEBUG 01-07 14:54:33.857028.857028 lmp.py:767]   Expert 59 |    140 | CPU
DEBUG 01-07 14:54:33.857148.857148 lmp.py:767]   Expert 40 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857029.857029 lmp.py:767]   Expert 12 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857195.857195 lmp.py:767]   Expert 20 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857123.857123 lmp.py:767]   Expert 46 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857289.857289 lmp.py:767]   Expert 56 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857217.857217 lmp.py:767]   Expert  4 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857144.857144 lmp.py:767]   Expert  2 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857072.857072 lmp.py:767]   Expert 48 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857238.857238 lmp.py:767]   Expert 61 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857643.857643 lmp.py:767]   Expert 33 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857571.857571 lmp.py:767]   Expert 10 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857498.857498 lmp.py:767]   Expert 35 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857664.857664 lmp.py:767]   Expert 55 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857354.857354 lmp.py:767]   Expert 51 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857281.857281 lmp.py:767]   Expert 36 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857971.857971 lmp.py:767]   Expert  8 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857422.857422 lmp.py:767]   Expert 52 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857111.857111 lmp.py:767]   Expert 37 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857516.857516 lmp.py:767]   Expert  0 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857443.857443 lmp.py:767]   Expert 57 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857133.857133 lmp.py:767]   Expert 39 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857583.857583 lmp.py:767]   Expert 25 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857511.857511 lmp.py:767]   Expert 62 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857200.857200 lmp.py:767]   Expert 38 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857128.857128 lmp.py:767]   Expert  7 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857817.857817 lmp.py:767]   Expert 27 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857745.857745 lmp.py:767]   Expert  3 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857627.857627 lmp.py:767]   Expert 24 |    252 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857793.857793 lmp.py:767]   Expert 28 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857244.857244 lmp.py:767]   Expert 21 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857933.857933 lmp.py:767]   Expert 60 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857384.857384 lmp.py:767]   Expert 16 |    263 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857073.857073 lmp.py:767]   Expert 49 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857762.857762 lmp.py:767]   Expert 43 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857213.857213 lmp.py:767]   Expert 23 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857856.857856 lmp.py:767]   Expert 29 |    278 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857022.857022 lmp.py:767]   Expert 15 |    289 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857381.857381 lmp.py:767]   Expert 47 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857024.857024 lmp.py:767]   Expert 22 |    296 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857667.857667 lmp.py:767]   Expert 41 |    297 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857071.857071 lmp.py:767]   Expert 44 |    306 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.857476.857476 lmp.py:767]   Expert 54 |    353 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.857880.857880 lmp.py:767]   Expert 14 |    373 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.858000.858000 lmp.py:767]   Expert 17 |    406 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.858881.858881 lmp.py:767]   Expert 45 |    460 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.858571.858571 lmp.py:769] 
DEBUG 01-07 14:54:33.858571.858571 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.858498.858498 lmp.py:770]   CPU:   1849 tokens
DEBUG 01-07 14:54:33.858380.858380 lmp.py:774]   cuda:1:   5291 tokens (23 experts)
DEBUG 01-07 14:54:33.858784.858784 lmp.py:774]   cuda:2:   5148 tokens (22 experts)
DEBUG 01-07 14:54:33.858712.858712 lmp.py:775]   Total GPU:  10439 tokens
DEBUG 01-07 14:54:33.858163.858163 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.858163.858163 lmp.py:776] 
DEBUG 01-07 14:54:33.858051.858051 cuda_h.py:19] end experts_map_get cost 0.0017316341400146484 seconds
DEBUG 01-07 14:54:33.858409.858409 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.858517.858517 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.858990.858990 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.858303.858303 cuda_h.py:19] end allocate_cuda_memory cost 0.0002002716064453125 seconds
DEBUG 01-07 14:54:33.858021.858021 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.858207.858207 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.858016.858016 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.858951.858951 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1c1d0d8f-dfa2-4f48-a8a6-4a199ac59c96
DEBUG 01-07 14:54:33.858896.858896 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.858443.858443 client.py:127] Model loaded
DEBUG 01-07 14:54:33.859478.859478 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.859920.859920 cuda_h.py:19] end restore2model cost 0.00032901763916015625 seconds
DEBUG 01-07 14:54:33.859498.859498 cuda_h.py:19] end sllm_worker_task cost 0.008783340454101562 seconds
INFO 01-07 14:54:33.859222.859222 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1c1d0d8f-dfa2-4f48-a8a6-4a199ac59c96
DEBUG 01-07 14:54:33.859296.859296 cuda_h.py:19] end load_into_gpu_async cost 0.0010821819305419922 seconds
DEBUG 01-07 14:54:33.859853.859853 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.859696.859696 cuda_h.py:19] end restore_tensors2 cost 0.00021195411682128906 seconds
DEBUG 01-07 14:54:33.860174.860174 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017971992492675781 seconds
DEBUG 01-07 14:54:33.860691.860691 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.861994.861994 cuda_h.py:19] end restore2model cost 0.001880645751953125 seconds
DEBUG 01-07 14:54:33.862519.862519 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.862456.862456 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.862060.862060 cuda_h.py:19] end allocate_cuda_memory cost 0.00020194053649902344 seconds
DEBUG 01-07 14:54:33.862704.862704 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.862599.862599 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.862117.862117 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.862051.862051 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 14d96fca-6ed6-45f9-84a0-20d88bc9feb3
DEBUG 01-07 14:54:33.862214.862214 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.863996.863996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 14d96fca-6ed6-45f9-84a0-20d88bc9feb3
DEBUG 01-07 14:54:33.863726.863726 cuda_h.py:19] end load_into_gpu_async cost 0.0010035037994384766 seconds
DEBUG 01-07 14:54:33.863806.863806 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.863429.863429 cuda_h.py:19] end restore_tensors2 cost 0.00018978118896484375 seconds
DEBUG 01-07 14:54:33.863622.863622 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016634464263916016 seconds
DEBUG 01-07 14:54:33.863279.863279 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.865750.865750 cuda_h.py:19] end restore2model cost 0.0017955303192138672 seconds
DEBUG 01-07 14:54:33.865865.865865 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0074422359466552734 seconds
DEBUG 01-07 14:54:33.865468.865468 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.865570.865570 lmp.py:816] 
DEBUG 01-07 14:54:33.865570.865570 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.865214.865214 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 14:54:33.865387.865387 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.875139.875139 mlpmodule.py:749] group tensors cost 0.00987553596496582 s
DEBUG 01-07 14:54:33.877020.877020 mlpmodule.py:787] pad cost 0.0009899139404296875 s
DEBUG 01-07 14:54:33.877719.877719 mlpmodule.py:793] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-07 14:54:33.877907.877907 mlpmodule.py:798] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-07 14:54:33.887231.887231 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.888098.888098 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.888618.888618 mlpmodule.py:818] group_w3 first element: -0.0211181640625
WARNING 01-07 14:54:33.888126.888126 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.905219.905219 mlpmodule.py:838] group einsum cost 0.027436494827270508 s
DEBUG 01-07 14:54:33.905788.905788 mlpmodule.py:846] cpy2cputensor cost 0.00040984153747558594 s
DEBUG 01-07 14:54:33.908936.908936 cuda_h.py:19] end wait_cetm_experts cost 0.042458534240722656 seconds
DEBUG 01-07 14:54:33.908324.908324 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.908819.908819 cuda_h.py:19] end gpu_sexperts cost 0.0004954338073730469 seconds
DEBUG 01-07 14:54:33.909284.909284 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.909704.909704 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-07 14:54:33.909645.909645 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.909070.909070 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1c1d0d8f-dfa2-4f48-a8a6-4a199ac59c96
INFO 01-07 14:54:33.910558.910558 client.py:127] Model loaded
INFO 01-07 14:54:33.910275.910275 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 14d96fca-6ed6-45f9-84a0-20d88bc9feb3
INFO 01-07 14:54:33.910376.910376 client.py:127] Model loaded
DEBUG 01-07 14:54:33.910073.910073 cuda_h.py:19] end wait_experts_multi_device cost 0.0014770030975341797 seconds
DEBUG 01-07 14:54:33.910783.910783 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.910082.910082 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:33.911378.911378 mlpmodule.py:533] gpu group tensors cost 0.0004534721374511719 s
DEBUG 01-07 14:54:33.913530.913530 mlpmodule.py:566] gpu pad cost 0.0013096332550048828 s
DEBUG 01-07 14:54:33.913558.913558 mlpmodule.py:584] gpu group einsum cost 0.0005438327789306641 s
DEBUG 01-07 14:54:33.915446.915446 mlpmodule.py:656] gpu experts func einsum cost 0.004437446594238281 s
DEBUG 01-07 14:54:33.916025.916025 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:33.916189.916189 mlpmodule.py:533] gpu group tensors cost 0.0004489421844482422 s
DEBUG 01-07 14:54:33.918465.918465 mlpmodule.py:566] gpu pad cost 0.0012676715850830078 s
DEBUG 01-07 14:54:33.918197.918197 mlpmodule.py:584] gpu group einsum cost 0.00044035911560058594 s
DEBUG 01-07 14:54:33.920777.920777 mlpmodule.py:656] gpu experts func einsum cost 0.004358768463134766 s
DEBUG 01-07 14:54:33.920139.920139 mlpmodule.py:707]  experts func einsum cost 0.054972171783447266 s
DEBUG 01-07 14:54:33.921447.921447 cuda_h.py:19] end gpu_experts_multi_device cost 0.010323286056518555 seconds
DEBUG 01-07 14:54:33.921822.921822 cuda_h.py:19] end layer_moe_generate_multi_device_13 cost 0.06544947624206543 seconds
DEBUG 01-07 14:54:33.921901.921901 lmp.py:194] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-07 14:54:33.921671.921671 lmp.py:153] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-07 14:54:33.921320.921320 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 14:54:33.921269.921269 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 14:54:33.921549.921549 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 14:54:33.921490.921490 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.009506225585938e-05 seconds
DEBUG 01-07 14:54:33.921325.921325 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.921069.921069 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.921979.921979 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.921597.921597 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.921996.921996 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.922974.922974 cuda_h.py:19] end allocate_cuda_memory cost 0.0003001689910888672 seconds
DEBUG 01-07 14:54:33.922282.922282 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.922044.922044 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.922198.922198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.922424.922424 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42927fde-fd9a-4750-8e96-897c71815b4e
DEBUG 01-07 14:54:33.922056.922056 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.922773.922773 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.923701.923701 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42927fde-fd9a-4750-8e96-897c71815b4e
DEBUG 01-07 14:54:33.923021.923021 cuda_h.py:19] end load_into_gpu_async cost 0.0008957386016845703 seconds
DEBUG 01-07 14:54:33.923294.923294 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.923515.923515 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 14:54:33.923364.923364 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001519918441772461 seconds
INFO 01-07 14:54:33.923578.923578 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42927fde-fd9a-4750-8e96-897c71815b4e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.926248.926248 cuda_h.py:19] end self_attn cost 0.0036535263061523438 seconds
DEBUG 01-07 14:54:33.926385.926385 cuda_h.py:19] end iln_self_attn_paln cost 0.0051059722900390625 seconds
DEBUG 01-07 14:54:33.926022.926022 cuda_h.py:10] start layer_moe_generate_multi_device_14
DEBUG 01-07 14:54:33.926401.926401 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.927900.927900 cuda_h.py:19] end gate cost 0.0006513595581054688 seconds
DEBUG 01-07 14:54:33.927491.927491 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.927664.927664 lmp.py:744] 
DEBUG 01-07 14:54:33.927664.927664 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.927295.927295 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.927613.927613 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.927402.927402 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.927807.927807 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.927781.927781 lmp.py:749] 
DEBUG 01-07 14:54:33.927781.927781 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.928708.928708 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.928597.928597 lmp.py:767]   Expert 34 |     30 | CPU
DEBUG 01-07 14:54:33.928763.928763 lmp.py:767]   Expert  7 |     32 | CPU
DEBUG 01-07 14:54:33.928214.928214 lmp.py:767]   Expert 13 |     43 | CPU
DEBUG 01-07 14:54:33.928618.928618 lmp.py:767]   Expert 54 |     76 | CPU
DEBUG 01-07 14:54:33.928546.928546 lmp.py:767]   Expert 18 |     82 | CPU
DEBUG 01-07 14:54:33.928997.928997 lmp.py:767]   Expert 39 |     83 | CPU
DEBUG 01-07 14:54:33.928732.928732 lmp.py:767]   Expert 49 |     86 | CPU
DEBUG 01-07 14:54:33.928945.928945 lmp.py:767]   Expert 16 |    103 | CPU
DEBUG 01-07 14:54:33.928680.928680 lmp.py:767]   Expert 59 |    103 | CPU
DEBUG 01-07 14:54:33.928655.928655 lmp.py:767]   Expert 21 |    109 | CPU
DEBUG 01-07 14:54:33.928390.928390 lmp.py:767]   Expert  0 |    111 | CPU
DEBUG 01-07 14:54:33.928364.928364 lmp.py:767]   Expert 41 |    117 | CPU
DEBUG 01-07 14:54:33.928815.928815 lmp.py:767]   Expert 22 |    120 | CPU
DEBUG 01-07 14:54:33.928551.928551 lmp.py:767]   Expert 15 |    122 | CPU
DEBUG 01-07 14:54:33.928286.928286 lmp.py:767]   Expert 45 |    123 | CPU
DEBUG 01-07 14:54:33.928545.928545 lmp.py:767]   Expert 17 |    128 | CPU
DEBUG 01-07 14:54:33.928519.928519 lmp.py:767]   Expert 61 |    132 | CPU
DEBUG 01-07 14:54:33.928016.928016 lmp.py:767]   Expert 52 |    133 | CPU
DEBUG 01-07 14:54:33.928467.928467 lmp.py:767]   Expert  8 |    136 | CPU
DEBUG 01-07 14:54:33.928633.928633 lmp.py:767]   Expert 12 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928753.928753 lmp.py:767]   Expert 38 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928026.928026 lmp.py:767]   Expert 35 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928861.928861 lmp.py:767]   Expert 48 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928027.928027 lmp.py:767]   Expert 31 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928193.928193 lmp.py:767]   Expert 36 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928882.928882 lmp.py:767]   Expert 53 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928572.928572 lmp.py:767]   Expert 50 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928738.928738 lmp.py:767]   Expert 40 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928857.928857 lmp.py:767]   Expert 60 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928262.928262 lmp.py:767]   Expert 27 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928951.928951 lmp.py:767]   Expert 19 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928402.928402 lmp.py:767]   Expert  4 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928092.928092 lmp.py:767]   Expert 29 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928019.928019 lmp.py:767]   Expert 30 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928424.928424 lmp.py:767]   Expert 11 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928590.928590 lmp.py:767]   Expert 20 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928802.928802 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928253.928253 lmp.py:767]   Expert 57 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928943.928943 lmp.py:767]   Expert 46 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928632.928632 lmp.py:767]   Expert  6 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928844.928844 lmp.py:767]   Expert 43 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928295.928295 lmp.py:767]   Expert  2 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928461.928461 lmp.py:767]   Expert 23 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928628.928628 lmp.py:767]   Expert 33 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928317.928317 lmp.py:767]   Expert 42 |    242 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928006.928006 lmp.py:767]   Expert 56 |    252 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928457.928457 lmp.py:767]   Expert 55 |    253 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928146.928146 lmp.py:767]   Expert 32 |    255 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928836.928836 lmp.py:767]   Expert  9 |    260 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928525.928525 lmp.py:767]   Expert  3 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928691.928691 lmp.py:767]   Expert 14 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928619.928619 lmp.py:767]   Expert 28 |    266 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928546.928546 lmp.py:767]   Expert 44 |    272 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928997.928997 lmp.py:767]   Expert 51 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.928687.928687 lmp.py:767]   Expert 58 |    277 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928614.928614 lmp.py:767]   Expert  1 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.928019.928019 lmp.py:767]   Expert 37 |    289 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.929808.929808 lmp.py:767]   Expert 47 |    291 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.929212.929212 lmp.py:767]   Expert 63 |    291 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.929617.929617 lmp.py:767]   Expert 24 |    309 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.929333.929333 lmp.py:767]   Expert 10 |    311 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.929691.929691 lmp.py:767]   Expert 62 |    311 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.929096.929096 lmp.py:767]   Expert 25 |    318 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.929262.929262 lmp.py:767]   Expert  5 |    366 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.929713.929713 lmp.py:769] 
DEBUG 01-07 14:54:33.929713.929713 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.929594.929594 lmp.py:770]   CPU:   1869 tokens
DEBUG 01-07 14:54:33.929714.929714 lmp.py:774]   cuda:1:   5278 tokens (23 experts)
DEBUG 01-07 14:54:33.929357.929357 lmp.py:774]   cuda:2:   5141 tokens (22 experts)
DEBUG 01-07 14:54:33.929570.929570 lmp.py:775]   Total GPU:  10419 tokens
DEBUG 01-07 14:54:33.929021.929021 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.929021.929021 lmp.py:776] 
DEBUG 01-07 14:54:33.929147.929147 cuda_h.py:19] end experts_map_get cost 0.0017538070678710938 seconds
DEBUG 01-07 14:54:33.929790.929790 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.929136.929136 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.929332.929332 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.929167.929167 cuda_h.py:19] end allocate_cuda_memory cost 0.0001976490020751953 seconds
DEBUG 01-07 14:54:33.929785.929785 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.929217.929217 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.929742.929742 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.929107.929107 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 08c767d8-dd7f-4092-9550-0299ad560a38
DEBUG 01-07 14:54:33.929482.929482 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.930429.930429 client.py:127] Model loaded
DEBUG 01-07 14:54:33.930796.930796 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.930046.930046 cuda_h.py:19] end restore2model cost 0.0003249645233154297 seconds
DEBUG 01-07 14:54:33.930670.930670 cuda_h.py:19] end sllm_worker_task cost 0.008908748626708984 seconds
INFO 01-07 14:54:33.930959.930959 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 08c767d8-dd7f-4092-9550-0299ad560a38
DEBUG 01-07 14:54:33.930087.930087 cuda_h.py:19] end load_into_gpu_async cost 0.00106048583984375 seconds
DEBUG 01-07 14:54:33.930883.930883 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.931924.931924 cuda_h.py:19] end restore_tensors2 cost 0.00021719932556152344 seconds
DEBUG 01-07 14:54:33.931071.931071 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017898082733154297 seconds
DEBUG 01-07 14:54:33.931880.931880 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.933812.933812 cuda_h.py:19] end restore2model cost 0.0018870830535888672 seconds
DEBUG 01-07 14:54:33.933291.933291 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.933989.933989 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.933031.933031 cuda_h.py:19] end allocate_cuda_memory cost 0.0002090930938720703 seconds
DEBUG 01-07 14:54:33.933251.933251 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.933815.933815 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.933763.933763 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.933698.933698 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb7a02d9-5dd8-4d56-8850-76e3cb6f8eab
DEBUG 01-07 14:54:33.933861.933861 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.934093.934093 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb7a02d9-5dd8-4d56-8850-76e3cb6f8eab
DEBUG 01-07 14:54:33.934730.934730 cuda_h.py:19] end load_into_gpu_async cost 0.0010237693786621094 seconds
DEBUG 01-07 14:54:33.934334.934334 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.934679.934679 cuda_h.py:19] end restore_tensors2 cost 0.0001952648162841797 seconds
DEBUG 01-07 14:54:33.934826.934826 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001699686050415039 seconds
DEBUG 01-07 14:54:33.934151.934151 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.936437.936437 cuda_h.py:19] end restore2model cost 0.0017981529235839844 seconds
DEBUG 01-07 14:54:33.936697.936697 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007494211196899414 seconds
DEBUG 01-07 14:54:33.936831.936831 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:33.936416.936416 lmp.py:816] 
DEBUG 01-07 14:54:33.936416.936416 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:33.936345.936345 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 14:54:33.936233.936233 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:33.942190.942190 mlpmodule.py:749] group tensors cost 0.005111217498779297 s
DEBUG 01-07 14:54:33.944129.944129 mlpmodule.py:787] pad cost 0.0012562274932861328 s
DEBUG 01-07 14:54:33.944093.944093 mlpmodule.py:793] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-07 14:54:33.944539.944539 mlpmodule.py:798] move to cpu cost 3.814697265625e-05 s
DEBUG 01-07 14:54:33.954882.954882 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:33.954557.954557 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:33.954647.954647 mlpmodule.py:818] group_w3 first element: 0.000789642333984375
WARNING 01-07 14:54:33.954439.954439 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:33.972919.972919 mlpmodule.py:838] group einsum cost 0.02846217155456543 s
DEBUG 01-07 14:54:33.973216.973216 mlpmodule.py:846] cpy2cputensor cost 0.0003814697265625 s
DEBUG 01-07 14:54:33.976489.976489 cuda_h.py:19] end wait_cetm_experts cost 0.03904843330383301 seconds
DEBUG 01-07 14:54:33.976088.976088 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:33.976539.976539 cuda_h.py:19] end gpu_sexperts cost 0.0005700588226318359 seconds
DEBUG 01-07 14:54:33.976204.976204 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:33.976584.976584 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-07 14:54:33.976571.976571 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:33.976235.976235 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 08c767d8-dd7f-4092-9550-0299ad560a38
INFO 01-07 14:54:33.977303.977303 client.py:127] Model loaded
INFO 01-07 14:54:33.977795.977795 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb7a02d9-5dd8-4d56-8850-76e3cb6f8eab
INFO 01-07 14:54:33.978013.978013 client.py:127] Model loaded
DEBUG 01-07 14:54:33.978458.978458 cuda_h.py:19] end wait_experts_multi_device cost 0.0013251304626464844 seconds
DEBUG 01-07 14:54:33.978499.978499 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:33.978176.978176 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:33.979451.979451 mlpmodule.py:533] gpu group tensors cost 0.00045943260192871094 s
DEBUG 01-07 14:54:33.980722.980722 mlpmodule.py:566] gpu pad cost 0.001295328140258789 s
DEBUG 01-07 14:54:33.981782.981782 mlpmodule.py:584] gpu group einsum cost 0.0005354881286621094 s
DEBUG 01-07 14:54:33.983538.983538 mlpmodule.py:656] gpu experts func einsum cost 0.004422426223754883 s
DEBUG 01-07 14:54:33.983679.983679 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:33.984061.984061 mlpmodule.py:707]  experts func einsum cost 0.047342538833618164 s
DEBUG 01-07 14:54:33.984854.984854 mlpmodule.py:533] gpu group tensors cost 0.0005280971527099609 s
DEBUG 01-07 14:54:33.985322.985322 mlpmodule.py:566] gpu pad cost 0.001255035400390625 s
DEBUG 01-07 14:54:33.986061.986061 mlpmodule.py:584] gpu group einsum cost 0.0004456043243408203 s
DEBUG 01-07 14:54:33.988859.988859 mlpmodule.py:656] gpu experts func einsum cost 0.004433393478393555 s
DEBUG 01-07 14:54:33.988472.988472 cuda_h.py:19] end gpu_experts_multi_device cost 0.010239124298095703 seconds
DEBUG 01-07 14:54:33.988494.988494 cuda_h.py:19] end layer_moe_generate_multi_device_14 cost 0.061939239501953125 seconds
DEBUG 01-07 14:54:33.988481.988481 lmp.py:194] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-07 14:54:33.988151.988151 lmp.py:153] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-07 14:54:33.988801.988801 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 14:54:33.988796.988796 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 14:54:33.989917.989917 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 14:54:33.989719.989719 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.793571472167969e-05 seconds
DEBUG 01-07 14:54:33.989223.989223 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:33.989351.989351 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:33.989108.989108 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:33.989316.989316 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.989761.989761 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.989527.989527 cuda_h.py:19] end allocate_cuda_memory cost 0.0002827644348144531 seconds
DEBUG 01-07 14:54:33.989066.989066 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.989875.989875 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.989221.989221 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.989970.989970 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b829b2ec-0737-4f14-9e2d-c450e83dd1fe
DEBUG 01-07 14:54:33.989933.989933 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:33.990127.990127 cuda_h.py:10] start self_attn
INFO 01-07 14:54:33.990307.990307 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b829b2ec-0737-4f14-9e2d-c450e83dd1fe
DEBUG 01-07 14:54:33.990766.990766 cuda_h.py:19] end load_into_gpu_async cost 0.0009019374847412109 seconds
DEBUG 01-07 14:54:33.990562.990562 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.990068.990068 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 14:54:33.990871.990871 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015032291412353516 seconds
INFO 01-07 14:54:33.990468.990468 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b829b2ec-0737-4f14-9e2d-c450e83dd1fe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:33.993379.993379 cuda_h.py:19] end self_attn cost 0.0037016868591308594 seconds
DEBUG 01-07 14:54:33.994390.994390 cuda_h.py:19] end iln_self_attn_paln cost 0.005148410797119141 seconds
DEBUG 01-07 14:54:33.994888.994888 cuda_h.py:10] start layer_moe_generate_multi_device_15
DEBUG 01-07 14:54:33.994412.994412 cuda_h.py:10] start gate
DEBUG 01-07 14:54:33.995336.995336 cuda_h.py:19] end gate cost 0.0006468296051025391 seconds
DEBUG 01-07 14:54:33.995973.995973 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:33.995477.995477 lmp.py:744] 
DEBUG 01-07 14:54:33.995477.995477 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:33.995154.995154 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:33.995234.995234 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:33.995546.995546 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:33.995712.995712 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:33.995686.995686 lmp.py:749] 
DEBUG 01-07 14:54:33.995686.995686 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:33.995614.995614 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:33.995502.995502 lmp.py:767]   Expert 15 |     66 | CPU
DEBUG 01-07 14:54:33.995430.995430 lmp.py:767]   Expert 41 |     68 | CPU
DEBUG 01-07 14:54:33.995642.995642 lmp.py:767]   Expert  0 |     74 | CPU
DEBUG 01-07 14:54:33.995332.995332 lmp.py:767]   Expert 63 |     77 | CPU
DEBUG 01-07 14:54:33.995783.995783 lmp.py:767]   Expert 20 |     82 | CPU
DEBUG 01-07 14:54:33.995995.995995 lmp.py:767]   Expert  7 |     92 | CPU
DEBUG 01-07 14:54:33.995969.995969 lmp.py:767]   Expert 45 |     93 | CPU
DEBUG 01-07 14:54:33.995705.995705 lmp.py:767]   Expert 28 |     94 | CPU
DEBUG 01-07 14:54:33.995679.995679 lmp.py:767]   Expert 54 |    109 | CPU
DEBUG 01-07 14:54:33.995176.995176 lmp.py:767]   Expert 12 |    110 | CPU
DEBUG 01-07 14:54:33.995912.995912 lmp.py:767]   Expert 40 |    120 | CPU
DEBUG 01-07 14:54:33.995409.995409 lmp.py:767]   Expert 52 |    121 | CPU
DEBUG 01-07 14:54:33.995621.995621 lmp.py:767]   Expert  5 |    123 | CPU
DEBUG 01-07 14:54:33.995072.995072 lmp.py:767]   Expert 59 |    123 | CPU
DEBUG 01-07 14:54:33.995285.995285 lmp.py:767]   Expert  4 |    130 | CPU
DEBUG 01-07 14:54:33.995259.995259 lmp.py:767]   Expert 34 |    132 | CPU
DEBUG 01-07 14:54:33.995756.995756 lmp.py:767]   Expert 21 |    136 | CPU
DEBUG 01-07 14:54:33.995491.995491 lmp.py:767]   Expert 55 |    136 | CPU
DEBUG 01-07 14:54:33.995989.995989 lmp.py:767]   Expert 13 |    137 | CPU
DEBUG 01-07 14:54:33.995155.995155 lmp.py:767]   Expert 62 |    137 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.995275.995275 lmp.py:767]   Expert 61 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.995394.995394 lmp.py:767]   Expert 42 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.995561.995561 lmp.py:767]   Expert 14 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996250.996250 lmp.py:767]   Expert 10 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996701.996701 lmp.py:767]   Expert 22 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996390.996390 lmp.py:767]   Expert 51 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996079.996079 lmp.py:767]   Expert 32 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996484.996484 lmp.py:767]   Expert 25 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996650.996650 lmp.py:767]   Expert 50 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996578.996578 lmp.py:767]   Expert  1 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996267.996267 lmp.py:767]   Expert 47 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996480.996480 lmp.py:767]   Expert 26 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996169.996169 lmp.py:767]   Expert 53 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996097.996097 lmp.py:767]   Expert  2 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996024.996024 lmp.py:767]   Expert  6 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996190.996190 lmp.py:767]   Expert 19 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996357.996357 lmp.py:767]   Expert 11 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996807.996807 lmp.py:767]   Expert 35 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996258.996258 lmp.py:767]   Expert 30 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996948.996948 lmp.py:767]   Expert 56 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996399.996399 lmp.py:767]   Expert 57 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996373.996373 lmp.py:767]   Expert 48 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996585.996585 lmp.py:767]   Expert 44 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996990.996990 lmp.py:767]   Expert 24 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996917.996917 lmp.py:767]   Expert 16 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996845.996845 lmp.py:767]   Expert 46 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996594.996594 lmp.py:767]   Expert 39 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996284.996284 lmp.py:767]   Expert 18 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996973.996973 lmp.py:767]   Expert 29 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996185.996185 lmp.py:767]   Expert 37 |    243 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996636.996636 lmp.py:767]   Expert 31 |    253 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996564.996564 lmp.py:767]   Expert  3 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996492.996492 lmp.py:767]   Expert 36 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996942.996942 lmp.py:767]   Expert 60 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996155.996155 lmp.py:767]   Expert  9 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996606.996606 lmp.py:767]   Expert 38 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996818.996818 lmp.py:767]   Expert 17 |    268 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996746.996746 lmp.py:767]   Expert 23 |    275 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996912.996912 lmp.py:767]   Expert 27 |    349 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996317.996317 lmp.py:767]   Expert 43 |    362 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996198.996198 lmp.py:767]   Expert  8 |    403 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996603.996603 lmp.py:767]   Expert 33 |    403 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996769.996769 lmp.py:767]   Expert 58 |    444 | GPU1(cuda:2)
DEBUG 01-07 14:54:33.996935.996935 lmp.py:767]   Expert 49 |    545 | GPU0(cuda:1)
DEBUG 01-07 14:54:33.996147.996147 lmp.py:769] 
DEBUG 01-07 14:54:33.996147.996147 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:33.996314.996314 lmp.py:770]   CPU:   2023 tokens
DEBUG 01-07 14:54:33.996195.996195 lmp.py:774]   cuda:1:   5075 tokens (22 experts)
DEBUG 01-07 14:54:33.996076.996076 lmp.py:774]   cuda:2:   5190 tokens (23 experts)
DEBUG 01-07 14:54:33.996527.996527 lmp.py:775]   Total GPU:  10265 tokens
DEBUG 01-07 14:54:33.996846.996846 lmp.py:776] ============================================================
DEBUG 01-07 14:54:33.996846.996846 lmp.py:776] 
DEBUG 01-07 14:54:33.996972.996972 cuda_h.py:19] end experts_map_get cost 0.0017266273498535156 seconds
DEBUG 01-07 14:54:33.996900.996900 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:33.996816.996816 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:33.996673.996673 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:33.997085.997085 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
DEBUG 01-07 14:54:33.997413.997413 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:33.997785.997785 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:33.997117.997117 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:33.997767.997767 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba960f72-c384-43de-be98-9fc71e4d43fd
DEBUG 01-07 14:54:33.997235.997235 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:33.997900.997900 client.py:127] Model loaded
DEBUG 01-07 14:54:33.997910.997910 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:33.998479.998479 cuda_h.py:19] end restore2model cost 0.00034928321838378906 seconds
DEBUG 01-07 14:54:33.998441.998441 cuda_h.py:19] end sllm_worker_task cost 0.00887608528137207 seconds
INFO 01-07 14:54:33.998190.998190 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba960f72-c384-43de-be98-9fc71e4d43fd
DEBUG 01-07 14:54:33.998603.998603 cuda_h.py:19] end load_into_gpu_async cost 0.0010924339294433594 seconds
DEBUG 01-07 14:54:33.998114.998114 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:33.998857.998857 cuda_h.py:19] end restore_tensors2 cost 0.0002079010009765625 seconds
DEBUG 01-07 14:54:33.998288.998288 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001837015151977539 seconds
DEBUG 01-07 14:54:33.998475.998475 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.000921.000921 cuda_h.py:19] end restore2model cost 0.001809835433959961 seconds
DEBUG 01-07 14:54:34.000923.000923 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.000012.000012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.001047.001047 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-07 14:54:34.001075.001075 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.001831.001831 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.001495.001495 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.001191.001191 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 96154a44-4476-403b-9688-4fb7022a4f18
DEBUG 01-07 14:54:34.001976.001976 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.002415.002415 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 96154a44-4476-403b-9688-4fb7022a4f18
DEBUG 01-07 14:54:34.002099.002099 cuda_h.py:19] end load_into_gpu_async cost 0.0010731220245361328 seconds
DEBUG 01-07 14:54:34.002656.002656 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.002577.002577 cuda_h.py:19] end restore_tensors2 cost 0.0001990795135498047 seconds
DEBUG 01-07 14:54:34.002963.002963 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001756906509399414 seconds
DEBUG 01-07 14:54:34.002096.002096 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.004205.004205 cuda_h.py:19] end restore2model cost 0.0018434524536132812 seconds
DEBUG 01-07 14:54:34.004115.004115 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007581472396850586 seconds
DEBUG 01-07 14:54:34.004387.004387 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.004635.004635 lmp.py:816] 
DEBUG 01-07 14:54:34.004635.004635 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.004710.004710 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-07 14:54:34.004359.004359 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.010298.010298 mlpmodule.py:749] group tensors cost 0.005934476852416992 s
DEBUG 01-07 14:54:34.013323.013323 mlpmodule.py:787] pad cost 0.001688241958618164 s
DEBUG 01-07 14:54:34.013805.013805 mlpmodule.py:793] create cpu tensor cost 5.745887756347656e-05 s
DEBUG 01-07 14:54:34.013716.013716 mlpmodule.py:798] move to cpu cost 4.887580871582031e-05 s
DEBUG 01-07 14:54:34.024658.024658 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.024105.024105 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.024870.024870 mlpmodule.py:818] group_w3 first element: -0.0595703125
WARNING 01-07 14:54:34.024146.024146 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.042158.042158 mlpmodule.py:838] group einsum cost 0.029127120971679688 s
DEBUG 01-07 14:54:34.043251.043251 mlpmodule.py:846] cpy2cputensor cost 0.0003936290740966797 s
DEBUG 01-07 14:54:34.046806.046806 cuda_h.py:19] end wait_cetm_experts cost 0.041365861892700195 seconds
DEBUG 01-07 14:54:34.046835.046835 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.046291.046291 cuda_h.py:19] end gpu_sexperts cost 0.0005021095275878906 seconds
DEBUG 01-07 14:54:34.046472.046472 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.046567.046567 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:34.046415.046415 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.046079.046079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba960f72-c384-43de-be98-9fc71e4d43fd
INFO 01-07 14:54:34.047042.047042 client.py:127] Model loaded
INFO 01-07 14:54:34.047070.047070 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 96154a44-4476-403b-9688-4fb7022a4f18
INFO 01-07 14:54:34.048017.048017 client.py:127] Model loaded
DEBUG 01-07 14:54:34.048939.048939 cuda_h.py:19] end wait_experts_multi_device cost 0.0013744831085205078 seconds
DEBUG 01-07 14:54:34.048072.048072 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.048180.048180 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.049438.049438 mlpmodule.py:533] gpu group tensors cost 0.0004725456237792969 s
DEBUG 01-07 14:54:34.050410.050410 mlpmodule.py:566] gpu pad cost 0.0012831687927246094 s
DEBUG 01-07 14:54:34.051007.051007 mlpmodule.py:584] gpu group einsum cost 0.0005443096160888672 s
DEBUG 01-07 14:54:34.053077.053077 mlpmodule.py:656] gpu experts func einsum cost 0.00452733039855957 s
DEBUG 01-07 14:54:34.053517.053517 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.054379.054379 mlpmodule.py:707]  experts func einsum cost 0.049729108810424805 s
DEBUG 01-07 14:54:34.054630.054630 mlpmodule.py:533] gpu group tensors cost 0.0005326271057128906 s
DEBUG 01-07 14:54:34.055024.055024 mlpmodule.py:566] gpu pad cost 0.001201629638671875 s
DEBUG 01-07 14:54:34.056593.056593 mlpmodule.py:584] gpu group einsum cost 0.0004949569702148438 s
DEBUG 01-07 14:54:34.058652.058652 mlpmodule.py:656] gpu experts func einsum cost 0.0043447017669677734 s
DEBUG 01-07 14:54:34.058874.058874 cuda_h.py:19] end gpu_experts_multi_device cost 0.010253190994262695 seconds
DEBUG 01-07 14:54:34.058559.058559 cuda_h.py:19] end layer_moe_generate_multi_device_15 cost 0.06429910659790039 seconds
DEBUG 01-07 14:54:34.058830.058830 lmp.py:194] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-07 14:54:34.058600.058600 lmp.py:153] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-07 14:54:34.058773.058773 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 14:54:34.058529.058529 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 14:54:34.058173.058173 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.765655517578125e-05 seconds
DEBUG 01-07 14:54:34.059591.059591 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.8650970458984375e-05 seconds
DEBUG 01-07 14:54:34.059618.059618 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.059077.059077 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.059252.059252 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.059871.059871 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.059124.059124 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.059644.059644 cuda_h.py:19] end allocate_cuda_memory cost 0.00027942657470703125 seconds
DEBUG 01-07 14:54:34.059355.059355 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.059542.059542 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.059172.059172 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.059729.059729 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de7c4164-c257-44ff-82f6-e5475e7d345e
DEBUG 01-07 14:54:34.059884.059884 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.060914.060914 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.061465.061465 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de7c4164-c257-44ff-82f6-e5475e7d345e
DEBUG 01-07 14:54:34.062162.062162 cuda_h.py:19] end load_into_gpu_async cost 0.0023179054260253906 seconds
DEBUG 01-07 14:54:34.062196.062196 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.062703.062703 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 14:54:34.062505.062505 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002897500991821289 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
INFO 01-07 14:54:34.062596.062596 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de7c4164-c257-44ff-82f6-e5475e7d345e
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.063193.063193 cuda_h.py:19] end self_attn cost 0.0029168128967285156 seconds
DEBUG 01-07 14:54:34.063760.063760 cuda_h.py:19] end iln_self_attn_paln cost 0.004394054412841797 seconds
DEBUG 01-07 14:54:34.063735.063735 cuda_h.py:10] start layer_moe_generate_multi_device_16
DEBUG 01-07 14:54:34.063352.063352 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.064368.064368 cuda_h.py:19] end gate cost 0.0006453990936279297 seconds
DEBUG 01-07 14:54:34.064436.064436 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.064198.064198 lmp.py:744] 
DEBUG 01-07 14:54:34.064198.064198 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.064591.064591 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.064386.064386 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.064175.064175 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.064579.064579 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.064553.064553 lmp.py:749] 
DEBUG 01-07 14:54:34.064553.064553 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.064243.064243 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.064369.064369 lmp.py:767]   Expert 58 |     34 | CPU
DEBUG 01-07 14:54:34.064774.064774 lmp.py:767]   Expert 31 |     60 | CPU
DEBUG 01-07 14:54:34.064225.064225 lmp.py:767]   Expert 47 |     61 | CPU
DEBUG 01-07 14:54:34.064153.064153 lmp.py:767]   Expert 49 |     61 | CPU
DEBUG 01-07 14:54:34.064842.064842 lmp.py:767]   Expert  4 |     66 | CPU
DEBUG 01-07 14:54:34.064054.064054 lmp.py:767]   Expert 38 |     68 | CPU
DEBUG 01-07 14:54:34.064790.064790 lmp.py:767]   Expert 45 |     70 | CPU
DEBUG 01-07 14:54:34.064764.064764 lmp.py:767]   Expert 41 |     84 | CPU
DEBUG 01-07 14:54:34.064261.064261 lmp.py:767]   Expert 43 |     86 | CPU
DEBUG 01-07 14:54:34.064235.064235 lmp.py:767]   Expert 33 |     95 | CPU
DEBUG 01-07 14:54:34.065732.065732 lmp.py:767]   Expert 50 |    102 | CPU
DEBUG 01-07 14:54:34.065706.065706 lmp.py:767]   Expert 57 |    102 | CPU
DEBUG 01-07 14:54:34.065157.065157 lmp.py:767]   Expert 11 |    108 | CPU
DEBUG 01-07 14:54:34.065370.065370 lmp.py:767]   Expert  2 |    114 | CPU
DEBUG 01-07 14:54:34.065821.065821 lmp.py:767]   Expert 14 |    118 | CPU
DEBUG 01-07 14:54:34.065556.065556 lmp.py:767]   Expert 51 |    120 | CPU
DEBUG 01-07 14:54:34.065292.065292 lmp.py:767]   Expert  0 |    121 | CPU
DEBUG 01-07 14:54:34.065028.065028 lmp.py:767]   Expert 54 |    127 | CPU
DEBUG 01-07 14:54:34.065002.065002 lmp.py:767]   Expert 56 |    140 | CPU
DEBUG 01-07 14:54:34.065121.065121 lmp.py:767]   Expert 26 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065526.065526 lmp.py:767]   Expert 34 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065215.065215 lmp.py:767]   Expert 27 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065143.065143 lmp.py:767]   Expert 28 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065071.065071 lmp.py:767]   Expert 55 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065237.065237 lmp.py:767]   Expert 10 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065688.065688 lmp.py:767]   Expert 25 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065092.065092 lmp.py:767]   Expert  9 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065258.065258 lmp.py:767]   Expert 13 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065948.065948 lmp.py:767]   Expert 61 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065399.065399 lmp.py:767]   Expert 48 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065611.065611 lmp.py:767]   Expert  6 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065300.065300 lmp.py:767]   Expert  7 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065274.065274 lmp.py:767]   Expert 46 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065725.065725 lmp.py:767]   Expert 24 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065653.065653 lmp.py:767]   Expert 42 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065819.065819 lmp.py:767]   Expert 18 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065270.065270 lmp.py:767]   Expert 40 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065483.065483 lmp.py:767]   Expert 63 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065933.065933 lmp.py:767]   Expert 12 |    215 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065384.065384 lmp.py:767]   Expert 59 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065597.065597 lmp.py:767]   Expert 21 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065809.065809 lmp.py:767]   Expert 29 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065737.065737 lmp.py:767]   Expert 22 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065903.065903 lmp.py:767]   Expert 32 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065592.065592 lmp.py:767]   Expert 19 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065043.065043 lmp.py:767]   Expert 36 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065494.065494 lmp.py:767]   Expert  3 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065945.065945 lmp.py:767]   Expert 37 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065396.065396 lmp.py:767]   Expert  1 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065847.065847 lmp.py:767]   Expert 16 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065775.065775 lmp.py:767]   Expert  5 |    260 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065464.065464 lmp.py:767]   Expert 20 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065153.065153 lmp.py:767]   Expert  8 |    265 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065842.065842 lmp.py:767]   Expert 15 |    271 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065816.065816 lmp.py:767]   Expert 30 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065506.065506 lmp.py:767]   Expert 62 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065957.065957 lmp.py:767]   Expert 39 |    299 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065123.065123 lmp.py:767]   Expert 35 |    301 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065289.065289 lmp.py:767]   Expert 17 |    307 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065693.065693 lmp.py:767]   Expert 60 |    317 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065575.065575 lmp.py:767]   Expert 52 |    355 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065979.065979 lmp.py:767]   Expert 23 |    362 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065146.065146 lmp.py:767]   Expert 44 |    378 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.065312.065312 lmp.py:767]   Expert 53 |    442 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.065524.065524 lmp.py:769] 
DEBUG 01-07 14:54:34.065524.065524 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.065167.065167 lmp.py:770]   CPU:   1737 tokens
DEBUG 01-07 14:54:34.065525.065525 lmp.py:774]   cuda:1:   5342 tokens (23 experts)
DEBUG 01-07 14:54:34.065930.065930 lmp.py:774]   cuda:2:   5209 tokens (22 experts)
DEBUG 01-07 14:54:34.065858.065858 lmp.py:775]   Total GPU:  10551 tokens
DEBUG 01-07 14:54:34.065309.065309 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.065309.065309 lmp.py:776] 
DEBUG 01-07 14:54:34.066197.066197 cuda_h.py:19] end experts_map_get cost 0.0017261505126953125 seconds
DEBUG 01-07 14:54:34.066317.066317 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.066424.066424 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.066381.066381 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.068116.068116 cuda_h.py:19] end allocate_cuda_memory cost 0.0019495487213134766 seconds
DEBUG 01-07 14:54:34.068357.068357 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.068305.068305 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.068068.068068 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.068195.068195 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bef34f31-9f42-4e12-a2c2-97ef74413f46
DEBUG 01-07 14:54:34.068307.068307 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.068631.068631 client.py:127] Model loaded
DEBUG 01-07 14:54:34.068520.068520 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.069562.069562 cuda_h.py:19] end restore2model cost 0.0004124641418457031 seconds
DEBUG 01-07 14:54:34.069722.069722 cuda_h.py:19] end sllm_worker_task cost 0.01000833511352539 seconds
INFO 01-07 14:54:34.069393.069393 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bef34f31-9f42-4e12-a2c2-97ef74413f46
DEBUG 01-07 14:54:34.069521.069521 cuda_h.py:19] end load_into_gpu_async cost 0.001279592514038086 seconds
DEBUG 01-07 14:54:34.069554.069554 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.069748.069748 cuda_h.py:19] end restore_tensors2 cost 0.00022363662719726562 seconds
DEBUG 01-07 14:54:34.069610.069610 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037665367126464844 seconds
DEBUG 01-07 14:54:34.069135.069135 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.071523.071523 cuda_h.py:19] end restore2model cost 0.0018732547760009766 seconds
DEBUG 01-07 14:54:34.071717.071717 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.071515.071515 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.072524.072524 cuda_h.py:19] end allocate_cuda_memory cost 0.0002186298370361328 seconds
DEBUG 01-07 14:54:34.072698.072698 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.072023.072023 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.072594.072594 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.072959.072959 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01ff5e23-618c-4124-ae24-7507d6630583
DEBUG 01-07 14:54:34.072427.072427 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.073981.073981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01ff5e23-618c-4124-ae24-7507d6630583
DEBUG 01-07 14:54:34.073426.073426 cuda_h.py:19] end load_into_gpu_async cost 0.0011379718780517578 seconds
DEBUG 01-07 14:54:34.073745.073745 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.073997.073997 cuda_h.py:19] end restore_tensors2 cost 0.00019741058349609375 seconds
DEBUG 01-07 14:54:34.073429.073429 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018310546875 seconds
DEBUG 01-07 14:54:34.073708.073708 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.075516.075516 cuda_h.py:19] end restore2model cost 0.0017619132995605469 seconds
DEBUG 01-07 14:54:34.075915.075915 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009548664093017578 seconds
DEBUG 01-07 14:54:34.075234.075234 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.075065.075065 lmp.py:816] 
DEBUG 01-07 14:54:34.075065.075065 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.075424.075424 cuda_h.py:19] end cpu_experts_submit cost 0.00011515617370605469 seconds
DEBUG 01-07 14:54:34.075835.075835 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.086765.086765 mlpmodule.py:749] group tensors cost 0.011022567749023438 s
DEBUG 01-07 14:54:34.089730.089730 mlpmodule.py:787] pad cost 0.0012922286987304688 s
DEBUG 01-07 14:54:34.089951.089951 mlpmodule.py:793] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-07 14:54:34.089848.089848 mlpmodule.py:798] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-07 14:54:34.097863.097863 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.098008.098008 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.098634.098634 mlpmodule.py:818] group_w3 first element: -0.02490234375
WARNING 01-07 14:54:34.098472.098472 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.111641.111641 mlpmodule.py:838] group einsum cost 0.022420883178710938 s
DEBUG 01-07 14:54:34.112679.112679 mlpmodule.py:846] cpy2cputensor cost 0.0003731250762939453 s
DEBUG 01-07 14:54:34.114576.114576 cuda_h.py:19] end wait_cetm_experts cost 0.03908848762512207 seconds
DEBUG 01-07 14:54:34.115275.115275 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.115207.115207 cuda_h.py:19] end gpu_sexperts cost 0.0005025863647460938 seconds
DEBUG 01-07 14:54:34.115818.115818 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.115476.115476 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 14:54:34.115947.115947 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.115657.115657 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bef34f31-9f42-4e12-a2c2-97ef74413f46
INFO 01-07 14:54:34.116588.116588 client.py:127] Model loaded
INFO 01-07 14:54:34.116232.116232 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01ff5e23-618c-4124-ae24-7507d6630583
INFO 01-07 14:54:34.117225.117225 client.py:127] Model loaded
DEBUG 01-07 14:54:34.117670.117670 cuda_h.py:19] end wait_experts_multi_device cost 0.0013806819915771484 seconds
DEBUG 01-07 14:54:34.117803.117803 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.117480.117480 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:34.118909.118909 mlpmodule.py:533] gpu group tensors cost 0.0004611015319824219 s
DEBUG 01-07 14:54:34.119442.119442 mlpmodule.py:566] gpu pad cost 0.0012390613555908203 s
DEBUG 01-07 14:54:34.120095.120095 mlpmodule.py:584] gpu group einsum cost 0.0006170272827148438 s
DEBUG 01-07 14:54:34.122526.122526 mlpmodule.py:656] gpu experts func einsum cost 0.004464626312255859 s
DEBUG 01-07 14:54:34.122324.122324 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:34.123499.123499 mlpmodule.py:707]  experts func einsum cost 0.04739880561828613 s
DEBUG 01-07 14:54:34.123558.123558 mlpmodule.py:533] gpu group tensors cost 0.0005521774291992188 s
DEBUG 01-07 14:54:34.124048.124048 mlpmodule.py:566] gpu pad cost 0.001306295394897461 s
DEBUG 01-07 14:54:34.125879.125879 mlpmodule.py:584] gpu group einsum cost 0.0004410743713378906 s
DEBUG 01-07 14:54:34.127603.127603 mlpmodule.py:656] gpu experts func einsum cost 0.004487276077270508 s
DEBUG 01-07 14:54:34.127302.127302 cuda_h.py:19] end gpu_experts_multi_device cost 0.010311365127563477 seconds
DEBUG 01-07 14:54:34.127941.127941 cuda_h.py:19] end layer_moe_generate_multi_device_16 cost 0.06405973434448242 seconds
DEBUG 01-07 14:54:34.127927.127927 lmp.py:194] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-07 14:54:34.127743.127743 lmp.py:153] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-07 14:54:34.127393.127393 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 14:54:34.127195.127195 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 14:54:34.127270.127270 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:34.127735.127735 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.8650970458984375e-05 seconds
DEBUG 01-07 14:54:34.127669.127669 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.128320.128320 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.128217.128217 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.128644.128644 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.128566.128566 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.128093.128093 cuda_h.py:19] end allocate_cuda_memory cost 0.00028443336486816406 seconds
DEBUG 01-07 14:54:34.128685.128685 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.128971.128971 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.128125.128125 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.128351.128351 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3be68013-0c21-43ba-95b8-84de8862253e
DEBUG 01-07 14:54:34.128122.128122 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.129792.129792 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.129868.129868 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3be68013-0c21-43ba-95b8-84de8862253e
DEBUG 01-07 14:54:34.129553.129553 cuda_h.py:19] end load_into_gpu_async cost 0.0009531974792480469 seconds
DEBUG 01-07 14:54:34.129262.129262 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.129391.129391 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-07 14:54:34.129863.129863 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015723705291748047 seconds
INFO 01-07 14:54:34.129732.129732 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3be68013-0c21-43ba-95b8-84de8862253e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.132668.132668 cuda_h.py:19] end self_attn cost 0.0037431716918945312 seconds
DEBUG 01-07 14:54:34.133712.133712 cuda_h.py:19] end iln_self_attn_paln cost 0.005198001861572266 seconds
DEBUG 01-07 14:54:34.133395.133395 cuda_h.py:10] start layer_moe_generate_multi_device_17
DEBUG 01-07 14:54:34.133211.133211 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.133142.133142 cuda_h.py:19] end gate cost 0.0006511211395263672 seconds
DEBUG 01-07 14:54:34.134779.134779 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.134329.134329 lmp.py:744] 
DEBUG 01-07 14:54:34.134329.134329 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.134483.134483 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.134278.134278 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.134590.134590 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.134756.134756 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.134492.134492 lmp.py:749] 
DEBUG 01-07 14:54:34.134492.134492 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.134943.134943 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.134023.134023 lmp.py:767]   Expert  4 |     11 | CPU
DEBUG 01-07 14:54:34.134381.134381 lmp.py:767]   Expert 28 |     27 | CPU
DEBUG 01-07 14:54:34.134071.134071 lmp.py:767]   Expert  7 |     45 | CPU
DEBUG 01-07 14:54:34.134760.134760 lmp.py:767]   Expert 53 |     57 | CPU
DEBUG 01-07 14:54:34.134211.134211 lmp.py:767]   Expert 52 |     67 | CPU
DEBUG 01-07 14:54:34.134185.134185 lmp.py:767]   Expert 43 |     73 | CPU
DEBUG 01-07 14:54:34.134874.134874 lmp.py:767]   Expert 49 |     80 | CPU
DEBUG 01-07 14:54:34.134848.134848 lmp.py:767]   Expert 12 |     87 | CPU
DEBUG 01-07 14:54:34.134584.134584 lmp.py:767]   Expert 47 |    103 | CPU
DEBUG 01-07 14:54:34.134558.134558 lmp.py:767]   Expert 24 |    104 | CPU
DEBUG 01-07 14:54:34.134817.134817 lmp.py:767]   Expert 33 |    108 | CPU
DEBUG 01-07 14:54:34.134029.134029 lmp.py:767]   Expert 15 |    112 | CPU
DEBUG 01-07 14:54:34.134765.134765 lmp.py:767]   Expert 50 |    112 | CPU
DEBUG 01-07 14:54:34.134739.134739 lmp.py:767]   Expert  2 |    113 | CPU
DEBUG 01-07 14:54:34.134428.134428 lmp.py:767]   Expert 39 |    113 | CPU
DEBUG 01-07 14:54:34.134402.134402 lmp.py:767]   Expert 60 |    115 | CPU
DEBUG 01-07 14:54:34.134138.134138 lmp.py:767]   Expert 36 |    121 | CPU
DEBUG 01-07 14:54:34.134873.134873 lmp.py:767]   Expert 25 |    122 | CPU
DEBUG 01-07 14:54:34.134609.134609 lmp.py:767]   Expert  6 |    125 | CPU
DEBUG 01-07 14:54:34.134775.134775 lmp.py:767]   Expert 61 |    129 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.134941.134941 lmp.py:767]   Expert 59 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.134869.134869 lmp.py:767]   Expert  3 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.134750.134750 lmp.py:767]   Expert 27 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.134916.134916 lmp.py:767]   Expert 58 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.134083.134083 lmp.py:767]   Expert 31 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135772.135772 lmp.py:767]   Expert  8 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135223.135223 lmp.py:767]   Expert 38 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135151.135151 lmp.py:767]   Expert 30 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135078.135078 lmp.py:767]   Expert 10 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135244.135244 lmp.py:767]   Expert 40 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135649.135649 lmp.py:767]   Expert 14 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135815.135815 lmp.py:767]   Expert 41 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135504.135504 lmp.py:767]   Expert 57 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135432.135432 lmp.py:767]   Expert 37 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135883.135883 lmp.py:767]   Expert 54 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135572.135572 lmp.py:767]   Expert 32 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135500.135500 lmp.py:767]   Expert 46 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135666.135666 lmp.py:767]   Expert 19 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135071.135071 lmp.py:767]   Expert 42 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135760.135760 lmp.py:767]   Expert 11 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135449.135449 lmp.py:767]   Expert 34 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135662.135662 lmp.py:767]   Expert 18 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135874.135874 lmp.py:767]   Expert 22 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135564.135564 lmp.py:767]   Expert 26 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135491.135491 lmp.py:767]   Expert  0 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135942.135942 lmp.py:767]   Expert 56 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135108.135108 lmp.py:767]   Expert  1 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135559.135559 lmp.py:767]   Expert 44 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135248.135248 lmp.py:767]   Expert 51 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135699.135699 lmp.py:767]   Expert 20 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135912.135912 lmp.py:767]   Expert 29 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135601.135601 lmp.py:767]   Expert 48 |    236 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135290.135290 lmp.py:767]   Expert 45 |    239 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135741.135741 lmp.py:767]   Expert 21 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135192.135192 lmp.py:767]   Expert 16 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135358.135358 lmp.py:767]   Expert 35 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135432.135432 lmp.py:767]   Expert 55 |    252 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135552.135552 lmp.py:767]   Expert  5 |    294 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135433.135433 lmp.py:767]   Expert 23 |    376 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135838.135838 lmp.py:767]   Expert 13 |    383 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135481.135481 lmp.py:767]   Expert 17 |    434 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135123.135123 lmp.py:767]   Expert  9 |    453 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135766.135766 lmp.py:767]   Expert 63 |    467 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.135125.135125 lmp.py:767]   Expert 62 |   1179 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.135814.135814 lmp.py:769] 
DEBUG 01-07 14:54:34.135814.135814 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.135219.135219 lmp.py:770]   CPU:   1695 tokens
DEBUG 01-07 14:54:34.135577.135577 lmp.py:774]   cuda:1:   5326 tokens (22 experts)
DEBUG 01-07 14:54:34.135458.135458 lmp.py:774]   cuda:2:   5267 tokens (23 experts)
DEBUG 01-07 14:54:34.135386.135386 lmp.py:775]   Total GPU:  10593 tokens
DEBUG 01-07 14:54:34.135075.135075 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.135075.135075 lmp.py:776] 
DEBUG 01-07 14:54:34.135440.135440 cuda_h.py:19] end experts_map_get cost 0.001722574234008789 seconds
DEBUG 01-07 14:54:34.135514.135514 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.135336.135336 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.135241.135241 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.136143.136143 cuda_h.py:19] end allocate_cuda_memory cost 0.00021266937255859375 seconds
DEBUG 01-07 14:54:34.136384.136384 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.136855.136855 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.136333.136333 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.136267.136267 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea77a7ec-066d-4692-bf83-e36966e82818
DEBUG 01-07 14:54:34.136464.136464 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.136649.136649 client.py:127] Model loaded
DEBUG 01-07 14:54:34.136300.136300 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.137206.137206 cuda_h.py:19] end restore2model cost 0.00031828880310058594 seconds
DEBUG 01-07 14:54:34.137545.137545 cuda_h.py:19] end sllm_worker_task cost 0.008922100067138672 seconds
INFO 01-07 14:54:34.137984.137984 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea77a7ec-066d-4692-bf83-e36966e82818
DEBUG 01-07 14:54:34.137920.137920 cuda_h.py:19] end load_into_gpu_async cost 0.0009589195251464844 seconds
DEBUG 01-07 14:54:34.137861.137861 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.137187.137187 cuda_h.py:19] end restore_tensors2 cost 0.0002162456512451172 seconds
DEBUG 01-07 14:54:34.137096.137096 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016961097717285156 seconds
DEBUG 01-07 14:54:34.137806.137806 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.139661.139661 cuda_h.py:19] end restore2model cost 0.0017976760864257812 seconds
DEBUG 01-07 14:54:34.139564.139564 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.139031.139031 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.139887.139887 cuda_h.py:19] end allocate_cuda_memory cost 0.00021219253540039062 seconds
DEBUG 01-07 14:54:34.139869.139869 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.139956.139956 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.139858.139858 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.139792.139792 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c936601e-7a3d-4ade-9945-9f83f2f3187a
DEBUG 01-07 14:54:34.140578.140578 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.140359.140359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c936601e-7a3d-4ade-9945-9f83f2f3187a
DEBUG 01-07 14:54:34.140712.140712 cuda_h.py:19] end load_into_gpu_async cost 0.0010113716125488281 seconds
DEBUG 01-07 14:54:34.140746.140746 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.141389.141389 cuda_h.py:19] end restore_tensors2 cost 0.0002040863037109375 seconds
DEBUG 01-07 14:54:34.141536.141536 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017087459564208984 seconds
DEBUG 01-07 14:54:34.141577.141577 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.143149.143149 cuda_h.py:19] end restore2model cost 0.0018334388732910156 seconds
DEBUG 01-07 14:54:34.143502.143502 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0073430538177490234 seconds
DEBUG 01-07 14:54:34.143821.143821 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.143784.143784 lmp.py:816] 
DEBUG 01-07 14:54:34.143784.143784 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.143951.143951 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-07 14:54:34.143362.143362 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.152536.152536 mlpmodule.py:749] group tensors cost 0.009416818618774414 s
DEBUG 01-07 14:54:34.154460.154460 mlpmodule.py:787] pad cost 0.001071929931640625 s
DEBUG 01-07 14:54:34.154643.154643 mlpmodule.py:793] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-07 14:54:34.154122.154122 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 14:54:34.163703.163703 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.163007.163007 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.163918.163918 mlpmodule.py:818] group_w3 first element: 0.00457763671875
WARNING 01-07 14:54:34.163233.163233 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.181226.181226 mlpmodule.py:838] group einsum cost 0.02696537971496582 s
DEBUG 01-07 14:54:34.182841.182841 mlpmodule.py:846] cpy2cputensor cost 0.0003638267517089844 s
DEBUG 01-07 14:54:34.185051.185051 cuda_h.py:19] end wait_cetm_experts cost 0.041684865951538086 seconds
DEBUG 01-07 14:54:34.185034.185034 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.185390.185390 cuda_h.py:19] end gpu_sexperts cost 0.0004982948303222656 seconds
DEBUG 01-07 14:54:34.185525.185525 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.185520.185520 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-07 14:54:34.185654.185654 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.185079.185079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea77a7ec-066d-4692-bf83-e36966e82818
INFO 01-07 14:54:34.186414.186414 client.py:127] Model loaded
INFO 01-07 14:54:34.186754.186754 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c936601e-7a3d-4ade-9945-9f83f2f3187a
INFO 01-07 14:54:34.187887.187887 client.py:127] Model loaded
DEBUG 01-07 14:54:34.187386.187386 cuda_h.py:19] end wait_experts_multi_device cost 0.0014562606811523438 seconds
DEBUG 01-07 14:54:34.187142.187142 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.187534.187534 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.188275.188275 mlpmodule.py:533] gpu group tensors cost 0.0005054473876953125 s
DEBUG 01-07 14:54:34.189784.189784 mlpmodule.py:566] gpu pad cost 0.0012943744659423828 s
DEBUG 01-07 14:54:34.190540.190540 mlpmodule.py:584] gpu group einsum cost 0.0005545616149902344 s
DEBUG 01-07 14:54:34.192828.192828 mlpmodule.py:656] gpu experts func einsum cost 0.004567861557006836 s
DEBUG 01-07 14:54:34.192653.192653 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.193022.193022 mlpmodule.py:707]  experts func einsum cost 0.049854278564453125 s
DEBUG 01-07 14:54:34.193710.193710 mlpmodule.py:533] gpu group tensors cost 0.00043773651123046875 s
DEBUG 01-07 14:54:34.195228.195228 mlpmodule.py:566] gpu pad cost 0.0015399456024169922 s
DEBUG 01-07 14:54:34.196729.196729 mlpmodule.py:584] gpu group einsum cost 0.0008635520935058594 s
DEBUG 01-07 14:54:34.198093.198093 mlpmodule.py:656] gpu experts func einsum cost 0.004762411117553711 s
DEBUG 01-07 14:54:34.198878.198878 cuda_h.py:19] end gpu_experts_multi_device cost 0.010872125625610352 seconds
DEBUG 01-07 14:54:34.198940.198940 cuda_h.py:19] end layer_moe_generate_multi_device_17 cost 0.06508374214172363 seconds
DEBUG 01-07 14:54:34.198834.198834 lmp.py:194] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-07 14:54:34.198557.198557 lmp.py:153] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-07 14:54:34.198015.198015 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 14:54:34.198817.198817 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 14:54:34.198892.198892 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:34.198688.198688 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.841255187988281e-05 seconds
DEBUG 01-07 14:54:34.198523.198523 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.198868.198868 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.198951.198951 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.198244.198244 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.199970.199970 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.199865.199865 cuda_h.py:19] end allocate_cuda_memory cost 0.00020170211791992188 seconds
DEBUG 01-07 14:54:34.199920.199920 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.199730.199730 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.199599.199599 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.199394.199394 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4653f1fa-c4b8-45bf-91f0-47830aec0617
DEBUG 01-07 14:54:34.199549.199549 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.199955.199955 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.200003.200003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4653f1fa-c4b8-45bf-91f0-47830aec0617
DEBUG 01-07 14:54:34.200554.200554 cuda_h.py:19] end load_into_gpu_async cost 0.0010998249053955078 seconds
DEBUG 01-07 14:54:34.200304.200304 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.200711.200711 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-07 14:54:34.200606.200606 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016143321990966797 seconds
INFO 01-07 14:54:34.200528.200528 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4653f1fa-c4b8-45bf-91f0-47830aec0617
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.203436.203436 cuda_h.py:19] end self_attn cost 0.003630399703979492 seconds
DEBUG 01-07 14:54:34.203513.203513 cuda_h.py:19] end iln_self_attn_paln cost 0.005020618438720703 seconds
DEBUG 01-07 14:54:34.203435.203435 cuda_h.py:10] start layer_moe_generate_multi_device_18
DEBUG 01-07 14:54:34.203906.203906 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.204977.204977 cuda_h.py:19] end gate cost 0.0006856918334960938 seconds
DEBUG 01-07 14:54:34.204329.204329 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.205270.205270 lmp.py:744] 
DEBUG 01-07 14:54:34.205270.205270 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.205980.205980 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.205630.205630 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.205703.205703 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.205631.205631 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.205228.205228 lmp.py:749] 
DEBUG 01-07 14:54:34.205228.205228 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.205109.205109 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.205666.205666 lmp.py:767]   Expert 32 |     34 | CPU
DEBUG 01-07 14:54:34.205024.205024 lmp.py:767]   Expert 30 |     51 | CPU
DEBUG 01-07 14:54:34.205667.205667 lmp.py:767]   Expert  5 |     54 | CPU
DEBUG 01-07 14:54:34.205026.205026 lmp.py:767]   Expert 46 |     72 | CPU
DEBUG 01-07 14:54:34.205907.205907 lmp.py:767]   Expert 40 |     92 | CPU
DEBUG 01-07 14:54:34.205073.205073 lmp.py:767]   Expert  8 |     95 | CPU
DEBUG 01-07 14:54:34.205001.205001 lmp.py:767]   Expert 12 |    101 | CPU
DEBUG 01-07 14:54:34.205167.205167 lmp.py:767]   Expert 17 |    102 | CPU
DEBUG 01-07 14:54:34.205095.205095 lmp.py:767]   Expert 27 |    113 | CPU
DEBUG 01-07 14:54:34.205022.205022 lmp.py:767]   Expert  3 |    114 | CPU
DEBUG 01-07 14:54:34.205950.205950 lmp.py:767]   Expert 60 |    114 | CPU
DEBUG 01-07 14:54:34.205593.205593 lmp.py:767]   Expert 58 |    115 | CPU
DEBUG 01-07 14:54:34.205998.205998 lmp.py:767]   Expert 21 |    118 | CPU
DEBUG 01-07 14:54:34.205164.205164 lmp.py:767]   Expert 28 |    120 | CPU
DEBUG 01-07 14:54:34.205091.205091 lmp.py:767]   Expert 29 |    121 | CPU
DEBUG 01-07 14:54:34.205258.205258 lmp.py:767]   Expert 25 |    128 | CPU
DEBUG 01-07 14:54:34.205185.205185 lmp.py:767]   Expert 35 |    133 | CPU
DEBUG 01-07 14:54:34.205351.205351 lmp.py:767]   Expert 19 |    135 | CPU
DEBUG 01-07 14:54:34.205564.205564 lmp.py:767]   Expert 41 |    136 | CPU
DEBUG 01-07 14:54:34.205353.205353 lmp.py:767]   Expert  0 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205949.205949 lmp.py:767]   Expert  6 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205308.205308 lmp.py:767]   Expert 52 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205950.205950 lmp.py:767]   Expert 56 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205832.205832 lmp.py:767]   Expert 54 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205475.205475 lmp.py:767]   Expert 37 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205641.205641 lmp.py:767]   Expert 53 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205046.205046 lmp.py:767]   Expert 48 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205165.205165 lmp.py:767]   Expert 63 |    157 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205047.205047 lmp.py:767]   Expert 36 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205451.205451 lmp.py:767]   Expert 59 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205856.205856 lmp.py:767]   Expert  9 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205022.205022 lmp.py:767]   Expert  1 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205665.205665 lmp.py:767]   Expert 39 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205831.205831 lmp.py:767]   Expert 20 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205236.205236 lmp.py:767]   Expert 43 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205640.205640 lmp.py:767]   Expert 11 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205760.205760 lmp.py:767]   Expert 61 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205165.205165 lmp.py:767]   Expert 42 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205808.205808 lmp.py:767]   Expert  7 |    207 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205974.205974 lmp.py:767]   Expert 34 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205140.205140 lmp.py:767]   Expert 55 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.205544.205544 lmp.py:767]   Expert 47 |    211 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205711.205711 lmp.py:767]   Expert 13 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.205638.205638 lmp.py:767]   Expert 16 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206566.206566 lmp.py:767]   Expert 57 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206447.206447 lmp.py:767]   Expert 18 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206567.206567 lmp.py:767]   Expert 15 |    238 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206972.206972 lmp.py:767]   Expert  4 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206899.206899 lmp.py:767]   Expert 22 |    244 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206827.206827 lmp.py:767]   Expert 33 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206993.206993 lmp.py:767]   Expert 45 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206636.206636 lmp.py:767]   Expert 31 |    248 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206802.206802 lmp.py:767]   Expert 50 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206207.206207 lmp.py:767]   Expert 51 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206327.206327 lmp.py:767]   Expert 49 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206208.206208 lmp.py:767]   Expert 26 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206613.206613 lmp.py:767]   Expert 38 |    277 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206017.206017 lmp.py:767]   Expert 10 |    288 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206422.206422 lmp.py:767]   Expert 44 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206588.206588 lmp.py:767]   Expert  2 |    300 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206754.206754 lmp.py:767]   Expert 24 |    307 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206159.206159 lmp.py:767]   Expert 14 |    314 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206563.206563 lmp.py:767]   Expert 23 |    408 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.206729.206729 lmp.py:767]   Expert 62 |    669 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.206180.206180 lmp.py:769] 
DEBUG 01-07 14:54:34.206180.206180 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.206300.206300 lmp.py:770]   CPU:   1948 tokens
DEBUG 01-07 14:54:34.206897.206897 lmp.py:774]   cuda:1:   5169 tokens (22 experts)
DEBUG 01-07 14:54:34.206540.206540 lmp.py:774]   cuda:2:   5171 tokens (23 experts)
DEBUG 01-07 14:54:34.206706.206706 lmp.py:775]   Total GPU:  10340 tokens
DEBUG 01-07 14:54:34.206395.206395 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.206395.206395 lmp.py:776] 
DEBUG 01-07 14:54:34.206806.206806 cuda_h.py:19] end experts_map_get cost 0.0017633438110351562 seconds
DEBUG 01-07 14:54:34.206165.206165 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.206226.206226 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.206031.206031 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.207826.207826 cuda_h.py:19] end allocate_cuda_memory cost 0.0003795623779296875 seconds
DEBUG 01-07 14:54:34.207013.207013 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.207723.207723 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.207055.207055 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.207467.207467 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c56dfca-38cc-4684-8ac7-65df31c266ce
DEBUG 01-07 14:54:34.207935.207935 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.207663.207663 client.py:127] Model loaded
DEBUG 01-07 14:54:34.207016.207016 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.207729.207729 cuda_h.py:19] end restore2model cost 0.00031948089599609375 seconds
DEBUG 01-07 14:54:34.207161.207161 cuda_h.py:19] end sllm_worker_task cost 0.009008407592773438 seconds
INFO 01-07 14:54:34.208378.208378 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c56dfca-38cc-4684-8ac7-65df31c266ce
DEBUG 01-07 14:54:34.208076.208076 cuda_h.py:19] end load_into_gpu_async cost 0.0010294914245605469 seconds
DEBUG 01-07 14:54:34.208348.208348 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.208840.208840 cuda_h.py:19] end restore_tensors2 cost 0.000232696533203125 seconds
DEBUG 01-07 14:54:34.208656.208656 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00194549560546875 seconds
DEBUG 01-07 14:54:34.208796.208796 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.210659.210659 cuda_h.py:19] end restore2model cost 0.001802206039428711 seconds
DEBUG 01-07 14:54:34.210277.210277 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.210459.210459 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.210785.210785 cuda_h.py:19] end allocate_cuda_memory cost 0.00020766258239746094 seconds
DEBUG 01-07 14:54:34.210290.210290 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.210139.210139 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.210564.210564 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.210498.210498 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d1beb65-46e2-4748-b4b7-4b6730f480b2
DEBUG 01-07 14:54:34.211714.211714 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.211806.211806 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d1beb65-46e2-4748-b4b7-4b6730f480b2
DEBUG 01-07 14:54:34.212688.212688 cuda_h.py:19] end load_into_gpu_async cost 0.0011749267578125 seconds
DEBUG 01-07 14:54:34.212199.212199 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.212273.212273 cuda_h.py:19] end restore_tensors2 cost 0.0002048015594482422 seconds
DEBUG 01-07 14:54:34.212420.212420 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018689632415771484 seconds
DEBUG 01-07 14:54:34.212792.212792 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.214789.214789 cuda_h.py:19] end restore2model cost 0.0018644332885742188 seconds
DEBUG 01-07 14:54:34.214003.214003 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007793903350830078 seconds
DEBUG 01-07 14:54:34.214844.214844 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.214092.214092 lmp.py:816] 
DEBUG 01-07 14:54:34.214092.214092 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.214167.214167 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 14:54:34.214340.214340 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.219968.219968 mlpmodule.py:749] group tensors cost 0.005396842956542969 s
DEBUG 01-07 14:54:34.221121.221121 mlpmodule.py:787] pad cost 0.0011036396026611328 s
DEBUG 01-07 14:54:34.221403.221403 mlpmodule.py:793] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-07 14:54:34.221505.221505 mlpmodule.py:798] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-07 14:54:34.231401.231401 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.232275.232275 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.232841.232841 mlpmodule.py:818] group_w3 first element: 0.0264892578125
WARNING 01-07 14:54:34.232872.232872 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.249110.249110 mlpmodule.py:838] group einsum cost 0.027895212173461914 s
DEBUG 01-07 14:54:34.250262.250262 mlpmodule.py:846] cpy2cputensor cost 0.0003886222839355469 s
DEBUG 01-07 14:54:34.253092.253092 cuda_h.py:19] end wait_cetm_experts cost 0.03864336013793945 seconds
DEBUG 01-07 14:54:34.253777.253777 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.253894.253894 cuda_h.py:19] end gpu_sexperts cost 0.0004999637603759766 seconds
DEBUG 01-07 14:54:34.253738.253738 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.253256.253256 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 14:54:34.253820.253820 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.253245.253245 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c56dfca-38cc-4684-8ac7-65df31c266ce
INFO 01-07 14:54:34.254601.254601 client.py:127] Model loaded
INFO 01-07 14:54:34.254511.254511 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d1beb65-46e2-4748-b4b7-4b6730f480b2
INFO 01-07 14:54:34.255340.255340 client.py:127] Model loaded
DEBUG 01-07 14:54:34.255745.255745 cuda_h.py:19] end wait_experts_multi_device cost 0.0014917850494384766 seconds
DEBUG 01-07 14:54:34.255455.255455 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.255516.255516 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.256643.256643 mlpmodule.py:533] gpu group tensors cost 0.0005404949188232422 s
DEBUG 01-07 14:54:34.258442.258442 mlpmodule.py:566] gpu pad cost 0.001262664794921875 s
DEBUG 01-07 14:54:34.258947.258947 mlpmodule.py:584] gpu group einsum cost 0.0005507469177246094 s
DEBUG 01-07 14:54:34.260036.260036 mlpmodule.py:656] gpu experts func einsum cost 0.004554033279418945 s
DEBUG 01-07 14:54:34.261350.261350 mlpmodule.py:707]  experts func einsum cost 0.04649496078491211 s
DEBUG 01-07 14:54:34.261222.261222 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.261988.261988 mlpmodule.py:533] gpu group tensors cost 0.000431060791015625 s
DEBUG 01-07 14:54:34.263607.263607 mlpmodule.py:566] gpu pad cost 0.0012073516845703125 s
DEBUG 01-07 14:54:34.263862.263862 mlpmodule.py:584] gpu group einsum cost 0.0004401206970214844 s
DEBUG 01-07 14:54:34.265096.265096 mlpmodule.py:656] gpu experts func einsum cost 0.004233121871948242 s
DEBUG 01-07 14:54:34.265595.265595 cuda_h.py:19] end gpu_experts_multi_device cost 0.010292530059814453 seconds
DEBUG 01-07 14:54:34.265942.265942 cuda_h.py:19] end layer_moe_generate_multi_device_18 cost 0.06200218200683594 seconds
DEBUG 01-07 14:54:34.266658.266658 lmp.py:194] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-07 14:54:34.266474.266474 lmp.py:153] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-07 14:54:34.266978.266978 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 14:54:34.266496.266496 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 14:54:34.266762.266762 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.0517578125e-05 seconds
DEBUG 01-07 14:54:34.266465.266465 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.103515625e-05 seconds
DEBUG 01-07 14:54:34.266016.266016 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.266236.266236 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.266655.266655 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.266128.266128 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.266573.266573 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.272402.272402 cuda_h.py:19] end allocate_cuda_memory cost 0.006123542785644531 seconds
DEBUG 01-07 14:54:34.272895.272895 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.272989.272989 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.272381.272381 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.272130.272130 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6caeb55d-a4dc-49de-b27e-b72e20315c5c
DEBUG 01-07 14:54:34.272000.272000 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.273829.273829 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.273442.273442 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6caeb55d-a4dc-49de-b27e-b72e20315c5c
DEBUG 01-07 14:54:34.273232.273232 cuda_h.py:19] end load_into_gpu_async cost 0.0009510517120361328 seconds
DEBUG 01-07 14:54:34.273790.273790 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.273150.273150 cuda_h.py:19] end restore_tensors2 cost 6.508827209472656e-05 seconds
DEBUG 01-07 14:54:34.273237.273237 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0073909759521484375 seconds
INFO 01-07 14:54:34.273127.273127 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6caeb55d-a4dc-49de-b27e-b72e20315c5c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.276075.276075 cuda_h.py:19] end self_attn cost 0.003734111785888672 seconds
DEBUG 01-07 14:54:34.277642.277642 cuda_h.py:19] end iln_self_attn_paln cost 0.010965585708618164 seconds
DEBUG 01-07 14:54:34.277326.277326 cuda_h.py:10] start layer_moe_generate_multi_device_19
DEBUG 01-07 14:54:34.277274.277274 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.278535.278535 cuda_h.py:19] end gate cost 0.0006506443023681641 seconds
DEBUG 01-07 14:54:34.278173.278173 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.278975.278975 lmp.py:744] 
DEBUG 01-07 14:54:34.278975.278975 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.278353.278353 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.278718.278718 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.278984.278984 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.278865.278865 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.278793.278793 lmp.py:749] 
DEBUG 01-07 14:54:34.278793.278793 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.278436.278436 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.278278.278278 lmp.py:767]   Expert 44 |     38 | CPU
DEBUG 01-07 14:54:34.278636.278636 lmp.py:767]   Expert  1 |     46 | CPU
DEBUG 01-07 14:54:34.278041.278041 lmp.py:767]   Expert 60 |     58 | CPU
DEBUG 01-07 14:54:34.278637.278637 lmp.py:767]   Expert 28 |     71 | CPU
DEBUG 01-07 14:54:34.278042.278042 lmp.py:767]   Expert 48 |     75 | CPU
DEBUG 01-07 14:54:34.278208.278208 lmp.py:767]   Expert 27 |     89 | CPU
DEBUG 01-07 14:54:34.278374.278374 lmp.py:767]   Expert  0 |    101 | CPU
DEBUG 01-07 14:54:34.278540.278540 lmp.py:767]   Expert 62 |    107 | CPU
DEBUG 01-07 14:54:34.278706.278706 lmp.py:767]   Expert 42 |    111 | CPU
DEBUG 01-07 14:54:34.278634.278634 lmp.py:767]   Expert 22 |    114 | CPU
DEBUG 01-07 14:54:34.278323.278323 lmp.py:767]   Expert 30 |    116 | CPU
DEBUG 01-07 14:54:34.278251.278251 lmp.py:767]   Expert 58 |    119 | CPU
DEBUG 01-07 14:54:34.278656.278656 lmp.py:767]   Expert 59 |    119 | CPU
DEBUG 01-07 14:54:34.278060.278060 lmp.py:767]   Expert  8 |    129 | CPU
DEBUG 01-07 14:54:34.278988.278988 lmp.py:767]   Expert 12 |    130 | CPU
DEBUG 01-07 14:54:34.278677.278677 lmp.py:767]   Expert 16 |    131 | CPU
DEBUG 01-07 14:54:34.278366.278366 lmp.py:767]   Expert 50 |    134 | CPU
DEBUG 01-07 14:54:34.278294.278294 lmp.py:767]   Expert 56 |    141 | CPU
DEBUG 01-07 14:54:34.278222.278222 lmp.py:767]   Expert  5 |    144 | CPU
DEBUG 01-07 14:54:34.279103.279103 lmp.py:767]   Expert 57 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279700.279700 lmp.py:767]   Expert 55 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279058.279058 lmp.py:767]   Expert 15 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279370.279370 lmp.py:767]   Expert 32 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279967.279967 lmp.py:767]   Expert 26 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279325.279325 lmp.py:767]   Expert 47 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279445.279445 lmp.py:767]   Expert 34 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279326.279326 lmp.py:767]   Expert  2 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279208.279208 lmp.py:767]   Expert 24 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279327.279327 lmp.py:767]   Expert 52 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279970.279970 lmp.py:767]   Expert 40 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279375.279375 lmp.py:767]   Expert 13 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279541.279541 lmp.py:767]   Expert 41 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279946.279946 lmp.py:767]   Expert  6 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279589.279589 lmp.py:767]   Expert 18 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279993.279993 lmp.py:767]   Expert  3 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279159.279159 lmp.py:767]   Expert 54 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279564.279564 lmp.py:767]   Expert 19 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279730.279730 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279896.279896 lmp.py:767]   Expert 37 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279539.279539 lmp.py:767]   Expert 46 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279944.279944 lmp.py:767]   Expert 25 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279348.279348 lmp.py:767]   Expert 51 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279753.279753 lmp.py:767]   Expert 17 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279919.279919 lmp.py:767]   Expert 43 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279562.279562 lmp.py:767]   Expert 11 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279966.279966 lmp.py:767]   Expert 31 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279848.279848 lmp.py:767]   Expert 35 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279968.279968 lmp.py:767]   Expert 23 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279611.279611 lmp.py:767]   Expert 49 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279015.279015 lmp.py:767]   Expert 39 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279658.279658 lmp.py:767]   Expert 53 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279063.279063 lmp.py:767]   Expert 10 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279467.279467 lmp.py:767]   Expert 33 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279633.279633 lmp.py:767]   Expert 36 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279038.279038 lmp.py:767]   Expert 38 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279919.279919 lmp.py:767]   Expert  4 |    304 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279039.279039 lmp.py:767]   Expert 21 |    332 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279159.279159 lmp.py:767]   Expert 14 |    341 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279087.279087 lmp.py:767]   Expert 63 |    365 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279968.279968 lmp.py:767]   Expert 45 |    374 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279373.279373 lmp.py:767]   Expert  9 |    389 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279777.279777 lmp.py:767]   Expert 61 |    392 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279420.279420 lmp.py:767]   Expert 29 |    489 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.279017.279017 lmp.py:767]   Expert  7 |    514 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.279944.279944 lmp.py:769] 
DEBUG 01-07 14:54:34.279944.279944 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.279587.279587 lmp.py:770]   CPU:   1973 tokens
DEBUG 01-07 14:54:34.279469.279469 lmp.py:774]   cuda:1:   5230 tokens (23 experts)
DEBUG 01-07 14:54:34.279873.279873 lmp.py:774]   cuda:2:   5085 tokens (22 experts)
DEBUG 01-07 14:54:34.279563.279563 lmp.py:775]   Total GPU:  10315 tokens
DEBUG 01-07 14:54:34.279775.279775 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.279775.279775 lmp.py:776] 
DEBUG 01-07 14:54:34.279147.279147 cuda_h.py:19] end experts_map_get cost 0.0017726421356201172 seconds
DEBUG 01-07 14:54:34.279505.279505 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.279189.279189 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.280908.280908 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.280234.280234 cuda_h.py:19] end allocate_cuda_memory cost 0.0002086162567138672 seconds
DEBUG 01-07 14:54:34.280276.280276 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.280985.280985 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.280371.280371 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.280497.280497 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a9a2f4c-a7f2-47b6-9c9a-f4e3b3bd385f
DEBUG 01-07 14:54:34.280833.280833 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.280540.280540 client.py:127] Model loaded
DEBUG 01-07 14:54:34.280992.280992 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.281177.281177 cuda_h.py:19] end restore2model cost 0.0003483295440673828 seconds
DEBUG 01-07 14:54:34.281768.281768 cuda_h.py:19] end sllm_worker_task cost 0.014767169952392578 seconds
INFO 01-07 14:54:34.281474.281474 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a9a2f4c-a7f2-47b6-9c9a-f4e3b3bd385f
DEBUG 01-07 14:54:34.281980.281980 cuda_h.py:19] end load_into_gpu_async cost 0.0010120868682861328 seconds
DEBUG 01-07 14:54:34.281014.281014 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.281029.281029 cuda_h.py:19] end restore_tensors2 cost 0.0002338886260986328 seconds
DEBUG 01-07 14:54:34.281745.281745 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001756906509399414 seconds
DEBUG 01-07 14:54:34.281839.281839 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.283836.283836 cuda_h.py:19] end restore2model cost 0.0018656253814697266 seconds
DEBUG 01-07 14:54:34.283885.283885 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.283782.283782 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.284413.284413 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-07 14:54:34.284588.284588 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.284151.284151 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.284100.284100 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.284796.284796 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7a272228-bea2-4c86-bc9f-00001e148743
DEBUG 01-07 14:54:34.284720.284720 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.285519.285519 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7a272228-bea2-4c86-bc9f-00001e148743
DEBUG 01-07 14:54:34.285964.285964 cuda_h.py:19] end load_into_gpu_async cost 0.0011241436004638672 seconds
DEBUG 01-07 14:54:34.285283.285283 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.285098.285098 cuda_h.py:19] end restore_tensors2 cost 0.00019049644470214844 seconds
DEBUG 01-07 14:54:34.285768.285768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018165111541748047 seconds
DEBUG 01-07 14:54:34.285901.285901 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.287385.287385 cuda_h.py:19] end restore2model cost 0.0017647743225097656 seconds
DEBUG 01-07 14:54:34.287115.287115 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007520914077758789 seconds
DEBUG 01-07 14:54:34.287719.287719 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.287728.287728 lmp.py:816] 
DEBUG 01-07 14:54:34.287728.287728 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.287849.287849 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 14:54:34.287737.287737 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.293733.293733 mlpmodule.py:749] group tensors cost 0.005487680435180664 s
DEBUG 01-07 14:54:34.295994.295994 mlpmodule.py:787] pad cost 0.0016984939575195312 s
DEBUG 01-07 14:54:34.295336.295336 mlpmodule.py:793] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-07 14:54:34.295433.295433 mlpmodule.py:798] move to cpu cost 4.57763671875e-05 s
DEBUG 01-07 14:54:34.306388.306388 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.306533.306533 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.306815.306815 mlpmodule.py:818] group_w3 first element: -0.0034942626953125
WARNING 01-07 14:54:34.306938.306938 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.325303.325303 mlpmodule.py:838] group einsum cost 0.029635190963745117 s
DEBUG 01-07 14:54:34.326073.326073 mlpmodule.py:846] cpy2cputensor cost 0.0004146099090576172 s
DEBUG 01-07 14:54:34.329780.329780 cuda_h.py:19] end wait_cetm_experts cost 0.04159188270568848 seconds
DEBUG 01-07 14:54:34.329959.329959 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.330082.330082 cuda_h.py:19] end gpu_sexperts cost 0.0006377696990966797 seconds
DEBUG 01-07 14:54:34.330938.330938 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.330987.330987 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-07 14:54:34.330644.330644 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.330214.330214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a9a2f4c-a7f2-47b6-9c9a-f4e3b3bd385f
INFO 01-07 14:54:34.331511.331511 client.py:127] Model loaded
INFO 01-07 14:54:34.331255.331255 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7a272228-bea2-4c86-bc9f-00001e148743
INFO 01-07 14:54:34.331666.331666 client.py:127] Model loaded
DEBUG 01-07 14:54:34.331019.331019 cuda_h.py:19] end wait_experts_multi_device cost 0.0014734268188476562 seconds
DEBUG 01-07 14:54:34.331251.331251 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.331412.331412 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:34.333644.333644 mlpmodule.py:533] gpu group tensors cost 0.0005414485931396484 s
DEBUG 01-07 14:54:34.334499.334499 mlpmodule.py:566] gpu pad cost 0.0013337135314941406 s
DEBUG 01-07 14:54:34.335389.335389 mlpmodule.py:584] gpu group einsum cost 0.0005819797515869141 s
DEBUG 01-07 14:54:34.337629.337629 mlpmodule.py:707]  experts func einsum cost 0.049672603607177734 s
DEBUG 01-07 14:54:34.337844.337844 mlpmodule.py:656] gpu experts func einsum cost 0.00472569465637207 s
DEBUG 01-07 14:54:34.337274.337274 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:34.338122.338122 mlpmodule.py:533] gpu group tensors cost 0.0005009174346923828 s
DEBUG 01-07 14:54:34.340520.340520 mlpmodule.py:566] gpu pad cost 0.0013096332550048828 s
DEBUG 01-07 14:54:34.340950.340950 mlpmodule.py:584] gpu group einsum cost 0.0005202293395996094 s
DEBUG 01-07 14:54:34.342673.342673 mlpmodule.py:656] gpu experts func einsum cost 0.00448918342590332 s
DEBUG 01-07 14:54:34.342445.342445 cuda_h.py:19] end gpu_experts_multi_device cost 0.010893106460571289 seconds
DEBUG 01-07 14:54:34.342402.342402 cuda_h.py:19] end layer_moe_generate_multi_device_19 cost 0.06554603576660156 seconds
DEBUG 01-07 14:54:34.343636.343636 lmp.py:194] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-07 14:54:34.343067.343067 lmp.py:153] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-07 14:54:34.343763.343763 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 14:54:34.343434.343434 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 14:54:34.343369.343369 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.0517578125e-05 seconds
DEBUG 01-07 14:54:34.343118.343118 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.0558319091796875e-05 seconds
DEBUG 01-07 14:54:34.343715.343715 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.343512.343512 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.343031.343031 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.343987.343987 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.343161.343161 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.344877.344877 cuda_h.py:19] end allocate_cuda_memory cost 0.00038743019104003906 seconds
DEBUG 01-07 14:54:34.344522.344522 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.344762.344762 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.344353.344353 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.344294.344294 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bcbc7315-5f32-407b-9ebb-9d2aea483079
DEBUG 01-07 14:54:34.344171.344171 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.344427.344427 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.345791.345791 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bcbc7315-5f32-407b-9ebb-9d2aea483079
DEBUG 01-07 14:54:34.345581.345581 cuda_h.py:19] end load_into_gpu_async cost 0.000919342041015625 seconds
DEBUG 01-07 14:54:34.345615.345615 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.345082.345082 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-07 14:54:34.345599.345599 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016486644744873047 seconds
INFO 01-07 14:54:34.345382.345382 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bcbc7315-5f32-407b-9ebb-9d2aea483079
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.348804.348804 cuda_h.py:19] end self_attn cost 0.003863811492919922 seconds
DEBUG 01-07 14:54:34.348715.348715 cuda_h.py:19] end iln_self_attn_paln cost 0.00551915168762207 seconds
DEBUG 01-07 14:54:34.348114.348114 cuda_h.py:10] start layer_moe_generate_multi_device_20
DEBUG 01-07 14:54:34.348062.348062 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.349133.349133 cuda_h.py:19] end gate cost 0.0006847381591796875 seconds
DEBUG 01-07 14:54:34.349062.349062 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.350241.350241 lmp.py:744] 
DEBUG 01-07 14:54:34.350241.350241 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.350951.350951 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.350839.350839 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.350389.350389 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.350556.350556 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.350053.350053 lmp.py:749] 
DEBUG 01-07 14:54:34.350053.350053 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.350980.350980 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.350107.350107 lmp.py:767]   Expert 54 |     25 | CPU
DEBUG 01-07 14:54:34.350796.350796 lmp.py:767]   Expert  3 |     35 | CPU
DEBUG 01-07 14:54:34.350724.350724 lmp.py:767]   Expert  8 |     42 | CPU
DEBUG 01-07 14:54:34.350413.350413 lmp.py:767]   Expert 28 |     45 | CPU
DEBUG 01-07 14:54:34.350387.350387 lmp.py:767]   Expert 43 |     55 | CPU
DEBUG 01-07 14:54:34.350885.350885 lmp.py:767]   Expert 63 |     55 | CPU
DEBUG 01-07 14:54:34.350620.350620 lmp.py:767]   Expert 36 |     74 | CPU
DEBUG 01-07 14:54:34.350879.350879 lmp.py:767]   Expert 38 |     78 | CPU
DEBUG 01-07 14:54:34.350615.350615 lmp.py:767]   Expert  6 |     81 | CPU
DEBUG 01-07 14:54:34.350873.350873 lmp.py:767]   Expert 39 |     92 | CPU
DEBUG 01-07 14:54:34.350371.350371 lmp.py:767]   Expert 57 |     98 | CPU
DEBUG 01-07 14:54:34.350106.350106 lmp.py:767]   Expert 41 |    105 | CPU
DEBUG 01-07 14:54:34.350319.350319 lmp.py:767]   Expert 52 |    106 | CPU
DEBUG 01-07 14:54:34.350816.350816 lmp.py:767]   Expert 12 |    107 | CPU
DEBUG 01-07 14:54:34.350552.350552 lmp.py:767]   Expert 19 |    119 | CPU
DEBUG 01-07 14:54:34.350049.350049 lmp.py:767]   Expert 47 |    125 | CPU
DEBUG 01-07 14:54:34.350023.350023 lmp.py:767]   Expert 13 |    135 | CPU
DEBUG 01-07 14:54:34.350520.350520 lmp.py:767]   Expert 22 |    140 | CPU
DEBUG 01-07 14:54:34.350017.350017 lmp.py:767]   Expert 46 |    150 | CPU
DEBUG 01-07 14:54:34.350707.350707 lmp.py:767]   Expert 50 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350634.350634 lmp.py:767]   Expert 40 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350277.350277 lmp.py:767]   Expert 24 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350967.350967 lmp.py:767]   Expert 23 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350894.350894 lmp.py:767]   Expert 20 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350345.350345 lmp.py:767]   Expert 55 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350034.350034 lmp.py:767]   Expert  2 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350439.350439 lmp.py:767]   Expert 61 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350844.350844 lmp.py:767]   Expert 37 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350294.350294 lmp.py:767]   Expert 53 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350745.350745 lmp.py:767]   Expert 21 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350196.350196 lmp.py:767]   Expert 49 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350316.350316 lmp.py:767]   Expert 42 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350959.350959 lmp.py:767]   Expert 18 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350364.350364 lmp.py:767]   Expert 33 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350007.350007 lmp.py:767]   Expert  0 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350888.350888 lmp.py:767]   Expert 32 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350246.350246 lmp.py:767]   Expert 16 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350128.350128 lmp.py:767]   Expert  5 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350532.350532 lmp.py:767]   Expert 30 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.350937.350937 lmp.py:767]   Expert  7 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.350341.350341 lmp.py:767]   Expert 34 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351746.351746 lmp.py:767]   Expert 31 |    207 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351912.351912 lmp.py:767]   Expert 14 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351078.351078 lmp.py:767]   Expert 60 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351721.351721 lmp.py:767]   Expert 59 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351364.351364 lmp.py:767]   Expert 62 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351484.351484 lmp.py:767]   Expert  9 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351127.351127 lmp.py:767]   Expert 29 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351531.351531 lmp.py:767]   Expert 10 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351174.351174 lmp.py:767]   Expert 17 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351579.351579 lmp.py:767]   Expert 58 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351745.351745 lmp.py:767]   Expert  4 |    235 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351911.351911 lmp.py:767]   Expert 15 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351316.351316 lmp.py:767]   Expert 26 |    244 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351720.351720 lmp.py:767]   Expert 11 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351363.351363 lmp.py:767]   Expert 51 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351006.351006 lmp.py:767]   Expert 44 |    269 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351172.351172 lmp.py:767]   Expert 56 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351339.351339 lmp.py:767]   Expert 27 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351505.351505 lmp.py:767]   Expert  1 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351432.351432 lmp.py:767]   Expert 45 |    372 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351598.351598 lmp.py:767]   Expert 25 |    456 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351765.351765 lmp.py:767]   Expert 35 |    519 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.351408.351408 lmp.py:767]   Expert 48 |    645 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.351620.351620 lmp.py:769] 
DEBUG 01-07 14:54:34.351620.351620 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.351786.351786 lmp.py:770]   CPU:   1667 tokens
DEBUG 01-07 14:54:34.351429.351429 lmp.py:774]   cuda:1:   5386 tokens (23 experts)
DEBUG 01-07 14:54:34.351357.351357 lmp.py:774]   cuda:2:   5235 tokens (22 experts)
DEBUG 01-07 14:54:34.351808.351808 lmp.py:775]   Total GPU:  10621 tokens
DEBUG 01-07 14:54:34.351020.351020 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.351020.351020 lmp.py:776] 
DEBUG 01-07 14:54:34.351955.351955 cuda_h.py:19] end experts_map_get cost 0.001718282699584961 seconds
DEBUG 01-07 14:54:34.351790.351790 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.351805.351805 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.351444.351444 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.351002.351002 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
DEBUG 01-07 14:54:34.352335.352335 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.352522.352522 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.352907.352907 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.352511.352511 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1c06775-5578-4e67-b728-f4a8d85e7778
DEBUG 01-07 14:54:34.352496.352496 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.352509.352509 client.py:127] Model loaded
DEBUG 01-07 14:54:34.352160.352160 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.352203.352203 cuda_h.py:19] end restore2model cost 0.0004470348358154297 seconds
DEBUG 01-07 14:54:34.353556.353556 cuda_h.py:19] end sllm_worker_task cost 0.009484529495239258 seconds
INFO 01-07 14:54:34.353578.353578 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1c06775-5578-4e67-b728-f4a8d85e7778
DEBUG 01-07 14:54:34.353514.353514 cuda_h.py:19] end load_into_gpu_async cost 0.0011501312255859375 seconds
DEBUG 01-07 14:54:34.353787.353787 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.353783.353783 cuda_h.py:19] end restore_tensors2 cost 0.00025391578674316406 seconds
DEBUG 01-07 14:54:34.353075.353075 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019333362579345703 seconds
DEBUG 01-07 14:54:34.353408.353408 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.355851.355851 cuda_h.py:19] end restore2model cost 0.0019485950469970703 seconds
DEBUG 01-07 14:54:34.355139.355139 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.355943.355943 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.355190.355190 cuda_h.py:19] end allocate_cuda_memory cost 0.0002186298370361328 seconds
DEBUG 01-07 14:54:34.356980.356980 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.356306.356306 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.356730.356730 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.356142.356142 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c3bf00e4-2923-41d5-bf7f-97da0bb91f66
DEBUG 01-07 14:54:34.356709.356709 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.357151.357151 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c3bf00e4-2923-41d5-bf7f-97da0bb91f66
DEBUG 01-07 14:54:34.357934.357934 cuda_h.py:19] end load_into_gpu_async cost 0.0011630058288574219 seconds
DEBUG 01-07 14:54:34.357491.357491 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.357466.357466 cuda_h.py:19] end restore_tensors2 cost 0.00020313262939453125 seconds
DEBUG 01-07 14:54:34.357851.357851 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018668174743652344 seconds
DEBUG 01-07 14:54:34.357223.357223 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.359769.359769 cuda_h.py:19] end restore2model cost 0.001850128173828125 seconds
DEBUG 01-07 14:54:34.359645.359645 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007912397384643555 seconds
DEBUG 01-07 14:54:34.359533.359533 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.359112.359112 lmp.py:816] 
DEBUG 01-07 14:54:34.359112.359112 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.359948.359948 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 14:54:34.359883.359883 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.371509.371509 mlpmodule.py:749] group tensors cost 0.011462926864624023 s
DEBUG 01-07 14:54:34.373634.373634 mlpmodule.py:787] pad cost 0.0011546611785888672 s
DEBUG 01-07 14:54:34.373194.373194 mlpmodule.py:793] create cpu tensor cost 4.1484832763671875e-05 s
DEBUG 01-07 14:54:34.373805.373805 mlpmodule.py:798] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-07 14:54:34.383519.383519 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.383870.383870 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.383959.383959 mlpmodule.py:818] group_w3 first element: 0.0205078125
WARNING 01-07 14:54:34.384395.384395 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.399278.399278 mlpmodule.py:838] group einsum cost 0.025903701782226562 s
DEBUG 01-07 14:54:34.399065.399065 mlpmodule.py:846] cpy2cputensor cost 0.0003790855407714844 s
DEBUG 01-07 14:54:34.402394.402394 cuda_h.py:19] end wait_cetm_experts cost 0.04292654991149902 seconds
DEBUG 01-07 14:54:34.402463.402463 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.403117.403117 cuda_h.py:19] end gpu_sexperts cost 0.0005095005035400391 seconds
DEBUG 01-07 14:54:34.403106.403106 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.403479.403479 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 14:54:34.403143.403143 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.403760.403760 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1c06775-5578-4e67-b728-f4a8d85e7778
INFO 01-07 14:54:34.404227.404227 client.py:127] Model loaded
INFO 01-07 14:54:34.404322.404322 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c3bf00e4-2923-41d5-bf7f-97da0bb91f66
INFO 01-07 14:54:34.404986.404986 client.py:127] Model loaded
DEBUG 01-07 14:54:34.404949.404949 cuda_h.py:19] end wait_experts_multi_device cost 0.0015103816986083984 seconds
DEBUG 01-07 14:54:34.404851.404851 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.405866.405866 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:34.406177.406177 mlpmodule.py:533] gpu group tensors cost 0.00047326087951660156 s
DEBUG 01-07 14:54:34.407856.407856 mlpmodule.py:566] gpu pad cost 0.0012438297271728516 s
DEBUG 01-07 14:54:34.408222.408222 mlpmodule.py:584] gpu group einsum cost 0.0005483627319335938 s
DEBUG 01-07 14:54:34.410766.410766 mlpmodule.py:656] gpu experts func einsum cost 0.00442051887512207 s
DEBUG 01-07 14:54:34.410206.410206 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:34.411056.411056 mlpmodule.py:707]  experts func einsum cost 0.05135393142700195 s
DEBUG 01-07 14:54:34.411194.411194 mlpmodule.py:533] gpu group tensors cost 0.0005319118499755859 s
DEBUG 01-07 14:54:34.412120.412120 mlpmodule.py:566] gpu pad cost 0.0012788772583007812 s
DEBUG 01-07 14:54:34.413098.413098 mlpmodule.py:584] gpu group einsum cost 0.00044274330139160156 s
DEBUG 01-07 14:54:34.415861.415861 mlpmodule.py:656] gpu experts func einsum cost 0.004434108734130859 s
DEBUG 01-07 14:54:34.415036.415036 cuda_h.py:19] end gpu_experts_multi_device cost 0.010254383087158203 seconds
DEBUG 01-07 14:54:34.415675.415675 cuda_h.py:19] end layer_moe_generate_multi_device_20 cost 0.0663597583770752 seconds
DEBUG 01-07 14:54:34.415708.415708 lmp.py:194] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-07 14:54:34.415432.415432 lmp.py:153] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-07 14:54:34.415889.415889 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 14:54:34.415645.415645 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 14:54:34.415011.415011 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.266334533691406e-05 seconds
DEBUG 01-07 14:54:34.415920.415920 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.486343383789062e-05 seconds
DEBUG 01-07 14:54:34.415755.415755 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.415161.415161 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.415342.415342 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.415258.415258 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.416949.416949 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.416742.416742 cuda_h.py:19] end allocate_cuda_memory cost 0.00030422210693359375 seconds
DEBUG 01-07 14:54:34.416354.416354 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.416693.416693 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.416132.416132 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.416689.416689 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5f32742b-65b5-4017-9384-89c0910fbda2
DEBUG 01-07 14:54:34.416413.416413 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.416164.416164 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.417727.417727 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5f32742b-65b5-4017-9384-89c0910fbda2
DEBUG 01-07 14:54:34.417517.417517 cuda_h.py:19] end load_into_gpu_async cost 0.0008537769317626953 seconds
DEBUG 01-07 14:54:34.417597.417597 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.417487.417487 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-07 14:54:34.417813.417813 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014994144439697266 seconds
INFO 01-07 14:54:34.417901.417901 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5f32742b-65b5-4017-9384-89c0910fbda2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.420156.420156 cuda_h.py:19] end self_attn cost 0.0036530494689941406 seconds
DEBUG 01-07 14:54:34.420153.420153 cuda_h.py:19] end iln_self_attn_paln cost 0.005146026611328125 seconds
DEBUG 01-07 14:54:34.420314.420314 cuda_h.py:10] start layer_moe_generate_multi_device_21
DEBUG 01-07 14:54:34.421739.421739 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.421199.421199 cuda_h.py:19] end gate cost 0.0006566047668457031 seconds
DEBUG 01-07 14:54:34.421790.421790 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.422248.422248 lmp.py:744] 
DEBUG 01-07 14:54:34.422248.422248 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.422341.422341 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.422945.422945 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.422687.422687 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.422569.422569 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.422258.422258 lmp.py:749] 
DEBUG 01-07 14:54:34.422258.422258 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.422901.422901 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.422981.422981 lmp.py:767]   Expert 44 |     31 | CPU
DEBUG 01-07 14:54:34.422339.422339 lmp.py:767]   Expert  9 |     35 | CPU
DEBUG 01-07 14:54:34.422459.422459 lmp.py:767]   Expert 11 |     37 | CPU
DEBUG 01-07 14:54:34.422864.422864 lmp.py:767]   Expert 56 |     59 | CPU
DEBUG 01-07 14:54:34.422792.422792 lmp.py:767]   Expert 54 |     79 | CPU
DEBUG 01-07 14:54:34.422958.422958 lmp.py:767]   Expert  7 |     86 | CPU
DEBUG 01-07 14:54:34.422409.422409 lmp.py:767]   Expert 47 |     88 | CPU
DEBUG 01-07 14:54:34.422336.422336 lmp.py:767]   Expert 62 |     92 | CPU
DEBUG 01-07 14:54:34.422026.422026 lmp.py:767]   Expert 51 |    104 | CPU
DEBUG 01-07 14:54:34.422192.422192 lmp.py:767]   Expert 60 |    105 | CPU
DEBUG 01-07 14:54:34.422881.422881 lmp.py:767]   Expert 52 |    107 | CPU
DEBUG 01-07 14:54:34.422286.422286 lmp.py:767]   Expert 41 |    111 | CPU
DEBUG 01-07 14:54:34.422690.422690 lmp.py:767]   Expert 22 |    112 | CPU
DEBUG 01-07 14:54:34.422141.422141 lmp.py:767]   Expert 53 |    113 | CPU
DEBUG 01-07 14:54:34.422069.422069 lmp.py:767]   Expert  1 |    126 | CPU
DEBUG 01-07 14:54:34.422758.422758 lmp.py:767]   Expert  6 |    126 | CPU
DEBUG 01-07 14:54:34.422209.422209 lmp.py:767]   Expert  8 |    126 | CPU
DEBUG 01-07 14:54:34.422375.422375 lmp.py:767]   Expert  2 |    129 | CPU
DEBUG 01-07 14:54:34.422064.422064 lmp.py:767]   Expert 48 |    129 | CPU
DEBUG 01-07 14:54:34.422184.422184 lmp.py:767]   Expert 32 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422542.422542 lmp.py:767]   Expert 27 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422662.422662 lmp.py:767]   Expert 59 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422544.422544 lmp.py:767]   Expert 35 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422187.422187 lmp.py:767]   Expert 23 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422591.422591 lmp.py:767]   Expert 39 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422711.422711 lmp.py:767]   Expert 26 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422115.422115 lmp.py:767]   Expert 50 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422520.422520 lmp.py:767]   Expert 14 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422686.422686 lmp.py:767]   Expert 46 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422852.422852 lmp.py:767]   Expert 24 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422257.422257 lmp.py:767]   Expert  0 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422423.422423 lmp.py:767]   Expert 34 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422304.422304 lmp.py:767]   Expert  4 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422424.422424 lmp.py:767]   Expert 38 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422067.422067 lmp.py:767]   Expert 49 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422472.422472 lmp.py:767]   Expert 40 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422876.422876 lmp.py:767]   Expert 63 |    184 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422042.422042 lmp.py:767]   Expert  5 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.422447.422447 lmp.py:767]   Expert 19 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.422852.422852 lmp.py:767]   Expert 13 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423018.423018 lmp.py:767]   Expert 29 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423899.423899 lmp.py:767]   Expert 43 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423780.423780 lmp.py:767]   Expert 61 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423185.423185 lmp.py:767]   Expert 57 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423590.423590 lmp.py:767]   Expert 33 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423994.423994 lmp.py:767]   Expert 31 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423399.423399 lmp.py:767]   Expert 20 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423803.423803 lmp.py:767]   Expert 16 |    248 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423969.423969 lmp.py:767]   Expert 37 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423612.423612 lmp.py:767]   Expert  3 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423017.423017 lmp.py:767]   Expert 15 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423421.423421 lmp.py:767]   Expert 36 |    270 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423588.423588 lmp.py:767]   Expert 18 |    281 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423992.423992 lmp.py:767]   Expert 12 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423397.423397 lmp.py:767]   Expert 28 |    305 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423563.423563 lmp.py:767]   Expert 17 |    308 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423206.423206 lmp.py:767]   Expert 55 |    313 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423087.423087 lmp.py:767]   Expert 25 |    320 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423730.423730 lmp.py:767]   Expert 30 |    321 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423896.423896 lmp.py:767]   Expert 58 |    335 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423063.423063 lmp.py:767]   Expert 10 |    361 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423705.423705 lmp.py:767]   Expert 45 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423348.423348 lmp.py:767]   Expert 21 |    393 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.423515.423515 lmp.py:767]   Expert 42 |    647 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.423204.423204 lmp.py:769] 
DEBUG 01-07 14:54:34.423204.423204 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.423085.423085 lmp.py:770]   CPU:   1795 tokens
DEBUG 01-07 14:54:34.423682.423682 lmp.py:774]   cuda:1:   5250 tokens (22 experts)
DEBUG 01-07 14:54:34.423563.423563 lmp.py:774]   cuda:2:   5243 tokens (23 experts)
DEBUG 01-07 14:54:34.423729.423729 lmp.py:775]   Total GPU:  10493 tokens
DEBUG 01-07 14:54:34.423180.423180 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.423180.423180 lmp.py:776] 
DEBUG 01-07 14:54:34.423592.423592 cuda_h.py:19] end experts_map_get cost 0.001756906509399414 seconds
DEBUG 01-07 14:54:34.423712.423712 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.423011.423011 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.423677.423677 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.423943.423943 cuda_h.py:19] end allocate_cuda_memory cost 0.00019860267639160156 seconds
DEBUG 01-07 14:54:34.424707.424707 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.424416.424416 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.424179.424179 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.424067.424067 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7e7a8aec-5e52-4d47-ab24-cb9f18616d1f
DEBUG 01-07 14:54:34.424285.424285 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.424138.424138 client.py:127] Model loaded
DEBUG 01-07 14:54:34.424491.424491 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.424278.424278 cuda_h.py:19] end restore2model cost 0.0003376007080078125 seconds
DEBUG 01-07 14:54:34.424140.424140 cuda_h.py:19] end sllm_worker_task cost 0.008944511413574219 seconds
INFO 01-07 14:54:34.424679.424679 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7e7a8aec-5e52-4d47-ab24-cb9f18616d1f
DEBUG 01-07 14:54:34.425761.425761 cuda_h.py:19] end load_into_gpu_async cost 0.0009884834289550781 seconds
DEBUG 01-07 14:54:34.425510.425510 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.425213.425213 cuda_h.py:19] end restore_tensors2 cost 0.00021409988403320312 seconds
DEBUG 01-07 14:54:34.425360.425360 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017087459564208984 seconds
DEBUG 01-07 14:54:34.425309.425309 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.427253.427253 cuda_h.py:19] end restore2model cost 0.0018618106842041016 seconds
DEBUG 01-07 14:54:34.427732.427732 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.427437.427437 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.427061.427061 cuda_h.py:19] end allocate_cuda_memory cost 0.00021648406982421875 seconds
DEBUG 01-07 14:54:34.427236.427236 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.427799.427799 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.427271.427271 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.427967.427967 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 15e40454-8403-4d4d-8fa8-f2610b0634cf
DEBUG 01-07 14:54:34.427793.427793 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.428195.428195 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 15e40454-8403-4d4d-8fa8-f2610b0634cf
DEBUG 01-07 14:54:34.428548.428548 cuda_h.py:19] end load_into_gpu_async cost 0.0011820793151855469 seconds
DEBUG 01-07 14:54:34.428105.428105 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.429463.429463 cuda_h.py:19] end restore_tensors2 cost 0.00020503997802734375 seconds
DEBUG 01-07 14:54:34.429610.429610 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018842220306396484 seconds
DEBUG 01-07 14:54:34.429982.429982 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.431928.431928 cuda_h.py:19] end restore2model cost 0.0018973350524902344 seconds
DEBUG 01-07 14:54:34.431472.431472 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007667064666748047 seconds
DEBUG 01-07 14:54:34.431076.431076 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.431754.431754 lmp.py:816] 
DEBUG 01-07 14:54:34.431754.431754 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.431160.431160 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 14:54:34.431809.431809 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.443286.443286 mlpmodule.py:749] group tensors cost 0.011744260787963867 s
DEBUG 01-07 14:54:34.444025.444025 mlpmodule.py:787] pad cost 0.0010018348693847656 s
DEBUG 01-07 14:54:34.445485.445485 mlpmodule.py:793] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-07 14:54:34.445720.445720 mlpmodule.py:798] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-07 14:54:34.458951.458951 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.458031.458031 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.458458.458458 mlpmodule.py:818] group_w3 first element: 0.00066375732421875
WARNING 01-07 14:54:34.458165.458165 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.474020.474020 mlpmodule.py:838] group einsum cost 0.029675960540771484 s
DEBUG 01-07 14:54:34.475217.475217 mlpmodule.py:846] cpy2cputensor cost 0.00033664703369140625 s
DEBUG 01-07 14:54:34.478366.478366 cuda_h.py:19] end wait_cetm_experts cost 0.04664325714111328 seconds
DEBUG 01-07 14:54:34.478442.478442 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.478361.478361 cuda_h.py:19] end gpu_sexperts cost 0.0004918575286865234 seconds
DEBUG 01-07 14:54:34.478257.478257 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.478583.478583 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-07 14:54:34.478671.478671 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.478572.478572 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7e7a8aec-5e52-4d47-ab24-cb9f18616d1f
INFO 01-07 14:54:34.479119.479119 client.py:127] Model loaded
INFO 01-07 14:54:34.479617.479617 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 15e40454-8403-4d4d-8fa8-f2610b0634cf
INFO 01-07 14:54:34.480629.480629 client.py:127] Model loaded
DEBUG 01-07 14:54:34.480406.480406 cuda_h.py:19] end wait_experts_multi_device cost 0.0013539791107177734 seconds
DEBUG 01-07 14:54:34.480016.480016 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.480885.480885 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.481666.481666 mlpmodule.py:533] gpu group tensors cost 0.0004725456237792969 s
DEBUG 01-07 14:54:34.482976.482976 mlpmodule.py:566] gpu pad cost 0.0012841224670410156 s
DEBUG 01-07 14:54:34.483911.483911 mlpmodule.py:584] gpu group einsum cost 0.0005471706390380859 s
DEBUG 01-07 14:54:34.485478.485478 mlpmodule.py:656] gpu experts func einsum cost 0.004551410675048828 s
DEBUG 01-07 14:54:34.485594.485594 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.486648.486648 mlpmodule.py:707]  experts func einsum cost 0.055008649826049805 s
DEBUG 01-07 14:54:34.486277.486277 mlpmodule.py:533] gpu group tensors cost 0.0005297660827636719 s
DEBUG 01-07 14:54:34.488168.488168 mlpmodule.py:566] gpu pad cost 0.0012164115905761719 s
DEBUG 01-07 14:54:34.488417.488417 mlpmodule.py:584] gpu group einsum cost 0.0004703998565673828 s
DEBUG 01-07 14:54:34.490345.490345 mlpmodule.py:656] gpu experts func einsum cost 0.004340648651123047 s
DEBUG 01-07 14:54:34.490950.490950 cuda_h.py:19] end gpu_experts_multi_device cost 0.010280132293701172 seconds
DEBUG 01-07 14:54:34.490304.490304 cuda_h.py:19] end layer_moe_generate_multi_device_21 cost 0.06969594955444336 seconds
DEBUG 01-07 14:54:34.490867.490867 lmp.py:194] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-07 14:54:34.490730.490730 lmp.py:153] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-07 14:54:34.490426.490426 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 14:54:34.491943.491943 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 14:54:34.491680.491680 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.6226043701171875e-05 seconds
DEBUG 01-07 14:54:34.491860.491860 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.626678466796875e-05 seconds
DEBUG 01-07 14:54:34.491933.491933 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.491008.491008 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.491573.491573 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.491589.491589 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.491750.491750 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.491635.491635 cuda_h.py:19] end allocate_cuda_memory cost 0.0003018379211425781 seconds
DEBUG 01-07 14:54:34.491790.491790 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.491599.491599 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.491753.491753 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.491264.491264 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 797e67ad-b600-4209-bb17-c1351ac5abbe
DEBUG 01-07 14:54:34.491988.491988 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.492103.492103 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.492349.492349 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 797e67ad-b600-4209-bb17-c1351ac5abbe
DEBUG 01-07 14:54:34.492378.492378 cuda_h.py:19] end load_into_gpu_async cost 0.001100778579711914 seconds
DEBUG 01-07 14:54:34.492412.492412 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.493726.493726 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 14:54:34.493575.493575 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017168521881103516 seconds
INFO 01-07 14:54:34.493756.493756 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 797e67ad-b600-4209-bb17-c1351ac5abbe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.496656.496656 cuda_h.py:19] end self_attn cost 0.003787994384765625 seconds
DEBUG 01-07 14:54:34.496408.496408 cuda_h.py:19] end iln_self_attn_paln cost 0.005228996276855469 seconds
DEBUG 01-07 14:54:34.496436.496436 cuda_h.py:10] start layer_moe_generate_multi_device_22
DEBUG 01-07 14:54:34.496861.496861 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.497606.497606 cuda_h.py:19] end gate cost 0.0006554126739501953 seconds
DEBUG 01-07 14:54:34.497482.497482 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.497840.497840 lmp.py:744] 
DEBUG 01-07 14:54:34.497840.497840 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.497079.497079 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.497636.497636 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.497664.497664 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.497545.497545 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.497996.497996 lmp.py:749] 
DEBUG 01-07 14:54:34.497996.497996 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.497924.497924 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.497765.497765 lmp.py:767]   Expert 25 |     16 | CPU
DEBUG 01-07 14:54:34.497408.497408 lmp.py:767]   Expert 48 |     34 | CPU
DEBUG 01-07 14:54:34.497859.497859 lmp.py:767]   Expert 45 |     35 | CPU
DEBUG 01-07 14:54:34.497072.497072 lmp.py:767]   Expert  9 |     60 | CPU
DEBUG 01-07 14:54:34.497523.497523 lmp.py:767]   Expert 20 |     84 | CPU
DEBUG 01-07 14:54:34.497735.497735 lmp.py:767]   Expert  0 |     86 | CPU
DEBUG 01-07 14:54:34.497424.497424 lmp.py:767]   Expert 43 |     87 | CPU
DEBUG 01-07 14:54:34.497637.497637 lmp.py:767]   Expert 54 |     87 | CPU
DEBUG 01-07 14:54:34.497372.497372 lmp.py:767]   Expert 47 |     90 | CPU
DEBUG 01-07 14:54:34.497585.497585 lmp.py:767]   Expert 57 |     90 | CPU
DEBUG 01-07 14:54:34.497559.497559 lmp.py:767]   Expert  6 |     93 | CPU
DEBUG 01-07 14:54:34.497295.497295 lmp.py:767]   Expert 36 |     96 | CPU
DEBUG 01-07 14:54:34.497745.497745 lmp.py:767]   Expert 62 |    100 | CPU
DEBUG 01-07 14:54:34.497196.497196 lmp.py:767]   Expert 13 |    105 | CPU
DEBUG 01-07 14:54:34.497170.497170 lmp.py:767]   Expert 15 |    105 | CPU
DEBUG 01-07 14:54:34.498144.498144 lmp.py:767]   Expert 61 |    107 | CPU
DEBUG 01-07 14:54:34.498357.498357 lmp.py:767]   Expert  1 |    110 | CPU
DEBUG 01-07 14:54:34.498093.498093 lmp.py:767]   Expert 38 |    110 | CPU
DEBUG 01-07 14:54:34.498067.498067 lmp.py:767]   Expert 50 |    110 | CPU
DEBUG 01-07 14:54:34.498471.498471 lmp.py:767]   Expert 37 |    118 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498591.498591 lmp.py:767]   Expert 14 |    120 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498711.498711 lmp.py:767]   Expert 46 |    120 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498115.498115 lmp.py:767]   Expert 28 |    134 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498043.498043 lmp.py:767]   Expert  7 |    136 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498448.498448 lmp.py:767]   Expert 21 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498375.498375 lmp.py:767]   Expert 52 |    137 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498065.498065 lmp.py:767]   Expert 44 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498231.498231 lmp.py:767]   Expert 10 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498827.498827 lmp.py:767]   Expert 24 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498709.498709 lmp.py:767]   Expert 42 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498398.498398 lmp.py:767]   Expert 11 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498087.498087 lmp.py:767]   Expert  2 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498777.498777 lmp.py:767]   Expert 35 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498989.498989 lmp.py:767]   Expert 26 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498678.498678 lmp.py:767]   Expert 31 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498606.498606 lmp.py:767]   Expert 19 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498534.498534 lmp.py:767]   Expert  3 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498177.498177 lmp.py:767]   Expert 32 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498058.498058 lmp.py:767]   Expert 12 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498463.498463 lmp.py:767]   Expert 60 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498629.498629 lmp.py:767]   Expert 56 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498318.498318 lmp.py:767]   Expert 40 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498008.498008 lmp.py:767]   Expert 41 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498174.498174 lmp.py:767]   Expert 23 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498863.498863 lmp.py:767]   Expert  8 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498744.498744 lmp.py:767]   Expert 53 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498387.498387 lmp.py:767]   Expert 58 |    235 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498838.498838 lmp.py:767]   Expert 16 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498289.498289 lmp.py:767]   Expert 51 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498740.498740 lmp.py:767]   Expert 59 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498429.498429 lmp.py:767]   Expert  4 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498642.498642 lmp.py:767]   Expert 55 |    268 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498093.498093 lmp.py:767]   Expert 49 |    273 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498736.498736 lmp.py:767]   Expert 29 |    277 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498379.498379 lmp.py:767]   Expert 18 |    282 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498068.498068 lmp.py:767]   Expert 34 |    286 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498711.498711 lmp.py:767]   Expert 63 |    298 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498115.498115 lmp.py:767]   Expert 27 |    356 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498335.498335 lmp.py:767]   Expert 39 |    376 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498693.498693 lmp.py:767]   Expert 17 |    392 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498382.498382 lmp.py:767]   Expert 22 |    428 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498833.498833 lmp.py:767]   Expert 33 |    454 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498761.498761 lmp.py:767]   Expert 30 |    455 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.498927.498927 lmp.py:767]   Expert  5 |    711 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.498901.498901 lmp.py:769] 
DEBUG 01-07 14:54:34.498901.498901 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.498875.498875 lmp.py:770]   CPU:   1605 tokens
DEBUG 01-07 14:54:34.498041.498041 lmp.py:774]   cuda:1:   5315 tokens (22 experts)
DEBUG 01-07 14:54:34.498969.498969 lmp.py:774]   cuda:2:   5368 tokens (23 experts)
DEBUG 01-07 14:54:34.498897.498897 lmp.py:775]   Total GPU:  10683 tokens
DEBUG 01-07 14:54:34.498632.498632 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.498632.498632 lmp.py:776] 
DEBUG 01-07 14:54:34.498090.498090 cuda_h.py:19] end experts_map_get cost 0.0017197132110595703 seconds
DEBUG 01-07 14:54:34.498733.498733 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.499887.499887 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.499844.499844 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.499310.499310 cuda_h.py:19] end allocate_cuda_memory cost 0.00024127960205078125 seconds
DEBUG 01-07 14:54:34.499676.499676 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.499479.499479 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.499288.499288 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.499938.499938 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 82b548e1-93ad-4b48-b868-0bae760378c0
DEBUG 01-07 14:54:34.499717.499717 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.499372.499372 client.py:127] Model loaded
DEBUG 01-07 14:54:34.499864.499864 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.500889.500889 cuda_h.py:19] end restore2model cost 0.00033926963806152344 seconds
DEBUG 01-07 14:54:34.500275.500275 cuda_h.py:19] end sllm_worker_task cost 0.009009838104248047 seconds
INFO 01-07 14:54:34.500754.500754 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 82b548e1-93ad-4b48-b868-0bae760378c0
DEBUG 01-07 14:54:34.500452.500452 cuda_h.py:19] end load_into_gpu_async cost 0.0011713504791259766 seconds
DEBUG 01-07 14:54:34.500724.500724 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.500136.500136 cuda_h.py:19] end restore_tensors2 cost 0.00020933151245117188 seconds
DEBUG 01-07 14:54:34.500852.500852 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019199848175048828 seconds
DEBUG 01-07 14:54:34.500800.500800 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.502719.502719 cuda_h.py:19] end restore2model cost 0.0018773078918457031 seconds
DEBUG 01-07 14:54:34.502390.502390 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.503380.503380 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.503428.503428 cuda_h.py:19] end allocate_cuda_memory cost 0.00021266937255859375 seconds
DEBUG 01-07 14:54:34.503218.503218 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.503066.503066 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.503776.503776 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.503949.503949 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ded1a40a-09a9-4594-9716-2914adc4b68e
DEBUG 01-07 14:54:34.503795.503795 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.504311.504311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ded1a40a-09a9-4594-9716-2914adc4b68e
DEBUG 01-07 14:54:34.504425.504425 cuda_h.py:19] end load_into_gpu_async cost 0.0012102127075195312 seconds
DEBUG 01-07 14:54:34.504267.504267 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.504142.504142 cuda_h.py:19] end restore_tensors2 cost 0.00020051002502441406 seconds
DEBUG 01-07 14:54:34.504335.504335 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018982887268066406 seconds
DEBUG 01-07 14:54:34.504707.504707 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.506930.506930 cuda_h.py:19] end restore2model cost 0.0018913745880126953 seconds
DEBUG 01-07 14:54:34.506952.506952 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007900476455688477 seconds
DEBUG 01-07 14:54:34.506032.506032 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.506564.506564 lmp.py:816] 
DEBUG 01-07 14:54:34.506564.506564 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.507354.507354 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-07 14:54:34.507481.507481 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.512014.512014 mlpmodule.py:749] group tensors cost 0.005322456359863281 s
DEBUG 01-07 14:54:34.514093.514093 mlpmodule.py:787] pad cost 0.0012547969818115234 s
DEBUG 01-07 14:54:34.514772.514772 mlpmodule.py:793] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-07 14:54:34.514457.514457 mlpmodule.py:798] move to cpu cost 3.814697265625e-05 s
DEBUG 01-07 14:54:34.523441.523441 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.523586.523586 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.523013.523013 mlpmodule.py:818] group_w3 first element: -0.018798828125
WARNING 01-07 14:54:34.523282.523282 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.539388.539388 mlpmodule.py:838] group einsum cost 0.024335861206054688 s
DEBUG 01-07 14:54:34.539659.539659 mlpmodule.py:846] cpy2cputensor cost 0.00039005279541015625 s
DEBUG 01-07 14:54:34.542496.542496 cuda_h.py:19] end wait_cetm_experts cost 0.03522086143493652 seconds
DEBUG 01-07 14:54:34.542281.542281 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.543003.543003 cuda_h.py:19] end gpu_sexperts cost 0.0005578994750976562 seconds
DEBUG 01-07 14:54:34.543707.543707 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.543663.543663 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-07 14:54:34.543273.543273 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.543698.543698 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 82b548e1-93ad-4b48-b868-0bae760378c0
INFO 01-07 14:54:34.544773.544773 client.py:127] Model loaded
INFO 01-07 14:54:34.544649.544649 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ded1a40a-09a9-4594-9716-2914adc4b68e
INFO 01-07 14:54:34.544477.544477 client.py:127] Model loaded
DEBUG 01-07 14:54:34.544353.544353 cuda_h.py:19] end wait_experts_multi_device cost 0.001361846923828125 seconds
DEBUG 01-07 14:54:34.544248.544248 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.544594.544594 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.545480.545480 mlpmodule.py:533] gpu group tensors cost 0.0004792213439941406 s
DEBUG 01-07 14:54:34.547299.547299 mlpmodule.py:566] gpu pad cost 0.001280069351196289 s
DEBUG 01-07 14:54:34.547632.547632 mlpmodule.py:584] gpu group einsum cost 0.0005614757537841797 s
DEBUG 01-07 14:54:34.549549.549549 mlpmodule.py:656] gpu experts func einsum cost 0.004534482955932617 s
DEBUG 01-07 14:54:34.550228.550228 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.550146.550146 mlpmodule.py:707]  experts func einsum cost 0.04328489303588867 s
DEBUG 01-07 14:54:34.551629.551629 mlpmodule.py:533] gpu group tensors cost 0.0004394054412841797 s
DEBUG 01-07 14:54:34.552075.552075 mlpmodule.py:566] gpu pad cost 0.001207113265991211 s
DEBUG 01-07 14:54:34.552146.552146 mlpmodule.py:584] gpu group einsum cost 0.0004787445068359375 s
DEBUG 01-07 14:54:34.554882.554882 mlpmodule.py:656] gpu experts func einsum cost 0.0042459964752197266 s
DEBUG 01-07 14:54:34.554865.554865 cuda_h.py:19] end gpu_experts_multi_device cost 0.01029205322265625 seconds
DEBUG 01-07 14:54:34.555881.555881 cuda_h.py:19] end layer_moe_generate_multi_device_22 cost 0.05854988098144531 seconds
DEBUG 01-07 14:54:34.555298.555298 lmp.py:194] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-07 14:54:34.555114.555114 lmp.py:153] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-07 14:54:34.555572.555572 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 14:54:34.555374.555374 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 14:54:34.555018.555018 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 14:54:34.555960.555960 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.817413330078125e-05 seconds
DEBUG 01-07 14:54:34.555748.555748 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.555096.555096 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.555276.555276 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.555749.555749 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.555433.555433 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.555449.555449 cuda_h.py:19] end allocate_cuda_memory cost 0.0002593994140625 seconds
DEBUG 01-07 14:54:34.556697.556697 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.556598.556598 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.556514.556514 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.556071.556071 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45680f86-a99a-4c3b-8b5d-2bf402b33fcd
DEBUG 01-07 14:54:34.556557.556557 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.556559.556559 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.556297.556297 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45680f86-a99a-4c3b-8b5d-2bf402b33fcd
DEBUG 01-07 14:54:34.557895.557895 cuda_h.py:19] end load_into_gpu_async cost 0.0009553432464599609 seconds
DEBUG 01-07 14:54:34.557168.557168 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.557052.557052 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:34.557900.557900 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015225410461425781 seconds
INFO 01-07 14:54:34.557505.557505 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45680f86-a99a-4c3b-8b5d-2bf402b33fcd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.560248.560248 cuda_h.py:19] end self_attn cost 0.003711700439453125 seconds
DEBUG 01-07 14:54:34.560013.560013 cuda_h.py:19] end iln_self_attn_paln cost 0.005116939544677734 seconds
DEBUG 01-07 14:54:34.560174.560174 cuda_h.py:10] start layer_moe_generate_multi_device_23
DEBUG 01-07 14:54:34.560122.560122 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.561860.561860 cuda_h.py:19] end gate cost 0.0006515979766845703 seconds
DEBUG 01-07 14:54:34.561021.561021 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.561624.561624 lmp.py:744] 
DEBUG 01-07 14:54:34.561624.561624 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.561049.561049 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.561606.561606 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.561110.561110 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.561707.561707 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.561634.561634 lmp.py:749] 
DEBUG 01-07 14:54:34.561634.561634 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.561277.561277 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.561596.561596 lmp.py:767]   Expert  5 |     16 | CPU
DEBUG 01-07 14:54:34.561716.561716 lmp.py:767]   Expert 56 |     34 | CPU
DEBUG 01-07 14:54:34.561882.561882 lmp.py:767]   Expert 27 |     80 | CPU
DEBUG 01-07 14:54:34.561525.561525 lmp.py:767]   Expert 16 |     85 | CPU
DEBUG 01-07 14:54:34.561453.561453 lmp.py:767]   Expert 17 |     90 | CPU
DEBUG 01-07 14:54:34.562619.562619 lmp.py:767]   Expert 40 |     95 | CPU
DEBUG 01-07 14:54:34.562785.562785 lmp.py:767]   Expert 63 |    101 | CPU
DEBUG 01-07 14:54:34.562428.562428 lmp.py:767]   Expert 51 |    104 | CPU
DEBUG 01-07 14:54:34.562071.562071 lmp.py:767]   Expert 53 |    105 | CPU
DEBUG 01-07 14:54:34.562475.562475 lmp.py:767]   Expert 49 |    108 | CPU
DEBUG 01-07 14:54:34.562165.562165 lmp.py:767]   Expert 28 |    110 | CPU
DEBUG 01-07 14:54:34.562331.562331 lmp.py:767]   Expert  7 |    112 | CPU
DEBUG 01-07 14:54:34.562782.562782 lmp.py:767]   Expert 38 |    119 | CPU
DEBUG 01-07 14:54:34.562709.562709 lmp.py:767]   Expert 37 |    121 | CPU
DEBUG 01-07 14:54:34.562637.562637 lmp.py:767]   Expert 47 |    121 | CPU
DEBUG 01-07 14:54:34.562327.562327 lmp.py:767]   Expert 62 |    126 | CPU
DEBUG 01-07 14:54:34.562254.562254 lmp.py:767]   Expert 11 |    130 | CPU
DEBUG 01-07 14:54:34.562659.562659 lmp.py:767]   Expert 58 |    130 | CPU
DEBUG 01-07 14:54:34.562063.562063 lmp.py:767]   Expert 57 |    136 | CPU
DEBUG 01-07 14:54:34.562422.562422 lmp.py:767]   Expert 39 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562018.562018 lmp.py:767]   Expert  1 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562900.562900 lmp.py:767]   Expert 14 |    148 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562543.562543 lmp.py:767]   Expert 52 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562424.562424 lmp.py:767]   Expert 23 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562782.562782 lmp.py:767]   Expert 25 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562379.562379 lmp.py:767]   Expert 33 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562022.562022 lmp.py:767]   Expert 21 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562903.562903 lmp.py:767]   Expert 60 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562308.562308 lmp.py:767]   Expert  6 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562712.562712 lmp.py:767]   Expert 45 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562117.562117 lmp.py:767]   Expert 19 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562521.562521 lmp.py:767]   Expert 44 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562641.562641 lmp.py:767]   Expert 12 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562761.562761 lmp.py:767]   Expert  4 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562642.562642 lmp.py:767]   Expert  3 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562762.562762 lmp.py:767]   Expert 31 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562167.562167 lmp.py:767]   Expert 36 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562810.562810 lmp.py:767]   Expert 30 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562691.562691 lmp.py:767]   Expert 55 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562049.562049 lmp.py:767]   Expert  9 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562646.562646 lmp.py:767]   Expert 34 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562766.562766 lmp.py:767]   Expert  0 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562409.562409 lmp.py:767]   Expert 22 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562052.562052 lmp.py:767]   Expert 41 |    230 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562695.562695 lmp.py:767]   Expert 26 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562338.562338 lmp.py:767]   Expert 54 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562981.562981 lmp.py:767]   Expert 43 |    238 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562101.562101 lmp.py:767]   Expert 59 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562459.562459 lmp.py:767]   Expert 18 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562863.562863 lmp.py:767]   Expert 13 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562268.562268 lmp.py:767]   Expert 50 |    255 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562911.562911 lmp.py:767]   Expert 20 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562554.562554 lmp.py:767]   Expert 15 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562958.562958 lmp.py:767]   Expert 24 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562078.562078 lmp.py:767]   Expert 29 |    265 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562960.562960 lmp.py:767]   Expert 42 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562364.562364 lmp.py:767]   Expert 61 |    273 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562769.562769 lmp.py:767]   Expert 35 |    281 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562173.562173 lmp.py:767]   Expert 32 |    302 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.562816.562816 lmp.py:767]   Expert 10 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562982.562982 lmp.py:767]   Expert  2 |    338 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.562387.562387 lmp.py:767]   Expert  8 |    338 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.563745.563745 lmp.py:767]   Expert 46 |    424 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.563627.563627 lmp.py:767]   Expert 48 |    443 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.563316.563316 lmp.py:769] 
DEBUG 01-07 14:54:34.563316.563316 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.563482.563482 lmp.py:770]   CPU:   1923 tokens
DEBUG 01-07 14:54:34.563602.563602 lmp.py:774]   cuda:1:   5254 tokens (23 experts)
DEBUG 01-07 14:54:34.563245.563245 lmp.py:774]   cuda:2:   5111 tokens (22 experts)
DEBUG 01-07 14:54:34.563411.563411 lmp.py:775]   Total GPU:  10365 tokens
DEBUG 01-07 14:54:34.563100.563100 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.563100.563100 lmp.py:776] 
DEBUG 01-07 14:54:34.563227.563227 cuda_h.py:19] end experts_map_get cost 0.0017740726470947266 seconds
DEBUG 01-07 14:54:34.563824.563824 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.563361.563361 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.563365.563365 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.563733.563733 cuda_h.py:19] end allocate_cuda_memory cost 0.0002727508544921875 seconds
DEBUG 01-07 14:54:34.563066.563066 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.563061.563061 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.563731.563731 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.563858.563858 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 82deeb3a-ce2e-41d8-900b-a06452f97e34
DEBUG 01-07 14:54:34.563108.563108 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.564881.564881 client.py:127] Model loaded
DEBUG 01-07 14:54:34.564949.564949 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.564551.564551 cuda_h.py:19] end restore2model cost 0.0003409385681152344 seconds
DEBUG 01-07 14:54:34.564797.564797 cuda_h.py:19] end sllm_worker_task cost 0.00896000862121582 seconds
INFO 01-07 14:54:34.564674.564674 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 82deeb3a-ce2e-41d8-900b-a06452f97e34
DEBUG 01-07 14:54:34.564371.564371 cuda_h.py:19] end load_into_gpu_async cost 0.0009636878967285156 seconds
DEBUG 01-07 14:54:34.564928.564928 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.564500.564500 cuda_h.py:19] end restore_tensors2 cost 0.0002224445343017578 seconds
DEBUG 01-07 14:54:34.565408.565408 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017681121826171875 seconds
DEBUG 01-07 14:54:34.565548.565548 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.567508.567508 cuda_h.py:19] end restore2model cost 0.0019445419311523438 seconds
DEBUG 01-07 14:54:34.567749.567749 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.567885.567885 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.567755.567755 cuda_h.py:19] end allocate_cuda_memory cost 0.00022125244140625 seconds
DEBUG 01-07 14:54:34.567452.567452 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.567585.567585 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.567249.567249 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.567898.567898 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e2303fc-0bdd-441e-a168-4d3a6b42474b
DEBUG 01-07 14:54:34.567459.567459 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.568629.568629 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e2303fc-0bdd-441e-a168-4d3a6b42474b
DEBUG 01-07 14:54:34.568035.568035 cuda_h.py:19] end load_into_gpu_async cost 0.0011670589447021484 seconds
DEBUG 01-07 14:54:34.568784.568784 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.568375.568375 cuda_h.py:19] end restore_tensors2 cost 0.00020074844360351562 seconds
DEBUG 01-07 14:54:34.568137.568137 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018742084503173828 seconds
DEBUG 01-07 14:54:34.569417.569417 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.570260.570260 cuda_h.py:19] end restore2model cost 0.0018231868743896484 seconds
DEBUG 01-07 14:54:34.570613.570613 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007723093032836914 seconds
DEBUG 01-07 14:54:34.570739.570739 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.571464.571464 lmp.py:816] 
DEBUG 01-07 14:54:34.571464.571464 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.571254.571254 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-07 14:54:34.571665.571665 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.580682.580682 mlpmodule.py:749] group tensors cost 0.009684085845947266 s
DEBUG 01-07 14:54:34.582235.582235 mlpmodule.py:787] pad cost 0.0012083053588867188 s
DEBUG 01-07 14:54:34.582146.582146 mlpmodule.py:793] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-07 14:54:34.582725.582725 mlpmodule.py:798] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-07 14:54:34.593143.593143 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.593573.593573 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.593901.593901 mlpmodule.py:818] group_w3 first element: 0.04248046875
WARNING 01-07 14:54:34.593607.593607 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.609631.609631 mlpmodule.py:838] group einsum cost 0.026781082153320312 s
DEBUG 01-07 14:54:34.610127.610127 mlpmodule.py:846] cpy2cputensor cost 0.0003936290740966797 s
DEBUG 01-07 14:54:34.613505.613505 cuda_h.py:19] end wait_cetm_experts cost 0.04204249382019043 seconds
DEBUG 01-07 14:54:34.613488.613488 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.613506.613506 cuda_h.py:19] end gpu_sexperts cost 0.0004975795745849609 seconds
DEBUG 01-07 14:54:34.613402.613402 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.613067.613067 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6941299438476562e-05 seconds
DEBUG 01-07 14:54:34.613154.613154 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.614532.614532 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 82deeb3a-ce2e-41d8-900b-a06452f97e34
INFO 01-07 14:54:34.614013.614013 client.py:127] Model loaded
INFO 01-07 14:54:34.615023.615023 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e2303fc-0bdd-441e-a168-4d3a6b42474b
INFO 01-07 14:54:34.615895.615895 client.py:127] Model loaded
DEBUG 01-07 14:54:34.615307.615307 cuda_h.py:19] end wait_experts_multi_device cost 0.001590728759765625 seconds
DEBUG 01-07 14:54:34.615448.615448 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.615178.615178 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:34.616032.616032 mlpmodule.py:533] gpu group tensors cost 0.0005233287811279297 s
DEBUG 01-07 14:54:34.618168.618168 mlpmodule.py:566] gpu pad cost 0.0012276172637939453 s
DEBUG 01-07 14:54:34.618295.618295 mlpmodule.py:584] gpu group einsum cost 0.0005500316619873047 s
DEBUG 01-07 14:54:34.620110.620110 mlpmodule.py:656] gpu experts func einsum cost 0.004445791244506836 s
DEBUG 01-07 14:54:34.621596.621596 mlpmodule.py:707]  experts func einsum cost 0.04983878135681152 s
DEBUG 01-07 14:54:34.621237.621237 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:34.621368.621368 mlpmodule.py:533] gpu group tensors cost 0.00045037269592285156 s
DEBUG 01-07 14:54:34.623041.623041 mlpmodule.py:566] gpu pad cost 0.0012459754943847656 s
DEBUG 01-07 14:54:34.623879.623879 mlpmodule.py:584] gpu group einsum cost 0.0004482269287109375 s
DEBUG 01-07 14:54:34.625663.625663 mlpmodule.py:656] gpu experts func einsum cost 0.004320621490478516 s
DEBUG 01-07 14:54:34.625799.625799 cuda_h.py:19] end gpu_experts_multi_device cost 0.010271310806274414 seconds
DEBUG 01-07 14:54:34.626862.626862 cuda_h.py:19] end layer_moe_generate_multi_device_23 cost 0.06540036201477051 seconds
DEBUG 01-07 14:54:34.626425.626425 lmp.py:194] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-07 14:54:34.626956.626956 lmp.py:153] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-07 14:54:34.626937.626937 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 14:54:34.626501.626501 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 14:54:34.626337.626337 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 14:54:34.626563.626563 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.841255187988281e-05 seconds
DEBUG 01-07 14:54:34.626683.626683 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.626565.626565 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.626269.626269 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.626795.626795 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.626148.626148 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.626033.626033 cuda_h.py:19] end allocate_cuda_memory cost 0.0003025531768798828 seconds
DEBUG 01-07 14:54:34.627672.627672 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.627673.627673 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.627827.627827 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.627145.627145 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b838e02-5d87-4c85-9fa1-223e91920382
DEBUG 01-07 14:54:34.627439.627439 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.627149.627149 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.628083.628083 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b838e02-5d87-4c85-9fa1-223e91920382
DEBUG 01-07 14:54:34.628396.628396 cuda_h.py:19] end load_into_gpu_async cost 0.001024484634399414 seconds
DEBUG 01-07 14:54:34.628953.628953 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.628837.628837 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:34.628162.628162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016443729400634766 seconds
INFO 01-07 14:54:34.628979.628979 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b838e02-5d87-4c85-9fa1-223e91920382
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.631282.631282 cuda_h.py:19] end self_attn cost 0.0036885738372802734 seconds
DEBUG 01-07 14:54:34.631557.631557 cuda_h.py:19] end iln_self_attn_paln cost 0.005110740661621094 seconds
DEBUG 01-07 14:54:34.631479.631479 cuda_h.py:10] start layer_moe_generate_multi_device_24
DEBUG 01-07 14:54:34.631381.631381 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.632920.632920 cuda_h.py:19] end gate cost 0.0006439685821533203 seconds
DEBUG 01-07 14:54:34.632319.632319 cuda_h.py:10] start experts_map_get
INFO 01-07 14:54:34.635813.635813 client.py:127] Model loaded
DEBUG 01-07 14:54:34.636846.636846 lmp.py:744] 
DEBUG 01-07 14:54:34.636846.636846 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.636987.636987 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.636935.636935 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.636273.636273 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.636638.636638 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.636235.636235 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.636878.636878 lmp.py:749] 
DEBUG 01-07 14:54:34.636878.636878 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.636998.636998 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.636555.636555 lmp.py:767]   Expert 36 |     22 | CPU
DEBUG 01-07 14:54:34.636436.636436 lmp.py:767]   Expert 35 |     31 | CPU
DEBUG 01-07 14:54:34.636841.636841 lmp.py:767]   Expert 25 |     44 | CPU
DEBUG 01-07 14:54:34.636769.636769 lmp.py:767]   Expert 46 |     44 | CPU
DEBUG 01-07 14:54:34.636935.636935 lmp.py:767]   Expert 51 |     51 | CPU
DEBUG 01-07 14:54:34.636101.636101 lmp.py:767]   Expert 16 |     61 | CPU
DEBUG 01-07 14:54:34.636029.636029 lmp.py:767]   Expert 30 |     61 | CPU
DEBUG 01-07 14:54:34.636102.636102 lmp.py:767]   Expert  0 |     64 | CPU
DEBUG 01-07 14:54:34.636268.636268 lmp.py:767]   Expert 43 |     67 | CPU
DEBUG 01-07 14:54:34.636958.636958 lmp.py:767]   Expert 55 |     70 | CPU
DEBUG 01-07 14:54:34.636647.636647 lmp.py:767]   Expert 47 |     71 | CPU
DEBUG 01-07 14:54:34.636098.636098 lmp.py:767]   Expert 42 |     74 | CPU
DEBUG 01-07 14:54:34.636787.636787 lmp.py:767]   Expert 39 |     76 | CPU
DEBUG 01-07 14:54:34.636000.636000 lmp.py:767]   Expert 44 |     76 | CPU
DEBUG 01-07 14:54:34.636450.636450 lmp.py:767]   Expert  2 |     87 | CPU
DEBUG 01-07 14:54:34.636855.636855 lmp.py:767]   Expert  4 |    111 | CPU
DEBUG 01-07 14:54:34.636544.636544 lmp.py:767]   Expert 48 |    118 | CPU
DEBUG 01-07 14:54:34.636187.636187 lmp.py:767]   Expert 13 |    119 | CPU
DEBUG 01-07 14:54:34.636069.636069 lmp.py:767]   Expert 33 |    121 | CPU
DEBUG 01-07 14:54:34.636381.636381 lmp.py:767]   Expert 24 |    122 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.636977.636977 lmp.py:767]   Expert 61 |    126 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637859.637859 lmp.py:767]   Expert  6 |    127 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637978.637978 lmp.py:767]   Expert 56 |    128 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637098.637098 lmp.py:767]   Expert 15 |    132 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637218.637218 lmp.py:767]   Expert 29 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637861.637861 lmp.py:767]   Expert 38 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637504.637504 lmp.py:767]   Expert  7 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637101.637101 lmp.py:767]   Expert  9 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637220.637220 lmp.py:767]   Expert 54 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637863.637863 lmp.py:767]   Expert 20 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637268.637268 lmp.py:767]   Expert 59 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637673.637673 lmp.py:767]   Expert 45 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637077.637077 lmp.py:767]   Expert 62 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637958.637958 lmp.py:767]   Expert 19 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637363.637363 lmp.py:767]   Expert 34 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637768.637768 lmp.py:767]   Expert 57 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637934.637934 lmp.py:767]   Expert 50 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637292.637292 lmp.py:767]   Expert 10 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637127.637127 lmp.py:767]   Expert 31 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637770.637770 lmp.py:767]   Expert 23 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637175.637175 lmp.py:767]   Expert 60 |    213 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637579.637579 lmp.py:767]   Expert  8 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637984.637984 lmp.py:767]   Expert 18 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637150.637150 lmp.py:767]   Expert 53 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637554.637554 lmp.py:767]   Expert 22 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637959.637959 lmp.py:767]   Expert 52 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637079.637079 lmp.py:767]   Expert 37 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637675.637675 lmp.py:767]   Expert 17 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637318.637318 lmp.py:767]   Expert  5 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637723.637723 lmp.py:767]   Expert 11 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637127.637127 lmp.py:767]   Expert  1 |    269 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637532.637532 lmp.py:767]   Expert 49 |    277 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637460.637460 lmp.py:767]   Expert 41 |    281 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637626.637626 lmp.py:767]   Expert 28 |    287 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637030.637030 lmp.py:767]   Expert 26 |    289 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637627.637627 lmp.py:767]   Expert 32 |    296 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637985.637985 lmp.py:767]   Expert 58 |    298 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637390.637390 lmp.py:767]   Expert 14 |    306 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637794.637794 lmp.py:767]   Expert 40 |    306 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637961.637961 lmp.py:767]   Expert 12 |    324 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637127.637127 lmp.py:767]   Expert 63 |    337 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637531.637531 lmp.py:767]   Expert 21 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637936.637936 lmp.py:767]   Expert 27 |    665 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.637102.637102 lmp.py:767]   Expert  3 |   1018 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.637507.637507 lmp.py:769] 
DEBUG 01-07 14:54:34.637507.637507 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.637865.637865 lmp.py:770]   CPU:   1368 tokens
DEBUG 01-07 14:54:34.637223.637223 lmp.py:774]   cuda:1:   5463 tokens (22 experts)
DEBUG 01-07 14:54:34.637628.637628 lmp.py:774]   cuda:2:   5457 tokens (23 experts)
DEBUG 01-07 14:54:34.637555.637555 lmp.py:775]   Total GPU:  10920 tokens
DEBUG 01-07 14:54:34.637245.637245 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.637245.637245 lmp.py:776] 
DEBUG 01-07 14:54:34.637086.637086 cuda_h.py:19] end experts_map_get cost 0.002052783966064453 seconds
DEBUG 01-07 14:54:34.637683.637683 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.637221.637221 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.638509.638509 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.638497.638497 cuda_h.py:19] end allocate_cuda_memory cost 0.00020432472229003906 seconds
DEBUG 01-07 14:54:34.638577.638577 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.638578.638578 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.638248.638248 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.638090.638090 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 817e2ae5-4214-46d0-ae6d-a7784b62f8bc
DEBUG 01-07 14:54:34.638572.638572 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.639846.639846 cuda_h.py:19] end restore2model cost 0.002619504928588867 seconds
DEBUG 01-07 14:54:34.639119.639119 cuda_h.py:19] end sllm_worker_task cost 0.012463092803955078 seconds
INFO 01-07 14:54:34.639590.639590 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 817e2ae5-4214-46d0-ae6d-a7784b62f8bc
DEBUG 01-07 14:54:34.639810.639810 cuda_h.py:19] end load_into_gpu_async cost 0.0011873245239257812 seconds
DEBUG 01-07 14:54:34.639606.639606 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.639216.639216 cuda_h.py:19] end restore_tensors2 cost 0.00021529197692871094 seconds
DEBUG 01-07 14:54:34.640410.640410 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002047300338745117 seconds
DEBUG 01-07 14:54:34.640881.640881 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.641535.641535 cuda_h.py:19] end restore2model cost 0.0018935203552246094 seconds
DEBUG 01-07 14:54:34.642497.642497 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.642872.642872 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.642589.642589 cuda_h.py:19] end allocate_cuda_memory cost 0.00021338462829589844 seconds
DEBUG 01-07 14:54:34.642332.642332 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.642896.642896 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.642083.642083 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.642971.642971 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3a88c3a7-2a2b-4e70-bf23-808ecab0de2e
DEBUG 01-07 14:54:34.642962.642962 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.643887.643887 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3a88c3a7-2a2b-4e70-bf23-808ecab0de2e
DEBUG 01-07 14:54:34.643332.643332 cuda_h.py:19] end load_into_gpu_async cost 0.0011630058288574219 seconds
DEBUG 01-07 14:54:34.643413.643413 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.643526.643526 cuda_h.py:19] end restore_tensors2 cost 0.0002002716064453125 seconds
DEBUG 01-07 14:54:34.643388.643388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018568038940429688 seconds
DEBUG 01-07 14:54:34.643283.643283 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.645805.645805 cuda_h.py:19] end restore2model cost 0.001901388168334961 seconds
DEBUG 01-07 14:54:34.645634.645634 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008017778396606445 seconds
DEBUG 01-07 14:54:34.645476.645476 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.646293.646293 lmp.py:816] 
DEBUG 01-07 14:54:34.646293.646293 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.646222.646222 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 14:54:34.646872.646872 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.652462.652462 mlpmodule.py:749] group tensors cost 0.0062084197998046875 s
DEBUG 01-07 14:54:34.654862.654862 mlpmodule.py:787] pad cost 0.0016963481903076172 s
DEBUG 01-07 14:54:34.655728.655728 mlpmodule.py:793] create cpu tensor cost 5.984306335449219e-05 s
DEBUG 01-07 14:54:34.655063.655063 mlpmodule.py:798] move to cpu cost 4.601478576660156e-05 s
DEBUG 01-07 14:54:34.663506.663506 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.663743.663743 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.663217.663217 mlpmodule.py:818] group_w3 first element: 0.00653076171875
WARNING 01-07 14:54:34.663248.663248 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.676755.676755 mlpmodule.py:838] group einsum cost 0.02155160903930664 s
DEBUG 01-07 14:54:34.677192.677192 mlpmodule.py:846] cpy2cputensor cost 0.0004100799560546875 s
DEBUG 01-07 14:54:34.680439.680439 cuda_h.py:19] end wait_cetm_experts cost 0.03390622138977051 seconds
DEBUG 01-07 14:54:34.680707.680707 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.680866.680866 cuda_h.py:19] end gpu_sexperts cost 0.0005288124084472656 seconds
DEBUG 01-07 14:54:34.680907.680907 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.680042.680042 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 14:54:34.680175.680175 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.680077.680077 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 817e2ae5-4214-46d0-ae6d-a7784b62f8bc
INFO 01-07 14:54:34.682550.682550 client.py:127] Model loaded
INFO 01-07 14:54:34.682923.682923 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3a88c3a7-2a2b-4e70-bf23-808ecab0de2e
INFO 01-07 14:54:34.683162.683162 client.py:127] Model loaded
DEBUG 01-07 14:54:34.683290.683290 cuda_h.py:19] end wait_experts_multi_device cost 0.0021927356719970703 seconds
DEBUG 01-07 14:54:34.683622.683622 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.683829.683829 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.684220.684220 mlpmodule.py:533] gpu group tensors cost 0.0003974437713623047 s
DEBUG 01-07 14:54:34.685878.685878 mlpmodule.py:566] gpu pad cost 0.0011990070343017578 s
DEBUG 01-07 14:54:34.686327.686327 mlpmodule.py:584] gpu group einsum cost 0.0005095005035400391 s
DEBUG 01-07 14:54:34.687606.687606 mlpmodule.py:656] gpu experts func einsum cost 0.0040187835693359375 s
DEBUG 01-07 14:54:34.688926.688926 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.688869.688869 mlpmodule.py:533] gpu group tensors cost 0.0003943443298339844 s
DEBUG 01-07 14:54:34.689980.689980 mlpmodule.py:566] gpu pad cost 0.0010802745819091797 s
DEBUG 01-07 14:54:34.690744.690744 mlpmodule.py:584] gpu group einsum cost 0.0004279613494873047 s
DEBUG 01-07 14:54:34.692538.692538 mlpmodule.py:656] gpu experts func einsum cost 0.0037670135498046875 s
DEBUG 01-07 14:54:34.692820.692820 cuda_h.py:19] end gpu_experts_multi_device cost 0.00903177261352539 seconds
DEBUG 01-07 14:54:34.692756.692756 cuda_h.py:19] end layer_moe_generate_multi_device_24 cost 0.060671329498291016 seconds
DEBUG 01-07 14:54:34.692354.692354 lmp.py:194] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-07 14:54:34.692269.692269 lmp.py:153] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-07 14:54:34.692780.692780 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 14:54:34.692827.692827 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 14:54:34.692578.692578 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.170967102050781e-05 seconds
DEBUG 01-07 14:54:34.692956.692956 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.842613220214844e-05 seconds
DEBUG 01-07 14:54:34.692937.692937 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.692005.692005 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.692863.692863 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.692884.692884 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.693995.693995 cuda_h.py:19] end allocate_cuda_memory cost 0.0002892017364501953 seconds
DEBUG 01-07 14:54:34.693659.693659 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.693561.693561 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.693483.693483 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.693948.693948 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20dab7fc-68fd-405b-8e25-6110105a9ff7
DEBUG 01-07 14:54:34.693010.693010 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.693929.693929 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.693963.693963 mlpmodule.py:707]  experts func einsum cost 0.04768776893615723 s
INFO 01-07 14:54:34.694489.694489 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20dab7fc-68fd-405b-8e25-6110105a9ff7
DEBUG 01-07 14:54:34.694985.694985 cuda_h.py:19] end load_into_gpu_async cost 0.000972747802734375 seconds
DEBUG 01-07 14:54:34.694317.694317 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.694015.694015 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-07 14:54:34.694010.694010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015866756439208984 seconds
INFO 01-07 14:54:34.694999.694999 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20dab7fc-68fd-405b-8e25-6110105a9ff7
DEBUG 01-07 14:54:34.694453.694453 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.698287.698287 cuda_h.py:19] end self_attn cost 0.0034601688385009766 seconds
DEBUG 01-07 14:54:34.698914.698914 cuda_h.py:19] end iln_self_attn_paln cost 0.0059926509857177734 seconds
DEBUG 01-07 14:54:34.698644.698644 cuda_h.py:10] start layer_moe_generate_multi_device_25
DEBUG 01-07 14:54:34.698876.698876 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.699582.699582 cuda_h.py:19] end gate cost 0.0006628036499023438 seconds
DEBUG 01-07 14:54:34.699266.699266 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.700438.700438 lmp.py:744] 
DEBUG 01-07 14:54:34.700438.700438 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.700877.700877 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.700195.700195 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.700507.700507 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.700197.700197 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.700932.700932 lmp.py:749] 
DEBUG 01-07 14:54:34.700932.700932 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.700383.700383 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.700556.700556 lmp.py:767]   Expert 13 |     25 | CPU
DEBUG 01-07 14:54:34.700722.700722 lmp.py:767]   Expert  9 |     40 | CPU
DEBUG 01-07 14:54:34.700173.700173 lmp.py:767]   Expert 44 |     42 | CPU
DEBUG 01-07 14:54:34.700339.700339 lmp.py:767]   Expert 25 |     43 | CPU
DEBUG 01-07 14:54:34.700267.700267 lmp.py:767]   Expert 38 |     46 | CPU
DEBUG 01-07 14:54:34.700241.700241 lmp.py:767]   Expert 16 |     47 | CPU
DEBUG 01-07 14:54:34.700215.700215 lmp.py:767]   Expert  2 |     51 | CPU
DEBUG 01-07 14:54:34.700951.700951 lmp.py:767]   Expert 22 |     56 | CPU
DEBUG 01-07 14:54:34.700925.700925 lmp.py:767]   Expert 33 |     56 | CPU
DEBUG 01-07 14:54:34.700183.700183 lmp.py:767]   Expert 42 |     57 | CPU
DEBUG 01-07 14:54:34.700157.700157 lmp.py:767]   Expert  5 |     68 | CPU
DEBUG 01-07 14:54:34.700893.700893 lmp.py:767]   Expert 23 |     75 | CPU
DEBUG 01-07 14:54:34.700298.700298 lmp.py:767]   Expert 24 |     82 | CPU
DEBUG 01-07 14:54:34.700795.700795 lmp.py:767]   Expert 10 |     84 | CPU
DEBUG 01-07 14:54:34.700829.700829 lmp.py:767]   Expert 59 |    100 | CPU
DEBUG 01-07 14:54:34.700803.700803 lmp.py:767]   Expert 21 |    105 | CPU
DEBUG 01-07 14:54:34.700300.700300 lmp.py:767]   Expert 46 |    115 | CPU
DEBUG 01-07 14:54:34.700036.700036 lmp.py:767]   Expert 55 |    118 | CPU
DEBUG 01-07 14:54:34.700010.700010 lmp.py:767]   Expert 61 |    119 | CPU
DEBUG 01-07 14:54:34.700176.700176 lmp.py:767]   Expert 45 |    122 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700534.700534 lmp.py:767]   Expert 31 |    126 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700462.700462 lmp.py:767]   Expert 36 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700913.700913 lmp.py:767]   Expert  6 |    139 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700364.700364 lmp.py:767]   Expert 51 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700053.700053 lmp.py:767]   Expert 43 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700981.700981 lmp.py:767]   Expert  8 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700531.700531 lmp.py:767]   Expert  3 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700234.700234 lmp.py:767]   Expert  0 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700268.700268 lmp.py:767]   Expert 18 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700063.700063 lmp.py:767]   Expert 48 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700336.700336 lmp.py:767]   Expert 26 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700323.700323 lmp.py:767]   Expert 41 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700072.700072 lmp.py:767]   Expert 12 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700345.700345 lmp.py:767]   Expert  7 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700571.700571 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700274.700274 lmp.py:767]   Expert 56 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700553.700553 lmp.py:767]   Expert 28 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700587.700587 lmp.py:767]   Expert 27 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700515.700515 lmp.py:767]   Expert 34 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700204.700204 lmp.py:767]   Expert  1 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700370.700370 lmp.py:767]   Expert 47 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700821.700821 lmp.py:767]   Expert 11 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.700894.700894 lmp.py:767]   Expert 32 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.700253.700253 lmp.py:767]   Expert 40 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701134.701134 lmp.py:767]   Expert 49 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701254.701254 lmp.py:767]   Expert 53 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701897.701897 lmp.py:767]   Expert 63 |    238 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701301.701301 lmp.py:767]   Expert 29 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701706.701706 lmp.py:767]   Expert  4 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701349.701349 lmp.py:767]   Expert 15 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701469.701469 lmp.py:767]   Expert 50 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701112.701112 lmp.py:767]   Expert 30 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701993.701993 lmp.py:767]   Expert 35 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701398.701398 lmp.py:767]   Expert 14 |    276 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701802.701802 lmp.py:767]   Expert 37 |    301 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701445.701445 lmp.py:767]   Expert 52 |    340 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701850.701850 lmp.py:767]   Expert 17 |    363 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701254.701254 lmp.py:767]   Expert 54 |    376 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701613.701613 lmp.py:767]   Expert 39 |    388 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701494.701494 lmp.py:767]   Expert 57 |    417 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701898.701898 lmp.py:767]   Expert 60 |    456 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701303.701303 lmp.py:767]   Expert 62 |    461 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701708.701708 lmp.py:767]   Expert 19 |    543 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.701112.701112 lmp.py:767]   Expert 58 |    574 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.701086.701086 lmp.py:769] 
DEBUG 01-07 14:54:34.701086.701086 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.701968.701968 lmp.py:770]   CPU:   1329 tokens
DEBUG 01-07 14:54:34.701564.701564 lmp.py:774]   cuda:1:   5424 tokens (22 experts)
DEBUG 01-07 14:54:34.701969.701969 lmp.py:774]   cuda:2:   5535 tokens (23 experts)
DEBUG 01-07 14:54:34.701897.701897 lmp.py:775]   Total GPU:  10959 tokens
DEBUG 01-07 14:54:34.701347.701347 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.701347.701347 lmp.py:776] 
DEBUG 01-07 14:54:34.701951.701951 cuda_h.py:19] end experts_map_get cost 0.0018455982208251953 seconds
DEBUG 01-07 14:54:34.701594.701594 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.701370.701370 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.701798.701798 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.701547.701547 cuda_h.py:19] end allocate_cuda_memory cost 0.00020503997802734375 seconds
INFO 01-07 14:54:34.701179.701179 client.py:127] Model loaded
DEBUG 01-07 14:54:34.702373.702373 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.702217.702217 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.702310.702310 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.702064.702064 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.702098.702098 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5ae9ec97-8c43-411e-94d9-988ab0f91df4
DEBUG 01-07 14:54:34.702918.702918 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.702771.702771 cuda_h.py:19] end restore2model cost 0.000640869140625 seconds
DEBUG 01-07 14:54:34.702362.702362 cuda_h.py:19] end sllm_worker_task cost 0.009961366653442383 seconds
INFO 01-07 14:54:34.703403.703403 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5ae9ec97-8c43-411e-94d9-988ab0f91df4
DEBUG 01-07 14:54:34.703101.703101 cuda_h.py:19] end load_into_gpu_async cost 0.001249551773071289 seconds
DEBUG 01-07 14:54:34.703896.703896 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.703891.703891 cuda_h.py:19] end restore_tensors2 cost 0.0002181529998779297 seconds
DEBUG 01-07 14:54:34.703323.703323 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021200180053710938 seconds
DEBUG 01-07 14:54:34.703125.703125 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.705300.705300 cuda_h.py:19] end restore2model cost 0.0020303726196289062 seconds
DEBUG 01-07 14:54:34.705409.705409 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.705796.705796 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.706031.706031 cuda_h.py:19] end allocate_cuda_memory cost 0.00024390220642089844 seconds
DEBUG 01-07 14:54:34.706397.706397 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.706961.706961 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.706432.706432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.706128.706128 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1accab46-a546-45ce-b494-4451f6fdb8e9
DEBUG 01-07 14:54:34.706418.706418 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.707834.707834 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1accab46-a546-45ce-b494-4451f6fdb8e9
DEBUG 01-07 14:54:34.707564.707564 cuda_h.py:19] end load_into_gpu_async cost 0.001004934310913086 seconds
DEBUG 01-07 14:54:34.707406.707406 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.707566.707566 cuda_h.py:19] end restore_tensors2 cost 0.00019979476928710938 seconds
DEBUG 01-07 14:54:34.707474.707474 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017414093017578125 seconds
DEBUG 01-07 14:54:34.707131.707131 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.709517.709517 cuda_h.py:19] end restore2model cost 0.0020112991333007812 seconds
DEBUG 01-07 14:54:34.709546.709546 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008229255676269531 seconds
DEBUG 01-07 14:54:34.709626.709626 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.709443.709443 lmp.py:816] 
DEBUG 01-07 14:54:34.709443.709443 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.709094.709094 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-07 14:54:34.709982.709982 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.720629.720629 mlpmodule.py:749] group tensors cost 0.010354280471801758 s
DEBUG 01-07 14:54:34.724360.724360 mlpmodule.py:787] pad cost 0.002712249755859375 s
DEBUG 01-07 14:54:34.724860.724860 mlpmodule.py:793] create cpu tensor cost 9.512901306152344e-05 s
DEBUG 01-07 14:54:34.724839.724839 mlpmodule.py:798] move to cpu cost 7.748603820800781e-05 s
DEBUG 01-07 14:54:34.732233.732233 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.732852.732852 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.732464.732464 mlpmodule.py:818] group_w3 first element: -0.02734375
WARNING 01-07 14:54:34.732952.732952 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.744578.744578 mlpmodule.py:838] group einsum cost 0.020203590393066406 s
DEBUG 01-07 14:54:34.745852.745852 mlpmodule.py:846] cpy2cputensor cost 0.0004181861877441406 s
DEBUG 01-07 14:54:34.748586.748586 cuda_h.py:19] end wait_cetm_experts cost 0.03831887245178223 seconds
DEBUG 01-07 14:54:34.748117.748117 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.749846.749846 cuda_h.py:19] end gpu_sexperts cost 0.0008897781372070312 seconds
DEBUG 01-07 14:54:34.749261.749261 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.749636.749636 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.291534423828125e-05 seconds
DEBUG 01-07 14:54:34.749831.749831 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.749986.749986 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5ae9ec97-8c43-411e-94d9-988ab0f91df4
INFO 01-07 14:54:34.750020.750020 client.py:127] Model loaded
INFO 01-07 14:54:34.751122.751122 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1accab46-a546-45ce-b494-4451f6fdb8e9
INFO 01-07 14:54:34.751493.751493 client.py:127] Model loaded
DEBUG 01-07 14:54:34.751906.751906 cuda_h.py:19] end wait_experts_multi_device cost 0.0015690326690673828 seconds
DEBUG 01-07 14:54:34.751092.751092 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.751398.751398 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.752221.752221 mlpmodule.py:533] gpu group tensors cost 0.0005364418029785156 s
DEBUG 01-07 14:54:34.754798.754798 mlpmodule.py:566] gpu pad cost 0.0013427734375 s
DEBUG 01-07 14:54:34.754832.754832 mlpmodule.py:584] gpu group einsum cost 0.0005443096160888672 s
DEBUG 01-07 14:54:34.756432.756432 mlpmodule.py:656] gpu experts func einsum cost 0.0046613216400146484 s
DEBUG 01-07 14:54:34.757020.757020 mlpmodule.py:707]  experts func einsum cost 0.04700040817260742 s
DEBUG 01-07 14:54:34.757729.757729 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.758445.758445 mlpmodule.py:533] gpu group tensors cost 0.00043320655822753906 s
DEBUG 01-07 14:54:34.759216.759216 mlpmodule.py:566] gpu pad cost 0.0012123584747314453 s
DEBUG 01-07 14:54:34.759259.759259 mlpmodule.py:584] gpu group einsum cost 0.0004253387451171875 s
DEBUG 01-07 14:54:34.761643.761643 mlpmodule.py:656] gpu experts func einsum cost 0.003988027572631836 s
DEBUG 01-07 14:54:34.761448.761448 cuda_h.py:19] end gpu_experts_multi_device cost 0.01020503044128418 seconds
DEBUG 01-07 14:54:34.761457.761457 cuda_h.py:19] end layer_moe_generate_multi_device_25 cost 0.06303620338439941 seconds
DEBUG 01-07 14:54:34.762670.762670 lmp.py:194] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-07 14:54:34.762923.762923 lmp.py:153] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-07 14:54:34.762666.762666 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 14:54:34.762753.762753 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 14:54:34.762973.762973 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.147125244140625e-05 seconds
DEBUG 01-07 14:54:34.762484.762484 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.0558319091796875e-05 seconds
DEBUG 01-07 14:54:34.762842.762842 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.762202.762202 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.762859.762859 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:34.762975.762975 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.762427.762427 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.762127.762127 cuda_h.py:19] end allocate_cuda_memory cost 0.0003039836883544922 seconds
DEBUG 01-07 14:54:34.762666.762666 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.763475.763475 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.763344.763344 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.763094.763094 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 480bcbf4-df6a-4c12-9f02-6b2da3054408
DEBUG 01-07 14:54:34.763626.763626 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:34.763714.763714 cuda_h.py:10] start self_attn
INFO 01-07 14:54:34.763530.763530 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 480bcbf4-df6a-4c12-9f02-6b2da3054408
DEBUG 01-07 14:54:34.763619.763619 cuda_h.py:19] end load_into_gpu_async cost 0.0009124279022216797 seconds
DEBUG 01-07 14:54:34.763321.763321 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.764212.764212 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-07 14:54:34.764968.764968 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015418529510498047 seconds
INFO 01-07 14:54:34.764957.764957 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 480bcbf4-df6a-4c12-9f02-6b2da3054408
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.767555.767555 cuda_h.py:19] end self_attn cost 0.0037221908569335938 seconds
DEBUG 01-07 14:54:34.767122.767122 cuda_h.py:19] end iln_self_attn_paln cost 0.0051648616790771484 seconds
DEBUG 01-07 14:54:34.767998.767998 cuda_h.py:10] start layer_moe_generate_multi_device_26
DEBUG 01-07 14:54:34.767708.767708 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.768617.768617 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-07 14:54:34.768301.768301 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.768481.768481 lmp.py:744] 
DEBUG 01-07 14:54:34.768481.768481 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.768681.768681 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.768238.768238 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.768073.768073 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.768477.768477 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.768928.768928 lmp.py:749] 
DEBUG 01-07 14:54:34.768928.768928 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.768618.768618 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.768506.768506 lmp.py:767]   Expert 20 |     10 | CPU
DEBUG 01-07 14:54:34.768433.768433 lmp.py:767]   Expert 61 |     12 | CPU
DEBUG 01-07 14:54:34.768646.768646 lmp.py:767]   Expert 11 |     30 | CPU
DEBUG 01-07 14:54:34.768574.768574 lmp.py:767]   Expert  7 |     40 | CPU
DEBUG 01-07 14:54:34.768501.768501 lmp.py:767]   Expert 62 |     41 | CPU
DEBUG 01-07 14:54:34.768952.768952 lmp.py:767]   Expert 51 |     42 | CPU
DEBUG 01-07 14:54:34.768165.768165 lmp.py:767]   Expert  3 |     44 | CPU
DEBUG 01-07 14:54:34.768377.768377 lmp.py:767]   Expert 30 |     51 | CPU
DEBUG 01-07 14:54:34.769113.769113 lmp.py:767]   Expert 17 |     53 | CPU
DEBUG 01-07 14:54:34.769087.769087 lmp.py:767]   Expert 29 |     53 | CPU
DEBUG 01-07 14:54:34.769822.769822 lmp.py:767]   Expert  6 |     62 | CPU
DEBUG 01-07 14:54:34.769035.769035 lmp.py:767]   Expert  9 |     65 | CPU
DEBUG 01-07 14:54:34.769963.769963 lmp.py:767]   Expert 63 |     74 | CPU
DEBUG 01-07 14:54:34.769937.769937 lmp.py:767]   Expert 38 |     76 | CPU
DEBUG 01-07 14:54:34.769149.769149 lmp.py:767]   Expert 55 |     82 | CPU
DEBUG 01-07 14:54:34.769362.769362 lmp.py:767]   Expert 59 |     87 | CPU
DEBUG 01-07 14:54:34.769097.769097 lmp.py:767]   Expert  8 |     94 | CPU
DEBUG 01-07 14:54:34.769833.769833 lmp.py:767]   Expert 48 |     94 | CPU
DEBUG 01-07 14:54:34.769569.769569 lmp.py:767]   Expert 19 |     95 | CPU
DEBUG 01-07 14:54:34.769211.769211 lmp.py:767]   Expert 49 |    101 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769331.769331 lmp.py:767]   Expert 22 |    105 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769213.769213 lmp.py:767]   Expert 24 |    112 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769140.769140 lmp.py:767]   Expert 34 |    114 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769068.769068 lmp.py:767]   Expert 36 |    115 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769519.769519 lmp.py:767]   Expert 50 |    117 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769447.769447 lmp.py:767]   Expert 42 |    118 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769136.769136 lmp.py:767]   Expert 39 |    126 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769064.769064 lmp.py:767]   Expert  4 |    132 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769230.769230 lmp.py:767]   Expert 37 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769919.769919 lmp.py:767]   Expert 15 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769608.769608 lmp.py:767]   Expert 41 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769298.769298 lmp.py:767]   Expert 23 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769987.769987 lmp.py:767]   Expert 16 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769676.769676 lmp.py:767]   Expert 56 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769127.769127 lmp.py:767]   Expert 60 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769578.769578 lmp.py:767]   Expert 44 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769029.769029 lmp.py:767]   Expert  1 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769195.769195 lmp.py:767]   Expert 21 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769600.769600 lmp.py:767]   Expert 43 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769527.769527 lmp.py:767]   Expert 47 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769978.769978 lmp.py:767]   Expert 53 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769429.769429 lmp.py:767]   Expert 12 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769880.769880 lmp.py:767]   Expert 33 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769569.769569 lmp.py:767]   Expert 13 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769259.769259 lmp.py:767]   Expert 32 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769425.769425 lmp.py:767]   Expert 28 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769068.769068 lmp.py:767]   Expert  0 |    255 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769996.769996 lmp.py:767]   Expert 31 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769446.769446 lmp.py:767]   Expert 54 |    258 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769136.769136 lmp.py:767]   Expert 26 |    263 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769063.769063 lmp.py:767]   Expert 10 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769514.769514 lmp.py:767]   Expert 18 |    267 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769204.769204 lmp.py:767]   Expert 57 |    272 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769654.769654 lmp.py:767]   Expert  2 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769105.769105 lmp.py:767]   Expert 58 |    300 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769510.769510 lmp.py:767]   Expert 40 |    340 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769583.769583 lmp.py:767]   Expert 25 |    364 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769465.769465 lmp.py:767]   Expert 45 |    364 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769869.769869 lmp.py:767]   Expert  5 |    444 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769274.769274 lmp.py:767]   Expert 35 |    464 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769440.769440 lmp.py:767]   Expert 27 |    484 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769845.769845 lmp.py:767]   Expert 46 |    557 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769249.769249 lmp.py:767]   Expert 52 |    592 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.769131.769131 lmp.py:767]   Expert 14 |    885 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.769535.769535 lmp.py:769] 
DEBUG 01-07 14:54:34.769535.769535 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.769463.769463 lmp.py:770]   CPU:   1105 tokens
DEBUG 01-07 14:54:34.769344.769344 lmp.py:774]   cuda:1:   5579 tokens (22 experts)
DEBUG 01-07 14:54:34.770510.770510 lmp.py:774]   cuda:2:   5604 tokens (23 experts)
DEBUG 01-07 14:54:34.770438.770438 lmp.py:775]   Total GPU:  11183 tokens
DEBUG 01-07 14:54:34.770366.770366 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.770366.770366 lmp.py:776] 
DEBUG 01-07 14:54:34.770492.770492 cuda_h.py:19] end experts_map_get cost 0.0017287731170654297 seconds
DEBUG 01-07 14:54:34.770089.770089 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.770958.770958 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.770339.770339 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.770367.770367 cuda_h.py:19] end allocate_cuda_memory cost 0.00019931793212890625 seconds
DEBUG 01-07 14:54:34.770124.770124 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.770641.770641 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.770927.770927 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.770816.770816 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3200aca-8023-4c2c-9162-37c4660a369c
DEBUG 01-07 14:54:34.770052.770052 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.770772.770772 client.py:127] Model loaded
DEBUG 01-07 14:54:34.770039.770039 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.771974.771974 cuda_h.py:19] end restore2model cost 0.0004038810729980469 seconds
DEBUG 01-07 14:54:34.771850.771850 cuda_h.py:19] end sllm_worker_task cost 0.008937358856201172 seconds
INFO 01-07 14:54:34.771727.771727 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3200aca-8023-4c2c-9162-37c4660a369c
DEBUG 01-07 14:54:34.771709.771709 cuda_h.py:19] end load_into_gpu_async cost 0.0010304450988769531 seconds
DEBUG 01-07 14:54:34.771789.771789 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.771956.771956 cuda_h.py:19] end restore_tensors2 cost 0.00020551681518554688 seconds
DEBUG 01-07 14:54:34.771434.771434 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001733541488647461 seconds
DEBUG 01-07 14:54:34.771521.771521 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.773067.773067 cuda_h.py:19] end restore2model cost 0.0018491744995117188 seconds
DEBUG 01-07 14:54:34.773785.773785 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.773636.773636 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.774221.774221 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-07 14:54:34.774534.774534 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.774144.774144 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.774854.774854 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.774312.774312 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df80c103-b184-44a7-b620-eba46ef1b901
DEBUG 01-07 14:54:34.774866.774866 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.775558.775558 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df80c103-b184-44a7-b620-eba46ef1b901
DEBUG 01-07 14:54:34.775765.775765 cuda_h.py:19] end load_into_gpu_async cost 0.0011224746704101562 seconds
DEBUG 01-07 14:54:34.775607.775607 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.775097.775097 cuda_h.py:19] end restore_tensors2 cost 0.00019741058349609375 seconds
DEBUG 01-07 14:54:34.775768.775768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018200874328613281 seconds
DEBUG 01-07 14:54:34.775139.775139 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.777264.777264 cuda_h.py:19] end restore2model cost 0.0019235610961914062 seconds
DEBUG 01-07 14:54:34.777478.777478 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076389312744140625 seconds
DEBUG 01-07 14:54:34.777320.777320 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.777660.777660 lmp.py:816] 
DEBUG 01-07 14:54:34.777660.777660 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.777073.777073 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-07 14:54:34.777961.777961 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.788085.788085 mlpmodule.py:749] group tensors cost 0.00995635986328125 s
DEBUG 01-07 14:54:34.790112.790112 mlpmodule.py:787] pad cost 0.0018489360809326172 s
DEBUG 01-07 14:54:34.790899.790899 mlpmodule.py:793] create cpu tensor cost 6.67572021484375e-05 s
DEBUG 01-07 14:54:34.791002.791002 mlpmodule.py:798] move to cpu cost 4.76837158203125e-05 s
DEBUG 01-07 14:54:34.798512.798512 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.799169.799169 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.799157.799157 mlpmodule.py:818] group_w3 first element: -0.0024261474609375
WARNING 01-07 14:54:34.799344.799344 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.814651.814651 mlpmodule.py:838] group einsum cost 0.023847579956054688 s
DEBUG 01-07 14:54:34.815177.815177 mlpmodule.py:846] cpy2cputensor cost 0.00030541419982910156 s
DEBUG 01-07 14:54:34.818419.818419 cuda_h.py:19] end wait_cetm_experts cost 0.04014945030212402 seconds
DEBUG 01-07 14:54:34.818349.818349 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.818440.818440 cuda_h.py:19] end gpu_sexperts cost 0.0004818439483642578 seconds
DEBUG 01-07 14:54:34.818852.818852 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.818272.818272 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-07 14:54:34.818551.818551 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.818452.818452 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3200aca-8023-4c2c-9162-37c4660a369c
INFO 01-07 14:54:34.819183.819183 client.py:127] Model loaded
INFO 01-07 14:54:34.819966.819966 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df80c103-b184-44a7-b620-eba46ef1b901
INFO 01-07 14:54:34.820416.820416 client.py:127] Model loaded
DEBUG 01-07 14:54:34.820907.820907 cuda_h.py:19] end wait_experts_multi_device cost 0.0013201236724853516 seconds
DEBUG 01-07 14:54:34.820517.820517 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.820241.820241 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.821550.821550 mlpmodule.py:533] gpu group tensors cost 0.0004711151123046875 s
DEBUG 01-07 14:54:34.822827.822827 mlpmodule.py:566] gpu pad cost 0.0012655258178710938 s
DEBUG 01-07 14:54:34.823809.823809 mlpmodule.py:584] gpu group einsum cost 0.0005857944488525391 s
DEBUG 01-07 14:54:34.825257.825257 mlpmodule.py:707]  experts func einsum cost 0.04738807678222656 s
DEBUG 01-07 14:54:34.825134.825134 mlpmodule.py:656] gpu experts func einsum cost 0.00465703010559082 s
DEBUG 01-07 14:54:34.825159.825159 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.826408.826408 mlpmodule.py:533] gpu group tensors cost 0.00043010711669921875 s
DEBUG 01-07 14:54:34.827688.827688 mlpmodule.py:566] gpu pad cost 0.0012042522430419922 s
DEBUG 01-07 14:54:34.828016.828016 mlpmodule.py:584] gpu group einsum cost 0.0008077621459960938 s
DEBUG 01-07 14:54:34.830425.830425 mlpmodule.py:656] gpu experts func einsum cost 0.0045166015625 s
DEBUG 01-07 14:54:34.830448.830448 cuda_h.py:19] end gpu_experts_multi_device cost 0.01055908203125 seconds
DEBUG 01-07 14:54:34.830047.830047 cuda_h.py:19] end layer_moe_generate_multi_device_26 cost 0.06334948539733887 seconds
DEBUG 01-07 14:54:34.831326.831326 lmp.py:194] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-07 14:54:34.831373.831373 lmp.py:153] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-07 14:54:34.831831.831831 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-07 14:54:34.831024.831024 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.1444091796875e-05 seconds
DEBUG 01-07 14:54:34.831813.831813 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:34.831954.831954 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:34.831010.831010 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:34.834515.834515 cuda_h.py:19] end self_attn cost 0.0025687217712402344 seconds
DEBUG 01-07 14:54:34.834048.834048 cuda_h.py:19] end iln_self_attn_paln cost 0.003236055374145508 seconds
DEBUG 01-07 14:54:34.834394.834394 cuda_h.py:10] start layer_moe_generate_multi_device_27
DEBUG 01-07 14:54:34.834196.834196 cuda_h.py:10] start gate
DEBUG 01-07 14:54:34.835873.835873 cuda_h.py:19] end gate cost 0.0006084442138671875 seconds
DEBUG 01-07 14:54:34.835272.835272 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:34.835591.835591 lmp.py:744] 
DEBUG 01-07 14:54:34.835591.835591 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:34.835823.835823 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:34.835049.835049 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:34.835553.835553 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:34.835673.835673 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:34.835078.835078 lmp.py:749] 
DEBUG 01-07 14:54:34.835078.835078 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:34.835436.835436 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:34.835039.835039 lmp.py:767]   Expert 18 |     68 | CPU
DEBUG 01-07 14:54:34.835206.835206 lmp.py:767]   Expert 47 |     69 | CPU
DEBUG 01-07 14:54:34.835895.835895 lmp.py:767]   Expert 54 |     71 | CPU
DEBUG 01-07 14:54:34.835584.835584 lmp.py:767]   Expert 23 |     77 | CPU
DEBUG 01-07 14:54:34.835558.835558 lmp.py:767]   Expert 48 |     81 | CPU
DEBUG 01-07 14:54:34.835771.835771 lmp.py:767]   Expert 44 |     85 | CPU
DEBUG 01-07 14:54:34.835983.835983 lmp.py:767]   Expert 45 |     86 | CPU
DEBUG 01-07 14:54:34.835719.835719 lmp.py:767]   Expert 20 |     92 | CPU
DEBUG 01-07 14:54:34.835170.835170 lmp.py:767]   Expert 31 |     96 | CPU
DEBUG 01-07 14:54:34.835336.835336 lmp.py:767]   Expert 36 |    108 | CPU
DEBUG 01-07 14:54:34.836740.836740 lmp.py:767]   Expert 61 |    117 | CPU
DEBUG 01-07 14:54:34.836529.836529 lmp.py:767]   Expert 33 |    119 | CPU
DEBUG 01-07 14:54:34.836503.836503 lmp.py:767]   Expert 42 |    119 | CPU
DEBUG 01-07 14:54:34.836477.836477 lmp.py:767]   Expert 10 |    120 | CPU
DEBUG 01-07 14:54:34.836451.836451 lmp.py:767]   Expert 43 |    122 | CPU
DEBUG 01-07 14:54:34.836425.836425 lmp.py:767]   Expert 24 |    123 | CPU
DEBUG 01-07 14:54:34.836399.836399 lmp.py:767]   Expert 11 |    124 | CPU
DEBUG 01-07 14:54:34.836897.836897 lmp.py:767]   Expert 49 |    126 | CPU
DEBUG 01-07 14:54:34.836871.836871 lmp.py:767]   Expert 56 |    128 | CPU
DEBUG 01-07 14:54:34.836275.836275 lmp.py:767]   Expert  6 |    139 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836680.836680 lmp.py:767]   Expert 51 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836846.836846 lmp.py:767]   Expert  0 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836727.836727 lmp.py:767]   Expert 17 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836470.836470 lmp.py:767]   Expert 12 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836782.836782 lmp.py:767]   Expert 40 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836948.836948 lmp.py:767]   Expert  5 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836637.836637 lmp.py:767]   Expert 55 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836042.836042 lmp.py:767]   Expert 59 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836208.836208 lmp.py:767]   Expert 26 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836374.836374 lmp.py:767]   Expert 57 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836302.836302 lmp.py:767]   Expert 38 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836991.836991 lmp.py:767]   Expert 46 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836833.836833 lmp.py:767]   Expert 58 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836760.836760 lmp.py:767]   Expert 13 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836450.836450 lmp.py:767]   Expert 30 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836616.836616 lmp.py:767]   Expert 35 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836736.836736 lmp.py:767]   Expert 50 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836617.836617 lmp.py:767]   Expert  7 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836545.836545 lmp.py:767]   Expert 16 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836472.836472 lmp.py:767]   Expert 15 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836923.836923 lmp.py:767]   Expert 32 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836374.836374 lmp.py:767]   Expert 14 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836064.836064 lmp.py:767]   Expert  1 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836514.836514 lmp.py:767]   Expert  3 |    218 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836442.836442 lmp.py:767]   Expert  4 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836131.836131 lmp.py:767]   Expert 39 |    235 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836821.836821 lmp.py:767]   Expert 34 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836987.836987 lmp.py:767]   Expert 52 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836438.836438 lmp.py:767]   Expert 28 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836650.836650 lmp.py:767]   Expert 25 |    249 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836101.836101 lmp.py:767]   Expert 22 |    258 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836029.836029 lmp.py:767]   Expert  2 |    273 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836672.836672 lmp.py:767]   Expert 41 |    281 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836030.836030 lmp.py:767]   Expert 21 |    282 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836150.836150 lmp.py:767]   Expert 63 |    284 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836078.836078 lmp.py:767]   Expert 60 |    286 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836528.836528 lmp.py:767]   Expert 29 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836979.836979 lmp.py:767]   Expert 62 |    300 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836669.836669 lmp.py:767]   Expert 27 |    301 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836881.836881 lmp.py:767]   Expert 37 |    324 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836094.836094 lmp.py:767]   Expert 53 |    335 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836544.836544 lmp.py:767]   Expert  8 |    336 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836757.836757 lmp.py:767]   Expert 19 |    443 | GPU1(cuda:2)
DEBUG 01-07 14:54:34.836208.836208 lmp.py:767]   Expert  9 |    616 | GPU0(cuda:1)
DEBUG 01-07 14:54:34.836943.836943 lmp.py:769] 
DEBUG 01-07 14:54:34.836943.836943 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:34.836394.836394 lmp.py:770]   CPU:   1931 tokens
DEBUG 01-07 14:54:34.836514.836514 lmp.py:774]   cuda:1:   5139 tokens (22 experts)
DEBUG 01-07 14:54:34.836965.836965 lmp.py:774]   cuda:2:   5218 tokens (23 experts)
DEBUG 01-07 14:54:34.837038.837038 lmp.py:775]   Total GPU:  10357 tokens
DEBUG 01-07 14:54:34.837443.837443 lmp.py:776] ============================================================
DEBUG 01-07 14:54:34.837443.837443 lmp.py:776] 
DEBUG 01-07 14:54:34.837616.837616 cuda_h.py:19] end experts_map_get cost 0.0017349720001220703 seconds
DEBUG 01-07 14:54:34.837544.837544 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:34.837082.837082 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.837370.837370 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.837975.837975 cuda_h.py:19] end allocate_cuda_memory cost 0.00023865699768066406 seconds
DEBUG 01-07 14:54:34.837772.837772 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.837336.837336 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.837867.837867 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.837993.837993 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 325fa85f-90af-4fdb-91d3-196fd297c584
DEBUG 01-07 14:54:34.837528.837528 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.838082.838082 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 325fa85f-90af-4fdb-91d3-196fd297c584
DEBUG 01-07 14:54:34.838004.838004 cuda_h.py:19] end load_into_gpu_async cost 0.0011589527130126953 seconds
DEBUG 01-07 14:54:34.838561.838561 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.839609.839609 cuda_h.py:19] end restore_tensors2 cost 0.00022172927856445312 seconds
DEBUG 01-07 14:54:34.839610.839610 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019130706787109375 seconds
DEBUG 01-07 14:54:34.839889.839889 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.840588.840588 cuda_h.py:19] end restore2model cost 0.0018565654754638672 seconds
DEBUG 01-07 14:54:34.841352.841352 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:34.841157.841157 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:34.841913.841913 cuda_h.py:19] end allocate_cuda_memory cost 0.0002086162567138672 seconds
DEBUG 01-07 14:54:34.841511.841511 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:34.841836.841836 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:34.841884.841884 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:34.841203.841203 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5394144-aacf-417e-b3d4-e91b8593c130
DEBUG 01-07 14:54:34.841386.841386 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:34.842980.842980 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5394144-aacf-417e-b3d4-e91b8593c130
DEBUG 01-07 14:54:34.842187.842187 cuda_h.py:19] end load_into_gpu_async cost 0.001169443130493164 seconds
DEBUG 01-07 14:54:34.842552.842552 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:34.842659.842659 cuda_h.py:19] end restore_tensors2 cost 0.00019550323486328125 seconds
DEBUG 01-07 14:54:34.842614.842614 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018498897552490234 seconds
DEBUG 01-07 14:54:34.842032.842032 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:34.844790.844790 cuda_h.py:19] end restore2model cost 0.0018622875213623047 seconds
DEBUG 01-07 14:54:34.844905.844905 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007794380187988281 seconds
DEBUG 01-07 14:54:34.844270.844270 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:34.844848.844848 lmp.py:816] 
DEBUG 01-07 14:54:34.844848.844848 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:34.845638.845638 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-07 14:54:34.845288.845288 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:34.850786.850786 mlpmodule.py:749] group tensors cost 0.005439043045043945 s
DEBUG 01-07 14:54:34.852849.852849 mlpmodule.py:787] pad cost 0.0010318756103515625 s
DEBUG 01-07 14:54:34.852046.852046 mlpmodule.py:793] create cpu tensor cost 8.654594421386719e-05 s
DEBUG 01-07 14:54:34.852194.852194 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 14:54:34.863101.863101 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:34.863736.863736 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:34.863441.863441 mlpmodule.py:818] group_w3 first element: -0.01263427734375
WARNING 01-07 14:54:34.863704.863704 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:34.882577.882577 mlpmodule.py:838] group einsum cost 0.030157804489135742 s
DEBUG 01-07 14:54:34.883384.883384 mlpmodule.py:846] cpy2cputensor cost 0.0003871917724609375 s
DEBUG 01-07 14:54:34.885802.885802 cuda_h.py:19] end wait_cetm_experts cost 0.04082059860229492 seconds
DEBUG 01-07 14:54:34.885533.885533 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:34.886154.886154 cuda_h.py:19] end gpu_sexperts cost 0.0004868507385253906 seconds
DEBUG 01-07 14:54:34.886420.886420 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:34.886872.886872 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.0967254638671875e-05 seconds
DEBUG 01-07 14:54:34.886198.886198 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:34.886292.886292 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 325fa85f-90af-4fdb-91d3-196fd297c584
INFO 01-07 14:54:34.887360.887360 client.py:127] Model loaded
INFO 01-07 14:54:34.887475.887475 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5394144-aacf-417e-b3d4-e91b8593c130
INFO 01-07 14:54:34.887500.887500 client.py:127] Model loaded
DEBUG 01-07 14:54:34.888230.888230 cuda_h.py:19] end wait_experts_multi_device cost 0.0013263225555419922 seconds
DEBUG 01-07 14:54:34.888079.888079 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:34.888756.888756 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:34.889179.889179 mlpmodule.py:533] gpu group tensors cost 0.0004763603210449219 s
DEBUG 01-07 14:54:34.890573.890573 mlpmodule.py:566] gpu pad cost 0.0012471675872802734 s
DEBUG 01-07 14:54:34.891637.891637 mlpmodule.py:584] gpu group einsum cost 0.00044226646423339844 s
DEBUG 01-07 14:54:34.892065.892065 mlpmodule.py:656] gpu experts func einsum cost 0.00422215461730957 s
DEBUG 01-07 14:54:34.893843.893843 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:34.893940.893940 mlpmodule.py:707]  experts func einsum cost 0.04822802543640137 s
DEBUG 01-07 14:54:34.894951.894951 mlpmodule.py:533] gpu group tensors cost 0.00042510032653808594 s
DEBUG 01-07 14:54:34.895014.895014 mlpmodule.py:566] gpu pad cost 0.0012035369873046875 s
DEBUG 01-07 14:54:34.895461.895461 mlpmodule.py:584] gpu group einsum cost 0.0004401206970214844 s
DEBUG 01-07 14:54:34.897515.897515 mlpmodule.py:656] gpu experts func einsum cost 0.004213571548461914 s
DEBUG 01-07 14:54:34.898790.898790 cuda_h.py:19] end gpu_experts_multi_device cost 0.009940147399902344 seconds
DEBUG 01-07 14:54:34.898144.898144 cuda_h.py:19] end layer_moe_generate_multi_device_27 cost 0.06351637840270996 seconds
DEBUG 01-07 14:54:34.898232.898232 lmp.py:194] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-07 14:54:34.898730.898730 cuda_h.py:19] end prefill_layer cost 2.591285228729248 seconds
DEBUG 01-07 14:54:37.084048.084048 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09583854675292969 s
DEBUG 01-07 14:54:37.427406.427406 cuda_h.py:19] end generate_input_ids cost 0.34237074851989746 seconds
DEBUG 01-07 14:54:37.427563.427563 cuda_h.py:10] start init_cache
DEBUG 01-07 14:54:37.427090.427090 cuda_h.py:19] end init_cache cost 6.413459777832031e-05 seconds
DEBUG 01-07 14:54:39.877298.877298 cuda_h.py:10] start init_weights
DEBUG 01-07 14:54:39.878656.878656 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:39.879261.879261 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:39.880367.880367 cuda_h.py:19] end allocate_cuda_memory cost 0.001283407211303711 seconds
DEBUG 01-07 14:54:39.880477.880477 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:39.880710.880710 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:39.880771.880771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:39.880997.880997 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ccb78fa1-573a-499b-8616-193eea7820fd
DEBUG 01-07 14:54:39.880974.880974 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:39.882462.882462 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ccb78fa1-573a-499b-8616-193eea7820fd
DEBUG 01-07 14:54:39.882199.882199 cuda_h.py:19] end load_into_gpu_async cost 0.0013420581817626953 seconds
DEBUG 01-07 14:54:39.882994.882994 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:39.882050.882050 cuda_h.py:19] end restore_tensors2 cost 5.0067901611328125e-05 seconds
DEBUG 01-07 14:54:39.882706.882706 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032265186309814453 seconds
DEBUG 01-07 14:54:39.882641.882641 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:39.882846.882846 cuda_h.py:19] end restore2model cost 0.0001633167266845703 seconds
INFO 01-07 14:54:39.882794.882794 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ccb78fa1-573a-499b-8616-193eea7820fd
INFO 01-07 14:54:39.961461.961461 client.py:127] Model loaded
DEBUG 01-07 14:54:39.961267.961267 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-07 14:54:39.961668.961668 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:39.961123.961123 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:39.962660.962660 cuda_h.py:19] end allocate_cuda_memory cost 0.00034165382385253906 seconds
DEBUG 01-07 14:54:39.962989.962989 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:39.962005.962005 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:39.962995.962995 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:39.962375.962375 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7b4f2b8-c0a1-4218-8268-41478fb67861
DEBUG 01-07 14:54:39.962076.962076 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:39.964032.964032 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7b4f2b8-c0a1-4218-8268-41478fb67861
DEBUG 01-07 14:54:39.964764.964764 cuda_h.py:19] end load_into_gpu_async cost 0.0018894672393798828 seconds
DEBUG 01-07 14:54:39.964574.964574 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:39.964589.964589 cuda_h.py:19] end restore_tensors2 cost 0.0001304149627685547 seconds
DEBUG 01-07 14:54:39.964989.964989 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029675960540771484 seconds
INFO 01-07 14:54:39.964130.964130 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7b4f2b8-c0a1-4218-8268-41478fb67861
INFO 01-07 14:54:39.979884.979884 client.py:127] Model loaded
DEBUG 01-07 14:54:39.980067.980067 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:39.981857.981857 cuda_h.py:19] end restore2model cost 0.0009372234344482422 seconds
DEBUG 01-07 14:54:39.981418.981418 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.019649028778076172 seconds
DEBUG 01-07 14:54:39.981202.981202 cuda_h.py:19] end init_weights cost 0.10295605659484863 seconds
DEBUG 01-07 14:54:39.981675.981675 cuda_h.py:10] start copy_emodel
DEBUG 01-07 14:54:40.747304.747304 cuda_h.py:19] end copy_emodel cost 0.7655274868011475 seconds
DEBUG 01-07 14:54:40.747505.747505 cuda_h.py:10] start init_hmv
DEBUG 01-07 14:54:40.892136.892136 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-07 14:54:40.893994.893994 cuda_h.py:19] end init_hmv cost 0.1458740234375 seconds
DEBUG 01-07 14:54:40.893631.893631 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-07 14:54:40.894795.894795 cuda_h.py:19] end init_inputs_tokens cost 0.0003018379211425781 seconds
DEBUG 01-07 14:54:40.894372.894372 cuda_h.py:10] start prefill_layer
DEBUG 01-07 14:54:40.894255.894255 lmp.py:153] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-07 14:54:40.894951.894951 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 14:54:40.894654.894654 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 14:54:40.894080.894080 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.8623809814453125e-05 seconds
DEBUG 01-07 14:54:40.894114.894114 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.224082946777344e-05 seconds
DEBUG 01-07 14:54:40.894949.894949 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:40.894077.894077 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:40.894285.894285 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:40.894939.894939 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.894187.894187 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.895234.895234 cuda_h.py:19] end allocate_cuda_memory cost 0.00037407875061035156 seconds
DEBUG 01-07 14:54:40.895032.895032 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.895332.895332 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.895890.895890 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.895414.895414 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97504c8e-bad7-44b0-81e4-3c8635fe80a5
DEBUG 01-07 14:54:40.895876.895876 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:40.895132.895132 cuda_h.py:10] start self_attn
INFO 01-07 14:54:40.897866.897866 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97504c8e-bad7-44b0-81e4-3c8635fe80a5
DEBUG 01-07 14:54:40.897644.897644 cuda_h.py:19] end load_into_gpu_async cost 0.0018086433410644531 seconds
DEBUG 01-07 14:54:40.897883.897883 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.897331.897331 cuda_h.py:19] end restore_tensors2 cost 8.344650268554688e-05 seconds
DEBUG 01-07 14:54:40.897909.897909 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026001930236816406 seconds
INFO 01-07 14:54:40.897566.897566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97504c8e-bad7-44b0-81e4-3c8635fe80a5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:40.899606.899606 cuda_h.py:19] end self_attn cost 0.0036225318908691406 seconds
DEBUG 01-07 14:54:40.899372.899372 cuda_h.py:19] end iln_self_attn_paln cost 0.0054779052734375 seconds
DEBUG 01-07 14:54:40.900009.900009 cuda_h.py:10] start dense_mlp
INFO 01-07 14:54:40.905477.905477 client.py:127] Model loaded
DEBUG 01-07 14:54:40.905856.905856 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:40.905386.905386 cuda_h.py:19] end restore2model cost 0.0005505084991455078 seconds
DEBUG 01-07 14:54:40.906713.906713 cuda_h.py:19] end sllm_worker_task cost 0.011250972747802734 seconds
DEBUG 01-07 14:54:40.906590.906590 cuda_h.py:19] end dense_mlp cost 0.0060422420501708984 seconds
DEBUG 01-07 14:54:40.906534.906534 lmp.py:194] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-07 14:54:40.906204.906204 lmp.py:153] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-07 14:54:40.906900.906900 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 14:54:40.906702.906702 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 14:54:40.906101.906101 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.2172927856445312e-05 seconds
DEBUG 01-07 14:54:40.906281.906281 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.245208740234375e-05 seconds
DEBUG 01-07 14:54:40.906831.906831 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:40.906522.906522 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:40.906881.906881 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:40.906632.906632 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.906217.906217 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.906517.906517 cuda_h.py:19] end allocate_cuda_memory cost 0.00020313262939453125 seconds
DEBUG 01-07 14:54:40.906084.906084 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.907040.907040 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.907982.907982 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.907182.907182 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b97be6c4-2f9e-4b66-8f96-0586fc463348
DEBUG 01-07 14:54:40.907438.907438 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:40.907960.907960 cuda_h.py:10] start self_attn
INFO 01-07 14:54:40.908925.908925 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b97be6c4-2f9e-4b66-8f96-0586fc463348
DEBUG 01-07 14:54:40.908855.908855 cuda_h.py:19] end load_into_gpu_async cost 0.0016162395477294922 seconds
DEBUG 01-07 14:54:40.908201.908201 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.908385.908385 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-07 14:54:40.908804.908804 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023207664489746094 seconds
INFO 01-07 14:54:40.908707.908707 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b97be6c4-2f9e-4b66-8f96-0586fc463348
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:40.910608.910608 cuda_h.py:19] end self_attn cost 0.0028734207153320312 seconds
DEBUG 01-07 14:54:40.910710.910710 cuda_h.py:19] end iln_self_attn_paln cost 0.004270792007446289 seconds
DEBUG 01-07 14:54:40.910255.910255 cuda_h.py:10] start layer_moe_generate_multi_device_1
DEBUG 01-07 14:54:40.910157.910157 cuda_h.py:10] start gate
DEBUG 01-07 14:54:40.911918.911918 cuda_h.py:19] end gate cost 0.0007388591766357422 seconds
DEBUG 01-07 14:54:40.911317.911317 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:40.911209.911209 lmp.py:744] 
DEBUG 01-07 14:54:40.911209.911209 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:40.911826.911826 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:40.911337.911337 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:40.911172.911172 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:40.912100.912100 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:40.912835.912835 lmp.py:749] 
DEBUG 01-07 14:54:40.912835.912835 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:40.912525.912525 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:40.912367.912367 lmp.py:767]   Expert 25 |     64 | CPU
DEBUG 01-07 14:54:40.912294.912294 lmp.py:767]   Expert 54 |     67 | CPU
DEBUG 01-07 14:54:40.912268.912268 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 14:54:40.912481.912481 lmp.py:767]   Expert 31 |     72 | CPU
DEBUG 01-07 14:54:40.912693.912693 lmp.py:767]   Expert 55 |     72 | CPU
DEBUG 01-07 14:54:40.912667.912667 lmp.py:767]   Expert 62 |     87 | CPU
DEBUG 01-07 14:54:40.912641.912641 lmp.py:767]   Expert 18 |     88 | CPU
DEBUG 01-07 14:54:40.912807.912807 lmp.py:767]   Expert 52 |     98 | CPU
DEBUG 01-07 14:54:40.912258.912258 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 14:54:40.912994.912994 lmp.py:767]   Expert 47 |    104 | CPU
DEBUG 01-07 14:54:40.912398.912398 lmp.py:767]   Expert  0 |    113 | CPU
DEBUG 01-07 14:54:40.912611.912611 lmp.py:767]   Expert 37 |    117 | CPU
DEBUG 01-07 14:54:40.912108.912108 lmp.py:767]   Expert 27 |    121 | CPU
DEBUG 01-07 14:54:40.912844.912844 lmp.py:767]   Expert 32 |    123 | CPU
DEBUG 01-07 14:54:40.912818.912818 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 14:54:40.912792.912792 lmp.py:767]   Expert 44 |    131 | CPU
DEBUG 01-07 14:54:40.912527.912527 lmp.py:767]   Expert 28 |    136 | CPU
DEBUG 01-07 14:54:40.912025.912025 lmp.py:767]   Expert 13 |    138 | CPU
DEBUG 01-07 14:54:40.912906.912906 lmp.py:767]   Expert 58 |    140 | CPU
DEBUG 01-07 14:54:40.912026.912026 lmp.py:767]   Expert 60 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912113.912113 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912233.912233 lmp.py:767]   Expert  1 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912267.912267 lmp.py:767]   Expert 38 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912579.912579 lmp.py:767]   Expert 49 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912652.912652 lmp.py:767]   Expert 51 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912726.912726 lmp.py:767]   Expert 34 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912084.912084 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912727.912727 lmp.py:767]   Expert 36 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912847.912847 lmp.py:767]   Expert 11 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912966.912966 lmp.py:767]   Expert 17 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912086.912086 lmp.py:767]   Expert 59 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912968.912968 lmp.py:767]   Expert 10 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912611.912611 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912730.912730 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912373.912373 lmp.py:767]   Expert 39 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912016.912016 lmp.py:767]   Expert 33 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912898.912898 lmp.py:767]   Expert 12 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912541.912541 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912422.912422 lmp.py:767]   Expert 48 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912257.912257 lmp.py:767]   Expert 15 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912092.912092 lmp.py:767]   Expert 53 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912404.912404 lmp.py:767]   Expert 19 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912524.912524 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912929.912929 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912810.912810 lmp.py:767]   Expert 45 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912453.912453 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912096.912096 lmp.py:767]   Expert  4 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912977.912977 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912859.912859 lmp.py:767]   Expert 42 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912263.912263 lmp.py:767]   Expert 50 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912906.912906 lmp.py:767]   Expert 29 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.912311.912311 lmp.py:767]   Expert 56 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.912431.912431 lmp.py:767]   Expert 61 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.913504.913504 lmp.py:767]   Expert  8 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.913339.913339 lmp.py:767]   Expert 63 |    285 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.913459.913459 lmp.py:767]   Expert 46 |    294 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.913102.913102 lmp.py:767]   Expert  9 |    300 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.913506.913506 lmp.py:767]   Expert  6 |    316 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.913149.913149 lmp.py:767]   Expert 16 |    316 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.913792.913792 lmp.py:767]   Expert 40 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.913674.913674 lmp.py:767]   Expert  7 |    322 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.913078.913078 lmp.py:767]   Expert 23 |    325 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.913721.913721 lmp.py:767]   Expert 14 |    413 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.913603.913603 lmp.py:767]   Expert 57 |    464 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.913054.913054 lmp.py:769] 
DEBUG 01-07 14:54:40.913054.913054 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:40.913935.913935 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 14:54:40.913724.913724 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 14:54:40.913559.913559 lmp.py:774]   cuda:2:   5088 tokens (22 experts)
DEBUG 01-07 14:54:40.913155.913155 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 14:54:40.913083.913083 lmp.py:776] ============================================================
DEBUG 01-07 14:54:40.913083.913083 lmp.py:776] 
DEBUG 01-07 14:54:40.913971.913971 cuda_h.py:19] end experts_map_get cost 0.001718282699584961 seconds
DEBUG 01-07 14:54:40.913091.913091 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:40.913914.913914 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.913003.913003 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.914325.914325 cuda_h.py:19] end allocate_cuda_memory cost 0.001256704330444336 seconds
DEBUG 01-07 14:54:40.914260.914260 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.914586.914586 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.914826.914826 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.914522.914522 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e134564b-46aa-44dd-a6bf-8d259ffb1f0e
DEBUG 01-07 14:54:40.915725.915725 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:40.916384.916384 client.py:127] Model loaded
DEBUG 01-07 14:54:40.916798.916798 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:40.917255.917255 cuda_h.py:19] end restore2model cost 0.0007207393646240234 seconds
DEBUG 01-07 14:54:40.917085.917085 cuda_h.py:19] end sllm_worker_task cost 0.010970830917358398 seconds
INFO 01-07 14:54:40.917674.917674 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e134564b-46aa-44dd-a6bf-8d259ffb1f0e
DEBUG 01-07 14:54:40.917331.917331 cuda_h.py:19] end load_into_gpu_async cost 0.0030736923217773438 seconds
DEBUG 01-07 14:54:40.917796.917796 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.918699.918699 cuda_h.py:19] end restore_tensors2 cost 0.00025391578674316406 seconds
DEBUG 01-07 14:54:40.918668.918668 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004887580871582031 seconds
DEBUG 01-07 14:54:40.918947.918947 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:40.920058.920058 cuda_h.py:19] end restore2model cost 0.00191497802734375 seconds
DEBUG 01-07 14:54:40.920067.920067 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.920210.920210 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.921434.921434 cuda_h.py:19] end allocate_cuda_memory cost 0.0005171298980712891 seconds
DEBUG 01-07 14:54:40.921985.921985 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.921596.921596 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.921352.921352 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.921763.921763 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3626675a-555d-4241-8055-1f19d509857e
DEBUG 01-07 14:54:40.921231.921231 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:40.922415.922415 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3626675a-555d-4241-8055-1f19d509857e
DEBUG 01-07 14:54:40.922390.922390 cuda_h.py:19] end load_into_gpu_async cost 0.0017774105072021484 seconds
DEBUG 01-07 14:54:40.922378.922378 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.923340.923340 cuda_h.py:19] end restore_tensors2 cost 0.00022673606872558594 seconds
DEBUG 01-07 14:54:40.923931.923931 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028204917907714844 seconds
DEBUG 01-07 14:54:40.923164.923164 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:40.925014.925014 cuda_h.py:19] end restore2model cost 0.001827239990234375 seconds
DEBUG 01-07 14:54:40.925924.925924 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.011791706085205078 seconds
DEBUG 01-07 14:54:40.925150.925150 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:40.925696.925696 lmp.py:816] 
DEBUG 01-07 14:54:40.925696.925696 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:40.925400.925400 cuda_h.py:19] end cpu_experts_submit cost 0.0001239776611328125 seconds
DEBUG 01-07 14:54:40.925527.925527 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:40.937605.937605 mlpmodule.py:749] group tensors cost 0.012004375457763672 s
DEBUG 01-07 14:54:40.939346.939346 mlpmodule.py:787] pad cost 0.0016055107116699219 s
DEBUG 01-07 14:54:40.940073.940073 mlpmodule.py:793] create cpu tensor cost 6.67572021484375e-05 s
DEBUG 01-07 14:54:40.940176.940176 mlpmodule.py:798] move to cpu cost 5.221366882324219e-05 s
DEBUG 01-07 14:54:40.951425.951425 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:40.951193.951193 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:40.951667.951667 mlpmodule.py:818] group_w3 first element: -0.0107421875
WARNING 01-07 14:54:40.951546.951546 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:40.967885.967885 mlpmodule.py:838] group einsum cost 0.027228355407714844 s
DEBUG 01-07 14:54:40.968175.968175 mlpmodule.py:846] cpy2cputensor cost 0.00039839744567871094 s
DEBUG 01-07 14:54:40.970029.970029 cuda_h.py:19] end wait_cetm_experts cost 0.04541158676147461 seconds
DEBUG 01-07 14:54:40.970535.970535 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:40.971209.971209 cuda_h.py:19] end gpu_sexperts cost 0.0004875659942626953 seconds
DEBUG 01-07 14:54:40.971674.971674 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:40.971663.971663 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 14:54:40.971127.971127 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:40.971029.971029 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e134564b-46aa-44dd-a6bf-8d259ffb1f0e
INFO 01-07 14:54:40.972636.972636 client.py:127] Model loaded
INFO 01-07 14:54:40.972518.972518 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3626675a-555d-4241-8055-1f19d509857e
INFO 01-07 14:54:40.972981.972981 client.py:127] Model loaded
DEBUG 01-07 14:54:40.973049.973049 cuda_h.py:19] end wait_experts_multi_device cost 0.0013854503631591797 seconds
DEBUG 01-07 14:54:40.973375.973375 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:40.973720.973720 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:40.975492.975492 mlpmodule.py:533] gpu group tensors cost 0.000888824462890625 s
DEBUG 01-07 14:54:40.976695.976695 mlpmodule.py:566] gpu pad cost 0.0014450550079345703 s
DEBUG 01-07 14:54:40.977129.977129 mlpmodule.py:707]  experts func einsum cost 0.05200695991516113 s
DEBUG 01-07 14:54:40.977556.977556 mlpmodule.py:584] gpu group einsum cost 0.0011248588562011719 s
DEBUG 01-07 14:54:40.979779.979779 mlpmodule.py:656] gpu experts func einsum cost 0.005493879318237305 s
DEBUG 01-07 14:54:40.980596.980596 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:40.981638.981638 mlpmodule.py:533] gpu group tensors cost 0.0009603500366210938 s
DEBUG 01-07 14:54:40.982199.982199 mlpmodule.py:566] gpu pad cost 0.001264810562133789 s
DEBUG 01-07 14:54:40.983509.983509 mlpmodule.py:584] gpu group einsum cost 0.0004858970642089844 s
DEBUG 01-07 14:54:40.984319.984319 mlpmodule.py:656] gpu experts func einsum cost 0.004484891891479492 s
DEBUG 01-07 14:54:40.984865.984865 cuda_h.py:19] end gpu_experts_multi_device cost 0.01184844970703125 seconds
DEBUG 01-07 14:54:40.984689.984689 cuda_h.py:19] end layer_moe_generate_multi_device_1 cost 0.07423615455627441 seconds
DEBUG 01-07 14:54:40.985691.985691 lmp.py:194] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-07 14:54:40.985944.985944 lmp.py:153] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-07 14:54:40.985686.985686 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 14:54:40.985489.985489 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 14:54:40.985894.985894 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 2.6464462280273438e-05 seconds
DEBUG 01-07 14:54:40.985405.985405 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 5.626678466796875e-05 seconds
DEBUG 01-07 14:54:40.985525.985525 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:40.985679.985679 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:40.985443.985443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.985703.985703 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.985809.985809 cuda_h.py:19] end allocate_cuda_memory cost 0.0001850128173828125 seconds
DEBUG 01-07 14:54:40.985964.985964 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:40.985840.985840 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.986678.986678 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.986368.986368 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.986025.986025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aea85173-7a4b-435e-9ce2-d89bd0b11529
DEBUG 01-07 14:54:40.986418.986418 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:40.986380.986380 cuda_h.py:10] start self_attn
INFO 01-07 14:54:40.986953.986953 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aea85173-7a4b-435e-9ce2-d89bd0b11529
DEBUG 01-07 14:54:40.986643.986643 cuda_h.py:19] end load_into_gpu_async cost 0.0009584426879882812 seconds
DEBUG 01-07 14:54:40.987916.987916 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.987283.987283 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-07 14:54:40.987993.987993 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001567840576171875 seconds
INFO 01-07 14:54:40.987968.987968 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aea85173-7a4b-435e-9ce2-d89bd0b11529
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:40.990163.990163 cuda_h.py:19] end self_attn cost 0.0037467479705810547 seconds
DEBUG 01-07 14:54:40.990047.990047 cuda_h.py:19] end iln_self_attn_paln cost 0.005097866058349609 seconds
DEBUG 01-07 14:54:40.990254.990254 cuda_h.py:10] start layer_moe_generate_multi_device_2
DEBUG 01-07 14:54:40.990679.990679 cuda_h.py:10] start gate
DEBUG 01-07 14:54:40.991563.991563 cuda_h.py:19] end gate cost 0.0006535053253173828 seconds
DEBUG 01-07 14:54:40.991485.991485 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:40.991903.991903 lmp.py:744] 
DEBUG 01-07 14:54:40.991903.991903 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:40.991997.991997 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:40.991415.991415 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:40.991965.991965 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:40.991608.991608 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:40.991536.991536 lmp.py:749] 
DEBUG 01-07 14:54:40.991536.991536 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:40.991941.991941 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:40.991306.991306 lmp.py:767]   Expert 58 |     50 | CPU
DEBUG 01-07 14:54:40.991995.991995 lmp.py:767]   Expert 27 |     56 | CPU
DEBUG 01-07 14:54:40.991208.991208 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 14:54:40.991420.991420 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 14:54:40.992394.992394 lmp.py:767]   Expert 24 |     86 | CPU
DEBUG 01-07 14:54:40.992368.992368 lmp.py:767]   Expert  0 |     88 | CPU
DEBUG 01-07 14:54:40.992342.992342 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 14:54:40.992316.992316 lmp.py:767]   Expert 34 |    116 | CPU
DEBUG 01-07 14:54:40.992052.992052 lmp.py:767]   Expert 51 |    118 | CPU
DEBUG 01-07 14:54:40.992503.992503 lmp.py:767]   Expert 32 |    120 | CPU
DEBUG 01-07 14:54:40.992954.992954 lmp.py:767]   Expert  9 |    130 | CPU
DEBUG 01-07 14:54:40.992451.992451 lmp.py:767]   Expert 15 |    134 | CPU
DEBUG 01-07 14:54:40.992425.992425 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 14:54:40.992160.992160 lmp.py:767]   Expert 23 |    136 | CPU
DEBUG 01-07 14:54:40.992373.992373 lmp.py:767]   Expert 26 |    138 | CPU
DEBUG 01-07 14:54:40.992632.992632 lmp.py:767]   Expert 30 |    144 | CPU
DEBUG 01-07 14:54:40.992844.992844 lmp.py:767]   Expert 45 |    146 | CPU
DEBUG 01-07 14:54:40.992818.992818 lmp.py:767]   Expert 62 |    147 | CPU
DEBUG 01-07 14:54:40.992315.992315 lmp.py:767]   Expert 57 |    150 | CPU
DEBUG 01-07 14:54:40.992958.992958 lmp.py:767]   Expert  1 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992032.992032 lmp.py:767]   Expert 36 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992152.992152 lmp.py:767]   Expert  8 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992271.992271 lmp.py:767]   Expert 29 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992438.992438 lmp.py:767]   Expert 25 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992127.992127 lmp.py:767]   Expert 54 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992055.992055 lmp.py:767]   Expert  6 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992982.992982 lmp.py:767]   Expert 49 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992155.992155 lmp.py:767]   Expert 48 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992798.992798 lmp.py:767]   Expert 12 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992726.992726 lmp.py:767]   Expert 35 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992892.992892 lmp.py:767]   Expert 37 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992581.992581 lmp.py:767]   Expert 60 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992224.992224 lmp.py:767]   Expert 13 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992106.992106 lmp.py:767]   Expert 53 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992272.992272 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992915.992915 lmp.py:767]   Expert 10 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992081.992081 lmp.py:767]   Expert 16 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992009.992009 lmp.py:767]   Expert 21 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992936.992936 lmp.py:767]   Expert 40 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992387.992387 lmp.py:767]   Expert 43 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992600.992600 lmp.py:767]   Expert 38 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992289.992289 lmp.py:767]   Expert  5 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992740.992740 lmp.py:767]   Expert 44 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992952.992952 lmp.py:767]   Expert 52 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992642.992642 lmp.py:767]   Expert 41 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992569.992569 lmp.py:767]   Expert 50 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992259.992259 lmp.py:767]   Expert 19 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992948.992948 lmp.py:767]   Expert  4 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992353.992353 lmp.py:767]   Expert 59 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992996.992996 lmp.py:767]   Expert 55 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992162.992162 lmp.py:767]   Expert 31 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992566.992566 lmp.py:767]   Expert 56 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992017.992017 lmp.py:767]   Expert 20 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992468.992468 lmp.py:767]   Expert 39 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992157.992157 lmp.py:767]   Expert 22 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992847.992847 lmp.py:767]   Expert  2 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992821.992821 lmp.py:767]   Expert 63 |    275 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992272.992272 lmp.py:767]   Expert 47 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992438.992438 lmp.py:767]   Expert 42 |    303 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992604.992604 lmp.py:767]   Expert 18 |    315 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992770.992770 lmp.py:767]   Expert 14 |    319 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.992175.992175 lmp.py:767]   Expert 46 |    367 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.992294.992294 lmp.py:767]   Expert 11 |    388 | GPU1(cuda:2)
DEBUG 01-07 14:54:40.993937.993937 lmp.py:767]   Expert 61 |    460 | GPU0(cuda:1)
DEBUG 01-07 14:54:40.993104.993104 lmp.py:769] 
DEBUG 01-07 14:54:40.993104.993104 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:40.993223.993223 lmp.py:770]   CPU:   2151 tokens
DEBUG 01-07 14:54:40.993582.993582 lmp.py:774]   cuda:1:   4994 tokens (22 experts)
DEBUG 01-07 14:54:40.993986.993986 lmp.py:774]   cuda:2:   5143 tokens (23 experts)
DEBUG 01-07 14:54:40.993437.993437 lmp.py:775]   Total GPU:  10137 tokens
DEBUG 01-07 14:54:40.993888.993888 lmp.py:776] ============================================================
DEBUG 01-07 14:54:40.993888.993888 lmp.py:776] 
DEBUG 01-07 14:54:40.993822.993822 cuda_h.py:19] end experts_map_get cost 0.0017306804656982422 seconds
DEBUG 01-07 14:54:40.993942.993942 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:40.993811.993811 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.993477.993477 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.993805.993805 cuda_h.py:19] end allocate_cuda_memory cost 0.0002808570861816406 seconds
DEBUG 01-07 14:54:40.993503.993503 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.993590.993590 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.993922.993922 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.993287.993287 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 23403fd3-9d79-4bb2-99c6-5d752a27477e
DEBUG 01-07 14:54:40.993127.993127 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:40.994969.994969 client.py:127] Model loaded
DEBUG 01-07 14:54:40.994289.994289 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:40.994053.994053 cuda_h.py:19] end restore2model cost 0.00041556358337402344 seconds
DEBUG 01-07 14:54:40.994359.994359 cuda_h.py:19] end sllm_worker_task cost 0.009178638458251953 seconds
INFO 01-07 14:54:40.994255.994255 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 23403fd3-9d79-4bb2-99c6-5d752a27477e
DEBUG 01-07 14:54:40.994854.994854 cuda_h.py:19] end load_into_gpu_async cost 0.0011739730834960938 seconds
DEBUG 01-07 14:54:40.994703.994703 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.995092.995092 cuda_h.py:19] end restore_tensors2 cost 0.0003311634063720703 seconds
DEBUG 01-07 14:54:40.995968.995968 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002093791961669922 seconds
DEBUG 01-07 14:54:40.995493.995493 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:40.997741.997741 cuda_h.py:19] end restore2model cost 0.0018401145935058594 seconds
DEBUG 01-07 14:54:40.997988.997988 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:40.997554.997554 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:40.997085.997085 cuda_h.py:19] end allocate_cuda_memory cost 0.00018262863159179688 seconds
DEBUG 01-07 14:54:40.997544.997544 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:40.997392.997392 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:40.997625.997625 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:40.997798.997798 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d3815a4d-2601-45e3-9c54-3f9663c3896b
DEBUG 01-07 14:54:40.997710.997710 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:40.998818.998818 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d3815a4d-2601-45e3-9c54-3f9663c3896b
DEBUG 01-07 14:54:40.998548.998548 cuda_h.py:19] end load_into_gpu_async cost 0.0010960102081298828 seconds
DEBUG 01-07 14:54:40.998390.998390 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:40.999175.999175 cuda_h.py:19] end restore_tensors2 cost 0.00027251243591308594 seconds
DEBUG 01-07 14:54:40.999574.999574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018434524536132812 seconds
DEBUG 01-07 14:54:40.999284.999284 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.001793.001793 cuda_h.py:19] end restore2model cost 0.0019273757934570312 seconds
DEBUG 01-07 14:54:41.001113.001113 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008039474487304688 seconds
DEBUG 01-07 14:54:41.001908.001908 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.001249.001249 lmp.py:816] 
DEBUG 01-07 14:54:41.001249.001249 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.001323.001323 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:41.001927.001927 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.005617.005617 mlpmodule.py:749] group tensors cost 0.004472255706787109 s
DEBUG 01-07 14:54:41.007382.007382 mlpmodule.py:787] pad cost 0.0012578964233398438 s
DEBUG 01-07 14:54:41.007751.007751 mlpmodule.py:793] create cpu tensor cost 5.888938903808594e-05 s
DEBUG 01-07 14:54:41.008449.008449 mlpmodule.py:798] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-07 14:54:41.019624.019624 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.019450.019450 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.019884.019884 mlpmodule.py:818] group_w3 first element: -0.0380859375
WARNING 01-07 14:54:41.019445.019445 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.035296.035296 mlpmodule.py:838] group einsum cost 0.027794361114501953 s
DEBUG 01-07 14:54:41.036594.036594 mlpmodule.py:846] cpy2cputensor cost 0.0004050731658935547 s
DEBUG 01-07 14:54:41.038545.038545 cuda_h.py:19] end wait_cetm_experts cost 0.03742384910583496 seconds
DEBUG 01-07 14:54:41.038184.038184 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.039506.039506 cuda_h.py:19] end gpu_sexperts cost 0.000476837158203125 seconds
DEBUG 01-07 14:54:41.039733.039733 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.039345.039345 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:41.039439.039439 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.039625.039625 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 23403fd3-9d79-4bb2-99c6-5d752a27477e
INFO 01-07 14:54:41.040827.040827 client.py:127] Model loaded
INFO 01-07 14:54:41.040994.040994 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d3815a4d-2601-45e3-9c54-3f9663c3896b
INFO 01-07 14:54:41.040212.040212 client.py:127] Model loaded
DEBUG 01-07 14:54:41.041902.041902 cuda_h.py:19] end wait_experts_multi_device cost 0.001363515853881836 seconds
DEBUG 01-07 14:54:41.041466.041466 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.041335.041335 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.045281.045281 mlpmodule.py:707]  experts func einsum cost 0.04430198669433594 s
DEBUG 01-07 14:54:41.046996.046996 mlpmodule.py:533] gpu group tensors cost 0.004414081573486328 s
DEBUG 01-07 14:54:41.047836.047836 mlpmodule.py:566] gpu pad cost 0.0012793540954589844 s
DEBUG 01-07 14:54:41.048918.048918 mlpmodule.py:584] gpu group einsum cost 0.0004239082336425781 s
DEBUG 01-07 14:54:41.049460.049460 mlpmodule.py:656] gpu experts func einsum cost 0.008203506469726562 s
DEBUG 01-07 14:54:41.050648.050648 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.050799.050799 mlpmodule.py:533] gpu group tensors cost 0.00045037269592285156 s
DEBUG 01-07 14:54:41.052207.052207 mlpmodule.py:566] gpu pad cost 0.0010533332824707031 s
DEBUG 01-07 14:54:41.052845.052845 mlpmodule.py:584] gpu group einsum cost 0.0005919933319091797 s
DEBUG 01-07 14:54:41.054170.054170 mlpmodule.py:656] gpu experts func einsum cost 0.003814220428466797 s
DEBUG 01-07 14:54:41.054093.054093 cuda_h.py:19] end gpu_experts_multi_device cost 0.013354063034057617 seconds
DEBUG 01-07 14:54:41.054507.054507 cuda_h.py:19] end layer_moe_generate_multi_device_2 cost 0.06388616561889648 seconds
DEBUG 01-07 14:54:41.054303.054303 lmp.py:194] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-07 14:54:41.054556.054556 lmp.py:153] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-07 14:54:41.054775.054775 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 14:54:41.054578.054578 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 14:54:41.054222.054222 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:41.054541.054541 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.698204040527344e-05 seconds
DEBUG 01-07 14:54:41.054137.054137 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.055543.055543 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.055247.055247 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.055296.055296 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.055125.055125 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.055837.055837 cuda_h.py:19] end allocate_cuda_memory cost 0.0002455711364746094 seconds
DEBUG 01-07 14:54:41.055952.055952 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.055761.055761 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.055346.055346 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.055856.055856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dcce91b6-938d-4e56-90f6-55aae4862a9b
DEBUG 01-07 14:54:41.055296.055296 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.055126.055126 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.056936.056936 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dcce91b6-938d-4e56-90f6-55aae4862a9b
DEBUG 01-07 14:54:41.056103.056103 cuda_h.py:19] end load_into_gpu_async cost 0.0009188652038574219 seconds
DEBUG 01-07 14:54:41.056614.056614 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.056975.056975 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-07 14:54:41.056777.056777 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014824867248535156 seconds
INFO 01-07 14:54:41.056083.056083 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dcce91b6-938d-4e56-90f6-55aae4862a9b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.059652.059652 cuda_h.py:19] end self_attn cost 0.003590822219848633 seconds
DEBUG 01-07 14:54:41.059682.059682 cuda_h.py:19] end iln_self_attn_paln cost 0.004973888397216797 seconds
DEBUG 01-07 14:54:41.059035.059035 cuda_h.py:10] start layer_moe_generate_multi_device_3
DEBUG 01-07 14:54:41.060460.060460 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.060244.060244 cuda_h.py:19] end gate cost 0.0006508827209472656 seconds
DEBUG 01-07 14:54:41.060643.060643 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.061121.061121 lmp.py:744] 
DEBUG 01-07 14:54:41.061121.061121 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.061738.061738 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.061057.061057 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.061561.061561 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.061396.061396 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.061800.061800 lmp.py:749] 
DEBUG 01-07 14:54:41.061800.061800 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.061920.061920 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.061524.061524 lmp.py:767]   Expert  1 |     50 | CPU
DEBUG 01-07 14:54:41.061643.061643 lmp.py:767]   Expert 27 |     62 | CPU
DEBUG 01-07 14:54:41.061286.061286 lmp.py:767]   Expert  7 |     75 | CPU
DEBUG 01-07 14:54:41.061214.061214 lmp.py:767]   Expert 48 |     82 | CPU
DEBUG 01-07 14:54:41.061380.061380 lmp.py:767]   Expert 15 |     98 | CPU
DEBUG 01-07 14:54:41.061262.061262 lmp.py:767]   Expert 30 |    110 | CPU
DEBUG 01-07 14:54:41.061666.061666 lmp.py:767]   Expert 32 |    117 | CPU
DEBUG 01-07 14:54:41.061832.061832 lmp.py:767]   Expert 61 |    117 | CPU
DEBUG 01-07 14:54:41.061237.061237 lmp.py:767]   Expert 45 |    118 | CPU
DEBUG 01-07 14:54:41.061641.061641 lmp.py:767]   Expert 18 |    119 | CPU
DEBUG 01-07 14:54:41.061569.061569 lmp.py:767]   Expert 34 |    133 | CPU
DEBUG 01-07 14:54:41.061020.061020 lmp.py:767]   Expert 39 |    134 | CPU
DEBUG 01-07 14:54:41.061471.061471 lmp.py:767]   Expert 36 |    138 | CPU
DEBUG 01-07 14:54:41.061160.061160 lmp.py:767]   Expert 11 |    139 | CPU
DEBUG 01-07 14:54:41.061850.061850 lmp.py:767]   Expert 26 |    139 | CPU
DEBUG 01-07 14:54:41.061539.061539 lmp.py:767]   Expert  5 |    140 | CPU
DEBUG 01-07 14:54:41.061751.061751 lmp.py:767]   Expert  6 |    143 | CPU
DEBUG 01-07 14:54:41.061394.061394 lmp.py:767]   Expert 59 |    143 | CPU
DEBUG 01-07 14:54:41.061560.061560 lmp.py:767]   Expert 51 |    145 | CPU
DEBUG 01-07 14:54:41.061395.061395 lmp.py:767]   Expert 49 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061754.061754 lmp.py:767]   Expert 23 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061827.061827 lmp.py:767]   Expert  2 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061709.061709 lmp.py:767]   Expert  9 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061352.061352 lmp.py:767]   Expert 50 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061995.061995 lmp.py:767]   Expert 56 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061399.061399 lmp.py:767]   Expert 40 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061804.061804 lmp.py:767]   Expert 52 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061208.061208 lmp.py:767]   Expert 16 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061613.061613 lmp.py:767]   Expert 35 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061209.061209 lmp.py:767]   Expert  4 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061568.061568 lmp.py:767]   Expert 13 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061449.061449 lmp.py:767]   Expert 37 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061569.061569 lmp.py:767]   Expert 42 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061689.061689 lmp.py:767]   Expert 17 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061332.061332 lmp.py:767]   Expert 38 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.061498.061498 lmp.py:767]   Expert 62 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061902.061902 lmp.py:767]   Expert 21 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.061307.061307 lmp.py:767]   Expert  3 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062950.062950 lmp.py:767]   Expert 44 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062116.062116 lmp.py:767]   Expert 28 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062521.062521 lmp.py:767]   Expert 60 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062402.062402 lmp.py:767]   Expert 58 |    213 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062283.062283 lmp.py:767]   Expert 10 |    214 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062403.062403 lmp.py:767]   Expert 47 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062285.062285 lmp.py:767]   Expert 53 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062166.062166 lmp.py:767]   Expert 55 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062809.062809 lmp.py:767]   Expert 20 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062213.062213 lmp.py:767]   Expert 57 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062856.062856 lmp.py:767]   Expert 33 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062261.062261 lmp.py:767]   Expert 31 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062666.062666 lmp.py:767]   Expert 46 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062070.062070 lmp.py:767]   Expert  8 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062713.062713 lmp.py:767]   Expert 19 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062879.062879 lmp.py:767]   Expert 24 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062045.062045 lmp.py:767]   Expert 14 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062165.062165 lmp.py:767]   Expert 63 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062047.062047 lmp.py:767]   Expert 29 |    275 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062166.062166 lmp.py:767]   Expert 12 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062048.062048 lmp.py:767]   Expert 22 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062929.062929 lmp.py:767]   Expert  0 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062334.062334 lmp.py:767]   Expert 43 |    311 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062738.062738 lmp.py:767]   Expert 54 |    341 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062143.062143 lmp.py:767]   Expert 41 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.062547.062547 lmp.py:767]   Expert 25 |    413 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.062998.062998 lmp.py:769] 
DEBUG 01-07 14:54:41.062998.062998 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.062641.062641 lmp.py:770]   CPU:   2202 tokens
DEBUG 01-07 14:54:41.062284.062284 lmp.py:774]   cuda:1:   4967 tokens (22 experts)
DEBUG 01-07 14:54:41.062166.062166 lmp.py:774]   cuda:2:   5119 tokens (23 experts)
DEBUG 01-07 14:54:41.062570.062570 lmp.py:775]   Total GPU:  10086 tokens
DEBUG 01-07 14:54:41.062498.062498 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.062498.062498 lmp.py:776] 
DEBUG 01-07 14:54:41.062386.062386 cuda_h.py:19] end experts_map_get cost 0.0017833709716796875 seconds
DEBUG 01-07 14:54:41.062221.062221 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.062852.062852 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.062325.062325 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.062267.062267 cuda_h.py:19] end allocate_cuda_memory cost 0.0002067089080810547 seconds
DEBUG 01-07 14:54:41.063985.063985 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.063979.063979 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.063596.063596 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.063246.063246 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff9956da-a9dd-463c-8de0-ee1485585912
DEBUG 01-07 14:54:41.063403.063403 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.063336.063336 client.py:127] Model loaded
DEBUG 01-07 14:54:41.063881.063881 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.063541.063541 cuda_h.py:19] end restore2model cost 0.0003151893615722656 seconds
DEBUG 01-07 14:54:41.063450.063450 cuda_h.py:19] end sllm_worker_task cost 0.008758306503295898 seconds
INFO 01-07 14:54:41.063347.063347 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff9956da-a9dd-463c-8de0-ee1485585912
DEBUG 01-07 14:54:41.064329.064329 cuda_h.py:19] end load_into_gpu_async cost 0.000957489013671875 seconds
DEBUG 01-07 14:54:41.064648.064648 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.064301.064301 cuda_h.py:19] end restore_tensors2 cost 0.00028061866760253906 seconds
DEBUG 01-07 14:54:41.064375.064375 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001767873764038086 seconds
DEBUG 01-07 14:54:41.064992.064992 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.066439.066439 cuda_h.py:19] end restore2model cost 0.0018470287322998047 seconds
DEBUG 01-07 14:54:41.066965.066965 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.066769.066769 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.066247.066247 cuda_h.py:19] end allocate_cuda_memory cost 0.00017881393432617188 seconds
DEBUG 01-07 14:54:41.066414.066414 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.066832.066832 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.066257.066257 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.066192.066192 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ca85afb-3e25-45d4-a795-1f72f0edd88b
DEBUG 01-07 14:54:41.067634.067634 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.067325.067325 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ca85afb-3e25-45d4-a795-1f72f0edd88b
DEBUG 01-07 14:54:41.067485.067485 cuda_h.py:19] end load_into_gpu_async cost 0.0011119842529296875 seconds
DEBUG 01-07 14:54:41.067043.067043 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.068013.068013 cuda_h.py:19] end restore_tensors2 cost 0.0002682209014892578 seconds
DEBUG 01-07 14:54:41.068266.068266 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018458366394042969 seconds
DEBUG 01-07 14:54:41.068022.068022 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.070020.070020 cuda_h.py:19] end restore2model cost 0.0019016265869140625 seconds
DEBUG 01-07 14:54:41.070625.070625 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007684230804443359 seconds
DEBUG 01-07 14:54:41.070136.070136 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.070953.070953 lmp.py:816] 
DEBUG 01-07 14:54:41.070953.070953 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.070312.070312 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:41.070677.070677 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.074708.074708 mlpmodule.py:749] group tensors cost 0.004160165786743164 s
DEBUG 01-07 14:54:41.076600.076600 mlpmodule.py:787] pad cost 0.0009806156158447266 s
DEBUG 01-07 14:54:41.076650.076650 mlpmodule.py:793] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-07 14:54:41.076229.076229 mlpmodule.py:798] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-07 14:54:41.087315.087315 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.088883.088883 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.088329.088329 mlpmodule.py:818] group_w3 first element: -0.054931640625
WARNING 01-07 14:54:41.088902.088902 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.106857.106857 mlpmodule.py:838] group einsum cost 0.02957320213317871 s
DEBUG 01-07 14:54:41.106618.106618 mlpmodule.py:846] cpy2cputensor cost 0.00040411949157714844 s
DEBUG 01-07 14:54:41.109842.109842 cuda_h.py:19] end wait_cetm_experts cost 0.03849220275878906 seconds
DEBUG 01-07 14:54:41.109633.109633 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.109816.109816 cuda_h.py:19] end gpu_sexperts cost 0.0004794597625732422 seconds
DEBUG 01-07 14:54:41.109758.109758 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.109462.109462 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.288818359375e-05 seconds
DEBUG 01-07 14:54:41.109688.109688 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.109113.109113 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff9956da-a9dd-463c-8de0-ee1485585912
INFO 01-07 14:54:41.110302.110302 client.py:127] Model loaded
INFO 01-07 14:54:41.110085.110085 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ca85afb-3e25-45d4-a795-1f72f0edd88b
INFO 01-07 14:54:41.111270.111270 client.py:127] Model loaded
DEBUG 01-07 14:54:41.111715.111715 cuda_h.py:19] end wait_experts_multi_device cost 0.0013577938079833984 seconds
DEBUG 01-07 14:54:41.111610.111610 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.111002.111002 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.112103.112103 mlpmodule.py:533] gpu group tensors cost 0.0005564689636230469 s
DEBUG 01-07 14:54:41.113022.113022 mlpmodule.py:566] gpu pad cost 0.0012805461883544922 s
DEBUG 01-07 14:54:41.114827.114827 mlpmodule.py:584] gpu group einsum cost 0.0004277229309082031 s
DEBUG 01-07 14:54:41.115232.115232 mlpmodule.py:707]  experts func einsum cost 0.04536104202270508 s
DEBUG 01-07 14:54:41.116473.116473 mlpmodule.py:656] gpu experts func einsum cost 0.004465818405151367 s
DEBUG 01-07 14:54:41.116602.116602 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.117998.117998 mlpmodule.py:533] gpu group tensors cost 0.0004572868347167969 s
DEBUG 01-07 14:54:41.118457.118457 mlpmodule.py:566] gpu pad cost 0.001196146011352539 s
DEBUG 01-07 14:54:41.119848.119848 mlpmodule.py:584] gpu group einsum cost 0.0003361701965332031 s
DEBUG 01-07 14:54:41.120904.120904 mlpmodule.py:656] gpu experts func einsum cost 0.003968954086303711 s
DEBUG 01-07 14:54:41.121410.121410 cuda_h.py:19] end gpu_experts_multi_device cost 0.00983119010925293 seconds
DEBUG 01-07 14:54:41.121380.121380 cuda_h.py:19] end layer_moe_generate_multi_device_3 cost 0.061109304428100586 seconds
DEBUG 01-07 14:54:41.121867.121867 lmp.py:194] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-07 14:54:41.121159.121159 lmp.py:153] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-07 14:54:41.121094.121094 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 14:54:41.121088.121088 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 14:54:41.121123.121123 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.361701965332031e-05 seconds
DEBUG 01-07 14:54:41.121065.121065 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.4849853515625e-05 seconds
DEBUG 01-07 14:54:41.121615.121615 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.121504.121504 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.121354.121354 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.121496.121496 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.121179.121179 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.122679.122679 cuda_h.py:19] end allocate_cuda_memory cost 0.00025391578674316406 seconds
DEBUG 01-07 14:54:41.122934.122934 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.122789.122789 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.122466.122466 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.122023.122023 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c704b9e8-a17f-4903-8380-25f3cbaccbd1
DEBUG 01-07 14:54:41.122986.122986 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.122386.122386 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.123964.123964 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c704b9e8-a17f-4903-8380-25f3cbaccbd1
DEBUG 01-07 14:54:41.123131.123131 cuda_h.py:19] end load_into_gpu_async cost 0.0009179115295410156 seconds
DEBUG 01-07 14:54:41.123881.123881 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.123241.123241 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-07 14:54:41.123043.123043 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014984607696533203 seconds
INFO 01-07 14:54:41.123562.123562 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c704b9e8-a17f-4903-8380-25f3cbaccbd1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.126755.126755 cuda_h.py:19] end self_attn cost 0.0036525726318359375 seconds
DEBUG 01-07 14:54:41.126130.126130 cuda_h.py:19] end iln_self_attn_paln cost 0.005054950714111328 seconds
DEBUG 01-07 14:54:41.126767.126767 cuda_h.py:10] start layer_moe_generate_multi_device_4
DEBUG 01-07 14:54:41.126192.126192 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.127731.127731 cuda_h.py:19] end gate cost 0.0006458759307861328 seconds
DEBUG 01-07 14:54:41.127938.127938 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.127078.127078 lmp.py:744] 
DEBUG 01-07 14:54:41.127078.127078 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.127457.127457 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.127775.127775 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.128279.128279 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.128114.128114 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.128519.128519 lmp.py:749] 
DEBUG 01-07 14:54:41.128519.128519 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.128639.128639 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.128242.128242 lmp.py:767]   Expert 14 |     64 | CPU
DEBUG 01-07 14:54:41.128885.128885 lmp.py:767]   Expert 57 |     73 | CPU
DEBUG 01-07 14:54:41.128051.128051 lmp.py:767]   Expert 13 |     76 | CPU
DEBUG 01-07 14:54:41.128741.128741 lmp.py:767]   Expert 26 |     81 | CPU
DEBUG 01-07 14:54:41.128430.128430 lmp.py:767]   Expert 31 |     90 | CPU
DEBUG 01-07 14:54:41.128119.128119 lmp.py:767]   Expert 54 |     93 | CPU
DEBUG 01-07 14:54:41.128570.128570 lmp.py:767]   Expert 11 |     94 | CPU
DEBUG 01-07 14:54:41.128736.128736 lmp.py:767]   Expert 45 |     98 | CPU
DEBUG 01-07 14:54:41.128379.128379 lmp.py:767]   Expert 58 |    102 | CPU
DEBUG 01-07 14:54:41.128545.128545 lmp.py:767]   Expert 51 |    107 | CPU
DEBUG 01-07 14:54:41.128473.128473 lmp.py:767]   Expert 30 |    110 | CPU
DEBUG 01-07 14:54:41.128878.128878 lmp.py:767]   Expert 36 |    115 | CPU
DEBUG 01-07 14:54:41.128567.128567 lmp.py:767]   Expert 32 |    116 | CPU
DEBUG 01-07 14:54:41.128779.128779 lmp.py:767]   Expert 10 |    117 | CPU
DEBUG 01-07 14:54:41.128230.128230 lmp.py:767]   Expert 20 |    127 | CPU
DEBUG 01-07 14:54:41.128681.128681 lmp.py:767]   Expert 63 |    135 | CPU
DEBUG 01-07 14:54:41.128894.128894 lmp.py:767]   Expert  8 |    136 | CPU
DEBUG 01-07 14:54:41.128344.128344 lmp.py:767]   Expert  4 |    138 | CPU
DEBUG 01-07 14:54:41.128948.128948 lmp.py:767]   Expert 53 |    141 | CPU
DEBUG 01-07 14:54:41.128829.128829 lmp.py:767]   Expert 34 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128141.128141 lmp.py:767]   Expert 61 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128261.128261 lmp.py:767]   Expert 16 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128381.128381 lmp.py:767]   Expert 47 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128501.128501 lmp.py:767]   Expert 60 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128859.128859 lmp.py:767]   Expert 28 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128263.128263 lmp.py:767]   Expert 42 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128906.128906 lmp.py:767]   Expert 17 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128073.128073 lmp.py:767]   Expert 29 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128477.128477 lmp.py:767]   Expert 44 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128882.128882 lmp.py:767]   Expert  7 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128048.128048 lmp.py:767]   Expert 41 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128452.128452 lmp.py:767]   Expert 27 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128857.128857 lmp.py:767]   Expert  9 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128261.128261 lmp.py:767]   Expert 56 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128428.128428 lmp.py:767]   Expert 48 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128594.128594 lmp.py:767]   Expert  2 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128998.128998 lmp.py:767]   Expert  3 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128641.128641 lmp.py:767]   Expert 15 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128523.128523 lmp.py:767]   Expert 24 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128642.128642 lmp.py:767]   Expert  0 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128524.128524 lmp.py:767]   Expert 18 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128167.128167 lmp.py:767]   Expert 55 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128571.128571 lmp.py:767]   Expert 38 |    213 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128738.128738 lmp.py:767]   Expert 22 |    214 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128380.128380 lmp.py:767]   Expert 40 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128785.128785 lmp.py:767]   Expert 23 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128428.128428 lmp.py:767]   Expert  6 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128594.128594 lmp.py:767]   Expert 37 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128760.128760 lmp.py:767]   Expert 46 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128165.128165 lmp.py:767]   Expert 19 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.128331.128331 lmp.py:767]   Expert 39 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.128497.128497 lmp.py:767]   Expert 25 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129663.129663 lmp.py:767]   Expert 12 |    261 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129306.129306 lmp.py:767]   Expert 50 |    261 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.129949.129949 lmp.py:767]   Expert 62 |    271 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.129069.129069 lmp.py:767]   Expert 21 |    281 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.129950.129950 lmp.py:767]   Expert 35 |    281 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129832.129832 lmp.py:767]   Expert 49 |    290 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129475.129475 lmp.py:767]   Expert 52 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.129641.129641 lmp.py:767]   Expert 33 |    300 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129569.129569 lmp.py:767]   Expert  1 |    351 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.129735.129735 lmp.py:767]   Expert  5 |    381 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129662.129662 lmp.py:767]   Expert 43 |    438 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.129590.129590 lmp.py:767]   Expert 59 |    586 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.129803.129803 lmp.py:769] 
DEBUG 01-07 14:54:41.129803.129803 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.129684.129684 lmp.py:770]   CPU:   2013 tokens
DEBUG 01-07 14:54:41.129519.129519 lmp.py:774]   cuda:1:   5081 tokens (22 experts)
DEBUG 01-07 14:54:41.129401.129401 lmp.py:774]   cuda:2:   5194 tokens (23 experts)
DEBUG 01-07 14:54:41.129044.129044 lmp.py:775]   Total GPU:  10275 tokens
DEBUG 01-07 14:54:41.129448.129448 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.129448.129448 lmp.py:776] 
DEBUG 01-07 14:54:41.129098.129098 cuda_h.py:19] end experts_map_get cost 0.0017750263214111328 seconds
DEBUG 01-07 14:54:41.129979.129979 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.129563.129563 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.129044.129044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.129709.129709 cuda_h.py:19] end allocate_cuda_memory cost 0.00024628639221191406 seconds
DEBUG 01-07 14:54:41.129711.129711 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.129706.129706 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.129899.129899 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.129503.129503 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 191873c7-0e34-47da-9578-da1dd4523f3b
DEBUG 01-07 14:54:41.130243.130243 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.130473.130473 client.py:127] Model loaded
DEBUG 01-07 14:54:41.130402.130402 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.130268.130268 cuda_h.py:19] end restore2model cost 0.0003247261047363281 seconds
DEBUG 01-07 14:54:41.130368.130368 cuda_h.py:19] end sllm_worker_task cost 0.008866310119628906 seconds
INFO 01-07 14:54:41.130343.130343 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 191873c7-0e34-47da-9578-da1dd4523f3b
DEBUG 01-07 14:54:41.130848.130848 cuda_h.py:19] end load_into_gpu_async cost 0.0010867118835449219 seconds
DEBUG 01-07 14:54:41.130882.130882 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.131138.131138 cuda_h.py:19] end restore_tensors2 cost 0.00030422210693359375 seconds
DEBUG 01-07 14:54:41.131868.131868 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019576549530029297 seconds
DEBUG 01-07 14:54:41.131816.131816 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.133800.133800 cuda_h.py:19] end restore2model cost 0.001856088638305664 seconds
DEBUG 01-07 14:54:41.133187.133187 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.133137.133137 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.133861.133861 cuda_h.py:19] end allocate_cuda_memory cost 0.00021958351135253906 seconds
DEBUG 01-07 14:54:41.133651.133651 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.133738.133738 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.133163.133163 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.133859.133859 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fff4ee31-6db5-41f0-bf15-ff687d285ebc
DEBUG 01-07 14:54:41.134539.134539 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.134801.134801 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fff4ee31-6db5-41f0-bf15-ff687d285ebc
DEBUG 01-07 14:54:41.134485.134485 cuda_h.py:19] end load_into_gpu_async cost 0.0011456012725830078 seconds
DEBUG 01-07 14:54:41.134280.134280 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.135569.135569 cuda_h.py:19] end restore_tensors2 cost 0.0002930164337158203 seconds
DEBUG 01-07 14:54:41.135630.135630 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019483566284179688 seconds
DEBUG 01-07 14:54:41.135148.135148 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.137199.137199 cuda_h.py:19] end restore2model cost 0.001905679702758789 seconds
DEBUG 01-07 14:54:41.137797.137797 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007990360260009766 seconds
DEBUG 01-07 14:54:41.137639.137639 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.137218.137218 lmp.py:816] 
DEBUG 01-07 14:54:41.137218.137218 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.137292.137292 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 14:54:41.137657.137657 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.143068.143068 mlpmodule.py:749] group tensors cost 0.006203413009643555 s
DEBUG 01-07 14:54:41.146978.146978 mlpmodule.py:787] pad cost 0.0015454292297363281 s
DEBUG 01-07 14:54:41.146215.146215 mlpmodule.py:793] create cpu tensor cost 5.745887756347656e-05 s
DEBUG 01-07 14:54:41.146205.146205 mlpmodule.py:798] move to cpu cost 4.291534423828125e-05 s
DEBUG 01-07 14:54:41.157773.157773 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.157394.157394 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.157363.157363 mlpmodule.py:818] group_w3 first element: 0.0086669921875
WARNING 01-07 14:54:41.157135.157135 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.174022.174022 mlpmodule.py:838] group einsum cost 0.027692556381225586 s
DEBUG 01-07 14:54:41.174655.174655 mlpmodule.py:846] cpy2cputensor cost 0.00034999847412109375 s
DEBUG 01-07 14:54:41.176661.176661 cuda_h.py:19] end wait_cetm_experts cost 0.039424896240234375 seconds
DEBUG 01-07 14:54:41.177499.177499 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.177438.177438 cuda_h.py:19] end gpu_sexperts cost 0.0005099773406982422 seconds
DEBUG 01-07 14:54:41.177903.177903 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.177561.177561 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 14:54:41.177264.177264 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.177404.177404 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 191873c7-0e34-47da-9578-da1dd4523f3b
INFO 01-07 14:54:41.178401.178401 client.py:127] Model loaded
INFO 01-07 14:54:41.178152.178152 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fff4ee31-6db5-41f0-bf15-ff687d285ebc
INFO 01-07 14:54:41.179293.179293 client.py:127] Model loaded
DEBUG 01-07 14:54:41.179646.179646 cuda_h.py:19] end wait_experts_multi_device cost 0.0014793872833251953 seconds
DEBUG 01-07 14:54:41.179779.179779 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.179171.179171 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.180279.180279 mlpmodule.py:533] gpu group tensors cost 0.000560760498046875 s
DEBUG 01-07 14:54:41.181589.181589 mlpmodule.py:566] gpu pad cost 0.0012867450714111328 s
DEBUG 01-07 14:54:41.182805.182805 mlpmodule.py:584] gpu group einsum cost 0.00044798851013183594 s
DEBUG 01-07 14:54:41.184413.184413 mlpmodule.py:656] gpu experts func einsum cost 0.004384756088256836 s
DEBUG 01-07 14:54:41.184483.184483 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.184144.184144 mlpmodule.py:707]  experts func einsum cost 0.0472567081451416 s
DEBUG 01-07 14:54:41.185367.185367 mlpmodule.py:533] gpu group tensors cost 0.00045752525329589844 s
DEBUG 01-07 14:54:41.187115.187115 mlpmodule.py:566] gpu pad cost 0.0015006065368652344 s
DEBUG 01-07 14:54:41.187552.187552 mlpmodule.py:584] gpu group einsum cost 0.0007088184356689453 s
DEBUG 01-07 14:54:41.189970.189970 mlpmodule.py:656] gpu experts func einsum cost 0.004802227020263672 s
DEBUG 01-07 14:54:41.190953.190953 cuda_h.py:19] end gpu_experts_multi_device cost 0.01070404052734375 seconds
DEBUG 01-07 14:54:41.190413.190413 cuda_h.py:19] end layer_moe_generate_multi_device_4 cost 0.06336808204650879 seconds
DEBUG 01-07 14:54:41.190924.190924 lmp.py:194] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-07 14:54:41.190793.190793 lmp.py:153] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-07 14:54:41.190536.190536 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 14:54:41.190815.190815 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 14:54:41.190174.190174 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.9325485229492188e-05 seconds
DEBUG 01-07 14:54:41.190970.190970 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.841255187988281e-05 seconds
DEBUG 01-07 14:54:41.190805.190805 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.190343.190343 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.190776.190776 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.190705.190705 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.190573.190573 cuda_h.py:19] end allocate_cuda_memory cost 0.0001857280731201172 seconds
DEBUG 01-07 14:54:41.191920.191920 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.191988.191988 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.191448.191448 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.191032.191032 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.191258.191258 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d88085c0-d489-4ecf-96e1-8d2303cd1e07
DEBUG 01-07 14:54:41.191936.191936 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.191953.191953 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.192939.192939 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d88085c0-d489-4ecf-96e1-8d2303cd1e07
DEBUG 01-07 14:54:41.192437.192437 cuda_h.py:19] end load_into_gpu_async cost 0.0008707046508789062 seconds
DEBUG 01-07 14:54:41.192233.192233 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.192786.192786 cuda_h.py:19] end restore_tensors2 cost 6.222724914550781e-05 seconds
DEBUG 01-07 14:54:41.192350.192350 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014789104461669922 seconds
INFO 01-07 14:54:41.192941.192941 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d88085c0-d489-4ecf-96e1-8d2303cd1e07
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.195254.195254 cuda_h.py:19] end self_attn cost 0.0036017894744873047 seconds
DEBUG 01-07 14:54:41.195073.195073 cuda_h.py:19] end iln_self_attn_paln cost 0.005014657974243164 seconds
DEBUG 01-07 14:54:41.195280.195280 cuda_h.py:10] start layer_moe_generate_multi_device_5
DEBUG 01-07 14:54:41.195466.195466 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.196827.196827 cuda_h.py:19] end gate cost 0.0006482601165771484 seconds
DEBUG 01-07 14:54:41.196140.196140 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.196472.196472 lmp.py:744] 
DEBUG 01-07 14:54:41.196472.196472 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.196328.196328 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.196646.196646 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.196150.196150 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.196270.196270 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.196675.196675 lmp.py:749] 
DEBUG 01-07 14:54:41.196675.196675 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.197795.197795 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.197636.197636 lmp.py:767]   Expert 34 |     23 | CPU
DEBUG 01-07 14:54:41.197518.197518 lmp.py:767]   Expert 45 |     61 | CPU
DEBUG 01-07 14:54:41.197684.197684 lmp.py:767]   Expert 22 |     77 | CPU
DEBUG 01-07 14:54:41.197373.197373 lmp.py:767]   Expert 57 |     77 | CPU
DEBUG 01-07 14:54:41.197301.197301 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 14:54:41.197513.197513 lmp.py:767]   Expert 15 |     99 | CPU
DEBUG 01-07 14:54:41.197441.197441 lmp.py:767]   Expert  4 |    102 | CPU
DEBUG 01-07 14:54:41.197130.197130 lmp.py:767]   Expert 28 |    107 | CPU
DEBUG 01-07 14:54:41.197820.197820 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 14:54:41.197794.197794 lmp.py:767]   Expert 60 |    117 | CPU
DEBUG 01-07 14:54:41.197245.197245 lmp.py:767]   Expert 36 |    124 | CPU
DEBUG 01-07 14:54:41.197888.197888 lmp.py:767]   Expert 12 |    126 | CPU
DEBUG 01-07 14:54:41.197815.197815 lmp.py:767]   Expert 16 |    128 | CPU
DEBUG 01-07 14:54:41.197982.197982 lmp.py:767]   Expert 25 |    128 | CPU
DEBUG 01-07 14:54:41.197909.197909 lmp.py:767]   Expert 14 |    129 | CPU
DEBUG 01-07 14:54:41.197314.197314 lmp.py:767]   Expert 52 |    130 | CPU
DEBUG 01-07 14:54:41.197003.197003 lmp.py:767]   Expert  8 |    135 | CPU
DEBUG 01-07 14:54:41.197692.197692 lmp.py:767]   Expert  2 |    137 | CPU
DEBUG 01-07 14:54:41.197905.197905 lmp.py:767]   Expert  5 |    146 | CPU
DEBUG 01-07 14:54:41.197548.197548 lmp.py:767]   Expert 35 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197144.197144 lmp.py:767]   Expert 30 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197787.197787 lmp.py:767]   Expert 23 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197430.197430 lmp.py:767]   Expert 61 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197597.197597 lmp.py:767]   Expert 39 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197716.197716 lmp.py:767]   Expert  0 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197598.197598 lmp.py:767]   Expert 31 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197718.197718 lmp.py:767]   Expert 13 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197076.197076 lmp.py:767]   Expert 42 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197957.197957 lmp.py:767]   Expert  3 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197123.197123 lmp.py:767]   Expert 44 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197289.197289 lmp.py:767]   Expert 41 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197217.197217 lmp.py:767]   Expert  9 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197145.197145 lmp.py:767]   Expert 46 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197788.197788 lmp.py:767]   Expert 43 |    184 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197477.197477 lmp.py:767]   Expert 50 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197882.197882 lmp.py:767]   Expert 62 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197048.197048 lmp.py:767]   Expert 18 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197214.197214 lmp.py:767]   Expert 26 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197857.197857 lmp.py:767]   Expert 51 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197500.197500 lmp.py:767]   Expert 49 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197381.197381 lmp.py:767]   Expert 27 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197263.197263 lmp.py:767]   Expert 47 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197383.197383 lmp.py:767]   Expert 11 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197787.197787 lmp.py:767]   Expert 20 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197192.197192 lmp.py:767]   Expert 19 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197596.197596 lmp.py:767]   Expert 55 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197001.197001 lmp.py:767]   Expert 63 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197405.197405 lmp.py:767]   Expert 56 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197333.197333 lmp.py:767]   Expert 38 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197499.197499 lmp.py:767]   Expert 48 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197381.197381 lmp.py:767]   Expert  1 |    235 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197500.197500 lmp.py:767]   Expert 10 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197143.197143 lmp.py:767]   Expert 54 |    246 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197025.197025 lmp.py:767]   Expert  7 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197145.197145 lmp.py:767]   Expert 21 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.197311.197311 lmp.py:767]   Expert 33 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.197477.197477 lmp.py:767]   Expert 29 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.198405.198405 lmp.py:767]   Expert 40 |    267 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.198809.198809 lmp.py:767]   Expert 24 |    272 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.198975.198975 lmp.py:767]   Expert 59 |    297 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.198141.198141 lmp.py:767]   Expert 37 |    335 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.198308.198308 lmp.py:767]   Expert 58 |    368 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.198474.198474 lmp.py:767]   Expert  6 |    388 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.198594.198594 lmp.py:767]   Expert 53 |    860 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.198998.198998 lmp.py:769] 
DEBUG 01-07 14:54:41.198998.198998 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.198879.198879 lmp.py:770]   CPU:   2056 tokens
DEBUG 01-07 14:54:41.198715.198715 lmp.py:774]   cuda:1:   5119 tokens (22 experts)
DEBUG 01-07 14:54:41.198133.198133 lmp.py:774]   cuda:2:   5113 tokens (23 experts)
DEBUG 01-07 14:54:41.198060.198060 lmp.py:775]   Total GPU:  10232 tokens
DEBUG 01-07 14:54:41.198750.198750 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.198750.198750 lmp.py:776] 
DEBUG 01-07 14:54:41.198399.198399 cuda_h.py:19] end experts_map_get cost 0.0017778873443603516 seconds
DEBUG 01-07 14:54:41.198758.198758 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.198057.198057 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.198829.198829 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.198207.198207 cuda_h.py:19] end allocate_cuda_memory cost 0.00017642974853515625 seconds
DEBUG 01-07 14:54:41.198626.198626 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.198859.198859 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.198668.198668 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.198272.198272 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 12f32682-5e58-498f-87d1-c049efb0556b
DEBUG 01-07 14:54:41.198012.198012 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.199905.199905 client.py:127] Model loaded
DEBUG 01-07 14:54:41.199019.199019 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.199694.199694 cuda_h.py:19] end restore2model cost 0.00032210350036621094 seconds
DEBUG 01-07 14:54:41.199271.199271 cuda_h.py:19] end sllm_worker_task cost 0.008869409561157227 seconds
INFO 01-07 14:54:41.199556.199556 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 12f32682-5e58-498f-87d1-c049efb0556b
DEBUG 01-07 14:54:41.199969.199969 cuda_h.py:19] end load_into_gpu_async cost 0.001096487045288086 seconds
DEBUG 01-07 14:54:41.199480.199480 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.200245.200245 cuda_h.py:19] end restore_tensors2 cost 0.0002944469451904297 seconds
DEBUG 01-07 14:54:41.200783.200783 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018801689147949219 seconds
DEBUG 01-07 14:54:41.200592.200592 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.202861.202861 cuda_h.py:19] end restore2model cost 0.0018548965454101562 seconds
DEBUG 01-07 14:54:41.202208.202208 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.202681.202681 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.202146.202146 cuda_h.py:19] end allocate_cuda_memory cost 0.0002033710479736328 seconds
DEBUG 01-07 14:54:41.202175.202175 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.202308.202308 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.202303.202303 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.202760.202760 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8a20cd2e-61a1-42cc-ac18-b038084276a0
DEBUG 01-07 14:54:41.202394.202394 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.203595.203595 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8a20cd2e-61a1-42cc-ac18-b038084276a0
DEBUG 01-07 14:54:41.203087.203087 cuda_h.py:19] end load_into_gpu_async cost 0.0010988712310791016 seconds
DEBUG 01-07 14:54:41.203644.203644 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.204588.204588 cuda_h.py:19] end restore_tensors2 cost 0.0002841949462890625 seconds
DEBUG 01-07 14:54:41.204941.204941 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018815994262695312 seconds
DEBUG 01-07 14:54:41.204458.204458 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.206285.206285 cuda_h.py:19] end restore2model cost 0.0019152164459228516 seconds
DEBUG 01-07 14:54:41.206128.206128 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007870674133300781 seconds
DEBUG 01-07 14:54:41.206685.206685 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.206741.206741 lmp.py:816] 
DEBUG 01-07 14:54:41.206741.206741 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.206338.206338 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-07 14:54:41.206750.206750 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.213254.213254 mlpmodule.py:749] group tensors cost 0.006624460220336914 s
DEBUG 01-07 14:54:41.215056.215056 mlpmodule.py:787] pad cost 0.0016913414001464844 s
DEBUG 01-07 14:54:41.215353.215353 mlpmodule.py:793] create cpu tensor cost 5.9604644775390625e-05 s
DEBUG 01-07 14:54:41.215972.215972 mlpmodule.py:798] move to cpu cost 4.649162292480469e-05 s
DEBUG 01-07 14:54:41.224153.224153 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.224019.224019 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.224234.224234 mlpmodule.py:818] group_w3 first element: -0.010498046875
WARNING 01-07 14:54:41.225483.225483 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.239698.239698 mlpmodule.py:838] group einsum cost 0.02337479591369629 s
DEBUG 01-07 14:54:41.240024.240024 mlpmodule.py:846] cpy2cputensor cost 0.0004532337188720703 s
DEBUG 01-07 14:54:41.242604.242604 cuda_h.py:19] end wait_cetm_experts cost 0.03654170036315918 seconds
DEBUG 01-07 14:54:41.243011.243011 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.243088.243088 cuda_h.py:19] end gpu_sexperts cost 0.00046896934509277344 seconds
DEBUG 01-07 14:54:41.243401.243401 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.243674.243674 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2649765014648438e-05 seconds
DEBUG 01-07 14:54:41.243900.243900 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.243756.243756 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 12f32682-5e58-498f-87d1-c049efb0556b
INFO 01-07 14:54:41.244091.244091 client.py:127] Model loaded
INFO 01-07 14:54:41.244589.244589 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8a20cd2e-61a1-42cc-ac18-b038084276a0
INFO 01-07 14:54:41.245286.245286 client.py:127] Model loaded
DEBUG 01-07 14:54:41.245116.245116 cuda_h.py:19] end wait_experts_multi_device cost 0.0014615058898925781 seconds
DEBUG 01-07 14:54:41.245488.245488 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.245403.245403 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.246151.246151 mlpmodule.py:533] gpu group tensors cost 0.0005016326904296875 s
DEBUG 01-07 14:54:41.247907.247907 mlpmodule.py:566] gpu pad cost 0.0013370513916015625 s
DEBUG 01-07 14:54:41.248633.248633 mlpmodule.py:584] gpu group einsum cost 0.0004520416259765625 s
DEBUG 01-07 14:54:41.250683.250683 mlpmodule.py:656] gpu experts func einsum cost 0.004512310028076172 s
DEBUG 01-07 14:54:41.250416.250416 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.251428.251428 mlpmodule.py:533] gpu group tensors cost 0.00045800209045410156 s
DEBUG 01-07 14:54:41.251764.251764 mlpmodule.py:707]  experts func einsum cost 0.04540085792541504 s
DEBUG 01-07 14:54:41.253277.253277 mlpmodule.py:566] gpu pad cost 0.0015833377838134766 s
DEBUG 01-07 14:54:41.254788.254788 mlpmodule.py:584] gpu group einsum cost 0.0009114742279052734 s
DEBUG 01-07 14:54:41.255218.255218 mlpmodule.py:656] gpu experts func einsum cost 0.004868507385253906 s
DEBUG 01-07 14:54:41.256367.256367 cuda_h.py:19] end gpu_experts_multi_device cost 0.010802268981933594 seconds
DEBUG 01-07 14:54:41.256767.256767 cuda_h.py:19] end layer_moe_generate_multi_device_5 cost 0.060407161712646484 seconds
DEBUG 01-07 14:54:41.256318.256318 lmp.py:194] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-07 14:54:41.256173.256173 lmp.py:153] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-07 14:54:41.256976.256976 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 14:54:41.256898.256898 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 14:54:41.256701.256701 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.956390380859375e-05 seconds
DEBUG 01-07 14:54:41.256212.256212 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.936622619628906e-05 seconds
DEBUG 01-07 14:54:41.256570.256570 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.256851.256851 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.256416.256416 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.256670.256670 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.256645.256645 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.257984.257984 cuda_h.py:19] end allocate_cuda_memory cost 0.0001800060272216797 seconds
DEBUG 01-07 14:54:41.257894.257894 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.257511.257511 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.257711.257711 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.257460.257460 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f99fe454-891e-4ec1-b4df-c1569f04cef5
DEBUG 01-07 14:54:41.257661.257661 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.257900.257900 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.257953.257953 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f99fe454-891e-4ec1-b4df-c1569f04cef5
DEBUG 01-07 14:54:41.257882.257882 cuda_h.py:19] end load_into_gpu_async cost 0.0007998943328857422 seconds
DEBUG 01-07 14:54:41.257439.257439 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.258561.258561 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:41.258125.258125 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0012860298156738281 seconds
INFO 01-07 14:54:41.258339.258339 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f99fe454-891e-4ec1-b4df-c1569f04cef5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.261428.261428 cuda_h.py:19] end self_attn cost 0.0036275386810302734 seconds
DEBUG 01-07 14:54:41.261286.261286 cuda_h.py:19] end iln_self_attn_paln cost 0.00492405891418457 seconds
DEBUG 01-07 14:54:41.261016.261016 cuda_h.py:10] start layer_moe_generate_multi_device_6
DEBUG 01-07 14:54:41.261441.261441 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.262920.262920 cuda_h.py:19] end gate cost 0.0006372928619384766 seconds
DEBUG 01-07 14:54:41.262889.262889 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.262161.262161 lmp.py:744] 
DEBUG 01-07 14:54:41.262161.262161 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.262314.262314 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.262110.262110 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.262899.262899 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.262303.262303 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.262231.262231 lmp.py:749] 
DEBUG 01-07 14:54:41.262231.262231 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.262920.262920 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.262570.262570 lmp.py:767]   Expert  1 |     45 | CPU
DEBUG 01-07 14:54:41.262498.262498 lmp.py:767]   Expert  7 |     55 | CPU
DEBUG 01-07 14:54:41.262710.262710 lmp.py:767]   Expert 37 |     72 | CPU
DEBUG 01-07 14:54:41.262446.262446 lmp.py:767]   Expert 54 |     75 | CPU
DEBUG 01-07 14:54:41.262181.262181 lmp.py:767]   Expert 17 |     81 | CPU
DEBUG 01-07 14:54:41.262679.262679 lmp.py:767]   Expert 18 |     83 | CPU
DEBUG 01-07 14:54:41.262414.262414 lmp.py:767]   Expert  9 |     86 | CPU
DEBUG 01-07 14:54:41.262912.262912 lmp.py:767]   Expert 13 |     96 | CPU
DEBUG 01-07 14:54:41.263647.263647 lmp.py:767]   Expert 22 |     99 | CPU
DEBUG 01-07 14:54:41.263098.263098 lmp.py:767]   Expert 58 |    101 | CPU
DEBUG 01-07 14:54:41.263026.263026 lmp.py:767]   Expert  0 |    108 | CPU
DEBUG 01-07 14:54:41.263477.263477 lmp.py:767]   Expert 26 |    116 | CPU
DEBUG 01-07 14:54:41.263927.263927 lmp.py:767]   Expert 16 |    120 | CPU
DEBUG 01-07 14:54:41.263140.263140 lmp.py:767]   Expert 63 |    125 | CPU
DEBUG 01-07 14:54:41.263637.263637 lmp.py:767]   Expert 10 |    126 | CPU
DEBUG 01-07 14:54:41.263373.263373 lmp.py:767]   Expert 59 |    130 | CPU
DEBUG 01-07 14:54:41.263632.263632 lmp.py:767]   Expert 62 |    144 | CPU
DEBUG 01-07 14:54:41.263129.263129 lmp.py:767]   Expert 43 |    145 | CPU
DEBUG 01-07 14:54:41.263864.263864 lmp.py:767]   Expert 28 |    147 | CPU
DEBUG 01-07 14:54:41.263792.263792 lmp.py:767]   Expert 33 |    148 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263720.263720 lmp.py:767]   Expert 29 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263409.263409 lmp.py:767]   Expert  2 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263860.263860 lmp.py:767]   Expert 51 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263265.263265 lmp.py:767]   Expert 55 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263669.263669 lmp.py:767]   Expert 45 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263835.263835 lmp.py:767]   Expert 11 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263432.263432 lmp.py:767]   Expert  3 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263121.263121 lmp.py:767]   Expert 53 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263811.263811 lmp.py:767]   Expert 23 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263261.263261 lmp.py:767]   Expert 40 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263474.263474 lmp.py:767]   Expert 32 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263925.263925 lmp.py:767]   Expert 14 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263376.263376 lmp.py:767]   Expert 34 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263827.263827 lmp.py:767]   Expert 41 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263277.263277 lmp.py:767]   Expert 52 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263682.263682 lmp.py:767]   Expert 42 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263087.263087 lmp.py:767]   Expert 21 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263253.263253 lmp.py:767]   Expert 57 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263180.263180 lmp.py:767]   Expert 30 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263062.263062 lmp.py:767]   Expert 15 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263751.263751 lmp.py:767]   Expert 35 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263202.263202 lmp.py:767]   Expert 12 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263653.263653 lmp.py:767]   Expert  4 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263104.263104 lmp.py:767]   Expert 19 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263078.263078 lmp.py:767]   Expert 46 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263529.263529 lmp.py:767]   Expert 50 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263980.263980 lmp.py:767]   Expert 24 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263954.263954 lmp.py:767]   Expert  8 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263358.263358 lmp.py:767]   Expert 44 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263286.263286 lmp.py:767]   Expert 49 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263452.263452 lmp.py:767]   Expert 38 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263618.263618 lmp.py:767]   Expert  6 |    246 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263784.263784 lmp.py:767]   Expert 31 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263474.263474 lmp.py:767]   Expert 47 |    252 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263924.263924 lmp.py:767]   Expert 61 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263137.263137 lmp.py:767]   Expert 39 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263349.263349 lmp.py:767]   Expert  5 |    302 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263992.263992 lmp.py:767]   Expert 36 |    306 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263920.263920 lmp.py:767]   Expert 27 |    309 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263086.263086 lmp.py:767]   Expert 60 |    335 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263729.263729 lmp.py:767]   Expert 20 |    338 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263611.263611 lmp.py:767]   Expert 48 |    371 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263492.263492 lmp.py:767]   Expert 25 |    393 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.263373.263373 lmp.py:767]   Expert 56 |    554 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.263539.263539 lmp.py:769] 
DEBUG 01-07 14:54:41.263539.263539 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.263944.263944 lmp.py:770]   CPU:   1954 tokens
DEBUG 01-07 14:54:41.263302.263302 lmp.py:774]   cuda:1:   5104 tokens (22 experts)
DEBUG 01-07 14:54:41.264707.264707 lmp.py:774]   cuda:2:   5230 tokens (23 experts)
DEBUG 01-07 14:54:41.264396.264396 lmp.py:775]   Total GPU:  10334 tokens
DEBUG 01-07 14:54:41.264847.264847 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.264847.264847 lmp.py:776] 
DEBUG 01-07 14:54:41.264497.264497 cuda_h.py:19] end experts_map_get cost 0.0017197132110595703 seconds
DEBUG 01-07 14:54:41.264378.264378 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.264724.264724 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.264728.264728 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.264863.264863 cuda_h.py:19] end allocate_cuda_memory cost 0.00024271011352539062 seconds
DEBUG 01-07 14:54:41.264620.264620 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.264568.264568 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.264185.264185 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.264788.264788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9fe5a07-8768-438a-a4af-6d33c7e527e6
DEBUG 01-07 14:54:41.264953.264953 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.264812.264812 client.py:127] Model loaded
DEBUG 01-07 14:54:41.265687.265687 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.265739.265739 cuda_h.py:19] end restore2model cost 0.00032258033752441406 seconds
DEBUG 01-07 14:54:41.265648.265648 cuda_h.py:19] end sllm_worker_task cost 0.008627653121948242 seconds
INFO 01-07 14:54:41.265127.265127 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9fe5a07-8768-438a-a4af-6d33c7e527e6
DEBUG 01-07 14:54:41.265347.265347 cuda_h.py:19] end load_into_gpu_async cost 0.00092315673828125 seconds
DEBUG 01-07 14:54:41.265381.265381 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.265285.265285 cuda_h.py:19] end restore_tensors2 cost 0.00025582313537597656 seconds
DEBUG 01-07 14:54:41.265823.265823 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017352104187011719 seconds
DEBUG 01-07 14:54:41.265393.265393 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.267813.267813 cuda_h.py:19] end restore2model cost 0.001827239990234375 seconds
DEBUG 01-07 14:54:41.267577.267577 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.267766.267766 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.268157.268157 cuda_h.py:19] end allocate_cuda_memory cost 0.0001857280731201172 seconds
DEBUG 01-07 14:54:41.268086.268086 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.268743.268743 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.268260.268260 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.268241.268241 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e076bf7d-c19f-4891-8353-00e92aad198b
DEBUG 01-07 14:54:41.268459.268459 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.269998.269998 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e076bf7d-c19f-4891-8353-00e92aad198b
DEBUG 01-07 14:54:41.269205.269205 cuda_h.py:19] end load_into_gpu_async cost 0.0009357929229736328 seconds
DEBUG 01-07 14:54:41.269000.269000 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.269579.269579 cuda_h.py:19] end restore_tensors2 cost 0.0002605915069580078 seconds
DEBUG 01-07 14:54:41.269879.269879 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016703605651855469 seconds
DEBUG 01-07 14:54:41.269257.269257 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.271659.271659 cuda_h.py:19] end restore2model cost 0.00188446044921875 seconds
DEBUG 01-07 14:54:41.271396.271396 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007436037063598633 seconds
DEBUG 01-07 14:54:41.271807.271807 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.271432.271432 lmp.py:816] 
DEBUG 01-07 14:54:41.271432.271432 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.271123.271123 cuda_h.py:19] end cpu_experts_submit cost 0.00010347366333007812 seconds
DEBUG 01-07 14:54:41.271534.271534 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.279967.279967 mlpmodule.py:749] group tensors cost 0.008042573928833008 s
DEBUG 01-07 14:54:41.281903.281903 mlpmodule.py:787] pad cost 0.0012614727020263672 s
DEBUG 01-07 14:54:41.282695.282695 mlpmodule.py:793] create cpu tensor cost 5.9604644775390625e-05 s
DEBUG 01-07 14:54:41.282042.282042 mlpmodule.py:798] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-07 14:54:41.291117.291117 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.291699.291699 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.291226.291226 mlpmodule.py:818] group_w3 first element: -0.003631591796875
WARNING 01-07 14:54:41.291263.291263 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.307681.307681 mlpmodule.py:838] group einsum cost 0.025142669677734375 s
DEBUG 01-07 14:54:41.307794.307794 mlpmodule.py:846] cpy2cputensor cost 0.00041031837463378906 s
DEBUG 01-07 14:54:41.310476.310476 cuda_h.py:19] end wait_cetm_experts cost 0.0385746955871582 seconds
DEBUG 01-07 14:54:41.310353.310353 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.310059.310059 cuda_h.py:19] end gpu_sexperts cost 0.0004792213439941406 seconds
DEBUG 01-07 14:54:41.310724.310724 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.311428.311428 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2172927856445312e-05 seconds
DEBUG 01-07 14:54:41.311131.311131 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.311079.311079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9fe5a07-8768-438a-a4af-6d33c7e527e6
INFO 01-07 14:54:41.312771.312771 client.py:127] Model loaded
INFO 01-07 14:54:41.312601.312601 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e076bf7d-c19f-4891-8353-00e92aad198b
INFO 01-07 14:54:41.312483.312483 client.py:127] Model loaded
DEBUG 01-07 14:54:41.312313.312313 cuda_h.py:19] end wait_experts_multi_device cost 0.0014371871948242188 seconds
DEBUG 01-07 14:54:41.312400.312400 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.312507.312507 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.313766.313766 mlpmodule.py:533] gpu group tensors cost 0.0004906654357910156 s
DEBUG 01-07 14:54:41.315029.315029 mlpmodule.py:566] gpu pad cost 0.0012562274932861328 s
DEBUG 01-07 14:54:41.315859.315859 mlpmodule.py:584] gpu group einsum cost 0.0004131793975830078 s
DEBUG 01-07 14:54:41.317834.317834 mlpmodule.py:656] gpu experts func einsum cost 0.0042989253997802734 s
DEBUG 01-07 14:54:41.317744.317744 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.318455.318455 mlpmodule.py:707]  experts func einsum cost 0.04676508903503418 s
DEBUG 01-07 14:54:41.318031.318031 mlpmodule.py:533] gpu group tensors cost 0.0005466938018798828 s
DEBUG 01-07 14:54:41.320642.320642 mlpmodule.py:566] gpu pad cost 0.0011875629425048828 s
DEBUG 01-07 14:54:41.320259.320259 mlpmodule.py:584] gpu group einsum cost 0.0003616809844970703 s
DEBUG 01-07 14:54:41.322823.322823 mlpmodule.py:656] gpu experts func einsum cost 0.004049062728881836 s
DEBUG 01-07 14:54:41.322283.322283 cuda_h.py:19] end gpu_experts_multi_device cost 0.009752273559570312 seconds
DEBUG 01-07 14:54:41.322399.322399 cuda_h.py:19] end layer_moe_generate_multi_device_6 cost 0.06085634231567383 seconds
DEBUG 01-07 14:54:41.322216.322216 lmp.py:194] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-07 14:54:41.322092.322092 lmp.py:153] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-07 14:54:41.322742.322742 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 14:54:41.322260.322260 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 14:54:41.322043.322043 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.5987625122070312e-05 seconds
DEBUG 01-07 14:54:41.322792.322792 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 5.507469177246094e-05 seconds
DEBUG 01-07 14:54:41.322342.322342 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.322549.322549 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.323128.323128 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.323957.323957 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.323212.323212 cuda_h.py:19] end allocate_cuda_memory cost 0.0002593994140625 seconds
DEBUG 01-07 14:54:41.323612.323612 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.323111.323111 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.323379.323379 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.323486.323486 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.323189.323189 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0fdad23a-725f-4697-a02a-520695af1b19
DEBUG 01-07 14:54:41.323179.323179 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.324096.324096 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.324333.324333 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0fdad23a-725f-4697-a02a-520695af1b19
DEBUG 01-07 14:54:41.324361.324361 cuda_h.py:19] end load_into_gpu_async cost 0.0008652210235595703 seconds
DEBUG 01-07 14:54:41.324587.324587 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.324478.324478 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-07 14:54:41.324042.324042 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015578269958496094 seconds
INFO 01-07 14:54:41.324501.324501 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0fdad23a-725f-4697-a02a-520695af1b19
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.327663.327663 cuda_h.py:19] end self_attn cost 0.003621339797973633 seconds
DEBUG 01-07 14:54:41.328124.328124 cuda_h.py:19] end iln_self_attn_paln cost 0.005110979080200195 seconds
DEBUG 01-07 14:54:41.328523.328523 cuda_h.py:10] start layer_moe_generate_multi_device_7
DEBUG 01-07 14:54:41.328471.328471 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.328487.328487 cuda_h.py:19] end gate cost 0.0006465911865234375 seconds
DEBUG 01-07 14:54:41.328409.328409 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.329165.329165 lmp.py:744] 
DEBUG 01-07 14:54:41.329165.329165 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.329603.329603 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.329637.329637 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.329949.329949 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.329592.329592 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.329281.329281 lmp.py:749] 
DEBUG 01-07 14:54:41.329281.329281 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.329732.329732 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.329620.329620 lmp.py:767]   Expert 50 |     45 | CPU
DEBUG 01-07 14:54:41.329025.329025 lmp.py:767]   Expert  3 |     54 | CPU
DEBUG 01-07 14:54:41.329953.329953 lmp.py:767]   Expert 46 |     55 | CPU
DEBUG 01-07 14:54:41.329642.329642 lmp.py:767]   Expert  1 |     79 | CPU
DEBUG 01-07 14:54:41.329854.329854 lmp.py:767]   Expert 29 |     85 | CPU
DEBUG 01-07 14:54:41.329305.329305 lmp.py:767]   Expert  4 |     86 | CPU
DEBUG 01-07 14:54:41.329279.329279 lmp.py:767]   Expert 40 |     95 | CPU
DEBUG 01-07 14:54:41.329492.329492 lmp.py:767]   Expert 15 |     96 | CPU
DEBUG 01-07 14:54:41.329943.329943 lmp.py:767]   Expert  8 |    110 | CPU
DEBUG 01-07 14:54:41.329678.329678 lmp.py:767]   Expert 41 |    110 | CPU
DEBUG 01-07 14:54:41.329844.329844 lmp.py:767]   Expert 28 |    113 | CPU
DEBUG 01-07 14:54:41.329534.329534 lmp.py:767]   Expert 16 |    125 | CPU
DEBUG 01-07 14:54:41.329985.329985 lmp.py:767]   Expert 48 |    127 | CPU
DEBUG 01-07 14:54:41.329436.329436 lmp.py:767]   Expert 27 |    128 | CPU
DEBUG 01-07 14:54:41.329840.329840 lmp.py:767]   Expert  6 |    130 | CPU
DEBUG 01-07 14:54:41.329814.329814 lmp.py:767]   Expert 13 |    131 | CPU
DEBUG 01-07 14:54:41.329788.329788 lmp.py:767]   Expert 51 |    133 | CPU
DEBUG 01-07 14:54:41.329285.329285 lmp.py:767]   Expert 54 |    133 | CPU
DEBUG 01-07 14:54:41.329259.329259 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 14:54:41.329426.329426 lmp.py:767]   Expert 60 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329115.329115 lmp.py:767]   Expert 39 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.329043.329043 lmp.py:767]   Expert 18 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329970.329970 lmp.py:767]   Expert 14 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329090.329090 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.329495.329495 lmp.py:767]   Expert 20 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329899.329899 lmp.py:767]   Expert 52 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329065.329065 lmp.py:767]   Expert 56 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.329231.329231 lmp.py:767]   Expert 36 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.329921.329921 lmp.py:767]   Expert 55 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.329133.329133 lmp.py:767]   Expert 10 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.329346.329346 lmp.py:767]   Expert 45 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329797.329797 lmp.py:767]   Expert 11 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.329009.329009 lmp.py:767]   Expert  5 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330698.330698 lmp.py:767]   Expert 62 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330911.330911 lmp.py:767]   Expert 44 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330362.330362 lmp.py:767]   Expert 57 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330243.330243 lmp.py:767]   Expert 33 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330409.330409 lmp.py:767]   Expert 58 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330337.330337 lmp.py:767]   Expert 53 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330503.330503 lmp.py:767]   Expert 25 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330431.330431 lmp.py:767]   Expert 32 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330405.330405 lmp.py:767]   Expert  2 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330856.330856 lmp.py:767]   Expert 31 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330307.330307 lmp.py:767]   Expert 63 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330758.330758 lmp.py:767]   Expert 21 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330732.330732 lmp.py:767]   Expert 35 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330182.330182 lmp.py:767]   Expert 49 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330633.330633 lmp.py:767]   Expert 17 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330846.330846 lmp.py:767]   Expert 34 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330774.330774 lmp.py:767]   Expert 42 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330940.330940 lmp.py:767]   Expert 37 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330867.330867 lmp.py:767]   Expert 59 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330272.330272 lmp.py:767]   Expert 22 |    238 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330676.330676 lmp.py:767]   Expert  0 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330366.330366 lmp.py:767]   Expert 19 |    257 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330578.330578 lmp.py:767]   Expert 24 |    286 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330552.330552 lmp.py:767]   Expert 61 |    287 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330957.330957 lmp.py:767]   Expert 30 |    300 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330361.330361 lmp.py:767]   Expert 47 |    320 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330004.330004 lmp.py:767]   Expert 38 |    364 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330647.330647 lmp.py:767]   Expert 26 |    377 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330052.330052 lmp.py:767]   Expert 12 |    426 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330933.330933 lmp.py:767]   Expert  9 |    685 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.330815.330815 lmp.py:767]   Expert 23 |    704 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.330742.330742 lmp.py:769] 
DEBUG 01-07 14:54:41.330742.330742 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.330624.330624 lmp.py:770]   CPU:   1970 tokens
DEBUG 01-07 14:54:41.330459.330459 lmp.py:774]   cuda:1:   5227 tokens (23 experts)
DEBUG 01-07 14:54:41.330102.330102 lmp.py:774]   cuda:2:   5091 tokens (22 experts)
DEBUG 01-07 14:54:41.330791.330791 lmp.py:775]   Total GPU:  10318 tokens
DEBUG 01-07 14:54:41.330242.330242 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.330242.330242 lmp.py:776] 
DEBUG 01-07 14:54:41.330892.330892 cuda_h.py:19] end experts_map_get cost 0.0017323493957519531 seconds
DEBUG 01-07 14:54:41.330535.330535 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.330357.330357 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.330699.330699 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.331819.331819 cuda_h.py:19] end allocate_cuda_memory cost 0.00019812583923339844 seconds
DEBUG 01-07 14:54:41.331729.331729 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.331915.331915 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.331963.331963 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.331090.331090 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b1f2880-bb1a-4acc-9bb4-e0438c40fe64
DEBUG 01-07 14:54:41.331983.331983 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.331775.331775 client.py:127] Model loaded
DEBUG 01-07 14:54:41.331320.331320 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.331179.331179 cuda_h.py:19] end restore2model cost 0.00032019615173339844 seconds
DEBUG 01-07 14:54:41.331326.331326 cuda_h.py:19] end sllm_worker_task cost 0.008896350860595703 seconds
INFO 01-07 14:54:41.332810.332810 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b1f2880-bb1a-4acc-9bb4-e0438c40fe64
DEBUG 01-07 14:54:41.332408.332408 cuda_h.py:19] end load_into_gpu_async cost 0.001064300537109375 seconds
DEBUG 01-07 14:54:41.332157.332157 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.332804.332804 cuda_h.py:19] end restore_tensors2 cost 0.00031065940856933594 seconds
DEBUG 01-07 14:54:41.332442.332442 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019001960754394531 seconds
DEBUG 01-07 14:54:41.332443.332443 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.334541.334541 cuda_h.py:19] end restore2model cost 0.001905202865600586 seconds
DEBUG 01-07 14:54:41.334212.334212 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.334010.334010 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.335581.335581 cuda_h.py:19] end allocate_cuda_memory cost 0.00021195411682128906 seconds
DEBUG 01-07 14:54:41.335941.335941 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.335312.335312 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.335453.335453 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.335626.335626 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 82219cdf-f384-407e-944f-dfce3ce5cde4
DEBUG 01-07 14:54:41.335915.335915 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.336866.336866 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 82219cdf-f384-407e-944f-dfce3ce5cde4
DEBUG 01-07 14:54:41.336835.336835 cuda_h.py:19] end load_into_gpu_async cost 0.0011553764343261719 seconds
DEBUG 01-07 14:54:41.336200.336200 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.336455.336455 cuda_h.py:19] end restore_tensors2 cost 0.00026798248291015625 seconds
DEBUG 01-07 14:54:41.336277.336277 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001916646957397461 seconds
DEBUG 01-07 14:54:41.336364.336364 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.338347.338347 cuda_h.py:19] end restore2model cost 0.0018191337585449219 seconds
DEBUG 01-07 14:54:41.338891.338891 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007860898971557617 seconds
DEBUG 01-07 14:54:41.338018.338018 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.338120.338120 lmp.py:816] 
DEBUG 01-07 14:54:41.338120.338120 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.338718.338718 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:41.338129.338129 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.345072.345072 mlpmodule.py:749] group tensors cost 0.0066797733306884766 s
DEBUG 01-07 14:54:41.347459.347459 mlpmodule.py:787] pad cost 0.001684427261352539 s
DEBUG 01-07 14:54:41.348563.348563 mlpmodule.py:793] create cpu tensor cost 5.9604644775390625e-05 s
DEBUG 01-07 14:54:41.348183.348183 mlpmodule.py:798] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-07 14:54:41.357059.357059 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.357687.357687 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.357214.357214 mlpmodule.py:818] group_w3 first element: 0.01263427734375
WARNING 01-07 14:54:41.357391.357391 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.373782.373782 mlpmodule.py:838] group einsum cost 0.024924516677856445 s
DEBUG 01-07 14:54:41.373333.373333 mlpmodule.py:846] cpy2cputensor cost 0.00043702125549316406 s
DEBUG 01-07 14:54:41.376654.376654 cuda_h.py:19] end wait_cetm_experts cost 0.03777432441711426 seconds
DEBUG 01-07 14:54:41.376491.376491 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.377768.377768 cuda_h.py:19] end gpu_sexperts cost 0.0005135536193847656 seconds
DEBUG 01-07 14:54:41.377273.377273 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.377500.377500 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 14:54:41.377680.377680 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.377105.377105 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b1f2880-bb1a-4acc-9bb4-e0438c40fe64
INFO 01-07 14:54:41.378710.378710 client.py:127] Model loaded
INFO 01-07 14:54:41.378540.378540 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 82219cdf-f384-407e-944f-dfce3ce5cde4
INFO 01-07 14:54:41.378089.378089 client.py:127] Model loaded
DEBUG 01-07 14:54:41.378295.378295 cuda_h.py:19] end wait_experts_multi_device cost 0.0013363361358642578 seconds
DEBUG 01-07 14:54:41.378475.378475 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.378198.378198 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:41.379058.379058 mlpmodule.py:533] gpu group tensors cost 0.00048542022705078125 s
DEBUG 01-07 14:54:41.381778.381778 mlpmodule.py:566] gpu pad cost 0.0012402534484863281 s
DEBUG 01-07 14:54:41.381527.381527 mlpmodule.py:584] gpu group einsum cost 0.0005593299865722656 s
DEBUG 01-07 14:54:41.383721.383721 mlpmodule.py:656] gpu experts func einsum cost 0.004450798034667969 s
DEBUG 01-07 14:54:41.384684.384684 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:41.385626.385626 mlpmodule.py:533] gpu group tensors cost 0.0004775524139404297 s
DEBUG 01-07 14:54:41.385226.385226 mlpmodule.py:707]  experts func einsum cost 0.04708743095397949 s
DEBUG 01-07 14:54:41.386225.386225 mlpmodule.py:566] gpu pad cost 0.0013971328735351562 s
DEBUG 01-07 14:54:41.387859.387859 mlpmodule.py:584] gpu group einsum cost 0.00046133995056152344 s
DEBUG 01-07 14:54:41.389397.389397 mlpmodule.py:656] gpu experts func einsum cost 0.004522562026977539 s
DEBUG 01-07 14:54:41.389334.389334 cuda_h.py:19] end gpu_experts_multi_device cost 0.010401487350463867 seconds
DEBUG 01-07 14:54:41.389258.389258 cuda_h.py:19] end layer_moe_generate_multi_device_7 cost 0.0610814094543457 seconds
DEBUG 01-07 14:54:41.389306.389306 lmp.py:194] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-07 14:54:41.389545.389545 lmp.py:153] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-07 14:54:41.389526.389526 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 14:54:41.389805.389805 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 14:54:41.389225.389225 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.6226043701171875e-05 seconds
DEBUG 01-07 14:54:41.389034.389034 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 14:54:41.389299.389299 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.389427.389427 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.389323.389323 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.389034.389034 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.389003.389003 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.390960.390960 cuda_h.py:19] end allocate_cuda_memory cost 0.00028634071350097656 seconds
DEBUG 01-07 14:54:41.390671.390671 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.390262.390262 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.390323.390323 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.390880.390880 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ccda9df9-485e-4c07-9c5c-883c6ee03065
DEBUG 01-07 14:54:41.390559.390559 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.390335.390335 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.391874.391874 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ccda9df9-485e-4c07-9c5c-883c6ee03065
DEBUG 01-07 14:54:41.391565.391565 cuda_h.py:19] end load_into_gpu_async cost 0.0009250640869140625 seconds
DEBUG 01-07 14:54:41.391314.391314 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.391297.391297 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-07 14:54:41.391100.391100 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015294551849365234 seconds
INFO 01-07 14:54:41.391552.391552 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ccda9df9-485e-4c07-9c5c-883c6ee03065
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.394152.394152 cuda_h.py:19] end self_attn cost 0.0035605430603027344 seconds
DEBUG 01-07 14:54:41.394944.394944 cuda_h.py:19] end iln_self_attn_paln cost 0.004976034164428711 seconds
DEBUG 01-07 14:54:41.394197.394197 cuda_h.py:10] start layer_moe_generate_multi_device_8
DEBUG 01-07 14:54:41.394430.394430 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.395270.395270 cuda_h.py:19] end gate cost 0.0007257461547851562 seconds
DEBUG 01-07 14:54:41.395238.395238 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.395702.395702 lmp.py:744] 
DEBUG 01-07 14:54:41.395702.395702 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.396319.396319 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.396923.396923 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.396950.396950 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.396308.396308 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.396474.396474 lmp.py:749] 
DEBUG 01-07 14:54:41.396474.396474 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.396594.396594 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.396436.396436 lmp.py:767]   Expert 38 |     13 | CPU
DEBUG 01-07 14:54:41.396317.396317 lmp.py:767]   Expert 39 |     61 | CPU
DEBUG 01-07 14:54:41.396483.396483 lmp.py:767]   Expert  7 |     71 | CPU
DEBUG 01-07 14:54:41.396411.396411 lmp.py:767]   Expert 30 |     77 | CPU
DEBUG 01-07 14:54:41.396624.396624 lmp.py:767]   Expert 24 |     93 | CPU
DEBUG 01-07 14:54:41.396551.396551 lmp.py:767]   Expert 14 |     94 | CPU
DEBUG 01-07 14:54:41.396002.396002 lmp.py:767]   Expert 27 |     94 | CPU
DEBUG 01-07 14:54:41.396122.396122 lmp.py:767]   Expert 36 |     94 | CPU
DEBUG 01-07 14:54:41.396765.396765 lmp.py:767]   Expert 17 |     99 | CPU
DEBUG 01-07 14:54:41.396931.396931 lmp.py:767]   Expert 32 |    101 | CPU
DEBUG 01-07 14:54:41.396097.396097 lmp.py:767]   Expert 40 |    101 | CPU
DEBUG 01-07 14:54:41.396502.396502 lmp.py:767]   Expert 16 |    104 | CPU
DEBUG 01-07 14:54:41.396191.396191 lmp.py:767]   Expert 18 |    107 | CPU
DEBUG 01-07 14:54:41.396642.396642 lmp.py:767]   Expert 48 |    109 | CPU
DEBUG 01-07 14:54:41.396815.396815 lmp.py:767]   Expert 12 |    114 | CPU
DEBUG 01-07 14:54:41.396220.396220 lmp.py:767]   Expert  1 |    116 | CPU
DEBUG 01-07 14:54:41.396670.396670 lmp.py:767]   Expert  6 |    125 | CPU
DEBUG 01-07 14:54:41.396121.396121 lmp.py:767]   Expert 59 |    133 | CPU
DEBUG 01-07 14:54:41.396572.396572 lmp.py:767]   Expert  0 |    140 | CPU
DEBUG 01-07 14:54:41.396646.396646 lmp.py:767]   Expert 42 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396719.396719 lmp.py:767]   Expert 53 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396793.396793 lmp.py:767]   Expert 51 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396674.396674 lmp.py:767]   Expert 22 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396032.396032 lmp.py:767]   Expert  8 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396675.396675 lmp.py:767]   Expert 60 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396080.396080 lmp.py:767]   Expert 44 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396723.396723 lmp.py:767]   Expert 15 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396889.396889 lmp.py:767]   Expert 29 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396293.396293 lmp.py:767]   Expert 54 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396460.396460 lmp.py:767]   Expert 35 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396626.396626 lmp.py:767]   Expert 33 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396030.396030 lmp.py:767]   Expert 47 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396865.396865 lmp.py:767]   Expert 34 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396747.396747 lmp.py:767]   Expert  9 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396628.396628 lmp.py:767]   Expert 19 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396271.396271 lmp.py:767]   Expert  3 |    195 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396153.396153 lmp.py:767]   Expert 56 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396557.396557 lmp.py:767]   Expert 21 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396723.396723 lmp.py:767]   Expert 46 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396889.396889 lmp.py:767]   Expert 20 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396055.396055 lmp.py:767]   Expert 45 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396460.396460 lmp.py:767]   Expert 49 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396388.396388 lmp.py:767]   Expert 28 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396792.396792 lmp.py:767]   Expert 57 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396482.396482 lmp.py:767]   Expert  2 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396648.396648 lmp.py:767]   Expert 43 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396052.396052 lmp.py:767]   Expert  4 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.396934.396934 lmp.py:767]   Expert 13 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.396577.396577 lmp.py:767]   Expert 10 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397458.397458 lmp.py:767]   Expert 50 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397386.397386 lmp.py:767]   Expert 41 |    243 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397552.397552 lmp.py:767]   Expert 26 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397718.397718 lmp.py:767]   Expert 63 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397646.397646 lmp.py:767]   Expert 37 |    263 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397050.397050 lmp.py:767]   Expert 61 |    269 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397455.397455 lmp.py:767]   Expert 31 |    273 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397383.397383 lmp.py:767]   Expert 52 |    304 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397549.397549 lmp.py:767]   Expert 58 |    324 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397953.397953 lmp.py:767]   Expert 62 |    326 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397835.397835 lmp.py:767]   Expert 55 |    341 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397478.397478 lmp.py:767]   Expert 11 |    380 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397121.397121 lmp.py:767]   Expert 23 |    381 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397240.397240 lmp.py:767]   Expert 25 |    403 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.397122.397122 lmp.py:767]   Expert  5 |    522 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.397811.397811 lmp.py:769] 
DEBUG 01-07 14:54:41.397811.397811 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.397977.397977 lmp.py:770]   CPU:   1846 tokens
DEBUG 01-07 14:54:41.397859.397859 lmp.py:774]   cuda:1:   5291 tokens (23 experts)
DEBUG 01-07 14:54:41.397263.397263 lmp.py:774]   cuda:2:   5151 tokens (22 experts)
DEBUG 01-07 14:54:41.397953.397953 lmp.py:775]   Total GPU:  10442 tokens
DEBUG 01-07 14:54:41.397403.397403 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.397403.397403 lmp.py:776] 
DEBUG 01-07 14:54:41.397815.397815 cuda_h.py:19] end experts_map_get cost 0.0017664432525634766 seconds
DEBUG 01-07 14:54:41.397650.397650 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.397188.397188 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.397106.397106 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.397041.397041 cuda_h.py:19] end allocate_cuda_memory cost 0.0004112720489501953 seconds
DEBUG 01-07 14:54:41.398136.398136 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.398084.398084 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.398655.398655 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.398020.398020 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f6c29a96-bad2-4963-bc00-586d312adae4
DEBUG 01-07 14:54:41.398529.398529 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.398533.398533 client.py:127] Model loaded
DEBUG 01-07 14:54:41.398078.398078 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.398838.398838 cuda_h.py:19] end restore2model cost 0.0003170967102050781 seconds
DEBUG 01-07 14:54:41.398508.398508 cuda_h.py:19] end sllm_worker_task cost 0.009028911590576172 seconds
INFO 01-07 14:54:41.398895.398895 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f6c29a96-bad2-4963-bc00-586d312adae4
DEBUG 01-07 14:54:41.399023.399023 cuda_h.py:19] end load_into_gpu_async cost 0.0009357929229736328 seconds
DEBUG 01-07 14:54:41.399010.399010 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.399649.399649 cuda_h.py:19] end restore_tensors2 cost 0.00027179718017578125 seconds
DEBUG 01-07 14:54:41.399141.399141 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001943349838256836 seconds
DEBUG 01-07 14:54:41.399427.399427 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.401624.401624 cuda_h.py:19] end restore2model cost 0.0019087791442871094 seconds
DEBUG 01-07 14:54:41.401388.401388 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.401239.401239 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.401320.401320 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-07 14:54:41.401918.401918 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.401574.401574 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.401330.401330 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.401219.401219 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 03d886cd-9c32-494b-bf9a-2820363621ac
DEBUG 01-07 14:54:41.402316.402316 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.402503.402503 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 03d886cd-9c32-494b-bf9a-2820363621ac
DEBUG 01-07 14:54:41.402995.402995 cuda_h.py:19] end load_into_gpu_async cost 0.0010809898376464844 seconds
DEBUG 01-07 14:54:41.402598.402598 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.403739.403739 cuda_h.py:19] end restore_tensors2 cost 0.00022029876708984375 seconds
DEBUG 01-07 14:54:41.403654.403654 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017826557159423828 seconds
DEBUG 01-07 14:54:41.403457.403457 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.405981.405981 cuda_h.py:19] end restore2model cost 0.0017981529235839844 seconds
DEBUG 01-07 14:54:41.405341.405341 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0077555179595947266 seconds
DEBUG 01-07 14:54:41.405183.405183 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.405523.405523 lmp.py:816] 
DEBUG 01-07 14:54:41.405523.405523 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.405882.405882 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:41.405724.405724 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.415479.415479 mlpmodule.py:749] group tensors cost 0.009762287139892578 s
DEBUG 01-07 14:54:41.417071.417071 mlpmodule.py:787] pad cost 0.0011417865753173828 s
DEBUG 01-07 14:54:41.417405.417405 mlpmodule.py:793] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-07 14:54:41.417031.417031 mlpmodule.py:798] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-07 14:54:41.426728.426728 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.426767.426767 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.426426.426426 mlpmodule.py:818] group_w3 first element: 0.0859375
WARNING 01-07 14:54:41.426073.426073 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.440090.440090 mlpmodule.py:838] group einsum cost 0.02345561981201172 s
DEBUG 01-07 14:54:41.441500.441500 mlpmodule.py:846] cpy2cputensor cost 0.0003986358642578125 s
DEBUG 01-07 14:54:41.443011.443011 cuda_h.py:19] end wait_cetm_experts cost 0.038580894470214844 seconds
DEBUG 01-07 14:54:41.444371.444371 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.444046.444046 cuda_h.py:19] end gpu_sexperts cost 0.0005269050598144531 seconds
DEBUG 01-07 14:54:41.444790.444790 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.444255.444255 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 14:54:41.444150.444150 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.444006.444006 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f6c29a96-bad2-4963-bc00-586d312adae4
INFO 01-07 14:54:41.445286.445286 client.py:127] Model loaded
INFO 01-07 14:54:41.445592.445592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 03d886cd-9c32-494b-bf9a-2820363621ac
INFO 01-07 14:54:41.446592.446592 client.py:127] Model loaded
DEBUG 01-07 14:54:41.446229.446229 cuda_h.py:19] end wait_experts_multi_device cost 0.001325368881225586 seconds
DEBUG 01-07 14:54:41.446601.446601 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.446516.446516 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:41.447342.447342 mlpmodule.py:533] gpu group tensors cost 0.00048279762268066406 s
DEBUG 01-07 14:54:41.448737.448737 mlpmodule.py:566] gpu pad cost 0.0012488365173339844 s
DEBUG 01-07 14:54:41.449003.449003 mlpmodule.py:584] gpu group einsum cost 0.0005524158477783203 s
DEBUG 01-07 14:54:41.451441.451441 mlpmodule.py:656] gpu experts func einsum cost 0.004419803619384766 s
DEBUG 01-07 14:54:41.451404.451404 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:41.452503.452503 mlpmodule.py:533] gpu group tensors cost 0.0004730224609375 s
DEBUG 01-07 14:54:41.453567.453567 mlpmodule.py:707]  experts func einsum cost 0.048009634017944336 s
DEBUG 01-07 14:54:41.453664.453664 mlpmodule.py:566] gpu pad cost 0.0013768672943115234 s
DEBUG 01-07 14:54:41.454669.454669 mlpmodule.py:584] gpu group einsum cost 0.00045371055603027344 s
DEBUG 01-07 14:54:41.456340.456340 mlpmodule.py:656] gpu experts func einsum cost 0.004496574401855469 s
DEBUG 01-07 14:54:41.456721.456721 cuda_h.py:19] end gpu_experts_multi_device cost 0.01027679443359375 seconds
DEBUG 01-07 14:54:41.456697.456697 cuda_h.py:19] end layer_moe_generate_multi_device_8 cost 0.06178641319274902 seconds
DEBUG 01-07 14:54:41.456268.456268 lmp.py:194] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-07 14:54:41.456177.456177 lmp.py:153] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-07 14:54:41.456827.456827 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 14:54:41.456583.456583 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 14:54:41.456843.456843 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.5510787963867188e-05 seconds
DEBUG 01-07 14:54:41.456638.456638 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.3882598876953125e-05 seconds
DEBUG 01-07 14:54:41.456996.456996 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.457640.457640 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.457682.457682 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.457738.457738 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.457919.457919 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.457975.457975 cuda_h.py:19] end allocate_cuda_memory cost 0.0002524852752685547 seconds
DEBUG 01-07 14:54:41.457567.457567 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.457853.457853 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.457199.457199 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.457756.457756 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dee21514-f2de-4e4f-acda-8d17ebc72e6b
DEBUG 01-07 14:54:41.457673.457673 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.458688.458688 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.458841.458841 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dee21514-f2de-4e4f-acda-8d17ebc72e6b
DEBUG 01-07 14:54:41.458492.458492 cuda_h.py:19] end load_into_gpu_async cost 0.0008919239044189453 seconds
DEBUG 01-07 14:54:41.458288.458288 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.458364.458364 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 14:54:41.458166.458166 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014765262603759766 seconds
INFO 01-07 14:54:41.458380.458380 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dee21514-f2de-4e4f-acda-8d17ebc72e6b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.461806.461806 cuda_h.py:19] end self_attn cost 0.0036787986755371094 seconds
DEBUG 01-07 14:54:41.462764.462764 cuda_h.py:19] end iln_self_attn_paln cost 0.005102872848510742 seconds
DEBUG 01-07 14:54:41.462733.462733 cuda_h.py:10] start layer_moe_generate_multi_device_9
DEBUG 01-07 14:54:41.462442.462442 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.462259.462259 cuda_h.py:19] end gate cost 0.0006403923034667969 seconds
DEBUG 01-07 14:54:41.462897.462897 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.463553.463553 lmp.py:744] 
DEBUG 01-07 14:54:41.463553.463553 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.463455.463455 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.463297.463297 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.463562.463562 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.463682.463682 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.463848.463848 lmp.py:749] 
DEBUG 01-07 14:54:41.463848.463848 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.463730.463730 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.463048.463048 lmp.py:767]   Expert 24 |     39 | CPU
DEBUG 01-07 14:54:41.463645.463645 lmp.py:767]   Expert  2 |     44 | CPU
DEBUG 01-07 14:54:41.463050.463050 lmp.py:767]   Expert 32 |     66 | CPU
DEBUG 01-07 14:54:41.463693.463693 lmp.py:767]   Expert 19 |     69 | CPU
DEBUG 01-07 14:54:41.463620.463620 lmp.py:767]   Expert 26 |     70 | CPU
DEBUG 01-07 14:54:41.463310.463310 lmp.py:767]   Expert 50 |     72 | CPU
DEBUG 01-07 14:54:41.463760.463760 lmp.py:767]   Expert 15 |     80 | CPU
DEBUG 01-07 14:54:41.463450.463450 lmp.py:767]   Expert 28 |     80 | CPU
DEBUG 01-07 14:54:41.463616.463616 lmp.py:767]   Expert  4 |     83 | CPU
DEBUG 01-07 14:54:41.463782.463782 lmp.py:767]   Expert  7 |     83 | CPU
DEBUG 01-07 14:54:41.463187.463187 lmp.py:767]   Expert 60 |     85 | CPU
DEBUG 01-07 14:54:41.463353.463353 lmp.py:767]   Expert 59 |     89 | CPU
DEBUG 01-07 14:54:41.463757.463757 lmp.py:767]   Expert 23 |     95 | CPU
DEBUG 01-07 14:54:41.463208.463208 lmp.py:767]   Expert 49 |     97 | CPU
DEBUG 01-07 14:54:41.463659.463659 lmp.py:767]   Expert  5 |    105 | CPU
DEBUG 01-07 14:54:41.463587.463587 lmp.py:767]   Expert 12 |    105 | CPU
DEBUG 01-07 14:54:41.463038.463038 lmp.py:767]   Expert 27 |    108 | CPU
DEBUG 01-07 14:54:41.463727.463727 lmp.py:767]   Expert 10 |    112 | CPU
DEBUG 01-07 14:54:41.463416.463416 lmp.py:767]   Expert 41 |    117 | CPU
DEBUG 01-07 14:54:41.463298.463298 lmp.py:767]   Expert  3 |    125 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.463941.463941 lmp.py:767]   Expert 16 |    128 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.463014.463014 lmp.py:767]   Expert 20 |    128 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.463611.463611 lmp.py:767]   Expert 40 |    128 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.463731.463731 lmp.py:767]   Expert 13 |    129 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.463612.463612 lmp.py:767]   Expert 25 |    129 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.463732.463732 lmp.py:767]   Expert 37 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.463375.463375 lmp.py:767]   Expert 17 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.463779.463779 lmp.py:767]   Expert 35 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.463661.463661 lmp.py:767]   Expert 47 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.463065.463065 lmp.py:767]   Expert 22 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464708.464708 lmp.py:767]   Expert 53 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464590.464590 lmp.py:767]   Expert 39 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464756.464756 lmp.py:767]   Expert 44 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464637.464637 lmp.py:767]   Expert 38 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464757.464757 lmp.py:767]   Expert 36 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464638.464638 lmp.py:767]   Expert 52 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464997.464997 lmp.py:767]   Expert 18 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464878.464878 lmp.py:767]   Expert 58 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464521.464521 lmp.py:767]   Expert 62 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464925.464925 lmp.py:767]   Expert 48 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464568.464568 lmp.py:767]   Expert 11 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464450.464450 lmp.py:767]   Expert 14 |    219 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464854.464854 lmp.py:767]   Expert 30 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464021.464021 lmp.py:767]   Expert  1 |    230 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464425.464425 lmp.py:767]   Expert 45 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464306.464306 lmp.py:767]   Expert 31 |    238 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464711.464711 lmp.py:767]   Expert 42 |    238 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464592.464592 lmp.py:767]   Expert 51 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464712.464712 lmp.py:767]   Expert  6 |    242 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464832.464832 lmp.py:767]   Expert 29 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464190.464190 lmp.py:767]   Expert 34 |    269 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464787.464787 lmp.py:767]   Expert 33 |    274 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464821.464821 lmp.py:767]   Expert 57 |    294 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464464.464464 lmp.py:767]   Expert 61 |    306 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464107.464107 lmp.py:767]   Expert 43 |    309 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464750.464750 lmp.py:767]   Expert  0 |    322 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464916.464916 lmp.py:767]   Expert 46 |    359 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464321.464321 lmp.py:767]   Expert  8 |    380 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464487.464487 lmp.py:767]   Expert  9 |    390 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464891.464891 lmp.py:767]   Expert 56 |    392 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464011.464011 lmp.py:767]   Expert 54 |    394 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464131.464131 lmp.py:767]   Expert 63 |    409 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464012.464012 lmp.py:767]   Expert 55 |    426 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.464132.464132 lmp.py:767]   Expert 21 |    485 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.464821.464821 lmp.py:769] 
DEBUG 01-07 14:54:41.464821.464821 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.464703.464703 lmp.py:770]   CPU:   1599 tokens
DEBUG 01-07 14:54:41.464823.464823 lmp.py:774]   cuda:1:   5288 tokens (22 experts)
DEBUG 01-07 14:54:41.464466.464466 lmp.py:774]   cuda:2:   5401 tokens (23 experts)
DEBUG 01-07 14:54:41.464155.464155 lmp.py:775]   Total GPU:  10689 tokens
DEBUG 01-07 14:54:41.464367.464367 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.464367.464367 lmp.py:776] 
DEBUG 01-07 14:54:41.464017.464017 cuda_h.py:19] end experts_map_get cost 0.0017805099487304688 seconds
DEBUG 01-07 14:54:41.464375.464375 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.464913.464913 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.464394.464394 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.465846.465846 cuda_h.py:19] end allocate_cuda_memory cost 0.0002319812774658203 seconds
DEBUG 01-07 14:54:41.465451.465451 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.465968.465968 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.465354.465354 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.465719.465719 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 616e9b62-a38a-47a9-899e-0e3aedb5c1fe
DEBUG 01-07 14:54:41.465698.465698 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.465886.465886 client.py:127] Model loaded
DEBUG 01-07 14:54:41.465683.465683 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.466108.466108 cuda_h.py:19] end restore2model cost 0.0004138946533203125 seconds
DEBUG 01-07 14:54:41.466699.466699 cuda_h.py:19] end sllm_worker_task cost 0.009142398834228516 seconds
INFO 01-07 14:54:41.466943.466943 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 616e9b62-a38a-47a9-899e-0e3aedb5c1fe
DEBUG 01-07 14:54:41.466925.466925 cuda_h.py:19] end load_into_gpu_async cost 0.0012650489807128906 seconds
DEBUG 01-07 14:54:41.466674.466674 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.466790.466790 cuda_h.py:19] end restore_tensors2 cost 0.0002715587615966797 seconds
DEBUG 01-07 14:54:41.466420.466420 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020716190338134766 seconds
DEBUG 01-07 14:54:41.466037.466037 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.468735.468735 cuda_h.py:19] end restore2model cost 0.0018215179443359375 seconds
DEBUG 01-07 14:54:41.468453.468453 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.468165.468165 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.469007.469007 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-07 14:54:41.469751.469751 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.469123.469123 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.469309.469309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.469720.469720 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 834f9d92-5b64-44e5-82e9-901e27f68158
DEBUG 01-07 14:54:41.469202.469202 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.470951.470951 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 834f9d92-5b64-44e5-82e9-901e27f68158
DEBUG 01-07 14:54:41.470920.470920 cuda_h.py:19] end load_into_gpu_async cost 0.001252889633178711 seconds
DEBUG 01-07 14:54:41.470192.470192 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.470565.470565 cuda_h.py:19] end restore_tensors2 cost 0.00025010108947753906 seconds
DEBUG 01-07 14:54:41.470673.470673 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019958019256591797 seconds
DEBUG 01-07 14:54:41.470952.470952 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.472572.472572 cuda_h.py:19] end restore2model cost 0.00186920166015625 seconds
DEBUG 01-07 14:54:41.472739.472739 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008075952529907227 seconds
DEBUG 01-07 14:54:41.472343.472343 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.472491.472491 lmp.py:816] 
DEBUG 01-07 14:54:41.472491.472491 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.472943.472943 cuda_h.py:19] end cpu_experts_submit cost 0.00010371208190917969 seconds
DEBUG 01-07 14:54:41.473831.473831 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.479770.479770 mlpmodule.py:749] group tensors cost 0.005968809127807617 s
DEBUG 01-07 14:54:41.481917.481917 mlpmodule.py:787] pad cost 0.0013930797576904297 s
DEBUG 01-07 14:54:41.481418.481418 mlpmodule.py:793] create cpu tensor cost 4.982948303222656e-05 s
DEBUG 01-07 14:54:41.481494.481494 mlpmodule.py:798] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-07 14:54:41.490476.490476 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.490866.490866 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.490101.490101 mlpmodule.py:818] group_w3 first element: 0.0157470703125
WARNING 01-07 14:54:41.490039.490039 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.505127.505127 mlpmodule.py:838] group einsum cost 0.024149656295776367 s
DEBUG 01-07 14:54:41.506240.506240 mlpmodule.py:846] cpy2cputensor cost 0.0004107952117919922 s
DEBUG 01-07 14:54:41.509156.509156 cuda_h.py:19] end wait_cetm_experts cost 0.03597855567932129 seconds
DEBUG 01-07 14:54:41.509702.509702 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.509084.509084 cuda_h.py:19] end gpu_sexperts cost 0.0004870891571044922 seconds
DEBUG 01-07 14:54:41.509636.509636 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.509909.509909 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.288818359375e-05 seconds
DEBUG 01-07 14:54:41.509135.509135 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.509799.509799 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 616e9b62-a38a-47a9-899e-0e3aedb5c1fe
INFO 01-07 14:54:41.511063.511063 client.py:127] Model loaded
INFO 01-07 14:54:41.511376.511376 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 834f9d92-5b64-44e5-82e9-901e27f68158
INFO 01-07 14:54:41.511041.511041 client.py:127] Model loaded
DEBUG 01-07 14:54:41.511771.511771 cuda_h.py:19] end wait_experts_multi_device cost 0.0019481182098388672 seconds
DEBUG 01-07 14:54:41.511951.511951 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.511489.511489 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.513297.513297 mlpmodule.py:533] gpu group tensors cost 0.000507354736328125 s
DEBUG 01-07 14:54:41.514547.514547 mlpmodule.py:566] gpu pad cost 0.0012793540954589844 s
DEBUG 01-07 14:54:41.515211.515211 mlpmodule.py:584] gpu group einsum cost 0.0005655288696289062 s
DEBUG 01-07 14:54:41.517150.517150 mlpmodule.py:656] gpu experts func einsum cost 0.004613399505615234 s
DEBUG 01-07 14:54:41.517133.517133 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.518881.518881 mlpmodule.py:533] gpu group tensors cost 0.0004684925079345703 s
DEBUG 01-07 14:54:41.518396.518396 mlpmodule.py:707]  experts func einsum cost 0.04524683952331543 s
DEBUG 01-07 14:54:41.519166.519166 mlpmodule.py:566] gpu pad cost 0.0013434886932373047 s
DEBUG 01-07 14:54:41.520205.520205 mlpmodule.py:584] gpu group einsum cost 0.0004646778106689453 s
DEBUG 01-07 14:54:41.522071.522071 mlpmodule.py:656] gpu experts func einsum cost 0.004366159439086914 s
DEBUG 01-07 14:54:41.522445.522445 cuda_h.py:19] end gpu_experts_multi_device cost 0.010377883911132812 seconds
DEBUG 01-07 14:54:41.522567.522567 cuda_h.py:19] end layer_moe_generate_multi_device_9 cost 0.06010174751281738 seconds
DEBUG 01-07 14:54:41.522880.522880 lmp.py:194] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-07 14:54:41.522689.522689 lmp.py:153] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-07 14:54:41.522882.522882 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 14:54:41.522207.522207 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 14:54:41.522375.522375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 14:54:41.522693.522693 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.555152893066406e-05 seconds
DEBUG 01-07 14:54:41.522336.522336 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.522650.522650 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.522784.522784 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.522071.522071 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.522093.522093 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.523938.523938 cuda_h.py:19] end allocate_cuda_memory cost 0.0002734661102294922 seconds
DEBUG 01-07 14:54:41.523669.523669 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.523478.523478 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.523440.523440 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.523235.523235 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d08eaa0-2e2b-4327-8d31-095c3e63ad76
DEBUG 01-07 14:54:41.523244.523244 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.523736.523736 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.524934.524934 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d08eaa0-2e2b-4327-8d31-095c3e63ad76
DEBUG 01-07 14:54:41.524605.524605 cuda_h.py:19] end load_into_gpu_async cost 0.0014262199401855469 seconds
DEBUG 01-07 14:54:41.524023.524023 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.524245.524245 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 14:54:41.524630.524630 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020301342010498047 seconds
INFO 01-07 14:54:41.525076.525076 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d08eaa0-2e2b-4327-8d31-095c3e63ad76
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.527878.527878 cuda_h.py:19] end self_attn cost 0.003380298614501953 seconds
DEBUG 01-07 14:54:41.527769.527769 cuda_h.py:19] end iln_self_attn_paln cost 0.004786014556884766 seconds
DEBUG 01-07 14:54:41.527976.527976 cuda_h.py:10] start layer_moe_generate_multi_device_10
DEBUG 01-07 14:54:41.527970.527970 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.528681.528681 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-07 14:54:41.528080.528080 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.528942.528942 lmp.py:744] 
DEBUG 01-07 14:54:41.528942.528942 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.528751.528751 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.528116.528116 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.528097.528097 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.528409.528409 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.528244.528244 lmp.py:749] 
DEBUG 01-07 14:54:41.528244.528244 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.528887.528887 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.528491.528491 lmp.py:767]   Expert 43 |     18 | CPU
DEBUG 01-07 14:54:41.528134.528134 lmp.py:767]   Expert 27 |     33 | CPU
DEBUG 01-07 14:54:41.528538.528538 lmp.py:767]   Expert 26 |     52 | CPU
DEBUG 01-07 14:54:41.528227.528227 lmp.py:767]   Expert 34 |     52 | CPU
DEBUG 01-07 14:54:41.528394.528394 lmp.py:767]   Expert  3 |     56 | CPU
DEBUG 01-07 14:54:41.528321.528321 lmp.py:767]   Expert 56 |     56 | CPU
DEBUG 01-07 14:54:41.529011.529011 lmp.py:767]   Expert  4 |     71 | CPU
DEBUG 01-07 14:54:41.529700.529700 lmp.py:767]   Expert 61 |     82 | CPU
DEBUG 01-07 14:54:41.529151.529151 lmp.py:767]   Expert 14 |     93 | CPU
DEBUG 01-07 14:54:41.529079.529079 lmp.py:767]   Expert 38 |     99 | CPU
DEBUG 01-07 14:54:41.529245.529245 lmp.py:767]   Expert  2 |    113 | CPU
DEBUG 01-07 14:54:41.529126.529126 lmp.py:767]   Expert 22 |    119 | CPU
DEBUG 01-07 14:54:41.529484.529484 lmp.py:767]   Expert 17 |    121 | CPU
DEBUG 01-07 14:54:41.529604.529604 lmp.py:767]   Expert 47 |    126 | CPU
DEBUG 01-07 14:54:41.529770.529770 lmp.py:767]   Expert 37 |    127 | CPU
DEBUG 01-07 14:54:41.529983.529983 lmp.py:767]   Expert 54 |    132 | CPU
DEBUG 01-07 14:54:41.529434.529434 lmp.py:767]   Expert 55 |    135 | CPU
DEBUG 01-07 14:54:41.529123.529123 lmp.py:767]   Expert 28 |    139 | CPU
DEBUG 01-07 14:54:41.529812.529812 lmp.py:767]   Expert 15 |    142 | CPU
DEBUG 01-07 14:54:41.529694.529694 lmp.py:767]   Expert  7 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529575.529575 lmp.py:767]   Expert 51 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529980.529980 lmp.py:767]   Expert 48 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529623.529623 lmp.py:767]   Expert 60 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529504.529504 lmp.py:767]   Expert  5 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529385.529385 lmp.py:767]   Expert 45 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529982.529982 lmp.py:767]   Expert 12 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529579.529579 lmp.py:767]   Expert 63 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529222.529222 lmp.py:767]   Expert 19 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529865.529865 lmp.py:767]   Expert  6 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529508.529508 lmp.py:767]   Expert 57 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529389.529389 lmp.py:767]   Expert 52 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529270.529270 lmp.py:767]   Expert 50 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529913.529913 lmp.py:767]   Expert 18 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529556.529556 lmp.py:767]   Expert 44 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529961.529961 lmp.py:767]   Expert 13 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529604.529604 lmp.py:767]   Expert 31 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529200.529200 lmp.py:767]   Expert 30 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529512.529512 lmp.py:767]   Expert 23 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529109.529109 lmp.py:767]   Expert 39 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529990.529990 lmp.py:767]   Expert 53 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529633.529633 lmp.py:767]   Expert 20 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529276.529276 lmp.py:767]   Expert 29 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529681.529681 lmp.py:767]   Expert 21 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529085.529085 lmp.py:767]   Expert 59 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529728.529728 lmp.py:767]   Expert 16 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529371.529371 lmp.py:767]   Expert 36 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529014.529014 lmp.py:767]   Expert 41 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529896.529896 lmp.py:767]   Expert 25 |    218 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529300.529300 lmp.py:767]   Expert 49 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529182.529182 lmp.py:767]   Expert 32 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529017.529017 lmp.py:767]   Expert 46 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529852.529852 lmp.py:767]   Expert 10 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529256.529256 lmp.py:767]   Expert 42 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529899.529899 lmp.py:767]   Expert  8 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529304.529304 lmp.py:767]   Expert 62 |    268 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529470.529470 lmp.py:767]   Expert 35 |    279 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529875.529875 lmp.py:767]   Expert  9 |    292 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529041.529041 lmp.py:767]   Expert 33 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529445.529445 lmp.py:767]   Expert 58 |    297 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529850.529850 lmp.py:767]   Expert 40 |    392 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.529254.529254 lmp.py:767]   Expert  0 |    428 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.529089.529089 lmp.py:767]   Expert 11 |    432 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.530401.530401 lmp.py:767]   Expert 24 |    566 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.530236.530236 lmp.py:767]   Expert  1 |    651 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.530926.530926 lmp.py:769] 
DEBUG 01-07 14:54:41.530926.530926 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.530853.530853 lmp.py:770]   CPU:   1766 tokens
DEBUG 01-07 14:54:41.530496.530496 lmp.py:774]   cuda:1:   5188 tokens (22 experts)
DEBUG 01-07 14:54:41.530663.530663 lmp.py:774]   cuda:2:   5334 tokens (23 experts)
DEBUG 01-07 14:54:41.530113.530113 lmp.py:775]   Total GPU:  10522 tokens
DEBUG 01-07 14:54:41.530564.530564 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.530564.530564 lmp.py:776] 
DEBUG 01-07 14:54:41.530737.530737 cuda_h.py:19] end experts_map_get cost 0.0017883777618408203 seconds
DEBUG 01-07 14:54:41.530857.530857 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.530203.530203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.530107.530107 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.531341.531341 cuda_h.py:19] end allocate_cuda_memory cost 0.0008063316345214844 seconds
DEBUG 01-07 14:54:41.531005.531005 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.531953.531953 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.531908.531908 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.531319.531319 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c6c39372-469c-4da4-ab4f-618102f78213
DEBUG 01-07 14:54:41.531484.531484 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.531282.531282 client.py:127] Model loaded
DEBUG 01-07 14:54:41.531218.531218 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.532846.532846 cuda_h.py:19] end restore2model cost 0.00032329559326171875 seconds
DEBUG 01-07 14:54:41.532138.532138 cuda_h.py:19] end sllm_worker_task cost 0.009325981140136719 seconds
INFO 01-07 14:54:41.533054.533054 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c6c39372-469c-4da4-ab4f-618102f78213
DEBUG 01-07 14:54:41.533851.533851 cuda_h.py:19] end load_into_gpu_async cost 0.0018880367279052734 seconds
DEBUG 01-07 14:54:41.533839.533839 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.533020.533020 cuda_h.py:19] end restore_tensors2 cost 0.0002493858337402344 seconds
DEBUG 01-07 14:54:41.533651.533651 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032563209533691406 seconds
DEBUG 01-07 14:54:41.533652.533652 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.535501.535501 cuda_h.py:19] end restore2model cost 0.0017933845520019531 seconds
DEBUG 01-07 14:54:41.535311.535311 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.535593.535593 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.535421.535421 cuda_h.py:19] end allocate_cuda_memory cost 0.0001926422119140625 seconds
DEBUG 01-07 14:54:41.535066.535066 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.535722.535722 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.535054.535054 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.535750.535750 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 438b7dd2-bc24-408c-b22d-a69a90df4361
DEBUG 01-07 14:54:41.536086.536086 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.537212.537212 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 438b7dd2-bc24-408c-b22d-a69a90df4361
DEBUG 01-07 14:54:41.537181.537181 cuda_h.py:19] end load_into_gpu_async cost 0.0016355514526367188 seconds
DEBUG 01-07 14:54:41.537546.537546 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.537906.537906 cuda_h.py:19] end restore_tensors2 cost 0.00024127960205078125 seconds
DEBUG 01-07 14:54:41.537728.537728 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023527145385742188 seconds
DEBUG 01-07 14:54:41.537531.537531 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.539667.539667 cuda_h.py:19] end restore2model cost 0.0018646717071533203 seconds
DEBUG 01-07 14:54:41.539735.539735 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009579896926879883 seconds
DEBUG 01-07 14:54:41.539530.539530 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.539348.539348 lmp.py:816] 
DEBUG 01-07 14:54:41.539348.539348 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.539230.539230 cuda_h.py:19] end cpu_experts_submit cost 0.00010514259338378906 seconds
DEBUG 01-07 14:54:41.539641.539641 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.552410.552410 mlpmodule.py:749] group tensors cost 0.011953115463256836 s
DEBUG 01-07 14:54:41.553816.553816 mlpmodule.py:787] pad cost 0.001032114028930664 s
DEBUG 01-07 14:54:41.553945.553945 mlpmodule.py:793] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-07 14:54:41.554133.554133 mlpmodule.py:798] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-07 14:54:41.563745.563745 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.563751.563751 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.563178.563178 mlpmodule.py:818] group_w3 first element: -0.0213623046875
WARNING 01-07 14:54:41.563971.563971 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.578789.578789 mlpmodule.py:838] group einsum cost 0.02425098419189453 s
DEBUG 01-07 14:54:41.578114.578114 mlpmodule.py:846] cpy2cputensor cost 0.0004372596740722656 s
DEBUG 01-07 14:54:41.582038.582038 cuda_h.py:19] end wait_cetm_experts cost 0.042450666427612305 seconds
DEBUG 01-07 14:54:41.582319.582319 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.583821.583821 cuda_h.py:19] end gpu_sexperts cost 0.0005052089691162109 seconds
DEBUG 01-07 14:54:41.583611.583611 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.583362.583362 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.288818359375e-05 seconds
DEBUG 01-07 14:54:41.583064.583064 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.583251.583251 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c6c39372-469c-4da4-ab4f-618102f78213
INFO 01-07 14:54:41.584490.584490 client.py:127] Model loaded
INFO 01-07 14:54:41.584180.584180 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 438b7dd2-bc24-408c-b22d-a69a90df4361
INFO 01-07 14:54:41.585493.585493 client.py:127] Model loaded
DEBUG 01-07 14:54:41.585806.585806 cuda_h.py:19] end wait_experts_multi_device cost 0.0019481182098388672 seconds
DEBUG 01-07 14:54:41.585655.585655 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.585570.585570 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.586718.586718 mlpmodule.py:533] gpu group tensors cost 0.0005130767822265625 s
DEBUG 01-07 14:54:41.587028.587028 mlpmodule.py:566] gpu pad cost 0.0012927055358886719 s
DEBUG 01-07 14:54:41.588574.588574 mlpmodule.py:584] gpu group einsum cost 0.0006201267242431641 s
DEBUG 01-07 14:54:41.590452.590452 mlpmodule.py:656] gpu experts func einsum cost 0.004634857177734375 s
DEBUG 01-07 14:54:41.590276.590276 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.591063.591063 mlpmodule.py:533] gpu group tensors cost 0.00046181678771972656 s
DEBUG 01-07 14:54:41.591034.591034 mlpmodule.py:707]  experts func einsum cost 0.051757097244262695 s
DEBUG 01-07 14:54:41.593753.593753 mlpmodule.py:566] gpu pad cost 0.0013604164123535156 s
DEBUG 01-07 14:54:41.593112.593112 mlpmodule.py:584] gpu group einsum cost 0.00035881996154785156 s
DEBUG 01-07 14:54:41.595312.595312 mlpmodule.py:656] gpu experts func einsum cost 0.003947734832763672 s
DEBUG 01-07 14:54:41.595878.595878 cuda_h.py:19] end gpu_experts_multi_device cost 0.010003328323364258 seconds
DEBUG 01-07 14:54:41.595126.595126 cuda_h.py:19] end layer_moe_generate_multi_device_10 cost 0.06774401664733887 seconds
DEBUG 01-07 14:54:41.595035.595035 lmp.py:194] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-07 14:54:41.595242.595242 lmp.py:153] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-07 14:54:41.595223.595223 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 14:54:41.595787.595787 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 14:54:41.595762.595762 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 14:54:41.595293.595293 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.152557373046875e-05 seconds
DEBUG 01-07 14:54:41.595651.595651 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.595997.595997 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.595054.595054 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.596247.596247 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.596827.596827 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.596401.596401 cuda_h.py:19] end allocate_cuda_memory cost 0.0002796649932861328 seconds
DEBUG 01-07 14:54:41.596470.596470 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.596279.596279 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.596578.596578 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.596612.596612 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3ddc5fde-46aa-4c49-933f-2e36931b2327
DEBUG 01-07 14:54:41.596906.596906 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.596769.596769 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.597313.597313 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3ddc5fde-46aa-4c49-933f-2e36931b2327
DEBUG 01-07 14:54:41.598434.598434 cuda_h.py:19] end load_into_gpu_async cost 0.0014832019805908203 seconds
DEBUG 01-07 14:54:41.598992.598992 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.598975.598975 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 14:54:41.598777.598777 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002092123031616211 seconds
INFO 01-07 14:54:41.598037.598037 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3ddc5fde-46aa-4c49-933f-2e36931b2327
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.600746.600746 cuda_h.py:19] end self_attn cost 0.003398895263671875 seconds
DEBUG 01-07 14:54:41.600412.600412 cuda_h.py:19] end iln_self_attn_paln cost 0.004823446273803711 seconds
DEBUG 01-07 14:54:41.600903.600903 cuda_h.py:10] start layer_moe_generate_multi_device_11
DEBUG 01-07 14:54:41.600805.600805 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.601606.601606 cuda_h.py:19] end gate cost 0.0007328987121582031 seconds
DEBUG 01-07 14:54:41.601482.601482 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.602091.602091 lmp.py:744] 
DEBUG 01-07 14:54:41.602091.602091 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.602516.602516 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.602835.602835 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.602147.602147 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.602267.602267 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.602433.602433 lmp.py:749] 
DEBUG 01-07 14:54:41.602433.602433 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.602314.602314 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.602203.602203 lmp.py:767]   Expert 39 |     15 | CPU
DEBUG 01-07 14:54:41.602845.602845 lmp.py:767]   Expert 13 |     20 | CPU
DEBUG 01-07 14:54:41.602773.602773 lmp.py:767]   Expert 49 |     40 | CPU
DEBUG 01-07 14:54:41.602224.602224 lmp.py:767]   Expert 35 |     49 | CPU
DEBUG 01-07 14:54:41.602913.602913 lmp.py:767]   Expert 19 |     63 | CPU
DEBUG 01-07 14:54:41.602887.602887 lmp.py:767]   Expert 26 |     73 | CPU
DEBUG 01-07 14:54:41.602100.602100 lmp.py:767]   Expert 32 |     74 | CPU
DEBUG 01-07 14:54:41.602312.602312 lmp.py:767]   Expert  9 |     75 | CPU
DEBUG 01-07 14:54:41.602286.602286 lmp.py:767]   Expert 41 |     80 | CPU
DEBUG 01-07 14:54:41.602499.602499 lmp.py:767]   Expert 33 |     82 | CPU
DEBUG 01-07 14:54:41.602188.602188 lmp.py:767]   Expert 23 |     85 | CPU
DEBUG 01-07 14:54:41.602639.602639 lmp.py:767]   Expert 31 |     88 | CPU
DEBUG 01-07 14:54:41.602090.602090 lmp.py:767]   Expert 46 |     89 | CPU
DEBUG 01-07 14:54:41.602302.602302 lmp.py:767]   Expert 18 |     94 | CPU
DEBUG 01-07 14:54:41.602038.602038 lmp.py:767]   Expert 38 |     97 | CPU
DEBUG 01-07 14:54:41.602012.602012 lmp.py:767]   Expert  6 |    102 | CPU
DEBUG 01-07 14:54:41.602986.602986 lmp.py:767]   Expert 17 |    102 | CPU
DEBUG 01-07 14:54:41.602722.602722 lmp.py:767]   Expert  3 |    106 | CPU
DEBUG 01-07 14:54:41.602696.602696 lmp.py:767]   Expert 20 |    121 | CPU
DEBUG 01-07 14:54:41.602862.602862 lmp.py:767]   Expert 40 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602505.602505 lmp.py:767]   Expert 61 |    131 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602433.602433 lmp.py:767]   Expert 50 |    132 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602645.602645 lmp.py:767]   Expert 43 |    134 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602526.602526 lmp.py:767]   Expert 62 |    134 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602693.602693 lmp.py:767]   Expert 15 |    135 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602766.602766 lmp.py:767]   Expert 16 |    136 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602124.602124 lmp.py:767]   Expert 44 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602198.602198 lmp.py:767]   Expert  2 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602079.602079 lmp.py:767]   Expert 59 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602484.602484 lmp.py:767]   Expert 42 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602888.602888 lmp.py:767]   Expert 63 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602054.602054 lmp.py:767]   Expert 36 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602697.602697 lmp.py:767]   Expert 10 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602102.602102 lmp.py:767]   Expert  5 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602507.602507 lmp.py:767]   Expert 34 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602388.602388 lmp.py:767]   Expert 27 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602031.602031 lmp.py:767]   Expert 52 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602912.602912 lmp.py:767]   Expert 45 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602794.602794 lmp.py:767]   Expert 60 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602914.602914 lmp.py:767]   Expert 48 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602556.602556 lmp.py:767]   Expert 51 |    215 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602961.602961 lmp.py:767]   Expert 56 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602604.602604 lmp.py:767]   Expert 24 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.602009.602009 lmp.py:767]   Expert 53 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602413.602413 lmp.py:767]   Expert  7 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602818.602818 lmp.py:767]   Expert  8 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602222.602222 lmp.py:767]   Expert 47 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.602865.602865 lmp.py:767]   Expert 57 |    254 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603985.603985 lmp.py:767]   Expert 29 |    263 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603105.603105 lmp.py:767]   Expert 21 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603463.603463 lmp.py:767]   Expert  4 |    279 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603821.603821 lmp.py:767]   Expert 14 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603703.603703 lmp.py:767]   Expert  0 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603107.603107 lmp.py:767]   Expert 55 |    314 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603512.603512 lmp.py:767]   Expert 22 |    315 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603916.603916 lmp.py:767]   Expert  1 |    318 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603082.603082 lmp.py:767]   Expert 58 |    318 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603725.603725 lmp.py:767]   Expert 37 |    322 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603130.603130 lmp.py:767]   Expert 54 |    335 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603535.603535 lmp.py:767]   Expert 28 |    356 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603654.603654 lmp.py:767]   Expert 12 |    382 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603251.603251 lmp.py:767]   Expert 25 |    396 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603371.603371 lmp.py:767]   Expert 11 |    404 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.603252.603252 lmp.py:767]   Expert 30 |    834 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.603703.603703 lmp.py:769] 
DEBUG 01-07 14:54:41.603703.603703 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.603108.603108 lmp.py:770]   CPU:   1455 tokens
DEBUG 01-07 14:54:41.603989.603989 lmp.py:774]   cuda:1:   5416 tokens (22 experts)
DEBUG 01-07 14:54:41.603632.603632 lmp.py:774]   cuda:2:   5417 tokens (23 experts)
DEBUG 01-07 14:54:41.603083.603083 lmp.py:775]   Total GPU:  10833 tokens
DEBUG 01-07 14:54:41.603772.603772 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.603772.603772 lmp.py:776] 
DEBUG 01-07 14:54:41.603945.603945 cuda_h.py:19] end experts_map_get cost 0.0017535686492919922 seconds
DEBUG 01-07 14:54:41.603065.603065 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.603888.603888 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.603938.603938 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.604709.604709 cuda_h.py:19] end allocate_cuda_memory cost 0.0008525848388671875 seconds
DEBUG 01-07 14:54:41.604519.604519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.604421.604421 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.604753.604753 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.604165.604165 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 994d4fc3-ce11-42a9-be0a-d9453d81ade2
DEBUG 01-07 14:54:41.604521.604521 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.604718.604718 client.py:127] Model loaded
DEBUG 01-07 14:54:41.604184.604184 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.605543.605543 cuda_h.py:19] end restore2model cost 0.00039958953857421875 seconds
DEBUG 01-07 14:54:41.605750.605750 cuda_h.py:19] end sllm_worker_task cost 0.009472131729125977 seconds
INFO 01-07 14:54:41.605103.605103 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 994d4fc3-ce11-42a9-be0a-d9453d81ade2
DEBUG 01-07 14:54:41.605801.605801 cuda_h.py:19] end load_into_gpu_async cost 0.0010509490966796875 seconds
DEBUG 01-07 14:54:41.605073.605073 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.605685.605685 cuda_h.py:19] end restore_tensors2 cost 0.0002510547637939453 seconds
DEBUG 01-07 14:54:41.605978.605978 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002466440200805664 seconds
DEBUG 01-07 14:54:41.605787.605787 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.607649.607649 cuda_h.py:19] end restore2model cost 0.0018024444580078125 seconds
DEBUG 01-07 14:54:41.607082.607082 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.607788.607788 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.608849.608849 cuda_h.py:19] end allocate_cuda_memory cost 0.00022292137145996094 seconds
DEBUG 01-07 14:54:41.608639.608639 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.608534.608534 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.608290.608290 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.608000.608000 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8808ce7a-9483-4c6b-8430-133349cf8201
DEBUG 01-07 14:54:41.608342.608342 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.609371.609371 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8808ce7a-9483-4c6b-8430-133349cf8201
DEBUG 01-07 14:54:41.609578.609578 cuda_h.py:19] end load_into_gpu_async cost 0.0011191368103027344 seconds
DEBUG 01-07 14:54:41.609658.609658 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.609747.609747 cuda_h.py:19] end restore_tensors2 cost 0.00025153160095214844 seconds
DEBUG 01-07 14:54:41.609378.609378 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018756389617919922 seconds
DEBUG 01-07 14:54:41.609657.609657 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.611117.611117 cuda_h.py:19] end restore2model cost 0.001857757568359375 seconds
DEBUG 01-07 14:54:41.611623.611623 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00832509994506836 seconds
DEBUG 01-07 14:54:41.611008.611008 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.611156.611156 lmp.py:816] 
DEBUG 01-07 14:54:41.611156.611156 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.611800.611800 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-07 14:54:41.611212.611212 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.618132.618132 mlpmodule.py:749] group tensors cost 0.006580352783203125 s
DEBUG 01-07 14:54:41.621907.621907 mlpmodule.py:787] pad cost 0.0017189979553222656 s
DEBUG 01-07 14:54:41.621534.621534 mlpmodule.py:793] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-07 14:54:41.621584.621584 mlpmodule.py:798] move to cpu cost 4.696846008300781e-05 s
DEBUG 01-07 14:54:41.630898.630898 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.630037.630037 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.630510.630510 mlpmodule.py:818] group_w3 first element: 0.01373291015625
WARNING 01-07 14:54:41.630541.630541 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.644048.644048 mlpmodule.py:838] group einsum cost 0.022859573364257812 s
DEBUG 01-07 14:54:41.645943.645943 mlpmodule.py:846] cpy2cputensor cost 0.000423431396484375 s
DEBUG 01-07 14:54:41.647806.647806 cuda_h.py:19] end wait_cetm_experts cost 0.03571891784667969 seconds
DEBUG 01-07 14:54:41.647975.647975 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.648662.648662 cuda_h.py:19] end gpu_sexperts cost 0.0005011558532714844 seconds
DEBUG 01-07 14:54:41.648102.648102 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.648236.648236 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:41.648131.648131 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.648894.648894 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 994d4fc3-ce11-42a9-be0a-d9453d81ade2
INFO 01-07 14:54:41.649721.649721 client.py:127] Model loaded
INFO 01-07 14:54:41.649981.649981 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8808ce7a-9483-4c6b-8430-133349cf8201
INFO 01-07 14:54:41.650904.650904 client.py:127] Model loaded
DEBUG 01-07 14:54:41.650918.650918 cuda_h.py:19] end wait_experts_multi_device cost 0.00191497802734375 seconds
DEBUG 01-07 14:54:41.650383.650383 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.650636.650636 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.651920.651920 mlpmodule.py:533] gpu group tensors cost 0.0004978179931640625 s
DEBUG 01-07 14:54:41.653105.653105 mlpmodule.py:566] gpu pad cost 0.0013034343719482422 s
DEBUG 01-07 14:54:41.653655.653655 mlpmodule.py:584] gpu group einsum cost 0.0005507469177246094 s
DEBUG 01-07 14:54:41.655751.655751 mlpmodule.py:656] gpu experts func einsum cost 0.004553318023681641 s
DEBUG 01-07 14:54:41.656430.656430 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.656720.656720 mlpmodule.py:707]  experts func einsum cost 0.04474472999572754 s
DEBUG 01-07 14:54:41.656155.656155 mlpmodule.py:533] gpu group tensors cost 0.0005891323089599609 s
DEBUG 01-07 14:54:41.658118.658118 mlpmodule.py:566] gpu pad cost 0.0011997222900390625 s
DEBUG 01-07 14:54:41.658843.658843 mlpmodule.py:584] gpu group einsum cost 0.00043964385986328125 s
DEBUG 01-07 14:54:41.660298.660298 mlpmodule.py:656] gpu experts func einsum cost 0.004281282424926758 s
DEBUG 01-07 14:54:41.660413.660413 cuda_h.py:19] end gpu_experts_multi_device cost 0.010177135467529297 seconds
DEBUG 01-07 14:54:41.660760.660760 cuda_h.py:19] end layer_moe_generate_multi_device_11 cost 0.059976816177368164 seconds
DEBUG 01-07 14:54:41.661842.661842 lmp.py:194] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-07 14:54:41.661367.661367 lmp.py:153] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-07 14:54:41.661824.661824 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 14:54:41.661388.661388 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 14:54:41.661079.661079 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.765655517578125e-05 seconds
DEBUG 01-07 14:54:41.661351.661351 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.602836608886719e-05 seconds
DEBUG 01-07 14:54:41.661948.661948 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.661022.661022 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.661680.661680 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.661557.661557 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.661109.661109 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.661317.661317 cuda_h.py:19] end allocate_cuda_memory cost 0.0002582073211669922 seconds
DEBUG 01-07 14:54:41.661836.661836 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.661307.661307 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.661938.661938 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.661733.661733 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d80c51b3-82b9-4a37-bad1-3ebc1e8f2bab
DEBUG 01-07 14:54:41.662504.662504 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.662420.662420 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.663359.663359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d80c51b3-82b9-4a37-bad1-3ebc1e8f2bab
DEBUG 01-07 14:54:41.663003.663003 cuda_h.py:19] end load_into_gpu_async cost 0.0013895034790039062 seconds
DEBUG 01-07 14:54:41.663798.663798 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.663782.663782 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 14:54:41.663346.663346 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001951456069946289 seconds
INFO 01-07 14:54:41.663367.663367 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d80c51b3-82b9-4a37-bad1-3ebc1e8f2bab
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.665723.665723 cuda_h.py:19] end self_attn cost 0.003462553024291992 seconds
DEBUG 01-07 14:54:41.666992.666992 cuda_h.py:19] end iln_self_attn_paln cost 0.004851102828979492 seconds
DEBUG 01-07 14:54:41.666722.666722 cuda_h.py:10] start layer_moe_generate_multi_device_12
DEBUG 01-07 14:54:41.666955.666955 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.667485.667485 cuda_h.py:19] end gate cost 0.0007801055908203125 seconds
DEBUG 01-07 14:54:41.667407.667407 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.667395.667395 lmp.py:744] 
DEBUG 01-07 14:54:41.667395.667395 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.667104.667104 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.667993.667993 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.667543.667543 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.667186.667186 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.667352.667352 lmp.py:749] 
DEBUG 01-07 14:54:41.667352.667352 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.667233.667233 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.667360.667360 lmp.py:767]   Expert 12 |     20 | CPU
DEBUG 01-07 14:54:41.667526.667526 lmp.py:767]   Expert 47 |     23 | CPU
DEBUG 01-07 14:54:41.667977.667977 lmp.py:767]   Expert 38 |     31 | CPU
DEBUG 01-07 14:54:41.667951.667951 lmp.py:767]   Expert 27 |     36 | CPU
DEBUG 01-07 14:54:41.667925.667925 lmp.py:767]   Expert 52 |     37 | CPU
DEBUG 01-07 14:54:41.667899.667899 lmp.py:767]   Expert 16 |     38 | CPU
DEBUG 01-07 14:54:41.667635.667635 lmp.py:767]   Expert 63 |     46 | CPU
DEBUG 01-07 14:54:41.667609.667609 lmp.py:767]   Expert  4 |     57 | CPU
DEBUG 01-07 14:54:41.667106.667106 lmp.py:767]   Expert 43 |     60 | CPU
DEBUG 01-07 14:54:41.667319.667319 lmp.py:767]   Expert 44 |     61 | CPU
DEBUG 01-07 14:54:41.667769.667769 lmp.py:767]   Expert 61 |     63 | CPU
DEBUG 01-07 14:54:41.667982.667982 lmp.py:767]   Expert 34 |     76 | CPU
DEBUG 01-07 14:54:41.667194.667194 lmp.py:767]   Expert 53 |     81 | CPU
DEBUG 01-07 14:54:41.667122.667122 lmp.py:767]   Expert  0 |     86 | CPU
DEBUG 01-07 14:54:41.667242.667242 lmp.py:767]   Expert 32 |     88 | CPU
DEBUG 01-07 14:54:41.667170.667170 lmp.py:767]   Expert 37 |     91 | CPU
DEBUG 01-07 14:54:41.667097.667097 lmp.py:767]   Expert 13 |    102 | CPU
DEBUG 01-07 14:54:41.667025.667025 lmp.py:767]   Expert 39 |    114 | CPU
DEBUG 01-07 14:54:41.667476.667476 lmp.py:767]   Expert 21 |    119 | CPU
DEBUG 01-07 14:54:41.667596.667596 lmp.py:767]   Expert 11 |    120 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.667716.667716 lmp.py:767]   Expert 20 |    124 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.667074.667074 lmp.py:767]   Expert  8 |    130 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.667432.667432 lmp.py:767]   Expert 60 |    133 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.667790.667790 lmp.py:767]   Expert 57 |    137 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668625.668625 lmp.py:767]   Expert 22 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668268.668268 lmp.py:767]   Expert 14 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668673.668673 lmp.py:767]   Expert  2 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668316.668316 lmp.py:767]   Expert 17 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668720.668720 lmp.py:767]   Expert 23 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668887.668887 lmp.py:767]   Expert 45 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668291.668291 lmp.py:767]   Expert 30 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668934.668934 lmp.py:767]   Expert 18 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668339.668339 lmp.py:767]   Expert 58 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668458.668458 lmp.py:767]   Expert  7 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668578.668578 lmp.py:767]   Expert 42 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668698.668698 lmp.py:767]   Expert 49 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668295.668295 lmp.py:767]   Expert 48 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668653.668653 lmp.py:767]   Expert 55 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668057.668057 lmp.py:767]   Expert 62 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668939.668939 lmp.py:767]   Expert 51 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668820.668820 lmp.py:767]   Expert  6 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668463.668463 lmp.py:767]   Expert 29 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668629.668629 lmp.py:767]   Expert 35 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668511.668511 lmp.py:767]   Expert 25 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668915.668915 lmp.py:767]   Expert  1 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668711.668711 lmp.py:767]   Expert 36 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668546.668546 lmp.py:767]   Expert 31 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668381.668381 lmp.py:767]   Expert 28 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668501.668501 lmp.py:767]   Expert 54 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668859.668859 lmp.py:767]   Expert  5 |    230 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668217.668217 lmp.py:767]   Expert 41 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668575.668575 lmp.py:767]   Expert  9 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668457.668457 lmp.py:767]   Expert 19 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668338.668338 lmp.py:767]   Expert 24 |    254 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668981.668981 lmp.py:767]   Expert 50 |    290 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668863.668863 lmp.py:767]   Expert 46 |    303 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668744.668744 lmp.py:767]   Expert 59 |    312 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668625.668625 lmp.py:767]   Expert 56 |    381 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668268.668268 lmp.py:767]   Expert 26 |    401 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668911.668911 lmp.py:767]   Expert 33 |    423 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668554.668554 lmp.py:767]   Expert  3 |    588 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668913.668913 lmp.py:767]   Expert 15 |    645 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668032.668032 lmp.py:767]   Expert 10 |    648 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.668391.668391 lmp.py:767]   Expert 40 |    787 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.668557.668557 lmp.py:769] 
DEBUG 01-07 14:54:41.668557.668557 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.668438.668438 lmp.py:770]   CPU:   1229 tokens
DEBUG 01-07 14:54:41.668035.668035 lmp.py:774]   cuda:1:   5471 tokens (22 experts)
DEBUG 01-07 14:54:41.668678.668678 lmp.py:774]   cuda:2:   5588 tokens (23 experts)
DEBUG 01-07 14:54:41.668606.668606 lmp.py:775]   Total GPU:  11059 tokens
DEBUG 01-07 14:54:41.668056.668056 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.668056.668056 lmp.py:776] 
DEBUG 01-07 14:54:41.668183.668183 cuda_h.py:19] end experts_map_get cost 0.0017726421356201172 seconds
DEBUG 01-07 14:54:41.668303.668303 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.668125.668125 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.669606.669606 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.669827.669827 cuda_h.py:19] end allocate_cuda_memory cost 0.0006210803985595703 seconds
DEBUG 01-07 14:54:41.669597.669597 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.669307.669307 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.669639.669639 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.669574.669574 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cdb7fac2-55b6-485d-acf4-357275034734
DEBUG 01-07 14:54:41.670268.670268 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.670842.670842 client.py:127] Model loaded
DEBUG 01-07 14:54:41.670864.670864 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.670862.670862 cuda_h.py:19] end restore2model cost 0.00031828880310058594 seconds
DEBUG 01-07 14:54:41.670248.670248 cuda_h.py:19] end sllm_worker_task cost 0.009153604507446289 seconds
INFO 01-07 14:54:41.670349.670349 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cdb7fac2-55b6-485d-acf4-357275034734
DEBUG 01-07 14:54:41.670570.670570 cuda_h.py:19] end load_into_gpu_async cost 0.0009288787841796875 seconds
DEBUG 01-07 14:54:41.670127.670127 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.671183.671183 cuda_h.py:19] end restore_tensors2 cost 0.000263214111328125 seconds
DEBUG 01-07 14:54:41.671145.671145 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021326541900634766 seconds
DEBUG 01-07 14:54:41.671000.671000 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.672082.672082 cuda_h.py:19] end restore2model cost 0.0018229484558105469 seconds
DEBUG 01-07 14:54:41.673131.673131 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.673320.673320 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.673705.673705 cuda_h.py:19] end allocate_cuda_memory cost 0.00021648406982421875 seconds
DEBUG 01-07 14:54:41.673303.673303 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.673675.673675 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.673577.673577 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.673227.673227 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 016dffee-4e2e-4ec4-9a4c-95be787108d0
DEBUG 01-07 14:54:41.673708.673708 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.674144.674144 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 016dffee-4e2e-4ec4-9a4c-95be787108d0
DEBUG 01-07 14:54:41.674874.674874 cuda_h.py:19] end load_into_gpu_async cost 0.000988006591796875 seconds
DEBUG 01-07 14:54:41.674431.674431 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.674744.674744 cuda_h.py:19] end restore_tensors2 cost 0.0002415180206298828 seconds
DEBUG 01-07 14:54:41.674852.674852 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017325878143310547 seconds
DEBUG 01-07 14:54:41.674608.674608 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.676406.676406 cuda_h.py:19] end restore2model cost 0.001859903335571289 seconds
DEBUG 01-07 14:54:41.676090.676090 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007862329483032227 seconds
DEBUG 01-07 14:54:41.676647.676647 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.676034.676034 lmp.py:816] 
DEBUG 01-07 14:54:41.676034.676034 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.676393.676393 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 14:54:41.676997.676997 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.686112.686112 mlpmodule.py:749] group tensors cost 0.009863138198852539 s
DEBUG 01-07 14:54:41.688275.688275 mlpmodule.py:787] pad cost 0.0010271072387695312 s
DEBUG 01-07 14:54:41.688358.688358 mlpmodule.py:793] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-07 14:54:41.688923.688923 mlpmodule.py:798] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-07 14:54:41.697544.697544 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.697027.697027 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.697838.697838 mlpmodule.py:818] group_w3 first element: -0.0162353515625
WARNING 01-07 14:54:41.697445.697445 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.711767.711767 mlpmodule.py:838] group einsum cost 0.022562026977539062 s
DEBUG 01-07 14:54:41.712225.712225 mlpmodule.py:846] cpy2cputensor cost 0.0004210472106933594 s
DEBUG 01-07 14:54:41.717224.717224 cuda_h.py:19] end wait_cetm_experts cost 0.04094266891479492 seconds
DEBUG 01-07 14:54:41.718328.718328 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.718426.718426 cuda_h.py:19] end gpu_sexperts cost 0.0005185604095458984 seconds
DEBUG 01-07 14:54:41.718091.718091 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.718510.718510 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-07 14:54:41.718690.718690 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.718883.718883 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cdb7fac2-55b6-485d-acf4-357275034734
INFO 01-07 14:54:41.720989.720989 client.py:127] Model loaded
INFO 01-07 14:54:41.720394.720394 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 016dffee-4e2e-4ec4-9a4c-95be787108d0
INFO 01-07 14:54:41.720860.720860 client.py:127] Model loaded
DEBUG 01-07 14:54:41.720544.720544 cuda_h.py:19] end wait_experts_multi_device cost 0.0019328594207763672 seconds
DEBUG 01-07 14:54:41.720916.720916 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.720368.720368 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.722973.722973 mlpmodule.py:533] gpu group tensors cost 0.0005102157592773438 s
DEBUG 01-07 14:54:41.723582.723582 mlpmodule.py:566] gpu pad cost 0.0013344287872314453 s
DEBUG 01-07 14:54:41.724393.724393 mlpmodule.py:584] gpu group einsum cost 0.0005946159362792969 s
DEBUG 01-07 14:54:41.728241.728241 mlpmodule.py:656] gpu experts func einsum cost 0.007346630096435547 s
DEBUG 01-07 14:54:41.729032.729032 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.729542.729542 mlpmodule.py:533] gpu group tensors cost 0.000370025634765625 s
DEBUG 01-07 14:54:41.730678.730678 mlpmodule.py:566] gpu pad cost 0.0010306835174560547 s
DEBUG 01-07 14:54:41.731834.731834 mlpmodule.py:707]  experts func einsum cost 0.05398440361022949 s
DEBUG 01-07 14:54:41.731800.731800 mlpmodule.py:584] gpu group einsum cost 0.0004115104675292969 s
DEBUG 01-07 14:54:41.733928.733928 mlpmodule.py:656] gpu experts func einsum cost 0.0035681724548339844 s
DEBUG 01-07 14:54:41.733189.733189 cuda_h.py:19] end gpu_experts_multi_device cost 0.012284994125366211 seconds
DEBUG 01-07 14:54:41.733443.733443 cuda_h.py:19] end layer_moe_generate_multi_device_12 cost 0.06700587272644043 seconds
DEBUG 01-07 14:54:41.733953.733953 lmp.py:194] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-07 14:54:41.733253.733253 lmp.py:153] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-07 14:54:41.733472.733472 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 14:54:41.733082.733082 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 14:54:41.733203.733203 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.765655517578125e-05 seconds
DEBUG 01-07 14:54:41.733476.733476 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.7220458984375e-05 seconds
DEBUG 01-07 14:54:41.733596.733596 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.733418.733418 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.733374.733374 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.733111.733111 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.734102.734102 cuda_h.py:19] end allocate_cuda_memory cost 0.00027441978454589844 seconds
DEBUG 01-07 14:54:41.734078.734078 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.734815.734815 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.734467.734467 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.734158.734158 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.734576.734576 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 15246a36-20d7-48cd-9e99-fc3e88f57e7d
DEBUG 01-07 14:54:41.734115.734115 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.734900.734900 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.735799.735799 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 15246a36-20d7-48cd-9e99-fc3e88f57e7d
DEBUG 01-07 14:54:41.735735.735735 cuda_h.py:19] end load_into_gpu_async cost 0.001461029052734375 seconds
DEBUG 01-07 14:54:41.735153.735153 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.735527.735527 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-07 14:54:41.735144.735144 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002184629440307617 seconds
INFO 01-07 14:54:41.735265.735265 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 15246a36-20d7-48cd-9e99-fc3e88f57e7d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.738305.738305 cuda_h.py:19] end self_attn cost 0.0033273696899414062 seconds
DEBUG 01-07 14:54:41.738295.738295 cuda_h.py:19] end iln_self_attn_paln cost 0.004842281341552734 seconds
DEBUG 01-07 14:54:41.738363.738363 cuda_h.py:10] start layer_moe_generate_multi_device_13
DEBUG 01-07 14:54:41.738549.738549 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.739778.739778 cuda_h.py:19] end gate cost 0.0006630420684814453 seconds
DEBUG 01-07 14:54:41.739939.739939 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.739549.739549 lmp.py:744] 
DEBUG 01-07 14:54:41.739549.739549 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.739212.739212 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.739054.739054 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.739319.739319 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.739916.739916 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.739559.739559 lmp.py:749] 
DEBUG 01-07 14:54:41.739559.739559 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.739917.739917 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.739997.739997 lmp.py:767]   Expert 42 |     23 | CPU
DEBUG 01-07 14:54:41.739879.739879 lmp.py:767]   Expert 19 |     25 | CPU
DEBUG 01-07 14:54:41.739045.739045 lmp.py:767]   Expert 30 |     27 | CPU
DEBUG 01-07 14:54:41.739688.739688 lmp.py:767]   Expert 32 |     43 | CPU
DEBUG 01-07 14:54:41.739616.739616 lmp.py:767]   Expert  6 |     58 | CPU
DEBUG 01-07 14:54:41.739543.739543 lmp.py:767]   Expert  5 |     72 | CPU
DEBUG 01-07 14:54:41.739663.739663 lmp.py:767]   Expert 53 |     75 | CPU
DEBUG 01-07 14:54:41.739783.739783 lmp.py:767]   Expert  1 |     77 | CPU
DEBUG 01-07 14:54:41.739664.739664 lmp.py:767]   Expert  9 |    120 | CPU
DEBUG 01-07 14:54:41.740069.740069 lmp.py:767]   Expert 13 |    120 | CPU
DEBUG 01-07 14:54:41.740997.740997 lmp.py:767]   Expert 58 |    129 | CPU
DEBUG 01-07 14:54:41.740924.740924 lmp.py:767]   Expert 50 |    131 | CPU
DEBUG 01-07 14:54:41.740852.740852 lmp.py:767]   Expert 34 |    132 | CPU
DEBUG 01-07 14:54:41.740780.740780 lmp.py:767]   Expert 63 |    132 | CPU
DEBUG 01-07 14:54:41.740469.740469 lmp.py:767]   Expert 59 |    134 | CPU
DEBUG 01-07 14:54:41.740397.740397 lmp.py:767]   Expert 26 |    135 | CPU
DEBUG 01-07 14:54:41.740563.740563 lmp.py:767]   Expert 31 |    135 | CPU
DEBUG 01-07 14:54:41.740014.740014 lmp.py:767]   Expert 18 |    137 | CPU
DEBUG 01-07 14:54:41.740703.740703 lmp.py:767]   Expert 56 |    142 | CPU
DEBUG 01-07 14:54:41.740061.740061 lmp.py:767]   Expert 11 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740896.740896 lmp.py:767]   Expert 40 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740493.740493 lmp.py:767]   Expert 46 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740805.740805 lmp.py:767]   Expert 12 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740686.740686 lmp.py:767]   Expert 20 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740091.740091 lmp.py:767]   Expert  2 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740734.740734 lmp.py:767]   Expert 33 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740615.740615 lmp.py:767]   Expert 48 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740258.740258 lmp.py:767]   Expert  4 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740901.740901 lmp.py:767]   Expert 61 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740306.740306 lmp.py:767]   Expert 10 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740426.740426 lmp.py:767]   Expert 35 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740413.740413 lmp.py:767]   Expert 55 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740248.740248 lmp.py:767]   Expert 51 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740607.740607 lmp.py:767]   Expert 36 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740726.740726 lmp.py:767]   Expert  8 |    184 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740800.740800 lmp.py:767]   Expert 52 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740681.740681 lmp.py:767]   Expert 37 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740086.740086 lmp.py:767]   Expert  0 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740729.740729 lmp.py:767]   Expert 57 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740372.740372 lmp.py:767]   Expert 39 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740015.740015 lmp.py:767]   Expert 25 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740658.740658 lmp.py:767]   Expert 62 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740301.740301 lmp.py:767]   Expert 38 |    243 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740944.740944 lmp.py:767]   Expert  7 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740302.740302 lmp.py:767]   Expert 24 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740183.740183 lmp.py:767]   Expert  3 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740303.740303 lmp.py:767]   Expert 28 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740661.740661 lmp.py:767]   Expert 27 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740543.740543 lmp.py:767]   Expert 60 |    258 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740947.740947 lmp.py:767]   Expert 21 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740590.740590 lmp.py:767]   Expert 49 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740995.740995 lmp.py:767]   Expert 16 |    266 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740876.740876 lmp.py:767]   Expert 29 |    271 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740281.740281 lmp.py:767]   Expert 43 |    273 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740924.740924 lmp.py:767]   Expert 23 |    275 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740328.740328 lmp.py:767]   Expert 15 |    289 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740733.740733 lmp.py:767]   Expert 22 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740853.740853 lmp.py:767]   Expert 47 |    294 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740972.740972 lmp.py:767]   Expert 41 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740092.740092 lmp.py:767]   Expert 44 |    303 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740166.740166 lmp.py:767]   Expert 54 |    351 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740809.740809 lmp.py:767]   Expert 14 |    374 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740452.740452 lmp.py:767]   Expert 17 |    408 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.740095.740095 lmp.py:767]   Expert 45 |    464 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.740261.740261 lmp.py:769] 
DEBUG 01-07 14:54:41.740261.740261 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.741665.741665 lmp.py:770]   CPU:   1847 tokens
DEBUG 01-07 14:54:41.741024.741024 lmp.py:774]   cuda:1:   5292 tokens (23 experts)
DEBUG 01-07 14:54:41.741667.741667 lmp.py:774]   cuda:2:   5149 tokens (22 experts)
DEBUG 01-07 14:54:41.741594.741594 lmp.py:775]   Total GPU:  10441 tokens
DEBUG 01-07 14:54:41.741999.741999 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.741999.741999 lmp.py:776] 
DEBUG 01-07 14:54:41.741364.741364 cuda_h.py:19] end experts_map_get cost 0.0017940998077392578 seconds
DEBUG 01-07 14:54:41.741437.741437 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.741644.741644 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.741032.741032 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.742552.742552 cuda_h.py:19] end allocate_cuda_memory cost 0.0010530948638916016 seconds
DEBUG 01-07 14:54:41.742270.742270 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.742694.742694 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.742934.742934 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.742584.742584 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e43fac61-5005-4220-955c-70962312e55a
DEBUG 01-07 14:54:41.742079.742079 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.742094.742094 client.py:127] Model loaded
DEBUG 01-07 14:54:41.742023.742023 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.743699.743699 cuda_h.py:19] end restore2model cost 0.0003578662872314453 seconds
DEBUG 01-07 14:54:41.743614.743614 cuda_h.py:19] end sllm_worker_task cost 0.009734392166137695 seconds
INFO 01-07 14:54:41.744906.744906 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e43fac61-5005-4220-955c-70962312e55a
DEBUG 01-07 14:54:41.744988.744988 cuda_h.py:19] end load_into_gpu_async cost 0.0018296241760253906 seconds
DEBUG 01-07 14:54:41.744452.744452 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.744998.744998 cuda_h.py:19] end restore_tensors2 cost 0.0002722740173339844 seconds
DEBUG 01-07 14:54:41.744914.744914 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034766197204589844 seconds
DEBUG 01-07 14:54:41.744961.744961 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.746145.746145 cuda_h.py:19] end restore2model cost 0.0018982887268066406 seconds
DEBUG 01-07 14:54:41.746240.746240 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.746998.746998 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.747655.747655 cuda_h.py:19] end allocate_cuda_memory cost 0.00020503997802734375 seconds
DEBUG 01-07 14:54:41.747922.747922 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.747579.747579 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.747288.747288 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.747985.747985 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9211ff3-74c9-4466-b946-35cb378295e0
DEBUG 01-07 14:54:41.747989.747989 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.748955.748955 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9211ff3-74c9-4466-b946-35cb378295e0
DEBUG 01-07 14:54:41.748308.748308 cuda_h.py:19] end load_into_gpu_async cost 0.0012023448944091797 seconds
DEBUG 01-07 14:54:41.748627.748627 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.748318.748318 cuda_h.py:19] end restore_tensors2 cost 0.0002384185791015625 seconds
DEBUG 01-07 14:54:41.748756.748756 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019335746765136719 seconds
DEBUG 01-07 14:54:41.748704.748704 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.750289.750289 cuda_h.py:19] end restore2model cost 0.0018069744110107422 seconds
DEBUG 01-07 14:54:41.750502.750502 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009435176849365234 seconds
DEBUG 01-07 14:54:41.750060.750060 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.750592.750592 lmp.py:816] 
DEBUG 01-07 14:54:41.750592.750592 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.750521.750521 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-07 14:54:41.750455.750455 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.760950.760950 mlpmodule.py:749] group tensors cost 0.010112285614013672 s
DEBUG 01-07 14:54:41.762445.762445 mlpmodule.py:787] pad cost 0.0012238025665283203 s
DEBUG 01-07 14:54:41.763124.763124 mlpmodule.py:793] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-07 14:54:41.763908.763908 mlpmodule.py:798] move to cpu cost 3.719329833984375e-05 s
DEBUG 01-07 14:54:41.771269.771269 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.771891.771891 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.771556.771556 mlpmodule.py:818] group_w3 first element: -0.0211181640625
WARNING 01-07 14:54:41.772561.772561 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.788030.788030 mlpmodule.py:838] group einsum cost 0.02511119842529297 s
DEBUG 01-07 14:54:41.788706.788706 mlpmodule.py:846] cpy2cputensor cost 0.0004093647003173828 s
DEBUG 01-07 14:54:41.791847.791847 cuda_h.py:19] end wait_cetm_experts cost 0.04073190689086914 seconds
DEBUG 01-07 14:54:41.791254.791254 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.792782.792782 cuda_h.py:19] end gpu_sexperts cost 0.00048542022705078125 seconds
DEBUG 01-07 14:54:41.792771.792771 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.792382.792382 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-07 14:54:41.792562.792562 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.792510.792510 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e43fac61-5005-4220-955c-70962312e55a
INFO 01-07 14:54:41.793288.793288 client.py:127] Model loaded
INFO 01-07 14:54:41.793170.793170 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9211ff3-74c9-4466-b946-35cb378295e0
INFO 01-07 14:54:41.793370.793370 client.py:127] Model loaded
DEBUG 01-07 14:54:41.793339.793339 cuda_h.py:19] end wait_experts_multi_device cost 0.0014197826385498047 seconds
DEBUG 01-07 14:54:41.793234.793234 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.793911.793911 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:41.794697.794697 mlpmodule.py:533] gpu group tensors cost 0.0004756450653076172 s
DEBUG 01-07 14:54:41.796046.796046 mlpmodule.py:566] gpu pad cost 0.001247406005859375 s
DEBUG 01-07 14:54:41.796670.796670 mlpmodule.py:584] gpu group einsum cost 0.0005602836608886719 s
DEBUG 01-07 14:54:41.798829.798829 mlpmodule.py:656] gpu experts func einsum cost 0.004401445388793945 s
DEBUG 01-07 14:54:41.799408.799408 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:41.799215.799215 mlpmodule.py:533] gpu group tensors cost 0.0004742145538330078 s
DEBUG 01-07 14:54:41.801452.801452 mlpmodule.py:566] gpu pad cost 0.001276254653930664 s
DEBUG 01-07 14:54:41.801201.801201 mlpmodule.py:584] gpu group einsum cost 0.00034737586975097656 s
DEBUG 01-07 14:54:41.803470.803470 mlpmodule.py:656] gpu experts func einsum cost 0.004138469696044922 s
DEBUG 01-07 14:54:41.803930.803930 cuda_h.py:19] end gpu_experts_multi_device cost 0.009894132614135742 seconds
DEBUG 01-07 14:54:41.803615.803615 cuda_h.py:19] end layer_moe_generate_multi_device_13 cost 0.06525421142578125 seconds
DEBUG 01-07 14:54:41.804677.804677 lmp.py:194] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-07 14:54:41.804506.804506 lmp.py:153] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-07 14:54:41.804633.804633 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 14:54:41.804150.804150 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 14:54:41.804510.804510 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.6702880859375e-05 seconds
DEBUG 01-07 14:54:41.804928.804928 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.745887756347656e-05 seconds
DEBUG 01-07 14:54:41.804955.804955 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.804891.804891 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.804416.804416 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.804314.804314 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.804428.804428 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.804743.804743 cuda_h.py:19] end allocate_cuda_memory cost 0.0002663135528564453 seconds
DEBUG 01-07 14:54:41.804872.804872 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.804873.804873 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.805934.805934 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.805445.805445 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0cf1fa5c-8555-4c31-adfe-6a6e04c2a624
DEBUG 01-07 14:54:41.805646.805646 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.805775.805775 mlpmodule.py:707]  experts func einsum cost 0.054347991943359375 s
DEBUG 01-07 14:54:41.805432.805432 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.805011.805011 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0cf1fa5c-8555-4c31-adfe-6a6e04c2a624
DEBUG 01-07 14:54:41.805085.805085 cuda_h.py:19] end load_into_gpu_async cost 0.0009982585906982422 seconds
DEBUG 01-07 14:54:41.805073.805073 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.806963.806963 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-07 14:54:41.806243.806243 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016012191772460938 seconds
INFO 01-07 14:54:41.806456.806456 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0cf1fa5c-8555-4c31-adfe-6a6e04c2a624
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.808667.808667 cuda_h.py:19] end self_attn cost 0.0029892921447753906 seconds
DEBUG 01-07 14:54:41.808227.808227 cuda_h.py:19] end iln_self_attn_paln cost 0.004525423049926758 seconds
DEBUG 01-07 14:54:41.808957.808957 cuda_h.py:10] start layer_moe_generate_multi_device_14
DEBUG 01-07 14:54:41.808620.808620 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.809636.809636 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-07 14:54:41.809035.809035 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.810168.810168 lmp.py:744] 
DEBUG 01-07 14:54:41.810168.810168 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.810640.810640 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.810766.810766 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.810317.810317 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.810483.810483 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.810934.810934 lmp.py:749] 
DEBUG 01-07 14:54:41.810934.810934 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.810100.810100 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.810988.810988 lmp.py:767]   Expert  7 |     29 | CPU
DEBUG 01-07 14:54:41.810916.810916 lmp.py:767]   Expert 34 |     33 | CPU
DEBUG 01-07 14:54:41.810651.810651 lmp.py:767]   Expert 13 |     43 | CPU
DEBUG 01-07 14:54:41.810625.810625 lmp.py:767]   Expert 54 |     75 | CPU
DEBUG 01-07 14:54:41.810361.810361 lmp.py:767]   Expert 39 |     84 | CPU
DEBUG 01-07 14:54:41.810096.810096 lmp.py:767]   Expert 49 |     85 | CPU
DEBUG 01-07 14:54:41.810071.810071 lmp.py:767]   Expert 18 |     86 | CPU
DEBUG 01-07 14:54:41.810806.810806 lmp.py:767]   Expert 59 |    102 | CPU
DEBUG 01-07 14:54:41.810780.810780 lmp.py:767]   Expert 16 |    106 | CPU
DEBUG 01-07 14:54:41.810708.810708 lmp.py:767]   Expert 21 |    109 | CPU
DEBUG 01-07 14:54:41.810159.810159 lmp.py:767]   Expert  0 |    111 | CPU
DEBUG 01-07 14:54:41.810610.810610 lmp.py:767]   Expert 45 |    117 | CPU
DEBUG 01-07 14:54:41.810822.810822 lmp.py:767]   Expert 41 |    119 | CPU
DEBUG 01-07 14:54:41.810319.810319 lmp.py:767]   Expert 22 |    121 | CPU
DEBUG 01-07 14:54:41.810055.810055 lmp.py:767]   Expert 15 |    126 | CPU
DEBUG 01-07 14:54:41.810552.810552 lmp.py:767]   Expert 17 |    128 | CPU
DEBUG 01-07 14:54:41.810049.810049 lmp.py:767]   Expert 52 |    133 | CPU
DEBUG 01-07 14:54:41.810547.810547 lmp.py:767]   Expert 61 |    133 | CPU
DEBUG 01-07 14:54:41.810044.810044 lmp.py:767]   Expert  8 |    136 | CPU
DEBUG 01-07 14:54:41.810495.810495 lmp.py:767]   Expert 12 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810184.810184 lmp.py:767]   Expert 35 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810873.810873 lmp.py:767]   Expert 38 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810662.810662 lmp.py:767]   Expert 31 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810782.810782 lmp.py:767]   Expert 48 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810663.810663 lmp.py:767]   Expert 53 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810306.810306 lmp.py:767]   Expert 40 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810148.810148 lmp.py:767]   Expert 50 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810314.810314 lmp.py:767]   Expert 36 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810765.810765 lmp.py:767]   Expert 60 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810216.810216 lmp.py:767]   Expert 27 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810667.810667 lmp.py:767]   Expert  4 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810118.810118 lmp.py:767]   Expert 19 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810569.810569 lmp.py:767]   Expert 29 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810020.810020 lmp.py:767]   Expert 30 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810470.810470 lmp.py:767]   Expert 20 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810921.810921 lmp.py:767]   Expert 11 |    219 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810087.810087 lmp.py:767]   Expert  6 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810254.810254 lmp.py:767]   Expert 57 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810181.810181 lmp.py:767]   Expert 26 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810871.810871 lmp.py:767]   Expert 46 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810321.810321 lmp.py:767]   Expert 43 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810011.810011 lmp.py:767]   Expert 33 |    238 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810462.810462 lmp.py:767]   Expert 23 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810674.810674 lmp.py:767]   Expert  2 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810887.810887 lmp.py:767]   Expert 42 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810337.810337 lmp.py:767]   Expert 56 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810788.810788 lmp.py:767]   Expert 55 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810239.810239 lmp.py:767]   Expert 32 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.810690.810690 lmp.py:767]   Expert  9 |    261 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.810141.810141 lmp.py:767]   Expert  3 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811353.811353 lmp.py:767]   Expert 28 |    267 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811281.811281 lmp.py:767]   Expert 44 |    268 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811209.811209 lmp.py:767]   Expert 14 |    269 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811137.811137 lmp.py:767]   Expert 51 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811780.811780 lmp.py:767]   Expert  1 |    280 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811469.811469 lmp.py:767]   Expert 47 |    285 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811443.811443 lmp.py:767]   Expert 58 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811655.811655 lmp.py:767]   Expert 37 |    288 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811868.811868 lmp.py:767]   Expert 63 |    290 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811080.811080 lmp.py:767]   Expert 10 |    309 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811293.811293 lmp.py:767]   Expert 24 |    309 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811505.811505 lmp.py:767]   Expert 62 |    309 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811479.811479 lmp.py:767]   Expert 25 |    310 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.811692.811692 lmp.py:767]   Expert  5 |    365 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.811381.811381 lmp.py:769] 
DEBUG 01-07 14:54:41.811381.811381 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.811309.811309 lmp.py:770]   CPU:   1876 tokens
DEBUG 01-07 14:54:41.811952.811952 lmp.py:774]   cuda:1:   5138 tokens (22 experts)
DEBUG 01-07 14:54:41.811879.811879 lmp.py:774]   cuda:2:   5274 tokens (23 experts)
DEBUG 01-07 14:54:41.811046.811046 lmp.py:775]   Total GPU:  10412 tokens
DEBUG 01-07 14:54:41.811781.811781 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.811781.811781 lmp.py:776] 
DEBUG 01-07 14:54:41.811000.811000 cuda_h.py:19] end experts_map_get cost 0.00170135498046875 seconds
DEBUG 01-07 14:54:41.811167.811167 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.811751.811751 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.811132.811132 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.813625.813625 cuda_h.py:19] end allocate_cuda_memory cost 0.0016293525695800781 seconds
DEBUG 01-07 14:54:41.813342.813342 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.813529.813529 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.813245.813245 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.813087.813087 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3cdbd560-70c4-470d-8f1c-0f86bf6eb6a1
DEBUG 01-07 14:54:41.813828.813828 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.813758.813758 client.py:127] Model loaded
DEBUG 01-07 14:54:41.813157.813157 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.814977.814977 cuda_h.py:19] end restore2model cost 0.0003266334533691406 seconds
DEBUG 01-07 14:54:41.814316.814316 cuda_h.py:19] end sllm_worker_task cost 0.009770393371582031 seconds
INFO 01-07 14:54:41.814661.814661 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3cdbd560-70c4-470d-8f1c-0f86bf6eb6a1
DEBUG 01-07 14:54:41.814504.814504 cuda_h.py:19] end load_into_gpu_async cost 0.0012438297271728516 seconds
DEBUG 01-07 14:54:41.814492.814492 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.814032.814032 cuda_h.py:19] end restore_tensors2 cost 0.0002677440643310547 seconds
DEBUG 01-07 14:54:41.814801.814801 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003456592559814453 seconds
DEBUG 01-07 14:54:41.814418.814418 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.816924.816924 cuda_h.py:19] end restore2model cost 0.0018200874328613281 seconds
DEBUG 01-07 14:54:41.816403.816403 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.816446.816446 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.817673.817673 cuda_h.py:19] end allocate_cuda_memory cost 0.00020432472229003906 seconds
DEBUG 01-07 14:54:41.817747.817747 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.817596.817596 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.817306.817306 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.817717.817717 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f03dc072-7ef3-4f28-982a-ee0dbbc9738f
DEBUG 01-07 14:54:41.817338.817338 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.818631.818631 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f03dc072-7ef3-4f28-982a-ee0dbbc9738f
DEBUG 01-07 14:54:41.818599.818599 cuda_h.py:19] end load_into_gpu_async cost 0.001088857650756836 seconds
DEBUG 01-07 14:54:41.818918.818918 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.818516.818516 cuda_h.py:19] end restore_tensors2 cost 0.00024127960205078125 seconds
DEBUG 01-07 14:54:41.818286.818286 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018177032470703125 seconds
DEBUG 01-07 14:54:41.818658.818658 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.820780.820780 cuda_h.py:19] end restore2model cost 0.0018537044525146484 seconds
DEBUG 01-07 14:54:41.820994.820994 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009262561798095703 seconds
DEBUG 01-07 14:54:41.820121.820121 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.820938.820938 lmp.py:816] 
DEBUG 01-07 14:54:41.820938.820938 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.820059.820059 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 14:54:41.820662.820662 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.826406.826406 mlpmodule.py:749] group tensors cost 0.00548100471496582 s
DEBUG 01-07 14:54:41.828845.828845 mlpmodule.py:787] pad cost 0.0010650157928466797 s
DEBUG 01-07 14:54:41.828888.828888 mlpmodule.py:793] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-07 14:54:41.828904.828904 mlpmodule.py:798] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-07 14:54:41.837314.837314 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.837334.837334 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.837238.837238 mlpmodule.py:818] group_w3 first element: 0.000789642333984375
WARNING 01-07 14:54:41.837700.837700 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.851322.851322 mlpmodule.py:838] group einsum cost 0.02287149429321289 s
DEBUG 01-07 14:54:41.852297.852297 mlpmodule.py:846] cpy2cputensor cost 0.000438690185546875 s
DEBUG 01-07 14:54:41.854215.854215 cuda_h.py:19] end wait_cetm_experts cost 0.03386068344116211 seconds
DEBUG 01-07 14:54:41.854198.854198 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.855984.855984 cuda_h.py:19] end gpu_sexperts cost 0.0005021095275878906 seconds
DEBUG 01-07 14:54:41.855212.855212 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.855115.855115 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 14:54:41.855109.855109 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.855872.855872 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3cdbd560-70c4-470d-8f1c-0f86bf6eb6a1
INFO 01-07 14:54:41.858073.858073 client.py:127] Model loaded
INFO 01-07 14:54:41.858955.858955 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f03dc072-7ef3-4f28-982a-ee0dbbc9738f
INFO 01-07 14:54:41.859279.859279 client.py:127] Model loaded
DEBUG 01-07 14:54:41.859725.859725 cuda_h.py:19] end wait_experts_multi_device cost 0.003724336624145508 seconds
DEBUG 01-07 14:54:41.859150.859150 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.859211.859211 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.860919.860919 mlpmodule.py:533] gpu group tensors cost 0.0005199909210205078 s
DEBUG 01-07 14:54:41.861058.861058 mlpmodule.py:566] gpu pad cost 0.0013022422790527344 s
DEBUG 01-07 14:54:41.862807.862807 mlpmodule.py:584] gpu group einsum cost 0.0005466938018798828 s
DEBUG 01-07 14:54:41.863501.863501 mlpmodule.py:707]  experts func einsum cost 0.04215192794799805 s
DEBUG 01-07 14:54:41.864194.864194 mlpmodule.py:656] gpu experts func einsum cost 0.0047571659088134766 s
DEBUG 01-07 14:54:41.865363.865363 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.865606.865606 mlpmodule.py:533] gpu group tensors cost 0.0004527568817138672 s
DEBUG 01-07 14:54:41.867496.867496 mlpmodule.py:566] gpu pad cost 0.0011973381042480469 s
DEBUG 01-07 14:54:41.867883.867883 mlpmodule.py:584] gpu group einsum cost 0.0004296302795410156 s
DEBUG 01-07 14:54:41.869696.869696 mlpmodule.py:656] gpu experts func einsum cost 0.003925323486328125 s
DEBUG 01-07 14:54:41.869149.869149 cuda_h.py:19] end gpu_experts_multi_device cost 0.01004791259765625 seconds
DEBUG 01-07 14:54:41.869688.869688 cuda_h.py:19] end layer_moe_generate_multi_device_14 cost 0.060587167739868164 seconds
DEBUG 01-07 14:54:41.869597.869597 lmp.py:194] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-07 14:54:41.869645.869645 lmp.py:153] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-07 14:54:41.869269.869269 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 14:54:41.869263.869263 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 14:54:41.869907.869907 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:41.869657.869657 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.745887756347656e-05 seconds
DEBUG 01-07 14:54:41.869776.869776 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.869314.869314 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.870509.870509 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.870199.870199 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.870607.870607 cuda_h.py:19] end allocate_cuda_memory cost 0.0002655982971191406 seconds
DEBUG 01-07 14:54:41.870808.870808 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.870783.870783 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.870720.870720 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.870020.870020 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.870769.870769 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 66879e7b-bb1c-43a3-a0c6-c56e962bfd56
DEBUG 01-07 14:54:41.870401.870401 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.871503.871503 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.871679.871679 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 66879e7b-bb1c-43a3-a0c6-c56e962bfd56
DEBUG 01-07 14:54:41.871277.871277 cuda_h.py:19] end load_into_gpu_async cost 0.0010080337524414062 seconds
DEBUG 01-07 14:54:41.871265.871265 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.871294.871294 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 14:54:41.871620.871620 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016980171203613281 seconds
INFO 01-07 14:54:41.871748.871748 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 66879e7b-bb1c-43a3-a0c6-c56e962bfd56
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.874748.874748 cuda_h.py:19] end self_attn cost 0.0031049251556396484 seconds
DEBUG 01-07 14:54:41.874739.874739 cuda_h.py:19] end iln_self_attn_paln cost 0.0045795440673828125 seconds
DEBUG 01-07 14:54:41.874184.874184 cuda_h.py:10] start layer_moe_generate_multi_device_15
DEBUG 01-07 14:54:41.874655.874655 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.875373.875373 cuda_h.py:19] end gate cost 0.0006365776062011719 seconds
DEBUG 01-07 14:54:41.875010.875010 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.875905.875905 lmp.py:744] 
DEBUG 01-07 14:54:41.875905.875905 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.875092.875092 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.875933.875933 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.875722.875722 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.875365.875365 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.875293.875293 lmp.py:749] 
DEBUG 01-07 14:54:41.875293.875293 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.875697.875697 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.875586.875586 lmp.py:767]   Expert 15 |     62 | CPU
DEBUG 01-07 14:54:41.875990.875990 lmp.py:767]   Expert 41 |     67 | CPU
DEBUG 01-07 14:54:41.875679.875679 lmp.py:767]   Expert  0 |     73 | CPU
DEBUG 01-07 14:54:41.875892.875892 lmp.py:767]   Expert 63 |     77 | CPU
DEBUG 01-07 14:54:41.875866.875866 lmp.py:767]   Expert 20 |     80 | CPU
DEBUG 01-07 14:54:41.875078.875078 lmp.py:767]   Expert 45 |     93 | CPU
DEBUG 01-07 14:54:41.875291.875291 lmp.py:767]   Expert 28 |     95 | CPU
DEBUG 01-07 14:54:41.876026.876026 lmp.py:767]   Expert  7 |     97 | CPU
DEBUG 01-07 14:54:41.876477.876477 lmp.py:767]   Expert 54 |    101 | CPU
DEBUG 01-07 14:54:41.876167.876167 lmp.py:767]   Expert 12 |    112 | CPU
DEBUG 01-07 14:54:41.876094.876094 lmp.py:767]   Expert 52 |    121 | CPU
DEBUG 01-07 14:54:41.876784.876784 lmp.py:767]   Expert 59 |    124 | CPU
DEBUG 01-07 14:54:41.876950.876950 lmp.py:767]   Expert  5 |    126 | CPU
DEBUG 01-07 14:54:41.876924.876924 lmp.py:767]   Expert 40 |    127 | CPU
DEBUG 01-07 14:54:41.876421.876421 lmp.py:767]   Expert  4 |    128 | CPU
DEBUG 01-07 14:54:41.876157.876157 lmp.py:767]   Expert 62 |    133 | CPU
DEBUG 01-07 14:54:41.876654.876654 lmp.py:767]   Expert 34 |    134 | CPU
DEBUG 01-07 14:54:41.876390.876390 lmp.py:767]   Expert 61 |    134 | CPU
DEBUG 01-07 14:54:41.876887.876887 lmp.py:767]   Expert 55 |    136 | CPU
DEBUG 01-07 14:54:41.876053.876053 lmp.py:767]   Expert 13 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876126.876126 lmp.py:767]   Expert 42 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876246.876246 lmp.py:767]   Expert 14 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876134.876134 lmp.py:767]   Expert 21 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876016.876016 lmp.py:767]   Expert 10 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876659.876659 lmp.py:767]   Expert 22 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876302.876302 lmp.py:767]   Expert 51 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876229.876229 lmp.py:767]   Expert 32 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876919.876919 lmp.py:767]   Expert 25 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876370.876370 lmp.py:767]   Expert 50 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876582.876582 lmp.py:767]   Expert 47 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876715.876715 lmp.py:767]   Expert 19 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876166.876166 lmp.py:767]   Expert 53 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876856.876856 lmp.py:767]   Expert  2 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876068.876068 lmp.py:767]   Expert  6 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876519.876519 lmp.py:767]   Expert 26 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876685.876685 lmp.py:767]   Expert 35 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876090.876090 lmp.py:767]   Expert  1 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876733.876733 lmp.py:767]   Expert 30 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876899.876899 lmp.py:767]   Expert 11 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876780.876780 lmp.py:767]   Expert 57 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876469.876469 lmp.py:767]   Expert 56 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876159.876159 lmp.py:767]   Expert 48 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876610.876610 lmp.py:767]   Expert 24 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876584.876584 lmp.py:767]   Expert 44 |    213 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876035.876035 lmp.py:767]   Expert 46 |    213 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876485.876485 lmp.py:767]   Expert 16 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876460.876460 lmp.py:767]   Expert 18 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876910.876910 lmp.py:767]   Expert 39 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876600.876600 lmp.py:767]   Expert 29 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876766.876766 lmp.py:767]   Expert 37 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876932.876932 lmp.py:767]   Expert  3 |    253 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876337.876337 lmp.py:767]   Expert 60 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876979.876979 lmp.py:767]   Expert 31 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876669.876669 lmp.py:767]   Expert 36 |    258 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876643.876643 lmp.py:767]   Expert 38 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876094.876094 lmp.py:767]   Expert  9 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876306.876306 lmp.py:767]   Expert 17 |    269 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876757.876757 lmp.py:767]   Expert 23 |    270 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876970.876970 lmp.py:767]   Expert 27 |    354 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876420.876420 lmp.py:767]   Expert 43 |    357 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876110.876110 lmp.py:767]   Expert  8 |    397 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876322.876322 lmp.py:767]   Expert 33 |    400 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876488.876488 lmp.py:767]   Expert 58 |    447 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.876893.876893 lmp.py:767]   Expert 49 |    553 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.876582.876582 lmp.py:769] 
DEBUG 01-07 14:54:41.876582.876582 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.876464.876464 lmp.py:770]   CPU:   2020 tokens
DEBUG 01-07 14:54:41.877868.877868 lmp.py:774]   cuda:1:   5081 tokens (22 experts)
DEBUG 01-07 14:54:41.877319.877319 lmp.py:774]   cuda:2:   5187 tokens (23 experts)
DEBUG 01-07 14:54:41.877531.877531 lmp.py:775]   Total GPU:  10268 tokens
DEBUG 01-07 14:54:41.877029.877029 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.877029.877029 lmp.py:776] 
DEBUG 01-07 14:54:41.877248.877248 cuda_h.py:19] end experts_map_get cost 0.0017266273498535156 seconds
DEBUG 01-07 14:54:41.877176.877176 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.877475.877475 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.877002.877002 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.878536.878536 cuda_h.py:19] end allocate_cuda_memory cost 0.001485586166381836 seconds
DEBUG 01-07 14:54:41.878856.878856 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.878374.878374 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.878613.878613 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.878501.878501 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c439fdaf-8a01-4ffd-88c6-30bf74410553
DEBUG 01-07 14:54:41.879527.879527 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.879423.879423 client.py:127] Model loaded
DEBUG 01-07 14:54:41.879234.879234 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.879620.879620 cuda_h.py:19] end restore2model cost 0.0004150867462158203 seconds
INFO 01-07 14:54:41.879159.879159 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c439fdaf-8a01-4ffd-88c6-30bf74410553
DEBUG 01-07 14:54:41.880724.880724 cuda_h.py:19] end sllm_worker_task cost 0.009992361068725586 seconds
DEBUG 01-07 14:54:41.880620.880620 cuda_h.py:19] end load_into_gpu_async cost 0.001230001449584961 seconds
DEBUG 01-07 14:54:41.880093.880093 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.880540.880540 cuda_h.py:19] end restore_tensors2 cost 0.00026679039001464844 seconds
DEBUG 01-07 14:54:41.880031.880031 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033376216888427734 seconds
DEBUG 01-07 14:54:41.880509.880509 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.882828.882828 cuda_h.py:19] end restore2model cost 0.0017871856689453125 seconds
DEBUG 01-07 14:54:41.882553.882553 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.882311.882311 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.882353.882353 cuda_h.py:19] end allocate_cuda_memory cost 0.00020742416381835938 seconds
DEBUG 01-07 14:54:41.882573.882573 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.882852.882852 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.882423.882423 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.882788.882788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d741b71a-359f-4687-acff-e7e8834e39d4
DEBUG 01-07 14:54:41.883654.883654 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.884925.884925 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d741b71a-359f-4687-acff-e7e8834e39d4
DEBUG 01-07 14:54:41.884550.884550 cuda_h.py:19] end load_into_gpu_async cost 0.0012471675872802734 seconds
DEBUG 01-07 14:54:41.884173.884173 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.884743.884743 cuda_h.py:19] end restore_tensors2 cost 0.00034737586975097656 seconds
DEBUG 01-07 14:54:41.884785.884785 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002141714096069336 seconds
DEBUG 01-07 14:54:41.884223.884223 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.887877.887877 cuda_h.py:19] end restore2model cost 0.002482175827026367 seconds
DEBUG 01-07 14:54:41.887204.887204 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.010110139846801758 seconds
DEBUG 01-07 14:54:41.887867.887867 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.887665.887665 lmp.py:816] 
DEBUG 01-07 14:54:41.887665.887665 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.887330.887330 cuda_h.py:19] end cpu_experts_submit cost 0.00013184547424316406 seconds
DEBUG 01-07 14:54:41.887086.887086 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.894046.894046 mlpmodule.py:749] group tensors cost 0.006996631622314453 s
DEBUG 01-07 14:54:41.897646.897646 mlpmodule.py:787] pad cost 0.0017364025115966797 s
DEBUG 01-07 14:54:41.897134.897134 mlpmodule.py:793] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-07 14:54:41.897992.897992 mlpmodule.py:798] move to cpu cost 4.482269287109375e-05 s
DEBUG 01-07 14:54:41.905192.905192 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.905927.905927 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.905831.905831 mlpmodule.py:818] group_w3 first element: -0.0595703125
WARNING 01-07 14:54:41.905054.905054 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.919355.919355 mlpmodule.py:838] group einsum cost 0.02222299575805664 s
DEBUG 01-07 14:54:41.920197.920197 mlpmodule.py:846] cpy2cputensor cost 0.00042629241943359375 s
DEBUG 01-07 14:54:41.922579.922579 cuda_h.py:19] end wait_cetm_experts cost 0.035444021224975586 seconds
DEBUG 01-07 14:54:41.923989.923989 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:41.924492.924492 cuda_h.py:19] end gpu_sexperts cost 0.0008988380432128906 seconds
DEBUG 01-07 14:54:41.924954.924954 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:41.924550.924550 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.100799560546875e-05 seconds
DEBUG 01-07 14:54:41.924181.924181 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:41.924052.924052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c439fdaf-8a01-4ffd-88c6-30bf74410553
INFO 01-07 14:54:41.925027.925027 client.py:127] Model loaded
INFO 01-07 14:54:41.925991.925991 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d741b71a-359f-4687-acff-e7e8834e39d4
INFO 01-07 14:54:41.926579.926579 client.py:127] Model loaded
DEBUG 01-07 14:54:41.926696.926696 cuda_h.py:19] end wait_experts_multi_device cost 0.0018444061279296875 seconds
DEBUG 01-07 14:54:41.926129.926129 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:41.926265.926265 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:41.929173.929173 mlpmodule.py:533] gpu group tensors cost 0.0010783672332763672 s
DEBUG 01-07 14:54:41.931874.931874 mlpmodule.py:707]  experts func einsum cost 0.04379153251647949 s
DEBUG 01-07 14:54:41.932040.932040 mlpmodule.py:566] gpu pad cost 0.0034112930297851562 s
DEBUG 01-07 14:54:41.933299.933299 mlpmodule.py:584] gpu group einsum cost 0.0010311603546142578 s
DEBUG 01-07 14:54:41.938811.938811 mlpmodule.py:656] gpu experts func einsum cost 0.010657310485839844 s
DEBUG 01-07 14:54:41.938662.938662 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:41.939039.939039 mlpmodule.py:533] gpu group tensors cost 0.0004572868347167969 s
DEBUG 01-07 14:54:41.941992.941992 mlpmodule.py:566] gpu pad cost 0.0013082027435302734 s
DEBUG 01-07 14:54:41.941758.941758 mlpmodule.py:584] gpu group einsum cost 0.00045800209045410156 s
DEBUG 01-07 14:54:41.943679.943679 mlpmodule.py:656] gpu experts func einsum cost 0.004334926605224609 s
DEBUG 01-07 14:54:41.943815.943815 cuda_h.py:19] end gpu_experts_multi_device cost 0.01705145835876465 seconds
DEBUG 01-07 14:54:41.943659.943659 cuda_h.py:19] end layer_moe_generate_multi_device_15 cost 0.06913971900939941 seconds
DEBUG 01-07 14:54:41.944264.944264 lmp.py:194] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-07 14:54:41.944703.944703 lmp.py:153] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-07 14:54:41.944882.944882 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 14:54:41.944837.944837 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 14:54:41.944972.944972 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.0994415283203125e-05 seconds
DEBUG 01-07 14:54:41.944158.944158 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.747245788574219e-05 seconds
DEBUG 01-07 14:54:41.944238.944238 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:41.944618.944618 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:41.944296.944296 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:41.944412.944412 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.944241.944241 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.944656.944656 cuda_h.py:19] end allocate_cuda_memory cost 0.000270843505859375 seconds
DEBUG 01-07 14:54:41.944936.944936 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.944884.944884 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.944561.944561 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.944072.944072 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e8010f2a-e9e3-4093-9b4d-d0e6521168c4
DEBUG 01-07 14:54:41.945796.945796 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.945569.945569 cuda_h.py:10] start self_attn
INFO 01-07 14:54:41.945565.945565 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e8010f2a-e9e3-4093-9b4d-d0e6521168c4
DEBUG 01-07 14:54:41.945925.945925 cuda_h.py:19] end load_into_gpu_async cost 0.0010116100311279297 seconds
DEBUG 01-07 14:54:41.945435.945435 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.946657.946657 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 14:54:41.946459.946459 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015850067138671875 seconds
INFO 01-07 14:54:41.946879.946879 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e8010f2a-e9e3-4093-9b4d-d0e6521168c4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:41.949880.949880 cuda_h.py:19] end self_attn cost 0.004093647003173828 seconds
DEBUG 01-07 14:54:41.949375.949375 cuda_h.py:19] end iln_self_attn_paln cost 0.005613803863525391 seconds
DEBUG 01-07 14:54:41.949628.949628 cuda_h.py:10] start layer_moe_generate_multi_device_16
DEBUG 01-07 14:54:41.949861.949861 cuda_h.py:10] start gate
DEBUG 01-07 14:54:41.950002.950002 cuda_h.py:19] end gate cost 0.0006344318389892578 seconds
DEBUG 01-07 14:54:41.950924.950924 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:41.951912.951912 lmp.py:744] 
DEBUG 01-07 14:54:41.951912.951912 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:41.951860.951860 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:41.951271.951271 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:41.951821.951821 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:41.951464.951464 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:41.951392.951392 lmp.py:749] 
DEBUG 01-07 14:54:41.951392.951392 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:41.951035.951035 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:41.951162.951162 lmp.py:767]   Expert 58 |     33 | CPU
DEBUG 01-07 14:54:41.951566.951566 lmp.py:767]   Expert 47 |     56 | CPU
DEBUG 01-07 14:54:41.951017.951017 lmp.py:767]   Expert 49 |     63 | CPU
DEBUG 01-07 14:54:41.951468.951468 lmp.py:767]   Expert 31 |     64 | CPU
DEBUG 01-07 14:54:41.951680.951680 lmp.py:767]   Expert 38 |     69 | CPU
DEBUG 01-07 14:54:41.951654.951654 lmp.py:767]   Expert  4 |     70 | CPU
DEBUG 01-07 14:54:41.951629.951629 lmp.py:767]   Expert 45 |     73 | CPU
DEBUG 01-07 14:54:41.951603.951603 lmp.py:767]   Expert 43 |     77 | CPU
DEBUG 01-07 14:54:41.951815.951815 lmp.py:767]   Expert 41 |     81 | CPU
DEBUG 01-07 14:54:41.951789.951789 lmp.py:767]   Expert 50 |     98 | CPU
DEBUG 01-07 14:54:41.951525.951525 lmp.py:767]   Expert 33 |    100 | CPU
DEBUG 01-07 14:54:41.951737.951737 lmp.py:767]   Expert 11 |    103 | CPU
DEBUG 01-07 14:54:41.951188.951188 lmp.py:767]   Expert 57 |    105 | CPU
DEBUG 01-07 14:54:41.951162.951162 lmp.py:767]   Expert  2 |    113 | CPU
DEBUG 01-07 14:54:41.951375.951375 lmp.py:767]   Expert 51 |    114 | CPU
DEBUG 01-07 14:54:41.951779.951779 lmp.py:767]   Expert  0 |    121 | CPU
DEBUG 01-07 14:54:41.951945.951945 lmp.py:767]   Expert 14 |    126 | CPU
DEBUG 01-07 14:54:41.951111.951111 lmp.py:767]   Expert 54 |    134 | CPU
DEBUG 01-07 14:54:41.951801.951801 lmp.py:767]   Expert 56 |    140 | CPU
DEBUG 01-07 14:54:41.951205.951205 lmp.py:767]   Expert 26 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951908.951908 lmp.py:767]   Expert 34 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951743.951743 lmp.py:767]   Expert 27 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951625.951625 lmp.py:767]   Expert 28 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951029.951029 lmp.py:767]   Expert 55 |    157 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951672.951672 lmp.py:767]   Expert 10 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951554.951554 lmp.py:767]   Expert 25 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951958.951958 lmp.py:767]   Expert  9 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951555.951555 lmp.py:767]   Expert 13 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951390.951390 lmp.py:767]   Expert 48 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951748.951748 lmp.py:767]   Expert 61 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951106.951106 lmp.py:767]   Expert  6 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951226.951226 lmp.py:767]   Expert  7 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951631.951631 lmp.py:767]   Expert 42 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951035.951035 lmp.py:767]   Expert 18 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951678.951678 lmp.py:767]   Expert 46 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951560.951560 lmp.py:767]   Expert 24 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951964.951964 lmp.py:767]   Expert 40 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951369.951369 lmp.py:767]   Expert 22 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951773.951773 lmp.py:767]   Expert 59 |    215 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951131.951131 lmp.py:767]   Expert 63 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951728.951728 lmp.py:767]   Expert 12 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951563.951563 lmp.py:767]   Expert 29 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.951160.951160 lmp.py:767]   Expert 21 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.951280.951280 lmp.py:767]   Expert 19 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952684.952684 lmp.py:767]   Expert 32 |    230 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952089.952089 lmp.py:767]   Expert 36 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952970.952970 lmp.py:767]   Expert  3 |    239 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952613.952613 lmp.py:767]   Expert 37 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952256.952256 lmp.py:767]   Expert  1 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952899.952899 lmp.py:767]   Expert 16 |    248 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952780.952780 lmp.py:767]   Expert 20 |    261 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952616.952616 lmp.py:767]   Expert  5 |    264 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952212.952212 lmp.py:767]   Expert  8 |    268 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952570.952570 lmp.py:767]   Expert 15 |    272 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952929.952929 lmp.py:767]   Expert 30 |    272 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952572.952572 lmp.py:767]   Expert 62 |    274 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952215.952215 lmp.py:767]   Expert 35 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952858.952858 lmp.py:767]   Expert 39 |    302 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952262.952262 lmp.py:767]   Expert 17 |    308 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952905.952905 lmp.py:767]   Expert 60 |    311 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952548.952548 lmp.py:767]   Expert 52 |    355 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952191.952191 lmp.py:767]   Expert 23 |    374 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952834.952834 lmp.py:767]   Expert 44 |    375 | GPU1(cuda:2)
DEBUG 01-07 14:54:41.952113.952113 lmp.py:767]   Expert 53 |    436 | GPU0(cuda:1)
DEBUG 01-07 14:54:41.952147.952147 lmp.py:769] 
DEBUG 01-07 14:54:41.952147.952147 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:41.952042.952042 lmp.py:770]   CPU:   1740 tokens
DEBUG 01-07 14:54:41.952599.952599 lmp.py:774]   cuda:1:   5205 tokens (22 experts)
DEBUG 01-07 14:54:41.952242.952242 lmp.py:774]   cuda:2:   5343 tokens (23 experts)
DEBUG 01-07 14:54:41.952931.952931 lmp.py:775]   Total GPU:  10548 tokens
DEBUG 01-07 14:54:41.952667.952667 lmp.py:776] ============================================================
DEBUG 01-07 14:54:41.952667.952667 lmp.py:776] 
DEBUG 01-07 14:54:41.952078.952078 cuda_h.py:19] end experts_map_get cost 0.0018053054809570312 seconds
DEBUG 01-07 14:54:41.952483.952483 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:41.952021.952021 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.952455.952455 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.952059.952059 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
INFO 01-07 14:54:41.953406.953406 client.py:127] Model loaded
DEBUG 01-07 14:54:41.953899.953899 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.953543.953543 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.953591.953591 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.953621.953621 cuda_h.py:19] end restore2model cost 0.0004570484161376953 seconds
DEBUG 01-07 14:54:41.953988.953988 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.953812.953812 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19bb8c8c-ff03-474b-857a-2de91b0131c7
DEBUG 01-07 14:54:41.954983.954983 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:41.953844.953844 cuda_h.py:19] end sllm_worker_task cost 0.00934457778930664 seconds
INFO 01-07 14:54:41.954801.954801 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19bb8c8c-ff03-474b-857a-2de91b0131c7
DEBUG 01-07 14:54:41.954684.954684 cuda_h.py:19] end load_into_gpu_async cost 0.0017893314361572266 seconds
DEBUG 01-07 14:54:41.954148.954148 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.955733.955733 cuda_h.py:19] end restore_tensors2 cost 0.0002300739288330078 seconds
DEBUG 01-07 14:54:41.955549.955549 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002684354782104492 seconds
DEBUG 01-07 14:54:41.955643.955643 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.957441.957441 cuda_h.py:19] end restore2model cost 0.001856088638305664 seconds
DEBUG 01-07 14:54:41.957258.957258 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:41.957208.957208 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:41.957713.957713 cuda_h.py:19] end allocate_cuda_memory cost 0.00019860267639160156 seconds
DEBUG 01-07 14:54:41.957595.957595 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:41.957014.957014 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:41.957154.957154 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:41.957519.957519 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 31d3fb67-4469-40ec-94eb-7d03d5f18778
DEBUG 01-07 14:54:41.957477.957477 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:41.958249.958249 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 31d3fb67-4469-40ec-94eb-7d03d5f18778
DEBUG 01-07 14:54:41.959694.959694 cuda_h.py:19] end load_into_gpu_async cost 0.0013427734375 seconds
DEBUG 01-07 14:54:41.959490.959490 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:41.959519.959519 cuda_h.py:19] end restore_tensors2 cost 0.0002415180206298828 seconds
DEBUG 01-07 14:54:41.959288.959288 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002065896987915039 seconds
DEBUG 01-07 14:54:41.959283.959283 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:41.961638.961638 cuda_h.py:19] end restore2model cost 0.0018849372863769531 seconds
DEBUG 01-07 14:54:41.961190.961190 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008821725845336914 seconds
DEBUG 01-07 14:54:41.961508.961508 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:41.961041.961041 lmp.py:816] 
DEBUG 01-07 14:54:41.961041.961041 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:41.961361.961361 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 14:54:41.961726.961726 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:41.974352.974352 mlpmodule.py:749] group tensors cost 0.012629985809326172 s
DEBUG 01-07 14:54:41.976599.976599 mlpmodule.py:787] pad cost 0.001413583755493164 s
DEBUG 01-07 14:54:41.976285.976285 mlpmodule.py:793] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-07 14:54:41.976083.976083 mlpmodule.py:798] move to cpu cost 5.364418029785156e-05 s
DEBUG 01-07 14:54:41.986968.986968 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:41.986504.986504 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:41.986885.986885 mlpmodule.py:818] group_w3 first element: -0.02490234375
WARNING 01-07 14:54:41.986579.986579 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:41.999906.999906 mlpmodule.py:838] group einsum cost 0.02271556854248047 s
DEBUG 01-07 14:54:42.000720.000720 mlpmodule.py:846] cpy2cputensor cost 0.00036978721618652344 s
DEBUG 01-07 14:54:42.003465.003465 cuda_h.py:19] end wait_cetm_experts cost 0.04140496253967285 seconds
DEBUG 01-07 14:54:42.003828.003828 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.003210.003210 cuda_h.py:19] end gpu_sexperts cost 0.0006811618804931641 seconds
DEBUG 01-07 14:54:42.003358.003358 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.004698.004698 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-07 14:54:42.004123.004123 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.004747.004747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19bb8c8c-ff03-474b-857a-2de91b0131c7
INFO 01-07 14:54:42.005285.005285 client.py:127] Model loaded
INFO 01-07 14:54:42.005764.005764 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 31d3fb67-4469-40ec-94eb-7d03d5f18778
INFO 01-07 14:54:42.005206.005206 client.py:127] Model loaded
DEBUG 01-07 14:54:42.005255.005255 cuda_h.py:19] end wait_experts_multi_device cost 0.0017101764678955078 seconds
DEBUG 01-07 14:54:42.005448.005448 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.005192.005192 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.007541.007541 mlpmodule.py:533] gpu group tensors cost 0.0006673336029052734 s
DEBUG 01-07 14:54:42.009782.009782 mlpmodule.py:566] gpu pad cost 0.0017895698547363281 s
DEBUG 01-07 14:54:42.009963.009963 mlpmodule.py:584] gpu group einsum cost 0.0005652904510498047 s
DEBUG 01-07 14:54:42.011604.011604 mlpmodule.py:707]  experts func einsum cost 0.049437522888183594 s
DEBUG 01-07 14:54:42.012598.012598 mlpmodule.py:656] gpu experts func einsum cost 0.00534367561340332 s
DEBUG 01-07 14:54:42.012226.012226 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.013940.013940 mlpmodule.py:533] gpu group tensors cost 0.00046563148498535156 s
DEBUG 01-07 14:54:42.014406.014406 mlpmodule.py:566] gpu pad cost 0.0011980533599853516 s
DEBUG 01-07 14:54:42.015648.015648 mlpmodule.py:584] gpu group einsum cost 0.0004246234893798828 s
DEBUG 01-07 14:54:42.016661.016661 mlpmodule.py:656] gpu experts func einsum cost 0.004192829132080078 s
DEBUG 01-07 14:54:42.017989.017989 cuda_h.py:19] end gpu_experts_multi_device cost 0.011180639266967773 seconds
DEBUG 01-07 14:54:42.017595.017595 cuda_h.py:19] end layer_moe_generate_multi_device_16 cost 0.06722044944763184 seconds
DEBUG 01-07 14:54:42.017378.017378 lmp.py:194] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-07 14:54:42.017605.017605 lmp.py:153] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-07 14:54:42.017354.017354 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 14:54:42.017832.017832 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 14:54:42.017536.017536 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.2901763916015625e-05 seconds
DEBUG 01-07 14:54:42.017862.017862 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.628036499023438e-05 seconds
DEBUG 01-07 14:54:42.017366.017366 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.017633.017633 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.017973.017973 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.018385.018385 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.018070.018070 cuda_h.py:19] end allocate_cuda_memory cost 0.0004329681396484375 seconds
DEBUG 01-07 14:54:42.018431.018431 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.018658.018658 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.018178.018178 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.018438.018438 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.018048.018048 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 00e50cd3-884c-48d4-a21a-c38be97606db
DEBUG 01-07 14:54:42.018601.018601 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.019305.019305 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.020829.020829 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 00e50cd3-884c-48d4-a21a-c38be97606db
DEBUG 01-07 14:54:42.020427.020427 cuda_h.py:19] end load_into_gpu_async cost 0.0013082027435302734 seconds
DEBUG 01-07 14:54:42.020415.020415 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.020166.020166 cuda_h.py:19] end restore_tensors2 cost 7.128715515136719e-05 seconds
DEBUG 01-07 14:54:42.020922.020922 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022134780883789062 seconds
INFO 01-07 14:54:42.020381.020381 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 00e50cd3-884c-48d4-a21a-c38be97606db
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.022922.022922 cuda_h.py:19] end self_attn cost 0.0033197402954101562 seconds
DEBUG 01-07 14:54:42.023211.023211 cuda_h.py:19] end iln_self_attn_paln cost 0.0052220821380615234 seconds
DEBUG 01-07 14:54:42.023087.023087 cuda_h.py:10] start layer_moe_generate_multi_device_17
DEBUG 01-07 14:54:42.023273.023273 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.023158.023158 cuda_h.py:19] end gate cost 0.0006916522979736328 seconds
DEBUG 01-07 14:54:42.023796.023796 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.024326.024326 lmp.py:744] 
DEBUG 01-07 14:54:42.024326.024326 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.024374.024374 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.024739.024739 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.024766.024766 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.024647.024647 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.024575.024575 lmp.py:749] 
DEBUG 01-07 14:54:42.024575.024575 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.024264.024264 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.024391.024391 lmp.py:767]   Expert  4 |     10 | CPU
DEBUG 01-07 14:54:42.024511.024511 lmp.py:767]   Expert 28 |     29 | CPU
DEBUG 01-07 14:54:42.024677.024677 lmp.py:767]   Expert  7 |     47 | CPU
DEBUG 01-07 14:54:42.024605.024605 lmp.py:767]   Expert 53 |     55 | CPU
DEBUG 01-07 14:54:42.024294.024294 lmp.py:767]   Expert 52 |     65 | CPU
DEBUG 01-07 14:54:42.024222.024222 lmp.py:767]   Expert 43 |     70 | CPU
DEBUG 01-07 14:54:42.024150.024150 lmp.py:767]   Expert 49 |     80 | CPU
DEBUG 01-07 14:54:42.024508.024508 lmp.py:767]   Expert 12 |     89 | CPU
DEBUG 01-07 14:54:42.024628.024628 lmp.py:767]   Expert 47 |    105 | CPU
DEBUG 01-07 14:54:42.024032.024032 lmp.py:767]   Expert 15 |    108 | CPU
DEBUG 01-07 14:54:42.024675.024675 lmp.py:767]   Expert 33 |    108 | CPU
DEBUG 01-07 14:54:42.024318.024318 lmp.py:767]   Expert  2 |    109 | CPU
DEBUG 01-07 14:54:42.024246.024246 lmp.py:767]   Expert 24 |    109 | CPU
DEBUG 01-07 14:54:42.024173.024173 lmp.py:767]   Expert 50 |    111 | CPU
DEBUG 01-07 14:54:42.024624.024624 lmp.py:767]   Expert 39 |    112 | CPU
DEBUG 01-07 14:54:42.024552.024552 lmp.py:767]   Expert 60 |    113 | CPU
DEBUG 01-07 14:54:42.024241.024241 lmp.py:767]   Expert 36 |    116 | CPU
DEBUG 01-07 14:54:42.024931.024931 lmp.py:767]   Expert  6 |    123 | CPU
DEBUG 01-07 14:54:42.024382.024382 lmp.py:767]   Expert 61 |    125 | CPU
DEBUG 01-07 14:54:42.024263.024263 lmp.py:767]   Expert 25 |    126 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.024860.024860 lmp.py:767]   Expert 59 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.024218.024218 lmp.py:767]   Expert  3 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.024576.024576 lmp.py:767]   Expert 58 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.024457.024457 lmp.py:767]   Expert 27 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.024100.024100 lmp.py:767]   Expert 31 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.024267.024267 lmp.py:767]   Expert 57 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025671.025671 lmp.py:767]   Expert 30 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025837.025837 lmp.py:767]   Expert 38 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025003.025003 lmp.py:767]   Expert  8 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025408.025408 lmp.py:767]   Expert 10 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025574.025574 lmp.py:767]   Expert 40 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025740.025740 lmp.py:767]   Expert 54 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025383.025383 lmp.py:767]   Expert 14 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025980.025980 lmp.py:767]   Expert 32 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025623.025623 lmp.py:767]   Expert 41 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025504.025504 lmp.py:767]   Expert 37 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025670.025670 lmp.py:767]   Expert 46 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025598.025598 lmp.py:767]   Expert 19 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025764.025764 lmp.py:767]   Expert 42 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025930.025930 lmp.py:767]   Expert 11 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025620.025620 lmp.py:767]   Expert 34 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025024.025024 lmp.py:767]   Expert  0 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025190.025190 lmp.py:767]   Expert 26 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025357.025357 lmp.py:767]   Expert 18 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025715.025715 lmp.py:767]   Expert 22 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025596.025596 lmp.py:767]   Expert 56 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025716.025716 lmp.py:767]   Expert 44 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025597.025597 lmp.py:767]   Expert  1 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025479.025479 lmp.py:767]   Expert 51 |    207 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025883.025883 lmp.py:767]   Expert 20 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025811.025811 lmp.py:767]   Expert 29 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025977.025977 lmp.py:767]   Expert 45 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025905.025905 lmp.py:767]   Expert 48 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025071.025071 lmp.py:767]   Expert 21 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025476.025476 lmp.py:767]   Expert 35 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025403.025403 lmp.py:767]   Expert 16 |    252 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025954.025954 lmp.py:767]   Expert 55 |    255 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025881.025881 lmp.py:767]   Expert  5 |    294 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025809.025809 lmp.py:767]   Expert 23 |    372 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025737.025737 lmp.py:767]   Expert 13 |    380 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025903.025903 lmp.py:767]   Expert 17 |    436 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025592.025592 lmp.py:767]   Expert  9 |    457 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025328.025328 lmp.py:767]   Expert 63 |    459 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.025540.025540 lmp.py:767]   Expert 62 |   1188 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.025561.025561 lmp.py:769] 
DEBUG 01-07 14:54:42.025561.025561 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.025773.025773 lmp.py:770]   CPU:   1684 tokens
DEBUG 01-07 14:54:42.025462.025462 lmp.py:774]   cuda:1:   5344 tokens (22 experts)
DEBUG 01-07 14:54:42.025198.025198 lmp.py:774]   cuda:2:   5260 tokens (23 experts)
DEBUG 01-07 14:54:42.025934.025934 lmp.py:775]   Total GPU:  10604 tokens
DEBUG 01-07 14:54:42.025192.025192 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.025192.025192 lmp.py:776] 
DEBUG 01-07 14:54:42.025412.025412 cuda_h.py:19] end experts_map_get cost 0.001760721206665039 seconds
DEBUG 01-07 14:54:42.025293.025293 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.025599.025599 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.025517.025517 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.026700.026700 cuda_h.py:19] end allocate_cuda_memory cost 0.0008738040924072266 seconds
DEBUG 01-07 14:54:42.026179.026179 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.026604.026604 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.026844.026844 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.027924.027924 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b8e4938d-bc65-4216-9dea-585ef121375b
DEBUG 01-07 14:54:42.027832.027832 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.028155.028155 client.py:127] Model loaded
DEBUG 01-07 14:54:42.028792.028792 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.028084.028084 cuda_h.py:19] end restore2model cost 0.0003523826599121094 seconds
DEBUG 01-07 14:54:42.028138.028138 cuda_h.py:19] end sllm_worker_task cost 0.010874271392822266 seconds
INFO 01-07 14:54:42.028691.028691 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b8e4938d-bc65-4216-9dea-585ef121375b
DEBUG 01-07 14:54:42.029017.029017 cuda_h.py:19] end load_into_gpu_async cost 0.0020575523376464844 seconds
DEBUG 01-07 14:54:42.029436.029436 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.029822.029822 cuda_h.py:19] end restore_tensors2 cost 0.0004343986511230469 seconds
DEBUG 01-07 14:54:42.029691.029691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003696441650390625 seconds
DEBUG 01-07 14:54:42.029215.029215 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.031365.031365 cuda_h.py:19] end restore2model cost 0.0018734931945800781 seconds
DEBUG 01-07 14:54:42.031866.031866 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.031061.031061 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.031667.031667 cuda_h.py:19] end allocate_cuda_memory cost 0.00023603439331054688 seconds
DEBUG 01-07 14:54:42.032079.032079 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.032358.032358 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.032452.032452 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.032340.032340 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dc8486c9-c0f4-45a4-a898-fad491baf9db
DEBUG 01-07 14:54:42.032962.032962 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.033125.033125 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dc8486c9-c0f4-45a4-a898-fad491baf9db
DEBUG 01-07 14:54:42.033438.033438 cuda_h.py:19] end load_into_gpu_async cost 0.0010051727294921875 seconds
DEBUG 01-07 14:54:42.033857.033857 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.033439.033439 cuda_h.py:19] end restore_tensors2 cost 0.00036835670471191406 seconds
DEBUG 01-07 14:54:42.033831.033831 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019123554229736328 seconds
DEBUG 01-07 14:54:42.033303.033303 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.035056.035056 cuda_h.py:19] end restore2model cost 0.0018961429595947266 seconds
DEBUG 01-07 14:54:42.035158.035158 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00977468490600586 seconds
DEBUG 01-07 14:54:42.035715.035715 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.035770.035770 lmp.py:816] 
DEBUG 01-07 14:54:42.035770.035770 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.035891.035891 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-07 14:54:42.035064.035064 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.047194.047194 mlpmodule.py:749] group tensors cost 0.011264324188232422 s
DEBUG 01-07 14:54:42.049385.049385 mlpmodule.py:787] pad cost 0.0016946792602539062 s
DEBUG 01-07 14:54:42.049071.049071 mlpmodule.py:793] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-07 14:54:42.049875.049875 mlpmodule.py:798] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-07 14:54:42.058061.058061 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.058160.058160 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.058964.058964 mlpmodule.py:818] group_w3 first element: 0.00457763671875
WARNING 01-07 14:54:42.058095.058095 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.072333.072333 mlpmodule.py:838] group einsum cost 0.02252364158630371 s
DEBUG 01-07 14:54:42.073339.073339 mlpmodule.py:846] cpy2cputensor cost 0.0003771781921386719 s
DEBUG 01-07 14:54:42.075596.075596 cuda_h.py:19] end wait_cetm_experts cost 0.039940834045410156 seconds
DEBUG 01-07 14:54:42.075124.075124 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.076035.076035 cuda_h.py:19] end gpu_sexperts cost 0.0008280277252197266 seconds
DEBUG 01-07 14:54:42.076562.076562 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.077380.077380 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-07 14:54:42.077793.077793 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.077258.077258 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b8e4938d-bc65-4216-9dea-585ef121375b
INFO 01-07 14:54:42.078975.078975 client.py:127] Model loaded
INFO 01-07 14:54:42.078099.078099 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dc8486c9-c0f4-45a4-a898-fad491baf9db
INFO 01-07 14:54:42.079544.079544 client.py:127] Model loaded
DEBUG 01-07 14:54:42.079793.079793 cuda_h.py:19] end wait_experts_multi_device cost 0.002325296401977539 seconds
DEBUG 01-07 14:54:42.079643.079643 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.079567.079567 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.081491.081491 mlpmodule.py:533] gpu group tensors cost 0.0010404586791992188 s
DEBUG 01-07 14:54:42.084534.084534 mlpmodule.py:707]  experts func einsum cost 0.048931121826171875 s
DEBUG 01-07 14:54:42.085650.085650 mlpmodule.py:566] gpu pad cost 0.0034148693084716797 s
DEBUG 01-07 14:54:42.086354.086354 mlpmodule.py:584] gpu group einsum cost 0.0010721683502197266 s
DEBUG 01-07 14:54:42.091140.091140 mlpmodule.py:656] gpu experts func einsum cost 0.01013636589050293 s
DEBUG 01-07 14:54:42.091912.091912 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.092712.092712 mlpmodule.py:533] gpu group tensors cost 0.0004458427429199219 s
DEBUG 01-07 14:54:42.093326.093326 mlpmodule.py:566] gpu pad cost 0.0016522407531738281 s
DEBUG 01-07 14:54:42.094348.094348 mlpmodule.py:584] gpu group einsum cost 0.0009562969207763672 s
DEBUG 01-07 14:54:42.096893.096893 mlpmodule.py:656] gpu experts func einsum cost 0.005248546600341797 s
DEBUG 01-07 14:54:42.097367.097367 cuda_h.py:19] end gpu_experts_multi_device cost 0.017403364181518555 seconds
DEBUG 01-07 14:54:42.097317.097317 cuda_h.py:19] end layer_moe_generate_multi_device_17 cost 0.07390952110290527 seconds
DEBUG 01-07 14:54:42.097598.097598 lmp.py:194] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-07 14:54:42.097136.097136 lmp.py:153] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-07 14:54:42.097985.097985 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 14:54:42.097416.097416 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 14:54:42.097359.097359 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.123283386230469e-05 seconds
DEBUG 01-07 14:54:42.097069.097069 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.67572021484375e-05 seconds
DEBUG 01-07 14:54:42.097672.097672 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.097482.097482 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.097418.097418 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.097991.097991 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.097351.097351 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.098073.098073 cuda_h.py:19] end allocate_cuda_memory cost 0.00018143653869628906 seconds
DEBUG 01-07 14:54:42.098923.098923 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.098871.098871 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.098217.098217 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.098205.098205 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 083f57fd-fc86-4981-ac7e-d18f99e90d79
DEBUG 01-07 14:54:42.098022.098022 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.098035.098035 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.099286.099286 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 083f57fd-fc86-4981-ac7e-d18f99e90d79
DEBUG 01-07 14:54:42.099453.099453 cuda_h.py:19] end load_into_gpu_async cost 0.0011653900146484375 seconds
DEBUG 01-07 14:54:42.099964.099964 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.099086.099086 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-07 14:54:42.099888.099888 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001646280288696289 seconds
INFO 01-07 14:54:42.099400.099400 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 083f57fd-fc86-4981-ac7e-d18f99e90d79
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.102352.102352 cuda_h.py:19] end self_attn cost 0.0040416717529296875 seconds
DEBUG 01-07 14:54:42.103687.103687 cuda_h.py:19] end iln_self_attn_paln cost 0.005559682846069336 seconds
DEBUG 01-07 14:54:42.103417.103417 cuda_h.py:10] start layer_moe_generate_multi_device_18
DEBUG 01-07 14:54:42.103412.103412 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.103971.103971 cuda_h.py:19] end gate cost 0.0006623268127441406 seconds
DEBUG 01-07 14:54:42.104662.104662 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.104477.104477 lmp.py:744] 
DEBUG 01-07 14:54:42.104477.104477 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.104048.104048 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.104605.104605 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.104394.104394 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.104514.104514 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.104203.104203 lmp.py:749] 
DEBUG 01-07 14:54:42.104203.104203 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.104369.104369 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.104496.104496 lmp.py:767]   Expert 32 |     37 | CPU
DEBUG 01-07 14:54:42.104185.104185 lmp.py:767]   Expert 30 |     54 | CPU
DEBUG 01-07 14:54:42.104159.104159 lmp.py:767]   Expert  5 |     55 | CPU
DEBUG 01-07 14:54:42.104372.104372 lmp.py:767]   Expert 46 |     72 | CPU
DEBUG 01-07 14:54:42.104584.104584 lmp.py:767]   Expert 40 |     89 | CPU
DEBUG 01-07 14:54:42.104796.104796 lmp.py:767]   Expert  8 |     91 | CPU
DEBUG 01-07 14:54:42.104771.104771 lmp.py:767]   Expert 12 |     98 | CPU
DEBUG 01-07 14:54:42.104268.104268 lmp.py:767]   Expert 17 |    106 | CPU
DEBUG 01-07 14:54:42.104242.104242 lmp.py:767]   Expert 60 |    111 | CPU
DEBUG 01-07 14:54:42.104169.104169 lmp.py:767]   Expert 27 |    112 | CPU
DEBUG 01-07 14:54:42.104620.104620 lmp.py:767]   Expert 58 |    112 | CPU
DEBUG 01-07 14:54:42.104310.104310 lmp.py:767]   Expert  3 |    116 | CPU
DEBUG 01-07 14:54:42.104237.104237 lmp.py:767]   Expert 21 |    118 | CPU
DEBUG 01-07 14:54:42.104688.104688 lmp.py:767]   Expert 28 |    118 | CPU
DEBUG 01-07 14:54:42.104185.104185 lmp.py:767]   Expert 29 |    120 | CPU
DEBUG 01-07 14:54:42.104921.104921 lmp.py:767]   Expert 25 |    126 | CPU
DEBUG 01-07 14:54:42.104418.104418 lmp.py:767]   Expert 41 |    126 | CPU
DEBUG 01-07 14:54:42.104154.104154 lmp.py:767]   Expert 35 |    132 | CPU
DEBUG 01-07 14:54:42.104413.104413 lmp.py:767]   Expert 19 |    133 | CPU
DEBUG 01-07 14:54:42.104340.104340 lmp.py:767]   Expert  0 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.104268.104268 lmp.py:767]   Expert 52 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.104196.104196 lmp.py:767]   Expert 54 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.104362.104362 lmp.py:767]   Expert  6 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.104767.104767 lmp.py:767]   Expert 56 |    148 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105410.105410 lmp.py:767]   Expert 37 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105576.105576 lmp.py:767]   Expert 63 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105742.105742 lmp.py:767]   Expert 48 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105193.105193 lmp.py:767]   Expert 53 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105882.105882 lmp.py:767]   Expert 36 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105333.105333 lmp.py:767]   Expert 59 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105453.105453 lmp.py:767]   Expert  1 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105857.105857 lmp.py:767]   Expert  9 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105262.105262 lmp.py:767]   Expert 39 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105905.105905 lmp.py:767]   Expert 20 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105548.105548 lmp.py:767]   Expert 11 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105383.105383 lmp.py:767]   Expert 42 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105741.105741 lmp.py:767]   Expert 61 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105099.105099 lmp.py:767]   Expert  7 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105934.105934 lmp.py:767]   Expert 34 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105577.105577 lmp.py:767]   Expert 43 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105220.105220 lmp.py:767]   Expert 55 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105625.105625 lmp.py:767]   Expert 47 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105791.105791 lmp.py:767]   Expert 16 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105957.105957 lmp.py:767]   Expert 57 |    219 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105123.105123 lmp.py:767]   Expert 13 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105528.105528 lmp.py:767]   Expert 18 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105456.105456 lmp.py:767]   Expert 15 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105860.105860 lmp.py:767]   Expert  4 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105503.105503 lmp.py:767]   Expert 33 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105623.105623 lmp.py:767]   Expert 22 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105743.105743 lmp.py:767]   Expert 31 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105624.105624 lmp.py:767]   Expert 45 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105982.105982 lmp.py:767]   Expert 50 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105387.105387 lmp.py:767]   Expert 51 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105030.105030 lmp.py:767]   Expert 49 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105434.105434 lmp.py:767]   Expert 38 |    274 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105839.105839 lmp.py:767]   Expert 26 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105005.105005 lmp.py:767]   Expert 10 |    290 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105410.105410 lmp.py:767]   Expert 44 |    297 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105053.105053 lmp.py:767]   Expert  2 |    302 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105457.105457 lmp.py:767]   Expert 24 |    306 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105339.105339 lmp.py:767]   Expert 14 |    317 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105982.105982 lmp.py:767]   Expert 23 |    408 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.105863.105863 lmp.py:767]   Expert 62 |    672 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.105029.105029 lmp.py:769] 
DEBUG 01-07 14:54:42.105029.105029 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.105149.105149 lmp.py:770]   CPU:   1926 tokens
DEBUG 01-07 14:54:42.105222.105222 lmp.py:774]   cuda:1:   5182 tokens (22 experts)
DEBUG 01-07 14:54:42.105865.105865 lmp.py:774]   cuda:2:   5180 tokens (23 experts)
DEBUG 01-07 14:54:42.105555.105555 lmp.py:775]   Total GPU:  10362 tokens
DEBUG 01-07 14:54:42.105006.105006 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.105006.105006 lmp.py:776] 
DEBUG 01-07 14:54:42.105417.105417 cuda_h.py:19] end experts_map_get cost 0.0017571449279785156 seconds
DEBUG 01-07 14:54:42.105298.105298 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.105075.105075 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.105555.105555 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.106536.106536 cuda_h.py:19] end allocate_cuda_memory cost 0.00019979476928710938 seconds
DEBUG 01-07 14:54:42.106439.106439 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.106248.106248 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.106488.106488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.106138.106138 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 521c3851-e294-40c1-b748-0d591f881ecc
DEBUG 01-07 14:54:42.106482.106482 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.106947.106947 client.py:127] Model loaded
DEBUG 01-07 14:54:42.106929.106929 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.107859.107859 cuda_h.py:19] end restore2model cost 0.0004336833953857422 seconds
INFO 01-07 14:54:42.107934.107934 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 521c3851-e294-40c1-b748-0d591f881ecc
DEBUG 01-07 14:54:42.107122.107122 cuda_h.py:19] end sllm_worker_task cost 0.009649276733398438 seconds
DEBUG 01-07 14:54:42.107687.107687 cuda_h.py:19] end load_into_gpu_async cost 0.0012302398681640625 seconds
DEBUG 01-07 14:54:42.107021.107021 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.108034.108034 cuda_h.py:19] end restore_tensors2 cost 0.0003657341003417969 seconds
DEBUG 01-07 14:54:42.108095.108095 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021686553955078125 seconds
DEBUG 01-07 14:54:42.108474.108474 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.110160.110160 cuda_h.py:19] end restore2model cost 0.0018777847290039062 seconds
DEBUG 01-07 14:54:42.110938.110938 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.110319.110319 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.110500.110500 cuda_h.py:19] end allocate_cuda_memory cost 0.00023937225341796875 seconds
DEBUG 01-07 14:54:42.110674.110674 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.110477.110477 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.110663.110663 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.110836.110836 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0f7d76e4-b805-476c-899b-8f19b697d8f2
DEBUG 01-07 14:54:42.110398.110398 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.111470.111470 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0f7d76e4-b805-476c-899b-8f19b697d8f2
DEBUG 01-07 14:54:42.111021.111021 cuda_h.py:19] end load_into_gpu_async cost 0.0010306835174560547 seconds
DEBUG 01-07 14:54:42.111486.111486 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.112240.112240 cuda_h.py:19] end restore_tensors2 cost 0.0003552436828613281 seconds
DEBUG 01-07 14:54:42.112540.112540 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001924753189086914 seconds
DEBUG 01-07 14:54:42.112918.112918 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.114056.114056 cuda_h.py:19] end restore2model cost 0.0018987655639648438 seconds
DEBUG 01-07 14:54:42.114429.114429 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008220911026000977 seconds
DEBUG 01-07 14:54:42.114483.114483 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.114538.114538 lmp.py:816] 
DEBUG 01-07 14:54:42.114538.114538 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.114898.114898 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-07 14:54:42.114640.114640 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.121689.121689 mlpmodule.py:749] group tensors cost 0.006840229034423828 s
DEBUG 01-07 14:54:42.123614.123614 mlpmodule.py:787] pad cost 0.0012636184692382812 s
DEBUG 01-07 14:54:42.123055.123055 mlpmodule.py:793] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-07 14:54:42.123786.123786 mlpmodule.py:798] move to cpu cost 3.719329833984375e-05 s
DEBUG 01-07 14:54:42.132204.132204 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.132541.132541 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.132254.132254 mlpmodule.py:818] group_w3 first element: 0.0264892578125
WARNING 01-07 14:54:42.133715.133715 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.149697.149697 mlpmodule.py:838] group einsum cost 0.025552988052368164 s
DEBUG 01-07 14:54:42.149704.149704 mlpmodule.py:846] cpy2cputensor cost 0.0004038810729980469 s
DEBUG 01-07 14:54:42.152085.152085 cuda_h.py:19] end wait_cetm_experts cost 0.037950992584228516 seconds
DEBUG 01-07 14:54:42.152575.152575 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.153405.153405 cuda_h.py:19] end gpu_sexperts cost 0.0007631778717041016 seconds
DEBUG 01-07 14:54:42.153362.153362 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.153511.153511 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.2901763916015625e-05 seconds
DEBUG 01-07 14:54:42.153209.153209 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.153005.153005 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 521c3851-e294-40c1-b748-0d591f881ecc
INFO 01-07 14:54:42.154576.154576 client.py:127] Model loaded
INFO 01-07 14:54:42.154573.154573 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0f7d76e4-b805-476c-899b-8f19b697d8f2
INFO 01-07 14:54:42.155297.155297 client.py:127] Model loaded
DEBUG 01-07 14:54:42.155645.155645 cuda_h.py:19] end wait_experts_multi_device cost 0.002294778823852539 seconds
DEBUG 01-07 14:54:42.156018.156018 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.156008.156008 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.158978.158978 mlpmodule.py:533] gpu group tensors cost 0.0008628368377685547 s
DEBUG 01-07 14:54:42.160663.160663 mlpmodule.py:707]  experts func einsum cost 0.04623842239379883 s
DEBUG 01-07 14:54:42.161294.161294 mlpmodule.py:566] gpu pad cost 0.0028192996978759766 s
DEBUG 01-07 14:54:42.161190.161190 mlpmodule.py:584] gpu group einsum cost 0.0005004405975341797 s
DEBUG 01-07 14:54:42.164062.164062 mlpmodule.py:656] gpu experts func einsum cost 0.0067632198333740234 s
DEBUG 01-07 14:54:42.164206.164206 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.165116.165116 mlpmodule.py:533] gpu group tensors cost 0.0004918575286865234 s
DEBUG 01-07 14:54:42.166075.166075 mlpmodule.py:566] gpu pad cost 0.0014805793762207031 s
DEBUG 01-07 14:54:42.167426.167426 mlpmodule.py:584] gpu group einsum cost 0.0005271434783935547 s
DEBUG 01-07 14:54:42.169608.169608 mlpmodule.py:656] gpu experts func einsum cost 0.004927873611450195 s
DEBUG 01-07 14:54:42.169255.169255 cuda_h.py:19] end gpu_experts_multi_device cost 0.013732194900512695 seconds
DEBUG 01-07 14:54:42.169550.169550 cuda_h.py:19] end layer_moe_generate_multi_device_18 cost 0.06663990020751953 seconds
DEBUG 01-07 14:54:42.170712.170712 lmp.py:194] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-07 14:54:42.170635.170635 lmp.py:153] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-07 14:54:42.170152.170152 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 14:54:42.170875.170875 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 14:54:42.170163.170163 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.409385681152344e-05 seconds
DEBUG 01-07 14:54:42.170879.170879 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.557868957519531e-05 seconds
DEBUG 01-07 14:54:42.170258.170258 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.170359.170359 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.170434.170434 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.170875.170875 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.170373.170373 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.171928.171928 cuda_h.py:19] end allocate_cuda_memory cost 0.0003027915954589844 seconds
DEBUG 01-07 14:54:42.171261.171261 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.171925.171925 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.171555.171555 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.171828.171828 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0beaaf00-e5df-4d0e-a550-dbf63c977604
DEBUG 01-07 14:54:42.171598.171598 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.171015.171015 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.172912.172912 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0beaaf00-e5df-4d0e-a550-dbf63c977604
DEBUG 01-07 14:54:42.172887.172887 cuda_h.py:19] end load_into_gpu_async cost 0.0010597705841064453 seconds
DEBUG 01-07 14:54:42.172921.172921 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.172918.172918 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-07 14:54:42.172151.172151 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016810894012451172 seconds
INFO 01-07 14:54:42.172425.172425 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0beaaf00-e5df-4d0e-a550-dbf63c977604
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.175566.175566 cuda_h.py:19] end self_attn cost 0.003311634063720703 seconds
DEBUG 01-07 14:54:42.175093.175093 cuda_h.py:19] end iln_self_attn_paln cost 0.0049326419830322266 seconds
DEBUG 01-07 14:54:42.175253.175253 cuda_h.py:10] start layer_moe_generate_multi_device_19
DEBUG 01-07 14:54:42.175678.175678 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.176046.176046 cuda_h.py:19] end gate cost 0.0006597042083740234 seconds
DEBUG 01-07 14:54:42.176683.176683 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.176036.176036 lmp.py:744] 
DEBUG 01-07 14:54:42.176036.176036 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.176322.176322 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.176163.176163 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.176952.176952 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.176595.176595 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.176761.176761 lmp.py:749] 
DEBUG 01-07 14:54:42.176761.176761 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.176404.176404 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.176438.176438 lmp.py:767]   Expert 44 |     40 | CPU
DEBUG 01-07 14:54:42.176796.176796 lmp.py:767]   Expert  1 |     47 | CPU
DEBUG 01-07 14:54:42.176963.176963 lmp.py:767]   Expert 60 |     59 | CPU
DEBUG 01-07 14:54:42.176129.176129 lmp.py:767]   Expert 28 |     64 | CPU
DEBUG 01-07 14:54:42.176295.176295 lmp.py:767]   Expert 48 |     75 | CPU
DEBUG 01-07 14:54:42.176461.176461 lmp.py:767]   Expert 27 |     79 | CPU
DEBUG 01-07 14:54:42.176627.176627 lmp.py:767]   Expert  0 |    100 | CPU
DEBUG 01-07 14:54:42.176224.176224 lmp.py:767]   Expert 62 |    107 | CPU
DEBUG 01-07 14:54:42.177105.177105 lmp.py:767]   Expert 42 |    112 | CPU
DEBUG 01-07 14:54:42.177510.177510 lmp.py:767]   Expert 22 |    113 | CPU
DEBUG 01-07 14:54:42.177914.177914 lmp.py:767]   Expert 30 |    114 | CPU
DEBUG 01-07 14:54:42.177319.177319 lmp.py:767]   Expert 59 |    118 | CPU
DEBUG 01-07 14:54:42.177247.177247 lmp.py:767]   Expert 58 |    125 | CPU
DEBUG 01-07 14:54:42.177936.177936 lmp.py:767]   Expert  8 |    130 | CPU
DEBUG 01-07 14:54:42.177625.177625 lmp.py:767]   Expert 16 |    132 | CPU
DEBUG 01-07 14:54:42.177076.177076 lmp.py:767]   Expert 12 |    134 | CPU
DEBUG 01-07 14:54:42.177004.177004 lmp.py:767]   Expert 50 |    134 | CPU
DEBUG 01-07 14:54:42.177931.177931 lmp.py:767]   Expert 56 |    140 | CPU
DEBUG 01-07 14:54:42.177621.177621 lmp.py:767]   Expert  5 |    146 | CPU
DEBUG 01-07 14:54:42.177502.177502 lmp.py:767]   Expert 55 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177576.177576 lmp.py:767]   Expert 26 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177934.177934 lmp.py:767]   Expert 15 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177531.177531 lmp.py:767]   Expert 32 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177366.177366 lmp.py:767]   Expert 57 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177247.177247 lmp.py:767]   Expert 24 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177128.177128 lmp.py:767]   Expert  2 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177771.177771 lmp.py:767]   Expert 52 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177414.177414 lmp.py:767]   Expert 47 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177580.177580 lmp.py:767]   Expert 34 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177223.177223 lmp.py:767]   Expert 40 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177628.177628 lmp.py:767]   Expert 54 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177509.177509 lmp.py:767]   Expert 18 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177106.177106 lmp.py:767]   Expert 41 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177226.177226 lmp.py:767]   Expert 13 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177823.177823 lmp.py:767]   Expert  3 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177942.177942 lmp.py:767]   Expert  6 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177585.177585 lmp.py:767]   Expert 19 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177228.177228 lmp.py:767]   Expert 20 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177633.177633 lmp.py:767]   Expert 46 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177037.177037 lmp.py:767]   Expert 37 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177442.177442 lmp.py:767]   Expert 25 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177847.177847 lmp.py:767]   Expert 51 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177013.177013 lmp.py:767]   Expert 35 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177417.177417 lmp.py:767]   Expert 11 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177583.177583 lmp.py:767]   Expert 43 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177273.177273 lmp.py:767]   Expert 17 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177154.177154 lmp.py:767]   Expert 31 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177035.177035 lmp.py:767]   Expert 23 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177155.177155 lmp.py:767]   Expert 49 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177275.177275 lmp.py:767]   Expert 39 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177680.177680 lmp.py:767]   Expert 53 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177846.177846 lmp.py:767]   Expert 10 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177012.177012 lmp.py:767]   Expert 33 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177178.177178 lmp.py:767]   Expert 36 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177583.177583 lmp.py:767]   Expert 38 |    271 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177749.177749 lmp.py:767]   Expert  4 |    307 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177915.177915 lmp.py:767]   Expert 21 |    331 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177319.177319 lmp.py:767]   Expert 14 |    344 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177962.177962 lmp.py:767]   Expert 63 |    368 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177082.177082 lmp.py:767]   Expert 45 |    374 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177679.177679 lmp.py:767]   Expert 61 |    390 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177037.177037 lmp.py:767]   Expert  9 |    398 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177680.177680 lmp.py:767]   Expert 29 |    485 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.177085.177085 lmp.py:767]   Expert  7 |    514 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.177774.177774 lmp.py:769] 
DEBUG 01-07 14:54:42.177774.177774 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.178702.178702 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 14:54:42.178583.178583 lmp.py:774]   cuda:1:   5233 tokens (23 experts)
DEBUG 01-07 14:54:42.178988.178988 lmp.py:774]   cuda:2:   5086 tokens (22 experts)
DEBUG 01-07 14:54:42.178438.178438 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 14:54:42.178651.178651 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.178651.178651 lmp.py:776] 
DEBUG 01-07 14:54:42.178778.178778 cuda_h.py:19] end experts_map_get cost 0.0017964839935302734 seconds
DEBUG 01-07 14:54:42.178136.178136 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.178343.178343 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.178591.178591 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.179995.179995 cuda_h.py:19] end allocate_cuda_memory cost 0.001142263412475586 seconds
DEBUG 01-07 14:54:42.179660.179660 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.179561.179561 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.179324.179324 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.179643.179643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 51b43e81-ac95-4f88-afa8-76e393509e6f
DEBUG 01-07 14:54:42.179484.179484 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.180646.180646 client.py:127] Model loaded
DEBUG 01-07 14:54:42.180707.180707 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.180932.180932 cuda_h.py:19] end restore2model cost 0.00034356117248535156 seconds
DEBUG 01-07 14:54:42.180178.180178 cuda_h.py:19] end sllm_worker_task cost 0.009852409362792969 seconds
INFO 01-07 14:54:42.180294.180294 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 51b43e81-ac95-4f88-afa8-76e393509e6f
DEBUG 01-07 14:54:42.180190.180190 cuda_h.py:19] end load_into_gpu_async cost 0.001163482666015625 seconds
DEBUG 01-07 14:54:42.180846.180846 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.181178.181178 cuda_h.py:19] end restore_tensors2 cost 0.00039505958557128906 seconds
DEBUG 01-07 14:54:42.181617.181617 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003023386001586914 seconds
DEBUG 01-07 14:54:42.181380.181380 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.183678.183678 cuda_h.py:19] end restore2model cost 0.0019474029541015625 seconds
DEBUG 01-07 14:54:42.183587.183587 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.183392.183392 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.183400.183400 cuda_h.py:19] end allocate_cuda_memory cost 0.00021886825561523438 seconds
DEBUG 01-07 14:54:42.183098.183098 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.183185.183185 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.183179.183179 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.183160.183160 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b55fc77-3eb3-4c81-83b4-642e59d15111
DEBUG 01-07 14:54:42.183093.183093 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.184212.184212 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b55fc77-3eb3-4c81-83b4-642e59d15111
DEBUG 01-07 14:54:42.184002.184002 cuda_h.py:19] end load_into_gpu_async cost 0.0010559558868408203 seconds
DEBUG 01-07 14:54:42.184420.184420 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.185959.185959 cuda_h.py:19] end restore_tensors2 cost 0.00026607513427734375 seconds
DEBUG 01-07 14:54:42.185828.185828 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001837015151977539 seconds
DEBUG 01-07 14:54:42.185346.185346 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.187898.187898 cuda_h.py:19] end restore2model cost 0.0018148422241210938 seconds
DEBUG 01-07 14:54:42.187158.187158 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00894784927368164 seconds
DEBUG 01-07 14:54:42.187285.187285 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.187102.187102 lmp.py:816] 
DEBUG 01-07 14:54:42.187102.187102 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.187176.187176 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 14:54:42.187588.187588 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.193729.193729 mlpmodule.py:749] group tensors cost 0.005882740020751953 s
DEBUG 01-07 14:54:42.195060.195060 mlpmodule.py:787] pad cost 0.0013990402221679688 s
DEBUG 01-07 14:54:42.195084.195084 mlpmodule.py:793] create cpu tensor cost 5.030632019042969e-05 s
DEBUG 01-07 14:54:42.195776.195776 mlpmodule.py:798] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-07 14:54:42.206305.206305 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.206695.206695 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.206593.206593 mlpmodule.py:818] group_w3 first element: -0.0034942626953125
WARNING 01-07 14:54:42.206478.206478 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.224670.224670 mlpmodule.py:838] group einsum cost 0.028977632522583008 s
DEBUG 01-07 14:54:42.225948.225948 mlpmodule.py:846] cpy2cputensor cost 0.0004069805145263672 s
DEBUG 01-07 14:54:42.228398.228398 cuda_h.py:19] end wait_cetm_experts cost 0.04074430465698242 seconds
DEBUG 01-07 14:54:42.228045.228045 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.229605.229605 cuda_h.py:19] end gpu_sexperts cost 0.0008134841918945312 seconds
DEBUG 01-07 14:54:42.229093.229093 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.229010.229010 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.647804260253906e-05 seconds
DEBUG 01-07 14:54:42.229946.229946 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.229935.229935 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 51b43e81-ac95-4f88-afa8-76e393509e6f
INFO 01-07 14:54:42.230082.230082 client.py:127] Model loaded
INFO 01-07 14:54:42.230689.230689 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b55fc77-3eb3-4c81-83b4-642e59d15111
INFO 01-07 14:54:42.231367.231367 client.py:127] Model loaded
DEBUG 01-07 14:54:42.231523.231523 cuda_h.py:19] end wait_experts_multi_device cost 0.0023272037506103516 seconds
DEBUG 01-07 14:54:42.231611.231611 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.231919.231919 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:42.234485.234485 mlpmodule.py:533] gpu group tensors cost 0.0010144710540771484 s
DEBUG 01-07 14:54:42.236371.236371 mlpmodule.py:707]  experts func einsum cost 0.0492100715637207 s
DEBUG 01-07 14:54:42.237057.237057 mlpmodule.py:566] gpu pad cost 0.0032956600189208984 s
DEBUG 01-07 14:54:42.238903.238903 mlpmodule.py:584] gpu group einsum cost 0.0009326934814453125 s
DEBUG 01-07 14:54:42.243924.243924 mlpmodule.py:656] gpu experts func einsum cost 0.00999140739440918 s
DEBUG 01-07 14:54:42.243206.243206 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:42.244464.244464 mlpmodule.py:533] gpu group tensors cost 0.0004627704620361328 s
DEBUG 01-07 14:54:42.245221.245221 mlpmodule.py:566] gpu pad cost 0.0013735294342041016 s
DEBUG 01-07 14:54:42.246773.246773 mlpmodule.py:584] gpu group einsum cost 0.00040340423583984375 s
DEBUG 01-07 14:54:42.248021.248021 mlpmodule.py:656] gpu experts func einsum cost 0.004419803619384766 s
DEBUG 01-07 14:54:42.248932.248932 cuda_h.py:19] end gpu_experts_multi_device cost 0.016438007354736328 seconds
DEBUG 01-07 14:54:42.248419.248419 cuda_h.py:19] end layer_moe_generate_multi_device_19 cost 0.07294797897338867 seconds
DEBUG 01-07 14:54:42.248488.248488 lmp.py:194] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-07 14:54:42.248563.248563 lmp.py:153] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-07 14:54:42.248266.248266 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 14:54:42.248221.248221 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 14:54:42.248548.248548 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.123283386230469e-05 seconds
DEBUG 01-07 14:54:42.248118.248118 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.05718994140625e-05 seconds
DEBUG 01-07 14:54:42.249629.249629 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.249796.249796 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.249276.249276 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.249151.249151 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.249818.249818 cuda_h.py:19] end allocate_cuda_memory cost 0.0002815723419189453 seconds
DEBUG 01-07 14:54:42.249086.249086 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.249207.249207 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.249634.249634 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.249232.249232 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.249948.249948 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5221526b-3d54-4ae9-ba41-5a8acd7e2d08
DEBUG 01-07 14:54:42.249004.249004 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.250986.250986 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.250353.250353 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5221526b-3d54-4ae9-ba41-5a8acd7e2d08
DEBUG 01-07 14:54:42.250282.250282 cuda_h.py:19] end load_into_gpu_async cost 0.0011441707611083984 seconds
DEBUG 01-07 14:54:42.250600.250600 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.251060.251060 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 14:54:42.251340.251340 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018777847290039062 seconds
INFO 01-07 14:54:42.251884.251884 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5221526b-3d54-4ae9-ba41-5a8acd7e2d08
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.254600.254600 cuda_h.py:19] end self_attn cost 0.0038056373596191406 seconds
DEBUG 01-07 14:54:42.254770.254770 cuda_h.py:19] end iln_self_attn_paln cost 0.005372762680053711 seconds
DEBUG 01-07 14:54:42.254746.254746 cuda_h.py:10] start layer_moe_generate_multi_device_20
DEBUG 01-07 14:54:42.254171.254171 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.255712.255712 cuda_h.py:19] end gate cost 0.0007176399230957031 seconds
DEBUG 01-07 14:54:42.255780.255780 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.255906.255906 lmp.py:744] 
DEBUG 01-07 14:54:42.255906.255906 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.255523.255523 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.255365.255365 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.255346.255346 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.255181.255181 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.255301.255301 lmp.py:749] 
DEBUG 01-07 14:54:42.255301.255301 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.255182.255182 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.255263.255263 lmp.py:767]   Expert 54 |     24 | CPU
DEBUG 01-07 14:54:42.255621.255621 lmp.py:767]   Expert  3 |     33 | CPU
DEBUG 01-07 14:54:42.255264.255264 lmp.py:767]   Expert  8 |     37 | CPU
DEBUG 01-07 14:54:42.255430.255430 lmp.py:767]   Expert 28 |     45 | CPU
DEBUG 01-07 14:54:42.255358.255358 lmp.py:767]   Expert 63 |     54 | CPU
DEBUG 01-07 14:54:42.255047.255047 lmp.py:767]   Expert 43 |     55 | CPU
DEBUG 01-07 14:54:42.255690.255690 lmp.py:767]   Expert 36 |     71 | CPU
DEBUG 01-07 14:54:42.256141.256141 lmp.py:767]   Expert 38 |     78 | CPU
DEBUG 01-07 14:54:42.256784.256784 lmp.py:767]   Expert  6 |     81 | CPU
DEBUG 01-07 14:54:42.256950.256950 lmp.py:767]   Expert 39 |     96 | CPU
DEBUG 01-07 14:54:42.256116.256116 lmp.py:767]   Expert 57 |    100 | CPU
DEBUG 01-07 14:54:42.256044.256044 lmp.py:767]   Expert 52 |    104 | CPU
DEBUG 01-07 14:54:42.256687.256687 lmp.py:767]   Expert 41 |    105 | CPU
DEBUG 01-07 14:54:42.256138.256138 lmp.py:767]   Expert 12 |    112 | CPU
DEBUG 01-07 14:54:42.256827.256827 lmp.py:767]   Expert 19 |    118 | CPU
DEBUG 01-07 14:54:42.256278.256278 lmp.py:767]   Expert 47 |    126 | CPU
DEBUG 01-07 14:54:42.256729.256729 lmp.py:767]   Expert 22 |    131 | CPU
DEBUG 01-07 14:54:42.256941.256941 lmp.py:767]   Expert 13 |    133 | CPU
DEBUG 01-07 14:54:42.256591.256591 lmp.py:767]   Expert 46 |    147 | CPU
DEBUG 01-07 14:54:42.256340.256340 lmp.py:767]   Expert 50 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256844.256844 lmp.py:767]   Expert 24 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256679.256679 lmp.py:767]   Expert 55 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256038.256038 lmp.py:767]   Expert 40 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256634.256634 lmp.py:767]   Expert 37 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256039.256039 lmp.py:767]   Expert 20 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256443.256443 lmp.py:767]   Expert 23 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256086.256086 lmp.py:767]   Expert 53 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256491.256491 lmp.py:767]   Expert 21 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256379.256379 lmp.py:767]   Expert 61 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256022.256022 lmp.py:767]   Expert 49 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256665.256665 lmp.py:767]   Expert  2 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256070.256070 lmp.py:767]   Expert 42 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256474.256474 lmp.py:767]   Expert 18 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256640.256640 lmp.py:767]   Expert 33 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256045.256045 lmp.py:767]   Expert 32 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256165.256165 lmp.py:767]   Expert  0 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256523.256523 lmp.py:767]   Expert 16 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256404.256404 lmp.py:767]   Expert 30 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256286.256286 lmp.py:767]   Expert  5 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256452.256452 lmp.py:767]   Expert  7 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256618.256618 lmp.py:767]   Expert 14 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256784.256784 lmp.py:767]   Expert 31 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256950.256950 lmp.py:767]   Expert 34 |    211 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256116.256116 lmp.py:767]   Expert 59 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256044.256044 lmp.py:767]   Expert 60 |    218 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256449.256449 lmp.py:767]   Expert 62 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256376.256376 lmp.py:767]   Expert  9 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256735.256735 lmp.py:767]   Expert 17 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256377.256377 lmp.py:767]   Expert 10 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256497.256497 lmp.py:767]   Expert 29 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256902.256902 lmp.py:767]   Expert 58 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256545.256545 lmp.py:767]   Expert 15 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256949.256949 lmp.py:767]   Expert  4 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256877.256877 lmp.py:767]   Expert 26 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256805.256805 lmp.py:767]   Expert 11 |    252 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256733.256733 lmp.py:767]   Expert 51 |    253 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256899.256899 lmp.py:767]   Expert 44 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256303.256303 lmp.py:767]   Expert 56 |    288 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256231.256231 lmp.py:767]   Expert 27 |    290 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256636.256636 lmp.py:767]   Expert  1 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256278.256278 lmp.py:767]   Expert 45 |    360 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.256921.256921 lmp.py:767]   Expert 25 |    467 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256326.256326 lmp.py:767]   Expert 35 |    517 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.256969.256969 lmp.py:767]   Expert 48 |    648 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.257181.257181 lmp.py:769] 
DEBUG 01-07 14:54:42.257181.257181 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.257824.257824 lmp.py:770]   CPU:   1650 tokens
DEBUG 01-07 14:54:42.257706.257706 lmp.py:774]   cuda:1:   5398 tokens (23 experts)
DEBUG 01-07 14:54:42.257110.257110 lmp.py:774]   cuda:2:   5240 tokens (22 experts)
DEBUG 01-07 14:54:42.257800.257800 lmp.py:775]   Total GPU:  10638 tokens
DEBUG 01-07 14:54:42.257535.257535 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.257535.257535 lmp.py:776] 
DEBUG 01-07 14:54:42.257662.257662 cuda_h.py:19] end experts_map_get cost 0.0017795562744140625 seconds
DEBUG 01-07 14:54:42.257020.257020 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.257465.257465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.257953.257953 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.258337.258337 cuda_h.py:19] end allocate_cuda_memory cost 0.0007779598236083984 seconds
DEBUG 01-07 14:54:42.258426.258426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.258612.258612 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.258944.258944 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.258071.258071 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 543ca759-edb7-4ff8-a3da-dc8ef39ba835
DEBUG 01-07 14:54:42.258859.258859 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.258515.258515 client.py:127] Model loaded
DEBUG 01-07 14:54:42.258689.258689 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.259327.259327 cuda_h.py:19] end restore2model cost 0.0004298686981201172 seconds
DEBUG 01-07 14:54:42.259541.259541 cuda_h.py:19] end sllm_worker_task cost 0.010102033615112305 seconds
INFO 01-07 14:54:42.259570.259570 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 543ca759-edb7-4ff8-a3da-dc8ef39ba835
DEBUG 01-07 14:54:42.259897.259897 cuda_h.py:19] end load_into_gpu_async cost 0.0011894702911376953 seconds
DEBUG 01-07 14:54:42.259554.259554 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.259148.259148 cuda_h.py:19] end restore_tensors2 cost 0.00030612945556640625 seconds
DEBUG 01-07 14:54:42.259778.259778 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002595663070678711 seconds
DEBUG 01-07 14:54:42.259018.259018 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.261143.261143 cuda_h.py:19] end restore2model cost 0.0019192695617675781 seconds
DEBUG 01-07 14:54:42.261622.261622 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.261579.261579 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.262735.262735 cuda_h.py:19] end allocate_cuda_memory cost 0.00025200843811035156 seconds
DEBUG 01-07 14:54:42.262240.262240 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.262612.262612 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.262322.262322 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.262971.262971 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9818f27d-16d6-4bc8-8d8c-e8be6a76d11e
DEBUG 01-07 14:54:42.262195.262195 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.263214.263214 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9818f27d-16d6-4bc8-8d8c-e8be6a76d11e
DEBUG 01-07 14:54:42.263289.263289 cuda_h.py:19] end load_into_gpu_async cost 0.0010230541229248047 seconds
DEBUG 01-07 14:54:42.263945.263945 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.263199.263199 cuda_h.py:19] end restore_tensors2 cost 0.00023221969604492188 seconds
DEBUG 01-07 14:54:42.263253.263253 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018074512481689453 seconds
DEBUG 01-07 14:54:42.263486.263486 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.265429.265429 cuda_h.py:19] end restore2model cost 0.0018260478973388672 seconds
DEBUG 01-07 14:54:42.265927.265927 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00847625732421875 seconds
DEBUG 01-07 14:54:42.265531.265531 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.265063.265063 lmp.py:816] 
DEBUG 01-07 14:54:42.265063.265063 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.265899.265899 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 14:54:42.265072.265072 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.277180.277180 mlpmodule.py:749] group tensors cost 0.011173009872436523 s
DEBUG 01-07 14:54:42.278943.278943 mlpmodule.py:787] pad cost 0.0011227130889892578 s
DEBUG 01-07 14:54:42.279801.279801 mlpmodule.py:793] create cpu tensor cost 4.267692565917969e-05 s
DEBUG 01-07 14:54:42.279187.279187 mlpmodule.py:798] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-07 14:54:42.288423.288423 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.288899.288899 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.288956.288956 mlpmodule.py:818] group_w3 first element: 0.0205078125
WARNING 01-07 14:54:42.288695.288695 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.304816.304816 mlpmodule.py:838] group einsum cost 0.025419950485229492 s
DEBUG 01-07 14:54:42.305286.305286 mlpmodule.py:846] cpy2cputensor cost 0.00040793418884277344 s
DEBUG 01-07 14:54:42.307987.307987 cuda_h.py:19] end wait_cetm_experts cost 0.04208064079284668 seconds
DEBUG 01-07 14:54:42.308581.308581 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.309867.309867 cuda_h.py:19] end gpu_sexperts cost 0.0009169578552246094 seconds
DEBUG 01-07 14:54:42.309414.309414 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.309107.309107 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.7670135498046875e-05 seconds
DEBUG 01-07 14:54:42.309387.309387 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.309529.309529 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 543ca759-edb7-4ff8-a3da-dc8ef39ba835
INFO 01-07 14:54:42.310694.310694 client.py:127] Model loaded
INFO 01-07 14:54:42.311619.311619 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9818f27d-16d6-4bc8-8d8c-e8be6a76d11e
INFO 01-07 14:54:42.311075.311075 client.py:127] Model loaded
DEBUG 01-07 14:54:42.312490.312490 cuda_h.py:19] end wait_experts_multi_device cost 0.002602815628051758 seconds
DEBUG 01-07 14:54:42.312162.312162 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.312774.312774 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:42.314604.314604 mlpmodule.py:533] gpu group tensors cost 0.0009453296661376953 s
DEBUG 01-07 14:54:42.316211.316211 mlpmodule.py:707]  experts func einsum cost 0.05012035369873047 s
DEBUG 01-07 14:54:42.317128.317128 mlpmodule.py:566] gpu pad cost 0.003060579299926758 s
DEBUG 01-07 14:54:42.318671.318671 mlpmodule.py:584] gpu group einsum cost 0.001001596450805664 s
DEBUG 01-07 14:54:42.323187.323187 mlpmodule.py:656] gpu experts func einsum cost 0.009662866592407227 s
DEBUG 01-07 14:54:42.323160.323160 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:42.324656.324656 mlpmodule.py:533] gpu group tensors cost 0.00043702125549316406 s
DEBUG 01-07 14:54:42.326375.326375 mlpmodule.py:566] gpu pad cost 0.0012428760528564453 s
DEBUG 01-07 14:54:42.326734.326734 mlpmodule.py:584] gpu group einsum cost 0.0003693103790283203 s
DEBUG 01-07 14:54:42.328202.328202 mlpmodule.py:656] gpu experts func einsum cost 0.004106044769287109 s
DEBUG 01-07 14:54:42.328299.328299 cuda_h.py:19] end gpu_experts_multi_device cost 0.01629781723022461 seconds
DEBUG 01-07 14:54:42.328520.328520 cuda_h.py:19] end layer_moe_generate_multi_device_20 cost 0.07413649559020996 seconds
DEBUG 01-07 14:54:42.328741.328741 lmp.py:194] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-07 14:54:42.328749.328749 lmp.py:153] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-07 14:54:42.328975.328975 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 14:54:42.329500.329500 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 14:54:42.329250.329250 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.9802322387695312e-05 seconds
DEBUG 01-07 14:54:42.329768.329768 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.532669067382812e-05 seconds
DEBUG 01-07 14:54:42.329656.329656 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.329075.329075 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.329455.329455 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.329173.329173 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.329572.329572 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.329424.329424 cuda_h.py:19] end allocate_cuda_memory cost 0.0003132820129394531 seconds
DEBUG 01-07 14:54:42.329089.329089 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.329752.329752 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.329621.329621 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.329563.329563 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95ff4c6f-9f1e-499c-8989-cb03a024c209
DEBUG 01-07 14:54:42.329525.329525 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.330551.330551 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.330696.330696 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95ff4c6f-9f1e-499c-8989-cb03a024c209
DEBUG 01-07 14:54:42.330102.330102 cuda_h.py:19] end load_into_gpu_async cost 0.001134634017944336 seconds
DEBUG 01-07 14:54:42.331089.331089 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.331311.331311 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 14:54:42.331113.331113 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017523765563964844 seconds
INFO 01-07 14:54:42.331817.331817 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95ff4c6f-9f1e-499c-8989-cb03a024c209
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.334010.334010 cuda_h.py:19] end self_attn cost 0.004115104675292969 seconds
DEBUG 01-07 14:54:42.334259.334259 cuda_h.py:19] end iln_self_attn_paln cost 0.005714893341064453 seconds
DEBUG 01-07 14:54:42.334658.334658 cuda_h.py:10] start layer_moe_generate_multi_device_21
DEBUG 01-07 14:54:42.334129.334129 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.335040.335040 cuda_h.py:19] end gate cost 0.0006747245788574219 seconds
DEBUG 01-07 14:54:42.335823.335823 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.336977.336977 lmp.py:744] 
DEBUG 01-07 14:54:42.336977.336977 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.336170.336170 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.336919.336919 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.336946.336946 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.336066.336066 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.336709.336709 lmp.py:749] 
DEBUG 01-07 14:54:42.336709.336709 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.336637.336637 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.336525.336525 lmp.py:767]   Expert  9 |     32 | CPU
DEBUG 01-07 14:54:42.336453.336453 lmp.py:767]   Expert 44 |     32 | CPU
DEBUG 01-07 14:54:42.336904.336904 lmp.py:767]   Expert 11 |     36 | CPU
DEBUG 01-07 14:54:42.336878.336878 lmp.py:767]   Expert 56 |     54 | CPU
DEBUG 01-07 14:54:42.336090.336090 lmp.py:767]   Expert 54 |     76 | CPU
DEBUG 01-07 14:54:42.336647.336647 lmp.py:767]   Expert  7 |     88 | CPU
DEBUG 01-07 14:54:42.336575.336575 lmp.py:767]   Expert 62 |     93 | CPU
DEBUG 01-07 14:54:42.336649.336649 lmp.py:767]   Expert 47 |     94 | CPU
DEBUG 01-07 14:54:42.336537.336537 lmp.py:767]   Expert 51 |    102 | CPU
DEBUG 01-07 14:54:42.336988.336988 lmp.py:767]   Expert 60 |    104 | CPU
DEBUG 01-07 14:54:42.336200.336200 lmp.py:767]   Expert 52 |    109 | CPU
DEBUG 01-07 14:54:42.336889.336889 lmp.py:767]   Expert 41 |    111 | CPU
DEBUG 01-07 14:54:42.336294.336294 lmp.py:767]   Expert 53 |    111 | CPU
DEBUG 01-07 14:54:42.336321.336321 lmp.py:767]   Expert 22 |    114 | CPU
DEBUG 01-07 14:54:42.336534.336534 lmp.py:767]   Expert  8 |    125 | CPU
DEBUG 01-07 14:54:42.336508.336508 lmp.py:767]   Expert  6 |    128 | CPU
DEBUG 01-07 14:54:42.336243.336243 lmp.py:767]   Expert 48 |    128 | CPU
DEBUG 01-07 14:54:42.336979.336979 lmp.py:767]   Expert  2 |    129 | CPU
DEBUG 01-07 14:54:42.336622.336622 lmp.py:767]   Expert 32 |    129 | CPU
DEBUG 01-07 14:54:42.336742.336742 lmp.py:767]   Expert  1 |    134 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336100.336100 lmp.py:767]   Expert 23 |    135 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336743.336743 lmp.py:767]   Expert 35 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336201.336201 lmp.py:767]   Expert 27 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336089.336089 lmp.py:767]   Expert 59 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336639.336639 lmp.py:767]   Expert 39 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336951.336951 lmp.py:767]   Expert 26 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336548.336548 lmp.py:767]   Expert 50 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336383.336383 lmp.py:767]   Expert 14 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336502.336502 lmp.py:767]   Expert 24 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336145.336145 lmp.py:767]   Expert 38 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336788.336788 lmp.py:767]   Expert  4 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336431.336431 lmp.py:767]   Expert  0 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336313.336313 lmp.py:767]   Expert 46 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336956.336956 lmp.py:767]   Expert 34 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336513.336513 lmp.py:767]   Expert 49 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336063.336063 lmp.py:767]   Expert 40 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.336421.336421 lmp.py:767]   Expert  5 |    184 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.336733.336733 lmp.py:767]   Expert 63 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337568.337568 lmp.py:767]   Expert 19 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337450.337450 lmp.py:767]   Expert 13 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337093.337093 lmp.py:767]   Expert 43 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337736.337736 lmp.py:767]   Expert 29 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337140.337140 lmp.py:767]   Expert 57 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337260.337260 lmp.py:767]   Expert 61 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337665.337665 lmp.py:767]   Expert 33 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337122.337122 lmp.py:767]   Expert 31 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337011.337011 lmp.py:767]   Expert 20 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337084.337084 lmp.py:767]   Expert 37 |    255 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337919.337919 lmp.py:767]   Expert 16 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337854.337854 lmp.py:767]   Expert  3 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337020.337020 lmp.py:767]   Expert 15 |    260 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337471.337471 lmp.py:767]   Expert 36 |    273 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337160.337160 lmp.py:767]   Expert 18 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337611.337611 lmp.py:767]   Expert 12 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337300.337300 lmp.py:767]   Expert 28 |    306 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337513.337513 lmp.py:767]   Expert 55 |    308 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337202.337202 lmp.py:767]   Expert 17 |    309 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337891.337891 lmp.py:767]   Expert 25 |    315 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337826.337826 lmp.py:767]   Expert 30 |    324 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337853.337853 lmp.py:767]   Expert 58 |    339 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337781.337781 lmp.py:767]   Expert 10 |    363 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337708.337708 lmp.py:767]   Expert 45 |    382 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337590.337590 lmp.py:767]   Expert 21 |    387 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.337094.337094 lmp.py:767]   Expert 42 |    654 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.337829.337829 lmp.py:769] 
DEBUG 01-07 14:54:42.337829.337829 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.337519.337519 lmp.py:770]   CPU:   1795 tokens
DEBUG 01-07 14:54:42.337685.337685 lmp.py:774]   cuda:1:   5247 tokens (22 experts)
DEBUG 01-07 14:54:42.337136.337136 lmp.py:774]   cuda:2:   5246 tokens (23 experts)
DEBUG 01-07 14:54:42.337348.337348 lmp.py:775]   Total GPU:  10493 tokens
DEBUG 01-07 14:54:42.337607.337607 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.337607.337607 lmp.py:776] 
DEBUG 01-07 14:54:42.337972.337972 cuda_h.py:19] end experts_map_get cost 0.0018341541290283203 seconds
DEBUG 01-07 14:54:42.337052.337052 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.337736.337736 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.337031.337031 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.338684.338684 cuda_h.py:19] end allocate_cuda_memory cost 0.0002663135528564453 seconds
DEBUG 01-07 14:54:42.338010.338010 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.338958.338958 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.338105.338105 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.338232.338232 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d3385d87-b543-4fc8-8b09-ce464fef355f
DEBUG 01-07 14:54:42.338159.338159 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.338939.338939 client.py:127] Model loaded
DEBUG 01-07 14:54:42.338067.338067 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.339539.339539 cuda_h.py:19] end restore2model cost 0.0004131793975830078 seconds
DEBUG 01-07 14:54:42.339368.339368 cuda_h.py:19] end sllm_worker_task cost 0.009806156158447266 seconds
INFO 01-07 14:54:42.339537.339537 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d3385d87-b543-4fc8-8b09-ce464fef355f
DEBUG 01-07 14:54:42.339718.339718 cuda_h.py:19] end load_into_gpu_async cost 0.0011196136474609375 seconds
DEBUG 01-07 14:54:42.339182.339182 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.339086.339086 cuda_h.py:19] end restore_tensors2 cost 0.0002548694610595703 seconds
DEBUG 01-07 14:54:42.339293.339293 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019659996032714844 seconds
DEBUG 01-07 14:54:42.339539.339539 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.341803.341803 cuda_h.py:19] end restore2model cost 0.0019180774688720703 seconds
DEBUG 01-07 14:54:42.341951.341951 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.341571.341571 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.342546.342546 cuda_h.py:19] end allocate_cuda_memory cost 0.00022864341735839844 seconds
DEBUG 01-07 14:54:42.342482.342482 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.342807.342807 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.342438.342438 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.342234.342234 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cebd6430-4d6b-4c59-9d77-eff5611ed6cc
DEBUG 01-07 14:54:42.342319.342319 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.343118.343118 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cebd6430-4d6b-4c59-9d77-eff5611ed6cc
DEBUG 01-07 14:54:42.343756.343756 cuda_h.py:19] end load_into_gpu_async cost 0.0012249946594238281 seconds
DEBUG 01-07 14:54:42.343598.343598 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.343050.343050 cuda_h.py:19] end restore_tensors2 cost 0.00023937225341796875 seconds
DEBUG 01-07 14:54:42.343873.343873 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019855499267578125 seconds
DEBUG 01-07 14:54:42.343437.343437 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.345345.345345 cuda_h.py:19] end restore2model cost 0.0019752979278564453 seconds
DEBUG 01-07 14:54:42.345433.345433 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008194208145141602 seconds
DEBUG 01-07 14:54:42.345772.345772 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.345066.345066 lmp.py:816] 
DEBUG 01-07 14:54:42.345066.345066 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.345141.345141 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 14:54:42.346075.346075 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.357644.357644 mlpmodule.py:749] group tensors cost 0.011299371719360352 s
DEBUG 01-07 14:54:42.359002.359002 mlpmodule.py:787] pad cost 0.0009844303131103516 s
DEBUG 01-07 14:54:42.359277.359277 mlpmodule.py:793] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-07 14:54:42.359749.359749 mlpmodule.py:798] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-07 14:54:42.367311.367311 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.367927.367927 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.367831.367831 mlpmodule.py:818] group_w3 first element: -0.022216796875
WARNING 01-07 14:54:42.367954.367954 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.381087.381087 mlpmodule.py:838] group einsum cost 0.022469282150268555 s
DEBUG 01-07 14:54:42.382100.382100 mlpmodule.py:846] cpy2cputensor cost 0.00038051605224609375 s
DEBUG 01-07 14:54:42.385315.385315 cuda_h.py:19] end wait_cetm_experts cost 0.03895401954650879 seconds
DEBUG 01-07 14:54:42.385565.385565 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.386095.386095 cuda_h.py:19] end gpu_sexperts cost 0.0008921623229980469 seconds
DEBUG 01-07 14:54:42.386848.386848 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.386555.386555 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.029273986816406e-05 seconds
DEBUG 01-07 14:54:42.386319.386319 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.386003.386003 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d3385d87-b543-4fc8-8b09-ce464fef355f
INFO 01-07 14:54:42.388277.388277 client.py:127] Model loaded
INFO 01-07 14:54:42.388499.388499 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cebd6430-4d6b-4c59-9d77-eff5611ed6cc
INFO 01-07 14:54:42.389339.389339 client.py:127] Model loaded
DEBUG 01-07 14:54:42.389496.389496 cuda_h.py:19] end wait_experts_multi_device cost 0.0028581619262695312 seconds
DEBUG 01-07 14:54:42.389612.389612 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.389086.389086 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.392662.392662 mlpmodule.py:533] gpu group tensors cost 0.0010342597961425781 s
DEBUG 01-07 14:54:42.393094.393094 mlpmodule.py:707]  experts func einsum cost 0.04749917984008789 s
DEBUG 01-07 14:54:42.395689.395689 mlpmodule.py:566] gpu pad cost 0.0034236907958984375 s
DEBUG 01-07 14:54:42.396671.396671 mlpmodule.py:584] gpu group einsum cost 0.00048232078552246094 s
DEBUG 01-07 14:54:42.398947.398947 mlpmodule.py:656] gpu experts func einsum cost 0.007369279861450195 s
DEBUG 01-07 14:54:42.398699.398699 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.399645.399645 mlpmodule.py:533] gpu group tensors cost 0.0004515647888183594 s
DEBUG 01-07 14:54:42.400427.400427 mlpmodule.py:566] gpu pad cost 0.0013217926025390625 s
DEBUG 01-07 14:54:42.401645.401645 mlpmodule.py:584] gpu group einsum cost 0.0005090236663818359 s
DEBUG 01-07 14:54:42.403797.403797 mlpmodule.py:656] gpu experts func einsum cost 0.0043909549713134766 s
DEBUG 01-07 14:54:42.403708.403708 cuda_h.py:19] end gpu_experts_multi_device cost 0.013874530792236328 seconds
DEBUG 01-07 14:54:42.403413.403413 cuda_h.py:19] end layer_moe_generate_multi_device_21 cost 0.06860876083374023 seconds
DEBUG 01-07 14:54:42.403349.403349 lmp.py:194] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-07 14:54:42.403808.403808 lmp.py:153] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-07 14:54:42.403749.403749 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 14:54:42.403466.403466 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 14:54:42.404508.404508 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.4332275390625e-05 seconds
DEBUG 01-07 14:54:42.404502.404502 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.985664367675781e-05 seconds
DEBUG 01-07 14:54:42.404867.404867 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.404141.404141 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.404707.404707 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.404761.404761 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.404547.404547 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.404121.404121 cuda_h.py:19] end allocate_cuda_memory cost 0.0002791881561279297 seconds
DEBUG 01-07 14:54:42.404282.404282 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.404330.404330 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.404914.404914 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.404948.404948 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4dc34322-14c4-461a-b172-06a70b05dfdf
DEBUG 01-07 14:54:42.404196.404196 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.405652.405652 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.405054.405054 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4dc34322-14c4-461a-b172-06a70b05dfdf
DEBUG 01-07 14:54:42.405606.405606 cuda_h.py:19] end load_into_gpu_async cost 0.0011150836944580078 seconds
DEBUG 01-07 14:54:42.405739.405739 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.406352.406352 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-07 14:54:42.406744.406744 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017495155334472656 seconds
INFO 01-07 14:54:42.406489.406489 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4dc34322-14c4-461a-b172-06a70b05dfdf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.409729.409729 cuda_h.py:19] end self_attn cost 0.0040035247802734375 seconds
DEBUG 01-07 14:54:42.409349.409349 cuda_h.py:19] end iln_self_attn_paln cost 0.0056574344635009766 seconds
DEBUG 01-07 14:54:42.409318.409318 cuda_h.py:10] start layer_moe_generate_multi_device_22
DEBUG 01-07 14:54:42.409312.409312 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.410369.410369 cuda_h.py:19] end gate cost 0.0006768703460693359 seconds
DEBUG 01-07 14:54:42.410536.410536 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.411014.411014 lmp.py:744] 
DEBUG 01-07 14:54:42.411014.411014 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.411062.411062 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.411665.411665 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.411931.411931 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.411766.411766 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.411170.411170 lmp.py:749] 
DEBUG 01-07 14:54:42.411170.411170 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.411528.411528 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.411132.411132 lmp.py:767]   Expert 25 |     12 | CPU
DEBUG 01-07 14:54:42.411298.411298 lmp.py:767]   Expert 48 |     35 | CPU
DEBUG 01-07 14:54:42.411987.411987 lmp.py:767]   Expert 45 |     38 | CPU
DEBUG 01-07 14:54:42.411961.411961 lmp.py:767]   Expert  9 |     62 | CPU
DEBUG 01-07 14:54:42.411174.411174 lmp.py:767]   Expert 43 |     83 | CPU
DEBUG 01-07 14:54:42.411148.411148 lmp.py:767]   Expert 54 |     83 | CPU
DEBUG 01-07 14:54:42.411360.411360 lmp.py:767]   Expert  0 |     88 | CPU
DEBUG 01-07 14:54:42.411573.411573 lmp.py:767]   Expert 20 |     89 | CPU
DEBUG 01-07 14:54:42.411308.411308 lmp.py:767]   Expert 47 |     92 | CPU
DEBUG 01-07 14:54:42.411759.411759 lmp.py:767]   Expert 57 |     93 | CPU
DEBUG 01-07 14:54:42.411548.411548 lmp.py:767]   Expert  6 |     94 | CPU
DEBUG 01-07 14:54:42.411522.411522 lmp.py:767]   Expert 36 |     99 | CPU
DEBUG 01-07 14:54:42.411973.411973 lmp.py:767]   Expert 13 |    105 | CPU
DEBUG 01-07 14:54:42.411901.411901 lmp.py:767]   Expert 15 |    105 | CPU
DEBUG 01-07 14:54:42.411451.411451 lmp.py:767]   Expert 62 |    105 | CPU
DEBUG 01-07 14:54:42.411094.411094 lmp.py:767]   Expert 61 |    106 | CPU
DEBUG 01-07 14:54:42.411545.411545 lmp.py:767]   Expert 50 |    107 | CPU
DEBUG 01-07 14:54:42.411757.411757 lmp.py:767]   Expert  1 |    110 | CPU
DEBUG 01-07 14:54:42.411493.411493 lmp.py:767]   Expert 38 |    110 | CPU
DEBUG 01-07 14:54:42.411659.411659 lmp.py:767]   Expert 37 |    112 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411064.411064 lmp.py:767]   Expert 46 |    119 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411230.411230 lmp.py:767]   Expert 14 |    120 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411919.411919 lmp.py:767]   Expert 21 |    133 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411847.411847 lmp.py:767]   Expert 28 |    134 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411536.411536 lmp.py:767]   Expert  7 |    136 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411040.411040 lmp.py:767]   Expert 52 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411968.411968 lmp.py:767]   Expert 44 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411896.411896 lmp.py:767]   Expert 10 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411346.411346 lmp.py:767]   Expert 24 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411943.411943 lmp.py:767]   Expert 42 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411778.411778 lmp.py:767]   Expert 11 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411660.411660 lmp.py:767]   Expert  2 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411303.411303 lmp.py:767]   Expert 26 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411184.411184 lmp.py:767]   Expert 35 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411065.411065 lmp.py:767]   Expert 31 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411523.411523 lmp.py:767]   Expert  3 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411881.411881 lmp.py:767]   Expert 32 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411339.411339 lmp.py:767]   Expert 19 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411267.411267 lmp.py:767]   Expert 12 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411433.411433 lmp.py:767]   Expert 56 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411360.411360 lmp.py:767]   Expert 40 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411288.411288 lmp.py:767]   Expert 60 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411977.411977 lmp.py:767]   Expert 41 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411190.411190 lmp.py:767]   Expert 23 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411641.411641 lmp.py:767]   Expert 53 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.411092.411092 lmp.py:767]   Expert  8 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.411543.411543 lmp.py:767]   Expert 58 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412855.412855 lmp.py:767]   Expert 51 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412259.412259 lmp.py:767]   Expert 16 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412286.412286 lmp.py:767]   Expert 59 |    249 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412691.412691 lmp.py:767]   Expert  4 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412142.412142 lmp.py:767]   Expert 55 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412308.412308 lmp.py:767]   Expert 49 |    273 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412282.412282 lmp.py:767]   Expert 29 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412733.412733 lmp.py:767]   Expert 18 |    281 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412945.412945 lmp.py:767]   Expert 34 |    287 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412919.412919 lmp.py:767]   Expert 63 |    294 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412370.412370 lmp.py:767]   Expert 27 |    355 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412583.412583 lmp.py:767]   Expert 39 |    373 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412557.412557 lmp.py:767]   Expert 17 |    391 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412008.412008 lmp.py:767]   Expert 22 |    433 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412697.412697 lmp.py:767]   Expert 33 |    449 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412148.412148 lmp.py:767]   Expert 30 |    457 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.412936.412936 lmp.py:767]   Expert  5 |    719 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.412864.412864 lmp.py:769] 
DEBUG 01-07 14:54:42.412864.412864 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.412269.412269 lmp.py:770]   CPU:   1616 tokens
DEBUG 01-07 14:54:42.412150.412150 lmp.py:774]   cuda:1:   5317 tokens (22 experts)
DEBUG 01-07 14:54:42.412555.412555 lmp.py:774]   cuda:2:   5355 tokens (23 experts)
DEBUG 01-07 14:54:42.412006.412006 lmp.py:775]   Total GPU:  10672 tokens
DEBUG 01-07 14:54:42.412980.412980 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.412980.412980 lmp.py:776] 
DEBUG 01-07 14:54:42.412259.412259 cuda_h.py:19] end experts_map_get cost 0.0017673969268798828 seconds
DEBUG 01-07 14:54:42.412186.412186 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.412340.412340 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.412258.412258 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.412724.412724 cuda_h.py:19] end allocate_cuda_memory cost 0.0002396106719970703 seconds
DEBUG 01-07 14:54:42.412197.412197 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.412814.412814 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.413020.413020 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.413498.413498 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b972b8b5-1723-4dd9-8701-782d327d1594
DEBUG 01-07 14:54:42.413168.413168 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.413614.413614 client.py:127] Model loaded
DEBUG 01-07 14:54:42.413215.413215 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.413818.413818 cuda_h.py:19] end restore2model cost 0.0003719329833984375 seconds
DEBUG 01-07 14:54:42.413594.413594 cuda_h.py:19] end sllm_worker_task cost 0.009647369384765625 seconds
INFO 01-07 14:54:42.414374.414374 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b972b8b5-1723-4dd9-8701-782d327d1594
DEBUG 01-07 14:54:42.414793.414793 cuda_h.py:19] end load_into_gpu_async cost 0.0011782646179199219 seconds
DEBUG 01-07 14:54:42.414735.414735 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.414830.414830 cuda_h.py:19] end restore_tensors2 cost 0.0002560615539550781 seconds
DEBUG 01-07 14:54:42.414169.414169 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019941329956054688 seconds
DEBUG 01-07 14:54:42.414263.414263 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.416061.416061 cuda_h.py:19] end restore2model cost 0.001859426498413086 seconds
DEBUG 01-07 14:54:42.416024.416024 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.416736.416736 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.416189.416189 cuda_h.py:19] end allocate_cuda_memory cost 0.00022912025451660156 seconds
DEBUG 01-07 14:54:42.416363.416363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.416404.416404 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.416829.416829 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.416717.416717 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f089ee9d-5fde-4fa4-ac1c-105bf76e6ffb
DEBUG 01-07 14:54:42.417080.417080 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.417051.417051 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f089ee9d-5fde-4fa4-ac1c-105bf76e6ffb
DEBUG 01-07 14:54:42.417172.417172 cuda_h.py:19] end load_into_gpu_async cost 0.0009856224060058594 seconds
DEBUG 01-07 14:54:42.417829.417829 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.418904.418904 cuda_h.py:19] end restore_tensors2 cost 0.00023937225341796875 seconds
DEBUG 01-07 14:54:42.418627.418627 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017502307891845703 seconds
DEBUG 01-07 14:54:42.418337.418337 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.420129.420129 cuda_h.py:19] end restore2model cost 0.001886129379272461 seconds
DEBUG 01-07 14:54:42.420767.420767 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007815837860107422 seconds
DEBUG 01-07 14:54:42.420847.420847 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.420618.420618 lmp.py:816] 
DEBUG 01-07 14:54:42.420618.420618 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.420706.420706 cuda_h.py:19] end cpu_experts_submit cost 0.00011658668518066406 seconds
DEBUG 01-07 14:54:42.420310.420310 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.427509.427509 mlpmodule.py:749] group tensors cost 0.006811857223510742 s
DEBUG 01-07 14:54:42.429149.429149 mlpmodule.py:787] pad cost 0.0015985965728759766 s
DEBUG 01-07 14:54:42.429809.429809 mlpmodule.py:793] create cpu tensor cost 5.459785461425781e-05 s
DEBUG 01-07 14:54:42.429667.429667 mlpmodule.py:798] move to cpu cost 4.935264587402344e-05 s
DEBUG 01-07 14:54:42.438173.438173 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.438311.438311 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.438732.438732 mlpmodule.py:818] group_w3 first element: -0.018798828125
WARNING 01-07 14:54:42.438763.438763 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.452596.452596 mlpmodule.py:838] group einsum cost 0.022711753845214844 s
DEBUG 01-07 14:54:42.453934.453934 mlpmodule.py:846] cpy2cputensor cost 0.00038695335388183594 s
DEBUG 01-07 14:54:42.456409.456409 cuda_h.py:19] end wait_cetm_experts cost 0.03555631637573242 seconds
DEBUG 01-07 14:54:42.456963.456963 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.457680.457680 cuda_h.py:19] end gpu_sexperts cost 0.0007696151733398438 seconds
DEBUG 01-07 14:54:42.457021.457021 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.457986.457986 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4809112548828125e-05 seconds
DEBUG 01-07 14:54:42.457544.457544 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.457394.457394 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b972b8b5-1723-4dd9-8701-782d327d1594
INFO 01-07 14:54:42.458083.458083 client.py:127] Model loaded
INFO 01-07 14:54:42.458259.458259 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f089ee9d-5fde-4fa4-ac1c-105bf76e6ffb
INFO 01-07 14:54:42.459494.459494 client.py:127] Model loaded
DEBUG 01-07 14:54:42.459842.459842 cuda_h.py:19] end wait_experts_multi_device cost 0.0025076866149902344 seconds
DEBUG 01-07 14:54:42.459308.459308 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.460946.460946 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.462556.462556 mlpmodule.py:533] gpu group tensors cost 0.0008609294891357422 s
DEBUG 01-07 14:54:42.464550.464550 mlpmodule.py:707]  experts func einsum cost 0.04404854774475098 s
DEBUG 01-07 14:54:42.464745.464745 mlpmodule.py:566] gpu pad cost 0.002760171890258789 s
DEBUG 01-07 14:54:42.465343.465343 mlpmodule.py:584] gpu group einsum cost 0.0009012222290039062 s
DEBUG 01-07 14:54:42.468162.468162 mlpmodule.py:656] gpu experts func einsum cost 0.007288932800292969 s
DEBUG 01-07 14:54:42.468521.468521 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.469974.469974 mlpmodule.py:533] gpu group tensors cost 0.0003864765167236328 s
DEBUG 01-07 14:54:42.470329.470329 mlpmodule.py:566] gpu pad cost 0.0010495185852050781 s
DEBUG 01-07 14:54:42.470953.470953 mlpmodule.py:584] gpu group einsum cost 0.00039958953857421875 s
DEBUG 01-07 14:54:42.472718.472718 mlpmodule.py:656] gpu experts func einsum cost 0.003638744354248047 s
DEBUG 01-07 14:54:42.472702.472702 cuda_h.py:19] end gpu_experts_multi_device cost 0.012702226638793945 seconds
DEBUG 01-07 14:54:42.472433.472433 cuda_h.py:19] end layer_moe_generate_multi_device_22 cost 0.0629429817199707 seconds
DEBUG 01-07 14:54:42.473798.473798 lmp.py:194] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-07 14:54:42.473561.473561 lmp.py:153] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-07 14:54:42.473542.473542 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 14:54:42.473344.473344 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 14:54:42.473141.473141 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.4809112548828125e-05 seconds
DEBUG 01-07 14:54:42.473890.473890 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:42.473639.473639 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.473343.473343 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.473319.473319 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.473984.473984 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.473483.473483 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.473322.473322 cuda_h.py:19] end allocate_cuda_memory cost 0.0003025531768798828 seconds
DEBUG 01-07 14:54:42.473722.473722 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.473531.473531 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.473877.473877 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.474911.474911 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f8930b6b-e039-4ffe-8428-0931a9b7cad3
DEBUG 01-07 14:54:42.474205.474205 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.474208.474208 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.474936.474936 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f8930b6b-e039-4ffe-8428-0931a9b7cad3
DEBUG 01-07 14:54:42.475149.475149 cuda_h.py:19] end load_into_gpu_async cost 0.0010516643524169922 seconds
DEBUG 01-07 14:54:42.475183.475183 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.475259.475259 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:42.475062.475062 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001674652099609375 seconds
INFO 01-07 14:54:42.475236.475236 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f8930b6b-e039-4ffe-8428-0931a9b7cad3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.477038.477038 cuda_h.py:19] end self_attn cost 0.0033407211303710938 seconds
DEBUG 01-07 14:54:42.478836.478836 cuda_h.py:19] end iln_self_attn_paln cost 0.004853248596191406 seconds
DEBUG 01-07 14:54:42.478758.478758 cuda_h.py:10] start layer_moe_generate_multi_device_23
DEBUG 01-07 14:54:42.478706.478706 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.478100.478100 cuda_h.py:19] end gate cost 0.0006437301635742188 seconds
DEBUG 01-07 14:54:42.478976.478976 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.479201.479201 lmp.py:744] 
DEBUG 01-07 14:54:42.479201.479201 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.479911.479911 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.479899.479899 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.479687.479687 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.479046.479046 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.479165.479165 lmp.py:749] 
DEBUG 01-07 14:54:42.479165.479165 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.479332.479332 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.479981.479981 lmp.py:767]   Expert  5 |     15 | CPU
DEBUG 01-07 14:54:42.479909.479909 lmp.py:767]   Expert 56 |     34 | CPU
DEBUG 01-07 14:54:42.479598.479598 lmp.py:767]   Expert 27 |     79 | CPU
DEBUG 01-07 14:54:42.479811.479811 lmp.py:767]   Expert 16 |     82 | CPU
DEBUG 01-07 14:54:42.479785.479785 lmp.py:767]   Expert 17 |     89 | CPU
DEBUG 01-07 14:54:42.479759.479759 lmp.py:767]   Expert 40 |     92 | CPU
DEBUG 01-07 14:54:42.479640.479640 lmp.py:767]   Expert 51 |    101 | CPU
DEBUG 01-07 14:54:42.479806.479806 lmp.py:767]   Expert 49 |    103 | CPU
DEBUG 01-07 14:54:42.479734.479734 lmp.py:767]   Expert 63 |    104 | CPU
DEBUG 01-07 14:54:42.479900.479900 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 14:54:42.479020.479020 lmp.py:767]   Expert  7 |    109 | CPU
DEBUG 01-07 14:54:42.479378.479378 lmp.py:767]   Expert 53 |    109 | CPU
DEBUG 01-07 14:54:42.479975.479975 lmp.py:767]   Expert 62 |    122 | CPU
DEBUG 01-07 14:54:42.479903.479903 lmp.py:767]   Expert 37 |    125 | CPU
DEBUG 01-07 14:54:42.479592.479592 lmp.py:767]   Expert 38 |    125 | CPU
DEBUG 01-07 14:54:42.479520.479520 lmp.py:767]   Expert 47 |    126 | CPU
DEBUG 01-07 14:54:42.479209.479209 lmp.py:767]   Expert 58 |    129 | CPU
DEBUG 01-07 14:54:42.479898.479898 lmp.py:767]   Expert 11 |    131 | CPU
DEBUG 01-07 14:54:42.479588.479588 lmp.py:767]   Expert 39 |    140 | CPU
DEBUG 01-07 14:54:42.479231.479231 lmp.py:767]   Expert 57 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.479874.479874 lmp.py:767]   Expert  1 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.479755.479755 lmp.py:767]   Expert 14 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.479160.479160 lmp.py:767]   Expert 25 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.479041.479041 lmp.py:767]   Expert 52 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.479922.479922 lmp.py:767]   Expert 23 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.479757.479757 lmp.py:767]   Expert 33 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.479592.479592 lmp.py:767]   Expert 21 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.479428.479428 lmp.py:767]   Expert  6 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.479309.479309 lmp.py:767]   Expert 60 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.479713.479713 lmp.py:767]   Expert 44 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480356.480356 lmp.py:767]   Expert 45 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480761.480761 lmp.py:767]   Expert  4 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480404.480404 lmp.py:767]   Expert 19 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480047.480047 lmp.py:767]   Expert 12 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480690.480690 lmp.py:767]   Expert  3 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480094.480094 lmp.py:767]   Expert 31 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480737.480737 lmp.py:767]   Expert 55 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480380.480380 lmp.py:767]   Expert 30 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480454.480454 lmp.py:767]   Expert 36 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480289.480289 lmp.py:767]   Expert  9 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480362.480362 lmp.py:767]   Expert  0 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480244.480244 lmp.py:767]   Expert 34 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480887.480887 lmp.py:767]   Expert 22 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480530.480530 lmp.py:767]   Expert 41 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480934.480934 lmp.py:767]   Expert 54 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480339.480339 lmp.py:767]   Expert 26 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480743.480743 lmp.py:767]   Expert 43 |    239 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480148.480148 lmp.py:767]   Expert 59 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480553.480553 lmp.py:767]   Expert 50 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480196.480196 lmp.py:767]   Expert 18 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480839.480839 lmp.py:767]   Expert 13 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480435.480435 lmp.py:767]   Expert 42 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480708.480708 lmp.py:767]   Expert 20 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480351.480351 lmp.py:767]   Expert 15 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480994.480994 lmp.py:767]   Expert 29 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480636.480636 lmp.py:767]   Expert 24 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480041.480041 lmp.py:767]   Expert 61 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480922.480922 lmp.py:767]   Expert 35 |    282 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480327.480327 lmp.py:767]   Expert 32 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480970.480970 lmp.py:767]   Expert  2 |    333 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480375.480375 lmp.py:767]   Expert  8 |    341 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480256.480256 lmp.py:767]   Expert 10 |    345 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480899.480899 lmp.py:767]   Expert 46 |    427 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.480542.480542 lmp.py:767]   Expert 48 |    444 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.480231.480231 lmp.py:769] 
DEBUG 01-07 14:54:42.480231.480231 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.480828.480828 lmp.py:770]   CPU:   1920 tokens
DEBUG 01-07 14:54:42.480617.480617 lmp.py:774]   cuda:1:   5252 tokens (23 experts)
DEBUG 01-07 14:54:42.480736.480736 lmp.py:774]   cuda:2:   5116 tokens (22 experts)
DEBUG 01-07 14:54:42.480902.480902 lmp.py:775]   Total GPU:  10368 tokens
DEBUG 01-07 14:54:42.480115.480115 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.480115.480115 lmp.py:776] 
DEBUG 01-07 14:54:42.480003.480003 cuda_h.py:19] end experts_map_get cost 0.0017819404602050781 seconds
DEBUG 01-07 14:54:42.480885.480885 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.480330.480330 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.480393.480393 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.481403.481403 cuda_h.py:19] end allocate_cuda_memory cost 0.0002548694610595703 seconds
DEBUG 01-07 14:54:42.481736.481736 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.481208.481208 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.481017.481017 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.481428.481428 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f8763dbb-bc63-4ff4-aa96-135e09ac2d1a
DEBUG 01-07 14:54:42.481587.481587 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.482082.482082 client.py:127] Model loaded
DEBUG 01-07 14:54:42.482097.482097 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.483666.483666 cuda_h.py:19] end restore2model cost 0.0003490447998046875 seconds
DEBUG 01-07 14:54:42.483866.483866 cuda_h.py:19] end sllm_worker_task cost 0.00971674919128418 seconds
INFO 01-07 14:54:42.483180.483180 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f8763dbb-bc63-4ff4-aa96-135e09ac2d1a
DEBUG 01-07 14:54:42.483745.483745 cuda_h.py:19] end load_into_gpu_async cost 0.002008676528930664 seconds
DEBUG 01-07 14:54:42.483402.483402 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.483722.483722 cuda_h.py:19] end restore_tensors2 cost 0.0002460479736328125 seconds
DEBUG 01-07 14:54:42.483538.483538 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002834320068359375 seconds
DEBUG 01-07 14:54:42.483678.483678 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.485611.485611 cuda_h.py:19] end restore2model cost 0.0019240379333496094 seconds
DEBUG 01-07 14:54:42.485898.485898 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.485604.485604 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.486374.486374 cuda_h.py:19] end allocate_cuda_memory cost 0.00021839141845703125 seconds
DEBUG 01-07 14:54:42.486309.486309 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.486396.486396 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.486298.486298 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.486994.486994 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f0c86ec-2836-4b29-9fcb-1113537fa056
DEBUG 01-07 14:54:42.486212.486212 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.487105.487105 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f0c86ec-2836-4b29-9fcb-1113537fa056
DEBUG 01-07 14:54:42.487617.487617 cuda_h.py:19] end load_into_gpu_async cost 0.00103759765625 seconds
DEBUG 01-07 14:54:42.487750.487750 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.487791.487791 cuda_h.py:19] end restore_tensors2 cost 0.00021529197692871094 seconds
DEBUG 01-07 14:54:42.487515.487515 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017611980438232422 seconds
DEBUG 01-07 14:54:42.487602.487602 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.489333.489333 cuda_h.py:19] end restore2model cost 0.0018448829650878906 seconds
DEBUG 01-07 14:54:42.489454.489454 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008684873580932617 seconds
DEBUG 01-07 14:54:42.489727.489727 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.489974.489974 lmp.py:816] 
DEBUG 01-07 14:54:42.489974.489974 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.489526.489526 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 14:54:42.489937.489937 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.501933.501933 mlpmodule.py:749] group tensors cost 0.011394739151000977 s
DEBUG 01-07 14:54:42.503552.503552 mlpmodule.py:787] pad cost 0.0011010169982910156 s
DEBUG 01-07 14:54:42.503741.503741 mlpmodule.py:793] create cpu tensor cost 4.220008850097656e-05 s
DEBUG 01-07 14:54:42.503458.503458 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 14:54:42.511788.511788 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.512695.512695 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.512222.512222 mlpmodule.py:818] group_w3 first element: 0.04248046875
WARNING 01-07 14:54:42.512491.512491 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.528779.528779 mlpmodule.py:838] group einsum cost 0.02473735809326172 s
DEBUG 01-07 14:54:42.528999.528999 mlpmodule.py:846] cpy2cputensor cost 0.00043320655822753906 s
DEBUG 01-07 14:54:42.531704.531704 cuda_h.py:19] end wait_cetm_experts cost 0.04163980484008789 seconds
DEBUG 01-07 14:54:42.531442.531442 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.531829.531829 cuda_h.py:19] end gpu_sexperts cost 0.00045180320739746094 seconds
DEBUG 01-07 14:54:42.531950.531950 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.532078.532078 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1219253540039062e-05 seconds
DEBUG 01-07 14:54:42.532781.532781 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.532914.532914 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f8763dbb-bc63-4ff4-aa96-135e09ac2d1a
INFO 01-07 14:54:42.532733.532733 client.py:127] Model loaded
INFO 01-07 14:54:42.533616.533616 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f0c86ec-2836-4b29-9fcb-1113537fa056
INFO 01-07 14:54:42.533915.533915 client.py:127] Model loaded
DEBUG 01-07 14:54:42.533453.533453 cuda_h.py:19] end wait_experts_multi_device cost 0.0014519691467285156 seconds
DEBUG 01-07 14:54:42.533964.533964 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.533303.533303 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:42.534548.534548 mlpmodule.py:533] gpu group tensors cost 0.00040411949157714844 s
DEBUG 01-07 14:54:42.535043.535043 mlpmodule.py:566] gpu pad cost 0.0010797977447509766 s
DEBUG 01-07 14:54:42.536446.536446 mlpmodule.py:584] gpu group einsum cost 0.0005085468292236328 s
DEBUG 01-07 14:54:42.538474.538474 mlpmodule.py:656] gpu experts func einsum cost 0.003931760787963867 s
DEBUG 01-07 14:54:42.538887.538887 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:42.539068.539068 mlpmodule.py:533] gpu group tensors cost 0.00039887428283691406 s
DEBUG 01-07 14:54:42.539583.539583 mlpmodule.py:707]  experts func einsum cost 0.04942822456359863 s
DEBUG 01-07 14:54:42.540110.540110 mlpmodule.py:566] gpu pad cost 0.001201629638671875 s
DEBUG 01-07 14:54:42.540582.540582 mlpmodule.py:584] gpu group einsum cost 0.00038051605224609375 s
DEBUG 01-07 14:54:42.542306.542306 mlpmodule.py:656] gpu experts func einsum cost 0.003770112991333008 s
DEBUG 01-07 14:54:42.542237.542237 cuda_h.py:19] end gpu_experts_multi_device cost 0.008919000625610352 seconds
DEBUG 01-07 14:54:42.542968.542968 cuda_h.py:19] end layer_moe_generate_multi_device_23 cost 0.06438016891479492 seconds
DEBUG 01-07 14:54:42.542301.542301 lmp.py:194] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-07 14:54:42.542223.542223 lmp.py:153] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-07 14:54:42.542396.542396 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 14:54:42.542198.542198 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 14:54:42.542657.542657 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.123283386230469e-05 seconds
DEBUG 01-07 14:54:42.542644.542644 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.103515625e-05 seconds
DEBUG 01-07 14:54:42.543102.543102 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.543350.543350 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.543631.543631 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.543220.543220 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.543352.543352 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.544009.544009 cuda_h.py:19] end allocate_cuda_memory cost 0.0004889965057373047 seconds
DEBUG 01-07 14:54:42.544313.544313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.544191.544191 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.544434.544434 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.544007.544007 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de5a439a-2b9d-4ba5-adfe-ba0a496a10e1
DEBUG 01-07 14:54:42.544299.544299 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.545571.545571 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.545367.545367 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de5a439a-2b9d-4ba5-adfe-ba0a496a10e1
DEBUG 01-07 14:54:42.546316.546316 cuda_h.py:19] end load_into_gpu_async cost 0.0015799999237060547 seconds
DEBUG 01-07 14:54:42.546880.546880 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.546725.546725 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-07 14:54:42.546481.546481 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027124881744384766 seconds
INFO 01-07 14:54:42.546231.546231 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de5a439a-2b9d-4ba5-adfe-ba0a496a10e1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.548628.548628 cuda_h.py:19] end self_attn cost 0.0030257701873779297 seconds
DEBUG 01-07 14:54:42.548097.548097 cuda_h.py:19] end iln_self_attn_paln cost 0.0055463314056396484 seconds
DEBUG 01-07 14:54:42.548311.548311 cuda_h.py:10] start layer_moe_generate_multi_device_24
DEBUG 01-07 14:54:42.548497.548497 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.549043.549043 cuda_h.py:19] end gate cost 0.0006499290466308594 seconds
DEBUG 01-07 14:54:42.549542.549542 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.549397.549397 lmp.py:744] 
DEBUG 01-07 14:54:42.549397.549397 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.549491.549491 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.549809.549809 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.549313.549313 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.549195.549195 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.549122.549122 lmp.py:749] 
DEBUG 01-07 14:54:42.549122.549122 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.549242.549242 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.549607.549607 lmp.py:767]   Expert 36 |     21 | CPU
DEBUG 01-07 14:54:42.550489.550489 lmp.py:767]   Expert 35 |     28 | CPU
DEBUG 01-07 14:54:42.550893.550893 lmp.py:767]   Expert 46 |     42 | CPU
DEBUG 01-07 14:54:42.550582.550582 lmp.py:767]   Expert 25 |     43 | CPU
DEBUG 01-07 14:54:42.550510.550510 lmp.py:767]   Expert 16 |     58 | CPU
DEBUG 01-07 14:54:42.550153.550153 lmp.py:767]   Expert 51 |     58 | CPU
DEBUG 01-07 14:54:42.550558.550558 lmp.py:767]   Expert  0 |     63 | CPU
DEBUG 01-07 14:54:42.550962.550962 lmp.py:767]   Expert 30 |     63 | CPU
DEBUG 01-07 14:54:42.550128.550128 lmp.py:767]   Expert 47 |     71 | CPU
DEBUG 01-07 14:54:42.550533.550533 lmp.py:767]   Expert 43 |     72 | CPU
DEBUG 01-07 14:54:42.550699.550699 lmp.py:767]   Expert 44 |     73 | CPU
DEBUG 01-07 14:54:42.550627.550627 lmp.py:767]   Expert 39 |     74 | CPU
DEBUG 01-07 14:54:42.550078.550078 lmp.py:767]   Expert 55 |     75 | CPU
DEBUG 01-07 14:54:42.550244.550244 lmp.py:767]   Expert 42 |     78 | CPU
DEBUG 01-07 14:54:42.550695.550695 lmp.py:767]   Expert  2 |     86 | CPU
DEBUG 01-07 14:54:42.550384.550384 lmp.py:767]   Expert  4 |    100 | CPU
DEBUG 01-07 14:54:42.550073.550073 lmp.py:767]   Expert 48 |    116 | CPU
DEBUG 01-07 14:54:42.550001.550001 lmp.py:767]   Expert  6 |    119 | CPU
DEBUG 01-07 14:54:42.550644.550644 lmp.py:767]   Expert 33 |    121 | CPU
DEBUG 01-07 14:54:42.550241.550241 lmp.py:767]   Expert 13 |    125 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550076.550076 lmp.py:767]   Expert 61 |    125 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550195.550195 lmp.py:767]   Expert 24 |    126 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550554.550554 lmp.py:767]   Expert 56 |    129 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550197.550197 lmp.py:767]   Expert 15 |    135 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550601.550601 lmp.py:767]   Expert 29 |    135 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550006.550006 lmp.py:767]   Expert  9 |    139 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550410.550410 lmp.py:767]   Expert 38 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550577.550577 lmp.py:767]   Expert  7 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550743.550743 lmp.py:767]   Expert 20 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550670.550670 lmp.py:767]   Expert 54 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550267.550267 lmp.py:767]   Expert 59 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550148.550148 lmp.py:767]   Expert 45 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550030.550030 lmp.py:767]   Expert 19 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550388.550388 lmp.py:767]   Expert 62 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550031.550031 lmp.py:767]   Expert 34 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550436.550436 lmp.py:767]   Expert 57 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550840.550840 lmp.py:767]   Expert 50 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550768.550768 lmp.py:767]   Expert 23 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550934.550934 lmp.py:767]   Expert 31 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550100.550100 lmp.py:767]   Expert 10 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550266.550266 lmp.py:767]   Expert  8 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550194.550194 lmp.py:767]   Expert 60 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550360.550360 lmp.py:767]   Expert 22 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550480.550480 lmp.py:767]   Expert 53 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550600.550600 lmp.py:767]   Expert 18 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550243.550243 lmp.py:767]   Expert 52 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550886.550886 lmp.py:767]   Expert 37 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550529.550529 lmp.py:767]   Expert  5 |    238 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550410.550410 lmp.py:767]   Expert 17 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550815.550815 lmp.py:767]   Expert 11 |    261 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550981.550981 lmp.py:767]   Expert  1 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550908.550908 lmp.py:767]   Expert 49 |    276 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550313.550313 lmp.py:767]   Expert 41 |    280 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550479.550479 lmp.py:767]   Expert 26 |    287 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550884.550884 lmp.py:767]   Expert 28 |    287 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550288.550288 lmp.py:767]   Expert 32 |    292 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.550454.550454 lmp.py:767]   Expert 58 |    299 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.550859.550859 lmp.py:767]   Expert 40 |    301 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.551456.551456 lmp.py:767]   Expert 14 |    314 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.551575.551575 lmp.py:767]   Expert 12 |    331 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.551695.551695 lmp.py:767]   Expert 63 |    333 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.551577.551577 lmp.py:767]   Expert 21 |    376 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.551412.551412 lmp.py:767]   Expert 27 |    656 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.551055.551055 lmp.py:767]   Expert  3 |   1026 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.551506.551506 lmp.py:769] 
DEBUG 01-07 14:54:42.551506.551506 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.551433.551433 lmp.py:770]   CPU:   1361 tokens
DEBUG 01-07 14:54:42.551553.551553 lmp.py:774]   cuda:1:   5459 tokens (22 experts)
DEBUG 01-07 14:54:42.551481.551481 lmp.py:774]   cuda:2:   5468 tokens (23 experts)
DEBUG 01-07 14:54:42.551932.551932 lmp.py:775]   Total GPU:  10927 tokens
DEBUG 01-07 14:54:42.551383.551383 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.551383.551383 lmp.py:776] 
DEBUG 01-07 14:54:42.551748.551748 cuda_h.py:19] end experts_map_get cost 0.0017733573913574219 seconds
DEBUG 01-07 14:54:42.551867.551867 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.551988.551988 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.551714.551714 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.553662.553662 cuda_h.py:19] end allocate_cuda_memory cost 0.001577138900756836 seconds
DEBUG 01-07 14:54:42.553042.553042 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.553275.553275 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.553991.553991 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.553118.553118 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3a687c7-9c5c-45dd-9edb-8e8a29908b38
DEBUG 01-07 14:54:42.553369.553369 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.553840.553840 client.py:127] Model loaded
DEBUG 01-07 14:54:42.553431.553431 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.553211.553211 cuda_h.py:19] end restore2model cost 0.0003337860107421875 seconds
DEBUG 01-07 14:54:42.554027.554027 cuda_h.py:19] end sllm_worker_task cost 0.010661840438842773 seconds
INFO 01-07 14:54:42.554122.554122 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3a687c7-9c5c-45dd-9edb-8e8a29908b38
DEBUG 01-07 14:54:42.554913.554913 cuda_h.py:19] end load_into_gpu_async cost 0.0010647773742675781 seconds
DEBUG 01-07 14:54:42.554000.554000 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.554983.554983 cuda_h.py:19] end restore_tensors2 cost 0.0002434253692626953 seconds
DEBUG 01-07 14:54:42.554037.554037 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032072067260742188 seconds
DEBUG 01-07 14:54:42.554608.554608 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.556723.556723 cuda_h.py:19] end restore2model cost 0.0018463134765625 seconds
DEBUG 01-07 14:54:42.556925.556925 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.556551.556551 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.556633.556633 cuda_h.py:19] end allocate_cuda_memory cost 0.00023651123046875 seconds
DEBUG 01-07 14:54:42.556569.556569 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.556656.556656 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.557081.557081 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.557492.557492 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed1593c2-c019-4b84-81b4-4e8e31a7cc0c
DEBUG 01-07 14:54:42.557908.557908 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.558553.558553 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed1593c2-c019-4b84-81b4-4e8e31a7cc0c
DEBUG 01-07 14:54:42.558429.558429 cuda_h.py:19] end load_into_gpu_async cost 0.0011303424835205078 seconds
DEBUG 01-07 14:54:42.558271.558271 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.558703.558703 cuda_h.py:19] end restore_tensors2 cost 0.00022292137145996094 seconds
DEBUG 01-07 14:54:42.558234.558234 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00188446044921875 seconds
DEBUG 01-07 14:54:42.558321.558321 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.560325.560325 cuda_h.py:19] end restore2model cost 0.0018715858459472656 seconds
DEBUG 01-07 14:54:42.560029.560029 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009155511856079102 seconds
DEBUG 01-07 14:54:42.560017.560017 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.560986.560986 lmp.py:816] 
DEBUG 01-07 14:54:42.560986.560986 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.560299.560299 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-07 14:54:42.560426.560426 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.566700.566700 mlpmodule.py:749] group tensors cost 0.005481719970703125 s
DEBUG 01-07 14:54:42.568814.568814 mlpmodule.py:787] pad cost 0.0012559890747070312 s
DEBUG 01-07 14:54:42.568268.568268 mlpmodule.py:793] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-07 14:54:42.568205.568205 mlpmodule.py:798] move to cpu cost 3.814697265625e-05 s
DEBUG 01-07 14:54:42.576912.576912 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.577673.577673 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.577624.577624 mlpmodule.py:818] group_w3 first element: 0.00653076171875
WARNING 01-07 14:54:42.577985.577985 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.591897.591897 mlpmodule.py:838] group einsum cost 0.022757768630981445 s
DEBUG 01-07 14:54:42.591223.591223 mlpmodule.py:846] cpy2cputensor cost 0.0004324913024902344 s
DEBUG 01-07 14:54:42.594582.594582 cuda_h.py:19] end wait_cetm_experts cost 0.03408384323120117 seconds
DEBUG 01-07 14:54:42.594435.594435 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.595521.595521 cuda_h.py:19] end gpu_sexperts cost 0.0007200241088867188 seconds
DEBUG 01-07 14:54:42.595696.595696 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.595024.595024 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.2901763916015625e-05 seconds
DEBUG 01-07 14:54:42.595523.595523 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.595690.595690 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3a687c7-9c5c-45dd-9edb-8e8a29908b38
INFO 01-07 14:54:42.598889.598889 client.py:127] Model loaded
INFO 01-07 14:54:42.598389.598389 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed1593c2-c019-4b84-81b4-4e8e31a7cc0c
INFO 01-07 14:54:42.599440.599440 client.py:127] Model loaded
DEBUG 01-07 14:54:42.599649.599649 cuda_h.py:19] end wait_experts_multi_device cost 0.003509044647216797 seconds
DEBUG 01-07 14:54:42.599221.599221 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.599423.599423 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.602000.602000 mlpmodule.py:533] gpu group tensors cost 0.0010347366333007812 s
DEBUG 01-07 14:54:42.602754.602754 mlpmodule.py:707]  experts func einsum cost 0.04173731803894043 s
DEBUG 01-07 14:54:42.605349.605349 mlpmodule.py:566] gpu pad cost 0.003343343734741211 s
DEBUG 01-07 14:54:42.606325.606325 mlpmodule.py:584] gpu group einsum cost 0.0011043548583984375 s
DEBUG 01-07 14:54:42.610177.610177 mlpmodule.py:656] gpu experts func einsum cost 0.009116411209106445 s
DEBUG 01-07 14:54:42.610487.610487 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.611599.611599 mlpmodule.py:533] gpu group tensors cost 0.0004515647888183594 s
DEBUG 01-07 14:54:42.612592.612592 mlpmodule.py:566] gpu pad cost 0.0012993812561035156 s
DEBUG 01-07 14:54:42.613227.613227 mlpmodule.py:584] gpu group einsum cost 0.0005009174346923828 s
DEBUG 01-07 14:54:42.615578.615578 mlpmodule.py:656] gpu experts func einsum cost 0.004368782043457031 s
DEBUG 01-07 14:54:42.615581.615581 cuda_h.py:19] end gpu_experts_multi_device cost 0.0156402587890625 seconds
DEBUG 01-07 14:54:42.615810.615810 cuda_h.py:19] end layer_moe_generate_multi_device_24 cost 0.06669855117797852 seconds
DEBUG 01-07 14:54:42.615501.615501 lmp.py:194] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-07 14:54:42.615099.615099 lmp.py:153] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-07 14:54:42.615232.615232 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 14:54:42.615141.615141 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 14:54:42.615990.615990 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.266334533691406e-05 seconds
DEBUG 01-07 14:54:42.615131.615131 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.961822509765625e-05 seconds
DEBUG 01-07 14:54:42.615449.615449 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.615531.615531 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.616004.616004 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.616059.616059 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.616268.616268 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.616299.616299 cuda_h.py:19] end allocate_cuda_memory cost 0.00030112266540527344 seconds
DEBUG 01-07 14:54:42.616441.616441 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.616866.616866 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.616258.616258 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.616438.616438 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2aeeb31-dab1-44ac-afcd-e7439eccdb9c
DEBUG 01-07 14:54:42.616639.616639 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.617842.617842 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.617003.617003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2aeeb31-dab1-44ac-afcd-e7439eccdb9c
DEBUG 01-07 14:54:42.617363.617363 cuda_h.py:19] end load_into_gpu_async cost 0.000997304916381836 seconds
DEBUG 01-07 14:54:42.617350.617350 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.617333.617333 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-07 14:54:42.617613.617613 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016083717346191406 seconds
INFO 01-07 14:54:42.617396.617396 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2aeeb31-dab1-44ac-afcd-e7439eccdb9c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.621642.621642 cuda_h.py:19] end self_attn cost 0.0038537979125976562 seconds
DEBUG 01-07 14:54:42.621176.621176 cuda_h.py:19] end iln_self_attn_paln cost 0.005452394485473633 seconds
DEBUG 01-07 14:54:42.621767.621767 cuda_h.py:10] start layer_moe_generate_multi_device_25
DEBUG 01-07 14:54:42.621954.621954 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.622023.622023 cuda_h.py:19] end gate cost 0.0006501674652099609 seconds
DEBUG 01-07 14:54:42.622806.622806 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.622661.622661 lmp.py:744] 
DEBUG 01-07 14:54:42.622661.622661 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.622947.622947 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.622027.622027 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.622008.622008 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.622082.622082 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.622486.622486 lmp.py:749] 
DEBUG 01-07 14:54:42.622486.622486 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.622606.622606 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.622448.622448 lmp.py:767]   Expert 13 |     28 | CPU
DEBUG 01-07 14:54:42.622329.622329 lmp.py:767]   Expert 44 |     37 | CPU
DEBUG 01-07 14:54:42.622734.622734 lmp.py:767]   Expert 25 |     39 | CPU
DEBUG 01-07 14:54:42.622900.622900 lmp.py:767]   Expert  9 |     40 | CPU
DEBUG 01-07 14:54:42.622828.622828 lmp.py:767]   Expert 16 |     46 | CPU
DEBUG 01-07 14:54:42.622994.622994 lmp.py:767]   Expert 38 |     47 | CPU
DEBUG 01-07 14:54:42.622445.622445 lmp.py:767]   Expert 22 |     51 | CPU
DEBUG 01-07 14:54:42.622134.622134 lmp.py:767]   Expert 33 |     55 | CPU
DEBUG 01-07 14:54:42.622062.622062 lmp.py:767]   Expert  2 |     57 | CPU
DEBUG 01-07 14:54:42.622943.622943 lmp.py:767]   Expert 42 |     61 | CPU
DEBUG 01-07 14:54:42.622825.622825 lmp.py:767]   Expert  5 |     64 | CPU
DEBUG 01-07 14:54:42.622229.622229 lmp.py:767]   Expert 23 |     74 | CPU
DEBUG 01-07 14:54:42.622872.622872 lmp.py:767]   Expert 24 |     85 | CPU
DEBUG 01-07 14:54:42.622038.622038 lmp.py:767]   Expert 10 |     87 | CPU
DEBUG 01-07 14:54:42.623728.623728 lmp.py:767]   Expert 59 |    102 | CPU
DEBUG 01-07 14:54:42.623417.623417 lmp.py:767]   Expert 21 |    105 | CPU
DEBUG 01-07 14:54:42.623345.623345 lmp.py:767]   Expert 46 |    109 | CPU
DEBUG 01-07 14:54:42.623795.623795 lmp.py:767]   Expert 55 |    114 | CPU
DEBUG 01-07 14:54:42.623485.623485 lmp.py:767]   Expert 61 |    118 | CPU
DEBUG 01-07 14:54:42.623605.623605 lmp.py:767]   Expert 45 |    120 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623724.623724 lmp.py:767]   Expert 31 |    125 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623559.623559 lmp.py:767]   Expert 36 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623441.623441 lmp.py:767]   Expert 51 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623276.623276 lmp.py:767]   Expert  6 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623634.623634 lmp.py:767]   Expert  0 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623039.623039 lmp.py:767]   Expert  8 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623682.623682 lmp.py:767]   Expert 43 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623086.623086 lmp.py:767]   Expert  3 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623491.623491 lmp.py:767]   Expert 26 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623134.623134 lmp.py:767]   Expert 18 |    157 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623538.623538 lmp.py:767]   Expert 48 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623704.623704 lmp.py:767]   Expert 41 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623347.623347 lmp.py:767]   Expert 12 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623514.623514 lmp.py:767]   Expert  7 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623110.623110 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623468.623468 lmp.py:767]   Expert 28 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623065.623065 lmp.py:767]   Expert 56 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623900.623900 lmp.py:767]   Expert 27 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623305.623305 lmp.py:767]   Expert 34 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623471.623471 lmp.py:767]   Expert 47 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623875.623875 lmp.py:767]   Expert  1 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623803.623803 lmp.py:767]   Expert 11 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623731.623731 lmp.py:767]   Expert 32 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623612.623612 lmp.py:767]   Expert 40 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623732.623732 lmp.py:767]   Expert 49 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623852.623852 lmp.py:767]   Expert 53 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623210.623210 lmp.py:767]   Expert 63 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623045.623045 lmp.py:767]   Expert 15 |    244 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623688.623688 lmp.py:767]   Expert 29 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623093.623093 lmp.py:767]   Expert  4 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623020.623020 lmp.py:767]   Expert 30 |    248 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623425.623425 lmp.py:767]   Expert 50 |    248 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623591.623591 lmp.py:767]   Expert 14 |    274 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623757.623757 lmp.py:767]   Expert 35 |    274 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623162.623162 lmp.py:767]   Expert 37 |    301 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623805.623805 lmp.py:767]   Expert 52 |    335 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623925.623925 lmp.py:767]   Expert 17 |    363 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623044.623044 lmp.py:767]   Expert 54 |    378 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623403.623403 lmp.py:767]   Expert 39 |    389 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623999.623999 lmp.py:767]   Expert 57 |    413 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623642.623642 lmp.py:767]   Expert 60 |    456 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623047.623047 lmp.py:767]   Expert 62 |    465 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623451.623451 lmp.py:767]   Expert 19 |    547 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.623617.623617 lmp.py:767]   Expert 58 |    577 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.623068.623068 lmp.py:769] 
DEBUG 01-07 14:54:42.623068.623068 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.623473.623473 lmp.py:770]   CPU:   1319 tokens
DEBUG 01-07 14:54:42.623354.623354 lmp.py:774]   cuda:1:   5429 tokens (22 experts)
DEBUG 01-07 14:54:42.623997.623997 lmp.py:774]   cuda:2:   5540 tokens (23 experts)
DEBUG 01-07 14:54:42.623640.623640 lmp.py:775]   Total GPU:  10969 tokens
DEBUG 01-07 14:54:42.623806.623806 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.623806.623806 lmp.py:776] 
DEBUG 01-07 14:54:42.624410.624410 cuda_h.py:19] end experts_map_get cost 0.0017859935760498047 seconds
DEBUG 01-07 14:54:42.624006.624006 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.624829.624829 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.624694.624694 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.624517.624517 cuda_h.py:19] end allocate_cuda_memory cost 0.00022172927856445312 seconds
DEBUG 01-07 14:54:42.624844.624844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.624792.624792 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.624508.624508 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.624112.624112 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e92bed60-0dd6-4431-a5a0-03ed9f462332
DEBUG 01-07 14:54:42.624853.624853 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.624801.624801 client.py:127] Model loaded
DEBUG 01-07 14:54:42.625836.625836 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.625361.625361 cuda_h.py:19] end restore2model cost 0.0004181861877441406 seconds
DEBUG 01-07 14:54:42.625429.625429 cuda_h.py:19] end sllm_worker_task cost 0.009479999542236328 seconds
INFO 01-07 14:54:42.625683.625683 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e92bed60-0dd6-4431-a5a0-03ed9f462332
DEBUG 01-07 14:54:42.625810.625810 cuda_h.py:19] end load_into_gpu_async cost 0.0013458728790283203 seconds
DEBUG 01-07 14:54:42.625083.625083 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.626278.626278 cuda_h.py:19] end restore_tensors2 cost 0.0002593994140625 seconds
DEBUG 01-07 14:54:42.626716.626716 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002142190933227539 seconds
DEBUG 01-07 14:54:42.626095.626095 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.628846.628846 cuda_h.py:19] end restore2model cost 0.0018200874328613281 seconds
DEBUG 01-07 14:54:42.628371.628371 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.628560.628560 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.628000.628000 cuda_h.py:19] end allocate_cuda_memory cost 0.00025343894958496094 seconds
DEBUG 01-07 14:54:42.628082.628082 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.628838.628838 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.628739.628739 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.628628.628628 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36e60e14-627c-4433-bd29-e0b485f54454
DEBUG 01-07 14:54:42.628309.628309 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.630578.630578 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36e60e14-627c-4433-bd29-e0b485f54454
DEBUG 01-07 14:54:42.630599.630599 cuda_h.py:19] end load_into_gpu_async cost 0.0015778541564941406 seconds
DEBUG 01-07 14:54:42.630872.630872 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.630862.630862 cuda_h.py:19] end restore_tensors2 cost 0.00028324127197265625 seconds
DEBUG 01-07 14:54:42.630685.630685 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024149417877197266 seconds
DEBUG 01-07 14:54:42.630679.630679 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.632233.632233 cuda_h.py:19] end restore2model cost 0.001889944076538086 seconds
DEBUG 01-07 14:54:42.632116.632116 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008590936660766602 seconds
DEBUG 01-07 14:54:42.632912.632912 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.632802.632802 lmp.py:816] 
DEBUG 01-07 14:54:42.632802.632802 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.632354.632354 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-07 14:54:42.632003.632003 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.641357.641357 mlpmodule.py:749] group tensors cost 0.008043050765991211 s
DEBUG 01-07 14:54:42.643592.643592 mlpmodule.py:787] pad cost 0.0012366771697998047 s
DEBUG 01-07 14:54:42.643457.643457 mlpmodule.py:793] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-07 14:54:42.643850.643850 mlpmodule.py:798] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-07 14:54:42.652782.652782 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.652776.652776 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.652918.652918 mlpmodule.py:818] group_w3 first element: -0.02734375
WARNING 01-07 14:54:42.652857.652857 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.668263.668263 mlpmodule.py:838] group einsum cost 0.02469778060913086 s
DEBUG 01-07 14:54:42.668447.668447 mlpmodule.py:846] cpy2cputensor cost 0.00036787986755371094 s
DEBUG 01-07 14:54:42.671605.671605 cuda_h.py:19] end wait_cetm_experts cost 0.03847908973693848 seconds
DEBUG 01-07 14:54:42.671498.671498 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.672837.672837 cuda_h.py:19] end gpu_sexperts cost 0.0009198188781738281 seconds
DEBUG 01-07 14:54:42.672192.672192 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.672839.672839 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.790855407714844e-05 seconds
DEBUG 01-07 14:54:42.672358.672358 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.672737.672737 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e92bed60-0dd6-4431-a5a0-03ed9f462332
INFO 01-07 14:54:42.673180.673180 client.py:127] Model loaded
INFO 01-07 14:54:42.674230.674230 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36e60e14-627c-4433-bd29-e0b485f54454
INFO 01-07 14:54:42.674428.674428 client.py:127] Model loaded
DEBUG 01-07 14:54:42.674392.674392 cuda_h.py:19] end wait_experts_multi_device cost 0.0017447471618652344 seconds
DEBUG 01-07 14:54:42.674434.674434 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.674748.674748 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.677068.677068 mlpmodule.py:533] gpu group tensors cost 0.0010056495666503906 s
DEBUG 01-07 14:54:42.679487.679487 mlpmodule.py:707]  experts func einsum cost 0.046372175216674805 s
DEBUG 01-07 14:54:42.680456.680456 mlpmodule.py:566] gpu pad cost 0.0031347274780273438 s
DEBUG 01-07 14:54:42.681889.681889 mlpmodule.py:584] gpu group einsum cost 0.0006821155548095703 s
DEBUG 01-07 14:54:42.683047.683047 mlpmodule.py:656] gpu experts func einsum cost 0.007708072662353516 s
DEBUG 01-07 14:54:42.684145.684145 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.685528.685528 mlpmodule.py:533] gpu group tensors cost 0.0005414485931396484 s
DEBUG 01-07 14:54:42.686074.686074 mlpmodule.py:566] gpu pad cost 0.001590728759765625 s
DEBUG 01-07 14:54:42.687056.687056 mlpmodule.py:584] gpu group einsum cost 0.0005691051483154297 s
DEBUG 01-07 14:54:42.689139.689139 mlpmodule.py:656] gpu experts func einsum cost 0.005345582962036133 s
DEBUG 01-07 14:54:42.690647.690647 cuda_h.py:19] end gpu_experts_multi_device cost 0.015195369720458984 seconds
DEBUG 01-07 14:54:42.690094.690094 cuda_h.py:19] end layer_moe_generate_multi_device_25 cost 0.06867647171020508 seconds
DEBUG 01-07 14:54:42.690879.690879 lmp.py:194] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-07 14:54:42.690537.690537 lmp.py:153] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-07 14:54:42.690677.690677 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 14:54:42.690321.690321 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 14:54:42.690727.690727 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.6702880859375e-05 seconds
DEBUG 01-07 14:54:42.690999.690999 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.626678466796875e-05 seconds
DEBUG 01-07 14:54:42.690119.690119 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.690750.690750 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:42.690660.690660 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.690920.690920 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.691090.691090 cuda_h.py:19] end allocate_cuda_memory cost 0.00029969215393066406 seconds
DEBUG 01-07 14:54:42.691781.691781 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.691902.691902 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.691270.691270 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.691046.691046 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.691703.691703 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bcd2532d-f822-4a7e-a5d2-d959eb246a04
DEBUG 01-07 14:54:42.691196.691196 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:42.691530.691530 cuda_h.py:10] start self_attn
INFO 01-07 14:54:42.692231.692231 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bcd2532d-f822-4a7e-a5d2-d959eb246a04
DEBUG 01-07 14:54:42.692347.692347 cuda_h.py:19] end load_into_gpu_async cost 0.001110076904296875 seconds
DEBUG 01-07 14:54:42.692957.692957 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.692086.692086 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-07 14:54:42.692365.692365 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001857757568359375 seconds
INFO 01-07 14:54:42.692572.692572 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bcd2532d-f822-4a7e-a5d2-d959eb246a04
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.694083.694083 cuda_h.py:19] end self_attn cost 0.0030138492584228516 seconds
DEBUG 01-07 14:54:42.695769.695769 cuda_h.py:19] end iln_self_attn_paln cost 0.004552602767944336 seconds
DEBUG 01-07 14:54:42.695361.695361 cuda_h.py:10] start layer_moe_generate_multi_device_26
DEBUG 01-07 14:54:42.695785.695785 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.696623.696623 cuda_h.py:19] end gate cost 0.0006544589996337891 seconds
DEBUG 01-07 14:54:42.696645.696645 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.696513.696513 lmp.py:744] 
DEBUG 01-07 14:54:42.696513.696513 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.696753.696753 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.696787.696787 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.696006.696006 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.696556.696556 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.696915.696915 lmp.py:749] 
DEBUG 01-07 14:54:42.696915.696915 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.696227.696227 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.696545.696545 lmp.py:767]   Expert 20 |     10 | CPU
DEBUG 01-07 14:54:42.696904.696904 lmp.py:767]   Expert 61 |     11 | CPU
DEBUG 01-07 14:54:42.696308.696308 lmp.py:767]   Expert 11 |     28 | CPU
DEBUG 01-07 14:54:42.696474.696474 lmp.py:767]   Expert  7 |     36 | CPU
DEBUG 01-07 14:54:42.696879.696879 lmp.py:767]   Expert 62 |     41 | CPU
DEBUG 01-07 14:54:42.696568.696568 lmp.py:767]   Expert  3 |     44 | CPU
DEBUG 01-07 14:54:42.696496.696496 lmp.py:767]   Expert 51 |     44 | CPU
DEBUG 01-07 14:54:42.696947.696947 lmp.py:767]   Expert 30 |     49 | CPU
DEBUG 01-07 14:54:42.696636.696636 lmp.py:767]   Expert 17 |     54 | CPU
DEBUG 01-07 14:54:42.696517.696517 lmp.py:767]   Expert 29 |     57 | CPU
DEBUG 01-07 14:54:42.696160.696160 lmp.py:767]   Expert  6 |     60 | CPU
DEBUG 01-07 14:54:42.696280.696280 lmp.py:767]   Expert  9 |     69 | CPU
DEBUG 01-07 14:54:42.696731.696731 lmp.py:767]   Expert 38 |     75 | CPU
DEBUG 01-07 14:54:42.696089.696089 lmp.py:767]   Expert 63 |     77 | CPU
DEBUG 01-07 14:54:42.696017.696017 lmp.py:767]   Expert 55 |     81 | CPU
DEBUG 01-07 14:54:42.696706.696706 lmp.py:767]   Expert 59 |     87 | CPU
DEBUG 01-07 14:54:42.696919.696919 lmp.py:767]   Expert 19 |     92 | CPU
DEBUG 01-07 14:54:42.696608.696608 lmp.py:767]   Expert  8 |     95 | CPU
DEBUG 01-07 14:54:42.696297.696297 lmp.py:767]   Expert 48 |     99 | CPU
DEBUG 01-07 14:54:42.697940.697940 lmp.py:767]   Expert 49 |     99 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697060.697060 lmp.py:767]   Expert 22 |    107 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697942.697942 lmp.py:767]   Expert 24 |    114 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697585.697585 lmp.py:767]   Expert 34 |    115 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697466.697466 lmp.py:767]   Expert 36 |    115 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697063.697063 lmp.py:767]   Expert 50 |    116 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697136.697136 lmp.py:767]   Expert 42 |    117 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697210.697210 lmp.py:767]   Expert 39 |    122 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697806.697806 lmp.py:767]   Expert  4 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697449.697449 lmp.py:767]   Expert 37 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697854.697854 lmp.py:767]   Expert 15 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697258.697258 lmp.py:767]   Expert 41 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697663.697663 lmp.py:767]   Expert 23 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697829.697829 lmp.py:767]   Expert 56 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697472.697472 lmp.py:767]   Expert 16 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697592.697592 lmp.py:767]   Expert 60 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697188.697188 lmp.py:767]   Expert 44 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697023.697023 lmp.py:767]   Expert  1 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697620.697620 lmp.py:767]   Expert 43 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697502.697502 lmp.py:767]   Expert 21 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697668.697668 lmp.py:767]   Expert 47 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697357.697357 lmp.py:767]   Expert 53 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697762.697762 lmp.py:767]   Expert 12 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697928.697928 lmp.py:767]   Expert 33 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697094.697094 lmp.py:767]   Expert 13 |    207 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697260.697260 lmp.py:767]   Expert 32 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697664.697664 lmp.py:767]   Expert 28 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697784.697784 lmp.py:767]   Expert  0 |    253 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697858.697858 lmp.py:767]   Expert 31 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697216.697216 lmp.py:767]   Expert 54 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697051.697051 lmp.py:767]   Expert 26 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697932.697932 lmp.py:767]   Expert 10 |    261 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697099.697099 lmp.py:767]   Expert 18 |    270 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697503.697503 lmp.py:767]   Expert 57 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697908.697908 lmp.py:767]   Expert  2 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697074.697074 lmp.py:767]   Expert 58 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697478.697478 lmp.py:767]   Expert 40 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697645.697645 lmp.py:767]   Expert 45 |    362 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697288.697288 lmp.py:767]   Expert 25 |    369 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697646.697646 lmp.py:767]   Expert  5 |    440 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697766.697766 lmp.py:767]   Expert 35 |    451 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697601.697601 lmp.py:767]   Expert 27 |    485 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697197.697197 lmp.py:767]   Expert 46 |    551 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697178.697178 lmp.py:767]   Expert 52 |    590 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.697106.697106 lmp.py:767]   Expert 14 |    893 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.697365.697365 lmp.py:769] 
DEBUG 01-07 14:54:42.697365.697365 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.697816.697816 lmp.py:770]   CPU:   1109 tokens
DEBUG 01-07 14:54:42.697505.697505 lmp.py:774]   cuda:1:   5589 tokens (22 experts)
DEBUG 01-07 14:54:42.697433.697433 lmp.py:774]   cuda:2:   5590 tokens (23 experts)
DEBUG 01-07 14:54:42.697168.697168 lmp.py:775]   Total GPU:  11179 tokens
DEBUG 01-07 14:54:42.697665.697665 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.697665.697665 lmp.py:776] 
DEBUG 01-07 14:54:42.697123.697123 cuda_h.py:19] end experts_map_get cost 0.001798391342163086 seconds
DEBUG 01-07 14:54:42.697481.697481 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.697403.697403 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.698414.698414 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.699934.699934 cuda_h.py:19] end allocate_cuda_memory cost 0.0016491413116455078 seconds
DEBUG 01-07 14:54:42.699843.699843 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.699745.699745 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.699031.699031 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.699396.699396 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fa11dec2-9987-45a0-b8ba-fda005d689b1
DEBUG 01-07 14:54:42.700330.700330 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.700779.700779 client.py:127] Model loaded
DEBUG 01-07 14:54:42.700993.700993 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.700875.700875 cuda_h.py:19] end restore2model cost 0.00040435791015625 seconds
DEBUG 01-07 14:54:42.701374.701374 cuda_h.py:19] end sllm_worker_task cost 0.010258197784423828 seconds
INFO 01-07 14:54:42.701774.701774 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fa11dec2-9987-45a0-b8ba-fda005d689b1
DEBUG 01-07 14:54:42.701240.701240 cuda_h.py:19] end load_into_gpu_async cost 0.0015211105346679688 seconds
DEBUG 01-07 14:54:42.701466.701466 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.701807.701807 cuda_h.py:19] end restore_tensors2 cost 0.00026154518127441406 seconds
DEBUG 01-07 14:54:42.701007.701007 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003757953643798828 seconds
DEBUG 01-07 14:54:42.701101.701101 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.703567.703567 cuda_h.py:19] end restore2model cost 0.0018246173858642578 seconds
DEBUG 01-07 14:54:42.703854.703854 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.703526.703526 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.704641.704641 cuda_h.py:19] end allocate_cuda_memory cost 0.00022554397583007812 seconds
DEBUG 01-07 14:54:42.704100.704100 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.704949.704949 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.704420.704420 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.704639.704639 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 708fdb35-5c8e-40a9-b755-1b3dda717e34
DEBUG 01-07 14:54:42.704003.704003 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.705682.705682 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 708fdb35-5c8e-40a9-b755-1b3dda717e34
DEBUG 01-07 14:54:42.705372.705372 cuda_h.py:19] end load_into_gpu_async cost 0.0015742778778076172 seconds
DEBUG 01-07 14:54:42.705929.705929 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.706244.706244 cuda_h.py:19] end restore_tensors2 cost 0.0002779960632324219 seconds
DEBUG 01-07 14:54:42.706067.706067 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023703575134277344 seconds
DEBUG 01-07 14:54:42.706300.706300 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.708999.708999 cuda_h.py:19] end restore2model cost 0.0018572807312011719 seconds
DEBUG 01-07 14:54:42.708159.708159 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.01013326644897461 seconds
DEBUG 01-07 14:54:42.708239.708239 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.708202.708202 lmp.py:816] 
DEBUG 01-07 14:54:42.708202.708202 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.708085.708085 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 14:54:42.708258.708258 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.714819.714819 mlpmodule.py:749] group tensors cost 0.006325960159301758 s
DEBUG 01-07 14:54:42.717764.717764 mlpmodule.py:787] pad cost 0.0017118453979492188 s
DEBUG 01-07 14:54:42.717345.717345 mlpmodule.py:793] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-07 14:54:42.717156.717156 mlpmodule.py:798] move to cpu cost 4.649162292480469e-05 s
DEBUG 01-07 14:54:42.726331.726331 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.726444.726444 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.726672.726672 mlpmodule.py:818] group_w3 first element: -0.0024261474609375
WARNING 01-07 14:54:42.726404.726404 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.741705.741705 mlpmodule.py:838] group einsum cost 0.024010896682739258 s
DEBUG 01-07 14:54:42.742261.742261 mlpmodule.py:846] cpy2cputensor cost 0.0003707408905029297 s
DEBUG 01-07 14:54:42.744566.744566 cuda_h.py:19] end wait_cetm_experts cost 0.03665280342102051 seconds
DEBUG 01-07 14:54:42.745571.745571 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.745209.745209 cuda_h.py:19] end gpu_sexperts cost 0.0007684230804443359 seconds
DEBUG 01-07 14:54:42.746266.746266 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.746700.746700 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.361701965332031e-05 seconds
DEBUG 01-07 14:54:42.746159.746159 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.746717.746717 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fa11dec2-9987-45a0-b8ba-fda005d689b1
INFO 01-07 14:54:42.747483.747483 client.py:127] Model loaded
INFO 01-07 14:54:42.747896.747896 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 708fdb35-5c8e-40a9-b755-1b3dda717e34
INFO 01-07 14:54:42.748725.748725 client.py:127] Model loaded
DEBUG 01-07 14:54:42.748907.748907 cuda_h.py:19] end wait_experts_multi_device cost 0.0023157596588134766 seconds
DEBUG 01-07 14:54:42.748558.748558 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.748621.748621 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.750799.750799 mlpmodule.py:533] gpu group tensors cost 0.0008456707000732422 s
DEBUG 01-07 14:54:42.752307.752307 mlpmodule.py:707]  experts func einsum cost 0.043853759765625 s
DEBUG 01-07 14:54:42.753578.753578 mlpmodule.py:566] gpu pad cost 0.0027725696563720703 s
DEBUG 01-07 14:54:42.754644.754644 mlpmodule.py:584] gpu group einsum cost 0.0008563995361328125 s
DEBUG 01-07 14:54:42.758863.758863 mlpmodule.py:656] gpu experts func einsum cost 0.008689165115356445 s
DEBUG 01-07 14:54:42.759794.759794 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.760774.760774 mlpmodule.py:533] gpu group tensors cost 0.0008115768432617188 s
DEBUG 01-07 14:54:42.761715.761715 mlpmodule.py:566] gpu pad cost 0.001294851303100586 s
DEBUG 01-07 14:54:42.762455.762455 mlpmodule.py:584] gpu group einsum cost 0.0006916522979736328 s
DEBUG 01-07 14:54:42.764512.764512 mlpmodule.py:656] gpu experts func einsum cost 0.004677534103393555 s
DEBUG 01-07 14:54:42.764509.764509 cuda_h.py:19] end gpu_experts_multi_device cost 0.015677452087402344 seconds
DEBUG 01-07 14:54:42.764578.764578 cuda_h.py:19] end layer_moe_generate_multi_device_26 cost 0.06916213035583496 seconds
DEBUG 01-07 14:54:42.764082.764082 lmp.py:194] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-07 14:54:42.764243.764243 lmp.py:153] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-07 14:54:42.764654.764654 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-07 14:54:42.764662.764662 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.1682510375976562e-05 seconds
DEBUG 01-07 14:54:42.764358.764358 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:42.764294.764294 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:42.765072.765072 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:42.767104.767104 cuda_h.py:19] end self_attn cost 0.002670764923095703 seconds
DEBUG 01-07 14:54:42.768300.768300 cuda_h.py:19] end iln_self_attn_paln cost 0.0033669471740722656 seconds
DEBUG 01-07 14:54:42.768606.768606 cuda_h.py:10] start layer_moe_generate_multi_device_27
DEBUG 01-07 14:54:42.768223.768223 cuda_h.py:10] start gate
DEBUG 01-07 14:54:42.769159.769159 cuda_h.py:19] end gate cost 0.0006198883056640625 seconds
DEBUG 01-07 14:54:42.769373.769373 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:42.769964.769964 lmp.py:744] 
DEBUG 01-07 14:54:42.769964.769964 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:42.769819.769819 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:42.769144.769144 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:42.769602.769602 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:42.769437.769437 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:42.769464.769464 lmp.py:749] 
DEBUG 01-07 14:54:42.769464.769464 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:42.769107.769107 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:42.769426.769426 lmp.py:767]   Expert 18 |     62 | CPU
DEBUG 01-07 14:54:42.769069.769069 lmp.py:767]   Expert 54 |     69 | CPU
DEBUG 01-07 14:54:42.769235.769235 lmp.py:767]   Expert 47 |     71 | CPU
DEBUG 01-07 14:54:42.769401.769401 lmp.py:767]   Expert 23 |     76 | CPU
DEBUG 01-07 14:54:42.769091.769091 lmp.py:767]   Expert 44 |     77 | CPU
DEBUG 01-07 14:54:42.769780.769780 lmp.py:767]   Expert 48 |     79 | CPU
DEBUG 01-07 14:54:42.769231.769231 lmp.py:767]   Expert 45 |     91 | CPU
DEBUG 01-07 14:54:42.769682.769682 lmp.py:767]   Expert 20 |     92 | CPU
DEBUG 01-07 14:54:42.769133.769133 lmp.py:767]   Expert 31 |     94 | CPU
DEBUG 01-07 14:54:42.769060.769060 lmp.py:767]   Expert 36 |    106 | CPU
DEBUG 01-07 14:54:42.769180.769180 lmp.py:767]   Expert 61 |    111 | CPU
DEBUG 01-07 14:54:42.769108.769108 lmp.py:767]   Expert 42 |    118 | CPU
DEBUG 01-07 14:54:42.769989.769989 lmp.py:767]   Expert 33 |    119 | CPU
DEBUG 01-07 14:54:42.769917.769917 lmp.py:767]   Expert 10 |    123 | CPU
DEBUG 01-07 14:54:42.769845.769845 lmp.py:767]   Expert 11 |    123 | CPU
DEBUG 01-07 14:54:42.769772.769772 lmp.py:767]   Expert 24 |    124 | CPU
DEBUG 01-07 14:54:42.769462.769462 lmp.py:767]   Expert 43 |    124 | CPU
DEBUG 01-07 14:54:42.769389.769389 lmp.py:767]   Expert 56 |    130 | CPU
DEBUG 01-07 14:54:42.769079.769079 lmp.py:767]   Expert 49 |    131 | CPU
DEBUG 01-07 14:54:42.769437.769437 lmp.py:767]   Expert  6 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770795.770795 lmp.py:767]   Expert 51 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770915.770915 lmp.py:767]   Expert 17 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770035.770035 lmp.py:767]   Expert  0 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770916.770916 lmp.py:767]   Expert  5 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770559.770559 lmp.py:767]   Expert 40 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770633.770633 lmp.py:767]   Expert 12 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770375.770375 lmp.py:767]   Expert 55 |    161 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770256.770256 lmp.py:767]   Expert 57 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770138.770138 lmp.py:767]   Expert 59 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770542.770542 lmp.py:767]   Expert 46 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770947.770947 lmp.py:767]   Expert 13 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770113.770113 lmp.py:767]   Expert 26 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770518.770518 lmp.py:767]   Expert 38 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770922.770922 lmp.py:767]   Expert 35 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770088.770088 lmp.py:767]   Expert 58 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770970.770970 lmp.py:767]   Expert 30 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770805.770805 lmp.py:767]   Expert  7 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770739.770739 lmp.py:767]   Expert 50 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770574.770574 lmp.py:767]   Expert 16 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770694.770694 lmp.py:767]   Expert 32 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770099.770099 lmp.py:767]   Expert 15 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770980.770980 lmp.py:767]   Expert 14 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770146.770146 lmp.py:767]   Expert  1 |    214 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770551.770551 lmp.py:767]   Expert  3 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770717.770717 lmp.py:767]   Expert  4 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770552.770552 lmp.py:767]   Expert 39 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770056.770056 lmp.py:767]   Expert 34 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770891.770891 lmp.py:767]   Expert 28 |    246 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770349.770349 lmp.py:767]   Expert 52 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770992.770992 lmp.py:767]   Expert 25 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770158.770158 lmp.py:767]   Expert 22 |    262 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770562.770562 lmp.py:767]   Expert  2 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770729.770729 lmp.py:767]   Expert 41 |    279 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770133.770133 lmp.py:767]   Expert 21 |    282 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770538.770538 lmp.py:767]   Expert 60 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770942.770942 lmp.py:767]   Expert 62 |    291 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770347.770347 lmp.py:767]   Expert 63 |    291 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770751.770751 lmp.py:767]   Expert 29 |    292 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770156.770156 lmp.py:767]   Expert 27 |    302 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770991.770991 lmp.py:767]   Expert 37 |    331 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770064.770064 lmp.py:767]   Expert 53 |    336 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770184.770184 lmp.py:767]   Expert  8 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770066.770066 lmp.py:767]   Expert 19 |    444 | GPU1(cuda:2)
DEBUG 01-07 14:54:42.770709.770709 lmp.py:767]   Expert  9 |    618 | GPU0(cuda:1)
DEBUG 01-07 14:54:42.770160.770160 lmp.py:769] 
DEBUG 01-07 14:54:42.770160.770160 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:42.770326.770326 lmp.py:770]   CPU:   1920 tokens
DEBUG 01-07 14:54:42.770445.770445 lmp.py:774]   cuda:1:   5138 tokens (22 experts)
DEBUG 01-07 14:54:42.770088.770088 lmp.py:774]   cuda:2:   5230 tokens (23 experts)
DEBUG 01-07 14:54:42.770016.770016 lmp.py:775]   Total GPU:  10368 tokens
DEBUG 01-07 14:54:42.770705.770705 lmp.py:776] ============================================================
DEBUG 01-07 14:54:42.770705.770705 lmp.py:776] 
DEBUG 01-07 14:54:42.770355.770355 cuda_h.py:19] end experts_map_get cost 0.0018181800842285156 seconds
DEBUG 01-07 14:54:42.770475.770475 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:42.770443.770443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.771646.771646 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.771112.771112 cuda_h.py:19] end allocate_cuda_memory cost 0.0002396106719970703 seconds
DEBUG 01-07 14:54:42.771585.771585 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.771301.771301 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.771740.771740 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.771773.771773 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b9e20b6-cd0e-4181-a67f-73b03510b7d8
DEBUG 01-07 14:54:42.771568.771568 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.773220.773220 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b9e20b6-cd0e-4181-a67f-73b03510b7d8
DEBUG 01-07 14:54:42.773103.773103 cuda_h.py:19] end load_into_gpu_async cost 0.001994609832763672 seconds
DEBUG 01-07 14:54:42.773137.773137 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.773922.773922 cuda_h.py:19] end restore_tensors2 cost 0.0002732276916503906 seconds
DEBUG 01-07 14:54:42.773691.773691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002828359603881836 seconds
DEBUG 01-07 14:54:42.773355.773355 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.775709.775709 cuda_h.py:19] end restore2model cost 0.0018491744995117188 seconds
DEBUG 01-07 14:54:42.775334.775334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:42.775662.775662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:42.776922.776922 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-07 14:54:42.776812.776812 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:42.776375.776375 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:42.776708.776708 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:42.776556.776556 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fda7ab11-9b9d-464d-bd90-cd06d60bd405
DEBUG 01-07 14:54:42.801349.801349 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:42.803784.803784 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fda7ab11-9b9d-464d-bd90-cd06d60bd405
DEBUG 01-07 14:54:42.803475.803475 cuda_h.py:19] end load_into_gpu_async cost 0.027494430541992188 seconds
DEBUG 01-07 14:54:42.803463.803463 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:42.804652.804652 cuda_h.py:19] end restore_tensors2 cost 0.00028967857360839844 seconds
DEBUG 01-07 14:54:42.804428.804428 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.028307199478149414 seconds
DEBUG 01-07 14:54:42.804568.804568 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:42.806626.806626 cuda_h.py:19] end restore2model cost 0.0018749237060546875 seconds
DEBUG 01-07 14:54:42.806654.806654 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.035187482833862305 seconds
DEBUG 01-07 14:54:42.806449.806449 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:42.806273.806273 lmp.py:816] 
DEBUG 01-07 14:54:42.806273.806273 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:42.806640.806640 cuda_h.py:19] end cpu_experts_submit cost 0.00011515617370605469 seconds
DEBUG 01-07 14:54:42.806457.806457 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:42.815271.815271 mlpmodule.py:749] group tensors cost 0.009334802627563477 s
DEBUG 01-07 14:54:42.818954.818954 mlpmodule.py:787] pad cost 0.0019519329071044922 s
DEBUG 01-07 14:54:42.818178.818178 mlpmodule.py:793] create cpu tensor cost 6.67572021484375e-05 s
DEBUG 01-07 14:54:42.818864.818864 mlpmodule.py:798] move to cpu cost 5.054473876953125e-05 s
DEBUG 01-07 14:54:42.828921.828921 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:42.828112.828112 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:42.829287.829287 mlpmodule.py:818] group_w3 first element: -0.01263427734375
WARNING 01-07 14:54:42.829536.829536 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:42.843754.843754 mlpmodule.py:838] group einsum cost 0.02488875389099121 s
DEBUG 01-07 14:54:42.844177.844177 mlpmodule.py:846] cpy2cputensor cost 0.0004024505615234375 s
DEBUG 01-07 14:54:42.847367.847367 cuda_h.py:19] end wait_cetm_experts cost 0.04078388214111328 seconds
DEBUG 01-07 14:54:42.847954.847954 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:42.848321.848321 cuda_h.py:19] end gpu_sexperts cost 0.0006256103515625 seconds
DEBUG 01-07 14:54:42.848669.848669 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:42.848240.848240 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-07 14:54:42.848010.848010 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:42.848548.848548 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b9e20b6-cd0e-4181-a67f-73b03510b7d8
INFO 01-07 14:54:42.849014.849014 client.py:127] Model loaded
INFO 01-07 14:54:42.849639.849639 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fda7ab11-9b9d-464d-bd90-cd06d60bd405
INFO 01-07 14:54:42.850246.850246 client.py:127] Model loaded
DEBUG 01-07 14:54:42.850917.850917 cuda_h.py:19] end wait_experts_multi_device cost 0.0021333694458007812 seconds
DEBUG 01-07 14:54:42.850879.850879 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:42.850153.850153 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:42.851137.851137 mlpmodule.py:533] gpu group tensors cost 0.0006346702575683594 s
DEBUG 01-07 14:54:42.854141.854141 mlpmodule.py:566] gpu pad cost 0.0024025440216064453 s
DEBUG 01-07 14:54:42.854972.854972 mlpmodule.py:707]  experts func einsum cost 0.048295021057128906 s
DEBUG 01-07 14:54:42.855575.855575 mlpmodule.py:584] gpu group einsum cost 0.0007851123809814453 s
DEBUG 01-07 14:54:42.859383.859383 mlpmodule.py:656] gpu experts func einsum cost 0.007802009582519531 s
DEBUG 01-07 14:54:42.859075.859075 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:42.860602.860602 mlpmodule.py:533] gpu group tensors cost 0.0007598400115966797 s
DEBUG 01-07 14:54:42.862585.862585 mlpmodule.py:566] gpu pad cost 0.001789093017578125 s
DEBUG 01-07 14:54:42.863812.863812 mlpmodule.py:584] gpu group einsum cost 0.0003781318664550781 s
DEBUG 01-07 14:54:42.864286.864286 mlpmodule.py:656] gpu experts func einsum cost 0.004785776138305664 s
DEBUG 01-07 14:54:42.865507.865507 cuda_h.py:19] end gpu_experts_multi_device cost 0.014574766159057617 seconds
DEBUG 01-07 14:54:42.865431.865431 cuda_h.py:19] end layer_moe_generate_multi_device_27 cost 0.09678530693054199 seconds
DEBUG 01-07 14:54:42.865352.865352 lmp.py:194] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-07 14:54:42.865420.865420 cuda_h.py:19] end prefill_layer cost 1.9711320400238037 seconds
DEBUG 01-07 14:54:45.060255.060255 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09525775909423828 s
DEBUG 01-07 14:54:45.425612.425612 cuda_h.py:19] end generate_input_ids cost 0.3634305000305176 seconds
DEBUG 01-07 14:54:45.425102.425102 cuda_h.py:10] start init_cache
DEBUG 01-07 14:54:45.425371.425371 cuda_h.py:19] end init_cache cost 5.888938903808594e-05 seconds
DEBUG 01-07 14:54:47.715637.715637 cuda_h.py:10] start init_weights
DEBUG 01-07 14:54:47.715893.715893 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:47.716012.716012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:47.718926.718926 cuda_h.py:19] end allocate_cuda_memory cost 0.0010912418365478516 seconds
DEBUG 01-07 14:54:47.718154.718154 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:47.718818.718818 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:47.718978.718978 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:47.718966.718966 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 05ad04bd-7269-4a29-a619-a79d35c657ed
DEBUG 01-07 14:54:47.718751.718751 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:47.719248.719248 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 05ad04bd-7269-4a29-a619-a79d35c657ed
DEBUG 01-07 14:54:47.719276.719276 cuda_h.py:19] end load_into_gpu_async cost 0.001636505126953125 seconds
DEBUG 01-07 14:54:47.719834.719834 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:47.720035.720035 cuda_h.py:19] end restore_tensors2 cost 5.364418029785156e-05 seconds
DEBUG 01-07 14:54:47.720122.720122 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003505706787109375 seconds
DEBUG 01-07 14:54:47.720772.720772 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:47.720474.720474 cuda_h.py:19] end restore2model cost 0.00017714500427246094 seconds
INFO 01-07 14:54:47.720329.720329 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 05ad04bd-7269-4a29-a619-a79d35c657ed
INFO 01-07 14:54:47.795843.795843 client.py:127] Model loaded
DEBUG 01-07 14:54:47.795080.795080 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-07 14:54:47.795342.795342 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:47.795776.795776 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:47.796542.796542 cuda_h.py:19] end allocate_cuda_memory cost 0.00036597251892089844 seconds
DEBUG 01-07 14:54:47.796362.796362 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:47.796616.796616 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:47.796507.796507 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:47.796171.796171 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8dba0726-575c-427c-bff0-9c4e35b9e5ba
DEBUG 01-07 14:54:47.797224.797224 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:47.798977.798977 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8dba0726-575c-427c-bff0-9c4e35b9e5ba
DEBUG 01-07 14:54:47.798855.798855 cuda_h.py:19] end load_into_gpu_async cost 0.0017857551574707031 seconds
DEBUG 01-07 14:54:47.798758.798758 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:47.798467.798467 cuda_h.py:19] end restore_tensors2 cost 0.00013637542724609375 seconds
DEBUG 01-07 14:54:47.798728.798728 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002946615219116211 seconds
INFO 01-07 14:54:47.798154.798154 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8dba0726-575c-427c-bff0-9c4e35b9e5ba
INFO 01-07 14:54:47.814516.814516 client.py:127] Model loaded
DEBUG 01-07 14:54:47.815322.815322 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:47.815355.815355 cuda_h.py:19] end restore2model cost 0.0008711814880371094 seconds
DEBUG 01-07 14:54:47.816154.816154 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020327329635620117 seconds
DEBUG 01-07 14:54:47.816607.816607 cuda_h.py:19] end init_weights cost 0.10048437118530273 seconds
DEBUG 01-07 14:54:47.816841.816841 cuda_h.py:10] start copy_emodel
DEBUG 01-07 14:54:48.731544.731544 cuda_h.py:19] end copy_emodel cost 0.915062427520752 seconds
DEBUG 01-07 14:54:48.732465.732465 cuda_h.py:10] start init_hmv
DEBUG 01-07 14:54:48.876608.876608 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-07 14:54:48.877875.877875 cuda_h.py:19] end init_hmv cost 0.14507341384887695 seconds
DEBUG 01-07 14:54:48.877637.877637 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-07 14:54:48.877535.877535 cuda_h.py:19] end init_inputs_tokens cost 0.00028133392333984375 seconds
DEBUG 01-07 14:54:48.877471.877471 cuda_h.py:10] start prefill_layer
DEBUG 01-07 14:54:48.877995.877995 lmp.py:153] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-07 14:54:48.877976.877976 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 14:54:48.877295.877295 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 14:54:48.877807.877807 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.3855438232421875e-05 seconds
DEBUG 01-07 14:54:48.877841.877841 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.532669067382812e-05 seconds
DEBUG 01-07 14:54:48.877199.877199 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:48.878704.878704 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:48.878701.878701 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:48.878961.878961 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.878139.878139 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.879423.879423 cuda_h.py:19] end allocate_cuda_memory cost 0.0004296302795410156 seconds
DEBUG 01-07 14:54:48.879355.879355 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.879558.879558 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.879410.879410 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.879678.879678 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1e77427f-9cdb-48b0-81ec-47d5344d2a2a
DEBUG 01-07 14:54:48.879685.879685 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:48.879576.879576 cuda_h.py:10] start self_attn
INFO 01-07 14:54:48.881337.881337 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1e77427f-9cdb-48b0-81ec-47d5344d2a2a
DEBUG 01-07 14:54:48.881071.881071 cuda_h.py:19] end load_into_gpu_async cost 0.0020608901977539062 seconds
DEBUG 01-07 14:54:48.881961.881961 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.881817.881817 cuda_h.py:19] end restore_tensors2 cost 0.0001494884490966797 seconds
DEBUG 01-07 14:54:48.881629.881629 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033864974975585938 seconds
INFO 01-07 14:54:48.882667.882667 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1e77427f-9cdb-48b0-81ec-47d5344d2a2a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:48.884515.884515 cuda_h.py:19] end self_attn cost 0.004091978073120117 seconds
DEBUG 01-07 14:54:48.884327.884327 cuda_h.py:19] end iln_self_attn_paln cost 0.006560564041137695 seconds
DEBUG 01-07 14:54:48.884680.884680 cuda_h.py:10] start dense_mlp
INFO 01-07 14:54:48.889545.889545 client.py:127] Model loaded
DEBUG 01-07 14:54:48.890615.890615 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.891139.891139 cuda_h.py:19] end restore2model cost 0.0009276866912841797 seconds
DEBUG 01-07 14:54:48.891719.891719 cuda_h.py:19] end sllm_worker_task cost 0.012756109237670898 seconds
DEBUG 01-07 14:54:48.891917.891917 cuda_h.py:19] end dense_mlp cost 0.006663084030151367 seconds
DEBUG 01-07 14:54:48.891279.891279 lmp.py:194] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-07 14:54:48.891473.891473 lmp.py:153] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-07 14:54:48.891407.891407 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 14:54:48.891925.891925 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 14:54:48.891277.891277 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.384185791015625e-05 seconds
DEBUG 01-07 14:54:48.891457.891457 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.435943603515625e-05 seconds
DEBUG 01-07 14:54:48.891961.891961 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:48.891645.891645 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:48.891396.891396 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.891572.891572 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:48.891356.891356 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.892094.892094 cuda_h.py:19] end allocate_cuda_memory cost 0.0002980232238769531 seconds
DEBUG 01-07 14:54:48.892855.892855 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.892176.892176 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.892359.892359 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.892051.892051 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43eb5efa-0673-443a-b0dc-81746fffa4db
DEBUG 01-07 14:54:48.893621.893621 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:48.893687.893687 cuda_h.py:10] start self_attn
INFO 01-07 14:54:48.894757.894757 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43eb5efa-0673-443a-b0dc-81746fffa4db
DEBUG 01-07 14:54:48.894954.894954 cuda_h.py:19] end load_into_gpu_async cost 0.0016922950744628906 seconds
DEBUG 01-07 14:54:48.894037.894037 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.894343.894343 cuda_h.py:19] end restore_tensors2 cost 0.0001308917999267578 seconds
DEBUG 01-07 14:54:48.894777.894777 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029096603393554688 seconds
INFO 01-07 14:54:48.894775.894775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43eb5efa-0673-443a-b0dc-81746fffa4db
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:48.897784.897784 cuda_h.py:19] end self_attn cost 0.0035965442657470703 seconds
DEBUG 01-07 14:54:48.897237.897237 cuda_h.py:19] end iln_self_attn_paln cost 0.00565028190612793 seconds
DEBUG 01-07 14:54:48.897974.897974 cuda_h.py:10] start layer_moe_generate_multi_device_1
DEBUG 01-07 14:54:48.897591.897591 cuda_h.py:10] start gate
DEBUG 01-07 14:54:48.898855.898855 cuda_h.py:19] end gate cost 0.0007219314575195312 seconds
DEBUG 01-07 14:54:48.898307.898307 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:48.898498.898498 lmp.py:744] 
DEBUG 01-07 14:54:48.898498.898498 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:48.898260.898260 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:48.898771.898771 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:48.898229.898229 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:48.898256.898256 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:48.898568.898568 lmp.py:749] 
DEBUG 01-07 14:54:48.898568.898568 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:48.898403.898403 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:48.898722.898722 lmp.py:767]   Expert 25 |     64 | CPU
DEBUG 01-07 14:54:48.898795.898795 lmp.py:767]   Expert 54 |     67 | CPU
DEBUG 01-07 14:54:48.898630.898630 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 14:54:48.898750.898750 lmp.py:767]   Expert 31 |     72 | CPU
DEBUG 01-07 14:54:48.898631.898631 lmp.py:767]   Expert 55 |     72 | CPU
DEBUG 01-07 14:54:48.898228.898228 lmp.py:767]   Expert 62 |     87 | CPU
DEBUG 01-07 14:54:48.898586.898586 lmp.py:767]   Expert 18 |     88 | CPU
DEBUG 01-07 14:54:48.898468.898468 lmp.py:767]   Expert 52 |     98 | CPU
DEBUG 01-07 14:54:48.898541.898541 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 14:54:48.898853.898853 lmp.py:767]   Expert 47 |    104 | CPU
DEBUG 01-07 14:54:48.898933.898933 lmp.py:767]   Expert  0 |    113 | CPU
DEBUG 01-07 14:54:48.898768.898768 lmp.py:767]   Expert 37 |    117 | CPU
DEBUG 01-07 14:54:48.898411.898411 lmp.py:767]   Expert 27 |    121 | CPU
DEBUG 01-07 14:54:48.898915.898915 lmp.py:767]   Expert 32 |    123 | CPU
DEBUG 01-07 14:54:48.899512.899512 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 14:54:48.899254.899254 lmp.py:767]   Expert 44 |    131 | CPU
DEBUG 01-07 14:54:48.899613.899613 lmp.py:767]   Expert 28 |    136 | CPU
DEBUG 01-07 14:54:48.899494.899494 lmp.py:767]   Expert 13 |    138 | CPU
DEBUG 01-07 14:54:48.899375.899375 lmp.py:767]   Expert 58 |    140 | CPU
DEBUG 01-07 14:54:48.899449.899449 lmp.py:767]   Expert 60 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899238.899238 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899788.899788 lmp.py:767]   Expert  1 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899815.899815 lmp.py:767]   Expert 38 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899889.899889 lmp.py:767]   Expert 49 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899247.899247 lmp.py:767]   Expert 51 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899605.899605 lmp.py:767]   Expert 34 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899202.899202 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899435.899435 lmp.py:767]   Expert 36 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899793.899793 lmp.py:767]   Expert 11 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899197.899197 lmp.py:767]   Expert 17 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899363.899363 lmp.py:767]   Expert 59 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899053.899053 lmp.py:767]   Expert 10 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899457.899457 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899054.899054 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899651.899651 lmp.py:767]   Expert 39 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899486.899486 lmp.py:767]   Expert 33 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899844.899844 lmp.py:767]   Expert 12 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899249.899249 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899415.899415 lmp.py:767]   Expert 48 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899342.899342 lmp.py:767]   Expert 15 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899270.899270 lmp.py:767]   Expert 53 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899959.899959 lmp.py:767]   Expert 19 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899126.899126 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899815.899815 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899981.899981 lmp.py:767]   Expert 45 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899386.899386 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899982.899982 lmp.py:767]   Expert  4 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899579.899579 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899937.899937 lmp.py:767]   Expert 42 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899865.899865 lmp.py:767]   Expert 50 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899031.899031 lmp.py:767]   Expert 29 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899197.899197 lmp.py:767]   Expert 56 |    262 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899125.899125 lmp.py:767]   Expert 61 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899814.899814 lmp.py:767]   Expert  8 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899980.899980 lmp.py:767]   Expert 63 |    285 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899908.899908 lmp.py:767]   Expert 46 |    294 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899359.899359 lmp.py:767]   Expert  9 |    300 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899287.899287 lmp.py:767]   Expert  6 |    316 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899976.899976 lmp.py:767]   Expert 16 |    316 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899142.899142 lmp.py:767]   Expert 40 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899739.899739 lmp.py:767]   Expert  7 |    322 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899335.899335 lmp.py:767]   Expert 23 |    325 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899932.899932 lmp.py:767]   Expert 14 |    413 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.899098.899098 lmp.py:767]   Expert 57 |    464 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.899311.899311 lmp.py:769] 
DEBUG 01-07 14:54:48.899311.899311 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:48.899000.899000 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 14:54:48.899120.899120 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 14:54:48.899570.899570 lmp.py:774]   cuda:2:   5088 tokens (22 experts)
DEBUG 01-07 14:54:48.899783.899783 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 14:54:48.899757.899757 lmp.py:776] ============================================================
DEBUG 01-07 14:54:48.899757.899757 lmp.py:776] 
DEBUG 01-07 14:54:48.900645.900645 cuda_h.py:19] end experts_map_get cost 0.0017647743225097656 seconds
DEBUG 01-07 14:54:48.900811.900811 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:48.900634.900634 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.900969.900969 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.900702.900702 cuda_h.py:19] end allocate_cuda_memory cost 0.0002982616424560547 seconds
DEBUG 01-07 14:54:48.900737.900737 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.900254.900254 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.900031.900031 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.900826.900826 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 09d3fcf0-331f-479c-8ed0-c23144582b43
DEBUG 01-07 14:54:48.900792.900792 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:48.902404.902404 client.py:127] Model loaded
DEBUG 01-07 14:54:48.902190.902190 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.903729.903729 cuda_h.py:19] end restore2model cost 0.0009436607360839844 seconds
DEBUG 01-07 14:54:48.903362.903362 cuda_h.py:19] end sllm_worker_task cost 0.011634111404418945 seconds
INFO 01-07 14:54:48.903935.903935 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 09d3fcf0-331f-479c-8ed0-c23144582b43
DEBUG 01-07 14:54:48.903734.903734 cuda_h.py:19] end load_into_gpu_async cost 0.0030517578125 seconds
DEBUG 01-07 14:54:48.903020.903020 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.903592.903592 cuda_h.py:19] end restore_tensors2 cost 0.0002532005310058594 seconds
DEBUG 01-07 14:54:48.904230.904230 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003927707672119141 seconds
DEBUG 01-07 14:54:48.904370.904370 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.906323.906323 cuda_h.py:19] end restore2model cost 0.0019364356994628906 seconds
DEBUG 01-07 14:54:48.906439.906439 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.906998.906998 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.906560.906560 cuda_h.py:19] end allocate_cuda_memory cost 0.0005204677581787109 seconds
DEBUG 01-07 14:54:48.906926.906926 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.906444.906444 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.906345.906345 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.906234.906234 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 746700cd-1810-453a-bb55-4636b6300f7a
DEBUG 01-07 14:54:48.907993.907993 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:48.908530.908530 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 746700cd-1810-453a-bb55-4636b6300f7a
DEBUG 01-07 14:54:48.908267.908267 cuda_h.py:19] end load_into_gpu_async cost 0.0018341541290283203 seconds
DEBUG 01-07 14:54:48.908539.908539 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.908859.908859 cuda_h.py:19] end restore_tensors2 cost 0.0002453327178955078 seconds
DEBUG 01-07 14:54:48.909543.909543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002892017364501953 seconds
DEBUG 01-07 14:54:48.909776.909776 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.910791.910791 cuda_h.py:19] end restore2model cost 0.0018031597137451172 seconds
DEBUG 01-07 14:54:48.910211.910211 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.010911941528320312 seconds
DEBUG 01-07 14:54:48.910576.910576 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:48.911267.911267 lmp.py:816] 
DEBUG 01-07 14:54:48.911267.911267 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:48.911872.911872 cuda_h.py:19] end cpu_experts_submit cost 0.00012302398681640625 seconds
DEBUG 01-07 14:54:48.911237.911237 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:48.925042.925042 mlpmodule.py:749] group tensors cost 0.014456987380981445 s
DEBUG 01-07 14:54:48.928565.928565 mlpmodule.py:787] pad cost 0.0017173290252685547 s
DEBUG 01-07 14:54:48.928100.928100 mlpmodule.py:793] create cpu tensor cost 6.127357482910156e-05 s
DEBUG 01-07 14:54:48.928904.928904 mlpmodule.py:798] move to cpu cost 4.38690185546875e-05 s
DEBUG 01-07 14:54:48.938431.938431 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:48.938689.938689 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:48.938884.938884 mlpmodule.py:818] group_w3 first element: -0.0107421875
WARNING 01-07 14:54:48.938796.938796 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:48.951073.951073 mlpmodule.py:838] group einsum cost 0.02274298667907715 s
DEBUG 01-07 14:54:48.952994.952994 mlpmodule.py:846] cpy2cputensor cost 0.0003895759582519531 s
DEBUG 01-07 14:54:48.955404.955404 cuda_h.py:19] end wait_cetm_experts cost 0.04411172866821289 seconds
DEBUG 01-07 14:54:48.955274.955274 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:48.955246.955246 cuda_h.py:19] end gpu_sexperts cost 0.0004966259002685547 seconds
DEBUG 01-07 14:54:48.956619.956619 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:48.956800.956800 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:48.956172.956172 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:48.956796.956796 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 09d3fcf0-331f-479c-8ed0-c23144582b43
INFO 01-07 14:54:48.957245.957245 client.py:127] Model loaded
INFO 01-07 14:54:48.957354.957354 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 746700cd-1810-453a-bb55-4636b6300f7a
INFO 01-07 14:54:48.957581.957581 client.py:127] Model loaded
DEBUG 01-07 14:54:48.957702.957702 cuda_h.py:19] end wait_experts_multi_device cost 0.001547098159790039 seconds
DEBUG 01-07 14:54:48.957411.957411 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:48.957519.957519 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:48.963716.963716 mlpmodule.py:707]  experts func einsum cost 0.052057743072509766 s
DEBUG 01-07 14:54:48.963496.963496 mlpmodule.py:533] gpu group tensors cost 0.004661083221435547 s
DEBUG 01-07 14:54:48.965308.965308 mlpmodule.py:566] gpu pad cost 0.0014314651489257812 s
DEBUG 01-07 14:54:48.966517.966517 mlpmodule.py:584] gpu group einsum cost 0.001035451889038086 s
DEBUG 01-07 14:54:48.967845.967845 mlpmodule.py:656] gpu experts func einsum cost 0.00896310806274414 s
DEBUG 01-07 14:54:48.968166.968166 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:48.969501.969501 mlpmodule.py:533] gpu group tensors cost 0.0008385181427001953 s
DEBUG 01-07 14:54:48.970797.970797 mlpmodule.py:566] gpu pad cost 0.0010750293731689453 s
DEBUG 01-07 14:54:48.971144.971144 mlpmodule.py:584] gpu group einsum cost 0.000797271728515625 s
DEBUG 01-07 14:54:48.972867.972867 mlpmodule.py:656] gpu experts func einsum cost 0.0044460296630859375 s
DEBUG 01-07 14:54:48.972367.972367 cuda_h.py:19] end gpu_experts_multi_device cost 0.015247821807861328 seconds
DEBUG 01-07 14:54:48.973621.973621 cuda_h.py:19] end layer_moe_generate_multi_device_1 cost 0.07565712928771973 seconds
DEBUG 01-07 14:54:48.973371.973371 lmp.py:194] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-07 14:54:48.973200.973200 lmp.py:153] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-07 14:54:48.973088.973088 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 14:54:48.973321.973321 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 14:54:48.973350.973350 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:48.973907.973907 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 5.841255187988281e-05 seconds
DEBUG 01-07 14:54:48.973026.973026 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:48.973916.973916 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:48.973481.973481 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:48.973960.973960 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.973220.973220 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.973552.973552 cuda_h.py:19] end allocate_cuda_memory cost 0.00017595291137695312 seconds
DEBUG 01-07 14:54:48.974283.974283 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.974900.974900 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.974769.974769 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.974041.974041 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 57f4bfd5-df27-4b73-9e61-c5207a2262fb
DEBUG 01-07 14:54:48.974527.974527 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:48.974145.974145 cuda_h.py:10] start self_attn
INFO 01-07 14:54:48.974585.974585 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 57f4bfd5-df27-4b73-9e61-c5207a2262fb
DEBUG 01-07 14:54:48.975468.975468 cuda_h.py:19] end load_into_gpu_async cost 0.0009450912475585938 seconds
DEBUG 01-07 14:54:48.975502.975502 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.975863.975863 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 14:54:48.975711.975711 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014348030090332031 seconds
INFO 01-07 14:54:48.975064.975064 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 57f4bfd5-df27-4b73-9e61-c5207a2262fb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:48.978735.978735 cuda_h.py:19] end self_attn cost 0.003708362579345703 seconds
DEBUG 01-07 14:54:48.978878.978878 cuda_h.py:19] end iln_self_attn_paln cost 0.005022764205932617 seconds
DEBUG 01-07 14:54:48.978561.978561 cuda_h.py:10] start layer_moe_generate_multi_device_2
DEBUG 01-07 14:54:48.978178.978178 cuda_h.py:10] start gate
DEBUG 01-07 14:54:48.979956.979956 cuda_h.py:19] end gate cost 0.0006453990936279297 seconds
DEBUG 01-07 14:54:48.979070.979070 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:48.979733.979733 lmp.py:744] 
DEBUG 01-07 14:54:48.979733.979733 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:48.979350.979350 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:48.979431.979431 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:48.979173.979173 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:48.979770.979770 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:48.979697.979697 lmp.py:749] 
DEBUG 01-07 14:54:48.979697.979697 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:48.979340.979340 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:48.979944.979944 lmp.py:767]   Expert 58 |     54 | CPU
DEBUG 01-07 14:54:48.979825.979825 lmp.py:767]   Expert 27 |     58 | CPU
DEBUG 01-07 14:54:48.979230.979230 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 14:54:48.979634.979634 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 14:54:48.980516.980516 lmp.py:767]   Expert 24 |     86 | CPU
DEBUG 01-07 14:54:48.980682.980682 lmp.py:767]   Expert  0 |     87 | CPU
DEBUG 01-07 14:54:48.980610.980610 lmp.py:767]   Expert 28 |    102 | CPU
DEBUG 01-07 14:54:48.980537.980537 lmp.py:767]   Expert 34 |    113 | CPU
DEBUG 01-07 14:54:48.980465.980465 lmp.py:767]   Expert 51 |    115 | CPU
DEBUG 01-07 14:54:48.980393.980393 lmp.py:767]   Expert 32 |    119 | CPU
DEBUG 01-07 14:54:48.980082.980082 lmp.py:767]   Expert  9 |    127 | CPU
DEBUG 01-07 14:54:48.980487.980487 lmp.py:767]   Expert 15 |    130 | CPU
DEBUG 01-07 14:54:48.980368.980368 lmp.py:767]   Expert  7 |    134 | CPU
DEBUG 01-07 14:54:48.980773.980773 lmp.py:767]   Expert 23 |    135 | CPU
DEBUG 01-07 14:54:48.980462.980462 lmp.py:767]   Expert 26 |    138 | CPU
DEBUG 01-07 14:54:48.980913.980913 lmp.py:767]   Expert 30 |    143 | CPU
DEBUG 01-07 14:54:48.980602.980602 lmp.py:767]   Expert 45 |    143 | CPU
DEBUG 01-07 14:54:48.980291.980291 lmp.py:767]   Expert 62 |    150 | CPU
DEBUG 01-07 14:54:48.980696.980696 lmp.py:767]   Expert 57 |    153 | CPU
DEBUG 01-07 14:54:48.980293.980293 lmp.py:767]   Expert  1 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980366.980366 lmp.py:767]   Expert 36 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980486.980486 lmp.py:767]   Expert  8 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980890.980890 lmp.py:767]   Expert 25 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980533.980533 lmp.py:767]   Expert 29 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980892.980892 lmp.py:767]   Expert 48 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980118.980118 lmp.py:767]   Expert 49 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980714.980714 lmp.py:767]   Expert  6 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980357.980357 lmp.py:767]   Expert 54 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980239.980239 lmp.py:767]   Expert 35 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980643.980643 lmp.py:767]   Expert 12 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980048.980048 lmp.py:767]   Expert 37 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980691.980691 lmp.py:767]   Expert 13 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980049.980049 lmp.py:767]   Expert 53 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980930.980930 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980573.980573 lmp.py:767]   Expert 60 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980740.980740 lmp.py:767]   Expert 10 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980906.980906 lmp.py:767]   Expert 21 |    195 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980072.980072 lmp.py:767]   Expert 16 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980000.980000 lmp.py:767]   Expert 40 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980643.980643 lmp.py:767]   Expert 43 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980809.980809 lmp.py:767]   Expert 38 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980213.980213 lmp.py:767]   Expert  5 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980095.980095 lmp.py:767]   Expert 44 |    215 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980453.980453 lmp.py:767]   Expert 19 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980857.980857 lmp.py:767]   Expert 50 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980262.980262 lmp.py:767]   Expert 41 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980428.980428 lmp.py:767]   Expert 52 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980356.980356 lmp.py:767]   Expert  4 |    222 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980760.980760 lmp.py:767]   Expert 59 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980688.980688 lmp.py:767]   Expert 55 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980331.980331 lmp.py:767]   Expert 31 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980974.980974 lmp.py:767]   Expert 56 |    243 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980379.980379 lmp.py:767]   Expert 20 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980545.980545 lmp.py:767]   Expert 39 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980711.980711 lmp.py:767]   Expert 22 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980877.980877 lmp.py:767]   Expert  2 |    269 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980282.980282 lmp.py:767]   Expert 47 |    275 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980448.980448 lmp.py:767]   Expert 63 |    277 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.980614.980614 lmp.py:767]   Expert 42 |    303 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.980257.980257 lmp.py:767]   Expert 18 |    313 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.981377.981377 lmp.py:767]   Expert 14 |    321 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.981973.981973 lmp.py:767]   Expert 46 |    367 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.981378.981378 lmp.py:767]   Expert 11 |    391 | GPU1(cuda:2)
DEBUG 01-07 14:54:48.981306.981306 lmp.py:767]   Expert 61 |    460 | GPU0(cuda:1)
DEBUG 01-07 14:54:48.981280.981280 lmp.py:769] 
DEBUG 01-07 14:54:48.981280.981280 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:48.981446.981446 lmp.py:770]   CPU:   2139 tokens
DEBUG 01-07 14:54:48.981566.981566 lmp.py:774]   cuda:1:   4998 tokens (22 experts)
DEBUG 01-07 14:54:48.981732.981732 lmp.py:774]   cuda:2:   5151 tokens (23 experts)
DEBUG 01-07 14:54:48.981421.981421 lmp.py:775]   Total GPU:  10149 tokens
DEBUG 01-07 14:54:48.981587.981587 lmp.py:776] ============================================================
DEBUG 01-07 14:54:48.981587.981587 lmp.py:776] 
DEBUG 01-07 14:54:48.981714.981714 cuda_h.py:19] end experts_map_get cost 0.0017805099487304688 seconds
DEBUG 01-07 14:54:48.981595.981595 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:48.981179.981179 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.981600.981600 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.981901.981901 cuda_h.py:19] end allocate_cuda_memory cost 0.0002605915069580078 seconds
DEBUG 01-07 14:54:48.981135.981135 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.981653.981653 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.981793.981793 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.981966.981966 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6603005b-04b3-4a3a-ab9b-d18b4e879b88
DEBUG 01-07 14:54:48.981209.981209 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:48.982944.982944 client.py:127] Model loaded
DEBUG 01-07 14:54:48.982588.982588 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.982104.982104 cuda_h.py:19] end restore2model cost 0.0003466606140136719 seconds
DEBUG 01-07 14:54:48.982351.982351 cuda_h.py:19] end sllm_worker_task cost 0.00889730453491211 seconds
INFO 01-07 14:54:48.982509.982509 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6603005b-04b3-4a3a-ab9b-d18b4e879b88
DEBUG 01-07 14:54:48.982121.982121 cuda_h.py:19] end load_into_gpu_async cost 0.0011141300201416016 seconds
DEBUG 01-07 14:54:48.982108.982108 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.983244.983244 cuda_h.py:19] end restore_tensors2 cost 0.0002868175506591797 seconds
DEBUG 01-07 14:54:48.983451.983451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019681453704833984 seconds
DEBUG 01-07 14:54:48.983353.983353 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.985177.985177 cuda_h.py:19] end restore2model cost 0.0018427371978759766 seconds
DEBUG 01-07 14:54:48.985624.985624 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:48.985760.985760 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:48.985952.985952 cuda_h.py:19] end allocate_cuda_memory cost 0.0001800060272216797 seconds
DEBUG 01-07 14:54:48.985934.985934 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:48.985021.985021 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:48.985969.985969 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:48.985904.985904 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 531825b2-a034-4246-8a07-40821659b937
DEBUG 01-07 14:54:48.985856.985856 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:48.986571.986571 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 531825b2-a034-4246-8a07-40821659b937
DEBUG 01-07 14:54:48.986446.986446 cuda_h.py:19] end load_into_gpu_async cost 0.0012240409851074219 seconds
DEBUG 01-07 14:54:48.986004.986004 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:48.987948.987948 cuda_h.py:19] end restore_tensors2 cost 0.00028395652770996094 seconds
DEBUG 01-07 14:54:48.987678.987678 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001977205276489258 seconds
DEBUG 01-07 14:54:48.987864.987864 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:48.989260.989260 cuda_h.py:19] end restore2model cost 0.0019080638885498047 seconds
DEBUG 01-07 14:54:48.989872.989872 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00804758071899414 seconds
DEBUG 01-07 14:54:48.989191.989191 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:48.989392.989392 lmp.py:816] 
DEBUG 01-07 14:54:48.989392.989392 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:48.989990.989990 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 14:54:48.989924.989924 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:48.996477.996477 mlpmodule.py:749] group tensors cost 0.0068511962890625 s
DEBUG 01-07 14:54:48.998311.998311 mlpmodule.py:787] pad cost 0.0013060569763183594 s
DEBUG 01-07 14:54:48.998852.998852 mlpmodule.py:793] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-07 14:54:48.998537.998537 mlpmodule.py:798] move to cpu cost 3.790855407714844e-05 s
DEBUG 01-07 14:54:49.007562.007562 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.007382.007382 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.007166.007166 mlpmodule.py:818] group_w3 first element: -0.0380859375
WARNING 01-07 14:54:49.007454.007454 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.023952.023952 mlpmodule.py:838] group einsum cost 0.024979591369628906 s
DEBUG 01-07 14:54:49.024210.024210 mlpmodule.py:846] cpy2cputensor cost 0.00039768218994140625 s
DEBUG 01-07 14:54:49.026818.026818 cuda_h.py:19] end wait_cetm_experts cost 0.03734612464904785 seconds
DEBUG 01-07 14:54:49.026973.026973 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.027455.027455 cuda_h.py:19] end gpu_sexperts cost 0.0004870891571044922 seconds
DEBUG 01-07 14:54:49.027351.027351 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.027724.027724 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.288818359375e-05 seconds
DEBUG 01-07 14:54:49.027950.027950 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.027137.027137 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6603005b-04b3-4a3a-ab9b-d18b4e879b88
INFO 01-07 14:54:49.028311.028311 client.py:127] Model loaded
INFO 01-07 14:54:49.028148.028148 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 531825b2-a034-4246-8a07-40821659b937
INFO 01-07 14:54:49.028134.028134 client.py:127] Model loaded
DEBUG 01-07 14:54:49.028625.028625 cuda_h.py:19] end wait_experts_multi_device cost 0.001344919204711914 seconds
DEBUG 01-07 14:54:49.029520.029520 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.029959.029959 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.033322.033322 mlpmodule.py:707]  experts func einsum cost 0.04437565803527832 s
DEBUG 01-07 14:54:49.034287.034287 mlpmodule.py:533] gpu group tensors cost 0.00458526611328125 s
DEBUG 01-07 14:54:49.035968.035968 mlpmodule.py:566] gpu pad cost 0.0012638568878173828 s
DEBUG 01-07 14:54:49.036313.036313 mlpmodule.py:584] gpu group einsum cost 0.0005433559417724609 s
DEBUG 01-07 14:54:49.038012.038012 mlpmodule.py:656] gpu experts func einsum cost 0.008637666702270508 s
DEBUG 01-07 14:54:49.038499.038499 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.039502.039502 mlpmodule.py:533] gpu group tensors cost 0.0004115104675292969 s
DEBUG 01-07 14:54:49.040626.040626 mlpmodule.py:566] gpu pad cost 0.001047372817993164 s
DEBUG 01-07 14:54:49.040546.040546 mlpmodule.py:584] gpu group einsum cost 0.00033855438232421875 s
DEBUG 01-07 14:54:49.042346.042346 mlpmodule.py:656] gpu experts func einsum cost 0.003457307815551758 s
DEBUG 01-07 14:54:49.042674.042674 cuda_h.py:19] end gpu_experts_multi_device cost 0.013463973999023438 seconds
DEBUG 01-07 14:54:49.042167.042167 cuda_h.py:19] end layer_moe_generate_multi_device_2 cost 0.063934326171875 seconds
DEBUG 01-07 14:54:49.042777.042777 lmp.py:194] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-07 14:54:49.042461.042461 lmp.py:153] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-07 14:54:49.042157.042157 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 14:54:49.042582.042582 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 14:54:49.042418.042418 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 14:54:49.043413.043413 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.6743621826171875e-05 seconds
DEBUG 01-07 14:54:49.043725.043725 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.043064.043064 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.043934.043934 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.043506.043506 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.043033.043033 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.043187.043187 cuda_h.py:19] end allocate_cuda_memory cost 0.00021791458129882812 seconds
DEBUG 01-07 14:54:49.043865.043865 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.043197.043197 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.043305.043305 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.043054.043054 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7f7b42f-f274-41d6-b2bf-33a9f3f052ad
DEBUG 01-07 14:54:49.043686.043686 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.044303.044303 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.044082.044082 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7f7b42f-f274-41d6-b2bf-33a9f3f052ad
DEBUG 01-07 14:54:49.044203.044203 cuda_h.py:19] end load_into_gpu_async cost 0.0009520053863525391 seconds
DEBUG 01-07 14:54:49.044237.044237 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.044836.044836 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-07 14:54:49.044684.044684 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014836788177490234 seconds
INFO 01-07 14:54:49.044421.044421 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7f7b42f-f274-41d6-b2bf-33a9f3f052ad
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.047848.047848 cuda_h.py:19] end self_attn cost 0.0037457942962646484 seconds
DEBUG 01-07 14:54:49.048852.048852 cuda_h.py:19] end iln_self_attn_paln cost 0.005097389221191406 seconds
DEBUG 01-07 14:54:49.048728.048728 cuda_h.py:10] start layer_moe_generate_multi_device_3
DEBUG 01-07 14:54:49.048345.048345 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.048951.048951 cuda_h.py:19] end gate cost 0.0006587505340576172 seconds
DEBUG 01-07 14:54:49.049827.049827 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.049080.049080 lmp.py:744] 
DEBUG 01-07 14:54:49.049080.049080 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.049458.049458 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.049062.049062 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.049327.049327 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.049209.049209 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.049613.049613 lmp.py:749] 
DEBUG 01-07 14:54:49.049613.049613 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.049256.049256 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.049575.049575 lmp.py:767]   Expert  1 |     49 | CPU
DEBUG 01-07 14:54:49.049171.049171 lmp.py:767]   Expert 27 |     62 | CPU
DEBUG 01-07 14:54:49.049053.049053 lmp.py:767]   Expert  7 |     73 | CPU
DEBUG 01-07 14:54:49.049696.049696 lmp.py:767]   Expert 48 |     82 | CPU
DEBUG 01-07 14:54:49.049100.049100 lmp.py:767]   Expert 15 |    101 | CPU
DEBUG 01-07 14:54:49.049790.049790 lmp.py:767]   Expert 30 |    106 | CPU
DEBUG 01-07 14:54:49.049717.049717 lmp.py:767]   Expert 32 |    117 | CPU
DEBUG 01-07 14:54:49.049407.049407 lmp.py:767]   Expert 45 |    118 | CPU
DEBUG 01-07 14:54:49.049096.049096 lmp.py:767]   Expert 61 |    118 | CPU
DEBUG 01-07 14:54:49.049739.049739 lmp.py:767]   Expert 18 |    119 | CPU
DEBUG 01-07 14:54:49.049143.049143 lmp.py:767]   Expert 34 |    130 | CPU
DEBUG 01-07 14:54:49.049071.049071 lmp.py:767]   Expert  5 |    134 | CPU
DEBUG 01-07 14:54:49.049237.049237 lmp.py:767]   Expert 39 |    135 | CPU
DEBUG 01-07 14:54:49.049927.049927 lmp.py:767]   Expert 36 |    136 | CPU
DEBUG 01-07 14:54:49.049854.049854 lmp.py:767]   Expert 11 |    139 | CPU
DEBUG 01-07 14:54:49.049544.049544 lmp.py:767]   Expert 26 |    139 | CPU
DEBUG 01-07 14:54:49.049756.049756 lmp.py:767]   Expert 59 |    142 | CPU
DEBUG 01-07 14:54:49.049399.049399 lmp.py:767]   Expert  6 |    145 | CPU
DEBUG 01-07 14:54:49.049565.049565 lmp.py:767]   Expert 51 |    145 | CPU
DEBUG 01-07 14:54:49.049208.049208 lmp.py:767]   Expert 23 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.049805.049805 lmp.py:767]   Expert  9 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.049448.049448 lmp.py:767]   Expert 49 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.049568.049568 lmp.py:767]   Expert  2 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050211.050211 lmp.py:767]   Expert 50 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050854.050854 lmp.py:767]   Expert 56 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050735.050735 lmp.py:767]   Expert 52 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050616.050616 lmp.py:767]   Expert 35 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050736.050736 lmp.py:767]   Expert 40 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050379.050379 lmp.py:767]   Expert 16 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050784.050784 lmp.py:767]   Expert  4 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050188.050188 lmp.py:767]   Expert 13 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050593.050593 lmp.py:767]   Expert 42 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050997.050997 lmp.py:767]   Expert 37 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050164.050164 lmp.py:767]   Expert 62 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050045.050045 lmp.py:767]   Expert 17 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050926.050926 lmp.py:767]   Expert 38 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050569.050569 lmp.py:767]   Expert 21 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050974.050974 lmp.py:767]   Expert 44 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050140.050140 lmp.py:767]   Expert  3 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050306.050306 lmp.py:767]   Expert 28 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050711.050711 lmp.py:767]   Expert 60 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050877.050877 lmp.py:767]   Expert 10 |    213 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050997.050997 lmp.py:767]   Expert 47 |    213 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050593.050593 lmp.py:767]   Expert 58 |    214 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050475.050475 lmp.py:767]   Expert 55 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050879.050879 lmp.py:767]   Expert 53 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050284.050284 lmp.py:767]   Expert 20 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050927.050927 lmp.py:767]   Expert 57 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050331.050331 lmp.py:767]   Expert 33 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050974.050974 lmp.py:767]   Expert 46 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050379.050379 lmp.py:767]   Expert 31 |    238 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050783.050783 lmp.py:767]   Expert  8 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050188.050188 lmp.py:767]   Expert 24 |    242 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050308.050308 lmp.py:767]   Expert 19 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050189.050189 lmp.py:767]   Expert 14 |    264 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050832.050832 lmp.py:767]   Expert 63 |    272 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050998.050998 lmp.py:767]   Expert 12 |    274 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050403.050403 lmp.py:767]   Expert 29 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050284.050284 lmp.py:767]   Expert 22 |    279 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050689.050689 lmp.py:767]   Expert  0 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050332.050332 lmp.py:767]   Expert 43 |    310 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050498.050498 lmp.py:767]   Expert 54 |    344 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050902.050902 lmp.py:767]   Expert 41 |    383 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.050545.050545 lmp.py:767]   Expert 25 |    410 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.050758.050758 lmp.py:769] 
DEBUG 01-07 14:54:49.050758.050758 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.050924.050924 lmp.py:770]   CPU:   2190 tokens
DEBUG 01-07 14:54:49.050521.050521 lmp.py:774]   cuda:1:   5125 tokens (23 experts)
DEBUG 01-07 14:54:49.050640.050640 lmp.py:774]   cuda:2:   4973 tokens (22 experts)
DEBUG 01-07 14:54:49.050045.050045 lmp.py:775]   Total GPU:  10098 tokens
DEBUG 01-07 14:54:49.050734.050734 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.050734.050734 lmp.py:776] 
DEBUG 01-07 14:54:49.050907.050907 cuda_h.py:19] end experts_map_get cost 0.0017871856689453125 seconds
DEBUG 01-07 14:54:49.050789.050789 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.050850.050850 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.051754.051754 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.051351.051351 cuda_h.py:19] end allocate_cuda_memory cost 0.0001983642578125 seconds
DEBUG 01-07 14:54:49.051844.051844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.051554.051554 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.051078.051078 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.051966.051966 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d85835c-011b-48bc-834b-00330aa060ec
DEBUG 01-07 14:54:49.051269.051269 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.051473.051473 client.py:127] Model loaded
DEBUG 01-07 14:54:49.051779.051779 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.052076.052076 cuda_h.py:19] end restore2model cost 0.00032806396484375 seconds
DEBUG 01-07 14:54:49.052892.052892 cuda_h.py:19] end sllm_worker_task cost 0.008967876434326172 seconds
INFO 01-07 14:54:49.052440.052440 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d85835c-011b-48bc-834b-00330aa060ec
DEBUG 01-07 14:54:49.052681.052681 cuda_h.py:19] end load_into_gpu_async cost 0.0010318756103515625 seconds
DEBUG 01-07 14:54:49.052338.052338 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.052601.052601 cuda_h.py:19] end restore_tensors2 cost 0.000308990478515625 seconds
DEBUG 01-07 14:54:49.052715.052715 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018782615661621094 seconds
DEBUG 01-07 14:54:49.052524.052524 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.054318.054318 cuda_h.py:19] end restore2model cost 0.0019273757934570312 seconds
DEBUG 01-07 14:54:49.054565.054565 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.054794.054794 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.055040.055040 cuda_h.py:19] end allocate_cuda_memory cost 0.00018334388732910156 seconds
DEBUG 01-07 14:54:49.055876.055876 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.055056.055056 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.055196.055196 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.055607.055607 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1877b8f2-2898-4175-a03f-c79a345473a3
DEBUG 01-07 14:54:49.055598.055598 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.056753.056753 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1877b8f2-2898-4175-a03f-c79a345473a3
DEBUG 01-07 14:54:49.056867.056867 cuda_h.py:19] end load_into_gpu_async cost 0.0010876655578613281 seconds
DEBUG 01-07 14:54:49.056722.056722 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.056301.056301 cuda_h.py:19] end restore_tensors2 cost 0.00026035308837890625 seconds
DEBUG 01-07 14:54:49.056363.056363 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00182342529296875 seconds
DEBUG 01-07 14:54:49.056880.056880 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.058285.058285 cuda_h.py:19] end restore2model cost 0.0017812252044677734 seconds
DEBUG 01-07 14:54:49.058644.058644 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007736921310424805 seconds
DEBUG 01-07 14:54:49.058009.058009 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.058972.058972 lmp.py:816] 
DEBUG 01-07 14:54:49.058972.058972 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.058954.058954 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-07 14:54:49.058174.058174 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.065234.065234 mlpmodule.py:749] group tensors cost 0.006224155426025391 s
DEBUG 01-07 14:54:49.067163.067163 mlpmodule.py:787] pad cost 0.001455068588256836 s
DEBUG 01-07 14:54:49.067531.067531 mlpmodule.py:793] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-07 14:54:49.067003.067003 mlpmodule.py:798] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-07 14:54:49.076960.076960 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.076429.076429 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.076736.076736 mlpmodule.py:818] group_w3 first element: -0.054931640625
WARNING 01-07 14:54:49.076502.076502 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.090498.090498 mlpmodule.py:838] group einsum cost 0.023014307022094727 s
DEBUG 01-07 14:54:49.091937.091937 mlpmodule.py:846] cpy2cputensor cost 0.0004706382751464844 s
DEBUG 01-07 14:54:49.093706.093706 cuda_h.py:19] end wait_cetm_experts cost 0.03504014015197754 seconds
DEBUG 01-07 14:54:49.093464.093464 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.094358.094358 cuda_h.py:19] end gpu_sexperts cost 0.0005326271057128906 seconds
DEBUG 01-07 14:54:49.094460.094460 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.094986.094986 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-07 14:54:49.094603.094603 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.094796.094796 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d85835c-011b-48bc-834b-00330aa060ec
INFO 01-07 14:54:49.097191.097191 client.py:127] Model loaded
INFO 01-07 14:54:49.097603.097603 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1877b8f2-2898-4175-a03f-c79a345473a3
INFO 01-07 14:54:49.097133.097133 client.py:127] Model loaded
DEBUG 01-07 14:54:49.097115.097115 cuda_h.py:19] end wait_experts_multi_device cost 0.002801179885864258 seconds
DEBUG 01-07 14:54:49.097295.097295 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.097442.097442 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:49.098999.098999 mlpmodule.py:533] gpu group tensors cost 0.0004253387451171875 s
DEBUG 01-07 14:54:49.099744.099744 mlpmodule.py:566] gpu pad cost 0.0010554790496826172 s
DEBUG 01-07 14:54:49.100321.100321 mlpmodule.py:584] gpu group einsum cost 0.00054168701171875 s
DEBUG 01-07 14:54:49.100863.100863 mlpmodule.py:707]  experts func einsum cost 0.04203343391418457 s
DEBUG 01-07 14:54:49.102999.102999 mlpmodule.py:656] gpu experts func einsum cost 0.004004955291748047 s
DEBUG 01-07 14:54:49.102359.102359 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:49.103725.103725 mlpmodule.py:533] gpu group tensors cost 0.00039005279541015625 s
DEBUG 01-07 14:54:49.104253.104253 mlpmodule.py:566] gpu pad cost 0.0010724067687988281 s
DEBUG 01-07 14:54:49.105472.105472 mlpmodule.py:584] gpu group einsum cost 0.0007348060607910156 s
DEBUG 01-07 14:54:49.106519.106519 mlpmodule.py:656] gpu experts func einsum cost 0.00410008430480957 s
DEBUG 01-07 14:54:49.106303.106303 cuda_h.py:19] end gpu_experts_multi_device cost 0.009320735931396484 seconds
DEBUG 01-07 14:54:49.107332.107332 cuda_h.py:19] end layer_moe_generate_multi_device_3 cost 0.05876588821411133 seconds
DEBUG 01-07 14:54:49.107943.107943 lmp.py:194] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-07 14:54:49.107726.107726 lmp.py:153] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-07 14:54:49.107946.107946 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 14:54:49.107748.107748 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 14:54:49.107114.107114 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0279159545898438e-05 seconds
DEBUG 01-07 14:54:49.107910.107910 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.984306335449219e-05 seconds
DEBUG 01-07 14:54:49.107029.107029 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.107541.107541 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.107583.107583 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.107321.107321 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.107012.107012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.108789.108789 cuda_h.py:19] end allocate_cuda_memory cost 0.00022220611572265625 seconds
DEBUG 01-07 14:54:49.108321.108321 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.108653.108653 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.108569.108569 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.108603.108603 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 797869e4-d2dd-4050-9899-767a173d0d1b
DEBUG 01-07 14:54:49.108373.108373 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.108646.108646 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.108005.108005 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 797869e4-d2dd-4050-9899-767a173d0d1b
DEBUG 01-07 14:54:49.109126.109126 cuda_h.py:19] end load_into_gpu_async cost 0.0008740425109863281 seconds
DEBUG 01-07 14:54:49.109876.109876 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.109952.109952 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 14:54:49.109515.109515 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014083385467529297 seconds
INFO 01-07 14:54:49.109822.109822 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 797869e4-d2dd-4050-9899-767a173d0d1b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.112720.112720 cuda_h.py:19] end self_attn cost 0.0037119388580322266 seconds
DEBUG 01-07 14:54:49.112049.112049 cuda_h.py:19] end iln_self_attn_paln cost 0.005110502243041992 seconds
DEBUG 01-07 14:54:49.112594.112594 cuda_h.py:10] start layer_moe_generate_multi_device_4
DEBUG 01-07 14:54:49.112211.112211 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.113764.113764 cuda_h.py:19] end gate cost 0.0006530284881591797 seconds
DEBUG 01-07 14:54:49.113832.113832 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.113455.113455 lmp.py:744] 
DEBUG 01-07 14:54:49.113455.113455 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.113311.113311 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.113391.113391 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.113518.113518 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.113114.113114 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.114519.114519 lmp.py:749] 
DEBUG 01-07 14:54:49.114519.114519 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.114162.114162 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.114004.114004 lmp.py:767]   Expert 14 |     64 | CPU
DEBUG 01-07 14:54:49.114362.114362 lmp.py:767]   Expert 57 |     73 | CPU
DEBUG 01-07 14:54:49.114766.114766 lmp.py:767]   Expert 13 |     75 | CPU
DEBUG 01-07 14:54:49.114694.114694 lmp.py:767]   Expert 26 |     80 | CPU
DEBUG 01-07 14:54:49.114099.114099 lmp.py:767]   Expert 31 |     86 | CPU
DEBUG 01-07 14:54:49.114503.114503 lmp.py:767]   Expert 11 |     90 | CPU
DEBUG 01-07 14:54:49.114054.114054 lmp.py:767]   Expert 54 |     92 | CPU
DEBUG 01-07 14:54:49.114220.114220 lmp.py:767]   Expert 45 |     98 | CPU
DEBUG 01-07 14:54:49.114909.114909 lmp.py:767]   Expert 58 |     99 | CPU
DEBUG 01-07 14:54:49.114598.114598 lmp.py:767]   Expert 51 |    105 | CPU
DEBUG 01-07 14:54:49.114288.114288 lmp.py:767]   Expert 30 |    109 | CPU
DEBUG 01-07 14:54:49.114931.114931 lmp.py:767]   Expert 10 |    110 | CPU
DEBUG 01-07 14:54:49.114527.114527 lmp.py:767]   Expert 36 |    116 | CPU
DEBUG 01-07 14:54:49.114693.114693 lmp.py:767]   Expert 32 |    121 | CPU
DEBUG 01-07 14:54:49.114383.114383 lmp.py:767]   Expert 20 |    132 | CPU
DEBUG 01-07 14:54:49.114072.114072 lmp.py:767]   Expert  8 |    134 | CPU
DEBUG 01-07 14:54:49.114761.114761 lmp.py:767]   Expert  4 |    139 | CPU
DEBUG 01-07 14:54:49.114358.114358 lmp.py:767]   Expert 61 |    139 | CPU
DEBUG 01-07 14:54:49.114524.114524 lmp.py:767]   Expert 53 |    140 | CPU
DEBUG 01-07 14:54:49.114405.114405 lmp.py:767]   Expert 63 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114241.114241 lmp.py:767]   Expert 34 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114599.114599 lmp.py:767]   Expert 47 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114911.114911 lmp.py:767]   Expert 16 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114507.114507 lmp.py:767]   Expert 28 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114912.114912 lmp.py:767]   Expert 60 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114555.114555 lmp.py:767]   Expert 42 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114198.114198 lmp.py:767]   Expert 17 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114556.114556 lmp.py:767]   Expert 29 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114437.114437 lmp.py:767]   Expert 44 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114511.114511 lmp.py:767]   Expert 27 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114154.114154 lmp.py:767]   Expert 41 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114558.114558 lmp.py:767]   Expert  7 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114725.114725 lmp.py:767]   Expert 48 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114129.114129 lmp.py:767]   Expert  9 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114203.114203 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114561.114561 lmp.py:767]   Expert 56 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114965.114965 lmp.py:767]   Expert  3 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114370.114370 lmp.py:767]   Expert 15 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114013.114013 lmp.py:767]   Expert 24 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114656.114656 lmp.py:767]   Expert  0 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114206.114206 lmp.py:767]   Expert 18 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114849.114849 lmp.py:767]   Expert 55 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114254.114254 lmp.py:767]   Expert 38 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114374.114374 lmp.py:767]   Expert 40 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114778.114778 lmp.py:767]   Expert 23 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114090.114090 lmp.py:767]   Expert 22 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114733.114733 lmp.py:767]   Expert  6 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114138.114138 lmp.py:767]   Expert 37 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114304.114304 lmp.py:767]   Expert 46 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114708.114708 lmp.py:767]   Expert 19 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114874.114874 lmp.py:767]   Expert 39 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114041.114041 lmp.py:767]   Expert 25 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.114399.114399 lmp.py:767]   Expert 12 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.114949.114949 lmp.py:767]   Expert 50 |    264 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.115115.115115 lmp.py:767]   Expert 62 |    272 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.115520.115520 lmp.py:767]   Expert 21 |    281 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.115448.115448 lmp.py:767]   Expert 35 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.115375.115375 lmp.py:767]   Expert 49 |    293 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.115733.115733 lmp.py:767]   Expert 33 |    299 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.115092.115092 lmp.py:767]   Expert 52 |    301 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.115735.115735 lmp.py:767]   Expert  1 |    348 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.115378.115378 lmp.py:767]   Expert  5 |    380 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.115544.115544 lmp.py:767]   Expert 43 |    438 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.115472.115472 lmp.py:767]   Expert 59 |    583 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.115830.115830 lmp.py:769] 
DEBUG 01-07 14:54:49.115830.115830 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.115234.115234 lmp.py:770]   CPU:   2002 tokens
DEBUG 01-07 14:54:49.115116.115116 lmp.py:774]   cuda:1:   5087 tokens (22 experts)
DEBUG 01-07 14:54:49.115759.115759 lmp.py:774]   cuda:2:   5199 tokens (23 experts)
DEBUG 01-07 14:54:49.115640.115640 lmp.py:775]   Total GPU:  10286 tokens
DEBUG 01-07 14:54:49.115329.115329 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.115329.115329 lmp.py:776] 
DEBUG 01-07 14:54:49.115363.115363 cuda_h.py:19] end experts_map_get cost 0.001802682876586914 seconds
DEBUG 01-07 14:54:49.115722.115722 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.115544.115544 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.115786.115786 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.115960.115960 cuda_h.py:19] end allocate_cuda_memory cost 0.00019884109497070312 seconds
DEBUG 01-07 14:54:49.115909.115909 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.115188.115188 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.115759.115759 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.115124.115124 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7b0eda62-3b74-4537-8db4-24adb7593d1e
DEBUG 01-07 14:54:49.116427.116427 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.116346.116346 client.py:127] Model loaded
DEBUG 01-07 14:54:49.116652.116652 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.116625.116625 cuda_h.py:19] end restore2model cost 0.0003333091735839844 seconds
DEBUG 01-07 14:54:49.116394.116394 cuda_h.py:19] end sllm_worker_task cost 0.008909225463867188 seconds
INFO 01-07 14:54:49.116457.116457 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7b0eda62-3b74-4537-8db4-24adb7593d1e
DEBUG 01-07 14:54:49.116445.116445 cuda_h.py:19] end load_into_gpu_async cost 0.0009593963623046875 seconds
DEBUG 01-07 14:54:49.116195.116195 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.117504.117504 cuda_h.py:19] end restore_tensors2 cost 0.0003066062927246094 seconds
DEBUG 01-07 14:54:49.117340.117340 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001786947250366211 seconds
DEBUG 01-07 14:54:49.117388.117388 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.119205.119205 cuda_h.py:19] end restore2model cost 0.0018353462219238281 seconds
DEBUG 01-07 14:54:49.119777.119777 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.119681.119681 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.119385.119385 cuda_h.py:19] end allocate_cuda_memory cost 0.0002040863037109375 seconds
DEBUG 01-07 14:54:49.119228.119228 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.119553.119553 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.119170.119170 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.119012.119012 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9964a112-e035-44a0-8252-e0e9c06d3238
DEBUG 01-07 14:54:49.119494.119494 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.120106.120106 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9964a112-e035-44a0-8252-e0e9c06d3238
DEBUG 01-07 14:54:49.120969.120969 cuda_h.py:19] end load_into_gpu_async cost 0.0011446475982666016 seconds
DEBUG 01-07 14:54:49.120116.120116 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.121513.121513 cuda_h.py:19] end restore_tensors2 cost 0.00036406517028808594 seconds
DEBUG 01-07 14:54:49.121787.121787 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002048492431640625 seconds
DEBUG 01-07 14:54:49.121987.121987 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.123600.123600 cuda_h.py:19] end restore2model cost 0.002452373504638672 seconds
DEBUG 01-07 14:54:49.123689.123689 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008484840393066406 seconds
DEBUG 01-07 14:54:49.123683.123683 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.123289.123289 lmp.py:816] 
DEBUG 01-07 14:54:49.123289.123289 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.124814.124814 cuda_h.py:19] end cpu_experts_submit cost 0.0001354217529296875 seconds
DEBUG 01-07 14:54:49.124855.124855 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.129816.129816 mlpmodule.py:749] group tensors cost 0.005629539489746094 s
DEBUG 01-07 14:54:49.132775.132775 mlpmodule.py:787] pad cost 0.00173187255859375 s
DEBUG 01-07 14:54:49.132337.132337 mlpmodule.py:793] create cpu tensor cost 6.246566772460938e-05 s
DEBUG 01-07 14:54:49.132699.132699 mlpmodule.py:798] move to cpu cost 5.078315734863281e-05 s
DEBUG 01-07 14:54:49.140686.140686 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.141300.141300 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.141468.141468 mlpmodule.py:818] group_w3 first element: 0.0086669921875
WARNING 01-07 14:54:49.141062.141062 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.155149.155149 mlpmodule.py:838] group einsum cost 0.022429227828979492 s
DEBUG 01-07 14:54:49.155653.155653 mlpmodule.py:846] cpy2cputensor cost 0.00045013427734375 s
DEBUG 01-07 14:54:49.158572.158572 cuda_h.py:19] end wait_cetm_experts cost 0.034010887145996094 seconds
DEBUG 01-07 14:54:49.158939.158939 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.158950.158950 cuda_h.py:19] end gpu_sexperts cost 0.0004904270172119141 seconds
DEBUG 01-07 14:54:49.158516.158516 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.158558.158558 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 14:54:49.158976.158976 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.158162.158162 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7b0eda62-3b74-4537-8db4-24adb7593d1e
INFO 01-07 14:54:49.159837.159837 client.py:127] Model loaded
INFO 01-07 14:54:49.159434.159434 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9964a112-e035-44a0-8252-e0e9c06d3238
INFO 01-07 14:54:49.160688.160688 client.py:127] Model loaded
DEBUG 01-07 14:54:49.160803.160803 cuda_h.py:19] end wait_experts_multi_device cost 0.0015270709991455078 seconds
DEBUG 01-07 14:54:49.160128.160128 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.160997.160997 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.161507.161507 mlpmodule.py:533] gpu group tensors cost 0.0005095005035400391 s
DEBUG 01-07 14:54:49.163274.163274 mlpmodule.py:566] gpu pad cost 0.0012736320495605469 s
DEBUG 01-07 14:54:49.163979.163979 mlpmodule.py:584] gpu group einsum cost 0.00042438507080078125 s
DEBUG 01-07 14:54:49.165275.165275 mlpmodule.py:656] gpu experts func einsum cost 0.004273653030395508 s
DEBUG 01-07 14:54:49.165940.165940 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.166269.166269 mlpmodule.py:707]  experts func einsum cost 0.04190397262573242 s
DEBUG 01-07 14:54:49.166845.166845 mlpmodule.py:533] gpu group tensors cost 0.00046133995056152344 s
DEBUG 01-07 14:54:49.167392.167392 mlpmodule.py:566] gpu pad cost 0.0012469291687011719 s
DEBUG 01-07 14:54:49.168303.168303 mlpmodule.py:584] gpu group einsum cost 0.0008029937744140625 s
DEBUG 01-07 14:54:49.170034.170034 mlpmodule.py:656] gpu experts func einsum cost 0.00471186637878418 s
DEBUG 01-07 14:54:49.171661.171661 cuda_h.py:19] end gpu_experts_multi_device cost 0.010545969009399414 seconds
DEBUG 01-07 14:54:49.171300.171300 cuda_h.py:19] end layer_moe_generate_multi_device_4 cost 0.0584256649017334 seconds
DEBUG 01-07 14:54:49.171188.171188 lmp.py:194] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-07 14:54:49.171918.171918 lmp.py:153] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-07 14:54:49.171614.171614 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 14:54:49.171655.171655 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 14:54:49.171107.171107 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 14:54:49.171287.171287 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.793571472167969e-05 seconds
DEBUG 01-07 14:54:49.171599.171599 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.171310.171310 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.171775.171775 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.171632.171632 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.171793.171793 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.172616.172616 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-07 14:54:49.172632.172632 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.172441.172441 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.172701.172701 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.172165.172165 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b0a99410-3bb8-471d-97cb-3208f96a0d0c
DEBUG 01-07 14:54:49.172559.172559 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.172701.172701 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.173628.173628 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b0a99410-3bb8-471d-97cb-3208f96a0d0c
DEBUG 01-07 14:54:49.173749.173749 cuda_h.py:19] end load_into_gpu_async cost 0.0008938312530517578 seconds
DEBUG 01-07 14:54:49.173829.173829 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.173713.173713 cuda_h.py:19] end restore_tensors2 cost 6.508827209472656e-05 seconds
DEBUG 01-07 14:54:49.173039.173039 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014302730560302734 seconds
INFO 01-07 14:54:49.173775.173775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b0a99410-3bb8-471d-97cb-3208f96a0d0c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.176063.176063 cuda_h.py:19] end self_attn cost 0.003646373748779297 seconds
DEBUG 01-07 14:54:49.176724.176724 cuda_h.py:19] end iln_self_attn_paln cost 0.0050830841064453125 seconds
DEBUG 01-07 14:54:49.176169.176169 cuda_h.py:10] start layer_moe_generate_multi_device_5
DEBUG 01-07 14:54:49.176309.176309 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.177610.177610 cuda_h.py:19] end gate cost 0.0006442070007324219 seconds
DEBUG 01-07 14:54:49.177201.177201 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.177348.177348 lmp.py:744] 
DEBUG 01-07 14:54:49.177348.177348 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.177726.177726 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.177568.177568 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.178595.178595 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.178954.178954 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.178643.178643 lmp.py:749] 
DEBUG 01-07 14:54:49.178643.178643 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.178286.178286 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.178128.178128 lmp.py:767]   Expert 34 |     22 | CPU
DEBUG 01-07 14:54:49.178486.178486 lmp.py:767]   Expert 45 |     64 | CPU
DEBUG 01-07 14:54:49.178891.178891 lmp.py:767]   Expert 57 |     73 | CPU
DEBUG 01-07 14:54:49.178295.178295 lmp.py:767]   Expert 22 |     78 | CPU
DEBUG 01-07 14:54:49.178461.178461 lmp.py:767]   Expert 15 |     96 | CPU
DEBUG 01-07 14:54:49.178912.178912 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 14:54:49.178601.178601 lmp.py:767]   Expert  4 |     97 | CPU
DEBUG 01-07 14:54:49.178052.178052 lmp.py:767]   Expert 28 |    110 | CPU
DEBUG 01-07 14:54:49.178980.178980 lmp.py:767]   Expert 60 |    112 | CPU
DEBUG 01-07 14:54:49.178954.178954 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 14:54:49.178359.178359 lmp.py:767]   Expert 36 |    123 | CPU
DEBUG 01-07 14:54:49.178525.178525 lmp.py:767]   Expert 52 |    125 | CPU
DEBUG 01-07 14:54:49.178691.178691 lmp.py:767]   Expert 16 |    126 | CPU
DEBUG 01-07 14:54:49.178619.178619 lmp.py:767]   Expert 14 |    127 | CPU
DEBUG 01-07 14:54:49.178070.178070 lmp.py:767]   Expert 25 |    129 | CPU
DEBUG 01-07 14:54:49.178997.178997 lmp.py:767]   Expert 12 |    130 | CPU
DEBUG 01-07 14:54:49.178925.178925 lmp.py:767]   Expert  2 |    135 | CPU
DEBUG 01-07 14:54:49.178137.178137 lmp.py:767]   Expert  8 |    143 | CPU
DEBUG 01-07 14:54:49.178304.178304 lmp.py:767]   Expert  5 |    144 | CPU
DEBUG 01-07 14:54:49.178900.178900 lmp.py:767]   Expert 35 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178258.178258 lmp.py:767]   Expert 23 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178140.178140 lmp.py:767]   Expert 39 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178783.178783 lmp.py:767]   Expert 30 |    157 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178426.178426 lmp.py:767]   Expert 61 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178069.178069 lmp.py:767]   Expert  0 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178473.178473 lmp.py:767]   Expert  3 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178878.178878 lmp.py:767]   Expert 42 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178521.178521 lmp.py:767]   Expert 46 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178879.178879 lmp.py:767]   Expert 13 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178760.178760 lmp.py:767]   Expert 44 |    175 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178165.178165 lmp.py:767]   Expert  9 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178808.178808 lmp.py:767]   Expert 31 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178213.178213 lmp.py:767]   Expert 41 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178617.178617 lmp.py:767]   Expert 43 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178022.178022 lmp.py:767]   Expert 62 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178141.178141 lmp.py:767]   Expert 51 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178500.178500 lmp.py:767]   Expert 18 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178381.178381 lmp.py:767]   Expert 50 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178024.178024 lmp.py:767]   Expert 26 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178429.178429 lmp.py:767]   Expert 49 |    195 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178833.178833 lmp.py:767]   Expert 27 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178761.178761 lmp.py:767]   Expert 47 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178881.178881 lmp.py:767]   Expert 11 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178762.178762 lmp.py:767]   Expert 19 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178167.178167 lmp.py:767]   Expert 20 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178571.178571 lmp.py:767]   Expert 63 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178976.178976 lmp.py:767]   Expert 55 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178142.178142 lmp.py:767]   Expert 56 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178308.178308 lmp.py:767]   Expert 38 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178713.178713 lmp.py:767]   Expert 48 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178117.178117 lmp.py:767]   Expert  1 |    235 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.178237.178237 lmp.py:767]   Expert 10 |    238 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.178118.178118 lmp.py:767]   Expert 54 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179761.179761 lmp.py:767]   Expert  7 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179927.179927 lmp.py:767]   Expert 21 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.179332.179332 lmp.py:767]   Expert 33 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.179498.179498 lmp.py:767]   Expert 29 |    261 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179903.179903 lmp.py:767]   Expert 40 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.179023.179023 lmp.py:767]   Expert 24 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179666.179666 lmp.py:767]   Expert 59 |    300 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.179308.179308 lmp.py:767]   Expert 37 |    336 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179475.179475 lmp.py:767]   Expert 58 |    369 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179879.179879 lmp.py:767]   Expert  6 |    384 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.179045.179045 lmp.py:767]   Expert 53 |    860 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.179258.179258 lmp.py:769] 
DEBUG 01-07 14:54:49.179258.179258 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.179662.179662 lmp.py:770]   CPU:   2044 tokens
DEBUG 01-07 14:54:49.179497.179497 lmp.py:774]   cuda:1:   5125 tokens (22 experts)
DEBUG 01-07 14:54:49.179094.179094 lmp.py:774]   cuda:2:   5119 tokens (23 experts)
DEBUG 01-07 14:54:49.179260.179260 lmp.py:775]   Total GPU:  10244 tokens
DEBUG 01-07 14:54:49.179711.179711 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.179711.179711 lmp.py:776] 
DEBUG 01-07 14:54:49.179122.179122 cuda_h.py:19] end experts_map_get cost 0.0017747879028320312 seconds
DEBUG 01-07 14:54:49.179481.179481 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.179111.179111 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.179823.179823 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.179435.179435 cuda_h.py:19] end allocate_cuda_memory cost 0.0002434253692626953 seconds
DEBUG 01-07 14:54:49.179811.179811 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.179759.179759 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.179760.179760 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.179648.179648 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3ef88a31-2a4b-4920-b85d-7b6c08df931f
DEBUG 01-07 14:54:49.180805.180805 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.180526.180526 client.py:127] Model loaded
DEBUG 01-07 14:54:49.180786.180786 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.180766.180766 cuda_h.py:19] end restore2model cost 0.0003712177276611328 seconds
DEBUG 01-07 14:54:49.180119.180119 cuda_h.py:19] end sllm_worker_task cost 0.009002685546875 seconds
INFO 01-07 14:54:49.180294.180294 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3ef88a31-2a4b-4920-b85d-7b6c08df931f
DEBUG 01-07 14:54:49.180283.180283 cuda_h.py:19] end load_into_gpu_async cost 0.0010161399841308594 seconds
DEBUG 01-07 14:54:49.180224.180224 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.181196.181196 cuda_h.py:19] end restore_tensors2 cost 0.00030541419982910156 seconds
DEBUG 01-07 14:54:49.181210.181210 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001947164535522461 seconds
DEBUG 01-07 14:54:49.181258.181258 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.183928.183928 cuda_h.py:19] end restore2model cost 0.0018002986907958984 seconds
DEBUG 01-07 14:54:49.183785.183785 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.183159.183159 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.183333.183333 cuda_h.py:19] end allocate_cuda_memory cost 0.0002014636993408203 seconds
DEBUG 01-07 14:54:49.183454.183454 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.183587.183587 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.183058.183058 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.183946.183946 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2aba97a6-8ad5-4548-a765-e3b39ec181c0
DEBUG 01-07 14:54:49.183560.183560 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.184471.184471 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2aba97a6-8ad5-4548-a765-e3b39ec181c0
DEBUG 01-07 14:54:49.184870.184870 cuda_h.py:19] end load_into_gpu_async cost 0.0011191368103027344 seconds
DEBUG 01-07 14:54:49.184665.184665 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.185815.185815 cuda_h.py:19] end restore_tensors2 cost 0.0002963542938232422 seconds
DEBUG 01-07 14:54:49.185783.185783 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019032955169677734 seconds
DEBUG 01-07 14:54:49.185255.185255 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.187020.187020 cuda_h.py:19] end restore2model cost 0.0018715858459472656 seconds
DEBUG 01-07 14:54:49.187618.187618 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00783991813659668 seconds
DEBUG 01-07 14:54:49.187221.187221 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.187800.187800 lmp.py:816] 
DEBUG 01-07 14:54:49.187800.187800 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.187875.187875 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-07 14:54:49.187001.187001 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.193548.193548 mlpmodule.py:749] group tensors cost 0.006476402282714844 s
DEBUG 01-07 14:54:49.195341.195341 mlpmodule.py:787] pad cost 0.001276254653930664 s
DEBUG 01-07 14:54:49.196829.196829 mlpmodule.py:793] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-07 14:54:49.196984.196984 mlpmodule.py:798] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-07 14:54:49.204304.204304 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.204456.204456 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.204029.204029 mlpmodule.py:818] group_w3 first element: -0.010498046875
WARNING 01-07 14:54:49.204821.204821 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.218425.218425 mlpmodule.py:838] group einsum cost 0.022782325744628906 s
DEBUG 01-07 14:54:49.219494.219494 mlpmodule.py:846] cpy2cputensor cost 0.0004792213439941406 s
DEBUG 01-07 14:54:49.222495.222495 cuda_h.py:19] end wait_cetm_experts cost 0.03525352478027344 seconds
DEBUG 01-07 14:54:49.222485.222485 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.223595.223595 cuda_h.py:19] end gpu_sexperts cost 0.0004954338073730469 seconds
DEBUG 01-07 14:54:49.223538.223538 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.223812.223812 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.193450927734375e-05 seconds
DEBUG 01-07 14:54:49.223038.223038 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.223509.223509 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3ef88a31-2a4b-4920-b85d-7b6c08df931f
INFO 01-07 14:54:49.224036.224036 client.py:127] Model loaded
INFO 01-07 14:54:49.224250.224250 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2aba97a6-8ad5-4548-a765-e3b39ec181c0
INFO 01-07 14:54:49.224211.224211 client.py:127] Model loaded
DEBUG 01-07 14:54:49.224041.224041 cuda_h.py:19] end wait_experts_multi_device cost 0.0014460086822509766 seconds
DEBUG 01-07 14:54:49.224459.224459 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.224705.224705 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.226891.226891 mlpmodule.py:533] gpu group tensors cost 0.0005195140838623047 s
DEBUG 01-07 14:54:49.227858.227858 mlpmodule.py:566] gpu pad cost 0.0013184547424316406 s
DEBUG 01-07 14:54:49.228416.228416 mlpmodule.py:584] gpu group einsum cost 0.0005745887756347656 s
DEBUG 01-07 14:54:49.230092.230092 mlpmodule.py:656] gpu experts func einsum cost 0.0047414302825927734 s
DEBUG 01-07 14:54:49.230348.230348 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.231443.231443 mlpmodule.py:707]  experts func einsum cost 0.04391837120056152 s
DEBUG 01-07 14:54:49.231826.231826 mlpmodule.py:533] gpu group tensors cost 0.0005481243133544922 s
DEBUG 01-07 14:54:49.233973.233973 mlpmodule.py:566] gpu pad cost 0.0015437602996826172 s
DEBUG 01-07 14:54:49.234054.234054 mlpmodule.py:584] gpu group einsum cost 0.0007495880126953125 s
DEBUG 01-07 14:54:49.235556.235556 mlpmodule.py:656] gpu experts func einsum cost 0.00474238395690918 s
DEBUG 01-07 14:54:49.235475.235475 cuda_h.py:19] end gpu_experts_multi_device cost 0.010939598083496094 seconds
DEBUG 01-07 14:54:49.236398.236398 cuda_h.py:19] end layer_moe_generate_multi_device_5 cost 0.05923295021057129 seconds
DEBUG 01-07 14:54:49.236049.236049 lmp.py:194] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-07 14:54:49.236394.236394 lmp.py:153] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-07 14:54:49.236567.236567 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 14:54:49.236608.236608 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 14:54:49.236643.236643 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:49.236392.236392 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.508827209472656e-05 seconds
DEBUG 01-07 14:54:49.236035.236035 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.236587.236587 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.236841.236841 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.236009.236009 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.236585.236585 cuda_h.py:19] end allocate_cuda_memory cost 0.0001800060272216797 seconds
DEBUG 01-07 14:54:49.236224.236224 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.236815.236815 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.237560.237560 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.237336.237336 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.237801.237801 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d0ae0774-c0ca-43a9-9c21-0c030256dd83
DEBUG 01-07 14:54:49.237525.237525 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.237859.237859 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.237901.237901 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d0ae0774-c0ca-43a9-9c21-0c030256dd83
DEBUG 01-07 14:54:49.238399.238399 cuda_h.py:19] end load_into_gpu_async cost 0.0009355545043945312 seconds
DEBUG 01-07 14:54:49.238718.238718 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.238410.238410 cuda_h.py:19] end restore_tensors2 cost 6.318092346191406e-05 seconds
DEBUG 01-07 14:54:49.238689.238689 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015406608581542969 seconds
INFO 01-07 14:54:49.238426.238426 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d0ae0774-c0ca-43a9-9c21-0c030256dd83
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.241893.241893 cuda_h.py:19] end self_attn cost 0.003721952438354492 seconds
DEBUG 01-07 14:54:49.241580.241580 cuda_h.py:19] end iln_self_attn_paln cost 0.005139350891113281 seconds
DEBUG 01-07 14:54:49.241071.241071 cuda_h.py:10] start layer_moe_generate_multi_device_6
DEBUG 01-07 14:54:49.241450.241450 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.242459.242459 cuda_h.py:19] end gate cost 0.0006401538848876953 seconds
DEBUG 01-07 14:54:49.242289.242289 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.242713.242713 lmp.py:744] 
DEBUG 01-07 14:54:49.242713.242713 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.242092.242092 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.242411.242411 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.242676.242676 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.242796.242796 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.242724.242724 lmp.py:749] 
DEBUG 01-07 14:54:49.242724.242724 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.242890.242890 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.242732.242732 lmp.py:767]   Expert  1 |     45 | CPU
DEBUG 01-07 14:54:49.243328.243328 lmp.py:767]   Expert  7 |     53 | CPU
DEBUG 01-07 14:54:49.243733.243733 lmp.py:767]   Expert 37 |     75 | CPU
DEBUG 01-07 14:54:49.243137.243137 lmp.py:767]   Expert 54 |     79 | CPU
DEBUG 01-07 14:54:49.243304.243304 lmp.py:767]   Expert 17 |     80 | CPU
DEBUG 01-07 14:54:49.243231.243231 lmp.py:767]   Expert 18 |     84 | CPU
DEBUG 01-07 14:54:49.243444.243444 lmp.py:767]   Expert  9 |     91 | CPU
DEBUG 01-07 14:54:49.243133.243133 lmp.py:767]   Expert 13 |     97 | CPU
DEBUG 01-07 14:54:49.243822.243822 lmp.py:767]   Expert 58 |     99 | CPU
DEBUG 01-07 14:54:49.243512.243512 lmp.py:767]   Expert 22 |    102 | CPU
DEBUG 01-07 14:54:49.243439.243439 lmp.py:767]   Expert  0 |    103 | CPU
DEBUG 01-07 14:54:49.243844.243844 lmp.py:767]   Expert 26 |    111 | CPU
DEBUG 01-07 14:54:49.243533.243533 lmp.py:767]   Expert 16 |    119 | CPU
DEBUG 01-07 14:54:49.243223.243223 lmp.py:767]   Expert 10 |    126 | CPU
DEBUG 01-07 14:54:49.243912.243912 lmp.py:767]   Expert 63 |    127 | CPU
DEBUG 01-07 14:54:49.243363.243363 lmp.py:767]   Expert 59 |    133 | CPU
DEBUG 01-07 14:54:49.243290.243290 lmp.py:767]   Expert 43 |    141 | CPU
DEBUG 01-07 14:54:49.243264.243264 lmp.py:767]   Expert 62 |    143 | CPU
DEBUG 01-07 14:54:49.243715.243715 lmp.py:767]   Expert 28 |    148 | CPU
DEBUG 01-07 14:54:49.243550.243550 lmp.py:767]   Expert 33 |    148 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243909.243909 lmp.py:767]   Expert 29 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243552.243552 lmp.py:767]   Expert  2 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243956.243956 lmp.py:767]   Expert 51 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243599.243599 lmp.py:767]   Expert  3 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243242.243242 lmp.py:767]   Expert 23 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243408.243408 lmp.py:767]   Expert 45 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243051.243051 lmp.py:767]   Expert 55 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243886.243886 lmp.py:767]   Expert 32 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243768.243768 lmp.py:767]   Expert 53 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243172.243172 lmp.py:767]   Expert 11 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243577.243577 lmp.py:767]   Expert 40 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243981.243981 lmp.py:767]   Expert 14 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243624.243624 lmp.py:767]   Expert 34 |    174 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243744.243744 lmp.py:767]   Expert 52 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243626.243626 lmp.py:767]   Expert 41 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243030.243030 lmp.py:767]   Expert 42 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243435.243435 lmp.py:767]   Expert 21 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243839.243839 lmp.py:767]   Expert 57 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243244.243244 lmp.py:767]   Expert 30 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243648.243648 lmp.py:767]   Expert 15 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243530.243530 lmp.py:767]   Expert 35 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243411.243411 lmp.py:767]   Expert 12 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243293.243293 lmp.py:767]   Expert  4 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243697.243697 lmp.py:767]   Expert 46 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243340.243340 lmp.py:767]   Expert 50 |    229 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243745.243745 lmp.py:767]   Expert 24 |    230 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243149.243149 lmp.py:767]   Expert 19 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243554.243554 lmp.py:767]   Expert 44 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243197.243197 lmp.py:767]   Expert 49 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243840.243840 lmp.py:767]   Expert  8 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243006.243006 lmp.py:767]   Expert 38 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243410.243410 lmp.py:767]   Expert  6 |    249 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243577.243577 lmp.py:767]   Expert 47 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243743.243743 lmp.py:767]   Expert 31 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243909.243909 lmp.py:767]   Expert 61 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243313.243313 lmp.py:767]   Expert 39 |    281 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243433.243433 lmp.py:767]   Expert  5 |    302 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.243315.243315 lmp.py:767]   Expert 27 |    309 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.243481.243481 lmp.py:767]   Expert 36 |    310 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.244647.244647 lmp.py:767]   Expert 60 |    330 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.244813.244813 lmp.py:767]   Expert 20 |    339 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.244218.244218 lmp.py:767]   Expert 48 |    372 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.244384.244384 lmp.py:767]   Expert 25 |    395 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.244027.244027 lmp.py:767]   Expert 56 |    551 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.244193.244193 lmp.py:769] 
DEBUG 01-07 14:54:49.244193.244193 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.244359.244359 lmp.py:770]   CPU:   1956 tokens
DEBUG 01-07 14:54:49.244240.244240 lmp.py:774]   cuda:1:   5096 tokens (22 experts)
DEBUG 01-07 14:54:49.244645.244645 lmp.py:774]   cuda:2:   5236 tokens (23 experts)
DEBUG 01-07 14:54:49.244096.244096 lmp.py:775]   Total GPU:  10332 tokens
DEBUG 01-07 14:54:49.244785.244785 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.244785.244785 lmp.py:776] 
DEBUG 01-07 14:54:49.244958.244958 cuda_h.py:19] end experts_map_get cost 0.0017650127410888672 seconds
DEBUG 01-07 14:54:49.244555.244555 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.244616.244616 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.244758.244758 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.244607.244607 cuda_h.py:19] end allocate_cuda_memory cost 0.00020003318786621094 seconds
DEBUG 01-07 14:54:49.244948.244948 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.244704.244704 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.244082.244082 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.244255.244255 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc7a19a6-d17c-4d9a-ab39-7085669e5497
DEBUG 01-07 14:54:49.244313.244313 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.245133.245133 client.py:127] Model loaded
DEBUG 01-07 14:54:49.245677.245677 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.245206.245206 cuda_h.py:19] end restore2model cost 0.0003223419189453125 seconds
DEBUG 01-07 14:54:49.245306.245306 cuda_h.py:19] end sllm_worker_task cost 0.008953094482421875 seconds
INFO 01-07 14:54:49.245708.245708 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc7a19a6-d17c-4d9a-ab39-7085669e5497
DEBUG 01-07 14:54:49.245505.245505 cuda_h.py:19] end load_into_gpu_async cost 0.0009741783142089844 seconds
DEBUG 01-07 14:54:49.245446.245446 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.246549.246549 cuda_h.py:19] end restore_tensors2 cost 0.00029730796813964844 seconds
DEBUG 01-07 14:54:49.246525.246525 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001806497573852539 seconds
DEBUG 01-07 14:54:49.246287.246287 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.247720.247720 cuda_h.py:19] end restore2model cost 0.0018014907836914062 seconds
DEBUG 01-07 14:54:49.248013.248013 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.248679.248679 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.248793.248793 cuda_h.py:19] end allocate_cuda_memory cost 0.00019311904907226562 seconds
DEBUG 01-07 14:54:49.248119.248119 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.248968.248968 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.248439.248439 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.248374.248374 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19f22056-dd0d-4844-a556-88723cd2da50
DEBUG 01-07 14:54:49.248849.248849 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.249345.249345 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19f22056-dd0d-4844-a556-88723cd2da50
DEBUG 01-07 14:54:49.249075.249075 cuda_h.py:19] end load_into_gpu_async cost 0.0010249614715576172 seconds
DEBUG 01-07 14:54:49.249871.249871 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.249497.249497 cuda_h.py:19] end restore_tensors2 cost 0.00029754638671875 seconds
DEBUG 01-07 14:54:49.249181.249181 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018160343170166016 seconds
DEBUG 01-07 14:54:49.249368.249368 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.251696.251696 cuda_h.py:19] end restore2model cost 0.0018644332885742188 seconds
DEBUG 01-07 14:54:49.251678.251678 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076181888580322266 seconds
DEBUG 01-07 14:54:49.251043.251043 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.251714.251714 lmp.py:816] 
DEBUG 01-07 14:54:49.251714.251714 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.252266.252266 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:49.252154.252154 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.258560.258560 mlpmodule.py:749] group tensors cost 0.005850076675415039 s
DEBUG 01-07 14:54:49.260693.260693 mlpmodule.py:787] pad cost 0.0013153553009033203 s
DEBUG 01-07 14:54:49.260630.260630 mlpmodule.py:793] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-07 14:54:49.260625.260625 mlpmodule.py:798] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-07 14:54:49.268947.268947 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.268482.268482 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.269790.269790 mlpmodule.py:818] group_w3 first element: -0.003631591796875
WARNING 01-07 14:54:49.269270.269270 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.284140.284140 mlpmodule.py:838] group einsum cost 0.024396896362304688 s
DEBUG 01-07 14:54:49.285889.285889 mlpmodule.py:846] cpy2cputensor cost 0.00045371055603027344 s
DEBUG 01-07 14:54:49.287874.287874 cuda_h.py:19] end wait_cetm_experts cost 0.03549623489379883 seconds
DEBUG 01-07 14:54:49.287996.287996 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.288802.288802 cuda_h.py:19] end gpu_sexperts cost 0.00048065185546875 seconds
DEBUG 01-07 14:54:49.288883.288883 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.288441.288441 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 14:54:49.288336.288336 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.288146.288146 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc7a19a6-d17c-4d9a-ab39-7085669e5497
INFO 01-07 14:54:49.289802.289802 client.py:127] Model loaded
INFO 01-07 14:54:49.289492.289492 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19f22056-dd0d-4844-a556-88723cd2da50
INFO 01-07 14:54:49.289250.289250 client.py:127] Model loaded
DEBUG 01-07 14:54:49.289649.289649 cuda_h.py:19] end wait_experts_multi_device cost 0.0016045570373535156 seconds
DEBUG 01-07 14:54:49.290544.290544 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.290268.290268 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.291558.291558 mlpmodule.py:533] gpu group tensors cost 0.0004968643188476562 s
DEBUG 01-07 14:54:49.292274.292274 mlpmodule.py:566] gpu pad cost 0.001344919204711914 s
DEBUG 01-07 14:54:49.293839.293839 mlpmodule.py:584] gpu group einsum cost 0.0005726814270019531 s
DEBUG 01-07 14:54:49.295912.295912 mlpmodule.py:656] gpu experts func einsum cost 0.0047266483306884766 s
DEBUG 01-07 14:54:49.295307.295307 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.295881.295881 mlpmodule.py:707]  experts func einsum cost 0.0437469482421875 s
DEBUG 01-07 14:54:49.296011.296011 mlpmodule.py:533] gpu group tensors cost 0.00047016143798828125 s
DEBUG 01-07 14:54:49.297943.297943 mlpmodule.py:566] gpu pad cost 0.0012514591217041016 s
DEBUG 01-07 14:54:49.298266.298266 mlpmodule.py:584] gpu group einsum cost 0.00047326087951660156 s
DEBUG 01-07 14:54:49.300257.300257 mlpmodule.py:656] gpu experts func einsum cost 0.004447221755981445 s
DEBUG 01-07 14:54:49.300447.300447 cuda_h.py:19] end gpu_experts_multi_device cost 0.010715246200561523 seconds
DEBUG 01-07 14:54:49.300463.300463 cuda_h.py:19] end layer_moe_generate_multi_device_6 cost 0.05914187431335449 seconds
DEBUG 01-07 14:54:49.301498.301498 lmp.py:194] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-07 14:54:49.301718.301718 lmp.py:153] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-07 14:54:49.301460.301460 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 14:54:49.301548.301548 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 14:54:49.301430.301430 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:49.301987.301987 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 5.6743621826171875e-05 seconds
DEBUG 01-07 14:54:49.301345.301345 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.301758.301758 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.301369.301369 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.301233.301233 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.301162.301162 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.322958.322958 cuda_h.py:19] end allocate_cuda_memory cost 0.021347522735595703 seconds
DEBUG 01-07 14:54:49.323455.323455 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.323928.323928 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.323223.323223 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.323186.323186 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 416541c9-4750-4e50-aeca-49cf0b65f58d
DEBUG 01-07 14:54:49.323021.323021 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.324480.324480 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.325888.325888 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 416541c9-4750-4e50-aeca-49cf0b65f58d
DEBUG 01-07 14:54:49.325655.325655 cuda_h.py:19] end load_into_gpu_async cost 0.0021033287048339844 seconds
DEBUG 01-07 14:54:49.325618.325618 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.325155.325155 cuda_h.py:19] end restore_tensors2 cost 0.00014448165893554688 seconds
DEBUG 01-07 14:54:49.325800.325800 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0242159366607666 seconds
INFO 01-07 14:54:49.325858.325858 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 416541c9-4750-4e50-aeca-49cf0b65f58d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.331188.331188 cuda_h.py:19] end self_attn cost 0.007332801818847656 seconds
DEBUG 01-07 14:54:49.332633.332633 cuda_h.py:19] end iln_self_attn_paln cost 0.031103849411010742 seconds
DEBUG 01-07 14:54:49.332663.332663 cuda_h.py:10] start layer_moe_generate_multi_device_7
DEBUG 01-07 14:54:49.332189.332189 cuda_h.py:10] start gate
INFO 01-07 14:54:49.333021.333021 client.py:127] Model loaded
DEBUG 01-07 14:54:49.333177.333177 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.334559.334559 cuda_h.py:19] end restore2model cost 0.0010330677032470703 seconds
DEBUG 01-07 14:54:49.334604.334604 cuda_h.py:19] end sllm_worker_task cost 0.033026695251464844 seconds
DEBUG 01-07 14:54:49.334618.334618 cuda_h.py:19] end gate cost 0.002279996871948242 seconds
DEBUG 01-07 14:54:49.335476.335476 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.335678.335678 lmp.py:744] 
DEBUG 01-07 14:54:49.335678.335678 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.335912.335912 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.336218.336218 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.336326.336326 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.336619.336619 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.336527.336527 lmp.py:749] 
DEBUG 01-07 14:54:49.336527.336527 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.336866.336866 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.336080.336080 lmp.py:767]   Expert 50 |     41 | CPU
DEBUG 01-07 14:54:49.336326.336326 lmp.py:767]   Expert  3 |     53 | CPU
DEBUG 01-07 14:54:49.336473.336473 lmp.py:767]   Expert 46 |     56 | CPU
DEBUG 01-07 14:54:49.336667.336667 lmp.py:767]   Expert  1 |     74 | CPU
DEBUG 01-07 14:54:49.336503.336503 lmp.py:767]   Expert  4 |     88 | CPU
DEBUG 01-07 14:54:49.336935.336935 lmp.py:767]   Expert 29 |     89 | CPU
DEBUG 01-07 14:54:49.336651.336651 lmp.py:767]   Expert 15 |     95 | CPU
DEBUG 01-07 14:54:49.336129.336129 lmp.py:767]   Expert 40 |     95 | CPU
DEBUG 01-07 14:54:49.336514.336514 lmp.py:767]   Expert  8 |    106 | CPU
DEBUG 01-07 14:54:49.336708.336708 lmp.py:767]   Expert 41 |    110 | CPU
DEBUG 01-07 14:54:49.336186.336186 lmp.py:767]   Expert 28 |    114 | CPU
DEBUG 01-07 14:54:49.336664.336664 lmp.py:767]   Expert 16 |    125 | CPU
DEBUG 01-07 14:54:49.336142.336142 lmp.py:767]   Expert 48 |    126 | CPU
DEBUG 01-07 14:54:49.336666.336666 lmp.py:767]   Expert  6 |    127 | CPU
DEBUG 01-07 14:54:49.336336.336336 lmp.py:767]   Expert 13 |    129 | CPU
DEBUG 01-07 14:54:49.336483.336483 lmp.py:767]   Expert 54 |    132 | CPU
DEBUG 01-07 14:54:49.336485.336485 lmp.py:767]   Expert 27 |    133 | CPU
DEBUG 01-07 14:54:49.336247.336247 lmp.py:767]   Expert  7 |    134 | CPU
DEBUG 01-07 14:54:49.336010.336010 lmp.py:767]   Expert 51 |    137 | CPU
DEBUG 01-07 14:54:49.336780.336780 lmp.py:767]   Expert 60 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337026.337026 lmp.py:767]   Expert 18 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337888.337888 lmp.py:767]   Expert 56 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337751.337751 lmp.py:767]   Expert 39 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337374.337374 lmp.py:767]   Expert 14 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337283.337283 lmp.py:767]   Expert 43 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337622.337622 lmp.py:767]   Expert 52 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337392.337392 lmp.py:767]   Expert 20 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337492.337492 lmp.py:767]   Expert 36 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337878.337878 lmp.py:767]   Expert 45 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337263.337263 lmp.py:767]   Expert 55 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337887.337887 lmp.py:767]   Expert  5 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337895.337895 lmp.py:767]   Expert 10 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337426.337426 lmp.py:767]   Expert 11 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337003.337003 lmp.py:767]   Expert 62 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337104.337104 lmp.py:767]   Expert 57 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337682.337682 lmp.py:767]   Expert 33 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337736.337736 lmp.py:767]   Expert 44 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337790.337790 lmp.py:767]   Expert 58 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337129.337129 lmp.py:767]   Expert 53 |    184 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337468.337468 lmp.py:767]   Expert 25 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337999.337999 lmp.py:767]   Expert  2 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337531.337531 lmp.py:767]   Expert 32 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337585.337585 lmp.py:767]   Expert 31 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.337401.337401 lmp.py:767]   Expert 63 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.337025.337025 lmp.py:767]   Expert 49 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338648.338648 lmp.py:767]   Expert 21 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338703.338703 lmp.py:767]   Expert 35 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338234.338234 lmp.py:767]   Expert 17 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338335.338335 lmp.py:767]   Expert 42 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338482.338482 lmp.py:767]   Expert 34 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338629.338629 lmp.py:767]   Expert 37 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338014.338014 lmp.py:767]   Expert 59 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338923.338923 lmp.py:767]   Expert 22 |    242 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338546.338546 lmp.py:767]   Expert  0 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338409.338409 lmp.py:767]   Expert 19 |    259 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338986.338986 lmp.py:767]   Expert 24 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338371.338371 lmp.py:767]   Expert 61 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338518.338518 lmp.py:767]   Expert 30 |    302 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338381.338381 lmp.py:767]   Expert 47 |    321 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338528.338528 lmp.py:767]   Expert 38 |    360 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338913.338913 lmp.py:767]   Expert 26 |    370 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338729.338729 lmp.py:767]   Expert 12 |    427 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338498.338498 lmp.py:767]   Expert  9 |    684 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.338599.338599 lmp.py:767]   Expert 23 |    708 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.338123.338123 lmp.py:769] 
DEBUG 01-07 14:54:49.338123.338123 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.338701.338701 lmp.py:770]   CPU:   1964 tokens
DEBUG 01-07 14:54:49.338424.338424 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 14:54:49.338810.338810 lmp.py:774]   cuda:2:   5093 tokens (22 experts)
DEBUG 01-07 14:54:49.338288.338288 lmp.py:775]   Total GPU:  10324 tokens
DEBUG 01-07 14:54:49.338865.338865 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.338865.338865 lmp.py:776] 
DEBUG 01-07 14:54:49.338979.338979 cuda_h.py:19] end experts_map_get cost 0.0038907527923583984 seconds
DEBUG 01-07 14:54:49.339080.339080 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.339964.339964 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.339731.339731 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.339651.339651 cuda_h.py:19] end allocate_cuda_memory cost 0.00029850006103515625 seconds
DEBUG 01-07 14:54:49.339224.339224 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.339590.339590 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.339970.339970 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.339654.339654 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dac17f23-24f8-4fbe-a489-ab4aea7ca884
DEBUG 01-07 14:54:49.340809.340809 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.341402.341402 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dac17f23-24f8-4fbe-a489-ab4aea7ca884
DEBUG 01-07 14:54:49.341901.341901 cuda_h.py:19] end load_into_gpu_async cost 0.0021648406982421875 seconds
DEBUG 01-07 14:54:49.342365.342365 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.342681.342681 cuda_h.py:19] end restore_tensors2 cost 0.00031280517578125 seconds
DEBUG 01-07 14:54:49.342511.342511 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003238201141357422 seconds
DEBUG 01-07 14:54:49.342658.342658 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.344220.344220 cuda_h.py:19] end restore2model cost 0.0019290447235107422 seconds
DEBUG 01-07 14:54:49.344229.344229 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.344557.344557 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.344015.344015 cuda_h.py:19] end allocate_cuda_memory cost 0.00019860267639160156 seconds
DEBUG 01-07 14:54:49.344567.344567 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.344177.344177 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.344986.344986 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.344590.344590 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 001fad2b-71a8-4567-8dd0-3e8da323b004
DEBUG 01-07 14:54:49.345111.345111 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.346580.346580 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 001fad2b-71a8-4567-8dd0-3e8da323b004
DEBUG 01-07 14:54:49.346979.346979 cuda_h.py:19] end load_into_gpu_async cost 0.001783132553100586 seconds
DEBUG 01-07 14:54:49.346820.346820 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.347181.347181 cuda_h.py:19] end restore_tensors2 cost 0.0002770423889160156 seconds
DEBUG 01-07 14:54:49.347435.347435 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025467872619628906 seconds
DEBUG 01-07 14:54:49.347668.347668 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.348140.348140 cuda_h.py:19] end restore2model cost 0.0018303394317626953 seconds
DEBUG 01-07 14:54:49.349507.349507 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00993037223815918 seconds
DEBUG 01-07 14:54:49.349256.349256 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.349649.349649 lmp.py:816] 
DEBUG 01-07 14:54:49.349649.349649 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.349293.349293 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 14:54:49.349705.349705 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.363688.363688 mlpmodule.py:749] group tensors cost 0.01412057876586914 s
DEBUG 01-07 14:54:49.365023.365023 mlpmodule.py:787] pad cost 0.0014750957489013672 s
DEBUG 01-07 14:54:49.365677.365677 mlpmodule.py:793] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-07 14:54:49.366037.366037 mlpmodule.py:798] move to cpu cost 3.8623809814453125e-05 s
DEBUG 01-07 14:54:49.374690.374690 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.374372.374372 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.374945.374945 mlpmodule.py:818] group_w3 first element: 0.01263427734375
WARNING 01-07 14:54:49.374751.374751 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.387168.387168 mlpmodule.py:838] group einsum cost 0.021224260330200195 s
DEBUG 01-07 14:54:49.387424.387424 mlpmodule.py:846] cpy2cputensor cost 0.0003814697265625 s
DEBUG 01-07 14:54:49.390933.390933 cuda_h.py:19] end wait_cetm_experts cost 0.04099440574645996 seconds
DEBUG 01-07 14:54:49.390963.390963 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.390106.390106 cuda_h.py:19] end gpu_sexperts cost 0.000484466552734375 seconds
DEBUG 01-07 14:54:49.390141.390141 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.390461.390461 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2172927856445312e-05 seconds
DEBUG 01-07 14:54:49.390118.390118 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.391503.391503 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dac17f23-24f8-4fbe-a489-ab4aea7ca884
INFO 01-07 14:54:49.391111.391111 client.py:127] Model loaded
INFO 01-07 14:54:49.392709.392709 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 001fad2b-71a8-4567-8dd0-3e8da323b004
INFO 01-07 14:54:49.392037.392037 client.py:127] Model loaded
DEBUG 01-07 14:54:49.392582.392582 cuda_h.py:19] end wait_experts_multi_device cost 0.0015726089477539062 seconds
DEBUG 01-07 14:54:49.392431.392431 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.392869.392869 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:49.393193.393193 mlpmodule.py:533] gpu group tensors cost 0.000484466552734375 s
DEBUG 01-07 14:54:49.395800.395800 mlpmodule.py:566] gpu pad cost 0.001260995864868164 s
DEBUG 01-07 14:54:49.395345.395345 mlpmodule.py:584] gpu group einsum cost 0.0005693435668945312 s
DEBUG 01-07 14:54:49.397044.397044 mlpmodule.py:656] gpu experts func einsum cost 0.004555940628051758 s
DEBUG 01-07 14:54:49.398533.398533 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:49.398755.398755 mlpmodule.py:707]  experts func einsum cost 0.04956936836242676 s
DEBUG 01-07 14:54:49.399900.399900 mlpmodule.py:533] gpu group tensors cost 0.0005578994750976562 s
DEBUG 01-07 14:54:49.400451.400451 mlpmodule.py:566] gpu pad cost 0.0013513565063476562 s
DEBUG 01-07 14:54:49.401277.401277 mlpmodule.py:584] gpu group einsum cost 0.00045418739318847656 s
DEBUG 01-07 14:54:49.403520.403520 mlpmodule.py:656] gpu experts func einsum cost 0.004636287689208984 s
DEBUG 01-07 14:54:49.403802.403802 cuda_h.py:19] end gpu_experts_multi_device cost 0.010674238204956055 seconds
DEBUG 01-07 14:54:49.403772.403772 cuda_h.py:19] end layer_moe_generate_multi_device_7 cost 0.07084512710571289 seconds
DEBUG 01-07 14:54:49.403475.403475 lmp.py:194] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-07 14:54:49.403921.403921 lmp.py:153] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-07 14:54:49.403140.403140 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 14:54:49.403910.403910 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 14:54:49.403554.403554 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 14:54:49.403780.403780 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.6743621826171875e-05 seconds
DEBUG 01-07 14:54:49.403615.403615 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.403213.403213 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.403063.403063 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.404873.404873 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.404418.404418 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.404541.404541 cuda_h.py:19] end allocate_cuda_memory cost 0.0003032684326171875 seconds
DEBUG 01-07 14:54:49.404935.404935 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.404029.404029 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.404136.404136 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.404693.404693 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, da716159-3adc-47be-9b6e-2d5561273264
DEBUG 01-07 14:54:49.404610.404610 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.404433.404433 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.405104.405104 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, da716159-3adc-47be-9b6e-2d5561273264
DEBUG 01-07 14:54:49.405794.405794 cuda_h.py:19] end load_into_gpu_async cost 0.00091552734375 seconds
DEBUG 01-07 14:54:49.405113.405113 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.405143.405143 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-07 14:54:49.405991.405991 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015330314636230469 seconds
INFO 01-07 14:54:49.405834.405834 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, da716159-3adc-47be-9b6e-2d5561273264
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.408642.408642 cuda_h.py:19] end self_attn cost 0.0030062198638916016 seconds
DEBUG 01-07 14:54:49.408097.408097 cuda_h.py:19] end iln_self_attn_paln cost 0.004469633102416992 seconds
DEBUG 01-07 14:54:49.408602.408602 cuda_h.py:10] start layer_moe_generate_multi_device_8
DEBUG 01-07 14:54:49.408696.408696 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.409427.409427 cuda_h.py:19] end gate cost 0.0006465911865234375 seconds
DEBUG 01-07 14:54:49.409018.409018 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.409820.409820 lmp.py:744] 
DEBUG 01-07 14:54:49.409820.409820 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.409007.409007 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.409895.409895 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.409207.409207 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.409134.409134 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.409108.409108 lmp.py:749] 
DEBUG 01-07 14:54:49.409108.409108 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.409321.409321 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.409971.409971 lmp.py:767]   Expert 38 |     10 | CPU
DEBUG 01-07 14:54:49.409137.409137 lmp.py:767]   Expert 39 |     66 | CPU
DEBUG 01-07 14:54:49.409349.409349 lmp.py:767]   Expert  7 |     76 | CPU
DEBUG 01-07 14:54:49.409800.409800 lmp.py:767]   Expert 30 |     79 | CPU
DEBUG 01-07 14:54:49.409774.409774 lmp.py:767]   Expert 14 |     91 | CPU
DEBUG 01-07 14:54:49.409748.409748 lmp.py:767]   Expert 27 |     91 | CPU
DEBUG 01-07 14:54:49.409722.409722 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 14:54:49.409696.409696 lmp.py:767]   Expert 24 |     96 | CPU
DEBUG 01-07 14:54:49.409670.409670 lmp.py:767]   Expert 36 |    100 | CPU
DEBUG 01-07 14:54:49.409406.409406 lmp.py:767]   Expert 32 |    101 | CPU
DEBUG 01-07 14:54:49.409380.409380 lmp.py:767]   Expert 40 |    101 | CPU
DEBUG 01-07 14:54:49.409116.409116 lmp.py:767]   Expert 16 |    102 | CPU
DEBUG 01-07 14:54:49.409328.409328 lmp.py:767]   Expert 18 |    109 | CPU
DEBUG 01-07 14:54:49.409302.409302 lmp.py:767]   Expert 12 |    110 | CPU
DEBUG 01-07 14:54:49.409276.409276 lmp.py:767]   Expert 48 |    112 | CPU
DEBUG 01-07 14:54:49.409966.409966 lmp.py:767]   Expert  1 |    116 | CPU
DEBUG 01-07 14:54:49.409178.409178 lmp.py:767]   Expert  6 |    124 | CPU
DEBUG 01-07 14:54:49.410914.410914 lmp.py:767]   Expert 59 |    131 | CPU
DEBUG 01-07 14:54:49.410649.410649 lmp.py:767]   Expert  0 |    138 | CPU
DEBUG 01-07 14:54:49.410723.410723 lmp.py:767]   Expert 42 |    138 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410081.410081 lmp.py:767]   Expert 53 |    141 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410201.410201 lmp.py:767]   Expert 22 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410082.410082 lmp.py:767]   Expert 51 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410725.410725 lmp.py:767]   Expert  8 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410083.410083 lmp.py:767]   Expert 60 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410965.410965 lmp.py:767]   Expert 29 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410608.410608 lmp.py:767]   Expert 44 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410489.410489 lmp.py:767]   Expert 54 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410894.410894 lmp.py:767]   Expert 15 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410298.410298 lmp.py:767]   Expert 33 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410180.410180 lmp.py:767]   Expert 35 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410823.410823 lmp.py:767]   Expert 34 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410704.410704 lmp.py:767]   Expert 19 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410824.410824 lmp.py:767]   Expert 47 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410467.410467 lmp.py:767]   Expert  9 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410871.410871 lmp.py:767]   Expert  3 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410276.410276 lmp.py:767]   Expert 21 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410919.410919 lmp.py:767]   Expert 56 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410323.410323 lmp.py:767]   Expert 20 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410205.410205 lmp.py:767]   Expert 46 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410086.410086 lmp.py:767]   Expert 45 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410729.410729 lmp.py:767]   Expert 49 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410895.410895 lmp.py:767]   Expert 28 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410300.410300 lmp.py:767]   Expert  2 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410466.410466 lmp.py:767]   Expert  4 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410632.410632 lmp.py:767]   Expert 13 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410037.410037 lmp.py:767]   Expert 57 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410441.410441 lmp.py:767]   Expert 43 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410846.410846 lmp.py:767]   Expert 50 |    242 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410727.410727 lmp.py:767]   Expert 10 |    243 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410370.410370 lmp.py:767]   Expert 41 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410775.410775 lmp.py:767]   Expert 63 |    254 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410418.410418 lmp.py:767]   Expert 26 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410822.410822 lmp.py:767]   Expert 37 |    258 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410227.410227 lmp.py:767]   Expert 61 |    268 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410631.410631 lmp.py:767]   Expert 31 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410036.410036 lmp.py:767]   Expert 52 |    302 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410917.410917 lmp.py:767]   Expert 58 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410799.410799 lmp.py:767]   Expert 62 |    328 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410442.410442 lmp.py:767]   Expert 55 |    340 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410085.410085 lmp.py:767]   Expert 11 |    382 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410489.410489 lmp.py:767]   Expert 23 |    388 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410894.410894 lmp.py:767]   Expert 25 |    407 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.410298.410298 lmp.py:767]   Expert  5 |    514 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.410988.410988 lmp.py:769] 
DEBUG 01-07 14:54:49.410988.410988 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.410869.410869 lmp.py:770]   CPU:   1849 tokens
DEBUG 01-07 14:54:49.410989.410989 lmp.py:774]   cuda:1:   5151 tokens (22 experts)
DEBUG 01-07 14:54:49.410393.410393 lmp.py:774]   cuda:2:   5288 tokens (23 experts)
DEBUG 01-07 14:54:49.410083.410083 lmp.py:775]   Total GPU:  10439 tokens
DEBUG 01-07 14:54:49.410010.410010 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.410010.410010 lmp.py:776] 
DEBUG 01-07 14:54:49.410660.410660 cuda_h.py:19] end experts_map_get cost 0.0017452239990234375 seconds
DEBUG 01-07 14:54:49.410780.410780 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.411318.411318 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.411507.411507 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.412375.412375 cuda_h.py:19] end allocate_cuda_memory cost 0.0015554428100585938 seconds
DEBUG 01-07 14:54:49.412377.412377 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.412040.412040 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.412803.412803 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.412407.412407 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 85585b27-d5c7-4632-84a5-6661649190b2
DEBUG 01-07 14:54:49.413087.413087 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.413228.413228 client.py:127] Model loaded
DEBUG 01-07 14:54:49.413587.413587 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.413261.413261 cuda_h.py:19] end restore2model cost 0.00032329559326171875 seconds
DEBUG 01-07 14:54:49.413600.413600 cuda_h.py:19] end sllm_worker_task cost 0.009671688079833984 seconds
INFO 01-07 14:54:49.413532.413532 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 85585b27-d5c7-4632-84a5-6661649190b2
DEBUG 01-07 14:54:49.413090.413090 cuda_h.py:19] end load_into_gpu_async cost 0.0010881423950195312 seconds
DEBUG 01-07 14:54:49.413316.413316 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.414214.414214 cuda_h.py:19] end restore_tensors2 cost 0.0002865791320800781 seconds
DEBUG 01-07 14:54:49.414229.414229 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032482147216796875 seconds
DEBUG 01-07 14:54:49.414753.414753 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.416158.416158 cuda_h.py:19] end restore2model cost 0.0017812252044677734 seconds
DEBUG 01-07 14:54:49.416452.416452 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.416780.416780 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.416140.416140 cuda_h.py:19] end allocate_cuda_memory cost 0.00023365020751953125 seconds
DEBUG 01-07 14:54:49.416930.416930 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.416494.416494 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.416726.416726 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.416423.416423 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61c53862-949e-438a-91bc-26ad4ccdb6b0
DEBUG 01-07 14:54:49.416328.416328 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.417245.417245 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61c53862-949e-438a-91bc-26ad4ccdb6b0
DEBUG 01-07 14:54:49.417690.417690 cuda_h.py:19] end load_into_gpu_async cost 0.0009157657623291016 seconds
DEBUG 01-07 14:54:49.417247.417247 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.417032.417032 cuda_h.py:19] end restore_tensors2 cost 0.0002720355987548828 seconds
DEBUG 01-07 14:54:49.417523.417523 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017101764678955078 seconds
DEBUG 01-07 14:54:49.417803.417803 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.419416.419416 cuda_h.py:19] end restore2model cost 0.0018634796142578125 seconds
DEBUG 01-07 14:54:49.419345.419345 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008926630020141602 seconds
DEBUG 01-07 14:54:49.419948.419948 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.420811.420811 lmp.py:816] 
DEBUG 01-07 14:54:49.420811.420811 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.420125.420125 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 14:54:49.420013.420013 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.429227.429227 mlpmodule.py:749] group tensors cost 0.008859634399414062 s
DEBUG 01-07 14:54:49.430116.430116 mlpmodule.py:787] pad cost 0.0011649131774902344 s
DEBUG 01-07 14:54:49.430563.430563 mlpmodule.py:793] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-07 14:54:49.431063.431063 mlpmodule.py:798] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-07 14:54:49.439151.439151 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.440647.440647 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.440167.440167 mlpmodule.py:818] group_w3 first element: 0.0859375
WARNING 01-07 14:54:49.440707.440707 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.455682.455682 mlpmodule.py:838] group einsum cost 0.023939132690429688 s
DEBUG 01-07 14:54:49.455437.455437 mlpmodule.py:846] cpy2cputensor cost 0.0003910064697265625 s
DEBUG 01-07 14:54:49.458426.458426 cuda_h.py:19] end wait_cetm_experts cost 0.03800845146179199 seconds
DEBUG 01-07 14:54:49.458594.458594 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.458638.458638 cuda_h.py:19] end gpu_sexperts cost 0.0004811286926269531 seconds
DEBUG 01-07 14:54:49.458766.458766 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.458755.458755 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 14:54:49.458935.458935 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.458360.458360 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 85585b27-d5c7-4632-84a5-6661649190b2
INFO 01-07 14:54:49.459067.459067 client.py:127] Model loaded
INFO 01-07 14:54:49.459373.459373 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61c53862-949e-438a-91bc-26ad4ccdb6b0
INFO 01-07 14:54:49.460013.460013 client.py:127] Model loaded
DEBUG 01-07 14:54:49.460557.460557 cuda_h.py:19] end wait_experts_multi_device cost 0.0015521049499511719 seconds
DEBUG 01-07 14:54:49.460691.460691 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.460129.460129 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.461202.461202 mlpmodule.py:533] gpu group tensors cost 0.0005028247833251953 s
DEBUG 01-07 14:54:49.463798.463798 mlpmodule.py:566] gpu pad cost 0.0013232231140136719 s
DEBUG 01-07 14:54:49.463794.463794 mlpmodule.py:584] gpu group einsum cost 0.0005719661712646484 s
DEBUG 01-07 14:54:49.465370.465370 mlpmodule.py:656] gpu experts func einsum cost 0.004736900329589844 s
DEBUG 01-07 14:54:49.466288.466288 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.466390.466390 mlpmodule.py:707]  experts func einsum cost 0.04677462577819824 s
DEBUG 01-07 14:54:49.467303.467303 mlpmodule.py:533] gpu group tensors cost 0.0005540847778320312 s
DEBUG 01-07 14:54:49.468979.468979 mlpmodule.py:566] gpu pad cost 0.0013039112091064453 s
DEBUG 01-07 14:54:49.469295.469295 mlpmodule.py:584] gpu group einsum cost 0.000469207763671875 s
DEBUG 01-07 14:54:49.471263.471263 mlpmodule.py:656] gpu experts func einsum cost 0.004496335983276367 s
DEBUG 01-07 14:54:49.471215.471215 cuda_h.py:19] end gpu_experts_multi_device cost 0.010681390762329102 seconds
DEBUG 01-07 14:54:49.471920.471920 cuda_h.py:19] end layer_moe_generate_multi_device_8 cost 0.06287980079650879 seconds
DEBUG 01-07 14:54:49.471373.471373 lmp.py:194] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-07 14:54:49.471149.471149 lmp.py:153] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-07 14:54:49.471891.471891 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 14:54:49.471694.471694 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 14:54:49.471576.471576 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 14:54:49.471849.471849 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 14:54:49.471922.471922 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.471096.471096 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.471615.471615 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.471571.471571 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.472831.472831 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.472815.472815 cuda_h.py:19] end allocate_cuda_memory cost 0.0002701282501220703 seconds
DEBUG 01-07 14:54:49.472678.472678 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.472163.472163 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.472840.472840 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.472397.472397 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61a8c2f3-3f15-4f92-b31d-4c213dd5203e
DEBUG 01-07 14:54:49.472221.472221 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.472416.472416 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.473955.473955 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61a8c2f3-3f15-4f92-b31d-4c213dd5203e
DEBUG 01-07 14:54:49.473645.473645 cuda_h.py:19] end load_into_gpu_async cost 0.0009596347808837891 seconds
DEBUG 01-07 14:54:49.473441.473441 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.473424.473424 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 14:54:49.473511.473511 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001538991928100586 seconds
INFO 01-07 14:54:49.473632.473632 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61a8c2f3-3f15-4f92-b31d-4c213dd5203e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.476218.476218 cuda_h.py:19] end self_attn cost 0.0037255287170410156 seconds
DEBUG 01-07 14:54:49.476799.476799 cuda_h.py:19] end iln_self_attn_paln cost 0.0051822662353515625 seconds
DEBUG 01-07 14:54:49.477529.477529 cuda_h.py:10] start layer_moe_generate_multi_device_9
DEBUG 01-07 14:54:49.477715.477715 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.477771.477771 cuda_h.py:19] end gate cost 0.0006406307220458984 seconds
DEBUG 01-07 14:54:49.477931.477931 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.478018.478018 lmp.py:744] 
DEBUG 01-07 14:54:49.478018.478018 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.478874.478874 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.478716.478716 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.478743.478743 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.478862.478862 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.478029.478029 lmp.py:749] 
DEBUG 01-07 14:54:49.478029.478029 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.478387.478387 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.478229.478229 lmp.py:767]   Expert 24 |     43 | CPU
DEBUG 01-07 14:54:49.478349.478349 lmp.py:767]   Expert  2 |     46 | CPU
DEBUG 01-07 14:54:49.478991.478991 lmp.py:767]   Expert 32 |     66 | CPU
DEBUG 01-07 14:54:49.478396.478396 lmp.py:767]   Expert 19 |     70 | CPU
DEBUG 01-07 14:54:49.478562.478562 lmp.py:767]   Expert 50 |     73 | CPU
DEBUG 01-07 14:54:49.478205.478205 lmp.py:767]   Expert 26 |     74 | CPU
DEBUG 01-07 14:54:49.478133.478133 lmp.py:767]   Expert 15 |     78 | CPU
DEBUG 01-07 14:54:49.478299.478299 lmp.py:767]   Expert  4 |     79 | CPU
DEBUG 01-07 14:54:49.478227.478227 lmp.py:767]   Expert  7 |     80 | CPU
DEBUG 01-07 14:54:49.478154.478154 lmp.py:767]   Expert 28 |     81 | CPU
DEBUG 01-07 14:54:49.478321.478321 lmp.py:767]   Expert 60 |     88 | CPU
DEBUG 01-07 14:54:49.478725.478725 lmp.py:767]   Expert 59 |     90 | CPU
DEBUG 01-07 14:54:49.478414.478414 lmp.py:767]   Expert 49 |     96 | CPU
DEBUG 01-07 14:54:49.478342.478342 lmp.py:767]   Expert  5 |     98 | CPU
DEBUG 01-07 14:54:49.478031.478031 lmp.py:767]   Expert 23 |    101 | CPU
DEBUG 01-07 14:54:49.478436.478436 lmp.py:767]   Expert 12 |    106 | CPU
DEBUG 01-07 14:54:49.478364.478364 lmp.py:767]   Expert 27 |    111 | CPU
DEBUG 01-07 14:54:49.478053.478053 lmp.py:767]   Expert 10 |    113 | CPU
DEBUG 01-07 14:54:49.478981.478981 lmp.py:767]   Expert  3 |    123 | CPU
DEBUG 01-07 14:54:49.478862.478862 lmp.py:767]   Expert 41 |    125 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478697.478697 lmp.py:767]   Expert 20 |    129 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478771.478771 lmp.py:767]   Expert 40 |    129 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478891.478891 lmp.py:767]   Expert 25 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478057.478057 lmp.py:767]   Expert 13 |    131 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478700.478700 lmp.py:767]   Expert 16 |    134 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478343.478343 lmp.py:767]   Expert 37 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478747.478747 lmp.py:767]   Expert 35 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478913.478913 lmp.py:767]   Expert 17 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478272.478272 lmp.py:767]   Expert 47 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478676.478676 lmp.py:767]   Expert 22 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478081.478081 lmp.py:767]   Expert 53 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478200.478200 lmp.py:767]   Expert 39 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478605.478605 lmp.py:767]   Expert 38 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478248.478248 lmp.py:767]   Expert 36 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478653.478653 lmp.py:767]   Expert 44 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.478534.478534 lmp.py:767]   Expert 52 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.478177.478177 lmp.py:767]   Expert 18 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479058.479058 lmp.py:767]   Expert 58 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479463.479463 lmp.py:767]   Expert 62 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479344.479344 lmp.py:767]   Expert 48 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479749.479749 lmp.py:767]   Expert 11 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479915.479915 lmp.py:767]   Expert 30 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479081.479081 lmp.py:767]   Expert 14 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479201.479201 lmp.py:767]   Expert  1 |    230 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479559.479559 lmp.py:767]   Expert 31 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479725.479725 lmp.py:767]   Expert 42 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479653.479653 lmp.py:767]   Expert  6 |    235 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479819.479819 lmp.py:767]   Expert 51 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479985.479985 lmp.py:767]   Expert 45 |    238 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479390.479390 lmp.py:767]   Expert 34 |    268 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479556.479556 lmp.py:767]   Expert 29 |    271 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479722.479722 lmp.py:767]   Expert 33 |    276 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479365.479365 lmp.py:767]   Expert 57 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479485.479485 lmp.py:767]   Expert 61 |    305 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479889.479889 lmp.py:767]   Expert 43 |    313 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479294.479294 lmp.py:767]   Expert  0 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479222.479222 lmp.py:767]   Expert 46 |    349 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479626.479626 lmp.py:767]   Expert  8 |    375 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479792.479792 lmp.py:767]   Expert  9 |    390 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479197.479197 lmp.py:767]   Expert 54 |    396 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479555.479555 lmp.py:767]   Expert 56 |    398 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479437.479437 lmp.py:767]   Expert 63 |    414 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479841.479841 lmp.py:767]   Expert 55 |    419 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.479246.479246 lmp.py:767]   Expert 21 |    484 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.479935.479935 lmp.py:769] 
DEBUG 01-07 14:54:49.479935.479935 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.479101.479101 lmp.py:770]   CPU:   1616 tokens
DEBUG 01-07 14:54:49.479221.479221 lmp.py:774]   cuda:1:   5397 tokens (23 experts)
DEBUG 01-07 14:54:49.479626.479626 lmp.py:774]   cuda:2:   5275 tokens (22 experts)
DEBUG 01-07 14:54:49.479268.479268 lmp.py:775]   Total GPU:  10672 tokens
DEBUG 01-07 14:54:49.479958.479958 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.479958.479958 lmp.py:776] 
DEBUG 01-07 14:54:49.479892.479892 cuda_h.py:19] end experts_map_get cost 0.0017693042755126953 seconds
DEBUG 01-07 14:54:49.479012.479012 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.479120.479120 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.479262.479262 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.479581.479581 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
DEBUG 01-07 14:54:49.480114.480114 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.480585.480585 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.480440.480440 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.480136.480136 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7a377283-06f8-4df0-9463-39acd8d219a5
DEBUG 01-07 14:54:49.480201.480201 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.480312.480312 client.py:127] Model loaded
DEBUG 01-07 14:54:49.480619.480619 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.480670.480670 cuda_h.py:19] end restore2model cost 0.0003223419189453125 seconds
DEBUG 01-07 14:54:49.480102.480102 cuda_h.py:19] end sllm_worker_task cost 0.00893092155456543 seconds
INFO 01-07 14:54:49.480965.480965 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7a377283-06f8-4df0-9463-39acd8d219a5
DEBUG 01-07 14:54:49.481378.481378 cuda_h.py:19] end load_into_gpu_async cost 0.0009331703186035156 seconds
DEBUG 01-07 14:54:49.481697.481697 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.481402.481402 cuda_h.py:19] end restore_tensors2 cost 0.000286102294921875 seconds
DEBUG 01-07 14:54:49.481132.481132 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017423629760742188 seconds
DEBUG 01-07 14:54:49.481988.481988 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.483290.483290 cuda_h.py:19] end restore2model cost 0.0018808841705322266 seconds
DEBUG 01-07 14:54:49.483584.483584 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.483620.483620 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.483562.483562 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-07 14:54:49.483398.483398 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.483770.483770 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.483288.483288 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.483269.483269 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 03a26cd9-3ea0-44aa-8187-a83a135ad174
DEBUG 01-07 14:54:49.484829.484829 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.484507.484507 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 03a26cd9-3ea0-44aa-8187-a83a135ad174
DEBUG 01-07 14:54:49.484429.484429 cuda_h.py:19] end load_into_gpu_async cost 0.0010805130004882812 seconds
DEBUG 01-07 14:54:49.484986.484986 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.485221.485221 cuda_h.py:19] end restore_tensors2 cost 0.00025343894958496094 seconds
DEBUG 01-07 14:54:49.485712.485712 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018219947814941406 seconds
DEBUG 01-07 14:54:49.485707.485707 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.487926.487926 cuda_h.py:19] end restore2model cost 0.0017852783203125 seconds
DEBUG 01-07 14:54:49.487908.487908 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00755620002746582 seconds
DEBUG 01-07 14:54:49.487750.487750 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.487614.487614 lmp.py:816] 
DEBUG 01-07 14:54:49.487614.487614 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.487887.487887 cuda_h.py:19] end cpu_experts_submit cost 0.00011205673217773438 seconds
DEBUG 01-07 14:54:49.487775.487775 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.492537.492537 mlpmodule.py:749] group tensors cost 0.005202293395996094 s
DEBUG 01-07 14:54:49.494793.494793 mlpmodule.py:787] pad cost 0.0010859966278076172 s
DEBUG 01-07 14:54:49.494406.494406 mlpmodule.py:793] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-07 14:54:49.494131.494131 mlpmodule.py:798] move to cpu cost 3.886222839355469e-05 s
DEBUG 01-07 14:54:49.503802.503802 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.503197.503197 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.503757.503757 mlpmodule.py:818] group_w3 first element: 0.0157470703125
WARNING 01-07 14:54:49.503788.503788 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.518473.518473 mlpmodule.py:838] group einsum cost 0.023798465728759766 s
DEBUG 01-07 14:54:49.519950.519950 mlpmodule.py:846] cpy2cputensor cost 0.00042557716369628906 s
DEBUG 01-07 14:54:49.521021.521021 cuda_h.py:19] end wait_cetm_experts cost 0.034198760986328125 seconds
DEBUG 01-07 14:54:49.521428.521428 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.522664.522664 cuda_h.py:19] end gpu_sexperts cost 0.00048160552978515625 seconds
DEBUG 01-07 14:54:49.522030.522030 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.522735.522735 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2172927856445312e-05 seconds
DEBUG 01-07 14:54:49.522391.522391 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.522485.522485 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7a377283-06f8-4df0-9463-39acd8d219a5
INFO 01-07 14:54:49.525139.525139 client.py:127] Model loaded
INFO 01-07 14:54:49.525445.525445 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 03a26cd9-3ea0-44aa-8187-a83a135ad174
INFO 01-07 14:54:49.525935.525935 client.py:127] Model loaded
DEBUG 01-07 14:54:49.526904.526904 cuda_h.py:19] end wait_experts_multi_device cost 0.0036122798919677734 seconds
DEBUG 01-07 14:54:49.526752.526752 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.526668.526668 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:49.527296.527296 mlpmodule.py:533] gpu group tensors cost 0.0004951953887939453 s
DEBUG 01-07 14:54:49.528647.528647 mlpmodule.py:566] gpu pad cost 0.0013186931610107422 s
DEBUG 01-07 14:54:49.529523.529523 mlpmodule.py:584] gpu group einsum cost 0.0005612373352050781 s
DEBUG 01-07 14:54:49.529922.529922 mlpmodule.py:707]  experts func einsum cost 0.042447566986083984 s
DEBUG 01-07 14:54:49.531721.531721 mlpmodule.py:656] gpu experts func einsum cost 0.004668474197387695 s
DEBUG 01-07 14:54:49.531095.531095 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:49.532638.532638 mlpmodule.py:533] gpu group tensors cost 0.0004947185516357422 s
DEBUG 01-07 14:54:49.533763.533763 mlpmodule.py:566] gpu pad cost 0.0012989044189453125 s
DEBUG 01-07 14:54:49.534708.534708 mlpmodule.py:584] gpu group einsum cost 0.0004341602325439453 s
DEBUG 01-07 14:54:49.536584.536584 mlpmodule.py:656] gpu experts func einsum cost 0.004213094711303711 s
DEBUG 01-07 14:54:49.536568.536568 cuda_h.py:19] end gpu_experts_multi_device cost 0.010298967361450195 seconds
DEBUG 01-07 14:54:49.536459.536459 cuda_h.py:19] end layer_moe_generate_multi_device_9 cost 0.05939912796020508 seconds
DEBUG 01-07 14:54:49.536209.536209 lmp.py:194] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-07 14:54:49.536733.536733 lmp.py:153] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-07 14:54:49.536191.536191 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 14:54:49.536185.536185 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 14:54:49.536306.536306 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:49.536102.536102 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.745887756347656e-05 seconds
DEBUG 01-07 14:54:49.536460.536460 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.536627.536627 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.537146.537146 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.537672.537672 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.537170.537170 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.537829.537829 cuda_h.py:19] end allocate_cuda_memory cost 0.0002760887145996094 seconds
DEBUG 01-07 14:54:49.537508.537508 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.537840.537840 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.537802.537802 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.537835.537835 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 93cd4d86-e676-4ab4-9579-fa8767ea94e3
DEBUG 01-07 14:54:49.537706.537706 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.537277.537277 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.538915.538915 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 93cd4d86-e676-4ab4-9579-fa8767ea94e3
DEBUG 01-07 14:54:49.538129.538129 cuda_h.py:19] end load_into_gpu_async cost 0.0009150505065917969 seconds
DEBUG 01-07 14:54:49.538640.538640 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.538861.538861 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 14:54:49.538187.538187 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015058517456054688 seconds
INFO 01-07 14:54:49.538970.538970 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 93cd4d86-e676-4ab4-9579-fa8767ea94e3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.541873.541873 cuda_h.py:19] end self_attn cost 0.0037162303924560547 seconds
DEBUG 01-07 14:54:49.542070.542070 cuda_h.py:19] end iln_self_attn_paln cost 0.0051271915435791016 seconds
DEBUG 01-07 14:54:49.542561.542561 cuda_h.py:10] start layer_moe_generate_multi_device_10
DEBUG 01-07 14:54:49.542463.542463 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.542903.542903 cuda_h.py:19] end gate cost 0.0006427764892578125 seconds
DEBUG 01-07 14:54:49.542302.542302 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.543680.543680 lmp.py:744] 
DEBUG 01-07 14:54:49.543680.543680 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.543059.543059 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.543093.543093 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.543120.543120 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.543001.543001 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.543929.543929 lmp.py:749] 
DEBUG 01-07 14:54:49.543929.543929 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.543333.543333 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.543414.543414 lmp.py:767]   Expert 43 |     20 | CPU
DEBUG 01-07 14:54:49.543772.543772 lmp.py:767]   Expert 27 |     35 | CPU
DEBUG 01-07 14:54:49.543700.543700 lmp.py:767]   Expert 34 |     52 | CPU
DEBUG 01-07 14:54:49.543627.543627 lmp.py:767]   Expert 56 |     53 | CPU
DEBUG 01-07 14:54:49.543270.543270 lmp.py:767]   Expert  3 |     57 | CPU
DEBUG 01-07 14:54:49.543198.543198 lmp.py:767]   Expert 26 |     57 | CPU
DEBUG 01-07 14:54:49.543887.543887 lmp.py:767]   Expert  4 |     69 | CPU
DEBUG 01-07 14:54:49.543054.543054 lmp.py:767]   Expert 61 |     78 | CPU
DEBUG 01-07 14:54:49.543981.543981 lmp.py:767]   Expert 14 |     93 | CPU
DEBUG 01-07 14:54:49.543671.543671 lmp.py:767]   Expert 38 |     99 | CPU
DEBUG 01-07 14:54:49.543883.543883 lmp.py:767]   Expert  2 |    113 | CPU
DEBUG 01-07 14:54:49.543811.543811 lmp.py:767]   Expert 17 |    119 | CPU
DEBUG 01-07 14:54:49.543738.543738 lmp.py:767]   Expert 22 |    121 | CPU
DEBUG 01-07 14:54:49.543666.543666 lmp.py:767]   Expert 47 |    127 | CPU
DEBUG 01-07 14:54:49.543355.543355 lmp.py:767]   Expert 55 |    128 | CPU
DEBUG 01-07 14:54:49.543045.543045 lmp.py:767]   Expert 37 |    131 | CPU
DEBUG 01-07 14:54:49.543257.543257 lmp.py:767]   Expert 54 |    132 | CPU
DEBUG 01-07 14:54:49.543947.543947 lmp.py:767]   Expert 28 |    134 | CPU
DEBUG 01-07 14:54:49.543397.543397 lmp.py:767]   Expert 51 |    143 | CPU
DEBUG 01-07 14:54:49.543279.543279 lmp.py:767]   Expert  7 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543922.543922 lmp.py:767]   Expert 15 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543042.543042 lmp.py:767]   Expert  5 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543400.543400 lmp.py:767]   Expert 12 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543281.543281 lmp.py:767]   Expert 48 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543924.543924 lmp.py:767]   Expert 60 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543567.543567 lmp.py:767]   Expert 63 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543210.543210 lmp.py:767]   Expert 45 |    153 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543615.543615 lmp.py:767]   Expert 19 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543258.543258 lmp.py:767]   Expert  6 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543616.543616 lmp.py:767]   Expert 52 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543259.543259 lmp.py:767]   Expert 57 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543379.543379 lmp.py:767]   Expert 18 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.543022.543022 lmp.py:767]   Expert 50 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.543426.543426 lmp.py:767]   Expert 31 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544831.544831 lmp.py:767]   Expert 44 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544997.544997 lmp.py:767]   Expert 13 |    186 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544878.544878 lmp.py:767]   Expert 30 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544998.544998 lmp.py:767]   Expert 23 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544403.544403 lmp.py:767]   Expert 39 |    195 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544807.544807 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544212.544212 lmp.py:767]   Expert 53 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544855.544855 lmp.py:767]   Expert 59 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544736.544736 lmp.py:767]   Expert 29 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544856.544856 lmp.py:767]   Expert 20 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544499.544499 lmp.py:767]   Expert 16 |    210 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544665.544665 lmp.py:767]   Expert 36 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544070.544070 lmp.py:767]   Expert 41 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544713.544713 lmp.py:767]   Expert 25 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544117.544117 lmp.py:767]   Expert 32 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544045.544045 lmp.py:767]   Expert 49 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544926.544926 lmp.py:767]   Expert 46 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544046.544046 lmp.py:767]   Expert  8 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544451.544451 lmp.py:767]   Expert 10 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544855.544855 lmp.py:767]   Expert 42 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544260.544260 lmp.py:767]   Expert 62 |    270 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544625.544625 lmp.py:767]   Expert 35 |    274 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544221.544221 lmp.py:767]   Expert 33 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544103.544103 lmp.py:767]   Expert 58 |    293 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544984.544984 lmp.py:767]   Expert  9 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544104.544104 lmp.py:767]   Expert 40 |    391 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544747.544747 lmp.py:767]   Expert  0 |    427 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544390.544390 lmp.py:767]   Expert 11 |    437 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544795.544795 lmp.py:767]   Expert 24 |    567 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.544199.544199 lmp.py:767]   Expert  1 |    650 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.544650.544650 lmp.py:769] 
DEBUG 01-07 14:54:49.544650.544650 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.544578.544578 lmp.py:770]   CPU:   1761 tokens
DEBUG 01-07 14:54:49.544698.544698 lmp.py:774]   cuda:1:   5337 tokens (23 experts)
DEBUG 01-07 14:54:49.544579.544579 lmp.py:774]   cuda:2:   5190 tokens (22 experts)
DEBUG 01-07 14:54:49.544983.544983 lmp.py:775]   Total GPU:  10527 tokens
DEBUG 01-07 14:54:49.544673.544673 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.544673.544673 lmp.py:776] 
DEBUG 01-07 14:54:49.544084.544084 cuda_h.py:19] end experts_map_get cost 0.00177764892578125 seconds
DEBUG 01-07 14:54:49.544204.544204 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.544742.544742 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.544845.544845 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.545502.545502 cuda_h.py:19] end allocate_cuda_memory cost 0.0002067089080810547 seconds
DEBUG 01-07 14:54:49.545643.545643 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.545598.545598 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.545169.545169 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.545011.545011 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c96d957d-10f6-42fb-b0c2-57934c050dd3
DEBUG 01-07 14:54:49.545936.545936 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.545233.545233 client.py:127] Model loaded
DEBUG 01-07 14:54:49.545076.545076 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.546502.546502 cuda_h.py:19] end restore2model cost 0.0004127025604248047 seconds
DEBUG 01-07 14:54:49.546093.546093 cuda_h.py:19] end sllm_worker_task cost 0.009023904800415039 seconds
INFO 01-07 14:54:49.546016.546016 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c96d957d-10f6-42fb-b0c2-57934c050dd3
DEBUG 01-07 14:54:49.546290.546290 cuda_h.py:19] end load_into_gpu_async cost 0.0010704994201660156 seconds
DEBUG 01-07 14:54:49.546469.546469 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.546969.546969 cuda_h.py:19] end restore_tensors2 cost 0.0002734661102294922 seconds
DEBUG 01-07 14:54:49.546461.546461 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018773078918457031 seconds
DEBUG 01-07 14:54:49.546939.546939 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.548308.548308 cuda_h.py:19] end restore2model cost 0.0018947124481201172 seconds
DEBUG 01-07 14:54:49.548257.548257 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.548824.548824 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.548527.548527 cuda_h.py:19] end allocate_cuda_memory cost 0.0002052783966064453 seconds
DEBUG 01-07 14:54:49.549079.549079 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.549689.549689 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.549829.549829 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.549525.549525 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f2b4257-6aa9-4610-a718-2257f43fa911
DEBUG 01-07 14:54:49.549993.549993 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.550934.550934 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f2b4257-6aa9-4610-a718-2257f43fa911
DEBUG 01-07 14:54:49.550379.550379 cuda_h.py:19] end load_into_gpu_async cost 0.0010342597961425781 seconds
DEBUG 01-07 14:54:49.550221.550221 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.550051.550051 cuda_h.py:19] end restore_tensors2 cost 0.00023627281188964844 seconds
DEBUG 01-07 14:54:49.550682.550682 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017600059509277344 seconds
DEBUG 01-07 14:54:49.550199.550199 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.552352.552352 cuda_h.py:19] end restore2model cost 0.0017712116241455078 seconds
DEBUG 01-07 14:54:49.552797.552797 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076141357421875 seconds
DEBUG 01-07 14:54:49.552639.552639 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.552139.552139 lmp.py:816] 
DEBUG 01-07 14:54:49.552139.552139 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.552690.552690 cuda_h.py:19] end cpu_experts_submit cost 0.00011849403381347656 seconds
DEBUG 01-07 14:54:49.552863.552863 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.564598.564598 mlpmodule.py:749] group tensors cost 0.011717796325683594 s
DEBUG 01-07 14:54:49.565931.565931 mlpmodule.py:787] pad cost 0.000978231430053711 s
DEBUG 01-07 14:54:49.566120.566120 mlpmodule.py:793] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-07 14:54:49.566606.566606 mlpmodule.py:798] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-07 14:54:49.574387.574387 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.574783.574783 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.574502.574502 mlpmodule.py:818] group_w3 first element: -0.0213623046875
WARNING 01-07 14:54:49.574903.574903 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.588583.588583 mlpmodule.py:838] group einsum cost 0.022383689880371094 s
DEBUG 01-07 14:54:49.589266.589266 mlpmodule.py:846] cpy2cputensor cost 0.00044465065002441406 s
DEBUG 01-07 14:54:49.592244.592244 cuda_h.py:19] end wait_cetm_experts cost 0.03981137275695801 seconds
DEBUG 01-07 14:54:49.592248.592248 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.592384.592384 cuda_h.py:19] end gpu_sexperts cost 0.0004782676696777344 seconds
DEBUG 01-07 14:54:49.593512.593512 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.593978.593978 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:49.593158.593158 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.593443.593443 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c96d957d-10f6-42fb-b0c2-57934c050dd3
INFO 01-07 14:54:49.594433.594433 client.py:127] Model loaded
INFO 01-07 14:54:49.594216.594216 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f2b4257-6aa9-4610-a718-2257f43fa911
INFO 01-07 14:54:49.594547.594547 client.py:127] Model loaded
DEBUG 01-07 14:54:49.594946.594946 cuda_h.py:19] end wait_experts_multi_device cost 0.0013585090637207031 seconds
DEBUG 01-07 14:54:49.594318.594318 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.594994.594994 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:49.595940.595940 mlpmodule.py:533] gpu group tensors cost 0.0004913806915283203 s
DEBUG 01-07 14:54:49.597357.597357 mlpmodule.py:566] gpu pad cost 0.0012967586517333984 s
DEBUG 01-07 14:54:49.597524.597524 mlpmodule.py:584] gpu group einsum cost 0.0005586147308349609 s
DEBUG 01-07 14:54:49.599589.599589 mlpmodule.py:656] gpu experts func einsum cost 0.004622459411621094 s
DEBUG 01-07 14:54:49.600315.600315 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:49.601615.601615 mlpmodule.py:533] gpu group tensors cost 0.0004820823669433594 s
DEBUG 01-07 14:54:49.601494.601494 mlpmodule.py:707]  experts func einsum cost 0.048601388931274414 s
DEBUG 01-07 14:54:49.602848.602848 mlpmodule.py:566] gpu pad cost 0.0013761520385742188 s
DEBUG 01-07 14:54:49.603184.603184 mlpmodule.py:584] gpu group einsum cost 0.0004420280456542969 s
DEBUG 01-07 14:54:49.605735.605735 mlpmodule.py:656] gpu experts func einsum cost 0.004468202590942383 s
DEBUG 01-07 14:54:49.605561.605561 cuda_h.py:19] end gpu_experts_multi_device cost 0.010614871978759766 seconds
DEBUG 01-07 14:54:49.605915.605915 cuda_h.py:19] end layer_moe_generate_multi_device_10 cost 0.06315255165100098 seconds
DEBUG 01-07 14:54:49.605049.605049 lmp.py:194] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-07 14:54:49.605335.605335 lmp.py:153] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-07 14:54:49.605031.605031 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 14:54:49.605549.605549 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 14:54:49.605623.605623 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:49.605657.605657 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 14:54:49.605492.605492 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.605176.605176 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.605854.605854 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.605260.605260 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.606275.606275 cuda_h.py:19] end allocate_cuda_memory cost 0.00022339820861816406 seconds
DEBUG 01-07 14:54:49.606933.606933 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.606643.606643 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.606035.606035 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.606738.606738 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 091086f8-e724-44f1-b16c-cc6c2678a753
DEBUG 01-07 14:54:49.606701.606701 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.606088.606088 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.606496.606496 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.607083.607083 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 091086f8-e724-44f1-b16c-cc6c2678a753
DEBUG 01-07 14:54:49.607966.607966 cuda_h.py:19] end load_into_gpu_async cost 0.0009396076202392578 seconds
DEBUG 01-07 14:54:49.607192.607192 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.607175.607175 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 14:54:49.607500.607500 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014612674713134766 seconds
INFO 01-07 14:54:49.607144.607144 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 091086f8-e724-44f1-b16c-cc6c2678a753
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.610816.610816 cuda_h.py:19] end self_attn cost 0.003589153289794922 seconds
DEBUG 01-07 14:54:49.610927.610927 cuda_h.py:19] end iln_self_attn_paln cost 0.005032777786254883 seconds
DEBUG 01-07 14:54:49.610895.610895 cuda_h.py:10] start layer_moe_generate_multi_device_11
DEBUG 01-07 14:54:49.610035.610035 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.611859.611859 cuda_h.py:19] end gate cost 0.0006442070007324219 seconds
DEBUG 01-07 14:54:49.611212.611212 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.611405.611405 lmp.py:744] 
DEBUG 01-07 14:54:49.611405.611405 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.612545.612545 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.612149.612149 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.612414.612414 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.612772.612772 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.612700.612700 lmp.py:749] 
DEBUG 01-07 14:54:49.612700.612700 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.612582.612582 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.612423.612423 lmp.py:767]   Expert 39 |     15 | CPU
DEBUG 01-07 14:54:49.612782.612782 lmp.py:767]   Expert 13 |     20 | CPU
DEBUG 01-07 14:54:49.612948.612948 lmp.py:767]   Expert 49 |     41 | CPU
DEBUG 01-07 14:54:49.612591.612591 lmp.py:767]   Expert 35 |     53 | CPU
DEBUG 01-07 14:54:49.612234.612234 lmp.py:767]   Expert 19 |     64 | CPU
DEBUG 01-07 14:54:49.612638.612638 lmp.py:767]   Expert  9 |     75 | CPU
DEBUG 01-07 14:54:49.612804.612804 lmp.py:767]   Expert 26 |     75 | CPU
DEBUG 01-07 14:54:49.612732.612732 lmp.py:767]   Expert 32 |     77 | CPU
DEBUG 01-07 14:54:49.612421.612421 lmp.py:767]   Expert 41 |     77 | CPU
DEBUG 01-07 14:54:49.612349.612349 lmp.py:767]   Expert 33 |     79 | CPU
DEBUG 01-07 14:54:49.612277.612277 lmp.py:767]   Expert 23 |     86 | CPU
DEBUG 01-07 14:54:49.612397.612397 lmp.py:767]   Expert 46 |     88 | CPU
DEBUG 01-07 14:54:49.612040.612040 lmp.py:767]   Expert 31 |     90 | CPU
DEBUG 01-07 14:54:49.612683.612683 lmp.py:767]   Expert 18 |     94 | CPU
DEBUG 01-07 14:54:49.612955.612955 lmp.py:767]   Expert 38 |    100 | CPU
DEBUG 01-07 14:54:49.612360.612360 lmp.py:767]   Expert  6 |    104 | CPU
DEBUG 01-07 14:54:49.612049.612049 lmp.py:767]   Expert 17 |    105 | CPU
DEBUG 01-07 14:54:49.612453.612453 lmp.py:767]   Expert  3 |    107 | CPU
DEBUG 01-07 14:54:49.612381.612381 lmp.py:767]   Expert 20 |    116 | CPU
DEBUG 01-07 14:54:49.612693.612693 lmp.py:767]   Expert 50 |    129 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612290.612290 lmp.py:767]   Expert 59 |    129 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612409.612409 lmp.py:767]   Expert 62 |    130 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612052.612052 lmp.py:767]   Expert 40 |    131 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612695.612695 lmp.py:767]   Expert 61 |    132 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612815.612815 lmp.py:767]   Expert 43 |    134 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612458.612458 lmp.py:767]   Expert 15 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612101.612101 lmp.py:767]   Expert 16 |    137 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612983.612983 lmp.py:767]   Expert 44 |    137 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612387.612387 lmp.py:767]   Expert 63 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612745.612745 lmp.py:767]   Expert  2 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612388.612388 lmp.py:767]   Expert 42 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612031.612031 lmp.py:767]   Expert 36 |    150 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612913.612913 lmp.py:767]   Expert 10 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612317.612317 lmp.py:767]   Expert  5 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612914.612914 lmp.py:767]   Expert 34 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612034.612034 lmp.py:767]   Expert 45 |    189 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612915.612915 lmp.py:767]   Expert 27 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612320.612320 lmp.py:767]   Expert 52 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612486.612486 lmp.py:767]   Expert 48 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612890.612890 lmp.py:767]   Expert 60 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612295.612295 lmp.py:767]   Expert 51 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612938.612938 lmp.py:767]   Expert 56 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612058.612058 lmp.py:767]   Expert 53 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612178.612178 lmp.py:767]   Expert 24 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612059.612059 lmp.py:767]   Expert  7 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612702.612702 lmp.py:767]   Expert  8 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.612345.612345 lmp.py:767]   Expert 57 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.612749.612749 lmp.py:767]   Expert 47 |    254 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613154.613154 lmp.py:767]   Expert 29 |    259 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613274.613274 lmp.py:767]   Expert 21 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613870.613870 lmp.py:767]   Expert  0 |    283 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613275.613275 lmp.py:767]   Expert  4 |    284 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613918.613918 lmp.py:767]   Expert 14 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613323.613323 lmp.py:767]   Expert 22 |    317 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613727.613727 lmp.py:767]   Expert 55 |    317 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613893.613893 lmp.py:767]   Expert  1 |    318 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613298.613298 lmp.py:767]   Expert 37 |    319 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613702.613702 lmp.py:767]   Expert 58 |    320 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613345.613345 lmp.py:767]   Expert 54 |    334 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613227.613227 lmp.py:767]   Expert 28 |    354 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613631.613631 lmp.py:767]   Expert 12 |    378 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613036.613036 lmp.py:767]   Expert 25 |    402 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613440.613440 lmp.py:767]   Expert 11 |    404 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.613607.613607 lmp.py:767]   Expert 30 |    837 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.613819.613819 lmp.py:769] 
DEBUG 01-07 14:54:49.613819.613819 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.613224.613224 lmp.py:770]   CPU:   1466 tokens
DEBUG 01-07 14:54:49.613582.613582 lmp.py:774]   cuda:1:   5411 tokens (22 experts)
DEBUG 01-07 14:54:49.613225.613225 lmp.py:774]   cuda:2:   5411 tokens (23 experts)
DEBUG 01-07 14:54:49.613676.613676 lmp.py:775]   Total GPU:  10822 tokens
DEBUG 01-07 14:54:49.613365.613365 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.613365.613365 lmp.py:776] 
DEBUG 01-07 14:54:49.613538.613538 cuda_h.py:19] end experts_map_get cost 0.0017924308776855469 seconds
DEBUG 01-07 14:54:49.613419.613419 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.613818.613818 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.613676.613676 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.613081.613081 cuda_h.py:19] end allocate_cuda_memory cost 0.00019741058349609375 seconds
DEBUG 01-07 14:54:49.613078.613078 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.613026.613026 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.613074.613074 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.613439.613439 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 60781495-29d4-4be8-a161-c9a52093da6a
DEBUG 01-07 14:54:49.614788.614788 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.614707.614707 client.py:127] Model loaded
DEBUG 01-07 14:54:49.614205.614205 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.614595.614595 cuda_h.py:19] end restore2model cost 0.00032448768615722656 seconds
DEBUG 01-07 14:54:49.614172.614172 cuda_h.py:19] end sllm_worker_task cost 0.008915424346923828 seconds
INFO 01-07 14:54:49.614705.614705 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 60781495-29d4-4be8-a161-c9a52093da6a
DEBUG 01-07 14:54:49.614694.614694 cuda_h.py:19] end load_into_gpu_async cost 0.0009467601776123047 seconds
DEBUG 01-07 14:54:49.614396.614396 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.615591.615591 cuda_h.py:19] end restore_tensors2 cost 0.00025916099548339844 seconds
DEBUG 01-07 14:54:49.615414.615414 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017504692077636719 seconds
DEBUG 01-07 14:54:49.615223.615223 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.617185.617185 cuda_h.py:19] end restore2model cost 0.0018048286437988281 seconds
DEBUG 01-07 14:54:49.617565.617565 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.617078.617078 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.617358.617358 cuda_h.py:19] end allocate_cuda_memory cost 0.00020885467529296875 seconds
DEBUG 01-07 14:54:49.617101.617101 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.617712.617712 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.617468.617468 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.617925.617925 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4e0a5b82-ee9f-4a3b-8ac9-7eca72229986
DEBUG 01-07 14:54:49.617162.617162 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.618795.618795 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4e0a5b82-ee9f-4a3b-8ac9-7eca72229986
DEBUG 01-07 14:54:49.618287.618287 cuda_h.py:19] end load_into_gpu_async cost 0.0009489059448242188 seconds
DEBUG 01-07 14:54:49.618367.618367 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.618104.618104 cuda_h.py:19] end restore_tensors2 cost 0.00023794174194335938 seconds
DEBUG 01-07 14:54:49.618735.618735 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016782283782958984 seconds
DEBUG 01-07 14:54:49.618537.618537 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.620085.620085 cuda_h.py:19] end restore2model cost 0.001886129379272461 seconds
DEBUG 01-07 14:54:49.620576.620576 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007433414459228516 seconds
DEBUG 01-07 14:54:49.620703.620703 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.620997.620997 lmp.py:816] 
DEBUG 01-07 14:54:49.620997.620997 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.621018.621018 cuda_h.py:19] end cpu_experts_submit cost 0.00010347366333007812 seconds
DEBUG 01-07 14:54:49.621953.621953 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.626390.626390 mlpmodule.py:749] group tensors cost 0.005426168441772461 s
DEBUG 01-07 14:54:49.628025.628025 mlpmodule.py:787] pad cost 0.0015530586242675781 s
DEBUG 01-07 14:54:49.629254.629254 mlpmodule.py:793] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-07 14:54:49.629814.629814 mlpmodule.py:798] move to cpu cost 4.2438507080078125e-05 s
DEBUG 01-07 14:54:49.637747.637747 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.637335.637335 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.637543.637543 mlpmodule.py:818] group_w3 first element: 0.01373291015625
WARNING 01-07 14:54:49.637798.637798 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.651287.651287 mlpmodule.py:838] group einsum cost 0.022734403610229492 s
DEBUG 01-07 14:54:49.652810.652810 mlpmodule.py:846] cpy2cputensor cost 0.0004162788391113281 s
DEBUG 01-07 14:54:49.654802.654802 cuda_h.py:19] end wait_cetm_experts cost 0.033835411071777344 seconds
DEBUG 01-07 14:54:49.655355.655355 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.655704.655704 cuda_h.py:19] end gpu_sexperts cost 0.0004928112030029297 seconds
DEBUG 01-07 14:54:49.655309.655309 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.655775.655775 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:49.655477.655477 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.655379.655379 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 60781495-29d4-4be8-a161-c9a52093da6a
INFO 01-07 14:54:49.657156.657156 client.py:127] Model loaded
INFO 01-07 14:54:49.657800.657800 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4e0a5b82-ee9f-4a3b-8ac9-7eca72229986
INFO 01-07 14:54:49.658869.658869 client.py:127] Model loaded
DEBUG 01-07 14:54:49.658547.658547 cuda_h.py:19] end wait_experts_multi_device cost 0.002828359603881836 seconds
DEBUG 01-07 14:54:49.658210.658210 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.658384.658384 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.659331.659331 mlpmodule.py:533] gpu group tensors cost 0.0005097389221191406 s
DEBUG 01-07 14:54:49.661024.661024 mlpmodule.py:566] gpu pad cost 0.001428842544555664 s
DEBUG 01-07 14:54:49.661916.661916 mlpmodule.py:584] gpu group einsum cost 0.0004520416259765625 s
DEBUG 01-07 14:54:49.663969.663969 mlpmodule.py:707]  experts func einsum cost 0.04210925102233887 s
DEBUG 01-07 14:54:49.664531.664531 mlpmodule.py:656] gpu experts func einsum cost 0.004693508148193359 s
DEBUG 01-07 14:54:49.664754.664754 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.665947.665947 mlpmodule.py:533] gpu group tensors cost 0.00045228004455566406 s
DEBUG 01-07 14:54:49.666063.666063 mlpmodule.py:566] gpu pad cost 0.0012214183807373047 s
DEBUG 01-07 14:54:49.667538.667538 mlpmodule.py:584] gpu group einsum cost 0.00048661231994628906 s
DEBUG 01-07 14:54:49.668003.668003 mlpmodule.py:656] gpu experts func einsum cost 0.004111051559448242 s
DEBUG 01-07 14:54:49.668146.668146 cuda_h.py:19] end gpu_experts_multi_device cost 0.010314226150512695 seconds
DEBUG 01-07 14:54:49.669116.669116 cuda_h.py:19] end layer_moe_generate_multi_device_11 cost 0.058173418045043945 seconds
DEBUG 01-07 14:54:49.669640.669640 lmp.py:194] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-07 14:54:49.669403.669403 lmp.py:153] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-07 14:54:49.669861.669861 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 14:54:49.669140.669140 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 14:54:49.669069.669069 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.765655517578125e-05 seconds
DEBUG 01-07 14:54:49.669103.669103 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.626678466796875e-05 seconds
DEBUG 01-07 14:54:49.669223.669223 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.669476.669476 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.669804.669804 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.669381.669381 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.669822.669822 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.670402.670402 cuda_h.py:19] end allocate_cuda_memory cost 0.0002846717834472656 seconds
DEBUG 01-07 14:54:49.670160.670160 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.670300.670300 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.670884.670884 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.670441.670441 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f01e1054-ee44-4d46-9c0f-cf5f02d3b00e
DEBUG 01-07 14:54:49.670404.670404 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.670699.670699 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.671034.671034 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f01e1054-ee44-4d46-9c0f-cf5f02d3b00e
DEBUG 01-07 14:54:49.671467.671467 cuda_h.py:19] end load_into_gpu_async cost 0.0010349750518798828 seconds
DEBUG 01-07 14:54:49.671316.671316 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.671014.671014 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-07 14:54:49.671101.671101 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016324520111083984 seconds
INFO 01-07 14:54:49.671891.671891 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f01e1054-ee44-4d46-9c0f-cf5f02d3b00e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.674005.674005 cuda_h.py:19] end self_attn cost 0.003742694854736328 seconds
DEBUG 01-07 14:54:49.674247.674247 cuda_h.py:19] end iln_self_attn_paln cost 0.0052568912506103516 seconds
DEBUG 01-07 14:54:49.674838.674838 cuda_h.py:10] start layer_moe_generate_multi_device_12
DEBUG 01-07 14:54:49.674979.674979 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.675948.675948 cuda_h.py:19] end gate cost 0.0006458759307861328 seconds
DEBUG 01-07 14:54:49.675493.675493 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.675971.675971 lmp.py:744] 
DEBUG 01-07 14:54:49.675971.675971 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.675588.675588 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.676906.676906 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.676934.676934 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.676815.676815 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.676743.676743 lmp.py:749] 
DEBUG 01-07 14:54:49.676743.676743 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.676386.676386 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.676704.676704 lmp.py:767]   Expert 12 |     18 | CPU
DEBUG 01-07 14:54:49.676824.676824 lmp.py:767]   Expert 47 |     26 | CPU
DEBUG 01-07 14:54:49.676752.676752 lmp.py:767]   Expert 38 |     31 | CPU
DEBUG 01-07 14:54:49.676680.676680 lmp.py:767]   Expert 27 |     34 | CPU
DEBUG 01-07 14:54:49.676369.676369 lmp.py:767]   Expert 16 |     37 | CPU
DEBUG 01-07 14:54:49.676774.676774 lmp.py:767]   Expert 52 |     39 | CPU
DEBUG 01-07 14:54:49.676701.676701 lmp.py:767]   Expert 63 |     50 | CPU
DEBUG 01-07 14:54:49.676629.676629 lmp.py:767]   Expert  4 |     52 | CPU
DEBUG 01-07 14:54:49.676080.676080 lmp.py:767]   Expert 43 |     62 | CPU
DEBUG 01-07 14:54:49.676484.676484 lmp.py:767]   Expert 61 |     65 | CPU
DEBUG 01-07 14:54:49.676412.676412 lmp.py:767]   Expert 44 |     68 | CPU
DEBUG 01-07 14:54:49.676863.676863 lmp.py:767]   Expert 34 |     73 | CPU
DEBUG 01-07 14:54:49.676552.676552 lmp.py:767]   Expert 53 |     78 | CPU
DEBUG 01-07 14:54:49.676480.676480 lmp.py:767]   Expert  0 |     89 | CPU
DEBUG 01-07 14:54:49.676885.676885 lmp.py:767]   Expert 32 |     92 | CPU
DEBUG 01-07 14:54:49.676574.676574 lmp.py:767]   Expert 37 |     92 | CPU
DEBUG 01-07 14:54:49.676939.676939 lmp.py:767]   Expert 13 |     98 | CPU
DEBUG 01-07 14:54:49.676105.676105 lmp.py:767]   Expert 39 |    113 | CPU
DEBUG 01-07 14:54:49.676794.676794 lmp.py:767]   Expert 11 |    118 | CPU
DEBUG 01-07 14:54:49.676914.676914 lmp.py:767]   Expert 21 |    119 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676557.676557 lmp.py:767]   Expert  8 |    126 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676677.676677 lmp.py:767]   Expert 20 |    128 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676797.676797 lmp.py:767]   Expert 60 |    136 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676917.676917 lmp.py:767]   Expert 57 |    138 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676560.676560 lmp.py:767]   Expert 14 |    139 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676726.676726 lmp.py:767]   Expert 22 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676892.676892 lmp.py:767]   Expert  2 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676058.676058 lmp.py:767]   Expert 17 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676463.676463 lmp.py:767]   Expert 45 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676106.676106 lmp.py:767]   Expert 18 |    158 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676702.676702 lmp.py:767]   Expert 23 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676107.676107 lmp.py:767]   Expert  7 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676511.676511 lmp.py:767]   Expert 58 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676439.676439 lmp.py:767]   Expert 30 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676367.676367 lmp.py:767]   Expert 42 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676294.676294 lmp.py:767]   Expert 48 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676222.676222 lmp.py:767]   Expert 49 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676342.676342 lmp.py:767]   Expert 55 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676223.676223 lmp.py:767]   Expert 62 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676389.676389 lmp.py:767]   Expert 35 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676794.676794 lmp.py:767]   Expert 51 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676960.676960 lmp.py:767]   Expert 29 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676126.676126 lmp.py:767]   Expert  6 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676531.676531 lmp.py:767]   Expert 25 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676697.676697 lmp.py:767]   Expert  1 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676055.676055 lmp.py:767]   Expert 36 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676652.676652 lmp.py:767]   Expert 31 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676056.676056 lmp.py:767]   Expert 28 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676461.676461 lmp.py:767]   Expert 41 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.676627.676627 lmp.py:767]   Expert  5 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.676032.676032 lmp.py:767]   Expert 54 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677436.677436 lmp.py:767]   Expert 19 |    236 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677602.677602 lmp.py:767]   Expert  9 |    244 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677769.677769 lmp.py:767]   Expert 24 |    255 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677650.677650 lmp.py:767]   Expert 50 |    290 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677293.677293 lmp.py:767]   Expert 46 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677697.677697 lmp.py:767]   Expert 59 |    311 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677102.677102 lmp.py:767]   Expert 56 |    387 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677268.677268 lmp.py:767]   Expert 26 |    403 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677434.677434 lmp.py:767]   Expert 33 |    421 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677600.677600 lmp.py:767]   Expert  3 |    581 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677767.677767 lmp.py:767]   Expert 15 |    649 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677648.677648 lmp.py:767]   Expert 10 |    653 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.677006.677006 lmp.py:767]   Expert 40 |    791 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.677934.677934 lmp.py:769] 
DEBUG 01-07 14:54:49.677934.677934 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.677100.677100 lmp.py:770]   CPU:   1235 tokens
DEBUG 01-07 14:54:49.677981.677981 lmp.py:774]   cuda:1:   5586 tokens (23 experts)
DEBUG 01-07 14:54:49.677386.677386 lmp.py:774]   cuda:2:   5467 tokens (22 experts)
DEBUG 01-07 14:54:49.677837.677837 lmp.py:775]   Total GPU:  11053 tokens
DEBUG 01-07 14:54:49.677049.677049 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.677049.677049 lmp.py:776] 
DEBUG 01-07 14:54:49.677938.677938 cuda_h.py:19] end experts_map_get cost 0.0017743110656738281 seconds
DEBUG 01-07 14:54:49.677011.677011 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.677741.677741 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.677745.677745 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.677303.677303 cuda_h.py:19] end allocate_cuda_memory cost 0.00023865699768066406 seconds
DEBUG 01-07 14:54:49.677591.677591 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.677585.677585 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.677156.677156 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.677805.677805 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 56617bc6-5c93-4275-ba0a-35adf1f0e454
DEBUG 01-07 14:54:49.678970.678970 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.678789.678789 client.py:127] Model loaded
DEBUG 01-07 14:54:49.678480.678480 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.678936.678936 cuda_h.py:19] end restore2model cost 0.0003383159637451172 seconds
DEBUG 01-07 14:54:49.678467.678467 cuda_h.py:19] end sllm_worker_task cost 0.009097099304199219 seconds
INFO 01-07 14:54:49.678074.678074 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 56617bc6-5c93-4275-ba0a-35adf1f0e454
DEBUG 01-07 14:54:49.678255.678255 cuda_h.py:19] end load_into_gpu_async cost 0.0010187625885009766 seconds
DEBUG 01-07 14:54:49.678527.678527 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.679974.679974 cuda_h.py:19] end restore_tensors2 cost 0.00026988983154296875 seconds
DEBUG 01-07 14:54:49.679320.679320 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001844167709350586 seconds
DEBUG 01-07 14:54:49.679699.679699 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.681803.681803 cuda_h.py:19] end restore2model cost 0.001909017562866211 seconds
DEBUG 01-07 14:54:49.681898.681898 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.681796.681796 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.681612.681612 cuda_h.py:19] end allocate_cuda_memory cost 0.00021791458129882812 seconds
DEBUG 01-07 14:54:49.681025.681025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.681827.681827 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.681252.681252 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.681186.681186 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d0d28f9-ea56-446d-a71f-2d7e96fdf724
DEBUG 01-07 14:54:49.681469.681469 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.682239.682239 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d0d28f9-ea56-446d-a71f-2d7e96fdf724
DEBUG 01-07 14:54:49.682354.682354 cuda_h.py:19] end load_into_gpu_async cost 0.001088857650756836 seconds
DEBUG 01-07 14:54:49.682672.682672 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.683555.683555 cuda_h.py:19] end restore_tensors2 cost 0.00024008750915527344 seconds
DEBUG 01-07 14:54:49.683232.683232 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018334388732910156 seconds
DEBUG 01-07 14:54:49.683180.683180 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.685890.685890 cuda_h.py:19] end restore2model cost 0.001795053482055664 seconds
DEBUG 01-07 14:54:49.685481.685481 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076982975006103516 seconds
DEBUG 01-07 14:54:49.685562.685562 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.685240.685240 lmp.py:816] 
DEBUG 01-07 14:54:49.685240.685240 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.685599.685599 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 14:54:49.685487.685487 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.697654.697654 mlpmodule.py:749] group tensors cost 0.011761665344238281 s
DEBUG 01-07 14:54:49.698543.698543 mlpmodule.py:787] pad cost 0.0009908676147460938 s
DEBUG 01-07 14:54:49.698480.698480 mlpmodule.py:793] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-07 14:54:49.698475.698475 mlpmodule.py:798] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-07 14:54:49.707416.707416 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.707573.707573 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.707940.707940 mlpmodule.py:818] group_w3 first element: -0.0162353515625
WARNING 01-07 14:54:49.707302.707302 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.721938.721938 mlpmodule.py:838] group einsum cost 0.022255420684814453 s
DEBUG 01-07 14:54:49.721545.721545 mlpmodule.py:846] cpy2cputensor cost 0.00035881996154785156 s
DEBUG 01-07 14:54:49.724435.724435 cuda_h.py:19] end wait_cetm_experts cost 0.038750410079956055 seconds
DEBUG 01-07 14:54:49.724710.724710 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.724625.724625 cuda_h.py:19] end gpu_sexperts cost 0.0005576610565185547 seconds
DEBUG 01-07 14:54:49.724481.724481 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.724093.724093 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 14:54:49.724226.724226 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.724889.724889 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 56617bc6-5c93-4275-ba0a-35adf1f0e454
INFO 01-07 14:54:49.725296.725296 client.py:127] Model loaded
INFO 01-07 14:54:49.725370.725370 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d0d28f9-ea56-446d-a71f-2d7e96fdf724
INFO 01-07 14:54:49.726104.726104 client.py:127] Model loaded
DEBUG 01-07 14:54:49.726788.726788 cuda_h.py:19] end wait_experts_multi_device cost 0.001331329345703125 seconds
DEBUG 01-07 14:54:49.726160.726160 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.726791.726791 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:49.727903.727903 mlpmodule.py:533] gpu group tensors cost 0.0004889965057373047 s
DEBUG 01-07 14:54:49.728259.728259 mlpmodule.py:566] gpu pad cost 0.0012812614440917969 s
DEBUG 01-07 14:54:49.729221.729221 mlpmodule.py:584] gpu group einsum cost 0.0005540847778320312 s
DEBUG 01-07 14:54:49.734244.734244 mlpmodule.py:656] gpu experts func einsum cost 0.0075185298919677734 s
DEBUG 01-07 14:54:49.734042.734042 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:49.735704.735704 mlpmodule.py:533] gpu group tensors cost 0.00047016143798828125 s
DEBUG 01-07 14:54:49.736497.736497 mlpmodule.py:707]  experts func einsum cost 0.05119895935058594 s
DEBUG 01-07 14:54:49.737406.737406 mlpmodule.py:566] gpu pad cost 0.0013356208801269531 s
DEBUG 01-07 14:54:49.737092.737092 mlpmodule.py:584] gpu group einsum cost 0.0004374980926513672 s
DEBUG 01-07 14:54:49.739402.739402 mlpmodule.py:656] gpu experts func einsum cost 0.004111289978027344 s
DEBUG 01-07 14:54:49.739922.739922 cuda_h.py:19] end gpu_experts_multi_device cost 0.013033628463745117 seconds
DEBUG 01-07 14:54:49.739461.739461 cuda_h.py:19] end layer_moe_generate_multi_device_12 cost 0.06465029716491699 seconds
DEBUG 01-07 14:54:49.739839.739839 lmp.py:194] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-07 14:54:49.739363.739363 lmp.py:153] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-07 14:54:49.739344.739344 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 14:54:49.739623.739623 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 14:54:49.739936.739936 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 14:54:49.739924.739924 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.91278076171875e-05 seconds
DEBUG 01-07 14:54:49.739521.739521 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.739535.739535 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.739817.739817 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.740918.740918 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.740782.740782 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.740972.740972 cuda_h.py:19] end allocate_cuda_memory cost 0.00027632713317871094 seconds
DEBUG 01-07 14:54:49.740756.740756 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.740757.740757 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.740341.740341 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.740614.740614 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54817ee0-e172-4861-aa9c-87f14a9df603
DEBUG 01-07 14:54:49.740815.740815 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.740062.740062 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.741322.741322 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54817ee0-e172-4861-aa9c-87f14a9df603
DEBUG 01-07 14:54:49.741595.741595 cuda_h.py:19] end load_into_gpu_async cost 0.0008985996246337891 seconds
DEBUG 01-07 14:54:49.741298.741298 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.741997.741997 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-07 14:54:49.741607.741607 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015053749084472656 seconds
INFO 01-07 14:54:49.741973.741973 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54817ee0-e172-4861-aa9c-87f14a9df603
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.744544.744544 cuda_h.py:19] end self_attn cost 0.003661632537841797 seconds
DEBUG 01-07 14:54:49.745125.745125 cuda_h.py:19] end iln_self_attn_paln cost 0.005156755447387695 seconds
DEBUG 01-07 14:54:49.745524.745524 cuda_h.py:10] start layer_moe_generate_multi_device_13
DEBUG 01-07 14:54:49.745710.745710 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.745057.745057 cuda_h.py:19] end gate cost 0.0006432533264160156 seconds
DEBUG 01-07 14:54:49.745887.745887 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.746974.746974 lmp.py:744] 
DEBUG 01-07 14:54:49.746974.746974 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.746591.746591 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.746432.746432 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.746698.746698 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.746056.746056 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.746461.746461 lmp.py:749] 
DEBUG 01-07 14:54:49.746461.746461 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.746865.746865 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.746707.746707 lmp.py:767]   Expert 19 |     22 | CPU
DEBUG 01-07 14:54:49.746827.746827 lmp.py:767]   Expert 30 |     26 | CPU
DEBUG 01-07 14:54:49.746993.746993 lmp.py:767]   Expert 42 |     26 | CPU
DEBUG 01-07 14:54:49.746636.746636 lmp.py:767]   Expert 32 |     39 | CPU
DEBUG 01-07 14:54:49.746802.746802 lmp.py:767]   Expert  6 |     56 | CPU
DEBUG 01-07 14:54:49.746253.746253 lmp.py:767]   Expert 53 |     74 | CPU
DEBUG 01-07 14:54:49.746181.746181 lmp.py:767]   Expert  5 |     78 | CPU
DEBUG 01-07 14:54:49.746109.746109 lmp.py:767]   Expert  1 |     79 | CPU
DEBUG 01-07 14:54:49.746036.746036 lmp.py:767]   Expert 13 |    117 | CPU
DEBUG 01-07 14:54:49.746964.746964 lmp.py:767]   Expert  9 |    128 | CPU
DEBUG 01-07 14:54:49.746653.746653 lmp.py:767]   Expert 58 |    129 | CPU
DEBUG 01-07 14:54:49.746104.746104 lmp.py:767]   Expert 63 |    129 | CPU
DEBUG 01-07 14:54:49.746509.746509 lmp.py:767]   Expert 34 |    131 | CPU
DEBUG 01-07 14:54:49.746675.746675 lmp.py:767]   Expert 26 |    134 | CPU
DEBUG 01-07 14:54:49.746841.746841 lmp.py:767]   Expert 50 |    134 | CPU
DEBUG 01-07 14:54:49.746530.746530 lmp.py:767]   Expert 11 |    136 | CPU
DEBUG 01-07 14:54:49.746458.746458 lmp.py:767]   Expert 31 |    138 | CPU
DEBUG 01-07 14:54:49.746386.746386 lmp.py:767]   Expert 40 |    140 | CPU
DEBUG 01-07 14:54:49.746552.746552 lmp.py:767]   Expert 59 |    143 | CPU
DEBUG 01-07 14:54:49.746195.746195 lmp.py:767]   Expert 12 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746076.746076 lmp.py:767]   Expert  2 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746958.746958 lmp.py:767]   Expert 18 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746601.746601 lmp.py:767]   Expert 56 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746959.746959 lmp.py:767]   Expert 20 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746363.746363 lmp.py:767]   Expert 48 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746722.746722 lmp.py:767]   Expert  4 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746842.746842 lmp.py:767]   Expert 46 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746723.746723 lmp.py:767]   Expert 33 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746604.746604 lmp.py:767]   Expert 61 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746486.746486 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746129.746129 lmp.py:767]   Expert 10 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.746772.746772 lmp.py:767]   Expert 55 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746415.746415 lmp.py:767]   Expert 51 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.746011.746011 lmp.py:767]   Expert 36 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747369.747369 lmp.py:767]   Expert  8 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747012.747012 lmp.py:767]   Expert 52 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747894.747894 lmp.py:767]   Expert 37 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747537.747537 lmp.py:767]   Expert  0 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747180.747180 lmp.py:767]   Expert 57 |    207 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747061.747061 lmp.py:767]   Expert 39 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747466.747466 lmp.py:767]   Expert 25 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747109.747109 lmp.py:767]   Expert 62 |    237 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747990.747990 lmp.py:767]   Expert 38 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747587.747587 lmp.py:767]   Expert  7 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747707.747707 lmp.py:767]   Expert 27 |    246 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747111.747111 lmp.py:767]   Expert  3 |    247 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747516.747516 lmp.py:767]   Expert 24 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747682.747682 lmp.py:767]   Expert 60 |    255 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747563.747563 lmp.py:767]   Expert 28 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747968.747968 lmp.py:767]   Expert 49 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747372.747372 lmp.py:767]   Expert 21 |    262 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747254.747254 lmp.py:767]   Expert 16 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747135.747135 lmp.py:767]   Expert 43 |    268 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747301.747301 lmp.py:767]   Expert 23 |    274 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747706.747706 lmp.py:767]   Expert 29 |    279 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747349.747349 lmp.py:767]   Expert 22 |    288 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747753.747753 lmp.py:767]   Expert 15 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747919.747919 lmp.py:767]   Expert 47 |    294 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747847.747847 lmp.py:767]   Expert 41 |    299 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747252.747252 lmp.py:767]   Expert 44 |    309 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747895.747895 lmp.py:767]   Expert 54 |    353 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747061.747061 lmp.py:767]   Expert 14 |    373 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747181.747181 lmp.py:767]   Expert 17 |    408 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.747301.747301 lmp.py:767]   Expert 45 |    444 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.747573.747573 lmp.py:769] 
DEBUG 01-07 14:54:49.747573.747573 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.747739.747739 lmp.py:770]   CPU:   1859 tokens
DEBUG 01-07 14:54:49.747859.747859 lmp.py:774]   cuda:1:   5286 tokens (23 experts)
DEBUG 01-07 14:54:49.747025.747025 lmp.py:774]   cuda:2:   5143 tokens (22 experts)
DEBUG 01-07 14:54:49.747191.747191 lmp.py:775]   Total GPU:  10429 tokens
DEBUG 01-07 14:54:49.747357.747357 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.747357.747357 lmp.py:776] 
DEBUG 01-07 14:54:49.747722.747722 cuda_h.py:19] end experts_map_get cost 0.0017809867858886719 seconds
DEBUG 01-07 14:54:49.747842.747842 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.747857.747857 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.747192.747192 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.748994.748994 cuda_h.py:19] end allocate_cuda_memory cost 0.0002086162567138672 seconds
DEBUG 01-07 14:54:49.748997.748997 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.748230.748230 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.748847.748847 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.748258.748258 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eeffc4a7-4322-45e6-898b-ff8eaa51950f
DEBUG 01-07 14:54:49.748700.748700 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.748970.748970 client.py:127] Model loaded
DEBUG 01-07 14:54:49.748052.748052 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.749955.749955 cuda_h.py:19] end restore2model cost 0.00041365623474121094 seconds
DEBUG 01-07 14:54:49.749354.749354 cuda_h.py:19] end sllm_worker_task cost 0.009072303771972656 seconds
INFO 01-07 14:54:49.749231.749231 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eeffc4a7-4322-45e6-898b-ff8eaa51950f
DEBUG 01-07 14:54:49.749935.749935 cuda_h.py:19] end load_into_gpu_async cost 0.0010783672332763672 seconds
DEBUG 01-07 14:54:49.749638.749638 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.749422.749422 cuda_h.py:19] end restore_tensors2 cost 0.0002734661102294922 seconds
DEBUG 01-07 14:54:49.749960.749960 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018794536590576172 seconds
DEBUG 01-07 14:54:49.749769.749769 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.751728.751728 cuda_h.py:19] end restore2model cost 0.0019073486328125 seconds
DEBUG 01-07 14:54:49.751247.751247 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.751522.751522 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.752047.752047 cuda_h.py:19] end allocate_cuda_memory cost 0.00021219253540039062 seconds
DEBUG 01-07 14:54:49.752221.752221 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.752546.752546 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.752925.752925 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.752336.752336 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5066d5b-76bc-44e9-ba81-a97abbb0424a
DEBUG 01-07 14:54:49.752228.752228 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.753183.753183 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5066d5b-76bc-44e9-ba81-a97abbb0424a
DEBUG 01-07 14:54:49.753013.753013 cuda_h.py:19] end load_into_gpu_async cost 0.0010793209075927734 seconds
DEBUG 01-07 14:54:49.753332.753332 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.753625.753625 cuda_h.py:19] end restore_tensors2 cost 0.00022721290588378906 seconds
DEBUG 01-07 14:54:49.753586.753586 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001802682876586914 seconds
DEBUG 01-07 14:54:49.753150.753150 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.755437.755437 cuda_h.py:19] end restore2model cost 0.0017986297607421875 seconds
DEBUG 01-07 14:54:49.755836.755836 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076982975006103516 seconds
DEBUG 01-07 14:54:49.755916.755916 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.755164.755164 lmp.py:816] 
DEBUG 01-07 14:54:49.755164.755164 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.755808.755808 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 14:54:49.755742.755742 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.767110.767110 mlpmodule.py:749] group tensors cost 0.01166224479675293 s
DEBUG 01-07 14:54:49.769156.769156 mlpmodule.py:787] pad cost 0.0010464191436767578 s
DEBUG 01-07 14:54:49.769570.769570 mlpmodule.py:793] create cpu tensor cost 3.719329833984375e-05 s
DEBUG 01-07 14:54:49.769042.769042 mlpmodule.py:798] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-07 14:54:49.777255.777255 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.777704.777704 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.777833.777833 mlpmodule.py:818] group_w3 first element: -0.0211181640625
WARNING 01-07 14:54:49.777824.777824 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.791610.791610 mlpmodule.py:838] group einsum cost 0.022436857223510742 s
DEBUG 01-07 14:54:49.792252.792252 mlpmodule.py:846] cpy2cputensor cost 0.0004131793975830078 s
DEBUG 01-07 14:54:49.794093.794093 cuda_h.py:19] end wait_cetm_experts cost 0.03912162780761719 seconds
DEBUG 01-07 14:54:49.794308.794308 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.795544.795544 cuda_h.py:19] end gpu_sexperts cost 0.00048041343688964844 seconds
DEBUG 01-07 14:54:49.795387.795387 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.795615.795615 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:49.795556.795556 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.795981.795981 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eeffc4a7-4322-45e6-898b-ff8eaa51950f
INFO 01-07 14:54:49.796361.796361 client.py:127] Model loaded
INFO 01-07 14:54:49.796244.796244 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5066d5b-76bc-44e9-ba81-a97abbb0424a
INFO 01-07 14:54:49.796283.796283 client.py:127] Model loaded
DEBUG 01-07 14:54:49.796728.796728 cuda_h.py:19] end wait_experts_multi_device cost 0.001360177993774414 seconds
DEBUG 01-07 14:54:49.796862.796862 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.796823.796823 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:49.798723.798723 mlpmodule.py:533] gpu group tensors cost 0.00048041343688964844 s
DEBUG 01-07 14:54:49.799641.799641 mlpmodule.py:566] gpu pad cost 0.0012440681457519531 s
DEBUG 01-07 14:54:49.799857.799857 mlpmodule.py:584] gpu group einsum cost 0.0004363059997558594 s
DEBUG 01-07 14:54:49.801257.801257 mlpmodule.py:656] gpu experts func einsum cost 0.00417637825012207 s
DEBUG 01-07 14:54:49.802274.802274 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:49.802717.802717 mlpmodule.py:533] gpu group tensors cost 0.0004792213439941406 s
DEBUG 01-07 14:54:49.804496.804496 mlpmodule.py:566] gpu pad cost 0.0012547969818115234 s
DEBUG 01-07 14:54:49.804034.804034 mlpmodule.py:584] gpu group einsum cost 0.00037360191345214844 s
DEBUG 01-07 14:54:49.805537.805537 mlpmodule.py:707]  experts func einsum cost 0.050131797790527344 s
DEBUG 01-07 14:54:49.806461.806461 mlpmodule.py:656] gpu experts func einsum cost 0.0042877197265625 s
DEBUG 01-07 14:54:49.806902.806902 cuda_h.py:19] end gpu_experts_multi_device cost 0.009867429733276367 seconds
DEBUG 01-07 14:54:49.806448.806448 cuda_h.py:19] end layer_moe_generate_multi_device_13 cost 0.0617823600769043 seconds
DEBUG 01-07 14:54:49.807471.807471 lmp.py:194] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-07 14:54:49.807764.807764 lmp.py:153] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-07 14:54:49.807937.807937 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 14:54:49.807693.807693 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 14:54:49.807337.807337 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 14:54:49.807324.807324 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.745887756347656e-05 seconds
DEBUG 01-07 14:54:49.807590.807590 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.807287.807287 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.807660.807660 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.807994.807994 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.807393.807393 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.807131.807131 cuda_h.py:19] end allocate_cuda_memory cost 0.000263214111328125 seconds
DEBUG 01-07 14:54:49.807080.807080 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.808459.808459 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.808566.808566 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.808031.808031 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2dba67fd-f1b1-4060-92ae-f1df5ae9ff1f
DEBUG 01-07 14:54:49.808233.808233 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.808913.808913 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.808856.808856 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2dba67fd-f1b1-4060-92ae-f1df5ae9ff1f
DEBUG 01-07 14:54:49.808361.808361 cuda_h.py:19] end load_into_gpu_async cost 0.0008397102355957031 seconds
DEBUG 01-07 14:54:49.808680.808680 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.808902.808902 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 14:54:49.809419.809419 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014088153839111328 seconds
INFO 01-07 14:54:49.809621.809621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2dba67fd-f1b1-4060-92ae-f1df5ae9ff1f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.812311.812311 cuda_h.py:19] end self_attn cost 0.0037055015563964844 seconds
DEBUG 01-07 14:54:49.812944.812944 cuda_h.py:19] end iln_self_attn_paln cost 0.005216836929321289 seconds
DEBUG 01-07 14:54:49.812535.812535 cuda_h.py:10] start layer_moe_generate_multi_device_14
DEBUG 01-07 14:54:49.812914.812914 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.813083.813083 cuda_h.py:19] end gate cost 0.0006520748138427734 seconds
DEBUG 01-07 14:54:49.813627.813627 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.813105.813105 lmp.py:744] 
DEBUG 01-07 14:54:49.813105.813105 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.813245.813245 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.813087.813087 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.813591.813591 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.813711.813711 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.813116.813116 lmp.py:749] 
DEBUG 01-07 14:54:49.813116.813116 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.814520.814520 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.814839.814839 lmp.py:767]   Expert  7 |     31 | CPU
DEBUG 01-07 14:54:49.814959.814959 lmp.py:767]   Expert 34 |     32 | CPU
DEBUG 01-07 14:54:49.814363.814363 lmp.py:767]   Expert 13 |     39 | CPU
DEBUG 01-07 14:54:49.814529.814529 lmp.py:767]   Expert 54 |     76 | CPU
DEBUG 01-07 14:54:49.814934.814934 lmp.py:767]   Expert 18 |     82 | CPU
DEBUG 01-07 14:54:49.814577.814577 lmp.py:767]   Expert 39 |     87 | CPU
DEBUG 01-07 14:54:49.814458.814458 lmp.py:767]   Expert 49 |     87 | CPU
DEBUG 01-07 14:54:49.814148.814148 lmp.py:767]   Expert 59 |    102 | CPU
DEBUG 01-07 14:54:49.814314.814314 lmp.py:767]   Expert 21 |    103 | CPU
DEBUG 01-07 14:54:49.814241.814241 lmp.py:767]   Expert  0 |    108 | CPU
DEBUG 01-07 14:54:49.814169.814169 lmp.py:767]   Expert 16 |    108 | CPU
DEBUG 01-07 14:54:49.814335.814335 lmp.py:767]   Expert 41 |    116 | CPU
DEBUG 01-07 14:54:49.814263.814263 lmp.py:767]   Expert 45 |    122 | CPU
DEBUG 01-07 14:54:49.814429.814429 lmp.py:767]   Expert 22 |    123 | CPU
DEBUG 01-07 14:54:49.814118.814118 lmp.py:767]   Expert 15 |    124 | CPU
DEBUG 01-07 14:54:49.814715.814715 lmp.py:767]   Expert 61 |    126 | CPU
DEBUG 01-07 14:54:49.814120.814120 lmp.py:767]   Expert 17 |    127 | CPU
DEBUG 01-07 14:54:49.814286.814286 lmp.py:767]   Expert 52 |    135 | CPU
DEBUG 01-07 14:54:49.814975.814975 lmp.py:767]   Expert 12 |    139 | CPU
DEBUG 01-07 14:54:49.814095.814095 lmp.py:767]   Expert  8 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814692.814692 lmp.py:767]   Expert 38 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814811.814811 lmp.py:767]   Expert 35 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814693.814693 lmp.py:767]   Expert 48 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814051.814051 lmp.py:767]   Expert 31 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814409.814409 lmp.py:767]   Expert 53 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814767.814767 lmp.py:767]   Expert 36 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814410.814410 lmp.py:767]   Expert 50 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814053.814053 lmp.py:767]   Expert 40 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814696.814696 lmp.py:767]   Expert 60 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814578.814578 lmp.py:767]   Expert 27 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814221.814221 lmp.py:767]   Expert 19 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814579.814579 lmp.py:767]   Expert 29 |    199 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814222.814222 lmp.py:767]   Expert  4 |    201 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814627.814627 lmp.py:767]   Expert 30 |    207 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814031.814031 lmp.py:767]   Expert 20 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814912.814912 lmp.py:767]   Expert 11 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814794.814794 lmp.py:767]   Expert 46 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814198.814198 lmp.py:767]   Expert 26 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814318.814318 lmp.py:767]   Expert 57 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814438.814438 lmp.py:767]   Expert  6 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814081.814081 lmp.py:767]   Expert 43 |    230 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814486.814486 lmp.py:767]   Expert  2 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814129.814129 lmp.py:767]   Expert 23 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814772.814772 lmp.py:767]   Expert 33 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814653.814653 lmp.py:767]   Expert 42 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814296.814296 lmp.py:767]   Expert 55 |    254 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814177.814177 lmp.py:767]   Expert 32 |    255 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814820.814820 lmp.py:767]   Expert 56 |    256 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814225.814225 lmp.py:767]   Expert  9 |    262 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814106.814106 lmp.py:767]   Expert 28 |    263 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814749.814749 lmp.py:767]   Expert  3 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814392.814392 lmp.py:767]   Expert 14 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814274.814274 lmp.py:767]   Expert 44 |    269 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.814393.814393 lmp.py:767]   Expert 51 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.814275.814275 lmp.py:767]   Expert  1 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.815679.815679 lmp.py:767]   Expert 58 |    280 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.815084.815084 lmp.py:767]   Expert 63 |    291 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.815442.815442 lmp.py:767]   Expert 47 |    292 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.815324.815324 lmp.py:767]   Expert 37 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.815205.815205 lmp.py:767]   Expert 62 |    305 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.815086.815086 lmp.py:767]   Expert 24 |    311 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.815729.815729 lmp.py:767]   Expert 10 |    315 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.815372.815372 lmp.py:767]   Expert 25 |    316 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.815015.815015 lmp.py:767]   Expert  5 |    362 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.815705.815705 lmp.py:769] 
DEBUG 01-07 14:54:49.815705.815705 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.815347.815347 lmp.py:770]   CPU:   1867 tokens
DEBUG 01-07 14:54:49.815944.815944 lmp.py:774]   cuda:1:   5141 tokens (22 experts)
DEBUG 01-07 14:54:49.815349.815349 lmp.py:774]   cuda:2:   5280 tokens (23 experts)
DEBUG 01-07 14:54:49.815038.815038 lmp.py:775]   Total GPU:  10421 tokens
DEBUG 01-07 14:54:49.815204.815204 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.815204.815204 lmp.py:776] 
DEBUG 01-07 14:54:49.815139.815139 cuda_h.py:19] end experts_map_get cost 0.001786947250366211 seconds
DEBUG 01-07 14:54:49.815497.815497 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.815558.815558 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.815800.815800 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.815889.815889 cuda_h.py:19] end allocate_cuda_memory cost 0.00024366378784179688 seconds
DEBUG 01-07 14:54:49.815639.815639 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.815918.815918 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.815873.815873 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.815000.815000 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fa786ee7-5724-4c7f-8872-d36012d447a7
DEBUG 01-07 14:54:49.816780.816780 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.816400.816400 client.py:127] Model loaded
DEBUG 01-07 14:54:49.816475.816475 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.816408.816408 cuda_h.py:19] end restore2model cost 0.0003390312194824219 seconds
DEBUG 01-07 14:54:49.816178.816178 cuda_h.py:19] end sllm_worker_task cost 0.009060144424438477 seconds
INFO 01-07 14:54:49.816683.816683 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fa786ee7-5724-4c7f-8872-d36012d447a7
DEBUG 01-07 14:54:49.816851.816851 cuda_h.py:19] end load_into_gpu_async cost 0.0009658336639404297 seconds
DEBUG 01-07 14:54:49.816462.816462 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.817862.817862 cuda_h.py:19] end restore_tensors2 cost 0.00027108192443847656 seconds
DEBUG 01-07 14:54:49.817208.817208 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017905235290527344 seconds
DEBUG 01-07 14:54:49.817971.817971 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.819197.819197 cuda_h.py:19] end restore2model cost 0.0017895698547363281 seconds
DEBUG 01-07 14:54:49.819623.819623 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.819905.819905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.819953.819953 cuda_h.py:19] end allocate_cuda_memory cost 0.00021386146545410156 seconds
DEBUG 01-07 14:54:49.819127.819127 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.819737.819737 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.819685.819685 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.819666.819666 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7f9a8c9-0104-41b7-8bb7-375aa987c876
DEBUG 01-07 14:54:49.819995.819995 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.820522.820522 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7f9a8c9-0104-41b7-8bb7-375aa987c876
DEBUG 01-07 14:54:49.820066.820066 cuda_h.py:19] end load_into_gpu_async cost 0.0011184215545654297 seconds
DEBUG 01-07 14:54:49.820577.820577 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.820645.820645 cuda_h.py:19] end restore_tensors2 cost 0.00023651123046875 seconds
DEBUG 01-07 14:54:49.820038.820038 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018579959869384766 seconds
DEBUG 01-07 14:54:49.820794.820794 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.822281.822281 cuda_h.py:19] end restore2model cost 0.0018770694732666016 seconds
DEBUG 01-07 14:54:49.822965.822965 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00762629508972168 seconds
DEBUG 01-07 14:54:49.822376.822376 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.823193.823193 lmp.py:816] 
DEBUG 01-07 14:54:49.823193.823193 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.823460.823460 cuda_h.py:19] end cpu_experts_submit cost 0.00010919570922851562 seconds
DEBUG 01-07 14:54:49.823679.823679 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.828518.828518 mlpmodule.py:749] group tensors cost 0.005336761474609375 s
DEBUG 01-07 14:54:49.830070.830070 mlpmodule.py:787] pad cost 0.001157999038696289 s
DEBUG 01-07 14:54:49.830358.830358 mlpmodule.py:793] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-07 14:54:49.830937.830937 mlpmodule.py:798] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-07 14:54:49.839124.839124 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.839235.839235 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.839742.839742 mlpmodule.py:818] group_w3 first element: 0.000789642333984375
WARNING 01-07 14:54:49.839713.839713 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.855126.855126 mlpmodule.py:838] group einsum cost 0.02457571029663086 s
DEBUG 01-07 14:54:49.855982.855982 mlpmodule.py:846] cpy2cputensor cost 0.0004553794860839844 s
DEBUG 01-07 14:54:49.858584.858584 cuda_h.py:19] end wait_cetm_experts cost 0.035059213638305664 seconds
DEBUG 01-07 14:54:49.858574.858574 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.858585.858585 cuda_h.py:19] end gpu_sexperts cost 0.0004899501800537109 seconds
DEBUG 01-07 14:54:49.858196.858196 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.858285.858285 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 14:54:49.859802.859802 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.859227.859227 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fa786ee7-5724-4c7f-8872-d36012d447a7
INFO 01-07 14:54:49.859103.859103 client.py:127] Model loaded
INFO 01-07 14:54:49.859317.859317 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7f9a8c9-0104-41b7-8bb7-375aa987c876
INFO 01-07 14:54:49.860760.860760 client.py:127] Model loaded
DEBUG 01-07 14:54:49.860298.860298 cuda_h.py:19] end wait_experts_multi_device cost 0.0013189315795898438 seconds
DEBUG 01-07 14:54:49.860921.860921 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.860221.860221 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.861085.861085 mlpmodule.py:533] gpu group tensors cost 0.0005023479461669922 s
DEBUG 01-07 14:54:49.863343.863343 mlpmodule.py:566] gpu pad cost 0.001318216323852539 s
DEBUG 01-07 14:54:49.863490.863490 mlpmodule.py:584] gpu group einsum cost 0.0005524158477783203 s
DEBUG 01-07 14:54:49.865041.865041 mlpmodule.py:707]  experts func einsum cost 0.042154550552368164 s
DEBUG 01-07 14:54:49.866733.866733 mlpmodule.py:656] gpu experts func einsum cost 0.004841327667236328 s
DEBUG 01-07 14:54:49.866075.866075 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.867577.867577 mlpmodule.py:533] gpu group tensors cost 0.00045752525329589844 s
DEBUG 01-07 14:54:49.868919.868919 mlpmodule.py:566] gpu pad cost 0.001247406005859375 s
DEBUG 01-07 14:54:49.868440.868440 mlpmodule.py:584] gpu group einsum cost 0.00045561790466308594 s
DEBUG 01-07 14:54:49.870467.870467 mlpmodule.py:656] gpu experts func einsum cost 0.004273414611816406 s
DEBUG 01-07 14:54:49.871172.871172 cuda_h.py:19] end gpu_experts_multi_device cost 0.010617494583129883 seconds
DEBUG 01-07 14:54:49.871294.871294 cuda_h.py:19] end layer_moe_generate_multi_device_14 cost 0.05842924118041992 seconds
DEBUG 01-07 14:54:49.871541.871541 lmp.py:194] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-07 14:54:49.871258.871258 lmp.py:153] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-07 14:54:49.871192.871192 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 14:54:49.871425.871425 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 14:54:49.871784.871784 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 14:54:49.871249.871249 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.841255187988281e-05 seconds
DEBUG 01-07 14:54:49.871038.871038 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.871496.871496 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.871730.871730 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.871105.871105 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.871696.871696 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.872408.872408 cuda_h.py:19] end allocate_cuda_memory cost 0.0002796649932861328 seconds
DEBUG 01-07 14:54:49.872642.872642 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.872782.872782 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.872128.872128 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.872162.872162 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 012655dc-b238-423f-9b3c-aeee3e25a1ed
DEBUG 01-07 14:54:49.872808.872808 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.872643.872643 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.873718.873718 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 012655dc-b238-423f-9b3c-aeee3e25a1ed
DEBUG 01-07 14:54:49.873130.873130 cuda_h.py:19] end load_into_gpu_async cost 0.0008878707885742188 seconds
DEBUG 01-07 14:54:49.873926.873926 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.873002.873002 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 14:54:49.873804.873804 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001468658447265625 seconds
INFO 01-07 14:54:49.873409.873409 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 012655dc-b238-423f-9b3c-aeee3e25a1ed
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.876260.876260 cuda_h.py:19] end self_attn cost 0.0037126541137695312 seconds
DEBUG 01-07 14:54:49.876317.876317 cuda_h.py:19] end iln_self_attn_paln cost 0.0051615238189697266 seconds
DEBUG 01-07 14:54:49.876478.876478 cuda_h.py:10] start layer_moe_generate_multi_device_15
DEBUG 01-07 14:54:49.876903.876903 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.877641.877641 cuda_h.py:19] end gate cost 0.0006515979766845703 seconds
DEBUG 01-07 14:54:49.877947.877947 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.878617.878617 lmp.py:744] 
DEBUG 01-07 14:54:49.878617.878617 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.878996.878996 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.878838.878838 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.878342.878342 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.878461.878461 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.878389.878389 lmp.py:749] 
DEBUG 01-07 14:54:49.878389.878389 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.878032.878032 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.878351.878351 lmp.py:767]   Expert 15 |     62 | CPU
DEBUG 01-07 14:54:49.878709.878709 lmp.py:767]   Expert 41 |     68 | CPU
DEBUG 01-07 14:54:49.878875.878875 lmp.py:767]   Expert 63 |     73 | CPU
DEBUG 01-07 14:54:49.878280.878280 lmp.py:767]   Expert  0 |     76 | CPU
DEBUG 01-07 14:54:49.878969.878969 lmp.py:767]   Expert 20 |     83 | CPU
DEBUG 01-07 14:54:49.878374.878374 lmp.py:767]   Expert 45 |     89 | CPU
DEBUG 01-07 14:54:49.878778.878778 lmp.py:767]   Expert  7 |     93 | CPU
DEBUG 01-07 14:54:49.878706.878706 lmp.py:767]   Expert 54 |    100 | CPU
DEBUG 01-07 14:54:49.878395.878395 lmp.py:767]   Expert 28 |    103 | CPU
DEBUG 01-07 14:54:49.878084.878084 lmp.py:767]   Expert 40 |    116 | CPU
DEBUG 01-07 14:54:49.878774.878774 lmp.py:767]   Expert 12 |    117 | CPU
DEBUG 01-07 14:54:49.878701.878701 lmp.py:767]   Expert 52 |    120 | CPU
DEBUG 01-07 14:54:49.878152.878152 lmp.py:767]   Expert  5 |    125 | CPU
DEBUG 01-07 14:54:49.878557.878557 lmp.py:767]   Expert 59 |    125 | CPU
DEBUG 01-07 14:54:49.878723.878723 lmp.py:767]   Expert  4 |    129 | CPU
DEBUG 01-07 14:54:49.878412.878412 lmp.py:767]   Expert 62 |    131 | CPU
DEBUG 01-07 14:54:49.878102.878102 lmp.py:767]   Expert 34 |    133 | CPU
DEBUG 01-07 14:54:49.878791.878791 lmp.py:767]   Expert 13 |    137 | CPU
DEBUG 01-07 14:54:49.878242.878242 lmp.py:767]   Expert 42 |    139 | CPU
DEBUG 01-07 14:54:49.878362.878362 lmp.py:767]   Expert 55 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878720.878720 lmp.py:767]   Expert 61 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878363.878363 lmp.py:767]   Expert 21 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878006.878006 lmp.py:767]   Expert 14 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878364.878364 lmp.py:767]   Expert 22 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878722.878722 lmp.py:767]   Expert 10 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878365.878365 lmp.py:767]   Expert 51 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878770.878770 lmp.py:767]   Expert 32 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878174.878174 lmp.py:767]   Expert 53 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878341.878341 lmp.py:767]   Expert 25 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878745.878745 lmp.py:767]   Expert 50 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878911.878911 lmp.py:767]   Expert 47 |    175 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878031.878031 lmp.py:767]   Expert  1 |    177 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878674.878674 lmp.py:767]   Expert 19 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878840.878840 lmp.py:767]   Expert 26 |    179 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878483.878483 lmp.py:767]   Expert 35 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878888.878888 lmp.py:767]   Expert  6 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878054.878054 lmp.py:767]   Expert 11 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878697.878697 lmp.py:767]   Expert  2 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878578.878578 lmp.py:767]   Expert 30 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878460.878460 lmp.py:767]   Expert 57 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878864.878864 lmp.py:767]   Expert 56 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878030.878030 lmp.py:767]   Expert 48 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878435.878435 lmp.py:767]   Expert 44 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878839.878839 lmp.py:767]   Expert 24 |    214 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878959.878959 lmp.py:767]   Expert 16 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878364.878364 lmp.py:767]   Expert 46 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.878530.878530 lmp.py:767]   Expert 39 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.878934.878934 lmp.py:767]   Expert 18 |    228 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879862.879862 lmp.py:767]   Expert 29 |    234 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879267.879267 lmp.py:767]   Expert 37 |    241 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879910.879910 lmp.py:767]   Expert 31 |    252 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879314.879314 lmp.py:767]   Expert  3 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879957.879957 lmp.py:767]   Expert 36 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879839.879839 lmp.py:767]   Expert 60 |    257 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879005.879005 lmp.py:767]   Expert 17 |    263 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879409.879409 lmp.py:767]   Expert 38 |    264 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879575.879575 lmp.py:767]   Expert  9 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879742.879742 lmp.py:767]   Expert 23 |    274 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879908.879908 lmp.py:767]   Expert 27 |    353 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879312.879312 lmp.py:767]   Expert 43 |    356 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879478.879478 lmp.py:767]   Expert 33 |    390 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879121.879121 lmp.py:767]   Expert  8 |    405 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879288.879288 lmp.py:767]   Expert 58 |    445 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.879215.879215 lmp.py:767]   Expert 49 |    545 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.879143.879143 lmp.py:769] 
DEBUG 01-07 14:54:49.879143.879143 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.879548.879548 lmp.py:770]   CPU:   2019 tokens
DEBUG 01-07 14:54:49.879906.879906 lmp.py:774]   cuda:1:   5069 tokens (22 experts)
DEBUG 01-07 14:54:49.879310.879310 lmp.py:774]   cuda:2:   5200 tokens (23 experts)
DEBUG 01-07 14:54:49.879761.879761 lmp.py:775]   Total GPU:  10269 tokens
DEBUG 01-07 14:54:49.879212.879212 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.879212.879212 lmp.py:776] 
DEBUG 01-07 14:54:49.879862.879862 cuda_h.py:19] end experts_map_get cost 0.0017697811126708984 seconds
DEBUG 01-07 14:54:49.879505.879505 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.879043.879043 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.879537.879537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.879056.879056 cuda_h.py:19] end allocate_cuda_memory cost 0.0002455711364746094 seconds
DEBUG 01-07 14:54:49.879595.879595 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.879159.879159 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.879683.879683 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.880572.880572 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c25b35ab-827d-44ba-8f8f-8bb5b3fb87a5
DEBUG 01-07 14:54:49.880775.880775 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.880579.880579 client.py:127] Model loaded
DEBUG 01-07 14:54:49.880443.880443 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.880026.880026 cuda_h.py:19] end restore2model cost 0.0003592967987060547 seconds
DEBUG 01-07 14:54:49.880703.880703 cuda_h.py:19] end sllm_worker_task cost 0.008980035781860352 seconds
INFO 01-07 14:54:49.880783.880783 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c25b35ab-827d-44ba-8f8f-8bb5b3fb87a5
DEBUG 01-07 14:54:49.881964.881964 cuda_h.py:19] end load_into_gpu_async cost 0.0010819435119628906 seconds
DEBUG 01-07 14:54:49.881428.881428 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.881378.881378 cuda_h.py:19] end restore_tensors2 cost 0.0002543926239013672 seconds
DEBUG 01-07 14:54:49.881863.881863 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019059181213378906 seconds
DEBUG 01-07 14:54:49.881672.881672 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.883521.883521 cuda_h.py:19] end restore2model cost 0.0017921924591064453 seconds
DEBUG 01-07 14:54:49.883569.883569 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.883897.883897 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.883753.883753 cuda_h.py:19] end allocate_cuda_memory cost 0.0002129077911376953 seconds
DEBUG 01-07 14:54:49.883020.883020 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.883822.883822 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.883294.883294 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.883751.883751 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32e90d91-8f33-427d-98a1-658bba03a177
DEBUG 01-07 14:54:49.883319.883319 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.884653.884653 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32e90d91-8f33-427d-98a1-658bba03a177
DEBUG 01-07 14:54:49.884482.884482 cuda_h.py:19] end load_into_gpu_async cost 0.0011167526245117188 seconds
DEBUG 01-07 14:54:49.884039.884039 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.885552.885552 cuda_h.py:19] end restore_tensors2 cost 0.0002472400665283203 seconds
DEBUG 01-07 14:54:49.885275.885275 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018627643585205078 seconds
DEBUG 01-07 14:54:49.885601.885601 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.887598.887598 cuda_h.py:19] end restore2model cost 0.0018663406372070312 seconds
DEBUG 01-07 14:54:49.887235.887235 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007750988006591797 seconds
DEBUG 01-07 14:54:49.887362.887362 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.887894.887894 lmp.py:816] 
DEBUG 01-07 14:54:49.887894.887894 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.887830.887830 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-07 14:54:49.887049.887049 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.893797.893797 mlpmodule.py:749] group tensors cost 0.006175041198730469 s
DEBUG 01-07 14:54:49.896899.896899 mlpmodule.py:787] pad cost 0.0016937255859375 s
DEBUG 01-07 14:54:49.896765.896765 mlpmodule.py:793] create cpu tensor cost 5.841255187988281e-05 s
DEBUG 01-07 14:54:49.896451.896451 mlpmodule.py:798] move to cpu cost 4.5299530029296875e-05 s
DEBUG 01-07 14:54:49.905423.905423 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.905858.905858 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.905166.905166 mlpmodule.py:818] group_w3 first element: -0.0595703125
WARNING 01-07 14:54:49.905315.905315 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.919392.919392 mlpmodule.py:838] group einsum cost 0.023072242736816406 s
DEBUG 01-07 14:54:49.920387.920387 mlpmodule.py:846] cpy2cputensor cost 0.0004544258117675781 s
DEBUG 01-07 14:54:49.922617.922617 cuda_h.py:19] end wait_cetm_experts cost 0.03510141372680664 seconds
DEBUG 01-07 14:54:49.922646.922646 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.923134.923134 cuda_h.py:19] end gpu_sexperts cost 0.0004913806915283203 seconds
DEBUG 01-07 14:54:49.923746.923746 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.923357.923357 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 14:54:49.923299.923299 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.923439.923439 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c25b35ab-827d-44ba-8f8f-8bb5b3fb87a5
INFO 01-07 14:54:49.924415.924415 client.py:127] Model loaded
INFO 01-07 14:54:49.924775.924775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32e90d91-8f33-427d-98a1-658bba03a177
INFO 01-07 14:54:49.925907.925907 client.py:127] Model loaded
DEBUG 01-07 14:54:49.925167.925167 cuda_h.py:19] end wait_experts_multi_device cost 0.0017676353454589844 seconds
DEBUG 01-07 14:54:49.925446.925446 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.925269.925269 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.926269.926269 mlpmodule.py:533] gpu group tensors cost 0.0005090236663818359 s
DEBUG 01-07 14:54:49.927362.927362 mlpmodule.py:566] gpu pad cost 0.0013363361358642578 s
DEBUG 01-07 14:54:49.928205.928205 mlpmodule.py:584] gpu group einsum cost 0.0005745887756347656 s
DEBUG 01-07 14:54:49.929353.929353 mlpmodule.py:707]  experts func einsum cost 0.04238629341125488 s
DEBUG 01-07 14:54:49.930160.930160 mlpmodule.py:656] gpu experts func einsum cost 0.004781484603881836 s
DEBUG 01-07 14:54:49.930826.930826 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.931660.931660 mlpmodule.py:533] gpu group tensors cost 0.0004596710205078125 s
DEBUG 01-07 14:54:49.933552.933552 mlpmodule.py:566] gpu pad cost 0.0012664794921875 s
DEBUG 01-07 14:54:49.933877.933877 mlpmodule.py:584] gpu group einsum cost 0.0003495216369628906 s
DEBUG 01-07 14:54:49.935077.935077 mlpmodule.py:656] gpu experts func einsum cost 0.004033565521240234 s
DEBUG 01-07 14:54:49.935729.935729 cuda_h.py:19] end gpu_experts_multi_device cost 0.010222434997558594 seconds
DEBUG 01-07 14:54:49.935507.935507 cuda_h.py:19] end layer_moe_generate_multi_device_15 cost 0.05859518051147461 seconds
DEBUG 01-07 14:54:49.935601.935601 lmp.py:194] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-07 14:54:49.935192.935192 lmp.py:153] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-07 14:54:49.935842.935842 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 14:54:49.935075.935075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 14:54:49.935150.935150 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:49.935614.935614 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.8650970458984375e-05 seconds
DEBUG 01-07 14:54:49.935403.935403 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:49.935815.935815 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:49.936063.936063 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:49.936681.936681 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.936319.936319 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.936892.936892 cuda_h.py:19] end allocate_cuda_memory cost 0.0002837181091308594 seconds
DEBUG 01-07 14:54:49.936690.936690 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.936499.936499 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.936938.936938 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.936733.936733 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ec6e9ff9-3e57-44e8-8136-aaf214e191fc
DEBUG 01-07 14:54:49.936080.936080 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:49.937957.937957 cuda_h.py:10] start self_attn
INFO 01-07 14:54:49.937510.937510 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ec6e9ff9-3e57-44e8-8136-aaf214e191fc
DEBUG 01-07 14:54:49.937916.937916 cuda_h.py:19] end load_into_gpu_async cost 0.0007636547088623047 seconds
DEBUG 01-07 14:54:49.937711.937711 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.937218.937218 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-07 14:54:49.937735.937735 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013804435729980469 seconds
INFO 01-07 14:54:49.937432.937432 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ec6e9ff9-3e57-44e8-8136-aaf214e191fc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:49.940030.940030 cuda_h.py:19] end self_attn cost 0.0037119388580322266 seconds
DEBUG 01-07 14:54:49.941942.941942 cuda_h.py:19] end iln_self_attn_paln cost 0.0051784515380859375 seconds
DEBUG 01-07 14:54:49.941294.941294 cuda_h.py:10] start layer_moe_generate_multi_device_16
DEBUG 01-07 14:54:49.941911.941911 cuda_h.py:10] start gate
DEBUG 01-07 14:54:49.941987.941987 cuda_h.py:19] end gate cost 0.0006542205810546875 seconds
DEBUG 01-07 14:54:49.941247.941247 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:49.942871.942871 lmp.py:744] 
DEBUG 01-07 14:54:49.942871.942871 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:49.942249.942249 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:49.942091.942091 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:49.942834.942834 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:49.942953.942953 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:49.942881.942881 lmp.py:749] 
DEBUG 01-07 14:54:49.942881.942881 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:49.942524.942524 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:49.942604.942604 lmp.py:767]   Expert 58 |     34 | CPU
DEBUG 01-07 14:54:49.942486.942486 lmp.py:767]   Expert 47 |     57 | CPU
DEBUG 01-07 14:54:49.942129.942129 lmp.py:767]   Expert 31 |     61 | CPU
DEBUG 01-07 14:54:49.942010.942010 lmp.py:767]   Expert 49 |     64 | CPU
DEBUG 01-07 14:54:49.942415.942415 lmp.py:767]   Expert  4 |     68 | CPU
DEBUG 01-07 14:54:49.942342.942342 lmp.py:767]   Expert 45 |     71 | CPU
DEBUG 01-07 14:54:49.942270.942270 lmp.py:767]   Expert 38 |     73 | CPU
DEBUG 01-07 14:54:49.942959.942959 lmp.py:767]   Expert 41 |     82 | CPU
DEBUG 01-07 14:54:49.942649.942649 lmp.py:767]   Expert 43 |     83 | CPU
DEBUG 01-07 14:54:49.942100.942100 lmp.py:767]   Expert 33 |     96 | CPU
DEBUG 01-07 14:54:49.942266.942266 lmp.py:767]   Expert 50 |     97 | CPU
DEBUG 01-07 14:54:49.942670.942670 lmp.py:767]   Expert 57 |    106 | CPU
DEBUG 01-07 14:54:49.942360.942360 lmp.py:767]   Expert 11 |    111 | CPU
DEBUG 01-07 14:54:49.942287.942287 lmp.py:767]   Expert  2 |    112 | CPU
DEBUG 01-07 14:54:49.942738.942738 lmp.py:767]   Expert 51 |    117 | CPU
DEBUG 01-07 14:54:49.942427.942427 lmp.py:767]   Expert  0 |    122 | CPU
DEBUG 01-07 14:54:49.942117.942117 lmp.py:767]   Expert 14 |    123 | CPU
DEBUG 01-07 14:54:49.942568.942568 lmp.py:767]   Expert 54 |    135 | CPU
DEBUG 01-07 14:54:49.942257.942257 lmp.py:767]   Expert 34 |    140 | CPU
DEBUG 01-07 14:54:49.942615.942615 lmp.py:767]   Expert 56 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.942212.942212 lmp.py:767]   Expert 26 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.942855.942855 lmp.py:767]   Expert 27 |    154 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.942498.942498 lmp.py:767]   Expert 28 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.942141.942141 lmp.py:767]   Expert 10 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.942784.942784 lmp.py:767]   Expert 55 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.942188.942188 lmp.py:767]   Expert 25 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.942070.942070 lmp.py:767]   Expert 13 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.942428.942428 lmp.py:767]   Expert  9 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.942832.942832 lmp.py:767]   Expert 61 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943237.943237 lmp.py:767]   Expert 48 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943118.943118 lmp.py:767]   Expert  6 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943761.943761 lmp.py:767]   Expert  7 |    193 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943643.943643 lmp.py:767]   Expert 46 |    194 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943286.943286 lmp.py:767]   Expert 42 |    198 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943929.943929 lmp.py:767]   Expert 24 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943333.943333 lmp.py:767]   Expert 18 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943976.943976 lmp.py:767]   Expert 12 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943050.943050 lmp.py:767]   Expert 40 |    212 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943646.943646 lmp.py:767]   Expert 63 |    215 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943528.943528 lmp.py:767]   Expert 22 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943932.943932 lmp.py:767]   Expert 21 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943575.943575 lmp.py:767]   Expert 59 |    218 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943980.943980 lmp.py:767]   Expert 29 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943623.943623 lmp.py:767]   Expert 32 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943027.943027 lmp.py:767]   Expert 19 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943386.943386 lmp.py:767]   Expert 36 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943744.943744 lmp.py:767]   Expert  3 |    243 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943148.943148 lmp.py:767]   Expert  1 |    245 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943791.943791 lmp.py:767]   Expert 37 |    245 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943434.943434 lmp.py:767]   Expert 16 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943077.943077 lmp.py:767]   Expert 20 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943720.943720 lmp.py:767]   Expert  5 |    265 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943840.943840 lmp.py:767]   Expert 30 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943198.943198 lmp.py:767]   Expert  8 |    267 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943080.943080 lmp.py:767]   Expert 15 |    273 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943723.943723 lmp.py:767]   Expert 62 |    273 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943366.943366 lmp.py:767]   Expert 35 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943009.943009 lmp.py:767]   Expert 39 |    301 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943129.943129 lmp.py:767]   Expert 17 |    307 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943772.943772 lmp.py:767]   Expert 60 |    310 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943891.943891 lmp.py:767]   Expert 52 |    353 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943011.943011 lmp.py:767]   Expert 23 |    368 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943416.943416 lmp.py:767]   Expert 44 |    377 | GPU1(cuda:2)
DEBUG 01-07 14:54:49.943820.943820 lmp.py:767]   Expert 53 |    434 | GPU0(cuda:1)
DEBUG 01-07 14:54:49.943033.943033 lmp.py:769] 
DEBUG 01-07 14:54:49.943033.943033 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:49.943960.943960 lmp.py:770]   CPU:   1752 tokens
DEBUG 01-07 14:54:49.943080.943080 lmp.py:774]   cuda:1:   5201 tokens (22 experts)
DEBUG 01-07 14:54:49.943246.943246 lmp.py:774]   cuda:2:   5335 tokens (23 experts)
DEBUG 01-07 14:54:49.943413.943413 lmp.py:775]   Total GPU:  10536 tokens
DEBUG 01-07 14:54:49.943340.943340 lmp.py:776] ============================================================
DEBUG 01-07 14:54:49.943340.943340 lmp.py:776] 
DEBUG 01-07 14:54:49.943752.943752 cuda_h.py:19] end experts_map_get cost 0.001783609390258789 seconds
DEBUG 01-07 14:54:49.943633.943633 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:49.943555.943555 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.943890.943890 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.944873.944873 cuda_h.py:19] end allocate_cuda_memory cost 0.00027108192443847656 seconds
DEBUG 01-07 14:54:49.944637.944637 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.944632.944632 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.944395.944395 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.944521.944521 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b050ab54-a1d5-4eb1-af92-4f627997f40f
DEBUG 01-07 14:54:49.944222.944222 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.944181.944181 client.py:127] Model loaded
DEBUG 01-07 14:54:49.944679.944679 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.945069.945069 cuda_h.py:19] end restore2model cost 0.00032520294189453125 seconds
DEBUG 01-07 14:54:49.945646.945646 cuda_h.py:19] end sllm_worker_task cost 0.009038448333740234 seconds
INFO 01-07 14:54:49.945132.945132 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b050ab54-a1d5-4eb1-af92-4f627997f40f
DEBUG 01-07 14:54:49.945452.945452 cuda_h.py:19] end load_into_gpu_async cost 0.00095367431640625 seconds
DEBUG 01-07 14:54:49.945632.945632 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.945403.945403 cuda_h.py:19] end restore_tensors2 cost 0.000263214111328125 seconds
DEBUG 01-07 14:54:49.945126.945126 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018029212951660156 seconds
DEBUG 01-07 14:54:49.945412.945412 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.947249.947249 cuda_h.py:19] end restore2model cost 0.001817941665649414 seconds
DEBUG 01-07 14:54:49.947152.947152 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:49.947102.947102 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:49.947872.947872 cuda_h.py:19] end allocate_cuda_memory cost 0.00021886825561523438 seconds
DEBUG 01-07 14:54:49.947854.947854 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:49.948226.948226 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:49.948413.948413 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:49.948109.948109 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f5d3501-51c3-4f45-960e-e5b37c37d5d5
DEBUG 01-07 14:54:49.948160.948160 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:49.948013.948013 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f5d3501-51c3-4f45-960e-e5b37c37d5d5
DEBUG 01-07 14:54:49.949843.949843 cuda_h.py:19] end load_into_gpu_async cost 0.0010144710540771484 seconds
DEBUG 01-07 14:54:49.949400.949400 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:49.949118.949118 cuda_h.py:19] end restore_tensors2 cost 0.0002593994140625 seconds
DEBUG 01-07 14:54:49.949749.949749 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017819404602050781 seconds
DEBUG 01-07 14:54:49.949551.949551 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:49.951197.951197 cuda_h.py:19] end restore2model cost 0.0018534660339355469 seconds
DEBUG 01-07 14:54:49.951549.951549 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007571697235107422 seconds
DEBUG 01-07 14:54:49.951868.951868 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:49.951877.951877 lmp.py:816] 
DEBUG 01-07 14:54:49.951877.951877 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:49.951144.951144 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 14:54:49.951363.951363 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:49.963212.963212 mlpmodule.py:749] group tensors cost 0.011543512344360352 s
DEBUG 01-07 14:54:49.964412.964412 mlpmodule.py:787] pad cost 0.000985860824584961 s
DEBUG 01-07 14:54:49.964017.964017 mlpmodule.py:793] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-07 14:54:49.965536.965536 mlpmodule.py:798] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-07 14:54:49.973817.973817 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:49.973490.973490 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:49.973175.973175 mlpmodule.py:818] group_w3 first element: -0.02490234375
WARNING 01-07 14:54:49.973894.973894 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:49.987350.987350 mlpmodule.py:838] group einsum cost 0.022444725036621094 s
DEBUG 01-07 14:54:49.988090.988090 mlpmodule.py:846] cpy2cputensor cost 0.0003898143768310547 s
DEBUG 01-07 14:54:49.990750.990750 cuda_h.py:19] end wait_cetm_experts cost 0.03879690170288086 seconds
DEBUG 01-07 14:54:49.990680.990680 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:49.990155.990155 cuda_h.py:19] end gpu_sexperts cost 0.00048279762268066406 seconds
DEBUG 01-07 14:54:49.991143.991143 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:49.991516.991516 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 14:54:49.991219.991219 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:49.991929.991929 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b050ab54-a1d5-4eb1-af92-4f627997f40f
INFO 01-07 14:54:49.992852.992852 client.py:127] Model loaded
INFO 01-07 14:54:49.992542.992542 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f5d3501-51c3-4f45-960e-e5b37c37d5d5
INFO 01-07 14:54:49.992496.992496 client.py:127] Model loaded
DEBUG 01-07 14:54:49.992809.992809 cuda_h.py:19] end wait_experts_multi_device cost 0.0013506412506103516 seconds
DEBUG 01-07 14:54:49.992419.992419 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:49.992672.992672 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:49.993897.993897 mlpmodule.py:533] gpu group tensors cost 0.0005068778991699219 s
DEBUG 01-07 14:54:49.995784.995784 mlpmodule.py:566] gpu pad cost 0.0012903213500976562 s
DEBUG 01-07 14:54:49.995454.995454 mlpmodule.py:584] gpu group einsum cost 0.0005693435668945312 s
DEBUG 01-07 14:54:49.997791.997791 mlpmodule.py:707]  experts func einsum cost 0.04587531089782715 s
DEBUG 01-07 14:54:49.997608.997608 mlpmodule.py:656] gpu experts func einsum cost 0.004716157913208008 s
DEBUG 01-07 14:54:49.998406.998406 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:49.999524.999524 mlpmodule.py:533] gpu group tensors cost 0.0004553794860839844 s
DEBUG 01-07 14:54:50.000314.000314 mlpmodule.py:566] gpu pad cost 0.0011925697326660156 s
DEBUG 01-07 14:54:50.000883.000883 mlpmodule.py:584] gpu group einsum cost 0.0004982948303222656 s
DEBUG 01-07 14:54:50.002664.002664 mlpmodule.py:656] gpu experts func einsum cost 0.004245758056640625 s
DEBUG 01-07 14:54:50.002893.002893 cuda_h.py:19] end gpu_experts_multi_device cost 0.010361671447753906 seconds
DEBUG 01-07 14:54:50.003723.003723 cuda_h.py:19] end layer_moe_generate_multi_device_16 cost 0.06183767318725586 seconds
DEBUG 01-07 14:54:50.003309.003309 lmp.py:194] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-07 14:54:50.003715.003715 lmp.py:153] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-07 14:54:50.003365.003365 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 14:54:50.003028.003028 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 14:54:50.003388.003388 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 14:54:50.003375.003375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.793571472167969e-05 seconds
DEBUG 01-07 14:54:50.003164.003164 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.003517.003517 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.003757.003757 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.003395.003395 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.004738.004738 cuda_h.py:19] end allocate_cuda_memory cost 0.0003218650817871094 seconds
DEBUG 01-07 14:54:50.004668.004668 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.004928.004928 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.004580.004580 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.004880.004880 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.004914.004914 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32b8a2b3-830c-4c3f-81c3-46ecc219b1b6
DEBUG 01-07 14:54:50.004698.004698 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.004291.004291 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.005329.005329 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32b8a2b3-830c-4c3f-81c3-46ecc219b1b6
DEBUG 01-07 14:54:50.005688.005688 cuda_h.py:19] end load_into_gpu_async cost 0.0008530616760253906 seconds
DEBUG 01-07 14:54:50.005722.005722 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.005229.005229 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-07 14:54:50.005600.005600 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016107559204101562 seconds
INFO 01-07 14:54:50.005059.005059 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32b8a2b3-830c-4c3f-81c3-46ecc219b1b6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.008813.008813 cuda_h.py:19] end self_attn cost 0.003656148910522461 seconds
DEBUG 01-07 14:54:50.008870.008870 cuda_h.py:19] end iln_self_attn_paln cost 0.00523066520690918 seconds
DEBUG 01-07 14:54:50.008699.008699 cuda_h.py:10] start layer_moe_generate_multi_device_17
DEBUG 01-07 14:54:50.008316.008316 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.009763.009763 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-07 14:54:50.009546.009546 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.010355.010355 lmp.py:744] 
DEBUG 01-07 14:54:50.010355.010355 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.010972.010972 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.010291.010291 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.010795.010795 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.010153.010153 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.010319.010319 lmp.py:749] 
DEBUG 01-07 14:54:50.010319.010319 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.010200.010200 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.010565.010565 lmp.py:767]   Expert  4 |     13 | CPU
DEBUG 01-07 14:54:50.010924.010924 lmp.py:767]   Expert 28 |     31 | CPU
DEBUG 01-07 14:54:50.010328.010328 lmp.py:767]   Expert  7 |     41 | CPU
DEBUG 01-07 14:54:50.010971.010971 lmp.py:767]   Expert 53 |     53 | CPU
DEBUG 01-07 14:54:50.010899.010899 lmp.py:767]   Expert 52 |     68 | CPU
DEBUG 01-07 14:54:50.010827.010827 lmp.py:767]   Expert 43 |     72 | CPU
DEBUG 01-07 14:54:50.010754.010754 lmp.py:767]   Expert 49 |     84 | CPU
DEBUG 01-07 14:54:50.010682.010682 lmp.py:767]   Expert 12 |     91 | CPU
DEBUG 01-07 14:54:50.010848.010848 lmp.py:767]   Expert 47 |     98 | CPU
DEBUG 01-07 14:54:50.010014.010014 lmp.py:767]   Expert 24 |    104 | CPU
DEBUG 01-07 14:54:50.010419.010419 lmp.py:767]   Expert 33 |    107 | CPU
DEBUG 01-07 14:54:50.010062.010062 lmp.py:767]   Expert 50 |    108 | CPU
DEBUG 01-07 14:54:50.010751.010751 lmp.py:767]   Expert 15 |    110 | CPU
DEBUG 01-07 14:54:50.010202.010202 lmp.py:767]   Expert 60 |    111 | CPU
DEBUG 01-07 14:54:50.010891.010891 lmp.py:767]   Expert 39 |    114 | CPU
DEBUG 01-07 14:54:50.010819.010819 lmp.py:767]   Expert  2 |    115 | CPU
DEBUG 01-07 14:54:50.010508.010508 lmp.py:767]   Expert 36 |    116 | CPU
DEBUG 01-07 14:54:50.010436.010436 lmp.py:767]   Expert  6 |    125 | CPU
DEBUG 01-07 14:54:50.010556.010556 lmp.py:767]   Expert 25 |    129 | CPU
DEBUG 01-07 14:54:50.010914.010914 lmp.py:767]   Expert 61 |    132 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010272.010272 lmp.py:767]   Expert 58 |    137 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010915.010915 lmp.py:767]   Expert 59 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010320.010320 lmp.py:767]   Expert  3 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010201.010201 lmp.py:767]   Expert 27 |    146 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010321.010321 lmp.py:767]   Expert  8 |    149 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010203.010203 lmp.py:767]   Expert 31 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010607.010607 lmp.py:767]   Expert 30 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010012.010012 lmp.py:767]   Expert 38 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010416.010416 lmp.py:767]   Expert 10 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010821.010821 lmp.py:767]   Expert 37 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010225.010225 lmp.py:767]   Expert 40 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010345.010345 lmp.py:767]   Expert 14 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010227.010227 lmp.py:767]   Expert 41 |    163 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010631.010631 lmp.py:767]   Expert 32 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010797.010797 lmp.py:767]   Expert 57 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010440.010440 lmp.py:767]   Expert 54 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010845.010845 lmp.py:767]   Expert 46 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010249.010249 lmp.py:767]   Expert 19 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010131.010131 lmp.py:767]   Expert 42 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010251.010251 lmp.py:767]   Expert 11 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010370.010370 lmp.py:767]   Expert 34 |    188 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010013.010013 lmp.py:767]   Expert 22 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010656.010656 lmp.py:767]   Expert  0 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010776.010776 lmp.py:767]   Expert 18 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010942.010942 lmp.py:767]   Expert 26 |    196 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010632.010632 lmp.py:767]   Expert 44 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.010036.010036 lmp.py:767]   Expert 56 |    202 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.010202.010202 lmp.py:767]   Expert  1 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011845.011845 lmp.py:767]   Expert 51 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011965.011965 lmp.py:767]   Expert 20 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011370.011370 lmp.py:767]   Expert 29 |    232 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011536.011536 lmp.py:767]   Expert 48 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011702.011702 lmp.py:767]   Expert 45 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011106.011106 lmp.py:767]   Expert 16 |    249 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011511.011511 lmp.py:767]   Expert 21 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011677.011677 lmp.py:767]   Expert 35 |    251 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011082.011082 lmp.py:767]   Expert 55 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011678.011678 lmp.py:767]   Expert  5 |    295 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011798.011798 lmp.py:767]   Expert 23 |    375 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011203.011203 lmp.py:767]   Expert 13 |    380 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011846.011846 lmp.py:767]   Expert 17 |    434 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011012.011012 lmp.py:767]   Expert  9 |    452 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011416.011416 lmp.py:767]   Expert 63 |    466 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.011821.011821 lmp.py:767]   Expert 62 |   1182 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.011272.011272 lmp.py:769] 
DEBUG 01-07 14:54:50.011272.011272 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.011392.011392 lmp.py:770]   CPU:   1690 tokens
DEBUG 01-07 14:54:50.011465.011465 lmp.py:774]   cuda:1:   5341 tokens (22 experts)
DEBUG 01-07 14:54:50.011870.011870 lmp.py:774]   cuda:2:   5257 tokens (23 experts)
DEBUG 01-07 14:54:50.011321.011321 lmp.py:775]   Total GPU:  10598 tokens
DEBUG 01-07 14:54:50.011771.011771 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.011771.011771 lmp.py:776] 
DEBUG 01-07 14:54:50.011421.011421 cuda_h.py:19] end experts_map_get cost 0.001775503158569336 seconds
DEBUG 01-07 14:54:50.011541.011541 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.011602.011602 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.011321.011321 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.011872.011872 cuda_h.py:19] end allocate_cuda_memory cost 0.00019741058349609375 seconds
DEBUG 01-07 14:54:50.011385.011385 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.011426.011426 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.011619.011619 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.011984.011984 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61c92919-90c9-4688-86fb-b311a4a175f1
DEBUG 01-07 14:54:50.012764.012764 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.012861.012861 client.py:127] Model loaded
DEBUG 01-07 14:54:50.012029.012029 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.012909.012909 cuda_h.py:19] end restore2model cost 0.00033593177795410156 seconds
DEBUG 01-07 14:54:50.012201.012201 cuda_h.py:19] end sllm_worker_task cost 0.009113311767578125 seconds
INFO 01-07 14:54:50.012823.012823 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61c92919-90c9-4688-86fb-b311a4a175f1
DEBUG 01-07 14:54:50.012097.012097 cuda_h.py:19] end load_into_gpu_async cost 0.0010538101196289062 seconds
DEBUG 01-07 14:54:50.013608.013608 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.013412.013412 cuda_h.py:19] end restore_tensors2 cost 0.00025272369384765625 seconds
DEBUG 01-07 14:54:50.013704.013704 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018429756164550781 seconds
DEBUG 01-07 14:54:50.013798.013798 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.015436.015436 cuda_h.py:19] end restore2model cost 0.0018115043640136719 seconds
DEBUG 01-07 14:54:50.015816.015816 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.015535.015535 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.015450.015450 cuda_h.py:19] end allocate_cuda_memory cost 0.00021910667419433594 seconds
DEBUG 01-07 14:54:50.015909.015909 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.015188.015188 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.015090.015090 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.015025.015025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61cb3ed7-99a8-46b1-b6cd-cc45816bc5d6
DEBUG 01-07 14:54:50.015500.015500 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.016165.016165 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61cb3ed7-99a8-46b1-b6cd-cc45816bc5d6
DEBUG 01-07 14:54:50.016233.016233 cuda_h.py:19] end load_into_gpu_async cost 0.001119375228881836 seconds
DEBUG 01-07 14:54:50.016028.016028 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.017189.017189 cuda_h.py:19] end restore_tensors2 cost 0.00023436546325683594 seconds
DEBUG 01-07 14:54:50.017243.017243 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018672943115234375 seconds
DEBUG 01-07 14:54:50.017761.017761 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.019129.019129 cuda_h.py:19] end restore2model cost 0.0018579959869384766 seconds
DEBUG 01-07 14:54:50.019005.019005 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076944828033447266 seconds
DEBUG 01-07 14:54:50.019846.019846 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.019856.019856 lmp.py:816] 
DEBUG 01-07 14:54:50.019856.019856 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.019122.019122 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-07 14:54:50.019819.019819 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.031879.031879 mlpmodule.py:749] group tensors cost 0.011954784393310547 s
DEBUG 01-07 14:54:50.033527.033527 mlpmodule.py:787] pad cost 0.000985860824584961 s
DEBUG 01-07 14:54:50.033848.033848 mlpmodule.py:793] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-07 14:54:50.033174.033174 mlpmodule.py:798] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-07 14:54:50.041829.041829 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.041218.041218 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.041287.041287 mlpmodule.py:818] group_w3 first element: 0.00457763671875
WARNING 01-07 14:54:50.041482.041482 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.055410.055410 mlpmodule.py:838] group einsum cost 0.021807193756103516 s
DEBUG 01-07 14:54:50.055255.055255 mlpmodule.py:846] cpy2cputensor cost 0.00036454200744628906 s
DEBUG 01-07 14:54:50.058578.058578 cuda_h.py:19] end wait_cetm_experts cost 0.0386502742767334 seconds
DEBUG 01-07 14:54:50.058753.058753 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.058757.058757 cuda_h.py:19] end gpu_sexperts cost 0.0004856586456298828 seconds
DEBUG 01-07 14:54:50.058084.058084 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.058649.058649 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-07 14:54:50.058591.058591 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.058969.058969 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61c92919-90c9-4688-86fb-b311a4a175f1
INFO 01-07 14:54:50.059919.059919 client.py:127] Model loaded
INFO 01-07 14:54:50.059517.059517 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61cb3ed7-99a8-46b1-b6cd-cc45816bc5d6
INFO 01-07 14:54:50.060350.060350 client.py:127] Model loaded
DEBUG 01-07 14:54:50.060372.060372 cuda_h.py:19] end wait_experts_multi_device cost 0.0013523101806640625 seconds
DEBUG 01-07 14:54:50.060744.060744 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.060620.060620 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.061018.061018 mlpmodule.py:533] gpu group tensors cost 0.0005037784576416016 s
DEBUG 01-07 14:54:50.062070.062070 mlpmodule.py:566] gpu pad cost 0.0013079643249511719 s
DEBUG 01-07 14:54:50.063986.063986 mlpmodule.py:584] gpu group einsum cost 0.0005662441253662109 s
DEBUG 01-07 14:54:50.065491.065491 mlpmodule.py:707]  experts func einsum cost 0.04567670822143555 s
DEBUG 01-07 14:54:50.065319.065319 mlpmodule.py:656] gpu experts func einsum cost 0.004761457443237305 s
DEBUG 01-07 14:54:50.066416.066416 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.066851.066851 mlpmodule.py:533] gpu group tensors cost 0.0004456043243408203 s
DEBUG 01-07 14:54:50.068290.068290 mlpmodule.py:566] gpu pad cost 0.0015454292297363281 s
DEBUG 01-07 14:54:50.069613.069613 mlpmodule.py:584] gpu group einsum cost 0.0008580684661865234 s
DEBUG 01-07 14:54:50.071351.071351 mlpmodule.py:656] gpu experts func einsum cost 0.004887580871582031 s
DEBUG 01-07 14:54:50.071348.071348 cuda_h.py:19] end gpu_experts_multi_device cost 0.01109170913696289 seconds
DEBUG 01-07 14:54:50.071218.071218 cuda_h.py:19] end layer_moe_generate_multi_device_17 cost 0.06253623962402344 seconds
DEBUG 01-07 14:54:50.071505.071505 lmp.py:194] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-07 14:54:50.071142.071142 lmp.py:153] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-07 14:54:50.071030.071030 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 14:54:50.071832.071832 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 14:54:50.071384.071384 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 14:54:50.071895.071895 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.817413330078125e-05 seconds
DEBUG 01-07 14:54:50.071491.071491 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.071619.071619 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.072656.072656 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.072756.072756 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.072243.072243 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.072014.072014 cuda_h.py:19] end allocate_cuda_memory cost 0.00020885467529296875 seconds
DEBUG 01-07 14:54:50.072393.072393 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.072295.072295 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.072210.072210 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.072244.072244 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de103fe3-e051-43d7-b0bc-ec8d5920a26c
DEBUG 01-07 14:54:50.072207.072207 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.072032.072032 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.073557.073557 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de103fe3-e051-43d7-b0bc-ec8d5920a26c
DEBUG 01-07 14:54:50.073393.073393 cuda_h.py:19] end load_into_gpu_async cost 0.000949859619140625 seconds
DEBUG 01-07 14:54:50.073904.073904 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.073933.073933 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-07 14:54:50.073782.073782 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014734268188476562 seconds
INFO 01-07 14:54:50.073804.073804 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de103fe3-e051-43d7-b0bc-ec8d5920a26c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.076125.076125 cuda_h.py:19] end self_attn cost 0.003727436065673828 seconds
DEBUG 01-07 14:54:50.077500.077500 cuda_h.py:19] end iln_self_attn_paln cost 0.005174875259399414 seconds
DEBUG 01-07 14:54:50.077899.077899 cuda_h.py:10] start layer_moe_generate_multi_device_18
DEBUG 01-07 14:54:50.077562.077562 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.077446.077446 cuda_h.py:19] end gate cost 0.0006532669067382812 seconds
DEBUG 01-07 14:54:50.077229.077229 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.078714.078714 lmp.py:744] 
DEBUG 01-07 14:54:50.078714.078714 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.078093.078093 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.078411.078411 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.078154.078154 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.078750.078750 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.078155.078155 lmp.py:749] 
DEBUG 01-07 14:54:50.078155.078155 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.078798.078798 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.078878.078878 lmp.py:767]   Expert 32 |     35 | CPU
DEBUG 01-07 14:54:50.078521.078521 lmp.py:767]   Expert 30 |     54 | CPU
DEBUG 01-07 14:54:50.078926.078926 lmp.py:767]   Expert  5 |     56 | CPU
DEBUG 01-07 14:54:50.078330.078330 lmp.py:767]   Expert 46 |     72 | CPU
DEBUG 01-07 14:54:50.078735.078735 lmp.py:767]   Expert 40 |     85 | CPU
DEBUG 01-07 14:54:50.078378.078378 lmp.py:767]   Expert  8 |     87 | CPU
DEBUG 01-07 14:54:50.078544.078544 lmp.py:767]   Expert 12 |     97 | CPU
DEBUG 01-07 14:54:50.078472.078472 lmp.py:767]   Expert 27 |    100 | CPU
DEBUG 01-07 14:54:50.078399.078399 lmp.py:767]   Expert 17 |    108 | CPU
DEBUG 01-07 14:54:50.078850.078850 lmp.py:767]   Expert 60 |    108 | CPU
DEBUG 01-07 14:54:50.078301.078301 lmp.py:767]   Expert  3 |    112 | CPU
DEBUG 01-07 14:54:50.078990.078990 lmp.py:767]   Expert 58 |    116 | CPU
DEBUG 01-07 14:54:50.078918.078918 lmp.py:767]   Expert 29 |    120 | CPU
DEBUG 01-07 14:54:50.078369.078369 lmp.py:767]   Expert 25 |    122 | CPU
DEBUG 01-07 14:54:50.078774.078774 lmp.py:767]   Expert 21 |    123 | CPU
DEBUG 01-07 14:54:50.078655.078655 lmp.py:767]   Expert 28 |    127 | CPU
DEBUG 01-07 14:54:50.078583.078583 lmp.py:767]   Expert 35 |    129 | CPU
DEBUG 01-07 14:54:50.078034.078034 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 14:54:50.078723.078723 lmp.py:767]   Expert 19 |    134 | CPU
DEBUG 01-07 14:54:50.078604.078604 lmp.py:767]   Expert  6 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.078724.078724 lmp.py:767]   Expert 52 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.078367.078367 lmp.py:767]   Expert  0 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.078248.078248 lmp.py:767]   Expert 54 |    146 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.078607.078607 lmp.py:767]   Expert 37 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.078250.078250 lmp.py:767]   Expert 56 |    151 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.078893.078893 lmp.py:767]   Expert 48 |    160 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.078297.078297 lmp.py:767]   Expert 63 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.078702.078702 lmp.py:767]   Expert 53 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.078106.078106 lmp.py:767]   Expert 36 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.078272.078272 lmp.py:767]   Expert 59 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.078154.078154 lmp.py:767]   Expert  9 |    180 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.078989.078989 lmp.py:767]   Expert  1 |    183 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079632.079632 lmp.py:767]   Expert 39 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079798.079798 lmp.py:767]   Expert 20 |    196 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079203.079203 lmp.py:767]   Expert 61 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079607.079607 lmp.py:767]   Expert  7 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079012.079012 lmp.py:767]   Expert 42 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079416.079416 lmp.py:767]   Expert 11 |    205 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079298.079298 lmp.py:767]   Expert 43 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079417.079417 lmp.py:767]   Expert 34 |    207 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079060.079060 lmp.py:767]   Expert 47 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079703.079703 lmp.py:767]   Expert 55 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079108.079108 lmp.py:767]   Expert 16 |    219 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079513.079513 lmp.py:767]   Expert 13 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079679.079679 lmp.py:767]   Expert 57 |    225 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079845.079845 lmp.py:767]   Expert 18 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079965.079965 lmp.py:767]   Expert 15 |    236 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079846.079846 lmp.py:767]   Expert  4 |    244 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079489.079489 lmp.py:767]   Expert 33 |    246 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079894.079894 lmp.py:767]   Expert 22 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079060.079060 lmp.py:767]   Expert 31 |    249 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079226.079226 lmp.py:767]   Expert 50 |    250 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079630.079630 lmp.py:767]   Expert 45 |    252 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079035.079035 lmp.py:767]   Expert 51 |    252 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079439.079439 lmp.py:767]   Expert 49 |    271 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079321.079321 lmp.py:767]   Expert 38 |    278 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079202.079202 lmp.py:767]   Expert 26 |    279 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079607.079607 lmp.py:767]   Expert 10 |    292 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079773.079773 lmp.py:767]   Expert 44 |    292 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079177.079177 lmp.py:767]   Expert 24 |    304 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079344.079344 lmp.py:767]   Expert  2 |    306 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079510.079510 lmp.py:767]   Expert 14 |    316 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079676.079676 lmp.py:767]   Expert 23 |    411 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.079842.079842 lmp.py:767]   Expert 62 |    664 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.079293.079293 lmp.py:769] 
DEBUG 01-07 14:54:50.079293.079293 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.079697.079697 lmp.py:770]   CPU:   1915 tokens
DEBUG 01-07 14:54:50.079817.079817 lmp.py:774]   cuda:1:   5188 tokens (22 experts)
DEBUG 01-07 14:54:50.079983.079983 lmp.py:774]   cuda:2:   5185 tokens (23 experts)
DEBUG 01-07 14:54:50.079196.079196 lmp.py:775]   Total GPU:  10373 tokens
DEBUG 01-07 14:54:50.079408.079408 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.079408.079408 lmp.py:776] 
DEBUG 01-07 14:54:50.079581.079581 cuda_h.py:19] end experts_map_get cost 0.0017764568328857422 seconds
DEBUG 01-07 14:54:50.079940.079940 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.079670.079670 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.079865.079865 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.080806.080806 cuda_h.py:19] end allocate_cuda_memory cost 0.0001704692840576172 seconds
DEBUG 01-07 14:54:50.080662.080662 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.080895.080895 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.080704.080704 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.080877.080877 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40506a7e-86ef-4143-8472-61664dea7aa8
DEBUG 01-07 14:54:50.080041.080041 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.080468.080468 client.py:127] Model loaded
DEBUG 01-07 14:54:50.080909.080909 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.080047.080047 cuda_h.py:19] end restore2model cost 0.00034809112548828125 seconds
DEBUG 01-07 14:54:50.080009.080009 cuda_h.py:19] end sllm_worker_task cost 0.008939266204833984 seconds
INFO 01-07 14:54:50.081565.081565 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40506a7e-86ef-4143-8472-61664dea7aa8
DEBUG 01-07 14:54:50.081038.081038 cuda_h.py:19] end load_into_gpu_async cost 0.0010862350463867188 seconds
DEBUG 01-07 14:54:50.081502.081502 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.081651.081651 cuda_h.py:19] end restore_tensors2 cost 0.0002605915069580078 seconds
DEBUG 01-07 14:54:50.081944.081944 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018291473388671875 seconds
DEBUG 01-07 14:54:50.081130.081130 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.083119.083119 cuda_h.py:19] end restore2model cost 0.0018243789672851562 seconds
DEBUG 01-07 14:54:50.083075.083075 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.083317.083317 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.083187.083187 cuda_h.py:19] end allocate_cuda_memory cost 0.00022101402282714844 seconds
DEBUG 01-07 14:54:50.083838.083838 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.084402.084402 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.084873.084873 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.084569.084569 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e802b7f0-d48b-4a34-91bf-13a32537bb9e
DEBUG 01-07 14:54:50.084276.084276 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.085667.085667 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e802b7f0-d48b-4a34-91bf-13a32537bb9e
DEBUG 01-07 14:54:50.085305.085305 cuda_h.py:19] end load_into_gpu_async cost 0.0012607574462890625 seconds
DEBUG 01-07 14:54:50.085670.085670 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.085428.085428 cuda_h.py:19] end restore_tensors2 cost 0.0002536773681640625 seconds
DEBUG 01-07 14:54:50.085912.085912 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020296573638916016 seconds
DEBUG 01-07 14:54:50.085384.085384 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.087175.087175 cuda_h.py:19] end restore2model cost 0.0018548965454101562 seconds
DEBUG 01-07 14:54:50.087766.087766 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007856369018554688 seconds
DEBUG 01-07 14:54:50.087131.087131 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.087902.087902 lmp.py:816] 
DEBUG 01-07 14:54:50.087902.087902 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.087738.087738 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 14:54:50.087434.087434 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.093091.093091 mlpmodule.py:749] group tensors cost 0.005235433578491211 s
DEBUG 01-07 14:54:50.094622.094622 mlpmodule.py:787] pad cost 0.0011954307556152344 s
DEBUG 01-07 14:54:50.095202.095202 mlpmodule.py:793] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-07 14:54:50.095357.095357 mlpmodule.py:798] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-07 14:54:50.103704.103704 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.103484.103484 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.103851.103851 mlpmodule.py:818] group_w3 first element: 0.0264892578125
WARNING 01-07 14:54:50.104478.104478 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.119407.119407 mlpmodule.py:838] group einsum cost 0.02436232566833496 s
DEBUG 01-07 14:54:50.120368.120368 mlpmodule.py:846] cpy2cputensor cost 0.000431060791015625 s
DEBUG 01-07 14:54:50.122323.122323 cuda_h.py:19] end wait_cetm_experts cost 0.034813880920410156 seconds
DEBUG 01-07 14:54:50.122922.122922 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.123781.123781 cuda_h.py:19] end gpu_sexperts cost 0.00048422813415527344 seconds
DEBUG 01-07 14:54:50.123386.123386 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.123858.123858 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 14:54:50.123276.123276 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.123224.123224 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40506a7e-86ef-4143-8472-61664dea7aa8
INFO 01-07 14:54:50.124340.124340 client.py:127] Model loaded
INFO 01-07 14:54:50.124077.124077 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e802b7f0-d48b-4a34-91bf-13a32537bb9e
INFO 01-07 14:54:50.124660.124660 client.py:127] Model loaded
DEBUG 01-07 14:54:50.124642.124642 cuda_h.py:19] end wait_experts_multi_device cost 0.0013887882232666016 seconds
DEBUG 01-07 14:54:50.124444.124444 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.124883.124883 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.126684.126684 mlpmodule.py:533] gpu group tensors cost 0.0005080699920654297 s
DEBUG 01-07 14:54:50.127346.127346 mlpmodule.py:566] gpu pad cost 0.0013012886047363281 s
DEBUG 01-07 14:54:50.128419.128419 mlpmodule.py:584] gpu group einsum cost 0.0005393028259277344 s
DEBUG 01-07 14:54:50.129651.129651 mlpmodule.py:707]  experts func einsum cost 0.0417637825012207 s
DEBUG 01-07 14:54:50.130441.130441 mlpmodule.py:656] gpu experts func einsum cost 0.0047152042388916016 s
DEBUG 01-07 14:54:50.130617.130617 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.131284.131284 mlpmodule.py:533] gpu group tensors cost 0.0004487037658691406 s
DEBUG 01-07 14:54:50.132017.132017 mlpmodule.py:566] gpu pad cost 0.0012557506561279297 s
DEBUG 01-07 14:54:50.133901.133901 mlpmodule.py:584] gpu group einsum cost 0.0004458427429199219 s
DEBUG 01-07 14:54:50.135961.135961 mlpmodule.py:656] gpu experts func einsum cost 0.004248380661010742 s
DEBUG 01-07 14:54:50.135620.135620 cuda_h.py:19] end gpu_experts_multi_device cost 0.010354042053222656 seconds
DEBUG 01-07 14:54:50.135735.135735 cuda_h.py:19] end layer_moe_generate_multi_device_18 cost 0.05817055702209473 seconds
DEBUG 01-07 14:54:50.135313.135313 lmp.py:194] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-07 14:54:50.135335.135335 lmp.py:153] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-07 14:54:50.135269.135269 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 14:54:50.135025.135025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 14:54:50.135445.135445 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 14:54:50.135432.135432 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.5789947509765625e-05 seconds
DEBUG 01-07 14:54:50.135029.135029 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.135826.135826 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.135437.135437 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.135082.135082 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.136819.136819 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.136962.136962 cuda_h.py:19] end allocate_cuda_memory cost 0.0002803802490234375 seconds
DEBUG 01-07 14:54:50.136946.136946 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.136185.136185 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.136008.136008 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.136711.136711 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20d8684b-f3b3-4863-ae4c-79cc0cfbbc0b
DEBUG 01-07 14:54:50.136482.136482 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.136767.136767 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.137943.137943 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20d8684b-f3b3-4863-ae4c-79cc0cfbbc0b
DEBUG 01-07 14:54:50.137349.137349 cuda_h.py:19] end load_into_gpu_async cost 0.0009284019470214844 seconds
DEBUG 01-07 14:54:50.137667.137667 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.137644.137644 cuda_h.py:19] end restore_tensors2 cost 6.29425048828125e-05 seconds
DEBUG 01-07 14:54:50.137969.137969 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015344619750976562 seconds
INFO 01-07 14:54:50.137382.137382 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20d8684b-f3b3-4863-ae4c-79cc0cfbbc0b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.140563.140563 cuda_h.py:19] end self_attn cost 0.0037546157836914062 seconds
DEBUG 01-07 14:54:50.140369.140369 cuda_h.py:19] end iln_self_attn_paln cost 0.0051724910736083984 seconds
DEBUG 01-07 14:54:50.141575.141575 cuda_h.py:10] start layer_moe_generate_multi_device_19
DEBUG 01-07 14:54:50.141524.141524 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.141917.141917 cuda_h.py:19] end gate cost 0.0006437301635742188 seconds
DEBUG 01-07 14:54:50.141793.141793 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.142602.142602 lmp.py:744] 
DEBUG 01-07 14:54:50.142602.142602 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.142457.142457 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.142537.142537 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.142803.142803 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.142923.142923 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.142850.142850 lmp.py:749] 
DEBUG 01-07 14:54:50.142850.142850 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.142493.142493 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.142335.142335 lmp.py:767]   Expert 44 |     36 | CPU
DEBUG 01-07 14:54:50.142217.142217 lmp.py:767]   Expert  1 |     48 | CPU
DEBUG 01-07 14:54:50.142860.142860 lmp.py:767]   Expert 28 |     63 | CPU
DEBUG 01-07 14:54:50.142787.142787 lmp.py:767]   Expert 60 |     64 | CPU
DEBUG 01-07 14:54:50.142715.142715 lmp.py:767]   Expert 48 |     75 | CPU
DEBUG 01-07 14:54:50.142643.142643 lmp.py:767]   Expert 27 |     82 | CPU
DEBUG 01-07 14:54:50.142571.142571 lmp.py:767]   Expert  0 |     99 | CPU
DEBUG 01-07 14:54:50.142498.142498 lmp.py:767]   Expert 62 |    105 | CPU
DEBUG 01-07 14:54:50.142426.142426 lmp.py:767]   Expert 22 |    114 | CPU
DEBUG 01-07 14:54:50.142069.142069 lmp.py:767]   Expert 59 |    114 | CPU
DEBUG 01-07 14:54:50.142712.142712 lmp.py:767]   Expert 42 |    115 | CPU
DEBUG 01-07 14:54:50.142640.142640 lmp.py:767]   Expert 30 |    116 | CPU
DEBUG 01-07 14:54:50.142091.142091 lmp.py:767]   Expert 58 |    120 | CPU
DEBUG 01-07 14:54:50.142018.142018 lmp.py:767]   Expert 16 |    126 | CPU
DEBUG 01-07 14:54:50.142184.142184 lmp.py:767]   Expert 12 |    128 | CPU
DEBUG 01-07 14:54:50.142874.142874 lmp.py:767]   Expert  8 |    132 | CPU
DEBUG 01-07 14:54:50.142325.142325 lmp.py:767]   Expert 50 |    139 | CPU
DEBUG 01-07 14:54:50.142491.142491 lmp.py:767]   Expert 56 |    143 | CPU
DEBUG 01-07 14:54:50.142657.142657 lmp.py:767]   Expert  5 |    145 | CPU
DEBUG 01-07 14:54:50.142538.142538 lmp.py:767]   Expert 57 |    150 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142896.142896 lmp.py:767]   Expert 55 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142778.142778 lmp.py:767]   Expert 15 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142421.142421 lmp.py:767]   Expert 26 |    155 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142302.142302 lmp.py:767]   Expert 32 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142422.142422 lmp.py:767]   Expert 47 |    161 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142780.142780 lmp.py:767]   Expert 24 |    162 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142423.142423 lmp.py:767]   Expert  2 |    164 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142828.142828 lmp.py:767]   Expert 34 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142232.142232 lmp.py:767]   Expert 52 |    166 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142875.142875 lmp.py:767]   Expert 18 |    167 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142280.142280 lmp.py:767]   Expert 54 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142923.142923 lmp.py:767]   Expert  6 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142520.142520 lmp.py:767]   Expert 40 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142401.142401 lmp.py:767]   Expert 13 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142044.142044 lmp.py:767]   Expert 41 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142925.142925 lmp.py:767]   Expert  3 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.142091.142091 lmp.py:767]   Expert 46 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.142734.142734 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143901.143901 lmp.py:767]   Expert 25 |    187 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143544.143544 lmp.py:767]   Expert 37 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143902.143902 lmp.py:767]   Expert 19 |    190 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143260.143260 lmp.py:767]   Expert 51 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143141.143141 lmp.py:767]   Expert 35 |    195 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143784.143784 lmp.py:767]   Expert 11 |    201 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143950.143950 lmp.py:767]   Expert 43 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143355.143355 lmp.py:767]   Expert 23 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143521.143521 lmp.py:767]   Expert 17 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143926.143926 lmp.py:767]   Expert 31 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143092.143092 lmp.py:767]   Expert 49 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143450.143450 lmp.py:767]   Expert 39 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143332.143332 lmp.py:767]   Expert 53 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143498.143498 lmp.py:767]   Expert 10 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143902.143902 lmp.py:767]   Expert 33 |    251 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143307.143307 lmp.py:767]   Expert 36 |    265 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143427.143427 lmp.py:767]   Expert 38 |    268 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143023.143023 lmp.py:767]   Expert  4 |    310 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143905.143905 lmp.py:767]   Expert 21 |    334 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143786.143786 lmp.py:767]   Expert 14 |    343 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143191.143191 lmp.py:767]   Expert 63 |    354 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143834.143834 lmp.py:767]   Expert 45 |    372 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143000.143000 lmp.py:767]   Expert 61 |    393 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143643.143643 lmp.py:767]   Expert  9 |    397 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143570.143570 lmp.py:767]   Expert 29 |    490 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.143452.143452 lmp.py:767]   Expert  7 |    512 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.143379.143379 lmp.py:769] 
DEBUG 01-07 14:54:50.143379.143379 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.143022.143022 lmp.py:770]   CPU:   1964 tokens
DEBUG 01-07 14:54:50.143142.143142 lmp.py:774]   cuda:1:   5089 tokens (22 experts)
DEBUG 01-07 14:54:50.143785.143785 lmp.py:774]   cuda:2:   5235 tokens (23 experts)
DEBUG 01-07 14:54:50.143713.143713 lmp.py:775]   Total GPU:  10324 tokens
DEBUG 01-07 14:54:50.143641.143641 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.143641.143641 lmp.py:776] 
DEBUG 01-07 14:54:50.143290.143290 cuda_h.py:19] end experts_map_get cost 0.0017788410186767578 seconds
DEBUG 01-07 14:54:50.143126.143126 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.143187.143187 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.143667.143667 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.144530.144530 cuda_h.py:19] end allocate_cuda_memory cost 0.00021791458129882812 seconds
DEBUG 01-07 14:54:50.144340.144340 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.144573.144573 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.144428.144428 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.144078.144078 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf2050d3-a8b3-48bd-a932-55d5c3ea76e4
DEBUG 01-07 14:54:50.144481.144481 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.144214.144214 client.py:127] Model loaded
DEBUG 01-07 14:54:50.144282.144282 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.144619.144619 cuda_h.py:19] end restore2model cost 0.0003218650817871094 seconds
DEBUG 01-07 14:54:50.144958.144958 cuda_h.py:19] end sllm_worker_task cost 0.008939743041992188 seconds
INFO 01-07 14:54:50.145526.145526 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf2050d3-a8b3-48bd-a932-55d5c3ea76e4
DEBUG 01-07 14:54:50.145846.145846 cuda_h.py:19] end load_into_gpu_async cost 0.0010421276092529297 seconds
DEBUG 01-07 14:54:50.145834.145834 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.145459.145459 cuda_h.py:19] end restore_tensors2 cost 0.0002620220184326172 seconds
DEBUG 01-07 14:54:50.145229.145229 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018353462219238281 seconds
DEBUG 01-07 14:54:50.145276.145276 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.147822.147822 cuda_h.py:19] end restore2model cost 0.0018143653869628906 seconds
DEBUG 01-07 14:54:50.147639.147639 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.147404.147404 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.147412.147412 cuda_h.py:19] end allocate_cuda_memory cost 0.0002193450927734375 seconds
DEBUG 01-07 14:54:50.147964.147964 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.147051.147051 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.147476.147476 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.147410.147410 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cda26e97-22d0-4f83-8990-a0f843acf595
DEBUG 01-07 14:54:50.148786.148786 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.148545.148545 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cda26e97-22d0-4f83-8990-a0f843acf595
DEBUG 01-07 14:54:50.149228.149228 cuda_h.py:19] end load_into_gpu_async cost 0.0011472702026367188 seconds
DEBUG 01-07 14:54:50.149309.149309 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.149125.149125 cuda_h.py:19] end restore_tensors2 cost 0.0002269744873046875 seconds
DEBUG 01-07 14:54:50.149418.149418 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018801689147949219 seconds
DEBUG 01-07 14:54:50.149313.149313 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.151952.151952 cuda_h.py:19] end restore2model cost 0.001850128173828125 seconds
DEBUG 01-07 14:54:50.151834.151834 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007699489593505859 seconds
DEBUG 01-07 14:54:50.151484.151484 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.151063.151063 lmp.py:816] 
DEBUG 01-07 14:54:50.151063.151063 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.151522.151522 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-07 14:54:50.151933.151933 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.157797.157797 mlpmodule.py:749] group tensors cost 0.006089448928833008 s
DEBUG 01-07 14:54:50.160721.160721 mlpmodule.py:787] pad cost 0.0017001628875732422 s
DEBUG 01-07 14:54:50.160156.160156 mlpmodule.py:793] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-07 14:54:50.160557.160557 mlpmodule.py:798] move to cpu cost 4.8160552978515625e-05 s
DEBUG 01-07 14:54:50.169798.169798 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.169134.169134 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.169872.169872 mlpmodule.py:818] group_w3 first element: -0.0034942626953125
WARNING 01-07 14:54:50.169114.169114 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.183143.183143 mlpmodule.py:838] group einsum cost 0.022740602493286133 s
DEBUG 01-07 14:54:50.183767.183767 mlpmodule.py:846] cpy2cputensor cost 0.00046443939208984375 s
DEBUG 01-07 14:54:50.186795.186795 cuda_h.py:19] end wait_cetm_experts cost 0.03479361534118652 seconds
DEBUG 01-07 14:54:50.186348.186348 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.186630.186630 cuda_h.py:19] end gpu_sexperts cost 0.0004813671112060547 seconds
DEBUG 01-07 14:54:50.187950.187950 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.187568.187568 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 14:54:50.187940.187940 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.187365.187365 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf2050d3-a8b3-48bd-a932-55d5c3ea76e4
INFO 01-07 14:54:50.188696.188696 client.py:127] Model loaded
INFO 01-07 14:54:50.188956.188956 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cda26e97-22d0-4f83-8990-a0f843acf595
INFO 01-07 14:54:50.188618.188618 client.py:127] Model loaded
DEBUG 01-07 14:54:50.188685.188685 cuda_h.py:19] end wait_experts_multi_device cost 0.0014677047729492188 seconds
DEBUG 01-07 14:54:50.188580.188580 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.188496.188496 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.189071.189071 mlpmodule.py:533] gpu group tensors cost 0.0005004405975341797 s
DEBUG 01-07 14:54:50.191137.191137 mlpmodule.py:566] gpu pad cost 0.0013191699981689453 s
DEBUG 01-07 14:54:50.191363.191363 mlpmodule.py:584] gpu group einsum cost 0.0005509853363037109 s
DEBUG 01-07 14:54:50.193009.193009 mlpmodule.py:707]  experts func einsum cost 0.041731834411621094 s
DEBUG 01-07 14:54:50.194134.194134 mlpmodule.py:656] gpu experts func einsum cost 0.00475764274597168 s
DEBUG 01-07 14:54:50.194502.194502 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.195023.195023 mlpmodule.py:533] gpu group tensors cost 0.0004487037658691406 s
DEBUG 01-07 14:54:50.196710.196710 mlpmodule.py:566] gpu pad cost 0.0012574195861816406 s
DEBUG 01-07 14:54:50.196370.196370 mlpmodule.py:584] gpu group einsum cost 0.0004558563232421875 s
DEBUG 01-07 14:54:50.198946.198946 mlpmodule.py:656] gpu experts func einsum cost 0.00425410270690918 s
DEBUG 01-07 14:54:50.199075.199075 cuda_h.py:19] end gpu_experts_multi_device cost 0.010378360748291016 seconds
DEBUG 01-07 14:54:50.199475.199475 cuda_h.py:19] end layer_moe_generate_multi_device_19 cost 0.05807757377624512 seconds
DEBUG 01-07 14:54:50.199476.199476 lmp.py:194] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-07 14:54:50.199253.199253 lmp.py:153] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-07 14:54:50.199870.199870 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 14:54:50.199434.199434 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 14:54:50.199932.199932 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.574920654296875e-05 seconds
DEBUG 01-07 14:54:50.199443.199443 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.507469177246094e-05 seconds
DEBUG 01-07 14:54:50.199755.199755 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.199068.199068 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.199395.199395 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.199251.199251 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.199650.199650 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.200946.200946 cuda_h.py:19] end allocate_cuda_memory cost 0.0002875328063964844 seconds
DEBUG 01-07 14:54:50.200133.200133 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.200035.200035 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.200666.200666 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.200700.200700 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc79ad84-411d-4e20-8932-5fedd128f5e0
DEBUG 01-07 14:54:50.200060.200060 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.200328.200328 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.201017.201017 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc79ad84-411d-4e20-8932-5fedd128f5e0
DEBUG 01-07 14:54:50.201422.201422 cuda_h.py:19] end load_into_gpu_async cost 0.0008819103240966797 seconds
DEBUG 01-07 14:54:50.201741.201741 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.201777.201777 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-07 14:54:50.201533.201533 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014796257019042969 seconds
INFO 01-07 14:54:50.201184.201184 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc79ad84-411d-4e20-8932-5fedd128f5e0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.204348.204348 cuda_h.py:19] end self_attn cost 0.0036618709564208984 seconds
DEBUG 01-07 14:54:50.204690.204690 cuda_h.py:19] end iln_self_attn_paln cost 0.005155324935913086 seconds
DEBUG 01-07 14:54:50.204420.204420 cuda_h.py:10] start layer_moe_generate_multi_device_20
DEBUG 01-07 14:54:50.204799.204799 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.205947.205947 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-07 14:54:50.205392.205392 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.205347.205347 lmp.py:744] 
DEBUG 01-07 14:54:50.205347.205347 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.206248.206248 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.206137.206137 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.206164.206164 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.206807.206807 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.206973.206973 lmp.py:749] 
DEBUG 01-07 14:54:50.206973.206973 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.206616.206616 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.206981.206981 lmp.py:767]   Expert 54 |     27 | CPU
DEBUG 01-07 14:54:50.206862.206862 lmp.py:767]   Expert  3 |     35 | CPU
DEBUG 01-07 14:54:50.206790.206790 lmp.py:767]   Expert  8 |     41 | CPU
DEBUG 01-07 14:54:50.206195.206195 lmp.py:767]   Expert 28 |     42 | CPU
DEBUG 01-07 14:54:50.206838.206838 lmp.py:767]   Expert 43 |     55 | CPU
DEBUG 01-07 14:54:50.206527.206527 lmp.py:767]   Expert 63 |     56 | CPU
DEBUG 01-07 14:54:50.206455.206455 lmp.py:767]   Expert 36 |     69 | CPU
DEBUG 01-07 14:54:50.206905.206905 lmp.py:767]   Expert 38 |     75 | CPU
DEBUG 01-07 14:54:50.206595.206595 lmp.py:767]   Expert  6 |     81 | CPU
DEBUG 01-07 14:54:50.206046.206046 lmp.py:767]   Expert 39 |     92 | CPU
DEBUG 01-07 14:54:50.206735.206735 lmp.py:767]   Expert 57 |    100 | CPU
DEBUG 01-07 14:54:50.206140.206140 lmp.py:767]   Expert 52 |    103 | CPU
DEBUG 01-07 14:54:50.206829.206829 lmp.py:767]   Expert 41 |    106 | CPU
DEBUG 01-07 14:54:50.206803.206803 lmp.py:767]   Expert 12 |    110 | CPU
DEBUG 01-07 14:54:50.206254.206254 lmp.py:767]   Expert 19 |    119 | CPU
DEBUG 01-07 14:54:50.206705.206705 lmp.py:767]   Expert 47 |    119 | CPU
DEBUG 01-07 14:54:50.206917.206917 lmp.py:767]   Expert 13 |    135 | CPU
DEBUG 01-07 14:54:50.206368.206368 lmp.py:767]   Expert 22 |    146 | CPU
DEBUG 01-07 14:54:50.206819.206819 lmp.py:767]   Expert 46 |    153 | CPU
DEBUG 01-07 14:54:50.206177.206177 lmp.py:767]   Expert 50 |    156 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206251.206251 lmp.py:767]   Expert 20 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206370.206370 lmp.py:767]   Expert 55 |    164 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206252.206252 lmp.py:767]   Expert 40 |    165 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206133.206133 lmp.py:767]   Expert 24 |    166 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206538.206538 lmp.py:767]   Expert 37 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206658.206658 lmp.py:767]   Expert 23 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206162.206162 lmp.py:767]   Expert 53 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206758.206758 lmp.py:767]   Expert 21 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206447.206447 lmp.py:767]   Expert 49 |    178 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206898.206898 lmp.py:767]   Expert 42 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206588.206588 lmp.py:767]   Expert  2 |    180 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206277.206277 lmp.py:767]   Expert 61 |    181 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206966.206966 lmp.py:767]   Expert 18 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206179.206179 lmp.py:767]   Expert 32 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206106.206106 lmp.py:767]   Expert 33 |    192 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206465.206465 lmp.py:767]   Expert  0 |    198 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206631.206631 lmp.py:767]   Expert  5 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206082.206082 lmp.py:767]   Expert 16 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206771.206771 lmp.py:767]   Expert 30 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206606.206606 lmp.py:767]   Expert  7 |    206 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206295.206295 lmp.py:767]   Expert 14 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206746.206746 lmp.py:767]   Expert 31 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206197.206197 lmp.py:767]   Expert 34 |    210 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206171.206171 lmp.py:767]   Expert 62 |    216 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206860.206860 lmp.py:767]   Expert 60 |    217 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206311.206311 lmp.py:767]   Expert 17 |    220 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206524.206524 lmp.py:767]   Expert 59 |    220 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206213.206213 lmp.py:767]   Expert  9 |    221 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206664.206664 lmp.py:767]   Expert 10 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.206115.206115 lmp.py:767]   Expert 29 |    231 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.206996.206996 lmp.py:767]   Expert  4 |    234 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207447.207447 lmp.py:767]   Expert 15 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207660.207660 lmp.py:767]   Expert 58 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207872.207872 lmp.py:767]   Expert 26 |    244 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207323.207323 lmp.py:767]   Expert 51 |    252 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207297.207297 lmp.py:767]   Expert 11 |    258 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207509.207509 lmp.py:767]   Expert 44 |    270 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207722.207722 lmp.py:767]   Expert 56 |    286 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207934.207934 lmp.py:767]   Expert 27 |    290 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207339.207339 lmp.py:767]   Expert  1 |    337 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207028.207028 lmp.py:767]   Expert 45 |    361 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207718.207718 lmp.py:767]   Expert 25 |    463 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207930.207930 lmp.py:767]   Expert 35 |    516 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.207143.207143 lmp.py:767]   Expert 48 |    641 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.207640.207640 lmp.py:769] 
DEBUG 01-07 14:54:50.207640.207640 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.207614.207614 lmp.py:770]   CPU:   1664 tokens
DEBUG 01-07 14:54:50.207018.207018 lmp.py:774]   cuda:1:   5390 tokens (23 experts)
DEBUG 01-07 14:54:50.207946.207946 lmp.py:774]   cuda:2:   5234 tokens (22 experts)
DEBUG 01-07 14:54:50.207920.207920 lmp.py:775]   Total GPU:  10624 tokens
DEBUG 01-07 14:54:50.207179.207179 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.207179.207179 lmp.py:776] 
DEBUG 01-07 14:54:50.207637.207637 cuda_h.py:19] end experts_map_get cost 0.0017321109771728516 seconds
DEBUG 01-07 14:54:50.207564.207564 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.207864.207864 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.207444.207444 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.207764.207764 cuda_h.py:19] end allocate_cuda_memory cost 0.00024008750915527344 seconds
DEBUG 01-07 14:54:50.207144.207144 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.207900.207900 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.207663.207663 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.207597.207597 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a85dc6e-c530-4dc2-ad9a-37835a34b6ac
DEBUG 01-07 14:54:50.208900.208900 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.208475.208475 client.py:127] Model loaded
DEBUG 01-07 14:54:50.208019.208019 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.208846.208846 cuda_h.py:19] end restore2model cost 0.0003306865692138672 seconds
DEBUG 01-07 14:54:50.208900.208900 cuda_h.py:19] end sllm_worker_task cost 0.0089111328125 seconds
INFO 01-07 14:54:50.208294.208294 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a85dc6e-c530-4dc2-ad9a-37835a34b6ac
DEBUG 01-07 14:54:50.208044.208044 cuda_h.py:19] end load_into_gpu_async cost 0.0009472370147705078 seconds
DEBUG 01-07 14:54:50.208032.208032 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.209783.209783 cuda_h.py:19] end restore_tensors2 cost 0.00024819374084472656 seconds
DEBUG 01-07 14:54:50.209314.209314 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017502307891845703 seconds
DEBUG 01-07 14:54:50.209123.209123 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.211352.211352 cuda_h.py:19] end restore2model cost 0.0018622875213623047 seconds
DEBUG 01-07 14:54:50.211347.211347 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.211728.211728 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.211445.211445 cuda_h.py:19] end allocate_cuda_memory cost 0.00021576881408691406 seconds
DEBUG 01-07 14:54:50.211282.211282 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.211653.211653 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.211886.211886 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.211344.211344 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ee8c61b-41ae-49f3-82c6-e8f14bc8b41a
DEBUG 01-07 14:54:50.211050.211050 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.212717.212717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ee8c61b-41ae-49f3-82c6-e8f14bc8b41a
DEBUG 01-07 14:54:50.212401.212401 cuda_h.py:19] end load_into_gpu_async cost 0.0009710788726806641 seconds
DEBUG 01-07 14:54:50.212481.212481 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.212615.212615 cuda_h.py:19] end restore_tensors2 cost 0.00021457672119140625 seconds
DEBUG 01-07 14:54:50.212431.212431 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016853809356689453 seconds
DEBUG 01-07 14:54:50.212472.212472 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.214446.214446 cuda_h.py:19] end restore2model cost 0.001779794692993164 seconds
DEBUG 01-07 14:54:50.214422.214422 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0073888301849365234 seconds
DEBUG 01-07 14:54:50.214409.214409 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.214750.214750 lmp.py:816] 
DEBUG 01-07 14:54:50.214750.214750 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.214871.214871 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-07 14:54:50.214043.214043 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.226746.226746 mlpmodule.py:749] group tensors cost 0.011742115020751953 s
DEBUG 01-07 14:54:50.228567.228567 mlpmodule.py:787] pad cost 0.0009720325469970703 s
DEBUG 01-07 14:54:50.228439.228439 mlpmodule.py:793] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-07 14:54:50.228773.228773 mlpmodule.py:798] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-07 14:54:50.237940.237940 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.237852.237852 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.237729.237729 mlpmodule.py:818] group_w3 first element: 0.0205078125
WARNING 01-07 14:54:50.237355.237355 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.251124.251124 mlpmodule.py:838] group einsum cost 0.022865772247314453 s
DEBUG 01-07 14:54:50.252250.252250 mlpmodule.py:846] cpy2cputensor cost 0.0004305839538574219 s
DEBUG 01-07 14:54:50.254398.254398 cuda_h.py:19] end wait_cetm_experts cost 0.03960275650024414 seconds
DEBUG 01-07 14:54:50.254542.254542 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.255608.255608 cuda_h.py:19] end gpu_sexperts cost 0.0008745193481445312 seconds
DEBUG 01-07 14:54:50.255891.255891 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.256778.256778 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.340576171875e-05 seconds
DEBUG 01-07 14:54:50.256986.256986 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.256427.256427 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a85dc6e-c530-4dc2-ad9a-37835a34b6ac
INFO 01-07 14:54:50.257971.257971 client.py:127] Model loaded
INFO 01-07 14:54:50.257585.257585 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ee8c61b-41ae-49f3-82c6-e8f14bc8b41a
INFO 01-07 14:54:50.258661.258661 client.py:127] Model loaded
DEBUG 01-07 14:54:50.258818.258818 cuda_h.py:19] end wait_experts_multi_device cost 0.002184629440307617 seconds
DEBUG 01-07 14:54:50.258974.258974 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.258283.258283 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 14:54:50.261214.261214 mlpmodule.py:533] gpu group tensors cost 0.0010292530059814453 s
DEBUG 01-07 14:54:50.261805.261805 mlpmodule.py:707]  experts func einsum cost 0.04653048515319824 s
DEBUG 01-07 14:54:50.264418.264418 mlpmodule.py:566] gpu pad cost 0.003379344940185547 s
DEBUG 01-07 14:54:50.265758.265758 mlpmodule.py:584] gpu group einsum cost 0.0011267662048339844 s
DEBUG 01-07 14:54:50.268073.268073 mlpmodule.py:656] gpu experts func einsum cost 0.007927894592285156 s
DEBUG 01-07 14:54:50.268621.268621 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 14:54:50.269703.269703 mlpmodule.py:533] gpu group tensors cost 0.0004913806915283203 s
DEBUG 01-07 14:54:50.270733.270733 mlpmodule.py:566] gpu pad cost 0.0014314651489257812 s
DEBUG 01-07 14:54:50.271243.271243 mlpmodule.py:584] gpu group einsum cost 0.0005202293395996094 s
DEBUG 01-07 14:54:50.273574.273574 mlpmodule.py:656] gpu experts func einsum cost 0.004750490188598633 s
DEBUG 01-07 14:54:50.273240.273240 cuda_h.py:19] end gpu_experts_multi_device cost 0.014965534210205078 seconds
DEBUG 01-07 14:54:50.273655.273655 cuda_h.py:19] end layer_moe_generate_multi_device_20 cost 0.06888914108276367 seconds
DEBUG 01-07 14:54:50.274817.274817 lmp.py:194] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-07 14:54:50.274449.274449 lmp.py:153] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-07 14:54:50.274112.274112 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 14:54:50.274928.274928 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 14:54:50.274354.274354 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.147125244140625e-05 seconds
DEBUG 01-07 14:54:50.274614.274614 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 8.678436279296875e-05 seconds
DEBUG 01-07 14:54:50.274272.274272 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.274472.274472 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.274475.274475 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.274108.274108 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.274801.274801 cuda_h.py:19] end allocate_cuda_memory cost 0.0002982616424560547 seconds
DEBUG 01-07 14:54:50.274273.274273 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.275221.275221 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.275183.275183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.275740.275740 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cbd4390c-0c44-41a5-a228-644ffb90e30d
DEBUG 01-07 14:54:50.275604.275604 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.275144.275144 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.275191.275191 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.275975.275975 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cbd4390c-0c44-41a5-a228-644ffb90e30d
DEBUG 01-07 14:54:50.276560.276560 cuda_h.py:19] end load_into_gpu_async cost 0.001020193099975586 seconds
DEBUG 01-07 14:54:50.276647.276647 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.276214.276214 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-07 14:54:50.276692.276692 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016453266143798828 seconds
INFO 01-07 14:54:50.276363.276363 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cbd4390c-0c44-41a5-a228-644ffb90e30d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.279961.279961 cuda_h.py:19] end self_attn cost 0.0037119388580322266 seconds
DEBUG 01-07 14:54:50.279236.279236 cuda_h.py:19] end iln_self_attn_paln cost 0.005270242691040039 seconds
DEBUG 01-07 14:54:50.279681.279681 cuda_h.py:10] start layer_moe_generate_multi_device_21
DEBUG 01-07 14:54:50.279014.279014 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.280785.280785 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-07 14:54:50.280707.280707 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.281793.281793 lmp.py:744] 
DEBUG 01-07 14:54:50.281793.281793 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.281410.281410 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.281252.281252 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.281333.281333 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.281691.281691 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.281618.281618 lmp.py:749] 
DEBUG 01-07 14:54:50.281618.281618 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.281261.281261 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.281865.281865 lmp.py:767]   Expert 44 |     26 | CPU
DEBUG 01-07 14:54:50.281746.281746 lmp.py:767]   Expert  9 |     32 | CPU
DEBUG 01-07 14:54:50.281389.281389 lmp.py:767]   Expert 11 |     39 | CPU
DEBUG 01-07 14:54:50.281317.281317 lmp.py:767]   Expert 56 |     59 | CPU
DEBUG 01-07 14:54:50.281198.281198 lmp.py:767]   Expert 54 |     81 | CPU
DEBUG 01-07 14:54:50.281080.281080 lmp.py:767]   Expert  7 |     86 | CPU
DEBUG 01-07 14:54:50.281723.281723 lmp.py:767]   Expert 47 |     92 | CPU
DEBUG 01-07 14:54:50.281889.281889 lmp.py:767]   Expert 62 |     93 | CPU
DEBUG 01-07 14:54:50.281055.281055 lmp.py:767]   Expert 60 |    104 | CPU
DEBUG 01-07 14:54:50.281221.281221 lmp.py:767]   Expert 51 |    108 | CPU
DEBUG 01-07 14:54:50.281149.281149 lmp.py:767]   Expert 53 |    108 | CPU
DEBUG 01-07 14:54:50.281077.281077 lmp.py:767]   Expert 52 |    109 | CPU
DEBUG 01-07 14:54:50.281004.281004 lmp.py:767]   Expert 41 |    111 | CPU
DEBUG 01-07 14:54:50.281932.281932 lmp.py:767]   Expert 22 |    112 | CPU
DEBUG 01-07 14:54:50.281383.281383 lmp.py:767]   Expert  8 |    121 | CPU
DEBUG 01-07 14:54:50.281026.281026 lmp.py:767]   Expert 48 |    124 | CPU
DEBUG 01-07 14:54:50.281430.281430 lmp.py:767]   Expert  1 |    128 | CPU
DEBUG 01-07 14:54:50.281358.281358 lmp.py:767]   Expert  6 |    128 | CPU
DEBUG 01-07 14:54:50.281286.281286 lmp.py:767]   Expert 32 |    128 | CPU
DEBUG 01-07 14:54:50.281406.281406 lmp.py:767]   Expert  2 |    132 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281241.281241 lmp.py:767]   Expert 23 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281122.281122 lmp.py:767]   Expert 27 |    139 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281004.281004 lmp.py:767]   Expert 35 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281885.281885 lmp.py:767]   Expert 59 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281005.281005 lmp.py:767]   Expert 39 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281886.281886 lmp.py:767]   Expert 26 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281529.281529 lmp.py:767]   Expert 50 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281695.281695 lmp.py:767]   Expert 14 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281100.281100 lmp.py:767]   Expert 46 |    168 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281743.281743 lmp.py:767]   Expert  0 |    170 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281147.281147 lmp.py:767]   Expert 24 |    170 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281552.281552 lmp.py:767]   Expert 49 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281956.281956 lmp.py:767]   Expert 34 |    172 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281361.281361 lmp.py:767]   Expert  4 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281481.281481 lmp.py:767]   Expert 38 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281601.281601 lmp.py:767]   Expert 40 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281482.281482 lmp.py:767]   Expert  5 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281887.281887 lmp.py:767]   Expert 63 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281530.281530 lmp.py:767]   Expert 19 |    194 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281411.281411 lmp.py:767]   Expert 29 |    200 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281292.281292 lmp.py:767]   Expert 43 |    200 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281412.281412 lmp.py:767]   Expert 13 |    202 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281294.281294 lmp.py:767]   Expert 57 |    207 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281175.281175 lmp.py:767]   Expert 61 |    217 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281818.281818 lmp.py:767]   Expert 33 |    223 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.281461.281461 lmp.py:767]   Expert 31 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.281865.281865 lmp.py:767]   Expert 16 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282747.282747 lmp.py:767]   Expert 20 |    253 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282151.282151 lmp.py:767]   Expert 37 |    255 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282033.282033 lmp.py:767]   Expert  3 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282676.282676 lmp.py:767]   Expert 15 |    266 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282319.282319 lmp.py:767]   Expert 18 |    276 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282723.282723 lmp.py:767]   Expert 36 |    276 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282128.282128 lmp.py:767]   Expert 12 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282009.282009 lmp.py:767]   Expert 28 |    299 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282414.282414 lmp.py:767]   Expert 17 |    304 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282818.282818 lmp.py:767]   Expert 55 |    315 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282938.282938 lmp.py:767]   Expert 25 |    319 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282535.282535 lmp.py:767]   Expert 30 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282178.282178 lmp.py:767]   Expert 58 |    338 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282821.282821 lmp.py:767]   Expert 10 |    362 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282464.282464 lmp.py:767]   Expert 45 |    382 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282345.282345 lmp.py:767]   Expert 21 |    389 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.282988.282988 lmp.py:767]   Expert 42 |    641 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.282677.282677 lmp.py:769] 
DEBUG 01-07 14:54:50.282677.282677 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.282559.282559 lmp.py:770]   CPU:   1789 tokens
DEBUG 01-07 14:54:50.282632.282632 lmp.py:774]   cuda:1:   5248 tokens (22 experts)
DEBUG 01-07 14:54:50.282037.282037 lmp.py:774]   cuda:2:   5251 tokens (23 experts)
DEBUG 01-07 14:54:50.282441.282441 lmp.py:775]   Total GPU:  10499 tokens
DEBUG 01-07 14:54:50.282369.282369 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.282369.282369 lmp.py:776] 
DEBUG 01-07 14:54:50.282019.282019 cuda_h.py:19] end experts_map_get cost 0.0017809867858886719 seconds
DEBUG 01-07 14:54:50.282900.282900 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.282723.282723 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.282349.282349 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.282881.282881 cuda_h.py:19] end allocate_cuda_memory cost 0.00021886825561523438 seconds
DEBUG 01-07 14:54:50.282049.282049 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.282282.282282 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.283522.283522 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.283132.283132 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e67c01c5-4517-4c20-986b-6df875c227e7
DEBUG 01-07 14:54:50.283284.283284 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.283885.283885 client.py:127] Model loaded
DEBUG 01-07 14:54:50.283722.283722 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.283503.283503 cuda_h.py:19] end restore2model cost 0.00036454200744628906 seconds
DEBUG 01-07 14:54:50.283895.283895 cuda_h.py:19] end sllm_worker_task cost 0.009413003921508789 seconds
INFO 01-07 14:54:50.284286.284286 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e67c01c5-4517-4c20-986b-6df875c227e7
DEBUG 01-07 14:54:50.284693.284693 cuda_h.py:19] end load_into_gpu_async cost 0.0011742115020751953 seconds
DEBUG 01-07 14:54:50.284508.284508 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.284931.284931 cuda_h.py:19] end restore_tensors2 cost 0.0003123283386230469 seconds
DEBUG 01-07 14:54:50.284436.284436 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020797252655029297 seconds
DEBUG 01-07 14:54:50.284259.284259 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.287573.287573 cuda_h.py:19] end restore2model cost 0.0028243064880371094 seconds
DEBUG 01-07 14:54:50.287107.287107 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.287900.287900 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.288296.288296 cuda_h.py:19] end allocate_cuda_memory cost 0.0003044605255126953 seconds
DEBUG 01-07 14:54:50.288803.288803 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.288169.288169 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.288628.288628 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.288080.288080 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80757eb7-c1ab-407c-8e2d-f79cfc2930fc
DEBUG 01-07 14:54:50.288392.288392 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.289656.289656 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80757eb7-c1ab-407c-8e2d-f79cfc2930fc
DEBUG 01-07 14:54:50.289102.289102 cuda_h.py:19] end load_into_gpu_async cost 0.0015711784362792969 seconds
DEBUG 01-07 14:54:50.289687.289687 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.290257.290257 cuda_h.py:19] end restore_tensors2 cost 0.00037670135498046875 seconds
DEBUG 01-07 14:54:50.290736.290736 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027303695678710938 seconds
DEBUG 01-07 14:54:50.290904.290904 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.293030.293030 cuda_h.py:19] end restore2model cost 0.0033457279205322266 seconds
DEBUG 01-07 14:54:50.293570.293570 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.01145792007446289 seconds
DEBUG 01-07 14:54:50.293723.293723 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.294132.294132 lmp.py:816] 
DEBUG 01-07 14:54:50.294132.294132 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.294062.294062 cuda_h.py:19] end cpu_experts_submit cost 0.00016999244689941406 seconds
DEBUG 01-07 14:54:50.294116.294116 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.308273.308273 mlpmodule.py:749] group tensors cost 0.013820648193359375 s
DEBUG 01-07 14:54:50.309661.309661 mlpmodule.py:787] pad cost 0.0009899139404296875 s
DEBUG 01-07 14:54:50.309459.309459 mlpmodule.py:793] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-07 14:54:50.310600.310600 mlpmodule.py:798] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-07 14:54:50.318735.318735 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.318747.318747 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.318730.318730 mlpmodule.py:818] group_w3 first element: 0.00066375732421875
WARNING 01-07 14:54:50.318555.318555 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.330900.330900 mlpmodule.py:838] group einsum cost 0.020167112350463867 s
DEBUG 01-07 14:54:50.330706.330706 mlpmodule.py:846] cpy2cputensor cost 0.00035691261291503906 s
DEBUG 01-07 14:54:50.333242.333242 cuda_h.py:19] end wait_cetm_experts cost 0.03888559341430664 seconds
DEBUG 01-07 14:54:50.333857.333857 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.334397.334397 cuda_h.py:19] end gpu_sexperts cost 0.0009596347808837891 seconds
DEBUG 01-07 14:54:50.334985.334985 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.334912.334912 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.364418029785156e-05 seconds
DEBUG 01-07 14:54:50.334259.334259 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.334620.334620 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e67c01c5-4517-4c20-986b-6df875c227e7
INFO 01-07 14:54:50.336598.336598 client.py:127] Model loaded
INFO 01-07 14:54:50.336874.336874 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80757eb7-c1ab-407c-8e2d-f79cfc2930fc
INFO 01-07 14:54:50.336917.336917 client.py:127] Model loaded
DEBUG 01-07 14:54:50.337260.337260 cuda_h.py:19] end wait_experts_multi_device cost 0.002120494842529297 seconds
DEBUG 01-07 14:54:50.337078.337078 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.337957.337957 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.339166.339166 mlpmodule.py:533] gpu group tensors cost 0.001054525375366211 s
DEBUG 01-07 14:54:50.340625.340625 mlpmodule.py:707]  experts func einsum cost 0.04612326622009277 s
DEBUG 01-07 14:54:50.343386.343386 mlpmodule.py:566] gpu pad cost 0.0034608840942382812 s
DEBUG 01-07 14:54:50.344306.344306 mlpmodule.py:584] gpu group einsum cost 0.0012006759643554688 s
DEBUG 01-07 14:54:50.348467.348467 mlpmodule.py:656] gpu experts func einsum cost 0.009648561477661133 s
DEBUG 01-07 14:54:50.348822.348822 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.349869.349869 mlpmodule.py:533] gpu group tensors cost 0.0004596710205078125 s
DEBUG 01-07 14:54:50.350803.350803 mlpmodule.py:566] gpu pad cost 0.0013265609741210938 s
DEBUG 01-07 14:54:50.351054.351054 mlpmodule.py:584] gpu group einsum cost 0.0005013942718505859 s
DEBUG 01-07 14:54:50.353507.353507 mlpmodule.py:656] gpu experts func einsum cost 0.004476308822631836 s
DEBUG 01-07 14:54:50.353948.353948 cuda_h.py:19] end gpu_experts_multi_device cost 0.016396045684814453 seconds
DEBUG 01-07 14:54:50.353303.353303 cuda_h.py:19] end layer_moe_generate_multi_device_21 cost 0.0739138126373291 seconds
DEBUG 01-07 14:54:50.354512.354512 lmp.py:194] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-07 14:54:50.354037.354037 lmp.py:153] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-07 14:54:50.354853.354853 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 14:54:50.354828.354828 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 14:54:50.354539.354539 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.123283386230469e-05 seconds
DEBUG 01-07 14:54:50.354156.354156 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.890296936035156e-05 seconds
DEBUG 01-07 14:54:50.354536.354536 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.354259.354259 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.354215.354215 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.354855.354855 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.355006.355006 cuda_h.py:19] end allocate_cuda_memory cost 0.0003197193145751953 seconds
DEBUG 01-07 14:54:50.355432.355432 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.355096.355096 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.355488.355488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.355045.355045 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 642f7371-36a6-44aa-bc15-98a5083cf00f
DEBUG 01-07 14:54:50.355670.355670 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.355449.355449 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.355688.355688 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.355058.355058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 642f7371-36a6-44aa-bc15-98a5083cf00f
DEBUG 01-07 14:54:50.356894.356894 cuda_h.py:19] end load_into_gpu_async cost 0.000904083251953125 seconds
DEBUG 01-07 14:54:50.356405.356405 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.356488.356488 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-07 14:54:50.356575.356575 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015377998352050781 seconds
INFO 01-07 14:54:50.356742.356742 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 642f7371-36a6-44aa-bc15-98a5083cf00f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.359050.359050 cuda_h.py:19] end self_attn cost 0.003813028335571289 seconds
DEBUG 01-07 14:54:50.359464.359464 cuda_h.py:19] end iln_self_attn_paln cost 0.00538182258605957 seconds
DEBUG 01-07 14:54:50.360956.360956 cuda_h.py:10] start layer_moe_generate_multi_device_22
DEBUG 01-07 14:54:50.360142.360142 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.360484.360484 cuda_h.py:19] end gate cost 0.0006756782531738281 seconds
DEBUG 01-07 14:54:50.360598.360598 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.361777.361777 lmp.py:744] 
DEBUG 01-07 14:54:50.361777.361777 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.361249.361249 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.361614.361614 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.361926.361926 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.361330.361330 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.361543.361543 lmp.py:749] 
DEBUG 01-07 14:54:50.361543.361543 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.361232.361232 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.361405.361405 lmp.py:767]   Expert 25 |     14 | CPU
DEBUG 01-07 14:54:50.361333.361333 lmp.py:767]   Expert 48 |     36 | CPU
DEBUG 01-07 14:54:50.361783.361783 lmp.py:767]   Expert 45 |     38 | CPU
DEBUG 01-07 14:54:50.361758.361758 lmp.py:767]   Expert  9 |     65 | CPU
DEBUG 01-07 14:54:50.361732.361732 lmp.py:767]   Expert 54 |     83 | CPU
DEBUG 01-07 14:54:50.361421.361421 lmp.py:767]   Expert 43 |     85 | CPU
DEBUG 01-07 14:54:50.361110.361110 lmp.py:767]   Expert  0 |     86 | CPU
DEBUG 01-07 14:54:50.361084.361084 lmp.py:767]   Expert 20 |     87 | CPU
DEBUG 01-07 14:54:50.361535.361535 lmp.py:767]   Expert 47 |     89 | CPU
DEBUG 01-07 14:54:50.361271.361271 lmp.py:767]   Expert 57 |     89 | CPU
DEBUG 01-07 14:54:50.361006.361006 lmp.py:767]   Expert 36 |     94 | CPU
DEBUG 01-07 14:54:50.361980.361980 lmp.py:767]   Expert  6 |     96 | CPU
DEBUG 01-07 14:54:50.361954.361954 lmp.py:767]   Expert 62 |    100 | CPU
DEBUG 01-07 14:54:50.361690.361690 lmp.py:767]   Expert 61 |    104 | CPU
DEBUG 01-07 14:54:50.361187.361187 lmp.py:767]   Expert 13 |    105 | CPU
DEBUG 01-07 14:54:50.361638.361638 lmp.py:767]   Expert 15 |    107 | CPU
DEBUG 01-07 14:54:50.361089.361089 lmp.py:767]   Expert 38 |    110 | CPU
DEBUG 01-07 14:54:50.361447.361447 lmp.py:767]   Expert 50 |    112 | CPU
DEBUG 01-07 14:54:50.361613.361613 lmp.py:767]   Expert 37 |    113 | CPU
DEBUG 01-07 14:54:50.361733.361733 lmp.py:767]   Expert 46 |    114 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361091.361091 lmp.py:767]   Expert  1 |    116 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361211.361211 lmp.py:767]   Expert 14 |    121 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361331.361331 lmp.py:767]   Expert  7 |    137 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361736.361736 lmp.py:767]   Expert 28 |    141 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361379.361379 lmp.py:767]   Expert 21 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361260.361260 lmp.py:767]   Expert 44 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361903.361903 lmp.py:767]   Expert 52 |    143 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361546.361546 lmp.py:767]   Expert 10 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361619.361619 lmp.py:767]   Expert 42 |    152 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361216.361216 lmp.py:767]   Expert 24 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361336.361336 lmp.py:767]   Expert 11 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361217.361217 lmp.py:767]   Expert  2 |    162 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361099.361099 lmp.py:767]   Expert 35 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361980.361980 lmp.py:767]   Expert 26 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.361623.361623 lmp.py:767]   Expert 31 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.361266.361266 lmp.py:767]   Expert  3 |    185 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362147.362147 lmp.py:767]   Expert 32 |    185 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362506.362506 lmp.py:767]   Expert 19 |    187 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362149.362149 lmp.py:767]   Expert 12 |    191 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362030.362030 lmp.py:767]   Expert 56 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362673.362673 lmp.py:767]   Expert 60 |    208 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362316.362316 lmp.py:767]   Expert 40 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362721.362721 lmp.py:767]   Expert 41 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362363.362363 lmp.py:767]   Expert 53 |    224 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362006.362006 lmp.py:767]   Expert 23 |    233 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362126.362126 lmp.py:767]   Expert 58 |    233 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362008.362008 lmp.py:767]   Expert 51 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362174.362174 lmp.py:767]   Expert  8 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362578.362578 lmp.py:767]   Expert 16 |    239 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362221.362221 lmp.py:767]   Expert 59 |    248 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362387.362387 lmp.py:767]   Expert  4 |    250 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362792.362792 lmp.py:767]   Expert 55 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362197.362197 lmp.py:767]   Expert 49 |    270 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362840.362840 lmp.py:767]   Expert 29 |    275 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362244.362244 lmp.py:767]   Expert 18 |    280 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362364.362364 lmp.py:767]   Expert 34 |    289 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362007.362007 lmp.py:767]   Expert 63 |    293 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362888.362888 lmp.py:767]   Expert 27 |    353 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362293.362293 lmp.py:767]   Expert 39 |    375 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362459.362459 lmp.py:767]   Expert 17 |    390 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362864.362864 lmp.py:767]   Expert 22 |    425 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362791.362791 lmp.py:767]   Expert 30 |    453 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362957.362957 lmp.py:767]   Expert 33 |    457 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.362600.362600 lmp.py:767]   Expert  5 |    715 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.362767.362767 lmp.py:769] 
DEBUG 01-07 14:54:50.362767.362767 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.362886.362886 lmp.py:770]   CPU:   1613 tokens
DEBUG 01-07 14:54:50.362251.362251 lmp.py:774]   cuda:1:   5308 tokens (22 experts)
DEBUG 01-07 14:54:50.362477.362477 lmp.py:774]   cuda:2:   5367 tokens (23 experts)
DEBUG 01-07 14:54:50.362558.362558 lmp.py:775]   Total GPU:  10675 tokens
DEBUG 01-07 14:54:50.362446.362446 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.362446.362446 lmp.py:776] 
DEBUG 01-07 14:54:50.362679.362679 cuda_h.py:19] end experts_map_get cost 0.0017838478088378906 seconds
DEBUG 01-07 14:54:50.362097.362097 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.362211.362211 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.362453.362453 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.363348.363348 cuda_h.py:19] end allocate_cuda_memory cost 0.00020647048950195312 seconds
DEBUG 01-07 14:54:50.363238.363238 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.363279.363279 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.363803.363803 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.363168.363168 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8fd873f3-4683-4d49-b463-f22554030718
DEBUG 01-07 14:54:50.363418.363418 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.363094.363094 client.py:127] Model loaded
DEBUG 01-07 14:54:50.363706.363706 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.364317.364317 cuda_h.py:19] end restore2model cost 0.0004088878631591797 seconds
DEBUG 01-07 14:54:50.364477.364477 cuda_h.py:19] end sllm_worker_task cost 0.00961160659790039 seconds
INFO 01-07 14:54:50.364316.364316 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8fd873f3-4683-4d49-b463-f22554030718
DEBUG 01-07 14:54:50.364643.364643 cuda_h.py:19] end load_into_gpu_async cost 0.0011780261993408203 seconds
DEBUG 01-07 14:54:50.364107.364107 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.364805.364805 cuda_h.py:19] end restore_tensors2 cost 0.00023746490478515625 seconds
DEBUG 01-07 14:54:50.364574.364574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019309520721435547 seconds
DEBUG 01-07 14:54:50.364576.364576 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.366123.366123 cuda_h.py:19] end restore2model cost 0.0018792152404785156 seconds
DEBUG 01-07 14:54:50.366470.366470 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.366182.366182 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.367005.367005 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-07 14:54:50.367749.367749 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.367598.367598 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.367453.367453 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.367865.367865 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b5e5f4d-2155-477a-8899-a6b5a4bd88c2
DEBUG 01-07 14:54:50.367816.367816 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.368289.368289 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b5e5f4d-2155-477a-8899-a6b5a4bd88c2
DEBUG 01-07 14:54:50.368868.368868 cuda_h.py:19] end load_into_gpu_async cost 0.0011417865753173828 seconds
DEBUG 01-07 14:54:50.368492.368492 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.368039.368039 cuda_h.py:19] end restore_tensors2 cost 0.00029921531677246094 seconds
DEBUG 01-07 14:54:50.368498.368498 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019910335540771484 seconds
DEBUG 01-07 14:54:50.368745.368745 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.371476.371476 cuda_h.py:19] end restore2model cost 0.0024340152740478516 seconds
DEBUG 01-07 14:54:50.371849.371849 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008604764938354492 seconds
DEBUG 01-07 14:54:50.371082.371082 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.371119.371119 lmp.py:816] 
DEBUG 01-07 14:54:50.371119.371119 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.371452.371452 cuda_h.py:19] end cpu_experts_submit cost 0.00013518333435058594 seconds
DEBUG 01-07 14:54:50.371539.371539 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.378238.378238 mlpmodule.py:749] group tensors cost 0.006679534912109375 s
DEBUG 01-07 14:54:50.380638.380638 mlpmodule.py:787] pad cost 0.0013167858123779297 s
DEBUG 01-07 14:54:50.380801.380801 mlpmodule.py:793] create cpu tensor cost 5.0067901611328125e-05 s
DEBUG 01-07 14:54:50.380294.380294 mlpmodule.py:798] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-07 14:54:50.389379.389379 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.390529.390529 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.390122.390122 mlpmodule.py:818] group_w3 first element: -0.018798828125
WARNING 01-07 14:54:50.390271.390271 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.405493.405493 mlpmodule.py:838] group einsum cost 0.02507305145263672 s
DEBUG 01-07 14:54:50.406763.406763 mlpmodule.py:846] cpy2cputensor cost 0.0003478527069091797 s
DEBUG 01-07 14:54:50.408322.408322 cuda_h.py:19] end wait_cetm_experts cost 0.037162065505981445 seconds
DEBUG 01-07 14:54:50.408699.408699 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.410954.410954 cuda_h.py:19] end gpu_sexperts cost 0.0009639263153076172 seconds
DEBUG 01-07 14:54:50.410728.410728 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.410085.410085 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.3882598876953125e-05 seconds
DEBUG 01-07 14:54:50.410485.410485 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.410714.410714 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8fd873f3-4683-4d49-b463-f22554030718
INFO 01-07 14:54:50.411282.411282 client.py:127] Model loaded
INFO 01-07 14:54:50.411128.411128 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b5e5f4d-2155-477a-8899-a6b5a4bd88c2
INFO 01-07 14:54:50.412979.412979 client.py:127] Model loaded
DEBUG 01-07 14:54:50.412440.412440 cuda_h.py:19] end wait_experts_multi_device cost 0.0021216869354248047 seconds
DEBUG 01-07 14:54:50.412827.412827 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.412777.412777 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.415568.415568 mlpmodule.py:533] gpu group tensors cost 0.0010371208190917969 s
DEBUG 01-07 14:54:50.415840.415840 mlpmodule.py:707]  experts func einsum cost 0.0438694953918457 s
DEBUG 01-07 14:54:50.418135.418135 mlpmodule.py:566] gpu pad cost 0.0031630992889404297 s
DEBUG 01-07 14:54:50.419124.419124 mlpmodule.py:584] gpu group einsum cost 0.0005769729614257812 s
DEBUG 01-07 14:54:50.421638.421638 mlpmodule.py:656] gpu experts func einsum cost 0.007702827453613281 s
DEBUG 01-07 14:54:50.422525.422525 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.423305.423305 mlpmodule.py:533] gpu group tensors cost 0.0005614757537841797 s
DEBUG 01-07 14:54:50.425868.425868 mlpmodule.py:566] gpu pad cost 0.0017075538635253906 s
DEBUG 01-07 14:54:50.425427.425427 mlpmodule.py:584] gpu group einsum cost 0.0005793571472167969 s
DEBUG 01-07 14:54:50.428462.428462 mlpmodule.py:656] gpu experts func einsum cost 0.005631923675537109 s
DEBUG 01-07 14:54:50.428234.428234 cuda_h.py:19] end gpu_experts_multi_device cost 0.01565241813659668 seconds
DEBUG 01-07 14:54:50.428534.428534 cuda_h.py:19] end layer_moe_generate_multi_device_22 cost 0.06848025321960449 seconds
DEBUG 01-07 14:54:50.428941.428941 lmp.py:194] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-07 14:54:50.428902.428902 lmp.py:153] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-07 14:54:50.428837.428837 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 14:54:50.428315.428315 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 14:54:50.428866.428866 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 14:54:50.429656.429656 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.429247.429247 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.0001308917999267578 seconds
DEBUG 01-07 14:54:50.429442.429442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.429741.429741 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.429114.429114 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.429571.429571 cuda_h.py:19] end allocate_cuda_memory cost 0.0002913475036621094 seconds
DEBUG 01-07 14:54:50.429454.429454 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.429476.429476 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.429790.429790 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.429613.429613 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.429124.429124 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1111a47-25d0-4c83-bcb0-b79473b9dc26
DEBUG 01-07 14:54:50.430153.430153 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.430599.430599 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.430491.430491 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1111a47-25d0-4c83-bcb0-b79473b9dc26
DEBUG 01-07 14:54:50.430572.430572 cuda_h.py:19] end load_into_gpu_async cost 0.0009987354278564453 seconds
DEBUG 01-07 14:54:50.430321.430321 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.430258.430258 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-07 14:54:50.431014.431014 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001773834228515625 seconds
INFO 01-07 14:54:50.431519.431519 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1111a47-25d0-4c83-bcb0-b79473b9dc26
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.433165.433165 cuda_h.py:19] end self_attn cost 0.0029883384704589844 seconds
DEBUG 01-07 14:54:50.433394.433394 cuda_h.py:19] end iln_self_attn_paln cost 0.004336118698120117 seconds
DEBUG 01-07 14:54:50.433601.433601 cuda_h.py:10] start layer_moe_generate_multi_device_23
DEBUG 01-07 14:54:50.433271.433271 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.434513.434513 cuda_h.py:19] end gate cost 0.0006723403930664062 seconds
DEBUG 01-07 14:54:50.434673.434673 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.434979.434979 lmp.py:744] 
DEBUG 01-07 14:54:50.434979.434979 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.434272.434272 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.434068.434068 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.435810.435810 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.435168.435168 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.435765.435765 lmp.py:749] 
DEBUG 01-07 14:54:50.435765.435765 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.435706.435706 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.435932.435932 lmp.py:767]   Expert  5 |     14 | CPU
DEBUG 01-07 14:54:50.435814.435814 lmp.py:767]   Expert 56 |     31 | CPU
DEBUG 01-07 14:54:50.435741.435741 lmp.py:767]   Expert 27 |     81 | CPU
DEBUG 01-07 14:54:50.435669.435669 lmp.py:767]   Expert 16 |     83 | CPU
DEBUG 01-07 14:54:50.435120.435120 lmp.py:767]   Expert 17 |     89 | CPU
DEBUG 01-07 14:54:50.435571.435571 lmp.py:767]   Expert 40 |     94 | CPU
DEBUG 01-07 14:54:50.435022.435022 lmp.py:767]   Expert 51 |    101 | CPU
DEBUG 01-07 14:54:50.435380.435380 lmp.py:767]   Expert 49 |    103 | CPU
DEBUG 01-07 14:54:50.435791.435791 lmp.py:767]   Expert 63 |    103 | CPU
DEBUG 01-07 14:54:50.435434.435434 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 14:54:50.435839.435839 lmp.py:767]   Expert  7 |    109 | CPU
DEBUG 01-07 14:54:50.435005.435005 lmp.py:767]   Expert 53 |    111 | CPU
DEBUG 01-07 14:54:50.435125.435125 lmp.py:767]   Expert 38 |    119 | CPU
DEBUG 01-07 14:54:50.435159.435159 lmp.py:767]   Expert 37 |    123 | CPU
DEBUG 01-07 14:54:50.435563.435563 lmp.py:767]   Expert 62 |    123 | CPU
DEBUG 01-07 14:54:50.435014.435014 lmp.py:767]   Expert 47 |    126 | CPU
DEBUG 01-07 14:54:50.435227.435227 lmp.py:767]   Expert 58 |    129 | CPU
DEBUG 01-07 14:54:50.435439.435439 lmp.py:767]   Expert 11 |    133 | CPU
DEBUG 01-07 14:54:50.435890.435890 lmp.py:767]   Expert 57 |    141 | CPU
DEBUG 01-07 14:54:50.435010.435010 lmp.py:767]   Expert 25 |    142 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435891.435891 lmp.py:767]   Expert 39 |    143 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435826.435826 lmp.py:767]   Expert  1 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435191.435191 lmp.py:767]   Expert 14 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435264.435264 lmp.py:767]   Expert 52 |    152 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435861.435861 lmp.py:767]   Expert 33 |    154 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435696.435696 lmp.py:767]   Expert 21 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435207.435207 lmp.py:767]   Expert 23 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435757.435757 lmp.py:767]   Expert  6 |    171 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435162.435162 lmp.py:767]   Expert 45 |    172 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435089.435089 lmp.py:767]   Expert 44 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435971.435971 lmp.py:767]   Expert 60 |    177 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435806.435806 lmp.py:767]   Expert 12 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435409.435409 lmp.py:767]   Expert 19 |    182 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435006.435006 lmp.py:767]   Expert  4 |    186 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435079.435079 lmp.py:767]   Expert  3 |    193 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435438.435438 lmp.py:767]   Expert 30 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435472.435472 lmp.py:767]   Expert 31 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435691.435691 lmp.py:767]   Expert 55 |    204 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435049.435049 lmp.py:767]   Expert  9 |    209 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435930.435930 lmp.py:767]   Expert 36 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435573.435573 lmp.py:767]   Expert 34 |    223 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435647.435647 lmp.py:767]   Expert  0 |    224 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435250.435250 lmp.py:767]   Expert 22 |    225 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435847.435847 lmp.py:767]   Expert 41 |    226 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435444.435444 lmp.py:767]   Expert 54 |    236 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435802.435802 lmp.py:767]   Expert 26 |    239 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.435790.435790 lmp.py:767]   Expert 43 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.435817.435817 lmp.py:767]   Expert 59 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436936.436936 lmp.py:767]   Expert 13 |    255 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436579.436579 lmp.py:767]   Expert 50 |    256 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436746.436746 lmp.py:767]   Expert 15 |    259 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436389.436389 lmp.py:767]   Expert 18 |    259 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436754.436754 lmp.py:767]   Expert 42 |    261 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436589.436589 lmp.py:767]   Expert 20 |    262 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436185.436185 lmp.py:767]   Expert 24 |    264 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436782.436782 lmp.py:767]   Expert 61 |    267 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436478.436478 lmp.py:767]   Expert 29 |    268 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436082.436082 lmp.py:767]   Expert 35 |    277 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436440.436440 lmp.py:767]   Expert 32 |    299 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436560.436560 lmp.py:767]   Expert  2 |    336 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436441.436441 lmp.py:767]   Expert  8 |    342 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436084.436084 lmp.py:767]   Expert 10 |    356 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436442.436442 lmp.py:767]   Expert 46 |    427 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.436085.436085 lmp.py:767]   Expert 48 |    449 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.436013.436013 lmp.py:769] 
DEBUG 01-07 14:54:50.436013.436013 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.436656.436656 lmp.py:770]   CPU:   1918 tokens
DEBUG 01-07 14:54:50.436167.436167 lmp.py:774]   cuda:1:   5115 tokens (22 experts)
DEBUG 01-07 14:54:50.436717.436717 lmp.py:774]   cuda:2:   5255 tokens (23 experts)
DEBUG 01-07 14:54:50.436897.436897 lmp.py:775]   Total GPU:  10370 tokens
DEBUG 01-07 14:54:50.436540.436540 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.436540.436540 lmp.py:776] 
DEBUG 01-07 14:54:50.436097.436097 cuda_h.py:19] end experts_map_get cost 0.0019335746765136719 seconds
DEBUG 01-07 14:54:50.436409.436409 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.436768.436768 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.436838.436838 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.438022.438022 cuda_h.py:19] end allocate_cuda_memory cost 0.0015034675598144531 seconds
DEBUG 01-07 14:54:50.438078.438078 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.438933.438933 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.438935.438935 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.438776.438776 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a7e3301-7f4f-4ac9-8a50-1489e5b12ee0
DEBUG 01-07 14:54:50.438001.438001 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.438799.438799 client.py:127] Model loaded
DEBUG 01-07 14:54:50.438496.438496 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.439154.439154 cuda_h.py:19] end restore2model cost 0.00040793418884277344 seconds
DEBUG 01-07 14:54:50.439553.439553 cuda_h.py:19] end sllm_worker_task cost 0.010235786437988281 seconds
INFO 01-07 14:54:50.439850.439850 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a7e3301-7f4f-4ac9-8a50-1489e5b12ee0
DEBUG 01-07 14:54:50.439468.439468 cuda_h.py:19] end load_into_gpu_async cost 0.0013401508331298828 seconds
DEBUG 01-07 14:54:50.439748.439748 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.439982.439982 cuda_h.py:19] end restore_tensors2 cost 0.0002493858337402344 seconds
DEBUG 01-07 14:54:50.439143.439143 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003444671630859375 seconds
DEBUG 01-07 14:54:50.440952.440952 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.442205.442205 cuda_h.py:19] end restore2model cost 0.0019812583923339844 seconds
DEBUG 01-07 14:54:50.442658.442658 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.442854.442854 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.442452.442452 cuda_h.py:19] end allocate_cuda_memory cost 0.00022149085998535156 seconds
DEBUG 01-07 14:54:50.442725.442725 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.442495.442495 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.442589.442589 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.442000.442000 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ddb68d8a-3afa-4286-9733-5fa8b4c90ac4
DEBUG 01-07 14:54:50.442058.442058 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.443146.443146 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ddb68d8a-3afa-4286-9733-5fa8b4c90ac4
DEBUG 01-07 14:54:50.443883.443883 cuda_h.py:19] end load_into_gpu_async cost 0.001092672348022461 seconds
DEBUG 01-07 14:54:50.443393.443393 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.443330.443330 cuda_h.py:19] end restore_tensors2 cost 0.0002410411834716797 seconds
DEBUG 01-07 14:54:50.444205.444205 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018820762634277344 seconds
DEBUG 01-07 14:54:50.444968.444968 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.446935.446935 cuda_h.py:19] end restore2model cost 0.001943349838256836 seconds
DEBUG 01-07 14:54:50.446394.446394 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009621858596801758 seconds
DEBUG 01-07 14:54:50.446210.446210 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.446027.446027 lmp.py:816] 
DEBUG 01-07 14:54:50.446027.446027 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.446578.446578 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 14:54:50.446190.446190 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.459367.459367 mlpmodule.py:749] group tensors cost 0.012656211853027344 s
DEBUG 01-07 14:54:50.461329.461329 mlpmodule.py:787] pad cost 0.0012853145599365234 s
DEBUG 01-07 14:54:50.461009.461009 mlpmodule.py:793] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-07 14:54:50.461164.461164 mlpmodule.py:798] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-07 14:54:50.470651.470651 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.470650.470650 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.470170.470170 mlpmodule.py:818] group_w3 first element: 0.04248046875
WARNING 01-07 14:54:50.470346.470346 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.483408.483408 mlpmodule.py:838] group einsum cost 0.02205371856689453 s
DEBUG 01-07 14:54:50.484380.484380 mlpmodule.py:846] cpy2cputensor cost 0.0003883838653564453 s
DEBUG 01-07 14:54:50.486476.486476 cuda_h.py:19] end wait_cetm_experts cost 0.04012703895568848 seconds
DEBUG 01-07 14:54:50.486382.486382 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.487463.487463 cuda_h.py:19] end gpu_sexperts cost 0.0007479190826416016 seconds
DEBUG 01-07 14:54:50.487413.487413 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.487562.487562 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-07 14:54:50.487306.487306 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.487070.487070 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a7e3301-7f4f-4ac9-8a50-1489e5b12ee0
INFO 01-07 14:54:50.488993.488993 client.py:127] Model loaded
INFO 01-07 14:54:50.489268.489268 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ddb68d8a-3afa-4286-9733-5fa8b4c90ac4
INFO 01-07 14:54:50.489764.489764 client.py:127] Model loaded
DEBUG 01-07 14:54:50.489457.489457 cuda_h.py:19] end wait_experts_multi_device cost 0.0018613338470458984 seconds
DEBUG 01-07 14:54:50.489506.489506 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.489444.489444 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.492783.492783 mlpmodule.py:533] gpu group tensors cost 0.0010335445404052734 s
DEBUG 01-07 14:54:50.493657.493657 mlpmodule.py:707]  experts func einsum cost 0.04685020446777344 s
DEBUG 01-07 14:54:50.495547.495547 mlpmodule.py:566] gpu pad cost 0.003450632095336914 s
DEBUG 01-07 14:54:50.497498.497498 mlpmodule.py:584] gpu group einsum cost 0.0011529922485351562 s
DEBUG 01-07 14:54:50.500600.500600 mlpmodule.py:656] gpu experts func einsum cost 0.009410619735717773 s
DEBUG 01-07 14:54:50.501194.501194 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.501190.501190 mlpmodule.py:533] gpu group tensors cost 0.0005261898040771484 s
DEBUG 01-07 14:54:50.503587.503587 mlpmodule.py:566] gpu pad cost 0.001316070556640625 s
DEBUG 01-07 14:54:50.503017.503017 mlpmodule.py:584] gpu group einsum cost 0.0004975795745849609 s
DEBUG 01-07 14:54:50.505901.505901 mlpmodule.py:656] gpu experts func einsum cost 0.004562854766845703 s
DEBUG 01-07 14:54:50.506329.506329 cuda_h.py:19] end gpu_experts_multi_device cost 0.016175031661987305 seconds
DEBUG 01-07 14:54:50.506670.506670 cuda_h.py:19] end layer_moe_generate_multi_device_23 cost 0.0724492073059082 seconds
DEBUG 01-07 14:54:50.506091.506091 lmp.py:194] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-07 14:54:50.506974.506974 lmp.py:153] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-07 14:54:50.506320.506320 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 14:54:50.506957.506957 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 14:54:50.506191.506191 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.24249267578125e-05 seconds
DEBUG 01-07 14:54:50.506722.506722 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.462501525878906e-05 seconds
DEBUG 01-07 14:54:50.506141.506141 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.506487.506487 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.506443.506443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.507500.507500 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.507691.507691 cuda_h.py:19] end allocate_cuda_memory cost 0.00031280517578125 seconds
DEBUG 01-07 14:54:50.507839.507839 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.507741.507741 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.507656.507656 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.507690.507690 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f5422033-ab43-47f7-af87-1a9c22610b88
DEBUG 01-07 14:54:50.507938.507938 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.507286.507286 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.508498.508498 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.508775.508775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f5422033-ab43-47f7-af87-1a9c22610b88
DEBUG 01-07 14:54:50.508863.508863 cuda_h.py:19] end load_into_gpu_async cost 0.0008871555328369141 seconds
DEBUG 01-07 14:54:50.508997.508997 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.508755.508755 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-07 14:54:50.508319.508319 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001539468765258789 seconds
INFO 01-07 14:54:50.508315.508315 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f5422033-ab43-47f7-af87-1a9c22610b88
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.511242.511242 cuda_h.py:19] end self_attn cost 0.003360271453857422 seconds
DEBUG 01-07 14:54:50.511531.511531 cuda_h.py:19] end iln_self_attn_paln cost 0.0049169063568115234 seconds
DEBUG 01-07 14:54:50.511904.511904 cuda_h.py:10] start layer_moe_generate_multi_device_24
DEBUG 01-07 14:54:50.512342.512342 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.512240.512240 cuda_h.py:19] end gate cost 0.0006625652313232422 seconds
DEBUG 01-07 14:54:50.512831.512831 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.513706.513706 lmp.py:744] 
DEBUG 01-07 14:54:50.513706.513706 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.513476.513476 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.513271.513271 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.513775.513775 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.513849.513849 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.513446.513446 lmp.py:749] 
DEBUG 01-07 14:54:50.513446.513446 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.513672.513672 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.513182.513182 lmp.py:767]   Expert 36 |     21 | CPU
DEBUG 01-07 14:54:50.513064.513064 lmp.py:767]   Expert 35 |     30 | CPU
DEBUG 01-07 14:54:50.513945.513945 lmp.py:767]   Expert 46 |     44 | CPU
DEBUG 01-07 14:54:50.513350.513350 lmp.py:767]   Expert 25 |     48 | CPU
DEBUG 01-07 14:54:50.513331.513331 lmp.py:767]   Expert 51 |     54 | CPU
DEBUG 01-07 14:54:50.513265.513265 lmp.py:767]   Expert 16 |     57 | CPU
DEBUG 01-07 14:54:50.513146.513146 lmp.py:767]   Expert  0 |     66 | CPU
DEBUG 01-07 14:54:50.513028.513028 lmp.py:767]   Expert 43 |     67 | CPU
DEBUG 01-07 14:54:50.513909.513909 lmp.py:767]   Expert 30 |     69 | CPU
DEBUG 01-07 14:54:50.513274.513274 lmp.py:767]   Expert 47 |     69 | CPU
DEBUG 01-07 14:54:50.513017.513017 lmp.py:767]   Expert 39 |     72 | CPU
DEBUG 01-07 14:54:50.513421.513421 lmp.py:767]   Expert 44 |     73 | CPU
DEBUG 01-07 14:54:50.513349.513349 lmp.py:767]   Expert 42 |     76 | CPU
DEBUG 01-07 14:54:50.513515.513515 lmp.py:767]   Expert 55 |     78 | CPU
DEBUG 01-07 14:54:50.513443.513443 lmp.py:767]   Expert  2 |     86 | CPU
DEBUG 01-07 14:54:50.513569.513569 lmp.py:767]   Expert  4 |    106 | CPU
DEBUG 01-07 14:54:50.513689.513689 lmp.py:767]   Expert 48 |    113 | CPU
DEBUG 01-07 14:54:50.513332.513332 lmp.py:767]   Expert 13 |    122 | CPU
DEBUG 01-07 14:54:50.513690.513690 lmp.py:767]   Expert  6 |    125 | CPU
DEBUG 01-07 14:54:50.513433.513433 lmp.py:767]   Expert 33 |    125 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513659.513659 lmp.py:767]   Expert 61 |    127 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.513494.513494 lmp.py:767]   Expert 24 |    129 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513852.513852 lmp.py:767]   Expert 56 |    131 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.513734.513734 lmp.py:767]   Expert 38 |    135 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513615.513615 lmp.py:767]   Expert 29 |    136 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.513457.513457 lmp.py:767]   Expert 15 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513769.513769 lmp.py:767]   Expert  9 |    142 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.513889.513889 lmp.py:767]   Expert 54 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513247.513247 lmp.py:767]   Expert 59 |    148 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.513420.513420 lmp.py:767]   Expert  7 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513977.513977 lmp.py:767]   Expert 20 |    153 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.513097.513097 lmp.py:767]   Expert 45 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.513978.513978 lmp.py:767]   Expert 19 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514621.514621 lmp.py:767]   Expert 62 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514502.514502 lmp.py:767]   Expert 34 |    184 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514583.514583 lmp.py:767]   Expert 57 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514418.514418 lmp.py:767]   Expert 50 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514776.514776 lmp.py:767]   Expert 10 |    204 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514134.514134 lmp.py:767]   Expert 31 |    206 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514830.514830 lmp.py:767]   Expert 23 |    207 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514149.514149 lmp.py:767]   Expert  8 |    212 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514746.514746 lmp.py:767]   Expert 53 |    216 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514389.514389 lmp.py:767]   Expert 18 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514032.514032 lmp.py:767]   Expert 60 |    218 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514913.514913 lmp.py:767]   Expert 22 |    222 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514755.514755 lmp.py:767]   Expert 52 |    226 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514351.514351 lmp.py:767]   Expert 37 |    231 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514710.514710 lmp.py:767]   Expert  5 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514068.514068 lmp.py:767]   Expert 17 |    243 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514810.514810 lmp.py:767]   Expert 11 |    261 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514844.514844 lmp.py:767]   Expert  1 |    272 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514964.514964 lmp.py:767]   Expert 49 |    272 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514607.514607 lmp.py:767]   Expert 41 |    280 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514488.514488 lmp.py:767]   Expert 28 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514131.514131 lmp.py:767]   Expert 26 |    287 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514536.514536 lmp.py:767]   Expert 32 |    287 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514179.514179 lmp.py:767]   Expert 58 |    287 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514160.514160 lmp.py:767]   Expert 40 |    303 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514094.514094 lmp.py:767]   Expert 14 |    309 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514453.514453 lmp.py:767]   Expert 12 |    319 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514811.514811 lmp.py:767]   Expert 63 |    335 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514169.514169 lmp.py:767]   Expert 21 |    377 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514110.514110 lmp.py:767]   Expert 27 |    668 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.514422.514422 lmp.py:767]   Expert  3 |   1017 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.514588.514588 lmp.py:769] 
DEBUG 01-07 14:54:50.514588.514588 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.514708.514708 lmp.py:770]   CPU:   1376 tokens
DEBUG 01-07 14:54:50.514782.514782 lmp.py:774]   cuda:1:   5457 tokens (22 experts)
DEBUG 01-07 14:54:50.514955.514955 lmp.py:774]   cuda:2:   5455 tokens (23 experts)
DEBUG 01-07 14:54:50.514266.514266 lmp.py:775]   Total GPU:  10912 tokens
DEBUG 01-07 14:54:50.514433.514433 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.514433.514433 lmp.py:776] 
DEBUG 01-07 14:54:50.514990.514990 cuda_h.py:19] end experts_map_get cost 0.0019485950469970703 seconds
DEBUG 01-07 14:54:50.514686.514686 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.514284.514284 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.514486.514486 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.515031.515031 cuda_h.py:19] end allocate_cuda_memory cost 0.0008215904235839844 seconds
DEBUG 01-07 14:54:50.515073.515073 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.515498.515498 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.515500.515500 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.515341.515341 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f48cd125-abc3-4ae5-a138-818ed9b7d9f2
DEBUG 01-07 14:54:50.516373.516373 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.516734.516734 client.py:127] Model loaded
DEBUG 01-07 14:54:50.516670.516670 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.516765.516765 cuda_h.py:19] end restore2model cost 0.00041484832763671875 seconds
DEBUG 01-07 14:54:50.516356.516356 cuda_h.py:19] end sllm_worker_task cost 0.0100555419921875 seconds
INFO 01-07 14:54:50.517293.517293 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f48cd125-abc3-4ae5-a138-818ed9b7d9f2
DEBUG 01-07 14:54:50.517964.517964 cuda_h.py:19] end load_into_gpu_async cost 0.0012521743774414062 seconds
DEBUG 01-07 14:54:50.517720.517720 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.517226.517226 cuda_h.py:19] end restore_tensors2 cost 0.00024127960205078125 seconds
DEBUG 01-07 14:54:50.517347.517347 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002655506134033203 seconds
DEBUG 01-07 14:54:50.517971.517971 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.519888.519888 cuda_h.py:19] end restore2model cost 0.001840353012084961 seconds
DEBUG 01-07 14:54:50.519897.519897 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.519702.519702 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.519446.519446 cuda_h.py:19] end allocate_cuda_memory cost 0.00023031234741210938 seconds
DEBUG 01-07 14:54:50.519772.519772 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.519866.519866 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.519536.519536 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.520948.520948 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ddaf1aef-31bf-4a32-93c0-7fb0891c5bc7
DEBUG 01-07 14:54:50.520482.520482 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.521692.521692 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ddaf1aef-31bf-4a32-93c0-7fb0891c5bc7
DEBUG 01-07 14:54:50.521191.521191 cuda_h.py:19] end load_into_gpu_async cost 0.001188039779663086 seconds
DEBUG 01-07 14:54:50.521463.521463 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.521001.521001 cuda_h.py:19] end restore_tensors2 cost 0.00023102760314941406 seconds
DEBUG 01-07 14:54:50.521155.521155 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001954317092895508 seconds
DEBUG 01-07 14:54:50.521673.521673 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.523597.523597 cuda_h.py:19] end restore2model cost 0.0018455982208251953 seconds
DEBUG 01-07 14:54:50.523857.523857 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008629798889160156 seconds
DEBUG 01-07 14:54:50.523222.523222 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.523323.523323 lmp.py:816] 
DEBUG 01-07 14:54:50.523323.523323 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.523444.523444 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 14:54:50.523664.523664 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.529163.529163 mlpmodule.py:749] group tensors cost 0.005292415618896484 s
DEBUG 01-07 14:54:50.530278.530278 mlpmodule.py:787] pad cost 0.0010752677917480469 s
DEBUG 01-07 14:54:50.530261.530261 mlpmodule.py:793] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-07 14:54:50.531111.531111 mlpmodule.py:798] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-07 14:54:50.539424.539424 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.539245.539245 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.539388.539388 mlpmodule.py:818] group_w3 first element: 0.00653076171875
WARNING 01-07 14:54:50.539988.539988 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.553172.553172 mlpmodule.py:838] group einsum cost 0.022721529006958008 s
DEBUG 01-07 14:54:50.554789.554789 mlpmodule.py:846] cpy2cputensor cost 0.00043129920959472656 s
DEBUG 01-07 14:54:50.557952.557952 cuda_h.py:19] end wait_cetm_experts cost 0.03348970413208008 seconds
DEBUG 01-07 14:54:50.557651.557651 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.557569.557569 cuda_h.py:19] end gpu_sexperts cost 0.0004944801330566406 seconds
DEBUG 01-07 14:54:50.557028.557028 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.557845.557845 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4332275390625e-05 seconds
DEBUG 01-07 14:54:50.557886.557886 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.557503.557503 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f48cd125-abc3-4ae5-a138-818ed9b7d9f2
INFO 01-07 14:54:50.561247.561247 client.py:127] Model loaded
INFO 01-07 14:54:50.561368.561368 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ddaf1aef-31bf-4a32-93c0-7fb0891c5bc7
INFO 01-07 14:54:50.561295.561295 client.py:127] Model loaded
DEBUG 01-07 14:54:50.561502.561502 cuda_h.py:19] end wait_experts_multi_device cost 0.003935098648071289 seconds
DEBUG 01-07 14:54:50.561397.561397 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.561836.561836 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.563630.563630 mlpmodule.py:533] gpu group tensors cost 0.0005037784576416016 s
DEBUG 01-07 14:54:50.564809.564809 mlpmodule.py:566] gpu pad cost 0.0013327598571777344 s
DEBUG 01-07 14:54:50.564054.564054 mlpmodule.py:707]  experts func einsum cost 0.04121994972229004 s
DEBUG 01-07 14:54:50.565106.565106 mlpmodule.py:584] gpu group einsum cost 0.0006768703460693359 s
DEBUG 01-07 14:54:50.567546.567546 mlpmodule.py:656] gpu experts func einsum cost 0.004728794097900391 s
DEBUG 01-07 14:54:50.567642.567642 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.568156.568156 mlpmodule.py:533] gpu group tensors cost 0.0004444122314453125 s
DEBUG 01-07 14:54:50.569787.569787 mlpmodule.py:566] gpu pad cost 0.0011603832244873047 s
DEBUG 01-07 14:54:50.570919.570919 mlpmodule.py:584] gpu group einsum cost 0.0006988048553466797 s
DEBUG 01-07 14:54:50.572218.572218 mlpmodule.py:656] gpu experts func einsum cost 0.004072666168212891 s
DEBUG 01-07 14:54:50.572426.572426 cuda_h.py:19] end gpu_experts_multi_device cost 0.010141849517822266 seconds
DEBUG 01-07 14:54:50.572873.572873 cuda_h.py:19] end layer_moe_generate_multi_device_24 cost 0.06015753746032715 seconds
DEBUG 01-07 14:54:50.572298.572298 lmp.py:194] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-07 14:54:50.572174.572174 lmp.py:153] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-07 14:54:50.572870.572870 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 14:54:50.572911.572911 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 14:54:50.572078.572078 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.765655517578125e-05 seconds
DEBUG 01-07 14:54:50.572066.572066 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.793571472167969e-05 seconds
DEBUG 01-07 14:54:50.572901.572901 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.572677.572677 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.572587.572587 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.572708.572708 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.573823.573823 cuda_h.py:19] end allocate_cuda_memory cost 0.0002262592315673828 seconds
DEBUG 01-07 14:54:50.573700.573700 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.573960.573960 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.573943.573943 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.573481.573481 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.573276.573276 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7047e9c6-9b55-46b9-adcc-b0e30c2a533f
DEBUG 01-07 14:54:50.573716.573716 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.573951.573951 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.574705.574705 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7047e9c6-9b55-46b9-adcc-b0e30c2a533f
DEBUG 01-07 14:54:50.574872.574872 cuda_h.py:19] end load_into_gpu_async cost 0.0008618831634521484 seconds
DEBUG 01-07 14:54:50.574238.574238 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.574082.574082 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-07 14:54:50.574599.574599 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001520395278930664 seconds
INFO 01-07 14:54:50.574952.574952 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7047e9c6-9b55-46b9-adcc-b0e30c2a533f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.577570.577570 cuda_h.py:19] end self_attn cost 0.0035924911499023438 seconds
DEBUG 01-07 14:54:50.577176.577176 cuda_h.py:19] end iln_self_attn_paln cost 0.005020618438720703 seconds
DEBUG 01-07 14:54:50.577244.577244 cuda_h.py:10] start layer_moe_generate_multi_device_25
DEBUG 01-07 14:54:50.577384.577384 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.578500.578500 cuda_h.py:19] end gate cost 0.0006492137908935547 seconds
DEBUG 01-07 14:54:50.578660.578660 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.578363.578363 lmp.py:744] 
DEBUG 01-07 14:54:50.578363.578363 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.578563.578563 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.578358.578358 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.578670.578670 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.578836.578836 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.579049.579049 lmp.py:749] 
DEBUG 01-07 14:54:50.579049.579049 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.579453.579453 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.579818.579818 lmp.py:767]   Expert 13 |     30 | CPU
DEBUG 01-07 14:54:50.579223.579223 lmp.py:767]   Expert 44 |     40 | CPU
DEBUG 01-07 14:54:50.579674.579674 lmp.py:767]   Expert 25 |     42 | CPU
DEBUG 01-07 14:54:50.579840.579840 lmp.py:767]   Expert  9 |     43 | CPU
DEBUG 01-07 14:54:50.579768.579768 lmp.py:767]   Expert 38 |     49 | CPU
DEBUG 01-07 14:54:50.579742.579742 lmp.py:767]   Expert  2 |     53 | CPU
DEBUG 01-07 14:54:50.579716.579716 lmp.py:767]   Expert 16 |     53 | CPU
DEBUG 01-07 14:54:50.579928.579928 lmp.py:767]   Expert 22 |     55 | CPU
DEBUG 01-07 14:54:50.579664.579664 lmp.py:767]   Expert 33 |     57 | CPU
DEBUG 01-07 14:54:50.579399.579399 lmp.py:767]   Expert  5 |     61 | CPU
DEBUG 01-07 14:54:50.579135.579135 lmp.py:767]   Expert 42 |     61 | CPU
DEBUG 01-07 14:54:50.579348.579348 lmp.py:767]   Expert 24 |     81 | CPU
DEBUG 01-07 14:54:50.579845.579845 lmp.py:767]   Expert 23 |     83 | CPU
DEBUG 01-07 14:54:50.579819.579819 lmp.py:767]   Expert 10 |     88 | CPU
DEBUG 01-07 14:54:50.579270.579270 lmp.py:767]   Expert 59 |    102 | CPU
DEBUG 01-07 14:54:50.579244.579244 lmp.py:767]   Expert 21 |    105 | CPU
DEBUG 01-07 14:54:50.579456.579456 lmp.py:767]   Expert 46 |    110 | CPU
DEBUG 01-07 14:54:50.579953.579953 lmp.py:767]   Expert 55 |    113 | CPU
DEBUG 01-07 14:54:50.579689.579689 lmp.py:767]   Expert 45 |    119 | CPU
DEBUG 01-07 14:54:50.579617.579617 lmp.py:767]   Expert 61 |    123 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579783.579783 lmp.py:767]   Expert 31 |    125 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579711.579711 lmp.py:767]   Expert 51 |    139 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579638.579638 lmp.py:767]   Expert 36 |    140 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579328.579328 lmp.py:767]   Expert  8 |    144 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579017.579017 lmp.py:767]   Expert  6 |    145 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579660.579660 lmp.py:767]   Expert  0 |    148 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579349.579349 lmp.py:767]   Expert 43 |    151 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579039.579039 lmp.py:767]   Expert 26 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579728.579728 lmp.py:767]   Expert  3 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579179.579179 lmp.py:767]   Expert 18 |    159 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579868.579868 lmp.py:767]   Expert 48 |    163 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579080.579080 lmp.py:767]   Expert 41 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579770.579770 lmp.py:767]   Expert  7 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579744.579744 lmp.py:767]   Expert 12 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579433.579433 lmp.py:767]   Expert 20 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579122.579122 lmp.py:767]   Expert 28 |    188 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579050.579050 lmp.py:767]   Expert 56 |    189 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579263.579263 lmp.py:767]   Expert 27 |    190 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579952.579952 lmp.py:767]   Expert  1 |    192 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579403.579403 lmp.py:767]   Expert 34 |    197 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579092.579092 lmp.py:767]   Expert 47 |    199 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579020.579020 lmp.py:767]   Expert 11 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579948.579948 lmp.py:767]   Expert 32 |    218 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579398.579398 lmp.py:767]   Expert 40 |    228 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579565.579565 lmp.py:767]   Expert 53 |    232 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579492.579492 lmp.py:767]   Expert 49 |    235 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579182.579182 lmp.py:767]   Expert 15 |    240 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579632.579632 lmp.py:767]   Expert 63 |    241 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579845.579845 lmp.py:767]   Expert 50 |    242 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579296.579296 lmp.py:767]   Expert 30 |    243 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579747.579747 lmp.py:767]   Expert 29 |    246 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579674.579674 lmp.py:767]   Expert  4 |    247 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579887.579887 lmp.py:767]   Expert 35 |    269 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579099.579099 lmp.py:767]   Expert 14 |    274 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579312.579312 lmp.py:767]   Expert 37 |    303 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.579763.579763 lmp.py:767]   Expert 52 |    340 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579975.579975 lmp.py:767]   Expert 17 |    362 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.579141.579141 lmp.py:767]   Expert 54 |    381 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.580307.580307 lmp.py:767]   Expert 39 |    388 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.580474.580474 lmp.py:767]   Expert 57 |    412 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.580640.580640 lmp.py:767]   Expert 62 |    456 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.580044.580044 lmp.py:767]   Expert 60 |    457 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.580926.580926 lmp.py:767]   Expert 19 |    546 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.580092.580092 lmp.py:767]   Expert 58 |    570 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.580304.580304 lmp.py:769] 
DEBUG 01-07 14:54:50.580304.580304 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.580470.580470 lmp.py:770]   CPU:   1345 tokens
DEBUG 01-07 14:54:50.580590.580590 lmp.py:774]   cuda:1:   5416 tokens (22 experts)
DEBUG 01-07 14:54:50.580995.580995 lmp.py:774]   cuda:2:   5527 tokens (23 experts)
DEBUG 01-07 14:54:50.580922.580922 lmp.py:775]   Total GPU:  10943 tokens
DEBUG 01-07 14:54:50.580850.580850 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.580850.580850 lmp.py:776] 
DEBUG 01-07 14:54:50.580262.580262 cuda_h.py:19] end experts_map_get cost 0.001714944839477539 seconds
DEBUG 01-07 14:54:50.580620.580620 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.580588.580588 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.580506.580506 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.580990.580990 cuda_h.py:19] end allocate_cuda_memory cost 0.0001850128173828125 seconds
DEBUG 01-07 14:54:50.580747.580747 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.580218.580218 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.580835.580835 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.580724.580724 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b1bf0062-dbb9-4947-a3a6-10d62cfabef4
DEBUG 01-07 14:54:50.580927.580927 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.581508.581508 client.py:127] Model loaded
DEBUG 01-07 14:54:50.581100.581100 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.581572.581572 cuda_h.py:19] end restore2model cost 0.0004200935363769531 seconds
DEBUG 01-07 14:54:50.581163.581163 cuda_h.py:19] end sllm_worker_task cost 0.00889277458190918 seconds
INFO 01-07 14:54:50.581019.581019 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b1bf0062-dbb9-4947-a3a6-10d62cfabef4
DEBUG 01-07 14:54:50.581042.581042 cuda_h.py:19] end load_into_gpu_async cost 0.001062154769897461 seconds
DEBUG 01-07 14:54:50.581083.581083 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.582343.582343 cuda_h.py:19] end restore_tensors2 cost 0.00023794174194335938 seconds
DEBUG 01-07 14:54:50.582921.582921 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001802682876586914 seconds
DEBUG 01-07 14:54:50.582968.582968 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.583764.583764 cuda_h.py:19] end restore2model cost 0.0017888545989990234 seconds
DEBUG 01-07 14:54:50.584853.584853 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.584180.584180 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.584474.584474 cuda_h.py:19] end allocate_cuda_memory cost 0.00021958351135253906 seconds
DEBUG 01-07 14:54:50.584184.584184 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.584510.584510 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.584696.584696 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.584108.584108 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5f643fa7-b5c5-4b8d-9a2b-9cac4ff1fff1
DEBUG 01-07 14:54:50.584437.584437 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.585886.585886 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5f643fa7-b5c5-4b8d-9a2b-9cac4ff1fff1
DEBUG 01-07 14:54:50.585047.585047 cuda_h.py:19] end load_into_gpu_async cost 0.0009903907775878906 seconds
DEBUG 01-07 14:54:50.585604.585604 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.585235.585235 cuda_h.py:19] end restore_tensors2 cost 0.00023055076599121094 seconds
DEBUG 01-07 14:54:50.585004.585004 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017349720001220703 seconds
DEBUG 01-07 14:54:50.585714.585714 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.587068.587068 cuda_h.py:19] end restore2model cost 0.001847982406616211 seconds
DEBUG 01-07 14:54:50.587229.587229 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00748443603515625 seconds
DEBUG 01-07 14:54:50.587117.587117 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.587742.587742 lmp.py:816] 
DEBUG 01-07 14:54:50.587742.587742 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.587194.587194 cuda_h.py:19] end cpu_experts_submit cost 0.00010323524475097656 seconds
DEBUG 01-07 14:54:50.587413.587413 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.593626.593626 mlpmodule.py:749] group tensors cost 0.00582432746887207 s
DEBUG 01-07 14:54:50.596694.596694 mlpmodule.py:787] pad cost 0.001678466796875 s
DEBUG 01-07 14:54:50.596191.596191 mlpmodule.py:793] create cpu tensor cost 0.00010585784912109375 s
DEBUG 01-07 14:54:50.596770.596770 mlpmodule.py:798] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-07 14:54:50.604259.604259 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.605543.605543 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.605917.605917 mlpmodule.py:818] group_w3 first element: -0.02734375
WARNING 01-07 14:54:50.605041.605041 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.619617.619617 mlpmodule.py:838] group einsum cost 0.022614479064941406 s
DEBUG 01-07 14:54:50.619009.619009 mlpmodule.py:846] cpy2cputensor cost 0.00042891502380371094 s
DEBUG 01-07 14:54:50.622491.622491 cuda_h.py:19] end wait_cetm_experts cost 0.03470611572265625 seconds
DEBUG 01-07 14:54:50.622858.622858 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.623254.623254 cuda_h.py:19] end gpu_sexperts cost 0.0004932880401611328 seconds
DEBUG 01-07 14:54:50.623004.623004 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.623278.623278 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.193450927734375e-05 seconds
DEBUG 01-07 14:54:50.623510.623510 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.623273.623273 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b1bf0062-dbb9-4947-a3a6-10d62cfabef4
INFO 01-07 14:54:50.624101.624101 client.py:127] Model loaded
INFO 01-07 14:54:50.624791.624791 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5f643fa7-b5c5-4b8d-9a2b-9cac4ff1fff1
INFO 01-07 14:54:50.625314.625314 client.py:127] Model loaded
DEBUG 01-07 14:54:50.625998.625998 cuda_h.py:19] end wait_experts_multi_device cost 0.0018718242645263672 seconds
DEBUG 01-07 14:54:50.625178.625178 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.625093.625093 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.626801.626801 mlpmodule.py:533] gpu group tensors cost 0.0004951953887939453 s
DEBUG 01-07 14:54:50.627006.627006 mlpmodule.py:566] gpu pad cost 0.0013186931610107422 s
DEBUG 01-07 14:54:50.628259.628259 mlpmodule.py:584] gpu group einsum cost 0.0005774497985839844 s
DEBUG 01-07 14:54:50.630699.630699 mlpmodule.py:707]  experts func einsum cost 0.04223918914794922 s
DEBUG 01-07 14:54:50.630672.630672 mlpmodule.py:656] gpu experts func einsum cost 0.004750728607177734 s
DEBUG 01-07 14:54:50.631655.631655 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.631124.631124 mlpmodule.py:533] gpu group tensors cost 0.0004482269287109375 s
DEBUG 01-07 14:54:50.633823.633823 mlpmodule.py:566] gpu pad cost 0.0012683868408203125 s
DEBUG 01-07 14:54:50.633430.633430 mlpmodule.py:584] gpu group einsum cost 0.0004520416259765625 s
DEBUG 01-07 14:54:50.635707.635707 mlpmodule.py:656] gpu experts func einsum cost 0.004214048385620117 s
DEBUG 01-07 14:54:50.635782.635782 cuda_h.py:19] end gpu_experts_multi_device cost 0.010319709777832031 seconds
DEBUG 01-07 14:54:50.635713.635713 cuda_h.py:19] end layer_moe_generate_multi_device_25 cost 0.058075666427612305 seconds
DEBUG 01-07 14:54:50.636581.636581 lmp.py:194] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-07 14:54:50.636119.636119 lmp.py:153] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-07 14:54:50.636576.636576 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 14:54:50.636379.636379 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 14:54:50.636546.636546 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.765655517578125e-05 seconds
DEBUG 01-07 14:54:50.636388.636388 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.53131103515625e-05 seconds
DEBUG 01-07 14:54:50.636746.636746 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.636330.636330 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 14:54:50.636763.636763 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.636329.636329 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.636353.636353 cuda_h.py:19] end allocate_cuda_memory cost 0.0002970695495605469 seconds
DEBUG 01-07 14:54:50.636992.636992 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.636490.636490 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.636857.636857 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.637309.637309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.637297.637297 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a28fbdd1-89e8-4116-bb0d-ea529987fba3
DEBUG 01-07 14:54:50.637591.637591 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 14:54:50.637256.637256 cuda_h.py:10] start self_attn
INFO 01-07 14:54:50.637471.637471 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a28fbdd1-89e8-4116-bb0d-ea529987fba3
DEBUG 01-07 14:54:50.637116.637116 cuda_h.py:19] end load_into_gpu_async cost 0.0007879734039306641 seconds
DEBUG 01-07 14:54:50.637911.637911 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.637702.637702 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 14:54:50.637266.637266 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015308856964111328 seconds
INFO 01-07 14:54:50.637063.637063 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a28fbdd1-89e8-4116-bb0d-ea529987fba3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.641288.641288 cuda_h.py:19] end self_attn cost 0.0036497116088867188 seconds
DEBUG 01-07 14:54:50.641079.641079 cuda_h.py:19] end iln_self_attn_paln cost 0.005168914794921875 seconds
DEBUG 01-07 14:54:50.641571.641571 cuda_h.py:10] start layer_moe_generate_multi_device_26
DEBUG 01-07 14:54:50.641949.641949 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.642667.642667 cuda_h.py:19] end gate cost 0.0006377696990966797 seconds
DEBUG 01-07 14:54:50.642636.642636 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.642477.642477 lmp.py:744] 
DEBUG 01-07 14:54:50.642477.642477 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.642379.642379 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.642744.642744 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.642771.642771 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.642652.642652 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.642342.642342 lmp.py:749] 
DEBUG 01-07 14:54:50.642342.642342 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.642508.642508 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.642396.642396 lmp.py:767]   Expert 20 |     10 | CPU
DEBUG 01-07 14:54:50.642801.642801 lmp.py:767]   Expert 61 |     12 | CPU
DEBUG 01-07 14:54:50.642967.642967 lmp.py:767]   Expert 11 |     28 | CPU
DEBUG 01-07 14:54:50.642133.642133 lmp.py:767]   Expert  7 |     34 | CPU
DEBUG 01-07 14:54:50.642061.642061 lmp.py:767]   Expert 62 |     40 | CPU
DEBUG 01-07 14:54:50.642988.642988 lmp.py:767]   Expert  3 |     42 | CPU
DEBUG 01-07 14:54:50.642678.642678 lmp.py:767]   Expert 51 |     44 | CPU
DEBUG 01-07 14:54:50.642367.642367 lmp.py:767]   Expert 30 |     50 | CPU
DEBUG 01-07 14:54:50.642056.642056 lmp.py:767]   Expert 17 |     54 | CPU
DEBUG 01-07 14:54:50.642984.642984 lmp.py:767]   Expert 29 |     58 | CPU
DEBUG 01-07 14:54:50.642627.642627 lmp.py:767]   Expert  6 |     59 | CPU
DEBUG 01-07 14:54:50.642032.642032 lmp.py:767]   Expert  9 |     66 | CPU
DEBUG 01-07 14:54:50.642959.642959 lmp.py:767]   Expert 38 |     76 | CPU
DEBUG 01-07 14:54:50.642649.642649 lmp.py:767]   Expert 63 |     76 | CPU
DEBUG 01-07 14:54:50.643815.643815 lmp.py:767]   Expert 55 |     78 | CPU
DEBUG 01-07 14:54:50.643266.643266 lmp.py:767]   Expert 59 |     86 | CPU
DEBUG 01-07 14:54:50.643955.643955 lmp.py:767]   Expert 19 |     89 | CPU
DEBUG 01-07 14:54:50.643644.643644 lmp.py:767]   Expert 48 |     92 | CPU
DEBUG 01-07 14:54:50.643810.643810 lmp.py:767]   Expert  8 |     99 | CPU
DEBUG 01-07 14:54:50.643407.643407 lmp.py:767]   Expert 49 |    101 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643527.643527 lmp.py:767]   Expert 22 |    106 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643885.643885 lmp.py:767]   Expert 36 |    113 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643290.643290 lmp.py:767]   Expert 24 |    115 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643933.643933 lmp.py:767]   Expert 50 |    117 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643576.643576 lmp.py:767]   Expert 34 |    118 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643980.643980 lmp.py:767]   Expert 39 |    118 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643861.643861 lmp.py:767]   Expert 42 |    121 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643220.643220 lmp.py:767]   Expert  4 |    131 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643863.643863 lmp.py:767]   Expert 37 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643744.643744 lmp.py:767]   Expert 15 |    145 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643149.643149 lmp.py:767]   Expert 41 |    147 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643030.643030 lmp.py:767]   Expert 23 |    155 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643673.643673 lmp.py:767]   Expert 56 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643078.643078 lmp.py:767]   Expert 16 |    168 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643721.643721 lmp.py:767]   Expert 44 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643125.643125 lmp.py:767]   Expert  1 |    176 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643768.643768 lmp.py:767]   Expert 60 |    179 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643649.643649 lmp.py:767]   Expert 21 |    181 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643769.643769 lmp.py:767]   Expert 43 |    183 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643651.643651 lmp.py:767]   Expert 53 |    191 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643294.643294 lmp.py:767]   Expert 47 |    195 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643698.643698 lmp.py:767]   Expert 33 |    205 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643103.643103 lmp.py:767]   Expert 12 |    208 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643984.643984 lmp.py:767]   Expert 13 |    209 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643150.643150 lmp.py:767]   Expert 32 |    227 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643270.643270 lmp.py:767]   Expert 28 |    229 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643151.643151 lmp.py:767]   Expert  0 |    252 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643794.643794 lmp.py:767]   Expert 31 |    257 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643199.643199 lmp.py:767]   Expert 54 |    258 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643604.643604 lmp.py:767]   Expert 26 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643770.643770 lmp.py:767]   Expert 10 |    268 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643174.643174 lmp.py:767]   Expert 18 |    270 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643340.643340 lmp.py:767]   Expert 57 |    272 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643983.643983 lmp.py:767]   Expert  2 |    283 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643103.643103 lmp.py:767]   Expert 58 |    291 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643508.643508 lmp.py:767]   Expert 40 |    340 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643389.643389 lmp.py:767]   Expert 45 |    361 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643794.643794 lmp.py:767]   Expert 25 |    373 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643483.643483 lmp.py:767]   Expert  5 |    443 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643888.643888 lmp.py:767]   Expert 35 |    451 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643815.643815 lmp.py:767]   Expert 27 |    486 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643173.643173 lmp.py:767]   Expert 46 |    544 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643293.643293 lmp.py:767]   Expert 52 |    596 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.643698.643698 lmp.py:767]   Expert 14 |    880 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.643672.643672 lmp.py:769] 
DEBUG 01-07 14:54:50.643672.643672 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.643361.643361 lmp.py:770]   CPU:   1093 tokens
DEBUG 01-07 14:54:50.643004.643004 lmp.py:774]   cuda:1:   5582 tokens (22 experts)
DEBUG 01-07 14:54:50.643647.643647 lmp.py:774]   cuda:2:   5613 tokens (23 experts)
DEBUG 01-07 14:54:50.643336.643336 lmp.py:775]   Total GPU:  11195 tokens
DEBUG 01-07 14:54:50.643026.643026 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.643026.643026 lmp.py:776] 
DEBUG 01-07 14:54:50.644676.644676 cuda_h.py:19] end experts_map_get cost 0.0017578601837158203 seconds
DEBUG 01-07 14:54:50.644318.644318 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.644141.644141 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.644191.644191 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.644723.644723 cuda_h.py:19] end allocate_cuda_memory cost 0.00021958351135253906 seconds
DEBUG 01-07 14:54:50.644368.644368 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.644363.644363 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.644741.644741 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.644629.644629 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f476d7a-dc31-4d3d-a727-ec786c7a5b58
DEBUG 01-07 14:54:50.644932.644932 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.644275.644275 client.py:127] Model loaded
DEBUG 01-07 14:54:50.644774.644774 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.645871.645871 cuda_h.py:19] end restore2model cost 0.00032138824462890625 seconds
DEBUG 01-07 14:54:50.645018.645018 cuda_h.py:19] end sllm_worker_task cost 0.00900888442993164 seconds
INFO 01-07 14:54:50.645359.645359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f476d7a-dc31-4d3d-a727-ec786c7a5b58
DEBUG 01-07 14:54:50.645725.645725 cuda_h.py:19] end load_into_gpu_async cost 0.0009322166442871094 seconds
DEBUG 01-07 14:54:50.645759.645759 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.645906.645906 cuda_h.py:19] end restore_tensors2 cost 0.00022554397583007812 seconds
DEBUG 01-07 14:54:50.645100.645100 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017039775848388672 seconds
DEBUG 01-07 14:54:50.645670.645670 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.647288.647288 cuda_h.py:19] end restore2model cost 0.0017974376678466797 seconds
DEBUG 01-07 14:54:50.647383.647383 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.647618.647618 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.648739.648739 cuda_h.py:19] end allocate_cuda_memory cost 0.00023245811462402344 seconds
DEBUG 01-07 14:54:50.648245.648245 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.648140.648140 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.648088.648088 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.648214.648214 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 662eb844-5faa-475f-a5d3-c8eeb6247ddb
DEBUG 01-07 14:54:50.648067.648067 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.649915.649915 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 662eb844-5faa-475f-a5d3-c8eeb6247ddb
DEBUG 01-07 14:54:50.649406.649406 cuda_h.py:19] end load_into_gpu_async cost 0.0010383129119873047 seconds
DEBUG 01-07 14:54:50.649725.649725 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.649111.649111 cuda_h.py:19] end restore_tensors2 cost 0.00022554397583007812 seconds
DEBUG 01-07 14:54:50.649450.649450 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017781257629394531 seconds
DEBUG 01-07 14:54:50.649729.649729 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.651977.651977 cuda_h.py:19] end restore2model cost 0.001840353012084961 seconds
DEBUG 01-07 14:54:50.651992.651992 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007427692413330078 seconds
DEBUG 01-07 14:54:50.651880.651880 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.651790.651790 lmp.py:816] 
DEBUG 01-07 14:54:50.651790.651790 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.651911.651911 cuda_h.py:19] end cpu_experts_submit cost 0.00010538101196289062 seconds
DEBUG 01-07 14:54:50.651845.651845 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.658980.658980 mlpmodule.py:749] group tensors cost 0.006672859191894531 s
DEBUG 01-07 14:54:50.661490.661490 mlpmodule.py:787] pad cost 0.0017266273498535156 s
DEBUG 01-07 14:54:50.661594.661594 mlpmodule.py:793] create cpu tensor cost 5.888938903808594e-05 s
DEBUG 01-07 14:54:50.661459.661459 mlpmodule.py:798] move to cpu cost 4.649162292480469e-05 s
DEBUG 01-07 14:54:50.670704.670704 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.670604.670604 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.670634.670634 mlpmodule.py:818] group_w3 first element: -0.0024261474609375
WARNING 01-07 14:54:50.670419.670419 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.684664.684664 mlpmodule.py:838] group einsum cost 0.022844791412353516 s
DEBUG 01-07 14:54:50.684419.684419 mlpmodule.py:846] cpy2cputensor cost 0.0003688335418701172 s
DEBUG 01-07 14:54:50.687196.687196 cuda_h.py:19] end wait_cetm_experts cost 0.0357511043548584 seconds
DEBUG 01-07 14:54:50.687226.687226 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.688191.688191 cuda_h.py:19] end gpu_sexperts cost 0.0004937648773193359 seconds
DEBUG 01-07 14:54:50.688510.688510 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.688976.688976 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 14:54:50.688401.688401 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.688210.688210 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f476d7a-dc31-4d3d-a727-ec786c7a5b58
INFO 01-07 14:54:50.689983.689983 client.py:127] Model loaded
INFO 01-07 14:54:50.689812.689812 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 662eb844-5faa-475f-a5d3-c8eeb6247ddb
INFO 01-07 14:54:50.689798.689798 client.py:127] Model loaded
DEBUG 01-07 14:54:50.689859.689859 cuda_h.py:19] end wait_experts_multi_device cost 0.0013957023620605469 seconds
DEBUG 01-07 14:54:50.689754.689754 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.689670.689670 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.690583.690583 mlpmodule.py:533] gpu group tensors cost 0.0005006790161132812 s
DEBUG 01-07 14:54:50.692754.692754 mlpmodule.py:566] gpu pad cost 0.0012938976287841797 s
DEBUG 01-07 14:54:50.692682.692682 mlpmodule.py:584] gpu group einsum cost 0.0005414485931396484 s
DEBUG 01-07 14:54:50.694366.694366 mlpmodule.py:656] gpu experts func einsum cost 0.004521846771240234 s
DEBUG 01-07 14:54:50.695066.695066 mlpmodule.py:707]  experts func einsum cost 0.04326987266540527 s
DEBUG 01-07 14:54:50.695652.695652 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.696498.696498 mlpmodule.py:533] gpu group tensors cost 0.00043010711669921875 s
DEBUG 01-07 14:54:50.697476.697476 mlpmodule.py:566] gpu pad cost 0.0012621879577636719 s
DEBUG 01-07 14:54:50.697803.697803 mlpmodule.py:584] gpu group einsum cost 0.0004227161407470703 s
DEBUG 01-07 14:54:50.699974.699974 mlpmodule.py:656] gpu experts func einsum cost 0.004189014434814453 s
DEBUG 01-07 14:54:50.699951.699951 cuda_h.py:19] end gpu_experts_multi_device cost 0.01019430160522461 seconds
DEBUG 01-07 14:54:50.699351.699351 cuda_h.py:19] end layer_moe_generate_multi_device_26 cost 0.058480024337768555 seconds
DEBUG 01-07 14:54:50.700001.700001 lmp.py:194] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-07 14:54:50.700241.700241 lmp.py:153] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-07 14:54:50.700414.700414 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-07 14:54:50.700859.700859 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.0728836059570312e-05 seconds
DEBUG 01-07 14:54:50.700409.700409 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 14:54:50.700915.700915 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 14:54:50.700164.700164 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 14:54:50.703762.703762 cuda_h.py:19] end self_attn cost 0.002566099166870117 seconds
DEBUG 01-07 14:54:50.703129.703129 cuda_h.py:19] end iln_self_attn_paln cost 0.003277301788330078 seconds
DEBUG 01-07 14:54:50.703144.703144 cuda_h.py:10] start layer_moe_generate_multi_device_27
DEBUG 01-07 14:54:50.703046.703046 cuda_h.py:10] start gate
DEBUG 01-07 14:54:50.704113.704113 cuda_h.py:19] end gate cost 0.0005781650543212891 seconds
DEBUG 01-07 14:54:50.704843.704843 cuda_h.py:10] start experts_map_get
DEBUG 01-07 14:54:50.704037.704037 lmp.py:744] 
DEBUG 01-07 14:54:50.704037.704037 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 14:54:50.704700.704700 lmp.py:745]   Total experts: 64
DEBUG 01-07 14:54:50.704257.704257 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 14:54:50.704046.704046 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 14:54:50.704928.704928 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 14:54:50.704902.704902 lmp.py:749] 
DEBUG 01-07 14:54:50.704902.704902 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 14:54:50.704591.704591 lmp.py:750]   -----------------------------------
DEBUG 01-07 14:54:50.704479.704479 lmp.py:767]   Expert 18 |     61 | CPU
DEBUG 01-07 14:54:50.705122.705122 lmp.py:767]   Expert 54 |     71 | CPU
DEBUG 01-07 14:54:50.705527.705527 lmp.py:767]   Expert 47 |     72 | CPU
DEBUG 01-07 14:54:50.705454.705454 lmp.py:767]   Expert 48 |     75 | CPU
DEBUG 01-07 14:54:50.705667.705667 lmp.py:767]   Expert 23 |     79 | CPU
DEBUG 01-07 14:54:50.705879.705879 lmp.py:767]   Expert 44 |     86 | CPU
DEBUG 01-07 14:54:50.705092.705092 lmp.py:767]   Expert 45 |     87 | CPU
DEBUG 01-07 14:54:50.705304.705304 lmp.py:767]   Expert 20 |     91 | CPU
DEBUG 01-07 14:54:50.705517.705517 lmp.py:767]   Expert 31 |     92 | CPU
DEBUG 01-07 14:54:50.705729.705729 lmp.py:767]   Expert 36 |    104 | CPU
DEBUG 01-07 14:54:50.705418.705418 lmp.py:767]   Expert 42 |    113 | CPU
DEBUG 01-07 14:54:50.705869.705869 lmp.py:767]   Expert 61 |    114 | CPU
DEBUG 01-07 14:54:50.705082.705082 lmp.py:767]   Expert 33 |    117 | CPU
DEBUG 01-07 14:54:50.705056.705056 lmp.py:767]   Expert 24 |    119 | CPU
DEBUG 01-07 14:54:50.705030.705030 lmp.py:767]   Expert 10 |    124 | CPU
DEBUG 01-07 14:54:50.705766.705766 lmp.py:767]   Expert 43 |    125 | CPU
DEBUG 01-07 14:54:50.705740.705740 lmp.py:767]   Expert 11 |    127 | CPU
DEBUG 01-07 14:54:50.705714.705714 lmp.py:767]   Expert 56 |    127 | CPU
DEBUG 01-07 14:54:50.705926.705926 lmp.py:767]   Expert 49 |    129 | CPU
DEBUG 01-07 14:54:50.705046.705046 lmp.py:767]   Expert  6 |    140 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705212.705212 lmp.py:767]   Expert 51 |    144 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705378.705378 lmp.py:767]   Expert 17 |    147 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705306.705306 lmp.py:767]   Expert  0 |    149 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705995.705995 lmp.py:767]   Expert  5 |    156 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705446.705446 lmp.py:767]   Expert 40 |    157 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705135.705135 lmp.py:767]   Expert 59 |    158 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705301.705301 lmp.py:767]   Expert 55 |    159 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705944.705944 lmp.py:767]   Expert 57 |    160 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705349.705349 lmp.py:767]   Expert 12 |    165 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705515.705515 lmp.py:767]   Expert 26 |    167 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705204.705204 lmp.py:767]   Expert 30 |    169 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705655.705655 lmp.py:767]   Expert 38 |    169 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705583.705583 lmp.py:767]   Expert 46 |    171 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705034.705034 lmp.py:767]   Expert 13 |    173 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705723.705723 lmp.py:767]   Expert 35 |    173 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705651.705651 lmp.py:767]   Expert 58 |    174 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705056.705056 lmp.py:767]   Expert 50 |    176 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705222.705222 lmp.py:767]   Expert  7 |    178 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705673.705673 lmp.py:767]   Expert 16 |    182 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705600.705600 lmp.py:767]   Expert 32 |    197 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705290.705290 lmp.py:767]   Expert 14 |    203 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705740.705740 lmp.py:767]   Expert 15 |    203 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705430.705430 lmp.py:767]   Expert  1 |    214 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705642.705642 lmp.py:767]   Expert  3 |    219 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705570.705570 lmp.py:767]   Expert  4 |    221 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705498.705498 lmp.py:767]   Expert 39 |    237 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705187.705187 lmp.py:767]   Expert 34 |    240 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705876.705876 lmp.py:767]   Expert 52 |    243 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705327.705327 lmp.py:767]   Expert 28 |    249 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705016.705016 lmp.py:767]   Expert 22 |    260 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705944.705944 lmp.py:767]   Expert 25 |    261 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705110.705110 lmp.py:767]   Expert  2 |    275 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705038.705038 lmp.py:767]   Expert 21 |    276 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705966.705966 lmp.py:767]   Expert 41 |    285 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705655.705655 lmp.py:767]   Expert 60 |    285 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705106.705106 lmp.py:767]   Expert 29 |    289 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705034.705034 lmp.py:767]   Expert 62 |    296 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705961.705961 lmp.py:767]   Expert 63 |    296 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705081.705081 lmp.py:767]   Expert 27 |    303 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.705724.705724 lmp.py:767]   Expert 37 |    330 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.705652.705652 lmp.py:767]   Expert  8 |    333 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.706580.706580 lmp.py:767]   Expert 53 |    335 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.706507.706507 lmp.py:767]   Expert 19 |    440 | GPU1(cuda:2)
DEBUG 01-07 14:54:50.706435.706435 lmp.py:767]   Expert  9 |    618 | GPU0(cuda:1)
DEBUG 01-07 14:54:50.706932.706932 lmp.py:769] 
DEBUG 01-07 14:54:50.706932.706932 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 14:54:50.706383.706383 lmp.py:770]   CPU:   1913 tokens
DEBUG 01-07 14:54:50.706503.706503 lmp.py:774]   cuda:1:   5144 tokens (22 experts)
DEBUG 01-07 14:54:50.706669.706669 lmp.py:774]   cuda:2:   5231 tokens (23 experts)
DEBUG 01-07 14:54:50.706882.706882 lmp.py:775]   Total GPU:  10375 tokens
DEBUG 01-07 14:54:50.706379.706379 lmp.py:776] ============================================================
DEBUG 01-07 14:54:50.706379.706379 lmp.py:776] 
DEBUG 01-07 14:54:50.706075.706075 cuda_h.py:19] end experts_map_get cost 0.0017197132110595703 seconds
DEBUG 01-07 14:54:50.706479.706479 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 14:54:50.706779.706779 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.706498.706498 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.706879.706879 cuda_h.py:19] end allocate_cuda_memory cost 0.000286102294921875 seconds
DEBUG 01-07 14:54:50.706868.706868 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.706955.706955 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.706294.706294 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.706706.706706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, afc0ef1c-049c-44e4-94b9-088dc4f84545
DEBUG 01-07 14:54:50.706678.706678 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.707605.707605 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, afc0ef1c-049c-44e4-94b9-088dc4f84545
DEBUG 01-07 14:54:50.707050.707050 cuda_h.py:19] end load_into_gpu_async cost 0.0010528564453125 seconds
DEBUG 01-07 14:54:50.707369.707369 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.708013.708013 cuda_h.py:19] end restore_tensors2 cost 0.0002415180206298828 seconds
DEBUG 01-07 14:54:50.708637.708637 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018756389617919922 seconds
DEBUG 01-07 14:54:50.708208.708208 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.709084.709084 cuda_h.py:19] end restore2model cost 0.0018126964569091797 seconds
DEBUG 01-07 14:54:50.710167.710167 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 14:54:50.710839.710839 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 14:54:50.710477.710477 cuda_h.py:19] end allocate_cuda_memory cost 0.0002269744873046875 seconds
DEBUG 01-07 14:54:50.710552.710552 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 14:54:50.710685.710685 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 14:54:50.710541.710541 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 14:54:50.710190.710190 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9116a002-81d3-48ff-a890-667278873691
DEBUG 01-07 14:54:50.710957.710957 client.py:106] call stub.LoadModelAsync
INFO 01-07 14:54:50.711828.711828 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9116a002-81d3-48ff-a890-667278873691
DEBUG 01-07 14:54:50.711797.711797 cuda_h.py:19] end load_into_gpu_async cost 0.0009584426879882812 seconds
DEBUG 01-07 14:54:50.711685.711685 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 14:54:50.711548.711548 cuda_h.py:19] end restore_tensors2 cost 0.00022673606872558594 seconds
DEBUG 01-07 14:54:50.711602.711602 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016913414001464844 seconds
DEBUG 01-07 14:54:50.711835.711835 cuda_h.py:10] start restore2model
DEBUG 01-07 14:54:50.713388.713388 cuda_h.py:19] end restore2model cost 0.0018541812896728516 seconds
DEBUG 01-07 14:54:50.713025.713025 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0075795650482177734 seconds
DEBUG 01-07 14:54:50.713390.713390 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 14:54:50.713300.713300 lmp.py:816] 
DEBUG 01-07 14:54:50.713300.713300 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 14:54:50.713613.713613 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 14:54:50.713309.713309 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 14:54:50.719181.719181 mlpmodule.py:749] group tensors cost 0.005326032638549805 s
DEBUG 01-07 14:54:50.721485.721485 mlpmodule.py:787] pad cost 0.0012750625610351562 s
DEBUG 01-07 14:54:50.721211.721211 mlpmodule.py:793] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-07 14:54:50.721704.721704 mlpmodule.py:798] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-07 14:54:50.729893.729893 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 14:54:50.729005.729005 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 14:54:50.730916.730916 mlpmodule.py:818] group_w3 first element: -0.01263427734375
WARNING 01-07 14:54:50.730086.730086 mlpmodule.py:828] start einsum2
DEBUG 01-07 14:54:50.744166.744166 mlpmodule.py:838] group einsum cost 0.0224149227142334 s
DEBUG 01-07 14:54:50.744221.744221 mlpmodule.py:846] cpy2cputensor cost 0.0004782676696777344 s
DEBUG 01-07 14:54:50.747534.747534 cuda_h.py:19] end wait_cetm_experts cost 0.033373355865478516 seconds
DEBUG 01-07 14:54:50.747617.747617 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 14:54:50.748827.748827 cuda_h.py:19] end gpu_sexperts cost 0.0004978179931640625 seconds
DEBUG 01-07 14:54:50.748147.748147 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 14:54:50.748453.748453 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1444091796875e-05 seconds
DEBUG 01-07 14:54:50.748441.748441 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 14:54:50.748826.748826 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, afc0ef1c-049c-44e4-94b9-088dc4f84545
INFO 01-07 14:54:50.750952.750952 client.py:127] Model loaded
INFO 01-07 14:54:50.750828.750828 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9116a002-81d3-48ff-a890-667278873691
INFO 01-07 14:54:50.751207.751207 client.py:127] Model loaded
DEBUG 01-07 14:54:50.751460.751460 cuda_h.py:19] end wait_experts_multi_device cost 0.0033164024353027344 seconds
DEBUG 01-07 14:54:50.751878.751878 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 14:54:50.751078.751078 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 14:54:50.752859.752859 mlpmodule.py:533] gpu group tensors cost 0.0005092620849609375 s
DEBUG 01-07 14:54:50.754547.754547 mlpmodule.py:566] gpu pad cost 0.001287698745727539 s
DEBUG 01-07 14:54:50.754746.754746 mlpmodule.py:584] gpu group einsum cost 0.0005340576171875 s
DEBUG 01-07 14:54:50.755594.755594 mlpmodule.py:707]  experts func einsum cost 0.04103994369506836 s
DEBUG 01-07 14:54:50.756231.756231 mlpmodule.py:656] gpu experts func einsum cost 0.004679441452026367 s
DEBUG 01-07 14:54:50.757771.757771 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 14:54:50.757695.757695 mlpmodule.py:533] gpu group tensors cost 0.00043654441833496094 s
DEBUG 01-07 14:54:50.759518.759518 mlpmodule.py:566] gpu pad cost 0.0011835098266601562 s
DEBUG 01-07 14:54:50.759326.759326 mlpmodule.py:584] gpu group einsum cost 0.00032830238342285156 s
DEBUG 01-07 14:54:50.761725.761725 mlpmodule.py:656] gpu experts func einsum cost 0.003689289093017578 s
DEBUG 01-07 14:54:50.761178.761178 cuda_h.py:19] end gpu_experts_multi_device cost 0.009709596633911133 seconds
DEBUG 01-07 14:54:50.761618.761618 cuda_h.py:19] end layer_moe_generate_multi_device_27 cost 0.05762338638305664 seconds
DEBUG 01-07 14:54:50.761208.761208 lmp.py:194] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-07 14:54:50.761739.761739 cuda_h.py:19] end prefill_layer cost 1.8837735652923584 seconds
Collecting data...
Generating '/tmp/nsys-report-e966.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [12%                         ] report1.nsys-rep[1/1] [=16%                        ] report1.nsys-rep[1/1] [==21%                       ] report1.nsys-rep[1/1] [====26%                     ] report1.nsys-rep[1/1] [=====31%                    ] report1.nsys-rep[1/1] [=======37%                  ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [==========47%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
